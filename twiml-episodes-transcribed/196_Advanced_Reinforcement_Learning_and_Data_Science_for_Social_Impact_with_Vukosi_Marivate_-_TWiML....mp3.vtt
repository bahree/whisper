WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:32.000
I'm your host, Sam Charrington.

00:32.000 --> 00:37.560
In this the final show of our deep learning endoba series, we speak with Bucosi Maravate,

00:37.560 --> 00:43.360
chair of data science at the University of Pretoria and co-organizer of the endoba.

00:43.360 --> 00:46.880
My conversation with Bucosi fell into two distinct parts.

00:46.880 --> 00:51.440
The first part focused on his PhD research and the area of reinforcement learning.

00:51.440 --> 00:57.560
And we discussed several advanced RL scenarios, including in verse RL, multiple agent RL,

00:57.560 --> 01:02.720
and using reinforcement learning when you have an incomplete knowledge of the environment.

01:02.720 --> 01:07.080
We then moved on to discuss his current research, which broadly falls under the banner of data

01:07.080 --> 01:09.440
science with social impact.

01:09.440 --> 01:14.440
Specifically, we review several of the applications he and his students are currently exploring

01:14.440 --> 01:18.840
in areas such as public safety and energy.

01:18.840 --> 01:22.840
As we close out the series, I'd like to send a final word of thanks to our friends at

01:22.840 --> 01:24.320
Google AI.

01:24.320 --> 01:28.400
If you've got an interest in machine learning research and want to level up your skills

01:28.400 --> 01:32.640
in one of the top ML research groups in the world, you should take a moment to learn

01:32.640 --> 01:37.360
more about the Google AI Residency program, which recently opened up applications for

01:37.360 --> 01:40.280
perspective 2019 residents.

01:40.280 --> 01:44.800
The Google AI Residency is a one-year machine learning research training program with the

01:44.800 --> 01:49.960
goal of helping individuals from all over the world and with a diverse set of educational

01:49.960 --> 01:55.280
and professional backgrounds become successful machine learning researchers.

01:55.280 --> 02:00.520
Find out more about the program at g.co slash AI Residency.

02:00.520 --> 02:05.360
And now on to the show.

02:05.360 --> 02:08.680
Hey everyone, I am on the line with Bucosi Maravate.

02:08.680 --> 02:15.320
Bucosi is the chair of data science at the University of Pretoria and was a co-organizer

02:15.320 --> 02:17.520
of the deep learning in Daba.

02:17.520 --> 02:20.760
Bucosi, welcome to this week in machine learning and AI.

02:20.760 --> 02:22.400
Thanks for having me.

02:22.400 --> 02:23.400
Absolutely.

02:23.400 --> 02:26.520
Why don't we get started by having you tell us a little bit about your background and

02:26.520 --> 02:31.160
how you got interested and involved in data science and machine learning?

02:31.160 --> 02:37.240
Yeah, I guess I have a background in electrical engineering that was my undergrad in Masters

02:37.240 --> 02:40.400
when I was doing my undergraduate in electrical engineering.

02:40.400 --> 02:45.120
I got to a point where I said, yeah, I don't think I'm interested in this power stuff.

02:45.120 --> 02:50.440
But I am interested in artificial intelligence and data.

02:50.440 --> 02:55.240
So I moved to a stream here at the University of the Vett Vater Science in Johannesburg,

02:55.240 --> 02:59.840
which allowed us to work on more data problems and more coding.

02:59.840 --> 03:05.760
And by the time I was doing my fourth year at the University of being a senior, I was

03:05.760 --> 03:13.520
working then on AI, specifically doing some work with neural networks at the time.

03:13.520 --> 03:20.640
And then I stayed on for another year at Vett University, did a Masters looking at

03:20.640 --> 03:22.520
some reinforcement learning work.

03:22.520 --> 03:29.280
I was very interested in kind of like, oh, machines can learn to make decisions and you

03:29.280 --> 03:33.280
only have to give them this kind of reward.

03:33.280 --> 03:40.480
And so after spending that year, doing that, I had applied also for a scholarship, a full

03:40.480 --> 03:46.800
bright scholarship to go to the US and one of the schools I had chosen was Rutgers University

03:46.800 --> 03:51.520
because of kind of then who would then become my future PhD advisor.

03:51.520 --> 03:55.720
I was like, oh, this is one of the people I read about when I was reading about RL.

03:55.720 --> 03:59.600
So it could be interesting to work under him.

03:59.600 --> 04:08.960
I then in between that started working for the CSR in early 2009 and a few months later

04:08.960 --> 04:17.000
I was then off to New Jersey to start Rutgers on the PhD program and then had Michael Littman

04:17.000 --> 04:19.120
as my PhD advisor.

04:19.120 --> 04:26.800
So another thing again, as you're going through the motions of doing a PhD, you look at

04:26.800 --> 04:32.560
the area with some depth, I work on some work in investment reinforcement learning.

04:32.560 --> 04:38.280
I worked a bit on kind of trying to think about having multiple reinforcement learning

04:38.280 --> 04:43.680
learners at all at once, but I think that kept on making me wake up every morning was

04:43.680 --> 04:47.040
like, I'm really interested in making reinforcement learning a little bit more practical.

04:47.040 --> 04:54.040
So how do you do things like evaluation where you don't have access to a simulator or complete

04:54.040 --> 04:58.360
embodiment, so if you think about things like medicine, if you might think about things

04:58.360 --> 05:02.760
like kind of education, these type of areas, you're not really going to experiment with people

05:02.760 --> 05:04.240
with your infrastructure learning algorithm.

05:04.240 --> 05:08.720
So you want to do your evaluation offline and to do that, you need to take care of a couple

05:08.720 --> 05:09.720
of things.

05:09.720 --> 05:14.240
So evaluation here, meaning that you want to see how well your model after it's learned

05:14.240 --> 05:17.280
actually does without having to deploy it.

05:17.280 --> 05:21.200
So you can't say, hey, you're going to learn how to treat cancer.

05:21.200 --> 05:24.000
And then after that, you build a model and you say, okay, now the model's going to be

05:24.000 --> 05:26.320
applied on real patients.

05:26.320 --> 05:28.880
That is going to be problematic in some ways.

05:28.880 --> 05:33.440
There is work in that area to make that actually much more possible.

05:33.440 --> 05:37.480
But that's the thing I was interested in, but like I don't be interested in this again,

05:37.480 --> 05:43.440
hey, I really enjoy working from like a challenge that's out there and then working backwards

05:43.440 --> 05:48.360
into what then models will be useful, what learning algorithms will then be useful to

05:48.360 --> 05:50.080
then develop.

05:50.080 --> 05:53.920
And at that time, I was at 2011, 2012, I started hearing

05:53.920 --> 05:58.720
this thing of like, you know, oh, there's this term called data scientist.

05:58.720 --> 06:05.680
And it's people who will wrangle with data, use kind of a different techniques, not necessarily

06:05.680 --> 06:09.640
just from computing, might be from statistics, might be like, you know, from social science

06:09.640 --> 06:12.280
and then try to kind of tackle these problems.

06:12.280 --> 06:17.560
And that way, then I kept on gravitating towards that, towards that.

06:17.560 --> 06:23.640
So by the end of my PhD, I was like, okay, let me go try and see.

06:23.640 --> 06:27.680
As I'm going back to South Africa to see if I can work in data science.

06:27.680 --> 06:33.000
And that's where, like, you know, arriving the last three years or so, mostly I was

06:33.000 --> 06:39.440
based at the CSR, working with the team of other data scientists for about three years.

06:39.440 --> 06:46.480
And then now I've moved to University of Victoria, then as the chair of data science, still

06:46.480 --> 06:54.720
contain some research with colleagues or prior colleagues at the CSR.

06:54.720 --> 06:59.080
Did the transition to data science or that you're kind of blossoming interest in data science

06:59.080 --> 07:07.080
lead to a change in direction for your PhD research, or did you complete that in reinforcement

07:07.080 --> 07:08.080
learning?

07:08.080 --> 07:13.840
I completed the PhD in reinforcement learning, but the work basically became this kind

07:13.840 --> 07:18.600
of looking at other looking at education.

07:18.600 --> 07:23.360
We were looking at health applications and all like health challenges and then working

07:23.360 --> 07:27.560
to build up tools for evaluation in that area.

07:27.560 --> 07:33.000
You mentioned a few things in the RL area that I haven't heard much about.

07:33.000 --> 07:36.680
The first of those is inverse RL, what's that?

07:36.680 --> 07:41.480
So inverse reinforcement learning is, okay, in the general reinforcement learning framework,

07:41.480 --> 07:47.240
you've got an environment, you've got an agent, which is the machine learner that you're

07:47.240 --> 07:50.640
going to have, that agent can do actions.

07:50.640 --> 07:54.720
So it's allowed to choose some action and then it gets carried through and it might move

07:54.720 --> 07:56.040
around.

07:56.040 --> 08:00.440
So think about like, you know, dumb example, you have a room in a room and it can choose

08:00.440 --> 08:05.960
to move, yeah, like to move around and then it can choose sometimes to vacuum.

08:05.960 --> 08:11.400
And what you do is you say, okay, I'm not going to specify how, what you must do.

08:11.400 --> 08:13.680
And I'll give you a reward for something, right?

08:13.680 --> 08:17.200
So I'll give you a one if you vacuum the dirt or something like that.

08:17.200 --> 08:21.960
And I'll give you a very negative reward if your patchy runs out, all right?

08:21.960 --> 08:27.960
So the rumor then just giving those signals will go around and it will exploit the beginning

08:27.960 --> 08:32.360
or try different actions, it might go in and like, you know, just vacuum in a place that

08:32.360 --> 08:35.040
there's nothing so you won't get a reward.

08:35.040 --> 08:38.400
But then sometimes it will vacuum on somewhere where there is dirt and it's sense I would

08:38.400 --> 08:41.920
have said there's dirt, but it didn't know how to interpret it before.

08:41.920 --> 08:47.520
And after a while, it will learn like, okay, yeah, look around for dirt if there's dirt vacuum

08:47.520 --> 08:49.320
it off.

08:49.320 --> 08:52.680
And then that, you know, if the battery dies, I got a very negative thing.

08:52.680 --> 08:57.800
So keep track of the battery level and things like so over time, you think that you will

08:57.800 --> 09:02.640
inculcate in it, it will learn all these expected kind of behaviors.

09:02.640 --> 09:06.680
So an inverse reinforcement learning is that there is no reward that's specified, right?

09:06.680 --> 09:10.520
So you don't have a reward, which actually is hard to specify sometimes.

09:10.520 --> 09:14.960
But what you do is that you can actually observe somebody do something, right?

09:14.960 --> 09:21.080
So you actually go in and maybe you see other rumbers or you have a human actually have

09:21.080 --> 09:25.200
a remote control to the room and it moves around and it does things.

09:25.200 --> 09:30.720
And then from there, what the goal of the learning algorithm is to do is to actually learn

09:30.720 --> 09:35.400
what the reward function would have been to actually replicate the behavior that it's

09:35.400 --> 09:36.400
seen.

09:36.400 --> 09:39.000
So what this makes me think of is imitation learning.

09:39.000 --> 09:41.400
Is that a name collision or are these related?

09:41.400 --> 09:42.800
Yeah, they are related.

09:42.800 --> 09:46.000
So that's one of the kind of other way, like imitation learning that might be multiple

09:46.000 --> 09:47.800
ways to do it.

09:47.800 --> 09:51.240
But inverse reinforcement learning could be one of the ways that you do imitation learning.

09:51.240 --> 09:52.240
Okay.

09:52.240 --> 09:53.240
Yeah.

09:53.240 --> 09:58.760
But one of the things that is interesting if you do really capture that award in a good

09:58.760 --> 10:03.720
way with a good representation is that you can then transfer it between domains.

10:03.720 --> 10:09.640
It's hard, it's still not trivial, but you can then learn like what's important to who

10:09.640 --> 10:13.520
you've been observing and then you move it to different domains and then try to then

10:13.520 --> 10:16.440
estimate what behavior you would have seen from that person or thing.

10:16.440 --> 10:18.400
Can you give an example of that?

10:18.400 --> 10:23.440
So let's say you've got the room again, it goes into a room, you show at the beginning,

10:23.440 --> 10:28.280
you train the room, but you move around the room, but you learn, okay, there's things

10:28.280 --> 10:31.840
such as the things such as battery state, there's things such as obstacles.

10:31.840 --> 10:35.560
But now you just adjust the room or you move the room into a new room.

10:35.560 --> 10:40.480
And then it, because it's learned the reward, you don't, you no longer, it doesn't need

10:40.480 --> 10:41.480
to imitate anymore.

10:41.480 --> 10:45.880
It can just take the reward that it learned before and then say, oh, I'm in a new room,

10:45.880 --> 10:47.560
but I kind of get the rules.

10:47.560 --> 10:48.560
Mm-hmm.

10:48.560 --> 10:49.560
Got it.

10:49.560 --> 10:53.280
So that's a good, like, you know, you, you kind of can then transfer that reward to something

10:53.280 --> 10:54.280
else.

10:54.280 --> 10:55.280
I love the Roomba example.

10:55.280 --> 10:56.960
I've never heard anyone use that.

10:56.960 --> 11:01.600
Usually we're talking about video games and robots and like, I guess the Roomba is a robot,

11:01.600 --> 11:08.520
but usually we're talking about video games, but the Roomba is a great example for RL,

11:08.520 --> 11:11.520
not that the actual Roomba actually uses RL, but...

11:11.520 --> 11:17.880
Yeah, I like making examples that are kind of very much more closer to people's, like,

11:17.880 --> 11:18.880
regular lives.

11:18.880 --> 11:21.680
Even though, like, most of us, I don't even have a Roomba.

11:21.680 --> 11:22.680
Right.

11:22.680 --> 11:25.480
But it's like, once you say it, people get it.

11:25.480 --> 11:26.480
Like, oh, okay.

11:26.480 --> 11:29.080
Yeah, you know, yeah, yeah, I see it, I see it now.

11:29.080 --> 11:30.080
Yeah.

11:30.080 --> 11:31.720
Roomba's even still a thing.

11:31.720 --> 11:32.720
Do they still...

11:32.720 --> 11:33.720
Yeah, yeah.

11:33.720 --> 11:37.320
They're a lot of them, and I've been trying to figure out how to get one from Xiaomi.

11:37.320 --> 11:42.640
It's not a Roomba, it's some other brand, I mean, another name, yeah, hopefully we don't

11:42.640 --> 11:43.640
get it.

11:43.640 --> 11:46.760
Yeah, but they still are there, and they're getting crazy.

11:46.760 --> 11:52.640
So you also mentioned multiple RL learners, kind of obvious from the context what that refers

11:52.640 --> 11:58.840
to, but I haven't seen much in terms of published research in that area.

11:58.840 --> 12:04.320
What are, kind of, some of the major challenges and results that folks have been seeing with

12:04.320 --> 12:05.320
multiple learners?

12:05.320 --> 12:11.800
Oh, this has been a while working in that space, but you can think about different settings.

12:11.800 --> 12:16.080
So one is that you could have, like, learners that have to co-operate.

12:16.080 --> 12:20.080
So working together to solve a bigger, like, high-level goal.

12:20.080 --> 12:24.960
So, like, you know, you can have a team playing a game, like, you know, here we can talk about

12:24.960 --> 12:27.000
football, which now has changed.

12:27.000 --> 12:33.320
I'm giving back, I'm back in South Africa, so football needs something else, so you could

12:33.320 --> 12:36.960
have multiple, like, you know, they're trying to play soccer, and then, again, you give them

12:36.960 --> 12:39.560
rewards, but then now they have to learn how to cooperate.

12:39.560 --> 12:43.760
That's one way of thinking about it, that's not really what I was trying to do sometime

12:43.760 --> 12:49.680
in my PhD, but one way was, okay, you have these different learners, but they only get different

12:49.680 --> 12:51.000
experiences, right?

12:51.000 --> 12:56.160
So the other time that they spend in the environment, it only gets them to see different parts

12:56.160 --> 12:57.160
of the world.

12:57.160 --> 13:01.360
You know, how do you take this, and then almost try to use their brains to get to something

13:01.360 --> 13:02.680
that is much better?

13:02.680 --> 13:08.200
So it brings you back to, like, ensemble methods, and could ensemble methods actually be something

13:08.200 --> 13:10.000
that works in reinforcement learning?

13:10.000 --> 13:11.000
Okay.

13:11.000 --> 13:12.000
Interesting.

13:12.000 --> 13:13.000
Yes.

13:13.000 --> 13:18.960
Another thing you mentioned it, the first of those examples, I did an interview recently

13:18.960 --> 13:26.800
about the OpenAI Dota OpenAI 5, which is, like, these five different agents that are operating

13:26.800 --> 13:32.640
in this environment, and need to figure out how to cooperate, and they do some interesting,

13:32.640 --> 13:36.200
some interesting kind of emergent behaviors we're seeing there.

13:36.200 --> 13:37.200
Okay.

13:37.200 --> 13:45.520
So you mentioned inverse RL, multiple RL learners, and then evaluation in incomplete environments,

13:45.520 --> 13:50.080
which you kind of alluded to with the multiple learners, where they're kind of learning different

13:50.080 --> 13:54.160
things independently, and then you're fusing what they're learning together.

13:54.160 --> 13:57.080
Was there other work that you did around these incomplete environments?

13:57.080 --> 14:02.880
It's not really incomplete environments, as opposed to you don't have access to them.

14:02.880 --> 14:11.120
So one of the things was, like, we wanted to look at health chronic disease management,

14:11.120 --> 14:15.840
and things like you can do things like marketing, because you've got a lot of that.

14:15.840 --> 14:19.160
So you don't have access to the environment in chronic disease, so you don't have access

14:19.160 --> 14:20.160
to your patients.

14:20.160 --> 14:25.320
But you can have historical diagnostic information, and also follow-up diagnostics.

14:25.320 --> 14:31.280
So in this case, I was looking at HIV, which, finally enough, I had also worked in my undergrad

14:31.280 --> 14:38.320
briefly looking at missing data for HIV, but then now I was actually looking at treatment.

14:38.320 --> 14:44.560
So we're going to simplify it again, so you've got a multiple patients going through treatments

14:44.560 --> 14:49.200
for HIV, and what you want to do to learn from there is a policy that in the future when

14:49.200 --> 14:55.840
you get a new patient, you can take some information from there and be able to personalize a treatment.

14:55.840 --> 15:01.840
But that treatment for HIV is sequential, so it's not simply a one decision is made, and

15:01.840 --> 15:02.840
that's it.

15:02.840 --> 15:05.920
So you're not going to choose a drug cocktail, and it's going to last for the life of the

15:05.920 --> 15:06.920
patient.

15:06.920 --> 15:10.720
So you're going to have multiple times you have to make decisions, so meaning you keep

15:10.720 --> 15:13.120
drug cocktail number one.

15:13.120 --> 15:18.360
It works for a while, and then it might stop working, unfortunately, given how HIV actually

15:18.360 --> 15:22.920
progresses, and then you have to then make a choice of switching to another treatment.

15:22.920 --> 15:24.640
And this could go on for a couple of times.

15:24.640 --> 15:28.960
So we restricted the problem into, I think, only two stages where you say you're going

15:28.960 --> 15:32.080
to get your initial treatment, and if you switch, what should then be the next treatment?

15:32.080 --> 15:36.280
So this becomes a sequential decision-making problem, which, again, is very nice for

15:36.280 --> 15:39.240
reinforcement learning, because that's exactly what you want to learn.

15:39.240 --> 15:43.520
But what you want to do is that because you're not going to have access to the real patients,

15:43.520 --> 15:48.800
to do the evaluation after you've learned from the data, we split the kind of learning

15:48.800 --> 15:57.440
into a process where some learning is used to just learn a model of the environment given

15:57.440 --> 15:59.080
the data that you've seen.

15:59.080 --> 16:03.120
So it's almost like you're building some sort of simulator, but it's going to have noise,

16:03.120 --> 16:07.720
because sometimes you haven't seen a specific drug cocktail used enough for you to really

16:07.720 --> 16:10.800
be sure what kind of effect it's going to have on a patient.

16:10.800 --> 16:14.600
So you have to then bring in uncertainty of saying that, okay, here you might end up

16:14.600 --> 16:16.760
with a viral load between here and here.

16:16.760 --> 16:22.160
So we then built up a model-based reinforcement learning algorithm that estimated, and the

16:22.160 --> 16:29.120
effect that drugs would have on a potential patient, and the information that we captured

16:29.120 --> 16:33.600
from the patient was like the demographics, some information about the disease at the

16:33.600 --> 16:38.320
beginning, and then from there you then run, and you're also learning algorithm that estimates

16:38.320 --> 16:43.040
then, okay, saying, okay, if you were to give a drug cocktail that was drug number, I mean,

16:43.040 --> 16:47.080
drug cocktail number one was this, and drug cocktail number two was this, this is likely

16:47.080 --> 16:52.280
how well you manage the disease over the next X amount of turns.

16:52.280 --> 16:59.880
Yeah, it's interesting, so it's like part of the environment is modeled probabilistically,

16:59.880 --> 17:05.080
and the agent has to figure out what to do with that constraint.

17:05.080 --> 17:10.400
Yes, yes, so because again, it brings up this thing of like you now want to allow people

17:10.400 --> 17:15.680
to do RL without necessarily having access to the real kind of thing, but they've got

17:15.680 --> 17:23.240
enough prior data to do something at least useful, and then you then could then say, okay,

17:23.240 --> 17:28.320
I want to also evaluate how close I am to the real world in some way.

17:28.320 --> 17:34.520
Some of the work of Susan Murphy at University of Michigan, they've done a lot of work in

17:34.520 --> 17:37.320
this area, and she was on my PhD committee.

17:37.320 --> 17:44.440
And so kind of fast-forwarding, you're now focused on data science at University of

17:44.440 --> 17:50.720
Pretoria, and a lot of your interests are centered around this idea of data science with social

17:50.720 --> 17:51.720
impact.

17:51.720 --> 17:53.520
What does that mean for you?

17:53.520 --> 18:01.600
So for me, social impact means like there's, we have a world that has kind of challenges,

18:01.600 --> 18:05.800
and from these challenges, you can come up with very interesting data science kind of problems

18:05.800 --> 18:08.200
that you can then do research on.

18:08.200 --> 18:13.920
And some of these will kind of have a flavor that's very similar around the world.

18:13.920 --> 18:21.040
So for example, while I was at CSR, one of the initial areas we had looked at is trying

18:21.040 --> 18:25.880
to think about public safety, and then thinking, if we have the constraint that we might not

18:25.880 --> 18:31.920
really have access to raw public safety data, could we use a proxy?

18:31.920 --> 18:36.280
And the proxy we had come up with was maybe social media is there, people might be describing

18:36.280 --> 18:40.720
incidents that are going on, like you know, it might be a fire, it might be a car accident,

18:40.720 --> 18:44.840
and from there, can you build something that at least gives you an indication of what

18:44.840 --> 18:48.280
might be going on in a town or in a city?

18:48.280 --> 18:54.480
So that is one, the other could be pay, I want to, you know, this data that I have access

18:54.480 --> 19:00.040
to, and we want to look at behavior in that data, and we want to pick out things that don't

19:00.040 --> 19:01.040
make any sense.

19:01.040 --> 19:02.200
So you want to look at anomaly.

19:02.200 --> 19:08.800
So I work with a student, two students to work on anomaly detection algorithms with

19:08.800 --> 19:13.360
that in mind, and hoping to get to a point where now, let's say you're looking at behavior

19:13.360 --> 19:18.240
of people purchasing electricity, which is one project, we had worked on at the CSR

19:18.240 --> 19:22.120
and I still continue to collaborate with some people at CSR on this, but you want to

19:22.120 --> 19:28.280
look at how people like purchase electricity, and if they have behavior that is anomalous,

19:28.280 --> 19:35.560
try to then go and understand why they are anomalous, and stick into the energy thing.

19:35.560 --> 19:39.720
You can then think about the same thing of saying, hey, now I'm not going to look at electricity

19:39.720 --> 19:42.040
purchase, but I might look at generation.

19:42.040 --> 19:48.760
So South Africa has been trying to build on more renewable energy, and you have a couple

19:48.760 --> 19:52.680
of research that we're interested in, hey, where should we be putting wind farms in the

19:52.680 --> 19:53.680
country?

19:53.680 --> 19:58.680
So we've got a couple, like, you know, a lot of data with wind data from, for all of South

19:58.680 --> 20:03.200
Africa, with, you know, about five, five by five kilometer pixels, and I work with some

20:03.200 --> 20:10.000
students then to say, what way are the most suitable places for wind farms given some constraints,

20:10.000 --> 20:13.960
like this place where you can build, you can be too close to communities, you can be

20:13.960 --> 20:18.920
too close to national parks, you can be too far away from roads, you can be too far away

20:18.920 --> 20:22.160
from distribution lines, those, those type of things.

20:22.160 --> 20:25.720
And with that, it kept on continuing where it's like, okay, fine, now you kind of know

20:25.720 --> 20:30.160
where your wind farms are going to be, now you want to predict how much wind you're going

20:30.160 --> 20:36.960
to have, let's say, over the next, the next couple of days, and then, or a couple of hours

20:36.960 --> 20:39.040
because then you can then predict the amount.

20:39.040 --> 20:44.640
So that's been going on with a couple of collaborators working in energy kind of a prediction.

20:44.640 --> 20:45.800
Yeah.

20:45.800 --> 20:50.040
So there's a bunch of interesting stuff to dive into there.

20:50.040 --> 20:56.200
Maybe to get started, I've got some questions about this wind farm placement problem.

20:56.200 --> 20:59.520
And in particular, folks have approached this placement problem with different types

20:59.520 --> 21:04.080
of optimizations that aren't necessarily machine learning.

21:04.080 --> 21:08.280
What does machine learning add to the mix in this particular type of problem?

21:08.280 --> 21:14.720
And how do you, what kinds of data science methods do you end up applying?

21:14.720 --> 21:15.720
Sure.

21:15.720 --> 21:23.200
So with the placement, when I work, we work with a student at African Institute for

21:23.200 --> 21:26.320
Mathematical Sciences, and then we use the suitability method.

21:26.320 --> 21:30.080
So yes, it wasn't machine learning, I was just a kind of statistical mathematical model

21:30.080 --> 21:37.600
that said, given what you rank, what's important to you, and given the rankings, then it changes

21:37.600 --> 21:38.600
the suitability.

21:38.600 --> 21:39.600
Got it.

21:39.600 --> 21:40.600
Yeah.

21:40.600 --> 21:47.200
So the student, Shanei Franckran, she worked on a suitability model, and that model we're

21:47.200 --> 21:52.640
able then to tweak it, you can then say, okay, I'm not really interested in the environmental

21:52.640 --> 21:54.360
things, for example.

21:54.360 --> 21:57.760
Like, you know, if you are that way inclined, then you could remove it.

21:57.760 --> 22:00.400
And then from there, we'll say, okay, these are the best places to build.

22:00.400 --> 22:06.440
You might say, yeah, the cost of how far I should be from roads, don't really care about

22:06.440 --> 22:07.440
it.

22:07.440 --> 22:11.400
And then it would change kind of the suitability.

22:11.400 --> 22:17.680
But where machine learning comes in now is on the flip side of saying, okay, fine.

22:17.680 --> 22:21.520
One other thing that comes into perspective is that you might have an area.

22:21.520 --> 22:26.400
You have some historical data in terms of how much wind was being generated.

22:26.400 --> 22:31.600
And now you're interested in how much wind will be generated over the next 24 hours.

22:31.600 --> 22:37.160
So you build, you build your wind farm, and you just need to make a decision on am I going

22:37.160 --> 22:41.360
to have to, like, you know, fire up my cold power station or my nuclear power station.

22:41.360 --> 22:44.120
I don't think nuclear power stations probably just go on and off.

22:44.120 --> 22:50.080
But let's say my cold power station, but I need to know kind of what's going to happen

22:50.080 --> 22:51.080
tomorrow.

22:51.080 --> 22:58.200
So they've been continuing collaborations with Boubacard Ames, with a couple of other students

22:58.200 --> 23:04.360
to then say, hey, can we build predictive models that can then just predict 12 hours ahead.

23:04.360 --> 23:08.480
And we've also brought in the Colleen Huerta, who's also at CSR, who had worked on a couple

23:08.480 --> 23:09.640
of models before.

23:09.640 --> 23:12.600
But now we're using deep learning for that.

23:12.600 --> 23:20.800
In this whole wind farm area, both the placement and the prediction of output, it's

23:20.800 --> 23:26.240
seen, it strikes me that there are a lot of moving parts to a problem like this.

23:26.240 --> 23:32.280
Can you kind of, you know, walk us through where some of the major challenges were and

23:32.280 --> 23:34.520
how they were addressed?

23:34.520 --> 23:35.760
Um, yeah.

23:35.760 --> 23:39.600
So getting all the data, I think, was challenging.

23:39.600 --> 23:46.040
So the, oh, the partly lucky thing is I have a wife who works in renewable energy.

23:46.040 --> 23:47.040
Okay.

23:47.040 --> 23:53.680
So we should have also, like, you know, spearheaded that I keep track of this research area,

23:53.680 --> 23:57.200
like as something that just keeps on kind of ongoing.

23:57.200 --> 24:03.280
So data science, step one is, yeah.

24:03.280 --> 24:09.000
So in this case, like, I do remember sometimes where I, like, you know, I would ask a student

24:09.000 --> 24:12.000
to ask and say, oh, yeah, I need access to data that matters like this.

24:12.000 --> 24:13.320
I don't know where to get it.

24:13.320 --> 24:15.800
And then I would just ask my wife and she would be like, oh, yeah, this would be on the

24:15.800 --> 24:19.880
Department of Environmental Affairs website and you would be able to get it.

24:19.880 --> 24:24.600
So things, things like protected areas, things like the national grid.

24:24.600 --> 24:29.200
So where all the big transmission lines are, those type of things.

24:29.200 --> 24:34.560
So you have to do kind of a big exercise on, on capturing from the design, I'm sorry,

24:34.560 --> 24:40.520
from the, like a potential client, what they take is being informative.

24:40.520 --> 24:42.520
And then from there saying, okay, what data do you have?

24:42.520 --> 24:46.880
And from the data, they don't have go in, find it outside to say, okay, we have to go

24:46.880 --> 24:49.080
find, find this data.

24:49.080 --> 24:55.640
And so were these various things that you were tracking the protected areas and the grid

24:55.640 --> 24:58.800
were these provided in a useful way?

24:58.800 --> 25:04.840
Like did you have to go from, I don't know, some kind of description to, like, bounding

25:04.840 --> 25:09.600
boxes or let long or something for various features?

25:09.600 --> 25:13.040
Yeah, so you're going to have assumptions that you're going to have to make, especially

25:13.040 --> 25:16.560
now you're working on like a five by five kilometer cell.

25:16.560 --> 25:21.520
So you could say how many wind turbines can fit or you fit in there, you're going to make

25:21.520 --> 25:28.080
an assumption that you're going to put only, like, you know, in one percent of the area.

25:28.080 --> 25:31.000
The simplest one is just to say, I'm going to put one wind turbine.

25:31.000 --> 25:35.680
It's not really true because what happens is that if you put wind turbines next to each

25:35.680 --> 25:40.760
other, they're going to have wakes, and from the wakes, they actually then impact on how

25:40.760 --> 25:43.960
much energy is actually going to be generated in total.

25:43.960 --> 25:47.200
So it's not simple, but you can make that assumption, say, I'm just going to have one wind

25:47.200 --> 25:48.200
turbine.

25:48.200 --> 25:52.240
And now I'm going to just try to figure out how much power would be generated.

25:52.240 --> 25:57.240
You have different heights of that wind turbine could be, you have different configurations

25:57.240 --> 25:58.720
of those wind turbines.

25:58.720 --> 26:06.560
So we had to kind of allow some flexibility with that of saying a user of the system can

26:06.560 --> 26:10.560
choose and say, I want to, I'm interested in wind, I mean, at a turbine that's at this

26:10.560 --> 26:14.240
height using this type of configuration, here's how big it's wind span.

26:14.240 --> 26:18.600
It's going to be, if you're trying to look at where all the major roads are, I'm trying

26:18.600 --> 26:23.640
to remember if we kind of did a hack on the Google Maps API, I might have been trying

26:23.640 --> 26:26.800
to figure out if there was a major road going through every block.

26:26.800 --> 26:30.040
And then from the estimating how far you are from a major highway.

26:30.040 --> 26:31.040
Yeah.

26:31.040 --> 26:36.800
So I think it was something of look, I think we had written some scripts for Google Maps

26:36.800 --> 26:45.080
to identify where all the highways were and how far each five, five kilometer pixel was

26:45.080 --> 26:46.800
from the major highway.

26:46.800 --> 26:52.520
And so for these various features, did you end up encoding them binarily?

26:52.520 --> 26:57.360
This one has a grid, doesn't have a grid, has a highway, doesn't have a highway and then

26:57.360 --> 27:03.720
just kind of counted pixels, or did you, were you kind of treating it more fine grain than

27:03.720 --> 27:04.720
that?

27:04.720 --> 27:09.760
As for Shane's work, there was a little bit more fine grain decisions that were made

27:09.760 --> 27:14.560
in just like, are you near, are you somewhere not too far and then are you far?

27:14.560 --> 27:20.840
And yeah, so you can have those knobs and then you can also kind of play with them.

27:20.840 --> 27:26.360
You can also then quantify them as cost instead and then say how costly is this going to

27:26.360 --> 27:27.360
be?

27:27.360 --> 27:31.680
And yeah, with some things a protected area, it's either it's there or it's not really,

27:31.680 --> 27:35.920
like, you know, so if there's a national park there, you don't build really sort of

27:35.920 --> 27:39.480
very negative, if I was thinking about rewards, they're going to be just a very big negative

27:39.480 --> 27:40.480
reward.

27:40.480 --> 27:41.480
Right, right.

27:41.480 --> 27:43.720
Yeah, kind of things like don't do it.

27:43.720 --> 27:47.920
And then if you had, then perfect where you had good wind because that was the other thing

27:47.920 --> 27:55.320
is that do you have a lot of wind that's in that area and then also what's your slope?

27:55.320 --> 27:56.320
So is it very sharp?

27:56.320 --> 28:00.240
A slope, if it is, you don't want to build there, you want to build as close to flat as possible.

28:00.240 --> 28:06.840
And you mentioned that some of these various data sets were on government websites was

28:06.840 --> 28:11.920
this project something that could have been done by anyone was or all the data sets publicly

28:11.920 --> 28:17.240
available or was there some private data that was used to figure this out?

28:17.240 --> 28:23.240
Yeah, so the wind data specifically, not that there is wind data that you can get for

28:23.240 --> 28:28.080
South Africa, that's open, but the one that we're using was one that was part of a study

28:28.080 --> 28:31.720
inside the CSR, so they did give access to the students to work on it.

28:31.720 --> 28:32.720
Okay.

28:32.720 --> 28:35.880
Yeah, yeah, on there, so you wouldn't necessarily have access to that, but I can point out

28:35.880 --> 28:43.400
people to kind of, I think there's a couple of stations across South Africa that are

28:43.400 --> 28:49.160
used and have public data, where if you want to go download the wind, I think it's called

28:49.160 --> 28:54.840
Wind Atlas South Africa, you can get data, but it would be for specific areas that are

28:54.840 --> 29:00.920
covered at the moment, but not every cell, the one that we had was a model that was used

29:00.920 --> 29:03.480
to extrapolate for the whole country, what the wind map would have been.

29:03.480 --> 29:07.680
Yeah, you also mentioned you did something on the utility side, is that there was different

29:07.680 --> 29:09.880
than the wind farm project?

29:09.880 --> 29:16.440
Yeah, yeah, so again, with the social impact, what I've been trying to do is get to point

29:16.440 --> 29:21.720
we're working with some of the local municipalities here in South Africa to look at some of their

29:21.720 --> 29:23.760
kind of problems.

29:23.760 --> 29:27.760
So with there, we had worked on, you've got electricity data in terms of purchases on

29:27.760 --> 29:32.440
a monthly basis, and from there, you can do kind of things, you can build, do analytics

29:32.440 --> 29:36.920
where you're just looking at, okay, what's kind of the span patterns, one which I still

29:36.920 --> 29:44.400
want to work on is now looking at these deviations from those spending patterns to try to identify

29:44.400 --> 29:45.400
behavior.

29:45.400 --> 29:53.920
So one that the city was interested in, Steve Swanee where I live and I work is could somebody

29:53.920 --> 29:59.920
have an install solar for you, for example, and how would we then capture that in the system

29:59.920 --> 30:05.880
and the students we're working with on that also kind of try to figure out a couple of

30:05.880 --> 30:07.520
heuristics to do this.

30:07.520 --> 30:11.920
So one was bringing in weather data again and looking at days or months that were particularly

30:11.920 --> 30:18.400
humid or they had lots of cloud cover during those months, you would expect that the solar

30:18.400 --> 30:21.880
use would be less because there would be less power actually generated and then you want

30:21.880 --> 30:26.720
to then see if that meant that the household during that time would then spend more on buying

30:26.720 --> 30:28.680
electricity from the city.

30:28.680 --> 30:32.440
What were the data sources that were used there?

30:32.440 --> 30:36.760
So that one, the data is internal to the city in terms of the electricity purchase data

30:36.760 --> 30:41.880
and then external is like using weather information and then using mapping which you have access

30:41.880 --> 30:44.200
to mapping for the country.

30:44.200 --> 30:47.680
So it's not as involved as the wind prediction one.

30:47.680 --> 30:51.400
Okay, and what kind of models did you end up producing for that?

30:51.400 --> 30:54.760
We're still trying to work on some anomaly detection models for it so that's not complete

30:54.760 --> 31:00.880
as yet but we are working on writing up on the analytics part of the work and then there's

31:00.880 --> 31:07.880
one on trying to look at the segmentation of the customers.

31:07.880 --> 31:12.000
So we're actually using a recent see if you can see monetary value analysis that's called

31:12.000 --> 31:17.760
RFM and it's used a lot in marketing but then using it now to understand the different

31:17.760 --> 31:21.800
baskets of customers that the city has.

31:21.800 --> 31:24.040
I'm sorry, what was the RFM?

31:24.040 --> 31:26.600
Renaissance frequency and monetary value.

31:26.600 --> 31:32.640
Let's see frequency monetary value and can you give us an overview of that model?

31:32.640 --> 31:40.320
Sure, you calculate for each customer in the last six months how much they have they

31:40.320 --> 31:45.320
bought, when's the last time they bought and how many times have they bought?

31:45.320 --> 31:49.080
For example, and from there you're then going to find some baskets so you can find that

31:49.080 --> 31:54.480
oh there's baskets of people buy a lot, five very frequently and they bought within the

31:54.480 --> 31:59.600
last month and some people might be that they buy very infrequently by small amounts

31:59.600 --> 32:01.840
and yeah, there's a little.

32:01.840 --> 32:07.600
Okay, and so you're using those metrics, the recent see frequency and value as a way

32:07.600 --> 32:10.920
to kind of cluster or segment the customer base?

32:10.920 --> 32:15.400
Yeah, it's a clustering mechanism basically and you can test it against your things like

32:15.400 --> 32:17.120
your k-means as well.

32:17.120 --> 32:20.920
The goal in applying that technique is what?

32:20.920 --> 32:27.440
So there is then you can think about what if then I wanted to estimate, if some of my

32:27.440 --> 32:32.560
customers are in one batch and I was too fine to move them to another batch, what could

32:32.560 --> 32:35.520
be the impact on my revenue, right?

32:35.520 --> 32:41.520
Because each group will have specific characteristics and there might be that you're trying to identify

32:41.520 --> 32:47.920
and say okay, maybe then you have people who would likely be moving to solar or something

32:47.920 --> 32:52.960
like that, so if I then said the people who are frequent users started using solar and

32:52.960 --> 32:58.600
they move to another batch, how much money would I lose from them moving to solar, but

32:58.600 --> 33:02.960
maybe how much could I gain if I offered a product that was much more compatible to households

33:02.960 --> 33:04.120
that you solar.

33:04.120 --> 33:10.440
So one might be I buy electricity from them at different times of the day and then I

33:10.440 --> 33:14.240
sell it to them back at night but I can take that same electricity I bought from them

33:14.240 --> 33:17.720
and I sell it to other people also and make more revenue.

33:17.720 --> 33:19.880
So it's kind of gaining those insights.

33:19.880 --> 33:27.080
You also mentioned the public safety project that was based on some social media analysis?

33:27.080 --> 33:32.480
Yeah, so this has been like a thread now that's run through probably the last few years

33:32.480 --> 33:35.520
is just working on natural language in one way or another.

33:35.520 --> 33:42.640
So initially when I started 2015 or so it was just to go like okay, could we use social

33:42.640 --> 33:48.520
media as a way to identify if there's public safety issues, so you just want it's a very

33:48.520 --> 33:51.400
cost and not accurate way.

33:51.400 --> 33:56.040
So one could be I wanted if people are complaining about an accident and they describe that there's

33:56.040 --> 34:01.560
an accident in a specific area in the city, could we pinpoint that and then from there

34:01.560 --> 34:06.080
kind of come up with a map that is just showing you from people going on to our public

34:06.080 --> 34:12.840
Facebook pages and putting this up so that way we kind of started and we worked on the

34:12.840 --> 34:20.720
kind of a initial model that was very basic language processing model and then we worked

34:20.720 --> 34:25.400
on it to then say okay one of the challenges that you have is that you can't really label

34:25.400 --> 34:32.280
a lot of the data so you can only label like some subset of it so that we worked on then

34:32.280 --> 34:37.400
doing kind of something like very rudimentary semi-supervised learning where you take a

34:37.400 --> 34:41.360
model, you take your data that you've labeled, you train a model and then you try to train

34:41.360 --> 34:45.720
more of the stuff that you haven't seen and you want to see if it will actually impact

34:45.720 --> 34:51.240
your performance, we took into account maybe even network effects so identifying kind

34:51.240 --> 34:54.800
of stuff about who's posting because there's these questions that come up about can you

34:54.800 --> 34:58.680
trust all the information that you get on social media maybe there's things like if you

34:58.680 --> 35:06.520
have somebody who has no followers and it just recently showed up maybe it's not you

35:06.520 --> 35:12.000
should just fill that out and not try to classify that and then start working with a couple

35:12.000 --> 35:19.440
of students like on things around like you know again using short text data for a couple

35:19.440 --> 35:25.680
of things so one is being one PhD student who's working on identifying authors so it's

35:25.680 --> 35:30.560
getting connected to this kind of trusting so saying who actually wrote this like you

35:30.560 --> 35:36.920
know a short piece of text and can we identify that so he's been working on kind of deep learning

35:36.920 --> 35:44.960
frameworks to be able to do that and there's been more work in now extending some of what

35:44.960 --> 35:52.320
we had done on using short text as a way to understand so right now still working on

35:52.320 --> 35:58.520
some methods to bring in more robustness in learning from short text without a lot

35:58.520 --> 36:04.280
of data so what what might happen or what I'm like hypothesizing is that if you're using

36:04.280 --> 36:09.560
social media as a data source some of the things that might happen over time is that there's

36:09.560 --> 36:16.560
a quick change in language sometimes and because of this and also because you have got like

36:16.560 --> 36:20.920
you know not that many words people might say the same thing in multiple ways but you

36:20.920 --> 36:24.240
don't have again you know you're not a Google you're not a Facebook so you're not going

36:24.240 --> 36:30.240
to have infinite amount of almost infinite amount of resources to actually label everything

36:30.240 --> 36:34.000
that you have what you might have a subset that's labeled and how can you use that smaller

36:34.000 --> 36:40.600
subset of data and try to make it kind of bigger and then by that improve how your machine

36:40.600 --> 36:44.720
learning model is actually going to perform over time so you don't want it that you train

36:44.720 --> 36:47.600
something and then three years later it actually is really bad.

36:47.600 --> 36:54.960
You mentioned that in there this kind of sub project of identifying the author of short

36:54.960 --> 37:00.560
pieces of text can you elaborate on that you're meaning identifying the author of a tweet

37:00.560 --> 37:06.440
for example or identifying the author meaning so you have the tweet but not the account

37:06.440 --> 37:13.320
that posted it or you trying to correlate it with authors that are outside of social media

37:13.320 --> 37:20.280
or what exactly you're trying to do there. Yeah so there I'll use a like okay more

37:20.280 --> 37:26.440
topical example today is this that you might have yes a short piece of text and what you're

37:26.440 --> 37:31.400
trying you you you say it sure it says it's from this person like you know they're saying

37:31.400 --> 37:36.360
it's from me but then you can actually look at the content and say oh actually this is

37:36.360 --> 37:41.800
not from this person this type of content is actually generated by these other people right

37:41.800 --> 37:47.320
so typically yes this might move into hey how does fake news get generated there's likely

37:47.320 --> 37:53.000
some generator that's like you know not that level we hope so that's one way you can think

37:53.000 --> 37:57.480
about it another way you can think about it's like you know you can see people taking content

37:57.480 --> 38:03.240
without attribution on there and you can kind of build up a source of kind of way of linguistics

38:03.240 --> 38:11.560
style that's that has happened I mean sorry that is in in that text so abedium woodoube who's

38:11.560 --> 38:18.680
supervising his PhD he's working on that and it's been kind of a way to to understand like

38:18.680 --> 38:24.200
you know oh this is actually real new content it's not something that somebody else posted

38:24.200 --> 38:29.160
before and this person might be just like you know reposting in kind of in a way you can think

38:29.160 --> 38:34.280
about it in terms of bots of identifying bots you can think about it in terms of terrorism in

38:34.280 --> 38:39.640
terms of trying to identify where source of information might have come from are you comparing it

38:39.640 --> 38:45.720
to other things that that user has tweeted to see if it's anomalous relative to what they've

38:45.720 --> 38:53.880
tweeted are you comparing it to the entire corpus to see if there's some large group of users that

38:53.880 --> 39:00.840
are all kind of tweeting the same things or the same way are you comparing it to some offline

39:00.840 --> 39:08.440
you know totally offline corpus to see if you can correlate others in one corpus to tweets

39:09.640 --> 39:13.480
it seems like you can do a ton of different things with this there's yeah there's a lot of

39:13.480 --> 39:19.240
different ways so yes one which you've highlighted we're not doing it in this case is you you

39:19.240 --> 39:23.480
could just look at the behavior of a person and like you know okay they write about this they tweet

39:23.480 --> 39:27.640
about this they might be a blog like you know they blog about this and then something shows up and

39:27.640 --> 39:34.200
you're like okay something's off here and that flags like you know saying hmm something is odd

39:34.840 --> 39:41.480
but then that doesn't really give you kind of power to then say okay where could this have come

39:41.480 --> 39:47.240
from but that's maybe you can then put that as a second item and say we're going to deal with this

39:47.240 --> 39:54.040
but a way that is like the maybe the simplest way to think about it is that you could say okay

39:54.040 --> 39:59.160
I'm going to characterize for something major where content comes from right so if you're looking

39:59.160 --> 40:04.200
at bloggers so you could if you were medium build up a huge database of all your bloggers

40:04.200 --> 40:08.440
and what they create and then you build a machine learning model that then every time you get a

40:08.440 --> 40:13.800
piece of content you can say oh it comes from this author right with with high probability I can

40:13.800 --> 40:18.280
tell you that this is the author who like the wrote wrote that thing but then yesterday you're

40:18.280 --> 40:23.720
scaling with lots lots of labels right because now you have a multi-class problem and you could have

40:23.720 --> 40:30.200
hundreds of thousands of labels that then put if then if you're Twitter you know millions if not

40:30.200 --> 40:38.440
billions over time that you've kind of gotten into so the classes might be different given different

40:38.440 --> 40:45.160
constraints so one you might just say is this original if is it not like and and and that could be

40:45.160 --> 40:51.240
a simple dichotomy that you then use as a labeler and then you want to now build the architecture

40:51.240 --> 40:54.600
like a deep learning architecture that can learn well from that because you don't have a

40:54.600 --> 41:00.760
and long space string of text you then can do even other things you can then say okay fine

41:00.760 --> 41:05.800
I'm not going to look at one treat an isolation maybe I look at the last five treats all right and

41:05.800 --> 41:11.560
then see what's actually do you go on what kinds of models are you looking at with that one

41:11.560 --> 41:17.400
on the deep left side yeah it's kind of kind of kind of based text models and yeah using

41:17.400 --> 41:22.120
auto n's and CNN's maybe that to kind of wrap things up I'm wondering as you look across this

41:22.120 --> 41:31.160
portfolio of projects focused on social impact applications of data science are there common threads

41:31.160 --> 41:38.360
or trends or challenges that you tend to see when you're trying to apply this set of tools to

41:38.360 --> 41:44.840
these types of problems or you know do they vary widely and don't have you know any any common

41:44.840 --> 41:51.800
alities yeah there's some things you learn through through time so so one is kind of how to

41:51.800 --> 41:57.720
define projects in a good way is good so you have to have a common language with who you're

41:57.720 --> 42:02.520
working with so people come to you and say we have this problem we think machine learning can

42:02.520 --> 42:08.360
assist like you know and then you go like okay what kind of data do you have and why do you think

42:08.360 --> 42:13.960
kind of predictions might help or anomaly detection might help and taking the time to kind of get

42:13.960 --> 42:22.840
a common language is useful because then it I think makes it much more interesting one is to stay

42:22.840 --> 42:27.800
away from like you know taking the ham like you know the hammer that you have and everything

42:27.800 --> 42:33.240
looking like a nail is that analogy yeah so sometimes you just go in and go like okay yeah

42:33.240 --> 42:37.960
maybe this is not for me I think you can solve this very simply we we don't need to do it in this

42:37.960 --> 42:43.480
way so let's get let's get somebody to help you with the simple way to to to kind of do that

42:44.440 --> 42:50.440
with other things like I've been with with natural language processing it's been interesting

42:50.440 --> 42:56.520
because you have a problem like one I hope to really get going is looking at things like

42:56.520 --> 43:02.040
compositional systems for like people who are working together in organizations I'd seen this

43:02.040 --> 43:07.640
from looking at some kind of work as a working government and they chat a lot and you might not

43:07.640 --> 43:11.320
have a way to track what's actually going on in there but now you're thinking oh machine learning

43:11.320 --> 43:15.400
could be useful in there because you can identify the context of what anybody's saying and like

43:15.400 --> 43:21.480
you know at any time and from there be able to a guide in resolving a problem that they're trying

43:21.480 --> 43:28.760
to work together to solve in a way so that brings in kind of a lot of layers of of things so I

43:28.760 --> 43:32.680
enjoy that I guess the problem kind of solving maybe it's part of my engineering background

43:33.560 --> 43:37.080
saying okay fine there's this problem that's out there how you break it down and how do you

43:37.080 --> 43:41.320
then take out the chunks that you'll do some science on and then some other parts are practical

43:41.320 --> 43:45.240
who do you have as a as a as a as a collaborated and who will take care of the practical parts and

43:45.240 --> 43:49.800
then I'll go look at some of the machine learning with a couple of of the students I work with or

43:49.800 --> 43:58.120
the other collaborators that I work with and and we work on that the other one is yeah maybe

43:58.120 --> 44:06.600
that also drives me is seeing people are trying things out there I'm yeah I'm organizing a workshop

44:06.600 --> 44:12.120
at International Data Week which is on the first from the 4th to the 8th of November and we have

44:12.120 --> 44:17.320
a session there on data for good and again going to see people and I know you're going to see

44:17.320 --> 44:23.480
people like an education trying to use data science and educate in education settings and seeing

44:23.480 --> 44:27.480
the problems that they're kind of having and all the time it's like you know that thing of like

44:27.480 --> 44:34.680
quantifying some behavior and then trying to use that to either predict or diagnose and because

44:34.680 --> 44:39.560
you're seeing all these people it means that there's also the decision makers behind them so these

44:39.560 --> 44:45.000
decision makers are trying to go like okay we know we've kind of gotten this data that we've

44:45.000 --> 44:49.800
either been collecting ourselves like given like example the municipality using electricity data

44:49.800 --> 44:57.000
but we really need to use it to improve the services that we provide for citizens and it's

44:57.000 --> 45:01.560
yeah it's rewarding in that way that if you come up with something and it's like you know it really

45:01.560 --> 45:06.680
gives some insight that people didn't know before that it could actually then make impact you

45:06.680 --> 45:11.880
know right there in your community that's great well because he thanks so much for taking the time

45:11.880 --> 45:18.360
to chat with us I enjoyed learning about the the various projects that you're working on

45:18.360 --> 45:26.280
yep thank you for having me and yeah I guess we look forward to again having people next year

45:26.280 --> 45:33.160
next year's in Dava there's obviously a couple of workshops that are coming up in different spaces

45:33.160 --> 45:39.240
or conferences that I might be at or some of my other collaborators on so yeah I'm on to it

45:39.240 --> 45:47.000
so you can find me are you at nips this year I will be speaking at black and AI okay yeah so I will

45:47.000 --> 45:56.360
be in Canada so it's just yeah making sure I can get there but yeah yeah I will be there like what

45:56.360 --> 46:02.040
are the things now again being back in in the south that low south is I haven't had to experience

46:02.040 --> 46:11.160
the winters and then so it's like oh damn you're going to be in Canada in December yeah yeah yeah so

46:11.160 --> 46:16.840
so yeah I need like you know spend some time in New Jersey so the winters were nice and ones the

46:16.840 --> 46:21.560
nice because the snow is beautiful but at the same time they really were depressing so being

46:21.560 --> 46:26.600
back in south it's been very nice because yeah they're like oh it's winter you're like no it's not

46:29.800 --> 46:35.160
nice nice well I'm looking forward to to meet you in Canada then okay thank you

46:35.160 --> 46:44.280
awesome take care all right everyone that's our show for today for more information on buccosi

46:44.280 --> 46:52.680
or any of the topics covered in this show visit twimmel ai.com slash talk slash 193 thanks again

46:52.680 --> 46:58.280
to google for their sponsorship of this series be sure to check out the 2019 AI residency program

46:58.280 --> 47:06.440
at g.co slash AI residency as always thanks so much for listening and catch you next time

