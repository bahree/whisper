WEBVTT

00:00.000 --> 00:04.960
All right, everyone. Welcome to another episode of the Twimble AI podcast. I am your host,

00:04.960 --> 00:10.400
Sam Charrington. And today, I'm joined by Heather Nollis, a principal machine learning engineer

00:10.400 --> 00:15.760
at T-Mobile. Before we get going, be sure to take a moment to hit that subscribe button wherever

00:15.760 --> 00:21.040
you're listening to today's show. Heather, welcome to the podcast. Thanks for having me, Sam. I'm

00:21.040 --> 00:25.360
excited to be here. I'm excited to chat with you. It's going to be a fun conversation

00:25.360 --> 00:31.200
about your journey with machine learning at T-Mobile. But before we jump into that,

00:31.200 --> 00:35.600
I'd love to have you share a little bit about your journey in machine learning more broadly.

00:35.600 --> 00:42.800
How do you get into the field? So my undergraduate degree is actually a neuroscience. And when I was

00:42.800 --> 00:50.160
studying neuroscience, I had this study where I had to keep rats alive for a year and measure

00:50.160 --> 00:55.360
their blood pressure. And at the end of my study, I had this notebook full of data where I very

00:55.360 --> 01:00.160
diligently had written every single thing about all of these rats. And I was so excited about

01:00.160 --> 01:04.560
my results. And I gave them to the PI of my lab. And I was like, here we go. And she was like,

01:04.560 --> 01:09.040
great, now you can pack this past this off to our analytics team who will analyze your results.

01:09.040 --> 01:14.880
And being like a micro-managing person who likes to know everything, I almost blew a gasket.

01:14.880 --> 01:20.800
They're like, what? My data. I'm perfectly qualified. And she's like, are you? And I was like,

01:20.800 --> 01:27.120
I will become qualified. Watch. And so I went, I took my first Python courses. I took some

01:27.120 --> 01:32.080
bioinformatics courses. And at that point, I was like, what I really want to do. Well, I kind of

01:32.080 --> 01:36.960
fell in love with computer science at that moment. And imagined I would end up with a PhD

01:36.960 --> 01:43.440
at molecular neuropharmacology doing big data that way. So I went to get a master's in computer

01:43.440 --> 01:48.240
science. And while I was getting that master's, I started working at team mobile. And while I was

01:48.240 --> 01:53.760
there, the team that I was on said, Oh, we're thinking about doing some AI proof of concepts.

01:53.760 --> 01:58.000
And my hand just got straight up in the air. It was like big data. It's the whole reason I started

01:58.000 --> 02:03.520
programming. It's like all of my side projects are in LP. Like, please pick me. And so that's kind

02:03.520 --> 02:07.920
of the story of how I got into doing this professionally. Awesome. I think we're going to have to call

02:07.920 --> 02:13.520
this episode machine learning comma cooler than rats. It is. It is though. Yeah.

02:16.560 --> 02:22.960
And so I guess we can start from the beginning then. You were there. Was that was this proof of

02:22.960 --> 02:30.320
concept the beginning of all ML at all of team mobile or in your particular quarter of team

02:30.320 --> 02:35.440
mobile? Yeah. So what had been happening is I think the same thing that many large companies had

02:35.440 --> 02:40.320
where you had huge data warehouses, lots of analytics, people doing decision science to put

02:40.320 --> 02:45.520
numbers into power points to help executives make really smart decisions. But we didn't have

02:45.520 --> 02:50.320
any real time models. And we weren't doing anything that I thought was super cutting edge. So at

02:50.320 --> 02:55.120
this is five years ago, so at the time, it was deep learning at all. And so my team's goal in

02:55.120 --> 03:00.720
this proof of concept was to put team models first real time deep learning model into production.

03:00.720 --> 03:06.000
And that's kind of where we've we've staked our home. It's like we do things real time. We focus

03:06.000 --> 03:12.560
on on more cutting edge style solutions. And we don't do a lot of that like batch analytics. We

03:12.560 --> 03:18.720
are the real time AI team got it. And how big was the team at the beginning? So the initial proof

03:18.720 --> 03:23.600
of concept, there was me and one other engineer and we were like, we need a we need a very strong

03:23.600 --> 03:27.760
data leader in the mix. So we we brought in my wife Jacqueline Nolis who has been on your podcast

03:27.760 --> 03:32.880
before. And so she helped us with that original proof of concept. And so it was the three of us

03:32.880 --> 03:40.240
that took that first API into production. And then wow. So how that happens kind of a cool story,

03:40.240 --> 03:46.400
if I can digress. How we even got to do this proof of concept was that team mobile has like an

03:46.400 --> 03:52.160
internal shark tank innovation round. So we pitched all these ideas and then they gave us $100,000

03:52.160 --> 03:59.360
in three months to pull something off. Okay. And so that's when we developed our first our first

03:59.360 --> 04:04.160
NLP deep learning model. We got it released into production. And then at the end of the innovation

04:04.160 --> 04:08.480
round, you pitched to executives trying to get them to buy your product forever. And we were

04:08.480 --> 04:12.960
bought. So after that, the we said, okay, now we have to build a full scale product around this

04:12.960 --> 04:18.240
and and get it in front of our front line to actually be used in contact centers and scale it.

04:18.240 --> 04:24.400
And so maybe we're going further down the the rat hole coming back to rats again. But like,

04:24.400 --> 04:30.400
how was that $100,000 spent? Was that like salaries or were there other hard costs associated with

04:30.400 --> 04:36.880
this POC? It was mostly salaries. Some of it was also training because we had the question of should

04:36.880 --> 04:43.120
we be building the stuff ourselves? Of course, I think that like, but we wanted to make sure that

04:43.120 --> 04:47.760
we weren't doing to mobile a disservice by not considering a lot of these like big vendors that

04:47.760 --> 04:52.960
claim to offer intent modeling as well. So some of it was in in trials with those sorts of things

04:52.960 --> 05:00.080
and then a lot of the rest was just staffing and research. And so talk about the this thing that

05:00.080 --> 05:06.720
you pitched the the the products. What what what was it seeking to solve? What was the use case?

05:06.720 --> 05:13.040
So so the team that I was on was focused on building all of the software plumbing that connects

05:13.040 --> 05:18.800
the experts in contact centers, solving team mobile problems to the customers that are trying to

05:18.800 --> 05:25.120
talk to us via digital means. So this is mostly Facebook, Twitter, our app, however, they're typing

05:25.120 --> 05:30.480
to us. We built the plumbing for all of that. And so when it came time to say, well, team mobile wants

05:30.480 --> 05:35.760
to do some AI stuff. What should we do? Of course, I say we are sitting on top of tons of conversation

05:35.760 --> 05:40.640
transcripts. We have all of this data of our customers telling us exactly what their problem is.

05:40.640 --> 05:48.400
And so our very first like just proof that we could even build a deep learning model was just a

05:48.400 --> 05:53.600
simple intent model. So we had 88 different intents that we identified or topics really throughout

05:53.600 --> 05:57.920
team mobile that people are really calling in about. And so it was developing and deploying that

05:58.480 --> 06:04.560
first model. And the product that we stood up around it was one messaging expert who's responding

06:04.560 --> 06:11.120
to Twitter, Facebook, app messages, web messages might have 10 different windows open at one time

06:11.120 --> 06:17.360
because these chats are asynchronous. And context switching is really difficult. So actually showing

06:17.360 --> 06:21.920
the topic of the conversation in whatever quick facts we can pull up about this person's account

06:21.920 --> 06:26.960
related to that topic is super, super useful because then they don't have to prep themselves.

06:26.960 --> 06:31.040
As soon as a customer comes in, we've already got their first message. We've calculated what

06:31.040 --> 06:35.600
their intent is. They're coming in. They're looking to talk about upgrading their phone. We've

06:35.600 --> 06:38.640
actually went out, pulled the data to say what phone they have now. And then we've

06:39.200 --> 06:43.600
surfaced links that say in case you don't know how to upgrade someone's phone. Here's actually how

06:43.600 --> 06:48.640
you do it. And so that's our first product that we came out with. And we called it expert assist.

06:48.640 --> 06:54.400
But now blank assist is industry standard terminology. But I will confidently say we coined that one.

06:54.400 --> 07:06.400
And so what were your you had a bunch of data? Was your data already I presume it wasn't already

07:06.400 --> 07:13.440
labeled for something or? No, what was it? Yeah, I'm so glad you asked about that because when we

07:13.440 --> 07:18.560
talk about where did that first $100,000 go so much of it went to the most expensive labeling

07:18.560 --> 07:24.160
job of all time. T-Mobile's very into customer privacy. So no way were they going to let us have

07:24.160 --> 07:28.080
an external vendor label our data. And at the time, they were like, we don't even want you to

07:28.080 --> 07:32.160
bring on anyone new because they might not have the business knowledge to accurately label data.

07:32.160 --> 07:38.960
So we paid data scientists to label our first 20,000 conversations manually, which yeah, most

07:38.960 --> 07:44.480
expensive labeling of all time. We now have an internal labeling team of five data annotators.

07:44.480 --> 07:51.120
So much different story now. And so what were some of your first steps in kind of building this out?

07:51.120 --> 07:55.920
The first thing that we said is we wanted to try unsupervised learning, right? We didn't want to

07:55.920 --> 08:00.720
have to take a supervised deep learning approach if we could do something with unsupervised learning.

08:00.720 --> 08:05.840
But using LDA and almost any unsupervised approach that we could, it really came up with that.

08:05.840 --> 08:11.440
There are two major types of conversations that happen in T-Mobile. About 80% of them are about

08:11.440 --> 08:19.360
the topic T-Mobile and about 20% are about the topic phones. So that's where we said, okay,

08:19.360 --> 08:23.840
I don't know about this. And I actually, I found a status. Even if you set your number of classes

08:23.840 --> 08:28.640
to be much bigger than that, like they still, it's just different ways to say phone and different

08:28.640 --> 08:33.440
ways to say T-Mobile. Yes, or different types of phone. And that's not necessarily business actionable,

08:33.440 --> 08:38.160
right? Like we weren't seeing any business actionable classes shake out. And I talked to another

08:38.160 --> 08:44.080
team who has managed to do this sort of modeling in an unsupervised way. But it involved like a

08:44.080 --> 08:48.720
Rube Goldberg machine of data pipelines to get somewhere. And so we said, we don't have time to

08:48.720 --> 08:52.800
think about that. Let's at this point, let's label 20,000 conversations and see what we can do.

08:52.800 --> 08:57.200
And you are ultimately hoping for your intent to these topics to pop out of this

08:58.000 --> 09:04.720
unstructured, unsupervised process. Yeah. And the thing that was really important is because we

09:04.720 --> 09:09.920
wanted to do real-time stuff, topics of like phone T-Mobile, even the type of phone someone's

09:09.920 --> 09:15.440
talking about, not useful real-time to an expert, because you have a human being sitting there

09:15.440 --> 09:20.080
also listening to the conversation. Like they very well know that it's still about iPhone.

09:20.080 --> 09:25.600
You know, so any of the classes that we create, we want to make sure there's actually business

09:25.600 --> 09:30.720
actions we can take there. And so the unsupervised thing didn't pan out. And so what'd you move to?

09:30.720 --> 09:35.520
So after that, that's when we decided to do supervised learning. But then we came to the problem

09:35.520 --> 09:41.760
that everybody has, which is what is our taxonomy going to be. Like every legacy company, we had

09:41.760 --> 09:47.920
taxonomies that existed. I believe that each taxonomy should be created for the specific problem

09:47.920 --> 09:54.240
that it's looking to solve instead of shoe horning as many as many meanings as you can to classes

09:54.240 --> 10:00.960
that are already created. And so we had to spend a lot of time advocating against some taxonomies

10:00.960 --> 10:07.760
used for post-call analytics. So I had to prove that the topics that we need real-time

10:07.760 --> 10:14.080
are not the same things that are useful after the call to say what people are generally talking

10:14.080 --> 10:20.400
about. And that took a very long time and was very difficult. So proving that we needed to actually

10:20.400 --> 10:25.680
develop our own taxonomy for this problem, very difficult. Because from a business perspective,

10:25.680 --> 10:29.760
it's introducing confusion. We have one dashboard. We know what all these things mean. Please don't

10:29.760 --> 10:36.160
let us make us learn another one. But after we won that argument, we asked our product and business

10:36.160 --> 10:40.960
people to go basically lock themselves in a room and come out with some sort of hierarchical

10:40.960 --> 10:46.480
taxonomy for us. And then we refined that taxonomy during our labeling process. So since we had

10:46.480 --> 10:51.600
data scientists having the label stuff, we were able to point out when classes were going to be

10:51.600 --> 10:56.960
easily confused based on the language being used or whenever they called out a class that was like

10:56.960 --> 11:03.280
nobody ever talks about that. So an example is they had five high-level categories for what

11:03.280 --> 11:08.320
different topics would be about in T-Mobile. And one of the categories was network. And

11:09.200 --> 11:13.280
customers don't have a lot of nuanced language to speak about the network. They really just say,

11:13.280 --> 11:18.320
hey, I have a question about my network or my signal. So they had spent time creating like 16

11:18.320 --> 11:22.480
subclasses of network conversations for us to have to come back and say you wasted your time.

11:22.480 --> 11:26.640
People really only, our customers only vaguely speak about network because they're not engineers.

11:28.880 --> 11:35.760
So going back to this idea of building the case for your own taxonomy,

11:36.400 --> 11:41.040
in retrospect, was there a silver bullet? How did you win that argument?

11:41.040 --> 11:44.400
Well, for someone else who's maybe embroiled in that now, like what?

11:44.400 --> 11:49.440
Yeah, well, the first thing I will say is if you're going to have this argument one time,

11:49.440 --> 11:53.840
you're probably going to have to have it a hundred times. So for me, like, I won this argument once,

11:53.840 --> 12:01.520
and then I've had to win it every time since. And what I keep going back to is I think that

12:02.160 --> 12:07.360
business users often forget that modeling is kind of the easy part of data science.

12:07.360 --> 12:11.680
So when we talk about creating new models, new taxonomies, they get very nervous. But for me,

12:11.680 --> 12:16.960
what takes a long time on our project is figuring out the business case. Can we actually bring value

12:16.960 --> 12:21.760
if I build this model? I can build shiny models for forever that sound really cool that aren't

12:21.760 --> 12:27.040
making anyone money. And so that's what takes a long time. So one of the things that's really

12:27.040 --> 12:32.160
helped me is being able to document that and saying, you're scared of us changing the taxonomy

12:32.160 --> 12:36.240
because you're afraid it will take time. That's not the bulk of the time. So you don't need to be

12:36.240 --> 12:42.400
scared about that. And then the second thing is just trying to drive home a culture of small models

12:42.400 --> 12:48.640
for small problems, build things specific for your use case to answer it exactly. Otherwise,

12:48.640 --> 12:54.720
you will get a deteriorated product. And so there's that. We also took all of the enterprise tax

12:54.720 --> 13:00.080
onomies and lined them up against each other. And I was able to show places where I needed

13:00.720 --> 13:03.920
a piece of information that the old taxonomies did not have inside of it.

13:03.920 --> 13:11.680
So a good example there might be, sometimes when people can't pay their bill, they set up a

13:11.680 --> 13:15.360
payment arrangement. And sometimes they can't pay their payment arrangement. And for me,

13:15.360 --> 13:21.680
that can't pay payment arrangement is very important. And I had that as a separate class. And in

13:21.680 --> 13:26.720
the other thing, it was all just billing. And it's like, I actually, like, billing might be useful

13:26.720 --> 13:31.120
for a PowerPoint when you need to know how much time call center experts are spending on billing,

13:31.120 --> 13:35.280
but it's not useful for helping an expert solve a call about billing while it's happening.

13:35.280 --> 13:41.280
And that kind of, like, light bulb moment. But I've had to, every time we go to build a new model,

13:41.280 --> 13:45.680
I do have to have this fight again. And so I have like a pre-planned deck that just kind of lines

13:45.680 --> 13:55.040
it all out. Nice. Talk more about this idea of small models versus big Uber models.

13:55.040 --> 14:02.880
Yeah. So our very first model that we released, I mentioned it, it had 88 different classes

14:02.880 --> 14:08.720
and was kind of a disaster. It still exists. It's still running. Like, like, it's still running.

14:08.720 --> 14:15.680
We are doing the giant refactor on it right now. But I learned a lot in doing that. So the first

14:15.680 --> 14:21.760
thing was we were really dedicated to doing a representative sample of the data. So we did not

14:21.760 --> 14:26.560
subsample anything. It was like a truly representative sample of conversations we labeled.

14:26.560 --> 14:32.320
And so we labeled this, but it turns out that many business actionable things are small and rare.

14:33.040 --> 14:39.200
So great that I picked the 88 most frequent topics, but they actually need when somebody is

14:39.200 --> 14:45.520
requesting a password update. And that's nowhere in my 88 topics. And so that's when we started saying,

14:45.520 --> 14:50.240
well, if we need password questions, let's build specific models and then talk about how we can

14:50.240 --> 14:57.040
write route to those specific submodels, if necessary. But just because it's kind of difficult,

14:57.040 --> 15:01.200
I'll give you an example of my favorite small model that we have that the natural language model.

15:02.640 --> 15:06.880
And I like it because it's an example of a time that we removed a chatbot from people by being

15:06.880 --> 15:12.800
smart. So when you messaged us, we used to have, well, thank you for those of us who didn't want to

15:12.800 --> 15:18.560
use that chatbot. Right. Yeah. That's why I like it. I built chatbots before. I think that there's

15:18.560 --> 15:24.480
a place for them. But sometimes when you can get away without it, don't. But so it was whenever

15:24.480 --> 15:28.560
you would message us for the first time, like if you were normally someone who called T-Mobile,

15:28.560 --> 15:33.600
but this time you're texting us, we would send you a picker that said, are you a customer select,

15:33.600 --> 15:39.520
yes or no? And the reason why we had to do that is some, some, you would think T-Mobile knows your

15:39.520 --> 15:43.360
phone number. You should know if we're a customer or not. But we actually don't in many situations,

15:43.360 --> 15:49.760
depending on which app you're coming to us from. And what we quickly realized is like asking people,

15:49.760 --> 15:53.840
yes or no, there is very silly because we can really tell from their first message whether

15:53.840 --> 15:57.680
they're a customer or not. If they messaged us, they say, I need help with my bill. Nobody

15:57.680 --> 16:02.160
is just not a customer needs help with their bill. But if they say, I want to switch to T-Mobile,

16:02.160 --> 16:07.760
nobody who is a customer says that. And so we were able to just take the first messages and the

16:07.760 --> 16:12.880
picker responses that were already selected and build a really quick, like, shallow neural network

16:12.880 --> 16:17.360
between the two and eliminate that picker for 80% of customers to chat with us.

16:18.560 --> 16:23.920
Going back to the previous example, you had this 88-class model and you're kind of

16:24.720 --> 16:29.200
in the process of refactoring it out to smaller models kind of along this idea.

16:30.720 --> 16:35.920
What do you hope to replace it with? You would think the router is still a class, an 88-class

16:35.920 --> 16:41.920
classifier. If it's a learn router, are you looking at heuristic approaches as opposed to

16:41.920 --> 16:47.680
the learn approaches? For us, one of the major things was that when we created this

16:47.680 --> 16:51.760
out of this representative sample of data, we aren't able to get those classes that

16:51.760 --> 16:55.920
business users are asking us for. So if they're asking us for something that occurs 0.001

16:55.920 --> 16:59.840
percent of the time, and we keep pulling this representative sample of data, we will have to

16:59.840 --> 17:04.720
label millions of conversations before we have enough to get the enough data to even get what

17:04.720 --> 17:10.720
they want to show up. So one of the major things in our refactor that we're focused on is reducing

17:10.720 --> 17:16.080
the number of pieces of label data. We need to create these new intensor topics.

17:16.080 --> 17:22.240
And so we are using, we still have the same, well, we've done some taxonomy refactoring since then,

17:22.240 --> 17:27.760
but we are shifting from our own in-house neural network to using distilbert from hugging phase

17:27.760 --> 17:32.640
as a baseline and then retraining on that. And then we're able to reduce the number

17:33.440 --> 17:39.040
of label data pieces we need per class dramatically before it would be 5 to 10,000. And now we're

17:39.040 --> 17:45.040
at 1,000, which makes us be faster for our business. So that's our major thing that we're focused on.

17:45.760 --> 17:53.760
The other thing that's kind of changed since we released is we originally released our models

17:53.760 --> 18:03.600
in R. So it's just R in a Docker container as an API. And they ran pretty okay. Like we were doing

18:03.600 --> 18:09.920
two million returns a day, but we are this kind of is where we switched to voice. So we were

18:09.920 --> 18:16.400
building this all in messaging. We had to have 20 containers of our model, but it was serving two

18:16.400 --> 18:21.360
million responses a day. And the team of all the business, they came to us and they said,

18:21.360 --> 18:25.440
it's really cute what you're doing here for all of the customers contacting us in messaging,

18:25.440 --> 18:32.000
but 90% of care traffic is in voice. So we say, okay. So we want you to build this where it will work

18:32.000 --> 18:40.560
for people who call in as well. Say, okay. Well, we can't have over 200 pods running of our topic

18:40.560 --> 18:44.960
model when this goes through production. What do you mean just sprinkle some Kubernetes on there?

18:44.960 --> 18:51.520
Like it's the most expensive of all time. Well, and the thing is is that messaging conversations

18:51.520 --> 18:55.600
tend to be pretty succinct. If you're chatting with somebody, you're direct on a voice conversation.

18:55.600 --> 19:00.800
You're going to talk about the weather and your kids. And so even 200 is not a good example,

19:00.800 --> 19:05.520
because it almost just depends on how chatty people are. And so that's when we said, okay,

19:05.520 --> 19:10.480
we need to do something smarter with how we're serving these models. And what we ended up doing is

19:10.480 --> 19:17.840
they are now deployed as Java Spring Boot services that run Python as a sidecar. And they are,

19:17.840 --> 19:23.600
they have both API endpoints, but then they're also Kafka consumer producers. So we use Kafka

19:23.600 --> 19:28.080
streaming architecture because we have so many predictions that we're making at this point.

19:28.080 --> 19:33.040
Was Java is Java just an engineering standard there that folks were comfortable with running in

19:33.040 --> 19:40.560
broad or yes, like we have people who like Java, but we did try in Python first because like we're

19:40.560 --> 19:45.440
like our data scientists know Python. Let's do this in Python. At the time when we were doing it,

19:45.440 --> 19:53.360
the Python streaming libraries for Kafka were not mature enough to do the joins that we need to do

19:53.360 --> 20:00.640
to get all of our data to be like filtered correctly. And so we ended up switching to Java because

20:00.640 --> 20:04.640
of that, but it's something that we do look at every once in a while to see how mature those

20:04.640 --> 20:09.440
Kafka streaming libraries for Python have become. Because once they can do very great streaming

20:09.440 --> 20:14.320
joins, then we would love to get Java out of our stack. I don't feel the need to keep languages

20:14.320 --> 20:19.040
around just because they're they look good enterprise wide, but yeah, there's a whole other

20:19.040 --> 20:25.040
rat hole maybe around streaming joins. Where where the complexity come in there?

20:25.040 --> 20:31.440
Well, at the time we were trying to build a dashboard for the business operations center that helped

20:31.440 --> 20:38.560
them with staffing. So I'll I'll kind of set it up where we have all sorts of bells and whistles

20:38.560 --> 20:43.520
on networks that tell you whatever those towers are going down, but no matter how fast we make

20:43.520 --> 20:47.360
those, we will never be faster than our customers who are going to tell us the second there is

20:47.360 --> 20:51.760
any problem. And when cell phone towers go down, people fled to messaging.

20:51.760 --> 20:56.080
You want to do like some kind of event correlation across all these things to try to figure out what

20:56.080 --> 21:02.000
is the actual thing happening? Even that or even being able to tell the operations center before

21:02.000 --> 21:06.480
the network engineering team has figured out what is going on, right? So network engineering team,

21:06.480 --> 21:11.200
they might get a blip. There's an issue. They're still investigating, but we can read in customers

21:11.200 --> 21:16.080
words. And we we know where that customer usually is using their phone because they have a primary

21:16.080 --> 21:22.240
place of use address. And so we can make some assumptions there. They also wanted us to look at

21:22.240 --> 21:28.720
the topics that people were coming in on and say, are there any anomalies? Because we had like if

21:28.720 --> 21:33.280
there's a billing systems issue, it could take a while for us to figure that out, but our customers

21:33.280 --> 21:37.920
might be telling us bright this second. And if we just look at the at how often customers are

21:37.920 --> 21:42.640
coming in with billing issues, maybe we can predict some of those downstream issues. We are also

21:42.640 --> 21:46.720
looking at it for staffing. So if we can predict how many conversations we're going to get in what

21:46.720 --> 21:51.440
sort of topics we're going to have, how do we make sure that our contact centers are staffed

21:51.440 --> 21:56.480
appropriately? And it was in doing that. They had a bunch of different filtering. They wanted

21:56.480 --> 22:00.720
to do on that dashboard, like click a state and then see all the topics. They also wanted to do

22:00.720 --> 22:05.840
trending topics for those states. So unsupervised utterances we were pulling out of there. And it was

22:05.840 --> 22:12.960
in all of that clicking that like the Python was not performing well on the joins to do that type

22:12.960 --> 22:20.800
of filtering. Even taking a step back, going from text to speech, it sounds like yeah, there's a

22:20.800 --> 22:28.640
ton of complexity that I'm imagining is introduced and going from going from one to the other.

22:28.640 --> 22:32.960
Can you talk a little bit about how you dealt with that? Yeah, so I'll tell a personal story first

22:32.960 --> 22:38.240
because I think it's really fun. I had worked in NLP but only on text and we had one other

22:38.240 --> 22:42.800
machine learning engineer who was our speech specialist. When we finally got green light to

22:42.800 --> 22:47.600
start working on speech, she was like, Heather, here's an initial reading. I'm going to be out for

22:47.600 --> 22:53.360
two weeks. You study speech to text and when I come back, we'll have a conversation. And she

22:53.360 --> 22:58.240
she came back and I sat down and I was like, so I've been thinking a lot about tropical

22:58.240 --> 23:04.640
semi-rings because you can use them to optimize a lot of speech to text calculations and she just

23:04.640 --> 23:10.960
looked at me and said, you've gone on the wrong path. She's like, you will never need any of that

23:10.960 --> 23:17.040
math. And I was like, oh, whoops. So that was my first lesson and like everything here is different.

23:17.680 --> 23:23.440
There's a lot that you have to think about, well, first from the technical perspective,

23:23.440 --> 23:30.640
which text, a computer gets text, how does your computer get a phone call? I didn't know the answer.

23:30.640 --> 23:38.000
I do now, but you, like the signals that phones are sending are like, I think RTP and STP

23:38.000 --> 23:43.520
streams and those are not web sockets or anything that a computer can consume. So you actually

23:43.520 --> 23:50.400
have to take those phone streams and route them through something like Zoom that can take

23:50.400 --> 23:56.320
computer calls to make them into phone calls and vice versa, use pieces of that to actually

23:56.320 --> 24:01.840
convert the audio streams into web sockets so that way we can even get the audio to start. And so

24:01.840 --> 24:07.600
at that point, it was kind of mind-blowing. And then in the speech space at all, you have to

24:07.600 --> 24:12.480
start thinking about not only the language that customers are saying to you, but the acoustic

24:12.480 --> 24:16.240
environment that they are in and how that's impacting the transcription. And for us,

24:16.240 --> 24:23.840
most speech detect modeling that's done is for, well, it's either done by, it's done on data

24:23.840 --> 24:30.080
that is men reading audiobooks slowly, how it's trained, and then it's normally trained for

24:30.080 --> 24:36.480
people speaking slowly in their acoustically nice living room. But that's not our customers,

24:36.480 --> 24:40.960
like our customers are in line at Starbucks and they are trying to do this on their lunch break,

24:40.960 --> 24:45.920
like they are yelling and their dogs are barking in the background. And so figuring all of that

24:45.920 --> 24:50.960
out and learning about that and about the way that different accents work and how we can try and

24:50.960 --> 24:57.600
make this technology we're building work equitably for all of our customers has been like,

24:57.600 --> 25:01.200
there's nothing like it in the text world whatsoever. You don't have the features.

25:01.760 --> 25:08.720
You started talking about the the compute environment pods and all that stuff.

25:08.720 --> 25:16.320
How are you running out? Is this the GPU heavy workload? Where is it running?

25:16.320 --> 25:23.280
Yeah. So our transcription stuff is incredibly GPU heavy. Our topic modeling

25:23.920 --> 25:29.360
less so, but the transcription is. And so we started out with a like an on-prem

25:30.240 --> 25:37.600
provider specific for GPU hardware because at the time we were getting in like ridiculously

25:37.600 --> 25:41.200
good latency because that that's one thing that's really important is a lot of time speech

25:41.200 --> 25:46.320
detects. It doesn't matter if it's slow because you might be transcribing stuff for post calling

25:46.320 --> 25:52.560
analytics, but for us, if we're trying to build experiences that pop up to help an expert solve a

25:52.560 --> 25:58.000
problem, we have to be faster than the human being hearing this sentence. So if someone's like I

25:58.000 --> 26:03.040
need to set up, I would love to pay my bill and I say great, I'm here to help you pay your bill.

26:03.040 --> 26:08.720
Let me dig around and then I click the app, I start to pay their bill and then a pop up comes up

26:08.720 --> 26:12.800
and says, would you like to pay their bill because our transcription is slow? I've created.

26:12.800 --> 26:19.760
That sounds like clippy. Yeah, exactly. And so so latency is like super important to us to build

26:19.760 --> 26:26.560
trust. And so we originally had an on-prem provider because we were getting good latency and we took

26:26.560 --> 26:32.800
it to AWS and we were like, hey, like can what can you guys do here at the time their latency

26:32.800 --> 26:37.440
was not very good. But since then we actually have been able to switch to a cloud provider. So

26:37.440 --> 26:45.600
we do use AWS to do this. But we have our own internal hosted Kubernetes that is then hosted on AWS

26:45.600 --> 26:51.280
if that makes up. Okay. But we do. It is a GPU heavy workload. So we do have them running on GPU

26:51.280 --> 26:56.640
instances for our topic models. Right now we're in the process of converting those to AWS

26:56.640 --> 27:02.960
inferringia chips, which we're still we're still waiting to see what the actual improvement will be from using

27:02.960 --> 27:12.480
the inferringia chips. This may be going back a bit, but you you mentioned that with the current version

27:13.120 --> 27:21.840
of this, I think as part of the the text to speech-based system transition, you went from

27:21.840 --> 27:28.640
something to distilbert like pre-trained distilbert and fine-tuning that. What was the the thing before?

27:29.200 --> 27:36.400
It was a hand a handcrafted network using Keras that was a like a shallow convolutional neural network.

27:37.040 --> 27:45.840
Okay. So very bespoke. Right. Exactly. And so it takes a lot to say we we're we're not going to do

27:45.840 --> 27:50.320
that anymore. But we still do like bespoke neural networks for other problems, but for our giant

27:50.320 --> 27:57.120
topic model distilbert's good. We in our first our first experiment with distilbert, we just like

27:57.120 --> 28:01.920
pulled it off the shelf and took our already labeled data and trained against it. And after one

28:01.920 --> 28:05.520
epic, we saw very good results. So we're like, okay, this is probably the direction that we're going.

28:05.520 --> 28:13.520
You can get this in just one epic. And have you had to do anything special to to get it to deal

28:13.520 --> 28:20.000
with the number of classes that you're working with? Not so far, but as I kind of mentioned, we're

28:20.000 --> 28:24.800
in the process of maybe breaking apart the models into a bunch of different submodels and having

28:24.800 --> 28:31.040
having a better router at the top. So we might end up doing that. We have zero interest in introducing

28:31.040 --> 28:36.800
new classes into this model because it's it's so old and giant. We one of our data scientists

28:36.800 --> 28:41.360
calls it the Toyota Corolla models. Like it just it's it's reliable. It does what it does, but no

28:41.360 --> 28:48.400
and super impressed by it. So we want to kind of let it continue do what it's doing. But any of

28:48.400 --> 28:53.040
the new type of topic modeling that we're looking to do, we are we are building other models to do

28:53.040 --> 28:59.200
it. We will never have an 88 class model again because maintaining it is awful. And I don't know if

28:59.200 --> 29:05.520
you answered the question about what what you're anticipating to use for that router. Oh yeah,

29:05.520 --> 29:11.600
so we don't know yet. It really depends on the type. Well, it depends on the type of experiences

29:11.600 --> 29:20.240
that that are our care stakeholders want. So I think a writ like for the first go that we have,

29:20.240 --> 29:26.080
we have two different experiences that we are rolling out. One is about network and one is

29:26.080 --> 29:31.040
about customers who are dissatisfied. And we think it's just going to be a logistic regression.

29:31.040 --> 29:35.280
Right? Like just which one do they go to dissatisfied or network or otherwise maybe

29:36.080 --> 29:41.040
which we can get in that. But we're not sure how that's going to scale. It really depends

29:41.040 --> 29:47.680
on their roadmap. So we've got to be in tight collaboration. So the idea then is that as opposed to

29:47.680 --> 29:53.040
kind of this flat 88 classes, you're going to have a kind of a hierarchical taxonomy. And you just

29:53.040 --> 29:57.680
have to figure out which of the which of the handful of branches they need to be routed to. And then

29:57.680 --> 30:03.360
you'll do the kind of fine grain classification lower down. Yes. Yeah. So it will be a hierarchical

30:03.360 --> 30:09.360
taxonomy. We will pass it off. And then within each of those general experiences that we're trying

30:09.360 --> 30:14.960
to roll out, we want to have like a proper like state engine where we have intent being recognized

30:14.960 --> 30:19.360
and then we're kind of deciding what to pop out for the for the expert next using an LSTM

30:19.360 --> 30:24.080
of some sort. So that's kind of the future vision that we're building where we're able to like

30:24.080 --> 30:31.040
walk experts through these flows smartly using the NLP that we're doing to check off any checks

30:31.040 --> 30:36.800
or fill in any boxes for them as they go through these workflows. And now there are tons of these

30:36.800 --> 30:45.360
off-the-shelf kind of intent engines and chatbot engines and conversational AI tools. How do you

30:45.360 --> 30:53.200
think about kind of the build versus buy decision? So what I tell my stakeholders always is if there's

30:53.200 --> 30:56.880
something out there that honestly works better than what I would build, I would love to buy it.

30:57.520 --> 31:01.840
But I'm very hesitant to put something that works less well than what we have in front of our

31:01.840 --> 31:08.800
experts. And so I can give a very easy example here which is recently we had a vendor solution

31:08.800 --> 31:16.480
that we were looking at that identified promises and commitments inside of conversations. And

31:17.200 --> 31:21.840
that's very exciting because we always want to know what our experts are promising our customers

31:21.840 --> 31:25.680
but we're committing to and if they call back in later and they say you promised me we want to be

31:25.680 --> 31:31.520
able to say yes we did promise you you're right I'm sorry. But when we dug into it the out of the

31:31.520 --> 31:38.400
box accuracy was like 53% so he said okay let's dig into some more of these and they didn't make any

31:38.400 --> 31:43.600
sense to us they weren't what we would consider promises or commitments from a business perspective

31:43.600 --> 31:48.320
whereas we put one of our data scientists on the task for one week and we can come up with something

31:48.320 --> 31:54.960
with about 80% accuracy because we know what we're looking for and that's the very hard story that

31:54.960 --> 32:02.240
we've been telling our stakeholders over and over again is that yes general language models work

32:02.240 --> 32:07.440
very well for general English but we don't really speak English at T-Mobile like we speak T-Mobile

32:07.440 --> 32:12.240
leagues there are so many words in the English language that will never appear and there are so

32:12.240 --> 32:16.000
many things that we are going to talk about that are completely different so an example I like to

32:16.000 --> 32:20.480
use is the word jump has a literal different meaning at T-Mobile because jump is the name of our

32:20.480 --> 32:26.720
insurance plan so like it's an argument for custom embeddings and so for me I think it's totally

32:26.720 --> 32:32.480
appropriate to take an off the shelf solution to prove a concept out and see if there's any value

32:32.480 --> 32:38.080
but then I always like to ask can you do something cheaper and better and so I can kind of speak

32:38.080 --> 32:42.640
about our speech detects here where we originally did roll out with vendor partners so we did a

32:42.640 --> 32:50.800
huge RFP every major speech detects writer in the world that exists I have reviewed them and we

32:50.800 --> 32:57.120
launched our original proof of concept with AWS transcribe and so we did use a vendor but

32:57.120 --> 33:02.080
immediately once we had the audio data we started looking at open source solutions and saying

33:02.080 --> 33:09.680
what can we do on our specific data and the word error rate on our data that we have right now

33:09.680 --> 33:14.400
is nine state of the arts like seven to five like state of the art for like standard slow

33:14.400 --> 33:20.240
English is seven to five and our word error is nine anytime we test a vendor product against it it

33:20.240 --> 33:29.520
is 18 human like 18 ish and you lose measurable meaning after 20 and so I just kind of all the time

33:29.520 --> 33:35.040
even when vendors say we have we have state of the art speech detects when you run it against our

33:35.040 --> 33:40.560
calls it's not because our acoustic environments are very strange the language that we use is

33:40.560 --> 33:47.120
different we have a lot of strange factors in our business and so just trying to reiterate constantly

33:47.120 --> 33:52.720
like like yes the numbers that you're seeing in the media are great if we were Wikipedia you know

33:52.720 --> 34:02.480
like if this but we're not our conversations are not Wikipedia so you mentioned dealing with

34:02.480 --> 34:08.880
accents for example and you know that representative of being representative of other biases that

34:08.880 --> 34:18.240
you might encounter how do you approach that whole spectrum of factors yeah so so for me when I

34:18.240 --> 34:23.680
think about it if I'm building efficiency tooling for the frontline I'm trying to make them

34:23.680 --> 34:30.080
smarter better at their jobs most contact centers compensate people by how happy the customers are

34:30.080 --> 34:35.200
afterward how quickly they saw calls how quickly they go through them and so then I'm thinking

34:36.080 --> 34:42.640
it is so incredibly important for me personally to build models that serve everyone equally

34:42.640 --> 34:47.440
because if not if I'm building models that help some people that's literally going to increase

34:47.440 --> 34:51.200
their paycheck and if I'm building models that don't help other people that's going to literally

34:51.200 --> 34:55.200
decrease their paycheck and so we talk about that all the time on our team like it is

34:55.200 --> 35:02.560
it is the most important thing to us and so we actually we have a full-time AI ethics specialist

35:02.560 --> 35:07.920
who she's an engineer and she's focused mostly on our voice models and so there's a data set

35:07.920 --> 35:13.680
called the Mozilla Common Voice Data Set which is anybody can go you can speak and transcribe

35:13.680 --> 35:18.800
your audio, tag it with your demographic data so we started with that testing our models against

35:18.800 --> 35:24.640
Mozilla Common Voice Data Set we found it to be pretty insufficient in some striking ways so an

35:24.640 --> 35:31.600
example is they have multiple different Asian accents listed in the data set for Africa they

35:31.600 --> 35:38.960
just have African as if there are yeah as if there aren't multiple African accents and so we

35:38.960 --> 35:45.360
use them originally to to kind of get a benchmark there but what we're working on really now is

35:45.360 --> 35:50.640
building our own team mobile version of that like what is the data set that accurately represents

35:50.640 --> 35:55.200
all of our customers and all of our employees that we can use to measure different word error

35:55.200 --> 36:00.160
rates against and see how we can improve and the one of the reasons why this is super important to

36:00.160 --> 36:05.760
us is our speech to text solution is very hard to scale like by the time we are at full scale we

36:05.760 --> 36:10.560
will be the largest speech to text for contact centers in the world or at least that was true a

36:10.560 --> 36:16.960
year ago I haven't checked both but but so it's very hard to scale and so we are right now live with

36:16.960 --> 36:24.240
7,000 agents but we plan to be live to everybody in the US by the end of 2022 and everybody globally

36:24.240 --> 36:31.040
by the end of 2023 and so for me what's very important is before we roll out to global partners

36:31.040 --> 36:36.560
so anybody who is answering the phone who is from any other country for two mobile I need to make

36:36.560 --> 36:42.640
sure that my models work well for them and so we have a huge focus on those specific areas

36:42.640 --> 36:48.480
in collecting that data to make sure that we will not release models that do not perform within

36:48.480 --> 36:54.480
an acceptable window of standard in this situation and so that's really kind of how we've done it

36:54.480 --> 36:59.600
but there's not there's not a good open source data set that has all the data that we need to

36:59.600 --> 37:04.320
accurately bias test it so we're just having to curate our own. You've been talking about speech

37:04.320 --> 37:11.520
to text speech to text is the transcript an actual product that you need or is the transcript an

37:11.520 --> 37:17.680
input to downstream things and that's kind of a you know the next question is you know do you

37:17.680 --> 37:23.600
think about like some uber you know deep network that goes straight from speech to intense and

37:23.600 --> 37:28.560
skip the whole text thing. I'm glad that you asked that because that was my dream originally

37:28.560 --> 37:32.320
when we said speech to tech I was like and we're going to build a tim modeling directly on audio

37:32.320 --> 37:38.640
signals and that's when my speech scientist was like Heather no okay she's like the computation

37:38.640 --> 37:42.960
for that would be so ridiculous but so what our speech to text mostly does right now is it's

37:42.960 --> 37:48.160
it's pattern it's powering a product we call auto memo after the end of every call our experts

37:48.160 --> 37:52.720
have to spend three to five minutes typing out everything that it was about and we said actually

37:52.720 --> 37:58.880
we think we can summarize some of this. Doing that took a very long time it turns out that

37:59.520 --> 38:04.000
human speech is not very good to even do an extractive summary from so like not only

38:04.000 --> 38:09.520
organization is still hard right well and especially when people speak we're not very succinct

38:09.520 --> 38:14.160
so that took a very long time to figure out what that product will look like and it is a combination

38:14.160 --> 38:19.680
of we add the top three what we call called drivers like the things that we think made them actually

38:19.680 --> 38:25.680
call in to the memo and then we also have it where experts can click and view the entire transcript

38:25.680 --> 38:32.000
if they need to dig in for some reason. I don't love showing the full transcript because I'm

38:32.000 --> 38:36.080
like we're going to make mistakes and people are going to give us feedback and it will be embarrassing

38:36.080 --> 38:40.880
but so far so good the experts seem to really like that and we're we're even toying around with

38:40.880 --> 38:46.640
the concept of if they can see the transcript in real time while they're talking could they flag

38:46.640 --> 38:52.720
things for correction so for us to go in and correct the transcripts later but so but the

38:52.720 --> 38:56.880
ultimate dream is that the speech to text is powering like all of these Jarvis style pop-ups

38:56.880 --> 39:01.040
just automatically drive and do all the silly things for the expert while they can just focus

39:01.040 --> 39:05.840
on having the human conversation the thing my robots will never be good at probably but

39:06.800 --> 39:12.400
at what are you using for summarization that's why I say it's an it's another internal model that

39:12.400 --> 39:17.920
just pulls out these three call drivers but we did over six months on an extractive summary thing

39:19.040 --> 39:22.640
the thing is is that it's very hard to get it to be business actionable it would come up with

39:22.640 --> 39:30.240
stuff like I'd be like I really like my phone plan I want a new phone you know like and that's not

39:30.240 --> 39:35.120
a good summary because a good summary for that is upgrade call but yeah one thing this kind of

39:35.120 --> 39:42.560
interesting is a lot of maybe it's not interesting maybe it's just expected but you know you haven't

39:42.560 --> 39:50.560
mentioned the terms but a lot of what you're experiencing connects to a theme that we've

39:50.560 --> 39:57.440
been exploring on the podcast over the past few weeks a couple months data center AI like you

39:57.440 --> 40:02.240
started with this heavy focus on models but a lot of the things that you ran into require that you

40:02.240 --> 40:09.280
refine the data refine the data and is that a does that term resonate for you or is that something

40:09.280 --> 40:14.640
that you've you've looked at at all yeah yeah I I would say that I know that there's like a

40:14.640 --> 40:21.120
official like data driven AI movement and I would say I think for largely an alignment right like

40:21.120 --> 40:27.760
like don't don't go creating AI for the sake of doing a stunt and and make sure that what you're

40:27.760 --> 40:35.520
doing actually delivers value and so yeah I do think it resonates can you can you talk a little

40:35.520 --> 40:44.160
bit more about the the ML ops aspect of keeping all these models up and running it in production

40:44.160 --> 40:50.320
like what kind of platforms and tooling have you built out to support all this yeah so our team

40:50.320 --> 40:56.240
is like so focused on product development that we honestly have not done our due diligence in

40:56.240 --> 41:02.400
many ways for model maintenance and so right now we have like we do have model audits that will happen

41:02.400 --> 41:11.520
so we have some lamb does that automatically put a percentage of conversations into AWS ground truth

41:11.520 --> 41:16.320
it for our data annotation team to actually check on and then we have some reporting that can

41:16.320 --> 41:22.640
be done around that but for the most part we haven't seen significant enough data drift to

41:22.640 --> 41:28.400
to touch our models except for when a team mobile and sprint merge together because all of a sudden

41:28.400 --> 41:32.160
sprint is no longer a competitor and people are talking about sprint they're talking about us

41:32.160 --> 41:35.760
and so that required a that was significant enough data drift for us to retrain everything

41:37.200 --> 41:41.120
but for the most part we are just like it works until somebody tells us otherwise

41:41.120 --> 41:53.040
which which is not the best strategy and otherwise it sounds like you're fairly invested in AWS's

41:53.040 --> 41:59.680
various offerings for from a tech perspective although you did say you you kind of built your own

41:59.680 --> 42:04.880
world drone Kubernetes cluster that you just happen to be hosting on AWS yeah yeah and so I would

42:04.880 --> 42:11.520
say we are interested in AWS's offerings only in their bare components so we are rarely a consumer

42:11.520 --> 42:17.360
of like a cognitive services service like we our team doesn't really buy those we mostly build

42:17.360 --> 42:23.840
our own models and we have them end up deployed on AWS but though we recently moved to Google and

42:23.840 --> 42:30.000
in my spare time when I'm doing side projects I use GCP for most of my staff and so hopefully we

42:30.000 --> 42:34.240
will have a tight-knur partnership with Google in the future and maybe I'll be talking about TPUs

42:34.240 --> 42:44.720
instead of infrared chips but we'll see and do you have opinions on either of their like data

42:44.720 --> 42:53.760
science workbench you know environments Sage maker vertex so Sage maker I feel like it works

42:53.760 --> 43:00.080
like it's fine I feel like I what I really like about working in GCP is they separate

43:00.080 --> 43:06.080
compute and storage completely all the time and so you always have to really think about your

43:06.080 --> 43:11.760
compute and your storage I also like that it's like a push architecture so you're always waiting

43:11.760 --> 43:18.240
for pushes instead of other things so that's why I like doing software but as far as like the

43:18.240 --> 43:23.120
different platforms for individual development I feel like it's all mostly fine like it's all

43:23.120 --> 43:27.520
it's all kind of apples to apples we end up having to build so many custom components on top of

43:27.520 --> 43:34.240
whatever we're doing it ends up the same we've done trials with Azure Databricks too so like

43:34.240 --> 43:39.280
Databricks through Microsoft Azure and we're like we already have a AWS fill so I guess we'll

43:39.280 --> 43:48.080
just keep doing that one for now but awesome awesome any thoughts on kind of you know future directions

43:48.080 --> 43:57.200
what's next on your roadmap yeah yeah so there's definitely the rolling out speech to everybody

43:57.200 --> 44:02.960
making sure that it works great for all of our customers we also have some interesting stuff

44:02.960 --> 44:08.240
potentially coming up with legal you know on the phone people always redo terms and conditions

44:08.240 --> 44:15.280
and you have to accept when when you are audited to show to the auditors that that happened you have

44:15.280 --> 44:21.360
to like pull conversations and show them like audio recordings the thing why can't we just build a

44:21.360 --> 44:27.200
dashboard that does a cosine similarity between terms and conditions and what was actually said I

44:27.200 --> 44:31.280
guess they read them and then they agreed so that's one of our really quick wins that's coming up

44:31.280 --> 44:36.080
that I'm I'm pretty excited about but for the most part everything that we do is trying to move

44:36.080 --> 44:42.400
to this dream of the autonomous desktop so like I said so our care experts can sit back chat

44:42.400 --> 44:47.440
have the human interaction while we are taking notes for them opening the right apps at the right

44:47.440 --> 44:54.240
time and so what I'm hoping is we are standing up a very robust click tracking infrastructure for

44:54.240 --> 44:59.840
our care desktop and I'm excited to predict clicks right like to open windows at the right time

44:59.840 --> 45:03.920
do things of that nature that's outside of the natural language intent stuff that we've been

45:03.920 --> 45:09.840
focused on we also are doing a bunch of stuff in what we call the virtual retail space lots of

45:09.840 --> 45:15.200
people went to buy phones and don't want to go into a store so we're like how can we use AI to help

45:15.200 --> 45:22.000
sales people sell and that's like helping create positioning statements helping them write fit

45:22.000 --> 45:27.360
accessories to a phone that this particular customer is trying to buy so that that recommendation

45:27.360 --> 45:32.080
space we've also just began to dip our toes into that's very exciting and then measuring the

45:32.080 --> 45:35.840
impact of recommendation systems is a whole separate bag that I'm excited to unpack

45:37.040 --> 45:43.280
nice nice well Heather thanks so much for taking the time to share a bit about what you're up to

45:43.280 --> 45:50.880
very cool very cool anecdotes and and lots of interesting lessons learned in there yeah thank you

45:50.880 --> 46:20.480
it was a nice chat

