Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host, Sam Charrington.
In this the final show of our deep learning endoba series, we speak with Bucosi Maravate,
chair of data science at the University of Pretoria and co-organizer of the endoba.
My conversation with Bucosi fell into two distinct parts.
The first part focused on his PhD research and the area of reinforcement learning.
And we discussed several advanced RL scenarios, including in verse RL, multiple agent RL,
and using reinforcement learning when you have an incomplete knowledge of the environment.
We then moved on to discuss his current research, which broadly falls under the banner of data
science with social impact.
Specifically, we review several of the applications he and his students are currently exploring
in areas such as public safety and energy.
As we close out the series, I'd like to send a final word of thanks to our friends at
Google AI.
If you've got an interest in machine learning research and want to level up your skills
in one of the top ML research groups in the world, you should take a moment to learn
more about the Google AI Residency program, which recently opened up applications for
perspective 2019 residents.
The Google AI Residency is a one-year machine learning research training program with the
goal of helping individuals from all over the world and with a diverse set of educational
and professional backgrounds become successful machine learning researchers.
Find out more about the program at g.co slash AI Residency.
And now on to the show.
Hey everyone, I am on the line with Bucosi Maravate.
Bucosi is the chair of data science at the University of Pretoria and was a co-organizer
of the deep learning in Daba.
Bucosi, welcome to this week in machine learning and AI.
Thanks for having me.
Absolutely.
Why don't we get started by having you tell us a little bit about your background and
how you got interested and involved in data science and machine learning?
Yeah, I guess I have a background in electrical engineering that was my undergrad in Masters
when I was doing my undergraduate in electrical engineering.
I got to a point where I said, yeah, I don't think I'm interested in this power stuff.
But I am interested in artificial intelligence and data.
So I moved to a stream here at the University of the Vett Vater Science in Johannesburg,
which allowed us to work on more data problems and more coding.
And by the time I was doing my fourth year at the University of being a senior, I was
working then on AI, specifically doing some work with neural networks at the time.
And then I stayed on for another year at Vett University, did a Masters looking at
some reinforcement learning work.
I was very interested in kind of like, oh, machines can learn to make decisions and you
only have to give them this kind of reward.
And so after spending that year, doing that, I had applied also for a scholarship, a full
bright scholarship to go to the US and one of the schools I had chosen was Rutgers University
because of kind of then who would then become my future PhD advisor.
I was like, oh, this is one of the people I read about when I was reading about RL.
So it could be interesting to work under him.
I then in between that started working for the CSR in early 2009 and a few months later
I was then off to New Jersey to start Rutgers on the PhD program and then had Michael Littman
as my PhD advisor.
So another thing again, as you're going through the motions of doing a PhD, you look at
the area with some depth, I work on some work in investment reinforcement learning.
I worked a bit on kind of trying to think about having multiple reinforcement learning
learners at all at once, but I think that kept on making me wake up every morning was
like, I'm really interested in making reinforcement learning a little bit more practical.
So how do you do things like evaluation where you don't have access to a simulator or complete
embodiment, so if you think about things like medicine, if you might think about things
like kind of education, these type of areas, you're not really going to experiment with people
with your infrastructure learning algorithm.
So you want to do your evaluation offline and to do that, you need to take care of a couple
of things.
So evaluation here, meaning that you want to see how well your model after it's learned
actually does without having to deploy it.
So you can't say, hey, you're going to learn how to treat cancer.
And then after that, you build a model and you say, okay, now the model's going to be
applied on real patients.
That is going to be problematic in some ways.
There is work in that area to make that actually much more possible.
But that's the thing I was interested in, but like I don't be interested in this again,
hey, I really enjoy working from like a challenge that's out there and then working backwards
into what then models will be useful, what learning algorithms will then be useful to
then develop.
And at that time, I was at 2011, 2012, I started hearing
this thing of like, you know, oh, there's this term called data scientist.
And it's people who will wrangle with data, use kind of a different techniques, not necessarily
just from computing, might be from statistics, might be like, you know, from social science
and then try to kind of tackle these problems.
And that way, then I kept on gravitating towards that, towards that.
So by the end of my PhD, I was like, okay, let me go try and see.
As I'm going back to South Africa to see if I can work in data science.
And that's where, like, you know, arriving the last three years or so, mostly I was
based at the CSR, working with the team of other data scientists for about three years.
And then now I've moved to University of Victoria, then as the chair of data science, still
contain some research with colleagues or prior colleagues at the CSR.
Did the transition to data science or that you're kind of blossoming interest in data science
lead to a change in direction for your PhD research, or did you complete that in reinforcement
learning?
I completed the PhD in reinforcement learning, but the work basically became this kind
of looking at other looking at education.
We were looking at health applications and all like health challenges and then working
to build up tools for evaluation in that area.
You mentioned a few things in the RL area that I haven't heard much about.
The first of those is inverse RL, what's that?
So inverse reinforcement learning is, okay, in the general reinforcement learning framework,
you've got an environment, you've got an agent, which is the machine learner that you're
going to have, that agent can do actions.
So it's allowed to choose some action and then it gets carried through and it might move
around.
So think about like, you know, dumb example, you have a room in a room and it can choose
to move, yeah, like to move around and then it can choose sometimes to vacuum.
And what you do is you say, okay, I'm not going to specify how, what you must do.
And I'll give you a reward for something, right?
So I'll give you a one if you vacuum the dirt or something like that.
And I'll give you a very negative reward if your patchy runs out, all right?
So the rumor then just giving those signals will go around and it will exploit the beginning
or try different actions, it might go in and like, you know, just vacuum in a place that
there's nothing so you won't get a reward.
But then sometimes it will vacuum on somewhere where there is dirt and it's sense I would
have said there's dirt, but it didn't know how to interpret it before.
And after a while, it will learn like, okay, yeah, look around for dirt if there's dirt vacuum
it off.
And then that, you know, if the battery dies, I got a very negative thing.
So keep track of the battery level and things like so over time, you think that you will
inculcate in it, it will learn all these expected kind of behaviors.
So an inverse reinforcement learning is that there is no reward that's specified, right?
So you don't have a reward, which actually is hard to specify sometimes.
But what you do is that you can actually observe somebody do something, right?
So you actually go in and maybe you see other rumbers or you have a human actually have
a remote control to the room and it moves around and it does things.
And then from there, what the goal of the learning algorithm is to do is to actually learn
what the reward function would have been to actually replicate the behavior that it's
seen.
So what this makes me think of is imitation learning.
Is that a name collision or are these related?
Yeah, they are related.
So that's one of the kind of other way, like imitation learning that might be multiple
ways to do it.
But inverse reinforcement learning could be one of the ways that you do imitation learning.
Okay.
Yeah.
But one of the things that is interesting if you do really capture that award in a good
way with a good representation is that you can then transfer it between domains.
It's hard, it's still not trivial, but you can then learn like what's important to who
you've been observing and then you move it to different domains and then try to then
estimate what behavior you would have seen from that person or thing.
Can you give an example of that?
So let's say you've got the room again, it goes into a room, you show at the beginning,
you train the room, but you move around the room, but you learn, okay, there's things
such as the things such as battery state, there's things such as obstacles.
But now you just adjust the room or you move the room into a new room.
And then it, because it's learned the reward, you don't, you no longer, it doesn't need
to imitate anymore.
It can just take the reward that it learned before and then say, oh, I'm in a new room,
but I kind of get the rules.
Mm-hmm.
Got it.
So that's a good, like, you know, you, you kind of can then transfer that reward to something
else.
I love the Roomba example.
I've never heard anyone use that.
Usually we're talking about video games and robots and like, I guess the Roomba is a robot,
but usually we're talking about video games, but the Roomba is a great example for RL,
not that the actual Roomba actually uses RL, but...
Yeah, I like making examples that are kind of very much more closer to people's, like,
regular lives.
Even though, like, most of us, I don't even have a Roomba.
Right.
But it's like, once you say it, people get it.
Like, oh, okay.
Yeah, you know, yeah, yeah, I see it, I see it now.
Yeah.
Roomba's even still a thing.
Do they still...
Yeah, yeah.
They're a lot of them, and I've been trying to figure out how to get one from Xiaomi.
It's not a Roomba, it's some other brand, I mean, another name, yeah, hopefully we don't
get it.
Yeah, but they still are there, and they're getting crazy.
So you also mentioned multiple RL learners, kind of obvious from the context what that refers
to, but I haven't seen much in terms of published research in that area.
What are, kind of, some of the major challenges and results that folks have been seeing with
multiple learners?
Oh, this has been a while working in that space, but you can think about different settings.
So one is that you could have, like, learners that have to co-operate.
So working together to solve a bigger, like, high-level goal.
So, like, you know, you can have a team playing a game, like, you know, here we can talk about
football, which now has changed.
I'm giving back, I'm back in South Africa, so football needs something else, so you could
have multiple, like, you know, they're trying to play soccer, and then, again, you give them
rewards, but then now they have to learn how to cooperate.
That's one way of thinking about it, that's not really what I was trying to do sometime
in my PhD, but one way was, okay, you have these different learners, but they only get different
experiences, right?
So the other time that they spend in the environment, it only gets them to see different parts
of the world.
You know, how do you take this, and then almost try to use their brains to get to something
that is much better?
So it brings you back to, like, ensemble methods, and could ensemble methods actually be something
that works in reinforcement learning?
Okay.
Interesting.
Yes.
Another thing you mentioned it, the first of those examples, I did an interview recently
about the OpenAI Dota OpenAI 5, which is, like, these five different agents that are operating
in this environment, and need to figure out how to cooperate, and they do some interesting,
some interesting kind of emergent behaviors we're seeing there.
Okay.
So you mentioned inverse RL, multiple RL learners, and then evaluation in incomplete environments,
which you kind of alluded to with the multiple learners, where they're kind of learning different
things independently, and then you're fusing what they're learning together.
Was there other work that you did around these incomplete environments?
It's not really incomplete environments, as opposed to you don't have access to them.
So one of the things was, like, we wanted to look at health chronic disease management,
and things like you can do things like marketing, because you've got a lot of that.
So you don't have access to the environment in chronic disease, so you don't have access
to your patients.
But you can have historical diagnostic information, and also follow-up diagnostics.
So in this case, I was looking at HIV, which, finally enough, I had also worked in my undergrad
briefly looking at missing data for HIV, but then now I was actually looking at treatment.
So we're going to simplify it again, so you've got a multiple patients going through treatments
for HIV, and what you want to do to learn from there is a policy that in the future when
you get a new patient, you can take some information from there and be able to personalize a treatment.
But that treatment for HIV is sequential, so it's not simply a one decision is made, and
that's it.
So you're not going to choose a drug cocktail, and it's going to last for the life of the
patient.
So you're going to have multiple times you have to make decisions, so meaning you keep
drug cocktail number one.
It works for a while, and then it might stop working, unfortunately, given how HIV actually
progresses, and then you have to then make a choice of switching to another treatment.
And this could go on for a couple of times.
So we restricted the problem into, I think, only two stages where you say you're going
to get your initial treatment, and if you switch, what should then be the next treatment?
So this becomes a sequential decision-making problem, which, again, is very nice for
reinforcement learning, because that's exactly what you want to learn.
But what you want to do is that because you're not going to have access to the real patients,
to do the evaluation after you've learned from the data, we split the kind of learning
into a process where some learning is used to just learn a model of the environment given
the data that you've seen.
So it's almost like you're building some sort of simulator, but it's going to have noise,
because sometimes you haven't seen a specific drug cocktail used enough for you to really
be sure what kind of effect it's going to have on a patient.
So you have to then bring in uncertainty of saying that, okay, here you might end up
with a viral load between here and here.
So we then built up a model-based reinforcement learning algorithm that estimated, and the
effect that drugs would have on a potential patient, and the information that we captured
from the patient was like the demographics, some information about the disease at the
beginning, and then from there you then run, and you're also learning algorithm that estimates
then, okay, saying, okay, if you were to give a drug cocktail that was drug number, I mean,
drug cocktail number one was this, and drug cocktail number two was this, this is likely
how well you manage the disease over the next X amount of turns.
Yeah, it's interesting, so it's like part of the environment is modeled probabilistically,
and the agent has to figure out what to do with that constraint.
Yes, yes, so because again, it brings up this thing of like you now want to allow people
to do RL without necessarily having access to the real kind of thing, but they've got
enough prior data to do something at least useful, and then you then could then say, okay,
I want to also evaluate how close I am to the real world in some way.
Some of the work of Susan Murphy at University of Michigan, they've done a lot of work in
this area, and she was on my PhD committee.
And so kind of fast-forwarding, you're now focused on data science at University of
Pretoria, and a lot of your interests are centered around this idea of data science with social
impact.
What does that mean for you?
So for me, social impact means like there's, we have a world that has kind of challenges,
and from these challenges, you can come up with very interesting data science kind of problems
that you can then do research on.
And some of these will kind of have a flavor that's very similar around the world.
So for example, while I was at CSR, one of the initial areas we had looked at is trying
to think about public safety, and then thinking, if we have the constraint that we might not
really have access to raw public safety data, could we use a proxy?
And the proxy we had come up with was maybe social media is there, people might be describing
incidents that are going on, like you know, it might be a fire, it might be a car accident,
and from there, can you build something that at least gives you an indication of what
might be going on in a town or in a city?
So that is one, the other could be pay, I want to, you know, this data that I have access
to, and we want to look at behavior in that data, and we want to pick out things that don't
make any sense.
So you want to look at anomaly.
So I work with a student, two students to work on anomaly detection algorithms with
that in mind, and hoping to get to a point where now, let's say you're looking at behavior
of people purchasing electricity, which is one project, we had worked on at the CSR
and I still continue to collaborate with some people at CSR on this, but you want to
look at how people like purchase electricity, and if they have behavior that is anomalous,
try to then go and understand why they are anomalous, and stick into the energy thing.
You can then think about the same thing of saying, hey, now I'm not going to look at electricity
purchase, but I might look at generation.
So South Africa has been trying to build on more renewable energy, and you have a couple
of research that we're interested in, hey, where should we be putting wind farms in the
country?
So we've got a couple, like, you know, a lot of data with wind data from, for all of South
Africa, with, you know, about five, five by five kilometer pixels, and I work with some
students then to say, what way are the most suitable places for wind farms given some constraints,
like this place where you can build, you can be too close to communities, you can be
too close to national parks, you can be too far away from roads, you can be too far away
from distribution lines, those, those type of things.
And with that, it kept on continuing where it's like, okay, fine, now you kind of know
where your wind farms are going to be, now you want to predict how much wind you're going
to have, let's say, over the next, the next couple of days, and then, or a couple of hours
because then you can then predict the amount.
So that's been going on with a couple of collaborators working in energy kind of a prediction.
Yeah.
So there's a bunch of interesting stuff to dive into there.
Maybe to get started, I've got some questions about this wind farm placement problem.
And in particular, folks have approached this placement problem with different types
of optimizations that aren't necessarily machine learning.
What does machine learning add to the mix in this particular type of problem?
And how do you, what kinds of data science methods do you end up applying?
Sure.
So with the placement, when I work, we work with a student at African Institute for
Mathematical Sciences, and then we use the suitability method.
So yes, it wasn't machine learning, I was just a kind of statistical mathematical model
that said, given what you rank, what's important to you, and given the rankings, then it changes
the suitability.
Got it.
Yeah.
So the student, Shanei Franckran, she worked on a suitability model, and that model we're
able then to tweak it, you can then say, okay, I'm not really interested in the environmental
things, for example.
Like, you know, if you are that way inclined, then you could remove it.
And then from there, we'll say, okay, these are the best places to build.
You might say, yeah, the cost of how far I should be from roads, don't really care about
it.
And then it would change kind of the suitability.
But where machine learning comes in now is on the flip side of saying, okay, fine.
One other thing that comes into perspective is that you might have an area.
You have some historical data in terms of how much wind was being generated.
And now you're interested in how much wind will be generated over the next 24 hours.
So you build, you build your wind farm, and you just need to make a decision on am I going
to have to, like, you know, fire up my cold power station or my nuclear power station.
I don't think nuclear power stations probably just go on and off.
But let's say my cold power station, but I need to know kind of what's going to happen
tomorrow.
So they've been continuing collaborations with Boubacard Ames, with a couple of other students
to then say, hey, can we build predictive models that can then just predict 12 hours ahead.
And we've also brought in the Colleen Huerta, who's also at CSR, who had worked on a couple
of models before.
But now we're using deep learning for that.
In this whole wind farm area, both the placement and the prediction of output, it's
seen, it strikes me that there are a lot of moving parts to a problem like this.
Can you kind of, you know, walk us through where some of the major challenges were and
how they were addressed?
Um, yeah.
So getting all the data, I think, was challenging.
So the, oh, the partly lucky thing is I have a wife who works in renewable energy.
Okay.
So we should have also, like, you know, spearheaded that I keep track of this research area,
like as something that just keeps on kind of ongoing.
So data science, step one is, yeah.
So in this case, like, I do remember sometimes where I, like, you know, I would ask a student
to ask and say, oh, yeah, I need access to data that matters like this.
I don't know where to get it.
And then I would just ask my wife and she would be like, oh, yeah, this would be on the
Department of Environmental Affairs website and you would be able to get it.
So things, things like protected areas, things like the national grid.
So where all the big transmission lines are, those type of things.
So you have to do kind of a big exercise on, on capturing from the design, I'm sorry,
from the, like a potential client, what they take is being informative.
And then from there saying, okay, what data do you have?
And from the data, they don't have go in, find it outside to say, okay, we have to go
find, find this data.
And so were these various things that you were tracking the protected areas and the grid
were these provided in a useful way?
Like did you have to go from, I don't know, some kind of description to, like, bounding
boxes or let long or something for various features?
Yeah, so you're going to have assumptions that you're going to have to make, especially
now you're working on like a five by five kilometer cell.
So you could say how many wind turbines can fit or you fit in there, you're going to make
an assumption that you're going to put only, like, you know, in one percent of the area.
The simplest one is just to say, I'm going to put one wind turbine.
It's not really true because what happens is that if you put wind turbines next to each
other, they're going to have wakes, and from the wakes, they actually then impact on how
much energy is actually going to be generated in total.
So it's not simple, but you can make that assumption, say, I'm just going to have one wind
turbine.
And now I'm going to just try to figure out how much power would be generated.
You have different heights of that wind turbine could be, you have different configurations
of those wind turbines.
So we had to kind of allow some flexibility with that of saying a user of the system can
choose and say, I want to, I'm interested in wind, I mean, at a turbine that's at this
height using this type of configuration, here's how big it's wind span.
It's going to be, if you're trying to look at where all the major roads are, I'm trying
to remember if we kind of did a hack on the Google Maps API, I might have been trying
to figure out if there was a major road going through every block.
And then from the estimating how far you are from a major highway.
Yeah.
So I think it was something of look, I think we had written some scripts for Google Maps
to identify where all the highways were and how far each five, five kilometer pixel was
from the major highway.
And so for these various features, did you end up encoding them binarily?
This one has a grid, doesn't have a grid, has a highway, doesn't have a highway and then
just kind of counted pixels, or did you, were you kind of treating it more fine grain than
that?
As for Shane's work, there was a little bit more fine grain decisions that were made
in just like, are you near, are you somewhere not too far and then are you far?
And yeah, so you can have those knobs and then you can also kind of play with them.
You can also then quantify them as cost instead and then say how costly is this going to
be?
And yeah, with some things a protected area, it's either it's there or it's not really,
like, you know, so if there's a national park there, you don't build really sort of
very negative, if I was thinking about rewards, they're going to be just a very big negative
reward.
Right, right.
Yeah, kind of things like don't do it.
And then if you had, then perfect where you had good wind because that was the other thing
is that do you have a lot of wind that's in that area and then also what's your slope?
So is it very sharp?
A slope, if it is, you don't want to build there, you want to build as close to flat as possible.
And you mentioned that some of these various data sets were on government websites was
this project something that could have been done by anyone was or all the data sets publicly
available or was there some private data that was used to figure this out?
Yeah, so the wind data specifically, not that there is wind data that you can get for
South Africa, that's open, but the one that we're using was one that was part of a study
inside the CSR, so they did give access to the students to work on it.
Okay.
Yeah, yeah, on there, so you wouldn't necessarily have access to that, but I can point out
people to kind of, I think there's a couple of stations across South Africa that are
used and have public data, where if you want to go download the wind, I think it's called
Wind Atlas South Africa, you can get data, but it would be for specific areas that are
covered at the moment, but not every cell, the one that we had was a model that was used
to extrapolate for the whole country, what the wind map would have been.
Yeah, you also mentioned you did something on the utility side, is that there was different
than the wind farm project?
Yeah, yeah, so again, with the social impact, what I've been trying to do is get to point
we're working with some of the local municipalities here in South Africa to look at some of their
kind of problems.
So with there, we had worked on, you've got electricity data in terms of purchases on
a monthly basis, and from there, you can do kind of things, you can build, do analytics
where you're just looking at, okay, what's kind of the span patterns, one which I still
want to work on is now looking at these deviations from those spending patterns to try to identify
behavior.
So one that the city was interested in, Steve Swanee where I live and I work is could somebody
have an install solar for you, for example, and how would we then capture that in the system
and the students we're working with on that also kind of try to figure out a couple of
heuristics to do this.
So one was bringing in weather data again and looking at days or months that were particularly
humid or they had lots of cloud cover during those months, you would expect that the solar
use would be less because there would be less power actually generated and then you want
to then see if that meant that the household during that time would then spend more on buying
electricity from the city.
What were the data sources that were used there?
So that one, the data is internal to the city in terms of the electricity purchase data
and then external is like using weather information and then using mapping which you have access
to mapping for the country.
So it's not as involved as the wind prediction one.
Okay, and what kind of models did you end up producing for that?
We're still trying to work on some anomaly detection models for it so that's not complete
as yet but we are working on writing up on the analytics part of the work and then there's
one on trying to look at the segmentation of the customers.
So we're actually using a recent see if you can see monetary value analysis that's called
RFM and it's used a lot in marketing but then using it now to understand the different
baskets of customers that the city has.
I'm sorry, what was the RFM?
Renaissance frequency and monetary value.
Let's see frequency monetary value and can you give us an overview of that model?
Sure, you calculate for each customer in the last six months how much they have they
bought, when's the last time they bought and how many times have they bought?
For example, and from there you're then going to find some baskets so you can find that
oh there's baskets of people buy a lot, five very frequently and they bought within the
last month and some people might be that they buy very infrequently by small amounts
and yeah, there's a little.
Okay, and so you're using those metrics, the recent see frequency and value as a way
to kind of cluster or segment the customer base?
Yeah, it's a clustering mechanism basically and you can test it against your things like
your k-means as well.
The goal in applying that technique is what?
So there is then you can think about what if then I wanted to estimate, if some of my
customers are in one batch and I was too fine to move them to another batch, what could
be the impact on my revenue, right?
Because each group will have specific characteristics and there might be that you're trying to identify
and say okay, maybe then you have people who would likely be moving to solar or something
like that, so if I then said the people who are frequent users started using solar and
they move to another batch, how much money would I lose from them moving to solar, but
maybe how much could I gain if I offered a product that was much more compatible to households
that you solar.
So one might be I buy electricity from them at different times of the day and then I
sell it to them back at night but I can take that same electricity I bought from them
and I sell it to other people also and make more revenue.
So it's kind of gaining those insights.
You also mentioned the public safety project that was based on some social media analysis?
Yeah, so this has been like a thread now that's run through probably the last few years
is just working on natural language in one way or another.
So initially when I started 2015 or so it was just to go like okay, could we use social
media as a way to identify if there's public safety issues, so you just want it's a very
cost and not accurate way.
So one could be I wanted if people are complaining about an accident and they describe that there's
an accident in a specific area in the city, could we pinpoint that and then from there
kind of come up with a map that is just showing you from people going on to our public
Facebook pages and putting this up so that way we kind of started and we worked on the
kind of a initial model that was very basic language processing model and then we worked
on it to then say okay one of the challenges that you have is that you can't really label
a lot of the data so you can only label like some subset of it so that we worked on then
doing kind of something like very rudimentary semi-supervised learning where you take a
model, you take your data that you've labeled, you train a model and then you try to train
more of the stuff that you haven't seen and you want to see if it will actually impact
your performance, we took into account maybe even network effects so identifying kind
of stuff about who's posting because there's these questions that come up about can you
trust all the information that you get on social media maybe there's things like if you
have somebody who has no followers and it just recently showed up maybe it's not you
should just fill that out and not try to classify that and then start working with a couple
of students like on things around like you know again using short text data for a couple
of things so one is being one PhD student who's working on identifying authors so it's
getting connected to this kind of trusting so saying who actually wrote this like you
know a short piece of text and can we identify that so he's been working on kind of deep learning
frameworks to be able to do that and there's been more work in now extending some of what
we had done on using short text as a way to understand so right now still working on
some methods to bring in more robustness in learning from short text without a lot
of data so what what might happen or what I'm like hypothesizing is that if you're using
social media as a data source some of the things that might happen over time is that there's
a quick change in language sometimes and because of this and also because you have got like
you know not that many words people might say the same thing in multiple ways but you
don't have again you know you're not a Google you're not a Facebook so you're not going
to have infinite amount of almost infinite amount of resources to actually label everything
that you have what you might have a subset that's labeled and how can you use that smaller
subset of data and try to make it kind of bigger and then by that improve how your machine
learning model is actually going to perform over time so you don't want it that you train
something and then three years later it actually is really bad.
You mentioned that in there this kind of sub project of identifying the author of short
pieces of text can you elaborate on that you're meaning identifying the author of a tweet
for example or identifying the author meaning so you have the tweet but not the account
that posted it or you trying to correlate it with authors that are outside of social media
or what exactly you're trying to do there. Yeah so there I'll use a like okay more
topical example today is this that you might have yes a short piece of text and what you're
trying you you you say it sure it says it's from this person like you know they're saying
it's from me but then you can actually look at the content and say oh actually this is
not from this person this type of content is actually generated by these other people right
so typically yes this might move into hey how does fake news get generated there's likely
some generator that's like you know not that level we hope so that's one way you can think
about it another way you can think about it's like you know you can see people taking content
without attribution on there and you can kind of build up a source of kind of way of linguistics
style that's that has happened I mean sorry that is in in that text so abedium woodoube who's
supervising his PhD he's working on that and it's been kind of a way to to understand like
you know oh this is actually real new content it's not something that somebody else posted
before and this person might be just like you know reposting in kind of in a way you can think
about it in terms of bots of identifying bots you can think about it in terms of terrorism in
terms of trying to identify where source of information might have come from are you comparing it
to other things that that user has tweeted to see if it's anomalous relative to what they've
tweeted are you comparing it to the entire corpus to see if there's some large group of users that
are all kind of tweeting the same things or the same way are you comparing it to some offline
you know totally offline corpus to see if you can correlate others in one corpus to tweets
it seems like you can do a ton of different things with this there's yeah there's a lot of
different ways so yes one which you've highlighted we're not doing it in this case is you you
could just look at the behavior of a person and like you know okay they write about this they tweet
about this they might be a blog like you know they blog about this and then something shows up and
you're like okay something's off here and that flags like you know saying hmm something is odd
but then that doesn't really give you kind of power to then say okay where could this have come
from but that's maybe you can then put that as a second item and say we're going to deal with this
but a way that is like the maybe the simplest way to think about it is that you could say okay
I'm going to characterize for something major where content comes from right so if you're looking
at bloggers so you could if you were medium build up a huge database of all your bloggers
and what they create and then you build a machine learning model that then every time you get a
piece of content you can say oh it comes from this author right with with high probability I can
tell you that this is the author who like the wrote wrote that thing but then yesterday you're
scaling with lots lots of labels right because now you have a multi-class problem and you could have
hundreds of thousands of labels that then put if then if you're Twitter you know millions if not
billions over time that you've kind of gotten into so the classes might be different given different
constraints so one you might just say is this original if is it not like and and and that could be
a simple dichotomy that you then use as a labeler and then you want to now build the architecture
like a deep learning architecture that can learn well from that because you don't have a
and long space string of text you then can do even other things you can then say okay fine
I'm not going to look at one treat an isolation maybe I look at the last five treats all right and
then see what's actually do you go on what kinds of models are you looking at with that one
on the deep left side yeah it's kind of kind of kind of based text models and yeah using
auto n's and CNN's maybe that to kind of wrap things up I'm wondering as you look across this
portfolio of projects focused on social impact applications of data science are there common threads
or trends or challenges that you tend to see when you're trying to apply this set of tools to
these types of problems or you know do they vary widely and don't have you know any any common
alities yeah there's some things you learn through through time so so one is kind of how to
define projects in a good way is good so you have to have a common language with who you're
working with so people come to you and say we have this problem we think machine learning can
assist like you know and then you go like okay what kind of data do you have and why do you think
kind of predictions might help or anomaly detection might help and taking the time to kind of get
a common language is useful because then it I think makes it much more interesting one is to stay
away from like you know taking the ham like you know the hammer that you have and everything
looking like a nail is that analogy yeah so sometimes you just go in and go like okay yeah
maybe this is not for me I think you can solve this very simply we we don't need to do it in this
way so let's get let's get somebody to help you with the simple way to to to kind of do that
with other things like I've been with with natural language processing it's been interesting
because you have a problem like one I hope to really get going is looking at things like
compositional systems for like people who are working together in organizations I'd seen this
from looking at some kind of work as a working government and they chat a lot and you might not
have a way to track what's actually going on in there but now you're thinking oh machine learning
could be useful in there because you can identify the context of what anybody's saying and like
you know at any time and from there be able to a guide in resolving a problem that they're trying
to work together to solve in a way so that brings in kind of a lot of layers of of things so I
enjoy that I guess the problem kind of solving maybe it's part of my engineering background
saying okay fine there's this problem that's out there how you break it down and how do you
then take out the chunks that you'll do some science on and then some other parts are practical
who do you have as a as a as a as a collaborated and who will take care of the practical parts and
then I'll go look at some of the machine learning with a couple of of the students I work with or
the other collaborators that I work with and and we work on that the other one is yeah maybe
that also drives me is seeing people are trying things out there I'm yeah I'm organizing a workshop
at International Data Week which is on the first from the 4th to the 8th of November and we have
a session there on data for good and again going to see people and I know you're going to see
people like an education trying to use data science and educate in education settings and seeing
the problems that they're kind of having and all the time it's like you know that thing of like
quantifying some behavior and then trying to use that to either predict or diagnose and because
you're seeing all these people it means that there's also the decision makers behind them so these
decision makers are trying to go like okay we know we've kind of gotten this data that we've
either been collecting ourselves like given like example the municipality using electricity data
but we really need to use it to improve the services that we provide for citizens and it's
yeah it's rewarding in that way that if you come up with something and it's like you know it really
gives some insight that people didn't know before that it could actually then make impact you
know right there in your community that's great well because he thanks so much for taking the time
to chat with us I enjoyed learning about the the various projects that you're working on
yep thank you for having me and yeah I guess we look forward to again having people next year
next year's in Dava there's obviously a couple of workshops that are coming up in different spaces
or conferences that I might be at or some of my other collaborators on so yeah I'm on to it
so you can find me are you at nips this year I will be speaking at black and AI okay yeah so I will
be in Canada so it's just yeah making sure I can get there but yeah yeah I will be there like what
are the things now again being back in in the south that low south is I haven't had to experience
the winters and then so it's like oh damn you're going to be in Canada in December yeah yeah yeah so
so yeah I need like you know spend some time in New Jersey so the winters were nice and ones the
nice because the snow is beautiful but at the same time they really were depressing so being
back in south it's been very nice because yeah they're like oh it's winter you're like no it's not
nice nice well I'm looking forward to to meet you in Canada then okay thank you
awesome take care all right everyone that's our show for today for more information on buccosi
or any of the topics covered in this show visit twimmel ai.com slash talk slash 193 thanks again
to google for their sponsorship of this series be sure to check out the 2019 AI residency program
at g.co slash AI residency as always thanks so much for listening and catch you next time
