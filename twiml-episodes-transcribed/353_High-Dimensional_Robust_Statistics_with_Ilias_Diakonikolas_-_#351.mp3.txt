Welcome to the Tumel AI Podcast. I'm your host, Sam Charrington.
All right, everyone. I am on the line with Elias Diaco Nicolos. Elias is on the faculty
at the University of Wisconsin-Madison. Elias, welcome to the Tumel AI Podcast.
Great to be here, Sam. I'm really looking forward to diving into our discussion. Before we do,
I'd love to hear a little bit about your background. Your primary research interests are
in algorithms and machine learning. And if the paper that we're going to discuss this time around,
distribution independent pack learning of half spaces with Moss Art Noise, which one
the Outstanding Paper Award at NURBS. If it's any indication, your work is quite theoretical
in nature. Tell us a little about your background and how you came to working on this type of work.
All right, so I grew up in Greece, and this is what I did in my undergrad. I moved to Columbia
University for grad school. My grad school was in a topic called the theoretical computer science,
so I'm an algorithms person. And somehow in the process, I realized that the best way to have
an impact in the world if you're doing theoretical algorithmic research is to actually work on algorithm
questions that come from machine learning and statistics. Why is that? Why is that the best place?
I mean, maybe, yeah, maybe the phrasing is not accurate. I think it's really a good place because
this is a setting where I think our listeners would all agree, but I'm curious your thought.
So I actually started doing this before it was popular, because I could really see that maybe not
all of the theoretical algorithm that one develops, but maybe some of them could be used in practice
and you could see the practical improvements in data analysis tasks. So in particular, I used to
like doing theoretical algorithmic research just for the sake of doing it, but sort of later,
like after my finish at my PhD, I started gravitating towards theoretical questions that if solved,
would actually have a practical impact. Describe for us broadly your research interests and focus,
so that we have a little bit of the context out of which this paper comes.
So I mean, I have broad interests within algorithms and machine learning. So this particular
narrative paper belongs at the high level in an area which is called the high-dimensional robust
learning. The idea here is that historically, every machine learning algorithm needs to make
some assumptions. Assumptions about the model where the data comes from. So in some sense,
very roughly speaking, every algorithm could be viewed as a data fitting method. You're trying
to fit the data to a model. Now, the issue is that this assumption about the data coming from
a model of a given type is very crucial. So and typically, you do not want your algorithm
to overfeed to this assumption. In the sense that if this assumption is not exactly true,
but if it's approximately true, you want your algorithm to still work. And unfortunately,
in high-dimensional settings, we realized about five years ago that this is actually not the case.
Even a very tiny deviation from the assume model could make the machine learning algorithm
very, very fragile. So we started and decided that, okay, we need to rectify this and develop
methodology to have robust learning algorithms for high-dimensional problems. And so when you talk
about high-dimensional problems and perturbations, are you thinking about things like the adversarial
examples, types of problems that we are familiar with, where you've got an image,
high-dimensional, and you apply some noise to it? So that's a great question. I was expecting
this question exactly to draw a difference. So these types of adversarial examples,
they're also some type of robustness, they're quite some type of robustness, but it's somewhat
different than the one I'd like to discuss. In particular, in the sort of adversarial robust
setting, what you have is that you train a bunch, so you train your neural network on some images.
And then you perturb those images in a way that's imperceptible to humans and see how the
how the model you learned performs. We have learned that it's actually non-robust and we need to do
something to make it robust. So the perturbations in the adversarial robust setting take place
at test time. So you train with a bunch of clean data and then you want to test on a set of
corrupted data. So the setting of robustness that I care about, at least with respect to this line
of work, is something that's called test time attacks, where you actually train on corrupted data.
So these two are related, so these two notions of robustness are related, but they're also quite
a bit different. And you said they're called test time attacks, but the data is perturbed in
training. So the side examples are called test time attacks. What I'm going to talk about is
called training time attacks. Got it. Okay. So let me give you an example. Like the most basic
example that I expect anyone could could understand with just a little bit of background. So if I give
you samples like IID samples from a probability distribution, like a Gaussian, and I ask you to find
the expectation, the mean value of the distribution where the samples come from. Let's say in one
dimension, then what would you do? To find the mean value. Yeah. You'd sum them and divide by the
number of samples you have. Yeah, that's fantastic. That's called sort of empirical mean. And we know
that it works, right? Unfortunately, though, if one of the samples that I give you is not drawn
from the distribution that you assumed it was, it's an outlier, then the average doesn't work anymore.
Because the average could be arbitrarily far from the true mean. It's not going to convert
to the true mean. If anything, you take infinitely many samples. So what do we do in this case?
So for the one-dimensional setting, the solution is known for like, I don't know, a centurion
statistics. So instead of taking the average, you're taking something which is called the median.
Okay, so we know that the median is robust to outliers, and it's optimally robust for one-dimensional
problems, right? Now imagine a generalization of this problem to hide dimensions. So now instead of
observing one-dimensional points, you're observing high-dimensional points. Every observation that you
have is a high-dimensional vector, let's say in a million dimensions. And you want to do the same
thing. You want to actually compute the expected value of the corresponding distribution.
Now in the case of clean data, you would do exactly the same thing that you did in the one-dimensional
case. You would sum all the samples and divide by the number of the samples. So this is the empirical
meaning high dimensions. And in the case of clean data, it works. Now the difficulty is actually
generalizing this high-dimensional empirical mean when you actually have, let's say, 10% of your
of your samples being arbitrary outliers. In this case, unfortunately, there's not such an easy
solution as taking the median. Meaning because the median and a high-dimensional scenario isn't well
defined or because of the number of outliers you have. That's, these are great questions. So
there are many ways to define a notion of a median and high dimensions. For example, one thing that
you could do is look at every coordinate individually and calculating the median of every coordinate and
giving that answer. Unfortunately, this is not going to work. The reason is they're going to work
is because you have many dimensions and in some sense the noise can accumulate across the
dimensions. So if you have, let's say, even a 1% of outliers, then the error you're going to get
at the end is going to be very large in the worst case. It would actually depend on, it would actually
scale with the number of dimensions. And this is something that you can avoid. We know that you can
avoid that if you look at like information theoretic bounds, but we didn't know how to avoid it with
a computationally efficient algorithm with a method that you can actually run. So what we did
four years ago with a number of great authors is we developed the first methods that is actually
robust for estimating the mean of a high dimension distribution to a constant number of outliers.
So even if you have, let's say, 20% of outliers and no matter how high the dimension is,
the algorithm runs efficiently and gives you an accurate approximation of the mean.
What's the general flavor or shape of this algorithm? I see. So there are many versions.
Maybe the easiest one is about detecting and removing the consequential outliers.
So we are in a high dimensional setting. So the most sort of naive thing to try to do is detect
the outliers and remove them. And after you do that, then you just output the mean of the rest.
It will be the ideal methodology to solve the problem. The issue is that this is impossible.
We can prove that it is impossible to actually detect the outliers in high dimension setting.
So what do we do? So the next thing to try to is, okay, maybe I cannot detect and remove all the
outliers. Maybe I can detect and remove the ones that if I kept in the data sets, then they
would actually skew the appear can mean by a lot. And it turns out that this is something that you
can do by using spectral memory. So I guess I do not have like a picture to show you, but the idea
is this that let's say you have your data set is some kind of clouds in high dimension. You might
get like a sphere, right? Even outliers very far from that sphere, then you can eyeball it.
You can eyeball it and you can remove it. These are outliers that are very easy to remove.
Unfortunately, in high dimensional settings, these are not the outliers that can kill you.
These are not the only outliers that can kill you. They can be outliers that are within
the initial cloud of points. Each one of them individually looks like a fine point.
You cannot say that this on its own is an outlier, but somehow the outliers have the ability
to collude with each other to skew your estimates. So what you need to do is somehow
detect outliers in a high dimensional setting in a more global scale. So it's like a local versus
global type of phenomenon that appears here. And this is because of the high dimensional setting.
Now does your problem presume single prior distribution? I'm thinking about the one-dimensional
example where as opposed to trying to identify and discard outliers, you might have multiple prior
distributions and you're trying to determine which of your samples belongs to which distribution
as a way to formulate the problem. Right, right. So the formulation that we're using this
setting is a frequentist formulation. It is not the Bayesian formulation. So there is not
something as a prior. So what we really assume is that we have a family of distributions,
let's say a family of models, where we assume the clean data comes from. Let's say for example,
the clean data could come from a mixture of high dimensional gougins. So that's an assumption.
Okay, so you do assume a mixture of gougins as opposed to a single gougin.
Yeah, we can do that. And in fact, there are many different assumptions that we can handle algorithmically.
These are related, I mean, this is a technical problem. So these are related to the rate of increase
of the moments of the distribution of the good error. So if the moments of the good distribution
behave well in the technical, in the technical sense, we can actually solve the problem.
But what I want to emphasize is that some types of assumptions of this form are actually necessary.
In the sense that if you make no assumptions about your good data in this unsupervised learning,
where you have unlabeled data, the problem is not solvable even information theoretically,
even like with infinitely many samples. And the reason is that the outliers, they have the ability
to actually completely mask the information that's contained in the good data.
So some type of assumption like the one that you are literally doing is actually
information theoretically necessary. Got it.
Right, so this is so basically where sort of thing started and this is an unsupervised
setting. Unsupervised machine learning means that the data set that you observe is an unlabeled
data set. You have a bunch of points in high dimension without labels.
So maybe it's time for me to move to the Norrips paper.
Yeah, yes. How does that paper come in?
Right. So this is a supervised learning setting. This is a setting where you observe labeled data.
And what you're trying to do is you're trying to fit a linear model. This is like the most basic
family of concepts that you could try to fit to the data. Like literally a linear separator.
You're trying to find a linear separator that separates the point into two classes,
the positive points and the negative points. This seems like almost like a too simplistic problem.
And indeed, in the case of of clean data, it is. Now the question is what happens
when the labels that you observe are actually not clean. They have, let's say, some kind of random
noise attached to them. Can you still recover the true linear model efficiently in the presence
of these types of corruptions? And what we show in this paper is that, in fact, in a very
reasonable model over random label perturbations, this is something that can be done. It can be done
with a computational efficient algorithm. If I understand what you're saying, it's that the linear
model is insufficient in the case of clean data. But when noise is added, that a linear model,
a simple model becomes sufficient. Let me rephrase. So the reason that we consider
settings where the labels are noisy is because these settings are more realistic in practice.
We cannot really assume that we observe label data and our labels are perfectly clean.
So what I was trying to say is that if you make the unrealistic assumption that the data
is clean, then we knew how to fit linear models since the 60s. What we did is we gave an algorithm
to fit linear models under the more realistic assumption that the labels are actually randomly
perturbed. So this is the contribution of this work compared to prior works. We can actually
learn linear separators efficiently in the presence of noise. And so the paper is called
distribution independent pack learning of half spaces with mass art noise. There's a bunch of
terminology in there. Walk us through that terminology pack learning half spaces mass art noise.
Where do they come into play? Okay, that's great. So pack learning. So pack is an acronym. It means
probably approximately correct is a standard model of binary classification introduced by
Leslie Valiant in the 80s and even before that similar models existed by WAPNIC.
So basically the model is essentially for someone who has seen statistics and machine learning.
The most natural thing you could imagine that you observe a bunch of IID labeled examples
that come from a distribution on points with corresponding labels and then you're trying to find
a classifier that generalizes over unseen data. So that's the definition of the pack model.
Now the term distribution independent which in fact maybe is in some sense unnecessary because
the original definition of the pack model was distribution independent is that I'm going to observe
a bunch of labeled examples x and y. Okay, x is going to be my point in high dimensions and y is
going to be a binary label 0 or 1. So what I do not want to do is I do not want to make any
assumptions about the distribution of the x's. Right? I do not want to assume that the x's are
drawn let's say from a Gaussian distribution. So the only thing I'm going to assume is that the
x's are IID samples from some distribution which is fixed but it's unknown to me and it can be
arbitrary and the motivation for all that is on the real data of this type there are settings
where we don't know anything about the distribution of the data and ideally we would like to be
able to handle noise even in those settings. So this is what distribution independent means.
Now the third and last term of the title is massar noise. So let me explain what this means.
So you observe your labeled examples x, y. If y was sort of in the case of clean data why would
actually be the correct label of x. Right? So now what would be a reasonable model of noise?
A reasonable model of noise would be that's okay. I take every y independently and I perturb it.
I flip it. I make it 0 from 0 to 1 not from 1 to 0 with some small probability. Let's say
1 tenth. So this is what massar noise is but it's a little bit more subtle. What it tells you is
that I take every label and with probability at most 1 tenth I perturb it. But you don't know what
is the probability that I use to perturb it. It's a number that's less than 1 tenth but it could
be anything between 0 and 10. Okay. That's the definition of the massar noise model. It means
that under perturbation and the probability of perturbing every label is going to be bounded
from above by some constant. Certainly the constant should be less than half otherwise I lose
all information. And the feature of the model is that you don't know what the flipping probability is.
It can be different across the examples you observe. Got it. And does that massar noise
particularly model well some natural phenomena that we see? Right. So it's reasonable to assume
that the noise added to the examples is independent or almost independence. But in general we don't
know and certainly we should be assuming some boundedness. Otherwise we get no information.
But what we really don't know is we don't know if the same noise is going to be added to different
examples. So in terms of practical applications there are many the people who define this model
like in the 80s and 90s have set out many settings where this is actually reasonable.
So as a theorist I just took the model and tried to analyze it. Got it. Got it.
So let me tell you one thing that I think is surprising especially if you haven't thought about
this problem. Let's consider the case where you know a priori that every label is going to be
perturbed probability exactly one time. So is this model easier or harder than the one I mentioned
already. So what would you think? I would think easier. I think you would say harder.
Actually it's the opposite. So I would think that you would say that it's harder but in fact it's
easier. Oh I was speaking it's easier from I guess an information theoretic perspective we have
more information about the problem. From an information theoretical perspective when you have more
noise you can predict less accurately. But you are right in the sense that algorithmically
it was known how to solve. Just to see that. So basically when you know exactly what is the
amount of noise you're going to add to every example then in some sense you have the ability to
invert the noise. So in fact go from let's say the any statistic that is defined on the
noisy data there is a mathematical way to transform it efficiently to the same statistic on the
clean data. So this has been studied a lot since the 90s it has a name it's called statistical
query model. There are some genetic transformations that tell you that any algorithm that works in
this statistical query model is actually tolerant to this type of noise. The type of noise where
everything is going to be perturbed with the same probability. But the massar noise model
where you know that the probability of flipping is going to be bounded from above on every example
at most one tenth. But you don't know what it is even though the accuracy you can get is higher
information theoretically the problem is easier algorithmically is much more challenging because now
if you see a given example with its label you have no way of knowing if this label is 100% correct
or 90% correct or anything between 90% and 100%. This makes it really hard to actually to actually
invert. In particular this genetic transformation I mentioned that relates this statistical query
model with tolerance to noise fails to hold in the massar noise model. So we need to do we need
to do something new. One more terminology or one more bit of terminology from the titles half
spaces. Right. Half space is just a linear separator. Oh got it. Just a linear model. You have
a bunch of points. You draw a hyperplane in Euclidean space. What's above the hyperplane is
positive? What's below is negative. All right. So in order to analyze this what kind of
machinery did you call in the play? Right. So what we wanted to do is use SGD. Okay. It makes
sense. SGD is the most natural algorithm to use to solve an ML problem. So you need to formulate
the problem in a mathematical way as an optimization problem and hopefully SGD is going to solve
this optimization problem. What we ended up showing as a first step is that this is impossible.
Okay. Fundamentally SGD can't be applied here in other words. Yes. So this is like 50% of the
truth. So if you try to write some kind of complex relaxation of the problem,
try to solve it by SGD. This is going to be this going to fail completely. We can prove that.
And the proof is not particularly difficult. Right. But during sort of the process of developing
this proof, we actually realized that even though SGD does not suffice to solve the problem of
the entire space, it actually suffices to solve the problem on a non-trivial fraction of the space.
Okay. Okay. So basically, I mean, this is of course, it's a technical thing. But we showed that
there exists a non-trivial fraction of a domain where SGD works. So what we, this is an unknown
subset that there is an efficient algorithm to actually detect. So we can find the subset of the
domain where SGD works. We can solve the problem on that fraction of the domain and then iterate on
the rest. Basically, the algorithm turns out to be an application of many codes to an SGD routine.
Are you able to either determine the importance of the subset of the space that you are able to
apply SGD or are you able to kind of keep track of how much of the space you've covered by iteratively
searching with SGD? Right. So to show that this algorithm is actually efficient,
this process that I describe this iterative process needs to happen a small number of times.
Right. If it happens a exponential number of times, you haven't solved the problem efficiently.
And this is part of the structural understanding that we obtained by solving the problem. But in
every iteration, we actually cover a non-trivial and inverse polynomial fraction of the space.
After at most the polynomial number of iterations, we have covered the entire space.
Right. Okay. Let's say in every iteration, we solve one percent of the problem. So we need
the hundred iterations solve the problem. Maybe this is a sidebar, but are there specific details
of the implementation or the proofs that you or what you covered in a paper that are accessible
without going into, without getting too pulled into the theory? I think the answer to that is
probably no, but I'll be honest here. So it's not a terribly complicated paper. I think it's
actually quite simple from a theory perspective. It has something original that people didn't come
up with before. So what I maybe should say that this, even though it answers an open problem
from a long time ago. So this was posed in the 80s in learning theory. It's not over here.
So this is in some sense the first paper in this sort of line of work of doing distribution
independent learning with noise. And I believe it's going to lead to many developments.
In particular, like something that we have been able to answer very recently with one of the
authors of the same paper, my colleague, Christos Zamos, and two of our PhD students here at
Madison is that in fact, if we make some very weak, but still reasonable assumptions about
the distribution. So if we look at the distribution specific sharing, but still reasonable,
we have a way of showing that SGD actually works as is. So we relax the problem a little bit,
but still in a way that it remains reasonable and we can now solve it by SGD.
And you're a bit cagey about the assumptions that you're making. Are they,
are you fixing to a limited subset of known distributions or is there some other
distributions that's important? Right, right. So the paper is going to be online in a week,
so I'm happy to share this. So I mean, the terms are going to be sort of a little
potentially, potentially a little bit technical, but really what we need is that the distribution
of the inputs is reasonable in the sense that it's not too concentrated or too sort of like,
let's say, not too dense or not too empty and where. Okay. And so there are these technical terms
that are called concentration, anti-cursentration. So as long as we have weak properties of that
for, this probably suffice to solve the problem. Okay. Interesting. Interesting. And so what is it
about this paper that you think kind of caught the interest of the NIPs reviewers and landed it
the outstanding paper award? Right. That's difficult for me to answer. I mean, this is,
I'm not happy that the paper got recognition and I really believed in it before we submitted it.
So I believe it was a significant advance. I think the reason is because it solves,
like, that's my guess, that it solves an old open problem and recognized open problem
in machine learning theory. And really, essentially, no progress had been made on distribution
independent learning in the presence of noise for a long time. And also at the same time,
the solution turns out to be quite clear, at least compared to other theory papers.
And were you surprised by how clean it ended up being? Yes, I was very surprised. In fact,
we solved this problem in a month and then we spent like 10 months to improve it,
and we couldn't. So it somehow gives me the belief that this turns out to be, this is
probably the best possible solution to the problem. But yet, you remain convinced that
there's more to come and you'll be able to build on it or improve on it. Yes, I mean,
there are some other things that we have recently done and I am indeed cage about them because
they're not sort of written yet. But yeah, I believe that this line of work is going to lead to
a lot of progress in the next couple of years. And so for folks that are interested in digging in
a little bit deeper, there's obviously this paper, but you've also recently
co-authored a survey on this broader space. Can you talk a little bit about that in the focus there?
Right, right. So since this initial 2016 paper on robustly learning high-dimensional
distributions, so we're back in the unsupervised setting. So once we wrote this paper,
a number of people found this interesting. And at this point, there is a long literature
on algorithmic high-dimensional robust statistics. So what I did with my long-time
collaborator, Daniel King, we decided, okay, there's so much work in the past four years and it's
unclear if people understand other people's work. So let's try the survey, giving an overview of
all the techniques that people have developed in this space. What are the problems that have been
solved? What are the problems that are open? Somehow giving some kind of, you know, pose, like I
point where, you know, the community needs to say, okay, this is what it has achieved so far.
What are the next directions to look at? So this is available on the archive and it's also going to be
sort of at least a short version of it's going to be part of a book chapter on the young worst
case analysis that's going to be published by Cambridge University Press soon. Okay, and this is
the recent advances in algorithmic high-dimensional robust statistics that was published on archive
back in November of last year. That's right. That's right. And how many papers does it cover?
I mean, in true detail, probably around 15, but we give an overview of about a hundred.
Oh, wow. Wow. There has been a lot of work in this space in the past few years and really
the reason for that are these theoretical questions have the potential of practical impact and
already we have seen some steps in that direction. For example,
one of the prototypical applications of robust statistics is in something that's called data
poisoning. So this is a phenomenon where you have a machine learning system. So the input
coming from the outside let's say you have many users, but then you have a small number of
malicious users that are trying to insert fake data in the system and completely destroy the
behavior of the system. So robust algorithm would actually be able to prevent that.
Okay, so we have had the number of papers and I've got all of the couple where we actually do that.
We actually show that some of these theoretical algorithms developed in these initial works
can give you provable and practically useful defenses against these types of data
poisoning attacks in machine learning systems. Okay. And are you aware of any actual implementations of
the work in the space? Implementation is what sense. I mean, I'm afraid
there. In a sense of a company using it. I see. Okay. So yeah, we're not there yet. So I'm
very eager to sort of, you know, to collaborate with people to do that. At this point,
we're at the stage where we have sort of proof of principle experiments published in like
ICML and Newrips. So we're not yet at the stage where this sort of line of work has reached
the industry. But it's a goal. It's a goal for the immediate future. And do you think that that
is because the, it sounds like folks are aware of the problem are the solutions sufficiently
generalizable at this point that they are easily applied in industry? So I think the reason is
that it hasn't propagated enough. Right. So in some sense, another reason might be that some of
the algorithms are not just creating the sense. Okay. There are a little bit more sophisticated
algorithms using spectral methods. They're not as automatic as machine learning people who'd like
them to be. So basically, a next step, which is currently something I'm currently working on,
is actually completely eliminate the algorithms from these problems. Right. So we formulate them in
a certain way so that we can just use it in solving. And somehow the insights obtained from these
initial papers are useful. Let's see that. So let me point out that these problems are inherently
non-convex. And this is why they're so hard. Okay. But even for non-convex problems,
when they have some additional structure, it is quite possible that if you formulate them the
right way, some version of SGD actually solves them. And this is something that I believe is true
and we're working towards proving it. Well, Alias, thanks so much for taking the time to share what
you're working on. Something you very much for the opportunity that you gave me. Thank you.
All right, everyone. That's our show for today. For more information on today's show,
visit twomolai.com slash shows. As always, thanks so much for listening and catch you next time.
