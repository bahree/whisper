WEBVTT

00:00.000 --> 00:05.680
All right, everyone. I am here with Jennifer Glor. Jennifer is the VP of customer engineering at

00:05.680 --> 00:11.040
San Bonova Systems. Jennifer, welcome to the Twoma AI podcast. Thanks for having me.

00:11.040 --> 00:17.200
I'm really looking forward to digging into our conversation. We're going to go deep on GPT-3

00:17.200 --> 00:23.840
and Transformers in the Enterprise in industries like banking and finance. But before we do,

00:23.840 --> 00:28.240
I'd love to have you share a little bit about your background and how you came to work in AI.

00:28.240 --> 00:34.640
Sure. So I've been at San Bonova Systems now for three years. The customer engineering team

00:34.640 --> 00:39.760
is responsible for the technical customer journey here from pre-sales all the way to

00:39.760 --> 00:45.120
post-sales deployment and customer success. Prior to being at San Bonova Systems, I was at Sun

00:45.120 --> 00:50.320
and Oracle, where one of our founders came from. And I had a varied background there where I

00:50.320 --> 00:57.280
worked with products, partners, customers. The last few positions I had involved engineered

00:57.280 --> 01:04.000
systems and cloud deployments for mission critical applications. So AI was up and coming for some

01:04.000 --> 01:08.640
time. It was an interesting technology and I was itching to get involved in that. And when

01:08.640 --> 01:13.760
the opportunity at San Bonova presented itself to combine my technical expertise with customers,

01:13.760 --> 01:19.440
it made perfect sense. That's awesome. That's awesome. I've been following the company for a while now.

01:19.440 --> 01:27.200
And a lot of my early conversations with the folks on the team there, Marshall, Rodrigo,

01:27.200 --> 01:35.040
and others have been around the hardware vision. Creating a new chip architecture to support

01:36.240 --> 01:42.080
machine learning applications. But more recently, the company has been focused on this

01:42.080 --> 01:48.400
GPT-3 thing. Where did that come from? Give us some context for that part of the journey.

01:48.400 --> 01:55.200
Yeah. So obviously San Bonova is an AI accelerator company and part of that is our own chip and our

01:55.200 --> 02:00.880
own system. But in all honesty, the premise for the company is a combination of both hardware

02:00.880 --> 02:06.960
and software. And hardware is only as good as the software that it runs on. And so we are actually

02:06.960 --> 02:12.800
a software-divined hardware platform. And when the company started four years ago, we had the

02:12.800 --> 02:20.960
mission that for AI workloads, deep neural networks, you need to reimagine what that platform,

02:20.960 --> 02:26.160
both software and hardware should look like for the type of workload that are coming, right?

02:26.160 --> 02:32.160
CPUs and GPUs are doing a great job, but they were built for more traditional workloads in mind.

02:32.160 --> 02:37.280
And when you look at these deep neural networks, compute is important, memory is important,

02:37.280 --> 02:43.200
but how the data flows through the system is extremely important. And models are changing and

02:43.200 --> 02:50.000
new research is being done. And so the ability to reconfigure and have flexibility and map your

02:50.000 --> 02:55.520
software to your hardware is extremely important. So from the very early days, well, we have our

02:55.520 --> 03:02.160
own chip and we have our own system. The software stack has been crucial. And so we have two products

03:02.160 --> 03:08.320
at Samba Nova Systems. One is Dataflow as a service, which packages our underlying hardware and

03:08.320 --> 03:15.120
software product and put services and solutions around that or focuses in natural language processing

03:15.120 --> 03:21.520
and computer vision. And then we also sell a data scale product, which is more just the hardware

03:21.520 --> 03:26.720
and the software for folks who want to control the full lifecycle of AI development themselves.

03:26.720 --> 03:33.600
So that's just getting the racks of the Samba Nova servers plus the software layer on top.

03:33.600 --> 03:40.000
Exactly. So we think of them in two ways. Dataflow as a service is more data-centric and data scale

03:40.000 --> 03:46.240
is more model-centric. So if customers are looking to consume solutions and services, they want to

03:46.240 --> 03:52.720
accelerate their AI journey and get there faster, then they're looking for a service and solution

03:52.720 --> 03:58.400
that's optimized and that's what Dataflow is a service. We provide the service, they bring their

03:58.400 --> 04:05.040
data. If you look at data scale, that's a much more model-centric platform where customers are

04:05.040 --> 04:11.040
researching models, doing a lot of work with models, as far as hyper parameter tuning or other

04:11.040 --> 04:16.240
things, making changes to their models, they control the full lifecycle and that would be the platform

04:16.240 --> 04:23.440
for them. Got it. So in the former case, or rather in the latter case, you're expecting

04:23.440 --> 04:28.000
the customers to be a lot more sophisticated. They're spending a lot of their time in training

04:28.000 --> 04:33.200
and development. In the latter case, it's meant to be more of a you bring data and will

04:34.480 --> 04:41.200
figure some stuff out for you. Exactly. And I'll be in EV. Exactly. For customers who are consuming

04:41.200 --> 04:46.400
Dataflow as a service, we're actually seeing two different types of consumers. So certainly,

04:46.400 --> 04:51.440
there's those customers that are early in their AI journey. They may have data scientists,

04:51.440 --> 04:57.280
but the team is not significantly large. They feel like they're maybe behind or haven't

04:57.280 --> 05:02.400
made a lot of progress on their AI journey. So they're looking to accelerate that. And so they bring

05:02.400 --> 05:08.320
in some solutions from us that helps get them part of the way and then they can focus their team

05:08.320 --> 05:15.040
to build workflows around that. There are other users of Dataflow as a service that actually do

05:15.040 --> 05:20.320
have larger AI teams. They're quite skilled, but it's just the decision of where to focus their

05:20.320 --> 05:26.400
effort. And so if they can purchase pre-packaged solutions from us that help take care of some of

05:26.400 --> 05:32.080
the NLP and CV problems, then they can go focus on more business critical parts of their workflow

05:32.080 --> 05:40.080
and AI. And so how did the focus on GPT-3 and transformers come to come to be?

05:40.080 --> 05:45.600
Yeah. So at Samba Nova Systems, as we've been working on our journey and the products that we

05:45.600 --> 05:52.160
have to offer, we're always looking at what are the capabilities that our platform can enable

05:52.160 --> 05:57.440
and bring value to customers. At the end of the day, it's all about the customers and how are they

05:57.440 --> 06:02.560
going to use the product and how are they going to be successful on their AI journey. So for us,

06:03.120 --> 06:09.440
some of the advantages of the underlying platform are tied to our large memory configuration,

06:09.440 --> 06:16.560
the flexibility we have in the platform. And so things like transformer models, both BERT and GPT,

06:17.520 --> 06:22.720
you know, they started a few years ago where you would have a hundred million parameter model,

06:22.720 --> 06:29.680
a 300 million parameter model, GPT-2, a 1.5 billion parameter model. And now we're looking at GPT-3,

06:29.680 --> 06:37.200
which is 175 billion parameter model. That is stressing not only the compute capacity,

06:37.200 --> 06:43.360
but also the memory needs of existing architectures. And because our platform has

06:44.240 --> 06:50.080
those capabilities in really shine in that space, it was just a place for us to get started

06:50.080 --> 06:53.200
and start showing the capabilities that our platform has to offer.

06:53.840 --> 07:02.160
When you're out talking to folks about these kinds of models, I'm curious to learn a bit about

07:02.160 --> 07:09.360
what you're seeing out in the real world, outside of academia, in the industries that I mentioned

07:09.360 --> 07:18.560
earlier, banking, finance, traditional organizations, like how far have they come with trying to use

07:18.560 --> 07:26.640
these models and what ways are they trying to use transformers and what's their experience so far?

07:26.640 --> 07:32.880
Yeah, so I think, I mean, obviously it depends. It depends where you are in the world. Different

07:32.880 --> 07:39.520
countries are potentially further along. Different industries within those countries are further along.

07:39.520 --> 07:44.640
And so you have, you know, if you take a look at, for example, hyperscalers, regardless of where

07:44.640 --> 07:49.680
they are, they are obviously very far in their journey with natural language processing.

07:49.680 --> 07:54.160
Many of them are coming out and pushing the boundaries with new models on a regular basis,

07:54.160 --> 08:00.960
right? And, you know, we used to say that hardware, you know, the hardware has a cycle that's usually

08:00.960 --> 08:06.640
years in gestation period. And these models are making significant improvements like every two to

08:06.640 --> 08:10.640
three months as far as the number of parameters and the compute and memory needs required.

08:10.640 --> 08:18.240
But what we're seeing in enterprise customers, regardless really of where they are in the world,

08:18.240 --> 08:23.680
is that, you know, they realize that they need to do something with AI.

08:24.560 --> 08:30.880
They feel like their competitors are ahead of them. And in some cases, there are actually

08:31.440 --> 08:36.000
examples that we know of or that they know of where investments have been made,

08:36.000 --> 08:42.480
significantly in resources, both people, time, machines to go build solutions, right?

08:42.480 --> 08:46.480
How successful those implementations have been, you know, varying degrees.

08:47.360 --> 08:54.880
But they realize that there is a lot of opportunity here. How they translate that opportunity to

08:55.840 --> 09:01.280
value that they bring to their customers and their business is that's where I think some of

09:01.280 --> 09:06.880
the questions still lie, right? Some people have started to figure it out and are deploying things

09:07.520 --> 09:12.960
slightly. Others are just very early on in their journey. And then you have some in the middle

09:12.960 --> 09:16.880
who have been trying things, but just haven't really figured out how to put it all together.

09:17.680 --> 09:23.920
You know, from a language perspective with natural language processing and our data flow as a service

09:23.920 --> 09:30.240
for language, we see this cutting across all industries. And if you take a look at, say,

09:30.240 --> 09:35.600
financial services, it's going to hit community banking. It will hit corporate banking,

09:35.600 --> 09:41.840
capital markets. There's applicability across all parts of banking and financial services as well

09:41.840 --> 09:48.480
as other industries. And it has the ability to be transformational, both, you know, customer

09:48.480 --> 09:54.800
facing and back office for many industries. And are there specific use cases in those industries

09:54.800 --> 10:02.080
that are coming to the fore as being places to places that organizations are starting or

10:02.080 --> 10:07.200
where they're seeing success? Yeah. So I think if you look at banking and this applies to other

10:07.200 --> 10:13.520
industries as well. The first use case that always jumps to people's minds is call center.

10:13.520 --> 10:20.000
And the reason for that is that is an easy one for people to walk through and understand.

10:20.000 --> 10:25.840
And it does apply in multiple industries. And so when you think about call center interactions,

10:26.400 --> 10:31.760
when they come in, you understand who your customer is. You have some information about them.

10:32.720 --> 10:38.240
Maybe they are speaking with you. They're texting with you. They're chatting with you in other

10:38.240 --> 10:43.040
ways. There's lots of ways that, you know, call centers are running these days, whether it's chat

10:43.040 --> 10:49.840
about with a live person. At the end of the day, despite a lot of technology being applied, you know,

10:49.840 --> 10:55.040
most people when you talk to them about how was your call center experience or support experience

10:55.040 --> 11:00.960
with x, y, and z, right? It's not a positive experience. And then you usually get asked for the

11:00.960 --> 11:06.560
survey at the end. And who fills out the surveys, except for the people who are really irritated

11:06.560 --> 11:11.440
about the process that they've been through. So I think, you know, call center is a very easy

11:11.440 --> 11:16.320
problem to understand. And there's a couple of different ways that we can apply natural language

11:16.320 --> 11:23.440
processing and GPT and obviously combined with other bits to improve that experience and drive

11:23.440 --> 11:29.280
customer value. So, you know, bank banking institutions, certainly when you come in and talk to them,

11:29.920 --> 11:36.160
they understand how to figure out, you know, was a customer happy or not. Some of it's through surveys,

11:36.160 --> 11:41.840
some of it's through other mechanisms. But think about as you're interacting, whether it's via text

11:42.960 --> 11:49.760
or actually talking to a live human being or speaking with the automated system, you know, by tone,

11:49.760 --> 11:55.520
by the word choice, word choice specifically for something like sentiment analysis as a downstream

11:55.520 --> 12:02.640
test of GPT, you can start to get live feedback on what the customer is saying and the word choice

12:02.640 --> 12:07.680
that they're using is this a positive experience, is this a negative experience, or is this a

12:07.680 --> 12:14.000
net neutral experience, right? So that's just one example. As you are talking to a customer or

12:14.000 --> 12:19.680
they're inputting things, you know, you can do extraction of text and apply it to rather than

12:19.680 --> 12:24.560
saying, you know, can you fill out this stuff for me or give me this information, you can grab a

12:24.560 --> 12:31.200
lot of that and get things into the system to improve the overall customer success flow. I mean,

12:31.200 --> 12:37.920
the end, the end state is really to try to get the information from the customer about their problem

12:37.920 --> 12:44.320
as quickly as possible to have the call center automated system or person that eventually gets called

12:44.320 --> 12:50.400
in to have the solution at the hand and ready for the problem that they have and then all of that

12:50.400 --> 12:55.520
be a positive experience. So there's lots of different ways that we can combine all of that to make

12:55.520 --> 13:05.040
that work. I'm not sure if this is a pushback or an opportunity for a liberation, but it just

13:05.040 --> 13:13.840
strikes me that there's so much opportunity to do basic things, like I'm very curious your

13:13.840 --> 13:21.840
experience about the readiness to even do advanced things, you know, to the point you mentioned

13:21.840 --> 13:29.680
earlier, ensuring that the rep that you're talking to has the information about your account

13:29.680 --> 13:34.000
in front of them. So you're not repeating things that you told the last rep or, you know,

13:34.000 --> 13:39.680
telling them what products you have. Like it seems like there are some pretty foundational things

13:39.680 --> 13:45.120
that organizations need to figure out. I don't know if it's just banks or rather, I don't

13:45.920 --> 13:50.640
have an opinion on whether banks are further ahead of that or behind on that, but what's the

13:50.640 --> 13:57.680
readiness of the enterprise to receive this kind of technology given the state of call center?

13:58.640 --> 14:03.360
Yeah, I mean, I think, you know, essentially when you think about a customer,

14:03.360 --> 14:07.840
regardless of industry, they're going to have, you know, they should know about your products,

14:07.840 --> 14:13.520
your previous transactions, your history. That's all structured data, right? So when you think

14:13.520 --> 14:19.360
about that, that is an easier problem to solve. And many people across many industries are doing

14:19.360 --> 14:24.320
better in that once they get some preliminary information from you, right? If you give, say,

14:25.040 --> 14:30.720
a key identifier, they just ask you to verify who you are, right? And they know, oh, here is your

14:30.720 --> 14:34.880
name. Here's the transactions you've had with us. And it can go very smoothly from there.

14:35.440 --> 14:40.720
It's this on other unstructured data, right? Which how do we incorporate that into the workflow,

14:41.360 --> 14:47.600
to bring a better synergy between the customer and the business? And so I think,

14:47.600 --> 14:55.680
you know, we are ready to start doing that. But I think one of the key things is when you start

14:55.680 --> 15:02.320
looking forward to how you do implementations, a lot of people get stuck on what is successful.

15:02.880 --> 15:08.720
And maybe they're thinking really big and really grand. And there are some small things and easy

15:08.720 --> 15:14.160
wins that you can make to show success. And so one of the things we talk about with our customers

15:14.160 --> 15:20.000
is, you know, breaking things down into smaller chunks and milestones where you can actually see

15:20.720 --> 15:28.640
this new technology making impact, you know, testing that it has an impact and then continuing to

15:28.640 --> 15:35.200
make adjustments and add additional things over time. So that you don't get stuck in the cycle of,

15:35.200 --> 15:40.000
I'm testing things and I don't know, is it successful? Is it not? It feels like we're what we call

15:40.000 --> 15:44.800
sort of POC purgatory where you're doing a lot of things, but are you actually driving business

15:44.800 --> 15:53.200
value into your core business? And what's an example of how you might walk back from, hey, I want

15:53.200 --> 16:01.760
to apply this to call center to a specific kind of sequence of of wins and things to test.

16:01.760 --> 16:09.360
If you think about accuracy of being able to translate what a customer is either writing to you

16:09.360 --> 16:17.200
or talking to you, right? That's highly important. And so GPT as an example does a great job

16:17.200 --> 16:24.160
at basic language, right? But if you say are in the financial space or maybe you're an airline,

16:24.160 --> 16:30.080
the vocabulary and types of words that you and your customers will use can be significantly

16:30.080 --> 16:35.360
different. So for different industries and different use cases, there are going to be what we

16:35.360 --> 16:41.520
call sort of custom corpuses or industry specific data sets that are important. So if you're

16:41.520 --> 16:48.160
say working in a call center in a bank and you want to inevitably get some workflows there to help

16:48.160 --> 16:56.800
improve it based on NLP, the first step is let's look at taking the base GPT model and improving

16:56.800 --> 17:03.840
that with custom corpuses that are specific to your industry or specific to your customer install

17:03.840 --> 17:08.960
base, right? So are there standard open source data sets or do you have to curate those data sets

17:08.960 --> 17:16.800
internally? But let's refine the knowledge that the AI model has. So as an example, if you say

17:16.800 --> 17:21.040
end of quarter, does that actually mean the end of a business quarter? Or does that mean the end

17:21.040 --> 17:27.040
of a sporting contest, right? And so those specifics look very different by industry. And so that

17:27.040 --> 17:34.640
would be step one. Let's do some fine tuning on this large NLP model. Then let's gauge accuracy

17:34.640 --> 17:39.840
and how did that improve things? We can do sentiment analysis. We can do text generation. There's

17:39.840 --> 17:45.600
other downstream tasks that we can use to evaluate that and to see, are we making progress?

17:45.600 --> 17:51.520
At some point you get to a, this is a great level of accuracy. I think we can do something with

17:51.520 --> 17:57.440
it. And then you would start to say, okay, let's transition that into adding it into a workflow.

17:57.440 --> 18:02.240
What parts of the workflow can we replace with this? What do we have to enhance as sort of the

18:02.240 --> 18:10.640
next phase? Got it. So it sounds like what I heard there was the first step is kind of transcribing

18:10.640 --> 18:18.720
the conversation and enhancing or enriching the notes that CSR might otherwise take. And then

18:18.720 --> 18:24.640
it's applying kind of these higher level capabilities, sentiment analysis or some predictive thing

18:25.680 --> 18:33.520
to maybe guide them in the conversation or allow you to better assess the success of your

18:33.520 --> 18:42.000
interactions? Exactly, right? So that first step is really to say, is the data that we're using

18:42.560 --> 18:47.840
and trained on capable of giving us the accuracy in our interactions that we want?

18:47.840 --> 18:53.840
And then when you get to a level that says, yeah, it can, you know, this AI model is not just

18:53.840 --> 19:00.160
generic to the English language, but it really understands commercial banking or it really understands

19:00.160 --> 19:06.640
capital markets to very different things, right? Then we can say, how do you apply that in workflows?

19:07.120 --> 19:11.040
And for each of those areas, they're going to have different workflows, right?

19:11.040 --> 19:16.640
Community banking certainly has a call center aspect to it. Capital markets may not. And so

19:16.640 --> 19:21.920
then you would take to the specific use cases and how to apply that. Got it. Got it. So as opposed

19:21.920 --> 19:30.960
to jumping to, you know, something in the workflow, start by, say, start by assessing whether

19:31.760 --> 19:40.640
the model can even be used in the context of your industry, either off the shelf or after fine

19:40.640 --> 19:46.880
tuning with whatever data you can access. Got it. Makes sense. Yeah. And I would say that the model

19:46.880 --> 19:54.000
is wonderful and can be applied across multiple industries. What we do at Samba Nova is pre-trained

19:54.000 --> 20:00.080
and optimize it for the English language on open data sets. And that is a hard chunk of work

20:00.080 --> 20:05.680
that not a lot of people can do across the world, right? So we're able to do that and we're able to

20:05.680 --> 20:12.560
get customers up and running quite quickly. But that stage of industry specification or specific

20:12.560 --> 20:17.440
data is really important so that, especially when you're dealing with customers, you know,

20:17.440 --> 20:21.360
you don't want to get them irritated because it's not giving them the right answer or not

20:21.360 --> 20:28.160
understanding the context. So those differences between industry words or words specific to your

20:28.160 --> 20:34.400
business matter and aren't going to show up in a traditional English language corpus. Or if they

20:34.400 --> 20:38.880
do show up, they're not going to be in the volume that the AI model is going to be able to learn

20:38.880 --> 20:47.520
enough about them. When an organization is trying to use a model like GPT-3 or BERT,

20:49.520 --> 20:55.520
you know, I think that the options that come to mind first are, you know, use GPT-3 as a service

20:55.520 --> 21:03.120
from OpenAI or, you know, pull down a model from hugging face and use that. How does someone know

21:03.120 --> 21:11.040
that they should be calling a seminar? Like, what are the hidden challenges of, you know,

21:11.040 --> 21:17.120
those two approaches or other approaches that maybe you're seeing folks take that folks tend to

21:17.120 --> 21:22.800
run into that impede their progress? The few things that come to mind are, first of all,

21:23.520 --> 21:32.080
finding the resources who can do the type of work at GPT scale. That's a very specific skill set.

21:32.080 --> 21:38.080
Those are hard resources to find, regardless of where you are in the world. And so when we've

21:38.080 --> 21:43.840
talked to customers, I have a customer as an example, in the financial services space, they looked

21:43.840 --> 21:49.360
across at a competitor and said, over the past three years, they've built a team of data scientists

21:49.360 --> 21:55.200
of hundreds, you know, spent millions and millions of dollars investing in hardware and then

21:55.200 --> 22:02.400
spent all that time to work on a solution, we cannot catch up with them, even if we started

22:02.400 --> 22:09.200
investing today. By the time that we get the people, if we can find them, and invest the money,

22:09.840 --> 22:14.400
we will have wasted significant time and they will have leapfrog does even more than today.

22:15.120 --> 22:22.640
So for them, they think about the time it will take to put together what we consider a do-it-yourself

22:22.640 --> 22:28.640
approach on a hardware perspective. There's the money to do that. And then also the people resources

22:28.640 --> 22:33.600
that you need to invest in and that can can do that work both on the hardware side and the software

22:33.600 --> 22:40.560
data science side. And so we are resource constrained to find the right type of people. And so

22:40.560 --> 22:48.080
working with a company like Samba Nova Systems that has the resources and experts who are working

22:48.080 --> 22:55.040
in algorithmic improvements at the cutting edge, at the cusp of research is an advantage that they

22:55.040 --> 23:01.840
can leverage. We have a solution that we bring that we have up and running in a day that customers

23:01.840 --> 23:09.920
can start using a pre-trained GPT model and get going. And so we continue as the life of the service

23:09.920 --> 23:15.440
to optimize that for them and keep abreast of new research and deliver new services and solutions

23:15.440 --> 23:21.280
for them. So by partnering with someone at Samba Nova Systems, they get to leverage our expertise

23:21.280 --> 23:28.080
over a period of time. The do-it-yourself approach is also hard. Even if you have the time to go and

23:28.080 --> 23:35.680
do it, doing something like GPT takes a large scale of equipment because of the constraints of

23:35.680 --> 23:44.240
traditional architectures. And so Samba Nova Systems allows people to basically deploy at a

23:44.240 --> 23:50.160
smaller configuration to start because of some of the enhancements we have in both our hardware

23:50.160 --> 23:56.320
and software and scale up in an optimized way without any change in their environment.

23:57.040 --> 24:02.480
And that's not something that you necessarily get with the off-the-shelf do-it-yourself components.

24:02.480 --> 24:09.680
And so you don't have this option of starting at a reasonable size. You just have to go to this huge

24:09.680 --> 24:17.280
scale. And that's a really big sort of roadblock for a lot of people. Now, to go back to your point,

24:17.280 --> 24:21.680
you say, well, they could go to the cloud and they could go use some of those services.

24:22.880 --> 24:29.280
But at the same time, some of the customers we have have said they've been surprised by some

24:29.280 --> 24:35.280
of the bills that they've received from some of these cloud service providers. Training is not

24:35.280 --> 24:43.280
a cheap endeavor. So compute time is certainly one thing and the network bandwidth of data back

24:43.280 --> 24:51.360
and forth. So while it might be a nice playground to start with, having that as a full-on production

24:51.360 --> 24:56.400
environment becomes a little bit difficult from a financial perspective. And they are starting to

24:56.400 --> 25:03.040
think that maybe some of those workloads should be brought back on-prem. That being said,

25:03.040 --> 25:08.080
we are happy to deploy our solution on-prem with hosting providers or in dedicated cloud

25:08.080 --> 25:15.120
environments for our customers. So we're very flexible. At the same time, we also do have many

25:15.120 --> 25:21.760
customers who have requirements to keep data within their own firewalls, within their own country.

25:21.760 --> 25:28.560
And so there's rules and regulations that play here. So there's lots of reasons I think why

25:28.560 --> 25:36.960
customers may start out looking at things that exist today in the market. But in order to deploy

25:36.960 --> 25:44.000
those in a real environment at production, at scale, I think Sombanova provides a unique advantage

25:44.000 --> 25:53.600
for them. Can you talk a little bit about the process for kind of building the solution

25:53.600 --> 26:05.200
on your end? And I guess to elaborate on that a little bit, the GPT-3 data set, for example,

26:05.200 --> 26:13.280
like OpenAI, Crawl, Reddit, the web, all this stuff, like it's not like a five-remembering

26:13.280 --> 26:17.920
crack. It's not like go to GitHub and download that data set. You have to go crawl that yourself,

26:17.920 --> 26:26.800
right? And there are aspects of the, certainly they publish the paper about the model,

26:27.760 --> 26:32.720
but those papers never really have all of the details about the model. Of course.

26:32.720 --> 26:37.760
Here is what all from a research and development perspective had to go into

26:38.640 --> 26:43.440
essentially replicating what they did and published a lot of, but not all of.

26:43.440 --> 26:52.800
There has been significant time and effort as we've looked at how our transformer models

26:53.440 --> 26:59.120
optimize to run on this new hardware and this new software stack, right? So it's not for us.

27:00.400 --> 27:06.400
It's not only with Dataflow as a service, download an industry standard model and run.

27:06.400 --> 27:12.240
We certainly can do that. Go to HuggingFace, download the model, run it on the platform. That is

27:12.240 --> 27:18.720
a great solution for customers who are interested in our data scale product. But for our Dataflow

27:18.720 --> 27:24.720
is a service product where we are packaging solutions. There's a much larger effort that goes into

27:24.720 --> 27:31.440
play there for the optimizations and enhancements that we put in the stack and for the solution around

27:31.440 --> 27:38.240
it. And I will say whether we're doing work internally or customers are doing work as they look

27:38.240 --> 27:45.280
to additional pre-training and fine-tuning. Data curation is one of the hardest aspects of this.

27:46.400 --> 27:52.160
Data may be available. Is it available in the right format? Do you have access to it? Can you

27:52.160 --> 27:59.840
use it? Different countries have different rules for how it's used. And some countries have more

27:59.840 --> 28:05.520
digitized text content than others. And so the one thing I can say whether it's internal to

28:05.520 --> 28:12.640
Samba Nova or external with our customers. Having the right data set to use is always the first

28:12.640 --> 28:20.240
discussion and always a challenge. As you're out talking to and working with customers, again,

28:20.240 --> 28:29.280
banking finance, but also beyond that, how well do they understand GPT-3 and transformers

28:29.280 --> 28:37.280
and maybe even more interesting, like what's surprising to them about the technology? What is it

28:37.280 --> 28:42.560
that they already kind of get and what is it that? Oh, it just blows their mind. It blows their mind

28:42.560 --> 28:50.160
not necessarily from a performance perspective. But what is it that they find interesting and

28:50.160 --> 28:54.560
counterintuitive, I guess, is what I'm trying to get at? Well, so obviously when you can talk to

28:54.560 --> 28:58.400
customers, there's lots of different personnel that you can be talking to. You can be talking to

28:58.400 --> 29:03.120
the technical people who are data scientists. You can talk to technical people who are more

29:03.840 --> 29:08.240
in the data center and administrators of systems. And you can also talk to business

29:08.880 --> 29:15.280
type users, right? So it all comes down to who you're talking to. If there is an established

29:15.280 --> 29:23.360
team of data scientists and data scientists who work in the area of AI focused on deep neural

29:23.360 --> 29:30.880
networks, I'm doing some clarification here. Then most of those people are abreast and have heard

29:30.880 --> 29:36.400
of Bert and they've heard of GPT. Whether or not they've used it themselves personally or

29:36.400 --> 29:42.800
internally is another question. If you have at customers technical people who are more on the

29:42.800 --> 29:49.200
analytic side and the traditional ML side, it's possible that they don't know much about Bert

29:49.200 --> 29:56.640
or GPT. And this is not a everybody that falls in that category, but there are situations where

29:56.640 --> 30:01.360
just because of the type of data and analytics work that they're doing, they're more focused on

30:01.920 --> 30:06.080
other types of problem solving than deep neural networks with transformers.

30:07.040 --> 30:13.440
The business side users, some of them have certainly same things in the press. I've said

30:13.440 --> 30:19.120
we've gone to talk about GPT and then I saw something about this other model that came out that

30:19.120 --> 30:27.520
's even bigger. The acronym is familiar from a they've heard about it and maybe seen some others

30:27.520 --> 30:33.520
are using it, but maybe the details aren't so well known on the technical side, but they're also

30:33.520 --> 30:39.920
interested in understanding what it can do and how they can take advantage of it. And I think

30:40.800 --> 30:46.560
not everybody has the same understanding of what these large transformer models are capable of

30:46.560 --> 30:52.080
and what they can be applied to, because that information isn't so readily available and shared

30:52.080 --> 30:57.680
at a level that everyone can get a common understanding on. So those are just when I go and talk to

30:57.680 --> 31:04.400
people, the levels of understanding are significantly different based on who we're talking to. A lot

31:04.400 --> 31:14.560
of people don't realize the effort it takes to get to an optimized and running configuration that's

31:14.560 --> 31:25.840
accurate. They underestimate it or they haven't underestimated it from a hardware configuration

31:25.840 --> 31:32.640
side, but having the skill set to be able to implement that is also challenging. So as I think

31:32.640 --> 31:39.280
alluded to earlier, there aren't many people in this world who can actually do an optimized GPT

31:39.280 --> 31:45.360
configuration, right? And so that takes expertise across an entire stack, both hardware and software,

31:46.000 --> 31:52.000
to be able to do that. And so I think that that in and of itself has surprised people when I've

31:52.000 --> 31:58.160
gone and talked to them. The other thing that's surprising, you know, and this is just, it's

31:58.160 --> 32:03.840
back to the value of Samba Nova systems is, you know, they're shocked that we can wheel in a

32:03.840 --> 32:09.120
service that within a day they can be using and it's already pre-trained and optimized for them.

32:09.120 --> 32:14.880
Right? And we can scale it from one rack to many racks. And for us, it doesn't really matter.

32:14.880 --> 32:21.200
And so for them that catches them by surprise because this is a hard problem. And so seeing that,

32:21.200 --> 32:26.880
you know, actually in practice is, you know, we get a lot of, wow, you said it, I don't think we

32:26.880 --> 32:33.200
believed you and you actually delivered and it's amazing. One of the issues that I think we're

32:33.200 --> 32:40.960
still trying to wrap our hands around as an industry with language models is, you know,

32:40.960 --> 32:49.040
predictability, controllability, governance, that kind of thing. Lots of examples of, you know,

32:49.040 --> 32:55.600
language models gone wrong. We don't need to, you know, repeat those. How are the folks that

32:55.600 --> 33:01.040
you're working with addressing those kinds of issues? So certainly they come up, right? As far as

33:01.040 --> 33:05.920
discussion points, right? And what should we be doing that about them? And so this comes back to,

33:05.920 --> 33:11.600
I think, a few things. Certainly it comes back to the data set, right? The information that the AI

33:11.600 --> 33:16.800
model learns is only as good as the data set that it's trained on, right? So what is the right

33:16.800 --> 33:24.000
data set to get you to an accuracy level that makes sense for your business? And so it's not only

33:24.000 --> 33:30.800
about the data set, but then how are you going to measure and test that? You are actually within

33:30.800 --> 33:36.240
the bounds that make sense for you. And that's not something necessarily that Samba Nova system can

33:36.240 --> 33:40.720
guide customers on because it's going to be specific to their business and specific to their

33:40.720 --> 33:45.680
industry, but we're happy to work with them and talk to them about some of these steps that we

33:45.680 --> 33:51.440
think are crucial for them to go through in order to make sure when things are deployed,

33:51.440 --> 33:56.320
it's doing what is expected, right? And if things aren't doing what they're expected, you want to

33:56.320 --> 34:01.920
catch them early before you've gone live and you want to understand how are you going to

34:01.920 --> 34:08.240
remediate that problem and ensure it doesn't happen again, right? So there is a life cycle around this.

34:08.240 --> 34:15.280
You hope to do most of it in the early phases of an implementation and really refine what you're

34:15.280 --> 34:21.120
working on so you know what the answers are going to be and how to address them. And then if you

34:21.120 --> 34:26.160
are in a production environment, if something does happen, how quickly can you respond to it

34:26.160 --> 34:30.160
and remediate things and fix things so they don't continue to happen moving forward?

34:30.160 --> 34:38.800
Can you talk through the data collection aspect of that with maybe some use case examples given

34:38.800 --> 34:44.080
a particular problem, you know, where folks collecting the data, what do they have to do with it

34:44.080 --> 34:53.520
in order to make use of it for fine-tuning? Yeah, so I think, you know, some of it is with data

34:53.520 --> 35:02.720
sanitization. So when you think about GPT models as an example or BERT, trained in pre-trained

35:02.720 --> 35:09.600
in English, we're all using sort of open standard corpses, right? So how sanitized are those,

35:09.600 --> 35:14.880
is there bias in them? You know, all the questions that you would you would think to ask people

35:14.880 --> 35:22.080
should be asking. And so as you start to curate additional data sets to do pre-training and fine-tuning,

35:22.880 --> 35:28.640
making sure, you know, it's you have to trust the source of the data. Is it external data?

35:28.640 --> 35:33.520
Is it internal data? If it's internal data, does it need to be cleansed first of sensitive

35:33.520 --> 35:40.480
information that you shouldn't be putting into an AI model? But then also, you know, you need a

35:40.480 --> 35:48.000
team of data experts who are familiar with how to produce data corpuses. And this is it's

35:48.000 --> 35:53.040
own practice in its own industry, right? And not necessarily my expertise, but it's certainly

35:53.920 --> 35:59.120
a focus where our customers are spending a lot of time. So they get the data set right.

35:59.120 --> 36:05.040
And it's not like you have to do it right in one shot. You can start and continually enhance it

36:05.040 --> 36:11.440
over time by doing additional pre-training and fine-tuning. So that allows you to start the hit

36:11.440 --> 36:18.720
some early milestones and deliver a continually improving solution. You mentioned measurement

36:18.720 --> 36:24.640
and testing with regard to these data sets. What exactly does that mean in this context?

36:24.640 --> 36:30.640
Well, so I think, you know, we have ways of, so take sentiment analysis as an example.

36:31.440 --> 36:38.000
I'm a finance customer. I have a GPT model. We'll go back to my end-of-quarter analysis, right?

36:39.040 --> 36:46.320
Is that a positive or is that a negative statement, right? So let's say, you know, the

36:46.320 --> 36:52.960
Bank of America here in the US ended up ended their quarter, you know, up $10 per share or something.

36:52.960 --> 36:59.200
Okay, so that is a positive statement. So from a sentiment analysis perspective, right? So it

36:59.200 --> 37:04.400
would have pre-trained, it would have done that, and then you would have some sanity. You need to

37:04.400 --> 37:12.080
check, right? Are is the analysis that the AI model doing correct or incorrect? When you start to

37:12.080 --> 37:18.240
do things that are very specific to finance and start talking about, maybe it's talking about

37:18.240 --> 37:24.640
puts or calls or things related to the stock market, it may not be able to discern that. And in

37:24.640 --> 37:29.440
fact, we've seen cases, I don't have one in front of me where, you know, models like Bert large

37:29.440 --> 37:36.080
or maybe GPT will classify something as negative or neutral when it's really positive. And so you

37:36.080 --> 37:44.080
need to be able to flag the incorrect assessments and figure out a way to refine the data that you're

37:44.080 --> 37:50.000
training on to get rid of those so that you're more accurate than not, right? So first of all,

37:50.000 --> 37:55.840
you want to start judging accuracy of your data set, but you also need to come in and actually check

37:55.840 --> 38:00.400
is your accuracy what you think it is or you falsely identifying things, right? And so

38:01.840 --> 38:07.040
two aspects to that. So a lot of what has driven the excitement around

38:07.040 --> 38:18.960
Bert and Transformers generally is that unlike kind of prior models in NLP and you know the way we

38:18.960 --> 38:24.240
think about much of machine learning in general, like you haven't needed these labeled data sets,

38:24.240 --> 38:30.160
like you it's you're kind of letting your training on unlabeled data.

38:30.160 --> 38:37.680
Yeah, it sounds like for these measurement and tests requirements, though, you would need

38:37.680 --> 38:44.320
some kind of labeled data set in order to do benchmarking. Is that the case and does that?

38:45.840 --> 38:50.240
Yeah, I'm not, though, so we're not necessarily using labeled data with our customers. I think

38:50.240 --> 38:57.200
there's just a, you know, when you think about deploying some of these solutions and people question

38:57.200 --> 39:03.600
is AI correct and is it, you know, do you get the same answer every time? There's care that goes

39:03.600 --> 39:09.520
into the creation of the data set, even if it's not labeled, right? So thoughts around that.

39:10.320 --> 39:14.960
And then, you know, I don't necessarily think you need to label everything, but there does need to

39:14.960 --> 39:21.040
be some checking and some test put in place to verify, right? And so maybe that's that spot checking

39:21.040 --> 39:26.480
or other things, right? So I don't think you need to go to the everything must be labeled.

39:26.480 --> 39:31.760
We know that's not going to be a scalable solution, but when you think about, you know,

39:31.760 --> 39:36.560
big name brands deploying these solutions in front of their customers or using it to make

39:36.560 --> 39:42.320
business decisions, you do want to put some ways to at least assess how things are looking.

39:42.960 --> 39:47.440
So you understand, you know, are you accurate or not and doesn't make sense to push forward?

39:48.480 --> 39:53.040
Yeah, yeah, that's that's kind of the question that I had and what I was getting at are folks

39:53.040 --> 40:02.160
spot checking and getting a general feel that this looks about right or are folks setting aside,

40:02.880 --> 40:09.840
you know, some labeled test set or validation set that they then, you know, for sentiment,

40:09.840 --> 40:17.760
let's say, run against their model and, you know, produce numerical reports against.

40:17.760 --> 40:22.960
And then how much of that, how hard is that effort, how well prepared are they to go through those

40:22.960 --> 40:27.440
efforts? Yeah, so I think, you know, in the conversations I've been with customers,

40:27.440 --> 40:32.800
you see sort of a little bit of both and questioning about what is the right way. And I'm not sure

40:32.800 --> 40:38.800
that there is a well, you know, people are still debating the approaches here of what should be

40:38.800 --> 40:43.360
taken. You know, obviously we know there when you create a curated data set and everything needs

40:43.360 --> 40:48.640
to be labeled, there's additional challenges there, right? So, but at the same time, people want

40:48.640 --> 40:54.400
some confidence. And so it's a where that will fall might depend on the customer and the industry,

40:54.400 --> 40:59.200
but I will say it's a discussion point. And I'm not sure that the answer, you know, industry best

40:59.200 --> 41:05.120
practice is well known at this point. Got it. And you also mentioned kind of these guard rails that

41:05.120 --> 41:12.560
folks will put up in place to ensure that when slash if a model has a problem, they can avoid

41:12.560 --> 41:18.000
that problem in the future. Can you talk a little bit about the approaches that you've seen for

41:18.000 --> 41:23.280
doing that? Yeah, so I mean, I think it's mainly about, it goes back to the process I've talked about

41:23.280 --> 41:29.440
where there's some initial training that's done, you do more pre-training or fine-tuning,

41:29.440 --> 41:35.840
you try your downstream tasks. At some point, you know, things are looking good, it's deployed,

41:35.840 --> 41:46.240
you know, but data changes things, things morph over time. And so as you think about deploying

41:46.240 --> 41:51.520
these into environments where they're more in production and less in test, you need to be

41:51.520 --> 41:57.040
constantly staying abreast and looking at are there things that I need to retrain? Do I need to

41:57.040 --> 42:02.320
bring additional data in? Do I need to, does the model need to be changed? That could potentially

42:02.320 --> 42:08.880
happen as well, right? And so how are you monitoring for that and the end-to-end lifecycle of things?

42:08.880 --> 42:14.960
It's not, I don't think it will forever be a, we've trained it and deployed it, you know,

42:14.960 --> 42:21.280
how people speak, what's acceptable or not acceptable, common vernacular, those things change

42:21.280 --> 42:26.400
over time. And so how do you keep up with those changes and incorporate them into a pipeline that

42:26.400 --> 42:33.760
get deployed is critical? We spoke a little bit earlier about what your customers find surprising

42:33.760 --> 42:39.680
as they're working with these models. To close out, I'm curious, what have you found surprising

42:39.680 --> 42:47.760
personally as you started to work more closely with DPT and Burton Transformers? Yeah, so, you know,

42:47.760 --> 42:52.000
I think, well, and maybe this is more of an AI thing in mind. When I, when I first joined

42:52.000 --> 42:57.840
sambanova, I certainly felt that this was a transformational technology. But now that I'm three

42:57.840 --> 43:04.960
years in, I'm looking at use cases with customers, we're exploring a variety of areas. I really

43:04.960 --> 43:15.200
understand that this is going to be a very transformative shift in technology and it's going to

43:15.200 --> 43:21.280
affect all industries, right? You can see it applied in so many different ways. And when I think

43:21.280 --> 43:26.720
about my lifetime, there's been very few of these moments. You think maybe of the internet

43:26.720 --> 43:34.240
boom and sort of the mobile phone. And I really think AI has the ability to be that transformational

43:34.240 --> 43:40.160
shift of this next generation. And so for me, I think that's the exciting part. I knew it was the

43:40.160 --> 43:45.120
new technology and there was lots of things to do. But I don't think when I started my journey

43:45.120 --> 43:52.560
at sambanova, I quite understood how impactful it could be across everybody's lives. Yeah, awesome,

43:52.560 --> 43:58.880
awesome. Well, Jennifer, thanks so much for joining us and sharing a bit of your experiences,

43:59.520 --> 44:07.120
deploying GPT3 and related technology out of customers. Thank you so much. It's been a pleasure.

44:07.120 --> 44:15.120
Thank you for having me.

