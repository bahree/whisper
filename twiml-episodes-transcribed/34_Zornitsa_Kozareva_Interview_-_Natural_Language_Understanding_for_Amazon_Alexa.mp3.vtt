WEBVTT

00:00.000 --> 00:16.680
Hello and welcome to another episode of Tumultalk, the podcast where I interview interesting

00:16.680 --> 00:21.520
people doing interesting things in machine learning and artificial intelligence.

00:21.520 --> 00:24.000
I'm your host, Sam Charrington.

00:24.000 --> 00:28.720
I apologize in advance for a longer than usual intro, but we've got a bunch of news and

00:28.720 --> 00:31.420
announcements that we wanted to share this week.

00:31.420 --> 00:35.920
Thanks to everyone that listened to, shared, and commented on last week's show.

00:35.920 --> 00:39.960
Based on your feedback so far, it's pretty clear you're enjoying both the Industrial

00:39.960 --> 00:44.440
AI series as well as our more technical Nerd Alert shows.

00:44.440 --> 00:48.200
I am too, so you'll definitely see more of both.

00:48.200 --> 00:52.600
This week though, we're starting a two week break from the Industrial AI series.

00:52.600 --> 00:57.040
I've got a great show for you today and then next week the week of July 3rd will

00:57.040 --> 01:02.600
be foregoing our usual Friday release and experimenting with a shift to a Monday release

01:02.600 --> 01:05.640
schedule for at least the rest of the summer.

01:05.640 --> 01:09.800
When this podcast drops, I'll be in New York City for the O'Reilly AI conference where

01:09.800 --> 01:14.720
I'll be interviewing speakers like Douglas Eck from Google Brain, Rana Alcaloubi from

01:14.720 --> 01:21.080
Effectiva, Ben Vigota from Gamalon, and Naveen Rao of Intel Nirvana.

01:21.080 --> 01:27.000
Our O'Reilly AI series will be posted on Monday July 10th for your binge listening pleasure.

01:27.000 --> 01:32.040
The following week I'm in Germany, in Hamburg, Berlin, and possibly Munich.

01:32.040 --> 01:35.880
If you're in or near one of those cities and you'd like to connect, definitely give me

01:35.880 --> 01:37.360
a shout out.

01:37.360 --> 01:42.080
As we've mentioned over the past few weeks, we've been planning and now have finalized

01:42.080 --> 01:44.760
our very first Twimmel Happy Hour.

01:44.760 --> 01:48.720
We've partnered with our friends from the NYAI meetup group and we'd love for you to

01:48.720 --> 01:54.280
meet us at Amesworth Midtown and New York City on Thursday, June 29th, starting at 6pm

01:54.280 --> 01:59.920
right after the O'Reilly conference for a few hours of drinks, conversations, and networking.

01:59.920 --> 02:03.800
I'm looking forward to being back in my hometown and sharing a drink with those of you who

02:03.800 --> 02:05.160
can make it.

02:05.160 --> 02:11.560
Make sure to RSVP at twimmelai.com slash NY meetup to let us know you're coming.

02:11.560 --> 02:13.400
And now about today's show.

02:13.400 --> 02:18.600
Our guest this week is Zornizza Kozarva, Manager of Machine Learning with Amazon Web

02:18.600 --> 02:23.120
Services Deep Learning, where she leads a group focused on natural language processing

02:23.120 --> 02:28.680
and dialogue systems for products like Alexa and Lex, the latter of which we discussed

02:28.680 --> 02:30.360
in the podcast.

02:30.360 --> 02:34.160
We spend most of our time talking through the architecture of modern natural language

02:34.160 --> 02:38.800
understanding systems, including the role of deep learning, and some of the various ways

02:38.800 --> 02:43.720
folks are working to overcome the challenges in the field, such as understanding human

02:43.720 --> 02:45.120
intent.

02:45.120 --> 02:49.600
If you're interested in this field, she mentions the AWS chatbot challenge, which you've

02:49.600 --> 02:55.080
still got a couple more weeks to participate in, of course, a link will be in the show notes,

02:55.080 --> 02:59.560
which will be posted at twimmelai.com slash talk slash 30.

02:59.560 --> 03:03.600
I had a ton of fun chatting with Zornizza and learned a bunch, and we couldn't wait

03:03.600 --> 03:05.800
to share this conversation with you.

03:05.800 --> 03:06.800
Enjoy.

03:06.800 --> 03:19.520
All right, everyone, I am on the line with Zornizza Kozarva, Zornizza is a manager with

03:19.520 --> 03:25.440
AWS deep learning, and we are going to be talking about deep learning and natural language

03:25.440 --> 03:26.440
understanding.

03:26.440 --> 03:29.240
And I'm super excited to have her on the line.

03:29.240 --> 03:30.240
How are you Zornizza?

03:30.240 --> 03:35.800
Likewise, thank you Sam, it's a great pleasure to be here and to be part of the show.

03:35.800 --> 03:38.040
I'm doing really well.

03:38.040 --> 03:39.040
Awesome, awesome.

03:39.040 --> 03:42.440
Well, why don't we get started by having you tell us a little bit about your background

03:42.440 --> 03:45.680
and how you got to where you are?

03:45.680 --> 03:52.680
Yes, so currently I'm a manager of the AWS deep learning group at Amazon that focuses

03:52.680 --> 03:56.360
on natural language processing and dialogue systems.

03:56.360 --> 04:02.000
My background and PhDs are in the field of natural language processing, which focuses

04:02.000 --> 04:06.320
on doing systems that understand what humans mean.

04:06.320 --> 04:11.360
For a couple of years, I wore an academic hat at the University of South and California.

04:11.360 --> 04:15.640
I was an assistant professor there for the computer science department, and I focused

04:15.640 --> 04:20.120
on different types of research funded by DARPA and IRPA.

04:20.120 --> 04:25.160
And after that, I moved to industry where I decided to tackle the same challenges, but

04:25.160 --> 04:30.800
at a much larger scale and with a bigger impact to humans and society.

04:30.800 --> 04:37.360
Hmm, do you currently do research or are you primarily focused on product oriented work?

04:37.360 --> 04:42.760
I'm focused on both, like we do a lot of product development inside the Amazon, but

04:42.760 --> 04:48.040
at the same time, I'm making sure that I continue participating and serving the scientific

04:48.040 --> 04:49.040
community.

04:49.040 --> 04:54.400
We do have scientific work as well as I regularly serve on the program committees and

04:54.400 --> 04:55.400
I'm an area chair.

04:55.400 --> 05:00.840
So I'm trying to do both, but at work, definitely the focus is on building products.

05:00.840 --> 05:01.840
Got it.

05:01.840 --> 05:02.840
Got it.

05:02.840 --> 05:06.640
You're currently working on the deep learning and natural language understanding systems

05:06.640 --> 05:10.840
that power Amazon Alexa and Amazon Lex.

05:10.840 --> 05:13.440
I'm pretty sure everyone knows what Amazon Alexa is.

05:13.440 --> 05:18.200
We've talked about it a bunch of times here on the show, and in fact, I demonstrated a

05:18.200 --> 05:21.480
few times how to access the show on Alexa.

05:21.480 --> 05:26.240
So folks are familiar with that, but I'm not sure everyone knows what Amazon Lex is.

05:26.240 --> 05:29.800
So can you maybe give us a high level overview of that service?

05:29.800 --> 05:32.480
It was just announced last year at ReInvent, right?

05:32.480 --> 05:34.120
That is absolutely right.

05:34.120 --> 05:38.800
Well, let me walk you through like how we ended up with Amazon Lex.

05:38.800 --> 05:44.280
So if you think about it, we live in the artificial intelligence era, and we see the development

05:44.280 --> 05:48.320
of very smart systems from self-driving cars to Internet of things.

05:48.320 --> 05:53.360
But at the core, since this conversation was system, that enabled the communications

05:53.360 --> 05:55.920
between machines and humans.

05:55.920 --> 06:00.840
And it has been a dream for developers and for sciences in general to be able to build

06:00.840 --> 06:02.320
such assistance.

06:02.320 --> 06:07.480
But if you take any developer and they have to build such kind of a system, it requires

06:07.480 --> 06:12.440
them to know a lot about natural language understanding and speech recognition, which

06:12.440 --> 06:13.440
are very tough.

06:13.440 --> 06:17.400
And you either should have like a PhD or should have spent significant amount in these

06:17.400 --> 06:18.400
areas.

06:18.400 --> 06:23.360
Developer had to worry about how do I build systems that are really scalable, how do I

06:23.360 --> 06:29.480
enable testing and make sure that my bots are going to be working what the users need,

06:29.480 --> 06:34.400
how to do authentication, how to integrate the business logic, and all of these challenges

06:34.400 --> 06:40.880
were kind of blocking the development at a faster space of all these applications.

06:40.880 --> 06:47.040
So we introduce Amazon Lex, which is a new service for building conversation interfaces

06:47.040 --> 06:50.680
for your apps using voice and text.

06:50.680 --> 06:53.600
And there are multiple benefits to that.

06:53.600 --> 06:56.400
One is like Amazon Lex is very easy to use.

06:56.400 --> 06:58.200
It's built for developers.

06:58.200 --> 07:02.600
And we at Amazon do all the heavy lifting in terms of the infrastructure we take care

07:02.600 --> 07:03.840
of the models.

07:03.840 --> 07:08.680
And the developer just has to focus on what is their customer use case and how they want

07:08.680 --> 07:10.560
these applications to look.

07:10.560 --> 07:15.600
The best part is like we have very high quality text and speech language understanding.

07:15.600 --> 07:20.160
And they are powered by the same deep learning technology as Alexa.

07:20.160 --> 07:24.360
So that's why we have the short legs, it's short for Alexa.

07:24.360 --> 07:30.040
The good part is also that any developer can seamlessly deploy and scale.

07:30.040 --> 07:35.560
If you build your application, for example, for specific platform, like let's say, Facebook

07:35.560 --> 07:40.240
Messenger, you can very easily port it to many other platforms and you don't have to worry

07:40.240 --> 07:41.480
about that.

07:41.480 --> 07:46.000
And at the same time, we have like AWS mobile hub integration that allows you to do many

07:46.000 --> 07:51.680
things like simple, nice data, analyze user behavior, track retention, integrate your

07:51.680 --> 07:53.840
bot and so many, many things.

07:53.840 --> 08:00.000
So this new service Amazon Lex allows people to focus on what matters to them and literally

08:00.000 --> 08:06.160
like so of a particular user need, whether it's booking a hotel or it's opening a bank

08:06.160 --> 08:07.160
account.

08:07.160 --> 08:11.800
And the most exciting part is like we're organizing a challenge right now.

08:11.800 --> 08:14.640
We started in April and it will end in July.

08:14.640 --> 08:18.800
So those folks that are really passionate and want to build their bots, I encourage them

08:18.800 --> 08:22.920
to have a look at our web page and just register for the challenge.

08:22.920 --> 08:29.320
Oh, is that some kind of is it like a prize for the best Amazon Lex app or something?

08:29.320 --> 08:33.720
Yeah, there are different rewards, there's the monetary rewards, there's the AWS credits

08:33.720 --> 08:38.000
and also folks can come to reinvent 2017, there will be ticket.

08:38.000 --> 08:44.120
And as I say, the focus is like build a chatbot that engages users and at the same time fulfills

08:44.120 --> 08:49.280
a specific need that you have like booking a hotel or any other thing that you might

08:49.280 --> 08:50.280
have in mind.

08:50.280 --> 08:51.280
Okay.

08:51.280 --> 08:52.280
Nice.

08:52.280 --> 08:57.520
So with that in mind, let's maybe talk about what are some of the biggest challenges

08:57.520 --> 09:01.600
in working on systems like this, like what are you currently researching?

09:01.600 --> 09:08.080
Well, my focus is in natural language processing and the most hard part is to build systems

09:08.080 --> 09:11.840
that actually understand what the humans mean.

09:11.840 --> 09:18.160
This involves like can we understand what intense people have in mind, can we identify the

09:18.160 --> 09:22.680
slots that enable us and understand how these intense should be fulfilled.

09:22.680 --> 09:26.320
And for most people that haven't worked in this area, it sounds like oh, that's pretty

09:26.320 --> 09:32.080
straightforward, but actually language is very ambiguous and very, very hard to understand.

09:32.080 --> 09:37.480
If we deal with very explicit intents, let's say cancel travel to Miami, I just literally

09:37.480 --> 09:44.360
said every single thing that I'm planning to do, cancel with my intent and Miami is my destination.

09:44.360 --> 09:48.200
But imagine I'm chatting with someone and they're asking me, are you coming to the board

09:48.200 --> 09:49.200
a party?

09:49.200 --> 09:51.960
And I suddenly say, I'm on my way.

09:51.960 --> 09:56.480
If the conversational system pops in and says, hey, Zornica, should I send an Uber your

09:56.480 --> 09:57.480
way?

09:57.480 --> 09:58.480
That's amazing.

09:58.480 --> 10:00.880
So, building such applications is really hard.

10:00.880 --> 10:07.040
It requires a system to understand implicit intents, which are very hard to detect.

10:07.040 --> 10:11.200
It requires the system to know what your user preferences are.

10:11.200 --> 10:14.320
Maybe I'm using specific means of transportation.

10:14.320 --> 10:16.440
The system has learned it over time.

10:16.440 --> 10:19.440
And it's making automatically the recommendation.

10:19.440 --> 10:25.240
And the ability to generate such kind of replies automatically instead of using templates

10:25.240 --> 10:30.080
that are already pre-specified, these are all very, very complex problems that are open

10:30.080 --> 10:31.080
ended.

10:31.080 --> 10:35.880
And we are continuing to invest both in terms of sciences as well as in industry.

10:35.880 --> 10:40.880
How do you solve and make systems being able to handle all this complexity?

10:40.880 --> 10:41.880
Hmm.

10:41.880 --> 10:49.360
So maybe what's a specific area that you've been focusing on there in terms of your research?

10:49.360 --> 10:54.920
My research focuses on building this natural language understanding capability.

10:54.920 --> 11:00.680
Anyone, anytime an utterance that comes in, we focus on extracting those slots to fill

11:00.680 --> 11:06.240
in that template as well as understanding what these intents are, such that when you pass

11:06.240 --> 11:12.240
that information to a dialogue manager or a component that communicates with the backends,

11:12.240 --> 11:18.680
we understand like what the human meant and the more correctly you extract such information

11:18.680 --> 11:24.280
and the most accurately you populate it in these specific templates, then the better your

11:24.280 --> 11:25.600
system will be.

11:25.600 --> 11:30.040
And humans don't have to repeat the same question over and over again.

11:30.040 --> 11:31.600
You mentioned a dialogue manager.

11:31.600 --> 11:38.200
Did these systems have standard components, independent of the implementation to all of

11:38.200 --> 11:43.120
these systems have dialogue managers and what is the general architecture of these types

11:43.120 --> 11:44.120
of systems?

11:44.120 --> 11:46.520
Yeah, that's an excellent question.

11:46.520 --> 11:50.840
While a conversational assistant can live in different shapes and forms like either on

11:50.840 --> 11:56.920
your phone or in your home device, even in your car, the common part is like they have

11:56.920 --> 12:03.320
very standard, like processing blocks, input is like either speech or text.

12:03.320 --> 12:08.360
And the first component that gets hit is the so-called natural language understanding component.

12:08.360 --> 12:13.960
That is the piece that focuses on understanding the intents and the slots of the users.

12:13.960 --> 12:19.200
Once that information is extracted, it gets passed to the dialogue manager.

12:19.200 --> 12:24.520
The task is to take these pieces of information, send them to the backends and a backend

12:24.520 --> 12:25.520
think about it.

12:25.520 --> 12:28.080
If you want to book, let's say, a flight.

12:28.080 --> 12:30.800
Maybe I just say book me a flight to Miami.

12:30.800 --> 12:34.960
Once extracted the Miami term and you pass it to the dialogue manager, it communicates

12:34.960 --> 12:37.440
to the backend, let's say your favorite travel website.

12:37.440 --> 12:41.720
And it says, well, now I need to know what date you will be traveling, do you have any

12:41.720 --> 12:45.920
price restrictions, do you want it to be like a direct flight or not?

12:45.920 --> 12:50.160
It sends back all this information to the dialogue manager says, hey, I need to have all

12:50.160 --> 12:52.040
this information filled.

12:52.040 --> 12:56.640
The dialogue manager passes the slots and then they hit a natural language generation

12:56.640 --> 13:01.800
component that says back to the user, hey, can you tell me like, do you want a direct flight

13:01.800 --> 13:04.720
and do you have any price constraints?

13:04.720 --> 13:08.000
That output could be both text or it could be speech.

13:08.000 --> 13:11.600
It gets sends back to the user and then the user says, well, actually, I don't have

13:11.600 --> 13:12.600
any constraints.

13:12.600 --> 13:15.080
Find me, let's say, the cheapest flight.

13:15.080 --> 13:19.560
So this loop, constant loop between these three components, natural language understanding,

13:19.560 --> 13:24.120
dialogue manager, natural language generation is what drives the whole conversation between

13:24.120 --> 13:26.120
a system and a human.

13:26.120 --> 13:30.800
How you implement them, it depends on you as a policy developer.

13:30.800 --> 13:33.760
How you decide what models to include.

13:33.760 --> 13:37.920
But on the high level, these are kind of like the three building blocks that act like

13:37.920 --> 13:40.600
everyone has to focus us on building.

13:40.600 --> 13:41.600
Okay.

13:41.600 --> 13:42.600
Okay.

13:42.600 --> 13:49.000
And then even within the NLU component there, we can even break that down further.

13:49.000 --> 13:57.000
I know or I recall that the Google a while ago, I guess, around a year ago announced like

13:57.000 --> 14:00.840
an open source parser, their parsing MacPars face rule.

14:00.840 --> 14:05.720
And that's just one of the different pieces of the NLU component itself.

14:05.720 --> 14:08.080
Like what does that part look like?

14:08.080 --> 14:13.520
Well, think about it that the natural language understanding components there, as I said,

14:13.520 --> 14:16.040
they're different and depends what your need is.

14:16.040 --> 14:17.040
Okay.

14:17.040 --> 14:21.200
And the tools that you quoted, they're kind of like a high level dependency parser or

14:21.200 --> 14:22.440
just a parser.

14:22.440 --> 14:27.640
You can use that information to facilitate how to build this kind of natural language understanding

14:27.640 --> 14:28.960
components.

14:28.960 --> 14:34.520
But at the core, it's like you have to think about how to define your slots or how do

14:34.520 --> 14:39.040
you define your semantics, how do you define the space over which your system will operate

14:39.040 --> 14:42.280
and would semantically understand what a human means.

14:42.280 --> 14:47.520
And these things typically are called slots, they're the entities and semantic bits of information.

14:47.520 --> 14:50.400
That capture what our request is.

14:50.400 --> 14:52.160
You can build them from scratch.

14:52.160 --> 14:56.560
You just need to know like what are the right machine learning models for that.

14:56.560 --> 15:01.800
Or if you want, as I say in Amazon Lex, we have like pre-built capabilities such that

15:01.800 --> 15:04.880
people can just choose from a drop-down menu.

15:04.880 --> 15:09.920
So that enables like a person who knows nothing about machine learning to be able to build

15:09.920 --> 15:10.920
them.

15:10.920 --> 15:16.120
For anyone that is from natural language crossing field and has dealt and worked in semantics

15:16.120 --> 15:21.920
and information extraction, it is much easier for people with such kind of skill set to

15:21.920 --> 15:26.800
be able to build their component from scratch and to know how to define these semantics

15:26.800 --> 15:33.920
or how to define the space that the machine learning system should operate over and make predictions.

15:33.920 --> 15:36.520
And how do you characterize that space?

15:36.520 --> 15:41.760
You know, you're starting with typically some audio waveform, like what's the process

15:41.760 --> 15:48.480
for getting that into some parsed set of slots that you can then operate on further

15:48.480 --> 15:50.000
back in the system.

15:50.000 --> 15:51.000
Uh-huh, yeah.

15:51.000 --> 15:56.720
Once you have the speech, as I said, the input could be both speech that you transfer from

15:56.720 --> 15:59.840
speech to text or it could be the text itself.

15:59.840 --> 16:02.000
Think about it like a text messaging.

16:02.000 --> 16:07.000
Once you have that text in, what you do is like you have to make the design of what the

16:07.000 --> 16:08.680
intents and the slots are.

16:08.680 --> 16:12.840
And I know sometimes people come and ask me, well, where do these intents and slots come

16:12.840 --> 16:13.840
from?

16:13.840 --> 16:16.280
And the answer is they're the designer's choice.

16:16.280 --> 16:20.280
You can take them from an existing large ontology, just pick the pieces that you care

16:20.280 --> 16:21.280
about.

16:21.280 --> 16:24.720
Let's say in travel, you might care about cities and countries and so on.

16:24.720 --> 16:29.560
You can automatically learn them from a lot of unlabeled text or you can even manually

16:29.560 --> 16:30.560
create them.

16:30.560 --> 16:33.600
So how do these slots look like?

16:33.600 --> 16:35.720
Let's say we're building a shopping bot.

16:35.720 --> 16:40.640
Then we can decide that our slots are the things that are most important, products and vendors

16:40.640 --> 16:44.000
and brands and models and product families.

16:44.000 --> 16:48.960
And the intents or which are the actions on top of which we can do operations are buying

16:48.960 --> 16:52.600
them, selling them, recommending them, tracking them.

16:52.600 --> 16:57.840
What we do is like we formulate this type of problems as a sequence prediction.

16:57.840 --> 17:02.240
Like if I give you these categories, the products and the brands and I give you some text of

17:02.240 --> 17:09.040
length M, like can you find segments inside the text that can be labeled with these specific

17:09.040 --> 17:10.520
categories?

17:10.520 --> 17:15.880
And the moment you do that and you're having this rich representation that you're caring

17:15.880 --> 17:20.840
about and that your dialogue system can ingest and actually build on top of.

17:20.840 --> 17:26.000
So you have to annotate your data in the correct way, meaning if I say purchase added

17:26.000 --> 17:33.840
as rules, quick to and Nike Pegasus, each word or how's it segments of words, they get

17:33.840 --> 17:36.520
tacked with this specific information.

17:36.520 --> 17:41.160
And then the machines just ingest it such that they can build prediction models on top

17:41.160 --> 17:42.240
of that.

17:42.240 --> 17:45.000
And that's one way you can do it.

17:45.000 --> 17:46.000
Yeah.

17:46.000 --> 17:47.000
Okay.

17:47.000 --> 17:54.880
So one thing I'm inferring from your description is that you consider or it's generally

17:54.880 --> 18:03.440
considered that the speech recognition component of, you know, a broader system like Lex and

18:03.440 --> 18:08.840
the NLU component of a broader system like, you know, system are like two different things.

18:08.840 --> 18:10.640
Is that the way you tend to think of it?

18:10.640 --> 18:18.200
Like this, you're getting speech that's already, you know, turned from audio signals to some

18:18.200 --> 18:21.240
set of symbols, whether that's, you know, language or something else.

18:21.240 --> 18:24.040
And then that's what you're working to understand.

18:24.040 --> 18:25.040
Is that right?

18:25.040 --> 18:26.040
That is correct.

18:26.040 --> 18:27.040
Yes.

18:27.040 --> 18:31.120
You think of them like different building blocks that you need to piece together in the

18:31.120 --> 18:35.840
right way, such that you can do the complex system that is going to be able to drive

18:35.840 --> 18:36.840
this dialogue.

18:36.840 --> 18:41.720
So in my case, I just focus on the natural language processing component.

18:41.720 --> 18:44.080
And we have amazing colleagues that do the same thing.

18:44.080 --> 18:50.520
They focus on speech or they focus on generating from speech to text, yes.

18:50.520 --> 18:56.880
So when you were talking about the intense and the slots and looking at that problem as

18:56.880 --> 19:03.880
predicting a sequence that makes me think of deep learning models like LSTMs, do those

19:03.880 --> 19:10.240
would come into play there, talk about the impact of deep learning on all this.

19:10.240 --> 19:11.240
Yes.

19:11.240 --> 19:12.240
Absolutely.

19:12.240 --> 19:18.240
You have very good intuition and LSTMs are very useful in solving such type of a problem.

19:18.240 --> 19:20.840
It's a structure prediction problem.

19:20.840 --> 19:26.800
And as I say, until recently, people used to employ a lot of the traditional supervised

19:26.800 --> 19:27.800
learning.

19:27.800 --> 19:33.920
They picked their favorite algorithm being a CRF dagger or being like learning to search

19:33.920 --> 19:34.920
algorithm.

19:34.920 --> 19:40.640
And most of the focus was on how to do feature engineering and find what are the right

19:40.640 --> 19:44.280
features and how do we iterate over those features.

19:44.280 --> 19:51.040
But now with the big wave of deep learning, we see that one can build such kind of systems.

19:51.040 --> 19:55.120
If you're an expert in the field, one can do them much faster in terms of like picking

19:55.120 --> 20:00.760
the right algorithm, you can train your word embeddings on a much larger, unlabeled data

20:00.760 --> 20:05.040
and also get much more powerful results.

20:05.040 --> 20:09.360
So LSTM is great for solving this kind of structure prediction problem.

20:09.360 --> 20:14.120
And typically we see very good results if you have the last layer with conditional random

20:14.120 --> 20:15.720
fields.

20:15.720 --> 20:16.800
Can you elaborate on that?

20:16.800 --> 20:18.960
What are conditional random fields?

20:18.960 --> 20:21.080
Yes, it's very, very standard.

20:21.080 --> 20:23.560
They're like discriminative classifiers.

20:23.560 --> 20:28.600
It's very, very standard built for many decades and using this kind of task.

20:28.600 --> 20:33.360
Their use, as I say, for sequence prediction, can encode relationships between the observed

20:33.360 --> 20:40.120
data, like typically the current and the previous word, does not model long-range dependencies.

20:40.120 --> 20:45.600
While in the LSTM, you have these deep learning models, which are more powerful, as I said,

20:45.600 --> 20:49.240
they can learn powerful representation given enough data.

20:49.240 --> 20:53.360
They can capture the long-term dependencies, not only in a sentence, but even they can

20:53.360 --> 20:56.160
span between sentences and paragraphs.

20:56.160 --> 21:00.480
And as I said, the best part is like you don't have to focus on feature engineering.

21:00.480 --> 21:04.840
You can just pass the raw data as input.

21:04.840 --> 21:13.760
So if you're looking to build a system like this, what are the primary considerations that

21:13.760 --> 21:20.600
you need to think about to architect it correctly and to build a system that meets a specific

21:20.600 --> 21:22.360
set of needs?

21:22.360 --> 21:28.680
I would say if you are familiar with machine learning, if you use these sets of methods or

21:28.680 --> 21:34.160
methods that are appropriate for structure prediction, your problem will be kind of solved.

21:34.160 --> 21:38.200
But the part that one really needs to focus on is the data.

21:38.200 --> 21:44.240
Because the data is going to drive the quality of how your system performs and behaves.

21:44.240 --> 21:48.400
And the semantic representation, this means as like how are these labeled spaces going

21:48.400 --> 21:50.120
to look like?

21:50.120 --> 21:54.760
In terms of like the machine learning algorithm themselves, there's like plenty of open-source

21:54.760 --> 22:01.200
platforms that people can use at Amazon, we have the MXNet platform, which is an open-source

22:01.200 --> 22:03.800
machine learning platform, we have TensorFlow.

22:03.800 --> 22:08.960
People have a wide variety of choosing which machine learning toolbox they can use.

22:08.960 --> 22:11.520
And as I said, that's pretty easy to pick up.

22:11.520 --> 22:15.320
But the hardest part is like if you don't know how to get your data, if you don't know

22:15.320 --> 22:20.840
how to represent it right, then even if you have the best toolbox on earth, you're

22:20.840 --> 22:24.400
only able to build your applications in the right way.

22:24.400 --> 22:29.160
So I encourage people to look at both things, not only at the machine learning side, but

22:29.160 --> 22:33.560
also on the side of like, how do I design my system?

22:33.560 --> 22:34.760
How do I collect the data?

22:34.760 --> 22:38.840
How do I drive all of these processes together?

22:38.840 --> 22:43.360
And you said making sure you represent your data right is one of the big challenges.

22:43.360 --> 22:46.400
What exactly does that mean and what are the considerations there?

22:46.400 --> 22:51.440
Yes, well, as I said, the biggest problem is like semantic understanding of like what

22:51.440 --> 22:56.440
humans mean and how should the computer in cold and understand that.

22:56.440 --> 22:57.440
And that's a challenge.

22:57.440 --> 23:00.040
And it's been a challenge for many years.

23:00.040 --> 23:04.440
There are theories, but yet building such a system that understands us humans is very

23:04.440 --> 23:05.440
challenging.

23:05.440 --> 23:10.920
So we have these basic representations that can, to some extent, work, but that doesn't

23:10.920 --> 23:13.520
mean that really understand what a human means.

23:13.520 --> 23:17.360
It's very hard for the systems to pick up like sarcasm.

23:17.360 --> 23:20.720
How do you take it, represent it and even like model it?

23:20.720 --> 23:24.480
These are much, much harder things we have to account for.

23:24.480 --> 23:29.480
Right now we have these basic, more flatter or slightly more structured representations,

23:29.480 --> 23:32.400
but that's definitely not the way to go forward.

23:32.400 --> 23:35.360
And I'm trying to put that into context.

23:35.360 --> 23:43.120
If I'm thinking through building out a system to understand language and you're advising

23:43.120 --> 23:50.720
me to start with the data collection and representation, I get collection, obviously it's going

23:50.720 --> 23:56.080
to be, or depending on the situation, it may be difficult to collect the data, but assume

23:56.080 --> 24:03.840
that I can collect a bunch of data, say, it's assumed it's in text form from bot requests

24:03.840 --> 24:05.680
or something like that.

24:05.680 --> 24:09.120
The next step you're saying is the representation.

24:09.120 --> 24:15.680
Where does representation come in before I start throwing my data at the machine learning

24:15.680 --> 24:20.960
algorithms and put another way, like part of what I'm expecting or hoping the machine

24:20.960 --> 24:26.760
learning algorithms to do is to kind of parse the data and help me figure out how to represent

24:26.760 --> 24:27.760
it.

24:27.760 --> 24:28.760
Is that right?

24:28.760 --> 24:31.600
Well, there are different ways one can do it.

24:31.600 --> 24:37.200
I'm also hearing a good thought from your side, which is like, can you even build the machines

24:37.200 --> 24:41.880
or can you build a machine, machine learning algorithms that can, given just some chat,

24:41.880 --> 24:46.920
but can automatically infer what the slots should be, what the intent should be.

24:46.920 --> 24:49.640
And definitely that's possible.

24:49.640 --> 24:53.760
It's not going to be very accurate because it's almost like when you do clustering over

24:53.760 --> 24:57.720
documents, right, you can end up with these different representations.

24:57.720 --> 25:00.160
And the same thing is going to happen here.

25:00.160 --> 25:05.920
So that's why typically you start with the notions of you defining your, your slots

25:05.920 --> 25:06.920
and intents.

25:06.920 --> 25:11.760
So when you build the machine learning applications, typically you have the classes, right, that

25:11.760 --> 25:16.240
you want to output, meaning if I give you a large document collection and I say, well,

25:16.240 --> 25:18.920
I just want to know is this low, is this medicine and so on.

25:18.920 --> 25:19.920
Okay.

25:19.920 --> 25:20.920
You already have these categories.

25:20.920 --> 25:24.560
So it's the same thing for building these natural language understanding components.

25:24.560 --> 25:29.520
You need to know what categories or what is your space over which you're going to operate.

25:29.520 --> 25:33.160
If you try to learn that automatically, as I say, you're going to end up with these

25:33.160 --> 25:38.560
coarse green, very high level, you'll define like meanings and they won't be sufficient

25:38.560 --> 25:46.240
for you to build a meaningful application, but if you sit down and actually write it yourself,

25:46.240 --> 25:51.120
you have much higher chance because think about it just to build a flight booking system.

25:51.120 --> 25:55.200
If you open the different travel website and you see like what are the minimum sets of

25:55.200 --> 26:00.400
inputs they require you from the destination to destination, time, location, and so on.

26:00.400 --> 26:04.680
And you just define literally that to be your space or the slots over which the system

26:04.680 --> 26:05.680
would operate.

26:05.680 --> 26:08.840
You're going to be able to build much, much better system.

26:08.840 --> 26:15.120
And to be honest, yes, one of the of the pushes in science, both in terms of industries,

26:15.120 --> 26:21.520
like can you build systems or conversational assistance that can learn from human interactions

26:21.520 --> 26:23.760
and that you can teach right now.

26:23.760 --> 26:27.880
If you ask something to a system to tell you, I'm sorry, I'm not quite sure about that

26:27.880 --> 26:29.720
or like I'm still learning.

26:29.720 --> 26:34.000
In reality, it will be really awesome if you make those system learn such that anything

26:34.000 --> 26:39.720
you say and based on how people have replied, plus like request for new, let's say for

26:39.720 --> 26:43.960
new information that you haven't seen before, if the system can learn it and start asking

26:43.960 --> 26:49.000
about it or see many people are talking about it, then this is the place where we want

26:49.000 --> 26:53.000
to go because humans cannot encode all the knowledge in the world.

26:53.000 --> 26:58.400
And where I'm headed at is like, if you look at how all of these applications are built,

26:58.400 --> 27:02.800
they are operated over different domains, which means you have a movie domain, you have

27:02.800 --> 27:06.200
like music domain, shopping domain and so on.

27:06.200 --> 27:11.320
And each of these domains have their semantic representations or so called slots and templates

27:11.320 --> 27:13.920
that you can call and you can fill in.

27:13.920 --> 27:18.920
But a human cannot sit down and represents the whole world in these frames, right?

27:18.920 --> 27:19.920
It's right.

27:19.920 --> 27:22.240
I'm consuming its labor intensive.

27:22.240 --> 27:23.880
It doesn't scale.

27:23.880 --> 27:28.120
And most importantly, it's like we humans don't operate for domains, right?

27:28.120 --> 27:31.640
I can say order my pizza and book a flight, right?

27:31.640 --> 27:35.960
I just request two different domains and express multiple intents.

27:35.960 --> 27:41.280
And that's the main reasons why it's, as I say, like the current technology is great

27:41.280 --> 27:43.160
and it's all real use cases.

27:43.160 --> 27:48.440
But there's like many, many more things that have to be done and we have to focus on figuring

27:48.440 --> 27:53.800
out how do you build an end-to-end system that can operate for any domain that can operate

27:53.800 --> 27:59.000
for different languages and that can continue to help assist in us.

27:59.000 --> 28:05.680
And so what's the state of the art there are people building a bunch of individual domain

28:05.680 --> 28:12.320
knowledge and then using some deep neural network to kind of identify which domain is

28:12.320 --> 28:20.040
being asked about in a particular utterance or are they building kind of bigger, flatter

28:20.040 --> 28:21.040
models?

28:21.040 --> 28:23.280
Is there any particular direction now?

28:23.280 --> 28:29.280
I think we have one of the most common trends that I have been seeing over time in this

28:29.280 --> 28:34.600
field is for people to try to focus on the different domains and for each domain focus

28:34.600 --> 28:35.600
on the slots.

28:35.600 --> 28:40.320
And sometimes I've seen people trying to transfer knowledge from similar domains, let's

28:40.320 --> 28:46.360
say I know everything about reserving restaurants and I have a little bit of data for hotels.

28:46.360 --> 28:51.320
Now can I learn how to reserve hotels by knowing how to reserve restaurants?

28:51.320 --> 28:53.240
So that's the most common approach.

28:53.240 --> 28:58.400
And as I said, it's a challenge because it doesn't scale, it just doesn't work.

28:58.400 --> 29:02.880
The ideal scenario is like, can you build a system that doesn't have these boundaries

29:02.880 --> 29:07.400
and can just like operate over anything that we have in mind?

29:07.400 --> 29:13.120
Yes, in terms of like what algorithms, there's a lot of people do use deep learning as

29:13.120 --> 29:15.920
I say, different parts of the components.

29:15.920 --> 29:16.920
Yeah.

29:16.920 --> 29:23.680
Yeah, and I guess deep learning isn't really fundamental to my question as much as is

29:23.680 --> 29:28.320
the best practice to or you know, is the research frontier.

29:28.320 --> 29:35.440
If I'm trying to build a system that can handle hotel reservations and pizza orders and

29:35.440 --> 29:41.760
buying cars and you know, multiple things, am I likely to be better off getting a bunch

29:41.760 --> 29:47.320
of data for each of those building out specialized representations for each of those and training

29:47.320 --> 29:52.800
models that perform well for each and then use some kind of discriminator that can figure

29:52.800 --> 30:00.800
out which model to use or is there some other kind of technique that at that metal level,

30:00.800 --> 30:02.520
you know, to pull it all together?

30:02.520 --> 30:09.520
Yeah, if you're building a production system that has to work and satisfy user and customer

30:09.520 --> 30:12.480
needs, then that's the right way to go.

30:12.480 --> 30:17.240
It will guarantee you one that your system is going to be doing the right things and

30:17.240 --> 30:22.240
it will have higher precision, which is what's very important for users.

30:22.240 --> 30:25.840
Nobody likes to hear the same question twice like, what did you mean?

30:25.840 --> 30:28.640
I didn't get your question.

30:28.640 --> 30:33.640
In terms of research, I think people can have much more flexibility and they can use

30:33.640 --> 30:34.640
all kinds of techniques.

30:34.640 --> 30:39.840
They can use like transfer learning to see like, how do I transfer my bot that I built?

30:39.840 --> 30:44.160
Let's say for restaurants into flights or into something else and I think these kind of

30:44.160 --> 30:49.280
transfers are more successful for things that are closer to each other.

30:49.280 --> 30:54.280
There are some people that I have just seen on general like entity recognition and sentiment

30:54.280 --> 30:59.560
analysis, but the thing is like they've been evaluated on much smaller data.

30:59.560 --> 31:04.160
So ideally what I really would like to see is like people doing it on a larger scale with

31:04.160 --> 31:09.400
lots of data and having many of these domains and actually showing like how possible it is

31:09.400 --> 31:13.440
and where are going to be like the biggest challenges.

31:13.440 --> 31:17.120
Also you can build the system in a different way like if you want, you can do these individual

31:17.120 --> 31:21.240
components and then you have something on the top that actually ranks your results and

31:21.240 --> 31:26.440
tells you what's the most likely domain sets of intents and also slots or you can build

31:26.440 --> 31:31.520
one big giant neural network architecture that you can incorporate.

31:31.520 --> 31:35.520
Let's say if you have your LSTM, you can make it learn both your slots.

31:35.520 --> 31:39.800
It can learn your intent as well as the domain and over time with a lot of data, you can

31:39.800 --> 31:44.680
learn these constraints that in certain domain, let's say like movies, it's very less likely

31:44.680 --> 31:48.560
that I do an action that is let's say possible for a different.

31:48.560 --> 31:53.840
I would say that if you are building a real application, then stick to what works.

31:53.840 --> 32:00.000
If you are passionate about exploring and pushing the frontiers and doing like a lot of research,

32:00.000 --> 32:04.920
then definitely there are many more like open doors in terms of like trying to see like

32:04.920 --> 32:08.040
where is the boundaries and how far can we get.

32:08.040 --> 32:10.040
Hmm, great, great.

32:10.040 --> 32:11.920
Let's talk about the data a little bit.

32:11.920 --> 32:18.040
Are there standard data sets that folks are using for these kinds of problems like there

32:18.040 --> 32:21.880
are in the image recognition side of things?

32:21.880 --> 32:27.640
I've seen like there is some challenges that are called the dialog state tracking challenge.

32:27.640 --> 32:34.440
They do focus a lot on the dialog manager component and there are also these attempts

32:34.440 --> 32:40.080
with these different same data challenge that people can do the knowledge transfer that

32:40.080 --> 32:41.480
I was talking about.

32:41.480 --> 32:46.600
I've seen people use different types like Ubuntu chats and that's like if you just want

32:46.600 --> 32:52.000
to build like a high level chatbot system that doesn't, it's not go oriented.

32:52.000 --> 32:57.480
And then I've seen a lot of work from Facebook AI that drives in that area and they have

32:57.480 --> 32:59.480
a data set that's called BABY.

32:59.480 --> 33:00.480
It's called what?

33:00.480 --> 33:01.480
I think BABY.

33:01.480 --> 33:02.480
Okay.

33:02.480 --> 33:08.960
I'm not sure how the right pronunciation is BABY, but it has like different tasks like

33:08.960 --> 33:15.240
20 tasks and it's annotated and people do use it for conducting research.

33:15.240 --> 33:20.480
So if somebody wants to like start in that area and wants to play around, maybe these

33:20.480 --> 33:21.480
are good places.

33:21.480 --> 33:26.520
As I said, it depends like you just want to build like a chatbot that doesn't have any

33:26.520 --> 33:31.480
goal for a few months or do you want to focus on building a real working system that is

33:31.480 --> 33:34.840
going to fulfill your goals for you as a human.

33:34.840 --> 33:35.840
Hmm.

33:35.840 --> 33:40.960
And now if you're building a system like this and none of these data sets work for you,

33:40.960 --> 33:45.480
you've got to figure out some place to find that data.

33:45.480 --> 33:50.600
And I noted that you've got some research experience into large scale knowledge extraction

33:50.600 --> 33:51.600
from the web.

33:51.600 --> 33:57.200
Are there any techniques there that you might use to help you collect the data set?

33:57.200 --> 33:59.640
Well, you can do different things.

33:59.640 --> 34:04.480
People have invested a lot of effort in building this wizard of all systems.

34:04.480 --> 34:09.120
It means like you can build very quick application that simulates a scenario.

34:09.120 --> 34:13.760
Let's say one person will pretend he is the booking expert and the other one will be

34:13.760 --> 34:19.440
the customer and they can drive the conversation on their own and the booking agent will just

34:19.440 --> 34:21.320
try to fulfill that intent.

34:21.320 --> 34:27.760
So if you create such scenarios and record all the data with different people interacting,

34:27.760 --> 34:32.880
that could be one easy quick way to start building your application.

34:32.880 --> 34:34.360
Another way could be that you can do that.

34:34.360 --> 34:37.760
And just to drill into that, what you're suggesting there is that you define out these

34:37.760 --> 34:42.360
scenarios and then are you thinking like go to some place like a mechanical Turk and

34:42.360 --> 34:47.600
say, hey, you know, you play the booking agent and you play the customer and you get kind

34:47.600 --> 34:52.080
of random people to explore these scenarios or do you mean something else by that?

34:52.080 --> 34:54.200
Yeah, it's perfectly feasible.

34:54.200 --> 34:56.920
Yes, you can exactly do that.

34:56.920 --> 35:01.000
Like kind of decide what you what the application you want to build.

35:01.000 --> 35:05.520
You can set up everything being on Amazon Turk or being even let's say you're a startup

35:05.520 --> 35:08.600
and you don't want this information to be leaking.

35:08.600 --> 35:09.600
Then you can set it up.

35:09.600 --> 35:14.880
Even build your own very quick in-house application that just can record these conversations.

35:14.880 --> 35:18.920
And once you have that data, then you can start building, let's say, a first prototype.

35:18.920 --> 35:22.360
You can even launch it and then test it on real users.

35:22.360 --> 35:25.360
When the data comes back, you can start iterating.

35:25.360 --> 35:29.400
And once you have this kind of nice loop, you can keep iterating and improving what you

35:29.400 --> 35:30.400
have done.

35:30.400 --> 35:31.400
That's one way.

35:31.400 --> 35:35.760
Like completely even focus on, let's say, like just Amazon Mechanical Turk.

35:35.760 --> 35:40.120
You can either have predefined questions, but then the conversation will become very artificial

35:40.120 --> 35:43.480
or you can play the game that you have just explained.

35:43.480 --> 35:48.600
And then the on your questions, like, can we do something if I give you the whole web?

35:48.600 --> 35:51.880
What can I do to facilitate the building of such systems?

35:51.880 --> 35:54.960
Like at the core of these systems is like a knowledge component.

35:54.960 --> 35:59.680
You have to have knowledge bases that help you extract this information much more accurately

35:59.680 --> 36:01.920
that help you get world knowledge.

36:01.920 --> 36:05.800
And one way is that you can get that world knowledge if you don't have your own knowledge

36:05.800 --> 36:06.800
graph.

36:06.800 --> 36:11.280
You can get that world knowledge by literally extracting all of that information from tons

36:11.280 --> 36:13.600
of web pages on different topics.

36:13.600 --> 36:16.240
And you can integrate it inside your models, right?

36:16.240 --> 36:21.360
Either as additional features or additional signal and the help drive these applications

36:21.360 --> 36:24.480
to be more precise and more accurate.

36:24.480 --> 36:28.200
Interesting, interesting.

36:28.200 --> 36:33.480
If you did a talk on dialogue systems, actually that's coming up.

36:33.480 --> 36:38.280
It looks like is that in the same kind of domain of the things that we've been talking about

36:38.280 --> 36:41.160
as far or there are different aspects to that?

36:41.160 --> 36:47.760
Yes, that was like, have the core component of like, if people know machine learning and

36:47.760 --> 36:52.360
they want to build everything from scratch, their cells is like, what components should

36:52.360 --> 36:53.520
they focus on?

36:53.520 --> 36:57.840
What machine learning algorithm they should work like pick up and then how to get the

36:57.840 --> 36:58.840
data?

36:58.840 --> 37:01.400
And at the same time, it's like, what's the expectation?

37:01.400 --> 37:07.200
Some people have the expectations that this system should be like 99% accurate.

37:07.200 --> 37:12.560
And I was like, oh, not really, we're doing these baby steps in the field for some very

37:12.560 --> 37:14.040
specific basic things.

37:14.040 --> 37:18.240
You have high accuracy, but that doesn't mean that you have solved the problem.

37:18.240 --> 37:23.760
It just shows that the solution of such task is possible, but doesn't mean that it's a

37:23.760 --> 37:24.760
solve problem.

37:24.760 --> 37:29.080
So, you bring up accuracy and that raises some interesting questions, I think, on the

37:29.080 --> 37:34.960
speech recognition side, you know, there are some standardized measures of accuracy and

37:34.960 --> 37:40.240
you have folks like, you know, Microsoft and others reporting there, their accuracy

37:40.240 --> 37:45.080
and, in fact, Microsoft recently reported, or they're, I think, a number of organizations

37:45.080 --> 37:49.800
have recently reported human parity and recognition.

37:49.800 --> 37:57.800
It seems like it's maybe not quite as straightforward to report accuracy on the NLU side of things.

37:57.800 --> 37:59.000
Is that true or no?

37:59.000 --> 38:06.000
Well, actually, no, think about it like when we annotate the data, you typically have

38:06.000 --> 38:09.600
your training set, your development set, and you have your test set.

38:09.600 --> 38:14.440
And for each of those, we always measure what is your precision, what is your recall,

38:14.440 --> 38:15.440
what's your F score?

38:15.440 --> 38:21.400
We go on the level of each of these slots, and we also record other things like, how hard

38:21.400 --> 38:23.200
is the task for a human?

38:23.200 --> 38:28.040
We measure the cap agreement, the Krippendorf Alpha, and the idea is that if you see how hard

38:28.040 --> 38:33.480
the task is for a human, then expect your system to be 10% less than that, right?

38:33.480 --> 38:38.760
So if two humans have really hard time annotating your data with your representations, this

38:38.760 --> 38:44.080
means that it will be extremely hard also for that system to learn about it.

38:44.080 --> 38:49.200
My point was that building the natural language understanding systems is much harder than

38:49.200 --> 38:52.720
building a, let's say, image understanding system.

38:52.720 --> 38:55.480
And the challenge is like language is very ambiguous.

38:55.480 --> 39:01.120
We have to deal with a lot of slang that people might be using, or specific like metaphors

39:01.120 --> 39:02.920
that people have in mind.

39:02.920 --> 39:07.840
And so the building of a system that can understand and operate on top of that, right?

39:07.840 --> 39:08.840
It's very hard.

39:08.840 --> 39:12.440
That's why I was saying that it's important to have your knowledge basis hooked up so

39:12.440 --> 39:18.640
that the system can get, think about like a cheat sheet and some extra information that

39:18.640 --> 39:22.360
can help it facilitate, understand better, like what we mean.

39:22.360 --> 39:23.360
Right.

39:23.360 --> 39:24.360
Yeah.

39:24.360 --> 39:26.560
I think that's what I was getting at with the accuracy question.

39:26.560 --> 39:32.760
I can think of many occasions often happening right here at home where I definitely understand

39:32.760 --> 39:36.160
the words, but I'm not sure I totally understand the meaning.

39:36.160 --> 39:46.040
And while I can certainly grade my system's accuracy relative to some label set, it's

39:46.040 --> 39:50.960
harder to capture even the right metrics in terms of, you mentioned this earlier in

39:50.960 --> 39:59.800
the conversation, like, do we even have representation for nuance and sarcasm and things

39:59.800 --> 40:05.880
like that, that, you know, if I had some uber metric of, hey, does, you know, does the system

40:05.880 --> 40:13.080
understand what was being said, it just seems way more difficult to really capture what

40:13.080 --> 40:14.440
that even means.

40:14.440 --> 40:15.440
Yes.

40:15.440 --> 40:20.200
And, you know, like back in the day when I was like with my academic head, my head that

40:20.200 --> 40:25.640
grant from my ARPA, that focused on, can you build systems that understand metaphors

40:25.640 --> 40:30.640
for four different languages, it was Arabic, Russian, Spanish and English, and what

40:30.640 --> 40:31.640
I mean, metaphors.

40:31.640 --> 40:32.640
Metaphors.

40:32.640 --> 40:33.640
Metaphors, got it.

40:33.640 --> 40:34.640
Yes.

40:34.640 --> 40:40.640
And you have these four different languages like Spanish and Russian and Arabic and English.

40:40.640 --> 40:46.200
And the idea is like, we just pass any text, could be news, can you find those metaphors,

40:46.200 --> 40:51.880
can you interpret them and also assign the sentiment that the person had when he said that

40:51.880 --> 40:52.880
metaphor, right?

40:52.880 --> 40:59.880
So, if I say my lawyer is a shark, so you know that, yeah, sharks are vicious, but it's

40:59.880 --> 41:04.040
really good for me to have a lawyer like that because it means that that the lawyer is

41:04.040 --> 41:07.280
going to do the right thing and they're going to protect you.

41:07.280 --> 41:11.840
But if I'm saying this to you, then for you, that is going to have a negative connotation,

41:11.840 --> 41:12.840
right?

41:12.840 --> 41:17.320
So, it was really hard to build systems that just given any three texts in these languages,

41:17.320 --> 41:21.760
it can identify the metaphoric expression interpret what they mean.

41:21.760 --> 41:26.600
And yeah, we've focused like two years on just building and trying to solve it.

41:26.600 --> 41:31.640
And unlike other tasks in each language processing that have matured over time and that have

41:31.640 --> 41:37.600
like significantly higher performance, building such kind of system that understand metaphors

41:37.600 --> 41:38.600
was very hard.

41:38.600 --> 41:42.240
It's like in the 50 percent, it's really challenging.

41:42.240 --> 41:47.960
Yeah, again, going back to my previous point, it's even hard to, before we get to building

41:47.960 --> 41:53.640
the system to think about what performance even means in this context, right?

41:53.640 --> 41:59.280
I think even that statement about my lawyer as a shark can be, you know, can probably have

41:59.280 --> 42:03.360
either positive or negative sentiment depending on the circumstance.

42:03.360 --> 42:05.160
That is correct, exactly.

42:05.160 --> 42:09.960
But you know, the best part is like, as I say, language is very hard and there are a lot

42:09.960 --> 42:13.960
of people trying to solve these challenging tasks for some of them, we've made tremendous

42:13.960 --> 42:18.400
progress, others are open-ended and we're still working on them.

42:18.400 --> 42:22.320
And that's what excites me because it means that we have a lot of work to do, a lot of

42:22.320 --> 42:25.680
efforts to put into building their systems.

42:25.680 --> 42:27.080
Absolutely, absolutely.

42:27.080 --> 42:31.160
What are some of the other areas that you're tracking that you're seeing exciting work

42:31.160 --> 42:32.160
happening?

42:32.160 --> 42:37.760
In natural language processing, there is like a lot of focus on question answering.

42:37.760 --> 42:41.920
And the building, both type of systems, like if I give you a knowledge base, can you

42:41.920 --> 42:46.720
do question answering over this knowledge base and do inferences on top of that?

42:46.720 --> 42:50.360
And we have seen open-ended question answering where you have a document and just somebody

42:50.360 --> 42:55.280
comes in and types the question like this on the spur of the moment, then can we find

42:55.280 --> 42:58.720
the corresponding answer in that document?

42:58.720 --> 43:01.240
They're both very challenging and exciting.

43:01.240 --> 43:06.000
So this year I will area chair for ACA, which is association of computational linguistics

43:06.000 --> 43:10.840
conference, our top tier one conference and like the biggest natural language processing

43:10.840 --> 43:15.920
conferences and the areas that we're training a lot for information extraction and question

43:15.920 --> 43:17.080
answering.

43:17.080 --> 43:22.840
And there's like a lot of effort, some challenges that are coming up and people have just

43:22.840 --> 43:28.880
been given the data and given the ability to think about how to innovate and how to solve

43:28.880 --> 43:29.880
them.

43:29.880 --> 43:36.760
I know Kora is among the folks that have data sets for question answering and there's

43:36.760 --> 43:41.440
another popular one, at least another popular one that I'm forgetting the name of right

43:41.440 --> 43:42.440
now.

43:42.440 --> 43:43.840
Yes, that's absolutely correct.

43:43.840 --> 43:46.520
Like Kora has a nice data set.

43:46.520 --> 43:51.600
You have squat, who is coming, does a data set developed by University of Stanford,

43:51.600 --> 43:53.000
Percy Liang's group?

43:53.000 --> 43:55.400
And that's one of the, it's a very good data set.

43:55.400 --> 44:00.680
It has a lot of training data, magnitude's larger than previous data set.

44:00.680 --> 44:03.360
And it has different types of categories of questions.

44:03.360 --> 44:07.520
So that kind of mostly simulates or approximate real case scenario.

44:07.520 --> 44:12.040
And that data set focuses on the second question answering type that I was talking about.

44:12.040 --> 44:16.280
You have like documents and then you have a question like can you find the answer in

44:16.280 --> 44:17.280
the document?

44:17.280 --> 44:21.200
And it's much challenging because people can ask the question in any form using different

44:21.200 --> 44:22.600
part of phrases.

44:22.600 --> 44:27.280
And then finding these pants with the correct answer is way harder than traversing a

44:27.280 --> 44:29.080
real knowledge base.

44:29.080 --> 44:35.680
And so are the core techniques that are used for these two different types of question

44:35.680 --> 44:39.280
answering tasks the same or are they dramatically different?

44:39.280 --> 44:45.160
Well, I've seen people that use, let's say, knowledge graphs to answer questions to

44:45.160 --> 44:48.040
use more graph based algorithms.

44:48.040 --> 44:52.040
And I'm seeing a lot of trends with the deep learning for the second kind of problem

44:52.040 --> 44:56.960
with this squat data set, which is more like machine comprehension from text.

44:56.960 --> 45:00.600
And there are people have different architectures of how they solve it.

45:00.600 --> 45:05.120
But let's say for the machine comprehension one, I've seen very common is like people

45:05.120 --> 45:09.640
try to represent the question into some kind of an embedding or vector space.

45:09.640 --> 45:14.360
And then they have the document they try to use like attention mechanism on top to pick

45:14.360 --> 45:18.520
up entities or pick up spans that could be good match for the answer.

45:18.520 --> 45:23.600
And then they kind of try to have some similarity between the question and the answer.

45:23.600 --> 45:28.760
So yes, both of those different types of question answering have wide variety of methods

45:28.760 --> 45:29.760
have been employed.

45:29.760 --> 45:34.440
But these are two things that I'm noticing are kind of trending when people publish their

45:34.440 --> 45:35.600
work.

45:35.600 --> 45:36.600
Hmm.

45:36.600 --> 45:42.800
So for the knowledge graphs, I'm imagining there that you're using some kind of technique

45:42.800 --> 45:50.320
to identify, well, maybe a precursor to that is what types of representations are using

45:50.320 --> 45:56.400
typically on your documents that you're trying to do this question answering for.

45:56.400 --> 46:04.640
Are you doing things like trying to do semantics and identify nouns and verbs and that kind

46:04.640 --> 46:05.640
of structure?

46:05.640 --> 46:09.840
Or are you operating on a lower level than that?

46:09.840 --> 46:15.680
Oh, actually, yeah, that's what I was saying that this data set, I like it because one,

46:15.680 --> 46:22.280
the magnitude is much larger than any previous data set and two, you have to focus on extracting

46:22.280 --> 46:25.000
different types of bits and pieces.

46:25.000 --> 46:28.040
And sometimes they could be just a word of phrase.

46:28.040 --> 46:32.280
They could be combinations of like just like a non phrase or much harder.

46:32.280 --> 46:37.160
It's not like a single answer like when was Barack Obama born and you just say the year,

46:37.160 --> 46:38.160
right?

46:38.160 --> 46:41.200
That's what a knowledge like a question answering over knowledge base does.

46:41.200 --> 46:46.400
This one is more open and that if I say like, hey, what were the symptoms for people who

46:46.400 --> 46:50.840
have cardiac arrest, maybe the answers were contained in different paragraphs and you

46:50.840 --> 46:55.520
have to find those different paragraphs and the exact spans with the answer.

46:55.520 --> 46:59.680
And that's what makes it much more challenging, but at the same time, much more useful because

46:59.680 --> 47:04.720
most of the information that we need and the questions that we have, they lay in this unlabeled

47:04.720 --> 47:10.720
documents that are being on the web or that you as a corporation might have and you might

47:10.720 --> 47:12.880
want to just search for the information.

47:12.880 --> 47:17.480
So I personally prefer this type of question answering work because it's, as I say, more

47:17.480 --> 47:19.000
real case scenario.

47:19.000 --> 47:23.600
And second, it's like more useful to us.

47:23.600 --> 47:24.960
And so just to take a step back.

47:24.960 --> 47:31.160
So with these question answering data sets in particular, the Stanford one, the data set

47:31.160 --> 47:37.400
includes the base document and then a set of questions and answers from that document

47:37.400 --> 47:44.520
and are there multiple answers for each question and to what degree to the questions overlap?

47:44.520 --> 47:48.120
Yes, that's a great question.

47:48.120 --> 47:53.600
So typically you have something like one question like, I'm just reading from the official

47:53.600 --> 47:58.240
paper that was published, which governing bodies have veto power and then you have a whole

47:58.240 --> 48:03.200
document that, let's say, is talking about something, right?

48:03.200 --> 48:08.120
There is one specific sentence that can have this answer, for example, the European Parliament

48:08.120 --> 48:12.800
and the Council of the European Union have powers over the month and veto and so on.

48:12.800 --> 48:18.160
So given that question, then the idea and this document idea is like, can you find the

48:18.160 --> 48:26.000
paragraph and more specifically the sentence that contains this specific type of an answer?

48:26.000 --> 48:31.760
And I haven't like the deeper in terms of like understanding like how many of the question

48:31.760 --> 48:37.400
the exact, let's say, question could be found with the exact answer inside.

48:37.400 --> 48:42.160
But I do know that the creators made sure that when that data was annotated, that they

48:42.160 --> 48:46.800
asked people is like, if you read this article, can you ask a question using paraphrases,

48:46.800 --> 48:50.760
which means like different words or different ways that you can ask about it.

48:50.760 --> 48:54.600
So it doesn't have to be the exact same, how to say exact same phrasing.

48:54.600 --> 48:58.680
If you had the exact same phrasing, then the problem is much more simple, right?

48:58.680 --> 49:03.280
But definitely that's how to say much more challenging dataset, the way it was created

49:03.280 --> 49:04.640
and the way it's annotated.

49:04.640 --> 49:09.440
So I think they did a good job on making sure it's created the right way.

49:09.440 --> 49:13.240
It has different complexity, yeah.

49:13.240 --> 49:19.280
So that helps me, that helps clarify for me like what you're fundamentally trying to

49:19.280 --> 49:26.360
do is you're given a question and you're trying to essentially index into this document,

49:26.360 --> 49:31.400
the sentence, the particular sentence that answers it, which is a totally different

49:31.400 --> 49:39.280
problem than, or at least it is a more narrow problem than synthesizing an answer based

49:39.280 --> 49:46.880
on multiple sentences in the document or a summary type of problem or trying to pull

49:46.880 --> 49:53.440
pieces from two different sentences that are required to formulate an answer.

49:53.440 --> 49:58.040
Yes, that's more like a summarization what you are describing.

49:58.040 --> 50:02.920
And there the goal is a little bit different if I give you one or multiple news articles

50:02.920 --> 50:08.120
about the same topic is like can you find sentences such that you can summarize the text

50:08.120 --> 50:10.480
in a much more compact fashion.

50:10.480 --> 50:15.120
And for a human, the moment they read it, they get the gist of the facts and at the same

50:15.120 --> 50:20.400
time the whole summary is coherent and has natural reading flow.

50:20.400 --> 50:27.200
There are dataset that has been created on that area is just the problem is called more

50:27.200 --> 50:28.960
like summarization, right?

50:28.960 --> 50:31.320
Right, but there's some overlap, right?

50:31.320 --> 50:37.040
So if you just to construct a simple example, if I've got a document that says somewhere

50:37.040 --> 50:42.040
in it, you know, my favorite color is red, you know, and then the next sentence is, you

50:42.040 --> 50:45.280
know, but I also like blue and yellow, right?

50:45.280 --> 50:48.840
And if you ask a question, what colors do I like?

50:48.840 --> 50:54.640
There's got to be some synthesis or summarization in there somewhere and, you know, A, is that,

50:54.640 --> 51:00.360
you know, typically part of the question answering, is there a, you know, a set of work in question

51:00.360 --> 51:06.520
answering that's looking at those kind of more complex scenarios or are there folks that

51:06.520 --> 51:11.240
are trying to combine the question answering and summarization pieces to, you know, answer

51:11.240 --> 51:12.840
these more complex questions.

51:12.840 --> 51:17.440
Yeah, if I'm not mistaken, there are people who are trying to do both.

51:17.440 --> 51:24.160
I've seen this a mostly like focusing on one, but noted the two, but I'm sure that there

51:24.160 --> 51:25.440
are people who work on that.

51:25.440 --> 51:30.040
I'm just not aware at the moment of, of, or I don't have them on top of my head for such

51:30.040 --> 51:36.200
paper, but like, there's a researcher called Sasha Rush, like he has a paper on like,

51:36.200 --> 51:40.600
how do you do this summarization that you were describing with attention mechanisms?

51:40.600 --> 51:45.400
So I'm sure that they're likely there could be a work combining both of the things that

51:45.400 --> 51:48.560
you're describing.

51:48.560 --> 51:53.680
So if someone wants to dig into this more, do you have any go-to resources for getting

51:53.680 --> 51:54.680
started?

51:54.680 --> 51:55.680
Yes.

51:55.680 --> 51:58.280
For example, depends on what your aim is.

51:58.280 --> 52:03.960
If your aim is to stay on top of the Neatronic Processing field, a great place is just to

52:03.960 --> 52:08.960
go to the ACO ontology and all the different NLP conferences, their index there.

52:08.960 --> 52:13.920
You can see the latest papers organized by yours and by tracks.

52:13.920 --> 52:18.040
So you can pick your favorite track, being question answering, being parsing, being

52:18.040 --> 52:20.280
machine translation, whatever excites you.

52:20.280 --> 52:24.760
And it's great to just sit down and like read through these papers and search that you

52:24.760 --> 52:26.360
can get on a high level.

52:26.360 --> 52:30.440
What is it that people are working on and how far they have advanced?

52:30.440 --> 52:35.240
If somebody's just a beginner and they're trying to learn about the field, I encourage

52:35.240 --> 52:36.240
you.

52:36.240 --> 52:39.840
You can look at the Stanford's class on deep learning, like Neatronic's first thing

52:39.840 --> 52:40.840
with deep learning.

52:40.840 --> 52:45.800
It's taught by Chris Manning and Richard Zohar, both of them are like leaders in the field.

52:45.800 --> 52:51.000
And it's a good place to start and just kind of learn both about what are the problems

52:51.000 --> 52:56.280
in NLP, like the basic ones, and then how do you solve them using deep learning?

52:56.280 --> 53:01.080
And there are a lot of books people can just take and read specific chapters.

53:01.080 --> 53:07.320
So it really depends on what is your end goal, is it learning or is it just download and

53:07.320 --> 53:08.320
build?

53:08.320 --> 53:13.720
And you have open source code that people can use as well, just to run something basic

53:13.720 --> 53:17.320
and understand what's happening.

53:17.320 --> 53:22.800
And to bring us full circle, if all you want to do is build systems that use this stuff,

53:22.800 --> 53:26.200
you can use services like the stuff you're working on at Amazon.

53:26.200 --> 53:27.840
Yes, you can do that.

53:27.840 --> 53:33.160
And as I say, one is if you know nothing about machine learning, but yet you want to build

53:33.160 --> 53:37.160
such systems, you can use a lot of the pre-built things and we've done the heavy lifting

53:37.160 --> 53:38.160
for you.

53:38.160 --> 53:42.440
If you are passionate about machine learning, you know the algorithms and you love implementing

53:42.440 --> 53:43.440
from scratch.

53:43.440 --> 53:47.600
You can use like open source like MXNet, which we are supporting.

53:47.600 --> 53:48.600
You can use TensorFlow.

53:48.600 --> 53:50.720
You can use any of those tools.

53:50.720 --> 53:56.240
It's just depending on like what's your level and also like are you on a deadline or are

53:56.240 --> 53:59.360
you in this like learning exploration mode?

53:59.360 --> 54:09.680
And do you foresee a future that allows folks to combine elements of both and in particular

54:09.680 --> 54:14.560
what I'm getting at is, you know, now your choice has seemed to be, you know, I can use

54:14.560 --> 54:23.360
a service like Lex that's, you know, pre-trained or I can, you know, roll my own and, you know,

54:23.360 --> 54:27.840
train using my own data and, you know, the presumption being I'm trying to get more accuracy

54:27.840 --> 54:33.320
by, you know, training on a more limited, you know, the more limited corpus that I'm concerned

54:33.320 --> 54:34.320
about.

54:34.320 --> 54:40.360
Do you see over time the kind of AI as a service offerings allowing you to upload your

54:40.360 --> 54:45.480
own data and train on it and somehow augment, you know, their pre-trained models?

54:45.480 --> 54:49.640
Yeah, I think that's exactly where like future is headed.

54:49.640 --> 54:53.080
Definitely people have their own data sets, their own requirements.

54:53.080 --> 54:59.320
If they have the data scientists also like available, doing exactly what you describe is

54:59.320 --> 55:00.320
possible.

55:00.320 --> 55:06.560
And I think that's fantastic way to take advantage of your in-house data, take advantage

55:06.560 --> 55:12.000
of your engineers and put them on a mission or put them on a task, which is like, okay,

55:12.000 --> 55:14.680
improve these services, augment them, make them better.

55:14.680 --> 55:20.160
So definitely I think that's a great place to be and in a great area to invest and focus

55:20.160 --> 55:21.160
on.

55:21.160 --> 55:22.160
Great.

55:22.160 --> 55:27.720
Well, I really appreciated all the time you spent with us today and I really enjoyed

55:27.720 --> 55:28.720
the conversation.

55:28.720 --> 55:29.720
Thanks so much.

55:29.720 --> 55:30.720
Zora Nitsa.

55:30.720 --> 55:32.720
Likewise, thank you very much Sam.

55:32.720 --> 55:33.720
Bye.

55:33.720 --> 55:34.720
Bye.

55:34.720 --> 55:35.720
Bye.

55:35.720 --> 55:42.480
All right, everyone, that's our show for today.

55:42.480 --> 55:47.480
Thanks so much for listening and for your continued support, comments and feedback.

55:47.480 --> 55:48.960
This is your last reminder.

55:48.960 --> 55:55.200
If you are in New York today, June 29th, Thursday, join me this evening at the happy hour.

55:55.200 --> 55:57.880
I'm hosting with the NYAI Meetup.

55:57.880 --> 56:05.080
If you'd like more details, please sign up using the form at twimlai.com slash NY Meetup.

56:05.080 --> 56:10.680
The notes for this episode can be found at twimlai.com slash talk slash 30.

56:10.680 --> 56:16.360
For more information on industrial AI, my report on the topic or the industrial AI podcast

56:16.360 --> 56:21.360
series, visit twimlai.com slash industrial AI.

56:21.360 --> 56:26.000
As always, remember to post your favorite quote or takeaway from this episode and we'll

56:26.000 --> 56:27.840
send you a laptop sticker.

56:27.840 --> 56:33.760
You can post them as comments to the show notes page via Twitter mentioning at twimlai or via

56:33.760 --> 56:35.360
our Facebook page.

56:35.360 --> 56:46.760
Thanks so much for listening and catch you next time.

