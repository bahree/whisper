1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:31,800
I'm your host Sam Charrington.

4
00:00:31,800 --> 00:00:36,900
Today we're joined by Tom Sumowski, data scientist at Urban, the parent company of Urban

5
00:00:36,900 --> 00:00:41,440
Outfitters, Anthropology and other consumer fashion brands.

6
00:00:41,440 --> 00:00:45,960
Tom and I caught up recently to discuss his project Exploring Custom Vision Services

7
00:00:45,960 --> 00:00:49,440
for Automated Fashion Product Attribution.

8
00:00:49,440 --> 00:00:53,320
We started our discussion with the definition of the product attribution problem in retail

9
00:00:53,320 --> 00:00:57,640
and fashion and the challenges it offers to data scientists.

10
00:00:57,640 --> 00:01:01,680
We then looked at the approach Tom and his team took to building custom attribution models

11
00:01:01,680 --> 00:01:06,720
and the results of their evaluation of various custom vision APIs for this purpose, with

12
00:01:06,720 --> 00:01:12,560
a focus on the Roblox and Lessons he and his team encountered along the way.

13
00:01:12,560 --> 00:01:16,120
Today's show is sponsored by our friends at Pegasystems.

14
00:01:16,120 --> 00:01:20,440
During a world, the company's annual digital transformation conference, which will be held

15
00:01:20,440 --> 00:01:26,440
at the MGM Grand in Las Vegas from June 2nd to 5th, is just a couple of months away now.

16
00:01:26,440 --> 00:01:31,280
I'll be attending the event as I did last year and will once again be presenting.

17
00:01:31,280 --> 00:01:36,000
In addition to hearing from me, the event is a great opportunity for you to learn how AI

18
00:01:36,000 --> 00:01:41,080
is being applied to the customer experience at real Pegasystems.

19
00:01:41,080 --> 00:01:47,280
As a Twimble listener, you can use promo code Twimble19 for $200 off of your registration.

20
00:01:47,280 --> 00:01:49,480
Again, that code is Twimble19.

21
00:01:49,480 --> 00:01:51,000
It's as easy as that.

22
00:01:51,000 --> 00:01:52,600
Hope to see you there.

23
00:01:52,600 --> 00:01:54,920
And now on to the show.

24
00:01:54,920 --> 00:01:58,640
All right, everyone.

25
00:01:58,640 --> 00:02:00,760
I am on the line with Tom Sumowski.

26
00:02:00,760 --> 00:02:06,560
Tom is a data scientist with Urban, the parent company of Urban Outfitters, Anthropology

27
00:02:06,560 --> 00:02:08,040
and other fashion brands.

28
00:02:08,040 --> 00:02:10,480
Tom, welcome to this week in Machine Learning and AI.

29
00:02:10,480 --> 00:02:11,720
Thanks for having me, Sam.

30
00:02:11,720 --> 00:02:18,040
So Tom was recently part of the team that worked on some work around product attribution.

31
00:02:18,040 --> 00:02:23,000
And just yesterday, their blog post about this project went live following them, open

32
00:02:23,000 --> 00:02:25,920
sourcing some code.

33
00:02:25,920 --> 00:02:27,160
And we'll talk all about that.

34
00:02:27,160 --> 00:02:31,760
But before we do, Tom, why don't you tell us a little bit about your background and

35
00:02:31,760 --> 00:02:34,760
how you got started working in data science and machine learning?

36
00:02:34,760 --> 00:02:35,760
Sure.

37
00:02:35,760 --> 00:02:41,040
By academic background, I have a bachelor's and master's in electrical engineering.

38
00:02:41,040 --> 00:02:46,080
From there, I went to Lockheed Martin, which is a defense contractor, working in their

39
00:02:46,080 --> 00:02:49,160
corporate research lab for many years.

40
00:02:49,160 --> 00:02:54,200
And in there, the focus was primarily on wireless systems signal processing.

41
00:02:54,200 --> 00:03:02,360
So I started off primarily with embedded systems or embedded platform development for the

42
00:03:02,360 --> 00:03:04,600
area of electronic warfare.

43
00:03:04,600 --> 00:03:08,120
So that involves anything to do with telecommunication.

44
00:03:08,120 --> 00:03:12,680
So these days, everything sort of talks to each other, phones, radios, you name it.

45
00:03:12,680 --> 00:03:19,560
Our goal was to sort of understand that communication spectrum and inferred activities that are

46
00:03:19,560 --> 00:03:20,560
going on.

47
00:03:20,560 --> 00:03:27,320
So started off in kind of building signal geolocation applications, kind of working at a very low level.

48
00:03:27,320 --> 00:03:35,200
Later on, the shift moved towards a theme of cognitive in the 2012 timeframe for advanced

49
00:03:35,200 --> 00:03:37,000
technologies in that space.

50
00:03:37,000 --> 00:03:42,280
So what they sort of defense meant in terms of cognitive was adding intelligence to those

51
00:03:42,280 --> 00:03:48,200
applications that typically were very sort of rule based and driven based on strict policies.

52
00:03:48,200 --> 00:03:53,800
So in other words, they were looking to apply machine learning sort of in the earlier era

53
00:03:53,800 --> 00:03:54,800
of that space.

54
00:03:54,800 --> 00:03:57,440
So this is sort of pre-deep learning.

55
00:03:57,440 --> 00:04:06,320
So on the job, I more or less learned how to apply machine learning for mainly pattern

56
00:04:06,320 --> 00:04:13,160
recognition of different signal patterns and making decisions on how you should act based

57
00:04:13,160 --> 00:04:14,800
on that information.

58
00:04:14,800 --> 00:04:20,880
So for that, it was a lot of experimentation, a lot of learning with online courses like

59
00:04:20,880 --> 00:04:21,880
Coursera.

60
00:04:21,880 --> 00:04:28,120
And since we are a research lab, it was building essentially prototypes for proof of concepts

61
00:04:28,120 --> 00:04:30,480
to the military.

62
00:04:30,480 --> 00:04:34,920
And the goal there was to get the users of these systems.

63
00:04:34,920 --> 00:04:38,920
So what they're called electronic warfare officers, the people that are running these

64
00:04:38,920 --> 00:04:44,880
systems in operations to essentially trust the prototypes enough that they can field

65
00:04:44,880 --> 00:04:46,120
and deploy them.

66
00:04:46,120 --> 00:04:53,320
So the focus across that entire time for these types of systems were trust, reliability,

67
00:04:53,320 --> 00:04:59,600
stability, and making sure that it's providing a lot of value to that warfare officer and

68
00:04:59,600 --> 00:05:02,360
not sort of inundate in them with too much information.

69
00:05:02,360 --> 00:05:04,760
So that was sort of the machine learning side.

70
00:05:04,760 --> 00:05:11,360
More recently, I guess since the 2013-2014 time frame, that's when we as an organization

71
00:05:11,360 --> 00:05:17,200
started getting interested in deep learning with some of the really early performance enhancements

72
00:05:17,200 --> 00:05:18,520
that were shown from that.

73
00:05:18,520 --> 00:05:24,520
So that's where I kind of dove pretty deep into trying to apply deep learning to the spectrum.

74
00:05:24,520 --> 00:05:29,240
So when I say spectrum, going back to communications, it's a signal.

75
00:05:29,240 --> 00:05:36,440
So we basically turn what we hear, say over the error in the cell phone signals into what's

76
00:05:36,440 --> 00:05:43,160
called a spectrogram and analyze that spectrogram and try and identify patterns for how they're

77
00:05:43,160 --> 00:05:48,400
behaving, how they're adapting, and kind of isolate different communication patterns.

78
00:05:48,400 --> 00:05:51,920
So that was pretty much my time at Lockheed Martin.

79
00:05:51,920 --> 00:05:57,760
About a year ago, actually for several years, I was kind of following the trends in machine

80
00:05:57,760 --> 00:06:00,120
learning and deep learning.

81
00:06:00,120 --> 00:06:06,680
And more recently, I guess what's called data science, following podcasts like this, blogs,

82
00:06:06,680 --> 00:06:07,680
etc.

83
00:06:07,680 --> 00:06:11,480
And really got an interest in how some of this machine learning technology was being

84
00:06:11,480 --> 00:06:15,600
fielded or deployed in other industries.

85
00:06:15,600 --> 00:06:18,400
So I was working more in a prototype space.

86
00:06:18,400 --> 00:06:21,520
We did have to build actual products and test them.

87
00:06:21,520 --> 00:06:26,400
But it wasn't really sort of at that level, say scaling out to hundreds of thousands of

88
00:06:26,400 --> 00:06:33,040
users or surfacing it across a different, unique customer base.

89
00:06:33,040 --> 00:06:36,440
So I started getting more of an interest in how it was being used in different industries

90
00:06:36,440 --> 00:06:40,640
and through a colleague, they connected me with Urban Outfitters, which recently stood

91
00:06:40,640 --> 00:06:44,840
up a data science and advanced analytics organization.

92
00:06:44,840 --> 00:06:47,160
And I've been there for about a year.

93
00:06:47,160 --> 00:06:54,160
Well that strikes me as a pretty significant shift from a defense contractor to kind

94
00:06:54,160 --> 00:06:55,400
of a hit retailer.

95
00:06:55,400 --> 00:06:56,400
Yeah, yeah.

96
00:06:56,400 --> 00:07:02,480
Well, I mean, as a natural transition to move from working with electronic warfare officers

97
00:07:02,480 --> 00:07:09,680
to trying to sell more dresses or match customers with the best dress that they believe that

98
00:07:09,680 --> 00:07:11,200
they should be wearing.

99
00:07:11,200 --> 00:07:17,440
Yeah, it does sound strange, but what's really funny is when I kind of started with the

100
00:07:17,440 --> 00:07:24,240
job and kind of really understood the landscape, the underlying technologies that are being

101
00:07:24,240 --> 00:07:30,400
used for both are very similar when it comes down to the approaches or the math or the deep

102
00:07:30,400 --> 00:07:32,640
learning models, machine learning models.

103
00:07:32,640 --> 00:07:34,240
It's just using it in a different way.

104
00:07:34,240 --> 00:07:39,240
And I kind of landed on that earlier on in my career when my originally my focus was

105
00:07:39,240 --> 00:07:45,520
on strict sort of wireless system signal processing and moving into more machine learning and

106
00:07:45,520 --> 00:07:48,600
researching some of the math behind there.

107
00:07:48,600 --> 00:07:54,480
Because when you kind of have to decode a message over the air coming from your phone that has

108
00:07:54,480 --> 00:07:58,800
an estimation that's going on in the background and the underlying math that's done there is

109
00:07:58,800 --> 00:08:02,360
very similar to what may be done in various machine learning domains.

110
00:08:02,360 --> 00:08:05,880
So there's sort of a lot of overlap when you get down to that level.

111
00:08:05,880 --> 00:08:14,200
And similarly for analyzing some of the spectrograms or the spectrum at Lockheed Martin, you can

112
00:08:14,200 --> 00:08:18,600
look at that almost as an image and you're doing image processing on it similar to how you

113
00:08:18,600 --> 00:08:25,560
would take a picture of a model and address and analyze the characteristics of that dress.

114
00:08:25,560 --> 00:08:31,240
So there's sort of very similar space, definitely a completely different domain and they both

115
00:08:31,240 --> 00:08:34,440
sort of have unique challenges.

116
00:08:34,440 --> 00:08:37,800
My background is electrical engineering as well.

117
00:08:37,800 --> 00:08:44,560
My graduate work was on the networking side like stochastic modeling of microcells and things

118
00:08:44,560 --> 00:08:45,560
like that.

119
00:08:45,560 --> 00:08:51,800
So I'm very, very curious about some of the work that you did in your past life and looking

120
00:08:51,800 --> 00:08:57,400
at applying deep learning to the frequency domain and things like that.

121
00:08:57,400 --> 00:09:00,040
But we're not going to talk about that now.

122
00:09:00,040 --> 00:09:04,760
We're going to talk about selling dresses.

123
00:09:04,760 --> 00:09:12,520
So you put together a couple of our two part blog series on this project in which you

124
00:09:12,520 --> 00:09:22,560
are using deep learning and in particular computer vision and in particular custom vision

125
00:09:22,560 --> 00:09:28,920
APIs to do what you called automated fashion product attribution.

126
00:09:28,920 --> 00:09:30,440
So what's the business problem there?

127
00:09:30,440 --> 00:09:36,800
What is fashion, what is product attribution and why is it important for urban outfitters?

128
00:09:36,800 --> 00:09:37,800
Yeah, sure.

129
00:09:37,800 --> 00:09:44,080
So in terms of product attribution, we'll start with like take a picture of a dress on

130
00:09:44,080 --> 00:09:46,960
any sort of e-commerce website.

131
00:09:46,960 --> 00:09:50,960
On that dress there are certain attributes about that particular product.

132
00:09:50,960 --> 00:09:57,840
So for dresses that may be characteristics such as the sleeve length, it could be the

133
00:09:57,840 --> 00:09:58,840
neckline.

134
00:09:58,840 --> 00:10:04,520
So is it a deep V, is it a crew neck, the color, the pattern, the length of the dress, how

135
00:10:04,520 --> 00:10:10,880
far it kind of goes down the leg, the fabric composition, the list sort of goes on there.

136
00:10:10,880 --> 00:10:19,080
And those attributes sort of provide a textual metadata or description about the essence

137
00:10:19,080 --> 00:10:20,760
of that product.

138
00:10:20,760 --> 00:10:28,120
Traditionally, the descriptions may be fairly short based on limitations of being able

139
00:10:28,120 --> 00:10:34,000
to code in those attributes if you're going to be doing thousands of them a week or thousands

140
00:10:34,000 --> 00:10:35,160
of them a month.

141
00:10:35,160 --> 00:10:40,280
So what we were interested in is are there ways we can sort of one automate the process

142
00:10:40,280 --> 00:10:45,520
of attributing our products the way we currently attribute them.

143
00:10:45,520 --> 00:10:49,880
And then two, are there ways that we can sort of augment the existing attributes set

144
00:10:49,880 --> 00:10:57,800
that our merchants, buyers and web product team use today to kind of enhance the description

145
00:10:57,800 --> 00:10:58,800
of those products.

146
00:10:58,800 --> 00:11:04,520
Because the products themselves in terms of representation, you have the image itself,

147
00:11:04,520 --> 00:11:12,000
you have the attributes, you have the copy or the textual description and the title.

148
00:11:12,000 --> 00:11:15,880
So all of those are sort of good indicators of what that particular product is and how

149
00:11:15,880 --> 00:11:18,360
it can be categorized.

150
00:11:18,360 --> 00:11:22,280
The attributes themselves are used in various different ways across the business and this

151
00:11:22,280 --> 00:11:27,120
is probably common across a lot of the e-commerce domain.

152
00:11:27,120 --> 00:11:32,600
So one way is it's used for navigation filters for the customer online when they're shopping.

153
00:11:32,600 --> 00:11:36,800
So how do you filter on obviously things like size and color but also some of those other

154
00:11:36,800 --> 00:11:38,400
attributes I described earlier.

155
00:11:38,400 --> 00:11:44,000
So if somebody is shopping for a cocktail party that may be different than how they shop

156
00:11:44,000 --> 00:11:50,200
for business attire and it'd be that's helpful to have attributes or coding that kind of

157
00:11:50,200 --> 00:11:54,840
tailors one to the other so that you can filter your site to give them the best sort of online

158
00:11:54,840 --> 00:11:57,080
experience as possible.

159
00:11:57,080 --> 00:12:03,680
Another way is search so you can treat those attributes as keywords and if you can identify

160
00:12:03,680 --> 00:12:10,760
some type of correlation or distance between those keywords that's a good way of enhancing

161
00:12:10,760 --> 00:12:19,520
the search beyond just strict keyword look up if it can sort of identify those associations.

162
00:12:19,520 --> 00:12:24,880
That's more on the front side for customer facing but the business uses it, uses the attributes

163
00:12:24,880 --> 00:12:31,280
in other different ways on the back end so think planning and forecasting.

164
00:12:31,280 --> 00:12:39,320
So how do we know as a company how many floral prints, midi dresses do we want to buy for

165
00:12:39,320 --> 00:12:47,000
next summer or how many even at the top level how many coats versus pants versus blouses

166
00:12:47,000 --> 00:12:49,520
need to be purchased season by season.

167
00:12:49,520 --> 00:12:55,000
So that kind of goes into the planning and forecasting side of trying to identify and

168
00:12:55,000 --> 00:12:59,920
kind of cluster these different products based on some of these attributes and if things

169
00:12:59,920 --> 00:13:06,400
are either misattributed or insufficiently attributed it can heavily sway the direction

170
00:13:06,400 --> 00:13:14,200
that some of those forecasts or even retrospective analysis of prior performance goes.

171
00:13:14,200 --> 00:13:20,080
What's the history of product attribution at a place like Urban Outfit as you just kind

172
00:13:20,080 --> 00:13:25,200
of relying on the data that comes from the manufacturers and you haven't done much

173
00:13:25,200 --> 00:13:31,000
with images previously or is there kind of historical work that's been done to try to do

174
00:13:31,000 --> 00:13:32,000
this.

175
00:13:32,000 --> 00:13:33,000
Sure.

176
00:13:33,000 --> 00:13:36,400
So my understanding is it's sort of done in a couple different stages.

177
00:13:36,400 --> 00:13:42,640
The first is during what we're calling the buying process or even the planning process.

178
00:13:42,640 --> 00:13:47,280
So that's when a product is purchase orders put out for it.

179
00:13:47,280 --> 00:13:50,760
It has attributes like you said perhaps from the manufacturer.

180
00:13:50,760 --> 00:13:54,720
We sometimes get samples from that product that we can sort of confirm those attributes

181
00:13:54,720 --> 00:13:58,320
before they get coded into the system on the front side of things.

182
00:13:58,320 --> 00:14:01,040
Then the order goes through and several weeks may go by.

183
00:14:01,040 --> 00:14:02,800
We get the product in house.

184
00:14:02,800 --> 00:14:05,920
We decide to list that product onto the website.

185
00:14:05,920 --> 00:14:10,920
That's when the web team comes in and they may sort of enhance or update some of those

186
00:14:10,920 --> 00:14:17,280
core attributes to Taylor to the current trends, current season or the current creative elements

187
00:14:17,280 --> 00:14:21,040
that are on the website to showcase some of those products.

188
00:14:21,040 --> 00:14:27,480
So on the front end it may be very simple just sort of colors, patterns, sizes, brands,

189
00:14:27,480 --> 00:14:28,480
et cetera.

190
00:14:28,480 --> 00:14:33,520
And then when it gets closer to customer facing website side, that's when it may be

191
00:14:33,520 --> 00:14:38,920
enriched with some of those examples telling you earlier like black dresses that may be

192
00:14:38,920 --> 00:14:41,920
good for a cocktail event.

193
00:14:41,920 --> 00:14:45,800
Historically that has been done very, it is a manual process.

194
00:14:45,800 --> 00:14:51,560
And it's important that at least at some point in that chain does get reviewed by an actual

195
00:14:51,560 --> 00:14:59,040
person because they're sort of so important into describing that product itself.

196
00:14:59,040 --> 00:15:04,760
Long term, the goal is to sort of, again automate some of that, but still have somebody

197
00:15:04,760 --> 00:15:11,320
always in the loop to confirm or if the system identifies errors to manually kind of override

198
00:15:11,320 --> 00:15:13,480
those errors.

199
00:15:13,480 --> 00:15:20,640
So we've also investigated in different vendors that provide this capability as well.

200
00:15:20,640 --> 00:15:25,720
And kind of experimented on and off and to be honest, urban outfiters as a whole does

201
00:15:25,720 --> 00:15:28,040
work with dozens of different vendors.

202
00:15:28,040 --> 00:15:33,680
So at various times we may be trying out different attributes feature sets that come from

203
00:15:33,680 --> 00:15:37,520
different vendors and using it in different contexts.

204
00:15:37,520 --> 00:15:43,640
To date though, the primary force is sort of manually driven by the merchants, the buyers,

205
00:15:43,640 --> 00:15:45,280
and the web product team.

206
00:15:45,280 --> 00:15:46,280
Okay.

207
00:15:46,280 --> 00:15:55,040
And so faced with this challenge of trying to interpret visual images and pull out these

208
00:15:55,040 --> 00:16:00,720
different attributes, there are lots of ways that you could tackle this problem with machine

209
00:16:00,720 --> 00:16:09,080
learning, what you did was turn to some of the cloud-based APIs that are available.

210
00:16:09,080 --> 00:16:15,280
Can you talk a little bit about your motivation there and the various considerations?

211
00:16:15,280 --> 00:16:16,280
Sure.

212
00:16:16,280 --> 00:16:26,840
So we actually started with building experimental in-house models using primarily like Keras built

213
00:16:26,840 --> 00:16:33,800
on like TensorFlow, sometimes PyTorch, and kind of tweaking existing models, retraining

214
00:16:33,800 --> 00:16:40,320
them, fine-tuning them, or I think what's called essentially transfer learning, to I reclassify

215
00:16:40,320 --> 00:16:44,200
those images based on whatever labels we have.

216
00:16:44,200 --> 00:16:47,240
So we did play around with that a little to start.

217
00:16:47,240 --> 00:16:48,560
That's of course coming in.

218
00:16:48,560 --> 00:16:52,160
That's the first thing that I was interested in doing, very excited to get my hand on some

219
00:16:52,160 --> 00:16:57,480
of the data that we had in-house, because we do have a large collection of hundreds of

220
00:16:57,480 --> 00:17:00,840
thousands of products with some labels on them.

221
00:17:00,840 --> 00:17:03,240
So why not straightening data to play with?

222
00:17:03,240 --> 00:17:09,880
That was one nice thing moving over to this industry, and Urban Outfitters from Lockheed

223
00:17:09,880 --> 00:17:16,720
Martin is Lockheed Martin in a research lab, since we kind of were working on essentially

224
00:17:16,720 --> 00:17:20,920
prototypes and on more of the advanced side.

225
00:17:20,920 --> 00:17:25,480
We were usually trying to generate our data, or it was also very expensive to acquire data,

226
00:17:25,480 --> 00:17:29,080
particularly setting up receivers and things to collect some of those signals.

227
00:17:29,080 --> 00:17:34,400
So being able to kind of walk in on day one and have the ability to tap into some of

228
00:17:34,400 --> 00:17:38,040
the rich product imagery and descriptions was very nice.

229
00:17:38,040 --> 00:17:43,480
At the same time, that was also a unique engineering exercise for me, like having to go through

230
00:17:43,480 --> 00:17:49,200
that amount of data, and sort of in an efficient manner to kind of get it into a point where

231
00:17:49,200 --> 00:17:54,560
it can train, as with many machine learning or deep learning applications, like 90% of

232
00:17:54,560 --> 00:17:55,880
the work.

233
00:17:55,880 --> 00:17:58,920
And that's where some of this kind of came in.

234
00:17:58,920 --> 00:18:05,480
We started seeing some of these machine auto-ML type of solutions come into market.

235
00:18:05,480 --> 00:18:09,600
We actually worked with Google on their alpha release of their auto-ML, so that was our

236
00:18:09,600 --> 00:18:16,480
first entrance into it, since they're sort of we interact with them pretty often.

237
00:18:16,480 --> 00:18:22,000
And from my perspective, or I should say our data science teams perspective, our team

238
00:18:22,000 --> 00:18:23,000
is fairly small.

239
00:18:23,000 --> 00:18:29,120
It's only a couple of people right now in the core data science group, and maybe a dozen

240
00:18:29,120 --> 00:18:35,160
total across data science, advanced analytics in the organization we work.

241
00:18:35,160 --> 00:18:40,400
So we have a lot of projects that we're interested in doing, and really it comes down to what's

242
00:18:40,400 --> 00:18:43,440
the most effective use of our time.

243
00:18:43,440 --> 00:18:49,000
And I was sort of attracted to at least trying out some of these auto-ML solutions to see

244
00:18:49,000 --> 00:18:54,240
how far can we get with sort of this automated solution?

245
00:18:54,240 --> 00:18:59,200
And is it good enough to use in production and satisfy the majority of our needs?

246
00:18:59,200 --> 00:19:05,280
It may not be 100% perfect, it may not beat the state of the art, but does it move the

247
00:19:05,280 --> 00:19:10,080
needle enough to warrant sort of going to a managed service versus building it in

248
00:19:10,080 --> 00:19:15,120
house, and that allows to focus on efforts that say use those attributes rather than having

249
00:19:15,120 --> 00:19:18,080
to generate those attributes, if that makes sense.

250
00:19:18,080 --> 00:19:24,840
When you were experimenting with the building this in-house with Keras and TensorFlow and

251
00:19:24,840 --> 00:19:35,320
the like, did you get far enough that as you started to explore the hosted services,

252
00:19:35,320 --> 00:19:42,520
you had something to compare to or did you run into, were you able to build in-house models

253
00:19:42,520 --> 00:19:45,240
to perform the tasks that you were trying to perform?

254
00:19:45,240 --> 00:19:50,640
Yeah, I'd say we actually started building the in-house models in the initiative kind

255
00:19:50,640 --> 00:19:56,440
of started in parallel with trying some of the managed services as well as in-house models.

256
00:19:56,440 --> 00:20:01,440
And in terms of like what a model like this looks like, the inputs would be the image

257
00:20:01,440 --> 00:20:07,680
and which in this case, the image for urban outfitters, if you go on one of our websites,

258
00:20:07,680 --> 00:20:13,080
is a model wearing a product, sometimes with a clear colored background, sometimes with

259
00:20:13,080 --> 00:20:16,920
a very rich atmospheric background.

260
00:20:16,920 --> 00:20:26,000
So some of our photography we shoot on site with, say, photos of some of the models wearing

261
00:20:26,000 --> 00:20:30,520
the products in a city or urban environment or in a desert environment.

262
00:20:30,520 --> 00:20:34,840
So there's some of that scenery is in there in the background as well.

263
00:20:34,840 --> 00:20:39,880
So we were just trying feeding the image in raw into one of these models and then the

264
00:20:39,880 --> 00:20:43,720
output would be to start a single attribute for that model.

265
00:20:43,720 --> 00:20:49,360
And that would be, say, a sleeve length and that sleeve length would have various values

266
00:20:49,360 --> 00:20:50,360
that you're trying to predict.

267
00:20:50,360 --> 00:20:51,360
Is it sleeveless?

268
00:20:51,360 --> 00:20:52,360
Is it short-sleeved?

269
00:20:52,360 --> 00:20:53,360
Is it three-quarters?

270
00:20:53,360 --> 00:20:56,560
Is it long-sleeved?

271
00:20:56,560 --> 00:20:59,400
From there we kind of built out a bank of those models.

272
00:20:59,400 --> 00:21:03,720
So one that would say do sleeve length, one that does neckline, one that does the dress

273
00:21:03,720 --> 00:21:07,240
length, one that does dress color, et cetera.

274
00:21:07,240 --> 00:21:12,000
And what we realized is when we're building out those models, both sort of in-house and

275
00:21:12,000 --> 00:21:18,320
with some of these services is that it really, that some attributes are really easy to identify

276
00:21:18,320 --> 00:21:20,000
like sleeve length, maybe one.

277
00:21:20,000 --> 00:21:26,480
Others are far more subtle, like the occasion of a dress, like, in my occasion we mean

278
00:21:26,480 --> 00:21:30,320
under what occasion would you want to wear a dress like this.

279
00:21:30,320 --> 00:21:34,360
We've also tried different types of products, so like tops and bottoms and doing the same

280
00:21:34,360 --> 00:21:36,120
thing with those attributes.

281
00:21:36,120 --> 00:21:42,280
So the challenge, I'd say the challenge across the two was sort of the same in that some

282
00:21:42,280 --> 00:21:48,400
attributes were far more challenging to discern the individual values between the others.

283
00:21:48,400 --> 00:21:56,440
And another challenge we ran into with these images is the complexity of the images required

284
00:21:56,440 --> 00:22:02,000
to require sometimes a level of segmentation in order to get the best results.

285
00:22:02,000 --> 00:22:09,600
So if we had just photo flats meaning it's just the product laid on a flat white background,

286
00:22:09,600 --> 00:22:14,200
then that takes out any background, it takes out any model, and it takes out any distortions

287
00:22:14,200 --> 00:22:17,120
of the product based on the models pose.

288
00:22:17,120 --> 00:22:21,000
But most of the time actually all the time we have these more creative images, which are

289
00:22:21,000 --> 00:22:25,920
great for providing context to the customer and how they can sort of wear this and under

290
00:22:25,920 --> 00:22:32,680
what occasions, but the challenge from the data side is how do you, if we're interested

291
00:22:32,680 --> 00:22:37,360
in just the essence of the product itself, it's hard to isolate the characteristics of

292
00:22:37,360 --> 00:22:38,760
the product from the background.

293
00:22:38,760 --> 00:22:43,760
So that's one thing that we realized really early on in both the in-house models and these

294
00:22:43,760 --> 00:22:48,280
managed services is the importance of isolating the product.

295
00:22:48,280 --> 00:22:53,640
And the same goes with if you have multiple products in a single photo.

296
00:22:53,640 --> 00:23:00,320
So if somebody's wearing a blouse, jeans, a hat, and some shoes, then the other products

297
00:23:00,320 --> 00:23:05,880
if you don't sort of isolate it can sort of mix in and bias the models that you're creating.

298
00:23:05,880 --> 00:23:08,200
That was probably the biggest ones that we ran into.

299
00:23:08,200 --> 00:23:11,920
So you started working with these custom vision services.

300
00:23:11,920 --> 00:23:20,040
Maybe walk us through kind of your methodology for trying out these various services.

301
00:23:20,040 --> 00:23:24,240
How did you even, like you didn't, did you use all of the ones that were available at

302
00:23:24,240 --> 00:23:26,080
the time or did you create a short list?

303
00:23:26,080 --> 00:23:29,640
How did you even choose which ones to look at?

304
00:23:29,640 --> 00:23:34,360
Yeah, we, so we isolated down, we wanted to narrow down to about five or six to keep

305
00:23:34,360 --> 00:23:36,000
this scope reasonable.

306
00:23:36,000 --> 00:23:42,720
And from there we just chose the ones that sort of showed up the most and started with

307
00:23:42,720 --> 00:23:44,200
some of the heavy hitters.

308
00:23:44,200 --> 00:23:53,040
So think like Google IBM, so to summarize a list that we tried, there was Google, AutoML,

309
00:23:53,040 --> 00:23:54,600
that's currently in beta.

310
00:23:54,600 --> 00:24:01,280
There's Salesforce Einstein Vision, which is driven by the Salesforce IBM Watson, had a

311
00:24:01,280 --> 00:24:03,040
vision solution.

312
00:24:03,040 --> 00:24:08,920
There was a company called Clarify, which is a smaller business, but they were started

313
00:24:08,920 --> 00:24:15,000
by a fairly prominent figure in deep learning and have been growing since 2013 issue.

314
00:24:15,000 --> 00:24:19,640
I want to say, yeah, that's Matt Zeeler who's been interviewed on the show before.

315
00:24:19,640 --> 00:24:21,040
Yes.

316
00:24:21,040 --> 00:24:25,400
And then there was also Microsoft Azure has their custom vision model.

317
00:24:25,400 --> 00:24:29,360
So we kind of stuck with the bigger ones that we found and then since Clarify had some

318
00:24:29,360 --> 00:24:33,760
income and see and experience in there, we added that as well.

319
00:24:33,760 --> 00:24:40,000
More recently after the conference presentation that I gave at rework deep learning London

320
00:24:40,000 --> 00:24:50,000
in September, we signed up for the Fast AI version three course and that started in October

321
00:24:50,000 --> 00:24:51,240
and November timeframe.

322
00:24:51,240 --> 00:24:56,360
And we were just curious how well would these models work just applying less than one, less

323
00:24:56,360 --> 00:25:02,360
than two, a Fast AI and how they would sort of compare to some of those.

324
00:25:02,360 --> 00:25:05,840
So that one came in just because that had a lot of momentum.

325
00:25:05,840 --> 00:25:09,480
They kind of had some close to out of box capabilities.

326
00:25:09,480 --> 00:25:15,160
But we were looking for ones that seemed fairly prominent, had various capabilities such

327
00:25:15,160 --> 00:25:22,760
as batch uploads, being able to automatically serve a model afterwards in some scalable

328
00:25:22,760 --> 00:25:27,440
manner if we wanted to run this in production.

329
00:25:27,440 --> 00:25:32,120
Something that had reasonable APIs or interfaces so that we can query it essentially as a

330
00:25:32,120 --> 00:25:34,560
service and some level of support.

331
00:25:34,560 --> 00:25:39,840
So there's certainly a lot of different people, a lot of players in this game.

332
00:25:39,840 --> 00:25:42,960
But those are just sort of the ones that we landed that we thought were representative

333
00:25:42,960 --> 00:25:45,680
of the current landscape.

334
00:25:45,680 --> 00:25:52,080
As you explore these different services, you know, so what degree did you find that the

335
00:25:52,080 --> 00:25:58,160
service itself is commoditized, meaning there's not a lot of difference in performance, there's

336
00:25:58,160 --> 00:26:07,440
not a lot of difference in features, or are there, you know, fairly significant differences

337
00:26:07,440 --> 00:26:12,560
from one to the next, again, performance features, usability, I think is something you

338
00:26:12,560 --> 00:26:13,800
looked at as well.

339
00:26:13,800 --> 00:26:18,400
Yeah, we broke it up in the two high level dimensions.

340
00:26:18,400 --> 00:26:23,280
One was performance, which includes your standard metrics like classification accuracy,

341
00:26:23,280 --> 00:26:29,200
AUC, and then usability, which includes all of the other factors that one may consider

342
00:26:29,200 --> 00:26:34,240
when using this, not from an academic perspective, but more from a business perspective.

343
00:26:34,240 --> 00:26:41,440
So that includes things like cost, the overall user interface in interacting with it, how

344
00:26:41,440 --> 00:26:48,600
easy is it to upload data, how easy is it to serve data, is it quick to serve or perform

345
00:26:48,600 --> 00:26:52,520
inference, how long does it take to train the models, how long does it take to tweak the

346
00:26:52,520 --> 00:26:58,960
models, and we tried to look at it both from a data scientist's perspective, as well as

347
00:26:58,960 --> 00:27:05,080
from a, anybody who is not necessarily an ML machine learning practitioner, so think

348
00:27:05,080 --> 00:27:10,480
like a traditional software developer or an analyst, and the reason we did that is because

349
00:27:10,480 --> 00:27:16,200
that's really where the target audience is for these, these at least automated machine

350
00:27:16,200 --> 00:27:21,560
learning products, the larger space are those people that have data, they're able to acquire

351
00:27:21,560 --> 00:27:25,440
labels, they're interested in building these models, but they don't necessarily want

352
00:27:25,440 --> 00:27:33,680
to take several different courses in machine learning and identify how to build one out.

353
00:27:33,680 --> 00:27:39,240
So on that front, we did have sort of an analyst slash intern kind of using these tools

354
00:27:39,240 --> 00:27:43,800
from that perspective, and then other more experienced data scientists used the tool

355
00:27:43,800 --> 00:27:47,960
too, and kind of collected our thoughts on some of the challenges we identified.

356
00:27:47,960 --> 00:27:53,840
We also tried to diversify the data sets that we're operating on, so we had one data

357
00:27:53,840 --> 00:27:59,600
set that we generated that was, we're calling it the Urban Outfitters Dress Data Set, which

358
00:27:59,600 --> 00:28:07,520
is just a collection of about 15 or 5500 dresses, and labeled very simply with just what's

359
00:28:07,520 --> 00:28:13,800
the dress pattern in terms of floral, solid stripes or not addressed, we're not addressed

360
00:28:13,800 --> 00:28:18,240
as something indicating it's very obviously not addressed like shoes.

361
00:28:18,240 --> 00:28:22,720
The goal there was just to have something that was kind of constrained and isolated.

362
00:28:22,720 --> 00:28:27,040
Not necessarily the actual data we'd want to use in real-time operations, but something

363
00:28:27,040 --> 00:28:33,160
that was controlled so that we can compare all the services against each other.

364
00:28:33,160 --> 00:28:38,120
So that was the one we had in-house, but we also used three public benchmark data sets.

365
00:28:38,120 --> 00:28:48,680
So we used C4-10 MNIST and fashion MNIST. So C4-10, I think they're 32 by 32 objects or

366
00:28:48,680 --> 00:28:54,560
images of different objects. MNIST is the digits, data set, and fashion MNIST is sort

367
00:28:54,560 --> 00:29:00,600
of the equivalent of MNIST, but using very simple looking fashion apparel, like shirts,

368
00:29:00,600 --> 00:29:07,200
pants, dresses, etc. So that way we sort of had a mix of different types of images going

369
00:29:07,200 --> 00:29:12,560
into this and we weren't sort of biasing towards the one dress data set that we had in-house.

370
00:29:12,560 --> 00:29:17,800
Did you get interesting information by doing C4-10 MNIST?

371
00:29:17,800 --> 00:29:23,920
One of the challenges I think in this industry is we talk about kind of being over-fitted

372
00:29:23,920 --> 00:29:29,360
on data sets like MNIST and C4-10. I'd expect all of these services to do pretty well on

373
00:29:29,360 --> 00:29:31,400
these. Was that the case or no?

374
00:29:31,400 --> 00:29:36,360
Yeah, if I recall, they all did pretty well. None of them quite got to the point of the

375
00:29:36,360 --> 00:29:44,840
true best scoring public benchmark. That's mainly because these algorithms that the services

376
00:29:44,840 --> 00:29:49,800
are using usually fall into from what I've seen one or one of two categories. The first

377
00:29:49,800 --> 00:29:55,240
one is transfer learning. So that's where you've taken already trained model, very deep

378
00:29:55,240 --> 00:30:01,400
trained model, cut off the head of it, have your own labels on the end and just retrain

379
00:30:01,400 --> 00:30:06,600
that sort of final layer or possibly tweak some of the layers in between. Then the other

380
00:30:06,600 --> 00:30:11,200
one, so that's the majority of them. Google Cloud, I think, was the one that stood out as

381
00:30:11,200 --> 00:30:16,160
different in that they used something called an architecture search or neural architecture

382
00:30:16,160 --> 00:30:21,880
search using something called NASNET that they published shortly before releasing AutoML.

383
00:30:21,880 --> 00:30:26,520
In that case, it's trying to find different configurations of the underlying neural network

384
00:30:26,520 --> 00:30:32,920
architecture that fit that data best. In the same with the in-house models, we were basically

385
00:30:32,920 --> 00:30:38,920
doing a in-house transfer learning on ResNet models. In all of those, you're already fit

386
00:30:38,920 --> 00:30:44,280
to or you're not training necessarily from scratch and training for hours with a really

387
00:30:44,280 --> 00:30:49,440
deep model. You're not going to hit those best performing numbers that you see in terms

388
00:30:49,440 --> 00:30:54,520
of the benchmarks out there, but they all get reasonably well. So if I recall, there

389
00:30:54,520 --> 00:31:00,280
may be fractions of a percent or a few percent often some of those data sets, and they all

390
00:31:00,280 --> 00:31:06,840
sort of performed very similarly. In fact, some of them, if I recall, may have even performed,

391
00:31:06,840 --> 00:31:13,160
we found they performed slightly better than we expected. It's mainly because that data

392
00:31:13,160 --> 00:31:17,760
set is, like you said, either A, already incorporated into some of those models that's already

393
00:31:17,760 --> 00:31:24,960
learned or B, essentially too small or too simple to be able to take a very large technique

394
00:31:24,960 --> 00:31:30,320
like neural architecture search and find in the best solution for. So, but across the

395
00:31:30,320 --> 00:31:37,760
board, for all those and even our internal dresses data set, performance as a whole was

396
00:31:37,760 --> 00:31:47,040
not a differentiator among any of the services that we found because most of them fell essentially

397
00:31:47,040 --> 00:31:53,280
within what one may deem the standard error for that data set. So like plus or minus a fraction

398
00:31:53,280 --> 00:31:58,480
or a couple percent. So if you're trying to eke out the absolute best performance for your

399
00:31:58,480 --> 00:32:04,160
use case, that may be very important for for our applications in sort of e-commerce or kind

400
00:32:04,160 --> 00:32:09,760
of enhancing these attributes for our internal teams. A fraction of percent is not going to make

401
00:32:09,760 --> 00:32:14,720
a huge difference. So it really came to that usability side that was more important for us.

402
00:32:14,720 --> 00:32:19,360
So that was one interesting finding is that there wasn't really any one major leader in terms

403
00:32:19,360 --> 00:32:26,160
of absolute performance. So it comes to all those other factors. This past summer, I had an

404
00:32:26,160 --> 00:32:34,480
intern. It was my daughter, actually, and she did a similar project working on or working with

405
00:32:34,480 --> 00:32:40,720
the speech to text API. So we had a bunch of podcasts. We had a bunch of transcripts and the

406
00:32:40,720 --> 00:32:49,440
idea was, could we build an automated pipeline to kind of transcribe our podcasts and using

407
00:32:49,440 --> 00:32:56,720
some of these similar kinds of APIs and ultimately maybe do some interesting things to help it

408
00:32:56,720 --> 00:33:04,080
perform better on kind of domain specific words. So this project started out with her looking

409
00:33:04,080 --> 00:33:11,120
at a bunch of APIs. And one of the things that we found pretty early on, like the initial plan

410
00:33:11,120 --> 00:33:19,680
was, we've got these APIs. We can throw a bunch of podcasts or audio samples at them and

411
00:33:19,680 --> 00:33:28,720
just kind of see how they do. But we found that each of the models had a bunch of like kind of,

412
00:33:28,720 --> 00:33:33,760
you know, they have kind of knobs, configuration parameters like, you know, Google supported three

413
00:33:33,760 --> 00:33:42,160
different models, telephone, video and default. They had different sample rates and things like

414
00:33:42,160 --> 00:33:49,760
that. All of these things are specific to audio. And the result of all that was that, you know,

415
00:33:49,760 --> 00:33:56,080
we certainly could not kind of compare these, you know, very easily using their default settings.

416
00:33:56,080 --> 00:34:02,160
But even when we tweaked the individual settings of a different model, we never really had a strong

417
00:34:03,200 --> 00:34:10,720
sense that we were able to compare apples to apples because, you know, we were kind of custom-fitting

418
00:34:12,320 --> 00:34:19,120
parameters for each of these runs. Is there a similar dynamic on the vision side? And if so,

419
00:34:19,120 --> 00:34:26,880
how did you address that? Yeah. So I think for on the vision side, the training and the, sort of,

420
00:34:26,880 --> 00:34:32,720
building the model itself is completely automated. So there's not much you can really do in terms of

421
00:34:33,360 --> 00:34:40,960
how to tweak knobs there. You can sort of iteratively update the model by providing new

422
00:34:42,240 --> 00:34:46,960
images or relabeling images as you go. But we did see that there were sort of knobs

423
00:34:46,960 --> 00:34:55,840
in terms of how you interact with the model after it's been trained. So not quite a knob,

424
00:34:55,840 --> 00:35:02,640
but a feature. One of the services offers human labeling for mislabeled or unlabeled images

425
00:35:02,640 --> 00:35:06,560
so that you can very rapidly kind of update your data set without having to do it from scratch.

426
00:35:07,760 --> 00:35:14,000
I think that one was Google. Clarify stands out as the one that was most quickly able to kind of

427
00:35:14,000 --> 00:35:20,400
through the interface, click on an image, relabel that image if it happened to be a false

428
00:35:21,040 --> 00:35:26,480
positive false negative and click retrain and get a response in a matter of like seconds.

429
00:35:27,120 --> 00:35:32,000
So that in that case, that's a sort of knob that's useful if you're rapidly interacting with it

430
00:35:32,000 --> 00:35:36,160
and you have a really messy data set that you're trying to use the service, not just to build models,

431
00:35:36,160 --> 00:35:42,480
but sort of to iterate you working with the model to iterate on that data set to kind of refine

432
00:35:42,480 --> 00:35:48,400
both the model as well as the quality of your the labels in your data. So we found more less

433
00:35:48,400 --> 00:35:53,760
on knobs in terms of the performance because it was a fully managed machine learning, so like

434
00:35:54,400 --> 00:35:59,680
machine learning as a service, but more on the usability side. And at last point that you are

435
00:35:59,680 --> 00:36:07,360
mentioning is that this feature that you are describing is this feature where you're able to

436
00:36:07,360 --> 00:36:15,520
identify mislabeled or misclassified images in a given run and kind of automatically tag those

437
00:36:15,520 --> 00:36:21,040
to get put into your training set for future runs. Yeah, yeah, that's that's the one there. Okay,

438
00:36:21,840 --> 00:36:27,680
cool. You know, and part of your analysis, you talked about this challenge that you ran into

439
00:36:27,680 --> 00:36:35,520
around data poisoning. Can you elaborate on that a little bit? Yes, so this goes to sort of the

440
00:36:35,520 --> 00:36:42,480
things that one should be careful with when using these types of services. The you don't want

441
00:36:42,480 --> 00:36:47,120
to look at these services as just a turnkey solution where you just give it the data. It's going

442
00:36:47,120 --> 00:36:51,120
to give you the perfect model and you don't really have to do much after that, particularly if you're

443
00:36:51,120 --> 00:36:57,280
sort of a manager that needs to plan time in deploying these type of products and allocating

444
00:36:57,280 --> 00:37:05,120
resources to it. So one interesting one we came into was if you what we have is for each

445
00:37:05,120 --> 00:37:10,320
product, there could be several different photos for it. So there could be a front-facing photo

446
00:37:10,320 --> 00:37:16,960
of a dress, a rear-facing side, different angles, zoomed in photos of the product. And the one

447
00:37:16,960 --> 00:37:24,800
example I think really resonated was a photo of a model wearing a dress and we, sorry, it was

448
00:37:24,800 --> 00:37:29,280
addressed with roughly four or five photos of that model wearing it with different angles and

449
00:37:29,280 --> 00:37:34,640
zooms. And then each one of those photos you could potentially treat as an independent sample.

450
00:37:35,520 --> 00:37:41,040
So each one of them is marked as a, in this case we, I think we're a classifying dress length,

451
00:37:41,040 --> 00:37:49,680
so is either a mini dress, mini dress or maxi dress, which is the different lengths. And if each

452
00:37:49,680 --> 00:37:58,720
one of those five images are treated independently, then if you use an arbitrary train validation

453
00:37:58,720 --> 00:38:05,360
test data split routine, then it's possible that that same exact product can end up both

454
00:38:05,360 --> 00:38:14,160
in your training, validation and test sets. And what that means is when you go to predict

455
00:38:14,160 --> 00:38:21,920
on say one of those test data, an image of that exact product was in training and then it happened

456
00:38:21,920 --> 00:38:27,520
to get spilled into test because of the way you split it, you could have trained to identify that

457
00:38:27,520 --> 00:38:34,800
that was a mini dress and then pass in a photo of that dress into the training side that is say

458
00:38:34,800 --> 00:38:41,520
a zoomed in picture of that dress of say just the top sides that's really accentuating say the

459
00:38:41,520 --> 00:38:47,280
neckline and maybe the sleeves. So you may not even see the bottom of that dress in that test photo,

460
00:38:47,840 --> 00:38:52,720
but the model will very accurately predict that it is a mini,

461
00:38:52,720 --> 00:38:58,080
light bottom length dress, which is not even in the photo. And the reason for that is because

462
00:38:58,080 --> 00:39:04,080
the model saw photos of that exact image under different angles in the training set.

463
00:39:04,880 --> 00:39:10,000
Right. So in that last statement, you said you'd pass in this view of the image into the the

464
00:39:10,000 --> 00:39:15,440
training side. I think you met the inference side. And so you're giving your passing your

465
00:39:15,440 --> 00:39:22,480
your trained model, cropped picture of the dress from which it could not reasonably predict the

466
00:39:22,480 --> 00:39:28,160
length of the dress and finding that it performs well, suggesting that it's picking up on it

467
00:39:28,160 --> 00:39:34,240
memorized basically that this dress is a mini dress. Yeah. And it may be for many other factors

468
00:39:34,240 --> 00:39:39,600
other than actually looking at features that indicate the length of the dress. So in that particular

469
00:39:39,600 --> 00:39:48,080
image, it had a nice clear blue background. The pattern of that dress was like a floral

470
00:39:48,640 --> 00:39:54,000
purple kind of themed dress that may have been unique to that dress out of the entire data set.

471
00:39:54,000 --> 00:40:01,120
So it may have just memorized that purple floral pattern is associated with an arbitrary labeled

472
00:40:01,120 --> 00:40:07,600
a mini length dress that we gave it. So one has to take care of that sort of if you're,

473
00:40:07,600 --> 00:40:14,400
if you just take, if we were to just walk in and take 50,000 photos with the labels on them and

474
00:40:14,400 --> 00:40:18,320
just allow it to do a random split, then they're going to kind of go all over the place. You need

475
00:40:18,320 --> 00:40:23,840
to kind of make sure that you cluster your products so that you're only feeding in

476
00:40:25,440 --> 00:40:31,280
products to training and independent products to validation or test. So that's just kind of one

477
00:40:31,280 --> 00:40:40,320
example we ran into. There's some other subtle ones that kind of go back to the point of segmentation.

478
00:40:41,040 --> 00:40:46,640
So there was one interesting example where the model was wearing a, I think it was a red and black

479
00:40:46,640 --> 00:40:55,840
striped dress and it kept ringing up as solid. And this was across both our in-house models and

480
00:40:55,840 --> 00:41:00,320
the managed service models. And we're like, why does this keep showing up as solid? It is clearly

481
00:41:00,320 --> 00:41:04,800
a striped dress. It looks a lot like the other striped dress that we stuck in there. So then we

482
00:41:04,800 --> 00:41:11,440
started poking around at it by sort of arbitrarily cropping the image in different areas and feeding

483
00:41:11,440 --> 00:41:18,880
in the cropped images to both the cloud services as well as our own classifier. And we realized that

484
00:41:18,880 --> 00:41:24,400
as we move the cropped image more and closer and closer to the hat that the model was wearing,

485
00:41:24,400 --> 00:41:31,680
which was a black solid hat, the more it was ringing up as solid. And then the more that we cropped

486
00:41:31,680 --> 00:41:38,160
that hat out and just focused just on the dress, it was stripes. So that's a case where for whatever

487
00:41:38,160 --> 00:41:46,240
reason it was tying that particular black solid hat. And that was the primary feature it was

488
00:41:46,240 --> 00:41:51,520
using to classify pattern instead of the dress itself. So it can be a little tricky to kind of like

489
00:41:51,520 --> 00:41:55,120
tame these models based on your input data. You have to be kind of be careful with that input

490
00:41:55,120 --> 00:41:59,200
data. And that goes back to what I was mentioning earlier where you can't just treat as a turnkey

491
00:41:59,200 --> 00:42:04,640
solution because that means in order to do that, you need to have a very clean data set. And in

492
00:42:04,640 --> 00:42:09,920
order to have a very well, in practice, at least I have never run into a perfectly clean data set

493
00:42:11,040 --> 00:42:17,840
in outside of academia. And even then they can be dirty sometimes. So that's sort of a cautionary

494
00:42:17,840 --> 00:42:23,120
tale to like really kind of inspect the outputs of these models. And that's actually where a lot of

495
00:42:23,120 --> 00:42:29,200
the effort that these managed services went into is the user interface after the model's built.

496
00:42:29,200 --> 00:42:34,080
How do you surface all of the false positives, false negatives? How do you categorize and cluster

497
00:42:34,080 --> 00:42:42,080
the different attributes that you're using your model to train on? And that way a user can

498
00:42:42,080 --> 00:42:45,360
without machine learning experience inspect and say, hey, something's fishy is there.

499
00:42:45,360 --> 00:42:52,160
So those are all great examples of things that people need to watch out for when they're working

500
00:42:52,160 --> 00:42:58,240
on with these products from a data perspective where there are other categories of kind of gotchas

501
00:42:58,240 --> 00:43:07,840
or did it all kind of boil down to data management data quality? I think it often boils down to the

502
00:43:07,840 --> 00:43:16,640
source of the data itself. There was an issue of sort of not necessarily an issue, but one thing

503
00:43:16,640 --> 00:43:22,480
to keep in mind is when do you think you're sort of getting to diminishing returns when tweaking

504
00:43:22,480 --> 00:43:30,080
and modifying these models? So if you hit sort of 92%, there's no real way of knowing whether or not

505
00:43:30,080 --> 00:43:36,560
you can get up to 98% without constantly tweaking and tweaking the model. And the same goes with

506
00:43:36,560 --> 00:43:42,240
sort of academic data sets. And these services allow you to, as I mentioned earlier, kind of

507
00:43:42,240 --> 00:43:48,560
relable mislabeled images, hit retrain and see the results again. But depending on the pricing

508
00:43:48,560 --> 00:43:53,280
structure, that can all come out of cost, whether it be a retraining cost or adding in additional

509
00:43:53,280 --> 00:43:57,360
images. So it's kind of tough to, as you're using these. And the same goes when you're kind of building

510
00:43:57,360 --> 00:44:06,720
these models offline or in-house in isolation. How do you know when to add more data to improve the

511
00:44:06,720 --> 00:44:12,400
model? How do you know when you need to improve the quality of the data? And then how do you know

512
00:44:12,400 --> 00:44:18,800
when it just sort of you hit? You hit the best you could do in a reasonable amount of time is one

513
00:44:19,280 --> 00:44:23,600
that was a little tricky. It's still data related, but it's more on the modeling side.

514
00:44:23,600 --> 00:44:30,160
So you've got in the blog post a couple of really interesting tables comparing the

515
00:44:31,200 --> 00:44:39,200
both usability and performance of the different services. And we'll link to the two blog posts

516
00:44:39,200 --> 00:44:46,560
in the show notes. Folks can go there to look at the detail. But the performance comparison

517
00:44:46,560 --> 00:44:55,200
table struck me as really interesting. In particular, the homegrown solution based on the Fast AI

518
00:44:55,200 --> 00:45:05,440
library performed very well state of the yard or at least let's say exhibited the best performance

519
00:45:05,440 --> 00:45:15,680
of all of the things that you compared on the public data sets, but not on your own urban outfit

520
00:45:15,680 --> 00:45:23,520
or dresses data set. That is where Google outperformed the other solutions. And now to be fair,

521
00:45:23,520 --> 00:45:33,840
the difference between Fast AI on your full data set and Google was very small. But I'm wondering

522
00:45:33,840 --> 00:45:39,680
if you have any kind of intuition as to what's happening here. Yeah, unfortunately that one's

523
00:45:39,680 --> 00:45:46,000
it's kind of tough to tease out exactly why Google kind of eaked out in performance over

524
00:45:46,960 --> 00:45:52,160
Fast AI because like you said, it was if I recall like a less than a percent or fraction of a

525
00:45:52,160 --> 00:46:00,320
percent. And for that data set, if I recall, there was in the test set 500 or so samples. So that could

526
00:46:00,320 --> 00:46:10,320
be just a few different images that happened to do slightly better in Google versus Fast AI. So

527
00:46:10,320 --> 00:46:16,640
factoring in the sample size of the test set, to me, that's almost sort of in the noise. The

528
00:46:16,640 --> 00:46:21,200
difference between those even though I think I probably highlighted them explicitly in that blog post

529
00:46:21,200 --> 00:46:28,800
there. So I kind of look at that as not necessarily that Google is performing better than Fast AI

530
00:46:28,800 --> 00:46:35,440
or that the other services are completely behind. But just it's from an from a operational

531
00:46:35,440 --> 00:46:40,000
standpoint, it's sort of in the noise like they all performs very similarly. Yeah, yeah.

532
00:46:41,040 --> 00:46:48,400
And so what was the what was kind of the the key takeaway here in terms of, you know, when you

533
00:46:48,400 --> 00:46:53,680
need to a tool to solve these kinds of problems for the business, where are you going to look?

534
00:46:53,680 --> 00:47:00,720
So we haven't actually decided to use any of the managed services. It was more of a experiment to

535
00:47:00,720 --> 00:47:06,960
to kind of see what was out there. Currently, our team is still kind of focused on using say

536
00:47:06,960 --> 00:47:13,440
Jupyter notebooks. We have been dabbling with the Fast AI solution as well. It's that's that was

537
00:47:13,440 --> 00:47:18,560
using like the less than one. So it was very quick to get started with it. And it also that

538
00:47:18,560 --> 00:47:23,760
library provides some visualization capability that's little easier than say, just manually rolling

539
00:47:24,640 --> 00:47:31,360
images through like MAT plotlib. But what we found, I wouldn't necessarily say we're forever staying

540
00:47:31,360 --> 00:47:37,520
away from these particular services. We may not even use them necessarily for a fully deployed

541
00:47:37,520 --> 00:47:45,840
model. But even just using it as a quick hand wavy benchmark of uploading some data, seeing how

542
00:47:45,840 --> 00:47:49,520
well these things, like if you have a fresh data set and you just want to see how it runs,

543
00:47:50,560 --> 00:47:54,640
running it through one of these services, getting in an interface so you can at least visualize

544
00:47:54,640 --> 00:48:01,920
some of the performance. And do it all roughly if you data set up reasonably well, roughly less than

545
00:48:01,920 --> 00:48:07,680
an hour. I mean, the training takes often less than five minutes surfaces you results pretty quickly.

546
00:48:08,480 --> 00:48:15,120
It's a nice way of very quickly getting a feel for what's in the realm of possible for these

547
00:48:15,120 --> 00:48:20,880
models, even for somebody who is an ML practitioner. So it kind of gives a nice sense of comfort that,

548
00:48:21,600 --> 00:48:28,720
yes, this is a tractable problem. You could get 80 plus percent in performance. And whether or not

549
00:48:28,720 --> 00:48:35,040
you kind of stick with that service to use it for deployment and productionize it. Or you just

550
00:48:35,040 --> 00:48:42,160
kind of use that as insight that your homegrown models may perform well. I found it much easier

551
00:48:42,160 --> 00:48:49,200
to kind of get up and running with that than wrangling the data in a custom in-house solution.

552
00:48:49,840 --> 00:48:58,880
Well, we've talked about the Fast AI library a few times. And I will add in a mention, a plug,

553
00:48:58,880 --> 00:49:07,440
you know, just as you found, you can do a lot going through the first couple of lessons of that

554
00:49:07,440 --> 00:49:13,600
Fast AI course using their library. And it is a fan favorite of folks in the Twimmel community. We've

555
00:49:13,600 --> 00:49:21,200
got a community that folks can find at twimmelai.com slash meetup, the Twimmel online meetup. And we've

556
00:49:21,760 --> 00:49:28,800
brought three cohorts of folks through the Fast AI course. The videos of our study groups are

557
00:49:28,800 --> 00:49:34,800
available on YouTube. And we're about to start, at least at the time of the recording of this

558
00:49:34,800 --> 00:49:42,400
group going through the part two course. I imagine with enough demand, we'll bring another group

559
00:49:42,400 --> 00:49:48,240
through the part one course again. But for anyone who's listening to this and wants to learn how to

560
00:49:48,240 --> 00:49:54,400
build their own state of the art vision models, the Fast AI course is a great place to start. And

561
00:49:54,400 --> 00:50:01,040
the Twimmel online meetup is a great place to get support in doing that. With that said, Tom,

562
00:50:01,040 --> 00:50:07,120
thanks so much for taking the time to share your work on this. Super interesting. And I appreciate

563
00:50:07,120 --> 00:50:10,880
you coming on the show. Yeah, thank you for having me.

564
00:50:14,640 --> 00:50:20,240
All right, everyone. That's our show for today. For more information on Tom or any of the topics

565
00:50:20,240 --> 00:50:28,320
covering in this episode, visit twimmelai.com slash talk slash 247. As always, thanks so much for

566
00:50:28,320 --> 00:50:38,320
listening and catch you next time.

