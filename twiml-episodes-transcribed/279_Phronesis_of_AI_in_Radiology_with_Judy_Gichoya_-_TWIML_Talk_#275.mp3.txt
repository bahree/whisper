Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
You are invited to join us for the very first Twimblecon conference which will focus on
the tools, technologies and practices necessary to scale the delivery of machine learning
and AI in the enterprise.
The event will be held October 1st and 2nd in San Francisco and early bird registration
is open today at twimblecon.com, again that's twimblecon.com, I can't wait to see you there.
Alright everyone, I am on the line with Judy Gesoya, Judy is an interventional radiology
fellow at the Daughter Institute at Oregon Health and Science University as well as a co-organizer
of Black and AI, Judy, welcome to this week in machine learning and AI.
Thank you Sam, I'm very excited to be here.
It is great to have you on the show and I'm really looking forward to diving into this
conversation about the intersection of radiology and AI but before we do that, how did
you come to start working in this space?
So I had some interest and experience already working in digital health in medicine.
I just a little bit of background about me, I went to medical school in Kenya and during
that time I was taking care of HIV patients and it was really difficult to sort of just
use paper and Excel spreadsheets and so I gravitated to sort of walking on an open source
medical record system and so I started walking, you know, deeply deploying, programming and
understanding how these systems are deployed.
And so at that point I did move to the US to do masters in clinical informatics and during
that point I decided that I wanted to get a clinical specialization just because the
truth is you get a little more respect if you have a clinical background, especially
when talking to clinicians, but also that I realized that what I was passionate about
which was building health systems that I use by doctors would be very difficult if you
are not using them yourself.
So I subsequently went to Indiana University for my radiology residency and the program
that allowed me to grow a lot, I had lots of opportunities to work on informatics on
a national level and so when I was attending the American College of Radiology Anum meeting
and that's around also when Joff Hinton, you know, publicly say that we should stop
training radiologists, you know, there was this sort of force and just uprising of physicians
who could do radiology and computer science to figure out why, you know, what was this
deep planning?
Why was it a threat?
And so I would say it was just right place, right time that I got involved into this sort
of this fantastic intersection of tech and medicine.
And that uprising as you call it resulted in a paper that you're the lead author on called
Frenesis of AI and Radiology, superhuman meets natural stupidity.
I think poking fun at this idea that AI will put radiologists out of business.
Yes, you know, some, it was very, very, first of all, you know, in medicine we don't publish
an archive, you know, and I have, so it's really such a big shift to be honest and one
of my really good friends who's, Satoshi, who's on the paper and we've known each other
on global health and work as good collaborators right now and, you know, it took me a lot
of evenings to try and explain to him what radiology does or drag him to the reading room
and just, you know, explain to him and just show him the workflow.
And, you know, at this, when we came to sort of this advert and, I mean, Andrew M. was
saying, you know, we're doing better than radiologists every, I mean, every article every
week just talked about how they had better performance, you know, and it was just sort
of like almost like, okay, maybe you should focus your efforts on maybe these areas that
would actually make you make us all better.
And to be honest, I think someone who's also an engineer, you get a little bit cocky when
you start to solve problems.
I think you always, it's very easy and I've suffered from this to dismiss domain expertise
and decide, you know, I can do this or all, that's just a few lines of code.
And so these people was sort of like, to be honest, we were hoping that it would get
debated at one of the debates in machine learning conferences and maybe we get to debate
it today at this weekend machine learning.
That's funny because we just recently hosted our first debate, if you want to call it,
not a formal debate, but a discussion around some recent announcements by open AI on
there.
I'm not going to go into the details there, but it was really interesting and we'd like
to do more of it.
So we'll talk offline about who the right people at the table should be for this debate
and maybe pull something together.
But it sounds like you're saying that part of the problem is that the people that are
out there proclaiming that we've solved radiology don't really understand radiology.
Absolutely.
Can you elaborate on that?
Have you figured out what it is that they don't understand or just that they don't understand
it?
Well, they just, they don't understand it.
And this is not also, to be honest, both sides can be very quirky.
The physician's medicine is very hierarchical, you wait for your turn.
In fact, I remember my teachers would say medicine is a club, we decide when and who
joins it.
So there's also the sort of like the nonchalant comfort, but I'm a doctor, what do you
mean you can do my work?
But there's also the other side of engineers.
And so I think what's missing is people who sit at the intersection of both, you know,
when you can easily describe things to the engineers and also sort of bring a little
bit of reason to the physicians.
And you know, I have sort of, back times with a little bit of stigma actually, because
in medicine, if you do anything but clinical work, now it's being embraced, but it was
always assumed that you're not good enough to be a doctor.
You know, you're not doing well.
If you do research, they're like, oh, yeah, he's good at research, but he's a terrible
doctor.
If you do IT or deep learning, you know, people expect you to not do a good job.
And so you have to fast fight that bias and stigma and do a very good clinical job as
a doctor so that people get that respect from you.
So there's all these sort of soft skills that you have to stimulate, even before we can
have a candid conversation where we have, you know, sort of engineers embedded in the healthcare
system to innovate, you know, and also to address problems that actually make an impact.
And so, for example, you know, we, we notice a little bit, so I think on online some
Altman recently wrote on CNBC that, you know, he'd rather have computer radiologists, more
than human radiologists, and you have these sort of people posting every, every week.
And it takes a long time to be a radiologist, you know, and it's, I think a little bit,
I was having a conversation with a friend of mine, you become emotionally attached.
And it's not just an attack on a profession, it becomes an attack on you.
You know, you're not good enough, you know, or you're indispensable, you know, dispensable.
And that can be a really big challenge also just to reconcile that personal conflict.
And, you know, I'm glad that radiology community has completely moved from this.
I mean, if you look at the last year, RSNN, you money challenged the top groups, the top
10 groups, what are radiologists, you know, and if you, we have a new radiology AI journal
that's online, that's, you know, good quality, pure reviewed, and it's focused on AI.
I mean, so it's amazing what in three years, you know, the rapid, that uprising,
the rapid transformation that came to sort of a little bit guard the profession,
but also to bring a little bit of common sense in discussing what's the best way forward,
because the truth is AI is coming, you know, we can't just control and make sure
that you're not wasteful and we get the benefit of it.
It sounds like you're saying on one hand, kind of the, this constant, you know,
derision of radiologists relative to AI, you know, isn't empathetic and it's not productive,
but also that is wrong.
And the examples that people try to out to demonstrate that AI has exceeded
the capability of radiologists are, well, you tell me how you characterize them,
you know, cherry-picked or incomplete or, you know, not representative of what's actually
happening in radiology.
And maybe as a, you know, taking a step back from that question, maybe a good way to get
there is to have you explain, you know, when you think of, you know, radiology and kind
of, in its broadest sense in what radiologists are doing, that image classifiers aren't
doing, you know, maybe we need to understand that more broadly.
Yeah.
So, I think you have to think about the sort of like the pixel level, pixel walk, which
is like the computer vision, can you diagnose pneumonia, can you diagnose a fracture, can
you diagnose a brain bleed?
And, you know, that's, I think a lot of people have focused on that, you know, because one
radiologist, especially if you've always digitized our, you know, our studies and their report.
So as long as you have access to the data, to be honest, you don't need to be a radiologist
to start to, you know, do some of this work.
But, you know, some, I think there'll be two things.
I think impactful AI will be embedded in healthcare institutions.
In fact, today, if I was, my advice to sort of healthcare managers, instead of buying
purchasing AI algorithms, I would say rent them or give them a place within your institution
to innovate and do the work and experiment.
And the reason is, I mean, your witness to this, the technology changes so much every
week, you know, and for you to sort of, if you understand the purchasing process of medicine,
it takes a long time by the time you, I mean, implementations of electronic medical records,
system ticks, months and years.
So if my implementation of your algorithm ticks, you know, nine months, by the time I'm
using it, it's updated, unless you have sort of new ways, and especially if you have to
get FDA approval for every algorithm, you're not going to go back in nine months before
you've made your money to get a new approval.
And so I see a big role, honestly, a big, if I was to say, what do I think are the big
grand challenges for AI in medicine?
It's really the workflow processes.
And you've, I mean, I'm a big fan of the podcast.
You had a few guests recently, like Microsoft talking about the notes, you know, enabling
the voice transcription on the notes for doctors, because physicians spend a lot of time at home
trying to catch up with documentation.
And we also have things around population health management.
So for example, I had a patient in May last year that I took care of and unfortunately
we had a congenital blood disease ended up getting institutional disease.
And this patient of mine would come to the hospital three times a week, because that's all
all dialysis patients come for dialysis three times a week.
So literally someone in the healthcare system, so this patient, unfortunately, 10 years
ago, he had had an IVC filter.
This is, you can think about this like an inverted umbrella, which you put in your vein to
sort of catch the cloth so that they don't go to your lungs.
And he had displaced, you know, after an accident, and it was never removed.
If you said IVC filters, there are lots of lawyers who like to sue about this.
And but the challenging part was, you know, these filters are placed in multiple institutions,
some of them are not placed under imaging.
So they just, it's just like, you know, it's like the wild west, you know, about where
these filters drop in.
And at the same time, why couldn't we, we must have had a, you know, an abdomen radiograph
that was done for something different.
And, you know, the person reading it, interpreting it may not really realize, okay, this is an
institutional disease patient who probably should not be having this old type of filter
that should affect their veins.
But you know, sort of like that addition of value.
So maybe the X-ray was done for constipation or something else.
So they focused on the constipation and they answered the question, the clinical question
that was asked before performing the study.
But with an AI running on the background, and this is a project that we are working on,
with Adam, my colleague at Emory, is to create an automatic, it's a computer detection problem.
And we create an automatic filter detector.
We run this every night, you know, at the end of the day with all our radiographs.
And if a patient has a filter, is anticoagulated, we send a message to their doctor and say,
hey, the next time they're coming in, you know, you may want to talk to them about these
IVC filter, refer them to a clinic to get this evaluated for removal.
So literally a decision that it's not really anyone's fault, but just sort of, we're so
narrow-minded and focused on the clinical problem at hand or for the day, we completely
miss the bigger picture of this patient, and that means he can never get a renal transplant
because he doesn't have the right veins, the old scar done after the IVC filter placement.
So this type of clinical questions, they actually come out naturally when you're embedded
in the healthcare system.
You know, I can go on and on with some really low-hanging fruits, and you know, it's very
difficult if you're not sort of bringing this, you know, cross-pollination of teams to
sort of answer these questions.
And that was actually, I would say, if you read this paper, the biggest thing is actually
the table one, landing passes in radiology, which is something that has been well-studied
by informaticians even before this era of deep planning.
And even give you some examples of things that you could do as an application that would
definitely augment and value to the radiologists.
Let's walk through that table.
What are some of the big biases that come up?
So for example, you could have a confirmation bias.
This is, for example, I may say, you know, man, this is pneumonia, and you keep searching
for evidence.
You know, you go back to the electronic medical record system, you call the doctor, you're
like, oh, you think this is pneumonia, right?
So you have sort of this preformed bias, and an AI tool could probably scout all the information
that's relevant already about that patient and present it in a consumable way for the radiologists
to interpret.
It could also give, you know, best if the AI tool was sort of not blind to the previous
studies.
It could say, you know, Judy, some of these studies that have been done in the past, which
have a similar sort of pixel appearance like this, were interpreted by these five radiologists
who, and we definitely know this high variability, but we said most of the radiologists thought
that this was something else like tuberculosis, not pneumonia.
And so it just gives you, you can get differential alternative diagnosis and, you know, then
contextually be like, okay, maybe it was a pneumonia or just raised the possibility
of both diagnosis, which I think is a big value.
Something else that happens a lot is this satisfaction of report or satisfaction of such,
and actually satisfaction of report which is different.
So for example, if you saw the previous radiologists who read a study said, oh, you know, I have,
this is cancer.
And if you read the report before looking at the images to form, first form your mental
representation and understanding of what the problem is, you could say, you could perpetuate
that diagnosis sometimes even when it's wrong.
And so one, some of the deep learning techniques that can be helped here is, for example, volumetric
just measurement, you know, you could measure the size of the otter, the size of a tumor
of multiple studies.
I mean, that, that task, specifically, is actually kind of repetitive and tedious for
our radiologists.
It's easier for me to have these representations, you know, on images and presented easily,
I'm like, okay, that's, that looks like accurate measurements.
And the computer is, we know this.
It's very accurate at determining volume and maybe even more consistent that radiologists.
And so it can sort of help instead of just me glancing and being like what we call eyeballing
and being like, oh, that tumor looks the same size.
It can help sort of even give more additional findings or additional data points to be like,
yeah, I can tell you that this tumor grew by 20%, which, you know, even just understanding
maybe an event, a timeline of the patient, maybe they got changed the chemotherapy three
months ago, can have an impact more than, because 20% change in a tumor in a patient
on chemotherapy versus one who's not on chemotherapy, completely means different things.
So there's always this sort of things that are going on.
It's not just sitting at a computer, looking at the image and be like, okay, this is pneumonia,
there's always this clinical context.
And I feel if you had an AI assistant or whoever an assistant at the back who was consistently,
you know, knows the correct information to send to you because the EMR, that is the electronic
medical record system is another monstrous dump of information would just present you
just in time intervention that made sense.
I think those are some of the true augmentation and true actually benefits we can rip from AI.
And some other examples could be, you know, the satisfaction of such a mention and this
because sometimes you just see the tumor. So for example, maybe we usually get some studies
around cities of the neck and, you know, you go in there and you see a big fracture,
maybe, you know, compressing the cord. I mean, that's very dramatic and drastic and you
call the ordering doctor and you tell them, you know, I see a big fracture.
And you know, this is probably a patient who just has, you know, came in because of trauma.
But you completely miss the big cancer that's just at the edge of the film, you know, on
the upper lungs because you, you know, you're happy. You're like, okay, I found the findings.
This patient is going to get treated this way. And those incidentals are really the places
where radiologists shine. But the AI could learn our blind spots and just ask, you know,
have just like another system that helps me be more cognizant of my blind spots. And
this is maybe not something documented, but this is how we learn, you know, every time,
you know, what you've missed and what you've caught and you start getting better and, you
know, like my such pattern every time I look at the city abdomen is to repetitively look
through the pancreas because those pancreatic tumors are very subtle and, you know, are
places where you can make a huge difference if you have early diagnosis. So I think we
have real good areas. And the reason why I actually just focused on buyers is because
this, we know this exists. We know that there's a big cost of medical errors and that there's
a pretty, pretty big opportunity to save costs and also to reduce death because medical
errors is the fat living cost of death in the United States.
It strikes me that this whole area of bias applied to radiology and AI is paradoxical in
the sense that you could easily argue that the existence of bias and human and radiologists
is the reason why we should be kind of all rooting for AI's to take over and for all these
stories about, you know, AI's up-performing radiologists to be true. At the same time,
these AI's are all trained on, you know, data sets that were labeled by humans and the
biases that you've outlined, you mentioned, you know, three or four here in the paper
you've got, you know, eight to ten, you know, these are all kind of embedded in our training
data sets. So, you know, the example you mentioned with an image that's got, you know, the
big compression fracture, but, you know, is labeled as, you know, perhaps in a training
data set is labeled as such, but not labeled for the, you know, the cancer that's at the
fringe. You know, we're kind of baking that into the AI's we're building today.
How do you kind of pick apart that paradox and is that something that you covered in the
paper or in your research or thinking about this generally?
So actually, we haven't covered this and I think, you know, this fairness and transparency
for ideology. First of all, this is a huge, huge, huge, huge area. Actually, this is
one of the areas I'm going to be focusing on as I begin my faculty position later this
year in July. And one is, even just the explainability, you know, like, why did it get here? You
know, you know, this idea of the black box AI, and this is not a problem, you know, we
always know that image net is the sort of the parent that all these AI tools at this
and computer vision are trained in for ideology. And the moment you say, yeah, we started
from dogs, cats and aeroplanes and cars. I mean, the radiologist and it goes back to the,
you know, the other discussion we had during this session where I said this a little bit
of soft power because when you say, oh, man, we started from cats and dogs, then you're
very far from replacing me or this, I mean, how do you come back to grayscale imaging,
which is radiology? But, you know, so there's one area about a gap in having more explainability.
But the issue around even bias, even North, the application and the downstream consequences
on policy and patient outcomes, the bias, I see radiology and I have to tell you that the
engineers who are working on this are not looking at these sort of questions, as far as
I know of, why maybe the AI's that will start to build help us open our eyes to the biases
that exist in medicine. We know this, but maybe it's that maybe the AI revolution will
help us sort of, you know, open this, open up these biases and come up with systemic
changes that actually end up improving our patients. And so, for example, there is, you
know, with their hospital scoring and the surgical scoring, people get very dinged for
re-admissions within 30 days or performing surgeries with poor outcomes. So, what the
doctors do, this is not documented, but you know it, is you self-select, you know. So,
if and also they sell selection for specialties. So, there's a reason why most of my calls,
I get them in the middle of the night and at that point, the excuse is that the patient
is not a good surgical candidate for a procedure because, you know, it's the middle of the night.
And so, we have all these subtle things that you as a doctor in the healthcare system,
you kind of know, but the people building these AI tools are a little blinded too. And we don't
talk, to be honest, we don't talk about them as biases in, you know, in sort of like the
stricter sense and sort of like this new discipline around bias and fairness and accountability
in AI, there just things that happen, you know. And so, maybe we will reap benefits, but only if we
start to look at the correct sort of information and again, work with multidisciplinary teams
that we can be able to address this issue. And specifically, if you look at, for example,
the engineer who gets, let's say you go, you buy a bunch of data and you come in and say,
oh, I trained on pneumonia, how will they know that they completely use the wrong data set
if they're not working with radiologists? So, I think it's going to be sort of this
union of both teams realizing that no, I'm knows it all. And we will discover things that
are embarrassing and things that forces to rethink how we provide healthcare. But it's only going
to come if the hype is not, I'm going to replace our radiologists because you will just replace
our radiologists with another radiologist. Maybe one who doesn't get tired because they can keep going
as long as they have electricity. But the subtle biases will be perpetuated and maybe amplified
because I mean, if there's no right now, we don't have a framework for continuous monitoring
or mandates for continuous monitoring in production. And we will continue to experience those
things. So, I know I was in a presentation where the Harvard group had trained an AI to detect
breast cancers. And you know, they got collaborators. I think this would be a big deal to validate
the algorithm around Detroit. And it really caught a lot of cancers in Detroit. And they
paused the question, why do we think it caught a lot of cancers in Detroit? And the reason was the
patients who come to the Harvard healthcare system come for regular mammograms for screening
Ali. And the Detroit patients came in late when they had the diagnosis, you know, head alarm
and they already had cancer. So, if you didn't understand who was coming to the healthcare system,
you'd be bragging how your AI is performing better, yet it just represents how healthcare is
delivered and the health-seeking behaviors of the two different populations in both areas.
So, the paper kind of invokes this idea of natural stupidity in the title. And you outline
kind of three behaviors that you label as kind of representative of this natural stupidity,
kind of the things that you see AI researchers talking about when they're not in close
collaboration with subject matter experts. Can you outline those for us?
Yeah, so we sort of picked up some areas and one was wishful, you know,
in the Monics. And I think this has been amplified honestly by the media. And also like when leaders
of group street, you know, that, oh, we are much better or we are the same as, you know, any
specialist. And so, for example, one of the things that came up actually around the check
net pneumonia paper was that there are many types of pneumonia. And actually, as someone who's
walked in global health and developing countries, that when you take care of HIV patients,
it's very different type of pneumonia. There's clinic on pneumonia and radiologic pneumonia.
So by just saying pneumonia, you know, everyone will be like, oh man, that's really amazing. But
when it comes to sort of like rational, just reading a negative chest x-ray, for example,
on a HIV patient, does not mean that it's negative for disease. You could say they're not finding,
not radiologic findings, but that does not always translate to negative for disease.
Can you elaborate on this distinction between clinical pneumonia and radiological pneumonia?
So, for example, radiologic would have a finding. So you may have like a consolidation that
would be pretty obvious. So for example, a low-burning pneumonia or multifocus pneumonia. But the patient
may, may, depending on the time or also when, where they are in terms of antibiotic treatment,
may not have radiologic findings because of the sort of like the spectrum of disease. Or if they
immunosuppressed to not monitor response that presents as opacities that you can see on a
radiograph, they still are sick and you can have lab tests and just the clinical appearance of
the picture and the history to help you diagnose, you know, clinical pneumonia. But at the same time,
their chest x-ray will be negative. So if your algorithm is only looking at one facet,
just the x-ray, which is maybe probably the only data available for you to look at,
then you would completely mislabel these patients as, you know, pneumonia,
negative for pneumonia, yet they have pneumonia. So not all pneumonia patients will have positive
findings on a radiograph. Got it, got it. And so, advertising your marketing, your
accomplishment as detecting, you know, some high percent of pneumonia without stating that
it's radiologic pneumonia, which is a subset of kind of the broader things that a radiologist needs
to be able to identify or that the medical community rather needs to be able to identify
is misleading. That's what you're getting out there. Yes. And so, what was the next one?
So, the next one is this assumption that human performance is decotomous. So, in this example,
using this sort of statement, we can say that you either diagnose pneumonia as positive or negative.
Okay. And a little bit, this is a bias of how the AI is allowed to give probabilities. You know,
I may think that maybe 80 percent probability that this is pneumonia. But when you look at the
performance, it's been compared to you, you just say, well, radiology, did you diagnose pneumonia
or non pneumonia? We do, we completely, or me, that we also depend on probabilities. And those
probabilities don't come out as a percentage. But for example, they varied a study and say,
you know, finding some most consistent or suggestive of malignancy and less likely infectious
etiology. That statement to a radiologist has a probability. And even for the referring doctor,
we'll know, okay, I should really make sure that there's no cancer here before, you know, going
the rabbit hole of infectious disease. And this one is says, okay, let's compare human performance
and AI. But you have to also factor in the probabilities of of of certainty of diagnosis
that the human performance look at. And so you can't just treat it as a zero, one
phenomenon for human performance, but have a little more variability when you think about the
machine performance. The other one we talked about was this idea of training with secondary data.
And, you know, I have to give full disclosure here that I really love to study how humans
work with technology, not just AI. And we know that data is a problem. The big institutions
have the data. But even when you have the data, it's not well labeled. And like I think you
exactly said, you may have a city for compression fracture, which was dictated as such. But if it
or completely omitted the tumor incidental tumor, then you perpetuate sort of those biases.
But this idea of secondary data, I think is we say that it's not enough for you to come up and
just use secondary data without a prospective validation trial where your head to head with
the radiologist in clinical practice and say I'm better than pneumonia. You know, and the examples
that give here are, for example, you could say it's not unusual when you're reading at 7 a.m.
you're reading the ICU films. You just say stable and stable. It doesn't mean normal. You know,
and if your algorithm doesn't your NLP tool doesn't recognize this, then you could this,
especially these groups, tend to be classified as negative. But you could have a patient who's
very sick and tubated with bilateral gestives and pneumothorax. But what I'm trying to communicate
to the ICU doctor is that nothing has changed. The tubes and lines are in stable position.
The appearance, the opacity on the chest structure are stable. So it helps them determine,
okay, is the patient, you know, getting better? But that's not the only metric that they use.
But you know, when I'm looking at tubes and lines, I'm checking how they moved in position so that
they need to be in position because that's sort of the purpose of an ICU team. And so to say that
you're looking at a one time, you know, look where you see some radiologists three or four. Have
them look at studies and then you come up and say, man, I can do better than radiologists. I think
is inaccurate, which, you know, which radiologists are you doing better than the chest experts? Are you
doing better than the resident who's just touching out to be a radiologist? I think relying on secondary
data is not bad, but I don't think it gives us enough mandate and enough platform to say that
we are better than a certain profession. And we need and calls for a calm and discipline to
identify that we do need prospective trials to figure out how the human machine assemblage walks
to to augment or be better than radiologists. Yeah, I think what I'm hearing here is that
it's well, several things, but one is that, you know, when you think about kind of the capabilities
of these algorithms, what really happens on the ground, the multiple parties involve the actual
nuance of these diagnoses, they don't necessarily translate to very well to kind of the way some of
these academic studies have been presented, but also that, you know, as a community of radiologists,
you're not, you know, it's not like kind of sticking your head in the sand and, you know, waiting
for this AI thing to go away. You know, what I'm seeing at least from you, you know, maybe you're
way more sophisticated than your colleagues, but it sounds like the field as a whole is recognizing
that AI can be a valuable tool. You know, let's try to work together to apply it to the problem
in a more sophisticated way, the better reflects the way, you know, what that community really needs.
Absolutely. Yeah, and I mean, so one of the things that are surprising was that the American
College of Radiology, which represents, you know, a lot of radiology has over 20,000 members
came together and set up a data science institute. And one of the things that's there, you know,
they have been walking on is setting up these writing use cases. And honestly, those can bring
a little bit of calm to say, okay, if I want to walk on this, maybe these, these are done by
several people, several radiologists, and they come together and say, hey, this would make
much more sense if I was walking on this. And, and you know, I think that's been a really good
way to sort of bring some calm. And you actually, there can be a win-win, you know, you can
build things that we need and we'll use them. And sort of aligning yourself with sort of these
initiatives and not, you know, going around the world and doing your own innovations,
I think can be a win for an entrepreneur. The other thing that, you know, for radiology,
what we've started to do, I've been doing this from December 2017, is organized a monthly
journal club on AI for the residents and the fellows. And we also have some faculty radiologists
who join in. And this has been fantastic. And just bringing those dialogues, bringing
engineers and bringing radiologists together and looking at papers and digesting this material.
And I think it's been, personal, it's been a fantastic experience to do this. But also to see,
also sort of like an understanding, right now, it's, you know, I know this hype and there'll be
a new person who posts something. But it's more of like, okay, I think I can't start to see the role
that I can play and where this can be beneficial. And I think that's, that's great. And I also see
a change in tone, even in terms of the new, the newer leaders when they speak, the recently
launched Coursera course by Andrew and I was listening to it on my flight yesterday. And you know,
he literally shows what machine learning can do and what he cannot do with an example from
radiology and states. Machine learning can learn from 10,000 just extra images or, you know,
just trying to say that from a large number. But machine learning cannot learn like a radiologist
who can just have three or four images of pneumonia and a short blob of text. And it's just this,
sort of learning that occurs. And some it's a little difficult to describe how actually that
learning occurs because the way we do it is you go in, you start to walk on an apprenticeship model
and you all of a sudden are left and call at night and you just don't realize how much you've
learned when the other doctors come in to ask you a question and you're like, oh, I think,
I think this is, you know, this is this or this is this and just brings your confidence.
I would, in fact, we are going to do this actually. We're going to start to maybe use some of the
techniques that we are seeing, for example, when people use YouTube to teach games and try and
get representations of the learning process, some of the tasks that can be of how especially
radiology residents learn and bring this human machine assemblage that is based within the system
that keeps learning and knows when to augment. And I think this will start will be probably one of
the earliest efforts to understand the future of work where radiologists work with AI.
Sounds like at least in what you're seeing being published by Andrew, there's maybe a broader
perspective or some recognition that there are some things that radiologists are good at.
Yeah. Well, Judy, thanks so much for taking the time to chat with me. It's been great discussing
your perspective on the way AI is impacting radiology and the kinds of things we need to move forward.
Absolutely. Thank you so much for inviting me. I'm a big fan.
All right, everyone. That's our show for today. For more information about today's show,
visit twimmolay.com. Be sure to visit twimmolcon.com for information or to register for Twimmolcon AI
platforms. As always, thanks so much for listening and catch you next time.
