WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:34.080
I'm your host, Sam Charrington. Before we dive into today's show, just a few quick

00:34.080 --> 00:40.000
meet up related announcements. First, let me say thanks to everyone who participated

00:40.000 --> 00:45.200
in this weekend's fast AI deep learning course study group. We had a great discussion

00:45.200 --> 00:50.720
about lesson one. If you missed it, the recap will be posted later this week, so be sure

00:50.720 --> 00:56.880
to subscribe to our YouTube channel or follow at Twimble AI on Twitter for updates.

00:56.880 --> 01:03.120
Also, this is your final reminder that the next Twimble online meet up will be tomorrow

01:03.120 --> 01:10.800
Tuesday June 12th at 5pm US Pacific time. Kelvin Ross will be reviewing the paper, cardiologist

01:10.800 --> 01:15.880
level arrhythmia detection with convolutional neural networks, which is worked by researchers

01:15.880 --> 01:25.360
and Andrew Ings lab at Stanford. For more information, visit twimbleai.com slash meetup.

01:25.360 --> 01:31.120
In this episode, I'm joined by Romero Salas, director of AI at LinkedIn. We begin with

01:31.120 --> 01:36.000
a discussion of graphical models and approximate probability inference, and he helps me make

01:36.000 --> 01:41.680
an important connection in the way I think about that topic. We then review some of the applications

01:41.680 --> 01:47.240
of machine learning at LinkedIn and how what Homer calls their holistic approach guides

01:47.240 --> 01:51.640
the evolution of machine learning projects at the company. This leads us into a really

01:51.640 --> 01:56.560
interesting discussion about problem formulation and selecting the right objective function

01:56.560 --> 02:01.960
for a given problem. We then talk through some of the tools LinkedIn has built to scale

02:01.960 --> 02:07.400
their data science efforts, including large scale constrained optimization solvers, online

02:07.400 --> 02:12.680
hyperparameter optimization, and more. This is a really fun conversation that I'm sure

02:12.680 --> 02:17.680
you'll enjoy. Let's go.

02:17.680 --> 02:24.800
All right, everyone. I am on the line with Romero Salas, who is director of artificial intelligence

02:24.800 --> 02:30.040
at LinkedIn. Romero, welcome to this week in machine learning and AI.

02:30.040 --> 02:35.440
Thank you, Sam. How are you? Glad to be here. Really excited to talk a little bit more

02:35.440 --> 02:41.640
about AI with you. I'm really a listener of your show in the past, and I really enjoy

02:41.640 --> 02:46.720
them. So looking forward to this. Awesome. That's great to hear, and I am doing great.

02:46.720 --> 02:52.240
And I'm excited to dig into our conversation, which as a listener, you know that I'll

02:52.240 --> 02:57.080
start by asking you how you got into artificial intelligence. Tell us a little bit about your

02:57.080 --> 02:58.080
background.

02:58.080 --> 03:09.360
OK, yes, so I guess my background as an undergraduate student is on something that is called informatics

03:09.360 --> 03:14.040
or informatics engineering. And this is something a term that is not used here in the States

03:14.040 --> 03:21.200
because I study in Venezuela for my undergrad. And that's kind of like a combination of math,

03:21.200 --> 03:28.440
computer science and stats or operations research. And, you know, looking back 20 years ago,

03:28.440 --> 03:35.640
this is exactly what you need to get into machine learning, right? So I was really interested

03:35.640 --> 03:44.440
in these topics from very long ago. And once I go into graduate school, I try to explore

03:44.440 --> 03:51.400
those more and more, first studying computer vision, which was kind of like my first subject

03:51.400 --> 03:57.800
area in graduate school. And then realizing that, you know, you could do a lot more in

03:57.800 --> 04:03.640
computer vision with the right sort of machine intelligence, right? And that got me more

04:03.640 --> 04:09.960
and more interested in AI. For example, I was looking at things like how do you recover

04:09.960 --> 04:15.040
the 3D structure of an object? And of course, the first thing you do in computer vision is

04:15.040 --> 04:19.840
you're going to the 3D geometry. And, you know, all of these things related to, you know,

04:19.840 --> 04:25.720
epipolar geometry or recovering the camera parameters. But then I try to approach the same

04:25.720 --> 04:32.520
type of problems using machine learning. And it just felt much more natural to me. And

04:32.520 --> 04:38.480
then I can go in in that direction and exploring a little bit more of a, you know, in-depth

04:38.480 --> 04:46.920
machine learning, did a couple of postdocs in the area, one in what I call image analysis

04:46.920 --> 04:55.040
and another one more related to how we scale inference in systems that are so large or

04:55.040 --> 05:01.360
so complicated that you cannot really do exact inference, but you have to go into approximate

05:01.360 --> 05:08.160
inference. So the area is really called approximate inference in graphical models.

05:08.160 --> 05:13.760
So, you know, that area really reinforces more and more, you know, what I really wanted

05:13.760 --> 05:18.800
to do in machine learning, which is to deal with these very large problems, large systems.

05:18.800 --> 05:23.560
And even if you cannot come up with an exact solution to all of these problems, to come

05:23.560 --> 05:32.720
up with a good approximations. So after that, I went to industry and I started working

05:32.720 --> 05:41.240
in the area of healthcare. So, which is a great area. It's a very, very meaningful area,

05:41.240 --> 05:48.840
which really needs, you see a lot of applications of artificial intelligence in this area. I

05:48.840 --> 05:55.160
spent about five or six years in the area of healthcare. And then I moved to Silicon

05:55.160 --> 06:02.400
Valley and right now I am here at LinkedIn. I think I'm very happy and I think I've been

06:02.400 --> 06:11.560
lucky to work on two areas that I consider that are pretty useful in general for the socially

06:11.560 --> 06:17.880
one is healthcare and the other one is my work here at LinkedIn, which is, as you know,

06:17.880 --> 06:21.240
deals with the subject of creating economic opportunity for everyone.

06:21.240 --> 06:27.720
Awesome. Well, I am curious about the work that you mentioned on approximate inference.

06:27.720 --> 06:30.720
Is that model specific?

06:30.720 --> 06:39.040
Yes. So approximate inference in graphical models is this area of machine learning where

06:39.040 --> 06:46.200
you know that if you really want to compute a posterior distribution, what we call, for

06:46.200 --> 06:52.240
a given random variable, given all the information that you know about the system around this

06:52.240 --> 06:59.360
random variable, they say you have a system of 100 random variables and you know a lot

06:59.360 --> 07:03.760
about 99 variables, but you don't, you want to know what those 99 variables tell you

07:03.760 --> 07:10.920
about these one variable, right? How do you compute the distribution over that random

07:10.920 --> 07:17.560
variable, right? So for example, you know, everything about the state of a patient, right,

07:17.560 --> 07:22.560
the result of many tests, how, how you can calculate the probability that this patient

07:22.560 --> 07:29.040
has a particular disease, for example, right? So we know that in complicated systems, depending

07:29.040 --> 07:36.240
on how these variables interact with each other, you can easily go into the field of, you

07:36.240 --> 07:41.560
know, such large computations that you cannot really compute is even if you have a very large

07:41.560 --> 07:49.360
computational resources. And you have to go and explore areas of approximations, right,

07:49.360 --> 07:55.920
of this posterior distribution. So basically approximate probability inference is the field

07:55.920 --> 08:00.480
of trying to come up with the best possible approximations to these very large problems

08:00.480 --> 08:05.960
that you cannot solve because they are either too large or simply because you don't

08:05.960 --> 08:12.560
have the time to wait for, for an answer. So anyway, that's a, that's in general what,

08:12.560 --> 08:17.600
what this area is. And you will surprise how quickly you go into these intractable models.

08:17.600 --> 08:24.080
For example, you have a, you have random variables that can take 10 values and you have a maybe

08:24.080 --> 08:31.360
50 of those, right? The number of possible states that the system could be in is already

08:31.360 --> 08:36.320
quite large. It approximates, I guess, in the number of particles in the, in the universe.

08:36.320 --> 08:43.600
So, wow, this is why you need this type of approximate algorithms and, and they actually

08:43.600 --> 08:49.320
very useful for a lot of the things that we do. Is the common theme between the work you've

08:49.320 --> 08:54.440
done in healthcare and the work you're doing at LinkedIn, this notion of graphical models,

08:54.440 --> 08:59.320
do you, do you use graphical models much at LinkedIn? Thinking in terms of graphical

08:59.320 --> 09:06.680
models is, is, to me, has been a really great way to think in terms of probability, a general

09:06.680 --> 09:11.160
way to think in terms, in terms of probability. And if you're in the field of machine learning,

09:11.160 --> 09:18.320
I think thinking in terms of probability, it's extremely useful. And even though you can

09:18.320 --> 09:22.560
do a lot of things, maybe without thinking directly in terms of probability, this, I

09:22.560 --> 09:28.080
think for most of the things that I have done in the past, the notion of probability,

09:28.080 --> 09:35.040
probability distribution, approximations have played a very important role. So, I think

09:35.040 --> 09:41.600
of graphical models as an excellent way to think in general about probability distributions

09:41.600 --> 09:48.640
and, and useful in, you know, many areas. In the healthcare field, for example, every

09:48.640 --> 09:55.200
time that you need to think about, well, what is the probability that this particular

09:55.200 --> 10:01.520
patient has this disease, given that we know the result of this test and this test and

10:01.520 --> 10:09.120
this other test, you know, it is court where everything we do, right? In the same way, in,

10:09.120 --> 10:15.160
in a large internet company like LinkedIn, understanding what is the probability that

10:15.160 --> 10:20.280
this member is going to really find value in this information that we are providing to

10:20.280 --> 10:27.000
him via the application, right? It's core to a lot of the things we do, right? So, we

10:27.000 --> 10:34.160
want to, at the end of the day, maximize the value that this member gets from interacting

10:34.160 --> 10:41.280
with LinkedIn and encoding this in terms of probabilities, right? Probability that the

10:41.280 --> 10:47.120
member is going to engage with this post or the probability that the member is going to

10:47.120 --> 10:53.440
invite a colleague to join LinkedIn or the probability that this member is going to maybe

10:53.440 --> 10:58.840
disable this notification because this notification wasn't the appropriate one to send, is something

10:58.840 --> 11:06.280
that we consider every day at my work. So, yes, I mean, thinking in terms of probabilities

11:06.280 --> 11:12.760
is, is at the core of everything we do. Graphical models provide a language to speaking in terms

11:12.760 --> 11:19.200
of probability that is very general and this is why, you know, I, I find it really useful

11:19.200 --> 11:26.320
and I, I was lucky to explore this field back when I was in academia and, you know, turns

11:26.320 --> 11:32.440
out that I'm using it every day, basically. It's really interesting. I've done a number

11:32.440 --> 11:40.040
of interviews on topic of graphical models and I've tended to think of them in the context

11:40.040 --> 11:47.640
of either computational graphs or like graph databases, things like that and always think

11:47.640 --> 11:54.000
of them visually. And it wasn't really until you just, until I heard your description

11:54.000 --> 11:58.200
that it really clicked, clicked for me that the, the graph we're really talking about

11:58.200 --> 12:02.560
is an application of baserol and conditional probabilities and that's really what their

12:02.560 --> 12:05.600
relationships are between these nodes and the graph. Is that the right way to think

12:05.600 --> 12:11.160
about this? You, you, you, you, you hit right on target, basically, approximate inference

12:11.160 --> 12:16.360
in graphical models is a way to efficiently apply Bayes rule. That's a, that is what

12:16.360 --> 12:23.120
this reduces to really, right? So, yeah, that's a, for example, algorithms like belief

12:23.120 --> 12:32.240
propagation, right? In a graph, right? It's an exact, exact way to apply Bayes rule, right?

12:32.240 --> 12:38.840
In some cases, you cannot apply the Bayes rule exactly, right? Because the computation

12:38.840 --> 12:46.680
is too large and these, they believe propagation algorithm becomes intractable, right? The exact

12:46.680 --> 12:54.920
one and approximating what belief propagation should do is, is basically core part of these

12:54.920 --> 13:00.520
algorithms for doing approximate inference in, in graphical models. So, yeah, I think

13:00.520 --> 13:07.360
that, that's another way to put it, right? So inference equates in these probabilistic

13:07.360 --> 13:13.360
systems as applying Bayes rule and when you cannot apply Bayes rule, you have to go into

13:13.360 --> 13:18.800
approximations, right? So, so now there is, that is not to say there are a lot of, there

13:18.800 --> 13:23.760
is a large field of machine learning that maybe you don't have to think directly in terms

13:23.760 --> 13:32.760
of probability, right? And for example, you know, I'll argue that even though it is useful,

13:32.760 --> 13:39.080
in many cases, thinking of when you need to use a neural network, let's say to address

13:39.080 --> 13:44.440
a classification task, you may or may not think in terms of probability and will be fine

13:44.440 --> 13:51.000
with it, right? But introducing probability in, in the thinking, in the reasoning about

13:51.000 --> 13:56.360
how machine learning works is, is super useful. And it's a, it's a great tool, right? Even

13:56.360 --> 14:02.000
if you are using, you know, neural networks or, or any of the things that on the surface

14:02.000 --> 14:08.040
don't require you to think in terms of probability directly, right? So, for example, in, in, you

14:08.040 --> 14:15.280
have a neural network trained to predict, let me use the same example in healthcare. The,

14:15.280 --> 14:22.600
you want to predict whether the patient is healthy or not, you can use as input the result

14:22.600 --> 14:29.880
of all the tests that you apply to this patient. And the output is going to be an activation

14:29.880 --> 14:36.160
of this normally referred to as a, as a neuron in the, in the, in the neural network that

14:36.160 --> 14:41.000
tells you whether the patient is sick or is not, right? Based on what he has learned from

14:41.000 --> 14:49.760
the past. And so far, I haven't brought up the term probability. But if you start thinking

14:49.760 --> 14:57.160
about how the activation of the neurons, right, relate to this, how certain the system

14:57.160 --> 15:02.720
is that the patient is sick or not, then you can translate that to, to a more probabilistic

15:02.720 --> 15:11.080
concept and start doing, you know, additional analysis on, let's say, the, how reliable

15:11.080 --> 15:16.040
the neural network is or how, how much it captures the true relationship between the inputs

15:16.040 --> 15:22.400
and outputs, right? So, anyway, that is kind of like my summary of why, you know, thinking

15:22.400 --> 15:26.480
in terms of probabilities is, to me, it's always helpful, even if you are not dealing with

15:26.480 --> 15:30.720
them directly, like in, like in some versions of neural networks.

15:30.720 --> 15:35.280
Yeah, I'm really glad we went down this path. I don't, you know, it seems so, so obvious

15:35.280 --> 15:40.320
in hindsight, but that way of thinking about graphical models is, is going to be helpful

15:40.320 --> 15:45.720
for me, I think. You know, maybe let's jump over to, to LinkedIn and, and what you're

15:45.720 --> 15:51.400
up to at LinkedIn. Can you talk a little bit about why AI at LinkedIn? I mean, some of

15:51.400 --> 15:57.600
that is going to be obvious, but maybe give us a lay of the land of how LinkedIn thinks

15:57.600 --> 16:03.640
about artificial intelligence and machine learning. So, basically, in everything you see

16:03.640 --> 16:12.160
on the LinkedIn app has, to a large extent, some form of machine learning in the background,

16:12.160 --> 16:17.600
right? Let's, let's start from the things that you normally see when you open the LinkedIn

16:17.600 --> 16:22.680
app, let's say the feet, right? The first thing you see normally is, is the LinkedIn

16:22.680 --> 16:29.680
feet, which ranks the conversations or updates or information that, in general, we believe

16:29.680 --> 16:37.200
is the most relevant to you. So, this, the reason why we rank things in, in that way, is

16:37.200 --> 16:44.760
because of the, how you have interacted with the LinkedIn application in the past, right?

16:44.760 --> 16:51.320
So we try to understand what interests you, what is relevant, right? You have a limited

16:51.320 --> 16:57.560
amount of time to invest on, using the LinkedIn app, we want to make sure that that's the

16:57.560 --> 17:04.720
most relevant that we can show you. In the same way, connection recommendations, who,

17:04.720 --> 17:11.040
who would you like to connect to? We try to infer from past activities and your past

17:11.040 --> 17:16.800
connections, you know, who you would be interested to connect with. Follows recommendation, who,

17:16.800 --> 17:21.440
would you like to follow? What topics do you like to follow? How to make messaging interactions

17:21.440 --> 17:29.480
simpler, right? How to, what to notify you off, right? So we know that notifications,

17:29.480 --> 17:35.720
too many notifications could be negative because we don't want to overwhelm anybody by sending

17:35.720 --> 17:40.800
too many notifications all the time, but so we want to really, really choose what is the

17:40.800 --> 17:47.760
best possible use of your time if we were to send you a notification. So machine learning

17:47.760 --> 17:53.040
plays a role there in trying to decide what is, what, what, what notification for all the

17:53.040 --> 17:58.560
notifications that we could send you has the high chance of providing value to you. And

17:58.560 --> 18:06.320
even in other areas that are not directly consumer or member focus, we use artificial intelligence

18:06.320 --> 18:13.080
a lot, for example, preventing some forms of abuse to the site, right? That's another

18:13.080 --> 18:20.560
area that understanding the patterns in the past that we have seen of abuse, let's say,

18:20.560 --> 18:29.160
to the site. I think we can prevent future problems with it, right? So jobs recommendations,

18:29.160 --> 18:35.360
right? So how to connect you with the right job, with the right company requires of understanding,

18:35.360 --> 18:41.200
you know, your skills. How do they, how they relate to certain types of jobs? What is your

18:41.200 --> 18:47.280
job title? So what type of jobs probably makes the most sense for us to recommend to you? And

18:47.280 --> 18:54.920
things like that, in addition to that, maybe your job requires you to know or to learn certain

18:54.920 --> 19:03.520
subject areas. So we can also recommend to you learning courses that you can also find in LinkedIn

19:03.520 --> 19:13.040
that will maximize the chances of you getting that next job, for example. In the same way,

19:13.040 --> 19:19.440
you know, in our search results, when you search for a particular topic or member or product or

19:19.440 --> 19:26.640
company in the app, we use artificial intelligence to show you what are the most likely matches to

19:26.640 --> 19:36.320
what you are intended to identify in the app. So, you know, I could, I could talk about all of

19:36.320 --> 19:43.200
these subjects for hours, right? But it's basically everywhere, yeah. I'm curious a lot of what you've

19:43.200 --> 19:50.720
described sounds common across internet companies and social types of applications, feeds,

19:50.720 --> 19:57.200
recommendations, things like that. I'm curious where LinkedIn's requirements and use cases might

19:57.200 --> 20:04.320
be different from some other companies in ways that are interesting. There are going to be things

20:04.320 --> 20:10.400
that are probably in common with other companies and things that are special to LinkedIn.

20:10.400 --> 20:16.000
One of the main things that we truly care at LinkedIn is that notion of, you know, are we providing

20:16.000 --> 20:22.640
the most possible value, right? The highest possible value to the member by showing the member

20:22.640 --> 20:28.640
a particular recommendation, for example, right? So, we think about this whole

20:29.680 --> 20:35.120
interaction with the application in a holistic way. And I think that's pretty interesting. I

20:35.840 --> 20:43.920
am not too familiar with other industries or companies thinking this holistically, right? So,

20:43.920 --> 20:50.080
and what do I mean by that, right? So, for example, recently, or maybe a couple of years ago,

20:50.080 --> 20:58.000
not so recently, we receive a lot of feedback that maybe LinkedIn was sending too much email,

20:58.000 --> 21:03.680
right, to people, right? And some of this feedback was public and that we have acknowledged this. So,

21:05.440 --> 21:09.440
what, we decided to think about, you know, what we need to do something about this, right? And

21:09.440 --> 21:16.080
why is it that, you know, we're sending so much email? And if you think short term, right?

21:16.080 --> 21:20.480
Well, you know, the more messages you send, the more email you send, in this case, you know,

21:20.480 --> 21:26.240
the higher the chances of engagement, right? So, if you want to maximize engagement, you know,

21:26.240 --> 21:33.280
sure, at least in the short term, send more email, right? And, well, that is a very, you know,

21:33.280 --> 21:39.920
short-sighted strategy, right? So, instead, what if you start thinking about if you want to improve

21:39.920 --> 21:47.520
the overall ecosystem of LinkedIn, right? And at the same time, the overall value that the member

21:47.520 --> 21:54.000
gets from using LinkedIn, then you start thinking much differently, right? And one of the

21:55.200 --> 22:01.440
early projects that we did in this area was, well, you know, engagement, you know, as a proxy for

22:01.440 --> 22:06.960
value is interesting, but we should also take into account negative signals, like, for example,

22:06.960 --> 22:14.640
is a member disabling or marking the email as spam, for example, right? So, so let's speak one

22:14.640 --> 22:21.920
email type and let's try to change the problem from trying to maximize engagement to a constraint

22:21.920 --> 22:27.760
optimization problem, where we think a little bit more holistically and say, well, let's try to

22:27.760 --> 22:35.280
maximize some form of engagement, which is a proxy to value, subject to some constraints on, let's

22:35.280 --> 22:41.760
say, negative feedback, like marking the email as spam. And, you know, that turns out, you know,

22:41.760 --> 22:48.400
that's that relatively simple optimization problem, you know, only one email type to utilities,

22:48.400 --> 22:56.240
one is related to engagement, one is related to negative feedback, had a huge impact on that

22:56.240 --> 23:02.080
particular type of notification or email that we were sending, right? And how do you characterize

23:02.080 --> 23:11.200
that impact? So, the way that we can address that impact is how many, how much negative feedback

23:11.200 --> 23:16.400
are we reducing? And so how much how much of a reduction negative feedback we can we can measure,

23:16.400 --> 23:24.560
right? How many fewer emails we can send at what level of engagement? So, it turns out that

23:24.560 --> 23:32.480
we could reduce the number of emails notification that we send by a pretty large amount. I think

23:32.480 --> 23:38.640
for that initial test that we run, it was at least 40% of email reduction with a equivalent

23:39.120 --> 23:46.400
percentage of negative feedback. And the engagement, the proxy to engagement that we were using

23:46.400 --> 23:54.000
at the time, which were sessions, right? We're almost unchanged, maybe negative 0.5 reduction

23:54.000 --> 24:00.240
in sessions. So, that's that's a great trade off to make, right? So, we we provide a much better

24:01.360 --> 24:07.680
experience at a very similar level of engagement and we actually could measure that there is a

24:07.680 --> 24:12.720
reduction in the negative feedback that we were getting, right? So, thinking holistically,

24:13.120 --> 24:20.880
basically gave us so many more insight into how we can do this across LinkedIn. So, so we didn't

24:20.880 --> 24:26.400
stop here. We said, well, you know, this is this is great. So, it may sound crazy, but what if we do

24:26.400 --> 24:32.720
this across all notifications that we're sending and at the time we were sending the primary

24:32.720 --> 24:38.960
form of notifications that we were sending were emails. So, let's say that we now instead of just

24:38.960 --> 24:44.240
why stop it at one email type, let's let's across all the possible emails that LinkedIn could send

24:44.240 --> 24:52.400
you. What if we apply a similar way of thinking, right? And then you you're running to scalability

24:52.400 --> 25:03.200
problems and having to work with an entire set of, you know, product managers within the company.

25:03.760 --> 25:10.160
And how do you deal with that, right? So, and this experience really gave us a lot of insights

25:10.160 --> 25:16.960
about how we approach future problems, right? But what we did basically was less, less formulate

25:16.960 --> 25:22.000
the problem again as a constraint optimization problem where you are less minimize the amount

25:22.000 --> 25:28.320
of messages that we send. Let's say that we want to really, you know, if we don't have to send any

25:28.320 --> 25:35.200
messages and provide the same amount of value to the members, then why not do that, right? So,

25:35.200 --> 25:38.640
the way that we formulated the problem was, well, less minimize the number of messages that we

25:38.640 --> 25:46.800
send in this case emails, subject to a maximum amount of negative feedback that we're willing to

25:46.800 --> 25:53.360
tolerate. We want, you know, less than 2% of negative feedback or 0.2% of negative feedback.

25:54.080 --> 26:00.880
And let's also make sure that there is certain level of engagement. So, we don't want to reduce the

26:00.880 --> 26:06.400
engagement too much because that's our proxy for for member value, right? So, let's let's play

26:06.400 --> 26:12.960
second strain on on the member value that we believe we are providing, right? And since we have

26:13.600 --> 26:18.880
maybe 20 different products or 30 different products across LinkedIn that are all sending some

26:18.880 --> 26:24.960
form of email or notification, let's make sure that we don't decrease the engagement that we are

26:24.960 --> 26:31.840
directing to those products more than a percentage, right? And then you see how we can we keep

26:31.840 --> 26:37.280
increasing the complexity of the problems and the number of constraints, right? So, this turnout

26:37.280 --> 26:46.720
to be a project that we, you know, decided to do and which enormously reduce the amount of emails

26:46.720 --> 26:54.240
that we sent to our members, all the product partners were positive about the impact that this

26:54.240 --> 27:00.720
was having across the product and basically address this very critical problem that we really,

27:00.720 --> 27:06.240
really wanted to solve, which is provide better member value while at the same time reducing the

27:06.240 --> 27:11.520
amount of notifications that we were sending, right? So, I believe that at the time the reduction

27:11.520 --> 27:19.280
of total messages sent to members was close to 65% or close to 50% overall without decreasing

27:19.280 --> 27:25.840
in negative feedback of 65% and less than 1% reduction in sessions overall, right? But,

27:25.840 --> 27:31.760
you know, we believe this is the right thing to do and we did it, right? This, even though

27:31.760 --> 27:36.720
this came at some cost, which is, you know, 1% reduction in sessions that in a large company that

27:36.720 --> 27:43.120
may be a large cost, but it was a right thing to do and it opened the door to a lot of other

27:43.120 --> 27:48.160
things that a lot of our future thinking about how to approach these problems. This is a really,

27:48.720 --> 27:55.760
really interesting story, a great story and really timely for me, I was just giving a talk

27:55.760 --> 28:03.040
earlier this week and talked about how the metric that you choose to optimize around, you know,

28:03.040 --> 28:08.400
has a huge impact in the way you can approach a machine learning problem, even if it's fundamentally

28:08.400 --> 28:12.800
the same kind of problem, you know, a recommendation problem, you could look at it from the perspective of

28:13.440 --> 28:21.200
revenue or profit or a lifetime customer value and there are all kinds of choices to make there

28:21.200 --> 28:26.160
that have different implications on the ultimate performance of your models, but also the user

28:26.160 --> 28:32.160
experience, the customer experience. So it's really interesting to hear how you've applied this.

28:32.160 --> 28:38.880
Are there other areas outside of this email domain that you've applied this kind of holistic thinking

28:38.880 --> 28:46.320
to? Yeah, so we're now using these to all the types of notifications as well, but I think

28:46.320 --> 28:54.320
one interesting example is also in the area of forming connections, right? So in LinkedIn,

28:54.320 --> 29:02.320
we have this product called BYNK or people you may know and this product is basically powered by

29:04.240 --> 29:09.680
machine learning algorithm that determines for a particular person. What are the connections that

29:09.680 --> 29:16.640
in the past, you know, we also think about what are the connections that are most likely to respond,

29:16.640 --> 29:25.600
yes, I want to connect with you, right? And when you then rethink the problem and think, well,

29:25.600 --> 29:32.000
you know, maybe we should think about the problem in terms of what are the most valuable connections,

29:32.000 --> 29:38.320
right? Or what are the connections that will in the future, you think of value as how much

29:38.320 --> 29:44.320
interaction you will have with these connections, then, you know, you start thinking about different

29:44.320 --> 29:51.760
objective functions and different ways to provide what we think is a better value to the members,

29:51.760 --> 29:58.400
right? So what we started to do was to instead of creating connections after connections,

29:58.960 --> 30:03.520
trying to maximize the number of connections that a person creates, try to maximize the

30:03.520 --> 30:07.760
valuable connections or the connections that are, that the connections that matter, right, or that

30:07.760 --> 30:18.560
we think that matter, right? So, so we reformulate the problem into less maximize the chances that

30:18.560 --> 30:23.200
you're going to really engage with this person, you connect with the person, subject to some constraints

30:23.200 --> 30:29.440
on, you know, I want you to be connected, right? I don't want the members to be all severely

30:29.440 --> 30:34.560
undreconnected because we are too picky about the type of connection we're recommending to

30:34.560 --> 30:42.720
this member, right? So, this had an interesting impact on, well, you know, the new connections

30:42.720 --> 30:46.480
that you're making are actually, you're actually interacting more with them because of the new,

30:46.480 --> 30:54.960
this new recommendation algorithm and it's probably of higher value to you, right? So,

30:54.960 --> 31:02.080
as another example where we were thinking about maybe the more of the ecosystem value, you know,

31:02.080 --> 31:10.240
or long-term value to the member, right? And another example is in the area of, so for example,

31:10.240 --> 31:16.800
on the feet, right, which is a core part of LinkedIn, you know, we want to make sure that everybody

31:16.800 --> 31:22.000
in the feet feels hurt, right? So, you know, when I post something in the feet, I want to make sure

31:22.000 --> 31:30.480
that people, you know, can see what I posted and I get feedback, right? You want to maximize

31:30.480 --> 31:37.840
click to rate, which is a usual metric that you will first think about. You will normally

31:37.840 --> 31:44.000
promote members that are very, very popular and get a lot of clicks, right? So, but you want to

31:44.000 --> 31:51.600
create a really a better sense of community and people, you want people to feel that they're

31:51.600 --> 32:00.080
hurt, right? You want to also take into account that maybe some members that are less active, right,

32:00.720 --> 32:06.560
will deserve the chance to get feedback as well, right? So, we want to maximize overall

32:07.440 --> 32:16.320
engagement, not just the gain of a few members, right, while other members feel that they are not

32:16.320 --> 32:24.480
hurt, right? So, that's another area. And so, what we did is we basically focused on a group of

32:24.480 --> 32:36.720
members that are new sharers or not very common sharers or contributors and decided to make a

32:36.720 --> 32:43.680
trade-off, basically. We want to have this, we want to have most members receiving feedback

32:43.680 --> 32:50.800
as compared to just a few members receiving a lot of feedback. And again, this had a very

32:50.800 --> 32:58.640
positive effect on the members who contributed and they were not necessarily the most popular

32:58.640 --> 33:03.760
members or heavy contributors, but because of the feedback they got, there was a considerable

33:03.760 --> 33:09.280
increase in how much these members contribute again and share another article or share their views

33:09.280 --> 33:17.040
again on the site. And again, this is something that maybe it is obvious once you think about it,

33:17.040 --> 33:23.920
but it is not how usually most companies start when they want to optimize something like the

33:23.920 --> 33:29.920
feed, for example, or connection recommendations. Usually, the tendency is to optimize for the

33:29.920 --> 33:35.920
metric that you can see the most now and hope that that is the metric that in the long term is

33:35.920 --> 33:42.160
going to be the best metric to optimize. And we have realized that that's not the case in many

33:42.160 --> 33:46.000
instances and instead you need to think a little bit more holistically and come up with a better

33:46.000 --> 33:52.560
proxy of what is the metric that is better for the overall good of the member and the

33:53.600 --> 33:59.200
engagement overall in the site. Now, this is not to say that we have solved the problem of what

33:59.200 --> 34:04.720
is the best long-term metric that you should optimize for. I think that's a really difficult

34:04.720 --> 34:13.520
problem and in many cases you get counterintuitive results into I want to optimize

34:14.480 --> 34:21.120
how much daily active users they are in the site in one year. What should I optimize more

34:21.920 --> 34:27.280
in the short term in order to get there? And I think that's a tougher question. That's a tougher

34:27.280 --> 34:36.800
question. Basically, this reflects our idea that you should try to optimize whatever is closer

34:36.800 --> 34:43.920
to the long-term metric you want to see change. As long as you have a way to more or less

34:44.800 --> 34:52.160
approximate that metric with something that you can measure in the short term. If we wanted

34:52.160 --> 35:01.520
to apply this idea, I would like to optimize the feed or LinkedIn overall for a metric that says

35:01.520 --> 35:08.640
how many people in the global workforce are employed and believe that have economic opportunity,

35:08.640 --> 35:14.400
right? But what is the, is that my objective function? What did you get pretty broad?

35:14.400 --> 35:18.640
Yeah, what is the derivative of that with respect to the variables that I can control? That is

35:18.640 --> 35:26.720
a, that is a problem. So that is trying to fill in the intermediate proxy objective functions

35:26.720 --> 35:32.800
that you think will get you to that overall ideal, right, is where there is so much

35:32.800 --> 35:43.200
interesting work and ideas in machine learning that this is such a broad subject. But this is

35:43.200 --> 35:47.680
more or less how we want to think about it. What is the true metric that you really want to go

35:47.680 --> 35:58.000
towards? So now that you have this experience, do you find that teams are starting with more

35:58.000 --> 36:06.560
holistic models from the beginning of a modeling process like for new features or do you find that

36:07.440 --> 36:14.160
it needs to be more of a crawl walk run and, you know, they should still start simple and

36:14.160 --> 36:22.720
evolve and mature over time? Yeah, so I think that definitely I always go for the, you know,

36:22.720 --> 36:30.480
try the simplest thing first, right? And try to understand from the simple approaches first,

36:30.480 --> 36:38.960
right? And, you know, for a new company that needs to grow very fast, right, in order to get

36:38.960 --> 36:46.080
that engagement going, especially say you're starting a new application for which the,

36:47.200 --> 36:51.920
the social aspect is very important, you know, perhaps trying to maximize the number of connections

36:51.920 --> 36:58.000
as much as possible is the best, right? Well, the cake and not the icing or the cherry.

36:58.000 --> 37:06.400
Exactly, right? So now, once you start learning and realizing that, you know, maybe, you know,

37:06.400 --> 37:14.560
our members have a limited amount of time and energy and attention, what is the next best thing

37:14.560 --> 37:22.000
that we could do to provide that value to them? Right? Then you probably start thinking into

37:22.000 --> 37:28.480
more sophisticated way to optimize for that. Also, you know, at the same time, when you are early,

37:28.480 --> 37:32.240
you know, when a company is an early in the early stages, you probably don't have a very

37:32.240 --> 37:37.920
large investment in machine learning, so you need to try simple things first, right? Because

37:38.560 --> 37:45.280
the ROI is this largest, right? At that stage, right? But once you have understood a lot about

37:46.320 --> 37:56.480
the members or people who use your application, it's really, it turns into an ethical question,

37:56.480 --> 38:02.800
you know, what is the best thing that we could do for our members, given that we have this level

38:02.800 --> 38:08.400
of maturity, you know, the standing, how to bring value, right? And this is what we are trying to do,

38:08.400 --> 38:14.560
right? We try to do the best we can, given, given all that we have learned throughout the many years

38:15.520 --> 38:24.880
at LinkedIn. There are certainly implicit, if not explicit, tones to, you know, fairness implications

38:24.880 --> 38:29.280
of some of the things that you describe, like, you know, particularly around the feed and what

38:29.280 --> 38:33.600
goes into the feed and that kind of thing. Yeah, exactly. I think that's something that

38:34.640 --> 38:41.680
we always keep in mind. I think that we always try to think about all of these considerations

38:41.680 --> 38:48.480
in terms of fairness, you know, reducing bias, and I'm members' privacy, of course, right? That

38:48.480 --> 38:57.040
go into all the things we do, but as long as all of those aspects are satisfied,

38:58.320 --> 39:03.680
they're thinking about how to think holistically to provide the best possible value, right?

39:04.320 --> 39:10.080
To the members is something that is now reflected in many of the things we do. So

39:12.000 --> 39:17.920
and I guess he helps that my team is responsible for a lot of the products that I mentioned earlier,

39:17.920 --> 39:24.960
so we really try to make sure that this this way of thinking permeates across the organization

39:24.960 --> 39:32.960
and it starts at that level instead of thinking too narrowly or too greedily in terms of maximizing

39:32.960 --> 39:38.960
one particular metric at the expense of all the things that we may be missing, right? That can

39:38.960 --> 39:44.560
be better for the overall ecosystem, right? So anyway, so that's just wanted to summarize

39:44.560 --> 39:49.920
maybe how how it is that we're thinking about all of these problems at a high level and maybe

39:49.920 --> 39:55.680
provide a few examples like the email example that where we could touch a little bit at the low level.

39:56.720 --> 40:05.520
Yeah, absolutely. I'm curious as your team takes on more of these constrained optimization

40:05.520 --> 40:11.840
types of problems, has it changed or to what degree has it changed? The tools that you use,

40:11.840 --> 40:19.200
the data pipelines, the modeling process, you know, the general approach to rolling these out.

40:19.600 --> 40:27.920
Okay. Yeah, that's a good question because we had to build tools for doing this more efficiently,

40:27.920 --> 40:34.720
right? And some of the tools, for example, that we had to build are this large scale

40:34.720 --> 40:42.720
constrained optimization solvers that can use, can take advantage of some level of distributed

40:42.720 --> 40:48.640
processing, right? And provide a result to the problem very quickly, right? Because a lot of

40:48.640 --> 40:53.840
these problems really, what something that is common about all of these problems is that you're

40:53.840 --> 41:02.160
normally computing a trade off across many different objectives, for example, you know,

41:02.160 --> 41:12.960
a number of negative feedback that you get, a number of sessions that we see, perhaps sessions

41:12.960 --> 41:18.080
to a particular product and so on, right? A number of connections that you make. So what is

41:18.080 --> 41:23.040
common across all of these kind of applications, or examples that I've given, is that you always

41:23.040 --> 41:28.000
end up with how do you set the right trade off across all of these possible objectives?

41:28.000 --> 41:34.000
Right? So in optimization, I think that's what's normally referred as the Pareto curve, right?

41:34.000 --> 41:40.960
What is the right point in the frontier where you want to operate, right? So in two dimensions,

41:40.960 --> 41:48.560
this is just a curve and two variables and, you know, usually an increase in the return that

41:48.560 --> 41:54.960
you're getting one variable implies that you will get a negative impact on the other variable,

41:54.960 --> 42:01.760
right? So, you know, and that's a, you know, that's a very large set of combinations of variables

42:01.760 --> 42:07.120
that you could get, right? In just in two dimensions, what if you have three different

42:07.600 --> 42:11.840
objectives, or we call it utilities, three different utilities that you need to balance,

42:11.840 --> 42:17.040
or four utilities? How do you quickly solve these problems? Now, one thing you could do is that

42:17.040 --> 42:23.520
you could solve these problems offline, right? And wait for your cube quadratic programming,

42:23.520 --> 42:29.600
or linear programming, a solver to give you the solution, and then put the solution into the

42:29.600 --> 42:34.720
system and, you know, a measure just to make sure that things are going the way you expect.

42:34.720 --> 42:41.520
So that's one way to deal with the problem, and we continue to build ways to scale these

42:41.520 --> 42:48.880
constraint optimization problems in our systems. Another way that you could think of of these problems

42:48.880 --> 42:56.640
is let's say I try to do this online, right? And this is an interesting problem that we're working

42:56.640 --> 43:03.840
on these days. Let's say we have three utilities, right? And I want to learn what is the best

43:03.840 --> 43:09.440
combination of those utilities that satisfy my constraints as I serve the traffic so that I

43:09.440 --> 43:19.840
can adjust these things as the traffic is being served, right? So there are working online,

43:19.840 --> 43:28.160
we call it online model selection methods that allow you to, well, you know, a member comes,

43:28.160 --> 43:33.120
we serve this with a particular combination of parameters, and we determine, you know,

43:33.120 --> 43:40.080
how well the response to that combination of parameters was, and then the system automatically

43:40.080 --> 43:43.840
says, you know, well, you know, based on all the information that I have collected in the past about

43:43.840 --> 43:49.040
how how members are interacting given this parameter setting, what is the next best set of

43:49.040 --> 43:56.240
parameter settings that I could try to improve my utilities and still satisfy the constraints,

43:56.240 --> 44:03.520
right? So there are actually ways that we are trying to adjust solve this optimization problem

44:03.520 --> 44:10.320
where you have a few, we call it hyperparameters, right? That determine how much importance

44:10.320 --> 44:17.440
each of the utilities has, right? And, you know, the process of trying to adjust this in real time

44:17.440 --> 44:24.320
as we see more and more data is one of the areas that I think is very exciting and we have seen

44:24.320 --> 44:30.240
quite a few positive results in this direction. Of course, this method may not be able to scale

44:30.240 --> 44:35.520
for a very large dimensions where you need, you probably will need to solve a full offline

44:36.320 --> 44:41.760
constraint optimization problem, but in many practical situations, being able to do this

44:41.760 --> 44:48.320
parameter tuning in the online form seems possible. And I think this is one of the areas where

44:48.320 --> 44:56.080
I think we are we're very excited to see positive results these days. So in this context of an

44:56.080 --> 45:02.640
online system, you mentioned the dynamic model selection, which makes me think of, you know,

45:02.640 --> 45:10.240
not so much updating hyperparameters or parameters in real time, but you have offline developed as

45:10.240 --> 45:16.320
opposed to one single model, multiple models, and you're trying to fit a given user to a model

45:16.320 --> 45:22.560
online and then use that model. But it also, it sounds like you're doing a bit of both. I guess

45:22.560 --> 45:27.200
I'm trying to get some confirmation of my hearing right that there are two different types of

45:27.840 --> 45:34.400
things that work as you're trying to make the system more dynamic. Yeah, I think the two examples

45:34.400 --> 45:41.520
you provided are very related problems. I was and I think one could approach them in a very

45:41.520 --> 45:48.000
similar way. I was referring mostly about the problem of fitting hyperparameters, right?

45:48.000 --> 45:53.280
Okay. Which is basically when you have a linear combination of utilities, you have that

45:54.160 --> 45:59.440
hyperparameter that that is specific is how much of each utility, you know, what is the weight

45:59.440 --> 46:05.680
for each utility, right? And how you should change the that weight to satisfy your constraints and

46:05.680 --> 46:11.520
to at the same time maximize an objective, right? So I just seen those parameters in real time is

46:11.520 --> 46:17.360
what mostly I was referring to. I got it. However, however, that is you are right on target when you

46:17.360 --> 46:25.120
when you relate this with the with the other problem of trying to decide in real time what is

46:25.120 --> 46:31.680
what is the best model variant, right? That you could use instead of having to run different

46:31.680 --> 46:38.160
AB tests separately. You may want to run just one AB test and let the AB test itself out to

46:38.160 --> 46:43.760
tune it, right? Self-tune it. So that you can decide what is the what is the best model variant.

46:43.760 --> 46:49.280
And yeah, those those two problems are very related and we are exploring these directions as well.

46:50.160 --> 46:54.960
Just in terms of the time check, we've had a really interesting conversation so far. There are

46:54.960 --> 47:02.480
other things that you would add in and around this topic of trying to approximate more holistic

47:02.480 --> 47:10.960
metrics in the way we model. No, I think I think that reflects at a high level. I think what

47:12.000 --> 47:16.560
how we're thinking about it. There are there are some papers that I can also share with you offline

47:16.560 --> 47:22.160
into that they're going to more details about these. We have a pretty active group of

47:22.160 --> 47:29.840
scientists, engineers, analysts that publish papers and attend conferences and pre-active in

47:29.840 --> 47:36.400
the research community. And you know, we have the data website at LinkedIn. You can search for

47:37.280 --> 47:43.920
a few blog posts and articles that we normally publish there to go into a lot more detail into

47:43.920 --> 47:50.960
what I just said. You know, we're pre-active overall in the research community. And you know,

47:50.960 --> 47:54.960
something that I found I guess that I think it's also probably interesting to mention here is that

47:56.000 --> 48:02.080
you know, I spent a lot of times many years in academia and I actually did several postdocs and

48:02.080 --> 48:08.400
you know, was very interested in co-research in this area. But you know, working in industry,

48:08.400 --> 48:17.200
you you you never run out of problems. That that that is no answer for and or that the answers

48:17.200 --> 48:24.960
are just not that great when you try them, right? That this creates a constant influx of problems

48:24.960 --> 48:33.680
that you wish you have more time to solve that that that are pretty advanced or research driven

48:33.680 --> 48:40.400
problems that you know, you can publish and make a lot of impact on. So I found the working in

48:40.400 --> 48:44.960
industry as one of the main sources of interesting problems that I can think of

48:44.960 --> 48:51.440
you know, for publishing or for you know, just personal satisfaction of of being able to to

48:51.440 --> 48:57.360
approach the problem for for a greater good, right? So I think that that's that's one message that

48:58.160 --> 49:03.360
I also wanted to share because it took me some time to realize this but once I realized it as well

49:03.360 --> 49:08.800
this is this is so obvious, right? So this is this is such a great place to think of, you know, to

49:08.800 --> 49:14.000
realize what are the really important problems that matter and if you solve them now, it will have

49:14.000 --> 49:20.000
a big impact not only on on on just core research but also on the impact that you can have to

49:20.000 --> 49:26.080
to society in general, right? Right. So I think I find it a great place to to do that and

49:27.600 --> 49:34.960
LinkedIn has a different initiative is also with academia. For example, we run this what we call

49:34.960 --> 49:42.320
the economic graph research program, right? Which is another way for us to share, hey, you know, he

49:42.320 --> 49:48.800
here is here is a data that has been of course properly, you know, to identify and this information

49:48.800 --> 49:55.600
has been properly processed to be shared with a certain group of people, right? And we work together

49:55.600 --> 50:02.480
with professors or people from academia and other parts of outside of LinkedIn to be able to

50:03.120 --> 50:07.040
share, hey, you know, this is the data, this is a problem we have. What are all the problems that you

50:07.040 --> 50:14.240
see that for which you can use this data and actually, you know, to research make a positive impact,

50:14.240 --> 50:20.320
right? So I just wanted to mention that as well as one of the things that I'm pretty excited about.

50:21.280 --> 50:27.520
What LinkedIn does overall and if anybody is interested, I think this is something that you can

50:27.520 --> 50:34.480
check out also in our web pages. Okay, great. Well, we will include links to those sites in our

50:34.480 --> 50:41.280
show notes as well as any papers that you want to send over. But Romeo, thank you so much for

50:41.280 --> 50:46.720
taking this time. It was really a pleasure to chat with you. Thank you very much. It's my pleasure.

50:46.720 --> 50:47.440
Talk to you later, Sam.

50:52.320 --> 50:58.720
All right, everyone, that's our show for today. For more information on the Romeo or any of the topics

50:58.720 --> 51:07.280
covered in this episode, head on over to twimmolai.com slash talk slash 149. For the details of our

51:07.280 --> 51:13.840
upcoming meetup for the fast AI study group we formed, visit twimmolai.com slash meetup.

51:13.840 --> 51:28.880
As always, thanks so much for listening and catch you next time.

