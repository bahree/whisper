WEBVTT

00:00.000 --> 00:17.440
Hello and welcome to another episode of Twymilthalk, the podcast where I interview interesting

00:17.440 --> 00:22.640
people, doing interesting things in machine learning and artificial intelligence.

00:22.640 --> 00:26.280
I'm your host Sam Charrington.

00:26.280 --> 00:31.400
Once again, thanks to everyone who sent in their favorite quote from a recent podcast.

00:31.400 --> 00:36.760
Another batch of stickers got mailed out this week, and please keep those quotes coming.

00:36.760 --> 00:40.280
We've had a blast getting your perspective from each talk.

00:40.280 --> 00:44.000
If you're new to the Twymil family, you too can get a sticker.

00:44.000 --> 00:50.360
Just send us a comment via the show notes page, tweet us at Twymilai or at Sam Charrington

00:50.360 --> 00:54.680
or share your quote via a post on our Facebook page.

00:54.680 --> 00:58.880
Before we jump into today's show, which I'm sure you're going to enjoy, I'd like to take

00:58.880 --> 01:03.880
a moment to remind you all about my upcoming event, the Future of Data Summit, which will

01:03.880 --> 01:08.080
be held May 15th and 16th in Las Vegas, Nevada.

01:08.080 --> 01:12.160
I'm really looking forward to the summit, and I hope you can join me there.

01:12.160 --> 01:16.060
You'll hear from industry leaders and technology users on how they're taking advantage of

01:16.060 --> 01:22.560
emerging data-centric technologies like IoT, blockchain, deep learning, and more.

01:22.560 --> 01:24.480
You'll learn a ton.

01:24.480 --> 01:29.360
I'm continuing to add new speakers to the lineup, including Jennifer Prinkey from Walmart

01:29.360 --> 01:34.560
Labs, who will be joining us to talk about what she calls data mixology.

01:34.560 --> 01:39.120
Jennifer currently leads a team of data scientists and engineers working on improving the online

01:39.120 --> 01:46.240
experience of the Walmart customer by integrating Walmart's stores data with e-commerce data.

01:46.240 --> 01:50.960
She also manages the metrics and measurements team there, a group in charge of creating

01:50.960 --> 01:56.320
metrics to measure the impact of all new features and algorithms, as well as solutions to

01:56.320 --> 02:01.840
automatically control and manage all machine learning algorithms in production.

02:01.840 --> 02:06.160
So we'll be talking about the importance of finding and fusing data to making machine

02:06.160 --> 02:10.760
learning predictions in production and describing the evolving platform that Walmart's put

02:10.760 --> 02:13.400
in place to facilitate all this.

02:13.400 --> 02:18.480
Jennifer is just one of a whole lineup of great speakers I've got for the summit, and

02:18.480 --> 02:23.560
the summit is just the first two days of the Interrupt ITX conference, which offers a

02:23.560 --> 02:29.880
week full of great educational content for folks interested in data and analytics.

02:29.880 --> 02:34.200
In addition to a dedicated data and analytics track at the conference, there will also be

02:34.200 --> 02:40.120
an AI theater and demo showcase dedicated to the practical application of AI, deep learning

02:40.120 --> 02:46.520
and machine learning for traditional enterprise tasks, such as dynamic pricing and insurance,

02:46.520 --> 02:52.720
perfecting the retail customer experience, optimizing job costing, transportation expenses

02:52.720 --> 02:54.360
and more.

02:54.360 --> 02:58.920
Case studies will be presented by businesses employing successful AI strategies and will

02:58.920 --> 03:03.600
provide strategic guidance and suggestions for attendees to utilize in their respective

03:03.600 --> 03:05.000
businesses.

03:05.000 --> 03:11.000
Accompanying the AI theater is the demo showcase, which will provide a hands-on lab demonstrating

03:11.000 --> 03:14.200
real world AI technologies.

03:14.200 --> 03:19.240
If you have any questions at all about the summit, don't hesitate to reach out to me.

03:19.240 --> 03:24.680
And to learn more, visit twimmolai.com slash future of data.

03:24.680 --> 03:29.400
The code I provide on that page, which is simply my last name, Charrington, provides

03:29.400 --> 03:35.160
Twimmol listeners with a 20% discount when they register for Interrupt ITX.

03:35.160 --> 03:37.320
And now about today's show.

03:37.320 --> 03:44.400
I guess this week is Scott Stevenson, Scott is co-founder and CEO of DeepGram, which has

03:44.400 --> 03:50.200
developed an AI-based platform for indexing and searching audio and video.

03:50.200 --> 03:55.760
Scott and I cover a ton of interesting topics in this talk, including applying machine learning

03:55.760 --> 04:01.000
techniques to particle physics, his time in a lab two miles below the surface of the

04:01.000 --> 04:07.320
earth, applying neural networks and deep learning to audio, and the deep learning framework core

04:07.320 --> 04:09.520
that his company is open sourced.

04:09.520 --> 04:12.080
I know you're going to love this one.

04:12.080 --> 04:14.320
And now on to the show.

04:14.320 --> 04:26.960
Hey everyone, this is Sam Charrington and welcome to another episode of this week in Machine

04:26.960 --> 04:32.840
Learning and AI, this week I've got Scott Stevenson on the line with me.

04:32.840 --> 04:39.160
Scott is co-founder and CEO of Machine Learning and AI Startup DeepGram.

04:39.160 --> 04:40.160
Scott, say hi.

04:40.160 --> 04:43.640
Hi, thanks for having me, Sam.

04:43.640 --> 04:45.760
It's great to have you on the show.

04:45.760 --> 04:51.640
I think the best place to get started is to maybe have you spend a little bit of time

04:51.640 --> 04:57.800
talking about your background because you come out of physics, right, not audio, speech,

04:57.800 --> 04:58.800
and all that.

04:58.800 --> 05:00.160
Yeah, absolutely.

05:00.160 --> 05:06.040
We are, you know, DeepGram is an audio AI company, but our background or most of the

05:06.040 --> 05:11.880
technical people in DeepGram, our background is in particle physics or at least some form

05:11.880 --> 05:13.960
of, you know, deep physics.

05:13.960 --> 05:20.000
And for me and my co-founder Noah Shetty, we both were doing particle physics before we

05:20.000 --> 05:25.560
started DeepGram, which was searching for dark matter.

05:25.560 --> 05:32.360
And this is about, you build an experiment that sits around, miles underground, essentially,

05:32.360 --> 05:35.760
you know, like one mile, two miles underground, the deepest labs in the world are two miles

05:35.760 --> 05:36.760
underground.

05:36.760 --> 05:41.000
And we were, our experiment was in the deepest lab in the world in Western China.

05:41.000 --> 05:42.960
It was called Panda X.

05:42.960 --> 05:48.680
And we built this experiment over the course of four years with a lot of other people,

05:48.680 --> 05:51.440
you know, with around two dozen other people.

05:51.440 --> 05:56.520
And with the help of the Chinese government, and that's an interesting story.

05:56.520 --> 06:02.920
But yeah, and the techniques that we learned in building this experiment, we've figured

06:02.920 --> 06:06.000
out were like really applicable to audio.

06:06.000 --> 06:11.320
And the reason is that physics is very, at least particle physics at the very hairy

06:11.320 --> 06:14.480
edge of research is still analog.

06:14.480 --> 06:21.600
And you still read, you still look for particles using analog detectors, they're called photomultiplier

06:21.600 --> 06:22.600
tubes.

06:22.600 --> 06:27.440
And the signals that you get out of these are just a waveform.

06:27.440 --> 06:31.680
It looks a lot like an audio waveform, but it's at a much higher sampling frequency.

06:31.680 --> 06:40.400
And those waves that are contained in the output of these photomultiplier tubes, the signals

06:40.400 --> 06:43.880
that are in there tell you the signature of the particle that you're seeing.

06:43.880 --> 06:49.920
So you might see a single photon, you might see a big splash of a muon in your detector.

06:49.920 --> 06:51.440
But it's all contained in those waves.

06:51.440 --> 06:56.560
And so what you have to do is extract that information from the photomultiplier tubes,

06:56.560 --> 07:00.960
and then make a guess, you know, did you see dark matter or not.

07:00.960 --> 07:03.400
And so we got very good at doing that.

07:03.400 --> 07:08.120
And it's actually really interesting because the state of the art in particle physics is

07:08.120 --> 07:12.760
essentially a lot of humans sitting down, figuring out how do you extract information from

07:12.760 --> 07:14.280
these signals.

07:14.280 --> 07:19.120
And you know, maybe you've heard of like the Higgs boson being discovered a few years

07:19.120 --> 07:20.120
ago.

07:20.120 --> 07:21.480
A lot of people, yeah.

07:21.480 --> 07:28.040
And that was done by thousands of scientists sitting down and saying, hey, I really want

07:28.040 --> 07:29.520
to find the Higgs boson.

07:29.520 --> 07:33.800
How do I make cuts in my data?

07:33.800 --> 07:39.760
How do I process my data to figure out, to make my signal to noise, you know, good enough

07:39.760 --> 07:41.840
to find these particles.

07:41.840 --> 07:50.800
And this is actually a lot of this hard manual labor of figuring out these cuts is done

07:50.800 --> 07:53.040
by machine learning now.

07:53.040 --> 07:59.080
So people will build boosted decision trees or kind of, that's not necessarily the realm

07:59.080 --> 08:04.440
for neural networks, but boosted decision trees and other statistical machine learning

08:04.440 --> 08:05.440
techniques.

08:05.440 --> 08:08.160
People are figuring out how to sort of automate this.

08:08.160 --> 08:11.480
But that's like the world that we came from essentially.

08:11.480 --> 08:16.920
And we were on that, you know, we were in that area thinking, like, man, this sucks.

08:16.920 --> 08:21.480
Let's automate this, you know, how do we automate it?

08:21.480 --> 08:25.080
Because I feel like a machine already just going through, like, here's another plot.

08:25.080 --> 08:26.080
Did this work well?

08:26.080 --> 08:27.080
Did that not work well?

08:27.080 --> 08:28.080
Like, what went on?

08:28.080 --> 08:29.840
And it's like, this could all be done with a machine.

08:29.840 --> 08:33.920
And so a lot of the people that are in deep-gram now, we were all sitting at University of

08:33.920 --> 08:39.080
Michigan thinking, you know, how can we make machine learning, or how can we jam machine

08:39.080 --> 08:44.120
learning into physics, particle physics, and then, like, extract something out of it.

08:44.120 --> 08:46.640
And did you, how far did you get down that path?

08:46.640 --> 08:52.400
Did you actually complete the jamming, or did you end up leaving and going off to start

08:52.400 --> 08:56.840
deep-gram before you fully applied ML to the particle physics?

08:56.840 --> 09:00.920
Yeah, so it's varied for the different people in deep-gram.

09:00.920 --> 09:05.040
So I did finish my PhD, I finished about two years ago.

09:05.040 --> 09:11.440
And Noah, who was my co-founder, went to a PhD program at Stanford, like, actually didn't

09:11.440 --> 09:13.440
even start it.

09:13.440 --> 09:18.000
He came out to the Bay Area, and we were working on deep-gram at the time, and we got a little

09:18.000 --> 09:23.120
bit of funding, and he was like, you know what, let's not do this physics thing.

09:23.120 --> 09:29.840
And anyway, but the couple other people in deep-gram either finished their PhD or, you know,

09:29.840 --> 09:32.560
got a master's and left after that.

09:32.560 --> 09:38.680
But we were definitely successful in sticking machine learning into a particle physics analysis

09:38.680 --> 09:40.000
pipeline.

09:40.000 --> 09:47.040
And in particular, for dark matter, what we did is reconstruct events in a 3D position,

09:47.040 --> 09:50.360
reconstruct the 3D position of the events that are happening inside.

09:50.360 --> 09:56.480
So the way that this works, I mean, it's like not to go too deep, but a particle detector

09:56.480 --> 09:58.280
is just at least for dark matter.

09:58.280 --> 10:02.520
It's just a tub of liquid, and it's a tub of cryogenic liquids, so it's very cold.

10:02.520 --> 10:06.680
But, and it's put two miles underground, and it's under a shield, and it's all very,

10:06.680 --> 10:09.880
you know, like, particular, but it's all, it's just a tub of liquid.

10:09.880 --> 10:14.880
And that tub of liquid has a lot of atoms in it, and those atoms happen to be, in this

10:14.880 --> 10:16.520
case, xenon.

10:16.520 --> 10:22.080
And you choose xenon because it doesn't interact with other things, it's a noble gas.

10:22.080 --> 10:28.120
So just like helium or neon or argon, it doesn't really interact, it doesn't form molecules,

10:28.120 --> 10:32.080
it doesn't really have, like, a chemical decay to it, nothing like that.

10:32.080 --> 10:38.160
But it's really big, and scientists surmise that dark matter particles, like really big

10:38.160 --> 10:39.360
particles, essentially.

10:39.360 --> 10:43.760
So you find the biggest non-reactive particle that you can, you put it into a tub, and

10:43.760 --> 10:49.840
then that tub is just sitting there with tons of atoms, and it's just waiting for a dark

10:49.840 --> 10:50.840
matter particle to hit it.

10:50.840 --> 10:54.640
It's just sitting there, just, you know, that its sole purpose in life is to get hit by

10:54.640 --> 10:58.880
a dark matter particle, and almost none of them have a dark matter particle hit it.

10:58.880 --> 11:06.760
But that's what's happening, and those signals, that atom that got hit, as soon as it gets

11:06.760 --> 11:12.960
hit, it flies through the other xenon atoms that are sitting around in this liquid, and it

11:12.960 --> 11:19.120
creates a puff of light, basically, and stirs up some photons, essentially, and it's

11:19.120 --> 11:23.720
like ten photons, you know, it's a very small number, but you have these detectors that

11:23.720 --> 11:30.200
can detect the single photons, and those single photons are bouncing around inside your detector,

11:30.200 --> 11:34.600
and they're finally getting picked up by these single pixels, essentially, and you need

11:34.600 --> 11:37.360
to figure out, like, where was that event, right?

11:37.360 --> 11:43.280
And so you're talking about, like, really low statistics pattern matching, and how do

11:43.280 --> 11:49.000
you make some kind of algorithm that says, hey, this is what the pattern that I got, where

11:49.000 --> 11:50.760
do I think this event was?

11:50.760 --> 11:56.840
And that was really successful, and compared to what a human can come up with, essentially,

11:56.840 --> 12:02.440
and the other is determining the energy of the particle, how big of a splash was it?

12:02.440 --> 12:07.720
That's a little easier to do, but machine learning made it a little bit better.

12:07.720 --> 12:14.240
And what about boosted decision trees lent themselves to application for this problem,

12:14.240 --> 12:15.240
domain?

12:15.240 --> 12:19.520
Yeah, so boosted decision trees, one thing, is that they're, like, fast to train.

12:19.520 --> 12:22.160
So that was really good.

12:22.160 --> 12:28.800
They also, when you have a low number of statistics, or at least a fairly low number of statistics,

12:28.800 --> 12:32.520
they can still do pretty well, compared to, like, a neural network that would over train

12:32.520 --> 12:33.520
or something.

12:33.520 --> 12:39.800
So we were very hot at the time on doing boosted decision trees for that type of problem,

12:39.800 --> 12:45.560
and I still think it's actually very good, and people are still using this, you know?

12:45.560 --> 12:51.320
So yeah, it lent itself very well to doing that, the reconstruction, and it also lent itself

12:51.320 --> 12:57.520
really well to doing a determination of whether it is a signal or background.

12:57.520 --> 12:59.520
Was it a dark matter particle or not?

12:59.520 --> 13:00.520
Right.

13:00.520 --> 13:04.320
Because the signal that you see in this photo multiplier tube in the waveform, it actually

13:04.320 --> 13:05.720
does look different.

13:05.720 --> 13:08.560
It's like a little bit noisier, and it's a little fatter, and things like that.

13:08.560 --> 13:12.960
But it's only kind of statistically noisier and statistically fatter, you know?

13:12.960 --> 13:19.160
And so these machine learning algorithms can do a better job than are just standard hard

13:19.160 --> 13:20.160
cuts.

13:20.160 --> 13:23.960
A human can still do better than the machine learning algorithm.

13:23.960 --> 13:27.760
You can look at all of these, but you don't want to look at billions of events.

13:27.760 --> 13:28.760
Interesting.

13:28.760 --> 13:29.760
Interesting.

13:29.760 --> 13:34.000
Do you have a sense that there are maybe more that physics, people with a physics background

13:34.000 --> 13:38.960
are somehow disproportionately represented in the machine learning and AI community?

13:38.960 --> 13:45.600
I'm only working on a small data set here, sample size, but I recently interviewed Josh

13:45.600 --> 13:52.560
Blum, who is an astrophysicist and did an AI start up.

13:52.560 --> 13:53.800
Have you seen that at all?

13:53.800 --> 13:56.000
Yeah, I do think so.

13:56.000 --> 14:00.360
And I run into a lot of people that have a physics background.

14:00.360 --> 14:07.920
And I think the reason that these two fields are kind of coming together is that AI is

14:07.920 --> 14:10.200
kind of just information physics.

14:10.200 --> 14:15.480
The way you try to solve a problem is exactly the same as how you would solve a particle

14:15.480 --> 14:16.480
physics problem.

14:16.480 --> 14:20.600
Like, get a ton of data, try to figure out what the trends are, try to see what the

14:20.600 --> 14:21.600
outliers are.

14:21.600 --> 14:24.520
Like, how do you actually tackle a problem?

14:24.520 --> 14:25.520
It's identical.

14:25.520 --> 14:29.080
I feel like I'm doing the exact same thing as physics, but I'm just doing it with voice

14:29.080 --> 14:31.080
now.

14:31.080 --> 14:33.840
Super interesting.

14:33.840 --> 14:39.800
So before we get too far from it, he mentioned a lot of your work happening in China and

14:39.800 --> 14:42.040
that there were some stories there.

14:42.040 --> 14:44.040
How did that happen?

14:44.040 --> 14:45.040
So connection.

14:45.040 --> 14:52.000
Yeah, there was just an upstart experiment as I was starting graduate school.

14:52.000 --> 14:55.840
This experiment was just sort of being circulated as a possibility.

14:55.840 --> 15:00.440
It wasn't even, there wasn't really anything going on yet, but people were like, hey, there's

15:00.440 --> 15:04.480
a spot underground in Western China, it's two miles underground, it would be the deepest

15:04.480 --> 15:09.760
lab in the world and it's not a lab yet, but we're trying to petition the Chinese government

15:09.760 --> 15:13.840
to turn it into a lab so that we can put a dark matter experiment there.

15:13.840 --> 15:20.240
And I was like, I am so in, you know, this, whatever that is that you just said, let's

15:20.240 --> 15:21.960
do it.

15:21.960 --> 15:24.080
You know, and that's actually what it was.

15:24.080 --> 15:28.560
I went to my, you know, my new advisor at the time, I was like, let's do it.

15:28.560 --> 15:30.400
He's like, you know, this isn't really a thing yet.

15:30.400 --> 15:31.400
And I'm like, I don't care.

15:31.400 --> 15:32.400
Let's do this, right?

15:32.400 --> 15:34.280
And it eventually turned into a thing.

15:34.280 --> 15:38.360
It involved, China is an interesting place, so I'll say that.

15:38.360 --> 15:47.320
But at first, there were failed talks to turn this into a lab and they went something like

15:47.320 --> 15:50.400
this, oh, well, okay, to back up just a second.

15:50.400 --> 15:54.920
Like why was this lab there anyway or why was this spot there?

15:54.920 --> 15:58.480
They were building the world's tallest hydroelectric dam right next to it.

15:58.480 --> 16:01.840
And they have all these tunneling machines and these mountains are made out of marble and

16:01.840 --> 16:03.480
marble is really easy to tunnel through.

16:03.480 --> 16:08.240
So they like Swiss cheese the mountain, you know, they just cut a whole bunch of holes

16:08.240 --> 16:15.320
in the mountain and there just happen to be a tunnel that is two miles underground.

16:15.320 --> 16:17.520
And this is where they were diverting water through.

16:17.520 --> 16:24.000
So it's actually a new type of hydroelectric dam where they have a really tall dam part

16:24.000 --> 16:25.640
and then they extract energy there.

16:25.640 --> 16:30.960
And then they go where there is a river that would go around a mountain, like a long distance

16:30.960 --> 16:34.080
around a mountain, instead they just tunnel through the mountain.

16:34.080 --> 16:37.240
And so the mountain itself is now a secondary dam essentially.

16:37.240 --> 16:38.240
Oh, wow.

16:38.240 --> 16:39.240
Yeah, you can look this up.

16:39.240 --> 16:42.920
It's the Jin Ping one and Jin Ping two dam in China and it was just completed like a

16:42.920 --> 16:44.760
year or two ago.

16:44.760 --> 16:47.120
But yeah, they, that's what they were doing.

16:47.120 --> 16:49.440
And so we were like, hey, you know, this is a great spot to do it.

16:49.440 --> 16:52.600
And we went there and said hello hydroelectric dam company.

16:52.600 --> 16:55.880
We are like ten scientists and we'd love to put an experiment down here and they're

16:55.880 --> 16:58.920
like, no.

16:58.920 --> 17:01.680
And so we were like, hmm, how can we work this a little better?

17:01.680 --> 17:06.920
And we were in, in kuhuts with Shanghai Jiao Tong University, which is, you know, one

17:06.920 --> 17:12.080
of, a very well known technical university in China.

17:12.080 --> 17:16.200
And we went to them and, well, we were in collaboration with them.

17:16.200 --> 17:20.200
And so like along with them and the leadership there, they said, okay, we'll talk to some

17:20.200 --> 17:21.360
people essentially.

17:21.360 --> 17:26.760
And so the educational system in China has a ton, a ton of power.

17:26.760 --> 17:32.240
And so they went to the hydro, the, the, like leaders of the education community went

17:32.240 --> 17:35.640
to the hydroelectric dam company and said, hey, do you guys want to do this?

17:35.640 --> 17:36.960
And they said, sure.

17:36.960 --> 17:39.960
So they have some sway there.

17:39.960 --> 17:42.320
It always helps to have the right people involved.

17:42.320 --> 17:43.600
Yeah, absolutely.

17:43.600 --> 17:46.080
And so, so that's how that all got started.

17:46.080 --> 17:51.040
And from that, from that yes moment to having a lab to actually work in, it was less than

17:51.040 --> 17:52.040
nine months.

17:52.040 --> 17:56.880
They had to, you know, get dynamite blast out a lab, like, turn it into an actual thing

17:56.880 --> 18:00.400
with cranes and, like, yellow railing.

18:00.400 --> 18:03.640
So it looks like a James Bond layer, you know, they had to do all of that.

18:03.640 --> 18:05.840
And they did it in, in less than nine months.

18:05.840 --> 18:09.280
And we were in there building our experiment right after that.

18:09.280 --> 18:16.720
And were you physically in China in this lab or virtually connected to it from Michigan?

18:16.720 --> 18:23.520
So I, I would physically, I would physically go there, like, four months out of the year,

18:23.520 --> 18:24.520
essentially.

18:24.520 --> 18:25.520
Okay.

18:25.520 --> 18:26.520
Yep.

18:26.520 --> 18:31.120
And that was, again, like for me, I grew up in a really small town in Michigan.

18:31.120 --> 18:37.720
And I kind of figured out that, like, the world exists, you know, outside of like a 38

18:37.720 --> 18:42.160
hundred person city or city, I shouldn't say city, you know, tiny town.

18:42.160 --> 18:48.480
And I, you know, was it, I went to, you know, undergrad in, in Missouri at a University

18:48.480 --> 18:49.480
of Missouri, St. Louis.

18:49.480 --> 18:52.560
And then I went to graduate school at University of Michigan.

18:52.560 --> 18:57.200
And the world is just getting bigger to me, you know, and, and then now I'm like, in

18:57.200 --> 19:00.880
China, halfway across the world, totally different people, totally different culture.

19:00.880 --> 19:02.760
And I was loving every minute of it.

19:02.760 --> 19:03.760
I thought it was great.

19:03.760 --> 19:04.760
And it's awesome.

19:04.760 --> 19:05.760
Yeah.

19:05.760 --> 19:09.200
And there was, there, there was so much to learn from being over there.

19:09.200 --> 19:14.240
But one of the biggest is that they have very few roadblocks, essentially.

19:14.240 --> 19:17.240
If you want to get something done and you have the resources to do it, you will get it

19:17.240 --> 19:19.680
done very quickly.

19:19.680 --> 19:23.640
And so that's why we could start the experiment, well, you know, that's why they could build

19:23.640 --> 19:24.880
a lab in nine months.

19:24.880 --> 19:27.040
That's why they could build this dam in five years.

19:27.040 --> 19:33.040
That's why we could start our experiment, like design the experiment, build the experiment,

19:33.040 --> 19:35.080
put it in, run it, et cetera.

19:35.080 --> 19:39.600
You, all of our data analysis, all in under four years, you know, because they, they were

19:39.600 --> 19:42.400
just like so helpful in removing roadblocks.

19:42.400 --> 19:46.320
So, so that was, that was really nice to see coming from the US.

19:46.320 --> 19:47.320
That's awesome.

19:47.320 --> 19:48.320
That's awesome.

19:48.320 --> 19:56.920
You, uh, so you worked on this project, finished your PhD, um, connected with your, your

19:56.920 --> 19:59.360
co-founder was also from, um, Michigan.

19:59.360 --> 20:00.360
Yeah.

20:00.360 --> 20:01.360
You was before.

20:01.360 --> 20:02.360
Yeah.

20:02.360 --> 20:06.560
Yeah, we were working on that experiment together, um, he's a decade younger than me.

20:06.560 --> 20:11.320
So, so essentially, he came into University of Michigan at like 15 or 16 years old and

20:11.320 --> 20:15.640
I was, you know, like an old graduate, old jaded graduate student, you know, at that

20:15.640 --> 20:16.640
point.

20:16.640 --> 20:20.760
And, uh, it started working in our lab and, you know, he is just very good and we hit

20:20.760 --> 20:26.720
it off and would spend a lot of time together, um, outside of his ex too, like mining bitcoin

20:26.720 --> 20:31.800
or building drones or whatever, you know, just kind of having fun and doing technical

20:31.800 --> 20:32.800
stuff together.

20:32.800 --> 20:33.800
Uh-huh.

20:33.800 --> 20:34.800
Yeah.

20:34.800 --> 20:35.800
Yeah.

20:35.800 --> 20:40.520
Uh, and so you guys, uh, you guys started this company, the, you, you talked about how the

20:40.520 --> 20:45.880
problems were similar, but how did the, what was the genesis for, you know, the idea behind

20:45.880 --> 20:47.880
what you're doing at deep-gram?

20:47.880 --> 20:48.880
Yeah.

20:48.880 --> 20:52.120
So, so Noah definitely has to take credit for this, my co-founder.

20:52.120 --> 20:57.640
So I was a little naysayer at first, um, where he, he wanted to start recording his life.

20:57.640 --> 21:02.600
So he built a, a little device out of like an Intel Edison, um, or a Raspberry Pi, one

21:02.600 --> 21:08.200
of these that it just had a battery, a Wi-Fi antenna, microphone, and a, you know, process

21:08.200 --> 21:14.240
around it, essentially, and he set it up so that it would record 24-7 and basically every

21:14.240 --> 21:18.480
minute make a new audio file and just sort of dump it into, um, storage.

21:18.480 --> 21:22.080
And then whenever it came in contact with Wi-Fi, it would upload all of it.

21:22.080 --> 21:23.080
Oh, wow.

21:23.080 --> 21:27.200
So essentially, he was backing up his life, backing up his audio life at least, uh-huh.

21:27.200 --> 21:29.840
And I was like, what are you going to do with all of that?

21:29.840 --> 21:32.920
You know, you're, trust me, your life's not that interesting.

21:32.920 --> 21:37.320
You know, in real time, you're not going to go back and listen to it again, right?

21:37.320 --> 21:39.000
And he's like, yeah, whatever, right?

21:39.000 --> 21:43.720
And so he recorded like two weeks of his life, you know, several hundred hours and, you

21:43.720 --> 21:46.920
know, you're sitting there at the end of it thinking like, oh yeah, okay, now this is

21:46.920 --> 21:47.920
a real problem.

21:47.920 --> 21:50.840
How are we going to go back and find anything that we want to hear?

21:50.840 --> 21:55.040
And so we started, we did the first thing that you would think of, um, hey, let's turn

21:55.040 --> 21:57.240
this into text, you know, speech to text.

21:57.240 --> 22:02.560
And, um, when that didn't work very well, because, uh, this, that's just like the state of

22:02.560 --> 22:09.400
speech to text, essentially, where if you have a microphone that is not super high quality

22:09.400 --> 22:14.400
and it's not right up in somebody's face and the person is not annunciating really well,

22:14.400 --> 22:17.800
then you're going to get pretty bad word error rate, meaning, you know, it's not going

22:17.800 --> 22:18.800
to be that accurate.

22:18.800 --> 22:19.800
Right, right.

22:19.800 --> 22:24.360
And, and so, so that's, that's a situation for like almost all of the world's audio.

22:24.360 --> 22:28.480
It's not great audio, um, but in this case, all of the audio was like that.

22:28.480 --> 22:31.840
And we're like, okay, this speech to text thing is not going to work.

22:31.840 --> 22:33.640
Um, can we do something better?

22:33.640 --> 22:36.960
Maybe, maybe somebody in the world out there like Google, hey, they know how to do search,

22:36.960 --> 22:38.280
they know how to do audio.

22:38.280 --> 22:41.840
Maybe they've made some kind of API or something that can do this audio search, right?

22:41.840 --> 22:45.760
And so we started playing around and looking there and we just couldn't find anything.

22:45.760 --> 22:51.680
And, uh, we found papers actually papers from like 2008, 2009, where Google wrote about

22:51.680 --> 22:55.480
this type of thing like doing search and audio, um, their technique was to turn it into

22:55.480 --> 22:59.160
text and then tried to search in it and it worked pretty well when it was on a reduced

22:59.160 --> 23:00.160
domain.

23:00.160 --> 23:06.880
So they did like, uh, political speeches and, uh, yeah, and they had fairly good results,

23:06.880 --> 23:09.320
but, you know, when you try to generalize it, it doesn't work very well because everybody

23:09.320 --> 23:13.360
speaks a little bit differently and political speeches are well recorded and, you know, everybody's

23:13.360 --> 23:16.760
annunciating, you know, so it goes pretty well then.

23:16.760 --> 23:20.200
But if you try to do this in a general sense, it doesn't work that well and we, we emailed

23:20.200 --> 23:24.920
us or, um, you know, set up a Skype call, um, with one of the engineers on the paper and

23:24.920 --> 23:26.960
said like, what are you guys doing now?

23:26.960 --> 23:31.080
Because, um, you know, some years had passed, you know, surely guys are working on this

23:31.080 --> 23:32.080
problem, right?

23:32.080 --> 23:33.880
And they're like, no, no, no, we gave up on that.

23:33.880 --> 23:34.880
We're not doing that.

23:34.880 --> 23:38.080
Um, we're just trying to make our speech a text better.

23:38.080 --> 23:39.080
Okay.

23:39.080 --> 23:40.080
Um, we're like, huh, okay.

23:40.080 --> 23:41.400
So it's still not very good.

23:41.400 --> 23:42.680
That doesn't help us.

23:42.680 --> 23:45.680
Um, so, so we started just working on ourselves.

23:45.680 --> 23:49.640
We were like, okay, you know, we know signals, we know machine learning, we know how to deal

23:49.640 --> 23:54.200
with lots and lots of data and, uh, let's see if we can make some kind of search engine

23:54.200 --> 23:55.200
for audio.

23:55.200 --> 24:01.040
And over the course of about four or five months, we went from, you know, very poor accuracy,

24:01.040 --> 24:07.720
meaning like maybe 20% of the time you'll find what you're looking for to, uh, 80 or 90%

24:07.720 --> 24:09.360
of the time finding what you're looking for.

24:09.360 --> 24:13.800
So that's like going, you know, state of the arts, 20%, you're at 90%, you're feeling

24:13.800 --> 24:14.800
pretty good.

24:14.800 --> 24:19.560
Um, so, so that's, uh, what the genesis of Deepgram essentially, we're like, whoa,

24:19.560 --> 24:21.640
this has a lot of applications.

24:21.640 --> 24:24.680
And at the time, you know, we were coming out of academia and we're like, hey, students

24:24.680 --> 24:26.800
can use this for lectures and whatever.

24:26.800 --> 24:31.040
But when we start to think about it a lot more, we're like, you know what, the world, like,

24:31.040 --> 24:36.480
the big audio source in the world, the huge data lake of audio in the world is like recorded

24:36.480 --> 24:37.800
business calls.

24:37.800 --> 24:42.000
So customer service calls and things like that, just call center stuff.

24:42.000 --> 24:43.360
And they're all really low quality.

24:43.360 --> 24:47.040
Nobody knows what to do with them, essentially, and we're like, man, like a Deepgram could

24:47.040 --> 24:50.560
be a massive company, um, if we do this right, yeah.

24:50.560 --> 24:56.760
Well, I think the other killer use case is, uh, I don't know if you're married or not,

24:56.760 --> 25:00.840
but my wife and I always have this conversation where, oh, I just told you this or no, you

25:00.840 --> 25:02.160
didn't say that or whatever.

25:02.160 --> 25:07.240
If I had his device and recorded all of our audio and then could easily go back and prove

25:07.240 --> 25:11.560
whether I said that or not, uh, there's got to be a huge market for that.

25:11.560 --> 25:16.600
I love, I love this use case for Deepgram because yes, I feel the same way.

25:16.600 --> 25:19.680
Actually, we've run across a lot of people though that are like, oh, no, this will make

25:19.680 --> 25:20.680
things worse.

25:20.680 --> 25:27.600
They probably would because my, uh, I think I probably think I'm right more than I actually

25:27.600 --> 25:29.400
am much more than I actually am.

25:29.400 --> 25:34.720
Yeah, exactly, but, um, but no, I think there's a regularizing effect there that if you

25:34.720 --> 25:38.920
know that there's something, uh, recording maybe before you say, I know I said this.

25:38.920 --> 25:43.880
You'll actually go back and check or something, you know, so I think it could work out.

25:43.880 --> 25:47.720
Actually, we do, we do kind of think about this problem.

25:47.720 --> 25:50.320
Um, I think that Mark is not really ready for it yet.

25:50.320 --> 25:55.400
You know, if you just put a recorder on everybody and said, you know, yeah, now we're backing

25:55.400 --> 25:58.000
up everybody's life and everything you say is recorded.

25:58.000 --> 26:02.520
Uh, I don't think people right now are going to be super into that.

26:02.520 --> 26:08.400
But it might come, um, and, and I kind of hope it does like, like for me, I wish I, I

26:08.400 --> 26:12.200
had it and we do have these devices like laying around our office from those days, you

26:12.200 --> 26:13.840
know, where I think, man, if I was just, you know, you know, I think, man, if I was just

26:13.840 --> 26:16.600
wearing that all day every day, um, then that would be great.

26:16.600 --> 26:18.240
Of course, they're very heavy.

26:18.240 --> 26:20.920
So we don't do that now, but you could make it much smaller.

26:20.920 --> 26:21.920
Yeah.

26:21.920 --> 26:23.480
Probably a lot later than they were then.

26:23.480 --> 26:24.480
Yep.

26:24.480 --> 26:26.800
Um, interesting.

26:26.800 --> 26:33.600
So you described the, the frustration that you were having with, uh, trying to do this

26:33.600 --> 26:40.680
and the state of the art being turning the audio into text and then running a search

26:40.680 --> 26:45.800
engine against that text is the implication then that you guys are not, uh, using text

26:45.800 --> 26:47.160
as an intermediary.

26:47.160 --> 26:48.160
Yes.

26:48.160 --> 26:49.160
That is true.

26:49.160 --> 26:52.240
So, um, we, we do build an index just like you would.

26:52.240 --> 26:55.840
So, you know, this, this is sort of the terminology that you would say before you built

26:55.840 --> 26:57.120
an index out of text, right?

26:57.120 --> 26:59.520
Well, we're not building an index out of text anymore.

26:59.520 --> 27:03.840
We're building an index, you know, like actually out of activations in a deep neural network,

27:03.840 --> 27:08.720
you know, uh, so, so activations in a representation that's deep in a deep neural network.

27:08.720 --> 27:13.280
Um, the best way to think of that though is that you're doing something kind of like searching

27:13.280 --> 27:14.440
through phonemes.

27:14.440 --> 27:18.520
So phonemes are like the, uh, the alphabet of speech, right?

27:18.520 --> 27:24.680
Um, but they're kind of a human, um, they're, like humans have assigned to those.

27:24.680 --> 27:27.880
Like those, these are the 40 phonemes or these are the 53 phonemes.

27:27.880 --> 27:29.480
Like you don't have to do that.

27:29.480 --> 27:33.720
You can just have it be defined by the data and, um, so that, that's what we do.

27:33.720 --> 27:39.920
But if you look at the, if you look at what these match up to, it's very similar to phonemes.

27:39.920 --> 27:45.480
So that, uh, statement that you quickly, uh, went by kind of blew my mind a little bit.

27:45.480 --> 27:51.280
You're indexing, you're building an index out of activations deep in a neural network that

27:51.280 --> 27:53.160
elaborate on that a little bit for us.

27:53.160 --> 27:54.160
Yeah, absolutely.

27:54.160 --> 27:59.720
So the, the output of a neural network is, is again, just an activation essentially, um,

27:59.720 --> 28:05.360
and what you're doing is you're forcing it to like, in the case of a speech recognition,

28:05.360 --> 28:09.800
you're forcing it to guess like, what is the word being said at this time, um, or, or

28:09.800 --> 28:15.840
in the case of like doing some multi-class, um, uh, uh, network that's trying to guess,

28:15.840 --> 28:20.480
you know, is this a handwritten zero or handwritten two or something like that that's trying

28:20.480 --> 28:21.480
to guess that.

28:21.480 --> 28:22.480
Yeah.

28:22.480 --> 28:23.480
Right.

28:23.480 --> 28:27.960
And so it, if you just sort of back up one layer from that, it's still pretty close

28:27.960 --> 28:32.760
to, to that output, you know, it's just some like linear combination and that has been

28:32.760 --> 28:36.240
stuck through an activation, um, to get to that output.

28:36.240 --> 28:42.240
And so, so, you know, you can, you can think of, um, images where it, at the very top,

28:42.240 --> 28:46.440
it depends on how you think of neural networks, but at the, at the, near the input of the,

28:46.440 --> 28:52.600
of the neural network, um, there's, it's looking for edges or rower things or something

28:52.600 --> 28:53.600
like that, right?

28:53.600 --> 28:56.760
And then as you get deeper, it's looking more for like faces or trees or something like

28:56.760 --> 28:57.840
that, right?

28:57.840 --> 29:01.240
And the same thing is happening in audio and now it's looking for things that are kind

29:01.240 --> 29:05.000
of word like or kind of like portions of a word like, right?

29:05.000 --> 29:10.000
And, um, so, so those activations are what we are interested in.

29:10.000 --> 29:14.080
And how deep are the networks that you're typically using and how do you know which of

29:14.080 --> 29:20.720
those activations to tap into or capture and, uh, is that static or dynamic?

29:20.720 --> 29:27.720
Does that change, uh, based on the utterances or how do you figure all that out?

29:27.720 --> 29:32.440
Very, very great question, um, you can, so there's several ways to go about this problem.

29:32.440 --> 29:36.560
You can just say literally let the data define this and, um, go to town.

29:36.560 --> 29:39.360
Um, that, that does work pretty well.

29:39.360 --> 29:43.560
Um, you can, you can sort of get a boost in accuracy, uh, a little bit of a boost in

29:43.560 --> 29:44.560
accuracy.

29:44.560 --> 29:49.040
If you, if you pin it at first, like when you're training, you might pin it to phonemes

29:49.040 --> 29:55.920
or you might pin it to some, uh, larger subset and, uh, then, then remove that restriction.

29:55.920 --> 29:59.160
So it's sort of seeded that it should have learned something like this.

29:59.160 --> 30:03.760
And then now it sort of builds off that knowledge, um, so, so that's kind of how you can guide

30:03.760 --> 30:08.120
the network, you know, you're pointing it in a direction that's approximately correct,

30:08.120 --> 30:13.200
but then you relax that and allow it to pick the things that are, that are working best.

30:13.200 --> 30:17.760
Um, the things that we're working on right now to make this even more accurate are instead

30:17.760 --> 30:24.040
of, uh, a word target, uh, you are searching for a light, oh, sorry, not searching.

30:24.040 --> 30:28.200
You're trying to force the network to guess like a topic or a part of speech, you know,

30:28.200 --> 30:30.160
is it a noun or a verb or something like that?

30:30.160 --> 30:32.440
And you do all of these things at the same time.

30:32.440 --> 30:36.800
So your network is sort of branched out and it knows, you know, I'm, I'm trying to guess

30:36.800 --> 30:37.800
words fine.

30:37.800 --> 30:38.800
I'm trying to guess the topic.

30:38.800 --> 30:40.400
I'm trying to guess all of these things.

30:40.400 --> 30:46.080
And so when you, when you force that, um, uh, restriction on the network, then it, it

30:46.080 --> 30:51.600
actually, it, you can control kind of what the activations are, are the information

30:51.600 --> 30:55.360
that the activations are holding, you can kind of control that by the target.

30:55.360 --> 31:02.880
Uh, so how, uh, can you say how deep your network's typically are, they, what you would

31:02.880 --> 31:09.000
think of is, you know, very deep, you know, tens, hundreds, uh, or more layers or, are

31:09.000 --> 31:10.000
they relatively shallow?

31:10.000 --> 31:14.040
Yeah, we're in the tens, um, in the tens category.

31:14.040 --> 31:19.400
And, um, yeah, we, so we, we have had a lot of success in that regime.

31:19.400 --> 31:23.840
If you go deeper, you need, um, a lot more firepower on the computational side.

31:23.840 --> 31:28.040
So, and you actually, and you need, um, more engineering on the, like, where do I put

31:28.040 --> 31:33.040
my skips and where do I put, like, uh, everything like that, you know, um, architecture becomes

31:33.040 --> 31:34.040
more complex.

31:34.040 --> 31:35.040
Yeah, exactly.

31:35.040 --> 31:40.200
And so, um, so we're, uh, a little, we're like an eight person team.

31:40.200 --> 31:46.040
So we don't, uh, yeah, we, we, we tried to, um, minimize some of those, uh, engineering

31:46.040 --> 31:51.320
bottlenecks as much as possible, um, and we've seen very good, oh, well, I guess, I guess

31:51.320 --> 31:55.040
another way to say this is that if the state of the arts 20% and you're like in the 80 and

31:55.040 --> 32:00.040
90% range with the networks that you have, you know, then, like, you could spend a lot

32:00.040 --> 32:05.160
of time turning it into, like, 92% accurate, um, by making your, um, making your network

32:05.160 --> 32:07.120
a lot deeper or something like that.

32:07.120 --> 32:12.200
But we, yeah, we, we don't focus too much on that yet until we have the pressure, um,

32:12.200 --> 32:13.200
to do that.

32:13.200 --> 32:14.200
Okay.

32:14.200 --> 32:15.200
Okay.

32:15.200 --> 32:22.080
So with the network in the tens of layers, then it sounds like it's, you have a pretty

32:22.080 --> 32:27.240
good sense based on your architecture of where, uh, you know, what layers, the phoneme

32:27.240 --> 32:34.680
layer versus, I don't even know names for the, the other, um, we don't know names either.

32:34.680 --> 32:35.680
Honestly.

32:35.680 --> 32:41.760
Like this, this is, it would be really, um, this hasn't been explored as much as images,

32:41.760 --> 32:45.640
you know, there, in, you know, there's sort of reasons for that, like, where are the data

32:45.640 --> 32:46.640
sets to do this?

32:46.640 --> 32:54.160
You know, um, also humans, I think, are not as interested, um, or I guess it's harder to,

32:54.160 --> 32:58.520
to ingest audio than it is images, images, you know, you're like instantly see it.

32:58.520 --> 33:03.360
You're also entertained by the images that you see that you see, but the, um, if you hear

33:03.360 --> 33:08.440
audio that you're not super interested in, um, you're like, you, you, your eyes glaze over

33:08.440 --> 33:09.440
right away, right?

33:09.440 --> 33:14.400
And so labeling the audio data is expensive and time consuming.

33:14.400 --> 33:18.080
And you can't just like click through a bunch of things and now you've labeled a ton

33:18.080 --> 33:21.840
of images, you know, you can't just click through a bunch of things and label a bunch of

33:21.840 --> 33:25.920
audio files, you know, like, that didn't work.

33:25.920 --> 33:31.240
And so those, those are kind of the problems that audio faces, but also, uh, you can't

33:31.240 --> 33:36.560
point to things and, um, you can't, you can't point to things and say, like that little

33:36.560 --> 33:40.760
edge feature right there is important because you're hearing it, right?

33:40.760 --> 33:44.480
It's, it's just not, we don't have that visualization capability.

33:44.480 --> 33:46.960
And so, uh, it's a little more challenging in that regard.

33:46.960 --> 33:50.560
So, so yeah, we don't have names for this stuff either, you know, um, there are, there

33:50.560 --> 33:55.800
are linguists out there in the world that probably have some, some names, you know, uh, but

33:55.800 --> 34:00.480
we just look at like a 2D FFT, um, you know, a spectrogram of the audio and say, like,

34:00.480 --> 34:02.880
oh, I can sort of see what's going on there.

34:02.880 --> 34:06.560
And you just kind of treat it like it's an image and think of it that way.

34:06.560 --> 34:07.560
Okay.

34:07.560 --> 34:14.520
Uh, so the other interesting, um, the interesting use case that occurred to me when I first

34:14.520 --> 34:20.880
saw your stuff was, you know, I've got a bunch of audio in the form of podcasts, podcast

34:20.880 --> 34:22.200
interviews.

34:22.200 --> 34:27.160
And, uh, I'd love to find a way to make that more accessible.

34:27.160 --> 34:31.520
And one idea that I've had for a while is, hey, it'd be great if I had a, a bot, like

34:31.520 --> 34:37.160
a Facebook messenger bot or a chat bot or whatever, where, you know, you, you pull this thing

34:37.160 --> 34:42.920
up and it's a, and you can ask it, hey, I want to find 20 episodes about convolutional

34:42.920 --> 34:44.200
neural nets.

34:44.200 --> 34:49.560
And it will, you know, look in its index and tell you, oh, check out, you know, episodes,

34:49.560 --> 34:55.160
you know, 13 and five at times x, y and z.

34:55.160 --> 34:59.640
It sounds like you're saying that your stuff could be a part of building that.

34:59.640 --> 35:04.120
So what would the process be to, you know, to get to what I'm talking about?

35:04.120 --> 35:08.480
Forget all the bot stuff, but, you know, just in terms of the voice search engine piece.

35:08.480 --> 35:10.360
Yeah, that's exactly right.

35:10.360 --> 35:17.320
The, um, the, the, the mentions is a part of it and topics is another part of it.

35:17.320 --> 35:20.360
And that's exactly the type of problem that DeepGram solves.

35:20.360 --> 35:24.040
So you have, uh, you have a lot of audio, right?

35:24.040 --> 35:27.760
And you have, you have listeners that don't want to sit through, you know, 20 hours of

35:27.760 --> 35:32.480
audio, trying to look for that one little tidbit, um, of information that they're, that

35:32.480 --> 35:34.400
they're interested in that time.

35:34.400 --> 35:37.360
And, um, that is what DeepGram solves.

35:37.360 --> 35:45.320
And that is actually, um, kind of a, a, a really interesting interactive experience once

35:45.320 --> 35:49.800
you finally do it, you know, so like when we first built DeepGram and we made, you know,

35:49.800 --> 35:54.680
the search engine and actually found moments where we were like, whoa, there, I, this is exactly

35:54.680 --> 35:55.680
what I was looking for.

35:55.680 --> 35:59.880
You know, it's a totally, totally different experience than what you would feel if you

35:59.880 --> 36:01.760
had tried to do this with speech detects.

36:01.760 --> 36:05.840
And so, so yeah, we're, we're very into solving that type of problem.

36:05.840 --> 36:11.320
And, and the way that you do it with DeepGram is we, um, we provide a, an API.

36:11.320 --> 36:17.040
So you go and sign up at dgram.com and, um, create an account and there, you upload your

36:17.040 --> 36:19.920
audio and you give us the query that you're looking for.

36:19.920 --> 36:24.480
So if you're looking for convolutional neural nets or CNNs or, uh, convolution, you

36:24.480 --> 36:28.720
know, put those keywords in, send it to the API and you'll get the results back of all

36:28.720 --> 36:32.080
of the, uh, mentions that were in your audio.

36:32.080 --> 36:37.840
And, uh, if you want to make that go even deeper to, it's, where it's more topic based

36:37.840 --> 36:42.060
rather than keyword based, then you like sort of work with us, uh, for a custom API end

36:42.060 --> 36:48.160
point to build a model that is more, um, tuned to the topics that you care about.

36:48.160 --> 36:54.440
And that is essentially you guys working in a professional services or whatever capacity

36:54.440 --> 36:59.880
needs, uh, build some, um, I don't know, what is that, what does that process look like

36:59.880 --> 37:00.880
from your perspective?

37:00.880 --> 37:03.960
What are you actually doing behind the scenes to make the, the topical stuff work?

37:03.960 --> 37:04.960
Yeah.

37:04.960 --> 37:05.960
Yeah.

37:05.960 --> 37:06.960
Good, good question.

37:06.960 --> 37:08.560
Um, the, so the general stuff kind of works right off the bat.

37:08.560 --> 37:11.640
Hey, you, you want to search for a keyword, you know, we have a lot of data that we've

37:11.640 --> 37:13.000
already trained on.

37:13.000 --> 37:16.360
And even if your keyword isn't in there, we can find it because it's essentially a fuzzy

37:16.360 --> 37:17.360
search.

37:17.360 --> 37:22.200
Um, but if you want to do this topic modeling, uh, then what you do is give us labeled

37:22.200 --> 37:23.200
data.

37:23.200 --> 37:29.000
So in your case, it would be, um, I have, I have all these episodes and they were the

37:29.000 --> 37:34.280
contents of these episodes, uh, you would have to know this, um, you know, yeah, we talked

37:34.280 --> 37:38.200
about convolutional neural networks in this one, um, we talked about, you know, recurrent

37:38.200 --> 37:41.840
neural networks in this one and boosted decision trees in this and, you know, we talked

37:41.840 --> 37:44.080
about productizing in this one.

37:44.080 --> 37:50.600
And, uh, you just put those simple labels in and, um, then you train a, um, model and

37:50.600 --> 37:53.600
it doesn't have to be a deep neural network either at that point because you have such

37:53.600 --> 37:58.560
a small amount of data, you probably do something like a, uh, boosted decision tree, um,

37:58.560 --> 38:03.840
but you train this model to do that topic prediction based on the search in your, in your

38:03.840 --> 38:04.840
audio.

38:04.840 --> 38:07.840
And this is actually getting really into the weeds, but the way that it actually works is

38:07.840 --> 38:11.040
we utilize the search for that topic modeling.

38:11.040 --> 38:17.640
So our, our search is, is the best in the world is the most accurate, um, and, and if you

38:17.640 --> 38:21.760
train a model with a target that says, here are these topics.

38:21.760 --> 38:25.480
And I want you to be able to predict these topics and I want you to be able to generalize

38:25.480 --> 38:31.000
to other audio files, then our, our model that we're building, whatever it is, but that

38:31.000 --> 38:37.640
topic modeling, uh, model, it is going through and it's not doing any heuristics whatsoever.

38:37.640 --> 38:41.880
It's sort of exhaustively searching all the possible phrases and saying, like, which

38:41.880 --> 38:44.120
ones help and which ones don't?

38:44.120 --> 38:48.440
And it's recursively eliminating the ones that don't help and, and it's arriving on things

38:48.440 --> 38:50.960
to search for that are very good.

38:50.960 --> 38:52.960
And it doesn't have to be a single search term.

38:52.960 --> 38:57.280
It could be tensing, you know, tens search terms and it also might be the non-existence of

38:57.280 --> 38:58.280
a term.

38:58.280 --> 39:01.400
It's like, you know, if, if you're talking about these 10 things and this other one, then

39:01.400 --> 39:04.880
it's some other topic, you know, and it, et cetera, and I don't even know how it works,

39:04.880 --> 39:05.880
right?

39:05.880 --> 39:07.800
It, that's, that's how it works.

39:07.800 --> 39:11.720
And then in the end, you look at the output and you say, like, these are the things

39:11.720 --> 39:14.920
it's saying search for and these are the things it's saying don't search for the area,

39:14.920 --> 39:17.040
you know, you don't want these to exist.

39:17.040 --> 39:20.560
And that's how the model works, you know, and it works extremely well.

39:20.560 --> 39:25.840
So, um, so yeah, that's, that's sort of, you know, how the sausage is made.

39:25.840 --> 39:33.400
And how much, how much data do you need in order for you to, to start getting, uh, interesting

39:33.400 --> 39:37.480
results, both from the basic search and, uh, the topic modeling?

39:37.480 --> 39:43.720
Or is the fact that you guys have already trained your model, like, well, let's start with

39:43.720 --> 39:44.720
that question.

39:44.720 --> 39:49.520
Um, is the fact that you guys have already trained the model on the data that you already

39:49.520 --> 39:50.520
have?

39:50.520 --> 39:57.640
Um, does that mean that I don't need to have some, uh, some specific level of data about

39:57.640 --> 40:00.480
my domain in order to get good results?

40:00.480 --> 40:01.480
Yeah.

40:01.480 --> 40:05.840
In some cases, that, that's how it works where, you know, if you have sort of like a broad

40:05.840 --> 40:10.840
topic, like, is this about sports or is this about politics, you know, um, then, then

40:10.840 --> 40:15.760
that data is sort of already lying around and, and, and incorporated into a model.

40:15.760 --> 40:19.800
But if you're talking about niche, niche markets, you know, um, then you probably want to

40:19.800 --> 40:24.240
supply something and, uh, then we'll, you know, build a model on top of that.

40:24.240 --> 40:28.480
But that doesn't, the data that you supply probably isn't the only training data that

40:28.480 --> 40:31.560
we're using, you know, we're just, we're just supplying that.

40:31.560 --> 40:35.040
It's essentially a form of transfer learning and then we're like changing the target of

40:35.040 --> 40:37.600
the model, mm-hmm.

40:37.600 --> 40:39.360
And so what am I supplying then?

40:39.360 --> 40:40.360
Yeah.

40:40.360 --> 40:44.400
You would supply like audio with some tags, um, so like here's an hour long audio and

40:44.400 --> 40:48.680
here are the 20 things we talked about or here are the 10 questions I asked or something

40:48.680 --> 40:49.680
like that.

40:49.680 --> 40:50.680
Okay.

40:50.680 --> 40:57.600
And, uh, the neural net can just figure out what's relevant and what is, uh, and kind of

40:57.600 --> 40:59.560
map those to the tags.

40:59.560 --> 41:00.560
Exactly.

41:00.560 --> 41:06.280
And even given, uh, you know, I would imagine a fairly limited or what, how much, how much

41:06.280 --> 41:12.120
audio and tags do I need to give the model for that to be useful for it, for it to be

41:12.120 --> 41:17.320
useful to a, like a consumer that's searching for something, um, because they're fairly

41:17.320 --> 41:18.880
error tolerant actually, right?

41:18.880 --> 41:23.160
Like if you get, if you get one out of two wrong, that's not too bad as long as one of

41:23.160 --> 41:24.160
those is okay, right?

41:24.160 --> 41:27.600
As long as one of those is what you're actually looking for, so you probably need something

41:27.600 --> 41:33.200
like, um, 50 or 100, um, different labeled files and you'll get a results that are similar

41:33.200 --> 41:34.200
to that.

41:34.200 --> 41:38.000
If you have around a thousand labeled files, then, um, then you get results that are

41:38.000 --> 41:40.680
more like, you know, 90% accuracy.

41:40.680 --> 41:43.760
And these are hour long files or shorter?

41:43.760 --> 41:48.000
It, it kind of depends on what you're searching for, but, um, they're generally in like the

41:48.000 --> 41:49.800
10 to hour long range.

41:49.800 --> 41:52.720
Um, you'll need more files if it's only like a minute long.

41:52.720 --> 41:53.720
Okay.

41:53.720 --> 41:54.720
Yeah.

41:54.720 --> 41:56.320
Oh, interesting, interesting.

41:56.320 --> 42:03.240
And so that, so then what you guys are offering is a service, um, and it, that exposes an API,

42:03.240 --> 42:07.960
but you also have done some work around, uh, an open source framework.

42:07.960 --> 42:10.560
Um, let's talk about that for a little bit.

42:10.560 --> 42:13.960
So, uh, why don't you walk us through what you've done there?

42:13.960 --> 42:14.960
Yeah.

42:14.960 --> 42:16.000
We're, we're extremely pumped about it.

42:16.000 --> 42:17.000
It's called Kerr.

42:17.000 --> 42:18.000
It's open source.

42:18.000 --> 42:19.320
You can go contribute to it.

42:19.320 --> 42:25.840
It's on GitHub, um, but the, the idea behind Kerr is that, uh, years ago, you know, around

42:25.840 --> 42:30.560
a decade ago, GPUs came onto the scene for neural networks, um, data started to become

42:30.560 --> 42:36.600
available and it became a really smart idea to start training neural networks on GPUs.

42:36.600 --> 42:41.320
And the people doing it back in the day knew something about GPUs, it, you know, in order

42:41.320 --> 42:45.200
to accomplish that task, you, you had to have some like domain expertise in order to pull

42:45.200 --> 42:46.960
it off in a good way.

42:46.960 --> 42:51.800
And, uh, Nvidia started to pick up on this and said, hey, uh, we're going to make CUDA,

42:51.800 --> 42:57.080
a framework that allows like C developers to get a little handle into the GPU and be

42:57.080 --> 43:03.480
able to train things that way, or be able to be able to use the GPU for matrix, um, multiplication

43:03.480 --> 43:04.960
and things like that.

43:04.960 --> 43:05.960
And so that's like another layer.

43:05.960 --> 43:10.560
You have the bare hardware and then you have like CUDA and, uh, then you have, um, like,

43:10.560 --> 43:15.440
uh, Brian Catanzaro, uh, making CUDNN so that it even works better for deep neural networks,

43:15.440 --> 43:16.440
right?

43:16.440 --> 43:20.920
But this is still all very, um, low level, uh, type stuff.

43:20.920 --> 43:28.880
And then, uh, you know, outcome other frameworks like theano or, uh, cafe or, um, TensorFlow.

43:28.880 --> 43:31.120
And those are another abstract layer on top.

43:31.120 --> 43:33.000
They make it more human palatable, right?

43:33.000 --> 43:34.000
Right.

43:34.000 --> 43:35.000
Right.

43:35.000 --> 43:36.000
Right.

43:36.000 --> 43:38.600
They're, they're much more palatable for the, um, developer or computer scientist that,

43:38.600 --> 43:41.240
you know, like really knows their stuff, right?

43:41.240 --> 43:44.560
And, um, and that, and that's totally fine and they work very well.

43:44.560 --> 43:49.400
Um, what we, what we have found out though at working internally, um, at deepgram is

43:49.400 --> 43:54.840
that working in those frameworks still is very, it's very slow for us to, uh, to try to

43:54.840 --> 44:00.240
do experiments, essentially, to try new model architectures and then, and then see the

44:00.240 --> 44:06.520
result of because we are not, we're not necessarily training time limited where, uh, we would

44:06.520 --> 44:08.120
really love to be training time limited.

44:08.120 --> 44:12.040
We were engineering limited, you know, and so it's like the time that you're putting in

44:12.040 --> 44:15.920
to sort of cook all of this up and make sure, do all the error checking and whatnot to

44:15.920 --> 44:17.720
make sure it's like training the way it's supposed to.

44:17.720 --> 44:21.600
We're like, man, why don't we just make some other framework on top?

44:21.600 --> 44:24.880
Let's just stack another framework on top that is more abstract.

44:24.880 --> 44:29.440
That sort of doesn't care about the back end and it, it doesn't care, you know, if you're

44:29.440 --> 44:33.760
using theano or TensorFlow or whatever, you can just switch it with a flip with a flip

44:33.760 --> 44:34.760
of the switch.

44:34.760 --> 44:40.360
And, um, if, if something's faster, fine, whatever, but like all we really want to do is

44:40.360 --> 44:41.360
describe our model.

44:41.360 --> 44:44.880
We want to say, hey, the input is going to be this audio.

44:44.880 --> 44:49.520
Then we're going to have a convolution, a 2D convolution and another con, a 2D convolution

44:49.520 --> 44:50.760
with a batch norm.

44:50.760 --> 44:54.240
And then we're going to have some, uh, a few recurrent, uh, layers.

44:54.240 --> 44:55.800
Those are going to have batch norm too.

44:55.800 --> 44:59.720
And then we're going to stick those out into, you know, a dense that then predicts every

44:59.720 --> 45:03.600
time, time slice, which character is going to be there, which word is going to be there.

45:03.600 --> 45:05.240
And so that's how we want to think of it.

45:05.240 --> 45:09.240
We don't want to think about like Python code and like, how do we like put all of that

45:09.240 --> 45:10.240
in there?

45:10.240 --> 45:14.800
And so, so that's what, um, we start working on a deepgram is like, how do we do that?

45:14.800 --> 45:20.000
So that we can multiply our engineering effort, essentially, you know, um, I just go in and

45:20.000 --> 45:23.960
I change a few settings and, and then start running my network again and then go off

45:23.960 --> 45:25.080
and do something else.

45:25.080 --> 45:27.600
And that's, that's exactly what cur is.

45:27.600 --> 45:30.520
It's a descriptive, deep learning framework.

45:30.520 --> 45:35.120
And, um, you know, we have examples on how to do image classification, examples on how

45:35.120 --> 45:40.720
to do speech recognition, um, with a network that's very similar to BIDU's deep speech

45:40.720 --> 45:45.280
model and, uh, like language, uh, language modeling and things like that.

45:45.280 --> 45:50.080
And it's all in this descriptive format, um, it's still not like, don't get me wrong.

45:50.080 --> 45:55.600
Like deep learning is still not easy because, um, right, because there's a computational

45:55.600 --> 45:58.400
problem there and there's a data problem there.

45:58.400 --> 46:00.360
Like how do you get it into the format that you need?

46:00.360 --> 46:01.640
You know, how do you collect the data?

46:01.640 --> 46:02.640
How do you clean it?

46:02.640 --> 46:03.680
Uh, everything like that.

46:03.680 --> 46:07.520
But the model part, you know, once you have your data and once you're all set up, the

46:07.520 --> 46:11.160
model part is now like so much easier for us using curve.

46:11.160 --> 46:16.360
And so, so we thought, you know, um, this is kind of a competitive advantage, yeah, it

46:16.360 --> 46:23.000
is, um, but we have gained so much knowledge by, um, using open source software and talking

46:23.000 --> 46:26.680
with people very freely, sort of in the deep learning community that, you know, this

46:26.680 --> 46:28.280
tool has been so valuable to us.

46:28.280 --> 46:33.080
Let's just release it like we're, we're probably going to get more, you know, than if we

46:33.080 --> 46:37.480
just kept it to ourselves, you know, and we actually have like, we, we released

46:37.480 --> 46:42.960
the current framework and within like weeks, somebody had added multi GPU support, you

46:42.960 --> 46:46.520
know, and I was like, whoa, oh wow, these people are serious, right?

46:46.520 --> 46:53.600
And so, so yeah, and, and this is also another way to like, um, if you're, if you're an

46:53.600 --> 46:57.760
AI company out there in the world and you want to hire engineers, you know, this is another

46:57.760 --> 47:00.920
way to find good ones and they could be across the world.

47:00.920 --> 47:06.480
And so, so it's like we're sort of, we want to, we want to be giving to the community.

47:06.480 --> 47:12.680
We also just want to be, um, we want to be part of that conversation because I think we

47:12.680 --> 47:14.760
have a lot to add, essentially.

47:14.760 --> 47:21.240
And, um, I think that the deep learning community, there's so much demand to, um, there's

47:21.240 --> 47:26.320
so much hype, first of all, um, but there's also, there's a ton of demand for on talent

47:26.320 --> 47:30.720
and there's a ton of demand for the type of critical thinking you need in order to

47:30.720 --> 47:32.480
solve these deep learning problems.

47:32.480 --> 47:34.040
You don't have to be secretive.

47:34.040 --> 47:38.920
You don't have to be like, this is our secret soft that whatever, no, everybody is like

47:38.920 --> 47:43.440
talent limited, they're computationally limited, they're data limited, they're not like

47:43.440 --> 47:44.440
good idea limited.

47:44.440 --> 47:45.440
So, right.

47:45.440 --> 47:46.440
Right.

47:46.440 --> 47:47.440
So, yeah.

47:47.440 --> 47:49.880
The, you mentioned it's, it's declarative.

47:49.880 --> 47:51.640
That's one of the, the main things that's doing it.

47:51.640 --> 47:59.280
Are you, have you created like a DSL to define your, neural net or is it a different, uh,

47:59.280 --> 48:00.880
type of express differently?

48:00.880 --> 48:01.880
Yeah.

48:01.880 --> 48:06.280
So, okay, great, yeah, great question and the way that you interact with Kerr is you

48:06.280 --> 48:12.640
pip install it and, um, so, so it's, you know, written Python and, uh, you can use it

48:12.640 --> 48:17.800
as an API just as you would carous or something like that where, um, you know, you're programming

48:17.800 --> 48:21.720
in Python and that's just how you use Kerr and that's totally fine.

48:21.720 --> 48:27.440
But sort of the DNA of your model is contained in what we call a Kerr file and that is YAML

48:27.440 --> 48:28.440
or JSON.

48:28.440 --> 48:33.480
And so, so that, that contains like your hyper parameters, your model architecture, like

48:33.480 --> 48:36.400
how you want your data to be supplied and things like that.

48:36.400 --> 48:42.520
Um, and a lot of that is boilerplate that is already, um, out there in examples, essentially.

48:42.520 --> 48:46.840
And so you just like use a Kerr file that somebody else has put out there in the world

48:46.840 --> 48:51.680
and then just edit it a little bit in, for your purpose, essentially.

48:51.680 --> 48:55.880
And so, yeah, that's how it operates, um, just basically YAML files and if you want to

48:55.880 --> 49:01.440
do, um, like a deeper, uh, surgery, then you do it in Python using API.

49:01.440 --> 49:02.440
Hmm.

49:02.440 --> 49:07.520
And does it, uh, can you, uh, does it sit on top of any of the other frameworks or can

49:07.520 --> 49:13.280
you, how do you leverage the work that's, um, being done on, you know, TensorFlow and

49:13.280 --> 49:14.960
all the other frameworks out there?

49:14.960 --> 49:15.960
Yeah, absolutely.

49:15.960 --> 49:16.960
I should have said that earlier.

49:16.960 --> 49:22.480
It does, um, it supports theano, it supports TensorFlow and it supports PyTorch.

49:22.480 --> 49:28.440
And, um, maybe we'll support other backends, um, since, since, uh, like deep learning for

49:28.440 --> 49:34.360
a J is, uh, is working its way into Keras now, uh, you know, we'll probably be supporting

49:34.360 --> 49:35.360
them soon.

49:35.360 --> 49:41.120
So, so yeah, that's, uh, that's, that's kind of how it goes, um, if, if you have a high

49:41.120 --> 49:47.120
level API that would fit into something like Keras, um, then it'll fit into Kerr as well.

49:47.120 --> 49:48.120
Okay.

49:48.120 --> 49:49.120
Yeah.

49:49.120 --> 49:53.920
So we've already done the legwork for those three, you know, TensorFlow, theano and PyTorch.

49:53.920 --> 49:54.920
Awesome.

49:54.920 --> 49:58.760
And you mentioned, uh, you mentioned this already, but it's not just for audio.

49:58.760 --> 50:04.360
It's for images and basically anything that you're trying to use a deep neural net, uh,

50:04.360 --> 50:05.360
with.

50:05.360 --> 50:06.360
Absolutely.

50:06.360 --> 50:10.680
We, all that we do at DeepGram is audio, that's true, um, but the net, but the, uh, Kerr,

50:10.680 --> 50:14.000
you know, and the networks that you can train using Kerr are agnostic.

50:14.000 --> 50:15.000
It doesn't matter.

50:15.000 --> 50:16.200
You know, you can do sequences.

50:16.200 --> 50:21.240
You can do audio, you can do, you know, text, audio, images, you know, it, cook it up

50:21.240 --> 50:22.520
and you'll be able to do it.

50:22.520 --> 50:28.400
Um, we just had a hackathon, um, last weekend and, uh, people were doing all sorts of things,

50:28.400 --> 50:33.560
you know, uh, music, uh, editing, editing videos on the fly so that, you know, your cat will

50:33.560 --> 50:39.120
look like a van go as it's, um, you know, crawling, crawling around and things like that,

50:39.120 --> 50:42.880
you know, like the, and they're using, they're using Kerr to do these things.

50:42.880 --> 50:50.560
So, so yeah, it's, um, it's, it's sort of agnostic, hmm, uh, that's very cool, very

50:50.560 --> 50:51.560
cool.

50:51.560 --> 50:58.560
Um, and so you mentioned, uh, the Baidu deep speech stuff, was that the, uh, was that

50:58.560 --> 51:06.400
the inspiration for Kerr or to what extent do you, is your, uh, is the DeepGram work, um,

51:06.400 --> 51:09.720
you know, your product based on that research?

51:09.720 --> 51:16.200
Sure, so our, our, the models that we use, um, to, to build our indexes and to ingest

51:16.200 --> 51:20.560
audio are extremely similar to the deep speech networks, um, you have a convolutional stack

51:20.560 --> 51:25.900
and you have a recurrent stack and the target is, uh, characters or words, um, in the deep

51:25.900 --> 51:31.400
speech cases characters, but, but nevertheless, the, the architecture is extremely similar.

51:31.400 --> 51:36.360
Um, and so the networks that we supply like in Kerr, or sorry, the, uh, examples that

51:36.360 --> 51:42.160
we supply in Kerr, um, are extremely similar to what we use, um, but, but we, we have tried

51:42.160 --> 51:45.360
to make networks that people are already familiar with, like they can go read a paper

51:45.360 --> 51:46.760
and figure out how it works, right?

51:46.760 --> 51:47.760
Okay.

51:47.760 --> 51:51.880
So yeah, and well, you know, we put that into the example file as well, saying like, hey,

51:51.880 --> 51:54.600
if you want to read about the architecture, this is where it came from.

51:54.600 --> 51:59.320
So that's, yeah, we, we're not trying to, um, confuse anybody about like how it works.

51:59.320 --> 52:03.520
So, so we sort of stick to the things that you can go out and look at a paper for, um,

52:03.520 --> 52:04.520
sorry.

52:04.520 --> 52:09.880
It has not written, um, a paper on what we're doing yet, um, it's kind of in the works

52:09.880 --> 52:15.480
always, um, but, you know, we, we really would love to, but, you know, that when you have,

52:15.480 --> 52:21.760
when you have like businesses to, uh, you know, to take care of and, uh, you know, customers,

52:21.760 --> 52:27.120
I guess, to take care of and, um, and only, you know, eight people, then, then you, that

52:27.120 --> 52:28.960
kind of gets thrown by the wayside.

52:28.960 --> 52:29.960
Right.

52:29.960 --> 52:30.960
Right.

52:30.960 --> 52:37.960
Any standout use cases for, uh, for this approach and deep-gram, anything that you're

52:37.960 --> 52:43.080
seeing, uh, as, you know, kind of coming to the fore in terms of what people want to do

52:43.080 --> 52:44.080
with it?

52:44.080 --> 52:45.080
Absolutely.

52:45.080 --> 52:51.200
Um, from, from the business side, um, there is, uh, fraud, fraud detection is a really big

52:51.200 --> 52:58.520
one, uh, where people will call into financial services companies and try to, um, you know,

52:58.520 --> 53:01.720
try to get money from them, essentially, try to take money out of your account or use,

53:01.720 --> 53:05.200
you know, get a credit card sent to the wrong address or something like that so that they

53:05.200 --> 53:06.680
can take advantage of it.

53:06.680 --> 53:11.880
And there are sort of patterns, um, in this and you can, the, these companies have, you

53:11.880 --> 53:15.480
know, uh, millions, hundreds of millions of calls every year.

53:15.480 --> 53:19.160
And they're trying to find, they're trying to correlate these things and say, like, hey,

53:19.160 --> 53:21.440
we know that fraud happened on these calls, et cetera.

53:21.440 --> 53:26.040
Can you, like, help us find where that's happening, you know, like every day people are calling

53:26.040 --> 53:29.520
in, trying to defraud us, can you at least give us an alert so that we can look at those

53:29.520 --> 53:34.400
harder, you know, and, and that's just, that's, that's one of the channels, um, that,

53:34.400 --> 53:38.440
that, that, that, like, provides a lot of value, uh, essentially to the, to the world, you

53:38.440 --> 53:43.120
know, because if, if there's lower fraud, you know, then, uh, everything becomes less expensive

53:43.120 --> 53:48.720
for everyone, essentially, um, but there's also like a quality assurance aspect to this

53:48.720 --> 53:53.600
and, and compliance aspect, um, again, this is still in calls where, you know, are people

53:53.600 --> 53:57.400
just saying the things they're supposed to say, you know, are they having good responses,

53:57.400 --> 54:03.600
you know, do customers have, uh, nice interactions, um, and having, uh, the way the companies

54:03.600 --> 54:08.680
deal with this now is they pay humans, um, to look at maybe anywhere from one to five

54:08.680 --> 54:15.360
percent of the calls, and in, in general, this is outsourced where, uh, you send them,

54:15.360 --> 54:18.960
you know, a random selection of your calls, and then you say, like, tell us what happened

54:18.960 --> 54:24.480
in these calls and they'll report back with a rubric of maybe like 10 or 20 different

54:24.480 --> 54:30.400
things and the quality will be pretty low. And that's like the only source of truth

54:30.400 --> 54:34.680
for these companies about their customer interactions that happen through phone calls.

54:34.680 --> 54:38.920
And so that's the type of thing that, you know, Teapgram is trying to help with. We, we

54:38.920 --> 54:43.040
take like that QA data that you've sent out to have humans label will help you figure

54:43.040 --> 54:47.320
out which of those labels are actually good. And then we'll build a model based on those

54:47.320 --> 54:52.280
labels to predict all of your audio, essentially, uh, you know, to predict the, uh, contents

54:52.280 --> 54:57.240
of all of your audio. And then you can take your QA team or your compliance team or whatever

54:57.240 --> 55:00.640
they're doing. You still have hundreds of these people like listening to all these calls.

55:00.640 --> 55:03.720
You point them in a new direction, you know, so they aren't doing the same like wrote

55:03.720 --> 55:08.120
thing over and over. They're like actually using their brain to do things that humans are

55:08.120 --> 55:12.760
really good at, which are like creative things like figure out, you know, a new way to, to

55:12.760 --> 55:17.960
find fraud rather than just sort of listening and, uh, hoping that they detect it randomly.

55:17.960 --> 55:25.360
You know, um, so we, this is, this is like, um, where Teapgram has a huge impact, I think,

55:25.360 --> 55:30.480
or has the, uh, ability to have a huge impact is just automating that entire process. Um,

55:30.480 --> 55:36.400
so for, for the consumer side, we are, um, we're not putting as much effort into making

55:36.400 --> 55:42.640
our product like, like Google for the internet, but for audio. I wish we were like, actually

55:42.640 --> 55:48.160
this is a product and somebody should build it using DeepGram. But, um, but, and we have

55:48.160 --> 55:53.120
built demos of this, uh, where, where you just scrape a lot of YouTube videos and then

55:53.120 --> 55:59.360
you're able to search it, um, using DeepGram's tech. Um, but, but I think, um, from a like

55:59.360 --> 56:05.320
company health perspective, like, in other words, DeepGram not dying in two years, um, and

56:05.320 --> 56:11.440
not having to raise like 200 million in the process of that death. Um, you know, it

56:11.440 --> 56:17.120
could go a lot of ways, but, but essentially, um, I think that product is, is, is like available

56:17.120 --> 56:21.480
and it's something to test. I think that, um, that just the greater human world right

56:21.480 --> 56:24.800
now is not necessarily ready, ready for it at this moment. But, you know, in the next

56:24.800 --> 56:29.080
couple of years, uh, that's what we're going to expect. We're going to expect that all

56:29.080 --> 56:33.000
of the content in the world is searchable. That, you know, when I think of like a movie

56:33.000 --> 56:37.080
quote or when I think of something that I listened to in a podcast or when I think

56:37.080 --> 56:41.240
of some interview that I saw on YouTube and I think like, oh, yeah, they talked about

56:41.240 --> 56:43.640
this and they talked about that. I should be able to search for it and I should be able

56:43.640 --> 56:48.600
to find it and people will start demanding that soon. Um, but yeah, we haven't spent, we

56:48.600 --> 56:53.600
did some, um, some market research on this, you know, um, to, to figure out is, is this

56:53.600 --> 56:58.480
an area that we should spend our effort right now, but it just isn't yet. Um, maybe, maybe,

56:58.480 --> 57:02.320
maybe we'll start doing that, you know, in the next couple of years, but, uh, it, it,

57:02.320 --> 57:08.840
it's not our focus yet. Awesome. Awesome. Um, well, this has been a great conversation.

57:08.840 --> 57:13.840
We, we talked about Kerr and that's open source and we'll put a link to the GitHub and the

57:13.840 --> 57:20.920
show notes, anything else folks should know to, uh, look for or how to get in touch. Yeah,

57:20.920 --> 57:26.480
you can, you can get in touch with deepgram at, uh, on Twitter at deepgram AI and it

57:26.480 --> 57:31.320
where you can send a message to me, um, at Scott at deepgram.com. I am not shy about

57:31.320 --> 57:35.680
throwing my email out there. So if you want, if you want to contact me, just, just go

57:35.680 --> 57:40.040
ahead. Awesome. Awesome. Well, thanks so much. God, it's been great having you on the

57:40.040 --> 57:49.840
show. Sam, I appreciate it. Thanks. All right, everyone. That's our show for today. During

57:49.840 --> 57:54.960
this interview, you may have heard me mention my previous interview with Josh Blue, whose

57:54.960 --> 58:01.840
company wise.io was acquired by GE to help them permeate machine learning and AI throughout

58:01.840 --> 58:07.480
that company. If you haven't already listened to that show, which was number five, you should

58:07.480 --> 58:12.880
because it was a great one. But even better, you should plan to attend the future of data

58:12.880 --> 58:17.960
summit because Josh will be speaking there on building AI products and running them in

58:17.960 --> 58:25.160
production. Really, you don't want to miss the summit. So check it out at twimlai.com.

58:25.160 --> 58:28.940
And if you work on machine learning and AI for your company and you think you've got

58:28.940 --> 58:33.880
an interesting story to share, don't hesitate to reach out. I'm finalizing the agenda

58:33.880 --> 58:39.960
for the summit soon, but I'm always looking for interesting user stories. This podcast

58:39.960 --> 58:45.280
is full of great quotes. Don't forget to share your favorites for one of our Twomo

58:45.280 --> 58:50.840
stickers. You can share them via the show notes page via Twitter and via our Facebook

58:50.840 --> 58:58.640
page. The notes for this show will be up on twimlai.com slash talk slash 19 where you'll

58:58.640 --> 59:05.120
find links to Scott and the various resources mentioned in the show. Thanks so much for listening

59:05.120 --> 59:35.080
and catch you next time.

