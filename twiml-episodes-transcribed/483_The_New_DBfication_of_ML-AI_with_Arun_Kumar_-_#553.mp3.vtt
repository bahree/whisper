WEBVTT

00:00.000 --> 00:21.000
All right, everyone. I am here with Arun Kumar. Arun is an associate professor at the University of California, San Diego. Arun, welcome to the Twoma AI podcast.

00:21.000 --> 00:24.000
Thank you for having me, Sam. It's a pleasure to be here.

00:24.000 --> 00:40.000
I'm looking forward to digging into our chat. You work at the intersection of databases, database management and machine learning and AI, certainly lots of interesting ground to cover there, but to get us started.

00:40.000 --> 00:45.000
I'd love to have you share a little bit about your background and how you came to work in the field.

00:45.000 --> 00:58.000
Yes, certainly. Like you said, my research is at the intersection of data management systems and machine learning and AI. My PhD is from the University of Wisconsin-Madison in the database group there.

00:58.000 --> 01:03.000
I moved to University of California, San Diego in 2016 after graduating there.

01:03.000 --> 01:08.000
I'm jointly affiliated with both computer science and data science here at UC San Diego.

01:08.000 --> 01:18.000
And my research started out in the database area. So I started working on information management and kind of tools and systems for that.

01:18.000 --> 01:28.000
And over my graduate school research, I started working on machine learning and database systems. And this was with Professor Christopher Raven, he was there.

01:28.000 --> 01:39.000
And afterwards I switched advisors and I worked with Professor Jeffrey Norton and Gignesh Patel, continuing to work on this area of looking at how do you scale machine learning algorithms to larger than memory data?

01:39.000 --> 01:52.000
How do we build tools to make machine learning easier to use, easier to kind of deploy and have collaborated with companies such as Microsoft and Oracle and Google and so on.

01:52.000 --> 02:01.000
And so this intersection of data management systems and machine learning was really exciting for me because it was a greenfield space.

02:01.000 --> 02:07.000
The database community has studied scaling of data intensive computations for four decades.

02:07.000 --> 02:17.000
And so now as machine learning becomes mainstream, people want to apply to large and complex data so that it just seemed like a natural fit for where my research should go.

02:17.000 --> 02:24.000
And sort of how I got into this space since my grad school day. So I've been working in this space for about a decade now.

02:24.000 --> 02:46.000
Awesome. Awesome. And you refer to this again, at least in your talk or some of your past talks is the DBification of ML and AI, which suggests that there's a migration or an evolution of machine learning and AI towards.

02:46.000 --> 02:56.000
Incorporating more database, what capability or functionality, how do you think of that.

02:56.000 --> 02:57.000
That evolution.

02:57.000 --> 03:10.000
Oh, yeah, sure, I can explain that. So the term new DBification is something that I cooked up earlier this year when I had to give a talk at ICDE for an award they gave me and I was thinking about what exactly is happening in this area.

03:10.000 --> 03:23.000
And that was the term I could come up with to describe it. The reason I call it that, and this is something I will talk about in the DBA workshop as well, is back in the 80s when relational algebra and SQL started taking off.

03:23.000 --> 03:32.000
People realize that there's a lot of things that are needed to make it practical. There's scalability, there is manageability, usability concerns and so on.

03:32.000 --> 03:42.000
And making these sorts of systems easier to build that is when the relational DBMS community started to form. And now 40 years down, it's like a very mature community.

03:42.000 --> 03:58.000
It is like 100 billion dollar plus industry for your right and so many companies in the space that are trying to make relational SQL computations practical and user friendly in the ML space that is sort of the change that we need to see.

03:58.000 --> 04:08.000
Making ML computations scalable, manageable, usable and making these sorts of tools easier to use and develop. That is what I call the DBification.

04:08.000 --> 04:19.000
So whatever transformation the research community did to relational SQL computations over the last 40 years, we need that to be done to ML computations and ML workflows and into an ML applications.

04:19.000 --> 04:27.000
So that is what I call debification of ML AI. So these concerns of usability, scalability, manageability need to be tackled.

04:27.000 --> 04:42.000
Awesome. Awesome. And in that sense, it's a bit of a meta commentary on kind of where we are in this state of time in ML and AI relative to where databases was some period of time ago.

04:42.000 --> 04:44.000
Absolutely.

04:44.000 --> 05:11.000
There's also an aspect of your research that deals with the relationship between the fields and how databases support machine learning workloads and I'm guessing help provide some of these these characteristics that you describe scalability, etc.

05:11.000 --> 05:14.000
So how do you see the relationship between the two?

05:14.000 --> 05:27.000
Oh, yes, certainly. So this is also something I will cover in my talk is the evolution of the landscape of ML platforms and one of the periods in that evolution is what I call in our DBMS ML toolkits.

05:27.000 --> 05:41.000
This is a field that has been studied for 20 years now back in the early 2000s or call Microsoft IBM and all these relational DBMS vendors decided to add support for machine learning and data mining algorithms on top of their relational DBMS platforms.

05:41.000 --> 05:52.000
And the target users were like enterprise analysts who would like to keep the data in their relational databases, rather than having to export them to flat files and then run them on separate things.

05:52.000 --> 05:59.000
And then that kind of leads to manage ability nightmare and so they said you could run these machine learning competitions in the DBMS process space.

05:59.000 --> 06:02.000
You could invoke them from the SQL console or something like that.

06:02.000 --> 06:04.000
And so that work still continues.

06:04.000 --> 06:12.000
There's a community that studies that sort of stuff and asked a lot of my work is also focused on that in the past in the last half a decade or so.

06:12.000 --> 06:22.000
The community has really expanded beyond that there's work on ML on data flow systems which also comes from the database and systems communities stuff like spark spark ML lib.

06:22.000 --> 06:29.000
There's work on custom ML systems now that's a new research community that has formed with this intersection.

06:29.000 --> 06:39.000
You have these tools like actually boost and then of course these deep learning systems like TensorFlow and PyTorch which very similar to kind of database systems in the way.

06:39.000 --> 06:45.000
You specify computations at a higher level they have compilers and optimization stacks that translated to hardware specific kernels.

06:45.000 --> 06:52.000
So there is this analogy of what the data systems are in the ML landscape versus what they were in the relational landscape.

06:52.000 --> 07:01.000
But now people are realizing to make ML more practical you have to really look beyond just the system stack for training and inference.

07:01.000 --> 07:09.000
You need to look at governance, you need to look at provenance, you need to look at data transformations and preparation data labeling and model deployment.

07:09.000 --> 07:16.000
So these end-to-end ML platforms such as MLflow and TensorFlow Extended and SageMaker they have also started to come about.

07:16.000 --> 07:22.000
And I think all of these sorts of tools stand to learn a lot from the relational database world.

07:22.000 --> 07:26.000
And that's one of the reasons why I'm excited about this workshop.

07:26.000 --> 07:35.000
So at the SIGMOT conference just one of the top database area conferences we've had the data management for end-to-end ML team workshop which looks at this sort of intersection.

07:35.000 --> 07:43.000
But now we want to bring that to the ML venues as well and hopefully the ML community can also get excited about what does ML look like in practice?

07:43.000 --> 07:49.000
What does ML look like at scale and what are the sort of data management issues in the end-to-end ML context?

07:49.000 --> 08:02.000
So walk us through your talk. How do you open your talk and contextualize the relationship between the fields?

08:02.000 --> 08:11.000
Sure, absolutely. So first of all, I motivate that ML and AI are no longer just arcane academic endeavors.

08:11.000 --> 08:20.000
And years ago, Newerves was probably the Hangouts platform mathematicians and statisticians mostly. Now if you look at it, it's like 10 times larger, 15 times larger.

08:20.000 --> 08:30.000
And it's so hard for me to look at the entire program and it's a hangout of big tech companies, a huge number of papers from tech companies, other enterprise companies, smaller web companies.

08:30.000 --> 08:33.000
So it's become a ubiquitous business vertical need.

08:33.000 --> 08:39.000
And so there are pressing problems of usability and scalability that need to be tackled to help democratize machine learning.

08:39.000 --> 08:42.000
So that is sort of the motivation for this larger area of work.

08:42.000 --> 08:49.000
We want to democratize machine learning by tackling these pressing issues of human productivity and human efficiency.

08:49.000 --> 08:54.000
So people involved in the loop, like data scientists, ML engineers, ML ops people, and also system resource efficiency.

08:54.000 --> 08:58.000
Making things cheaper, faster, and easier to use, that sort of stuff.

08:58.000 --> 09:06.000
And so this is where I believe that the database and systems communities can bring a lot to the table and tackle these issues of

09:06.000 --> 09:11.000
system efficiency and human efficiency. So that is sort of how I motivate the stock.

09:11.000 --> 09:17.000
And then I draw analogy to the database communities work in how they help democratize relational and SQL computations.

09:17.000 --> 09:29.000
Like nowadays when you want to perform, say, data record retrieval or update transaction or aggregate statistic for, I don't know, sales forecasting or something like that.

09:29.000 --> 09:38.000
You don't sit and write C++ code, you write one line SQL code, you write, you probably use dashboards and business intelligence tools.

09:38.000 --> 09:50.000
Whereas if you're going to do a mail, you're going to be sitting writing what Jupiter notebooks, you're going to be writing low level Python code using libraries and stitching functions together here and there using airflow scripts and stuff like that.

09:50.000 --> 09:56.000
So that's sort of state of the art is often a mess in production.

09:56.000 --> 10:05.000
So some of the lessons that we had from the database world on, how do we commoditize data software systems that needs to be translated to the machine learning world.

10:05.000 --> 10:10.000
And so I go over across the entire lifecycle of machine learning applications.

10:10.000 --> 10:16.000
I divide that lifecycle into three stages, sourcing of data, building of models and deployment of prediction pipelines.

10:16.000 --> 10:30.000
The sourcing stage is where you convert raw data in your data warehouses, data lakes, database systems into what I call ML ready data. That is where you go through the process of acquisition, transformation preparation, labeling and cleaning and stuff.

10:30.000 --> 10:37.000
Then you have the building stage where you do the feature engineering model selection, hyper parameter tuning, all of these things.

10:37.000 --> 10:46.000
And then you have the deployment stage, which is where you integrated back into your application, which could be on the web, which could be on IoT devices or in your data warehouses.

10:46.000 --> 10:50.000
And then you have to monitor and maintain these models as the application evolves.

10:50.000 --> 11:02.000
So I decompose the study of the space into these three large kind of high level stages because the concerns for these software systems and the concerns for the users across these stages are very different.

11:02.000 --> 11:14.000
The sourcing stage, a lot of the work is still very manual. There is very little scope for kind of automation that can be end to end because there's just so many bespoke issues that happen with data preparation and cleaning and labeling and so on.

11:14.000 --> 11:18.000
So there are some tools that are coming about to improve productivity of people in this space.

11:18.000 --> 11:29.000
And that is an area I think that the database communities expertise with data integration data cleaning data provenance workflow management and query languages and APIs, all of that can help.

11:29.000 --> 11:41.000
And then comes the build stage where you need really high throughput execution of ML computations, resource efficiency, you want to make sure you use your clusters and your GPUs optimally as close to as possible.

11:41.000 --> 11:44.000
And that is where the systems issues come into play.

11:44.000 --> 11:59.000
Translating stuff into faster executions using query optimization technique using compiler techniques using scalable data systems techniques like parallel database systems and data flow systems cloud native executions, these sorts of things really matter.

11:59.000 --> 12:03.000
And so that also is an area where the data systems community has a lot to help.

12:03.000 --> 12:14.000
Finally, in the deployment stage, I think there is a lot of issues in ML ops. How do we productionize these sorts of pipelines and to end pipelines, again, provenance management, debug ability, explainability.

12:14.000 --> 12:24.000
There is a lot of software engineering issues there. So like the software engineering for a mail space data engineering for a mail space. I think there's a lot of open questions in those arenas as well.

12:24.000 --> 12:34.000
So that is sort of the overview I give. Then I dive into two specific research projects from my research that are exemplars of both the sourcing stage and the building stage.

12:34.000 --> 12:38.000
That's primarily where my research is focused on.

12:38.000 --> 12:55.000
You know, thinking about the analogy that you're making between the database in general database systems and ML and AI and the ML and AI workflow.

12:55.000 --> 13:13.000
It strikes me that in a lot of ways, even though databases can be large and complex, they are more or less single purpose in the sense that they're there to store data and return data in response to some set of queries.

13:13.000 --> 13:28.000
As the machine learning workflow, as you've identified in these, you know, these three different stages, you know, as, you know, those stages are have very different sets of requirements.

13:28.000 --> 13:39.000
And, you know, the overall workflow is hard to reduce to a single, you know, single thing that it's doing in the same way.

13:39.000 --> 13:47.000
I'm curious how you how you think about, you know, that impedance mismatch, maybe in the analogy.

13:47.000 --> 13:56.000
One thing to note is in the relational database world, people focus on the RDBMS primarily as the engine that kind of answers SQL queries.

13:56.000 --> 14:05.000
But there's a whole stage called ETL that goes before the data even gets loaded in many cases. And so the sourcing stages analogous to ETL in the database world.

14:05.000 --> 14:16.000
You don't tend to highlight on ETL stacks, but now ETL, reverse ETL, ELT, all these are hot areas of research and kind of startups that are coming about in the database industry itself.

14:16.000 --> 14:22.000
I mean, why did Hadoop take off? Why did MapReduce take off? It's because database people underappreciated the importance of ETL.

14:22.000 --> 14:25.000
And that's sort of why what we've learned over the last decade.

14:25.000 --> 14:33.000
And so now you have Spark and data lakes and data lake houses, they kind of bridge this gap between the querying stack and the ETL stack.

14:33.000 --> 14:38.000
And so now you could operate on raw file system. So there's a lot of innovation happening in that space as well.

14:38.000 --> 14:52.000
And now coming to ML ops, I think there has been in the past companies that wanted to do data ops as well, which is delivering data to kind of websites and IoT devices that are near real time.

14:52.000 --> 15:03.000
And that whole data ops space is kind of what led to innovation in the key value stores landscape like Amazon.com, Facebook.com, these are websites that have profile data that need to be updated in real time.

15:03.000 --> 15:15.000
And so that's sort of why key value stores came about. And now people are realizing with things like feature stores, you need some of that again, you need to have data ops delivery of data in near real time.

15:15.000 --> 15:26.000
And now ML ops is obviously more complicated than that. The ETL that is needed for ML is obviously more complicated than what people did for database ETL.

15:26.000 --> 15:32.000
However, some of the principles and tools, I think there is a lot to learn from in that landscape.

15:32.000 --> 15:46.000
Coming to the analogy with the querying system, so you have RDBMS stack where you have SQL console and you train it and you can get your query answered. The analogy for that would be like model building systems, like a tens of floor, PyTorch or XG boost.

15:46.000 --> 15:58.000
You don't need to read right ML algorithm implementations for these. You just give the data, you specify the invocation and their APIs, they build a model for you. And they do this at scale, they do this in parallel, if needed.

15:58.000 --> 16:09.000
They may not do it that well. Some of the deep learning tools still fail to scale on models or data for many reasons. But that is sort of the analogy for the RDBMS stack for the SQL console itself.

16:09.000 --> 16:18.000
And then in the database world, you also have this whole stack of data integration and business intelligence tools and visualization tools.

16:18.000 --> 16:30.000
You need all of that for ML too, because you need to do monitoring, you need to do maintenance of the workflows, you need to do access control and governance. And so that sort of stuff would also, you'd have to see the analog come about in the ML landscape.

16:30.000 --> 16:50.000
Part of the analogy is encouraging us to zoom out from the database and look at this broad ecosystem of tools that evolve to support kind of end-to-end working with data. And, you know, we can see a lot of the same things happening on the machine learning side.

16:50.000 --> 17:08.000
Exactly. So in the database community, it's not just the RDBMS like optimizing SQL queries. There's all these other topics that people have been studying for decades now. In the ML world, there's been intense study on scaling ML algorithms in particular and new model architectures and new ML algorithms, new optimization procedures.

17:08.000 --> 17:21.000
I think they need to zoom out and then look at the end to an ML workflow and look at the end to an ML application lifecycle and start studying these sorts of auxiliary issues that are also critical and that are now the main bottlenecks for many adopters of machine learning.

17:21.000 --> 17:40.000
And in some ways, thinking about the end-to-end machine learning workflow and ML ops, they seem like software engineering challenges as opposed to research challenges.

17:40.000 --> 17:54.000
And there's a broad research community that is thinking about these issues too. Where, you know, what's the role of research and thinking about these, you know, more production types of issues, tools, issues, et cetera.

17:54.000 --> 18:02.000
Yeah, that's a great question. My frank answer would be I do not know much about that space as much as people who are actually working in industry.

18:02.000 --> 18:19.000
And this is something that I've had conversations with several folks, Sharia Shankar and Chip Huyen, Sarah Katyn Zaro, and several others, Goku Mohandas, I invite them over to my classes to give kind of guest lectures, meet with them at conferences to understand this space.

18:19.000 --> 18:28.000
I am not running and operating a giant ML production platform. So I don't get to see the kind of ML ops issues that happen in the deploy stage of the lifecycle.

18:28.000 --> 18:36.000
And this is something that academics in general face because they don't run these billion user services that companies face.

18:36.000 --> 18:46.000
Now coming to the issue of software engineering for a mail, I think there is both a research community and a practice oriented issue there, because there is a research community around software engineering in academia too.

18:46.000 --> 19:01.000
And they publish at venues such as XC and FSE and so on. They try to understand the principles of software engineering. I think looking at that from the ML kind of software engineering for a milestone point, there is some research issues to be studied there from the software engineering research world.

19:01.000 --> 19:18.000
Now in the practice world, practitioners who kind of build these sorts of tools and pipelines and then kind of deployment infrastructure, what will help is for them to kind of think about what are the more generalizable questions beyond their particular company beyond their particular use case or pipeline.

19:18.000 --> 19:29.000
Are there challenges that can potentially be surfaced to the research community that can lead to kind of virtuous cycle that lead to better tools in the future.

19:29.000 --> 19:34.000
I think that would be an interesting avenue for collaboration between researchers and practitioners.

19:34.000 --> 19:44.000
And I think these workshops of these sort and also the industrial conferences like the Spark AI summit that I went to strata that already ran before pandemic.

19:44.000 --> 19:48.000
Those are sort of great venues for these sorts of conversations to take place.

19:48.000 --> 20:05.000
A lot of practitioners usually don't show up to research conferences because it's not that relevant for their work. But now I think a lot of practitioners are showing up to new reps and ICML and they want to kind of interact with the research community to tighten that kind of to kind of make that loop faster.

20:05.000 --> 20:17.000
Hopefully we will see more research come about in the ML ops landscape from the academic and industrial research world as well. And rather than just building tools and open source developments, which is also important.

20:17.000 --> 20:29.000
But for longevity, we need to understand the more fundamental principles and the technical challenges at a more general level than just a pipeline or stack that they build for their particular organization.

20:29.000 --> 20:41.000
You mentioned that section of your talk is reviewing a couple of projects that you and your research group are working on. Can you introduce us to this?

20:41.000 --> 20:42.000
Absolutely.

20:42.000 --> 20:54.000
So bulk of my research in the last half a decade has focused on the source and the build parts of the lifecycle, the data preparation issues in particular and the model building issues for deep learning.

20:54.000 --> 21:13.000
I can talk about the latter first. So that is project cerebro. So these are the two exemplars that I give in my talk at the DBA workshop. Now the cerebro project was launched based on a single observation that many people who are building these ML systems are focusing on building one model at a time.

21:13.000 --> 21:25.000
And so they are thinking of stuff in a very low level manner. What I have learned from my conversations with ML practitioners at over three dozen enterprise web health care domain science and many other settings is the model building process.

21:25.000 --> 21:34.000
There's a higher level structure there. And this is what I call as the model selection triple. They need to tune and tweak around the data and feature representation.

21:34.000 --> 21:43.000
They need to tweak around with the architecture. They need to tweak around with the hyper parameters. These three changes put together lead to a massive number of models being built.

21:43.000 --> 21:49.000
And it's not like it's an ad hoc process. There is auto-ML heuristics for hyper parameter tuning that are widely used now.

21:49.000 --> 21:59.000
And so they specify a bulk set of models to train. One of the things I've been exploring over the last five years is understand that process more rigorously from the standpoint of ML users.

21:59.000 --> 22:08.000
How do they think about how do you go about building models. They don't think about just here's a computational graph train it and then they come back and then he has another competition graph from totally from scratch.

22:08.000 --> 22:15.000
They think about it in terms of changes they'd like to do to the data representation changes they'd like to explore as part of the architecture.

22:15.000 --> 22:22.000
Like if you want to build a CNN on say time series data, which is something we did for public health use cases here on campus.

22:22.000 --> 22:30.000
There are certain classes of CNNs you want to explore on dimensional CNNs with certain number of layers you have some intuition. So now you can train these models in bulk.

22:30.000 --> 22:38.000
The second issue I noticed was scalability was really not addressed that well in the open source world for PyTorch intensive flow.

22:38.000 --> 22:42.000
More recently, I think PyTorch distributed data parallel has been doing better job.

22:42.000 --> 22:52.000
How to what is doing a better job but for a long time it was not their primary concern. If you're operating on small data that fits on your memory, that's okay.

22:52.000 --> 22:56.000
And now with transformer style models, even models don't fit on GPU memory.

22:56.000 --> 23:03.000
And so we started looking at in the cerebral project scalability from the first principles. How do you scale to very large data sets?

23:03.000 --> 23:09.000
How do you scale to very large models? How do you scale to large numbers of models being trained simultaneously in the model selection process?

23:09.000 --> 23:17.000
And so all of this put together is what I call high throughput deep learning systems where we would like to perform model building at a higher level.

23:17.000 --> 23:22.000
But then the system now takes care of translating it to lower level computations for you.

23:22.000 --> 23:28.000
And this is a paradigm that's called logical physical separation. It's inspired by the database systems.

23:28.000 --> 23:37.000
Like when you write an SQL query or when you write a transaction, you don't think about how exactly is it accessing the data, how exactly is it scaling to petabyte size data sets and so on.

23:37.000 --> 23:40.000
Or when you're writing a spark the SQL query or something like that.

23:40.000 --> 23:48.000
We want to bring the philosophy to the model selection world. You specify your model search process. You specify your model architecture in higher level tools.

23:48.000 --> 23:52.000
Careers auto amount you risk they all allow you to do it in a very succinct manner.

23:52.000 --> 24:04.000
And so now cerebral will be a middle-verse system that intercepts that and now translates the computations to TensorFlow and PyTorch executions for you by rewriting when exactly these computations are scheduled.

24:04.000 --> 24:10.000
Where exactly they are scheduled. So now you could scale to very large data sets that may not fit on a single machine.

24:10.000 --> 24:16.000
You could scale to very large models that may not fit on a single GPU without needing to have that sort of systems expertise.

24:16.000 --> 24:24.000
You don't have you don't need to force ML users to understand how do you partition your workload, how do you scale your things, how do you stage out computations and so on.

24:24.000 --> 24:36.000
And that is sort of the vision which we. We published at the cider conference earlier this year the large scale platform for deep learning that's a title cerebral or large scale platform for deep learning.

24:36.000 --> 24:45.000
It gives us it kind of gives us this perspective of decoupling the water of the model building process from the how of the execution.

24:45.000 --> 24:56.000
And that is again inspired by the database systems philosophy of decoupling the water of the logic of the query execution from the how of you optimize and run the actual executions themselves.

24:56.000 --> 25:07.000
And so as part of the cerebral project once we had this decoupling we can now infuse several systems techniques what we call multi query optimization techniques that's jargon from the database world.

25:07.000 --> 25:15.000
Basically what it means is you look across multiple model executions see what you can share you can share data access can you share computations.

25:15.000 --> 25:21.000
And then that allows us to improve resource efficiency allows us to reduce run times through scalability and so on.

25:21.000 --> 25:34.000
So that is what we've been pursuing the cerebral project over the last few years and we've kind of gotten along kind of long way through that solving the data scalability challenge solving the model scalability challenge.

25:34.000 --> 25:40.000
Now we're looking at kind of transfer learning as well we're going to look at transfer learning is front and center and deep learning.

25:40.000 --> 25:49.000
It turns out that there is a model selection issue and transfer that you have to figure out which layers are you going to transfer from your pre trained models and that requires comparing different data representations.

25:49.000 --> 25:59.000
And that leads to redundant computations that lead to scalability issues and again those are data systems issues and that's sort of what we're tackling also in the cerebral project.

25:59.000 --> 26:13.000
And so cerebral is is it have elements of both the data the build and the deploy model it is a living all three of those or is it primarily build and deploy or just deploy.

26:13.000 --> 26:18.000
I would say it's primarily build and deploy because in the deep learning landscape.

26:18.000 --> 26:23.000
I think the data preparation style issues are not as sophisticated as on tabular data.

26:23.000 --> 26:30.000
And this is an interesting dichotomy in a machine learning world. Most people don't use deep learning as much on tabular data.

26:30.000 --> 26:40.000
And a lot of business critical use cases are on tabular data and they use boosted tree ensembles. I mean grading boosted trees are still the most popular methods for machine learning.

26:40.000 --> 26:51.000
I saw the recent Kaggle survey I keep track of the Kaggle survey and random forest and boosted decision trees are still the most popular on tabular data.

26:51.000 --> 26:57.000
And so cerebro is really focused on any neural computation graph. So things that can be expressed with tens of low and pie touch and the like.

26:57.000 --> 27:05.000
And so that is primarily around unstructured and semi structures style data like time series like images video audio and so on.

27:05.000 --> 27:16.000
You could apply to tabular data sets to but I don't see that many use cases for tabular data sets in that region. So cerebro that's why primarily focus on the build stage and somewhat on the deploy stage as well.

27:16.000 --> 27:22.000
Over the next year we're going to focus a lot more on deploy stage by looking at cloud native execution for cerebro.

27:22.000 --> 27:28.000
So there you will see a lot more integration with kind of cloud native infrastructure, so less infrastructure and so on.

27:28.000 --> 27:52.000
When I hear you describe the cerebro what comes to mind is you know something analogous to like a DSL for describing the way you want to deploy your machine learning models is that you're trying to raise the level of abstraction from thinking about OK, I have a model.

27:52.000 --> 27:58.000
I want to put it here and here and here to I have a model.

27:58.000 --> 28:03.000
I have a model and I wanted to serve this use case is that correct.

28:03.000 --> 28:15.000
That is correct. I mean that is I wouldn't call it a DSL. We're not creating a new language. I would call it higher level APIs. So in the paper itself, we go over the kinds of higher level APIs we are aiming to support.

28:15.000 --> 28:23.000
There is some that are already popular that we don't need to reinvent the wheel there, like automobiles, heuristics are already popular for hyper parameter tuning.

28:23.000 --> 28:32.000
There's algorithms like hyper Rob, hyper band, asha and so on. There's architecture tuning algorithms, just like Google's NAS and auto care and so on.

28:32.000 --> 28:42.000
All of these are basically DSL's if you wish. They are like poor man's DSL because they are APIs that under the hood produce different training configurations automatically for you.

28:42.000 --> 28:53.000
Rebro would basically support these sorts of APIs on top. Now for some of these evolving kind of emerging use cases like transfer learning carous and all these other tools like hugging face, they are coming up with APIs as well.

28:53.000 --> 29:10.000
And so those can be automatically kind of reused in this rebro context going kind of looking further ahead, we could actually construct a unifying DSL across these sorts of kind of environments to reduce the complexity of having to learn these multiple APIs.

29:10.000 --> 29:13.000
And that is certainly a possibility to look at in the future.

29:13.000 --> 29:29.000
And so is the core of cerebro is it kind of an expression of a workflow or process, you know, that starts from training a model, maybe invoking some kind of auto ML or architecture search and then you need to deploy.

29:29.000 --> 29:43.000
So going out to figure out taking or creating that artifact and then pushing it out to some cloud service at that level, that is correct. So you specify your model building workload at this higher level using these APIs.

29:43.000 --> 29:55.000
You could specify here is my compute cluster and then the system would automatically figure out how to place those computations on the cluster for you could be provision cluster we have integrated this with multiple backend systems.

29:55.000 --> 30:01.000
You could run it on spark, for example, we have integrated an open source that cerebro spark releases available.

30:01.000 --> 30:10.000
So if your data files are sitting on an HDFS and you're using spark, you could do some ETL there and then you could run cerebro for training these models in that regime.

30:10.000 --> 30:21.000
We've also integrated this with the green plum, which is a parallel or the BMS that pivotal now VMware offers and they have kind of ship some of these ideas for their enterprise customers as well.

30:21.000 --> 30:27.000
So if your data sets are reciting on the green plum warehouse, then you could actually run these computations there.

30:27.000 --> 30:39.000
You could also run this on native file systems. We are releasing a integration with desk and desk is quite popular among data scientists these days for small clusters less than kind of 10 nodes or something like that.

30:39.000 --> 30:47.000
So cerebro can now paralyze your model building competitions using desk and offer all these optimization techniques that I'm talking about out of out of the box.

30:47.000 --> 30:53.000
And then in the future in the next one or two years, our vision is to integrate this with cloud native infrastructure as well.

30:53.000 --> 30:58.000
So now you could say here's my budget and here's sort of my cloud infrastructure.

30:58.000 --> 31:08.000
You could specify time budgets or cost budgets. Then cerebro would also auto provision resources for your model building process. So that is part of our vision in the future.

31:08.000 --> 31:19.000
So basically ML users should not have to worry about systems and infrastructure issues that is sort of the primary philosophy that is driving the cerebro project.

31:19.000 --> 31:34.000
What's the relationship between the users data and all the rest of these things that they want to do in cerebro and so where does cerebro start from the with relation to the data.

31:34.000 --> 31:44.000
The data could be like like I said, it could be a set of files on a file system, which you want to use to build a model like a concrete use case I could give is with the public health use cases.

31:44.000 --> 31:52.000
Let's say they have they have accelerometer data time series data that about a terabyte large they've already labeled this data.

31:52.000 --> 32:03.000
So this is an edge funded work and they were looking at building the learning models to improve the accuracy of predicting user activities are they sitting on the standing or they're walking that sort of stuff.

32:03.000 --> 32:16.000
And in the past they've built some kind of hand engineered physics based feature eyes random forest models and they had about 75% accuracy for a binarized version of the staff.

32:16.000 --> 32:26.000
We built these deep learning models using cerebro that uses one dimensional CNNs and LSDM's on their data that hit accuracy of about 92% and we published this in public health journals.

32:26.000 --> 32:33.000
The way to approach this is they have these data files that are partitioned and they are stored on a multi note cluster on campus.

32:33.000 --> 32:42.000
And so now when we want to train these models on these data sets, you would invoke the Python API of cerebro as from a client like from your laptop or something.

32:42.000 --> 32:53.000
You would connect it to the machines that are available there you indicate these are the data files that you want to operate on. And then cerebro would now take your TensorFlow code and automatically place it on these sorts of clusters.

32:53.000 --> 33:00.000
Make sure that you don't have to copy the data manually or anything like that. It doesn't need to replicate the data across workers for parallelization.

33:00.000 --> 33:16.000
And it would execute this process, it would surface the results of you, you're using TensorFlow for visualizing the results as well now. And so you could now monitor how are these models doing over time and you could potentially stop some models, add some models in a human and loop fashion on the fly as well.

33:16.000 --> 33:31.000
And so at the end of the session, you would have the models that you're interested in available with their accuracy. And then now you could do post processing with that you could basically say this is the model I want to choose in our public health use case they decided to do an ensemble at the end.

33:31.000 --> 33:35.000
They chose the top three performing models because they're accuracy metrics.

33:35.000 --> 33:47.000
There are several accuracy metrics and they can have had ferrito optimal issues. And so that's sort of what we ended up. So the part that cerebro has abstracted away is having to worry about fitting these large data sets into your TensorFlow.

33:47.000 --> 33:54.000
Rather, you just specify your model architecture and your model building process and then you get the output models at the end with their accuracy.

33:54.000 --> 34:03.000
The next example that you discuss in your talk is a project called sorting hat. Can you tell us about that one?

34:03.000 --> 34:17.000
Oh, sure. Now sorting hat focuses primarily on the sourcing part of the life cycle. And here the primary concern we were looking at. I mean, again, there's a lot of issues in the sourcing part. We're not tackling all of these issues.

34:17.000 --> 34:33.000
The one thing that kind of motivated me to look at this more is in the last few years, several companies are starting to claim they have automated the n2nm workflow. And this, I mean, of course, model architecture search hyper parameter tuning feature engineering.

34:33.000 --> 34:46.000
The several meta heuristics that have come about that are really good. They can automate it. The data preparation part. No, not so good. And so what I thought was happening was they were claiming something that wasn't actually really good.

34:46.000 --> 34:55.000
You can claim you have automated it, but if it is no good, what is the point of automation? And so what I decided to do is let's create benchmarks.

34:55.000 --> 35:02.000
And this is a standard way for comparing tools for testing their efficiency and testing their effectiveness and so on.

35:02.000 --> 35:17.000
And so here we realized what is missing in this landscape for wetting these sorts of claims is a suite of standardized task definitions and label data sets to figure out how well does auto data prep work today.

35:17.000 --> 35:34.000
And that is sort of what project sorting has. It's very complimentary, very different from the cerebral landscape, which is really focused on system internals and scalability and stuff like that. Here, the focus is on understanding what are these data transformations that take place on tabular data before you can train an ML model.

35:34.000 --> 35:50.000
How much of that is automatable and how much of that is robustly automatable. And what are the implications if those automated steps fail if they don't prepare the data correctly. How does it affect the model that you're building what is the implications for the bias variance straight up from a learning theoretical standpoint.

35:50.000 --> 36:13.000
So these are sort of the questions we've been looking into the space we published a vision paper on this. We've been creating benchmark tasks and data sets we've in this in this space and we've been collaborating with some companies Google and Amazon and now open ML as well as part of this project before we get to the specifics of the benchmarks and the data sets.

36:13.000 --> 36:41.000
I'd love some examples of where these automated data prep systems tend to fail. You know, there are a number of them out there, both kind of academic open source as well as commercial and you know, they will typically do things like, you know, automatic try to automatically bend your data or create, you know, relationships between your features to

36:41.000 --> 36:58.000
the, you know, often auto and model builders kind of more features to work with, but it sounds like you've identified some patterns where you know those features don't, you know, don't work or don't create the results that that are claimed.

36:58.000 --> 37:02.000
So elaborate on, you know, where you see them failing.

37:02.000 --> 37:15.000
There's this boundary between what we call data preparation and feature engineering. And so in the data mining and ML world, they've studied feature engineering where you come up with these transformed features or you do the bending of these things.

37:15.000 --> 37:27.000
So what we're looking at is actually even before that, which is you, you take your database that you get from your RDBMS or a data lake system and then you just up, uploaded to your auto ML to us as CSV file.

37:27.000 --> 37:37.000
Now, what do you do with the first off, identifying what are the features present in the data, and that is the problem of feature type inference. That's the gateway step to data preparation.

37:37.000 --> 37:44.000
You need to identify, for example, your zip code of a customer, which is stored as an integer in your database or data file on a data lake.

37:44.000 --> 37:47.000
It's stored as an integer, but it's not a numeric feature for a map.

37:47.000 --> 37:59.000
You have to have either the user manually annotated, but many of these auto ML tools automatically infer the feature type by looking at the data and they infer it wrongly. They will conclude that zip code is actually an numeric feature.

37:59.000 --> 38:04.000
Imagine giving zip code is a numeric feature to logistic regression. It could give you garbage results.

38:04.000 --> 38:13.000
And so the first task we formalized was this feature type inference task given your data file and your attribute name and your values are present in the data file.

38:13.000 --> 38:20.000
Let's say they upload it as a CSV to these tools like Einstein or Sage micro autopilot or Google Cloud auto ML tables.

38:20.000 --> 38:28.000
They all allow you to upload a CSV file or a TSV file or JSON file or whatever, but they all have these syntactic data types present.

38:28.000 --> 38:33.000
And so now they have to infer what are the feature types that are present in the table. So that's the first task.

38:33.000 --> 38:45.000
What we found was many of these tools fail when they can they are not able to distinguish between categoricals and numericals. And the zip code is a good example turns out to be very common issue.

38:45.000 --> 38:52.000
There's product codes, there's health codes, so many categorical data are stored as integers because people like to encode them.

38:52.000 --> 39:00.000
And so these tools think of them as numeric features and it turns out that there's a semantic gap there. How do you figure out something is a categorical.

39:00.000 --> 39:16.000
And so part of our benchmarks what we did was we created these label data sets that can that metadata sets that annotated almost 10,000 columns from hundreds of data files that we collected from public sources and we annotated them and we released them as label benchmark data sets.

39:16.000 --> 39:20.000
We then compared these tools against ML models.

39:20.000 --> 39:30.000
So now that you've we have formulated this task as multiclass classification given a column in a data file. Tell me what is the feature type is it categorical is it numeric is a timestamp.

39:30.000 --> 39:46.000
We created a unified vocabulary for type inference by studying all these existing tools in this space. And then we build simple ML models turns out that a random forest model based on some statistics features and the name of the attribute can beat substantially all these prior tools that were out there.

39:46.000 --> 40:05.000
So blue on and transmogrify and TFTV and pandas and so on. And so that was the paper that published it sigmo this year. And that is the first task in the what we call the ML data prep so that's the benchmark the zoo of pre trained models that we released the data sets that we released and the task definitions subsequent tasks.

40:05.000 --> 40:11.000
We are looking at some more and we have published a vision paper laying out some common data prep steps that take place.

40:11.000 --> 40:18.000
The task that we've studied now is what is called category de duplication when you have a categorical like say state of a customer.

40:18.000 --> 40:22.000
Sometimes they enter California as California, sometimes they enter it as CA.

40:22.000 --> 40:31.000
And now a data scientist is sitting and deduplicating these categories so that you don't end up with overfitting of the model if you have too many representations of the same entity.

40:31.000 --> 40:41.000
And so you sit and manually edit your data frame or your data file on Excel trying to reconcile the value representation that is a data prep step.

40:41.000 --> 40:51.000
And so now we are benchmarking that data prep step trying to understand how does it affect amalacuracy if you do not the duplicate and creating benchmark label data sets for these duplicate representations.

40:51.000 --> 41:05.000
And again, training mm models to automate steps. So these are the kind of seem like very low level grunt work, but it is these sorts of accumulation of low level grunt work that impede the productivity of data scientists when they are working with tabular data.

41:05.000 --> 41:13.000
And if auto ML platforms aim to automate these things, you really need to understand where are they failing in these automation of these grunt work steps.

41:13.000 --> 41:24.000
And if they are failing, are they leaving a lot of accuracy on the table when they are building the automated ML method at the end. So that is sort of the kind of I hope that gives you a good picture of what what we are targeting in this space.

41:24.000 --> 41:33.000
No, it definitely does. It definitely does. It also raises for me, obviously similar questions happening at the feature engineering level.

41:33.000 --> 41:45.000
And curious if there are benchmarks and data sets like what you're doing here, applying to those types of systems seems like there are some opportunities there as well.

41:45.000 --> 41:57.000
Absolutely. The data mining and ML world have been studying some of those automation of feature engineering automation of algorithm search and hyper parameter training and there are benchmarks like open ML itself has the benchmark suite for those kinds of things.

41:57.000 --> 42:09.000
So what we found to be this big gap was really in the data prep stage. And I think the reason for that again going back to our original theme database and ML communities have been so far apart that this thing fell through the cracks.

42:09.000 --> 42:15.000
The ML community understood feature engineering they understood algorithm search and hyper parameter tuning so they were able to create benchmarks for that.

42:15.000 --> 42:29.000
The ML community did not appreciate the data prep stage because they thought, oh, that's just a grant work, but it turns out that the database community understands that grant work for like two, three decades because we've studied data cleaning and data integration and data ETL and transformation and so on.

42:29.000 --> 42:35.000
So this is another area where I think the database community and the ML community need to come together and work together.

42:35.000 --> 42:53.000
I ran a panel discussion at Sigma this year focused on this topic. There is a blog post out on it on the Sigma blog. So I would encourage your listeners to check that out too, where I hope over time, the research community in both ML and DB work together to understand this data prep space better.

42:53.000 --> 43:05.000
There's also this data centric AI workshop that Andrew and others have launched that's right after this DBA workshop that also looks very exciting. So I'm glad that there is more attention to data centric issues in the ML world as well.

43:05.000 --> 43:19.000
We really need to understand the way the data is modified the ways data is edited. How does that affect ML and how do we make that process more systematic how to make how do you create tools that make people more productive when doing that sort of stuff.

43:19.000 --> 43:37.000
I think that's a big opportunity at this intersection. What do you think needs to happen in order to kind of gather more momentum at this intersection? Does it kind of teaching database people more about machine learning teaching machine learning people more about databases or you know all of the above.

43:37.000 --> 43:51.000
All of the above that is correct and that kind of has a good segue for the last section of my talk where I say how do we go where do we go from here. And so I give avenues that amount people can learn about some of these techniques on the database world and vice versa.

43:51.000 --> 43:59.000
Conferences and publication avenues. There's this scalable data science track that will be in sig mod now where you can publish this kind of stuff.

43:59.000 --> 44:09.000
You're also has the data sets and benchmarks track where you can publish kind of stuff that's the ML system conference. So this is kind of new community to nurture this sort of research that has formed.

44:09.000 --> 44:18.000
And coming to these sorts of workshops will allow you to exchange ideas with people from multiple areas and create the sort of synthesis of these areas that is needed.

44:18.000 --> 44:29.000
Apart from that, I mean in terms of community efforts, these workshops will hopefully spur conversations on creating more standardized tasksets and benchmarks and data sets.

44:29.000 --> 44:35.000
And I hope the industry companies that are building these sorts of tools also participate in these conversations.

44:35.000 --> 44:46.000
It has had transformative impact in both the database and ML was like imagine it, for example, was a defining kind of pivot point in the ML history of the ML research industry.

44:46.000 --> 44:53.000
In the database world, we've had the TPC benchmarks, which were a pivot point for how the database industry was shaped.

44:53.000 --> 45:02.000
And so in the data prep landscape, I think there really needs to be a push towards these sorts of understanding of what are the common tasks and what are the sort of benchmarks that we should strive towards.

45:02.000 --> 45:07.000
How do we evaluate these sorts of tools on a comparable basis on an even footing.

45:07.000 --> 45:13.000
These are sort of some questions that I think these community efforts will hopefully lead to kind of resolutions.

45:13.000 --> 45:19.000
Awesome. Awesome. Well, we'll run thanks so much for joining the podcast and sharing with us.

45:19.000 --> 45:23.000
It was a pleasure. Thank you again for having me and thanks for all these questions.

45:23.000 --> 45:31.000
And I hope the audience enjoys the nearest conference and the DBA workshop. And I look forward to seeing people think.

45:31.000 --> 45:32.000
Awesome. Thanks so much.

45:32.000 --> 45:33.000
Thank you, Sam.

45:33.000 --> 45:43.000
Thank you.

