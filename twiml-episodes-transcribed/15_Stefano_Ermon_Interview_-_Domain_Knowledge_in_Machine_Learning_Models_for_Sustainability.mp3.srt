1
00:00:00,000 --> 00:00:16,000
Hello and welcome to another episode of Twymilthalk, the podcast where I interview

2
00:00:16,000 --> 00:00:21,320
interesting people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,320 --> 00:00:25,080
I'm your host Sam Charrington.

4
00:00:25,080 --> 00:00:28,800
I'd really like to take a moment to thank all of you who listen to this show.

5
00:00:28,800 --> 00:00:33,040
I am constantly humbled by your interest and offers of support.

6
00:00:33,040 --> 00:00:37,560
Thanks to you, the show keeps reaching more and more people with last week's show being

7
00:00:37,560 --> 00:00:42,840
our fastest ever to 5,000 listens in just over 24 hours.

8
00:00:42,840 --> 00:00:47,240
So please, please, please keep reaching out via the show notes page, Twitter, Facebook,

9
00:00:47,240 --> 00:00:48,640
YouTube, etc.

10
00:00:48,640 --> 00:00:52,000
We really, really love to hear from you.

11
00:00:52,000 --> 00:00:58,040
Inspired by listener Beth Ann and YC on Twitter, we want to try a little contest for you.

12
00:00:58,040 --> 00:01:02,440
We've got some fresh new stickers on hand and we'd like to get them into your hands.

13
00:01:02,440 --> 00:01:05,200
I've got to say they really turned out great.

14
00:01:05,200 --> 00:01:07,600
So here's what you need to do to get one.

15
00:01:07,600 --> 00:01:12,920
Let us know your favorite quote from today's podcast via Facebook, Twitter, YouTube or

16
00:01:12,920 --> 00:01:18,800
SoundCloud comment or comment on the show notes page by midnight Sunday Pacific time and

17
00:01:18,800 --> 00:01:21,200
we'll send you one.

18
00:01:21,200 --> 00:01:25,440
Before we jump into our show, I wanted to remind you to check out the future of data

19
00:01:25,440 --> 00:01:27,960
summit that I'm organizing.

20
00:01:27,960 --> 00:01:32,840
It'll take place in Las Vegas and May at the Interop ITX conference and I'm excited to

21
00:01:32,840 --> 00:01:38,200
have already heard from a bunch of Twinmal listeners making arrangements to attend.

22
00:01:38,200 --> 00:01:43,000
We'll be covering some really exciting topics, including of course machine learning and AI,

23
00:01:43,000 --> 00:01:48,880
but also IoT and edge computing, augmented and virtual reality, blockchain, algorithmic

24
00:01:48,880 --> 00:01:51,320
IT operations, data security and more.

25
00:01:51,320 --> 00:01:53,320
It's going to be a great event.

26
00:01:53,320 --> 00:02:00,400
You can learn more about the summit at twinmalai.com slash future of data.

27
00:02:00,400 --> 00:02:02,480
And now about today's show.

28
00:02:02,480 --> 00:02:09,160
This week our guest is Stefano Irman, Assistant Professor of Computer Science at Stanford University

29
00:02:09,160 --> 00:02:14,480
and fellow at Stanford's Woods Institute for the Environment.

30
00:02:14,480 --> 00:02:19,440
Stefano and I met at the rework deep learning summit earlier this year where he gave a presentation

31
00:02:19,440 --> 00:02:22,560
on machine learning for sustainability.

32
00:02:22,560 --> 00:02:27,680
We spoke about a range of topics, including incorporating domain knowledge into your

33
00:02:27,680 --> 00:02:33,400
machine learning models, dimensionality reduction and his interest in applying machine learning

34
00:02:33,400 --> 00:02:40,120
and AI to addressing sustainability issues like poverty, food security and the environment.

35
00:02:40,120 --> 00:02:50,000
And now on to the show.

36
00:02:50,000 --> 00:02:54,520
Hello everyone, welcome to another episode of this week in machine learning and AI.

37
00:02:54,520 --> 00:03:00,640
I am here with Stefano Irman, who is an Assistant Professor at Stanford University.

38
00:03:00,640 --> 00:03:06,080
Stefano and I connected after his presentation at the recent rework deep learning summit

39
00:03:06,080 --> 00:03:09,640
where he spoke on machine learning for sustainability.

40
00:03:09,640 --> 00:03:11,640
Stefano wanted to say hi to the audience.

41
00:03:11,640 --> 00:03:13,640
Hi everybody, thanks for the invitation.

42
00:03:13,640 --> 00:03:15,800
It's great to be here with you today.

43
00:03:15,800 --> 00:03:19,040
I'm really excited to have you on the show.

44
00:03:19,040 --> 00:03:24,800
I enjoyed your presentation and I spent a little bit of time looking into some of the

45
00:03:24,800 --> 00:03:31,040
work that your group is doing at Stanford and I found a really interesting mix of fundamental

46
00:03:31,040 --> 00:03:37,600
research into machine learning techniques as well as a strong interest in a particular

47
00:03:37,600 --> 00:03:41,120
application area, notably sustainability.

48
00:03:41,120 --> 00:03:48,080
So why don't you get us started by talking about how those two kind of meld for you and

49
00:03:48,080 --> 00:03:50,520
how you arrived at your area of focus?

50
00:03:50,520 --> 00:03:51,520
Sure, yeah.

51
00:03:51,520 --> 00:03:56,920
So a lot of the research that we do in my group is really at the foundation or artificial

52
00:03:56,920 --> 00:03:58,600
intelligence machine learning.

53
00:03:58,600 --> 00:04:04,800
So we do a lot of work on probabilistic modeling of data, developing scalable and accurate

54
00:04:04,800 --> 00:04:10,520
inference techniques for high dimensional probabilistic models of data, knowledge representation

55
00:04:10,520 --> 00:04:13,720
and decision making and uncertainty techniques.

56
00:04:13,720 --> 00:04:18,000
So we're really interested in the whole pipeline of going from data to extracting knowledge

57
00:04:18,000 --> 00:04:23,440
and extracting insights from the data to using these insights to improve the way we make

58
00:04:23,440 --> 00:04:24,760
decisions.

59
00:04:24,760 --> 00:04:30,640
And a lot of the work is really foundational, so we proved theorems, developed algorithms,

60
00:04:30,640 --> 00:04:31,840
developed new models.

61
00:04:31,840 --> 00:04:38,000
But we also like to think about real world problems and I'm particularly excited about new

62
00:04:38,000 --> 00:04:40,960
applications areas for AI machine learning.

63
00:04:40,960 --> 00:04:45,000
And as you mentioned, one that I'm really excited about is this new area of computational

64
00:04:45,000 --> 00:04:50,760
sustainability, where we're trying to apply computer science techniques and generally

65
00:04:50,760 --> 00:04:56,880
use ideas from computational thinking to help solve and address some of the big sustainability

66
00:04:56,880 --> 00:04:58,680
issues of our times.

67
00:04:58,680 --> 00:05:08,040
And these include things like poverty or environmental issues or energy, sustainable energy problems,

68
00:05:08,040 --> 00:05:12,680
network resource management, a problem scene ecology and so forth.

69
00:05:12,680 --> 00:05:19,680
So I'm very, very interested in finding ways to use this new amazing technologies that we've

70
00:05:19,680 --> 00:05:26,480
been developing in the past 10 or 20 years in AI machine learning and use them to address

71
00:05:26,480 --> 00:05:32,120
problems that are extremely important, I think, but perhaps they don't, they are not studied

72
00:05:32,120 --> 00:05:36,440
as much as they should in the field of machine learning and AI.

73
00:05:36,440 --> 00:05:43,440
I think you're right that they're not studied as much as they should be, how did you arrive

74
00:05:43,440 --> 00:05:50,480
at that research focus as opposed to one of the more popular or buzzy buzz worthy areas

75
00:05:50,480 --> 00:05:55,880
like robotics and or even here in the valley, getting people to click on ads.

76
00:05:55,880 --> 00:05:57,640
You know, I have a red thread.

77
00:05:57,640 --> 00:06:04,200
So I also started with my PhD actually, so I did my PhD in computer science at Cornell

78
00:06:04,200 --> 00:06:06,960
University and arrived when I joined.

79
00:06:06,960 --> 00:06:13,040
My advisor had just received a big grant from NSF, an expedition in computing to start

80
00:06:13,040 --> 00:06:16,280
a whole new research area in computer science.

81
00:06:16,280 --> 00:06:23,400
And the idea was really to try to see whether we can take all these amazing techniques and

82
00:06:23,400 --> 00:06:30,000
ideas that we have and use them to address problems in the sort of in the public space.

83
00:06:30,000 --> 00:06:37,680
The idea being that information technology and computers and AI have really revolutionized

84
00:06:37,680 --> 00:06:43,640
the way people live and a lot of way people do businesses and they really changed the

85
00:06:43,640 --> 00:06:44,640
world.

86
00:06:44,640 --> 00:06:51,160
But if you think on the other hand, at the way we try to solve some of the big societal

87
00:06:51,160 --> 00:06:55,600
problems that we have in the public space dealing with the environment and how we manage

88
00:06:55,600 --> 00:07:00,800
our network resources or how we try to sort of close the gap between developing and

89
00:07:00,800 --> 00:07:06,880
developed countries, we're still not taking advantage of all of these ideas just because

90
00:07:06,880 --> 00:07:13,160
there's not so much economic incentive to sort of apply, develop the necessary models,

91
00:07:13,160 --> 00:07:16,880
develop the necessary algorithms, figure out how to actually use them to solve these

92
00:07:16,880 --> 00:07:17,880
problems.

93
00:07:17,880 --> 00:07:23,000
And so, you know, that was kind of how I got started and I've been working on those

94
00:07:23,000 --> 00:07:28,080
kind of problems basically ever since, so for almost 10 years now.

95
00:07:28,080 --> 00:07:29,080
Very nice.

96
00:07:29,080 --> 00:07:36,400
Now, in your presentation, you shared some statistics around the impact of the problems

97
00:07:36,400 --> 00:07:41,720
that you're going after with regard to poverty and food security and the environment.

98
00:07:41,720 --> 00:07:46,640
You know, in many ways, I think it's kind of obvious that these are important issues,

99
00:07:46,640 --> 00:07:52,400
but like you say, in a lot of ways, they're understudied because of the lack of a driving

100
00:07:52,400 --> 00:07:53,400
economic incentive.

101
00:07:53,400 --> 00:07:58,560
You know, can you share some of those stats or at least the ones that inspire you to continue

102
00:07:58,560 --> 00:07:59,560
pursuing this work?

103
00:07:59,560 --> 00:08:00,560
Right.

104
00:08:00,560 --> 00:08:06,760
Like I was actually looking at the 2030 agenda for sustainable development that was recently

105
00:08:06,760 --> 00:08:11,760
adopted by the United Nations and if you look at the kind of problems that were sort of

106
00:08:11,760 --> 00:08:17,360
identified as being some of the big societal challenges that sort of all the governments

107
00:08:17,360 --> 00:08:21,040
in the world should be working together to address.

108
00:08:21,040 --> 00:08:25,720
We see things like ending extreme poverty, there are still hundreds of millions of people

109
00:08:25,720 --> 00:08:30,120
around the world living extreme poverty or eliminating hunger.

110
00:08:30,120 --> 00:08:34,800
It turns out that again, there are lots of people, especially in places like Africa and

111
00:08:34,800 --> 00:08:37,800
Asia and so forth that don't have enough to be.

112
00:08:37,800 --> 00:08:44,600
Or you know, protecting biodiversity, there's this huge biodiversity loss and we need to

113
00:08:44,600 --> 00:08:51,000
find ways to manage our resources in a more sustainable way so that we can sort of guarantee

114
00:08:51,000 --> 00:08:56,360
the welfare, not just about current generation, but also our children and the generations

115
00:08:56,360 --> 00:08:58,000
that will come after them.

116
00:08:58,000 --> 00:09:04,560
So these are all big and problem problems and a lot of them, one of the challenges right

117
00:09:04,560 --> 00:09:05,560
there.

118
00:09:05,560 --> 00:09:10,000
So they figure out this partially because they involve this sort of global skill phenomena

119
00:09:10,000 --> 00:09:17,000
thinking about a climate change or how to manage these very large ecosystems or the fact

120
00:09:17,000 --> 00:09:21,360
that we need to deal with multiple agents that are sort of have different objective functions

121
00:09:21,360 --> 00:09:23,000
than they're interacted with each other.

122
00:09:23,000 --> 00:09:27,920
But there's clearly like a computational component to these problems, but so far it has

123
00:09:27,920 --> 00:09:29,760
not been studied so much.

124
00:09:29,760 --> 00:09:36,000
And so one of the focus of my research is really to try to find ways to apply these techniques

125
00:09:36,000 --> 00:09:40,640
from AI and computer science to help address some of these issues.

126
00:09:40,640 --> 00:09:46,960
And on that note, do you come at things from the perspective of, as you said, apply

127
00:09:46,960 --> 00:09:53,720
applying techniques that are developed in AI and machine learning research to this application

128
00:09:53,720 --> 00:09:59,680
area or the other way around, meaning identifying specific problems in the research area and

129
00:09:59,680 --> 00:10:04,480
using those to drive research around specific techniques.

130
00:10:04,480 --> 00:10:05,480
That's a big question.

131
00:10:05,480 --> 00:10:10,880
I actually like to think of it as a two-way street, so yes and yes.

132
00:10:10,880 --> 00:10:18,040
On the one hand, sometimes we start with a problem and we realize that maybe we don't

133
00:10:18,040 --> 00:10:22,440
have the tools right now, or we don't have the right models to address the problem.

134
00:10:22,440 --> 00:10:26,320
And that often happens because this problem haven't been studied so much with computer science.

135
00:10:26,320 --> 00:10:31,160
So there's always some aspect of this problem that has not been studied before or some

136
00:10:31,160 --> 00:10:36,280
variation that sort of gives rise to a new problem that will require new models, new

137
00:10:36,280 --> 00:10:41,640
model algorithms, and we can sort of publish our papers in sort of top AI machine learning

138
00:10:41,640 --> 00:10:42,640
conferences.

139
00:10:42,640 --> 00:10:49,040
And on the other hand, we also like to do a lot of foundational research, and so sometimes

140
00:10:49,040 --> 00:10:55,080
we know about all the capabilities that we have right now, the cutting edge of AI machine

141
00:10:55,080 --> 00:10:56,080
learning.

142
00:10:56,080 --> 00:11:00,080
So just by talking with my colleagues and Stanford, sometimes I hear about, no, I asked

143
00:11:00,080 --> 00:11:02,360
them, what are the problems that they are working on?

144
00:11:02,360 --> 00:11:09,200
And we tried to find ways to use this new ideas and apply them to help them solve this

145
00:11:09,200 --> 00:11:11,080
very important problems.

146
00:11:11,080 --> 00:11:15,440
So one reason why this, it's interesting that you take this two-way street approaches

147
00:11:15,440 --> 00:11:22,840
because I spend quite a bit of time following companies that are trying to democratize machine

148
00:11:22,840 --> 00:11:29,640
learning in AI, and often what they're doing is trying to create generalized machine learning

149
00:11:29,640 --> 00:11:34,480
in AI platforms, and in fact, you know, all of the large cloud companies like Google

150
00:11:34,480 --> 00:11:38,680
Microsoft and Amazon are trying to do that same thing.

151
00:11:38,680 --> 00:11:44,680
But then we have a group like yours that has a fundamental focus on a specific application

152
00:11:44,680 --> 00:11:50,560
area that drives deep, deep, unique research into the field.

153
00:11:50,560 --> 00:11:53,360
I'm wondering what's your take on that?

154
00:11:53,360 --> 00:11:58,960
Do you feel like what's the role of what's your take on the role of kind of generalized

155
00:11:58,960 --> 00:12:07,280
machine learning in AI techniques and versus very application-specific techniques?

156
00:12:07,280 --> 00:12:16,440
I think there's definitely a lot of value in developing tools that can be easily used

157
00:12:16,440 --> 00:12:23,200
by people that are not necessarily the domain experts, and I will definitely help in a lot

158
00:12:23,200 --> 00:12:30,520
of context, including the sustainability space, but I do believe that sometimes you really

159
00:12:30,520 --> 00:12:34,200
need to develop some actual research to be done.

160
00:12:34,200 --> 00:12:40,440
There are some problems that require actually new techniques, and so there's definitely

161
00:12:40,440 --> 00:12:47,000
a lot of space for developing new ideas, new models that maybe are motivated by this

162
00:12:47,000 --> 00:12:52,160
specific application, but then they can potentially apply it down the line to other problems

163
00:12:52,160 --> 00:12:54,600
that are completely different of names.

164
00:12:54,600 --> 00:12:59,760
That's kind of the beauty of computer science is this idea of abstraction to develop general

165
00:12:59,760 --> 00:13:04,960
models, these general algorithms that are maybe inspired by one specific problem, but

166
00:13:04,960 --> 00:13:10,200
then a few years later, somebody else comes up with a completely different new application

167
00:13:10,200 --> 00:13:15,200
that you would never have thought about, and they apply exactly the same algorithm to

168
00:13:15,200 --> 00:13:16,200
this new problem.

169
00:13:16,200 --> 00:13:21,080
I think that's really the power of computer science, this layers of abstraction.

170
00:13:21,080 --> 00:13:28,680
All right, so let's maybe try to get more concrete and talk through some of the specific

171
00:13:28,680 --> 00:13:36,040
research that your group is doing and how it's uniquely applied in this application area.

172
00:13:36,040 --> 00:13:40,960
One of the papers that I came across on your group's website, which I'll link to in the

173
00:13:40,960 --> 00:13:47,240
show notes, is one on deep Gaussian process for crop yield prediction based on remote

174
00:13:47,240 --> 00:13:49,240
sensing data.

175
00:13:49,240 --> 00:13:55,440
Crop yield prediction will talk about the importance of that problem and the data source

176
00:13:55,440 --> 00:13:59,680
and then walk us through kind of what the research is hoping to achieve.

177
00:13:59,680 --> 00:14:05,840
Yeah, so that particular paper, we were looking at problems in the food security space.

178
00:14:05,840 --> 00:14:09,560
It turns out that there are, as I mentioned earlier, there are lots of people around the

179
00:14:09,560 --> 00:14:17,720
world that don't have enough to eat, or suffering from various kind of food crisis, due to

180
00:14:17,720 --> 00:14:26,400
weather, climate change, like erosion, or rising waters, all sorts of problems are kind

181
00:14:26,400 --> 00:14:29,480
of causing this food security issues.

182
00:14:29,480 --> 00:14:34,120
And we know that the situation is going to get worse with time, but the world population

183
00:14:34,120 --> 00:14:38,560
is growing and we're going to have to find a way to, there's an estimated, I think, two

184
00:14:38,560 --> 00:14:43,480
billion more people that we're going to have in 2050 and we're going to have to find

185
00:14:43,480 --> 00:14:46,080
ways to feed this growing population.

186
00:14:46,080 --> 00:14:52,160
So the kind of problem that we looked at was that of trying to see whether we can use

187
00:14:52,160 --> 00:15:01,200
inexpensive, cheap, unconventional data sources, like satellite data to keep track and predict

188
00:15:01,200 --> 00:15:07,080
various food security measures and monitor agricultural outcomes.

189
00:15:07,080 --> 00:15:14,120
So in particular, we try to develop these machine learning techniques to predict just

190
00:15:14,120 --> 00:15:21,720
by looking at the images of the Earth from space, to predict how the kind of level of agricultural

191
00:15:21,720 --> 00:15:28,240
productivity of a geographical area just by looking at it from from space, essentially

192
00:15:28,240 --> 00:15:35,120
we developed some machine learning models that can track the growth of plants from space

193
00:15:35,120 --> 00:15:41,440
and use that information to predict ahead of time how much in that particular application

194
00:15:41,440 --> 00:15:47,720
we're looking at soybeans, but since then we've extended it to corn and other crops.

195
00:15:47,720 --> 00:15:52,960
We're able to actually predict very accurately from space using cheap, unconventional data

196
00:15:52,960 --> 00:15:57,960
sources, the level of productivity of different geographical regions.

197
00:15:57,960 --> 00:16:02,920
And this is important because given this kind of data, we can start collecting this kind

198
00:16:02,920 --> 00:16:06,400
of data, especially in developing countries, it's very expensive.

199
00:16:06,400 --> 00:16:12,240
We don't have much data on this kind of measures in places like Africa.

200
00:16:12,240 --> 00:16:20,560
And so if we had a way to measure these crop yields or other food security measures,

201
00:16:20,560 --> 00:16:27,200
like something or things like that, that could be extremely useful to improve the kind

202
00:16:27,200 --> 00:16:34,600
of policies that both governments and NGO use things like predicting whether it's going

203
00:16:34,600 --> 00:16:42,080
to be a farm item, a certain region, or a certain government should stock or increase

204
00:16:42,080 --> 00:16:50,120
the levels of food reserves in case there's an emergency and things like that.

205
00:16:50,120 --> 00:16:56,680
And so in this particular case, remote sensing data, the satellite imagery is where did that

206
00:16:56,680 --> 00:16:57,680
come from?

207
00:16:57,680 --> 00:17:03,760
Is this Google Maps type data, for example, or Google Earth type data, or a government

208
00:17:03,760 --> 00:17:05,400
or proprietary data source?

209
00:17:05,400 --> 00:17:07,360
It's actually publicly available data.

210
00:17:07,360 --> 00:17:11,840
We were using data from NASA, the MOLIS satellites.

211
00:17:11,840 --> 00:17:13,880
So this is publicly available data.

212
00:17:13,880 --> 00:17:18,200
It takes an image of the basically the entire world every eight days.

213
00:17:18,200 --> 00:17:24,240
And this is my spectral data, so it's not just sort of like visible RGB bands, but there's

214
00:17:24,240 --> 00:17:30,280
also infrared and other bands that contain additional information that we can use in our

215
00:17:30,280 --> 00:17:32,680
machine learning system to make our predictions.

216
00:17:32,680 --> 00:17:33,680
OK.

217
00:17:33,680 --> 00:17:41,160
So you started with the goal of taking this multimodal image-sentient image data and trying

218
00:17:41,160 --> 00:17:45,200
to predict crop yields based on it.

219
00:17:45,200 --> 00:17:52,240
And along the way, developed some new techniques around one that was called out in the paper

220
00:17:52,240 --> 00:17:55,000
is dimensionality reduction.

221
00:17:55,000 --> 00:18:00,960
Can we spend some time talking about that particular technique and its novelty and even the

222
00:18:00,960 --> 00:18:05,360
step before that, for folks that aren't familiar with it, what is dimensionality reduction

223
00:18:05,360 --> 00:18:07,680
and why is it important in this problem space?

224
00:18:07,680 --> 00:18:08,680
Yeah.

225
00:18:08,680 --> 00:18:13,040
So the challenge for this kind of application is that we didn't have a whole lot of training

226
00:18:13,040 --> 00:18:14,040
data available.

227
00:18:14,040 --> 00:18:18,200
Like these days, if you have a lot of training data, then you can take a sufficiently high-capacity

228
00:18:18,200 --> 00:18:25,680
model, like a big large amount of networks, and there is a high chance that with a sufficiently

229
00:18:25,680 --> 00:18:31,120
large amount of training data, you will be able to do a pretty good job of predicting these

230
00:18:31,120 --> 00:18:33,560
outcomes that we care about.

231
00:18:33,560 --> 00:18:38,560
But in a lot of these sustainability applications, like in this case, for predicting crop yields

232
00:18:38,560 --> 00:18:44,120
and also, we did some other work on predicting other kind of socio-economic measures of interest

233
00:18:44,120 --> 00:18:49,000
like poverty, it turns out that the amount of training data available is extremely limited,

234
00:18:49,000 --> 00:18:50,200
it's very, very scarce.

235
00:18:50,200 --> 00:18:54,680
And so you cannot just train machine learning systems, state-of-the-art machine learning

236
00:18:54,680 --> 00:18:57,400
system end-to-end from inputs to outputs.

237
00:18:57,400 --> 00:19:04,040
And so what we did is we've been developing several techniques to try to get away with

238
00:19:04,040 --> 00:19:06,080
less training data.

239
00:19:06,080 --> 00:19:10,960
One in particular that we use the one, the particular dimension, which, and other several

240
00:19:10,960 --> 00:19:17,680
ways to do it, sometimes, and essentially, in all the cases, we either do transfer learnings

241
00:19:17,680 --> 00:19:23,280
or we try to use some proxy for the measures that we care about to get some signal, and

242
00:19:23,280 --> 00:19:27,320
maybe pre-trained the system and learn something useful about the structure of this kind

243
00:19:27,320 --> 00:19:34,040
of multispectral images that we use as input, or we use some kind of prior knowledge, maybe

244
00:19:34,040 --> 00:19:38,720
something about something that we know about the outcomes that we're trying to predict,

245
00:19:38,720 --> 00:19:42,920
the relationships between input and outputs, and we can use it, we can sort of put that

246
00:19:42,920 --> 00:19:49,280
into the system to make sure that we can basically get very good results even when we don't

247
00:19:49,280 --> 00:19:50,920
have a whole lot of training data.

248
00:19:50,920 --> 00:19:55,640
In this particular context, the dimensionality reduction technique that we used was an idea

249
00:19:55,640 --> 00:20:01,120
that we had to essentially reduce the dimensionality of the inputs.

250
00:20:01,120 --> 00:20:05,920
An image is very high-dimensional, you have a lot of pixels, and they can take many different

251
00:20:05,920 --> 00:20:06,920
values.

252
00:20:06,920 --> 00:20:10,760
So it's a very high-ded sort of input data, lies in a very high-dimensional space, although

253
00:20:10,760 --> 00:20:12,200
there is a lot of structure.

254
00:20:12,200 --> 00:20:18,960
And so, in some sense, the information that we care about is actually can be extracted

255
00:20:18,960 --> 00:20:25,560
from without really looking at the exact position of all the pixels in the image.

256
00:20:25,560 --> 00:20:31,840
So what we came up with was an idea to reduce the dimensionality of the inputs while preserving

257
00:20:31,840 --> 00:20:33,760
most of the information comp.

258
00:20:33,760 --> 00:20:35,000
And the idea was fairly simple.

259
00:20:35,000 --> 00:20:41,280
The idea was that if you care about predicting crop fields, it doesn't really matter where

260
00:20:41,280 --> 00:20:49,880
the fields are in the image, so the soybean fields are in the image, their actual location

261
00:20:49,880 --> 00:20:50,880
doesn't matter.

262
00:20:50,880 --> 00:20:52,640
Do you say the soybean fields?

263
00:20:52,640 --> 00:20:54,880
Let's say the soybean fields.

264
00:20:54,880 --> 00:20:55,880
Soybean fields, okay?

265
00:20:55,880 --> 00:21:01,440
The actual position in the image, whether they appear in the top right corner or the

266
00:21:01,440 --> 00:21:04,440
left bottom corner doesn't matter.

267
00:21:04,440 --> 00:21:10,360
So you can use this prior knowledge to essentially reduce the dimensionality of the inputs while

268
00:21:10,360 --> 00:21:16,000
preserving the information content, and that makes learning the problem easier.

269
00:21:16,000 --> 00:21:22,640
So when I think about the image problem, in what way is that a high dimensionality problem

270
00:21:22,640 --> 00:21:27,800
and how do those dimensions correspond to the actual problem space?

271
00:21:27,800 --> 00:21:32,840
Well, you have basically one dimension for a pixel in the image, so if you have a thousand

272
00:21:32,840 --> 00:21:38,200
by a thousand pixels, there you have a million dimensions for the inputs, and that's essentially

273
00:21:38,200 --> 00:21:41,000
what's causing the problem.

274
00:21:41,000 --> 00:21:47,160
It's very high dimensional, and so it's known that there's a lot of machine learning algorithms

275
00:21:47,160 --> 00:21:49,120
and a lot of algorithms in computer science.

276
00:21:49,120 --> 00:21:54,880
They suffer from this curse of dimensionality problem that as the dimensionality grows, the

277
00:21:54,880 --> 00:21:57,760
volume of objects grows exponentially fast.

278
00:21:57,760 --> 00:22:02,480
So kind of the coverage that you have of this very high dimensional space by getting samples

279
00:22:02,480 --> 00:22:06,640
that you have from your training data is extremely, extremely sparse, which is so high

280
00:22:06,640 --> 00:22:12,040
dimensional that you have like so few points, but makes it very different to sort of infer

281
00:22:12,040 --> 00:22:15,840
something about what is going on in this very high dimensional space.

282
00:22:15,840 --> 00:22:22,440
So you have to use some kind of prior knowledge to realize that actually, well, there are certain

283
00:22:22,440 --> 00:22:26,240
things that don't really matter, that we're looking for things that maybe are translational

284
00:22:26,240 --> 00:22:33,040
invariant, or maybe we know that some bands don't matter, or we have some kind of inductive

285
00:22:33,040 --> 00:22:40,440
bias that we can use to input that knowledge into the system so that we can still do something

286
00:22:40,440 --> 00:22:45,400
useful, even though the inputs are so high dimension.

287
00:22:45,400 --> 00:22:49,520
So in this case, dimensionality reduction, another way of thinking about that is just

288
00:22:49,520 --> 00:22:55,800
getting your machine learning algorithm to focus on the important parts of the thing that

289
00:22:55,800 --> 00:23:03,040
you're trying to train it on as opposed to the entire space of the images.

290
00:23:03,040 --> 00:23:09,040
And so you mentioned another thing you mentioned in terms of techniques for accomplishing this

291
00:23:09,040 --> 00:23:18,080
is transfer learning, which is applying pre-existing models as kind of starter models to training

292
00:23:18,080 --> 00:23:19,480
application specific models.

293
00:23:19,480 --> 00:23:21,480
Is that the way you would describe that?

294
00:23:21,480 --> 00:23:26,120
So that is that you typically have a task in the case of machine learning that you want

295
00:23:26,120 --> 00:23:29,840
to solve, and maybe you have limited amount of training data for the task.

296
00:23:29,840 --> 00:23:34,480
So you can set up a different but related machine learning task for which you have plenty

297
00:23:34,480 --> 00:23:36,000
of training data available.

298
00:23:36,000 --> 00:23:40,680
And by solving, by trying to learn how to solve this new task, the hope is that you're

299
00:23:40,680 --> 00:23:45,000
going to learn something useful, you're going to learn some skills that then you can transfer

300
00:23:45,000 --> 00:23:48,800
to your regional machine learning problem that you care about.

301
00:23:48,800 --> 00:23:53,760
And this is often done with models trained on like ImageNet data, for example, is that

302
00:23:53,760 --> 00:23:55,880
something that you guys did in particular?

303
00:23:55,880 --> 00:24:00,680
Or did you apply other models to this particular problem?

304
00:24:00,680 --> 00:24:03,320
And how did you go about thinking about where to start?

305
00:24:03,320 --> 00:24:09,320
Yeah, so that's how the ImageNet is often a great place to start with if you're looking

306
00:24:09,320 --> 00:24:11,840
with, if you're dealing with sort of natural images.

307
00:24:11,840 --> 00:24:17,480
One challenge in our application domain is that we're looking at satellite images, which

308
00:24:17,480 --> 00:24:23,240
look very, very different from the kind of images that you can find in ImageNet.

309
00:24:23,240 --> 00:24:27,720
They are not object-centric, like there's not a single object in the middle, like you typically

310
00:24:27,720 --> 00:24:28,720
have ImageNet.

311
00:24:28,720 --> 00:24:33,400
They are taken sort of like from this bird's eye perspective, which is very different

312
00:24:33,400 --> 00:24:34,400
from ImageNet.

313
00:24:34,400 --> 00:24:38,880
They have more bands, so it's not just RGB, but you have a whole set of other bands that

314
00:24:38,880 --> 00:24:40,680
you don't typically have in ImageNet.

315
00:24:40,680 --> 00:24:46,960
And so the kind of typical features that you, that the network say convolutional or network

316
00:24:46,960 --> 00:24:53,960
pre-trained on ImageNet is able to discover, do not work well when dealing with satellite

317
00:24:53,960 --> 00:24:54,960
images.

318
00:24:54,960 --> 00:25:00,080
And so what we did was to come up with other transfer learning ideas.

319
00:25:00,080 --> 00:25:04,920
This was actually for a slightly different problem in which we were trying to predict

320
00:25:04,920 --> 00:25:12,520
the distribution of wealth and poverty, in this case, in developing countries.

321
00:25:12,520 --> 00:25:17,760
Again, we were trying to do this using a cheap and conventional data sources.

322
00:25:17,760 --> 00:25:21,840
In this case, we were using higher solution satellite images, while there is very little

323
00:25:21,840 --> 00:25:27,680
data on poverty, there are many African countries that are not taking a nationally representative

324
00:25:27,680 --> 00:25:29,720
survey, maybe in a decade or so.

325
00:25:29,720 --> 00:25:34,000
Satellite images are available in basically every part of the world that they can update

326
00:25:34,000 --> 00:25:35,880
it very frequently.

327
00:25:35,880 --> 00:25:41,080
And they contain a lot of information about various types of socioeconomic outcomes, both

328
00:25:41,080 --> 00:25:48,840
in terms of poverty, wealth, but also, yeah, agriculture outcomes, like we were just

329
00:25:48,840 --> 00:25:52,600
talking about before in the context of copy and prediction.

330
00:25:52,600 --> 00:25:57,240
And so the problem that we were looking at in that paper was that of trying to predict

331
00:25:57,240 --> 00:26:04,920
various types of poverty estimates like asset-based measures of wealth or other measures of poverty

332
00:26:04,920 --> 00:26:05,920
based on income.

333
00:26:05,920 --> 00:26:10,680
Again, using raw satellite images, which are widely available.

334
00:26:10,680 --> 00:26:15,120
And the challenge was that, again, we have very limited training data available to train

335
00:26:15,120 --> 00:26:16,120
these models.

336
00:26:16,120 --> 00:26:18,520
And so we had to do some transfer learning.

337
00:26:18,520 --> 00:26:24,320
And there, the idea was that it turns out that there are satellites that take images of

338
00:26:24,320 --> 00:26:27,080
the Earth both during day and during night.

339
00:26:27,080 --> 00:26:34,720
And so during night, you get to see the amount of nighttime light intensity associated with

340
00:26:34,720 --> 00:26:36,680
essentially every region in the world.

341
00:26:36,680 --> 00:26:42,920
And it turns out that nighttime light intensity is heavily correlated with the level of economic

342
00:26:42,920 --> 00:26:43,920
activity.

343
00:26:43,920 --> 00:26:47,960
If you haven't seen it, you should try to see the different areas in North Korea and South

344
00:26:47,960 --> 00:26:48,960
Korea.

345
00:26:48,960 --> 00:26:53,720
You're going to see that South Korea almost looks like an island at night because North Korea

346
00:26:53,720 --> 00:26:55,040
is so dark at night.

347
00:26:55,040 --> 00:27:00,840
And so the idea there was to see whether we can train a machine learning model to predict

348
00:27:00,840 --> 00:27:07,280
the amount of nighttime light intensity for many, many locations across the world just

349
00:27:07,280 --> 00:27:11,320
by looking at the corresponding daytime images.

350
00:27:11,320 --> 00:27:12,320
And we could do that.

351
00:27:12,320 --> 00:27:16,440
And this is a task for which we have essentially an infinite amount of training data because

352
00:27:16,440 --> 00:27:20,920
these satellites are continuously taking images both during day and during night.

353
00:27:20,920 --> 00:27:25,960
And the hope was that by training the model to solve this task, people discover features.

354
00:27:25,960 --> 00:27:30,600
They are somehow related to the level of economic activity.

355
00:27:30,600 --> 00:27:35,040
And it turns out that it is indeed the case, it turns out that if you train a convolution

356
00:27:35,040 --> 00:27:40,480
neural net to solve this task, and then you sort of try to visualize the features that

357
00:27:40,480 --> 00:27:47,280
the network learns, you discover very features that are very semantically meaningful, like there

358
00:27:47,280 --> 00:27:52,560
is a filter that learns how to recognize roads, other filters try to identify different

359
00:27:52,560 --> 00:27:58,720
types of houses or other features of the landscape, like farmland, whether there are roads with

360
00:27:58,720 --> 00:28:01,960
lots of traffic or not, even swimming pools.

361
00:28:01,960 --> 00:28:06,000
And the nice thing was that this was all discovered in a unsupervised way.

362
00:28:06,000 --> 00:28:11,240
Like we never told the network, you know, look for houses or provide labels of what a road

363
00:28:11,240 --> 00:28:14,240
is or what a house is or what a swimming pool is.

364
00:28:14,240 --> 00:28:20,600
It really discovered these semantically meaningful features by itself, purely by solving this

365
00:28:20,600 --> 00:28:26,560
transfer learning task of trying to predict nighttime-line intensity from data and images.

366
00:28:26,560 --> 00:28:33,320
And then what we did was to use these features that we learned in this transfer learning task

367
00:28:33,320 --> 00:28:38,440
to actually predict the various poverty measures that we cared about.

368
00:28:38,440 --> 00:28:43,960
And because we had such good features, again, we were able to get very high accuracy, even

369
00:28:43,960 --> 00:28:49,680
though we had, there's limited amount of training data corresponding to these poverty metrics

370
00:28:49,680 --> 00:28:51,560
that we cared about predict.

371
00:28:51,560 --> 00:28:54,240
Wow, very, very interesting.

372
00:28:54,240 --> 00:29:00,840
What do you call the name of the paper where you describe the transfer learning technique?

373
00:29:00,840 --> 00:29:02,160
So we had two papers on this.

374
00:29:02,160 --> 00:29:09,120
There was a paper, a triple AI, which is called the transfer learning from the features

375
00:29:09,120 --> 00:29:11,760
for remote sensing and poverty mapping.

376
00:29:11,760 --> 00:29:17,160
And then we had a follow-up paper on science called the combining satellite imagery and machine

377
00:29:17,160 --> 00:29:23,200
learning to predict poverty, where we actually detailed the kind of results that we got in

378
00:29:23,200 --> 00:29:27,400
predicting poverty in across five African countries.

379
00:29:27,400 --> 00:29:32,520
And we showed that it can really outperform all the previously existing techniques by quite

380
00:29:32,520 --> 00:29:34,640
a large margin.

381
00:29:34,640 --> 00:29:40,920
So in that what were without totally losing our place on the crop yield prediction,

382
00:29:40,920 --> 00:29:48,280
can you talk through some of the techniques that went into the transfer learning work?

383
00:29:48,280 --> 00:29:55,120
So that's essentially the key, sort of, just of the transfer learning, trying to find

384
00:29:55,120 --> 00:30:00,080
a task that is somehow correlated with the one you care about, but for which you have

385
00:30:00,080 --> 00:30:01,720
a lot of training data.

386
00:30:01,720 --> 00:30:05,360
We didn't actually use transfer learning for the crop yield prediction.

387
00:30:05,360 --> 00:30:07,640
We just used the dimensionality reduction.

388
00:30:07,640 --> 00:30:13,080
The other thing we used was an idea called semi-supervised learning, which is another approach

389
00:30:13,080 --> 00:30:18,920
that you can use when you have a small amount of labeled training data and potentially

390
00:30:18,920 --> 00:30:24,160
very large amount of unlabeled training data, which is, for example, the case in our applications

391
00:30:24,160 --> 00:30:30,080
where we have a lot of satellite images, but we have a very small amount of labels corresponding

392
00:30:30,080 --> 00:30:38,120
to the amount of soybeans that were produced in different regions or the poverty, sort

393
00:30:38,120 --> 00:30:42,840
of, like, survey-based measures of poverty in developing countries.

394
00:30:42,840 --> 00:30:48,360
And the kind of technique that we use to do semi-supervised learning in this case is a

395
00:30:48,360 --> 00:30:52,000
combination of neural networks with Gaussian processes.

396
00:30:52,000 --> 00:30:58,160
The idea is that we are trying to predict things that have a structure, like we're trying

397
00:30:58,160 --> 00:31:03,960
to predict a distribution of, say, wealth or crop yields across space and time.

398
00:31:03,960 --> 00:31:09,240
And we are expecting these outputs that we're trying to predict to change slowly as a function

399
00:31:09,240 --> 00:31:11,440
of time and space.

400
00:31:11,440 --> 00:31:15,200
And so that's some kind of microbiology that you can incorporate into the model.

401
00:31:15,200 --> 00:31:21,120
And we did this using our Gaussian process, which is a probabilistic model that you can

402
00:31:21,120 --> 00:31:26,360
use to model all sorts of things, but it's very popular in the Geo-statistics community

403
00:31:26,360 --> 00:31:33,160
to sort of model functions that are over space and time, and then you can use this probabilistic

404
00:31:33,160 --> 00:31:38,520
model to not only make predictions, but also to measure the uncertainty that you have

405
00:31:38,520 --> 00:31:43,280
when you make predictions at new locations for which you don't have training data.

406
00:31:43,280 --> 00:31:51,080
And so is the Gaussian process primarily used, especially, as you just mentioned, or is

407
00:31:51,080 --> 00:31:57,520
it also used in time, meaning I've got a label at some point in time, but I don't know

408
00:31:57,520 --> 00:32:01,560
how the value of that label changes over time.

409
00:32:01,560 --> 00:32:05,320
So we apply a Gaussian to that, or both of the above.

410
00:32:05,320 --> 00:32:09,800
Both of the above, yeah, in our case, we were looking both over space and time.

411
00:32:09,800 --> 00:32:15,760
So in general, you can use Gaussian processes over any kind of input space.

412
00:32:15,760 --> 00:32:22,480
They're often used to model functions of the change over space and time.

413
00:32:22,480 --> 00:32:29,600
And the key thing that we did was to combine these with neural networks for each location

414
00:32:29,600 --> 00:32:30,920
in space and time.

415
00:32:30,920 --> 00:32:36,320
We have a corresponding image that is collected by a satellite, and so we somehow want to

416
00:32:36,320 --> 00:32:42,920
include that information to inform the predictions that are made by the discussion process.

417
00:32:42,920 --> 00:32:48,520
And the idea was that we could somehow extract features from an image using a convolution

418
00:32:48,520 --> 00:32:53,640
neural network, and then use these features together sort of the spatial and temporal structure

419
00:32:53,640 --> 00:32:56,000
of the problem to make predictions.

420
00:32:56,000 --> 00:33:00,920
And the nice thing about the Gaussian process is that it not only allows you to make predictions,

421
00:33:00,920 --> 00:33:05,640
but again, it lets you quantify the uncertainty that you have when you make predictions and

422
00:33:05,640 --> 00:33:08,160
new unlabeled data points.

423
00:33:08,160 --> 00:33:14,400
So our idea of doing semi-supervised learning was to sort of join to train the neural network

424
00:33:14,400 --> 00:33:20,240
and the Gaussian process in order to achieve a good fit at the points for which we had actual

425
00:33:20,240 --> 00:33:21,240
labels.

426
00:33:21,240 --> 00:33:27,200
What at the same time, trying to minimize the uncertainty at points for which we don't

427
00:33:27,200 --> 00:33:31,480
have labels, points for which we have the inputs, but we don't have the outputs.

428
00:33:31,480 --> 00:33:36,680
And it turns out that even though we don't have the actual sort of output for this, for

429
00:33:36,680 --> 00:33:41,160
this unlabeled data points, the Gaussian process will still be able to make a prediction and

430
00:33:41,160 --> 00:33:44,120
will still be able to quantify the uncertainty of this prediction.

431
00:33:44,120 --> 00:33:49,520
So we can join to train both of them to actually minimize this measure of uncertainty.

432
00:33:49,520 --> 00:33:55,160
And that's essentially how we use the unlabeled data points together with the labeled ones

433
00:33:55,160 --> 00:33:58,520
to in this semi-supervised learning framework.

434
00:33:58,520 --> 00:34:02,960
And in some sense, it's a formal regularization that is sort of forcing the model to look for

435
00:34:02,960 --> 00:34:09,280
features that are not only useful for the labeled data points, but it's sort of also, they

436
00:34:09,280 --> 00:34:14,080
are also relevant for the unlabeled data points.

437
00:34:14,080 --> 00:34:19,520
And it turns out that by using this framework, the semi-supervised framework we developed,

438
00:34:19,520 --> 00:34:25,640
we were able to further improve the accuracy in both the power-to-tradition task and the

439
00:34:25,640 --> 00:34:27,160
crop-to-tradition task.

440
00:34:27,160 --> 00:34:36,120
Okay, so taking a step back, you've got this image data from the satellites that is, you

441
00:34:36,120 --> 00:34:43,640
know, has pixels, but is multi-model, so it has multiple pixels for each location.

442
00:34:43,640 --> 00:34:50,920
When you talk about making a prediction from a particular point, is that, what's the

443
00:34:50,920 --> 00:34:51,920
granularity there?

444
00:34:51,920 --> 00:34:57,680
Are you predicting the level of Walter Poverty from a pixel or are you somehow aggregating

445
00:34:57,680 --> 00:34:59,880
multiple pixels to form an area?

446
00:34:59,880 --> 00:35:00,880
Yeah, good question.

447
00:35:00,880 --> 00:35:06,120
So we were looking, we were making predictions at the one kilometer or one kilometer sort

448
00:35:06,120 --> 00:35:09,400
of areas, which correspond to multiple pixels.

449
00:35:09,400 --> 00:35:14,440
So for each sort of location, we would collect multiple images that would cover that location,

450
00:35:14,440 --> 00:35:18,320
and then we would sort of aggregate all the information and make a prediction for that

451
00:35:18,320 --> 00:35:19,320
area.

452
00:35:19,320 --> 00:35:25,320
And so you've got all this input data, you're feeding that input data into a convolutional

453
00:35:25,320 --> 00:35:33,880
neural net, which is essentially taking kind of various chunks of the images and translating

454
00:35:33,880 --> 00:35:38,480
them, rotating them, things like that to try to identify what are the salient features

455
00:35:38,480 --> 00:35:41,040
within the images.

456
00:35:41,040 --> 00:35:46,960
And then your, I guess the question that I'm getting at is how and, you know, where do

457
00:35:46,960 --> 00:35:52,640
you marry the Gaussian stuff with the CNN stuff?

458
00:35:52,640 --> 00:35:54,160
Is that a training?

459
00:35:54,160 --> 00:35:56,200
Is that a step that's taken in the training?

460
00:35:56,200 --> 00:35:59,800
Is that a feature of the model architecture?

461
00:35:59,800 --> 00:36:01,080
How do they tie together?

462
00:36:01,080 --> 00:36:03,680
Yeah, you can think of it as both.

463
00:36:03,680 --> 00:36:09,360
So you can sort of think that there is one neural network making prediction at each

464
00:36:09,360 --> 00:36:10,840
different location.

465
00:36:10,840 --> 00:36:16,160
But then all the predictions that are made across different locations are all tied together,

466
00:36:16,160 --> 00:36:19,080
because we know that the outputs are spatially correlated.

467
00:36:19,080 --> 00:36:24,800
So if you take two locations that are close to each other, we know that we sort of expect

468
00:36:24,800 --> 00:36:29,400
the outcomes that we're trying to predict to be more similar to the locations are close

469
00:36:29,400 --> 00:36:30,400
to each other.

470
00:36:30,400 --> 00:36:36,120
And we know that empirically, if you plot a very grand measuring place, there is a large

471
00:36:36,120 --> 00:36:39,240
spatial correlation in these kind of things that we're trying to predict.

472
00:36:39,240 --> 00:36:45,080
As you can imagine, the Gaussian process has an extra layer in your neural network at

473
00:36:45,080 --> 00:36:46,080
the very end.

474
00:36:46,080 --> 00:36:52,040
It's kind of tying together, coupling together all the outputs of these predictions made

475
00:36:52,040 --> 00:36:55,720
by all these various convolutional neural networks.

476
00:36:55,720 --> 00:37:01,920
And by using this, you can sort of exploit this prior knowledge that you have about the

477
00:37:01,920 --> 00:37:06,080
spatial and potentially important dependencies across the outputs.

478
00:37:06,080 --> 00:37:09,240
How many layers did the network end up having?

479
00:37:09,240 --> 00:37:12,800
Yeah, we experimented with several architectures.

480
00:37:12,800 --> 00:37:19,520
I think the one in the science paper, it was based on a BGG network.

481
00:37:19,520 --> 00:37:24,640
More recently, we've been playing with Rasmash of 50 layers, and those tend to work

482
00:37:24,640 --> 00:37:26,160
even better.

483
00:37:26,160 --> 00:37:33,480
And what's the, do you have a sense for the relative performance within without the Gaussian

484
00:37:33,480 --> 00:37:34,480
layer?

485
00:37:34,480 --> 00:37:36,080
Or I imagine that's what you talked about in your paper.

486
00:37:36,080 --> 00:37:43,200
Was that, you know, the, I guess, fundamentally, did the Gaussian layer make this possible?

487
00:37:43,200 --> 00:37:47,160
Or was it adding an incremental boost in performance?

488
00:37:47,160 --> 00:37:50,560
It's adding an incremental boosting performance.

489
00:37:50,560 --> 00:37:55,680
I think you could have gotten some reasonable results, even without the Gaussian process,

490
00:37:55,680 --> 00:38:02,520
but the Gaussian process definitely, definitely helped by maybe improving by maybe 10% or

491
00:38:02,520 --> 00:38:05,120
15% something like that.

492
00:38:05,120 --> 00:38:10,800
Is there anything in particular else that you learned about the process of architecting

493
00:38:10,800 --> 00:38:14,960
networks for this type of problem in the context of this work?

494
00:38:14,960 --> 00:38:27,240
Well, one thing that matters the most is that somehow it's quite interesting how we started

495
00:38:27,240 --> 00:38:32,440
trying to sort of inspire the architectures and try out networks that were sort of losing

496
00:38:32,440 --> 00:38:38,120
inspired by what our domain experts would tell us was important to say in the context

497
00:38:38,120 --> 00:38:42,840
of crop yield prediction, there has been quite a bit of work in the remote sensing literature

498
00:38:42,840 --> 00:38:48,800
in coming up with the handcrafted features and various types of indexes, combination

499
00:38:48,800 --> 00:38:55,400
of various bands that they think are going to be predictive of vegetation growth and

500
00:38:55,400 --> 00:38:58,080
therefore also crop yields.

501
00:38:58,080 --> 00:39:03,560
And it turns out that if you actually train and the neural network to sort of discover

502
00:39:03,560 --> 00:39:10,960
the features by itself just by doing representation learning using a modern machine learning approach

503
00:39:10,960 --> 00:39:16,520
where we let the data speak for itself and try to identify which features are relevant

504
00:39:16,520 --> 00:39:17,520
directly from data.

505
00:39:17,520 --> 00:39:26,120
It turns out that our model ended up using a very, very different kind of different inputs

506
00:39:26,120 --> 00:39:31,000
ended up matter, mattering much more for our model than what was previously thought in

507
00:39:31,000 --> 00:39:32,640
the remote sensing literature.

508
00:39:32,640 --> 00:39:37,640
So some bands that people thought were not particularly important for crop yield prediction

509
00:39:37,640 --> 00:39:42,080
ended up being very, very important for our neural network and vice versa.

510
00:39:42,080 --> 00:39:46,120
So I think it's similar to what's going on, what happened in computer vision, what

511
00:39:46,120 --> 00:39:52,120
people for a long time were handcrafting features and then it turns out that if you sort of

512
00:39:52,120 --> 00:39:56,920
train and to end the neural network you can do an out better than anything sort of people

513
00:39:56,920 --> 00:40:03,600
had the all the kind of kind of crafted features that people had come up with in over the years.

514
00:40:03,600 --> 00:40:08,760
And so something similar was happening in this case that using this modern machine learning

515
00:40:08,760 --> 00:40:12,600
techniques we were able to come up with very different features than what was previously

516
00:40:12,600 --> 00:40:13,600
thought.

517
00:40:13,600 --> 00:40:20,160
And do you attribute the difference between what your models came up with and what domain

518
00:40:20,160 --> 00:40:28,240
experts tended to use with biases on the part of the domain experts with confounding factors

519
00:40:28,240 --> 00:40:32,440
in the model or the use case, any particular insights there?

520
00:40:32,440 --> 00:40:37,720
So unfortunately this neural network is very powerful and making predictions but it can

521
00:40:37,720 --> 00:40:40,720
be hard to really, they're not getting different.

522
00:40:40,720 --> 00:40:45,160
It can be very hard to figure out exactly what they're doing.

523
00:40:45,160 --> 00:40:49,800
We'll talk about that problem quite a bit on the shelf.

524
00:40:49,800 --> 00:40:54,560
So we had the same issues and sort of trying to understand and trying to explain what this

525
00:40:54,560 --> 00:40:57,840
model is doing was very hard.

526
00:40:57,840 --> 00:41:05,560
And so we don't have a good sense of why at the moment is something we're actually actively

527
00:41:05,560 --> 00:41:10,520
researching and really trying to understand why this model capturing and why does it perform

528
00:41:10,520 --> 00:41:12,800
so much better on the previous techniques.

529
00:41:12,800 --> 00:41:18,800
But I think we're going to need probably entirely new techniques to figure out these issues

530
00:41:18,800 --> 00:41:22,560
in a more physical way.

531
00:41:22,560 --> 00:41:29,280
When you describe the approach of using the nighttime imagery to train the model on the

532
00:41:29,280 --> 00:41:35,520
daytime imagery imagery, it reminded me a little bit of another one of your recent papers.

533
00:41:35,520 --> 00:41:43,520
Also AAAI paper from this year on the label-free supervision of neural networks with physics.

534
00:41:43,520 --> 00:41:46,920
And so there are a lot of kind of a lot of parallels there.

535
00:41:46,920 --> 00:41:50,880
But this one, the context in which it's talked about in this paper is kind of an interesting

536
00:41:50,880 --> 00:41:57,160
one where you've got models that you're trying to predict, well, I guess I should allow

537
00:41:57,160 --> 00:42:00,200
you to explain that.

538
00:42:00,200 --> 00:42:03,960
Why don't you go ahead and explain what the focus of that paper was?

539
00:42:03,960 --> 00:42:04,960
Sure.

540
00:42:04,960 --> 00:42:09,680
So I mean, it fits into the general, one of the general themes that I'm excited about,

541
00:42:09,680 --> 00:42:13,600
which is this idea of trying to incorporate the main knowledge into machine learning

542
00:42:13,600 --> 00:42:14,600
systems.

543
00:42:14,600 --> 00:42:23,000
So find ways to provide supervision that are alternative to coming up with millions of

544
00:42:23,000 --> 00:42:24,000
labeled examples.

545
00:42:24,000 --> 00:42:28,680
And so the idea of doing semi-supervised learning, the idea of doing transfer learning,

546
00:42:28,680 --> 00:42:35,480
the idea of doing various dimensionality reduction techniques, fits into this broader

547
00:42:35,480 --> 00:42:36,480
agenda.

548
00:42:36,480 --> 00:42:42,840
I'm trying to see where we can go beyond this labeling, which is really a major bottleneck

549
00:42:42,840 --> 00:42:47,200
and it's really preventing us from applying this machine learning techniques in domains

550
00:42:47,200 --> 00:42:51,760
like the kind of applications we are interested in, this is the ability space where the labels

551
00:42:51,760 --> 00:42:52,760
are just not available.

552
00:42:52,760 --> 00:42:55,760
And I mean, if you wanted more labels, you could not get them.

553
00:42:55,760 --> 00:43:04,480
Like we were a couple of months ago, I said, we were running our model in Somalia, we're

554
00:43:04,480 --> 00:43:08,080
making poverty predictions in Somalia for the World Bank.

555
00:43:08,080 --> 00:43:12,320
And that's a country where they cannot, they were telling me how they cannot even stand

556
00:43:12,320 --> 00:43:17,040
that there are people on the ground to collect data because it's just too dangerous.

557
00:43:17,040 --> 00:43:22,000
And so we are literally looking at problems where getting labels is not possible or is just

558
00:43:22,000 --> 00:43:23,000
too expensive.

559
00:43:23,000 --> 00:43:29,640
So we need to think about different ways to incorporate domain knowledge into machine learning

560
00:43:29,640 --> 00:43:30,640
systems.

561
00:43:30,640 --> 00:43:34,200
And this particular triple AI paper that you mentioned, we were looking at whether we

562
00:43:34,200 --> 00:43:41,600
can use a prior domain knowledge, like knowledge about the laws of physics to supervise object

563
00:43:41,600 --> 00:43:46,880
detectors in that case, supervise, convolutional neural networks and teach them how to recognize

564
00:43:46,880 --> 00:43:52,320
objects by providing sort of this high level description of the kind of things the network

565
00:43:52,320 --> 00:43:53,320
should be looking for.

566
00:43:53,320 --> 00:43:57,440
So even though we don't have precise labels saying, okay, here's the object that you should

567
00:43:57,440 --> 00:43:58,960
be looking for.

568
00:43:58,960 --> 00:44:02,640
One thing that we tried was to see whether it's possible to learn how to recognize these

569
00:44:02,640 --> 00:44:07,280
objects by providing a high level description, like something like a loose description of

570
00:44:07,280 --> 00:44:11,160
the dynamics of the kinematics of the object.

571
00:44:11,160 --> 00:44:18,000
And we showed in that paper that it's possible in some cases, we provide some proof of concept

572
00:44:18,000 --> 00:44:22,480
demonstration that it's possible for example to train a convolutional neural network to

573
00:44:22,480 --> 00:44:30,160
recognize objects moving, falling sort of through the air, just by providing some prior

574
00:44:30,160 --> 00:44:35,560
knowledge about gravity essentially just by saying, well, I know that if an object is falling

575
00:44:35,560 --> 00:44:42,240
and moving through the air, then there's gravity, and so the trajectory will form a parabola.

576
00:44:42,240 --> 00:44:47,440
Just by using this prior knowledge, it turns out it was sufficient to learn how to recognize

577
00:44:47,440 --> 00:44:50,160
objects moving in that video.

578
00:44:50,160 --> 00:44:55,520
And so to be a little bit more concrete in this paper, you use the example of projectile

579
00:44:55,520 --> 00:44:57,840
in particular a pillow.

580
00:44:57,840 --> 00:45:02,440
And from some of the images that you had in the paper, you can imagine a neural network

581
00:45:02,440 --> 00:45:07,760
getting confused between the pillow and the fluorescent lighting, and presumably the knowledge

582
00:45:07,760 --> 00:45:12,080
that you're giving it about the laws of motion, if you will, the physics of a projectile

583
00:45:12,080 --> 00:45:16,400
pillow will help the network figure out where the pillow is.

584
00:45:16,400 --> 00:45:17,400
Exactly.

585
00:45:17,400 --> 00:45:24,160
And then it strikes me that perhaps this is relatable to your research on crop yields.

586
00:45:24,160 --> 00:45:30,760
And for example, you may have knowledge about seasonality in the way, or if not crop

587
00:45:30,760 --> 00:45:37,240
yields the poverty piece, but you may have information about seasonality and how tree

588
00:45:37,240 --> 00:45:41,560
leaf colors change over time, or there's all kinds of things that we know about the

589
00:45:41,560 --> 00:45:47,160
physical world, and one would presume that the more we can incorporate that into our

590
00:45:47,160 --> 00:45:49,600
models, the smarter those models would be.

591
00:45:49,600 --> 00:45:50,600
Correct.

592
00:45:50,600 --> 00:45:57,760
And so how exactly do you, how do you incorporate that into models that an algebraic representation

593
00:45:57,760 --> 00:46:00,800
of some sort, or so, yeah.

594
00:46:00,800 --> 00:46:06,320
So in the triple algorithm, we were only looking at algebraic representation in the case

595
00:46:06,320 --> 00:46:09,600
of physics law, or using logical representation.

596
00:46:09,600 --> 00:46:14,600
We also had another example where we showed that if you know some, you have some prior knowledge

597
00:46:14,600 --> 00:46:20,440
that you can describe using logical forms, something like whenever object A appears in

598
00:46:20,440 --> 00:46:24,600
an image, then object B is also present in an image.

599
00:46:24,600 --> 00:46:31,200
Think this kind of relationship that can be fairly naturally captured using logic in terms

600
00:46:31,200 --> 00:46:37,040
of it's a fairly natural framework for you to model and to write down some prior knowledge

601
00:46:37,040 --> 00:46:38,520
of a particular domain.

602
00:46:38,520 --> 00:46:43,280
That's those are the two things that we that we explore in the triple AI paper.

603
00:46:43,280 --> 00:46:47,480
We are doing some work right now on using simulators.

604
00:46:47,480 --> 00:46:55,200
That's another fairly common way in which we can formulate prior knowledge about domain,

605
00:46:55,200 --> 00:46:59,760
especially in the physical sciences, we might have a rough simulator that gives us a sense

606
00:46:59,760 --> 00:47:03,720
of how a particular physical system behaves.

607
00:47:03,720 --> 00:47:07,440
And the question was whether some of the things we are exploring right now is to see how

608
00:47:07,440 --> 00:47:14,040
to incorporate a simulator and put it together with data on labeled data and see whether

609
00:47:14,040 --> 00:47:19,840
we can combine these things together and use the knowledge that is sort of inherently present

610
00:47:19,840 --> 00:47:24,920
in the simulator to provide supervision to say neural networks.

611
00:47:24,920 --> 00:47:31,440
One of the areas spending some time researching of latest industrial AI and how AI factors

612
00:47:31,440 --> 00:47:37,120
into control and optimization scenarios and robotics and manufacturing and things like

613
00:47:37,120 --> 00:47:38,120
that.

614
00:47:38,120 --> 00:47:42,720
And the use of simulators is a key importance in those areas.

615
00:47:42,720 --> 00:47:45,680
So it's interesting to see you applying that here as well.

616
00:47:45,680 --> 00:47:54,680
So are you are we at the point where you have a how generalizable is the an architecture

617
00:47:54,680 --> 00:48:02,000
that can incorporate these types of rules, meaning is there is the you know, a particular

618
00:48:02,000 --> 00:48:08,840
law of physics, you know, baked deeply into the model architecture or the training process

619
00:48:08,840 --> 00:48:15,440
or, you know, can you envision some kind of architecture or a training regime that you

620
00:48:15,440 --> 00:48:21,760
can feed a somewhat generic kind of rule or law engine that can bake the stuff in.

621
00:48:21,760 --> 00:48:23,160
Yeah, that's a great question.

622
00:48:23,160 --> 00:48:29,040
So at the moment, it's all very much specific to particular constraints and particular forms

623
00:48:29,040 --> 00:48:30,040
of domain knowledge.

624
00:48:30,040 --> 00:48:34,560
At the moment, basically, you have to invest a considerable effort into the engineering

625
00:48:34,560 --> 00:48:39,400
and the right objective function and figure out how to bake in the prior knowledge into

626
00:48:39,400 --> 00:48:40,400
the system.

627
00:48:40,400 --> 00:48:44,360
So it's a different kind of trade off where you're sort of you're still spending and seeing

628
00:48:44,360 --> 00:48:48,480
significant amount of time sort of providing supervision to the system.

629
00:48:48,480 --> 00:48:53,800
But the advantage is that it does not scale linearly in the number of in the size of your

630
00:48:53,800 --> 00:48:54,800
training data.

631
00:48:54,800 --> 00:48:55,800
Right.

632
00:48:55,800 --> 00:49:03,040
So it's an interesting trade off that might be might be advantageous in some situations.

633
00:49:03,040 --> 00:49:08,280
But the dream is to be as you said, sort of come up with a general language that we can

634
00:49:08,280 --> 00:49:13,560
use or a general system that will make it easy to incorporate prior knowledge into

635
00:49:13,560 --> 00:49:14,560
engineering systems.

636
00:49:14,560 --> 00:49:17,040
But we're not there at the moment.

637
00:49:17,040 --> 00:49:18,040
We don't have it.

638
00:49:18,040 --> 00:49:23,240
But I think that that's what we need in order to make sure that people can use the systems

639
00:49:23,240 --> 00:49:27,280
and they can really dramatically reduce the amount of training data that they need to

640
00:49:27,280 --> 00:49:28,600
solve their tasks.

641
00:49:28,600 --> 00:49:34,040
Maybe we're not going to be able to get away with the training data completely, like we

642
00:49:34,040 --> 00:49:38,200
showed in the trip or I paper where we didn't use any label at all.

643
00:49:38,200 --> 00:49:44,040
But maybe and the hope is that it would work like for us for humans where maybe a handful

644
00:49:44,040 --> 00:49:50,480
of examples is enough to learn how to solve an interesting task because and maybe just

645
00:49:50,480 --> 00:49:56,040
a high level description plus a few examples is enough to solve the problem as opposed

646
00:49:56,040 --> 00:50:03,560
to millions of labels, which which is not how we how we learn, I think, right.

647
00:50:03,560 --> 00:50:10,960
So any thoughts on where you see this all going or how you see it evolving over time or

648
00:50:10,960 --> 00:50:14,400
even simply what you're most excited about right now?

649
00:50:14,400 --> 00:50:20,160
Yeah, that's definitely something I'm interested in trying to understand how to put in how

650
00:50:20,160 --> 00:50:26,800
to put in prior knowledge, how to combine it with labels in a most effective way, also

651
00:50:26,800 --> 00:50:31,400
how to do, I mean, a super buzz learning, that's another thing we're playing with this

652
00:50:31,400 --> 00:50:37,600
day is how do you discover structures from data and how far we can push this thing and

653
00:50:37,600 --> 00:50:43,720
really how many, how much, why, how much can we reduce the need for training data and

654
00:50:43,720 --> 00:50:47,960
these are all problems that I'm very excited about thinking about what's the right way

655
00:50:47,960 --> 00:50:52,280
to represent knowledge and what's the right way to put the knowledge into the machine learning

656
00:50:52,280 --> 00:50:57,440
systems and finally how to reverse the process like here we showed how we can put in some

657
00:50:57,440 --> 00:51:00,560
physics and we can make the machine learning system better.

658
00:51:00,560 --> 00:51:06,520
But ideally, I would like to then invert this and try to go from then try to still physics

659
00:51:06,520 --> 00:51:09,800
and try to still knowledge from the from the raw data.

660
00:51:09,800 --> 00:51:14,800
I want my machine learning system to come up with new hypothesis and one is to discover

661
00:51:14,800 --> 00:51:19,760
where have it be just with the end of it is and I think that's what's really exciting

662
00:51:19,760 --> 00:51:24,280
I think we're we're we're so far but I think that would be pretty amazing because then

663
00:51:24,280 --> 00:51:28,640
we can really think about using machine learning in the most physical sciences that's a

664
00:51:28,640 --> 00:51:34,440
space in which we haven't seen as much as we not not as much as in sort of other kind

665
00:51:34,440 --> 00:51:39,120
of application domains I think so I think but there's a lot of potential for using AI

666
00:51:39,120 --> 00:51:42,680
machine learning in the physical sciences because they're doing more and more of high

667
00:51:42,680 --> 00:51:50,080
throughput experiments collecting massive amounts of data and to human time humans are

668
00:51:50,080 --> 00:51:53,400
really the bottleneck trying to analyze this data trying to figure out what is going

669
00:51:53,400 --> 00:51:58,360
on figure trends understand what is interesting what it's not and if we had a way to to put

670
00:51:58,360 --> 00:52:05,320
in that machine learning and any AI systems to help and then sort of make the process easier

671
00:52:05,320 --> 00:52:09,760
trying to automate it a little bit or as much as possible I think I think the benefits

672
00:52:09,760 --> 00:52:11,520
could be could be really huge.

673
00:52:11,520 --> 00:52:14,280
Yeah absolutely absolutely.

674
00:52:14,280 --> 00:52:20,840
So we talked about a bunch of your work in particular several papers if someone wanted

675
00:52:20,840 --> 00:52:27,000
to you know if it's possible to do this kind of get up to speed on your research and

676
00:52:27,000 --> 00:52:32,160
the you know the kinds of things we've discussed are there you know one two or three papers

677
00:52:32,160 --> 00:52:36,480
that would be the kind of key things to you know help them understand what you're up

678
00:52:36,480 --> 00:52:37,480
to.

679
00:52:37,480 --> 00:52:42,040
So if you want to learn about the physics and domain knowledge just the triple AI paper

680
00:52:42,040 --> 00:52:47,520
called supervised supervising neural network with physics and other domain knowledge for

681
00:52:47,520 --> 00:52:53,760
the sustainability applications so there are the papers you mentioned there's the science

682
00:52:53,760 --> 00:52:58,440
paper and that there's the deep Gaussian process for property prediction which is also

683
00:52:58,440 --> 00:53:02,560
triple AI showing discussing how to use the Gaussian processes and the missionality

684
00:53:02,560 --> 00:53:06,040
reductions in to deal with remote sensing data.

685
00:53:06,040 --> 00:53:08,440
So those are the right places to start.

686
00:53:08,440 --> 00:53:15,240
And just to close out if the what's the someone wants to kind of learn more or get in touch

687
00:53:15,240 --> 00:53:20,000
or kind of follow you on a social media if you're out there any particular coordinates

688
00:53:20,000 --> 00:53:21,480
you would point folks to.

689
00:53:21,480 --> 00:53:26,400
Yeah come to my website just to Google my name it's probably the first thing that comes

690
00:53:26,400 --> 00:53:30,840
up with Google it's you can see all my papers or visit my research group website then

691
00:53:30,840 --> 00:53:32,480
you can see all the latest stuff.

692
00:53:32,480 --> 00:53:37,080
Well we'll link directly to it in the show notes so folks won't need to Google it.

693
00:53:37,080 --> 00:53:41,840
But this was a great conversation I really enjoyed talking to you about the work and

694
00:53:41,840 --> 00:53:46,760
I'm super excited about the work you're doing the papers are really interesting and I learned

695
00:53:46,760 --> 00:53:47,760
a ton.

696
00:53:47,760 --> 00:53:48,760
Thanks so much Stefano.

697
00:53:48,760 --> 00:53:49,760
Thanks for having me.

698
00:53:49,760 --> 00:53:50,760
It was a lot of fun too.

699
00:53:50,760 --> 00:53:51,760
Bye bye.

700
00:53:51,760 --> 00:53:52,760
Bye bye.

701
00:53:52,760 --> 00:54:01,280
Alright everyone that's our show for today.

702
00:54:01,280 --> 00:54:05,760
Once again thanks so much for listening and for your continued support.

703
00:54:05,760 --> 00:54:10,200
Don't forget to share your favorite quote from this show to get one of our new stickers.

704
00:54:10,200 --> 00:54:15,160
You can share them via the show notes page via Twitter via our Facebook page or via a

705
00:54:15,160 --> 00:54:18,000
comment on YouTube or SoundCloud.

706
00:54:18,000 --> 00:54:22,680
Please use the hashtag Twimlai on Twitter.

707
00:54:22,680 --> 00:54:28,840
The notes for this show will be up on twimlai.com slash talk slash 15 where you'll find links

708
00:54:28,840 --> 00:54:32,920
to Stefano and the various resources mentioned in the show.

709
00:54:32,920 --> 00:54:59,680
Thanks so much for listening and catch you next time.

