1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:31,840
I'm your host Sam Charrington.

4
00:00:31,840 --> 00:00:37,560
In this episode we're joined by Garrett Hoffman, Director of Data Science at Stocktwitz.

5
00:00:37,560 --> 00:00:41,640
Garrett and I caught up at last month's Stratid Data Conference where he presented a tutorial

6
00:00:41,640 --> 00:00:47,800
on deep learning methods for NLP with emphasis on financial services.

7
00:00:47,800 --> 00:00:51,760
Garrett is a social network for the investing community which has its root in the use of

8
00:00:51,760 --> 00:00:54,160
the cash tag on Twitter.

9
00:00:54,160 --> 00:00:59,320
In our conversation we discuss applications such as Stocktwitz own use of social sentiment

10
00:00:59,320 --> 00:01:04,560
graphs built on multi-layer LSTM networks to gauge community sentiment about certain

11
00:01:04,560 --> 00:01:09,880
stocks in real time as well as the more general use of natural language processing for generating

12
00:01:09,880 --> 00:01:12,280
training ideas.

13
00:01:12,280 --> 00:01:15,920
Before we dive into the conversation I'd like to send a huge thanks to our friends at

14
00:01:15,920 --> 00:01:19,280
IBM for their sponsorship of this episode.

15
00:01:19,280 --> 00:01:24,520
Interested in exploring code patterns leveraging multiple technologies including ML and AI,

16
00:01:24,520 --> 00:01:26,520
then check out IBM Developer.

17
00:01:26,520 --> 00:01:32,040
With more than 100 open source programs, a library of knowledge resources, developer advocates

18
00:01:32,040 --> 00:01:37,880
ready to help and a global community of developers, what in the world will you create?

19
00:01:37,880 --> 00:01:46,440
Just dive in at IBM.biz slash ML AI podcast and be sure to let them know that Twimmel sent

20
00:01:46,440 --> 00:01:51,200
you and now on to the show.

21
00:01:51,200 --> 00:01:57,560
Alright everyone I am here in New York City at the Stratid Conference and I am with Garrett

22
00:01:57,560 --> 00:01:58,560
Hoffman.

23
00:01:58,560 --> 00:02:01,840
Garrett is the director of Data Science at Stocktwitz.

24
00:02:01,840 --> 00:02:04,280
Garrett, welcome to this week in machine learning and AI.

25
00:02:04,280 --> 00:02:05,280
Thanks for having me Sam.

26
00:02:05,280 --> 00:02:07,160
It's fantastic to be here.

27
00:02:07,160 --> 00:02:08,160
Awesome.

28
00:02:08,160 --> 00:02:12,240
I am always super excited when someone, I'm interviewing someone and they say they listen

29
00:02:12,240 --> 00:02:17,000
to the show and enjoy the show so thanks for offering that.

30
00:02:17,000 --> 00:02:23,680
Why don't we get started by having you tell us for those who aren't familiar with Stocktwitz,

31
00:02:23,680 --> 00:02:25,400
what's Stocktwitz all about?

32
00:02:25,400 --> 00:02:26,400
Yeah I'd love to.

33
00:02:26,400 --> 00:02:33,000
So Stocktwitz is a FinTech financial technology company we're based here in New York City

34
00:02:33,000 --> 00:02:38,920
and our core product is the Stocktwitz.com or the Stocktwitz mobile app which is a social

35
00:02:38,920 --> 00:02:42,280
network for the finance community.

36
00:02:42,280 --> 00:02:48,760
So kind of like a LinkedIn meets Twitter specifically for traders and investors.

37
00:02:48,760 --> 00:02:53,480
So people who are interested in the market can come on, connect with each other, share

38
00:02:53,480 --> 00:03:00,560
ideas, learn from each other and most importantly they can enjoy participating in the markets

39
00:03:00,560 --> 00:03:06,160
and investing even more by sharing in that experience together.

40
00:03:06,160 --> 00:03:13,080
Our core user is the millennial investor who we know is digitally native, increasingly

41
00:03:13,080 --> 00:03:14,400
social.

42
00:03:14,400 --> 00:03:20,520
This is a group that really loves social engagement around the decisions that they're making and

43
00:03:20,520 --> 00:03:26,440
we've seen companies like Amazon facilitate this and eat commerce when someone's looking

44
00:03:26,440 --> 00:03:30,760
to buy something through going through reviews, talking with their friends about kind of

45
00:03:30,760 --> 00:03:36,600
the stuff that they're purchasing and as a company we really see ourselves as a platform

46
00:03:36,600 --> 00:03:41,280
where people can come to engage in this type of social interaction around the decisions

47
00:03:41,280 --> 00:03:45,080
that they're making in investing and financial services.

48
00:03:45,080 --> 00:03:51,160
So right now conversation centers mostly around individual stocks but our new product

49
00:03:51,160 --> 00:03:56,760
that we actually just launched called rooms allows the community to start to self organize

50
00:03:56,760 --> 00:04:01,760
around specific topics that they're interested in and that's really exciting for us because

51
00:04:01,760 --> 00:04:07,240
it allows people to dive deeper in details so maybe like they want a room just to talk

52
00:04:07,240 --> 00:04:12,760
about Apple products and what that might mean for the stock but it actually also helps

53
00:04:12,760 --> 00:04:18,000
conversation grow bigger and more general maybe people want to talk about other financial

54
00:04:18,000 --> 00:04:23,880
services like Robo advisors like general like insurance stuff like that.

55
00:04:23,880 --> 00:04:30,880
So it's really giving the community a platform to talk more about financial services in

56
00:04:30,880 --> 00:04:34,280
general or specific topics that they're interested in.

57
00:04:34,280 --> 00:04:40,040
And I've got this impression that Stock Twits grew out of the stock tag on Twitter.

58
00:04:40,040 --> 00:04:41,560
Is that the case or?

59
00:04:41,560 --> 00:04:49,400
Yeah so our founder Howard lives in back I think it was 2009 invented the cash tag and

60
00:04:49,400 --> 00:04:56,800
so this was a dollar sign in front of a ticker symbol on Twitter and we were actually partnered

61
00:04:56,800 --> 00:05:04,680
with Twitter using the Twitter API to kind of search and filter Twitter for tweets specifically

62
00:05:04,680 --> 00:05:06,080
that had a cash tag.

63
00:05:06,080 --> 00:05:14,000
So it was kind of a filter on the Twitter API a few years later we actually left the

64
00:05:14,000 --> 00:05:19,680
Twitter API and became a standalone platform so it was born through the cash tag.

65
00:05:19,680 --> 00:05:26,600
The cash tag is our main mechanism for index and conversations to specific stocks but

66
00:05:26,600 --> 00:05:31,800
Stock Twits today it's its own standalone platform but it is that micro blogging real

67
00:05:31,800 --> 00:05:37,400
time Twitter like form out of discussion and what's your background?

68
00:05:37,400 --> 00:05:45,920
Yeah so I in undergrad I study in mathematics and finance I got exposed to a lot of like

69
00:05:45,920 --> 00:05:55,880
the core ML mathy concepts matrix factorization eigenvectors optimization statistical learning

70
00:05:55,880 --> 00:06:02,960
but I'd say my first introduction to kind of machine learning as like a field that was

71
00:06:02,960 --> 00:06:07,720
more than just like the sum of these individual parts that I was learning was when I started

72
00:06:07,720 --> 00:06:13,280
researching topics for my undergraduate thesis and came across neural networks.

73
00:06:13,280 --> 00:06:19,120
I really wanted to study something that was math as used in the finance industry to kind

74
00:06:19,120 --> 00:06:25,840
of tie both my field of study together and I saw that people were starting to like resurface

75
00:06:25,840 --> 00:06:32,480
neural networks to do forecasting on stock prices and I actually decided to pass on that

76
00:06:32,480 --> 00:06:33,480
topic.

77
00:06:33,480 --> 00:06:36,920
I was like oh this was done in the 80s it's kind of been explored already I couldn't

78
00:06:36,920 --> 00:06:42,560
have been more wrong about how prevalent it would be a few years later in fact I was

79
00:06:42,560 --> 00:06:48,960
more interested at the time in kind of probability theory stochastic calculus random processes

80
00:06:48,960 --> 00:06:57,120
um so I actually this was 2011 when I finished undergrad and at the time the default job

81
00:06:57,120 --> 00:07:02,640
for people who studied math and didn't really want to teach was an actuary so I got a job

82
00:07:02,640 --> 00:07:08,360
as an actuary at Xerox part of a smaller business group called buck consultants that they

83
00:07:08,360 --> 00:07:13,360
owned a lot of people don't know that Xerox played in kind of the consulting playground

84
00:07:13,360 --> 00:07:20,720
but I did actual consulting around benefit plans so valuing retirement plans valuing

85
00:07:20,720 --> 00:07:26,960
health plans executive stock option plans kind of working on the investment strategy around

86
00:07:26,960 --> 00:07:34,560
the funds that pay those types of benefits and being an actuary is a phenomenal profession

87
00:07:34,560 --> 00:07:42,160
but after a year or so I kind of realized it wasn't for me um I I wanted to have more of

88
00:07:42,160 --> 00:07:47,520
a tangible impact and be able to kind of like see the impact of the models that I was creating

89
00:07:47,520 --> 00:07:53,360
and of the analysis that I was doing so I I really liked my company and I liked the space I'm

90
00:07:53,360 --> 00:07:58,320
I'm very passionate about financial wellness and financial literacy and helping people

91
00:07:59,040 --> 00:08:03,360
get gain the knowledge and tools that they need to kind of be independent and and

92
00:08:03,360 --> 00:08:09,760
wait through a very complex world on their own so I really became interested in how can we help

93
00:08:09,760 --> 00:08:17,200
our clients help their employees make better decisions around their benefits so this was more

94
00:08:17,200 --> 00:08:24,000
of like a behavioral psychology behavioral economics problem and I think was my first cross in

95
00:08:24,000 --> 00:08:29,440
my professional life of kind of leaving actual the world of actuarial problems and the the types

96
00:08:29,440 --> 00:08:35,200
of stuff that actuaries normally think about to enter in kind of a data science problem a problem

97
00:08:35,200 --> 00:08:41,440
that could be um solved using machine learning and data science so I actually spent the next few

98
00:08:41,440 --> 00:08:47,040
years still at that company doing kind of like half actuarial stuff half product development for

99
00:08:47,040 --> 00:08:53,760
these new solutions um they actually started to take off we got a few client projects Xerox actually

100
00:08:54,400 --> 00:09:01,200
let me take a sabbatical they sent me to uh metastata science boot camp in New York City to kind of

101
00:09:01,200 --> 00:09:07,360
true up my knowledge fill in the gaps more on the product and delivery side like how are solutions

102
00:09:07,360 --> 00:09:13,040
in data science and machine learning scaled and delivered just because as an org we were kind of

103
00:09:13,040 --> 00:09:19,360
waiting through new territory no one really had that knowledge of okay once we we've done the modeling

104
00:09:19,360 --> 00:09:23,760
and done the technical stuff like what are clients who are looking for these solutions actually

105
00:09:23,760 --> 00:09:30,320
looking for what when they ask someone to help them with it um so stuff like productizing data

106
00:09:30,320 --> 00:09:37,200
through APIs you know building applications with data science stuff like that um ended up going

107
00:09:37,200 --> 00:09:44,000
back to Xerox for about six more months and realized that um I really wanted to go somewhere where

108
00:09:45,840 --> 00:09:54,320
where I could really shape um like a consumer facing product I wanted to be somewhere a little

109
00:09:54,320 --> 00:10:01,600
more closer to the technology industry the actual at the actuarial industry is um great lagging maybe

110
00:10:01,600 --> 00:10:07,440
a little bit behind in terms of like using cutting edge technology um so at that time I started

111
00:10:07,440 --> 00:10:13,040
looking for new opportunities I ended up at stock twitch it was kind of a great marriage for us where

112
00:10:13,760 --> 00:10:20,240
I'd have a treasure trove of data being close to like being centered around a social a social

113
00:10:20,240 --> 00:10:26,400
network and still kind of at an org where their goal was to help people understand this really complex

114
00:10:26,400 --> 00:10:35,120
world of finance and so you did a tutorial actually uh here at Strata on the use of deep learning

115
00:10:35,120 --> 00:10:40,560
methods for natural language processing with a particular emphasis on financial services and

116
00:10:41,200 --> 00:10:47,280
some of the things you're doing at stock twitch what are some of the ways that NLP that you use

117
00:10:47,280 --> 00:10:54,240
NLP at stock twitch yeah so um our core data that we have available to us at stock twitch is of course

118
00:10:54,240 --> 00:11:00,960
raw messages that people are writing ideas that they're generating um so we're working a lot with

119
00:11:00,960 --> 00:11:10,640
just raw text data and as a data scientist at stock twitch I see the core mission of our team is to

120
00:11:10,640 --> 00:11:20,320
really improve the user experience and improve the product through data and so for us and a lot

121
00:11:20,320 --> 00:11:26,080
of how I see machine learning like what what machine learning aims to do is to actually kind

122
00:11:26,080 --> 00:11:32,080
of like shrink the world and so stock twitch there's real-time information flowing by really really

123
00:11:32,080 --> 00:11:40,800
quickly um you know things change super quickly it's a real-time stream so to to the extent that we

124
00:11:40,800 --> 00:11:46,960
can use data to build data products to kind of help people discover like snapshots of what's

125
00:11:46,960 --> 00:11:51,920
going on right now help them really find stocks that they're interested help them find people that

126
00:11:51,920 --> 00:11:58,960
were they're interested in um that's really how we're using data so one of our biggest uses for NLP

127
00:11:58,960 --> 00:12:05,440
is actually our social sentiment model so we like to summarize the stream of what's going on with

128
00:12:06,160 --> 00:12:12,720
sentiment graphs so we try to keep real-time updates of how our community feels about a certain

129
00:12:12,720 --> 00:12:20,000
stock and we're doing NLP modeling to extract financial sentiment from all the text data that's

130
00:12:20,000 --> 00:12:26,480
coming in and then aggregating that at its individual stock level to kind of see how that's moving

131
00:12:26,480 --> 00:12:32,640
and see how that's changing over time so that lets people come in and see maybe they've done some

132
00:12:32,640 --> 00:12:38,480
research off platform they want to just check out what people are saying on stock twitch even before

133
00:12:38,480 --> 00:12:44,880
waiting through you know thousands of of messages in a real-time stream they can have this nice

134
00:12:44,880 --> 00:12:50,960
little little snapshot of you know how does the stock twitch community feel are they overly bullish

135
00:12:50,960 --> 00:12:57,760
or they more bullish than they typically are has there been a drastic like riser or fall in sentiment

136
00:12:57,760 --> 00:13:03,440
in the last few days um stuff like that so your your talk was on deeplining methods what are some

137
00:13:03,440 --> 00:13:08,880
of the methods that you apply to to solving those types of problems so when we think about um

138
00:13:09,600 --> 00:13:17,680
sentiment we're typically in the realm of RNN so we're using multi-layered LSTM networks to

139
00:13:17,680 --> 00:13:23,920
um just extract a sentiment a bullish neutral and bearish signal and we're fortunate enough

140
00:13:24,480 --> 00:13:33,440
that we have um users have the ability to tag their messages with sentiment when they post it so

141
00:13:33,440 --> 00:13:40,240
we've been able to inherently gather label training data through general usage of the app

142
00:13:41,280 --> 00:13:47,120
and through people tagging their messages um one of the reasons we go on to model sentiment

143
00:13:47,120 --> 00:13:55,440
further is only about 20 to 25% of messages are tagged so by by building a model around sentiment

144
00:13:55,440 --> 00:14:00,960
we can expand that coverage to a hundred percent of of the volume instead of just this very small

145
00:14:00,960 --> 00:14:08,640
subset of tag messages um we typically have to supplement um our tag data through manual curation

146
00:14:08,640 --> 00:14:17,520
just kind of validating that those tags exist so we use LSTM networks um it's really a great method

147
00:14:17,520 --> 00:14:26,480
for capturing those dependencies across multiple across as it changes capturing dependencies of like

148
00:14:26,480 --> 00:14:32,160
the language and the relationship through text through a nice sequential model like like RNNs

149
00:14:32,160 --> 00:14:37,920
and LSTMs help us capture more nuance in the language so sometimes you get a really straightforward

150
00:14:37,920 --> 00:14:45,440
message like I am bullish um maybe yeah and so that's that's really obvious and then sometimes it

151
00:14:45,440 --> 00:14:52,240
might not be so straightforward so so an example of that might be someone saying like oh Tesla

152
00:14:52,240 --> 00:14:59,280
here looks really really high right now um I don't think I'm a buyer if it dropped maybe down to

153
00:14:59,280 --> 00:15:05,600
like the 200 range then I would definitely get in so if I'm using a method or a model to classify

154
00:15:05,600 --> 00:15:12,480
that that statement um typically you know you're making classifications at the end of your sequence

155
00:15:12,480 --> 00:15:17,920
the the end of that sentence makes it seem like that person might not that they are bullish that

156
00:15:17,920 --> 00:15:24,720
they're going to be a buyer but LSTMs allow us to capture kind of the the um the state of that

157
00:15:24,720 --> 00:15:31,600
sentence to know you know at the start of this sentence this person was pretty bearish um and so

158
00:15:31,600 --> 00:15:38,320
LSTMs allow us to cat to retain that information throughout the entire sequence that we're trying

159
00:15:38,320 --> 00:15:44,400
to classify what challenges do you run into when you're trying to develop these these models based

160
00:15:44,400 --> 00:15:53,920
on LSTMs yeah so I'd say our biggest challenge is probably the domain specific nature of the language

161
00:15:53,920 --> 00:16:01,440
so like bear in bowl in a generic setting of of language processing or just animals um like

162
00:16:02,000 --> 00:16:08,000
cup and handle is a very is like a stock pattern so so the the world of finance has a ton of

163
00:16:08,000 --> 00:16:16,240
vocabulary that is very neat to um talking about finance itself so this is something we actually

164
00:16:16,240 --> 00:16:22,480
talk about at the talk uh in the training is this dealing with this domain specific language

165
00:16:22,480 --> 00:16:27,920
and tackling it through leveraging what we can from the open source community so there's a

166
00:16:27,920 --> 00:16:32,720
ton of pre-trained word vectors that exist out there but those might not get the job done when

167
00:16:32,720 --> 00:16:40,480
you have a domain specific language so we actually talked about the idea of starting with pre-trained

168
00:16:41,200 --> 00:16:47,280
word vectors but building on those through training additional word to vex on your

169
00:16:47,280 --> 00:16:53,520
corpus that's specific to your domain so maybe instead of seating like if you're going to train a

170
00:16:53,520 --> 00:16:59,760
word to vex model to get you know efficient representations of your language and your vocabulary

171
00:17:00,800 --> 00:17:06,000
instead of seating randomly you can see it with a pre-trained word vector maybe out of google

172
00:17:06,000 --> 00:17:13,360
news and then train over your corpus so that it can kind of start to learn um language that may

173
00:17:13,360 --> 00:17:20,240
exist in a pre-trained vector but can adjust that to specifically model your language inherently

174
00:17:20,240 --> 00:17:26,400
and you get a nice platform to jump off of because google's done a lot of like work to train

175
00:17:26,400 --> 00:17:34,000
vectors on billions and billions of news articles of the various uh pre-trained word vectors out

176
00:17:34,000 --> 00:17:40,240
there glove and google news and others uh is google news the one that closely most closely matched

177
00:17:40,240 --> 00:17:48,160
to your use case so we actually um like starting with the twitter glove vectors mostly because

178
00:17:48,160 --> 00:17:54,640
to capture like the syntactical nuances of how people talk in short form text over social media

179
00:17:54,640 --> 00:18:00,880
so we found we found that um the the twitter data glove was a good launching point and it's

180
00:18:00,880 --> 00:18:08,000
actually you wouldn't we saw a deep like pretty decent result just using those vectors alone

181
00:18:08,000 --> 00:18:13,920
so one of the takeaways um and something that i'd push to anyone who um um um talking to this stuff

182
00:18:13,920 --> 00:18:21,360
about it is there are people who are a lot smarter than me who have done a lot of legwork and um

183
00:18:21,360 --> 00:18:26,080
like us as practitioners are fortunate enough that they open that work for everyone else to use

184
00:18:26,080 --> 00:18:32,720
so even though stuff may not seem like it's applicable don't let that stand in your way to just

185
00:18:32,720 --> 00:18:39,680
get out there and getting started um training custom word vectors is no small task um it requires

186
00:18:39,680 --> 00:18:48,960
a ton of data it requires potentially days or weeks of training and that's the result of that

187
00:18:48,960 --> 00:18:53,840
you're not even positive if it's gonna make that big of a difference in your downstream modeling

188
00:18:53,840 --> 00:19:01,040
task so something we i like to stress is wherever you can start with like like stand on the shoulders

189
00:19:01,040 --> 00:19:08,400
of these giants who who did this work before us um and try to kind of start with that see where

190
00:19:08,400 --> 00:19:15,680
it gets you assess the situation and go on from there is there a method a method to do like composite

191
00:19:15,680 --> 00:19:21,680
training with multiple pre-trained word vectors like is there a way to combine glove and google news

192
00:19:23,440 --> 00:19:27,760
i haven't done anything like that i would imagine there could be some

193
00:19:27,760 --> 00:19:36,480
like meta modeling or on sampling on top of it where i this this may or may not exist there

194
00:19:36,480 --> 00:19:42,560
might be some research on top of this but i couldn't see why you couldn't maybe instead of

195
00:19:43,120 --> 00:19:48,400
you know in a traditional word-to-vec model that you're starting from scratch your input is a

196
00:19:48,400 --> 00:19:54,800
one-hot encoded vector of a word your output is one-hot encoded vectors of the context of that word

197
00:19:54,800 --> 00:20:03,200
um i could see maybe some method where the input is some like concatenation of like of existing

198
00:20:03,200 --> 00:20:09,440
word vectors and your kind of hidden layer is still learning like how to combine the best things

199
00:20:09,440 --> 00:20:14,480
from those existing word vectors to learn the context because at the end of the day what word to

200
00:20:14,480 --> 00:20:22,240
that what boils down to is we want to learn some efficient representation of words such that our

201
00:20:22,240 --> 00:20:28,640
representation reflects semantic and syntactic and contextual meaning across multiple words so

202
00:20:28,640 --> 00:20:35,920
i always like to say that the philosophy of word-to-vec is a quote from uh JR Firth who's a famous

203
00:20:35,920 --> 00:20:42,640
english linguist who said uh you shall judge a word by the company it keeps so that's that's

204
00:20:42,640 --> 00:20:48,880
basically the philosophy of word-to-vec is we just want to ultimately end up with representations

205
00:20:48,880 --> 00:20:56,720
that um kind of can be shared across syntactical meaning so if i have the word good and i have the

206
00:20:56,720 --> 00:21:04,080
word great i should have a representation of that word such that my LSTM model can leverage the

207
00:21:04,080 --> 00:21:09,040
fact that those words are similar to make the predictions that it needs to make so no matter

208
00:21:09,040 --> 00:21:14,720
what your input is that hidden layer by nature of the way you construct that that prediction test

209
00:21:14,720 --> 00:21:20,800
of predicting context it's going to force words that show up in similar context to have similar

210
00:21:20,800 --> 00:21:26,080
representations so i'd imagine if you start with pre-trained word vectors instead of one hot and

211
00:21:26,080 --> 00:21:31,680
coated it might be able to kind of pick out the best stuff even for your specific use case so

212
00:21:31,680 --> 00:21:36,560
that that could be a good approach maybe maybe we'll go back and i'll put that on our backlog to

213
00:21:36,560 --> 00:21:42,480
to experiment with you mentioned that uh you use specifically multi-layer LSTM what does the

214
00:21:42,480 --> 00:21:49,200
multi-layer refer to there so the multi-layer just stacks multiple LSTM layers on top of each

215
00:21:49,200 --> 00:21:56,480
other so something i stress in this training and and i think anyone who's kind of learning about

216
00:21:56,480 --> 00:22:02,720
LSTMs is there's a lot of things called like layers and like a lot of dimensions so like

217
00:22:02,720 --> 00:22:10,240
so like you have an LSTM cell with a hidden layer and then you might have multiple LSTM layers

218
00:22:10,240 --> 00:22:15,120
and then within each cell of an LSTM there's kind of like four layers that are doing their

219
00:22:15,120 --> 00:22:20,880
things to maintain the state and retain information from the past sequence so i try to when i'm

220
00:22:20,880 --> 00:22:26,000
doing this training make it super approachable like kind of make sure that people are understanding

221
00:22:26,000 --> 00:22:33,200
what that distinction is and so a hidden layer is just like some vector that lives inside the LSTM cell

222
00:22:33,200 --> 00:22:41,520
the four like feed forward layers in an LSTM cell are just kind of moving that state through

223
00:22:41,520 --> 00:22:48,480
different gates and through activation functions and when i say multi-layered network so now we're

224
00:22:48,480 --> 00:22:54,400
at a network level we're outside just a cell of an LSTM we're really talking about stacking two

225
00:22:54,400 --> 00:23:01,360
whole LSTM layers on top of each other so if you think of like a graph pointing upwards like you'd

226
00:23:01,360 --> 00:23:07,120
start with your embedding look up so you'd input your word at any time the first layer would be

227
00:23:07,120 --> 00:23:13,760
your embedding look up that embedding would get passed up to the first LSTM layer it would do its

228
00:23:13,760 --> 00:23:21,120
thing part of that is it would output the output from that LSTM layer then goes as the input of a

229
00:23:21,120 --> 00:23:28,480
second LSTM layer and then that LSTM layer does a thing then you take that last final state at the

230
00:23:28,480 --> 00:23:33,760
end of the sequence pass that up to your fully connected layer and do kind of your softmax

231
00:23:33,760 --> 00:23:39,040
prediction or your sigmoid prediction depending on how many levels you have so when when someone's

232
00:23:39,040 --> 00:23:46,960
referring to multi-layered LSTM network they're really referring to two steps of LSTM the first step

233
00:23:46,960 --> 00:23:52,880
where your input is actually the word vector associated with each word and the second layer is

234
00:23:52,880 --> 00:24:00,640
actually the LSTM output at that time being passed as the input to the next LSTM layer and how do

235
00:24:00,640 --> 00:24:05,840
you know when you need to do that what's the intuition for what these different layers are doing

236
00:24:05,840 --> 00:24:13,840
yeah so I'd say a lot of this is learned through observing what's happening cross validation

237
00:24:13,840 --> 00:24:23,520
performance on a validation set I do think there is this understanding of like the complexity

238
00:24:23,520 --> 00:24:30,800
and the nuance of the the text that you're working with basically all in LSTM is doing is it's

239
00:24:30,800 --> 00:24:36,800
trying to summer like trying to learn a state of your sentence that kind of summarizes all of

240
00:24:36,800 --> 00:24:42,720
this information and I know the word state can be so abstract so that I try to also stress like what

241
00:24:42,720 --> 00:24:50,400
that means when we say state basically we're trying to capture all of the semantic and contextual

242
00:24:50,400 --> 00:24:59,520
nuance of a sentence in like a 128-dimensional or 256-dimensional vector so your first LSTM

243
00:24:59,520 --> 00:25:05,600
network is going to learn a state such that you know maybe one dimension of that state refers to

244
00:25:05,600 --> 00:25:13,040
it was this sentence negated at any time another dimension or a linear combination of dimensions might

245
00:25:13,040 --> 00:25:18,720
say is the sentiment the last sentiment I saw bullish or bearish and then that state can kind of

246
00:25:18,720 --> 00:25:24,720
be combined and it's like okay like I saw bearish sentiment but I saw a negation so now I actually

247
00:25:24,720 --> 00:25:32,480
know to predict that this is something bullish and so stacking layers on top just continual like

248
00:25:32,480 --> 00:25:39,200
they they allow you to do more linear transformations on that state to try to learn a richer representation

249
00:25:39,920 --> 00:25:46,000
at the end of the day what matters is that your prediction test is as accurate as you need it to be

250
00:25:46,720 --> 00:25:53,840
so we're not going to you know pull out our LSTM states and examine them and be like okay like

251
00:25:53,840 --> 00:26:03,200
I can see everything I want to be represented so a lot of this comes down to cross like just like

252
00:26:03,200 --> 00:26:08,560
validation accuracy observing these things through training deep learning can be really tough

253
00:26:08,560 --> 00:26:14,800
to do this parameter tuning if you're a small company and you don't have a ton of GPU resources

254
00:26:14,800 --> 00:26:20,560
available to you these things can take a long time to train to be effective and some people can't

255
00:26:20,560 --> 00:26:27,840
just spin up like 10 concurrent GPUs and monitor all this stuff in as it's running so tensor board

256
00:26:27,840 --> 00:26:34,080
is is a great tool that we try to leverage where you can monitor something as it's training and if

257
00:26:34,080 --> 00:26:40,720
you can see like oh our law stopped going down you know let's cancel this and try something else

258
00:26:41,440 --> 00:26:45,760
so you can kind of see the model learning in real time you can benchmark it against like your

259
00:26:45,760 --> 00:26:50,240
current best model and if it's not on track to beat that you're saying okay like let's cut this

260
00:26:50,240 --> 00:26:58,560
training short try something new again I'd always recommend to start simpler maybe start with one

261
00:26:58,560 --> 00:27:04,080
layer get a baseline model if you need to tune that better start adding in more and more layers

262
00:27:04,080 --> 00:27:08,640
I would treat that architecture like you would treat any other hyper parameter that you're you're

263
00:27:08,640 --> 00:27:18,480
trying to tune and so the the the layers aren't differentiated anyway well of course there are

264
00:27:18,480 --> 00:27:23,840
their hyper parameters but other than that they're not you know fundamentally different they're

265
00:27:23,840 --> 00:27:28,480
just you know multiple LSTM layers stacked on one another fit or feeding into one another

266
00:27:29,360 --> 00:27:34,800
and like you said you treat it as a hyper parameter try adding another one how many what's the

267
00:27:34,800 --> 00:27:40,560
most number of stacked LSTM layers you've seen for what we do we've probably never

268
00:27:40,560 --> 00:27:46,640
explored anything more than three I'm not sure if other existing research out there like people

269
00:27:46,640 --> 00:27:52,480
using LSTMs for more complicated learning tests might be stacking on time of each other um

270
00:27:53,600 --> 00:28:00,160
bi-directional LSTMs is something else that we've explored and what we've found is actually

271
00:28:00,160 --> 00:28:05,920
if you choose to go with a bi-directional LSTM for those not familiar it's kind of a bi-directional

272
00:28:05,920 --> 00:28:12,960
LSTM is two LSTMs just one reads your input text forward to backwards the second reads your input

273
00:28:12,960 --> 00:28:18,320
text backwards to forwards so it would start with your last token in your sequence then read it

274
00:28:18,320 --> 00:28:25,440
backwards and then you'd kind of concatenate those into your output to pass up so we've found that

275
00:28:25,440 --> 00:28:31,840
bi-directional with smaller with a small with fewer actual layers stacked on top of each other

276
00:28:31,840 --> 00:28:39,440
can perform as good as a regular LSTM with layers stacked on top and it kind of makes sense because

277
00:28:39,440 --> 00:28:45,680
the goal what these LSTMs are trying to do is just learn this this representation and learn this

278
00:28:45,680 --> 00:28:52,160
state and passing in multiple layers you're kind of maybe maybe each network while they look

279
00:28:52,160 --> 00:28:57,360
the same they're learning different things so maybe you know the first LSTMs or like learning

280
00:28:57,360 --> 00:29:03,440
baseline state stuff the second LSTM is really taking that state and finding the interactions with

281
00:29:03,440 --> 00:29:09,440
each other and how how things in that state um we're working together to help in your prediction

282
00:29:09,440 --> 00:29:14,880
test a bi-directional LSTM can do that in fewer layers because it's kind of seeing the text twice

283
00:29:14,880 --> 00:29:20,800
so it's learning a state going forward it might be picking up on other nuances going backwards

284
00:29:20,800 --> 00:29:26,080
and then tying those things together where you where you can get away with the smaller

285
00:29:26,080 --> 00:29:32,320
architecture so LSTMs figure very prominently in the sentiment analysis that you're doing are there

286
00:29:32,320 --> 00:29:40,640
other techniques that you bring the bear yeah so something I get really excited about and this

287
00:29:40,640 --> 00:29:45,280
we're kind of just starting research on this it's kind of a future frontier where we're hoping to

288
00:29:45,280 --> 00:29:53,360
get to one of the main goals like I said before is we want to help people find what is relevant to

289
00:29:53,360 --> 00:30:00,240
them and wade through what seems like a suffocating amount of information to find what they need

290
00:30:00,880 --> 00:30:08,480
this actually aligns really well with a common problem in active investing where idea generation

291
00:30:08,480 --> 00:30:13,520
is almost parallelizing like it's really hard to get into investing because you need to kind of

292
00:30:13,520 --> 00:30:19,680
do the research come up with the ideas what do I want to invest in so to the extent that we can

293
00:30:19,680 --> 00:30:25,040
help people find individual stocks help people find individual content or help people connect with

294
00:30:25,040 --> 00:30:29,760
other people that will help them generate those ideas it's things that we're interested in so

295
00:30:30,640 --> 00:30:39,120
besides just sentiment we are looking at this is actually still related to we're exploring LSTMs

296
00:30:39,120 --> 00:30:43,920
we're exploring convolutional neural networks for this but doing more representation learning

297
00:30:44,560 --> 00:30:53,920
for the conversation going on or like between users on certain stock streams and we want to basically

298
00:30:53,920 --> 00:30:59,120
do this for recommendation purposes so this I think is this newer trend with neural networks and

299
00:30:59,120 --> 00:31:04,960
deep learning that we're seeing more recently where we have some prediction task we're learning

300
00:31:04,960 --> 00:31:10,960
is state so this this state might be like the the final hidden state in an LSTM it might be like

301
00:31:10,960 --> 00:31:16,960
the final fully connected layer in a convolutional neural network and you might be predicting something

302
00:31:16,960 --> 00:31:22,560
that thing could be arbitrary and at the end you're kind of like throwing that task away and you're

303
00:31:22,560 --> 00:31:28,480
left with this representation that you can put in an embedding space to kind of then do something

304
00:31:28,480 --> 00:31:35,040
like can yours neighbors to find similar things so through conversation we're trying we're exploring

305
00:31:35,040 --> 00:31:42,400
can we like embed like stock to its messages in a in a message space where we can see like the

306
00:31:42,400 --> 00:31:48,000
types of messages that a user typically likes to engage in maybe the types of stocks that they're

307
00:31:48,000 --> 00:31:53,760
engaging in maybe we have another embedding space around stocks that kind of can can say okay

308
00:31:53,760 --> 00:31:58,880
like you're interested in these stocks here are stocks that are similar based on this embedding

309
00:31:58,880 --> 00:32:04,880
and then find you know the best messages about that stock from from this message embedding space

310
00:32:04,880 --> 00:32:11,120
so we're exploring convolutional neural networks to basically not for a prediction task itself

311
00:32:11,120 --> 00:32:20,880
but to kind of create this this like embedded space of users of messages and of stocks themselves

312
00:32:20,880 --> 00:32:28,480
to kind of to to make recommendations and so in this case what's your input so the input would

313
00:32:28,480 --> 00:32:36,960
still be the text data itself so we and your convolutions are across the vectorized representation

314
00:32:36,960 --> 00:32:43,120
of the text input yeah so this is a technique there's a canonical paper that's convolutional

315
00:32:43,120 --> 00:32:48,800
neural networks for text it was kind of the first paper that explored this and basically we have a

316
00:32:48,800 --> 00:32:55,760
one-dimensional convolution so your input is exactly like you said it's a matrix two dimensions

317
00:32:57,280 --> 00:33:02,080
down the rows would be the words in your sequence across the columns is your

318
00:33:03,520 --> 00:33:10,480
each dimension of your word vector for that for that for each word and we do a one-dimensional

319
00:33:10,480 --> 00:33:17,360
convolution because we're just taking windows and sliding them down across the entire word embedding

320
00:33:17,360 --> 00:33:24,080
so you're kind of capturing features generated through words that appear next to each other

321
00:33:24,080 --> 00:33:29,120
and you would kind of have parallelized windows of different lengths just like you'd have filters

322
00:33:29,120 --> 00:33:35,680
of different sizes for for a two-dimensional convolution and this makes this intuitively this

323
00:33:35,680 --> 00:33:40,560
should make sense because when you're dealing with images in a convolutional neural network

324
00:33:40,560 --> 00:33:48,240
information is local to an individual pixel so an individual pixel is just one entry in your

325
00:33:48,240 --> 00:33:54,640
input matrix so when you have this two-dimensional window that you're sliding over it pixels go

326
00:33:54,640 --> 00:34:01,680
in both dimensions when you're dealing with text information isn't local to just like one

327
00:34:01,680 --> 00:34:09,440
dimension of your word embedding information about that word encompasses maybe like all 50 or

328
00:34:09,440 --> 00:34:14,640
250 dimensions of your word embedding so the one-dimensional convolution makes sense because

329
00:34:14,640 --> 00:34:20,720
you want to make sure when you're representing a word you're not excluding certain dimensions

330
00:34:20,720 --> 00:34:28,000
of your of your word embedding yeah interesting so are the network architectures here are

331
00:34:28,000 --> 00:34:34,160
these kind of simple CNNs or have complex network architectures like inception and all that kind

332
00:34:34,160 --> 00:34:41,920
of stuff evolve for textual data in my experience i've seen fairly simple sand ends we we would

333
00:34:41,920 --> 00:34:49,920
probably do maybe have four or five window lengths so like taking three word four word five word

334
00:34:49,920 --> 00:34:58,240
six word windows maybe have a hundred to a hundred and fifty filters of each size and then kind of

335
00:34:58,240 --> 00:35:06,160
branching off into like maybe those four or five parallel neural net like convolutional neural

336
00:35:06,160 --> 00:35:11,760
networks that then end up at some point like concatenating back together for like that last

337
00:35:11,760 --> 00:35:18,800
fully connected layer so it's i'd say it's it's a fairly simple architecture but you get a little

338
00:35:18,800 --> 00:35:25,600
bit additional complexity if you kind of are doing a couple different size filters in parallel

339
00:35:25,600 --> 00:35:30,480
and then kind of bringing them back together so i i'd think of it like four different CNNs

340
00:35:30,480 --> 00:35:35,760
each branching out their own direction and then ultimately coming together at some point to

341
00:35:35,760 --> 00:35:40,800
have a like a final prediction made i'm wondering if there are other tricks that you're kind of

342
00:35:40,800 --> 00:35:49,920
layering onto the CNNs to help here um no i mean we we're still pretty early in our research at

343
00:35:49,920 --> 00:35:56,320
stock puts on this so we're trying to start simple we drew a lot of inspiration actually from uh

344
00:35:56,320 --> 00:36:03,680
companies like Spotify who are using these types of methods to kind of do music recommendation

345
00:36:03,680 --> 00:36:13,120
and for us you know stocks are very similar to music um we so like you kind of have these like

346
00:36:13,120 --> 00:36:18,880
genres and and like playlist where you can kind of tie stocks together through conceptual

347
00:36:18,880 --> 00:36:25,520
themes so like stocks related to self-driving cars stocks related to AI tech stocks um you kind

348
00:36:25,520 --> 00:36:30,960
of have this engagement so like people are listening to different music people are like engaging

349
00:36:30,960 --> 00:36:37,280
in different stocks and then you actually have kind of a similarity for price movement of a stock

350
00:36:37,280 --> 00:36:44,880
like if you're analyzing music and you're actually looking like at the notes um like the the

351
00:36:44,880 --> 00:36:52,240
structure of a note or the structure of you know music at that level isn't that dissimilar to

352
00:36:52,240 --> 00:36:57,920
just like looking at a stock price change over time where like the the the chart is your your

353
00:36:57,920 --> 00:37:05,040
clout of it like the chart is um kind of your bars and like each time frame is kind of note so

354
00:37:05,040 --> 00:37:10,800
we try to draw inspiration from other leaders who are doing this type of work um so they they're

355
00:37:10,800 --> 00:37:16,960
probably quite a bit ahead of us they might be doing a little bit more complex things um but as far

356
00:37:16,960 --> 00:37:23,680
as CNNs we we try to keep it fairly simple okay so we've got LSTMs we've got CNNs are there other

357
00:37:23,680 --> 00:37:28,800
techniques that you tend to use to solve some of these problems yeah so another area that we're

358
00:37:28,800 --> 00:37:37,360
starting to research is tech summarization so like I said the streams the velocity is very very high

359
00:37:37,360 --> 00:37:44,000
information is coming through if if something is trending like if something crazy happened um

360
00:37:44,960 --> 00:37:51,920
for example like if Elon Musk is going off the deep end and and Tesla is tanking we may be seeing um

361
00:37:52,800 --> 00:38:00,880
like upwards of like 500 messages come in like a minute so it's it's kind of really hard for like

362
00:38:00,880 --> 00:38:06,880
maybe someone who hasn't developed a really refined process for how they like to use stock

363
00:38:06,880 --> 00:38:12,160
tweets to come on to stock tweets and not be overwhelmed by the sheer amount of information that

364
00:38:12,160 --> 00:38:19,280
they're seeing so so tech summarization is something that is super interesting to us um we curate

365
00:38:19,280 --> 00:38:25,280
news as well so news summarizations like a more well understood problem we're really curious can we

366
00:38:25,280 --> 00:38:31,440
apply those techniques to a stream where we can maybe extract the most important things that are

367
00:38:31,440 --> 00:38:37,360
going on in the last hour from what people are saying about the stock and and maybe have those

368
00:38:37,360 --> 00:38:43,360
as bullet points when you're going to the Tesla page the kind of ease in and still get okay what

369
00:38:43,360 --> 00:38:49,200
are people saying about this stock without you know being like oh man like there's just stuff

370
00:38:49,200 --> 00:38:55,200
coming in so fast I can't really deal with it so for our tech summarization we've been still focused

371
00:38:55,200 --> 00:39:02,000
in the RNN domain but more focused on kind of these in these sequence to sequence models so encoder

372
00:39:02,000 --> 00:39:09,280
decoder networks with um with attention uh and so how did what's the how do those work

373
00:39:10,080 --> 00:39:16,560
yeah so I believe it's even better how do you explain them how did you explain

374
00:39:16,560 --> 00:39:26,560
yeah yeah yeah yeah so RNNs are very robust they they there's a lot of different flavors of LSTN

375
00:39:26,560 --> 00:39:31,600
so when we're dealing with the sentiment classification problem we're dealing with kind of a

376
00:39:31,600 --> 00:39:39,440
many to one RNN where our input is many the different words in our sentence one at a time

377
00:39:39,440 --> 00:39:44,480
and then after we've seen all those words we want to make a single prediction um is this

378
00:39:44,480 --> 00:39:51,920
bullish as is neutral is this bearish when we're dealing with problems like text classification

379
00:39:51,920 --> 00:39:59,920
our input is a sequence and our output is a sequence so we're inputting the words of our original

380
00:39:59,920 --> 00:40:05,600
text let's just say we're dealing with the news article and then we want to output another

381
00:40:05,600 --> 00:40:13,120
sentence that is just a summary of that text so our output is um multiple tokens of our summary

382
00:40:13,120 --> 00:40:22,880
and so the way we can handle that is kind of stacking two RNNs on top of each other not like we did

383
00:40:22,880 --> 00:40:30,000
it before um but kind of letting it's referred to as an encoder decoder so we have a first RNN

384
00:40:30,000 --> 00:40:36,960
that's taking in our inputs um our input sequence and it's kind of learning a state of that input

385
00:40:36,960 --> 00:40:45,040
sequence and then we have a decoder RNN who is taking in that state from our encoder and kind

386
00:40:45,040 --> 00:40:50,480
of decoding that and picking what um kind of generating what what the best summary would be

387
00:40:51,120 --> 00:40:58,160
and in the past the original models of this had the encoder and the decoder talk directly to

388
00:40:58,160 --> 00:41:03,440
each other so the encoder would come up with a final state it would pass that final state to the

389
00:41:03,440 --> 00:41:09,040
decoder network that final state would be the initial input to the decoder network which would

390
00:41:09,040 --> 00:41:14,880
then kind of learn from like it would maintain its own internal state to try to say what word from

391
00:41:14,880 --> 00:41:21,120
my vocabulary has the best probability of being the next word so the decoder RNN is really trying

392
00:41:21,120 --> 00:41:27,440
to predict given the state that I have and what I just said the first word of this summary is

393
00:41:27,440 --> 00:41:34,080
what's going to be the next word in our summary so this is truly like language generative model

394
00:41:34,080 --> 00:41:39,440
language where we we have some vocabulary and we're trying to generate language that makes sense

395
00:41:40,400 --> 00:41:50,480
and this original model kind of had its drawbacks where we were asking a lot of the encoder RNN

396
00:41:50,480 --> 00:41:56,560
where we're saying encode everything that you have to say in this one final state that's

397
00:41:56,560 --> 00:42:02,560
going to be passed to the decoder network and it was actually I think neural machine translation

398
00:42:02,560 --> 00:42:08,400
that introduced this idea of attention and so now attention is this layer that lives between

399
00:42:08,400 --> 00:42:16,160
the encoder network and the decoder network that basically says at any point when we are decoding

400
00:42:16,160 --> 00:42:22,640
let me look back at the entire input sequence and let me focus on where in the input it is important

401
00:42:22,640 --> 00:42:28,560
for me to make my prediction on what the next word is going to be and how have you found this

402
00:42:30,160 --> 00:42:35,200
this model to perform for summarization do you have you gotten you're getting good summarization

403
00:42:35,200 --> 00:42:43,760
of we you can get pretty decent summarizations on news news is like a very well structured input a

404
00:42:43,760 --> 00:42:50,640
just random sequence of tweets is not very well structured so we're we still have quite a way to go

405
00:42:50,640 --> 00:42:57,920
before I think we get anything that that we would put into production for tweet summarization

406
00:42:57,920 --> 00:43:03,280
but and it's also you're you're not necessarily trying to summarize an individual tweet it's

407
00:43:03,280 --> 00:43:09,440
more like corpus summarization right you're trying to pick the main elements across multiple tweets

408
00:43:09,440 --> 00:43:15,600
and so I do like just concatenate them all together or is there some that that seems like you're

409
00:43:15,600 --> 00:43:22,000
losing something if you do that yeah so I think how we've approached it is we've tried to kind

410
00:43:22,000 --> 00:43:31,920
of explore with this idea of a three-dimensional input to your RNN so like traditionally inputs to

411
00:43:31,920 --> 00:43:39,040
RNNs are two to like two-dimensional respect that you have a sequence of words so your sequence

412
00:43:39,040 --> 00:43:43,920
of words is the first to mention your sentence could be 10 words and then each individual word

413
00:43:43,920 --> 00:43:51,360
that you're inputting is has like a one row with 300 columns of your word embedding so we were

414
00:43:51,360 --> 00:43:59,360
playing with kind of a three-dimensional input where your first sequence is a stream your second

415
00:43:59,360 --> 00:44:04,960
sequence is a tweet in the stream and like your third dimension is like the words in that tweet

416
00:44:04,960 --> 00:44:12,560
and I think you kind of hit the nail on the head where we are probably not being fair to our LSTM

417
00:44:12,560 --> 00:44:18,800
network we're probably asking it to do too much by trying to treat a stream like it is one cohesive

418
00:44:18,800 --> 00:44:27,200
document when in reality I think our next direction of research is gonna be more okay let maybe

419
00:44:27,200 --> 00:44:33,040
don't summarize a whole stream but can we pick out an individual tweet that we think is really

420
00:44:33,040 --> 00:44:39,280
good and let encompasses like a broader trend that we're seeing across multiple tweets so maybe

421
00:44:39,280 --> 00:44:46,000
it's not necessarily framing it directly like you would frame a news article summarization more

422
00:44:46,000 --> 00:44:53,600
framing it like a um still we're not generating new language but we're finding a tweet that is

423
00:44:53,600 --> 00:44:59,760
representative over like a broader concept that we can identify in a stream does transfer learning

424
00:44:59,760 --> 00:45:06,480
apply in the spaces at all like you know we've got the pre-trained love vectors and um it is

425
00:45:06,480 --> 00:45:12,960
there anything that can be used to accelerate a summarization task so that you're not pre-training

426
00:45:12,960 --> 00:45:17,440
everything from scratch yeah training everything from scratch yeah definitely so um

427
00:45:19,040 --> 00:45:26,320
the NLP community is starting to make like a lot like bigger strides in getting to effective

428
00:45:26,320 --> 00:45:31,920
transfer learning for language tests um I still don't think it's close to where the computer

429
00:45:31,920 --> 00:45:38,400
vision community is but progress is definitely being made um for for kind of generic things there are

430
00:45:38,960 --> 00:45:45,200
pre-trained models out there from they're not like they're not kind of like the computer vision

431
00:45:45,200 --> 00:45:51,120
where there's like these go-to trained models but you can find decent research out of there um

432
00:45:51,120 --> 00:45:57,280
there's a paper I really like um that I've drawn a lot of inspiration from from Abigail C

433
00:45:57,280 --> 00:46:06,400
on pointer networks and so pointer networks were um are this extension of just based like

434
00:46:06,400 --> 00:46:12,720
vanilla attention models where you're also kind of training this parameter called a pointer

435
00:46:12,720 --> 00:46:20,480
that's saying anywhere in when I'm predicting the next word in my summary do I want to just kind

436
00:46:20,480 --> 00:46:26,640
of generate a new word from my generic vocabulary or do I want to pick a specific word from the

437
00:46:26,640 --> 00:46:32,800
input text to use here so I think one of the biggest problems that people were seeing in summarization

438
00:46:32,800 --> 00:46:39,920
was that it was getting baseline facts wrong from from the input text um so like if I was

439
00:46:39,920 --> 00:46:46,000
summering a news article that Tesla dropped 10 percent pre-market the traditional techniques

440
00:46:46,000 --> 00:46:52,080
for having it like a tough time extracting that that 10 percent figure so this pointer can

441
00:46:52,080 --> 00:46:58,960
basically say okay like I know that I'm about to pull a figure out um I'm going to grab I'm

442
00:46:58,960 --> 00:47:06,000
going to grab um vocab from my source text and not try to like pick a needle out of a haystack

443
00:47:06,000 --> 00:47:11,360
of what this metric might be from like all the metrics I've ever seen that live in my vocabulary

444
00:47:11,360 --> 00:47:16,640
and is this all deep learning based or is there like some tokenization entity resolution that kind

445
00:47:16,640 --> 00:47:24,240
of thing happening up front um I believe it's all it's end-to-end deep learning based yeah so I

446
00:47:24,240 --> 00:47:30,720
think there's um I'm not sure what they used for the word vectors or if if the word vectors are

447
00:47:30,720 --> 00:47:35,760
just learned in an end-to-end fashion but there is a pre-trained model out there like they

448
00:47:35,760 --> 00:47:41,200
wrote they open source to all the code from this model it was trained on CNN and daily news data

449
00:47:41,200 --> 00:47:47,760
um and so there is a pre-trained model out there that exists that that was kind of our first step

450
00:47:47,760 --> 00:47:53,840
of saying okay like if we just took this model and ran financial news through it would we would

451
00:47:53,840 --> 00:48:00,000
we get anything like would it be able to be applied I also think you could kind of use that

452
00:48:00,000 --> 00:48:06,240
model as a baseline and then retrain on your specific data I do think in our case of like trying

453
00:48:06,240 --> 00:48:11,520
to summarize tweets we're kind of starting from scratch I don't know how much how much transfer

454
00:48:11,520 --> 00:48:20,080
learning is there I think the where transfer learning comes into play for NLP is really can we learn

455
00:48:20,880 --> 00:48:27,840
like do we have greater representations for more generic text at like a high level language modeling

456
00:48:27,840 --> 00:48:34,000
text so I think when you're getting to like generative language I see the future of transfer learning

457
00:48:34,000 --> 00:48:39,840
in NLP being like okay here are these good models that kind of like help us generate text so like

458
00:48:39,840 --> 00:48:45,680
they learn kind of just like the state of like a pre-trained model for computer vision is kind of

459
00:48:45,680 --> 00:48:52,160
learn these nice feature representations for different like parts of an image or different objects

460
00:48:52,160 --> 00:48:58,480
that appear in an image can we learn just like really good generic representations for how

461
00:48:58,480 --> 00:49:05,440
text interacts with each other how words interact with each other to generate like sentences and

462
00:49:05,440 --> 00:49:10,640
language that makes sense and then starting with those representations is kind of to be the first

463
00:49:10,640 --> 00:49:16,400
steps of your your model and and build maybe many models on top of that if that makes sense no it

464
00:49:16,400 --> 00:49:24,000
does it does okay this has been great are there any kind of words of inspiration or wisdom that

465
00:49:24,000 --> 00:49:32,080
you would leave with folks who want to start exploring some of these techniques more my best advice

466
00:49:32,080 --> 00:49:39,600
would be dive in I think you can spend months probably even years at this point with all the

467
00:49:39,600 --> 00:49:44,800
information that's out there trying to learn trying to figure out exactly what's going on trying

468
00:49:44,800 --> 00:49:51,280
to just become an expert but really no one's an expert we're we're applying these methods to new

469
00:49:51,280 --> 00:49:56,080
problems that really don't necessarily have a solution they have like the best solution that we

470
00:49:56,080 --> 00:50:03,760
have for them today and you're really not going to you're really not going to be able to know

471
00:50:03,760 --> 00:50:08,720
everything before you dive in you're going to learn a lot as you're going so so my advice would be

472
00:50:08,720 --> 00:50:16,000
you know don't be afraid the the training I offer tries to kind of make deep learning methods

473
00:50:16,000 --> 00:50:21,840
accessible because I think once you dive in you'll you'll realize that deep learning isn't that

474
00:50:21,840 --> 00:50:28,160
far of a jump from what you're doing today so yeah just don't be afraid just dive in head first

475
00:50:28,160 --> 00:50:35,280
well said and you you mentioned that the you've got code from your training in a repository and

476
00:50:35,280 --> 00:50:39,200
the slides and all that kind of stuff and you'll get that link to me we'll get that link on the

477
00:50:39,200 --> 00:50:44,800
show notes page anyone that wants to to follow along with the material that you presented they'll

478
00:50:44,800 --> 00:50:50,400
be able to do it there yep we'll do awesome thanks so much guys thanks for having us and it's been great

479
00:50:56,000 --> 00:51:01,280
all right everyone that's our show for today for more information on Garrett or any of the topics

480
00:51:01,280 --> 00:51:08,880
covering in this episode head over to twimmel ai.com slash talk slash 194 if you're a fan of the pod

481
00:51:08,880 --> 00:51:13,920
we'd like to encourage you to visit your apple or google podcast app and leave us a five star

482
00:51:13,920 --> 00:51:18,880
rating and review your reviews help inspire us to create more and better content and they help

483
00:51:18,880 --> 00:51:24,400
new listeners find the show thanks again to our friends at IBM for their sponsorship of this

484
00:51:24,400 --> 00:51:32,320
episode be sure to check out IBM developer at IBM dot biz slash ml ai podcast as always thanks

485
00:51:32,320 --> 00:51:44,080
so much for listening and catch you next time

