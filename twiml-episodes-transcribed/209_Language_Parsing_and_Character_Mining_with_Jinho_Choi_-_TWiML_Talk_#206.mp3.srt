1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:31,480
I'm your host Sam Charrington.

4
00:00:31,480 --> 00:00:36,080
Today in the second episode of our reinvent series, we're joined by Geno Choi, assistant

5
00:00:36,080 --> 00:00:39,400
professor of computer science at Emory University.

6
00:00:39,400 --> 00:00:45,040
Geno participated in the conference's AI Summit, presenting on ELIT, which is short for evolution

7
00:00:45,040 --> 00:00:50,920
of language and information technology, which is a cloud-based NLP platform.

8
00:00:50,920 --> 00:00:54,720
In our conversation, we discuss some of the key NLP challenges that Geno and his group

9
00:00:54,720 --> 00:01:00,520
are tackling, including language parsing and character mining, as well as their vision

10
00:01:00,520 --> 00:01:05,920
for ELIT, which makes it easy for researchers to develop access and deploy cutting-edge

11
00:01:05,920 --> 00:01:09,320
NLP models to the cloud.

12
00:01:09,320 --> 00:01:13,080
If you're hearing this on Wednesday, I'm currently at NURRIPS.

13
00:01:13,080 --> 00:01:18,080
If you're also here, please join the listener meetup I'm hosting tonight at 630 at Tavern

14
00:01:18,080 --> 00:01:19,080
Midway.

15
00:01:19,080 --> 00:01:24,440
Be sure to RSVP via the social activities thread in the conference's Hoover app.

16
00:01:24,440 --> 00:01:26,880
Next week, I'll be in Seattle at CUBECON.

17
00:01:26,880 --> 00:01:30,480
I'd love to connect with any listeners in the area or in attendance.

18
00:01:30,480 --> 00:01:35,080
Feel free to shoot me a message via at Sam Charrington on Twitter, via email, or the

19
00:01:35,080 --> 00:01:57,880
Twomo website, CURM, and now on to the show.

20
00:01:57,880 --> 00:02:04,880
So we are sitting here in Las Vegas, the occasion that brought us together is the reinvent conference

21
00:02:04,880 --> 00:02:11,160
here, where you delivered a presentation on some of the work that you're doing at Emery.

22
00:02:11,160 --> 00:02:15,120
But before we dive into that, tell us a little bit about your background and how you got

23
00:02:15,120 --> 00:02:16,640
involved in machine learning.

24
00:02:16,640 --> 00:02:17,640
Right.

25
00:02:17,640 --> 00:02:22,760
I actually got into the natural language processing back in 2002, so that's when I was

26
00:02:22,760 --> 00:02:28,920
doing my master's degree at University of Pennsylvania, and so I've been always interested

27
00:02:28,920 --> 00:02:34,680
in studying languages and having the language understanding by computers.

28
00:02:34,680 --> 00:02:40,240
So since I was young, I was always telling my mom that I wanted to make a robot that

29
00:02:40,240 --> 00:02:47,280
understands me, and I guess I'm stepping towards to that goal still, and I don't know if

30
00:02:47,280 --> 00:02:52,080
it's going to happen before my time or not, but I'm going to try to strive to it.

31
00:02:52,080 --> 00:02:57,560
So once I actually got into this field, I was fascinated by all these machine learning

32
00:02:57,560 --> 00:02:58,560
approaches.

33
00:02:58,560 --> 00:03:03,800
The machine is capable of learning the patterns that we don't really even teach, and you actually

34
00:03:03,800 --> 00:03:08,760
can pick up the patterns that we don't even think about, especially with the latest

35
00:03:08,760 --> 00:03:11,200
technologies with dim learning and neural networks.

36
00:03:11,200 --> 00:03:16,920
It's actually started discovering some linguistic phenomena that has not been really discovered

37
00:03:16,920 --> 00:03:18,600
by humans yet.

38
00:03:18,600 --> 00:03:23,400
So this is actually a very exciting time of the year to study natural learning processing

39
00:03:23,400 --> 00:03:24,880
along with machine learning.

40
00:03:24,880 --> 00:03:29,920
What are the research areas that you focus on in your work?

41
00:03:29,920 --> 00:03:30,920
Right.

42
00:03:30,920 --> 00:03:36,000
So there are many different fields in natural learning processing that I do, but there

43
00:03:36,000 --> 00:03:39,240
are like mainly three projects I work on.

44
00:03:39,240 --> 00:03:42,440
One is the core level natural learning processing.

45
00:03:42,440 --> 00:03:50,080
What we call given an unstructured raw free text, we try to analyze the text into structures.

46
00:03:50,080 --> 00:03:54,760
So this is all prototypical since you learn from the elementary school.

47
00:03:54,760 --> 00:04:00,040
So you analyze the language into grammatical categories, synthetic patterns, semantic

48
00:04:00,040 --> 00:04:02,480
processing, and some understanding.

49
00:04:02,480 --> 00:04:08,400
So we now try to have computers to generate the similar structures that we have been

50
00:04:08,400 --> 00:04:10,360
teaching in the decades.

51
00:04:10,360 --> 00:04:16,560
So that's the one part of the research I work on, which we call as a language parsing.

52
00:04:16,560 --> 00:04:22,960
And the second part is we also try to show how the language represent.

53
00:04:22,960 --> 00:04:28,560
So especially we are trying to present this into the setting of the machine comprehension.

54
00:04:28,560 --> 00:04:35,800
So the project that I actually created since I came to Emory was a project called Character

55
00:04:35,800 --> 00:04:42,600
Mining, and the goal of the project is to understand human conversation involving multiple

56
00:04:42,600 --> 00:04:43,800
parties.

57
00:04:43,800 --> 00:04:50,680
So now the scenario I'm designing right now is if you have a machine such as Alexa or

58
00:04:50,680 --> 00:04:58,120
any of this client conversation agent machines, it can just listen to our conversation.

59
00:04:58,120 --> 00:05:03,120
And later on, if we actually forget some contents about this conversation, we can, instead

60
00:05:03,120 --> 00:05:09,280
of calling multiple people around about this, we can ask the machine, so what did I talk

61
00:05:09,280 --> 00:05:10,280
about?

62
00:05:10,280 --> 00:05:11,280
What did I talk about?

63
00:05:11,280 --> 00:05:16,080
And if I forgot your last name, so what was Sam's last name, it should be able to tell

64
00:05:16,080 --> 00:05:19,960
if that kind of content was brought up during the conversation.

65
00:05:19,960 --> 00:05:24,280
So that's one project I call Character Mining, that's what I work on most.

66
00:05:24,280 --> 00:05:29,920
And also along the application size, since Emory has a huge hospital, we have so much

67
00:05:29,920 --> 00:05:35,640
records, years of years of data from patients and all this different kind of electrical

68
00:05:35,640 --> 00:05:37,640
healthcare data.

69
00:05:37,640 --> 00:05:42,840
So we actually also try to apply natural links processing to help people to facilitate

70
00:05:42,840 --> 00:05:45,240
better for their medical needs.

71
00:05:45,240 --> 00:05:50,440
So especially what we have done is we have tried to done the classification of the radiology

72
00:05:50,440 --> 00:05:57,240
reports and see the machines capable of seeing what kind of severity level of this patient

73
00:05:57,240 --> 00:06:00,720
has based on the text and the report.

74
00:06:00,720 --> 00:06:04,920
And I think we have been reaching to the similar accuracy as humans do.

75
00:06:04,920 --> 00:06:07,440
So that's what the technology is involved.

76
00:06:07,440 --> 00:06:13,520
And also another new project that we start working on is, given the language patterns,

77
00:06:13,520 --> 00:06:20,440
or you basically ask the person to speak freely about certain things, about what or two

78
00:06:20,440 --> 00:06:21,440
minutes.

79
00:06:21,440 --> 00:06:28,560
And analyze the style of the language or some patterns of the language, and we can detect

80
00:06:28,560 --> 00:06:34,600
if the person has some kind of cognitive impairment and leading to the Alzheimer's disease.

81
00:06:34,600 --> 00:06:39,400
So we are actually trying to catch a very early stage of Alzheimer's disease by using

82
00:06:39,400 --> 00:06:43,840
our language technology, and this has been actually working really exciting project for

83
00:06:43,840 --> 00:06:44,840
me.

84
00:06:44,840 --> 00:06:45,840
Oh wow.

85
00:06:45,840 --> 00:06:49,120
There's a lot of interesting stuff to dig into.

86
00:06:49,120 --> 00:06:57,240
So the first one that you talked about is kind of language parsing, and we have a long

87
00:06:57,240 --> 00:07:05,160
history of trying to do this with computers, both using more traditional rules, model-based

88
00:07:05,160 --> 00:07:12,640
approach to doing it, and more recently statistical-based approaches to doing it.

89
00:07:12,640 --> 00:07:18,800
What are the main elements of the way that you're going after this problem?

90
00:07:18,800 --> 00:07:19,800
Right.

91
00:07:19,800 --> 00:07:26,240
So during my PhD, I graduated from my PhD even in 2012, which is not that long ago.

92
00:07:26,240 --> 00:07:32,480
Amazing thing is every approach I actually learned during the PhD actually has changed.

93
00:07:32,480 --> 00:07:37,120
One side story, one side story about this is, when I came to Emory, I spent a year to

94
00:07:37,120 --> 00:07:41,960
make slides for my natural language processing graduate level class.

95
00:07:41,960 --> 00:07:47,800
That was year 2015, and I cannot use any of those slides anymore, because technology evolved

96
00:07:47,800 --> 00:07:52,920
so much, which is great thing for the field, but for faculty members like us, we just have

97
00:07:52,920 --> 00:07:55,400
to keep making new slides every year.

98
00:07:55,400 --> 00:08:02,240
Well, I mean, it's a happy thought, but so the ladies break through, I have to say,

99
00:08:02,240 --> 00:08:04,440
it's a neural network and dim learning.

100
00:08:04,440 --> 00:08:10,080
So at the moment, we are trying to rely on the supervised learning, which you need to

101
00:08:10,080 --> 00:08:17,120
require an enormous amount of manually annotated data from the linguist, and you basically

102
00:08:17,120 --> 00:08:21,680
the machine tried to learn the patterns among the human annotations and tried to produce

103
00:08:21,680 --> 00:08:25,120
a very similar result for the unseen data.

104
00:08:25,120 --> 00:08:31,680
So this approach has been working for over 20 years in natural language processing lately,

105
00:08:31,680 --> 00:08:36,760
because of this evolved amount of neural network, we can actually use a lot of unsupervised

106
00:08:36,760 --> 00:08:37,760
data.

107
00:08:37,760 --> 00:08:43,440
So free text without human annotations can actually take a huge role into this field now.

108
00:08:43,440 --> 00:08:46,800
So all of a sudden, let me give you a very solid example.

109
00:08:46,800 --> 00:08:51,640
So there was a synthetic parsing test case, one of the tests that natural needs processing

110
00:08:51,640 --> 00:08:54,560
field has been investigated for a long time.

111
00:08:54,560 --> 00:09:03,560
And the accuracy of 92 or 93% was the barrier that had not been broken for over 15 years.

112
00:09:03,560 --> 00:09:09,800
And after this neural network, it got broken up to 96% now.

113
00:09:09,800 --> 00:09:16,120
As of last month, one of my pitches actually broke the record to the 96%, which is something

114
00:09:16,120 --> 00:09:19,360
that we couldn't even dream of just two years ago.

115
00:09:19,360 --> 00:09:24,600
So yeah, I think all this involvement of the diminuting and machine learning technology

116
00:09:24,600 --> 00:09:28,040
really played a huge role in natural needs processing.

117
00:09:28,040 --> 00:09:35,800
And so is there a particular type of model or model architecture that you're using to

118
00:09:35,800 --> 00:09:38,120
do the syntax parsing?

119
00:09:38,120 --> 00:09:39,120
Right.

120
00:09:39,120 --> 00:09:42,800
So there are multiple different ways of doing it.

121
00:09:42,800 --> 00:09:46,760
So for parsing, there are two main streams of parsing.

122
00:09:46,760 --> 00:09:51,720
One is known as a transition-based parsing, and there is known as a graph-based parsing.

123
00:09:51,720 --> 00:09:57,800
So in all days, just like it's not even all days in five years ago, a lot of people focused

124
00:09:57,800 --> 00:10:04,600
on the transition-based parsing approach, which doesn't search for the entire, search spaces

125
00:10:04,600 --> 00:10:09,480
and entire possibilities, but it actually prints out a lot of search space so it will run

126
00:10:09,480 --> 00:10:11,000
much faster.

127
00:10:11,000 --> 00:10:14,040
And speed is really essential for the big data analysis.

128
00:10:14,040 --> 00:10:18,120
So everyone was going for a transition-based parsing.

129
00:10:18,120 --> 00:10:25,280
What was actually amazing was now because of all this power of the GPU, which is known

130
00:10:25,280 --> 00:10:31,120
for parallel processing, even if we actually make an exhaustive search using graph-based

131
00:10:31,120 --> 00:10:36,280
parsing, it can actually still run as fast as a transition-based parsing.

132
00:10:36,280 --> 00:10:41,440
So this actually is another movement that I didn't actually dream of during my PhD time.

133
00:10:41,440 --> 00:10:46,080
But now my students actually are discovering graph-based parsing, which usually is more

134
00:10:46,080 --> 00:10:49,480
accurate, and now can even run as fast.

135
00:10:49,480 --> 00:10:56,480
So the algorithm is basically making the exhaustive search and giving all the possible probabilities,

136
00:10:56,480 --> 00:11:00,880
now you can re-rank to find the best structure out of it.

137
00:11:00,880 --> 00:11:05,560
So which is getting much more popular approaches these days.

138
00:11:05,560 --> 00:11:14,920
And so in that model and the graph-based processing, what are the nodes of the graph?

139
00:11:14,920 --> 00:11:17,880
No, self-the-graph is the individual word.

140
00:11:17,880 --> 00:11:20,320
And the connection?

141
00:11:20,320 --> 00:11:27,240
The connections will be what we call dependency relations, so like subject, object, preposition

142
00:11:27,240 --> 00:11:28,240
relations.

143
00:11:28,240 --> 00:11:34,600
So if you have a simple sense of like John but a car, so John is a subject of both and

144
00:11:34,600 --> 00:11:39,280
car is an object of both, and all is a determiner of car.

145
00:11:39,280 --> 00:11:42,440
So that kind of relation is the synthetic parsing.

146
00:11:42,440 --> 00:11:47,120
You start with just nodes then, right, because the problem that you're trying to solve is

147
00:11:47,120 --> 00:11:50,160
define what the connections are.

148
00:11:50,160 --> 00:11:55,440
So now in this example, there are four words, John but a car.

149
00:11:55,440 --> 00:12:00,400
And so you have four nodes, and you have one external called root root of the sentence.

150
00:12:00,400 --> 00:12:05,680
So it depends on your approach, but root of the sentence in this case will be a bot.

151
00:12:05,680 --> 00:12:10,280
So bot will be connected to root, and everything else will have a connection to itself.

152
00:12:10,280 --> 00:12:17,400
So the current approaches that we are developing is you try to find if every pair will be compared

153
00:12:17,400 --> 00:12:19,440
if there is a relation.

154
00:12:19,440 --> 00:12:25,160
And now you run the optimization algorithm to find which is the most probable tree you

155
00:12:25,160 --> 00:12:28,160
will generate out of this.

156
00:12:28,160 --> 00:12:31,120
And you're doing this via neural network.

157
00:12:31,120 --> 00:12:33,200
Now we are doing this neural network, yes.

158
00:12:33,200 --> 00:12:35,480
Is it a supervised learning problem?

159
00:12:35,480 --> 00:12:42,160
At the moment, so I would say like the most latest approaches are semi-supervised.

160
00:12:42,160 --> 00:12:47,400
So we do use all the training data from the human annotation, but we also may take advantage

161
00:12:47,400 --> 00:12:50,800
of unstructured data on annotated data.

162
00:12:50,800 --> 00:12:55,840
So this is the, well, everyone uses an object called word embeddings.

163
00:12:55,840 --> 00:13:00,440
So this word representation is trained on a large amount of data.

164
00:13:00,440 --> 00:13:04,520
So the data that we have is about 62 gigabytes of the text.

165
00:13:04,520 --> 00:13:11,040
So 62 gigabytes of text is actually equivalent to so much more if you compare to images.

166
00:13:11,040 --> 00:13:13,160
Because it's only the character in level.

167
00:13:13,160 --> 00:13:20,640
So yeah, and we can actually learn all the, what's the best representation for this word

168
00:13:20,640 --> 00:13:26,240
out of all this text and apply that knowledge into this supervised learning passion?

169
00:13:26,240 --> 00:13:33,600
So that means so then each of the nodes then isn't a symbolic representation of the word

170
00:13:33,600 --> 00:13:37,400
rather it's an embedding that has some semantic space.

171
00:13:37,400 --> 00:13:38,400
Right.

172
00:13:38,400 --> 00:13:39,880
What we call distributional semantics.

173
00:13:39,880 --> 00:13:40,880
Okay.

174
00:13:40,880 --> 00:13:42,560
Distributional semantics, right.

175
00:13:42,560 --> 00:13:49,080
And so this, this corpus that you describe the 62 gigabytes is that your own corpus

176
00:13:49,080 --> 00:13:51,200
or is that like love vectors or something like that?

177
00:13:51,200 --> 00:13:52,600
It's all publicly available.

178
00:13:52,600 --> 00:13:58,080
So the most popular one, the entire Wikipedia is available to everyone.

179
00:13:58,080 --> 00:14:03,400
Amazon wonderfully released all their review, a lot of like 10 years of their review.

180
00:14:03,400 --> 00:14:04,400
Reviews.

181
00:14:04,400 --> 00:14:05,400
We have those.

182
00:14:05,400 --> 00:14:08,680
We have a lot of Twitter data as well.

183
00:14:08,680 --> 00:14:12,720
And there are some medical domain Wikipedia that you can crawl.

184
00:14:12,720 --> 00:14:13,720
Okay.

185
00:14:13,720 --> 00:14:15,680
And so those are also in there too.

186
00:14:15,680 --> 00:14:16,680
Okay.

187
00:14:16,680 --> 00:14:22,080
And also, there is also New York Times corpus from LDC.

188
00:14:22,080 --> 00:14:26,600
So that's actually you have to buy from the organization what we have is so we are also

189
00:14:26,600 --> 00:14:27,600
using it.

190
00:14:27,600 --> 00:14:33,560
Can you describe kind of the algorithm and the way that you're using embeddings and kind

191
00:14:33,560 --> 00:14:41,080
of the network architecture that you're using and how you're training these models to ultimately

192
00:14:41,080 --> 00:14:43,480
produce these graphs?

193
00:14:43,480 --> 00:14:44,480
Right.

194
00:14:44,480 --> 00:14:49,120
And so in the very low level, the generations who are already embedding, they're like so

195
00:14:49,120 --> 00:14:51,080
many different approaches coming out.

196
00:14:51,080 --> 00:14:54,880
It's basically you try to develop a language model.

197
00:14:54,880 --> 00:15:01,640
So for given each all this text, for every word in the text, you are basically trying

198
00:15:01,640 --> 00:15:06,800
to build a model that actually can predict the contextual words.

199
00:15:06,800 --> 00:15:08,360
So you can go the other way too.

200
00:15:08,360 --> 00:15:12,680
Given the contextual word, you can try to predict that word of the target.

201
00:15:12,680 --> 00:15:17,440
So once you develop this kind of language model and you can develop in many different ways.

202
00:15:17,440 --> 00:15:22,560
So the most popular approach called word to bag is just using a very simple feed forward

203
00:15:22,560 --> 00:15:25,160
neural network with just one layer.

204
00:15:25,160 --> 00:15:30,520
But the latest approach that people are using is more complicated as a bidirectional LSTM

205
00:15:30,520 --> 00:15:37,600
kind of approaches, which tends to give better higher accuracy, but it's probably slower.

206
00:15:37,600 --> 00:15:43,400
So given this language model, the language model tells you this word, for this word, this

207
00:15:43,400 --> 00:15:47,080
is the best vector representation of the word.

208
00:15:47,080 --> 00:15:51,160
So now every word will be represented as a vector.

209
00:15:51,160 --> 00:15:57,880
So given that, now we pair, we tokenize every word into sentences.

210
00:15:57,880 --> 00:16:03,080
And for every pair of word in the sentence, you try to see if there is a dependency

211
00:16:03,080 --> 00:16:04,760
relation or not.

212
00:16:04,760 --> 00:16:07,160
And that's the supervised version.

213
00:16:07,160 --> 00:16:14,720
So now we have a large corpus, about 2.5 million words corpus that actually has an annotated

214
00:16:14,720 --> 00:16:17,520
for this kind of dependency relations.

215
00:16:17,520 --> 00:16:25,560
So the end is that the annotation, is it contextual or is it like engram?

216
00:16:25,560 --> 00:16:26,560
It's a contextual.

217
00:16:26,560 --> 00:16:28,160
It's an actual text.

218
00:16:28,160 --> 00:16:34,520
So a lot of the most famous one, what everyone knows in the field of NLP is called Pantry

219
00:16:34,520 --> 00:16:35,520
Bank.

220
00:16:35,520 --> 00:16:38,760
So that's the 1 million words one.

221
00:16:38,760 --> 00:16:44,080
After that, there is another project called Antonut, which is a big one to note.

222
00:16:44,080 --> 00:16:49,480
So it's yeah, ON to ONTO note.

223
00:16:49,480 --> 00:16:56,240
So this is also another project, and it actually has 2.5 million words, so it's a bigger corpus

224
00:16:56,240 --> 00:16:58,120
with much more genre.

225
00:16:58,120 --> 00:17:04,080
So Pantry Bank was only for the new swire, but Antonut's project had a broadcasting conversation,

226
00:17:04,080 --> 00:17:09,680
broadcasting news, telephone conversation, web blogs, and even the Bibles.

227
00:17:09,680 --> 00:17:14,120
So it has much more different kind of genres, these bigger corpus.

228
00:17:14,120 --> 00:17:19,600
And we also internally have some of this annotation on the medical domain as well.

229
00:17:19,600 --> 00:17:23,320
So all this combined together is making a supervised learning.

230
00:17:23,320 --> 00:17:24,320
Okay.

231
00:17:24,320 --> 00:17:27,480
So that's kind of the graph model.

232
00:17:27,480 --> 00:17:32,920
You also mentioned the transition model, which confused me at first because when I think

233
00:17:32,920 --> 00:17:37,280
of graphs, I think of transitions as these variations between the nose, but it sounds

234
00:17:37,280 --> 00:17:43,680
like what that, that's more of like a, I don't know if you'd call it stateful or stateless,

235
00:17:43,680 --> 00:17:49,760
but like you're looking at the current word at the time, as opposed to the entire relationship

236
00:17:49,760 --> 00:17:51,480
between everything and you're trying to.

237
00:17:51,480 --> 00:17:53,080
You've got the exactly right.

238
00:17:53,080 --> 00:17:54,080
Okay.

239
00:17:54,080 --> 00:17:59,400
So graph based algorithm basically doesn't take in each node as an individual state, it

240
00:17:59,400 --> 00:18:03,640
just take a whole holistic view of the entire graph.

241
00:18:03,640 --> 00:18:09,320
The transition based parsing, however, is looking at a word at a time.

242
00:18:09,320 --> 00:18:14,760
So it's making the transition between one word to the other word and try to see if there

243
00:18:14,760 --> 00:18:19,840
are some word, contextual words around it has the dependency relations.

244
00:18:19,840 --> 00:18:22,440
So that's how the transition based parsing works.

245
00:18:22,440 --> 00:18:27,240
And the advantage of transition based parsing is the parsing complexity is much lower.

246
00:18:27,240 --> 00:18:33,880
So we have, many people actually have written several papers about the parsing complexity

247
00:18:33,880 --> 00:18:37,360
on average, can be as low as the big of n.

248
00:18:37,360 --> 00:18:43,120
So basically, if you have n number of words in the sentence, you need to make about n number

249
00:18:43,120 --> 00:18:45,280
of comparisons to be done.

250
00:18:45,280 --> 00:18:49,360
Whereas graph based parsing, you have to make n squared comparisons.

251
00:18:49,360 --> 00:18:55,960
So that's why transition based parsing is tend to be much faster.

252
00:18:55,960 --> 00:19:04,120
But because it's not comparing every possible pairs, it tends to be a little less accurate.

253
00:19:04,120 --> 00:19:09,680
So, but people were buying the speed over accuracy for a long time period.

254
00:19:09,680 --> 00:19:14,880
So I also focused a lot on the transition based parsing in the past because of the efficiency

255
00:19:14,880 --> 00:19:16,040
reason.

256
00:19:16,040 --> 00:19:22,200
But these days, because of this GPU, now comparing n number of things versus n squared,

257
00:19:22,200 --> 00:19:27,040
actually it's not that much different because everything is done in parallel now.

258
00:19:27,040 --> 00:19:33,760
So a graph based parsing, I couldn't even believe, but it actually is performing as fast

259
00:19:33,760 --> 00:19:35,200
as a transition based parsing.

260
00:19:35,200 --> 00:19:36,200
Okay.

261
00:19:36,200 --> 00:19:42,760
And was the transition based parsing also being done with neural networks?

262
00:19:42,760 --> 00:19:44,840
It can be trained on the neural networks.

263
00:19:44,840 --> 00:19:49,720
So transition versus graph is depending on the parsing algorithm.

264
00:19:49,720 --> 00:19:55,240
So it's a different way of processing the text.

265
00:19:55,240 --> 00:20:01,120
And once you define your parsing algorithm, you can use any kind of machine learning algorithms.

266
00:20:01,120 --> 00:20:07,800
So you can use as easy as logistic regression, like one layer, simple or support vector

267
00:20:07,800 --> 00:20:09,640
machines in all days.

268
00:20:09,640 --> 00:20:15,840
But now everyone is moving on to using neural networks to take advantage of the more accurate

269
00:20:15,840 --> 00:20:17,000
deck.

270
00:20:17,000 --> 00:20:21,360
And so that could be the language parsing piece.

271
00:20:21,360 --> 00:20:27,240
And then the, I can't even read my own hand right here, character mining, character

272
00:20:27,240 --> 00:20:28,240
mining.

273
00:20:28,240 --> 00:20:29,240
Yes.

274
00:20:29,240 --> 00:20:30,240
Yes.

275
00:20:30,240 --> 00:20:34,640
Well, it's on usual title too, so yeah.

276
00:20:34,640 --> 00:20:38,200
And so character mining, so you describe this.

277
00:20:38,200 --> 00:20:44,160
If I'm remembering the scenario, like you've got two or multi-parties in a conversation

278
00:20:44,160 --> 00:20:49,440
and you're trying to basically have the machine understand what there is, like a machine

279
00:20:49,440 --> 00:20:50,440
comprehension.

280
00:20:50,440 --> 00:20:51,440
Right.

281
00:20:51,440 --> 00:20:55,400
But it's, it's like a third-party comprehension, you're trying to comprehend a dialogue.

282
00:20:55,400 --> 00:20:56,400
Exactly.

283
00:20:56,400 --> 00:21:00,880
So yeah, I want to, thanks for pointing that out, actually, you understood this correctly.

284
00:21:00,880 --> 00:21:06,720
So I, yeah, I want to distinguish this project versus like a traditional other, what everyone

285
00:21:06,720 --> 00:21:11,760
is going for as a conversation agent that's like a conversation between the agent, the

286
00:21:11,760 --> 00:21:17,120
computer agent and the human, that's not my goal, because I want to have a third-party

287
00:21:17,120 --> 00:21:20,800
agent that's listening to our conversation.

288
00:21:20,800 --> 00:21:25,160
And if we need something that, if you're missing from this conversation, it can actually,

289
00:21:25,160 --> 00:21:30,280
so the best application for this kind of approach is maybe in your business meeting.

290
00:21:30,280 --> 00:21:35,680
So business meeting, you always have a security writing notes for you.

291
00:21:35,680 --> 00:21:41,400
And this conversation, this character mining project can really help to automate the process.

292
00:21:41,400 --> 00:21:47,600
Or like if you had some birthday party with your son last time, and you forgot what kind

293
00:21:47,600 --> 00:21:53,760
of twist you were going to buy for him, then you are pretty embarrassed to ask to your son

294
00:21:53,760 --> 00:21:54,760
about it.

295
00:21:54,760 --> 00:21:56,760
Then you can ask this to assist you.

296
00:21:56,760 --> 00:21:57,760
Right.

297
00:21:57,760 --> 00:22:00,960
So you can see for all your embarrassment as well.

298
00:22:00,960 --> 00:22:01,960
Yeah.

299
00:22:01,960 --> 00:22:06,480
I'm not sure if it's a good application or a bad application, but I'm imagining all kinds

300
00:22:06,480 --> 00:22:12,560
of domestic applications between husbands and wives.

301
00:22:12,560 --> 00:22:15,760
Alexa, you said they were going to buy the milk?

302
00:22:15,760 --> 00:22:16,760
No.

303
00:22:16,760 --> 00:22:20,800
You know, actually Sam, you said you were going to buy the milk, right?

304
00:22:20,800 --> 00:22:23,600
You have a hard proof phrase.

305
00:22:23,600 --> 00:22:27,680
So, I mean, all this privacy issue actually will come out.

306
00:22:27,680 --> 00:22:32,040
So I don't imagine people would like it to be listening to you all the time.

307
00:22:32,040 --> 00:22:33,040
All the time, right?

308
00:22:33,040 --> 00:22:38,120
Well, I mean, like our conversation like the interview like this is a perfect situation.

309
00:22:38,120 --> 00:22:42,280
If the machine is listening to us, if later on, I wouldn't actually make sure if I said

310
00:22:42,280 --> 00:22:46,520
things right, I don't have to bother you, right?

311
00:22:46,520 --> 00:22:48,880
I can just ask the machine too.

312
00:22:48,880 --> 00:22:51,480
The word character there.

313
00:22:51,480 --> 00:22:52,480
What is the character?

314
00:22:52,480 --> 00:22:53,480
Character is people.

315
00:22:53,480 --> 00:22:54,480
Okay.

316
00:22:54,480 --> 00:22:56,760
Character as a people.

317
00:22:56,760 --> 00:23:01,800
So the project actually is rather fun because it's actually my student's favorite project.

318
00:23:01,800 --> 00:23:07,040
Whenever they come to my lab, research lab, they always want to work on this project instead

319
00:23:07,040 --> 00:23:12,880
of some other one because it's a more high level project.

320
00:23:12,880 --> 00:23:20,160
So I started this because I believe conversation data is going to be the key to natural and

321
00:23:20,160 --> 00:23:22,280
gender understanding in the future.

322
00:23:22,280 --> 00:23:31,240
So I have a kind of evidence for this too because how often do you text all the time?

323
00:23:31,240 --> 00:23:32,560
You can even count, right?

324
00:23:32,560 --> 00:23:36,440
But how often do you, so compare to email, right?

325
00:23:36,440 --> 00:23:40,720
Email you probably pretty frequently, but not as much as text, but if you think about

326
00:23:40,720 --> 00:23:44,400
like blogging, even Twitter stream, right?

327
00:23:44,400 --> 00:23:48,720
All these things, what people are focusing on to do the data money, doesn't even come

328
00:23:48,720 --> 00:23:53,080
close to the conversation you're making on the text.

329
00:23:53,080 --> 00:23:59,000
So conversational data, the amount of the conversation data is growing way, way faster

330
00:23:59,000 --> 00:24:07,400
than any other type of data, but natural language processing is one of the genre NLP is missing

331
00:24:07,400 --> 00:24:08,400
so much.

332
00:24:08,400 --> 00:24:17,120
NLP does very well for newswire kind of formal data, or also even like a Twitter kind of social

333
00:24:17,120 --> 00:24:20,640
media data, people have been vaccinated for past 10 years.

334
00:24:20,640 --> 00:24:25,880
So they are doing very well for those domains at the moment, but conversation data is still

335
00:24:25,880 --> 00:24:27,560
hugely lacking.

336
00:24:27,560 --> 00:24:31,840
That's why this Alexa actually, Alexa Price, this kind of challenge is a very challenging

337
00:24:31,840 --> 00:24:32,840
task.

338
00:24:32,840 --> 00:24:33,840
And what's the Alexa Price?

339
00:24:33,840 --> 00:24:44,080
Oh, Alexa Price is, so we're in the, we're in the, the win, or one of the win hotels

340
00:24:44,080 --> 00:24:45,080
and...

341
00:24:45,080 --> 00:24:46,080
What are you looking for?

342
00:24:46,080 --> 00:24:47,080
Okay.

343
00:24:47,080 --> 00:24:48,080
Oh, you guessed it.

344
00:24:48,080 --> 00:24:49,080
Yeah, yeah, yeah.

345
00:24:49,080 --> 00:24:51,840
Stop, let's just stop.

346
00:24:51,840 --> 00:24:52,840
It's not there yet.

347
00:24:52,840 --> 00:24:55,720
So I've just muted it again.

348
00:24:55,720 --> 00:25:00,560
So we're in the, the win hotel, and some folks may remember that a couple of years ago,

349
00:25:00,560 --> 00:25:06,600
I think it may have been here at a reinvent, Amazon and the win hotels announced that they

350
00:25:06,600 --> 00:25:09,560
were putting an Alexa in every hotel room.

351
00:25:09,560 --> 00:25:10,560
Really?

352
00:25:10,560 --> 00:25:11,560
They did.

353
00:25:11,560 --> 00:25:12,560
Yeah.

354
00:25:12,560 --> 00:25:13,560
That's just part of the hotel room.

355
00:25:13,560 --> 00:25:14,960
Oh, actually, you didn't bring this.

356
00:25:14,960 --> 00:25:17,240
No, no, it was a part of the hotel.

357
00:25:17,240 --> 00:25:19,560
It's actually pretty awesome.

358
00:25:19,560 --> 00:25:21,800
Alexa, open the drapes.

359
00:25:21,800 --> 00:25:24,800
Oh my God.

360
00:25:24,800 --> 00:25:25,800
That's pretty cool, isn't it?

361
00:25:25,800 --> 00:25:26,800
Full motivation.

362
00:25:26,800 --> 00:25:27,800
Yeah.

363
00:25:27,800 --> 00:25:28,800
Hotel automation, in this case.

364
00:25:28,800 --> 00:25:29,800
Yeah.

365
00:25:29,800 --> 00:25:35,600
So yeah, Alexa Price is a competition that allows research to show off their research skills

366
00:25:35,600 --> 00:25:36,600
on the conversation agent.

367
00:25:36,600 --> 00:25:37,600
Okay.

368
00:25:37,600 --> 00:25:43,040
So they had a huge competition, and one of my colleagues from Emory actually participated

369
00:25:43,040 --> 00:25:45,680
and they were very close to win the third place.

370
00:25:45,680 --> 00:25:47,720
I think they won the fourth place.

371
00:25:47,720 --> 00:25:52,280
So they were not one of the finalists, but yeah, next year, probably.

372
00:25:52,280 --> 00:25:54,760
And what's the problem, problem formulation of...

373
00:25:54,760 --> 00:25:57,680
The problem formulation is you are supposed to be...

374
00:25:57,680 --> 00:26:04,880
So there are many judges for this competition, and each judges basically talk freely in

375
00:26:04,880 --> 00:26:05,880
open domain.

376
00:26:05,880 --> 00:26:07,680
It's not necessarily even questions.

377
00:26:07,680 --> 00:26:11,880
You're just trying to make a conversation with Alexa.

378
00:26:11,880 --> 00:26:18,040
And if judge feels it actually is in the into the level of the satisfaction, they give

379
00:26:18,040 --> 00:26:24,240
some kind of scores, and they gather all those scores to see who actually has the best

380
00:26:24,240 --> 00:26:25,240
model.

381
00:26:25,240 --> 00:26:30,680
Because it's open-ended, kind of like gymnastics in the Olympics, you're trying to impress

382
00:26:30,680 --> 00:26:32,480
the judges with what Alexa can understand.

383
00:26:32,480 --> 00:26:33,480
Exactly.

384
00:26:33,480 --> 00:26:34,480
Oh, wow.

385
00:26:34,480 --> 00:26:35,480
That's...

386
00:26:35,480 --> 00:26:36,480
And it sounds like it's an ongoing...

387
00:26:36,480 --> 00:26:37,480
It is an...

388
00:26:37,480 --> 00:26:38,480
It's been there for...

389
00:26:38,480 --> 00:26:41,000
I know it's been there at least for two years.

390
00:26:41,000 --> 00:26:42,480
I think it's been...

391
00:26:42,480 --> 00:26:45,480
And I know they are going to do again for sure next year.

392
00:26:45,480 --> 00:26:52,080
The first year was the winner of the competition actually gets $1 million, so it's a serious

393
00:26:52,080 --> 00:26:53,080
deal.

394
00:26:53,080 --> 00:26:57,760
From the faculty point of view, it's not just a prize, but it's also a very intellectually

395
00:26:57,760 --> 00:27:00,200
challenging problem too, so it's very interesting.

396
00:27:00,200 --> 00:27:06,960
Plus, I mean, they actually give out the support for AWS Cloud Computing and also the PhD students.

397
00:27:06,960 --> 00:27:10,800
If you are selected, one of the top-aids teams, so...

398
00:27:10,800 --> 00:27:14,120
You were talking about how we've got all this news.

399
00:27:14,120 --> 00:27:20,640
You know, we have a mature set of practices for applying this type of analysis to news.

400
00:27:20,640 --> 00:27:28,120
We've got kind of these news data sets where much further behind and conversational.

401
00:27:28,120 --> 00:27:30,240
Is it like a chicken and an egg kind of problem?

402
00:27:30,240 --> 00:27:34,320
Like, we don't have the data set because we haven't been working on it as hard and...

403
00:27:34,320 --> 00:27:41,280
And so, I mean, I think it was basically based on the initial interest of the NLP.

404
00:27:41,280 --> 00:27:47,160
So initially, as I mentioned, the Pantry Bank was the largest corpus that we had for a

405
00:27:47,160 --> 00:27:48,160
while.

406
00:27:48,160 --> 00:27:54,320
And it's not anymore, but it's still one of those initial tribank that was...

407
00:27:54,320 --> 00:27:59,440
That allowed us to do any meaningful statistical based natural image processing.

408
00:27:59,440 --> 00:28:00,440
So...

409
00:28:00,440 --> 00:28:04,200
And I think their intention originally was to analyze news data.

410
00:28:04,200 --> 00:28:07,400
So that's why they chose the genre of the news.

411
00:28:07,400 --> 00:28:11,720
If they chose the genre of like conversation data, it would have been probably a good

412
00:28:11,720 --> 00:28:13,680
guarantee to that side.

413
00:28:13,680 --> 00:28:17,000
But I mean, government had their own reasons, right?

414
00:28:17,000 --> 00:28:22,600
So and the tricky part about the conversation data though, would you be willing to give

415
00:28:22,600 --> 00:28:24,360
out your text data to other people?

416
00:28:24,360 --> 00:28:31,600
I was thinking about this as you're describing this like, you know, if, yeah, I'm thinking

417
00:28:31,600 --> 00:28:36,040
about like what kind of incentive system, you know, some app might have to put into place

418
00:28:36,040 --> 00:28:41,480
so that, you know, a user would buy into the idea of using this messaging system knowing

419
00:28:41,480 --> 00:28:43,440
that they were sending all their data someplace.

420
00:28:43,440 --> 00:28:44,440
That's a tough ask.

421
00:28:44,440 --> 00:28:52,120
Yeah, yeah, so I mean, I even tried to ask my own student and I actually even tried to

422
00:28:52,120 --> 00:28:56,800
sign up some kind of form to them that I would not reveal this data to anyone else.

423
00:28:56,800 --> 00:29:01,560
But I mean, there were actually students who were willing to just give to me, but most

424
00:29:01,560 --> 00:29:03,640
of them said no, obviously.

425
00:29:03,640 --> 00:29:09,560
So that was the first barrier we couldn't find a good large amount of data that has a human

426
00:29:09,560 --> 00:29:10,920
conversation.

427
00:29:10,920 --> 00:29:19,320
So the closest data that we found is Twitter, actually coming from the TV shows.

428
00:29:19,320 --> 00:29:27,920
So we got the 10 years of the transcript from the show called Friends, which, so that

429
00:29:27,920 --> 00:29:33,120
show does have some use, exactly, and basically everyone knows that you and they're making

430
00:29:33,120 --> 00:29:36,280
reruns for another 10 years now, right?

431
00:29:36,280 --> 00:29:42,760
So we actually made the effort to make the transcript, it was transcript actually was done

432
00:29:42,760 --> 00:29:47,000
by all the fan-based, but none of them was structured.

433
00:29:47,000 --> 00:29:51,480
So we actually had to spend a year to make the data structurized.

434
00:29:51,480 --> 00:29:58,720
After that, we have a fairly clean data for this script and we particularly liked this

435
00:29:58,720 --> 00:30:02,720
show because this show is not talking a particular thing.

436
00:30:02,720 --> 00:30:03,720
It's just not jargonous.

437
00:30:03,720 --> 00:30:04,720
Exactly.

438
00:30:04,720 --> 00:30:05,720
Life.

439
00:30:05,720 --> 00:30:06,720
Yeah.

440
00:30:06,720 --> 00:30:07,720
For people.

441
00:30:07,720 --> 00:30:12,160
But so that's why we chose this over some other shows.

442
00:30:12,160 --> 00:30:18,240
So even that is involving a lot more like humorous sarcasm.

443
00:30:18,240 --> 00:30:19,240
Right.

444
00:30:19,240 --> 00:30:24,840
So when we talk about it right now, so we don't make so as much humor or sarcasm or all

445
00:30:24,840 --> 00:30:28,600
this metaphors, they intentionally do so much time.

446
00:30:28,600 --> 00:30:33,280
So people think these scripted languages are actually easier to process, but they're

447
00:30:33,280 --> 00:30:36,640
actually harder because of all these reasons.

448
00:30:36,640 --> 00:30:42,880
So anyway, so we have that data now and given the data, the first experiment we ran is,

449
00:30:42,880 --> 00:30:47,800
is it possible to tell like when you talk, when these people are talking to each other,

450
00:30:47,800 --> 00:30:54,280
is it possible to tell who is talking to others or if, say, to one of the character in the

451
00:30:54,280 --> 00:31:01,200
friends and named Ross, his sister is also in the show called Monica and they are Ross

452
00:31:01,200 --> 00:31:06,000
and Monica are talking together and they're talking about their mom and dad.

453
00:31:06,000 --> 00:31:10,040
And their mom and dad actually appears some other episodes.

454
00:31:10,040 --> 00:31:15,400
So we were trying to experiment, is it possible when they talk mom and dad, if the machine

455
00:31:15,400 --> 00:31:19,840
will be able to figure out who that mom actually is?

456
00:31:19,840 --> 00:31:22,680
So like entity disambiguation.

457
00:31:22,680 --> 00:31:24,360
So what we call entity linking.

458
00:31:24,360 --> 00:31:25,360
Entity linking.

459
00:31:25,360 --> 00:31:28,360
Entity disambigation is also right terminology.

460
00:31:28,360 --> 00:31:34,600
So yeah, so basically you have to listen to the entire show, pretty much the entire show,

461
00:31:34,600 --> 00:31:39,440
but usually those people are gonna appear within next few episodes, so you don't have

462
00:31:39,440 --> 00:31:45,920
to search that much, but your search space is still out of like 400 characters, out

463
00:31:45,920 --> 00:31:52,480
of 400 characters, which one of these is mom, Ross's mom, Monica's mom.

464
00:31:52,480 --> 00:31:59,400
So that's the first test we ran, we actually even ran the international, what we call

465
00:31:59,400 --> 00:32:04,640
semi-veils, the semantic evaluation test last year and I think it was well received.

466
00:32:04,640 --> 00:32:09,720
A lot of people get very much interest and I'm still getting a lot of requests from the

467
00:32:09,720 --> 00:32:10,720
people too.

468
00:32:10,720 --> 00:32:17,160
So that was the first test, we need to figure out like who these people are talking about.

469
00:32:17,160 --> 00:32:20,840
So that was the first part of the character mining project.

470
00:32:20,840 --> 00:32:24,320
So second task that we tackled.

471
00:32:24,320 --> 00:32:29,520
And if I can just ask a question about that, you're doing that in a totally model free

472
00:32:29,520 --> 00:32:30,520
way.

473
00:32:30,520 --> 00:32:37,320
It's all happening with kind of a flat algorithm as opposed to pre-processing to identify

474
00:32:37,320 --> 00:32:41,880
people and then remembering the people that are talked about and kind of linking.

475
00:32:41,880 --> 00:32:47,960
It's not bad, it's like just running, you know, kind of training a neural network on

476
00:32:47,960 --> 00:32:48,960
this.

477
00:32:48,960 --> 00:32:53,200
So having the neural network, you send in a sentence and having the neural network point

478
00:32:53,200 --> 00:32:57,960
you to the sentence that refers back to the people that you're talking about.

479
00:32:57,960 --> 00:32:58,960
It could be so.

480
00:32:58,960 --> 00:32:59,960
For example.

481
00:32:59,960 --> 00:33:00,960
For example.

482
00:33:00,960 --> 00:33:01,960
Exactly.

483
00:33:01,960 --> 00:33:05,920
So you sent it different from traditional entity linking task which is also known as

484
00:33:05,920 --> 00:33:07,560
a wikipication.

485
00:33:07,560 --> 00:33:13,440
So wikipication is another entity linking task, much more well-known, which is given

486
00:33:13,440 --> 00:33:19,920
like a name, like Lincoln, you find a wikipedia page for that link.

487
00:33:19,920 --> 00:33:22,200
So you have to do some disambigation as well.

488
00:33:22,200 --> 00:33:26,640
Lincoln can be a link on hall or a link on bridge or actually every link.

489
00:33:26,640 --> 00:33:27,640
Yeah.

490
00:33:27,640 --> 00:33:28,960
So so many different links, right?

491
00:33:28,960 --> 00:33:34,240
So that, but those task has significant advantage that all those entities are already

492
00:33:34,240 --> 00:33:35,240
well-known.

493
00:33:35,240 --> 00:33:39,760
So you already have some good knowledge base established for this entities.

494
00:33:39,760 --> 00:33:43,120
But for this show, we don't have any of these knowledge.

495
00:33:43,120 --> 00:33:48,080
We are not assuming any of these knowledge base, basically the machine has to listen

496
00:33:48,080 --> 00:33:53,240
to these conversations and figure out if there's a link between these mentions.

497
00:33:53,240 --> 00:33:57,560
So it's a much more challenging task as in sense, yeah.

498
00:33:57,560 --> 00:34:04,280
And so you talked about another couple of projects, the kind of what I have is what I got

499
00:34:04,280 --> 00:34:08,520
out of that was like interpreting structure and kind of semi-structured reports, like

500
00:34:08,520 --> 00:34:09,520
medical reports.

501
00:34:09,520 --> 00:34:10,520
Oh, yeah.

502
00:34:10,520 --> 00:34:11,520
Yes.

503
00:34:11,520 --> 00:34:16,760
And another one, which is a really interesting application of identifying the early indicators

504
00:34:16,760 --> 00:34:21,480
of cognitive impairment through speech.

505
00:34:21,480 --> 00:34:26,600
But as we're kind of coming up on the end of our time here, I did want to ask you about

506
00:34:26,600 --> 00:34:33,240
one of the presentations you gave here at re-event about this NLP platform that you built.

507
00:34:33,240 --> 00:34:37,000
What is the NLP platform that you built?

508
00:34:37,000 --> 00:34:41,200
So this is a project called Elite ELIT.

509
00:34:41,200 --> 00:34:47,000
So it's short for evolution of language and information technology.

510
00:34:47,000 --> 00:34:53,080
We call this evolution because I think the way that people are doing language technology

511
00:34:53,080 --> 00:34:58,440
has to be evolved into the modern computing technology.

512
00:34:58,440 --> 00:35:05,080
So what I mean by that also is all these natural language processing models lately, as I said,

513
00:35:05,080 --> 00:35:08,240
are making heavy use of deep learning.

514
00:35:08,240 --> 00:35:15,080
Deep learning is a neural network with multiple layers and it requires a lot of computations.

515
00:35:15,080 --> 00:35:21,200
Because of this, to run, to train or decode any of the state of our models, you really

516
00:35:21,200 --> 00:35:25,400
need to have a very high computing GPU power.

517
00:35:25,400 --> 00:35:32,240
All days, when I was actually my PhD dissertation was purely focused on the efficiency of NLP

518
00:35:32,240 --> 00:35:39,640
models, how to make the model as small as possible while not losing accuracy.

519
00:35:39,640 --> 00:35:41,840
So you can actually run on your laptop.

520
00:35:41,840 --> 00:35:46,560
So all my models were able to, you could run on your laptop, as long as you have like

521
00:35:46,560 --> 00:35:48,640
a three gigabyte sub-ramp.

522
00:35:48,640 --> 00:35:55,080
But now, because after all this neural network error, it's almost impossible to run this

523
00:35:55,080 --> 00:36:03,400
into your local machines. So a lot of researchers are having difficulties of making use of this

524
00:36:03,400 --> 00:36:04,400
technology.

525
00:36:04,400 --> 00:36:09,400
And when we're talking about the size, are we talking about training or inference?

526
00:36:09,400 --> 00:36:10,400
Both.

527
00:36:10,400 --> 00:36:11,400
Okay.

528
00:36:11,400 --> 00:36:16,800
So for both training and inference, you do need a GPU to run this neural network models.

529
00:36:16,800 --> 00:36:21,600
At least if you want to run the state of the art models, not the simple toy models,

530
00:36:21,600 --> 00:36:23,280
but really good models.

531
00:36:23,280 --> 00:36:27,760
And in all days, before neural network with the linear models, it was still possible

532
00:36:27,760 --> 00:36:31,200
to optimize those models to make it very small.

533
00:36:31,200 --> 00:36:36,480
So without losing so much accuracy, so you could just run any researchers like linguist

534
00:36:36,480 --> 00:36:39,880
or historian, they could just run on their laptops.

535
00:36:39,880 --> 00:36:44,840
So these people still want to take advantage of all these latest technology that we are

536
00:36:44,840 --> 00:36:48,000
developing, which are tons and tons.

537
00:36:48,000 --> 00:36:53,760
But now it's literally impossible for anybody who doesn't have these high computing machines

538
00:36:53,760 --> 00:36:56,360
to run this kind of models.

539
00:36:56,360 --> 00:37:02,280
So there is a solution for it, which we found a solution from a cloud computing.

540
00:37:02,280 --> 00:37:09,440
So the platform, the elite platform that we are developing is a SaaS architecture.

541
00:37:09,440 --> 00:37:14,720
So we are bringing all our natural language processing models to the cloud.

542
00:37:14,720 --> 00:37:18,800
So anybody in the world can actually call this as a web API.

543
00:37:18,800 --> 00:37:24,840
Just like the way you use Google search, you can just send your text and it will send

544
00:37:24,840 --> 00:37:30,160
you back your NLP result with a simple HTTP call.

545
00:37:30,160 --> 00:37:36,520
And so is this a generic platform that you can then plug in these different projects

546
00:37:36,520 --> 00:37:42,280
as the types, the calls that you would make and you would get back?

547
00:37:42,280 --> 00:37:49,120
And so what I just described about web API in SaaS environment, that was the original

548
00:37:49,120 --> 00:37:51,560
intention for our lab.

549
00:37:51,560 --> 00:37:57,440
So because we actually started having so much needs of running this NLP models.

550
00:37:57,440 --> 00:38:02,240
So we actually developed the SaaS architecture for ourselves first.

551
00:38:02,240 --> 00:38:07,480
So my students can actually just use that without installing anything on their local machines.

552
00:38:07,480 --> 00:38:13,280
But we tried to bring that up to the cloud so everyone in the world can actually use it.

553
00:38:13,280 --> 00:38:17,880
And thanks to AWS, who has been supporting us for making this happen.

554
00:38:17,880 --> 00:38:21,800
But now the intention actually became much more interesting.

555
00:38:21,800 --> 00:38:29,600
So the motivation at the moment now is we want to invite all NLP community, people to

556
00:38:29,600 --> 00:38:33,440
contribute their models to this cloud.

557
00:38:33,440 --> 00:38:39,640
So this is actually huge because how many papers do you think are getting published every

558
00:38:39,640 --> 00:38:42,640
year to like top three conferences?

559
00:38:42,640 --> 00:38:47,280
NLP or NLP, like top three conferences in LLP.

560
00:38:47,280 --> 00:38:56,000
Gosh, how many papers a year to the top three conferences in NLP, 2,500?

561
00:38:56,000 --> 00:38:57,520
It's still 1,000.

562
00:38:57,520 --> 00:38:58,520
All right.

563
00:38:58,520 --> 00:38:59,520
Yeah.

564
00:38:59,520 --> 00:39:00,520
I didn't do the count.

565
00:39:00,520 --> 00:39:15,880
But even the workshop papers and all NLP, I would imagine like a 5,000 of those.

566
00:39:15,880 --> 00:39:23,080
So in every single paper, basically claims they have the best model of some sort, right?

567
00:39:23,080 --> 00:39:25,320
Otherwise, you wouldn't be published.

568
00:39:25,320 --> 00:39:30,480
So every paper has developed some kind of model that has some value.

569
00:39:30,480 --> 00:39:36,160
How many of them are actually getting used, right, less than few percent?

570
00:39:36,160 --> 00:39:38,280
So why is that though?

571
00:39:38,280 --> 00:39:43,520
These PhD students are spending at least five years of their life dedicated to develop

572
00:39:43,520 --> 00:39:47,760
these models and after they graduate, nobody uses it.

573
00:39:47,760 --> 00:39:53,200
So I think this is a issue and it's a very depressing issue to me at least because I want

574
00:39:53,200 --> 00:39:58,920
all like the models that we develop are has to be getting used in some sense, but it's

575
00:39:58,920 --> 00:40:01,600
not getting used at all, right?

576
00:40:01,600 --> 00:40:09,360
So it strikes me that some of that issue is accessibility and cloud and platforms dress

577
00:40:09,360 --> 00:40:10,360
that.

578
00:40:10,360 --> 00:40:16,400
But if there's also the assumptions that the model makes, a lot of them are rather limiting

579
00:40:16,400 --> 00:40:18,400
for actual use.

580
00:40:18,400 --> 00:40:19,400
Excellent.

581
00:40:19,400 --> 00:40:20,400
That's an excellent point.

582
00:40:20,400 --> 00:40:25,440
That's what I want to actually open up the free platform for people to actually show

583
00:40:25,440 --> 00:40:28,200
off your model actually works well.

584
00:40:28,200 --> 00:40:29,200
Right?

585
00:40:29,200 --> 00:40:34,760
So yes, you have proof that your model has value in your paper in this sense, but does

586
00:40:34,760 --> 00:40:40,560
it actually do the right thing for real application or your application?

587
00:40:40,560 --> 00:40:49,040
So if the developers or the researchers truly believe their model has value, they can deploy

588
00:40:49,040 --> 00:40:54,480
their model to our platform and anybody in the world can test it out.

589
00:40:54,480 --> 00:41:00,080
And see, okay, this model actually does work really well, then it gets promoted.

590
00:41:00,080 --> 00:41:05,040
So we will actually have to show the ranking of the usage of the models as well.

591
00:41:05,040 --> 00:41:10,520
So anybody in the world can actually see, okay, this model does well for this kind of

592
00:41:10,520 --> 00:41:11,520
event.

593
00:41:11,520 --> 00:41:15,040
And we can actually include to the discussion forum to see, okay, this model didn't do

594
00:41:15,040 --> 00:41:19,200
well for this genre, but this genre it did exceptionally well.

595
00:41:19,200 --> 00:41:22,640
So users can actually write their reviews about this.

596
00:41:22,640 --> 00:41:26,240
It's like that's what the technology should be, right?

597
00:41:26,240 --> 00:41:31,120
When you have a new phone, when you have new technology, there's so many reviewers write

598
00:41:31,120 --> 00:41:33,320
the reviews about it.

599
00:41:33,320 --> 00:41:39,280
But our in academic world, what happens is you saw me on paper, the paper gets reviewed

600
00:41:39,280 --> 00:41:45,040
by three reviewers and that was it later on people forget about it.

601
00:41:45,040 --> 00:41:48,800
But actual usage can be now reviewed by people.

602
00:41:48,800 --> 00:41:53,480
So this is I think a very exciting part, also another part that I really want to focus

603
00:41:53,480 --> 00:41:59,480
on is I believe there are a lot of models that are really good, but are not getting published

604
00:41:59,480 --> 00:42:01,400
for some reason.

605
00:42:01,400 --> 00:42:07,160
So for many different reasons, we all know this, sometimes this review system doesn't work

606
00:42:07,160 --> 00:42:08,800
on some others.

607
00:42:08,800 --> 00:42:16,200
So and also another thing is somebody actually is not really intended to invent some algorithm,

608
00:42:16,200 --> 00:42:21,760
but they replicate someone else's work, but happen to have a better performance.

609
00:42:21,760 --> 00:42:26,560
And the academic conferences don't allow you to really write papers about this, replicating

610
00:42:26,560 --> 00:42:28,160
someone else's work.

611
00:42:28,160 --> 00:42:31,800
There are some venues, but usually it's not as valued.

612
00:42:31,800 --> 00:42:36,760
But now these people can actually deploy all their models to our platform, then they

613
00:42:36,760 --> 00:42:41,720
can actually show, okay, so I use the same algorithm, but my model actually works more

614
00:42:41,720 --> 00:42:47,640
efficiently or better in some sense, so please take a try out and see if it actually works

615
00:42:47,640 --> 00:42:48,640
well.

616
00:42:48,640 --> 00:42:54,760
So you have to open the door to the developers and researchers to show off how well of engineering

617
00:42:54,760 --> 00:43:00,320
or like researchers they have done and prove it to the world from the practical point of

618
00:43:00,320 --> 00:43:01,320
view.

619
00:43:01,320 --> 00:43:07,120
How does a researcher format their model to submit it to your platform?

620
00:43:07,120 --> 00:43:08,120
Right.

621
00:43:08,120 --> 00:43:14,280
So I tried so many different ways, I have an NLP platform called, it used to be called

622
00:43:14,280 --> 00:43:17,480
clear NLP, now it's called NLP4J.

623
00:43:17,480 --> 00:43:23,080
So this platform has been used quite a bit by industry and academics.

624
00:43:23,080 --> 00:43:27,960
So I used to get at least 500 downloads every month about this software.

625
00:43:27,960 --> 00:43:30,760
So it was a huge project.

626
00:43:30,760 --> 00:43:37,640
The lesson I learned from that is you should not force developers to write their code

627
00:43:37,640 --> 00:43:39,560
into some kind of architecture.

628
00:43:39,560 --> 00:43:40,560
They are not going to fall.

629
00:43:40,560 --> 00:43:44,680
They have their own architecture already, and they are not going to follow whatever you

630
00:43:44,680 --> 00:43:47,120
think is the best for them, right?

631
00:43:47,120 --> 00:43:50,160
So I'm going to give complete freedom to develop.

632
00:43:50,160 --> 00:43:52,440
You can write your model in any way you want.

633
00:43:52,440 --> 00:43:56,440
The only thing that I want to standardize is the IO format.

634
00:43:56,440 --> 00:44:00,840
Input and output format, which in natural and its processing is pretty standard.

635
00:44:00,840 --> 00:44:03,440
The input is text, right?

636
00:44:03,440 --> 00:44:07,440
Output is some kind of generated labels that you have.

637
00:44:07,440 --> 00:44:14,840
So basically, we are putting, given the input text, you are actually generating a dictionary

638
00:44:14,840 --> 00:44:17,760
that has a label of your task.

639
00:44:17,760 --> 00:44:25,080
So once that part is standardized, then all these models can actually even work together.

640
00:44:25,080 --> 00:44:30,520
So this is another unique part about our platform, or rather about natural and its processing.

641
00:44:30,520 --> 00:44:34,040
A lot of models need to work together.

642
00:44:34,040 --> 00:44:36,280
They're not working independently.

643
00:44:36,280 --> 00:44:40,840
So this is a very unique thing, and because of this, if you actually standardize their

644
00:44:40,840 --> 00:44:48,160
IO format, they can actually take advantage of all the other models and extract features

645
00:44:48,160 --> 00:44:51,280
from those models to make even better models.

646
00:44:51,280 --> 00:44:58,920
So I think from the research and user point of view, they can choose any of the models

647
00:44:58,920 --> 00:45:04,040
that deploy to the platform, and you can actually try out which one works better for you.

648
00:45:04,040 --> 00:45:08,000
And the best thing is you don't even have to install anything on your machine.

649
00:45:08,000 --> 00:45:11,080
So you can just call it out from the web and get all the results.

650
00:45:11,080 --> 00:45:18,200
So is the developer, the researcher, are they zipping up a Python folder, or whatever?

651
00:45:18,200 --> 00:45:23,560
Are they zipping something up, and maybe some kind of JSON to tell you where they need

652
00:45:23,560 --> 00:45:31,560
to get their IO, or is it containers, or what's the actual format of the algorithms

653
00:45:31,560 --> 00:45:32,560
that they're submitting?

654
00:45:32,560 --> 00:45:39,320
Right. So we have released SDK, as of yesterday.

655
00:45:39,320 --> 00:45:41,320
So we have SDK for Python.

656
00:45:41,320 --> 00:45:43,960
Oh, you did a big launch here at EOS.

657
00:45:43,960 --> 00:45:52,000
Well, we didn't make an official announcement, but the packages are on the release now.

658
00:45:52,000 --> 00:45:53,000
People can use it.

659
00:45:53,000 --> 00:45:56,000
They don't know where the link is probably.

660
00:45:56,000 --> 00:46:00,760
So as soon as I go back to Atlanta, I'm going to actually try to make a big announcement

661
00:46:00,760 --> 00:46:01,760
about this.

662
00:46:01,760 --> 00:46:07,440
But yeah, so we have SDK that provides you abstract classes, basically.

663
00:46:07,440 --> 00:46:13,040
So as a matter of fact, there's only one abstract class with four abstract functions.

664
00:46:13,040 --> 00:46:16,200
And that's all we're asking you to overwrite.

665
00:46:16,200 --> 00:46:19,760
So you can completely independently develop your model.

666
00:46:19,760 --> 00:46:21,200
Sounds very job-ish.

667
00:46:21,200 --> 00:46:22,200
Yeah.

668
00:46:22,200 --> 00:46:28,200
I'm coming from object-oriented programming background, so it's not really Python-like, but I get

669
00:46:28,200 --> 00:46:29,200
that.

670
00:46:29,200 --> 00:46:34,160
Well, yeah, so we have an environment developed for both Python and Java.

671
00:46:34,160 --> 00:46:36,840
So if you are a Java programmer, you can just submit.

672
00:46:36,840 --> 00:46:40,520
And that was also another great thing about cloud computing, right?

673
00:46:40,520 --> 00:46:45,600
So now these models that's written in either Python or Java can work together, because

674
00:46:45,600 --> 00:46:52,840
it will be connected by the network and communicating between the AWS instances is really fast.

675
00:46:52,840 --> 00:46:53,840
Right.

676
00:46:53,840 --> 00:46:55,760
Do you have a web page for it yet?

677
00:46:55,760 --> 00:46:56,760
Yes.

678
00:46:56,760 --> 00:47:00,280
The project is called at least in the web page is elite.cloud.

679
00:47:00,280 --> 00:47:01,280
Oh, nice.

680
00:47:01,280 --> 00:47:02,280
So E-L-I-T.cloud.

681
00:47:02,280 --> 00:47:03,280
All right.

682
00:47:03,280 --> 00:47:04,280
Sounds interesting.

683
00:47:04,280 --> 00:47:10,560
Well, thank you so much for taking the time to chat with me about what you're up to.

684
00:47:10,560 --> 00:47:12,560
It was a really interesting stuff.

685
00:47:12,560 --> 00:47:13,560
Thank you very much.

686
00:47:13,560 --> 00:47:15,560
And yeah, time flies.

687
00:47:15,560 --> 00:47:16,560
It was very exciting.

688
00:47:16,560 --> 00:47:17,560
Yeah.

689
00:47:17,560 --> 00:47:18,560
Thank you.

690
00:47:18,560 --> 00:47:19,560
Yeah.

691
00:47:19,560 --> 00:47:20,560
I had a lot of fun.

692
00:47:20,560 --> 00:47:21,560
Thank you.

693
00:47:21,560 --> 00:47:26,560
All right, everyone, that's our show for today.

694
00:47:26,560 --> 00:47:33,160
For more information on Geno or any of the topics covered in this episode, visit twomolei.com

695
00:47:33,160 --> 00:47:36,520
slash talk slash 206.

696
00:47:36,520 --> 00:48:05,240
As always, thanks so much for listening and catch you next time.

