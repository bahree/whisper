WEBVTT

00:00.000 --> 00:05.040
All right, everyone. Welcome to another episode of the Twemal AI podcast. I am your host,

00:05.040 --> 00:10.640
Sam Charrington. And today I'm joined by Ken Goldberg, the professor of industrial engineering

00:10.640 --> 00:16.880
and operations research, and the William S. Floyd Jr. Distinguished Chair in Engineering at UC

00:16.880 --> 00:23.280
Berkeley. Ken is also the chief scientist at MB Robotics. Before we get going, be sure to take

00:23.280 --> 00:28.880
a moment to hit that subscribe button wherever you're listening to today's show. Ken, it has been a

00:28.880 --> 00:33.600
bit. Welcome back to the podcast. Thank you, Sam. It's a pleasure. I've been enjoying listening to

00:33.600 --> 00:39.200
your shows over the last couple of years. Awesome. Yeah, it is hard to believe that it has been two

00:39.200 --> 00:46.560
and a half years since the last time we spoke. Of course, a ton has been happening in Robotics.

00:46.560 --> 00:52.160
And I guess we're going to use this next next little bit for you to catch us up on everything.

00:52.160 --> 00:58.720
Well, it's been actually an amazing time. I mean, with the pandemic, obviously, we were in the

00:58.720 --> 01:04.560
middle of it when we last talked. And so much has happened. I would say that it's actually been a

01:04.560 --> 01:10.160
very productive time for Robotics. That people have made enormous amounts of progress. There's a

01:10.160 --> 01:16.320
lot of publications, a lot of research that's been going on. And also the world has changed in

01:16.320 --> 01:23.360
interesting ways that I think is as favorable to Robotics as a field. Absolutely. Absolutely.

01:23.360 --> 01:31.280
Now, I'll refer folks back to our conversation that was episode number 359 back in March of 2020,

01:31.280 --> 01:38.400
the third wave of robotic learning for a great conversation in your full background. But for those

01:38.400 --> 01:44.240
who, you know, haven't caught that, why don't you share a little bit about how you came into

01:44.240 --> 01:52.320
Robotics? Well, I was, I've been interested in robots since I was a kid. And back in the old days

01:52.320 --> 02:04.800
of Star Trek and Waston Space. And I've just continued that for, you know, 50 years. And what I

02:04.800 --> 02:15.600
have to say is I rediscovered Robotics as an undergrad. And found that it was just absolutely a

02:15.600 --> 02:20.640
fascinating set of questions. I was lucky to have a great advisor, Regina Bicci. It was at

02:20.640 --> 02:27.040
UPEN. At the time, she took me under a wing, really mentored me. And she's still a good friend.

02:27.040 --> 02:32.640
She was at Berkeley for many years now back at Penn. And then I went to Carnegie Mellon where I

02:32.640 --> 02:42.720
worked with both Matt Mason and also for a little bit with Mark Rayburt. And so I had just the

02:42.720 --> 02:48.800
opportunity to work right at the heart of where robotics has been, had been start growing. And I

02:48.800 --> 02:54.640
took an interest in one particular problem, which was grasping. And I, I've been working on the

02:54.640 --> 03:02.560
same problem for 35 years. Which says a lot about how hard that problem is. Exactly. Exactly.

03:02.560 --> 03:06.480
You know, it's interesting because most, you know, I think everyone on this, who's listening to

03:06.480 --> 03:11.920
this knows that it's a, it's a hard problem for robots. But it's still interesting for the public

03:11.920 --> 03:17.680
that most people, you know, we humans do this effortlessly. It's very easy to pick up almost

03:17.680 --> 03:23.600
anything, right? That we, you're handed. In fact, my dog can pick up almost anything with a parallel

03:23.600 --> 03:27.680
jog ripper, right? It's, it's a, it's a, it's a, it's a, and it quickens out, you know, you can pull

03:27.680 --> 03:31.680
out some very weird shaped object and it'll quickly figure out where to grasp it.

03:31.680 --> 03:37.760
That is a fascinating skill. But if you do that in front of a robot, it is, we're very far from

03:37.760 --> 03:44.480
being able to, to do that reliably. Yeah. I think one of the things, um, and kind of looking over

03:44.480 --> 03:51.600
some of your recent work that most jumped out at me as indicative of the kind of progress we've made

03:51.600 --> 04:00.640
is a paper that you worked on with your team autonomously untangling long cables. And I guess that

04:00.640 --> 04:07.600
struck me because I remembered back to, I don't, it must have been maybe four or five years ago.

04:07.600 --> 04:12.320
I don't think it was, it was your paper. I think it was Peter Abiel had this paper of like,

04:13.280 --> 04:20.640
trying to untie a knot on like a gigantic rope, you know, a single knot. And if the color of

04:20.640 --> 04:26.800
the background change didn't work, if the color of the rope changed, it didn't work. And here you are

04:26.800 --> 04:34.000
with this paper like untangling a hornet's nest of cables. Well, it's not quite the hornet's

04:34.000 --> 04:37.920
nest yet, but, um, but you're, you're, you're, you're right in it. That's, that's a very good

04:37.920 --> 04:45.600
perspective. We were, um, Peter was working with a thick cable. Um, and it was, I believe that was

04:45.600 --> 04:52.480
tying a knot. Okay. To get to create a knot. A few years ago, we started looking at untangling.

04:52.480 --> 05:00.320
And we started with very simple, very small sections of cable. So on the order of eight inches.

05:00.960 --> 05:06.480
And we actually used our surgical robot as an implementation of that. So we had, um, the

05:06.480 --> 05:14.240
Da Vinci, um, trying to untangle these, uh, very small, uh, segments. And they were very simple knots.

05:14.240 --> 05:20.720
They were just overhand knots. And that, that was a, that's a hard problem because it's, you're in

05:20.720 --> 05:27.280
the realm of, of deformable objects. And so, you know, and there's an infinite state space

05:27.920 --> 05:35.360
for those. There's also self-occlusion. And, and, and in fact, though, we minimize the self-occlusion

05:35.360 --> 05:39.600
because of the, the size of the knot, the size of the cable, right? It was fairly small. So you

05:39.600 --> 05:45.840
didn't have all this overlap and slack, if you will. So the key was to identify where the

05:45.840 --> 05:50.960
knots were, which we, we learned with a deep network, lots of examples. And then it would just

05:50.960 --> 05:56.720
start pulling at these knots and then, and then be able to open them. What was, what was exciting

05:56.720 --> 06:03.120
was the, the, we started thinking about longer cables and really expanding this into the macro scale

06:03.120 --> 06:09.840
with a, a full-scale robot, a dual-armed, um, um, UMI robot. And really starting to think about

06:09.840 --> 06:15.760
all the complexities now of, of, of truly trying to untangle this thing, pull it apart and manage

06:15.760 --> 06:22.080
the workspace for a dual-armed robot, which is, there's got a lot of complexities in its own

06:22.080 --> 06:27.040
right, because you have to avoid self-collisions with the two arms. They have to work around each

06:27.040 --> 06:34.080
other. And there's challenges and perception. And also, the workspace of the, of the robot is

06:34.080 --> 06:40.000
surprisingly small. It's usually about the size of a dinner plate, really. And the cable, in this

06:40.000 --> 06:44.960
case, was about three meters. So that greatly exceeds the size of the workspace. So you have to think

06:44.960 --> 06:52.240
about how to move things in and out of the, of the workspace and resolve ambiguities. But that,

06:52.240 --> 06:56.480
that has been a very fun project, I have to say. The team has done a great job. It was actually

06:56.480 --> 07:04.960
led by two, uh, two undergrads who became master students now, uh, Vynavy and Koshek. And they, um,

07:05.760 --> 07:12.480
and, and with, uh, Justin Kerr, a PhD student, they presented this at RSS this year. And they did

07:12.480 --> 07:19.040
such a fantastic job. They won the best systems paper award there. Yeah, congrats to, to you and

07:19.040 --> 07:26.160
them on the best systems paper award. The award calls out the, the systems and nature of this. Uh,

07:26.160 --> 07:30.640
can you talk a little bit about about this as a systems challenge? Definitely. And thanks for asking

07:30.640 --> 07:37.200
about that. In fact, it is a systems paper because you have the, the system of the perception system,

07:37.200 --> 07:42.880
the, the planning system, the actuation system. One of the key things that made this new work possible

07:42.880 --> 07:50.400
was a very, very clever hardware design that Justin came up with, which was to add a little foot

07:50.400 --> 07:57.600
onto the parallel jaw grippers. And if you think of it as just a little L shape, but a very small,

07:57.600 --> 08:03.360
I, almost a toe, if you will, what that allows it to do is that the, the grippers now can be fully

08:03.360 --> 08:09.280
closed and that holds the cable tightly. But if you open them by a little more than the diameter

08:09.280 --> 08:16.000
of the cable, then those two toes basically are interlock and they, um, prevent the cable from

08:16.000 --> 08:23.520
escaping. So we call that caging in, in robotics. Caging is where you have the object contained,

08:23.520 --> 08:30.080
can't escape, but it may not be held immobilized. So it might bounce around. So caging like you put

08:30.080 --> 08:37.040
your hand or, you know, our bird in a bird cage, it can move, but it can't escape. So caging is,

08:37.040 --> 08:43.040
um, is an interesting geometric problem in its own right. But here we, we think about caging,

08:43.040 --> 08:49.040
which is a way of allowing the, the, the gripper to enclose the cable and slide along the cable,

08:49.040 --> 08:57.680
which tends to pull through knots and tangles. So that turned out to be a big, very, very critical

08:57.680 --> 09:03.840
part of the, of the system, that piece of hardware that wasn't allowed us to introduce new primitives.

09:04.800 --> 09:11.440
So what we call cage pinch dilation, which is where we pinch with one jaw, cage with the other

09:11.440 --> 09:19.760
jaw and then pull dilate. And that allows the, uh, the, the system to untangle individual knots.

09:19.760 --> 09:27.840
And then we systematically pull through the slack and there's one other challenges, the depth,

09:27.840 --> 09:34.000
finding the where to grasp a cable is difficult because the cable is not lying perfectly on the plane.

09:34.000 --> 09:41.840
So it tends to loop and sometimes those loops can lift three or four inches off the plane. So if you

09:41.840 --> 09:48.800
go to grasp them, you really do need to have some sense of depth. And so we use a depth camera,

09:48.800 --> 09:57.360
but those are very slow because of the scanning process. So what we are moving to right now,

09:57.360 --> 10:03.840
and this is continuing, is to, is, is, is trying to avoid the depth camera. Is the depth, depth camera

10:03.840 --> 10:11.040
that you've been using? Is it, uh, like a vision-based 3D stereo thing or more like a point cloud,

10:11.040 --> 10:16.880
connect type of camera? More like a point cloud connect. So it's using a laser scanner and, uh,

10:16.880 --> 10:23.440
and, and, and it's, so it's a structure of light, but what, um, that scan is slow. It's about,

10:23.440 --> 10:29.920
it's about one frame per second at best. Now, the, um, and it also has a lot of specularities,

10:29.920 --> 10:36.080
problems with the, just getting that accurate is, is challenging. So here's what we've been thinking

10:36.080 --> 10:44.000
about, Sam, is, um, trying to imagine that we can't know exactly the height of the, of the cable,

10:44.000 --> 10:48.880
but what we can do is we can use geometry and physics. So what we do is place the,

10:48.880 --> 10:54.560
trying to estimate a, a position for the gripper above the cable in such a way that the cable

10:54.560 --> 10:58.960
is somewhere in here. We don't know where, but what we're doing is now lowering the cable down

10:58.960 --> 11:05.120
in such a way that it will again cage the, um, the cable as it moves to the, to the work surface,

11:05.120 --> 11:09.600
and then it closes. And so we're guaranteed to get the cable even though we don't know it's

11:09.600 --> 11:14.960
exact depth. So this is the kind of thing where we're, we're, we're interested in is how to use

11:14.960 --> 11:24.720
geometry and mechanics to perform things where the censoring may not be sufficient. And another example

11:24.720 --> 11:31.440
is that if we, um, if, what we, we, here's something we're very interested in right now,

11:31.440 --> 11:39.040
which is starting to use the subtle clues where I want to, um, determine where, let's say,

11:39.040 --> 11:43.360
do what really care about where the, the cable is. It's, it's sort of moved up and sitting on

11:43.360 --> 11:49.920
over the table. What I can do is move down with a jaws and carefully monitor what's going on.

11:49.920 --> 11:55.040
And when the, when the moment when there's a movement of the cable will be an indication that I've

11:55.040 --> 12:03.760
made contact. So the vision can actually provide a lot more information than we tend to think. We

12:03.760 --> 12:09.520
don't need, we don't need a contact sensor here. We have a vision because the cable will imperceptibly

12:09.520 --> 12:14.480
move just a few pixels. But knowing that is a trigger to say, wait, that's the height. And we know

12:14.480 --> 12:19.520
the height of the robot arm because of the kinematics. So I can determine that. Well, therefore that's

12:19.520 --> 12:27.680
where the, where the cable is. Interesting. Interesting. Uh, so hardware played a, a big role in, uh,

12:27.680 --> 12:35.200
allowing you to do this. Can you talk a little bit about, um, the software or MLAI side of things.

12:35.200 --> 12:40.400
And, uh, with a particular emphasis on, you know, things that have changed over the past,

12:41.120 --> 12:47.120
a couple of years that have really helped to tackle a problem like this. Sure. And the, the,

12:47.120 --> 12:51.520
because we've been, this problem has been evolving. And it's one thing I'm actually just

12:51.520 --> 12:55.680
want to mention, I really believe in. So I came to the students last week and we were saying,

12:55.680 --> 13:00.800
you know, I'm really proud of the, the, the projects that tend to continue over multiple years.

13:01.600 --> 13:07.760
Uh, you know, DexNet, as you, as you know, was our grasping work and started with DexNet 1.0.

13:07.760 --> 13:15.200
And when all the way up to 4.0. And we're not working on 5.0 actually. Because what I like is that

13:15.200 --> 13:21.920
we take a problem and we really try to, to, to, to dig deeper and deeper into it. And in this case,

13:21.920 --> 13:27.840
it's, um, it's really looking at the failure modes, really trying to not be satisfied with the

13:27.840 --> 13:34.160
performance that, you know, and, and, and, and wanting to understand how can this be made better?

13:34.160 --> 13:39.200
How can we really push the envelope? How can we really reduce the failures? In this line of work,

13:39.200 --> 13:46.480
we, we systematically characterize the failures. So, you know, just as an aside, I see

13:46.480 --> 13:53.680
today so many papers that, you know, say, we've bit, we've beat the state of the art. And, uh, you

13:53.680 --> 14:00.480
know, thank you. This is, this is superior and end of story. Um, and it's very frustrating because

14:00.480 --> 14:04.400
I always want to know, well, where, how did you beat the state of the art? What, you know, just

14:04.400 --> 14:10.320
giving me a, a mean success rate doesn't tell me a lot. I want to know, did you, did you succeed on

14:10.320 --> 14:17.120
a number of cases where the prior out, you know, the baselines failed? Or what, what, what did you,

14:17.120 --> 14:23.040
where did you succeed? And where did you fail? And, and that failure, you know, it's interesting

14:23.040 --> 14:29.600
because we have a, I think an instinctive desire not to want to look at that. But it's actually

14:29.600 --> 14:35.440
where the most interesting aspects of the problem are. And so you really want to study those

14:35.440 --> 14:41.120
failure modes. And so we do, we, we, we, we, we characterize them into different categories. Every

14:41.120 --> 14:46.240
single case, we really determine what was the failure mode. Where did that one go wrong? And

14:46.240 --> 14:53.600
then we try and look at those and say, okay, how can we address that? So the, the, the, the ideas

14:53.600 --> 14:59.600
that in each case, we have to, to really develop new primitives and new primitives both for

14:59.600 --> 15:06.240
perception and for action. And then we try and think about how do we sequence between those

15:06.240 --> 15:13.040
primitives? So the, so these are the software aspects. One of the, one of the algorithmic aspect is

15:13.040 --> 15:20.320
learning the, to recognize just where knots are in images. And so we, we did that in real by

15:20.320 --> 15:27.120
sampling lots and lots of examples. We just have the, the system watching the cable and we do

15:27.120 --> 15:32.080
a certain amount of self supervised movement. So the cable, basically tie a knot in it. And then

15:32.080 --> 15:38.160
we allow the system to move itself, move the cable around, taking images over and over again.

15:38.160 --> 15:44.480
And then we, we either manually or what we hope to do is the more and more is to have a self

15:44.480 --> 15:49.520
supervised method that provides ground truth, labels, images, and then we can train a network.

15:49.520 --> 15:54.080
So that's been a core part of it. And that's, you know, that's a huge thing where deep learning

15:54.080 --> 16:01.440
has changed the equation over the last decade that we have that perceptual ability that, that,

16:01.440 --> 16:06.480
that really can solve some of the very, very complex perceptual problems where it's very hard

16:06.480 --> 16:11.040
to analytically determine what you're looking for. Right. And this is to determine what is a knot.

16:11.040 --> 16:16.080
It's actually very hard. One thing that also is interesting is there's a whole body of theory

16:16.080 --> 16:22.320
called knot theory. And mathematicians have been working on this for centuries. It's, it's,

16:22.320 --> 16:27.360
it's very interesting. It's, uh, it's where they, they begin by turning it into a, a graph.

16:28.560 --> 16:35.600
So they abstract away from all the geometry and, and the, the physics. But I'm very interested in,

16:35.600 --> 16:40.560
in combining these. And there's one technique that comes from, from, um, from knot theory,

16:40.560 --> 16:44.880
called a rate of mice to move that is actually analogous to what we do when we pull through

16:45.520 --> 16:49.440
the, uh, the cable from end to end. So we've been applying that. We've been applying new,

16:49.440 --> 16:55.760
new forms of, uh, of, of learning in particular. We're right now, again, trying to remove the,

16:55.760 --> 17:01.120
the reliance on the depth sensor and learn primitives that can determine, they can compensate for

17:01.120 --> 17:06.960
not having depth. And I'm also very interested in having human in the loop. And by that, I mean,

17:07.760 --> 17:16.240
very sporadically, um, um, when the system is stuck where it's not making progress or it determines

17:16.240 --> 17:21.440
that it's in a sufficiently uncertain state, it can call in a human for help.

17:22.880 --> 17:28.240
And this, this is, this is, this is interesting in its own right, in more general sense of,

17:28.800 --> 17:33.520
of when, how do you do this to move? You want to minimize the burden on the supervisor of the human.

17:34.960 --> 17:41.760
And by the way, this is, this is a, this is a, a widespread issue. For example, as you,

17:41.760 --> 17:47.520
as you know, Google is testing an automated, uh, car service, taxi service in the Bay Area.

17:48.320 --> 17:55.360
And my understanding is that they have humans, um, networked in and are standing by.

17:56.480 --> 18:02.240
Now you have one human, probably controlling multiple taxis. So now you have a question, how,

18:02.240 --> 18:08.320
when, when do you call that human in? Right. And you, you want to minimize that because,

18:08.320 --> 18:13.600
ideally, you can have one human supervising 50 taxis, right? So you don't need, you don't need

18:13.600 --> 18:21.200
the person that often. But in, in any robotics case, it can be very tedious to be constantly bothered,

18:21.200 --> 18:28.880
right? So there's a nice problem in when, when do you call human? And also when the human comes in,

18:28.880 --> 18:34.480
when do you transfer control back to the robot? So you, you have these nice dual problems,

18:34.480 --> 18:39.200
and they both have to do it in a sense, a model of confidence. So we've been looking at that. And

18:39.200 --> 18:44.080
I think that that applies to many of the kind of tasks we're interested in, where there are these

18:44.080 --> 18:49.920
failure modes that you're really unrecoverable, at least currently. And so that's where there's no

18:49.920 --> 18:54.960
harm. And, you know, maybe once an hour or so, you want to have a human come over just to just

18:54.960 --> 19:00.080
something and then, um, then, you know, go back to whatever they were doing. Yeah. When I, when I

19:00.080 --> 19:06.560
introduce you, I referenced that you're in the School of IE and OR, and it strikes me in your

19:06.560 --> 19:11.440
description of the, you know, this problem, there's also some interesting kind of classical OR

19:11.440 --> 19:17.200
queuing theory types of problems in there, you know, despite the, the degree to which I enjoyed

19:17.200 --> 19:22.240
working on that kind of stuff in grad school, I have not looked a whole lot into what's happening

19:22.240 --> 19:26.960
to marry machine learning and queuing theory. Do you know of anything interesting out there?

19:26.960 --> 19:32.880
Oh, well, it's quite a bit. I mean, queuing is a, is also a beautiful model. There's, it's,

19:32.880 --> 19:38.560
it's always used a Poisson distribution assumption. And a lot of nice theorems you can prove on that,

19:38.560 --> 19:45.280
but the reality is not, it doesn't behave that way. So how can you generalize that to real empirical

19:45.280 --> 19:51.280
objects or real empirical distributions? And I'm glad you mentioned, um, that you, you know, this

19:51.280 --> 19:58.080
connection with, with queuing, you know, in, in OR, you know, my colleagues say, well, we've

19:58.080 --> 20:04.720
been doing, you know, we've been doing AI for, uh, with the century now. I mean, what, because,

20:04.720 --> 20:11.360
because in some sense, you know, mark up decision problems, um, these have been the core of operations

20:11.360 --> 20:19.440
research for a very long time. And so those are early forms of AI and still, and being rediscovered

20:19.440 --> 20:25.280
in a way, especially where it comes to optimization, which is at the core of deep learning. And so many

20:25.280 --> 20:31.760
of the models that we're using now. So it, it's very natural to have connection between, uh, OR

20:31.760 --> 20:37.200
and AI. And the industrial engineering side of it comes with the other aspect, which is how do you

20:37.200 --> 20:43.680
make these systems practical? And that's where factors like what we're just talking about, the human

20:43.680 --> 20:50.640
interface come into play. You know, there's a, there's a distinction between robotics and automation.

20:51.760 --> 21:00.960
And robotics is obviously much more popular and, uh, enticing and the press labs and robots,

21:00.960 --> 21:06.960
et cetera. And so I've always been amused by the fact that, you know, if you start talking about

21:06.960 --> 21:12.240
automation, it's tends to be, you know, just, uh, that sounds like something, you know, in a,

21:12.240 --> 21:17.200
in a factory, I don't want to really talk about that. But if it's, is robotics, it's really exciting

21:17.200 --> 21:24.080
and energizing and, um, you know, it feels like, you know, science fiction. What's been happening,

21:24.080 --> 21:29.200
I think, in the last few years is that there's a trend toward automation because there's a

21:29.200 --> 21:34.480
recognition that we want to start putting things into practice. And that's where you have to worry

21:34.480 --> 21:41.840
about robustness. You have to put guarantees on performance. You want to worry about

21:41.840 --> 21:49.200
cost, reliability, all those, those factors that are, um, you know, often overlooked when you're

21:49.200 --> 21:53.200
just doing something in a lab. Yeah. Interesting. I thought you were going to go a totally

21:53.200 --> 22:02.080
different, uh, direction with that last, last comment. Um, people often will talk about software

22:02.080 --> 22:11.760
robots. Uh, and I, I'll ask you what, what your take is on that. But to me, like a robot, part of

22:12.880 --> 22:20.400
what fundamentally defines a robot is this bridging of the digital and the physical realms and

22:20.400 --> 22:24.960
something that, you know, purely exists in the digital realm. Unless we're talking about

22:24.960 --> 22:30.160
a simulation of something that exists in the physical realm, uh, I don't like calling those

22:30.160 --> 22:35.920
things robots. The software or it's, you know, some, you know, it's automation, uh, it's supposed to,

22:37.280 --> 22:41.760
you know, software robot. Oh, no, I agree. I can't, I couldn't agree more. I mean, I think that's

22:41.760 --> 22:47.920
actually, it's a misdomer. People often say bots, right? Oh, it's the, you know, bots took down

22:47.920 --> 22:55.200
this website, right? Because it was automated, um, some automated modules that would be able to

22:55.200 --> 23:02.560
do something, but they're just software, right? And they're, I think that is definitely a confusion.

23:02.560 --> 23:09.840
And I, I mean, to my mind, the robot has to have a physical component. In fact, this brings up

23:09.840 --> 23:17.120
another aspect, which is a lot of research has been done just in simulators and then demonstrated

23:17.120 --> 23:27.600
with simulation. And I think there's a danger there that if you, you can, you, you can almost have

23:27.600 --> 23:32.160
a self-fulfilling prophecy. You build the system, you build the simulator, you're retuned,

23:32.160 --> 23:37.120
you work with a simulator, you tune off of the simulator. It's very nice because it gives you

23:37.120 --> 23:44.080
the ability to do, to collect lots of huge amounts of data and you can do resets in the simulation.

23:44.080 --> 23:50.560
But if your simulation is even slightly deviates from reality, when you now take that policy and

23:50.560 --> 23:58.800
put it into practice, you have a performance can, can degrade, you know, dramatically. And so

23:58.800 --> 24:06.400
a lot of the early mijoco demonstrations of walking machines, etc. looked great and they

24:06.400 --> 24:14.000
look beautiful and just surprising how fast they would learn. But then they would not easily transfer

24:14.000 --> 24:23.040
into real machines. So this is the, you know, the, the, the sim to real gap that I think is so

24:23.040 --> 24:29.280
interesting right now. And it is really important to recognize. And you've been doing a bunch of work

24:29.280 --> 24:35.120
in that area as well, you and your, your live feed talk a little bit more about kind of how you

24:35.120 --> 24:40.640
characterize that sim and real gap as a set of research problems and some of the specifics that

24:40.640 --> 24:46.000
you've been working on. Sure. One of the things that I've always been interested in is this,

24:46.880 --> 24:56.960
is the, is the limitations of simulation and in grasping. And I talk about the, the very real problem

24:56.960 --> 25:06.320
of, of the, being able to, there's essentially indeterminacies in physics that are due to friction.

25:06.320 --> 25:12.400
And the example I always like to point out is just pushing as a pencil across your, your,

25:12.400 --> 25:18.320
your desk. And if you, if you do that with just put your index finger and you do, you do, you

25:18.320 --> 25:25.600
do that repeatedly, the position of the pencil will be very different. And so in, it's a chaotic

25:25.600 --> 25:33.360
system. It's basically based on the, the, this complex surface physics, the surface topography.

25:34.000 --> 25:40.560
And that is very difficult. It's not, it changes every single time you, you perform this. So

25:40.560 --> 25:46.880
in a sense, it's impossible to predict how that pencil is going to, with the final state of

25:46.880 --> 25:52.480
the pencil. It's, it's, it's, it's, it's, it's undecidable. I feel like, I think we talked about

25:52.480 --> 25:57.200
this in a fair amount of detail last time. All right. You have a good memory. I, I, I know,

25:57.200 --> 26:02.000
I don't want to repeat myself, but I wasn't saying that because you're repeating yourself. I'm,

26:02.000 --> 26:09.680
I was more saying that because there, there's a part of me that wants to, you know, get into a

26:09.680 --> 26:15.040
philosophical argument about it. And I'm wondering if we, if I got us into that philosophical argument

26:15.040 --> 26:21.520
at last time, you know, the basic question being, is it kind of practically chaotic because we,

26:21.520 --> 26:28.720
we don't have the resolution to incorporate the fluctuations in the surface and the dust particles

26:28.720 --> 26:36.240
and all these things? Or is it, you know, if we could do, if we could capture the microscopic

26:36.240 --> 26:43.360
physics, would we then have a deterministic system? Or are the, whether, whether always be

26:44.400 --> 26:48.720
some element that we can capture, you know, humidity, temperature, what have you?

26:48.720 --> 26:54.480
Mm-hmm. Mm-hmm. No, I, I, I, I love that. We could probably talk for an hour just on that.

26:54.480 --> 27:00.080
I've been using the, the term, thinking about the terms epistemic and aleatory uncertainty.

27:00.080 --> 27:05.200
And this is exactly what you're talking about. So the epistemic is that we just need to model

27:05.200 --> 27:09.600
this better. We have those aspects we don't, we, we don't currently know, but aleatory is what's

27:09.600 --> 27:15.920
inherently uncertain. And that's, you know, it's the same for throwing a dice, right? You, you,

27:15.920 --> 27:20.080
if you're having better and better models, you're still not going to know how, you know,

27:20.080 --> 27:25.760
being able to predict that with certainty is, you know, inherently uncertain. Now, at some point,

27:25.760 --> 27:30.560
you get down to the, uh, the subatomic level and you back to the Einstein and God does not play

27:30.560 --> 27:35.840
dice at the universe, right? So, but, but, but, but any, but any practical sense, you're never going

27:35.840 --> 27:41.120
to be able to predict the position of that pencil. And so you have this, the, the reason I say this

27:41.120 --> 27:46.560
is it's not, doesn't mean that you can't do it. People do it all the time. We pick up pencils.

27:46.560 --> 27:51.760
So what's going on? What's missing? And I think that robots and simulators have a problem because

27:51.760 --> 27:58.000
they're very, they're deterministic. They, the, the simulation has one outcome. And if you perform

27:58.000 --> 28:03.120
the same thing over over, it's doing the same thing. So you tend to, to, to have a system of policy

28:03.120 --> 28:08.800
that's trained on that particular outcome, but it's not trained to be robust to those variations.

28:08.800 --> 28:15.680
Now, the, the trick to doing that is in this idea of domain randomization, right? Which is where

28:15.680 --> 28:21.360
you randomize the outputs in the simulator, but you want to do that very, very methodically.

28:22.320 --> 28:29.680
So the, the, the, the trick there is to have the simulator have ranges of outputs that are

28:29.680 --> 28:35.360
consistent with what you would see and simulate in reality. So this is why what we've been talking

28:35.360 --> 28:43.280
about recently is, is, is real to sim. And we learned this by, through a, a project that we were

28:43.280 --> 28:49.840
doing on, it was very, very, also working with cables, but here the problem is to what we call

28:49.840 --> 28:56.800
cleaner robot casting. And so here you have a robot with a, a weight on the end of a cable.

28:57.520 --> 29:03.520
And the robot is holding the cable above the surface and it basically casts the, the cable out,

29:03.520 --> 29:09.440
like you would a fishing rod, fishing lure. And then you pick a target somewhere on the surface

29:09.440 --> 29:14.400
above where the cable has landed. And then you want the robot to do a motion that will cause the

29:14.400 --> 29:19.440
cable to wind up, but the endpoint to wind up at a particular target point, meaning when it's pulling

29:19.440 --> 29:24.640
it back or when it's casting it out. No, when it's pulling it back. So you want to sort of, you want

29:24.640 --> 29:30.400
to sort of motion like this that will cause a dynamic motion towards a land in, in this particular

29:30.400 --> 29:35.840
point. The, the nice thing is you can do a lot of supervised data collection, self-superbite data

29:35.840 --> 29:40.480
collection. So the system, we have a camera overhead, we have this cable set up and this system

29:40.480 --> 29:48.400
just basically does this, you know, all day long. So we have a, a data on the input control that

29:48.400 --> 29:54.080
we give to the robot and where did the actual cable land. And one thing is there's, there's this

29:54.080 --> 29:58.160
aleatory uncertainty and you can measure it because you give it exactly the same cable motion

29:58.160 --> 30:03.280
and the, the, the endpoint lands in different places, right? And so we can actually draw

30:03.280 --> 30:08.480
an ellipse around that and say, this is the uncertainty that's inherent. Even though this can run

30:08.480 --> 30:14.720
all day long, it's still only capable of generating a few thousand examples. You really need

30:14.720 --> 30:22.400
many more to train a reliable policy. So we wanted to use a simulator. Now, what we found was

30:22.400 --> 30:27.120
that the simulators, they're the number of simulation packages that can do this. Mojoko, Isaac,

30:27.120 --> 30:32.800
Sim and others. And they all look good. They all kind of, when you look at them, they look very

30:32.800 --> 30:36.720
similar to what we're seeing in the physical space. But then we try to actually give it the true

30:36.720 --> 30:43.200
parameters of what we're measuring. And there's a, there's a deviation, right? So this is where

30:43.200 --> 30:52.800
the question is, how do we tune that simulator to closely match reality? So that's the real

30:52.800 --> 30:57.600
system. So you see the difference because if you just use Mojoko and you try to have a walking

30:57.600 --> 31:02.160
machine and you just start with the simulator, right? You, you get this thing and it trains and

31:02.160 --> 31:06.320
it runs and then you say, okay, now I've got a policy. Let me go pull it and try it on a real robot

31:06.320 --> 31:10.880
and it doesn't work. But if you start out by saying, I have a real robot and now I want to make a

31:10.880 --> 31:18.720
simulator that really mirrors what's going on with that, um, that, that robot. And this is

31:18.720 --> 31:24.640
closely related. Maybe it's, it's very similar to the idea of the digital twin. That's very popular

31:24.640 --> 31:33.520
now. And the key is how do you actually do this tuning systematically? And people call that system

31:33.520 --> 31:39.440
identification, right? That's a very common term. But there's a lot of misconceptions about that.

31:39.440 --> 31:44.880
System ID is, uh, is fairly well understood if you have, if you know the structure of the system,

31:44.880 --> 31:48.880
you know, if you have equations that decide the system like a pendulum and you want to identify

31:48.880 --> 31:54.240
what is the mass at the tip of that pendulum, then system ID is very good for telling you that.

31:55.040 --> 32:00.960
But if you have a system like this, this, uh, piece of cable and, uh, and the frictional

32:00.960 --> 32:06.640
interactions of something sliding across the surface, then you don't have a, you don't have a structural

32:06.640 --> 32:11.760
mark. And so it's very hard to figure out what should the, what should the parameters be in the

32:11.760 --> 32:16.400
simulation? By the way, simulation has a lot of parameters. There's, there's, um, things like

32:16.400 --> 32:21.360
torsion of the cable, there's friction of everything. There's inner, you know, when the cable

32:21.360 --> 32:25.040
rubs against itself, there's another frictional property, another frictional parameter for that.

32:25.760 --> 32:31.440
So there's a dozen or more. And now you have a nice optimization problem because you have a

32:31.440 --> 32:35.120
bunch of data that you've collected in real and you want to tune the simulator to match that.

32:36.400 --> 32:40.960
So, um, so we've been exploring that in this context that we actually turned out that in,

32:40.960 --> 32:45.840
we have a paper real to sim to real. We start out with real, we tune the simulator, then we can

32:45.840 --> 32:51.200
generate lots of examples. We combine that with the, the limited number of samples we got in real

32:51.200 --> 32:56.720
and then train a policy and then bring that back into real. And so, and that seems to perform

32:57.440 --> 33:04.000
better, much better than if we just use a very limited amount of real data, which is all we can get,

33:04.000 --> 33:10.560
or if we just use all the simulated data that wasn't tuned to the real system.

33:10.560 --> 33:15.360
So, I've been excited about this because I think it applies to so many problems that we're

33:15.360 --> 33:22.400
looking at in robotics, where we look at a, we have these, these systems and we really want

33:22.400 --> 33:28.240
to have a simulator that's, that's very physical accurate. And what's also been very interesting,

33:28.240 --> 33:35.600
as you, as you know, is that, um, Nvidia has made a major push in simulation. So they've got a huge

33:35.600 --> 33:42.400
team of various student researchers developing Isaac Sim and Variant and also thinking about how to

33:42.400 --> 33:51.760
make those run very fast. And in parallel, um, deep mind acquired Mujoko last year. And that was,

33:51.760 --> 33:59.840
it was almost exactly a year ago, that was a major, major milestone because Mujoko, um, was,

33:59.840 --> 34:04.320
was a, was a very good system, but it was run by a fairly small team. Now it went into deep mind,

34:04.320 --> 34:13.120
which has, you know, much more resources. And they've assembled a fantastic team of physicists

34:13.120 --> 34:20.560
and researchers to basically take Mujoko to an entirely new level of realism. So it's been fantastic

34:20.560 --> 34:25.520
to have these two projects coming along, where they're both getting the simulators better and better.

34:26.480 --> 34:30.960
And that is, I think, is going to lead to major breakthroughs in the field.

34:30.960 --> 34:38.160
You know, along these lines, I wonder if you have been involved in exploring the

34:40.000 --> 34:45.920
possible impact of causal based models here. I'm thinking about the ellipse that you're

34:45.920 --> 34:51.440
describing around kind of some ideal point, you know, where you're casting back to. And you've got

34:52.160 --> 34:57.680
a bunch of different sources of possible, you know, call it noise. You know, you've got

34:57.680 --> 35:03.760
measurement noise, you've got control noise, various other things. You know, is there some kind of

35:04.960 --> 35:11.120
discot that are folks looking at causality as a way to understand that, you know, how these

35:11.120 --> 35:16.640
inputs combine to create uncertainty and to create better models in the robotic realm?

35:17.200 --> 35:24.080
Well, I would have to say one, one answer to that is by trying to figure out how to optimize

35:24.080 --> 35:32.240
the tuning process. And that is that there is a causality inherent in controllable in the sense that

35:32.240 --> 35:39.040
that the robot is able to change its parameters. And you want to be able to do that systematically.

35:39.600 --> 35:45.440
So one way to do it, let's just take the planer robot casting is you pretty much randomly generate

35:45.440 --> 35:52.000
a lot of control inputs, trajectories for the arm. And then you just observe where the end point

35:52.000 --> 35:59.040
of this cable winds up on the surface. Now, you can just generate a big data set and then throw it

35:59.040 --> 36:06.080
in and then try and analyze that to come up with a model. A better way is to do that systematically

36:06.080 --> 36:14.240
where you start doing some random examples, but then you start testing basically values of those

36:14.240 --> 36:21.360
parameters and going back out into the real system and fine tuning it so that also regions of

36:21.360 --> 36:28.080
the state space that you hadn't explored earlier, you can or you haven't explored sufficiently,

36:28.080 --> 36:33.200
you can you can reevaluate and put more, do more experiments in that area.

36:34.080 --> 36:39.680
So that I think is really interesting where the experiments in real are costly, if you will.

36:39.680 --> 36:46.640
They require time and an offer and it's very difficult to reset the system to obtain

36:46.640 --> 36:55.360
the same input to run it again, right? But it's very, so you want to be thoughtful and systematic

36:55.360 --> 37:00.640
and this is related to the theory of the design of experiments. And typically you're trying to

37:00.640 --> 37:06.400
maximize some kind of mutual information gain that you will, by doing this experiments,

37:06.400 --> 37:10.560
you want to choose the experiment that's going to gain you the most information. But it turns out

37:10.560 --> 37:18.560
computing that solving that is a very difficult problem. So there's so many interesting open

37:18.560 --> 37:27.440
problems here and it's very exciting to see how the field is is maturing. I think robotics is

37:28.480 --> 37:35.600
is moving at a remarkable pace, but it's still from the public perception very far from what

37:35.600 --> 37:43.600
what people commonly, you know, commonly think should happen. And people are still thinking, well,

37:43.600 --> 37:48.080
the robot, you know, why don't we have our robot drivers? Why don't we have our robot,

37:49.200 --> 37:55.600
you know, robots in the kitchen and robots at home taking care of us? And these things are

37:55.600 --> 38:03.040
still very far off, unfortunately. Maybe digging into that a little bit where maybe three weeks beyond

38:03.040 --> 38:13.040
Tesla's Optimus Robot announcement, which is, you know, causing people to ask the question again,

38:13.040 --> 38:21.680
oh, hey, are we close to our robot in the home? Elon says we are. What's your take on Optimus? What

38:21.680 --> 38:28.320
was really demonstrated there, you know, the extent to which it demonstrates that we're close to,

38:28.320 --> 38:35.600
you know, practical everyday robotics? Okay, so I do have a take on this. I was very interested.

38:35.600 --> 38:41.840
I watched it right as it came out and it was it was very interesting. I mean, I do have to hand it

38:41.840 --> 38:53.840
to Elon Musk. He's a great entertainer. He has a real knack for doing things and doing stunts

38:53.840 --> 39:00.880
and basically having ideas that are really, you know, out there. But he's also, you know,

39:00.880 --> 39:07.360
has been a visionary. He has actually has succeeded in certain categories. So he's done with

39:08.400 --> 39:16.560
electric cars and with Tesla, with in terms of batteries, in terms of space and landing

39:16.560 --> 39:24.320
an aircraft or a rocket back on the earth, that's remarkable. And those are, you have to put

39:24.320 --> 39:29.120
those into context of everything else that he's doing. And so I have to say, my first reaction is

39:29.920 --> 39:39.120
was, look, you know, what's going on here? He is, he's probably keenly aware that the price

39:39.120 --> 39:45.520
earnings ratio of an auto company is, you know, kind of at one level, but the price earnings ratio

39:45.520 --> 39:52.560
of a robotics company is much higher. So if he transforms Tesla into a robotics company,

39:52.560 --> 40:00.160
there's a very clear benefit for that. Right. So that could be one, one part of what he's thinking.

40:00.160 --> 40:06.320
But I think what's also going on is that he's saying that he really is putting his, you know,

40:06.320 --> 40:14.400
put it putting out there, you know, a bold new idea. And he's not afraid to take risks like that.

40:14.400 --> 40:21.040
Now, what I was happy to see was that, you know, that robot was, was substantial progress from

40:22.080 --> 40:27.680
the past year when they had first announced it. And I remember when he very first announced it,

40:27.680 --> 40:34.080
I thought, what are you talking about a humanoid? No, that's not going to happen. But he has,

40:34.080 --> 40:41.680
he's really put real research behind it. Now, it was, it fell short of anyone's expectation,

40:41.680 --> 40:48.160
if you know about what's going on with agility, robotics, and, and, and, and Boston Dynamics.

40:48.880 --> 40:57.760
But it was, it is a start. I think that the one thing I'm very excited about is that he understands

40:57.760 --> 41:02.960
the this aspect of automation in the sense that it has to make something that's going to run

41:03.440 --> 41:09.280
reliably and cost-effective. So when anybody has been building humanoid over the past

41:09.280 --> 41:15.440
three decades, nobody's really talked about the cost effectiveness of that, right? But he was,

41:15.440 --> 41:20.720
he went out and said $20,000, right? Okay. Well, what does that mean? That means he's going to have

41:20.720 --> 41:25.520
to develop some new motors that are, because he's got a lot of motors in the system. What would you

41:25.520 --> 41:35.680
say the, the list price is on the analog? Oh, the Alex? Oh, it's, I, I, I haven't, I haven't seen,

41:35.680 --> 41:41.440
but it's, it's probably over 200,000. Order of magnitude, a couple order of magnitude, maybe?

41:41.440 --> 41:47.840
Yes. And the, the thing is that these are, you know, you have to amortize all the research

41:47.840 --> 41:52.400
over, over the, over the volume. So if you have, if you're arguably able to produce in volume,

41:52.400 --> 42:00.000
you can do this. The, the challenges in designing new motors, gear trains, sensors that, these

42:00.000 --> 42:05.200
are all things we actually need in robotics. You know, arms, there's a number of arms out there,

42:05.200 --> 42:14.080
but they're really, they're all still, um, fairly expensive and either imprecise or, um, or,

42:14.080 --> 42:20.400
or dangerous, right? So I think there's, I would, I would love to see, and I think Tesla is in a

42:20.400 --> 42:24.960
perfect position to do this, is that they would come out with a new line of motors, and those

42:24.960 --> 42:29.360
could be used for robots. They might even come out, here's something I'd be saying. I think they

42:29.360 --> 42:35.600
could come out with an industrial robot arm, that, um, that Tesla would come out with a new arm,

42:35.600 --> 42:42.480
that would be, that would actually be very high precision, low cost, low mass, and, and we need that.

42:42.480 --> 42:47.680
So particularly if it's one that's based on their own needs and experience as a manufacturer.

42:47.680 --> 42:52.480
Exactly. Exactly. Because that, that's right. So he has a use case right there, right? And there's

42:52.480 --> 42:57.680
all kinds of aspects of the, and they tried to automate with, with existing robots and had

42:57.680 --> 43:02.640
number of challenges. If they build their own robots now, that's very, that really changes

43:02.640 --> 43:07.920
the equation. No, very, no one else, no other company has that big of a use case and production

43:07.920 --> 43:13.600
capability. So they could do it. And the other is sensors. You know, we're just talking about

43:13.600 --> 43:18.880
the connect and all the lines of 3D sensors. They could really put their muscle behind a really

43:18.880 --> 43:27.280
nice compact, uh, uh, sensor that could be, they could give us 3D or very fast 2D sensing.

43:27.280 --> 43:33.280
And that would be very bad. Tactile sensing. By the way, that's also heated up since the last

43:33.280 --> 43:42.400
time we talked that Facebook has really developed a partnership with, um, with Jelsight and come out

43:42.400 --> 43:50.480
with the, um, digit, um, tactile sensor. And that is very interesting. By the way, that's a big

43:50.480 --> 43:57.040
breakthrough. Um, and we've been using that. And now Jelsight just announced a new version of

43:57.040 --> 44:04.480
their sensor, higher resolution. And they're faster. Um, we're very interested in this is like a new

44:04.480 --> 44:10.320
generation of tactile sensing that I think we're going to see lots of applications. Okay. That's

44:10.320 --> 44:14.960
super interesting. I, we may have talked about this last time. I remember as a kid taking, uh,

44:15.920 --> 44:20.480
Paisio electric foam or something like that and slapping it between a couple of circuit boards

44:20.480 --> 44:27.520
printed on one side and using that as like a touch-ish pressure sensor. Exactly. Exactly. We,

44:27.520 --> 44:31.920
you know, good memory. I, I, we did talk about that because that was where I got started as an

44:31.920 --> 44:37.040
undergrad doing trying to build touch sensors. And it's, it's that, you know, you don't have that

44:37.040 --> 44:42.320
yet. And the Jelsight is, is kind of another breakthrough just as connect was that starts to make

44:42.320 --> 44:48.240
that more, more feasible. And because it's using optics, it's kind of riding the, the curve of,

44:48.240 --> 44:57.680
of advances in, in cameras. So it sounds like, uh, kind of the, the, the, to net out your take on

44:57.680 --> 45:03.600
optimists. There's some interesting things that you hope grow out of it. Um, but you didn't

45:03.600 --> 45:10.480
necessarily see anything that, uh, you know, if you were Boston dynamics would make you fear for

45:10.480 --> 45:16.160
the future of your, your own company. No, but I would have to say, I think, well, I think it's good

45:16.160 --> 45:23.360
for the field. So when you have, you know, you have someone with that level of attention

45:23.920 --> 45:29.840
and, and, and mind share, coming out and saying robotics is where we're going to make major

45:29.840 --> 45:36.880
advances. That is good for the whole field. I think it, it talks to young engineers who, you know,

45:36.880 --> 45:42.880
want to take a robotics class or want to maybe go into the field. It also, it speaks to investors

45:42.880 --> 45:47.200
who are, you know, look at his track record and say, hey, maybe he's going to pull us off.

45:47.920 --> 45:52.720
And I think, I think it would be, I don't, I think a bit very unwise to bet against him.

45:53.360 --> 45:57.360
In other words, I'm not saying he's going to come out with a, with a practical humanoid.

45:57.360 --> 46:01.440
I don't think that's, I think he's going to quickly discover how complicated that is.

46:01.440 --> 46:06.000
Yeah, I think that's what, uh, what I'm kind of getting at or trying to get your take on it.

46:06.000 --> 46:11.120
Well, he, you know, I was, I was joking that, you know, uh, it's true, rocket, robotics isn't

46:11.120 --> 46:17.840
rocket science. It's, it's actually, it's much harder. Um, and, and by that, you know, because

46:17.840 --> 46:22.640
this comes back to the things we were talking about, you know, um, basically doing a landing

46:22.640 --> 46:28.560
of a, of a rocket, um, back on, you know, that stabilizing that is a beautiful control problem.

46:28.560 --> 46:34.000
But there's, the, there's only contact at the end of that. In relation, you have continuous

46:34.000 --> 46:40.240
contacts. And those are very difficult and non deterministic for all the reasons we talked

46:40.240 --> 46:46.480
about. So that, that problem is technically harder. And so getting that right is going to require

46:46.480 --> 46:51.600
the next generation. I mean, we're, that's what I'm excited about. So yeah, because I do feel like

46:51.600 --> 46:56.320
we're at the point where the lot of vectors are lining up that we're going, we're going to see

46:56.320 --> 47:03.360
progress and having someone like Elon and his, you know, army of supporters is, uh, is a great

47:03.360 --> 47:09.440
thing for the field. Mm hmm. Uh, I guess one more topic I want to take on before we wrap up,

47:09.440 --> 47:15.600
you're the chief scientist at Ambi Robotics. Uh, what is Ambi up to and, and how is it pushing

47:15.600 --> 47:22.560
the field forward? Well, I've been very impressed with the team, um, at Ambi. The, since we started,

47:24.080 --> 47:30.240
three years ago, the, the team has just been absolutely fantastic, very, very laser focused,

47:30.240 --> 47:39.040
Jeff Mueller as the, as the, the, um, the chief technology officer and really the mastermind

47:39.040 --> 47:45.520
behind Dexnet, he has been leading the technical team and, um, on the software side. And then Steve

47:45.520 --> 47:53.680
McKinley and David Geely have been working on the hardware side. So it's a blend of, of, of very

47:53.680 --> 48:01.600
elegant new software and hardware that are coming together in these systems. And, um, the, the,

48:01.600 --> 48:10.000
the CEO who Jim Leifer has this incredible background in the, in logistics. So this actually

48:10.000 --> 48:16.720
also has happened since you and I talked last. Jim has been, you know, a history working in Wal-Mart

48:16.720 --> 48:22.800
and working with, um, with a number of, uh, of logistics companies. So he really understands

48:22.800 --> 48:28.800
the real problems. And then they, we've been working with the company, uh, named Pitney Bose,

48:29.840 --> 48:40.320
who is a, you know them? Uh, yep. I, uh, I worked at Pitney Bose, uh, as an undergrad for a co-op.

48:40.320 --> 48:48.880
I was doing, um, I was doing, uh, I forget the term, like essentially laying out, uh, custom,

48:48.880 --> 48:55.120
um, custom chips. Really? Oh my God. So you know Pitney Bose. Pitney is very interesting. They're,

48:55.120 --> 48:59.920
they're an old company. They've been a old-school company. Postal, yeah. Postal leaders,

48:59.920 --> 49:04.720
1920. So they just celebrated their 100-year anniversary. And what's been interesting is,

49:04.720 --> 49:08.480
when you look at them, they've, they've always been looking at technology for postage in various

49:08.480 --> 49:14.640
ways. And they, um, they, they, but they, what they do is they, they're sort of behind the scenes

49:14.640 --> 49:19.360
of a lot of the postal sorting systems around the country. And so they installed them for the US

49:19.360 --> 49:26.320
Postal Service, for UPS, for, for FedEx and others. So they really know this technology. And it's been

49:26.320 --> 49:32.000
a pleasure to work with them because they, they're really true engineers. They really try to solve

49:32.000 --> 49:38.480
problems. And so, um, partnering with them has been terrific because we're, we work side-by-side,

49:38.480 --> 49:45.600
where they've, they've essentially, um, you know, become our, our biggest customer. And we,

49:45.600 --> 49:53.040
you know, we're installed 60 of our systems over the summer all across America. And they just

49:53.040 --> 50:00.160
invested in us. So what are the system? Is it, uh, is it a, a hardware system? Yes. The system

50:00.160 --> 50:06.800
is hardware software. It's called ambiSort. And what it does is it takes bins of packages and

50:06.800 --> 50:13.120
sort them into smaller bins according to zip code. So sorting is a little different than just grasping.

50:13.120 --> 50:18.560
You have to grasp the object and then scan it, determine what the code it is, put it on another

50:18.560 --> 50:24.320
a gantry robot that then puts it out to, uh, and drops it into a bin. So there's a quite a bit of

50:24.320 --> 50:29.040
hardware. In fact, it's, it's sort of the size of a living room. Um, it actually fills up at 18

50:29.040 --> 50:36.720
wheel truck. That's, that's the, and what's the form factor of the robot? Is it, uh, an arm type of form

50:36.720 --> 50:42.640
factor or? Yes. So there's a, the standard six-degree of freedom industrial arm at the front of it.

50:42.640 --> 50:48.480
It's picking things up. And then there's a gantry type robot. Like I think of it x, y, um, system that,

50:48.480 --> 50:53.920
that has a pivot that drops the package into the appropriate bin. So that whole system is called

50:53.920 --> 51:02.400
ambi sort and involves lots of cameras, lots of safety features, lots of, of, of, of, of, failsafe

51:02.400 --> 51:08.720
features. It's a, it's a big operation. It's got thousands of parts. But that is, those are the

51:08.720 --> 51:15.200
systems we're talking about. So each one of those can, can, can basically sort through hundreds of

51:15.200 --> 51:22.480
parcels per hour. And that is a big, um, it's an interesting challenge because it's very hard. This

51:22.480 --> 51:30.240
is a, can be back breaking work. Humans are, are prone to making a lot of mistakes. Um, and people,

51:30.240 --> 51:36.400
the turnover in these warehouses is enormous. Uh, you know, all the companies, now Amazon is very

51:36.400 --> 51:43.120
big on this. They're starting to, to try to, um, find ways to automate this. And this is really our

51:43.120 --> 51:53.040
focus. Awesome. Awesome. Um, and the, uh, you know, for that, for, for packages, you often see,

51:53.760 --> 52:00.240
you know, as opposed to hand, uh, you know, gripper types of actuators like suction actuators and

52:00.240 --> 52:06.800
other things. You mentioned Dexnet. So I'm assuming, uh, you're doing kind of more of a gripper type of

52:06.800 --> 52:14.000
actuator. Well, a great question. So Dexnet 3.0 was, uh, suction, where we, we took the same,

52:14.000 --> 52:19.200
same idea and applied it to the suction model. In, in a sense, you have a gripper is a two-point

52:19.200 --> 52:24.240
contact. You have to find two points on the object of pair. In suction, you have to find one.

52:25.120 --> 52:31.760
And so it's just one point contact. But the, but the physics are very different. And so the

52:31.760 --> 52:38.400
resistance to shear forces, for example, are much lower for a suction cup than a gripper. So in

52:38.400 --> 52:45.520
the, the suction cup can be, is, is actually the, the workhorse for this kind of work in industry.

52:45.520 --> 52:53.040
And we can extend Dexnet, um, in a number of ways to make it work in this context. And that's

52:53.040 --> 52:59.280
really been where the team has been pushing the envelope. And we also collect data from every one

52:59.280 --> 53:04.800
of these systems. So it's, it's a, it's a wonderful problem from a machine learning point of view.

53:04.800 --> 53:08.960
Because we have data sets, we have images, we have sensor values, we have all this, we can

53:09.520 --> 53:16.640
characterize every single failure. And analyze it. And then try back testing different algorithms

53:16.640 --> 53:22.080
to be able to reduce those. And that's, that's where there's a, there's a huge opportunity. Because

53:22.720 --> 53:28.240
really, there's this gap. Can we start closing it to really increase the, the throughput,

53:28.240 --> 53:36.560
the pigs per hour? Awesome. Awesome. Uh, well, Ken, I think, uh, we covered a ton of ground,

53:37.120 --> 53:42.800
but also demonstrated that it's really hard to stick to in a half years of robotics,

53:43.440 --> 53:49.200
advancement and innovation in an hour. Uh, so I think that just means we'll have to be sure to

53:49.200 --> 53:53.600
catch up more frequently in the future. Ah, I would love that. Thanks Sam. I have to say I've been

53:53.600 --> 54:00.160
such a pleasure because I listened to your podcast on my bike rides, um, mountain biking. And so

54:00.160 --> 54:07.200
I've just enjoyed them so, so many good hours on a bike, uh, with you. And, um, last thing I want

54:07.200 --> 54:12.000
to say, I don't know if that, when this will air, but the conference on robot learning is going to be

54:12.000 --> 54:20.480
in New Zealand this, in, in December, 14 through the 18th. And it is, um, so I'm, I'm chairing the

54:20.480 --> 54:27.200
conference and we've been, it's been a real pleasure. We have 500 papers submitted a top-notch group

54:27.200 --> 54:34.320
of about 200 papers will be presented there. And you can register as an online, um, online to watch

54:34.320 --> 54:40.240
all the talks and everything else, uh, for, I think it's like close to $200, not too expensive.

54:40.240 --> 54:45.600
And then I will tell you your audience that we're also going to make all this available offline

54:45.600 --> 54:50.720
after the conference. Awesome. Uh, thank you so much, Sam. I really appreciate your great

54:50.720 --> 55:17.680
heartbeat. Thanks so much, Ken. All right. Take care.

