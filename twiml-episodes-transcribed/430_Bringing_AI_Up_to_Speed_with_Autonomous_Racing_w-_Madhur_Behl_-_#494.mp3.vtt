WEBVTT

00:00.000 --> 00:15.680
All right, everyone. I'm here with Mador Behehl. Mador is an assistant professor in the

00:15.680 --> 00:21.280
Department of Computer Science at the University of Virginia. Mador, welcome to this one, my AI

00:21.280 --> 00:26.640
podcast. Yeah, thank you for inviting me, Sam. I'm very happy to be here and excited to share

00:26.640 --> 00:32.240
a thing or two about autonomous racing today. We are going to have a really interesting conversation.

00:33.120 --> 00:39.120
As you mentioned, we're talking about autonomous racing, but before we dig in or race off into

00:39.120 --> 00:43.840
that direction, I'd love to hear you share a little bit about your background and tell us how you

00:43.840 --> 00:52.160
came to work in autonomous vehicles and autonomous racing. Sure, so I think for me, the trajectory

00:52.160 --> 00:59.040
into AI and autonomous racing, it really started because of my love and affinity for robotics and

00:59.040 --> 01:05.040
autonomous systems. So as far as I can remember, I've always been interested in robotics and that

01:05.040 --> 01:11.520
that interest really took shape in my undergraduate back in India, where I even got the chance to sort

01:11.520 --> 01:18.240
of lead the robotics club of my university. I must say, though, back then, you know, I was miles

01:18.240 --> 01:24.720
away from doing anything principal than scientific and what would be an AI. It was mostly about

01:24.720 --> 01:30.400
hacking your way through just getting this set of motor and arms to work and climbing staircase

01:30.400 --> 01:37.680
or navigate some obstacle avoidance course. So I have no shame in admitting early on that I think

01:37.680 --> 01:43.760
I probably have built five or half a dozen robots without ever having written a single piece of

01:43.760 --> 01:51.280
mathematical equation or even drawing on matrix. So really, I think the the journey for me solidified

01:51.280 --> 01:56.880
when I started attending grad school at the University of Pennsylvania and that's really where I

01:56.880 --> 02:01.760
started, you know, learning about the theoretical underpinnings of the field and developing the

02:01.760 --> 02:07.600
background in in control systems and embedded systems and optimization and eventually in machine

02:07.600 --> 02:13.920
learning and autonomous systems and deep learning, which we all know are somewhat like the ingredients of

02:13.920 --> 02:21.440
this, you know, AI field. And so for me, I think the the tipping point or what I realized was that

02:21.440 --> 02:28.000
I had affinity to apply novel theoretical methods but to physical system, right? So that that

02:28.000 --> 02:33.360
aspect of having to control something in the real world, whether that's a robot or it could be

02:33.360 --> 02:38.880
even a building automation system, but something physical, something even safety critical or life

02:38.880 --> 02:44.880
critical. That's something which is canonical to most of my research even today. And so when I

02:44.880 --> 02:50.480
joined the University of Virginia a little over three and a half years ago, you know, I got very

02:50.480 --> 02:57.600
excited and interested in safety aspects of AI for robotics for autonomous systems and self-driving

02:57.600 --> 03:04.320
cars are a very good example for this sort of a problem and someone would consider self-driving cars

03:04.320 --> 03:09.120
to be one of the biggest challenges in the field right now and one which has the potential to

03:09.120 --> 03:15.200
transform mobility. So it got my attention and I was very fortunate to work with some super shop

03:15.200 --> 03:21.200
students and very, you know, great colleagues and have the freedom to pursue some crazy ideas

03:21.200 --> 03:26.480
including one that I would love to talk about today where we are trying to train artificial

03:26.480 --> 03:33.200
intelligence to race self-driving cars at speeds of over 150 miles per hour. Yeah, that's awesome,

03:33.200 --> 03:42.240
that's all. And we will talk about that. I'd like to start by understanding your perspective on

03:42.240 --> 03:52.320
autonomous vehicles racing relative to kind of the more typical autonomous vehicle challenges,

03:52.320 --> 03:59.440
right? In, you know, city driving on the one hand you've got to worry about, you know, pedestrians

03:59.440 --> 04:06.720
and, you know, untrained drivers and balls rolling in the street. All these kinds of challenges

04:06.720 --> 04:12.800
that, you know, we're struggling to figure out how to deal with safely, you know, not to mention

04:13.440 --> 04:16.160
your path planning in an urban environment and that kind of thing.

04:16.160 --> 04:25.600
And a track environment, your, you know, navigation, you know, is constrained quite a bit,

04:25.600 --> 04:31.760
that may be simpler, you know, you may tell us if not. You don't have balls typically rolling

04:31.760 --> 04:36.080
in the street, you don't have the pedestrians trying to run across the track, you know, how do you

04:36.080 --> 04:43.600
think about racing versus, you know, commercial or passenger autonomous vehicles that we're

04:43.600 --> 04:47.840
trying to develop in terms of, you know, relative challenging complexity.

04:48.560 --> 04:53.760
Yeah, I think that's a very great, great question and it touches upon a very key issue that

04:53.760 --> 04:58.960
you already identified that racing as a, as an environment is very different from, you know,

04:58.960 --> 05:04.160
regular driving or urban driving. So, so, so let me maybe, you know, touch upon where I see the

05:04.160 --> 05:09.040
connections and the differences between the two. So, so in a nutshell, you know, if you look at

05:09.040 --> 05:15.200
what is happening in the autonomous vehicle industry today in terms of making a case for

05:15.200 --> 05:21.440
whether or not their prototype car is safe, I really see like two, two ends of a spectrum,

05:21.440 --> 05:26.960
which have to be somewhat navig, we have to navigate those in order to get to like a substantial

05:26.960 --> 05:33.440
point where it can be considered safe enough to be running in the wild. So on one hand, I would say

05:33.440 --> 05:39.840
the approach is what we can describe as brute force. So, let's drive millions of miles whether

05:39.840 --> 05:44.160
in simulation or in the real world using hundreds of thousands of vehicles in the fleet.

05:44.800 --> 05:49.360
And really, you know, start looking at where did the vehicle make a mistake, when did the safety

05:49.360 --> 05:54.640
operator had to intervene, when did somebody disengage the autonomous mode and things like that.

05:54.640 --> 05:59.200
So it's like a, you know, bucket list of, oh, here's something I have to get back to my engineers

05:59.200 --> 06:04.560
and design, been back to the table. And so it, I don't want to undermine the value of real world

06:04.560 --> 06:10.240
testing. I think it's irreplaceable, but at the same time, this sort of a exhaustive approach,

06:10.880 --> 06:15.760
some might argue is, you know, the list of things that you have to account for are, you know,

06:15.760 --> 06:20.800
uncountable or infinite in some sense, the list of possible things that can go wrong. And these include

06:20.800 --> 06:25.440
you're checking off a list of corner cases. You've got a long list that you need to check off.

06:25.440 --> 06:30.320
Yeah, and I would say that it's maybe even impossible to check it off completely. So you get into

06:30.320 --> 06:35.920
this whole argument about what sort of a statistical guarantee could you offer at the end of the day.

06:35.920 --> 06:40.960
I think that's a, that's a separate discussion to be had. So you're right, you know, and the part

06:40.960 --> 06:47.040
of the problem is this heterogeneity in the number of objects that have to appear in the scene.

06:47.040 --> 06:52.320
And even if you have perfect detection of these different agents, different vehicles or

06:52.320 --> 06:56.960
lane markings, traffic signs, traffic lights, pedestrians, pets, they're a very long list.

06:58.080 --> 07:04.080
Even if you had 100% accurate scene understanding, it's very difficult to anticipate what everybody

07:04.080 --> 07:09.440
else is doing, which you need to do in order to plan your own sort of maneuver in the short term,

07:09.440 --> 07:14.720
in like, you know, the next second or two seconds. So this is where I think most of the focus of

07:14.720 --> 07:21.040
demonstrations and very impressive in many cases without a driver behind the wheels is being done

07:21.040 --> 07:27.920
today. On the other end of this spectrum is more theoretical. We need some breakthrough, I would say,

07:27.920 --> 07:35.520
in bridging AI and deep learning with giving guarantees or formal methods, which is like a sub-discipline

07:35.520 --> 07:42.640
and computer science, right? So can we design algorithms which we can, you know, look at what bad

07:42.640 --> 07:48.160
inputs will cause, what bad outputs. And in a nutshell, they have to be accountable for why they

07:48.160 --> 07:53.440
are making a mistake, which is, you know, we are very far from that. There's some very exciting work

07:53.440 --> 07:58.320
in that area as well, but we are not quite there yet, you know, so that breakthrough has to occur.

07:58.320 --> 08:02.640
So this is a wide spectrum. There's many other approaches. I'm a little bit simplifying it.

08:03.600 --> 08:10.000
And so I see there's many intermediate steps where you could still make progress and enhance

08:10.000 --> 08:16.720
safety of cell driving cars. And so one idea or rather hypothesis that we are working on is what I

08:16.720 --> 08:23.600
would call safety through agility, with the idea of being that if we can teach an autonomous

08:23.600 --> 08:30.560
vehicle how to operate at the limits of its control, how to steer aggressively, how to break

08:30.560 --> 08:37.520
aggressively, how to maneuver in an agile manner, then I would argue you are ultimately enhancing

08:37.520 --> 08:44.320
the safety of that autonomous vehicle, right? So I'll be the first one to say that, you know,

08:44.320 --> 08:50.640
driving safely and driving in an agile manner seem to be very contradictory, sort of objectives.

08:50.640 --> 08:54.000
And so we are not proposing that you weave through traffic all the time.

08:55.360 --> 09:00.560
But but instead there are some theoretical results to say those folks that drive a little fast

09:00.560 --> 09:06.960
and weave through traffic help the traffic. Yeah, yeah, you're right. I can't argue with that.

09:06.960 --> 09:14.400
But yeah, so the idea is we have all experienced this when we drive ourselves that there are

09:14.400 --> 09:19.920
irrational drivers as a mix of sort of human and semi-economist eventually autonomous cars.

09:19.920 --> 09:24.240
And so we've seen, you know, occasionally that driver who indicates they will take the right

09:24.240 --> 09:28.640
exit but then the merge left in front of you at the last second or someone who just break

09:28.640 --> 09:34.480
check you for no reason or speed up and overtaken an unsafe manner. So so so there's all these

09:34.480 --> 09:41.040
dynamic situations that the self-driving car has to deal with. And I would even go as far as saying

09:41.040 --> 09:49.600
that any collision or any imminent collision at the in the very last few milliseconds or even a second

09:49.600 --> 09:55.280
looks a lot like, you know, racing because you are at a high speed and it's like a very abrupt

09:55.280 --> 10:03.600
change in momentum. And so so the idea is that can we use racing as a means to learn this agile

10:03.600 --> 10:09.120
controller, right? So this this controller that will augment the safe operation and but kick in

10:09.120 --> 10:13.920
when there's an imminent collision. So so I jokingly say this but I think it's becoming true and

10:13.920 --> 10:18.400
true. Everybody's teaching their vehicles to remain on the road. I'm teaching them with the

10:18.400 --> 10:22.720
ability to go off road if it matters most if it ends up, you know, saving someone's life at the end

10:22.720 --> 10:29.760
of the day. So so that's the connect between being safe and being agile. And so the next question

10:29.760 --> 10:36.000
obviously is that how do you train a autonomous vehicle to be agile? And so that's where we draw

10:36.000 --> 10:41.760
inspiration from motorsport racing. And we simply say that let's race these cars against each other

10:41.760 --> 10:48.000
in these high speed close proximity situations, which are the norm rather than the exception when

10:48.000 --> 10:52.880
it comes to being on the track, right? So most of racing is drivers trying to crash each other but

10:52.880 --> 10:57.920
not quite. And even like impeding the progress of each other. So if we can capture those

10:57.920 --> 11:05.440
patient temporal interactions and you know manifest them into a robust algorithm, then we have a

11:05.440 --> 11:11.360
chance of bringing it back to urban driving and enhancing overall safety. So so in a nutshell,

11:11.360 --> 11:17.680
you know, in motorsport racing, there's a saying that if everything seems under control,

11:17.680 --> 11:22.000
then you're not going fast enough, right? That's the that's the mentality of the race driver.

11:22.000 --> 11:27.600
And so what I'm trying to do is develop an AI with with that statement as its objective function.

11:28.720 --> 11:38.400
Nice. So to kind of understand the the landscape and the approaches in autonomous racing on the

11:40.240 --> 11:45.760
you know, urban driving kind of contemporary autonomous vehicles. One of the

11:45.760 --> 11:55.600
dimensions in which there are strong opinions is kind of the you know vision first or vision only

11:55.600 --> 12:05.200
approach, you know, versus kind of sensor fusion. That's kind of correlated in some ways to end

12:05.200 --> 12:17.840
to end deep learning versus ensemble systems is. And I'm curious if the the racing setting has

12:17.840 --> 12:27.360
specific implications in those dimensions or you know, or you know, as it just is diverse, the

12:28.560 --> 12:34.480
directions that folks are going. Yeah. So the the short answer is there's a lot of room for

12:34.480 --> 12:40.160
many approaches, but but I'll I'll get into a little bit in the weeds of, you know, answering that

12:40.160 --> 12:45.360
more specifically. So so Geek out with me for a second here Sam. So, you know, and even it goes

12:45.360 --> 12:52.800
back to even what she said earlier. So, yes, racing doesn't look visually anything like urban driving.

12:52.800 --> 12:57.680
We don't have to solve this problem of detecting a million things on the track, right? There's

12:57.680 --> 13:02.160
only a few things. You would be actually surprised if there's anything besides another car on the

13:02.160 --> 13:07.920
track. We don't want that at all. So, so yes, you know, the equivalency is broken there. I think

13:07.920 --> 13:15.680
the biggest sort of if I have to sort of outline it in terms of approaches or technical issues.

13:16.720 --> 13:21.920
So every robot or every set of driving car has to solve these three problems of perception,

13:21.920 --> 13:27.600
planning and control. That's the common DNA for all of robotics. And so so in perception,

13:27.600 --> 13:33.280
we have a different set of problems in racing, but they are going to affect regular driving.

13:33.280 --> 13:38.240
I mean, list some of the challenges itself. And then we can discuss whether vision only or

13:38.240 --> 13:45.760
fusion is a better way to go about it. So, no one or there is literally very limited or non-existing

13:45.760 --> 13:54.720
data. How does lidar and camera and radar perform at speeds excess of 150 miles per hour, right? So,

13:54.720 --> 14:00.800
this vibration images are going to get blurred. Is there skew in the radar because you are moving

14:00.800 --> 14:05.680
at hundreds of feet per second. So, by the time you receive some packet, things have already moved

14:05.680 --> 14:11.360
around in your vicinity. And so, you know, what is the time specific to vehicles? I would have

14:11.360 --> 14:18.720
imagined that, you know, we'd be drawing on military uses of or, you know, aeronautical uses of

14:18.720 --> 14:23.040
radar and lidar and there would be lots of information about how they perform at speed.

14:23.040 --> 14:28.880
Yeah, but would you be surprised like the sort of sensors that we are working on with the

14:28.880 --> 14:33.280
full-scale car, which are the same sensors. So, let me maybe re-phrase my statement.

14:33.280 --> 14:39.520
Yeah. The same family of sensors, which are on urban cars, haven't been tested yet on these

14:39.520 --> 14:45.120
things. So, you are right. There's definitely something that I don't know of or this classified

14:45.120 --> 14:50.000
sensor, which has been tested. Yeah. Yeah. And I thought you were referring to

14:50.000 --> 14:53.840
lidar and radar as a broad class. No, no, no, no.

14:53.840 --> 14:58.400
It has opposed to the specific, you know, working with a specific sensor. Yeah, that's a great

14:58.400 --> 15:03.360
point because, you know, if we're talking about a machine learning, deep learning solution,

15:03.360 --> 15:06.880
they're going to be quite sensitive to the actual sensors that you're using.

15:06.880 --> 15:11.840
Yeah, you got it, right? So, the specific sensors themselves, we have to work with a lot of issues.

15:11.840 --> 15:18.400
Like, even something that you may not think about for a regular car, there's a very important aspect

15:18.400 --> 15:22.880
that all your sensor data has to be perfectly synchronized to the same clock.

15:23.440 --> 15:29.840
And in regular driving, you can bear some offset between the lidar and the camera images,

15:29.840 --> 15:34.560
right? So, the lidar is telling you there's an obstacle at this bearing and this distance,

15:34.560 --> 15:38.480
but the camera is telling you that the pixel and the obstacle is offset.

15:38.480 --> 15:42.960
You can get by, you can do some machine learning to fix that, learn the skew over time.

15:42.960 --> 15:50.880
In racing, the margins become very, very thin, right? So, the burden then is shifted to the

15:50.880 --> 15:56.080
software because you can only do so much hardware synchronization on the real sensor.

15:56.080 --> 16:02.080
So, these are just few examples in the perception stack, right? So, let's move to planning and then

16:02.080 --> 16:10.320
we can go back to the fusion question. So, in racing, I would say planning is somewhat harder

16:10.320 --> 16:15.440
than regular driving because there is no structure to the traffic, right? So, racing has some

16:15.440 --> 16:20.800
general etiquette that drivers respect each other. They don't want to crash their own car,

16:20.800 --> 16:25.360
but it's not as spelled out as the rules of the road, which are embedded deep into

16:26.000 --> 16:29.920
all the motion planning algorithms of regular self-dabbing vehicles today.

16:29.920 --> 16:34.240
So, there's no concept of yield or, you know, you don't want to yield basically,

16:34.240 --> 16:37.840
but at the same time, you don't want to go into unnecessary risks. So,

16:37.840 --> 16:45.200
so there, one of the challenges that we have to solve is we have to build state estimation algorithms

16:45.200 --> 16:50.160
that will give a best guess or the likelihood of what the racing driver

16:50.880 --> 16:55.360
in front of us and behind us is going to do. And that's another thing about racing. You also have

16:55.360 --> 16:59.520
to worry about what's behind you and not just everything is not just forward looking because you

16:59.520 --> 17:05.600
have to sometimes maneuver to gain, like, positional advantage. And so, here there's a lot of room

17:05.600 --> 17:15.040
for normal algorithms where, you know, you are planning in a manner that you want to trade off

17:16.000 --> 17:21.200
risk versus your track position, but at the same time, you really don't want to thread the

17:21.200 --> 17:28.320
needle between two cars if it's not absolute necessary to do so. So, so we made some, you know,

17:28.320 --> 17:34.000
some algorithms, which are a mix of, I would say, this end-to-end idea and, you know,

17:34.000 --> 17:39.920
classical approach of path planning. So, so I'll give you one example that in one of my work

17:39.920 --> 17:48.560
with my PhD student Trent Weiss. So, he has developed this simulator. Essentially, he has taken

17:48.560 --> 17:54.480
the world's most famous Formula One game. And this game is so photorealistic that it's used by

17:54.480 --> 18:00.000
real F1 drivers during the pandemic because they couldn't race in the real world. And so,

18:00.000 --> 18:04.800
it's very photorealistic. It's, you know, building upon decades of high-fidelity physics and

18:05.360 --> 18:10.960
ray tracing graphics and whatnot. And this game is so realistic that it actually outputs a stream

18:10.960 --> 18:16.560
of data to interface with these massive hardware simulators that these drivers train in.

18:17.120 --> 18:23.040
So, we leverage that. We leverage that and we tap or listen into that data stream. And then we

18:23.040 --> 18:28.960
can convert the game into a simulation environment, right? So, all of a sudden, we have methods to

18:28.960 --> 18:34.720
look at the images of the camera from the game from the driver's perspective and annotate that

18:34.720 --> 18:39.360
with some ground truth data about steering, what speed and heading and things like that.

18:39.360 --> 18:44.400
So, this becomes a recipe to try some end-to-end methods. And we did try them and we found that

18:45.040 --> 18:51.280
if you just do a complete pixels to control end-to-end implementation, where you are basing your

18:51.280 --> 18:56.720
steering and throttle based off the scene information or pixel information or even a history of

18:56.720 --> 19:01.360
pixel information or images, it's very brittle, right? So, it's simply just too brittle. The car

19:01.360 --> 19:08.480
cannot recover. If you go off track, you basically ram into the wall for sure. And so, we had to fix

19:08.480 --> 19:16.320
that by breaking this chain of not being purely end-to-end. And so, what we do is we take the images

19:16.320 --> 19:22.560
and instead of mapping them to control values, we map them to trajectories, right? So, we map them

19:22.560 --> 19:28.320
to, this is the path you want to follow for the next, you know, 100 milliseconds or one second

19:28.320 --> 19:34.560
or whatever horizon. And so, that's a go-control. And then, yeah, then you use some low-level control,

19:34.560 --> 19:39.680
like pure pursuit or model predictive control to actually figure out the steering and the throttle

19:39.680 --> 19:45.200
actuation to follow that path. And what we have determined, very surprisingly and interestingly,

19:45.200 --> 19:51.600
this is so robust, right? So, this is already as competitive as some of the best human

19:51.600 --> 19:58.400
export drivers in the game. And, you know, it has a very good understanding of where the track

19:58.400 --> 20:03.760
bounds are. And I must say that initially, we went in purely with this supervised learning

20:04.480 --> 20:09.360
method. So, it's like a behavioral cloning. We have tons of data of drivers driving in the game.

20:09.360 --> 20:15.680
But now, we have the ability to not do just purely supervised learning, but instead,

20:15.680 --> 20:21.840
at runtime, we can actually generate many, many likely trajectories and then synthesize

20:21.840 --> 20:25.680
the preferred trajectory, which has some desirable properties. So, you know, you don't want to turn

20:25.680 --> 20:31.120
the wheel so sharply, or you don't want to minimize some derivative of the trajectory as well.

20:31.120 --> 20:37.520
So, interestingly enough, the way we design these trajectories is using something called

20:37.520 --> 20:42.720
Bezier curves, which have their region and computer graphics. And I just want to throw in this

20:42.720 --> 20:48.880
trivia or snippet here that Pierre Bezier, who was the pioneer of the Bezier curve, he intent,

20:48.880 --> 20:54.480
he used these curves, or when they were invented or used or popularized, he used them to design

20:54.480 --> 20:59.760
the profile of Renault race cars, right? So, in a very serendipitous way, we are bringing the

20:59.760 --> 21:05.760
racing routes of Bezier curves back into autonomous racing. And so, so the last thing I would say here

21:05.760 --> 21:15.680
is, again, if you can put a pin in that for one sec and remember it, you mentioned a bunch of

21:15.680 --> 21:20.960
things I wanted to fill in on, but one of the things that you talked about was you had this

21:22.640 --> 21:28.080
this kind of path that your low-level system is recommending or a family of paths, and then you

21:28.080 --> 21:34.240
have a set of constraints or desired properties. And I'm curious what those, you know, how those

21:34.240 --> 21:41.440
are implemented are those heuristics or those also learned. Where does that, how do you inform

21:41.440 --> 21:48.640
your model of those preferences? Yeah, so they are learned, although that is a possibility to use

21:48.640 --> 21:54.880
some kind of inverse reinforcement learning to learn what objective function the drivers actually

21:54.880 --> 22:01.440
use to generate their own paths, but we aren't there quite yet. So, so what we draw inspiration from

22:01.440 --> 22:07.200
is the actual domain of racing, right? So, so my students have now we have

22:08.720 --> 22:14.320
racing rules, we have watched videos, we have watched interviews of every crash that has happened

22:14.320 --> 22:19.200
and how the drivers explain what went wrong in that crash. And so, this filtering process, right,

22:19.200 --> 22:25.760
if generators set of candidate possible trajectories you could take, and then you have some way of

22:25.760 --> 22:32.080
assigning cost to each trajectory. So, there could be a cost of you don't want to be, you know,

22:32.080 --> 22:36.880
a certain distance laterally from any opponent, and that's, you know, gives the trajectory a certain

22:36.880 --> 22:41.600
way. Another one, like I said before, as you want your trajectory to be have some smoothness

22:41.600 --> 22:46.720
properties so that, you know, the car will spin out if you rank the the steering wheel because

22:46.720 --> 22:53.120
these are very sensitive vehicle dynamics. And so, so this is the layer where we can

22:53.120 --> 23:00.080
sprinkle in the objective functions for collision avoidance, for multi agent racing, for, you know,

23:00.080 --> 23:06.480
taking the sticking as close as possible to the geometric race line. So, we have, you could call

23:06.480 --> 23:12.240
it a heuristic, but it is these are heuristics which are derived from the domain of regular

23:12.240 --> 23:16.880
motorsport racing. So, they're informed by, you know, what drivers typically look to maximize

23:16.880 --> 23:22.000
one day race. So, yeah, so there is room to do some machine learning there as well, but we haven't

23:22.000 --> 23:25.920
gotten to that yet. Awesome, awesome. The third point that you were mentioning.

23:27.040 --> 23:34.000
Yeah, I mean, I was I was talking about that initially, the way we train our algorithm to map

23:34.000 --> 23:41.280
images to trajectories in the front of the car ego vehicle on the track, it's it's it was using

23:41.280 --> 23:46.720
behavioral cloning, which means that we have tons of data observed from the game of regular,

23:46.720 --> 23:53.760
you know, online players. Now, we can even, you know, log into a session as a autonomous agent,

23:53.760 --> 23:59.360
and have a car race autonomously amongst other humans without nobody ever finding out that

23:59.360 --> 24:04.480
they're racing against a game AI, right? So, so, so, so essentially, we can get data,

24:04.480 --> 24:11.120
an observed data of other players as well. And mind you, this is, this seems like a good idea,

24:11.120 --> 24:16.720
but there's a lot of bad data, right? I mean, like, do you have some amateur players who are cutting

24:16.720 --> 24:22.480
corners and we don't want our algorithms to pick that behavior, right? We wanted to have a clean

24:22.480 --> 24:28.400
lap between the bounds of the track and set the fastest sort of lap time as well. So, that's why,

24:28.400 --> 24:34.160
if you just do behavioral cloning, as you would in some any other machine learning setting,

24:34.160 --> 24:39.120
so supervised learning, you just have image and here's the trajectory, which was taken by the

24:39.120 --> 24:43.840
expert. So, just try to, you know, do some least square error between your trajectory and the

24:43.840 --> 24:49.120
ground truth. So, that will get you halfway there, but because you are averaging over

24:49.840 --> 24:56.880
multiple levels of expert data, it won't reach or get you to the point where you become competitive

24:56.880 --> 25:03.520
in this in this setting. So, that's why we have to augment and take a step back from behavioral

25:03.520 --> 25:09.120
cloning by saying that it's not proved end to just generate one trajectory and follow it blindly,

25:09.120 --> 25:14.960
but let's generate a candidate of many possible trajectories and then use these sort of filtering

25:14.960 --> 25:20.160
methods that are described earlier to choose between them. Then the thing that I was wondering was

25:21.280 --> 25:26.800
if the behavioral cloning was related to or if you draw inspiration from imitation learning

25:27.600 --> 25:32.240
as it plays out in like reinforcement learning scenarios? Yes, yes, I would say very much so,

25:32.240 --> 25:38.400
it's a, they're very alike. And then we are, you know, the, we are somewhat hitting the ceiling

25:38.400 --> 25:43.200
of the fact that this is not meant to be a simulator. We are just, it's a game that we have,

25:43.920 --> 25:49.520
and by the way, anyone can, you know, buy the game for what 30 bucks and the API is open source,

25:49.520 --> 25:54.400
you can run all our experiments and I think I provided the link to this as well. But the,

25:54.400 --> 26:01.280
the, you know, this, this, this doesn't behave like a simulator where we could hook it up to some

26:01.280 --> 26:06.480
kind of an open AIJM or reinforcement learning framework and run millions of instances very,

26:06.480 --> 26:11.520
very fast to do exploration, exploitation. So we want to do that. I think we need much more

26:11.520 --> 26:17.520
low level access to the game and we are in conversation with the actual manufacturer of the

26:17.520 --> 26:23.200
the game itself for a much more formal collaboration than us just trying to infer things based

26:23.200 --> 26:31.680
on what's readily available. So, you know, of the, the three areas that we've talked about,

26:31.680 --> 26:38.800
I think perception is about what I expected. You kind of lose some complexity because you don't

26:38.800 --> 26:44.560
have to worry about things coming on the road, but everything's happening much faster. Control,

26:44.560 --> 26:48.400
you know, things are happening much faster. I expect that to be more complex.

26:48.400 --> 26:54.480
Planning, I think, is the one that surprises me. I would have thought that planning was simplified

26:54.480 --> 27:02.720
in the race environment because, you know, you go at the track is, is, is static and circular,

27:03.680 --> 27:10.160
at least in a simple example. And everyone's goals are the same. You don't have people kind of

27:10.160 --> 27:16.480
crossing through your, your domain that are trying to do random things that you have no idea or

27:16.480 --> 27:21.520
can't even fathom or predict what they might be trying to accomplish. But it sounds like that's

27:21.520 --> 27:26.320
not the case in your experience. Yeah, it's, it's, it's, it's not as easy. I mean, there are,

27:26.320 --> 27:33.680
there's some truth to your sort of expectation, but I think the, the thing which I think surprised us

27:33.680 --> 27:40.560
was, even this, even you would imagine it's easier to predict what your opponent is trying to do,

27:40.560 --> 27:46.320
but it turns out it's, it's pretty complicated, right? Because, because there is no, they could be

27:46.320 --> 27:52.400
literally the, the reachability of their likely positions in the future just explodes. Because,

27:53.040 --> 27:58.160
because even a small maneuver can get picked up by some algorithm or a Kalman filter and they

27:58.160 --> 28:02.560
will just extrapolate that to, well, they could be anywhere on the track. Well, if that's the case,

28:02.560 --> 28:07.600
how do I make progress? Right? So, so I think getting that piece pitch perfect has been,

28:07.600 --> 28:14.480
has been more of a challenge than I originally anticipated. And then the, the speed at the end

28:14.480 --> 28:20.000
of the day is the bottom line, which makes all of this super, super difficult, right? So, we don't

28:20.000 --> 28:26.080
have even the luxury of time to do something super complex at runtime, right? Because you may want

28:26.080 --> 28:31.600
to say, okay, when I get to this turn, I'm going to do, you know, take this race line and if

28:31.600 --> 28:36.960
somebody's on my race line, I'm going to plan something else. Well, you know, by the time you figure

28:36.960 --> 28:41.600
out your result, you're already there at the, at the turn, right? So, because the, the car is moving

28:41.600 --> 28:48.720
so fast. So, so getting that trade off of how do you dynamically adjust your horizon? You do,

28:48.720 --> 28:53.680
and then there is, there is high level planning strategy, which comes into play, right? So,

28:53.680 --> 29:00.880
you have to think about the effect of the vehicle dynamics on your planner. So, these cars are

29:00.880 --> 29:06.800
highly specialized and they have very different dynamics than regular sedans or SUVs that we drive.

29:06.800 --> 29:12.640
And so, therefore, you have to understand that the tires will behave differently after 10 laps.

29:12.640 --> 29:17.760
You have to monitor tire temperature, tire pressure, wheel slip angles because the car will just

29:17.760 --> 29:23.840
drift out if you try to, again, turn to send, it's very sensitive to the rate of your steering

29:23.840 --> 29:29.200
that you input into the car itself. You have to account for aerodynamic effects, right? So, in the,

29:29.200 --> 29:34.560
in the real race, and also in the simulation race that we are doing as part of preparing to,

29:35.360 --> 29:41.520
you know, move to the real car, all cars are same, right? It's a battle of AI algorithms.

29:41.520 --> 29:47.200
It's not about who has the deepest pockets or the most expensive motor. So, so, so if everything

29:47.200 --> 29:53.120
is the same, you have two competitive cars. How do you ever overtake your opponent? And so, in

29:53.120 --> 29:59.440
racing, there is this concept of slipstream or drafting. So, when you get behind an opponent,

29:59.440 --> 30:06.000
opportunistically, you will gain upon them because you are moving through less, sort of dirty

30:06.000 --> 30:11.920
air, less draft. And so, so, where's the path planner which takes that into account, right?

30:13.200 --> 30:18.400
It's not there yet. So, so, there is just, the devilism, the details, basically, at the end of

30:18.400 --> 30:23.840
the day. And that's why the motion planning algorithms, which exist for regular driving,

30:23.840 --> 30:28.400
you can take inspiration from them. But because of the lack of structure, there's no lanes,

30:29.040 --> 30:35.200
there's no defined rule set of what other opponents are really trying to do. And that's really what

30:35.200 --> 30:40.880
got, you know, causes the problem. And if it speak to any real race driver, which I've had the,

30:40.880 --> 30:46.480
the good fortune of doing so, they will tell you that they race with feel, okay? They can feel

30:46.480 --> 30:51.440
when the car is sitting at the edge of its traction. They can feel when the rear left is going to

30:51.440 --> 30:56.480
give out any time and so they can back off. In the track that we will race on in Indianapolis,

30:57.520 --> 31:01.360
it's very unforgiving because there's a concrete barrier on the right hand side throughout the

31:01.360 --> 31:07.440
over. So, there's literally, you know, no incentive to go right unless you are doing it to, to save

31:07.440 --> 31:13.280
yourself from a crash. So, so, so there's just a pile of issues we have to work through and make sure

31:13.280 --> 31:18.800
our planner is robust and can account for a combination of many of these issues that we are aware of.

31:20.960 --> 31:30.000
So, you in talking about planning, you raised this issue of a kind of hierarchical planning,

31:30.000 --> 31:34.160
you've got, you know, when you initially described it, you kind of project in, you know,

31:34.160 --> 31:39.120
a few milliseconds and then you're choosing a path based on that. But then there's this higher

31:39.120 --> 31:44.000
level planning that you might want to do. You reference the slipstream issue. I don't know if the

31:44.000 --> 31:48.960
track that you'll be racing on are the ones that you model are oval tracks. But if you've got a more

31:48.960 --> 31:53.440
complex track, you want to kind of hit the corn, hit the curves at a certain point, you know, low

31:53.440 --> 32:00.240
on the curve. Like, how do you incorporate that type of higher level planning in? Is that part of

32:00.240 --> 32:05.840
these heuristics that you include in the low level or is it a totally different process?

32:05.840 --> 32:10.880
So, I think different teams are taking different approaches. In my case, we have actually taken

32:10.880 --> 32:16.080
a cue from some data driven and, you know, some machine learning methods that can help us out there

32:16.080 --> 32:25.360
as well. So, we have some data to infer from how racing experts navigate high level strategic

32:25.360 --> 32:32.000
decisions. So, you know, there's even some very good evidence and footage of a driver intentionally

32:32.000 --> 32:37.600
backing off at a corner because they know that on the straightaway, they will get into the slipstream

32:37.600 --> 32:43.680
and be able to attempt in a better, you know, have a better shot at overtaking. So, so at the high

32:43.680 --> 32:49.760
level, it boils down to, if I think about it, boils down to two or three high level things that we

32:49.760 --> 32:58.240
have to always worry about. One is everybody, if they have done their homework, knows what is the

32:58.240 --> 33:03.840
geometric fastest way around the track, right? That's sort of open knowledge. It's easy to determine.

33:03.840 --> 33:09.680
And so, that's the one where if it's an oval, it's not as complex, but it's the one where you want to

33:09.680 --> 33:15.120
carry the highest speed through every corner. So, you kind of go out on entry, you touch the apex and

33:15.120 --> 33:21.040
then you exit wide as well. And that will give you the sort of the curve of the largest radius. So,

33:21.040 --> 33:25.600
it's the minimum steering input. So, everybody knows that. Everybody wants to be on that, but that's

33:25.600 --> 33:31.200
the problem, right? Because if someone else is on your race line, you have two options. So,

33:31.200 --> 33:38.400
either you go into some kind of adaptive cruise control mode, where you just stay behind them

33:38.400 --> 33:45.120
until they make a mistake and then you get your chance. Or you intentionally decide to deviate

33:45.120 --> 33:51.280
from your race line and see if there's a wide enough gap and where you want to merge back on the

33:51.280 --> 33:56.080
race line in front of them, all the while being aware of if there's any other cars which may

33:56.080 --> 34:02.560
interfere in this entire maneuver. And so, so this multi agent aspect of high speed racing is also

34:02.560 --> 34:08.480
what's making it very difficult. And it's a combination of both the short term path you want to plan.

34:08.480 --> 34:13.520
And, you know, you don't want to be myopic. You don't want to go after every opportunity of overtaking

34:13.520 --> 34:18.560
as well. So, that's where some strategy comes in. You want to be aware of what is your current track

34:18.560 --> 34:23.040
position. So, are you behind the pack? Are you in the middle? How many laps are left?

34:23.760 --> 34:27.920
What is the rate at which you can close the gap to your leading car? So, there's just

34:28.960 --> 34:35.280
all of this racing knowledge has been embodied into a code essentially by my team over the past

34:35.280 --> 34:41.600
year and a half. And, you know, that's what's allowing us to to match this high level strategic

34:41.600 --> 34:46.640
controller with the low level planner. And then even lower than that is the controller itself,

34:46.640 --> 34:52.480
which is going to make sure we can follow the plan that we regenerate. So, it's a mix of,

34:52.480 --> 34:57.440
again, I know I'm giving the same answer again, but that's really the case. It's a mix of

34:58.560 --> 35:05.040
these domain specific maneuvers or strategic decisions that we have been able to

35:06.880 --> 35:11.280
encode into some kind of a logical sort of construct. And we're trying to implement that

35:11.280 --> 35:17.920
using classical methods or using deep learning based approaches. Yeah. One thing comes to mind

35:17.920 --> 35:23.760
in thinking about this that I'm not sure I can come up with any examples of having seen.

35:24.560 --> 35:33.040
And that is, typically when we've got, you know, video off of a vehicle and we're labeling it,

35:33.040 --> 35:40.000
we're labeling it for things in the video, your description makes me think about, you know,

35:40.000 --> 35:46.560
is there is there some kind of model or process where it makes sense to label

35:47.920 --> 35:54.000
video or some other set of fees for driver intent? Like, what is the driver trying to do here?

35:54.000 --> 36:01.680
And then train a model based on trying to learn and to learn driver intent and, you know,

36:01.680 --> 36:07.040
then feed that into control. Does that make any sense? It does. And, you know, what, like just

36:07.040 --> 36:15.760
prior to this, this, this, this podcast earlier today, I am working with a bunch of people

36:15.760 --> 36:20.560
who are helping us label some of the data from these videos which are openly available.

36:20.560 --> 36:27.840
So, so you raise a good point about the intent and we can do a certain bit of that in the game

36:27.840 --> 36:34.160
because in the formula one game, we can determine the track position of whatever cars

36:34.160 --> 36:40.880
enough field of view. And a history of track position is an indicator of future trajectory of

36:40.880 --> 36:46.160
the vehicle. And so that's actually the, the ingredients to this model which is doing the state

36:46.160 --> 36:51.440
estimation for other agents, right? It is some kind of a recurrent neural network which is looking at

36:51.440 --> 36:56.400
a history of intent of the driver and then trying to predict the most likely thing that driver

36:56.400 --> 37:05.600
is going to do within my planning horizon. Having to capture intent just from like on board

37:05.600 --> 37:11.200
camera footage is pretty difficult, I would say I haven't tried it. But you would be surprised

37:11.200 --> 37:15.920
like even something that we may take for granted because, you know, like you would say, okay,

37:16.800 --> 37:22.720
if we go back to perception, we don't even think about that detecting vehicles, how difficult of

37:22.720 --> 37:28.240
that is a problem for said driving because there's a pre-trained networks on these massive

37:28.240 --> 37:34.000
data sets that can classify 3D bounding boxes and volumes of wear vehicles is wear the

37:34.000 --> 37:41.680
draggable surfaces. And we used some of these data sets and these pre-trained networks and we

37:41.680 --> 37:47.440
told them can you now tell us where the racing cars are on the track and they were like no

37:47.440 --> 37:55.840
better than a coin toss. So there's not even a specialized data set for doing bounding box

37:55.840 --> 37:59.920
detection for racing vehicles because yeah, I mean, at the end of the day, if you detect four

37:59.920 --> 38:05.200
wheels, it's likely a car. But the rear end of the vehicle, the side perspectives, they look very

38:05.200 --> 38:12.000
different from these regular vehicle detection. So I'm having to lead that effort myself and we

38:12.000 --> 38:18.560
have a corpus off, you know, tens of thousands of images now where we are detecting the bounding

38:18.560 --> 38:26.080
boxes for the specialized Indy car looking vehicles. And so my feeling is once you can get to where,

38:26.080 --> 38:32.000
let's say, the centroid of that vehicle detection is, then you start looking at a history of

38:32.000 --> 38:37.680
image sequences and that will give you some some idea of the intent of the real driver as

38:37.680 --> 38:41.920
opposed to the gaming driver. So there might be something, something too yet. We haven't done

38:41.920 --> 38:47.200
it with real data and we are relying on our state estimator which is trained on the simulation

38:47.200 --> 38:50.720
and the game yet to solve this problem of intent prediction there.

38:55.040 --> 39:01.440
So we've talked about the the challenges relative to racing and you've got some specific

39:01.440 --> 39:08.160
examples of the way you put the stuff to the test. You've hinted at one which is this

39:09.680 --> 39:14.800
autonomous challenge. But you've got another one and I think you've got an example of that in

39:14.800 --> 39:23.120
your background there. This one 10. Tell us about that. Yeah, so this is this is a I know if someone

39:23.120 --> 39:28.080
is not looking at the video, there's a one 10 scale vehicle behind me. It's a fully autonomous

39:28.080 --> 39:36.080
one 10 scale race car. So yeah, this is another one of my my brainchild and I really like

39:36.080 --> 39:42.880
developed this when I was graduating out of my PhD degree at Penn. And so before I kind of

39:42.880 --> 39:47.520
describe what this is all about and the in the autonomous challenge which is the next big thing

39:47.520 --> 39:54.080
that we are currently navigating around. Let me prefix this by by just saying you know,

39:54.080 --> 39:59.280
we do all the research and the cool things in our lab and we have access to all these resources.

39:59.840 --> 40:05.520
But I've always felt that the way you know, there's a big gap between the way we conduct research

40:05.520 --> 40:10.960
in cell driving and autonomous vehicles and the way we teach about these things to

40:10.960 --> 40:17.520
undergraduates and graduate students alike. And so so a lot of the the initiative behind

40:17.520 --> 40:25.360
developing this f 110 or this one 10 scale racing platform was to make autonomy accessible

40:25.360 --> 40:30.400
for everyone right. So I actually truly believe that this is the best time to be working in AI

40:30.400 --> 40:34.240
and autonomous vehicles and then you know, these these technologies are already sort of well

40:34.240 --> 40:41.920
knit into the fabric of society. So so this this vehicle is essentially was a scale version of

40:41.920 --> 40:48.400
what you would find on a regular cell driving prototype. So it has a lidar, it has cameras,

40:48.400 --> 40:54.400
it has an IMU sensor, it has the same family of the GPU from Nvidia that you would find on full

40:54.400 --> 40:59.840
scale cars. It has a wireless channel which you can remotely access for telemetry. And so

40:59.840 --> 41:06.240
so we developed this and we made this open source. Anyone can go to f110.org and then you will

41:06.240 --> 41:12.320
find this almost IKEA like instructions for how to put this together. And then you know,

41:12.320 --> 41:17.280
you can put the hardware together. It's is reasonably priced but then there's the software part

41:17.280 --> 41:23.120
right. So like I said before, this is all about improving algorithms of perception planning control.

41:23.120 --> 41:30.080
So I actually teach a course on autonomous racing online and you can also find out on YouTube

41:30.080 --> 41:36.160
it's not behind any paywall. It's just free. All the video lectures will walk you through first

41:36.160 --> 41:41.920
understanding the software which is based in Ross or robot operating system. And then we gradually

41:41.920 --> 41:48.320
go all the way to you know, path planning and perception and slam and mapping and then eventually

41:48.320 --> 41:52.480
racing. And so there's a great this is a great tool for doing research. It's a good tool for

41:52.480 --> 41:59.440
education. And for the past four years I've also been organizing the international f110

41:59.440 --> 42:05.200
autonomous racing competitions at some, you know, premier venues and robotics and machine learning

42:05.200 --> 42:10.400
and cyber physical systems. So teams from all over the world, they built their cars and then they

42:10.400 --> 42:16.000
come and we compete in autonomous racing. In fact, long before we went to full-scale autonomous

42:16.000 --> 42:22.240
racing, we already successfully showed the world's first autonomous overtake on month 10th scale,

42:22.240 --> 42:27.360
right. So they had to do it. Like a practice run for the for the real deal.

42:27.360 --> 42:33.520
Yeah, so this is this is an excellent platform. It's very popular. It's used by almost 15

42:33.520 --> 42:38.960
institutions around the world. And now, you know, this this is this is and I like to say it's one

42:38.960 --> 42:44.080
10th scale, but it's 10 times the fun. It's it's my favorite course to teach as well.

42:44.080 --> 42:51.360
I love that the the AWS deep racer platform. Yeah, I have. I have. I think the I give them props for

42:51.360 --> 42:58.400
bringing the price point to below $500, but I think this vehicle, not to kind of dismiss the AWS

42:58.400 --> 43:03.920
effort, but the F1 10 vehicle is a lot more heavy duty and capable. So, you know, just to give

43:03.920 --> 43:09.360
you an idea, this thing can go up to 16 miles per hour indoors, right. So it's impossible to run

43:09.360 --> 43:15.440
behind it and keep track of it. The racer is not very fast. It's not fast. I think, but so I think

43:15.440 --> 43:21.280
they did a good job of making sure that you have a like online simulator available. So they may

43:21.280 --> 43:27.040
get the onboarding process easy, which is the bulk of the effort actually. We had to invest a ton of

43:27.040 --> 43:34.320
time to make sure all the documentation, every single piece of what is needed to get started with

43:34.320 --> 43:38.320
this is taken care of, right. So you can literally let get started if you have the hardware

43:38.320 --> 43:44.560
and less than two hours. And so in in line of, you know, and so we cannot test the ideas on one 10

43:44.560 --> 43:51.760
scale in my lab, I have about 20 of these cars in my lab. So we can do very complex maneuvers

43:51.760 --> 43:56.640
with multiple cars, but you know, it has its limitations, right. So it's a different scale,

43:56.640 --> 44:01.680
different parameters, but the breaking on this vehicle is not realistic and there's no error,

44:01.680 --> 44:09.280
error effects at all. So our next big endeavor at UVA and my group is we are participating in this

44:09.280 --> 44:15.920
indie autonomous challenge, which is essentially, you know, in my view, the DARPA grand challenge

44:15.920 --> 44:21.280
for autonomous racing, right. So it's a million dollar race that will take place in October this year

44:21.280 --> 44:27.600
at the historic Indianapolis Motorsport Speedway, which is considered as part of the top three tracks

44:27.600 --> 44:32.240
in racing. So it's part of the triple crown and racing is what they call it. And so we will be

44:32.240 --> 44:39.680
racing with some fellow innovators from US and from outside of of the country about seven or eight

44:39.680 --> 44:46.640
cars I anticipate in in the world's first head to head fully autonomous race, where we can,

44:46.640 --> 44:53.200
you know, aim to go above 150 miles per hour. That's the goal. And everybody's kind of trying to,

44:53.200 --> 44:59.840
you know, fully immerse themselves to make that a reality. So, so, you know, just to just to quickly

44:59.840 --> 45:08.400
remark on on the significance of this, if you look at motorsport racing or the history of motorsport

45:08.400 --> 45:14.000
racing, it has always been the proving grounds for automotive technology. In fact, the reason it

45:14.000 --> 45:20.240
started was because when people transition from horse driven carriages to horseless carriages,

45:20.240 --> 45:24.240
they were very skeptical. And now we are transitioning from driver to driverless and there's

45:24.240 --> 45:31.440
the same sort of skepticism here. So racing became as means to to show endurance and safety and

45:31.440 --> 45:35.680
convince people that the engine is not going to blow up in your face and the brakes work properly

45:35.680 --> 45:40.960
and everything is, you know, trustworthy. So I think a similar litmus test is now required for

45:40.960 --> 45:48.320
the software stack for self driving. And so I think racing can become that proving ground where we

45:48.320 --> 45:54.560
can push the AI for self driving towards limits and show that, you know, if you can race at

45:55.280 --> 46:00.320
high speeds and close proximity when people are trying to intentionally block your progress

46:00.320 --> 46:05.920
without crashing, that's a very significant token. And it could eventually have a huge bearing

46:05.920 --> 46:12.240
on safety of regular autonomous driving. So I'm very excited to be involved in this challenge

46:12.240 --> 46:17.840
from the very get go and we can't wait to get our hands on the actual race car and transfer our

46:17.840 --> 46:21.760
knowledge from one times scale from the simulation on to the actual way code.

46:22.960 --> 46:30.400
You've got a few months, but how close do you think you are in terms of being able to successfully

46:30.400 --> 46:39.040
complete that challenge? Yeah, I'm a rational optimist fan. So I think it's,

46:41.680 --> 46:46.560
yeah, I would be a miss to say that it's going to be easy. It's a very significant undertaking.

46:46.560 --> 46:52.880
We all know as roboticists that when you work with the real thing, there's just a bunch of

46:52.880 --> 46:58.640
messy real world problems that you have to overcome before you even get to the intellectual sort of

46:58.640 --> 47:05.120
part of why your algorithm is better than others. So my feeling is we'll spend a solid few weeks

47:05.120 --> 47:10.880
at a stretch to just work through these issues. And what it helps is because most of our competitors

47:10.880 --> 47:17.120
are from other academic institutions. There is some collaboration happening at what is the

47:17.120 --> 47:21.280
base level software that everybody will have access to. So because there's a lowest common

47:21.280 --> 47:26.960
denominator that every team has to overcome before it becomes about the high level algorithms.

47:26.960 --> 47:32.560
So it is a significant undertaking. We have access to some predetermined schedule where we have

47:32.560 --> 47:38.560
reserved track time in Indy. And so my team and I will travel to Indy, we'll spend the entire

47:38.560 --> 47:46.320
summer there, possibly even the next semester. And then on October, yeah, I'm literally running

47:47.280 --> 47:52.640
besides my research lab and my own research, I'm also running a racing team on nights and

47:52.640 --> 47:59.840
games. So it's very exciting. I have no qualms about it. This is sort of what really excites me.

47:59.840 --> 48:06.880
I think it's going to be tough undertaking and just like any sport,

48:06.880 --> 48:13.440
if the outcome is a reflection of how much effort you put in, then I think that's my own thinking

48:13.440 --> 48:19.920
of it. So we'll go all in. We'll try to get this car running. Firstly, I don't think on the first

48:19.920 --> 48:27.920
day we'll touch even 25 miles per hour. But it's slowly take your car through the paces and you

48:27.920 --> 48:33.040
gain more confidence about your localization is working fine. You're confident that what you see

48:33.040 --> 48:38.640
as the position of the car is where the car is on the track. So we have a long flight checklist,

48:38.640 --> 48:44.720
if you will, that we have to go through. And then it becomes, you know, what did we miss when

48:44.720 --> 48:49.520
we were designing all these cool ideas in the simulation? How did they plan out on the track?

48:49.520 --> 48:54.240
What are the obvious things that we missed about the behavior of the car? And it's also,

48:54.240 --> 48:59.520
we have more than just computer scientists on my team. We have people from mechanical engineering,

48:59.520 --> 49:05.440
from systems engineering, from ECE embedded systems. There's actually a racing driver on my team

49:05.440 --> 49:11.120
who has some background in NASCAR racing. So it's just a pretty elaborate gig that I'm going on right

49:11.120 --> 49:18.960
now. That's awesome. Yeah, we started this talking about kind of what we can learn about safety

49:18.960 --> 49:26.720
from racing. I'm curious how you when you think about, you know, putting this AI that you're

49:26.720 --> 49:34.240
building into a full scale car, moving in 150 miles an hour. How do you think about the relationship

49:34.240 --> 49:41.920
between speed and safety and, you know, being competitive, but also being safe? How do you approach

49:41.920 --> 49:49.360
that? Yeah, so that's a tough one to really nail down. You know, speed is only useful if you are

49:49.360 --> 49:57.200
facing the right direction, right? So the first thing is to, I think, be be prioritized safety

49:57.200 --> 50:02.720
over speed because the cost of being unsafe is the ultimate price where you lose your car and

50:02.720 --> 50:10.480
you can't compete. I know it's not. So, you know, my honest feeling is that while we strive to

50:10.480 --> 50:17.520
go to these super high racing speed, it's going to be quite difficult to, you know, show that you

50:17.520 --> 50:24.240
are overtaking and going close to the barrier and taking that super risk, which is all the excitement

50:24.240 --> 50:31.200
about racing. You know, I honestly think that's a very tough ask. So this is not the only such

50:31.200 --> 50:37.040
competition. It's not the last one for sure. So I think it's a process, right? So we have sort of

50:37.040 --> 50:42.240
at the, just like with any field when you're at the frontier of a certain field, they're more

50:42.240 --> 50:48.880
sort of unanswered questions than there are answers. I feel this one is in their realm. So

50:48.880 --> 50:54.800
so we do prioritize collision avoidance actively, both in front of us and behind us. So even if the

50:54.800 --> 51:01.200
car behind us is doing something erratic, we would rather not deal with that then to be like,

51:01.200 --> 51:07.920
oh, let's push our elbows out and see what happens, right? So and part of it is this just mindset of

51:07.920 --> 51:14.720
the roots of our research is in safety of AI, safe autonomous vehicle. So it would be kind of a

51:14.720 --> 51:20.560
moot point if we just take an unnecessary risk and and crash our car, right? So as they say,

51:22.080 --> 51:26.480
to finish first, first you have to finish, right? So that's I think a good summary of how we

51:26.480 --> 51:32.320
approach the straight up between safety. At the same time, you know, we do want to push our car

51:32.320 --> 51:39.600
to the limits of how fast it can go while respecting and behaving in expected manner. So maybe

51:40.320 --> 51:47.200
my response to this sort of trade-off is we are comfortable going at the speed limit where the

51:47.200 --> 51:54.000
car behaves as we expect it to behave. So as a racing team, we hate surprises. Okay, so if things are

51:54.000 --> 51:59.360
deterministic, if we know how our car will behave in a given situation, sure, let's go for it.

51:59.360 --> 52:04.720
But as soon as we begin to get into that gray area where, hey, we didn't anticipate that.

52:04.720 --> 52:09.200
Oh, why did we make that staring adjustment? So maybe, you know, our models are a mess. They

52:09.200 --> 52:13.760
were not designed for such speeds. So we have obviously, you know, mistuned some parameters

52:13.760 --> 52:19.120
somewhere. But then we will apply the brakes literally and figuratively on our approach here.

52:20.720 --> 52:27.280
Awesome. Well, Madhu, thanks so much for taking the time to share with us a bit about your journey

52:27.280 --> 52:32.160
and what you're up to. It's very cool stuff. Yeah, thanks Sam for for again inviting me to this.

52:32.160 --> 52:37.840
I had a really fun time, very enjoyable discussion and keep an eye out in October. You will likely

52:37.840 --> 52:59.040
hear about this event. And yeah, I hope to be amongst the teams which crossed the finish line.

