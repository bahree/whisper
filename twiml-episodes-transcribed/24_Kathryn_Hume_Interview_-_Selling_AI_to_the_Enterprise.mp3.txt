Hello and welcome to another episode of Tumel Talk, the podcast where I interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
As usual, thanks so much to everyone who sent in their favorite quote from a recent podcast.
Another batch of stickers got mailed out this week, so keep those quotes coming.
So far this month, we've sent stickers to five different countries.
If you're new to the Tumel worldwide family, you too can get a sticker.
Just let us know your favorite quote from this or any recent Tumel and AI episode.
You can do that via posting a comment to the show notes page by tweeting us at Tumel AI
or at Sam Charrington or via a post on our Facebook page.
Your feedback is very important to us and we appreciate every bit of it.
We're going to jump right into our show.
You may recall that we spent some time in New York City a few weeks ago at the NYU Future
Labs AI Summit.
While there, I had the opportunity to sneak backstage and interview a few of the great
speakers from the event, including this week's guest, Catherine Hume.
Catherine is the president of Fast Forward Labs, which is an independent machine intelligence
research company that helps organizations accelerate their data science and machine
intelligence capabilities.
If that name sounds familiar, that's because we had their founder Hillary Mason on the
show a few months ago.
We'll link to that show in the show notes, it was a great one.
My discussion with Catherine focused on AI adoption within the enterprise.
She shared several really interesting examples of the kind of things she's seeing enterprises
do with machine learning in AI, and we discussed a few of the various challenges they face
and some of the lessons her company has learned in helping them along.
I really enjoyed our conversation and I know you will too.
And now on to the show.
Hey, everyone.
I am here with Catherine Hume.
Catherine is president of Fast Forward Labs.
If you listen to the podcast, you may recall that I interviewed her colleague Hillary Mason
on the podcast some time ago, and she's here at the Future Labs AI Summit.
She just finished her talk and she's agreed to chat with us for a little bit.
Catherine?
Hey Sam, I'm happy to be here.
Great.
You know what?
You have a really intriguing background, mostly or in part because I'm a linguophile and
you speak eight languages I hear.
But you have kind of a, you're not the PhD in neural networks that I often interview.
So how did you kind of find your way from where you were to in this space?
Through a long and tortured path, I suppose.
Yeah, so my PhD is actually in comparative literature, which is where I spent a lot of time
learning languages and reading literature in those languages in my path life.
So I was a mathematician as an undergrad and just was fascinated by language and cultures
and decided to shift paths and do a PhD in literature.
And I found myself as I was working on it always really interested in what has become natural
language processing.
So thinking about language, not only from a, let's go out and talk with people and communicate
perspective, but also how they work.
And I became increasingly interested in the fact that in using AI systems, they didn't
really treat language like language.
So in some of the statistical developments in the early 2000s, it's my PhD from 2007
to 2012.
It was a lot of N gram or bi gram type work in language processing.
And it was fascinating to me that you didn't need to think about syntax and semantics and
all of the grammatical terms that linguists used to think about language to make sense of
it could just be reduced to a stats problem.
And that was totally bizarre and interesting and weird for me.
So I developed an early interest in AI and I had a couple of jobs in software companies
that weren't using machine learning and then found my way fortunately into this space
eventually.
That's amazing.
So your talk was on selling AI into the enterprise.
What were the main things you were trying to accomplish with the talk?
So I think the main thing was I assume that there were a lot of young entrepreneurs in
the audience and I wanted to help them appreciate that you can't just say, you know, I'm going
to go from my research that I did in graduate school and I'm going to go form a company and
everything's going to work and be magical, right?
There's a lot of tactical hard work you have to do in order to really make money off
of these new technologies and tools.
So I started at three parts in my talk.
The first one was what I called the five axioms of enterprise AI and it just went through
a lot of the trends that we're seeing in the enterprise space across different verticals
fast forward doesn't wear a horizontal consulting and research firm.
So we, you know, we work with companies of all shapes and sizes, but there's some patterns
that show up some the biggest of which I think is companies discomfort with risk and probability.
So there's a cultural and process shift that has to take place for them to really succeed
with AI as they move from big data data analytics where they're counting transactions that
occurred in the past to fill out 10k forms and do reporting to experimenting with data
to build out new revenue streams and products and there's just, it's a massive undertaking
to reshape the mentality that folks have to actually do this well.
And then I talked about what I consider to be some super interesting use cases of real,
you know, real enterprise AI that we've seen in our customer base ranging from building
out personalized, recommender systems to support sales and financial services to building
in context to wear surgical robots that can identify critical points in surgeries to basically
shift to the future of automated robotic surgery somewhere 10 to 15 years down the line.
Well, maybe can we maybe walk through one of those?
Yeah, sure, absolutely, so let's pick one, we do some work with the big four and we
As in accounting firms?
Big four accounting firms, yep.
So they've got a lot of problems where they're trying to audit the financial statements
of their clients for compliance or they'll be giving tax advice or some sort of consulting
advice to their clients.
So one use case is it's not the sexiest in the world, but I think it's a great machine
or any problem.
They came to us and they said today our tax practitioners have a hard time keeping up
with new rulings and opinions and news for lack of a better term in the legal world related
to their particular clients issue.
So there's a big gap between the world of know how, let's say in law and in advising and
the world of applied know how where you take the rules and regulations and then you apply
it to your customer's particular situation.
So they engaged us to try to not go so far as to automate the work of providing tax
advice but provide more dynamic up to date and specific alerts for their tax practitioners
on new legal documents that were coming out that were relevant for their particular
client cases.
So that involved are using some statistical topic modeling techniques where we went in
and we started off actually with regular expressions and just found got the most out
of rules that we could to sort of bootstrap up intelligence in the system and then added
on an additional statistical layer of intelligence to get them to a point where they're now able
to provide dynamic advice to their clients because as new rulings come in they have their
sort of fact specific alerts that are coming out and shift around the product offering,
repricate, repackage it and offer something different than their competitors.
Interesting.
If there are a couple of generalizable rules in there one being do you commonly see folks
in traditional enterprises having their first step being using these systems to augment
their human staff as opposed to replace and the second being you know starting out simply
with you know things like regular expressions and then eventually building up to the statistical
techniques.
Yeah those are both absolutely true.
So I think one of the common mistakes that we see is that when somebody working in the
enterprise who's non-technical not a machine learning specialist and is interested in trying
to do something cool with AI normally their default assumption is that they can go from
manual to completely automated in the first pass which I think is leading to what I call
sort of some of the big distractions and discussions around AI where we assume that in the next
10 years the work place is going to radically shift and everybody's going to lose their
jobs and we're going to be replaced by machines and universal basic income comes up right
so there's all of this mania we see online and you know our sort of humbled experience
in working with companies and practices that that's not happening anytime soon.
How people work will change when they have machines as a you know a companion and component
but most of the time just from a pure technical perspective it's so hard to have the amount
of data that's required to train a system that could really perform with the levels of
accuracy that are required to do risk-oriented tasks like healthcare, diagnostics, treating
stocks whatever it may be that they're just you know they're mistrusting of the systems
and it really takes a long time to actually get enough labeled training data to get a
system to perform and then the second is yeah from a product development perspective we
tend to at fast-forward labs tend to think that you should always start with the simplest
algorithm that will scale so we tend to you know we don't we don't start with the neural
network we start with the linear regression right and if it works then it's got all sorts
of benefits it's if the accuracy is good it's interpretable we know how to debug it we
know how to fix it we can do some feature engineering as opposed to just throwing the big
guns at a problem that might not actually require that so yeah so you want to get touched
on trust and you know what we can kind of wrap up as cultural issues within customers how
do you do you and if so how do you help them kind of wrap their arms around you know these broader
cultural issues that are you know ultimately required for them to successfully introduce
these kinds of technologies into their organizations I think it takes a lot of education and training
in a lot of time so there's sort of two cultural hurdles to primary culture hurdles that we see
the first is on let's say the project planning phase where you know there's a lot of risk
involvement experimentation involved in doing data science and AI projects so they don't lend
themselves to they certainly don't lend themselves to a waterfall methodology and they don't even
really lend themselves to agile because you're not really sure at each step how long it's going
to take if it's going to work if the models are going to converge so we have to do a lot of
just coaching to help people understand how to do the data science phase let's say in a product
development process and and help let's say the the technologists that we're working with coach
them to have the meetings that they're going to have to have with their management who are going
to be skeptical and not understand why they're spending money on a project that might not work out
right so it's a lot of the fail fast risk-based thinking that we hear about in the startup world
that needs to be important and the enterprise the second is on let's say the consumption
and the user like the use of outputs of the system where there's a lot of design thinking that
has to go in to help people use predictions well so if they let's say they're using a more
like complex statistical tool and the output is going to be a distribution that says yeah we think
it's here's our prediction we're 82% confident and the accuracy rate is at you know 36% or something
like that so the average user is not going to know what to do when that's what their system tells
them so you know I think there's there's a lot of work in the bigger problem in the enterprise
today is not is not replacing our workers but actually giving them some sort of basic statistical
intuition so they can they can use machine learning effectively interesting yeah so I spoke
when Hillary was on the show we spent some time talking about the this issue of agile methodologies
not lending themselves to this type of problem which was really counterintuitive to me I thought that
you know I guess thinking of it kind of you know in a bipolar way waterfall and agile hey you'd
wanted you want to use agile on the topic of culture one of the most interesting stories that I've
heard came out of lows I heard a talk by the head of innovation there who's focused on
some of their machine learning AI types of initiatives and they were really struggling to get their
executives kind of on board with some of these types of projects and you know I get there get
their heads wrapped around the these you know the risk issues without them you know just kind of
latching into these problems and taking them you know either taking them too far or you know out
of the gate saying hey you know that'll never work right and so what they did was they they hired
a graphic artist and they produced these comic books that basically illustrated you know a given
future you know at lows and what they found was that the the comic books were interest in a very
interesting way they were you know tangible but they were also constrained so you know they
they didn't necessarily you know that an executive could say yeah I want to do that I'm
willing to put some money behind that so so one of the examples they gave was I think they call
it the low spot it's basically a customer service robot that roams around stores and will you
know can answer questions and things like that and they first documented what they envisioned this
project to be in one of these comic books and eventually got funded and I think it's in a few
stores in northern California now are there any other kind of tricks or interesting things that you've
seen customers do to kind of help drive these cultural shifts I think there's all sorts of
lessons in what you just described from low so when you were when you're singing about the comic
book and the tangibility um the imagination is really important right so um you know there's
one thing that we see is it's and I talked about this in the talk um you know the executives that
companies will have seen that Google is able to classify cats or they'll have seen IBM Watson and
they'll have seen plane jeopardy and they'll have seen Google Deep Mine plane go and they're completely
befuddled as as to how those achievements in the realm of games and in the realm of the sort of
consumer internet and the frivolousness around it right are relevant for the tactical boring
business problems that they have and in part that's because if you don't really understand the general
backend technology it's it's it's hard to make the imaginative leap from you know to do the the
the synthesis between one domain and how that might be applied in another so I think um the
concreteness of the book right where it's not you're not leaving it up to their imagination to
imagine what this technology might do you're playing out scenarios you're using fiction and the
ability of the imagination to sort of to to make that happen and granted it's there's a difference
between who knows if the reality is like the the uh the screenplay that was written but that's okay
the the actual product can be completely different from the origin version it just just have to
have the impetus to want to invest so I think um one of the things that we've seen it fast forward
we have a as i'm sir hillary talked about on the podcast we have a subscription product where
we educate our customers as to what's possible today in realm of AI very fewer those who actually
are applying the algorithms that we teach them about but that's okay because it inspires their
imagination it gets them excited and it's a really useful tool to then to muster a lot of the
you know the organizational energy that's required to then do something that because practical
might look really different um other kind of techniques that i've seen i think there is i think
i talked about this a little bit in the talk too um we have to always remember that we're all
just humans right and um and we respond at work kind of the same ways that respond when we're
outside of work but we sort of we put on this work hat and suddenly think that we're supposed to
use these processes and this stuff that we read about that is a little counterintuitive it doesn't
necessarily feel right and my hunches and and take is that if we can use humor even i i talk
with somebody who's just an excellent uh a bist of person the other day who would start off his
meetings with large serious customers with some sort of gimmick and it would just shift the the
tone in the room and lead to real honest problem solving discussion and i think if you anything
that you can do to get that so that you're not fearful of saying something that's gonna upset
your boss or you know having to go around corners and stuff and even from being a company a startup
company working with a large organization to the extent to which you can create an environment where
it's two equals thinking through something you have a much higher probability of success so
very interesting i'm curious where at what part of the cycle does your typical client come to you
today uh is it is it mania driven hey we want to do something around this AI stuff and we hear
that you folks are good at it or is it we've got a specific problem and we want to solve it or
somewhere in between can you statistically characterize the distribution
is it what's on here i guess so it varies we definitely have a lot of um you know younger
smart bright uh researchers and machine learning who will write in and say this is awesome i want
i want to read your reports i want to work for you um and that's great and it helps us build our
community but it's not necessarily what pays our bills um i think from the you know the real
interest it'll sort of lie in in that depends on the spectrum of maturity that the different
enterprises have sometimes folks will reach out and they're actually really at the beginning of a
data science journey for lack of a better word and they're looking for help building out a governance
plan doing some basic analytics etc and that's not exactly we're not we're not staffed we're not a
heart huge consulting company that can serve those kind of requests so we have sort of a partnership
network will push them off the ones that work um often either have a specific problem so they have
enough uh awareness and understanding of the business potential of AI that they can pose a good
problem but they don't necessarily have the internal resources to staff it and execute or they may
have already they do have data scientists they're doing some work um but they're looking for a
neutral third party who has expertise in the domain which is rare to come in and evaluate what
they're doing these heavy the Googles and Facebook's and IBM's of the world to just make sure they're
on the right track um so so we tend to work well uh if there is an existing data science team
in place um and they're looking to go from you know where they are today to where they might go
and using some more advanced techniques there's not a ton of companies that are sort of at the
you know at that phase there's very few enterprises that are actually using deep learning like
very few right because they don't have the data they I mentioned this in the talk too there's um
we have this uh false impression that just because it's a big enterprise they're going to have lots
of data they do but they haven't been considering data over the last hundred years with an i towards
building machine learning products so they don't have labeled training sets and they don't have it
well composed and and processed and ready to use it's there but it takes years of work to
make it useful um do you have any perspective on um your company has uh made a name for itself
initially I believe as a data science company and you know there's obviously um a lot of again
kind of maniac around AI and I've been trying to kind of wrap my head wrap my head around the
relationship between these two terms do you have a perspective on that it's a good question so
I think uh the even the experts in the AI and machine learning community don't agree on
what the definition of what AI is so Hillary and I will just say it's whatever computers can't do
until they can so it really is sort of a it's our subjective impression on what the stuff is um
I mean we consider AI to be today and if you look through the history one can go back to expert
systems and some of the early attempts to mimic first-order logic and the days of touring and
you know uh Claude Shannon and early information theory so um and I actually think there could be
a resurgence of uh symbolic you know AI techniques sometime in the future as we try to move towards
training systems with with less data but um the inheritance of the early 2000s where you know we
really were collecting data and processing it at scales that we hadn't seen before and with
computational power that was faster than we'd seen before I think leads it to the fact that AI
systems today are just sort of a next extension of what we call data science uh sometimes I think
it's meaningful to say the type of data that AI systems work on is different so we're going from
transactional data to images text speech right so categories that historically intractable because
they require vectors of such high dimensionality that we didn't have the backend functions that
could approximate you know universal functions right so just get to the level of complexity where
they actually work for that kind of data I think that's meaningful um outside of that it's
you know what one person calls AI might be with somebody else calls data science and it's just a
question of it's a question of which which term you want to use to get more bang for your buck yeah
so as we wrap things up any parting thoughts for the listeners sure so we talked a little bit about
you know other past guests that you've had that have been focused on thinking about ethics and trust
and bias in these systems um I think it's a big issue we're actually working on it right now fast
forward lab our upcoming topic is on interpretability so the ability that the standard sort of wisdom
today is that if you're using a model like a neural network it's going to give you great predictions
but you have no idea why um and I think in you know some of the large enterprises financial services
healthcare regulated industries and even ones where consumers are just curious about why
why the machine is telling them to do what they're what's it's telling them to do I think there's
some cool efforts afoot to try to gain a little bit more transparency um try to you know turn a
non-linear complex function into something that we can understand a little bit better um and
you know it's something to the companies that a as a as a machine learning practitioner you have
to keep your eye out for because it can be an obstacle to adoption and be that people just seem
to be generally interested in yeah it's a huge issue and that one that I hear coming up all over
the time yeah yeah yeah great well thanks so much Catherine it was great having you on the show
thanks for having me
all right everyone that's our show for today don't forget to share your favorite quotes for one
of our 20 stickers again you can share them via the show that's paid via Twitter or via our
Facebook page the nudge for this show will be up on truly i.com slash talk slash 20 we will
find links to Catherine in the areas resources thank you so much for listening and catch you next time
