WEBVTT

00:00.000 --> 00:11.760
All right, everyone. I am here with Artur Yakimovic. Artur is co-founder at Artificial Intelligence

00:11.760 --> 00:18.720
for Life Sciences and a visiting scientist in the lab for molecular cell biology at University

00:18.720 --> 00:24.800
College London. Artur, welcome to the Twimal AI podcast. Hello, Sam. It's a pleasure.

00:24.800 --> 00:31.200
It's great to have you on the show and I'm looking forward to our chat. You know, let's get started

00:31.200 --> 00:37.680
with a little bit about your background. You are very active in trying to bring these two streams

00:37.680 --> 00:45.680
together, AI and life sciences. You know, what's the origin of that interest? That's a great question.

00:45.680 --> 00:56.400
So, I guess, you know, by my background, essentially, highly interdisciplinary. I did my undergrad

00:56.400 --> 01:04.560
in chemistry. Then I decided that I'm very interested to learn where does chemistry stop and biology

01:04.560 --> 01:12.400
starts. So I went on to do a PhD in biology and computational biology. And computers and

01:12.400 --> 01:20.080
computer science was always a great interest for me and I was always thinking about, well, you know,

01:20.080 --> 01:26.480
we could probably do more and better in biology in general and, you know, spearhead the discovery

01:26.480 --> 01:35.760
if we use a little bit more computers there. So after finishing my PhD, I did a short postdoc

01:35.760 --> 01:47.520
at University Hospital in Zurich and I was working on in the Department of Microbiology working on

01:47.520 --> 01:56.400
bacteria and computer vision algorithms. And after that, I moved on to do another longer postdoc

01:57.600 --> 02:02.640
University College London. The postdoc I just recently finalized.

02:02.640 --> 02:11.680
Okay. Cool. And you said something interesting in there. You wanted to see where chemistry stopped

02:11.680 --> 02:20.800
and biology finished and that led you to studying viruses. What's what about viruses kind of

02:20.800 --> 02:29.520
characterizes that that edge unlike any other, you know, number of biological processes that are

02:29.520 --> 02:36.240
also fundamentally chemical? That's a great question, thanks. So in principle, you know, there's

02:36.240 --> 02:42.320
a big philosophical discussion where the viruses are dead or alive. I think personally,

02:43.760 --> 02:48.240
and that's that might start a huge conversation in the in the follow-up of the show, but I think

02:48.240 --> 02:55.680
I think personally that they are undead. So, absolutely, vampires and zombies in the life.

02:55.680 --> 03:01.920
Well, think about that. Viruses technically are alive only once they are inside of a host cell.

03:01.920 --> 03:10.160
So at any time between that, they don't show any signs of being alive. So in that sense,

03:10.160 --> 03:18.720
they can be classified as either alive or dead at any time apart from any specific circumstances.

03:18.720 --> 03:27.920
But they're different from other compounds, and that once they are inside of a host, they start

03:27.920 --> 03:34.640
to do things that we associate with being alive like... Absolutely....and metabolize and all these other

03:34.640 --> 03:41.520
things. Absolutely. So not like some inert catalyst. Exactly. Yeah. And they are very complex systems

03:41.520 --> 03:50.800
that are able to self-replicate and go on with their lives for only that long as the host is alive.

03:53.520 --> 04:03.760
And so after... I mentioned your co-founder of an organization, artificial intelligence for

04:03.760 --> 04:11.840
life sciences, it sounds like it's a consortium is probably not the right word, but it's an organization

04:11.840 --> 04:17.440
along those lines and that you're trying to bring folks together and start conversations.

04:18.000 --> 04:21.600
Tell us a little bit more about what you're up to there and your goals.

04:22.400 --> 04:28.720
Yeah, absolutely. Thanks a lot. So the artificial intelligence for life sciences is essentially just

04:28.720 --> 04:37.760
a platform bringing together people from life sciences, academics, and anyone who is interested in

04:37.760 --> 04:43.120
life sciences in any way, and bringing people... Platform like platform like Facebook or...

04:45.200 --> 04:52.160
We use multiple sort of technology platforms, just an organization or platform.

04:52.160 --> 04:58.480
More like an organizational platform. We simply bring people together and provide

04:58.480 --> 05:07.200
them with means like a simple forum, an exchange of data, a chat where they can exchange

05:07.200 --> 05:13.840
opinions and ask for some technical help or maybe some clarifications and stuff like that.

05:13.840 --> 05:20.400
So our main page if you look at it essentially is a forum where we try to discuss things,

05:20.400 --> 05:26.960
do journal clubs, look at papers, share code, share solutions, and so on.

05:26.960 --> 05:34.480
So the organization itself is aimed as a community interest company, a non-for-profit organization.

05:35.040 --> 05:41.920
And the core idea behind it is essentially to bridge the massive massive divide that exists

05:41.920 --> 05:46.400
between life sciences and computer science or artificial intelligence.

05:47.680 --> 05:55.280
And the divide is constantly growing and as AI progresses, things become more and more

05:55.280 --> 06:04.000
difficult to get into. And we're trying to kind of bring the value that advanced AI can give

06:04.000 --> 06:06.320
to life sciences and to scientific discovery.

06:08.000 --> 06:15.920
Why is it that you think that AI gets more difficult to get into for folks in the life sciences?

06:15.920 --> 06:24.240
It seems like as the field progresses, different approaches become commoditized,

06:24.240 --> 06:30.640
the tools are becoming commoditized and the barriers to entry in a lot of ways are falling.

06:32.400 --> 06:42.000
That certainly is the case. However, let's say many problems that are getting

06:42.000 --> 06:46.400
commoditized are still not the same problems that life sciences is looking on.

06:46.400 --> 06:55.360
So, in life sciences, you quite often try to do things in a little bit more of a broader fashion

06:55.360 --> 07:00.640
where you try to bring in several methods showing the same thing. Whereas in computer science,

07:00.640 --> 07:07.440
you quite often try to look at the same problem over and over and over again using a variation of

07:07.440 --> 07:13.280
as, you know, like you define those canonical problems like facial recognition and

07:13.280 --> 07:19.520
somatic segmentation and so on and so on. Whereas in life sciences, you're trying to bring all

07:19.520 --> 07:26.640
sorts of different kinds of data, DNA sequencing, bi-imaging electron microscopy, this kind of

07:26.640 --> 07:33.840
things in order to kind of show the representative problem from multifaceted view.

07:34.560 --> 07:40.080
So, in this sense, it's a quite a different way of thinking about these problems.

07:40.080 --> 07:49.600
And although certain methodologists get more and more commoditized, as they do, so they certainly

07:49.600 --> 07:57.760
become less difficult to apply to the same problem and more difficult to apply to new problems.

07:59.760 --> 08:08.080
Okay. I've had a number of conversations with folks on the podcast

08:08.080 --> 08:19.200
in the life sciences and a lot of them have, well, they've been fairly varied, but a good number

08:19.200 --> 08:23.840
of them have been focused on microscopy data. And I think that aligns with just the point you

08:23.840 --> 08:30.560
are raising that we've made, made so much progress in computer vision recently. Is that one of the

08:30.560 --> 08:39.120
the fields or problems that you've been working in? Yeah, absolutely. Definitely, thanks a lot

08:39.120 --> 08:47.360
for mentioning it. So the microscopy is and biomedical imaging in general is sort of a

08:47.360 --> 08:58.160
pinnacle of the entire quantitative biology and the way it's moving forward. It is one of the most

08:58.160 --> 09:06.560
sort of digitalized sources of biological data. And obviously working with images is getting

09:06.560 --> 09:15.040
increasingly more and more sort of easier. Like I wouldn't say easier, probably easy is the wrong

09:15.040 --> 09:22.560
word. It's getting, you're getting a bigger tool set to work with images every day. And

09:22.560 --> 09:29.680
thanks for getting. Go on to that distinction. So you've certainly got a lot of tools, but hopefully

09:29.680 --> 09:34.240
the impact of all of these new tools is that they make things easier, but you're not quite ready

09:34.240 --> 09:42.640
to say that yet. Yeah, I think quite often it's a little bit of that's hidden again on the same

09:42.640 --> 09:51.360
point that you raised before, as we progress with things like AutoML and things getting easier and

09:51.360 --> 09:56.320
more commoditized. Suddenly, you don't even know anymore. What is it that you're looking for?

09:56.320 --> 10:01.360
Are you looking for image classifier? Are you looking for a segmentation? And there's awful loads

10:01.360 --> 10:07.360
you need to know about overall image analysis and all this kinds of problem in a history, a problem's

10:07.360 --> 10:17.280
history sort of if you will and computer science background to move it to the from the idea or an

10:17.280 --> 10:23.920
actual biological problem to a computational problem that is then going to be solvable by those

10:23.920 --> 10:33.520
commoditized tools. So we'll come back to kind of some of the broader life sciences,

10:34.800 --> 10:41.600
you know, issues, but let's maybe talk a little bit about your particular research interests.

10:41.600 --> 10:48.320
What did you do for your postdoc and what are some of the things that you do in your current role?

10:49.360 --> 10:57.680
Right, thanks. So in my postdoc, I worked in combining deep learning with

10:58.480 --> 11:06.320
microscopy, quite specifically, super-resolution microscopy of viruses. So virus

11:06.320 --> 11:16.800
particles or like one of the tricky things about viruses altogether is that probably one of the

11:18.240 --> 11:23.200
perhaps one of the only thing that they have in common is that they are cold viruses.

11:24.560 --> 11:29.600
They are quite different entities altogether depending on the kind of virus. They may be

11:29.600 --> 11:36.960
comprised of RNA. They may be comprised of DNA. They may be large. They may be small. The

11:36.960 --> 11:45.520
size can vary between microns and nanometers. So like probably the smallest one is around 20,

11:45.520 --> 11:54.880
30 nanometers. So it's a vast huge field with things being very, very fragmented in multiple subfuelts.

11:54.880 --> 12:03.760
So again, that's coming back to the problem of making things more applicable for computer science

12:03.760 --> 12:10.880
methodology, right? If it's certainly not a great idea to have a lot of small data sets rather than

12:10.880 --> 12:19.440
one huge data set helping to solve one big problem. So in this, in one of the projects,

12:19.440 --> 12:28.000
I worked in several vapors. In one of the projects I've listened to published, we managed to

12:28.000 --> 12:35.760
sort of explore the space of a super-resolved virus particles of so-called

12:35.760 --> 12:39.520
vixenia virus. It's a box virus family. What's the virus name?

12:40.320 --> 12:46.560
Vixenia virus. It's the virus that was used as a life of a vaccine for eradication of small

12:46.560 --> 12:58.720
pox. And in this work, we looked at, we used a set of different relatively advanced,

12:59.600 --> 13:05.440
or let's say, you could say state of the art and neural net architectures for image analysis

13:05.440 --> 13:15.120
and image classification to solve a number of day-to-day problems of ourologist phase

13:15.120 --> 13:23.600
with their data. For example, if you've got a micrograph of a cell infected by a virus,

13:23.600 --> 13:29.760
how do you tell whether the tiny little dots that look like kind of stars are inside of the

13:29.760 --> 13:36.000
cell or outside of the cell? And that's in three dimensional space. So in a biological sense,

13:36.000 --> 13:43.440
what we managed to show is that you can use advanced neural networks to pick

13:43.440 --> 13:53.520
these minute signals, alterations that occur once the virus is crossing the cell or membrane,

13:53.520 --> 14:00.240
so that you could tell that from the virus micrographs by themselves. And one of the interesting

14:00.240 --> 14:10.560
sort of tricks we managed to use in this case, and that's advocating for

14:10.560 --> 14:16.640
using a deep learning for viruses specifically, is that we've been multiplexing the number

14:16.640 --> 14:23.120
of data points through the fact that you would have multiple viruses per one single cell.

14:23.120 --> 14:30.320
And since quite often in microscopy, the fixed magnification is way more suitable for

14:30.320 --> 14:36.160
celler size than the virus, single of our size, you get way more virus particles in your

14:36.160 --> 14:44.880
data set from one single cell. And that allowed us to use more advanced neural nets. And

14:44.880 --> 14:53.280
additionally to that, we developed a trick where we called mimicry embedding, which essentially

14:53.280 --> 15:01.440
repurposed, it's a variation of transfer learning where you simply repurpose things like

15:01.440 --> 15:09.360
amnesty by just feeding all this potentially not useful representations from handwritten digits.

15:09.360 --> 15:20.320
And it turns out that single channel of a viral core looks very similar if you projected

15:20.320 --> 15:26.000
in a certain way, it looks very similar to a handwritten digit. So data sets are very similar

15:26.000 --> 15:32.560
in this case. And that allowed us to sort of avoid the trap of using very high capacity

15:33.440 --> 15:43.760
neural nets on relatively shallow data sets. And just so I'm understanding what you're

15:43.760 --> 15:53.760
saying here, are you saying that this single channel super resolution microscopy imagery,

15:53.760 --> 16:02.480
you're able to do some kind of dimensionality reduction or projected into some embedding space

16:02.480 --> 16:11.440
and to something that's on the order of an amnest digit in terms of the number of features or

16:12.320 --> 16:18.560
there's actually something that is like the digits themselves about this data set that you're

16:18.560 --> 16:25.040
working with. It's more coincidental in this case and it's just the fact that if you work in

16:25.040 --> 16:30.320
fluorescence microscopy, there's a lot of, you know, tricky technical things that are already done

16:30.320 --> 16:35.760
for you as compared to traditional computer vision. So let's say if you have a normal photograph

16:35.760 --> 16:41.360
in computer vision, you would need to mix channels or do some semantic segmentation to avoid

16:41.360 --> 16:50.640
to look at the foreground versus background. And since those were problems in the field of

16:50.640 --> 16:54.960
microscopy for a very long time and a long time ago before we had all these powerful computers and

16:54.960 --> 17:04.560
methods, there was a rather simple physical solution sort of developed for this computer science

17:04.560 --> 17:13.040
problem, if you will, where fluorescence functional microscopy used the system of specific

17:14.720 --> 17:22.560
specific color elimination and filters to just filter out the light that is not necessary. So

17:22.560 --> 17:29.040
you are end up with just looking at the foreground on the black background. And that is quite

17:29.040 --> 17:35.520
an interesting sort of approach and it's very, very commonly used essentially in microscopy

17:35.520 --> 17:44.800
fluorescence microscopy. And that's why, you know, when in computer science people quite often

17:45.840 --> 17:51.520
were, you know, trying to develop a very complex solutions to do the segmentations in biology

17:51.520 --> 17:59.600
people were just like, oh, we're just used, you know, a binning or thresholding as Nikola to just

17:59.600 --> 18:07.120
separate up and down and we're happy we've got our objects here. So that's, it's, there's a

18:07.120 --> 18:13.840
difference in mentality in both fields. And I guess that's what I was alluded to in my previous

18:13.840 --> 18:22.880
points. In past conversations, the issues that I tend to hear about that make traditional approaches

18:22.880 --> 18:32.640
to like segmentation easy to apply to this microscopy data are things like occlusion where you've

18:32.640 --> 18:38.720
got, you know, whatever your target is, say a virus or a cell, depending on your scale, you've got

18:38.720 --> 18:43.040
because you've got these multiple layers, you can have them stacked on each other and things like

18:43.040 --> 18:54.160
that is the nature of the problem that you are looking at such that, you know, because the

18:54.160 --> 19:00.960
virus is the virus are so small relative to the cell that you didn't have that those types of

19:00.960 --> 19:08.240
occlusion issues to deal with or were you, you know, zooming in to able to kind of isolate the,

19:08.240 --> 19:13.920
you know, the individual virus entities or is there, is there something else happening there?

19:14.560 --> 19:21.040
That's a, that's a great question. I'm really glad you asked. So the thing is that in case of

19:21.040 --> 19:30.880
viruses, what we had, what we're dealing with quite often is a very, so we are hitting the

19:31.920 --> 19:37.520
so-called diffraction limit of enlightened microscopy. So obviously that would be definitely

19:37.520 --> 19:43.680
small enough to properly resolve the virus. Absolutely. So, and it depends, obviously it depends

19:43.680 --> 19:49.280
on the virus you're working in, but the virus I was working in and that particular study was

19:50.720 --> 20:01.440
around 450 nanometers in diameter and that's as close as it gets basically to being slightly

20:01.440 --> 20:08.080
above the diffraction limit, which is about 200 nanometers depending on the wavelength. And

20:08.800 --> 20:16.160
basically that allows to exist at this sort of sub-pixel, a little bit of a structure resolution

20:16.160 --> 20:26.160
and you would maybe be able to see, to see if you get a brighter particle in case it's a cluster

20:26.160 --> 20:32.400
of multiple viruses and not, but it's very difficult to get essentially ground truth for that.

20:32.400 --> 20:38.800
And we're just moving towards this direction. We're at the limit of diffraction, if you will,

20:38.800 --> 20:44.080
in virus-like microscopy. And that's where we need techniques like super-resolution microscopy,

20:45.760 --> 20:50.320
which is not to be confused with super-resolution in AI. It's slightly different.

20:50.320 --> 21:00.800
Right. I'm glad you mentioned that because I was wondering about whether there was a relationship

21:00.800 --> 21:08.720
between the two. Super-resolution in AI tends to refer to taking a photo of a given resolution

21:08.720 --> 21:15.120
and making a higher resolution, usually a generative version of that. Super-resolution

21:15.120 --> 21:21.040
microscopy is just talking about using very higher resolution microscopes or is there more to it

21:21.040 --> 21:30.880
than that? So essentially, in a physical scale, there is no a straightforward way to bypass the

21:30.880 --> 21:39.840
or to cross the diffraction limit. And several techniques have been proposed in the past

21:39.840 --> 21:46.560
a few decades that are extremely interesting and extremely successful at the same time. And they

21:48.000 --> 21:54.560
some of them overlap a lot with computational microscopy techniques where you would

21:54.560 --> 22:04.240
essentially try to find sources of information to allow you to cross this limit and compute

22:04.240 --> 22:11.920
beyond the diffraction limit. One of sources of such information could be temporal source where

22:11.920 --> 22:18.800
you could try to unmix individual point sources by making molecules blank rather than shine at

22:18.800 --> 22:28.240
the same time. And another ways to do that would be to temporarily deplete some of the molecules

22:28.240 --> 22:35.520
that are shining and make sure that only if you are shining again. But essentially, the trick

22:35.520 --> 22:39.760
of super-resolution microscopy or difficulty of super-resolution microscopy is that

22:43.040 --> 22:47.280
that there is different fundamental information difference between

22:50.000 --> 22:56.080
pixel resolution and spatial resolution. So with the spatial resolution, you're trying to

22:56.080 --> 23:03.040
understand if you have one pixel, is this one molecule or two molecules. And with pixel resolution,

23:03.040 --> 23:10.960
you can happily create a little bit of structure by doubling the number of pixels and try to do

23:10.960 --> 23:15.520
some prediction there. But essentially, if you don't have enough information on whether it's

23:16.080 --> 23:22.080
single molecule or whether it's two molecules or multiple molecules, then you're a little bit in

23:22.080 --> 23:25.920
trouble, you don't have enough information. And that's why there are all this clever techniques how to

23:25.920 --> 23:38.880
bypass that. Now, I'm trying to resolve all this conversation we're having about the diffraction

23:38.880 --> 23:47.520
limit and things like that with these terribly detailed pictures of the, you know, coronavirus

23:47.520 --> 23:53.760
that we're all intimately familiar with now. Is that just a gigantic, massive virus that is easy

23:53.760 --> 23:59.120
to resolve? Or how do we produce these, you know, those images relative to the types of things

23:59.120 --> 24:06.240
that we're talking about? So one of the classic techniques, so I would say that that light microscopy,

24:06.240 --> 24:12.080
the stuff that I've been talking about, is relatively fresh in virology and sort of a bread and butter

24:12.080 --> 24:17.040
technique in virology would be electron microscopy. So electron microscopy, by using electrons,

24:17.040 --> 24:23.840
rather than photons, you definitely can bypass the diffraction limit. And hence you can get those

24:23.840 --> 24:32.400
very detailed images of viruses. But the trouble with electron microscopy in general is that it

24:32.400 --> 24:41.840
takes a room-sized device and a days of sample preparation to do some work there. So it's also

24:41.840 --> 24:48.080
destructive relative here. Yeah, absolutely. Yeah, so you definitely cannot do this life.

24:48.880 --> 24:53.280
So there is a, there is a field in microscopy or in light microscopy called

24:54.880 --> 25:00.880
a life microscopy or a lifestyle microscopy where you just essentially do a video of what's going

25:00.880 --> 25:14.000
on the cell with a different temporal resolution. Got it. And so this entire project that you

25:14.000 --> 25:22.560
are working on was interesting from a life sciences perspective because it was allowing you to

25:22.560 --> 25:32.240
resolve things at the level of a virus that were kind of at the edge of what you might be able to do

25:32.240 --> 25:38.480
with light microscopes. It's actually not particularly impressive for scanning electron microscopes,

25:38.480 --> 25:47.280
but just that's a lot more expensive. And not only that, I mean in terms of let's say differences

25:47.280 --> 25:52.880
in, there are differences in sample preparations, as you said, right? The sample preparation can be

25:52.880 --> 26:09.200
destructive and the entire sort of process of so-called functional microscopy is not as well

26:09.200 --> 26:16.400
developed in electron microscopy. By functional microscopy, I mean the situation where you can

26:16.400 --> 26:24.160
specifically tag the molecule you're interested in. So in this case, you in fluorescence microscopy,

26:24.160 --> 26:31.280
you're able to know specifically like, oh, I, you know, I placed a GFP, which is a green fluorescent

26:31.280 --> 26:39.440
protein in the capsid of a virus. So I know that if I'm seeing some green spot, that's probably the

26:39.440 --> 26:46.560
capsid of the virus. And that's what I mean by functional microscopy and that's a whole new different

26:46.560 --> 26:52.320
level of techniques. And I think electron microscopy is trying to get to that level, but it's a

26:52.320 --> 26:59.760
way, way trickier. So there's so in addition to to costs and the sample prep, there's also just

26:59.760 --> 27:04.160
stuff that we know how to do with light that we haven't figured out how to do with electrons yet.

27:04.160 --> 27:13.040
Absolutely. Okay. Okay. And so is this work that you're referring to the work that was recently

27:13.040 --> 27:18.160
accepted in the American Society of Microbiology paper or is this is that different? Yeah, yeah,

27:18.160 --> 27:25.920
that's a fresh stuff of the press. Awesome. And so in our, you mentioned that that paper also

27:25.920 --> 27:34.720
looked at the application of caps nets, capsule networks to this problem. And I mentioned when

27:34.720 --> 27:38.480
we were chatting earlier that I think this may be the first time I've heard of caps nets being

27:38.480 --> 27:44.000
applied in the wild. Tell us a little bit about your experience using caps nets. Why, why did you

27:45.600 --> 27:51.440
you know, try that route and what kind of results did you see there relative to, you know, CNNs?

27:51.440 --> 28:00.880
Yeah, thanks. Absolutely. So the caps nets, I have to say, they kind of swayed me with the whole

28:02.160 --> 28:06.400
sort of elegance of the idea. So I decided to try them on and just drop some data on it.

28:06.400 --> 28:11.440
And there's not a skirm that the folks are familiar with that, you know, maybe take a second to

28:12.640 --> 28:19.920
what specifically swayed you about the idea there and what the idea? Yeah, absolutely. So the idea

28:19.920 --> 28:26.800
of having sort of nested representations in capsules and trying to learn the nested representations,

28:28.640 --> 28:37.440
I find this somewhat attractive just because you probably would expect some logical connections

28:37.440 --> 28:45.120
to be retrieved in such a way. So I decided to try to train a capsule network. And so this

28:45.120 --> 28:55.520
turned out to be relatively difficult with absolutely sort of naive architecture without any

28:55.520 --> 29:03.840
pre-trading. However, using this trick that I've been talking about before with embedding some

29:03.840 --> 29:09.680
amnesty data and training it together with, or in a transfer learning sort of setting

29:09.680 --> 29:19.840
with various data, that helped a lot. And we got pretty good results. Resnets still win,

29:19.840 --> 29:26.560
but capsule networks are able to train on even on such wild data, as you mentioned.

29:27.760 --> 29:33.520
Interesting. Yeah, so the way I tend to think about the capsule idea relative to

29:33.520 --> 29:42.480
CNNs, and you tell me if this is a horrible explanation or not, is I think of CNNs as being good at

29:42.480 --> 29:49.040
kind of this two-dimensional, translational, invariance, whereas capsule networks are

29:50.320 --> 30:00.160
designed to represent kind of the structure within the thing, the image in multiple

30:00.160 --> 30:05.840
and higher dimensions, is that the main thing that you find interesting there?

30:05.840 --> 30:11.280
Yeah, absolutely, yeah. And I think that's there is something in this idea because I just

30:12.160 --> 30:20.160
doing some convolutions and then pulling it somehow, although it works remarkably well,

30:20.160 --> 30:26.640
and I don't mean to say anything about very clear and basic convolutional networks.

30:26.640 --> 30:38.560
However, it seems like there should be something more to that, so I choose a belief.

30:40.400 --> 30:52.560
And when it comes to the ultimate results that you saw is the idea and kind of what

30:52.560 --> 31:01.440
is power in your belief in the promise of Capsnets, is it that we with CNNs, and I think you said

31:01.440 --> 31:09.280
you use Resnets, like we know how to scale the compute there, and Capsnets, they're newer,

31:09.280 --> 31:14.320
maybe we don't know how to scale the compute as well and make networks that are as deep, but

31:16.000 --> 31:21.600
fundamentally, if we could do with Capsnets, what we are able to do now with Resnets,

31:21.600 --> 31:27.120
you would expect it to perform better, is it that kind of thing where we're just kind of catching up

31:27.120 --> 31:34.560
in our ability to compute. I'm trying to really get at the thing that you think holds,

31:35.840 --> 31:39.280
you know, holds so much promise given that it isn't working as well.

31:40.560 --> 31:50.320
Yeah, so I hope that exactly, as you suggested, if we able to scale the sort of network capacity

31:50.320 --> 32:00.560
required to address certain problems, we'll get to, we'll get them to work a little bit better

32:00.560 --> 32:07.440
than they do at the moment. And in principle, maybe it's not the capsule networks in general

32:07.440 --> 32:14.960
that will work out in the end. Maybe it is also some other approach that will build upon this

32:14.960 --> 32:21.440
promise that, you know, there's more of a context that we need to try to include in multiple levels

32:21.440 --> 32:37.520
at the same time. Is there, is your work touching on kind of this inherent graph, graphical nature of

32:37.520 --> 32:44.240
the underlying biological systems at all, is that something that you look at?

32:45.440 --> 32:51.280
Not yet. Unfortunately, we didn't have sort of capacity to look at this aspect, but I certainly

32:51.280 --> 32:58.640
think that, you know, there's only that many questions you answer, you can answer with a binary

32:58.640 --> 33:04.400
classification problem, right? So there is definitely an necessity to go deeper into representing the

33:04.400 --> 33:13.280
knowledge that is contained in the massive bodies of biomedical literature, for example,

33:13.280 --> 33:22.320
to try to understand the complexity that we have in the data. I mean, from the point of,

33:22.320 --> 33:27.680
from probably the very first day when I started working with microscopy images, I always perceived

33:27.680 --> 33:37.040
it as a sort of an ultimate roach act test, if you will. You get a spot, like a white spot,

33:37.040 --> 33:42.320
or a grayscale spot in a black background, and you try to understand what is that thing,

33:42.320 --> 33:48.880
and different people would definitely see different things in the same image. One person would be

33:48.880 --> 33:54.080
like, oh, what is that thing? Oh, somebody told me that's a cell nucleus, and another person

33:54.080 --> 33:58.880
would see chromatin there, and a cell is about to divide, and, you know, there's a lot of

33:59.440 --> 34:04.000
information that depends on the contacts, and depends on your prior knowledge there. So,

34:04.000 --> 34:10.080
obviously, as you said, I think incorporating things like knowledge graphs into work like this

34:10.080 --> 34:17.360
would be definitely a way forward, and that's something that I see developing in the coming years

34:17.360 --> 34:27.520
and the field. And so, maybe using that as an opportunity to zoom back out to AI and life sciences

34:27.520 --> 34:36.000
generally, we spend a lot of time talking about microscopy, and that plays a big role in the field.

34:36.000 --> 34:43.680
Are you, has your organization, you know, many new attempts to kind of map out the various ways

34:43.680 --> 34:51.440
that AI, you know, can or should impact life sciences, and how far along we are in those various

34:51.440 --> 34:58.000
areas? That will be a thing to go for that we that we have already discussed with my colleagues.

34:59.280 --> 35:04.720
And unfortunately, we hadn't had that much time to do that just yet, but I think in general,

35:07.120 --> 35:12.480
you know, going beyond just microscopy and images, looking at the, there's a lot of research

35:12.480 --> 35:20.320
going on right now in the field of molecular life sciences in general, looking at the

35:20.320 --> 35:27.200
molecular structures or sequences, protein sequences, DNA sequences, and trying to combine it with,

35:27.840 --> 35:33.280
you know, basic techniques like, same that is used in the in the fields of natural language

35:33.280 --> 35:38.720
processing, for example, right, where you could try to use some generated approaches, for example,

35:38.720 --> 35:48.320
to see, to predict the binding sites and to predict novel confirmations of molecules and so on.

35:49.280 --> 35:56.560
So this is definitely a great direction to start getting into. And I guess the way I see the

35:56.560 --> 36:05.120
mission for the organization is that we should try to bring the conversation forward to

36:05.120 --> 36:12.240
to combining similar to the way that life sciences are structured today. We need to combine

36:12.240 --> 36:18.640
multiple sources of information revolving around a single phenomena in order to sort of

36:18.640 --> 36:26.800
be able to push the discovery because life's discovery in life sciences is never done as a result

36:26.800 --> 36:36.160
of a single sort of method that that shows one thing. You always need to reach out and then try

36:36.160 --> 36:44.640
to prove, prove your concepts using multiple methodologies. And yeah, look at things from

36:44.640 --> 36:55.440
multiple sites. And is that fundamentally because what where the real insights are in life sciences

36:55.440 --> 36:59.920
when we start to understand function and you don't just kind of see that in a one shot thing,

36:59.920 --> 37:05.920
it's based around a developing body of knowledge that comes from looking at things in different angles.

37:06.720 --> 37:13.200
Absolutely. So the thing is that my most discoveries made not because, you know,

37:13.200 --> 37:20.480
you see something unusual and that's a discovery. It's quite in contrary, it's a rigorous process of

37:20.480 --> 37:29.520
just trying to prove that you made a discovery essentially in multiple ways until you run out of

37:29.520 --> 37:40.000
ways to just to prove yourself. So I remember when I stumbled upon a virus inhibitor for which

37:40.000 --> 37:48.320
we were published in 2017, it was using biomedical imaging at the time lapse imaging of

37:48.320 --> 37:54.720
of a so-called virus plaques. Virus plaques are when you start the infection with one single cell

37:54.720 --> 38:00.960
at Chines Green and then you see that the infection spread into neighboring cells and you get an idea

38:00.960 --> 38:07.520
what's going on with those cells. Are they supporting the infections where I do not? And I couldn't

38:07.520 --> 38:13.200
get it to work under certain conditions and it turned out that one of the molecules I was keeping

38:13.200 --> 38:20.640
in my medium was preventing it from spreading and that's how you stumbled upon a discovery.

38:20.640 --> 38:27.360
But essentially to get from that point to the actual published paper, it took collaboration of

38:27.360 --> 38:33.360
multiple people and multiple methodologies to address multiple aspects of what's going on.

38:33.360 --> 38:47.680
So what degree are there hobbyist opportunities in life sciences? Do you have to have the

38:47.680 --> 38:55.440
backing of a huge lab to not necessarily make interesting discoveries but even play with the

38:55.440 --> 39:04.880
data or are there things that folks can do to just start to better understand biology with

39:06.560 --> 39:11.360
the tools that we have in neural networks and the data sets that have been made available.

39:12.000 --> 39:17.280
That's an excellent question, thanks a lot. So actually I believe personally that there are

39:17.280 --> 39:23.680
massive amounts of hobbyist opportunities scattered around the field. There is simply not enough

39:23.680 --> 39:32.400
hands in life sciences to get all this advanced methodologies going and doing what they can do best

39:33.200 --> 39:41.920
like fostering science, improving the accuracy of assays and so on. So I think that

39:43.440 --> 39:50.400
that's one of the main missions of the organization I'm trying to build. It's to bring together

39:50.400 --> 39:57.040
hobbyist researchers from all sorts of fields in order to see, okay, maybe there is an opportunity

39:57.040 --> 40:03.680
to publish paper here and there and maybe there is an opportunity to make advances in biology.

40:03.680 --> 40:08.000
Maybe there is an opportunity to just get some published data and play with it a little bit.

40:08.000 --> 40:17.280
So that's one of the goals of this work. And in principle there is really a lot of data sources

40:17.280 --> 40:24.960
that maybe not many people know about that they can immediately work with as from a public domain.

40:25.600 --> 40:29.920
And there are a lot of open problems, we just need hands.

40:31.040 --> 40:36.320
Awesome, awesome. And so for folks that are interested in taking you up on that, how do they

40:37.440 --> 40:41.120
find you, connect with you, learn more about the opportunities that are out there?

40:41.120 --> 40:49.440
Go to ails.institute and join the forum, start conversation, ask a question.

40:49.440 --> 40:55.280
And the idea is that we will connect you with researchers who are actually working at this.

40:55.280 --> 41:01.120
Awesome. Awesome. Well, Arter, thanks so much for taking the time to share a bit about what you're up to.

41:01.120 --> 41:17.120
Awesome. Thanks a lot. It's a lot of fun. Thank you.

