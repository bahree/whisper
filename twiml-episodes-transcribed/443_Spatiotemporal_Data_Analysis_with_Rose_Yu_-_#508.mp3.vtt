WEBVTT

00:00.000 --> 00:23.000
All right, everyone. I am here with Rose. You Rose is an assistant professor at UC San Diego. Rose, welcome to the tool AI podcast. Thank you.

00:23.000 --> 00:31.000
I'd love to have you start by sharing a little bit about your background and how you came to work in machine learning.

00:31.000 --> 00:50.000
I'm currently a assistant professor at UC San Diego Computer Science Institute. I did my PhD at USC Computer Science and then I finished my postdoc training at Caltech Computer Science and Mathematics.

00:50.000 --> 01:08.000
My machine learning journey started way earlier when I was an undergraduate, when I participated in an undergraduate research project and was able to publish a paper at AAAI, which is one of the top AI conferences almost 10 years ago.

01:08.000 --> 01:24.000
I started my journey in machine learning and throughout my journey, I got a lot of mentorship and help from my advisors, postdoc advisors, my collaborators and students, and that's how I landed here.

01:24.000 --> 01:32.000
Nice, nice. Tell us about your research interests. What do you focus on from a research perspective?

01:32.000 --> 01:43.000
Absolutely. So my research focus on advancing machine learning, algorithms and methods for analyzing large scale time series and spatial temporal data.

01:43.000 --> 01:55.000
So specifically, we develop research in deep learning, tensor methods, non-combat optimization to understand dynamical systems.

01:55.000 --> 02:05.000
We apply these methods to solve challenging problems in climate science, in transportation, and many other physical science areas.

02:05.000 --> 02:16.000
So compare with traditional applications in machine learning such as image data or text data, spatial temporal data has their own unique challenges.

02:16.000 --> 02:40.000
Often times, they are governed by certain physical processes underneath. So the reason research trust of our lab is called physics guided AI, where we aim to integrate first principle methods from physics into data driven machine learning models such that they are more accurate, more physically consistent and more trustworthy.

02:40.000 --> 02:54.000
So maybe we can start by having you talk about some of the use case areas that you apply your research to just to give us some context.

02:54.000 --> 03:13.000
Sure. So at an Indian poll, in climate science, climate models are often used to understand the evolution of atmospheric dynamics. However, climate models at higher scale space and time resolution are extremely time consuming to simulate.

03:13.000 --> 03:31.000
And you're only running a climate model at full scale across the globe takes a couple months. So this is already too late when we want to understand the change of the climate, the weather or to you on, you'll make predictions of what going to happen in atmospheric environment.

03:31.000 --> 03:46.000
So one of the research a project was published in KDD 2020 and I clear 2010, 2021 is about developing deep learning models that can speed up this process.

03:46.000 --> 04:02.000
Essentially, we want to build deep learning models that can emulate the evolution of climate simulations and these climate simulations are typically governed by partial differential equations that describes underlying physical processes.

04:02.000 --> 04:27.000
So the main challenge is if we just used a vanilla deep learning model, they would not be able to capture the physical characteristics of the underlying phenomenon. So in our example, we use the hybrid models to borrow ideas from physical sciences, such as integrating ideas about

04:27.000 --> 04:46.000
computational fluid dynamics or integrating ideas about symmetry into deep learning. So in this way, our deep learning models can not only emulate the evolution of, for example, turbulence, which is a very common phenomenon in climate.

04:46.000 --> 05:06.000
It will not, it will also be able to predict values that are physically meaningful. So at example, we can measure when we try to predict the turbulence evolution, which is a very common in clouds, evolution in ocean current evolution.

05:06.000 --> 05:20.000
So when you say evolution, you're primarily referring to just the way it develops over time and that this is where kind of the time series element comes in exactly. So there are basically values that are changing over time.

05:20.000 --> 05:29.000
So mathematical, it's called dynamic or system. And when we try to develop basically describe the changing these values. And that's what I meant by evolution.

05:29.000 --> 05:49.000
Yep. Okay. So, you know, one in the one about KDD papers, what we showed is that, you know, if you just predict, for instance, the evolution of turbulence, velocity, right, you're essentially predicting a video right into the future, given the past friends of video.

05:49.000 --> 06:05.000
However, if you just use a video prediction methods that are developed out of computer vision community, then the predicted values of this video are not able to capture the correct energy spectrum of the underlying turbulence.

06:05.000 --> 06:30.000
And in turbulence community, this kind of energy cascade or energy spectrum is critical to describe the underlying physical characteristics of the system, whereas if we use our hybrid model, where we combine ideas from physical modeling and deep learning, our model is able to generate much more physically meaningful predictions.

06:30.000 --> 06:36.000
And our predicted energy spectrum just matches well with the ground truth.

06:36.000 --> 06:56.000
And so just so I understand the setup here is the key distinction that you're making between a model that's based on video and a model that's maybe a higher dimensional model or are using video in both cases, but in one case, you're not using the physical knowledge that you have.

06:56.000 --> 07:00.000
And in any other case, you're incorporating that physical knowledge.

07:00.000 --> 07:08.000
Yeah, it's a second case where, you know, both models are fed with the same information, whereas, you know, the natural video, because it's very complicated.

07:08.000 --> 07:18.000
We have, you know, many objects interacting with each other. It's very difficult to describe them with certain equations or certain governing laws, right.

07:18.000 --> 07:29.000
And in turbulence, the nice thing is that we know the underlying governing equation, and we have a lot of techniques from computational food dynamic community that we can exploit.

07:29.000 --> 07:36.000
So by exporting this type of knowledge, we can improve our predictions by significant amount.

07:36.000 --> 07:50.000
You mentioned space, your temporal data, it sounds, I'm inferring from that that the differential equations that you're using or the partial differential equations that you're using are relative to both space and time.

07:50.000 --> 07:51.000
Correct.

07:51.000 --> 07:58.000
And so how do you incorporate in those that physical knowledge or those partially partial differential equations.

07:58.000 --> 08:07.000
Yeah, great question. So there are multiple ways, right. So in the community paper, what we basically leverage is that, you know, the multi-scale modeling.

08:07.000 --> 08:16.000
We actually did not use the equation themselves, but rather we're looking at how people usually approximate these solutions of equations.

08:16.000 --> 08:29.000
So we found that there are basically convolutional operators that are computed over space and time. And this in CFT community was called the spatial averaging or temporal averaging, right.

08:29.000 --> 08:34.000
And more, I guess the acronyms are, you know, rents, LES coupling.

08:34.000 --> 08:47.000
So the rest LES coupling, the Reynolds averaging L is large edit simulation, essentially calculating the space and time average using convolution operator.

08:47.000 --> 09:03.000
So what we did is that, you know, instead of using deep learning to approximate the partial differential equations themselves, we're going to approximate the convolution operator by replacing this traditional design operators.

09:03.000 --> 09:15.000
With trainable neural networks, which follows down to convolutional neural nets. So then we have separate convolutional modules, she captured different scales of turbulence.

09:15.000 --> 09:23.000
And by doing so, we can model the multi-scale behavior in the turbulence and generate much better prediction.

09:23.000 --> 09:43.000
So that's one of the ways we can exploit the underlying physical physics. But I clear paper was was reasonably published is about, you know, looking at the symmetries in a partial differential equation, right, because, you know, if we think about partial differential equations.

09:43.000 --> 10:05.000
There are a lot of symmetries. And by symmetry, what I mean is, if I have a solution, that is a solution of the partial differential equation. And I can apply certain transformations to this equation by, for example, shifting by certain amount or rotating by certain amount or scale it up by certain amount.

10:05.000 --> 10:17.000
And this kind of transformation will change the equation themselves, but there will not change the solution by itself. So that's a symmetry in the solution of the PDE.

10:17.000 --> 10:39.000
And what we found out is that, you know, if we can incorporate the symmetries into our deep learning model, we can also capture the underlying physics, right, because there is a notation theorem that links the conservation laws with symmetry, essentially saying that for every symmetry, there is a conservation law.

10:39.000 --> 10:57.000
The translation time translation symmetry will correspond to energy conservation. So, so if we can incorporate this type of symmetries into deep learning, we naturally satisfy conservation laws, which are very important in physical model, right, and this idea is not.

10:57.000 --> 11:15.000
The symmetry across properties, meaning, you know, between the time and the energy properties of the system, or is it within the time domain or within the energy domain, you're exploiting symmetries.

11:15.000 --> 11:37.000
So it depends on what type of symmetry groups that you are either considering, right, so, for example, if you are considering the symmetry on the long time translation that is only on time, but if you consider for the gallon transformation, which is basically about space and time, right, then the scaling is about a different transformation on the input.

11:37.000 --> 11:54.000
And this idea of exploiting symmetry in deep learning is not new, so the reason, for example, convolutional neural networks are so successful in modeling image data is that it leveraged to translation symmetry in the spatial domain.

11:54.000 --> 12:04.000
Similarly, the reason why RNNs are very powerful in modeling sequence data is that it has built in time translation symmetry.

12:04.000 --> 12:13.000
And graph neural networks are very powerful in modeling graph data or set data, because it has, you know, intrinsic permutation symmetry.

12:13.000 --> 12:28.000
So this idea of incorporating symmetry in deep learning is not new, but what we did is to generalize this idea to the system to model space and time data that is basically governed by partial differential equations.

12:28.000 --> 12:39.000
And use this model to predict evolution of turbulence, the future states of ocean currents, or even forecast the future trajectories of autonomous vehicles.

12:39.000 --> 12:48.000
Got it. And so how exactly did you incorporate the symmetry properties into the deep learning models that you built.

12:48.000 --> 13:03.000
So that's actually the whole paper is about. So, you know, one idea is basically right think about how convolutional neural networks is able to incorporate translation symmetry and that's way sharing.

13:03.000 --> 13:18.000
And the same thing, you know, basically within the same filter, they are different ways, but across different filter, they use the exact same way. And that basically allows us to incorporate translation symmetry in complex.

13:18.000 --> 13:36.000
So we can apply the same idea to other kind of symmetry groups, for example, if we wanted to incorporate scaling symmetry. Now we basically need to design the filters in the convolutional architecture such that they're shared within, you know, different skills.

13:36.000 --> 13:52.000
So we have to deal with different kind of coordinates in the in the autonomous vehicle paper or the echo paper echo very continuous convolution, what we did is to work in a polar coordinates instead of the Euclidean space, right.

13:52.000 --> 14:10.000
And the model basically the scaling in terms of angle and the radius. And then we can share weights along basically different on like radius, but then have different weights with different angles.

14:10.000 --> 14:37.000
So in the case of the so that is the paper that you're referring to is it, are there separate papers for each of these use cases that is incorporating the symmetry information or is it is the paper primarily about methods to incorporate the symmetry into the dynamical models.

14:37.000 --> 14:50.000
That's a nice question. So it's a better both right because we often, you know, we conduct a use inspired research, you know, where we often develop method inspired by certain use cases.

14:50.000 --> 15:09.000
So we have, you know, two paper that I clear, which about incorporating symmetry and the first one is about, you know, incorporate in different symmetry groups into the sequence models for forecasting video is essentially for turbulence velocity fields and for ocean currents.

15:09.000 --> 15:23.000
Right. And, you know, obviously these symmetries are derived from PDEs and Navi Stokes equations, but we would imagine these methods that would develop our generically applicable to similar type of data, right.

15:23.000 --> 15:41.000
Another kind of the other paper that we published about equivalence continuous convolution is about point cloud data, right. So we have point cloud collected about from autonomous vehicles using radar, right. And we can basically work in a polar coordinate framework.

15:41.000 --> 15:54.000
And then we design equivalence continuous convolution, which essentially allows us to model rotation symmetry and scale symmetry in in this point cloud data.

15:54.000 --> 16:11.000
So we basically tested our method for the autonomous vehicle partition tasks and as well as the pedestrian trajectory, tradition tasks, but we also imagine that, you know, this method would probably be useful for other kind of point cloud data.

16:11.000 --> 16:28.000
I think your previous answer anticipated a question that I was starting to have. And that was, you know, when you talk about these symmetries, there are symmetries that

16:28.000 --> 16:42.000
we know kind of exist based on the properties of the systems of PDEs. And then, but there's a separate type of symmetry that kind of emerges from the data itself.

16:42.000 --> 16:56.000
And you're developing methods to kind of handle both of them are they are they totally separate use cases or are they kind of ultimately linked by the data that the PDEs create.

16:56.000 --> 17:06.000
That's very great observation. So, so actually, you know, there are basically multiple type of symmetry that can exist as you alluded to.

17:06.000 --> 17:27.000
And one is basically derived from partial differential equations, right, then we can analytically basically write down what are the symmetry has a set of equations satisfy. And that's what's used again, you know, the, the, the actual paper, incorporating symmetries into the dynamics models.

17:27.000 --> 17:38.000
But what we showed you that even though, right, sometimes we have data where we have no idea what are other actual equations that governs it, for example, ocean currents.

17:38.000 --> 17:48.000
We only know approximately that maybe Navista equations are the governing equation ocean currents. But there are because the underlying processes are so complicated.

17:48.000 --> 18:07.000
And we cannot write out all the possible symmetries of this data. So, but the model still performs well in this case, that just means even with approximate symmetry or some very, you know, vague idea of why it can help it will help in terms of prediction.

18:07.000 --> 18:27.000
So, that's the first part. And the data symmetry is about sometimes we have some intuition of the symmetry in the system that we want to model. For instance, in, in the time of the vehicles, we cannot derive the equations that captures the motion of Tom's vehicle because it's so complicated.

18:27.000 --> 18:43.000
But we have some intuition of what kind of symmetry can exist in driving, right, for instance, when we drive in the North America, right, and we wanted to turn right and we automatically know how to turn right.

18:43.000 --> 19:01.000
And then suddenly, let's say, if we move to, to south atmosphere, right, then we drive in Australia, for example, and we still wanted to turn right. But our brain can automatically adjust this change of reference and still be able to recognize that we can turn right.

19:01.000 --> 19:15.000
Even though we're in a complete different reference point, right. So then this kind of intrinsic or implicit symmetry is built into our reasoning framework.

19:15.000 --> 19:22.000
And then we can incorporate this kind of symmetry also in our model to improve predictions.

19:22.000 --> 19:41.000
You mentioned that we don't have the equations to model ocean currents. And this is maybe a bit of a digression, but that's somehow surprising to me, just thinking about like we, we, we know a lot about, for example, modeling air currents and weather.

19:41.000 --> 19:52.000
We do a pretty good job at that. I would have thought that ocean currents would be pretty similar and we have all those equations, but it sounds like that's not the case.

19:52.000 --> 20:00.000
Well, we were closely with climate scientists and what they taught me that is the climate models are not as good as you thought.

20:00.000 --> 20:06.000
And that's why there are so many great challenges that we need to work on.

20:06.000 --> 20:11.000
Got it. Got it.

20:11.000 --> 20:34.000
And so you mentioned, you mentioned convolutional neural net, you mentioned grass, you mentioned RNNs, it sounds like your work is primarily focused on using convolution operators and translational symmetry, or are you working with these other kinds of networks as well.

20:34.000 --> 20:53.000
Now, we actually develop our own network, right? That's what I'm trying to say, like, you know, as an example of how symmetry was incorporated into deep learning team, preparation in a CNN, the RNs are exactly these examples, but these are only focused on translation symmetry, right?

20:53.000 --> 21:10.000
And general symmetry, such as, you know, rotation, symmetry, scaling, symmetry, and even continuous images in lead groups, there are no neural networks that can do that. So that's, you know, basically our contribution, we are designing new type of neural networks that can do that.

21:10.000 --> 21:13.000
And obviously get on other people's work.

21:13.000 --> 21:24.000
I thought I had heard that you somehow mapped these types of translation onto the convolutional convolution operators, but.

21:24.000 --> 21:31.000
Yeah, so yes to me, the one of them, for example, is called convolution, but it's not the regular convolution.

21:31.000 --> 21:43.000
So I stood on the work of from condo and traveri, right, and many others, you know, work about group convolution, right, so it's a different type of mathematical operator.

21:43.000 --> 21:58.000
Got it. And so then can you talk a little bit about how you get from the mathematical representations of come of convolution or of symmetry or

21:58.000 --> 22:07.000
the translation that you care about to the network architectures that you developed.

22:07.000 --> 22:16.000
So yeah, basically, you know, once we came up with the right group convolution, right, which is the type of, you know, mathematical operator.

22:16.000 --> 22:31.000
So you can implement them in, you know, neural networks through either tensor construction or matrix multiplication.

22:31.000 --> 22:35.000
Once we do that, we basically divine a forward pass using the deep learning framework such as part towards, and now we can just, you know, fill it up as a module in a deep learning, you know, neural network.

22:35.000 --> 22:46.000
Okay, and you mentioned tensor methods as being one of the tools that you use, can you talk a little bit more about that.

22:46.000 --> 22:56.000
Sure, so the tensor methods actually came out of my PhD work, my PhD work was about, you know, developing tensor methods to understand spatial temporal data.

22:56.000 --> 23:07.000
Because tensor methods are, they're not deep message, they're shallow methods, right, but the nice thing is that they provide much more interpretable predictions.

23:07.000 --> 23:31.000
You can understand, you know, when we look at the prediction of a deep learning model, sometimes we're puzzled like why this model is making this kind of prediction, whereas tensor models a shadow model, it has multi linear structure between the input and output, and it's easier for us to diagnose this model and understand what is contributing to the prediction of the model.

23:31.000 --> 23:50.000
And another thing about tensor model is that, you know, it generalized the matrix method, which usually, you know, matrix methods models pair watch relationships think about the Netflix challenge in movie reviews where using matrix compilation, you can model the pair watch relationship between user and movies.

23:50.000 --> 24:06.000
But a lot of times when we model state spatial temporal data, they're higher order correlations, right, there are correlations among different locations and their correlations among different timestamps and they're also correlations among different features of variables.

24:06.000 --> 24:30.000
So, matrix methods are inefficient to model this kind of higher order correlation, and that's why that's where tensor methods shine in this region, it allows us to model, you know, triplets information or even higher order correlation, but all at the same time generate interpretable models to help us understand what's going on.

24:30.000 --> 24:39.000
And I guess another kind of relatively exciting direction is that, you know, deep learning is mostly about non-converse optimization.

24:39.000 --> 24:57.000
So, unfortunately, a lot of the optimization techniques and analysis were developed for convex regime. So, tensor methods are non-converse, and it allows us to, it provides us with a nice platform to study this group of non-converse optimization problem.

24:57.000 --> 25:06.000
And hopefully the insights that would derive from understanding tensor methods can be generalized to understanding deep learning.

25:06.000 --> 25:08.000
Nice, nice.

25:08.000 --> 25:20.000
You've also got a paper focused on looking at the uncertainty within these deep spatial temporal models.

25:20.000 --> 25:25.000
Is that built on the work that we've been discussing thus far?

25:25.000 --> 25:33.000
So, there are, they are basically related, but they're not the physics based model yet.

25:33.000 --> 25:39.000
So, this is just the first step for us to look at the risk assessment in uncertainty quantification.

25:39.000 --> 25:48.000
Actually, in terms of physics guided AI, the model that we use for this paper is the slightly different technique.

25:48.000 --> 25:58.000
It basically learns the residuals between the physics based model and the ground truth. So, you asked about how to incorporate physics into deep learning model.

25:58.000 --> 26:05.000
And this is the third way, right, because we talked about learning the convolutional operators, we talked about incorporating symmetries.

26:05.000 --> 26:16.000
And the third way that we did is to learn the residuals to learn the correction term between the ground truth data and the physics simulators.

26:16.000 --> 26:29.000
So, in this paper, which is originally published in IKVD, it's about, you know, forecasting COVID-19 or forecasting air quality, where we have very sparse data set.

26:29.000 --> 26:34.000
Right, in these regions, you know, we cannot have a million of data points to train.

26:34.000 --> 26:41.000
And using a deep learning model, obviously, will not perform well, because it's in a small data region.

26:41.000 --> 26:52.000
So, what we did is to incorporate, you know, physics models as a prior and learn the correction terms between the ground truth and the physics based model.

26:52.000 --> 27:00.000
So, in that way, we can use the physics model as a starting point, and we don't need that much data to train.

27:00.000 --> 27:11.000
And in these regions, obviously, because we have fewer data points, and it's important to characterize not only the prediction themselves, but also the confidence interval.

27:11.000 --> 27:15.000
So, imagine if you want to forecast a number of infectious cases in the next four weeks.

27:15.000 --> 27:21.000
It's not enough just to say the next four weeks, infectious cases will be, you know, X amount.

27:21.000 --> 27:29.000
But we also need to say the next four weeks, infectious cases will be X amount with 90% confidence.

27:29.000 --> 27:32.000
So, that's what I mean by uncertainty quantification.

27:32.000 --> 27:39.000
And it's extremely important in, you know, special time for forecasting in physics based model as well.

27:39.000 --> 27:44.000
Right, it gives us a tool to assess the risk that's attached to it.

27:44.000 --> 27:57.000
So, what we did in this paper is to investigate in a benchmark study study what type of uncertainty quantitative techniques that we can use in the context of deep learning.

27:57.000 --> 28:11.000
Okay, and what did you find there? Did you, did you, you kind of looked at the landscape, but did you find some methods that you thought would be interesting for the kinds of problems that you care most about?

28:11.000 --> 28:22.000
Yeah, exactly. So, so you really, right, when people think about uncertainty quantification for deep learning, the two goal method is based in neural networks.

28:22.000 --> 28:30.000
And you really, you know, based in neural networks, there are different techniques such as Monte Carlo dropout, which is approximate based on inference methods.

28:30.000 --> 28:36.000
And there is also what exact basic information master based on Mark of chain Monte Carlo.

28:36.000 --> 28:40.000
So, what we did in this paper is to look at two group of methods.

28:40.000 --> 28:44.000
The frequent is the UQ methods and the basic is UQ method.

28:44.000 --> 28:53.000
So, what we found is that, you know, within the frequent is the UQ methods, there are classic techniques based on bootstrap or based on interval scores.

28:53.000 --> 29:10.000
And there are actually quite competitive in generating the confidence interval, but then, you know, they often provide very wide confidence interval, which means they have good coverage of the forecast, but they may not have very high confidence.

29:10.000 --> 29:19.000
As, you know, in a basic regime, we looked at, you know, the stochastic gradient MCMC, which is the type of Monte Carlo method.

29:19.000 --> 29:24.000
And we also looked at Monte Carlo dropout, which is a approximate based in inference method for UQ.

29:24.000 --> 29:33.000
And what we found is that, you know, the, the mark of chain Monte Carlo methods, they give very good confidence intervals and they also have a good coverage.

29:33.000 --> 29:41.000
However, it takes a long time to train because we have to run the deep learning methods multiple times and to collect the samples.

29:41.000 --> 29:49.000
So, it's a very time consuming process and then Monte Carlo dropout provides, you know, good coverage.

29:49.000 --> 29:56.000
But it doesn't give the good intervals in terms of the uncertainty quantification, right? So, the conclusion.

29:56.000 --> 30:04.000
Exactly. So then, the conclusion is that there is no winner takes all situation in uncertainty quantification.

30:04.000 --> 30:11.000
It's really about the balance in computation, in sample complexity, in the coverage of the prediction and the accuracy.

30:11.000 --> 30:23.000
So, therefore, we provide a recipe for the practitioners in our paper, right? And you can just look at the recipe and, you know, deciding on what method you want to use for uncertainty quantification.

30:23.000 --> 30:26.000
Kind of like a flow chart. Yeah.

30:26.000 --> 30:28.000
Got it. Awesome. Awesome.

30:28.000 --> 30:41.000
So, maybe we can wrap up by having you share a little bit about future directions and what you're seeing as being exciting in the space and where you want to take your research.

30:41.000 --> 30:55.000
Sure, absolutely. So, as I mentioned, you know, the physics space AI is just just at its beginning, right? The idea of incorporating, you know, domain knowledge and physical laws into machine learning model is a very exciting direction.

30:55.000 --> 31:02.000
And right now we have been only focused on, you know, just generating predictions or emulating the models.

31:02.000 --> 31:20.000
The future of this direction, what about decision making as well? How can we leverage, you know, existing physical models combined with data to matter better decisions, right? And that will involve, you know, new techniques such as the basic optimization reinforcement learning.

31:20.000 --> 31:36.000
And even techniques from mechanism design economics, right? These are the new kind of direction that we want to push for. And again, the, the key there is to not only blindly trust the data and develop black box models.

31:36.000 --> 31:53.000
But rather to understand online governing process of the data and to exploit the known domain knowledge in this data in physical laws in conservation laws and all kinds of principles that we have to build better models, right?

31:53.000 --> 32:15.000
In this way, we can, you know, really advance, I guess, one of our passion is to use to use AI to advance scientific development and engineering, right? So if we wanted to really do that, we really need to develop models that can understand the physics that can understand the science behind it and can be trustworthy for the domain scientific to use them.

32:15.000 --> 32:23.000
Awesome. Awesome. Well, Rose, thanks so much for taking the time to share a bit about what you're working on. It's great to learn a bit about your research.

32:23.000 --> 32:51.000
Thank you so much for this interview. Thank you.

