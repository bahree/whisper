All right, everyone. Welcome to another episode of the Twinkle AI podcast. I am your host, Sam
Charrington. And today I'm joined by Rob Walker, VP of Decisioning and Analytics and General
Manager of one to one customer engagement at Pegasystems. Before we get going, be sure to take
a moment to hit that subscribe button wherever you're listening to today's show. Rob, it's been
almost three years to the day since the last time we spoke. Welcome back to the podcast.
Yeah, thank you. Yeah, glad to be here. Incredible three years ago, my God.
It has been a crazy three years. Why don't we have you introduce yourself or reintroduce
yourself to our audience? It's been a while. Tell us how you got involved in AI and we'll jump in
from there. Yeah, no, happy to, happy to do that. Yeah, well, AI has been a real passion of me
for a long time. I'm not prepared to admit how long it is. But I did a PhD in AI a long time ago.
Before it was really fashionable, I was just very intrigued by the promise. But obviously,
at that point, it was, well, we have neural networks, not the deep learning quite yet,
but definitely the learning. But it was also expert systems and rules. But that got me really into
that, into that, into that space. So I did my PhD then work for a large consultancy firm
around mostly predictive analytics. What we probably would now call data science and
consultancy around that. And then really, really, really wanted to, you know, set up my own,
my own company in an area called Decisioning, which was not quite a verb, is not quite a
verb I think. So maybe we coined it, but it's pretty popular right now. And that sort of is like
an applied way of, you know, of using data science and predictive models. So I've always been
intrigued by sort of, you know, apart from the science of it, but also, you know, how to make it
like really, really practical. So that company I sold and then through another acquisition,
you know, got, got to be part of, of, of, of Bega, where I'm responsible for, you know,
that part of the, of the business. So basically, long wind away saying, I've never done anything else,
then sort of AI, then applied, applied AI. So, yeah, I'm always excited to, to talk about that.
Awesome. Well, let's, let's talk a little bit more about the use of AI and ML in the context of
customer engagement and customer decisioning. What are the types of problems that you find yourself
helping people solve? Yeah. And, and, and this is actually sort of even, even way back. I've
always tried, maybe that's the consultancy background. I've always been very careful, I think,
to align this with outcomes because AI and machine learning is obviously used and very, very
broad. Even in customer engagement, it's still relatively broad because it can go from creating
auto generating text or images that you may want to use in marketing to stuff that, that we do,
which is really around determining the next best action or the next best experience, next best
conversation. There's a lot of next best now in the market. But have AI in combination with
business rules, determine what you should be talking about with a particular customer to make
that super relevant and, and very, you know, contextual. So the, the business outcomes are usually
around, you know, mutual value creation, right? So it's obviously, you know, it can be about
revenue. But in these times, you know, during the pandemic, actually, especially, but also in,
you know, in other sort of economic downturns, it's also about maybe coaching or counseling,
customers, you know, towards, you know, financial resilience. It's really not just about selling,
next best action is, is really about, like, you know, across the whole customer life cycle,
you know, whether it's nurturing retention, risk management, sales or, or actually determining
in real time that nothing is really relevant enough. So we shouldn't, you know, steal the moment
from the customer to talk about something. But, but it is, it's really about, so where the
machine learning and AI comes in is in part to determine what's best in next best action, right?
So that, that metric, because that sounds very simple, but in practice, it means that,
if you combine that to another big thing that's really important to, to, you know, to our vision,
is the sort of the one-to-one approach, right? So it's not working off averages and segments,
but it is really like, you know, for this particular customer, you know, Sam Charrington is,
you know, calling or browsing or swiping on his mobile app. Now, what do we do based on what
we know about him, based on what he's currently doing, maybe what he's even doing another, you know,
another devices or other systems, what should we be really talking about? And then the moment you
do something and react to it, we need to, you know, recalculate that in the moment. And the
relevance, I think, is a, is a key thing. And that's where we use the AI for. Like, what are you
likely, you know, going to be favorably disposed to, or what is top of mind for you? Yeah. Yeah.
How do you distinguish this idea of next best action and determining it from a recommender system,
you know, which we're all familiar with and interact with, with all the time, both from a kind of
high level use case perspective, as well as, you know, from a technical perspective.
It's interesting, because the, is there some media distinction there?
No, there is a media distinction, because we actually work in a few, you know, in some from
eco, e-customer or e-commerce clients, where both are being used, right? And, and typically,
I mean, in next best action is really at a customer level, right? Whereas the recommender system
is an input to that on, you know, doing a basket analysis and those kind of things. And then saying,
hey, people like you have built, have bought this based on transactions. And that's only part of
it, right? Because for instance, the next best action would, on top of that recommendation, say,
yeah, that's really, you know, what that person would be interested in, what that customer is
interested in, but it's too expensive. Or we believe that if he took out a loan on that,
then he wouldn't repay it. Or he is actually not interested in this at all, because there's a
surface issue that we should really solve. And that's what, you know, is actually the most pressing
thing right now. So it's an input to a next best action. And it's an inside that is useful,
but can easily be overruled or augmented by, you know, other more important insights.
Got it. So what I'm hearing there is that recommender systems tend to be kind of broader,
maybe product and offering based. And this idea of next best action is very personalized
to the, to the individual. Yeah. And very personalized to the individual. And I think that is the,
that is sort of, I think, the important thing. And also looks at a lot of different things.
Well, as an example, right, the recommender system might say, hey, this is like, you know,
your 4k television that you would likely be interested in because people like you would have,
would have bought that, right? But then on top of that, you know, you would, you would really have to look
at like, you know, can you afford it? Did you already maybe, you know, buy that particular
television? You already have it. So you may be interested because you already actually bought it.
And we should do something else, maybe an accessory to that television. There is like all of these
things get into, you know, come into consideration. So to us, it's just one of the many, many
propensities you would get, product propensities. That's the, that's the outcome. And in the case
where we work with like retailers, actually, next best action is often used sort of at the category
level. So it is using, hey, like, hey, we have this, we have this person, we think based on everything
she's been doing, this is the category she's interested in, which may be, you know, high
definition televisions. And then which particular brand and model of television might be the output
of a recommender system. And technically, because she also asked technically, the other thing
is that the recommender system doesn't really have to, you know, refresh all the time, right? So
in these scenarios where, you know, next best action works with the recommender system,
the recommender system, it's fine to, you know, overnight churn and create 10 million different
probabilities at the product level, at the skew level, right? Whereas next best action will just
grab that from the database, but then adds all the contextual insights and behavioral insights
to decide, yeah, this is the thing we need to actually talk about. Sounds a little bit like the
fusing of a CRM and a recommender and, you know, all of the possibilities that are created by
machine learning. It's a great combination. And the, yeah, it's, but it is really at the, because
a recommender system is really at sort of the skew level recommendation, which in a customer
experience, customer engagement context is really only one of the things you should be looking, you
know, you should be looking at if you want to be, you know, customer centric. Got it, got it. And
so if you're building a system like this, what are some of the things that you need to be thinking
about from a machine learning perspective to deliver these types of next best actions?
Yes, next, well, next best action recommendations. Yes, it's like it's fine. The recommender system
is just a particular class, you know, of algorithms that just an input. It's very confusing.
But I think the, the important thing, and this is obviously an open door, but I just want to sort of
say it's still, you know, it's not like, you know, doing AI or machine learning for, you know,
AI shake, right? So we really, really start, and I've always started from the business side,
right? So what are the outcomes in the customer engagement you want to achieve? Is it, is it
revenue growth or is it revenue growth with like constraints on the risk if you're a bank,
you know, you can, you know, you can hand out as we've seen a lot of mortgages, but, you know,
what does your risk profile look like? So, so you look at sort of the outcomes and KPIs,
and once you have established sort of those broad business goals, then you can sort of see the
sort of the scaffolding of, you know, the best metric in next best action, right? And the best,
then say, if this is the outcome, what kind of thing are we, for instance, if this is about
retention initially, right? And we want to retain customers that are, you know, dear to us,
and profitable to us, but, you know, we see sort of, you know, the, the bells of churn,
and we need to, you know, we need to see if we can, you know, save them. From that metric,
you then have to decide, okay, what kind of rules apply? So that's human judgment or, or, or,
or economic factors and profitability factors, right? Like, hey, we want to retain you, Sam,
right? But how much is that worth to us? What can we actually do that would be, you know, that,
that we have in stock in terms of, you know, convince you to stay longer with us, for instance?
So that's, that's past one. And then you're sort of start at the machine learning AI level,
where now we need to figure out, you know, what is on your mind, right? What you would be interested
in, what you would likely say yes to, right? And, and, and, and, and then one level below that is
another level of machine learning and AI. And that is like, okay, once we have decided that we
know what to talk to you about right now, right? And that can change on a dime, but probably talk
about that later when we talk about like real time and those kind of things. But once you have,
once we've decided this is what we need to talk to you about, now the question is how are we going
to do that? Like, are we using a visual? What's the script? How should we say it? All of these kind
of things. And again, that's where AI and machine learning will come up, you know, based on,
you know, collective learnings on what's best. That's sort of the, the approach very much top
down from the outcomes and then all the way down from, you know, outcomes and KPIs to rules,
to predictions to the data that is then required to actually make those predictions.
And is that last part relatively new? You mentioned kind of creating the script. Are you
now at the point where you're looking at generative AI to kind of assemble the script from a set of
data points? Yeah. We, we, we pick actually sort of more, you know, script or content because I
think that is a particular use case of AI, which is very interesting, you know, to generate,
you know, what is the perfect sentence? What's the perfect image? So we do sort of, you know,
some creative optimization, but it is of a stock, right? Because I think, especially generating it,
right, not picking the best one, but generating it, very interesting. It's not what we do,
but we work with systems like that and say, Hey, we give you the context. We know exactly what we
want to talk about. If, you know, if you can pick or construct more interesting, you know, the
right background image or the right, you know, banner text, then that's great. We don't, we don't
specifically do that. We just pick it from a library of, of actions, which can be thousands of
things. A couple of things that you mentioned jumped out of me. One is this idea of starting from
the, the outcome. Another is part of that. You mentioned that use a combination of machine learning
and heuristics. I'd love to get your take on kind of how those are co-existing in your
engagements nowadays. I think we've kind of, you know, there's been this pendulum swing of,
hey, we're going to do everything using statistical machine learning to, hey, you know, we've got all
this domain knowledge and these rule-based systems. Can we find ways to fuse them together?
I'm curious how this plays out and the types of problems that you're solving.
Yes. And it's, I think it's, it's, it's, it's a very interesting, I think topic to, to discuss
a little bit because the, the combination of sort of, yeah, heuristics or, or even human judgment
in most cases, but mostly, you know, heuristics on, on top of machine learning, I think that
combination is important for, for a few reasons. I think one, there are just things that honestly
require, you know, human policies at least, right? For instance, an AI will not tell you that,
unless that's what it's trying to do, but will not tell you that there is a competitive pressure
or there is an announcement of an acquisition in your industry and you need to really, you know,
prepare for that and change tack. You know, so that's the kind of heuristic that you really want
to change quickly, but you don't necessarily want the AI to do those kind of things for you,
indefinitely not unsupervised. And that's the second topic, is that in the industries,
we do most in, which is, you know, retail banking, insurance, communications, healthcare.
It's typically very important that you can also, to some degree, and in many cases,
to a pretty significant degree, explain what is happening, right? So if you had like AI,
especially, you know, the, the fancy algorithms, try to figure out everything that would not be
an acceptable way of, of doing it, even if it worked, but in combination, so the heuristics on
top of thousands of insights that are generated by AI machine learning, we've learned that just from
a business outcome perspective, that's pretty, you know, um, parallel performance.
And can you talk a little bit about how you make that work? Is it kind of
fusing rules engines with algorithms? It is, um, although that makes it sound a little bit like,
you know, it's like a technical integration. Um, and the thing is, um, we've done this for a very
long time. I mean, you know, we spoke last time three years ago, but I've been in this business,
as I said, much longer than I care to admit. Um, and, and, and we've really been very opinionated
now, uh, in a good way, opinionated sounds maybe a little bad, but it's like, um, we know sort of,
you know, what these large brands or, you know, in particular industries, what's best practice,
right? So it's, it's really like more of, um, of, um, of a declarative way of saying, hey,
let's, let's take you through this process of defining the outcomes, then defining rules,
like, for instance, eligibility rules, right? I mean, whatever the AI thinks, you cannot actually
sell a car to a four-year-old, right? Even if the person would be really, really interested to buy
like a, whatever, there's like all sorts of, all sorts of rules that maybe, you know, inventory,
there's risk and margin rules, there's all sorts of these kind of rules that you need. So that's
what you start to define outcomes, then eligibility rules, suitability rules, maybe some competitive,
you know, priorities that you, that you, that you see. And then you start looking at sort of the,
the full action library. So what are all the actions across, you know, nurturing and onboarding
and selling and retention and, and, and, and, and, and, and, and, and, and, and, and risk management
like collections across all of the actions in those categories. Um, how are we going to arbitrate,
given the top of that pyramid, pyramid that I just described, right? And then automatically,
and automatic is here, one of the key words because there are thousands of these actions. And if you
have the treatments on how to, how to present those actions, it gets into even bigger numbers.
For each of those, you need a predictive model to predict this is the interest in the moment,
right? And, and it's not like you have to import or something or find, you know, a thousand
algorithms in the organization, the way that typically because that would obviously be, you know,
fine, but un, unmanageable. Um, so the way that really works is that we look at the data science
output that's already available, right? They may have a risk model or many risk models or attrition
models or propensity models for certain very important products, which we would actually import
into that framework. So we can execute it, but we almost always compliment that, um, with a massive
machine learning capability to compliment data science, right? So data science, typically with the
kind of, um, brands we work with, uh, would still monitor that. So it's like, they shouldn't really
care whether this is a model they created in, you know, um, you know, Python or whatever it is,
or it's a self-learning model that beg I has supplied to them, you know, they, it's, it's their
responsibility, but it just gives them, uh, uh, much, much higher throughput, right? Because these
models learn on the fly, they look about competitive actions that look about seasonal
winfluences, well, all of these kind of things, um, and, and, and, and, and just back to your question,
so they stop down approach, declarative from the outcomes, then the rules that every business
will understand, like eligibility and profitability and all of these kind of things,
then to all the actions and their propensity models that are generated automatically,
that sort of, you know, I think the state of play currently in the, in the industry, it's not a
patchwork of like costly integration to do this. It's just that's the motion for next best action.
And when you go into a large brand of those propensity models already typically exist or
are there, you know, are there holes that need to be filled or new ones that need to be created
in order to, to fulfill the, the framework that you're trying to create? Yes, two, two, two things
about that. So, uh, usually, um, um, so first of all, from, from a, from a decisioning perspective,
that's at Europe again, um, um, we're, we're really trying to be, uh, agnostic about where the
algorithms come from, right? Because there's like, there's great open source tools,
the big cloud platforms will have, you know, offer increasingly more analytics. So,
I don't really care about any of that, where that comes from. I just care about like, can I have
um, an algorithm behind every single action and treatment? And can I execute it in the moment?
That's very important. So, I, I don't want to retrieve a probability from a database, right?
Because if, if a customer says no, right, then I want to re-evaluate a thousand different
predictive models where that no may have some influence and then re-decide what the next best
action, what the next best action is, right? So, so we usually, and, and I'm, when I say usually,
actually, I mean always, complement the, the existing models, um, the data science models with
this machine learning capability. Um, but one thing I would like to, to add is that on top of that,
and this is, I think what a lot of brands are also asking for is around like, you know, this whole
responsible AI, right? We also want to make sure that every algorithm, whether the data science
department build it or our machine learning generated it for them, um, we'll have to adhere to,
you know, sort of the tenets of responsible AI. Like, is it a fair model? Is it a robust model?
Is it transparent? If you need it to be transparent in a particular, um, as said, is it empathetic,
which is sort of, in my mind, really about like, is it relevant? But anyway, those, those tenets
of responsible AI are much easier to enforce if you have like a central AI policy that you can
apply to, you know, your next best action strategy, wherever the algorithm or originated from.
I think that's important. And, and, and lastly, Sam, just before we move on, it's also like,
because it's this combination of heuristics and AI, we can't just look at an AI algorithm
and say, oh, it's biased, you know, it's, well, if it's biased, it's biased and, you know,
we have a problem. If it's not biased, that doesn't mean that your overall outcome is unbiased.
If you apply your rules to it and, and a hundred other models and then arbitrate,
is the final outcome of that, the final recommendation is that fair, right? That's, that's more
of sort of the challenge that we take on. Okay. Uh, I want to circle back to, uh, responsible
AI. One of the things you mentioned in kind of drawing this distinction between
data science and machine learning or these, uh, propensity models and, and kind of the
decisioning on top is that you don't want to have predictions, uh, in some database because
you want to be able to evaluate them real time across these thousands of models. Uh, talk a
little bit about the doing that at scale. Yeah, that's hard. That's actually, it sounds hard.
It is, it is, it is hard. Yes. So I think part of a little part of, of, of,
certainly, of, of my career, but also, you know, the, the teams that have been, that have been
building this, um, it's, it's all about that scale. Can you do that, um, at scale and can you
do it fast enough, right? Because remember, this is customer engagement, right? So you are, it
means that, that if, if, if, if, if, you know, if, if you were, you know, saying no to something,
we need to within fraction of a second, we need to take that no into account, recalculate 1200
propensities, apply all the rules on top of it and then say, oh, but in that case, you know,
and then, you know, have the next best action ready, right? So that's, um, from a technology
perspective, I think is, is, is quite a feat. Um, and I think it's often confused and, and maybe
even downplayed a little bit in, not, it sort of in the market like, well, do we really need real time?
Um, and, and there are really two different things. One is like, do we have all the data real time?
And that can be a challenge. You don't meet all the data, you know, real time. I don't need to know
your birthday in real time, you know, that's fine. Um, but the, the thing that you're doing in a
particular channel, right? What I'm browsing, what I'm clicking, what I'm not clicking, my mood,
all, all of these things that we can now figure out increasingly accurately, um, all change the
context, right? And I want to have the, the most up to date, really up to the second context,
added to sort of a more static profile, and then apply all of these algorithms to it, right?
If I don't, um, then if you said no, then, you know, the results will be pretty much the same.
Well, I would probably suppress it in a rule. I would say, if he said no, let's not offer this
again in three weeks, right? But in fact, you'll know informs a thousand predictions, right? That
again, you know, maybe some of them will not change. A lot of them may change a little bit. So
may change a lot, right? And then the next best action, that kind of relevance is, I think,
that's sort of definitely our claim to fame, but, you know, relevance drives conversions,
drives drives, drives customer satisfaction, drives a conversation like, you know, interaction.
And that's why it's important to not retrieve a score from a database that is, even if it's,
you know, a minute old, that's already not great. Like it would be like, we were, we would be talking
with like a minute delay. It would be hard.
Yes, it's the way it usually works. So first of all, we do support, you know, both on-premise
and cloud model, but pretty much all we do is, you know, it's all cloud, either our cloud or,
you know, the client's cloud, the private one, whatever, all of these options exist. And it's
actually more, more of a, you know, a data and data governance challenge than it is a technical,
than it is a technical, technical challenge. But what we, what we do is like we do pre-aggregate
all the things we can pre-aggregate. And again, that's completely automated. There's no building.
It all comes from declaring what your business challenge is that you're trying to solve, you know,
from that pyramid that I described from the outcome down, but also all the data transformations,
you know, are also happening in real time. But for instance, what we don't need to calculate in
real time is like, for instance, if you are, you know, with like, you know, like a telecom operator,
right, we don't need to re-calculate your, you know, your text messaging or I am volumes
over the month, is that going up? Is that going down? You know, those kind of things you can,
if that's a, if that's a material predictor, right, you can, you can pre-calculate all of that.
And there are many of these kind of trending things that we, that we would sort of pre-aggregate
to make sure that in the moment we don't have to do that. And we can just take your monthly
effort and your weekly effort and your three monthly effort as pre-calculated, assuming that. In the
machine learning and ML ops ecosystem, there's this notion of a feature store which sounds a little
bit like what you're describing. Do you relate this idea to a feature store? Yes, yes, I would,
I would definitely, you know, call it that. We call it, you know, an extended analytics record,
but that's pretty much, pretty much the same thing. So it's the usual profile data then,
then as much of a transactional data that you have or that, you know, the brand cares to share,
you know, could be part of, you know, of a customer data platform or in, you know, big storage,
big data platforms. And, and then, and then some of these features that you can pre-calculate
and are not two-time sensitive, that's, that would be added to that, to that, to that record.
But not sort of, I just want to make clear because it so nicely top down, you don't have to sort
of boil the ocean. I see a lot of, a lot of organizations that think, hey, we're going to build
our CDP or our data, you know, big data platform and we're going to do that first because we need
that to do analytics and we need to do the decisioning on top of it. So that will have to wait.
That's actually, although it sounds sort of common sense, but that's actually the wrong way of
doing it because if you go from, well, it's not the wrong way of doing it. It's a very expensive
way of doing it, right? Because you can use AI and machine learning to sort of figure out, hey,
first of all, given that we're optimizing business outcomes, maybe the data that we have or can get
relatively quickly, we'll get us already 80% there, right? So you have like the funding and,
and, and, and, and, and, and, and the business case to then iterate and, you know, make your data
better or, you know, increase the number of features that you would, in the feature store.
All of these things are much better informed if you actually know what you have rather than
trying to be complete and, and AI sort of, it's almost a side effect, but not really AI and machine
learning can report very accurately on, hey, this data works, this data works with this kind of data,
or there is a correlation between this and this, so you actually don't even need to store this,
or certainly not, you don't have to make it available in real time, you know, so from, from
thousands and thousands and thousands of customer attributes, for instance, the predictive models
may use a couple of hundred, maybe even tens, you know, in, in, in some cases, and it's really good
to know that, otherwise you will invest a lot of time and money in making the data perfect.
Are these next best action types of problems? Typically, at least the machine learning parts
supervise, like is there a requirement to label a lot of data? It's, it's usually really matched
against, you know, it's supervised because it's running against particular outcomes that we already
know, right? So we are trying to predict, are you going to what's right? Are you going to default
on your loan? Are you going to buy this product? Are you going to make us, you know,
is the value of the relationship going to go up and down? And, and, and that's essentially,
you know, what, what you learn about. So it's, it's in that sense, it's supervised learning,
it's supervised, very highly used from historical data, as opposed to, you know,
have a label, a particular transaction. No end, no end labeling, no, no, no, this is all,
yeah, no good question. Yeah, so that's all, this is all at the, at the, at the very large
scale. I think part of this, it's only part, but part of this is trying to sort of, you know,
industrialize this whole process, right? Because otherwise, it would just be, be daunting,
right? So that's sort of the design phase is actually relatively easy, you know, if you know,
what you're doing, you go from the outcomes and the rules and the data, it's, you know,
and then you don't boil the ocean, but you start at maybe 80% of the value, which will be in
a astronomical figure, usually given, you know, the brands we work with, at least. And then,
you know, you can get from 80 to 85 to 90, maybe to 95, and maybe you don't even worry about the
last, the last 5% because, you know, it may not even be, be worth squeezing the data for, for, for, for, for, you
know, that last bit. Yeah, maybe one last question on this. I think you spoke to this already
from an explainability perspective and kind of the opacity of, quote unquote, fancy algorithms,
which I took to mean deep learning. You know, deep learning gets a lot of attention, but a lot
of the bread and butter problems within enterprises are kind of these tabular data problems that,
that is struggles with our, I'm curious the types of models that you, that you see I'm assuming,
you know, kind of a lot of classical tree-based types of things. Are you also seeing places for
deep learning within the, this next best action problem? Yeah, some, and, and, and, but as you say,
because I get the question a lot like, hey, we want to do deep learning, but again, it's often for
deep learning sake, right, because it's, it is, first of all, it is opaque, so you have to be very
careful in practice of what you let it predict, you know, if this is the background color, okay,
or the position of your billboard in the city, maybe, right, but whether you get like a mortgage or
not or be approved for a loan, there's no way any bank would apply a deep learning model to do
that, but from our perspective, as I said before, we are really agnostic and then allow, so we,
so if you, if you, for instance, if we will work with the bank and the bank says we have like,
you know, an incredible model to predict risk, right, then, then you could actually, so we don't
really care, except we allow them to apply sort of an AI policy. So, transparency is a good one,
there's more, like bias and things like that, but that's part of sort of the AI policies,
not our policy, that's not our place, but we allow these organizations to define an AI policy
that we will automatically check against the algorithms, right, which means that a deep learning
model would not be compliant, so we would flag it as incompliant or not compliant if it is about,
like, you know, the probability to take on a loan or recommend a loan, but we would probably
approve it if it's about the position of a particular ad on the web page. Got it. It's hard to
visualize the user interface of a AI policy system, although maybe it's, it's similar to, you know,
it's, it's another set of rules. Yeah, it is like, well, it's more like the way we look at it,
it is more like, like, like, like a filter, so you have like all of these models that you are,
if you have your libraries, so that's part of part of, you know, of model ups, it's like you have
all of all of the models, and they get tacked by like, you know, their explainability or the
type of algorithm, and then, and then we sort of see, well, this is allowed, and this is part of
the policy, you just define and say, hey, for this particular use case or this particular, you know,
decision, we really have to insist on a very transparent models like a decision tree or regression,
or just rules, whereas here, you know, go a lot, right? So even if we don't really understand it,
but we would flag, before taking something into production, we would flag, you know, the
oh for all logic, which is, you know, the heuristics plus the models as being out of compliance. Now,
transparency is just one aspect of responsible AI, what are some of the other ways that you're helping
customers manage those challenges? Yeah, well, so the way we define responsible AI, yeah,
transparency is I think is clear, and we discussed the other one is I think it's also obvious,
you know, fairness, so is there a bias? But again, it's not a bias in the model, well, as well,
but, but no bias or very acceptable bias, maybe if there is anything acceptable about it,
but in the model, doesn't actually mean that your final decision will be biased, right? It's a very
subtle combination of predictive insights with like, for instance, eligibility or suitability
or profitability rules may actually produce results you didn't expect, right? And that's what we
in that AI policy test against. So you can have 100 models, you can have, you know, a thousand
different predictive models underneath all of the rules, and we check if the next best action
distribution is actually fair, right? And I think that's the kind of thing I think that's that's
important. And then we have sort of softer things that we call it empathy in our responsible AI that's
like, it's maybe not even completely correct because it's, you know, you can be responsible
without being empathetic, but we get and I get when I talk to executives a lot of things like,
well, we don't want to be a clinical brand that, you know, has this robot AI deciding what to do
and it's not warm enough or it doesn't really reflect our brand values and that's another
aspect. So we also calculate sort of the softer elements like, for instance, your level of empathy,
your relevance, like are you, for instance, withholding relevant messages or actions to a particular,
you know, subgroup of your customer base. And if so, why is that? Is that like, because it can
be eligibility rule, like back to the car selling the cars or, you know, to teenagers, for instance.
So in that case, that's okay that you're doing that. They may be interested and the models may
indicate they're interested, but you still can't do it. But it can be a lot more subtle, right?
Maybe it's like a policy way that you've set or you put in competitive pressure or you, you said,
well, the profitability is so important. Like, for instance, we need to get this message out
because we need to sell, you know, 10,000 of these and we are completely spamming our customer
base and nobody's interested. We would flag that kind of meta analysis to say, that's not very
empathetic and you need to decide on, you know, what your brand is. And also what the cost is
of doing those kind of things. And the last one, Sam, is around robustness. And this is a question
I also get a lot. And that is like, if you have your predictive models and they're static predictive
models, so, you know, you've been building them or your data science group has been building these
models and you execute them in real time, the model itself obviously doesn't need to change.
And that's fine. So you can test it, you can simulate it. All of these things are fine.
But if it's a self-learning model, especially if you have thousands of them, you want to make
sure that none of them goes rogue, right? Like, hey, it's it's being exposed to real time or real
life, I should say, real life behavior. And suddenly it's doing weird, weird things. And especially
if you combine that with like, you know, maybe a deep learning algorithm, you know, that can go,
hey, why are you really quick? So that's another aspect that we make sure like, okay, we are testing
these self-learning models. Are they are they drifting? Are they drifting a little bit too quick?
Is there a concern? And there's thousands of them. So you can't manually look at that. So you
need to flag that for a data science or a governance body like the model of his in a large organization
and say, hey, there's something weird going on. It still works. You're not you're still fair.
You know, you're still making value, creating value. But this model is doing weird things and you
need to, you know, look at why that is and we then, you know, help this that discovery process.
Awesome. Awesome. Well, I know that in addition to customer engagement, one of the other things that
you're excited about is your upcoming conference, Pega World. And before we wrap up, I wanted to
give you a chance to share a bit about that. Is that a place where folks can come to learn more
about the kinds of things we've been talking about? Absolutely. So, yeah, Pega World, old virtual.
So everybody can sign up. It's it's it's free. Maybe the last time or one of the last time,
we do it virtually, virtually only. But for now, it's virtual. Everybody can sign up.
It is May 24th in the morning in the in the US. So it won't take up all of your all of your day.
And you will hear, you know, companies like, like, for instance, T-Mobile talk about, you know,
much of this and their vision and how they've been, you know, operating and and and and productizing
next best action in that are obviously, you know, breakdowns and deep dives. It's very interesting.
And we'll talk about a lot of these kind of things. But you can also, as I said, hear it from,
you know, the brands themselves. Awesome. Well, Rob, great to see you once again. And thanks so
much for joining the show and sharing a bit about what you've been up to recently and digging into
this more detail. And thanks for having me, Sam, as always. Okay. Yeah. Bye-bye.
