Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
Today in the second episode of our reinvent series, we're joined by Geno Choi, assistant
professor of computer science at Emory University.
Geno participated in the conference's AI Summit, presenting on ELIT, which is short for evolution
of language and information technology, which is a cloud-based NLP platform.
In our conversation, we discuss some of the key NLP challenges that Geno and his group
are tackling, including language parsing and character mining, as well as their vision
for ELIT, which makes it easy for researchers to develop access and deploy cutting-edge
NLP models to the cloud.
If you're hearing this on Wednesday, I'm currently at NURRIPS.
If you're also here, please join the listener meetup I'm hosting tonight at 630 at Tavern
Midway.
Be sure to RSVP via the social activities thread in the conference's Hoover app.
Next week, I'll be in Seattle at CUBECON.
I'd love to connect with any listeners in the area or in attendance.
Feel free to shoot me a message via at Sam Charrington on Twitter, via email, or the
Twomo website, CURM, and now on to the show.
So we are sitting here in Las Vegas, the occasion that brought us together is the reinvent conference
here, where you delivered a presentation on some of the work that you're doing at Emery.
But before we dive into that, tell us a little bit about your background and how you got
involved in machine learning.
Right.
I actually got into the natural language processing back in 2002, so that's when I was
doing my master's degree at University of Pennsylvania, and so I've been always interested
in studying languages and having the language understanding by computers.
So since I was young, I was always telling my mom that I wanted to make a robot that
understands me, and I guess I'm stepping towards to that goal still, and I don't know if
it's going to happen before my time or not, but I'm going to try to strive to it.
So once I actually got into this field, I was fascinated by all these machine learning
approaches.
The machine is capable of learning the patterns that we don't really even teach, and you actually
can pick up the patterns that we don't even think about, especially with the latest
technologies with dim learning and neural networks.
It's actually started discovering some linguistic phenomena that has not been really discovered
by humans yet.
So this is actually a very exciting time of the year to study natural learning processing
along with machine learning.
What are the research areas that you focus on in your work?
Right.
So there are many different fields in natural learning processing that I do, but there
are like mainly three projects I work on.
One is the core level natural learning processing.
What we call given an unstructured raw free text, we try to analyze the text into structures.
So this is all prototypical since you learn from the elementary school.
So you analyze the language into grammatical categories, synthetic patterns, semantic
processing, and some understanding.
So we now try to have computers to generate the similar structures that we have been
teaching in the decades.
So that's the one part of the research I work on, which we call as a language parsing.
And the second part is we also try to show how the language represent.
So especially we are trying to present this into the setting of the machine comprehension.
So the project that I actually created since I came to Emory was a project called Character
Mining, and the goal of the project is to understand human conversation involving multiple
parties.
So now the scenario I'm designing right now is if you have a machine such as Alexa or
any of this client conversation agent machines, it can just listen to our conversation.
And later on, if we actually forget some contents about this conversation, we can, instead
of calling multiple people around about this, we can ask the machine, so what did I talk
about?
What did I talk about?
And if I forgot your last name, so what was Sam's last name, it should be able to tell
if that kind of content was brought up during the conversation.
So that's one project I call Character Mining, that's what I work on most.
And also along the application size, since Emory has a huge hospital, we have so much
records, years of years of data from patients and all this different kind of electrical
healthcare data.
So we actually also try to apply natural links processing to help people to facilitate
better for their medical needs.
So especially what we have done is we have tried to done the classification of the radiology
reports and see the machines capable of seeing what kind of severity level of this patient
has based on the text and the report.
And I think we have been reaching to the similar accuracy as humans do.
So that's what the technology is involved.
And also another new project that we start working on is, given the language patterns,
or you basically ask the person to speak freely about certain things, about what or two
minutes.
And analyze the style of the language or some patterns of the language, and we can detect
if the person has some kind of cognitive impairment and leading to the Alzheimer's disease.
So we are actually trying to catch a very early stage of Alzheimer's disease by using
our language technology, and this has been actually working really exciting project for
me.
Oh wow.
There's a lot of interesting stuff to dig into.
So the first one that you talked about is kind of language parsing, and we have a long
history of trying to do this with computers, both using more traditional rules, model-based
approach to doing it, and more recently statistical-based approaches to doing it.
What are the main elements of the way that you're going after this problem?
Right.
So during my PhD, I graduated from my PhD even in 2012, which is not that long ago.
Amazing thing is every approach I actually learned during the PhD actually has changed.
One side story, one side story about this is, when I came to Emory, I spent a year to
make slides for my natural language processing graduate level class.
That was year 2015, and I cannot use any of those slides anymore, because technology evolved
so much, which is great thing for the field, but for faculty members like us, we just have
to keep making new slides every year.
Well, I mean, it's a happy thought, but so the ladies break through, I have to say,
it's a neural network and dim learning.
So at the moment, we are trying to rely on the supervised learning, which you need to
require an enormous amount of manually annotated data from the linguist, and you basically
the machine tried to learn the patterns among the human annotations and tried to produce
a very similar result for the unseen data.
So this approach has been working for over 20 years in natural language processing lately,
because of this evolved amount of neural network, we can actually use a lot of unsupervised
data.
So free text without human annotations can actually take a huge role into this field now.
So all of a sudden, let me give you a very solid example.
So there was a synthetic parsing test case, one of the tests that natural needs processing
field has been investigated for a long time.
And the accuracy of 92 or 93% was the barrier that had not been broken for over 15 years.
And after this neural network, it got broken up to 96% now.
As of last month, one of my pitches actually broke the record to the 96%, which is something
that we couldn't even dream of just two years ago.
So yeah, I think all this involvement of the diminuting and machine learning technology
really played a huge role in natural needs processing.
And so is there a particular type of model or model architecture that you're using to
do the syntax parsing?
Right.
So there are multiple different ways of doing it.
So for parsing, there are two main streams of parsing.
One is known as a transition-based parsing, and there is known as a graph-based parsing.
So in all days, just like it's not even all days in five years ago, a lot of people focused
on the transition-based parsing approach, which doesn't search for the entire, search spaces
and entire possibilities, but it actually prints out a lot of search space so it will run
much faster.
And speed is really essential for the big data analysis.
So everyone was going for a transition-based parsing.
What was actually amazing was now because of all this power of the GPU, which is known
for parallel processing, even if we actually make an exhaustive search using graph-based
parsing, it can actually still run as fast as a transition-based parsing.
So this actually is another movement that I didn't actually dream of during my PhD time.
But now my students actually are discovering graph-based parsing, which usually is more
accurate, and now can even run as fast.
So the algorithm is basically making the exhaustive search and giving all the possible probabilities,
now you can re-rank to find the best structure out of it.
So which is getting much more popular approaches these days.
And so in that model and the graph-based processing, what are the nodes of the graph?
No, self-the-graph is the individual word.
And the connection?
The connections will be what we call dependency relations, so like subject, object, preposition
relations.
So if you have a simple sense of like John but a car, so John is a subject of both and
car is an object of both, and all is a determiner of car.
So that kind of relation is the synthetic parsing.
You start with just nodes then, right, because the problem that you're trying to solve is
define what the connections are.
So now in this example, there are four words, John but a car.
And so you have four nodes, and you have one external called root root of the sentence.
So it depends on your approach, but root of the sentence in this case will be a bot.
So bot will be connected to root, and everything else will have a connection to itself.
So the current approaches that we are developing is you try to find if every pair will be compared
if there is a relation.
And now you run the optimization algorithm to find which is the most probable tree you
will generate out of this.
And you're doing this via neural network.
Now we are doing this neural network, yes.
Is it a supervised learning problem?
At the moment, so I would say like the most latest approaches are semi-supervised.
So we do use all the training data from the human annotation, but we also may take advantage
of unstructured data on annotated data.
So this is the, well, everyone uses an object called word embeddings.
So this word representation is trained on a large amount of data.
So the data that we have is about 62 gigabytes of the text.
So 62 gigabytes of text is actually equivalent to so much more if you compare to images.
Because it's only the character in level.
So yeah, and we can actually learn all the, what's the best representation for this word
out of all this text and apply that knowledge into this supervised learning passion?
So that means so then each of the nodes then isn't a symbolic representation of the word
rather it's an embedding that has some semantic space.
Right.
What we call distributional semantics.
Okay.
Distributional semantics, right.
And so this, this corpus that you describe the 62 gigabytes is that your own corpus
or is that like love vectors or something like that?
It's all publicly available.
So the most popular one, the entire Wikipedia is available to everyone.
Amazon wonderfully released all their review, a lot of like 10 years of their review.
Reviews.
We have those.
We have a lot of Twitter data as well.
And there are some medical domain Wikipedia that you can crawl.
Okay.
And so those are also in there too.
Okay.
And also, there is also New York Times corpus from LDC.
So that's actually you have to buy from the organization what we have is so we are also
using it.
Can you describe kind of the algorithm and the way that you're using embeddings and kind
of the network architecture that you're using and how you're training these models to ultimately
produce these graphs?
Right.
And so in the very low level, the generations who are already embedding, they're like so
many different approaches coming out.
It's basically you try to develop a language model.
So for given each all this text, for every word in the text, you are basically trying
to build a model that actually can predict the contextual words.
So you can go the other way too.
Given the contextual word, you can try to predict that word of the target.
So once you develop this kind of language model and you can develop in many different ways.
So the most popular approach called word to bag is just using a very simple feed forward
neural network with just one layer.
But the latest approach that people are using is more complicated as a bidirectional LSTM
kind of approaches, which tends to give better higher accuracy, but it's probably slower.
So given this language model, the language model tells you this word, for this word, this
is the best vector representation of the word.
So now every word will be represented as a vector.
So given that, now we pair, we tokenize every word into sentences.
And for every pair of word in the sentence, you try to see if there is a dependency
relation or not.
And that's the supervised version.
So now we have a large corpus, about 2.5 million words corpus that actually has an annotated
for this kind of dependency relations.
So the end is that the annotation, is it contextual or is it like engram?
It's a contextual.
It's an actual text.
So a lot of the most famous one, what everyone knows in the field of NLP is called Pantry
Bank.
So that's the 1 million words one.
After that, there is another project called Antonut, which is a big one to note.
So it's yeah, ON to ONTO note.
So this is also another project, and it actually has 2.5 million words, so it's a bigger corpus
with much more genre.
So Pantry Bank was only for the new swire, but Antonut's project had a broadcasting conversation,
broadcasting news, telephone conversation, web blogs, and even the Bibles.
So it has much more different kind of genres, these bigger corpus.
And we also internally have some of this annotation on the medical domain as well.
So all this combined together is making a supervised learning.
Okay.
So that's kind of the graph model.
You also mentioned the transition model, which confused me at first because when I think
of graphs, I think of transitions as these variations between the nose, but it sounds
like what that, that's more of like a, I don't know if you'd call it stateful or stateless,
but like you're looking at the current word at the time, as opposed to the entire relationship
between everything and you're trying to.
You've got the exactly right.
Okay.
So graph based algorithm basically doesn't take in each node as an individual state, it
just take a whole holistic view of the entire graph.
The transition based parsing, however, is looking at a word at a time.
So it's making the transition between one word to the other word and try to see if there
are some word, contextual words around it has the dependency relations.
So that's how the transition based parsing works.
And the advantage of transition based parsing is the parsing complexity is much lower.
So we have, many people actually have written several papers about the parsing complexity
on average, can be as low as the big of n.
So basically, if you have n number of words in the sentence, you need to make about n number
of comparisons to be done.
Whereas graph based parsing, you have to make n squared comparisons.
So that's why transition based parsing is tend to be much faster.
But because it's not comparing every possible pairs, it tends to be a little less accurate.
So, but people were buying the speed over accuracy for a long time period.
So I also focused a lot on the transition based parsing in the past because of the efficiency
reason.
But these days, because of this GPU, now comparing n number of things versus n squared,
actually it's not that much different because everything is done in parallel now.
So a graph based parsing, I couldn't even believe, but it actually is performing as fast
as a transition based parsing.
Okay.
And was the transition based parsing also being done with neural networks?
It can be trained on the neural networks.
So transition versus graph is depending on the parsing algorithm.
So it's a different way of processing the text.
And once you define your parsing algorithm, you can use any kind of machine learning algorithms.
So you can use as easy as logistic regression, like one layer, simple or support vector
machines in all days.
But now everyone is moving on to using neural networks to take advantage of the more accurate
deck.
And so that could be the language parsing piece.
And then the, I can't even read my own hand right here, character mining, character
mining.
Yes.
Yes.
Well, it's on usual title too, so yeah.
And so character mining, so you describe this.
If I'm remembering the scenario, like you've got two or multi-parties in a conversation
and you're trying to basically have the machine understand what there is, like a machine
comprehension.
Right.
But it's, it's like a third-party comprehension, you're trying to comprehend a dialogue.
Exactly.
So yeah, I want to, thanks for pointing that out, actually, you understood this correctly.
So I, yeah, I want to distinguish this project versus like a traditional other, what everyone
is going for as a conversation agent that's like a conversation between the agent, the
computer agent and the human, that's not my goal, because I want to have a third-party
agent that's listening to our conversation.
And if we need something that, if you're missing from this conversation, it can actually,
so the best application for this kind of approach is maybe in your business meeting.
So business meeting, you always have a security writing notes for you.
And this conversation, this character mining project can really help to automate the process.
Or like if you had some birthday party with your son last time, and you forgot what kind
of twist you were going to buy for him, then you are pretty embarrassed to ask to your son
about it.
Then you can ask this to assist you.
Right.
So you can see for all your embarrassment as well.
Yeah.
I'm not sure if it's a good application or a bad application, but I'm imagining all kinds
of domestic applications between husbands and wives.
Alexa, you said they were going to buy the milk?
No.
You know, actually Sam, you said you were going to buy the milk, right?
You have a hard proof phrase.
So, I mean, all this privacy issue actually will come out.
So I don't imagine people would like it to be listening to you all the time.
All the time, right?
Well, I mean, like our conversation like the interview like this is a perfect situation.
If the machine is listening to us, if later on, I wouldn't actually make sure if I said
things right, I don't have to bother you, right?
I can just ask the machine too.
The word character there.
What is the character?
Character is people.
Okay.
Character as a people.
So the project actually is rather fun because it's actually my student's favorite project.
Whenever they come to my lab, research lab, they always want to work on this project instead
of some other one because it's a more high level project.
So I started this because I believe conversation data is going to be the key to natural and
gender understanding in the future.
So I have a kind of evidence for this too because how often do you text all the time?
You can even count, right?
But how often do you, so compare to email, right?
Email you probably pretty frequently, but not as much as text, but if you think about
like blogging, even Twitter stream, right?
All these things, what people are focusing on to do the data money, doesn't even come
close to the conversation you're making on the text.
So conversational data, the amount of the conversation data is growing way, way faster
than any other type of data, but natural language processing is one of the genre NLP is missing
so much.
NLP does very well for newswire kind of formal data, or also even like a Twitter kind of social
media data, people have been vaccinated for past 10 years.
So they are doing very well for those domains at the moment, but conversation data is still
hugely lacking.
That's why this Alexa actually, Alexa Price, this kind of challenge is a very challenging
task.
And what's the Alexa Price?
Oh, Alexa Price is, so we're in the, we're in the, the win, or one of the win hotels
and...
What are you looking for?
Okay.
Oh, you guessed it.
Yeah, yeah, yeah.
Stop, let's just stop.
It's not there yet.
So I've just muted it again.
So we're in the, the win hotel, and some folks may remember that a couple of years ago,
I think it may have been here at a reinvent, Amazon and the win hotels announced that they
were putting an Alexa in every hotel room.
Really?
They did.
Yeah.
That's just part of the hotel room.
Oh, actually, you didn't bring this.
No, no, it was a part of the hotel.
It's actually pretty awesome.
Alexa, open the drapes.
Oh my God.
That's pretty cool, isn't it?
Full motivation.
Yeah.
Hotel automation, in this case.
Yeah.
So yeah, Alexa Price is a competition that allows research to show off their research skills
on the conversation agent.
Okay.
So they had a huge competition, and one of my colleagues from Emory actually participated
and they were very close to win the third place.
I think they won the fourth place.
So they were not one of the finalists, but yeah, next year, probably.
And what's the problem, problem formulation of...
The problem formulation is you are supposed to be...
So there are many judges for this competition, and each judges basically talk freely in
open domain.
It's not necessarily even questions.
You're just trying to make a conversation with Alexa.
And if judge feels it actually is in the into the level of the satisfaction, they give
some kind of scores, and they gather all those scores to see who actually has the best
model.
Because it's open-ended, kind of like gymnastics in the Olympics, you're trying to impress
the judges with what Alexa can understand.
Exactly.
Oh, wow.
That's...
And it sounds like it's an ongoing...
It is an...
It's been there for...
I know it's been there at least for two years.
I think it's been...
And I know they are going to do again for sure next year.
The first year was the winner of the competition actually gets $1 million, so it's a serious
deal.
From the faculty point of view, it's not just a prize, but it's also a very intellectually
challenging problem too, so it's very interesting.
Plus, I mean, they actually give out the support for AWS Cloud Computing and also the PhD students.
If you are selected, one of the top-aids teams, so...
You were talking about how we've got all this news.
You know, we have a mature set of practices for applying this type of analysis to news.
We've got kind of these news data sets where much further behind and conversational.
Is it like a chicken and an egg kind of problem?
Like, we don't have the data set because we haven't been working on it as hard and...
And so, I mean, I think it was basically based on the initial interest of the NLP.
So initially, as I mentioned, the Pantry Bank was the largest corpus that we had for a
while.
And it's not anymore, but it's still one of those initial tribank that was...
That allowed us to do any meaningful statistical based natural image processing.
So...
And I think their intention originally was to analyze news data.
So that's why they chose the genre of the news.
If they chose the genre of like conversation data, it would have been probably a good
guarantee to that side.
But I mean, government had their own reasons, right?
So and the tricky part about the conversation data though, would you be willing to give
out your text data to other people?
I was thinking about this as you're describing this like, you know, if, yeah, I'm thinking
about like what kind of incentive system, you know, some app might have to put into place
so that, you know, a user would buy into the idea of using this messaging system knowing
that they were sending all their data someplace.
That's a tough ask.
Yeah, yeah, so I mean, I even tried to ask my own student and I actually even tried to
sign up some kind of form to them that I would not reveal this data to anyone else.
But I mean, there were actually students who were willing to just give to me, but most
of them said no, obviously.
So that was the first barrier we couldn't find a good large amount of data that has a human
conversation.
So the closest data that we found is Twitter, actually coming from the TV shows.
So we got the 10 years of the transcript from the show called Friends, which, so that
show does have some use, exactly, and basically everyone knows that you and they're making
reruns for another 10 years now, right?
So we actually made the effort to make the transcript, it was transcript actually was done
by all the fan-based, but none of them was structured.
So we actually had to spend a year to make the data structurized.
After that, we have a fairly clean data for this script and we particularly liked this
show because this show is not talking a particular thing.
It's just not jargonous.
Exactly.
Life.
Yeah.
For people.
But so that's why we chose this over some other shows.
So even that is involving a lot more like humorous sarcasm.
Right.
So when we talk about it right now, so we don't make so as much humor or sarcasm or all
this metaphors, they intentionally do so much time.
So people think these scripted languages are actually easier to process, but they're
actually harder because of all these reasons.
So anyway, so we have that data now and given the data, the first experiment we ran is,
is it possible to tell like when you talk, when these people are talking to each other,
is it possible to tell who is talking to others or if, say, to one of the character in the
friends and named Ross, his sister is also in the show called Monica and they are Ross
and Monica are talking together and they're talking about their mom and dad.
And their mom and dad actually appears some other episodes.
So we were trying to experiment, is it possible when they talk mom and dad, if the machine
will be able to figure out who that mom actually is?
So like entity disambiguation.
So what we call entity linking.
Entity linking.
Entity disambigation is also right terminology.
So yeah, so basically you have to listen to the entire show, pretty much the entire show,
but usually those people are gonna appear within next few episodes, so you don't have
to search that much, but your search space is still out of like 400 characters, out
of 400 characters, which one of these is mom, Ross's mom, Monica's mom.
So that's the first test we ran, we actually even ran the international, what we call
semi-veils, the semantic evaluation test last year and I think it was well received.
A lot of people get very much interest and I'm still getting a lot of requests from the
people too.
So that was the first test, we need to figure out like who these people are talking about.
So that was the first part of the character mining project.
So second task that we tackled.
And if I can just ask a question about that, you're doing that in a totally model free
way.
It's all happening with kind of a flat algorithm as opposed to pre-processing to identify
people and then remembering the people that are talked about and kind of linking.
It's not bad, it's like just running, you know, kind of training a neural network on
this.
So having the neural network, you send in a sentence and having the neural network point
you to the sentence that refers back to the people that you're talking about.
It could be so.
For example.
For example.
Exactly.
So you sent it different from traditional entity linking task which is also known as
a wikipication.
So wikipication is another entity linking task, much more well-known, which is given
like a name, like Lincoln, you find a wikipedia page for that link.
So you have to do some disambigation as well.
Lincoln can be a link on hall or a link on bridge or actually every link.
Yeah.
So so many different links, right?
So that, but those task has significant advantage that all those entities are already
well-known.
So you already have some good knowledge base established for this entities.
But for this show, we don't have any of these knowledge.
We are not assuming any of these knowledge base, basically the machine has to listen
to these conversations and figure out if there's a link between these mentions.
So it's a much more challenging task as in sense, yeah.
And so you talked about another couple of projects, the kind of what I have is what I got
out of that was like interpreting structure and kind of semi-structured reports, like
medical reports.
Oh, yeah.
Yes.
And another one, which is a really interesting application of identifying the early indicators
of cognitive impairment through speech.
But as we're kind of coming up on the end of our time here, I did want to ask you about
one of the presentations you gave here at re-event about this NLP platform that you built.
What is the NLP platform that you built?
So this is a project called Elite ELIT.
So it's short for evolution of language and information technology.
We call this evolution because I think the way that people are doing language technology
has to be evolved into the modern computing technology.
So what I mean by that also is all these natural language processing models lately, as I said,
are making heavy use of deep learning.
Deep learning is a neural network with multiple layers and it requires a lot of computations.
Because of this, to run, to train or decode any of the state of our models, you really
need to have a very high computing GPU power.
All days, when I was actually my PhD dissertation was purely focused on the efficiency of NLP
models, how to make the model as small as possible while not losing accuracy.
So you can actually run on your laptop.
So all my models were able to, you could run on your laptop, as long as you have like
a three gigabyte sub-ramp.
But now, because after all this neural network error, it's almost impossible to run this
into your local machines. So a lot of researchers are having difficulties of making use of this
technology.
And when we're talking about the size, are we talking about training or inference?
Both.
Okay.
So for both training and inference, you do need a GPU to run this neural network models.
At least if you want to run the state of the art models, not the simple toy models,
but really good models.
And in all days, before neural network with the linear models, it was still possible
to optimize those models to make it very small.
So without losing so much accuracy, so you could just run any researchers like linguist
or historian, they could just run on their laptops.
So these people still want to take advantage of all these latest technology that we are
developing, which are tons and tons.
But now it's literally impossible for anybody who doesn't have these high computing machines
to run this kind of models.
So there is a solution for it, which we found a solution from a cloud computing.
So the platform, the elite platform that we are developing is a SaaS architecture.
So we are bringing all our natural language processing models to the cloud.
So anybody in the world can actually call this as a web API.
Just like the way you use Google search, you can just send your text and it will send
you back your NLP result with a simple HTTP call.
And so is this a generic platform that you can then plug in these different projects
as the types, the calls that you would make and you would get back?
And so what I just described about web API in SaaS environment, that was the original
intention for our lab.
So because we actually started having so much needs of running this NLP models.
So we actually developed the SaaS architecture for ourselves first.
So my students can actually just use that without installing anything on their local machines.
But we tried to bring that up to the cloud so everyone in the world can actually use it.
And thanks to AWS, who has been supporting us for making this happen.
But now the intention actually became much more interesting.
So the motivation at the moment now is we want to invite all NLP community, people to
contribute their models to this cloud.
So this is actually huge because how many papers do you think are getting published every
year to like top three conferences?
NLP or NLP, like top three conferences in LLP.
Gosh, how many papers a year to the top three conferences in NLP, 2,500?
It's still 1,000.
All right.
Yeah.
I didn't do the count.
But even the workshop papers and all NLP, I would imagine like a 5,000 of those.
So in every single paper, basically claims they have the best model of some sort, right?
Otherwise, you wouldn't be published.
So every paper has developed some kind of model that has some value.
How many of them are actually getting used, right, less than few percent?
So why is that though?
These PhD students are spending at least five years of their life dedicated to develop
these models and after they graduate, nobody uses it.
So I think this is a issue and it's a very depressing issue to me at least because I want
all like the models that we develop are has to be getting used in some sense, but it's
not getting used at all, right?
So it strikes me that some of that issue is accessibility and cloud and platforms dress
that.
But if there's also the assumptions that the model makes, a lot of them are rather limiting
for actual use.
Excellent.
That's an excellent point.
That's what I want to actually open up the free platform for people to actually show
off your model actually works well.
Right?
So yes, you have proof that your model has value in your paper in this sense, but does
it actually do the right thing for real application or your application?
So if the developers or the researchers truly believe their model has value, they can deploy
their model to our platform and anybody in the world can test it out.
And see, okay, this model actually does work really well, then it gets promoted.
So we will actually have to show the ranking of the usage of the models as well.
So anybody in the world can actually see, okay, this model does well for this kind of
event.
And we can actually include to the discussion forum to see, okay, this model didn't do
well for this genre, but this genre it did exceptionally well.
So users can actually write their reviews about this.
It's like that's what the technology should be, right?
When you have a new phone, when you have new technology, there's so many reviewers write
the reviews about it.
But our in academic world, what happens is you saw me on paper, the paper gets reviewed
by three reviewers and that was it later on people forget about it.
But actual usage can be now reviewed by people.
So this is I think a very exciting part, also another part that I really want to focus
on is I believe there are a lot of models that are really good, but are not getting published
for some reason.
So for many different reasons, we all know this, sometimes this review system doesn't work
on some others.
So and also another thing is somebody actually is not really intended to invent some algorithm,
but they replicate someone else's work, but happen to have a better performance.
And the academic conferences don't allow you to really write papers about this, replicating
someone else's work.
There are some venues, but usually it's not as valued.
But now these people can actually deploy all their models to our platform, then they
can actually show, okay, so I use the same algorithm, but my model actually works more
efficiently or better in some sense, so please take a try out and see if it actually works
well.
So you have to open the door to the developers and researchers to show off how well of engineering
or like researchers they have done and prove it to the world from the practical point of
view.
How does a researcher format their model to submit it to your platform?
Right.
So I tried so many different ways, I have an NLP platform called, it used to be called
clear NLP, now it's called NLP4J.
So this platform has been used quite a bit by industry and academics.
So I used to get at least 500 downloads every month about this software.
So it was a huge project.
The lesson I learned from that is you should not force developers to write their code
into some kind of architecture.
They are not going to fall.
They have their own architecture already, and they are not going to follow whatever you
think is the best for them, right?
So I'm going to give complete freedom to develop.
You can write your model in any way you want.
The only thing that I want to standardize is the IO format.
Input and output format, which in natural and its processing is pretty standard.
The input is text, right?
Output is some kind of generated labels that you have.
So basically, we are putting, given the input text, you are actually generating a dictionary
that has a label of your task.
So once that part is standardized, then all these models can actually even work together.
So this is another unique part about our platform, or rather about natural and its processing.
A lot of models need to work together.
They're not working independently.
So this is a very unique thing, and because of this, if you actually standardize their
IO format, they can actually take advantage of all the other models and extract features
from those models to make even better models.
So I think from the research and user point of view, they can choose any of the models
that deploy to the platform, and you can actually try out which one works better for you.
And the best thing is you don't even have to install anything on your machine.
So you can just call it out from the web and get all the results.
So is the developer, the researcher, are they zipping up a Python folder, or whatever?
Are they zipping something up, and maybe some kind of JSON to tell you where they need
to get their IO, or is it containers, or what's the actual format of the algorithms
that they're submitting?
Right. So we have released SDK, as of yesterday.
So we have SDK for Python.
Oh, you did a big launch here at EOS.
Well, we didn't make an official announcement, but the packages are on the release now.
People can use it.
They don't know where the link is probably.
So as soon as I go back to Atlanta, I'm going to actually try to make a big announcement
about this.
But yeah, so we have SDK that provides you abstract classes, basically.
So as a matter of fact, there's only one abstract class with four abstract functions.
And that's all we're asking you to overwrite.
So you can completely independently develop your model.
Sounds very job-ish.
Yeah.
I'm coming from object-oriented programming background, so it's not really Python-like, but I get
that.
Well, yeah, so we have an environment developed for both Python and Java.
So if you are a Java programmer, you can just submit.
And that was also another great thing about cloud computing, right?
So now these models that's written in either Python or Java can work together, because
it will be connected by the network and communicating between the AWS instances is really fast.
Right.
Do you have a web page for it yet?
Yes.
The project is called at least in the web page is elite.cloud.
Oh, nice.
So E-L-I-T.cloud.
All right.
Sounds interesting.
Well, thank you so much for taking the time to chat with me about what you're up to.
It was a really interesting stuff.
Thank you very much.
And yeah, time flies.
It was very exciting.
Yeah.
Thank you.
Yeah.
I had a lot of fun.
Thank you.
All right, everyone, that's our show for today.
For more information on Geno or any of the topics covered in this episode, visit twomolei.com
slash talk slash 206.
As always, thanks so much for listening and catch you next time.
