1
00:00:00,000 --> 00:00:15,920
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:15,920 --> 00:00:20,880
people doing interesting things in machine learning and artificial intelligence.

3
00:00:20,880 --> 00:00:23,240
I'm your host Sam Charrington.

4
00:00:23,240 --> 00:00:28,440
I'd like to start off this show by sending out a huge thank you to everyone listening.

5
00:00:28,440 --> 00:00:32,800
We've dropped a ton of great interviews over the past few weeks and through your dedication

6
00:00:32,800 --> 00:00:39,040
we continue to see a growing outpouring of feedback comments and shares with each release.

7
00:00:39,040 --> 00:00:43,580
If you're a regular listener but don't normally send in feedback we'd really love to hear

8
00:00:43,580 --> 00:00:44,580
from you.

9
00:00:44,580 --> 00:00:50,520
So please head on over to Apple Podcasts or wherever you listen and leave us a review.

10
00:00:50,520 --> 00:00:55,760
A 5 star review is of course appreciated but what's most important is that your voice

11
00:00:55,760 --> 00:00:56,960
is heard.

12
00:00:56,960 --> 00:01:01,800
It lets us know what you like or what you feel we can improve on and it also lets those

13
00:01:01,800 --> 00:01:06,880
looking for a new machine learning and AI podcast know that they should join the Twimble

14
00:01:06,880 --> 00:01:09,120
community.

15
00:01:09,120 --> 00:01:15,040
Speaking of community, the details of our next Twimble online meetup have been posted.

16
00:01:15,040 --> 00:01:22,440
On Tuesday November 14th at 3pm Pacific time, we'll be joined by Kevin T who will be presenting

17
00:01:22,440 --> 00:01:28,120
his paper, active preference learning for personalized portfolio construction.

18
00:01:28,120 --> 00:01:32,000
If you've already registered for the meetup, you should have received an invitation

19
00:01:32,000 --> 00:01:33,960
with all the details.

20
00:01:33,960 --> 00:01:39,840
If you still need to register, head on over to twimbleai.com slash meetup to do so.

21
00:01:39,840 --> 00:01:41,480
We hope to see you there.

22
00:01:41,480 --> 00:01:45,800
Now as some of you may know, we spent a few days last week in New York City hosted by

23
00:01:45,800 --> 00:01:49,120
our great friends at NYU Future Labs.

24
00:01:49,120 --> 00:01:53,920
About six months ago, we covered their inaugural AI Summit, an event they hosted to showcase

25
00:01:53,920 --> 00:01:58,960
the startups in the first batch of their AI Nexus Lab program, as well as the impressive

26
00:01:58,960 --> 00:02:02,040
AI talent in the New York City ecosystem.

27
00:02:02,040 --> 00:02:06,160
While we were more than excited when we found out they would be having a second summit

28
00:02:06,160 --> 00:02:11,360
so soon, this time we had the pleasure of interviewing the four startups of the second

29
00:02:11,360 --> 00:02:19,080
AI Nexus Lab batch, Mount Clevverist, Bite.ai, Second Mind, and Bowtie Labs.

30
00:02:19,080 --> 00:02:23,800
We also interviewed a bunch of the speakers from the event and will be sharing those discussions

31
00:02:23,800 --> 00:02:25,880
over the upcoming weeks.

32
00:02:25,880 --> 00:02:31,280
In this show, I speak with Cool Singh, CEO and founder of Second Mind.

33
00:02:31,280 --> 00:02:36,200
Second Mind is building an integration platform for businesses that allows them to bring augmented

34
00:02:36,200 --> 00:02:39,000
intelligence to voice conversations.

35
00:02:39,000 --> 00:02:43,520
We talked to Cool about the concept behind Second Mind and how the company combines ambient

36
00:02:43,520 --> 00:02:48,440
listening with a low latency matching system to help users eliminate an estimated two

37
00:02:48,440 --> 00:02:53,640
and a half hours of manual searches per day, and now on to the show.

38
00:02:53,640 --> 00:03:07,920
All right, everyone, I am here at NYU Future Labs, speaking with some of the AI Nexus startups,

39
00:03:07,920 --> 00:03:13,480
and I am with Cool Singh right now, founder and CEO of Second Mind.

40
00:03:13,480 --> 00:03:16,080
Cool, welcome to this week in Machine Learning and AI.

41
00:03:16,080 --> 00:03:17,080
Thank you.

42
00:03:17,080 --> 00:03:18,080
It's a great time.

43
00:03:18,080 --> 00:03:20,840
How do we get started by having you tell me a little bit about your background?

44
00:03:20,840 --> 00:03:21,840
Sure.

45
00:03:21,840 --> 00:03:29,480
I came to New York as a derivatives trader, and so I was doing what was considered now

46
00:03:29,480 --> 00:03:31,480
with considered AI back then.

47
00:03:31,480 --> 00:03:37,320
We were doing AI's effectively expected value, and we were doing very intensive Monte Carlos

48
00:03:37,320 --> 00:03:42,480
simulations and doing from mortgage derivatives and other structured type products.

49
00:03:42,480 --> 00:03:46,760
So that was where I started, and then I took doing that and building the systems that

50
00:03:46,760 --> 00:03:50,080
I was on the trading side, but building the systems on that, I got an interest in technology,

51
00:03:50,080 --> 00:03:55,080
and I started two companies that were in the low latency side of it.

52
00:03:55,080 --> 00:04:00,920
So two technology companies, and basically one company is actually still operational with

53
00:04:00,920 --> 00:04:05,560
the product still being adopted across many enterprises, Fortune 100 companies, and I have

54
00:04:05,560 --> 00:04:09,320
two patents in terms of low latency systems.

55
00:04:09,320 --> 00:04:14,440
And then I actually started a lab with a team in Ukraine and Eastern Europe that was focused

56
00:04:14,440 --> 00:04:15,440
on NLP and AI.

57
00:04:15,440 --> 00:04:21,720
That sort of built back, and it's early in terms of NLP, but they've been doing it for

58
00:04:21,720 --> 00:04:24,760
a while, but built early shop bots around travel and some other things.

59
00:04:24,760 --> 00:04:28,720
So I've been doing this for a while, and then I started having an interest in an idea

60
00:04:28,720 --> 00:04:31,880
around this particular company's second mind.

61
00:04:31,880 --> 00:04:33,680
And so what does second mind do?

62
00:04:33,680 --> 00:04:41,280
So basically we're looking to solve the time that you're spending on search.

63
00:04:41,280 --> 00:04:47,600
And basically we sort of accept the fact that we have to find information, and we do have

64
00:04:47,600 --> 00:04:50,240
search engines now, and we accept that's great.

65
00:04:50,240 --> 00:04:55,040
But the fact is we're now spending about two and a half hours out of our day on average

66
00:04:55,040 --> 00:04:56,040
searching for information.

67
00:04:56,040 --> 00:04:57,040
That's 30%.

68
00:04:57,040 --> 00:04:58,040
Okay.

69
00:04:58,040 --> 00:05:01,040
If I told you you're stuck in traffic for two and a half hours a day, you're like, okay,

70
00:05:01,040 --> 00:05:02,040
I have to fix my life.

71
00:05:02,040 --> 00:05:03,040
But this is what we're doing.

72
00:05:03,040 --> 00:05:07,960
This is in 2016, the type of data, so it's not like this is getting worse, the problem.

73
00:05:07,960 --> 00:05:13,040
I mean, just as you say that, I reject that notion, but it sounds about right.

74
00:05:13,040 --> 00:05:14,040
Yeah.

75
00:05:14,040 --> 00:05:17,960
I mean, you have to think of it as simple as saying, are you available for lunch next

76
00:05:17,960 --> 00:05:18,960
week?

77
00:05:18,960 --> 00:05:20,280
You're searching for your calendar.

78
00:05:20,280 --> 00:05:21,800
Where should we go for lunch?

79
00:05:21,800 --> 00:05:24,360
You're searching for restaurants or whatever it may be.

80
00:05:24,360 --> 00:05:30,160
It could be for information like from your CRM or for if you're in the trading world for

81
00:05:30,160 --> 00:05:31,160
market data.

82
00:05:31,160 --> 00:05:33,480
So you're constantly looking for information.

83
00:05:33,480 --> 00:05:36,520
And the fact is we also don't know what we don't know.

84
00:05:36,520 --> 00:05:38,560
So that problem takes time.

85
00:05:38,560 --> 00:05:44,160
So that whole situation creates this situation where we're constantly looking and searching

86
00:05:44,160 --> 00:05:47,600
for data, people are overwhelmed in that thing.

87
00:05:47,600 --> 00:05:50,680
And we've heard this information overload, but this is actually a slightly different

88
00:05:50,680 --> 00:05:55,040
thing where yes, we have so much data in so many different places and to manage it and

89
00:05:55,040 --> 00:05:56,040
so forth.

90
00:05:56,040 --> 00:05:58,520
We have search engines, but that's still not working.

91
00:05:58,520 --> 00:06:03,360
So what we're looking to do is say, hey, can we solve that problem specific to conversations?

92
00:06:03,360 --> 00:06:04,360
Okay.

93
00:06:04,360 --> 00:06:09,600
The fact is the impetus for many of our searches are driven by a conversation, just as I gave

94
00:06:09,600 --> 00:06:10,920
examples for.

95
00:06:10,920 --> 00:06:12,760
So clients are saying, can you have that information?

96
00:06:12,760 --> 00:06:17,560
And the fact is when you're on a call or an in-person conversation like we are now and

97
00:06:17,560 --> 00:06:22,280
someone asked for that, you're either having the multi-task, which is obviously stressful,

98
00:06:22,280 --> 00:06:24,600
or you're saying I have to get back to you later on that.

99
00:06:24,600 --> 00:06:28,280
And what's worse when you have a client here to say I have to get back to you, someone

100
00:06:28,280 --> 00:06:30,400
else is going to close that business.

101
00:06:30,400 --> 00:06:36,080
So from a business standpoint, this is a very costly problem because they're spending,

102
00:06:36,080 --> 00:06:42,480
not only the money to employees, it works out from an $80,000 every side, about $14,000

103
00:06:42,480 --> 00:06:44,800
annually that's just gone and wasted.

104
00:06:44,800 --> 00:06:47,400
And on top of that, you're using those two hours a day of searching?

105
00:06:47,400 --> 00:06:48,400
Exactly, that type.

106
00:06:48,400 --> 00:06:52,920
And then you're also losing the opportunity cost in terms of the revenue of not closing

107
00:06:52,920 --> 00:06:55,240
the clients when you have that information, right?

108
00:06:55,240 --> 00:06:59,080
So that's the problem we're looking to solve and so what we basically have developed is

109
00:06:59,080 --> 00:07:01,080
you can think of this matching engine.

110
00:07:01,080 --> 00:07:04,760
I'm sort of using a Wall Street prerogative here, but basically, you can think of like

111
00:07:04,760 --> 00:07:09,840
it for it because an exchange would do for stocks, matching buyers and sellers, what we're

112
00:07:09,840 --> 00:07:16,000
doing is identifying the events in a conversation and mapping it to any data, whether it's internal

113
00:07:16,000 --> 00:07:19,440
or external, and pushing it to people in real time.

114
00:07:19,440 --> 00:07:24,480
And so that can be information from your CRM, from your market data, from say a Bloomberg

115
00:07:24,480 --> 00:07:28,640
or Reuters, it can be from your email or files.

116
00:07:28,640 --> 00:07:32,400
But someone says, you know, as you get that file, I said, it shows up right away.

117
00:07:32,400 --> 00:07:34,480
You know, you don't have to sit there and fidget.

118
00:07:34,480 --> 00:07:36,320
This is a typing part takes time.

119
00:07:36,320 --> 00:07:37,320
Right.

120
00:07:37,320 --> 00:07:38,320
So that's sort of the thing.

121
00:07:38,320 --> 00:07:40,560
And the way you can think of the product, it's sort of like, you can think of like a

122
00:07:40,560 --> 00:07:45,640
slack for conversation or the glue to provide all those applications that people can

123
00:07:45,640 --> 00:07:51,080
developers and companies can tie in and it's as a feed as you're speaking.

124
00:07:51,080 --> 00:07:56,800
And you're using conversation and speaking as the way you describe these interactions,

125
00:07:56,800 --> 00:08:02,400
but then you reference slack, is it primarily for textual communications or are we literally

126
00:08:02,400 --> 00:08:03,400
talking about speaking?

127
00:08:03,400 --> 00:08:04,400
Yeah.

128
00:08:04,400 --> 00:08:05,880
So our focus is around voice competition.

129
00:08:05,880 --> 00:08:07,400
That's sort of where RIP is.

130
00:08:07,400 --> 00:08:08,400
Sorry.

131
00:08:08,400 --> 00:08:12,440
And we can do regular conversation, text and chat conversations as well.

132
00:08:12,440 --> 00:08:16,880
Will we see the real opportunity and the unique differentiations around voice conversations?

133
00:08:16,880 --> 00:08:17,880
Yeah.

134
00:08:17,880 --> 00:08:22,880
I mean, when I think of the, you know, the way we've envisioned some of these interactions

135
00:08:22,880 --> 00:08:29,240
like from a sci-fi perspective and kind of this notion of the augmented human, right?

136
00:08:29,240 --> 00:08:33,640
Like it's like you want something that's kind of passively listening to all these interactions

137
00:08:33,640 --> 00:08:39,160
that you are having and then just making you smarter by popping that email up or, oh,

138
00:08:39,160 --> 00:08:42,920
you just mentioned lunch, you know, here with three places that, you know, fit the profile

139
00:08:42,920 --> 00:08:47,840
of the kind of place you like to go to without having to pull out the phone and the keyboard

140
00:08:47,840 --> 00:08:49,320
and all that kind of stuff.

141
00:08:49,320 --> 00:08:50,320
Exactly.

142
00:08:50,320 --> 00:08:54,960
It's a big vision we have, it's around the AR side and you sort of where people can be

143
00:08:54,960 --> 00:08:58,480
effectively Jarvis and Iron Man where you can show that.

144
00:08:58,480 --> 00:09:02,680
And so, I mean, that's not that far afresh from our standpoint because it's just a screen

145
00:09:02,680 --> 00:09:03,680
from our standpoint.

146
00:09:03,680 --> 00:09:08,280
We can display that information on any screen and basically it's just what we're providing

147
00:09:08,280 --> 00:09:12,640
is a low latency matching system to provide that data and any screen so that it can be

148
00:09:12,640 --> 00:09:15,640
that phone, your mobile phone, it can be on the desktop.

149
00:09:15,640 --> 00:09:19,040
If we can connect with the enterprise voice, it can be a video calls or it can be in an

150
00:09:19,040 --> 00:09:20,040
AR.

151
00:09:20,040 --> 00:09:26,640
And so, do you end up taking a position on kind of the pervasive listening aspect of

152
00:09:26,640 --> 00:09:27,640
that or?

153
00:09:27,640 --> 00:09:28,640
That's a great question.

154
00:09:28,640 --> 00:09:34,720
So, one of the unique IP aspects of our product is that we don't need to record conversations

155
00:09:34,720 --> 00:09:35,840
optionally we can.

156
00:09:35,840 --> 00:09:42,880
So, a lot of the companies that sort of are in the voice type space are recording data.

157
00:09:42,880 --> 00:09:47,080
What we've really, again, goes back to sort of my background with sort of like in line

158
00:09:47,080 --> 00:09:51,560
streaming of this data, throw it a process and throw it away, in fact, we are core data

159
00:09:51,560 --> 00:09:55,040
that we're capturing as a metadata of the mapping engine of the maps.

160
00:09:55,040 --> 00:09:57,240
That's where we're really focused on.

161
00:09:57,240 --> 00:10:02,600
So, we basically are looking to process in line, everything's in memory, we're not, you

162
00:10:02,600 --> 00:10:05,320
know, that's sort of, so, you know, where a lot of the companies are saying, hey, we're

163
00:10:05,320 --> 00:10:09,840
building on this unique part of the components and so forth, where our unique things that we're

164
00:10:09,840 --> 00:10:15,240
doing is focused on the real time low latency on the front end, not on the training side

165
00:10:15,240 --> 00:10:19,320
so much, but on the front end where very few companies are basically, we have, like, you

166
00:10:19,320 --> 00:10:22,800
can think of it like, again, the best way to think of is like a high-frequency training

167
00:10:22,800 --> 00:10:28,160
system or like what you see on Wall Street where you're processing trades very, very fast

168
00:10:28,160 --> 00:10:32,320
and we're looking at cashing that data very fast and processing and mapping it very fast

169
00:10:32,320 --> 00:10:33,320
to that conversation.

170
00:10:33,320 --> 00:10:39,200
So, that's really where the unique sauce comes in and so we don't need to record the

171
00:10:39,200 --> 00:10:44,880
conversation and start analyzing it, capturing the events and we will store the events so

172
00:10:44,880 --> 00:10:48,600
that could be like data that could be saved in the CRM or so forth or summering, but

173
00:10:48,600 --> 00:10:51,480
it's not necessarily the actual conversation.

174
00:10:51,480 --> 00:10:52,480
Okay.

175
00:10:52,480 --> 00:11:00,640
So, I get that you're not required to record the data in order to do the things that

176
00:11:00,640 --> 00:11:05,360
you're trying to do, but a lot of companies, you know, aren't recording data because they

177
00:11:05,360 --> 00:11:10,120
need to to deliver their service to recording the data because they use it to train and

178
00:11:10,120 --> 00:11:12,200
make their algorithm smarter.

179
00:11:12,200 --> 00:11:15,800
So, you know, kind of flipping it on the other side, you know, if you're taking a hard

180
00:11:15,800 --> 00:11:18,280
position, it says we're not going to record any data.

181
00:11:18,280 --> 00:11:21,640
Do you miss an opportunity to produce better product?

182
00:11:21,640 --> 00:11:22,640
That way.

183
00:11:22,640 --> 00:11:29,280
It's not, so to make it clear, there's the recording of the audio, which we're not focused

184
00:11:29,280 --> 00:11:30,280
on.

185
00:11:30,280 --> 00:11:36,000
Where we are focused on is we are storing the metadata, which is the mapping piece that

186
00:11:36,000 --> 00:11:39,360
we are maintaining and that we do need to know.

187
00:11:39,360 --> 00:11:44,720
So, basically, for that standpoint, we can then see where our engine is getting false

188
00:11:44,720 --> 00:11:46,680
negatives, false positives, and so forth.

189
00:11:46,680 --> 00:11:51,000
So, we're seeing and we can see where we are mapping the right data or the wrong data

190
00:11:51,000 --> 00:11:52,000
so forth.

191
00:11:52,000 --> 00:11:55,880
So, that's for us, I mean, that's why, you know, using this analogy of where real-time

192
00:11:55,880 --> 00:11:57,720
mapping engine or matching engine.

193
00:11:57,720 --> 00:11:58,720
Let's use the analogy.

194
00:11:58,720 --> 00:12:02,680
If you go to whatever you might use for an online trading system and you go, I want

195
00:12:02,680 --> 00:12:07,400
to buy Apple and it gets you Google, you're not going to be happy with it, right?

196
00:12:07,400 --> 00:12:14,000
So, that's what we are looking to ensure we don't do that, but it's different than recording

197
00:12:14,000 --> 00:12:19,840
someone's conversations, storing those conversations, where a lot of the companies are focusing

198
00:12:19,840 --> 00:12:24,440
on analytics and storing that, which then becomes, it's actually just a legal aspect to

199
00:12:24,440 --> 00:12:25,440
it.

200
00:12:25,440 --> 00:12:29,000
You have to tell people this conversation is being recorded and monitored, that's a law

201
00:12:29,000 --> 00:12:30,880
across the most states.

202
00:12:30,880 --> 00:12:35,120
Because we are not recording or monitoring those conversations, it's just being analyzed

203
00:12:35,120 --> 00:12:39,000
and, you know, inline and done away effectively.

204
00:12:39,000 --> 00:12:42,240
We don't need to even say that in that standpoint.

205
00:12:42,240 --> 00:12:49,200
You take in the voice and then you are you converting that to text and then your metadata

206
00:12:49,200 --> 00:12:53,160
is based on a text transcription of what the person said.

207
00:12:53,160 --> 00:12:57,960
So, they were identifying keyword to key phrases and then when we were building, so basically

208
00:12:57,960 --> 00:13:00,760
our chief scientist had written some papers on this.

209
00:13:00,760 --> 00:13:06,240
He was most recently a professor at Institute of Budapest, where he wrote some papers around

210
00:13:06,240 --> 00:13:10,840
the concept of attribute variable matrices and doing it in real time.

211
00:13:10,840 --> 00:13:17,000
So basically the idea would be in a conversation, it's not always a linear process of finding

212
00:13:17,000 --> 00:13:22,240
and achieving it when an event is achieved, so when I say an event means, when an event

213
00:13:22,240 --> 00:13:23,240
is triggered.

214
00:13:23,240 --> 00:13:24,240
Okay?

215
00:13:24,240 --> 00:13:29,600
So, if you think about it, if I say, if I go to buy a train ticket and I say, okay, I

216
00:13:29,600 --> 00:13:33,840
want to buy a train ticket, okay, I can't buy the ticket yet, the person asked me, where

217
00:13:33,840 --> 00:13:40,080
are you going and what date, what time, now I can start maybe by the train ticket, that

218
00:13:40,080 --> 00:13:43,480
the trigger is now finally, it gets me how many people and so forth, right?

219
00:13:43,480 --> 00:13:49,600
So in the same way, we are doing the same thing where we basically set up this matrices

220
00:13:49,600 --> 00:13:55,600
which says, okay, let's identify from the text, we can start filling out that matrices

221
00:13:55,600 --> 00:13:57,360
and is there an event trigger?

222
00:13:57,360 --> 00:14:01,400
If one set event gets triggered, it could be one keyword, it could be a bunch of keywords

223
00:14:01,400 --> 00:14:02,400
that we need to hear.

224
00:14:02,400 --> 00:14:06,840
So for example, it could be on a trading floor, it could be how many shares traded, that

225
00:14:06,840 --> 00:14:12,520
you can't maybe trigger there, but if someone said, what do you think of IBM, and then

226
00:14:12,520 --> 00:14:17,080
said, how many shares traded, or now we know for IBM, right?

227
00:14:17,080 --> 00:14:21,280
Or someone says, how many shares of IBM traded, we can then find that.

228
00:14:21,280 --> 00:14:26,880
So in that vein, we don't need to record the audio or save the text, we just need to

229
00:14:26,880 --> 00:14:31,760
capture the fact that someone wants to know how many shares and what stuff, and we can

230
00:14:31,760 --> 00:14:36,280
capture in any order, and then when it's triggered, we map it to the data that we know

231
00:14:36,280 --> 00:14:38,200
where to find it.

232
00:14:38,200 --> 00:14:45,720
So I guess the personal assistant type of use case that we discussed is kind of a clear

233
00:14:45,720 --> 00:14:46,720
one.

234
00:14:46,720 --> 00:14:52,800
Are there other use cases, or what's the initial target customer and use case that you're

235
00:14:52,800 --> 00:14:53,800
going after for this?

236
00:14:53,800 --> 00:14:59,640
So probably as I said before, there is that knowledge worker in general that we use that.

237
00:14:59,640 --> 00:15:04,760
We're seeing interests from the financial services vertical, financial advisors, traders,

238
00:15:04,760 --> 00:15:10,840
where there's a need for having that information, salespeople having to get information, close

239
00:15:10,840 --> 00:15:16,240
that sale, and having that data for managing that information, and so forth, obviously.

240
00:15:16,240 --> 00:15:21,360
But any market, maybe think about a real estate agent, someone's calling up, but they can't

241
00:15:21,360 --> 00:15:24,200
manage all the properties in the MLS listings, right?

242
00:15:24,200 --> 00:15:29,040
So someone says, what properties available in the West Village here in New York, they're

243
00:15:29,040 --> 00:15:30,040
not going to know.

244
00:15:30,040 --> 00:15:34,360
So we could push intelligently what those properties are based on some criteria that

245
00:15:34,360 --> 00:15:35,520
person says.

246
00:15:35,520 --> 00:15:38,920
You can now deliver that information intelligently.

247
00:15:38,920 --> 00:15:42,080
One area we're seeing, we're sort of working with a data provider and exploring these

248
00:15:42,080 --> 00:15:43,080
around attorneys.

249
00:15:43,080 --> 00:15:46,400
They're on the phone all the time, they're in conversation all the time, and they're constantly

250
00:15:46,400 --> 00:15:52,360
trying to get information on precedents and other legal facts that require so much search

251
00:15:52,360 --> 00:15:53,360
and data.

252
00:15:53,360 --> 00:15:56,840
So the more we can push that to the person as they're having the conversation, when now

253
00:15:56,840 --> 00:16:00,640
you don't have to have that asynchronous process of, let me get back to you and let's set

254
00:16:00,640 --> 00:16:01,640
up another call.

255
00:16:01,640 --> 00:16:06,880
Let me think about the time it takes to set up another call, get on the call, the process

256
00:16:06,880 --> 00:16:12,400
of a few minutes of talking, okay, chat, chat, chat, okay, now let's get to it.

257
00:16:12,400 --> 00:16:16,120
Then, oh, I don't know that answer, let me write that down, get back to you.

258
00:16:16,120 --> 00:16:20,920
And that constant process, we are trying to streamline that where you can now take maybe

259
00:16:20,920 --> 00:16:24,720
two, three, four calls and you can make it into one, maybe two.

260
00:16:24,720 --> 00:16:29,600
But you're basically now significantly reducing the amount of time that people need to be

261
00:16:29,600 --> 00:16:35,600
on those calls and searching, and you're basically making people, you know, much more efficient

262
00:16:35,600 --> 00:16:41,400
productive, and as you sort of said, hopefully a little, a dream of being a super intelligent

263
00:16:41,400 --> 00:16:43,320
or smarter than otherwise.

264
00:16:43,320 --> 00:16:46,320
So we've talked a little bit about the front end of this process.

265
00:16:46,320 --> 00:16:52,320
How are you handling the kind of knowledge, retrieval aspect of it on the back end?

266
00:16:52,320 --> 00:16:57,760
It strikes me that there are a number of interesting challenges there that you'd have to overcome.

267
00:16:57,760 --> 00:17:04,760
So the first thing we're doing is in terms of our core product, we are offering it to,

268
00:17:04,760 --> 00:17:09,960
you know, we're initially focused on enterprises, and we're offering that as a virtual machine.

269
00:17:09,960 --> 00:17:16,440
And we offer, again, this goes back to some of the IP and technology I had built in a previous

270
00:17:16,440 --> 00:17:21,200
companies, which is sort of like a very much of a published subscribe real-time architecture.

271
00:17:21,200 --> 00:17:24,440
So that's just, I'm sort of, you know, one of the things I've always loved about building

272
00:17:24,440 --> 00:17:30,080
companies is you sort of, you find the, the sort of the gap between two areas, and you

273
00:17:30,080 --> 00:17:34,320
sort of focus on there, because if you focus on, on just a machine learning and so forth,

274
00:17:34,320 --> 00:17:38,000
you obviously have very big players that have a lot of expertise, and you focus on, say,

275
00:17:38,000 --> 00:17:41,880
publish, subscribe in real-time, where you have TIPCO and IBM that are very big players

276
00:17:41,880 --> 00:17:42,880
in there.

277
00:17:42,880 --> 00:17:46,160
But you get in the gaps, you can sort of build a very exciting company that's sort of in

278
00:17:46,160 --> 00:17:47,160
the wedge.

279
00:17:47,160 --> 00:17:50,720
So we're building sort of like a wedge company that's in between those markets, which is

280
00:17:50,720 --> 00:17:55,240
saying, hey, we're building a published, scribe, event-based technology that's using machine

281
00:17:55,240 --> 00:17:58,520
learning, and a lot of the capabilities around there.

282
00:17:58,520 --> 00:18:04,720
And what we're doing there is to, we're leveraging what we call, like a high-performance caching

283
00:18:04,720 --> 00:18:11,120
engine, where companies can open data sockets from any database or technology system to

284
00:18:11,120 --> 00:18:17,560
our product, and we're basically have both an in-memory cache as well as a cache that

285
00:18:17,560 --> 00:18:21,600
could sit in storage basically that based companies would be able to access data in real

286
00:18:21,600 --> 00:18:24,280
time, and we'd be able to show it in the feed.

287
00:18:24,280 --> 00:18:27,900
So it's not a major integration process, and basically, it's just opening up a data

288
00:18:27,900 --> 00:18:32,080
socket to our caching engine, and then we would pull that, and a lot of that, a lot

289
00:18:32,080 --> 00:18:37,280
of this between this feature recognition NLP and the cache are all running in memory.

290
00:18:37,280 --> 00:18:43,920
So on this back inside of things, what are some of the data sources that you envision

291
00:18:43,920 --> 00:18:46,000
your early customers connecting to?

292
00:18:46,000 --> 00:18:50,880
Is there like, you know, a top three lists of, you know, their email servers or something

293
00:18:50,880 --> 00:18:51,880
else?

294
00:18:51,880 --> 00:18:56,240
Or do you expect it to be more specialized, maybe proprietary systems or databases?

295
00:18:56,240 --> 00:18:57,240
Yeah, great question.

296
00:18:57,240 --> 00:19:04,000
I mean, what we've done for building the initial prototypes, we did, you know, the Dropbox,

297
00:19:04,000 --> 00:19:08,400
Google Drive, Gmail, Yahoo Finance, to be able to show that.

298
00:19:08,400 --> 00:19:14,000
So now, right now, you can have a conversation on our product, and you know, you ask for

299
00:19:14,000 --> 00:19:15,720
the price of Amazon, it shows up.

300
00:19:15,720 --> 00:19:18,760
You ask for an email, and on X, it shows up.

301
00:19:18,760 --> 00:19:23,320
We're also working on exchange integration, and what we're doing is there's certain integrations

302
00:19:23,320 --> 00:19:28,960
where they're more broad across many enterprises, and doing a very tight, custom integration

303
00:19:28,960 --> 00:19:31,480
where we can find information very fast.

304
00:19:31,480 --> 00:19:36,080
So exchange integration gives us both enterprise emails as well as a calendar information.

305
00:19:36,080 --> 00:19:37,080
I mean, that's awesome.

306
00:19:37,080 --> 00:19:41,040
So it's just, hey, when I gave you example, when you available, boom, who was on that

307
00:19:41,040 --> 00:19:42,040
call?

308
00:19:42,040 --> 00:19:43,040
You know, who's going to be on that call?

309
00:19:43,040 --> 00:19:45,360
You can bring in all that information and show that person.

310
00:19:45,360 --> 00:19:48,600
You don't have to sit there and fidget your email, your calendars, whatever.

311
00:19:48,600 --> 00:19:52,720
So a lot of enterprises now are using things like box and Dropbox, so that would be a more

312
00:19:52,720 --> 00:19:55,440
general type of integration that we would offer.

313
00:19:55,440 --> 00:19:58,920
Where we see, for example, for financial services, we talk, you know, a conversation would

314
00:19:58,920 --> 00:20:04,120
be with routers and market data, my Bloomberg sources there, same thing with legal, like,

315
00:20:04,120 --> 00:20:09,440
routers, Alexa Snack is our major players, Salesforce to be an integration on the sales side.

316
00:20:09,440 --> 00:20:13,320
So, you know, MLS would be an integration to real estate.

317
00:20:13,320 --> 00:20:17,480
That's sort of the, the integrations are really not, the focus really, it gets to being,

318
00:20:17,480 --> 00:20:22,960
make sure to get the language, the purpose for each one, so you're not, you're getting

319
00:20:22,960 --> 00:20:26,680
good matches, that's the idea.

320
00:20:26,680 --> 00:20:28,200
And how have you tackled that challenge?

321
00:20:28,200 --> 00:20:32,800
So initially, we're focused on initially a couple of articles.

322
00:20:32,800 --> 00:20:37,640
We're not, we're not going to target the entire marketplace and we have customer interest

323
00:20:37,640 --> 00:20:38,640
in both side.

324
00:20:38,640 --> 00:20:42,080
We're actually, in the very close to releasing a enterprise version of the product here

325
00:20:42,080 --> 00:20:45,240
within a couple of weeks, so excited about that.

326
00:20:45,240 --> 00:20:49,880
And then we have, you know, these are Fortune 50 type companies that are, that are going

327
00:20:49,880 --> 00:20:54,600
to be demoing the product too and go from there effectively.

328
00:20:54,600 --> 00:21:00,840
And then in terms of, you know, the goal is to expand the capabilities to a little, you

329
00:21:00,840 --> 00:21:03,280
know, a little more of the cognitive side of things where we can, you know, this is

330
00:21:03,280 --> 00:21:06,080
sort of why we joined the, and why we use the program.

331
00:21:06,080 --> 00:21:10,000
And so we can work closely with some of the professors and doing some of the things

332
00:21:10,000 --> 00:21:14,440
around building out our APIs so we can do a little more, and not have to be so limited

333
00:21:14,440 --> 00:21:18,960
to building out each vertical, but you can do probably to more of a broader solution

334
00:21:18,960 --> 00:21:22,040
for multiple type of verticals.

335
00:21:22,040 --> 00:21:23,040
Okay.

336
00:21:23,040 --> 00:21:24,040
Cool.

337
00:21:24,040 --> 00:21:26,240
So what's next for the company?

338
00:21:26,240 --> 00:21:30,040
So, you know, as I said, you know, we're excited about releasing this product here and

339
00:21:30,040 --> 00:21:32,040
getting these customers teed up.

340
00:21:32,040 --> 00:21:36,760
It's one of these things where it's fun to show the product because it's, it's sort

341
00:21:36,760 --> 00:21:38,080
of magical.

342
00:21:38,080 --> 00:21:42,920
It's also, you want to move faster, but you have to obviously go sort of a certain course

343
00:21:42,920 --> 00:21:45,960
to sort of, you know, achieve those results.

344
00:21:45,960 --> 00:21:50,600
And basically, we're just, it's first completing this next, what we call the beta of the enterprise

345
00:21:50,600 --> 00:21:56,600
version, get these customers using the product and using it, and then scale from it.

346
00:21:56,600 --> 00:21:57,600
Great.

347
00:21:57,600 --> 00:21:59,080
I really appreciate you spending some time with me.

348
00:21:59,080 --> 00:22:03,640
It sounds like you guys are doing really interesting things, and I'm looking forward to

349
00:22:03,640 --> 00:22:05,640
keeping up with you as the company evolves.

350
00:22:05,640 --> 00:22:06,640
Thank you.

351
00:22:06,640 --> 00:22:07,640
I appreciate the time as well.

352
00:22:07,640 --> 00:22:08,640
Great.

353
00:22:08,640 --> 00:22:09,640
Thank you.

354
00:22:09,640 --> 00:22:16,120
All right, everyone, that's our show for today.

355
00:22:16,120 --> 00:22:21,400
Thanks so much for listening and for your continued feedback and support.

356
00:22:21,400 --> 00:22:27,360
For more information on cool, second mind, or any of the topics covered in this episode,

357
00:22:27,360 --> 00:22:32,600
head on over to twimlai.com slash talk slash 65.

358
00:22:32,600 --> 00:22:37,560
To follow along with the NYU Future Labs AI Summit series, which will be piping to

359
00:22:37,560 --> 00:22:44,720
your favorite pod catcher all week, visit twimlai.com slash AI Nexus Lab 2.

360
00:22:44,720 --> 00:22:50,720
Of course, you can send along your feedback or questions via Twitter to at twimlai or

361
00:22:50,720 --> 00:22:56,080
at Sam Charrington or leave a comment or write on the show notes page.

362
00:22:56,080 --> 00:23:00,200
Thanks again to NYU Future Lab for their sponsorship of the show.

363
00:23:00,200 --> 00:23:06,400
For more information on the AI Nexus Lab program, visit futurelabs.nyc.

364
00:23:06,400 --> 00:23:09,680
And of course, thanks again for listening and catch you next time.

