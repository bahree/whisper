Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charington.
The show you are about to hear is the first of a series of shows recorded in New York City
at the O'Reilly AI New York event.
But before we get to the show, I've got a ton of updates and announcements for you.
First off, I want to give a huge thank you to everyone who came out to our very first
Twimble Happy Hour in New York City.
It was a great mix of folks and attendance, including listeners from New York, O'Reilly
AI attendees, and NYAI members.
It was an awesome, awesome night.
I want to especially thank Mariam and the rest of the team at the NYAI meetup for helping
us pull this entire thing together and for clarify for supporting it.
The O'Reilly AI conference itself was great, and of course my favorite part was getting
to meet so many listeners.
I especially enjoyed meeting Twimble's super fans Bill Barion and Beth Ann Noble.
They're both long time listeners of the show and highly engaged members of this community
and it was just amazing to get a chance to hang out with them.
I did a ton of interviews at the show and I'm pleased to present them to you for your
binge listening pleasure.
We have got your commute covered for the entire week with this series.
The series is brought to you by our friends at Intel Nirvana.
I talked about Intel's acquisition of Nirvana systems when it happened almost a year ago,
and I was super excited to have an opportunity to sit down with Nirvana co-founder Naveen
Rao, who now leads Intel's newly formed AI products group.
Naveen and I talked about how Intel plans to extend its leadership position in general
purpose compute into the AI realm by delivering silicon design specifically for AI and to end
solutions including the cloud enterprise data center and the edge and tools that let customers
quickly productize and scale AI based solutions.
I also spoke with Hanlon Tang and algorithms engineer on that team about two such tools
announced at the conference version 2.0 of Neon until Nirvana's deep learning framework
and Nirvana graph a new project for expressing and running deep learning applications as
framework and hardware independent computational graphs Nirvana graph in particular sounds
like a very interesting project not to mention a smart move for Intel and I'd encourage
folks to take a look at their GitHub repo at github.com slash Nirvana systems as well
as their main site at intel Nirvana.com.
One of the things announced at the conference is that Intel and O'Reilly will be partnering
on the AI conference going forward starting with the San Francisco event in September.
They've also changed the name of the event to the AI conference to celebrate all this.
We at twimmel are going to start our the AI conference ticket giveaway early and run
it through the end of the month.
To enter just let us know what you think about any of the podcasts in the series or post
your favorite quote from any of them on our series page on Twitter or via any of our social
media channels.
Make sure to mention at twimmel AI at intel AI and at the AI comf so that we know you want
to enter full details can be found on the series page at twimmel AI dot com slash O'Reilly
AI and why.
By the time this series drops I'll have just returned to the states from my trip to
Europe.
I'll be back on the road later this month to check out the wrangle conference in San Francisco
on July 20th.
You may remember that I recorded the very first twimmel talk show with Claire Cortell at
wrangle and cloud error was my very first sponsor for the podcast so I'm really looking forward
to getting back there.
I definitely hope to catch up with some twimmel listeners while I'm out there so please
check the event out.
If you'd like to attend I've arranged for a special discount for twimmel listeners using
the code PC VIP that's good for 20% off of registration.
Finally a couple of shows ago I mentioned the idea of starting a paper reading group
and it turns out a bunch of you are interested so let's make it happen.
If you'd like to give some input on the details visit twimmel AI dot com slash meetup
and join the discussion in the comments actually I've got one more finally.
Long time listeners will know that I've been talking about doing a newsletter since the
dawn of time well friends and I were chatting the other day about how we've both been
putting off launching our newsletters and ended up challenging each other to just do
it so look for it next week and if you're not already signed up please do so at twimmel
AI dot com slash newsletter.
Okay apologies for the long intro but now a bit more about this series in addition to
my conversations with Navine and Hanlon this series is packed with more interviews that
I know you'll love including my conversation with Doug Eck of Google brains project magenta
in which we discussed the intersection of AI and art in general as well as Google's
recently announced performance RNN project which was demonstrated for the first time
at the O'Reilly AI conference Ben Vagoda of Gamalon in which we discuss probabilistic programming
this one I think is nerd alert worthy raises a day of matroid about how his company is scaling
video object detection and Rana Elkayubi of affectiva about how her company uses emotional AI
to allow brands to better measure the effectiveness of customer experiences all right enough meta
let's jump right into the first episode of our O'Reilly AI New York series after the bumper
you'll hear my brief interview with Navine and immediately after that my interview with Hanlon
enjoy
so hey everyone I am here with Navine Rao Navine is the vice president of Intel AI product group
and we're here on location at the O'Reilly AI conference where he just delivered a keynote
they mean how are you great it's I think you went over pretty well short and sweet
got to announce a few important things around some of the open source projects we have going on
as well as our direction of end to end AI great why don't you tell us a little bit about the
announcements you made yes so one of them was about Intel Nirvana Graph this is a almost an
abstraction where for hardware basically collapsing primitive some different deep-boarding frameworks
into a common representation that we can then optimize for different types of hardware platforms
CPUs GPUs our new architecture FPGAs that kind of thing so it really lessens the burden on
optimizing each framework for every new hardware platform out there I think this is something we
want to drive forward as a standard in industry and the other one is we release neon 2.0 which is
our reference standard framework for deep-learning and this supports Intel architectures CPUs the
latest CPU that's going to be launched from Intel and will be supported by this framework and
optimize highly okay great and I've got a conversation scheduled with one of the technical folks in
I didn't tell Hanlon for later on so we'll dig into some of that but I wanted to also just kind
of get a pulse from you on it's been almost exactly a year since the acquisition it's been
about ten months yeah how's it going and what have you been up to what's been consuming your time
besides from the announcements that you just made yeah it's been a ride actually so when we came
in to Intel we were 50% startup now where we formed an entire new division devoted to AI
kind of seeded from that 50% startup and it's it's much bigger than that now so it's actually
been quite exciting to you know bring together the resources that we have it until and actually
drive a bigger picture a broader portfolio of products and solutions to the industry the way we
think has to change a bit as a startup you're trying to be scrappy you're trying to get that
next deal now we can think in a much bigger way right we can say well what can we do they'll have
a maximum impact across the entire industry sales channels and you know relationships it Intel
has with enterprise is just enormous 6000 salespeople can be unwished which is just a different way
of thinking entirely from a startup absolutely absolutely if I can kind of dig right in one of the
you know what I think of like the elephant in the room when I think about Intel is you know at
the the chip level and video was kind of at the right place at the right time for AI with their
GPUs and they a lot of people think that they've got a big head start in the market and you know
I wonder what's kind of how does Intel think about that and what's the plan I mean there's no doubt
they're executing extremely well they're doing a great job they've adapted their architecture
for these kinds of problems pretty well you know head start sure y'all who had head start
approval to so there's a there's a lot of examples to the contrary there and you know I welcome
the competition I think we're at a point now where obviously there's not going to be there's
never going to be one provider for these things Intel really owns the host processor in the data
center the harm the huge software investments that have been made in in terms of building the
internet right things where you can really scale out infrastructure make it reliable like when
you hit a website it works every time because of all the software investment builds on top of
Intel architecture so we're leveraging that and actually most AI solutions that are deployed
in the data center actually running on Intel right so we have we have those things we're enabling
them with our software stack today some of the announcements I made are relevant to that we're
adapting our main product lines for these purposes and we're also going straight for AI as a
as a preferred workflow essentially for acceleration so you'll be seeing some announcements in the
next you know six months to a year around our our silicon in that space as well okay you guys have
made some pre-announcements in terms of the broad picture broad brush roadmap can you walk us
through you know what we should expect to see sure so that was really based on the roadmap we had
from nirvana as a company so we are developing the silicon that we were developing at nirvana you
know it's going to be prototypes this year and we're really taking the learnings from that building
a real new architecture for this kind of workload is not simple all right takes a few iterations
so we're not really announcing products beyond that in terms of roadmap but we are basically going
to have products out in 2018 19 20 an entire roadmap that we're not talking about performance
just yet but I mean we do have some really important and exciting things on horizon from
the silicon engineering side as well so AI is is a great showcase for those capabilities
because density of compute and power per operation matter right right so that's something that
into it's right in until schoolhouse and then speaking of density a big part of the nirvana
story was around cloud how are you guys thinking about the role of cloud with regards to AI so yeah
that's a really interesting question so part of it is actually we're continuing our hosted cloud
service so we're talking about nirvana cloud we look at that as very very much a quick way of
getting going on a solution for an enterprise in addition to that we want to bring those
capabilities on prem for enterprise customers you don't necessarily want to move data on their
premises and so that's kind of the products will be you'll be seeing in the next year or so then
obviously a broader industry cloud service providers are a huge customer of Intel also Amazon
Google Microsoft the big ones so they're all developing their AI platforms and we're supporting
that effort it's basically a different kind of customer for us but we look at is basically they
intercept at different points in the stack right and so I think you're going to see a variety of
solutions ranging from fully in the cloud to hybrid on prem cloud and completely on prem okay
okay great great one of the announcements you made was around the nirvana software stack how does
can you talk about how that relates to some of the other frameworks that are out in the marketplace
TensorFlow for example has gained a lot of traction I think my impression was that nirvana's stack
was initially positioned as an alternative to something like a TensorFlow is that still the case
and how do you see the kind of landscape there yeah so when we first started nirvana actually there
was no TensorFlow right there are a few fragments of frameworks we put neon out at that time and it
is still an alternative to TensorFlow it's kind of works at the same semantic level okay we are
keeping that development going as a reference standard people can obviously build on and we're
supporting it that's good for us because it allows us to bring the latest optimizations that we
have for hardware to the open source community quickly we're not beholden to anyone else who
owns the database basically right right so we can get those out intel nirvana graph is about
supporting everybody else's frameworks so if you go to intel nirvana.com you can actually see
how we're plugging TensorFlow into intel nirvana graph and allowing it to be optimized on various
hardware platforms so we want to play in the community that way but we can control the ecosystem
from the neon side and provide the latest innovations there and it'll take a little bit
longer for the trickle down into the rest of the open source community okay what are some of
the specific ways today that the hardware innovations are surfacing in into the neon framework
I mean these are some of these things are we can't talk about just yet but we're going to do
parallelism and distribution okay of work was we have some novel constructs and the way we handle
memory and things like that okay it's not to say we couldn't make it work in other frameworks but
we'd have to really fork it and do things a little bit differently so we can get those new concepts
out and I think now what's what's cool about being part of such a big company is that we can
actually shape how the rest of industry sees this so we get those things out I think researchers
are playing with it and we start seeing changes happening in all the frameworks okay I'm sure
it'll be interesting I've seen similar path happened with the intel investment in cloud error
and how they push a lot of the security and encryption innovation and other things like that
into the Hadoop ecosystem it would be interesting to watch so I think we're about at our time
anything else you'd like to mention to the listeners well I think you know the partnership with
O'Reilly it is very exciting for us I think we're at a time and industry we're seeing adoption
happen quickly and so O'Reilly has been on the strata Hadoop site has been really a big
player in that and so I see a parallel happening with AI as well and so I hope to see this this
grow for O'Reilly and we'll be part of it and you just announce a strategic partnership where
you guys are the exclusive partner for the O'Reilly AI conference going forward not exclusive we'll
still take on other partnerships of course with them but we are the main headline sponsor yes okay
analogous to the cladera and exactly strata data now you got a conference okay awesome awesome
while looking forward to seeing you in September and at the O'Reilly AI San Francisco looking forward to
as well awesome thanks to being all right thank you
hey everyone I am here with Hanlon Tang Hanlon is a senior algorithms engineer with Intel
Nirvana Hanlon gave a talk here yesterday at the O'Reilly AI conference and we're here to talk
about his talking what he's been up to how you doing Hanlon good how are you I'm doing great I'm
doing great why don't we start by actually having you talk a little bit about your background and
how you got into AI and algorithms yeah of course I guess it mainly started when I was in graduate
school I was doing research and computational neuroscience and that's really where the connection
between understanding how the brain works and attempting to transfer some of that knowledge
into silicon and computer systems really took hold so after graduate school I joined Nirvana
which is a deep learning startup and through that it began to sort of apply the research that I did
in graduate school to some of the applications that Nirvana is developing the now of course
as Intel we have the opportunity to scale that out quite significantly across all fronts hardware
software algorithms great great and you gave a talk here yesterday at the conference that's right
I think I mainly focused on how do we do that exact same process that I had just described
of no taking research these sort of algorithms and models that you see in the scientific literature
and then begin to apply them and deploy them into production settings okay our sort of unique
challenges that you face when trying to do something like that why don't we have you walk us
through that I know a lot of myself and a lot of our listeners will read papers and walk through
you know the latest cutting edge research and try to understand how to implement it but putting
it in a production is a whole other issue so how did you frame that up in your talk I think I
mainly focused around three key aspects so the first one being the lack of data so I think we've
often heard that there is a flood of data in the world today and certainly with fortune 500
companies and government agencies is a large corpus of data but all that data has to be funneled
through a very small pipe of manual annotations because existing methods we need a human to actually
go through and put you know boxes around all of the cars for thousands of images before a model
can learn to do it so we're data rich but labeled data poor that's right and be able to navigate
that environment with either in heavy investments in data or some of the newer techniques and
generating synthetic data from what you already have is sort of quite critical on building applications
that perform well because deep learning particularly requires a large amount of data to reach
the level of performance that sort of exceeds what humans can do so on your first point then with
regards to data you know we there's clearly you know there are ways to take this on manually by
you know just investing in labeling data but on the synthetic data side what's happening in that
part of the what kind of activity is happening there so one great example is from Intel labs
where they have used video games to generate some realistic imagery by sort of getting graphics
artists and such to build out a video game environment to use that sort of build a synthetic data in
order to train many of the autonomous driving applications okay or alternatively there have also
been advances in using generative out of serial networks to also generate realistic imagery that
could be used during the training process oh interesting I think I've seen examples of the
using video game data to train autonomous driving programs at the time I thought the results
that I saw suggested that for whatever reason the results didn't transfer very well did you
guys in the lab research that you're referring to find some ways to address that I think that's
still an active area of research is how to generalize but they did find that if you're able to augment
your existing rural data set with the synthetic data set you do get better performance overall
because the transferability problem exists for real data sets as well or you may collect large
amounts of data in one city but not able to generalize to other cities or other environments okay
oh interesting yeah the other sort of aspect that I highlighted was building a feedback loop
into the into your systems to have annotation occur on the edge and what I mean by that is if
you're building say aviation security application when you have sort of detectors at the scanning
sites looking for you know dangerous objects and baggage you also want to build in a system for
the agents to provide feedback on how the algorithm is doing and in that way you build a sort of cycle
of collecting data and monitoring data in production right and we've seen that to be quite critical
because the world and the can change underneath you so objects that may be more popular during
the summer maybe less popular in the winter so being able to monitor those changes of the
distribution to object that you expect to see and modify the algorithm appropriately is quite
critical that's an interesting point I know a lot of startups are you know founded basically
around this idea of collecting data and allowing consumers to to basically annotate models for
them annotate data for them but I can imagine enterprises building these systems and putting them
out and not kind of closing the loop that's right is relatively easily to close the loop when
it's just a web interface where the closing the loop is quite simple but in autonomous driving
or aviation security or many of these are the applications where physically the inference occurs
on the edge you actually have to build in the networking and the storage and the memory and also
the sort of components that Intel has in order to close that loop in many of these many of these
scenarios okay all right so you talked about data as one of the first elements of being
able to put these systems into production what else did you talk about the other point that I
really wanted to highlight was around model selection uh-huh it's a difficult challenge these days
because for any particular tasks such as object localization you will find many models in the
literature so faster RCNN single shot detection models RFCN and there are always newer ones coming
out you know all the time so Intel recently has pva net as well and how do you make a decision
as a data scientist of what models to choose and I guess what we've seen is that many customers
may sort of just choose the latest model and run with that where sometimes you have to make very fine
grain speed accuracy trade-offs around your particular use case so a particular model may
be more performant but also take longer to train in which case your iteration cycle is slower
right or on your training costs are higher yes and your training costs are higher or some models
may perform better than another model on sort of an aggregate performance metric but perhaps one
model will perform better at small objects compared to large objects and so be able to make that
fine-grained determination not just on sort of average metric level but also splitting it up into
the individual categories depending on what you're interested in is what we've found to be valuable
for many of our enterprise customers do you find that that understanding the the various
trade-offs is it to what degree is it dependent on a very specific use case and specific data set
and I guess the broader question is is it possible to kind of come up with some standard metrics
around you know in a given category like object detection or speech recognition and you know
rate the different algorithms according to you know some set of standard metrics I haven't seen
anything like that but it would certainly be helpful to folks that are you know coming into a
space like object detection and trying to figure out where to get started. There are certainly
ways to do that so there was a recent paper by many of our colleagues at Google on doing exactly
that okay measuring the various types of object detection models on performance and speed
and that is sort of valuable work to help guide many of our customers and that determination
somewhat general across different use cases with an object detection however for your particular
use case you need to dive much deeper than that it's not enough just to look at the overall
mean average precision which is the metric that they use you then have to split it out by
particular pedestrians or motion large objects small objects and that determination is much more
use case specific. And then in this paper that you're referring to did they also consider
practicalities like training time and you know training cost things like that. They did not I
think they were mostly focused on the inference side of the equation so that's certainly valuable
work moving forward. Interesting. So what else did you cover in your talk? I think those were the
three sort of main points. I made around data closing the loop and model selection okay. I guess
if I were to add a fourth one that I had mentioned was knowing your model provenance. So going back
to the object detection example there that model and many of those models are designed for specific
data sets you know as a grad student you build a model around specific benchmark data sets to help
guide you on how you are doing. And so in particular two data sets Pascal VOC and MS-Coco have been
very popular for object detection. But those data sets typically have maybe five to ten objects
per image. If we're trying to transfer that same object detection model to do a different
application such as satellite imagery. Suddenly you have a scenario where the data sets statistics
don't match the benchmark data sets of the model was designed for. In satellite imagery you have
hundreds of objects in a particular image. You have rotational symmetry because an aerial image
can be rotated and retain many of the similar properties. You have boxes around buildings that
are no longer you know that are rotated. And so now you need to additionally predict an angle
in addition to the coordinates. And so we've been actively developing ways to adapt existing models
to that application. So even though both paths are object detection knowing where the model came
from and what it was designed for can help you sort of maximize the performance on your particular
application where the statistics may be completely different. Yeah this comes up all the time in
the context of the research community and the practitioner community kind of you know quote-unquote
overfitting on image net right. And it sounds like some similar things are happening in the object
detection realm where there are some standard data sets that you know folks are building models
on and then trying to apply all over the place. Knowing the providence of your models is one thing
it sounds like you're also then coming up with techniques that allow you to generalize and adapt
those models to new situations. In the case of satellite imagery for example how exactly do you
what's kind of the underlying techniques that you're using to enable the model to adapt to
a different use case. It's really doing surgery on the model itself. So in this particular case
existing object detection models in the literature mostly just predict the xy coordinate of the
upper left corner and then a width and a height of a box. And so we are working on modifying that
for traditionally predict rotation angle for example or dealing with multispectral satellite data
where it's not just red green blue in the image but IR near IR as well. So there are also these
other spectrums that we can begin to build a model to to take advantage of. Okay so we're
here we're talking about evolving the models themselves as opposed to we're not training a model
on the original data set and then using some techniques with a train model to give it better
inference in a new scenario. We're talking about how do we build a new model that is better adapted
to this situation. Yes exactly. I mean don't get me wrong these existing object localization
models are very powerful. Oh absolutely. You know five years ago as a grassland I would never
have imagined a world where these sort of applications can be done and not only be performed well
but at real time speed. Right. It's quite incredible. And so we really is sort of standing on the
shoulders of sort of these papers but then entering further for particular use cases where you need
to make some some changes. Okay and then I think in your presentation you also talked a little bit
about the Nirvana stack and what was happening in that area. It's an exciting time for us. We've
spent the last two and a half years building a full stack for for deep learning and I think as
Nirvana and now as Intel we still firmly believe in that philosophy that you need the full stack in
order to get maximal performance and ease of use out of what we're building. So it's everything
from the custom silicon to our software work up to a cloud or platform service and finally to
to applications and now that we're part of Intel we have an opportunity to supercharge those
efforts in a sense and so as Naveen had mentioned we've released Neon 2.0 which Neon previously was
known you know when we were start up as one of the fastest frameworks on GPUs due to the custom
assembly kernels that we wrote and some of the algorithmic innovations that we introduced with
winner grad convolution and now we're you know have we've been working very hard with other
engineers of Intel to also optimize Neon for Intel architecture and so by integrating into Intel's
math kernel library we can achieve quite significant speed ups so on an image classification model
such as Google net inference is about 98 times faster than previously so these are very serious
optimizations that Intel has done for other frameworks as well such as TensorFlow and MXnet
and we're excited to work with them to now bring many of these optimizations into Neon as well
okay for those that aren't familiar with Neon can you walk us through the design philosophy and how
it differs from some of the other frameworks that are out in the market of course so Neon we
really designed for enterprise use cases where speed was quite important and many of our customers
don't really need the model of the week they want a stable and fast and optimized object
localization model or speech recognition model and that's really what we provide to many of our
customers in addition we pay a lot of attention to data loading because the you know the folks
that we talked to Ado Riley you know those that run companies that build applications they don't
train their models on image net or on MS cocoa or on pen tree bank they train on their own custom
data sets right and so we put a lot of effort into designing modular data loaders that are fast
but also flexible okay and easily provide a data API for users to switch between different
models so if I'm doing an object detection model we have a couple that we've implemented there's
a common data API for loading that kind of data so that you can test different models
are relatively easily okay are there particular use cases beyond the ones that you've mentioned
that you've found to be the sweet spot for Neon relative to other frameworks I think we found
use cases across a variety of domains so not just an image that I mostly focused on but also in
speech recognition where we've developed a model based on by do state of the art deep speech to
model okay a natural language processing which many of our financial customers are using
I think one of our sort of MOs is to keep track of the quickly changing literature for new
models coming out that bring new level of capabilities and then porting them into Neon and then
optimizing them for speed and for stability and for ease of of data loading and that's really
where we find the value to provide to many of the folks that that we work with one of the the
challenges for enterprises putting these types of machine learning models into production is
monitoring their performance over time and then building a feedback loop that allows them to
improve and enhance their models does Neon have anything in particular to offer in that scenario?
Yes so in Neon we built in callbacks okay that allow the model to report back its progress either
during the training process but also actually mostly during during the training process we don't
have anything currently for sort of specially built for monitoring in inference okay but that's
certainly a good idea that we can look into okay so in addition to the Neon 2.0 announcement you
also announced the Nirvana Graph product can you talk to us a little bit about that?
The Nirvana Graph project really started even before we were acquired okay add Nirvana
when we realized that many of the newer models coming out attention-based models for example
were much easier expressed in a computational graph and that's really the core of the efforts
that we're doing where we've really rethought the backend of Neon and with the Nirvana Graph
effort we built and we're in the process of designing a Nirvana Graph interview representation
which different frameworks can then hook into okay and then on the back and different hardware
back ends will take the graph emitted from Nirvana Graph and then apply their hardware specific
optimization passes until we eventually build an executable execution graph that can run
on different devices so at Intel we're fortunate to have a variety of hardware targets
Zian Zian Phi, Future Lake Crests, Movedias, FPGA's and having a common tool chain to allow folks
to train on one hardware device and deploy on another one or train on a heterogeneous mixture
of hardware devices we think will really change how models are being developed and make
it much easier for industry to transfer those models you know between these different devices.
Can you talk a little bit more about graph as a paradigm for building out these models?
You mentioned attention based models as an example how what's the relationship between
you know a graph based view of the world and attention models and how does a graph
framework support building that kind of model better?
Fundamentally neural networks are graphs of computations and representing that directly
in the Nirvana Graph framework and allowing folks to interact with the graph in building these
models will allow much more flexibility than what we had originally envisioned with NIA.
And so it's the idea that for an arbitrary network my different layers represent nodes in the
graph or what does a node in the graph represent? So a node in a graph represents a fundamental
operation adding or exponential function or matrix multiply. And so layers which is a higher
level concept each layer implements a graph of operations. And when we stream together layers
are essentially adding components and nodes to the graph itself and that's during the construction
phase and after that construction is complete we now have a complete view of the exact
operations that you need to do to train your model. And from that we can then apply optimization
passes to reduce unnecessary computations to optimize memory usage and also taking to account
the specific data layout requirements of different hardware. So how does the developer experience
change in using the graph project? You call it a project or product? I would call it a project.
What I'm an engineer? Not a product person. So I'm not quite sure what the exact
semantics are. So it's clear that thinking about a neural network as a computational graph
and having that explicitly laid out allows us to perform optimization just like a compiler
might or like a query planner and a database might. Is this something that's happening at the
developer level or is it kind of shimmed in underneath an experience that the developer might
already be using like Neon or TensorFlow or something else? If you're a developer that principally
uses components that have already been written out so layers like convolution and pooling
then your experience will be relatively similar. If you have to develop new layers or apply
some custom computation then you're able to access this node level directly and develop on that
so you can compose the ops yourself into a graph. And in many cases we find that the latter
brings a lot of value because not everyone is just sort of applying the vanilla models and layers
that have already come out there. And part for the reasons that we previously talked about they
don't apply as well to some problem sets or data sets then a model that's been augmented to
meet the specific needs of that data set. Right and in many cases it's not just the different
layers that they're composing together but also the way they're composing them together.
So I have a bunch of layers coming in and I want to fork that into outputs that get broadcast to
multiple streams or I may have multiple streams of data coming in whether it be images and
video and text I want to concatenate that together. So the graph also allows that to be much easier
than before because if we know the graph we know how to do the forward and the backward passes
during the training regime. Whereas before and neon you would have to explicitly guide the model
towards okay I have this topology do the forward pass this way and then pass you know the outputs
across this fork and then collect the gradients etc. So the graph takes care a lot of that
so you can it's much more composable is one of the key points okay oh super interesting
it. How can folks learn more about the neon and the graph projects? I definitely encourage listeners
to check out our GitHub page. Okay. Nirvana systems. There is a repository for neon and also
for n graph or the Nirvana graph. Okay. Additionally if you go to www.intelnervana.com we have a
couple blog posts that introduce the sort of the framework itself how to use it links to the model
zoo where we have a lot of pre-trained models that folks and easily get started with. And we
definitely encourage the community to contribute as well. The Nirvana graph effort is still in the
early stages we're sort of releasing our sort of latest commits quite often but definitely if users
look into that and see a feature that they like that they're missing you know we definitely welcome
external contributions. Awesome. Awesome. Anything else you'd like to mention? I think that's it.
I'm excited to be here at Eteralli talking to you and I'd be happy to continue the conversation
in future future meetings. Fantastic. Thank you. Thank you.
All right everyone that is our show thanks so much for listening and for your continued support
comments and feedback. A special thanks goes out to our series sponsor Intel Nirvana. If you didn't
catch the first show in this series definitely check it out. If you didn't catch the first show
in this series where I talked to Naveen Rao the head of Intel's AI product group about how they plan
to leverage their leading position and proven history and silicon innovation to transform the
world of AI you're going to want to check that out next. For more information about Intel Nirvana's
AI platform visit intel Nirvana.com. Remember that with this series we've kicked off our giveaway
for tickets to the AI conference. To enter just let us know what you think about any of the podcasts
in the series or post your favorite quote from any of them on the show notes page on Twitter
or via any of our social media channels. Make sure to mention at Twimlai at Intel AI and at
the AI Conf so that we know you want to enter the contest. Full details can be found on the series
page and of course all entrants get one of our slick Twimo laptop stickers. Speaking of the
series page you can find links to all of the individual show notes pages by visiting twimlai.com
slash O'Reilly AI and Y. Thanks so much for listening and catch you next time.
