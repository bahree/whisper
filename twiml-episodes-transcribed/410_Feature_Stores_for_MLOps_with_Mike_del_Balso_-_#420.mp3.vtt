WEBVTT

00:00.000 --> 00:12.320
All right, everyone. I am here with Mike DelBalso. Mike is the co-founder and CEO of Techton.

00:13.040 --> 00:17.920
Mike, welcome to the Twomo AI podcast or I should say welcome back to the Twomo AI podcast.

00:17.920 --> 00:22.160
Yeah, thank you. Happy to be back after a couple of years now.

00:22.160 --> 00:28.800
A couple of years. So we recorded our first interview in March of 2018. So

00:28.800 --> 00:37.440
it's like two and a half years. It was episode number 115 and we just published four

00:37.440 --> 00:45.680
17. So 300 episodes ago. Wow. I'm not even considering 2020 years which make it seem way

00:45.680 --> 00:50.960
longer. Yeah, that's like three decades ago. That's nuts. Well, I'm happy to be back and

00:50.960 --> 01:01.280
congrats on having what 415, 417. Wow, that's a that's quite an accomplishment.

01:02.240 --> 01:06.160
Yeah, happy to be back. Thanks for having me. Absolutely, absolutely. And you've been busy

01:06.160 --> 01:14.000
yourself. When we first spoke, you were at Uber and we were talking about Michelangelo, the platform

01:14.000 --> 01:23.280
that you built there to help scale and operationalize machine learning and you left Uber to help

01:23.280 --> 01:31.040
other folks do that. When did you how long has it been? Yeah, so beginning of 2019 right at the

01:31.040 --> 01:37.920
end of 2018, that's when myself and some of the other folks that helped build the Michelangelo

01:37.920 --> 01:48.000
system, we kind of split off to help other folks solve similar problems. And yeah, so companies

01:48.000 --> 01:54.960
called Techton, we build an enterprise feature store for machine learning and happy to tell folks

01:54.960 --> 02:01.360
about that today. But yeah, that started. So we've been doing that almost two years into that.

02:01.360 --> 02:14.080
Wow, wow. I'm curious about one thing I'm curious about is, you know, Michelangelo kind of

02:14.080 --> 02:24.560
encompassed a ton of features not to overload that term. And you could have done a lot of things

02:24.560 --> 02:33.040
in space, but you chose to focus on the kind of feature store part of it. Maybe share a little bit

02:33.040 --> 02:40.880
of that to help contextualize the way you think about the overall problem of operationalizing machine

02:40.880 --> 02:48.880
learning. Yeah, for sure. Well, so I've been doing this a long time now. And before building this

02:48.880 --> 02:59.120
stuff at Uber, I actually was at Google and I worked on the machine learning systems that power

02:59.120 --> 03:06.720
that adds auction at Google. And they had been doing this for many years and they had really great

03:06.720 --> 03:13.120
systems to power these core processes that run Google's business, right, determining what you

03:13.120 --> 03:19.520
had to show. And it's very financially important and super highly productionized. And you know,

03:19.520 --> 03:27.440
at Uber, we were starting from, you know, not zero, but we just had a handful of models and

03:27.440 --> 03:32.960
production. It was kind of early days for machine learning at that time. And we went through this

03:32.960 --> 03:40.080
journey at Uber over a period of like two and a half, three years where we brought in the right

03:40.080 --> 03:48.800
tooling and we really unlocked the ability for the data science and the analytics teams to really

03:48.800 --> 03:53.200
build machine learning systems and deploy them in production. And so during that time, I was,

03:53.200 --> 03:57.520
you know, thinking about, hey, what is, you know, how does this look when it's done right? And

03:57.520 --> 04:02.080
I was thinking a lot about my time at Google and with these really amazing large models updated

04:02.080 --> 04:08.640
all the time, you know, really, we didn't use the term ML ops at that time. But things were highly

04:08.640 --> 04:16.480
productionized and had a very DevOps and modern ML ops feel. And so, you know, we had to build the

04:16.480 --> 04:24.800
whole stack at Uber. We started that 20 in 2015. And there was not a lot of good ML infrastructure

04:24.800 --> 04:33.920
and all tools at that time. And going through that journey, I had the chance to really kind of

04:33.920 --> 04:39.760
understand the value of every single component to the ML stack as we added it, right? We added

04:40.320 --> 04:45.360
model serving layer and, you know, how many use cases did that unlock and how much, how much

04:45.360 --> 04:51.600
did it make it easier for teams that were trying to put ML in production? And we built a model

04:51.600 --> 04:56.000
training system and then we connected them. We built all the different components. And

04:56.000 --> 05:05.040
what we found was that the, so we always hear, you know, team struggle with data and data scientists

05:05.040 --> 05:10.640
spend 85% of their time cleaning data. You know, I'm sure every single, you know, podcast guests

05:10.640 --> 05:18.400
has said that at one point. So we also found though that after kind of solving spending 85% of their

05:18.400 --> 05:23.360
time on that, there's another kind of like hidden 85% of the time it takes to get something into

05:23.360 --> 05:30.640
production as well. And so, and I get that that adds up to more than 100%, but it's also like kind

05:30.640 --> 05:37.040
of the point. And the core of that was these data challenges that were preventing people from

05:37.040 --> 05:43.200
getting to production. And as we built out, what at the time was just kind of like data infrastructure

05:43.200 --> 05:47.760
that we were building into the machine learning system and we were building in these kind of core

05:47.760 --> 05:54.400
data workflows into the machine learning platform at Uber. We found out that that unlocked a lot

05:54.400 --> 06:02.240
of value. And so what, what does that mean? More specifically, it allowed teams to get

06:03.120 --> 06:08.000
into production, to go to production really quickly because before they would have to, they would

06:08.000 --> 06:16.080
be really like coming up with some cool model prototype and then have a bunch of data engineering

06:16.080 --> 06:20.880
that they would have to do to get that model in production. And a lot of the kind of future

06:20.880 --> 06:26.960
store capabilities, we didn't even call it future store right away, are things that unlocked that

06:26.960 --> 06:32.400
path to production really quickly for data scientists who are just trying to build their models.

06:33.120 --> 06:40.000
And the second element there was making just in terms of in terms of machine learning as a

06:40.000 --> 06:50.480
like an organization thing, the future store really allowed for different teams to be able to reuse

06:50.480 --> 06:55.600
each other's work. And so it really kind of like led to the scaling of machine learning across

06:55.600 --> 07:04.720
the organization really quickly because you know, we would have teams that have a variety of

07:05.680 --> 07:08.880
models that they want to build, but they're all kind of similar. They're all kind of using

07:08.880 --> 07:15.600
similar and related data. And so they probably have very high overlap in the number of,

07:15.600 --> 07:20.400
in which features they want to use across those models. And so this provided a way for teams to

07:20.400 --> 07:27.040
share and reuse and kind of have this canonical catalog of these features that allowed for like

07:27.040 --> 07:30.960
kind of like a Cambrian explosion of machine learning at the company. And it wasn't even really

07:30.960 --> 07:35.760
something that we realized at the time, but kind of looking back on it and doing reflections and

07:35.760 --> 07:41.120
reviews, you're like, oh, that was really the component that was the most useful and unlocking

07:41.120 --> 07:44.960
machine learning at the company. And so we spend a lot of time formalizing like what is a

07:44.960 --> 07:52.000
feature store? And what are the bounds of it? And how, you know, how does it use? And that's why

07:52.000 --> 07:58.000
we really focused on the area. Does that make sense? Yeah, no, it does. It does. Yeah, it makes me think

07:58.000 --> 08:03.520
of a question that I've asked a number of folks. We may have even talked about this a couple of

08:03.520 --> 08:12.160
years ago, but when, you know, talking to folks about a feature store, there's, you know,

08:12.160 --> 08:18.880
there's often a set of folks that are super excited about it and get this idea of feature

08:18.880 --> 08:24.720
reusability and wanting to make it, you know, easy for, you know, the next data scientist that

08:24.720 --> 08:30.560
has to deal with customers or products or some of these core ideas that, you know, that a given

08:30.560 --> 08:36.640
business deals with over and over again, you know, wanting to make it easy for them to use pre-built

08:36.640 --> 08:41.600
features. You know, there's a core set of folks that get excited about that. There are other

08:41.600 --> 08:51.120
folks that are somewhat hesitant and, you know, worry about the burden it puts on a data scientist

08:51.120 --> 08:56.160
to, you know, they're essentially then if they publish a feature into a feature store kind of

08:56.160 --> 09:01.520
owning a product, that feature that they have to then maintain and, you know, they may be confronted

09:01.520 --> 09:06.800
with requirements from other data scientists that are not really in line with what they're trying

09:06.800 --> 09:13.040
to do. There's a little bit of, you know, tension between, you know, just making it really easy

09:13.040 --> 09:19.360
for folks to solve their own problem, you know, and then you put in this kind of reuse infrastructure

09:19.360 --> 09:28.800
that promises to make the overall ecosystem faster, but it does require, you know, potentially

09:28.800 --> 09:34.560
sacrifices on the part of individual data scientists. And I'm curious, is that something, you know,

09:34.560 --> 09:40.880
that you run into is that, you know, how was that evolved kind of over the past couple of years

09:40.880 --> 09:46.640
in terms of in practice and the way you see folks use these kind of tools? Yeah, I mean, this is,

09:46.640 --> 09:53.200
I guess that's a core collaboration problem, right? And why do teams want to do this in the first

09:53.200 --> 09:59.040
place? Well, the reason is because these efficiencies that you mentioned, you know, without this,

09:59.040 --> 10:05.120
we, you know, talk to companies every day, see the first hand, there will be two data scientists

10:05.120 --> 10:10.560
who sit right next to each other and they're building the same 10 features or the same 100 features

10:10.560 --> 10:16.400
and either they don't know that the other person is building the same features or they know about it

10:16.400 --> 10:20.560
and then they don't have a way to reuse it. They don't have, they don't have that kind of path

10:20.560 --> 10:25.280
to build that into their model. And then there's that kind of third element of like,

10:25.280 --> 10:31.680
hey, I actually do have a way to reuse this, but you know, I don't know if I'm going to be able

10:31.680 --> 10:36.000
to trust that this person is going to maintain this data pipeline, this feature at the quality,

10:36.000 --> 10:39.760
the level of quality that I care about, is this person going to be on call for this pipeline?

10:39.760 --> 10:46.080
Is, does this person think of it as seriously as I do? You know, I could probably work something

10:46.080 --> 10:49.520
out with them, but you know, it's probably just easier for me to build my own thing even though

10:49.520 --> 10:55.680
it's going to be a hassle. I want to, I want to save this future larger hassle. And so these are

10:55.680 --> 11:00.960
kind of problems, collaboration problems that can be solved by a central platform, right? So

11:00.960 --> 11:12.160
within a feature store, of course, the feature store tracks the kind of data, the feature values

11:12.160 --> 11:17.200
and the functions or the pipelines that generate these features. But there's also like a variety

11:17.200 --> 11:22.400
of metadata, which is like a pretty important component of the feature store metadata that are

11:22.400 --> 11:29.120
tracked for these features to allow different organizations to kind of apply policies for reuse,

11:29.120 --> 11:35.920
right? Who's the owner of this feature? And what level of kind of productionization or SLA,

11:35.920 --> 11:40.480
are they promising for this feature? Are they promising? Is this used in like a tier one system

11:40.480 --> 11:44.880
or a tier two system? And different organizations have different ways that they think about this

11:44.880 --> 11:50.960
kind of stuff. Is it an experimental feature, a production feature, or a completely dev feature?

11:50.960 --> 11:58.400
And so having this kind of metadata and this transparency of this metadata is the first step

11:58.400 --> 12:05.680
to allowing these teams to collaborate. But one kind of pattern that we're beginning to see

12:05.680 --> 12:13.680
in many organizations also is there is this notion of these kind of like analytical data pipelines

12:13.680 --> 12:22.560
and then these operational data pipelines. Think of analytical as being data that doesn't actually

12:22.560 --> 12:26.960
get used in my product or in production in some way, but it's just something I've built for

12:26.960 --> 12:34.640
exploration or reporting or just like a one-off analysis, hey, I want to estimate what the

12:34.640 --> 12:41.600
sales forecast is going to be at the end of the year or something like that. And then the operational

12:41.600 --> 12:46.160
pipelines are things that run every day or potentially real time, they're using the product,

12:46.160 --> 12:52.000
they're productionized, they have SLAs, you want to be on call for them. And so

12:52.000 --> 13:02.400
another kind of pattern we're starting to see in organizations is that beyond, they recognize

13:02.400 --> 13:06.640
that individual data scientists need to be able to get stuff in production on their own.

13:07.360 --> 13:14.880
But as what they have built becomes useful to beyond just their single use case,

13:15.360 --> 13:19.840
there tends to be these kind of central, most a lot of companies have these ML platform teams

13:19.840 --> 13:25.760
and the ML platform teams often dedicate some resources to like managing the core feature pipelines

13:25.760 --> 13:34.000
for the company. So rather than just having data scientists now have to worry about owning this

13:34.000 --> 13:38.880
feature that other people will consume and then they'll have all these extra expectations of them,

13:39.680 --> 13:47.600
a central kind of like feature team as a sub team of the ML platform team is a common pattern

13:47.600 --> 13:52.000
we're beginning to see. And they'll kind of take over the most use and the highest value features

13:52.000 --> 13:57.360
to guarantee their correctness, et cetera. And that's actually the pattern we use in the Michael

13:57.360 --> 14:04.320
Angelo team as well. Now you're talking about a level of rigor and sophistication that's

14:04.320 --> 14:12.080
you know fairly common in the kind of large Silicon Valley companies, but for traditional enterprises

14:12.080 --> 14:18.240
is certainly starting to see more and more platform teams forming,

14:19.040 --> 14:24.000
but it's not nearly as common in my experience. I'm curious if that's your experience as well.

14:24.000 --> 14:30.640
And if you can kind of maybe compare and contrast what you're seeing in traditional enterprises,

14:31.840 --> 14:38.720
both with regard to feature stores, but more broadly kind of their journey to operationalizing

14:38.720 --> 14:46.320
machine learning. Yeah, I mean, it really depends on the company, but there's a lot of companies

14:46.320 --> 14:51.280
who are being told, hey, we need to we need to figure out ML. We need to kind of that's

14:51.280 --> 14:56.720
core to our strategy. And they're spinning up an ML platform team and ML infrastructure team,

14:56.720 --> 15:04.560
or it could be kind of like an advanced analytics infrastructure group. And it's hard, you know,

15:04.560 --> 15:10.800
often it's hard to find people who the people who like know know this stuff well, or it's hard

15:10.800 --> 15:15.600
to like learn this stuff in the first place. And a big challenge that a lot of these companies

15:15.600 --> 15:22.080
have is that they're still not kind of at like data maturity. So then building like ML maturity

15:22.080 --> 15:29.840
on top of that is a tricky spot to be probably the biggest kind of elements. And technically,

15:29.840 --> 15:34.320
that's the challenge is you have to be in a pretty good spot with your data infrastructure.

15:34.320 --> 15:40.240
First and a lot of these companies, you know, they're trying to hop on the AI, the machine learning

15:40.240 --> 15:47.280
wave while they're still mid migration to cloud, or they have a ton of data silos, or they're

15:47.280 --> 15:52.000
they have they're trying to figure out how to adopt streaming data at the same time, but they want

15:52.000 --> 15:56.720
to build machine learning using streaming data. So kind of like that core infrastructure and the

15:56.720 --> 16:05.600
core data is something that I would say is like one of the top priorities to focus on and really

16:05.600 --> 16:11.120
work on as you're building out the ML platform team. But then also kind of on top of that,

16:11.120 --> 16:17.200
you want to build ML ops processes. And it's a super fragmented space right now. And I think it'll

16:17.200 --> 16:21.840
stay like that for a while. The ML ops, all the different tools that can fit in the ML ops pipelines.

16:21.840 --> 16:26.880
But that's stuff you can figure it out and get started with. There's a lot of good options out

16:26.880 --> 16:31.920
there and you know, just goes start using cube flow. A lot of teams can just pull that in and get

16:31.920 --> 16:37.680
going. But a specific challenge that teams face there is kind of the boundary between that

16:37.680 --> 16:45.120
infrastructure data and and the kind of ML ops tooling. And we see a lot of kind of,

16:45.120 --> 16:51.760
for example, example, like see a lot of auto ML systems that do really nice demos where

16:52.400 --> 16:57.920
you know, they'll say, okay, let me just drag in this training data dot CSV into my auto ML

16:57.920 --> 17:01.920
system. And then, you know, I have this amazing model now and it's productionized. But it's like,

17:01.920 --> 17:05.840
where did that training data dot CSV come from? That's actually the whole hard part here.

17:05.840 --> 17:11.280
And then how do I use that in production? And so, you know, practically like I want to

17:11.280 --> 17:16.560
calculate a feature on a stream. I want to share share something with my colleague. A lot of

17:16.560 --> 17:21.760
these elements are challenging. And and I think like getting started with the infrastructure.

17:21.760 --> 17:26.560
And then some of the just like core ML ops frameworks like cube flow is a great option. It's just

17:26.560 --> 17:37.840
a great way to get started. You know, kind of digging into the feature store and and you know,

17:37.840 --> 17:46.160
kind of what it really means technically. Yeah, I'm curious your sense for, you know,

17:46.160 --> 17:55.280
what are the kind of core components or or capabilities. I think at the highest level,

17:55.280 --> 18:00.080
like you can kind of group it into online and offline. And you know, those have different

18:00.880 --> 18:06.000
requirements. But I've, you know, refer, I think we actually talked about this at one point.

18:06.000 --> 18:12.320
Like, you know, there's, you know, different, you know, feature stores will do like automatic

18:12.320 --> 18:17.440
backfilling and, you know, have all different kinds of abilities. I'm curious what you,

18:18.720 --> 18:22.400
you know, and maybe the way to lay it out is in terms of, you know, what do you need when

18:22.400 --> 18:27.840
you're just getting started? And, you know, gives you kind of the, you know, 60% of the bang for

18:27.840 --> 18:38.320
your buck or your 80% and what are the capabilities that more mature teams tend to look for or need to

18:38.320 --> 18:47.520
build? Yeah, it's, it's very interesting because the space of needs is really large. So different

18:47.520 --> 18:54.800
teams need totally different things. And, and it really comes down to kind of what are their data

18:54.800 --> 19:01.280
needs for their models and the ML things that they're trying to build. So if you're a company where

19:01.280 --> 19:11.200
you have, you, if you're a company that is only doing kind of batch analyses, there's no real time

19:11.200 --> 19:15.680
component to your, to your company. There's no interaction, live interactions with the customer.

19:16.480 --> 19:23.600
The concept of a batch, batch feature stores, probably sufficient. And that's, it's not so much

19:23.600 --> 19:30.400
different from what you would get from a standard data warehouse and some kind of typical data

19:30.400 --> 19:36.800
pipeline and tools where things start to get more complicated is when you have, you really have

19:36.800 --> 19:44.000
this operational environment, this production environment on top of the analytic environment

19:44.000 --> 19:49.600
or as alongside it. And then you have to manage your machine learning development process

19:49.600 --> 19:55.360
in such a way that it interacts with that it plays well with the operational or the production

19:55.360 --> 20:02.640
environment. And so a feature store kind of, what is it? It's a data system built for supporting

20:04.480 --> 20:10.480
ML ops workflows. And so it operates the data pipelines that generate feature values,

20:11.040 --> 20:18.000
it persists and manages the feature data itself. And then it serves this feature data consistently

20:18.000 --> 20:26.800
across production, you know, online and development offline workflows. And so we think of it kind

20:26.800 --> 20:34.880
of as like a central hub for feature data and the metadata that is used across ML models,

20:34.880 --> 20:40.480
lifecycle and especially for sharing and crossing organization. So some specific things, you know,

20:40.480 --> 20:50.160
you mentioned, you mentioned that kind of backfilling. So, you know, feature stores are unique in

20:50.160 --> 20:58.720
that they map across the development environment and the production environment. And so when they

20:58.720 --> 21:04.880
have some special capabilities to allow when you add a new feature to automatically backfilling

21:04.880 --> 21:09.920
and calculate historical values of a feature. So when you're training a model on all

21:09.920 --> 21:15.920
logins on the past six months or all purchases in the last year or something like that,

21:16.480 --> 21:21.360
you don't have to wait another year for a feature to be calculated, right? You don't have to

21:21.360 --> 21:26.720
log that feature for a year. You can generate, you can continually register new features and have

21:27.440 --> 21:34.400
all of that training data be instantly available. And so that's a pretty big component

21:34.400 --> 21:38.960
of feature stores. But we break down the capabilities of a feature stores roughly into five

21:38.960 --> 21:44.560
components, right? A transformation layer, which takes your raw data and generates feature

21:44.560 --> 21:50.720
dollars, a storage layer. So that's kind of like feature store, the storage layer, which

21:51.680 --> 21:58.160
organizes those feature values and persists them for use, for retrieval online and offline.

21:59.200 --> 22:05.040
And then a serving layer that serves them online. So for real time serving less than

22:05.040 --> 22:15.760
so like low latency serving, monitored, etc. And to and to also power training data set feature

22:15.760 --> 22:21.920
retrieval to build a model to generate a training data set. So kind of a unified retrieval interface

22:21.920 --> 22:27.760
across the serving, across online and offline. So those are kind of the three main components that

22:27.760 --> 22:34.080
touch the data. And then a central registry that defines all of these features and contains

22:34.080 --> 22:38.160
that data and metadata, which is kind of like an immutable record of what was what was I using

22:38.160 --> 22:43.600
in production? What was available analytically at this time or that time? And a monitoring layer to

22:44.880 --> 22:50.160
ensure the correctness of features and the operational, you know, track the operational metrics of all

22:50.160 --> 22:58.640
of the data pipelines that are powering my model in production. Now a lot of the elements that you

22:58.640 --> 23:05.680
talked about have kind of traditional analogs within the enterprise data ecosystem. Data catalogs

23:05.680 --> 23:12.800
have gotten more popular. You know, certainly there's data warehouses, you know, snowflake,

23:12.800 --> 23:17.520
IPO, make sure that we all know about data warehouses, although that's been part of the enterprise

23:17.520 --> 23:24.720
data landscape for a very long time. But there's, you know, all of these kind of independent

23:24.720 --> 23:35.920
tools that have played a role in helping enterprises do similar kinds of things. Is it, is it, you know,

23:35.920 --> 23:41.680
easy to kind of put a finger on the difference between, you know, those standalone components

23:41.680 --> 23:48.000
and a feature store or are you maybe even seeing organizations, you know, take their existing databases

23:48.000 --> 23:55.200
and data warehouses and data catalogs and kind of build a feature store out of those things. Yeah,

23:55.200 --> 24:01.120
so those components make up, those components are reused by a feature store. So feature store

24:01.120 --> 24:08.880
really coordinates across, like across a common orchestration data transformation orchestration

24:08.880 --> 24:16.240
system or a warehouse for storage or a data lake for storage. And we don't reuse anything,

24:16.240 --> 24:21.920
we've run our own kind of serving layer. But the goal, it's kind of important to recognize that

24:22.480 --> 24:29.200
the goal of the feature store is to provide really, really good access to data in the ways that

24:29.200 --> 24:34.480
ML ops workflows need that data. It's not to replace existing data infrastructure. So it's actually

24:34.480 --> 24:41.120
quite important for the feature store to plug in and integrate quite nicely with what data

24:41.120 --> 24:47.440
infrastructure, a team company already has today that they're happy with. And, you know,

24:47.440 --> 24:53.280
this kind of goes back to actually like a lesson that I learned, I learned building out

24:53.280 --> 24:58.240
Michelangelo, you know, we would go to, we'd, we'd built Michelangelo, we would go talk to

24:58.240 --> 25:03.280
different teams internally, hey, you guys are building this kind of model. Can Michelangelo help

25:03.280 --> 25:09.680
your team out? And it was never the case that a team would say, hey, I want to migrate this

25:09.680 --> 25:14.800
existing thing that's working for me onto this other system that you're coming and telling me about.

25:14.800 --> 25:21.360
It was always, hey, we have some pain points and maybe we can build V2 of what we're building

25:21.360 --> 25:26.720
on your new system because that system solves all of these additional pain points and makes use

25:26.720 --> 25:32.800
of what is already working. And so this concept of being gradually adoptable and reusing as much

25:32.800 --> 25:39.520
of the company's existing data infrastructure such that there's as little duplication as possible,

25:39.520 --> 25:44.960
was quite important for a feature store. I think the biggest distinction though is the concept of

25:44.960 --> 25:50.160
now we're talking about operational environment as well. And so that's the big shift that a

25:50.160 --> 25:55.280
feature store also has to take into account. It's, it's, there's this concept of a catalog of

25:55.280 --> 26:01.760
operationally available, vetted, productionized signals features for use in models.

26:03.440 --> 26:10.640
And on the note of kind of this evolution, what does it typically look like to

26:12.400 --> 26:19.840
deploy one of these? So that conversation that you had with team at Uber, I imagine you're having

26:19.840 --> 26:25.520
various versions of that conversation with teams today. And what are you telling them? It looks

26:25.520 --> 26:33.760
like to eventually kind of make their way to, you know, dynamic, always available feature store

26:33.760 --> 26:43.920
in Irvana. Yeah, there's, so a tech con we have a couple of deployment models. And one of, so

26:43.920 --> 26:53.280
they range from a fully hosted cloud service to a, a managed cloud service that lives actually

26:53.280 --> 27:02.640
in your cloud account. So tech con is completely cloud based. And the, the distinction between

27:02.640 --> 27:09.760
those deployment models that I just mentioned is that in one, it's a little bit more similar to

27:09.760 --> 27:16.080
a snowflake model where tech con manages the whole tech con cluster, the whole feature store,

27:16.080 --> 27:21.840
we manage all the SLAs for it. You pass your data into it, it's storing the features and it

27:21.840 --> 27:27.520
will serve features to you. And so your data comes into tech con's account and we, and we manage the

27:27.520 --> 27:32.480
whole thing end to end. You don't need to have any engineers do anything internally to kind of

27:32.480 --> 27:41.200
maintain or support the tech on deployment. There's a separate deployment model, which is preferred

27:41.200 --> 27:47.760
by some organizations, which actually has tech on run in there, Amazon account, but still have

27:47.760 --> 27:54.720
our team manage that software. And this is becoming a more and more common deployment model for

27:54.720 --> 28:01.840
enterprise data infrastructure assets. It's, it's really, you know, have, have a company from the,

28:01.840 --> 28:09.440
from the outside, have their control plan talk into connect to a data plan that lives within the

28:09.440 --> 28:17.760
customers, AWS account or whatever it is. And within that, that there's a VPC where all that

28:17.760 --> 28:25.440
software runs and talks to the data sources internal to the customers account processes that data

28:25.440 --> 28:30.000
and serves that data all within the customers account. So their data never leaves their own account.

28:30.000 --> 28:34.960
And so you can imagine there's some larger enterprises that prefer deployment models like that.

28:37.600 --> 28:43.600
And maybe let's talk a little bit about what you're seeing in terms of the, you know, for folks that

28:43.600 --> 28:53.040
decide to go this route, what does the ecosystem look like? You've got some open source out there,

28:53.040 --> 29:02.000
particularly in the Kubernetes community in Feast. There are kind of rumblings that, you know,

29:02.000 --> 29:08.000
some of the cloud providers will incorporate feature store capabilities into their offerings.

29:08.000 --> 29:16.960
You know, what else are you seeing out there and what, you know, your, your offering is

29:17.680 --> 29:24.480
cloud-based. Does that, you know, does that disadvantage you when the cloud vendors decide that

29:24.480 --> 29:29.520
they want to offer this as a, you know, feature store as a feature? I mean, it's going to be a

29:29.520 --> 29:35.680
battle, but, you know, it's definitely not worried that they're going to build a better product or

29:35.680 --> 29:42.400
better feature store than we will. The, you know, the space right now, there's a handful of

29:43.200 --> 29:50.800
systems called feature stores, the most notable beyond. So we kind of coined the term feature store

29:50.800 --> 29:56.080
a couple of years ago when we published a blog post at Uber about Michelangelo and we talked a

29:56.080 --> 30:02.640
lot about this notion of a feature store. There's a couple of different projects that have come out

30:02.640 --> 30:08.400
and a number of kind of talks at conferences where different companies have, have talked about,

30:08.400 --> 30:12.560
hey, this is how we implemented a feature store internally. One of the most notable is,

30:14.240 --> 30:23.120
is Gojack on G, on GCP, they open sourced pretty lightweight, but very powerful feature store

30:23.120 --> 30:26.800
that is quite good and people should check it out. It's really easy to get started with that.

30:26.800 --> 30:34.320
That is based on Google right now. I'm sure it's going to be in other clouds quite soon as well.

30:34.320 --> 30:41.840
And then TechCon offering is more of like an enterprise-based offering. So, you know,

30:41.840 --> 30:50.960
with SLAs, hosting, you know, being on call all of the enterprise capabilities. And I think we're

30:50.960 --> 30:57.280
going to see the cloud providers and the big data companies come in this space quite strong.

30:57.280 --> 31:02.720
I believe that 2021 is going to be the year of the feature store. I can't tell you how many

31:02.720 --> 31:08.480
companies come to us asking for a feature store without, you know, having a great understanding,

31:08.480 --> 31:14.080
like originally about what a feature store is, what problems directly it solves for them,

31:14.080 --> 31:20.240
because they have a variety of problems and they know just, hey, I have so many data problems.

31:20.240 --> 31:23.920
How can the feature store help me out? And we have a lot of those discussions and just to help

31:23.920 --> 31:34.720
them get started in this space. Yeah, it's been an interesting evolution of the MLOB space

31:35.600 --> 31:42.480
in general. You know, just in doing this interview and kind of reflecting on the fact that this

31:42.480 --> 31:51.040
was two and a half years ago that we were talking about feature stores. The first wave of products

31:51.040 --> 31:54.880
in the space, and it's more nuanced in this, but a lot of them were kind of these workflow

31:54.880 --> 31:59.600
end to end. We're going to try to slurp up your entire process and automate it.

32:02.160 --> 32:10.560
And yet, when in my conversations with folks that were, you know, building and running these

32:10.560 --> 32:17.600
systems, you know, at Facebook and Google and Airbnb and others, one of the most important

32:17.600 --> 32:21.920
elements of what they're doing was this, you know, this feature store. Airbnb has Zipline,

32:21.920 --> 32:27.360
which is, you know, their kind of central repository. And I forget what it was called in Facebook,

32:27.360 --> 32:35.520
but they had theirs and Google had theirs. And yet, it's taken quite a while before, you know,

32:35.520 --> 32:43.680
you have started to see kind of commercial offerings in the space. Your company's relatively

32:43.680 --> 32:51.920
new in terms of go-to-market. And yet, it seems like I read 2021 is going to be this year where,

32:51.920 --> 32:56.400
you know, we're starting to see a lot more activity. And I'm curious to your take on why that is.

32:57.360 --> 33:00.400
Yeah, I think it's interesting because you think of machine marketing.

33:00.400 --> 33:05.200
It's going to be great for you. Like, you have this market that you know that you know is important

33:05.200 --> 33:10.640
and no one seems to be in it for a really long time, or I should say few seem to be in it because

33:10.640 --> 33:18.160
there are, you know, some folks, but a lot of what I've seen thus far has been folks taking, you

33:18.160 --> 33:22.560
know, older technologies or technologies that weren't necessarily purpose-built and trying to

33:22.560 --> 33:30.480
apply them to solving this problem as opposed to taking a purpose-built feature store approach.

33:30.480 --> 33:36.800
Yeah, I think part of the trickiness here in one factor is just when you think of machine learning,

33:36.800 --> 33:42.800
you think of models, and you think of, you know, when people get started, what's the sexiest thing

33:42.800 --> 33:47.280
to work on? I want to get started on these cool models. And, you know, some people just jump straight

33:47.280 --> 33:52.720
to deep learning, which you know, I'm sure you've had a ton of people on the podcast say the way

33:52.720 --> 33:57.120
to do it is actually start as simple as possible with the simplest algorithm and then you get more

33:57.120 --> 34:04.880
complicated after that, right? And so what we see is the teams, there's just kind of like this

34:04.880 --> 34:14.400
anti-pattern in industry where teams kind of get started with kind of focusing on stuff that's

34:14.400 --> 34:22.000
slightly more advanced in what their needs actually are. And they kind of over-invest in some of the

34:22.000 --> 34:30.000
model stuff at first, which ends up being actually operationally easier to manage than the

34:30.000 --> 34:38.800
data pipelines that power these models. And so the teams that come to us, or they kind of say,

34:38.800 --> 34:42.080
hey, we actually thought we could repurpose a lot of our existing data infrastructure,

34:42.080 --> 34:46.560
just like plug it in directly to the models. But what actually happened was that's now where we're

34:46.560 --> 34:51.680
having a ton of pain, a ton of friction. And that's the core thing that's grinding the innovation

34:51.680 --> 34:58.560
from our data science teams to a halt. So, you know, we see a feature store to help us out there,

34:58.560 --> 35:01.840
but we already have this investment in this model stuff and we probably should have

35:02.960 --> 35:09.920
done it the other order or kind of done those in parallel. And so it's not a super obvious,

35:09.920 --> 35:15.760
there's all these kind of roadblocks and challenges you face that are not super obvious up front.

35:16.720 --> 35:20.240
But when you hit them, it kind of just grinds things to a halt.

35:26.560 --> 35:29.120
I had a follow-on question to that.

35:29.120 --> 35:41.760
You know, one of the things that we have that I think we see that is like actually quite challenging

35:41.760 --> 35:48.640
for people to kind of makes, it really makes it obvious what some of the data challenges are when

35:48.640 --> 35:55.200
putting machine learning into production is that there's kind of just a variety of elements,

35:55.200 --> 36:00.400
you know, the development and production environments are not the same. So you kind of have to map

36:00.400 --> 36:06.080
between those. And then we see teams that have kind of constraints from what can be done in

36:06.080 --> 36:10.960
production that affect what the data scientists are even allowed to experiment with. And that

36:10.960 --> 36:15.520
really kind of just like constraints, you know, what they're able to do. Deploying these systems

36:15.520 --> 36:22.320
is really complex as well. And even just like monitoring and validation of these systems,

36:22.320 --> 36:26.480
not a solve problem. So when things break in machine learning, it tends to be kind of the data

36:26.480 --> 36:32.480
pipelines that break and investing in. And so these problems are super hard to debug also.

36:32.480 --> 36:37.760
So it kind of investing in that layer ends up going paying off in a big way when you're really

36:37.760 --> 36:44.240
trying to depend a core business process on these systems. And the question that I was looking for

36:44.240 --> 36:54.560
earlier was right along those lines, do you you mentioned platform teams earlier as folks that

36:54.560 --> 37:05.840
are kind of owning these production feature pipelines. Is that the primary person that is that

37:05.840 --> 37:10.880
you see kind of leading the the feature store charge or does it does it ever come from data

37:10.880 --> 37:18.640
engineering and the data infrastructure side of the house or good question. So the so there's

37:18.640 --> 37:23.360
a couple of things like why do people adopt feature stores in the first place. And so it kind of

37:23.360 --> 37:29.040
comes. There's kind of two paths. There's teams who are just trying to get this one model,

37:29.040 --> 37:34.080
you know, they have this important use case where this fraud system and we need to be able to

37:34.080 --> 37:39.120
calculate features in real time and use our historical features. And it's just like a crazy

37:39.120 --> 37:43.440
engineering problem for us and we just want a system that can handle that for us. So that's that

37:43.440 --> 37:50.400
kind of component. Another path for people who are adopting feature stores is when they are

37:50.400 --> 37:55.200
trying to build out their ML infrastructure properly and they're doing their research and they

37:55.200 --> 38:00.640
identify, you know, I was going to conversation with a big bank the other day and they're showing

38:00.640 --> 38:05.760
their stack and right in the center they're kind of ideal stack and there's kind of data infrastructure

38:05.760 --> 38:10.080
feature store feature catalog right in the center and then some of the modeling elements

38:10.080 --> 38:14.160
and the application elements on top. So they're just trying to take a very thoughtful approach to

38:14.160 --> 38:19.840
building the right infrastructure and the right tooling. What we want to enable the goal is to

38:19.840 --> 38:27.680
enable data scientists or analysts who ever are building these features to be able to to go

38:27.680 --> 38:32.640
end to end and get their models all the way in production without requiring without throwing

38:32.640 --> 38:37.840
things over the wall to the engineering teams for every single change that they have. You shouldn't

38:37.840 --> 38:43.920
need production or data engineers really have to know or be involved in any way when a data scientist

38:43.920 --> 38:49.600
is making a change to their model and production. When that happens, we've seen a real kind of shift

38:49.600 --> 38:57.760
in almost like the almost like the roles it kind of makes data scientists much more owners of their

38:57.760 --> 39:02.800
work in production rather than rather than being in a position where yeah I handed it off to that

39:02.800 --> 39:08.160
team and they're handling it. I don't know why it's not working right now and so that has been

39:08.160 --> 39:13.840
like a really big cultural shift in teams that have adopted this kind of adopted this technology

39:13.840 --> 39:19.840
that allows data scientists to kind of get stuff into production on their own. So we like to kind

39:19.840 --> 39:24.320
of have the people who build the systems be the owners of those systems and then there's just

39:24.320 --> 39:30.000
instances where you you have so many people who depend on these systems that you might want to

39:30.000 --> 39:35.120
centralize some components of that ownership. Is it now like us to the transformation has been

39:35.120 --> 39:40.480
happening over the past 10 years or so with traditional software engineering and DevOps and

39:40.480 --> 39:47.600
having these pizza box teams that you know exactly like cycle of their services. Exactly and

39:47.600 --> 39:55.200
yeah and people you know sometimes company will ask okay what's the the right operational ml stack

39:55.680 --> 40:00.880
and you know I don't think the space of needs is so so large I don't think there is one and

40:01.920 --> 40:06.880
to me it's kind of like what's the right software stack period in question mark right and it's

40:06.880 --> 40:13.760
just like you know it depends and the answer is always it depends and so you know I kind of like

40:13.760 --> 40:20.560
give guidance to companies or when you're trying to figure out what the right approach is talk to

40:20.560 --> 40:24.800
someone who's done it before and they can kind of walk you through a lot of the challenges that

40:24.800 --> 40:31.040
you're likely to encounter there's a lot of a lot of bottlenecks that you will hit when you have

40:31.680 --> 40:36.240
you know data scientists and engineers starting to collaborate for the first time or when you're

40:36.240 --> 40:40.560
trying to buy some software that you've never had to buy before you don't have an owner for the

40:40.560 --> 40:47.840
software there's just like a number of elements that come to cause a lot of challenges without

40:47.840 --> 40:52.080
being kind of thoughtful about things ahead of time and on the data side we think obviously we

40:52.080 --> 40:58.800
think feature stores are like the right way to kind of unlock a lot of the core ability to put

40:58.800 --> 41:05.200
models in production features in production and so that's kind of the key reason why we got started

41:05.200 --> 41:12.400
with the feature store yeah yeah I mean there's an interesting paradox in there where you know earlier

41:12.400 --> 41:19.520
you were alluding to folks that were choosing more complex technology than they needed for the

41:19.520 --> 41:23.520
thing that they were doing the thought in my head as you were saying that was yeah I need to deploy

41:24.400 --> 41:31.920
you know you know single you know team internal web app I need Kubernetes right and you know at

41:31.920 --> 41:38.720
the same time your advice is talk to folks who have kind of gone down the road and

41:40.160 --> 41:49.760
consider things that you're likely to run into as you're making your plans and and you know

41:49.760 --> 41:55.920
that in many cases is what you know leads folks to kind of overbuild right there kind of thinking

41:55.920 --> 42:01.360
far into the future at least that's an optimistic you know view rather than kind of playing with

42:01.360 --> 42:06.080
cool what actually mean like talk to someone who knows what they're doing who can tell you hey don't

42:06.080 --> 42:10.480
overbuild someone who can someone who can say you probably shouldn't be investing in that because

42:10.480 --> 42:15.840
you don't even have you don't even have your data in the right place or I know where I'm where

42:15.840 --> 42:22.400
I'm the question and I'm trying to get to is like you know how does someone know if they should

42:22.400 --> 42:29.040
even be thinking about a feature store at all or if it's you know a step or or or five ahead of

42:29.040 --> 42:34.880
them and it sounds like the first question is you know do you have your data house in order you know

42:34.880 --> 42:42.160
if you don't worry about that first right yeah I think the core kind of like the two biggest

42:42.160 --> 42:49.680
things are are you building models that need to interact in real time so are do you have some online

42:49.680 --> 42:54.320
component to your machine learning application to your operational machine learning application

42:54.320 --> 42:59.680
that's when you that's just like a key like a pretty good indicator that okay I'm going to have

42:59.680 --> 43:03.760
I'm gonna have this production environment I'm gonna have to have a real time real time serving

43:03.760 --> 43:09.920
on this machine learning application very likely includes kind of an online data storage

43:09.920 --> 43:13.520
element for my features which I'm gonna have to manage and it's a data scientist probably haven't

43:13.520 --> 43:22.400
done that before so that's kind of one pretty important kind of path and then second is do we have

43:22.400 --> 43:29.440
do we have more than a handful of models and more than a handful of features powering those right

43:29.440 --> 43:36.080
uh especially if they're being shared across those models it it goes from I've seen teams kind of

43:36.080 --> 43:42.560
like manage their collaboration with you know a Google spreadsheet and they have a list of

43:42.560 --> 43:48.720
features that is okay this pipeline is here and this feature does this and just ask this person

43:48.720 --> 43:54.000
if you want to use it or if you want the code for it and uh and so I've talked to them and said

43:54.000 --> 43:59.280
hey this is working pretty well for us now and uh that's great when that works for you and then a

43:59.280 --> 44:04.400
month later they call me up and then they were like okay so now we're at uh you know a couple hundred

44:04.400 --> 44:08.640
rows of this thing and things are kind of going crazy and we need a better way to manage this so

44:08.640 --> 44:12.960
it's almost like when you get that scale and you need some kind of like you need to start thinking

44:12.960 --> 44:19.120
about collaboration between your team and you want to have some efficiencies of scale as well.

44:25.440 --> 44:31.120
Features you know one of the uh you you brought up uh kind of deep learning earlier in the

44:31.120 --> 44:37.600
conversation is kind of a side comment um you know deep learning is kind of notable for not being

44:37.600 --> 44:46.240
as dependent on features and feature engineering as traditional ML models um is a feature store still

44:46.240 --> 44:54.560
relevant in that world or no not as well. Yeah good question um so we see uh teams use feature

44:54.560 --> 45:02.560
stores in two ways for when they're doing deep learning. One is uh to to host pre-computed parts

45:02.560 --> 45:08.640
of uh their model you can think of it as like use a feature store to do my embeddings properly

45:08.640 --> 45:14.480
and uh and pre-computed my embeddings and then look them up in production so that's a really big

45:14.480 --> 45:18.800
element of a feature store is kind of like making that stuff operationally possible and really easy

45:20.560 --> 45:24.640
and then a second component is making sure the data is available so you know you may have a

45:24.640 --> 45:33.440
uh deep learning model that let's say it's a uh recommendation model and it does uh it needs

45:33.440 --> 45:40.480
some input from for example your current search query right that's one one input to the model

45:40.480 --> 45:46.960
and then some also some information about the user itself or users themselves and maybe some

45:46.960 --> 45:52.720
information about the current page or the current product that they're looking at that model needs

45:52.720 --> 45:59.120
to have access to all that information that historical information about the user item etc and

45:59.120 --> 46:04.400
it's really the feature store's responsibility to get that right information at the right time

46:04.400 --> 46:09.520
and deliver that information the those data uh to that model and they're effectively features

46:09.520 --> 46:14.320
at that point that we're passing into the model though they're typically less processed features

46:14.320 --> 46:19.360
than uh you might have in a non deep learning uh kind of model does that make sense you got

46:19.360 --> 46:23.760
you get what I'm saying where you know you bring that data up and make that available to the

46:23.760 --> 46:30.320
model and that's really um uh that's really kind of the role of the feature store for deep learning

46:30.320 --> 46:36.640
models typically yeah well what it made me think of is um you know presentations that I've seen

46:36.640 --> 46:41.840
from folks at like Google for example where they talk about one of the main issues that they see

46:41.840 --> 46:49.840
in production is um you know for any kind of model deep learning or otherwise is the feature data

46:49.840 --> 46:57.040
just changing in semantic or being semantics or being missing or um you know before you

46:57.680 --> 47:02.720
you know had you know something as nulls and then you change it to empties or whatever it's just

47:02.720 --> 47:10.160
random things that that happen in a pipeline that no one sees and it's um it sounds like what you're

47:10.160 --> 47:18.080
saying is that people use the feature store to kind of manage uh that uh that infrastructure that

47:18.080 --> 47:24.560
that process and and specifically the the data part yeah having a common way to reference like

47:24.560 --> 47:29.280
a common way to literally specify what data does this model need what data does it need in

47:29.280 --> 47:35.680
production yeah I'm making a prediction for this user and this item how do I know which data to

47:35.680 --> 47:40.320
pass into the model for that purpose for this this data for this user and this data for this item for

47:40.320 --> 47:47.200
example um but then all of that data that does you know we do use for that model you know we think

47:47.200 --> 47:51.920
of it as kind of making it like operationally ready for for machine learning consumption for your

47:51.920 --> 47:58.400
actual ML application where there's a bunch of things you want to do uh in terms of like validating

47:58.400 --> 48:03.760
that data monitoring it for drift when we talk about monitoring it for drift it's like monitoring

48:03.760 --> 48:07.680
it compared to you know how the data looks today compared to how it looked last week and make

48:07.680 --> 48:13.120
sure the data doesn't look completely different but also does this data look similar to the data

48:13.120 --> 48:18.000
that the model was trained on in the first place and you know is there are there any indications that

48:18.000 --> 48:24.320
this model is um starting starting to get a completely different data than it expects in which case

48:24.320 --> 48:29.360
we don't really have any guarantees about its behavior and it's you can't really expect non

48:29.360 --> 48:38.240
erratic behavior from a model in in that situation mm-hmm awesome awesome uh well great stuff here

48:38.240 --> 48:44.720
any uh kind of parting thoughts or you know for folks that want to dig in deeper to this where they

48:44.720 --> 48:51.680
should look or um words of wisdom being uh a couple of years into this journey well or more than

48:51.680 --> 48:56.640
a couple years into this journey yeah i would say i would say start simple and um yeah for

48:56.640 --> 49:02.560
your interest in learning more about feature stores um or getting started with them uh come to

49:02.560 --> 49:08.480
tecton.ai and uh and just leave us you know get in touch and uh and we can chat and see how we can

49:08.480 --> 49:15.680
help awesome well mike uh wonderful to catch up with you and yeah i want to see all the cool things

49:15.680 --> 49:33.600
you guys are up to yeah thanks a lot it's been fun awesome thank you

