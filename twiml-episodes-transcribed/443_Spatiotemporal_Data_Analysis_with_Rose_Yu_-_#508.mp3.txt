All right, everyone. I am here with Rose. You Rose is an assistant professor at UC San Diego. Rose, welcome to the tool AI podcast. Thank you.
I'd love to have you start by sharing a little bit about your background and how you came to work in machine learning.
I'm currently a assistant professor at UC San Diego Computer Science Institute. I did my PhD at USC Computer Science and then I finished my postdoc training at Caltech Computer Science and Mathematics.
My machine learning journey started way earlier when I was an undergraduate, when I participated in an undergraduate research project and was able to publish a paper at AAAI, which is one of the top AI conferences almost 10 years ago.
I started my journey in machine learning and throughout my journey, I got a lot of mentorship and help from my advisors, postdoc advisors, my collaborators and students, and that's how I landed here.
Nice, nice. Tell us about your research interests. What do you focus on from a research perspective?
Absolutely. So my research focus on advancing machine learning, algorithms and methods for analyzing large scale time series and spatial temporal data.
So specifically, we develop research in deep learning, tensor methods, non-combat optimization to understand dynamical systems.
We apply these methods to solve challenging problems in climate science, in transportation, and many other physical science areas.
So compare with traditional applications in machine learning such as image data or text data, spatial temporal data has their own unique challenges.
Often times, they are governed by certain physical processes underneath. So the reason research trust of our lab is called physics guided AI, where we aim to integrate first principle methods from physics into data driven machine learning models such that they are more accurate, more physically consistent and more trustworthy.
So maybe we can start by having you talk about some of the use case areas that you apply your research to just to give us some context.
Sure. So at an Indian poll, in climate science, climate models are often used to understand the evolution of atmospheric dynamics. However, climate models at higher scale space and time resolution are extremely time consuming to simulate.
And you're only running a climate model at full scale across the globe takes a couple months. So this is already too late when we want to understand the change of the climate, the weather or to you on, you'll make predictions of what going to happen in atmospheric environment.
So one of the research a project was published in KDD 2020 and I clear 2010, 2021 is about developing deep learning models that can speed up this process.
Essentially, we want to build deep learning models that can emulate the evolution of climate simulations and these climate simulations are typically governed by partial differential equations that describes underlying physical processes.
So the main challenge is if we just used a vanilla deep learning model, they would not be able to capture the physical characteristics of the underlying phenomenon. So in our example, we use the hybrid models to borrow ideas from physical sciences, such as integrating ideas about
computational fluid dynamics or integrating ideas about symmetry into deep learning. So in this way, our deep learning models can not only emulate the evolution of, for example, turbulence, which is a very common phenomenon in climate.
It will not, it will also be able to predict values that are physically meaningful. So at example, we can measure when we try to predict the turbulence evolution, which is a very common in clouds, evolution in ocean current evolution.
So when you say evolution, you're primarily referring to just the way it develops over time and that this is where kind of the time series element comes in exactly. So there are basically values that are changing over time.
So mathematical, it's called dynamic or system. And when we try to develop basically describe the changing these values. And that's what I meant by evolution.
Yep. Okay. So, you know, one in the one about KDD papers, what we showed is that, you know, if you just predict, for instance, the evolution of turbulence, velocity, right, you're essentially predicting a video right into the future, given the past friends of video.
However, if you just use a video prediction methods that are developed out of computer vision community, then the predicted values of this video are not able to capture the correct energy spectrum of the underlying turbulence.
And in turbulence community, this kind of energy cascade or energy spectrum is critical to describe the underlying physical characteristics of the system, whereas if we use our hybrid model, where we combine ideas from physical modeling and deep learning, our model is able to generate much more physically meaningful predictions.
And our predicted energy spectrum just matches well with the ground truth.
And so just so I understand the setup here is the key distinction that you're making between a model that's based on video and a model that's maybe a higher dimensional model or are using video in both cases, but in one case, you're not using the physical knowledge that you have.
And in any other case, you're incorporating that physical knowledge.
Yeah, it's a second case where, you know, both models are fed with the same information, whereas, you know, the natural video, because it's very complicated.
We have, you know, many objects interacting with each other. It's very difficult to describe them with certain equations or certain governing laws, right.
And in turbulence, the nice thing is that we know the underlying governing equation, and we have a lot of techniques from computational food dynamic community that we can exploit.
So by exporting this type of knowledge, we can improve our predictions by significant amount.
You mentioned space, your temporal data, it sounds, I'm inferring from that that the differential equations that you're using or the partial differential equations that you're using are relative to both space and time.
Correct.
And so how do you incorporate in those that physical knowledge or those partially partial differential equations.
Yeah, great question. So there are multiple ways, right. So in the community paper, what we basically leverage is that, you know, the multi-scale modeling.
We actually did not use the equation themselves, but rather we're looking at how people usually approximate these solutions of equations.
So we found that there are basically convolutional operators that are computed over space and time. And this in CFT community was called the spatial averaging or temporal averaging, right.
And more, I guess the acronyms are, you know, rents, LES coupling.
So the rest LES coupling, the Reynolds averaging L is large edit simulation, essentially calculating the space and time average using convolution operator.
So what we did is that, you know, instead of using deep learning to approximate the partial differential equations themselves, we're going to approximate the convolution operator by replacing this traditional design operators.
With trainable neural networks, which follows down to convolutional neural nets. So then we have separate convolutional modules, she captured different scales of turbulence.
And by doing so, we can model the multi-scale behavior in the turbulence and generate much better prediction.
So that's one of the ways we can exploit the underlying physical physics. But I clear paper was was reasonably published is about, you know, looking at the symmetries in a partial differential equation, right, because, you know, if we think about partial differential equations.
There are a lot of symmetries. And by symmetry, what I mean is, if I have a solution, that is a solution of the partial differential equation. And I can apply certain transformations to this equation by, for example, shifting by certain amount or rotating by certain amount or scale it up by certain amount.
And this kind of transformation will change the equation themselves, but there will not change the solution by itself. So that's a symmetry in the solution of the PDE.
And what we found out is that, you know, if we can incorporate the symmetries into our deep learning model, we can also capture the underlying physics, right, because there is a notation theorem that links the conservation laws with symmetry, essentially saying that for every symmetry, there is a conservation law.
The translation time translation symmetry will correspond to energy conservation. So, so if we can incorporate this type of symmetries into deep learning, we naturally satisfy conservation laws, which are very important in physical model, right, and this idea is not.
The symmetry across properties, meaning, you know, between the time and the energy properties of the system, or is it within the time domain or within the energy domain, you're exploiting symmetries.
So it depends on what type of symmetry groups that you are either considering, right, so, for example, if you are considering the symmetry on the long time translation that is only on time, but if you consider for the gallon transformation, which is basically about space and time, right, then the scaling is about a different transformation on the input.
And this idea of exploiting symmetry in deep learning is not new, so the reason, for example, convolutional neural networks are so successful in modeling image data is that it leveraged to translation symmetry in the spatial domain.
Similarly, the reason why RNNs are very powerful in modeling sequence data is that it has built in time translation symmetry.
And graph neural networks are very powerful in modeling graph data or set data, because it has, you know, intrinsic permutation symmetry.
So this idea of incorporating symmetry in deep learning is not new, but what we did is to generalize this idea to the system to model space and time data that is basically governed by partial differential equations.
And use this model to predict evolution of turbulence, the future states of ocean currents, or even forecast the future trajectories of autonomous vehicles.
Got it. And so how exactly did you incorporate the symmetry properties into the deep learning models that you built.
So that's actually the whole paper is about. So, you know, one idea is basically right think about how convolutional neural networks is able to incorporate translation symmetry and that's way sharing.
And the same thing, you know, basically within the same filter, they are different ways, but across different filter, they use the exact same way. And that basically allows us to incorporate translation symmetry in complex.
So we can apply the same idea to other kind of symmetry groups, for example, if we wanted to incorporate scaling symmetry. Now we basically need to design the filters in the convolutional architecture such that they're shared within, you know, different skills.
So we have to deal with different kind of coordinates in the in the autonomous vehicle paper or the echo paper echo very continuous convolution, what we did is to work in a polar coordinates instead of the Euclidean space, right.
And the model basically the scaling in terms of angle and the radius. And then we can share weights along basically different on like radius, but then have different weights with different angles.
So in the case of the so that is the paper that you're referring to is it, are there separate papers for each of these use cases that is incorporating the symmetry information or is it is the paper primarily about methods to incorporate the symmetry into the dynamical models.
That's a nice question. So it's a better both right because we often, you know, we conduct a use inspired research, you know, where we often develop method inspired by certain use cases.
So we have, you know, two paper that I clear, which about incorporating symmetry and the first one is about, you know, incorporate in different symmetry groups into the sequence models for forecasting video is essentially for turbulence velocity fields and for ocean currents.
Right. And, you know, obviously these symmetries are derived from PDEs and Navi Stokes equations, but we would imagine these methods that would develop our generically applicable to similar type of data, right.
Another kind of the other paper that we published about equivalence continuous convolution is about point cloud data, right. So we have point cloud collected about from autonomous vehicles using radar, right. And we can basically work in a polar coordinate framework.
And then we design equivalence continuous convolution, which essentially allows us to model rotation symmetry and scale symmetry in in this point cloud data.
So we basically tested our method for the autonomous vehicle partition tasks and as well as the pedestrian trajectory, tradition tasks, but we also imagine that, you know, this method would probably be useful for other kind of point cloud data.
I think your previous answer anticipated a question that I was starting to have. And that was, you know, when you talk about these symmetries, there are symmetries that
we know kind of exist based on the properties of the systems of PDEs. And then, but there's a separate type of symmetry that kind of emerges from the data itself.
And you're developing methods to kind of handle both of them are they are they totally separate use cases or are they kind of ultimately linked by the data that the PDEs create.
That's very great observation. So, so actually, you know, there are basically multiple type of symmetry that can exist as you alluded to.
And one is basically derived from partial differential equations, right, then we can analytically basically write down what are the symmetry has a set of equations satisfy. And that's what's used again, you know, the, the, the actual paper, incorporating symmetries into the dynamics models.
But what we showed you that even though, right, sometimes we have data where we have no idea what are other actual equations that governs it, for example, ocean currents.
We only know approximately that maybe Navista equations are the governing equation ocean currents. But there are because the underlying processes are so complicated.
And we cannot write out all the possible symmetries of this data. So, but the model still performs well in this case, that just means even with approximate symmetry or some very, you know, vague idea of why it can help it will help in terms of prediction.
So, that's the first part. And the data symmetry is about sometimes we have some intuition of the symmetry in the system that we want to model. For instance, in, in the time of the vehicles, we cannot derive the equations that captures the motion of Tom's vehicle because it's so complicated.
But we have some intuition of what kind of symmetry can exist in driving, right, for instance, when we drive in the North America, right, and we wanted to turn right and we automatically know how to turn right.
And then suddenly, let's say, if we move to, to south atmosphere, right, then we drive in Australia, for example, and we still wanted to turn right. But our brain can automatically adjust this change of reference and still be able to recognize that we can turn right.
Even though we're in a complete different reference point, right. So then this kind of intrinsic or implicit symmetry is built into our reasoning framework.
And then we can incorporate this kind of symmetry also in our model to improve predictions.
You mentioned that we don't have the equations to model ocean currents. And this is maybe a bit of a digression, but that's somehow surprising to me, just thinking about like we, we, we know a lot about, for example, modeling air currents and weather.
We do a pretty good job at that. I would have thought that ocean currents would be pretty similar and we have all those equations, but it sounds like that's not the case.
Well, we were closely with climate scientists and what they taught me that is the climate models are not as good as you thought.
And that's why there are so many great challenges that we need to work on.
Got it. Got it.
And so you mentioned, you mentioned convolutional neural net, you mentioned grass, you mentioned RNNs, it sounds like your work is primarily focused on using convolution operators and translational symmetry, or are you working with these other kinds of networks as well.
Now, we actually develop our own network, right? That's what I'm trying to say, like, you know, as an example of how symmetry was incorporated into deep learning team, preparation in a CNN, the RNs are exactly these examples, but these are only focused on translation symmetry, right?
And general symmetry, such as, you know, rotation, symmetry, scaling, symmetry, and even continuous images in lead groups, there are no neural networks that can do that. So that's, you know, basically our contribution, we are designing new type of neural networks that can do that.
And obviously get on other people's work.
I thought I had heard that you somehow mapped these types of translation onto the convolutional convolution operators, but.
Yeah, so yes to me, the one of them, for example, is called convolution, but it's not the regular convolution.
So I stood on the work of from condo and traveri, right, and many others, you know, work about group convolution, right, so it's a different type of mathematical operator.
Got it. And so then can you talk a little bit about how you get from the mathematical representations of come of convolution or of symmetry or
the translation that you care about to the network architectures that you developed.
So yeah, basically, you know, once we came up with the right group convolution, right, which is the type of, you know, mathematical operator.
So you can implement them in, you know, neural networks through either tensor construction or matrix multiplication.
Once we do that, we basically divine a forward pass using the deep learning framework such as part towards, and now we can just, you know, fill it up as a module in a deep learning, you know, neural network.
Okay, and you mentioned tensor methods as being one of the tools that you use, can you talk a little bit more about that.
Sure, so the tensor methods actually came out of my PhD work, my PhD work was about, you know, developing tensor methods to understand spatial temporal data.
Because tensor methods are, they're not deep message, they're shallow methods, right, but the nice thing is that they provide much more interpretable predictions.
You can understand, you know, when we look at the prediction of a deep learning model, sometimes we're puzzled like why this model is making this kind of prediction, whereas tensor models a shadow model, it has multi linear structure between the input and output, and it's easier for us to diagnose this model and understand what is contributing to the prediction of the model.
And another thing about tensor model is that, you know, it generalized the matrix method, which usually, you know, matrix methods models pair watch relationships think about the Netflix challenge in movie reviews where using matrix compilation, you can model the pair watch relationship between user and movies.
But a lot of times when we model state spatial temporal data, they're higher order correlations, right, there are correlations among different locations and their correlations among different timestamps and they're also correlations among different features of variables.
So, matrix methods are inefficient to model this kind of higher order correlation, and that's why that's where tensor methods shine in this region, it allows us to model, you know, triplets information or even higher order correlation, but all at the same time generate interpretable models to help us understand what's going on.
And I guess another kind of relatively exciting direction is that, you know, deep learning is mostly about non-converse optimization.
So, unfortunately, a lot of the optimization techniques and analysis were developed for convex regime. So, tensor methods are non-converse, and it allows us to, it provides us with a nice platform to study this group of non-converse optimization problem.
And hopefully the insights that would derive from understanding tensor methods can be generalized to understanding deep learning.
Nice, nice.
You've also got a paper focused on looking at the uncertainty within these deep spatial temporal models.
Is that built on the work that we've been discussing thus far?
So, there are, they are basically related, but they're not the physics based model yet.
So, this is just the first step for us to look at the risk assessment in uncertainty quantification.
Actually, in terms of physics guided AI, the model that we use for this paper is the slightly different technique.
It basically learns the residuals between the physics based model and the ground truth. So, you asked about how to incorporate physics into deep learning model.
And this is the third way, right, because we talked about learning the convolutional operators, we talked about incorporating symmetries.
And the third way that we did is to learn the residuals to learn the correction term between the ground truth data and the physics simulators.
So, in this paper, which is originally published in IKVD, it's about, you know, forecasting COVID-19 or forecasting air quality, where we have very sparse data set.
Right, in these regions, you know, we cannot have a million of data points to train.
And using a deep learning model, obviously, will not perform well, because it's in a small data region.
So, what we did is to incorporate, you know, physics models as a prior and learn the correction terms between the ground truth and the physics based model.
So, in that way, we can use the physics model as a starting point, and we don't need that much data to train.
And in these regions, obviously, because we have fewer data points, and it's important to characterize not only the prediction themselves, but also the confidence interval.
So, imagine if you want to forecast a number of infectious cases in the next four weeks.
It's not enough just to say the next four weeks, infectious cases will be, you know, X amount.
But we also need to say the next four weeks, infectious cases will be X amount with 90% confidence.
So, that's what I mean by uncertainty quantification.
And it's extremely important in, you know, special time for forecasting in physics based model as well.
Right, it gives us a tool to assess the risk that's attached to it.
So, what we did in this paper is to investigate in a benchmark study study what type of uncertainty quantitative techniques that we can use in the context of deep learning.
Okay, and what did you find there? Did you, did you, you kind of looked at the landscape, but did you find some methods that you thought would be interesting for the kinds of problems that you care most about?
Yeah, exactly. So, so you really, right, when people think about uncertainty quantification for deep learning, the two goal method is based in neural networks.
And you really, you know, based in neural networks, there are different techniques such as Monte Carlo dropout, which is approximate based on inference methods.
And there is also what exact basic information master based on Mark of chain Monte Carlo.
So, what we did in this paper is to look at two group of methods.
The frequent is the UQ methods and the basic is UQ method.
So, what we found is that, you know, within the frequent is the UQ methods, there are classic techniques based on bootstrap or based on interval scores.
And there are actually quite competitive in generating the confidence interval, but then, you know, they often provide very wide confidence interval, which means they have good coverage of the forecast, but they may not have very high confidence.
As, you know, in a basic regime, we looked at, you know, the stochastic gradient MCMC, which is the type of Monte Carlo method.
And we also looked at Monte Carlo dropout, which is a approximate based in inference method for UQ.
And what we found is that, you know, the, the mark of chain Monte Carlo methods, they give very good confidence intervals and they also have a good coverage.
However, it takes a long time to train because we have to run the deep learning methods multiple times and to collect the samples.
So, it's a very time consuming process and then Monte Carlo dropout provides, you know, good coverage.
But it doesn't give the good intervals in terms of the uncertainty quantification, right? So, the conclusion.
Exactly. So then, the conclusion is that there is no winner takes all situation in uncertainty quantification.
It's really about the balance in computation, in sample complexity, in the coverage of the prediction and the accuracy.
So, therefore, we provide a recipe for the practitioners in our paper, right? And you can just look at the recipe and, you know, deciding on what method you want to use for uncertainty quantification.
Kind of like a flow chart. Yeah.
Got it. Awesome. Awesome.
So, maybe we can wrap up by having you share a little bit about future directions and what you're seeing as being exciting in the space and where you want to take your research.
Sure, absolutely. So, as I mentioned, you know, the physics space AI is just just at its beginning, right? The idea of incorporating, you know, domain knowledge and physical laws into machine learning model is a very exciting direction.
And right now we have been only focused on, you know, just generating predictions or emulating the models.
The future of this direction, what about decision making as well? How can we leverage, you know, existing physical models combined with data to matter better decisions, right? And that will involve, you know, new techniques such as the basic optimization reinforcement learning.
And even techniques from mechanism design economics, right? These are the new kind of direction that we want to push for. And again, the, the key there is to not only blindly trust the data and develop black box models.
But rather to understand online governing process of the data and to exploit the known domain knowledge in this data in physical laws in conservation laws and all kinds of principles that we have to build better models, right?
In this way, we can, you know, really advance, I guess, one of our passion is to use to use AI to advance scientific development and engineering, right? So if we wanted to really do that, we really need to develop models that can understand the physics that can understand the science behind it and can be trustworthy for the domain scientific to use them.
Awesome. Awesome. Well, Rose, thanks so much for taking the time to share a bit about what you're working on. It's great to learn a bit about your research.
Thank you so much for this interview. Thank you.
