WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:33.460
I'm your host, Sam Charrington, today we're excited to continue the AI for the benefit

00:33.460 --> 00:37.680
of society series that we've partnered with Microsoft to bring you.

00:37.680 --> 00:41.880
In this episode, we're joined by Peter Lee, corporate vice president and Microsoft

00:41.880 --> 00:45.640
research responsible for the company's healthcare initiatives.

00:45.640 --> 00:49.960
Peter and I met a few months ago at the Microsoft Ignite conference where he gave me some really

00:49.960 --> 00:53.280
interesting takes on AI development in China.

00:53.280 --> 00:56.960
We referenced those in the conversation and you can find more on that topic in the show

00:56.960 --> 00:57.960
notes.

00:57.960 --> 01:03.400
This conversation those centers on three impact areas that Peter sees for AI and healthcare,

01:03.400 --> 01:09.240
namely diagnostics and therapeutics, tools and the future of precision medicine.

01:09.240 --> 01:14.000
We dig into some examples in each area and Peter details the realities of applying machine

01:14.000 --> 01:18.000
learning and some of the impediments to rapid scale.

01:18.000 --> 01:22.160
Before diving in, I'd like to thank Microsoft for their support of the show and their sponsorship

01:22.160 --> 01:24.320
of this series.

01:24.320 --> 01:28.880
Microsoft is committed to ensuring the responsible development and use of AI and is empowering

01:28.880 --> 01:33.880
people around the world with this intelligent technology to help solve previously intractable

01:33.880 --> 01:40.600
societal challenges, spanning sustainability, accessibility and humanitarian action.

01:40.600 --> 01:43.880
Learn more about their plan at Microsoft.ai.

01:43.880 --> 01:51.120
All right, everyone, I am on the line with Peter Lee.

01:51.120 --> 01:56.320
Peter is a corporate vice president at Microsoft, responsible for the company's healthcare

01:56.320 --> 01:57.320
initiatives.

01:57.320 --> 02:00.000
Peter, it is so great to speak with you again.

02:00.000 --> 02:02.840
Welcome to this week in machine learning and AI.

02:02.840 --> 02:05.240
Sam, it's great to be here.

02:05.240 --> 02:11.960
So Peter, you gave a really interesting presentation to a group that I was at at Ignite about

02:11.960 --> 02:18.720
what some of Microsoft was working on at Microsoft Research, as well as a really interesting

02:18.720 --> 02:21.320
take on AI development in China.

02:21.320 --> 02:25.800
They kind of peak my interest and we ended up sitting down to chat about that in a little

02:25.800 --> 02:28.200
bit more detail.

02:28.200 --> 02:33.040
And while we, I did cover that from my blog and newsletter and I'll be linking to it

02:33.040 --> 02:36.600
in the show notes, we won't be diving into that today.

02:36.600 --> 02:41.920
It was a really, really interesting take that I reflect on often.

02:41.920 --> 02:46.800
And I think it's an interesting setup for diving into your background because you do

02:46.800 --> 02:54.480
have a very interesting background and interesting perspective and set up responsibilities at Microsoft.

02:54.480 --> 02:59.200
So on that note, can you share with our audience a little bit about your background?

02:59.200 --> 03:00.200
Sure, Sam.

03:00.200 --> 03:02.200
I'd love to do that.

03:02.200 --> 03:03.200
I agree.

03:03.200 --> 03:09.440
It is a little bit unusual, although I think the common thread throughout has been about

03:09.440 --> 03:12.600
research and trying to bring research into the real world.

03:12.600 --> 03:16.160
And so I am a computer scientist by training.

03:16.160 --> 03:20.000
I was a professor of computer science at Carnegie Mellon for a long time, actually, for

03:20.000 --> 03:22.200
24 years.

03:22.200 --> 03:26.040
And at the end of my time there was the head of the computer science department.

03:26.040 --> 03:31.640
And then I went to Washington, D.C. to serve at an agency called DARPA, which is the

03:31.640 --> 03:35.560
Defense Advanced Research Projects Agency.

03:35.560 --> 03:43.640
It's kind of the storied research agency that built the Saturn V booster technology, invented

03:43.640 --> 03:50.360
the ARPANET, which became the Internet, developed robotics, lots and lots of other things.

03:50.360 --> 03:56.160
And I learned a lot about bringing research to life there.

03:56.160 --> 04:03.120
And then after a couple of years there, I was recruited to Microsoft and joined Microsoft

04:03.120 --> 04:10.200
Research, started managing the mothership lab in Redmond in the headquarters in Redmond

04:10.200 --> 04:17.040
and then a little bit later all of the U.S. research labs and then ultimately all of Microsoft's

04:17.040 --> 04:19.320
13 labs around the world.

04:19.320 --> 04:24.360
And right about that time, Steve Balmer announced his retirement, Satya Nadella, took over

04:24.360 --> 04:34.160
as a CEO, Harry Schum, took over all of AI and research at Microsoft and became my boss.

04:34.160 --> 04:40.760
And they asked me to start a new type of research organization that internally is called Next,

04:40.760 --> 04:44.440
which stands for New Experiences and Technologies.

04:44.440 --> 04:50.120
And we've been sort of trying to grow and incubate new research-powered businesses ever since,

04:50.120 --> 04:52.400
and most recently in healthcare.

04:52.400 --> 05:00.280
I think when I think about AI and healthcare, there's certainly a ton of ground to cover

05:00.280 --> 05:01.280
there.

05:01.280 --> 05:06.680
But I think one of the areas that gets a lot of attention of late is all the progress

05:06.680 --> 05:15.920
that's being made around applying neural nets, CNNs in particular to imagery.

05:15.920 --> 05:22.080
I want to read from your perspective, how do you tend to think about AI applied to

05:22.080 --> 05:25.760
the healthcare space and where the big opportunities are?

05:25.760 --> 05:32.440
Yeah, when I think about AI and healthcare, I'm really optimistic about the future.

05:32.440 --> 05:38.520
Not that there aren't huge difficult problems and sometimes things always seem to grow slower

05:38.520 --> 05:39.520
than you expect.

05:39.520 --> 05:43.160
It's a little bit like watching grass grow.

05:43.160 --> 05:48.280
It does grow and things do happen, but sometimes it's hard to see it.

05:48.280 --> 05:55.000
But over the last 15 years, the thing that I think is underappreciated is the entire healthcare

05:55.000 --> 05:57.400
industry has gone digital.

05:57.400 --> 06:05.040
It was only 15 years ago that, for example, in the United States, less than 10% of physicians

06:05.040 --> 06:10.880
were recording your health history in a digital electronic health record.

06:10.880 --> 06:14.480
And now we're up over 95%.

06:14.480 --> 06:18.800
And that's just an amazing transformation over 15 years.

06:18.800 --> 06:24.360
And it's not like we don't still have problems, the data is siloed.

06:24.360 --> 06:27.000
It's not in standard formats, there's all sorts of problems.

06:27.000 --> 06:33.200
But the fact that it's gone digital just opens up huge, huge amounts of potential.

06:33.200 --> 06:38.280
And so I kind of look at the potential for AI in three areas.

06:38.280 --> 06:43.920
One is sort of the thing that you pointed at, which AI technologies that actually lead

06:43.920 --> 06:47.880
to better diagnostics and therapeutics.

06:47.880 --> 06:52.320
Things that actually advance medical science and medical technology.

06:52.320 --> 06:58.600
A second area for AI is in the area of tools.

06:58.600 --> 07:04.120
Tools that actually make doctors better at what they do, make them happier while they're

07:04.120 --> 07:11.400
doing it, and also improve the experience for you and me as patients or consumers of healthcare.

07:11.400 --> 07:17.440
And then the third area is in this wonderful future of precision medicine.

07:17.440 --> 07:24.120
That's taking new sources of information, digital information, your genome, your proteome,

07:24.120 --> 07:31.200
your immunome, data from your fitness wearables and so on, integrating all of that together

07:31.200 --> 07:34.320
to give you a complete picture of what's going on with your body.

07:34.320 --> 07:39.680
So those are sort of three broad areas, and they're all incredibly exciting right now.

07:39.680 --> 07:45.440
When you think about the first two of those categories, better diagnostics and therapeutics

07:45.440 --> 07:48.720
and tools, how do you distinguish them?

07:48.720 --> 07:55.360
It strikes me that giving doctors a better way to analyze medical imagery, for example,

07:55.360 --> 07:59.160
or to use that example again is a tool that they can use.

07:59.160 --> 08:01.960
But when you say tools, what do you specifically mean?

08:01.960 --> 08:03.800
Yeah, you're absolutely right.

08:03.800 --> 08:09.960
There's an overlap, it's not like the boundaries between these things are all that hardened.

08:09.960 --> 08:16.160
But if you think about one problem that doctors have today is, by some estimates in the

08:16.160 --> 08:22.880
United States, doctors are spending 40 to 50% of their work days entering documentation,

08:22.880 --> 08:29.000
entering notes that record what happened in their encounters with patients.

08:29.000 --> 08:31.280
And that's sometimes called an encounter note.

08:31.280 --> 08:37.560
That documentation is actually required now by various rules and regulations.

08:37.560 --> 08:41.960
It's an incredible source of burnout, and in fact, I'm guessing you've had this experience.

08:41.960 --> 08:46.800
Most people have you go to your doctor, I go to mine, and I like her very much.

08:46.800 --> 08:50.640
But while I'm being examined by her, she's not looking at me, she's actually sitting

08:50.640 --> 08:55.080
at a PC, typing in the encounter notes.

08:55.080 --> 08:59.640
And the reason she's doing that is if she doesn't do it while she's examining me, she'll

08:59.640 --> 09:04.100
have to do it for a couple of hours, maybe in the evening, taking time away from her

09:04.100 --> 09:05.960
own family.

09:05.960 --> 09:14.200
And that burden is credited or blamed for a rise in physician burnout.

09:14.200 --> 09:22.400
While AI technologies today are rapidly approaching the point where an ambient intelligence

09:22.400 --> 09:29.840
can just observe and listen to a doctor patient encounter and automate the vast majority of

09:29.840 --> 09:33.600
the burden of that required clinical note-taking.

09:33.600 --> 09:38.960
And so that's an example of a kind of technology that could, in a really material way, just

09:38.960 --> 09:44.160
improve the lives and the work they said is faction of doctors and nurses.

09:44.160 --> 09:47.040
And that's, I put that in a different category.

09:47.040 --> 09:54.600
And technologies that actually give you more precise diagnosis of what's ailing you,

09:54.600 --> 10:02.360
or ability to target therapies that might actually attack the very specific genetic makeup,

10:02.360 --> 10:05.760
let's say, of the cancer that's inhabiting your body right now.

10:05.760 --> 10:06.760
Got it.

10:06.760 --> 10:07.760
Got it.

10:07.760 --> 10:11.360
So maybe let's take each of these categories in turn.

10:11.360 --> 10:20.120
I'd love to get a perspective from you on where you see the important developments coming

10:20.120 --> 10:28.040
from, from a research perspective, and where you see the opportunities and where you see

10:28.040 --> 10:30.840
things heading in each.

10:30.840 --> 10:31.840
Sure.

10:31.840 --> 10:37.880
Well, why don't we start with your example of imaging because computer vision based

10:37.880 --> 10:43.600
on deep neural nets has just been progressing at this stunning rate.

10:43.600 --> 10:49.880
And it seems like every week you see another company, another startup, or another university

10:49.880 --> 10:58.040
research group showing off their latest advances in using deep neural net based computer vision

10:58.040 --> 11:04.560
technologies to do various kinds of medical image diagnosis or segmentation.

11:04.560 --> 11:09.400
And here at Microsoft, we've been working pretty hard on those as well.

11:09.400 --> 11:18.160
We have this wonderful program based primarily in India that's been trained on the health records

11:18.160 --> 11:24.280
and eye images of over 200,000 patients.

11:24.280 --> 11:30.440
And that idea of taking all that data, you get the signal of which of those patients

11:30.440 --> 11:38.200
have, let's say, suffered from, say, diabetic retinopathy or a progression of refractive

11:38.200 --> 11:40.720
error leading to blindness.

11:40.720 --> 11:46.200
And from that signal in the electronic health record coupled with the images, we are able

11:46.200 --> 11:54.920
to train a computer vision based thing to make a prediction about whether a child whose

11:54.920 --> 11:59.520
eye image has been taken is in danger of losing eyesight.

11:59.520 --> 12:02.520
And that is in deployment right now in India.

12:02.520 --> 12:06.520
And of course, for other parts of the world, like the United States and Europe, which are

12:06.520 --> 12:12.440
more regulated, these things are in various states of clinical validation, as they can be

12:12.440 --> 12:14.560
more broadly deployed.

12:14.560 --> 12:21.840
Another example is a project that we have called Inner Eye that is trying to just reduce

12:21.840 --> 12:31.000
the incredible kind of boring and mundane problem of just pixel-by-pixel outlining the parts

12:31.000 --> 12:36.880
of your body that are tumor and should be attacked with a radiation beam, as opposed

12:36.880 --> 12:38.440
to the healthy tissue.

12:38.440 --> 12:43.560
And that problem of radiation therapy planning has to be done really perfectly, which is

12:43.560 --> 12:47.120
why it's this sort of pixel-by-pixel process.

12:47.120 --> 12:55.600
But there is maybe five or 15 minutes of real black magic that's drawing on all of the

12:55.600 --> 13:02.400
intuition and experience and wisdom of a radiologist, and then two to three hours of complete

13:02.400 --> 13:03.400
drudgery.

13:03.400 --> 13:08.000
And much of that complete drudgery can just be eliminated with modern computer vision

13:08.000 --> 13:09.000
technologies.

13:09.000 --> 13:14.880
And so these things are really developing so rapidly and coming online.

13:14.880 --> 13:21.120
And they tend not to replace completely what doctors and radiologists can do, because

13:21.120 --> 13:25.360
there is always some judgment and intuition involved in these things.

13:25.360 --> 13:30.760
But when done right, they can integrate into the workflow to really enable to kind of

13:30.760 --> 13:38.760
liberate clinicians from a lot of drudgery and to reduce mistakes.

13:38.760 --> 13:44.680
And I think one other thing that's sometimes not fully appreciated is you also, when you

13:44.680 --> 13:48.920
get these tools, you can take these measurements over and over and over again.

13:48.920 --> 13:54.380
When they become cheap, you can take them every day if necessary, which allows you to

13:54.380 --> 14:01.240
track the progression of a disease or its treatment over time much more precisely.

14:01.240 --> 14:08.920
And so these sorts of applications, I think, in medical imaging, I think are really promising.

14:08.920 --> 14:18.440
One thing I, it's a hobby horse of mine before I pause is, you know, in 2015 here in Microsoft

14:18.440 --> 14:22.680
research, we invented something called deep residual networks, which are now commonly

14:22.680 --> 14:23.680
called ResNet.

14:23.680 --> 14:29.080
And ResNet has become part of an industry standard and research standard in computer vision

14:29.080 --> 14:31.560
using deep neural nets.

14:31.560 --> 14:39.720
We ourselves have refrained from using ResNet for doing things like imaging of 3D images

14:39.720 --> 14:43.720
for the purposes of radiation therapy planning, and there are various technical reasons for

14:43.720 --> 14:44.720
that.

14:44.720 --> 14:49.840
And so sometimes we have a mixture of being proud seeing the rest of the world use our

14:49.840 --> 14:54.720
invention for interesting medical imaging, but we also sometimes get worried that people

14:54.720 --> 14:59.480
don't quite understand the failure modes in these things.

14:59.480 --> 15:02.160
But still, the progress has just been spectacular.

15:02.160 --> 15:06.080
I mean, that's kind of an interesting prompt.

15:06.080 --> 15:13.200
Maybe let's take a moment to explore the failure modes and why don't you, it sounds like

15:13.200 --> 15:18.240
you don't advise folks to apply ResNet to the types of images that we tend to see in medical

15:18.240 --> 15:19.240
imaging.

15:19.240 --> 15:20.240
What's that about?

15:20.240 --> 15:26.640
Yeah, it's not advising or warning people against it.

15:26.640 --> 15:32.200
So if you think about, let's say, take the problem of radiation therapy planning, it's

15:32.200 --> 15:33.800
a 3D problem.

15:33.800 --> 15:41.160
You have a tumor that is a 3D mass in your body and you're trying to come up with a plan

15:41.160 --> 15:48.360
for that radiation beam to attack ideally as much of that tumor while preserving as much

15:48.360 --> 15:50.560
healthy tissue as possible.

15:50.560 --> 15:58.320
And of course, your picture into that 3D tumor is as a series of two-dimensional slices,

15:58.320 --> 16:00.720
at least with current medical imaging.

16:00.720 --> 16:11.120
And so one very basic question is, as you examine slice by slice, that tumor with respect

16:11.120 --> 16:17.200
to the healthy tissue, is each slice being properly and logically registered with the

16:17.200 --> 16:19.080
next one.

16:19.080 --> 16:27.800
And a simple or naive application of a convolutional neural network like a ResNet doesn't automatically

16:27.800 --> 16:29.120
do that.

16:29.120 --> 16:37.000
The other problem is it's unclear to what extent a bad training sample or set of training

16:37.000 --> 16:42.560
samples will do to one of these deep neural nets.

16:42.560 --> 16:49.560
And in fact, just in the last few weeks and months, there have been more and more interesting

16:49.560 --> 16:56.440
academic research studies showing some interesting failure modes from a surprisingly small number

16:56.440 --> 17:00.120
of bad training samples.

17:00.120 --> 17:06.680
And so I think that these things are changing all the time, our algorithms and our algorithmic

17:06.680 --> 17:09.680
understanding are improving all the time.

17:09.680 --> 17:16.600
But at least within our research groups, we've taken pains to understand that this application

17:16.600 --> 17:20.040
of computer vision isn't like others.

17:20.040 --> 17:27.200
It's more in the realm of driverless cars where safety is of paramount concern and we

17:27.200 --> 17:32.320
just have to have absolute certainty that we understand the possible failure modes of

17:32.320 --> 17:33.320
these things.

17:33.320 --> 17:41.120
Sometimes with just an authorship application of ResNet or any similar kind of deep neural

17:41.120 --> 17:48.120
net algorithm, we and now more and more other researchers at universities are finding that

17:48.120 --> 17:51.280
we don't yet fully understand the failure modes.

17:51.280 --> 18:00.000
In some ways, there's an opportunity beyond kind of naive application of an algorithm

18:00.000 --> 18:03.000
that performs very well on ImageNet.

18:03.000 --> 18:08.840
Also for, so today you can get data sets that include kind of these 2D representations

18:08.840 --> 18:14.320
of what are fundamentally 3D applications or 3D images and kind of apply the regular

18:14.320 --> 18:18.520
2D algorithms to them and find interesting things.

18:18.520 --> 18:25.560
But you're saying that there, A, we can do better and B, we may not even be doing the

18:25.560 --> 18:30.840
right things in many cases because of these safety issues.

18:30.840 --> 18:36.600
I'm wondering do you, on the first of those two points, the doing better, is there either

18:36.600 --> 18:42.200
a standard approach that's better than ResNet for these 3D images that you've developed

18:42.200 --> 18:50.160
at Microsoft or have seen otherwise or where are we in terms of taking advantage of the

18:50.160 --> 18:54.400
3D nature of medical images and deep learning?

18:54.400 --> 19:01.400
Yeah, it's a good question, you know, for our inner-eye project, which is really run by

19:01.400 --> 19:09.520
a great set of researchers, based mostly in our Cambridge UK research lab and led by Antonio

19:09.520 --> 19:17.440
Kriminesi and he's really one of the pre-eminent authorities in computer vision.

19:17.440 --> 19:23.760
In fact, he, he led an effort some years ago to work out the 3D computer vision for

19:23.760 --> 19:29.320
Connect and so he's really specialized in 3D.

19:29.320 --> 19:36.000
And so the inner-eye project, which is really for us an effort to really understand completely

19:36.000 --> 19:43.320
the workflow of radiation therapy planning, that system actually doesn't use residual

19:43.320 --> 19:44.320
network.

19:44.320 --> 19:51.640
What it does is it uses a kind of an architecture of layered, what a code decision for us.

19:51.640 --> 20:00.520
And that gives not only some benefits in terms of more compact representations of the machine

20:00.520 --> 20:08.560
learned models and therefore some performance improvements, but it allows us to kind of

20:08.560 --> 20:16.280
capture a kind of logical registration of the images as they go slice by slice.

20:16.280 --> 20:24.120
In other words, it's you're inferring not just the segmentation of each 2D image slice,

20:24.120 --> 20:33.400
but you're actually trying to infer the voxel, the 3D voxel volume of these, of the tumor

20:33.400 --> 20:35.320
that you're trying to attack.

20:35.320 --> 20:39.680
And so, and then on top of that, there's a process involved when you're dealing with

20:39.680 --> 20:41.520
medical technologies.

20:41.520 --> 20:45.920
You don't just put it out there and start applying it on people.

20:45.920 --> 20:51.600
You get it peer reviewed, you get it peer reviewed and in this case in computer science journals

20:51.600 --> 20:53.720
and in medical journals.

20:53.720 --> 20:56.640
And you go through a clinical validation.

20:56.640 --> 21:02.080
And if you're in the United States, for example, through an FDA approval process.

21:02.080 --> 21:09.240
And so for us, as we're learning about what does our cloud, what do our AI services, what

21:09.240 --> 21:17.000
do our tools have to be in order to support this future of AI powered healthcare?

21:17.000 --> 21:22.360
In their eyes, an example of us going end to end to try to build it all out and to understand

21:22.360 --> 21:27.680
all of those components and to understand what has to be done to really do it right.

21:27.680 --> 21:31.160
And it's been a great learning experience.

21:31.160 --> 21:37.120
We're now in the process, not only of working with various companies who might want to integrate

21:37.120 --> 21:44.600
this interi technology into their medical devices, but we're starting to now pull apart

21:44.600 --> 21:49.600
the kind of bricks and mortar that we used in the technical architecture for interi

21:49.600 --> 21:54.320
in order to expose those as APIs for other developers to use.

21:54.320 --> 21:57.800
And so our intent is not to get into the radiation therapy business.

21:57.800 --> 22:03.320
Our intent is not to get into radiology, but we do want our cloud and our AI services

22:03.320 --> 22:10.800
and our algorithms to be a great place for any other company or any other startup or

22:10.800 --> 22:17.200
innovator who wants to do that and ideally do it on our cloud using our tools.

22:17.200 --> 22:25.480
So an interesting point in there, you mentioned that the decision for us that you've developed

22:25.480 --> 22:32.360
to address this problem, you know, I guess we often think of there being this trade

22:32.360 --> 22:42.240
off between factors like explainability or, you know, safety as you related that second

22:42.240 --> 22:49.520
point and performance, which we think of as the neuron that is delivering the kind of

22:49.520 --> 22:52.920
the ultimate in performance in many cases.

22:52.920 --> 23:00.720
But in this case, your this decision for us algorithm is outperforming your, at least

23:00.720 --> 23:04.280
your classic 2D resnets.

23:04.280 --> 23:08.960
And I'm imagining also providing benefits in terms of explainability slash safety, is

23:08.960 --> 23:09.960
that correct?

23:09.960 --> 23:16.480
Well, I we feel very strongly that it provides benefits in terms of safety, explainability

23:16.480 --> 23:21.320
is really another very interesting question and the problem.

23:21.320 --> 23:26.640
And so there's a potential for greater explainability, you know, one of the lessons that

23:26.640 --> 23:32.920
we learned when we were working on AI for sales intelligence.

23:32.920 --> 23:37.960
And so we had really developed a tremendous amount of AI that would ingest large amounts

23:37.960 --> 23:44.080
of data from the world as well as from customer relationship management databases, emails

23:44.080 --> 23:47.480
and so on for our sales teams.

23:47.480 --> 23:57.880
And use that through various AI algorithms to do things like synthesize new offers to

23:57.880 --> 24:05.920
specific customers or to surface new prospective customers or to suggest new discount pricing

24:05.920 --> 24:07.720
for specific customers.

24:07.720 --> 24:13.480
And one of the things we learned is that, you know, no self-respecting sales executive

24:13.480 --> 24:21.080
is going to offer 20% discount to a customer just because his algorithm says so.

24:21.080 --> 24:25.720
You know, and, you know, typically doctors are probably similar.

24:25.720 --> 24:26.720
That's right.

24:26.720 --> 24:33.960
And so in that situation, we also moved away from, in that specific case, moved away from

24:33.960 --> 24:40.960
the pure deep neural net architecture to having kind of layered architecture of Bayesian

24:40.960 --> 24:42.960
graphical models.

24:42.960 --> 24:49.160
And the reason for that was so that we could synthesize an explanation in plain English

24:49.160 --> 24:53.680
of not only, you know, offer a 20% discount, but why?

24:53.680 --> 24:59.520
And as we get into away from more kind of point solutions that are kind of machine learning

24:59.520 --> 25:08.000
or AI powered to more of that digital assistant that is the companion to a clinician and gives

25:08.000 --> 25:14.480
that clinician a second opinion or advice on the first opinion, those sorts of explanations

25:14.480 --> 25:19.560
undoubtedly are going to become important, especially at the beginning when we're trying

25:19.560 --> 25:22.560
to establish trust in these things.

25:22.560 --> 25:27.720
And so, you know, as we've been experimenting even with the kind of ambient intelligence

25:27.720 --> 25:34.240
to just listen in on a doctor patient encounter and try to automate a note, one thing we found

25:34.240 --> 25:42.240
is that doctors will look at the synthesized note and not trust everything in it, because

25:42.240 --> 25:46.680
they don't quite yet have the understanding of, you know, why did the note come out

25:46.680 --> 25:47.680
this way?

25:47.680 --> 25:53.440
And so it became important to provide tools so that when you, you know, say, click on a

25:53.440 --> 25:59.840
specific entry in the note that it could be mapped back to a running transcript and

25:59.840 --> 26:03.080
to the right spot in the running transcript that was recorded.

26:03.080 --> 26:08.560
And so these sorts of things, I think, are part of that maybe the human computer interaction

26:08.560 --> 26:15.520
or the human AI interaction that we're having to think about pretty hard as we try to integrate

26:15.520 --> 26:18.680
these things into clinical workflow.

26:18.680 --> 26:26.080
Before we move on beyond diagnostics and therapeutics, all of the examples that you gave fell

26:26.080 --> 26:35.280
into the domain of computer vision, are there interesting things happening in diagnostics

26:35.280 --> 26:39.920
beyond the kind of onslaught of these new computer vision based approaches?

26:39.920 --> 26:46.800
Yeah, I think actually some of the most interesting things are not in computer vision.

26:46.800 --> 26:50.880
And this maybe crosses over into the precision medicine thing.

26:50.880 --> 26:56.200
One of the projects I'm so excited about is something that we're doing jointly with

26:56.200 --> 27:00.600
Seattle biotech startup adaptive biotechnologies.

27:00.600 --> 27:09.600
And so the setup is this, you know, if you take a small blood sample from your body in

27:09.600 --> 27:15.320
that sample, in that one mill sample, you'll end up capturing on the order of one million

27:15.320 --> 27:16.320
T cells.

27:16.320 --> 27:22.000
T cells are one of the primary agents in your adaptive immune system.

27:22.000 --> 27:27.640
And about two and a half years ago, there was a major scientific breakthrough that got

27:27.640 --> 27:35.160
published that showed that the receptor, there's a receptor on the surface of your T cells.

27:35.160 --> 27:40.000
And in that receptor, there's a small snippet of DNA.

27:40.000 --> 27:44.760
And there was strong evidence two and a half years ago that that snippet of DNA completely

27:44.760 --> 27:52.480
determines what pathogen or infectious disease agent or cancer that T cell has been programmed

27:52.480 --> 27:55.440
to seek out and destroy.

27:55.440 --> 28:02.080
And that paper was very interesting because it used a simple linear regression in order

28:02.080 --> 28:10.040
to identify from a read of that little snippet of DNA on your T cell receptor, whether you

28:10.040 --> 28:14.440
had cytomegalovirus or not.

28:14.440 --> 28:19.560
And so it was really just an impressive paper and then just very recent.

28:19.560 --> 28:24.120
Well, the thing that was interesting about adaptive biotechnologies is adaptive biotechnologies

28:24.120 --> 28:30.600
was in the business of giving you a printout of that specific snippet of DNA in all the

28:30.600 --> 28:32.760
T cell receptors in the blood sample.

28:32.760 --> 28:40.760
So they had a business model that would help some cancer centers titrate the amount of

28:40.760 --> 28:45.560
a specific chemotherapy you were getting based on a reading of the DNA.

28:45.560 --> 28:51.080
And so that raised the question, would it be possible to take that printout of those

28:51.080 --> 28:53.880
T cell receptor DNA sequences?

28:53.880 --> 29:01.800
And in essence, think of that as a language and translate it into the language of antigens.

29:01.800 --> 29:08.080
And then if you can do that, can you take those antigens and do a kind of topic identification

29:08.080 --> 29:14.840
problem to figure out what infectious diseases, what cancers, and what autoimmune disorders,

29:14.840 --> 29:17.720
your body is currently coping with right now?

29:17.720 --> 29:23.720
And so it turned into this very interesting new business opportunity for adaptive biotechnologies

29:23.720 --> 29:30.120
that if machine learning could be used to solve those two problems, then they would have

29:30.120 --> 29:36.120
a technology that would be very similar to a universal diagnostic, a simple blood test

29:36.120 --> 29:42.080
powered by machine learning that could do early diagnosis of any infectious disease, any

29:42.080 --> 29:45.440
cancer, and any autoimmune disorder.

29:45.440 --> 29:50.720
And so Microsoft found that interesting enough that we actually took an investment position

29:50.720 --> 29:56.840
in adaptive biotechnologies and agreed to work with them on the machine learning.

29:56.840 --> 30:02.680
And adaptive for their part agreed to build a bigger production pipeline in order to generate

30:02.680 --> 30:09.560
training data to power the machine learning that we're developing at Microsoft.

30:09.560 --> 30:16.120
What has transpired since then has been an amazing amount of progress where we've added

30:16.120 --> 30:22.640
tremendous amount of sophistication actually using deep neural nets and started to feed

30:22.640 --> 30:25.880
it with billions of points of training data.

30:25.880 --> 30:29.920
And in fact, this year the production facility adaptive will be able to generate up to a trillion

30:29.920 --> 30:32.440
points of training data.

30:32.440 --> 30:40.000
And we're now targeting five specific diseases, a varying cancer, pancreatic cancer, type

30:40.000 --> 30:43.520
one diabetes, celiac disease, and Lyme disease.

30:43.520 --> 30:47.240
And so that's two cancers, two autoimmune disorders, and one infectious disease with the

30:47.240 --> 30:50.080
same machine learning pipeline.

30:50.080 --> 30:56.440
And it's still an experiment, but it kind of shows you the potential power of these advances

30:56.440 --> 31:04.600
in immunology, in genomics, and AI all being bound together to give the possibility.

31:04.600 --> 31:07.120
We know the science now is valid.

31:07.120 --> 31:12.240
And if we can now build a technology that ties those things together, we get the potential

31:12.240 --> 31:16.920
for a universal diagnostic, but as close a thing that we could imagine getting to the

31:16.920 --> 31:20.280
Star Trek tricorder as anything.

31:20.280 --> 31:26.800
Yeah, that was the thing that popped immediately to mind for me, the tricorder.

31:26.800 --> 31:38.320
But that example I think captures for me really plainly both the promise of applying machine

31:38.320 --> 31:45.920
learning and AI to this healthcare domain, but also maybe a little bit of the frustration

31:45.920 --> 31:51.600
and thinking through collecting a trillion samples and you've got this pipeline, why does

31:51.600 --> 31:52.600
it take so long?

31:52.600 --> 32:00.360
And there's certainly regulatory and political types of reasons that maybe we'll get into.

32:00.360 --> 32:09.160
But I'm wondering if you can elaborate on with that much training data and the science

32:09.160 --> 32:14.320
in place and a pipeline in place.

32:14.320 --> 32:24.880
What are the realities of applying machine learning in this type of context that impede

32:24.880 --> 32:26.680
kind of rapid scale?

32:26.680 --> 32:32.040
Like why just five diseases and not 25, for example?

32:32.040 --> 32:35.320
Yeah, that's such a great question.

32:35.320 --> 32:41.320
And it's human biology is just so complicated.

32:41.320 --> 32:46.520
You know, let's say there are three ways maybe to take a cut at that.

32:46.520 --> 32:53.880
If we just look at the very basic science, let's just consider the human genome.

32:53.880 --> 32:59.720
Something that geneticists at several universities have taught me, which was really eye opening,

32:59.720 --> 33:07.680
is if you look at the human genome and then look at all the possible variants, the number

33:07.680 --> 33:14.000
of variants and the human genome that would still be considered, you know, homo sapiens

33:14.000 --> 33:17.840
is just astronomically large.

33:17.840 --> 33:24.280
And yet the total number of people on the planet is a relative that number is really tiny,

33:24.280 --> 33:27.000
you know, only what's seven and a half billion people.

33:27.000 --> 33:32.760
And in fact, if we had somehow DNA samples from every human that has ever existed, I think

33:32.760 --> 33:37.640
most estimates say there are fewer than a hundred and six billion people that have ever existed

33:37.640 --> 33:39.600
since Adam and Eve.

33:39.600 --> 33:45.080
And so if we are using modern machine learning, which is basically looking at statistical patterns

33:45.080 --> 33:52.560
and correlations, we have an immediate problem for a lot of basic problems in genomics, because

33:52.560 --> 33:59.000
we basically don't have a source of enough training data, the complexity of human beings,

33:59.000 --> 34:05.120
the complexity of cancer, the complexity, the genetic complexity of disease is just vastly

34:05.120 --> 34:09.760
larger than the number of people that have ever existed.

34:09.760 --> 34:19.720
Meaning relative to the possible combinations of genes, every human is, you know, I guess

34:19.720 --> 34:24.680
it shouldn't be surprising that every human is unique, but even given, I mean, it's a

34:24.680 --> 34:25.680
little counterintuitive.

34:25.680 --> 34:29.520
You think there's only like these four letters that were thrown together to make all this

34:29.520 --> 34:31.200
stuff out, right?

34:31.200 --> 34:38.720
Yeah, it's, and so, you know, and so what that means is that yes, we will, and we have

34:38.720 --> 34:44.360
been making, we meaning the scientific community and the technology community have been making

34:44.360 --> 34:52.320
stunning advances and making really meaningful improvements for neonatal intensive care for

34:52.320 --> 35:02.320
cancer treatments for immunology, but fundamentally, scientifically, we still need something beyond

35:02.320 --> 35:08.640
just machine learning, and we really need something that gets into the basic biology.

35:08.640 --> 35:12.840
And so that's kind of one reason why this is hard, and another reason is these are just

35:12.840 --> 35:13.840
big problems.

35:13.840 --> 35:19.480
In the project with adaptive biotechnologies, there are between 10 to the 15th and 10

35:19.480 --> 35:27.360
to the 16th different T-cell receptors that your body can produce, and on the order of

35:27.360 --> 35:35.480
maybe 10 to the 7th known antigens, and, and so imagine what we're trying to do is trying

35:35.480 --> 35:42.080
to fill out a gigantic X-cell spreadsheet, you know, with 10 to the 16th columns and 10

35:42.080 --> 35:47.680
to the 7th rows, and that's just a heck of a big table.

35:47.680 --> 35:54.040
And so you end up needing a large monitoring data to discern enough structure, find enough

35:54.040 --> 36:00.800
patterns in, in order to have a shot at filling in at least useful parts of that table.

36:00.800 --> 36:08.240
The good news is, you know, everybody has T-cells, and so we can take blood samples from

36:08.240 --> 36:14.240
anybody, from just ordinary healthy people, and then we can go to research laboratories

36:14.240 --> 36:22.560
around the world that have stored the libraries of antigens, and start kind of correlating

36:22.560 --> 36:27.920
those stored libraries of antigens against those what are called naive blood samples.

36:27.920 --> 36:32.760
And that's exactly what adaptive biotechnologies is doing, in order to generate the very large

36:32.760 --> 36:33.760
monitoring data.

36:33.760 --> 36:39.880
So it's a little bit of a good news situation there, that we don't need to find thousands

36:39.880 --> 36:45.000
or millions of sick people, we can generate the data from just ordinary samples, but

36:45.000 --> 36:48.360
it's still a very large monitoring data that we need.

36:48.360 --> 36:56.280
And then, you know, the third kind of way that I think about this is, you know, it gets

36:56.280 --> 36:58.040
back to the safety issue.

36:58.040 --> 37:04.400
You know, we do things a certain way, because ultimately medicine and medical science

37:04.400 --> 37:10.320
is based on causal relationships, in other words, you know, we want to know that A causes

37:10.320 --> 37:18.080
B, but what we typically get out of machine learning is just A is correlated with B, and

37:18.080 --> 37:23.040
we get those inferences, and then it takes more work and more testing under controlled

37:23.040 --> 37:25.960
circumstances to know that there's a causal relationship.

37:25.960 --> 37:33.200
And so all three of those things kind of create, you know, challenges, it does take time,

37:33.200 --> 37:39.960
but you know, it's, I think the good thing is, as the regulatory organizations like the

37:39.960 --> 37:46.080
FDA have gotten smarter and smarter about what is machine learning, what is good for

37:46.080 --> 37:52.520
or what are its limitations, that whole process has gotten, I think, faster and more efficient

37:52.520 --> 37:54.400
over time.

37:54.400 --> 38:00.680
And then, and then there's a second element, which is, of course, companies are in it

38:00.680 --> 38:06.680
to make money at a minimum, even if they have purely humanitarian intentions, at a minimum,

38:06.680 --> 38:09.680
they have to be sustained over time.

38:09.680 --> 38:15.000
And so that means that insurance companies, Medicare, Medicaid, they have to be willing

38:15.000 --> 38:22.440
to reimburse doctors and nurses when they actually use or prescribe these diagnostics

38:22.440 --> 38:23.440
and therapeutics.

38:23.440 --> 38:25.960
And so all of that takes time.

38:25.960 --> 38:34.560
At least on the, the second of your three points in thinking about scaling, solving problems

38:34.560 --> 38:43.600
like this, specifically training data, do you have a, a rule of thumb, a chart that says,

38:43.600 --> 38:48.760
okay, you are one trillion training samples, we'll get us these five diseases, but we'll

38:48.760 --> 38:52.200
need 10 trillion to get to 10 disease.

38:52.200 --> 38:57.160
I realize that that's almost an ass and I question, and it's much more complex than that,

38:57.160 --> 39:01.040
but do you, does it make sense at all to think of it like that?

39:01.040 --> 39:07.720
And I think of, I guess, the impact of collecting training data and what the trajectory looks

39:07.720 --> 39:11.680
like that over time, kind of like the way we thought of, you know, as we drive the cost

39:11.680 --> 39:15.480
of sequencing down, the downstream effects that that'll have.

39:15.480 --> 39:20.240
Yeah, well, when you find the answer to that question, please tell me.

39:20.240 --> 39:28.000
You know, it's, so in my experience, I've seen this go two ways.

39:28.000 --> 39:31.760
You know, one of the wonderful things about modern machine learning algorithms today is

39:31.760 --> 39:39.080
that they're, they're far less susceptible to problems of overfitting.

39:39.080 --> 39:46.240
They come very close to this, this wonderful property that the more data, the more better.

39:46.240 --> 39:53.320
And, but it does happen that sometimes you hit a wall, you know, that you start to see

39:53.320 --> 39:56.720
a trail off in improvement.

39:56.720 --> 40:05.440
And, and so it, we really don't know, we're very, that kind of early results that we've

40:05.440 --> 40:12.040
gotten with admittedly simpler diseases like CMV and then CMV is actually, you know, not

40:12.040 --> 40:18.680
that interesting from a medical perspective, they give us tremendous hope.

40:18.680 --> 40:25.520
And then other kind of internal more technical validations give us supreme confidence that

40:25.520 --> 40:30.280
the basic science, the biological sciences will understand now.

40:30.280 --> 40:35.120
But you know, once you start really attacking much more complex diseases, you know, like

40:35.120 --> 40:39.080
any cancer, it's, it's really hard.

40:39.080 --> 40:44.080
I would be unwilling personally to make a prediction about what will happen.

40:44.080 --> 40:48.200
But you know, there is every reason today for optimism.

40:48.200 --> 40:53.280
And, and I think that only unknown is, you know, whether there is a, whether we fall

40:53.280 --> 41:02.880
off a cliff at some point and, and stop finding improvements, or, you know, if we're, you

41:02.880 --> 41:09.880
know, if, if we're going to just get to a viable FDA approved diagnostic in the near

41:09.880 --> 41:14.680
term, that will be constantly improving as more and more people are diagnosed.

41:14.680 --> 41:18.080
So, so it could really go in either way.

41:18.080 --> 41:23.520
And then, yeah, I'm, I'm really unable and actually unwilling to make a prediction about

41:23.520 --> 41:25.320
which way will go.

41:25.320 --> 41:27.360
But, but we are feeling pretty confident.

41:27.360 --> 41:35.560
Incidentally, I should say, you know, last month, adaptive biotechnologies closed a deal

41:35.560 --> 41:45.320
with Genentech for applications of this T solar receptor antigen map in the therapeutic space

41:45.320 --> 41:50.960
in the area of cellular therapies for targeted cancer treatments.

41:50.960 --> 41:57.080
And, and that deal has a value of over $2 billion.

41:57.080 --> 42:02.680
So there's also some, you know, when you're dealing with kind of commercial relationships

42:02.680 --> 42:07.000
like that, you know, there, you know, there's a tremendous amount of due diligence.

42:07.000 --> 42:13.600
There's also, you know, these are big bets and a big pharma is, is accustomed to making

42:13.600 --> 42:18.800
a large risky bets like this, but I think it's, it's another sign, at least leading scientists

42:18.800 --> 42:25.240
at one of the larger pharmaceutical organizations is also increasingly confident that, that, that

42:25.240 --> 42:27.000
we can fill out this map.

42:27.000 --> 42:31.760
So we've talked about diagnostics, we've talked about precision medicine.

42:31.760 --> 42:38.000
What do you see happening on the tooling side, both from the doctor's perspective as well

42:38.000 --> 42:40.560
as the patient experience perspective?

42:40.560 --> 42:46.440
Yeah, you know, one thing that it's a, it's a simple thing, but it's been surprising

42:46.440 --> 42:50.280
how useful it has turned out to be.

42:50.280 --> 42:57.720
We've been piloting chatbot technology, you know, that we call the Microsoft Healthbot.

42:57.720 --> 43:05.320
And this has been sort of in a beta program with a few dozen healthcare organizations.

43:05.320 --> 43:14.800
And what it does is it, we've sort of advanced our cognitive services for language processing,

43:14.800 --> 43:21.440
natural language processing for conversational understanding, and the tooling to provide

43:21.440 --> 43:28.320
a drag and drop interface so that ordinary people can program these chatbots, at least

43:28.320 --> 43:29.640
for medical settings.

43:29.640 --> 43:35.320
And then we've improved the models, the language models that they understand medical and healthcare

43:35.320 --> 43:37.960
concepts and terms.

43:37.960 --> 43:43.520
And so we've been surprised at the kinds of applications that that people use.

43:43.520 --> 43:48.640
So one example is there are organizations that have made prescription bots.

43:48.640 --> 43:53.880
So the idea is this, maybe you get a prescription from your doctor or from the hospital, you

43:53.880 --> 44:02.520
go to the pharmacy, you get prescription filled, and then day or two later you get a message

44:02.520 --> 44:06.240
from this intelligent chatbot just asking, you know, how's it going?

44:06.240 --> 44:12.360
Yeah, have you had any, do you have any questions or have you had any issues with your medication?

44:12.360 --> 44:21.360
And it invites you proactively to get into a conversation that gives the healthcare provider

44:21.360 --> 44:25.280
tremendous insight into whether you're adhering to your prescription.

44:25.280 --> 44:26.600
That's a huge problem.

44:26.600 --> 44:34.040
Something like 35% of people actually don't follow through with their prescription medications.

44:34.040 --> 44:40.920
And it's just there to answer questions, maybe you have some stomach upset, or some people

44:40.920 --> 44:46.160
who are in a lot of medications hate having all those bottles and they put them all, you

44:46.160 --> 44:50.880
know, dump all the pills into a baggie and then they can't remember which pills are which.

44:50.880 --> 44:55.960
And so the health bot is able to converse with you and say, oh, well, why don't you point

44:55.960 --> 45:02.320
your phone camera at this, at a bunch of pills and I'll remind you what they are and

45:02.320 --> 45:10.600
it uses modern computer vision resonance actually to remind you what these pills are.

45:10.600 --> 45:19.320
And so the kind of engagement that the healthcare providers get, the improvements in engagement

45:19.320 --> 45:27.720
and the satisfaction that people like you and me have is really improved or just asking

45:27.720 --> 45:36.280
simple benefits, questions or medical triage, various sorts, these kinds of ideas have been

45:36.280 --> 45:43.480
surprisingly interesting and in fact, so surprising for us that later this week will be making

45:43.480 --> 45:47.960
that product generally available for sale and so you'll be able to use the micro health

45:47.960 --> 45:53.400
bot technology without any restrictions, well, except for payment of course.

45:53.400 --> 45:58.200
And so that is something that has gone extremely well.

45:58.200 --> 46:05.280
And that technology now is kind of being baked into more and more of I think of what

46:05.280 --> 46:06.920
people will be seeing.

46:06.920 --> 46:14.160
We have a collaboration hub application in Office 365 called Teams and Teams has been

46:14.160 --> 46:21.360
this just wonderful technology for improving collaboration and all sorts of work by settings.

46:21.360 --> 46:27.760
Well, we've made teams healthcare compliant and able to connect to electronic health record

46:27.760 --> 46:35.240
systems and then by integrating great kind of collaboration intelligence tools to just

46:35.240 --> 46:41.240
kind of parse records or know where to go to find certain bits of information or just

46:41.240 --> 46:48.200
to be able to ask an intelligent agent that is part of your team, you know, did so and

46:48.200 --> 46:56.120
so, check, you know, the sutures last night and be able to get a smart answer, whether

46:56.120 --> 47:03.280
people are wake or not, you know, is there are all these little ways that I think AI can

47:03.280 --> 47:07.600
be used in the workflow of healthcare delivery.

47:07.600 --> 47:12.680
One of the things that is I think underappreciated about healthcare delivery today, especially

47:12.680 --> 47:16.440
in acute care settings is it's a super collaborative environment.

47:16.440 --> 47:21.640
Sometimes there can be as many as 20 people, you know, that are working together as a team

47:21.640 --> 47:25.480
delivering care to multiple patients at a time.

47:25.480 --> 47:32.800
And so how to keep that team of 20 people all on the same page and all coordinated is

47:32.800 --> 47:40.720
getting to be a really difficult problem, typically done with, you know, posted notes and

47:40.720 --> 47:47.880
you know, half erased whiteboards, now transitioning to pretty insecure consumer messaging apps,

47:47.880 --> 47:55.760
but the idea of having real enterprise grade collaboration support with AI, I think

47:55.760 --> 48:00.720
just can make all of that much better and then provide much more security and privacy

48:00.720 --> 48:02.200
for people.

48:02.200 --> 48:09.400
So a lot of these applications of AI end up being, you know, more less flashy than doing

48:09.400 --> 48:14.960
some automatic radiation therapy planning on the medical image, but they really kind

48:14.960 --> 48:20.720
of help people, you know, those people on the front lines of healthcare delivery do their

48:20.720 --> 48:21.720
jobs better.

48:21.720 --> 48:27.680
Yeah, I tend to find myself having a really kind of mixed feelings about conversational

48:27.680 --> 48:31.920
applications, at least from the perspective of talking about them on the podcast, like

48:31.920 --> 48:38.840
I think that they are, there's no question that conversational experiences and interfaces

48:38.840 --> 48:43.600
will be a huge part of the way we interact with computers in the future and that there's

48:43.600 --> 48:49.560
tons of work that needs to happen there because of the reasons that you mentioned, like

48:49.560 --> 48:50.560
less flashy.

48:50.560 --> 48:55.440
I wonder if there's still interesting research or at least my question to you is, are there

48:55.440 --> 49:01.000
still interesting research challenges there or is it all, you know, do we have all the

49:01.000 --> 49:05.880
pieces and it's just kind of rolling up the sleeves and, you know, building enterprise

49:05.880 --> 49:08.760
software, which we know is hard and takes time?

49:08.760 --> 49:12.640
Yeah, it's a good question.

49:12.640 --> 49:18.920
It feels like research to me and some of the laboratories are, some of the problems

49:18.920 --> 49:28.000
of anything feel a little difficult, honestly, you know, it's, so, you know, if we just

49:28.000 --> 49:35.840
say take the problem of listening to a doctor patient conversation and from that understanding

49:35.840 --> 49:41.640
what you go into the standard form of a clinical encounter note.

49:41.640 --> 49:47.280
Here's a typical thing, there could be an exchange if, let's say Sam, you're my doctor

49:47.280 --> 49:53.840
and I'm your patient and you might be asking me how I'm doing and I might complain about

49:53.840 --> 50:00.000
you know, pain in my left knee hasn't gone away and what, you know, and we can have an

50:00.000 --> 50:08.760
exchange about how that goes and ultimately what goes into the note by you is a note about

50:08.760 --> 50:16.800
my continued lack of weight loss and that my, you know, being overweight is contributing

50:16.800 --> 50:26.600
to the lack of healing with my knee problem that may or may not have been a part of our conversation.

50:26.600 --> 50:32.880
And so while it's important that the weight loss elements be in that clinical note, in

50:32.880 --> 50:38.120
fact, it might even mean revenue for that doctor because there may be a weight loss program

50:38.120 --> 50:43.680
that gets prescribed and so on, that's important and it's important not to miss that.

50:43.680 --> 50:51.160
But the human exchange here and the things that are implicit in those conversations led

50:51.160 --> 50:59.000
along the fact that I'll say kneecap and you'll say Patela are things that are as close

50:59.000 --> 51:06.880
to general artificial intelligence style problems as anything and so, you know, it's, and

51:06.880 --> 51:11.200
look, we don't kid ourselves that we're anywhere close to solving those kinds of problems

51:11.200 --> 51:16.080
but those are the kinds of problems we think about, even when we just look at the kind

51:16.080 --> 51:21.880
of day-to-day minute-by-minute work that people do to deliver healthcare.

51:21.880 --> 51:22.880
Right.

51:22.880 --> 51:23.880
Right.

51:23.880 --> 51:30.440
Here's another one that's interesting to really unlock the power of AI, what we would

51:30.440 --> 51:38.400
want to do is to just open up huge databases to great researchers and innovators everywhere.

51:38.400 --> 51:43.920
But of course, we need to do that without violating anyone's privacy and so there's one problem,

51:43.920 --> 51:44.920
something called de-identification.

51:44.920 --> 51:51.000
It would be great to be able to take a treasure trove of, let's say, electronic health records

51:51.000 --> 51:54.560
and, quote unquote, de-identify it.

51:54.560 --> 51:58.200
Well, some parts of those electronic health records are easy to do because there might

51:58.200 --> 52:02.000
be a field called Social Security Number, another field called Name, another one called

52:02.000 --> 52:05.440
Address and so on, so you can just scrub those out.

52:05.440 --> 52:12.760
But large amounts of chronicle data involve just unstructured notes.

52:12.760 --> 52:17.760
And to really have a deep understanding of what's in those notes and in order to scrub

52:17.760 --> 52:23.760
those in a way that won't inadvertently build somebody's identity or their medical condition,

52:23.760 --> 52:30.160
again, is something that, in the ultimate, ends up being a very general AI problem.

52:30.160 --> 52:37.440
That's a great reframing of the way to think about this is like, yes, most chatbots are

52:37.440 --> 52:39.960
boring because they're boring.

52:39.960 --> 52:46.920
It's like, you know, the kind of the entity intent framework that, you know, most chatbots

52:46.920 --> 52:52.640
are built on is kind of like table stakes relative to what we're really trying to do with

52:52.640 --> 53:04.480
conversational experiences and that really requires a level of sophistication and our ability

53:04.480 --> 53:08.480
to use and work with and manipulate natural language that is very much at the research

53:08.480 --> 53:09.480
frontier now.

53:09.480 --> 53:14.840
And that's why most current, you know, in production chatbots are kind of boring.

53:14.840 --> 53:21.400
Yeah, we've taken a step forward of trying to think of these things almost in terms of

53:21.400 --> 53:25.480
playing, you know, being able to play a game of 20 questions.

53:25.480 --> 53:33.240
You know, one of the most inspiring applications of health bots that we dream about is in

53:33.240 --> 53:36.000
matching people to clinical trials.

53:36.000 --> 53:40.400
You know, at any point, there are thousands of clinical trials available and you can

53:40.400 --> 53:47.640
go to a website called clinicaltrials.gov and there's a search bar there and you can

53:47.640 --> 53:50.440
type in something like breast cancer.

53:50.440 --> 53:57.280
And when you do that, you get this gigantic dump of every registered clinical trial going

53:57.280 --> 54:01.240
on that might be pertinent to breast cancer.

54:01.240 --> 54:06.680
And while that's useful, the problem with that is it's hard to know which ones of those,

54:06.680 --> 54:12.920
you know, if you are, say, someone who's desperate to find clinical trial to enroll in because

54:12.920 --> 54:22.360
you've run out of other viable options for whatever is ailing you, it's just almost impossible

54:22.360 --> 54:25.960
to go through all of that technical information and try to understand this.

54:25.960 --> 54:32.360
And so, you know, would it be possible to use an AI to read through all of that technical

54:32.360 --> 54:37.640
information and then to synthesize what amounts to a game of 20 questions, something that

54:37.640 --> 54:44.120
will converse with you and ask you questions in order to narrow down to just that one or

54:44.120 --> 54:48.600
two or three clinical trials that might be a match for you.

54:48.600 --> 54:55.400
And it's that kind of thing where it's not fully general conversation of the sort that

54:55.400 --> 55:00.640
I think you and I were talking about just a minute ago, but it is slightly more structured

55:00.640 --> 55:07.760
than that in order to help you more intelligently and more efficiently find the right medical

55:07.760 --> 55:10.320
or healthcare solution for you.

55:10.320 --> 55:17.840
And that kind of application is something that we're really putting a lot of kind of hard

55:17.840 --> 55:21.480
and mind into, along with many others around the world.

55:21.480 --> 55:26.520
And it's exciting that we're starting to see these things actually make it into clinical

55:26.520 --> 55:28.040
use today.

55:28.040 --> 55:32.200
And so, I kind of agree with you.

55:32.200 --> 55:39.120
I roll my eyes sometimes at the overheated hype around intelligently and chatbots as

55:39.120 --> 55:45.160
well, just like anybody else, but it's really getting somewhere in these more limited domains.

55:45.160 --> 55:51.760
I think it also says why the interesting work in domains like this is going to be, you

55:51.760 --> 55:53.120
know, it's not generic, right?

55:53.120 --> 55:57.240
You're solving a specific problem and there's a lot of investment in kind of getting the

55:57.240 --> 56:03.200
machine learning DA right for this particular problem as opposed to implementing a generic

56:03.200 --> 56:04.200
framework.

56:04.200 --> 56:05.200
That's right.

56:05.200 --> 56:06.200
Awesome.

56:06.200 --> 56:12.080
Well, Peter, thank you so much for taking the time to chat with me about the stuff you're

56:12.080 --> 56:15.080
seeing and working on in the healthcare space.

56:15.080 --> 56:22.680
A ton of really interesting examples in there and I'm looking forward to kind of following

56:22.680 --> 56:25.400
all this work and digging deeper.

56:25.400 --> 56:26.400
Thank you.

56:26.400 --> 56:28.000
I didn't even talk about China once.

56:28.000 --> 56:29.000
It's great.

56:29.000 --> 56:36.280
Well, you mentioned ResNet a few times, kind of taunting me to dive into that conversation.

56:36.280 --> 56:40.120
But our fur folks to the article and we'll put the link in the show notes.

56:40.120 --> 56:41.120
Sounds great.

56:41.120 --> 56:44.240
It was really a pleasure chatting.

56:44.240 --> 56:48.240
All right, everyone.

56:48.240 --> 56:53.240
That's our show for today for more information on Peter or any of the topics covered in

56:53.240 --> 56:58.760
the show, visit twimmalai.com slash talk slash two, three, one.

56:58.760 --> 57:04.560
To follow along with the AI for the benefit of society series, visit twimmalai.com slash

57:04.560 --> 57:06.800
AI for society.

57:06.800 --> 57:33.560
As always, thanks so much for listening and catch you next time.

