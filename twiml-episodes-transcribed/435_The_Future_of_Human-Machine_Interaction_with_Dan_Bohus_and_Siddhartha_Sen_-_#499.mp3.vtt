WEBVTT

00:00.000 --> 00:26.000
All right, everyone, one of the most promising aspects of the way that we're thinking about AI today is a deliberate focus on human AI complementarity that is looking at ways that AI can complement rather than replace human intelligence.

00:26.000 --> 00:39.000
This idea has become so important that some notably Gary Kasparov, who I interviewed three years ago on the show, have proposed redefining AI as augmented intelligence.

00:39.000 --> 00:51.000
Today I'm joined by Dan Bohus and Siddhartha Sen of Microsoft Research to explore two very different projects that they're working on that both connect to this theme.

00:51.000 --> 00:54.000
Welcome Dan and said to the podcast.

00:54.000 --> 00:58.000
Thanks for having us. Nice meet you.

00:58.000 --> 01:00.000
Thanks, it's great to be here.

01:00.000 --> 01:13.000
Before we jump into your individual projects, I'd love to have each of you share a bit about your background and how you come to or how you've come to work in the area of human and machine collaboration.

01:13.000 --> 01:16.000
Let's get started with you, Siddhartha.

01:16.000 --> 01:34.000
Yeah, so my background is generally as a distributed systems researcher. I'm going to join Microsoft Research after graduating my PhD and I was focusing on systems research, but because I was surrounded by a lot of people working in artificial intelligence, I slowly started to incorporate artificial intelligence into the work that I did.

01:34.000 --> 01:46.000
And then I realized that we don't often have a great balance between the kind of work that the AI does for us and the work that we do using our human heuristics or human designs.

01:46.000 --> 01:53.000
And so I became increasingly, increasingly interested in that intersection between AI and human design working well together.

01:53.000 --> 02:12.000
And that's one of the reasons I've been moving towards this space. So instead of trying to replace our human solutions with the eye, trying to find the right synergy and different contexts, whether it's algorithms or data structures or games like tests, trying to figure out the right balance between when we can use AI at what it's good at and when we can use our own human solutions that we're good at.

02:12.000 --> 02:16.000
So that's been an increasing interest of mine in recent years.

02:16.000 --> 02:33.000
Awesome. Then yeah, so I basically the questions that drive my research are, how can we get computers and computing systems to perceive and reason about physical surroundings and collaborate with people in physical space.

02:33.000 --> 02:39.000
So how can we have much more human centric collaboration going on when we interact with computation.

02:39.000 --> 02:56.000
Now, how I got here, it was kind of serendipitous route and I have a deep interest in language and that started in my undergrad years when I was doing computer science and I was looking around for opportunities to get more engaged in research.

02:56.000 --> 03:09.000
The system professors at the university I was at was working on building the resources that you would need to start building a speech recognizer for the Romanian language. This is back in Romania where I'm originally from.

03:09.000 --> 03:29.000
And so I got involved in that work and I started working on natural language processing and then I went to graduate school where I worked on spoken dialogue systems back in the early 2000s, these were telephony based systems with same kind of technology you have in in these voice assistance these days.

03:29.000 --> 03:48.000
And I was looking at problems of how do you get these systems to know when they don't know to understand that errors might be happening speech recognition was not that great back in that day, you know, and kind of behave more like humans we we sometimes have misunderstandings with each other when we interact with each other.

03:48.000 --> 04:04.000
So I was able to quickly and gracefully recover from those were monitoring for mutual understanding and were able to recover from these errors. And so from that I after graduating I joined Microsoft research where I am now in this.

04:04.000 --> 04:18.000
And I got the systems interaction research group and when I joined in 2007 this group was actually led by Eric Corvitz, I know you had a recent interview with him, which is quite a great to listen to.

04:18.000 --> 04:47.000
The manager at the time and he's the one that actually kind of spurred me on and encouraged me to almost like brought on the frame of mind from thinking from you know voice only interfaces to how might we one day be able to build computing systems that reason about people in physical space and interact and collaborate with them with language or in other ways, but with the fluidity that kind of characterizes human human interactions.

04:47.000 --> 04:52.000
So that's kind of what I'm passionate about and what drives me and what I do these days.

04:52.000 --> 05:07.000
Awesome awesome well I think this theme of kind of two very different approaches and backgrounds with some commonalities is something that will be seeing and speaking a lot of in this conversation.

05:07.000 --> 05:20.000
Let's kind of transition to having each of you dig into your individual projects and kind of set the stage for broader conversation around the this theme.

05:20.000 --> 05:26.000
Sid, let's go back to you and have you share a little bit about Maya.

05:26.000 --> 05:55.000
Yeah, so one nice thing about the labs that Dan and I work in is that we're surrounded by a lot of different disciplines and in some sense that influence has found its way into my work and so I'm surrounded by social scientists by artificial intelligence researchers by people who study ethics of machine learning and its role in society and so you know a lot of these influences have kind of come together in this project that we call Maya where we're trying to really take a particular kind of system, which is the game of chess.

05:55.000 --> 06:13.000
And try to make it more oriented towards humans and it's interesting to look at chess because chess is often a precursor to a lot of AI research, it's often a playground and a model system where you can try out and test out different ideas and AI before you try them out in more complex or more realistic domains.

06:13.000 --> 06:40.000
One of the reasons it's really nice to work in chess is because it's very self contained we have clear rules it's still a very challenging game to solve and people still play it despite the fact that you know humans have been outperformed by machines since you know since deep blue defeated a casserole back in the day in 1997 and you know definitively we have AI that is super human in the sense that at this particular in this particular context in this game.

06:40.000 --> 06:58.000
It can defeat the strongest players in the world and so what we wanted to do was instead of having a situation where there's AI that just beats humans all the time can we reorient that AI towards humans to try to understand how humans play and to help humans develop and grow and learn chess in a better way.

06:58.000 --> 07:20.000
And so the Maya project is trying to do that we're taking state of the art AI engines that are good at playing chess and instead of training them to basically win the game we're training them to understand the decisions humans make and try to understand them at a very individual level like what would a player at this level do in this situation or what would the specific player do in the situation.

07:20.000 --> 07:43.000
And the goal is that by understanding and being and doing a good job at predicting those decisions we can get a better gauge of the strengths and weaknesses of humans at different levels of individuals of specific individuals and there and therefore suggest ways in which they can train or improve themselves to get better at this game.

07:43.000 --> 07:54.000
Essentially what Maya is so Maya is a chess engine that predicts human decisions at different levels and can even predict the decisions of individuals if we've trained on enough of their games in the past.

07:54.000 --> 08:04.000
So that's another nice thing about chess is that all the games that you play and all these online forums are public and available to us so we can take them and learn from them.

08:04.000 --> 08:20.000
I think the larger agenda and vision of the Maya project is to start with chess but to ultimately develop teaching tools that can be combined with human teachers in the right way to help people improve their game of chess.

08:20.000 --> 08:47.000
Nice, nice. I would say no accident that I mentioned Gary Casparov earlier in the conversation and one of the things that he's been excited about is this idea of a different kind of collaboration between humans and computers in the game of chess using the computer as kind of augmenting the human in them playing chess.

08:47.000 --> 08:55.000
This is a very different approach where you're trying to augment the teaching of chess.

08:55.000 --> 08:58.000
Yeah, I think there is an interesting connection there.

08:58.000 --> 09:08.000
You know, there are different modes of chess where you can actually play with another person advising and what to do and team them up together and even play with an engine as well as a team.

09:08.000 --> 09:18.000
And so we're actually exploring all kinds of collaborations so similar to the ones that you spoke to Gary about we are trying to see how these two entities can work together.

09:18.000 --> 09:36.000
And when it comes to teaching, I think that the AI engines that we've developed can be a great tool for someone is trying to teach others how to play chess because it can help the teacher understand the weaknesses of the player to focus on the areas where they need to develop more.

09:36.000 --> 09:42.000
And they can also recognize the player's game. So one of the cool things that our engines can do is they can give them a set of games that you played.

09:42.000 --> 09:52.000
We can tell who played them, which to me implies a kind of deeper understanding that these models we've created have been able to achieve even though we don't fully understand what's going on inside these models.

09:52.000 --> 09:56.000
We know that they've somehow been able to recognize different playing styles.

09:56.000 --> 10:04.000
So what makes your playing style different from your playing styles these models have somehow figured it out so they can distinguish different people from each other.

10:04.000 --> 10:20.000
And I think this is actually a really good teaching tool because to me, one of the good things that a coach or a teacher can do is recognize their students work and understand their students strengths and weaknesses so that we can better guide the development of their and their learning process.

10:20.000 --> 10:39.000
We are doing experiments now where we're imagining a collaboration between a human and the Maya engines in an actual chess game, which is more along the lines of what I think you're talking about Sam, which would be a very interesting kind of collaboration because if I was playing with someone who was way stronger than me.

10:39.000 --> 10:53.000
They suggested I do a move that I really wasn't capable of handling or understanding, I might mess up the game entirely. And so it's interesting to find the right balance and this is something that I think Maya can do well, they can figure out, OK, you're at this level.

10:53.000 --> 11:03.000
Let me advise you to do this move in the game because if I advise you to do this really advanced move that a grand master would do, I think you're probably going to mess it up in a few moves from now.

11:03.000 --> 11:12.000
So understanding what level your partner is at is another interesting dimension of this work, which I'm really looking forward to exploring.

11:12.000 --> 11:25.000
And I'm imagining that in this case, level can be much more rich and robust than beginner intermediate expert is I've seen you do these types of moves before.

11:25.000 --> 11:35.000
This is something that you could probably execute or understand. It's kind of just that the edge of what you might otherwise do so I can teach it to you.

11:35.000 --> 11:44.000
Yeah, exactly. And this is one of the nice things about chess is that there is a very well established rating system called the elo rating system that gives everyone a number.

11:44.000 --> 11:56.000
And you know, this rating system is relative to other players that you play, but we've trained Maya engines for people who are rated at let's say 1100 1200 1300 up to 1900.

11:56.000 --> 12:04.000
A grand master's rating is about 2500 and the world champions rating is above 2800. They call them super grand masters these days.

12:04.000 --> 12:16.000
And so you have this very detailed rating system and we can train models that are catered to different levels, even if they're only separated by let's say 100 kilo rating points.

12:16.000 --> 12:32.000
So yeah, I think I was envisioning that the there will be a degree of learn personalization that transcends the an elo rating like a not being a chess person.

12:32.000 --> 12:41.000
I'm envisioning that, you know, two people with a 1500 elo rating might have different strengths and weaknesses and lean on different moves and things like that.

12:41.000 --> 12:49.000
And the engines even more customized to their particular playing style, then, you know, just looking at the number.

12:49.000 --> 12:55.000
I see what you're getting. Yes, yes, exactly. Yeah, you're right that when we train these models to learn about individual player style.

12:55.000 --> 13:05.000
They do learn some of the nuances and the kinds of moves that individual players will make. And you're right, the two people at the same level might be there for very different reasons.

13:05.000 --> 13:16.000
One might be stronger at the opening of the play. One might be stronger in the middle game. One might be really good at end games or one might be really good at what they call tactics or, you know, ways of maneuvering your pieces to get an advantage.

13:16.000 --> 13:26.000
So the my models we've created will try to understand the kinds of moves you'll make. And this is actually how they're able to distinguish your games from other people's games.

13:26.000 --> 13:40.000
And it's interesting that you mentioned this point about being good at different things. It's a very actually a very deep observation, I think, because a lot of times people will play our bots, which we say, oh, we trained these bots on moves played by people who are 1500 rated players.

13:40.000 --> 13:50.000
And then they play the bot and they say, this is way stronger than 1500 or stronger than 1500. And the reason is, because we're collecting the some total of knowledge of people who are at 1500.

13:50.000 --> 13:55.000
The total at the totality of that knowledge is actually stronger than a 1500 rated player.

13:55.000 --> 14:02.000
So if you put a lot of 1500 rated players together and they're good at different things and they got to that 1500 rating for different reasons.

14:02.000 --> 14:12.000
The combined wisdom of that group of players is actually something that's stronger than 1500 rated players. So that's one of the most common questions we get in emails.

14:12.000 --> 14:18.000
Why is this bot stronger than the games you trained it on. And it's exactly for this reason that you just mentioned.

14:18.000 --> 14:24.000
Right. It almost prompts kind of a philosophical question about the rating system itself.

14:24.000 --> 14:39.000
It does. Yeah, there's a, and I think it's an interesting question about group wisdom and, you know, and what people can do when they come together, like, does that work and look, when we've trained them with automated algorithms and data crunching, we can actually take that knowledge and I think use it in a more cohesive manner.

14:39.000 --> 14:50.000
If you put 10 people in a room and ask them to play a game together, which they sometimes do in chess, you know, there was a game famous game where Gary casserox played the world where everyone could collaborate on the moves together and played against him.

14:50.000 --> 15:01.000
I actually don't know how well that works. That's an interesting experiment to run. I mean, you want, then you're talking about people who are coordinating and trying to make a decision together. And that's, that's another problem on its own.

15:01.000 --> 15:06.000
Awesome. Awesome. Dan, why don't you introduce us to your project.

15:06.000 --> 15:23.000
Yeah, so my research work is in a different domain than said and chess, but it has the same kind of over actually team, if you want, of like, how do we get computers to meet people where people are right in people's space where people find themselves.

15:23.000 --> 15:38.000
You think about how we interact with computers today, the dominant mode still remains one that we had from the 70s and 80s where, you know, I sit down on a chair in front of a screen, I type on a plastic keyboard, I know all about files and directories and Wi-Fi connections.

15:38.000 --> 15:46.000
But the computer has no idea about me about, you know, my space and where's my attention and how do I behave as a human in the social world.

15:46.000 --> 15:58.000
And so in my work, I'm looking at how, how might we create systems that can interact with humans in physical space with the fluidity that human interactions have.

15:58.000 --> 16:01.000
Now, I'm particularly interested, as I mentioned before in language.

16:01.000 --> 16:25.000
And if you look at a lot of the language research that happens today, a lot of it is anchored in the written or the spoken word, right, like we have machine translation speech recognition, you know, documents, marization, it's not a surprise that we equate language with with text in some sense, because I think writing is such a kind of powerful cultural tool that we have.

16:25.000 --> 16:35.000
And if you look closely at how interaction actually happens between people in face to face settings, it's a much, much richer phenomenon that goes well beyond the spoken word.

16:35.000 --> 16:48.000
We do a lot of things non verbally, we coordinate with each other a lot without realizing, even that we're doing these things, how do I place my body and my shoulders relative to everyone else in a cocktail party group.

16:48.000 --> 17:07.000
And so I look and for how long and how long did my gaze linger here or there, the facial expression I have head nods and head shakes, the prosodical contours of my speech gestures, all of these things coming to play to create, you know, the simulness that we have with each other.

17:07.000 --> 17:24.000
And a little bit is that the richness of this process does not become apparent until you actually try to ask the question, well, how might I make a computer participate in that, you know, how might I build this computationally, you know, and then you realize, wow, there's all these, all these different things that that are going on.

17:24.000 --> 17:38.000
In my work, I'm trying to look at various ways of computationalizing if you want these processes and getting computers to understand the social physics of how we interact with each other.

17:38.000 --> 17:51.000
I can give you an example, for instance, like think of how you take turns, you know, multi party conversation, right, we have this voice assistance today in our pockets, we push a button, ask a question, get an answer back.

17:51.000 --> 17:56.000
There's this kind of turn taking model, right, speak something, something gets spoken back.

17:56.000 --> 18:02.000
And if I'm lucky, maybe there's, I can do a follow up turn and some context is carried, right.

18:02.000 --> 18:16.000
Now, if you look again back to the dinner conversation, you know how to speak and when to speak, you know, you know the timing of when to speak and you do that seamlessly and you actually use a lot of cues for that.

18:16.000 --> 18:32.000
For example, one piece of work we did is on building models that let computers do inferences about not only when the speech happening, but who is actually talking, if I mean, you know, kind of group setting, who are they talking to, who do they expect should talk next is it might turn to talk, right.

18:32.000 --> 18:49.000
So there's all these problems that come in before you even get to things like speech recognition that create the glue in human human interactions, and we're trying to look at can we get computing systems to reason about these processes and participate in them.

18:49.000 --> 19:04.000
But my initial sense is that on the one hand, there's an element of these types of problems for which an AI learn type of approach is ideal, right.

19:04.000 --> 19:14.000
It's very much akin to in computer vision, you know, could you write down the rules for identifying, you know, a cat's face versus a dog's face and an image.

19:14.000 --> 19:20.000
So, but, you know, you feed enough data to a CNN and it can do it pretty easily.

19:20.000 --> 19:26.000
So, you know, similarly, I don't know that I could write down the rules for turn taking, it's just something that we know how to do.

19:26.000 --> 19:38.000
And so learning that should be ideal on the other hand, knowing how to write down the question seems really hard.

19:38.000 --> 19:50.000
That's right, there's a lot of a lot of it's funny that you mentioned that that's that's exactly spot on like a lot of the difficulties we're having is almost in how do you formulate the problem.

19:50.000 --> 19:52.000
How do you verify these constructs?

19:52.000 --> 20:05.000
What is what is the actual construct that I want to model sure I can train something, but I need to first decide what what is the representation I'm going to use a word we're dealing with a lot of questions of for instance in this multi party turn taking model.

20:05.000 --> 20:13.000
What is the representation question, do I represent, you know, one way to go about it is to think, OK, I'm going to represent this notion of conversational floor.

20:13.000 --> 20:19.000
One of us has the floor at a given point in time and I'm going to try to train a machine learning model to figure out who has the floor.

20:19.000 --> 20:27.000
But I could go differently about it. I could say no, no, no, the way this process actually really works is that we each do floor control actions.

20:27.000 --> 20:38.000
So for instance, if you look in social linguistics and cycle linguistics and so this literature in the space of human communication dynamics, you'll find patterns like if I want to.

20:38.000 --> 20:46.000
You know, give you the turn in a conversation, you know, I might end my sentence with the downward prosody and look at you, right.

20:46.000 --> 20:56.000
Whereas if I don't want to give you the turn, I might kind of put some hesitations in there and look up and avoid gaze contact while I retain the turn because I want to formulate what I'm going to say next right.

20:56.000 --> 21:04.000
So so you have these patterns and so then you can think, well, maybe I can model that maybe I can model, are you doing a floor release action?

21:04.000 --> 21:08.000
Are you trying to release the conversational floor or are you doing a floor hold action.

21:08.000 --> 21:15.000
But this question of representation and how do you represent these concepts that are kind of fuzzy and, you know, nature doesn't come in boxes.

21:15.000 --> 21:23.000
We kind of have to put it in boxes to computationalize things, but I think issues of representation are actually quite important.

21:23.000 --> 21:28.000
And there's of course the dimension of yes, a lot of these things can be trained from data.

21:28.000 --> 21:33.000
You have to have the right kind of data, you know, it's the problems are very multimodally nature, right.

21:33.000 --> 21:38.000
There's there's both visual and audio, you know, signal in how we do this.

21:38.000 --> 21:52.000
And then apart from the inference problems, you also have control problems, right, because if you're let's say a social robot museum guide, right, that really wants to interact, you need to not only understand what's going on, but you need to control your own actions.

21:52.000 --> 22:04.000
All needs to happen under uncertainty and also under latency constraints and the important time in constraints because, you know, you cannot wait too long, you know, to keep things going smoothly.

22:04.000 --> 22:16.000
So I think there's a space of problems, you know, from representation to inference to control, you know, that only to work well, you know, to get something that that really works.

22:16.000 --> 22:43.000
And you talk about this broad line of research as physically situated interaction, the in the robotics example, there's, you know, the physicality of that is very clear in the turn taking example, maybe less so, is there a spectrum of physicality in the examples that you look like, or maybe another way to put that is, how do you think of, you know, the physical aspect of these types of problems.

22:43.000 --> 22:56.000
I mean, in some sense, I think even in turn taking, it is quite, or the way I conceptualize it, I think of it, it is quite, I don't know if physical, maybe it's not the right word, it's embodied, it's an embodied process.

22:56.000 --> 23:05.000
When we interact with each other, we have all these affordances of embodiment, like the fact that I can shift my gaze from A to B can communicate actually something.

23:05.000 --> 23:34.000
That's in my mind that gay shift is almost like a physical process, right, like I'm pointing from here to there, but certainly the space is, you know, so, so I think often of embodiment and I guess of the, what are the affordances that embodiment creates an embodiment does not need to mean antropomorphic embodiment, you can sometimes create things that convey meaning in a spatial or in an embodied sense, without necessarily fully anthropomorphizing things or having robots that look exactly like humans.

23:34.000 --> 24:00.000
On this idea of embodiment, I'm wondering, Sid and Maya does, to what extent does that come to play in your research, your systems are looking at humans and trying to understand, well, you tell me the extent to which that comes into play.

24:00.000 --> 24:20.000
Yeah, I think it actually, you know, dance, dance work and dance platform and framework that he's created a great inspiration for me because I really want Maya to get into that direction right now, Maya has survived by studying data, a public chess game data offline to try to understand human playing styles, strength weaknesses, things like that.

24:20.000 --> 24:33.000
But ultimately what I want to be able to do is to be in a situation like a situated environment where there's a teacher working with a student trying to teach them, and this is where a lot of dance work really inspires me because that dynamic is going to be very interesting.

24:33.000 --> 24:45.000
I can provide the teacher with all these tools, I can tell them here are the weaknesses, here are the games that played here, the kind of moves they make, but then looking at that interaction, how does a teacher use that to help train the student is a student getting it.

24:45.000 --> 25:11.000
What are the different learning styles, these are some of the questions that I'm looking into now that are really forcing me to branch out away from my comfort zone and the disciplines that I've been trained in as Dan is doing branching out into other disciplines like education research, social social science, psychology, behavioral decision making to try to understand how that dynamic should look and how it should adapt to different learning styles, different teaching styles.

25:11.000 --> 25:26.000
Ultimately, how do we measure progress? So one nice thing about chess is it's not so hard to measure progress. We have rating systems and you know people can play games and we can, you know, we have a good metric for progress in that sense, but this dynamic between teacher and student what's working what's not working.

25:26.000 --> 25:50.000
That to me is is definitely a very situated problem, a problem of looking at two humans in a working together, and this is something that's fascinating, we were really slowly starting to get towards those kinds of experiments where we're actually involving humans and trying to show that they're actually learning, and so all of these questions are coming up and honestly I think it's a much more challenging space to be in I can't hide in my bubble of chess much longer.

25:50.000 --> 25:57.000
I'm going to have to kind of break free and deal with the real world in the way that Dan's describing.

25:57.000 --> 26:10.000
And then soon raises an issue that I'm imagining is quite challenging in your environment, and that is kind of performance and progress measurements and benchmarking.

26:10.000 --> 26:37.000
How do you measure turn taking, for example, I'll be frank, it's a mess, so it's really like it is challenging. I mean, like I just mentioned, even their education, you do influences that the representation you use, you know, might influence how you how you're able to assess something, you know, how do you measure fluidity or you know kind of seamlessness interactions.

26:37.000 --> 26:54.000
In a lot of this, you know, when you're looking at the human computer interaction space, you know, you can ultimately go to a metric like, you know, user satisfaction, or, you know, you can you can ask people, you know, how, how did this feel or is was this experience better than that experience, you know, you can get some signal back.

26:54.000 --> 27:09.000
But the signal is either it seems far at the end of a system that has many different components and then the question becomes, well, what translated into that, you know, like, you know, how do I use that signal to drive improvements in my pieces and my components.

27:09.000 --> 27:24.000
Or you get a signal that's at the level of your component, you know, like the little box you build, build to make inferences about turn thinking let's say, and then the question becomes well, but does a 5% improvement in that mean anything anywhere.

27:24.000 --> 27:34.000
I think the other challenge I think in the world that I mean, I think in seeds world as well, is the interactive nature of things right.

27:34.000 --> 27:47.000
There's been a lot of progress in the last couple of decades, you know, in many areas of AI where people are able to establish have been able to establish clear benchmarks and metrics right and you have these competitions and people escalate and they'll better and better and better and better.

27:47.000 --> 27:58.000
And there's a way to to evaluate and assess and measure progress and, you know, we might disagree about whether the blue score, you know, it's really a good metric or you know what, what the metrics are.

27:58.000 --> 28:11.000
But at least there's a way to measure, I feel in the interactive space, the problem gets more complicated also because the systems are interactive and I think chess is the same way, or at least if you're talking about the interaction between a teacher and a student right.

28:11.000 --> 28:36.000
Whatever the system or the teacher does right affects how the student or the other part of the user behaves so you're in this kind of chicken and egg problem back and forth loop and the evaluation really to do a proper evaluation really to have a system that works with people and that you evaluate with people and that's just costly is not as easy as sort of downloading it this and you know calculating accuracy.

28:36.000 --> 28:53.000
So I think you're hitting on evaluation is a huge challenge. Yeah, I think it's also yeah, sorry, you know, that what dancing is making me realize that this dynamic is also a very complex one for which the reward function is unclear on when someone's teaching someone something.

28:53.000 --> 29:16.000
It could be that ultimately they they gain from it and the rating improves but they may have had a horrible time because it was a stressful experience that i'm going through this with my kids you know like you know they're going to intense piano lessons and other kinds of sports lessons and maybe they're not enjoying it but underneath the covers maybe they are actually developing and improving so is that the reward metric I should focus on or should I focus on their and happiness and their engagement in the process.

29:16.000 --> 29:43.000
And they're you know their ability to last through lessons longer so these kinds of metrics and signals I think are very multifaceted multi-dimensional and one of the things I you know I tried it in my work is try to collect all of those signals so that later on we can after the fact play around with different kinds of reward functions that combine these signals together to see which ones are the right ones if I just optimize for your elo rating sure maybe that's ultimately what a lot of just players care about but you might not have a very pleasant process.

29:43.000 --> 30:12.000
You know of learning going through it and in some sense I think that this is something you mentioned earlier Sam about you know AI being better or even while suited for certain parts of it i'm fascinated by this question because I actually think that AI can serve a role that maybe it might might be difficult for human to serve well in some situations like you were giving the example of recognizing images are putting into words what it means for a cat to be a cat.

30:12.000 --> 30:41.000
Some things in the in the dynamic of chess and in other situations I imagine where may I may be more suitable you know for example an AI engine won't get impatient with you sometimes people feel more comfortable actually when they're working with an AI engine or doing puzzles online because they can make mistakes and no one's watching them right when you're making mistake in front of a teacher I think that's a completely different dynamic than making a mistake in front of a robot or an engine or an AI or some online tool.

30:41.000 --> 31:09.000
Right so there's an interesting synergistic approach we can take care I think we have to open our minds a little bit and think about places where AI can be better suited to some of the task and where humans can be better suited some of the task so I find I think that's a fascinating question Sam and I don't have answers in that space but you mentioned it and it is something I i've been thinking about and realizing over time as we're as we're thinking about putting our chess work into a more situated environment like the ones that is describing.

31:09.000 --> 31:37.000
We started the conversation talking about representations broadly and one of the things that your work has in common is you know in some ways the machine is trying to build a representation of the human and how the human learns and how humans communicate in this turn taking example how they learn in the case of chess.

31:37.000 --> 31:52.000
I remember reading an article or read an article not too long ago actually that was I forget the details but it was about chess and the person was talking about this experience that they were having.

31:52.000 --> 32:21.000
Learning chess and then playing their their child to learn chess and he described there's an aspect of the experience that he described as kind of you know he's not really able to articulate why a certain move is is clear to him now where as you know previously it wasn't clear to him at a prior level like it's just a whole new.

32:21.000 --> 32:31.000
Dimension of play that you know opened up to him you know based on achieving a greater level and.

32:31.000 --> 32:46.000
I think that's tying into me is like i'm imagining that the state that we're trying to represent of a human's knowledge of chess is very complex and like how does a computer begin to build and model that.

32:46.000 --> 33:02.000
Yeah yeah it's it's a interesting question it's I think what you what you described is something that I've experienced myself because in the process of doing this chess research I've tried to improve my own game and you know what I see at different levels.

33:02.000 --> 33:19.000
Definitely changes as I understand the concept I now see it almost immediately I see in a position I know this is not good or I should do this but this feels wrong and because I'm obsessed with teaching I tried to put that into words so I can explain it.

33:19.000 --> 33:33.000
And this is something that the AI engines that we've developed are not giving us like they're they're they're able to recognize and see these patterns but they're not able to translate them into words and I think that's one of the biggest problems with the way we use.

33:33.000 --> 33:44.000
Chess AI engines today is that they just tell you what the best move is they don't really tell you why and the more important than that they don't tell you why in a way that you can understand.

33:44.000 --> 34:01.000
The why for the explainability research that we see in a yeah I think so I think there is a there is a lot of there is a lot of potential to adopt some of the techniques that people have developed to explain what's going on inside models.

34:01.000 --> 34:12.000
To dissect them to understand which features contribute to which decisions or which data contributes to which decisions that could be relevant here I've done some work in this space myself trying to connect.

34:12.000 --> 34:32.000
Decisions made by model to the training data that caused those decisions i'm trying to say okay these are the these are the reasons this is the data from which that model derived that decision and to try to draw these connections but there's still a lot of work to do and explain ability research but this is definitely something I've become interested in more because I want to be able to explain.

34:32.000 --> 34:42.000
In a better way why I believe that you're going to make that move or why I think you're going to do this or why I think you're going to make a mistake here and if I could explain that better.

34:42.000 --> 34:52.000
By poking into a models and understanding what they understand innately then maybe I can advise or guide a teacher or coach in a better way.

34:52.000 --> 35:02.000
Then tell us a little bit more about how this idea of understanding the human experience represents itself or plays out in your research.

35:02.000 --> 35:24.000
Yeah so I like we were discussing representation is core and in a lot of the systems we build we actually so the explain ability aspects kind of surface almost in a different way almost like in an embody way and i'll describe what I mean by that but we the the models will be our compositional and we put in the representation so we don't have so much this black box problem like.

35:24.000 --> 35:44.000
I train something and I don't know what goes on inside of it right because each of the models we have are are you know built on representations that we kind of understand at the same time there's a there's a parallel problem almost which is when we interact with each other we're very good at kind of.

35:44.000 --> 36:04.000
It's a state transparency in some sense or we were good at projecting you know mutual understanding and what we understand what we don't understand you know you can kind of look at my far or eyebrows or you know my hesitation in my speech and get a lot from it and you know for instance you know tutoring domain that helps a lot like sido saying you know like.

36:04.000 --> 36:33.000
And you know progress there's a similar notion in this embodied systems within some interesting work at some point where we're trying to reflect the actual probabilistic uncertainties that the machine had internally in various models in facial expressions like you know if I if my vision tracker doesn't see you that well maybe I can squint and lean forward a bit this is in the case of a virtual avatar that sits on the screen and tries to interact with people you know or we had a.

36:33.000 --> 37:02.000
Little one of these now direction robots those those giving directions in the building and you know people are curious sometimes they would approach it and get very close to it thinking that if they get close and speak louder will understand better you know so we're looking at okay how does the robot kind of explain to people that look this is the ideal place where you should sit and the ideal kind of volume level or you know how do we shape the interaction but in a gentle graceful way you know kind of to get people to.

37:02.000 --> 37:22.000
Go into the zone where the system functions well so it's interesting when you guys are talking about explainability my mind when they're like I'm like that's that's I guess some sort of explain ability some sort of like here's where I am you know and this is something we we humans again do often and also unself consciously so yeah.

37:22.000 --> 37:51.000
Yeah you know we were able to it's interesting we have because we have this kind of black box model problem you know it's hard to to it's unsatisfying in some sense I have to say this this kind of the research a lot of the research that we do when we don't have a good understanding or explanation what's going on underneath the covers so I really think that that's something that you know in both of our work we want to pursue going forward we can get hints here and there as an example one of the things we've discovered is that.

37:51.000 --> 38:09.000
What identifies your playing style often ends up being the slight mistakes that you make not the obvious mistakes like the big blunders they call them blunders and chess or the really good moves you make but it's the slight inaccuracies that tend to be more distinguishing of one player to another that's an example of something we've done.

38:09.000 --> 38:31.000
We can also map people to some space like we've been able to map players and their games in some embedding space high dimensional space and say you're very similar to this person or your games are very similar to this person's game so these two games are very similar but what does that mean we really have to unpack that a little better so we can do a lot of things constructively but then I think we actually need to deconstruct them.

38:31.000 --> 38:46.000
If I can use that word overloaded use of that word but we need to deconstruct the constructions we've made and try to convert those into explanations that's something I definitely want to do more work on going forward.

38:46.000 --> 39:15.000
Can each of you talk through the different types of models that you are using the different types of data the relative complexity of the setups I think part of you know what we're gathering here is that each of your projects correct me if I'm wrong is kind of a portfolio it's a research portfolio as opposed to a specific system but I'd love to you know make this more concrete by talking about you know the different things that you're exploring.

39:15.000 --> 39:44.000
Then sure yeah so the models themselves you know the so as I mentioned before there's issues of representation inference and control right on the inference side right on the perception side we do use machine learning models they're multi model nature often right like and usually when you fuse multiple modalities or information coming from different modalities you know they get better the types of models we use are sometimes really simple actually you know like you know simple

39:44.000 --> 39:54.000
random forest or logistic regression or not even in this deep learning space you know although there's a lot of research in deep sort of multi model learning.

39:54.000 --> 40:10.000
And the other set of kind of models we we use and we often struggle with are more like the control models or decision making models where you need to kind of balance various courses of actions you know under uncertainty and also under time constraints like

40:10.000 --> 40:32.000
and so I think it's not so much for me in the in the specific technique like you know do I use this particular kind of you know machine learning technique is more in the problem formulation you know or how you know we build models for instance where the system reasons about the time elapsed in its internal computations

40:32.000 --> 40:42.000
because we need to be very fast and fluid you know and so so you need to even reason about how much time will this take for me to computer to think about so that I can take the right action.

40:42.000 --> 40:58.000
And so I think those are the interesting bits to me where you get to sort of novel ways of sort of bringing in you know value of information approaches and you know kind of thinking about how can you make decisions under latency constraints and under uncertainty.

40:58.000 --> 41:10.000
But a lot of the models we use are you know from machine learning perspective relatively straightforward and simple most of the work I think is in the representations.

41:10.000 --> 41:27.000
How about you said yeah so the networks we built on are similar to the ones used by deep mind in their alpha zero work their famous alpha zero work and which has been open sourced in an engine called Lila and so these are deep neural networks they have residual layers convolutional layers they have residual connection sorry between these layers.

41:27.000 --> 41:46.000
So they're pretty deep and complex neural networks but what we've used what we've done is we've taken that architecture so the same kind of brains that are used to learn optimal chess play and using the same kind of brain network to instead predict human play and predict what humans are going to do.

41:46.000 --> 42:14.000
So we did have to tweak and and change networks a little bit especially near the inputs and the outputs but for the lot for the most part we can reuse a lot of that brain and just redirected by changing the question again this is a question of formulation formulate the problem differently ask a different question and you might be able to use the same brain to answer that question because obviously what this brain has been able to do this calling it a brain but you know it's this neural network architecture has been able to do is learn chess really well.

42:14.000 --> 42:42.000
And I do think that you need to know chess pretty well in order to understand what a human is going to do or what a particular student is going to do but you don't necessarily have to know how to play the game optimally to do that as we know right is an interesting question right we know that coaches aren't always the best at playing those games like a great coach it's not necessarily a fantastic player themselves but they're usually a good player or they usually have a decent amount of experience so

42:42.000 --> 42:59.000
so yeah that's basically what we've been focusing on so far is basically using deep neural networks including existing ones that have already been used to you know to train engines that play very well and just repurposing them by asking a different question or optimizing them in a different direction.

42:59.000 --> 43:22.000
And are you reusing the architecture or is there a transfer learning ask type of approach where you can pre train your you're taking a pre train model that knows how to play chess really well and applying existing you know weights and and training to the problem of that you're trying to solve.

43:22.000 --> 43:46.000
Yeah there's a transfer learning dimension so we do train the original network that was let's say used in alpha zero or in the open source Lila version to train the initial Maya models but then after that point once you've trained that let's say a model for a particular player rating level we then can take that network and fine tune it with games may played by an individual player to learn a personalized model.

43:46.000 --> 44:15.000
So we do take that initial network we freeze some parts of it there are a lot of different ways to do transfer learning and to do fine tuning so we freeze some parts of the network we let other parts of it evolve still and we then supply it with data from an individual's games and then we can take the base model and specialize it to each individual person as long as we have enough games played by you and you know what is enough really has varied and we've been you know looking at this data problem quite deeply as well to but you know 5,000 games.

44:15.000 --> 44:26.000
But you know 5,000 games are great 10,000 even better if you played a decent number of games we can then kind of fine tune these base models to to the individuals so yeah there is an element of fine tuning that we do as well.

44:26.000 --> 44:29.000
Got it got it.

44:29.000 --> 44:37.000
Dan share a little bit about where you see the space going both in terms of your individual research and more broadly.

44:37.000 --> 44:57.000
Yeah I mean as I mentioned like I'm super excited I think we have we really have a tremendous opportunity I think in the next I don't know maybe 10 years 20 years to really create new experiences and new modes by which you know interact with computing systems where they meet us more in the physical world right.

44:57.000 --> 45:14.000
Obviously there's a whole space of you know robots and robotics you already see robots being deployed in hospitals taking supplies from roommate to room B you know I think we're going to see more and more of those systems of times goes goes by perception is getting better and better sensors are getting cheaper.

45:14.000 --> 45:17.000
So I think there's interesting opportunities in that space.

45:17.000 --> 45:38.000
Interesting opportunities in terms of applications in sort of intelligent spaces and buildings you know whether it's a factory floor that automatically detects hazardous conditions or whether we're you know enabling more independent living for the aging population with sensors that kind of monitor and understand what's going on.

45:38.000 --> 46:03.000
I think there's a lot of opportunities in that space and finally another space that really excites me is the augmented mixed reality space where we kind of you pick a bit over the horizon maybe these devices are not yet you know consumer you know great but but if you pick over the horizon you can kind of see this world where we will have sort of virtual artifacts over late on our physical world.

46:03.000 --> 46:20.000
And there's really interesting questions about how do we design those you know human centric way you know in in a way that blends with our physical reality how do we how do we create those experiences while putting the human at the center.

46:20.000 --> 46:44.000
There's a lot of sort of a lot to be done in this space in the particular space of language interaction I think again we've made a lot of progress in the last 10 years you know in a lot of the core if you want perceptual tasks but I think we have more integrity work ahead of us where we need to bring together more of these technologies you know you're starting to see already sort of more of this multi model space growing you know.

46:44.000 --> 47:09.000
There's a lot of digital question answering people starting to put vision and audio together and so I think there's a lot of more to be done in that space in bringing together different kinds of AI technologies into systems that work kind of end to end in real time like in in a fluid way I'm excited about it I think there's there's a lot of potential.

47:09.000 --> 47:19.000
There's an example of in the mixed or augmented reality space that you mentioned how this human centricity.

47:19.000 --> 47:41.000
Yeah I mean it's it's you know so if I have things overlaid in my visual field of view you know as I work on something you know and someone walks into the room and walks through my windows that I'm working in you know well how do my windows need to move towards just socially to what else happens in my physical space I don't know is that a good idea is it a bad idea.

47:41.000 --> 47:59.000
You know how might we construct an educational experience you know I was thinking the other day I was you know as a kid I was very much into physics and so how might I construct an education experience where where it's a tutoring like you know going back to what seat was talking about where where machines can help tutor or or educate.

47:59.000 --> 48:23.000
How might I construct an experience where I see the forces visualized on objects in the room and how do I build a tutoring experience based on that that that kind of really understands about where my attention is and what I'm interested in and drawn into and so on so I think there's there's a lot of potential I don't know people and people get very creative and so I expect to see a lot more on that I guess.

48:23.000 --> 48:47.000
From my research and technology standpoint I have this deep conviction that machines need to really understand us as social beings you know there's not one user interacting with one computer world of people that are you know embodied and that do things with each other and I think developing technologies will enable all sorts of interesting kind of ways of interaction in the future.

48:47.000 --> 48:59.000
How about you said what are you excited about you know when I hear about Dan talking about these kind of situations that humans put themselves and I really am amazed at how amazing humans are I guess and what they're able to do really is not.

48:59.000 --> 49:15.000
And I thought I could hide in my world of chess and in the moment I start thinking about okay now how do I get a teacher to help a student all of a sudden it just opens up this kind of worms all the issues that Dan is talking about the cues the learning styles and he worked you know he liked physics he maybe he thought spatially and he learned better spatially.

49:15.000 --> 49:44.000
You know can can my teacher learn to do that you know so what humans are able to do as teachers or as just individuals interacting with each other is really amazing so you know going forward my my goal is to try to find the right kind of hybrid solutions I really believe in that that kind of world and I oftentimes I write hybrid HIV RID where the H is for human and the AI is you know for AI I really do believe that there is a good synergy to be had here.

49:44.000 --> 49:49.000
And I want to understand what AI is good at when humans are good at and how they can come together.

49:49.000 --> 50:13.000
So this is something that I don't really see in a lot of the work that in a lot of the fields that I've worked and I often see one kind of replacing the other there's some kind of competition between them not so much of a synergy and so I do believe that going forward if we're able to achieve what we set out to do let's say in this small domain of chess maybe it might be an instructive example of how

50:13.000 --> 50:21.000
AI and humans can interact in a more productive way and a more synergistic way and I hope to try to apply that to other settings as well.

50:21.000 --> 50:39.000
It doesn't have to be other games it can be more complex situations it can be medical settings it can be settings where you're you know where you're driving cars or you drive and you're using kind of smart devices and smart engines but you're trying to do it in a way that works synergistically.

50:39.000 --> 50:56.000
And I think so you know I really I'm looking forward to trying to paint this hybrid picture a little bit more clearly between and understand the right balance and synergy and also think about the safety involved in that this is something that comes up all the time I think.

50:56.000 --> 51:25.000
I imagine this comes up a lot and dance at work and situations as well is how to how to create a safe environment how to guarantee safety how to make people feel comfortable when they're using these engines in chess it's a very I can give you a very simple very safe example you know in chess we can talk about safe moves what we were talking about earlier like I advise you to do something but it's too complicated and you lose the game but the cost is that you lost the game I mean in others in more complex applications in real life the cost can be much greater.

51:25.000 --> 51:33.000
So we're looking a lot into safety and this is something I want to think about kind of going forward as well.

51:33.000 --> 51:35.000
Awesome awesome.

51:35.000 --> 51:42.000
Well said Dan it's been a pleasure chatting with both of you and learning about your research thanks so much for joining us.

51:42.000 --> 51:47.000
Well thank you this is great thank you thank you so I had a lot of fun.

51:47.000 --> 51:57.000
Bye bye.

