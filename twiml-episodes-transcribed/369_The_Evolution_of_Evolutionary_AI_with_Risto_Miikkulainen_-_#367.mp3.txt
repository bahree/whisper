Welcome to the Tumel AI Podcast, I'm your host Sam Charrington.
Hey, what's up everyone?
Before we get to the show, I'd like to send a huge thanks to everyone who participated
in last week's first ever interactive podcast listening session with Kwak Le.
Kwak and I had a great time answering your questions and discussing his perspective
on the state of deep learning research and all the cool things he's up to at Google.
If you missed the session, we'll have a transcript of the Q&A linked from the show notes
page at twumelai.com slash talk slash 366.
That said, I am pleased to announce our next live program, responsible data science in
the fight against COVID-19, which will be live streamed this Wednesday, April 22nd at
noon pacific time.
Since the beginning of the coronavirus pandemic, we've seen an outpouring of interest on the
part of data scientists and AI practitioners wanting to make a contribution.
At the same time, some of the resulting efforts have been criticized for promoting the spread
of misinformation or being disconnected from the applicable domain knowledge.
In this discussion, we explore the question of how data scientists and MLNI practitioners
can contribute responsibly to the fight against coronavirus and COVID-19.
This discussion will be streamed live on YouTube and other social media channels.
For more information, visit twumelai.com slash RDSCOVID.
And now on to the show.
Alright, everyone.
I am here in Vancouver at NURBS 2019, and I've got the pleasure of being seated with Ristu
Mikkuleinen.
Ristu is a former guest of the podcast, as well as an associate VP of Evolutionary AI at
Cognizant and Professor of Computer Science at the University of Texas at Austin.
Ristu, welcome back to the Twimal AI podcast.
Thank you.
Pleasure to be here.
So it's been a bit since we last spoke at least a year, because that's how long you've
been at Cognizant.
In addition to being at UT Austin, you were working on a startup called Sentient.
Tell us a little bit about the story and transition there.
Yeah, that's right.
So Sentient was a startup in AI, Evolutionary AI in particular.
And we had at Sentient, made a couple of products, one in stock trading, another one in Evolutionary
Optimization of Webpages.
And at one point, those were spun off at their own units.
And the research team now moved to Cognizant, where we continue as an Evolutionary AI research
team and powering applications, trying to take Evolutionary AI to the real world in multiple
applications.
Cognizant is primarily a consulting company?
Yes, it has done a lot of outsourcing and now a lot of consulting in AI and data modernization,
digitization, and AI is becoming a much bigger part of the company because that's a natural
extension of digitizing and starting to work with data.
And so before we started rolling, you mentioned that a big part of what this transition does
for you and the team gives you more exposure to real world scenarios and maybe exposes
some of the things that you need to be thinking about when you're trying to apply Evolutionary
AI in the real world.
Talk a little bit more about that.
Yes, that's been a lot of fun doing consulting and doing modernization in many different industries.
It turns out that AI is not just building something like self-driving cars that never existed
before, but there's a lot of opportunity in just about everywhere to take advantage
of AI.
AI.
And that's because almost all industries now have data.
They collect data about the customers, about their products, how they work, how they sell,
and also feedback on what works what doesn't.
And that data provides a great opportunity to bring in AI, to learn from that data and
then improve it in the future.
And it turns out that it doesn't really matter what industry you are in.
You might be in retail, healthcare, or oil exploration, or manufacturing, or many, many
different industries.
All of those are now on the verge of being able to take advantage of AI.
And that's what we're trying to do.
Take the technology there and make it actually work and add value.
And so how is that change in perspective is kind of exposure to different use cases changed
how you think about your particular work with evolutionary AI.
And maybe we can start with having you do a little refresher or primer on evolutionary
AI for folks who haven't yet heard your, you know, our first conversation.
Sure.
And it is different from what you might imagine what AI is today, because today, most
of AI is taking that data and then building a model that predicts what will happen in
the future.
And that is, for instance, image recognition, object recognition, language understanding,
speech recognition, all of those are trying to get AI to do what we already know how to
do.
Now, with evolutionary AI, we're trying to take the next step and that's making AI creative.
Having AI actually come up with new solutions or designs.
Discover something that does not already exist.
And that might be, for instance, a design for a web page.
Humans can design web pages, turns out that AI, evolutionary AI can do it better.
Come up with solutions or designs that take advantage of interactions that humans have
hard time understanding.
Humans can only keep a couple of variables in mind.
With evolution, we can keep hundreds, so hundreds of thousands of variables in mind and
optimize in a much larger scale.
And that's what evolutionary AI is.
It's making AI creative.
And there's a whole new opportunity here in applying it to different places.
Not just predict, but also prescribe and create.
And this web page design use case is one that you spent quite a bit of time working
on at Centian.
Is that still something that you're in the context of cognizant going out and working
with people on or if you brought ends to other use cases?
Yes, that was one of the first we started with and it's now its own company called
Evolve.
And they are marketing and they are building and developing that application, automated
web site optimization to maximize conversions.
We are doing other things.
We're really expanding out the opportunity to use AI to optimize decision making.
And that means that in companies, there's a lot of data about situations where decisions
had to be made in order to achieve certain objectives like maximize performance while
minimizing cost.
It turns out that data is absolute gold mine because we can learn from it what happens.
If you decide these actions in these situations, are you going to achieve your objectives?
So we can learn from it and we can optimize it.
And that's not something that is done today, but it can be done as soon as we get those
data sources together so we can learn from history, we can start optimizing for the future.
When you summarize the technical foundations of evolutionary AI or in essence how it works
what it does, how do you capture that quickly for folks?
Yes.
So Evolve or AI is population-based search.
So you are trying to discover something new.
You're trying to develop a new design or maybe a decision strategy.
You create a population of potential solutions.
That might be 100, 200 different possible solutions.
And then you evaluate how well each one of those work.
And then you discover that these are the good ones, these are the bad ones, we throw away
the bad ones.
You keep the good ones and then form recommendations and mutations of those good ones.
It's like it's after biological evolution.
This is how search takes place.
In computational evolution you can throw away a lot of solutions that don't work.
You're looking for some where the building blocks coincide so that you get a better solution
than your previous ones.
And this way you can find solutions in huge search spaces.
Two to the two to the 70th is one example we came up with designing a multiplexer for
70 bits, multiplexer problem.
Two to the two to the 70th is so large that if you print it out on a piece of paper it
takes light 95 years to go from the beginning of the number to the end of that number.
That's how many states there are where you're trying to find a solution.
So that's the power of evolution because it's population-based search.
You find building blocks, recombine them and gradually find the solutions.
And it turns out there are many problems like that in the world.
We haven't really thought of them as machine learning problems because they are so huge.
But now we can.
And part of that is that we have the compute and we have the technology.
And so is the idea to identify the problems that naturally lend themselves or are naturally
kind of inherently population-based or evolution-based or is this a technique that can be applied
broadly wherever we're trying to do machine learning?
Yeah, it is very broad.
It applies to problems where we need to find solutions we don't already know.
So it's not object detection, object recognition because we already know what those objects
are.
We have the power status.
It's problems where we don't know what the right solutions are.
What is the optimal design of a web page, for instance?
We don't know that.
We have to explore, try out alternatives and learn what works and what doesn't.
Now the population-based search is unique in that it allows you to explore a lot more.
You could do some of this with reinforcement learning and it'd be successful.
But it's based on improving an individual solution.
And if you have to refine it, you can with that technique.
With population-based search, you can hedge your bets.
You can have a population that's very broadly distributed.
You try things that you don't know anything about and you find stepping stones.
But then you can inspire in order to find something that's surprising.
And that's the crux of it.
Evolution allows you to explore and find surprises.
Those that human designers might not think of.
You mentioned reinforcement learning and I was going to ask about this, the relationship
between the two as you describe the two.
It almost sounds like in a way that evolution or these population-based approaches is like
a breadth-first search, whereas reinforcement learning is a depth-first search.
Yeah, that's kind of an interesting way of looking at it, I think it's accurate in a
sense that it's breadth-first search, but you don't try to find every possible solution.
You are casting your white net in that sense, have a lot of breadth.
But when you find something useful, partial solutions, then you do a recombination of
those.
That's the recombination, that's the interesting secret.
So you don't have to systematically do breadth-first search, you find something that works and
you recombine and focus where you go next.
That's the key of evolution and the theory of evolution is evolution, the computation is
based on that.
Building blocks, hypothesis and schema theorem, there's some theory that suggests that when
you find good partial solutions, they will become more prevalent in the population and that's
how you find those solutions that solve the problem.
So kind of going back to that analogy in deep reinforcement learning, there's work that's
happening to try to maximize what we learn as we're making, taking actions as opposed
to just throwing them out, you know, once we've gotten to an end state, that's kind of
analogous to what we're doing with evolution.
We're trying to take, you know, what we're learning from kind of this breadth-first search
if you will and combine the best of these elements together.
I think I may be pushing this analogy too far.
They really are different in that in reinforcement learning, you're trying to improve in a single
solution.
You get a little closer when you're thinking of off-policy learning where you're trying
to combine knowledge from multiple hypothetical universes, but fundamentally, population search,
space search, distribute your potential solutions, and it's based on statistics, obviously, it's
a stochastic search method, but stochastic is represented by the population.
So what's there in the population represents what you know about the domain.
So you gradually focus your individuals where the most likely solutions are.
But you always want to, there's another part of it.
You always want to maintain diversity.
You always want to explore areas that you don't know about, and that's unique to evolution.
That allows you to do that without much cost.
I mean, you can afford it because you have multiple solutions if some don't turn out.
That's no big deal.
You try something else.
And you eventually find a component that's been missing and then you recombine it with
other solutions to make big leaps in performance.
It's not a gradual search method that way.
You make these recombinations that actually allow you to make large changes and large improvements.
One of the areas that this has been applied is in like neural architecture search.
Yes.
Is that an area that you work in?
Yes, absolutely.
That's something I continue to work on.
And this has also been happening for a long time.
Architectural matter in neural networks.
And currently it is only a few people who have expertise to construct these architects.
So they're very different.
Now we can automate that by doing architects of search.
And again, population based search is great in that it allows you to hedge your bets.
Try out different architectures.
If you find an innovation, you can combine it with other kinds of architectures.
And therefore, come up with better ones.
And this is something that's been going on for decades.
We used to do it so that evolution optimizes the entire network, including its weights.
And now more recently, we optimized the architecture, the topology of the network.
And then use stochastic gradient to train them.
So they're interesting synergies between different approaches.
But again, the evolution based architecture search is the most, perhaps, bold or exploratory.
Because in architecture search, you can get quite a good performance by just tuning hyper
parameters, tuning some small modifications.
But with evolution, you can search a lot larger space.
We can look at the topologies modules, as well as hyper parameters, and find more surprising
architectures that way.
So this is, of course, very compute-intensive.
But that's what you want.
Because compute is still coming out.
We have access to more compute than ever.
And we can actually utilize it to do this more broad search and find more surprises.
And so from a research perspective, where is the research frontier around evolutionary
search relative to a year plus ago when we spoke like, how is it?
I'm assuming it like everything else in this space is evolving quickly.
What are the contemporary topics that folks are talking about?
Yeah, there's one area is novelty, trying to encourage indeed search to discover things
that are surprising, how to do that right.
We are starting to get a handle on that.
It's not just that you reward novelty, but you do it in a systematic way so that you guarantee
a certain level of quality, as well.
So there's a synergy between optimizing the performance and encouraging surprises and
novelty to be discovered.
What I think is still a biggest leap that we need to make in evolution is even though we
have computational methods that have demonstrated the discovery of new things, we're still not
quite at the level of natural biological evolution.
For instance, we are missing major transitions.
How do you search and change your own representations so that now you can search in a different level?
Like transition from single cell to multicell organisms.
Creating evolution, discover representations that allow you to build a larger structure
systematically.
What's an example of that particular challenge applied to a real use case?
Well, it could be, for instance, in behavior.
In AI, we see a lot of agents in games, for instance, so in that domain, it might be
that you have individuals now that perform very well in Atari games, for instance, maybe
Starcraft.
But the next level there might be that they start building roads, they start building buildings
or vehicles and then discover strategies that utilize those structures that they constructed.
That would be a concrete major transition from one level where we operate at the level
of whatever objects they are, to constructing new objects that then you use.
Yes, that strikes me as a big leap, to get its creativity.
In some ways, I don't want to necessarily invoke AGI, but it's a creative essence that
has been very difficult for us to achieve with AI.
Presumably, you're scaling that back to small leaps.
What exactly does that mean?
How do you formulate that problem from a research perspective?
That's exactly right.
That's why it's called major transitions.
We've seen it in biology a few times.
It's not something that happens every day in biology, ain't it?
But we haven't really seen it in evolution, computational evolution yet.
But we are getting there.
It's done to understand how that might work.
Indeed, they happen in small steps.
Open and open and discover is another term that's used there.
Something that doesn't really run out of steam after you solve one problem, but it creates
another level of problem that you then start.
Typically, those are done in games.
So you perhaps evolve the game environment together with the solution.
So you start with navigation, a simple environment, and then you have more objects there that
you have to get around on maybe other opponents that become more sophisticated.
So that's how you approach it.
Sounds a little bit like curriculum learning in a sense that you're kind of gradient-graduating.
You're making your environment or your problem more complex than trying to...
Yes.
It's much like curriculum learning with one exception, the curriculum is designed automatically.
It's a co-evolutionary system.
So you have solutions and problems that evolve at the same time.
And that's how you might get open-endedness in the end, and that's the goal.
We're not there completely yet, but there are some indications that we might get there one day.
So that's one big area.
There are also, I think, an interesting opportunity in looking at what's been learned in biology
in the last 50 years or so, because most of the techniques are based on our understanding
of how genetic algorithms work based on population biology.
But we know a lot more now than we did in 50 years ago.
So looking at what current biology thinks is happening in evolution and discovery might
give us better computation.
So one of them is that it's not just selection, mutation and recombination, but there's also
drift.
There's also large populations with weak selection that allows you to come up with solutions
that don't necessarily help.
They are weakly deleterious, but in the long run, serve a stepping stone to something
bigger.
And our computational methods don't actually do that today, and we're starting to look
into how we can do that.
And a third area might be indirect representations.
So we are currently in evolutionary computation focusing on genetic representation that maps
directly to the solution, one to one.
In biology, there's a developmental process.
There's interaction with environment.
There's even interactions between genes.
And then the final product, like a human being, is not determined by genes.
It's determined by genes plus environmental interactions.
How do we take advantage of that?
How do we create a learning process that takes into account that there's a mechanism of
interaction that makes you what you are?
So that's a third area where we're going today and in the future.
I'm going back to the analogy of, or the use case of architecture search and trying to
think through the way that this problem of creativity expresses itself.
And when you're trying to apply evolutionary AI to something like an architecture search,
are you starting with, presumably you're starting with some known architectures and evolving
based on those, and at some point you want to get to something new, right?
Kind of refine that, you know, how do you represent the knowns in a given problem generally
and then, you know, what does it mean to, you know, recombine things?
It depends how ambitious you want to be.
I mean, you could start with an architecture that already exists and mostly refine it.
You take dense net, you take rest net, you take something like that, modify some of the topology
of that.
So you've got layers and connections and kind of these existing, you know, modules and
things like that and you're reorganizing these things that you already know.
And that already helps.
And you're taking, you're taking the components and principles and then defining a search
space around it and finding if there's a better solution that utilizes those components.
And that works quite well now, but you could try to make it more ambitious.
And that means that you are defining a larger space, maybe, so you take one principle,
but might be that architectures are build on modules.
And then you repeat those modules many time in some kind of organization.
So now you start by evolving a module, which is a combination of different layer types.
You program those up first, define a module and then you define how you combine it at
the second level.
So that's another good approach.
It's a little bit broader search space now because you have a search of modules as well
as the whole architecture.
But you have to, if you have to have a hunch or an idea where the solutions are likely
to be, so that the search will be, you know, finished in our lifetime.
Yeah.
That's kind of the thing that I was poking at.
It's like, you know, how do you represent the thing that you have no idea what it is?
You have to, it has to be at least directed and, you know, not totally open ended or
else.
Yeah.
Well, this is a really a crucial research question because you scientifically, well, you
want it to be as open and as possible.
You want the system to be able to discover things you don't already know.
Right.
But the more knowledge you put in, the more likely you are to find some solutions.
Right.
So it comes back to the major transitions that we really need a system that can evolve
its own representations so that when it discovers something useful, it can use that as a new
representation and build upon it.
And we're not quite there yet.
Yeah.
I mean, we have, live an idea how to put together modules and then structures based on
those modules, but eventually it bottoms out on certain layer types that you program
up, certain ways of doing the connectivity.
And that is based on what we know of what kind of architectures people have built and
how they work.
So you try to abstract those principles and expand a little bit, but not too much.
So it's not a needle in a, well, it's needle in a haystack, but it's still guided towards
architectures.
We believe I like it to work.
And so is this space gotten more accessible over the past year in change or they're like
easily accessible toolkits that someone can, you know, download and play around with
those implementations.
Yes.
Yeah.
There's a lot more now.
They look more approaches as well.
And most of those approaches are clever ideas on how to make do with less, make more
with less.
So, for instance, you evolve a smaller architecture and then there's a mechanism of expanding
it, like just copying and making more, adding more depth and so on, which adds more power.
So you're trying to discover a principle and then mechanically expand it to get more performance.
But there's another direction, I think, that's really interesting in the future also.
And it's not just to try, not just try to come up with better performing architectures,
but optimize something else about that architecture as well, like its size.
You're trying to come up with a small architecture that does the job to a certain specification.
So maybe architectures that are more robust against adversarial attacks or other aspects
like that, use less energy, people are becoming quite aware that these are really not sustainable
architectures.
You have hundreds of millions of parameters.
You can't really use it on a car or a phone or a doll or something like that.
They have to be manageable.
So optimizing the architectures, not just for performance, but other metrics as well.
I think it's an interesting future direction and practical one.
Sounds analogous to multi-task learning approach, which is shown to have some great
advantages and other applications.
Yeah, and that carries over the idea that we shouldn't necessarily start from scratch
every time.
Because we already have some good models, use them and build on them and use other tasks
to bring them together, you don't have to start from scratch, you already have representations
that support multiple different tasks.
They might support a new task much more easily.
It might be possible to build something that supports a new task more easily.
And similarly, it has to do with data who has 100 million examples of their own application.
Those 100 million examples exist for ImageNet and maybe a couple of other benchmark tasks.
And if you actually try to solve your problem, maybe lung disease classification or something,
there aren't that many cases.
So you actually have to use other datasets in order to support learning of your own task.
And that's a multi-task domain and there also architecture search makes a big difference.
So that's interesting.
We asked what has happened since we last talked.
That has happened that we used to focus kind of one single track mine on performance, but
now we realize that there are many other things that need to be optimized in order to make
these things practical.
Switching topics briefly, you recently co-authored a position paper on kind of the historical evolution
of AI and what that says about where things are going or need to go.
Can you give us a quick summary of that?
Yeah, I'd love to.
How many hours do you have?
It's why I qualified that.
Well, there's a lot of discussion about AI and its role in society and good and bad.
And there are some reactions that suggest that AI is going to be dangerous and it's going
to increase inequality and various other challenges like that.
But what we took a look at is some of the other technologies that have been in a similar
role in the past.
And what happened there and what is happening now and discovered that there's actually an
analogy of what AI can do and what the pitfalls are as well.
So those other technologies were computing in general and the world by web.
So if you look at computing, it was initially just for a few government or industry research
labs, then became out-can PCs and Macs and now other people can use them, graphical interfaces
to them.
And cell phones that you have now computing in your pocket and it is now right now computing
has become like plumbing or like electricity.
So you don't even know where it happens, you don't have to, it's available.
So we call those stages standardization like PCs, usability, like user interfaces, consumerization
like cell phones.
And then last phase is making it part of the infrastructure.
And we see that in world by web as well, HTML, style seats, web 2.0 and what's happening
now is that everything is based on web interfaces or commerce and social media.
So in the world by web, the same kind of stages have happened and in both computing and
world by web, beyond the last stage, it's becoming the fabric of society.
Computing happens like plumbing, world by web is everywhere.
And you have your personal as well as business interactions in it.
So if you look at that and look at AI, you can see that there should be similar stages
in the future.
We are at the very beginning right now.
AI is done by a few experts, well in New York, there's 13,000 such experts, but at least
people are learning from it.
But it's still quite difficult to understand and apply and see the opportunities.
So that's before any of these four stages, but you can think of standardization.
So that's what does that even mean?
I'm trying to wrap my head around what would standardization mean for such a broad topic
like AI.
And would that is that I can't imagine that same question could have been asked about
computing before it was standardized.
Well, the way I look at it, it's, it's, it's, it means that the different AI's can
talk to each other.
So we have standard interfaces you can have a visual recognition system that can talk
to a natural language processing system.
And these are developed by different people, different companies, different research labs,
and they can talk to each other.
So we have standardized interfaces so that the AI's can build upon each other and talk
to each other.
But it's still a machine starting to machines, it's program starting, that's a standardization.
It becomes usability when people can talk to them.
And we are not there yet.
We don't really have an easy interface to talk to an AI.
It's very difficult to take advantage of those.
We have some initial attempts to that programming language is perhaps an interface that allow
you to direct the other certain solutions.
But it's not, by and large, not yet happening.
That's a usability part.
Consumeration means that anyone can take blocks away AI and put together a solution.
They can manage their finances, their health, they can, I don't know, design their garden,
the home, they use AI to do it, and they parameterize it, they run it, and they interact
with it.
So making it a consumer product, something that everybody can use for their advantage.
That's a consumerization.
Karl Semain, one of the popular visions of AI, that of everyone's going to have this
potentially a cadre of intelligent agents that are out acting in the world on their
behalf, and that requires the ability for these agents to talk to other agents and to
talk to other systems and things like that.
Yes, it requires that, that was a standardization, but also talk to people, the usability part.
But then the fact that you are actually in control, you consumer picks what you want
to do and what components to use and how to put them together.
So it becomes such a second nature for humans that you can actually solve problems with it.
So it becomes a point where you think of say furnishing a room, you call an AI agent to
try out different alternatives, make suggestions, you are totally running it, you're in control,
you calling it, it's not controlling you, that's an important part of it.
It becomes consumer goods just like, you know, cell phones or running errands on the
web, through the web.
And the last step I think is really quite interesting and in the future, that it could become
AI could become a fabric of society.
And what that means is that we as a society decide what we want.
We want to maximize perhaps productivity and growth, but we might also say that we want
to minimize impact on the environment or maximize equality and access.
And then we can use AI to design policies and execute those policies so that those goals
are met.
I mean, that's what AI does.
It's really good in the end on optimization and discovery of how to achieve certain goals.
But when it becomes institutionalized in the sense and in society, it means it gives
humans the power to come up and to achieve the goals that we decide.
And that's remarkable because it's not happening today.
It's never happened.
There's always been individual personal agendas.
There's always been dishonesty graph, various things that get in the way and create conflict.
But if we let AI do the optimization, all we have to do is agree on what we want.
And that's not a small challenge, but it separates all the challenges that get in the way today
from the really what we should agree upon is what we want.
That's the ultimate goal.
When getting there, I think there's a stage where it becomes irresponsible to try to make
decisions and create policies without the use of AI.
AI is objective.
It's based on data.
It allows you to optimize and currently it's done by humans and not so well.
And it becomes irresponsible to try to make these decisions as humans when AI can do
it better.
But we have to still take the responsibility of setting those goals so that we can use
those AI in a responsible and productive manner.
So that's the last stage for AI.
And that's why I think it's exciting.
And it's also important that we are now at the crossroads.
We can actually adopt that vision and make AI such that it helps us achieve what we want.
And we have to make the right decisions in a way.
We cannot let the mistakes of the computing enrolled by web get in a way.
There were mistakes along the way.
And our monopolies as well as over regulation, they can get in a way.
And we have to recognize that we need to build these capabilities over time.
We need to adjust to them.
So is the main thrust of the paper and the model, is it that is it to kind of locate us
in time?
Hey, we are here in the next stage of standardization.
Is it to reassure us that everything's going to be okay because there's this kind of bright
future for AI driven policy making like what is the main thing that you're trying to convey?
Yeah, that's, it's definitely trying to raise awareness that we have a great opportunity
to make AI work for us and improve the world that way.
But we have to recognize it.
We have to recognize it.
We have to build it most likely through these stages because we've seen two examples of
them.
And at the time when we were working on computing a world where we made some mistakes,
we could learn from those and do better this time.
And it's possible, for instance, that AI is over-regulated.
There's no access to data.
There's no decision making done by AI because people are afraid of it and they don't really
see the potential benefit and it will never develop or it will, development will be delayed.
But recognizing the potential, recognizing the pitfalls allows us to see what needs to
be done and hopefully nurture the field so that it will, will get there and it will happen
in smaller steps. We can't replace everything a decision-making with AI today.
We'll have to develop the technology.
We have to develop the datasets.
We have to develop the, it's a humans' understanding how to use it.
And there are some challenges like you pointed out that humans are not willing to give control
very easily to machines.
But there's also, I've seen, as a professor, I've seen a change in the last couple of years
and decades that people are much more accepting of it now because they can see the benefits.
And that's happened in, say, just one example, self-driving cars.
2003, we were working with manufacturers developing self-driving systems and they said that they
will never happen because people will not let machines take over their car.
They can only warn you while you're driving.
But somehow the attitudes changed.
People saw what the opportunities are and now we have self-driving cars almost ready
to hit the road.
That kind of change of attitudes has to happen and people have to be educated and learn
of what's possible and learn to understand what the limitations are, so to avoid them.
But the sooner we understand, both of those dimensions, the opportunities as well as
the challenges.
I think better off we are and we can make this future happen sooner and another day.
Unfortunately, we're going to have to leave that there, put a pin in it, we probably should
have started the conversation there and we could have gotten into it for the whole time.
But interesting perspective for sure and I am very appreciative of the update on Evolutionary
AI, so he still thanks so much for taking the time to chat with us.
My pleasure.
Thank you.
Awesome.
Thank you.
All right, everyone.
That's our show for today.
To learn more about today's guest or the topics mentioned in this interview, visit twimmelai.com.
Of course, if you like what you hear on the podcast, please subscribe, rate and review
the show on your favorite pod catcher.
Thanks so much for listening and catch you next time.
