Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
This week on the podcast, we feature a few of my many conversations from last week's AWS
Reinvent Conference in Las Vegas.
For today's show, I'm excited to present our second annual Reinvent Roundtable Roundup.
I had a blast last week learning about all the new ML&AI products and services announced
by AWS.
If you missed the news coming out of Reinvent, or you want to know more about what one
of the biggest AI platform providers is up to, you'll want to stay tuned because we discussed
many of their new offerings in this show.
This year, I'm joined by my friends Dave McCrory, VP of Software Engineering at Wise.io
at GE Digital, and Val Berkevici, founder and CEO of pencil data.
We cover all of AWS's most important ML&AI announcements, including SageMaker Groundtruth,
reinforcement learning and Neo, DeepRacer, Inferentia, and ElasticInference, ML Marketplace
Personalized, Forecast, TextTrack, and more.
We don't do these kinds of discussions very often on the show, but I always enjoy it when
we do, and I hope you do too.
Before we dive in, I'm at Neurips this week in Montreal, and CubeCon next week in Seattle,
and I'd love to connect with any listeners and attendants or in the area.
Feel free to shoot me a message via at Sam Charington on Twitter via email or the Twimble
AI website, or, if you see me, don't be afraid to say hi.
If you're heading to Neurips, look for the listener meetup and AI platform's meetup topics
I've posted in the Hooba app.
See you around.
And now, onto the show.
Hey, what's up, everyone?
I am here at ReInvent, and this is becoming a bit of a tradition, isn't it Dave?
It is indeed.
And the tradition that I will unveil is our second annual ReInvent Roundup Roundtable,
in which we discuss all of the cool things that happened here at ReInvent, all of the
announcements, etc.
And so before, or as kind of our first step in jumping in, I would like the two of you
to introduce yourselves, and I guess Dave, since you are our veteran panelist, why don't
you go first?
Certainly, my name is Dave McCrory.
I am the VP of Engineering for WISEIO, a division of GE Digital, that works on machine
learning and industrial internet of things.
Awesome.
And Val.
Yes, I am.
And Dave, it's my honor to be here on the second Roundup ReInvent Roundup.
My name is Val Burkivichi, and it's very wise if you say I'm going to let me pronounce
my name first, because it always ships up.
Always ships up some people.
I am CEO and co-founder of pencil data.
And our tagline is, we tamper-proof digital transformation.
But that has a lot of deeper meanings as well.
Before that, some people might remember me from your podcast when I was CTO of Net
App and Solid Fire.
And you know, I was thinking earlier about what is always so cool for me about ReInvent
is that I get to see so many people that I've known for so long.
Were both of you guys also at the very first ReInvent?
I was not at the first, but I think I've been at every ReInvent since.
Okay.
I think I'm a lot like Dave.
I have to check my records. I know I lobbied hard at Net App to be at the first one.
I don't remember whether we succeeded the first year or that second year for sure.
Okay.
Nice.
I was at the first and second, and I think I missed one or two in between, and I've
been at the last three, I think there are.
I don't know.
I think we do not have enough time to talk about everything that was unveiled and announced
here at ReInvent.
And of course, we'll want to kind of wait our discussion points a little bit to the
ML and AI side of things, but maybe a good way to start is to just ask each of you, what
are you most excited about based on what you heard announced here at ReInvent?
In my opinion, there are a couple of things that are really exciting.
I think the Lambda layers function, which really comes down to being able to run different
runtimes on Lambda is probably the biggest and most exciting thing to me.
I think that's going to have a profound impact on the use of Lambda and the growth of Lambda,
but I see it plugging into a lot of the machine learning kind of problems that we had that
were much harder to use Lambda pre-being able to bring your own libraries, dependencies
and execution environments.
I think that's big.
I also think it really adds, I guess, another layer of difficulty if you're a platform
is a service vendor, not that there weren't already some difficulties in some forms or
others, but I think layers definitely adds to that.
So is layers the ability to support multiple or arbitrary languages for Lambda functions
or is it more than that?
It is indeed the ability to do the runtimes, so that would be safe if you wanted to run
or go or Python or Java or pick your favorite language, Rust, it doesn't matter.
But then along with that, being able to have the libraries and dependencies that go with
that, so that formerly, if you wanted to run a Lambda, it was very, very basic code that
you were essentially just gluing two things together with.
You might have something trigger, something else, et cetera, but it was kind of limited
from that perspective, very scalable, but also very limited.
With layers, you end up with so many different abilities that you wouldn't have before, prior
with just regular Lambda, and I would say that makes it incredibly attractive in my mind.
You can now do much more complex things even within the Lambda functions themselves because
of the ability to do this.
What you still cannot do is directly tie it to persistence, so there's still no guarantee
of persistence.
If that makes sense, that's kind of the one missing thing.
Other than that, I guess sky's the limit, so to speak.
They also added some other functionality, but the layers is the most exciting to me.
I'd say the other thing, since I mentioned that there was more than one, the other thing
was the Kafka streaming capability.
But now, basically AWS will run Kafka for you, so Amazon Managed Streaming for Kafka is
pretty exciting in my mind, being able to just use Kafka instead of having to set it
up, configure it, manage it, and maintain it.
That's pretty exciting.
If I was someone that was running Confluent Kafka on my own, and I used AWS, this would
really make me pause and think about, do I want to keep doing that, or would I rather
just let Amazon do it?
Kafka is a big part of a lot of data pipelines, but I also recently interviewed a woman
named Lima Nasseri from Comcast on the podcast to build out a data pipeline for a recommendation
system using Lambda.
I thought it was really cool that her team was able to take advantage of Lambda functions
to do data transformations and things like that, so I think that'll be increasingly part
of the machine learning toolkit and not just the traditional app dev toolkit.
That's right, and Nasseri has personalized, so for me, if we take us all the way back
to Wednesday yesterday, I'm thinking of Andy's keynote, and we were talking about the
very first couple of reinvents where the big announcement was a new instance type, or some
new lower pricing for EC2, or RS3, et cetera, and we've come such a long way since then
where the major highlights, even though I think there were some pretty cool storage highlights
for me, were definitely all the machine learning introductions.
There's so many, but I think my personal favorite is the SageMaker Ground Truth, but that's
one of the things I wanted to have when I first got into machine learning, and I just couldn't
believe it wasn't there.
But I don't know if you guys might be more current with the Google Suite or the Google
Cloud portfolio than me, but I'm not sure if they have a similar service yet, so it just
strikes me as AWS continues to just be more in tune with what their customers really
want, and they're executing and delivering really well.
And so SageMaker Ground Truth is a new offering that basically allows users to create these labeling
pipelines.
And how do you want to go through the details of that, how, how, okay.
So such a big part of an average data scientist's work, if there is such a thing as an average
data scientist, is actually setting up supervised training, right?
That supervised learning that's effectively what most machine learning is nowadays, and
there's a very manual human dependency ironically on that part, which is to actually label data.
So a lot of the captures and recaptures that we see sometimes are asked to identify objects
on a four by four frame of pictures, is us being mechanical turks of doing labeling
for other people to label, you know, features in an image and so forth, the ability to apply
machine learning intelligently, and use inference to automatically label the huge portion
of these data sets now without all that manual effort.
I think it's a huge step forward in the productivity of data scientists and the ability
to generate, you know, more knowledge models going forward.
It's part of that theme, I think Samu and I discussed yesterday, which is that AWS ironically
better than Google at the moment is doing a really good job of democratizing AI, democratizing
machine learning for people, democratizing the data science field itself.
And that's, that's good for the industry, right, that brings more people into it.
It brings more projects forward.
It promotes more knowledge models, and I, you know, I've got a selfish motivation as well
and that my company helps with the reproducibility of all that once we have more candidates
for, you know, promotion into production.
The thing that I found most interesting about ground truth is that it's the labeling,
you know, it kind of ties into these third party labeling services.
So mechanical turk is one example, but they, I think they announced like seven different
partners, including figure eight, but it's not just that there's a pipeline that includes
active learning.
So they are optimizing what needs to be labeled basically there, they're going to choose
what needs to be manually labeled according to some optimization function as opposed to
randomly at the idea being that you kind of manage and keep low the costs of the labeling
process.
That is pretty cool.
Yeah.
That's by far the exciting part to me, you know, the fact that there's better integration
with mechanical turks is an important sort of workflow improvement.
But the fact that we're finally being able to sort of, you know, go, go native, if you
will, or eat our own dog food and actually automate the function of labeling by and large
is, you know, even if it's not a complete solution today, the fact that that's the goal
and the fact that we have it initial operating is very exciting to me.
So now I've got to say you surprised me here, given what your company's focused on nowadays,
I had a thought that your favorite announcement was one of a couple of others.
Well, there's definitely on the blockchain side there was, there was the expected, right?
So AWS is kind of playing catch up to IBM and Oracle with regards to offering managed
hyper ledger blockchains, but also having the nice option of managed Ethereum blockchain,
which I thought was super cool.
The wild card, which I think has got a lot of people buzzing, definitely myself included,
is QLDB, the, I'm not sure why they named it quantum ledger, but certainly the quantum
ledger database is super exciting.
And it actually corresponds to talks I've been giving it or Riley this year around has
this very famous blog in the, just before the peak of the, the cryptocurrency media called
a fat protocol blog, which argued that there'd be a lot of network effect value in a protocol
more than the apps and that was before there were 2,000 versions of Ethereum, so, 3,000 potential
network effects.
So the sad protocol blog was brilliant, you know, in 2016, but did not stand a test of
time.
And at least the enterprise reality is very much that, you know, there will be a few
key platforms, blockchain, and secure ledger platforms, such as QLDB, that enterprise
is standard, a standardized on, but there won't be 2,000 of them.
And that the network effect will indeed go to the platform and the application layers
where the value is closer to the user.
Well, it's my understanding that the quantum and QLDB comes from the name of the internal
AWS system that they kind of extracted this from, whether, you know, encode or in idea.
And what's so exciting about that relative to, you know, the managed blockchain that,
you know, folks kind of expected them to come out with.
So what most people don't realize when you're talking about a managed blockchain service
is it addresses 2 of the 3 impediments towards adoption and enterprise.
That first one being sort of the design and creation or building of a blockchain.
And the second one, which is very important after that, the ongoing operations and management
of that blockchain.
But the third one that, you know, the actual buyers or, you know, budget owners of these
technologies, the executives that would want to see results that isn't addressed by this
or any other managed blockchain service is the usability of the blockchain.
It's actually tying into your application that's actually seeing either, you know, operational
efficiencies or greater compliance or ideally even, you know, new business models that were
impossible before.
And that's the part that, you know, wasn't announced really by a managed blockchain service.
But they inched a lot closer with QLDB, where now you've got, you know, a fully ready-made
solution to just consume.
It's not about thinking how you would build QLDB or how you'd manage it.
Obviously, AWS is greater than president doing that for you.
It's ready for consumption.
So that's what excited me very, very much about QLDB.
And it certainly just is another instantiation of soon to be popular service that validates
the market to pencil data.
Right.
Right.
So for me, and I guess I'm sure you guys felt like this as well, it's kind of like a kid
in the candy store, so many cool new things.
It's really hard to pick just one.
But if I really, really, really had to pick just one, the thing that I'm super excited
about is the SageMaker reinforcement learning announcement.
And I've been a fan of and talking about and learning about reinforcement learning for
a bit now, folks on the podcast have heard a lot of conversations about that.
But what is always part of those conversations is how hard it is and how, you know, unstable
the algorithm training processes, how difficult it is to get the right reward function, all
of these things, and how hard it is to ultimately apply it in a real enterprise environment.
And we've seen folks take swipes at making that easier, bonsai, has been a sponsor of
this podcast that in our industrial AI series last year, and they were acquired by Microsoft
because they did such a great job at this.
But AWS has such a massive presence in the marketplace.
There's a real opportunity for them to bring a lot of attention to reinforcement learning.
And as a result, kind of start this virtuous cycle of, you know, more eyes on it, you
know, lower the impediments to doing it and make it much more easy to extract value out
of it.
So I'm super excited about that.
It's an ascension to SageMaker, which is their kind of data science as a service platform.
It supports a wide variety of 2D and 3D simulation physics environments, including open
gym and Sumerian, which is their 3D environment, RoboMaker, which is another one of their
announcements, Roz, which is the robotics operating system.
It's got a lot of the pieces in place.
You know, the one thing that's kind of interesting about this relative to AWS is typical MO.
They tend to be, you know, this is a lot further out in front, I think, than they tend to like
to be, right?
They kind of pride themselves on being very responsive and only building stuff when like
real customers are asking for it.
And oftentimes commoditizing something that already exists, right?
Like S3, we knew what storage was.
They didn't invent that.
EC2, they, you know, made servers more accessible.
Yeah, they're not inventing reinforcement learning either.
So I don't know that this analogy, you know, fits very well.
But it's certainly, we're certainly way out ahead of the market in some ways.
And hopefully, you know, what I'm excited about is just accelerating that process because
the challenge with deep learning is that it's so data-intensive, labeled data-intensive
and reinforcement learning plus simulation promises to fix that for a good many applications.
And this is a quick question I'd have for you, Sam, is, you know, empirically I'm seeing
a ton of just, you know, image recognition, text and voice recognition and the related
neural networks that correspond with that.
I haven't seen a lot of successful production, you know, transfer learning or reinforcement
learning projects in place.
You know, do you think that would kickstart that and would open up a new front, new frontier
actually in the home machine learning world?
So I would say, you know, I would kind of pick apart transfer and reinforcement learning.
I think transfer learning is one of those things that people maybe don't talk about as much.
It's kind of receded into the background, but it is, I think foundational to a lot of
what folks are doing in the image domain, like it's very popular to pick up a pre-trained
image net model.
And if not use that out of the gate, like tweak that, use, you know, or fine tune it,
they'll say, and kind of start with that to avoid having to train everything from scratch.
And in fact, there's a lot of work that's been done recently by Jeremy Howard and Sebastian
Rooter, who have both been on the podcast relatively recently to apply that same transfer
learning concept to natural language processing.
But reinforcement learning, on the other hand, like it's still largely the domain of like
playing video games, it's like the thing that research labs are pursuing as a stepping
stone to general artificial intelligence, the only folks that very, I've seen very few
folks applying deep reinforcement learning in a kind of commercial enterprise business
kind of way, the bonsai again being the one.
Are you talking about, so you changed it to deep reinforcement learning versus reinforcement
learning?
And we also touched on the idea of transfer.
I tried to be careful there because, yes, reinforcement learning does have a history
that goes back to, I don't know when, I think the 60s, like it's been around for a while
and it's been used as a kind of standard optimization algorithm.
I think it's related to like multi-arm bandits and things like that.
I don't know a ton about it and how it's been used, but what's different is deep reinforcement
learning.
It's promised, but also the challenge is associated with making it work.
Got it.
And I've seen a lot of Elon Musk headlines around how open AI is beating all sorts of professional
e-sports gamers and stuff like that, but to your point, I haven't seen a lot of commercial
applications ever yet.
Yeah.
And if Amazon scale says anything, maybe we'll see that change over the next couple years.
I did want to hit on something interesting since we were talking about different things
that we believed were the most significant.
I've been kind of perusing and I know I had mentioned as my favorite and most impactful
being the Lambda Layers functionality, but I did kind of a interesting perusal on Twitter
and it appears that the most popular announced thing out there is the outpost announcement
out of all of them.
And by a fairly large margin, like three-ish X roughly compared to everything else, actually
that's not true.
Looking, the runtimes to Lambda is about, let's say, two thirds as popular as the outpost
announcement.
Although taking into account it was announced six hours ago, maybe it'll surpass it,
but outpost is pretty darn popular.
And I think it is pretty significant both for ML and such and outside of ML, really.
The other announcement that we didn't talk about that I do think has big impact for ML
is the, and I don't remember the name of it now, but it's the elastic something that
you can attach a GPU to an EC2 instance, I see that is pretty big as well.
So let's start there and then kind of work our way back to outpost.
I was in a conversation with someone yesterday, maybe it was you now, when we were talking
about what was kind of, what was our most exciting, what were the things we were most exciting
about.
And in that conversation, I prefaced it by, there's the thing I'm kind of geeked about,
kid in a candy store style, and the thing I think is going to be most impactful.
And that thing is the elastic inference.
So Andy, Jesse, I heard a couple of numbers thrown around, and in fact, this was a question
that I was asking folks to share data points on Twitter several weeks ago, but the data
points that AWS folks were throwing around were that anywhere from 10 to 20%, 10 to 30%
of the cost of doing machine learning is training, and 70 to 90% of the costs is inference.
And the example that someone pointed me to when I was first looking for this, that's really
hit home for me was Google, it turns out that their investment in the TPU building chips
and as much as they're investing in that now on multiple versions of these chips, that
all started when Jeff Dean kind of did this back of the envelope calculation that said
that our user base does just three seconds of voice search per day, the inference would
basically eat us alive and have us needing to build some multiple of them needing to build
some multiple of the number of data centers that they already had.
And so attacking that inference costs and AWS is throwing down numbers like 75% reductions
in inference costs is potentially quite huge for folks that are doing ML and a cloud.
Yeah, my question actually curiosity more than question is I always have this mental
model of training being done in the cloud, but inference at the edge and a bunch of the
use cases for customers who are working with autonomous vehicles, driverless taxis and
so forth are very much that.
But do you have any idea what the percentage is of inference if there is a breakdown roughly
between cloud and edge?
That is a good question.
I don't have any data.
I think what everyone's excited about for edge is that even if whatever the number is
today, there's kind of, you know, whenever you see like somebody joked about it on did Andy
Jesse joke about this on stage or maybe it was at the analyst summit, but like you always
see this exponential curve in the number of devices that are going to be out in the edge.
And there is a presumption that a lot of inference is going to be moving to the edge for, you
know, latency and bandwidth reasons and all other things.
And in fact, they had an announcement there, I think, yeah, actually so it's SageMaker
Neo did.
I don't think it showed up in the keynote.
Did you guys catch that one?
I did not.
I did not see it in the keynote.
I don't remember seeing it anywhere.
So SageMaker Neo is a essentially it's, it's a, they're open sourcing it.
It's an open source model compiler.
And so they kind of pitching it as this train wants run anywhere, but they've built in some,
some deep optimization into this model compiler so that they're touting two X performance and
one tenth the size for your models and they're targeting a wide variety of hardware targets
including edge devices and some of these like compute and memory constrained device targets.
That one should be pretty cool.
And it kind of begs the question to Dave's point, you know, how low or how far can they
take out post and future generations?
And they bring it down to you know Raspberry Pi style and maybe not the elasticity of it
still have the exact same control and management flow that you'd enjoy in a cloud.
So I never thought of outpost quite like that.
So maybe we should jump into outpost and what it is and why are folks excited about it.
I think that's a good idea.
I think it's going to be the bridge that gets people that that had reasons why they needed
physical equipment on premises.
This doesn't give them the excuse that Amazon is only available in Amazon data centers.
You now have flexibility to have equipment running on premises that is the same as what
AWS runs in its data centers will to you all on site as well as offering the capability
to run and be either in the cloud or on site.
I see that as a pretty big deal.
It really isn't.
You know, here's a couple of the maybe non intuitive questions that come to mind for me is
how are Amazon and partners like we are going to prove compliance?
You know with data, the necessity laws or other privacy laws internationally with regards
to what kind of metadata and what kind of control, you know, really flows back and forth
between one of their regions and an on-prem implementation of outpost.
I'd love to get more details on that.
Well, one of the things that was not in abundance around this announcement was details.
What we know is that this is AWS Design Hardware.
It's the same hardware they say that runs in their data centers, but it's delivered and
installed on the customer premises.
There are supposedly two flavors of it.
What's not clear at all are the hardware specs, and they said they're not talking about
that until next year.
There are two kind of flavors of it.
One of them is, you know, runs as VMware kind of flavor of AWS.
And the other is kind of traditional EC2 instances.
So it appears like an extension of your AWS Availability Zone.
That begs my questions.
Yeah, I would want to feel like as a developer is an operator, I'd want to operate like
that.
But you know, when I think about overseas deployments or even things like China, there's
a lot of those detailed questions that need to be answered to see just how broadly applicable
this could be.
You know, this is not new in the kind of the world of cloud.
Azure Soft has Azure Stack, which is kind of the same idea.
AWS is saying that I guess they talked about EC2.
They talked about cloud formation templates and AMIs being available.
They said that some of the other services like RDS and SageMaker will be supported.
It's not clear when that will be is could take a while.
I'd love to see how much of some of these cool new, you know, Lambda services and runtimes
are available without post as well, because quite naturally, me like most SaaS companies
would love to be able to answer yes when certain customers ask to run your functionality
on Prem.
This offers a promise of that and based on some of the answers to the detailed questions
now or later, this could be game changing in terms of really helping the entire SaaS
industry penetrate deeper into the enterprise, you know, on the back of AWS.
I would argue you could already do that with the green grass.
You can already run Lambda functions and several of the other capabilities green grass
on premises, along with some of the capabilities that Snowball provides.
And that was another announcement that was made.
I don't know if it was pre the conference or not, where the new specs of Snowball, which
were pretty impressive, and that's another thing that you can run on premises along with
green grass.
And the green grass stuff, people are running all sorts of Lambda functions and such already.
And that's cool.
If I could see DynamoDB and S3 and obviously Lambda as we've mentioned, and just a few basic
easy to instance types available on prem with the same control flow and the same developer
interfaces that that's a game changer at least for from my SaaS offering.
So before we kind of run down the rest of the ML and AI announcements, there are a few
candidates for the wackiest new product or new offering or the most unexpected Val, what's
on that list for you?
I wouldn't call it wacky.
I'd call it super geeky cool, which is deep racer.
Right?
I'll put you guys on a spot and say if you've pre-ordered yours already, I think I remember
your answer Sam, not sure, but I have not ordered that although I did, I did order the deep
lens when it was available and got that played with that quite a bit.
Very cool.
The other wacky thing and it belongs in the rumor mill was that Amazon AWS, we're doing
something with all the photos of the attendees that appear on the badges with regards to
just propping up their own image training data sets for their services.
Yeah.
Again, that's just a rumor us on Twitter that caught my attention.
Okay.
I would say wackiest for me is AWS station.
Yes.
And so that caught me off guard.
A fully managed ground station as a service for when you want to launch a satellite.
That I was not seeing, I did not see that one coming at all.
I can finally plan that trip to the Sahara desert.
They also announced RoboMaker, which is this environment for like building robotics applications
that I kind of, I mean, they did some stuff with with with Ross.
Last year, I think.
And so maybe this is an extension of that, but I, you know, they're doing like it's a full
robotics development environment, it's got simulation environment, they're doing fleet
management.
That's that's one of the biggest things that I thought was exciting about that was the
simulator where you can, where you can see not only a single robot and interfacing with
that, but you can simulate that fleet of robots and how they will behave without needing
all that equipment.
I think that's a game changer in and of itself for people doing robotic projects.
Mm-hmm.
And that's actually cool, but ironically, I think that was a Tuesday announcement, right?
So it almost got wrapped up by me.
I'd love to see again whether or not so much reference customers, but just see examples
of how people are applying this, even in small ways, you know, whether it's interesting enough
for, you know, robotic assembly and assembly lines, whether it's helping with logistics
of shipping or other interesting applications, particularly ones where there's a lot of
health hazards to humans and robots could do those tasks much more safely.
Mm-hmm.
Speaking of early announcements that kind of got, you know, swept up and forgotten in the
melee here, there was an interesting announcement in what has now become known as pre-invents,
the, you know, all of the announcements before reinvent.
We've got a name for that now, so as one of the pre-invent announcements, they announced
predictive scaling.
Did anyone catch that?
I think out of the sight of my eye, but I never actually internalized it until you
brought it up right now, that's stupid.
Was that tied to some of the automated tiering in S3 that they announced?
Ah, so that's another interesting one.
So I don't know, you know, maybe kind of ideologically tied, well, definitely ideologically tied,
and that's what's kind of interesting here.
So predictive scaling is basically, I'm assuming it works, you know, in conjunction with like
cloud formation and some of the other auto-scaling mechanisms, but the idea is that they've got
machine learning models now that are making predictive scaling decisions as opposed to
the operator having to define a set of rules around, you know, memory or CPU utilization
or what have you.
And so this is particularly interesting for folks that have applications that maybe have
a long warm up time or take a long time to, you know, stand up for whatever reason.
Yeah, I was thinking, yeah, Lambda cold start, right, that sounds like an ideal application
for that.
And so this, the S3 thing, I forget what that one is called, but it's similar like they're
going to be predictive tiering or something like particularly staging data across these.
Storage tiering is like a good decade, 15 year old technology that's been applied, you
know, particularly in the days of high cache systems like the MC Symmetrics when it first
came out and then in the area of flash now with memory tiers and flash and disk tiers.
But they've always been fairly, you know, static models or very simplistic algorithms.
And I think some people are trying to, you know, I remember, because it's not hopefully
not confidential and it's been more than 12 months at NetApp, we were definitely trying
to do some more clever things with regards to on tap caching, but this seems to take
it to a whole other level because of obviously the resources available for both the training
and the inference to apply, you know, the right decision to whichever data needs to move
between tiers.
So these two announcements collectively for me are a strong candidate for kind of a most
exciting thing at re-invent and it's the idea that machine learning is becoming part
of the infrastructure, right, part of the way that we're able to deliver, you know, scalable
infrastructure.
So, you know, Jeff Dean, obviously Google does a lot of this and AWS does a lot of this
stuff internally that we don't know so much about, but Jeff Dean at Google, for example,
has been doing talks on this for quite a while about how, you know, we can use machine learning
for a ton of things to make infrastructure more effective, like query optimization and
cache optimization and, you know, predictive scaling and tiering.
But I think this is just the beginning of this wave.
And that's one of my favorite topics actually.
Probably remember, I think the title of Jeff's paper was the case for learned indexes.
It was actually a eco-authored, it was a bunch of other researchers, but it was fascinating
that it ties into a blog Andre Carpathy from Tesla Rotor on software 2.0 and how, you
know, incredibly valuable, you know, web properties such as the actual Google homepage, the
search page is anywhere between 15 to 20 percent machine-generated code now, no longer
human-generated code.
And you know, more to Jeff's point, you're able to take a lot of these low-level routines
with a storage or compute resource management index management and so forth and be better
at it with thousands of instances of machine inference versus just a few smart DBAs or,
you know, other content managers and that's interesting, but also potentially disturbing
trend if it's not managed carefully.
So I'm going to run down these announcements and just jump in if you've got, if it strikes
you as interesting or you've got anything you want to chime in on.
So we talked about SageMaker ground truth, SageMaker reinforcement learning, deep racer,
minus on order, valve is on order.
I wonder, well, by the time this podcast is published, it will be more expensive.
There is a special on these things during re-invent.
So I tweeted about it, hopefully you saw that, if you're interested, EC2, P3, DN instances,
one of you guys referred to this earlier.
Yes.
Yes.
So this is the AWS's largest compute instance, P3, but with now 100 gig networking and VD
V100, 32 gigs per GPU, Skylake, VCPUs with the AVX 512 instruction set.
That sounds like a mother of all instance for today for this week.
It's a massive amount of compute power and an instance type that you can spin up on
demand.
Yeah.
Yeah.
It all comes back to the ability to rent a supercomputer right for as little time as you
need.
It's amazing, one of the amazing attributes of cloud overall.
So we talked about elastic inference.
We did not talk about another interesting announcement, AWS Inferentia.
Anyone catch that one?
I did not.
What is that mean either?
AWS Inferentia is their forthcoming high performance machine learning chip.
So this is a product of their acquisition of Annapurna Labs.
It is slated to come out next year.
It is inference, I believe, well, Inferentia is focused on inference, right?
And each of these chips will do hundreds of tensor operations per second.
And you can cluster these chips to scale that to the thousands.
And so there's kind of this interesting one, two punched between elastic inference, which
is, I think this is GA now, right?
And Inferentia, so elastic inference is going to promises to lower inference cost by up
to 75%.
GA when it comes online, they're saying offers further reduction of cost by 10X.
Wow.
Wow.
Wow.
So this actually corresponds to two related announcements this week.
One was obviously support for, I don't know, initially, or just more ARM instance types.
And the other one that was in an Amazon announcement, but just happened the same week, was the
risk five announcement by the Linux Foundation.
And some of the potential opportunities that offers people like Amazon to offer really
interesting customized chips, that's like this for almost any high volume application
with a 10X impact.
Interesting.
Interesting.
And so clearly, AWS is not alone in chasing down this custom inference chip, custom inference
hardware.
We talked about the Google TPU, Microsoft, is there's brain wave, or is that something different?
Yeah, I know they've had, was it, these are certainly custom FPGA with Azure, but maybe
even some custom A6, but am I the only one now that starts to feel like this is the
mainframe error all over again, with everyone running completely custom hardware and some
thin shame of compatibility, maybe at the container level between the clouds themselves.
Well, or the model compiler level, I'll say maker Neo, wait, are we saying that AWS is
becoming IBM that all of them are actually, except for maybe IBM ironically, you're
doing with power, but yeah, I was talking to someone and we were saying that AWS was becoming
more like an IBM in Microsoft of the 90s and that we were seeing, I think we said Microsoft
was behaving more like, like Apple, Apple was behaving, who's Apple behaving, Apple
was behaving more like,
Oracle, Dell, in the 90s, I lived through those errors of Microsoft could kill an industry
with a pre-announced press release and it does seem like Amazon, particularly AWS has
that power now in the tech industry to just announce or pre-announce something in freeze
like an entire new market segment.
I mean, if you look at outpost, I wouldn't be looking to buy hardware to build my new
VMware or a competitive cloud thing until I was able to see what they were going to offer
and what the cost structure and such looked like.
Yeah, at a macro level, you can probably start the countdown clock as to how many more
hardware refresh cycles there will be for people if, as you say, Dave, if the specs and
the price performance match up to expectations.
The machine learning offerings that we ran through are kind of under the broad category
of new stuff and then there's more like improvements and incremental stuff and tools and there
are a bunch of those as well.
So one of those was, they announced earlier in the week, a marketplace for machine learning.
So kind of like an ML app store to anyone that catches your eye, but I'd actually caught
my eye.
I noticed, of course, they weren't the first to do this, but just the fact that in combination,
with integrated workflow for a data scientist and all the other cool tools that are either
maturing, which I think the maturing of all these services announced in prior years might
be the unsung hero of these announcements because they're really usable now and very functional.
But the fact that now you have this kind of marketplace also available on AWS is with
partners as well as natively from the rest of Amazon is very, very cool.
If they do share some of the models they use in the proper Amazon retail side, then that
could also be a game changer with regards to e-commerce everywhere.
One of the things that I thought was interesting about this, if I'm not mixing it up with
another announcement is that it's all based on when I first heard it describe, I thought,
okay, well, how is this different from labeling an amy as machine learning, but this is all
based on containers?
Yeah, I forgot that detail, but it makes it a bit more granular for sure.
Yeah.
So it's interesting, it's based on containers, they've got some ability to, like the partner
amies, you can monetize them, and they've got folks like Figure 8 and Deep Vision, H2O,
H2O and some others that are kind of already part of this new ecosystem.
And yeah, how is this going to tie into the comments you made earlier in the podcast on transfer
learning and the ability to just buy a model, maybe tweak it or not and just apply it to
some other thing and be super productive much early on in a data science cycle?
I mean, I think that's where this heads, I think the interesting thing will be, to me,
can they evolve it where I can see what the specific specs of the performance of this
model are and compare similar models and look at the performance and accuracy that they
offer and decide which one is best for me, and at that point, there's not that much incentive
for me to go out and build my own model from scratch.
How about a recommendation and engine for we just described Dave?
Of course.
I'm like slowly wrapping my head around what this is, and I've talked to folks at AWS
about this yesterday.
I think the thing that caught me up is that the folks that they are rolling out as partners
like TIPCO and figure eight, I think of them as like application and tools and platform
vendors, and so I think that these are like entire systems that we could already put those
in AMIs and spin them up, and so what's the big deal?
But I guess the reason why this container thing is important, going back to what was
clear to you and is sinking in for me is that those are just companies that are publishing
into a model marketplace and repository that you can access from SageMaker as opposed
to like spinning up some new product or spinning up some whole product in an instance.
It's broke-growing algorithms.
So there are folks that play in this space, algorithmia is one, a company who I've got
a lot of respect for, they're doing really interesting things.
It'd be interesting to see, you know, how this plays out for them.
So the next set of announcements are, I think, all around these, like the highest tier
and the ML stack, these cognitive APIs or these AI as a service APIs, and there are a couple
of these that I found really interesting.
So there's one that's called Personalize, and the idea is that it is a recommendation
system kind of as a service, recommendations as a service, and then there's one that's
called Forecasts, and that is Forecasting as a service.
And, you know, their pitch for this is that recommendations and forecasts are both, forecasting
are both these examples of things that are really hard to do generically.
Like your product catalog and data sources, you know, whether it's click stream or logs
or whatever, that's very customized to you.
And likewise, things that you need to forecast are very customized to you.
And so it's very difficult to offer just a generic personalization API or forecasting
API, but, and this is what's really interesting.
And they didn't explain it like this, but it was kind of a light bulb as soon as they
set it for me.
What they've really done with these is like, it's an application level version of AutoML.
Like so what Google did with AutoML is like, it's a machine learning thing, right?
You give it a bunch of images, and, you know, they're going to do architecture
search and optimization to give you to give you a better, you know, image labeling API.
But this is, that's same idea.
You're giving it your data, and it's going to do architecture search and data cleansing
and like a whole set of steps that is doing is basically doing AutoML for you, but at
at a much higher level, at an application or really a business level, which is really cool.
I agree.
I would love to try this, you know, with very common businesses that have to forecast,
you know, how much supply they're going to buy.
Forecasts were kind of staffed to get a need to manufacture or assemble something.
Forecasts were kind of shipping.
They're going to have to reserve ahead of time forecast how long it's going to take
for customers to pay them, and you know, is that going to be quicker than when the payments
have to make their suppliers.
This can impact literally almost every aspect of a business, and it's going to be exciting
to see what people do with it next year and year after that.
Mm-hmm.
So I pulled up my list of the things that they're doing.
So they're loading your data, they're inspecting your data, they're identifying features,
they're selecting algorithms, they're selecting hyperparameters, they're training and optimizing
models, they're building a feature store, they're deploying and hosting these models or
so serving them up for you, and they're caching, they're creating real-time caches.
So they're doing all of this stuff, you know, specific to your data, that is pretty cool.
Yeah.
So a couple of other services that they announced, Comprehend Medical, so Comprehend
is their, like, text extraction service, and Comprehend Medical is a vertical medical,
obviously, oriented version of that.
And then another one that I think is kind of the, maybe like the low-key, super high
utility, you know, not sexy, announcement of this whole, you know, of all of these is
a new one called Textract.
And it's basically a souped up OCR system that you give it a PDF, or they say almost
any document, and it'll extract the text and data from that document, but it does it
in a way that's like, if there are tables in that document, it will extract those tables.
If there are, you know, you know, kind of lists, you know, it'll extract key value pairs.
It, I heard someone say this, it wasn't in any of the slides I saw, but like it, it sounds
like it will retain some of the structure of the documents, it'll deliver bounding
boxes for where, you know, document features are like tables and stuff like that.
And you don't need to know any machine learning to do any of that stuff.
I can see, I can envision, you know, whole businesses kind of just built on kind of commercializing
this service.
Yeah, like I remember still having PTSD from doing expenses at an app with like an antiquated
1990s Oracle, like expense system, and so this could revolutionize that, right?
If you have expenseify or concur, integrate this, hopefully very quickly, it could just
increase productivity and employing morale so much just for expense reporting alone.
I was curious how that would work.
You would upload receipt images and have it generate the expense report.
Exactly, zero touch almost.
The use case that they gave for this was tax forms.
Like, you know, there's one canonical W-9 form, but there are, you know, hundreds of
different kind of versions of W-9 forms.
Like as long as you capture the information and the lines, you could come up with your own
custom version of that form and apparently everyone has.
And so automating, pulling, extracting the data from those forms into a form that you
can then dump into a database is difficult because you have all these variants of these
forms.
You know, if you think of like invoices, you know, it's structured or semi-structured if
you prefer data, right?
It's not a picture, it's not a bunch of texts, but OCR just treats it, you know, it starts
with a picture and gets out a bunch of texts, but it loses all of the semantic meaning in
these forms.
And so what text extract is meant to do is to preserve all of that using, of course, machine
learning, which is pretty cool.
I see text, but the bigger one that I see would be medical.
Yeah.
Talk about that.
That's huge.
Think about all of the medical forms, things that you would submit to insurance.
All of that, if you were a hospital or medical, medical group and you deal with submitting
to different insurance companies, I see lots and lots of applicability for that.
Let alone the myriad of different, as you pointed out, text forms and such.
I would see that as big.
The other thing that would be big would be legal in maintaining the forms because a lot
of different legal documents that you file with courts and such also follow a standardized
format for that court or maybe even for that state, depending, but at least for, say,
that specific county, but it will change for others, but they, but all of those documents
for that specific court will follow the same format, at least for long periods of time,
say, decades.
So being able to maintain that would also be huge, but those are just a few examples
that come to mind that are very, very large have broad applicability.
Mm-hmm.
Yeah, the semantic processing of images is one thing.
I'm wondering how they'll be able to extend this to other localized languages, so to speak,
because I just came back from some trips to China and that massive Belt and Road Initiative
they have, touches so many countries and so many cultures and languages and written
characters and scripts that as this mature, this could be another game changer for how
you process that kind of very heterogeneous supply chain.
Yeah, so it's, you're coming about medical.
Does raise an interesting question about the relationship between the new comprehend
medical offering and textract and do they already, you know, talk to one another, does
textract use comprehend medical for that very domain specific thing or can you do that
or is that something that's coming in the future?
Interesting stuff there.
So I think we made it through the ML related stuff amazingly in an hour, but there's
a bunch more stuff does anyone have or do you guys have like your favorite thing that
we haven't talked about yet?
We covered a lot.
I think there's a whole bunch of as we talked earlier, maturing security offerings just
for better overall governance and supervision of the various policies you have and the monitoring
tools and the probably endless dashboards now that are available to you in terms of
monitoring activity, so the whole notion of just a maturity overall of security and compliance
tools and tool sets for AWS customers is one of those unsung heroic set of announcements
this year for me as well.
How about you, Dave?
I don't know.
I think for me, the, I think the biggest thing is the absolute number of deeply innovative
announcements with lots of meat behind them, lots and lots of things in the ML and the
infrastructure space, both and it makes me wonder if it's not time for them to change
the conference.
I think that we're at the point where there are too many announcements.
The topics are too broad, they cover too much and the conference itself, it's not possible
to go if you have an interest that spreads even a couple of these for you to successfully
go and attend the workshops and sessions and so when a conference reaches that, it's
usually time for the conference to split out into more separate conferences that cover
each of those kind of domains and I think reinvent is at that point.
That's my opinion.
As an attendee, I would say I agree with Dave, right, I'm not sure if you're a presenter
or you know, exhibitor or actually the one that hosts the conference that the economies
of scale would be attractive but as an attendee, I couldn't agree more with Dave and I think
moreover, we noticed earlier on that there's more and more pre-announcements happening
because you can only squeeze in one keynote a year for major announcements and spreading
the conferences out, both location wise, venue wise chronologically would let them announce
I think more timely availability of these cool new services that they keep announcing.
I also have a meta comment but I'm going to hold that for one second because I do have
one more product announcement that I'm really excited about and it's kind of like adjacent
to machine learning stuff.
Did you catch the Lake Formation announcement?
Yes.
Lake Formation is pretty cool.
So I guess the meta to Lake Formation is that AWS this year, I think for the first time,
has been super aggressive about positioning S3 as a data lake.
I have not heard them talk about it like that before.
And so Lake Formation is this new offering that basically automates the data pipeline for
getting data into S3.
So talking about like crawling your on-premises data stores and cataloging and cleansing data,
getting it into S3, organizing it, deduplication and it can crawl relational databases as well
as semi-structured and unstructured data sources.
When I think about and talk to folks about the path to kind of repeatable enterprise machine
learning, like the stumbling block for a lot of people, like kind of stuck in the blocks
is having a centralized data repository, whether you call it a data warehouse or it is a data
warehouse or a data lake or a fabric or whatever, I guess a big deal and it's cool to see them
taking that on.
Yeah, in fact, not only that, but I think they buried the lead a little bit with Lake Formation
and that this can revolutionize things like GDPR and other kinds of privacy compliance
efforts where the discovery part of this alone, particularly as more and more data is either
managed in conjunction with our post at both on-prem and off-prem, the discovery part and then
the cataloging part is that mature as you can automatically categorize data and create
automated master data models and then you can do all sorts of interesting recommendation
engines based on that.
When you tie some of those workflows together that is a really revolutionary in this world
of compliance and spending a lot of time in.
Awesome.
Yeah.
I agree.
I think a lot of people have been using S3 is kind of their mini data lake, so to speak.
They'll dump as much as they can in, but they're still kind of limited in their options with
what they can do and how it works, although they keep expanding S3's functionality constantly.
I still think this taking on the data lake, especially for the impact it has with analysis
and machine learning is a big deal.
It really is.
That's true.
My meta comment that I was saving was one of the things that they've taken some steps
towards addressing with their, oh, they also announced like a whole ML training and certification
curriculum, by the way, or that, oh, that, right, exactly, and they'd previously announced
like ML partner competencies, but one of the things that struck me in going into the Expo,
which is massive, like several hundred exhibiting companies in the Expo, very few of them, even
at this stage, our ML and AI related, like a lot of them have, or do other things that
are kind of, have their ML and AI story as vendors do, tech vendors do, but in terms of
kind of pure play, ML and AI partners, you know, whether services or product ISVs, software
as a service, the pickings were relatively slim.
And it kind of brought to mind a question that I started kind of asking myself last year,
which is like, does AWS have an ecosystem problem around machine learning?
Like, is it not, you know, open enough or inclusive enough or, you know, something that they're
not able to kind of catalyze partners to get on board or make it worth their while?
Or is it just too early?
It's something I noticed actually about the machine learning, you know, industry and
markets, I went as a whole, is by and large, very few of those companies, if any, grow
up to be big, independent successes, and, you know, consequently, there's just a lot of
acryhiring going on.
So I don't know if these companies reach a stage where they can actually get enough capital
to have a branding style of marketing campaign that capital and tons of companies, like
the storage companies, my confirmation bias goes to, I noticed, I noticed so many giant,
you know, storage, you know, logos and branding on the miracle mile screen, you know, across
from the area in the Cosmo, and I just saw a lot of marketing and branding dollars going,
you know, from infrastructure companies.
But to your point, not so much more, a lot of the smaller innovative companies and spaces
like ML.
Hmm.
Interesting.
Take for sure.
I think that just speaks more to my point about splitting the conference into smaller conferences.
Right.
Right.
If you're a ML or AI pure play company, like the, the hit rate here, the signal to noise
ratios got to be pretty low still.
Yeah.
Unfortunately.
Uh, I could get with that, Dave, uh, just, let's start a movement right now.
Don't make it any later in the year.
Oh, yeah.
Agreed.
Um, you know, I think we should, uh, I think we should reach out to Berner and, uh, and
and, and Jesse and tell them that they're awesome.
Well, guys, I've got to pack up and bolt to the airport, uh, but it was awesome or recapping.
Uh, reinvent with you guys.
Thanks so much for, uh, hopping on with me at a great time.
Thanks for including me this year.
And yeah, to Dave's point, maybe we'll have, you know, more mini recaps going forward
when they split up these conferences.
Nice.
Nice.
Awesome.
Take care, guys.
Bye.
Bye.
Bye.
Bye.
All right, everyone.
That's our show for today for more information on Dave, Val, or any of the topics
covered in this episode, visit twimmaleye.com slash talk slash 205.
If you're a fan of the show and you haven't already done so, or if you're a new listener
and you like what you hear, visit your Apple or Google podcast app and leave us a five-star
rating and review.
You reviews help inspire us to create more and better content and they help new listeners
find the show.
As always, thanks so much for listening and catch you next time.
