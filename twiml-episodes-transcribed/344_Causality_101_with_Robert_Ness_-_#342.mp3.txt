Welcome to the Tumel AI Podcast. I'm your host, Sam Charrington.
Hey everyone, I am on the line with Robert Osezua Ness.
Robert is a machine learning research engineer at Gamalon and an instructor at Northeastern
University. Robert and I met at the last NURPS conference where he had an accepted poster session
around his paper integrating Markov processes with structural causal modeling enables counterfactual
inference in complex systems, which he also presented at the Black and AI workshop.
This kicked off a bunch of great conversations between the two of us leading ultimately
to collaboration that we'll talk a little bit about in this conversation. Robert, thanks so much
for joining me on the Tumel AI Podcast. Thanks for having me, Sam. Your introduction makes me think
I should have came up with more clever name for that paper. You know what, a lot of the papers
we talk about on this show are quite the mouthful, so yours is no exception. Maybe someone will
build a model that seeks to determine a inverse correlation or correlation between the lengthiness
of a paper's title and its number of citations or something like that, but let's set that aside
for now. Have you spent a few minutes introducing yourself? How did you get started in machine learning,
what picture interests? You know, ultimately we'll be spending a lot of time here talking about
causality. How did you come to become interested in that? You know, my path to machine learning was
a bit, I'd say unconventional. I started off working in Asia and China, specifically I
was at the degree at Hopkins and international studies and was planning to pursue a degree in
economic, in economics, focusing on economic development. I got involved with some internet
companies out in Beijing and that's kind of, that got me into coding and databases and data in general
and I decided I was interested in that and went to, so I applied to four programs in statistics,
particularly with a focus on computational statistics. I went back to the States, came back to the
States, went to Purdue University to do my PhD in stats. My PhD work was on causal inference,
graphical models, basically how to learn causal models from data, particularly in the context
of systems biology and from then after I graduated I went straight into industry. Got it. Now,
we hear very frequently folks refer to their path into machine learning as unconventional or
indirect. In your case, you came into an interesting gaming and that led you to apply for or go into
grad school for statistic. What was that particular connection? Really, it's when you're on the
back end of an app and you're looking at the data and you're realizing that there's a lot of insights
to be had of only we could model this data and turn it into some service on the front end.
I realized, people were just starting to talk about data science and how Varian had just recently
came out and said that statistics is the new sexiest. I can't remember what the exact
quote was. Pick your metaphor. Yeah, pick your metaphor. Orange, New Black, statistics is the new,
rock star. That's why I pivoted to stats in
machine learning. I guess through stats, people might argue whether or not stats in machine learning
are the same thing. The problems that I was working on at PhD were using probabilistic graphical
models, which has strong roots in artificial intelligence. That was my introduction to machine
learning. One of the things that's come up in our conversations about causality and the work
that you're doing with your courses is the idea that historically talking about causality has
been the domain of statisticians and folks like economists and that a lot of that conversation
is inaccessible or isn't really tailored to the needs of developers and data scientist machine
learning engineers. I didn't realize all the time we were talking about that that your background
was an economics. You have some of the exposure to the way that causality has been traditionally
kind of used and talked about. Maybe I guess I'll just use this as a segue to
kind of opening up the floor to ask you, how do you define causality?
The interesting thing about causality and maybe part of why maybe it is a challenging thing to
deal with particularly for statisticians I would say is that it's very difficult to talk about
it without finding yourself having a philosophical conversation. This is something that
you know what is the causality. These are something that philosophers have been wrestling with
through the ages, right? Hume has a counterfactual definition of causality that's
you know A follows from B and had A not happen B would not have happened
but you know philosophers going back to the Buddha all kind of take their stab at what is causality
and so there's a there's different philosophical arguments for causality and what it means.
I think from a practical standpoint what most people mean when they say cause or inference is
they mean the estimation of causal effects. So if you're say for example at a tech company and
you want to run some kind of experiment about whether a feature will drive a click or some other
key performance indicator or metric you're asking your experiment is essentially trying to get
at the question of what is the causal effect of this feature on this outcome and you'll be using
assumptions and methods from statistics to estimate assuming your assumptions are valid those causal
effects but when we're talking in machine learning we're now hearing you know so I had
near ups like you said you know Joshua Benjillo gave this talk about having agents that can
understand the causal structure of the world and that causality is essential from moving from
system one to system two cognition as you day a pearl was a very preeminent causal inference
researcher talks about causal reasoning in in terms of free will and you know the ability to
understand intention and and so there are definitely definitely a lot of angles to tackle this
question from the perspective of artificial intelligence that you know people who are running
experiments in in Facebook and Netflix are not really thinking about yeah it's interesting that
you you kind of you know where you started your response and ended your response when I talk
to people about causality and and agreed you know at nirips and even before you know causality
over the past year has really been one of those topics I think maybe peeking at nirips it was
definitely a hot topic at nirps I don't think I think it's too early to say that it was peeking
and I don't think that that's the case but it was definitely a hot topic at nirps but even before
there was kind of this growing crescendo of interest and enthusiasm around this idea of causality
when I talk to folks about it the conversations tend to be you know either the the philosophical
conversations kind of very abstract conversations that you mentioned that you started your
explanation with or you know talking about it like it's you know another algorithm or
tool or approach on the on the shelf and that hey you know we've been doing machine learning and
now we you know you know we realize we just need to pick up this you know this causality tool
and kind of sprinkle it on what we've been doing all along and you know we've got a better
approach to doing things do you get that sense as well in the industry and what do you think
driving that yeah and I I sense a lot of cultural clash in terms of trying to articulate the problems
in one field and what the ideal solutions are coming from one camp and you know what people are
already doing who are working on causal inference and what they think the smart ways of what the
next steps are in that line of research I think you know from the algorithmic standpoint clearly
yeah that's where we want to go we want to be able to algorithmatize causal reasoning right now
um and there are ways of doing that and they're connected of course so for example if we're talking
about like what I said the traditional question of of causal inference is you know can we estimate
a causal effect if the causal effect is again the effect of something that you care about like some
kind of utility you're not really that far away from say a mark-off decision process or
reinforcement learning especially for example you're you know the the thing that's your the
experiment that you're running your running in sequence so so that's you know you you run the
experiment you get some kind of results you you update some kind of belief structure about your
motto and then run a new experiment that's getting very very close to the language of reinforcement
learning but if you're in if you're working in reinforcement learning and you try and dive into
that literature you're going to see a bunch of papers on public health uh experimental designs and
you know and and really kind of very domain specific assumptions built up around linear models
none of the stuff that you're working on if you're a typical reinforcement learning or researcher
another issue would be for example if you are working on trying to if you're working on deep learning
for example and you're thinking okay well how can I just apply deep learning to causal inference
well one of the chief problems in causal inference is the question of whether or not something's
identifiable right so this is to say that I want to I have some I have a model and I have a causal
question that I want to ask my model and I have some data now given my data is this question even
is it even possible for me to answer it and the answer might be no this is something that I found
that people with a background in machine learning particularly a deep background and deep learning
have trouble thinking about because they're they tend to think that if I get the right architecture
and I get enough data and I label the the data in the correct way and I get the right loss function
then I can solve this and so that that's a huge clash right there right that's a it's a fundamental
clash and so um you know getting a lot getting over some of those I consider them cultural barriers
is um is I think what we need to be striving for as a community the example that you brought up
of you know you're an engineer working at uh you know uh add tech startup or you know any kind of
web startup uh and you want to estimate the probability that the change that you're making
you know has a result that you're predicting you kind of use that broadly as an example of where
you might apply causality uh but we've been trying to estimate these kinds of things for a long time
what's different about the causal approach to this well at a if you had to define what a fun
what a causal model can do that's a non causal model can't do at a most basic level is that it
can predict the effect of an intervention and so what an intervention is is some kind of action
that's that you take or a modeler takes or people who are making decisions based on a model
on a model are taking that affects the data generating process um and so if you are affecting
the data generating process then and you're and you're you're changing it well that means that's
the data that you're now getting from that new process is different from the data that you
change your model on now if you have a causal model your causal model can account for that change
and its predictions will still be valid but as we know with even some of the more powerful models
in machine learning if we if they're just pure predictive models they don't have a causal structure
to them then the second you change the uh the data generating process such that a difference
from the training data you're going to have it you're going to have issues and it's not going to be
very robust to new data that your model hasn't seen before and so that's that's kind of when I
when I try and pitch people on like why should I care about causal inference that's really the
the main thing is that so in the example I think that you're referring to like it's a simple example
but I say suppose that you were you know you had some kind of sensors that were collecting
data about the climate the weather in the local the micro climate where you live in the morning
and using that and then in the evening you you you record whether or not it rained okay and so
after a while you collect you collect enough data and then you create a predictive model that
predicts whether or not it will rain and then based on this model you make a decision based on
this prediction you make a decision and that decision is whether or not to carry an umbrella with
you in the morning now that's fine because what happens there is carrying the umbrella is going to
have no effects on the weather but we can look at a comparative example say for example in business
where you look at some business indicators and then you you and then at the end of whatever
period it is a quarter you know a cycle you record you know the revenue for your company
and then you do that for a while and then you train a model that predicts future revenue given
these business indicators and then if your future revenue looks like it's going to be low
you run some advertising well that advertising is going to now start generating data that is
affected by that advertising and so when you retrain your model and that new data you're getting
this kind of feedback loop that where your actions are affecting the data generating process and
and feeding back into the data this this is an issue for example in fraud detection so that's
I don't know what happens once you start you're able to detect fraud then you start rejecting
the fraudulent transactions and now all the only fraudulent transactions that make it into your
future trading data are these edge cases of fraudulent transactions and so when you retrain
your model it's now has this strange bias towards those edge cases and so that can confuse things
and so at at a very basic the very basic use case for causal modeling and in machine learning is
to be able to predict the outcomes of interventions and so and once we can bridge interventions we
can do a lot of clever things on top of that so we can for example we can have models or we can
have modules of our models that are more robust and can transfer across domains so that we don't
have to retrain them once we get to a new data set or a new domain and considering the cost of
training a model these days that can be that can lead to some significant cost savings
again we can we can estimate causal effects which is very relevant and feels like reinforcement
learning as I said and you know and then there's the there's the question of counterfactual reasoning
so just to recap that before we move on what you're saying is that the traditional machine learning
models that are kind of sitting on the shelves for us to use you know tend to make this assumption
this iid assumption that the you know the data that it's trained on are all independently and
identically distributed right and in many use cases the decisions that we're making based on the
models that we're using actually changes the distribution and the independence of the data
in future time steps and sounds like we just live with that application but it causes problems for
us and one of the reasons why people are starting to get excited about causality is because it holds
some promise for fixing this and thus you know making our application of machine learning more kind
of applicable in the real world that we live in yeah you know so speaking of real world applications
people would be interested I think you've had speakers like Tim Nidon who were talking about
algorithmic fairness and you know so causal inference would have a lot to say about that for
example right so like is is a policy's effect on some kind of outcome like say an adverse outcome
for a specific group of people is it a direct cause of that policy is it's kind of being mediated
through indirect causes or is it just correlated to that to that initial cause because of some kind
of confounding factors in the outside environment that generated the data though you know so
that is one reason why when we're worried about like you know algorithmic fairness and ethical
way I clearly you know causal inference has a lot to say about that the example that I just gave
of course and just making sure that our models if we're making decisions that affect the training
data that goes into our models and making sure that's is somehow accounted for and you know those
are those are some very basic applications of it although I think that when when machine learning
people at machine learning conferences get excited about causality I don't think it's so much
because of estimating causal effects or ethical AI or or explainable AI I think it really has to
do with things like modeling like disentangle representations and and and variational autoencoders
for example like if for these if we're trying to parse apart these latent variables that are
that have some kind of meaning and transfer across datasets can we bring can we bring some causal
reasoning to bear on that problem I think people are interested in people in a probabilistic
programming community like myself are very interested in the ability to build causal models
as programs and use those to reason counterfactually that that's the kind of cure that's the kind of
bread and butter AI application of of causal inference although these other these other domains
that I mentioned are clearly very relevant you mentioned disentangle representation and
variational autoencoders when I think of that the kind of analogy that comes to mind for me
is like embeddings and you know a transformation from you know the feature domain to some
embedding space and typically that's a kind of opaque representation is the idea that with
causality that embedding space or representation space is more meaningful causal understandable
explainable or is it something different than that yeah so generally the idea is that
this embedding space is somehow capturing latent causes and so there's some very there's
very important question about hey okay statistically is it even possible to identify latent causes
even in a multi-variant setting which some people think is possible like but there's a lot of
you know you can show mathematically that you you get a lot of problems if you try doing that
so people are worrying are thinking about that and they're thinking about you know there are when
you have a a a a a a probability distribution say of a of a effect given a cause a conditional
probability distribution of an effect given a cause is driven by some natural causal mechanism
that drives that effect from the cause right and we assume that that's causal mechanism since
it's a part of nature is going to be invariant across datasets right so if we can look at that
type of intuition and you know what it means for these mechanisms or what what the nature of these
mechanisms and how they might for example be independent of one another what that might say about
the distributions that they entail you know can we now build those as assumptions inside of
of a say a deep model like this right build it into the for safer example the the the loss function
or the structure of the model and come up with latent representations that we can have
stronger believe that these are actually good representations of causes you know and talking
about causality we've talked about some of the you know the kind of philosophical origins of just
defining what causality means and it's popularity within the research community how ready are the
tools around causality that they can be practically used by you know folks in industry are we there
yet or is there are we not quite there yet there are some excellent packages both in R and in Python
that will do useful things when it comes to causal effect estimation so you know it's I there's
a fellow Microsoft research name Amit Sharma who has a library called DUI which is I think when
it comes to just that problem of estimating causal effects I think is has the has one of the best
inner faces that I've seen for that problem it's very intuitive because you lots of options and
it separates and it separates the problem of identification and estimation very well I am somebody
who comes from the deep probabilistic programming community I like to think about a data generated
generating function as a causal process and I like to think about how I can model that in
in a program and and use tools like tensor flow or pi torch to capture the complexities and
nonlinearities in that system so so for example with the workshops and the courses that I teach I
use pyro which is a deep generative modeling framework from Uber AI labs that extends
pi torch now that said you know some of the challenges there and there's some challenges there
when it comes to inference on these models it can be I think that's an act of area of research and so
if you're not you know you kind of have to turn away at the inference problem when you're working
on these models but it's certainly doable well maybe refine or restate the question
to you know where are people successfully using this kind of body of knowledge around
causality in machine learning not in stats or economics but in machine learning you've mentioned
some examples of representative problems but are these problems that are you know solvable
today that people are you know using causal approaches in or are these things that we would like
to apply causality to once the tools are mature you know the best applications within the AI
space that I've seen and I very much hope if your listeners take issue of what I'm about to say
that they they email me and prove me wrong but you know most of the the cutting edge up is
happening within a research community within industry there are I would say that's I've seen
people in industry working on say an analysis by synthesis approaches which is where say you
have some kind of latent grammar of you know abstractions within a domain that you use to
generate say images or synthetic environments for say for example training self-driving cars for
example and when they design these grammars they add a kind of causal semantics to them I've
seen some early success with those types of approaches the biggest application in industry that
I've seen be successful that's kind of not surprising is when it comes to say actual machine learning
models in production would be people who are applying causal inference techniques and experiment
and experimentation to the optimizing of hyper parameters for machine learning model so it's
just running experiments on models to make them to tune their parameters. So I hinted at this
earlier you've got a course that you are teaching at Northeastern University as well as through
your own upstart education company all deep AI and I'll have you talk a little bit about that
and we're launching a collaboration around bringing a study group that you'll be leading
for this course to the twimmel community and anyone who's listening to this who's interested
in learning more can join us for an overview session that we'll be doing on February 1st but
so let's have you share a little bit about your thinking around this course how it's different
from other educational resources around causality and in particular who it's who it's for
given kind of where you think the you know the market is and where causality is from a utility
perspective. Okay yeah so it's it's all deep school of AI all deep AI and it helps people
break into new opportunities surrounding cutting edge AI and so it assumes that you already have
a background in data science and machine learning and that you can code although not a preliminary
background is fine you know I started it because as a as a research engineer working in the field
I was seeing that you'd have to have a case where somebody would identify some kind of pivot
they would they want to make like say for example I'm a data scientist and I want to transition to
an engineering role where I'm working on machine learning algorithms or that I'm a software
engineer and I want to take a lead on building our company's new experimentation platform
or even kind of off the wall things like I want to implement and deploy an agent step plays
online poker right and so to get these types of goals to really achieve them you need to combine
learning about new research in an area in AI with actually finding tools and libraries and
tutorials that help you do the implementation and you know so the process of going through a bunch
of research papers and medium blog posts and jubber notebooks it's slow it's arduous it's there's
a lot of hype and noise that you have to turn through in order to get a little bit of signal
so all deep solving this by bundling the science and the implementation and presenting in a way
that delivers a transformation that people are looking for by the end of the workshop
so the first sequence of courses are having to do with you know causal modeling and machine
learning and so if you've been to you know like you're like you were saying before you know we've
gone to these conferences we know that's the gets to common sense reasoning in AI we need to look
at causal inference but it like I said if you look at the causal inference literature you're
going to find weird toy problems you know language that's focused on econometrics and public health
you know a lot of talk about problem specific variations of linear models and stats that's
are probably a lot different from the kinds of problems that you're working on it's very hard
to penetrate so the course does what the course does is explain or the courses rather they explain
at a high level in the language and in the context of machine learning what these well what what
causal inference is about what causal modeling is about what counterfactual inference is all about
and how to algorithmize it and if you're like say for example you're familiar with things like
topic models other latent variable models Bayesian non-parametric models
and you're in you're comfortable working in a deep probabilistic program main language like
pyro it's I think it's a great choice are those things prerequisites because I imagine there are
a lot of folks out there that are interested in causality want to be able to engage in conversations
about it or understand the conversations that are happening about it but don't know anything about
probabilistic programming or any of the other things that you mentioned I would say that
don't are not prerequisites if you have a background there you're going to be able to take off
right away putting probabilistic programming aside it's it's more focused on the idea of model-based
machine learning which is that which is saying that to tackle machine learning problem you should
be thinking very very precisely about your data generating process and then write a create a
bespoke model tailored to that process and you know and since I would argue that for a human being
it's impossible to think of a process that generated the data without you thinking about it in causal
terms it really just that way of thinking models sorry maps directly to the causal modeling and so
probabilistic programming is just a really way really easy way of going about that if you don't
have experienced probabilistic programming so none of the examples are the types of you know large
deep models that take all data train and are very difficult to debug they're all very easy to
sink your teeth you to while at the same time and they're all very kind of contextualized within
the kinds of machine learning problems that's somebody with a machine learning background what
I've used to but at the same time there it's clear how they can be generalized to
more deeper and more nuanced more complex models you made a point in there about the
causality I believe or I don't recall if you were precisely referring to causality or
probability probabilistic programming but the idea that in thinking about a model you're thinking
about the the way that the data is generated can you elaborate on that point a little bit?
Yeah so it's it's a philosophy that is commonly articulated as model-based machine learning
and so yeah the typical machine learning playbook is that you you get the data sets you look at
the structure the features you look at the structure of the race of the target response variable
you start transforming things to fit whatever modeling framework you are familiar with or whatever
happens to be fashionable at the time maybe you go on to you go and pick the most fashionable model
and you kind of switch out the eminist data for whatever your data is and just assume it's going
to work and then you kind of iterate on it you tweak things until you can ramp up predictive
accuracy this the model-based machine learning approach is is it's saying that it's taking a
different philosophy for building a model you're saying that rather than being a hammer and search
of a nail you should say all right let me let me think about the process that generated this data
let me build a bespoke model with respect to this data and and and and try and then let me try
to you know evaluate and critique this model in terms of how well how faithful I think it is to
the original data generating process of course you can still have a loss function that optimizes
for prediction now this relates to causality because if you're thinking about a process that generated
data typically the way you think about it is as a causal process so first this happened and that
that happened and then maybe some noise was added and then it was translated all of these things are
you're thinking about a kind of causal narrative for a kind of causal origin story for your data
and so so in this course we build on that model-based machine learning intuition that that
generated modeling intuition what is it that excites you about causality is it the you know the use cases is it about the
kind of the elegance of the proofs like what is it that really gets you going about this topic
you know I think for me the cool thing is to be able to write really the right programs
to write explicitly in terms of like a program what you think the actual processes that generated
the data and and we have a lot of cool background research from all kinds of different domains
that do that so we have say for example simulations in like climateology or multi-agent systems we
have you know differential equations you know stochastic differential equations we have stochastic
processes that we use to kind of describe how something came to be right and so it turns out
that we can actually implement these as causal models and then reason about them counterfactually
so what a counterfactual means is that you know I you know specifically a kind of counterfactual
we call it twin world counterfactual we are thinking about parallel universes you're saying that like
I did this thing and here's where I am so I ate this hamburger and now I have a stomach ache
had I not eaten this hamburger I would not I would not have a stomach ache and that's something
that's been very challenging for machine learning because that's that's example where
that data point where you did not eat this the the hamburger and didn't get the stomach ache
that doesn't exist in a training data right so you need some kind of way of simulating the
alternate reality for doing that and so you know for me personally just kind of
writing algorithms that that that that does that that's super fun so like I you know I was I was
saying that you know it's very normal for a human being to say like oh man like had I not
data that's woman in college I'd be a much happier man today that that kind of reasoning is
really easy for us I think about how cool it is that you can actually write an algorithm that
can reason the same way right now now I'll be honest with you I don't I've seen some some
I've seen a few actual practical examples of this like in terms of
within machine learning I've seen something things like a reasoning about occlusion in an image
you know some of the things that we see like with deep fakes for example you can you can
actually consider that a kind of counterfactual problem like what would this video look like if
it were Obama talking instead of somebody else you know those are those are fun examples I don't
know if they if they're really kind of the killer app I think we're still looking for that the
honestly it's really fun to play with I was just getting that I think the you know what I'm
hearing you say is that you know with regards to the field in general your course you're not necessarily
promoting this as something that someone is going to go home and apply in their you know day job
but rather it's going to position them to start to reason about the application of machine learning
in some different ways that are starting to get I would say that to be clear the stuff
that you need to get a job on the causal inference team at Netflix or Facebook is definitely in
there that's definitely covered deeply in this course and you need to understand that stuff
before you can move into some of the more cooler AI applications it's just for me is the the
those cooler AI applications are kind of what drives my motivation but you know I I definitely
I definitely have respect for all the people who are interested in running good experiments
yeah yeah there's still a little bit of like a disconnect between you know if you if there is
a causal inference job to be had at Netflix or Facebook there is some practical application or
else those teams wouldn't exist right yeah yeah and those and and those teams are like I said those
are typically experimentation teams kind of working on you know serving ads and trying to price
correct ads correctly for an auction trying to figure out what's trailer to show you when you
log into Netflix that's not it is and and and it gets kind of closer to AI when they're thinking
about what they call time varying treatments what you might what a machine learning person might
call a Markov decision process just trying to think of if I do these things in in sequence and
have been kind of run automatically how do I do that yeah but I think there's cooler stuff
than that so for those that are are listening to this and aren't aware of what it means when I say
a study group one of the things we do as part of our broader twimmel meetup and community is go
through online courses together we've done that for a ton of the fast AI courses as well as
courses like the Stanford CS to 24 and LP course the Andrew wings deep learning that AI course
and we're excited to kick off a collaboration with Robert around his causal modeling and machine
learning sequence and this is particularly special because this is the first time we have an
instructor of a course leading the study group with us for more information about the study group
you can visit twimmelai.com slash community and join the community join the slack channel for the
course and we'll post information there about the information session that again we'll hold on
Saturday February 1st at 8 a.m. Robert any parting thoughts or words on we didn't get to your
paper I thought we'll have to we'll have to talk about that at some other time but I think you
know this you know this is certainly not the the first conversation that we'll need to have
on the show about causality because again it is coming up over and over and over again
and the few people that I've mentioned as I've started talking about the this collaboration
you know I've gotten a lot of enthusiasm because it's one of these things that a lot of people
are talking about but you know very few people really understand what it is and how to apply it
so I'm definitely looking forward to getting us kicked off as are you know many other people that
I've talked to again sorry any parting thoughts from your end yeah and I'd say to all of the
research engineers all the research scientists data scientists out there who are maybe feeling a
bit stuck on the on trying to say pursue you know certain career goals and and and and hearing about
all of the hype and the trends that if you really go deep on the problems that you think are cool
you really can't go wrong I I love this cosmoling stuff I love how it relates to symbolic AI I
love how I replete I love the idea of creating an algorithm that can mimic how I regret dating the
woman I did I dated in college I love all that stuff I love I love all that stuff about this field
and you know even before it was sexy so I think I'm you know if you're interested in if you're
interested in talking about it more I'd love to I'd love for you to reach out to me awesome well
Robert thanks so much for taking the time to chat with us and by all means reach out to Robert
R.I. about the course or Robert about his work and hopefully we'll catch you in the study group
thanks Robert thanks Sam all right everyone that's our show for today for more information on
today's show visit twomolai.com slash shows as always thanks so much for listening and catch you
next time
