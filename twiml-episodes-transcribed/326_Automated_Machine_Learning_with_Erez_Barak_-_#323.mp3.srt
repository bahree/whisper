1
00:00:00,000 --> 00:00:13,400
Welcome to the Twimal AI Podcast.

2
00:00:13,400 --> 00:00:15,600
I'm your host, Sam Charrington.

3
00:00:15,600 --> 00:00:23,200
Hey, what's up everyone?

4
00:00:23,200 --> 00:00:24,200
This is Sam.

5
00:00:24,200 --> 00:00:29,040
A quick reminder that we've got a bunch of newly formed or forming study groups, including

6
00:00:29,040 --> 00:00:34,800
groups focused on Kaggle competitions and the fast.aiNLP and deep learning for coders

7
00:00:34,800 --> 00:00:36,760
part one courses.

8
00:00:36,760 --> 00:00:42,960
It's not too late to join us, which you can do by visiting twimalai.com slash community.

9
00:00:42,960 --> 00:00:47,960
Also, this week I'm at ReInvent and next week I'll be at NURRIPS.

10
00:00:47,960 --> 00:00:50,360
If you're at either event, please reach out.

11
00:00:50,360 --> 00:00:52,360
I'd love to connect.

12
00:00:52,360 --> 00:00:57,860
Alright, this week on the podcast, I'm excited to share a series of shows recorded in

13
00:00:57,860 --> 00:01:01,580
Orlando during the Microsoft Ignite conference.

14
00:01:01,580 --> 00:01:05,820
Before we jump in, I'd like to thank Microsoft for their support of the show and their sponsorship

15
00:01:05,820 --> 00:01:07,140
of this series.

16
00:01:07,140 --> 00:01:11,900
Thanks to decades of breakthrough research and technology, Microsoft is making AI real

17
00:01:11,900 --> 00:01:18,660
for businesses with Azure AI, a set of services that span vision, speech, language processing,

18
00:01:18,660 --> 00:01:21,740
custom machine learning, and more.

19
00:01:21,740 --> 00:01:26,180
Millions of developers and data scientists around the world are using Azure AI to build

20
00:01:26,180 --> 00:01:31,260
innovative applications and machine learning models for their organizations, including

21
00:01:31,260 --> 00:01:35,260
85% of the Fortune 100.

22
00:01:35,260 --> 00:01:41,260
Microsoft customers like Spotify, Lexmark, and Airbus choose Azure AI because of its proven

23
00:01:41,260 --> 00:01:47,420
enterprise grade capabilities and innovations, wide range of developer tools and services

24
00:01:47,420 --> 00:01:49,460
and trusted approach.

25
00:01:49,460 --> 00:01:54,500
Stay tuned to learn how Microsoft is enabling developers, data scientists, and MLOPS

26
00:01:54,500 --> 00:02:00,260
and DevOps professionals across all skill levels to increase productivity, operationalize

27
00:02:00,260 --> 00:02:06,660
models at scale, and innovate faster and more responsibly with Azure machine learning.

28
00:02:06,660 --> 00:02:11,540
Learn more at aka.ms slash Azure ML.

29
00:02:11,540 --> 00:02:14,340
Alright, onto the show.

30
00:02:14,340 --> 00:02:22,740
Alright, everyone, I am here in Orlando at Microsoft Ignite and I've got the pleasure of

31
00:02:22,740 --> 00:02:25,660
sitting with Eris Barak.

32
00:02:25,660 --> 00:02:28,580
Eris is group manager for Azure AI.

33
00:02:28,580 --> 00:02:31,340
And it is welcome to the Twoma AI podcast.

34
00:02:31,340 --> 00:02:32,340
Thank you.

35
00:02:32,340 --> 00:02:33,340
Thank you.

36
00:02:33,340 --> 00:02:34,340
Great to be here.

37
00:02:34,340 --> 00:02:35,340
Great to be here with you, Sam.

38
00:02:35,340 --> 00:02:36,340
I'm super excited about this conversation.

39
00:02:36,340 --> 00:02:43,020
We will be diving into a topic that is generating a lot of excitement in the industry and that

40
00:02:43,020 --> 00:02:48,580
is AutoML and the automation of the data science process.

41
00:02:48,580 --> 00:02:55,540
But before we dig into that, I'd love to hear how you got started working in ML and AI.

42
00:02:55,540 --> 00:03:00,380
It's a great question because I've been working with data for quite a while.

43
00:03:00,380 --> 00:03:06,500
And I think roughly about five to ten years ago, it became apparent that the next chapter

44
00:03:06,500 --> 00:03:11,620
for anyone working with data has to weave itself through the AI world.

45
00:03:11,620 --> 00:03:19,540
The world of opportunity with AI is really, really only limited by the amount of data you

46
00:03:19,540 --> 00:03:26,180
have, the uniqueness of the data you have and the access you have to data.

47
00:03:26,180 --> 00:03:33,380
And once you're able to connect those two worlds, a lot of things like predictions, new insights,

48
00:03:33,380 --> 00:03:36,060
new directions, sort of come out of the woodwork.

49
00:03:36,060 --> 00:03:42,620
So seeing that opportunity, imagining that potential has naturally led me to work with AI,

50
00:03:42,620 --> 00:03:45,780
I was lucky enough to join the Azure AI group.

51
00:03:45,780 --> 00:03:49,700
And there's really three focal areas within that group.

52
00:03:49,700 --> 00:03:51,500
One of them is machine learning.

53
00:03:51,500 --> 00:03:58,100
How do we enable data scientists of all skills to operate through the machine learning

54
00:03:58,100 --> 00:04:03,220
lifecycle, starting from the data, to the training, to registering the models, to put

55
00:04:03,220 --> 00:04:07,860
in them in productions and managing them, a process we call ML ops.

56
00:04:07,860 --> 00:04:13,660
So just looking at that end-to-end, then I'm just understanding how we enable others to

57
00:04:13,660 --> 00:04:19,460
really go through that process in a responsible, trusted, and a known way, it's been a super

58
00:04:19,460 --> 00:04:21,460
exciting journey so far.

59
00:04:21,460 --> 00:04:27,380
And so did you come at this primarily from a data science perspective, a research perspective,

60
00:04:27,380 --> 00:04:28,860
an engineering perspective?

61
00:04:28,860 --> 00:04:33,900
Well, I think none of the above or all of the above, I'm actually going to go with all

62
00:04:33,900 --> 00:04:34,900
of that above.

63
00:04:34,900 --> 00:04:39,580
I think it'd be remiss to think that, well, if you're going to hit it from a data science

64
00:04:39,580 --> 00:04:46,620
perspective and you're trying to build a product, really looking to build the right set of products

65
00:04:46,620 --> 00:04:51,620
for people to use as they go through their AI journey, you'd probably miss out on an aspect

66
00:04:51,620 --> 00:04:52,620
of it.

67
00:04:52,620 --> 00:04:55,620
If you're just thinking about the engineering perspective, you'll probably end up with

68
00:04:55,620 --> 00:04:59,380
great info that doesn't align with any of the data science.

69
00:04:59,380 --> 00:05:05,220
So you really got to think between the two worlds and how one empowers the other.

70
00:05:05,220 --> 00:05:12,020
You really got to figure out where most data scientists of all skills need the help.

71
00:05:12,020 --> 00:05:13,020
Want the help?

72
00:05:13,020 --> 00:05:18,340
Are looking for tools and products and services on Azure to help them out?

73
00:05:18,340 --> 00:05:23,180
And I think that's the part I find most compelling, sort of figuring that out and then really

74
00:05:23,180 --> 00:05:28,340
going deep where you landed, right? Because if we end up building a new SDK, we're going

75
00:05:28,340 --> 00:05:34,300
to spend a whole lot of time with our data science customers, our data science internal teams

76
00:05:34,300 --> 00:05:37,620
and figure out, well, how should that SDK look like?

77
00:05:37,620 --> 00:05:41,900
But if you're building something like AutoML that's targeted not only at the deeper data

78
00:05:41,900 --> 00:05:47,380
scientists, but also the deeper rooted data professionals, you're going to spend some

79
00:05:47,380 --> 00:05:51,220
time with them and understand not only what they need, but also how that applies to the

80
00:05:51,220 --> 00:05:52,900
world of data science.

81
00:05:52,900 --> 00:05:56,780
And what were you working on before Azure AI?

82
00:05:56,780 --> 00:06:02,260
So before Azure AI in Microsoft, I worked for a team called ShareData, which really created

83
00:06:02,260 --> 00:06:05,860
a set of data platforms for our internal teams.

84
00:06:05,860 --> 00:06:09,860
And prior to joining Microsoft, I worked in the marketing automation space, completely

85
00:06:09,860 --> 00:06:12,580
called the Optify.

86
00:06:12,580 --> 00:06:17,460
And again, the unique assets we were able to bring to the table as part of Optify and

87
00:06:17,460 --> 00:06:20,100
the world of marketing automations were always database.

88
00:06:20,100 --> 00:06:24,620
We're always sort of looking at the data assets the marketers had and said, what else can

89
00:06:24,620 --> 00:06:26,100
we get out of it?

90
00:06:26,100 --> 00:06:31,100
Machine learning wasn't as prevalent at the time, but you could track back to a lot of

91
00:06:31,100 --> 00:06:35,660
what we did at that time and how machine learning would have helped if it was used on such

92
00:06:35,660 --> 00:06:36,980
a general basis.

93
00:06:36,980 --> 00:06:44,300
Yeah, one of the first machine learning use cases that I worked with were with folks

94
00:06:44,300 --> 00:06:52,380
that were doing trying to do like lead scoring and likelihood to buy propensity to buy types

95
00:06:52,380 --> 00:06:53,380
of use cases.

96
00:06:53,380 --> 00:06:55,900
I mean, that's been going on for a really long time.

97
00:06:55,900 --> 00:06:56,900
So we're on a podcast.

98
00:06:56,900 --> 00:07:03,380
So you can see me smiling, but we did a lot of work around building load, lead scoring.

99
00:07:03,380 --> 00:07:04,380
Okay.

100
00:07:04,380 --> 00:07:07,460
And you're a sticks and manual, you're a sticks and sort of general, you're a sticks and

101
00:07:07,460 --> 00:07:10,060
you're a sticks that the customer could customize.

102
00:07:10,060 --> 00:07:14,660
And today you've seen that to really evolve to a place where there's a lot of machine learning

103
00:07:14,660 --> 00:07:15,660
behind it.

104
00:07:15,660 --> 00:07:16,660
I mean, it's perfect for machine learning, right?

105
00:07:16,660 --> 00:07:18,900
You've got all this data, it's fresh.

106
00:07:18,900 --> 00:07:22,660
It's coming, you know, it does insights that are really hard to find out.

107
00:07:22,660 --> 00:07:27,940
Once you start slicing and dicing it by regions or by size of customers, it gets even more

108
00:07:27,940 --> 00:07:28,940
interesting.

109
00:07:28,940 --> 00:07:32,540
So they're all the makings for having machine learning really make it shine.

110
00:07:32,540 --> 00:07:33,940
Yeah, you are getting pretty excited.

111
00:07:33,940 --> 00:07:35,660
Oh, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no,

112
00:07:35,660 --> 00:07:36,660
no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no,

113
00:07:36,660 --> 00:07:44,260
no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no, no,nice,

114
00:07:44,260 --> 00:07:45,580
nice, nice.

115
00:07:45,580 --> 00:07:47,580
Who want to dive into talking about auto ML.

116
00:07:47,580 --> 00:07:48,720
I mean, this is.

117
00:07:48,720 --> 00:07:54,880
Yeah, probably for the level of excitement that and demand for auto ML and enthusiasm

118
00:07:54,880 --> 00:08:00,580
that folks have for the topic, not to mention the amount of confusion that there is for

119
00:08:00,580 --> 00:08:01,580
the topic.

120
00:08:01,580 --> 00:08:08,380
covered it nearly enough on the podcast, you know, certainly, you know, when I think of when I

121
00:08:08,380 --> 00:08:17,260
think of AutoML, if there's, you know, a long kind of academic history behind the the technical

122
00:08:17,260 --> 00:08:25,980
approaches that that drive it, but it was really popularized for many, you know, with Google's cloud

123
00:08:25,980 --> 00:08:31,900
AutoML in 2018 and like before that, they had this New York Times, you know, they had this PR win,

124
00:08:31,900 --> 00:08:35,980
it was like a New York Times article talking about how, you know, AI was going to create itself.

125
00:08:36,540 --> 00:08:44,140
And I think that contributed a lot to, for lack of a better term in this space. But then we see it,

126
00:08:44,140 --> 00:08:50,860
you know, all over the place, there are other approaches more focused on kind of citizen data science.

127
00:08:50,860 --> 00:09:00,380
You know, I'd love to, you know, just start with how you define AutoML and, you know, is, is,

128
00:09:01,180 --> 00:09:05,980
you know, what you're taking on it as a space and, you know, it's role and importance, that kind of thing.

129
00:09:06,540 --> 00:09:12,300
You know, I think I can, I really relate to many of the things you touched on. So maybe I'll start,

130
00:09:13,260 --> 00:09:17,900
and this is true for many things you do in Australia, but definitely for AutoML, on your point around

131
00:09:17,900 --> 00:09:25,660
academic roots. Microsoft has this division called MSR, Microsoft Research, and it's really a set

132
00:09:25,660 --> 00:09:32,140
of researchers who look into bleeding edge topics and drive the world of research in different areas.

133
00:09:32,780 --> 00:09:42,540
And that is when we first got, in our team, introduced to AutoML. So they've been doing research,

134
00:09:42,540 --> 00:09:49,580
a subset of that team has been doing research around the AutoML area for quite a few years.

135
00:09:49,580 --> 00:09:54,060
They've been looking at it. They've been thinking, well, you know, it started. Yes, I've heard the

136
00:09:54,060 --> 00:10:00,780
sentence AI making AI. But, you know, when you start reading into it, like, what does it mean? And,

137
00:10:02,300 --> 00:10:07,500
it means, to be honest, it means a lot of things to many people. It's quite overused. I'll be

138
00:10:07,500 --> 00:10:13,500
quite frank. There's no one standard industry standard definition that says, here's what AutoML is.

139
00:10:13,500 --> 00:10:17,660
I can tell you what it is for us. I can tell you what it is for our customers. I can tell you

140
00:10:17,660 --> 00:10:24,780
where we're seeing it make a ton of impact. And it comes to using machine learning capabilities

141
00:10:25,580 --> 00:10:34,220
in order to help you, being the data scientist, create machine capabilities in a more efficient,

142
00:10:34,220 --> 00:10:42,220
in a more accurate, in a more structured fashion. My reaction to that is that it's super high level.

143
00:10:42,220 --> 00:10:48,460
And it, it kind of leaves the door open for all of, you know, this broad spectrum of definitions

144
00:10:48,460 --> 00:10:56,060
that you just talked about. Like, for example, not to kind of over index on what Google's been doing,

145
00:10:56,060 --> 00:11:03,340
but like Cloud AutoML Vision when it first came out was, you know, a way for folks to do a

146
00:11:03,340 --> 00:11:11,820
vision cognitive services, but use some of their own data to tune it, right? Which is a lot different.

147
00:11:11,820 --> 00:11:18,620
In fact, they, they caught a lot of flack from the, the academic AutoML community because

148
00:11:19,180 --> 00:11:25,980
they totally redefined what that community had been working for, you know, for many years. And,

149
00:11:27,180 --> 00:11:32,140
you know, started kind of creating the, the confusion. How do we, maybe the first question is,

150
00:11:32,140 --> 00:11:39,500
do you see it as kind of, you know, being the kind of a broad spectrum of things? Or is it,

151
00:11:40,700 --> 00:11:47,020
you know, how do we even get to a definition that kind of separates the personalized, you know,

152
00:11:47,020 --> 00:11:52,860
cognitive services trained with my own data versus, you know, this other set of things?

153
00:11:53,900 --> 00:11:55,100
I don't know if that's a question.

154
00:11:55,100 --> 00:12:00,540
No, no, no, I think as you see it as more of that general sense. So, yeah, I would say,

155
00:12:02,060 --> 00:12:09,420
probably not. I see it as a much more concrete set of capabilities that adhere to a well-known

156
00:12:09,420 --> 00:12:14,540
process. Okay. That actually is agreed upon across the industry. When you build a model, what do you

157
00:12:14,540 --> 00:12:21,660
do? You get data, you featureize that data. Once the features are in place, you choose a learner,

158
00:12:21,660 --> 00:12:27,820
you choose an algorithm. You train that algorithm with the data, creating a model. At that point,

159
00:12:27,820 --> 00:12:33,580
you want to assess the evaluate the model, make sure it's accurate. And you want to get some

160
00:12:33,580 --> 00:12:39,420
understanding towards what are the underlining features that have most affected the model.

161
00:12:39,980 --> 00:12:45,820
And you want to make sure, in addition to that, that you can explain that model is not biased.

162
00:12:45,820 --> 00:12:52,700
You can explain that model is really fair towards all aspects of what it's looking at. That's a

163
00:12:52,700 --> 00:12:57,100
well-known process. I think there's no argument around that in the sort of the machine learning field,

164
00:12:57,100 --> 00:13:04,460
that's sort of the end to end. AutoML allows automating that process. So, at its purest, you feed

165
00:13:04,460 --> 00:13:11,500
AutoML the data and you get the rest for free, if you may. Okay, that would be sort of where we're

166
00:13:11,500 --> 00:13:17,820
heading, where we want to be. And I think that's at the heart of AutoML. So, where does the confusion

167
00:13:17,820 --> 00:13:27,260
start? I could claim that what we or others do for custom vision follows that path. And it does.

168
00:13:27,260 --> 00:13:32,860
I can also claim that some of what we do for custom vision is automated. And, you know,

169
00:13:32,860 --> 00:13:39,020
then there's a short sort of hop to say, well, therefore it is AutoML. But I think that misses the

170
00:13:39,020 --> 00:13:45,180
general point of what we're trying to do with AutoML. Custom vision is a great example where

171
00:13:45,180 --> 00:13:50,780
AutoML can be leveraged. But AutoML can be leveraged wherever that end-to-end process happens in

172
00:13:50,780 --> 00:13:59,740
machine learning. Nice. I like it. I like it. So, maybe we can kind of walk through that end-to-end

173
00:13:59,740 --> 00:14:08,300
process and talk about some of the key areas where automation is applied to contribute to AutoML.

174
00:14:09,580 --> 00:14:17,100
So, I'd like to start with Featureization. And, you know, at the end of the day, we want an

175
00:14:17,100 --> 00:14:24,220
accurate model. A lot of that accuracy, a lot of the insights we can get, the predictions we can

176
00:14:24,220 --> 00:14:32,220
get, and the output we can get from any model is really hinged on how effective your Featureization

177
00:14:32,220 --> 00:14:38,700
is. So, you know, many times you hear that, well, 80% of the time on data sciences spend on data.

178
00:14:39,420 --> 00:14:43,100
A lot of the time is, can I put it up? Do you know where that number comes from?

179
00:14:43,100 --> 00:14:47,900
Oh, of course. Everyone says it. Everyone repeats it. It's a self-fulfilling prophecy.

180
00:14:47,900 --> 00:14:53,980
You know, I'm going to say 79% of this, just to be sure. But I think it's more of an urban legend

181
00:14:53,980 --> 00:14:59,580
at that point. I don't think there's a, you know, I am seeing customers who do spend that kind of

182
00:14:59,580 --> 00:15:03,900
percentage of time. I am seeing experiments we run that take that amount of time.

183
00:15:04,380 --> 00:15:07,020
Generalizing that number is just, it's too fun not to do.

184
00:15:07,020 --> 00:15:12,300
So, you know, I was wondering if there's, I was thinking about this recently and I'm wondering

185
00:15:12,300 --> 00:15:16,780
if there's some, you know, institute for data science that's been tracking this number over time.

186
00:15:16,780 --> 00:15:20,860
It'd be interesting to see how it changes over time, I think, is the broader curiosity.

187
00:15:20,860 --> 00:15:23,420
If you would, I should go figure that out. I think that's an interesting one.

188
00:15:23,420 --> 00:15:24,860
I've got to be interested in the outside.

189
00:15:25,900 --> 00:15:26,460
So, sorry.

190
00:15:28,940 --> 00:15:35,100
So, but, you know, you can easily and anyone who's built a model can quickly see the effect of

191
00:15:35,100 --> 00:15:44,300
featureization on the output. Now, a lot of what's done when building features can be automated.

192
00:15:44,300 --> 00:15:49,820
I would even venture say that a part of it can be easily automated. But then, naturally,

193
00:15:49,820 --> 00:15:54,620
what are some examples? Some examples are like, I want to take two columns and bring them together

194
00:15:54,620 --> 00:16:00,460
into one. I want to change a date format to better align with the rest of my columns.

195
00:16:01,020 --> 00:16:06,940
You know, not even an easy one. I'd like to enhance my data with some public holiday data

196
00:16:06,940 --> 00:16:11,260
when I do my sales forecasting because that's really going to make it more accurate.

197
00:16:11,260 --> 00:16:16,460
It's more a data enhancement, but you definitely want to build features into your data to do that.

198
00:16:16,460 --> 00:16:24,060
So, getting that right is key. Now, start thinking of data sets that have many rows,

199
00:16:25,100 --> 00:16:30,220
but more importantly, have many columns. Okay, and then the problem gets harder and harder.

200
00:16:30,220 --> 00:16:34,700
You want to try a lot more options. There's a lot more ways of featureizing the data.

201
00:16:34,700 --> 00:16:42,060
Some are more effective than others. Like, you know, we recently in AutoML have incorporated

202
00:16:42,700 --> 00:16:50,140
the birth model into our auto-futurization capability. Now, that allows us to take text data

203
00:16:50,140 --> 00:16:56,220
used for classification and quickly featureize it. It helps us featureize it in a way that

204
00:16:56,220 --> 00:17:01,740
requires less input data to come in for the model to be accurate. I think that's a great example

205
00:17:01,740 --> 00:17:10,380
of how deep and how far that can go. You mentioned that getting that featureization right is key.

206
00:17:11,260 --> 00:17:18,140
To what extent is it an algorithmic methodological challenge versus a computational challenge?

207
00:17:18,140 --> 00:17:25,580
If you can even separate these two, meaning, you know, there's this trade-off between like,

208
00:17:25,580 --> 00:17:32,540
you know, we've got kind of this catalog of, you know, recipes, you know, like combining columns

209
00:17:32,540 --> 00:17:37,820
and, you know, binning things and whatever that we can just throw at a data set that looks like it

210
00:17:37,820 --> 00:17:46,380
might fit, you know, versus more intelligent or selective application of techniques based on,

211
00:17:46,380 --> 00:17:52,220
you know, nuances, you know, whether predefined or learned about the data.

212
00:17:52,220 --> 00:17:59,180
Yeah. So it extends on a few dimensions. Okay. I would say there are techniques. Some require more

213
00:17:59,180 --> 00:18:04,860
compute than others. Some are easier to get done. Some require sort of a deeper integration with

214
00:18:04,860 --> 00:18:10,300
existing miles. Like I mentioned, the bird before to be effective. But that's only one dimension.

215
00:18:10,300 --> 00:18:16,700
The other dimension is the fit of the data into a specific learner. So, you know, we don't call it

216
00:18:16,700 --> 00:18:22,060
experiments and machine learning for nothing. You experiment. Right. You try. Okay. Nobody really

217
00:18:22,060 --> 00:18:27,100
knows exactly which features would affect the model in a proper way would drive accuracy.

218
00:18:27,100 --> 00:18:33,660
So there's a lot of iteration and experimentation being done. Now think of this place where you have

219
00:18:33,660 --> 00:18:38,460
a lot of data, creating a lot of features and you want to try multiple learners, multiple algorithms

220
00:18:38,460 --> 00:18:44,460
if you may. And that becomes quickly quite a mundane process that automating can really,

221
00:18:44,460 --> 00:18:52,060
really help with. And then at the top of that, we're seeing more and more models creating created with

222
00:18:52,060 --> 00:18:59,500
just more and more features. The more features you have, the more nuance you can get about describing

223
00:18:59,500 --> 00:19:04,780
your data, the more nuance the model can get about predicting what's going to happen next. So we're

224
00:19:04,780 --> 00:19:10,140
not seeing models with millions and billions of features coming out. Now, auto mail is not yet

225
00:19:10,140 --> 00:19:15,900
to prepare the prepared to deal with the billion feature model, but we see that dimension extent.

226
00:19:15,900 --> 00:19:23,740
So extend compute one, extend the number of iterations you would have, extend to the number of features

227
00:19:23,740 --> 00:19:30,220
you have. Now you got a problem that's quickly going to be referred to as mundane, hard to do.

228
00:19:30,220 --> 00:19:36,300
Repetitive doesn't really require a lot of imagination. Automation just sounds perfect for that.

229
00:19:36,300 --> 00:19:41,980
So that's why sort of one of the things we went after in the past, I'd say six to twelve

230
00:19:41,980 --> 00:19:46,860
months is how we get featureization to a place where you do a lot of auto featureization.

231
00:19:46,860 --> 00:19:53,100
I'm trying to parse whether the extent to which you got to, you know, whether you agree with this

232
00:19:53,100 --> 00:19:57,980
kind of dichotomy that I presented. Like there's, you've got this, you know, this mundane problem that

233
00:19:57,980 --> 00:20:06,460
if, you know, a human data scientist was doing it would be, you know, just, you know, extremely iterative.

234
00:20:06,460 --> 00:20:13,660
There's certainly one way of automating is just, you know, do that iteration a lot quicker

235
00:20:13,660 --> 00:20:24,780
because a machine can do that. Another way of automating is apply, you know, let's call it, you know,

236
00:20:24,780 --> 00:20:29,980
more intelligent approaches to navigating that feature space or that, you know, iteration space.

237
00:20:31,260 --> 00:20:37,740
And identifying, you know, through algorithmic techniques, you know, what are likely to be the,

238
00:20:37,740 --> 00:20:42,300
the right combinations of features as opposed to just kind of throwing the kitchen sink at it and,

239
00:20:42,300 --> 00:20:47,100
you know, putting that in a bunch of loops. And certainly that's, you know, that's not a dichotomy,

240
00:20:47,100 --> 00:20:53,500
right? You do a bit of both. Can you elaborate on that kind of trade off or the relationship

241
00:20:53,500 --> 00:20:57,020
between those two approaches? Is that even a right way to think about it? Or is that the wrong

242
00:20:57,020 --> 00:21:01,580
way to think about it? I think it's a definitely a way to think about it. Like if you think about it,

243
00:21:01,580 --> 00:21:08,860
it's a, no, I'm just thinking through that lens for a second. So I think you describe sort of the

244
00:21:08,860 --> 00:21:13,820
brute force approach. Yeah. Yeah. On one side. Right. The other side is how nuanced can you get

245
00:21:13,820 --> 00:21:19,740
about it? Yeah. So what we know is you can get quite nuanced. Those things that are known to work,

246
00:21:19,740 --> 00:21:25,500
things that are not known to work, things that work with a certain type of data set that don't work

247
00:21:25,500 --> 00:21:30,300
with another. Right. Things that work with a certain type of data set combined with the learner

248
00:21:31,020 --> 00:21:37,420
that don't work with others. So as we build AutoML, I talked about machine learning used to

249
00:21:37,420 --> 00:21:42,380
help with machine learning. We train a model to say, okay, in this kind of event, you might want to

250
00:21:42,380 --> 00:21:47,260
try this kind of combination first, because if you're, I talked about the number of features,

251
00:21:47,260 --> 00:21:51,980
brute force is not an option. So we got to get a lot more nuanced about it. So what AutoML does

252
00:21:51,980 --> 00:21:59,100
is given those conditions, if you may, or those features for that model, it helps sort of the,

253
00:21:59,100 --> 00:22:05,740
it helps shape the right set of experiments before others. That's allowing you to get a more

254
00:22:05,740 --> 00:22:11,980
accurate model faster. So I think that's one aspect of it. I think another aspect which you may

255
00:22:11,980 --> 00:22:17,420
have touched on. And I think it's really important throughout AutoML. But definitely in featureization is

256
00:22:19,340 --> 00:22:25,020
while people are excited about that, the next thing you're going to hear is, but I want to see what

257
00:22:25,020 --> 00:22:34,460
you did. And you got to show what kind of features you used. Yeah. And quickly follows is, I want to

258
00:22:34,460 --> 00:22:41,180
change feature 950 out of the thousand features you gave me. And I want to add two more features at

259
00:22:41,180 --> 00:22:45,740
the end, because I think they're important. That's where my innovation as a data scientist comes

260
00:22:45,740 --> 00:22:53,900
into play. So you got to, and AutoML allows you to do that, be able to open up that aspect and say,

261
00:22:53,900 --> 00:22:58,140
here's what I've come up with. Would you like to customize? Would you like to add? Would you like

262
00:22:58,140 --> 00:23:03,820
to remove? Because that's where you as a data scientist shine and are able to innovate.

263
00:23:03,820 --> 00:23:11,500
So we started with featureization. Next step is learner slash model selection. I think it's

264
00:23:11,500 --> 00:23:16,860
probably the best next step to talk about. Okay. I think there's a lot of configuration that goes

265
00:23:16,860 --> 00:23:21,980
into this. Like how many iterations do I want to do? Yeah. For instance, how accurate do I want to

266
00:23:21,980 --> 00:23:28,780
get? What defines accuracy? But those are more sort of manual parameters. We ask the user to add

267
00:23:28,780 --> 00:23:36,300
to it. But when automation again comes into play is learner selection. So what happens? You know,

268
00:23:36,300 --> 00:23:41,340
putting AutoML aside, what's going to happen? Build a set of feature, choose a learner. One that I

269
00:23:41,340 --> 00:23:48,060
happen to know is really good for this kind of a problem and try it out. See how accurate I get.

270
00:23:48,060 --> 00:23:52,620
If it doesn't work, but even if it works, you're going to try another. Try another few, try a few

271
00:23:52,620 --> 00:23:58,380
options. AutoML at the heart of it is what it does. Now going back to what we talked about in

272
00:23:58,380 --> 00:24:03,740
featureization, we don't take a brute force approach. We have a model that's been trained over

273
00:24:03,740 --> 00:24:09,180
millions of experiments, sort of knows what would be a good first choice. Given the data,

274
00:24:09,180 --> 00:24:15,020
given the type of features, given the type of outcome you want, what do we try first? Because

275
00:24:15,020 --> 00:24:22,220
people can't just run an endless number of iterations. It takes time, takes cost, and sort of takes

276
00:24:22,220 --> 00:24:29,580
the, frankly, takes a lot of the ROI out of some statistics from AutoML. So you want to get there

277
00:24:29,580 --> 00:24:35,340
as fast as possible based on learnings from the past. So what we've automated is that selection.

278
00:24:35,340 --> 00:24:39,420
Put in the data, set the number of iterations or not set them. We have a default number that

279
00:24:39,420 --> 00:24:44,540
goes in and then start using the learners based on the environment you're seeing out there

280
00:24:44,540 --> 00:24:50,060
and choosing them out of that from that other model we've trained over time. By the way,

281
00:24:50,060 --> 00:24:57,260
that's a place where we really leaned on the outputs and the outputs we got from MSR.

282
00:24:57,260 --> 00:25:02,620
That's a place where they, as they were defining AutoML, as they were researching it,

283
00:25:02,620 --> 00:25:08,300
really went deep into and really sort of created assets were then able to leverage a product

284
00:25:08,300 --> 00:25:13,100
sort of evolves over time and technology evolves over time. But if I have to pick the most

285
00:25:13,100 --> 00:25:19,100
or the deepest rooted area we've looked at from MSR, it's definitely the ability to choose

286
00:25:19,100 --> 00:25:24,380
the right learner for the right job with a minimal amount of compute associated with it if you

287
00:25:24,380 --> 00:25:32,700
may. And what are some of the core contributions of that research if you kind of go to the layer

288
00:25:32,700 --> 00:25:38,780
deeper than that? Are you asking the context of choosing a model or in general?

289
00:25:38,780 --> 00:25:43,500
Yeah, in the context of choosing a model. Like, for example, as you described this,

290
00:25:43,500 --> 00:25:51,580
what is essentially a learner that's learning which model to use that created a bunch of

291
00:25:51,580 --> 00:25:58,220
questions from me around like, okay, how do you represent this whole? What are the features of

292
00:25:58,220 --> 00:26:05,820
that model and what is the structure of that model? I'm curious if that's something that came out

293
00:26:05,820 --> 00:26:12,860
of MSR or that was more the, you know, came from the productization and then, you know, if there are

294
00:26:12,860 --> 00:26:19,100
specific things that came out of that MSR research that come to mind as being, you know, pivotal to the

295
00:26:19,100 --> 00:26:30,860
way you think about that process. So the first version coming out of MSR wasn't really of the

296
00:26:30,860 --> 00:26:39,020
end to end product, but at the heart of it was the model that helps you pick learners as it relates

297
00:26:39,020 --> 00:26:45,180
to the type size of data you have and the type of target you have. This is where a lot of the research

298
00:26:45,180 --> 00:26:51,420
went into. This is where we publish papers around where which features matter when you choose that.

299
00:26:52,060 --> 00:26:57,340
This is where MSR went and collected a lot of historical data around people running experiments

300
00:26:57,340 --> 00:27:04,540
and trained that model. So the basis at the heart of our earliest versions, we really leaned on MSR

301
00:27:04,540 --> 00:27:10,140
to get that model in place. You know, within the workflow to where the auto-futurization I talked

302
00:27:10,140 --> 00:27:14,860
about some other aspects we'll talk about in a minute, but at the heart of it, they did all that

303
00:27:14,860 --> 00:27:19,740
research to understand, well, first trained that model, just, you know, grabbing the data,

304
00:27:19,740 --> 00:27:27,260
getting it right out of experiments. Is that model? Is it, you know, a single model? Is it relatively simple?

305
00:27:27,260 --> 00:27:33,900
Is it fairly complex? Is it some kind of ensemble? Like, oversimplify a little bit, but remember,

306
00:27:34,620 --> 00:27:40,620
it profiles your data. So it takes a profile of your data. It profiles your features. It takes a

307
00:27:40,620 --> 00:27:46,140
profile of your features. It looks at the kind of outcome you want to achieve. Am I doing time

308
00:27:46,140 --> 00:27:50,060
series forecasting here? I'm doing classification. I'm doing regression. That really matters.

309
00:27:50,620 --> 00:27:59,100
And then based on those features, picks the first learner to go after. Then what it does is

310
00:27:59,100 --> 00:28:05,340
uses the result of that first iteration, which included all the features I'm talking about,

311
00:28:05,340 --> 00:28:12,780
but also now includes, hey, I also tried learner X. And I got this result. And that helps it

312
00:28:12,780 --> 00:28:21,180
choose the next one. So what happens is you look at the base data you have, but you constantly

313
00:28:21,180 --> 00:28:27,420
have additional features that show you, well, what have I tried and what were the results? And then

314
00:28:27,420 --> 00:28:32,700
the next learner gets picked based on that. And that gets you in a place where the more you iterate,

315
00:28:32,700 --> 00:28:38,460
the closer you get to that learner that gives you a more accurate, accurate result.

316
00:28:38,460 --> 00:28:45,580
So then is it kind of at its core? Is it a, you know, it's, I'm hearing elements of both,

317
00:28:45,580 --> 00:28:50,700
you know, supervised learning. You have a bunch of experiments and, you know, the models that

318
00:28:50,700 --> 00:28:57,260
were chosen, ultimately, you know, but also elements of something, you know, more like, you know,

319
00:28:57,260 --> 00:29:02,460
simple reinforcement learning, contextual bandics, explore, exploit kind of things as well.

320
00:29:02,460 --> 00:29:09,020
It definitely does both. I would, if I could just sort of touch on one point, reinforcement

321
00:29:09,020 --> 00:29:14,700
learning as it's defined, I wouldn't say we're doing reinforcement learning there. Saying that,

322
00:29:14,700 --> 00:29:20,060
we're definitely sort of every time we have an iteration going or, you know, every X times we have

323
00:29:20,060 --> 00:29:26,060
that, we do fine tune the training of the model to learn as it runs more and more. So I think

324
00:29:26,060 --> 00:29:33,980
reinforcement learning is a lot more sort of a mem reactive. But taking that as an analogy,

325
00:29:33,980 --> 00:29:39,020
we do sort of continuously collect more training data and then retrain the model that helps us choose

326
00:29:39,020 --> 00:29:44,700
better and better over time. Interesting, interesting. So we've talked about a couple of these aspects of

327
00:29:44,700 --> 00:29:51,740
the process, feature engineering model selection. You know, one of the next is once you've identified

328
00:29:51,740 --> 00:29:59,260
the model like tuning hyper parameters and optimization, do you consider that its own step or is that

329
00:29:59,260 --> 00:30:05,020
kind of, you know, a thing that you're doing all along or both? I consider it part of that Uber

330
00:30:05,020 --> 00:30:11,500
process I talked about earlier. You know, we're just delving into starting to use deep learning

331
00:30:12,620 --> 00:30:20,220
learners within AutoML. So that's where we're also going to automate the parameter selection,

332
00:30:20,220 --> 00:30:25,100
hyper parameter selection. A lot of the learners we have today are classic machine learning if you

333
00:30:25,100 --> 00:30:32,940
may. So that's where hyper parameter tuning is not as applicable. But seeing that every time

334
00:30:33,500 --> 00:30:38,300
we see an opportunity like that, I think I mentioned earlier in our forecasting capabilities,

335
00:30:38,300 --> 00:30:43,580
we're now adding them deep learning models. In order to make the forecasting more accurate,

336
00:30:43,580 --> 00:30:47,340
that's where that tuning will also be automated. Then if you think about actually a library,

337
00:30:47,340 --> 00:30:57,020
I think we chatted about that pre-interview. But you mentioned that you're doing some stuff with

338
00:30:57,020 --> 00:31:03,020
TCN and Arima around time series forecasting. Can you elaborate on that? Yeah, so I talked about this

339
00:31:03,900 --> 00:31:12,060
process of choosing a learner. Now, you also have to consider what is your possible set of learners

340
00:31:12,060 --> 00:31:20,700
you can choose from. And what we've added recently are sort of deep learning models or networks that

341
00:31:20,700 --> 00:31:27,740
actually are used within that process. So TCN and Arima are quite useful when doing time series

342
00:31:27,740 --> 00:31:33,500
forecasting really drive the accuracy based on the data you have. So we've now embedded those

343
00:31:33,500 --> 00:31:39,580
capabilities within our forecasting capability. So then when you say within forecasting meaning

344
00:31:39,580 --> 00:31:48,700
a forecasting service that you're offering as opposed to within. Let me clarify. Yeah, there's

345
00:31:48,700 --> 00:31:58,540
three core use cases. We support us part of AutoML. One for classification. The other for regression.

346
00:31:59,420 --> 00:32:05,100
And the third for time series forecasting. So when I refer to that, I was referring more to that

347
00:32:05,100 --> 00:32:11,980
use case within AutoML. Got it. Got it. So in other words, in the context of that forecasting

348
00:32:11,980 --> 00:32:22,140
use case as opposed to building a system that is general and applying it to time series and using

349
00:32:22,140 --> 00:32:29,100
you know more generalized models you're using now TCN and Arima as kind of quarter that which are

350
00:32:29,100 --> 00:32:35,100
you know long proven models for time series forecast. Yeah, I would argue there also be generalized

351
00:32:35,100 --> 00:32:40,700
but in the context of forecast. So but but let me tell you how we're thinking about it. There's

352
00:32:40,700 --> 00:32:45,820
generally applicable models. Yeah. Now we'll see in different use cases like in forecasting,

353
00:32:45,820 --> 00:32:51,020
there are generally applicable models for that area that are really useful in that area. That's

354
00:32:51,020 --> 00:32:56,220
sort of the current state we're in right now. And we want to add a lot more sort of known

355
00:32:56,220 --> 00:33:02,780
and generally applicable models to each area. In addition to that sort of where we're heading and

356
00:33:02,780 --> 00:33:08,140
as I see this moving forward, more and more customers will want to add their own custom model.

357
00:33:08,140 --> 00:33:14,380
Right. We've done forecasting for our manufacturing. We've tuned it to a place where it's just

358
00:33:14,380 --> 00:33:18,860
amazing for what we do because we know a lot more about our business than anyone else.

359
00:33:19,580 --> 00:33:23,980
We'd like to put that in the mix every time your AutoML considers the best option.

360
00:33:23,980 --> 00:33:29,980
So I think we're going to see I'm already seeing a lot of that sort of they bring your own model

361
00:33:30,540 --> 00:33:34,780
which makes sense. Yeah, it's an interesting extension to kind of bring your own data which was

362
00:33:34,780 --> 00:33:39,580
the you know one of the first frontiers here. No, I think it's very like I mean you're coming in

363
00:33:40,140 --> 00:33:44,300
to a world now it's not the hey there's no data science here. There's a lot of data science going

364
00:33:44,300 --> 00:33:50,140
on. So I'm the data scientist. I've worked on this model for the past you name it weeks, months,

365
00:33:50,140 --> 00:33:57,020
years and now this AutoML thing is really going to help me be better. I don't think that's a claim

366
00:33:57,020 --> 00:34:02,540
we even want to make. I don't think that's a claim that fair to make. The whole idea is find

367
00:34:02,540 --> 00:34:07,660
the user where they are. You have a custom model. Sure, let's plug that in. It's going to be

368
00:34:07,660 --> 00:34:14,220
considered with the rest in a fair and visible way. Maybe with the auto-futurization it even

369
00:34:14,220 --> 00:34:19,740
goes and becomes more accurate. Maybe you'll find out something else you want to do in your model.

370
00:34:19,740 --> 00:34:23,180
Maybe you have five of those models and you're not sure which one is best. You plug in all five.

371
00:34:23,900 --> 00:34:28,300
I think that's very much sort of where we're heading. Plugging into an existing process that's

372
00:34:28,300 --> 00:34:35,100
already deep and rich wherever we land. The three areas that we've talked about again,

373
00:34:35,100 --> 00:34:42,060
featureization model selection and parameter or optimization are I think kind of what we

374
00:34:42,060 --> 00:34:52,540
tend to think of as the core of AutoML. Do you also see it playing in the tail end of that

375
00:34:52,540 --> 00:34:59,020
process like the deployment after the models deployed? There are certainly opportunities to

376
00:34:59,580 --> 00:35:07,660
automate there. A lot of that is very much related to DevOps and that kind of thing. Are there

377
00:35:07,660 --> 00:35:17,580
elements of that that are more like what we're talking about here? I think there's two steps before

378
00:35:17,580 --> 00:35:25,180
that. I think there's the evaluation of the model. How accurate is it? But again, you get into

379
00:35:25,180 --> 00:35:30,700
this world of iterations. That's where automation is really helpful. That's one. The other

380
00:35:30,700 --> 00:35:37,180
is the interpretation of the model. That's where automation really helps as well. Now especially when

381
00:35:37,180 --> 00:35:41,980
I did a bunch of automation, I now want to make sure what which features really did affect this

382
00:35:41,980 --> 00:35:49,420
thing. Explain them to me and work that into your automated processes. Did your process provide a

383
00:35:49,420 --> 00:35:57,820
fair set of data for my model to learn from? Does it represent all, all genders probably?

384
00:35:57,820 --> 00:36:02,940
Does all races probably? Does it represent all aspects of my problem? You choose them in a fair

385
00:36:02,940 --> 00:36:11,820
way. Where do you see imbalance? I think automating those pieces are right before we jump into

386
00:36:11,820 --> 00:36:18,140
deployment. I think it's really mandatory when you do AutoML to give that full picture. Otherwise,

387
00:36:18,140 --> 00:36:25,740
you're creating the right set of tools, but I don't feel or I feel without doing that, you're

388
00:36:25,740 --> 00:36:30,460
falling a bit short of providing everyone the right checks and balances to look at the work they're

389
00:36:30,460 --> 00:36:36,780
doing. When I generalize the AutoML process, I definitely include that. Back to your question,

390
00:36:36,780 --> 00:36:44,940
does deployment... Do I see deployment playing there? You know what? To be honest, I'm not sure.

391
00:36:44,940 --> 00:36:52,540
So I think we're definitely the way we evaluate success is we look at the models deployed

392
00:36:52,540 --> 00:36:59,500
with AutoML or via AutoML or that were created via AutoML or not deployed. We looked at their

393
00:36:59,500 --> 00:37:06,700
inferences. We look at their scoring and we provide that view to the customer to assess

394
00:37:06,700 --> 00:37:12,700
the real value of their model. Automation there, I think. You know, if I have to guess,

395
00:37:12,700 --> 00:37:19,500
yes. Automation will stretch there. Do I see it today? Can I call it out today? Not just yet.

396
00:37:19,500 --> 00:37:26,860
Well, I mean, a lot of conversation around this idea of deploying a model out into production

397
00:37:26,860 --> 00:37:37,420
and we've thankfully, I think, convinced people that it's not just like deploy once and you're

398
00:37:37,420 --> 00:37:42,220
not thinking about it anymore. You have to monitor the performance of that model and there's

399
00:37:42,220 --> 00:37:47,740
a limited lifespan for most of the models that we're putting in production. And then kind of the

400
00:37:47,740 --> 00:37:53,180
next thing that folks get excited about as well, I can just see when my model falls out of tolerance

401
00:37:53,180 --> 00:37:58,060
and then like auto retrain. It's one of these. Everyone's talking about it, you know,

402
00:37:58,060 --> 00:38:04,460
few are actually doing it. It sounds like you're kind of in agreement with that. Like we're kind

403
00:38:04,460 --> 00:38:12,300
of not there yet at scale or no. So I think, you know, we often refer to that world as the world

404
00:38:12,300 --> 00:38:22,060
of ML ops, machine learning operations in a more snappy way. I think there is a lot of automation

405
00:38:22,060 --> 00:38:28,780
there. If you look at automation, you do it DevOps for just code. I mean, forget machine learning

406
00:38:28,780 --> 00:38:34,860
code, but code let alone models is very much automation we need. Right. I do think there are like

407
00:38:35,820 --> 00:38:42,940
two separate loops that have clear interface points, like deployed models, like maybe

408
00:38:43,660 --> 00:38:50,220
data about data drift, but they sort of move in different cycles at different speeds. So I'm

409
00:38:50,220 --> 00:38:58,700
maybe, you know, we're learning more about this, but I suspect that iteration of training,

410
00:38:58,700 --> 00:39:03,500
improving accuracy, getting to a model where the data science team says, oh, this one's great,

411
00:39:03,500 --> 00:39:08,380
let's use that. I suspect that's one cycle. And frankly, that's where we've been

412
00:39:08,380 --> 00:39:13,980
hyper focused on automating with auto ML. There's naturally another cycle of that operations that

413
00:39:13,980 --> 00:39:19,020
we're sort of looking at the automation opportunities with ML ops. Do they combine into one automation

414
00:39:19,020 --> 00:39:30,620
cycle? I'm not sure. It does strike me that like when, you know, for example, the decision,

415
00:39:30,620 --> 00:39:37,900
you know, do I kind of retrain from scratch? Do I incrementally retrain? Do I start all the way

416
00:39:37,900 --> 00:39:47,100
over? Maybe that decision could be driven by, you know, some patterns or characteristics in the

417
00:39:47,100 --> 00:39:53,260
nature of the drift and the performance shift that, you know, a model could be applied to. And then

418
00:39:53,260 --> 00:39:57,820
we start to, you know, there are aspects of, you know, what we're thinking about and talking about

419
00:39:57,820 --> 00:40:05,340
as auto ML that are applied to that like DevOps-y part. Who knows? I'd say who knows? And I think, you know,

420
00:40:05,340 --> 00:40:11,580
listening to you, you know, I'm taking note to myself that while we sort of have a bit of a fixed

421
00:40:11,580 --> 00:40:17,020
mindset on the definition, we definitely need to break through some of that and open up and see

422
00:40:17,020 --> 00:40:23,820
well, what is it that we're hearing from the real world that should shape what we automate, how

423
00:40:23,820 --> 00:40:29,980
we automate under which umbrella we put it? I think, and you will notice this moving so fast

424
00:40:29,980 --> 00:40:35,580
and evolving so fast. I think we're just at the, you know, first step of it. Yeah. Yeah. Yeah.

425
00:40:36,940 --> 00:40:44,540
A couple of quick points that I wanted to ask about. Another couple of areas that are generating

426
00:40:44,540 --> 00:40:51,180
excitement under this umbrella are neural architecture search and neural evolution and kind of

427
00:40:51,180 --> 00:40:56,700
techniques like that. Are you doing anything in those domains? Again, we're incorporating some of

428
00:40:56,700 --> 00:41:04,380
those neural architectures into auto ML today. I talked about our deeper roots with MSR and sort of

429
00:41:04,380 --> 00:41:11,420
how they got us that first model. Our MSR team is very much looking deeper into those areas. They're

430
00:41:11,420 --> 00:41:19,580
not things that have formulated just yet, but the feeling is that sort of the same concepts we put

431
00:41:19,580 --> 00:41:27,340
into auto ML or automated machine learning can be used there, can be automated there. I'm being a

432
00:41:27,340 --> 00:41:33,420
little vague because it is a little vague for us, but the feeling is that there is something there.

433
00:41:33,420 --> 00:41:38,220
And, you know, we're lucky enough to have the MSR arm that when there's a feeling there's something

434
00:41:38,220 --> 00:41:43,180
there. Some research starts to pan out and the thinking of different ideas there. But

435
00:41:44,540 --> 00:41:49,100
to be frank, I don't have much to share at that point in terms of more specifics. Yeah. Yeah.

436
00:41:49,100 --> 00:41:57,100
And I guess as, you know, we've been focused on this auto ML is a kind of set of platform

437
00:41:57,100 --> 00:42:03,260
capabilities that helps data scientists be more productive. There's a whole other aspect of,

438
00:42:03,260 --> 00:42:09,100
you know, Microsoft delivering cognitive services for vision and, you know, other things

439
00:42:10,140 --> 00:42:16,860
where they're using auto ML internally and where kind of, you know, it's primarily deep learning

440
00:42:16,860 --> 00:42:22,300
based and I can only imagine that they're throwing things like architecture search and things

441
00:42:22,300 --> 00:42:29,020
like that at the problem. Yeah. Yeah. So they do happen in many cases. I think custom vision is

442
00:42:29,020 --> 00:42:35,180
a good example. We don't see the general patterns just yet. And for the ones we do see sort of the

443
00:42:35,180 --> 00:42:41,500
means of automation haven't been put out that yet. So I think it's like if I look at where we were

444
00:42:41,500 --> 00:42:47,420
with the auto ML thinking probably a few years back is where that is right now, meaning oh,

445
00:42:47,420 --> 00:42:53,100
it's interesting. We know there's something there. The question is how we sort of further evolve

446
00:42:53,100 --> 00:42:58,940
into something more specific. Well, Ed is thanks so much for taking the time to chat with us about

447
00:42:58,940 --> 00:43:04,380
what you're up to. Great conversation and learned a ton. Thank you. Same here. Thanks for your time

448
00:43:04,380 --> 00:43:11,900
and the questions were great. That a great time. All right, everyone. That's our show for today

449
00:43:11,900 --> 00:43:19,340
to learn more about this episode. Visit Twomla.com. As always, thanks so much for listening and catch you

450
00:43:19,340 --> 00:43:29,740
next time.

