WEBVTT

00:00.000 --> 00:06.640
It's hard to believe, but this is the last podcast episode you will hear before I kick off our inaugural

00:06.960 --> 00:12.520
Twimmelcon conference on Tuesday morning with my on-stage interviews with Anjuang,

00:13.160 --> 00:20.840
co-founder of Landing AI and Coursera, and Deepak Agarwal, vice-president of artificial intelligence at LinkedIn.

00:22.440 --> 00:27.220
This has shaped up to be an incredible event with speakers from Airbnb,

00:27.220 --> 00:34.580
capital-1, Facebook, Levi Strauss, Stripe, SurveyMonkey, Twitter, Uber, and many more companies,

00:34.580 --> 00:41.780
all detailing how they're moving ML and AI out of the lab and driving real value by accelerating,

00:41.780 --> 00:46.180
automating, and scaling their ability to get models into production.

00:46.900 --> 00:49.060
It is not too late to join us.

00:49.060 --> 00:56.020
Register for Twimmelcon today using the code I Want In for 20% off of registration

00:56.020 --> 01:00.500
and a ticket to the hottest enterprise machine learning conference of the year.

01:01.380 --> 01:03.380
Hope to see you there.

01:05.860 --> 01:11.460
All right, everyone. I am on the line with Alex Bann. Alex is a professor of electrical

01:11.460 --> 01:16.740
engineering and computer science at UC Berkeley. Alex, welcome to this weekend machine learning

01:16.740 --> 01:21.060
in AI. Hi, good morning. Thank you for having me. It's fun to be here today.

01:21.060 --> 01:28.340
I am actually in Las Vegas, but you are no longer in Las Vegas, but the thing that

01:28.340 --> 01:34.820
kind of brings us together is you were recently speaking at the AI summit that Amazon put together

01:34.820 --> 01:41.060
here at the reinvent conference. We're going to dig into your presentation, but before we do,

01:41.060 --> 01:45.780
I'd love to hear a little bit about your background and how you got involved in machine learning.

01:45.780 --> 01:50.420
While I was a control theorist by training, which means essentially learning how to

01:50.420 --> 01:54.500
build algorithms to control machines, to control processes, to control robots,

01:55.460 --> 02:01.140
and it's a discipline which is fairly optimization based that finds its roots in the 90s.

02:01.140 --> 02:06.660
And so with the current revolution we are experiencing in AI and machine learning,

02:07.700 --> 02:12.580
I think it became almost obvious that all these fields are progressively merging.

02:12.580 --> 02:17.060
So you think about robotics, about perception and action, optimization, control.

02:17.060 --> 02:22.500
It's all becoming one. And so like many others in this field, I was drawn to it because it provided

02:22.500 --> 02:27.300
a lot of opportunities for new breakthroughs and revisiting all the problems with new techniques

02:27.300 --> 02:33.540
that will clearly advance the field. Great. And so what are your research interests?

02:34.340 --> 02:41.620
So I'm interested in two topics which are interconnected. The first one is the large-scale

02:41.620 --> 02:46.740
impacts of traffic routing apps. When it happens with many, many people use the same apps on the road,

02:47.300 --> 02:52.020
what it does to mobility at super large scale. And then the second topic, which probably is the

02:52.020 --> 02:58.660
topic we're going to talk most today, is the notion of mixed autonomy. What do you do if you have

02:58.660 --> 03:03.700
self-driving vehicles or vehicles with some level of automation interact with manned vehicles?

03:03.700 --> 03:09.380
Your car, my car, car driven by human. And so these two interact because if you think about mobility,

03:09.380 --> 03:15.060
mobility obviously has a lot of large scale aspects. How do you solve the traffic jams in LA?

03:15.060 --> 03:20.420
But mobility also has a lot of local aspects. How do you make traffic flow more efficiently at

03:20.420 --> 03:25.220
a local level? How do you manage an intersection better? How you smooth traffic on the freeway

03:25.220 --> 03:30.100
and so on and so forth? And both of these scales are deeply impacted by machine learning and AI

03:30.100 --> 03:38.980
these days. Interesting. So I'm originally from New York and my wife will on occasion

03:38.980 --> 03:44.820
remind me that I am also a New York driver to her that has a very particular meaning.

03:45.780 --> 03:53.460
But not long ago, there was some research. Actually, it was long ago. Many years ago, I came across

03:53.460 --> 04:00.260
some research study that said that a single aggressive driver can dramatically improve

04:00.260 --> 04:05.780
traffic flow on a highway. And I've always kind of presented her with that fact when she kind of

04:05.780 --> 04:12.900
says that I'm doing this New York driving thing. And I've more recently seen some research that

04:12.900 --> 04:18.820
talks about kind of applies the same idea to autonomous vehicles. Like a single or small number

04:18.820 --> 04:24.580
of autonomous vehicles can also dramatically improve traffic flow. Is that the kind of thing that

04:24.580 --> 04:29.940
you look at near research? Totally. And we must be cousins because I'm a Paris driver. So I think

04:29.940 --> 04:34.900
we share a lot of things in common here. But yeah, no, totally. So it's interesting. In fact,

04:34.900 --> 04:41.460
what you're saying is so true. I would say a single driver can affect traffic very positively

04:41.460 --> 04:46.340
and very negatively. And obviously with self-driving features that are coming on board vehicles,

04:46.340 --> 04:51.060
we're trying to really steer the system towards the better. But we'll have been in a case where

04:51.620 --> 04:55.380
someone does something really strange and it creates some breakdown. It creates a shock wave.

04:55.380 --> 04:59.220
It creates some congestion. It creates some strange phenomenon on the freeway that we did not

04:59.220 --> 05:05.700
anticipate. That happens every day. What we're trying to do here is, in fact, the opposite, which is

05:05.700 --> 05:12.660
trying to understand how the level of automation that is progressively entering the vehicles

05:12.660 --> 05:19.140
could be used to essentially improve things. Whether it's aggressive or not, it's almost a

05:19.140 --> 05:25.140
technicality. But it's more to do something that a human might not necessarily think to do,

05:25.140 --> 05:31.700
but that is actually proven to improve things. And I think the most counter-intuitive things nowadays

05:31.700 --> 05:36.260
in self-driving vehicles is that slowing down in some circumstances might actually improve

05:36.260 --> 05:42.820
traffic flow. Now, it's something that people in 2018 might have a difficult time to conceive.

05:42.820 --> 05:47.620
But it's not that different that maybe 50 years ago when someone came up, or maybe 80 years ago,

05:47.620 --> 05:52.660
when someone came up with a traffic light which had a red as a color and that meant you have to stop,

05:52.660 --> 05:56.740
maybe people didn't realize right away. Well, actually, that will make traffic better because

05:56.740 --> 06:02.020
traffic lights are better than stop signs or unmanaged intersections. What's exactly the same

06:02.020 --> 06:08.500
with self-driving vehicles? It's just not in our culture yet. It's not even in our DNA yet.

06:08.500 --> 06:13.620
But the very same thing we've done with ramped metering or coordinated traffic light signals

06:13.620 --> 06:19.700
in cities in New York, obviously, is one of them. That can also be applied at the level of cars

06:19.700 --> 06:24.340
on the freeways. In fact, it's something that is known and has been known by truckers for a while

06:24.340 --> 06:30.740
because truckers are known to be flow pacifiers. They all maintain a given speed. They usually go on

06:30.740 --> 06:35.860
the same lane. That lane really doesn't have many breakdowns. It's a very smooth lane. So it's

06:35.860 --> 06:41.140
something which has been known in some quote subcommunities of motorists, if you will, over the years.

06:42.580 --> 06:47.300
But that's something that with the self-driving features we see coming into cars is going to become

06:47.300 --> 06:53.700
a reality of our future driving life and have really great potential to make things much better.

06:54.580 --> 07:00.980
That's what we're doing. We're trying to understand how AI can help solve that problem and how can

07:00.980 --> 07:05.860
AI provide solutions which are really innovative in the way we look at that problem?

07:06.500 --> 07:10.820
It makes me think a little bit about the concept of swarming behaviors.

07:10.820 --> 07:22.580
In particular, the idea that you can have these individual agents that have a set of behaviors

07:22.580 --> 07:30.740
that they are program or train or whatever to do. But when you put them in a system together,

07:30.740 --> 07:36.100
they can work towards some kind of broader goal. It's like the self-driving car that you're

07:36.100 --> 07:42.580
describing. It's not just trying to get its passenger from point A to point B, but it's also

07:44.260 --> 07:48.020
well, I mean, that's part of the question. Is it also trying explicitly to

07:49.540 --> 07:55.700
help manage the traffic or is that just a property or an emergent property or something that

07:55.700 --> 08:03.380
happens? That's such a beautiful analogy. Actually, metaphorical and actual. First because swarming

08:03.380 --> 08:11.300
is meant among birds, for example, to reduce drag. The reason why birds swarm is they can fly

08:11.300 --> 08:18.180
much longer. Information is almost like formation flight and reduce the drag. It's not even a metaphor.

08:18.180 --> 08:23.940
It's real. Trucks do platoon to reduce drag. That's beautiful analogy of something real.

08:23.940 --> 08:29.540
But it's also metaphorical. That's really what I like about what you just said. Swarming,

08:29.540 --> 08:35.140
in a sense, attempts among the species that do that to optimize some cost function that might

08:35.140 --> 08:40.020
not be necessarily revealed. It's not that a fish or bird has a cost function that they can compute,

08:40.020 --> 08:46.020
because obviously, even it's implicitly there, it's not explicitly stated in the way they act

08:46.020 --> 08:51.620
to it. But at the end of the day, the swarming achieves a higher objective amongst the swarms.

08:51.620 --> 09:00.180
That's what the self-driving vehicle approach we're following is attempting to do. In swarming,

09:00.180 --> 09:05.300
there's leaders, there's followers. You can view the self-driving analogy in the same way.

09:05.300 --> 09:10.820
If you have, say, 5-10% of vehicles acting in a very specific way to improve the flow,

09:10.820 --> 09:15.140
you could view them as leaders in a kind of a leader following game in a game theoretic sense of

09:15.140 --> 09:21.300
the term. Then the manned vehicles who have to react to this by maybe being surprised,

09:21.300 --> 09:24.980
but if people are driving slower in front of you, you can't pass them, so you'll have to drive

09:24.980 --> 09:32.100
slow as well, or followers in that type of two-team games. The swarming analogy is actually a very

09:32.100 --> 09:38.100
good analogy in that process as that. With a small number of self-driving vehicles, we could

09:38.100 --> 09:44.020
induce the whole population to behave collectively better because of that steering that is done by

09:44.020 --> 09:48.580
these few agents that are able to work with this higher degree of intelligence in the traffic flow.

09:48.580 --> 09:56.260
So, coming back to your presentation at the conference, can you give us an overview of the

09:57.060 --> 10:02.260
general aim and flow of the presentation? Yeah, what we're trying to convey in the

10:02.980 --> 10:08.100
presentation is that AI is going to drive us through a few successive revolutions that are

10:08.100 --> 10:13.540
going to deeply impact the way mixed up to many traffic is studied and eventually how it happens.

10:13.540 --> 10:20.020
The first revolution is models are potentially going away, and what that means is that if you think

10:20.020 --> 10:25.300
about the history of engineering, in engineering, in every subfield whether you work in fluid mechanics,

10:25.300 --> 10:29.940
in structural engineering, and mechanical engineering, or whatever it is, you usually start with an

10:29.940 --> 10:34.740
equation, the model of water, with Navier Stokes' equation, the model of a car, the model of thermodynamics,

10:34.740 --> 10:40.020
whatever it is. There's been hundreds of years of people modeling these things so that you can

10:40.020 --> 10:44.820
inherit the equation and you use the equation to control it, to optimize it, to make things better.

10:45.540 --> 10:50.660
But it turns out that with deeper and first point learning, if you can inherit a simulator

10:51.220 --> 10:57.620
that was built, you know, by experts, you don't need to have actual knowledge of the equation

10:57.620 --> 11:04.260
to improve things. So, in other words, this notion of model-free learning, where you can actually

11:04.260 --> 11:10.740
improve a scoring function without having actually visibility on what the model does, but just

11:10.740 --> 11:16.660
on seeing its output is something that is going to deeply change traffic engineering. And that's

11:16.660 --> 11:20.500
mostly because if you think about the phenomena of traffic, you know, changing lane,

11:20.500 --> 11:26.260
decelerating, routing, deciding to go or not go, stop, accelerate, all these things,

11:26.820 --> 11:31.220
these are very, they're not necessarily complicated to model, but there's a lot of different

11:31.220 --> 11:35.300
actions a human can take. So, if you can get rid of all that modeling and all those

11:35.300 --> 11:40.260
bullion variables corresponding to these decision factors and just learn over simulation,

11:41.140 --> 11:46.660
that's going to make things much easier. And that's what we showed in the talk is that, you know,

11:46.660 --> 11:52.020
simple cases where humans have spent decades to research on how to control, with deeper and

11:52.020 --> 11:56.820
first point learning, we could redo within a few months and we could actually beat. And that's

11:56.820 --> 12:02.420
the beginning of this first revolution where by simulation and by deeper and first point learning

12:02.420 --> 12:08.260
over high fidelity simulators, it will become possible to solve a lot of problems that are

12:08.260 --> 12:13.460
currently unsolved with AI. And the list is long, I mean, the list could include coordination

12:13.460 --> 12:19.140
of traffic light much better than currently done, insertion of self-driving vehicles inside traffic,

12:19.140 --> 12:24.740
control of traffic by self-driving vehicles, automated intersections, and so on and so forth.

12:24.740 --> 12:29.540
So, that's the first revolution I try to explain in the talk saying that, you know,

12:29.540 --> 12:35.060
there's a whole legacy of work that maybe will become obsolete or maybe will just be used for

12:35.060 --> 12:40.340
other things, but there's this new body of work that is progressively emerging where we can beat

12:40.340 --> 12:45.940
the past and do things which are way more innovative. And then beyond that, there's a second

12:45.940 --> 12:51.780
revolution that is maybe a bit further away, which is, well, what if in addition to just forgetting

12:51.780 --> 12:56.740
about the models we could learn from pictures? And that's something that a lot of people have done.

12:56.740 --> 13:01.060
I mean, obviously supervised learning has done a lot of phase recognition and object recognition

13:01.060 --> 13:07.060
and so on and so forth. Well, we're not that far from being able to do the same for traffic management

13:07.060 --> 13:13.700
and traffic control. What if after watching enough videos of traffic, whether these are videos

13:13.700 --> 13:17.860
rendered because they're part of a simulation that produces things or whether they are actual

13:17.860 --> 13:22.980
videos, you know, video cameras deployed in the street or dash car or cams or stuff like that.

13:24.260 --> 13:30.980
Over time, we should be able to learn how to manage streams of vehicles from that data

13:30.980 --> 13:35.700
and potentially from these simulations. And that is likely to be the second revolution we see in

13:35.700 --> 13:41.540
traffic control and traffic management over time. And that revolution is likely to have a much

13:41.540 --> 13:48.100
bigger set of consequences because with the liquidity of cameras and connectivity, we're not that far

13:48.100 --> 13:52.740
from the world where, you know, every vehicle will have cameras and multiple cameras, probably.

13:53.700 --> 13:58.580
And that could help the management of traffic at the scale of cities in ways that have never even

13:58.580 --> 14:04.020
been possible or conceivable before. That's what's going to happen over the next five to ten years.

14:04.020 --> 14:08.900
And it's just the beginning, but that's going to accelerate drastically with the rapid pace of

14:08.900 --> 14:16.660
technology here. So with regard to the first of the two revolutions that you outlined, I think

14:17.700 --> 14:23.460
long-term listeners of the show probably kind of know the direction that I'm going ahead in

14:23.460 --> 14:30.820
and the question that I'm going to ask. And it relates to this notion of model-free.

14:31.620 --> 14:38.420
In particular, it seems to be, I guess in a lot of ways, like a very Berkeley-oriented idea.

14:38.420 --> 14:43.620
And I guess I'm rarely extrapolating from maybe very few conversations.

14:43.620 --> 14:47.300
You know, one of the conversations that I had very early on was with Peter Abiel,

14:47.300 --> 14:51.700
who, you know, believes very strongly in this idea of kind of model-free approaches and

14:51.700 --> 15:00.500
reinforcement learning-based approaches. And since then, I kind of test that idea with a lot

15:00.500 --> 15:07.620
of people. And the kind of conclusion that I've come to is that, A, this is a major kind of theme

15:07.620 --> 15:15.540
and where we are in the AI community. And it seems like for many, like we had this

15:16.500 --> 15:21.620
model-oriented view of the world as you described. It goes back many, many years.

15:22.500 --> 15:29.700
And then we've been more recently very excited about deep learning and deep reinforcement

15:29.700 --> 15:32.980
learning and other approaches and have kind of thrown away the models.

15:32.980 --> 15:40.500
You know, I guess ultimately what it comes down to is overcome the, you know, some of the,

15:40.500 --> 15:45.460
you know, I guess basically just get the best of both worlds, right? Overcome the computational

15:45.460 --> 15:51.700
challenges of deep learning, deep reinforcement learning, and take advantage of the many years of

15:51.700 --> 15:57.380
models. And I'm just curious now that I've got another opportunity to talk to someone at Berkeley

15:57.380 --> 16:04.340
having kind of put all of this together, you know, what your take is. Right. Well, first go bears

16:04.340 --> 16:11.780
and thank you for mentioning Berkeley. Couldn't resist doing this one. So it's very interesting

16:11.780 --> 16:17.780
what you're saying because first, maybe the first point that is important to mention is

16:18.740 --> 16:24.340
model-free works for certain things might not work as well for some other things. And for example,

16:24.340 --> 16:28.260
you think about safety critical systems for many years. I used to work in traffic management.

16:29.220 --> 16:34.100
If you think about autopilot certification, about a lot of medical devices, which are, you know,

16:34.100 --> 16:39.860
safety critical, well, maybe people need to think twice about, you know, forgetting about the model

16:40.580 --> 16:45.220
because there's real laws of physics involved and there's real certification issues there.

16:45.220 --> 16:51.220
And so we have embraced this model-free approach for what we do just because we have evidence that

16:51.220 --> 16:58.340
in many of the known cases, it already beats half a century or more of work of the modeling community.

16:59.140 --> 17:05.060
And we want to really point out that we use it for a very specific purpose. We are not in the

17:05.060 --> 17:11.860
business of doing autopilot collision avoidance, anti-crash systems, safety systems for cars.

17:12.420 --> 17:17.460
These systems have a lot of different degrees of certification requirements

17:17.460 --> 17:24.020
that come with a lot of constraints. It's unclear whether what we do would apply there and it's

17:24.020 --> 17:29.940
really not our job. Our job is to be able to come up with new methods that can coordinate hundreds

17:29.940 --> 17:35.700
of thousands of vehicles or maybe more local scales, maybe dozens of vehicles or hundreds of vehicles.

17:36.340 --> 17:40.580
And you could really view this as a planning tool. A planning tool in a sense in the old

17:40.580 --> 17:45.220
sense of the term is like you were planning train schedules or airline schedules. And if you're off

17:45.220 --> 17:50.900
by three minutes and you manage it properly on the ground, it's not a big deal. If your train is

17:50.900 --> 17:56.100
laid by 30 minutes, as long as you have the right away and you have the space on the railway, no problem.

17:57.060 --> 18:04.180
So here that's the same idea. It's like probably in 99% of the cases what we come up with will provide

18:04.180 --> 18:09.460
substantially better solutions than the state of the art. And maybe in 1% it will do something

18:09.460 --> 18:14.820
really strange. And because it's not safety critical, well, that's not a big deal. I mean,

18:14.820 --> 18:18.980
what will happen as well? Maybe there will be three cars stuck on the freeway for five minutes

18:18.980 --> 18:24.580
in a very strange way and we didn't understand why. But nobody died. It's a planning problem.

18:24.580 --> 18:28.980
And so I think the point is that, you know, there's this ongoing debate that you really mentioned

18:28.980 --> 18:34.580
about model base versus non-model based. Obviously both approaches have their sweet spots.

18:34.580 --> 18:42.900
I think the model free approaches like we're using now clearly have demonstrated a very

18:42.900 --> 18:48.820
disruptive nature in the industry in which we are and in the world in which we live for coordination

18:48.820 --> 18:55.060
of multiple vehicles. But you know, if you're doing precision chemistry or physics, we probably

18:55.060 --> 18:59.860
need a pretty good model of what you're doing because it's material science, because it's laws

18:59.860 --> 19:05.380
of physics. And there it's maybe the story is different. The second part of what you mentioned

19:05.380 --> 19:10.660
is also very interesting is like, well, you know, how can we live in a place where we take the best

19:10.660 --> 19:15.620
of both worlds? And I really think about the fact that, you know, we're not going to throw all the

19:15.620 --> 19:21.380
models and everything we've been doing for half a century in the trash right away. These can be

19:21.380 --> 19:26.660
used to accelerate machine learning in many ways. And so if you think about warm start,

19:26.660 --> 19:31.220
if you think about transfer learning where you learn on some specific setting and apply to

19:31.220 --> 19:37.060
a different setting, if you think about reward shaping and many different, you know, sub-approaches

19:37.060 --> 19:43.060
of making deeper enforcement learning more efficient, that's I think where model based can help.

19:43.940 --> 19:49.380
There's no reason to just get a deeper enforcement learning algorithm searching in the wild when

19:49.380 --> 19:55.220
you already have the good baseline that can be inherited from the past. So in a sense, you can view

19:55.220 --> 20:01.380
this as a way to accelerate the convergence of the algorithm. And that's exactly the sweet spot in

20:01.380 --> 20:08.980
which you want, in fact, AI to augment what the human could not finish. And so maybe, you know,

20:08.980 --> 20:13.300
half a century of research in coordination of traffic lights and coordination of vehicles

20:13.300 --> 20:20.100
and platooning and automated intersections made us come that far. And that's where it's platoon,

20:20.100 --> 20:26.020
that's where it's as I'm told it in a sense. And maybe the next stage is what AI brings us to.

20:26.020 --> 20:31.620
And so that's where I think the two can coexist quite nicely. And that's part of what we're doing

20:31.620 --> 20:36.100
as well as like there's no reason to start from scratch. We could start from what the human has come

20:36.100 --> 20:43.620
up with and let machine learning do the rest. I like that nuance in the context of reinforcement

20:43.620 --> 20:52.260
learning. The idea that, you know, maybe, you know, it's not worth trying to bolt these, you know,

20:52.260 --> 20:58.660
the model together with the learner inherently. But, you know, we can use it in these supporting

20:59.460 --> 21:07.860
functions like cold start, warm start, or, you know, giving hints of some sort, as well as the model

21:07.860 --> 21:14.180
may play a role in whatever the simulation environment is and the way that it presents the real

21:14.180 --> 21:21.300
world to the learning agent. Exactly. And so the second revolution that you described,

21:22.260 --> 21:27.780
you didn't say this explicitly, but I was hearing the theme of imitation learning,

21:27.780 --> 21:33.540
is that kind of the direction you're heading or something else? Well, more specifically,

21:33.540 --> 21:37.700
we're really interested in end-to-end pixel learning. What's the distinction between those two?

21:37.700 --> 21:42.740
Well, it's hard to make a general statement, but the one thing I could say is that in the context

21:42.740 --> 21:53.060
of traffic, what would be a holy grail to M4 is a system in which by looking at pictures,

21:53.060 --> 22:00.900
videos rendering, whatever it is, you can provide the same level of efficiency as by having access

22:00.900 --> 22:06.340
to the state space. I mean, so the previous part of the conversation, essentially, we still,

22:06.340 --> 22:10.900
we maybe got rid of some of the models or all of the models, but we kept the state space. We have

22:10.900 --> 22:18.340
access to vehicle velocity, position, and all the parameters. These almost disappear in an image.

22:18.340 --> 22:24.100
So if you think about a movie of traffic that either was shot from a video or from the rendering

22:24.100 --> 22:31.060
of a simulation software, that video, you could say implicitly contains these parameters because

22:31.060 --> 22:35.620
technically you could re-infer the speed, you could re-infer the position, but the point is

22:35.620 --> 22:40.420
they've been blended in the rendering. Or if this was a video shot from a video camera,

22:40.420 --> 22:45.220
well, you never had access to them in the first place. And so this end-to-end pixel learning

22:45.220 --> 22:53.700
to us is very important because it would almost enable us to extend or build on the very famous

22:53.700 --> 22:59.460
work we've seen all over the social media recently about, you know, Q learning applications for

22:59.460 --> 23:05.460
playing video games. I mean, the Atari games, the pong, and they were probably the first successes.

23:05.460 --> 23:10.820
And now we see there's a lot of progress with Mario and, you know, more and more elaborate video games.

23:11.460 --> 23:17.860
And so obviously, pong and Atari and all these, it's the early ages of video gaming. It's

23:17.860 --> 23:25.860
still pretty simple games, but if you think about traffic, traffic is not, you know, it's not the

23:25.860 --> 23:30.660
state of the art video gaming with a lot of levels of sophistication, decision, 3D rendering,

23:30.660 --> 23:35.300
and all kinds of strategic decisions. It's something which is clearly more complex than an Atari

23:35.300 --> 23:41.860
video game, but it's not something which is on a different scale either. And so that's where

23:41.860 --> 23:49.460
we see the most interesting next revolution is demonstrating that just by working directly on

23:49.460 --> 23:53.780
rendering of traffic, we could achieve the same performance as having access to the state space

23:53.780 --> 23:59.220
because then I will provide proof that, well, maybe you don't need that ubiquitous connectivity

23:59.220 --> 24:04.020
anymore. All you need is an image. And then if you push this even further,

24:05.460 --> 24:09.700
onboard all the self-driving vehicles or vehicles with high level of automation, there's obviously

24:09.700 --> 24:15.940
a lot of sensing and part of that sensing is video-based. And then there's this segmentation problem,

24:15.940 --> 24:20.260
trying to understand how to isolate pedestrians from cars, directions of movement and everything.

24:21.060 --> 24:26.340
That is a field that is moving super fast. That in a sense, we don't want to touch, but we would

24:26.340 --> 24:32.500
love to, at some point, acquire the outputs of once there is software out there or enough data

24:32.500 --> 24:38.100
out there so that we can recuperate all these segmented images and treat them as inputs for what

24:38.100 --> 24:44.260
we do. Because then we have closed the loop. Essentially, we have first demonstrated, we don't

24:44.260 --> 24:48.660
need the old models. Second demonstrated, we don't even need the state space, we can just work with

24:48.660 --> 24:55.620
the image of the state space. And third, finally, linked that with the physical hardware sensing of

24:55.620 --> 25:00.580
the world, which produces these images in a way that these images can be treated in real time.

25:00.580 --> 25:05.300
And that's why I was saying a few minutes ago that it's going to take probably five to ten years

25:05.300 --> 25:10.260
because there's these two revolutions I mentioned before, but that third bridge with the rest of

25:10.260 --> 25:15.460
the community that is doing machine vision, I mean, that's that field is far from being solved.

25:15.460 --> 25:22.580
I mean, there's super rapid progress, but there's still a lot of work to be done for it to become

25:22.580 --> 25:29.300
operational, to run online, to run onboard the platforms, to be fast enough that it can be integrated

25:29.300 --> 25:33.540
in a real-time traffic management system. So there's all these steps, which each of them are

25:33.540 --> 25:38.980
pre-challenging there. But I think what's really nice is to have this overarching vision of where

25:38.980 --> 25:46.500
that whole system will go within the next five to ten years. So you mentioned earlier that the models

25:46.500 --> 25:52.260
that you're building are not intended to be these core control systems that are controlling the

25:52.260 --> 26:02.260
vehicles, collision avoidance, and I took it to be a fundamental mobility. I guess I'm trying to

26:02.260 --> 26:07.540
get at, I also get the impression that you're not talking about kind of an offline, you know,

26:07.540 --> 26:14.660
traffic system that is, you know, looking at these vehicles and providing some analysis and

26:14.660 --> 26:20.500
telling some other system what to do. Like, you're trying to integrate this into an online system.

26:21.060 --> 26:26.820
What are the relationships between these two systems and how does that interface work?

26:26.820 --> 26:32.580
Yeah, absolutely. So maybe the first part of the question, the reason why we don't do collision

26:32.580 --> 26:40.100
avoidance is it's really not our job. But also, if you think about the process of control of vehicles,

26:40.100 --> 26:44.260
I mean, there is what's called the low-level controller acceleration, acceleration, automated

26:44.260 --> 26:48.260
braking, co-operative, adaptive cruise control, and all these tools that are, some of them have

26:48.260 --> 26:53.140
been part of our life for more than ten years. Some of them are just coming now. A lot of it is

26:53.140 --> 26:58.820
really based on very classical control theory, PID control, lead lag, I mean, you know, stuff that

26:58.820 --> 27:03.460
came from the sixties that works well, and there's no reason to change it. Of course, the most

27:03.460 --> 27:08.660
the more recent work of collision avoidance and, you know, trajectory planning at super short-term

27:08.660 --> 27:14.500
horizons to make sure that trajectories are safe. Okay, that requires a little bit more sophistication,

27:14.500 --> 27:21.540
both in terms of the sensing and the learning. But that's really, that's really an area for which

27:21.540 --> 27:28.340
the tools you need are very specific. You need very fast controllers. You need super fast sensing

27:28.340 --> 27:34.100
loops that can provide almost immediate detection of anti-positioning of collisions and things like

27:34.100 --> 27:39.060
this. So the tools for that are very different. The architecture is probably also very different

27:39.060 --> 27:43.380
because you need something to run onboard on the specific chip to be certified and so on and so

27:43.380 --> 27:53.380
forth. So that's why, in a sense, we assume that we are, that that job has been taken care of. There's

27:53.380 --> 27:59.060
the auto manufacturer, there's the autopilot manufacturer, whoever is in charge here. And our job

27:59.060 --> 28:03.700
is more of the coordination. So the analogy would be, you know, if you're running an airline

28:05.140 --> 28:11.220
and you're doing the scheduling of an airline, you don't really care about the speed of landing

28:11.220 --> 28:17.780
of an aircraft because that's going to be taken care by the mechanical crew. And there's essentially

28:17.780 --> 28:22.980
a controller for that. But if you're planning the whole airline, all you want is landing

28:24.020 --> 28:26.500
a window of two minutes the rest. That's not your problem.

28:27.540 --> 28:34.340
Right. I guess so maybe the question that I was getting at more directly was is the system that

28:34.340 --> 28:41.700
you're looking at and trying to build analogous to kind of planning, you know, at the level of the

28:41.700 --> 28:48.580
airline, like a centralized planning system that knows about all the planes and is trying to do

28:48.580 --> 28:54.020
kind of high order scheduling or is it something that is, you know, the back to this distributed

28:54.020 --> 28:59.220
and swarming thing that we talked about at the level of the vehicle that is kind of feeding into

28:59.220 --> 29:04.740
the first person navigation, but, you know, is kind of aware of these broader impacts.

29:05.380 --> 29:09.780
Yeah. So now the question you're asking is a really deep question and it's a question about

29:09.780 --> 29:14.020
what will the future of our transportation system look like and that answer will be very

29:14.020 --> 29:19.460
different on the place depending on the place and the, I would say, involvement that cities will

29:19.460 --> 29:26.580
get. So imagine a world in which maybe 5% of the vehicles are automated. You know, it doesn't

29:26.580 --> 29:33.220
mean that the government, the city or the company that built the vehicles can decide unilaterally

29:33.220 --> 29:38.580
to connect all of these, which is just pushing some code and have them do some traffic flow

29:38.580 --> 29:43.460
regulation, which is pushing another piece of code and turning it on. Obviously, there needs to be

29:43.460 --> 29:50.100
partnerships. The city needs to agree that on these 10 miles of freeways, every connected car

29:50.100 --> 29:56.180
from brand ABC will automatically turn a flow pacifier algorithm that smooths its traffic.

29:56.180 --> 30:00.500
And then every participant will have to at some point agree when maybe they buy the car or they

30:00.500 --> 30:04.580
turn on the car, you know, like when you're downloading an app on your iPhone or your Android,

30:04.580 --> 30:09.380
you click yes, yes, yes, yes, yes. In the same way when you buy the car, you might agree that at

30:09.380 --> 30:13.780
some point you might release the autonomy of the car to higher authority, which will do things,

30:13.780 --> 30:20.340
where things is smoothing traffic. So I think in the situation in which you have 5% of

30:20.340 --> 30:26.180
willing to participate vehicles and vehicle owners, the, you know, the institutional framework in

30:26.180 --> 30:31.300
which you built an online controller, real-time controller like this, that leverages all these

30:31.300 --> 30:36.180
vehicles. That's still a big institutional question mark. Is that going to be run by the state,

30:36.180 --> 30:41.300
is that going to be run by the city, by the local MPO, or by the car company, or by a third party

30:41.300 --> 30:46.900
that is almost like a global scheduler, like the FAA or Euro-controlled for air traffic.

30:46.900 --> 30:51.860
And, you know, if you push this to the extreme and you look at places in the Middle East,

30:51.860 --> 30:57.940
like a Neum city, they're building in the north of the kingdom of Saudi Arabia or Dubai or Abu Dhabi

30:57.940 --> 31:02.740
and places which are very forward looking in the way they think about their urbanization,

31:02.740 --> 31:06.500
because they're building cities from scratch or they're building at a rate which supersedes

31:06.500 --> 31:12.500
anything we've seen before. Then you could envision networks which have a sub portion that is

31:12.500 --> 31:18.340
fully automated, like a place where you could not go if you don't have a vehicle of a certain level

31:18.340 --> 31:23.620
of automation, say four or five, and within that district, there's only five pre-proved models.

31:24.180 --> 31:29.460
And once you enter the district, not only does it take over your routing, but it takes over

31:29.460 --> 31:32.900
everything, like, you know, you punch a destination, you'll figure out the route, you'll figure out

31:32.900 --> 31:37.780
the speed and you'll figure out how to coordinate you with the other vehicles. So that paradigm,

31:37.780 --> 31:42.820
where you have automation on steroids and, you know, every vehicle is automated, that's actually

31:42.820 --> 31:49.220
much more in reach than mixed autonomy. And that's because having vehicles avoid pedestrians,

31:49.220 --> 31:54.580
bikes, scooters, cows or whatever animal is running on the street, that's hard. That's something

31:54.580 --> 32:00.340
which is not easy to certify and to do. But having a city or a guided community or district

32:00.340 --> 32:05.940
or boulevard or whatever it is, where all the vehicles are automated and they have a specific

32:05.940 --> 32:10.180
push of the software, that's something we could do tomorrow. The technology is there, there's

32:10.180 --> 32:14.420
car manufacturing companies there that have enough level of automation to enforce that.

32:15.460 --> 32:20.260
And that's, you know, something where an online system, like I would just been discussing

32:20.260 --> 32:25.460
for the last few minutes, is going to change mobility entirely. I mean, the notion that, you know,

32:25.460 --> 32:30.820
you enter the center city, you push the destination and the rest is taken care of,

32:30.820 --> 32:36.500
that's what happens essentially to a certain extent with airlines. I mean, obviously there's

32:36.500 --> 32:43.700
ways to fly, file flight plans, there's ways you fly, but you file a flight plan and then the FA

32:43.700 --> 32:48.660
will maybe give you an amended flight plan. And if there's weather to have a, again, amended

32:48.660 --> 32:54.740
flight plan, that paradigm essentially will work in a self-driving district. And that's in reach.

32:54.740 --> 32:59.300
And so you can see walking from 5% where we're now to 100%.

32:59.300 --> 33:03.860
But there'll be different paradigms. And there'll be places which are very forward looking and

33:03.860 --> 33:08.580
we'll allow that. There'll be places where they will allow flow pacifiers. And there'll be places

33:08.580 --> 33:12.980
where they won't. And so the answer to the question really will depend on the city,

33:14.020 --> 33:18.820
not just the technology readiness, but also the willingness to embrace these new paradigms.

33:19.620 --> 33:25.620
So kind of within these, these, you know, two plus one, revolutions that you've talked about,

33:25.620 --> 33:33.460
what are some of the key research challenges and which in particular are the ones that you and

33:33.460 --> 33:43.460
your group are digging into? So there's every problem is hard. That's why it's exciting to be

33:43.460 --> 33:48.100
in this field right now. And let me just list a few, you know, which will be my top five of the

33:48.100 --> 33:53.700
moment. And if we talk again in a week, maybe there'll be different. So, you know, the first thing is

33:53.700 --> 34:00.900
this notion of multi agent learning. It's one thing to learn a global policy and to say every

34:00.900 --> 34:06.980
car of a given brand, you know, it's going to deploy the same policy. But the truth is it doesn't

34:06.980 --> 34:12.180
work this way. There's different types of cars. There's different types of ways people want to

34:12.180 --> 34:17.380
use their cars. So the notion that we can do learning multi agent learning where some are

34:17.380 --> 34:21.620
cooperative, some are not cooperative, that's inherently hard. And people who've been in game

34:21.620 --> 34:27.860
theory and non-cooperative games know this. There's all kinds of notions of sub-optimality,

34:27.860 --> 34:34.260
Nash equilibrium, price of unarchy, prisoners, many things like this. Well, these don't go away

34:34.260 --> 34:40.260
with machine learning because the uncooperative nature of the agents just make it hard. So that's one

34:40.260 --> 34:47.380
thing. It kind of drags me right back to, you know, this point about model free. Like, I'd love to

34:47.380 --> 34:54.740
be able to give the agent the hint that, hey, there are these, you know, 10 things that we know

34:54.740 --> 35:02.820
from game theory that may play out here. And so if you, you know, if you see one of these, you can

35:02.820 --> 35:09.540
kind of get a shortcut to learning. Exactly. And that's exactly the way we want to use game theory.

35:09.540 --> 35:17.860
By, for example, one example would be how you steer to more cooperativeness between the agents

35:17.860 --> 35:26.340
and how thereby, you know, more optimality and choose from that behavior. Another really

35:27.620 --> 35:34.980
problematic part of this work is that it needs to scale up the simulations. They're still

35:34.980 --> 35:39.940
quite expensive. I mean, if you're going to simulate the I 210 freeway in Los Angeles, you know,

35:39.940 --> 35:46.100
it's a five lane freeway to directions. Freeway lane carries 2000 vehicles an hour. So essentially,

35:46.100 --> 35:51.060
if you're just standing on the bridge in the middle, you've watched 10,000 vehicles go by in one hour.

35:51.060 --> 35:58.020
And now that freeway extends for dozens of kilometers. So creating a simulator that is able to do

35:58.020 --> 36:04.580
this efficiently and being able to learn over that simulator efficiently is very hard. So if you're

36:04.580 --> 36:09.540
running simulations with, say, a hundred thousand vehicles and you're trying to learn over it,

36:09.540 --> 36:13.620
you probably don't need to re-simulate the hundred thousand vehicles. You're probably going to

36:13.620 --> 36:18.900
learn over 1000 vehicles or hybrid vehicles that are actually key to what's happening there.

36:19.540 --> 36:26.100
But the process of it's people call this learning how to learn. So it's like there's this thing in

36:26.100 --> 36:30.340
supervised learning where, you know, which images should you train on or what is the training data

36:30.340 --> 36:35.220
you should select to train. That's a completely open problem in traffic. It's like, is there a

36:35.220 --> 36:41.140
process by which you could determine how should you learn to learn more efficiently given that

36:41.140 --> 36:47.140
probably 95% of what you're simulating there is useless. And that's a whole area of

36:48.900 --> 36:52.980
meta-learning, active learning, curriculum learning, all of these types of things.

36:52.980 --> 36:56.660
And we've not even scratched the surface there. Like when I say we is like our group,

36:56.660 --> 37:00.980
that's not, I mean, we're not there yet. Just because we have so many other problems,

37:00.980 --> 37:08.180
we need to solve first. But clearly, once people start to do optimization of traffic and mobility

37:08.180 --> 37:13.700
at the scale of a city, that's going to be one of the big elephants in the room if we want to

37:13.700 --> 37:21.860
achieve scalability ultimately. And so that's another really big one. The third one is this end-to-end

37:21.860 --> 37:27.460
pixel learning right now seems in reach. But I think we've again just scratched the surface. I mean,

37:27.460 --> 37:32.740
you know, we've done some moderately difficult cases. Just like people with video games,

37:32.740 --> 37:37.940
they've done pong, they've done Mario, they've probably done a few others. So, you know, how do we

37:37.940 --> 37:42.900
make it work for real? How do we make it work for something which has, you know, hundreds of thousands

37:42.900 --> 37:51.300
of vehicles? So that's another big challenge that make it hard. So I think what's exciting is that

37:51.300 --> 37:57.300
the rate at which innovations happen in AI is so high that there are a lot of tools that appear

37:58.660 --> 38:04.020
quite often that, you know, weren't not really obvious before, like this pixel learning just

38:04.020 --> 38:10.180
had major breakthroughs. And so I think there's a hope that over the next couple of years we'll see

38:10.180 --> 38:14.980
things come from fields we didn't even think would be relevant that actually matter for what we do.

38:16.020 --> 38:21.220
And so we're far from being done, but things are moving so rapidly that I think the progress

38:21.220 --> 38:28.900
rate is quite quite amazing. I feel like we could have spent, you know, entire hours and podcasts

38:28.900 --> 38:35.140
on any of these topics. And so we've just kind of scratched the surface here. Any

38:35.940 --> 38:41.220
suggestions or pointers or words of wisdom for folks that are intrigued by this and want to

38:41.220 --> 38:46.820
dig in deeper? Well, I think from a technical standpoint, we've covered a lot of ground, but I

38:46.820 --> 38:51.940
think the maybe higher level point of wisdom that I would really like to convey is that this

38:51.940 --> 38:58.980
paradigm really can only work if we have cooperation between very different animals. And these

38:58.980 --> 39:04.100
animals include obviously academia or tech or research wherever that happens, whether it's in

39:04.100 --> 39:09.540
the private sector or the public sector, that's us. It involves the car manufacturing industry

39:09.540 --> 39:16.660
because at the end, someone has to push a new release of the autopilot software to make it work

39:16.660 --> 39:21.940
in the field. And to make it work in the field means on the freeway, not in a content test facility

39:21.940 --> 39:28.500
like for real. And the third animal is the government, whether it's federal regulations, whether

39:28.500 --> 39:35.540
state regulation, MPO, city ordinance, wherever it is, there needs to be buy-in so that first it's

39:35.540 --> 39:40.660
actually agreeable to the city to operate this way. There's mobility on demand and cars are

39:40.660 --> 39:46.820
cooperative for 10 miles where the city takes over the automation or something. So it's hard,

39:46.820 --> 39:50.740
because you have academics like us that are pushing new paradigms. You have the private sector,

39:50.740 --> 39:55.380
which has its own constraint. Obviously, they have to go through certification. It's got to be

39:55.380 --> 40:00.580
aligned with their market strategy. Any of the government, which essentially has to regulate

40:00.580 --> 40:05.860
and make sure that we don't kill people and that things are fair and equitable. So the word of

40:05.860 --> 40:11.540
wisdom is that we need to create a community so that these three types of animals start talking

40:11.540 --> 40:17.380
about these things. AI is changing cities, is changing a lot of different urban problems.

40:17.380 --> 40:24.260
And mostly in good ways. We've seen some cases of TNCs and mobility test demand companies,

40:24.260 --> 40:30.500
right-hailing companies or Airbnb styles of this world, how it can be complicated for a city to

40:30.500 --> 40:37.540
regulate over these new technologies and services. And the same is true for this mixed autonomy.

40:37.540 --> 40:42.740
And that's why it's very important to get that conversation started early so that all protagonists

40:42.740 --> 40:49.060
are ready for the time when it becomes a technological reality. And is this conversation happening

40:49.060 --> 40:59.220
today in some centralized place or is it just this highly local set of conversations that are

40:59.220 --> 41:06.180
happening? How can folks plug into whatever or wherever is the best place to kind of tap into

41:06.180 --> 41:11.940
this conversation now? Yes, this is a super interesting question because there is no institutional

41:12.500 --> 41:17.300
place or way to have these conversations. I think what's very encouraging is that you see a lot

41:17.300 --> 41:21.380
of forums where these conversations happen, the transportation research board in Washington every

41:21.380 --> 41:28.820
year. The IEEE intelligent transportation systems conference every year from the IEEE some

41:28.820 --> 41:38.660
specific state driven programs like the Institute of Transportation Studies forums and workshop

41:38.660 --> 41:44.820
in California, ITS America and the ITS World Congress and so on and so forth. But the truth is these

41:44.820 --> 41:51.140
conversations are still I would say boutique sessions in these venues or special sessions in

41:51.140 --> 41:58.260
these conferences. But there's not been a forum, like a worldwide forum on how are we going to

41:58.260 --> 42:04.820
bring this to reality. And I think it will probably emerge. I think we all have a responsibility

42:04.820 --> 42:11.780
to do this. The difficulty is that the AI community is fascinated with research and technological

42:11.780 --> 42:17.220
advances and that's what we should be doing. And obviously public agencies have to deal with

42:17.220 --> 42:21.780
public infrastructure and policy and that's what they've been elected for or that's what they've

42:21.780 --> 42:27.700
been hired for. And the private sector is driven by their products. And so obviously there is

42:27.700 --> 42:32.260
common ground and there's common interest, but these are three orthogonal directions in a 3D

42:32.260 --> 42:39.300
vector space. And so it's hard to institutionalize this until there is a real need for it. And

42:39.300 --> 42:45.140
anticipation is maybe sometimes not the forte of these three actors that are working on different

42:45.140 --> 42:53.140
time scales. It does sound like a massively complex game theory problem. Totally is with three

42:53.140 --> 42:59.460
players that want to be cooperative. Well, Alex, thanks so much for taking the time to chat with us

42:59.460 --> 43:05.860
about this. It's a super interesting conversation and I look forward to kind of keeping tabs on the

43:05.860 --> 43:10.100
field as it evolves. Thank you so much. It was really fun conversation. Really, I appreciate

43:10.100 --> 43:18.420
the time this morning. Thank you. Thank you. All right, everyone. That's our show for today.

43:18.420 --> 43:26.180
For more information about today's show, visit twomelai.com. Thanks so much for listening and see you

43:26.180 --> 43:36.180
next week at Twomelcon.

