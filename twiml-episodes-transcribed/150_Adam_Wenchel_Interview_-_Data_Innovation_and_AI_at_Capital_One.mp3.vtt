WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:31.520
I'm your host Sam Charrington.

00:31.520 --> 00:36.600
In this episode I'm joined by Adam Wenzhel, Vice President of AI and Data Innovation at

00:36.600 --> 00:41.960
Capital One to discuss how machine learning and AI are being integrated into their day-to-day

00:41.960 --> 00:46.560
practices and how those advances benefit the customer.

00:46.560 --> 00:51.640
In our conversation we look into a few of the many applications of AI at the bank, including

00:51.640 --> 00:59.480
fraud detection, fighting money laundering, customer service, and automating back office processes.

00:59.480 --> 01:03.720
Adam describes some of the challenges of applying machine learning and financial services

01:03.720 --> 01:09.880
and how Capital One maintains consistent portfolio management practices across the organization.

01:09.880 --> 01:13.920
We also discuss how the bank is organized to scale their machine learning efforts and

01:13.920 --> 01:18.600
the steps they've taken to overcome the talent shortage in the industry.

01:18.600 --> 01:23.240
A big thanks to our friends at Capital One for their sponsorship of this show.

01:23.240 --> 01:27.480
As you hear in this conversation with Adam, Capital One is hosting their second annual

01:27.480 --> 01:31.760
Data Intelligence Conference, which will bring together machine learning practitioners

01:31.760 --> 01:36.160
and researchers for several days of presentations and talks.

01:36.160 --> 01:38.600
The conference will take place later on this summer.

01:38.600 --> 01:42.000
I'm really looking forward to it, so I'll keep you posted.

01:42.000 --> 01:47.200
A quick thanks to everyone who joined us for the first session of our Twomo Fast AI Study

01:47.200 --> 01:49.000
Group this past weekend.

01:49.000 --> 01:53.520
We had a great discussion, and I'm excited to get the group rolling.

01:53.520 --> 01:58.000
This first session was just an orientation, so there's still time to join in if you missed

01:58.000 --> 01:59.000
it.

01:59.000 --> 02:03.360
Keep an eye out for the recap video going up this week via the Slack group.

02:03.360 --> 02:07.600
You'll find more information at twomola.com slash fastai.

02:07.600 --> 02:14.520
Finally, our next Twomo online meetup is taking place next week on Tuesday, June 12th.

02:14.520 --> 02:19.720
Kelvin Ross will be presenting the paper cardiologist-level arrhythmia detection with convolutional

02:19.720 --> 02:24.760
neural networks, which is worked by researchers in Andrew Eng's lab at Stanford.

02:24.760 --> 02:29.000
For more information, visit twomola.com slash meetup.

02:29.000 --> 02:32.040
Alright, let's do it.

02:32.040 --> 02:34.360
Alright, everyone.

02:34.360 --> 02:39.920
I am on the line with Adam Wenzhel. Adam is vice president of AI and data innovation

02:39.920 --> 02:41.680
at Capital One.

02:41.680 --> 02:44.560
Adam, welcome to this weekend machine learning and AI.

02:44.560 --> 02:45.560
Thank you, Sam.

02:45.560 --> 02:47.040
I appreciate you having me on.

02:47.040 --> 02:48.040
Absolutely.

02:48.040 --> 02:51.680
Why don't we get started by having you tell us a little bit about your background and

02:51.680 --> 02:54.480
how you got involved in AI?

02:54.480 --> 02:55.480
Absolutely.

02:55.480 --> 03:00.560
I studied computer sciences and undergrad at the University of Maryland and took the only

03:00.560 --> 03:04.640
two AI courses that were available at the time, which is actually still the case fit at

03:04.640 --> 03:07.400
many undergraduate curriculums.

03:07.400 --> 03:10.480
When I graduated in the late 90s, I actually went to work.

03:10.480 --> 03:14.040
One of my professors had gone to DARPA to start a new program there, and so I was able

03:14.040 --> 03:18.680
to, you know, I immediately went to DARPA and was working in AI research there for the

03:18.680 --> 03:24.120
first couple years of my career, so I have been involved in this field for quite a while.

03:24.120 --> 03:28.280
It's funny to look around now and see all the, you know, how many jobs there are in this

03:28.280 --> 03:33.280
industry at the time, it felt like a very small community and was seen as somewhat quixotic

03:33.280 --> 03:34.280
at the time.

03:34.280 --> 03:41.760
So, this current, you know, massive surge in interest has been fascinating to watch.

03:41.760 --> 03:47.680
And from there, I went into a series of startups after working in DARPA for a couple years,

03:47.680 --> 03:52.520
some of which involved a little bit of AI, but a lot of more were straight, you know,

03:52.520 --> 03:54.000
web application startups.

03:54.000 --> 03:59.760
And then about five or six years ago, maybe a few more than that, I started, you know,

03:59.760 --> 04:05.880
with the kind of confluence of these really enabling technologies like GPU and big data

04:05.880 --> 04:11.120
and cloud computing that have kind of led to the recent resurgence of machine learning

04:11.120 --> 04:16.160
and coming together, you know, really started to get back into it in a big way, in particular

04:16.160 --> 04:22.200
in the cyber security domain, which is really ripe for machine learning.

04:22.200 --> 04:27.880
And so for the last six or so years, I've been really focused on machine learning.

04:27.880 --> 04:32.360
And then joined Capital One about two and a half years ago, initially to lead up a big

04:32.360 --> 04:37.680
project they had to create a new data platform and, you know, machine learning, suite of machine

04:37.680 --> 04:40.000
learning analytics for cyber security.

04:40.000 --> 04:44.800
And that has since kind of, my scope here is kind of expanded now, I help with machine

04:44.800 --> 04:47.040
learning implementations all across the company.

04:47.040 --> 04:52.880
Oh, fantastic. Well, maybe we can, we can have you give us a lay of the land and overview

04:52.880 --> 04:57.360
of the different ways ML and AI are being used at Capital One.

04:57.360 --> 05:02.560
Absolutely. So in financial, there's really kind of no end to, to the way machine learning

05:02.560 --> 05:06.480
can be deployed. There's a, there are a lot of possible use cases, huh?

05:06.480 --> 05:11.560
Absolutely. I mean, it's just a fundamentally quantitative field. And so everything from,

05:11.560 --> 05:16.160
you know, the way we fight fraud and there's many different flavors of fraud to financial

05:16.160 --> 05:22.320
crimes, like money laundering to, you know, to the way we service our customers, you know,

05:22.320 --> 05:26.240
making sure that they have the best experience as possible and he can get answers to the questions

05:26.240 --> 05:31.600
they need as quickly as possible, whether they're talking to a human or a bot or on their

05:31.600 --> 05:36.720
mobile app or the web app, we use it all over the place as well as for, you know, a lot

05:36.720 --> 05:41.640
of our internal back office processes, which for any large scale company, you know, bringing

05:41.640 --> 05:43.800
automation to that can create huge efficiencies.

05:43.800 --> 05:49.920
What would you say is an example of one of the more innovative projects that you're working

05:49.920 --> 05:50.920
on there?

05:50.920 --> 05:56.880
I think a lot of the way we're taking on fraud, both transaction fraud as well as account

05:56.880 --> 06:01.960
takeover fraud and, you know, identities after are really innovative. Similarly, that's

06:01.960 --> 06:07.840
the work we're doing and money laundering has really begun to bear some fruits recently.

06:07.840 --> 06:12.160
Can you walk us through one of those examples? You know, I'm curious about, you know, some

06:12.160 --> 06:17.760
of the data sources that come into play, you know, what you're, you know, the way you

06:17.760 --> 06:24.520
approach modeling there and, you know, there is related to those topics that might help

06:24.520 --> 06:29.200
us understand the way you go about applying ML and AI in your environment.

06:29.200 --> 06:34.200
Yeah, absolutely. So one of the ones that we like to talk about is an application we have

06:34.200 --> 06:39.640
called Second Look. And Second Look is for something that helps our customers out very

06:39.640 --> 06:44.600
directly. And it's, you know, I know that I'm sure all the listeners to your, to your

06:44.600 --> 06:50.160
podcast have are very dutiful about checking their, their credit card bill, you know,

06:50.160 --> 06:54.440
every day and making sure that all the transactions look correctly. But for those of us who are

06:54.440 --> 06:59.160
perhaps a little bit less diligent about it, you know, what we've done is we've actually

06:59.160 --> 07:03.840
trained a machine learning system to go and spot transactions that, you know, that, that

07:03.840 --> 07:07.120
we should highlight to our attention because everyone's busy. And so, you know, you don't

07:07.120 --> 07:10.920
always have time to review your bill. And so it's good to know that, that someone's kind

07:10.920 --> 07:15.600
of checking it for you, if you will. And so that can be things like spotting, say, a

07:15.600 --> 07:21.200
suspiciously high tip on a restaurant bill or getting double charge for the same service

07:21.200 --> 07:26.600
or product or just having sort of a recurring payment that, that one month, all of a sudden

07:26.600 --> 07:31.160
significantly higher than usual. Though there's a number of reasons why, you know, things

07:31.160 --> 07:36.440
that, that you might want to kind of be notified about on your credit card statement. And,

07:36.440 --> 07:41.160
you know, obviously there's a real, there's a real kind of a, um, precision that's needed

07:41.160 --> 07:46.360
because if you go lower down too many things, then it just becomes a frustrating user experience.

07:46.360 --> 07:50.760
But we also want to make sure that, um, that stuff doesn't slip through the cracks either.

07:50.760 --> 07:54.320
And so we put quite a lot of work and it's, it's really one of the, um, the kind of

07:54.320 --> 07:58.080
innovative ways that we're improving our customer experience. And it's funny. Like when

07:58.080 --> 08:01.000
I go, when I meet people at, you know, a party or something and tell my work at Capital

08:01.000 --> 08:04.920
One, by far and away, this is the, the thing that, you know, people mentioned the most

08:04.920 --> 08:08.960
consistently is, you know, how much they love this feature and how, and, and they always

08:08.960 --> 08:13.200
have a story about some, you know, some charge at cost that they wouldn't have caught otherwise.

08:13.200 --> 08:16.600
That was incorrect. They've been able to straighten out. So I think that's a great example of

08:16.600 --> 08:20.960
the way machine learning is, is, um, bringing some transformation into the financial services

08:20.960 --> 08:21.960
industry.

08:21.960 --> 08:28.720
Oh, that sounds like a feature I'd like to have. I imagine that the, the training data for

08:28.720 --> 08:35.880
something like this comes from the traditional customer reported issues. Yeah. So we do have,

08:35.880 --> 08:41.680
you know, there's a number of ways we look at it. Um, you know, we do have sort of a, um,

08:41.680 --> 08:46.440
a customer feedback loop in there where they can kind of tag stuff as being problematic

08:46.440 --> 08:50.920
or if alert, you know, not being problematic. I think with those kind of, um, those kind

08:50.920 --> 08:55.640
of systems that, that where you have kind of human generated tagging, um, they are, they

08:55.640 --> 09:00.440
are one source of ground truth. They're not the, the, you don't over rely on that kind

09:00.440 --> 09:05.080
of stuff, but it can be very helpful. I think there's also a lot of work from our, uh,

09:05.080 --> 09:10.240
our data scientists looking at, uh, things like, you know, using sort of, um, unsupervised

09:10.240 --> 09:14.560
learning and anomaly, uh, detection kind of approaches to kind of, uh, tease out some

09:14.560 --> 09:18.520
of the patterns and the data and, and, and that's another way that, um, through things

09:18.520 --> 09:23.720
like, uh, you know, label propagation, we can, we can, um, uh, begin to, you know, really

09:23.720 --> 09:29.240
hone in on the transactions that, that we want to alert off of. Oh, interesting. Uh, and

09:29.240 --> 09:34.560
you mentioned that you came in to, uh, capital one with a focused on cyber security.

09:34.560 --> 09:39.680
I imagine that that's a big deployment area as well. It is. Yeah. There's a, you know,

09:39.680 --> 09:44.800
that with, with cyber security, you just have such massive, um, amounts of data and even

09:44.800 --> 09:50.000
with a large team of analysts who staff are, um, cyber security operations center, uh,

09:50.000 --> 09:54.520
they're really constrained to only be able to look at a really small amount of the number

09:54.520 --> 09:58.960
of events that we have on our, our network and our computers every day. And so, you

09:58.960 --> 10:03.320
know, machine learning really gives, uh, a great opportunity to number one, cut through

10:03.320 --> 10:09.080
all that noise and really kind of surface the events that are, um, most that, that, that

10:09.080 --> 10:13.160
we really want to have the analyst focus on that may be suspicious that, you know, or

10:13.160 --> 10:16.120
maybe they're completely benign, but we need to have someone to check into and then we

10:16.120 --> 10:20.520
kind of get smarter, uh, along the process. And so that can be anything from a piece of

10:20.520 --> 10:24.960
malware on a computer to some sort of, uh, attempted data exfiltration. There's, there's

10:24.960 --> 10:29.880
a lot of, um, a lot of different attack vectors, malicious emails, whether that's phishing

10:29.880 --> 10:33.880
or spearfishing or extortion attempts or, you know, there's just quite a lot of, uh, threats

10:33.880 --> 10:40.800
that, that any large company faces and particularly one that, um, uh, manages a great deal of money.

10:40.800 --> 10:46.120
And a situation like cyber security where, you know, capital one certainly is far from alone

10:46.120 --> 10:52.400
and having to worry about these kinds of concerns. Do you find that, uh, your primary vector

10:52.400 --> 10:58.560
for kind of inserting machine learning into solving some of these problems is via off

10:58.560 --> 11:03.840
the shelf software, meaning your vendors kind of built, uh, ML and AI into their products

11:03.840 --> 11:08.800
or you kind of out in front of it with your own data scientist building kind of custom

11:08.800 --> 11:15.360
systems to help you stay, uh, ahead of, uh, your cyber adversaries.

11:15.360 --> 11:20.960
Yeah, it's a, it's a very good question. I think for us, we do buy a lot of kind of

11:20.960 --> 11:26.120
best-to-breed, um, cyber security products and I think it would be, um, uh, you know, it's

11:26.120 --> 11:29.760
certainly advantageous. It's really important to take advantage of, of kind of the rich

11:29.760 --> 11:35.480
product ecosphere that's out there. Um, there are, you know, when, when you kind of deploy

11:35.480 --> 11:39.520
a lot of these solutions, um, there are still opportunities that present themselves that

11:39.520 --> 11:44.720
are either, you know, unique to the, to the, to the, to capital one or just, um, that

11:44.720 --> 11:50.240
are created by the way that the, the product marketplace landscape, um, lines up to, uh,

11:50.240 --> 11:55.200
to, um, kind of even strengthen things beyond that. And that's, we, we focus on those opportunities.

11:55.200 --> 11:59.280
Are there any examples in that domain you can give us at least at the high level?

11:59.280 --> 12:03.960
Um, sure. One of the ones that we've, we've talked about, uh, at a couple conferences

12:03.960 --> 12:09.880
recently is on detecting malware callouts and a, and, um, specifically malware callouts

12:09.880 --> 12:15.640
that use, uh, DGA, DGA's domain generating algorithms. Um, we've done some pretty innovative

12:15.640 --> 12:21.760
work there that we've presented on a conferences and, and, you know, um, we'll potentially, uh,

12:21.760 --> 12:25.440
be sharing in the future. But that's, uh, you know, it's, it's been a fun challenge

12:25.440 --> 12:29.880
where we've applied some of our really, um, uh, interesting machine learning approaches

12:29.880 --> 12:34.680
using convolutional neural networks and other features, um, to, to bring kind of a, uh, this,

12:34.680 --> 12:37.720
this, this problem has been around for a while. And it's kind of one that, uh, a number

12:37.720 --> 12:41.120
of AI researchers have taken on and, and, you know, we have a pretty novel approach which

12:41.120 --> 12:46.120
has been, um, working well for us. So what's, uh, what's a malware callout?

12:46.120 --> 12:50.800
So you can imagine if you're, you know, if, if I'm sure it would be you, but if one of

12:50.800 --> 12:54.840
your friends' computers got infected because they clicked on the wrong link or, you know,

12:54.840 --> 12:58.320
double clicked on the wrong attachment and their email, uh, and then had a piece of malware

12:58.320 --> 13:02.400
on their computer, it might, you know, once it, once your machine's infected, the next

13:02.400 --> 13:07.400
stage is for it to reach out to a server controlled by the attacker and say, hey, I managed to affect

13:07.400 --> 13:11.520
the, in fact, this computer, what was you like me to do? And that can be anything from

13:11.520 --> 13:17.160
lock their computer to we pay, to they pay us a, a, a ransom and cryptocurrency to, um,

13:17.160 --> 13:21.800
look, search the computer for, um, any files containing with a title financial disclosures

13:21.800 --> 13:26.140
or something like that. And, and, you know, uh, download those to the, to the most

13:26.140 --> 13:30.080
a server, I mean, there's a wide variety of things you can do once the computer's infected.

13:30.080 --> 13:34.680
A lot of times it's participation in a botnet where you're, um, maybe trying to, you know,

13:34.680 --> 13:39.440
hack into another, a system controlled by another company, um, through some sort of

13:39.440 --> 13:46.680
brute force method. And so when it makes that call out to the, to the server, it, um, uh,

13:46.680 --> 13:51.800
you know, we, we focus on kind of detecting at that point. Um, uh, that's one of the areas

13:51.800 --> 13:56.840
that we've explored. And there, those, the, um, the way that those callouts are made,

13:56.840 --> 14:02.760
the way that those servers are effectively domain names they use, um, some of the attackers

14:02.760 --> 14:08.320
have gotten come up with some really complex algorithms for, um, basing the host names

14:08.320 --> 14:13.480
on either some sort of time-based algorithm where, you know, maybe there's like 20,000

14:13.480 --> 14:19.920
different domain names per given day. And you can say at any given, at any given time,

14:19.920 --> 14:24.400
there could be one that you decided to register that your malware will call out to, which

14:24.400 --> 14:28.200
makes, you know, the traditional kind of blacklist, whitelist approaches to blocking

14:28.200 --> 14:33.880
malware callouts very difficult. Um, and, and so we've focused, you know, that's one

14:33.880 --> 14:38.680
of the categories of attacks that we've focused on. And you mentioned that part of the solution

14:38.680 --> 14:46.440
here is involves the use of convolutional neuralness. CNNs are typically used in, like, image

14:46.440 --> 14:51.880
recognition types of tasks. How have you applied them to, uh, the cyber security use case?

14:51.880 --> 14:57.040
Yes. So CNNs are famous, certainly, for a kind of computer vision task, but more recently,

14:57.040 --> 15:01.160
there's been quite a lot of work. I think a real kind of, um, you know, surge of interest

15:01.160 --> 15:06.560
in using them for more NLP-based tasks. And that's, that's, this, this, this, this kind

15:06.560 --> 15:11.960
of category of, of, um, problem that I'm describing fits into that NLP category.

15:11.960 --> 15:15.600
Can you elaborate on that a little bit more? Sure. So, you know, really what we're trying

15:15.600 --> 15:22.040
to do is distinguish between, uh, you know, a host name that, um, that maybe is, let's

15:22.040 --> 15:28.240
say, phonetically plausible, but not a real word, like Google, um, to one that, uh, is just

15:28.240 --> 15:33.960
a string of jumbled up letters. Um, that's, that's kind of the first, uh, step. And then,

15:33.960 --> 15:37.760
you know, some of the more recent attacks actually use, uh, our dictionary-based attacks,

15:37.760 --> 15:40.720
where they'll generate the domain name from real dictionary words, but just put them in

15:40.720 --> 15:46.440
odd combinations. So understanding, like, what's an odd combination and what's not as Facebook,

15:46.440 --> 15:51.440
an odd combination, or does that make sense? And it really kind of gets into, uh, a decent

15:51.440 --> 15:57.320
amount of kind of language understanding to, to really, um, uh, to, to create a model

15:57.320 --> 16:02.000
that can accurately distinguish between those types of, uh, domain names. Ah, it sounds

16:02.000 --> 16:07.360
a bit like, uh, the challenge at Google and others face keeping up with, with spammers

16:07.360 --> 16:13.320
as spammers learn how to use proper grammar. Very, very much, very much so it's, you know,

16:13.320 --> 16:17.000
it's continually, uh, whether it's spamming or cyber security, it's a constant cat

16:17.000 --> 16:22.560
and mouse game, right? So, uh, it's, it keeps it fun. I never gets boring. And so one of

16:22.560 --> 16:29.920
the challenges that the industry has been, you know, faced with is, uh, is the talent

16:29.920 --> 16:36.800
shortage. Um, how have you managed at, at the bank to address that? Yeah, it's a good

16:36.800 --> 16:41.600
question. There is, there is a massive talent shortage going on right now. And, you know,

16:41.600 --> 16:45.200
there's no, there's no silver bullets to that answer to that question, but, um, there's

16:45.200 --> 16:50.040
a number of ways we're addressing it. So obviously, we, we are hiring, you know, going

16:50.040 --> 16:55.400
aggressively after recruiting people who have, um, good amounts of experience in that

16:55.400 --> 17:00.320
field. They're not a lot of those people, but, but we're certainly, uh, you know, very,

17:00.320 --> 17:03.840
uh, you know, work very hard to make sure that we can attract as many as possible. We

17:03.840 --> 17:07.680
also have a program at Capital One called the TDP, the technology development professional

17:07.680 --> 17:13.640
where we go out to primarily the top 20 computer science departments in the nation and, uh,

17:13.640 --> 17:18.520
and recruit heavily from that. And once they're here, they work all over in a bunch of

17:18.520 --> 17:21.880
different technology areas, but the ones that come to the center for machine learning,

17:21.880 --> 17:26.320
um, we actually have a pretty rigorous, um, process around, you know, training them

17:26.320 --> 17:29.920
and getting them up to speed on machine learning. And so we're, we're kind of famous for

17:29.920 --> 17:35.080
being the group that, uh, gives homework. And, um, we do things like we have a weekly

17:35.080 --> 17:39.760
paper sessions where we'll, we'll review kind of academic papers and, and, and sort of

17:39.760 --> 17:43.440
discuss their merits. And, you know, I think that's one of the things that really distinguishes

17:43.440 --> 17:49.120
the machine learning from, uh, other kind of software engineering computer science disciplines

17:49.120 --> 17:54.440
is it, it still has a very academic bent to it. Um, so even though there's like massive

17:54.440 --> 17:59.040
applicability across a wide range of business problems, um, there's still kind of a culture

17:59.040 --> 18:03.400
of, you know, making sure that you're keeping up with the latest and academic literature.

18:03.400 --> 18:08.400
And the academic literature is, is, is produced, you know, by, uh, and, you know, probably,

18:08.400 --> 18:13.400
this is much by commercial teams as it is by academic teams. And so, uh, it really creates

18:13.400 --> 18:17.440
a unique culture. So that's, you know, making sure that you have, you're continuing to do

18:17.440 --> 18:21.800
ongoing training and that you're, you're able to take people into the, into the group

18:21.800 --> 18:25.880
and train additional machine learning talent. That way is, uh, immensely important to

18:25.880 --> 18:29.960
being able to meet the, the talent needs that we have. It sounds like you're going after

18:29.960 --> 18:36.720
the same students that, uh, Google and a Facebook might go after. Do you find that you're challenged

18:36.720 --> 18:42.920
to convince them to, uh, to join a bank as opposed to, you know, one of these more sexy kind

18:42.920 --> 18:48.280
of internet-borne social media type of plays? Yeah, it's a good question. We, we definitely

18:48.280 --> 18:53.080
do compete head with, with a lot of the tech companies, um, for, for talent. And, you

18:53.080 --> 18:58.160
know, and that is a challenge. It's, fortunately, um, getting easier is more and more people

18:58.160 --> 19:02.880
become aware of, of, you know, really what a tech company, Capital One has become. Um,

19:02.880 --> 19:07.400
but, you know, the, the way I look at it is, uh, I, I, Capital One, you know, I think that

19:07.400 --> 19:12.040
we've seen disruption happen via machine learning across a wide range of industries,

19:12.040 --> 19:16.800
right? Whether we're talking logistics with self-driving cars or healthcare or commerce.

19:16.800 --> 19:20.560
And I, and I really think that, um, financial services is, is, you know, you're beginning

19:20.560 --> 19:23.520
to see the, you're seeing the beginnings of a similar kind of disruption. And so I

19:23.520 --> 19:28.120
think there are a lot of people who are really excited about, uh, you know, not just taking

19:28.120 --> 19:31.760
on marketing and advertising, but actually being able to, to apply their machine learning

19:31.760 --> 19:35.440
skill to something really impactful, like, how do people manage their money and, and how

19:35.440 --> 19:38.960
can we empower people more for their, to take better control of their financial lives

19:38.960 --> 19:44.720
and really kind of set them up for lifelong financial success? Uh, you mentioned Capital

19:44.720 --> 19:48.920
One kind of becoming a, a more and more like a tech company. And I think we kind of throw

19:48.920 --> 19:52.920
around in the industry that, you know, all companies are going to need to look more and

19:52.920 --> 19:57.680
more like software companies over time, sooner rather than later. In fact, uh, but Capital

19:57.680 --> 20:02.960
One actually has a pretty long history at this. I remember, um, Capital One was featured

20:02.960 --> 20:09.640
in, and a book that I read many years ago, competing on analytics by, uh, Thomas Devon

20:09.640 --> 20:14.560
Port, I think is the name of the author, uh, but really talked about how the company

20:14.560 --> 20:22.240
was before machine learning became cool, like it is now, um, really applying predictive

20:22.240 --> 20:28.400
analytics and other things to, uh, to the way it, you know, made decisions to the way

20:28.400 --> 20:35.400
the company made decisions. So my question is, in the company, do you find that having

20:35.400 --> 20:42.720
that history is kind of predisposed the, your business counterparts to kind of understand

20:42.720 --> 20:49.640
and be ready and willing to work with, uh, machine learning and, and predictive and statistical

20:49.640 --> 20:55.760
kinds of approaches. And, and algorithms already still find yourself, you know, with many

20:55.760 --> 21:00.720
of the cultural challenges that some of your counterparts and, and companies that don't

21:00.720 --> 21:06.000
have that history might have. Yeah, it's a, it's a great question. And, uh, and I think

21:06.000 --> 21:10.360
that's really good context about Capital One. Um, it's something that I didn't fully appreciate

21:10.360 --> 21:14.520
when I first started talking to them about joining, but, but I've really come to appreciate

21:14.520 --> 21:20.600
now, um, which is that the, the DNA of the company is very much in that, um, data analytics

21:20.600 --> 21:25.680
space. And that's how they, you know, that was their whole initial kind of founding hypothesis.

21:25.680 --> 21:30.560
And, um, Capital One is still founder led. And so Rich Fairbank, who's the CEO who started

21:30.560 --> 21:34.480
the company with that conviction still runs the company with that conviction. And it really

21:34.480 --> 21:40.240
trickles down. I think where, um, you know, machine learning is obviously a pretty, uh, pretty

21:40.240 --> 21:44.600
different shift from kind of the, some of the traditional, uh, stats and quants that have

21:44.600 --> 21:49.000
been done, um, and a lot of companies for, for many years, and it requires sort of a slightly

21:49.000 --> 21:54.000
different way of thinking about problems. And so I think that, yes, there's a long, um,

21:54.000 --> 21:58.960
it's, it's squarely in the company's DNA to think about, um, uh, you know, to think

21:58.960 --> 22:03.520
in a data driven way and data driven insights are worth their weight in gold. Um, I think

22:03.520 --> 22:07.920
we have had to evolve like a lot of people, um, along, you know, more machine learning

22:07.920 --> 22:11.600
lines. And that's something that we're, that we're embracing. But the DNA of the company

22:11.600 --> 22:16.840
is, is definitely there. Um, and it's been amazing to watch how much the company has, has

22:16.840 --> 22:22.520
embraced that other specific aspects that you can point to or examples you can give

22:22.520 --> 22:28.760
as to the way that that, uh, cultural shift is manifesting at Capital One. What are the,

22:28.760 --> 22:34.640
the things that you're finding, uh, your business counterparts kind of needing to hear the

22:34.640 --> 22:40.120
most and how are you articulating helping them come to terms with those things? Yeah, I

22:40.120 --> 22:44.200
think they're, you know, there are a number of changes. And I think, you know, everyone's

22:44.200 --> 22:48.920
very, um, I think everyone's really excited and enthusiastic about it. And so there's been,

22:48.920 --> 22:52.840
you know, what I've seen, people have really taken it upon themselves to kind of go out

22:52.840 --> 22:57.720
and educate themselves on, um, what machine learning can, can accomplish and, you know,

22:57.720 --> 23:02.840
separating the hype from their reality. I think, uh, one example is the, of, of kind of

23:02.840 --> 23:07.880
the evolution that's needed is, um, you know, traditionally, I think in a lot of large

23:07.880 --> 23:13.560
companies, uh, data science and, and software and systems engineering were sort of distinct

23:13.560 --> 23:20.720
activities. And a lot of the, the really disruptive, um, machine learning, uh, systems that

23:20.720 --> 23:25.520
you're seeing being built at, you know, in any industry are really kind of, uh, being

23:25.520 --> 23:30.400
produced when you have that software engineering, data engineering and, um, the, the kind of

23:30.400 --> 23:37.280
data science all working together as one, um, whole. Um, so if you talk about like a reinforcement

23:37.280 --> 23:41.680
learning system or, you know, any, any sort of interactive system machine learning system,

23:41.680 --> 23:46.720
you know, it's, it's critical that, uh, it's, it's not just a standalone model, but, but

23:46.720 --> 23:51.760
it's part of a system. And so I think that's been, um, a big, uh, you know, it's been kind

23:51.760 --> 23:57.040
of an evolution for us to, to really make sure we're building teams and, and setting up projects

23:57.040 --> 24:01.360
in that way, um, to take advantage. But that fundamental belief that, that data driven

24:01.360 --> 24:08.080
insights or, or, or data analytics can really, um, power great games is, is, is, has always

24:08.080 --> 24:15.040
been in the company's DNA. One of the big things that came out in, uh, an event that I recently

24:15.040 --> 24:23.600
held, uh, AI summit was that, you know, often companies, particularly large companies get caught

24:23.600 --> 24:32.720
up and comparing traditional software engineering with, uh, data science and, uh, data science driven

24:32.720 --> 24:38.240
efforts. And, uh, the particular area that was mentioned was just this notion of the, you know,

24:38.240 --> 24:44.800
the keyword and data science being science and it's a much more exploratory type of, uh, type of

24:44.800 --> 24:51.040
process and doesn't lend itself to, you know, agile, for example, uh, in the way that traditional

24:51.040 --> 24:55.280
software development does, is that, uh, is that your experience there as well? And how,

24:56.080 --> 25:00.960
how have you been kind of working to, you know, what are your methodologies there? And how have

25:00.960 --> 25:08.080
you been working to kind of fuse software engineering and, and, uh, data science and the other,

25:08.080 --> 25:13.040
you mentioned data engineering as well into a process that kind of works well for Capital One.

25:13.040 --> 25:18.800
Yeah, it's a good question. There's a couple, a couple big themes, um, wrapped up in that. The,

25:18.800 --> 25:23.920
the first one is you're talking about the science and data science and a lot of times it has been,

25:23.920 --> 25:29.120
essentially humans kind of experimenting with the data, uh, looking for, for insights, right,

25:29.120 --> 25:33.040
like trying to find, you know, in search of an insight and then finding that insight and then

25:33.040 --> 25:38.320
turning it into some sort of model that, that gets, um, uh, that can be, that can be put into

25:38.320 --> 25:43.840
production and make predictions. Um, the, uh, with machine learning systems, what we're really

25:43.840 --> 25:50.400
trying to do is create a system that sort of, uh, continually generates these insights in an

25:50.400 --> 25:56.000
automated way. And that's, you know, a pretty, pretty big shift from sort of a human looking for

25:56.000 --> 26:00.640
insights for themselves to generate building a system that can kind of, uh, continually look for

26:00.640 --> 26:04.800
insights and, and generate them. And so it does require a slightly different skill set in a slightly

26:04.800 --> 26:10.720
different way of, of thinking. Um, and then in terms of the methodology, you know, agile, uh,

26:10.720 --> 26:15.600
is great for software development. I think a lot of modeling is much less deterministic. Like,

26:15.600 --> 26:21.200
if you're trying to achieve a certain degree of accuracy on a model or efficacy on a model, um,

26:21.200 --> 26:26.320
it's really tough to, to predict and plan out, you know, how quickly you'll get there and,

26:26.320 --> 26:30.880
and what you, you know, you may have theories, but, um, it's just not that deterministic about

26:30.880 --> 26:35.280
when you're going to achieve the kind of results that you need to make a model really valuable.

26:35.280 --> 26:40.560
And so you, you know, the process, I think that, that people end up adopting is a little bit

26:40.560 --> 26:46.000
different than the traditional kind of agile methodology because, uh, you just, you have to take

26:46.000 --> 26:51.760
a really exploratory, um, approach to it because you're not sure, you know, what each step,

26:51.760 --> 26:56.000
you, whenever you take a step forward, it's going to, you're going to learn sort of on the fly,

26:56.000 --> 27:00.480
what the next avenues of exploration are going to be and you need to be prepared to react with that.

27:01.280 --> 27:08.320
Right, right. Uh, yeah, one of the, the interesting slides that came out of this session was that,

27:08.320 --> 27:14.720
you know, whereas you can kind of think of traditional engineering and, and agile as being more linear,

27:14.720 --> 27:18.960
right, we have these burn down charts and we're kind of creating linear value over time

27:19.600 --> 27:25.120
with, uh, machine learning is more of an S curve because of that exploration up front. And this is,

27:25.120 --> 27:31.360
uh, you know, kind of in mapping out ROI, that ROI takes longer to kind of get to and require

27:31.360 --> 27:39.440
some critical mass, but then when you do, you're, uh, able to, to, you know, get a significant ROI

27:39.440 --> 27:44.880
in your efforts relative to, again, traditional development. Do you see that kind of relationship

27:44.880 --> 27:50.960
between ROI and machine learning as well? I definitely agree that there's a lot of times a longer

27:50.960 --> 27:57.440
up front period of exploration. Um, we've seen uncertain projects and pretty dramatic ROI on these

27:57.440 --> 28:04.640
projects like, um, just because, uh, if you're, if you're coming into a system or, or, or a, uh,

28:04.640 --> 28:10.320
a business area that hasn't, you know, essentially right now with machine learning because

28:10.320 --> 28:14.960
it hasn't been applied broadly, there's a lot of kind of green field opportunities and

28:14.960 --> 28:19.040
kind of low hanging through. Yeah, a lot of low hanging fruit, um, but, but, you know,

28:19.040 --> 28:24.080
stuff that can be really impactful. And, and so, you know, some of the, some of the RF,

28:24.080 --> 28:29.760
the ROI on, on, on some of these initial like, on, on projects can be, can be pretty dramatic.

28:30.480 --> 28:34.480
I think that the, you know, the hard part is just scaling up the talent so that you, you can,

28:35.840 --> 28:40.720
you can, you can, uh, implement systems in all the, the opportunity areas that, that you have.

28:40.720 --> 28:46.240
And so given, uh, a constrained base of talent, how do you approach portfolio management across

28:46.240 --> 28:51.200
the business? Um, do you, uh, you know, I've talked to some folks that kind of take, you know,

28:51.200 --> 28:55.840
all their talent and apply it to, you know, their most pressing problems, kind of like a moonshot

28:55.840 --> 29:00.160
approach, you know, with the idea that, you know, if they solve or make a dent in that, they'll

29:00.160 --> 29:06.560
have a huge impact, you know, other folks, you know, go for kind of quick wins to help establish,

29:06.560 --> 29:10.320
you know, a machine learning way of thinking within organization. How do you balance that?

29:11.680 --> 29:15.520
Yeah, I think that's, you know, that, that's right on the mark for us. We started this center for

29:15.520 --> 29:19.120
machine learning about a year and a half ago. And I think when initially we were getting started,

29:19.120 --> 29:24.080
and we were sort of building some organizational muscle, um, we took on a fairly broad kind of

29:24.080 --> 29:29.040
organic set of projects that really allowed us to, um, help the business partners understand

29:29.040 --> 29:34.720
what machine learning could do and help us develop a little muscle around delivery. And, um, and,

29:34.720 --> 29:39.040
and that's what we got started. But, you know, once we've been doing that for a while, we sort of, uh,

29:39.040 --> 29:44.000
said, all right, we need to take a step back and actually sort of take a, a top-down assessment of

29:44.000 --> 29:49.680
the, of the, um, uh, of the enterprise and understand, like, where are the really high leverage

29:49.680 --> 29:54.640
opportunities for machine learning? And so that was, it's obviously, um, a conversation that we had

29:55.360 --> 30:00.800
with our business partners who have a lot more context around, you know, their business areas.

30:00.800 --> 30:05.840
And we really worked together to help understand and prioritize what those areas are. And we've

30:05.840 --> 30:10.720
devoted, you know, probably the lion's share of our resources against those really transformative

30:10.720 --> 30:16.560
opportunities. Um, that said, we still do hold back a team, uh, our internal consulting team

30:16.560 --> 30:22.000
that's available for sort of, like, the, the broader ones that may not be, um, the moonshots,

30:22.000 --> 30:26.560
but that, uh, but that are really important. Um, so we want to make sure we're servicing

30:26.560 --> 30:30.800
both. And we're, we have the right balance there between going after these really transformative

30:30.800 --> 30:36.480
opportunities, but also not ignoring, like, the, the hundreds of efficiency gains that collectively

30:36.480 --> 30:42.400
can be, uh, really add up to something pretty powerful. How are you organized around data science?

30:42.400 --> 30:46.160
It sounds like you've got a center. So there's some central centralization there. But what's the

30:46.160 --> 30:51.120
relationship between, uh, that center for machine learning and the various business units?

30:52.640 --> 30:57.440
Um, yeah. So, you know, it is, we have a center of excellence, but it's the machine learning

30:57.440 --> 31:02.400
expertise is, you know, across the company and the data science community is, is there's,

31:02.400 --> 31:05.920
you know, data sciences spread all across the company. So I don't, I certainly don't want to give

31:05.920 --> 31:10.960
the impression that it's all central, because that's, that's not the case. I think having,

31:10.960 --> 31:15.600
having the center of excellence has allowed us to have a, a small core of that, like,

31:15.600 --> 31:22.800
you know, really work closely together to sort of, um, help define best practices and really,

31:23.600 --> 31:27.040
you know, it's nice when you have a tight cluster of people because the amount of knowledge

31:27.040 --> 31:32.240
share and shared learnings, um, is, is tremendous. And it really kind of accelerates the, the growth

31:32.240 --> 31:38.080
uh, professionally of, of that group. Um, but, but we are, you know, we have people who rotate

31:38.080 --> 31:43.360
out from that center and go into the lines of business and, and help kind of see teams that way.

31:43.360 --> 31:48.720
And so there's a number of ways that we kind of manage that balance and, um, and so machine

31:48.720 --> 31:54.400
learning is really like our, all the, the business teams have embedded data science groups in them

31:54.400 --> 31:58.400
as well that are, that are really doing great things with machine learning. And, um, so the center

31:58.400 --> 32:02.480
of excellence is kind of one of the, one of the mechanisms we have towards building out

32:02.480 --> 32:10.480
machine learning systems, the capital one. So for an enterprise, you know, in, uh, financial services

32:10.480 --> 32:17.360
or elsewhere, um, that, you know, recognizes the importance of machine learning, you know,

32:17.360 --> 32:22.240
and is somewhere on the, the spectrum, but doesn't yet have a center of excellence of some sort.

32:22.240 --> 32:27.040
Is that something that you recommend? And, and if so, what, what do you think? Well, groundwork has

32:27.040 --> 32:34.720
to be in place before, uh, one can do that. Um, I, I do think it, uh, it's something I recommend.

32:34.720 --> 32:39.200
I think that it, one of the reasons why we've been able to attract a very high level, uh, you

32:39.200 --> 32:44.640
know, three of talent and a very, very competitive, um, talent segment is that working in the center

32:44.640 --> 32:49.280
of excellence is, is very, um, it's a very compelling opportunity for machine learning professional.

32:49.280 --> 32:55.760
And, and so, you know, from that perspective, I think it's been, uh, enormously helpful. Um, so I

32:55.760 --> 33:00.880
think that the, you know, as to what the groundwork you need to lay is, essentially, if you need

33:00.880 --> 33:05.680
to have a strong core of people and initial core, and because that's what's going to attract, you

33:05.680 --> 33:11.760
know, the, the additional talent. And, and so that's for us a big part of the reason why we initially

33:11.760 --> 33:16.800
created the center was to, to, to create that really kind of attractive place for, for talented

33:16.800 --> 33:22.320
machine learning professionals to come work at. When you look out across your industry,

33:22.320 --> 33:28.960
what unique challenges do you see to applying machine learning within the financial services

33:28.960 --> 33:33.760
context? I think the, the big challenges are just, you know, it's a heavily regulated environment,

33:33.760 --> 33:40.160
right? And so, um, it's one of the reasons we are focusing or, or investing heavily in areas like,

33:41.600 --> 33:49.600
explainability and fairness, um, because, you know, there's obviously many, many, uh, years of,

33:49.600 --> 33:55.280
of regulation and, and, um, working with the regulators to understand best practices for managing

33:55.280 --> 34:00.000
models and, and making sure that you're managing the risk and that's generated from those models

34:00.000 --> 34:06.000
appropriately. And so I think that's a, um, you know, it's, it's, it's a really kind of unique

34:06.000 --> 34:10.880
to financial services, um, practices around that and, and understanding how to navigate that.

34:10.880 --> 34:14.000
You know, it's tough. I think one of the reasons why I think we've seen less disruption from

34:14.000 --> 34:18.080
startups in the financial services industry is because of those type of challenges. And it really

34:18.080 --> 34:25.200
takes, you know, a, a larger bank that has the, the, um, all the teams and the personnel and the

34:25.200 --> 34:30.880
experience of having dealt with, uh, you know, those type of regulatory processes for many years to,

34:30.880 --> 34:36.720
to, uh, to be able to push more aggressively into, um, deploying machine learning in, in, in some

34:36.720 --> 34:43.520
of these, uh, heavily regulated areas. Uh, so on the one hand, financial services has had to deal

34:43.520 --> 34:50.000
with a lot of these issues before, but at the same time machine learning is, is changing things.

34:50.000 --> 34:54.960
What are some of the things that are changing in the way a bank would have to think about or deal

34:54.960 --> 34:59.760
with the issues that you've mentioned, you know, ethics, fairness, transparency, those kinds of things?

35:00.480 --> 35:04.960
Yeah. So I think that the, the, we could, we could talk for hours just about this subject, uh,

35:04.960 --> 35:09.680
uh, but I think, um, with, with a lot of these models, there's, they're effectively,

35:09.680 --> 35:13.440
you, there are more complex than, than the models that have been traditionally used and what that

35:13.440 --> 35:19.200
complexity becomes, comes additional power, but there also makes it, uh, a little bit harder to,

35:19.200 --> 35:25.440
to, uh, really kind of fully understand everything that the model is doing. And so having to invest in

35:25.440 --> 35:31.360
kind of automated ways of bringing that level of transparency, uh, it has been a big focus for us.

35:31.360 --> 35:36.080
And so, you know, I think that that's, um, that's a pretty big shift and then working with the

35:36.080 --> 35:41.280
regulators to make sure that these new ways of kind of understanding the models are, um,

35:41.280 --> 35:45.920
sufficient and, and kind of meet the, you know, meet, meet the, the spirit of the regulation. And

35:45.920 --> 35:49.360
it's not just working with the regulators, we're also working with kind of academic partners and

35:49.360 --> 35:55.360
others to, to really, um, understand collectively as a group, like what the best way is to bring

35:55.360 --> 35:59.920
that same level of understanding that, that we've had from traditional quantitative models to,

35:59.920 --> 36:03.760
to machine learning. And that's, you know, it's very much a work in the progress, in progress,

36:03.760 --> 36:08.800
but it's also a process that we're, um, we're very committed to and, and, and putting quite a lot

36:08.800 --> 36:14.880
of effort into. You mentioned in their automation, can you talk about some of the ways that you've

36:14.880 --> 36:20.000
approached automation around explainability? Um, sure. Well, some, I think a lot of it is there,

36:20.000 --> 36:24.880
there's a number of, um, papers that have been written and, and we've done our own internal work

36:24.880 --> 36:31.200
around, um, you know, if you have this extremely complex model, how do you get it to kind of explain

36:31.200 --> 36:36.320
its actions when it makes a prediction and why it made the prediction? And so having some sort of

36:36.320 --> 36:41.200
automatic system that can, you know, it's not something you, these, obviously, these models are so

36:41.200 --> 36:45.440
complex, you're not going to manually trace through it and understand the, the decision logic.

36:45.920 --> 36:50.880
But this, uh, you know, but there are, there are sort of a growing set of techniques for,

36:50.880 --> 36:56.160
for dealing with this in a, in a automated way that, you know, the systems will actually generate

36:56.160 --> 37:03.440
explanations for you that do a pretty good job of talking about the major, um, uh, reasons why

37:03.440 --> 37:10.080
a particular prediction was made. So are these techniques like, uh, you, like the line paper or

37:10.080 --> 37:15.760
like fitting more transparent, more explainable models to more opaque models, or did you have some

37:15.760 --> 37:20.320
other, uh, things in mind? Those are certainly two big areas. You have the line paper was, is,

37:20.320 --> 37:25.360
is a very seminal one. And, uh, probably the best known in this field. And I think that, um,

37:25.360 --> 37:28.880
there's a, there's just a tremendous amount of interest in this topic. And so there's,

37:28.880 --> 37:33.360
there's a lot more work, uh, the newer work that's coming out as well on this topic. And,

37:33.360 --> 37:39.120
and so I think it's, uh, um, it's an exciting area to, to be in, and, um, uh, you know, I've been

37:39.120 --> 37:44.320
at a couple major ML conferences recently. And this has been a huge topic for, for people at them.

37:44.320 --> 37:50.080
And, uh, um, so I, so I'm really excited by what I see in terms of, uh, the progress that's being

37:50.080 --> 37:56.080
made in, in getting to a point where we do have that good, you know, a good degree of explainability

37:56.080 --> 38:02.640
from these really complex models. What's kind of the, the, the lay of the line in terms of, um,

38:02.640 --> 38:08.880
the, the spectrum of model complexity that you're using there, like, is it, um,

38:10.720 --> 38:14.320
I, I guess I'm pausing because I, yeah, I'm guessing that I know the answer that, you know,

38:14.320 --> 38:18.640
it's like a 80 percent, you know, relatively simple things. And then you've got some more complex

38:18.640 --> 38:24.400
stuff, but like how, I guess maybe the question is more, you mentioned using CNNs, like how much

38:24.400 --> 38:29.760
are you using CNNs? How much are you using deep learning? And, and you mentioned reinforcement

38:29.760 --> 38:33.920
learning. Like, do you have reinforcement learning based apps and production? I'd like to get a

38:33.920 --> 38:40.640
sense for the range of complexity of the things you're doing. Yeah. So, you know, a lot of the stuff

38:40.640 --> 38:46.080
we're doing is, so for starters, you know, anytime you have a system where you're bringing

38:46.080 --> 38:50.560
machine learning to it for the first time, a lot of times you can get a big benefit just comes

38:50.560 --> 38:56.480
from kind of the basic data engineering. And, and, and, you know, and kind of getting the system

38:56.480 --> 39:01.360
straightened out and, uh, and even applying a relatively simple, uh, non deep learning type

39:01.360 --> 39:06.640
model to it can, can, you know, gives you massive gains. Right. There's, you know, that's another

39:06.640 --> 39:11.600
reason for the pause, right? There's nothing wrong with like taking the simplest approach and

39:11.600 --> 39:14.800
spreading it far and wide, right? You can get a lot of benefit in doing that.

39:14.800 --> 39:19.280
Yes. And, and, and, you know, those simpler models are really good about like telling

39:19.280 --> 39:22.400
you feature importance and things like that. And so, that's really good when you're in your initial

39:22.400 --> 39:27.840
stages to make sure there's not like some weird quirk in the data that's causing some,

39:27.840 --> 39:33.040
some results in the lab that will never be reproducible in production data. And there's a number

39:33.040 --> 39:37.920
of reasons to start simple. But, all that said, like, we know that, you know, deep learning,

39:37.920 --> 39:42.320
like CNNs is, is really like, there's, there's, there's certainly, there's a reason there's a

39:42.320 --> 39:46.960
lot of excitement around that type of stuff. And, and, and then techniques like reinforcement

39:46.960 --> 39:51.200
learning, you know, where you, where you really kind of give the systems a little more autonomy

39:51.200 --> 39:56.960
to explore the, the space are just fascinating. Um, when you can kind of, when, when you have a

39:56.960 --> 40:02.720
problem that's appropriate for it. And so we, we are doing a lot of research or a lot of work on,

40:02.720 --> 40:08.080
you know, deep learning based models, CNNs for computer vision, NNLP type applications and,

40:08.080 --> 40:13.920
you know, LSTMs for a lot of, like, time series based type prediction and things like that. And

40:13.920 --> 40:18.880
so there's, there's, you know, there's a lot of excitement about what those techniques can do.

40:18.880 --> 40:23.840
I think that, as I mentioned, the center is relatively new. So a lot of those uses are,

40:24.480 --> 40:29.360
not yet in production, but, but certainly, you know, driving in that direction. And,

40:30.320 --> 40:32.960
you know, excited to see what that yields over the next couple of years.

40:32.960 --> 40:39.040
I'm curious. Are there any applications of how far have you gotten with reinforcement learning?

40:39.040 --> 40:43.680
Have you identified some potential applications within Capital One?

40:43.680 --> 40:48.800
Yeah. So, you know, I'm not going to go too much into specifics, but we, there are a couple that

40:48.800 --> 40:52.960
were, that were eyeing. You know, it's not right for every, every situation. And one of the things

40:52.960 --> 41:00.880
about the financial world is for many of the problems, the, you know, you may not know whether a

41:00.880 --> 41:06.480
prediction was successful for three or four years, right? And so doing reinforcement learning

41:06.480 --> 41:13.520
with, when your feedback cycle is that long is creates its own set of challenges. And so,

41:13.520 --> 41:17.200
you know, it's something that we're, that we definitely focus on, because we do think it's

41:17.200 --> 41:21.360
a really powerful technique. But, you know, you need to, you need to make sure you have the right

41:21.360 --> 41:23.840
problem to focus it on and, and, and are doing it in the right way.

41:23.840 --> 41:32.000
I imagine that, uh, the bank has come across that kind of issue. These attribution problems

41:32.560 --> 41:37.440
in, in lots of different areas, trying to attribute, you know, the success of marketing campaigns

41:37.440 --> 41:44.320
and other things. Do you, all right? So, what degree do you, uh, have you identified or you,

41:44.320 --> 41:49.760
do you think that, you know, a path forward is in bringing some of the techniques that you've

41:49.760 --> 41:55.600
learned in that traditional space and applying it to RL, or is that more the domain of research

41:55.600 --> 42:00.560
and your way to, like, gets figured out? Uh, you know, what's interesting is, as you mentioned

42:00.560 --> 42:07.200
earlier in the podcast, Capital One has a lot of, uh, uh, history, uh, in analytic space. And,

42:07.200 --> 42:12.880
in particular, testing, you know, which we're talking about here, um, the, the more I've kind of

42:12.880 --> 42:17.760
learned, and as we've, we've kind of gone into, you know, talked to, explored more business areas

42:17.760 --> 42:22.880
for applying machine learning. Um, it, it's really interesting to see, I think in, in the early days,

42:22.880 --> 42:27.360
so that that was something, Capital One's, like, always been very good at is, is really,

42:27.360 --> 42:31.600
you know, having kind of, uh, control groups and test groups and, and really being disciplined

42:31.600 --> 42:36.400
about that. And so, um, I think there's a lot of practices that we're able to, the kind of

42:36.400 --> 42:41.760
leverage that we're existing in Capital One for, for that type of testing. Hmm. Okay, so maybe

42:41.760 --> 42:46.640
shifting gears a little bit, your group is sponsoring an event at Capital One coming up soon,

42:46.640 --> 42:51.680
the data intelligence conference. Can you talk a little bit about the objectives for that conference?

42:52.320 --> 42:56.080
Yeah, absolutely. So we're, we're really excited about that. Um, we held the first one,

42:56.080 --> 42:59.760
last year was the first one we did. Uh, it's called the data intelligence conference. It's held in

42:59.760 --> 43:07.120
McLean, Virginia in June. And I think our website is data-intelligence.ai. Um, and what this is,

43:07.120 --> 43:12.320
is really kind of intended to be a, a hybrid between an academic conference and a practitioner

43:12.320 --> 43:17.200
focus conference, um, really kind of blending the best of both worlds. And they're, they're, uh,

43:17.200 --> 43:22.560
we really saw a need, um, in, in that space with that focus. Um, we had a great lineup of speakers

43:22.560 --> 43:27.280
last time. We're gonna have the lineup of speakers this time is shaping up to be even, even better.

43:27.840 --> 43:33.840
We have separate tracks on, uh, the couple key tracks on, um, uh, one on fairness and explainability.ai,

43:33.840 --> 43:38.320
another one on, uh, data and ML visualization that, that I think are going to be quite good.

43:38.320 --> 43:45.680
And, um, and so, uh, it's just an opportunity to really kind of convene a group to get together.

43:45.680 --> 43:49.840
And lots of great conversations happen. It's a very kind of collegial feeling conference, um,

43:50.560 --> 43:55.360
uh, conference. It's held being in the DC area. There really isn't a major machine learning conference

43:55.360 --> 44:00.720
in the, the mid-Atlantic. And so, um, it's really kind of filled a nice gap and, and attracted a

44:00.720 --> 44:05.680
pretty big crowd force. We sold out last year and we've increased the, um, the capacity, uh,

44:05.680 --> 44:09.680
significantly this year, but, but I'm still expecting it to, to sell out well in advance.

44:10.320 --> 44:12.800
Any particular session you're really looking forward to this year?

44:12.800 --> 44:16.720
Um, I think we're still kind of finalizing the list. So I don't want to, uh, I don't want to

44:16.720 --> 44:21.120
be my favorite quite yet at the risk of alienating anyone, but, uh, there'll be some good ones.

44:21.760 --> 44:26.000
Who's the target audience for it? So I think it's really, you know, it's really focused on

44:26.000 --> 44:30.400
practitioners, although we do have a lot of, um, you know, students, grad students and put,

44:30.400 --> 44:35.040
we have poster sessions and things like that. So there's, uh, um, there is an academic bent to it,

44:35.040 --> 44:39.840
but, but really it's for, for machine learning practitioners and financial services in particular

44:39.840 --> 44:44.960
or more broadly, more broadly. Um, yeah, I would say it's, I wouldn't say it's, um,

44:44.960 --> 44:49.680
primarily focused on financial services. There, there obviously is some content that are using

44:49.680 --> 44:54.480
examples from financial services industry, but, um, it's a, it's a, it's a full spectrum machine learning

44:54.480 --> 44:59.600
conference. Awesome. Awesome. Well, from what I've seen, it looks like a, a great event.

44:59.600 --> 45:05.120
Any kind of parting thoughts or additional perspective that you'd like to share with our audience

45:05.120 --> 45:09.120
before we close out? No, just, you know, I think that we're, uh, we're at a very interesting time.

45:09.120 --> 45:13.120
As I mentioned, the being of the podcast, having been a machine learning, uh, for the better part of,

45:13.120 --> 45:18.000
it's not continuously, but it's starting 20 years ago. Um, it, it's just amazing to see, and I think

45:18.000 --> 45:22.640
that, uh, um, you know, there's a lot of kind of important questions like we were talking about

45:22.640 --> 45:27.200
around fairness and explainability and ethics in AI that are, um, are critical to think about

45:27.200 --> 45:31.920
along with the, uh, all the exciting technology technological aspects. And, and so I think, um,

45:31.920 --> 45:35.920
the next few years should be very interesting for, for us and we're excited to be a part of it.

45:36.800 --> 45:40.720
Fantastic. Well, Adam, thank you so much for taking the time to chat with us.

45:41.680 --> 45:42.400
Great. Thank you.

45:45.520 --> 45:51.520
All right, everyone. That's our show for today. For more information on Adam or any of the topics

45:51.520 --> 45:59.600
covered in this episode, head over to twimlai.com slash talk slash 147. Thanks once again to Adam

45:59.600 --> 46:05.360
and capital one for their sponsorship of this episode. And thank you so much for listening.

46:05.360 --> 46:24.000
And catch you next time.

