Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
Before we get going, I'd like to send a huge thanks to our friends at HPE for sponsoring
this week's series of shows from the O'Reilly AI Conference in New York City.
At the conference, and in my chat with them, HPE's punkage Goyal and Rochena Don discuss
how large enterprises can unlock the value of their data using AI, and they detail the
workings of HPE InfoSight, which is the company's cloud-based solution for helping IT organizations
better manage and ensure the health of an enterprise's IT infrastructure.
Now I've previously written about this category of AI-enabled operations management tools,
which folks refer to as AIOPS.
It is a very interesting use case for AI, and as you'll hear, HPE has an interesting
story in this space.
For more information on HPE InfoSight, visit twomalai.com slash HPE.
All right, everyone.
I am here in New York City for the O'Reilly AI Conference, and I'm with punkage Goyal,
and Rochena Don, punkage is the vice president for AI and HPE product management at HPE,
and Rochena is director of product management with HPE InfoSight.
Punkage and Rochena, welcome to this week in machine learning and AI.
Thank you.
Thank you, Sam, for having us.
Absolutely.
Absolutely.
I am excited to jump into our conversation.
Punkage, you're key noting at some point.
One is that, or both of you.
Both of us.
It is today, afternoon, and our topic is how HPE's helping our customers get the best
out of their data by using AI.
Awesome, awesome.
We'll dive into that, but before we do, I'd love to learn a little bit more about your
background.
Why don't we start with you, punkage?
Sure, Sam.
I'm a computer science engineer by background, by education.
Back in the days, actually, I did my bachelor thesis in national language processing when
we were trying to parse a mixed language text, a mixture of multiple languages, and since
then, it is fascinating to see how the world of machine learning has evolved over the
last 10 to 15 years.
I did a stint at McKinsey and company as a management consultant in tech industry, and
I also ran a startup in the mobility space back in India at HPE.
I today lead the product management for this exciting space of AI and high performance computing.
And before that, I used to run business operations and strategy for our data center business.
Awesome.
Awesome.
Thank you, Raja.
So I started, again, my training as a masters in computer science, and I did an undergrad
degree in computer science as well.
And my specialty actually was computer graphics, and so as soon as I graduated, I made a
B-line for SGI, which was the hot computer graphics company at the time long, long ago.
But ever since then, I've worked at a series of high growth startups, mostly through
the category defining startups.
I worked for Love Cloud, which was Netscape Founder Mark in recent startup after he was
ESP, right?
Yes.
Cloud before Cloud.
Wow.
I saw it before.
You know, it was before virtualization came along, and so Cloud was hard to do before
there was virtual machines.
And so I was there for about five years.
We learned a lot, and from there, I went to VMware, and I said virtualization is going
to solve a lot of problems.
And so I did product management there.
I did a lot of work in the hypervisor, and we centered the management of flagship product.
And then from there, I went to Nimble Storage, and Nimble was really small.
And that is where we thought about how to bring AI to the IT industry alongside our main
line of business, which was storage enterprise storage.
And then Nimble Storage got acquired by HP approximately two years ago.
And I've been heading on product management for Infosight, which is our AI ops product
at HP.
So, Pankaj, why don't you walk us through a little bit of the presentation that you're
giving and the way you think about AI at HP?
Sure, Sam.
So, we are really in living in some really exciting times today.
AI has come a long way in terms of expanding the world of possibilities.
And it can be attributed to the data explosion that we have seen, and also the compute power
explosion that we have seen over the last, I would say three to five years.
Even in our personal lives, AI touches each of us very closely.
My two kids, five and two year olds, they actually know how to talk to our voice assistants.
And it's amazing to see how they interact with all these AI driven machines and gadgets
in our homes.
We at HP truly believe in this power of transformation, which is being enabled through AI.
It is almost a natural step where we collected a lot of data over the last five to ten years.
And now we are trying to get the real insights which can impact the way we live and the way
we work in our daily lives.
We are truly excited about this potential and it is one of the top priorities for us as
a company.
When we think of AI, we really think of it in three pillars.
Pillar number one is how we are bringing the best people, the best technology and the
best partners to our customers, to adopt AI, to help them in their journey towards an
AI lead transformation.
And I'm going to talk more about it.
Pillar number two is how we are adopting, how we are changing ourselves by using AI machine
learning as a next frontier.
And how we are enriching our product portfolio to enable new customer experiences, especially
in the field of data center operations, which are becoming more and more complex day-by-day.
And what Roshna is leading is tremendously impactful and we are already seeing solid positive
results.
And then Pillar number three is how we are investing in the future of AI.
As you all know, AI is a dynamic field.
Not all the problems have been solved.
There's a lot of research going on to understand the next generation of algorithms, the next
generation of technologies which will power those algorithms.
And through our efforts by Hewlett Packard Enterprise Labs, we are investing in these efforts
specifically around memory driven computing, which becomes really critical as the data set
size increases.
And through our efforts to understand the next generation of accelerators like dot product
engine, which is our efforts to effort towards it.
So these are three pillars for us, AI for our customers, number two, AI within our own
products.
And the number three is AI for the future.
When you think about AI for your customers, how do you characterize where your customers
are?
Each piece of huge company, lots of customers, lots of different sizes and shapes and industries.
Is there any kind of one way that you think about where that customer base is with regards
to AI?
We are definitely seeing that all the customers are not at the same point in their AI journey.
We think of customers in three different stages on the maturity of their AI adoption.
There are a large set of enterprise customers which are just getting started.
So they do not know the exact AI use cases.
They are almost anxious about adopting AI.
But they are trying to figure out what to do about it.
Number two is we have a set of customers which have figured out where to get started,
but they are experimenting a lot.
I think a lot of enterprise AI is experimentation today.
And then number three, we have a set of advanced customers.
And to their credit, they have been investing in AI for 5, 10, 15, 20 years.
And they have reached a stage where AI is almost in their DNA of how they work, how they strategize,
and how they shape up the future of not only their own company, but the whole industry.
And we work with them a lot as well.
Depending on the maturity stage, the help that these customers need from HPE differs.
If you are an enterprise which is looking to get started, HPE helps them by providing
them the advisory services to get started to understand which what is happening in the
industry, what is the landscape like, what are the use cases to get the maximum ROI.
If you are running an experiment, your problem statement is different, your problem statement
is where is my data, what is my data pipeline, how do I get my data scientists, how do I prove
the ROI so that I can get more investments from my CIO or from a CIO.
And there we follow a solution centric approach where we bring in our best in class people,
data scientists, solution architects, data engineers.
And we bring in our best in class technology, right from compute to storage from edge inference
to training in the data center, and then we bring in a curated list of partners who can
help in that journey.
There is a lot of fragmentation in the ecosystem.
Many startups are coming up, everybody is talking about AI.
We act as that trusted partner to help our customers understand which partners to work
with.
And through this combination, we are attacking specific use cases for our customers.
For example, today we work with five leading car companies in helping them in their self-riving
projects.
We are working with leading manufacturing companies in the US and in Asia to help them improve
quality control on their factory floor.
We are working with some of the leading consumer tech companies to solve some of the largest
AI problems.
We are working with some of the leading city governments to enable smart cities and to
build the cities for the next 10 to 20 years.
And we have built and we continue to build some of the largest AI infrastructure or some
of the largest AI supercomputing power or supercomputing infrastructures at a country level, at a
research level to help provide large scale access to these capabilities for startups, for
research, and for enterprise purposes.
And that we do in the US, in Europe, in Japan, across the world.
With all these success stories, we are truly doing some incredible work at HP to push forward,
to help our enterprise customers go through this journey.
Personally, can you elaborate on InfoSight and where InfoSight fits into that mix?
Right.
You know, that's the overarching grade view of punkage that you gave about where all HP's
AI is going.
What we've done in InfoSight is we've taken a sliver of that and what we've told people
is if you're buying a product from HPE, there is AI embedded in that product and what
that will enable that product to do in these enterprise products or a data center products.
What that enables that product to do is our ultimate vision, it is self-managing, self-healing,
self-optimizing.
So for example, if you're buying a storage appliance from HPE, be it nimble storage,
three-par storage, it comes embedded with thousands of sensors that it's sending back to our
own HPE Cloud, where we're doing a very aggressive AI on and have been doing for a very long
time, more than seven years now.
And as a result of what we have been able to do with that data that's coming home across
the globe, across the install base, we have been able to predict issues that can happen
in the field and prevent issues that happen for customers in the field.
And so when you're buying one of these appliances and you install them in your data center,
for example, there's a lot of benefits you see from them.
So for example, the amount of time and skill level you need to manage one of these devices
goes down.
We've measured recently doing surveys of our customers anywhere from 75% to 90% fewer
resources required.
They run optimally.
We have a customer recently who participated in an activity with us to actually quantify
what they've been able to get through buying these products that are embedded with AI that
managed themselves, and they showed us how they saved close to a million dollars and
not having to buy additional hardware equipment because through the machine learning that we
do in the back, we were able to tell them how they can recover resources and optimize
how they run applications on these capabilities.
So basically what we're doing is saying, hey, the IT industry, the IT people today are
used to enabling AI for their businesses, whether it's selling widgets or optimizing your sales,
targets, etc.
But what is AI doing for the IT industry itself?
And that's where Infosight comes in, is where we actually enable these capabilities,
these products to manage themselves, and they can be software products or hardware products.
You mentioned that the devices, like the storage devices, have thousands of sensors in them.
I think of thousands of sensors, I think of an aircraft engine, like the classic GE example.
What are the sensors in a storage array?
And so they can be pretty complicated devices.
Our customers consider the mission critical because they have mission critical applications
running on them.
They could have had a trading application running where latency, which is a concept of
a response time, if they miss latencies by some seconds, it can be pretty, the financial
losses can be pretty big.
So these are capabilities that have to, while lives don't depend on them, they are mission
critical to businesses.
So the sensors are widespread.
They could be sensors that measure in lots of details how the different components inside
the box is doing, so how is the CPU performing right now?
CPU itself has tens and 20 sensors itself.
There's a concept called a CPU ready.
The is an application waiting to get compute, or does it have the computer needs, which
application is getting the compute?
Memory has a lot of sensors.
If you look at how an application flows with the CPU, there's memory, there's lots of
cards, how what is the health of each card?
And so if you actually pry open these things, there are a lot of factors that can indicate
health.
And then there's the whole software stack, right?
Because every stack behaving the way it needs to behave, there's very complex file systems
and these.
And so who's consuming the most resource, who's waiting for a resource?
And then there are some more traditional sensors like fans and temperatures and stuff like
that, but some of them are very critical.
The interesting thing is the infosite idea came from the acquisition of Nimble Storage.
And Nimble Storage's first line of code was written about eight to nine years ago when
the company was founded.
And by that time, there was this vision that IoT has arrived, not just for consumer products,
but for enterprise products and the data center as well.
And so when our engineers wrote the first line of code, they had that vision in mind of
they needed to telemetrize everything that they're writing.
So they actually built very deep sensors into each and every line of code, thinking that
later when they go into debugging mode or when they understand how products behave in customers,
environments and data centers, this will actually help them, right?
I mean, initially what we had was like a doctor status scope.
And now what we have are these very fancy MRI machines, so that's kind of the equivalent
they had those MRI machines in mind when they wrote that.
And so it tells you about the health, it tells you about the performance, it tells you
what events that are going on, falls as well.
It tells you about configuration settings, each customer sets these things up with the
different configurations.
I think we often talk about technologies that were born in the age of the web and technologies
that were born in the age of mobile and how what's available impacts the way technology
evolves.
And the idea of enterprise technology being born in the age of IoT and AI and what the
implications of that are, I think, is kind of an interesting one starting from kind of
taking advantage of all of this telemetry data that's available and pulling it in so
that something can be done with it.
Right.
So there was a leapfrog advantage right by the time we started.
There were a few nasiers in the industry and they said, well, enterprise products, I don't
think mission critical applications, sensitive applications for businesses.
People are not going to send you data just like you connect IoT or consumer product
through IoT.
They're not going to send you this data.
We found out that our attach rate for this data was 97%.
These were enterprise companies.
You mean the customer had the option to do that?
They had the option.
They had to turn it on because it was a time and be one share of customers would send
us streaming data from their highly sensitive equipment back to our cloud and trust us
with that data. We figured by default, we leave it off and the customer can opt in and
we found 97% of our customers opted in.
Some of them initially said they were policies within the companies that they could not send
data out.
They could not connect to the cloud.
They had never done it while lo and behold, the first time they ran into some problem,
we showed them what we could do for other customers.
If you're sitting on these data and the tools that we have to interpret it, the value
then drove them to actually turn that on.
And of course, this is on machine data.
It's not customer sensitive data.
But it is that almost like a revolution where the enterprise products are now seeing what
consumer products can do for them.
At the end of the day, if it's going to save you 80% of your time, that you would otherwise
send, spend in troubleshooting, hairy issues by looking at 20 different graphs, have ten
people involved, and the worst of all, if you talk to enterprise customers and IT people
that actually manage these devices, they have to call multiple vendors for support.
What we did at Dimmel Storage was because we had so much automation and insight built
into our products.
We did not have level 1 and level 2 support engineers.
We never hired those as a startup.
We hired directly level 3 engineers, so how you call on the phone and someone asks you
and tells you to reboot the thing or just gives you some list of a script that they have
and then they pass you to the level 2 engineer.
And then finally, you know, you talk to the gods that are actually talking to the developers.
We eliminated, we never hired and to this day we don't have level 1 level 2 engineers.
You call, you get, go straight to a level 3 engineer.
So the issues that the level 1 and level 2 people would have resolved have been eliminated
through machine learning, AI and automation.
And so those issues don't happen for the customer.
So if the customer is facing an issue and thinking this thing is not behaving the way
you want it to, it's probably a very hairy issue.
So they just call and they talk to a level 3 person.
We're also very proud that when you actually call a level 3 person, we answer the phone
in less than one minute.
So it's not like we're queuing people up because we don't have level 1 level 2.
Our customer satisfaction scores are extremely high, 4.9 out of 5.
This is customer self-reported saying how satisfied they were.
And even these hairy issues we solve in less than 45 minutes.
These are issues that can take weeks sometimes to resolve if you don't have that level of
insight and you have and build the machine learning models to automate.
Can you maybe walk us through one of these, an example of one of these hairy issues that
comes up that may take hours or weeks to troubleshoot and how the data and machine learning
plays into solving that?
Definitely.
Definitely.
And I can't name names, so this is a large customer in the oil and gas industry.
They make additives for additive products for oil and gas, a very global company.
Sounds like this is going to be a real example.
It's going to be a real example.
The revenues are about $6 billion.
Okay, you can Google it now and see who this is.
But they came to us and they were looking to buy more gear from us and this actually
is a story from three-part storage arrays that we sell.
And they said they just cannot add more workload.
They've been having issues with workloads that are running today.
Of course, the response times have been sub-milliseconds, but they have not been able to expand
the footprint and they were running VMWares, BDI, which is a virtual desktop product, which
is very popular in very large companies.
They actually had consultants come in from different vendors, which also I shall not name
your old friends, but they had different vendors come in and there was one vendor assignment
that was engaged for about months, trying to figure out what the problem was, what
why they could not put more workload on these devices and why there was erratic behaviour.
The people collected a lot of logs, etc. that couldn't fix it.
This was the time when three-part was just coming on to InfoSight support the product
itself, because like I said, it started with nimble storage, not coming on to all HB products.
And so we three-part came on, we started collecting a lot of the telemetry, starting doing a lot
of the analysis on that.
And literally within a matter of days, we could show them, you know, it takes time for
the data to come and for us to analyze.
And then what we do is we show the data to our support people and we reflect it back
to the customer through a portal and they could log in.
And out of the thousands and thousands of virtual machines they had, they could pinpoint
a few virtual machines that were behaving strange.
And what happened in those virtual machines was it's a virtual desktop, so when the user
logs out of it, it triggers an antivirus scan.
And that takes up a lot of the resources.
But to find those needles in the haystack was very hard before we had all this modeling
that they plugged into.
And they were able to solve the problem in as a result.
But how did they...
But how did they...
As we wanted to sell them, but they...
What specific data and what specific models allowed them to solve the stuff?
Yeah, so there's lots of different models that we employ.
The data that we get from, for example, from VMware, tells us on the compute layer.
Now, the thing to notice, I'm talking about, we were selling storage products to them.
But that doesn't prevent us from collecting data from products that are running on top
of the storage product, right?
The application owner at the end of the day cares whether their application is running
or not.
The business cares about the application.
The many layers of hardware and software underneath they don't care about.
So what we've decided, we will collect data from the entire stack.
Because at the end of the day, we want to show you where some problems are coming.
So from VMware, we collect intensive CPU data, intensive memory data, audio data to see
all these little cards that are running are desaturated or not.
And then we correlate.
And so we have some, today, mostly supervised machine learning models.
You know, we do regression analysis for some, we do classifiers for some others.
We are just starting to go into unsupervised.
But we correlate this data across the stack where we see what looks like a problem.
A lot of these expert define as well.
So over time, what we've done is when people report problems, we have gone and then labeled
our data and tagged our data to show what do problems look like and then what do solutions
look like.
And so there's a lot of that, that modeling that we have done in the past as well.
And so we are sitting on these patterns where the patterns can detect and say, this is
a problem and this is what solves the problem.
And so if you look at our UI, there's recommendations that we make and say, you know, your number
of one recommendation is you can move this virtual machine to another resource that has
excisey specification number two recommendation is you can throttle this virtual machine.
So these problems on finding the needle in the haystack we're able to do because it's
pattern recognition.
If you were a human being going through each and every virtual machine and seeing how
it was behaving, you know, it would just exhaust that.
You take the two weeks.
Well, not the two weeks, I think that people working on it for weeks and weeks.
So it would be more of a, I would say at the scale of a year or so, because we're talking
about thousands and thousands of virtual machines that these environments have.
So you need to have patterns that that you can just scan through and we do it automatically
all the time.
You don't wait for somebody to complain and it can highlight.
And so the models that you're working with, do they, you mentioned supervised on supervised
and regressions and things like that, that they tend to be fairly simple, traditional machine
learning, time series kinds of things or deep learning like what's the spectrum of complexity.
So for the models today, they're so, they're relatively simple, you know, there's not
depends on the use cases.
Sometimes we do a lot of forecasting, for example, we help customers with capacity planning.
And they're simple forecasting tools that we use today, we use Arima, for example, what,
and then for the prediction capabilities, a supervised are, you know, regression analysis
of classifiers, we do decision trees.
Very simple for right now, but we have a team of data scientists that are just focused
on going deeper into into the data now, yes, they are now going, they're exploring more
neural networks, for example, and to see what they can get out of that.
You know, initially, when we started eight years ago, we just did even simple SQL queries
and pure correlations and that revealed a lot of, a lot of capabilities that, you know,
nobody had done this for the IT industry prior.
I'm imagining if you've got a dashboard that you're presenting to IT folks and telling
them they need to go do thing X reboot the, reboot the storage array or something, probably
in more detail or more fine grain.
But this whole idea of explainability, like it's not just do this, it's like why, you
know, you need to do that.
So what degree does that come up?
Right.
So, you know, there's always initially people who want to be cautious, especially if it
been the systems emission critical, when you tell them to do something they want to know
why, you know, their jobs depend on this, if they do something wrong and the application
goes down, you know, there's financial consequences of that.
And but over time, people build confidence.
So what we do today is, you know, predicting what's going to happen and knowing how to
prevent it based on the models that you've trained in the past is one thing.
But we've also gone and built because of this, there was a necessity to build automation.
And so when when we do, you know, today we have, I don't know, more than there's hundreds
of thousands of deployments in the field across the globe, right?
And the models are running on all of them.
So the scale is huge.
And like I said, we don't have many people supporting that, right?
So we build a lot of automation and these tools will actually then detect that something
is going to go wrong.
For example, they may be some memory issue that's going to happen, that will impact certain
applications.
So we automatically notify the customer.
What we hear from our customers often is somebody called me and told me, no problem is
going to happen, which I've never experienced before.
It's usually me banging on the doors right and saying, there's a problem, help me.
And so we notify the customer and it is very easy for them to quickly see the symptoms
because we can tell them what the symptoms are.
And if you tell them where to go, look, they can go look there and see it for themselves.
It's just a problem that when the scales at which IT admins manage these devices, they
don't know where to look, let alone beforehand, even after issues happen, they don't know
where to look.
So we show them the proof of the pudding, there's a little bit of information, we give them.
Now the customers have built so much confidence in these predictions that we make, that they
have actually asked us, since you know this with so much confidence, why don't you fix it
for us?
And that is actually where our vision is as HPE, we are now building capabilities to go
fix these issues for customers.
So once you buy the product, you put it in your data center, you have these eyes and
ears and hands that are going to take care of it and fix it for you.
And the reason we can do that at reasonable cost is because we've automated it, right?
We're not putting people behind that.
But customers do ask, initially they ask, skeptical and they do ask, but they very quickly
see the credibility behind it.
Because you can actually, once you know where to look, you can look and see that this is
actually something that's going on.
So much of transitioning through that maturity cycle, that's the way I think I did a paper
on industrial AI and kind of build out this model, reflecting the way I saw folks deploying
that kind of AI in industrial settings, that first they're using it to help them monitor
or then they move to helping them optimize and then they move to helping them control
or automate.
And it's kind of a maturity spectrum and it's really the, you know, where a given company
is, it's all about trust, like how much do they trust the technology that do they trust
AI to give them recommendations that will actually optimize what they're trying to do?
Right.
Do they trust that, you know, if they hand over the keys that it's actually going to
fix problems before they start?
Right.
And so we are at that point where we tell them what to do, but we tell them very precisely
because of how much we know about that environment.
And they have gone, gotten to the point where they're trusting us because they're seeing
when they do make the changes that we ask them to make, that it makes, it actually solves
the problem, right?
So the keys are in their hands now and the next stage is for us to go, they're asking
us to take the keys and do the job for them, right?
They don't want to drive around anymore.
They just want Uber to show up and take them there.
I imagine providing a rich level of detail is part of what helps create that trust.
Yes and no.
I think I do find that sometimes sharing other customers example, sometimes it's the brand
that you have built is enough.
Each customer is different.
There are those that are very hands on and they like that.
But there is a trend where a lot of our customers just can't scale anymore and they are more
willing to trust you with making changes.
You know, I saw that when I was at VMWare where we introduced this capability, which was
you could take a workload and application, move it around physical resources, separate
compute boxes automatically, it's called VMotion.
VMotion was a big deal, huge.
But I was at VMWare when before we introduced VMotion and people told us, never let you
do that.
How can you move a workload and look at where it is today?
And the way we built that was we built a safety net around it and we said, okay, we'll
come out and recommend that you should move this workload to this destination, but you
will be the one hitting the go button.
And they said, fine, I can look for that.
They tried that and they said, well, every time it tells me I hit the go button, so I might
as well let it go.
And I had one customer saying, well, I will let it do it, but I'll sit there and keep
watching it for a while.
And, you know, I'm sure that customer is not watching it anymore.
Right.
So trust has to be built, yes.
So this started with storage or really grew out of things that you were doing at Nimble.
How, I'm trying to get how much work it is to go to the next thing, like, you know, so
from one storage thing to the next storage thing is probably pretty easy, but then, you
know, to servers is that, right?
So actually, so our goal is to bring it out, to bring infosite capability to the entire
HB portfolio and it's not going to happen over time and we don't, it's going to happen
over time.
It's not going to be instant.
We don't want it to be instant.
And so there's a, there's a two prong.
Even if you had a magic wand like you and, yeah, if I had a magic wand, yes, I would,
but I know I don't.
If you want to be careful when you're rolling these things out, so we went from one storage
to the next storage pretty quickly and we're taking a two prong approach where, you know,
we talked about the machine learning models, the AI, the sort of the fun stuff.
There is a less fun sounding, but very important capability, which is the infrastructure in
the back, right?
This data pipelines is data lakes and this ETL, there's capabilities are the data scientists,
the tools that they used to just mess around and see what patterns come up and what distributions
they say they just, they do their own thing.
And so what we're doing is we're helping different teams build this, but leverage from our learning
of what worked and did not work in terms of infrastructure.
And also in terms of use cases, there are some use cases that lend themselves, they're
the low hanging fruit, use cases.
Each product also may have different pain points in the industry and, you know, on how they
compete with other products in the industry.
So we help other customers, other products find the use cases.
There are some models, some automation that lend themselves pretty readily and there are
others that will have to be built, definitely.
So that two prong approaches, we're helping people, other products build this, but build
it to our specs.
And we're building actually a services oriented architecture in the back where all these
capabilities that amend that go into infrastructure will be turnkey for the other products.
So we will build that and then we'll say, okay, you know, product, the new product that
wants to do this, this learning in the cloud for their own product, they come to us and
then we give them turnkey solutions, we give them a data pipeline, we'll give them the
data lake, but they can put their data, we have all the tools ready.
So we're going to put this platform that they can plug into.
And that's how we will, we will roll out even farther and beyond.
The idea here also is one plus one equals five, right, where for the, not even three,
you're going for five, that's AI, right?
But the idea is you can see patterns across the board that are much more valuable than if
you just showed, did correlations, for example, within your own silo, right, when the correlation
jumps the silo, imagine for the application, sometimes this is all the same resources
underneath, right?
Be my thing, it's a sensor server, it's a storage, it's a networking device, but from an
application's perspective, application owners perspective, it's all the same, that all
means to end to his application, right?
And but if you can correlate, you can eliminate, you know, things that look like false positives
in the silo, for example, but together, they may make sense and you can pinpoint accurately.
So there'll be some domain learning in each capability that will build over time, but
it is lots to leverage already that's in place.
So punkage, when you think about the capability that you're bringing to bear with InfoSight,
and maybe even more importantly, what you're learning from engaging with customers around,
you know, data and telemetry and AI and automation, how do you see that more broadly impact
the portfolio at HP?
So broadly, we are making our portfolio more intelligent.
And we are enabling new user experiences, which were not possible in the past.
And HP InfoSight is a great example of how we can do that in a data center environment.
We have similar efforts going around on the Aruba side, where Aruba is bringing some
of these capabilities and even more at the edge.
So overall, if you look at HP's vision, we do want to bring in new experiences and
intelligence to our end customers to make their life simpler so that they can spend their
time on more value added activities.
And they can benefit from a lot of automation, a lot of prediction, and ultimately move
to this long-term vision of self-healing, self-maintaining data centers.
So we are truly excited by that, and the other angle of that is we are learning a lot while
we are building InfoSight, not only on the customer side, but also on the backend side,
in terms of how to build these large-scale data infrastructure.
And we are taking some of these learnings to our customers who are trying to solve the
same problem.
How do I handle large amounts of data?
How do I connect my data pipeline from where I'm collecting data to where actually I can
train my data to where I can infer from the model that I've trained.
So we are taking that learning as well as to our customers to help them solve similar
problems for different use cases in their own environments.
So as an organization, as a company, we are definitely learning a lot.
We are moving fast, and we are committed to enabling this vision.
As you talked about, the things you're learning and the challenges that you're experiencing
being reflective of the things that your customers are experiencing, more broadly, there's
a move on the part of a lot of enterprises to kind of serviceize their products, if that
means anything.
GE doesn't want to sell you an aircraft engine anymore with the 2,000 sensors.
They want to provide it as a service.
Do you, and it's open to either of you, do you see IT moving in that direction?
I guess it already has in a way with SaaS, but with the physical infrastructure that we're
delivering to IT organizations.
Right.
And I can take my attempt at that.
There's been a little bit of a pendulum effect, and I think we're kind of settling in
the middle of that pendulum right now, where the traditional was, you own everything,
you manage everything, the more control you have, the better it is for your business.
And then it started to swing in the other direction, where it said, I'm going to put everything
in the cloud.
I just don't want to own anything on my box.
I want to go to OPACs, and I'm going to sit there focused on my differentiator, and
the industry started believing, well, everything is going to the cloud.
And I know a lot of people in the investment banking started to believe, the other thing
is going to the cloud.
What's going to happen to these companies that are sending equipment for the data center?
Well, now cloud has been out long enough where people have had experience with that, enterprises
have had experience with that, and learn that that is not the, you know, the be all that
they thought it was, and it's not going to solve all the problems.
And so it's coming back to the middle where there are, they need people have decided they
do need to own infrastructure, have their own infrastructure, go with a best and best
of breed infrastructure, have control on it, etc.
But they're also now looking at seeing how, instead of managing day to day, they can
do services on it in the sense, have, pay someone, have a managed service provider for them,
for example.
And then managed service provider is a great model for companies like HPE.
Just for the record, Infosight is given away for free today.
And so what you're saying is, we will use technology to do as much management automatically
for you for free customer.
But there are those higher level services that we need to offer that are very contact
sensitive to that customer or are very specific to their needs.
And we have now very thriving business built on services of these capabilities.
Now whether the SKU transfer from paying for the device and just all the way paying to
services, I can't comment on that.
I don't think that's in the works today, but that is more of a financial exercise, right?
But the idea is, first you leverage technology to automate a lot of those things, predict,
prevent, automate.
And then you offer services at a higher level, right?
It's an interesting question because the labor component is a big part of the cloud value
proposition if you, through automation, eliminate that, that kind of impacts where that
pendulum settles for a lot of organizations, I think.
It's also that services, in my view, is an experience.
And it is not an experience only for the IT team.
I truly believe that it is an experience for the whole company.
So it is an experience for the CFO, it is an experience for the CIO, it is an experience
for the business in a GM, it is an experience for the CEO.
And we are treating Azure services and experience addressing all these stakeholders.
HP GreenLake is one of the top priorities for us, which provides us as a service workload,
as a service IT in a hybrid environment, whether it is on-prem, whether it is managed service
providers, or whether it is off-prem.
In this hybrid environment, how can we provide this as-a-service experience to data scientists,
to machine learning developers, to IT teams, to CFOs is a big focus area.
And actually recently, I think four or five months ago, Blue Data joined HP family.
And Blue Data is our effort to provide AI as a service.
It essentially provides containers as a service, making it super easy for data engineer or
a machine learning developer or a data scientist to spin off the right AI or the right big data
environments in their infrastructure, and in a truly hybrid way.
So we are moving in that direction where we want to provide this as-a-service experience
for machine learning workloads and other workloads as well.
And we are committed as a company to do that.
Well, punkage, Rochner, thanks so much for taking the time to chat with us.
Thanks for having us.
Thank you, Sam, for having us.
Alright, everyone, that's our show for today.
If you like what you've heard here, please do us a huge favor and tell your friends about
the show.
And if you haven't already hit that subscribe button yourself, make sure you do, so
you don't miss any of the great episodes we've got in store for you.
For more information on any of the shows in our AI conference series, visit twomolei.com
slash AINY19.
Thanks again to HPE for sponsoring the series.
Make sure to check them out at twomolei.com slash HPE.
As always, thanks so much for listening and catch you next time.
