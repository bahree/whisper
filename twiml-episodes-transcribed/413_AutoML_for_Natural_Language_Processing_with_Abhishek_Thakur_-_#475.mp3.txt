All right, everyone, I am here with Abhishek Thakur. Abhishek is a machine learning engineer at Huggingface and the world's first quadruple Kaggle Grandmaster. Abhishek, welcome to the Twoma AI podcast.
Thank you very much, Sam, for inviting me here. I'm really excited to be here. I'm super excited to jump into our conversation as well.
Let's start as we often do here on the podcast with having you share a little bit about your background. How did you come to work in machine learning?
Sure, that's a long story where do I start from? So I think it all started from my internship that I was doing during my bachelor's and I was studying electronics engineering and I got an internship at University of Warwick where I was supposed to be working on pathological images.
And that's where I came to know about random forest. I didn't know what it is, but I just heard the name. And then I was in the image processing part of the image analysis.
So I wasn't doing a lot of machine learning. When I came back, I went to a university upon where I was doing my master's in computer science because I always wanted to study computer science. And they're also my favorite subjects were image processing and computer vision, not machine learning or deep learning.
So I was working at front of her and a lot of friends of mine were talking about machine learning. They were working machine learning and because of that, that I got interested in machine learning and deep learning and data science and then I found Kaggle and I started doing some completions learning yet on my own.
So that's where it started like back in 2010, 11. That's awesome. That's awesome. I'd love to hear you share a little bit about your journey with Kaggle. What was your first competition and how did you approach it?
Okay, my first competition is it's I think it was facial expression recognition or emotion recognition something something like that. So you were given a lot of facial images and you had to predict what kind of emotion it is. I think it was that.
I'm not so sure anymore. What I did was I was using MATLAB because at that time I didn't know Python and I was using my old school image processing skills to figure out the emotions of these pictures.
There were not so many computers in that competition because it required a lot of hardware, I guess, and at that time GPUs were very expensive deep learning was new and this was back in, I think, 2013.
So long time ago and deep learning was new. I think at that time, a lot of people were just using random forest for everything.
So I did some basic stuff in that competition ended up being at the middle of the leaderboard and that was like there were only 50 60 people in that competition.
So it was very interesting.
The guys who won the competition use deep learning. So there I got to know what neural networks are.
So it was it was a good beginning for me and I saw that it's much easier if you use Python. So I started learning Python and nobody, nobody used MATLAB in that competition.
And MATLAB is also not free. So you have to buy the license and Python is free. And Python is always active.
So when I started with the Android and lecture, he was using Octave for everything. But Python is also very similar. So some people think it's going to take them a lot of time to switch from MATLAB or Octave to Python, but it's not like that. It's quite similar.
The syntax and all.
So how many competitions have you done so far? Oh my god, difficult question. I haven't kept track. So I tried to I just tried to jump in a competition. I don't do all competition seriously.
So I don't invest much time as normal competitors in a given competition. So I just pick up a competition. I do some of my own stuff. I submit the result even if I rank 1000. It's OK.
Because I haven't shown any effort there. Right. So I think right now I participate in more than 200 competitions, including, including Kaggle and everything else like driven data.
So these are things.
That's great. And are you still actively participating in those or you focus on other things nowadays?
I used to have a lot of time to participate in competitions. Actually Kaggle was one of the websites I found very early. And that's how I began my journey into data science. And at that time, data science was also very new.
But there were not a lot of people in data science and machine learning. So you really had to build a strong profile to get a job in data science as a fresher.
So that's where Kaggle helped me a lot. I used to invest a lot of time. I used to probably spend few nights, pull all nighters several times a week. But nowadays I cannot do that because I have a day job.
I have to be focused there. And I also I'm also doing a lot of different other things like making YouTube videos or sharing stuff on social media. So I really don't have much time for Kaggle. But I tried to participate in a competition seriously, like once a year or two or three times a year.
Not so much. Now people on the commercial side will often kind of turn their noses up and Kaggle and say, Hey, there's a real world problem. It's not a Kaggle competition as if Kaggle competitions are bad.
But you've invested a lot of time in them, participated in a lot of that presumably you've learned a ton with Kaggle competitions. How do you react when people respond that way?
They are not wrong. But they are also not entirely correct. When you're working on a Kaggle competition, you get data which is clean.
But if you go to the competition forums, people still complain that the data is not clean. So people are always going to complain.
And getting the data is the hardest part when when you're working in industry, when you're working in some companies, you will see you spend more time getting the data and gathering everything from all all the infrastructure that you have.
And then modeling is a very small part of your job and you're still a machine learning engineer or a data scientist. You're doing analysis, but you spending 78% of your time just collecting the data or cleaning the data.
So in this regard, Kaggle is very different from the industries, but when we talk about what you learn from doing Kaggle competitions, can you apply them to industries? Of course you can.
So even if even if you're doing competitions in different domains, you can just use the knowledge that you have gained doing those competitions and apply to real world scenarios.
And I have done that in the past. I still do that. And I think that's one of the best way to learn and people say like when you go to industry, when you're working in a company, you learn the most, right.
And this is also very similar when you're practicing the problems and you're trying to compete with others, you see what others are doing and you're trying to build something better on top of what others have built.
So this is also a good way to learn and you do the same in industries and companies, you work in teams, here also you work in teams. So these kind of things.
What are the biggest things that you've learned in participating in Kaggle competitions, if you had to name a few top takeaways.
So one of the most, one of the most important things that I learned was how to handle categorical variables. So there was a competition several years ago called Amazon Employee Access Challenge.
And in that challenge, it was all about categorical variables and people presented there like we didn't have Kaggle Kernel. So people would write code in discussion forums or just upload their Python scripts there and there was just so much to learn in that combination.
So I still consider it as a very good example, if you want to learn about categorical variables and how to handle categorical variables in many different ways, you should go and take a look at Amazon Employee Access Challenge.
So there's that and then when Kaggle introduced these code competitions, one of the things that you learn is how to run your code given a time limit. So which is also very important in the industry, if you're building models which you want to put in production, they should be reliable enough and they should also have a very low latency.
So it should be able to do a lot of jobs in less amount of time. And I think that's also a good thing to learn. Then I learned how to approach different kinds of problems like images, time series problems, text data, what kind of different.
For text data, there haven't been a lot of competition for, but for images, there's so many competitions going on on Kaggle all the time. And for different kinds of image problems like object detection, segmentation, classification.
So there's a lot to learn from from these competitions and it also helps you like building your portfolio approach.
So I started out with a focus on computer vision and now you're spending much of your time on the natural language processing. How did you end up at hugging face.
So I've always been interested in natural language processing and the companies that have worked before in past few years, they have always been focused on natural language processing problems.
So hugging face is for hugging face, I was talking to Thomas who is one of the founders of hugging face that I have an idea and let's try to build something. And he was, he was also very interested in implementing that idea and that was about alternative.
So that's how I started working with hugging face.
And so there, so I didn't realize that you were the originator of the auto and LP idea there. Maybe tell us a little bit about the idea and where it came about.
I won't say if I was the originator because even I don't know that, but I did start the project.
So I've always been interested in automatic machine learning when I was doing my PhD, my one of the major things that I was focusing on was recommendation systems and at the same time, machine learning was very popular.
So there was a competition called the auto ml challenge and it used to there are auto ml workshops in ICML and they used to organize this auto ml challenge.
So I took part in those challenges and I won some, I got my first GPU because of the auto ml challenge and it was very interesting for me to see like, okay.
You don't need a lot of complicated things to build the automatic machine learning system. It's all about, it's all about what to use when the data is blah blah blah.
So something like this, and if you know that like for me, if I have taken part in now 200 completions, I don't spend much time doing exploratory analysis, I should do that.
Before that, but even before that, I tried to build a model and I tried to see, okay, now I have a baseline, now I will go and do the EDA part.
So, after, after the, had you built up in the course of building out, in the course of competing in so many competitions, have you had you build out like your own frameworks that you use for lots of different competitions.
During the time of my PhD, we did build a framework, but we never got to publish it because I quit my PhD after one year and then I went back to the industries.
So this idea was always there, I always wanted to do something with auto automatic machine learning and then I thought, why not NLP?
Because no one is doing crazy things like with NLP, when it comes to automated machine learning or and when we look at hugging face, they have all these state of the art models.
So it just makes sense that they should do automatic and actual language processing auto NLP and that's why I thought, okay, it's best to work with hugging face and build this system that people can use.
And so, what were the initial goals of auto NLP? How did you kind of scope the effort?
Initially, when we started, it's quite simple, let's say you have a CSV file and you have text and you have some class associated with that text.
So all you need to do is just upload this file somewhere and it will run a bunch of models, state of the art models like bird, rubber, these kind of models, it's going to do all the hyper parameter tuning for you.
You don't need to worry about anything, you don't need to select batch size, you don't need to select the learning rate or the line length, the number of tokens, you don't need to worry about tokenization, which tokenizer to use for what kind of model, you don't need to worry about anything and you just all you need to do is upload the data and then you get the model.
And hugging face has built such a good infrastructure already that every model that we train using auto NLP is automatically eligible for, let's say eligible for production.
You can you can deploy it in production in one click and that's what people want because people don't want to spend time deploying a model, which is like bird or robot or even larger models.
So the problem domain is a primarily focused on fine tuning a language model or are there other problems that it'll work on like any hour or.
Yeah, you definitely so we currently we have implemented a few different tasks, so we have binary classification, multi class classification, we have regression, we have named entity recognition, we have summarization, we are also expanding to question and answering and translation very soon.
So we have different kinds of tasks, so we currently have not thought much about if you can train your or if you can pre train a language model from scratch, but that should also be possible without NLP, but it does require a lot of infrastructure.
And so where were you finding the most use thus far, the project is relatively young, is that right.
It is, it is indeed quite young, it's we started, I think it was mid or end of December and we released it to public one month ago.
So it's very young, so people are still trying it, we haven't publicized that much.
And we are still thinking about a lot of different things in the project because it's it's it's it's it's like currently it's in it's in baby stages, but it's growing quite fast, so we are adding new models and new tasks every week.
So it's growing quite fast or any of those tasks.
Kind of driving the majority of the interest or is our folks using it for everything.
Folks are using it for mostly people are interested in classification problems and that's one one of the reasons we started with binary classification because everyone has data for binary classification problems and every industry.
Or every person wants to try these models on different types of classification problem and very simple thing would be like sentiment detection.
Everybody wants to build model around sentiment in fiction. I don't know why, but yeah, that's how it is.
And so majority of the focus I would say is around classification, which is quite strong at the moment.
But when we come to when we talk about development, we are working with summarization, so sequence sequence models now.
What is the team look like around auto and LP?
It's not much it's just me and one more person named Simon.
We are two people, but we also have Anthony who is in the infra part, we have Thomas who is leading everything.
So we also have many front-end people like we are also coming up with some kind of graphical user interface.
Currently, everything is based on CLI. So we have people here and there, but only to our working full time on this project.
Would you have imagined that you kind of get so much done in such a short period of time with such a small team?
It's very difficult to accomplish to implement so many different kinds of tasks.
So we deployed the whole infrastructure on humanities.
So that's also like it's a pain to deploy stuff and everything should work and to end all the time.
So yeah, it has been quite a journey, but as I said, it's just the beginning and after a few months, I think things will come down or maybe they never will.
It has never come down for me at least.
But yeah, it's quite fun because when you're working on a fun project like this, you don't really care about time.
So like the project drives you. So there's so much to so much to implement so many things to fix so many ways of doing hyper parameter optimization, different kinds of architecture selection.
So it's quite nice, quite interesting.
You mentioned that you're running everything on Kubernetes.
Is that something that you had experienced with before and how has that experience gone?
So I didn't have much experience with Kubernetes. So I as a data scientist as a machine learning engineer, I could I could deploy a demo project on Kubernetes.
But most of the time it was the operations team that takes care of that.
And here also when when it comes to auto LP, most of the work has been done by the infer team.
Deploying to Kubernetes is something that they have taken care of.
We talked a little bit about kind of your broad lessons learned with Kaggle.
I'm curious if you have a similar set of kind of core lessons from the more recent NLP experience and auto NLP in particular.
So much. I mean, it's it's NLP is going quite fast. So you do need to keep yourself updated.
So that's one one of the things that I've learned.
And whenever whenever a new state of the art model comes, do read the paper, go through go through the paper.
Don't worry about.
So a lot of people I've seen a lot of people they have like couple hundred samples of data and they start with a very large huge model.
Probably only that you can you can get away with smaller models.
So it's it's going to be all about transformers in near future.
So get yourself updated and yeah, not much.
Can you maybe talk a little bit about the about how auto NLP approaches a task like binary classification.
Is there a methodology that you've built into it that you could describe?
So I can probably describe like give you a small overview.
So we do have we do have different models for different languages.
So when you're doing sentiment classification, you can choose a language in which you want the models to be from.
And then we choose models from from that given language. So if you're doing sentiment classification for Japanese.
We choose models which have been trained on Japanese and then we try to hyper hyper parameter tune.
Sorry, tune their hyper parameters.
And in the end, we present to you a kind of a leaderboard where you can see how the model performs against different metrics.
So for binary classification, it's it's metrics like F1 precision recall a UC accuracy.
So log loss these kind of things.
And then you can choose the model based on the accuracy and the latency.
So you probably don't want to choose a large model, which gives you and a lift of 0.001% in a UC.
Compared to a small model, because it's also going to take a lot of time for it to predict when it's live.
So the whole back end of auto and LP is closed source.
Only the front end part where you upload the models where you see the data where you choose the different languages.
This is open to the world and auto and LP is built on top of transformers or existing resources from hugging phase.
Like the data sets library, the transformers library.
So when you're when you're building something with auto and LP, do you?
Well, maybe asking a different way like, well, how do you, how does auto and LP the result of auto and LP compare to a model that you've hand crafted and and built?
Yeah, I mean, it's it might not be good.
So auto and LP is all about so.
And let's say you, you, you got the data set.
So the most difficult part is still yours.
You have to get the data set. You have to do some cleaning if you want.
We do take part of some cleaning, but if you want, you can do some cleaning.
And then upload this data now.
During this time, you can build one model, right?
Maybe train one model auto and LP you will train you like 15 20 models.
So this is a difference and then you get a leaderboard where you can check.
Okay, so so if you have if you have one GPU or two two GPUs that at your work, you can probably train two models in parallel.
But given this infrastructure that we have, we can train multiple models in parallel.
And we can do hyper parameter tuning on all these models simultaneously.
And in the end present you the results from all these different kinds of models.
And you just have to choose a single model.
But auto and LP can also be used in a very different in a different way.
So a lot of auto ml vendors, they don't give you the model weights.
They just give you an endpoint and you can use that endpoint.
But yeah, auto LP from hugging face does give you the model weight does give you the tokenizer.
So you have everything that you need.
So you train the model using auto LP choose the best one and try to improve on this result manually.
So you can fine tune the fine tune model.
So this is also one of the use cases people can try.
Nice. What's the approach to hyper parameter optimization? Is it, you know, simple grid based approaches?
Or is it kind of exotic Bayesian stuff? How do you or is it?
Is it task specific based on research papers?
I won't, I'm going to details of this, but it's a, it's a combination of both grid and Bayesian approaches.
Okay.
So sounds like an area that you've invested some kind of creating some IP into.
We are trying to, yeah.
All right.
So, as I mentioned previously.
Automatic machine learning or any kind of auto ml model.
You probably don't need to tune all parameters all the time.
You just need to know which parameter to tune and what should the range of this parameter be.
So if you talk about a model like XG boost, it, and you compare it with light GBM.
Light GBM has so many parameters, right?
And it's so, it becomes so difficult to tune it, but you can, what you can do is you can use XG boost.
Trune some parameters and then transfer it to light GBM and tune further.
So these kind of tricks you can do, you just need to know what, what should I do?
Like if I, if I increase the depth, I should decrease the learning rate.
So these kind of tricks you should know.
And then you will be able to build your own auto ml solution.
And are the, these kinds of tricks things that you have gotten from just trying a lot of different things.
Or do you find that you're learning a lot of these tricks from papers?
Yeah, I'm from both.
So I have, I've gained some knowledge from trying out different competitions, trying out different kinds of datasets.
Yes.
And also learning from different papers, like, like if you're doing biogen search, you have to define the search space, right?
So this is something that you have to do manually.
They won't come up with some kind of search space for you.
Maybe they do.
So this space, if you define it properly, you are, it's more probable that you will get a good model quickly.
Now, what have you learned about working with the transformer models?
I've learned that they are the state with the art right now.
So, yeah, I've learned quite a lot about transformer models.
And I've learned learned a lot from the team, which is working with, with transformers, the library.
So I've, there were many tasks that I didn't try before.
And now I'm, I'm, I'm getting my hands dirty with.
So like the task, like summarization or translation.
So these kind of tasks are quite new for me.
So I'm still in process of learning about these using transformers.
Yeah, I think I was mostly curious.
Like in the hyperparameter tuning and some of the other areas we discussed, there are tricks that you eventually figure out.
If you read enough papers or beat your head against the wall, that you could share that would help folks shortcut that learning, you know, that learning loop.
So yeah, most of the papers come with implementation. And I usually try to start from the implementation and keep the paper on the side.
So you have, you know how this thing is implemented when the author talks about something specific.
So I think that helps a lot.
And like, if you, if you look at the paper.
The intention is all you need. And then you have this web page from Howard NLP annotated transformer.
Okay.
In which they do, they have the whole paper and they have shown how each and everything is implemented.
So that gives you a much clearer picture. So, and then there are many YouTubers who are making videos on when a paper was announced.
And next day they have a video around it.
So try to take a look at those videos and different kinds of tutorials about about the papers.
If you are not so much into reading papers.
Yeah. Speaking of YouTube, you're working on YouTube among other things, you know, when you're not working on auto NLP.
Tell us a little bit about the various things that you have been up to recently.
Yeah, YouTube, YouTube is like it's a fun thing that I do.
And I started it because I face a lot of problems learning things which are not usually taught.
So you can do lectures, but no one is going to tell you how you can write this in a proper manner that you can reuse it again and again and again.
So my YouTube channel focuses a lot of writing clean code.
It's very much applied. So you can learn the theory, but a lot of people face this problem.
Like if they're given a data set, they are not able to apply the theory and they know everything. They know about by torch.
They know how things work and they know deep learning. So they know everything, but they are not able to apply this for some reason.
And that's why I created this YouTube channel where I focus on the applied aspect of machine learning and deep learning.
And what's the, what's the YouTube channel where can folks find it?
Oh, if this search, my name, they will find it.
Well, it's just my name.
And you also published a book recently.
I did publish a book. So that's also very applied.
And it's more of a code book. It's called approaching almost any machine learning problem. It has less text more code.
A lot of people also said that you could have just released it on GitHub.
As it's grid me. So I said, no, then you have all the code and you can copy paste.
So it's better to release it as a book.
So yeah, the book start from some basics of machine learning goes a little bit into deep learning some NLP problem, some image problem.
I'm touching the surface of image and NLP and then showing you how you can use docker docker to deploy your machine learning models.
So yeah, it's like 300 pages, a small book, but a lot of code.
And now I always I have written this in the beginning of the book that if you didn't code you didn't learn so you do need to code to get something out of this book.
So if you're looking for something that.
If this if you think like this book is going to make you a Kaggle grandmaster or you're going to call my data or anything.
This book is not for you.
It can just give you ideas on how to.
Who is it for? Who is it for then?
What is the specific problem that it's all?
Yeah, it's like it can give you ideas on how to approach different kinds of problems.
So when you're starting with machine learning or if you have done some theory on machine learning.
Then you can use this book and implement some examples from the book.
And you can understand more like like categorical variables is my favorite chapter.
So I spent quite a lot of time there.
And there's there's a lot of things there that you don't learn in theory.
So you will only learn it then.
When you when you're solving some problems like entity embeddings.
And nobody is going to teach you how to convert categorical variables into embeddings.
And how to use a neural network there.
So these kind of things you you probably won't learn in theory easily.
And yeah.
Yeah, that's it.
Besides from Kaggle, what resources, you know, courses, books, even papers, most influenced you and your your career.
Everyone's lectures were quite nice.
I was not I was not very good in attending the lectures at my own university.
So I learned everything on my own.
So whenever I saw something, it was like a entity recognition model in head.
If you don't understand something, Google it.
So I used to Google and I used to find different kinds of paper.
There long ago, there was a paper called a natural language processing almost from scratch.
I like that paper a lot.
And it has all these different kinds of problems related to an LP.
It's a big paper.
It's a very easy read.
And but nowadays, everyone is using transformers for everything anyways.
So it's a different story.
But yeah, what helped was lectures from Andrew, a lot of different kinds of YouTube videos, tutorials, and also quite a lot of googling, reading a lot of research papers.
I used to implement research papers at some point, but now I don't have the time.
So I've lost my touch.
What are you, what are you most excited about?
Kind of beyond your work and as you look out onto the horizon of machine learning and deep learning, anything.
You know that you're kind of playing around with or keeping an eye on because you think it could be pretty interesting.
I'm playing around with a lot of things actually.
I'm juggling so many things right now.
I lose track, but I think.
Machine learning and data science in general is reaching such a stage where probably you won't go a lot going forward.
So if you have to train a model and if there's tools available that can train models for you, do all kinds of a parameter tuning in like few commands.
Why would why would industries want to spend time hiring so many data scientists?
So I would suggest like people should try to focus on building these kind of tools.
They think the future is in is an auto, auto X.
It is going there, right?
So everything is getting automated.
Now now you have like you have pre-trained models for doing almost everything and you just fine tune them on very small set of your data and it just works.
It works out of the box.
So you don't even need to invest so much time thinking about how would you approach these kind of problems.
So I'm talking totally from the applied perspective.
There's a lot going on in research and we are using that research.
Yeah.
Yeah, so I do think like if I have to train a model for classification right now or for entertainment or for different tasks of natural language processing, I would probably just throw it inside
Auto and P and C what performs the best so that would be my first step and then extract the model and then do some build something else on top of it.
Like even on Kaggle when you're when you're working with different models, you just take an average of all of them and it becomes an ensemble.
So things like that and yeah, infrastructure is getting cheaper and cheaper day by day.
Would you worry that that approach like a given model that auto auto and LP chooses as the best is like a local optima and some other model that auto and LP didn't do as well on could have been manually optimized.
Yes, yes, sure computers are wrong a lot of time right.
Yeah, it is indeed possible so there are many things that you can do in simple ways.
So as a human and like as a data scientist as a data scientist from this generation.
If they're presented with 304 samples of text what they are going to do is to start using transformers on on it and apply a fancy bird model right nobody's even going to try TF IDF and large degradation maybe that performs well.
So you you never know so there can be situations in which yeah, probably auto and LP didn't choose or any kind of auto ML solution didn't choose the best model.
But you're trying more than you might have otherwise is the yeah, yeah, awesome awesome.
Well, I was like thanks so much for taking the time to chat about what you're up to has been great getting to learn a bit about auto and LP and yeah, a little bit of your story.
Thank you very much for the invitation and it was great talking to you Sam.
Thank you.
