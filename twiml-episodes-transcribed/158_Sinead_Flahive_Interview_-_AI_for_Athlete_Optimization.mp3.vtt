WEBVTT

00:00.000 --> 00:16.200
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.200 --> 00:21.320
people, doing interesting things in machine learning and artificial intelligence.

00:21.320 --> 00:33.800
I'm your host Sam Charrington. Perhaps especially appropriate given that much of the globe

00:33.800 --> 00:38.440
is glued to the world cup at the moment, we're excited to kick off this week a series of

00:38.440 --> 00:45.400
shows on AI and sports. While I'm not personally the biggest sports fan, my producer Amari is

00:45.400 --> 00:50.240
a huge sports follower and this series has been something he's wanted to see since we started

00:50.240 --> 00:56.720
working together. So if you like these shows, be sure to hit him up on Twitter at at Twimble

00:56.720 --> 01:04.480
underscore Amari, I am AI. Before we get into the show, a quick update about July's Twimble

01:04.480 --> 01:11.120
online meetup. On July 17th at 5 p.m. Pacific time, Nick Teague will lead a discussion on the

01:11.120 --> 01:17.880
paper Quantum Machine Learning by Jacob Biamonte at all. The paper explores how to devise

01:17.880 --> 01:23.480
and implement concrete quantum software for accomplishing machine learning tasks. If

01:23.480 --> 01:30.360
you haven't joined our meetup yet, visit twimbleai.com slash meetup to sign up. Also, be sure

01:30.360 --> 01:35.360
to sign up for our weekly newsletter. I recently shared a write up detailing the machine learning

01:35.360 --> 01:40.440
and AI job board we're working on and got a ton of encouragement and interest. To make

01:40.440 --> 01:48.840
sure you don't miss anything, head over to twimbleai.com slash newsletter. In this episode, I'm joined

01:48.840 --> 01:55.560
by Shanade Flahive, data scientist at Dublin, Ireland based Kittman Labs. Shanade joined me to

01:55.560 --> 02:00.760
discuss Kittman's athlete optimization system, which allows sports trainers and coaches to

02:00.760 --> 02:07.880
collect and analyze data for player performance optimization and injury reduction. In our conversation,

02:07.880 --> 02:13.080
we take a look at the different ways this data is collected and analyzed and the various modeling

02:13.080 --> 02:19.480
techniques Shanade and her team use to create player insights for coaches and trainers. Shanade also

02:19.480 --> 02:24.840
shares her view of the data driven sports landscape and how it's evolving. Enjoy.

02:28.440 --> 02:33.720
All right, everyone. I am on the line with Shanade Flahive. Shanade is a data scientist with

02:33.720 --> 02:39.640
Kittman Labs based in Dublin, Ireland. Shanade, welcome to this week in machine learning and AI.

02:39.640 --> 02:44.280
Hi, Sam. Thanks for having me. I delighted to be here. Let's get started by having you tell us

02:44.280 --> 02:50.360
a little bit about your background and how you got started and interested in data science and machine

02:50.360 --> 02:57.080
learning. Yes, so I took not a direct route into the data science area. I initially studied

02:57.080 --> 03:03.240
financial mathematics and actuarial science in my undergraduate towards the end of the

03:03.240 --> 03:11.640
undergraduate. I was more interested in more statistical type-based modules and my university was

03:11.640 --> 03:18.040
very accommodating and allowed me to kind of change the traditional modules that I should have

03:18.040 --> 03:24.920
been sitting and I ended up doing more statistics modules than traditional. So while my undergrad

03:24.920 --> 03:30.040
degree is financial maths and actuary, I traditionally probably have more of a statistics degree.

03:30.040 --> 03:37.320
So I began working straight out of university for a statistical analysis consulting company

03:37.320 --> 03:45.320
where I was doing statistical analysis and using software and for consulting, doing lots of

03:45.320 --> 03:51.320
projects across lots of different areas and I was really enjoying it and I liked the variety and

03:51.320 --> 03:55.160
the different types of data sets that I was working with. So I continued on myself and did a

03:55.160 --> 04:02.280
masters in business analytics. So that steers me more towards the data science role. So that position

04:02.280 --> 04:08.200
I grew into more of a data science role there in terms of the manipulation of data, performing

04:08.200 --> 04:15.160
more analysis into deployment of models going forward. So when I moved on from that position,

04:15.160 --> 04:21.160
one of the things that struck me was I was very much more enthusiastic about working with data sets

04:21.160 --> 04:26.760
that were interesting. So there's an abundance of data out there as we all know and it's growing

04:26.760 --> 04:33.640
very regularly. That I was more enthusiastic and excited about data sets that I had a passion for

04:33.640 --> 04:40.200
and I would be quite a keen sports fan myself. So when the opportunity came to work with a sports

04:40.200 --> 04:46.760
data set as I get to do daily now and in Kidman Labs where I'm working, that I jumped at the

04:46.760 --> 04:52.600
opportunity. So that was how I got into working in data science at sport is kind of combining two

04:52.600 --> 04:57.720
key passions of mine, the data science side of it and getting to work with a really interesting

04:57.720 --> 05:04.280
data set as well. Oh, very nice. What are your favorite sports? I would be a keen rugby union fan.

05:04.280 --> 05:10.840
Okay. And so in Ireland we've been we're quite successful in rugby union. We recently won a

05:10.840 --> 05:17.640
national competition where we play our closest competitors called the Six Nations and the Irish

05:17.640 --> 05:21.880
rugby team who are one of our customers here in Kidman Labs won that outright. So they beat

05:21.880 --> 05:26.520
every other team and we were involved in that and contributed in some small way I like to think.

05:26.520 --> 05:33.080
Awesome. Yeah. And in Ireland then we have our national sports. So they're amateur sports. So

05:33.080 --> 05:39.480
there's Gaelic football and hurling which is quite a it's kind of like hockey but at a much faster

05:39.480 --> 05:44.760
pace that we have here in Ireland. So they would be kind of my own sporting. I don't play any of them

05:44.760 --> 05:53.560
mind you to follow and to keep up with. Awesome. And so what does Kidman Labs do and what's

05:53.560 --> 05:59.080
its role in the sporting arena? Yeah. So here at Kidman Labs we have developed an athlete

05:59.080 --> 06:05.000
optimization system. So our athlete optimization system enables training and medical staff

06:05.000 --> 06:10.440
for elite sports teams teams to collect and analyze their data in that way they can optimize

06:10.440 --> 06:16.520
performance and they can reduce the risk of injury because we collect electronic medical

06:16.520 --> 06:25.240
medical records from our teams as well. So as we have Kidman Labs have a dashboard that

06:25.240 --> 06:30.760
allows the practitioners to look at the current status of all of their athletes based on their own

06:30.760 --> 06:37.640
data collected in their systems. So we have certain ways that data is ingested into our system.

06:37.640 --> 06:43.240
So we have we have our own app that athletes can enter in different things on so kind of subjective

06:43.240 --> 06:48.360
measures. How are they feeling? How did they sleep last night? Do they have any muscle soreness?

06:48.760 --> 06:54.520
We also have as I mentioned the electronic medical record system where the medical staff in the

06:54.520 --> 06:59.800
the clubs would enter injuries when they occurred where in the body they are. So that gives us

06:59.800 --> 07:07.000
a lot a lot of information on the injuries. We also allow the practitioners to impose other

07:07.000 --> 07:14.200
kind of objective tests. So if an athlete was doing a screening it's what we tend to call it.

07:14.200 --> 07:19.800
They would do things like check their hip mobility or their ankle mobility and there's

07:19.800 --> 07:25.400
different tests that do all these things. So the coaches would enter that information for their athletes

07:25.400 --> 07:33.080
in their system as well. And then we also have a capability that allows our teams to ingest

07:33.080 --> 07:39.800
all of the GPS type metrics. So you've probably seen it on the on the the TV sometimes they wear

07:39.800 --> 07:45.800
the the vest that have the GPS monitors inside them. And that that that all gets an ingested into

07:45.800 --> 07:51.240
into our system as well. So we have a we're in a unique position then whereby we are allowed we

07:51.240 --> 07:57.240
are able to link all of that injury from information to all of the other information that the athletes

07:57.240 --> 08:05.080
provide or that their coaches give us. And one of our one of our aims is to identify and drivers of

08:05.080 --> 08:10.440
injury risk based on all that information that we collect from the from the athletes. Interesting.

08:10.440 --> 08:18.360
So you're collecting a lot of information off the field. You mentioned the GPS vests. Are you also

08:18.360 --> 08:26.040
is there some way that you're capturing? You know rugby. It's a contact sport from what I've seen.

08:26.040 --> 08:32.040
Is there a way that you're capturing impacts and contact and that kind of thing as well?

08:33.400 --> 08:39.080
Not directly. So through the through the GPS metrics and that come through from the providers.

08:39.080 --> 08:43.720
There's lots of different vendors that we work with who provide this information. They're one of

08:43.720 --> 08:50.120
their metrics that they would include would be number of impacts. Okay. So we get that information.

08:50.120 --> 08:56.680
It comes in as part of the the GPS that type of data we would consider workload data.

08:56.680 --> 09:01.880
So it's what what what what exertion to the athlete perform on the pitch whether it was in training

09:01.880 --> 09:06.760
and sometimes during in games in in some leagues. They're not permitted to wear the GPS units during

09:06.760 --> 09:12.120
games. But if it's available, we have it. When the injury information comes in in our

09:12.120 --> 09:17.720
Electronical Medical Records, the practitioners would tag whether the injury came from contact

09:17.720 --> 09:22.920
activity or a non contact activity if it was just a something that flared up over time.

09:23.640 --> 09:32.120
And so the sports teams now have you know you've mentioned already tons of different sources of

09:32.120 --> 09:40.360
data and I'm envisioning other things like Fitbit devices and you know even data that's extracted

09:40.360 --> 09:46.920
from like computer vision models of the field, the pitch and the players. You know I imagine

09:46.920 --> 09:52.520
these teams are you know quickly gotten to a point where they're a wash and data and need to

09:52.520 --> 09:57.960
figure out how to use that data to be more competitive. Like what does the overall landscape

09:57.960 --> 10:03.000
of data driven sports look like from your perspective? Yes. So as you mentioned and you're

10:03.000 --> 10:07.880
100% correct there's the velocity volume and variety of data being collected these days.

10:07.880 --> 10:13.160
It's such in a fast-paced sporting environment. It can cause a problem which here we kind of

10:13.160 --> 10:18.920
call paralysis by analysis. I think that's a general general term anyway. What we have found is that

10:18.920 --> 10:24.920
things like the tech wearables, the Fitbits etc. They deliver data and measurements back to the

10:24.920 --> 10:29.960
athletes. However the the kind of crocs of it and where we kind of come in is they get the data

10:29.960 --> 10:35.000
measurements but it's the real insights based on the linking of all the data together. It is what

10:35.000 --> 10:39.640
we do here at Kipman Labs. So what we've kind of found is that while you have more data

10:39.640 --> 10:44.440
that can lead to more decisions but more data here does not necessarily mean that you have

10:44.440 --> 10:51.160
better decisions. So our key service I suppose from an analytical point of view that we provide

10:51.160 --> 10:56.840
is driving insights for our teams based on the data that they put into our system.

10:56.840 --> 11:05.400
And so those insights it sounds like are primarily around you know performance and how to optimize it

11:05.400 --> 11:15.800
on well let me ask is it on an athlete by athlete basis or is it on a team basis and is it

11:16.440 --> 11:26.120
well let's start there. Yeah so our data set we have like we have our system in 120 sports teams

11:26.120 --> 11:32.760
across 35 leagues so therefore we have a lot of data ingested. What you will find is that

11:34.040 --> 11:40.200
the insights that that you would discover they vary sport to sport position to position

11:40.200 --> 11:44.520
and as you mentioned athlete to athlete and that's one of the things that that's really

11:44.520 --> 11:50.760
interesting about our problem here when we try to solve based on say one of the things as I

11:50.760 --> 11:58.360
mentioned was based on injury risk as is in most areas if we go down and down to athlete level

11:58.360 --> 12:03.000
you will get small sample size even though some of our teams that have them with us and they have

12:03.000 --> 12:07.720
them with us for four years so we have a lot of bank data built up with those customers which

12:07.720 --> 12:13.880
makes it easier for a sport. There's interest across all the levels a lot of time there's comparison

12:13.880 --> 12:18.840
so what you'll find is that teams will be interested in comparing say we're just going to like

12:18.840 --> 12:23.400
their forwards to their backs and what are the key differences between those. At the moment at an

12:23.400 --> 12:30.920
athlete level like I said small sample size very very localized insights it's quite good to

12:30.920 --> 12:35.720
that we can we can turn those over but from a comparison point of view suppose positional

12:35.720 --> 12:41.000
level would be good and then looking across the different injury types as well so like one of the

12:41.000 --> 12:47.560
things that that we we understand here at Ekitman Labs is that the actual manifestation of injuries

12:47.560 --> 12:53.080
is quite complex and you could have like obviously the drivers for a hamstring injury are going

12:53.080 --> 12:58.840
to be quite different from the drivers for a shoulder injury for example so they're the kind

12:58.840 --> 13:02.600
of different areas that that people would like to compare different types of injuries different

13:02.600 --> 13:08.920
positions in their teams and we provide the the analytical solution for for our teams to be able

13:08.920 --> 13:18.840
to do that. And you mentioned in your introduction that you apply this model or the the Ekitman works

13:18.840 --> 13:27.000
with some of your favorite sports rugby and some of your national sports but what other sports do

13:27.000 --> 13:33.320
you have you applied this model to? Yes so we have like I said rugby would is one we have soccer

13:33.320 --> 13:39.160
teams we have cricket teams we have baseball teams basketball American football

13:39.800 --> 13:45.800
then Australia we've probably league so we do have like a broad range of sports across a broad

13:45.800 --> 13:50.600
range of continents that that that contribute information into our system. Okay and so you're

13:50.600 --> 13:57.960
now a data scientist in a playground of you know data around your favorite topic how do you

13:57.960 --> 14:04.440
approach trying to deliver insights to these teams with this data that they have?

14:05.320 --> 14:10.440
Yes so we work quite closely with our applied sports science team and our applied sports

14:10.440 --> 14:15.240
science team here at Ekitman Labs they deal directly with our customers find out their needs

14:15.240 --> 14:20.200
and and figure out and if they're there's certain areas that we should be looking at from an

14:20.200 --> 14:25.400
analytical point of view. So our main kind of application and our main insights driver

14:25.400 --> 14:31.160
Ekitman Labs and what we've we've developed and what we've been working on to to help reduce

14:31.160 --> 14:40.040
kind of injury risk across our teams we work on the basis that we that coaches would like to know

14:40.040 --> 14:45.960
what are the things that are driving injury risk so they collect all of this data and in our system

14:45.960 --> 14:51.320
you can view that on a dashboard so when they come in they can see the dashboard which allows

14:51.320 --> 14:58.600
them to view the current status of the athletes and they can then set alarms on that data and alarm

14:58.600 --> 15:04.840
being go red if a if an athlete gets into a certain band or a certain range or over a certain

15:04.840 --> 15:10.040
amount of a variable or it can be green if you're happy with them the color coding think kind of

15:10.040 --> 15:16.200
depends on the the personal preference of the practitioner. So our practitioners traditionally

15:16.200 --> 15:21.080
could just set their alarms based on their own intuition and their own judgment

15:21.080 --> 15:26.760
and expertise but where we come in and where the the main analytics that that we work on

15:26.760 --> 15:34.680
here at Ekitman is to provide data behind that and to potentially provide data driven alarm

15:34.680 --> 15:40.600
thresholds for the practitioners to set that will fire when their athletes get into a certain

15:40.600 --> 15:47.880
range or you think they might be in trouble. So maybe to to apply some examples and be a little

15:47.880 --> 15:54.840
bit more concrete here it sounds like you're saying that traditionally or maybe not traditionally

15:54.840 --> 16:01.960
but you know one way of approaching keeping athletes healthy and in high-performance zones

16:01.960 --> 16:09.800
would be to set a threshold that said you know that would allow a you know one of the sports

16:09.800 --> 16:14.520
medicine staff out of team to say well you know I'm concerned about overtraining I don't want

16:14.520 --> 16:21.880
this athlete to train you know more than X hours a day and so that's a intuition based

16:22.680 --> 16:29.880
threshold that they might set but you're maybe doing some analysis or building some models based

16:29.880 --> 16:36.840
on the data that you've collected to allow them to more dynamically optimize those kinds of

16:36.840 --> 16:41.480
thresholds maybe you know based on based on this starting point maybe you can give us some specific

16:41.480 --> 16:47.560
examples and the kinds of you know modeling models and approaches that you might use for different

16:47.560 --> 16:54.520
teams. Exactly so suppose from the first point is that we initially when we started on this

16:54.520 --> 17:00.280
journey relating injury risk to the different metrics in our system the alarms that we set up

17:00.280 --> 17:05.400
they were on a univariate level so we started small and kind of built it up along as as we

17:05.400 --> 17:11.400
continued through our journey at a univariate level we have a system in place that a practitioner

17:11.400 --> 17:16.040
can set an alarm like you mentioned a certain number of training hours per day I mean we provide

17:16.040 --> 17:21.400
the analysis for them to check that alarm and see how relevant that alarm is based on their

17:21.400 --> 17:28.040
injury risk. And meaning meaning what specifically so one thing you're doing is you're allowing them

17:28.040 --> 17:36.120
to pull different data sources together so they can even easily track how many hours a given

17:36.120 --> 17:42.280
athlete has been training. Exactly so once they put the data into our system it's all

17:42.280 --> 17:47.160
collated into essential repository and metrics that they wish to view or that they wish to set

17:47.160 --> 17:50.600
alarms on that they wish to monitor for their athletes are displayed in their dashboard.

17:51.240 --> 17:57.800
So not not only are the I suppose the raw metrics displayed we also allow them to create different

17:57.800 --> 18:03.160
aggregations and things that they might be concerned about as well so what you'll find is kind of

18:03.160 --> 18:08.920
you know in a sports related area obviously if you're coming up to a game the things that happen

18:08.920 --> 18:13.320
in the few days leading up to a game can be very important to determine whether an athlete is

18:13.320 --> 18:19.080
going to perform well in that game or not. So we allow them to to create different aggregations

18:19.080 --> 18:25.960
for example their workload over the last seven days their max speed over the last seven days

18:25.960 --> 18:31.720
that they did in training we allow them to look at different metrics in those types of aggregations

18:31.720 --> 18:36.520
and also what is very important and what we found to be important is like the change in those

18:36.520 --> 18:41.880
metrics leading up to the game so we allow them to calculate z scores and complex n scores so

18:41.880 --> 18:46.920
they have an abundance of data that they can display across their dashboard and set alarms

18:46.920 --> 18:53.400
off that that I'm concerned if athlete goes into does as you said over XR as a training per week.

18:53.960 --> 19:00.280
The analysis that we perform then takes that data so for their positional group or that

19:00.280 --> 19:07.320
that they they're involved in and looks at how that that metric relates to the different types

19:07.320 --> 19:12.120
of injuries that other people in their positions would have gotten so that if they're concerned about

19:12.120 --> 19:17.480
that they can set the alarm or change their alarm based on what the data is actually telling them

19:17.480 --> 19:23.080
and use that then on top of their own intuition. Tell me a little bit about the kind of the modeling

19:23.080 --> 19:28.680
process and how you as a data scientist have built up these models over time.

19:28.680 --> 19:34.920
Yeah so the most recent I suppose model that that we were working on was what I was talking

19:34.920 --> 19:39.400
about previously was all at a uni-variate level so is this one metric related to injury risk

19:39.400 --> 19:46.040
and more recently we've developed into the multi-variate alarm so the idea with that is that

19:46.040 --> 19:51.960
the customer is identified where their injury problems are for example they look at a diagnostic

19:51.960 --> 19:58.840
injury for their season they had a really bad hamstring problem so they will access our system

19:58.840 --> 20:03.880
and they'll say okay look at my for the season look at my hamstring injuries and we have been

20:03.880 --> 20:08.840
built models that will turn around and tell them different types of injuries for different

20:08.840 --> 20:14.280
combinations of metrics. So the idea then is that they will choose an injury level that they're

20:14.280 --> 20:19.640
comfortable with or they'll see affwatt at what values for different combinations of metrics

20:19.640 --> 20:24.120
was were my athletes at the higher injury risk and then they can set that for their group of

20:24.120 --> 20:27.880
for their group of athletes so going forward into next season hopefully they'll get a warning

20:27.880 --> 20:34.760
if this injury risk increases. So from our point of view then at the on the data science team

20:34.760 --> 20:40.200
the key thing from us from a machine learning point of view is that our analysis has to be

20:40.200 --> 20:47.800
transparent so while there are amazing models out there that would give you a really good risk score

20:47.800 --> 20:53.000
or a prediction as they say what we have learned and what I mentioned our collaboration with the

20:53.000 --> 20:59.400
sport science team earlier our customers in particular here they need to know why so here we need

20:59.400 --> 21:04.840
to know what's going on but going on in the box so the important thing for us is that the models

21:04.840 --> 21:11.880
that we use here are transparent interpretable and that we are able to build on top of the key

21:11.880 --> 21:17.480
metrics and figure out then what the optimal thresholds are for each of those metrics based on

21:17.480 --> 21:21.720
the injury risk specification for the injuries that the teams are interested.

21:21.720 --> 21:29.640
And so what models does that leave you to use? So it would be the more I suppose traditional models

21:29.640 --> 21:35.880
the ones that wouldn't be considered black box that we would so again models that are

21:35.880 --> 21:42.040
quite transparent and easily interpretable like in general and some of the analysis that we would

21:42.040 --> 21:48.200
perform you would find decision trees would be quite an interesting approach to this because you

21:48.920 --> 21:54.600
automatically get both your related metrics and your specific thresholds and that come true

21:54.600 --> 21:59.800
in terms of we then take out from that and kind of make it into a more consumable format

21:59.800 --> 22:06.120
because I suppose the kind of key crocs of that is that the practitioners and the coaches using

22:06.120 --> 22:10.600
our system they don't have a lot of time so if we put a big massive decision tree up in front of

22:10.600 --> 22:16.280
them that's not going to be easily interpretable or consumable for them so we need to and that's

22:16.280 --> 22:20.600
one of the things that's really good about being a data scientist here as well is that we will

22:20.600 --> 22:26.120
work with design and product and figure out how that's going to be implemented kind of from a

22:26.120 --> 22:30.680
conceptual analytical point of view into something that's easily digestible for our coaches.

22:31.480 --> 22:36.520
That's interesting. Can you talk more about that process? Where does it manifest itself? Does it

22:36.520 --> 22:43.880
impact the design that you will ultimately choose or the model type or parameters that you'd

22:43.880 --> 22:49.640
ultimately choose as a data scientist or is it more with a given model that you've chosen

22:49.640 --> 22:59.240
for other reasons like performance? The way you communicate and display the types of things

22:59.240 --> 23:05.000
that customers will want to know about from that model? Yes, we will spend a lot of time

23:05.000 --> 23:10.760
in the conceptual formulation phase where we will develop the algorithms. Our general process

23:10.760 --> 23:15.640
would be to potentially come up with two or three different algorithms, compare them, build

23:15.640 --> 23:21.080
prototypes so that the prototypes can then be validated so they can be validated both internally

23:21.080 --> 23:26.440
and with the other members of our team so with the product and design team with the engineers

23:26.440 --> 23:32.040
if it became that this algorithm needs to be implemented in our product. Can we can you support

23:32.040 --> 23:36.920
that? Can you help us with that? But also for the we would do external validation as well with

23:36.920 --> 23:41.400
our customers so that will be again where the collaboration with the sports science team would

23:41.400 --> 23:46.280
come in. They have the ability to take the prototypes that we build, show them to customers,

23:46.280 --> 23:51.640
we get feedback that gets implemented and then again it's a massive collaboration effort.

23:51.640 --> 23:56.200
When all of that comes together we go back to the design team, figure out how it's going to fit

23:56.200 --> 24:01.560
into the product and it moves on then to engineering into the product and eventually then into

24:01.560 --> 24:06.760
the hands of the customers themselves. And so have you had situations where you know for

24:06.760 --> 24:14.600
example you chose a simpler model because it was easier to present the results to customers or do

24:15.480 --> 24:22.200
use the model but invest extra on the presentation side after assuming a given model in place

24:22.200 --> 24:29.960
is in place. I suppose that there is a bit of both we would always aim for the optimal model

24:29.960 --> 24:36.440
but we would always vary in the back of our mind that the optimal model that we build in our

24:36.440 --> 24:43.160
prototype against our data set that it can be quite resource consuming and potentially not

24:43.160 --> 24:47.960
sustainable given the amount of data that we have that goes into the product. So we have

24:49.000 --> 24:52.920
like I said a lot of collaboration with the engineering team to make sure that the solutions

24:52.920 --> 24:57.640
that we come up with are indeed implement you are able to implement them into the product and that

24:57.640 --> 25:02.840
they won't break everything that it won't be very slow. So we would do a lot of testing with

25:02.840 --> 25:08.840
the different types of data all the aggregations that we have and we would try to come up with

25:08.840 --> 25:15.960
something that satisfies every member I suppose of the team involved and again is the best model

25:15.960 --> 25:21.400
that will get good insights for our customers that that's the most important thing is that the

25:21.400 --> 25:28.120
the customers are getting the insights the why I'm getting such an injury risk score and not just

25:28.120 --> 25:34.760
what the percentage is. And out of curiosity do you use a lot of ensembles of models or do they

25:34.760 --> 25:42.360
tend to be simpler models? We tend to keep it more simple. Okay again at the presentation. Yeah,

25:43.800 --> 25:51.160
the interpretability of models that we would use. I mean in saying that the data science team

25:51.160 --> 25:58.680
we like to be innovative in ourselves so we would have departmental workshops whereby we would

25:59.800 --> 26:05.320
do things that on the side like that try different types of models see how they would work

26:06.120 --> 26:12.840
while we're always dripping that forward. So at the moment we are focused on actionable insights

26:12.840 --> 26:18.280
key deliverables that the practitioners can combine with their own intuition to make their decisions

26:18.280 --> 26:24.200
but that's not to say that that's going forward for different areas that we might be getting into

26:24.200 --> 26:29.320
that that models like that wouldn't be would be more applicable. How is your product delivered?

26:29.320 --> 26:36.520
Is it a cloud-based solution where your customers are uploading their data centrally or is it

26:36.520 --> 26:45.560
mobile or desktop? So there's a web browser that the coaches and the backroom staff I suppose

26:45.560 --> 26:51.320
get access to to login to where everything is displayed and through there they would upload

26:51.320 --> 26:59.560
their information in terms of the EMR, electronic and medical records. From the other ways we

26:59.560 --> 27:05.560
collect data we have a mobile app so we have a mobile app for the athletes themselves so they

27:05.560 --> 27:10.280
install the app and they put in their subjective type measures. We have another mobile app for the

27:10.280 --> 27:15.400
coaches which provides a summary of all of the information that they would see on the dashboard

27:15.400 --> 27:22.040
when they log into the web app. They get that on their phones and you find I think in sports

27:22.040 --> 27:26.680
complexes or in the training grounds particularly throughout the pitch they wouldn't have a lot of

27:26.680 --> 27:33.800
Wi-Fi so having something on the mobile is more efficient for them. We have the web browser as I

27:33.800 --> 27:39.960
mentioned and we also have a motion capture data collection system which is quite interesting

27:39.960 --> 27:49.240
so we have a system where you stand in front of a camera and it uses infrared sensors to detect

27:49.240 --> 27:55.480
the athlete and we take them through a series of movements and they kind of follow a demo as

27:55.480 --> 28:00.600
it's going through, perform the movements and we get all that data back into our system as well.

28:01.240 --> 28:06.920
And what types of analytics does the motion capture roll up into?

28:06.920 --> 28:12.280
So again the outputs from that would they get cleaned and transformed but they would then

28:12.280 --> 28:17.240
essentially just become metrics on the teams can put onto their dashboards as well so you would be

28:17.240 --> 28:24.600
looking for things like angle of your internal shoulder rotation or how aligned were your knees

28:24.600 --> 28:29.960
when you were doing a squash these kind of things so we have metrics that get derived automatically

28:29.960 --> 28:35.000
from them from the system. A lot to do with alignment between say the left and right side of your

28:35.000 --> 28:40.280
body and how good your your movement is as you go through the different movements we have like

28:40.280 --> 28:48.040
squats, lunges, y balance these kind of different things. I was just talking to someone about

28:48.040 --> 28:54.360
they were someone made a comment about how they wanted to get a like a workout coach or something

28:54.360 --> 28:59.640
like that so that they can you know get an analysis of their technique. Do you see that kind of

28:59.640 --> 29:08.520
thing being more commoditized and available just via you know mobile devices and you know deep

29:08.520 --> 29:14.200
learning just kind of point the camera at you while you're doing your squats and it'll tell you

29:14.200 --> 29:20.200
how good your technique is. Yeah a hundred percent I think that that's where where everything is

29:20.200 --> 29:25.240
going. I mean like I mentioned that that our system that we have here is at the moment only

29:25.240 --> 29:32.120
currently provided to like elite teams and professional athletes but in saying that I mean with

29:32.120 --> 29:38.360
the kind of the prosumers of the technology like someone trying to better themselves saying

29:38.360 --> 29:44.440
in a more amateur type setting or as an individual sport all of these things are applicable.

29:44.440 --> 29:49.480
And there's such developments again in technology I mean there's something new coming out every day

29:49.480 --> 29:55.720
that a hundred percent I I would believe that like personal personal workout or your your own

29:55.720 --> 30:02.120
smart trainer your own smart coach these things are definitely not too far down the line from us

30:02.120 --> 30:06.520
with with all of the developments and technology that are happening. Yeah having said that I'm sure

30:06.520 --> 30:12.120
listeners will tweet me like five to ten companies that are already doing this thing. Yeah I wouldn't

30:12.120 --> 30:16.520
I wouldn't doubt that. I mean I know one of the things that that kind of always interests me

30:16.520 --> 30:23.160
and I think that where we're going is kind of the smart sports equipment and I'm sure that there

30:23.160 --> 30:29.000
are companies out there for example if you're using a equipment in your sport like for example say

30:29.000 --> 30:33.720
a baseball bash I'm sure there are companies out there that are developing the technology to

30:33.720 --> 30:39.320
look at your motion as you swing it and hate it and I mean I I guess there are people out there

30:39.320 --> 30:45.800
even with footwear with boots or trainers that people are wearing as they're performing that to

30:45.800 --> 30:50.280
detect from that as well so the the abundance the data that that's going to be coming in it

30:50.280 --> 30:57.640
is is just going to grow exponentially I imagine. And so what do you see as the key challenges face

30:57.640 --> 31:04.680
by data scientists as they're working in fields like this with the the data volumes rising but

31:04.680 --> 31:10.280
where a very personalized approach needs to be taken. I think the key the key challenges

31:10.280 --> 31:18.760
would be in I suppose identifying the noise that that that that is their from us so as that

31:18.760 --> 31:24.520
becomes to kind of a more a more personalized level I think one of the one of the good things

31:24.520 --> 31:28.600
about these is that people like to compare themselves to other people of a similar nature

31:29.160 --> 31:36.120
and so the challenges would be providing good insights at a localized level with with small

31:36.120 --> 31:42.520
sample size whereas the kind of benefit of that is that you can yield from from a larger data

31:42.520 --> 31:49.000
setup of similar population and and if people engaged with that and get people engaged with

31:49.000 --> 31:55.640
in with different ways that they can engage their customers and the the consumers of this information

31:56.360 --> 32:03.800
potentially that would be where they can kind of overcome the challenges of small sample size

32:03.800 --> 32:08.680
and and and that that that would come from a more personal approach. Yeah I was going to ask a

32:08.680 --> 32:16.760
related question to this earlier even with with all of the teams that you work with and all

32:16.760 --> 32:23.880
of the athletes that play for those teams you know often there's a situation where the the events

32:23.880 --> 32:29.800
that you want to model against your your interests set you know our injuries which are relatively

32:29.800 --> 32:37.240
infrequent as compared to your overall data set is that a challenge in your case and how do you

32:37.800 --> 32:44.920
address that challenge. Yeah so within our data set like one of our challenges that we have

32:44.920 --> 32:51.960
is that you have teams that they screen differently so it's you can have a team that will require

32:51.960 --> 32:56.760
their athletes to go through screenings one day a week or you will have teams that will require

32:56.760 --> 33:01.240
their athletes to go through three days a week or five days a week or every single day depending

33:01.240 --> 33:08.040
on whether they're training or not. Okay so that can be quite quite of one of the challenges so

33:08.040 --> 33:13.160
it can be quite difficult to to compare two different teams if they have completely different

33:13.160 --> 33:18.440
training methods and when we're delivering our insights back to our customers that they they're

33:18.440 --> 33:22.760
aware that it's all their own data and if anybody wants something at a kind of a more aggregated

33:22.760 --> 33:29.080
level we will have the caveat that you are aware this is different sport different et cetera so

33:29.080 --> 33:37.240
used as a kind of a guideline. In terms of from our point of view we would have and it's quite good

33:37.240 --> 33:43.640
a lot of our teams would have compliance rules so they would require their athletes to screen

33:43.640 --> 33:49.000
a certain amount so we're aware of that so we know how often the athletes are screening and how

33:49.000 --> 33:54.760
they're meant to screen before we kind of attach any analysis to what they're doing so I mean for

33:54.760 --> 33:59.720
one team they screen three times another team they screen once a week we know that so we can

33:59.720 --> 34:04.040
then adjust any analytics that we perform for them kind of according to that and you would have

34:04.600 --> 34:09.560
as I said the compliance and the teams would expect I think some of them it can be in their

34:09.560 --> 34:14.120
contracts that they're required to screen a certain number of times a week and to provide data.

34:14.120 --> 34:20.520
How do you do that from a you know techniques perspective and is this kind of a sampling exercise

34:20.520 --> 34:28.760
or normalization exercise or how do you work with your data so that you can allow folks to

34:28.760 --> 34:33.880
compare metrics that have different you know volumes of sampling coming in.

34:35.320 --> 34:43.640
Yes so we in general like we would I suppose if have the problem of you would have missing data

34:43.640 --> 34:52.120
if athletes don't screen on certain days we tend to look to the customer and ask them so

34:52.760 --> 34:58.440
why we would have obviously there are statistical methods and as you mentioned yourself normalization

34:58.440 --> 35:04.520
and different things and taking the average over a certain period of time or rolling the last

35:04.520 --> 35:09.160
value that they had forward to all these different or imputing by a model all these different

35:09.160 --> 35:14.280
things we tend to work with customers and see how they would they would feel about that so what do

35:14.280 --> 35:19.960
they think would be the best approach for them for their own specific analysis and that would be

35:19.960 --> 35:24.440
kind of an option it's not currently built in but something that we are looking to to go towards

35:24.440 --> 35:29.560
so even if there is a very poor quality of metric collected they have the option not to include

35:29.560 --> 35:34.600
that in any analysis so for example if they only for the the period of time that they choose

35:34.600 --> 35:39.960
if they only have valid data for say 10% of the time just wrote not going to include that at all

35:39.960 --> 35:43.560
just don't there's not enough information for the the games if it's something that's screened

35:43.560 --> 35:48.600
quite frequently or something you'll find that that they might screen and collect for a while and

35:48.600 --> 35:54.760
then not collect after that so again it is quite and like I said we do with collaborate quite

35:54.760 --> 35:58.520
closely with our applied sports science team who are very close to the customers and take that

35:58.520 --> 36:03.720
guide and so for example one of the things that that if we were to impute by a model there would be

36:03.720 --> 36:11.080
the question that well how is that number calculated and step that kind of led would lead to more

36:11.080 --> 36:16.840
questions being asked so it is quite on a team by team basis and we would do a lot of collaboration

36:16.840 --> 36:21.160
of people and on making that decision for themselves okay so make sure they understand the various

36:21.160 --> 36:29.560
trade-offs and in surfacing those trade-offs via the tooling exactly yeah okay and out of curiosity

36:29.560 --> 36:35.720
mentioning tooling what kind of tools are in your tool chain so the data science team here

36:35.720 --> 36:42.920
acutement labs at the moment utilize mostly ore and python okay so a lot of our analysis

36:42.920 --> 36:51.640
is carried out in ore the prototypes that we build in ore using the shiny app that would be

36:51.640 --> 36:56.200
sent out for validation and where everything that that would eventually end up in the product

36:56.200 --> 37:01.240
kind of grows from but we're kind of developing python types of as well at the moment so

37:01.240 --> 37:07.000
there's a little bit of both going on and you mentioned shiny app what's that so shiny is

37:07.000 --> 37:14.200
part of the R studio package okay shiny allows you to take all the code and display it in a web

37:14.200 --> 37:20.200
browser and build your own little mini application basically so that's kind of what we do with the

37:20.200 --> 37:26.200
analysis and set it up so that the sports science team can can go and take it out to site and they

37:26.200 --> 37:30.200
don't need us with them that they can click around and make selections and it runs the analysis

37:30.200 --> 37:37.640
and displays things back to the customers okay so it sounds like you're actively involved in

37:37.640 --> 37:44.600
helping sports teams further their performance help their help keep their athletes healthy

37:44.600 --> 37:52.760
where do you see this going what are the opportunities for teams to use the data that they have

37:52.760 --> 37:58.600
available and the data that you know will soon be available to them yes so I mean at the moment

37:58.600 --> 38:05.720
we and up until now we've been very injury focused so again the idea would be to keep the athlete

38:05.720 --> 38:11.400
healthy that we would instigate the alarms that would allow them to identify when when a

38:11.400 --> 38:17.720
potential athlete is potentially at risk going forward and for them then to make their their own

38:17.720 --> 38:22.600
judgment and decision about what the action to take on that is so should they potentially reduce

38:22.600 --> 38:28.120
their training load or get them to screen again these these kind of things so from the injury

38:28.920 --> 38:33.880
type of view we've we've kind of been looking at individual risk factors the interactions of those

38:33.880 --> 38:39.880
and identifying kind of different types of responders then to to an action or an intervention

38:39.880 --> 38:44.920
and it's somewhere where we think that that that we might carry on with this and eventually kind of

38:44.920 --> 38:51.800
to work towards the the forecasting and proactive planning so to kind of look forward and say okay

38:51.800 --> 38:56.840
in the next week these athletes should only do this workload and this workload so so that's kind of

38:56.840 --> 39:02.520
the where where where we'd like to get into from an injury point of view also moving on from

39:02.520 --> 39:08.120
that then is is kind of what's becoming quite evident and important is kind of the performance in

39:08.120 --> 39:14.040
games so we have a lot of information about our athletes and that the information that they give us

39:14.040 --> 39:19.000
the pictures we call their psychophysiological metrics and at the moment we've been really

39:19.000 --> 39:24.680
injury focused with that but we're hoping to move into the area of in-game performance and see how

39:24.680 --> 39:29.000
the the information in our system relates to how they perform in games so there are lots of

39:29.000 --> 39:35.720
companies out there opta in stat etc providing breakdowns of of how players performed in games

39:35.720 --> 39:40.360
their technical metrics how many shots they missed they scored tackles missed

39:40.360 --> 39:45.960
interceptions etc depending for all the sports and and we're hoping to to get an area where

39:45.960 --> 39:51.560
we can relate what's in our system with with those things and move on to to performance in-game

39:51.560 --> 39:58.440
so we we we are hoping to to get an area a time where you can assess potentially when teams

39:59.160 --> 40:04.280
are more likely to beat a team they do these certain things and the fifth psychophysiological

40:04.280 --> 40:09.640
metrics that are in our system how we can relate those and and try and get our teams to to boost

40:09.640 --> 40:15.800
their performance and increase their chance of winning well shane thank you so much for taking

40:15.800 --> 40:21.560
the time to share a bit about what you're up to there it sounds like you're doing some really

40:21.560 --> 40:27.400
interesting things yeah and and long hopefully it will continue like that awesome thank you so much

40:27.400 --> 40:36.120
thanks them thanks for chatting to all right everyone that's our show for today for more

40:36.120 --> 40:42.680
information on shaneid or any of the topics covered in this episode head on over to twimmolayi.com

40:42.680 --> 40:50.600
slash talk slash 155 to follow along with the AI and sports series visit twimmolayi.com slash

40:50.600 --> 40:56.840
AI and sports and if you're a fan of the podcast we'd like to encourage you to click into your

40:56.840 --> 41:02.920
podcast app and leave us a five star rating and review they are super helpful to us as we push

41:02.920 --> 41:32.840
to grow this show and community as always thanks so much for listening and catch you next time

