Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
Alright Twimble listeners, this is your last chance to join the conversation and share
your take on home and personal AI.
Entries for our My AI Contest close on Sunday, February 25th at 1159 PM Eastern.
So go ahead, hit pause right now, jump on over to twimbleai.com slash My AI, check out some
of the existing entries and submit yours.
Before we move on, I want to give a quick shout out and thanks to everyone who has submitted
a video so far this week, so cheers to you Matt, Bradley, Lawrence and Mohit.
In this episode, I speak with Shreverm Notarajan, Associate Professor in the Department of
Computer Science at UT Dallas.
While at nips a few months back, Shreverm and I sat down to discuss his work on statistical
relational artificial intelligence.
Star AI is the combination of probabilistic and statistical machine learning techniques
with relational databases.
We cover systems learning on top of relational databases and making predictions with relational
data with quite a few examples from the healthcare field.
Shreverm and his collaborators have also developed Boost SRL, a gradient boosting based
approach to learning different types of statistical relational models.
We briefly touched on this along with other implementation approaches.
Alright, let's do it.
Alright everyone, I am here in Long Beach, California.
I'd say sunny Long Beach, California, but it's actually fairly late in the evening.
My first interview here at nips, in fact, the first time I've attended the nips conference,
and I've got the pleasure of being seated with Shreverm Notarajan.
Shreverm is an Associate Professor of Computer Science at the University of Texas at Dallas.
Shreverm, welcome to this week in Machine Learning and AI.
Hey, great to be here.
Why don't we get started by having you tell us a little bit about your background and
how you got interested in machine learning and artificial intelligence?
So my interests are in machine learning, artificial intelligence, primarily in this field called
Statistical Relational Artificial Intelligence, about which we are giving a tutorial tomorrow,
which is why I'm here at nips.
And the application and adaptation of these algorithms to many real problems, focusing
mainly on healthcare type problems, but also on natural language, understanding, finance
types of problems, but mainly focusing on healthcare problems.
How did I get interested?
I think it started from a grad school.
When I came here for masters at Oregon State, my interest was primarily just computer science
in the broad area of computer science.
But I took artificial intelligence courses under Professor Prasad Thali Polly, who went
on to later become my PhD advisor.
And I know I just liked the style of teaching.
I liked the fact that the artificial intelligence and machine learning techniques combined two
of my favorite topics, math and statistics, with computer science.
So the combination of math and computer science kind of looted me into AI.
So my thesis was primarily in artificial intelligence and machine learning, didn't have too much
healthcare problems.
When I did a post-doc at University of Wisconsin-Madison, Professor David Page and Professor Jude
Shavelic introduced me to the possibility of using machine learning and artificial intelligence
to solve healthcare problems.
We are looking at electronic health data, electronic health record data from Marshfield, Wisconsin.
That got me interested into kind of like personalized medicine, now it's called precision health.
So I got interested in adapting our algorithms for these problems.
So I think that's how my journey has happened so far.
Okay.
Great.
And so you mentioned that you're doing a tutorial tomorrow, right?
It's on statistical artificial intelligence or star AI, which is a great acronym.
Thanks.
What is star AI?
So star AI is the combination of probabilistic or classical statistical machine learning with
more logical or relational artificial intelligence.
The idea being that so the traditional artificial intelligence techniques and machine learning
techniques make a lot of assumptions on the data.
They need a lot of preprocessing, they need a lot of engineering.
Whereas what the star AI feels, star AI methods try and do is kind of look at the data in
a kind of a more holistic manner, look at the data in the natural form, in the relational
form.
Okay.
A classic example is most of these machine learning algorithms do what is called as an
IID assumption, independent and identically distributed, which means each of us is described
by the same features or same set of attributes.
And each of us is drawn independent of each other.
And then you learn a classifier, you learn a predictor on top of us.
Whereas if you look at real data, it's not true.
The probability of you having diabetes or me having diabetes depends on your parents.
And in my case, my parents and my parents and so on.
So the family history matters.
Sure.
I can see that's particularly not true in the case of diabetes or disease.
Are there other examples outside of the healthcare realm or that assumption?
Oh, even social behavior, right?
How some, even some small thing, the probability of somebody smoking depends on the fact that
their social network friend smokes are not.
How popular a particular person is, let's say in a scientific field, depends on who
is or her co-authors, his collaborators are, so how the popularity levels of the collaborators.
So if you take classical machine learning methods, they kind of project these multi-relational
data into a single fixed flat form and they operate on that.
Statistical relational learning methods on the other hand, allow the data to be in a
structural form.
And we try to learn using the power of first-order logic and relational logic.
So think of learning in a relational database using statistical methods.
Okay.
So that's why it's called statistical relational artificial intelligence, because it takes
the classical machine learning methods but kind of upgrade them to learn on relational
data, allowing data to be in the natural form.
So you take any data, electronic health records or classic examples, but you look at
social networks or you look at author citations, you look at movie databases, everything
right?
Most real data, now Google stores, everybody stores the data in a relational database.
But somehow when we are learning it, they are transformed into a different format.
They are aggregated, they are somehow shortened, and they are all compressed into one form,
and then the algorithms run on those compressed form.
In our case, what we are saying is, well, the data be in its pure form, which is relational.
Somehow, the models be learned at a relational level, which is why we sometimes call these
models as lifted models, because they are lifted from a flat representation to a much
more rational representation.
Now when you first started going through this, the first thought that jumped out in my
mind was relational database.
But then as you described it from the context of different distributions and kind of moving
beyond the independent, identically distributed assumption, I thought he's not talking about
relational database stuff.
But then you come back full circle to relational database.
Can you elaborate on the relationship between statistical relational AI and relational databases?
So relational databases are representations.
So relational databases are how the data is actually stored on whatever you're storing them
on.
The statistical relational AI says, I'll take the structure of the relational database and
learn a model upon the structure.
So what happens is, so let's just take a simple example in an IID framework in the classical
machine learning framework, each of us, you and I, your father, my father, we all become
individual examples for a classifier.
In these relational models, however, your family becomes one mega example, my family becomes
one mega example.
We may be connected, I don't know, when we go like 20 levels up.
But for whatever data we have, we could be different sets of mega examples.
And we are, so what these statistical relational learning does is learn at these mega example
levels, then at individual example levels.
So how are they related to databases?
If you look at a database and I start, let's say, with you, or let's say we start from
Shreya Ram, that's easier to explain in an academic context, then you go to my advisor,
my advisor's collaborators, my collaborators.
You can form a small network of people around me and basically use that information to predict
something about me, whether I'll be successful, whether I'll, I'm going to have a paper next
year or whether I'm going to have a grant next year.
You may be able to predict that by looking at whom I'm working with, what topics I'm working
on, how popular it is and so on and so forth.
When it comes to relational data, you're basically looking at all the relations that are connected
to me and figuring out how you can make some predictions about me.
This is true, not just in citations, it's true in many of these health care problems,
it's true in natural language problems, it's true in any real problem that you look
at.
You have objects, people are objects and they are related and you have objects everywhere,
people are objects, things are objects and emails are objects and projects are objects
and then we are all related to emails and projects and papers and so on and so forth.
Then you start talking about relations, how are these relations?
Maybe two people work on a project, right?
Two people work for another person and that person reports to an organization and the
organization is managed by somebody so there's always these situations that you can tease
out from a database.
So it's very related to a database and you can think of what we do as learning on top
of a database.
So I'm envisioning then, well I guess there's two directions that I want to go with
as one is the extent to which what you're specifically talking about is from an implementation
related to learning on databases, meaning taking advantage of schemas and primary keys
and things like that, that's one possibility.
But then I'm also hearing something that sounds to me like whereas we might have in traditional
machine learning a set of independent examples in statistical relational AI you've got this
set of examples and kind of overlaid by some connectivity graph and it sounds like
what you're doing in a sense is maybe finding different ways to kind of featureize that
graph and use it in the training process.
That's actually one one's reasonably simple way of understanding what we're doing.
Reasonably simple is a great place to start, that's true.
The reason I'm saying reasonably simple is because we really do not construct too many
features.
We let the features be defined based on the relationships themselves.
So for instance let's go back and take a classic example of movies, I want to predict
that the next Marvel movie, how much money is it going to make and then you want to
look at, well typically people look at history, how things change and so on.
But you could also look at the actors and you could look at the different actors that
are involved in a movie and you could say well these lead actors have typically tend
to get a lot of box office collection and so on and so forth.
So what we are trying to do is we are looking at the fact that one Marvel movie might
have five stars, five big entertainment stars, like big actors and then another movie
on the other hand might be carried solo by a single, you know, Iron Man, is Iron Man
even Marvel or are they decent?
That's Marvel.
Okay, I got that right.
So Robert Downey himself carries one movie with him, but let's say the Avengers are
some other one is carried by five, six people.
Does that necessarily mean that it's better than one?
We don't know that, right?
And what typical machine learning methods tend to do is kind of collapse them into one group.
We on the other hand say well, how about we let the data speak for itself?
We each of them combine some way and I look at the previous Avengers, look at who's directing
who's imparting.
So from that perspective, I'm not doing too much feature engineering, but I'm figuring
out how can I use this graph of people and make that use that to make a prediction that
I cannot with a normal machine learning algorithm.
The other problem is here is the problem, okay?
So let's say you in classical machine learning, you make an assumption.
Well, I'm going to look at the top five actors.
But let's say suddenly Marvel decides to make this mega Avengers movie with 20 actors,
right?
Okay, so you've got to go back to your model and say, ooh, man, we went from five to 20.
Right.
And he's just your model.
Exactly.
You might want to, you cannot generalize that easily.
Right.
We on the other hand make no assumption on the number of individuals, number of objects.
We can say as long as, you know, they're actors in a movie, we're going to use their
information to make predictions.
So that's where the power of relational representations come in.
Okay.
And they're kind of tied.
Actually, you ask me two questions.
One is on the implementation aspect, the one on the, and I don't think they are too different.
Okay.
Because when you think about how these are ultimately implemented, they are in some
sense implemented based on either a logical representation, the power of first-order logic,
as people know for a long time in computer science, or from a relational representation as
a database.
So it's I, so which is why in US, this is called statistical relational learning.
Because most of the work is done on top of relational databases.
In Europe, this is called probabilistic logic learning.
Because most of the machinery underlying is a logical representation.
And both of them do minimal feature construction.
They kind of learn at the level of the databases.
The cool thing is they are statistical and probabilistic because you can all of the data
to be noisy.
So that's what happens.
So our data can be noisy.
Our models are robust to noise.
Our models are robust to changing number of individuals, number of parameters, number
of objects in the world.
And so we learn at the level of objects and relations, not at the level of specific people.
Okay.
And I think that's why these models are powerful.
Okay.
And so how does it work?
How does learning work or how does kind of what's the, you know, the method that you
applied?
So what we do, for instance, I'm going to talk about one specific method that we do,
which is called relational functional gradient boosting.
There is this famous gradient boosting technique inside machine learning.
What we are doing is we are elevating it to the relational setting.
So it's called lifted gradian boosting.
And the idea is very simple.
So let's say I'm interested, let's just take a simple example.
I'm interested in predicting if somebody has a heart attack.
Okay.
Let's look at the database, let's say I'm a positive example in that I have a heart
attack.
Sam, you're a negative example, you look much fitter than I am.
So you don't have a heart attack.
And what happens is my model uses my attributes and it starts to learn.
And then it says, who is the father of this person diabetic, turns out my father is.
Okay.
And then is the, is the cholesterol level of this person pretty high?
If so, then the probability of a heart attack is, let's say, my model comes up with me having
a probability of 0.7.
It's a heart attack.
The same model comes with you to have a probability of 0.13.
Okay.
Now, my, because I'm a positive example, it should say that I have a probability of
1 to have a heart attack, but I said 0.7, which means 1 minus 0.7, 0.3 is the mistake
that the model makes on me.
Your probability should have been 0, because that's, you don't have a heart attack according
to the data.
But my model said 0.13 as your probability.
So, your weight, so to say, is minus 0.13, that is the mistake.
So, every positive example will have a weight of greater than or equal to 0.
Every negative example, like you, will have a weight of less than or equal to 0.
So, what we do is, we learn a small model, regression model, it would be a class which
says, if the father is, father of this person is diabetic, and if this person's cholesterol
level in the last three months is greater than, I don't know, let's say the H.D.L.
cholesterol is less than 30, then the probability of heart attack is this.
You could go do other things, for instance, that says, the relational power comes from
the fact that your class could say something like, if any of his close family members, and
this close family members could mean, my dad, my dad's dad, my dad's brother, my mom's
brothers and so on and so forth, and you will have completely different number of uncles
and aunts as I do, so you could say something like, if a close family member has a predisposition
for heart attack, then the probability of heart attack for me is so much.
And you could say that, because of the fact that I am not defining, I can define close
family member to be either an uncle or an aunt or a first cousin or my grandparents
on either side and so on and so forth, and we are not restricting the number.
You just look into the data and you can learn it.
So what the model does is, it tries to find out these factors that matter, put them together
and make a prediction, and then it finds which mistake, where it makes a mistake, learn
something else to fix that mistake.
So for people who don't have low H.D.L., and whose father don't have, let's say, diabetes,
it could be that they smoke a lot and drink a lot, and for them there is a different issue.
So what the model does is, oh, okay, I got freedom mostly covered, there's only a small
mistake on freedom, but there is this other person who has a heart attack, whom I am not
covered.
So let me focus on that person.
So it kind of fixes these mistakes repeatedly and learns one robust model in the end.
And it scales up pretty well, we have, the code is available online, so people can look
at that from my webpage as well, okay.
Simple things.
So one, you talked about heart attacks, smoking, cholesterol levels, these are all things
that I would associate as being features in a traditional model, but you said that you
don't really get into features as much with this.
How do you, how do you recognize all that?
So I have to make it clearer.
In the sense that these are all features, so everything is a feature.
What I'm saying is we don't really do a lot of feature engineering.
We don't say, oh, for instance, a beautiful question, right?
So let's say you go to the hospital, again, you're looking much fitter than I am, you'll
go to the hospital maybe once a year to do your annual checkup.
I go to the hospital three or four times a year, okay.
Now think about how a classical machine learning algorithm will do.
You will have one measurement of cholesterol, I will have four measurements of cholesterol.
I might have my A1Cs recorded every, actually four, it's good for a year, so four A1Cs
which is every three months, I'm going to record my blood sugar level.
And so I have multiple measurements and you have only one measurement.
How do we do this?
Well, classical methods say min, max, average.
So it takes an average of my cholesterol level, it takes a minimum maximum and puts them
as features.
This is what we call as feature engineering, okay?
We don't do that.
We say, if the cholesterol level in the last one year has ever been greater than this.
And that can be written by logic.
So logic statement says there exists a cholesterol level, this is called quantification in logic.
And so they kind of, so we don't even do that min, max, etc.
They can be done.
If needed, we can do it.
But doing that is a subset of what we can do.
We can just let the data as it is, which says that anytime in the last five years, Srinams
cholesterol level has been this, anytime, after the age of 55, this person's A1C has been
this.
And so we can tease that out.
So what I mean by feature engineering is we don't construct specific features for specific
problems.
You just let the data be in its natural form.
It still sounds like features.
It sounds like the if statement is like a one-hard encoding on whether their cholesterol
has been high.
So cholesterol is a classic example, okay?
Cholesterol might not be the best example to illustrate the difference.
Like the smoking properties of a friend, okay?
If you're close friends mocks, the probability of having a heart rate, I guess, 0.3 or 0.4.
How do you define that in a propositional or in a normal setting?
Okay.
I want to say if a closer and closer features fall down because they're not related
to the individual entity, whereas you've got this broad universes captured by all these
relationships.
And it's all features, but they're not like features of me.
It's features of this network.
It's features of this network and the size of the network varies between people.
Right.
So in the end, everything is a feature.
You're right.
Right.
But what is the feature of?
My point is that we don't do specific feature engineering continuously.
We let the data in its natural form, which is I could talk about objects and relations
and features of those objects and features of those relations.
Right.
Okay.
I just have to say, well, again, you might have five close friends.
I might have three close friends.
How do you encode this?
Right.
Right.
Right.
But as our models can just handle them because it just says, who is that one friend?
Is that two friends?
You can just look at it and you can learn from it.
It's easy to do that.
I thought you were going someplace that you didn't end up going.
It strikes me that you gave the example of the multiple.
You go into the hospital multiple times a year and get your four A1C readings.
I go in one and get my one.
And then you write your rule that basically looks to see if I have had a higher A1C reading
over the past 10 years.
It strikes me that you've lost a lot of information.
Maybe there's information in the fact that you actually want four times and I only want
one.
That's a great point.
It's not necessarily that we lose that information.
If you want to take that, you can record that too.
Actually, the two things that I want to clarify, first, I don't write the rules.
Because of this boosting algorithm, rules are automatically learned from data.
So we use only data and we use some domain knowledge.
Actually, I work on what is called a knowledge-based machine learning.
Now we call it a human and the loop machine learning.
There is a human expert.
We work with cardiologists.
We work with radiologists.
We work with neuro-radiologists and so on and so forth.
We have a lot of collaborations in medical groups, so that's a slightly more of the rules
learned by algorithms.
The rules are learned by algorithms.
What they give us is a little bit more knowledge.
They can say things like, this guy is much more difficult to predict than this person.
Then we tell the data, focus on this person or a person could come and say, I'll come
to that about the experts in a little bit after I answer this question.
So we don't provide the rules.
The rules are learned automatically from the data.
And the rules themselves are capable of learning that.
The rules themselves are capable of saying, if the number of misses matter, then it can
say, actually, if the number of misses is greater than 4, and in that number, if there
is a1c reading greater than this much.
So when you say you don't learn the rules, does that mean you don't learn?
No, we don't write the rules.
Right.
We learn the rules.
When you say you learn the rules, are you learning the parameters of the rules?
No.
You learn the rules themselves.
We learn the rules, along with the parameters, which is why, so if you think of complex neural
network or deep network, where writing these features out, the features themselves can
be learned by us.
So we learn these rules, which are basically if then else statements, and then we parameterize
them with probabilities, or real numbers, depending on whatever interpretation you take.
But we learn the rules from data.
So yeah, so we learn it from data.
Now, going back to the other point that I wanted to make about experts.
Experts can provide a lot of things.
Experts can tell us things like, in some cases, false positives are more important than
false negatives.
Okay.
So for instance, in recommendation systems, I'm recommending a job to you, or I get
these linked in recommendations, which keep telling me there is a post doc position open.
Okay.
And I'm like, come on, man, I did my time, that was seven years back, I don't want to
do this again.
Right.
Right.
So that is a false positive, it's a false positive.
There, from a recommendation system perspective, that needs to be eliminated.
If you tell me four jobs, only four jobs, and those are all relevant to what I'm looking
at, I'm going to trust your system.
So out of the potentially four thousand jobs, you may list only four jobs, but those are
important to me.
So I'll look at it.
If you give me 20 jobs, sort of which only four are relevant, the rest are not false positives.
Then I'm going to lose trust in your system.
Now think exactly the opposite side of an epidemic, you're interested in predicting Ebola,
for instance.
Right.
It's okay to quarantine four more people.
What is the worst thing they're going to do?
They're going to sue the city.
Million dollars each, at most 10 million dollars is what we're going to lose.
Think about releasing four people with Ebola into the general community, then it becomes
an epidemic and costs us billions of dollars just to talk in terms of numbers.
So what I'm trying to illustrate here is, in one case of recommendation system, false
positives are more important than false negatives.
In another case, false negatives are much more dangerous than false positives.
An expert could come and tell us, no, no, no, this is the case where this is more important
than the other one.
And what we do is we think of it as a knob and turn this knob on the classifier and say,
oh, you know what, that's what it is.
And in another example, a domain expert could say, Shriram, for people, what I have observed
in my experience is that, for people with high cholesterol, if they have high BMI, then
the risk of a heart attack is higher than people with lower cholesterol.
So even people with high BMI have two different effects.
They are not exactly telling me how these things influence, except they give a qualitative
understanding between two things and a target of heart attack.
So that's called monotonicity, synergies, they call qualitative relationships.
We can take that.
You can take preferences.
How do you encode that kind of thing?
I'll come to that in a second.
I'll just illustrate this one thing and I'll come to that.
So third thing, for instance, I was in a college town, Bloomington, Indiana.
Let's assume that you're trying to build a robot and the robot is sitting on top of
a building, having a donut in one hand, and observing how people stop at stop signs.
People stop at stop signs.
I'm in a university town, which means only 50% of the people stop at stop signs.
Then the machine could ask the human, hey, I'm looking at this data, but only 50% seem
to be stopping.
What do you think I should do?
Then the expert could say, well, I prefer that you stop at stop signs if it is safe to
stop.
Maybe there is an extreme case where, you know, you don't want to stop in a stop sign
because it's dangerous actually to stop, right?
You might put you in danger or somebody in the, I don't know.
I can imagine such situations with autonomous cars, for instance.
And you say something soft that says, I prefer that you stop at stop signs.
And then it says, okay, great.
Then what our algorithm does is it takes these statements as constraints.
And then it combines that with the data that I have, okay?
So there could be regions in the data where there is a lot of mistakes, like stop signs.
Then it says, ooh, the data has a lot of mistakes, but the expert has told me that this is
what he or she prefers.
So what I'm going to do is take what he or she tells me, combine it with my data.
And wherever the data conflicts the expert, or the expert conflicts the data, I'm going
to weigh that lower, wherever the agree, I'm going to weigh that higher, and kind of
incorporate that into my model.
So what I do is I get these human inputs as constraints to the learning algorithm.
And we have shown across several publications that such constraints improve performance.
And very recently what we have been trying to do is also do a little bit more, which is
let the algorithm ask questions, instead of the expert telling, so when we started this
research, the expert has to say everything that he or she knows about the problem.
Then we take them as constraints and learn.
But now we have gone the other way and we have said, we'll start looking at the data.
In the regions where we have extreme uncertainty about things that we are trying to learn,
we will solicit information from the expert.
So we call it actively advice, seeking advice.
So the key is for the machine to know what it knows, and solicit information about what
it does not know.
And the expert could say something, it takes that back into the model, adjust it again
because it's an iterative learning method that we have.
It can go back and try and fix its mistakes.
So let's put this on the stack after the answer to the encoding question.
But it strikes me there that there's a huge gap between what the algorithm is likely to
surface.
Some factor is, there's a high degree of ambiguity in some factor in something that you
can present to a doctor that makes that intelligible and kind of elicits useful advice to feed
back into the algorithm, which goes back to the encoding question.
Like how does all that part work?
Wonderful question.
That is a fantastic question.
And that is another reason why these logical models are more useful.
Okay.
Here's the problem.
If I now use a very complex learning system underneath, then it's going to say, feature
one, seven, six, three, five, four, two, one, seems very feared for me.
And I go to the doctor.
The doctors are going to know anything, right?
On the other hand, mine is a logical class.
It's an if-then-else statement.
So it could say, for people who have slightly lower HDL level, but on the other hand,
they triglycerate level seems to be good.
There seems to be a lot of distribution over these hot attacks and diabetes.
What do I do?
So what happens is because of the fact that we are learning these knowledge at the level
of the data themselves, the relational schema themselves, it's easier to present to the
doctor because they know what the schema looks like.
It's not just the doctors.
We work again with financial experts.
So again, our legal experts.
So we have these documents.
And we can say, well, you can't say something like, if the parse tree comes up with this
noun phrase, no, but we can extract the says that says this part of the sentence that
seems to be always conflicted with this part of the sentence, ways that.
And we can ask that question.
And that is only because of the fact that we are learning a much more representative model,
much more interpretable model than a typical complex model errors.
So that's because of the fact that you're learning if object, object type, objects value,
objects relations are like this, then something, right?
Okay.
So then you can present this to the user.
So that's another power that comes from these relational models that you don't get with
standard models.
Yeah.
So can you talk a little bit about how you benchmark this relative to other approaches
and what kind of results you've seen?
So that's something that we do all the time extensively.
What we try and do is we take these models and try to, for instance, if I have to run
a deep belief network or something, we try to create as we spend a lot of time engineering
as much as possible.
And try to engineer this a lot and then create many, many, many features.
And you try to use a standard machine learning algorithm as your baseline.
Now what happens is for the current data set, it might learn a good performance, right?
On your training set, it could actually give pretty good performance because most of these
machine learning algorithms can learn well if you engineer your features very well.
And that's doable.
We do that.
Right.
So the real problem comes when it comes to generalization.
So most of the benchmarking that we do is on generalization.
So for instance, you learn about whether a student works with a professor from one university,
right?
You test on that university.
Most of these algorithm works great.
Now what you do is you go to a different university and deploy this model.
Right.
And they kind of break down because you have to create new features, new things.
Whereas these relational learning algorithms, because of the fact that they learn not at
the level of the individual professors, but at the level of these groups of people, sets
of people, it's much more easy to adapt and transfer.
So when we do this benchmarking, we try to figure out, let's say, other networks, which
is why a classic example is, let's say you've used all of Shredam's family network data.
What I'll do is when I'm testing it, I'll go to Sam's data.
And I see, does Sam's data work on my model?
And then you do that with these classical methods, some of the times you don't get them.
Sometimes, if you know what you're going to test on, you can certainly engineer and try
and do that.
But most of the times, these relational models work beautifully on this problem as well.
Yeah, I hear people talk all the time about like overfitting on ImageNet and things like
that in the industry, in the field.
Do you feel that this notion of kind of focusing on generalization as opposed to performance
is like underappreciated or under pursued in the space? Definitely, definitely, but the
good thing is that there's been a new conscience on looking at generalization as an important
aspect.
But initially, there's been a lot of work on the science of experimental methodology of
machine learning.
There's been a lot of work on empirical machine learning.
I think that's an extremely important research direction.
People kind of lost a little bit of that oversight when we went and developed aggressively more
and more and more newer models.
But I think now people have started realizing that because of this abundance of data sources,
we have these multiple data sources that we have to somehow integrate and work with.
Suddenly, generalization again has become an important issue.
So from my limited whatever, 15, 16 year experience, I've seen that there is a lot of interest
now in making sure that we build models that generalize across populations, across data
sets, across diverse data sources.
And I think that's certainly an important research direction.
And which is one of the reasons we want to make sure that any model that you develop is
not pipe to that particular thing.
Right.
Which is why when I see many of these people talk about AI, we're all a little bit worried
because it is such a specific domain specific solution that you are always worried when
it's going to break.
And it could break very easily if you don't think about generalization.
Are there standard and well accepted ways of measuring generalization or do you feel
like everyone kind of figures it out, you know, presents their own results in their
own way in papers?
There's a lot of work on generalization errors and understanding generalization errors,
cross validation and the whole bias variance theory is trying to figure out how the bias
on a particular data set is going to affect the variance across multiple data sets.
So there's definitely a lot of understanding and statistical machine learning on this
notion of generalization error.
And people have definitely looked at it.
But I think when it comes to the practical implementation, people tend to ignore it.
They tend to kind of evaluate them in a very narrow field.
I've even had students, both in my class and in my research group, sometimes build these
so-called tuning sets where you fix your parameters using these tuning set for your learning
algorithm from test sets.
You should never do that.
That's like cheating.
That's like having a practice question from the final midterm or the final exam that
you have.
You're going to have a practice question on that.
So that's cheating.
There's students who do that all the time.
So we tend to try and teach them that's not the right way to do it and we try to show
them a proper way to do it.
So there's definitely a lot of work on generalization and understanding generalization.
But remember, it's within a certain domain.
Can we do it across domains?
Maybe, maybe not.
Can you take something like learning how to drive a car and figure out how to drive a plane
or fly a plane?
No.
But maybe driving a car in US or India, I can't imagine doing that easily, but you could
do that.
You could try and understand how does it generalize across multiple countries and try to understand
how the rules of the domains change.
At some point it gets into artificial general intelligence, right?
Exactly.
If you can generalize across every domain, that's what that's the goal.
Yeah, well, that's a goal.
That's a goal, but I don't know.
I'm not saying that you need something that is very general.
I'm saying that you need something that is generalizable enough inside the same problem
domain.
Right.
Yeah, I think we are not.
If I build a model, as I said, for driving in US, that should be able to drive in Europe,
if not in India, let's say, that level of chaos may be difficult, but maybe at least
in Europe, maybe in London, it should be able to drive a car.
If I teach it how to drive a car in LA, and that amount of generalization should be there
at the very least.
That would be cool to drive a car in India.
That would be awesome to achieve it.
But I'm not really looking for this one system that drives and flies at the same time.
Right.
In fact, I'm worried that that might lose some specific knowledge that a driving agent
will have, that the flying agent will not.
Yeah.
So that's the balance.
How much general knowledge do you want and how much specific, I guess, what's the right
word here, specific skill set you want for solving that problem?
I think that's the difference that we have to find, and the sweet spot depends on the
problem domain.
In some problems, it's, so think about it, like, you have a problem and you go to a doctor,
and this doctor is a neurologist, and now you want to talk a little bit about diabetes.
This person is going to tell you something, but they're going to say, this is what I know,
and you better talk to somebody who knows this, and you go there, or like a cancer, you
want to go to an oncologist, right?
So, but before that, you have a family friend who's a radiologist, radiologist is going
to give you a lot of information, but then you say, but I'll still refer you to this oncologist
for your treatment plans.
Yeah.
And that's what you want, even with systems.
You don't really want systems that say, oh, I can solve this, and this, and this, and
this.
Right.
And so not too generalizable.
Right.
Right.
But, so artificial general intelligence is great, but we also have to accept that, that
comes at a cost.
It's a contextual.
Yes.
Um, you mentioned you had code up on your site.
Yeah.
Tell me a little bit about the code, is it, is it kind of code applied to the healthcare
site?
So, that's a great question.
No.
You know, general algorithm or?
It's a general algorithm.
It's a boosting algorithm that anybody can download.
It's a gradient boosting, but operates on relational databases.
Okay.
We have an extensive tutorial on how to convert your data to our format, how to run the
code.
We can learn multiple types of models, relational probabilistic models.
We can learn multiple, we can take the human inputs on this.
We actually have a wrapper that can do natural language extractions.
So you have text data, but you want to, let's say, figure out who, who is married to
whom based on paragraphs reading some, some CNN articles or something.
Okay.
And you can, you can post that problem.
We have shown how to do it.
So this is an extensive tutorial on how to use this.
Okay.
It's available off of my web page.
Okay.
Go to my lab deck page through my web page in the software.
It's there.
Okay.
And people can download it and use it.
It's a general purpose software.
Okay.
Not only applied to health problems.
Okay.
When it comes to health problems, there is always a catch.
We have to be very careful on what we release and what we don't and so on and so forth.
So yeah.
Okay.
And then we've been talking about relational databases, but there is a whole set of, a
whole type of database called graph databases.
Yes.
Does your method apply to graph databases as well?
Fantastic question.
Yes.
The answer is yes, because graph is a relation for us.
Right.
Right.
Notes and adjust our relations.
So relation is this common word that we use.
Yeah.
So graphs are just relations.
And actually, because one of the most important step inside our optimization function is
to count.
You have to count the number of instances, so count the number of papers that somebody wrote.
Count the number of friends that somebody has in Facebook and so on and so forth.
And that counting is actually a complex problem.
So we actually use graph databases to accelerate our counts.
So we do use sometimes a temporary representation of a graph database to accelerate our line.
So for us, graph databases and databases, graphs, they're all structured problems that
we can handle using the formalism of logic.
Absolutely.
That's the answer is yes.
And what we're trying to do is actually do exactly that, build a version that is more
optimized for graph databases, because graph databases are much simpler sometimes than
the full logic, like psych-carp knowledge base or never-ending learning material or
nail-knowledge base.
Those are logical knowledge bases and those are huge.
What did they call it?
Psych-carp.
Yeah.
Psych-carp is this company that's been running a learning.
It's been building a knowledge base for over 35, 40 years.
And so those are like giant knowledge bases, whereas graph databases are much easier
to manage and work with.
So they may be even faster for us to learn with.
So yeah, absolutely.
Learning with graph databases is something that we do all the time.
And so you're out doing the tutorial kind of evangelizing this approach.
What's the end goal for you?
Is it you trying to get grad students and postdocs?
You're trying to get industry to adapt this, what's the motivation and vision?
I think we want people to be aware of this big goal of statistical relational AI.
We want people to know that deep learning is not everything and we want people to know
that there are other learning areas that focus on some richer, probably more important
questions.
In terms of the four of us who are giving the tutorial actually have large groups ourselves
so it's not like we are trying to recruit people here.
Okay.
Learning one conference at a time to kind of show that this field is now actually much
more matured than what it was 10 years back.
And we are trying to tell people that there is a lot of opportunities inside our field.
So combining deep models with logical models, combining matrix factorization with relational
data.
So there's a lot of opportunities for this and that's what we are highlighting in the
tutorial tomorrow is inviting more people to work on similar problems like we do and
that's the ultimate goal for us.
It's kind of show people that this is an important research area and problem and that all of us
together can contribute to.
So we want more people to work on these problems and that's our end goal.
Great.
Are there specific examples of like case studies or like health centers or products that
use this?
Sure.
That's a very good question.
So I think one of the case is this deep dive by Professor Kirisre from Stanford that's
now been bottled by Apple.
So this is this probabilistic databases which kind of is statistical relational AI in some
sense.
That automatically extracted information, knowledge extraction from videos and images and
text.
And so that's a classic case.
We have been working with hospitals on trying to see how we can put the data back into their
learning system for making predictions on the number of hospital raid missions, the
number of procedures that need to be done on some persons.
We recently have got some very good success on using such models on predicting postpartum
depression by looking at the network of women, sorry network of people that the women are
in touch with.
And so we are trying to talk to people to see how this can go out to the market.
We work with a particular bank on looking at their legal documents and figuring out if
a new document comes in, does this match the standards of the company, of the bank.
And we can do that automatically with like 98% or 99% accuracy.
And the ones that we fail, we can flag it and show it to the human expert who currently
looks at it.
So yes, there's a lot of these case studies out there.
But again, we are trying to do the deployment at this point.
So maybe hopefully if I talk to you in two years, I'll be able to say, well, I probably
will not be able to say company A uses it, but I can say there is a company that uses it.
Same thing with recommendation systems.
The job recommendation system is actually a real project that we have done with the
real company.
Okay.
And they are looking to use our product in their collaborative filtering system.
Okay.
There's a lot of success stories on this, actually, which is what we're going to highlight
tomorrow.
You should drop by.
Okay.
Awesome.
Well, sure.
Well, sure.
Thanks so much for joining me.
I really appreciate having an opportunity to learn about statistical relational AI.
Thank you.
Any final words or places that you like to point folks to or anything else?
Oh, thanks.
There is a book on statistical relational AI.
Of course, that time I caught that off.
Actually, the four of us who wrote the book are the four who are giving tutorials tomorrow.
Okay.
There's a series of workshops that happen every year that the four of us again founded
10 years, eight, nine years back, I don't know, eight, nine years back, I'm getting old.
And but now people are running it.
It's kind of self-sustaining in its own.
So I invite people to look at this problems of statistical relational AI and contact any
of us.
If you need any directions or anything else, that's all I'm very, very happy to help.
Awesome.
Thanks so much.
Thank you.
Thanks.
All right, everyone.
That's our show for today.
For more information on Shrewroom or any of the topics covering in this episode, head
on over to twimmolai.com slash talk slash 113.
Definitely remember to submit your thoughts on AI in your life at twimmolai.com slash my
AI.
And of course, thanks so much for listening and catch you next time.
