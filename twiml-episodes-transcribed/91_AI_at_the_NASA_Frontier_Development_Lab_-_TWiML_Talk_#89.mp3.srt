1
00:00:00,000 --> 00:00:15,920
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

2
00:00:15,920 --> 00:00:20,880
people doing interesting things in machine learning and artificial intelligence.

3
00:00:20,880 --> 00:00:23,640
I'm your host Sam Charrington.

4
00:00:23,640 --> 00:00:28,200
This week on the podcast, we're featuring a series of conversations from the Nips conference

5
00:00:28,200 --> 00:00:30,480
in Long Beach, California.

6
00:00:30,480 --> 00:00:34,400
This was my first time at Nips and I had a great time there.

7
00:00:34,400 --> 00:00:37,600
I attended a bunch of talks and of course learned a ton.

8
00:00:37,600 --> 00:00:43,800
I organized an impromptu roundtable on building AI products and I met a bunch of wonderful

9
00:00:43,800 --> 00:00:47,920
people including some former Twimble Talk guests.

10
00:00:47,920 --> 00:00:52,760
I'll be sharing a bit more about my experiences at Nips via my newsletter, which you should

11
00:00:52,760 --> 00:00:59,440
take a second right now to subscribe to at twimblei.com slash newsletter.

12
00:00:59,440 --> 00:01:05,080
This week through the end of the year, we're running a special listener appreciation contest

13
00:01:05,080 --> 00:01:09,840
to celebrate hitting one million listens on the podcast and to thank you all for being

14
00:01:09,840 --> 00:01:11,800
so awesome.

15
00:01:11,800 --> 00:01:16,480
Tweet to us using the hashtag twimble1mil to enter.

16
00:01:16,480 --> 00:01:21,120
Everyone who enters is a winner and we're giving away a bunch of cool Twimble swag and

17
00:01:21,120 --> 00:01:23,120
other mystery prizes.

18
00:01:23,120 --> 00:01:29,920
If you're not on Twitter or want more ways to enter, visit twimblei.com slash twimble1mil

19
00:01:29,920 --> 00:01:32,360
for the full rundown.

20
00:01:32,360 --> 00:01:36,720
Before we dive in, I'd like to thank our friends over at Intel Nirvana for their sponsorship

21
00:01:36,720 --> 00:01:39,920
of this podcast and our Nips series.

22
00:01:39,920 --> 00:01:44,960
While Intel was very active at Nips with a bunch of workshops, demonstrations and poster

23
00:01:44,960 --> 00:01:50,680
sessions, their big news this time was the first public viewing of the Intel Nirvana

24
00:01:50,680 --> 00:01:54,480
Neural Network Processor or NNP.

25
00:01:54,480 --> 00:01:59,400
The goal of the NNP architecture is to provide the flexibility needed to support deep learning

26
00:01:59,400 --> 00:02:04,520
primitives while making the core hardware components as efficient as possible, giving

27
00:02:04,520 --> 00:02:10,000
neural network designers powerful tools for solving larger and more difficult problems

28
00:02:10,000 --> 00:02:14,640
while minimizing data movement and maximizing data reuse.

29
00:02:14,640 --> 00:02:20,480
To learn more about Intel's AI products group and the Intel Nirvana NNP, visit Intel

30
00:02:20,480 --> 00:02:22,640
Nirvana.com.

31
00:02:22,640 --> 00:02:28,640
In this episode, I'm joined by Sarah Jennings, Timothy Sebrick and Andres Rodriguez to discuss

32
00:02:28,640 --> 00:02:32,560
NASA's Frontier Development Lab or FDL.

33
00:02:32,560 --> 00:02:39,000
The FDL is an intense eight week applied AI research accelerator, focusing on tackling

34
00:02:39,000 --> 00:02:42,480
knowledge gaps useful to the space program.

35
00:02:42,480 --> 00:02:47,640
In our discussion, Sarah, producer at the FDL, provides some insight into its goals

36
00:02:47,640 --> 00:02:49,320
and structure.

37
00:02:49,320 --> 00:02:54,440
Timothy, a researcher at FDL, describes his involvement with the program, including

38
00:02:54,440 --> 00:02:57,680
some of the projects he worked on while on-site.

39
00:02:57,680 --> 00:03:03,120
He also provides a look into some of this year's FDL projects, including planetary defense,

40
00:03:03,120 --> 00:03:07,600
solar storm prediction and lunar water location.

41
00:03:07,600 --> 00:03:13,880
Last but not least, Andres, senior principal engineer at Intel's AI products group joins

42
00:03:13,880 --> 00:03:19,080
us to detail Intel's support of the FDL and how the various elements of the Intel AI

43
00:03:19,080 --> 00:03:22,080
stack supported the FDL research.

44
00:03:22,080 --> 00:03:26,920
This is a jam-packed conversation, so be sure to check out the show notes at twimlai.com

45
00:03:26,920 --> 00:03:32,200
slash talk slash 89 for all the links and tidbits from this episode.

46
00:03:32,200 --> 00:03:35,520
And now on to the show.

47
00:03:35,520 --> 00:03:46,080
Alright everyone, I'm here in Long Beach at the Nip's conference, and I have the pleasure

48
00:03:46,080 --> 00:03:51,040
of being joined by Sarah Jennings, who is the producer and NASA's Frontier Development

49
00:03:51,040 --> 00:03:58,120
Lab, Timothy Seabrook, NASA Frontier Development Lab researcher via the City Institute at University

50
00:03:58,120 --> 00:04:05,960
of Oxford, and Andres Rodriguez, senior principal engineer at Intel's AIPG.

51
00:04:05,960 --> 00:04:10,040
And I am really excited to have a chance to talk a little bit about this program that

52
00:04:10,040 --> 00:04:15,280
you're all involved in and share it with the folks listening to the podcast.

53
00:04:15,280 --> 00:04:16,280
So welcome everyone.

54
00:04:16,280 --> 00:04:17,280
Thank you.

55
00:04:17,280 --> 00:04:18,280
Happy to be here.

56
00:04:18,280 --> 00:04:19,280
Absolutely.

57
00:04:19,280 --> 00:04:22,600
Why don't we get started by just kind of going around the table and doing intros.

58
00:04:22,600 --> 00:04:24,600
We'll start with you Sarah.

59
00:04:24,600 --> 00:04:28,720
Great, so I'm the producer for NASA Frontier Development Lab, which means I get the really

60
00:04:28,720 --> 00:04:33,520
cool job of working with the researchers for different challenges over the summer throughout

61
00:04:33,520 --> 00:04:35,120
our program.

62
00:04:35,120 --> 00:04:40,080
And previously I've worked in emerging tech and innovation at X-Prize, where I did prize

63
00:04:40,080 --> 00:04:44,520
design and operations, and I've done a lot of work with the private space industry

64
00:04:44,520 --> 00:04:45,520
as well.

65
00:04:45,520 --> 00:04:46,520
Awesome.

66
00:04:46,520 --> 00:04:47,520
Awesome.

67
00:04:47,520 --> 00:04:48,520
Andres?

68
00:04:48,520 --> 00:04:49,520
Yeah, thanks for having me here.

69
00:04:49,520 --> 00:04:55,000
As engineering and intelligent engineering tell me with various customers to understand their

70
00:04:55,000 --> 00:04:57,880
workloads and build solutions for them.

71
00:04:57,880 --> 00:05:03,320
And I work with a lot of other Intel teams to provide to build a solution for our customers.

72
00:05:03,320 --> 00:05:09,520
The solutions may be anywhere from designing models for their particular problems.

73
00:05:09,520 --> 00:05:16,720
So deep learning models or optimizing their algorithms so that they run efficiently on Intel

74
00:05:16,720 --> 00:05:17,920
architecture.

75
00:05:17,920 --> 00:05:24,920
I've been working on AI for about 13 years in an exciting area to be especially over the

76
00:05:24,920 --> 00:05:30,360
past four years, five years to see the tremendous growth and interest for the community in this

77
00:05:30,360 --> 00:05:31,360
area.

78
00:05:31,360 --> 00:05:32,360
Absolutely.

79
00:05:32,360 --> 00:05:33,360
How about you, Tim?

80
00:05:33,360 --> 00:05:38,560
So, as you mentioned previously during my PhD at the University of Oxford, I come from

81
00:05:38,560 --> 00:05:41,640
quite a multi-disciplinary background.

82
00:05:41,640 --> 00:05:46,560
So I've studied under engineering, computer science and communication systems, and that's

83
00:05:46,560 --> 00:05:51,920
given me quite a broad view of technology and also of the machine learning field.

84
00:05:51,920 --> 00:05:57,880
So right now I'm focusing and I'm super interested in verification of learning and multi-agent

85
00:05:57,880 --> 00:06:03,040
systems so that hopefully we can have a bit of specification about these learning agents

86
00:06:03,040 --> 00:06:07,680
so that they might be able to be deployed and used in public grounds because of the minute

87
00:06:07,680 --> 00:06:11,800
you know, it can be a little bit risky to put something out that learns without knowing

88
00:06:11,800 --> 00:06:12,800
what it could learn.

89
00:06:12,800 --> 00:06:14,560
So that's my focus there.

90
00:06:14,560 --> 00:06:19,520
Yeah, I was super happy to go along to the Frontier Development Lab over the summer being

91
00:06:19,520 --> 00:06:20,920
based at NASA.

92
00:06:20,920 --> 00:06:26,080
That was a great opportunity and a great experience and I'm happy to be continuing involvement

93
00:06:26,080 --> 00:06:27,080
with that going forward.

94
00:06:27,080 --> 00:06:29,040
And what was your role with the program?

95
00:06:29,040 --> 00:06:30,080
I was a researcher there.

96
00:06:30,080 --> 00:06:35,440
I applied through the normal means, the application process, got to meet James and Sarah first

97
00:06:35,440 --> 00:06:37,200
online and then in person.

98
00:06:37,200 --> 00:06:41,200
So there were a number of projects that were involved at the Frontier Development Lab and

99
00:06:41,200 --> 00:06:45,480
I was involved in one of those which was the exploration of lunar water and volatiles.

100
00:06:45,480 --> 00:06:46,480
Okay.

101
00:06:46,480 --> 00:06:50,000
Actually, I'll talk a little bit, I guess a little bit about that now.

102
00:06:50,000 --> 00:06:51,560
We can dig into that in a second.

103
00:06:51,560 --> 00:06:56,080
For now probably makes sense to get a little bit more context on FDL as a whole and what

104
00:06:56,080 --> 00:06:59,480
the mission is, Sarah, what can you tell us about FDL?

105
00:06:59,480 --> 00:07:06,880
Yeah, so FDL is an applied artificial intelligence research accelerator and it was kind of

106
00:07:06,880 --> 00:07:13,160
started with the premise of bringing back the Apollo era of interdisciplinary teams paired

107
00:07:13,160 --> 00:07:17,560
with rapid innovation and so during that time they would bring together the comms team

108
00:07:17,560 --> 00:07:21,480
with the life support team and the propulsion team all in the same room so that they could

109
00:07:21,480 --> 00:07:24,160
work on advancing things faster.

110
00:07:24,160 --> 00:07:27,360
And so that was really where this started from.

111
00:07:27,360 --> 00:07:33,680
It started in 2016 with asteroid grant challenge where they mostly focused on planetary defense

112
00:07:33,680 --> 00:07:39,440
problems and now we're moving on to your three because the program has been so successful.

113
00:07:39,440 --> 00:07:45,160
So we bring together researchers from AI fields and we pair them with planetary scientists

114
00:07:45,160 --> 00:07:49,240
and we work on challenges that are of interest to NASA.

115
00:07:49,240 --> 00:07:50,240
Hmm.

116
00:07:50,240 --> 00:07:54,600
And now I've heard this description before and every time planetary defense is said I

117
00:07:54,600 --> 00:07:57,280
think of like defending us against aliens.

118
00:07:57,280 --> 00:07:59,480
What does that mean to you?

119
00:07:59,480 --> 00:08:04,440
Yeah, so the challenges that we focused on were asteroids and long period comms for this

120
00:08:04,440 --> 00:08:05,440
past year.

121
00:08:05,440 --> 00:08:06,440
Okay.

122
00:08:06,440 --> 00:08:09,720
So it's mainly detection and understanding them a little bit better.

123
00:08:09,720 --> 00:08:14,960
So if there was an asteroid that was coming towards us we'd have a little bit more of understanding

124
00:08:14,960 --> 00:08:17,360
of mitigation strategies and things like that.

125
00:08:17,360 --> 00:08:18,360
Okay.

126
00:08:18,360 --> 00:08:23,720
So it actually is protecting us from things that are hurling towards us from space.

127
00:08:23,720 --> 00:08:30,880
And so tell us about the program, what's the structure of the FDL program and how, you

128
00:08:30,880 --> 00:08:33,320
know, how's it organized, who's involved?

129
00:08:33,320 --> 00:08:36,760
Yeah, so it is a public private partnership.

130
00:08:36,760 --> 00:08:41,600
So it's with NASA Ames and hosted at the study institute and then we are able to bring

131
00:08:41,600 --> 00:08:46,760
a lot of our private partners and which allows us to bring in researchers and mentors from

132
00:08:46,760 --> 00:08:48,080
around the world.

133
00:08:48,080 --> 00:08:53,560
It is an eight week program that takes place out at NASA Ames and Silicon Valley where

134
00:08:53,560 --> 00:08:58,360
we bring in about 24 researchers and put them on teams of four.

135
00:08:58,360 --> 00:09:02,120
For that eight week program it starts out with a bootcamp where everybody gets an understanding

136
00:09:02,120 --> 00:09:07,400
of all the problems and then it goes into brainstorming different approaches to work

137
00:09:07,400 --> 00:09:08,840
on solutions for them.

138
00:09:08,840 --> 00:09:09,840
Okay.

139
00:09:09,840 --> 00:09:12,560
And then they do rapid prototyping during that time.

140
00:09:12,560 --> 00:09:15,960
But then after the program ends it doesn't, the work doesn't end.

141
00:09:15,960 --> 00:09:19,560
We do a lot of continuity work and Tim will talk a little bit more about what he's doing

142
00:09:19,560 --> 00:09:20,560
with Intel later.

143
00:09:20,560 --> 00:09:26,200
Okay, and the researchers that you've referred to, they're all or predominantly PhD students

144
00:09:26,200 --> 00:09:27,200
or it is a very.

145
00:09:27,200 --> 00:09:28,200
It varies.

146
00:09:28,200 --> 00:09:32,760
We had a mix of PhDs, postdocs, and individuals in the industry that actually took sabbaticals

147
00:09:32,760 --> 00:09:33,760
from their job.

148
00:09:33,760 --> 00:09:34,760
Oh wow.

149
00:09:34,760 --> 00:09:37,480
And we had an astronomer from Brazil, so it's quite a combination.

150
00:09:37,480 --> 00:09:40,000
It's a really high caliber of people that we bring in.

151
00:09:40,000 --> 00:09:41,000
Oh, very cool.

152
00:09:41,000 --> 00:09:42,000
Very cool.

153
00:09:42,000 --> 00:09:46,000
So Tim, why don't you give us an overview of the types of research that the different teams

154
00:09:46,000 --> 00:09:47,000
worked on?

155
00:09:47,000 --> 00:09:51,840
Sure, so I'm sure you're aware there's a lot of excitement around the field of deep learning

156
00:09:51,840 --> 00:09:52,840
at the moment.

157
00:09:52,840 --> 00:09:53,840
Really?

158
00:09:53,840 --> 00:09:57,200
I'm not sure if you noticed.

159
00:09:57,200 --> 00:10:05,200
Yeah, so I guess to start off with expanding what Sarah mentioned was, it seemed like the

160
00:10:05,200 --> 00:10:08,760
goal of the Frontier Development Lab was really to empower talented scientists who have

161
00:10:08,760 --> 00:10:14,120
been working the field for a long time with these new technologies and enable them to

162
00:10:14,120 --> 00:10:16,960
achieve more than they've been able to previously.

163
00:10:16,960 --> 00:10:23,160
So we were very much looking, and the bootcamp was incredibly helpful to be talking to

164
00:10:23,160 --> 00:10:27,000
NASA scientists and really understand the state of the game when it comes to space and

165
00:10:27,000 --> 00:10:28,960
what's been done and what needs to be done next.

166
00:10:28,960 --> 00:10:31,720
Was that an area that you had any experience with going in?

167
00:10:31,720 --> 00:10:36,400
I mean, as a hobbyist, you know, we're all nerds at the Frontier Development Lab.

168
00:10:36,400 --> 00:10:40,800
We all have a little bit of space, a bit of Star Trek, a bit of Star Wars and stuff

169
00:10:40,800 --> 00:10:41,800
like that.

170
00:10:41,800 --> 00:10:47,240
I don't know, yeah, as a hobbyist from Space News, I was fairly aware of things, but not

171
00:10:47,240 --> 00:10:50,640
to the depth of NASA scientists, of course, have been working a field for 40 years.

172
00:10:50,640 --> 00:10:55,480
Throughout that bootcamp week, we really did come to understand what was going on and sort

173
00:10:55,480 --> 00:10:57,920
of did have to explore where we could contribute.

174
00:10:57,920 --> 00:11:03,960
So we had the artistic freedom to explore and do the prototyping and work out where our

175
00:11:03,960 --> 00:11:07,760
skills as individuals aligned with the needs of the group.

176
00:11:07,760 --> 00:11:12,040
So each individual team came up with their own custom solution to the problems they

177
00:11:12,040 --> 00:11:13,040
were facing.

178
00:11:13,040 --> 00:11:17,600
So a lot of it was, so for my team, it was image classification, similarly for long period

179
00:11:17,600 --> 00:11:21,360
comments, looking at cameras situated around the world.

180
00:11:21,360 --> 00:11:25,040
Sarah, do you know what the name of the camera's project?

181
00:11:25,040 --> 00:11:26,040
Cam's project.

182
00:11:26,040 --> 00:11:27,040
Okay.

183
00:11:27,040 --> 00:11:34,720
Yeah, so what the goal of that is is to detect objects coming through the atmosphere and

184
00:11:34,720 --> 00:11:38,600
identifying when it isn't object and it's not just a bat or a firebug that's gone in

185
00:11:38,600 --> 00:11:42,400
front of the lens and doing that autonomously because people have been doing that for 40

186
00:11:42,400 --> 00:11:45,160
years by hand, which is incredibly arduous.

187
00:11:45,160 --> 00:11:52,040
The asteroid shape modeling team were using variational auto encoders to try and transfer

188
00:11:52,040 --> 00:11:57,760
Doppler shift images, which are incredibly unintuitive into a 3D model so that the shapes

189
00:11:57,760 --> 00:12:01,520
of asteroids and the distribution of the shapes of asteroids can be better understood

190
00:12:01,520 --> 00:12:07,520
the team was working on invasion techniques to ensure that there was, to encode the knowledge

191
00:12:07,520 --> 00:12:12,760
of the NASA scientists into a prior distribution so that the shapes that came out made sense.

192
00:12:12,760 --> 00:12:16,720
So the weather prediction teams, they were looking at predicting when a coronal mass

193
00:12:16,720 --> 00:12:20,680
ejection might come out, which would be quite catastrophic if it does, when a coronal

194
00:12:20,680 --> 00:12:22,160
mass ejection.

195
00:12:22,160 --> 00:12:27,160
So when a magnetic band within the sun sort of snaps and it ejects a huge plume of

196
00:12:27,160 --> 00:12:32,000
heart plasma through the solar system and the Earth luckily has a magnetic field that

197
00:12:32,000 --> 00:12:37,040
protects us from most of that, but if we get hit by a 1 or 2 or several waves then it

198
00:12:37,040 --> 00:12:42,760
can be quite catastrophic and damage satellites of course, it could be dangerous for people

199
00:12:42,760 --> 00:12:43,760
on space stations.

200
00:12:43,760 --> 00:12:46,040
How often does this kind of thing happen?

201
00:12:46,040 --> 00:12:48,240
So there was the Carrington event in...

202
00:12:48,240 --> 00:12:49,240
The Carrington event.

203
00:12:49,240 --> 00:12:50,240
Carrington event.

204
00:12:50,240 --> 00:12:51,240
Yeah, that was the...

205
00:12:51,240 --> 00:12:52,240
No relation to Carrington.

206
00:12:52,240 --> 00:12:53,240
My last name.

207
00:12:53,240 --> 00:12:59,440
Yeah, that was the last major one, but they haven't happened quite frequently.

208
00:12:59,440 --> 00:13:03,840
So I think it was around late 19th century, so there wasn't too much electricity around

209
00:13:03,840 --> 00:13:06,200
by then, so it wasn't too damaging to that.

210
00:13:06,200 --> 00:13:09,880
It went largely under my notice, apart from in Canada I believe, it was where it was

211
00:13:09,880 --> 00:13:11,120
noticed the most.

212
00:13:11,120 --> 00:13:16,880
So that caused some great northern lights to show up, so people were really loving that,

213
00:13:16,880 --> 00:13:19,840
but it would be a little bit more damaging now.

214
00:13:19,840 --> 00:13:26,160
But yeah, I believe there are smaller events happening quite a lot, and I mean, we're

215
00:13:26,160 --> 00:13:31,400
a small dart in a solar system, so a lot of the time they'll miss us, which is fortunate.

216
00:13:31,400 --> 00:13:36,120
Yeah, I mean, in day-to-day life, they can affect things like GPS, mobile phone signals,

217
00:13:36,120 --> 00:13:37,120
things like that.

218
00:13:37,120 --> 00:13:38,120
Okay.

219
00:13:38,120 --> 00:13:41,880
So we really need to have a prediction of when one of these events might happen, and

220
00:13:41,880 --> 00:13:46,360
the way you do that is by monitoring the hyperspecial images of the sun's surface

221
00:13:46,360 --> 00:13:47,880
what you can see.

222
00:13:47,880 --> 00:13:54,520
So we had the team there was using LSTM, which is a type of neural network, often used

223
00:13:54,520 --> 00:13:56,360
for neural linguistic programming.

224
00:13:56,360 --> 00:14:01,640
It's long short-term memory, that's what the LSTM stands for, so that takes into account

225
00:14:01,640 --> 00:14:05,800
the long-term history of the sun's activity as well as the short-term, so it is quite

226
00:14:05,800 --> 00:14:08,600
useful in financial predictions as well.

227
00:14:08,600 --> 00:14:13,960
We also had the other teams, so the terrestrial interaction, they had a hard time.

228
00:14:13,960 --> 00:14:14,960
Terrestrial interactions?

229
00:14:14,960 --> 00:14:15,960
So the terrestrial.

230
00:14:15,960 --> 00:14:16,960
Terrestrial interaction.

231
00:14:16,960 --> 00:14:20,440
So that happens when the solar activity does hit the earth.

232
00:14:20,440 --> 00:14:24,880
And how that might affect electrical companies, how that might affect markets and things

233
00:14:24,880 --> 00:14:26,280
like this.

234
00:14:26,280 --> 00:14:30,160
And it's really difficult to get a hold of the law of that data.

235
00:14:30,160 --> 00:14:33,920
I mean, and then just for that problem or for all of these problems that we've discussed?

236
00:14:33,920 --> 00:14:38,400
Well, luckily there is a huge wealth of public data for most of these things, particularly

237
00:14:38,400 --> 00:14:40,000
when it comes to looking at the moon.

238
00:14:40,000 --> 00:14:44,000
It's up there we've got, it's fortunately NASA's a public entity.

239
00:14:44,000 --> 00:14:46,000
So all the work they do, well, a lot of the data that they do, they do, they do, they

240
00:14:46,000 --> 00:14:51,280
are a lot of the data that they do is available to the public, which is great for hobbyists.

241
00:14:51,280 --> 00:14:57,000
So yeah, the solar terrestrial interaction team was pulling as much data as they could

242
00:14:57,000 --> 00:15:02,200
from disparate sources, from insurance companies, from claims of damage that have been done

243
00:15:02,200 --> 00:15:08,360
to transformers and things like this and trying to find a model to describe, particularly

244
00:15:08,360 --> 00:15:12,960
what the cost of damage could be if one of these events happens, so they ended up using

245
00:15:12,960 --> 00:15:16,560
a wide variety of techniques and machine learning and, for instance, and funding together

246
00:15:16,560 --> 00:15:18,880
and see where they could come out with.

247
00:15:18,880 --> 00:15:22,680
And I guess last but not least the work that the team I was on was working on.

248
00:15:22,680 --> 00:15:23,680
We had a good team.

249
00:15:23,680 --> 00:15:29,000
There's Deep Mar Backus, who is a, he does a lot of mapping problems and a lot of, yeah,

250
00:15:29,000 --> 00:15:31,680
a lot of synthesis of maps and working on those.

251
00:15:31,680 --> 00:15:36,160
Eleni Beowichek, who does computer vision for Mars Rovers.

252
00:15:36,160 --> 00:15:42,120
We had Nate Amusa, who was one of those, for those from industry, who comes from a strong

253
00:15:42,120 --> 00:15:44,160
understanding of computer vision.

254
00:15:44,160 --> 00:15:49,200
Myself and also we were supported by Tony Dubovowski, who is a planetary scientist, particularly

255
00:15:49,200 --> 00:15:52,720
interested in creative formations, which was incredibly useful.

256
00:15:52,720 --> 00:15:54,240
And so what was your project?

257
00:15:54,240 --> 00:16:00,200
So the project was to find a way to facilitate the investigation and the quantification

258
00:16:00,200 --> 00:16:07,720
of how much water or volatile is refocused on water is on the lunar surface.

259
00:16:07,720 --> 00:16:09,880
And there's potentially quite a lot.

260
00:16:09,880 --> 00:16:14,480
I was surprised to learn this because you know, there's a lot of discussion about, maybe

261
00:16:14,480 --> 00:16:19,160
there's water on Mars, maybe there's water on one of the moons of Jupiter or Saturn.

262
00:16:19,160 --> 00:16:23,640
But it seems there's a lot, quite a lot closer to home.

263
00:16:23,640 --> 00:16:29,400
Sarah, I'm curious from your perspective, why is, you know, in one sense, there's, you

264
00:16:29,400 --> 00:16:32,520
know, it's obvious that we'd be interested in exploring, you know, water on the moon,

265
00:16:32,520 --> 00:16:37,600
but how, you know, what are, how does NASA think about the reason why this is important

266
00:16:37,600 --> 00:16:42,680
and maybe you can also touch on some of the, you know, how do we know there's water

267
00:16:42,680 --> 00:16:43,680
on the moon?

268
00:16:43,680 --> 00:16:44,680
Yeah.

269
00:16:44,680 --> 00:16:50,080
So I can touch a little bit on that without overstepping, but so the reason NASA is focused

270
00:16:50,080 --> 00:16:54,480
on the moon currently is because with this new administration we're focused on going

271
00:16:54,480 --> 00:16:55,640
back to the moon.

272
00:16:55,640 --> 00:17:00,680
So the reason why later resources is important and Tim can also share a little bit more about

273
00:17:00,680 --> 00:17:06,120
that is that those resources are very expensive to move from the earth into space.

274
00:17:06,120 --> 00:17:11,360
And so if you already have those resources there, then you could utilize them for fuel

275
00:17:11,360 --> 00:17:16,920
or for other things potentially like settlements and things where you don't have to import those

276
00:17:16,920 --> 00:17:17,920
materials there.

277
00:17:17,920 --> 00:17:18,920
Mm-hmm.

278
00:17:18,920 --> 00:17:21,560
So that's another, another way there.

279
00:17:21,560 --> 00:17:22,560
Okay.

280
00:17:22,560 --> 00:17:27,440
And I heard an anecdote about the first discovery of water on the moon, like how do we,

281
00:17:27,440 --> 00:17:28,440
Oh.

282
00:17:28,440 --> 00:17:29,440
Yeah.

283
00:17:29,440 --> 00:17:31,000
So it was the lacrosse mission.

284
00:17:31,000 --> 00:17:35,880
So the Apollo, some Apollo 15 rock samples showed water in them, but, you know, there was

285
00:17:35,880 --> 00:17:38,920
disputed whether or not they've been contaminated and things like this.

286
00:17:38,920 --> 00:17:39,920
Right.

287
00:17:39,920 --> 00:17:42,480
So there was seeking for further evidence.

288
00:17:42,480 --> 00:17:47,200
So there were a couple more missions, one from NASA, one from the Indian Space Agency,

289
00:17:47,200 --> 00:17:53,200
which involved sending an impactor into a crater on the South Pole that never sees sunlight.

290
00:17:53,200 --> 00:17:58,280
So I can explain a little bit maybe why that was the reason, but why that was chosen.

291
00:17:58,280 --> 00:18:04,240
So the impactor wouldn't hit the surface, it was basically crashing a ship into a vehicle

292
00:18:04,240 --> 00:18:06,560
of some sort into the side of the crater.

293
00:18:06,560 --> 00:18:07,560
Yeah.

294
00:18:07,560 --> 00:18:11,080
And the ejecto plume that came out, all the dust that was kicked up, spectral reading

295
00:18:11,080 --> 00:18:16,760
was taken of that and showed, I believe, about 4.6 percent water in a form of ice particles.

296
00:18:16,760 --> 00:18:17,760
I imagine.

297
00:18:17,760 --> 00:18:18,760
Yeah.

298
00:18:18,760 --> 00:18:22,640
I'm not sure because the impact of the energy might have vaporized some of it, but yeah,

299
00:18:22,640 --> 00:18:26,040
in its stable form it would have been ice, yeah.

300
00:18:26,040 --> 00:18:31,080
So yeah, the reason that they were targeting permanently shadowed craters is because I

301
00:18:31,080 --> 00:18:36,200
mean, if you consider that of the last 4 billion years, every meteor and comet that's impacted

302
00:18:36,200 --> 00:18:40,720
on the moon has had the potential to contain some rare earth metals and some water.

303
00:18:40,720 --> 00:18:42,640
All of that's been deposited.

304
00:18:42,640 --> 00:18:47,480
Some of it will evaporate, some of it will escape the atmosphere, but some of it will get stuck

305
00:18:47,480 --> 00:18:50,280
in the bottom of the craters that are at 40 Kelvin.

306
00:18:50,280 --> 00:18:54,000
So anything that goes in there freezes and gets stuck there potentially forever.

307
00:18:54,000 --> 00:18:55,000
Okay.

308
00:18:55,000 --> 00:18:58,640
So it's considered that might be, you know, the great wealth, the bank of resources that

309
00:18:58,640 --> 00:19:01,240
was available on the moon.

310
00:19:01,240 --> 00:19:05,960
And the role of your team was to basically figure out how much of this stuff might exist.

311
00:19:05,960 --> 00:19:09,640
And the role of our team was to work out how we could contribute to the accessing of

312
00:19:09,640 --> 00:19:10,640
it, right?

313
00:19:10,640 --> 00:19:11,640
Using machine learning.

314
00:19:11,640 --> 00:19:12,640
Right.

315
00:19:12,640 --> 00:19:13,720
So yeah, we started off.

316
00:19:13,720 --> 00:19:21,320
So right now, as I understand, an objective would be to exactly investigate, understand

317
00:19:21,320 --> 00:19:26,840
how much there is, understand if it's economically viable to set up a base there or to send

318
00:19:26,840 --> 00:19:32,720
further missions, the way you do that is with rovers, is with in situ resource measurements.

319
00:19:32,720 --> 00:19:37,080
So we were looking firstly, looking at traverse planning, rovers have to stay in sunlight

320
00:19:37,080 --> 00:19:40,880
all the whole time with a solar powered or for as long as possible anyway.

321
00:19:40,880 --> 00:19:44,480
They have to stay in direct communication with the earth a lot of the time, so the moon's

322
00:19:44,480 --> 00:19:45,480
quite close.

323
00:19:45,480 --> 00:19:47,080
So usually it's still human operated.

324
00:19:47,080 --> 00:19:49,800
When there's a rover up there, it's only a second or two delay.

325
00:19:49,800 --> 00:19:53,880
So we were looking at that problem and then we realized that, you know, there were some

326
00:19:53,880 --> 00:19:59,160
other work that needed to be done before that to facilitate that sort of advancement.

327
00:19:59,160 --> 00:20:00,520
And what was that other work?

328
00:20:00,520 --> 00:20:06,400
So in doing the traverse planning, we realized that it's the maps weren't in the highest

329
00:20:06,400 --> 00:20:11,480
quality that we had come to expect, you know, maybe lately we thought the moon's just above

330
00:20:11,480 --> 00:20:16,520
us that the maps should be complete, right, right, regions where there is permanent shadow,

331
00:20:16,520 --> 00:20:21,720
visual images are difficult to to grab and also as the, you know, reconnaissance orbiter,

332
00:20:21,720 --> 00:20:25,840
which is where we took our data from, as that's orbited the moon, thousands and thousands

333
00:20:25,840 --> 00:20:31,640
of time and built a laser altimeter sort of height map readings, a stitching and the composite

334
00:20:31,640 --> 00:20:36,880
images that are formed have created artifacts which to a rover and a rover's eyes look like

335
00:20:36,880 --> 00:20:38,960
20 foot clips and 20 foot digits.

336
00:20:38,960 --> 00:20:39,960
So when you're trying to...

337
00:20:39,960 --> 00:20:40,960
They aren't actually there.

338
00:20:40,960 --> 00:20:41,960
That may not be.

339
00:20:41,960 --> 00:20:42,960
Yeah, actually there.

340
00:20:42,960 --> 00:20:44,920
Yeah, but a lot of them aren't.

341
00:20:44,920 --> 00:20:48,960
So you can just smooth over because, I mean, a rovers an expensive thing to put on a moon

342
00:20:48,960 --> 00:20:53,560
you don't have to fall down one of these digits, if it is real, but also you can't do an automated

343
00:20:53,560 --> 00:20:57,320
plan until you've worked out which ones are your own which ones aren't.

344
00:20:57,320 --> 00:20:59,760
Okay, so that became the focus of our continued work.

345
00:20:59,760 --> 00:21:00,760
Okay.

346
00:21:00,760 --> 00:21:05,400
And there was also an element of your work that involved trying to count the number of

347
00:21:05,400 --> 00:21:06,760
craters on the moon.

348
00:21:06,760 --> 00:21:08,640
So where did that come in?

349
00:21:08,640 --> 00:21:09,640
The lunar surface.

350
00:21:09,640 --> 00:21:13,640
I suppose every time a picture of the lunar surface has been taken, there's no GPS,

351
00:21:13,640 --> 00:21:14,640
right?

352
00:21:14,640 --> 00:21:17,240
So you don't know exactly where that photo is.

353
00:21:17,240 --> 00:21:22,160
But thankfully, craters being so abundant, form a sort of fingerprint that allows you

354
00:21:22,160 --> 00:21:25,000
to uniquely identify what you're looking at.

355
00:21:25,000 --> 00:21:30,080
And by matching that in a visual image with the elevation model, then you can compare

356
00:21:30,080 --> 00:21:34,520
what the artifacts might be in the elevation model with the visual images.

357
00:21:34,520 --> 00:21:38,840
And then if it's in one but not the other, then you know it doesn't exist.

358
00:21:38,840 --> 00:21:42,800
If it's in both, then you know, okay, that is a ditch that I need to watch out for.

359
00:21:42,800 --> 00:21:47,840
And maybe going back to more fundamental kind of space question, like how many craters

360
00:21:47,840 --> 00:21:48,840
are on the moon?

361
00:21:48,840 --> 00:21:49,840
Oh gosh.

362
00:21:49,840 --> 00:21:51,160
More than we can count.

363
00:21:51,160 --> 00:21:52,360
More than we can count.

364
00:21:52,360 --> 00:21:57,640
Are these craters that were all created with the creation of the moon itself or are these

365
00:21:57,640 --> 00:22:01,480
craters a result of impact like comments or other things?

366
00:22:01,480 --> 00:22:05,880
So I believe there's 10 notable fresh impacts per day.

367
00:22:05,880 --> 00:22:10,920
So we looked at around 40 to 100,000 craters.

368
00:22:10,920 --> 00:22:13,760
And that was around 1,000th of a percent of the lunar surface.

369
00:22:13,760 --> 00:22:14,760
Wow.

370
00:22:14,760 --> 00:22:15,760
Yeah.

371
00:22:15,760 --> 00:22:16,760
They're coming every day.

372
00:22:16,760 --> 00:22:18,800
But I think a lot of it was historical.

373
00:22:18,800 --> 00:22:22,000
A lot of it has been in the past and it's come down a bit.

374
00:22:22,000 --> 00:22:23,000
But it's still going.

375
00:22:23,000 --> 00:22:24,600
There's still impacts every day, yes.

376
00:22:24,600 --> 00:22:25,600
Okay.

377
00:22:25,600 --> 00:22:28,520
Is the earth impacted that much by craters?

378
00:22:28,520 --> 00:22:31,720
Is it our magnetic field as you were describing earlier that protects us from that?

379
00:22:31,720 --> 00:22:34,920
Or do we get our fair share of those crater impacts as well?

380
00:22:34,920 --> 00:22:37,640
Like certainly the earth is in pocket with craters like the moon is.

381
00:22:37,640 --> 00:22:39,720
So we do get a lot of things coming through the atmosphere.

382
00:22:39,720 --> 00:22:43,360
You might see a shooting star every now again that's a small meteoroid coming through

383
00:22:43,360 --> 00:22:44,360
the atmosphere.

384
00:22:44,360 --> 00:22:47,400
The atmosphere is another protective shield for us.

385
00:22:47,400 --> 00:22:52,600
You know, the friction that the meteoroid comes under as it's entering causes it to burn

386
00:22:52,600 --> 00:22:54,400
up a lot of the time or break apart.

387
00:22:54,400 --> 00:22:56,160
So we do have that minor protection.

388
00:22:56,160 --> 00:23:00,800
Yeah, the planetary defense team, they're really looking at bigger asteroids that could

389
00:23:00,800 --> 00:23:02,120
be more deadly.

390
00:23:02,120 --> 00:23:06,360
So I think it was 10 years ago we thought there were maybe 16,000 of these.

391
00:23:06,360 --> 00:23:11,240
Now we know there's hundreds of thousands of potentially dangerous objects floating

392
00:23:11,240 --> 00:23:13,280
around the space.

393
00:23:13,280 --> 00:23:18,120
Luckily we've gotten much better at modeling where these are and understanding which ones

394
00:23:18,120 --> 00:23:23,360
could be dangerous and it looks like we're in a clearer at least for now.

395
00:23:23,360 --> 00:23:33,480
So to kind of take a step back, you're trying to ultimately understand the available resources

396
00:23:33,480 --> 00:23:36,400
on the moon in order to do that.

397
00:23:36,400 --> 00:23:42,880
One of the techniques involved was trying to understand actually was trying to plan out

398
00:23:42,880 --> 00:23:48,800
the rover mission or provide information that would be used in planning a rover mission.

399
00:23:48,800 --> 00:23:53,200
In order to do that, we need to understand how the maps all fit together.

400
00:23:53,200 --> 00:23:56,560
And in order to do that, we need to be able to identify the craters.

401
00:23:56,560 --> 00:23:57,560
Yeah.

402
00:23:57,560 --> 00:24:01,600
So this was really a keystone that would open up the possibility for future works to go

403
00:24:01,600 --> 00:24:02,600
ahead.

404
00:24:02,600 --> 00:24:10,120
And so what were the techniques and challenges involved in identifying the craters?

405
00:24:10,120 --> 00:24:13,280
I mean, main challenges came to even understanding the problem.

406
00:24:13,280 --> 00:24:16,960
I mean, it took a lot of, thank God we had the prototype in process.

407
00:24:16,960 --> 00:24:21,120
So we only came to understand that problem by trying to do the diverse plans.

408
00:24:21,120 --> 00:24:25,080
When it came to it, I think we were five weeks in program already.

409
00:24:25,080 --> 00:24:26,280
There were three weeks left.

410
00:24:26,280 --> 00:24:29,440
So we had a lot of late nights labeling all the data.

411
00:24:29,440 --> 00:24:34,080
So for any machine learning algorithm, you need to give it training examples, right?

412
00:24:34,080 --> 00:24:37,120
You need to teach it as though it's going through school.

413
00:24:37,120 --> 00:24:38,120
Right.

414
00:24:38,120 --> 00:24:42,800
So we had to collect images, representative images of craters and come to an

415
00:24:42,800 --> 00:24:48,120
agreeance of what the crater looks like so that we could feed that to our algorithm.

416
00:24:48,120 --> 00:24:49,120
Okay.

417
00:24:49,120 --> 00:24:50,760
That was surprisingly difficult actually.

418
00:24:50,760 --> 00:24:55,640
We had five people on the team and several others were helping us label these images.

419
00:24:55,640 --> 00:25:00,800
And to come to a consensus on which should be considered to be good representations of

420
00:25:00,800 --> 00:25:06,120
craters and which weren't and which were too ambiguous was a long process actually.

421
00:25:06,120 --> 00:25:11,080
Meaning full-fledged craters versus, you know, dips in the terrain or something like that.

422
00:25:11,080 --> 00:25:16,560
So one interesting thing we came across was that actually hills look exactly like craters

423
00:25:16,560 --> 00:25:18,880
depending on the angle of the light.

424
00:25:18,880 --> 00:25:22,360
So that was a little bit, after you were looking through thousands of these, everything started

425
00:25:22,360 --> 00:25:23,760
looking like a hill and you weren't sure anymore.

426
00:25:23,760 --> 00:25:28,080
You have to take a break every now and again to, you know, let me perception rest again.

427
00:25:28,080 --> 00:25:33,120
So yeah, it was the sheer number of training examples that we had to label ourselves and

428
00:25:33,120 --> 00:25:34,120
then.

429
00:25:34,120 --> 00:25:36,160
And so how many of these craters did you personally label?

430
00:25:36,160 --> 00:25:37,520
I looked through 40,000.

431
00:25:37,520 --> 00:25:38,520
Wow.

432
00:25:38,520 --> 00:25:43,240
There was a bottle of scotch nearby that definitely helped me through that process.

433
00:25:43,240 --> 00:25:44,240
Yeah.

434
00:25:44,240 --> 00:25:45,240
So we got through that.

435
00:25:45,240 --> 00:25:49,320
And then once we got to that training data, then it went through the iteration process of

436
00:25:49,320 --> 00:25:55,360
developing a computational network classifier, and thankfully we had Intel, Nirvana, and

437
00:25:55,360 --> 00:25:59,520
the technology there to help us go through that process quickly and we had the support

438
00:25:59,520 --> 00:26:04,680
of the Intel engineers to give us advice and support on how to use their framework most

439
00:26:04,680 --> 00:26:05,920
effectively.

440
00:26:05,920 --> 00:26:12,040
Was there anything that came up as kind of unique about training a model in this situation

441
00:26:12,040 --> 00:26:15,760
that you wouldn't expect in other, you know, applications of CNNs?

442
00:26:15,760 --> 00:26:22,200
I would imagine one of the things that is unique compared to what you usually find in academia

443
00:26:22,200 --> 00:26:24,880
you're focusing on two aspects.

444
00:26:24,880 --> 00:26:29,160
One is it's a binary, is this a crater or not?

445
00:26:29,160 --> 00:26:34,280
You're not trying to classify between thousands or hundreds of classes.

446
00:26:34,280 --> 00:26:38,320
And the second one is you are also doing detection.

447
00:26:38,320 --> 00:26:43,480
You don't, you're looking for the craters in large images.

448
00:26:43,480 --> 00:26:46,280
So the project essentially has these two steps.

449
00:26:46,280 --> 00:26:53,400
First, can you classify craters versus non-creators and second, can you then detect them in a large

450
00:26:53,400 --> 00:26:54,400
image?

451
00:26:54,400 --> 00:26:55,400
I don't know.

452
00:26:55,400 --> 00:26:57,160
If you have other things to add to.

453
00:26:57,160 --> 00:26:58,160
Yeah.

454
00:26:58,160 --> 00:27:03,000
So one of the particular problems with the crater detection was that there's just so many

455
00:27:03,000 --> 00:27:08,000
of them and they're all overlaying on each other and that's quite a difficult image classification

456
00:27:08,000 --> 00:27:09,000
problem.

457
00:27:09,000 --> 00:27:11,480
So if you're doing facial recognition, for example, you don't expect to see a face in

458
00:27:11,480 --> 00:27:16,120
a face in a face in a face or like a cluster of faces altogether.

459
00:27:16,120 --> 00:27:21,000
So that was definitely a challenge for the image classifier.

460
00:27:21,000 --> 00:27:27,600
Andres, maybe give us some perspective on why does Intel support a program like this?

461
00:27:27,600 --> 00:27:31,640
How does Intel think about engaging with programs like FTL?

462
00:27:31,640 --> 00:27:39,000
Intel wants to advance science and this is a great opportunity for Intel to partner

463
00:27:39,000 --> 00:27:46,920
both with researchers, with NASA engineers, with the NASA program to advance science.

464
00:27:46,920 --> 00:27:50,840
And in addition, Intel wants to democratize machine learning.

465
00:27:50,840 --> 00:27:57,320
So it was a great opportunity to work with engineers that many of them had not to not have

466
00:27:57,320 --> 00:28:03,800
a background in machine learning and give them the knowledge and the tools to use machine

467
00:28:03,800 --> 00:28:06,760
learning for a particular problem.

468
00:28:06,760 --> 00:28:10,640
And how did your team in particular get involved with the projects?

469
00:28:10,640 --> 00:28:19,960
So we were invited, one of our team managers received an invitation for Intel to participate

470
00:28:19,960 --> 00:28:23,000
and we were very excited to join the opportunity.

471
00:28:23,000 --> 00:28:32,240
I went to the kickoff meeting and got to meet the researchers in the program and invited

472
00:28:32,240 --> 00:28:35,360
a couple of my colleagues to come and participate.

473
00:28:35,360 --> 00:28:42,960
One who couldn't be here unfortunately, his name is Najib Hakim, who was the main Intel

474
00:28:42,960 --> 00:28:49,000
engineer, his principal engineer, with a strong background in machine learning and deep

475
00:28:49,000 --> 00:28:50,160
learning.

476
00:28:50,160 --> 00:28:56,800
And he provided a lot of the mentorship and guidance that the engineers needed, along

477
00:28:56,800 --> 00:29:05,120
with Ravi, Panchamarthi and Hanlin, they provided additional assistance, engineering assistance

478
00:29:05,120 --> 00:29:07,440
to the teams.

479
00:29:07,440 --> 00:29:14,120
You mentioned a moment ago the kind of the unique challenges of this problem with regard

480
00:29:14,120 --> 00:29:19,600
to clusters of craters and craters and all that kind of stuff.

481
00:29:19,600 --> 00:29:23,200
How did you overcome those problems?

482
00:29:23,200 --> 00:29:27,440
So thankfully the problem that we were trying to solve was the co-registration improvement

483
00:29:27,440 --> 00:29:28,760
of maps.

484
00:29:28,760 --> 00:29:33,200
So so long as we could get a reliable fingerprint for an image that could be matched in the

485
00:29:33,200 --> 00:29:36,760
elevation model, then that would satisfy our goals.

486
00:29:36,760 --> 00:29:44,480
So when there was particularly rough areas, then it didn't matter so much that maybe the

487
00:29:44,480 --> 00:29:48,720
quality of our image classified suffered in those regions because we were able to make

488
00:29:48,720 --> 00:29:50,160
up for it elsewhere.

489
00:29:50,160 --> 00:29:56,640
So it would definitely be a problem for research question almost and when it comes to building

490
00:29:56,640 --> 00:30:02,560
an application in a short period of time, sometimes we had to make do with what we had and

491
00:30:02,560 --> 00:30:06,480
do it quickly, rather than trying to buy it off more than we could chew an identity

492
00:30:06,480 --> 00:30:07,800
up, not contributing anything.

493
00:30:07,800 --> 00:30:08,800
Right.

494
00:30:08,800 --> 00:30:09,800
Right.

495
00:30:09,800 --> 00:30:16,600
And so how do you envision, I understand there's an ongoing role for you in particular in

496
00:30:16,600 --> 00:30:19,920
this project with FDL, how does it move forward?

497
00:30:19,920 --> 00:30:25,400
So I mean, identifying the issues that we had with the time constraints, we all invited

498
00:30:25,400 --> 00:30:29,120
individually to continue to contribute if we would like to.

499
00:30:29,120 --> 00:30:34,040
I think for many of us, it's, you know, this really stirred up our passion and our excitement

500
00:30:34,040 --> 00:30:35,840
about the whole field.

501
00:30:35,840 --> 00:30:41,720
So since the end of the project, we've been working to, you know, tidy up the code, make

502
00:30:41,720 --> 00:30:46,520
it publicly available, and we've been working alongside the folks at Intel to improve

503
00:30:46,520 --> 00:30:51,360
the algorithm to be able to detect clusters of creators and creators within creators using

504
00:30:51,360 --> 00:30:55,400
our newer techniques, single-shot detector, it's a modipox.

505
00:30:55,400 --> 00:31:00,000
Which allows you to identify lots of creators in the same image.

506
00:31:00,000 --> 00:31:05,960
So moving forward, I suppose we're looking forward to a fronted development of 2018, we're

507
00:31:05,960 --> 00:31:10,880
going to be taking applications for that currently up until March.

508
00:31:10,880 --> 00:31:16,200
And really what we're looking for is to see what ideas people come with and how the

509
00:31:16,200 --> 00:31:20,360
ways that they can contribute to the continuation of this project.

510
00:31:20,360 --> 00:31:26,320
Andreas, were there any kind of unique properties of the Intel AI stack that lent themselves

511
00:31:26,320 --> 00:31:32,160
to solving this problem or that, you know, helped in helping these research teams advance

512
00:31:32,160 --> 00:31:33,160
their research?

513
00:31:33,160 --> 00:31:38,800
Yeah, until we have the full solution stack anywhere from starting at the bottom with

514
00:31:38,800 --> 00:31:47,000
our hardware, we have our general purpose CPU, such as young processors, we're also developing

515
00:31:47,000 --> 00:31:52,200
a deep learning accelerator, specific target for the learning world, that was not available

516
00:31:52,200 --> 00:31:58,000
in 2017 when these researchers were working on this problem, we hope that they'll be able

517
00:31:58,000 --> 00:32:04,320
to use it in the following summer, but we have our CPUs in addition to that, we have libraries

518
00:32:04,320 --> 00:32:11,160
that are optimized to run deep learning functions efficiently on our CPUs, you might have heard

519
00:32:11,160 --> 00:32:17,400
of the Intel math kernel library, we in addition we have deep learning frameworks that we've

520
00:32:17,400 --> 00:32:24,440
optimized, such as cafe, TensorFlow, MxNet, and we have an in-house framework called NEON,

521
00:32:24,440 --> 00:32:32,160
which was the framework that was made available, FTL for the researchers to use, NEON's unique

522
00:32:32,160 --> 00:32:38,760
in the sense that it's a framework that is highly optimized, but Intel for both CPUs and

523
00:32:38,760 --> 00:32:45,160
CPUs, you can get very high throughput and high utilization, regardless of the hardware

524
00:32:45,160 --> 00:32:52,400
backend that you use, and in addition to that, we actually have a Nirvana offering called

525
00:32:52,400 --> 00:33:00,200
the Intel AI cloud, it used to be called the Intel Nirvana cloud, and this cloud where

526
00:33:00,200 --> 00:33:07,480
our partners can log in and easily load their jobs and they have the tools to easily experiment

527
00:33:07,480 --> 00:33:13,400
with various models and various hyperparameters, meaning various knobs that you need to often

528
00:33:13,400 --> 00:33:16,880
tweak in order to get your models to officially train.

529
00:33:16,880 --> 00:33:23,840
So we spend some time getting the engineers and have the alab to speed on how to use the

530
00:33:23,840 --> 00:33:32,400
tools, but once you spend a few days or even less a couple of days or day, you can start

531
00:33:32,400 --> 00:33:39,320
training your own models, so you usually start by training a simple model like Lynette,

532
00:33:39,320 --> 00:33:44,120
which is an all model that was developed a couple decades ago, and you can do that

533
00:33:44,120 --> 00:33:50,840
your first couple of hours, you train that model on image recognition, and then you can

534
00:33:50,840 --> 00:33:56,800
actually modify it a little bit to start getting a baseline on how well does this work

535
00:33:56,800 --> 00:34:05,040
on our crater images, and do I need to add more layers, do I need to add more units or

536
00:34:05,040 --> 00:34:12,400
neurons in its layer, once you can do crater classification then you can move into detection,

537
00:34:12,400 --> 00:34:20,560
which as Tim was talking about, initially we use single shot detection algorithm or SSD,

538
00:34:20,560 --> 00:34:28,360
and there are newer algorithms that are better for this type of workloads, where you have

539
00:34:28,360 --> 00:34:33,240
small craters, some large craters, and you don't have a diversity of classes, you're

540
00:34:33,240 --> 00:34:39,360
trying to classify, and so that's going to be the next step of classifiers or detectors

541
00:34:39,360 --> 00:34:41,560
that we're going to be using.

542
00:34:41,560 --> 00:34:43,680
Awesome, awesome.

543
00:34:43,680 --> 00:34:50,200
This sounds like an amazing program, maybe we can close out by having you Sarah tell

544
00:34:50,200 --> 00:34:55,800
us like for folks that want to learn more about participating in the 2018 program, is there

545
00:34:55,800 --> 00:34:59,040
a site they can go to, or what's the process there?

546
00:34:59,040 --> 00:35:04,800
Yeah, so if you're interested in the program, you would go to frontchairdevelopmentlab.org,

547
00:35:04,800 --> 00:35:09,280
and like Tim said, we do have our applications open, we're currently doing our planning

548
00:35:09,280 --> 00:35:12,960
for next year, and so our challenges should be launched here soon as well.

549
00:35:12,960 --> 00:35:20,160
Okay, and Tim from you, any final thoughts or advice for folks that might be interested

550
00:35:20,160 --> 00:35:24,760
in pursuing, either getting involved in FDL or doing similar research?

551
00:35:24,760 --> 00:35:31,240
Yeah, I'd say, just go for it, you know, I grew up in the UK, I never imagined for a

552
00:35:31,240 --> 00:35:36,240
second that I could be working alongside NASA scientists or living on a NASA facility.

553
00:35:36,240 --> 00:35:38,360
Similar program was absolutely excellent.

554
00:35:38,360 --> 00:35:44,240
If you're wanting to get involved in machine learning, start reading online, take small

555
00:35:44,240 --> 00:35:46,120
goals, keep assuring them.

556
00:35:46,120 --> 00:35:50,000
It's very easy to be like, should I learn this machine learning algorithm today, or

557
00:35:50,000 --> 00:35:54,920
should I watch another season of my favorite TV show, put short-term goals, keep going

558
00:35:54,920 --> 00:35:59,200
for it, and you'll be able to contribute in this new and exciting field as well.

559
00:35:59,200 --> 00:36:00,200
Awesome, awesome.

560
00:36:00,200 --> 00:36:03,200
And how about from you, any parting thoughts?

561
00:36:03,200 --> 00:36:08,680
Yeah, in total doing a lot of exciting work to advance AI, and you can check out what

562
00:36:08,680 --> 00:36:15,840
we're doing at internalrunner.com, in addition of developing this new, the Blurnexelerator,

563
00:36:15,840 --> 00:36:22,360
we've optimized the framework, so if you were to do deep learning on CPUs, today you'll

564
00:36:22,360 --> 00:36:28,400
see significant gains in performance, and if you were, if you had tried to do deep learning

565
00:36:28,400 --> 00:36:34,560
on CPUs a year ago, or even six months ago, so it's an exciting time.

566
00:36:34,560 --> 00:36:42,920
We want to democratize the use of deep learning, and most facilities have Intel CPUs, so we

567
00:36:42,920 --> 00:36:48,720
hope that they can be put to good use, such as we did with FDL.

568
00:36:48,720 --> 00:36:52,720
On that note, for the hobbyist, Intel does have an AI bootcamp that provides a lot of

569
00:36:52,720 --> 00:36:57,400
resources available for people to learn how to use Intel Nirvana, oh, Intel AI, I think

570
00:36:57,400 --> 00:37:02,200
it's called now, and yeah, get involved and get their hands dirty with the final points

571
00:37:02,200 --> 00:37:03,920
of learning machine learning.

572
00:37:03,920 --> 00:37:09,560
Awesome, as well as the dev cloud offering, which I did an interview, I forget which episode

573
00:37:09,560 --> 00:37:13,440
it was, but we'll put that in the show notes as well, folks can sign up for access to that

574
00:37:13,440 --> 00:37:14,440
too.

575
00:37:14,440 --> 00:37:15,440
Thanks.

576
00:37:15,440 --> 00:37:16,440
Awesome.

577
00:37:16,440 --> 00:37:20,080
Well, Sarah Andres, Tim, thanks so much for taking the time to chat.

578
00:37:20,080 --> 00:37:21,080
Thank you.

579
00:37:21,080 --> 00:37:24,080
Thank you for trying that out.

580
00:37:24,080 --> 00:37:29,920
All right, everyone, that's our show for today.

581
00:37:29,920 --> 00:37:34,960
Thanks so much for listening, and for your continued feedback and support.

582
00:37:34,960 --> 00:37:41,240
For more information on Sarah, Timothy, Andres, or any of the topics covered in this episode,

583
00:37:41,240 --> 00:37:45,840
head on over to twimlai.com slash talk slash 89.

584
00:37:45,840 --> 00:37:52,760
To follow along with the nip series, visit twimlai.com slash nips 2017.

585
00:37:52,760 --> 00:37:59,400
To enter our twimla 1 mil contest, visit twimlai.com slash twimla 1 mil.

586
00:37:59,400 --> 00:38:04,160
Of course, we'd be delighted to hear from you either via a comment on the show notes

587
00:38:04,160 --> 00:38:10,320
page or via a tweet to at twimlai or at Sam Charrington.

588
00:38:10,320 --> 00:38:14,880
Thanks once again to Intel Nirvana for their sponsorship of this series.

589
00:38:14,880 --> 00:38:19,560
To learn more about the Intel Nirvana NNP and the other things Intel's been up to in

590
00:38:19,560 --> 00:38:23,800
the AI arena, visit intel Nirvana.com.

591
00:38:23,800 --> 00:38:28,560
As I mentioned a few weeks back, this will be our final series of shows for the year.

592
00:38:28,560 --> 00:38:33,800
So take your time and take it all in and get caught up on any of the old pods you've been

593
00:38:33,800 --> 00:38:35,400
saving up.

594
00:38:35,400 --> 00:38:37,840
Happy Holidays and Happy New Year.

595
00:38:37,840 --> 00:38:40,120
See you in 2018.

596
00:38:40,120 --> 00:39:06,880
And of course, thanks once again for listening and catch you next time.

