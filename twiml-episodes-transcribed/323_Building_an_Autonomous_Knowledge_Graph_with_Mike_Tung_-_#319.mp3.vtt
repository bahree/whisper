WEBVTT

00:00.000 --> 00:15.920
Welcome to the Twimble AI Podcast, I'm your host Sam Charrington.

00:15.920 --> 00:22.680
Hey, what's up everyone?

00:22.680 --> 00:26.680
If it's been a while since you've checked out the Twimble online community, now would

00:26.680 --> 00:29.960
be a really good time to stop by and get reacquainted.

00:29.960 --> 00:33.680
We've got a ton of interesting things happening for folks looking to grow their machine learning

00:33.680 --> 00:35.680
and AI knowledge.

00:35.680 --> 00:38.280
Here's a sample of what's new.

00:38.280 --> 00:42.720
The new Kaggle Slash Projects Meetup, led by Michael, Christine, Philip, and Mahul,

00:42.720 --> 00:45.040
is off to a very strong start.

00:45.040 --> 00:49.800
They'll be meeting on Saturdays at 10am Pacific and focused on competing in Kaggle competitions

00:49.800 --> 00:56.200
together, and more generally supporting one another and working on ML and AI projects.

00:56.200 --> 01:00.040
If natural language processing is more your interest, we've got a study group for the

01:00.040 --> 01:04.160
Fast.ai NLP course starting December 14th.

01:04.160 --> 01:08.960
The course will cover NLP applications like topic modeling, classification, language

01:08.960 --> 01:11.000
modeling, and translation.

01:11.000 --> 01:15.240
If that sounds interesting but you don't want to wait, the Fast.ai deep learning from

01:15.240 --> 01:20.160
the foundation study group is starting Lesson 12 this Saturday, which is essentially

01:20.160 --> 01:23.240
a three week NLP crash course.

01:23.240 --> 01:25.440
You're welcome to join in.

01:25.440 --> 01:29.560
We've also got group leaders organizing study groups for the Fast.ai deep learning for

01:29.560 --> 01:35.320
coders, i.e. the Part 1 course, which is a great place to get started with deep learning,

01:35.320 --> 01:41.040
as well as Andrew Ng's deeplearning.ai course, which takes a more traditional and math oriented

01:41.040 --> 01:42.600
take on the topic.

01:42.600 --> 01:46.800
Finally, if you're more interested in learning how to use and deploy machine learning and

01:46.800 --> 01:52.080
AI in the Enterprise, I'll be leading a study group focused on the IBM AI Enterprise

01:52.080 --> 01:57.000
workflow certification, which is a sequence of courses hosted over on Coursera.

01:57.000 --> 01:59.120
That group will start in January.

01:59.120 --> 02:04.120
The way to get started with any of this is to join the Twimal community at twimalai.com

02:04.120 --> 02:06.120
slash community.

02:06.120 --> 02:09.720
Submitting that form will get you invited to our Slack, and once you're there, you can

02:09.720 --> 02:12.680
join the appropriate study group channels.

02:12.680 --> 02:17.680
Hope to see you online.

02:17.680 --> 02:22.840
All right, everyone. I am on the line with Mike Tong. Mike is the founder and CEO of Diffbot.

02:22.840 --> 02:26.240
Mike, welcome to the Twimal AI podcast.

02:26.240 --> 02:27.800
Thanks for having me, Sam.

02:27.800 --> 02:30.560
Yeah, I am looking forward to this chat.

02:30.560 --> 02:36.360
We first talked about cover Diffbot in a newsletter.

02:36.360 --> 02:40.960
When you announce, I think it was the company's knowledge graph project, and the headline

02:40.960 --> 02:46.400
of that newsletter was all the world's knowledge on tap, and so it's taken us a while, but

02:46.400 --> 02:50.080
we will finally dig into what that was all about.

02:50.080 --> 02:53.720
But before we do, let's explore your background a little bit.

02:53.720 --> 02:56.240
You were a patent lawyer at one point.

02:56.240 --> 02:57.240
Yes.

02:57.240 --> 03:01.920
Among many random jobs I've held, quick background on me.

03:01.920 --> 03:03.880
I'm a machine learning researcher, right?

03:03.880 --> 03:09.960
So I studied at Berkeley electrical engineering, and then at Stanford, I started grad school

03:09.960 --> 03:20.040
in AI, and I've worked as a software engineer before at Microsoft, at eBay, and Yahoo.

03:20.040 --> 03:26.040
I was the founder of a startup that was sold to Cisco, called Click.TV, that was like a video

03:26.040 --> 03:31.080
search engine, and I was a founding engineer of a startup called Defined that was a product

03:31.080 --> 03:32.080
search engine.

03:32.080 --> 03:37.040
I was sold to Facebook, and in between all that, while I was in grad school, doing research

03:37.040 --> 03:40.880
and AI, I held a side job as a patent attorney.

03:40.880 --> 03:44.440
So as a patent prosecutor, helping people write patents.

03:44.440 --> 03:53.240
So I was the patent prosecutor for Panasonic out here in the Bay Area, and that's sort

03:53.240 --> 03:56.320
of how I bootstrapped the company and paid the bills at the very beginning.

03:56.320 --> 04:02.160
So I got really good at writing patents, could basically pull all nighters and jam out

04:02.160 --> 04:04.640
a patent over the weekend and make like 20K.

04:04.640 --> 04:08.320
So I have like my rent covered for a few months here in the Bay Area.

04:08.320 --> 04:09.320
That's awesome.

04:09.320 --> 04:14.000
So does that mean that before the engineering degrees, you had a law degree?

04:14.000 --> 04:18.840
No, so the thing about patent law is, you know, first of all, it's federal, right?

04:18.840 --> 04:20.640
So it's Washington, DC.

04:20.640 --> 04:25.880
So you don't have to have a state bar, but you get the patent bar.

04:25.880 --> 04:31.440
So all I did was I sat for the patent bar, took that exam, passed it, and could represent

04:31.440 --> 04:33.800
clients and helping them get patents.

04:33.800 --> 04:34.800
That's awesome.

04:34.800 --> 04:41.000
I wonder if we'll have any takers, you know, listeners that try to pick up this side hustle.

04:41.000 --> 04:42.800
Sounds like a nice one.

04:42.800 --> 04:46.120
Well, I really doubt tell with my interest, right?

04:46.120 --> 04:51.000
Because I mean, patents are kind of, especially the claims part of the patent is almost

04:51.000 --> 04:54.880
like a programming language in itself, it's a legal programming language.

04:54.880 --> 04:58.920
And to write the description part of the patent, you have to be technical, right?

04:58.920 --> 05:03.160
So you have to be an engineer and I was, since I had a CS and electrical engineering

05:03.160 --> 05:07.720
training, I was able to translate that into a patent language.

05:07.720 --> 05:11.840
And then think of like alternative embodiments of the invention, right, that the inventor

05:11.840 --> 05:12.840
came up with.

05:12.840 --> 05:13.840
Nice.

05:13.840 --> 05:14.840
Nice.

05:14.840 --> 05:23.000
Yeah, my sister sat out to Lori is a patent, an IP lawyer at Intel.

05:23.000 --> 05:28.960
And we have really interesting conversations about the public aspects of what she does.

05:28.960 --> 05:31.640
It definitely sounds like interesting work.

05:31.640 --> 05:37.240
But you know, on to machine learning AI and Diffbot, tell us a little bit about the

05:37.240 --> 05:38.240
company.

05:38.240 --> 05:47.480
You know, as I mentioned, I was at Stanford in grad school and, you know, I was, you know,

05:47.480 --> 05:51.520
kind of procrastinating from writing my thesis, you know, and thinking of like what kind

05:51.520 --> 05:55.080
of area of AI research to specialize in.

05:55.080 --> 06:01.280
But I realized that, you know, there's essentially three key drivers to improving AI, right?

06:01.280 --> 06:03.640
There's people that work on the hardware.

06:03.640 --> 06:07.080
There's people that work on improving the software and algorithms.

06:07.080 --> 06:09.760
And there's people that work on data, right?

06:09.760 --> 06:15.120
And there's large public companies that focus on essentially Moore's law, like making the

06:15.120 --> 06:20.080
hardware faster, like NVIDIA and, you know, where your relative works at Intel, right?

06:20.080 --> 06:22.360
They're making the chips faster.

06:22.360 --> 06:28.280
There's tons of people now making the algorithms better, right, including what I was supposed

06:28.280 --> 06:33.600
to be doing as a grad student, as well as, you know, things like TensorFlow and PyTorch,

06:33.600 --> 06:35.000
like these actual frameworks.

06:35.000 --> 06:39.680
Yeah, I was going to say, I'd argue that there's at least a fourth category of tools that

06:39.680 --> 06:44.880
support the folks that are using the algorithms, but not to take away from your point.

06:44.880 --> 06:45.880
I get it.

06:45.880 --> 06:46.880
Totally.

06:46.880 --> 06:48.680
Yeah, the tools, I mean, I would include that in software, right?

06:48.680 --> 06:53.360
It's the algorithms itself plus a software, but yeah, you could separate that out.

06:53.360 --> 06:57.680
But the third category data, I feel like there isn't like sort of like an everything

06:57.680 --> 06:59.200
store of data, right?

06:59.200 --> 07:05.480
If you're building an AI application, you generally have the data as part of your current

07:05.480 --> 07:06.480
process, right?

07:06.480 --> 07:10.920
Or you start rolling up your own sleeves and gathering information, right?

07:10.920 --> 07:16.440
So this became really clear, actually, at that time, I was at Stanford because that's around,

07:16.440 --> 07:21.040
you know, just down the hall, Fei-Fei Li was coming up with the ImageNet, right?

07:21.040 --> 07:25.640
Which is a very large set of annotated images, right?

07:25.640 --> 07:29.880
And, you know, I think it's like about a million images classified into about a thousand

07:29.880 --> 07:33.360
since set categories of WordNet.

07:33.360 --> 07:38.240
And that dataset is really what kicked off the deep learning revolution, right?

07:38.240 --> 07:41.720
Just that amount of labeled structured data.

07:41.720 --> 07:46.520
And so, you know, a lot of neural networks were invented way before, right?

07:46.520 --> 07:52.280
Like in the 70s and 80s, and we've made some tweaks to improve how fast they train

07:52.280 --> 07:57.040
and our new architectures and so forth, but it was really that dataset that made computer

07:57.040 --> 08:01.720
vision go from something that was basically a research grade, you know, task into something

08:01.720 --> 08:03.320
that's production grade, right?

08:03.320 --> 08:06.960
Something that's a little bit better than random to something that's approaching human

08:06.960 --> 08:10.480
level of classification accuracy.

08:10.480 --> 08:13.840
So at that time, I was thinking about, you know, how could you build like an ImageNet

08:13.840 --> 08:17.560
for language or general concepts, right?

08:17.560 --> 08:22.080
And the way that they built ImageNet, basically using Google Image Search and Amazon Mechanical

08:22.080 --> 08:29.400
Turk, you would require a calculated about 50 manures with a team of about 20 people to

08:29.400 --> 08:34.120
build a similar kind of dataset for language because there's languages way more complex

08:34.120 --> 08:35.120
than vision, right?

08:35.120 --> 08:41.600
Like human beings alone have language and like all animals have computer vision.

08:41.600 --> 08:43.000
But then there's way more concepts, right?

08:43.000 --> 08:47.760
So if you think about a number of concepts even on Wikipedia, there's about a million or

08:47.760 --> 08:54.240
so a quarter of magnitude pages on Wikipedia and so just having about a thousand labeled

08:54.240 --> 09:00.320
examples of each of those concepts, you quickly stack up like how much it would take.

09:00.320 --> 09:03.960
So I started thinking about, well, where is all this knowledge?

09:03.960 --> 09:06.280
It exists on the public web.

09:06.280 --> 09:11.440
It's the web is the largest, you know, resource of public knowledge we have as a species.

09:11.440 --> 09:15.680
But the problem is the information is stored in all of these documents.

09:15.680 --> 09:17.680
So it's not structured data, right?

09:17.680 --> 09:19.000
It's not machine readable.

09:19.000 --> 09:24.200
And so if only we could create an algorithm that could actually read and understand all

09:24.200 --> 09:29.160
of those pages on the web and convert it into a coherent machine readable structure, then

09:29.160 --> 09:33.920
we would have solved this problem, essentially using AI.

09:33.920 --> 09:37.040
And so that got me to thinking about the idea behind Diffbot.

09:37.040 --> 09:42.360
So the mission of our company is to build the world's first complete map of the human knowledge

09:42.360 --> 09:48.200
and make it machine readable so that other companies can build all kinds of smart experiences

09:48.200 --> 09:49.920
are on top of it.

09:49.920 --> 09:54.320
And so we can have that future that we all won't watch with intelligent agents all around

09:54.320 --> 09:55.320
us, right?

09:55.320 --> 09:58.080
That can benefit from structured information.

09:58.080 --> 09:59.080
So how to do that?

09:59.080 --> 10:04.400
It's kind of a big, a big task and we don't have the resources, you know, bootstrapping

10:04.400 --> 10:07.600
to crawl the whole internet from day one.

10:07.600 --> 10:15.400
In fact, one of the first things that I thought as you kind of laid out that mission is, you

10:15.400 --> 10:20.760
know, Google and Microsoft are both out there talking about their knowledge graphs and

10:20.760 --> 10:27.920
how they're kind of the very core of what they're able to do in many cases, machine learning

10:27.920 --> 10:29.760
and AI and beyond.

10:29.760 --> 10:30.760
Yeah.

10:30.760 --> 10:35.720
A lot of those come from, you know, their experience is building the Google and being search

10:35.720 --> 10:37.440
engines.

10:37.440 --> 10:43.760
You know, massive, massive investments in pulling all that together, sounds like how can we

10:43.760 --> 10:44.760
do it?

10:44.760 --> 10:45.760
Exactly.

10:45.760 --> 10:49.680
That's a lot of people ask us for sure.

10:49.680 --> 10:52.040
So how Google really coined that word knowledge graph.

10:52.040 --> 10:57.880
So how they did it is basically the history behind that, they acquired a company called

10:57.880 --> 10:58.880
MetaWeb, right?

10:58.880 --> 11:04.440
They had a project called Freebase and Freebase was essentially that.

11:04.440 --> 11:09.560
It's Freebase was basically imported all of the information from Wikipedia, those info

11:09.560 --> 11:11.240
boxes on Wikipedia.

11:11.240 --> 11:16.120
And then they had like a crowd editor that basically kind of allowed you to edit Freebase,

11:16.120 --> 11:17.600
like random people on the internet, right?

11:17.600 --> 11:19.160
So kind of crowdsourcing the problem.

11:19.160 --> 11:20.160
Mm-hmm.

11:20.160 --> 11:21.160
And Google acquired.

11:21.160 --> 11:22.160
Yeah.

11:22.160 --> 11:23.160
Sorry.

11:23.160 --> 11:24.160
Go ahead.

11:24.160 --> 11:25.160
Yeah.

11:25.160 --> 11:29.920
It's interesting that I think I envisioned something much more, I don't know, glamorous

11:29.920 --> 11:36.840
is the right word, but you know, something more learned than something that started with

11:36.840 --> 11:37.840
Wikipedia.

11:37.840 --> 11:44.360
Like they kind of used the page rank graph and figured out what the concepts were and

11:44.360 --> 11:47.880
you know, did something, I guess exotic is what I envisioned.

11:47.880 --> 11:48.880
Yeah.

11:48.880 --> 11:51.880
I mean, people just, they have the assumption that, okay, they're Google, they have infinite

11:51.880 --> 11:52.880
resources.

11:52.880 --> 11:55.040
So everything is machine learning, right?

11:55.040 --> 11:56.040
You see, right?

11:56.040 --> 11:59.440
The knowledge channels and everything like that, right?

11:59.440 --> 12:05.080
But the reality is, when you're searching on Google, only things that generally have a

12:05.080 --> 12:09.600
Wikipedia page have a knowledge panel, at least that was originally when it launched,

12:09.600 --> 12:13.840
like you type in someone who's famous and you'll get a knowledge panel, right?

12:13.840 --> 12:15.760
But you type in like a regular Joe, right?

12:15.760 --> 12:19.640
Or you type in one of your relatives, your friends, your colleagues, they don't get a knowledge

12:19.640 --> 12:20.640
panel, right?

12:20.640 --> 12:21.640
Look, why is that?

12:21.640 --> 12:22.640
Because no one's added it.

12:22.640 --> 12:28.480
You know, it's actually great, even though there's pages about them for sure, right?

12:28.480 --> 12:35.400
And so what the, at these large companies, many of which are customers actually go more

12:35.400 --> 12:42.000
into that, you know, if we have time, but they basically start out with Wikipedia and then

12:42.000 --> 12:44.720
allow there's ability to edit and curate it.

12:44.720 --> 12:48.840
And then this knowledge graph basically becomes like a file format within the company that

12:48.840 --> 12:51.200
many teams contribute to actually, right?

12:51.200 --> 12:54.920
So a lot of these data sources, they're licensed from third parties, right?

12:54.920 --> 12:59.680
Like the sports scores and things like that, the weather feeds and stats, other pieces

12:59.680 --> 13:05.320
of information that go into it are built by a specific department at the company.

13:05.320 --> 13:09.240
So there'll be like a recipes department that focuses on the recipe section of the knowledge

13:09.240 --> 13:10.240
graph.

13:10.240 --> 13:14.880
And they'll have an entire army of curators and stuff that is uncurrating those particular

13:14.880 --> 13:15.880
sections.

13:15.880 --> 13:21.960
But the different knowledge graph is the only one that is fully built by an autonomous

13:21.960 --> 13:22.960
system, right?

13:22.960 --> 13:27.640
We don't have the resources to hire thousands of curators and labelers to curate all

13:27.640 --> 13:30.200
different aspects of knowledge.

13:30.200 --> 13:34.880
So the biggest difference is between us is a, well, first of all, our knowledge graph is

13:34.880 --> 13:35.880
much larger, right?

13:35.880 --> 13:39.760
Because it's based on actually a different technique of crawling all the pages on the web and

13:39.760 --> 13:41.400
building it.

13:41.400 --> 13:47.120
So it does have like those average Joe entities and startups and smaller companies in it.

13:47.120 --> 13:51.400
It has about 10 billion entities in the knowledge graph and about a trillion edges.

13:51.400 --> 13:57.680
Thirdly, it's, secondly, sorry, it's, you know, it's available for use, right?

13:57.680 --> 14:01.720
So it's not just for like consumer search where, you know, it's good for like the Kanye

14:01.720 --> 14:03.800
West or Taylor Swift query, right?

14:03.800 --> 14:08.320
But it's good for the kinds of entities that you would interact with in the business world,

14:08.320 --> 14:10.040
your suppliers, your vendors, right?

14:10.040 --> 14:12.640
Your customers, people you're trying to recruit, right?

14:12.640 --> 14:16.600
So I always like to say, you're not usually trying to recruit, you know, like Donald Trump

14:16.600 --> 14:20.440
or like higher tide, you know, sell something to Tiger Woods, these kind of entities that

14:20.440 --> 14:23.640
are in these consumer knowledge graphs, right?

14:23.640 --> 14:27.920
But those entities that you would deal with in the business world are actually in ours.

14:27.920 --> 14:32.400
So ours, I would argue, is much more useful to building real things.

14:32.400 --> 14:34.080
And then you can use it.

14:34.080 --> 14:35.520
So that's a very important point too.

14:35.520 --> 14:39.360
Like the Google Knowledge Graph, you can't actually pay like to access it, right?

14:39.360 --> 14:44.000
And that has to do with, you know, for strategic and business reasons, they don't want people

14:44.000 --> 14:48.640
to just build a skin on top of Google and, and they just have like a, you know, a competitive

14:48.640 --> 14:51.840
product offering.

14:51.840 --> 14:56.200
So they haven't focused on that as their main revenue model.

14:56.200 --> 15:02.680
One of the use cases that I often hear Google and Microsoft talking about the contribution

15:02.680 --> 15:06.480
of their knowledge graphs is with virtual assistants.

15:06.480 --> 15:13.640
Do you find folks using Diffbot as a kind of foundational component for building that

15:13.640 --> 15:17.640
kind of virtual assistant bot experience?

15:17.640 --> 15:18.640
Yes.

15:18.640 --> 15:23.200
I can't share too many details, right, about the companies that use it in that way.

15:23.200 --> 15:27.120
But they include big companies as well as startups.

15:27.120 --> 15:32.400
The main problem that everyone's trying to solve in this category is basically a virtual

15:32.400 --> 15:36.800
assistant needs to have knowledge in order to be intelligent, right?

15:36.800 --> 15:41.640
Most of the time you ask Alexa or Siri a question, you know, if it hasn't been something that's

15:41.640 --> 15:44.960
been pre-programmed and it's not going to be able to answer that, right?

15:44.960 --> 15:48.480
You have to almost talk like a robot to communicate with these systems.

15:48.480 --> 15:52.400
You have to talk in certain templates, right?

15:52.400 --> 15:55.920
And if they could solve actually the problem of knowledge, they'd be able to answer, right?

15:55.920 --> 15:58.080
Almost any question that's, that's askable.

15:58.080 --> 15:59.440
That's like a public fact.

15:59.440 --> 16:04.000
That is definitely one of the applications that we see of the knowledge graph.

16:04.000 --> 16:09.720
In general, though, we have, you know, over 400 companies that currently use Diffbot.

16:09.720 --> 16:13.640
There's, that's example of a consumer application, like an intelligent assistant.

16:13.640 --> 16:18.800
We have a lot of the major search engines like DuckDuckGo, Yandex, Bing, where we're

16:18.800 --> 16:22.280
powering like their knowledge panels that you see, you know, so we're powering parts

16:22.280 --> 16:24.840
of their knowledge experience.

16:24.840 --> 16:29.880
And then we have a lot of consumer apps like Instapaper, Snapchat, we power like the articles

16:29.880 --> 16:30.880
for you and that.

16:30.880 --> 16:35.080
There's like a wedding planning app, Zola, where people build like a wedding registry.

16:35.080 --> 16:37.640
And then there's a whole bunch of business process applications.

16:37.640 --> 16:39.800
So you can use a knowledge graph to find sales leads.

16:39.800 --> 16:42.120
You can use it to find people to hire.

16:42.120 --> 16:47.120
You can use it to enrich your current CRM to better understand your customer insights,

16:47.120 --> 16:48.120
right?

16:48.120 --> 16:51.720
If you're a brand, you can use it to track like all the places online that are selling

16:51.720 --> 16:56.680
Nike's and monitor if anyone's selling fake Nike's or have counterfeit goods and things

16:56.680 --> 16:57.680
like that.

16:57.680 --> 17:03.960
So there's a whole bunch of BI and market intelligence applications too that we're seeing

17:03.960 --> 17:04.960
now.

17:04.960 --> 17:05.960
This new product.

17:05.960 --> 17:06.960
Interesting.

17:06.960 --> 17:10.280
And so what's the typical user developer experience?

17:10.280 --> 17:15.400
So if you're a developer wanting to use DiffBots products, there's basically three main ways

17:15.400 --> 17:16.640
you can use it.

17:16.640 --> 17:18.880
The first is our extraction APIs, right?

17:18.880 --> 17:24.040
So you can pass in an individual URL from the web to our endpoint and then our machine

17:24.040 --> 17:27.800
learning will classify that URL and then extract it into an entity, right?

17:27.800 --> 17:31.920
So if you pass in like a product page, it'll say this is a product page.

17:31.920 --> 17:36.640
It's a type product and here's the price and here's the image and name of the product

17:36.640 --> 17:41.480
and description and SKU and weight and all those product facts, right?

17:41.480 --> 17:48.120
Actually, let's just pause on that because I've got a little bit of experience trying

17:48.120 --> 17:49.760
to extract data from pages.

17:49.760 --> 17:55.880
I'm sure a lot of people that are listening have tried to do this and it is historically

17:55.880 --> 17:56.880
very, very hard.

17:56.880 --> 18:02.200
I mean, you have, first of all, trying to do if you're doing it based on regular expressions

18:02.200 --> 18:05.840
or X-Path, there's all different kinds of ways to do it.

18:05.840 --> 18:07.640
They're all super fragile.

18:07.640 --> 18:10.080
The sites change and they break all the time.

18:10.080 --> 18:11.040
They break all those roles.

18:11.040 --> 18:12.040
Yeah.

18:12.040 --> 18:13.040
Right.

18:13.040 --> 18:16.560
So what you're saying sounds like magic, like, you know?

18:16.560 --> 18:17.560
Yeah.

18:17.560 --> 18:19.560
So we launched that on hacker news, right?

18:19.560 --> 18:24.200
I'm sure some of your listeners are familiar with that site and that's what a lot of

18:24.200 --> 18:25.200
developers say.

18:25.200 --> 18:27.320
This is basically like magic.

18:27.320 --> 18:31.800
As an alternative, you'd have to use something like impar.io or scrapy, right?

18:31.800 --> 18:35.560
And like you said, create all these patterns and then maintain them.

18:35.560 --> 18:39.600
That's actually fine if you just want to get information from one site on a one time

18:39.600 --> 18:40.600
job, right?

18:40.600 --> 18:41.600
Right.

18:41.600 --> 18:42.680
And maybe take a few minutes to configure that.

18:42.680 --> 18:46.680
But it's a problem when you want an ongoing process, right?

18:46.680 --> 18:49.880
And you want to get information at large scale, like from thousands of sites, right?

18:49.880 --> 18:54.120
It starts to become tractable to maintain that, like 15% of your roles will break each

18:54.120 --> 18:55.120
week, right?

18:55.120 --> 18:56.120
Right.

18:56.120 --> 18:57.120
Right.

18:57.120 --> 19:01.600
And so with the machine learning based approach, it's robust to any changes, like you

19:01.600 --> 19:05.720
said in the design or the layout and you don't have to create any roles.

19:05.720 --> 19:09.160
You just pass in the URL and we don't have to create any roles because you can literally

19:09.160 --> 19:10.440
pass in a URL from anywhere.

19:10.440 --> 19:13.160
So it's like we can't, right?

19:13.160 --> 19:18.280
And then the other thing that's quite distinctive too is it works across any language on the web

19:18.280 --> 19:19.280
too.

19:19.280 --> 19:23.440
So you can pass in a page, like a Japanese e-commerce page, which has totally different

19:23.440 --> 19:24.440
design conventions, right?

19:24.440 --> 19:28.960
Or like a German article page and it'll parse it perfectly as well.

19:28.960 --> 19:32.120
So a lot of people use it because of that aspect.

19:32.120 --> 19:37.280
So that was our first product, really popular as an alternative to writing your own custom

19:37.280 --> 19:38.800
web scraper.

19:38.800 --> 19:41.160
The second way developers can use it is called crawlbot.

19:41.160 --> 19:44.760
So that's crawling an entire domain essentially, right?

19:44.760 --> 19:49.480
So it'll start from those C-D-R-Ls and then it'll, that's how you can get essentially

19:49.480 --> 19:51.360
the entire database from a site, right?

19:51.360 --> 19:56.440
So you can say, I want all of the products from Target, Macy's, J-Crew, Dan or Republic

19:56.440 --> 20:02.600
Home Depot, and then you get the entire product catalog, right, of those sites synchronized.

20:02.600 --> 20:05.400
And then the third way is, of course, the knowledge graph.

20:05.400 --> 20:09.680
And the way that you interface with that as a developer is with the Diffbot query language,

20:09.680 --> 20:13.280
which is basically kind of like a structured semantic search.

20:13.280 --> 20:17.600
So you can almost search the web as if it was like a huge, you know, a structured semantic

20:17.600 --> 20:19.480
database.

20:19.480 --> 20:25.080
And we also have like a UI that allows you to help you build those queries, sort of for

20:25.080 --> 20:26.640
the less technical users.

20:26.640 --> 20:32.040
And then for like business users, we integrate, right, the knowledge graph into the tools

20:32.040 --> 20:33.040
they already use, right?

20:33.040 --> 20:37.920
So you can export it as CSV, and so you can open it in Excel, or you, we plan to build

20:37.920 --> 20:44.720
integrations directly into things like Tableau, Salesforce, Excel, the actual tools that you

20:44.720 --> 20:50.400
might be, you know, your actual daily driver, right, where you're doing your data manipulation,

20:50.400 --> 20:53.160
being able to tap into the knowledge graph directly from those.

20:53.160 --> 20:58.320
And so when you're writing these queries, you're using machine learning on the backend

20:58.320 --> 21:05.920
to do the crawling and kind of understand the pages and please elaborate on what specifically

21:05.920 --> 21:08.280
you're doing there.

21:08.280 --> 21:15.720
But are you also applying some kind of machine learning and interpreting the query itself?

21:15.720 --> 21:20.680
So, you know, if I put in a term, it's not just the literal term, but maybe hitting

21:20.680 --> 21:24.920
some embedding or, you know, abstraction that's kind of trying to figure out what I'm looking

21:24.920 --> 21:25.920
for.

21:25.920 --> 21:30.560
Yeah, so there's, like I was saying earlier in this call, like our almost our entire company

21:30.560 --> 21:32.680
is one big machine learning problem.

21:32.680 --> 21:37.040
There's about actually like a 50 or 60 separate machine learning problems that we study

21:37.040 --> 21:38.040
at the bottom, right?

21:38.040 --> 21:43.920
So we're about a, now a 35 person company and like 80% of our company is machine learning

21:43.920 --> 21:45.920
researchers.

21:45.920 --> 21:52.980
So when we crawled the web, that's largely, our VP of Search is Matt Wells, he was the

21:52.980 --> 21:55.360
founder of a search engine called Gigablast, right?

21:55.360 --> 22:00.720
So that's how we're able to, as a small start up, crawl the full web.

22:00.720 --> 22:03.480
But what we, what differs is we render the whole web.

22:03.480 --> 22:08.960
So we're actually running the web inside real, real browsing engines and playing the web,

22:08.960 --> 22:10.720
almost like a video game.

22:10.720 --> 22:15.160
We serialize from every page, essentially all the pixels on the page, the geometry of

22:15.160 --> 22:20.560
the page, all the visual styles and layout and the internal state of the virtual machine,

22:20.560 --> 22:23.440
the JavaScript and CSS layout engine.

22:23.440 --> 22:27.360
And those are essentially just like a long, you know, string of numbers.

22:27.360 --> 22:32.280
And that's where our algorithms use those numbers to classify the type of the page, right?

22:32.280 --> 22:35.480
So this page look like a article page.

22:35.480 --> 22:41.000
It has a very different look and layout from a article page or a product page or like

22:41.000 --> 22:42.400
a person page.

22:42.400 --> 22:46.000
And then we use machine learning to extract the particular fields after we've classified

22:46.000 --> 22:47.000
it, right?

22:47.000 --> 22:52.040
So on a product page, look for the things that look like the price of the product, look

22:52.040 --> 22:54.880
for the things that look like the image of the product, right?

22:54.880 --> 22:58.760
And then analyze the actual image to determine what's the color of the product, what material

22:58.760 --> 22:59.760
is it made from?

22:59.760 --> 23:00.760
Right?

23:00.760 --> 23:06.760
Is it a, you know, red sports car inside at which model of cars it, right?

23:06.760 --> 23:09.400
Is it a brown sweater, right?

23:09.400 --> 23:13.400
Like what kind of fabric and swatch pattern and such and so forth.

23:13.400 --> 23:16.880
And then we're analyzing the text of the page as well.

23:16.880 --> 23:24.160
So, you know, inside an organization's description, it might include like what is the category

23:24.160 --> 23:27.320
of that organization when it was founded, where it's based, right?

23:27.320 --> 23:29.840
Who are the main officers of the company?

23:29.840 --> 23:35.160
So to do that, you need to do various kinds of natural language processing.

23:35.160 --> 23:40.520
So we have folks that have developed the state of the art in entity linking, working at

23:40.520 --> 23:43.240
Diffbot to find the entities in the text.

23:43.240 --> 23:47.520
We do what's called a relation extraction to find the relations between those entities.

23:47.520 --> 23:49.560
And we also do machine translation, right?

23:49.560 --> 23:55.040
Because the text could be a non-English to start out with like Arabic or Chinese, right?

23:55.040 --> 24:00.000
And then once we've extracted these things, we then need to be able to link it across pages,

24:00.000 --> 24:01.000
right?

24:01.000 --> 24:06.120
There could be one page about Sam Charrington and then another one on a different page

24:06.120 --> 24:07.120
on the web.

24:07.120 --> 24:08.680
But we know they're the same real world person, right?

24:08.680 --> 24:12.280
You don't want to have two entries in the knowledge graph for that, right?

24:12.280 --> 24:16.480
So we need to use machine learning to link together those extractions across multiple

24:16.480 --> 24:17.720
pages.

24:17.720 --> 24:22.200
And then we work on a problem called knowledge fusion, which is given all that evidence,

24:22.200 --> 24:25.080
what is the probability of truth of each of those statements?

24:25.080 --> 24:28.760
And then we write the really highly confident facts, like as triples, into the knowledge

24:28.760 --> 24:29.760
graph.

24:29.760 --> 24:34.400
And that's kind of like end-to-end kind of soup to nuts, how it goes from a page into

24:34.400 --> 24:38.360
an entity, right, inside this AI-sensized system.

24:38.360 --> 24:42.640
We build a new knowledge graph, like around every four days.

24:42.640 --> 24:47.440
And then on the query side, of course, we have structured querying, right, like such as

24:47.440 --> 24:52.560
the default query language, there can be ambiguity, right, in parts of the syntax.

24:52.560 --> 24:58.400
Like if I say I'm looking for machine learning engineers that live in Mountain View, well,

24:58.400 --> 25:01.880
it needs to interpret whether that's Mountain View, California, or Mountain View, Arkansas,

25:01.880 --> 25:02.880
right?

25:02.880 --> 25:05.040
There's another city over there that's called Mountain View.

25:05.040 --> 25:08.000
There's also another Mountain View, you know, outside of the US.

25:08.000 --> 25:11.280
But we all know which one, you know, we're likely referring to.

25:11.280 --> 25:16.080
So it needs to take in the stats, right, to interpret that statement.

25:16.080 --> 25:19.680
And then we're also doing at the research level, natural language question answering, right,

25:19.680 --> 25:23.880
which is more in line with the kind of earlier question about assistance.

25:23.880 --> 25:24.880
Yeah.

25:24.880 --> 25:28.600
You know, what's fascinating about this is that, you know, when you talk about the extraction

25:28.600 --> 25:36.920
problem and identifying the pictures and identifying the, you know, what's probably the price,

25:36.920 --> 25:45.120
it sounds both super, you know, simple, really from the straight forward, but also like

25:45.120 --> 25:48.840
terribly, terribly complex at scale.

25:48.840 --> 25:54.360
The trick is getting it to, it's easy to get 80% accuracy, but to get to the level back

25:54.360 --> 25:59.200
or see needed by commercial customers, you know, and at an at scale across, you see a

25:59.200 --> 26:02.840
lot of weird stuff when you crawl the whole internet, right, there's all kinds of, of

26:02.840 --> 26:07.520
wacky stuff going on in the long tail of the web, but to get it to work perfectly there

26:07.520 --> 26:13.440
as well, right, that's where it's really hard and we'll be working on this problem for

26:13.440 --> 26:14.440
many years.

26:14.440 --> 26:23.560
Now, often when a company is tackling these kinds of problems, you know, whether it's information

26:23.560 --> 26:29.800
extraction or a natural language processing, there's, you know, we're using machine learning,

26:29.800 --> 26:37.640
but also whether, you know, for exceptions or, you know, the kind of under the covers

26:37.640 --> 26:42.880
thing that's doing the heavy lifting is, you know, some old school, you know, rejects

26:42.880 --> 26:46.640
or rule rules base or something like that.

26:46.640 --> 26:52.440
I can't imagine that, you know, again, scaling working in this context, do you kind of totally

26:52.440 --> 26:57.600
issue that, you know, those types of approaches or do you, do you do them and have you found

26:57.600 --> 26:59.920
a way to fuse them in a way that works?

26:59.920 --> 27:03.320
I mean, I guess, you know, we established a Google kind of does this.

27:03.320 --> 27:08.720
So, you know, it can be done at scale, but perhaps not with the team of 35.

27:08.720 --> 27:09.720
Yeah.

27:09.720 --> 27:14.760
So actually, if you are a user of this bot and you have access to developer APIs, when

27:14.760 --> 27:19.880
you log into our developer dashboard, there is an ability to override what's extracted

27:19.880 --> 27:21.320
by our AI.

27:21.320 --> 27:27.200
So essentially, if, for example, you know, our attraction works pretty well.

27:27.200 --> 27:32.200
It has over 95 percent, you know, like precision and recall.

27:32.200 --> 27:36.920
But if it made a mistake for whatever reason, you have an ability to actually say, hey, no,

27:36.920 --> 27:42.000
this was the actual price of the product and override that with a rule as a customer.

27:42.000 --> 27:46.040
And so you kind of crowdsource the corrections?

27:46.040 --> 27:47.640
Yeah, exactly.

27:47.640 --> 27:51.760
That basically allows someone who's non-technical with like a visual interface, right, to kind

27:51.760 --> 27:52.920
of correct it.

27:52.920 --> 27:56.320
That basically, you know, it works now for you.

27:56.320 --> 28:00.200
And then the second thing it does is basically, it takes that rectangle, right, that they

28:00.200 --> 28:03.000
clicked on and then it adds it to our training set, right?

28:03.000 --> 28:05.720
So it improves the global model for everybody.

28:05.720 --> 28:12.760
So it doesn't create a rule that is, you know, an override for everyone just for that

28:12.760 --> 28:13.760
user.

28:13.760 --> 28:14.760
Okay.

28:14.760 --> 28:15.760
Yeah.

28:15.760 --> 28:16.760
Interesting.

28:16.760 --> 28:17.760
Yeah.

28:17.760 --> 28:18.760
Yeah.

28:18.760 --> 28:19.760
That is basically trained in that.

28:19.760 --> 28:20.760
It's kind of like your spam, right?

28:20.760 --> 28:25.200
Like you might mark stuff as spam or not spam in your own inbox and it affects you.

28:25.200 --> 28:28.400
But then it also helps, you know, your email provider's global model.

28:28.400 --> 28:34.680
So I'm curious when you set out to start the company or, you know, thinking about the

28:34.680 --> 28:42.520
evolution of the company, is it like a machine learning, research project organization

28:42.520 --> 28:48.760
that turned into a commercial entity or was it a commercial entity that, you know, eventually

28:48.760 --> 28:53.240
found in order to really do this, you have to be a really heavy research organization.

28:53.240 --> 28:58.880
Well, I mean, the purpose was, you know, as I said, it was before, it's a try to build

28:58.880 --> 29:02.080
the first complete map of human knowledge, right?

29:02.080 --> 29:07.880
And it just turns out that a corporate structure, I found is the best way to organize labor,

29:07.880 --> 29:08.880
right?

29:08.880 --> 29:15.200
But at the, for the first couple of years, yes, it was just pretty much me sitting in a

29:15.200 --> 29:18.160
dark basement, like working on the math problems, right?

29:18.160 --> 29:23.160
Because I really wanted to make sure that the technology actually worked before trying

29:23.160 --> 29:28.240
to do things like hire a bunch of people or scale it or raise money or things like that,

29:28.240 --> 29:30.240
right?

29:30.240 --> 29:37.240
Because I think all too often with a lot of AI projects, like they might work well at

29:37.240 --> 29:41.680
a researcher prototype phase, but then they're not at the level of quality that someone would

29:41.680 --> 29:44.840
actually pay to use it, right, in the business world, right?

29:44.840 --> 29:49.520
And then so they, they'll have problems down the line trying to commercialize it, right?

29:49.520 --> 29:54.840
So another unique aspect of our company, even though it is primarily an AI research company,

29:54.840 --> 29:56.400
is that we're profitable.

29:56.400 --> 30:01.520
So a lot of other groups that do AI research are either subsidized by another part of the

30:01.520 --> 30:02.520
company, right?

30:02.520 --> 30:08.120
Like, like, most of the major tech companies, right, they aren't themselves a profit center,

30:08.120 --> 30:13.840
or they're funded by, you know, like a philanthropist, like, like one of those nonprofit,

30:13.840 --> 30:16.360
you know, AI research companies.

30:16.360 --> 30:17.840
Formerly nonprofit?

30:17.840 --> 30:18.840
Yeah.

30:18.840 --> 30:24.680
Well, open AI, well, also the Alan Institute, I think, is another example where it's funded

30:24.680 --> 30:29.120
by, you know, primarily Paul Allen, but that, I think it's great though, right, that money

30:29.120 --> 30:32.480
is going into advancing the research that we definitely benefit, right, from those

30:32.480 --> 30:33.480
results.

30:33.480 --> 30:40.440
But yeah, so then over time though, as, you know, this kind of web scraping machine learning

30:40.440 --> 30:48.280
AI became popular, we needed to hire people to help keep the servers up, and to grow the

30:48.280 --> 30:49.280
data center.

30:49.280 --> 30:52.280
We crawled the web out of two data centers here in the Bay Area, and so that's when I

30:52.280 --> 30:57.760
started kind of tapping into my Stanford network, eventually got connected with Andy

30:57.760 --> 31:04.000
Backelstein, who was the first investor in Google, so he led our angel round and defbot

31:04.000 --> 31:09.280
and invested twice as much in our company, and then partnered with Skydatin, who is the

31:09.280 --> 31:15.320
founder of both Earthlink as well as cloud kitchens, and then in the series they partnered

31:15.320 --> 31:21.560
up with some of the folks behind Tesla and SpaceX, and folks at Tencent.

31:21.560 --> 31:28.160
I mean, you mentioned that there's kind of 50 machine learning problems or challenges

31:28.160 --> 31:33.600
as you kind of look across the things that you need to do to deliver this offering or

31:33.600 --> 31:35.280
solve this problem.

31:35.280 --> 31:42.600
Are your researchers also, do you publish, do you go to conferences like Noreps and kind

31:42.600 --> 31:45.360
of contribute to the community in that way?

31:45.360 --> 31:51.520
Yeah, so basically the area of machine learning, machine learning is a big tent, right?

31:51.520 --> 31:56.680
But the area that we care about is information extraction, right, from unstructured information,

31:56.680 --> 32:02.360
whether it's text or images or document layout, right, and also knowledge fusion.

32:02.360 --> 32:09.040
So this particular corner of AI, the people that are working at Defbot are in general way

32:09.040 --> 32:12.760
more qualified than me, so I'm probably the least qualified person in the company, and

32:12.760 --> 32:16.080
that they've probably developed a state of the art system in that area, right?

32:16.080 --> 32:23.640
So in unstructured relation extraction, open relation extraction, the folks that developed

32:23.640 --> 32:28.360
the state of the art system there now, in during their PhD work on that problem at Defbot

32:28.360 --> 32:34.040
and have scaled it to the size of the Defbot knowledge graph, one of the previous CTO

32:34.040 --> 32:39.520
of DPPDIA, which is another well-known knowledge graph joined Defbot to focus on knowledge fusion.

32:39.520 --> 32:45.280
So we benefit from these top researchers, and then another thing I should mention is

32:45.280 --> 32:50.720
we give free access to our knowledge graph to about a dozen or so different academic

32:50.720 --> 32:57.880
AI research groups, and the thinking is that those professors and PhD students and grad

32:57.880 --> 33:04.440
students should be able to stay within academia and do fruitful research in this area of knowledge

33:04.440 --> 33:09.720
graph and large-scale information extraction without having to join a big company.

33:09.720 --> 33:14.360
So we kind of see them and give them access to our knowledge graph, and they've used that

33:14.360 --> 33:16.000
to produce some interesting results.

33:16.000 --> 33:23.920
So we had a collaboration like that that had a paper at NERIPS, and we've also done more

33:23.920 --> 33:26.480
active, more recently, some of our own publishing.

33:26.480 --> 33:34.160
So at the last EMNLP, we released a data set called KnowledgeNet that allows you to, in

33:34.160 --> 33:37.440
the research world, build your own end-to-end knowledge graph.

33:37.440 --> 33:43.680
It's the largest knowledge graph construction data set that's been released so far, and

33:43.680 --> 33:47.640
it's very high quality compared to previous data sets.

33:47.640 --> 33:54.960
And we also released like a baseline system in the open source that is a reference system

33:54.960 --> 33:58.760
on that knowledge-based construction task.

33:58.760 --> 34:03.840
And so that's also being used by a lot of other AI centers right now.

34:03.840 --> 34:08.760
So I think in the earlier years, we're just pretty heads down on getting stuff to work,

34:08.760 --> 34:17.880
and now we're trying to have a more capacity to publish and help other research groups,

34:17.880 --> 34:22.920
and kind of help with knowledge sharing, and help see more research in this area.

34:22.920 --> 34:29.120
So one of the bottlenecks to productive research in this area is, like if you, there hasn't

34:29.120 --> 34:32.960
been a lot of progress in knowledge fusion, for example, in academia, because you need

34:32.960 --> 34:37.160
access to a really large database as a knowledge graph to study that problem, right?

34:37.160 --> 34:41.720
And so hopefully we're unblocking one of the bottlenecks to more research going on in

34:41.720 --> 34:43.760
the state of yarn in academia.

34:43.760 --> 34:49.800
Can you talk about those couple of challenges that you mentioned, one, knowledge fusion,

34:49.800 --> 34:51.120
and what's there?

34:51.120 --> 34:55.720
And you also mentioned the knowledge-based construction task.

34:55.720 --> 35:00.880
How's that problem framed, and what are the, you know, the success metrics there?

35:00.880 --> 35:02.080
Totally, yeah.

35:02.080 --> 35:08.880
So knowledge-based construction, so like a very classical academic shared task for that

35:08.880 --> 35:15.440
is run by a tech KBP, so that's like, I think, was originally organized by the National

35:15.440 --> 35:20.040
Institute of Standards, but the input to that problem is basically text, right?

35:20.040 --> 35:25.720
So like, newswire articles and things like that, and the output to that problem is, is

35:25.720 --> 35:26.720
a knowledge graph.

35:26.720 --> 35:31.080
So it's like, what are the entities mentioned, and all those documents, and what is the

35:31.080 --> 35:33.880
relationship between those entities, right?

35:33.880 --> 35:36.920
Like is it company A, acquired company B?

35:36.920 --> 35:41.360
Those would be two different entities mentioned, and then the relationship would be like acquisition,

35:41.360 --> 35:42.360
right?

35:42.360 --> 35:45.040
Or person A is the founder of company B.

35:45.040 --> 35:49.320
Those are all examples of relations or triples.

35:49.320 --> 35:57.920
So knowledge fusion is probably not a very, you know, probably, it's not very well publicized.

35:57.920 --> 36:03.160
A lot of people have heard about this research problem, but what it is is basically how do

36:03.160 --> 36:09.800
you fuse multiple sources of data, right, into a singular resource or database, right?

36:09.800 --> 36:17.600
So on the web, you can think about, you know, there's many different kinds of sites and

36:17.600 --> 36:22.360
variety of different kinds of levels of quality of information on the web, right?

36:22.360 --> 36:26.120
And you know, you might trust, for example, something you read on Wikipedia more or so

36:26.120 --> 36:32.720
than on a blog that's hosted in Ukraine that just, you know, was created a month ago, right?

36:32.720 --> 36:36.160
Or something posted on social media, for example, right?

36:36.160 --> 36:38.400
And also there's the time aspect, right?

36:38.400 --> 36:44.560
So what was true at one point in time may not be true at another point in time, like people

36:44.560 --> 36:50.080
change jobs, people switch roles, relationships change, right?

36:50.080 --> 36:51.080
Products change.

36:51.080 --> 36:53.160
There's new stuff coming out all the time.

36:53.160 --> 36:56.920
And the recency of information is critical, right, to any kind of business application,

36:56.920 --> 36:57.920
right?

36:57.920 --> 37:04.280
So what Knowledge Fusion does, we've created essentially algorithms at Diffbot, kind

37:04.280 --> 37:07.080
of equivalent to what we call knowledge-based trust.

37:07.080 --> 37:13.720
So think about PageRank, but not for site authority, but for trustworthiness of the facts,

37:13.720 --> 37:15.360
like from that origin, right?

37:15.360 --> 37:16.360
Okay.

37:16.360 --> 37:22.160
So we almost have an algorithm that propagates truth, right, through this graph that learns

37:22.160 --> 37:27.000
on its own to know that Wikipedia, if something is published there, is more trustworthy, right,

37:27.000 --> 37:29.720
than a random social media post, right?

37:29.720 --> 37:30.720
Because why?

37:30.720 --> 37:38.480
Because Wikipedia has a higher track record in previous iterations of knowledge-based trust

37:38.480 --> 37:40.920
of producing facts that agree with other sources, right?

37:40.920 --> 37:47.400
So there's kind of like a consensus algorithm going on and cross-checking going on.

37:47.400 --> 37:51.720
Within Knowledge Fusion, there's a whole kinds of different ways of approaching the problem.

37:51.720 --> 37:53.880
There's ontological inference.

37:53.880 --> 38:01.720
So for example, if you see on a page, Mike Tung, who's me, lives on the planet Venus, right?

38:01.720 --> 38:05.320
Our algorithms would ideally say that that's not very likely to be a true fact.

38:05.320 --> 38:06.320
Why?

38:06.320 --> 38:08.920
Because other pages say Mike Tung works at Diffbot.

38:08.920 --> 38:14.560
Diffbot is based in Menlo Park, Menlo Park is in California on the planet Earth, right,

38:14.560 --> 38:17.520
which is millions of miles away from Venus, right?

38:17.520 --> 38:19.120
Those are all entities in our knowledge graph, right?

38:19.120 --> 38:25.880
So that logical chain of reasoning would assign very low weight to that fact being true, right?

38:25.880 --> 38:30.760
And also the fact it's not being corroborated by other trustworthy sources, right?

38:30.760 --> 38:36.040
So this kind of mechanical calculation of how likely something is to be true is part

38:36.040 --> 38:40.960
of Knowledge Fusion, which fuses it together to estimate a probability of truth.

38:40.960 --> 38:44.560
One question that I've got, you know, as you describe this knowledge-based construction

38:44.560 --> 38:53.240
task and the example that you gave of the kind of knowledge-based that one might want

38:53.240 --> 39:01.120
to extract from newswire articles, et cetera, I guess I'm trying to work through the relationship

39:01.120 --> 39:06.600
between a knowledge-based that you've got, you know, that's kind of a global knowledge-based

39:06.600 --> 39:11.680
and a knowledge-based that, you know, I want to create around my documents.

39:11.680 --> 39:14.520
Should I be trying to, you know, if I've got a problem and I want

39:14.520 --> 39:19.440
to, you know, say, you know, I'm at a large enterprise and I've got kind of stores of internal

39:19.440 --> 39:24.880
knowledge and I want to, you know, create some kind of knowledge graph based on that.

39:24.880 --> 39:32.200
Should I be building a knowledge graph from scratch that is not aware of kind of the

39:32.200 --> 39:39.200
broader global knowledge graph or knowledge-based or should I somehow be, you know, not to overload

39:39.200 --> 39:44.800
the worth fusing, but, you know, kind of fuse the knowledge that, you know, service

39:44.800 --> 39:49.200
like yours might make available to me about the broader world, you know, maybe treat

39:49.200 --> 39:54.200
that as some kind of framework or ontology or something to get me started.

39:54.200 --> 39:57.240
How do you see folks kind of dealing with those questions?

39:57.240 --> 40:00.560
Yeah, so that's a really good question.

40:00.560 --> 40:04.760
So, I mean, there's all kinds of vendors in this burgeoning space, right, of knowledge

40:04.760 --> 40:12.440
graph. I think it's recently been added as one of kind of like the things that attract

40:12.440 --> 40:17.000
in like the hype cycle, gardener's hype cycle.

40:17.000 --> 40:21.680
There's people that provide actually knowledge graph databases, right, like graph databases.

40:21.680 --> 40:26.120
There's people that are kind of provide consulting services to help your organization build

40:26.120 --> 40:28.640
their own knowledge graph.

40:28.640 --> 40:33.600
Our focus is on just structuring the public knowledge, right, of the public entities and

40:33.600 --> 40:40.000
that's a big enough space for us, but what we find though is that a lot of the entities

40:40.000 --> 40:44.640
that companies care about are public knowledge, they are public entities, right, like all

40:44.640 --> 40:51.760
of the accounts inside your CRM, like an inside your customer database, those aren't specific

40:51.760 --> 40:52.760
to you.

40:52.760 --> 40:57.160
There are companies that exist out there in the real world, right, so are the people,

40:57.160 --> 41:02.560
like we have a vast majority of the people on earth inside our knowledge graph.

41:02.560 --> 41:08.400
So however, the key thing is being able to connect the internal knowledge graph to the

41:08.400 --> 41:13.280
external one and benefit from it, right, so be able to import the facts that we know

41:13.280 --> 41:18.440
in the Diffbag Global Knowledge Graph into your internal stores, right, so that's where

41:18.440 --> 41:25.640
the integrations are key, right, so there's a API that we have called Enhance that actually

41:25.640 --> 41:32.160
allows you to, let's say imagine, for example, you're a small business, you have some

41:32.160 --> 41:37.200
leads inside a database that you collect from your website, you might know, okay, the first

41:37.200 --> 41:43.720
name, email address, and company that one of your customers works for, you can essentially

41:43.720 --> 41:48.600
look that up in our knowledge graph, just only using those three facts, what we call a

41:48.600 --> 41:53.680
impartial entity, and match our entity in our knowledge graph, and then you'll gain

41:53.680 --> 41:59.280
basically like 200 or 300 additional facts like about that entity, so Diffbag can be used

41:59.280 --> 42:06.560
as a tool to both correct your internal data and to keep it up to date with new information.

42:06.560 --> 42:11.600
So if you think about enterprise knowledge, a lot of people's effort is spent just keeping

42:11.600 --> 42:17.560
that database up to date, right, you have like a big vendor database and how many of these

42:17.560 --> 42:21.640
vendors are still in business, or is this the current mailing address of this company

42:21.640 --> 42:27.040
anymore, right, it's a huge headache, right, and a lot of effort is spent in many functions

42:27.040 --> 42:33.200
across the whole enterprise, just maintaining the currency and accuracy of all this information,

42:33.200 --> 42:37.120
and that's the kind of work that we hope to alleviate human beings from having to do in

42:37.120 --> 42:40.880
the future by basically tapping into this global knowledge base.

42:40.880 --> 42:47.480
Awesome, lots of good stuff in this conversation, you know, I guess one quick question I have,

42:47.480 --> 42:55.000
just pulling up the Diffbot page and looking at, or the Diffbot site and looking at pricing,

42:55.000 --> 43:03.160
it doesn't look like there's a kind of developer free tier, that kind of thing, so maybe folks

43:03.160 --> 43:06.320
listening to this shouldn't get excited and say, oh, I'm going to go try this out, you've

43:06.320 --> 43:12.840
got a free trial, but you're not necessarily taking that kind of freemium type of a model,

43:12.840 --> 43:20.640
is that correct, or is there something available for folks that want to play around, hobby

43:20.640 --> 43:22.720
projects, that kind of thing?

43:22.720 --> 43:27.240
So we call our business model knowledge as a service, right, so it's a subscription

43:27.240 --> 43:32.280
to access information called the knowledge graph, like you said, we do have a two-week

43:32.280 --> 43:37.720
free trial for trial access, if you need to use it longer than that for certain projects,

43:37.720 --> 43:42.720
like I mentioned, we do provide free access to certain kinds of groups, if it's a student

43:42.720 --> 43:49.560
project, or if it's like academic research for things like that, I think we have pretty

43:49.560 --> 43:58.560
friendly pricing for startups, starting at $2.99, it'll basically be the same cost as

43:58.560 --> 44:04.320
your EC2 server, probably that you host your application on, or less if you're like a startup,

44:04.320 --> 44:08.920
for the larger companies, large enterprise, usually those kind of companies like to pay

44:08.920 --> 44:14.320
annually with annual contracts, so those are basically gone through sales rather than

44:14.320 --> 44:15.320
the website.

44:15.320 --> 44:21.040
Cool, well Mike, thanks so much for taking the time to chat with me, share a bit about

44:21.040 --> 44:23.440
what you're up to, definitely enjoy it.

44:23.440 --> 44:27.480
Yeah, likewise, it's been pleasure talking to you, Sam, thanks for having me on.

44:27.480 --> 44:28.480
Thank you.

44:28.480 --> 44:35.440
All right, everyone, that's our show for today, to learn more about this episode, visit

44:35.440 --> 44:46.400
homolei.com, as always, thanks so much for listening and catch you next time.

