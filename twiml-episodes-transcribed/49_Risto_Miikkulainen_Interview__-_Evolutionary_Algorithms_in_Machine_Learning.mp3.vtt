WEBVTT

00:00.000 --> 00:15.920
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

00:15.920 --> 00:20.880
people doing interesting things in machine learning and artificial intelligence.

00:20.880 --> 00:23.440
I'm your host Sam Charrington.

00:23.440 --> 00:28.120
Before I introduce this week's guest, here's a quick reminder about the upcoming Twimble

00:28.120 --> 00:35.520
Online Meetup, which will be held tomorrow, September 12th, at 3 o'clock, specific time.

00:35.520 --> 00:40.200
The discussion will be led by Nikola Kuchereva, who will be presenting learning long-term

00:40.200 --> 00:45.640
dependencies with gradient descent is difficult, by Yasuo Benjio and company.

00:45.640 --> 00:50.320
Of course, it's best if you've taken a look at the paper in advance, but even if not,

00:50.320 --> 00:53.560
you're sure to learn something from the discussion.

00:53.560 --> 00:59.440
For more information or to register, visit twimlai.com slash meetup.

00:59.440 --> 01:01.680
See you online tomorrow.

01:01.680 --> 01:05.680
If there's any one topic that I've received a bunch of requests about covering on the

01:05.680 --> 01:12.760
show, it's the subject of this week's discussion, evolutionary algorithms and machine learning.

01:12.760 --> 01:18.800
My guest this week is Risto Mikulainen, professor of computer science at UT Austin, and vice

01:18.800 --> 01:22.680
president of research at sentient technologies.

01:22.680 --> 01:27.080
During our talk, Risto and I discussed some of the things sentient is working on in the

01:27.080 --> 01:33.040
financial services and retail fields, and we dig into the technology behind them, evolutionary

01:33.040 --> 01:38.760
algorithms, which is also the focus of his research at University of Texas.

01:38.760 --> 01:44.640
I really enjoyed this week's interview and learned a ton, and I'm sure you will too.

01:44.640 --> 01:50.040
Before we get to the show, a word about this week's sponsor, Clydeira.

01:50.040 --> 01:54.280
You probably think of Clydeira primarily as the Hadoop company, and you're not wrong

01:54.280 --> 01:55.280
for that.

01:55.280 --> 02:00.160
But did you know that they also offer software for data science and deep learning?

02:00.160 --> 02:02.240
The idea here is pretty simple.

02:02.240 --> 02:06.680
If you work for a large enterprise, you probably already have Hadoop in place, and your Hadoop

02:06.680 --> 02:12.480
cluster is filled with lots of data that you want to use in building your models.

02:12.480 --> 02:18.000
But you still need to easily access that data, process it using the latest open source

02:18.000 --> 02:22.880
tools and harness bursts of compute power to train your models.

02:22.880 --> 02:26.800
This is where Clydeira's data science workbench comes in.

02:26.800 --> 02:30.640
With the data science workbench, Clydeira can help you get up and running with deep learning

02:30.640 --> 02:36.920
without massive new investments by implementing an on-demand self-service deep learning platform

02:36.920 --> 02:40.680
on your existing CDH cluster.

02:40.680 --> 02:47.160
To learn more about the data science workbench, visit twimmaleye.com slash Clydeira.

02:47.160 --> 02:53.400
And for a limited time, Clydeira is offering a free drone to qualify participants who register

02:53.400 --> 02:54.920
for a demo.

02:54.920 --> 03:00.520
Again, the URL for that is twimmaleye.com slash Clydeira.

03:00.520 --> 03:05.360
And now on to the show.

03:05.360 --> 03:11.200
All right, everyone.

03:11.200 --> 03:17.440
I am on the line with Risto McGulainen, who is vice president of research at sentient

03:17.440 --> 03:24.560
technologies and a professor of computer science at University of Texas at Austin.

03:24.560 --> 03:31.680
Risto and I recently tried to connect at the O'Reilly AI conference in New York.

03:31.680 --> 03:36.680
Unfortunately, we weren't able to do an in-person interview, but we were able to get on the

03:36.680 --> 03:42.240
line together and I'm really looking forward to this conversation and I think you'll really

03:42.240 --> 03:47.000
enjoy it because we'll be talking about something we haven't talked about yet on the podcast

03:47.000 --> 03:50.080
and that is evolutionary algorithms.

03:50.080 --> 03:52.760
So Risto, welcome to the podcast.

03:52.760 --> 03:53.760
Thank you.

03:53.760 --> 03:54.760
Pleas to be here.

03:54.760 --> 03:55.760
It's great to have you on.

03:55.760 --> 03:59.960
Why don't we get started by having you tell us a little bit about your background?

03:59.960 --> 04:07.800
Okay, yes, so I got my PhD at UCLA 1990 and was working at the time of neural networks,

04:07.800 --> 04:12.640
which I've continued doing all my career, but got also interested in evolutionary algorithms

04:12.640 --> 04:18.160
about the same time and have gradually drifted more in that direction and especially in the

04:18.160 --> 04:20.000
intersection of those two things.

04:20.000 --> 04:25.960
So we've been evolving neural networks since the early 90s and you can view that as one

04:25.960 --> 04:31.160
way of training neural networks in domains where you cannot really do other types of learning

04:31.160 --> 04:33.800
like deep learning, supervised learning.

04:33.800 --> 04:35.360
So that's been my research focus.

04:35.360 --> 04:39.520
I've also originally I did a lot of work in natural language processing with neural networks

04:39.520 --> 04:42.960
and then understanding the visual cortex with neural networks.

04:42.960 --> 04:48.520
Most recently, this evolution-based work has focused on building robotic control game

04:48.520 --> 04:55.160
characters and more recently solving problems in the real world using using this technology.

04:55.160 --> 04:56.960
And that's what I'm doing at Sentiant.

04:56.960 --> 05:01.600
I'm on Lee from UT Austin, I've been for two years trying to take the technology to

05:01.600 --> 05:04.280
the real world and it's been a lot of fun.

05:04.280 --> 05:07.840
So tell us a little bit about what Sentiant does and what the focus is there.

05:07.840 --> 05:12.480
Sure, Sentiant's been around actually for 10 years, although they came out of stealth

05:12.480 --> 05:14.360
only three years ago or two years ago.

05:14.360 --> 05:16.000
That's a long time in stealth.

05:16.000 --> 05:19.320
Well, it took a while to develop all the infrastructure.

05:19.320 --> 05:24.600
So initially, Sentiant was doing stock trading and still is doing stock trading as one of

05:24.600 --> 05:25.600
the applications.

05:25.600 --> 05:30.080
It's a great first application because you don't need to have much customer support and

05:30.080 --> 05:31.080
other things like that.

05:31.080 --> 05:35.760
You just run your algorithms and they trade directly and make money, but it took a long

05:35.760 --> 05:41.240
time to build those algorithms and also build the infrastructure, the computing infrastructure.

05:41.240 --> 05:48.080
So evolution is one of those technologies that requires a lot of computing power to excel.

05:48.080 --> 05:53.920
And here at Sentiant, we built that kind of a computing power distributed system across

05:53.920 --> 06:00.720
the internet using, at that time, two million CPUs to evolve stock traders.

06:00.720 --> 06:04.360
And that was very successful and it was a lot of fun to build that.

06:04.360 --> 06:09.840
That was the first product and then we changed the course to added another direction rather

06:09.840 --> 06:13.960
going to e-commerce building intelligence interfaces to e-commerce.

06:13.960 --> 06:15.880
So there are two products there.

06:15.880 --> 06:21.480
One of them is Sentiant Aware, which is a visual interface to catalog of products that

06:21.480 --> 06:23.400
understands what the user wants.

06:23.400 --> 06:28.160
It's more like a personalized assistant that you might find in Nordstrom or other fancy

06:28.160 --> 06:29.480
department store.

06:29.480 --> 06:34.160
You click on a choices and the system will understand what it is that you're looking

06:34.160 --> 06:37.120
for and a couple of clicks will get you what you want.

06:37.120 --> 06:42.280
The other one is Sentiant Sentiant, which is a way of using evolutionary computation to

06:42.280 --> 06:46.920
design web interfaces so that they are most effective.

06:46.920 --> 06:51.560
For instance, optimizing conversion rate on an e-commerce website is one of the applications

06:51.560 --> 06:52.560
of that technology.

06:52.560 --> 06:54.720
So those are the three products.

06:54.720 --> 06:59.760
But behind all that, we develop, we are technology companies, so we develop evolution

06:59.760 --> 07:04.440
computation methods, deep learning methods, combinations of those as well as surrogate

07:04.440 --> 07:08.400
optimization and back by optimization in various domains.

07:08.400 --> 07:10.600
So that's our technology pace.

07:10.600 --> 07:11.600
Okay.

07:11.600 --> 07:14.840
Is the, actually, I'll get back to that.

07:14.840 --> 07:18.120
You mentioned two million CPU cores.

07:18.120 --> 07:24.560
Is that the cloud, is that distributed or those in your own data centers?

07:24.560 --> 07:25.560
Yeah.

07:25.560 --> 07:26.560
That's interesting.

07:26.560 --> 07:31.160
This is like a grid machine, sort of like folded or sitting at home.

07:31.160 --> 07:32.160
Yeah.

07:32.160 --> 07:33.160
Exactly.

07:33.160 --> 07:34.160
Same idea.

07:34.160 --> 07:36.560
Utilizing freely available compute time.

07:36.560 --> 07:41.840
I mean, not freely available, we prefer it, but available idle compute time in around

07:41.840 --> 07:42.840
the world.

07:42.840 --> 07:47.640
And this is, I think, a really interesting proposition and there's so much compute

07:47.640 --> 07:52.560
distributed now in people's laptops, PCs, cell phones.

07:52.560 --> 07:55.080
And if he could harness that, we could do a lot of computing.

07:55.080 --> 07:56.080
But of course, things change.

07:56.080 --> 08:00.560
That was the CPUs were perfectly good in the first several years when we were evolving

08:00.560 --> 08:02.000
stock traders.

08:02.000 --> 08:05.280
More recently, we evolved deep learning neural networks.

08:05.280 --> 08:09.200
And the need is a little different because they are trained on GPUs.

08:09.200 --> 08:13.440
So now we have to have access to GPUs and the demographics has changed a bit.

08:13.440 --> 08:16.320
And this is a very rapidly changing space.

08:16.320 --> 08:21.200
It's also become very economical to buy a bunch of GPUs, thousands of them perhaps, and

08:21.200 --> 08:22.640
build your own center.

08:22.640 --> 08:28.120
So we are continuous looking for opportunities to harness computation, whatever form it is.

08:28.120 --> 08:31.040
But we have expertise in both kinds of setups.

08:31.040 --> 08:32.040
Okay.

08:32.040 --> 08:37.800
And so is the company still using this highly distributed grid like infrastructure, or have

08:37.800 --> 08:41.600
you shifted to an owned infrastructure?

08:41.600 --> 08:42.600
Yeah.

08:42.600 --> 08:47.200
We're still using it and we also exploring other ways of getting the computation.

08:47.200 --> 08:50.120
They are, they serve a little bit different purposes.

08:50.120 --> 08:54.200
One of them is very massively parallel and not necessarily that reliable.

08:54.200 --> 08:56.520
And that's good for some applications.

08:56.520 --> 08:59.240
And in others, you need more reliability.

08:59.240 --> 09:03.160
The compute has to be accessible all the time and it has to finish.

09:03.160 --> 09:07.480
And therefore, you need different kinds of sources for compute and we are pursuing several

09:07.480 --> 09:09.600
sources as a result.

09:09.600 --> 09:14.680
And you give us examples of the kinds of applications that work well and for each?

09:14.680 --> 09:15.680
Yeah.

09:15.680 --> 09:22.200
So for instance, a stock trading is very robust because we are evolving traders and evolution

09:22.200 --> 09:23.200
in general.

09:23.200 --> 09:29.800
Evolution in general is robust because you have a population of solutions and you are testing

09:29.800 --> 09:35.960
that population in a distributed fashion across the different compute sites.

09:35.960 --> 09:40.440
And if something goes wrong and you don't get back an evaluation of one of your candidates,

09:40.440 --> 09:41.440
that's okay.

09:41.440 --> 09:43.200
You have hundreds of other candidates.

09:43.200 --> 09:48.720
It's okay to lose one candidate or have it only partially evaluated because there's

09:48.720 --> 09:53.800
a lot of noise in this evolution research process and it actually thrives on diversity

09:53.800 --> 09:55.960
and multiple alternatives.

09:55.960 --> 10:01.200
So it's not depend on any single alternative or an accurate evaluation.

10:01.200 --> 10:06.440
It's based on evaluating a lot of candidates and many times.

10:06.440 --> 10:11.040
And that you can do on a compute source that's very unreliable.

10:11.040 --> 10:16.600
Now if you are building a particular application based on say deep learning, you want that

10:16.600 --> 10:21.600
deep learning network to be very well built and very well trained and reliable and sometimes

10:21.600 --> 10:24.480
that training will take several days.

10:24.480 --> 10:29.240
So it has to be a reliable source so that you can get back that result of the training.

10:29.240 --> 10:31.840
Otherwise, you waste a lot of time on it.

10:31.840 --> 10:34.960
So that's where we need more reliable sources.

10:34.960 --> 10:35.960
Okay.

10:35.960 --> 10:42.640
And so is the company still working on financial services or did you migrate or pivot from

10:42.640 --> 10:45.960
financial services to the e-commerce solution?

10:45.960 --> 10:49.200
You know, we definitely working on trading as well.

10:49.200 --> 10:54.760
It's a more like an AI based hedge fund than financial services.

10:54.760 --> 10:57.560
And there we have expanded to different markets.

10:57.560 --> 11:02.960
So that part is growing and the algorithms have also evolved to some degree, but the

11:02.960 --> 11:05.800
base is still to run a hedge fund using AI.

11:05.800 --> 11:08.760
So the traders are automatic.

11:08.760 --> 11:13.240
They actually are looking at the stock market and deciding what the trends are and what

11:13.240 --> 11:15.800
should be done and then to make those trades.

11:15.800 --> 11:20.360
Of course, in the end, there's a person also watching this with a hand on a red button

11:20.360 --> 11:24.080
in case something goes wrong, but that almost never happens.

11:24.080 --> 11:27.360
I don't think it actually has happened in that urgency.

11:27.360 --> 11:30.440
But sometimes also the stock market is interesting that there might be something happening in

11:30.440 --> 11:31.440
a stock market.

11:31.440 --> 11:35.040
You can tell that now this is not a usual situation.

11:35.040 --> 11:40.320
It's going haywire and we'll stop the trading and let it come back and become more normal.

11:40.320 --> 11:45.560
So there's a human in the loop, but it is interesting that AI can do much of this on its own.

11:45.560 --> 11:51.880
And are you trading your own book or are you working with other hedge funds and helping

11:51.880 --> 11:52.880
them trade?

11:52.880 --> 11:53.880
Yeah.

11:53.880 --> 11:56.160
Currently trading our own funds.

11:56.160 --> 12:00.960
And there's a plan to open it up in the future for investors.

12:00.960 --> 12:01.960
Interesting.

12:01.960 --> 12:07.960
I wonder why, if you've got that working, it's kind of this perpetual money machine, right?

12:07.960 --> 12:10.800
Why even bother with retail?

12:10.800 --> 12:11.800
That's a good question.

12:11.800 --> 12:18.040
Well, in the AI world and in the startup world and in the Silicon Valley, it's always

12:18.040 --> 12:20.840
grow scale, get more.

12:20.840 --> 12:26.880
And this was a successful, is a successful technology, so now the question is, what else can

12:26.880 --> 12:27.880
you do with it?

12:27.880 --> 12:33.360
And indeed, it's nice to have several different technologies and bases, and especially then

12:33.360 --> 12:36.680
because you start getting a cross pollination of them.

12:36.680 --> 12:41.560
So the second one we looked at was very different from Evo's algorithms, was deep learning.

12:41.560 --> 12:47.760
And we've found that we could use it to encode human preferences, what humans perceive

12:47.760 --> 12:53.240
as similar and visually, and identify that this would be something that the retail industry

12:53.240 --> 12:59.240
could really use because retail is changing rapidly and fundamentally.

12:59.240 --> 13:04.920
From the brick and mortar stores, we are changing into internet-based commerce.

13:04.920 --> 13:10.040
And this is a really big change, but internet commerce is quite clunky still today.

13:10.040 --> 13:14.840
It's hard to find what you want in those web interfaces.

13:14.840 --> 13:19.640
And the reason that was pretty obvious was that you have to know what you're looking

13:19.640 --> 13:20.640
for.

13:20.640 --> 13:23.800
And you have to know the keywords for those items that you're looking for.

13:23.800 --> 13:28.360
And if you do, you may be able to find and do your satisfactory, some product that you

13:28.360 --> 13:31.640
interested in, but if you don't, it can be very frustrating.

13:31.640 --> 13:35.680
And as a matter of fact, we've done some tests on that, typically in an e-commerce site,

13:35.680 --> 13:42.000
in a week, 15% of the catalog is actually seen by the users because they have to go

13:42.000 --> 13:45.480
through these rigid categories and keywords.

13:45.480 --> 13:50.320
And it's very hard to find different variability or diversity in a catalog.

13:50.320 --> 13:54.000
We identified very early on that this is actually something that could be done differently.

13:54.000 --> 13:58.480
We could use human-like perception of similarity, visual similarities.

13:58.480 --> 14:05.560
So if you're thinking of, say, a catalog of shoes or jackets or sunglasses, then a human

14:05.560 --> 14:07.760
can identify something that he likes.

14:07.760 --> 14:12.080
So he likes very quickly by being presented a bunch of alternatives.

14:12.080 --> 14:13.680
This is the one I like the most.

14:13.680 --> 14:16.480
And then another set of candidates comes up.

14:16.480 --> 14:18.560
And these are now based on the first click.

14:18.560 --> 14:21.920
They are similar to the first click, but variation around that area.

14:21.920 --> 14:23.400
And now you can click again.

14:23.400 --> 14:28.480
And it turns out, in about seven clicks, you can find anything in the catalog, according

14:28.480 --> 14:31.160
to our evaluation.

14:31.160 --> 14:37.120
And in that process, the users actually see about 70% of the catalog each week.

14:37.120 --> 14:39.760
And this is a situation where everybody wins.

14:39.760 --> 14:43.840
As a user, you have access to more variety.

14:43.840 --> 14:49.880
And the e-commerce vendor will sell a motor catalog, and the manufacturers get their

14:49.880 --> 14:52.480
products out there for people to see.

14:52.480 --> 14:57.480
So it is just fundamentally a better way to access e-commerce catalogs.

14:57.480 --> 15:02.440
And it's based on understanding human perception and training machines, turning neural networks

15:02.440 --> 15:04.120
to represent those similarities.

15:04.120 --> 15:08.320
That sounds like a really interesting application.

15:08.320 --> 15:09.320
So both...

15:09.320 --> 15:15.000
Well, actually, you said the financial services you started with applying evolutionary algorithms

15:15.000 --> 15:21.360
and with this e-commerce application, the focus is more on deep learning.

15:21.360 --> 15:22.360
Exactly.

15:22.360 --> 15:23.360
Is that the right way to think about it?

15:23.360 --> 15:24.360
Yes.

15:24.360 --> 15:25.360
That's exactly right.

15:25.360 --> 15:29.560
Maybe let's dive into evolutionary algorithms now.

15:29.560 --> 15:34.400
Tell us, you know, you gave us a little bit of a taste of it earlier, but what does that

15:34.400 --> 15:35.400
mean?

15:35.400 --> 15:36.400
All right.

15:36.400 --> 15:41.600
So evolution, and you can see there's this form of similar to reinforcement learning,

15:41.600 --> 15:46.400
where you do not get the correct answer to learn from.

15:46.400 --> 15:50.800
I mean, in deep learning and most of the machine learning applications that are out there

15:50.800 --> 15:55.360
are based on these large data sets, where somebody has collected the data.

15:55.360 --> 16:01.160
This is a situation, and this is the right categorization or action at that situation.

16:01.160 --> 16:07.480
For instance, you know, images and their classification, categorization, or speech and a transcription

16:07.480 --> 16:08.800
of the speech.

16:08.800 --> 16:14.560
And this is very doable, and we have systems that have come up, mechanical turk and

16:14.560 --> 16:18.240
mighty AI and others who are now collecting and forming such data sets.

16:18.240 --> 16:24.240
And then systems like deep learning can be involved to build models of those kinds of

16:24.240 --> 16:25.240
tasks.

16:25.240 --> 16:31.440
And it's very powerful, but there's a lot of tasks in the world where those actual correct

16:31.440 --> 16:33.160
answers are not known.

16:33.160 --> 16:38.520
So for instance, driving a car, a robot navigating, playing any kind of game.

16:38.520 --> 16:42.480
You don't know what the actual optimal answers are.

16:42.480 --> 16:46.080
And in such domains, the learning is based on exploration.

16:46.080 --> 16:49.000
You try out things and see how well they work.

16:49.000 --> 16:51.600
In a big picture, this might be called reinforcement learning.

16:51.600 --> 16:53.480
You get reinforcement to your actions.

16:53.480 --> 16:58.480
Now reinforcement learning, actually, as a term refers to a category or class of algorithms

16:58.480 --> 17:03.120
that is a little different from evolution into the social or traditional sense.

17:03.120 --> 17:07.480
They are mostly those reinforcement learning items are mostly based on value function approaches

17:07.480 --> 17:12.480
where you list all your actions and learn how good each action is in each state.

17:12.480 --> 17:16.600
And that's a different approach to solving a problem when you don't have gradients, when

17:16.600 --> 17:19.800
you don't have supervised targets.

17:19.800 --> 17:21.200
Evolution is a different approach.

17:21.200 --> 17:27.120
The idea there is that you have a whole population of solutions and you evaluate each solution.

17:27.120 --> 17:33.520
And as in biology, those who evaluate well get to reproduce more and generate offspring.

17:33.520 --> 17:37.680
And the offspring is somehow generated in various ways from the parents.

17:37.680 --> 17:41.640
You take an encoding of the parent and encoding of another parent.

17:41.640 --> 17:44.400
And then you cross them over just like in biology.

17:44.400 --> 17:47.880
So there's some kind of a linear encoding us like DNA.

17:47.880 --> 17:51.800
You can take part of that DNA from one parent and another part from another parent to form

17:51.800 --> 17:52.800
an offspring.

17:52.800 --> 17:57.120
And that means that you are combining properties of both parents into the offspring.

17:57.120 --> 18:00.800
And this is the fundamental idea of the evolutionary search.

18:00.800 --> 18:06.760
You are trying to recombine components or schemas or building blocks that are sometimes

18:06.760 --> 18:09.880
called to find better combinations of them.

18:09.880 --> 18:12.520
And there's another component which is important as well.

18:12.520 --> 18:13.520
That's my question.

18:13.520 --> 18:14.520
Yeah.

18:14.520 --> 18:17.560
Before you dive into that, I have a question about something you said about

18:17.560 --> 18:19.520
reinforcement learning.

18:19.520 --> 18:26.080
And that is you said that the reinforcement learning is characterized by these value functions.

18:26.080 --> 18:31.880
And in order to evaluate these value functions, we apply gradient-based approaches.

18:31.880 --> 18:38.120
And you said that in order to do that, we can only do that under supervision of some sort.

18:38.120 --> 18:44.200
And elaborate on that because we're typically applying, as you said, reinforcement learning

18:44.200 --> 18:47.840
in what we think of unsupervised problems.

18:47.840 --> 18:48.840
Right.

18:48.840 --> 18:51.520
So, supervised learning is different from reinforcement learning.

18:51.520 --> 18:55.320
So that supervised learning means that we do have correct answers and we can calculate

18:55.320 --> 18:56.320
gradients.

18:56.320 --> 18:59.640
In reinforcement learning, we don't have those gradients.

18:59.640 --> 19:01.560
We don't have correct targets.

19:01.560 --> 19:03.560
So it's based on exploration.

19:03.560 --> 19:09.880
So in reinforcement learning, the agent will try out different actions and will eventually

19:09.880 --> 19:13.160
get an evaluation of how well those actions worked out.

19:13.160 --> 19:19.000
And then dynamic programming is, incremental dynamic programming is typically used then to

19:19.000 --> 19:26.840
propagate that reward back to the earlier actions and changing their value in this representation

19:26.840 --> 19:28.920
of how good each action is.

19:28.920 --> 19:31.920
So it is not supervised.

19:31.920 --> 19:36.200
It thinks it's a little confused because, confusing because this, in this purest form,

19:36.200 --> 19:41.720
this kind of value function learning applies to a table of actions in a table of states.

19:41.720 --> 19:43.120
But that is very limiting.

19:43.120 --> 19:47.880
So we need to be able to approximate a large number of actions and large number of states.

19:47.880 --> 19:52.600
And that means that a lot of times we use a function approximator and then use gradient

19:52.600 --> 20:00.000
descent to build that function approximator using the propagated values as targets.

20:00.000 --> 20:06.160
So we use gradient descent as a way of generalizing reinforcement learning.

20:06.160 --> 20:11.160
But the information for reinforcement learning comes from the outcomes of these exploration

20:11.160 --> 20:12.160
episodes.

20:12.160 --> 20:13.520
Right, right.

20:13.520 --> 20:20.720
And one of the challenges with reinforcement learning is that you are, sorry, way to articulate

20:20.720 --> 20:26.560
this year, kind of weighing exploration and exploitation and your exploration tends to

20:26.560 --> 20:29.800
be focused around fixed paths.

20:29.800 --> 20:36.880
And you don't really have a built-in mechanism to combine different exploratory directions.

20:36.880 --> 20:40.680
And that sounds like that's one of the advantages of evolutionary algorithms.

20:40.680 --> 20:41.680
Yes.

20:41.680 --> 20:43.120
This is absolutely right.

20:43.120 --> 20:47.640
So there are two main challenges for reinforcement learning.

20:47.640 --> 20:49.800
One of them is this large search space.

20:49.800 --> 20:54.520
Like I said, it works really well if you have a smaller space where you can enumerate

20:54.520 --> 20:56.520
all your actions and states.

20:56.520 --> 21:01.880
And it's difficult when those grow and become maybe continuous.

21:01.880 --> 21:06.840
And another problem is that it works well when your state contains all the information

21:06.840 --> 21:07.840
from the past.

21:07.840 --> 21:11.240
It's uniquely specified or exactly specified.

21:11.240 --> 21:16.480
If you have partially observable states, then it becomes very difficult to learn using

21:16.480 --> 21:18.320
this kind of value function approach.

21:18.320 --> 21:24.360
And both of those are actually addressed if you evolve, use evolution to construct neural

21:24.360 --> 21:26.760
networks in such tasks.

21:26.760 --> 21:32.240
So neural networks work very well when they are in continuous domains.

21:32.240 --> 21:34.040
You don't have to enumerate all the possibilities.

21:34.040 --> 21:37.320
They are already doing the function approximation.

21:37.320 --> 21:41.320
And regarding the second problem, you can evolve recurrent neural networks.

21:41.320 --> 21:46.680
And when you have recurrency, your entire sequence of actions that you've taken up to this

21:46.680 --> 21:51.320
state is taken into account in making the next decision.

21:51.320 --> 21:56.800
And therefore, it can disambiguate much of the state ambiguity and therefore work better

21:56.800 --> 22:00.320
and partially observable problems as well.

22:00.320 --> 22:01.320
So that is true.

22:01.320 --> 22:05.760
You have to have a decision-making system such as a neural network as a base.

22:05.760 --> 22:10.520
But then you can evolve that neural network in order to get over these two challenges

22:10.520 --> 22:12.160
to reinforcement learning.

22:12.160 --> 22:18.760
One challenge to reinforcement learning is the issue of reward attribution.

22:18.760 --> 22:26.240
Is that covered under the partially observable state issue or is that a separate category

22:26.240 --> 22:27.840
of challenge?

22:27.840 --> 22:30.440
And how was that addressed by evolutionary algorithms?

22:30.440 --> 22:33.200
Well, they are related.

22:33.200 --> 22:40.360
So reward attribution, if you have a partially observable problem and you make a decision,

22:40.360 --> 22:44.000
part of the credit for that success for that decision depends on how you got to that

22:44.000 --> 22:47.000
state, those unobserved variables.

22:47.000 --> 22:51.840
So if you have a system that takes into account all the actions that got you to that state,

22:51.840 --> 22:55.200
you are doing the credit assignment better and more accurately.

22:55.200 --> 22:57.720
So yeah, in that sense, they are related.

22:57.720 --> 23:06.320
So maybe is there a way to, you know, granted that a podcast is limited and it's been with,

23:06.320 --> 23:12.320
you know, not having a visual component here, but is there a way to kind of walk us through

23:12.320 --> 23:20.120
the, you know, the setup for an evolutionary algorithm and how it's applied to training

23:20.120 --> 23:21.120
neural networks?

23:21.120 --> 23:22.120
Sure.

23:22.120 --> 23:25.720
And I've been vigorously waving my hands here, like you haven't been able to see all

23:25.720 --> 23:26.720
along.

23:26.720 --> 23:30.320
So yeah, the big, big starting point that's different from reinforcement learning is,

23:30.320 --> 23:31.920
is the population.

23:31.920 --> 23:37.520
So you have a collection of individuals and typically it's 100 to 100 maybe.

23:37.520 --> 23:40.680
In some cases, different, different variances might be smaller.

23:40.680 --> 23:42.520
And so what is an individual?

23:42.520 --> 23:43.520
Yes.

23:43.520 --> 23:48.280
It's indeed individuals represents a solution, a potential solution to the problem.

23:48.280 --> 23:51.640
Like in this case, in the simplest case, it could be a neural network.

23:51.640 --> 23:55.600
And it means all the weights and all the nodes, weight values and all the nodes and the

23:55.600 --> 23:57.200
structure of the neural network.

23:57.200 --> 23:58.200
Okay.

23:58.200 --> 24:00.720
So it's pre constrained by architecture.

24:00.720 --> 24:06.840
You've defined an architecture for this target neural network and you're using the evolutionary

24:06.840 --> 24:13.680
algorithm to figure out its various parameters as opposed to evolve the network architecture

24:13.680 --> 24:14.680
itself.

24:14.680 --> 24:16.720
Well, that's the simplest way of doing it.

24:16.720 --> 24:21.520
But the most powerful evolutionary neural network systems actually evolve the architecture

24:21.520 --> 24:22.520
as well.

24:22.520 --> 24:23.520
Oh, right.

24:23.520 --> 24:29.400
You have to have a representation that can be encoded into a, into a string typically

24:29.400 --> 24:32.960
or a tree, but most often a string like DNA.

24:32.960 --> 24:38.160
So you have a DNA representation of that solution and it may include the weights on the connections,

24:38.160 --> 24:43.200
making, include the hyper parameters like the slope of the sigmoid or something like that.

24:43.200 --> 24:48.360
And it may include the topology, like how the graph is actually connected between nodes.

24:48.360 --> 24:50.520
It's just an issue of how you encode it.

24:50.520 --> 24:54.520
But the, but the end result is that you will have some kind of a string representation

24:54.520 --> 24:59.720
or a tree in a more general sense for each of the individuals, for each of the neural network,

24:59.720 --> 25:01.120
the solutions.

25:01.120 --> 25:03.760
And now you, and now you have a population of them.

25:03.760 --> 25:08.600
And then on that population, you run an evolutionary algorithm and there are many flavors of those

25:08.600 --> 25:13.520
what I've been talking about is, is the genetic algorithm flavor, John Holland's tradition.

25:13.520 --> 25:15.040
There are many others too.

25:15.040 --> 25:20.120
But that is the most closely associated with biology in that you take each individual,

25:20.120 --> 25:23.120
you test them in a task, you evaluate them in a task.

25:23.120 --> 25:26.200
And that's where the parallel computing comes in because you have a population, you can

25:26.200 --> 25:31.600
send each individual to a different machine across the internet to be evaluated.

25:31.600 --> 25:37.320
And sometimes most of the time the evaluation is the most computationally expensive part

25:37.320 --> 25:41.800
of the algorithm because you may be driving a robot or you may be doing stock trading

25:41.800 --> 25:44.960
or whatever it is that you're doing, it takes time to evaluate.

25:44.960 --> 25:49.120
And that's really nice because evolution algorithms parallelize very well in that sense.

25:49.120 --> 25:51.440
Each individual can be evaluated separately.

25:51.440 --> 25:55.200
And then you get back to your values, the fitness values, how well they perform in the

25:55.200 --> 25:56.200
task.

25:56.200 --> 26:01.280
And now the entire population is associated, each one individual is associated with a fitness

26:01.280 --> 26:05.240
value and you can find the best ones and you can find the worst ones.

26:05.240 --> 26:11.360
The worst ones you throw away and the best ones you pair up so that you can do crossover,

26:11.360 --> 26:17.040
as I mentioned earlier, and also the second component of evolution, the mutation.

26:17.040 --> 26:24.120
Also, it gives you new combinations of building blocks or schemas, partial solutions.

26:24.120 --> 26:28.320
Mutation creates new ones because it's not necessarily, you usually initialize the population

26:28.320 --> 26:32.920
randomly, like random weight neural networks, but it doesn't guarantee that you have the

26:32.920 --> 26:35.200
weight in the right place when you need it.

26:35.200 --> 26:38.880
So mutation is a mechanism for creating that.

26:38.880 --> 26:43.520
It's a random change in the weight value or random change in the topology that happens

26:43.520 --> 26:49.200
on a low probability, about 2% or 4% or so, as part of that evolutionary step.

26:49.200 --> 26:54.840
So you take in your parents and you create their offspring and that offspring then is

26:54.840 --> 26:59.120
used to replace those poor individuals that were thrown away.

26:59.120 --> 27:04.000
And that creates your new population, a new generation, and then this process repeats.

27:04.000 --> 27:10.600
In this process, in essence, you are doing a parallel search in the solution space, starting

27:10.600 --> 27:16.640
from your 100 initial random individuals, you gradually reward those that perform the

27:16.640 --> 27:22.960
best and you perform more search in the areas where there's better solutions.

27:22.960 --> 27:24.200
But it's in parallel.

27:24.200 --> 27:29.800
So you're still not following just one potential kind of solution, but you are in parallel

27:29.800 --> 27:33.520
focusing on multiple potentially good solutions.

27:33.520 --> 27:38.400
And eventually, then you find some really good ones and the algorithm focuses on refining

27:38.400 --> 27:43.080
that area and finding the absolute best in a smaller area around the best solution.

27:43.080 --> 27:44.920
That's what ends up happening.

27:44.920 --> 27:47.480
And that's a evolution algorithm in a nutshell.

27:47.480 --> 27:52.600
As I said, there are many variations and they're also interesting to talk about, but that

27:52.600 --> 27:58.240
principle of parallel search in a solution space, which is directed by these periodic

27:58.240 --> 28:02.120
evaluations in the real world, is the essence of the method.

28:02.120 --> 28:03.120
Okay.

28:03.120 --> 28:09.760
So it sounds like, maybe perhaps not if applied to a deep neural network, but if applied

28:09.760 --> 28:17.080
to a more simple type of machine learning model, essentially what we're doing is a search

28:17.080 --> 28:23.240
of the solution space that could be analogous to a grid search of hyper parameters.

28:23.240 --> 28:33.080
But in the evolutionary world, we're able to, we're able to constrain our search and

28:33.080 --> 28:34.560
as well as parallelize it.

28:34.560 --> 28:40.040
And so I'm imagining that, you know, from like a big O perspective, this is, you know,

28:40.040 --> 28:44.840
log, log and time as opposed to N or something like that with a grid search.

28:44.840 --> 28:46.360
Am I thinking about that the right way?

28:46.360 --> 28:47.360
Yeah.

28:47.360 --> 28:48.360
That's intuitively.

28:48.360 --> 28:49.360
I think that's correct.

28:49.360 --> 28:53.680
It's, of course, a different question of can we prove that's results, but that is

28:53.680 --> 28:55.040
in essence what's happening.

28:55.040 --> 28:59.040
So it is, it is not laying all your eggs in one basket.

28:59.040 --> 29:05.400
It is a pursuing multiple alternatives at once and it's then gradually focusing the search

29:05.400 --> 29:10.480
where the most promises, whereas creatures is just brute force approach, you spread your

29:10.480 --> 29:15.600
all your individuals as wide as possible and find something in there and end up wasting

29:15.600 --> 29:19.720
a lot of time and also not necessarily finding the very best one because you are limited

29:19.720 --> 29:21.360
by the, by the grid.

29:21.360 --> 29:25.000
So in that sense, that you could think of it as more intelligent version of that, much

29:25.000 --> 29:26.000
more intelligent.

29:26.000 --> 29:29.320
It's actually sometimes amazing how efficient it can be.

29:29.320 --> 29:35.440
So we've done a sentient, a couple of demonstrations in a multiplexer domain, which is a very easy

29:35.440 --> 29:41.640
domain to solve symbolically, but you can create it into a, turn it into a search problem.

29:41.640 --> 29:46.600
You have to find the right encoding of bits so that you get the right answers to the,

29:46.600 --> 29:49.800
to any given address from your bit string.

29:49.800 --> 29:53.240
Now the search space is huge in this case.

29:53.240 --> 29:59.200
It can be, and we've solved 70 bit multiplexer, which the search space is two to the two to

29:59.200 --> 30:00.600
the seven days.

30:00.600 --> 30:05.520
It's a very large search space and it's still evolution can find solutions quite quickly

30:05.520 --> 30:09.080
in hundreds of thousands or millions of trials.

30:09.080 --> 30:14.040
You'll find solution in that, that, that, that magnificently large space.

30:14.040 --> 30:19.600
Can you take a step back and elaborate on that problem and how it's applied or how it's

30:19.600 --> 30:20.600
used in practice?

30:20.600 --> 30:25.000
Well, multiplexer is, it's a benchmark problem.

30:25.000 --> 30:27.880
It's not something that you would solve using evolution algorithm.

30:27.880 --> 30:33.240
It's only used to illustrate how, or evaluate the different algorithms and how it works,

30:33.240 --> 30:35.360
how, how well they work.

30:35.360 --> 30:39.200
You have a number of address bits and then you have a number of data bits.

30:39.200 --> 30:41.720
So that is your individual.

30:41.720 --> 30:47.800
And then what you're learning is rules, how to map those address bits to a data bit.

30:47.800 --> 30:49.440
And that's what the multiplexer does.

30:49.440 --> 30:52.000
Given an address, it gives you one of the data bits.

30:52.000 --> 30:57.840
So you can evolve it to solve that in various ways, you evolve rules and the rules express

30:57.840 --> 31:02.480
that, okay, if we have this, this and this bit in the addresses, then this is the output.

31:02.480 --> 31:08.880
So now the space that you're searching is the set of all, all rule sets.

31:08.880 --> 31:12.480
And that space is humongous and we can calculate how large it is.

31:12.480 --> 31:17.680
This is worked done by John Kosa a long time ago just to demonstrate how effective learning

31:17.680 --> 31:20.440
algorithms can be, evolution, learning algorithms can be.

31:20.440 --> 31:25.440
At that time, I think we were considering 11 multiplexer, which has a search base of

31:25.440 --> 31:29.280
10 to the, I think it's 616.

31:29.280 --> 31:32.440
And you can solve it by searching this set of rules.

31:32.440 --> 31:38.800
And in the rules, you have a certain way of identifying the input bits and then ending

31:38.800 --> 31:44.560
and auring them and so on, performing logical operations so that in the end, you get the

31:44.560 --> 31:49.440
data bit and you can calculate how large that search base is, how many ways there are

31:49.440 --> 31:54.800
to combine these input bits, address bits and the logical operations on them.

31:54.800 --> 31:58.880
And therefore you can estimate how large the search base is and how hard the problem is.

31:58.880 --> 32:08.640
So in 11 case, it's 10 to the 616th and we expanded it to the 2 to the 7th, and it still

32:08.640 --> 32:09.640
works.

32:09.640 --> 32:14.200
And that is, I think to me, it's very amazing that evolution can very quickly identify

32:14.200 --> 32:19.800
what actually works, those component solutions, those building blocks and then put them together

32:19.800 --> 32:23.520
into a solution when search base is huge.

32:23.520 --> 32:24.520
So that is power.

32:24.520 --> 32:29.480
But not everything is, of course, amenable to evolutionary computation.

32:29.480 --> 32:35.160
Before we jump into that, you mentioned provability.

32:35.160 --> 32:38.560
Can you elaborate on the work that's been done there?

32:38.560 --> 32:43.160
For example, you mentioned in describing evolutionary algorithm that you kind of throw

32:43.160 --> 32:52.000
away the worst performing models or parameter sets, and then you mate, if that's the right

32:52.000 --> 32:54.680
word, the best performing ones.

32:54.680 --> 33:01.320
And you know, is there a formal proof that we're not susceptible to some local minimum

33:01.320 --> 33:06.960
maxima, and you might get some better result by mating non-performers and performers?

33:06.960 --> 33:10.440
Yeah, there's quite a bit of theory on evolutionary algorithms.

33:10.440 --> 33:15.400
It started already in the 70s with the Schema theorem, and that says the Schema theorem

33:15.400 --> 33:22.280
states that in this process, the shorter the Schema's are, the combinations of elements

33:22.280 --> 33:26.160
in the solution, in that bit string, in that genetic string.

33:26.160 --> 33:32.320
The shorter they are, and the more powerful they are, the more strongly they actually affect

33:32.320 --> 33:34.440
the fitness of the organism.

33:34.440 --> 33:39.400
Then more prominent, they will be in future generations, they will become more prevalent

33:39.400 --> 33:42.880
in the population, and that is a theoretical result.

33:42.880 --> 33:49.600
The Schema theorem shows that this happens in this mechanism, and how does a short Schema

33:49.600 --> 33:52.600
apply to a practical problem?

33:52.600 --> 33:53.600
What does that mean?

33:53.600 --> 34:00.240
Well, so Schema lengths means that you have, well, so let's think of a genetic encoding,

34:00.240 --> 34:04.400
for instance, a string of weights on a neural network.

34:04.400 --> 34:09.560
So the Schema means that a good neural network has this weight on this connection, this

34:09.560 --> 34:12.040
weight on this connection, and this weight on this connection.

34:12.040 --> 34:14.160
That's a Schema of length 3.

34:14.160 --> 34:20.000
And it may be that indeed you have these kinds of interactions between weights in a neural

34:20.000 --> 34:24.760
network, and you have to set them right in order for the network to perform well.

34:24.760 --> 34:30.640
And the Schema theorem just says that if they are short, small segments of weights, or segments

34:30.640 --> 34:34.760
of the neural network that are powerful, they are easier to find.

34:34.760 --> 34:41.560
Now if the Schema covers a large number of weights, that's more difficult to find.

34:41.560 --> 34:43.040
Obviously, it makes sense, right?

34:43.040 --> 34:47.200
So you have to set more numbers correctly in order to see the benefit.

34:47.200 --> 34:51.280
And the Schema theorem just says that if you have short Schema's easy ways of gaining

34:51.280 --> 34:55.680
the benefit, finding these three weights of the right values, that's going to be very

34:55.680 --> 34:59.960
easy to find, and it will very quickly become prominent in the population.

34:59.960 --> 35:01.880
And from the point of view of biology, that makes sense.

35:01.880 --> 35:06.960
I mean, if there are some genes that are very short, I mean, just single genes instead

35:06.960 --> 35:11.200
of interaction with multiple genes, that's going to be very prominent and very quickly

35:11.200 --> 35:13.120
propagate to the population.

35:13.120 --> 35:17.720
And that's the mathematics of Schema theorem just expresses that idea.

35:17.720 --> 35:25.440
And when we're training with evolutionary algorithms, is the Schema length a constant,

35:25.440 --> 35:31.480
or does this method kind of zoom in and zoom out to different levels of resolution?

35:31.480 --> 35:32.480
Yes, exactly.

35:32.480 --> 35:33.480
It will do that.

35:33.480 --> 35:36.560
We don't know ahead of time what the Schemas are like.

35:36.560 --> 35:40.080
So we define the encoding.

35:40.080 --> 35:44.880
And you try to put in as much insight into that encoding as possible.

35:44.880 --> 35:49.560
You try to define a search space where you believe, first of all, that the solutions lie

35:49.560 --> 35:54.760
in that search space, and also that it's easy to move around in that search space.

35:54.760 --> 35:59.680
And that is that requires human thinking and creativity, but evolution will then find

35:59.680 --> 36:04.320
you the best combinations of those elements in that search space.

36:04.320 --> 36:05.680
But encoding matters.

36:05.680 --> 36:09.760
In some cases, it is obvious and it's given by the domain very much.

36:09.760 --> 36:14.760
Like in neural networks, it's an obvious encoding to have ways put together into a string.

36:14.760 --> 36:18.920
But then when you think about it, some more you realize that he actually is a topology

36:18.920 --> 36:20.920
of the neural network matters as well.

36:20.920 --> 36:25.760
And then you want to have some way of encoding topology and letting evolution discover different

36:25.760 --> 36:26.760
topologies.

36:26.760 --> 36:31.480
And then you discover things like, well, if in order to make it easier to search the space,

36:31.480 --> 36:35.560
which now became much bigger because it's all the topologies in addition to just all

36:35.560 --> 36:41.920
the weight values, a clever idea is that let's start with a very small neural network, a

36:41.920 --> 36:43.240
small search space.

36:43.240 --> 36:48.200
Initially, we just start with neural networks that connect inputs directly to the outputs.

36:48.200 --> 36:53.400
No hidden nodes at all and let evolution run in that space for a while, find good, such

36:53.400 --> 36:55.040
simple networks.

36:55.040 --> 36:57.520
And then we'll add complexity.

36:57.520 --> 37:00.240
We add a hidden node and another hidden node.

37:00.240 --> 37:04.880
And then we add recurrent connections and gradually discover complexity as we go.

37:04.880 --> 37:08.880
And this principle, instead of starting with all kinds of topologies of neural networks

37:08.880 --> 37:14.520
as the initial population, if we start small, if we start simple and gradually complexify

37:14.520 --> 37:18.920
evolution is much more powerful in finding these complex solutions.

37:18.920 --> 37:23.600
So that's what I meant by being smart about how you encode it and how you let evolution

37:23.600 --> 37:25.280
to search the space.

37:25.280 --> 37:26.280
It makes a big difference.

37:26.280 --> 37:31.680
And this is one principle has turned out over and over again to be very useful.

37:31.680 --> 37:36.480
How complex can you get with this technique?

37:36.480 --> 37:45.920
If you come up with an encoding that can represent convolution layers and rectifying layers

37:45.920 --> 37:53.080
and the kinds of things that we do and CNNs for computer vision, can this thing come

37:53.080 --> 37:59.800
up with a very deep model, the types of models that we're using for object recognition nowadays

37:59.800 --> 38:01.600
or is it more limited?

38:01.600 --> 38:02.600
Yes.

38:02.600 --> 38:03.600
It's a good question.

38:03.600 --> 38:07.120
So there's really been two approaches to doing this.

38:07.120 --> 38:11.960
And the first one I just described was that you have an encoding that in principle could

38:11.960 --> 38:15.760
encode anything, any kind of connectivity and you build up from that.

38:15.760 --> 38:20.160
And that is actually very good on tasks like the reinforcement learning problem where you

38:20.160 --> 38:26.240
have to define a custom kind of recurrency that retains just the right information over

38:26.240 --> 38:30.680
time for you to disambiguate the partially observable problem.

38:30.680 --> 38:36.280
Very recently in the last two years or so, maybe two years or so, and other approaches

38:36.280 --> 38:41.120
emerged and that's specifically to evolve deep learning architectures.

38:41.120 --> 38:46.400
And there's an interesting difference in that those architectures are composed of specific

38:46.400 --> 38:47.400
components.

38:47.400 --> 38:54.920
You mentioned different convolutional neural networks, LSTM networks, drop out as a parameter

38:54.920 --> 39:01.360
max pool layers, all kinds of structures now exist that people compose these deep learning

39:01.360 --> 39:02.680
architectures from.

39:02.680 --> 39:06.720
And it now makes sense to do this a little differently because we know that there are some

39:06.720 --> 39:08.920
components that are useful.

39:08.920 --> 39:15.440
Well, let's give those components as a source material or raw material for evolution.

39:15.440 --> 39:20.120
And now you can come up with a mechanism that maybe operates in a couple of different

39:20.120 --> 39:25.240
levels, you could evolve the weights, you could evolve the components, and then you could

39:25.240 --> 39:29.560
evolve the overall topology that's based on those components.

39:29.560 --> 39:34.440
And this is currently where the deep learning neural evolution is, evolving deep learning

39:34.440 --> 39:35.440
networks.

39:35.440 --> 39:38.880
There are multiple approaches, but by and large, they do this.

39:38.880 --> 39:45.880
They evolve the hyper parameters of those networks and maybe the topology of the networks.

39:45.880 --> 39:50.720
But then the weights are trained using a supervised training set like image recognition,

39:50.720 --> 39:51.720
you mentioned.

39:51.720 --> 39:57.520
So there's still a big benefit from evolving those deep learning networks, even if you're

39:57.520 --> 40:02.600
applying it eventually to a supervised problem, because it's very hard to construct the right

40:02.600 --> 40:04.800
topology for your problem.

40:04.800 --> 40:07.560
Let's evolve and do that.

40:07.560 --> 40:10.720
And then use the training to set the weights.

40:10.720 --> 40:14.880
Weights there are millions, billions of weights, but potentially it's very hard for evolution

40:14.880 --> 40:20.000
to get every single one right if it needs to do a mutation to get the weight value right.

40:20.000 --> 40:21.920
Deep learning is much better to doing that.

40:21.920 --> 40:26.960
But the topology matters as well, and the architects of the components matters as well,

40:26.960 --> 40:31.600
and hyper parameters matter, and that we can optimize using evolution.

40:31.600 --> 40:43.280
So help us understand, so what you just said was the evolution is better for the architectural

40:43.280 --> 40:47.840
identifying the architectural solution, the connectivity, and the types of layers, and

40:47.840 --> 40:48.840
things like that.

40:48.840 --> 40:54.480
And traditional deep learning training techniques are better for the weights.

40:54.480 --> 40:55.480
Why exactly is that?

40:55.480 --> 40:59.280
You mentioned because there are a lot of weights, but I thought that was an advantage of the

40:59.280 --> 41:00.640
evolutionary approach.

41:00.640 --> 41:07.920
Well, again, so it's actually a very simple point that if you are evolving the entire network

41:07.920 --> 41:12.400
including the weights, then evolutionary operators need to set the weight values.

41:12.400 --> 41:15.040
And that means crossover or mutation.

41:15.040 --> 41:18.240
And mutation means that you are changing each weight randomly.

41:18.240 --> 41:22.760
And if you have a million weights, that's a very slow process.

41:22.760 --> 41:26.960
In contrast, something like deep learning of backpropagation, stochastic gradient descent,

41:26.960 --> 41:31.040
every time you show an example, you can change every single weight.

41:31.040 --> 41:36.960
So there's a lot more parallelism, it's a lot more efficient way of changing the weight.

41:36.960 --> 41:42.160
So what we're saying here is, if you've got training data, use traditional training

41:42.160 --> 41:47.720
techniques gradient descent, which uses that training data to accelerate training.

41:47.720 --> 41:48.720
Yeah, exactly.

41:48.720 --> 41:53.240
And where you don't have training data is kind of at this higher level.

41:53.240 --> 41:58.400
Well, it seems like you kind of, if you have the training data, you should also be able

41:58.400 --> 42:02.640
to use that for the architectural stuff.

42:02.640 --> 42:07.640
But I guess we don't have techniques for doing that gradient descent.

42:07.640 --> 42:09.640
That's where evolutionary comes in.

42:09.640 --> 42:10.640
Exactly.

42:10.640 --> 42:11.640
That's exactly the point.

42:11.640 --> 42:12.640
Okay.

42:12.640 --> 42:17.080
Now, of course, people do research and try to break free of these restrictions.

42:17.080 --> 42:22.280
And you could, for instance, use evolution for the weights as well, even in deep learning

42:22.280 --> 42:23.280
networks.

42:23.280 --> 42:26.360
But there's an interesting approach that allows you to do it.

42:26.360 --> 42:30.480
And that is that you don't evolve every single weight separately.

42:30.480 --> 42:33.040
But you evolve, say, patterns of weights.

42:33.040 --> 42:34.040
Color evolution.

42:34.040 --> 42:36.680
Well, it's a different level of evolution.

42:36.680 --> 42:42.040
It's called co-evolution, co-evolution of different levels to co-evolution of topology,

42:42.040 --> 42:46.920
co-evolution with components and then weights.

42:46.920 --> 42:52.120
But the trick here is that instead of having to set each value independently using mutation

42:52.120 --> 42:55.880
crossover, you have some kind of a pattern that you are evolving.

42:55.880 --> 42:59.760
And then you, that pattern, you use that pattern to derive the weight values.

42:59.760 --> 43:05.120
And in extreme, that pattern could be given by a different neural network, a separate

43:05.120 --> 43:06.360
neural network.

43:06.360 --> 43:11.680
So you're evolving a neural network whose outputs then give you the weight values.

43:11.680 --> 43:15.360
That technique is called compositional pattern producing neural net.

43:15.360 --> 43:19.400
And it's been used to evolve these deep learning architectures.

43:19.400 --> 43:24.280
And this is an example of how you can still use evolution, even if you don't have supervised

43:24.280 --> 43:25.280
training data necessarily.

43:25.280 --> 43:28.400
You could still use a deep learning network with millions of weights.

43:28.400 --> 43:31.920
But you have to use this kind of an indirect encoding of its weights, perhaps through another

43:31.920 --> 43:32.920
neural network.

43:32.920 --> 43:41.240
And so when you're using evolutionary algorithms to evolve the architecture and the connectivity

43:41.240 --> 43:51.840
of deep neural network or anything for that matter, are you applying evolutionary algorithms

43:51.840 --> 43:56.880
hierarchically or that as an approach hierarchically like, you know, first evolve the connectivity

43:56.880 --> 44:03.800
and separately evolve the layers or is it all done at once?

44:03.800 --> 44:04.800
All of that is possible.

44:04.800 --> 44:09.800
And all of that is under, under research right now, you know, I guess I should have anticipated

44:09.800 --> 44:10.800
that.

44:10.800 --> 44:11.800
Yes.

44:11.800 --> 44:12.800
Yes.

44:12.800 --> 44:13.800
Exactly.

44:13.800 --> 44:14.800
And you mentioned co evolution.

44:14.800 --> 44:16.840
That's a powerful approach in evolution.

44:16.840 --> 44:21.920
And that means that you have two evolutionary processes, two or more going on at once and

44:21.920 --> 44:23.000
they interact.

44:23.000 --> 44:28.040
So in this case, it would be that you evolve the module that might be a convolutional layer

44:28.040 --> 44:31.880
or some other, or LSTM type of a module.

44:31.880 --> 44:34.840
And then you evolve a topology how you connect them together.

44:34.840 --> 44:36.600
And that means that you have two populations.

44:36.600 --> 44:42.520
One of them encodes a different LSTM node and the other one encodes how they are connected.

44:42.520 --> 44:47.440
And then you can evolve them at the same time and evaluate them together as a single architecture

44:47.440 --> 44:52.200
and then the individuals inherit the fitness of the entire architecture.

44:52.200 --> 44:53.920
And that's a very interesting approach.

44:53.920 --> 44:58.200
You could also do it differently if you have a, if you have a way of assigning a fitness

44:58.200 --> 45:03.280
to say a single in LSTM node somehow, like maybe it's memory capacity or something, then

45:03.280 --> 45:07.720
you could evolve that first and evolve a bunch of different maybe LSTM nodes for different

45:07.720 --> 45:09.520
kinds of fitness functions.

45:09.520 --> 45:13.880
Use those as raw material at a higher level evolution and do it sequentially.

45:13.880 --> 45:15.360
That's also possible.

45:15.360 --> 45:17.480
But yeah, go ahead.

45:17.480 --> 45:24.680
It almost suggests that there's probably some analog for, for Gens, a generative adversarial

45:24.680 --> 45:30.040
networks like generative adversarial evolutionary algorithms or something like that is.

45:30.040 --> 45:32.320
Does that mean anything in this world?

45:32.320 --> 45:33.320
Yes, exactly.

45:33.320 --> 45:36.920
And that's actually how Gens kind of got started and motivated that.

45:36.920 --> 45:37.920
Oh, really?

45:37.920 --> 45:38.920
Yes.

45:38.920 --> 45:43.640
So it was possible to evolve input examples that broke the deep learning network that had

45:43.640 --> 45:49.680
been trained very well in a training set and, and, and then Jeff Kloon evolved these patterns

45:49.680 --> 45:54.720
that were pretty much just noise, but the network's still confident to claim that, oh, that's

45:54.720 --> 45:55.720
a dog.

45:55.720 --> 46:00.440
And, and this is like the school bus giraffe kind of example, that kind of thing.

46:00.440 --> 46:03.240
I'm not familiar with that example school bus giraffe.

46:03.240 --> 46:04.240
What is that?

46:04.240 --> 46:11.560
I'm, I may be mixing up my objects and animals here, but there is some set of famous examples

46:11.560 --> 46:17.320
where, for whatever reason, if you give, you know, one of the same famous object detection

46:17.320 --> 46:22.960
CNN's picture of a zebra or a giraffe or something like that, it confidently proclaims

46:22.960 --> 46:24.360
it to be a school bus.

46:24.360 --> 46:25.360
Oh, I see.

46:25.360 --> 46:26.360
I see.

46:26.360 --> 46:27.360
Yeah.

46:27.360 --> 46:29.920
There are many demonstrations of this same, same problem that that sounds like it's one

46:29.920 --> 46:30.920
of them.

46:30.920 --> 46:31.920
Yes.

46:31.920 --> 46:35.840
So you can mix the categories, but the most impressive demonstration to me is that there's

46:35.840 --> 46:38.160
an image that looks pretty much just noise.

46:38.160 --> 46:42.800
You cannot see anything in it, but still the deep learning system somehow declares that

46:42.800 --> 46:45.920
to be, I don't know, a school bus or something else.

46:45.920 --> 46:46.920
Right.

46:46.920 --> 46:51.120
So, but this, the origin of that was that it was possible to evolve those images.

46:51.120 --> 46:55.840
It wasn't just that we look at, look at bad mistakes in a training set, but evolve these

46:55.840 --> 47:00.120
images that we had no constraints on what they had to be and they turned out to be pretty

47:00.120 --> 47:03.160
much as noise looking images, noise images.

47:03.160 --> 47:07.720
And evolution discovered that this is a way of getting the deep learning network to perform

47:07.720 --> 47:08.720
very poorly.

47:08.720 --> 47:09.720
Wow.

47:09.720 --> 47:11.080
You've confident into something else.

47:11.080 --> 47:12.080
Yeah.

47:12.080 --> 47:13.080
That's really interesting background.

47:13.080 --> 47:14.080
I didn't realize that.

47:14.080 --> 47:18.920
And from there on, the whole field of generally a traversor and network study, like how could

47:18.920 --> 47:19.920
we actually do this?

47:19.920 --> 47:25.480
How could we have an adversarial training, the trainer or supervisor so that the network

47:25.480 --> 47:26.800
could actually perform better?

47:26.800 --> 47:31.800
Because you could use those images to train it as well as just break it.

47:31.800 --> 47:36.920
And this is, so this is a very close relation and I think it's still being explored.

47:36.920 --> 47:41.280
It's possible to evolve training sets and it's possible to evolve also these systems that

47:41.280 --> 47:45.480
are learning from them so that they become more robust and also they develop internal

47:45.480 --> 47:48.160
representations that are more representative.

47:48.160 --> 47:53.560
So we can use evolution to bias these learning systems in a way we want and make it more

47:53.560 --> 47:57.400
general, make them interpretable and more robust.

47:57.400 --> 47:58.400
Interesting.

47:58.400 --> 47:59.400
Interesting.

47:59.400 --> 48:04.440
I interrupted you earlier when you were about to talk about classes of problems for which

48:04.440 --> 48:08.200
evolutionary algorithms are particularly suited and not suited.

48:08.200 --> 48:09.200
Right.

48:09.200 --> 48:14.880
So this, of course, a lot of work in trying to expand the space of possible problems.

48:14.880 --> 48:18.360
Now, we were comparing reinforcement learning with evolution.

48:18.360 --> 48:21.800
I would like to point out that reinforcement learning has a little bit different perspective

48:21.800 --> 48:23.040
and goal.

48:23.040 --> 48:28.240
The idea there is to model a learning of an individual more or less during its lifetime.

48:28.240 --> 48:34.920
So as it's living its life and it's performing every step counts and in a sense, it's like

48:34.920 --> 48:36.440
an online method.

48:36.440 --> 48:41.480
The typical application of evolution is offline engineering type of an application that you

48:41.480 --> 48:46.560
do have, you do have a simulator for instance of the system you're trying to, or the environment

48:46.560 --> 48:48.240
for the system trying to evolve.

48:48.240 --> 48:51.800
And you can fail miserably in some of these candidates.

48:51.800 --> 48:57.320
The only thing that counts is that in the end you have a very well engineered system.

48:57.320 --> 48:59.760
And that is a different kind of a perspective.

48:59.760 --> 49:03.920
You don't get penalized for your exploration in evolutionary algorithms.

49:03.920 --> 49:07.600
You only get evaluated in the final result versus in reinforcement learning.

49:07.600 --> 49:11.640
It's a continual lifelong learning system perhaps.

49:11.640 --> 49:13.600
Now, and that makes sense.

49:13.600 --> 49:18.760
I mean, evolution is an engineering approach can can be we can evolve.

49:18.760 --> 49:22.600
For instance, controllers for finalist rockets is one thing that we did.

49:22.600 --> 49:27.960
You couldn't possibly use it in a physical system because you would have to explode hundreds

49:27.960 --> 49:29.440
of thousands of rockets.

49:29.440 --> 49:32.960
But if you have a simulator for that system, you can do anything you want with it.

49:32.960 --> 49:35.120
You can explore very wild solutions.

49:35.120 --> 49:39.280
And as a matter of fact, some of those wide solutions developed into really good solutions

49:39.280 --> 49:40.280
in the end.

49:40.280 --> 49:44.640
And in the end, we have a controller for a finless rockets that keeps its table in a reliable

49:44.640 --> 49:45.640
way.

49:45.640 --> 49:50.640
And that's the kind of typical application for an evolutionary algorithm system.

49:50.640 --> 49:54.880
Now, in on the other hand, if you have an online system that needs to learn online while

49:54.880 --> 49:58.640
it's performing, that's not as easy to use evolution for that.

49:58.640 --> 50:01.040
You have to build extra machinery for it.

50:01.040 --> 50:02.040
But you can.

50:02.040 --> 50:04.880
That's the kind of a reinforcement learning system that reinforcement learning initially

50:04.880 --> 50:06.160
came from.

50:06.160 --> 50:09.080
But it has also been to confuse everybody.

50:09.080 --> 50:13.880
It has been used to do engineering design as well, just like evolution is used to do online

50:13.880 --> 50:14.880
learning.

50:14.880 --> 50:19.000
But that's not the opposite to the origin and that's that sort of the first application

50:19.000 --> 50:22.800
would be engineering versus online learning.

50:22.800 --> 50:26.560
You mentioned simulation and that reminded me of a question that I had earlier.

50:26.560 --> 50:32.840
Is there a relationship in, you know, particularly in the context of the trading work that you've

50:32.840 --> 50:38.040
done between Monte Carlo types of approaches, the evolutionary approaches?

50:38.040 --> 50:39.040
Yeah.

50:39.040 --> 50:46.080
So Monte Carlo's simulation means just that you randomize your domain and let and generate

50:46.080 --> 50:47.800
new situations that way.

50:47.800 --> 50:54.000
Now, when you use it as a solution mechanism, you're banking on the idea that even randomized

50:54.000 --> 50:57.040
solutions are likely to be successful sometimes.

50:57.040 --> 51:03.720
So you could think of evolution as a 2.0 of that that you actually trying to learn from

51:03.720 --> 51:05.200
your mistakes.

51:05.200 --> 51:09.320
You're trying to learn from your, those trials and that is using crossover on a good

51:09.320 --> 51:13.840
at candidates and mutation on a good candidates and focus to search more.

51:13.840 --> 51:17.760
And that is, I think, a good way to formulate the relationship.

51:17.760 --> 51:22.320
You could even look at some of the evolutionary algorithm methods.

51:22.320 --> 51:26.960
We've been talking about generic algorithms, which is crossover mutation based.

51:26.960 --> 51:31.520
There are other evolution methods that are closer to something I want to call in that.

51:31.520 --> 51:38.640
They will build a statistical model of the domain, which individual components, schemas,

51:38.640 --> 51:41.720
are how reliable they are in predicting the fitness.

51:41.720 --> 51:45.320
You form that kind of probabilistic model of your search base.

51:45.320 --> 51:48.880
And then when you construct new individuals, when you construct offspring, you don't

51:48.880 --> 51:52.160
do it based on crossover mutation, you do it statistically.

51:52.160 --> 51:54.160
You sample from that model.

51:54.160 --> 51:59.600
And it's still a population based approach in that sense falls under the evolution algorithms,

51:59.600 --> 52:03.600
but it's closer to probabilistic reasoning and Monte Carlo methods and other statistical

52:03.600 --> 52:04.600
methods.

52:04.600 --> 52:05.600
And they perform quite well.

52:05.600 --> 52:07.080
Those methods perform quite well too.

52:07.080 --> 52:09.560
No, interesting, interesting.

52:09.560 --> 52:21.800
Is there a simple way to kind of categorize or characterize, I should say, the various types

52:21.800 --> 52:27.360
of evolutionary algorithms or approaches or the, you know, the various tweaks that have

52:27.360 --> 52:31.120
evolved to the basic generic approach?

52:31.120 --> 52:35.280
Well, we can attempt to do it.

52:35.280 --> 52:36.280
Researches are very creative.

52:36.280 --> 52:41.520
I mean, whenever you come up in this category, then they will cross the categories.

52:41.520 --> 52:46.560
And that's part of how research works, too, that you will combine ideas across different

52:46.560 --> 52:47.960
approaches and categories.

52:47.960 --> 52:53.040
But generic algorithms is one where the close connection to biology is obvious, crossover

52:53.040 --> 52:54.600
mutation.

52:54.600 --> 52:59.480
And then there are these statistics based approaches, like I mentioned, sometimes called

52:59.480 --> 53:04.720
estimation of distribution algorithms where you estimate the probabilistic model of what

53:04.720 --> 53:05.720
works.

53:05.720 --> 53:11.400
For example, from that, there are methods based on evolution strategy where you don't have

53:11.400 --> 53:18.120
crossover, but you have a small population and you mostly using mutation to do the search.

53:18.120 --> 53:20.320
But you make the mutations intelligent.

53:20.320 --> 53:26.000
If you have a small population, you form, for instance, a covariance matrix of how your

53:26.000 --> 53:27.760
mutations call vary.

53:27.760 --> 53:33.680
Try to find these interactions specifically and then use that model of the interactions

53:33.680 --> 53:36.240
to construct new individuals.

53:36.240 --> 53:42.240
There's differential evolution, there's different buzzwords, I can give you a lot of these,

53:42.240 --> 53:44.080
but there's a large number of them.

53:44.080 --> 53:50.720
And they are based on sometimes letting go of the biological analogy and instead focusing

53:50.720 --> 53:55.600
on the idea that what if you do have a population, how could you utilize the information in that

53:55.600 --> 53:59.600
population to construct new individuals better?

53:59.600 --> 54:04.240
And that is kind of the general umbrella of evolution algorithms.

54:04.240 --> 54:09.320
And you could even think of an interesting direction trying to go towards the biology,

54:09.320 --> 54:14.920
on the opposite direction, talking about abstracting it to probabilistic reasoning, probabilistic

54:14.920 --> 54:17.120
and stochastic search.

54:17.120 --> 54:22.880
But you could also go towards biology and there's an interesting idea, try to take some ideas

54:22.880 --> 54:26.080
that are more biological, for instance, in directing coding.

54:26.080 --> 54:33.680
The fact that in biology, DNA, the actual ribbon, like that, asic does not really specify

54:33.680 --> 54:40.120
the full individual, there's a large network of interactions that come after generating

54:40.120 --> 54:42.640
the proteins from the DNA and RNA.

54:42.640 --> 54:48.240
So genetic regulatory networks are a huge part of biological construction from the DNA

54:48.240 --> 54:49.680
to an individual.

54:49.680 --> 54:53.960
And currently we are pretty much missing that in these algorithms.

54:53.960 --> 54:58.360
So there's a lot of complexity in this kind of indirect encoding.

54:58.360 --> 55:02.480
There are approaches that try to invoke genetic regulatory networks.

55:02.480 --> 55:08.240
There are approaches that are trying to include a developmental phase, which is also big in biology.

55:08.240 --> 55:14.240
So after the individual is constructed, after it's born, there's usually a period of learning

55:14.240 --> 55:15.240
that happens.

55:15.240 --> 55:19.120
Interaction with the environment and that then constructs the final individual.

55:19.120 --> 55:24.080
For instance, human brain, we have 30,000 genes maybe in the genome.

55:24.080 --> 55:29.320
There's no way the brain can be specified except at a course kind of instructive level,

55:29.320 --> 55:31.040
pattern level.

55:31.040 --> 55:35.960
Most of the brain structure is actually learned in an interaction with the environment.

55:35.960 --> 55:39.720
Evolution just produces a starting point for that learning.

55:39.720 --> 55:44.840
So combining learning and evolution that way is fundamentally biological and it's also

55:44.840 --> 55:49.440
something that we should be looking into and we are looking into, people are looking into it.

55:49.440 --> 55:55.840
This is really a fascinating area for folks that want to dig in a little bit deeper or

55:55.840 --> 55:59.360
learn more, where is the best place to start?

55:59.360 --> 56:02.360
Are there canonical papers they should start at?

56:02.360 --> 56:06.760
Is there a resource that you'd like to recommend people take a look at?

56:06.760 --> 56:13.240
Sure, there are some classic books that are about evolution algorithms and can find

56:13.240 --> 56:18.840
genetic algorithm evolution computation books that are textbooks, Holland, Mitchell, Goldberg

56:18.840 --> 56:19.840
for instance.

56:19.840 --> 56:24.960
They tend to be a little bit old right now because the field is developing very rapidly.

56:24.960 --> 56:31.120
It has been explosive growth, but the typical sources on Scholarpedia for instance and

56:31.120 --> 56:37.160
then the tutorials that appear in the main conferences I think would be a great source.

56:37.160 --> 56:42.400
There will be actually a genetic and evolution computation conference Gecko starts tomorrow

56:42.400 --> 56:44.720
as a matter of fact in Berlin.

56:44.720 --> 56:50.160
And the first two days are tutorials and lots of those tutorials are online, even some

56:50.160 --> 56:54.480
of the videos about the tutorials online and I think that those are really a great way

56:54.480 --> 56:55.480
to get started.

56:55.480 --> 57:01.120
It is a big field and in a very diverse field, it's kind of interesting because evolution

57:01.120 --> 57:05.560
drives on diversity, the algorithms drive on diversity, but the field is also tremendously

57:05.560 --> 57:07.160
diverse.

57:07.160 --> 57:12.240
So that is a bit of a challenge that you may get lost in all these terminology and all

57:12.240 --> 57:17.000
the different approaches, and that's why I'm recommended that maybe starting from one

57:17.000 --> 57:21.960
of the textbooks even if it's a little bit older is a good idea that gives you the perspective

57:21.960 --> 57:27.120
and then looking at the tutorials and maybe there on it, you should have access to a

57:27.120 --> 57:29.800
lot of literature on the internet.

57:29.800 --> 57:36.440
Are there tools and frameworks or do the deep learning frameworks, the TensorFlow's of

57:36.440 --> 57:37.440
the world, and the like?

57:37.440 --> 57:44.800
Do they support, have any kind of support for evolutionary algorithms or are folks rolling

57:44.800 --> 57:45.800
their own?

57:45.800 --> 57:52.040
Yeah, so TensorFlow, I don't think currently has evolution component, but it is likely

57:52.040 --> 57:53.040
that it will in the future.

57:53.040 --> 57:57.320
It's an open source project and people are contributing to it, so it's very likely to

57:57.320 --> 57:58.320
happen.

57:58.320 --> 58:04.480
There's for instance, ECJ, evolution competition in Java, that's a big effort, George Mason

58:04.480 --> 58:09.240
University, and that software includes many different evolutionary algorithms, and that

58:09.240 --> 58:13.800
I think is currently the best source to get started with, software system to get started

58:13.800 --> 58:14.800
with.

58:14.800 --> 58:15.800
Great, great.

58:15.800 --> 58:21.680
Well, to wrap things up, can you let folks know what's the best way to check in on you

58:21.680 --> 58:23.080
or to get in touch with you?

58:23.080 --> 58:29.000
Well, I have a name that's very easy to find, if you can figure out the spelling.

58:29.000 --> 58:35.600
Yeah, so I have a website at UT Austin, where much of my research from my whole career is

58:35.600 --> 58:36.600
always there.

58:36.600 --> 58:43.560
I try to keep that up to speed, and of course, Cynthia itself has a set of blog posts and

58:43.560 --> 58:47.920
web pages describing the technology we are developing here, which is evolution, competition

58:47.920 --> 58:48.920
and deep learning.

58:48.920 --> 58:54.040
So those sites are usually quite well up to date, and then we have pointers to more material

58:54.040 --> 58:56.320
that you can use those as a starting point.

58:56.320 --> 58:59.600
Okay, great, and we'll link to both of those in the show notes.

58:59.600 --> 59:00.600
Very good.

59:00.600 --> 59:01.600
Thank you.

59:01.600 --> 59:02.720
All right, well, Risto, thank you very much.

59:02.720 --> 59:03.720
This was amazing.

59:03.720 --> 59:07.720
It was a lot of fun.

59:07.720 --> 59:14.120
All right, everyone, that's our show for today.

59:14.120 --> 59:20.440
Thanks so much for listening, and of course, for your ongoing feedback and support.

59:20.440 --> 59:27.560
For the notes for this episode, head on over to twimlai.com slash talk slash 47.

59:27.560 --> 59:29.360
I've got a quick favor to ask.

59:29.360 --> 59:35.120
If you enjoy the podcast, and especially if you like this episode, please take a moment

59:35.120 --> 59:40.040
to jump on over to iTunes and leave us a five-star review.

59:40.040 --> 59:46.080
We'd love to read these, and it lets others know that the podcast is worth tuning into.

59:46.080 --> 59:50.720
Another thanks to this week's sponsor, Claudeira, for more information on their data science

59:50.720 --> 59:57.680
workbench or to schedule your demo and get a drone, visit twimlai.com slash Claudeira.

59:57.680 --> 01:00:02.560
I'd also like to send a huge shout out to friend of the show Hilary Mason, whose company

01:00:02.560 --> 01:00:07.240
Fast Forward Labs was acquired by Claudeira just last week.

01:00:07.240 --> 01:00:13.560
For more on Hilary and Fast Forward Labs, check out my interview with her at twimlai.com

01:00:13.560 --> 01:00:18.840
slash talk slash 11, and my interview with the former president of that company, Catherine

01:00:18.840 --> 01:00:23.560
Hume, at twimlai.com slash talk slash 20.

01:00:23.560 --> 01:00:52.080
Thanks again for listening, and catch you next time.

