Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
This week's shows are drawn from some of the great conversations I had at the recent
Nvidia GPU technology conference and they're brought to you by Dell.
If you caught my tweets from GTC, you may already know that one of the announcements this
year was a new reference architecture for data science work stations powered by high
NGPUs and accelerated software such as Nvidia's Rapids.
Dell was among the key partners showcased during the launch and offers a line of workstations
designed for modern machine learning and AI workloads.
To learn more about Dell precision workstations and some of the ways they're being used by customers
in industries like media and entertainment, engineering and manufacturing, healthcare
and life sciences, oil and gas and financial services, visit Dell EMC.com slash precision.
Alright everyone, I am on the line with Gerald Kwan.
Gerald is an assistant professor at UC Davis.
Gerald, welcome to this week in machine learning and AI.
Thanks for the invitation to interview with you.
Absolutely, absolutely.
I'm looking forward to diving into some of the work that you've been doing around applying
deep learning to genomics.
Before we do that, I'd love to hear a little bit about your background and how you started
working in the intersection of those two fields.
So I guess my career in computational biology started out in my first year undergrad actually
where I was initially slated to enter a computer science undergraduate program and about
two weeks before I started, I got a piece of paper in the mail from my university telling
me that they started a new bioinformatics program and were wondering if I was interested
in joining.
And actually initially, I initially turned them down because I thought the idea of kind
of studying biology with computers was, you know, it didn't seem that interesting.
But after a couple semesters, I just happened to meet a professor doing some really interesting
kind of high throughput data analysis, looking at proteins in their kind of three dimensional
structures and he was interested in kind of predicting these 3D structures from their
kind of linear protein sequence and I was just kind of peaked my interest in from there
I just kind of, yeah, I never really looked back.
And so do you currently sit in which department at Davis?
So I'm in the department of Lecler and Cell Bio, which is a little bit of a, yeah, it's
kind of an interesting, interesting place to be because I, you know, my undergrad gain
was kind of in computer science bioinformatics and then I took a brief break and went to biochemistry,
had to do masters in biochemistry before I went back to computer science for a PhD.
And I think this kind of background where I have a little bit of biology and a little bit
of computer science background kind of appealed to my department and so that's kind of how
I ended up here.
Awesome.
Awesome.
And so you were recently at the NVIDIA GTC conference where you gave a presentation
on deep domain adaptation and generative models for single cell genomics.
What's the main challenge that you're talking about in that presentation?
Well, so basically in the field of kind of molecular biology, you know, these kind of genomics
technologies are the biologist's way of kind of getting really high resolution snapshots
of different kinds of like human tissues and so on.
And the work that I spoke with specifically is kind of on this emerging field called
single cell genomics where you could actually do these measurements on individual cells
where it's kind of historically you had to kind of use like really big tissues in order
to get enough sample to generate this data.
And so it's kind of exciting because you know, because you can do measurements on these
on these single cells, you can generate vast orders of magnitude more data than you could
previously.
And so now, whereas before when you look at kind of human data, you could only generate
data for say like a couple hundred tissues or samples, now we can generate like millions
of data for millions of samples.
And so that it's really exciting because you can now we can sort of apply a lot of the
kind of methods from like deep learning and so on because we have this large amount
of data that we we didn't previously have.
What are some of the things that you're trying to understand through these analyses or diseases
that you're trying to identify or fight?
We try to study a couple of diseases of interest.
So these include things like cancer and Alzheimer's disease and schizophrenia.
And so the basic premise is that you know, if you want to kind of understand how say
a disease like schizophrenia works, you know, you kind of want to take say samples from
brain tissues from sort of so-called healthy normal people and you want to take them
from these, you know, say people with schizophrenia, and then you want to somehow be able to
compare, you know, the data that you get from both of these groups of patients in order
to figure out what changed when you know, when schizophrenia happens at different stages.
And so again, in sort of this, in our work that we presented at the GTC, the tool that
we developed was specifically designed to basically build models of genomic data in both
kind of normal people and schizophrenia people and then kind of use techniques from domain
adaptation to kind of understand how the two are related.
And this is maybe a more domain specific question.
But for something like schizophrenia, it strikes me as more of a systemic problem than
a, you know, something that you would see in a single cell.
How does what's the connection?
So you're right.
You know, complex diseases like schizophrenia have, you know, there's many factors that
contribute to the development of schizophrenia.
In our particular work, we look at, we try to look at whole regions of the brain and how
these whole regions may change between normal people with schizophrenia.
And so the reason why this single cell stuff is really interesting is because previously
if you wanted to, like we know that in the brain there's like lots of different types
of cells and tissues in there.
And so previously when people did these kind of studies, they could only take say an entire
brain kind of chop it up and then look at a snapshot of the whole brain and compare
a whole normal versus whole schizophrenia.
But now because we can measure things at single cell, we can take, we can measure like millions
of cells in a single normal person, millions of cells in a single schizophrenia person,
and then try to compare and say, okay, of these million cells I got from one normal, one
schizophrenic person, which subset of these million cells is actually changing because
not all, like not, you know, not everything in the brain will change when you get schizophrenia.
And so we've talked about genomics here is the data that you're fundamentally looking
at, is it sequence data or is it some kind of imaging data or a combination of the two?
So the data that sort of comes from the biologist comes in the form of like DNA or RNA sequence
from these patients, but that kind of gets converted in this kind of data preprocessing
steps such that the data that we look at essentially is just, it just blows down to matrices
where like columns of these matrices correspond to different cells from a patient and rows
represent kind of different features of the cells that are measured through genomics.
So a feature, an example of a feature being like a known sequence or something, the existence
of a known sequence or a snip or something like that?
So it actually corresponds to like a gene and so the idea is that when you look at a cell
within, you know, a patient, you can measure, you can make many different types of measurements
on the cells, but one common type of measurement is called a gene expression measurement.
So the idea is that, you know, each cell has DNA in it, but DNA by itself usually acts
as kind of just a storage mechanism.
So for DNA to do anything, it actually, large parts of it get converted to this molecule
called RNA.
And so what we're measuring, what each features measuring is how much of this kind of active
RNA molecule gets produced from each part of the DNA.
And so that's how we get like a vector for each cell where each component corresponds
to how much activity we see from a given part of the genome.
Okay.
And so how does, where does domain adaptation and generative models, where do those come
into your workflow here?
So we're, the GTC talk was, was basically discussing two different projects.
So in terms of domain adaptation, the problem we were trying to solve there is that essentially
the problem is when you kind of look at, when you look at these features of cells in normal
versus schizophrenia people, the, and you do say, so one of the, one of the most common
first tasks that people do when they, when they get this kind of data is they, they will
do some, you know, dimensionality reduction and they'll sort of visualize the cells that
they get from these normal schizophrenia people.
And the first thing that you notice when you do this visualization is that all of the
cells that you collect from normal people separate very distinctly from the cells that you
get from schizophrenia people.
Now this is kind of a problem because the, you know, your underlying goal is, you know,
you have these different types of cells represented in the normal and the schizophrenia people.
And you ideally want to kind of in an unsupervised way match the right cell types from the normal
schizophrenia people so that you can figure out for each type of cell, how are they different
across the two populations.
And so we use, we basically perform domain, domain adaptation to take these cells that kind
of look very different overall between normal schizophrenia people and kind of merge them
together such that cells of the same type basically look very similar to each other.
And so we can kind of match them across, across these two groups of people.
So the adaptation really is in basically building model to say, okay, given this is what my data
from the normal people look like, given this is what the data from the schizophrenia people
look like.
Can I kind of match them such that the distribution of my cells in this feature space basically
overlap?
And so when you say the data looks very different between these two groups, in what sense?
I mean, in some sense, that's what you want if you're trying to build a classifier that
can determine whether a given cell indicates schizophrenia, for example.
But it sounds like that's not the part of the process that you're working on here.
So I guess just to be more clear, there are both kind of very large scale differences
between normal and schizophrenia people.
And then there's very kind of smaller changes that are specific to each type of cell that
is different between normal and schizophrenia people.
And so in a typical kind of analysis, you want to first characterize what are those very
big changes that cause these two different types of cells from these two types of people
to reside in different regions of this feature space.
And then conditioned on understanding what those big changes are, you want to then take
away the effect of that big change such that now you can look at individual cell types
and then ask, okay, for these individual groups of cells that are common between normal
and schizophrenia, what's different about them?
What's the approach for doing that?
There's been some previous work published, basically these class of models called associative
domain adaptation have previously been developed.
And so in the associative domain adaptation problem, the problem that are trying to solve
is that they basically envision that you have, say, two different data sets where you're
trying to perform the same task.
So they assume that you're trying to do classification in dataset one and classification in dataset
two.
And they assume that you have, you know, you have the same labels that you're trying to
classify in both datasets.
Now what the assumption that the original associative domain adaptation makes is that although the
labels that you're trying to classify are the same, the distribution of the data is different.
So given your feature space, the data in one dataset sits in a different region of the
feature space than the other.
And so this, their domain adaptation approach was designed to basically try to essentially
learn kind of common features that are predictive of the same labels across these two different
datasets.
And so our approach is basically similar in the sense that we have, you know, we have data
in sort of two different regions of the feature space, corresponding to normal and schizophrenia.
But in our case, we're trying to do an unsupervised analysis, so we're trying to group cells that
come from these two different domains, but we think represent the same cell type.
And so we basically modify their domain app, original supervised domain adaptation approach
to do unsupervised clustering across two datasets.
So the way that the approach works is that it's a deep neural network and it looks, it
looks for all intents and purposes like an autoencoder.
So, you know, the first half of the network takes the data in the original feature space
and it projects it down to a low dimensional manifold.
And then the second half of the network takes the low dimensional manifold and projects
it back into some high dimensional space.
But kind of unlike a typical autoencoder where the loss function that you're optimizing,
you know, can be something like C squared loss, sorry, squared error.
What are and what what our loss function is and what the other domain adaptation loss
function is, is it it actually, what we try to do is we try to find a low dimensional
embedding of the different cells such that the marginal distribution of the cells in the
latent space overlap between the two datasets as much as possible.
And so there's no kind of notion of kind of squared loss or reconstruction loss that
we're trying to optimize here.
It's really just trying to match the marginal distributions of the cells in the low dimensional
embedding space between the two different datasets.
And so the embedding space that you're creating when you're trying to overlap the two, that's
essentially the domain adaptation aspect of this, is that right?
Exactly.
Yeah, we're essentially adapting like one domain to another.
We're distorting one set of cells to match the marginal distribution of the other.
So where does the domain adaptation fit in in your overall kind of end to end experimentation?
Well, so what we do is we take the two the cells from the two different groups.
We do this adaptation of to bring them into the same region of the future space.
And that then allows us to match for an individual cell by cell basis.
We can say, okay, this cell in the normal person corresponds to exactly this normal cell
in the schizophrenic person.
And then we can, that then allows us downstream to then look at those individual cells paired
across normal schizophrenic people and ask the question, how are they different in
terms of the original features?
And when you're talking about looking at these different types of cells pre and post adaptation,
are you taking the output of the domain adaptation and using that to train a model or is it for
more manual analysis?
So one thing that I didn't quite discuss it as I said that we, you know, we trained
this network to learn and embedding a shared embedding space for both kind of the normal
and schizophrenic people, but what I didn't talk about is that the other half of the network
is still a decoder and it's a decoder in the traditional sense where we learn the encoder
separately.
And then after we learn the shared embedding space, we train decoders to take cells from
this shared embedding space and project them back into the normal versus schizophrenic
data set.
And so this is important for the following reason.
So the reason why domain adaptation is necessary for this kind of genomic analysis is that
in the ideal biological experiment, you would be able to take a normal cell, you would
be able to kind of assay it's, you know, make those high dimensional measurements, you
would then be able to kind of give it schizophrenic and give it schizophrenia in some sense and then measure
its activity again.
And so in that sense, you'd be able to take exactly the same cell but kind of before and
after you've applied this phenotype, this disease phenotype, and then see exactly what change
occurred in that cell do do this, do this stimulus.
And so this isn't possible in real biology because to kind of, you know, make these high
dimensional measurements, you have to kill the cell and so you can measure the same cell
twice.
But because we can train decoders which take any cell in this shared embedding space, project
it to normal or schizophrenia, we can now kind of simulate, you know, what would happen
if you took one cell and you gave it either, you know, you made it either normal cell or
schizophrenia cell.
And so now we can treat these projections as paired data and then ask on a personal basis,
you know, how do they, how do they differ between between these two conditions?
And so, so getting back to original question, we don't, you know, the downstream analysis
is still kind of somewhat manual but we are kind of trying to do something a little bit
smarter by using these decoders to kind of simulate these biological experiments that
we can't do.
Right.
Right.
But ultimately you're not trying to like train a classifier to determine, you know, given
a cell, whether it's normal or schizophrenic or not, it's more using the domain adaptation
to allow you to more kind of manually compare the characteristics of these two types of
cells absent the kind of broad spectrum differences between the two.
So that's the domain adaptation piece and then you, you're using generative models as
a part of this as well.
Where do they come in?
Right.
And so the idea behind these generative models is that one of the kind of really hot research
areas in biology right now is to kind of try to understand how cells work together.
Right.
And so, you know, there's this kind of this big focus on, okay, can we, you know, do these
genomic measurements on these individual cell single cell levels?
But part of the thing is that when you look at, like, you know, a disease like cancer,
for example, cancer is not really just kind of a collection of individual cancer cells
doing their own thing.
They're kind of, there's a lot of cross talk between them.
They're kind of helping each other out to kind of, you know, metastasize and so on.
And so the idea of our generative model is that we kind of want to, is that, you know,
it's very easy nowadays to take cells in isolation and, you know, measure their genomics profile
to see what they're doing.
And it's also easy to take a collection of them together when they're working together
and measure as a whole, you know, what they're doing.
And so now what we're trying to do is we're trying to develop models where generative models
where we have generative models for each individual cell based on measurements we make on single
cell level.
And then these component generative models essentially inform a very larger generative
model which try to explain what happens when you put them all together, if that makes
sense.
And so we're basically learning these nested generative models to say, okay, what can
we learn about cells in isolation and then can we explain how they work together and why
that's different from just some of the individual components itself.
Wow, there's a lot there.
So these nested generative models, are they end to end trained or are you training them
on a cell by cell basis and then kind of unsombling or aggregating to create the system
level?
We're basically training them end to end by optimizing.
So basically, for example, the component generative models that kind of handle what generating
individual cell types look like, those are influenced both by our data on the individual
cells themselves as well as kind of the cells all together, whereas other components that
take these, whereas the other pieces of the bigger model that take the individual components
and somehow add them together, those are only influenced by the data on kind of the bulk
cells, all of the cells together.
And so we kind of try to optimize them all, we try to optimize the parameters of all
of these parts of the network at the same time.
And so is the starting the underlying data set that you're using to build up these generative
models?
Is it the same type of data that we discussed previously for the domain adaptation piece?
Right, so the parts, the type of data used to train the individual generative models
of each cell type are the same type of data as we just talked about with the domain adaptation.
The type of data that we collect to measure how they're working together is actually from
an older technology.
So kind of genomics technologies that don't work on single cell levels, but they work
on measuring genomics of a collection of cells together.
And so we're kind of mixing data then from a newer generation and in older generation.
What type of gen approach did you use for this?
So we actually, we started out with variational auto encoders actually.
We tried different types of different variants of variational auto coders, it turns out for
this specific problem, in terms of performance, you know, this specific variant didn't seem
to make such a big difference.
So we are trying to, we are also trying more certainly to kind of combine.
So I mean, the number of people have looked at this performance, basically use like deep
graphical models, where again, like the generative models are, you know, they use proper probability
distributions, but they also use neural networks in there as well.
So the variational auto encoder, you started this project using variational auto encoders
for your generative models, but then did you ultimately evolve to using more of a
GAN type of a model?
We actually have tried, we've tried GANs in the past, we found they were a little bit
more difficult to train.
And so part of the issue here, when, you know, part of the issue we have in the field of
computation biology is that we're building these models in part to try to understand
something about biology into these, but also a lot of these kind of problems.
So this, the problem that we're trying to solve with these generative models is what's
called deconvolution.
And this, the problem of deconvolution arises in many different areas of biology as well.
And so part of what we're trying to do is also develop kind of usable software than
Ben Shindtis, Ben Shindtis biologists who may not have a lot of experience training
neural nets, for example, can easily just kind of pick up and apply to their own problems.
And so we found it using, at least, you know, when comparing VAE's versus GANs, the VAE
based models were easier for other people to train and use on their own data, whereas
the GANs seem to be much harder to get to work out of the box.
Got it.
And so I guess from a more practical perspective, we, our current models are based on VAE's
just because it's easier to give to other people to use on their own problems.
And so you've got the domain adaptation piece and the generative models.
Are those, do those then come together as part of this pipeline, or are they just both
tools in your tool bag that you used to study these cells and the conditions that create
them?
So they're basically two related but distinct tools that we're using on similar problems.
So we're basically part of a project called the human cell Atlas, whose goal is in part
to kind of characterize human tissues and organs at the single cell level and characterize
how they look under normal and disease conditions.
And so both of these tools, you know, one which enables comparison of data collected
under different experiments, which is the domain adaptation and the other deconvolution,
which is a tool to help us understand how do, you know, wire human tissues, not just collections
of their individual components.
I sort of see both of these tools as, you know, ways to study this, to study the same problem
essentially.
Are there examples you can share of insights that these tools ultimately led to?
Up to now, we've basically been working mostly on kind of the development aspect of this
tool, so we've been developing it and kind of validating that it works on, you know,
datasets with known ground truth.
And so now we're kind of in the, we're in the process of applying these tools in the
number of different ways.
And so to give an example of, you know, maybe a more practical application, this tool,
we're working, you know, one, in one problem we're looking at, we're trying to understand
how, for example, these malaria parasites, you know, transmit themselves across, you
know, across various populations.
And so, you know, the thing about malaria is that malaria is kind of an interesting parasite
because it has this like life cycle where for single, basically for single parasite,
at the end of this life cycle, it has to make a decision, you know, do I asexually reproduce
or do I sexually reproduce and therefore, you know, which therefore leads to transmission.
And so kind of understanding, you know, if you can get a good grasp of how these malaria
parasites decide when and how to transmit to other hosts, then you could potentially
develop therapies to stop it.
And so that's in this specific problem we were working with some other scientists to,
to basically compare malaria parasites that were undergoing kind of sexual or asexual
reproduction and doing this domain adaptation to then ask the question, you know, at what
point do these two different, do these malaria parasites, you know, going down two different
fates change.
And so by applying this tool, we identified a small set of genes, which now we think
if we kind of delete these genes from the malaria or somehow inhibit them from working,
we might be able to stop their transmission.
But this kind of work is still, the downstream application of these tools is still kind
of something that we're now just getting into now that we've kind of established that
the tools are working.
Well, certainly that the application to malaria could be hugely impactful if we're able
to identify and kind of stop that whatever the sequence is, yeah, the transmission, obviously
the transmission, but whatever the mechanism is that is causing the transmission, whether
there are other things that you covered in your presentation that it would make sense
to jump into.
So I think, you know, one of the things that we briefly touched on that we're really
excited about is kind of the use of the use of machine learning to do what people sometimes
call like multimodal data integration.
And so the idea here is that sort of in biology again, a lot of people including, including,
you know, my research lab, you know, we do a lot of analyses at kind of like the DNA level,
which is kind of very low level.
And we, you know, our goal is always to somehow tie what happens at the low level to, you
know, the big things like, you know, are you going to get the disease or not?
But you know, tying these low level events to these high level things like disease incidents
is sometimes really hard because there's a lot of steps between, you know, things that
happen at DNA level and things that happen at, you know, the whole human level.
So nowadays there's kind of more and more interest in people collecting data from the same kinds
of cells or tissues that both kind of like the DNA level and at the whole cell level and
at the kind of tissue level and then trying to link all of these things together such
that we can instead of just trying to predict, okay, if something happened, if this event
happens at DNA, you know, am I going to get disease?
Now we can try to predict, okay, if something happens at the DNA level, does that somehow
change how my, like, tissues are organized or how my brain is, like, structured and then
how does that then kind of impact the season?
So I think, you know, for example, we're working with some people at the Allendants
too for brain science where they're kind of, they're doing some really cool experiments
where they can take certain types of brain cells and they can use like electrophysiology
or, you know, they can take pictures of the cell to look at their shape and then also
measure what's happening at the genome level.
And so now we're trying to build models which can basically tie together things at the
DNA level, at the kind of electrophysiology level and at the imaging level to try to get
a better understanding of how do events at the DNA change our risk of disease.
And so this is, you know, this is kind of exciting because, you know, now we, you know, there's
obviously tons and tons of work in the computer vision field for doing things like, you know,
doing all things related to image processing and, you know, understanding, understanding
images.
And so now we can, you know, our goal over the next few years is to try to incorporate,
you know, what's happening in, like, computer vision with, you know, our work in sort of genomics
along with, you know, what people have been doing, modeling neuroscience data and try
to put it all together to try to kind of really understand what's happening in biology
and the human cell.
Well, very interesting work, Gerald, thanks so much for taking the time to chat with us
about it.
Yep, definitely.
Thanks.
All right, everyone, that's our show for today.
For more information on any of the shows in our GTC 2019 series, visit twimmaleye.com
slash GTC19.
Thanks again to Dell for sponsoring this series.
Be sure to check them out at dellemc.com slash precision.
As always, thanks so much for listening and catch you next time.
