1
00:00:00,000 --> 00:00:13,400
Welcome to the Twomo AI Podcast.

2
00:00:13,400 --> 00:00:16,400
I'm your host Sam Charrington.

3
00:00:16,400 --> 00:00:24,360
Hey, what's up Twomo listeners?

4
00:00:24,360 --> 00:00:28,720
I've got a super busy few weeks ahead of me as I head back out on the road to close out

5
00:00:28,720 --> 00:00:31,640
the 2019 conference season.

6
00:00:31,640 --> 00:00:35,520
Next week I'll be at CUBEcon, hanging out with my Kubanot friends and getting caught

7
00:00:35,520 --> 00:00:40,280
up on how the open source Kuban80's project is evolving to support machine learning at

8
00:00:40,280 --> 00:00:41,880
scale.

9
00:00:41,880 --> 00:00:45,840
Then the week of December 2nd, I'll be turning my attention to machine learning and AI

10
00:00:45,840 --> 00:00:50,160
in the cloud at the AWS re-invent conference.

11
00:00:50,160 --> 00:00:54,040
In the following week, the week of the 9th, I'll be hanging out with the AI research

12
00:00:54,040 --> 00:00:56,880
community at NURRIPS.

13
00:00:56,880 --> 00:01:04,040
Definitely reach out if you'll be at any of these events I'd really love to meet you.

14
00:01:04,040 --> 00:01:09,880
Before we get to today's show, a quick plug for the TwomoCon AI Platforms video packages

15
00:01:09,880 --> 00:01:12,840
that we've currently got available for pre-order.

16
00:01:12,840 --> 00:01:17,080
If you're working in an organization where productivity, efficiency, or scale of your machine

17
00:01:17,080 --> 00:01:22,960
learning efforts matters, please hit the pause button and check out twomocon.com slash

18
00:01:22,960 --> 00:01:27,240
videos where you can take a look at what we've got on offer.

19
00:01:27,240 --> 00:01:31,840
While I could list a ton of reasons why you should get these for yourself or your team,

20
00:01:31,840 --> 00:01:36,120
instead I thought I'd share a few of my favorite attendee quotes.

21
00:01:36,120 --> 00:01:39,880
Very, very relevant for my day-to-day work.

22
00:01:39,880 --> 00:01:45,000
Practical information for those trying to scale AI in their organization.

23
00:01:45,000 --> 00:01:50,240
If you were to plot out quality versus density, this is up and to the right.

24
00:01:50,240 --> 00:01:54,400
More pricing goes away as soon as we get the videos posted, which is likely within

25
00:01:54,400 --> 00:01:55,400
a week.

26
00:01:55,400 --> 00:02:00,880
So don't miss this opportunity to get a great deal on this amazing resource and of course

27
00:02:00,880 --> 00:02:04,160
to support your favorite ML&AI podcast.

28
00:02:04,160 --> 00:02:09,960
Once again, visit twomocon.com slash videos for more information on individual and team

29
00:02:09,960 --> 00:02:10,960
pricing.

30
00:02:10,960 --> 00:02:14,160
All right, on to the show.

31
00:02:14,160 --> 00:02:20,400
All right, everyone, I am on the line with Terry Stenobsky.

32
00:02:20,400 --> 00:02:25,920
Terry is the Frances Crick Chair and Head of the Computational Neurobiology Lab at Salk

33
00:02:25,920 --> 00:02:32,480
Institute for Biological Studies, as well as he's on the faculty at UC San Diego.

34
00:02:32,480 --> 00:02:35,400
Terry, welcome to the Twomo AI podcast.

35
00:02:35,400 --> 00:02:37,040
Wonderful to be here.

36
00:02:37,040 --> 00:02:40,720
I'm really excited about jumping into our conversation.

37
00:02:40,720 --> 00:02:44,360
Why don't we start by having you share a little bit about your background.

38
00:02:44,360 --> 00:02:49,880
You are one of the founders of the field of computational neuroscience.

39
00:02:49,880 --> 00:02:51,720
How did that come to be?

40
00:02:51,720 --> 00:02:58,720
Yes, it is a combination of my training first in physics.

41
00:02:58,720 --> 00:03:06,000
My PhD is from Princeton University and then postdoctoral work afterwards at Harvard Department

42
00:03:06,000 --> 00:03:07,800
of Neurobiology.

43
00:03:07,800 --> 00:03:13,200
And it was at a time when neuroscience was really heavily dominated by empirical studies

44
00:03:13,200 --> 00:03:20,240
and it still is, but I felt that with my training in physics and developing models that this

45
00:03:20,240 --> 00:03:30,400
could be another part of enhanced neuroscience and help go from the biological substrate

46
00:03:30,400 --> 00:03:35,400
to a more computational perspective on the function of the neural circuits that we were

47
00:03:35,400 --> 00:03:36,400
trying to study.

48
00:03:36,400 --> 00:03:45,360
And so are you fundamentally trying to apply computation to better understand the neurons

49
00:03:45,360 --> 00:03:53,720
and how they operate within a biological context or to use neurological function as we understand

50
00:03:53,720 --> 00:03:56,520
it to improve computation?

51
00:03:56,520 --> 00:03:57,960
You know, it's really both.

52
00:03:57,960 --> 00:04:00,120
It's a two-way street.

53
00:04:00,120 --> 00:04:04,200
And Richard Feynman once said that how do you know whether you really understand something

54
00:04:04,200 --> 00:04:09,560
is when you can build it based on the principles that you've uncovered and it works and it has

55
00:04:09,560 --> 00:04:11,640
the same functionality.

56
00:04:11,640 --> 00:04:19,320
And so we've been trying to do that with building, you know, very detailed models of neurons,

57
00:04:19,320 --> 00:04:27,960
but also synapses, but also developing larger-scale, neural, spiking neural models, which help

58
00:04:27,960 --> 00:04:30,960
the experimental people interpret their data.

59
00:04:30,960 --> 00:04:39,880
And at the same time, because we have computational applications, we can use that to develop much

60
00:04:39,880 --> 00:04:46,160
more powerful systems for being able to do things like control robots, vision systems,

61
00:04:46,160 --> 00:04:49,800
and all of the recent advances that have been occurring in deep learning have basically

62
00:04:49,800 --> 00:04:52,560
come from that direction.

63
00:04:52,560 --> 00:04:53,560
Interesting.

64
00:04:53,560 --> 00:04:54,560
Interesting.

65
00:04:54,560 --> 00:05:01,760
A few chats about spiking neural nets on the show before, most recently, the podcast

66
00:05:01,760 --> 00:05:07,440
I did with Jeff Gellhar from Qualcomm and it came up in a very tangential ways.

67
00:05:07,440 --> 00:05:12,120
So this would be the first time that I've had an opportunity to really, really dig into

68
00:05:12,120 --> 00:05:13,120
the topic.

69
00:05:13,120 --> 00:05:20,760
My understanding of the general idea of spiking neural nets as it applies to machine learning

70
00:05:20,760 --> 00:05:29,240
is that in a lot of ways deep learning and artificial neural nets are inspired by biological

71
00:05:29,240 --> 00:05:36,840
systems, but one key difference is that biological systems exhibit the spiking behavior.

72
00:05:36,840 --> 00:05:43,880
And so the field of spiking neural nets is trying to come up with computational analogs

73
00:05:43,880 --> 00:05:51,840
for the spiking system that can do, that can act or perform like artificial, or that

74
00:05:51,840 --> 00:05:59,760
can perform as artificial neural nets and hopefully lead us to more performing and

75
00:05:59,760 --> 00:06:03,800
more efficient artificial neural net systems.

76
00:06:03,800 --> 00:06:10,840
Is that kind of a good, super high level synopsis of the general direction of research in

77
00:06:10,840 --> 00:06:11,840
this area?

78
00:06:11,840 --> 00:06:21,160
Yes, I think you've set up the issues, which really are based on efficiency.

79
00:06:21,160 --> 00:06:23,200
So let's just make a few comparisons.

80
00:06:23,200 --> 00:06:32,640
So your brain runs on about 20 watts of power, and that should be compared to the enormous

81
00:06:32,640 --> 00:06:36,360
amount of power right now that's going into deep learning in the cloud.

82
00:06:36,360 --> 00:06:41,800
There's an article in today's paper that it's increasing at a phenomenal rate.

83
00:06:41,800 --> 00:06:48,040
I mean, it's not just it's a lot, but it keeps growing and it's been an effort to create

84
00:06:48,040 --> 00:06:52,320
special purpose machine learning chips, which of course are more efficient.

85
00:06:52,320 --> 00:06:58,880
But it doesn't even come close to the efficiency that nature has achieved with regard to how

86
00:06:58,880 --> 00:07:04,640
the brain is able to accomplish all it does in real time with so little power.

87
00:07:04,640 --> 00:07:14,240
And the real secret turns out to be to use signaling, electrical signaling very sparingly.

88
00:07:14,240 --> 00:07:16,680
So it's very sparse.

89
00:07:16,680 --> 00:07:25,160
But they able to encode information in a way that is highly able to represent the information

90
00:07:25,160 --> 00:07:29,080
but also to compute with spikes.

91
00:07:29,080 --> 00:07:34,320
And with the spike, a spike is an all-in-one event.

92
00:07:34,320 --> 00:07:37,240
It's technically called an action potential.

93
00:07:37,240 --> 00:07:38,560
And we know a lot about it.

94
00:07:38,560 --> 00:07:44,920
We know the biophysical mechanisms underlying it last for about a millisecond.

95
00:07:44,920 --> 00:07:54,640
It travels down nerves at variable speed depending on the diameter of the axon, the nerve,

96
00:07:54,640 --> 00:07:56,400
bundle.

97
00:07:56,400 --> 00:07:59,960
And it's relatively slow by computer standards.

98
00:07:59,960 --> 00:08:05,440
So you have signaling within chips at something close to the speed of light.

99
00:08:05,440 --> 00:08:14,760
But if you look at a nerve, the typical speeds are on the order of meters per second.

100
00:08:14,760 --> 00:08:21,400
So you might say, gee, can't neurons do better?

101
00:08:21,400 --> 00:08:29,920
Well, in fact, one of the fastest nerves that's been studied is that the giant axon of

102
00:08:29,920 --> 00:08:37,400
the squid that's used for when the squid has to flee is an escape response.

103
00:08:37,400 --> 00:08:40,840
And this nerve is a millimeter in diameter.

104
00:08:40,840 --> 00:08:45,120
And in fact, when the anonymous looked at it, they mistook it for a blood vessel.

105
00:08:45,120 --> 00:08:56,000
But later, the neurophysiologist, Alan Hodgkin and Huxley, Hugh Huxley, were able to use

106
00:08:56,000 --> 00:09:00,120
this as a model system for understanding the mechanisms.

107
00:09:00,120 --> 00:09:04,280
And they wrote down a set of equations, how are the Hodgkin Huxley equations, which have

108
00:09:04,280 --> 00:09:09,480
served as the foundation for all of signaling, electrical signaling, many other types of

109
00:09:09,480 --> 00:09:14,000
channels and pathways that have been built on top of that.

110
00:09:14,000 --> 00:09:16,280
So that really was foundational.

111
00:09:16,280 --> 00:09:20,480
But now the question is, how do you compute with those spikes?

112
00:09:20,480 --> 00:09:25,000
And that's really an interesting problem.

113
00:09:25,000 --> 00:09:26,920
Let me jump in with a quick question.

114
00:09:26,920 --> 00:09:35,000
When we're talking about these spikes, are they fundamentally digital in nature, a spike

115
00:09:35,000 --> 00:09:37,520
occurred, or a spike didn't occur?

116
00:09:37,520 --> 00:09:43,680
Or are there other characteristics that may be important, at least biologically, such

117
00:09:43,680 --> 00:09:46,960
as the amplitude of the spike or the duration of the spike?

118
00:09:46,960 --> 00:09:50,920
Or I can imagine there might be others, some intensity.

119
00:09:50,920 --> 00:09:58,320
How do we characterize these spikes, and what do we think might be part of the information

120
00:09:58,320 --> 00:10:00,440
that's transmitted with them?

121
00:10:00,440 --> 00:10:01,440
Right.

122
00:10:01,440 --> 00:10:07,520
Well, all of the above, certainly, they're all or none, that's the characteristic of

123
00:10:07,520 --> 00:10:08,520
a spike.

124
00:10:08,520 --> 00:10:11,200
However, they come in many different sizes and shapes.

125
00:10:11,200 --> 00:10:16,600
In fact, the fast sodium spike I was talking about on the millisecond time scale has

126
00:10:16,600 --> 00:10:23,160
variable width, also a calcium spike, which is much broader, and in fact, your heart uses

127
00:10:23,160 --> 00:10:30,480
the calcium spike hundreds of milliseconds long in order to maintain a heartbeat.

128
00:10:30,480 --> 00:10:35,040
But the first approximation that you should think of it, yes, it is a digital signal.

129
00:10:35,040 --> 00:10:37,120
There's either a signal there or not.

130
00:10:37,120 --> 00:10:41,600
But it occurs at an analog time, because the spiking is asynchronous.

131
00:10:41,600 --> 00:10:45,320
There is no clock, master clock in the brain.

132
00:10:45,320 --> 00:10:50,120
There may be local synchronization that takes place in small circuits.

133
00:10:50,120 --> 00:10:54,680
But the idea, though, is that, and this is something that's actually a very powerful way

134
00:10:54,680 --> 00:11:01,040
to think about computing, which now that, for example, machine learning chips are being

135
00:11:01,040 --> 00:11:02,040
developed.

136
00:11:02,040 --> 00:11:07,320
There's 100 startup companies out there right now that are all vying for this big market

137
00:11:07,320 --> 00:11:10,320
that people see.

138
00:11:10,320 --> 00:11:17,640
And once you've gone to an asynchronous system, it just makes designing chips much more easy

139
00:11:17,640 --> 00:11:23,840
in a sense that you no longer have to have a signal that is transmitted all over the

140
00:11:23,840 --> 00:11:31,000
chip that allows you to get the transistor on and off.

141
00:11:31,000 --> 00:11:34,160
But there are other things, too, which are very important.

142
00:11:34,160 --> 00:11:39,240
It's not just the spike itself, but what happens to the spike when it reaches the synapse.

143
00:11:39,240 --> 00:11:45,840
And there, there's an even more complex dynamical system that controls the release of neurotransmitter.

144
00:11:45,840 --> 00:11:53,320
And depending on the rate of firing of these spikes and depending on the signaling to

145
00:11:53,320 --> 00:12:02,720
the postsynaptic cell, you have a very wide range of not just strengths, but temporal modulation

146
00:12:02,720 --> 00:12:05,320
of that signal.

147
00:12:05,320 --> 00:12:07,400
So, you know, you elaborate on that bit a bit?

148
00:12:07,400 --> 00:12:12,440
Yeah, okay, so, you know, in neural network models, we have learning algorithms, and the

149
00:12:12,440 --> 00:12:17,560
idea here is that these are slow changes in the weights and they're permanent, but that

150
00:12:17,560 --> 00:12:20,480
is to say they'll last for, you know, many days.

151
00:12:20,480 --> 00:12:26,360
But there are the short-term synaptic plasticity mechanisms that occur on less than a second

152
00:12:26,360 --> 00:12:27,520
scale.

153
00:12:27,520 --> 00:12:32,800
For example, if you have a burst of firing of a bunch of spikes at a high rate, then the

154
00:12:32,800 --> 00:12:38,480
strength of the synapse facilitates, you know, it could double in size, which means that

155
00:12:38,480 --> 00:12:45,880
a burst of spikes has actually has much more impact than an isolated spike or a same number

156
00:12:45,880 --> 00:12:48,800
of spikes that are spaced in time.

157
00:12:48,800 --> 00:12:58,840
And this is an example of a mechanism which is very important for timing and also for regulating

158
00:12:58,840 --> 00:13:05,840
the flow of information, which isn't incorporated right now in traditional neural network models

159
00:13:05,840 --> 00:13:11,840
that use graded activity rather than spiking activity.

160
00:13:11,840 --> 00:13:19,400
So just to try to capture that, it sounds like one first order difference between the way

161
00:13:19,400 --> 00:13:26,520
the biological systems work and the neural network, artificial neural networks are work

162
00:13:26,520 --> 00:13:34,080
is that in the latter, there's no notion of kind of this, even a dual time scale, kind

163
00:13:34,080 --> 00:13:42,160
of a short-term accumulation effect in changes to inputs versus kind of a long-term adjustment

164
00:13:42,160 --> 00:13:43,160
of weights.

165
00:13:43,160 --> 00:13:44,160
Right.

166
00:13:44,160 --> 00:13:49,480
Actually, Jeff Hinton has a paper, very old paper, probably going back more than 20 years,

167
00:13:49,480 --> 00:13:55,360
where he showed that the short-term changes actually could be helpful for networks that

168
00:13:55,360 --> 00:13:57,320
have dynamical outputs.

169
00:13:57,320 --> 00:14:05,440
By the way, there's another very important degree of freedom here that we, as we know,

170
00:14:05,440 --> 00:14:12,000
is used at various places in the brain, and I actually think it adds a computational,

171
00:14:12,000 --> 00:14:14,480
a very powerful computational dimension.

172
00:14:14,480 --> 00:14:18,600
So that has to do with the relative timing of spikes.

173
00:14:18,600 --> 00:14:24,440
So what's known, this is a mechanism for synaptic plasticity, which depends on spike timing.

174
00:14:24,440 --> 00:14:31,040
It's known that if the spike coming into a neuron occurs within a very brief 10 millisecond

175
00:14:31,040 --> 00:14:39,480
window before the output neuron spikes, pre-before post, and if that's repeated at 10 hertz or

176
00:14:39,480 --> 00:14:44,400
above, that that will increase the strength of the synapse, long-term potentiation.

177
00:14:44,400 --> 00:14:49,320
That means that it will increase in strength and will stay elevated for many hours.

178
00:14:49,320 --> 00:14:57,480
However, if you reverse the order of the two spikes so that the output neuron spikes

179
00:14:57,480 --> 00:15:05,600
before the synaptic input spikes, and you pair that at 10 hertz with a time window here

180
00:15:05,600 --> 00:15:11,400
from 10 to 50 milliseconds depending on the neuron, then that will decrease the strength

181
00:15:11,400 --> 00:15:14,640
of the synapse, and that's a long-term depression.

182
00:15:14,640 --> 00:15:21,640
So it means that the brain is able to use these relative times to regulate the neuron,

183
00:15:21,640 --> 00:15:29,400
the house of strength of a synapse is either increasing or decreasing it, and it can

184
00:15:29,400 --> 00:15:31,560
do that very, very rapidly.

185
00:15:31,560 --> 00:15:38,800
And if you think about it, having, there must be a discriminator sitting in the synapse

186
00:15:38,800 --> 00:15:44,880
that can, is literally able to tell the order of the pre-imposed synaptic activity within

187
00:15:44,880 --> 00:15:53,040
a few milliseconds, which is pretty good for biology, that's a very fast timescale.

188
00:15:53,040 --> 00:15:59,640
The conclusion that you just mentioned suggests that what we're talking about with these spikes

189
00:15:59,640 --> 00:16:06,880
and whether they're pre-imposed isn't kind of the result of, again, kind of some kind

190
00:16:06,880 --> 00:16:14,040
of internal accumulator, like some chemical thing where the spikes are coming in faster

191
00:16:14,040 --> 00:16:17,760
than they're going out, there's a build-up of something.

192
00:16:17,760 --> 00:16:24,560
It's more about the proximity of input and output timings relative to one another that

193
00:16:24,560 --> 00:16:33,600
isn't related to just thinking about the input and output of a bucket like a drain or something

194
00:16:33,600 --> 00:16:34,600
like that.

195
00:16:34,600 --> 00:16:42,040
Well, those are all good analogies, but the reality is that the synapse is a very complex

196
00:16:42,040 --> 00:16:49,800
biochemical machine that has components in small numbers, like there's, in the post-ynaptic

197
00:16:49,800 --> 00:16:56,680
site, for example, there's an area of very dense structure that shows up in the EM as it's

198
00:16:56,680 --> 00:17:02,360
kind of a black surface, the EM block with proteins, electron microscopy.

199
00:17:02,360 --> 00:17:08,680
This is a very high-resolution way of looking inside of cells, nanometer scale, and there's

200
00:17:08,680 --> 00:17:13,760
like 300 different proteins in that post-ynaptic density.

201
00:17:13,760 --> 00:17:22,040
They're all there to work, as you say, doing all of the functions that accumulating information,

202
00:17:22,040 --> 00:17:27,760
that's an integration step, but also keeping track of what's been happening over a longer

203
00:17:27,760 --> 00:17:35,520
time scale and through a downstream pathways can increase the size of the synapse through

204
00:17:35,520 --> 00:17:40,960
this potentiation mechanism that I was telling you about.

205
00:17:40,960 --> 00:17:48,040
People think of, in networks, as a weight, a single connection strength is one number,

206
00:17:48,040 --> 00:17:53,960
but the reality is, as I said, the synapse is a dynamical system with probably dozens

207
00:17:53,960 --> 00:18:00,240
of degrees of freedom, different timescales, and those are all there for a variety of reasons

208
00:18:00,240 --> 00:18:05,800
which have to do with being able to have what's called traces.

209
00:18:05,800 --> 00:18:09,080
You want to keep traces of something without permanently changing the strength.

210
00:18:09,080 --> 00:18:14,800
You want to keep track of things that have happened maybe over the last 10 minutes, and

211
00:18:14,800 --> 00:18:17,920
this actually comes up in reinforcement learning algorithms.

212
00:18:17,920 --> 00:18:22,600
This is Andy Bartow and Rich Sutton, developed a whole series of reinforcement algorithms

213
00:18:22,600 --> 00:18:29,560
that use trace conditioning, these mechanisms for keeping track of information within the

214
00:18:29,560 --> 00:18:33,320
synapse itself, so that you can make decisions later.

215
00:18:33,320 --> 00:18:42,680
Again, to kind of summarize thus far, there's work happening on the biological side to

216
00:18:42,680 --> 00:18:51,480
understand these neurons, and we've identified a whole set of phenomena, our characteristic

217
00:18:51,480 --> 00:19:01,200
of the way these systems work, including the timing of spikes and the duration of spikes

218
00:19:01,200 --> 00:19:09,280
and frequency of spikes, and we have some sense of how they translate into behavior within

219
00:19:09,280 --> 00:19:17,800
the biological system, and then there's this whole other set of work and activity to

220
00:19:17,800 --> 00:19:23,280
try to replicate that on the computational side, and I say, and then there's this not

221
00:19:23,280 --> 00:19:31,120
to artificially separate the two, but let's maybe talk a little bit about the state of

222
00:19:31,120 --> 00:19:38,880
the R and major research directions on that other side, the replication or modeling of

223
00:19:38,880 --> 00:19:42,520
the biological systems on the computational side.

224
00:19:42,520 --> 00:19:50,520
Well, this is an area that is very active right now, that has to say there's a number

225
00:19:50,520 --> 00:19:57,280
of groups around the world who have recognized that if we can build deep learning networks

226
00:19:57,280 --> 00:20:05,800
of spiking units rather than these graded ones, then not only would there be a tremendous

227
00:20:05,800 --> 00:20:14,280
energy savings, but now you could use these deep networks in edge devices like your watch

228
00:20:14,280 --> 00:20:22,600
or sensors directly at the point where the information is coming in, and that would

229
00:20:22,600 --> 00:20:26,640
allow a tremendous amount of compression to occur, and as much more efficient in terms

230
00:20:26,640 --> 00:20:33,000
of just how to get the bandwidth, reduce the bandwidth that you're going to need to get

231
00:20:33,000 --> 00:20:36,800
the information into the internet.

232
00:20:36,800 --> 00:20:43,440
So my own group, over the last few years, has put some effort into being able to do

233
00:20:43,440 --> 00:20:47,040
stochastic gradient descent, which is the algorithm that's used for most deep learning

234
00:20:47,040 --> 00:20:53,240
networks for being able to adjust the weights, but to do that with spiking units rather

235
00:20:53,240 --> 00:20:57,560
than graded units, and we've had some success.

236
00:20:57,560 --> 00:21:07,200
This is Ben Ha, who is a former graduate student of mine who's now working at IBM, but that

237
00:21:07,200 --> 00:21:14,640
looked very promising in a sense that we were able to generalize the algorithm so that

238
00:21:14,640 --> 00:21:17,000
it would be able to work near thresholds.

239
00:21:17,000 --> 00:21:21,440
See, the neurons have these very sharp thresholds where if you're below it, nothing happens,

240
00:21:21,440 --> 00:21:25,640
and as soon as you go above it, you get a spike, all in non-spike, but we showed that if

241
00:21:25,640 --> 00:21:33,000
you have a blurry region, a window in between those two states, that you could use it in

242
00:21:33,000 --> 00:21:36,800
an analog way in order to be able to compute gradients.

243
00:21:36,800 --> 00:21:38,320
So that was very exciting.

244
00:21:38,320 --> 00:21:41,440
To have that, it was a Neurip's paper a few years ago.

245
00:21:41,440 --> 00:21:48,600
If I can pause there with a few questions about that work, is that work, or even today,

246
00:21:48,600 --> 00:21:55,320
are we talking about a handful of, I guess I'm curious about the complexity of the

247
00:21:55,320 --> 00:22:01,000
systems that we're establishing, is this a couple of layers, a couple of neurons?

248
00:22:01,000 --> 00:22:06,000
Are we experimenting with deep systems?

249
00:22:06,000 --> 00:22:14,560
So that's kind of A, and then B, I'm assuming you're not doing this on new hardware by one

250
00:22:14,560 --> 00:22:22,000
of the hundred or so startups that's working in this area, but that you're using traditional

251
00:22:22,000 --> 00:22:31,240
clocked computing, are we talking about simulation-based experiments, or are you building custom

252
00:22:31,240 --> 00:22:38,640
hardware, or what's the kind of hardware at side of this?

253
00:22:38,640 --> 00:22:45,440
Right, well, my lab isn't a hardware lab, but we do collaborate with others, and the

254
00:22:45,440 --> 00:22:51,360
work I was talking about was all done with simulations with fully recurrent networks

255
00:22:51,360 --> 00:23:02,560
having sizes in the several hundred spiking units that were trained to do simple tasks.

256
00:23:02,560 --> 00:23:07,560
Simple in the sense that it's certainly not at the level of deep learning, but these

257
00:23:07,560 --> 00:23:13,400
are benchmark tasks that have been just to show that for one of the issues, and a very

258
00:23:13,400 --> 00:23:20,040
important one with recurrent network is whether you can take input and store it over some

259
00:23:20,040 --> 00:23:24,160
length of time, and then use that to make a decision when another input comes in, say

260
00:23:24,160 --> 00:23:31,800
a second or two later, and that's, we demonstrated that, so it's, it has a lot of the strengths

261
00:23:31,800 --> 00:23:38,680
of these recurrent neural networks that are used right now for language translation.

262
00:23:38,680 --> 00:23:44,440
Now that having been said, we still haven't scaled it up yet, in principle, it should

263
00:23:44,440 --> 00:23:48,920
be possible to have layers, multiple layers of these recurrent networks, but that's not

264
00:23:48,920 --> 00:23:54,360
something unfortunately been left before he could get to that point, but that's not

265
00:23:54,360 --> 00:23:55,920
the only approach.

266
00:23:55,920 --> 00:24:03,480
We have also recently with a graduate student taken another attack, and the idea here

267
00:24:03,480 --> 00:24:08,160
is that, hey, we already have ways of training up these recurrent networks with back propagation

268
00:24:08,160 --> 00:24:09,160
and time.

269
00:24:09,160 --> 00:24:16,640
Why not take one of them that already exists and convert it into a spiking network?

270
00:24:16,640 --> 00:24:19,400
And that's a difficult problem.

271
00:24:19,400 --> 00:24:25,880
Many people have tried to do this, and one typical approach was to say, okay, we'll just

272
00:24:25,880 --> 00:24:35,720
replace every graded unit with 100 spiking units, which then will have stochastic variability,

273
00:24:35,720 --> 00:24:43,320
but it will get the same message through with some degree of variability or noise.

274
00:24:43,320 --> 00:24:47,560
And yeah, if you have enough units, you can do that, but it's very, very expensive because

275
00:24:47,560 --> 00:24:51,440
you're just throwing away a tremendous number of units.

276
00:24:51,440 --> 00:25:00,760
So Robert Kim, who's a graduate student in my lab, came up with a really efficient and

277
00:25:00,760 --> 00:25:02,920
elegant solution to the problem.

278
00:25:02,920 --> 00:25:08,080
So here's what he did, and this is a paper that will be out very soon in the proceedings

279
00:25:08,080 --> 00:25:14,120
of the National Academy of Sciences, before you dive into the approach he took, I want

280
00:25:14,120 --> 00:25:22,440
to make sure that we understand the context so that we understand how important it is.

281
00:25:22,440 --> 00:25:29,360
This kind of assumption that for each of a traditional kind of artificial neuron, we

282
00:25:29,360 --> 00:25:32,960
would need hundreds of spiking units.

283
00:25:32,960 --> 00:25:37,960
Does that come from the idea, roughly, that if you've

284
00:25:37,960 --> 00:25:44,600
got a system that, let's say it's an eight-bit, it can handle eight-bit weights or inputs

285
00:25:44,600 --> 00:25:53,360
or is quantized in some way, and we need to represent that with a system that is essentially

286
00:25:53,360 --> 00:25:54,360
binary.

287
00:25:54,360 --> 00:26:01,600
We'll need many of those binary kind of spiking neurons or spiking units to achieve the

288
00:26:01,600 --> 00:26:08,720
same amount of information storage or flow as in the traditional graded neuron.

289
00:26:08,720 --> 00:26:15,480
Well, that would be a very direct digital solution, just to have each unit representing

290
00:26:15,480 --> 00:26:24,720
a different unit, to represent, for example, eight bits, you need eight units being on

291
00:26:24,720 --> 00:26:25,720
or off.

292
00:26:25,720 --> 00:26:30,520
But if you have spiking units that are asynchronous, you need a lot more because you're averaging

293
00:26:30,520 --> 00:26:36,200
over spikes, and you might need for eight bits, you may need, I'd have to calculate it,

294
00:26:36,200 --> 00:26:43,560
but something like maybe 25 or 50 in order to get, you reduce the noise by square to

295
00:26:43,560 --> 00:26:44,560
Venn.

296
00:26:44,560 --> 00:26:48,040
I'll elaborate on this a little bit more because there's a piece that I think is important

297
00:26:48,040 --> 00:26:55,640
here and not obvious, the averaging over spikes and that kind of driving this fan out

298
00:26:55,640 --> 00:26:57,240
and the number of spiking units.

299
00:26:57,240 --> 00:26:59,240
Why does that come about?

300
00:26:59,240 --> 00:27:06,720
Well, in fact, it's called a population code, and a lot of it was one of the early ideas

301
00:27:06,720 --> 00:27:12,680
in the neural modeling going back to Jack Cohen, which is that we have a lot of neurons,

302
00:27:12,680 --> 00:27:13,680
right?

303
00:27:13,680 --> 00:27:18,440
We have 100 billion, so you might think that you have a lot of units to spare, so it's

304
00:27:18,440 --> 00:27:19,440
redundancy.

305
00:27:19,440 --> 00:27:25,080
You can have the same signal being carried by 100 neurons.

306
00:27:25,080 --> 00:27:32,840
And then if you want to get an accurate estimate for an output, like for a motor neuron, then

307
00:27:32,840 --> 00:27:43,040
you just average over all those spikes, and one of the drawbacks of that approach is that

308
00:27:43,040 --> 00:27:50,600
if you look at how good the variance is, the variability in the estimate for the average,

309
00:27:50,600 --> 00:27:57,360
it goes down as 1 over n, and that means that if you want to reduce it by 10%, you've got

310
00:27:57,360 --> 00:27:59,120
to have 100 units.

311
00:27:59,120 --> 00:28:00,120
Got it.

312
00:28:00,120 --> 00:28:04,080
That's the problem that we're trying to overcome.

313
00:28:04,080 --> 00:28:10,320
By the way, I don't believe for a minute that the brain uses units so profilically.

314
00:28:10,320 --> 00:28:12,000
It just doesn't make any sense to me.

315
00:28:12,000 --> 00:28:16,560
It's just like throwing away tremendous amount of machinery.

316
00:28:16,560 --> 00:28:21,840
And so that's why Robert's solution to the problem, I think, is so elegant.

317
00:28:21,840 --> 00:28:29,520
What he showed was that you don't need to throw in a bunch of spiking units.

318
00:28:29,520 --> 00:28:36,480
You can get by with one spiking unit per one analog graded unit.

319
00:28:36,480 --> 00:28:42,040
But now here's the simple solution, which is that you have to decrease the strength of

320
00:28:42,040 --> 00:28:46,960
the weight, and typically by factor of 10.

321
00:28:46,960 --> 00:28:52,040
And what you find is that if you do this right and tune it up a little bit, you can get

322
00:28:52,040 --> 00:28:58,200
performance which is good, in some cases, a little better than the original network.

323
00:28:58,200 --> 00:29:05,760
And that is truly, from my perspective, it's revealing because it means that it is possible

324
00:29:05,760 --> 00:29:07,680
for the brain to compute with spikes.

325
00:29:07,680 --> 00:29:14,400
It can actually replace the very, the eight-bit kind of, and the throughput that it would

326
00:29:14,400 --> 00:29:16,560
need if you were just averaging.

327
00:29:16,560 --> 00:29:22,360
So in common deep learning, neural nets, you've mentioned gradient descent.

328
00:29:22,360 --> 00:29:29,160
You mentioned back prop, the core problem that we've overcome that allowed us to have

329
00:29:29,160 --> 00:29:35,400
the success we've seen with deep learning is this idea of diminishing and exploding

330
00:29:35,400 --> 00:29:46,000
gradients in these neural networks is do you get the same problem in when you've got networks

331
00:29:46,000 --> 00:29:50,360
of spiking units or is there an analogous kind of definitional problem that we need to

332
00:29:50,360 --> 00:29:51,360
figure out?

333
00:29:51,360 --> 00:29:52,360
Right.

334
00:29:52,360 --> 00:29:58,160
Well, you know, there have been mech ways to overcome the diminishing gradient.

335
00:29:58,160 --> 00:30:04,400
So we have various ways of being able to get the gradient using skip connections back

336
00:30:04,400 --> 00:30:11,600
down to the early layers and also by starting out with the right set of connections so that

337
00:30:11,600 --> 00:30:15,600
it has favorable properties for transmitting information back down.

338
00:30:15,600 --> 00:30:18,280
So we have the same things kind of work?

339
00:30:18,280 --> 00:30:22,800
We haven't done it yet, but that will certainly be our starting point too.

340
00:30:22,800 --> 00:30:25,400
We think that the same principles should apply.

341
00:30:25,400 --> 00:30:32,400
I think what we have already is a good indication that there's a great future ahead for spiking

342
00:30:32,400 --> 00:30:37,080
networks and this feeds into the hardware side, which is analog vealous eye chips that

343
00:30:37,080 --> 00:30:41,520
are now becoming very efficient.

344
00:30:41,520 --> 00:30:46,040
And there are many companies now that are beginning to explore this.

345
00:30:46,040 --> 00:30:51,440
You may know that Intel has a whole group which are neuromorphic engineering group that

346
00:30:51,440 --> 00:30:58,440
is built a chip that is of use of spiking units and also has implemented a lot of the

347
00:30:58,440 --> 00:31:03,520
other details I was telling you about, like short term plasticity, spiked time dependent

348
00:31:03,520 --> 00:31:04,880
plasticity.

349
00:31:04,880 --> 00:31:10,960
And so, you know, we have, we do have a platform now that we could take our simulations

350
00:31:10,960 --> 00:31:19,400
to and demonstrate that we get this great advantage in terms of energy and efficiency.

351
00:31:19,400 --> 00:31:28,520
And so, what would you say are the, is there a way to kind of characterize the major research

352
00:31:28,520 --> 00:31:35,200
problems or directions that folks are currently working on in the space?

353
00:31:35,200 --> 00:31:45,360
Right, I think that the, you know, the problem that we're facing now is architectural

354
00:31:45,360 --> 00:31:46,360
and systems.

355
00:31:46,360 --> 00:31:53,840
In other words, we can put together densely connect small, densely connected networks.

356
00:31:53,840 --> 00:32:00,680
And this is a problem that's faced by deep learning as well as the spiking version,

357
00:32:00,680 --> 00:32:07,240
which has to do with the fact that the biggest deep learning networks today have on the order

358
00:32:07,240 --> 00:32:13,360
of a billion weights, you know, thinking of as parameters, a billion parameters.

359
00:32:13,360 --> 00:32:20,200
Well, in a cubic millimeter of the cerebral cortex, which is what the deep learning emulates,

360
00:32:20,200 --> 00:32:25,240
in a single cubic millimeter, there's a billion synapses.

361
00:32:25,240 --> 00:32:36,800
And what that tells me is that the cortex has the capacity to create, you know, many thousands,

362
00:32:36,800 --> 00:32:40,160
maybe, you know, hundreds of thousands of deep learning networks.

363
00:32:40,160 --> 00:32:46,760
And now the question that hasn't yet been solved or confronted even is, how do you control

364
00:32:46,760 --> 00:32:50,960
the flow of information through a hundred thousand deep learning networks?

365
00:32:50,960 --> 00:32:51,960
Right, right.

366
00:32:51,960 --> 00:32:54,480
And that's a systems level problem.

367
00:32:54,480 --> 00:32:59,800
And, you know, that's a problem that nature solved a long time ago.

368
00:32:59,800 --> 00:33:03,720
And it's one that we're just beginning to come to grips with.

369
00:33:03,720 --> 00:33:11,040
Yeah, I mean, when you think about the kind of, you know, even the most basic kind of picture

370
00:33:11,040 --> 00:33:19,720
of neurons, you know, that you might, might see in a book or article for lay people, you

371
00:33:19,720 --> 00:33:25,840
know, it becomes clear that, or at least it, that system seems a lot less orderly than

372
00:33:25,840 --> 00:33:29,560
the things that we've put in place for deep learning, right?

373
00:33:29,560 --> 00:33:35,520
We've got these neurons that have many connections by directional.

374
00:33:35,520 --> 00:33:43,560
What do we know about the architecture of these neurons with regard to, I'm not articulating

375
00:33:43,560 --> 00:33:47,480
this question, but it feels like it, it feels like those systems are a lot more chaotic

376
00:33:47,480 --> 00:33:49,040
than the things that we're doing.

377
00:33:49,040 --> 00:33:54,560
And, you know, what kind of directions are, you know, do we think will allow us to build

378
00:33:54,560 --> 00:33:58,360
and manage systems with those many, that many degrees of freedom?

379
00:33:58,360 --> 00:33:59,920
Does that question make any sense?

380
00:33:59,920 --> 00:34:01,160
Yes, makes a lot of sense.

381
00:34:01,160 --> 00:34:08,840
In fact, you know, if you look at an electron microscopic image of the cortex, it looks

382
00:34:08,840 --> 00:34:09,920
like spaghetti.

383
00:34:09,920 --> 00:34:16,040
In other words, there's axons and dendrites and synapses all kind of mishmash together.

384
00:34:16,040 --> 00:34:22,440
But as we develop tools and techniques that allow us to dissect out the actual circuits,

385
00:34:22,440 --> 00:34:24,080
you know, the wiring.

386
00:34:24,080 --> 00:34:28,480
Also, not just local, but the long range connections.

387
00:34:28,480 --> 00:34:33,480
What we're discovering is that what looked like it was a mishmash is actually incredibly

388
00:34:33,480 --> 00:34:36,760
precisely put together.

389
00:34:36,760 --> 00:34:44,160
It's all done with molecular systems that are like lock and keys that allow one neuron

390
00:34:44,160 --> 00:34:46,960
to find another.

391
00:34:46,960 --> 00:34:52,640
And that can be over, you know, centimeters, you know, you have this little axon that's

392
00:34:52,640 --> 00:34:59,160
traveling over many centimeters and has to, it's like finding, it's, you know, going from

393
00:34:59,160 --> 00:35:05,160
San Diego and having a little string going up to L.A. and finding a particular address

394
00:35:05,160 --> 00:35:06,160
up in L.A.

395
00:35:06,160 --> 00:35:09,320
I mean, that, that's the level of precision with which the brain is put together.

396
00:35:09,320 --> 00:35:12,560
This is an incredible device we have.

397
00:35:12,560 --> 00:35:19,640
And we will know very soon, sometime next year, Clay Reed, who's at the Allen Institute

398
00:35:19,640 --> 00:35:22,480
for Brain Science, is going to,

399
00:35:22,480 --> 00:35:26,800
you know, announce a connectomic reconstruction.

400
00:35:26,800 --> 00:35:33,080
This is a tour de force because this is something that requires like a petabyte of data

401
00:35:33,080 --> 00:35:37,960
to be computationally stitched together.

402
00:35:37,960 --> 00:35:42,560
But he'll be able to have the entire wiring diagram for a cubic millimeter of cortex.

403
00:35:42,560 --> 00:35:47,160
And as I said before, this contains about a billion synapses and about a hundred thousand

404
00:35:47,160 --> 00:35:49,880
pieces of a hundred thousand neurons.

405
00:35:49,880 --> 00:35:56,080
So we're, you know, we're reaching at a point now where we will have real detailed ideas

406
00:35:56,080 --> 00:36:03,680
for what's the real complexity of these neural circuits.

407
00:36:03,680 --> 00:36:10,280
What makes it, you know, the brain, I think, powerful is that it's not, it's not the case

408
00:36:10,280 --> 00:36:14,920
like they are in deep learning networks where the units are more or less the same, you

409
00:36:14,920 --> 00:36:19,520
know, with different parameters, but more or less the same input output and so forth.

410
00:36:19,520 --> 00:36:25,240
But the, there's hundreds, in fact, thousands of different types of neurons, specialized

411
00:36:25,240 --> 00:36:26,240
neurons.

412
00:36:26,240 --> 00:36:32,680
There's just within inhibitory neurons, there's about 20 different types that have separate

413
00:36:32,680 --> 00:36:37,840
functions and are integrated into a circuit with a great precision.

414
00:36:37,840 --> 00:36:43,720
And so nature has had much more time to evolve and optimize the circuit for the particular

415
00:36:43,720 --> 00:36:45,320
function that it has.

416
00:36:45,320 --> 00:36:47,320
And that's different, different parts of the brain.

417
00:36:47,320 --> 00:36:53,240
The cortex has a different circuit from the, for example, another visual area called

418
00:36:53,240 --> 00:36:58,480
the superior colloculus, which is used in lower vertebrates for their visual system.

419
00:36:58,480 --> 00:37:02,720
And there are hundreds of brain areas, each of which has a different type of neuron and

420
00:37:02,720 --> 00:37:03,880
type of circuit.

421
00:37:03,880 --> 00:37:06,880
So this is a very highly evolved system.

422
00:37:06,880 --> 00:37:08,360
Right now we're at the very beginning.

423
00:37:08,360 --> 00:37:12,560
In fact, I think you could compare where we are now, you know, the deep learning networks

424
00:37:12,560 --> 00:37:17,200
where the right brothers were back in 1903 when they had their first flight, right?

425
00:37:17,200 --> 00:37:24,080
It was a proof of principle, but it was far, far away from where we end up today.

426
00:37:24,080 --> 00:37:29,360
There are a couple of papers that I wanted to make sure that we covered.

427
00:37:29,360 --> 00:37:35,080
One of those was, it's called a simple framework for constructing functional spiking RNNs.

428
00:37:35,080 --> 00:37:40,640
I feel like we talked about some of that stuff, but did we talk about this paper, the key

429
00:37:40,640 --> 00:37:41,640
results of this paper?

430
00:37:41,640 --> 00:37:43,360
Is this one of the ones that you mentioned?

431
00:37:43,360 --> 00:37:49,800
It's a foundational paper for this new method for replacing graded units with spiking units,

432
00:37:49,800 --> 00:37:59,360
but we went through a very millions and millions of simulations in order to pin down the robustness.

433
00:37:59,360 --> 00:38:05,960
I mean, how many networks, you know, when you put them together will work as advertised

434
00:38:05,960 --> 00:38:10,880
and it turns out to be a very high percentage, but also varying a lot of the parameters.

435
00:38:10,880 --> 00:38:14,000
And so this is something you do when you just get something, you know, you have to prove

436
00:38:14,000 --> 00:38:15,480
that it actually works.

437
00:38:15,480 --> 00:38:21,560
But now what we've done is to a paper that we're just preparing is to apply that to much

438
00:38:21,560 --> 00:38:28,120
more complex problems and also compare it to recordings from neurons in different parts

439
00:38:28,120 --> 00:38:29,520
of the cortex.

440
00:38:29,520 --> 00:38:34,440
And what we're finding is something that is happening not just in our lab, but many other places

441
00:38:34,440 --> 00:38:39,920
in the world like Jim DeCarlo at MIT is that when you train up one of these networks,

442
00:38:39,920 --> 00:38:43,760
either deep learning for the visual system or recurrent networks, which is what we're

443
00:38:43,760 --> 00:38:48,920
studying here, which is relevant for the prefrontal cortex, what you find is that the properties

444
00:38:48,920 --> 00:38:56,840
of the units in these networks are phenomenally similar, statistically similar to the recordings

445
00:38:56,840 --> 00:39:04,040
that are made from the brains of monkeys and other species that are solving specific

446
00:39:04,040 --> 00:39:11,160
problems, visual recognition problems or memory problems.

447
00:39:11,160 --> 00:39:15,920
So this is really exciting because it means that there's this is very close conversions

448
00:39:15,920 --> 00:39:22,520
that's occurring between neuroscience on one hand and machine learning and deep learning

449
00:39:22,520 --> 00:39:29,040
on the other hand, which I think is really going to be very, you know, the interaction

450
00:39:29,040 --> 00:39:37,040
the synergies, the fantastic opportunities that are opening up now for the first time in

451
00:39:37,040 --> 00:39:44,040
AI that are going to be sending, you know, information and talent back and forth.

452
00:39:44,040 --> 00:39:50,280
And this is, there's been a couple dozen AI and neuroscience meetings that I've been

453
00:39:50,280 --> 00:39:55,040
to a few of them, but there are many others, you know, I think that there's going to be

454
00:39:55,040 --> 00:40:00,640
a career path here for other people who have an interest in this convergence that's going

455
00:40:00,640 --> 00:40:01,960
on.

456
00:40:01,960 --> 00:40:10,320
And then you've got another couple of collaborations that are focused on this idea of the

457
00:40:10,320 --> 00:40:16,760
application of spiking neural networks to sensory motor control and kind of this, what

458
00:40:16,760 --> 00:40:19,200
you call a sweet spot.

459
00:40:19,200 --> 00:40:21,600
And I guess there's a tradeoff between speed and accuracy.

460
00:40:21,600 --> 00:40:23,360
Can you talk a little bit about that work?

461
00:40:23,360 --> 00:40:30,440
Yes, this is a collaboration with John Doyle, who's a control theorist at Caltech.

462
00:40:30,440 --> 00:40:40,000
And we're looking at the problem of how animals are able to be both fast and accurate, despite

463
00:40:40,000 --> 00:40:49,080
the fact that as I was saying earlier, axons are very limited either they're very fast

464
00:40:49,080 --> 00:40:54,920
but very inaccurate because they take up a lot of space and you can only pump so many spikes

465
00:40:54,920 --> 00:41:01,680
down them or if you have very thin axons like in the alfactory bulb where receptors coming

466
00:41:01,680 --> 00:41:05,680
in have very, very small caliber.

467
00:41:05,680 --> 00:41:10,320
So you have, but you have a hundred million of them and they're very, very, very slow.

468
00:41:10,320 --> 00:41:13,000
So they're very accurate but very, very, very slow.

469
00:41:13,000 --> 00:41:16,760
And the visual system itself, there's a time to leave about a hundred milliseconds.

470
00:41:16,760 --> 00:41:21,160
So you have these built-in limitations in the hardware.

471
00:41:21,160 --> 00:41:28,280
But how is it that you can, for example, mountain bike down a mountain side where you're getting

472
00:41:28,280 --> 00:41:34,000
jostled on a very fast timescale and you have to maintain your balance and at the same

473
00:41:34,000 --> 00:41:45,200
time, you have to navigate down a very winding and perhaps dangerous trail that, and you

474
00:41:45,200 --> 00:41:49,880
know, keep the plant, you have to plan ahead as well as respond to things that are happening.

475
00:41:49,880 --> 00:41:55,280
So in any case, we've developed a theoretical model that can accomplish that and we have

476
00:41:55,280 --> 00:41:56,280
a game.

477
00:41:56,280 --> 00:42:01,680
It's a driving game but it has a lot of the elements of mountain biking in terms of the fast

478
00:42:01,680 --> 00:42:07,240
timescales with jitter of the wheel and also planning ahead the path.

479
00:42:07,240 --> 00:42:13,640
And what we've uncovered in developing the model is something that we call the diversity

480
00:42:13,640 --> 00:42:16,160
enabled sweet spot.

481
00:42:16,160 --> 00:42:17,160
So what does that mean?

482
00:42:17,160 --> 00:42:20,240
First of all, diversity is something we're all familiar with.

483
00:42:20,240 --> 00:42:28,520
You have a very wide range of axon diameters that you see in the brain.

484
00:42:28,520 --> 00:42:36,680
And the question is, can you, if you have the right combination, can you incorporate

485
00:42:36,680 --> 00:42:42,760
them into a control model that takes into account two things, signaling right and speed

486
00:42:42,760 --> 00:42:44,480
and optimize that?

487
00:42:44,480 --> 00:42:46,960
And that's the speed accuracy trade-off.

488
00:42:46,960 --> 00:42:54,560
And what we showed is that once you set up that system, you can reproduce one of the most

489
00:42:54,560 --> 00:43:01,280
celebrated speed accuracy trade-offs in the motor control literature called, this is

490
00:43:01,280 --> 00:43:10,320
something that goes back, you know, 50 years, called FIT's law, if ITTS fits law.

491
00:43:10,320 --> 00:43:17,360
And it's a logarithmic law and it's very, very, a general trade-off between the accuracy

492
00:43:17,360 --> 00:43:19,160
and the speed.

493
00:43:19,160 --> 00:43:24,240
And we've shown now that mathematically and politically, we can achieve that with the

494
00:43:24,240 --> 00:43:28,040
kind of diversity of hardware that's seen in the brain.

495
00:43:28,040 --> 00:43:29,640
Now this is a general principle.

496
00:43:29,640 --> 00:43:36,240
In fact, these logarithmic laws that, like FIT's law, are found throughout sensory and

497
00:43:36,240 --> 00:43:37,240
motor systems.

498
00:43:37,240 --> 00:43:42,840
You know, this is a FECKNERS law and vision, for example, sensory systems.

499
00:43:42,840 --> 00:43:50,160
And we think that not just biology, but we think that a lot of engineered control systems

500
00:43:50,160 --> 00:43:52,560
can benefit from this principle.

501
00:43:52,560 --> 00:43:53,560
Interesting.

502
00:43:53,560 --> 00:43:54,560
Interesting.

503
00:43:54,560 --> 00:44:00,520
So this idea of a speed accuracy trade-off is something that's been well studied in

504
00:44:00,520 --> 00:44:08,440
biology and has resulted in a number of laws, like FIT's laws, that kind of govern the

505
00:44:08,440 --> 00:44:12,880
way we see this trade-off in biological systems.

506
00:44:12,880 --> 00:44:22,280
And you've been able to kind of recreate that using diversity as your control parameter,

507
00:44:22,280 --> 00:44:23,280
if you will.

508
00:44:23,280 --> 00:44:24,280
Exactly.

509
00:44:24,280 --> 00:44:25,280
Exactly.

510
00:44:25,280 --> 00:44:31,760
This optimizing, the sweet spot, is optimizing those two different constraints.

511
00:44:31,760 --> 00:44:35,880
One of the constraints has to do with speed and the other one with accuracy, you know,

512
00:44:35,880 --> 00:44:39,520
the signaling, the accuracy.

513
00:44:39,520 --> 00:44:44,040
And, and by the way, one of the, for me, one of the satisfying parts was that this was

514
00:44:44,040 --> 00:44:49,200
a marriage of two important parts in engineering that are separate from each other.

515
00:44:49,200 --> 00:44:52,680
One of them is control theory, which is all about time delays.

516
00:44:52,680 --> 00:44:58,800
Very rarely do they worry about the signaling pathways because they're using digital logic

517
00:44:58,800 --> 00:45:00,040
and so forth.

518
00:45:00,040 --> 00:45:04,720
And then on the other hand, there's information theory, which is all about information and

519
00:45:04,720 --> 00:45:08,320
how much information you can get through a channel.

520
00:45:08,320 --> 00:45:09,600
But they never worry about time delay.

521
00:45:09,600 --> 00:45:10,600
This is not interesting.

522
00:45:10,600 --> 00:45:15,880
So you have to do extremes and we put the two together and we find this beautiful sweet

523
00:45:15,880 --> 00:45:16,880
spot.

524
00:45:16,880 --> 00:45:17,880
Awesome.

525
00:45:17,880 --> 00:45:18,880
Awesome.

526
00:45:18,880 --> 00:45:23,200
So before we go, one of the things that you mentioned, as we were chatting before we

527
00:45:23,200 --> 00:45:29,800
started the interview was that you are one of the founders of what sounds like a really

528
00:45:29,800 --> 00:45:33,600
interesting workshop focused on neuromorphic engineering.

529
00:45:33,600 --> 00:45:39,320
Can you talk a little bit about the field and the workshop and what you're up to there?

530
00:45:39,320 --> 00:45:40,640
Right.

531
00:45:40,640 --> 00:45:49,440
So I was a visiting professor at Caltech back in the 80s or actually it was a fair trial

532
00:45:49,440 --> 00:45:53,040
this thing was scholar and was actually in the 90s, early 90s.

533
00:45:53,040 --> 00:45:57,880
And I used to go to a Carver Meads lab meetings and I was fascinated.

534
00:45:57,880 --> 00:46:05,840
This is an error when he created the first, you know, vision chip that was able to replicate

535
00:46:05,840 --> 00:46:10,440
some of the things that happened in the retina with asynchronous spiking coming out.

536
00:46:10,440 --> 00:46:14,600
And a cochlear chip for auditory processing.

537
00:46:14,600 --> 00:46:20,560
And this turned out to be a kind of a seed.

538
00:46:20,560 --> 00:46:27,680
He published a book around that era on analog VLSI neural systems, which really started

539
00:46:27,680 --> 00:46:33,160
a whole new branch of analog VLSI design.

540
00:46:33,160 --> 00:46:37,560
And that his students went off to the four corners of the world, but wanted to continue

541
00:46:37,560 --> 00:46:43,000
meeting. So I helped organize an NSF sponsored workshop at Telluride.

542
00:46:43,000 --> 00:46:49,200
It has been meeting for the last 25 years during the first three weeks of July.

543
00:46:49,200 --> 00:46:50,680
And it's a real workshop.

544
00:46:50,680 --> 00:46:56,560
People go there, they bring equipment, they bring robots, they bring all sorts of devices

545
00:46:56,560 --> 00:46:58,960
and oscilloscopes and so forth.

546
00:46:58,960 --> 00:47:00,480
And they work on projects.

547
00:47:00,480 --> 00:47:05,200
We have about 50 students and about 50 faculty who give lectures.

548
00:47:05,200 --> 00:47:08,960
And it's just a wonderful atmosphere because if you've been to Telluride, you're up there

549
00:47:08,960 --> 00:47:14,960
in the mountains and you're kind of it's isolated, but it's a beautiful place outdoors

550
00:47:14,960 --> 00:47:15,960
in the summer.

551
00:47:15,960 --> 00:47:18,280
Now I know where your mountain biking references are coming from.

552
00:47:18,280 --> 00:47:19,280
Yes.

553
00:47:19,280 --> 00:47:25,200
Well, we do a lot of, I don't do personally a lot of biking, but I do a lot of hiking.

554
00:47:25,200 --> 00:47:29,920
But the spirit there is very intense and the students are basically there.

555
00:47:29,920 --> 00:47:33,760
They're not just learning, they're collaborating, they're creating new projects, they take

556
00:47:33,760 --> 00:47:39,160
them home with them, and it's created an international community, which I think is very vibrant

557
00:47:39,160 --> 00:47:43,520
and very, very exciting right now because it's become clear that Moore's law has come

558
00:47:43,520 --> 00:47:49,680
to an end in terms of how being able to reduce the line widths any further is already reaching

559
00:47:49,680 --> 00:47:56,480
the point where you have leakage and so forth that is becoming an energy problem.

560
00:47:56,480 --> 00:48:04,880
But this is having these chips which are incredibly power efficient because you're working not

561
00:48:04,880 --> 00:48:11,280
at saturation, but right at the beginning of the non-linear activation and you're dealing

562
00:48:11,280 --> 00:48:22,400
with microwatts rather than watts to be able to do a decision down at the level of a spike.

563
00:48:22,400 --> 00:48:27,000
So this is really, I think, ultimately this is going to be the technology that's going

564
00:48:27,000 --> 00:48:32,840
to be out there in robots someday because as you know, robots are also have to worry about

565
00:48:32,840 --> 00:48:33,840
power.

566
00:48:33,840 --> 00:48:40,120
They can't take a super computer around with them if you want them to perform properly.

567
00:48:40,120 --> 00:48:41,120
Awesome.

568
00:48:41,120 --> 00:48:46,920
Well, we will include a link to that workshop as well as the papers that we've discussed

569
00:48:46,920 --> 00:48:48,920
here in our show notes.

570
00:48:48,920 --> 00:48:53,720
Terri, thanks so much for taking the time to chat really, really interesting conversation.

571
00:48:53,720 --> 00:49:00,520
Well, thank you very much, I really enjoyed it.

572
00:49:00,520 --> 00:49:07,640
All right everyone, that's our show for today to learn more about this episode visit Twomolaii.com.

573
00:49:07,640 --> 00:49:12,560
Once again, if you missed Twomolcan or want to share what you learned with your team, be

574
00:49:12,560 --> 00:49:19,800
sure to visit twomolcan.com slash videos for more information about our video packages.

575
00:49:19,800 --> 00:49:46,560
As always, thanks so much for listening and catch you next time.

