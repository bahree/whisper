WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:31.360
I'm your host Sam Charrington.

00:31.360 --> 00:35.800
You may have listened to one or more of the shows from our AI and consumer electronic series

00:35.800 --> 00:36.800
last week.

00:36.800 --> 00:42.320
There's a ton of interesting work happening in that space, but the reality is that I came

00:42.320 --> 00:48.720
back from CES both excited and also somewhat disillusioned about personal AI.

00:48.720 --> 00:53.040
Don't get me wrong, there's a bunch of cool stuff coming for sure, but it's taking

00:53.040 --> 00:55.000
so long.

00:55.000 --> 00:59.800
In the meantime, the privacy sacrifices we're being asked to make for modest conveniences

00:59.800 --> 01:02.280
seem pretty steep at times.

01:02.280 --> 01:06.480
I want to know what you think about the state of personal AI.

01:06.480 --> 01:11.040
I really want to hear from listeners on their thoughts, experience and desires on the role

01:11.040 --> 01:16.160
AI is playing in your home and personal life, your favorite examples of home or personal

01:16.160 --> 01:17.360
AI.

01:17.360 --> 01:22.240
The home or personal AI that you really want to see in your lifetime, and just where

01:22.240 --> 01:30.120
you see this all going, please check out TwimbleAI.com slash my AI to share your thoughts.

01:30.120 --> 01:34.360
We've got some really great entries so far, and you can check them out on that page,

01:34.360 --> 01:38.160
but we're missing a very important one, yours.

01:38.160 --> 01:41.560
Let me know your thoughts, and you'll be automatically entered into the running for

01:41.560 --> 01:44.400
some great prizes.

01:44.400 --> 01:50.200
For today's show, I'm joined by Nialing Marosi, senior data science researcher at the Council

01:50.200 --> 01:56.320
for Scientific and Industrial Research, or CSIR, in Pretoria, South Africa.

01:56.320 --> 02:02.120
We discuss two major projects that Nialing is a part of at the CSIR, one a predictive

02:02.120 --> 02:07.760
policing use case which focused on understanding and preventing rhino poaching in Kruger National

02:07.760 --> 02:13.440
Park, and the other a healthcare use case which focuses on understanding the effects of

02:13.440 --> 02:18.640
a drug treatment that was causing pancreatic cancer in South Africans.

02:18.640 --> 02:23.480
Along the way, we talk about the challenges of data collection, data pipelines, and overcoming

02:23.480 --> 02:24.800
sparsity.

02:24.800 --> 02:28.720
This was a really interesting conversation that I'm sure you'll enjoy.

02:28.720 --> 02:30.040
Let's do it.

02:30.040 --> 02:36.320
Alright everyone, I am on the line with Nialing Marosi.

02:36.320 --> 02:42.880
Nialing is a senior data science researcher at the Council for Scientific and Industrial

02:42.880 --> 02:49.040
Research, or CSIR, in Pretoria, South Africa, and Nialing, welcome to this weekend machine

02:49.040 --> 02:50.760
learning and AI.

02:50.760 --> 02:51.760
Thank you.

02:51.760 --> 02:52.760
Thank you.

02:52.760 --> 02:56.040
I'm really happy to be on today.

02:56.040 --> 02:58.960
And I'm happy to have you on.

02:58.960 --> 03:06.360
I got a chance to hear your talk at the Black and AI workshop at Nips, and you are doing

03:06.360 --> 03:09.040
some really amazing work.

03:09.040 --> 03:14.080
And I'm looking forward to learning even more about it.

03:14.080 --> 03:19.400
But before we get into what you're up to nowadays, why don't you spend a little bit of time

03:19.400 --> 03:24.240
telling the audience about your background and how you got involved in data science and

03:24.240 --> 03:25.240
machine learning?

03:25.240 --> 03:35.720
Alright, so I am actually originally from Lesutu, but I did most of my university in

03:35.720 --> 03:40.000
the US, so I went to my Calista College for my undergraduate.

03:40.000 --> 03:46.200
I was going to be an econ major because all the cool kids were doing it, but I know

03:46.200 --> 03:49.760
and I've been distracted halfway through.

03:49.760 --> 03:57.640
So yes, in St Paul, Minnesota, I decided during my degree that I ought to know a little

03:57.640 --> 04:03.680
bit more about computing in order to be a really good economist, of course.

04:03.680 --> 04:06.840
But then the bug caught.

04:06.840 --> 04:08.400
I just couldn't stop.

04:08.400 --> 04:13.200
I took an AI class in undergrad, and I was taught by this really brilliant woman, Susan

04:13.200 --> 04:14.200
Fox.

04:14.200 --> 04:17.680
I'm completely plugging her in right now shamelessly.

04:17.680 --> 04:22.720
She was completely brilliant, and I was just wowed by it and the area.

04:22.720 --> 04:27.120
But generally, the whole reason I was into econ to even start with was because I was really

04:27.120 --> 04:29.200
obsessed with trying to understand things.

04:29.200 --> 04:31.240
Like, why do things happen the way they happen?

04:31.240 --> 04:33.040
Why do people do the things they do?

04:33.040 --> 04:37.560
And for what I, as far as I knew, economic theory was one of the best way to describe why

04:37.560 --> 04:39.680
people do the things they did.

04:39.680 --> 04:46.440
But then when I got into AI and the modeling of AI, and then later on, I went to, for my

04:46.440 --> 04:52.520
PhD, which is very unfinished, I went to University of Minnesota and I was doing machine learning.

04:52.520 --> 04:59.480
Then it was also the development of these models that can help you not only observe, which

04:59.480 --> 05:05.560
sometimes in econ, you observe, and then you plan back, but also try to model these things

05:05.560 --> 05:09.040
and try to extract these features that explain to you.

05:09.040 --> 05:14.320
And if you can, you know, in mechanical design, mechanism design, you know, the whole thing

05:14.320 --> 05:18.760
of like, if you can just tweak it a little bit, you can get the output you want, that really

05:18.760 --> 05:20.680
got me very interested.

05:20.680 --> 05:25.640
So overall, I will say I am a true student of liberal arts.

05:25.640 --> 05:31.440
So my machine learning is tainted by econ, is tainted by biology, and it's tainted

05:31.440 --> 05:33.520
by a couple of other things.

05:33.520 --> 05:37.520
So but I've always just wanted to know how things work the way they work, why they work,

05:37.520 --> 05:38.680
the way they work.

05:38.680 --> 05:39.760
And I love Paxons.

05:39.760 --> 05:43.320
I love just discovering what's embedded in a process.

05:43.320 --> 05:44.800
And yeah, that's that.

05:44.800 --> 05:46.320
Yeah, that's amazing.

05:46.320 --> 05:51.960
The more and the deeper I get into, you know, the machine learning AI and the kind

05:51.960 --> 05:57.880
of the opportunities around it, the more I am convinced that, you know, everyone, you

05:57.880 --> 06:03.240
know, we need people from a very broad cross section of backgrounds who understand

06:03.240 --> 06:09.360
this and are working on it and can kind of, you know, both, you know, bring their perspectives

06:09.360 --> 06:15.160
to it, but also apply it to, you know, their disciplines and I'll end doing that.

06:15.160 --> 06:19.040
Can we really advance this to where it needs to be?

06:19.040 --> 06:20.880
No, I agree with you.

06:20.880 --> 06:27.840
I actually think it's in the problem that the worth of these processes is.

06:27.840 --> 06:33.360
I mean, the mathematics can be really beautiful and understand this, the structures under.

06:33.360 --> 06:38.920
But when you sit in an area and you're able to dissect an area and actually apply it,

06:38.920 --> 06:44.480
I've always been drawn to that kind of machine learning, so very applied.

06:44.480 --> 06:46.920
I like seeing the results.

06:46.920 --> 06:47.920
What is CSIR?

06:47.920 --> 06:53.520
Oh, yeah, CSIR, so it's, I think in the US, we call it the government lab.

06:53.520 --> 06:54.520
Okay.

06:54.520 --> 06:55.520
National labs.

06:55.520 --> 06:57.320
We have a national lab, yeah.

06:57.320 --> 06:58.320
Yeah.

06:58.320 --> 06:59.320
Okay.

06:59.320 --> 07:00.320
Yeah.

07:00.320 --> 07:02.160
So it's just this campus and we've got different units.

07:02.160 --> 07:06.800
We've got nano-centile study, nano-particles and the applications, biosciences and these are

07:06.800 --> 07:08.360
the biologies, the wet labs.

07:08.360 --> 07:09.360
Okay.

07:09.360 --> 07:10.360
We've got security.

07:10.360 --> 07:16.080
We've got, so it's a bunch of research lab, national research labs and we serve both the

07:16.080 --> 07:18.800
government and industry.

07:18.800 --> 07:22.840
And academia, actually, sometimes.

07:22.840 --> 07:27.880
And so what are some of the types of projects that you get involved in there?

07:27.880 --> 07:38.200
Yeah, so going back to my all-ever-so-curious, I've been in, I know, but I do try to segment

07:38.200 --> 07:43.360
them, but I've been in a couple of projects and maybe just for today I'll talk about just

07:43.360 --> 07:44.360
the two of them.

07:44.360 --> 07:50.080
One that I'm currently working on and one that I just recently parted with a little bit.

07:50.080 --> 07:56.360
And so some of one of the projects that we worked with was an understanding rhino poaching.

07:56.360 --> 08:02.480
So I have a feeling a lot of people will be aware of this that there is a huge problem

08:02.480 --> 08:04.960
in rhino poaching.

08:04.960 --> 08:11.080
And so we were contracted by the South African park rangers who were the guys that police

08:11.080 --> 08:12.920
the parks in South Africa.

08:12.920 --> 08:20.000
And they contracted us to say, can you guys provide for us some model to understand how

08:20.000 --> 08:21.240
these poaching happens?

08:21.240 --> 08:26.640
And if there is any way that maybe we can have a sort of predictive system that we can

08:26.640 --> 08:30.600
work with, to just cut down on the search space.

08:30.600 --> 08:31.600
So we worked with them.

08:31.600 --> 08:37.480
We were contracted to go work at the Kruger National Park, which is a fairly big national

08:37.480 --> 08:38.480
park.

08:38.480 --> 08:39.480
It's the size of Israel.

08:39.480 --> 08:40.480
Yeah.

08:40.480 --> 08:41.480
Kruger.

08:41.480 --> 08:43.480
Yeah.

08:43.480 --> 08:45.440
It spans all the way into Mozambique.

08:45.440 --> 08:47.440
It's on the border with South Africa and Mozambique.

08:47.440 --> 08:48.920
It's fairly big.

08:48.920 --> 08:55.280
But we work with one of the units in the CSI heart that does security.

08:55.280 --> 09:01.360
And we just, we were building a model to sort of try to narrow down a probability distribution

09:01.360 --> 09:03.400
map over the land.

09:03.400 --> 09:07.680
So to say, you look at the different features there as in things like when was the last

09:07.680 --> 09:12.400
poaching, how far from water, what's the weather like, what's the moonlight like, how far

09:12.400 --> 09:16.640
from the road, and things like those or how dense is the forestry.

09:16.640 --> 09:20.640
And try to put all those features and see how much each one of them contributes to an

09:20.640 --> 09:26.080
area being very high that, you know, a rhino is going to be poached there.

09:26.080 --> 09:31.560
And by doing that, then, you know, maybe the parks can then be allocated there in areas

09:31.560 --> 09:35.000
that we suspect is going to be high poaching.

09:35.000 --> 09:41.440
Obviously, this is, this is a model that can get quite compromised to somebody knows how

09:41.440 --> 09:42.440
it works.

09:42.440 --> 09:46.480
Because then, you know, shifting resources from one area to the other.

09:46.480 --> 09:48.560
And so, you know, maybe that's a lot of time.

09:48.560 --> 09:50.600
But rhinos are fairly territorial.

09:50.600 --> 09:54.960
And so, like, the poachings are going to happen around where they are going to be.

09:54.960 --> 09:59.640
And so we studied those things like how they migrate and all of that kind of stuff.

09:59.640 --> 10:01.480
So that was a project that we did.

10:01.480 --> 10:03.640
It's currently running.

10:03.640 --> 10:11.000
And it ended some early this, this, oh, it's a new year in 2017 and March, 2017.

10:11.000 --> 10:12.000
Okay.

10:12.000 --> 10:13.000
So that was that.

10:13.000 --> 10:14.560
But currently, yes.

10:14.560 --> 10:15.560
You make that one.

10:15.560 --> 10:18.240
That project sounds so easy.

10:18.240 --> 10:24.240
But when you kind of rattle off some of the features of this model, it strikes me that

10:24.240 --> 10:26.920
data is coming from all over the place.

10:26.920 --> 10:29.200
Like lots of different data sources.

10:29.200 --> 10:33.600
Can you talk a little bit about the, you know, the kind of the pipeline.

10:33.600 --> 10:37.760
And the challenges associated with that particular project.

10:37.760 --> 10:38.760
Yeah.

10:38.760 --> 10:41.560
So we actually worked a lot with the experts.

10:41.560 --> 10:45.080
So as one of those models that, like, one was informed by data and the other one was

10:45.080 --> 10:50.040
informed by the experts to start off with, we built this thing where, as the ranges are

10:50.040 --> 10:52.040
patrolling, they can start to input data.

10:52.040 --> 10:53.040
Okay.

10:53.040 --> 10:57.280
So, for example, data about you can see some of the leftover food steps by maybe people

10:57.280 --> 10:58.760
that should not have been in the park.

10:58.760 --> 10:59.760
Okay.

10:59.760 --> 11:03.760
There will be some areas of the parks that are closed off, but also if they had been approaching,

11:03.760 --> 11:06.120
you can see like food steps towards there.

11:06.120 --> 11:11.920
And so like that would information that like a park range would, would, would input.

11:11.920 --> 11:14.600
But also the park does have sensors in there.

11:14.600 --> 11:20.720
And so the sensors would be another, you know, input, data input.

11:20.720 --> 11:28.560
The park we do have knowledge about where the water sources are and generally what, like,

11:28.560 --> 11:36.040
vegetation and what's the word, like, you know, the level, like, how steep it is, how mountain

11:36.040 --> 11:37.840
else it is and stuff like that.

11:37.840 --> 11:38.840
Okay.

11:38.840 --> 11:40.000
And like, how far from the road it is.

11:40.000 --> 11:44.520
So there was already some of that data that was there because obviously this is a very

11:44.520 --> 11:46.960
important area in South Africa.

11:46.960 --> 11:54.120
So that information was there, but that combined with literally the ranges just walking in the

11:54.120 --> 11:55.120
park.

11:55.120 --> 11:56.120
Okay.

11:56.120 --> 12:01.240
So something can be noted as the water source, but then the water is all gone if it hadn't

12:01.240 --> 12:04.760
been raining, things like those, you know, then they would correct it.

12:04.760 --> 12:11.240
So we were seriously learning and we actually have this as a, as it's continuously ingesting

12:11.240 --> 12:12.240
new data.

12:12.240 --> 12:18.920
So every day we get new data from, you know, the last night patrols or things like those.

12:18.920 --> 12:22.560
We also get data from helicopters that will fly over.

12:22.560 --> 12:23.560
Yeah.

12:23.560 --> 12:28.320
So you're right, it came from multiple sources and we just put it together.

12:28.320 --> 12:34.600
Not just, but so some of the problems that we run into here, one of the biggest problems

12:34.600 --> 12:39.840
actually that we ran into was the problem of statistics and the problem is that we would

12:39.840 --> 12:42.360
have a lot of spots.

12:42.360 --> 12:46.880
So we, we had very sparse data, it's a vast land.

12:46.880 --> 12:52.720
And so we will have a lot of areas where we hadn't seen any data points, right?

12:52.720 --> 12:56.400
We don't, we don't have any information on whether there had been a poaching or something

12:56.400 --> 12:57.400
like that.

12:57.400 --> 13:01.800
And we really could only predict based, you know, like everything else that there was

13:01.800 --> 13:03.640
no poaching.

13:03.640 --> 13:08.760
We had to also say whether there was no poaching because there can be a poaching there

13:08.760 --> 13:10.960
or it just hadn't occurred yet.

13:10.960 --> 13:11.960
Okay.

13:11.960 --> 13:12.960
Yeah.

13:12.960 --> 13:18.560
So that was, I think the spacity of the data was one of the things that was quite difficult

13:18.560 --> 13:22.360
when we're trying to generalize over the whole park.

13:22.360 --> 13:26.680
When you, you, you do see it change.

13:26.680 --> 13:29.840
We did see the patterns change over the years.

13:29.840 --> 13:34.320
So, you know, that's why I go back to that thing of saying, you know, just because you haven't

13:34.320 --> 13:37.680
seen a poaching happen in an area doesn't mean that it's not going to be the next area

13:37.680 --> 13:38.680
of interest.

13:38.680 --> 13:39.680
Right.

13:39.680 --> 13:40.680
Right.

13:40.680 --> 13:41.680
Yeah.

13:41.680 --> 13:46.640
How did you deal with attacking that or overcoming that sparsity issue?

13:46.640 --> 13:52.320
Well, we are, I don't know if we, this is cheating or what, but we, we did it.

13:52.320 --> 13:53.320
We did a lot of smoothing.

13:53.320 --> 13:55.320
So, we did a lot of things.

13:55.320 --> 13:56.320
Okay.

13:56.320 --> 14:00.960
It takes things out, but, you know what though, I have to say this.

14:00.960 --> 14:05.640
It turned out that it wasn't even the big problem with our motto.

14:05.640 --> 14:08.680
It seemed, it was pretty good.

14:08.680 --> 14:12.640
So we had cut up the park into Kilometre square grid.

14:12.640 --> 14:13.640
Okay.

14:13.640 --> 14:17.680
It's pretty good, but it turned out that even at the granularity of Kilometre square

14:17.680 --> 14:20.040
grid, it's still too difficult.

14:20.040 --> 14:24.720
Like a poaching can actually happen in this square where we said it would happen.

14:24.720 --> 14:27.160
And they will still not get the poachers.

14:27.160 --> 14:28.160
Ah, okay.

14:28.160 --> 14:30.160
And so it has to make it bigger.

14:30.160 --> 14:31.160
So it has to make it bigger.

14:31.160 --> 14:32.160
That granularity was even too big.

14:32.160 --> 14:33.160
Ah, even that.

14:33.160 --> 14:38.560
And this is, I think, we were working, I think, overall, it's like very square Kilometres

14:38.560 --> 14:42.360
and we broke it down into Kilometres and even that wasn't, wasn't good enough in terms

14:42.360 --> 14:47.560
of truly pinpointing this in order to make it effective enough.

14:47.560 --> 14:51.680
So I, you know, it's one of those where you're like, that's, I mean, sometimes it worked,

14:51.680 --> 14:58.120
but then it was, that part of it was a bit difficult because it's like, oh, you know, you were

14:58.120 --> 15:06.480
so close and our model, certainly, took that into effect because for us, our model punished

15:06.480 --> 15:09.160
a lot more if we missed the poaching, right?

15:09.160 --> 15:10.160
Right.

15:10.160 --> 15:14.360
And if you say there's going to be a poaching and the poaching doesn't happen.

15:14.360 --> 15:17.480
So those are some of the things that we had to take care of.

15:17.480 --> 15:22.920
And like, you know, making sure that the cost truly reflects the outcome that we want.

15:22.920 --> 15:30.080
And was the, you talked about the granularity in terms of the area, but what was the granularity

15:30.080 --> 15:32.000
in terms of time?

15:32.000 --> 15:38.640
Like how did you, did you, were you trying to predict that a poaching might happen in

15:38.640 --> 15:41.280
a given day or week or month?

15:41.280 --> 15:42.280
It was a day.

15:42.280 --> 15:43.280
Okay.

15:43.280 --> 15:48.080
And we were getting updated data every day and so the predictions were daily within

15:48.080 --> 15:49.080
you data.

15:49.080 --> 15:50.400
Yeah.

15:50.400 --> 15:58.240
And did you find that the predictions in terms of area very dramatically day to day or

15:58.240 --> 16:01.120
were they relatively static?

16:01.120 --> 16:05.920
Yeah, the shifts would take a little bit longer.

16:05.920 --> 16:10.520
So the migration pattern in terms of where the poachings would happen would actually shift

16:10.520 --> 16:14.960
a little bit like we take multiple, multiple days to actually move.

16:14.960 --> 16:17.440
But like I said, that's the problem.

16:17.440 --> 16:21.160
And if you say, you know, it's going to happen in this grid and then like next, it's going

16:21.160 --> 16:26.920
to happen in the next grid or, you know, it was still around the same area.

16:26.920 --> 16:30.680
So the policy wasn't as bad.

16:30.680 --> 16:34.280
But once again, it's the limited resources that the park rangers have.

16:34.280 --> 16:36.040
It's the danger of the job.

16:36.040 --> 16:37.040
Right.

16:37.040 --> 16:38.040
You can't just complain side, right?

16:38.040 --> 16:41.280
I mean, just because you are there doesn't mean that they're going to stop poaching.

16:41.280 --> 16:42.280
Right.

16:42.280 --> 16:43.280
Yeah.

16:43.280 --> 16:48.760
And so there were some of those things that actually, you know, really complicated the problem.

16:48.760 --> 16:49.760
But you know what?

16:49.760 --> 16:50.760
I have to say this.

16:50.760 --> 16:53.120
And maybe there's a little bit of a plug.

16:53.120 --> 16:55.800
It was, it was very interesting work.

16:55.800 --> 16:57.120
It was very useful work.

16:57.120 --> 17:00.400
And if there's people, I know there's work like this happening in Kenya.

17:00.400 --> 17:03.840
The groups that are doing the same thing around poaching in Kenya.

17:03.840 --> 17:07.440
And you know, it's one of those things that, you know, it just needs, maybe needs more

17:07.440 --> 17:14.440
men power because it's, it's the only way to truly beat it because it's a social problem

17:14.440 --> 17:16.560
as long as the incentives are there.

17:16.560 --> 17:17.560
Right.

17:17.560 --> 17:21.880
I mean, definitely that gets made by poaching is an offer somebody to risk their life and

17:21.880 --> 17:25.240
go to jail and or what jail, right?

17:25.240 --> 17:26.680
So that's the, that's the thing.

17:26.680 --> 17:30.720
That's why I'm saying like, even when we made it fairly difficult, there would still

17:30.720 --> 17:32.720
be occurrences.

17:32.720 --> 17:33.720
Right.

17:33.720 --> 17:37.160
And and it's mostly because of the geographical space.

17:37.160 --> 17:42.920
So when this model runs in smaller spaces, so there were privately owned firms around

17:42.920 --> 17:43.920
there.

17:43.920 --> 17:44.920
And those are not as big.

17:44.920 --> 17:49.880
And their problem there wasn't as bad because, you know, they're managing a smaller space.

17:49.880 --> 17:54.400
But given how big the space is, given the incentives, given that this is a project that

17:54.400 --> 18:00.160
goes between two countries, you know, it gets very difficult to pull this.

18:00.160 --> 18:01.160
Right.

18:01.160 --> 18:07.320
We lend a lot and the South African park rangers are still using the two.

18:07.320 --> 18:09.200
So they are still getting some value for it.

18:09.200 --> 18:14.000
So I always say sometimes when you're working with Israel world problems, it's just cutting

18:14.000 --> 18:15.000
the search space.

18:15.000 --> 18:16.600
It's not finding the solution.

18:16.600 --> 18:18.320
It's cutting the search space.

18:18.320 --> 18:19.320
Mm hmm.

18:19.320 --> 18:20.320
Yeah.

18:20.320 --> 18:28.400
And in this particular example, we're talking about search space both from a modeling perspective,

18:28.400 --> 18:32.240
but also literally the land perspective.

18:32.240 --> 18:42.240
Yes, the landmass, the little red, yeah, like, yes, in kiloveturn, in by, so no, it's

18:42.240 --> 18:43.240
in kiloveturn.

18:43.240 --> 18:44.240
Right.

18:44.240 --> 18:45.240
Yes.

18:45.240 --> 18:46.240
Right.

18:46.240 --> 18:55.080
But yeah, that project came to, well, our contribution, my contribution in that project

18:55.080 --> 19:01.760
kind of came to an end when we were done developing the model, and that was in March.

19:01.760 --> 19:05.000
And pieces of those are published.

19:05.000 --> 19:09.720
And then of course, like I said, the software was delivered to the park rangers.

19:09.720 --> 19:17.160
And so I moved on from that one, from that project, but it's certainly an interesting one.

19:17.160 --> 19:20.640
And it's been one where we actually have been contacted by other people.

19:20.640 --> 19:25.120
For example, the cash in transit robberies, you know, where they're saying, you know, can

19:25.120 --> 19:29.600
you tell us, spatial, because we've worked with spatial data now, spatially, you know,

19:29.600 --> 19:33.960
what are the chances that this one area is going to be a hotspot for the next, you know,

19:33.960 --> 19:42.360
a hit on a delivery, but yes, you know, they all link up, well, somewhat.

19:42.360 --> 19:46.120
It's different, but you know, at least they have that spatial component.

19:46.120 --> 19:47.120
Right.

19:47.120 --> 19:48.120
Right.

19:48.120 --> 19:54.720
So that one ended about a year ago, just over a year ago.

19:54.720 --> 19:57.840
And so now you're working on what?

19:57.840 --> 20:02.560
So now I actually, it's funny because my life sort of came full circle, and I went back

20:02.560 --> 20:03.560
to biology.

20:03.560 --> 20:07.680
I know I did say that I started off as an economist, but people have to forgive me because

20:07.680 --> 20:12.280
like I say, I am a liberal art student.

20:12.280 --> 20:18.240
So I actually have my undergrad is both computer science and biology, and then, you know, my

20:18.240 --> 20:22.120
PhD work was the science economics and bioinformatics a little bit.

20:22.120 --> 20:23.560
I was just doing a project.

20:23.560 --> 20:29.200
That's also why the PhD never got finished, there was just too much, too much going on.

20:29.200 --> 20:35.040
But so I got contacted by the bio sciences group here at the CSIR.

20:35.040 --> 20:41.120
So these are the white lab biology, so we actually run the experiments and run samples.

20:41.120 --> 20:49.320
And so they had run a project like last year, and that project was on understanding an

20:49.320 --> 20:54.400
effect of one HIV treatment drug, and they found that, you know, there were biomarkers

20:54.400 --> 21:00.040
in African populations that had not been studied and were causing renal failure in the patients

21:00.040 --> 21:02.840
that were taking that specific drug.

21:02.840 --> 21:08.160
And so based on that, it was a signal that no, actually we really have to take this problem

21:08.160 --> 21:09.800
very carefully.

21:09.800 --> 21:16.680
So we know that generally people have the same processes, generally, as human beings.

21:16.680 --> 21:25.600
But also there are some manifestations of diseases that are race or geography dependent.

21:25.600 --> 21:31.600
And so we wanted to, so South Africa is going through a whole thing.

21:31.600 --> 21:38.600
So there's such an increase in cancer incidence in South Africa, as is in the world over.

21:38.600 --> 21:45.400
But there's several research that will show that the rates of these incidence is actually

21:45.400 --> 21:47.600
different in different populations.

21:47.600 --> 21:53.840
So for example, black men will have a higher incidence rate of prostate cancer.

21:53.840 --> 21:59.320
Or for example, it's a lot more difficult to detect breast cancer in black women, and

21:59.320 --> 22:05.280
actually in Latina women, even more, mostly because of how dense the breast tissue is.

22:05.280 --> 22:09.880
So there are some of these things that we know that there are some differential biomarkers

22:09.880 --> 22:14.560
in different populations that make the disease manifest itself differently.

22:14.560 --> 22:17.720
And therefore the therapy ought to be different.

22:17.720 --> 22:26.520
And so we decided to study pancreatic cancer in African population, but specifically South

22:26.520 --> 22:32.360
Africans, which literature will show that they can be quite different, you know, they

22:32.360 --> 22:35.280
can be quite genetically different from maybe let's say West African.

22:35.280 --> 22:36.280
So I want to make that clear.

22:36.280 --> 22:39.680
We're not looking at all people of African descent.

22:39.680 --> 22:44.040
One of the really biggest things I have to say, so besides understanding these biomarkers

22:44.040 --> 22:47.640
is actually just to create the data, make sure the data is out there.

22:47.640 --> 22:53.040
So there may be however much we get to in identifying these biomarkers in pancreatic

22:53.040 --> 22:58.240
cancer, but the most important thing is to create this data so that other researchers

22:58.240 --> 23:03.360
in the rest of the world can study the data because one of the biggest problem with diseases

23:03.360 --> 23:09.160
in African populations is that African populations are not usually included in medical trials.

23:09.160 --> 23:14.720
So there isn't enough information and enough data to go about to see how things affect

23:14.720 --> 23:16.600
people of African origin.

23:16.600 --> 23:21.240
The same happens with the amount of genomic data that's out there, which of course also

23:21.240 --> 23:23.320
the amount of proteomic data.

23:23.320 --> 23:26.160
We are looking at proteomic data.

23:26.160 --> 23:33.640
So this is the data, it's just the proteins and that in actually it's going to be peptides.

23:33.640 --> 23:38.600
But I'm going to stick with proteins just for the sake of just removing it.

23:38.600 --> 23:43.760
It's not really complex, but you know, just for we're having a chip chat, right?

23:43.760 --> 23:51.880
Anyway, the scientists hopefully will not kill me for saying proteins when actually.

23:51.880 --> 23:58.440
So yeah, so you know, we just want to collect like try to find some of these proteins and

23:58.440 --> 24:04.360
see if there are some of them are actually biomarkers in this disease and maybe it might

24:04.360 --> 24:08.640
actually help to say what actually a biomarker is because there's a technical definition

24:08.640 --> 24:14.760
of the biomarker is that a biomarker has to be a protein that is related to a disease.

24:14.760 --> 24:18.040
It is actionable and it is measurable.

24:18.040 --> 24:21.840
So it is measurable enough that you can make a decision.

24:21.840 --> 24:28.040
So there are, so this is why we always talk about biomarkers because if you can truly identify

24:28.040 --> 24:33.040
biomarkers, which means they are actionable, then you can hopefully start to think about

24:33.040 --> 24:39.920
drug development or some kind of corrective thing because you can clearly pinpoint it

24:39.920 --> 24:41.760
and you can take some action.

24:41.760 --> 24:47.400
And some of that action can just be that you can predict and say if I see this biomarker,

24:47.400 --> 24:54.400
I know it is differentiated enough that I can actually predict your susceptibility to

24:54.400 --> 24:58.760
the disease or actually whether the disease or the stage of the disease.

24:58.760 --> 25:00.320
So that's what we wanted to do.

25:00.320 --> 25:08.000
We want to identify these biomarkers and then we want to populate this data set so that

25:08.000 --> 25:09.800
other research has had it.

25:09.800 --> 25:15.920
And for us, we certainly want to find these biomarkers and pass them on to our own, you

25:15.920 --> 25:23.640
know, drug development companies or, you know, we, it's a whole pipeline, this whole system.

25:23.640 --> 25:27.800
So you've got doctors in one end and then you've got academic and research in such it

25:27.800 --> 25:28.800
on the other.

25:28.800 --> 25:33.480
You've got drug companies and then it goes right back to the doctors and we're working

25:33.480 --> 25:35.160
with the local hospitals here.

25:35.160 --> 25:36.800
That's where we're getting the samples.

25:36.800 --> 25:43.440
So in the samples from the local hospitals here, in most of them, I in Johannesburg,

25:43.440 --> 25:48.120
I'm sorry, but it's like 40 kilometers, 50 kilometers away from each other, so practically

25:48.120 --> 25:49.520
close by.

25:49.520 --> 25:56.920
Maybe let's talk a little bit about that, that initial element of collecting the samples

25:56.920 --> 26:00.960
and processing them, and turning them into a data set that you can use.

26:00.960 --> 26:03.520
How, how do you go about that?

26:03.520 --> 26:08.560
Well, you get a sample and you have to prepare this sample.

26:08.560 --> 26:13.520
So I mean, you know, like the doctor goes in and then they diagnose you, oh, that sounds

26:13.520 --> 26:14.520
bad.

26:14.520 --> 26:17.120
I'm sorry, it's always so morbid this whole discussion.

26:17.120 --> 26:24.240
But, you know, like, you know, there's cancer and they, you know, then we ask, you know,

26:24.240 --> 26:28.840
when they are going to do biopsies and stuff like that, right, they'll have like a sample.

26:28.840 --> 26:35.760
And so we get this sample and then it goes into a lab, it gets prepared, it gets run through

26:35.760 --> 26:40.240
mass spec, and the actual process that we use is the SWAT process.

26:40.240 --> 26:44.440
It really is not that important, but it goes through mass spec, and then mass spec is going

26:44.440 --> 26:47.520
to tell us, you know, which proteins are present in this sample.

26:47.520 --> 26:51.920
It's also going to tell us how much of each one of these proteins are present.

26:51.920 --> 26:57.320
And it's in that how much, well, assuming, first of all, you can clearly and neatly say

26:57.320 --> 27:01.920
which proteins are present, because that's the whole science of its own too.

27:01.920 --> 27:06.760
And then you then, after you have defined your, your, your identify them, then you find

27:06.760 --> 27:10.640
out how much of them are present in the sample.

27:10.640 --> 27:17.560
And then you are then, if, if you can find differences between either a protein or a group

27:17.560 --> 27:22.680
of protein between the disease cells and the non-disease cells, then you can say that,

27:22.680 --> 27:26.080
you know, you're starting to get biomarkers for that specific disease.

27:26.080 --> 27:31.880
Now, some of the problems that we run into here is, so I actually had one.

27:31.880 --> 27:36.840
I worked a little bit with data, with genomics data, and anyone that has done like genomics

27:36.840 --> 27:42.120
data and done PCR, I mean, the whole point of PCR is to, what's it called, is to make

27:42.120 --> 27:43.120
more of it.

27:43.120 --> 27:44.440
I can't think of the word.

27:44.440 --> 27:46.440
It's to amplify it.

27:46.440 --> 27:47.440
Expression or amplification?

27:47.440 --> 27:48.440
Yeah.

27:48.440 --> 27:49.440
Yeah.

27:49.440 --> 27:50.440
You know, you can amplify DNA, right?

27:50.440 --> 27:53.280
Unfortunately, for us, you can amplify the protein.

27:53.280 --> 27:56.280
So the amount of sample you have is the amount of sample you have.

27:56.280 --> 27:57.280
Okay.

27:57.280 --> 28:03.440
As always, you have like, so proteomics is one of these things that reproducibility is

28:03.440 --> 28:06.040
a big thing.

28:06.040 --> 28:10.400
And so also, you know, like the whole thing of like confidence in your results.

28:10.400 --> 28:17.400
So this whole statistical packages that are just developed to do this, because the sample

28:17.400 --> 28:20.320
will degrade, but now you can't do anything.

28:20.320 --> 28:22.920
And so you don't get as high a signal.

28:22.920 --> 28:24.920
And so, yeah.

28:24.920 --> 28:30.200
So one of the first thing actually we always do is to standardize our equipment so that

28:30.200 --> 28:36.320
when we do get the sample, we try to get everything run as quickly as possible.

28:36.320 --> 28:41.200
I know I've actually just gone into so many other things, besides where we start the

28:41.200 --> 28:42.200
question.

28:42.200 --> 28:45.600
But hopefully there is a thread that runs through.

28:45.600 --> 28:51.720
Well, you know, one of the things that, you know, one of the things that comes up in

28:51.720 --> 28:57.760
this area is that the data collection itself is often pretty noisy.

28:57.760 --> 29:03.240
And I'm wondering if that's something that you experienced and, you know, how you dealt

29:03.240 --> 29:05.560
with that in your pipeline.

29:05.560 --> 29:06.560
Yeah.

29:06.560 --> 29:10.840
So we are actually just now starting to collect the data.

29:10.840 --> 29:12.160
So you're right.

29:12.160 --> 29:16.920
We get, we get like by like, no, this is a three year project.

29:16.920 --> 29:18.440
And so year one just passed.

29:18.440 --> 29:21.960
And so that was the data collection for the biologists.

29:21.960 --> 29:25.160
And for us, it was to standardize the workflow.

29:25.160 --> 29:28.840
So that then takes care of the technical noise.

29:28.840 --> 29:31.800
So what they call, what is it called, like technical or something?

29:31.800 --> 29:34.480
Anyway, I'm going to call it technical noise because I can't remember.

29:34.480 --> 29:37.120
And I think for people in this audience, it makes sense.

29:37.120 --> 29:40.920
But this is, you know, given the tools that you are using, right?

29:40.920 --> 29:45.840
How much noise do you just get from those tools and try to measure that?

29:45.840 --> 29:47.280
So that's the first thing.

29:47.280 --> 29:50.720
And then yes, we do have sample noise as well.

29:50.720 --> 29:56.640
And the thing, generally, the thing you do in this area is to just try to get as many

29:56.640 --> 30:01.160
samples as possible, which we can't always hide.

30:01.160 --> 30:05.120
And maybe that's a good thing because I mean, it's not as many people have counts are.

30:05.120 --> 30:11.680
But then of course, it has those other implications.

30:11.680 --> 30:17.240
But yeah, I mean, you just, I mean, like I say, it's just like any other statistical exercise.

30:17.240 --> 30:21.480
You just have to have more data in order to be confident in your results.

30:21.480 --> 30:22.480
You have to have more data.

30:22.480 --> 30:25.280
You have to run the samples multiple times.

30:25.280 --> 30:30.080
So for each sample, we run it multiple times and to find out, you know, the noise that's

30:30.080 --> 30:34.280
embedded in just that one sample and the variations that are in that one sample.

30:34.280 --> 30:36.960
And then we run it.

30:36.960 --> 30:41.320
Sometimes we run two samples at the same time and then look at like that, that are supposed

30:41.320 --> 30:43.360
to come from the same cluster.

30:43.360 --> 30:47.280
And then we look at like the variation of the protein there.

30:47.280 --> 30:50.960
And then that will help, you know, at least there we know that they just ran through the

30:50.960 --> 30:51.960
same run.

30:51.960 --> 30:55.240
So at least the technical variation is not exactly there.

30:55.240 --> 30:58.440
And then we can just look at the sample variation.

30:58.440 --> 30:59.440
But this is the place.

30:59.440 --> 31:00.440
This is what biology is.

31:00.440 --> 31:01.440
You're right.

31:01.440 --> 31:05.160
It's always, it's always a variation.

31:05.160 --> 31:12.920
And so the only decisions you really can make is when your data is sufficiently separated.

31:12.920 --> 31:18.080
So one of the first things you do is just look at the means of the two samples.

31:18.080 --> 31:21.600
So you look at mean expression of the disease cell and you look at mean expression of the

31:21.600 --> 31:23.840
non-disease cell.

31:23.840 --> 31:25.920
And then you compare the two means.

31:25.920 --> 31:30.640
And if, if, for example, the standard error, you know, Chris crosses, you really have to

31:30.640 --> 31:34.280
go back and just work through your, your workflow.

31:34.280 --> 31:37.480
So we just start off simple as that.

31:37.480 --> 31:40.720
Because then you can't tell, obviously there you can't draw in conclusions.

31:40.720 --> 31:45.440
But if we can start to see some of those differences, then we get a little bit more confident.

31:45.440 --> 31:49.840
And then we can start to see per sample, where each sample falls.

31:49.840 --> 31:55.160
And then we start to look at, you know, can we predict per sample?

31:55.160 --> 32:01.600
And but yeah, this is something that can be one protein or it can be a combination of

32:01.600 --> 32:02.600
proteins.

32:02.600 --> 32:08.840
Is the process that would happen on the medical side the same as your process?

32:08.840 --> 32:15.920
Meaning you, you got these biopsy samples and you ran them through the mass spec to

32:15.920 --> 32:18.600
separate out all the proteins.

32:18.600 --> 32:26.280
Is that how the absent, your data collection is that how the disease would be diagnosed

32:26.280 --> 32:32.960
or would it be like a radiologist and imaging data and that kind of thing, a different kind

32:32.960 --> 32:33.960
of process?

32:33.960 --> 32:37.800
Oh, I think usually it is still the imaging part.

32:37.800 --> 32:45.280
I have to also say, I don't know as much, I have absolute, everyone's, well, yeah, I have

32:45.280 --> 32:52.560
a lay only a lay on knowledge on how the diseases themselves are diagnosed, like in the hospital

32:52.560 --> 32:53.560
itself.

32:53.560 --> 32:59.280
Because yeah, I get to interact with the data once with the bioscientists and they run

32:59.280 --> 33:06.240
through and all I do is help them standardize the equipment and then later on to do the data

33:06.240 --> 33:07.240
analysis.

33:07.240 --> 33:08.240
Okay.

33:08.240 --> 33:13.280
And so the data that you get is already labeled as to whether the sample is cancerous or

33:13.280 --> 33:14.280
not?

33:14.280 --> 33:15.280
Yes.

33:15.280 --> 33:16.280
Okay.

33:16.280 --> 33:17.280
Yes.

33:17.280 --> 33:18.280
Yes.

33:18.280 --> 33:20.680
The thing is we are getting, yes.

33:20.680 --> 33:24.960
So after a patient has been diagnosed with a certain kind of cancer, then we get a sample.

33:24.960 --> 33:29.400
So if, you know, like you've been diagnosed with pancreatic cancer, then we get the sample

33:29.400 --> 33:30.400
from the pancreas.

33:30.400 --> 33:36.640
We also get a sample from the biofluids, which are like bloods and the lymph something.

33:36.640 --> 33:37.640
Yes.

33:37.640 --> 33:38.640
The biofluids.

33:38.640 --> 33:40.520
So that's the information that we get.

33:40.520 --> 33:45.360
And then yes, that's the one that gets segmented with the mass spec.

33:45.360 --> 33:46.360
Okay.

33:46.360 --> 33:51.360
And so you're, you're kind of in this data collection process now.

33:51.360 --> 33:53.560
Have you started?

33:53.560 --> 34:00.240
And you've also started kind of exploratory work with the data, but you're pretty kind

34:00.240 --> 34:02.280
of the modeling stage.

34:02.280 --> 34:03.280
Yes.

34:03.280 --> 34:04.280
Yes.

34:04.280 --> 34:06.720
Yes, we are definitely before that.

34:06.720 --> 34:11.160
So like I had mentioned that other study with using data.

34:11.160 --> 34:18.040
So we actually are using that data to sort of standardize the workflow.

34:18.040 --> 34:23.740
So all the way, like to see how things shift from, you know, the point of them getting

34:23.740 --> 34:29.440
segmented all the way until they get quantified and start to, you know, to understand that.

34:29.440 --> 34:33.920
And then that way we understand our equipment and we understand what we need to change.

34:33.920 --> 34:42.760
So there are multiple workflows in proteomics, multiple, they spy ex, they is, they is open

34:42.760 --> 34:49.360
swathes, you know, there's trans proteomic pipeline and and all of them really are like

34:49.360 --> 34:50.360
these pipelines.

34:50.360 --> 34:54.280
So, you know, it goes into mass spec and then it gets into another thing that's going to

34:54.280 --> 35:00.080
pick like a peak, like it's going to find all the areas that that are present and then

35:00.080 --> 35:04.680
it gets labeled and then it gets quantified and then, you know, all of this.

35:04.680 --> 35:09.640
And then like we're still at the peptide level and then we go to the good old string alignment.

35:09.640 --> 35:11.680
But what do they call in proteomics?

35:11.680 --> 35:17.040
We do alignment to try to figure out if you see this set of peptide, what's the probability

35:17.040 --> 35:20.840
that it's this protein and then it gets labeled.

35:20.840 --> 35:23.440
So that is always a pipeline.

35:23.440 --> 35:28.880
And so, you know, all these tools in the pipeline are pieces of code and sensors that come

35:28.880 --> 35:32.400
with their own variation and have to be standardized.

35:32.400 --> 35:34.320
So that's what we've been doing.

35:34.320 --> 35:39.880
Once we have that, once we have data that we think is good, that we think we can trust

35:39.880 --> 35:42.560
which will hopefully be at the end of this year.

35:42.560 --> 35:48.960
So the process of actual data analysis is going to be this year.

35:48.960 --> 35:56.240
And then, then we can start really running the biggest thing in this area is to do classification

35:56.240 --> 36:00.640
right, when an extracting those features that put one sample one side over the other.

36:00.640 --> 36:02.000
Because those are the biomarkers, right?

36:02.000 --> 36:07.200
Like they're going to, in this area, be like those features that are seeing your disease

36:07.200 --> 36:08.280
on one disease.

36:08.280 --> 36:12.920
So for us, we're looking at it as a classification problem and to put it on one side over the

36:12.920 --> 36:14.120
other.

36:14.120 --> 36:18.560
We are also very interested in actually just running a clustering problem, even on the

36:18.560 --> 36:19.560
data.

36:19.560 --> 36:24.720
So maybe this goes back to your question of, so it comes labeled to maybe even see if

36:24.720 --> 36:28.480
like, are these expressions, you know, all that different?

36:28.480 --> 36:33.120
Can we, when we cluster them, are there, you know, like some similarities, even between

36:33.120 --> 36:34.280
the disease and non-disease?

36:34.280 --> 36:38.160
So you just cluster the whole data set and hopefully we'll get the separation that these

36:38.160 --> 36:42.640
are the disease cells and they'll cluster together and these are the non-diseased, you know,

36:42.640 --> 36:45.280
and they'll cluster together, the data from both will cluster together.

36:45.280 --> 36:49.000
But you can do that, but that's a lot of the work that you do when you're just exploring

36:49.000 --> 36:50.000
your data.

36:50.000 --> 36:54.680
The same thing, which is, you know, like understanding the differences of the means, you go through

36:54.680 --> 36:59.000
and you just understand your data and then like, you know, like chopping up your data into

36:59.000 --> 37:04.280
blocks so that you're not observing some other phenomena, let's say, maybe you're just

37:04.280 --> 37:09.120
seeing this disease only in like old people or something like that so that you can mix

37:09.120 --> 37:15.120
like, you know, old people and young people and still try to detect these differences.

37:15.120 --> 37:22.760
It ends up being something a process that has a lot of data and I do think one other thing

37:22.760 --> 37:27.960
that makes the problem a little bit complicated is that actually in the whole process of running

37:27.960 --> 37:33.240
your mass spec and everything, though we might run to one to run as many samples as possible.

37:33.240 --> 37:36.400
Remember, I did say that's the sample degrades.

37:36.400 --> 37:41.480
So we always have like a timeline of how much we can take to even run experiments and

37:41.480 --> 37:45.160
that actually is one of the things that limits how much data we can collect.

37:45.160 --> 37:49.760
So ideally we'd collect as much as possible, but you know, we get limited by that.

37:49.760 --> 37:55.400
It's not just that we get too few samples, it's also that the samples we have can degrade

37:55.400 --> 37:59.400
and it can be difficult to rerun them later.

37:59.400 --> 38:06.120
Which actually is why sometimes this process of swath is good because all it does is just

38:06.120 --> 38:07.920
breaks down everything, all it wants.

38:07.920 --> 38:12.360
So without even necessarily needing to label it, you don't need to pick it just segments

38:12.360 --> 38:13.360
everything.

38:13.360 --> 38:18.200
So later on you can actually go back to the old samples and study them when you have

38:18.200 --> 38:23.080
more information of how to actually understand this data, at least it will exist.

38:23.080 --> 38:30.120
One question that occurs for me in thinking about the way you describe your workflow, even

38:30.120 --> 38:34.440
like at the super macro level, right?

38:34.440 --> 38:42.120
The first year is spent on data collection and kind of refining this data workflow and

38:42.120 --> 38:49.000
then you kind of transition to an analysis phase in the second year.

38:49.000 --> 38:54.960
But often these two are like the overall process of getting to a model is very iterative and

38:54.960 --> 39:00.000
you end up tweaking the way you collect data and the kinds of data you collect and building

39:00.000 --> 39:01.480
out features and things like that.

39:01.480 --> 39:07.480
And I'm wondering how, if that's something that you observe as well and how you fit that

39:07.480 --> 39:12.560
into the way you work there on this project?

39:12.560 --> 39:13.880
Yes, definitely.

39:13.880 --> 39:19.320
We definitely do run the problem of getting to some point and then just not having the

39:19.320 --> 39:26.320
results that we wish to have, but or just not having results that are reliable.

39:26.320 --> 39:32.440
But yeah, so it won't mean that we will stop collecting data on yet when year three, that

39:32.440 --> 39:34.800
data will keep coming.

39:34.800 --> 39:40.840
And so while we are running this analysis, we might find that actually we have to check

39:40.840 --> 39:48.520
away some of that data and have to inform the doctors on how to collect the data.

39:48.520 --> 39:58.040
The nice thing is that, like I said, this kind of study is not like we are breaking ground

39:58.040 --> 40:00.880
in the processes, it's not.

40:00.880 --> 40:05.960
We are using processes that have been developed and we're trying to make them better.

40:05.960 --> 40:10.240
There's a lot of work to still like for improvement in this area, like technically.

40:10.240 --> 40:16.440
So yes, we can contribute those kind of technical, you know, like contributions.

40:16.440 --> 40:20.960
But the processes, there are multiple studies, there are multiple universities that are

40:20.960 --> 40:24.560
doing the work and material mix and in cancer.

40:24.560 --> 40:30.680
So you know, we have an idea generally of how to prepare samples of how, you know, we

40:30.680 --> 40:33.480
have a lot of literature that we can lean on to.

40:33.480 --> 40:39.880
So hopefully, you know, fingers crossed, things will work out fine and generally they really

40:39.880 --> 40:40.880
should.

40:40.880 --> 40:41.880
Right.

40:41.880 --> 40:47.320
I don't know what could be so different because we expect the difference is going to be

40:47.320 --> 40:48.760
in the population.

40:48.760 --> 40:49.760
Right.

40:49.760 --> 40:53.600
Because in terms of collections and stuff like those that we are just, it's standardized

40:53.600 --> 40:54.600
methods.

40:54.600 --> 40:55.600
Yeah.

40:55.600 --> 40:56.600
Yeah.

40:56.600 --> 41:03.800
So ultimately, the goal here isn't to, you know, pioneer some new, you know, approach

41:03.800 --> 41:12.000
to collecting the data or modeling, it's rather to apply things that are fairly well understood,

41:12.000 --> 41:16.400
but to a population that has been underrepresented and understudied.

41:16.400 --> 41:17.400
Exactly.

41:17.400 --> 41:26.480
I'm thinking about the, you know, the conversations that I've had with folks in data science

41:26.480 --> 41:35.440
and researchers in, in Africa in particular, I'm forgetting the name of the gentleman

41:35.440 --> 41:46.640
who presented at the black and AI workshop in, from Kenya and, yeah, I think the common

41:46.640 --> 41:54.080
thread through, you know, the things that you presented is this idea of applying these,

41:54.080 --> 41:58.760
actually both of the projects, I think he was working on a similar project with regard

41:58.760 --> 42:06.920
to, to natural resources, as well as kind of applying some of these methods to, to kind

42:06.920 --> 42:09.440
of understudied populations.

42:09.440 --> 42:15.400
And I don't know, I, I guess the question that I'm kind of struggling with is, is, you

42:15.400 --> 42:20.440
know, is a little bit of, is that the fact that you're kind of both working on similar

42:20.440 --> 42:27.440
things is that, to what degree is that kind of representative of the unique, you know,

42:27.440 --> 42:35.360
challenges that are kind of expressing themselves in African countries, you know, versus maybe

42:35.360 --> 42:39.920
a selection bias, that's what the organizers of black and AI thought would be interesting.

42:39.920 --> 42:40.920
Yeah.

42:40.920 --> 42:46.920
So, you know, but I think I actually had a little bit of a difference with the, with a difference

42:46.920 --> 42:52.160
of understanding with the work that I think Shira actually presented.

42:52.160 --> 42:57.720
I, I thought there was a lot of innovation in that, because it's, it's understanding

42:57.720 --> 43:04.000
the resources that you have and having to make these processes work for you.

43:04.000 --> 43:08.600
So, I have to say, and this is actually something I learned about when I moved here, there

43:08.600 --> 43:12.480
is a certain way that you work with these problems when, you know, you are in the US

43:12.480 --> 43:15.960
and you have the resources, you've got all the computing resources and you've got, you

43:15.960 --> 43:21.480
know, other resources, and then you move here and then you don't have as many resources

43:21.480 --> 43:26.160
and the level actually that the innovation comes at that of trying to still do the same

43:26.160 --> 43:34.680
quality of work, but, but at fairly low resources, because the work still has to be done.

43:34.680 --> 43:41.120
So I, I actually really think that is, so we have two areas of opportunity to contribute

43:41.120 --> 43:46.560
I think to, to, you know, the scientific dialogue in the world. Number one is how do you do

43:46.560 --> 43:51.560
science when you don't have as many resources, but how do you do good, usable, useful

43:51.560 --> 43:52.560
science?

43:52.560 --> 43:55.400
And I think for us, that's the most important thing. We don't have the luxury of, you

43:55.400 --> 44:00.160
know, dwelling on the smallest of problems, like, I think it's going to sound bad.

44:00.160 --> 44:06.840
I, my, I, please don't give me on Twitter, but, you know, for goodness, but, you know, like,

44:06.840 --> 44:11.760
if I'm going to be asking for a grant, like, the, the level I am going to get questioned

44:11.760 --> 44:17.120
at, you know, like, it's not just like there's all of this just a line there. So you have

44:17.120 --> 44:21.360
to learn how to work with, with, with those things. And I think that's where innovation

44:21.360 --> 44:26.400
comes from, because in fact, then that sort of thing can be pushed back into the developed

44:26.400 --> 44:30.160
world and say, no, you can actually do it with less resource. And so, you know, there

44:30.160 --> 44:33.760
isn't, you know, that can actually help. And there's been instances where this sort of

44:33.760 --> 44:37.840
thing has happened. And processes have gotten removed because of that. Because, you know,

44:37.840 --> 44:42.040
as they say, what is it called deprivation is the mother of invention. I'm sure I've

44:42.040 --> 44:51.440
just made that up, but I think this is a specific example of interviewing somebody who's

44:51.440 --> 44:58.040
English is a second language, right? We make things like that. But anyway, so, so that's

44:58.040 --> 45:04.720
the first thing. But the second thing is that we have very interesting problems. Like,

45:04.720 --> 45:11.480
we have problems that actually you can make an impact on. Like, just study in this data,

45:11.480 --> 45:17.000
however much we go through, and, you know, can make a difference. And that's the luxury

45:17.000 --> 45:21.600
that we have. That's the thing that really motivates us. So I think, I mean, there's a lot

45:21.600 --> 45:28.400
of basic research that gets done here too. I mean, Amazon has a very, very good lab in

45:28.400 --> 45:33.200
Cape Town. So that's where that's coming out of here. There's a lot of other labs actually

45:33.200 --> 45:37.360
that are running around. There's research institutes. Even here at the CSI, there's a lot

45:37.360 --> 45:44.360
of basic, basic work that gets done. But like I said, I like applied work. So I can't

45:44.360 --> 45:49.680
really say that generally captures the type of work that gets done here. But I do think

45:49.680 --> 45:55.560
we do more of that kind of work here. And I think you'll see maybe that same thing happening

45:55.560 --> 46:00.880
with maybe Latin America also, some of the, you know, the results you see coming out.

46:00.880 --> 46:07.920
And I think it's because we stand to truly make an impact. And it's really attractive

46:07.920 --> 46:13.520
to work in an area where you feel you can actually make an impact to a process to people's

46:13.520 --> 46:25.440
lives. Right. Outstanding. So that's that. That's my walk around. Yeah. And so what are

46:25.440 --> 46:30.960
some of the other things I came across a couple of other things that you've been involved

46:30.960 --> 46:38.000
in? I know last year there was the deep learning in Daba. Were you involved in that?

46:38.000 --> 46:44.960
Yes. Yes. Yes. I was, I was one of the organizers of the deep learning in Daba. I still

46:44.960 --> 46:50.680
am. Okay. So for folks that are familiar with that, what was that? I was, I was cheering

46:50.680 --> 46:55.240
you on from afar. Like, you know, I saw the tweets all the time and I was like, Oh, man,

46:55.240 --> 46:59.400
I need to find a way to go to that and just never was able to make it happen. But it

46:59.400 --> 47:07.840
looked like an awesome event. It was so great. So what happened is just a team of,

47:07.840 --> 47:11.920
our friends, I think actually, these are people that already knew each other from before.

47:11.920 --> 47:20.000
I mean, but overall, we all kind of also met or over Skype and, you know, but we, the

47:20.000 --> 47:25.920
whole purpose of the in Daba is to strengthen machine learning research in Africa. So one of

47:25.920 --> 47:31.120
the big problem actually, it's not the problem of even computing resource. Sometimes the problem

47:31.120 --> 47:36.960
of human resource, you know, like building a team that's big enough to truly, you know,

47:36.960 --> 47:44.400
build that momentum. And so we wanted to find out who else is here doing this work. It can

47:44.400 --> 47:49.520
be really difficult to find out who because we are so sparse, you know, like placed all over.

47:49.520 --> 47:53.200
Find out who's doing it. And for people that are interested, is there where we can

47:53.200 --> 47:58.320
capacity change them? So it was, it was a summer school. I urged people to go check out our

47:58.320 --> 48:05.680
videos on on YouTube. And we managed to get a, you know, a lot of people that actually

48:05.680 --> 48:11.360
this time around have the main planning people were people that have their roots in Africa.

48:11.360 --> 48:18.880
These are Africans. So we managed to all come together. And some of them were in deep

48:18.880 --> 48:25.360
mind and some somewhere in the US and a lot were here in South Africa. And the next year,

48:25.360 --> 48:30.560
so 2018 in Daba is still going to happen in September. And we're looking even for even more

48:30.560 --> 48:36.400
Africans that are practicing in this area because we don't want to have this idea that then no

48:36.400 --> 48:42.640
Africans are doing this work because then it's too wide. Looks unreachable. It looks foreign.

48:42.640 --> 48:48.880
And it's not foreign. It's a technique that can be applied to our problems in our world. So

48:49.440 --> 48:55.120
we have been trying to find more Africans or I'm also trying to find experts, not just, you know,

48:55.120 --> 49:02.800
Afro-African descent, but other experts to come and teach and you know, just be around here.

49:02.800 --> 49:08.800
And it was a fantastic, fantastic event. We had Nando, we had Anima,

49:10.000 --> 49:16.880
who just came, we had George from Brown. We had, and everybody was so, it was a really,

49:16.880 --> 49:24.480
really good contagious. And I can tell you already the type of research and the kind of relationships

49:24.480 --> 49:30.480
collaborations we've formed just from that week. Like it really energized our work.

49:31.200 --> 49:37.040
Oh, that's great. Because even with the guys at Black and AI, I got to meet them because they

49:37.040 --> 49:44.240
saw that we're doing this in Daba. And I really have never worked with it like nicer planning

49:44.240 --> 49:50.080
committee. We generally, I don't know if they'll be mad at me for this, but we fight like crazy

49:50.080 --> 49:58.240
by the nice thing is we are all interested in the same thing. And we work like crazy too. So

49:58.240 --> 50:04.000
anyone that wants to work with us wants to help us see this thing come true, please. Like we are

50:04.000 --> 50:09.280
always open. And that's what we want to do. We just want to strengthen African machine learning.

50:09.280 --> 50:15.600
We have very interesting problems in Africa because the dynamics are different. So if you get

50:15.600 --> 50:22.560
a model in US, it may not work here just because the dynamics are different. So we bring in a whole

50:22.560 --> 50:28.240
new way of turning around some of these theories to get to understand how they may work in our

50:28.240 --> 50:33.520
environments. And we can't do that if we don't have truly fundamental knowledge of how these

50:33.520 --> 50:38.800
things work. We can't expand and stretch them to fit our problems if we don't fully understand

50:38.800 --> 50:44.240
how far they can stretch and expand. So that's why we want to embed like deep, deep, you know,

50:44.240 --> 50:50.720
theoretical knowledge. So people we can really grasp these concepts. And then I think then we

50:50.720 --> 50:57.760
can really do something for ourselves. Well, you're passion for all of this is very palpable,

50:57.760 --> 51:04.640
very tangible. And I appreciate you taking the time to chat with me about it. This is really

51:04.640 --> 51:14.320
fun. Yeah, anything else that you'd like to mention before we close out? I think maybe I'll actually

51:14.320 --> 51:21.120
go back to the whole thing of collaboration partners. If anyone is interested in any of the things

51:21.120 --> 51:25.680
we said or has been interested in a problem that maybe they observed well, they took, you know,

51:25.680 --> 51:34.320
a trip down here to South Africa or anywhere else in Africa. We like collaborators because,

51:35.120 --> 51:41.360
you know, we don't necessarily, it need not be that we are isolated, you know, we get isolated.

51:41.360 --> 51:46.000
So if there are people that are generally interested in working with some of these projects,

51:46.000 --> 51:51.680
one thing I can really tell them is they are rewarding. The findings can be quite rewarding.

51:51.680 --> 51:56.560
And that we're all looking for collaborators because we don't also want to get myopic and how

51:56.560 --> 52:02.320
we understand our own problems. Perhaps looking at them from the outside can be a way to solve them.

52:02.320 --> 52:08.640
So we're open to discussions. Great. And is there any particular best way for folks to connect

52:08.640 --> 52:16.320
with you? Sure. They can get in touch with me. I am on Twitter. Oh, I don't know if I should disclose

52:16.320 --> 52:28.000
who I am on Twitter, given the things I said. I want to tell my, my handle is Ed Nunewska.

52:28.000 --> 52:35.440
That's the name my father gave me and it's stuck. Ed Nunewska. So, Ed Nunewska. So that's that.

52:35.440 --> 52:42.160
And then of course, my email is and more CSI R.C.O.D. Zere. And maybe you can just link that

52:42.160 --> 52:46.560
to the link to the web link. We'll link all of that together in the show notes.

52:47.600 --> 52:50.800
Okay. Great. Yeah. No. If you're just getting in touch with me,

52:50.800 --> 52:55.440
if you want to get in touch with the deep learning Indava to please just link our link over there.

52:55.440 --> 53:01.040
It's deeplearningindava.com. If you want to get in touch with our combatee, please check us out.

53:02.080 --> 53:06.800
Check, you know, maybe there's somebody they've always wanted to work with. Maybe you just like us.

53:06.800 --> 53:13.280
But anyway, yes. I think collaboration is good. Yeah. Great. Well, Nyalin, thank you so much.

53:14.480 --> 53:23.520
And well, yeah, just thank you so much. Thank you so much. It's been interesting.

53:24.080 --> 53:28.960
And please, you know, everybody, I'm always open for discussion. If I said something,

53:28.960 --> 53:34.320
that was not correct. Please, you know, guide me in the right direction. That's what I said,

53:34.320 --> 53:40.000
collaboration, conversation and exploration. That's it. Awesome. Awesome. Thank you.

53:43.040 --> 53:49.120
All right, everyone. That's our show for today. Remember, we want to hear your thoughts on personal

53:49.120 --> 53:57.680
AI head on over to twimlai.com slash my AI to share. For more information on Nyalin or any of the

53:57.680 --> 54:04.000
topics covered in this episode or to share your feedback, head on over to twimlai.com slash talk

54:04.000 --> 54:11.840
slash 109. Thanks so much for listening and catch you next time.

