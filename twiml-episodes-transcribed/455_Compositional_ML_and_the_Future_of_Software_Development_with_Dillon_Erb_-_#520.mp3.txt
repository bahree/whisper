All right, everyone. I am here with my good friend, Dylan Herb. Dylan is the CEO of PaperSpace.
Dylan, welcome back to the Twimal AI podcast. Thanks for having me. Hey, I am really looking
forward to digging into our conversation. It is just about actually just over a year since
the last time we spoke. We had a really good conversation on machine learning as a software
engineering discipline. And maybe we'll reflect a little bit on that. But before we do,
I'd love to have you kind of reintroduce yourself to our audience and maybe share a bit of an
update on PaperSpace and what you've been up to in the past year. Awesome, thanks Sam. Yeah,
so my name is Dylan Herb. I'm the CEO and co-founder of PaperSpace. We are a cloud computing company
that builds a suite of tools for machine learning developers that simplifies the process
of training and deploying machine learning models. We're based in New York and yeah, I guess it's
been a fun year since we last chat in. Yeah, so I mentioned that conversation and it was one
that we got a lot of great feedback on. We talked about this idea of machine learning. I guess
it was a point in time where it was becoming very clear to folks that there was a shift for many
in thinking about machine learning as this experimental process or an exploratory process to one
that required engineering rigor and discipline. We had a really good conversation about that idea,
but I wonder if you would share maybe your big takeaways or recollections from that conversation.
What were the key points for you? Yeah, definitely. I think that it's probably true in any space that's
moving very quickly where the underlying technology is changing seemingly every week.
But as you know, in the machine learning space in particular, there's been a big conversation
about questions such as does machine learning require its own special set of tools or can we reuse
maybe existing tools from the software engineering world? Are there special considerations for
the users of these applications? Is a data scientist a traditional software engineer or something
different? How do we bridge the gap between the kind of more standard machine learning programming
languages like Python or Julia and the more traditional kind of software web tools and programming
languages like Go and JavaScript? I think it's moved very quickly and I would say even today
it's shifting, but I think it's undeniable that machine learning is very quickly making its way
into the software engineering discipline and we're more importantly into a practice of
like delivering machine learning models. So I saw a tweet this morning actually from SRK
and paraphrasing it a little bit here, but the idea was 2015 to 2016 image and vision.
Someone added 2017-2018 Transformers 2019-2020 NLP 2021-2022 MLOPS and the big question was 2023-2024
question mark and you know they were soliciting thoughts on kind of what's next and idea that
we've been talking about that we'll kind of discuss more here you know could be the thing that
fills in that blank and this idea of compositional machine learning. We picked it around a couple
times in prior conversations and you know maybe this is kind of a good entree to have you share a
little bit about you know when you think of this idea of compositional machine learning you know
what is it where did it come from what were some of the inspirations that you've seen recently
that started you thinking down this line. Yeah I really like that that framing and it's funny how
quickly all of those changes happened you know I think there's there's also this whole question
around foundational machine learning or foundational models you know where are we in sort of the
adoption curve I think you know an idea that we've been kicking around I know that you and I
have talked about in the past is this you know or more recently around compositional AI and so for
us you know we've we are we're really at the I would say the beginning of a lot of folks is
journey into machine learning so gradient our machine learning stack is is used by you know at
this point hundreds of thousands of data scientists and machine learning engineers for primarily a
Jupyter notebook product similar to like a Google collab or you know kind of a web based IDE
and so you know we've been really close to seeing folks you know kind of begin their journey
into machine learning and very rapidly we've started to see some some kind of interesting breakout
cases of of how this of how machine learning has become sort of you know composed or or remix in a
way that I think is just fascinating you know a couple that come to mind that have really kind of
sparked a an internal you know kind of dialogue for for us at paper space have been you know one is
is you know this model a first-order motion model came out of NERIPS in 2019 and then earlier
this year we had someone on our platform build a kind of viral funny lip-syncing app that went
from you know sort of academic paper a couple years ago to you know number one app in the app
store you know in lots of countries worldwide and so you know it's kind of interesting where you
see you know maybe an app developer taking a machine learning model and applying to something
you know odd or interesting the other one that I think has been really inspiring is you know we
talk a lot about you know who who's the audience of this and is it software engineers as a data
scientist as a mathematician statisticians and and I think it's actually you know gone expanded
more quickly than we could have imagined so today you know one of the biggest audiences in the
in the Twitter sphere is you know artists and creators you know folks doing generative art and
that's been precipitated largely by open AI's clip model which is contrastive language image
pre-training which basically was a model that was introduced that when you kind of remix it with a
couple of other generative models gives you the ability to kind of you know use a text-based input
and generate you know really fantastical amazing art projects you know and now this is making its
way into NFTs so so I think what's really interesting today is you know whether whether or not some of
these big models are foundational or or essential or or whatever I think what we're seeing is you
know they're getting composed in interesting ways so the API is not necessarily a cloud-based
API that people are consuming but really like you know taking these building blocks and reapplying
so so I think this idea of compositional AI is something that we're you know it's it's kind
of a framework that we're understanding how machine learning is moving past kind of this academic
phase into you know kind of unexpected and interesting real world applications. Do you draw
inspiration for that from kind of the first wave of APIs around the web but certainly you know
especially when you use the term remix that was the term that we like to throw around I was trying
to kind of mentally pin that in time and I don't really have the I don't you know I have to
research that but like there was this transition from kind of this old school way of thinking about
integrating different applications like you know SOA and web sorry XMO web services that no one
thinks about anymore you know to kind of like web 2.0 and rest APIs when the like the essentially
the bar for integration and remixing different services got dramatically lower to the point that
I think you know it's almost not a specific thing anymore because it's just such an integrated part
of the way we think about building new applications and services especially given the rise of cloud.
You know I'm I wonder you know what that experience in that context tells you about the way
composition will evolve on the machine learning side. Yeah I mean I think it's a it's a big question
I think a lot of like you know a lot of smart folks are thinking about sort of what that looks like
you know one of the you know I think the question for us is kind of what's the form factor there
you know if you think about sort of composable portable and encapsulated building blocks of
any kind of software architecture you know immediately the question becomes sort of how big are they
you know what is the kind of interface between them you know machine learning has rapidly gone
through a number of phases and you know we've been around you know for I guess six six years now
and sort of seen a number of these kind of rise and fall so the first was this kind of idea
everyone's going to consume machine learning models through APIs because you know that's how web
developers are used to consuming things like you know clear bits for or something like that you know
a lot of companies kind of rose rose on that model companies like clarify doing really interesting
vision work and making that available as APIs then the big cloud providers followed with vision
APIs and the idea was that we would just kind of layer these into applications I you know I I kind
of what even when that was really sort of the model that people were pushing it was clear that
wasn't going to be sufficient because you know folks want to build their own you know variant of
these and the API model is kind of fundamentally limited so what we're you know another way of saying
that is that the kind of the granularity had to get kind of smaller you know there's been a lot
of consternation earlier which was like hey these things are enormously computationally intense to
to actually create like very few companies can create models the size of GPT-3
arguably you know a number you can count on your hand and so this whole notion of kind of
pre-training or refitting models was really sort of the I would say for the last five years kind of
the the standard like no one's going to retrain the kind of the first few layers of of the image net
they're going to you know train the last one and now we're seeing you know I think even a like a
step beyond that which is you know in the case of these kind of creative you know this creative
artistic community using Clip what they're doing is they're using Clip which is a you know a model
that opening I released that they open I did not release sort of the generator architecture
on top of it so the community has has kind of taken that and applied another generator called
DQGAM and so it's not even just taking one model and changing the data set you're working on it's
taking two models and then recomposing them in a really interesting way so yeah so I don't think
we know exactly what the form factor is but you know when you know I'm I run a company that that
builds tools for this so we have to look for precedence and so you know in our case one of the
the main precedence that we've looked at is is looking at other kind of composable code
architectures you know for example in GitHub there's there's this kind of very large ecosystem
of actions which are these kind of composable encapsulated building blocks that you can apply
into your code repo that can do things like you know do code coverage or deploy your code or test it
or you know add additional functionality and so as we've begun to develop more of our products
and sort of you know build products that that respond to this compositional AI
reality you know we're we're very heavily inspired by you know things that have worked well and
arguably you know we have pretty good precedent for how how to compose you know code that comes
from all sorts of you know different places in the world and different you know different sort
of foundational I guess I don't want to say foundational models but different kind of foundational
pieces I think that's that is an interesting I don't know if it's a point as much as a discussion
around what is the right granularity for delivering machine learning you know as you alluded to
is something that we've been talking about for a long time you and I in particular and the community
at large you know more broadly you know to what degree will you know models as a service be the
primary delivery mechanism for you know your typical developer versus you know them needing the
control that will require them to have access to you know notebooks and infrastructure and
the entire and an experience so that they can customize what they're doing and I think this
the idea that the future is not just single models but kind of multiple models with you know
that are trained in either some end-to-end way or fine-tuned in end-to-end way or in a tightly
coupled way does you know at some point the the permutations of models you know that people might
want to kind of remix you know breaks the industry's ability to you know create wrapper services
for different combinations and people just to operate at a lower level it sounds like that's the
you know what you what you're seeing or what you're you know the vision that is driving
your interest in this compositional idea yeah absolutely you know I think there's there's
you've heard a million times from you know companies and software developers in the space talking
about you know end-to-end pipelines you know you explore some data you train a model you deploy it
um I think that that that paradigm has stuck around I think it's a it's a it's a good one for how
you know data scientists and and data engineers can you know work on a product pipeline that
eventually ships into something interesting um I think that the idea of end-to-end is maybe a
little bit um uh it oversimplifies it a bit because it kind of it sounds like it's sort of there's
an input and then an output whereas you know what what I think we're really seeing is more
combinatorial you know like there are many inputs and many outputs and it's you a fan in architecture
fan out architecture um and very you know practically this has informed how we're building tools um
you know our our main our most popular product is a Jupyter notebook based product and for folks
that are you know there's obviously a large conversation around what what is the role of Jupyter
inside of the machine learning you know development process but you know one of the very fundamental
limitations um and I think there are a lot of benefits but one of the fundamental limitations is that
it is really a you know a linear pipeline it starts at the top and it works its way through cells
down to the bottom um and so fundamentally it's not really recomposable in a way that um you know
that that facilitates or makes possible these more interesting applications um you know they're they're
not as they're not as composable or portable so they're harder to share you know like they um
they're hard to death you know they're they're large JSON objects I think they're extremely useful
in some ways but um you know we've seen there's a there's a reason that folks have really been
embracing sort of these pipelining tools that let you do kind of arbitrarily complex input outputs
you know uh and so that's where a lot of our thinking is today um is around sort of what is
that form factor how do you go from maybe exploring something model or data or um you know just
code repo in a notebook and sort of an interactive REPL uh and then you know how does it get into a
quote-unquote production or you know not even production how does it get into a more interesting
kind of state after you've modified it um and so that's really I think informed a lot of
our thinking uh because you know there's there's you know data code clearly is the main input on one
side you want to create an app or a web service on the other side but but you know there's a lot of
other pieces you pull in and we've been drawing you know a lot on ideas like continuous integration
continuous deployment um composability uh you know pipelining uh uh dags and you know there's
memes now about dags and yamls because I think what we're what the industry is seeing is that we
have to uh you know embrace kind of a more flexible system for building out these new kind of
composed machine learning applications now your your comments on notebooks is calling the mind
another kind of data science internet I don't know if it's a meme or a feud or a drama or whatever
but you know maybe just put it as like you know there are different opinions on the role of notebooks
or the appropriateness of notebooks uh probably best characterized by uh Joe Bruce on one side
you know and his I don't like notebooks talk and then Jeremy Howard on the other side you know
with his I like notebooks talk uh and I think that um you know that that contrast is is
there are folks that have taken you know those positions and tried to operationalize them in
different ways so like you know typically the I don't like notebooks camp well they just don't
use notebooks and they use traditional code and traditional code artifacts uh you know repos
and containers and you know productionalize their projects just not using notebooks on the other
side you know there's folks uh like you know Jeremy and fast AI uh but also you know Netflix I think
is kind of famous for this and some companies which spun out of Netflix uh for and I believe
Airbnb was trying to do this uh for a while I don't know the the more recent status of this but
trying to take the notebook and turn it into a production artifact um you know either through
you know some kind of decorators or annotators or things like that that allow you to to specify
within the notebook hey this is the code that needs to be exposed uh or other mechanisms um
it sounds like you you you started it what's interesting I think in this conversation is you started
with a notebook service that was popular uh but then took this you know traditional engineering
code artifact route as opposed to leaning into the notebook um you know tell yeah here's the thinking
there yeah also um you know for folks that are listening that aren't familiar with paper space
you know we originally started more as an infrastructure as a service company focused on GPUs
and so we are we're interesting in that you know we kind of in many ways grew up with this machine
learning developer audience and kind of washed what they were doing so you know the first very
first offering we provided with something called machine learning in a box which was you know
uh basically a virtual machine template with all sorts of dependencies kind of pre-installed that
we spent countless hours you know fine-tuning to make it work um this was before really containerization
and taken off uh we worked very you know early on we worked very closely with Jeremy at fast
AI um you know we've been very fortunate to I think um I don't know the you know where where
it falls you know from all the numbers but we we've trained a lot of folks in the in the fast
AI universe um or onboarded them into machine learning and deep learning more broadly uh through
the notebook product but you know notebooks we we kind of formalized because it was a pattern we
saw everyone doing they would create a virtual machine and then they would install Jupiter uh
and then they would you know run a web service and put a public IP on it um so you know we we
kind of formalized that pattern um and that became gradient notebooks um it's so for us we with that
background we've kind of had two you know we have sort of this beginners using notebooks at the same
time we are running um you know large GPU infrastructure large clusters we've worked with
um a handful of much much larger kind of very advanced uh um practitioners on on doing kind of
production deployments really uh and so for us it was really you know I think it's the question
of how do you bridge those two worlds I think notebooks are um you know really wonderful
for onboarding people into complex code and data concepts um you know I don't know if it's a
forever thing you know I think it's you know when we describe gradient notebooks today we talk
about it more as it's a it's a web based Jupiter notebook and IDE um so you know you can bring
in uh Python code and Yamel code and um you know other kind of supporting bits as well so it looks
more like maybe a VS code than then uh sort of a standalone Jupiter interface um but fundamentally
you know we've been very interested in in how do you go from a notebook into uh you know like a
notebook is like you're kind of building your your idea or conviction around something and how
do you take that and make something more out of it um and so you know that's that's I think the
area that a lot of folks are thinking about um it's interesting you'd mentioned kind of decorators
and patterns that have kind of been introduced for turning a notebook into a you know runnable Python
file there was a you know paper mill um is a the Netflix project that is very very popular um you
know there are other interesting ones like streamlit which are kind of um I don't even know how to
describe them sort of a combination of a of an interactive notebook and a deployed uh process um
and yeah I mean I think that um that's sort of like right now the question is how do you take
this audience I mean in our case very practically we have a lot of folks that are sort of maybe
growing out of Jupiter notebooks and how do we give them sort of a more composable uh past or
or you know easier path into promoting what they're building or maybe even thinking of like larger
possibilities because they can bring in you know easier more shareable composable building blocks um
so yeah I mean I think uh I don't think notebooks are going anywhere um and I and I think they're
enormously useful um but you know I don't think they're exclusively the form factor and so
you know that's why we're all kind of working hard to find sort of uh uh you know the next step here
and you're uh the the direction that you're betting on is you know the the mean
dag yes the very mean to dag um I mean yeah the machine learning memes have gotten pretty pretty
good in the last year um so I don't know where that puts us on the the hype cycle um but uh but
yeah so you know we uh the one that I shared yesterday on twitter which I thought was really
funny was like a movie poster it was like from the creators of untitled.ipymb and untitled parentheses
one.ipymb is untitled parentheses too.ipymb yep yep yep spot on um you know it's uh yeah I mean
well that's actually you know practically Jupiter notebooks are really hard diversion we actually
had an internal tool that we're you know hopefully we'll release one day but um that we call
MBDIF which is our Diffing Tool for notebooks just because we had to do it um and we ended up running
into a lot of kind of weird issues because um they're you know they're just they're not they're not
really okay uh the format is odd people can annotate it you know colab can add different metadata
annotations the spec changes a bit um you know we can add annotations and it's just it's it's like
hard to diff and and sort of there's different inputs and outputs there you know Jupiter widgets
which are sort of these uh special collaborations between server and client side they're just they're
really weird um for if you from a traditional code perspective um so you know I think we have to
move towards a direction that looks more like um more you know more like traditional software
engineering and that was my you know big pitch a year ago I yeah stand by it we have you know we
we believe really strongly that um Jupiter has a place uh for sure but but you know to to kind of
move the next step we have to um start thinking of you know drawing from known best practices and in
the uh you know uh kind of software engineering world and and one of those is you know uh I wouldn't
even call them DAGs necessarily I mean they certainly you know uh directed aciculate graphs uh but but um
yeah I mean you need to start you know introducing kind of pipelining uh syntax and semantics and
and kind of those primitives you know for us um where uh we're actually just about to my time
this airs we will have rolled out um workflows which is really like our most ambitious project and
also um kind of our most comprehensive which is uh really an automation um and build system for
machine learning applications that allows you to um you know really tightly couple it to source
control so you know to your point on uh kind of untitled one and two um you know that's not
sustainable um uh but you know sort of add a a few lines of code into a repo um uh and begin to
turn that into a kind of a composable building block that could be consumed by other people um and
you know like I mentioned earlier this is heavily inspired by GitHub actions um and and tools like
that um and sort of blended with uh you know kind of the data pipelining tools such as um you know
airflow or you know we're using Argo uh which is kind of a containerized Kubernetes um uh system
but yeah I mean I think this is where it has to go um so you know I don't think we're leaving
notebooks behind but we you know they're insufficient to take us to I think where we want to go
as an industry um so your your infrastructure um use Kubernetes under the covers uh in a lot of
places correct me if I'm wrong but I believe that yeah we're a big Kubernetes yeah uh and you're
you know you selected Argo as the workflow engine which cube flow does one that just like create
cube flow as a service other folks have have gone that route uh why kind of build it from scratch
yeah that's a great question I mean I think um cube flow uh amazing uh project in lots of ways
I think um it's uh this is my opinion in my opinion alone I think it kind of struggles to
to to uh to match sort of the um the audience where it is today um I think it's it's hard to set up
I think um you know the building out sort of the um the the cube flow actions effectively I think
is um still a bit difficult so it requires just more software engineering work so very large
companies um you know I don't spotify uh can can use um cube flow because they can invest in that
ecosystem I think um you know there it's it's not a pattern that um will be as extensible for
the kind of wide adoption that I foresee um and so you know what we've done with workflows which
is our uh kind of newest addition to gradient um is it's kind of take the best of of cube flow
and Argo which is you know containerization um you know sort of uh the ability to create these
you know complex tags with triggers and and sort of the fundamental pieces but expose it in a way
that is much more uh kind of akin to folks that are building you know for example we took a lot
of inspiration from tools like Netlify and Versal which are these web tools that basically let you
come in attach a repo uh to to their service and then it you know basically creates a build system
and gives you a website at the end um with just clicking a few buttons um and I think that's
the form factor we need um and today you know workflows when you when you onboard you basically
it's it's a very similar process give me a repo or pick one of a sample repo um it's going to
give a little bit of code in in a workflow dot yaml file um although that's kind of abstracted
away um and and I think we're gonna move quickly to a point where the yaml is really an implementation
detail uh and folks will be you know I don't know if it's a full low code no code because I don't
know how quickly we get there um but um you know the composability is where we want to focus our
energy um and so you know I think Duplo it has solved a lot of interesting problems and and you
know they're a handful of other folks in the data kind of the data flow space that have worked on
this as well folks coming from the the Jupiter world so there's like uh these tool like plumber
is a really interesting one that I've been looking at recently there's one called kale for Kubernetes
which lets you sort of build out building blocks um um from a notebook and make them deployable
um but we're coming out of any other direction which is like what are what's the you know
what tools are common in the software engineers tool belt and how do we make this machine learning
thing look a lot more like that so for us the inspiration is um it's not starting at Jupiter notebooks
it's starting at um you know uh Jenkins, CircleCI, Versal, Netlify, GitHub actions things that are
like kind of like known known paradigms and known tool stacks or types of tools in uh you know
for folks that are building production applications. Yeah one of the things that I think is
compelling from a user and a face user experience kind of perspective about um you know paper mill
ask type of types of approaches is the idea that they start with the notebook and you know you
because the notebooks is an interesting and useful place for kind of the throwing stuff against
the wall and seeing what sticks and like starting to you know shape it and um you know just kind of
bootstrapping your thinking about the way to attack a problem uh and then you know the traditional
approaches okay you do that you kind of bang stuff into shape and then you like pull it out into
a python module into a text file um but the you know these other approaches allow you to like
it's it's even easier in a sense and if you've already got that infrastructure in place you just
kind of add your decorator or whatever and you know there's your your artifact um I think the
question I'm trying to get to is like you know do you see a bridge between the worlds and what
you've built with workflows where you know you're starting in this you're you're I don't think
you're suggesting folks to not use notebooks to you know get started or to to experiment because
they're useful for that is there a bridge from that to a dag based you know traditional system
other than okay you know rip your stuff out of the notebook and put it into a code module and
take it in to get up yeah uh that's a good one um I I don't know I mean I think that um that
we're we're internally doing a lot of work on on thinking about that form factor like can you
you know turn a cell into an action in our in our pipeline um can you sort of send one over um
the I think that the form factor that we need to get to more quickly and this is actually where
we sent more of our more more of our energy with workflows is um kind of closer what I would call
maybe build packs or sample apps so for example you know I think what versatile and for folks not
familiar it's a it's a web hosting tool for building or a tool for building web applications
very easily and it relies a lot on you know things like for example create react app which is sort
of a starter template that if you're making a website it's a really good place to kind of fork
that one and start somewhere and so I think that you know the pattern we have for notebooks today is
people fork a notebook and build something out um you know clip and vqgan and then they run through
it and they get some images um I guess you know that form factor is is hard to you know directly turn
into something like a create react app or a um uh you know I don't know a starter template of
sorts but I do think is it the nature of notebooks that makes it hard yeah I mean it's it's largely
because the the you know the the large benefit of a notebook is that you get this interactive
repel environment you know you type code you get a response very quickly um but that same you know
the the the fact that it is sort of embedding its outputs and its inputs um cells are not really
ordered um you know they don't have any reference to the dependencies or the or the metadata um
that's required to run the thing it's hard because it's a notebook it's hard because it's a notebook
and so you know what I think well you know one of the things that we're bringing over more into workflows
is the kind of interactive repel you know idea um like for example in circle CI which is our build
tool that we really like um for our web application um you know you can SSH into an instance which is
the equivalent of kind of creating a repel you kind of go in and you can start interacting with the
real thing um it's just you're doing it at a at a you know a higher like a different level of
granularity um you know a notebook is really like tightly connected to a single kernel and you're
kind of you know going through um I think you know I I don't think they're going anywhere I think
they're extremely important components um I think that their importance will be will know more um
I think in a few you know maybe even in the next year when we start seeing sort of how the
the next set of killer applications um you know come to fruition and my guess is it's going to look
more like starter templates like create react app that you're forking um you know more like build
systems and build packs um where you're kind of focusing your energy on picking different you
know um instead of dolly you're picking vqgant um or instead the first order motion model you're
picking uh you know uh the the new enhanced one that that snapchat just came out with um so
so yeah I think that that's it's a big open question um but the good thing is we don't have to
invent it from scratch we can follow um you know a good precedent and I think we should draw that
and this goes back to the sort of the last conversation I think we should draw primarily from
the software engineering world because a lot of this has been resolved over the last say 25 years
or whatever um on how you how do you build scalable you know large production uh applications
one of the things still in that I've heard you say and in this conversation and we we've talked
previously is that this project is you know one of your or your the paper spaces most ambitious
undertaking and um you know I'm curious what why that is like what makes it ambitious it sounds
like you took Argo and like build a web app around it like you know you can make it you can you
can reduce it or simplify it to sounding very simple you know yep what where's the complexity
and the effort yeah uh great question I mean I um you know what I think for us it's we know that
there are certain really well-known best practices so notebooks today whether we think they're
going to exist for 10 years or not they're they're really practical useful um components in the
machine learning you know developers tool belt um deployments on the other end which we also
a deployment service that were were by time this rolls out there will be sort of our next iteration
of that that has been released um but deployments are also relatively well understood at least from a
web perspective I mean we can go into you know edge deployments and quantizing and pruning models
and sort of the you know the complexity there but I think it's there there are less open questions
um really uh you know it's the question about the glue or the fabric that takes these kind of early
you know exploratory prototyping tools and lets them kind of transition into the you know
the the production world you know think that every software company in the MLO space is talking
about end-to-end you know training to deployment R&D to production um and I think that you know
so that that inner fabric I think is really important um and there's no shortage of
DAG based data flow data um you know data tools um and so for us it was very much pick you know
have some principles on what we're picking as the foundational piece you know containerization
we think is it's you know we're making bets we're making bets on technology stacks you know we
invested very heavily into Kubernetes um and you know Kubernetes is an amazing technology has
actually I think been more complicated than some people thought um but I think is a you know
it's a big it's a big bet for us is that that type of container orchestration layer um is one
that we you know shouldn't try to solve differently for machine learning than we should other other
areas um the form factor though for how you compose them is very different um because the
reality is the audience is different you know the folks that are that are I would say um
um that should be using machine learning in their day-to-day work if all things were created equal
and it were very easy to do is massive it includes uh marketing people and statisticians and
folks in the humanities and artists and um you know in addition to software engineers and
BI people and you know analysts and it really is and medical practice you know uh practitioners
so it's pretty it's pretty expansive and so what that means is there's there I don't think there is a
single form factor for everyone um you know I can see a world where uh there it you know
there are zapier like you know connections for um machine learning models to endpoints and there
are APIs that are consumable um just like there are today for web services but I think the question
that you know when we think about it you know our audience is every software developer in the world
building uh you know software applications and delivering those we believe that they are going to
use machine learning as just a part of their toolbell a part of their stack um so you know we have
some guidance on how to how you know workflow should be designed um but it's it's a uh you know it
is not there there's no very obvious precedent for exactly how this should be done um and I think
that when you take on a very large projects like this um getting the form factor wrong especially
for you know uh a software company um can be can be really dangerous um so you know we can get
into sort of how product and development and management is done but I you know it it really is
always I think even at all good companies um some percentage of like seeing where the world is
today uh what are people building you know what are their problems and challenges uh and then the
other 50% is you know what are going to be the challenges a year from now and given how quickly
the space is moving and how many things that I think are just really amazing and unpredictable um
you know it's uh it's it's I think you know ambitious to to try to give a a version of a future
that is um uh you know so so up in the air right now um yeah I think uh uh you reference this idea form
factor you know multiple times throughout this conversation and and you know what you're saying
clearly is that it's not the it's not necessarily the like the engineering challenge of
hooking up a workflow you know engine to uh deployment system to this it's it's all of that
you know there are there is existing software out there that you're taking advantage of you
know not that that's easy right when you have a large distributed system it's always hard but it's
sounds like what you're saying is that the you know the challenge was more getting the user
experience right uh in all that you know compared to you know your previous undertaking which was
there's this well-known user experience a notebook how do we make it so that you know how do
we make it easier to deploy that yeah there's a lot more risk in trying to figure out you know as you
say kind of look into the future in terms of what people will need to you know more easily kind of
compose machine learning uh an AI systems and then build a system that uses just these infrastructure
primitives to make that easier to do yeah absolutely I think that is the challenge I don't think
it's ours alone but I think you know what we're coming at it with is uh I think a you know a somewhat
unique perspective which is that we you know we have a um more of an infrastructure you know deep GPU
and accelerator focused than probably most companies in this space at the same time you know we have
created tool that is used by uh you know probably more folks in this space than almost any other tool
for kind of learning this for the first time and so we have these you know this kind of split
audience of like beginners and advanced people and and I think that that gives us an interesting
perspective on how to how to bridge those but certainly it's not resolved and you know I can see
a scenario where you come back in a year and we say yeah so you know actually you know we the
YAML stuff was too hard to do and the audience didn't need it we you know we really had to make
this say uh you know a wizzy wig a gooey build or something like that or you know more of a safe
year or you know notebooks actually um you know are no longer as useful when people can can clone
starter apps that do basically what they want to do anyway um including the deployment and the
training and the you know inferencing logic um so yeah I think we'll see I mean I think look uh
we're we're in a really exciting time I mean for software developers in particular uh you know
I just listened to the Greg Brockman version of your podcast which I really liked talking about
codex and copilot you know these tools are being used today um in in the real world by you know
like machine learning and assisted technologies are real and they're being used by programmers by
physicians by um you know a lot of folks and so you know it's some level I think it's inevitable
that this technology breaks out of the lab or whatever the analogy is um but um you know I think
there's a race to figure out the form factor and I think the opportunity is massive because I think
we're gonna see you know just like today totally unexpected applications um that are really
inspiring you know I think it's it's amazing that we've been in the space you know uh for it's
relatively um short life life cycle um and just I continue to be amazed at what is being created
and um you know what's possible um and you know we could we could have a whole other our conversation
about you know transformers and uh you know sort of what what what that what that has done for the
space but um and we probably should but uh you you brought up the the interview with Greg and and
codex and um you you talked abstractly about that stuff being used but from our conversations
I know it's not necessarily just abstract for you you actually used it and there's some
codex generated code in in paper base yeah yeah we'll have to uh I mean it's uh still you know
we we were when it first came out we were kind of playing around and you know giving some comments
like generate a function that uh you know does this simple task uh creates an array of of interesting
names or whatever uh for sample projects um and we actually do have a piece today which is um
totally AI generated that is in our production application um it's small it's you know
founded but it opens up the question you know if one whatever 0.001% of our code base is AI generated
generated today um you know I'm curious what percentage that is a year from now or the next time
we talk my guess is it's going to be more um and so uh you know that's an exciting future for sure
like this this stuff is not we're not talking abstractly about the power of machine learning to
change your day-to-day it's actually doing it um you know that's this is also a very complicated
topic I don't think engineer you know software engineers are going to be out of jobs but um you
know I think this this kind of radical AI assisted future uh is really exciting whether you're an
artist a programmer um you know a media producer uh whatever it is like I think that um that's why
this space is so exciting and that's why I think you know um we we care so much about trying to
find the right form factor UX sort of the the the way that we can assist in um you know helping
build more amazing applications like you know kind of breaking out of the the kind of meme culture
and getting into like what what what are you know what are builders building kind of thing
awesome awesome well Dylan always a pleasure to catch up with you thanks so much for the update
and uh looking forward to next time awesome thanks soon take care thank you
