The conversation you're about to hear was recorded live at Twomokon AI
platforms. For more coverage of Twomokon, visit Twomokon.com-news or follow us
on Twitter at Twomokon AI. But first, a word from our sponsor.
Thanks to our friends at Dot Science for being a founding sponsor of Twomokon AI
platforms. Dot Science is excited to have met so many amazing attendees at this
year's conference and looks forward to continuing those conversations. If you
weren't able to connect with their team at the conference
or aren't interested in what you heard on stage or at their exhibit in the
community hall, head over to dot science dot com slash deploy
for a free demo and see just how easy it is to get your models into production
and keep them performing. So please take the opportunity to
join me in welcoming our first guest Hussein Mahana is the head of artificial
intelligence and machine learning at cruise and Hussein has a very unique
set of experiences that I'm excited to dig into
in this interview. He was founding engineering leads on the Facebook's FB
learner platform went on to Google to work on Google Cloud and now is
running ML and AI at cruise. Hussein, welcome to Twomokon.
As I mentioned in the interview, you have had a very unique set of experiences
in this space, starting with joining Facebook at a really pivotal
time I think for the company clearly before there was a machine learning
platform in helping get that effort launched. Tell us a little bit about those
you know that time period that you were there. I imagine it was a crazy
period and you've got some more stories. Yeah, it was 2012 and I think it was
the really best time to work on machine learning at Facebook at the time because
the product was mature enough to support machine learning.
Before you can do machine learning you also need good data infrastructure
but the machine learning platform and capabilities themselves were very little.
So at the time there was probably maybe two algorithms at most,
probably maybe two people using machine learning at Facebook and maybe
over the you know an entire year maybe 20 models were trained. By the time I left
we had 25% of engineering using machine learning so we were in the
thousands and we were training maybe two to three million models a month and
a big portion of those were automatically trained and triggered just like
whenever new data comes they just got launched. And most important metric of
all is the time it takes to ship a model from idea to production.
A relatively simple model would take three months, four months in those days.
When I started. When I started and then we got to a point where
multiple models a day could be launched. Wow, that's incredible. So the early
models were that I'm imagining ads and feed? I mean yes, I mean ads and news
feed and search at Facebook are the biggest consumers of machine learning
and they continued but the earliest models were very very simple,
very rudimentary but at the time I left we've supported sort of all sorts of
algorithms and models you can think of. I can imagine. So when you got started was
how big was that effort? Was there a minimum viable product for the platform or
there was no Facebook wide platform. There were like sort of pockets of people
who decided that they had to work on a platform for their team because they
just couldn't ship anything and I became one of those. There was there was a
small tool that we had and I went to my manager after several months working in
the ads team and I said you know what I'm just going to focus on the platform.
It is our biggest bottleneck and so I started working and I remember the
first thing I shipped I locked myself for three weeks. We were training a simple
boosted decision tree that took three days and when I got it down to 21 hours I
could just see the tears of joy because my fears were like you're seeing I could
I could train a model in a day and get the results in a day you know in the
morning and then and then just be done like they were extremely happy and we
eventually got that down to two hours and so and you can see a correlation
between sort of the innovation we had and the productivity that machine learning
engineers had so I decided to focus on that and then as the journey of the
platform evolved we realized that there's an opportunity to support applied
research because now when you have a platform that unifies the company if you
drop in a advanced algorithm everyone else can use it and so the
platform supported applied research in a in a great way and so the work you did
with the boosted decision trees how did you achieve that speed?
Was it just working on the algorithm itself or was it scaling it some way
distributing a combination of everything so the first early wins were mostly
about just avoiding some inefficiencies often machine learning data
scientists or or machine learning scientists are not the best infrastructure
builders and so there was just very common mistakes and those were the early
or low hanging fruit but eventually we got to a point where it was all about
making the algorithm itself faster there's a paper that Facebook one
published about image net in an hour that's an example of how such
scaling efforts eventually evolved where it wasn't just about the
infrastructure but it's also about exploring different algorithms learning
algorithms that can speed up the training
training overall. Did the speed for training a model versus
cycle time what like what ended up being your driving metric what was the thing
you were focused on? That's a fantastic question it's the end-to-end
machine learning cycle all the way from the moment you prepare your data
to generate your features to training your models to
deploying and then back again that cycle was essentially our entire focus
and moving through that cycle faster and faster meant that we're essentially
building models that are learning faster because that cycle itself is one
cycle of learning and reality so we focused on the entire end-to-end.
We talked about the MVP can you talk about the evolution of the platform there?
Yeah we went through three phases in 2012 I focused on what was at the time
called ab learner that was just for ads and it became really successful that
other teams started coming to us and saying hey you know we want to give up our
platform start using your things so that's when we moved it to FB
learner and we had like two other groups at Facebook
but then we realized that so we were scaling on the dimension of teams or
scenarios but we're not scaling on the dimension of algorithms and techniques so
it was a platform basically basically based around the couple of algorithms so
we then moved to the third generation which is FB learner flow and that's when
we scaled the number of scenarios significantly and the number of algorithms
that we support and we built that platform with extensibility
from the get go and not necessarily extensibility by the core FB learner team
but the entire company and that's when the adoption rate in Facebook picked up
one of the things I'm really proud of is that we balance flexibility with
ease of use that we had about maybe a hundred to two hundred users from
Cheryl Sandberg's org and their finance and business and so we're really proud
about democratizing machine learning within Facebook to that extent
at the same time we had the latest convolutional nets we had deep learning for NLP
so we successfully I think we successfully built a a good multi-layered
platform that scaled for different use cases. So you just mentioned use cases you
started with a teams dimension and an algorithms dimension do those two get you
use cases or is there another abstraction that you thought of where you're
trying to generalize a use case beyond the specific team and an algorithm?
Yes so if we talk about abstraction layer FB learners flows
contribution I would say and we talked about this on on Facebook log is
I think we nailed the right upstraction it's a workflow and a workflow consists
of an operator that takes generic data whatever data types you want
and gives generic outputs. The nice thing is that once you have an operator you
can create any workflow you want but what's even more powerful is the entire
workflow can become an operator and yet another workflow and this composition
allowed us to build multi-layered platform. Let me give you a concrete example so
let's say you build a convolutional net that takes in an image and produces a
model that classifies based on the data and the labels we offer that in itself is
extremely powerful requires someone who's deep in in convolutional nets and deep
learning but at the same time it's still hard for a lot of other machine learning
users even data scientists to use so what you can do is you can wrap that in
another workflow that simplifies it by saying just give us the data and we'll
do hyper parameter tuning on your behalf and then you can wrap that with another
workflow that makes it more useful from a business case so
filtering images and in different scenarios like if you're filtering them to
remove explicit content is different than if you're filtering them to
propose an image for you to share later so these are all different use cases so
essentially that multi-layering allowed us to scale and the most important part is
making everything shareable and reusable so whenever some team builds
something every other team at Facebook has the opportunity of reusing it
and to make it reusable we had to make it discoverable so we created search
we would rank these workflows by how many times they've been used how many times
they've been successful so that the rest of Facebook which started growing
into the thousands would know like oh this is the most popular convolutional
network workflow or this is the most popular text classification workflow
and so on so that was very useful at Facebook and it helped spread adoption
Facebook in a lot of ways has demonstrated a huge commitment to
open source and open is generally if you look at
the kind of the bottom of the stack they do open compute at the top of the
stack they're doing things like PyTorch and Onyx but they haven't
you know open source the platform and I've had conversations on the
podcast with folks on the T man while I didn't ask this my sense was that
a lot of the way things are done or work are very Facebook specific like
yep there was no Kubernetes when we started this so we're doing our own
distributed compute the connections to data is that kind of yeah no that's
absolutely right once you start going into end-to-end machine learning
unlike PyTorch which is heavily contained the integration into whatever
infrastructure system you have is a much bigger component and so when we were
looking at open sourcing of the learner flow we had to open source the rest of
Facebook with it now the beauty of Kubernetes is that it gives you this
abstraction layer and through my time at Google we invested in
Qflow pipelines which is you can think of it as a moving workflow engine that
you can take with you wherever Kubernetes exists yeah yeah speaking of
Google after Facebook you went to Google can you talk a little bit about yeah
absolutely so I was very passionate about you know building machine learning
and helping tools or platforms and helping others adopt machine learning and
frankly there's no better place to do this than being at Google because of
its amazing machine learning brand amazing machine learning research
capabilities and Google Cloud and so that trifecta was extremely
exciting for me and I joined Google and you know I just like my time at
Facebook was extremely amazing but then seeing the platter of machine learning
use cases from healthcare to autonomous vehicles to
finance and so on just was fabulous and amazing like there's a lot of
diversity in machine learning so you joined Facebook at
in 2012 and Google in 2017 they had this amazing machine learning brand
the work was all done they were much further along
Google you mean Google so not necessarily actually Google and Facebook their
investments in machine learning follow their strategies so let me explain
what I mean by that Google has a very broad set of products like documents
doorbells cameras all you name it Facebook is far more focused okay right and
so when you look at machine learning investments Google has a broad
portfolio Facebook is far more focused there are places where Facebook is more
is better or advanced and vice versa the nice thing is that the two are
complimentary so I'll give you an example I think PyTorch demonstrates
Facebook's focus on usability and ease of use but then you look at Facebook
Google's broad portfolio of research it demonstrates
its breadth so I won't say one is better than the other they just have two
different styles that they've inherited from how they invest in technology in
general one of the themes that's
recurred in my interviews here and beyond this conference is the idea that
right now productivity and machine learning is primarily a usability
challenge as opposed to a you know a modeling challenge for example would you
agree with that or I agree to a very large extent to that that that's
absolutely right and that's one of my you know pieces of advice that I give
to people who are trying to build a new platform it's not necessarily about
sophistication because your end customer may not need it yet right your end
customer might have a usability problem and and through Google Cloud we found
that different customer types had different usability issues even the very
sophisticated customers who would come to us and say just give me GPUs even the
usability of giving them a GPU easily and clearly meant a big difference to them
so I think my advice is do not ignore usability
machine learning is obviously a very deep technical area but approach it with a
product sense and that's why at Google and at times that Facebook designers and
user-experient experts were my friends because I would ask them to help me
figure out where the usability bottlenecks that users are suffering from and
then if we solve them you see massive increase in productivity are there
examples of where designers have kind of come in oh yeah
what you thought about a problem absolutely so one example is at Google we had a
fantastic user experience team and we were building a lot of great machine
learning tools for text and image and and so on and then what we noticed is
that our users wanted to combine all these together
right and so our our we deployed our UX team and they would sit
with our users to go through an end-to-end machine learning workflow
and those users are other companies and then when we showed them these end-to-end
workflows you could see how it just thinks click in the eyes of our users are
like oh I understand why it takes so long because I would spend so much time in
this part like preparing data when I thought that the hardest part was using
TensorFlow but I actually need to invest in improving this so that was one of
the examples and it just happened again and again and became our most
favorite topic with customers that customers would come to us and say
where's your UX team so it was really interesting
awesome so you've been at cruise for about six months now yes
what's your why cruise and what's your role yeah absolutely I
so I started in machine learning in 2012 when things were just ramping up and
not a lot of people thought that machine learning is the
sexiest thing I actually see another trend that is about to happen and that's
the domain of autonomous vehicles I think that's going to push AI to a whole
new level in terms of the depth of the problem
and in terms of scale so let me give you concrete examples
most of the machine learning applications that are dominant in the industry
today are either advertisement or recommendations for movies or
products and these are very decent and extremely impactful
applications but if you compare them to what a car needs to do
navigate the roads of San Francisco safely the decision making is
maybe an order of magnitude less so the car has to
track so many objects including pedestrians
funny pedestrians who might be wearing a palm tree costume the car needs to have
common sense that happens here in San Francisco
I've seen a gentleman who had a bike with a four trolley system behind them
so you see a lot of these interesting things and then the car needs to
predict what these different agents are going to do
and so the decision-making is very complex and you need to do that in a hundred
milliseconds so the problem is far deeper and that just pushes
AI to new limits the other thing that is really important is
the accuracy required is very high in order to drive a car safely
no one gets hurt if you show them a bad ad or a bad recommendation
right and what's interesting is that you can learn from that but
in autonomous vehicles we have to push our accuracy limits and then finally
every car moving in the street has multiple sensors
so they have multiple cameras multiple lidars that are generating gigabytes of
data a second and when you have multiple cars of these roaming around
the data scale is actually gigonomous
so scale is an interesting point we had a really interesting exchange
early on when we were talking about the you participating in the conference
and I kind of approach you with hey you are at these huge scale places
Google and Facebook that you know nothing's bigger than that right and you're
like hold on autonomous vehicles is way bigger scale
elaborate on that you know how do you think about the two relative to one
oh absolutely here's a way to analyze scale if you look at your training data
right don't just look at the number of rows but look at the size of a record
one record most of the time when you leverage when you leverage recommendations
it's tabular data the record size is not huge
but if you look at the record size for an autonomous vehicle
it could be thousands of lidar points
multiple you know tens of thousands of pixels
even audio matters because the car needs to listen if an
emergency vehicle is coming around we actually need to figure out if
if a pedestrian is waving to us or looking at the car or looking at the phone
so the record is just far bigger so that's one example of scale
there's another thing that is interesting machine learning is just part of
the application it's it's it's among so in web development or web-based
applications like recommendations the tool chain is well developed
in autonomous vehicles we're still innovating that we're still building it
um and we're still trying to scale to the amount of data
and um that's one other example of how scale matters in autonomous vehicles
because the tool chain doesn't yet exist um we're in we're inventing that
as we're inventing the cars themselves
are scale and the need to build out the tools or those that the only challenges
that you face or are the problems themselves in early
challenging all of them but they are in what ways yeah i mean the
you get into a cycle of like i can solve this problem if i could just scale
then after you scale okay i solve this problem now i i discover a new problem
and i need to scale further so one of the things that attracted me to
the company is this understanding the interplay between the applied research
problem and the underlying tooling and that's why um our co-founder Kyle says
he's building two things he's building the car and he's building the tools
that are going to build the car because no one has no one has built that before
if you compare this to the web world the tools the tool chain is far more mature
we've been building web applications and mobile applications for
for a couple of decades now and so the tool chain is far more mature but
you look at autonomous vehicles that's just not there it cruises your approach is
multimodal in terms of the types of information that you're taking in off the
vehicle you've mentioned LiDAR you've mentioned imagery you've mentioned
sound even uh within all of those are there specific categories of problems
that are uh key or oh yeah yeah i can list so many i mean the basic is just
detecting um objects in the scene understanding that this is a car
and that the scar is heading this way um understanding whether the scar is moving
or not um you have the same problem for pedestrians bicycles and now scooters
and all of these agents have different behaviors and it's not just
enough to say this is where they at now you also need to predict what are they
going to do in the future and so behavioral prediction is also another problem
one of the other interesting areas to apply machine learning which i don't think
people know uh a lot about uh autonomous vehicles the style of driving how fast you
break and how fast you accelerate uh may not
necessarily affect safety but affects your experience as a writer
not so because if you break hard um the writers may get nauseous
right and so the driving style so my wife tells me
exactly and so the driving style itself is a machine learning problem i mean i
think it's it's a Pandora box like frankly um i went there because the the
number of machine learning problems is just endless and i think it will
it will it will be an exciting place for anyone excited about
machine learning uh problems or machine learning tools
and one of the ways you were introduced to cruises that they were doing some
of their work on the google platform can you talk a little bit about
yeah how you're platforming uh the you know machine learning i cruise today
so google cloud we offer multiple sort of suites of products to our AI
customers cruises obviously an AI company so they were mostly
focused on the lower level infrastructure like GPUs and some tooling around it
um i remember my first meeting with cruise and i was like okay well you know i'm
getting introduced to these people they seem really enthusiastic
and then i look at our numbers and i start seeing the GPU usage
you know uh rocketing up to the extent that we have to go and
you know um scrambled to get them more GPUs and i was like something is happening there
um and for me you know you know a company's uh focus on machine learning
by how much they spend on the infrastructure and how much they use it and so
it's very clear to me that something big is happening there
and then i visited them a few months later and the progress rate
was phenomenal um so i joined uh there um a few months ago and it was
eight months into building their own machine learning uh dedicated platform
and it just advanced uh really quickly and just in the five months that i've
been there it even advanced further um so i'm really glad
them there because the problem is deep the
pace is really fast uh and that's something i enjoy and i think it's very
important for machine learning um and i get to again redefine what
the future of machine learning i believe is going to look like because i
believe in uh just like ads and and and recommendations
propelled the application of machine learning in the industry the last three
to five years i think in the next five years it's going to be robotics
and autonomous vehicles and it's going to push machine learning to levels we
haven't seen and i'm really excited about that period i think machine learning
and AI will fulfill their promise uh through the vehicle of robotics
uh so you you you're bringing a whole an incredible wealth of
platform building experiences to a new problem one that has unique
challenges how do you customize you know what you've
done before what you've learned or what you believe about you know
delivering platforms to that specific problem you know both
generally philosophically but also you know concretely what does the cruise
platform look like sure so i think for cruise particularly and this is
something i did super well at facebook it's the interplay between applied
research and platforms how can you scale applied research
by shipping it through a platform because applied research and machine
learning is costly and you don't want every team every sub team to do their
own applied research what you'd rather do is if one team innovates you want
everyone else to use it and so that interplay is important is that is is applied
research the print your primary user at cruise as opposed to data
scientists machine learning engineers that are both other function all of
these are all in in by org so the applied uh research
part of the autonomous vehicle the data scientists and the machine learning
platform are all one community that's essentially cruise the eye and that's
one of the things that i think is unique about cruise often if you see
companies who split the two in the early days at
facebook these were combined google also the machine
intelligence group is also a combined group and i think that approach is
really important because the platform evolves through the demands of the
research scientists and and the the data scientists
but also the platform has an ability to influence them and
improve their research so that sort of yang and yang is very important
in terms of um general advice about a platform i would say
first thing is what i mentioned bring your scientists and your platform
builders together uh the second thing is uh be extremely
customer driven uh sometimes it's enticing to chase a very sophisticated
scenario but that may not be what you needed the moment
so be customer driven the the third thing is be careful bringing
biases of other experiences so i often seen that big data techniques
failed for machine learning um so as an example if you use map
produce um it's just it doesn't scale as well as one
gpu machine and i had this example at facebook where there's a sophisticated
graph processing system it ran on 500 machines
and it ran slower than one single machine um and ran even
much much slower compared to one gpu so um bringing some of these biases
is dangerous and then finally i believe a proper platform is an algorithm
agnostic platform um that's the basic minimum level of
extensibility uh that a platform has if you build it around an algorithm
machine learning changes so much what is hot today is
tomorrow's um is is tomorrow's deprecated algorithm
and so if your entire platform is basically based on a bunch of them
then you're going to be wasting a lot of work and effort
a lot of teams struggle with uh this generalizability
aspect that you're mentioning you know do we support a specific
framework do we support a bunch of frameworks we support specific algorithms
versus a bunch of algorithms do you think there's a certain scale that
you have to be at before you can afford to do to be general
or is that something that you need to commit to
independent of the size that you're at well it depends on the company i
think we made an early decision in 2014 at facebook
that we are going to generalize because it was very clear that the company
is going to require different algorithms different use cases and we don't
want to reinvent the wheel um but maybe a different
different companies have different uh circumstances so just work it
backwards from where you think the customer will be not today
but in three years um i believe companies like facebook,
cruise, google and so on will benefit from a general platform
um smaller companies may benefit from more specialized platforms like if you're
a fintech company and you know you're not going to be dealing with
images at all and there's no value for you then focus on tabular data
and build your platform that way um but if you're a company that has mixed
sources of data very likely you need to generalize
um curious about how you how you approach the organizational side of things
you mentioned that you've got uh all of the kind of key
customer groups uh in the same org as the platform and that's key are there
other things that you've uh learned or believe organizationally that
require then are required to make this successful. Yeah you know over my time at
facebook and google and in cruise i've ran organizations for AI
that consisted of different uh functions
not just machine learning experts um and my advice is treat all of them
equally you need them all to deliver a good machine learning
product and so as an example at facebook one of the very early decisions
we realized that machine learning has a usability problem so we need to hire
user uh interface ui people and we elevated them to the same level as our
researchers because they didn't want to join a team where they felt they're
going to be second class so um a big believer in this cross functional uh
mixture of talent and actually what's interesting is they
each function brings its diverse uh perspective and that aggregation of
perspectives creates really fantastic machine learning
product. So where do you see platforms going
overall or machine learning in kind of the enterprise context?
Well i'm going to be biased because i've made my bet through google cloud i
think um there's going to be a lot in kubernetes um and that's the reason why
we invested in q-flow i think um uh notebooks um interacting well with machine
learning workflows that's why q-flow has a notebook solution and has q-flow
pipelines and then i'm very excited about the ability to share
so if someone builds a interesting machine learning component or an interesting
machine learning workflow how can they share this with the rest of their
company or the rest of the community? So i think these um pillars are
necessary for successful machine learning platforms
and i believe cloud providers are going to play a very big role
in that aspect but i think it's going to be on kubernetes.
Nice i should mention that i have not seen them yet but uh
david aronchick one of the founding team members of q-flow is here somewhere
and uh there's quite a bit of interest in a
q-flow session in the unconference if that's of interest uh definitely check
that out uh who's saying thanks so much for joining us here at twomelcon AI
platforms. Thank you very much. Appreciate it.
All right everyone i hope you enjoyed our show straight from the main
stage at twomelcon AI platforms. For more information about today's show
visit twomelai.com and for more twomelcon coverage
visit twomelcon.com slash news. Thanks so much for listening
and catch you next time.
