WEBVTT

00:00.000 --> 00:15.920
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

00:15.920 --> 00:20.880
people doing interesting things in machine learning and artificial intelligence.

00:20.880 --> 00:23.320
I'm your host Sam Charrington.

00:23.320 --> 00:27.520
This show you are about to hear as part of a series of shows recorded in San Francisco

00:27.520 --> 00:32.040
at the Artificial Intelligence Conference, which was hosted by our friends at O'Reilly

00:32.040 --> 00:33.840
in Intel Nirvana.

00:33.840 --> 00:39.040
In addition to their support for the event itself, Intel Nirvana is also our sponsor for this

00:39.040 --> 00:41.400
series of podcasts from the event.

00:41.400 --> 00:45.640
A huge thanks to them for their continued support of this show.

00:45.640 --> 00:50.680
Make sure you check out my interview with Navine Rao, VP and GM of Intel's AI products

00:50.680 --> 00:56.000
group, and Scott Appland, director of Intel's developer network, which you can find at

00:56.000 --> 01:00.360
Twimbleai.com slash talk slash 51.

01:00.360 --> 01:06.400
At the AI conference, Intel Nirvana announced DevCloud, a cloud hosted hardware and software

01:06.400 --> 01:13.280
platform for learning, sandboxing and accelerating the development of AI solutions.

01:13.280 --> 01:19.520
The DevCloud will be available to 200,000 developers, researchers, academics and startups

01:19.520 --> 01:23.400
via the Intel Nirvana AI Academy this month.

01:23.400 --> 01:30.000
For more information on the DevCloud or the AI Academy, visit intelnervana.com slash

01:30.000 --> 01:31.760
DevCloud.

01:31.760 --> 01:37.800
My guess for this show is Paul Tepper, Worldwide Head of Cognitive Innovation and Product

01:37.800 --> 01:43.120
Manager for Machine Learning and AI at Nuance Communications.

01:43.120 --> 01:48.880
Paul gave a talk at the conference on critical factors in building successful AI-powered conversational

01:48.880 --> 01:50.600
interfaces.

01:50.600 --> 01:57.440
We covered this and a bunch of other topics like voice UI design, behavioral biometrics,

01:57.440 --> 02:01.200
and other interesting things that Nuance has in the works.

02:01.200 --> 02:04.200
And now on to the show.

02:04.200 --> 02:15.920
Alright everyone, I am here at the AI conference in San Francisco and I'm with Paul Tepper,

02:15.920 --> 02:22.680
who is the Worldwide Head of Cognitive Innovation and the Product Manager for AI and Machine

02:22.680 --> 02:28.080
Learning at Nuance Communications, the Enterprise Division of Nuance Communications in particular.

02:28.080 --> 02:32.840
I had the pleasure of meeting Paul at the AI conference in New York just a few months

02:32.840 --> 02:38.760
ago and he was kind enough to volunteer to jump in the hot seat.

02:38.760 --> 02:40.000
So welcome Paul.

02:40.000 --> 02:41.000
Thank you.

02:41.000 --> 02:42.000
Good to be here.

02:42.000 --> 02:43.000
Absolutely.

02:43.000 --> 02:44.000
Absolutely.

02:44.000 --> 02:48.960
So let's start by having you introduce yourself to the audience and talk a little bit about

02:48.960 --> 02:52.840
your background and how you got into Machine Learning and AI.

02:52.840 --> 02:53.840
Sure.

02:53.840 --> 02:58.600
Well for about a year now I've worked at Nuance Communications with our Enterprise Division.

02:58.600 --> 03:01.280
I lead a team that has a few functions.

03:01.280 --> 03:05.640
One of our main functions is identifying high value problems for which the company doesn't

03:05.640 --> 03:11.000
yet have a solution and working with our large corporate research division to see if we

03:11.000 --> 03:16.360
have new forward looking research that could be sort of productized or prototyped to get

03:16.360 --> 03:21.240
in front of customers as a way to kind of move innovation in product, give the product

03:21.240 --> 03:25.920
manager and teams across the company new opportunities and things to look at there.

03:25.920 --> 03:30.000
I did my PhD at Northwestern, my focus was on computational linguistics particularly

03:30.000 --> 03:31.000
in dialogue.

03:31.000 --> 03:35.640
It's had a lot of work on nonverbal behavior, gesture in particular and I also spent

03:35.640 --> 03:39.520
a few years prior to Nuance working on a startup not around anymore, it was called

03:39.520 --> 03:46.920
Citibon and we focused on building cloud-based NLP platform that really focused on human

03:46.920 --> 03:51.600
and loop computing and crowdsourcing as a way to quickly build data sets out to build

03:51.600 --> 03:53.120
custom models for NLP.

03:53.120 --> 03:54.120
Okay.

03:54.120 --> 03:58.960
I don't think I realized the Northwestern connection, I'm a PhD job out at it.

03:58.960 --> 04:00.760
I was really impressed.

04:00.760 --> 04:01.760
Yeah.

04:01.760 --> 04:03.000
Engineering on my side were you engineering or?

04:03.000 --> 04:04.000
Yeah.

04:04.000 --> 04:08.480
I helped to found this program called the Technology and Social Behavior Program that

04:08.480 --> 04:13.920
was a joint degree in computer science and communication studies of all things but that's

04:13.920 --> 04:16.760
where we ended up in communication studies doing a lot of work at that time.

04:16.760 --> 04:17.760
Okay.

04:17.760 --> 04:18.760
That was super interesting.

04:18.760 --> 04:19.760
Super interesting.

04:19.760 --> 04:20.760
Do you miss Evanston?

04:20.760 --> 04:22.760
I'm more of an East Coast guy.

04:22.760 --> 04:26.640
I am an undergrad at Rutgers and I spent a year in Scotland and my master's out there

04:26.640 --> 04:30.400
so I traveled around quite a bit but I'm definitely an East Coast guy.

04:30.400 --> 04:31.400
Nice.

04:31.400 --> 04:32.400
Nice.

04:32.400 --> 04:38.160
I think the folks will get a little bit more about what you're up to now if you maybe

04:38.160 --> 04:41.840
spend a few minutes talking about nuance and what nuance is doing.

04:41.840 --> 04:42.840
Yeah.

04:42.840 --> 04:48.280
So nuance is a fairly large complicated company with about 14,000 employees and several

04:48.280 --> 04:49.280
different divisions.

04:49.280 --> 04:54.280
We have a division that focuses strictly on mobility, mobile products, automotive products.

04:54.280 --> 04:59.680
We have ASR and a lot of cars that people drive due recognition for cars, the in-car systems.

04:59.680 --> 05:05.480
We've got a healthcare division that is some of the top systems for dedication for doctors

05:05.480 --> 05:09.840
to do electronic medical records and imaging division and my division in particular focuses

05:09.840 --> 05:15.360
on enterprise communications and we have two main product areas or areas of focus and

05:15.360 --> 05:19.800
that's one IVR systems or interactive voice response and that was one of the first commercial

05:19.800 --> 05:23.480
applications of speech recognition systems that you can call into and instead of doing

05:23.480 --> 05:27.760
kind of dial tone menus you can just say what you want conversationally and more recently

05:27.760 --> 05:30.440
our focus has been on the digital side.

05:30.440 --> 05:34.000
Now they're called chatbots but we've been calling them virtual systems for a long time

05:34.000 --> 05:37.240
and actually there's a lot of overlap in those two technologies.

05:37.240 --> 05:44.120
So a lot of the technology that has been built out for IVR so to recognize intent, to recognize

05:44.120 --> 05:49.480
concepts and do entity extraction inside sentences and then also the dialogue build out the dialogue

05:49.480 --> 05:52.240
flows with other graphs or trees to build through a dialogue.

05:52.240 --> 05:55.840
A lot of that actually works similarly in the chat world.

05:55.840 --> 05:59.240
However in the IVR world the utterances tend to be a lot shorter.

05:59.240 --> 06:02.520
The chat world will tend to talk a lot longer so different complexities there.

06:02.520 --> 06:06.360
That's an actually an active area of research for us so how do we use user experience?

06:06.360 --> 06:10.960
How do we use UX to get people to talk longer in IVR so we have more because the natural

06:10.960 --> 06:16.320
language understanding or NLU as we call it has really far outpaced what people actually

06:16.320 --> 06:21.480
say today in IVR systems so that's an interesting technical challenge for us.

06:21.480 --> 06:26.400
Yeah I think of when I think of IVR I think of call center and I think of the objective

06:26.400 --> 06:30.480
on both the person that's interacting with the call center and the company that's making

06:30.480 --> 06:34.960
it available is to keep the interaction as short as possible and it sounds like the

06:34.960 --> 06:38.240
technology is allowing us to go the opposite direction.

06:38.240 --> 06:43.200
I think the technical terms in the industry are things like containment so keeping the

06:43.200 --> 06:47.640
user contained to the IVR as opposed to transferring to a live agent or using live agents

06:47.640 --> 06:51.800
are more expensive and not just expense it's actually hard to staff them even if you

06:51.800 --> 06:55.000
have all the resources in the world it's hard to hire up call centers that are big enough

06:55.000 --> 06:59.240
for some companies to even handle attractive if they even wait on limited budget.

06:59.240 --> 07:03.200
So containment's a big one and our one's first contact revolution is a popular KPI in

07:03.200 --> 07:07.240
the industry so that you can have a you don't have to call back you know your resolves

07:07.240 --> 07:13.000
within that first call so it's not always about short but it tends to be about can you

07:13.000 --> 07:18.000
build self-service so being able to let the user call and interact with a system that they

07:18.000 --> 07:21.600
can solve their problem automatically and I'll talk about that in my talk a little bit

07:21.600 --> 07:25.640
about some of the statistics that have come out recently showing that today especially

07:25.640 --> 07:29.560
with like younger generations and consumers people really don't care whether they're

07:29.560 --> 07:34.120
talking to a machine or a human they just want to get their problem solved and in some

07:34.120 --> 07:38.360
cases there's even times prefer it prefer to talk to a human you know sensitive situation

07:38.360 --> 07:42.600
sorry prefer to talk to a bot maybe a sensitive situation you know you have to call in and

07:42.600 --> 07:46.360
talk about you know I need a change of flight because of a death in the family or something

07:46.360 --> 07:50.200
in some cases like that you don't it's sensitive and you don't actually want to talk to

07:50.200 --> 07:54.200
a person even though people have this feeling that emotional intelligence is so important

07:54.200 --> 07:58.280
sometimes it's actually you don't want to get into it you just want to get your transaction

07:58.280 --> 08:04.840
done yeah yeah so you mentioned your talk what's the title of your talk I believe it's a long

08:04.840 --> 08:11.320
title I think it's critical factors in conversational interfaces design and commercial interfaces

08:11.320 --> 08:15.880
they don't know the whole thing memorized so kind of lessons learned in best practices that you've

08:15.880 --> 08:19.720
come across along the way yeah it'll be a mix of lessons learned in best practices as well as

08:19.720 --> 08:23.960
some of the newer things we've discovered and developed new ones okay so walk us through walk us

08:23.960 --> 08:28.120
through those yeah sounds like a fascinating topic put me on the spot I don't think they have

08:28.120 --> 08:34.200
them all memorized at the point I think I practiced your talk I've got about I think 10 at this point

08:34.200 --> 08:37.800
that we're going to talk about yeah I think I had previously done a version this talk where I had

08:37.800 --> 08:42.920
six and this talk that talk was 20 minutes so I thought okay 35 minutes I've got to beef it up a

08:42.920 --> 08:48.040
little bit yeah well just expand upon some of the ones that I briefed three to one through so I

08:48.040 --> 08:53.720
kind of go there's like a high level of things like context and personalization so if you're

08:53.720 --> 08:59.480
on a website and you're browsing let's we deal a lot with like banks and insurance and those kind

08:59.480 --> 09:05.400
of enterprises and you're in the auto insurance part of the website and a chat bot pops up and

09:05.400 --> 09:09.240
says can I help you it actually you know that's the typical thing they're going to say right can I

09:09.240 --> 09:15.240
help you but at this point in the website basic UX you know we'll let you know you should say

09:15.240 --> 09:22.840
hi so and so hi Paul how can I help you with auto insurance those basic principles of UX have not

09:22.840 --> 09:27.480
totally been carried over yet into chatbot world so it's those kind of things like building those

09:27.480 --> 09:31.160
integrations into the systems it's the websites and stuff a lot of times these chat bots are

09:31.160 --> 09:34.920
come from a different platform so you have to actually build those integrations between the

09:34.920 --> 09:39.720
companies website and the chatbot and those kind of things basic UX but they're not totally there

09:39.720 --> 09:46.360
yet in the chatbot world it's funny you you mentioned that I've been kind of on the dl evangelizing

09:46.360 --> 09:52.520
this idea that that a lot of you know what we've learned so much about user experience design

09:52.520 --> 09:59.240
in the web world and in mobile and kind of in these other interface technologies that hasn't really

09:59.240 --> 10:06.280
made it into or we haven't formalized to the degree yet or in and around AI and artificially

10:06.280 --> 10:11.800
intelligent user interfaces and I think the you know so I call it intelligent design but that's

10:11.800 --> 10:19.480
kind of a worldwide term. I haven't come up with the ideal the the ideal replacement for that one

10:19.480 --> 10:27.560
but as certainly you know chatbots are the kind of the tip of the spear so to speak but even devices

10:27.560 --> 10:33.000
like your nest thermostat or something like that there's I think there are like unique things

10:33.000 --> 10:39.000
that you need to take into account to you know make sure that users are comfortable with the

10:39.000 --> 10:44.200
fact that this thing has some intelligence and also kind of signal to them how to interact with

10:44.200 --> 10:50.200
the intelligence. That's interesting now nuance has been doing we call vui design for a long time

10:50.200 --> 10:54.200
or voice user interface design and many of the people who design many of them backgrounds in

10:54.200 --> 10:59.800
linguistics PhDs in linguistics even who design the flow of the conversation and we'll do you know

10:59.800 --> 11:05.480
user testing AB testing etc to figure out what the rest flows are and you'll see these people

11:05.480 --> 11:10.200
who the people with this experience are being scooped up now by google and amazon so you look

11:10.200 --> 11:15.000
at the people now who google has a whole vui design team now for a assistant as is amazon a lot

11:15.000 --> 11:19.880
of former nuance people because we've been doing this for a long time in the ivr world and it turns

11:19.880 --> 11:26.440
out like a lot of those a lot of the basic principles of how a conversation works without a screen

11:26.440 --> 11:32.280
transfer over to these note these kind of like iot devices and it's different when you have a screen

11:32.280 --> 11:37.320
when the screen we actually know a lot about a lot about web design ux and that's another problem

11:37.320 --> 11:41.880
right like there's this area of overlap between a non-like thinking of a venn diagram of like

11:41.880 --> 11:46.680
conversational user interfaces on or voicers in a race to sign web user interface design and that

11:46.680 --> 11:51.560
little spot in the middle of the overlap in the venn diagram where this weird world of okay well

11:51.560 --> 11:55.160
the conversational principles aren't going to cover it completely the web principles are going

11:55.160 --> 11:58.040
to cover completely so you have to kind of merge those two together and figure out things like

11:58.040 --> 12:03.400
okay well on this part of the website the person's browsing you know looking at whatever product

12:03.400 --> 12:07.720
the conversational agent needs to know about that stuff that's one of the things i'll be talking about

12:07.720 --> 12:12.120
another thing is security making it easier for people to either authenticate via traditional

12:12.120 --> 12:17.720
password or SSO as well as new ones as voicebound metric product so you can really transfer you over

12:17.720 --> 12:22.760
to say like my voice is my password use a voice print to identify i don't get the sense that that's

12:22.760 --> 12:29.400
very popular i haven't read it no no no it's it's really new cutting edge and it's it's it's

12:29.400 --> 12:33.640
easier than mobile devices from the mobile devices where we're building virtual distance there

12:33.640 --> 12:37.800
where the whole interface is spoken it's a little bit more you know part of the flow but we are

12:37.800 --> 12:43.320
to vote prototype systems now or you can actually voice print if i or a bank on the web or

12:43.320 --> 12:51.000
oh wow yeah that's a huge it's a huge friction point i think of the the places that that

12:51.000 --> 12:56.120
recognize my number and based on my number you know associate me with a record like the airlines

12:56.120 --> 13:00.200
for example have done a really good job of coming up to the speed on this in the past few years

13:00.200 --> 13:05.000
but then there are other places where they're like okay type or say your password and i'm like well

13:05.000 --> 13:10.680
you know it's like 26 characters and it's in my password safe thing or yeah there's no way

13:10.680 --> 13:14.840
i'm either going to type it or say it yeah so and this is this is another it's a big area of

13:14.840 --> 13:18.760
AI machine learning you know is these systems are all AI machine learning driven these voice

13:18.760 --> 13:23.880
biometric systems are sitting there's also face print identification now we do some work there

13:23.880 --> 13:27.800
and we'll start to see other kinds of biometrics too like behavioral biometrics i've heard of this

13:27.800 --> 13:32.680
where the way a person interacts with a website the way they move their mouths this the cadence

13:32.680 --> 13:37.880
at which they type etc that also creates a unique fingerprint of that person very very hard

13:37.880 --> 13:44.040
to spoof fingerprint i think my first experience with that is with coursera like when you when

13:44.040 --> 13:48.840
you're taking a coursera course like the andering you know deep learning course like you there's

13:48.840 --> 13:54.120
an honor code and you have to type out this honor code thing that says that you know this is you and

13:54.120 --> 13:58.920
when you're taking one of their exams you type this passage out again and it uses that to

13:58.920 --> 14:02.920
verify that you're you i didn't see that i think if you don't if it doesn't think you're you

14:02.920 --> 14:07.560
you have to take a picture with your webcam that's cool how okay that's really cool yeah so that's

14:07.560 --> 14:12.920
that's another gets a reducing that friction point and i'll be spending a while talking about

14:12.920 --> 14:18.520
some new techniques that we're using to try to incorporate unsupervised learning into our pipeline

14:18.520 --> 14:23.560
now this is kind of a frontier area for a right now the majority of it's all supervised at this

14:23.560 --> 14:32.200
point but we're looking at methods where you can take in a set of chat logs or voice conversation

14:32.200 --> 14:39.000
transcripts and the big thing with chatbots and with conversational systems is the first layer is

14:39.000 --> 14:44.200
the nlu the intent classification so what are the what's the intent of the burden of saying such

14:44.200 --> 14:48.360
that then you can then you know respond to that intent whether it's like check my balance or pay

14:48.360 --> 14:54.040
a bill or working on looking at data sets and extracting those intense automatically through unsupervised

14:54.040 --> 14:59.960
learning he kind of double click on that and give a little bit more detail there yeah sure so

14:59.960 --> 15:04.120
unsupervised methods one of the big things they tend to do is group things together automatically

15:04.120 --> 15:10.040
yeah clustering or hierarchical clustering or various kinds of methods that bucket things together

15:10.040 --> 15:15.240
so i can't give out all the secrets off there but that's part of it yeah that's part of it involves

15:15.240 --> 15:19.000
that and part of it involves other steps that can actually identify what the intense are of those

15:19.000 --> 15:25.240
cluster automatically so as a first pass this used to have to all be done manually our our

15:25.240 --> 15:28.600
we call them speech scientists and also our data scientists would have to go through the data

15:28.600 --> 15:33.000
to figure out what the intense were in a large data set as well as interviewing subject matter

15:33.000 --> 15:37.400
experts out of company now is the first pass but today we've managed to cut down a process that

15:37.400 --> 15:41.960
you know used to take hundreds of hours down to a few days months down to a few days by using

15:41.960 --> 15:47.240
this new process that we call intent discovery whereby you can bucket the data and then automatically

15:47.240 --> 15:53.000
identify what the intense are in the data then you can use those data use those that bucketing

15:53.000 --> 15:59.080
to automatically label the data so you get a first pass at like a labeled data set and bootstrap a

15:59.080 --> 16:04.680
model or train a model off of that put a model online now the idea here is that the system won't

16:04.680 --> 16:09.720
necessarily have the same accuracy as it would with a hand tuned system so respecting a hand

16:09.720 --> 16:15.480
to just be 85 90 percent accurate one of these bootstrap systems might be like 65 70 percent

16:15.480 --> 16:21.560
accurate but then what we do is we put that system online and for all the questions that the

16:21.560 --> 16:26.920
VA or the bot the vertus or the bot doesn't know we can pass off for one turn to we call it a hidden

16:26.920 --> 16:32.200
agent a person a human in the loop they can then check what the intent was for that and send it

16:32.200 --> 16:37.240
back to the system so the user ends up with this seamless experience of they're just talking to a

16:37.240 --> 16:41.320
bot would be with like a five second delay when it goes to the person or 10 second delay where it says

16:41.320 --> 16:46.120
hold on I'm checking with you know checking with one of my partners then we can use that data then

16:46.120 --> 16:50.280
train in the future and then we won't have to have that you know that missing data that loop in the

16:50.280 --> 16:55.320
future that makes sense no it makes it makes a ton of sense it I'm wondering does this

16:55.320 --> 17:02.120
create a new business model for nuance where we're in previously I'd imagine you're you selling an

17:02.120 --> 17:08.040
enterprise some set of technology whereas now it's you know the technology but also the service

17:08.040 --> 17:14.040
like are you providing the agents yeah that does this or are the you providing a you know a console

17:14.040 --> 17:19.880
that they can have their own virtual agents doing the checking yeah or both so yeah a few years

17:19.880 --> 17:24.840
ago about here two years ago we acquired a company called touch commerce which is a live chat

17:24.840 --> 17:30.040
platform they provide a whole suite of live chat they also they can provide the agents to you

17:30.040 --> 17:35.000
or they can just provide the interface to you so we have that which is really cool too because now we

17:35.000 --> 17:39.160
can if a VA doesn't know if a virtual system doesn't know the answer or chat button doesn't know

17:39.160 --> 17:43.000
the answer we can we could if a company wants to partner with us transfer that way transferred

17:43.000 --> 17:47.480
directly to our live chat but we also talk work with lots of companies who have their own live chat

17:47.480 --> 17:51.960
platforms a big one in Salesforce they provide live chats with really popular one of these days

17:51.960 --> 17:58.520
transfer to those agents we have a console we can provide to allow companies to have this to use

17:58.520 --> 18:03.800
their own pool of live agents to do this human assisted step or we can provide the software and

18:03.800 --> 18:07.720
the agents we've all different ways of working on it it's very you know we can customize and

18:07.720 --> 18:12.360
all different ways with that not to be too salesy here but you know we have all different ways

18:12.360 --> 18:16.040
of working on it and yeah it is it is a new it is kind of a new line of business the new way of

18:16.040 --> 18:23.320
thinking about it okay all right what else oh targeting that's another big area so when do you

18:23.320 --> 18:28.760
have a chat window actually pop up you know I think based on the way it's implemented now always

18:28.760 --> 18:34.440
always right yeah and it seems like and when I use these systems I it just seems like no rhyme or

18:34.440 --> 18:39.080
reason for I feel like a lot of times these systems it's just a clock or something right and like

18:39.080 --> 18:44.280
if you've been on the page longer than 30 seconds it pops up or if you're visiting the site on your

18:44.280 --> 18:50.280
mobile phone do it you know immediately secure everything else yeah see there's the UX that

18:50.280 --> 18:56.760
she's totally worked out yeah we we have a targeting engine that's constantly undergoing new

18:56.760 --> 19:01.320
prototypes and stuff but that's aimed at like when are you interact with the user how do you

19:01.320 --> 19:05.880
interact with the user in what way what language do you use what even down to like the colors and

19:05.880 --> 19:11.480
stuff on the interface and that targeting engine is based on all kinds of things like how long

19:11.480 --> 19:15.800
has the user been on the page is certainly one of them but what what have they put in their shopping

19:15.800 --> 19:19.000
car like they put something in their shopping cart and walked away so there's all these different

19:19.560 --> 19:25.000
inputs to the system that you can use to then tune when you're going to pop up that you know pop

19:25.000 --> 19:31.000
up that chatbot to ask if they want to talk to an agent or talk to Nina's the name of our

19:31.000 --> 19:37.480
registers talk to Nina talk to a chatbot and assuming it's machine learning driving that ultimate

19:37.480 --> 19:46.200
target decision how transferable are the models from one customer one one one website to another

19:46.200 --> 19:52.200
like are you training these models on a customer by customer basis or is there you know you have

19:52.200 --> 19:59.320
industry models or is there a generic model that outperforms just show the chat bottle yeah so

19:59.320 --> 20:04.920
there we do have generic sit generic setups you know for various verticals but when it comes

20:04.920 --> 20:10.280
down to a lot of this is this is a very difficult subject right now these days for us because a lot

20:10.280 --> 20:13.480
of our customers really feel very shown that they don't want the data share they don't even want

20:13.480 --> 20:20.840
the models shared you know so it's a new it's it's a it's even for when their chatbot pops up on

20:20.840 --> 20:27.160
their website anything it's a it's a it's a very tricky area that I think that our company I think

20:27.160 --> 20:33.720
a lot of companies today are having to deal with which is like how do you both be a competitive AI

20:33.720 --> 20:38.120
machine learning company while at the same time protecting the data of your customers in a way

20:38.120 --> 20:43.080
that they're comfortable and they can that like dealing with all the kind of compliance issues

20:43.080 --> 20:47.480
too because a lot of our customers are banks so it may even be that legally you can you know unless

20:47.480 --> 20:53.320
there's actually a specific consent for example we deal with a government agency in Australia and

20:53.320 --> 20:57.480
they I was reading one of their one of their privacy policy documents on our day and I was

20:57.480 --> 21:01.720
saying like unless you have explicit consent from a user like a pilot says I consent to use this

21:01.720 --> 21:07.080
or you sign some checkbox or something they can't use that data for anything else tuning a model

21:07.080 --> 21:13.320
even you know so this is really I think we talked about all you know all the exciting stuff in AI

21:13.320 --> 21:17.640
today and all the amazing things that are happening when it comes down to for a lot of businesses

21:18.200 --> 21:24.520
these are the real problems today it's not how do I scale a deep learning model or how do I

21:24.520 --> 21:29.640
productionize this system and get it working on you know going from one cluster to a thousand

21:29.640 --> 21:35.320
computers or whatever it's like the legal problems how do you actually deal with the data in a way

21:35.320 --> 21:40.360
that's safe for the company and for the user you know it's really like a huge somewhere you know

21:41.240 --> 21:48.520
right yeah I was just reading I forget what I think it was I think it was a particle in someone

21:48.520 --> 21:54.360
in his newsletter or something like that that was talking about how there's this huge gray area

21:54.360 --> 22:01.400
around copyright and data sets and you know basically everyone who's using for the most part

22:01.400 --> 22:08.520
these public data sets is kind of flying under the radar but there's this you know potential exposure

22:08.520 --> 22:16.600
where there's no established you know precedent around you know the extent to which copyright on

22:16.600 --> 22:21.960
a data set flows into the model for example and so potentially someone using this copyright

22:21.960 --> 22:28.520
data set to train the model could be creating a model that's you know has potentially owned or

22:28.520 --> 22:34.040
has some copyright liability with someone else so that's an example of this kind of meta concern

22:34.040 --> 22:39.880
that that your customers are thinking about do you have any perspectives on the you know the rise

22:39.880 --> 22:47.080
of the consumer voice interface devices the virtual assistance your Alexa's and your Google

22:47.080 --> 22:52.360
assistance and things like that yeah it's interesting I think a lot of that stuff it has to do with

22:52.360 --> 22:57.240
their APIs you know with those kind of systems we right now we have our our chat box integrates

22:57.240 --> 23:02.520
with like Alexa integrates with Google Home but there's certain things we can't do there's certain

23:02.520 --> 23:06.040
things we can't do so one thing we would really like to do a lot of our customers like a center

23:06.040 --> 23:12.440
banks right and with thanks this voice biometrics has become very popular recently but one thing we

23:12.440 --> 23:18.680
can't do right now is voice biometrics over Google and Alexa because they only send you text

23:19.240 --> 23:23.560
so at this point there they don't actually send you the audio signal they do all the ASR for you

23:23.560 --> 23:29.400
speech recognition and the TTS for you the text to speech and they have no way of sending out

23:29.400 --> 23:35.000
those signals so I think this is something that we've had huge strides in terms of the openness

23:35.000 --> 23:39.960
and the compatibility of these platforms with Alexa and now with Google Home but for years this was

23:39.960 --> 23:44.440
a big problem with Siri right with Apple if they had no ability to do 30 third party integration

23:44.440 --> 23:50.200
you couldn't say to Siri like you know play a song on Spotify for me so this is this is definitely

23:50.200 --> 23:56.520
like a big topic for new ones right now this idea of we call it cognitive arbitration where you have

23:56.520 --> 24:02.680
agents that sit like kind of Uber agents that sit in the middle of all these different IOT systems

24:02.680 --> 24:06.600
and coordinate those for you and bring that data together bring the systems together

24:06.600 --> 24:11.000
and those APIs together to talk to these different systems I know this is also a vision of Amazon's

24:11.000 --> 24:15.480
as well with being able to sit and like have their agent that has goes out and there's always

24:15.480 --> 24:20.200
different skills that they come to so this is kind of this is a newer topic for for new ones

24:20.200 --> 24:25.640
that are working on more recently is how you can use intelligence and reasoning and other kinds

24:25.640 --> 24:31.640
of machine learning to build agents that can sit in between all these different IOT devices and talk

24:31.640 --> 24:39.960
each other and do you see is there a role or any emergence of like standards or standardized

24:39.960 --> 24:45.320
approaches like for example you know there's tons of work that's been done around federated

24:45.320 --> 24:50.840
identity in the web and now this is you're introducing a whole other layer around biometrics

24:50.840 --> 24:57.160
does any of that kind of work transfer here do you think or we just like to or no no I think it will

24:57.160 --> 25:01.800
I think that this is word in very early days here so it's basically like I don't think the very

25:01.800 --> 25:05.640
beginning of the internet when these kind of standards were being built out you know like what's

25:05.640 --> 25:10.520
HTML and how does it work that's where we are today with AI so these issues the thing like you

25:10.520 --> 25:14.520
brought up with the data that those kind of issues haven't been solved yet like how do you there's

25:14.520 --> 25:20.360
no you know a patchy license for data at this point you know whereas that stuff you know to season

25:20.360 --> 25:24.600
software engineers and product managers now it's just kind of like second language they know

25:24.600 --> 25:28.440
with the with the licenses mean they know which what they can reuse which code can be leverage

25:28.440 --> 25:32.200
which can't what you had to declare what you don't etc but that stuff doesn't exist for data

25:32.200 --> 25:35.320
but it's an interesting point you know I hadn't thought about it but yeah I think that that'll

25:35.320 --> 25:40.120
come about and similarly with with these standards around interoperability I think that's

25:40.120 --> 25:44.120
something that we have teams at nuance we're working on and trying to kind of reach out to

25:44.120 --> 25:48.120
different partners because this is not a problem that's going to be solved by any particular

25:48.120 --> 25:52.520
company just in the same way that like you know JSON standards can't be solved by Google

25:52.520 --> 25:56.120
you know they can't just make a really great JSON parse on everybody take it and put it in

25:56.120 --> 26:01.000
their browsers or put in their systems it has to be you know standards based and community based

26:01.000 --> 26:05.720
so I think we are we are thinking about these kind of interoperability standards at this point

26:05.720 --> 26:12.440
very early days though right any other things that you covered in your talk that you want to

26:12.440 --> 26:17.880
share with us yeah I covered most of it yeah there's a couple of things like in the front

26:17.880 --> 26:23.800
matter of the cover of the talk that I was talking about which is that in this world of chatbots

26:23.800 --> 26:30.040
and virtual assistants it's surprising about how much of it isn't AI and isn't machine learning

26:30.040 --> 26:34.600
and we really there's a lot of companies will have like you know a dot AI in their name

26:34.600 --> 26:39.320
but everything is still like based on regular expressions and rules and that sort of stuff

26:39.320 --> 26:44.840
so or people or people yeah or people big time that's that's not always necessarily a bad thing

26:44.840 --> 26:48.920
but it's it's often part of the company's strategy in terms of you know having everything

26:48.920 --> 26:54.200
the beginning be run by humans as a way to gather data and then over time learn from it

26:54.200 --> 27:01.080
but that's something we try to help educate our customers about is how much of this actually

27:01.080 --> 27:07.000
is AI and machine learning and how much of it isn't today most of the AI and machine learning

27:07.000 --> 27:13.080
for us happens on the language understanding side of things so when the input comes in

27:13.080 --> 27:18.760
we can be able to categorize it using statistical models and LP models in order to route

27:18.760 --> 27:23.080
to the right response you know to give you the right response to a question we can also do

27:23.080 --> 27:26.680
things like energy extraction extractor concepts of you're saying something like you know I'd

27:26.680 --> 27:32.040
like to order a pizza or I'd like to order a large pizza a large vegetarian pizza with pepper

27:33.320 --> 27:40.200
peppers and onions almost at pepperoni be able to identify both that the intent was to order a

27:40.200 --> 27:45.320
large pizza that the toppings and the size and that sort of stuff a lot those categories that

27:45.320 --> 27:49.400
kind of technology now some of that stuff is standard but there's still quite a few you know

27:49.400 --> 27:53.000
different platforms out there for doing chatbites that don't offer that kind of you know that

27:53.000 --> 27:59.000
level of a machine learning and LP but beyond that played with that stuff in the past like api.ai

27:59.000 --> 28:05.160
it's a very manual and tedious process to build out those those entity trees exactly yeah and so

28:05.160 --> 28:10.280
you're it sounds like what you're describing is a way to learn some of that from the after data

28:10.280 --> 28:15.800
itself yeah exactly so that when it comes to when it comes to our intent discovery and bootstrapping

28:15.800 --> 28:21.240
process we're learning the intense automatically and building out kind of you could call it an

28:21.240 --> 28:25.640
ontology the the group of the intense than the various concepts that are associated with those

28:25.640 --> 28:30.440
intents but yeah we try to just like encourage people to be discerning and try to figure these things

28:30.440 --> 28:35.080
out when you're looking at a platform today I think the next frontier is going to be

28:35.080 --> 28:40.520
on the other side though there really isn't any system on the market today including ours

28:40.520 --> 28:45.080
that can automatically learn how to answer the questions especially if they're complicated

28:45.080 --> 28:50.760
back and forth dialogues so if it requires like a back and forth conversation those tend to be

28:50.760 --> 28:56.680
you know built out manually either as an enterprise in the enterprise you know by talking to

28:56.680 --> 29:01.240
subject matter experts or people are doing it themselves by figuring it out themselves that way

29:01.240 --> 29:06.760
that I think is different is the next frontier for this technology is learning how to answer questions

29:06.760 --> 29:12.360
and dialogue and a lot of now there are tons of people who say they can do that yeah there are a lot

29:12.360 --> 29:16.360
of there's what they tend to do though is you have to feed the system question answer pairs

29:17.640 --> 29:24.440
then it can learn to map new questions to those answers right this question answering

29:24.440 --> 29:32.040
but it's not dialogue that's if something exists sort of an FAQ can you identify if the question

29:32.040 --> 29:36.120
takes a different format though that it actually mapped to this question that's in the FAQ that's

29:36.120 --> 29:39.560
about a format I mean it could not be an FAQ it might be like a list of a thousand questions and

29:39.560 --> 29:42.920
answer pairs or whatever but I mean cutting edge research today I don't know if you remember

29:42.920 --> 29:48.760
with like the Stanford squad data set that Q&A data set where it's trying to answer questions

29:48.760 --> 29:53.240
off Wikipedia articles this is pretty cutting edge research at this point there's research teams

29:53.240 --> 29:59.400
across the world competing in this kind of thing but even that still is focused on you know the answer

29:59.400 --> 30:04.280
is in the article you know we're talking the kind of stuff nuanced is working on today that is

30:04.280 --> 30:07.960
one thing I forgot to mention we've got a product a project we're working on now called mean

30:07.960 --> 30:13.080
and knowledge where you can basically push a button to ingest a website or a set of documents

30:13.080 --> 30:17.560
then start doing question answering on it yeah and it it does leverage from the technology that's

30:17.560 --> 30:22.600
being used to answer like those to work with that squad data set but it also leverages technology

30:22.600 --> 30:27.800
from information retrieval search so it combines a few different areas machine learning as well

30:27.800 --> 30:33.240
as NLP and question answering so that and I like to think of this as low hanging fruit really

30:33.240 --> 30:38.280
because these kinds of questions that you actually have just a one shot answer to those are the

30:38.280 --> 30:43.000
candidates for automation today the things that we still really are still very early days in the

30:43.000 --> 30:49.640
research in is how do you actually learn a back and forth conversation that requires multiple

30:49.640 --> 30:54.520
questions and feedback going through a conversation with somebody from data I think it's the next

30:54.520 --> 31:02.360
frontier in the case of this of Nina knowledge so what degree is it you're doing like transfer

31:02.360 --> 31:09.720
learning off of a model trained on squad and applying that model to the website that's being

31:09.720 --> 31:16.040
ingested or is this process including like training up a new model on that website yeah the

31:16.040 --> 31:21.000
process is yeah certainly we start from scratch you know on each one each time we haven't we

31:21.000 --> 31:24.920
haven't gotten transferred learning like that into production yet today but those are certainly

31:24.920 --> 31:29.640
areas of research are working on is so one area where I don't know if I don't know if you'd

31:29.640 --> 31:34.120
call it transfer learning or not but you can certainly do things like learn word vectors you know

31:34.120 --> 31:37.880
from one data set and apply to another that's that is certainly like a form of transfer learning

31:37.880 --> 31:41.160
most people think about transfer learning I think today they're thinking okay I built this big

31:41.160 --> 31:46.680
multi-layer neural network and I'm extracting a piece of it and then using it on another data set

31:46.680 --> 31:51.000
I think it's still early days for that sort of stuff but certainly when it comes to word vectors

31:51.000 --> 31:56.280
or other kinds of vectors paragraph vectors document vectors etc that stuff can be transferred

31:56.280 --> 32:02.280
and it can be very helpful in improving the quality of a model pretty quickly where are we in terms

32:02.280 --> 32:07.240
of you know we've talked a lot about identifying the intent of you know an utterance or something

32:07.240 --> 32:14.120
that's typed into a chatbot but where are we in terms of you know more you may be more realistic

32:14.120 --> 32:19.800
kind of dialogues that have multiple intents or hidden intents or you know things like that you know

32:19.800 --> 32:24.440
and this is maybe a slightly different direction for the question but you know for a while we've

32:24.440 --> 32:31.400
talked about the IVR systems being able to identify the emotion and you know change or escalate

32:31.400 --> 32:36.440
the way the call is handled based on the emotion you know when I'm frustrated I try to make sure

32:36.440 --> 32:42.760
the IVR knows I'm frustrated and it never makes a difference I really love this question particularly

32:42.760 --> 32:47.960
the emotion part of it I really love that question because we've been working on it a lot lately

32:47.960 --> 32:52.120
yeah of what do you do with taxid sentiment right so that's basically tends to be in the

32:52.120 --> 32:56.520
seminar although there are some models now that classify things into like the five base emotions

32:56.520 --> 33:01.800
like anger happiness frustration says is like these you know old models of this there are some

33:01.800 --> 33:05.160
models that claim to be able to do that I don't know how accurate they are but sentiment that's

33:05.160 --> 33:08.680
at least one that you were pretty accurate we can get pretty accurate on that for the most part at

33:08.680 --> 33:13.480
the global sentiment of a sentence that doesn't always sufficient because there can often be two

33:13.480 --> 33:18.280
sentiments in a sentence you know I love this but I hate this what I do there so I'm getting off

33:18.280 --> 33:23.080
on a tangent but the reason I think this is really fascinating is because the real question is okay

33:23.080 --> 33:27.720
great so what do you do with what do you do when you know someone's pissed off what do you do when

33:27.720 --> 33:33.160
you know someone's frustrated and that's a really hard question because it tends to be what a

33:33.160 --> 33:38.840
company what a customer wants to do is figure out a way it's about containment right so how do we

33:38.840 --> 33:43.560
handle this without escalating to a person because that's going to a person's expensive but

33:43.560 --> 33:46.440
when you have a frustrated person the only thing we know how to do to know with the only thing

33:46.440 --> 33:52.680
we tend to do today is escalate to a person so I think what it's going to come down to is understanding

33:52.680 --> 33:56.840
that they're these aren't black and white things that there's just like we have no confidence

33:56.840 --> 34:03.400
scores and probabilistic models that give you a gradient of how sort of of confidence and say you

34:03.400 --> 34:09.800
know a right answer there's gonna be a gradient in terms of like sentiment so if a person is saying

34:09.800 --> 34:13.800
something like you know I'm having trouble with this then you might be able to say oh okay I'm

34:13.800 --> 34:17.320
sorry you're having trouble with this I really you know wish you were doing a better job there but

34:17.320 --> 34:22.200
you know can I offer you this you know tool this troubleshooting step you know this troubleshooting

34:22.200 --> 34:27.080
dialogue where as a person is really upset then yeah you probably just want to say maybe you want

34:27.080 --> 34:31.240
to offer them at least to say would you like me to have a technical support person contact you

34:31.240 --> 34:36.120
directly you can just like hold on and we'll call you or do you want to proceed with our you know

34:36.120 --> 34:43.320
troubleshooting online yeah so I think although we still aren't there 100% with recognizing these

34:43.320 --> 34:48.120
things the question like what do you do with it once you have recognized it might be even a

34:48.120 --> 34:53.160
harder problem to deal with you know because great we can get like we end up with 100% 99%

34:53.160 --> 34:57.560
accuracy of knowing when some how angry someone is but how do you what how does that help you what

34:57.560 --> 35:02.360
your customer does not want to escalate all of those two you know they're most senior rap or

35:02.360 --> 35:06.760
or exactly right so how do you handle it what do you do with it for an enterprise like how do you

35:06.760 --> 35:10.520
actually use that data in a way that's interesting and again this doesn't actually come down to

35:10.520 --> 35:15.480
an AI problem it comes down to like a user experience problem or design problem yeah I wonder if

35:15.480 --> 35:20.840
there's like you know companies all over of Glondon to net promoter scores a way to measure

35:20.840 --> 35:29.000
customer satisfaction but I wonder if there's like a net IVR anger scores yeah you you guys should

35:29.000 --> 35:36.200
do that yeah yeah this our customers ask about this stuff a lot so it's really it's on the

35:36.200 --> 35:40.200
the front of people's minds but you do to the when you go down that dialogue when you go down

35:40.200 --> 35:47.880
that path it's you know okay so then what yeah awesome football thank you so much for taking the

35:47.880 --> 35:54.920
time to sit down with me I'm looking forward to catching pieces of your talk and how you know

35:54.920 --> 35:59.480
their ways that folks can kind of find out about your research or connect you on Twitter or

35:59.480 --> 36:06.120
anything like that yeah my Twitter handle is my name with the first initials switch so okay

36:06.120 --> 36:11.480
it's all pepper to you well pepper on Twitter that's probably the best way to get at me these days

36:11.480 --> 36:15.640
okay nice nice well good luck with your talk tomorrow thank you thanks

36:20.280 --> 36:26.520
all right everyone that's our show for today thanks so much for listening and of course

36:26.520 --> 36:32.440
for your ongoing feedback and support for more information on Paul and any of the other topics

36:32.440 --> 36:40.760
covered in this episode head on over to twomlai.com slash talk slash 52 for the rest of the series

36:40.760 --> 36:49.400
head over to twomlai.com slash a i s f 2017 and please please please send us any questions or

36:49.400 --> 36:57.480
comments that you may have for us or our guests via Twitter at twomlai or at sam charrington or leave

36:57.480 --> 37:02.840
a comment on the show notes page there are a ton of great conferences coming up through the end

37:02.840 --> 37:08.920
of the year to stay up to date on which events will be attending and hopefully to meet us there

37:08.920 --> 37:19.720
check out our new events page at twomlai.com slash events twimlai.com slash events thanks again for

37:19.720 --> 37:29.720
listening and catch you next time

