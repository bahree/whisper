Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host, Sam Charrington, you may have seen the news yesterday that MIT researcher
Katie Bowman produced the first image of a black hole.
What's been less reported is that the algorithm she developed to accomplish this is based
on machine learning.
Machine learning is having a huge impact in the fields of astronomy and astrophysics,
and I'm excited to bring you interviews with some of the people innovating in this area.
Today we're joined by Yasha Haseve, assistant professor at the University of Montreal,
and research fellow at the Center for Computational Astrophysics at Flatiron Institute.
Yasha and I caught up to discuss his work on gravitational lensing, which is the bending
of light from distant sources due to the effects of gravity.
In our conversation, Yasha and I discussed how machine learning can be applied to undistort
images, including some of the various techniques used, and how the data is prepared to get the
best results.
We also discussed the intertwined roles of simulation and machine learning in generating
images, incorporating other techniques such as domain transfer or GANS, and how he assesses
the results of this project.
For more of our astronomy and astrophysics coverage, be sure to check out the following
interviews.
I'd like to thank everyone who entered our AI conference and TensorFlow Edge device
giveaways.
Today, I'm excited to announce the winner of our AI conference giveaway, Mark T. from Indiana.
Mark, I'm looking forward to seeing you in New York next week.
Today's show is sponsored by our friends at Pegasystems.
Pegaworld, the company's annual digital transformation conference, will be held at the
MGM Grand in Las Vegas from June 2nd through 5th.
I'll be attending the event as I did last year, and I'm looking forward to presenting again.
In addition to hearing from me, the event is a great opportunity to learn how AI is being
applied to the customer experience and real Pegasystems customers.
As a Twomo listener, you can use the promo code Twomo19 at pegaworld.com for $200 off
of your registration.
Again, that code is Twomo19.
Hope to see you there.
Enjoy.
All right, everyone, I am on the line with Yashar Heiseve. Yashar is an assistant professor
at the University of Montreal and a research fellow at the Center for Computational Astrophysics
at Flatiron Institute.
Yashar, welcome to this week in Machine Learning and AI.
Thanks, Ben.
Thank you very much for inviting me.
Let's start by talking a little bit about your background.
We recently joined University of Montreal as an assistant professor, but tell us a little
bit about the arc of your studies and research.
Yeah, so I'm an astrophysicist, and for most of my research career, I've been primarily
doing research in astrophysics.
I did my undergrad in Physics and Astrophysics at the University of Victoria in Canada,
and my PhD at Meal University in Montreal.
I got my PhD in 2013, and I moved to Stanford as a hubbell fellow until recently.
I just moved from Stanford about three months ago.
And during this whole period of 10 years as a graduate student and a researcher, I've
been working on specifically astrophysical data analysis, and in the past couple of years,
with all the buzz about machine learning, I've kind of started to look into the application
of machine learning methods to astrophysical data analysis.
And so now a good fraction of my research has kind of focused on developing new machine
learning methods for the analysis of astrophysical data, so like telescope data.
And your particular research area is focused on strong gravitational lensing.
That's that.
Strong lensing is the distortion in the images of distant objects, done by the gravity
of intervening object structures.
So just think about it that gravity actually bends light.
So here on the earth, we don't notice it because it's such a tiny effect that you don't
notice it.
But in reality, if you had a flashlight, the light rays instead of going straight, they
would actually blend a little bit because of the gravity of the earth.
It's the same reason that black holes are black because they absorb all this light because
the light falls into the black hole.
So at cosmological distances, you can have two galaxies, one sitting far away, say, five
billion lighters from us.
And second galaxy could be like much farther away, say, 12 billion lighters, but right behind
this middle galaxy.
So we have this scenario.
It's us.
We call it the middle galaxy, we call it like the foreground and the background galaxy.
And so the light rays of that background galaxy as they come and they pass near the foreground
galaxy, they get bent, they get deflected because of its gravity.
And so they come to us from these different angles, different directions because of, you
know, the spending of light.
And as a result, what happens here is that here on the earth, we see these distorted images
of that background galaxy that look like rings and arcs around the middle galaxy.
So you can have, you know, instead of like one galaxy, it can be in front of the other
one, you would see one galaxy and around it, you would see these rings and arcs, which
are actually the images of the distant background galaxy.
And so how does the use of machine learning play into your study of these, these lensing
effects?
So there are two things.
So to give you an analogy about this, you know, I like to make an analogy to lensing
of a candle flame with a wine glass.
So think about it, you know, you have a candle sitting on the table and you have a wine
glass.
If you look at the candle flame through the foot of the wine glass, you can see that
the image of the flame kind of wraps around the foot of the wine glass and it makes like
rings around that thing.
So that's why this is called gravitational lensing because it acts, you know, the middle
galaxy likes acts like a lens.
And so this is kind of the thing that we have and we usually have two questions in each
of these observations.
The first thing that we want to figure out is what is the shape of the foot of the wine
glass?
What is the distortion that this caused the image?
And so this relates to, you know, how much matter there is in the middle galaxy.
So we are trying to use these images, distortions to learn about how matter, you know, to map
the distribution of matter in these lensing galaxies.
And then the second question is that, so I see a distorted image of this background source,
but what does it truly look like?
You know, if I'm looking at this arc that is a stretched out image of the candle flame,
I'm interested, you know, what does the candle flame truly look like?
How could I undistort this image?
And so you can see that all of this kind of relates to image analysis and image processing.
So one thing that, you know, works really well for us is, you know, this development
of convolutional neural networks that are specifically tailored to image analysis problems.
And so we've been kind of like, you know, hijacking them and using them for this application
to answer these two questions, you know.
If I get a distorted image of these background things, can I predict what, you know, the
distortion is that's been caused and can I undistort, can I reconstruct the true image
of this background galaxy?
And so what are some of the techniques that you're using to do this?
So traditionally, this is done by something called, I'll just throw the name and I'll explain
what it is, you know, using like maximum likelihood lens model.
So the way that this works is that you say, well, let's think about this.
I have this, you know, candle in the background, I'm putting a lens in front of it.
So I see this distorted image, you know, magnified image of the candle.
And I have an observation, so I see that image.
But I need to know what that candle truly looks like.
Nor do I know what is the distortion that's been added to its image, right?
So, so I, if I see that the data, I cannot predict these two together, but what I can do
is that I can produce a lot of simulations.
So if you gave me an image of a candle and you gave me a lens, it's easy to simulate
it and say, you know, because you can go from one to the other.
So I can get a lens and predict what is the distortion that it causes to space.
And then I can put the image of the candle and it can make a simulation.
So say, you know, it lends the image, it distorted the image of the candle with look like
that.
It's the problem is that, you know, it's difficult to undo this.
So the way to stop traditionally has been that, you know, I would just produce a lot of
different simulations with like, you know, perhaps random candles and random lenses.
And try to find out which one of them really looks like the data.
And so if I find one simulation that really looks like the data, you know, I can kind of
infer that the parameters that I assume for it, you know, the background source that I
assume for it, the foreground lens that I simply should be kind of a correct description
of their, you know, reality.
And so this kind of like falls into this, you know, general umbrella, like, you know,
inverse problems where it's easy to go from the ingredients of the model.
Like if I knew the truth about the truth about the candle and the lens, I can go forward
and make a simulation, but the inverse problem is difficult.
If I, if you gave me the output, then I cannot figure out, you know, what was the initial
ingredients that it was made from.
So with machine learning, what is exciting about it is that we can construct these inverse,
you know, mappings.
So by using a lot of simulated data or true data, I can learn to just kind of like directly
predict what these background sources or the foreground lenses look like, just directly
looking at the data, we don't need to produce in a lot of simulations for every data analysis.
And describing the simulation based approach, there's something kind of intuitively unsatisfying
about that.
The idea that you're going to just randomly generate a bunch of candles and randomly
generate a bunch of lenses.
And if you get something that kind of looks like, or looks very close to the result that
you've got, you assume that it's that specific lens and candle configuration.
Is it that the chance that you get a good match, you know, without the candle and the lens
being exactly right or close so small that gives you comfort in choosing that particular
configuration?
Or I guess this part of me that says, you know, there could be any number of configurations
of candles and lenses that that's a great question.
That's a great question.
So so in a statistical way, what you really do is that you would say, I'm actually going
to find out every candle and every lens that will kind of produce.
So there might as you said, there might be like multiple answers.
And I'm going to find every one of them that will match the data within my uncertainties.
And so it means that you have to have a statistical description of your data to understand what
are your uncertainties, uncertainties could come from, for example, noise.
And you would write a statistical model to say, well, this particular candle and this particular
glass, it fits my data to some, you know, in a probabilistic way.
And this other one could also match it.
And that's one of the things that makes it even more difficult because the problem is
not only even finding a single answer.
The problem is that now you have to kind of explore all the different answers and kind
of give a range of these answers that are consistent with the data.
So it works well.
It's just that computationally, it's very expensive because now it means that you have to try millions
and millions of these simulations to give an answer for one specific data set.
And what are you assuming as known in the way you've formulated the problem here?
Because you kind of know what a candle looks like and you know what a lens kind of looks
like.
What assumptions are you making about the candle and the lens to you then now?
That's a really good question.
So these assumptions typically in the language of statistical analysis, you would call them
priors.
So these are the prior information, the prior knowledge that we have about these things.
And so the way that these priors are specifically encoded in the analysis could be different
from, you know, mildly different.
But you can imagine that, for example, in the case of strong lensing, you want the background
source to be something looking like a galaxy.
So you would impose some sort of like, you know, prior knowledge, you would say, I have
a prior knowledge of the background source, you know, is a galaxy.
So for example, when I make images of this thing, I will, you know, kind of enforce that,
for example, it is, you know, it's blobby or it's concentrated at the center or that, you
know, it's peaks, you know, it's density at this, you know, it's brightness at the center.
But the way that you define it could be tricky.
And specifically when you were doing these, you know, the kind of like forward modern,
you know, lens modeling procedures, it is difficult to actually specify these priors.
One of the cool things about machine learning is that these prior information, you can
actually learn them from data itself.
And that's one of the really like great advantages of a machine learning approach is that if
I had a large data set of these lenses or galaxies in general, if I think that the background
sources a galaxy, I can get millions of images of other galaxies in the universe from, you
know, all sorts of telescopes.
And I can put it through a machine learning procedure and I can actually learn what are
the kind of structural priors that I need to respect.
And then try to kind of like find out what are the solutions within that kind of like,
you know, range of, you know, possibilities that match this particular data set.
And so maybe share a little bit about the data collection and preparation aspect of these
types of problems, assuming the data that you're working with comes from these, you know,
large radio telescopes and you're able to collect that very fairly readily, but you have
to do a lot of processing to it.
Yeah.
So we work both with radio telescopes and and regular optical telescopes like, you know, Hubble
Space Telescope.
So two of the first like machine learning papers that we wrote were basically just using,
you know, Hubble Space Telescope images.
So these images, usually there's like a few steps of pre-processing that you need to
do with it.
The telescope that comes with, you know, from the image that comes from the telescope might
for example have a lot of cosmic rays.
These are just like particles, you know, around the earth that hit the, you know, the cameras
on the telescope and they just leave these traces very high energy particles.
And so, you know, you might need to remove those.
You might need to, for example, subtract the light from the lensing galaxy itself because
remember what we are interested in is a distortion of this background galaxy and how it's been
distorted.
One of the new sense things here is that the middle galaxy that is distorting also has a lot
of stars.
It has a lot of light that's added to this image.
And so a lot of times you would try to kind of subtract this light first and then kind
of like look at the remaining the arcs that come from the backgrounds or so, how do you
do that?
You know, you might take advantage of the fact that the background galaxy and the foreground
galaxy have different colors and so use the color information from these things.
You might need to estimate what is the blurring of the telescopes.
So the images are never perfectly sharp.
There's some amount of blurring that's your resolution.
So if you have a bigger telescope that are camera on it, you're going to get sharper images.
So that's kind of the blurring of the telescope or the point spread function.
So you might want to estimate that for the analysis and all of these things.
So when you're doing for radio data, it's kind of different things.
But typically there's a lot of these like steps and pre-processing steps that you need
to do before you even move on to that final stage where we're actually doing these simulations
and comparing it into the data.
I got the impression earlier that the simulation was kind of the way you used to do it and
now you're using machine learning as an alternative.
Is that, it sounds like that it's not the case.
You're using the simulations and machine learning to get kind of being conjunction with
one another to solve this problem.
Is that right?
Yeah, so their roles have kind of changed.
So in a what I call maximum lens modeling, just lens modeling in a traditional way.
If you gave me a specific data set, one image of a gravitational lens and I wanted to
analyze it, I need to produce millions of simulations and one by one compared them to the data.
And then based on that comparison, I will pick my next simulation to produce.
So there is a systematic way to kind of like go through these simulations and just say,
well this one is not good in this particular way.
So the next simulation that I need to produce will have to be something that looks like
this, it kind of looks like this or whatever, that's kind of the correct direction for
me to go.
So and then once you're done with that procedure, so let's say you got your answer and
you say, well, these are the ranges of answers from background candles and the foreground
lenses that are consistent with the data.
So you move on the next that you come and you have a new example, a new data set from
a new telescope and you want to get the answer.
So you need to go through the whole thing one more time.
So you need to produce like millions of simulations again for this specific system to analyze it.
With machine learning, what we do is that we produce a lot of these simulations in one
go, we train a machine learning model and then we're done forever.
Because this machine learning model, from all these simulations in one go, it learned
how to do that mapping, how to get, how to predict these parameters that we were interested
in from the data set.
And then so I can apply to this data set and then tomorrow I can apply to another data
set and I never ever have to run another simulation again.
So we're using the same sort of simulations to train the machine learning methods, but
we only need to do it once.
Learning to the machine learning models that you're using to predict the lensing, you
know, one of the things that kind of immediately comes to mind when I think of imaging or processing
images is deep learning and convolutional neural nets.
Is that a part of the solution here?
Yeah, yeah.
So we're using a lot of deep learning and convolution neural nets for the analysis of
these data.
That's right.
What we're doing is allowing you to kind of set up standard supervised learning, training
of CNNs or is there, is that the right way to think of what you're doing?
Yeah.
Yeah, yeah.
Absolutely.
So what we're doing is that we're producing training sets where, so I can, I can, for
example, pick, you know, a particular image of a background galaxy.
And I pick, you know, a galaxy that's doing the lensing, the lensing galaxy with certain
parameters, for example, it's electricity or how massive it is or, you know, where it
is in the sky.
And so I know the truth because this is a simulation, it's a control simulation.
So I know what the truth is.
And I will produce an image.
And so then I will put this image as the inputs of my convolutional neural network and
train me to predict the particular outputs that I have because this is, yeah, supervised
training because I know what the truth is for this particular case.
And so this is, you know, one of the approaches that we've done for this is exactly that,
produce training sets from simulated data and train convolutional neural nets in a supervised
way with these things.
And the reason that we use simulations, by the way, one of the things to say is that there
are two reasons why we use simulations.
One is that we could produce really realistic simulations.
So, and so in a really realistic look in simulation, the good thing is that the labels that we
have, the truth that we have are the absolute truth because these are actually producing
a, you know, control simulation.
So whereas if I actually get a realistic, you know, a real data set from this side that
has been analyzed, the prediction for that itself had some error in it, depending on
various parameters.
And the second thing is that currently we only know of a few hundred gravitational lenses
altogether.
So we probably know of about, like, you know, something out there, like 500 lenses, which
is really, really not enough for training these, like, large deep net worth.
So when we are doing simulations, we would produce like half a million of these things.
And it would only take like, you know, about a day to produce this.
And so that gives us, you know, a lot of data set to avoid, you know, issues like overfitting.
Do you find that the models that you produce as a result of this simulation and training
process apply well to real world images, or do you need to incorporate something like domain
transfer or some of these other techniques?
Yeah, we do.
So this, the lensing simulation aspect of it itself is fine.
It's just that telescopes usually have a lot of funny things happening today.
So there's, you know, various forms of noise, they could be cosmic rays like what I described
earlier.
It could be various.
So, in the first form of noise and, oh, you mentioned the cosmic rays.
Yeah.
So cosmic rays is another kind of like, you know, corruption that happens to the data.
So the first time that we tried this on real data, that's what happened was that we trained
it, you know, as CNN and then we looked at its predictions for real data for the first
time.
And we knew the answer for this real data set because we had modeled it before.
So we had a kind of a rough comparison and we're like, it's, you know, the answer was
to keep garbage.
And so what we did is we took these saliency maps, which means that we took kind of like,
we looked at the gradient of our predictions with respect to the data set.
So anywhere in the data that is, you know, making a huge contribution to our decision for
what the truth, you know, what the, what the prediction is, it would kind of like, you
know, shine bright.
And immediately we noticed that anywhere that there was a hint of kind of like, a low
intensity kind of dotting the image, these are cosmic rays that kind of like, you know,
put kind of like a dot or, you know, imprints in the images, it was shining bright.
And we were like, oh, okay, like, that's kind of a sign that, you know, all these other
corruptions that are in the data do really impact the decisions of the CNN.
So the challenging aspect was exactly that, that domain adaptation to try to, or, you
know, in this case, like really simulate, you know, realistic looking images that bring
every aspect representative of the data that we were going to analyze.
Another technique that comes to mind for this type of a problem, it sounds in many ways
to some of the problems like, you know, correcting missing pixels or distortion and photographic
images is generative models.
Is that something that you've been looking at for this problem?
We have been discussing this, but we haven't, we haven't done anything about it.
So in terms of the generative part of this problem, there's like two parts of it that could
be very interesting.
So the first one is the background sources.
So the background source that's being lensed is the image of an actual real galaxy.
So the thing that we did so far was that we actually got a bunch of a large data set of
real images of galaxies.
And so these are from, you know, these are galaxies that are not strong with lens.
So some of them are galaxies, you know, in the local universe, you know, we have beautiful
images from the Hubble Space Telescopes.
Some of them are more distant galaxies in the universe.
But you know, we got like, you know, 100,000 images of galaxies and then we put those through
simulations and made these arcs and, you know, lensed them.
But you know, we were still limited, you know, by these data sets.
So one thing is that that we've been discussing is using these generative models to produce
an un-lensed image of a galaxy, just produce an image of a galaxy.
And then putting that through a simulation lensed.
So for the lensing aspect of it, you could also do this.
You can imagine, well, I'll just train a generative model that produces a lensed image to begin
with.
Well, the thing about that is that the lensing aspect of things is easy, is relatively
easy.
You know, it just involves running something called a ray tracing simulation, which is not
the most efficient thing in the universe, but it's not too bad.
It's not the bottleneing.
And but then the third aspect of it that could also get interesting with generative models
is exactly the point that you brought up about all the other sorts of corruptions that
goes into data.
You know, can I produce a generative model that actually gets these simple simulations
and adds the various effects of, you know, different instruments and telescopes and gives
me images that are represented to flip off that so that I use it for training off the
other machine learning methods like these humans.
How do you kind of envision the future application of machine learning in the space?
You know, obviously, we just talked about some of the generative models and the applications
of those techniques.
But are there other areas that you see as being interesting ones to explore here?
Oh, yeah.
So this is becoming, you know, kind of a popular topic in astrophysics now.
There are a lot of young people looking into the application of this for different things.
You know, there are so many things in astrophysics that you could kind of like use a neural network
to answer the question, but it's really the question of, you know, is it particularly
useful in this particular, you know, case?
So one thing that really made it worth it for us was that in the next few years, we're
expecting to discover about 200,000 strong rabbit nature lenses.
There are a few new surveys that are planned to be operational.
So like, LSSD is a huge project and Euclid telescope, you know, it's a European satellite.
So these are expected to be surveys.
So they will like map huge chunks of the sky.
LSSD in particular will map the whole sky, the visible part of the sky every three nights.
And it will produce, you know, a ridiculous amount of data.
And we're expecting to discover a forward of like, you know, 200,000 lenses.
Now with my traditional methods, if I wanted to go and fit a lens model to every one of
these, you know, 200,000 lenses, even if it took me like, you know, two, three days to
come up with the answer for one lens, which is optimistic actually.
You know, it would take me like 14, you know, 100 years to do that.
So for strong lensing, it really looks like, you know, it's just like, you know, it's a
matter of speed and the number of lenses that we have to analyze.
So in other fields, like, you know, in imaging of the cosmic microwave background, there
are, you know, papers being written right now, people looking into the application of machine
learning.
But, you know, for example, in that field, the problem is not really speed.
It's sometimes about accuracy and could you train neural networks that can be more accurate
than these maximum likelihood methods, because they can deal with, you know, complex
noise, for example.
So, but my general feeling is that, you know, it's becoming an active field in astrophysics
and more and more people are getting excited about it.
Like, you know, when I started giving talks about this, like, you know, two years ago,
I kind of saw, you know, some level of skepticism, primarily because, you know, people have
this worry that these are black boxes and, you know, you cannot control exactly what
happens.
You don't understand why they're making the decisions that they're making.
But as, you know, people have seen the results of, you know, the excellent performance of
these methods.
I think now more and more people are kind of like warming up to the idea and kind of
a lot of research is going that way.
Awesome.
And, and maybe a quick note before we close out, you mentioned the excellent performance
of these methods in your case where you're looking at gravitational lensing.
How do you characterize that performance and what are the types of results you've seen?
So, for us, there's been kind of like two kind of metrics of performance.
And the most important one has been speed.
And so when we train the neural network, you know, the training itself takes just like
a couple of days.
And after that, you know, for the estimation of its parameters of a single lens, you know,
it would take us a hundredth of a second on a single GPU.
And if you assume that the analysis of, you know, a lens of a typical complexity would
take, you know, a few days, you know, often actually like experts' time that, you know,
would have to sit on this and run, you know, quite a few CPUs.
It's something about, you know, 10 million times improvement in analysis speed.
So you know, the analysis of the LCC dataset that I discussed with you earlier.
So this could be done half an hour on single lap cell, which is completely like orders
of magnitude, you know, faster than whatever you could get from traditional modeling.
And then in terms of the accuracy of the models it themselves, you know, we're showing
that you can get accuracies that are within basically the uncertainties of the parameters.
So we can get excellent accuracies on these predictions.
So remember that we were actually looking at the answers that we were saying, well, I'm
interested about a range of answers that match my thing.
And so the precision of these models are really comfortable to the, you know, kind of the
uncertainties that we get from maximum likelihood modeling anyways.
And the other thing is that in there are certain cases where they can actually outperform
these methods.
So another direction we've gone is recently we're using recurrent neural networks.
So these are networks that are typically used for, you know, speech analysis because
they're good at modeling sequences of data.
What we're teaching them here is actually try to model a sequence of steps in these images.
So imagine, you know, imagine, so we're interested in, for example, predicting the distribution
of matter in the lensing galaxies.
And so we'll start from, you know, an unknown guess, something, you know, a random guess
so we don't know what it is.
And we'll have to take a series of steps to get closer to our answer.
So maybe the first guess is going to be that this galaxy, you know, looks like something,
you know, it has some electricity in some direction and some mass.
And then I will refine my answer as I go.
As we're putting this through a recurrent neural network that, you know, so this is
a particular architecture is called the recurrent inference machine.
And so the recurrent inference machine every time looks at its own prediction and then
and then puts that through our simulation that uses the actually like physical model.
And updates its answer.
And one thing that we've been showing is that this can actually like, you know, predict
background source images with the lens or the undistort the image of the background
sources that are better representation of the data than these maximum likelihood models.
And the reason for that is the same thing that you mentioned at the very beginning of
the talk about priors.
And the reason is that this network can learn the complex prior off of what a background
source, what a galaxy really looks like from the training data set, whereas when you
try to define that in, you know, a statistical way from, you know, just, you know, in a statistical
way, it's just difficult.
It's really difficult to define on a pixel per pixel basis what is a galaxy?
What does a galaxy look like?
Right.
If I show you something that, you know, has a little bit of, you know, more fluctuations
here or a little bit spread out, you know, what kind of scored you give it to say how
galaxy, you know, galaxy looking like this is or this is not.
The neural networks, they can learn that from the training data and perform really, really
well.
Well, Ashley, thanks so much for taking the time to share this with us is really interesting,
really interesting work.
I always love talking to folks that are working on astrophysics and cosmology in general.
The use cases are so, just the scale of them is just enormous.
Yeah.
It's really fun talking to you.
I didn't expect this to become more like kind of a high level.
Yeah, I never thought, you know, about throwing the word CNN or RNN or things like that,
but it was just fun for me to have more technical stuff.
Yeah.
Nice.
Fantastic.
Thanks so much, Ashur.
All right.
Thank you.
All right, everyone, that's our show for today.
For more information on Yashur or any of the topics covered in this show, visit twomolei.com
slash talk slash 250.
Make sure to register for Pegaworld using the code twomole19 for $200 off of registration
at Pegaworld.com.
As always, thanks so much for listening and catch you next time.
