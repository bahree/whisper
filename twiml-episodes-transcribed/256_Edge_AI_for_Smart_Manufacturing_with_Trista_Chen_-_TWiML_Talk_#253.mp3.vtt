WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:32.440
I'm your host Sam Charrington.

00:32.440 --> 00:36.680
This week's shows are drawn from some of the great conversations I had at the recent Nvidia

00:36.680 --> 00:40.960
GPU technology conference and they're brought to you by Dell.

00:40.960 --> 00:44.840
If you caught my tweets from GTC, you may already know that one of the announcements this

00:44.840 --> 00:49.320
year was a new reference architecture for data science work sessions powered by high

00:49.320 --> 00:54.480
NGPUs and accelerated software such as Nvidia's Rabbids.

00:54.480 --> 00:58.960
Dell was among the key partners showcased during the launch and offers a line of workstations

00:58.960 --> 01:03.040
designed for modern machine learning and AI workloads.

01:03.040 --> 01:07.720
To learn more about Dell precision workstations and some of the ways they're being used by customers

01:07.720 --> 01:12.320
in industries like media and entertainment, engineering and manufacturing, healthcare

01:12.320 --> 01:23.040
and life sciences, oil and gas and financial services, visit Dell EMC.com slash precision.

01:23.040 --> 01:25.840
Alright everyone, I am on the line with Trista Chen.

01:25.840 --> 01:30.000
Trista is the chief scientist of machine learning at Inventek.

01:30.000 --> 01:33.160
Trista, welcome to this week a machine learning and AI.

01:33.160 --> 01:35.640
Thank you Sam, thank you for inviting me.

01:35.640 --> 01:36.640
Absolutely, absolutely.

01:36.640 --> 01:39.720
I'm looking forward to our conversation.

01:39.720 --> 01:45.480
Before we jump into the heart of our talk, which would be focused on a presentation you

01:45.480 --> 01:52.960
did recently at the Nvidia GTC conference on edge AI and smart manufacturing, I'd love

01:52.960 --> 01:54.840
to learn a bit about your background.

01:54.840 --> 01:57.240
How did you get started working in machine learning?

01:57.240 --> 02:01.800
I'm always a visual person to start with as a child.

02:01.800 --> 02:09.200
So naturally I study computer vision and after I finished my PhD at Carnegie Mande University,

02:09.200 --> 02:15.360
I joined Nvidia to be the first video architect of their video processor.

02:15.360 --> 02:22.240
So video processor is their new line of processor in addition to the graphic processor, so that

02:22.240 --> 02:30.040
they can handle all the video encoding, decoding and preprocessing post-processing more smoothly.

02:30.040 --> 02:38.080
After Nvidia, I joined Intel to be their research scientist, I lead a team of researchers

02:38.080 --> 02:47.480
in Russia to do open CV development, as well as working on medical and multi-core processor

02:47.480 --> 02:48.480
research.

02:48.480 --> 02:57.280
So open CV to some of you who know the open source library is probably the biggest open source

02:57.280 --> 02:59.080
library on computer vision.

02:59.080 --> 03:07.160
You have 14 million dollars so far and I'm very happy to be proud of effort to contribute

03:07.160 --> 03:13.600
to the community to help everybody to have a good head start in all the computer vision

03:13.600 --> 03:15.720
applications.

03:15.720 --> 03:22.720
And after Intel, I think most people at Silicon Valley had this dream of studying their

03:22.720 --> 03:25.720
own company.

03:25.720 --> 03:33.240
So I started my own company doing computer vision for other companies.

03:33.240 --> 03:35.600
So basically a B2B effort.

03:35.600 --> 03:43.040
So I help company to annotate their image or video assets so that they can match related

03:43.040 --> 03:46.640
advertisement to their image or video.

03:46.640 --> 03:50.680
So example to that would be if you watch YouTube video array.

03:50.680 --> 03:56.600
So a lot of them are consumer generated and you want to monetize them.

03:56.600 --> 04:02.040
So our company will help them to look at what's inside a video and then what would be

04:02.040 --> 04:06.200
the appropriate related content.

04:06.200 --> 04:12.200
For example, if you are posted a video of writing a bicycle in the wild, then maybe we will

04:12.200 --> 04:17.760
match our AI advertisement for you and same thing with image.

04:17.760 --> 04:24.120
So if you write a blog about your dinner with friends and then you write a blog about

04:24.120 --> 04:30.320
going to somewhere for fun, then we can match that with travel advertisement and whatnot.

04:30.320 --> 04:35.000
And so we got accepted by a wide combinator in the last round.

04:35.000 --> 04:39.320
But eventually I didn't join the wide combinator effort.

04:39.320 --> 04:46.320
And then so because I was a first time entrepreneur, it wasn't successful.

04:46.320 --> 04:52.160
And after that, I get a taste of stuff and I decided to join another stuff which was

04:52.160 --> 04:55.320
called cognitive networks.

04:55.320 --> 04:58.760
So what they do is they do content recognition on TV.

04:58.760 --> 05:06.080
So they have this small device inside the TV that they partner with so that they can

05:06.080 --> 05:10.840
understand exactly what TV content you are watching.

05:10.840 --> 05:19.040
For example, you are watching Big Ben Theory episode A and two minutes of two and 30 seconds

05:19.040 --> 05:20.320
and whatnot.

05:20.320 --> 05:29.320
So by knowing what you are watching at the moment, they can do a lot of analytics, the video,

05:29.320 --> 05:35.760
they can know the advertisement or the campaign effectiveness and whatnot.

05:35.760 --> 05:42.200
So eventually the company was successful and got acquired by Vizio, one of the top TV

05:42.200 --> 05:51.200
manufacturer in the world, and so after a happy acquisition, I kind of semi-retire, per

05:51.200 --> 05:52.200
say.

05:52.200 --> 05:59.680
Yeah, after like 15 years of second value, like how working and craziness.

05:59.680 --> 06:05.600
So I actually moved across Pacific Ocean to Taiwan.

06:05.600 --> 06:10.880
So actually my career has been interesting in that it's been different countries.

06:10.880 --> 06:17.920
It's been different areas as a firm research to industry research from big companies and

06:17.920 --> 06:23.360
eventually start up and now I'm moving back to another big company, which is Inventake

06:23.360 --> 06:24.880
in Taiwan.

06:24.880 --> 06:31.960
So for a lot of you in the US, you might not be aware of the company Inventake.

06:31.960 --> 06:37.400
It's actually OEM or some of you might heard of FACSCOM, right?

06:37.400 --> 06:43.160
So FACSCOM make manufacturer all the Apple devices for Apple.

06:43.160 --> 06:47.560
So Inventake is a similar line of company.

06:47.560 --> 06:56.240
So they manufacture cloud servers, laptops and smart devices for all the famous computer

06:56.240 --> 07:03.440
they ever heard of, even though you never heard of Inventake itself because it's OEM.

07:03.440 --> 07:13.800
As a chief scientist in the company, I was actually I'm helping the company to optimize

07:13.800 --> 07:23.080
their industrial 4.0 effort in the factory as well as looking at future direction in products

07:23.080 --> 07:33.600
so that we can prepare ourselves to be ready to manufacture a new line of AI products for

07:33.600 --> 07:34.920
our customers.

07:34.920 --> 07:43.200
So the presentation that you did at GTC around the application of AI at the edge, was that

07:43.200 --> 07:49.160
for Inventake's own manufacturing facilities or for customers or partners?

07:49.160 --> 07:52.400
Yeah, the answer is yes and no.

07:52.400 --> 07:58.200
So to start the research, we actually focus mostly internally.

07:58.200 --> 08:03.400
So we go to the factory and talk to the people in the production line to understand what

08:03.400 --> 08:06.720
their needs and what their pain point is.

08:06.720 --> 08:09.400
And from there we develop the solutions.

08:09.400 --> 08:17.320
So what you see in our GTC presentation are the real application that we develop for

08:17.320 --> 08:19.360
the factories.

08:19.360 --> 08:22.160
And from there it becomes a solution.

08:22.160 --> 08:28.480
So it's possible that we provide the solution or we customize a solution for other customers

08:28.480 --> 08:30.480
other than Inventake.

08:30.480 --> 08:34.240
But that's another process.

08:34.240 --> 08:36.920
So now we are not talking about that in the presentation.

08:36.920 --> 08:40.520
So the presentation that you saw is for Inventake only.

08:40.520 --> 08:41.840
Okay, great.

08:41.840 --> 08:46.800
And so we're not going to assume that anyone listening has seen the presentation.

08:46.800 --> 08:53.200
So why don't you walk us through the main points of the case study?

08:53.200 --> 08:57.280
What were the main challenges that you are trying to solve?

08:57.280 --> 08:58.440
Let's start there.

08:58.440 --> 08:59.440
Okay.

08:59.440 --> 09:04.760
So manufacturing is actually a very interesting area.

09:04.760 --> 09:10.200
So most people, they had the whole their smartphones, they had their computers, but they

09:10.200 --> 09:13.200
had no knowledge about those factories.

09:13.200 --> 09:19.280
So they imagined something like, oh, there's this big huge factory in China somewhere.

09:19.280 --> 09:26.440
And some like huge robots or many robots working there along with maybe a lot of cheap labor

09:26.440 --> 09:27.440
and all that.

09:27.440 --> 09:31.160
Honestly, it's more advanced than that.

09:31.160 --> 09:40.280
So industry 4.0 is actually an effort to digitize a lot of the physical part of the factory

09:40.280 --> 09:48.200
so that we can seamlessly integrate what we sense from the physical, for example, the

09:48.200 --> 09:55.760
defects or what we see from the production line together with a lot of the knowledge that

09:55.760 --> 10:00.160
we learned from previously for that to optimize the process.

10:00.160 --> 10:01.160
Okay.

10:01.160 --> 10:03.160
So let me give you an example.

10:03.160 --> 10:11.200
So traditionally in like industry of 3.0, so we need a lot of humans to look at, for

10:11.200 --> 10:16.120
example, the PCB board or the motherboard of a computer, one by one, right?

10:16.120 --> 10:21.800
To make sure that the components in the PCB board are not misplaced, they are not having

10:21.800 --> 10:26.080
any defects, they are not missing and whatnot.

10:26.080 --> 10:30.040
But then you can imagine that it's pretty cost ineffective, right?

10:30.040 --> 10:36.200
And then a human can get tired and they can get inconsistent in their result.

10:36.200 --> 10:42.840
So by using a computer region to do this, we can ensure that accuracy of its action is

10:42.840 --> 10:44.160
much higher.

10:44.160 --> 10:46.720
And more importantly, you'll be more consistent, right?

10:46.720 --> 10:51.480
So a lot of people or a lot of labor before a lunchtime, they get so tired, they want

10:51.480 --> 10:58.600
to go to lunch and they will simply just press OK or back to the product, right?

10:58.600 --> 11:02.400
And then they just go to and they finish their job and they can go, right?

11:02.400 --> 11:07.920
But then for computer, they won't have such a problem, they'll just keep working tirelessly.

11:07.920 --> 11:15.160
So this is the very obvious example of application of AI in manufacturing.

11:15.160 --> 11:20.200
But honestly, industry application of AI is actually a very broad area.

11:20.200 --> 11:28.280
So according to McKinsey, a report of McKinsey in 2013, they actually more manufacturing

11:28.280 --> 11:33.760
data than any other sector combined in a year.

11:33.760 --> 11:40.080
So that would be two extra bytes or two and then 10 to the power of 18 bytes of data per

11:40.080 --> 11:43.040
year, according to the report.

11:43.040 --> 11:49.920
And that amount of data can be used to do a lot of interesting things.

11:49.920 --> 11:56.960
In addition to defect detection, so it could be used to do like pretty few maintenance.

11:56.960 --> 12:04.280
It can be used to do operational optimization, supply chain optimization and all that.

12:04.280 --> 12:12.360
So what we talk about in GTC is just a very small portion of how AI can help manufacturing

12:12.360 --> 12:13.360
or factory.

12:13.360 --> 12:20.000
Now, one of the things that I've heard in talking to folks about this space and I'm curious

12:20.000 --> 12:26.680
if you've seen similar is that one of the big challenges here is that while there

12:26.680 --> 12:35.400
is a ton of data, often it's locked in proprietary systems like robotics provider might provide

12:35.400 --> 12:41.760
the robot, but not open up the data to the customer to integrate it in with other things

12:41.760 --> 12:49.360
or they may have data in some SCADA system, but they aren't easy interfaces to accessing

12:49.360 --> 12:51.000
or using that data.

12:51.000 --> 12:54.440
Do you find that in your world as well?

12:54.440 --> 12:57.560
Yeah, that's an excellent question, actually.

12:57.560 --> 12:59.920
So there are two aspects to that.

12:59.920 --> 13:07.000
So one is the device, with the device actually output the data you need in order to do your

13:07.000 --> 13:08.000
AI thing.

13:08.000 --> 13:11.920
So first, for example, in the case of defect detection, right?

13:11.920 --> 13:17.640
So AOI machine stands for automatic optical inspection.

13:17.640 --> 13:23.240
So what they do is they use a camera, press some algorithm to detect defect, but a lot

13:23.240 --> 13:30.360
of times those AOI vendor, they won't output the raw image to the factory people.

13:30.360 --> 13:36.280
So what they're going to output is just a result of a pass or fail of this piece before.

13:36.280 --> 13:43.480
And there's a good reason that they don't want to release their precious data to the customer.

13:43.480 --> 13:48.160
So oftentimes you have to pay extra fee or maintenance fee or service fee in order

13:48.160 --> 13:56.240
to get those data to do further optimization as a factory customer to those device manufacturers.

13:56.240 --> 13:58.160
So that's one aspect to that.

13:58.160 --> 14:05.400
And the other aspect is even the factory has access to all of this confidential or secret

14:05.400 --> 14:06.400
data.

14:06.400 --> 14:14.200
It's usually hard or impossible for the outsider to touch those sensitive manufacturing

14:14.200 --> 14:16.960
data to do further things.

14:16.960 --> 14:18.960
So I will use the example, right?

14:18.960 --> 14:21.040
For example, like landing AI.

14:21.040 --> 14:27.160
So a company that is certified into one of the AI pioneers, right?

14:27.160 --> 14:37.080
So landing AI, they claim to work on this field of industry or AI, but honestly, any outsider

14:37.080 --> 14:43.360
is close to impossible to touch data like what is the EORA of the process.

14:43.360 --> 14:49.400
And then, for example, what is the inventory level and what is the order level or the

14:49.400 --> 14:55.120
older number, the sales order number of this factory or for this side.

14:55.120 --> 14:59.800
So those are so sensitive that it's impossible to reduce to outsiders.

14:59.800 --> 15:05.600
So to answer your question, I think a lot of the thing is happening inside the factory,

15:05.600 --> 15:07.480
inside the wall of the factory.

15:07.480 --> 15:14.040
So the wall could be physical, it could be digital, but whichever, everything is contained.

15:14.040 --> 15:20.560
So I would say it's not a sexy field to work with by design.

15:20.560 --> 15:29.520
So that they can keep all the secret data that can affect their like stock price and

15:29.520 --> 15:37.720
then that can affect a lot of things, transactions that keep everything inside and they work on

15:37.720 --> 15:40.600
those data inside the wall.

15:40.600 --> 15:44.960
And so you mentioned these ALI systems.

15:44.960 --> 15:54.080
When folks are deploying AI to do visual inspection, that's one of the big use case areas for

15:54.080 --> 16:03.400
AI in the industrial context is defect reduction and visual inspection is a goal to replace

16:03.400 --> 16:12.760
the existing ALI systems which tend to be based on more traditional computer vision algorithms

16:12.760 --> 16:18.240
as opposed to machine learning or is it to as you're suggesting you take their data

16:18.240 --> 16:22.360
and optimize but still use those systems.

16:22.360 --> 16:27.840
And there are lots of different types of computer vision based systems on the in a manufacturing

16:27.840 --> 16:28.840
environment.

16:28.840 --> 16:32.960
There are these defect detection systems, there are the sorting types of systems, but they're

16:32.960 --> 16:39.840
all kind of characterized as being these closed systems where you'd want to have the

16:39.840 --> 16:42.440
data to optimize.

16:42.440 --> 16:47.280
Are folks trying to replace these with more open types of systems or just get access to

16:47.280 --> 16:50.400
the data and feed it back to what those systems are doing?

16:50.400 --> 16:58.080
Yeah, I think it depends on the stage of your development in using AI in factory.

16:58.080 --> 17:04.880
So ALI is actually a pretty mature field so you can go out and talk to at least a hundred

17:04.880 --> 17:11.040
different ALI vendors in the market and buy machines that do ALI for you.

17:11.040 --> 17:16.880
So like you said, so currently most of the ALI machine in the market are using the so-called

17:16.880 --> 17:21.560
traditional computer vision methods to find out the defects.

17:21.560 --> 17:28.680
For example, it can detect the lines, it can detect a pattern and then the ALI machine

17:28.680 --> 17:38.320
will realize that this pattern is like 10 degrees different from the position or the

17:38.320 --> 17:43.480
angle that it should be, or the part is missing because the pattern doesn't match.

17:43.480 --> 17:51.440
So those are pretty typical computer vision thing that, for example, OpenCV can do.

17:51.440 --> 17:59.280
But for some of the defects like solder, that is kind of fuzzy or ambiguous.

17:59.280 --> 18:00.800
Human can do pretty good on that.

18:00.800 --> 18:05.480
They can look at the image and say, hey, this is too much solder and this is like too

18:05.480 --> 18:06.480
little solder.

18:06.480 --> 18:13.880
But for computer or for traditional computer vision, what they see is just a bunch of stuff,

18:13.880 --> 18:14.880
right?

18:14.880 --> 18:18.560
They don't know the angle, they don't, it's probably hard for them to calculate the area

18:18.560 --> 18:25.320
and that would be the thing that is most suitable for the did learning base AI agreement to

18:25.320 --> 18:29.960
attack or to solve and so like I said, right?

18:29.960 --> 18:35.240
So ALI machine is capable if you can get the image out of the machine, then you can have

18:35.240 --> 18:44.120
a second stage re-inspection engine to the image so that you can fix the defect detection

18:44.120 --> 18:49.080
after you have fixed already the first level of defect detection.

18:49.080 --> 18:53.880
The first level will be the easier cases that you can detect with traditional computer

18:53.880 --> 18:54.880
vision.

18:54.880 --> 19:01.240
And in the second stage, you can use AI based method to solve the harder to detect kind

19:01.240 --> 19:04.680
of fuzzy and ambiguous case.

19:04.680 --> 19:12.920
And eventually, if the system is smart enough and maybe eventually some of the AI machines

19:12.920 --> 19:19.920
smart enough, it can combine both of the traditional and the new deep learning base method together

19:19.920 --> 19:27.560
so it can either switch between or fuse them together so that you have one super powerful

19:27.560 --> 19:32.360
AI machine that does everything and that can look at different kind of defects that had

19:32.360 --> 19:34.160
different characteristics.

19:34.160 --> 19:39.280
So the way I see that is like it does not one answer to that.

19:39.280 --> 19:44.760
It depends on the stage of your development and sometimes it's two stages and it's like

19:44.760 --> 19:48.160
one big stage and that.

19:48.160 --> 19:52.560
So we've talked about ALI and defect detection quite a bit.

19:52.560 --> 19:56.000
Were there other use cases that you mentioned in your presentation?

19:56.000 --> 19:57.000
Yes.

19:57.000 --> 20:04.560
So this presentation is mostly focused on defect detection even though I talked earlier,

20:04.560 --> 20:08.120
like there's other application of AI in Infectory.

20:08.120 --> 20:15.160
For example, like older prediction, like predictive maintenance, like safety improvement using

20:15.160 --> 20:20.560
computer vision or environmental aspect of the AI.

20:20.560 --> 20:26.200
So there are actually a lot of more different applications but it's not mentioned in my presentation.

20:26.200 --> 20:30.920
Based on the title of your presentation, you also were incorporating the idea of edge

20:30.920 --> 20:31.920
in Twitter.

20:31.920 --> 20:33.800
Where does that fit in?

20:33.800 --> 20:38.000
So there are two kind of scenarios.

20:38.000 --> 20:40.960
One is edge, the other one is cloud.

20:40.960 --> 20:47.000
So cloud in general is the mainstream of most of the AI application right now.

20:47.000 --> 20:52.480
So in terms of image, you capture image or video, you send it to the cloud and the cloud

20:52.480 --> 20:58.960
had usually super powerful machine with graphic processing there and they do all the inference

20:58.960 --> 21:01.880
and the speedouts and results.

21:01.880 --> 21:08.560
For example, pass or fail or they tell you the object type does contain in this image

21:08.560 --> 21:11.960
and does them send it back to the user which is at edge.

21:11.960 --> 21:13.880
So that's one scenario.

21:13.880 --> 21:19.960
The other scenario is edge meaning you don't send your image or your data to the cloud.

21:19.960 --> 21:26.120
You compute everything on site and when I say on site, there are a few benefits to that.

21:26.120 --> 21:28.920
So one obvious benefit is privacy.

21:28.920 --> 21:33.080
So there's no intermediate point that you can hijack the data.

21:33.080 --> 21:38.080
You can keep everything within the locality of this edge device.

21:38.080 --> 21:42.000
So privacy is number one and number two is reliability.

21:42.000 --> 21:49.000
So reliability, what I mean by that is sometimes the network or the communication become reliable.

21:49.000 --> 21:54.880
You can drop off or the bandwidth can be reduced and there could be error in your transmission.

21:54.880 --> 22:01.680
And as I said earlier, they could be interference or somebody can hijack your data or your package.

22:01.680 --> 22:04.800
And that causes a huge issue in the result.

22:04.800 --> 22:09.160
So by having edge AI, then you avoid that problem.

22:09.160 --> 22:14.440
And the last point of edge AI benefit would be network efficiency.

22:14.440 --> 22:17.400
So in terms of a defect detection.

22:17.400 --> 22:22.560
So image data is an input for your AI engine.

22:22.560 --> 22:27.840
And image data are usually quite big, especially if you had like hundreds, thousands, if not

22:27.840 --> 22:32.360
millions of images sending to the cloud, every hour, right?

22:32.360 --> 22:37.040
That would pretty much jam all your infrastructure, the network infrastructure.

22:37.040 --> 22:40.840
So by computing on the edge, then you avoid that problem altogether.

22:40.840 --> 22:43.360
So you don't have that problem.

22:43.360 --> 22:50.680
And so most of the conversation around edge today is focused on edge inference.

22:50.680 --> 22:57.440
And we're seeing a lot of new hardware, actually almost every week, there's folks proposing

22:57.440 --> 23:04.240
new hardware approaches for edge-based inference, low-power inference, et cetera.

23:04.240 --> 23:10.640
But there's also work happening around more advanced scenarios.

23:10.640 --> 23:17.760
So just starting to see like federated learning and ways to combine the edge with the cloud

23:17.760 --> 23:22.720
and to have learning that incorporates the edge.

23:22.720 --> 23:27.840
Are you doing any work in that area or seeing anything interesting in some of these more

23:27.840 --> 23:29.840
advanced scenarios?

23:29.840 --> 23:31.160
Yes.

23:31.160 --> 23:37.120
So when you just mentioned, I believe you something called hybrid AI.

23:37.120 --> 23:44.440
So basically AI computation or inference can happen, like I said, in both cloud and edge.

23:44.440 --> 23:49.360
And edge device traditionally are pretty, they don't have that much power.

23:49.360 --> 23:53.520
So they can emote in the case of image, they can emote capture image.

23:53.520 --> 24:00.720
And it tracks some features like edge, like regional interests, and send the data back

24:00.720 --> 24:08.320
to the cloud to do most of the computation like detection and classification and all that.

24:08.320 --> 24:17.160
But now they more and more AI device like you said is popping up from the market pretty

24:17.160 --> 24:18.480
much every day.

24:18.480 --> 24:25.440
I think in addition to those AI chips, per se, a lot of existing device like cameras,

24:25.440 --> 24:31.360
they start to have more and more terror frops inside their module already.

24:31.360 --> 24:36.720
So I think it's right now it's kind of like a messy situation that everybody is trying

24:36.720 --> 24:42.600
to capture some piece of this AI shape or edge AI market.

24:42.600 --> 24:50.120
So what I observed right now may not be conclusive, but I think this trend is going to continue.

24:50.120 --> 24:57.080
And then everybody is going to expand their territory, so Amazon is going to claim that

24:57.080 --> 25:03.080
a cloud service is more powerful, more accurate, and then it's easier to deploy and all that.

25:03.080 --> 25:07.360
And then I think the edge AI people or the chip people, they're going to say, hey, it's

25:07.360 --> 25:11.920
more private, it's more reliable and what now I think this was going to continue.

25:11.920 --> 25:15.440
And then eventually nobody is going to win or lose.

25:15.440 --> 25:16.840
I think it's going to be win-win.

25:16.840 --> 25:22.520
And then it's depending on your usage scenario and then you will choose the best solution.

25:22.520 --> 25:23.920
I'm sure.

25:23.920 --> 25:32.960
Going back to this idea of hybrid AI, have you seen any use cases for doing some learning

25:32.960 --> 25:37.120
at the edge and some learning in the cloud?

25:37.120 --> 25:44.200
So in particular to learning, so most of the edge devices are not, they only do inference.

25:44.200 --> 25:50.320
So they don't have the capability of adapting or training on the go.

25:50.320 --> 25:55.640
So what usually happened is you had you download a model.

25:55.640 --> 25:59.120
So they call it model, a deep learning model from the cloud.

25:59.120 --> 26:02.000
So those are trained in the cloud.

26:02.000 --> 26:05.800
And in the edge, they simply do the inference or testing.

26:05.800 --> 26:14.120
So in the case of human detection and at edge, they deploy, like say smart camera.

26:14.120 --> 26:15.920
Smart camera with the AI chip inside.

26:15.920 --> 26:21.560
For example, the smart camera will do the detection and happy, right?

26:21.560 --> 26:30.480
But if somehow the population that this camera see starts to change or migrate over time,

26:30.480 --> 26:35.960
so you might need to update your model about how people around this area look like, right?

26:35.960 --> 26:38.640
So in this case, you have to update your model.

26:38.640 --> 26:44.160
And currently all the training is still in the cloud and updating of the model is still

26:44.160 --> 26:45.480
happening in the cloud.

26:45.480 --> 26:52.480
And you still have to periodically or depends on the event that you download the new model

26:52.480 --> 26:54.960
or updating model to the edge device.

26:54.960 --> 27:00.240
So there's no device training currently as far as I can see.

27:00.240 --> 27:07.160
So the hybrid AI that I see is mostly training in the cloud inference in the edge.

27:07.160 --> 27:13.480
Yeah, that's a little bit different from this thing that is you're still a bit undefined

27:13.480 --> 27:20.120
and maybe even still a bit mythical of federated AI where you're trying to do distributed training

27:20.120 --> 27:22.160
across multiple devices.

27:22.160 --> 27:26.840
But I just, I keep asking everyone who might know a little bit about, might have seen

27:26.840 --> 27:31.600
it to get a sense for if anyone's doing it out in the wild yet.

27:31.600 --> 27:32.600
Yeah.

27:32.600 --> 27:39.160
In terms of distributed AI in training, I do see a quite a few applications in there.

27:39.160 --> 27:43.360
So in coming back to the example of human recognition.

27:43.360 --> 27:48.640
So for example, you can place your camera in different locations, different cities,

27:48.640 --> 27:51.160
and different city would have different people looking differently, right?

27:51.160 --> 27:57.080
In New York, people look like they're dressing suits and like very serious and look serious.

27:57.080 --> 28:02.440
So and then you have some camera that's in urban area, suburban area that people dress at

28:02.440 --> 28:05.040
t-shirt and sandals and whatnot.

28:05.040 --> 28:11.920
So collection of data, they happen, distributionally, that's obvious, right?

28:11.920 --> 28:16.760
And in terms of training, I think distributed training, they might have a local training

28:16.760 --> 28:24.160
server that is in the proximity of those sensors and do their local training on how the

28:24.160 --> 28:29.840
human look like in that area and eventually they'll combine them out in the cloud so

28:29.840 --> 28:36.960
that you would have this like very small argument that can understand how human look like

28:36.960 --> 28:38.360
in different areas.

28:38.360 --> 28:44.680
So that's what I see in distributed AI training, but I don't see distributed AI inference

28:44.680 --> 28:50.480
because there's no such need to do inference in multiple locations as far as I see because

28:50.480 --> 28:56.000
inference usually is not as heavy as training, so you don't need distributed inference.

28:56.000 --> 29:03.880
And so this distributed training that you're referring to when the model is combined, is

29:03.880 --> 29:10.760
that a fairly simple combination like some kind of ensembling or where you're running

29:10.760 --> 29:16.560
multiple models and picking the one that's most confident or is it something more elaborate

29:16.560 --> 29:20.880
where you're kind of merging the models in some kind of way?

29:20.880 --> 29:28.040
Yeah, that's a different level of integration or a different level of merging of the model.

29:28.040 --> 29:31.480
So the simplest way is like winner winner take all right.

29:31.480 --> 29:37.960
So whoever whose model performs the best in that case then wins, right?

29:37.960 --> 29:39.960
So the other case is simple waiting.

29:39.960 --> 29:46.320
So you weigh the score from different model in different locations and combined results.

29:46.320 --> 29:49.840
So that's a second approach, still pretty simple.

29:49.840 --> 29:54.760
And eventually you can go through this like super complicated case that you have another

29:54.760 --> 29:56.800
neural network, right?

29:56.800 --> 30:03.080
That neural network is trying to combine all this like child model and combine it together.

30:03.080 --> 30:08.760
And in that you will need training data from more training data so that you can train

30:08.760 --> 30:17.160
the parameters of this like super neural network on top of all these child models.

30:17.160 --> 30:21.080
So there are different complexity in terms of how you combine it together.

30:21.080 --> 30:28.320
Going back to your presentation, one of the things that you mentioned is the need to

30:28.320 --> 30:38.480
redefine the problems in order to get the kind of results in terms of ROI and solution

30:38.480 --> 30:41.960
capability that you're ultimately looking for.

30:41.960 --> 30:45.320
Can you elaborate a bit on that and how that comes up?

30:45.320 --> 30:52.400
Yeah, so when we start talking to the factory people, right, there are there are how working

30:52.400 --> 30:57.520
people they they they focus on one specific area every single day.

30:57.520 --> 31:02.880
So one of them talk to us about the problem that they are facing, they're like, oh, our

31:02.880 --> 31:11.000
inventory is so big that we have to keep building like a warehouse to store all the parts that

31:11.000 --> 31:12.000
we need.

31:12.000 --> 31:16.320
And then the warehouse is getting bigger and bigger is getting harder and harder to manage.

31:16.320 --> 31:21.080
And then so they're like, oh, can AI help us to manage the inventory and also to help

31:21.080 --> 31:23.600
us to build a bigger warehouse?

31:23.600 --> 31:29.160
And we're like, hmm, that's an interesting question to have, let's figure out like how

31:29.160 --> 31:30.160
we do that.

31:30.160 --> 31:32.640
Well, now architect, we don't build warehouses.

31:32.640 --> 31:34.720
So how can we help them?

31:34.720 --> 31:42.640
So in so after digging deeper and talk to them more, they actually had different problem

31:42.640 --> 31:46.160
that caused this warehouse problem, right?

31:46.160 --> 31:52.840
So what they have is they actually don't have accurate forecast or accurate prediction

31:52.840 --> 31:58.320
of their order so that in order to meet or in order to fulfill the requirement of the

31:58.320 --> 31:59.320
customer.

31:59.320 --> 32:04.440
They can prepare a lot of parts in advance so that if the customer wants something, they

32:04.440 --> 32:09.800
can quickly pull out the parts and assemble the computer for the customer.

32:09.800 --> 32:14.880
So eventually this is not a warehouse problem or how to manage a warehouse problem.

32:14.880 --> 32:18.600
This is actually an older position problem.

32:18.600 --> 32:27.480
So this is what I mean by one of the key examples redefine the problem and using AI.

32:27.480 --> 32:32.040
And another thing that you mentioned is this AI thing.

32:32.040 --> 32:36.400
So our AI stands for return on investment.

32:36.400 --> 32:44.360
So this is a typical practice of everybody working in manufacturing or industry.

32:44.360 --> 32:51.480
So in order to buy something or in order to adopt a solution, you have to actually calculate.

32:51.480 --> 32:58.600
So this much cost will take you two years, three years, 80 months, whatever long time that

32:58.600 --> 33:02.560
to recapture the cost that you invest.

33:02.560 --> 33:09.520
And so for a lot of the thing, our AI is really hard to calculate because this is not a typical

33:09.520 --> 33:13.960
stationary or static optimization problem that you had all the parameters laying out in

33:13.960 --> 33:15.560
front of you.

33:15.560 --> 33:19.640
And then you can do your optimization and do your trick.

33:19.640 --> 33:23.640
And then you come up with some savings or you come up with some improvement.

33:23.640 --> 33:26.480
This is actually a dynamic process.

33:26.480 --> 33:34.520
So when you are optimizing the system, you're actually changing the nature of the factory.

33:34.520 --> 33:37.480
And it's similar to start market, right?

33:37.480 --> 33:43.800
So you don't, it's like Warren Buffet, like praying in the start market when he decided

33:43.800 --> 33:51.240
to buy something, actually he changed the S&P index already because the volume is so big.

33:51.240 --> 33:52.360
So similar to that.

33:52.360 --> 33:59.000
So when you actually change something or invest to something into the factory, you actually

33:59.000 --> 34:01.840
change the nature of the problem.

34:01.840 --> 34:04.120
So it's on the gold target.

34:04.120 --> 34:09.240
So our AI is consequently very difficult to calculate.

34:09.240 --> 34:17.240
Can you give a specific example of a change that AI causes in the factory that makes it

34:17.240 --> 34:20.320
difficult to estimate ROI?

34:20.320 --> 34:27.280
And one point of clarification before you do that is the challenge, specifically with

34:27.280 --> 34:32.160
forecasting ROI or measuring it after the fact or both.

34:32.160 --> 34:33.400
I think it's both.

34:33.400 --> 34:35.480
So forecasting is actually harder.

34:35.480 --> 34:38.200
So let's say I decided to buy robots.

34:38.200 --> 34:39.200
Okay.

34:39.200 --> 34:46.080
So buy robots to move all the parts in different size of my factory.

34:46.080 --> 34:50.880
And then you can say, hey, the robot cost me like a million dollars and blah, blah, blah.

34:50.880 --> 34:53.560
And then so the AI is like 18 months, right?

34:53.560 --> 34:57.680
But then this is actually eventually is going to be wrong.

34:57.680 --> 35:07.200
Reason for that is by adopting robots, you actually improve the accuracy of or the time that

35:07.200 --> 35:10.800
arrive at different manufacturing lines.

35:10.800 --> 35:14.080
So the time that you arrive at the line is more precise.

35:14.080 --> 35:19.240
So you can produce your product in a more timing manner, manner.

35:19.240 --> 35:21.400
So your euro will be higher and all that.

35:21.400 --> 35:30.840
So when your euro is higher, actually the overall profit or revenue of the companies is increased.

35:30.840 --> 35:35.240
And how do you factor that into your calculation of our AI, right?

35:35.240 --> 35:41.880
And that's why in prediction or imagery, both the our calculations is often wrong.

35:41.880 --> 35:42.880
Okay.

35:42.880 --> 35:46.160
It sounds like if I could maybe try to restate that.

35:46.160 --> 35:54.400
It sounds like when you automate in the manufacturing facility, you know, there's a specific

35:54.400 --> 35:57.120
thing that you're trying to improve.

35:57.120 --> 36:02.440
Maybe it's reducing defect and then you automate, but the introduction of automation has a

36:02.440 --> 36:09.160
bunch of downstream effects like increasing consistency and reducing wait times and things

36:09.160 --> 36:10.240
like that.

36:10.240 --> 36:16.920
And it's hard to produce an all encompassing ROI study that takes into account all these

36:16.920 --> 36:17.920
different factors.

36:17.920 --> 36:23.560
Trista, were there any other thoughts that you included in your presentation as key takeaways

36:23.560 --> 36:29.520
or any parting thoughts that you'd like to leave with the audience that, you know, might

36:29.520 --> 36:33.160
help them in their path towards industry for data?

36:33.160 --> 36:34.160
Yes.

36:34.160 --> 36:40.720
And industry for that is a seamless integration of physical and digital world.

36:40.720 --> 36:45.160
So the obvious benefit will be accuracy, consistency, and ROI.

36:45.160 --> 36:49.560
And then when I want to stress, it's actually go higher than that.

36:49.560 --> 36:57.080
So if you can actually get all those digital and physical data, IoT data, with you, you

36:57.080 --> 36:59.400
can do much, much more optimization.

36:59.400 --> 37:04.440
You can actually change the whole scope of how you design the manufacturing line.

37:04.440 --> 37:08.160
You can change how you take the order.

37:08.160 --> 37:09.600
You can change how you ship.

37:09.600 --> 37:13.200
You can change the location where you start your inventory.

37:13.200 --> 37:14.840
You can change the whole thing.

37:14.840 --> 37:23.640
I think without the digital and physical integration or people call it digital twin, without

37:23.640 --> 37:24.640
that.

37:24.640 --> 37:31.920
I know where you can do such a ground up change of how the whole manufacturing process.

37:31.920 --> 37:39.200
So in addition to focusing on the obvious benefit, I think everybody working in manufacturing

37:39.200 --> 37:48.280
should look one step up and looking at what you can do to change the whole process.

37:48.280 --> 37:54.240
And then this, again, it's not just 10%, 20%, it could be like exponential, like two times

37:54.240 --> 37:57.680
and it can be 10 times because the whole thing is changed.

37:57.680 --> 37:58.680
Awesome.

37:58.680 --> 38:01.280
Well, Trista, thank you so much for chatting with us.

38:01.280 --> 38:02.280
Thank you.

38:02.280 --> 38:08.920
All right, everyone, that's our show for today.

38:08.920 --> 38:15.440
For more information on any of the shows in our GTC 2019 series, visit twimmaleye.com

38:15.440 --> 38:18.440
slash GTC19.

38:18.440 --> 38:21.160
Thanks again to Dell for sponsoring this series.

38:21.160 --> 38:25.920
Be sure to check them out at dellemc.com slash precision.

38:25.920 --> 38:52.680
As always, thanks so much for listening and catch you next time.

