Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
In this episode we're joined by Garrett Hoffman, Director of Data Science at Stocktwitz.
Garrett and I caught up at last month's Stratid Data Conference where he presented a tutorial
on deep learning methods for NLP with emphasis on financial services.
Garrett is a social network for the investing community which has its root in the use of
the cash tag on Twitter.
In our conversation we discuss applications such as Stocktwitz own use of social sentiment
graphs built on multi-layer LSTM networks to gauge community sentiment about certain
stocks in real time as well as the more general use of natural language processing for generating
training ideas.
Before we dive into the conversation I'd like to send a huge thanks to our friends at
IBM for their sponsorship of this episode.
Interested in exploring code patterns leveraging multiple technologies including ML and AI,
then check out IBM Developer.
With more than 100 open source programs, a library of knowledge resources, developer advocates
ready to help and a global community of developers, what in the world will you create?
Just dive in at IBM.biz slash ML AI podcast and be sure to let them know that Twimmel sent
you and now on to the show.
Alright everyone I am here in New York City at the Stratid Conference and I am with Garrett
Hoffman.
Garrett is the director of Data Science at Stocktwitz.
Garrett, welcome to this week in machine learning and AI.
Thanks for having me Sam.
It's fantastic to be here.
Awesome.
I am always super excited when someone, I'm interviewing someone and they say they listen
to the show and enjoy the show so thanks for offering that.
Why don't we get started by having you tell us for those who aren't familiar with Stocktwitz,
what's Stocktwitz all about?
Yeah I'd love to.
So Stocktwitz is a FinTech financial technology company we're based here in New York City
and our core product is the Stocktwitz.com or the Stocktwitz mobile app which is a social
network for the finance community.
So kind of like a LinkedIn meets Twitter specifically for traders and investors.
So people who are interested in the market can come on, connect with each other, share
ideas, learn from each other and most importantly they can enjoy participating in the markets
and investing even more by sharing in that experience together.
Our core user is the millennial investor who we know is digitally native, increasingly
social.
This is a group that really loves social engagement around the decisions that they're making and
we've seen companies like Amazon facilitate this and eat commerce when someone's looking
to buy something through going through reviews, talking with their friends about kind of
the stuff that they're purchasing and as a company we really see ourselves as a platform
where people can come to engage in this type of social interaction around the decisions
that they're making in investing and financial services.
So right now conversation centers mostly around individual stocks but our new product
that we actually just launched called rooms allows the community to start to self organize
around specific topics that they're interested in and that's really exciting for us because
it allows people to dive deeper in details so maybe like they want a room just to talk
about Apple products and what that might mean for the stock but it actually also helps
conversation grow bigger and more general maybe people want to talk about other financial
services like Robo advisors like general like insurance stuff like that.
So it's really giving the community a platform to talk more about financial services in
general or specific topics that they're interested in.
And I've got this impression that Stock Twits grew out of the stock tag on Twitter.
Is that the case or?
Yeah so our founder Howard lives in back I think it was 2009 invented the cash tag and
so this was a dollar sign in front of a ticker symbol on Twitter and we were actually partnered
with Twitter using the Twitter API to kind of search and filter Twitter for tweets specifically
that had a cash tag.
So it was kind of a filter on the Twitter API a few years later we actually left the
Twitter API and became a standalone platform so it was born through the cash tag.
The cash tag is our main mechanism for index and conversations to specific stocks but
Stock Twits today it's its own standalone platform but it is that micro blogging real
time Twitter like form out of discussion and what's your background?
Yeah so I in undergrad I study in mathematics and finance I got exposed to a lot of like
the core ML mathy concepts matrix factorization eigenvectors optimization statistical learning
but I'd say my first introduction to kind of machine learning as like a field that was
more than just like the sum of these individual parts that I was learning was when I started
researching topics for my undergraduate thesis and came across neural networks.
I really wanted to study something that was math as used in the finance industry to kind
of tie both my field of study together and I saw that people were starting to like resurface
neural networks to do forecasting on stock prices and I actually decided to pass on that
topic.
I was like oh this was done in the 80s it's kind of been explored already I couldn't
have been more wrong about how prevalent it would be a few years later in fact I was
more interested at the time in kind of probability theory stochastic calculus random processes
um so I actually this was 2011 when I finished undergrad and at the time the default job
for people who studied math and didn't really want to teach was an actuary so I got a job
as an actuary at Xerox part of a smaller business group called buck consultants that they
owned a lot of people don't know that Xerox played in kind of the consulting playground
but I did actual consulting around benefit plans so valuing retirement plans valuing
health plans executive stock option plans kind of working on the investment strategy around
the funds that pay those types of benefits and being an actuary is a phenomenal profession
but after a year or so I kind of realized it wasn't for me um I I wanted to have more of
a tangible impact and be able to kind of like see the impact of the models that I was creating
and of the analysis that I was doing so I I really liked my company and I liked the space I'm
I'm very passionate about financial wellness and financial literacy and helping people
get gain the knowledge and tools that they need to kind of be independent and and
wait through a very complex world on their own so I really became interested in how can we help
our clients help their employees make better decisions around their benefits so this was more
of like a behavioral psychology behavioral economics problem and I think was my first cross in
my professional life of kind of leaving actual the world of actuarial problems and the the types
of stuff that actuaries normally think about to enter in kind of a data science problem a problem
that could be um solved using machine learning and data science so I actually spent the next few
years still at that company doing kind of like half actuarial stuff half product development for
these new solutions um they actually started to take off we got a few client projects Xerox actually
let me take a sabbatical they sent me to uh metastata science boot camp in New York City to kind of
true up my knowledge fill in the gaps more on the product and delivery side like how are solutions
in data science and machine learning scaled and delivered just because as an org we were kind of
waiting through new territory no one really had that knowledge of okay once we we've done the modeling
and done the technical stuff like what are clients who are looking for these solutions actually
looking for what when they ask someone to help them with it um so stuff like productizing data
through APIs you know building applications with data science stuff like that um ended up going
back to Xerox for about six more months and realized that um I really wanted to go somewhere where
where I could really shape um like a consumer facing product I wanted to be somewhere a little
more closer to the technology industry the actual at the actuarial industry is um great lagging maybe
a little bit behind in terms of like using cutting edge technology um so at that time I started
looking for new opportunities I ended up at stock twitch it was kind of a great marriage for us where
I'd have a treasure trove of data being close to like being centered around a social a social
network and still kind of at an org where their goal was to help people understand this really complex
world of finance and so you did a tutorial actually uh here at Strata on the use of deep learning
methods for natural language processing with a particular emphasis on financial services and
some of the things you're doing at stock twitch what are some of the ways that NLP that you use
NLP at stock twitch yeah so um our core data that we have available to us at stock twitch is of course
raw messages that people are writing ideas that they're generating um so we're working a lot with
just raw text data and as a data scientist at stock twitch I see the core mission of our team is to
really improve the user experience and improve the product through data and so for us and a lot
of how I see machine learning like what what machine learning aims to do is to actually kind
of like shrink the world and so stock twitch there's real-time information flowing by really really
quickly um you know things change super quickly it's a real-time stream so to to the extent that we
can use data to build data products to kind of help people discover like snapshots of what's
going on right now help them really find stocks that they're interested help them find people that
were they're interested in um that's really how we're using data so one of our biggest uses for NLP
is actually our social sentiment model so we like to summarize the stream of what's going on with
sentiment graphs so we try to keep real-time updates of how our community feels about a certain
stock and we're doing NLP modeling to extract financial sentiment from all the text data that's
coming in and then aggregating that at its individual stock level to kind of see how that's moving
and see how that's changing over time so that lets people come in and see maybe they've done some
research off platform they want to just check out what people are saying on stock twitch even before
waiting through you know thousands of of messages in a real-time stream they can have this nice
little little snapshot of you know how does the stock twitch community feel are they overly bullish
or they more bullish than they typically are has there been a drastic like riser or fall in sentiment
in the last few days um stuff like that so your your talk was on deeplining methods what are some
of the methods that you apply to to solving those types of problems so when we think about um
sentiment we're typically in the realm of RNN so we're using multi-layered LSTM networks to
um just extract a sentiment a bullish neutral and bearish signal and we're fortunate enough
that we have um users have the ability to tag their messages with sentiment when they post it so
we've been able to inherently gather label training data through general usage of the app
and through people tagging their messages um one of the reasons we go on to model sentiment
further is only about 20 to 25% of messages are tagged so by by building a model around sentiment
we can expand that coverage to a hundred percent of of the volume instead of just this very small
subset of tag messages um we typically have to supplement um our tag data through manual curation
just kind of validating that those tags exist so we use LSTM networks um it's really a great method
for capturing those dependencies across multiple across as it changes capturing dependencies of like
the language and the relationship through text through a nice sequential model like like RNNs
and LSTMs help us capture more nuance in the language so sometimes you get a really straightforward
message like I am bullish um maybe yeah and so that's that's really obvious and then sometimes it
might not be so straightforward so so an example of that might be someone saying like oh Tesla
here looks really really high right now um I don't think I'm a buyer if it dropped maybe down to
like the 200 range then I would definitely get in so if I'm using a method or a model to classify
that that statement um typically you know you're making classifications at the end of your sequence
the the end of that sentence makes it seem like that person might not that they are bullish that
they're going to be a buyer but LSTMs allow us to capture kind of the the um the state of that
sentence to know you know at the start of this sentence this person was pretty bearish um and so
LSTMs allow us to cat to retain that information throughout the entire sequence that we're trying
to classify what challenges do you run into when you're trying to develop these these models based
on LSTMs yeah so I'd say our biggest challenge is probably the domain specific nature of the language
so like bear in bowl in a generic setting of of language processing or just animals um like
cup and handle is a very is like a stock pattern so so the the world of finance has a ton of
vocabulary that is very neat to um talking about finance itself so this is something we actually
talk about at the talk uh in the training is this dealing with this domain specific language
and tackling it through leveraging what we can from the open source community so there's a
ton of pre-trained word vectors that exist out there but those might not get the job done when
you have a domain specific language so we actually talked about the idea of starting with pre-trained
word vectors but building on those through training additional word to vex on your
corpus that's specific to your domain so maybe instead of seating like if you're going to train a
word to vex model to get you know efficient representations of your language and your vocabulary
instead of seating randomly you can see it with a pre-trained word vector maybe out of google
news and then train over your corpus so that it can kind of start to learn um language that may
exist in a pre-trained vector but can adjust that to specifically model your language inherently
and you get a nice platform to jump off of because google's done a lot of like work to train
vectors on billions and billions of news articles of the various uh pre-trained word vectors out
there glove and google news and others uh is google news the one that closely most closely matched
to your use case so we actually um like starting with the twitter glove vectors mostly because
to capture like the syntactical nuances of how people talk in short form text over social media
so we found we found that um the the twitter data glove was a good launching point and it's
actually you wouldn't we saw a deep like pretty decent result just using those vectors alone
so one of the takeaways um and something that i'd push to anyone who um um um talking to this stuff
about it is there are people who are a lot smarter than me who have done a lot of legwork and um
like us as practitioners are fortunate enough that they open that work for everyone else to use
so even though stuff may not seem like it's applicable don't let that stand in your way to just
get out there and getting started um training custom word vectors is no small task um it requires
a ton of data it requires potentially days or weeks of training and that's the result of that
you're not even positive if it's gonna make that big of a difference in your downstream modeling
task so something we i like to stress is wherever you can start with like like stand on the shoulders
of these giants who who did this work before us um and try to kind of start with that see where
it gets you assess the situation and go on from there is there a method a method to do like composite
training with multiple pre-trained word vectors like is there a way to combine glove and google news
i haven't done anything like that i would imagine there could be some
like meta modeling or on sampling on top of it where i this this may or may not exist there
might be some research on top of this but i couldn't see why you couldn't maybe instead of
you know in a traditional word-to-vec model that you're starting from scratch your input is a
one-hot encoded vector of a word your output is one-hot encoded vectors of the context of that word
um i could see maybe some method where the input is some like concatenation of like of existing
word vectors and your kind of hidden layer is still learning like how to combine the best things
from those existing word vectors to learn the context because at the end of the day what word to
that what boils down to is we want to learn some efficient representation of words such that our
representation reflects semantic and syntactic and contextual meaning across multiple words so
i always like to say that the philosophy of word-to-vec is a quote from uh JR Firth who's a famous
english linguist who said uh you shall judge a word by the company it keeps so that's that's
basically the philosophy of word-to-vec is we just want to ultimately end up with representations
that um kind of can be shared across syntactical meaning so if i have the word good and i have the
word great i should have a representation of that word such that my LSTM model can leverage the
fact that those words are similar to make the predictions that it needs to make so no matter
what your input is that hidden layer by nature of the way you construct that that prediction test
of predicting context it's going to force words that show up in similar context to have similar
representations so i'd imagine if you start with pre-trained word vectors instead of one hot and
coated it might be able to kind of pick out the best stuff even for your specific use case so
that that could be a good approach maybe maybe we'll go back and i'll put that on our backlog to
to experiment with you mentioned that uh you use specifically multi-layer LSTM what does the
multi-layer refer to there so the multi-layer just stacks multiple LSTM layers on top of each
other so something i stress in this training and and i think anyone who's kind of learning about
LSTMs is there's a lot of things called like layers and like a lot of dimensions so like
so like you have an LSTM cell with a hidden layer and then you might have multiple LSTM layers
and then within each cell of an LSTM there's kind of like four layers that are doing their
things to maintain the state and retain information from the past sequence so i try to when i'm
doing this training make it super approachable like kind of make sure that people are understanding
what that distinction is and so a hidden layer is just like some vector that lives inside the LSTM cell
the four like feed forward layers in an LSTM cell are just kind of moving that state through
different gates and through activation functions and when i say multi-layered network so now we're
at a network level we're outside just a cell of an LSTM we're really talking about stacking two
whole LSTM layers on top of each other so if you think of like a graph pointing upwards like you'd
start with your embedding look up so you'd input your word at any time the first layer would be
your embedding look up that embedding would get passed up to the first LSTM layer it would do its
thing part of that is it would output the output from that LSTM layer then goes as the input of a
second LSTM layer and then that LSTM layer does a thing then you take that last final state at the
end of the sequence pass that up to your fully connected layer and do kind of your softmax
prediction or your sigmoid prediction depending on how many levels you have so when when someone's
referring to multi-layered LSTM network they're really referring to two steps of LSTM the first step
where your input is actually the word vector associated with each word and the second layer is
actually the LSTM output at that time being passed as the input to the next LSTM layer and how do
you know when you need to do that what's the intuition for what these different layers are doing
yeah so I'd say a lot of this is learned through observing what's happening cross validation
performance on a validation set I do think there is this understanding of like the complexity
and the nuance of the the text that you're working with basically all in LSTM is doing is it's
trying to summer like trying to learn a state of your sentence that kind of summarizes all of
this information and I know the word state can be so abstract so that I try to also stress like what
that means when we say state basically we're trying to capture all of the semantic and contextual
nuance of a sentence in like a 128-dimensional or 256-dimensional vector so your first LSTM
network is going to learn a state such that you know maybe one dimension of that state refers to
it was this sentence negated at any time another dimension or a linear combination of dimensions might
say is the sentiment the last sentiment I saw bullish or bearish and then that state can kind of
be combined and it's like okay like I saw bearish sentiment but I saw a negation so now I actually
know to predict that this is something bullish and so stacking layers on top just continual like
they they allow you to do more linear transformations on that state to try to learn a richer representation
at the end of the day what matters is that your prediction test is as accurate as you need it to be
so we're not going to you know pull out our LSTM states and examine them and be like okay like
I can see everything I want to be represented so a lot of this comes down to cross like just like
validation accuracy observing these things through training deep learning can be really tough
to do this parameter tuning if you're a small company and you don't have a ton of GPU resources
available to you these things can take a long time to train to be effective and some people can't
just spin up like 10 concurrent GPUs and monitor all this stuff in as it's running so tensor board
is is a great tool that we try to leverage where you can monitor something as it's training and if
you can see like oh our law stopped going down you know let's cancel this and try something else
so you can kind of see the model learning in real time you can benchmark it against like your
current best model and if it's not on track to beat that you're saying okay like let's cut this
training short try something new again I'd always recommend to start simpler maybe start with one
layer get a baseline model if you need to tune that better start adding in more and more layers
I would treat that architecture like you would treat any other hyper parameter that you're you're
trying to tune and so the the the layers aren't differentiated anyway well of course there are
their hyper parameters but other than that they're not you know fundamentally different they're
just you know multiple LSTM layers stacked on one another fit or feeding into one another
and like you said you treat it as a hyper parameter try adding another one how many what's the
most number of stacked LSTM layers you've seen for what we do we've probably never
explored anything more than three I'm not sure if other existing research out there like people
using LSTMs for more complicated learning tests might be stacking on time of each other um
bi-directional LSTMs is something else that we've explored and what we've found is actually
if you choose to go with a bi-directional LSTM for those not familiar it's kind of a bi-directional
LSTM is two LSTMs just one reads your input text forward to backwards the second reads your input
text backwards to forwards so it would start with your last token in your sequence then read it
backwards and then you'd kind of concatenate those into your output to pass up so we've found that
bi-directional with smaller with a small with fewer actual layers stacked on top of each other
can perform as good as a regular LSTM with layers stacked on top and it kind of makes sense because
the goal what these LSTMs are trying to do is just learn this this representation and learn this
state and passing in multiple layers you're kind of maybe maybe each network while they look
the same they're learning different things so maybe you know the first LSTMs or like learning
baseline state stuff the second LSTM is really taking that state and finding the interactions with
each other and how how things in that state um we're working together to help in your prediction
test a bi-directional LSTM can do that in fewer layers because it's kind of seeing the text twice
so it's learning a state going forward it might be picking up on other nuances going backwards
and then tying those things together where you where you can get away with the smaller
architecture so LSTMs figure very prominently in the sentiment analysis that you're doing are there
other techniques that you bring the bear yeah so something I get really excited about and this
we're kind of just starting research on this it's kind of a future frontier where we're hoping to
get to one of the main goals like I said before is we want to help people find what is relevant to
them and wade through what seems like a suffocating amount of information to find what they need
this actually aligns really well with a common problem in active investing where idea generation
is almost parallelizing like it's really hard to get into investing because you need to kind of
do the research come up with the ideas what do I want to invest in so to the extent that we can
help people find individual stocks help people find individual content or help people connect with
other people that will help them generate those ideas it's things that we're interested in so
besides just sentiment we are looking at this is actually still related to we're exploring LSTMs
we're exploring convolutional neural networks for this but doing more representation learning
for the conversation going on or like between users on certain stock streams and we want to basically
do this for recommendation purposes so this I think is this newer trend with neural networks and
deep learning that we're seeing more recently where we have some prediction task we're learning
is state so this this state might be like the the final hidden state in an LSTM it might be like
the final fully connected layer in a convolutional neural network and you might be predicting something
that thing could be arbitrary and at the end you're kind of like throwing that task away and you're
left with this representation that you can put in an embedding space to kind of then do something
like can yours neighbors to find similar things so through conversation we're trying we're exploring
can we like embed like stock to its messages in a in a message space where we can see like the
types of messages that a user typically likes to engage in maybe the types of stocks that they're
engaging in maybe we have another embedding space around stocks that kind of can can say okay
like you're interested in these stocks here are stocks that are similar based on this embedding
and then find you know the best messages about that stock from from this message embedding space
so we're exploring convolutional neural networks to basically not for a prediction task itself
but to kind of create this this like embedded space of users of messages and of stocks themselves
to kind of to to make recommendations and so in this case what's your input so the input would
still be the text data itself so we and your convolutions are across the vectorized representation
of the text input yeah so this is a technique there's a canonical paper that's convolutional
neural networks for text it was kind of the first paper that explored this and basically we have a
one-dimensional convolution so your input is exactly like you said it's a matrix two dimensions
down the rows would be the words in your sequence across the columns is your
each dimension of your word vector for that for that for each word and we do a one-dimensional
convolution because we're just taking windows and sliding them down across the entire word embedding
so you're kind of capturing features generated through words that appear next to each other
and you would kind of have parallelized windows of different lengths just like you'd have filters
of different sizes for for a two-dimensional convolution and this makes this intuitively this
should make sense because when you're dealing with images in a convolutional neural network
information is local to an individual pixel so an individual pixel is just one entry in your
input matrix so when you have this two-dimensional window that you're sliding over it pixels go
in both dimensions when you're dealing with text information isn't local to just like one
dimension of your word embedding information about that word encompasses maybe like all 50 or
250 dimensions of your word embedding so the one-dimensional convolution makes sense because
you want to make sure when you're representing a word you're not excluding certain dimensions
of your of your word embedding yeah interesting so are the network architectures here are
these kind of simple CNNs or have complex network architectures like inception and all that kind
of stuff evolve for textual data in my experience i've seen fairly simple sand ends we we would
probably do maybe have four or five window lengths so like taking three word four word five word
six word windows maybe have a hundred to a hundred and fifty filters of each size and then kind of
branching off into like maybe those four or five parallel neural net like convolutional neural
networks that then end up at some point like concatenating back together for like that last
fully connected layer so it's i'd say it's it's a fairly simple architecture but you get a little
bit additional complexity if you kind of are doing a couple different size filters in parallel
and then kind of bringing them back together so i i'd think of it like four different CNNs
each branching out their own direction and then ultimately coming together at some point to
have a like a final prediction made i'm wondering if there are other tricks that you're kind of
layering onto the CNNs to help here um no i mean we we're still pretty early in our research at
stock puts on this so we're trying to start simple we drew a lot of inspiration actually from uh
companies like Spotify who are using these types of methods to kind of do music recommendation
and for us you know stocks are very similar to music um we so like you kind of have these like
genres and and like playlist where you can kind of tie stocks together through conceptual
themes so like stocks related to self-driving cars stocks related to AI tech stocks um you kind
of have this engagement so like people are listening to different music people are like engaging
in different stocks and then you actually have kind of a similarity for price movement of a stock
like if you're analyzing music and you're actually looking like at the notes um like the the
structure of a note or the structure of you know music at that level isn't that dissimilar to
just like looking at a stock price change over time where like the the the chart is your your
clout of it like the chart is um kind of your bars and like each time frame is kind of note so
we try to draw inspiration from other leaders who are doing this type of work um so they they're
probably quite a bit ahead of us they might be doing a little bit more complex things um but as far
as CNNs we we try to keep it fairly simple okay so we've got LSTMs we've got CNNs are there other
techniques that you tend to use to solve some of these problems yeah so another area that we're
starting to research is tech summarization so like I said the streams the velocity is very very high
information is coming through if if something is trending like if something crazy happened um
for example like if Elon Musk is going off the deep end and and Tesla is tanking we may be seeing um
like upwards of like 500 messages come in like a minute so it's it's kind of really hard for like
maybe someone who hasn't developed a really refined process for how they like to use stock
tweets to come on to stock tweets and not be overwhelmed by the sheer amount of information that
they're seeing so so tech summarization is something that is super interesting to us um we curate
news as well so news summarizations like a more well understood problem we're really curious can we
apply those techniques to a stream where we can maybe extract the most important things that are
going on in the last hour from what people are saying about the stock and and maybe have those
as bullet points when you're going to the Tesla page the kind of ease in and still get okay what
are people saying about this stock without you know being like oh man like there's just stuff
coming in so fast I can't really deal with it so for our tech summarization we've been still focused
in the RNN domain but more focused on kind of these in these sequence to sequence models so encoder
decoder networks with um with attention uh and so how did what's the how do those work
yeah so I believe it's even better how do you explain them how did you explain
yeah yeah yeah yeah so RNNs are very robust they they there's a lot of different flavors of LSTN
so when we're dealing with the sentiment classification problem we're dealing with kind of a
many to one RNN where our input is many the different words in our sentence one at a time
and then after we've seen all those words we want to make a single prediction um is this
bullish as is neutral is this bearish when we're dealing with problems like text classification
our input is a sequence and our output is a sequence so we're inputting the words of our original
text let's just say we're dealing with the news article and then we want to output another
sentence that is just a summary of that text so our output is um multiple tokens of our summary
and so the way we can handle that is kind of stacking two RNNs on top of each other not like we did
it before um but kind of letting it's referred to as an encoder decoder so we have a first RNN
that's taking in our inputs um our input sequence and it's kind of learning a state of that input
sequence and then we have a decoder RNN who is taking in that state from our encoder and kind
of decoding that and picking what um kind of generating what what the best summary would be
and in the past the original models of this had the encoder and the decoder talk directly to
each other so the encoder would come up with a final state it would pass that final state to the
decoder network that final state would be the initial input to the decoder network which would
then kind of learn from like it would maintain its own internal state to try to say what word from
my vocabulary has the best probability of being the next word so the decoder RNN is really trying
to predict given the state that I have and what I just said the first word of this summary is
what's going to be the next word in our summary so this is truly like language generative model
language where we we have some vocabulary and we're trying to generate language that makes sense
and this original model kind of had its drawbacks where we were asking a lot of the encoder RNN
where we're saying encode everything that you have to say in this one final state that's
going to be passed to the decoder network and it was actually I think neural machine translation
that introduced this idea of attention and so now attention is this layer that lives between
the encoder network and the decoder network that basically says at any point when we are decoding
let me look back at the entire input sequence and let me focus on where in the input it is important
for me to make my prediction on what the next word is going to be and how have you found this
this model to perform for summarization do you have you gotten you're getting good summarization
of we you can get pretty decent summarizations on news news is like a very well structured input a
just random sequence of tweets is not very well structured so we're we still have quite a way to go
before I think we get anything that that we would put into production for tweet summarization
but and it's also you're you're not necessarily trying to summarize an individual tweet it's
more like corpus summarization right you're trying to pick the main elements across multiple tweets
and so I do like just concatenate them all together or is there some that that seems like you're
losing something if you do that yeah so I think how we've approached it is we've tried to kind
of explore with this idea of a three-dimensional input to your RNN so like traditionally inputs to
RNNs are two to like two-dimensional respect that you have a sequence of words so your sequence
of words is the first to mention your sentence could be 10 words and then each individual word
that you're inputting is has like a one row with 300 columns of your word embedding so we were
playing with kind of a three-dimensional input where your first sequence is a stream your second
sequence is a tweet in the stream and like your third dimension is like the words in that tweet
and I think you kind of hit the nail on the head where we are probably not being fair to our LSTM
network we're probably asking it to do too much by trying to treat a stream like it is one cohesive
document when in reality I think our next direction of research is gonna be more okay let maybe
don't summarize a whole stream but can we pick out an individual tweet that we think is really
good and let encompasses like a broader trend that we're seeing across multiple tweets so maybe
it's not necessarily framing it directly like you would frame a news article summarization more
framing it like a um still we're not generating new language but we're finding a tweet that is
representative over like a broader concept that we can identify in a stream does transfer learning
apply in the spaces at all like you know we've got the pre-trained love vectors and um it is
there anything that can be used to accelerate a summarization task so that you're not pre-training
everything from scratch yeah training everything from scratch yeah definitely so um
the NLP community is starting to make like a lot like bigger strides in getting to effective
transfer learning for language tests um I still don't think it's close to where the computer
vision community is but progress is definitely being made um for for kind of generic things there are
pre-trained models out there from they're not like they're not kind of like the computer vision
where there's like these go-to trained models but you can find decent research out of there um
there's a paper I really like um that I've drawn a lot of inspiration from from Abigail C
on pointer networks and so pointer networks were um are this extension of just based like
vanilla attention models where you're also kind of training this parameter called a pointer
that's saying anywhere in when I'm predicting the next word in my summary do I want to just kind
of generate a new word from my generic vocabulary or do I want to pick a specific word from the
input text to use here so I think one of the biggest problems that people were seeing in summarization
was that it was getting baseline facts wrong from from the input text um so like if I was
summering a news article that Tesla dropped 10 percent pre-market the traditional techniques
for having it like a tough time extracting that that 10 percent figure so this pointer can
basically say okay like I know that I'm about to pull a figure out um I'm going to grab I'm
going to grab um vocab from my source text and not try to like pick a needle out of a haystack
of what this metric might be from like all the metrics I've ever seen that live in my vocabulary
and is this all deep learning based or is there like some tokenization entity resolution that kind
of thing happening up front um I believe it's all it's end-to-end deep learning based yeah so I
think there's um I'm not sure what they used for the word vectors or if if the word vectors are
just learned in an end-to-end fashion but there is a pre-trained model out there like they
wrote they open source to all the code from this model it was trained on CNN and daily news data
um and so there is a pre-trained model out there that exists that that was kind of our first step
of saying okay like if we just took this model and ran financial news through it would we would
we get anything like would it be able to be applied I also think you could kind of use that
model as a baseline and then retrain on your specific data I do think in our case of like trying
to summarize tweets we're kind of starting from scratch I don't know how much how much transfer
learning is there I think the where transfer learning comes into play for NLP is really can we learn
like do we have greater representations for more generic text at like a high level language modeling
text so I think when you're getting to like generative language I see the future of transfer learning
in NLP being like okay here are these good models that kind of like help us generate text so like
they learn kind of just like the state of like a pre-trained model for computer vision is kind of
learn these nice feature representations for different like parts of an image or different objects
that appear in an image can we learn just like really good generic representations for how
text interacts with each other how words interact with each other to generate like sentences and
language that makes sense and then starting with those representations is kind of to be the first
steps of your your model and and build maybe many models on top of that if that makes sense no it
does it does okay this has been great are there any kind of words of inspiration or wisdom that
you would leave with folks who want to start exploring some of these techniques more my best advice
would be dive in I think you can spend months probably even years at this point with all the
information that's out there trying to learn trying to figure out exactly what's going on trying
to just become an expert but really no one's an expert we're we're applying these methods to new
problems that really don't necessarily have a solution they have like the best solution that we
have for them today and you're really not going to you're really not going to be able to know
everything before you dive in you're going to learn a lot as you're going so so my advice would be
you know don't be afraid the the training I offer tries to kind of make deep learning methods
accessible because I think once you dive in you'll you'll realize that deep learning isn't that
far of a jump from what you're doing today so yeah just don't be afraid just dive in head first
well said and you you mentioned that the you've got code from your training in a repository and
the slides and all that kind of stuff and you'll get that link to me we'll get that link on the
show notes page anyone that wants to to follow along with the material that you presented they'll
be able to do it there yep we'll do awesome thanks so much guys thanks for having us and it's been great
all right everyone that's our show for today for more information on Garrett or any of the topics
covering in this episode head over to twimmel ai.com slash talk slash 194 if you're a fan of the pod
we'd like to encourage you to visit your apple or google podcast app and leave us a five star
rating and review your reviews help inspire us to create more and better content and they help
new listeners find the show thanks again to our friends at IBM for their sponsorship of this
episode be sure to check out IBM developer at IBM dot biz slash ml ai podcast as always thanks
so much for listening and catch you next time
