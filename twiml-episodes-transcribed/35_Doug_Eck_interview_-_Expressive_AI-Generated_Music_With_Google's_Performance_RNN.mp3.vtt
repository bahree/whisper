WEBVTT

00:00.000 --> 00:15.440
Hello and welcome to another episode of Twinmultaugh, the podcast where I interview interesting

00:15.440 --> 00:20.040
people doing interesting things in machine learning and artificial intelligence.

00:20.040 --> 00:22.520
I'm your host, Sam Charington.

00:22.520 --> 00:27.480
The show you're about to hear is part two of our O'Reilly AI New York series sponsored

00:27.480 --> 00:29.160
by Intel Nirvana.

00:29.160 --> 00:32.880
I'm super grateful to them for helping make this series possible.

00:32.880 --> 00:37.440
And I'm excited about the cool stuff they launched at the O'Reilly AI New York Conference,

00:37.440 --> 00:42.640
including version 2.0 of their neon framework and their new Nirvana graph project.

00:42.640 --> 00:46.000
Be sure to check them out at intelnervana.com.

00:46.000 --> 00:50.040
If you haven't already listened to the first show in this series, where I interview Naveen

00:50.040 --> 00:56.240
Raugh, who leads Intel's newly formed AI products group, and Hanlon Tang and algorithms

00:56.240 --> 01:02.200
engineer on that team, it's Twinmultaugh number 31, and you definitely want to start there.

01:02.200 --> 01:06.080
My guess for this show is Doug Eck of Google Brain.

01:06.080 --> 01:10.720
Doug did a keynote at the O'Reilly conference on magenta, Google's project for melding

01:10.720 --> 01:12.680
machine learning and the arts.

01:12.680 --> 01:18.200
Doug and I talk about the newly announced performance RNN project, which uses neural networks

01:18.200 --> 01:21.880
to create expressive AI-generated music.

01:21.880 --> 01:25.800
The demonstrations of this project are truly incredible and I encourage you to check them

01:25.800 --> 01:28.800
out via the links we're placing in the show notes.

01:28.800 --> 01:30.800
All right, on to the show.

01:30.800 --> 01:42.760
All right, hey everyone, I am here with Doug Eck at the O'Reilly AI conference.

01:42.760 --> 01:47.760
Doug is a research scientist on the Google Brain team, who's principally focused on the

01:47.760 --> 01:49.440
magenta project.

01:49.440 --> 01:50.760
Doug, welcome to the podcast.

01:50.760 --> 01:52.240
Hey Sam, thanks for having me.

01:52.240 --> 01:53.240
Excited to be here.

01:53.240 --> 01:58.200
Absolutely, so this podcast, while I focus on interviews now, I originally focused on

01:58.200 --> 02:04.000
covering news in the space and I covered the magenta project when it launched.

02:04.000 --> 02:11.520
And I remember this vividly because my daughter was in a summer program or leadership program

02:11.520 --> 02:16.440
or something like, I live in St. Louis and I had to drive her down state and I spent a

02:16.440 --> 02:20.880
bunch of time on the trip back listening to something about, I might have been listening

02:20.880 --> 02:26.960
to my notes or articles that I had doing like text-to-voice about the magenta project.

02:26.960 --> 02:31.760
And so I'm excited to finally get a chance to talk to you about it and learn more about

02:31.760 --> 02:32.760
it.

02:32.760 --> 02:35.240
And yeah, so welcome once again.

02:35.240 --> 02:40.680
I'm happy to be here a little over a year later from our initial launch and still

02:40.680 --> 02:41.680
add it.

02:41.680 --> 02:42.680
Absolutely, absolutely.

02:42.680 --> 02:48.760
And I think this is the first time from an interview perspective that we're really

02:48.760 --> 02:55.320
getting into the intersection of AI and art, which is an area that I've been wanting to

02:55.320 --> 02:57.800
talk a little bit more about as well.

02:57.800 --> 03:00.760
So very excited to have you on.

03:00.760 --> 03:07.360
Earlier today, you delivered a keynote at the conference and we'll jump into that.

03:07.360 --> 03:12.880
But first, why don't you walk us through your background and how you got into AI?

03:12.880 --> 03:14.640
So how did I get into AI?

03:14.640 --> 03:15.880
Good question.

03:15.880 --> 03:23.000
My undergraduate was in English literature, creative writing, and I finished that, and

03:23.000 --> 03:27.880
it turns out some of your listeners may not know this, but it's hard to get a job when

03:27.880 --> 03:28.880
you're undergraduate.

03:28.880 --> 03:29.880
It's in English literature.

03:29.880 --> 03:31.880
You actually have to work at something.

03:31.880 --> 03:35.120
So there's David Foster Wallace and then there's me.

03:35.120 --> 03:40.280
I became a database programmer, which actually I love coding and worked for a while as just

03:40.280 --> 03:41.280
a coder.

03:41.280 --> 03:45.360
Coding databases in Albuquerque, New Mexico and playing music, the pinnacle of my music

03:45.360 --> 03:50.400
career happened in Albuquerque as well, playing for dozens of fans in coffee houses all around

03:50.400 --> 03:51.400
the street.

03:51.400 --> 03:52.400
Is that nice?

03:52.400 --> 03:53.400
I don't know.

03:53.400 --> 03:55.720
I just was doing what I could.

03:55.720 --> 03:57.880
I was passionate about it.

03:57.880 --> 03:59.200
And I drifted back into grad school.

03:59.200 --> 04:02.480
I think I was just, you know, for the intellectual challenge of it and it made more sense

04:02.480 --> 04:03.640
to stay with computer science.

04:03.640 --> 04:08.040
So actually, I think it was one of the better decisions that I made in my life.

04:08.040 --> 04:11.880
I just not easily took the joint, you know, the overlap of two things I was passionate

04:11.880 --> 04:13.240
about, which is computing and music.

04:13.240 --> 04:18.200
And I just said, well, I like music and I like computers.

04:18.200 --> 04:20.280
So what can you do with computers and music?

04:20.280 --> 04:23.320
And you know, it's 24 and that was what I was thinking.

04:23.320 --> 04:24.880
And I said, hey, let's do AI.

04:24.880 --> 04:26.520
Let's do AI music.

04:26.520 --> 04:30.080
So I wanted to work with a guy named Doug Hofstetter at Indiana University.

04:30.080 --> 04:31.080
Okay.

04:31.080 --> 04:33.720
I ended up actually not doing my PhD under his direction, but took courses with him and

04:33.720 --> 04:35.880
ended up working with some other advisors there.

04:35.880 --> 04:42.200
Just kind of dove into a PhD in music and music cognition and computer science and kind

04:42.200 --> 04:47.160
of kept at it and eventually, you know, eventually ended up at Google, having been a faculty

04:47.160 --> 04:48.680
member for a while at University of Montreal.

04:48.680 --> 04:49.680
Okay.

04:49.680 --> 04:53.880
But really, it was kind of following a passion, just doing what I thought I was good

04:53.880 --> 04:54.880
at.

04:54.880 --> 04:55.880
Oh, that's awesome.

04:55.880 --> 04:56.880
That's awesome.

04:56.880 --> 05:03.000
So maybe tell us a little bit about your keynote today and along the way, weave in magenta

05:03.000 --> 05:06.080
or you can start with magenta and then go into the keynote, whatever kind of makes

05:06.080 --> 05:07.080
the most sense.

05:07.080 --> 05:08.080
Sure.

05:08.080 --> 05:13.800
So today's keynote had a particular focus that I think is important, which is that we

05:13.800 --> 05:19.280
can't do machine learning for music or art without the music in the art.

05:19.280 --> 05:23.080
So machine learning is about learning how to solve a problem.

05:23.080 --> 05:26.520
You know, you build an algorithm that itself can learn how to solve a problem.

05:26.520 --> 05:31.840
So I guess it stands to reason that if you want to build machine learning algorithms

05:31.840 --> 05:36.800
that can make music or make art or be tools for musicians and tools for artists, they have

05:36.800 --> 05:38.240
to see the right data.

05:38.240 --> 05:40.520
They have to see the world in the right way.

05:40.520 --> 05:42.600
And so I talked about two projects.

05:42.600 --> 05:45.080
One of them came out today on the magenta blog.

05:45.080 --> 05:47.680
Please check it out, g.co slash magenta.

05:47.680 --> 05:54.400
It's a recurrent neural network trained to make piano music perform a score that it writes.

05:54.400 --> 05:59.600
And crucially, it's trained on real piano performances, captured and midi.

05:59.600 --> 06:02.200
And there's captured and midi really isn't that important.

06:02.200 --> 06:06.160
We still know where, you know, all of the keys were pressed and how long they were pressed

06:06.160 --> 06:09.960
and how hard, you know, the velocity, et cetera.

06:09.960 --> 06:12.720
For your listeners who aren't familiar with midi, think of that as just kind of a way

06:12.720 --> 06:17.600
to store the events that happen when you play, you know, a synthesizer or electric keyboard

06:17.600 --> 06:20.040
or an appropriate piano.

06:20.040 --> 06:26.000
And it turns out that when you train on this data versus a bunch of musical scores that

06:26.000 --> 06:29.440
is with no performance, timing, you know, just the score.

06:29.440 --> 06:33.080
The resulting output of the models is dramatically different.

06:33.080 --> 06:36.760
And to my ear, at least, much more human sounding, almost delicate sometimes in terms of how

06:36.760 --> 06:39.600
the model figures out how to play the piano.

06:39.600 --> 06:41.200
So I thought that was a really nice story.

06:41.200 --> 06:47.000
And the scores that you played during the keynote were incredible.

06:47.000 --> 06:48.600
I mean, the after.

06:48.600 --> 06:53.280
Like there was the before and the after before is just the model train on the score.

06:53.280 --> 06:58.800
But the after was incorporating in, I guess, the more subtle effects, like, I don't know,

06:58.800 --> 07:01.000
attack and delay, I guess, of the ways I'm thinking of it.

07:01.000 --> 07:05.720
Like, just the force with which they pressed the nodes and that kind of thing and timing,

07:05.720 --> 07:07.080
subtle timing differences.

07:07.080 --> 07:12.520
And yeah, I never heard anything like that from a computer-generated program.

07:12.520 --> 07:13.560
Yeah, it's quite nice.

07:13.560 --> 07:18.600
I mean, I haven't done a thorough enough literature search to know if, you know, I haven't

07:18.600 --> 07:19.600
heard anything like it either.

07:19.600 --> 07:22.600
Hopefully people will come up and say, hey, we did this cool work before and we'll say,

07:22.600 --> 07:23.600
great, we'll credit it.

07:23.600 --> 07:24.600
We'll learn from it.

07:24.600 --> 07:25.600
You know, this is a research project.

07:25.600 --> 07:28.440
We're trying to always give credit where it's due, but I haven't heard anything quite

07:28.440 --> 07:29.440
like this.

07:29.440 --> 07:32.680
And I think you're right, you know, the way to think about it is, you know, Chopin wrote

07:32.680 --> 07:34.160
a piece of music, right?

07:34.160 --> 07:38.040
Yeah, we still love listening to different pianists interpret that music.

07:38.040 --> 07:42.080
And especially with that kind of music, the interpretation actually matters.

07:42.080 --> 07:47.200
You know, if you don't believe it, it's really entertaining to listen to a truly robotic

07:47.200 --> 07:50.360
performance of a piece of music that just doesn't work.

07:50.360 --> 07:54.840
And I think, you know, in modern pop and rock and jazz, it's even more so the case.

07:54.840 --> 07:59.800
Like think of Jimmy Hendrix playing the star-spangled banner.

07:59.800 --> 08:05.680
Like we're not listening to that because of the score, right, because this melody is

08:05.680 --> 08:06.680
so good, right?

08:06.680 --> 08:07.680
Right.

08:07.680 --> 08:11.080
It has cultural significance and it's this carrier for the sounds that Jimmy's making

08:11.080 --> 08:12.080
with his guitar.

08:12.080 --> 08:13.080
Yeah.

08:13.080 --> 08:16.840
So like this idea that the expressive timing matters is, you know, if you kind of unpeel

08:16.840 --> 08:18.800
the onion a little bit, it's pretty clear.

08:18.800 --> 08:22.280
And it's really fun to see what a model can do when it finally has that data.

08:22.280 --> 08:27.880
Well, you made a comment that I thought was really, really interesting and that was that,

08:27.880 --> 08:36.960
you know, what this work gets you closer to is looking at the keyboard or other instruments

08:36.960 --> 08:42.480
in other cases, but as, you know, sensors that are capturing sensory motor control from

08:42.480 --> 08:47.200
humans all the way up, you know, from fingers to muscles to, you know, neural transmission

08:47.200 --> 08:48.600
and that kind of stuff.

08:48.600 --> 08:50.440
Can you elaborate on that a little bit?

08:50.440 --> 08:51.440
Yeah.

08:51.440 --> 08:52.440
And did I capture that?

08:52.440 --> 08:53.440
You did.

08:53.440 --> 08:54.440
I think you did, yeah.

08:54.440 --> 08:58.000
So first in terms of just the model, yeah, what's being captured is how hard the finger

08:58.000 --> 09:03.600
hit the key and there are lots of just kind of the data picks up on, you know, human constraints

09:03.600 --> 09:05.800
that I think are important to music, right?

09:05.800 --> 09:11.120
And I've always been fascinated by the connections between dance and music and between motor control

09:11.120 --> 09:12.880
and general and music.

09:12.880 --> 09:15.960
There's lots, you know, piles of books written about why is music here?

09:15.960 --> 09:21.200
Is it maybe creating co-presence between people or it's about motor control synchronization

09:21.200 --> 09:26.120
and it's about just having fun, but in any case, it's clear that there's the motoric aspect

09:26.120 --> 09:27.120
is really important.

09:27.120 --> 09:29.160
The same thing is true for drawing, right?

09:29.160 --> 09:32.680
The constraints of the hand, what the hand can do, I think, is really important whether

09:32.680 --> 09:35.480
it's holding a paintbrush, you know, or a pencil.

09:35.480 --> 09:39.880
I guess arguably if you move to Photoshop here in a different world, I'm not sure that

09:39.880 --> 09:42.800
it matters how your hand holds the mouse, but maybe there, too.

09:42.800 --> 09:47.240
And it's really cool that we're able to train on the data that drives that.

09:47.240 --> 09:48.640
I could say more about this if you want.

09:48.640 --> 09:49.640
Sure.

09:49.640 --> 09:54.120
The other thing that I would add is a lot of people work in machine learning right now

09:54.120 --> 09:57.080
are working with images and with audio.

09:57.080 --> 09:58.080
I mean, we are, too.

09:58.080 --> 10:00.000
And I think it's really important.

10:00.000 --> 10:04.280
But I'm always concerned by, or not concerned by, but intrigued by the idea that when we

10:04.280 --> 10:09.960
as people, when we make new artifacts, whether it's like a new painting or a new piece of

10:09.960 --> 10:15.720
music, we tend to actually not do it pixel by pixel or, you know, we don't have the control,

10:15.720 --> 10:20.040
even our voices, we don't really have control over the waveform, right?

10:20.040 --> 10:23.880
We have a buzzer in our throat called, you know, called vocal cords and then we're shaping

10:23.880 --> 10:24.880
our vocal tract, right?

10:24.880 --> 10:30.560
It's very, very in machine learning terms, it's, it's a pretty low dimensional control

10:30.560 --> 10:31.760
surface, right?

10:31.760 --> 10:34.200
So we're not dealing with like millions of parameters.

10:34.200 --> 10:37.480
We're able to like move some muscles around and make something vibrate.

10:37.480 --> 10:41.720
With playing a piano, we build this thing out of wood and metal and then fundamentally

10:41.720 --> 10:43.760
we bang it with our fingers, right?

10:43.760 --> 10:47.920
And so, you know, I think, I think trying to do machine learning for art and music, trying

10:47.920 --> 10:51.920
to move into these spaces that are really low dimensional and by that, I mean, you've

10:51.920 --> 10:55.920
only got 88 keys and that may seem like a lot until you think of the number of pixels

10:55.920 --> 11:02.320
there are in an image or the number of moving numbers there are in a one second of CD quality

11:02.320 --> 11:03.320
audio.

11:03.320 --> 11:05.560
It's a relatively low number of parameters to work with.

11:05.560 --> 11:10.480
And I think that that ties to these really beautiful ideas about, you know, what is meaning

11:10.480 --> 11:15.240
but at some level, compression, like just pulling the important bits out of a hard problem

11:15.240 --> 11:16.720
and it's easier to get there.

11:16.720 --> 11:18.240
I'm getting too philosophical, but...

11:18.240 --> 11:22.760
No, I mean, it's an interesting conversation and it reminds me a little bit of not much

11:22.760 --> 11:27.480
of an audio file admittedly or not at all an audio file really admittedly.

11:27.480 --> 11:28.480
But...

11:28.480 --> 11:30.480
Big headphones, I mean, come on.

11:30.480 --> 11:35.640
But, you know, you get people argue over, you know, CDs versus vinyl records and like

11:35.640 --> 11:40.320
the, you know, the get into these debates about the richness of the vinyl records or transistors

11:40.320 --> 11:45.600
versus tubes and that kind of thing and it does, you know, when you think about it in

11:45.600 --> 11:51.200
this context, it does kind of think of, you know, the machine learning, the input that

11:51.200 --> 11:54.920
we're giving to machine learning models in a lot of ways is kind of reductionists and

11:54.920 --> 12:01.040
do we, you know, how do we make sure we don't reduce out the essence of the thing, right?

12:01.040 --> 12:03.040
Does that make any sense?

12:03.040 --> 12:04.040
Yeah, it does.

12:04.040 --> 12:09.600
I mean, so first, I think that we are always at risk of doing that and what makes the

12:09.600 --> 12:14.680
problem retain, you know, retain for me its beauty is that, you know, we're always there.

12:14.680 --> 12:18.360
Like, I'm not interested in a machine learning algorithm where I can just push a button and

12:18.360 --> 12:19.880
have it do its work.

12:19.880 --> 12:23.440
I mean, I think it's cool, like the samples we posted today were basically pushing a

12:23.440 --> 12:25.920
button, but that's more or less to understand how the model works.

12:25.920 --> 12:30.840
I think these get interesting when you close the loop and you have musicians able to work

12:30.840 --> 12:36.800
with them and use them as ways to kind of expand possibilities or create some, some

12:36.800 --> 12:39.600
line and then you add another line, et cetera, like that.

12:39.600 --> 12:44.080
I think that becomes, becomes less reductionist, but yeah, look, let's be real.

12:44.080 --> 12:45.080
What are these bottles doing?

12:45.080 --> 12:46.600
They're basically warping data.

12:46.600 --> 12:49.960
They're doing some, they're taking some numbers in and they're transforming them and

12:49.960 --> 12:51.840
they're pushing some numbers out.

12:51.840 --> 12:55.240
Hopefully you've done the math right and you can, you can roll the dice and sample from

12:55.240 --> 12:57.880
these and get lots of different really interesting instances.

12:57.880 --> 13:02.120
But yeah, I mean, reductionist is a pretty fair term.

13:02.120 --> 13:08.680
Were we close to being able to do like a music style transfer, like, you know, I've got

13:08.680 --> 13:13.760
this rough idea of, you know, score or melody or, yeah, I don't know what the input would

13:13.760 --> 13:18.120
be, but, you know, show pan eyes this for me.

13:18.120 --> 13:23.560
The demo that you played was kind of a vocative of that kind of idea for me.

13:23.560 --> 13:29.240
If we rely on the representation of MIDI, where what we're manipulating are the notes

13:29.240 --> 13:32.160
and when they happen and how many of them there are and we're adding and subtracting notes

13:32.160 --> 13:37.920
and we're performing them, yeah, I think we can, we can imagine with some work being able

13:37.920 --> 13:40.160
to do a style transfer over something.

13:40.160 --> 13:46.960
However, can we take an Adele tune and make it sound like it was done by, I mentioned

13:46.960 --> 13:47.960
Jimmy Hendrix, right?

13:47.960 --> 13:48.960
Right.

13:48.960 --> 13:49.960
It's a very different kind of style transfer.

13:49.960 --> 13:53.720
Or can we, can we take it and Adele tune and make it sound like bebop jazz from the

13:53.720 --> 13:54.720
audio?

13:54.720 --> 13:55.720
Right.

13:55.720 --> 13:56.720
We're very, very far from that.

13:56.720 --> 14:00.720
I think, to be honest, I think that's more getting at the flavor of what style transfer

14:00.720 --> 14:02.600
for images does.

14:02.600 --> 14:07.120
And the reason I bring it up is that there's a nice trick in style transfer for images.

14:07.120 --> 14:11.520
You know, for example, taking a painting and making it look more like Picasso, which is

14:11.520 --> 14:16.360
that it's, it's looking at little patches in the image and the patches are varying sizes,

14:16.360 --> 14:17.360
but it's always local.

14:17.360 --> 14:18.360
Right.

14:18.360 --> 14:22.760
Literally, you can imagine just like moving a little spotlight over, over the image.

14:22.760 --> 14:25.640
And then doing transforms at some layer of granularity.

14:25.640 --> 14:29.480
So you can like get thicker brush strokes versus thinner ones, right?

14:29.480 --> 14:33.440
But in music, you know, music unfolds in time.

14:33.440 --> 14:38.560
And it's not always the case that it's the nearest sounds that are the most important.

14:38.560 --> 14:41.440
There's not this locality, this spatial locality in music.

14:41.440 --> 14:45.480
And I think, I think that would make like a style transfer so that something sounded more

14:45.480 --> 14:49.240
like, you know, an electric guitar quite, quite a bit harder.

14:49.240 --> 14:53.200
I don't, certainly the tools that are used for image style transfer don't quite make sense.

14:53.200 --> 14:57.440
Which is why, by the way, we don't see lots of groups have tried this.

14:57.440 --> 15:00.400
We don't see compelling audio based style transfers.

15:00.400 --> 15:01.400
Okay.

15:01.400 --> 15:02.400
We're getting there.

15:02.400 --> 15:03.400
We'll get there.

15:03.400 --> 15:04.400
I mean, someone will figure it out.

15:04.400 --> 15:06.400
But it's just, it doesn't sort of fall out for free from the, from the image side.

15:06.400 --> 15:07.400
Right.

15:07.400 --> 15:08.400
Right.

15:08.400 --> 15:13.240
So why don't you walk us through the, kind of the technical underpinnings, the architecture

15:13.240 --> 15:17.240
of the, the project that we just talked about.

15:17.240 --> 15:21.880
The project performance RNN, we give things names just to have something to talk about.

15:21.880 --> 15:26.840
It's not an important name, but performance RNN is a recurrent neural network called

15:26.840 --> 15:34.360
LSTM, long short-term memory, that is listening to, to lots and lots of performances, in this

15:34.360 --> 15:36.000
case, panel performances.

15:36.000 --> 15:41.400
What it's seeing is actually a very simple encoding of that performance, a note turned

15:41.400 --> 15:48.920
on that had this velocity, a note turned off, let's advance time, let's advance the clock.

15:48.920 --> 15:53.560
So it's almost like, imagine you've got a paper punch in your cutting holes, you punch,

15:53.560 --> 15:56.600
punch, punch, punch, and then you move forward and you punch, punch, punches, a very, very,

15:56.600 --> 16:00.000
very simple way to reduce to represent the data, but it's not losing any of the data.

16:00.000 --> 16:02.920
You can reconstruct the entire performance from there, right?

16:02.920 --> 16:06.080
The recurrent neural network is, is trying to solve an interesting problem.

16:06.080 --> 16:08.200
It's listening, so to speak.

16:08.200 --> 16:10.080
It's processing this information.

16:10.080 --> 16:12.800
It's trying to predict what's coming next.

16:12.800 --> 16:18.760
And in our case, it can predict, hey, generate another note, turn off a note, or move the

16:18.760 --> 16:20.200
clock.

16:20.200 --> 16:24.120
And every time it gets it right, every time it predicts correctly what it's being trained

16:24.120 --> 16:27.000
on, you know, it gets a good job.

16:27.000 --> 16:32.200
And every time it gets it wrong, then we adjust the weights of the network.

16:32.200 --> 16:36.720
So these are weighted connections between computational units or nodes in the network, so that

16:36.720 --> 16:38.920
it does better next time.

16:38.920 --> 16:44.640
And so it's really playing kind of a funny telephone game, you know, where you, maybe that's not

16:44.640 --> 16:45.640
the right word for it.

16:45.640 --> 16:49.080
I had an analogy for this, but like, it's kind of a weird thought.

16:49.080 --> 16:50.080
You know, you're listening.

16:50.080 --> 16:54.200
You've heard six notes of a melody, and you're trying to guess what the seventh note is.

16:54.200 --> 16:56.360
Even people aren't going to get it right all the time, because there's lots of possible

16:56.360 --> 16:58.240
ways, which things can go.

16:58.240 --> 17:01.880
So in the end, these models, they don't memorize specific tunes.

17:01.880 --> 17:07.000
Instead, they kind of figure out patterns of what should come next given these previous

17:07.000 --> 17:08.000
notes.

17:08.000 --> 17:09.480
And in fact, they learn about chords.

17:09.480 --> 17:10.480
They learn about arpeggiation.

17:10.480 --> 17:13.920
They learn about scales, because those happen in the data.

17:13.920 --> 17:14.920
Okay.

17:14.920 --> 17:19.320
And when we want to make a piece of music, we do take a clever, very simple trick that's

17:19.320 --> 17:24.160
been around for 20 years, you start with a note or two, and then you predict what should

17:24.160 --> 17:25.160
come next.

17:25.160 --> 17:29.040
And that's like a, not an exact answer.

17:29.040 --> 17:32.080
The model says these are the possible things that can come next.

17:32.080 --> 17:34.240
You choose one based upon those probabilities.

17:34.240 --> 17:37.520
And then you feed it in, like you feed, it's, you feed the networks output back in as

17:37.520 --> 17:39.920
input, and you kind of keep going called auto regression.

17:39.920 --> 17:42.240
And in that way, you end up like composing a new score.

17:42.240 --> 17:43.240
Okay.

17:43.240 --> 17:48.520
How many order of magnitude musical samples are you training this on?

17:48.520 --> 17:53.240
And are you training them on full scores or snippets or does that matter?

17:53.240 --> 17:54.240
It does matter.

17:54.240 --> 17:58.320
And the end, for technical reasons, you end up kind of chunking things, but we have ways

17:58.320 --> 17:59.320
to do that automatically.

17:59.320 --> 18:04.680
So in terms of when the model receives the input, it processes an entire score.

18:04.680 --> 18:09.360
I think it's on the order of 20 or 30,000 pieces of music in this case, it's not huge.

18:09.360 --> 18:13.680
They're all performances, and they're all from solo piano.

18:13.680 --> 18:14.680
Okay.

18:14.680 --> 18:20.120
So, and, and did, did you commission them or co, no, these are, so these are all pieces that

18:20.120 --> 18:24.800
were, you know, like Chopin, you know, it's all public old, you know, old classical music

18:24.800 --> 18:28.680
and their performances that come from a number of sources, all kind of freely out there

18:28.680 --> 18:29.680
on the web.

18:29.680 --> 18:33.280
And you can, you can track those down if you follow the magenta blog where we have it.

18:33.280 --> 18:34.280
Okay.

18:34.280 --> 18:36.120
It's probably not interesting to go and aware the data source has actually come from,

18:36.120 --> 18:39.600
but they're, but behind the dollar, are people having performed these for sometimes

18:39.600 --> 18:40.600
for competitions?

18:40.600 --> 18:41.600
Okay.

18:41.600 --> 18:45.480
One of the sources is that you can use is, is Yamaha has a particular kind of piano that's

18:45.480 --> 18:49.440
like a player piano called the disclivier, and they've had competitions where very, you

18:49.440 --> 18:51.560
know, top to your pianist come and play.

18:51.560 --> 18:54.680
And at the same time, the piano records all of the movements of the hammers, so you have

18:54.680 --> 18:56.080
the trace left behind of what they played.

18:56.080 --> 18:57.080
Oh well.

18:57.080 --> 18:58.720
So we're training, we can train that data like that.

18:58.720 --> 18:59.720
Okay.

18:59.720 --> 19:00.720
Oh, really interesting.

19:00.720 --> 19:07.680
So you've got this, you know, 20, 30,000, and were they all specifically Chopin or

19:07.680 --> 19:12.040
no matter how much variation, large variation across the classical tradition.

19:12.040 --> 19:13.040
Okay.

19:13.040 --> 19:14.880
And we have other, we can collect other data sets.

19:14.880 --> 19:19.080
In fact, you know, it's perfectly reasonable for someone to actually just collect a few

19:19.080 --> 19:22.280
hours of playing of their own, and that's going to be enough to train a model.

19:22.280 --> 19:26.640
Not one hour, but if you, if like one of your listeners is say like a jazz pianist and

19:26.640 --> 19:30.640
does jazz improv, you know, you could, you could train a model on just a few hours of

19:30.640 --> 19:35.360
improv, and then they'd have their own, like the model would encode their own playing style,

19:35.360 --> 19:36.360
which is kind of cool.

19:36.360 --> 19:37.360
Right.

19:37.360 --> 19:38.360
Right.

19:38.360 --> 19:40.440
And then when you sample from the model, you can kind of hear some, some of your own aspects

19:40.440 --> 19:41.440
of playing.

19:41.440 --> 19:42.440
Wow.

19:42.440 --> 19:49.160
So what degree was the network architecture for this particular neural network?

19:49.160 --> 19:54.680
How is it unique from other network architectures that are used for, you know, other LSTM based network

19:54.680 --> 19:59.200
architectures that are used for like, you know, the kind of thing you do to, you know, we've

19:59.200 --> 20:01.920
seen the projects where we're getting scripts auto generated.

20:01.920 --> 20:02.920
Right.

20:02.920 --> 20:03.920
That's good.

20:03.920 --> 20:04.920
Yeah.

20:04.920 --> 20:05.920
Yeah.

20:05.920 --> 20:06.920
Yeah.

20:06.920 --> 20:08.320
The network is actually pretty much a generic LSTM.

20:08.320 --> 20:10.960
What's somewhat novel is the representation of the data.

20:10.960 --> 20:13.120
So what the model is trying to predict.

20:13.120 --> 20:19.240
There have been other people who have predicted like the duration of, of a note in terms of

20:19.240 --> 20:23.440
its relative duration in the score, like, I'm going to generate a middle C, and it's

20:23.440 --> 20:25.720
going to be a 16th note.

20:25.720 --> 20:29.160
And we've simply extended that to say, well, forget about whether it's a 16th note.

20:29.160 --> 20:33.520
Instead, let's just move the clock forward some number of milliseconds.

20:33.520 --> 20:36.000
And that way, we'll just learn about real time.

20:36.000 --> 20:37.000
Right.

20:37.000 --> 20:41.600
So if that's not clear, that means we don't need a metronome to figure out what a quarter

20:41.600 --> 20:42.600
note is.

20:42.600 --> 20:43.600
Right.

20:43.600 --> 20:46.760
If that's not clear, like, what a quarter note is is that it's a quarter of a measure.

20:46.760 --> 20:48.960
And what a measure is is defined by the beat.

20:48.960 --> 20:52.560
And if the beat's fast, quarter note takes less time to be played, right?

20:52.560 --> 20:57.120
Here we're just saying, we're just going to look at the time of the pieces at unfolds

20:57.120 --> 20:58.480
in the performance.

20:58.480 --> 21:00.480
And so the model doesn't know what a quarter note is at all.

21:00.480 --> 21:02.840
It just generates notes and moves the clock.

21:02.840 --> 21:04.440
And that, I think that's unique.

21:04.440 --> 21:08.240
Again, we just put this blog posting out and we're in the middle writing a paper around

21:08.240 --> 21:09.240
it.

21:09.240 --> 21:11.520
And it's pretty hard and research to do something that's completely new.

21:11.520 --> 21:13.760
You always find that someone did something similarly, right?

21:13.760 --> 21:17.560
I mean, there's almost nothing new under the stars and sun.

21:17.560 --> 21:18.560
Nice.

21:18.560 --> 21:24.000
Well, we'll definitely include the audio that you shared in your keynote in the show notes

21:24.000 --> 21:25.800
for folks to check out.

21:25.800 --> 21:28.040
It was really, really compelling.

21:28.040 --> 21:32.760
We also talked about a project based on the Google Draw experiment.

21:32.760 --> 21:33.760
Yeah.

21:33.760 --> 21:35.280
Tell us a little bit about that one.

21:35.280 --> 21:37.480
That was an AI experiment called Quick Draw.

21:37.480 --> 21:40.640
It was done by the Creative Lab folks in New York at Google.

21:40.640 --> 21:45.680
And what they did was they, we already had some image classifiers that we can use that

21:45.680 --> 21:49.960
can identify like tens of thousands of different kinds of images.

21:49.960 --> 21:54.280
You see, you point your mobile device and it recognizes through the camera that that's

21:54.280 --> 21:57.880
a lamp or that's a dog or that's a cell phone.

21:57.880 --> 22:01.920
And so someone had a clever idea of saying, well, what if could it identify a sketch of

22:01.920 --> 22:04.840
a dog or a sketch of a cell phone, it turns out, yeah, I can't.

22:04.840 --> 22:08.960
So you get to play Pictionary against an image classifier.

22:08.960 --> 22:11.320
Actually, you're playing Pictionary with an image classifier.

22:11.320 --> 22:12.960
Remember Pictionary is collaborative, right?

22:12.960 --> 22:18.200
And so you're given a prompt like, hey, you have 20 seconds to draw a dog and you try

22:18.200 --> 22:19.200
to draw a dog.

22:19.200 --> 22:23.560
And if the image classifier can guess it, then you get a point, right?

22:23.560 --> 22:28.320
So at some point, we decided we wanted to use this data for machine learning.

22:28.320 --> 22:30.280
So we changed the messaging on the site.

22:30.280 --> 22:32.520
So it said, hey, we're going to, you know, if you want to play the game, we're just going

22:32.520 --> 22:35.640
to keep anonymized drawings around, we're going to learn from them, right?

22:35.640 --> 22:36.640
We're going to train.

22:36.640 --> 22:37.640
So so we kept that data.

22:37.640 --> 22:41.360
We gave it back to the community to use for other, for artistic purposes and people have

22:41.360 --> 22:43.640
done tons of crazy things with this data.

22:43.640 --> 22:45.120
What are some of those things?

22:45.120 --> 22:47.000
So this, by the way, this is an art machine learning.

22:47.000 --> 22:52.000
This is just the people's drawings, analyzing how different people in different cultures

22:52.000 --> 22:56.160
draw circles, turns out like some cultures draw circles clockwise and other cultures

22:56.160 --> 22:59.640
draw them counterclockwise and you kind of clustered things.

22:59.640 --> 23:05.680
The way that people draw chairs, Asian culture is apparently draw chairs often, I'm going

23:05.680 --> 23:12.040
to get these backwards because yeah, they usually draw chairs in, no, it's in three, whether

23:12.040 --> 23:16.120
you do it in 3D or 2D, whether a chair is just like an H almost, right?

23:16.120 --> 23:17.360
Which is what I would draw.

23:17.360 --> 23:18.800
And I think that's actually an Asian pattern.

23:18.800 --> 23:19.800
Okay.

23:19.800 --> 23:25.760
Yeah, someone else outside of Google took the data, the circle stuff is like a blog posting

23:25.760 --> 23:28.520
from a couple of weeks ago, encourage your listeners to find it.

23:28.520 --> 23:32.480
Just a Google like quick draw circles and it has you draw a circle and tells you some

23:32.480 --> 23:36.400
things about the circle you drew and analyzes the circles from around the world.

23:36.400 --> 23:40.680
And so I don't know, you just kind of get this kind of fun, I mean, it's not world changing,

23:40.680 --> 23:41.680
but it's interesting, right?

23:41.680 --> 23:43.360
It's a kind of sociology behind it.

23:43.360 --> 23:44.680
Anyway, I digress.

23:44.680 --> 23:50.400
We had this data and David Ha, who is the primary person on this paper, decided to train

23:50.400 --> 23:53.840
a recurrent neural network to try to reproduce the strokes.

23:53.840 --> 23:55.680
And we have the strokes as they appeared in order.

23:55.680 --> 23:59.640
So, you know, if you were trying to draw a garden, if you drew a flower first and then you drew

23:59.640 --> 24:03.040
the grass, then it would be reproduced in that order.

24:03.040 --> 24:04.720
This was a slightly different model.

24:04.720 --> 24:08.880
This was two different recurrent neural networks and an intermediate representation.

24:08.880 --> 24:11.240
But maybe that's too far a field too.

24:11.240 --> 24:20.000
The upshot is you can now generate new instances of like dogs or cats or, you know, several

24:20.000 --> 24:25.000
hundred classes and kind of try to get a better understanding of what people are doing

24:25.000 --> 24:28.080
when they draw them and also have a way to explore the space.

24:28.080 --> 24:29.080
Hmm.

24:29.080 --> 24:31.080
So what exactly does that mean?

24:31.080 --> 24:37.240
You've got a kind of encoder, decoder encoder set up where the decoder is learning, how

24:37.240 --> 24:41.600
people are drawing these things and you've got an encoder that is trying to, you know,

24:41.600 --> 24:46.120
give it a thing that it's trying to create that thing or...

24:46.120 --> 24:49.240
I think you reverse it to reverse it to reverse it to reverse it.

24:49.240 --> 24:55.440
Yeah, so the one way to think about it is that the work that I described with the performance

24:55.440 --> 24:58.440
RNN, you could think of as a decoder.

24:58.440 --> 25:01.440
It's not encoding into some different representation.

25:01.440 --> 25:05.240
It's basically just taking the score and trying to predict the next note.

25:05.240 --> 25:07.400
This model does something slightly different.

25:07.400 --> 25:13.520
It takes the strokes and tries to encode them into a vector, into a sequence of numbers.

25:13.520 --> 25:20.680
And then only from that sequence of numbers does it try to reproduce or decode the drawing.

25:20.680 --> 25:22.920
So it's getting these strokes in.

25:22.920 --> 25:28.040
It's pushing some information via recurrent neural network into this kind of intermediate

25:28.040 --> 25:32.160
representation called our latent space if you want the technical term.

25:32.160 --> 25:36.200
And then it's trying to then recreate the drawing by decoding it using another recurrent

25:36.200 --> 25:37.680
neural network.

25:37.680 --> 25:43.000
And the crucial, the reason that we use this intermediate step of this latent space is

25:43.000 --> 25:48.080
that if we've constructed it correctly, we can do a really nice job of generating new

25:48.080 --> 25:51.280
samples with lots of variants for the same problem.

25:51.280 --> 25:52.280
I don't know.

25:52.280 --> 25:53.280
A library on that.

25:53.280 --> 25:54.280
Yeah.

25:54.280 --> 25:55.880
No idea how technical they get.

25:55.880 --> 26:02.040
So for example, we could take the drawing of a face that has like almost like a triangle

26:02.040 --> 26:07.520
inverted triangle or like a pointy chin, right, and we could run that through the encoder.

26:07.520 --> 26:09.440
And that would give us some vector.

26:09.440 --> 26:15.080
And then we might take another face that's a big round face, we know with a big round

26:15.080 --> 26:17.880
nose and run that through the encoder.

26:17.880 --> 26:21.360
And that would give us another vector in this latent space, right.

26:21.360 --> 26:24.960
But now we have these two vectors that are not very big, maybe a few dozen numbers or

26:24.960 --> 26:26.600
maybe a hundred numbers.

26:26.600 --> 26:29.240
And we could just take the average of those two.

26:29.240 --> 26:34.200
And that should, if we've trained our model right, give us the face that is somewhere

26:34.200 --> 26:39.360
towards, yeah, kind of between this triangular face and between this circular face, right.

26:39.360 --> 26:43.760
And if you do that enough, you get to like the meaning of a face, right?

26:43.760 --> 26:44.760
Is that the idea?

26:44.760 --> 26:45.760
Yeah.

26:45.760 --> 26:49.880
I mean, you capture, yeah, I mean, in a hand-woven philosophical way, you get the platonic

26:49.880 --> 26:50.880
face.

26:50.880 --> 26:51.880
Right.

26:51.880 --> 26:55.320
In a less ridiculous way, at the very least you get like, what's happening is that latent

26:55.320 --> 26:58.920
space is forced, is encoding those aspects of the face that are the most important to

26:58.920 --> 27:01.960
remember if you want to be able to cover the variance of faces.

27:01.960 --> 27:06.640
And so, yeah, it's captured something really important, some of the really important aspects

27:06.640 --> 27:07.640
of faces.

27:07.640 --> 27:11.920
So in that latent space, as you move around that space and maybe you generate some random

27:11.920 --> 27:16.360
vector in that space, you should still be able to decode some kind of face, right.

27:16.360 --> 27:17.840
Let's call it a variational model.

27:17.840 --> 27:18.840
Okay.

27:18.840 --> 27:22.600
So I don't know if that captures the gist of the tech.

27:22.600 --> 27:26.600
I think that one of the take home messages is the goal, the reasons why we're caring

27:26.600 --> 27:31.880
about having this embedding space, this latent space is that we can use it as a way to

27:31.880 --> 27:35.920
give artists more control over a model like that.

27:35.920 --> 27:41.880
So for example, you could take, you could draw a face and encode it through the encoder.

27:41.880 --> 27:45.120
And then now you have this vector and you could perturb that vector, you could move that

27:45.120 --> 27:50.320
vector around, you could use this as a starting point for some, you know, some other work

27:50.320 --> 27:51.640
with the model.

27:51.640 --> 27:54.280
You could just email that vector to someone else and they could reproduce it, they could

27:54.280 --> 27:55.600
know what you think about.

27:55.600 --> 28:01.040
Now granted, this is all in the context of drawings that took 20 seconds to make using

28:01.040 --> 28:02.320
a mouse on a computer.

28:02.320 --> 28:07.960
So our expectations are not that, you know, people will go, oh, I can make, you know, the

28:07.960 --> 28:10.480
next shagall painting or whatever with this.

28:10.480 --> 28:16.880
But that in principle, you have this space where, you know, we can encode some drawing

28:16.880 --> 28:21.400
into some space that is kind of really good at storing drawings.

28:21.400 --> 28:24.600
And then from there, we can carry that around and we can decode not just that original

28:24.600 --> 28:28.800
drawing, but tons of drawings like it, and then maybe, you know, be able to move forward

28:28.800 --> 28:33.040
with, you know, possibilities for moving around that space for reasons like for animation

28:33.040 --> 28:34.040
and things like that.

28:34.040 --> 28:35.040
Okay.

28:35.040 --> 28:36.040
It's interesting.

28:36.040 --> 28:40.400
One of the other, one of the interviews I did yesterday that'll be coming out at the

28:40.400 --> 28:46.120
same time in this O'Reilly series is, we're talking about word to veck.

28:46.120 --> 28:51.680
And it's interesting to kind of think about all of the various, we talked about several

28:51.680 --> 28:58.040
applications of embeddings in the context of, you know, word to veck and related things.

28:58.040 --> 29:00.520
But, you know, this is definitely drawing to veck.

29:00.520 --> 29:01.520
Right.

29:01.520 --> 29:02.520
Yeah.

29:02.520 --> 29:10.480
So you encode your samples into this vector or vector space and then you use that to,

29:10.480 --> 29:15.280
you can use that as, you know, almost like a filter for creating things through the decoding

29:15.280 --> 29:16.280
process.

29:16.280 --> 29:21.720
I think one of the examples you showed was, and contextualize this for us, but you had

29:21.720 --> 29:24.440
folks draw like an eight-legged pig.

29:24.440 --> 29:29.200
You encoded that and then decoded it using the kind of the pig vector.

29:29.200 --> 29:30.200
Yeah.

29:30.200 --> 29:31.200
Is that the way to think about that?

29:31.200 --> 29:32.200
Yeah.

29:32.200 --> 29:34.040
So you're trading this autoencoder model only on pigs.

29:34.040 --> 29:35.040
Yep.

29:35.040 --> 29:36.040
So it knows nothing but pigs.

29:36.040 --> 29:37.040
Yeah.

29:37.040 --> 29:38.040
Oh, it's pigs all the way down.

29:38.040 --> 29:39.040
Right.

29:39.040 --> 29:41.880
And, you know, we make these latent spaces pretty small and inject some noise.

29:41.880 --> 29:43.160
We don't want them to overfit.

29:43.160 --> 29:44.920
It's boring if they just memorize the data.

29:44.920 --> 29:45.920
Mm-hmm.

29:45.920 --> 29:46.920
Right.

29:46.920 --> 29:50.920
So this little vector can barely, barely manage to generate a pig, but it does pretty

29:50.920 --> 29:52.280
good job of generating pigs.

29:52.280 --> 29:53.280
Mm-hmm.

29:53.280 --> 29:54.280
Yeah, and you give it a pig with eight legs.

29:54.280 --> 29:56.760
Well, it never sees pigs with eight legs.

29:56.760 --> 30:00.800
So it encodes through the encoder, the recurrent norm that work.

30:00.800 --> 30:05.120
It encodes some numbers that were driven by those, those strokes, including the eight

30:05.120 --> 30:06.120
legs.

30:06.120 --> 30:07.120
Mm-hmm.

30:07.120 --> 30:12.120
But when it decodes it, what's remembered by that embedding is that there were four.

30:12.120 --> 30:13.120
Mm-hmm.

30:13.120 --> 30:14.120
Right.

30:14.120 --> 30:15.120
I think it's kind of nice.

30:15.120 --> 30:19.360
Also, the other example that I talked about in the keynote was if you have the same pig

30:19.360 --> 30:26.200
class, the same pig auto encoder, and you take a nice drawing of a semi-truck, you know,

30:26.200 --> 30:27.200
it decodes, guess what?

30:27.200 --> 30:28.200
It's a pig truck, right?

30:28.200 --> 30:32.480
Like, it kind of turns into a pig because that's what the pig model knows about is pigs.

30:32.480 --> 30:34.080
And it's at one level, that's a weakness, right?

30:34.080 --> 30:36.840
It's like, well, but there are so many other things in the world.

30:36.840 --> 30:39.520
But of course, you can train more models and you can train models that are conditional

30:39.520 --> 30:42.000
so they can represent more than one thing.

30:42.000 --> 30:48.480
It's that this latent space is really capturing some important aspects of pigness, right?

30:48.480 --> 30:53.720
And people have someone else in open source, not us, took those very embeddings and then

30:53.720 --> 30:54.720
did something fun.

30:54.720 --> 30:59.640
They started looking for examples of pigs in the quick draw dataset that were far away

30:59.640 --> 31:01.400
from that embedding.

31:01.400 --> 31:06.240
So you imagine you embed a bunch of pigs, so you get the average embedding, you know,

31:06.240 --> 31:10.120
you don't have to embed all of them, but 10,000 of them get the average, right, to

31:10.120 --> 31:11.120
take the average.

31:11.120 --> 31:15.040
Even from there, you embed a pig and you take its distance, how far away is it from that

31:15.040 --> 31:16.440
average, right?

31:16.440 --> 31:20.640
And then, like, what's fun is they just, they just found really poorly drawn pigs, or

31:20.640 --> 31:24.760
they occasionally someone did just written the word pig, you know, and it's like, that's

31:24.760 --> 31:25.760
not a pig.

31:25.760 --> 31:28.280
I mean, it says pig, but these models didn't learn to read.

31:28.280 --> 31:31.800
And so, and so you get this weird kind of fun outlier detection.

31:31.800 --> 31:33.880
And you know, you can cluster the space too.

31:33.880 --> 31:39.920
That's often done with word-to-vec models where you say, okay, like for cats, there are,

31:39.920 --> 31:44.320
it's not that there are just, you know, several million, completely unique cats.

31:44.320 --> 31:48.560
People kind of either draw them in profile, you know, or they draw them just the cat's

31:48.560 --> 31:49.560
head.

31:49.560 --> 31:50.880
And sometimes the profile flips us where this way.

31:50.880 --> 31:54.480
And if you, in this embedding space, if you do clustering in the embedding space, so

31:54.480 --> 31:59.040
you look for, you know, it's not like given the number of possible, the possible values

31:59.040 --> 32:01.200
in this embedding, everything is equally spread out.

32:01.200 --> 32:03.160
It's like, there are mountains, right?

32:03.160 --> 32:06.240
And here's the profile mountain, and here's the profile, the other way mountain, and here's

32:06.240 --> 32:07.240
the face mountain.

32:07.240 --> 32:09.880
And you can visualize that and kind of get an idea, you know, what

32:09.880 --> 32:12.560
people are really doing with these drawings.

32:12.560 --> 32:19.760
Can you then identify a distance from your average pig vector beyond which you won't be

32:19.760 --> 32:21.800
able to recognize something as a pig?

32:21.800 --> 32:24.400
Yeah, and that's the classifiers job.

32:24.400 --> 32:27.840
In this case, it was an autoencoder, so it wasn't trying to decide whether something was

32:27.840 --> 32:28.840
a pig or not.

32:28.840 --> 32:30.520
It was trying to draw a pig.

32:30.520 --> 32:34.000
So there's no, there's no magic value, but you could always calculate one, right?

32:34.000 --> 32:36.920
You can kind of figure out where, where you're going.

32:36.920 --> 32:38.720
It's important to keep track of the goals, right?

32:38.720 --> 32:39.720
Right.

32:39.720 --> 32:43.560
You know, this is, this is a kind of small, it's a large data set in terms of the number

32:43.560 --> 32:47.160
of samples we have, but you know, it's a pretty simple drawing task.

32:47.160 --> 32:51.240
I think it's, it's fun to think about where we can go if we have, if we have better data

32:51.240 --> 32:52.920
and, and better models.

32:52.920 --> 32:54.240
And where is that?

32:54.240 --> 32:56.600
So I think there are a couple of possibilities.

32:56.600 --> 33:04.560
One is that we just nail it, and we, we basically do something that happens one in a million

33:04.560 --> 33:08.680
times, which is we invent a new art form, where we enable a new art form.

33:08.680 --> 33:13.080
Now, it's been done before, technology has done this before, the film camera, enabled

33:13.080 --> 33:14.800
a new art form, right?

33:14.800 --> 33:17.520
The drum machine enabled a new art form.

33:17.520 --> 33:20.920
And we could probably, together we could riff, and if we had a whiteboard, we'd come up

33:20.920 --> 33:21.920
with 30 or 40 of them.

33:21.920 --> 33:25.760
But we wouldn't want to forget that there were another, you know, thousands and thousands

33:25.760 --> 33:30.440
of, did the theorem in invent a new art form, maybe, right?

33:30.440 --> 33:32.560
The synthesizer, yes, right?

33:32.560 --> 33:36.800
So maybe we'll invent a new art form, and it's really interesting to think like what

33:36.800 --> 33:41.320
would, the core of that art form would be that the artist would have something smart

33:41.320 --> 33:43.240
against which to, to project ideas.

33:43.240 --> 33:45.040
I think that would be the core.

33:45.040 --> 33:48.840
That, you know, you can try things out with, with your sequencer, you know, or you can

33:48.840 --> 33:53.720
try things out with Photoshop, or you can try things out with, with a pen and paper.

33:53.720 --> 34:00.360
But the idea that we would have machine intelligence models trained that are, by analogy,

34:00.360 --> 34:03.120
as smart as translate, right?

34:03.120 --> 34:04.120
Because they're trained right.

34:04.120 --> 34:06.520
And you, like, that's really, really interesting, I mean.

34:06.520 --> 34:10.960
There's an inherent limitation in that, in that it, we're training on, for the most

34:10.960 --> 34:13.280
part, things that we've seen before, right?

34:13.280 --> 34:19.600
And so it kind of cuts off, at least intuitively, seems to cut off this creative avenue for

34:19.600 --> 34:24.520
innovating, for, you know, creating the holy new thing.

34:24.520 --> 34:25.520
I agree.

34:25.520 --> 34:31.120
And I think that, I think that if we create a new art form, it will be through gradual,

34:31.120 --> 34:34.840
through many, many interaction loops of artists working with this technology.

34:34.840 --> 34:39.160
So for, like, that's not that crazy to think about, if you watch what happened with the

34:39.160 --> 34:44.240
808 drum machine and drum machines moving forward, people first use drum machines on, on

34:44.240 --> 34:46.320
sort of, you know, Roland's terms.

34:46.320 --> 34:49.360
This is what a drum machine is, you know, but gradually, they just are like, I'm going

34:49.360 --> 34:51.040
to use it however I want, right?

34:51.040 --> 34:54.760
And then the drum machines were manufactured to adapt to that, et cetera.

34:54.760 --> 34:58.280
And I think one way to think about this is, if this were to actually generate a new

34:58.280 --> 35:03.040
art form of interest, you train a model, it generates some things that are somewhat surprising

35:03.040 --> 35:04.800
to you, but you like, you keep them.

35:04.800 --> 35:08.440
You change your writing style somewhat or you change your performance style somewhat.

35:08.440 --> 35:12.080
Maybe, you know, like, I can imagine living in a world where the data is so important,

35:12.080 --> 35:15.560
like part of what you do as an artist is create data.

35:15.560 --> 35:20.160
And so in some sense, you're like, you are helping create this model because you're the

35:20.160 --> 35:23.840
one providing it with its lifeblood with data, or ultimately, you're hacking the model,

35:23.840 --> 35:25.360
either because you're a coder, right?

35:25.360 --> 35:27.880
So then you say, okay, this model changed slightly how I do music.

35:27.880 --> 35:29.840
Maybe it just added some rhythms to my repertoire.

35:29.840 --> 35:30.840
I don't usually use it.

35:30.840 --> 35:34.480
It does some crazy harmonization that I wouldn't normally do.

35:34.480 --> 35:37.920
And then you make some more music and then you retrain your model, but now there's new

35:37.920 --> 35:38.920
stuff there, right?

35:38.920 --> 35:40.640
And you've moved a little bit, right?

35:40.640 --> 35:44.520
I don't think the movement has to be earthquake large.

35:44.520 --> 35:48.320
You know, it doesn't have to be groundbreakingly large to be new, right?

35:48.320 --> 35:53.120
I mean, imagine just like if we kind of work out a new way to harmonize music.

35:53.120 --> 35:56.000
So all, you know, you have a melody and you have all these extra voices.

35:56.000 --> 36:00.240
You know, just imagine via a model that's trained right, we suddenly get different kinds

36:00.240 --> 36:02.480
of harmonizations that we didn't get before.

36:02.480 --> 36:07.120
That would already be interesting or another example I like, which is crazy hard,

36:07.120 --> 36:09.280
but I think it's very evocative.

36:09.280 --> 36:14.800
I think like a long form, something long form like a novel, right?

36:14.800 --> 36:16.720
And think about plot, right?

36:16.720 --> 36:18.640
Like plot, plot is hard, right?

36:18.640 --> 36:21.680
You can, like I, my hat's off to someone who can write like a long,

36:21.680 --> 36:26.400
my hat's off to Game of Thrones and keeping all these characters straight, right?

36:26.400 --> 36:30.080
George R. Martin is my hero, but you could imagine like,

36:30.080 --> 36:33.680
imagine that some writers care less about plot and they really care about character,

36:33.680 --> 36:38.160
they care about texture, imagine the right kind of machine learning model

36:38.160 --> 36:43.520
that can generate intricate plots with really interesting relationships between characters

36:43.520 --> 36:45.680
and movement of action, right?

36:45.680 --> 36:51.200
Such that like maybe in a way that's even, you know, at some level of complexity

36:51.200 --> 36:54.560
too hard for a human to do because it can search out more possibilities,

36:54.560 --> 36:58.640
but yet maybe everything kind of clicks and lands and it feels good as the reader to be like,

36:58.640 --> 37:02.480
oh wow, that character just came and did that, that's crazy, right?

37:02.480 --> 37:05.120
Almost like writing jokes that have sort of three punchlines that all

37:05.120 --> 37:06.960
in, you know, land at the same time.

37:06.960 --> 37:10.880
That like because, you know, machine learning algorithms are really good at

37:10.880 --> 37:13.760
high dimensional spaces with lots of possibilities.

37:13.760 --> 37:16.720
You know, maybe we'd land at some new form of storytelling.

37:16.720 --> 37:19.600
I don't think it would be one where we would care about reading the computer's story,

37:19.600 --> 37:24.960
but that the computer might add something to the writer's world where like,

37:24.960 --> 37:26.800
in some sense the writer might offload plot.

37:26.800 --> 37:28.560
You're like, that's not, I don't do plot.

37:28.560 --> 37:30.640
What I do with the plot is something even more interesting.

37:30.640 --> 37:34.000
Like I shape it, I craft it, I make it beautiful to read, right?

37:34.640 --> 37:37.360
So that's one way to think about it that like, you know,

37:37.360 --> 37:39.840
I don't want this to be too long-winded, but it's really important to me like,

37:39.840 --> 37:43.120
what the drum machine did was in one really important way,

37:43.120 --> 37:45.680
it offloaded some of the percussion work.

37:46.640 --> 37:50.240
But, you know, if you want to be cynical about it, then you're like,

37:50.240 --> 37:52.720
oh yeah, and it just killed, it just killed percussion.

37:52.720 --> 37:53.760
It didn't.

37:53.760 --> 37:58.080
It offloaded one thing and that opened up a bunch of other opportunities, right?

37:58.080 --> 38:03.600
And so then the idea is, well, what sort of things can you offload onto a super smart

38:03.600 --> 38:06.800
machine learning model? And to be honest, I don't know, I don't know the answer,

38:06.800 --> 38:11.200
but I mean, if you move through different kinds of media from painting to music,

38:11.200 --> 38:14.800
to literature, you certainly can get some ideas.

38:14.800 --> 38:16.960
Yeah, awesome, awesome.

38:16.960 --> 38:22.880
And so magenta as a whole is kind of an umbrella for a bunch of these different

38:22.880 --> 38:28.480
directions, right? Maybe you take a second to talk about magenta and how Google

38:28.480 --> 38:31.280
thinks about that, why Google's even, you know,

38:31.280 --> 38:33.680
bothering. Tell us about magenta.

38:34.480 --> 38:37.440
Yeah, this isn't funny. This question usually comes early, right?

38:37.440 --> 38:40.160
It's good to have this come after people have heard some specifics.

38:40.160 --> 38:43.680
So the basic idea is of magenta is posing the question, you know,

38:43.680 --> 38:47.520
what can we do with deep learning and reinforcement learning in this basic creativity?

38:47.520 --> 38:54.880
And we've already fully realized that the meat of the problem lies in these algorithms

38:54.880 --> 38:59.680
interacting with musicians and artists. And that's not because we're afraid of trying to get

38:59.680 --> 39:02.800
these models to be interesting on their own, but that I think that's how art works.

39:02.800 --> 39:05.680
It's collaborative, you know, other artists are working together and we're thinking,

39:05.680 --> 39:07.680
you know, these things are going to work with artists.

39:07.680 --> 39:12.720
And so we, in the last year, magenta has been around publicly for about a year and before

39:12.720 --> 39:15.360
we launched, we were working on it for another six months.

39:15.360 --> 39:20.320
We've done work in music sequence generation, including musical scores and also performances

39:20.320 --> 39:26.080
like we did today. We've done work in generating new kinds of sounds and synth project, which is

39:26.080 --> 39:30.000
basically building a synthesizer where all of the sounds are dreamt up by a neural network.

39:30.960 --> 39:33.760
And we've done some unpublished work in joke telling.

39:33.760 --> 39:38.720
And it's, it's unpublished because, well, it wasn't very funny.

39:38.720 --> 39:44.160
Now we did a summer internship like looking at joke telling as exercise in generating

39:44.160 --> 39:47.680
interesting surprises. I think especially punchline driven humor is like, oh, that was

39:47.680 --> 39:52.240
surprising in a nice way. You know, yes, my kids like getting to the level of dad joke.

39:52.240 --> 39:57.200
It should be hard. I know. I know. I know we're both dads here. We should be experts at this.

39:57.200 --> 40:02.720
Like if we just team up. Yeah. And what my motivation actually is speaking of kids might,

40:03.440 --> 40:08.240
okay, so let me finish the, and then thinking a little bit more about language, but most of what we've

40:08.240 --> 40:12.400
had to do, oh, and then learning to sketch the sketch to sketch our NN stuff. And then some

40:12.400 --> 40:18.000
implementations of style transfer for images. So, so we've got kind of a wide array of things

40:18.000 --> 40:24.240
that we're trying. I think the glue of the project, what holds it together is a, we're limiting

40:24.240 --> 40:29.040
ourselves to deep learning and reinforcement learning. We're looking at creative applications

40:29.040 --> 40:32.960
of machine learning, but we're not going to try everything. Like there are lots of ways to solve

40:32.960 --> 40:36.320
these problems. Lots of great ways. Right. We're not saying that machine learning is the only way

40:36.320 --> 40:38.960
of the sort we're doing. It's just like, we got to limit ourselves to something. So we're part,

40:38.960 --> 40:44.640
we know, we're really linked to TensorFlow. Also that really what we care about are like behind

40:44.640 --> 40:50.960
these, this one year of trying some new things, I think the really core issues lift above any

40:50.960 --> 40:56.720
specific medium. I think it's about, it's about storytelling and narrative, whether it's music or

40:56.720 --> 41:03.040
paintings or literature. And it's about structure and narrative arc and about these ideas about

41:03.040 --> 41:07.520
surprise and what, what makes something simple. So I think there's a, there's a whole area of like,

41:07.520 --> 41:12.960
you know, generative models for media that, that, you know, can we generate interesting

41:12.960 --> 41:17.360
bits of media for us to share that help us tell the story of our lives and, you know,

41:17.360 --> 41:21.840
different modes of communication, possibly coming from this. Actually, almost certainly coming

41:21.840 --> 41:26.640
from this. You know, those are the goals. Why is Google doing this? Well, like, one thing is,

41:26.640 --> 41:30.800
we're publishing a lot of papers. So we're part of Google Brain and the framework of generative

41:30.800 --> 41:35.840
models is important. It's important. It's an important research topic. And the idea that you,

41:35.840 --> 41:41.440
you know, maybe you'd want to generate, you know, new candidate molecules, maybe you'd want to

41:41.440 --> 41:46.480
look at healthcare, maybe you'd want to look at something for robotics and generating trajectories.

41:46.480 --> 41:52.560
But I think, you know, when I look at what my kids are doing with their mobile devices,

41:52.560 --> 41:56.800
I've got a 13 year old and an 18 year old, you know, they're, they're information seeking,

41:56.800 --> 42:01.200
they're entertainment and they're communicating with their friends, right? So there's a huge chunk

42:01.200 --> 42:06.080
of what we're doing with computation that has to do with entertainment. And I think, you know, it's

42:06.080 --> 42:11.200
a really important area of research. I mean, just, you know, just point blank. I think music and

42:11.200 --> 42:15.440
art are important. They are important for our lives and it's absolutely worth investing some time

42:15.440 --> 42:19.680
into it. Awesome. That's what we're doing. Awesome. Anything else that you'd like to

42:20.400 --> 42:27.200
mention or any other places that folks should look or are there, you know, three canonical

42:27.200 --> 42:31.920
resources to, you know, for folks that really want to dig into this? Yeah. So there's two things

42:31.920 --> 42:38.560
I would say. First, please visit g.co slash magenta. That's the shortest link I have. And we have

42:38.560 --> 42:42.320
a blog, we have a blog there that's getting, if you want to geek out, would you call it nerd time?

42:42.320 --> 42:48.320
What did you say? Uh, nerd alert. Nerd. Yeah. We nerds. Listen or nerds. If you like that,

42:48.320 --> 42:54.160
come look at our blog. And the other thing is we're very, very actively trying to engage with

42:54.160 --> 43:00.160
some particular types of folks in the community. There are three types. One type is pretty obvious.

43:00.160 --> 43:05.440
Artists and musicians, fun. And then there's always the machine learning folks, nerd alert. But

43:05.440 --> 43:10.240
there's this middle, middle ground where I think there's probably more there than any place else. And

43:10.240 --> 43:15.440
it's, it's in this kind of world of creative coding. Do you know what I mean by that? So like,

43:15.440 --> 43:20.320
I mean, what do you mean by that? Well, I mean, I'm sort of stealing that, you know, creative coding

43:20.320 --> 43:25.600
is, is just that it's coding. I mean, the way I define it is it's the creative aspects of coding.

43:25.600 --> 43:30.240
Right. So I don't want to add to it. So coding or coding applied to creative. It's that. Yeah.

43:30.240 --> 43:34.480
Sorry. I said wrong. Yeah. And I think, you know, I was talking about how a musician might

43:35.120 --> 43:39.040
play a few hours of music and then use that to drive a machine learning model. And in some sense,

43:39.040 --> 43:43.280
they're hacking the model because they're providing the data. But also building these models

43:43.280 --> 43:48.000
as a creative thing in and of itself. And we're trying to build some frameworks where like,

43:48.000 --> 43:53.200
if there were an artist who knew how to code some, you don't have to be like the world's best

43:53.200 --> 43:58.160
machine learning coder. But we have some models where, you know, you could change a few things.

43:58.160 --> 44:01.920
You could, you could say, I want, if you had some way that you could, for example, let's say you

44:01.920 --> 44:07.200
wanted the music that was generated by the model to be more shimmery. Whatever that means. Fine.

44:07.200 --> 44:10.960
If you think you know what it means and you can define that in a way that if we get a piece of

44:10.960 --> 44:14.640
music and you say, oh, that sounds more shimmery, then we can actually use that with the, we can train

44:14.640 --> 44:18.720
the model to do a better job of generating that kind of music. So I don't know. I think there's

44:18.720 --> 44:24.960
a whole, a whole direction of like having coding be part of artistic generation. And that machine

44:24.960 --> 44:29.680
learning and a project like magenta is really a core place to try that. And so we're trying to get

44:29.680 --> 44:33.280
more people through open source to work with us, to collaborate with us, to make art and make music

44:33.280 --> 44:37.280
and hack stuff. Awesome. And so we'd love to see more people from, you know, from your listeners

44:37.280 --> 44:42.320
join us. That's it. That's what I want to say. Awesome. Well, thanks so much. I really enjoyed

44:42.320 --> 44:45.840
this conversation and I'm sure folks will enjoy listening to it. Thanks for all of your great

44:45.840 --> 44:55.280
questions, Sam. Thank you. All right, everyone. That is our show. Thanks so much for listening and for

44:55.280 --> 45:01.440
your continued support, comments and feedback. A special thanks goes out to our series sponsor,

45:01.440 --> 45:06.880
Intel Nirvana. If you didn't catch the first show in this series where I talked to Naveen Rao,

45:06.880 --> 45:11.920
the head up Intel's AI product group about how they plan to leverage their leading position and

45:11.920 --> 45:17.520
proven history and Silicon innovation to transform the world of AI, you're going to want to check

45:17.520 --> 45:24.400
that out next. For more information about Intel Nirvana's AI platform, visit intelnervana.com.

45:25.120 --> 45:30.880
Remember that with this series, we've kicked off our giveaway for tickets to the AI conference.

45:31.680 --> 45:37.200
To enter, just let us know what you think about any of the podcasts in the series or post your

45:37.200 --> 45:42.960
favorite quote from any of them on the show notes page on Twitter or via any of our social media

45:42.960 --> 45:51.840
channels. Make sure to mention at Twomo AI, at Intel AI and at the AI Conf so that we know

45:51.840 --> 45:58.480
you want to enter the contest. Full details can be found on the series page and of course,

45:58.480 --> 46:03.840
all entrants get one of our slick Twomo laptop stickers. Speaking of the series page,

46:03.840 --> 46:10.480
you can find links to all of the individual show notes pages by visiting Twomo AI.com slash

46:10.480 --> 46:40.320
O'Reilly AINY. Thanks so much for listening and catch you next time.

