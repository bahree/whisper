WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:34.440
I'm your host Sam Charrington, I want to send a quick thanks to everyone who commented

00:34.440 --> 00:37.880
on and shared last week's show with Jeff Dean.

00:37.880 --> 00:42.120
We were super excited to share that show with you and the feedback and love you sent

00:42.120 --> 00:44.400
our way was amazing.

00:44.400 --> 00:48.760
Weeks like last are how we expand the Twimble community and get into the ears of people

00:48.760 --> 00:50.720
who don't know about us yet.

00:50.720 --> 00:57.640
All your shares, likes, tweets and retweets matter a great deal to us, so thanks.

00:57.640 --> 01:03.960
Before I introduce today's show, the details for April's Twimble Online Meetup are set.

01:03.960 --> 01:10.680
Join us on April 18th at 5pm Pacific time as Chris Butler dives headfirst into the topic

01:10.680 --> 01:16.000
of Trust in AI, covering a myriad of papers in the process.

01:16.000 --> 01:25.440
To register or for more details, head on over to twimbleai.com slash meetup.

01:25.440 --> 01:31.120
In this episode, I'm joined by David Rosenberg, data scientist in the office of the CTO at

01:31.120 --> 01:36.880
Financial Publisher Bloomberg to discuss his work on extracting data from tables and charts

01:36.880 --> 01:40.040
in natural document formats.

01:40.040 --> 01:44.440
Bloomberg deals with tons of financial and company data and PDFs and other unstructured

01:44.440 --> 01:47.560
document formats on a daily basis.

01:47.560 --> 01:52.000
To make meaning from this information more efficiently, David and his team have implemented

01:52.000 --> 01:55.760
a deep learning pipeline for extracting data from the documents.

01:55.760 --> 02:01.640
In our conversation, we dig into the information extraction process, including how it was built,

02:01.640 --> 02:06.960
how they source their training data, why they use Latech as an intermediate representation,

02:06.960 --> 02:11.320
and how and why they optimize for pixel-perfect accuracy.

02:11.320 --> 02:14.800
There's a lot of interesting info in this show, and I think you're going to really enjoy

02:14.800 --> 02:16.800
it.

02:16.800 --> 02:28.240
Alright everyone, I am on the line with David Rosenberg.

02:28.240 --> 02:34.320
David is a data scientist in the CTO's office at Bloomberg, the Financial Publisher.

02:34.320 --> 02:38.880
He's also an adjunct associate professor in the Center for Data Science at NYU.

02:38.880 --> 02:41.800
David, welcome to this week in Machine Learning and AI.

02:41.800 --> 02:43.800
Thanks so much, happy to be here.

02:43.800 --> 02:44.800
Awesome.

02:44.800 --> 02:48.960
It's our tradition to have our guests start by introducing themselves to the audience.

02:48.960 --> 02:52.800
So tell us how did you get involved in data science and machine learning?

02:52.800 --> 02:53.800
Yeah, sure.

02:53.800 --> 03:00.120
I've been interested in AI since I was a kid reading science fiction books as an elementary

03:00.120 --> 03:06.200
school about robots and artificial intelligence really grabbed my interest, and I guess it

03:06.200 --> 03:12.680
was in eighth grade, there's a summer program, and we got to build these Fisher Technic

03:12.680 --> 03:19.040
Kit projects that's kind of like motorized and computer controllable Lego Kit, but it

03:19.040 --> 03:22.040
was made by this company Fisher Technic, and I loved it.

03:22.040 --> 03:28.280
I thought it was a most amazing thing to be able to control a robot-like device with

03:28.280 --> 03:34.760
computer programming, and then a few years later, I guess in high school then, I started

03:34.760 --> 03:39.840
hearing about neural networks, which was my first exposure to machine learning.

03:39.840 --> 03:45.880
And yeah, for a project, I bought a textbook and I implemented a neural network to do some

03:45.880 --> 03:51.720
classification on some medical data, and yeah, frankly at the time, I didn't really

03:51.720 --> 03:57.000
understand very well how the neural network was working at the detailed mathematical level,

03:57.000 --> 04:03.400
but I had a taste of the ML framework even as like early 90s.

04:03.400 --> 04:08.280
That's pretty amazing that you were exposed to neural nets in high school.

04:08.280 --> 04:09.840
Where did you go to high school?

04:09.840 --> 04:13.240
I went to Montgomery Blair High School in Silver Spring, Maryland.

04:13.240 --> 04:17.040
It was a math science computer science magnet program.

04:17.040 --> 04:22.680
I don't remember how I first heard about neural networks, but somehow it came to my attention

04:22.680 --> 04:29.200
and found a way to special order these books that the local Barnes and Noble, and I coded

04:29.200 --> 04:30.720
it up in Pascal.

04:30.720 --> 04:31.720
Nice.

04:31.720 --> 04:36.040
How did you end up at Bloomberg, and what's your focus there?

04:36.040 --> 04:37.040
Right.

04:37.040 --> 04:39.080
So, yeah, two hops to Bloomberg.

04:39.080 --> 04:46.340
So after grad school, I moved to New York and I joined a startup company that was Tony

04:46.340 --> 04:51.160
Jabara, who's a machine learning professor, who's a machine learning professor from Columbia.

04:51.160 --> 04:53.360
Now he's at Netflix.

04:53.360 --> 04:58.560
I joined his startup company, we're doing a lot of spatial temporal data, machine learning

04:58.560 --> 05:04.680
based on spatial temporal data, and then eventually got into mobile advertising.

05:04.680 --> 05:12.280
So doing things like building bidders for ad exchanges, and those kind of fun problems

05:12.280 --> 05:15.960
that a lot of ML gets applied to these days.

05:15.960 --> 05:22.440
We got acquired by YP, which is yellow pages, and I stayed there for about a year or

05:22.440 --> 05:29.760
so, and then I looked for my next step and I ended up at Bloomberg, where at Bloomberg

05:29.760 --> 05:35.320
I'm in the office of the CTO, and just a small group, I think about 25 people total within

05:35.320 --> 05:41.880
that group, there's a five person data science group that I'm a member of, and kind of our

05:41.880 --> 05:49.080
task is to work on strategic projects or plan strategic projects on kind of a two to four

05:49.080 --> 05:50.560
year time horizon.

05:50.560 --> 05:56.320
Things that are a little bit too long term for any individual engineering group to really

05:56.320 --> 06:03.200
plan for, so we kind of make strategic initiatives and kind of point the data science part of

06:03.200 --> 06:06.000
the company in different different directions.

06:06.000 --> 06:10.840
So that's kind of the big picture, another way, another way we think about it is if some

06:10.840 --> 06:16.720
other company were to gain a large advantage over Bloomberg because of some new technology

06:16.720 --> 06:20.440
in data science that we did not pursue, that would be our fault.

06:20.440 --> 06:26.960
We're responsible for making sure we're not missing out on important new tech developments.

06:26.960 --> 06:27.960
Right.

06:27.960 --> 06:34.520
Can you give us some examples of the kinds of things that you're looking at, or have looked

06:34.520 --> 06:38.720
at the past that kind of fall into this two to four year time frame?

06:38.720 --> 06:40.040
Sure, I can.

06:40.040 --> 06:49.600
So one thing, maybe not quite so such a long term play, but when I joined maybe three

06:49.600 --> 06:56.760
years ago, there was a machine learning was at this interesting time where neural networks

06:56.760 --> 07:04.000
were starting to do very well on many tasks, but just kind of specific tasks, like certainly

07:04.000 --> 07:13.760
vision and some NLP tasks, but it was kind of to get into neural networks, it's a pretty

07:13.760 --> 07:16.320
big investment in terms of hardware.

07:16.320 --> 07:19.760
At Bloomberg, we don't have the ability to use the Amazon Cloud or something.

07:19.760 --> 07:22.000
We need to use internal machines.

07:22.000 --> 07:28.520
So the CTO office kind of led the movement to try out neural networks, which involves

07:28.520 --> 07:35.400
investing in cluster GPU machines and seeding projects with various engineering teams

07:35.400 --> 07:41.920
to see if neural networks was going to benefit the types of problems that we work on.

07:41.920 --> 07:48.160
And indeed, we have found within a couple of years that it's very important to some areas

07:48.160 --> 07:49.800
of the work that we do.

07:49.800 --> 07:54.400
So I could say that strategic, not so much because of the time horizon, but because of

07:54.400 --> 07:59.400
the investment required that was kind of too large for any individual engineering group

07:59.400 --> 08:00.400
to take that risk.

08:00.400 --> 08:09.080
I guess I'm curious about the evolution of the use of machine learning at a company like

08:09.080 --> 08:10.720
Bloomberg.

08:10.720 --> 08:12.720
And you said, how long have you been there now?

08:12.720 --> 08:14.760
I've been coming up on three years.

08:14.760 --> 08:16.440
Coming up on three years.

08:16.440 --> 08:20.840
So maybe you'll have a sense of this.

08:20.840 --> 08:29.720
I talk to people all the time about how enterprises, large businesses kind of evolve these types

08:29.720 --> 08:33.360
of technologies.

08:33.360 --> 08:39.880
It's interesting in that there are some businesses where there are parts of the business that

08:39.880 --> 08:43.000
have used machine learning for a really long time.

08:43.000 --> 08:48.840
Like it's been baked into, you know, just core ways that they deliver their products.

08:48.840 --> 08:53.400
But yet and still even at those businesses, there's been like a shift over the past five

08:53.400 --> 08:57.840
years in the way they've thought about machine learning.

08:57.840 --> 08:58.840
I'm just curious.

08:58.840 --> 09:04.120
Like in your words, like, does any of that resonate and how have you seen that evolve at

09:04.120 --> 09:05.120
Bloomberg?

09:05.120 --> 09:06.120
Yeah.

09:06.120 --> 09:14.120
So, I think Bloomberg was fairly early in bringing machine learning into the product,

09:14.120 --> 09:16.200
which I could tell you a little bit about.

09:16.200 --> 09:21.600
So I think machine learning at Bloomberg was well underway, I mean, you know, there's

09:21.600 --> 09:26.800
close to a hundred people doing machine learning at Bloomberg before I even arrived.

09:26.800 --> 09:31.160
So I can't really speak to how that developed.

09:31.160 --> 09:38.240
But I can say that even now we're continually trying to find areas where machine learning

09:38.240 --> 09:44.800
can help via by automation or just kind of maybe more broadly the machine learning, just

09:44.800 --> 09:52.640
a good data science statistical approach to assessing new, even if it's a rules based

09:52.640 --> 10:00.120
method to use kind of proper methodology and assessing performance and these sorts of

10:00.120 --> 10:01.120
things.

10:01.120 --> 10:08.080
In fact, to that end, to try to see where we can leverage ML more or data science more

10:08.080 --> 10:13.920
at Bloomberg, another strategic initiative that is almost a year old now coming from the

10:13.920 --> 10:18.880
CTO department is what we're calling ML EDU, so machine learning education.

10:18.880 --> 10:25.440
But the purview is broader than ML, it's kind of just data science more broadly.

10:25.440 --> 10:37.040
And we're trying to educate people at all different levels, basically from the most

10:37.040 --> 10:42.680
basic understanding of the main concepts of machine learning things like the notion

10:42.680 --> 10:49.520
of splitting your data into training and test and notions of overfitting these fundamental

10:49.520 --> 10:56.520
ideas of machine learning that we have a course called ML1, which is two half days and

10:56.520 --> 11:00.560
it's a few hours lecture and a few hours lab where people go through that.

11:00.560 --> 11:05.120
And that kind of gives people just a sense of what is this ML about.

11:05.120 --> 11:11.800
And then we have at the other extreme we have a kind of fairly in-depth course called

11:11.800 --> 11:16.360
ML101, which is kind of like a master's level machine learning class.

11:16.360 --> 11:23.960
That's kind of fairly mathematical, but with practical end, which is learning all the

11:23.960 --> 11:28.840
connections between things like gradient boosting and random forest and L1L2 regularization,

11:28.840 --> 11:31.920
kind of a standard master's level machine learning class.

11:31.920 --> 11:33.840
And we're trying to fill in everything in between.

11:33.840 --> 11:42.560
So how to manipulate data, explore data, visualize it, how to do basic statistics, things like

11:42.560 --> 11:49.200
AB testing, hypothesis testing, confidence intervals, and then machine learning, predictive

11:49.200 --> 11:50.200
theory.

11:50.200 --> 11:51.200
Awesome.

11:51.200 --> 11:55.800
I am shortly going to be jumping on a plane to head out to the Bay Area for the GTC

11:55.800 --> 11:56.800
conference.

11:56.800 --> 11:57.800
Yeah.

11:57.800 --> 12:03.760
And you will too, probably not before me since I'm getting on a plane in a few hours.

12:03.760 --> 12:10.440
But you're going to be presenting there on what is presumably one of these projects within

12:10.440 --> 12:15.280
the CTO's office, data science team that you've been working on.

12:15.280 --> 12:17.200
Can you tell us about that?

12:17.200 --> 12:18.200
Sure.

12:18.200 --> 12:19.200
Sure.

12:19.200 --> 12:24.160
So the title is information extraction for natural document formats.

12:24.160 --> 12:28.880
So natural document format, to my knowledge is not really a common terminology, but we

12:28.880 --> 12:30.120
encountered a lot of Bloomberg.

12:30.120 --> 12:37.720
And what we mean by that is a document that was designed for easy human consumption and

12:37.720 --> 12:42.800
comprehension, things like a word document, a PDF document.

12:42.800 --> 12:47.160
And in particular, what we have in mind for the projects I'll be speaking about is where

12:47.160 --> 12:53.160
some kind of, there's some kind of underlying data that is represented or that are represented

12:53.160 --> 12:58.720
in this natural document format in a way that's just fine for a person to comprehend, but

12:58.720 --> 13:06.520
is not easy at all to extract that data back out into say a database or an Excel spreadsheet

13:06.520 --> 13:08.000
or something like that.

13:08.000 --> 13:11.720
And this is a problem that we have a lot of at Bloomberg.

13:11.720 --> 13:12.720
A Bloomberg.

13:12.720 --> 13:17.120
So an example of this might be like a chart or graph or something like that.

13:17.120 --> 13:18.120
Is that the?

13:18.120 --> 13:19.120
Absolutely.

13:19.120 --> 13:20.120
Yeah.

13:20.120 --> 13:28.520
So a scatter plot, a pie chart, a bar chart, or a table, a table of numbers, a table of

13:28.520 --> 13:35.080
all things, you think should be very easy to extract the data out into an spreadsheet

13:35.080 --> 13:40.360
or a database or something, but when a table is just represented in a PDF document in the

13:40.360 --> 13:45.880
middle of a, say, company filing, Bloomberg collects all these documents from other companies,

13:45.880 --> 13:49.080
things like company filings and these sorts of things.

13:49.080 --> 13:55.320
And we, these documents that they deliver in a PDF format typically has important data

13:55.320 --> 14:01.280
in it that we need to extract that it's easy for our Bloomberg's customers to use to

14:01.280 --> 14:02.520
get to.

14:02.520 --> 14:08.920
And so traditionally, I think almost since the founding of the company 30 years ago, there's

14:08.920 --> 14:14.880
been a whole organization within the company called Global Data where it's people's jobs

14:14.880 --> 14:20.880
to figure out the most efficient and most correct way to extract this information from

14:20.880 --> 14:21.880
the documents.

14:21.880 --> 14:28.320
And there's, I can't say exactly how much, but certainly at least hundreds of people

14:28.320 --> 14:32.920
working on these problems, not necessarily, and it's been going on for 30 years.

14:32.920 --> 14:37.080
So it's started off mostly by hand.

14:37.080 --> 14:43.000
And a big effort over the years has been to see how to automate this as much as possible

14:43.000 --> 14:45.680
or make it more efficient for the people doing it.

14:45.680 --> 14:47.760
That's kind of the business driver.

14:47.760 --> 14:54.320
In this particular scenario, I kind of thought this was a solve problem like for 10 years

14:54.320 --> 15:04.680
now, I thought that financial filings, I forget where, I thought there was the development

15:04.680 --> 15:11.760
of some standardized XML formats that were used for S1s and all these financial filings

15:11.760 --> 15:12.760
now.

15:12.760 --> 15:17.760
It sounds like that it's, I know that maybe the largest companies kind of submit their

15:17.760 --> 15:22.920
things via these XML formats, but there's still a ton of traditional documents flying

15:22.920 --> 15:24.640
around with this information.

15:24.640 --> 15:25.640
They're sure.

15:25.640 --> 15:30.720
And maybe it's a letter to shareholders that is not necessarily regulated.

15:30.720 --> 15:33.760
There's no requirements on a format to use.

15:33.760 --> 15:36.520
And we kind of want to get as much data as we can.

15:36.520 --> 15:41.600
And even if the US were to go in a certain direction, there's still all the other countries

15:41.600 --> 15:44.840
that may or may not have these requirements.

15:44.840 --> 15:51.440
And so, yes, in some sense, perhaps someday everyone will kind of publish all their,

15:51.440 --> 15:56.760
any data that show up in any inconvenient document will be paired with a, you know, some

15:56.760 --> 16:00.360
kind of standard XML format, but we're surely not there yet.

16:00.360 --> 16:01.360
Interesting.

16:01.360 --> 16:04.360
So, tell me about the approach you're taking with us.

16:04.360 --> 16:05.360
Sure.

16:05.360 --> 16:09.960
So, there's kind of three different tasks that I'll be talking about.

16:09.960 --> 16:14.400
One of them is as far as extracting data from tables that show up in documents.

16:14.400 --> 16:20.800
And the first task there is to just find the tables in the PDF documents.

16:20.800 --> 16:27.720
So for that, we're using fairly off the shelf image detection methods.

16:27.720 --> 16:34.320
The same thing as you would use to find a CAD or a kite or whatever it is in an image.

16:34.320 --> 16:38.600
One advantage that we have is because we've been solving this problem by hand for so

16:38.600 --> 16:42.520
many years, we have a tremendous amount of labeled training data.

16:42.520 --> 16:46.760
And so now we're able to leverage that to build models.

16:46.760 --> 16:54.240
And one interesting aspect we have is we need, we basically can't afford to automate unless

16:54.240 --> 16:58.520
the performance will be at least as good as the humans.

16:58.520 --> 17:03.320
And so before we're willing to cut a human out of the loop completely.

17:03.320 --> 17:08.400
And so in fact, we've done that for this relatively straightforward problem of at least

17:08.400 --> 17:13.200
for some kind of sub-problems of finding charts and documents.

17:13.200 --> 17:18.840
We've been able to exceed human precision and recall, which was great.

17:18.840 --> 17:26.040
And then the downstream tasks of actually extracting the numbers from the table use some

17:26.040 --> 17:28.360
other techniques for.

17:28.360 --> 17:32.760
And so that's the second thing that I'm going to talk about in the presentation, which

17:32.760 --> 17:35.120
is a little bit futuristic.

17:35.120 --> 17:39.960
It's not something that we kind of, it's purely research right now.

17:39.960 --> 17:44.080
That's not something we're planning to productize anytime soon because it's kind of a long

17:44.080 --> 17:45.280
path.

17:45.280 --> 17:50.480
But we were inspired by this image captioning work that started a few years ago where you

17:50.480 --> 17:56.760
could show a picture of a man crossing the street and what it would produce using an image

17:56.760 --> 18:02.120
to sequence model the sentence man crossed the street or something like that.

18:02.120 --> 18:07.840
And the idea was like boy, if we could feed in a page of a document and have it output

18:07.840 --> 18:15.960
directly in one step kind of a well-structured XML or JSON or standardized formatting of

18:15.960 --> 18:21.200
all the content in that kind of picture of the page or the document wouldn't that be great

18:21.200 --> 18:23.920
then you could because that's so much easier.

18:23.920 --> 18:28.880
That's so there's so much you can do with that downstream as far as automated processing.

18:28.880 --> 18:33.360
It's hard to begin if you just have kind of a raw PDF, the format, if I could show

18:33.360 --> 18:40.400
you the format of the internal PDF or even a parsed PDF is not very easy to extract the

18:40.400 --> 18:42.880
structure from.

18:42.880 --> 18:46.600
So for that problem, so how are we going to apply image caption to this sort of thing?

18:46.600 --> 18:55.400
So I partnered with a student from Harvard, Yun Tian Dang who had this really cool work

18:55.400 --> 19:02.680
a year or two ago with Sasha Rush and some others was to convert a picture of an equation

19:02.680 --> 19:08.520
of mathematical equation that was generated by latex which is kind of mark up for making

19:08.520 --> 19:12.720
equations and scientific documents.

19:12.720 --> 19:18.760
And to go from the image and reproduce latex code that you would need to generate that

19:18.760 --> 19:19.760
equation.

19:19.760 --> 19:20.760
Interesting.

19:20.760 --> 19:25.920
You can see as kind of a simple version of going from the image of something to a structured

19:25.920 --> 19:32.280
representation of kind of the underlying information in the picture that you could then do further

19:32.280 --> 19:34.080
information extraction on.

19:34.080 --> 19:38.960
So we wanted to adapt that idea to this problem of information extraction from tables.

19:38.960 --> 19:44.720
So given the image of a table, that was, and we're restricting here to kind of somewhat

19:44.720 --> 19:49.520
of a toy problem where we assume the table is generated from latex in the first place

19:49.520 --> 19:51.560
from a latex document.

19:51.560 --> 19:58.760
And so the problem is can we regenerate the latex code that would reproduce that table exactly,

19:58.760 --> 20:01.040
kind of pixel level, exact.

20:01.040 --> 20:03.360
And so that's another thing I'll be talking about.

20:03.360 --> 20:05.920
We had a fairly impressive results for that.

20:05.920 --> 20:10.240
The kind of the exact match rate isn't so high, and it's 40%.

20:10.240 --> 20:14.240
But the errors are even when it makes errors that are pretty minor.

20:14.240 --> 20:19.160
So this seems like an interesting line of work that we're saying.

20:19.160 --> 20:23.800
And the last thing was extracting data from scatter plots.

20:23.800 --> 20:29.560
So in a document, they'll offer me scatter plots or plots containing information.

20:29.560 --> 20:34.600
And we found ourselves once or twice with the ruler trying to figure out exactly what points

20:34.600 --> 20:38.880
are represented in this chart, lining up the point with the axis.

20:38.880 --> 20:39.880
Right.

20:39.880 --> 20:40.880
Right.

20:40.880 --> 20:46.520
It seems like, boy, this should be automatable with all the computer vision technologies

20:46.520 --> 20:48.040
we have now.

20:48.040 --> 20:54.440
And this was an interesting thing where we actually thought that this was close enough to something

20:54.440 --> 20:59.360
we could make a product out of that we kind of went straight for what's the most direct

20:59.360 --> 21:05.760
way to solve this problem without, you know, it's very tempting to try to make kind of the

21:05.760 --> 21:11.800
end-to-end solution that are, you know, so striking these days with the neural networks.

21:11.800 --> 21:15.360
Like for instance, the image of the table to the late echo that produces that would be,

21:15.360 --> 21:18.160
I consider that an end-to-end solution.

21:18.160 --> 21:23.400
But so we were tempted to make the input, the chart and the output just be the list of

21:23.400 --> 21:26.200
points in one fell swoop.

21:26.200 --> 21:29.760
But it seems to be a little bit too hard for right now for us.

21:29.760 --> 21:33.000
So we broke that down into a pipeline of steps.

21:33.000 --> 21:39.040
Each one of which was just using off-the-shelf techniques, start with kind of image recognition

21:39.040 --> 21:43.800
to find the components of the charts.

21:43.800 --> 21:49.920
Then we used some various heuristics to put them together and at the end, I could do a fairly

21:49.920 --> 21:54.880
good job of extracting the data from scatterplots and currently we're working on pie charts

21:54.880 --> 21:58.360
and next I guess we bar charts and line charts.

21:58.360 --> 22:03.320
And I mean the goal is to solve the problem in this particular case rather than to come

22:03.320 --> 22:07.080
up with a very kind of one shot end-to-end solution.

22:07.080 --> 22:08.080
Right, right.

22:08.080 --> 22:15.880
So the first of the problems you described was just really localizing these graphical

22:15.880 --> 22:16.880
the tables.

22:16.880 --> 22:18.920
The tables in particular or any kind?

22:18.920 --> 22:19.920
Tables and charts.

22:19.920 --> 22:20.920
Okay.

22:20.920 --> 22:23.360
But we were focusing particularly on the tables initially.

22:23.360 --> 22:25.360
Okay.

22:25.360 --> 22:32.480
And if you're just looking at tables and charts like I'm curious, how much of the PDF internals

22:32.480 --> 22:37.520
do you actually use or do you just like take a picture of the page essentially and do

22:37.520 --> 22:40.400
your image recognition on the page itself?

22:40.400 --> 22:41.560
Yeah, good question.

22:41.560 --> 22:47.440
So the punchline is that it can do just fine using just the picture.

22:47.440 --> 22:53.800
So if you treat each PDF page as a picture just render it and use that as input, that

22:53.800 --> 22:54.800
works just fine.

22:54.800 --> 22:58.760
Initially, we were concerned that it would be too hard.

22:58.760 --> 23:02.680
So we tried to use a part of the PDF to simplify the image.

23:02.680 --> 23:07.240
So for instance, we figured it doesn't really know you to know exactly what characters

23:07.240 --> 23:08.240
are there.

23:08.240 --> 23:13.240
Maybe just needs to know the character type, like letter versus number, this sort of thing.

23:13.240 --> 23:14.240
Okay.

23:14.240 --> 23:20.080
You know, render a simpler version of the page that would be easier for the object detection

23:20.080 --> 23:22.320
system to learn from.

23:22.320 --> 23:25.880
But it turns out it works just fine with the rendering of the raw.

23:25.880 --> 23:29.640
I mean, sometimes one works a little better, sometimes the other works a little better,

23:29.640 --> 23:33.480
but it can go directly from the rendered image.

23:33.480 --> 23:41.800
So the result of this first step is just, you know, is it like a bounding box and a label

23:41.800 --> 23:44.880
that says table or chart or?

23:44.880 --> 23:45.880
It is a bounding box.

23:45.880 --> 23:50.960
And it sounds, when I first heard about it, I felt like this sounds so easy.

23:50.960 --> 23:51.960
Why?

23:51.960 --> 23:55.880
I'm sure everyone's thinking that.

23:55.880 --> 24:02.080
And it mostly is, but the issue is that, you know, if you don't get the bounding box

24:02.080 --> 24:06.520
exactly right, if you leave off a column or leave off some of the header, or you don't

24:06.520 --> 24:11.520
properly separate the headers from the rest of the table, which is another part of finding

24:11.520 --> 24:16.240
the table in the first place, then the entire extraction is messed up.

24:16.240 --> 24:20.440
And we don't, and kind of 95% accuracy isn't really good enough.

24:20.440 --> 24:24.080
So it's always about the, again, if I had pictures, I could show you some.

24:24.080 --> 24:29.240
So at the, if you go to the presentation, we could show you some really weird looking

24:29.240 --> 24:33.240
tables that heuristics just will fail on.

24:33.240 --> 24:36.400
This is actually really, really easy for me to visualize.

24:36.400 --> 24:43.240
And the reason why is because I often use my cell phone camera to take pictures of receipts

24:43.240 --> 24:45.640
or pages or things like that.

24:45.640 --> 24:49.720
And the particular app that I use, you know, whether it's there or several that I use,

24:49.720 --> 24:56.280
ever notice one cam scanner as another, but these apps will try to, you know, do exactly

24:56.280 --> 25:00.280
what you're describing, like draw a bounding box around the document and then like use

25:00.280 --> 25:06.160
that to like, you know, rewarp it or straighten it and crop it from the background.

25:06.160 --> 25:11.520
But it is uncanny the mistakes that these things will make and how, you know, I don't think

25:11.520 --> 25:18.400
the accuracy is anywhere near 95% on, you know, what, you know, even if I've got the

25:18.400 --> 25:23.760
paper on a black notebook or something like that, like it's still seems to be a challenging

25:23.760 --> 25:24.760
problem.

25:24.760 --> 25:30.160
And, you know, it's perhaps complicated by the fact that it's running on a mobile device,

25:30.160 --> 25:32.000
I don't know.

25:32.000 --> 25:38.760
But I can certainly imagine if you now, kind of, you know, you don't even have the benefit

25:38.760 --> 25:43.320
of the back, the contrasting background, you've got all different kinds of, you know, shapes

25:43.320 --> 25:48.720
and sizes of tables and, you know, adjacency of one table to the next.

25:48.720 --> 25:52.920
And, you know, I can, I can, you know, I said, is it, you know, just this issue of creating

25:52.920 --> 25:58.280
the back, the bounding box, but as you're describing this, I can imagine all of the complexities

25:58.280 --> 26:00.120
associated with getting this right.

26:00.120 --> 26:06.680
Right. And, and you nailed one of the challenges, which is when tables are adjacent, the problem

26:06.680 --> 26:10.760
of multiple columns, you know, there's often two column or three column documents.

26:10.760 --> 26:15.880
Yeah, I, I think you appreciate the, it's harder than it sounds, it's harder than it

26:15.880 --> 26:16.880
sounds.

26:16.880 --> 26:23.000
Is this a system that you've, you've tried to, or gotten to the point of operationalizing

26:23.000 --> 26:26.280
it, or is this, this is deployed, this is deployment.

26:26.280 --> 26:33.960
So this is in, this is kind of in the pipeline, helping people, either it's assisting people

26:33.960 --> 26:39.800
to annotate documents, so someone will load the document, the document will be kind of

26:39.800 --> 26:46.440
pre annotated with a guess by this system of finding the tables, and then a human can

26:46.440 --> 26:49.600
approve or edit those annotations.

26:49.600 --> 26:54.600
And then for some classes of documents, it's just straight pass through with no human

26:54.600 --> 26:56.600
oversight needed with decided.

26:56.600 --> 27:00.520
And that was, and that was going to be my exact question like, do you, you know, are

27:00.520 --> 27:08.920
you utilizing a model where you identify like a, or you kind of surface when, when the system

27:08.920 --> 27:13.560
isn't sure to the user and allow the, you know, that human in the loop to kind of make

27:13.560 --> 27:18.560
the final decision when there's some uncertainty or, you know, does it have to be kind of all

27:18.560 --> 27:19.560
or nothing?

27:19.560 --> 27:24.080
It sounds like, it sounds like you are kind of doing that, you know, taking that middle

27:24.080 --> 27:27.400
ground where you're surfacing the, you know, where there's some ambiguity.

27:27.400 --> 27:28.400
Right.

27:28.400 --> 27:29.400
So, yes.

27:29.400 --> 27:36.640
So I think what one thing that you seem to be speaking about is where the system will perhaps

27:36.640 --> 27:41.720
based on, you know, what it sees, and it will give a measured response.

27:41.720 --> 27:45.520
Like, you know, I think this is the bounding box, but my confidence is low or, or they may

27:45.520 --> 27:48.080
give a numeric score to the confidence or something.

27:48.080 --> 27:51.800
And then the ones that are low confidence will be highlighted to a user.

27:51.800 --> 27:58.240
But we feel see for with for now is finding classes of documents that overall have a very

27:58.240 --> 28:06.440
high performance kind of above human level accuracy or precision recall measures.

28:06.440 --> 28:12.160
And as a group, those will be kind of passed through because the issue with confidence

28:12.160 --> 28:16.720
is that you have to trust the confidence measure, you have to trust the confidence score.

28:16.720 --> 28:19.880
And so that would have to be kind of assessed on its own.

28:19.880 --> 28:20.880
Okay.

28:20.880 --> 28:25.320
So, how are these classes of documents described?

28:25.320 --> 28:31.440
Like is it, you know, all of the, you know, S1s for a major fortune, you know, 500 companies

28:31.440 --> 28:37.000
all kind of look the same or all of AT&T's, S1s, we've got good performance on or that

28:37.000 --> 28:38.000
kind of thing.

28:38.000 --> 28:39.000
Right.

28:39.000 --> 28:40.000
Yeah.

28:40.000 --> 28:44.160
It's like a class of documents, like, filings of a certain type, for example, that have

28:44.160 --> 28:47.280
such a certain regularity to them.

28:47.280 --> 28:53.040
And the performance is very high that will kind of shun those to automatic pass through,

28:53.040 --> 28:55.880
which is to say doesn't need a human oversight.

28:55.880 --> 28:56.880
Okay.

28:56.880 --> 29:02.720
And it sounds like by implication, then when, you know, when the system's nailed a document

29:02.720 --> 29:09.040
class, yeah, it's confident, well, you know, aside from confidence, like it, it performs

29:09.040 --> 29:15.160
extremely well, like, you know, above human levels of performance on every document in

29:15.160 --> 29:18.920
that class, there's not a lot of variability within the class.

29:18.920 --> 29:19.920
Yeah.

29:19.920 --> 29:20.920
That's the idea, right?

29:20.920 --> 29:25.960
You'd like a more fine-grained certainty measure that one could leverage.

29:25.960 --> 29:26.960
Yeah.

29:26.960 --> 29:31.880
I mean, I don't know that it's like, I guess I would expect that within, even within

29:31.880 --> 29:37.280
a document class, there are still ambiguous situations.

29:37.280 --> 29:45.080
And I would expect you to want to somehow kind of surface that ambiguity.

29:45.080 --> 29:47.160
But you don't want to do that.

29:47.160 --> 29:51.720
You want it to be kind of all or nothing, and I'm really trying to get into the thinking

29:51.720 --> 29:52.720
there.

29:52.720 --> 29:54.000
Well, I, you know, it's interesting.

29:54.000 --> 30:01.120
I think part of it is the way our annotation system works, but the annotation system works

30:01.120 --> 30:02.840
at the document level.

30:02.840 --> 30:11.400
So a doc, maybe 10 to 50 pages, and in some sense, we either have a person annotated document

30:11.400 --> 30:12.400
or we don't.

30:12.400 --> 30:17.840
At this point, don't have a kind of page-by-page decision on whether it will be annotated.

30:17.840 --> 30:18.840
Okay.

30:18.840 --> 30:20.560
So I think that's that part of it.

30:20.560 --> 30:21.560
That's a bit of it.

30:21.560 --> 30:22.960
Perhaps an idiosyncrasy of our setup.

30:22.960 --> 30:23.960
Right.

30:23.960 --> 30:24.960
Right.

30:24.960 --> 30:28.520
So if you had, if you could just throw ambiguous pages on a stack and, you know, someone

30:28.520 --> 30:33.000
goes through those page-by-page, then that might have changed the way you approach that

30:33.000 --> 30:34.400
piece.

30:34.400 --> 30:35.400
I think that's right.

30:35.400 --> 30:36.400
Yeah.

30:36.400 --> 30:42.080
Although I think, I think being able to trust a confidence score is a interesting problem

30:42.080 --> 30:43.080
in and of itself.

30:43.080 --> 30:48.640
You know, it's, it's very, you know, most, most machine learning methods these days output

30:48.640 --> 30:53.400
something that you are tempted to interpret as a probability, but whether those, oh, for

30:53.400 --> 30:59.600
a probability of, for classification, for instance, probability of being a cat versus

30:59.600 --> 31:00.600
not a cat.

31:00.600 --> 31:01.600
Mm-hmm.

31:01.600 --> 31:02.600
That's sort of things.

31:02.600 --> 31:03.600
Right.

31:03.600 --> 31:07.040
But whether those probabilities are calibrated in the sense that it will actually be right

31:07.040 --> 31:12.280
that number of times, if, when you predict cat is, that has to be confirmed.

31:12.280 --> 31:17.600
That's just because a method gives a probability score doesn't mean that's actually the probability,

31:17.600 --> 31:18.600
I guess.

31:18.600 --> 31:19.600
Right.

31:19.600 --> 31:20.600
Right.

31:20.600 --> 31:26.720
There's an implicit weighting of kind of trusting that confidence versus like assuming

31:26.720 --> 31:35.160
that it's 100% and kind of pushing those documents through like how is, I don't have

31:35.160 --> 31:42.320
an intuitive feel for why that trust is any, any better than, you know, even in the case

31:42.320 --> 31:48.600
where you've got general high level of trust in a class, like, you might, you know, in

31:48.600 --> 31:54.360
that case, seems like there'd be information in a low confidence, an exceedingly low confidence

31:54.360 --> 31:55.360
level for a document.

31:55.360 --> 31:56.360
Right.

31:56.360 --> 31:57.360
So I think you have the impression.

31:57.360 --> 31:58.360
Which do we have in better?

31:58.360 --> 31:59.360
Yeah.

31:59.360 --> 32:01.120
So I guess, I guess that's all I'm saying.

32:01.120 --> 32:05.240
So we have a class of documents, which without any information about the individual page

32:05.240 --> 32:11.040
or the individual document, the overall performance will be, say, 98% precision and recall while

32:11.040 --> 32:13.320
human is 97 or 98.

32:13.320 --> 32:14.320
Okay.

32:14.320 --> 32:16.200
So match or exceed human performance.

32:16.200 --> 32:21.360
And then you're pointing out, maybe we could do even better by going page by page and

32:21.360 --> 32:27.640
highlighting the ones that are somewhat less certain and maybe sending those to a human

32:27.640 --> 32:29.920
and then we can do even better overall.

32:29.920 --> 32:30.920
Yeah.

32:30.920 --> 32:31.920
Right.

32:31.920 --> 32:32.920
Yeah.

32:32.920 --> 32:33.920
Right.

32:33.920 --> 32:34.920
Yeah.

32:34.920 --> 32:35.920
I appreciate you.

32:35.920 --> 32:36.920
I appreciate you putting it like that.

32:36.920 --> 32:40.640
It's certainly not my job to, there's often a way to do better.

32:40.640 --> 32:46.520
But then there are, you know, the trade offs that, you know, come with trying it with doing

32:46.520 --> 32:47.520
that.

32:47.520 --> 32:53.800
And if you've achieved a level of performance that you need for your use case, then, you

32:53.800 --> 32:54.800
know, great.

32:54.800 --> 32:55.800
Yeah.

32:55.800 --> 33:02.680
So for the past through the, it's not even 97, 90, it's like essentially a hundred.

33:02.680 --> 33:03.680
Oh, really?

33:03.680 --> 33:04.680
Yeah.

33:04.680 --> 33:05.680
Yeah.

33:05.680 --> 33:12.560
For the 96, 97, I think they're still good at humans.

33:12.560 --> 33:17.880
I could, I'm not 100% sure, I'd have to double check that.

33:17.880 --> 33:25.760
And so another kind of thought that I'm wondering if you are thinking about it and tracking

33:25.760 --> 33:36.680
is the whole kind of adversarial attack conversation and like, you use some scenario where, you

33:36.680 --> 33:46.400
know, a company kind of, you know, manipulates the presentation of their data to, you know,

33:46.400 --> 33:51.640
change the way your parser interprets their charts and tables and, you know, somehow

33:51.640 --> 33:54.480
affect trades of Bloomberg customers.

33:54.480 --> 33:57.320
Like, I'm assuming that's something that you folks are thinking about.

33:57.320 --> 33:59.560
I mean, that's really important.

33:59.560 --> 34:05.760
So there's a little bit of that we've already seen where there'll be a document that if

34:05.760 --> 34:09.920
you look at it to the eye, nothing unusual going on.

34:09.920 --> 34:17.240
But if you parse it with a PDF parser, which tries to extract the text and stuff for you,

34:17.240 --> 34:25.600
but what we found is some documents will put incorrect information or confusing information

34:25.600 --> 34:29.440
in a kind of invisible font color.

34:29.440 --> 34:34.160
And so when you parse it, it's very difficult to figure out what's going on if you use

34:34.160 --> 34:36.440
like a PDF parser.

34:36.440 --> 34:41.520
But we've been able to get around those because we just use the rendering of the page.

34:41.520 --> 34:50.840
And so if the human can't see it, I mean, it can, let me just say that the network can

34:50.840 --> 34:56.840
figure out what are kind of relevant colors and irrelevant colors and that sort of thing.

34:56.840 --> 35:06.200
But we're not protected against kind of not necessarily protected against adversarial

35:06.200 --> 35:12.200
images that could mess up a network, but a human wouldn't see.

35:12.200 --> 35:17.080
I mean, I don't know how that would work through after being printed out and stuff, I assume

35:17.080 --> 35:18.080
it would.

35:18.080 --> 35:21.720
But yeah, of course, we've seen, I assume you're talking about these pretty cool examples

35:21.720 --> 35:27.360
where there'll be a picture that's clearly a cat and the classifier will give it 99%

35:27.360 --> 35:29.520
confidence that it's a car or something like that.

35:29.520 --> 35:30.520
Exactly.

35:30.520 --> 35:31.520
Exactly.

35:31.520 --> 35:33.920
That's really interesting.

35:33.920 --> 35:39.440
We have noticed things like that happening, but it's definitely something we need to keep

35:39.440 --> 35:40.440
it I have for.

35:40.440 --> 35:41.440
Yeah.

35:41.440 --> 35:47.480
I like the way you describe the tricks that folks do with like kind of background colored

35:47.480 --> 35:52.640
text makes me think of, I just struck me that like in some ways you can think of like

35:52.640 --> 35:57.480
fine print and some of these things as like adversarial attacks against a human brain,

35:57.480 --> 35:58.480
right?

35:58.480 --> 36:03.720
It's like things we do to like, you know, present information so as to missly the

36:03.720 --> 36:04.720
reader.

36:04.720 --> 36:05.720
Right.

36:05.720 --> 36:06.720
Right.

36:06.720 --> 36:09.200
So the first part is identifying these tables and charts.

36:09.200 --> 36:16.160
The second part is then parsing the tables and you talked about, you know, some of the

36:16.160 --> 36:21.080
challenges associated with that as a high level over there.

36:21.080 --> 36:28.960
You know, where did the kind of the bulk of the work on that particular piece take place

36:28.960 --> 36:33.480
or were there any like major, you know, what were the major challenges that you had to overcome

36:33.480 --> 36:37.480
on that, the table interpretation part?

36:37.480 --> 36:44.120
The finding the tables part or the late tech, the late tech extraction, the reverse engineering

36:44.120 --> 36:45.960
the tables, I guess.

36:45.960 --> 36:46.960
Right.

36:46.960 --> 36:47.960
Right.

36:47.960 --> 36:48.960
Right.

36:48.960 --> 36:51.720
One issue is that the images are just bigger.

36:51.720 --> 36:59.960
There's just much more information in a table potentially than in an equation that which

36:59.960 --> 37:03.520
has a lot of information, but a table is just can be a whole lot of numbers.

37:03.520 --> 37:05.640
It could be quite large.

37:05.640 --> 37:13.160
And there we get into kind of memory issues with these convolutional neural networks.

37:13.160 --> 37:19.880
When you're training, for instance, if you have, you know, a large input image, you're

37:19.880 --> 37:26.880
restricted to how big a batch you can use at one time and this will slow down training.

37:26.880 --> 37:32.280
And so the first challenge is that these things, you know, we're taking two weeks to train,

37:32.280 --> 37:37.480
which is, you know, it's hard to iterate on a problem when it takes along the train.

37:37.480 --> 37:39.120
So we did some work at that.

37:39.120 --> 37:45.320
We happened to have to have received the new Nvidia GPUs at that time.

37:45.320 --> 37:52.080
So that had 16-bit kind of floating, 16-bit floating point capabilities which are kind

37:52.080 --> 37:56.000
of theoretically going to be twice as fast and you can kind of have too many weight-storted

37:56.000 --> 37:58.760
memory because you're only using half as many bits for them.

37:58.760 --> 38:04.960
So we spent a lot of time trying to adapt to this 16-bit technology so we could have,

38:04.960 --> 38:09.560
you know, the speed up and the kind of access to put more stuff in memory, but it turned

38:09.560 --> 38:13.040
out to be much harder than we thought it would be.

38:13.040 --> 38:18.360
There are a whole bunch of kind of technical issues when we represented our weights in

38:18.360 --> 38:22.160
our network with only 16 bits.

38:22.160 --> 38:23.720
And it turns out we weren't alone.

38:23.720 --> 38:30.880
It turns out this has kind of been, it's kind of a known issue at this point that you don't

38:30.880 --> 38:32.600
really want to store everything in 16 bits.

38:32.600 --> 38:36.400
You can do some calculations in 16 bits, but your weights eventually should be stored

38:36.400 --> 38:39.240
in 32 bits.

38:39.240 --> 38:43.560
So we spent a lot of time kind of working through that problem.

38:43.560 --> 38:51.560
And what we're working on now is, I mean, so what's the basic issue with this table to

38:51.560 --> 38:55.960
latex is that it looks fine, but it doesn't really work that well if you're going for an

38:55.960 --> 39:01.280
exact match and we're going for an exact match, you know, 40%, that's 40% correct.

39:01.280 --> 39:04.720
That's pretty low by any of those standards.

39:04.720 --> 39:10.040
The equations were kind of more up like 80% exactly correct.

39:10.040 --> 39:12.600
So I mean, and this is ongoing work.

39:12.600 --> 39:14.400
Is your measure of correctness?

39:14.400 --> 39:21.880
Is this like pixel, like, you know, pixel overlay or is it something else?

39:21.880 --> 39:24.920
So is it more information based, I guess?

39:24.920 --> 39:25.920
Right.

39:25.920 --> 39:26.920
Yeah.

39:26.920 --> 39:27.920
So it's not information based.

39:27.920 --> 39:34.680
During training time, we're just trying to maximize kind of the likelihood of the

39:34.680 --> 39:37.880
correct latex, but that's training time.

39:37.880 --> 39:43.880
But when it actually comes to evaluation, we're going for exact pixel-to-pixel match.

39:43.880 --> 39:44.880
So it's binary.

39:44.880 --> 39:46.560
You either got it exactly correct or not.

39:46.560 --> 39:52.120
So what that means is, the inputs the image of the table, the outputs a string of latex

39:52.120 --> 39:56.920
tokens, which feed that string into a latex compiler, it renders an image.

39:56.920 --> 40:00.920
And then we compare that image pixel by pixel to be original image.

40:00.920 --> 40:03.160
And if it's an exact match, it's correct.

40:03.160 --> 40:05.200
And otherwise, it's incorrect.

40:05.200 --> 40:06.960
And why do you care about that?

40:06.960 --> 40:09.800
Why do we care about the exact match?

40:09.800 --> 40:16.640
You know, why is your bar, I guess there are multiple ways to ask a question like, why

40:16.640 --> 40:19.440
do you care about kind of the latex representation?

40:19.440 --> 40:21.800
Why do you care about pixel-to-pixel match?

40:21.800 --> 40:27.240
You know, why is it just that you've extracted the, you know, the rows and columns of data,

40:27.240 --> 40:30.440
the headings, the text, the numbers, all that stuff?

40:30.440 --> 40:31.440
Okay.

40:31.440 --> 40:33.080
So there's a few things in there.

40:33.080 --> 40:34.080
Let's see.

40:34.080 --> 40:41.000
So latex, I don't care about latex per se, latex is kind of a stand-in for a structured

40:41.000 --> 40:45.000
representation from which it should be easy to do the things you said, extract the rows

40:45.000 --> 40:46.760
and columns and that sort of thing.

40:46.760 --> 40:55.200
So why latex, we happen to have access to a huge collection of real world latex documents

40:55.200 --> 40:57.120
that have tables in them.

40:57.120 --> 41:02.480
And so that's kind of our label trainings that we went to archive, we scraped out all

41:02.480 --> 41:06.600
these papers, we found almost a half million tables with the original latex.

41:06.600 --> 41:07.600
Oh, nice.

41:07.600 --> 41:08.600
Yeah.

41:08.600 --> 41:12.200
So I mean, we could have generated artificial tables, but it's really better to work with

41:12.200 --> 41:14.960
kind of real live natural data.

41:14.960 --> 41:19.480
So that's, that's part, that's basically how we ended up with latteque.

41:19.480 --> 41:22.240
Then the question, why do we care about exact match?

41:22.240 --> 41:29.740
And well, one reason is expedience, which is that it's easy to do and it's actually quite

41:29.740 --> 41:35.680
difficult to figure out how you would score something that's not an exact match.

41:35.680 --> 41:40.120
I mean, you could do it in the image space where you then you have this kind of, the image

41:40.120 --> 41:44.360
is not an exact match and then if you want to rate it by how off it is, you'd have to

41:44.360 --> 41:51.480
kind of do some alignment and find, it seems like a very complicated problem in itself.

41:51.480 --> 41:55.680
And then, and then you're asking, what about just measuring how it does a downstream task,

41:55.680 --> 42:01.800
which is just finding the data, like extracting the data from the latex and, you know, are

42:01.800 --> 42:03.920
the numbers correct or the headers correct?

42:03.920 --> 42:05.800
And that would be possible.

42:05.800 --> 42:08.800
That would, it's still very difficult to score.

42:08.800 --> 42:14.560
We actually have the same problem with when we're extracting data from scattered plots,

42:14.560 --> 42:22.960
you know, there's 60 points in the chart, the system finds 57 and the points, you know,

42:22.960 --> 42:30.720
have to root the amounts of error ranging from 100% to, like by celebrating back there.

42:30.720 --> 42:31.720
Yeah.

42:31.720 --> 42:32.720
Sorry about that.

42:32.720 --> 42:33.720
Yeah.

42:33.720 --> 42:39.080
Is it kind of a, awards thing going on just starting now next door to me.

42:39.080 --> 42:46.320
So it sounds like in both the table and the, the scatter plots, you're using the visual

42:46.320 --> 42:52.920
domain and visual domain accuracy is really, it's just a connection.

42:52.920 --> 42:59.440
Convenient intermediary for you to be able to test whether you've accomplished the goal,

42:59.440 --> 43:05.040
whether you're able to replicate the system and because, at least in the case of the tables.

43:05.040 --> 43:10.240
And I think you're doing the same thing with the, the scatter plots because the table that

43:10.240 --> 43:19.280
you're generating or predicting is generated via via a structured representation.

43:19.280 --> 43:22.880
It doesn't really matter what it is, but you happen to have training data that's

43:22.880 --> 43:27.160
in the tech because you're generating it via a structured representation.

43:27.160 --> 43:31.320
You know that, you know, downstream, you'll be able to pull the data out the way you

43:31.320 --> 43:32.320
need to.

43:32.320 --> 43:34.720
That's, that's right.

43:34.720 --> 43:41.160
Also, it's, it's convenience to do in the image domain, but also it's, it's hard to

43:41.160 --> 43:45.760
know exactly what downstream tasks we're going to want to do on the structured representation.

43:45.760 --> 43:51.920
And maybe there's important information in that boldface versus italics, which you might

43:51.920 --> 43:57.040
think isn't necessarily part of the core information of the table.

43:57.040 --> 44:03.560
So the harder tables to extract, a lot of that complexity comes from things like hierarchical

44:03.560 --> 44:10.320
column headers or row headers or cells that span multiple rows or columns.

44:10.320 --> 44:18.760
And this is actually difficult to represent in a, it's difficult to score the performance

44:18.760 --> 44:23.040
on those sorts of mistakes, like what if it didn't properly represent the cell spanning

44:23.040 --> 44:26.120
to column headers or these sorts of things.

44:26.120 --> 44:33.440
So I guess, yes, it comes down to simplicity, but also it just not being exactly clear

44:33.440 --> 44:38.720
how, what else we would do, how else we would score in a way that would be, you know, good

44:38.720 --> 44:41.480
for any possible downstream task we'd want to do.

44:41.480 --> 44:45.880
Yeah, now that makes it, that makes a ton of sense, that makes a ton of sense.

44:45.880 --> 44:52.440
Awesome. So you, in your presentation, you kind of go through these three sub projects.

44:52.440 --> 44:53.440
Yeah.

44:53.440 --> 45:01.240
Were there any closing or parting thoughts that would make a good wrap up for us here?

45:01.240 --> 45:08.560
Well, I guess one, one thing that people often wonder about is, what about all these people

45:08.560 --> 45:13.280
who are labeling documents and now are they going to be automated away?

45:13.280 --> 45:17.640
And we're really not worried about it, not because we don't care about people's jobs,

45:17.640 --> 45:18.640
we absolutely do.

45:18.640 --> 45:23.360
But because the people doing the labeling are actually often fairly highly trained and

45:23.360 --> 45:29.840
we'd, we'd love to have them working on harder and deeper problems that they'll have

45:29.840 --> 45:33.960
time for once the more, the problems that a computer can solve are solved.

45:33.960 --> 45:40.040
So, you know, questions about we can find the data and then we can flag things that are

45:40.040 --> 45:45.800
unexpected, then the human can go and tag the unexpected behavior with perhaps linking

45:45.800 --> 45:47.560
to a possible reason why.

45:47.560 --> 45:53.040
These sorts of things are more still human level tasks that's not clear are automatable

45:53.040 --> 45:59.480
in the near future and kind of automating the menial tasks will hopefully be humans

45:59.480 --> 46:05.160
free to do the tasks that we don't yet know how to automate and maybe are more like specific

46:05.160 --> 46:08.040
to needing human intelligence at least for now.

46:08.040 --> 46:10.600
And it sounds like in the example you gave more valuable.

46:10.600 --> 46:11.600
Right.

46:11.600 --> 46:12.600
Awesome.

46:12.600 --> 46:15.120
Well, David, you've been very generous with your time.

46:15.120 --> 46:17.240
Thank you so much for chatting with us.

46:17.240 --> 46:18.240
It's been my pleasure.

46:18.240 --> 46:19.240
Thanks so much.

46:19.240 --> 46:25.120
All right, everyone, that's our show for today.

46:25.120 --> 46:30.040
For more information on David or any of the topics covered in this episode, you'll find

46:30.040 --> 46:36.240
the show notes at twomolei.com slash talk slash one, two, six.

46:36.240 --> 46:38.760
Thanks once again for listening and catch you next time.

