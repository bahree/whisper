WEBVTT

00:00.000 --> 00:13.360
Welcome to the Twemal AI Podcast.

00:13.360 --> 00:24.360
Hey, what's up everyone?

00:24.360 --> 00:29.000
Before we get to today's show, just a few quick updates.

00:29.000 --> 00:33.440
First off, I'd like to ask for your help with our latest survey, this time around on

00:33.440 --> 00:36.560
the Python data science ecosystem.

00:36.560 --> 00:40.880
This is our second year exploring this space and we'd love to have your input.

00:40.880 --> 00:47.080
If you use Python for data science, please visit twemalai.com slash Python survey to take

00:47.080 --> 00:48.680
the survey.

00:48.680 --> 00:53.080
The survey will only take a few minutes to complete and three lucky submissions will receive

00:53.080 --> 00:58.560
a $25 Amazon gift card.

00:58.560 --> 01:03.600
Speaking of languages, we are super excited to announce the great machine learning language

01:03.600 --> 01:05.400
on debate.

01:05.400 --> 01:10.400
Join us for a thoughtful discussion exploring the strengths, weaknesses, and approaches

01:10.400 --> 01:16.400
of popular and emerging programming languages for machine learning like Python, R, C++,

01:16.400 --> 01:22.680
Swift, Julia, Closure, and more, and an opportunity for you to engage with experts and peers on

01:22.680 --> 01:23.680
the topic.

01:23.680 --> 01:28.280
It's not too late to let us know the languages you'd like to see included and who you'd

01:28.280 --> 01:30.120
like to see representing them.

01:30.120 --> 01:37.120
Send me your suggestions via Twitter at at Sam Charrington or hit me up at Sam at twemalai.com.

01:37.120 --> 01:42.920
Visit twemalai.com slash languages for more information or to register.

01:42.920 --> 01:45.280
And now on to the show.

01:45.280 --> 01:46.760
All right, everyone.

01:46.760 --> 01:49.480
I am on the line with Marsal Gavolda.

01:49.480 --> 01:54.720
Marsal is head of machine learning for the commerce platform at square.

01:54.720 --> 01:57.560
Marsal, welcome to the twemalai podcast.

01:57.560 --> 01:58.560
Thank you so much.

01:58.560 --> 02:01.240
I'm very excited to be in your podcast.

02:01.240 --> 02:04.040
It's great to have an opportunity to speak with you.

02:04.040 --> 02:09.840
And I'm looking forward to digging into how ML is working at square, what you're up to.

02:09.840 --> 02:13.720
But before we do that, share a little bit about your background.

02:13.720 --> 02:20.040
What got you interested in machine learning and what are some of your interest areas?

02:20.040 --> 02:21.040
Yeah, sure.

02:21.040 --> 02:23.200
I'm happy to share my sort of life story here.

02:23.200 --> 02:29.040
I grew up in Barcelona, Catalonia, Spain, which actually is in the news still quite a bit

02:29.040 --> 02:34.200
because there's an unresolved conflict between Catalonia and the rest of Spain.

02:34.200 --> 02:35.720
And a lot of it is based on language.

02:35.720 --> 02:40.840
So growing up there, I got very interested in languages because I wondered how come half

02:40.840 --> 02:44.920
of my classmates speak Catalan and they all have speak Spanish.

02:44.920 --> 02:50.160
When if you look at the history as the Roman Empire extended throughout Europe, they were

02:50.160 --> 02:53.040
all supposed to be speaking Latin, right?

02:53.040 --> 02:58.800
And yet Latin gave rise to Italian in one place, Romanian, French, Portuguese, Spanish,

02:58.800 --> 03:02.640
Catalan, all the languages that we now call Latin or Roman's languages.

03:02.640 --> 03:07.800
So that got me curious about where do languages come from and how do they evolve?

03:07.800 --> 03:09.680
What is common across all languages?

03:09.680 --> 03:11.200
What is unique?

03:11.200 --> 03:12.720
Take the word for window, right?

03:12.720 --> 03:19.360
And Catalan window is finistra, which actually is the exact same word as in Italian finistra.

03:19.360 --> 03:21.920
Very close to the French finetra, right?

03:21.920 --> 03:26.560
Even close to the German finster, even though Germany is not even a Latin language, whereas

03:26.560 --> 03:29.560
in Spanish, I don't know if you know any Spanish.

03:29.560 --> 03:30.560
Spentana, right?

03:30.560 --> 03:31.560
Exactly.

03:31.560 --> 03:32.560
Yes.

03:32.560 --> 03:34.520
And where is the etymology of Entana?

03:34.520 --> 03:36.320
Where does it come from?

03:36.320 --> 03:40.280
Entana comes from Viento, which means wind.

03:40.280 --> 03:45.640
And it's super interesting because the work, the origin of the, in English, of window also

03:45.640 --> 03:51.480
comes from like all Germanic wind out, so like a wind's eyelid, a little hole for the

03:51.480 --> 03:57.640
wind to go through, which if it's, you know, what would you call now something for air

03:57.640 --> 04:00.920
or wind to go through that doesn't have a glass?

04:00.920 --> 04:03.200
You would call that event, right?

04:03.200 --> 04:08.280
So you have window and ventana, all these sort of related to wind, and on the other hand,

04:08.280 --> 04:09.280
there's finistra, right?

04:09.280 --> 04:10.280
Which apparently...

04:10.280 --> 04:12.280
This might be the first episode of my language podcast.

04:12.280 --> 04:13.280
Oh, yeah.

04:13.280 --> 04:16.080
Let's expand our horizons.

04:16.080 --> 04:17.080
Yeah.

04:17.080 --> 04:18.080
You know what?

04:18.080 --> 04:22.160
It's interesting that you're starting off with this conversation about language is something

04:22.160 --> 04:24.240
that I'm super excited about.

04:24.240 --> 04:30.680
I don't spend nearly enough time studying it, but this conversation around the etymology

04:30.680 --> 04:34.960
of words reminds me of a book that I read, the history of the English language that kind

04:34.960 --> 04:36.920
of goes through.

04:36.920 --> 04:41.120
The thing that I remember most vividly from that book is this concept of the Great Language

04:41.120 --> 04:46.440
Shift, I don't know if something similar happened in the room, the, or sorry, the Great

04:46.440 --> 04:47.440
vowel shift.

04:47.440 --> 04:51.320
If something similar happened in the romance languages, but in English, there was this

04:51.320 --> 04:57.840
period of time in which the vowels all shifted in the sounds that they made that made, and

04:57.840 --> 05:03.560
it's apparent when you look at like Beowulf and other writing, and you see these words

05:03.560 --> 05:07.640
that don't really make any sense until you realize that there was this vowel shift.

05:07.640 --> 05:08.640
Anyway, I just...

05:08.640 --> 05:09.640
Yeah.

05:09.640 --> 05:15.880
Yeah, and one very interesting thing about English is that it basically has this duality

05:15.880 --> 05:20.960
of vocabulary, because English is a Germanic language, but then it had a huge influence

05:20.960 --> 05:23.200
of Latin through French, right?

05:23.200 --> 05:28.720
And so you get these pairs, you know, what is the difference between freedom and liberty?

05:28.720 --> 05:33.000
Well, it's really kind of the same, it's just, you know, freedom is a Germanic one and

05:33.000 --> 05:35.600
liberty is the romance.

05:35.600 --> 05:41.800
On the other hand, there's also these super fun pairs like pig and pork, or cow and beef,

05:41.800 --> 05:47.200
where the animal, the word for the animal is the Germanic one, whereas the one for the,

05:47.200 --> 05:51.960
for the, for the, for the dish or the cook thing is the, the Latin one.

05:51.960 --> 05:55.480
Even the difference between kitchen and cuisine, right?

05:55.480 --> 05:56.480
Look at that.

05:56.480 --> 05:58.320
It's cuisine is just kitchen in French, right?

05:58.320 --> 05:59.320
Yeah.

05:59.320 --> 06:00.320
Yeah.

06:00.320 --> 06:03.080
But so word is endlessly fast, languages are endlessly fascinating.

06:03.080 --> 06:09.080
It's also not just the words, but also the constituents like in Japanese, you, you say

06:09.080 --> 06:11.400
the girl, a book reads, right?

06:11.400 --> 06:15.560
You put the verb at the end, which incidentally is also how Yoda talks.

06:15.560 --> 06:21.360
So it just appears to kind of, it lends more gravitas if you at the end of the sentence,

06:21.360 --> 06:24.480
the verb place.

06:24.480 --> 06:30.080
But of course, so, but so the interesting is that all languages have nouns and verbs,

06:30.080 --> 06:33.240
which is not surprising, because this is how we humans perceive the world.

06:33.240 --> 06:36.640
There's sort of static objects, like a cup, and then there's actions.

06:36.640 --> 06:39.440
You pour into the cup, or you drink from the cup, right?

06:39.440 --> 06:43.800
But then the way in which you put these building blocks together is more, it's more arbitrary.

06:43.800 --> 06:48.680
But of course, fundamentally, all languages have the same expressive power, it's just

06:48.680 --> 06:54.120
that certain languages tend to put more emphasis in certain aspects, like another cool example

06:54.120 --> 06:59.720
is in Chinese, you could not just say brother or sister, you have to specify whether it's

06:59.720 --> 07:01.400
older brother or younger sister, right?

07:01.400 --> 07:03.960
There's like four different words for sibling.

07:03.960 --> 07:12.360
So an interest in kind of a political interest in language, drove an interest in languages broadly,

07:12.360 --> 07:14.600
it sounds like, and is that right?

07:14.600 --> 07:15.600
Right.

07:15.600 --> 07:17.600
So you and to machine learning.

07:17.600 --> 07:18.600
Yes.

07:18.600 --> 07:22.280
So that's one aspect that've always been just, and I've tried to like learn a few languages,

07:22.280 --> 07:25.120
et cetera, sort of can mumble my way through a few.

07:25.120 --> 07:29.440
But then the other piece of technology, don't put me on the spot.

07:29.440 --> 07:34.080
But basically, so Catalan and Spanish, German, English.

07:34.080 --> 07:39.120
And then Chinese and Japanese, a little bit, I can know some basic stuff.

07:39.120 --> 07:43.440
And then actually, other languages like French and Italian Portuguese, just through sort of

07:43.440 --> 07:47.720
Romans, Osmosis, right, it's they're so close that you can basically understand.

07:47.720 --> 07:48.720
Cool.

07:48.720 --> 07:49.720
Yeah.

07:49.720 --> 07:52.160
But then the other piece is sort of technology.

07:52.160 --> 07:58.120
One day my dad brought home an HB85, one of the early home computers, a beautifully

07:58.120 --> 07:59.200
design machine, right?

07:59.200 --> 08:05.360
So the CRT monochrome screen, magnetic cartridge for storage, a thermal printer, this built

08:05.360 --> 08:06.360
in keyboard.

08:06.360 --> 08:10.840
And then some manuals that were very well done and taught you how to program at that time

08:10.840 --> 08:12.440
that was in basic.

08:12.440 --> 08:18.520
So that's how I sort of got hooked into coding and I ended up studying computer science as

08:18.520 --> 08:24.280
an undergrad in Barcelona at the UPC, the University of Polytechnic at Catalonia, which

08:24.280 --> 08:26.880
is I think now goes by Barcelona tech.

08:26.880 --> 08:31.560
But when I finished, I realized that there was this sort of nascent field at the time called

08:31.560 --> 08:36.520
computational linguistics, now better known as sort of maybe language technologies, which

08:36.520 --> 08:41.360
is this attempt of getting computer systems to understand aspects of human language.

08:41.360 --> 08:43.720
And then I thought, wow, that's absolutely amazing.

08:43.720 --> 08:49.360
I can sort of merge, combine my two interests in languages and technology.

08:49.360 --> 08:55.040
So after my undergrad in Barcelona, I did one year in Germany at the University of

08:55.040 --> 08:58.840
Cascua and then I came to the U.S. for grad school.

08:58.840 --> 09:03.120
I was at Carnegie Mellon for quite a few years because I first did a master's in computational

09:03.120 --> 09:07.800
linguistics and then I stayed for a PhD in computer science and in language technologies.

09:07.800 --> 09:08.800
Okay.

09:08.800 --> 09:13.480
So I start working on things like speech recognition, machine translation.

09:13.480 --> 09:19.880
Some of the early were calling sort of end to end speech translation, which was doing

09:19.880 --> 09:25.440
the recognition and then a fair amount of minimum amount of understanding so that you could

09:25.440 --> 09:29.120
sort of generate into a target language.

09:29.120 --> 09:35.400
Something that now is more common, but 25 years ago was sort of a pioneering work with

09:35.400 --> 09:39.360
Alex Vival, the Janus project and some other researchers.

09:39.360 --> 09:40.360
Okay.

09:40.360 --> 09:41.360
Nice.

09:41.360 --> 09:42.360
Nice.

09:42.360 --> 09:45.000
And I've got a note here that you went to CMU with Manuel Ovalosa.

09:45.000 --> 09:48.600
We've talked obviously lots of folks on the past, of course.

09:48.600 --> 09:51.720
We went on through CMU, but were you there at the same time?

09:51.720 --> 09:52.720
Do you know one?

09:52.720 --> 09:53.720
Yeah.

09:53.720 --> 09:56.200
I had her as a teacher, as a professor, of course, yes.

09:56.200 --> 09:57.200
Oh.

09:57.200 --> 09:58.200
Yeah, yeah.

09:58.200 --> 10:04.160
I think like some like just like ML or some, I remember an assignment that I did for

10:04.160 --> 10:10.720
Manuel Ovalosa, which was to automatically create crossword puzzles, not to solve them

10:10.720 --> 10:12.200
but to create them.

10:12.200 --> 10:13.200
Okay.

10:13.200 --> 10:15.200
That was one of the assignments I remember.

10:15.200 --> 10:16.200
Yeah.

10:16.200 --> 10:17.200
Awesome.

10:17.200 --> 10:18.200
Cool.

10:18.200 --> 10:20.440
So how long have you been at Square?

10:20.440 --> 10:28.080
So at Square's, but it's three years now, I did some, I was, so I spent some time doing

10:28.080 --> 10:33.160
like speech analytics for like call centers and then I moved more into kind of the startup

10:33.160 --> 10:34.160
world.

10:34.160 --> 10:36.760
It was with mine melt with Yic Yac.

10:36.760 --> 10:42.720
And then three years ago, I took it with some other team from Yic Yac we joined Square.

10:42.720 --> 10:44.040
Okay.

10:44.040 --> 10:51.040
And you're particularly focused on commerce at Square.

10:51.040 --> 10:58.320
I imagine there are lots of different ways that machine learning is used at the company,

10:58.320 --> 11:04.880
but what is the, you know, earlier, a handful of core use cases for ML at commerce.

11:04.880 --> 11:05.880
Yeah.

11:05.880 --> 11:06.880
Yeah.

11:06.880 --> 11:07.880
Yeah.

11:07.880 --> 11:10.880
The cool thing about Square is that sort of machine learning is foundational to the company,

11:10.880 --> 11:11.880
right?

11:11.880 --> 11:17.840
Because we can be so open as a platform and allow for anybody to sign up to be a square

11:17.840 --> 11:24.440
seller or even a square developer through our API is also because we have the mechanisms

11:24.440 --> 11:27.360
in place to watch out for bad actors, right?

11:27.360 --> 11:34.200
Anytime that you deal with money, you have to watch out for all kinds of fraud and risk.

11:34.200 --> 11:39.640
And so to some extent, risk management is sort of the foundational piece of the application

11:39.640 --> 11:45.560
of ML at Square, but then over the course of the years, because we're not just the people

11:45.560 --> 11:52.240
know about the little white reader that converts a smartphone into a credit card or a point

11:52.240 --> 11:58.760
of sale system, but actually we've expanded quite a lot the offerings in terms of products

11:58.760 --> 12:00.000
and services.

12:00.000 --> 12:05.400
You can run a small business just using Square with things like inventory management and

12:05.400 --> 12:10.160
even team management, we can do payroll and taxes for your employees.

12:10.160 --> 12:19.280
So that on the one hand, obviously, it's an excellent way of helping our sellers.

12:19.280 --> 12:23.960
On the other, from a risk perspective, you also have to watch out for sort of new avenues,

12:23.960 --> 12:26.480
new avenues for sort of malicious users.

12:26.480 --> 12:32.520
I'll give you a cool example, which is we have a product called Square Marketing, right?

12:32.520 --> 12:37.120
Which allows our sellers to have a conversation with their buyers through email campaigns.

12:37.120 --> 12:42.760
And we provide some nicely designed templates so that they can show their latest products

12:42.760 --> 12:47.960
or loyalty program, et cetera, except that in a couple of occasions, we saw that that

12:47.960 --> 12:51.360
was being misused as phishing attempt, right?

12:51.360 --> 12:57.600
So someone would craft what looked like was supposed to be an email marketing campaign

12:57.600 --> 13:04.400
that actually contain some link to some nefarious phishing site.

13:04.400 --> 13:07.320
So what happens there, sort of ML to the rescue, right?

13:07.320 --> 13:13.080
So we quickly develop a classifier so that before an email gets sent, it gets inspected.

13:13.080 --> 13:19.560
And then we look at what are some signals here that tells us that something is off.

13:19.560 --> 13:23.760
And of course, you can think of, well, usually there's a button associated with that sort

13:23.760 --> 13:28.760
of with a call to action, with a phishing attempt, so we can inspect the URL and compare

13:28.760 --> 13:33.200
whether the domain of the URL matches the URL of the seller if they have a website.

13:33.200 --> 13:35.880
If it doesn't, that's a bit of a red flag.

13:35.880 --> 13:41.280
But interestingly, and going back to the language, just by looking at a couple of examples,

13:41.280 --> 13:46.040
you can see that the language being used in the phishing attempts is very different from

13:46.040 --> 13:49.240
the normal sort of marketing campaign.

13:49.240 --> 13:52.040
In fact, it tends to be much more negative, right?

13:52.040 --> 13:57.080
It says, problem with your account, go fix it.

13:57.080 --> 14:01.800
And so interestingly, as I'm sure you know, there's this technique in natural language processing

14:01.800 --> 14:06.520
called sentiment analysis, where you can take a bunch of text and basically map it onto

14:06.520 --> 14:10.560
a single number, you know, minus one sad to plus one happy.

14:10.560 --> 14:17.880
So the sentiment polarity is a signal that we now use for this classifier and not by

14:17.880 --> 14:20.960
itself, but in conjunction with other features.

14:20.960 --> 14:27.200
And of course, now, so I tell, I always say, you know, don't tell these to the bad guys,

14:27.200 --> 14:28.200
right?

14:28.200 --> 14:32.720
Otherwise, they're going to adapt and start crafting marketing campaigns, saying wonderful

14:32.720 --> 14:33.720
opportunity.

14:33.720 --> 14:36.520
We can press this button, so we can have that.

14:36.520 --> 14:37.520
That's right.

14:37.520 --> 14:39.920
Wouldn't you want to freshen up your password?

14:39.920 --> 14:40.920
Yeah.

14:40.920 --> 14:46.840
So, but so the overall point here is that anytime that you have a new product, anytime that

14:46.840 --> 14:51.160
you have a new API, you obviously have to also think about, you know, how could these

14:51.160 --> 14:54.840
be misused and how can we sort of protect against that?

14:54.840 --> 15:01.720
So, manage degrees remains one of the sort of largest applications of ML at square.

15:01.720 --> 15:06.080
Another one though, which is also very interesting is just being able to be better at automating

15:06.080 --> 15:13.280
operations and being able to, for example, do more accurate marketing campaigns.

15:13.280 --> 15:20.160
As our number of products grows, it's also important to be able to let a certain subset

15:20.160 --> 15:25.040
of our sellers know about that new product, the ones that are going to be most interested

15:25.040 --> 15:26.040
in in them, right?

15:26.040 --> 15:31.600
So, a good example is a square appointments, square appointments, if you're a hairdresser,

15:31.600 --> 15:34.240
and you don't want to be on the phone all the time, you know, are you open at three, can

15:34.240 --> 15:35.640
I come in tomorrow?

15:35.640 --> 15:41.080
You'd rather have a self-serve external portal where people can just a calendar where people

15:41.080 --> 15:42.960
can book themselves, right?

15:42.960 --> 15:46.120
So that's exactly what square appointments is, and actually you're offering these for

15:46.120 --> 15:49.280
free for just for an initial location.

15:49.280 --> 15:56.040
So we've had a lot of success, but then the next question is, among our millions of sellers,

15:56.040 --> 15:58.400
who would benefit the most from square appointments, right?

15:58.400 --> 16:01.760
Because we don't want to send like a mass email that people are going to consider spam

16:01.760 --> 16:07.240
if they're not, if they're just a little kiosk, and they're not like booking doesn't

16:07.240 --> 16:09.200
make sense for that particular seller.

16:09.200 --> 16:15.920
So obviously we can do that by sort of what we call MCC Merchant Category Code, but also

16:15.920 --> 16:22.040
there's some cool ways of kind of inspecting the items and services that are in our seller's

16:22.040 --> 16:27.400
catalogs to understand whether there's certain things that are being booked by time, right?

16:27.400 --> 16:31.880
Is there any place in the description of your item where you mentioned one hour or a half

16:31.880 --> 16:32.880
an hour?

16:32.880 --> 16:36.080
Well, that's a perfect candidate for square appointments.

16:36.080 --> 16:42.200
So we're able to sort of use also a mail to have a much more targeted marketing campaigns.

16:42.200 --> 16:45.880
And so that's going to put a million operations.

16:45.880 --> 16:53.960
And then there's a third category, which you can think of driving sort of product features

16:53.960 --> 16:57.840
something that is visible to the seller, right?

16:57.840 --> 17:04.120
And so a couple of examples are we now are able to make suggestions in your catalog like

17:04.120 --> 17:09.320
based on what type of business you are, or what type of items you already have in your

17:09.320 --> 17:10.320
catalog.

17:10.320 --> 17:15.760
We're able to sort of suggest something that other products that you may want to carry.

17:15.760 --> 17:20.160
Or a simple thing is when you create a new item, let's say you're a bakery, which by

17:20.160 --> 17:21.440
the way, it's interesting.

17:21.440 --> 17:25.880
We can also know what type of business you are, obviously based on your name, right?

17:25.880 --> 17:30.080
If you're Josephine's bakery, you're a bakery, also this is a true story.

17:30.080 --> 17:36.880
If you're, what was the, oh yeah, rolling scones, you're also a bakery.

17:36.880 --> 17:40.880
And then so we're able to based on your name and certainly based on the type of items

17:40.880 --> 17:41.880
that you sell.

17:41.880 --> 17:42.880
Have a good name.

17:42.880 --> 17:44.200
Where is that business?

17:44.200 --> 17:46.240
It's a real bakery somewhere.

17:46.240 --> 17:47.240
I'm not sure.

17:47.240 --> 17:50.800
I think maybe Seattle will have what can look it up.

17:50.800 --> 17:54.640
So we know what type of business you are based also a little bit of sort of this sort of

17:54.640 --> 18:05.240
behavior, not just the name, but also the items that you sell and the ticket sizes, etc.

18:05.240 --> 18:08.920
But then when you create an item, let's say you're a bakery and you create a new item

18:08.920 --> 18:14.560
called croissant, well, we know that there's going to be certain very common variations,

18:14.560 --> 18:18.280
like plain, almond, chocolate, right?

18:18.280 --> 18:23.320
And we actually, what, you don't like croissants?

18:23.320 --> 18:31.600
No, I was thumbs down, plain, almond, meat, chocolate, yeah, it's a progression, yeah.

18:31.600 --> 18:32.600
Yes.

18:32.600 --> 18:38.080
And so we're able to auto suggest that because those are sort of, you know, we, because

18:38.080 --> 18:43.040
we understand a bit of the domain, but in a way that is sort of fully automated.

18:43.040 --> 18:45.880
So that's one example, suggestions in the catalog.

18:45.880 --> 18:52.440
And then another very sort of new area where we're just starting with is with what we call

18:52.440 --> 18:54.600
the square assistant.

18:54.600 --> 18:59.080
This is the, the result of an acquisition we did last year of eloquent labs.

18:59.080 --> 19:01.080
We now call it the conversations team.

19:01.080 --> 19:06.200
And they recently released square assistant right now for appointments, which means that

19:06.200 --> 19:11.240
when you, when a buyer gets a reminder of one of these square appointments, they can

19:11.240 --> 19:17.760
now reply and say, oh, yes, I'll be there or oh, shoot, can I come in tomorrow instead?

19:17.760 --> 19:24.400
And rain out so the assistant is able to respond on the seller's behalf about the appointments.

19:24.400 --> 19:29.240
And so these are kind of a new area where I think there's a lot of potential.

19:29.240 --> 19:37.440
So when you have a business, you know, for which ML is so fundamental, yeah, I'm thinking

19:37.440 --> 19:41.800
about how you kind of manage the portfolio of projects and how you kind of organize

19:41.800 --> 19:42.800
around that.

19:42.800 --> 19:48.480
Very different from, you know, an enterprise that is, you know, has some other business

19:48.480 --> 19:52.440
and is thinking about how can we, you know, take advantage of machine learning.

19:52.440 --> 19:55.600
Let's spin up a project here, spin it, spin up a project there.

19:55.600 --> 19:56.600
Right.

19:56.600 --> 20:03.200
You know, here you've got, you know, I can imagine, you know, every, you know, every product,

20:03.200 --> 20:07.360
every feature effort you're thinking about, you know, an engineer is thinking in the

20:07.360 --> 20:12.120
back of their head is, you know, is my goal best served by machine learning or something

20:12.120 --> 20:17.440
simpler, you know, and that might have you with a lot of, you know, places where you're

20:17.440 --> 20:22.640
trying to have a lot of impact across the, the product portfolio.

20:22.640 --> 20:27.320
How do you, well, yes, yes, I would say to that is it's certainly the case that it's

20:27.320 --> 20:31.560
where I guess we're sort of enough, you know, sort of a lucky situation where, sort

20:31.560 --> 20:37.440
of technology and ML was understood as a kind of a core component from the get go.

20:37.440 --> 20:42.920
But for any other organization, I think there's some steps that anybody can take, which is

20:42.920 --> 20:45.280
the first one is just kind of more awareness, right?

20:45.280 --> 20:51.160
So provide some broad machine learning training so that people at least sort of understand

20:51.160 --> 20:54.720
a little bit of the concepts of how do you have this.

20:54.720 --> 20:58.080
So the key thing about machine learning is that it's something that learns from the data,

20:58.080 --> 21:00.600
learns from experience, right?

21:00.600 --> 21:08.160
And so what we do even at square is we have sort of a training that we call ML for everyone

21:08.160 --> 21:11.200
where sort of we sort of teach this concept.

21:11.200 --> 21:14.920
And then we follow that up with a brainstorming session, like now that we know a little bit

21:14.920 --> 21:22.080
about ML, let's think about how could ML help your team or your customers and we come

21:22.080 --> 21:24.440
up with specific examples, right?

21:24.440 --> 21:29.160
And actually it's cool to also use the, you know, Andruang's sort of heuristic about

21:29.160 --> 21:34.600
what ML can do, but he says any task that a human can do in about a second of thought,

21:34.600 --> 21:39.560
about about one second of cognitive effort is something that we can probably automate,

21:39.560 --> 21:40.560
right?

21:40.560 --> 21:44.240
And of course, it's not a perfect heuristic, like, you know, chess playing, we would

21:44.240 --> 21:48.400
already take way longer than a second to decide the next move.

21:48.400 --> 21:51.000
But it gives us a little bit of some parameters.

21:51.000 --> 21:54.160
And so that gives us a lot of ideas to our teams.

21:54.160 --> 21:59.080
And then of course, you need to kind of aggregate and prioritize.

21:59.080 --> 22:00.560
But that typically leads.

22:00.560 --> 22:03.320
So a lot of these ideas are very good.

22:03.320 --> 22:07.200
But then you realize that they depend on the availability of data.

22:07.200 --> 22:13.720
So the third point is from an organizational perspective to treat data as a first class

22:13.720 --> 22:20.080
citizen, meaning that it's not that you have some sort of analytics as an afterthought

22:20.080 --> 22:25.600
of some, you know, kind of looking over and trying to, you know, look at some logs.

22:25.600 --> 22:31.200
But rather half the data already have a, when you design a functionality, when you design

22:31.200 --> 22:38.440
a product or an API already having mine, which data is this service going to consume?

22:38.440 --> 22:44.920
And most importantly, which data the service is able to generate so that other services

22:44.920 --> 22:47.080
can easily use that data, right?

22:47.080 --> 22:52.640
So there's quite a bit of work in terms of standardizing how we produce that data.

22:52.640 --> 22:56.960
And then also kind of the data infrastructure to have kind of a common repository of that

22:56.960 --> 23:02.360
data and not just the raw data, but then also have you sort of aggregated into sort of

23:02.360 --> 23:07.920
useful features, meaning, for example, in terms of transactions, you don't have to some,

23:07.920 --> 23:11.680
for in some cases, you don't need to know every single transaction about a seller.

23:11.680 --> 23:17.760
You just want to know what their average weekly, you know, processing volume is, right?

23:17.760 --> 23:21.680
And so you aggregate that into a signal and you can put that into what we call a feature

23:21.680 --> 23:27.840
store, then can be used by other teams and other, even other ML models.

23:27.840 --> 23:33.480
So once you have these sort of data as a first-class citizen, then it's much easier to start

23:33.480 --> 23:39.120
sort of weaving machine learning into your kind of products and processes by making use

23:39.120 --> 23:40.840
of these data.

23:40.840 --> 23:46.440
And then all of these, obviously, also, there's all these talk about, and necessarily talk

23:46.440 --> 23:54.960
about sort of ethical AIML principles and also being aware of regulations like GDPR in

23:54.960 --> 24:00.400
the European Union or CCPA in California, that you want to make sure that these systems

24:00.400 --> 24:05.520
sort of are, the technical term is, you need to show that they don't have a so-called

24:05.520 --> 24:09.680
disparate impact on protected classes, right?

24:09.680 --> 24:15.960
But it basically means that they're sort of neutral and there's a side where, so when

24:15.960 --> 24:20.040
you create a certain model, there's certain features that you don't want to look at,

24:20.040 --> 24:23.360
at the same time, for a compliance perspective, you still need to know what those features

24:23.360 --> 24:26.720
are to show that there's no disparate impact.

24:26.720 --> 24:30.320
But that's done by different teams, okay?

24:30.320 --> 24:37.440
So if you do that, so provide broad ML training, brainstorming about what ML can do for you,

24:37.440 --> 24:43.040
treat data for first-class citizen, then you can start doing some cool ML driven.

24:43.040 --> 24:48.280
Initially, it could just be some smart defaults, personalization, and then over time, you

24:48.280 --> 24:55.200
can have almost entire divisions, like Square Capital, which is sort of the armament within

24:55.200 --> 24:58.080
Square where we facilitate loans to our sellers.

24:58.080 --> 25:06.680
You can basically argue that that's pretty much all driven by ML, because, in fact, Square

25:06.680 --> 25:15.440
Capital is a great example where we can really show that the over-arching purpose at Square

25:15.440 --> 25:23.240
we call it economic empowerment, and that means making it easier for everyone to be able

25:23.240 --> 25:32.160
to participate in the economy and to have very clear understanding of what the processing

25:32.160 --> 25:41.720
fees are, exactly what is expected, and there's no hidden fees or issues like that.

25:41.720 --> 25:48.480
And so one of the good examples of this is how Square Capital just looks at how a seller

25:48.480 --> 25:50.720
is doing within our platform.

25:50.720 --> 25:56.920
We don't necessarily need to go out and check your FICO score or your history outside.

25:56.920 --> 26:04.840
We just look at how you've been doing within Square, and that has allowed us to basically

26:04.840 --> 26:09.160
facilitate these loans to many sellers to expand their business.

26:09.160 --> 26:16.400
On this idea of data as a first-class citizen, does that automatically mean just kind of

26:16.400 --> 26:24.480
save everything, or are you still needing to be very selective as to what you save, how

26:24.480 --> 26:31.560
to obtain it, compliant applications, how do you balance those operations?

26:31.560 --> 26:38.760
There's a good point, I mean, your initial instinct might be, well, let's just save everything,

26:38.760 --> 26:42.080
but that quickly becomes unmanageable.

26:42.080 --> 26:47.760
If you look at the log files generated by every single service, and we have hundreds

26:47.760 --> 26:53.520
if not thousands of services, so even there's some operational logs and stuff that you

26:53.520 --> 26:56.920
just retain for a little bit.

26:56.920 --> 27:04.120
But then there's the important piece, more of the semantics of this user logged in, and

27:04.120 --> 27:05.800
they have these transactions.

27:05.800 --> 27:08.320
That is certainly recorded.

27:08.320 --> 27:17.640
So there is a little bit of certainly sort of filtering of the important actions, and

27:17.640 --> 27:23.920
then there's also a lot of what I was mentioning before of converting these raw data into

27:23.920 --> 27:26.160
more useful aggregates.

27:26.160 --> 27:35.960
I'm so curious about given all of the places that you are trying to make an impact at Square,

27:35.960 --> 27:43.360
how does your particular team, you run an ML organization as opposed to engineering,

27:43.360 --> 27:50.720
a particular feature, or I'm trying to get at the relationship between your organization

27:50.720 --> 27:59.240
and the product teams, and are you kind of embedding people, are you kind of a centralized

27:59.240 --> 28:06.800
organization that takes on ownership of ML capabilities that get plugged into other

28:06.800 --> 28:07.800
features.

28:07.800 --> 28:08.800
How does all that work?

28:08.800 --> 28:13.120
Yeah, it's a good question because it's really a bit of a fluid situation.

28:13.120 --> 28:18.400
So, a couple of things there, first of all, Square is very much a product oriented, and

28:18.400 --> 28:25.200
so ultimately what really drives the adoption of machine learning is how well it can serve

28:25.200 --> 28:32.360
the ultimate function of overall its economic empowerment, make the life of our sellers easier,

28:32.360 --> 28:38.760
and create sort of in the parlance of these remarkable or delightful experiences that

28:38.760 --> 28:43.560
really make it sort of almost fun to use, you know, a Square software.

28:43.560 --> 28:50.200
So that is the ultimate sort of driver, and so we see ML as an enabler to that, and the

28:50.200 --> 28:55.120
question about how exactly do you do that, so they're supposed sort of kind of vertical

28:55.120 --> 29:01.200
and horizontal in the sense that first of all, we do want every engineer at Square to

29:01.200 --> 29:03.960
be at least aware of machine learning, right?

29:03.960 --> 29:10.360
In the same way that you want every engineer to be infosec conscious, right, aware of information

29:10.360 --> 29:15.800
security issues, and when you develop an API, how do you check that you're not being hacked?

29:15.800 --> 29:25.000
We also encourage all the engineers to get more familiar with what ML is capable of.

29:25.000 --> 29:32.440
Now we do also have teams that are sort of highly skilled data scientists and ML engineers,

29:32.440 --> 29:38.640
and they can sort of drive more of that, but typically, so we have some teams that are

29:38.640 --> 29:44.440
almost like all data science ML, but then the other idea that they were increasingly

29:44.440 --> 29:49.240
doing is kind of in the same way that you in order to have a full stack team, you need

29:49.240 --> 29:56.160
backend and you need front end, well, you will also add some like ML sort of expert

29:56.160 --> 30:03.200
or some engineer that has more interest in ML to kind of balance the team.

30:03.200 --> 30:08.520
Is there a typical project or a way that you engage with these product groups to help

30:08.520 --> 30:11.600
deliver new ML capability?

30:11.600 --> 30:17.920
So yes, typically there's an assessment of kind of the backlog, like what all the features

30:17.920 --> 30:21.720
are already sort of planning to do, but then we also do these brainstorming sessions

30:21.720 --> 30:26.880
to kind of bubble up some new ideas, and then of course there's this interesting sort

30:26.880 --> 30:33.000
of assessment of the idea in terms of, well, what is the expected impact, but also how

30:33.000 --> 30:36.400
feasible is it from a ML perspective, right?

30:36.400 --> 30:43.280
And also do we have enough data for the model to be able to make a good decision.

30:43.280 --> 30:49.040
And so if we go through a bit of that, and then we kind of select the sort of the most

30:49.040 --> 30:55.640
promising projects, and then we typically, what we, a good model that we have found is

30:55.640 --> 31:02.960
that the ML team is responsible for kind of the backend, kind of computing these suggestions

31:02.960 --> 31:08.640
or being able to respond to all these different messages from buyers.

31:08.640 --> 31:16.720
And then the product team that owns that sort of the product surface that we're talking

31:16.720 --> 31:22.880
about kind of ends up owning the feature, but basically they make calls to the backend

31:22.880 --> 31:25.760
that is managed by an ML team.

31:25.760 --> 31:34.320
Yeah, one of the issues that I think that that kind of relationship raises is that there's

31:34.320 --> 31:42.880
so much crossover in terms of the way machine learning originated information is surface

31:42.880 --> 31:49.920
to users, and do you express a degree of certainty on a probabilistic determination?

31:49.920 --> 31:56.640
And if so, how, you know, kinds of design issues that come into there, you know, something

31:56.640 --> 32:01.640
that you think a lot about there, or as you approach that.

32:01.640 --> 32:02.640
Right.

32:02.640 --> 32:03.640
Yeah, yeah.

32:03.640 --> 32:07.760
As I mentioned, so fundamental to how we approach the development of an ML driven feature

32:07.760 --> 32:09.720
is how is it going to look like?

32:09.720 --> 32:15.600
What's the experience going to be both when the model is accurate and most importantly,

32:15.600 --> 32:18.040
what happens when the model fails, right?

32:18.040 --> 32:23.040
And failing, there's ways of failing failing because there's no suggestion that is above

32:23.040 --> 32:28.320
a certain confidence threshold, in which case there are like, there's no suggestion.

32:28.320 --> 32:32.000
That's one situation and then the other one, which is obviously worse, is what happens

32:32.000 --> 32:34.240
when the suggestion is incorrect, right?

32:34.240 --> 32:35.960
And there's different degrees of that.

32:35.960 --> 32:41.080
So for example, in the case of item suggestion, you know, what is the worst that could happen?

32:41.080 --> 32:46.120
Well, you know, you're a bakery, and instead of suggesting a croissant, we suggest sock,

32:46.120 --> 32:47.120
right?

32:47.120 --> 32:49.920
Well, a little bit odd, but not the end of the world, right?

32:49.920 --> 32:52.880
So in that case, we can be a bit more lenient.

32:52.880 --> 32:58.440
On the other hand, for something like, you know, the credit, you know, issuing a loan or

32:58.440 --> 33:04.160
not, we have to be quite accurate in terms of modeling precision versus recall and the

33:04.160 --> 33:09.360
cost of a false positive, for example, a seller that would not pay us back versus a false

33:09.360 --> 33:13.720
negative, a seller that would have benefited, but we didn't issue a loan.

33:13.720 --> 33:20.600
And so ultimately, it's kind of a business decision, but it's highly informed by the model

33:20.600 --> 33:24.480
and being able to kind of set the correct operating point.

33:24.480 --> 33:29.800
To your point, it's certainly something that we have sort of front and center is the design

33:29.800 --> 33:35.960
of the feature and being able to make sure that that overall the product and the feature

33:35.960 --> 33:41.840
is still useful even when the model makes a mistake.

33:41.840 --> 33:47.240
And so that could go a little bit about sort of the sort of these four aspects that we

33:47.240 --> 33:54.640
think about when designing an ML driven feature, certainly the design and the actual UI and

33:54.640 --> 33:57.320
the different sort of experience.

33:57.320 --> 34:00.280
So the other one is the modeling, right?

34:00.280 --> 34:02.280
So how can we make the model more accurate?

34:02.280 --> 34:06.440
How do we make sure that it actually improves over time?

34:06.440 --> 34:14.080
And that typically means that we also have kind of a product analytics layer that kind of

34:14.080 --> 34:19.520
looks at how the adoption of that feature and how often those suggestions get accepted

34:19.520 --> 34:22.600
or not, and that feeds back into the model.

34:22.600 --> 34:25.800
And then the other piece is sort of engineering, right?

34:25.800 --> 34:29.960
Sometimes you may have a very complex model, but then when you need to run it, not for

34:29.960 --> 34:35.120
one user, but for millions of users, then you suddenly realize that maybe you need something

34:35.120 --> 34:38.920
a little bit simpler, so that it's actually computationally tractable.

34:38.920 --> 34:50.720
I'm curious when you kind of look across your portfolio of models, what is the technology

34:50.720 --> 34:57.320
mix? The square is obviously working with a lot of kind of traditional tabular data.

34:57.320 --> 35:03.980
Does that mean you're attending a more traditional techniques, or do you have a significant deep

35:03.980 --> 35:05.280
learning footprint?

35:05.280 --> 35:08.280
How do you think about technology landscape?

35:08.280 --> 35:09.280
Yeah.

35:09.280 --> 35:10.280
Yeah.

35:10.280 --> 35:15.440
Well, so it's interesting because on a per-task basis, you always want to start with a simplest

35:15.440 --> 35:17.560
model possible, right?

35:17.560 --> 35:23.520
It's sort of very alluring to say, oh, we're going to move everything to deep learning.

35:23.520 --> 35:29.560
But in fact, if taking a weighted average of what happened in the last two weeks gives

35:29.560 --> 35:34.080
you a good sense, you don't need a super complex model.

35:34.080 --> 35:39.640
And certainly when we started, now the company is 11 years old, there wasn't even deep

35:39.640 --> 35:40.640
learning at the time.

35:40.640 --> 35:49.360
So certainly some of the models are simpler, like the XG boost, et cetera, et cetera.

35:49.360 --> 35:57.200
But over time, now we also have some very sophisticated models that do use things like RNNs and

35:57.200 --> 35:59.000
CNNs.

35:59.000 --> 36:04.120
But we always sort of compare and contrast kind of making sure that the additional complexity

36:04.120 --> 36:08.640
is worth it and that the accuracy actually goes up.

36:08.640 --> 36:13.440
Are there any particular examples of places where you found that the additional complexity

36:13.440 --> 36:19.840
was justified because the problem was that interesting or complex or nuanced?

36:19.840 --> 36:20.840
Yeah.

36:20.840 --> 36:23.440
So I'll give you a relatively simple example.

36:23.440 --> 36:31.680
But going back to these item suggestions, we basically, rather than trying to do some

36:31.680 --> 36:37.920
simple, I don't know, like TFI, DF, like work frequencies and stuff, we just trained

36:37.920 --> 36:39.960
our own embeddings, right?

36:39.960 --> 36:45.960
So we applied something similar to Word2Vec in the description of the item.

36:45.960 --> 36:51.120
So we have, usually an item has a category like pastry, the item is the croissant and

36:51.120 --> 36:57.000
then the variations are in your favorite order, chocolate, almond, plain, although some

36:57.000 --> 37:02.440
people call it butter instead of plain, to make it less plain, they call it butter.

37:02.440 --> 37:09.160
And so you put all of these millions of descriptions together and you train a Word2Vec, which is

37:09.160 --> 37:14.000
basically you learn these vector representations in this hyper-dimensional space that is very

37:14.000 --> 37:17.040
sort of semantically true to the semantics.

37:17.040 --> 37:23.560
So interestingly, when we do that, we realize that even though, say, small and large are

37:23.560 --> 37:29.200
kind of opposites of each other in general English, within the context of these item catalogs,

37:29.200 --> 37:33.360
small and large are actually semantically very close and literally they are geometrically

37:33.360 --> 37:36.360
close in this hyper-dimensional vector space.

37:36.360 --> 37:42.280
And that is because in this case, both small and large encode a value for the attribute

37:42.280 --> 37:47.320
size, right, which can be applied to a coffee or to a t-shirt.

37:47.320 --> 37:52.720
And so this is how we kind of approach some of more sophisticated models, but we kind

37:52.720 --> 37:54.880
of make sure that it works.

37:54.880 --> 38:01.360
And also, one thing to add is we recently, so Square recently acquired Desa from Toronto,

38:01.360 --> 38:04.200
where they have a lot of deep learning expertise.

38:04.200 --> 38:09.200
In fact, they were famous for some cool sort of deep fakes.

38:09.200 --> 38:14.320
And so we have a lot of ideas about how to apply some of more of these sophisticated

38:14.320 --> 38:20.280
techniques to both the Square Cellar, POS, and also to Square Cash, the Cash app.

38:20.280 --> 38:29.280
What kind of tooling and technology platforms have you established to allow your data scientists

38:29.280 --> 38:35.520
to move more quickly, be more agile, get models and a production more repeatedly?

38:35.520 --> 38:36.520
Yeah.

38:36.520 --> 38:38.440
This is also evolving.

38:38.440 --> 38:44.520
As you can imagine in the beginning, it's, and also because Square is fairly decentralized,

38:44.520 --> 38:47.320
we have sort of different teams exploring different solutions.

38:47.320 --> 38:51.240
But it's also a combination of, we have our own data centers, but we also use quite a

38:51.240 --> 38:54.440
bit of cloud, both AWS, GCP.

38:54.440 --> 39:00.600
And so, you could, roughly speaking, we do a lot of the training and model development

39:00.600 --> 39:02.120
in the cloud.

39:02.120 --> 39:07.760
But when it comes time to serve, we still serve from our data centers, not, you know,

39:07.760 --> 39:11.440
not an absolute, but as, you know, kind of overall.

39:11.440 --> 39:15.880
And then in terms of making it easy for internally to write.

39:15.880 --> 39:23.000
That proximity to, to feature data or some other factor that has you as that split.

39:23.000 --> 39:26.240
Yeah, also kind of historical reason.

39:26.240 --> 39:31.280
And like we, we do have for some of the core services, we do want to maintain sort of

39:31.280 --> 39:33.240
full control.

39:33.240 --> 39:38.840
We have a good record of sort of availability and we want to maintain that.

39:38.840 --> 39:45.520
And then we have kind of a platform team that is developing some things like, you know,

39:45.520 --> 39:55.080
hosted Python notebooks and some feature store and some data infrastructure that is sort

39:55.080 --> 39:57.080
of used across all the teams.

39:57.080 --> 40:03.320
And then each team also has a, but so each team also has some sort of the freedom to use

40:03.320 --> 40:07.120
slightly different, you know, text acts, depending on their preferences.

40:07.120 --> 40:13.120
But we do have a very sort of active internal sort of community where we get together every

40:13.120 --> 40:19.920
week and we sort of share the different projects across the different teams and units so that

40:19.920 --> 40:24.360
people are aware of sort of best practices and we can collaborate.

40:24.360 --> 40:30.360
Are the folks in your, or primarily engineers or data scientists or a mix?

40:30.360 --> 40:35.680
Yeah, it's a mix because at the end of the day, we're still shipping features, right?

40:35.680 --> 40:42.200
And so we can partner with product teams or to some extent, we now also have ML heavy

40:42.200 --> 40:51.760
teams that end up being full stack because that's also made the faster path to productizing

40:51.760 --> 40:52.760
a feature.

40:52.760 --> 40:58.320
A good example is this conversations team, right, that is responsible for score assistant.

40:58.320 --> 41:04.280
They are extremely sort of ML AI heavy, but now they also have, you know, front and

41:04.280 --> 41:08.240
engineers to help them get the product out faster.

41:08.240 --> 41:16.880
And so when you think about that spectrum of, you know, ML heaviness or readiness and kind

41:16.880 --> 41:23.040
of a role or an organization that's focused on ML, you know, that's ML in the, in the

41:23.040 --> 41:28.440
name, like head of ML, you know, being your title, like is ultimately like, do you think

41:28.440 --> 41:36.400
that your role is to put yourself out of a job by making the product teams, you know,

41:36.400 --> 41:40.800
self-sufficient that, you know, it's, ML is kind of a corporate capability.

41:40.800 --> 41:46.920
And if so, like, you know, what's the timeline on that or do you, do you think that standalone

41:46.920 --> 41:52.200
ML organizations are kind of long-term, you know, have a long-term sustainable role?

41:52.200 --> 41:54.400
And if so, kind of what do you think that is?

41:54.400 --> 41:55.400
Right.

41:55.400 --> 42:02.480
Yeah, I do like a lot the idea of basically increasing the overall skill set of, of engineers and

42:02.480 --> 42:08.520
product managers and designers about ML. And so ultimately, that is my goal.

42:08.520 --> 42:12.080
That doesn't mean though that obviously there's going to be always a core that is sort of

42:12.080 --> 42:16.600
more following the latest developments and doing some research of their own.

42:16.600 --> 42:22.440
But I think that's certainly to make a product feature successful, you could not have too

42:22.440 --> 42:25.600
much of a separation between ML and product, right?

42:25.600 --> 42:27.480
It has to be more embedded.

42:27.480 --> 42:34.960
I mean, it's certainly been amazing to see, you know, how quickly kind of innovation jumps

42:34.960 --> 42:41.600
from pure research academia into commercial environments.

42:41.600 --> 42:47.840
And, you know, your typical kind of, yeah, I guess just comparing it to, you know, other

42:47.840 --> 42:53.680
kind of technology waves that, you know, we've seen like mobile and cloud and these other

42:53.680 --> 42:58.160
things like they didn't necessarily require people to read papers in order to, you know,

42:58.160 --> 43:04.600
have an impact, whereas, you know, with machine learning, you know, I'm, you know, when

43:04.600 --> 43:09.520
I'm talking to people doing kind of practical things to push a business forward, that often

43:09.520 --> 43:15.080
involves, you know, being under being aware of kind of the latest developments and research

43:15.080 --> 43:20.480
and using those to push the kick the ball forward, push the needle forward, whatever

43:20.480 --> 43:24.160
the right analogy is.

43:24.160 --> 43:26.160
Do you see that well?

43:26.160 --> 43:27.160
Yes.

43:27.160 --> 43:32.800
So, to some extent, I mean, obviously there, it's amazing to have people that are super excited

43:32.800 --> 43:39.400
and following the latest research and we do have, you know, paper reading groups that some

43:39.400 --> 43:45.480
of us participating, having said that, I would actually argue that there is also beginning

43:45.480 --> 43:51.080
to be quite a strong sort of a democratization process of ML.

43:51.080 --> 43:57.560
And if you look at what the, you know, the usual suspects offer in terms of ML capabilities,

43:57.560 --> 44:03.080
they started with some basic, oh, we can do model hosting for you, right?

44:03.080 --> 44:08.480
But now it's not just model hosting, but basically there's some like ready-made models that

44:08.480 --> 44:12.880
you don't even need to like train yourself or, or, or, or, or, you don't, you don't even

44:12.880 --> 44:17.520
need to have almost like a training set, you can use sort of off the shelf things for

44:17.520 --> 44:24.560
say recognizing the, the license plates, right, or, or analyzing driver's license.

44:24.560 --> 44:30.200
So to some extent, it's also going to be much easier in the future to use some of these

44:30.200 --> 44:34.400
models and it's almost just going to put these building blocks together, right?

44:34.400 --> 44:40.800
Have teams that square built products on third party, you know, AI as a service types

44:40.800 --> 44:42.560
of models?

44:42.560 --> 44:48.600
So yeah, typically not, typically, because we are actually very protective of our data,

44:48.600 --> 44:49.600
right?

44:49.600 --> 44:55.880
So we typically like do our own models, although, I mean, for certain, you know, explorations

44:55.880 --> 45:01.240
outside of the core business, certainly, we, you know, we, we, we kind of play with have

45:01.240 --> 45:04.280
some prototypes with some external models.

45:04.280 --> 45:10.640
And I'm interested, I have more questions about kind of the, you know, all the stuff

45:10.640 --> 45:15.480
that we talked about the relationship between your group and others and kind of the tooling

45:15.480 --> 45:16.480
and platform.

45:16.480 --> 45:23.760
I mean, maybe a good place to, to go to start to wind down is, you know, just in terms

45:23.760 --> 45:29.600
of the things you've learned, kind of building and, you know, what was, was the team small

45:29.600 --> 45:33.840
when you arrived or did you inherit a team even or did you build it up from scratch?

45:33.840 --> 45:34.840
Yeah.

45:34.840 --> 45:40.080
Well, this specific team, the Commerce and Mail, I, I, yeah, I, that, that one, I sort

45:40.080 --> 45:44.360
of, I started as a, you know, as a, as a single person and then, and then sort of growing,

45:44.360 --> 45:45.360
growing over time.

45:45.360 --> 45:52.060
I think the most interesting lesson is, um, there's certainly a lot of interest in how

45:52.060 --> 45:58.960
ML can improve the, you know, the, the, the day to day of both internal teams and, and,

45:58.960 --> 46:01.680
um, and our sellers and, and customers.

46:01.680 --> 46:07.760
Um, but of course, the, the fun part is kind of identifying which projects are going to

46:07.760 --> 46:12.840
be the most relevant and be able to do some quick prototyping to kind of either validate

46:12.840 --> 46:16.560
or realize that that may not be the, a good path forward.

46:16.560 --> 46:20.800
So being able to kind of do some quick iterations is, is important.

46:20.800 --> 46:29.560
And the other thing was, as in any organization, there's always ways to improve the data quality,

46:29.560 --> 46:30.560
right?

46:30.560 --> 46:35.320
So, so not just the kind of the, the infrastructure and the pipelines, but also, uh, the type

46:35.320 --> 46:43.000
of data that is, uh, that is locked and, and how it is locked so that, um, other teams basically

46:43.000 --> 46:51.240
increase the, the, the clarity of the semantics about, uh, what that data is, um, meaning these

46:51.240 --> 46:57.480
team call this field, uh, you know, item description, um, by what do you mean by item description

46:57.480 --> 47:02.280
because there's, there's the category, there's the variation, does it include the price?

47:02.280 --> 47:07.280
Um, so different people may have different assumptions about what that field means.

47:07.280 --> 47:13.320
Um, and so also being able to have a, kind of a consistent semantics across services and

47:13.320 --> 47:17.880
teams, um, this is, uh, you know, I'm not saying that we've solved it, but this is a, sort

47:17.880 --> 47:22.160
of an ongoing and something that we've made a huge, uh, advances on.

47:22.160 --> 47:23.160
Mm-hmm.

47:23.160 --> 47:31.200
Yeah, you mentioned, uh, kind of being thoughtful about the types of projects that you go after.

47:31.200 --> 47:37.600
One of the, the often recurring themes that, uh, has come up when I've talked to folks

47:37.600 --> 47:44.640
that are kind of in this, uh, head of ML type of role is kind of balancing the practicality

47:44.640 --> 47:52.200
of your portfolio, but also kind of having some moonshot aspects of it that if slash one

47:52.200 --> 47:57.720
achieve significantly can, you know, make a big dent and, you know, can be kind of game

47:57.720 --> 48:02.560
changes. Is that, do you, do you think about it similarly? And you kind of get your portfolio

48:02.560 --> 48:03.560
in that way?

48:03.560 --> 48:04.560
Yeah.

48:04.560 --> 48:05.560
Yeah.

48:05.560 --> 48:11.240
Um, we do want to have a mix of more sort of short-term, uh, quote unquote realistic,

48:11.240 --> 48:15.200
uh, projects, you know, something that we feel is very doable.

48:15.200 --> 48:18.840
It's just going to take, you know, one quarter or two quarters or three quarters.

48:18.840 --> 48:23.840
But then there's also the kind of a longer horizon of, um, more sort of, yeah, one shot

48:23.840 --> 48:30.880
as, as you called it, um, or just explorations of features that would be extremely cool

48:30.880 --> 48:32.560
if we could do these or that.

48:32.560 --> 48:37.280
So what would typically what we do is, um, almost like the, the, the old famous, you know,

48:37.280 --> 48:38.960
the Google 8020.

48:38.960 --> 48:43.800
So we, we do have some, uh, hack weeks and we have some people devoting a sort of amount

48:43.800 --> 48:48.360
of their time to more of these, uh, long-term, uh, projects.

48:48.360 --> 48:55.160
Um, and it's, it's, they also need a bit of a, of a balance, um, um, and so, but so,

48:55.160 --> 49:00.040
yeah, typically the way I organize it is making sure that in any given quarter, we have

49:00.040 --> 49:07.000
some work done for some of these more long-term, um, projects and some of it is just sort

49:07.000 --> 49:14.040
of researching new technologies, um, doing some, uh, sort of just, just kind of mock ups

49:14.040 --> 49:21.160
of how things could be, if only we had this, so if we, we only, only had that technology.

49:21.160 --> 49:31.080
Are the long-term plays as equally product-driven as the, the short-term or are they, you

49:31.080 --> 49:35.560
know, did they come from the product teams like each, each of the product teams has their

49:35.560 --> 49:36.560
long-term vision?

49:36.560 --> 49:42.560
Or are they, you know, more driven by the opportunity created by the technology and, you

49:42.560 --> 49:43.560
know, yeah.

49:43.560 --> 49:45.520
But almost say it's, it's more like the, the latter.

49:45.520 --> 49:50.040
Like so, because the product teams already have a, a well-defined backlog and, and some

49:50.040 --> 49:52.880
of it is already very sort of forward-looking.

49:52.880 --> 49:58.200
And so the thought experiment is more about even in, you know, like a, the, you know, three

49:58.200 --> 50:02.720
to five years, not even, you know, one to two years, but like three to five, what, where

50:02.720 --> 50:09.640
could we be, um, what are the, the general trends in society and in technology?

50:09.640 --> 50:14.320
I mean, frankly, like, you know, the whole COVID situation and working from home, that seems

50:14.320 --> 50:18.160
to, you know, it will, it will stay here for quite a while.

50:18.160 --> 50:24.440
So how does society change because of that and, and how can we sort of position square

50:24.440 --> 50:28.880
to help our sellers in that environment, um, and also in general, what, you know, what

50:28.880 --> 50:35.920
kind of, um, new forms of almost like human behavior are going to arise from these

50:35.920 --> 50:41.760
new circumstances? Hmm. Very cool, very cool. Well, Marcel, thanks so much for taking

50:41.760 --> 50:48.280
the time to chat. If I do decide to start the Sam, you know, oh, yeah, the linguistics.

50:48.280 --> 50:54.040
Yeah. Yeah. Yeah. Yeah. I can tell you some more anecdotes about, about, uh, funny languages

50:54.040 --> 50:59.640
like, uh, Google Imuthir, where you could not say I'm standing in front of Sam. I would

50:59.640 --> 51:05.440
have to say I'm standing northwest of Sam or something. Anyway, of course, this is all

51:05.440 --> 51:10.960
changed by, by remote technologies too. But, uh, yeah, but it's been a pleasure. Um, and

51:10.960 --> 51:16.120
I thank you for having me on your, on your podcast, Sam. All right. Thanks so much, Marcel.

51:16.120 --> 51:24.960
Take care. All right, everyone. That's our show for today. For more information on today's

51:24.960 --> 51:32.280
show, visit twomolai.com slash shows. As always, thanks so much for listening and catch

51:32.280 --> 51:44.280
you next time.

