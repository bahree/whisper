WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:31.160
I'm your host Sam Charrington.

00:31.160 --> 00:35.280
This week on the podcast we're featuring a series of shows that highlight just a few of

00:35.280 --> 00:39.800
the great innovations and innovators at the intersection of three very important and

00:39.800 --> 00:46.280
familiar topics, data science, the Python programming language and open source software.

00:46.280 --> 00:49.960
To better understand our listeners' views on the importance of open source and the projects

00:49.960 --> 00:54.520
and players in this space, I'm conducting a survey which I'd be very grateful if you

00:54.520 --> 00:57.040
took a moment to complete.

00:57.040 --> 01:01.760
To access the survey, visit Twimbleai.com slash Python survey.

01:01.760 --> 01:09.800
Please hit pause now and we'll wait for you to get back.

01:09.800 --> 01:15.880
That's twimbleai.com slash Python survey.

01:15.880 --> 01:19.840
Before we dive into the show, I'd like to send a huge thanks to our sponsor for this

01:19.840 --> 01:22.200
series IBM.

01:22.200 --> 01:27.200
Speaking of open source, IBM has a long history of engaging in and supporting open source projects

01:27.200 --> 01:33.040
that are important to enterprise data science, projects like Hadoop, Spark, Jupiter and

01:33.040 --> 01:35.680
Cubeflow to name just a few.

01:35.680 --> 01:41.640
IBM also hosts the IBM data science community, which is a place for enterprise data scientists

01:41.640 --> 01:47.320
looking to learn, share and engage with their peers and industry renowned practitioners.

01:47.320 --> 01:52.440
Here you'll find informative tutorials and case studies, Q&As with leaders in the field

01:52.440 --> 01:57.800
and a lively forum covering a variety of topics of interest to both beginning and experience

01:57.800 --> 01:59.560
data scientists.

01:59.560 --> 02:05.160
Check out and join the IBM data science community by visiting IBM.com slash community slash

02:05.160 --> 02:06.160
data science.

02:06.160 --> 02:12.120
Alright everyone, I am on the line with Inez Montani.

02:12.120 --> 02:20.960
Inez is the co-founder of Explosion, a co-developer of the popular NLP open source library

02:20.960 --> 02:24.920
Spacey and lead developer of Prodigy.

02:24.920 --> 02:27.960
Inez, welcome to this weekend machine learning and AI.

02:27.960 --> 02:28.960
Yay, thanks.

02:28.960 --> 02:30.360
I'm really happy to be here.

02:30.360 --> 02:32.400
I'm excited to have you on as well.

02:32.400 --> 02:37.160
I've been looking forward to speaking with you for quite some time now.

02:37.160 --> 02:42.920
I'd love to hear a little bit about how you got started on this path of working at this

02:42.920 --> 02:48.320
confluence of open source and AI and Python.

02:48.320 --> 02:49.960
How did it all happen?

02:49.960 --> 02:54.920
Yeah, so I actually had to try out quite a few things to kind of end up at this point

02:54.920 --> 02:58.920
where I found kind of like the perfect job that combines all of the things I like doing

02:58.920 --> 03:02.480
and all of kind of my skills and things I'm good at.

03:02.480 --> 03:06.600
So I initially, I've always been into programming.

03:06.600 --> 03:09.520
So I grew up on the internet.

03:09.520 --> 03:13.680
I've made websites where we got our first computer when I was like 11.

03:13.680 --> 03:14.680
So I was really into that.

03:14.680 --> 03:20.480
So I spent most of my teenage years building websites basically.

03:20.480 --> 03:23.360
But I didn't actually choose to go into computer science.

03:23.360 --> 03:28.360
So I did my degree in communication science and linguistics, which are also things I was

03:28.360 --> 03:29.360
really interested in.

03:29.360 --> 03:30.800
I worked in media for a while.

03:30.800 --> 03:35.800
But I was always kind of programming on the side and doing those kinds of things.

03:35.800 --> 03:42.000
I eventually, I met my co-founder and also the initial Spacey author Matthew Hannibal

03:42.000 --> 03:44.600
in 2014 here in Berlin.

03:44.600 --> 03:47.360
And yeah, we just started working together and we quickly realized that we had very

03:47.360 --> 03:54.400
similar ideas about like building software, making the technology accessible, making it

03:54.400 --> 03:56.400
usable.

03:56.400 --> 04:00.640
And so yeah, so we eventually, we decided to find a company together, explosion.

04:00.640 --> 04:05.760
Initially we bootstrapped with a bit of consulting and then focused 100% on product.

04:05.760 --> 04:08.400
And development for developer tools.

04:08.400 --> 04:11.560
And yeah, Prodigy was our first product that we launched.

04:11.560 --> 04:12.560
Awesome.

04:12.560 --> 04:14.880
And so Spacey came before Prodigy, correct?

04:14.880 --> 04:16.400
Prodigy is relatively new, right?

04:16.400 --> 04:21.120
Yeah, Prodigy, I think we launched, we went on sale in December 2017.

04:21.120 --> 04:25.360
So it's actually been out for quite a while and we've been really, really happy about like,

04:25.360 --> 04:29.680
you know, response to it and how well, like how many people have been adopting it.

04:29.680 --> 04:34.960
But yeah, Spacey's been there before, Matt basically, he left academia when he realized

04:34.960 --> 04:38.320
that like, wow, you know, the technology is becoming a lot more mature.

04:38.320 --> 04:43.080
People, companies wanted to use his research code and asked him about licensing terms and

04:43.080 --> 04:48.080
he was like, well, you know, if I actually focus on this and write a library that's really

04:48.080 --> 04:52.760
focused on doing all of this in production and getting stuff done, that could be, you

04:52.760 --> 04:54.400
know, really useful to people.

04:54.400 --> 05:01.480
So yeah, he developed Spacey, it was, you know, released open source and I kind of started

05:01.480 --> 05:05.640
working on it pretty much kind of around the time I was first released, but that's when

05:05.640 --> 05:07.600
we started working together.

05:07.600 --> 05:13.360
And so as I mentioned in the intro, Spacey is a very popular library.

05:13.360 --> 05:20.240
I hear it come up all the time in the context of NLP, but for those that aren't familiar

05:20.240 --> 05:25.960
with it, can you maybe share a little bit about what makes it unique and the philosophy

05:25.960 --> 05:31.840
behind it relative to the many other libraries kind of in the NLP landscape?

05:31.840 --> 05:32.840
Yeah, sure.

05:32.840 --> 05:36.440
So Spacey is a library for natural language processing in Python.

05:36.440 --> 05:41.200
So basically, if you have lots of text and pretty much any company, any kind of use case,

05:41.200 --> 05:43.360
you always end up with lots of text.

05:43.360 --> 05:46.880
And at some point, you want to find out more about that text that also goes beyond like

05:46.880 --> 05:51.000
what you can personally read and also goes beyond a bit of like keyword search.

05:51.000 --> 05:56.280
So you know, we want to find out like what companies I mentioned, what people, who says

05:56.280 --> 05:59.920
what and to whom and how are the people, how are there all the things and concepts and

05:59.920 --> 06:00.920
ideas related.

06:00.920 --> 06:06.720
And so Spacey is a library that can help you do that using rule-based methods, but also

06:06.720 --> 06:10.400
with using machine learning models and by training.

06:10.400 --> 06:13.440
And you know, that also helps you train your own machine learning models to do these things.

06:13.440 --> 06:18.720
And the focus is really specifically on industry and production use cases.

06:18.720 --> 06:22.400
So I would say that's also where Spacey is a bit different from a lot of other libraries

06:22.400 --> 06:24.200
that focus a lot more on research.

06:24.200 --> 06:27.680
And you know, research is clearly like also a very important field, but we say okay, instead

06:27.680 --> 06:32.160
of giving you lots of different ways to do one thing so you can, you know, compare

06:32.160 --> 06:38.760
them and you know, compare different model architectures, we give you one way to do things.

06:38.760 --> 06:43.800
And you know, one API, you know, we focus a lot on having a concise API and also having

06:43.800 --> 06:49.560
like one implementation that does one thing and, you know, that and also I think I guess

06:49.560 --> 06:52.760
one another thing Spacey is kind of famous for is that it's very fast.

06:52.760 --> 06:57.320
So that's another very important kind of goal we set ourselves that like whatever we build

06:57.320 --> 07:02.680
and whatever we ship to people has to run fast enough that you can process millions, billions

07:02.680 --> 07:07.240
of documents, you know, in a time that's feasible for a production use case.

07:07.240 --> 07:15.440
I imagine the 900 pound gorilla in the space is NLTK, is that kind of the, the, the

07:15.440 --> 07:21.320
the fact of standard for, you know, folks doing NLP and Python or is there something else

07:21.320 --> 07:23.600
that comes to mind for you?

07:23.600 --> 07:28.000
So NLTK is definitely very popular library and it's also one, a library that many people

07:28.000 --> 07:33.040
have started working with when they, you know, learned NLP, it's very, it was initially

07:33.040 --> 07:38.160
developed for teaching and research, so it still has, you know, very wide adoption, but

07:38.160 --> 07:43.920
it's also very much research focused, like a lot of other, you know, libraries, we now

07:43.920 --> 07:50.840
have, you know, also there are lots of implementations that use PyTorch or TensorFlow to do NLP, but

07:50.840 --> 07:55.480
still there's a very, you know, but a lot of focus is on, you know, really building the

07:55.480 --> 07:59.840
model architectures and we kind of start like kind of on the other side where we say,

07:59.840 --> 08:05.720
okay, we give you APIs and basically the whole like, you know, container objects and the

08:05.720 --> 08:10.720
whole like infrastructure plus optimized statistical models to solve your NLP problems.

08:10.720 --> 08:17.240
And you mentioned the, that part of it is that it offers kind of facility for rule-based

08:17.240 --> 08:20.760
processing in addition to models.

08:20.760 --> 08:22.160
Can you elaborate on that a little bit?

08:22.160 --> 08:27.600
Yeah, obviously a lot of the excitement is around machine learning and models, but

08:27.600 --> 08:32.200
I just did an interview yesterday, it hasn't been published yet, but we were talking about

08:32.200 --> 08:36.560
how, you know, in the real world, you know, in these production use cases, especially at

08:36.560 --> 08:40.320
scale, sometimes, you know, it just makes sense to do things with rules.

08:40.320 --> 08:44.280
Yeah, absolutely, yeah, I would definitely agree with that, like that's also something

08:44.280 --> 08:46.120
we see a lot.

08:46.120 --> 08:50.720
So, you know, what space your office is kind of imagine regular expressions, but with

08:50.720 --> 08:54.040
like, you know, a lot of additional features that you can take advantage of because, you

08:54.040 --> 08:59.680
know, we can now predict a lot of things about a sentence that holds a lot of deeper information.

08:59.680 --> 09:05.320
For example, you can find things in, but only if they attach to a verb or you can, you

09:05.320 --> 09:11.280
know, use a lot of those like linguistic attributes to build a very, very complex or

09:11.280 --> 09:16.880
also a very simple straightforward set of rules that lets you extract content or information

09:16.880 --> 09:17.880
that you're looking for.

09:17.880 --> 09:23.040
And especially actually if combined with statistical models, rule-based systems can be incredibly

09:23.040 --> 09:24.040
powerful.

09:24.040 --> 09:28.320
And also something we see a lot in a lot of industry use cases that actually, yeah, it's

09:28.320 --> 09:32.840
kind of, you know, the fun part is training all your hip neural network models and fiddling

09:32.840 --> 09:37.440
with the hyperparameters, but actually in production, what often really makes a difference

09:37.440 --> 09:43.320
is a really good set of rules that's been tested, validated, and build up over a long

09:43.320 --> 09:46.360
period of time and is really, really specific to the use case.

09:46.360 --> 09:51.640
And in that enhanced, with some machine learning can actually often be much more effective

09:51.640 --> 09:54.040
than like an end-to-end approach.

09:54.040 --> 09:59.480
Are there any use cases that come to mind as, you know, particularly exciting or even

09:59.480 --> 10:04.320
surprising why I never would have imagined someone would have done this with this code

10:04.320 --> 10:05.320
that we wrote?

10:05.320 --> 10:10.280
I mean, in general, like I'm one thing I'm always very, you know, excited about, or like

10:10.280 --> 10:14.640
what that was very eye-opening was that like, it's really, there's, there's no like boundaries

10:14.640 --> 10:19.440
in like the industries that use NLP, like, you know, often people think, oh, well, of course

10:19.440 --> 10:24.440
that the large like tech companies or anyone's doing something with like tech modern stuff

10:24.440 --> 10:31.440
will be using NLP, but it's like a lot of from aerospace to like, I don't know, energy

10:31.440 --> 10:36.080
companies, like everyone has text and everyone uses NLP.

10:36.080 --> 10:40.720
So often also when, you know, we have like new companies who are like, who start using

10:40.720 --> 10:45.480
prodigy or annotation tool, we're like, oh, wow, you use spacey in production and you

10:45.480 --> 10:46.480
do NLP.

10:46.480 --> 10:51.280
Yeah, I guess it makes sense, but it can still, it's basically like, you know, it's

10:51.280 --> 10:54.040
not, it's everywhere.

10:54.040 --> 10:58.000
And in terms of, I mean, use cases, it's, I do, I do have to say that the things that

10:58.000 --> 11:03.440
work best are probably not the most like, oh my god, exciting use cases.

11:03.440 --> 11:07.640
Like, you know, people love to talk about the really like, you know, like cutting edge,

11:07.640 --> 11:10.840
like, I don't know, things you could have never guessed, but actually the stuff that works

11:10.840 --> 11:15.080
well is just like, really good old like information extraction.

11:15.080 --> 11:21.360
You have some problem, you want to, for example, pre fill a database with information from

11:21.360 --> 11:23.320
natural language text.

11:23.320 --> 11:26.440
And that's actually, that's the stuff that actually works really, really well.

11:26.440 --> 11:31.920
And luckily, it's also kind of the stuff that like offers the biggest, I guess, return

11:31.920 --> 11:37.200
and monetary value to like companies doing that.

11:37.200 --> 11:40.680
When you say the stuff, that's the stuff that works really, really well, a library on

11:40.680 --> 11:47.080
that is that mean that it's the stuff that the library does best or the stuff that folks

11:47.080 --> 11:52.840
have the most success in actually implementing or, or something else.

11:52.840 --> 11:57.080
I would say actually we're just, we're just with NLP in general, whether technology or

11:57.080 --> 12:01.320
doing machine learning with text actually, it has proven to work.

12:01.320 --> 12:04.560
Like there are other fields like, you know, we are seeing a lot of like, you know, really

12:04.560 --> 12:11.000
cool like achievements in even conversational stuff, but like it's just that, and you

12:11.000 --> 12:15.160
know, that that just doesn't yet work as well as, you know, people would maybe, you know,

12:15.160 --> 12:17.280
people on the outside would maybe imagine it to work.

12:17.280 --> 12:21.800
Like you still don't have like a magical computer that can answer any question, whereas,

12:21.800 --> 12:25.640
okay, yeah, but about the kind of, the more information extraction stuff, which also

12:25.640 --> 12:30.520
is something we kind of focus on a bit because it works so well is really what's, you know,

12:30.520 --> 12:35.480
that works, we can, you know, we can predict the right things, we can augment, you know,

12:35.480 --> 12:41.600
the predictions with rules, and that's actually, yeah, it's just more successful than other

12:41.600 --> 12:43.440
more speculative areas.

12:43.440 --> 12:49.440
Is explosion you and Matt, or is it a bigger company than that today?

12:49.440 --> 12:53.520
So it started out with only us, and it was only us for quite a while.

12:53.520 --> 12:56.800
We're now working with a few other people on different types of projects.

12:56.800 --> 13:01.440
So, you know, we currently have one person working full time together with us on cool new

13:01.440 --> 13:04.360
features for Spacey, which is really exciting.

13:04.360 --> 13:09.240
And then we have a few developers working on kind of an extension product to Prodigy,

13:09.240 --> 13:13.600
which we're currently finishing, but we still, we still have a small company and a

13:13.600 --> 13:16.840
very small team, and we also plan on staying a very small team.

13:16.840 --> 13:20.080
So that's definitely an important part of kind of our strategy.

13:20.080 --> 13:26.400
And so when you think about Spacey as an open source project, is the contribution

13:26.400 --> 13:35.400
and the code from that primarily contributions made by the explosion team, or do you have,

13:35.400 --> 13:39.680
there's clearly a broad community there, but is it a broad user community, or contributing

13:39.680 --> 13:43.960
community, or a little bit of both, how is that aspect of the project then?

13:43.960 --> 13:49.000
So I would say compared to other more community open source projects, we still have a fairly

13:49.000 --> 13:52.120
small number of my core contributors.

13:52.120 --> 13:56.680
That's true, so a lot of the sort of direction is driven by us, but it's also something

13:56.680 --> 14:01.000
that works well because, you know, users use Spacey because they want to have like, you

14:01.000 --> 14:04.600
know, a good implementation, and they're like, okay, you guys do the implementation,

14:04.600 --> 14:08.200
and we'll use it, and we'll report bugs, and that's okay, that's fine, that's something

14:08.200 --> 14:13.680
we accept, but where we see a lot of contributions, especially like recently, is all the language

14:13.680 --> 14:14.680
specific stuff.

14:14.680 --> 14:20.360
So Spacey ships with a bunch of rules and a bunch of kind of base, basically the kind of

14:20.360 --> 14:25.160
basic setup for all kinds of languages that we support, and that's really where people,

14:25.160 --> 14:28.800
even people who are kind of new in the field can very easily help out, like, you know,

14:28.800 --> 14:32.080
you could, if you speak, or if you know some language, you could maybe add some rules

14:32.080 --> 14:37.600
to improve the way Spacey can tell what a word is and what's not a word and what's punctuation,

14:37.600 --> 14:43.560
for example, or, you know, add some other rules for limitization, or, I don't know, just

14:43.560 --> 14:44.560
add some more tests.

14:44.560 --> 14:47.400
So that's really, that's where we see most of the community contributions, and that's

14:47.400 --> 14:50.640
also where the community contributions are most valuable.

14:50.640 --> 15:00.120
Given the focus on rules and some of the fundamental NLP techniques, do you also track closely

15:00.120 --> 15:09.720
the more cutting edge stuff, like how does Spacey relate to, you know, these new models

15:09.720 --> 15:15.800
like Bert and GPT2, do you try to implement those and ship those with Spacey, or are

15:15.800 --> 15:17.520
they kind of separate?

15:17.520 --> 15:21.960
Yeah, so we, I mean, basically, so our mission has always been, we take what's proven to

15:21.960 --> 15:25.680
work in research and bring it into production so people can views it reliably.

15:25.680 --> 15:29.880
So that's always been our focus, of course, we track what's going on, and then the next

15:29.880 --> 15:33.840
challenge is, okay, we have to see how are we implementing this in a way that it makes

15:33.840 --> 15:37.040
sense for people, because, you know, often what's a bit unintuitive to people is that,

15:37.040 --> 15:40.640
well, you can't just, you know, you can't just pip install Bert, and then it will just

15:40.640 --> 15:46.520
like run magically in your production application, but it's like, you know, sometimes people

15:46.520 --> 15:49.960
have like this idea, it's like, oh, what can be so hard about like just, you know, giving

15:49.960 --> 15:54.320
us all of these models, but, you know, so what we do is we see, okay, how can we make

15:54.320 --> 15:55.320
this work?

15:55.320 --> 15:57.960
Also, how can we make this work with the performance targets we have?

15:57.960 --> 16:03.400
Like, you know, if you have a system, you know, like Bert, where we, basically, we predict

16:03.400 --> 16:08.200
the next word given, you know, the context and the previous words, that's like, those

16:08.200 --> 16:12.120
models are very, very large, and they're also not necessarily very fast.

16:12.120 --> 16:18.240
And at Spacey, we have like, you know, performance target of like 10,000 tokens per second.

16:18.240 --> 16:19.240
That's pretty fast.

16:19.240 --> 16:24.360
So like, for example, to be able to implement this sort of idea, we came up with kind

16:24.360 --> 16:26.520
of our own way of doing this.

16:26.520 --> 16:30.360
So what we're doing in Spacey is we're actually predicting the vector of the next word,

16:30.360 --> 16:34.080
which makes our models much, much smaller and makes it much, much faster.

16:34.080 --> 16:38.120
But actually, yeah, with the latest version of Spacey, we were able to ship a pre-training

16:38.120 --> 16:43.960
feature that basically, you know, let's, let's people use the way, those very new transfer

16:43.960 --> 16:48.520
learning techniques in NLP that I've made the headlines recently, that's a, that's a

16:48.520 --> 16:49.520
very cool thing.

16:49.520 --> 16:53.840
Yeah, can you elaborate a little bit more on that distinction, the distinction of predicting

16:53.840 --> 16:57.760
the vector of the next word as opposed to the next word and how that gives you the performance

16:57.760 --> 16:58.760
increases?

16:58.760 --> 17:03.760
Well, basically, I mean, if you, you know, if you predicting the vector, you're only predicting

17:03.760 --> 17:07.840
kind of an approximation and we can also take advantage of pre-trained word vectors that

17:07.840 --> 17:08.840
we already have.

17:08.840 --> 17:13.400
So like, you know, something like word-to-vec, we also ship like a pre-trained package,

17:13.400 --> 17:16.640
and you can actually, so instead of always keeping track of, you know, all of the individual

17:16.640 --> 17:21.040
words and having representations of all of these words, we actually only have like kind

17:21.040 --> 17:24.600
of the rough meeting representation, the word vector.

17:24.600 --> 17:29.880
So, you know, we can predict that, we can use take, you know, we can take advantage of

17:29.880 --> 17:34.280
a pre-trained word vectors we already have, and it basically makes, it makes the overall

17:34.280 --> 17:39.360
artifact much smaller, and we can rely on that at runtime, so it makes it, it makes it

17:39.360 --> 17:43.960
faster and smaller, and like, you know, there's some other tricks that we have in spacey in

17:43.960 --> 17:50.720
a way we, you know, store those vectors and, you know, cache the data, that also, you

17:50.720 --> 17:53.200
know, contribute a bit to the performance.

17:53.200 --> 17:58.280
And so, yeah, we tried this out, we actually, we had this idea for a while, but we're like,

17:58.280 --> 18:02.440
we weren't sure if it would work, we ran some tests, it looked good, and actually what

18:02.440 --> 18:06.280
was really great was that, like, while we were trying this out, someone actually published

18:06.280 --> 18:10.760
a paper showing that it worked with exactly kind of the same idea, and we were like, yay,

18:10.760 --> 18:14.320
they did, like, of course, of course, they did like much better experiments, and we could

18:14.320 --> 18:18.640
have ever done, and, you know, they really did this well, so we were like, okay, that gave

18:18.640 --> 18:20.600
us a lot of confidence.

18:20.600 --> 18:24.600
And yeah, so we actually, yeah, we just shipped that with spacey 2.1, and there are a lot

18:24.600 --> 18:28.720
of other things we also were like, you know, working on, and spacey does have like its own

18:28.720 --> 18:33.080
neural network model implementations, and we actually have kind of our own little library

18:33.080 --> 18:34.080
for that.

18:34.080 --> 18:38.640
So it is, you know, it's, we're obviously baking to keep up with what works, but it's also

18:38.640 --> 18:43.280
not like, you know, if you want to try out some deletus like model architecture by, you

18:43.280 --> 18:47.480
know, in some paper that was recently published and compare that and hack around with it, that's

18:47.480 --> 18:51.840
maybe, spacey is maybe not the best choice for that, because, you know, we give you one,

18:51.840 --> 18:55.040
the implementation once it's ready and once it's usable.

18:55.040 --> 19:02.080
And so is spacey, is it pure Python, or is it written in C, or underneath, or, yeah,

19:02.080 --> 19:04.600
so it's Python with C extensions, yeah.

19:04.600 --> 19:05.600
Okay.

19:05.600 --> 19:10.760
And the NLP stuff that you're doing, are you writing that in, Sython, are you writing

19:10.760 --> 19:16.480
that, like, are you, do you ever like popping down in the C to get speed, or is it all done

19:16.480 --> 19:17.480
in Python?

19:17.480 --> 19:22.160
I mean, it depends, like some aspects of the library were actually, you know, that, that

19:22.160 --> 19:26.080
really matters, is written in Sython, other parts, we can write in pure Python.

19:26.080 --> 19:30.120
I mean, it's kind of a nice, that's the nice thing about Sython is that you can actually

19:30.120 --> 19:36.040
write Python, but can take advantage of the C whenever you need that, and it still all

19:36.040 --> 19:40.720
looks like Python, which, you know, makes it, at least makes it a bit more approachable.

19:40.720 --> 19:43.800
It still means that, okay, maybe for some contributors, it's a bit of a barrier because

19:43.800 --> 19:50.400
it's just like, I don't know, you have to know some arbitrary stuff, many needs to be compiled,

19:50.400 --> 19:55.840
so it's maybe not as approachable as a pure Python project, but yeah, so it's, I'm

19:55.840 --> 19:58.680
not even sure, I'm not sure it's 5050, it's like probably a bit less, like the most of

19:58.680 --> 20:04.920
the models, of course, the model implementations, obviously, and Sython, then some other, you

20:04.920 --> 20:09.520
know, all the stuff that, all the objects, container objects, all that, like, kind of infrastructure

20:09.520 --> 20:13.600
that needs to be really fast, yeah, and then some Python around it.

20:13.600 --> 20:14.600
Okay.

20:14.600 --> 20:20.880
So all that familiar with, with Sython, I assume that it was Python with an underlying

20:20.880 --> 20:28.040
C implementation, but it sounds like you're a bit more exposed to the C part with Sython.

20:28.040 --> 20:32.000
If you're doing compiling and stuff like that, well, yeah, you, in the end, you compile

20:32.000 --> 20:34.840
it, but it's more like what I meant was like, okay, the syntax, like, I don't know, if

20:34.840 --> 20:38.720
you, if you look at, okay, if you, if you look at spacey source and you look at, look

20:38.720 --> 20:42.240
at the code and what it looks like, it's, you know, you'll be able to read it because it

20:42.240 --> 20:43.400
looks, it's Python.

20:43.400 --> 20:44.400
Okay.

20:44.400 --> 20:47.600
Like, the syntax is way, you know, it will look way familiar.

20:47.600 --> 20:52.000
They're just like some, you know, some little things that look a bit different.

20:52.000 --> 20:53.000
Okay.

20:53.000 --> 21:02.480
And is, is spacey as well a commercial product for explosion or is, is prodigy the first

21:02.480 --> 21:03.480
commercial product?

21:03.480 --> 21:07.240
prodigy is, prodigy is our first commercial product, and we also, it was very important

21:07.240 --> 21:11.520
to us to kind of have a clear distinction between like the open source library and how

21:11.520 --> 21:12.520
we make money.

21:12.520 --> 21:16.240
Um, I mean, at least in terms of, okay, what, you know, what you can use like spacey will

21:16.240 --> 21:20.280
always, spacey is a free library and the code we believe is always, you know, that, that's

21:20.280 --> 21:22.600
always going to be free and open source.

21:22.600 --> 21:27.520
And instead, we think that actually it's much nicer to monetize all the, you know, the

21:27.520 --> 21:28.520
space around it.

21:28.520 --> 21:32.680
Like, for example, um, you know, we can say, Hey, if you, if you power use of spacey and

21:32.680 --> 21:36.880
you really like our open source software, we have something else that, you know, you

21:36.880 --> 21:41.800
might be interested in, which our first product of, our first example of this is prodigy.

21:41.800 --> 21:45.800
So, um, you know, we, we actually think it's like, you know, there's, there's a lot of

21:45.800 --> 21:48.480
talk around like, Oh, how do you monetize open source?

21:48.480 --> 21:53.480
And we think that having a very clear separation between, okay, here's our free library.

21:53.480 --> 21:56.200
Here's our free product and here's our paid product.

21:56.200 --> 21:58.840
Um, it's actually very useful and very good.

21:58.840 --> 21:59.840
Mm-hmm.

21:59.840 --> 22:01.880
Do you also provide commercial support for spacey?

22:01.880 --> 22:02.880
No.

22:02.880 --> 22:05.360
So we've actually, that's, that's another thing.

22:05.360 --> 22:08.240
Like, you know, we, of course, it's, this is also a common, but they come in like business

22:08.240 --> 22:10.840
model and it's, it is what a lot of people do.

22:10.840 --> 22:13.560
And, um, in, you know, in some cases, it works, it actually works quite well because you

22:13.560 --> 22:17.000
can have like, you know, especially in, like, infrastructure cloud staff, there's, there's

22:17.000 --> 22:19.040
a big space for like that sort of stuff.

22:19.040 --> 22:24.040
But for us, we always felt like you end up, if you also, if you're the vendor, um, and

22:24.040 --> 22:28.360
you also like the author of, um, inner the product, uh, you often end up in this really

22:28.360 --> 22:33.040
weird situation where you want to, you want to provide like as much free support as possible.

22:33.040 --> 22:36.640
Like, you want to have really great documentation, you want to have all of, um, that stuff, because

22:36.640 --> 22:39.960
you want people using the library, but at the same time, you sort of want, you want people

22:39.960 --> 22:42.640
to pay you to help them with it.

22:42.640 --> 22:47.720
And if you, you know, if you, a software is like quite easy to use, um, well, then, you

22:47.720 --> 22:50.080
know, you're making less money because people don't actually need you.

22:50.080 --> 22:54.200
Um, if you make your dog shit, cool, people will actually come and want to pay you for,

22:54.200 --> 22:58.920
uh, providing the dogs, but then, you know, you, you're soon running out of customers because

22:58.920 --> 23:02.040
you're, you know, you're product is so shit that always going to use it.

23:02.040 --> 23:05.560
So that's, that's kind of, there's a real dilemma and it's like, to be fair, okay, machine

23:05.560 --> 23:09.160
learning, there's a lot more, actually any, you know, support wouldn't necessarily be

23:09.160 --> 23:11.480
support in terms of, hey, how do I install this?

23:11.480 --> 23:13.200
So how do I write this kind of logic?

23:13.200 --> 23:16.320
It's more like, how should I structure my, you know, P projects?

23:16.320 --> 23:18.400
So how should I do that kind of stuff?

23:18.400 --> 23:22.000
But, um, we actually think there's, you know, you can, uh, people, people say, oh, you

23:22.000 --> 23:25.120
can run lots of companies, but like, in reality, you could run one company, like, you

23:25.120 --> 23:29.400
could really only run one company and we were like, okay, the company, we run one, where

23:29.400 --> 23:34.560
we have the best, like, edge and what, you know, where we actually, you know, like, also

23:34.560 --> 23:39.880
what we enjoy doing is building developer tools, it's not running a support company.

23:39.880 --> 23:42.640
Can you talk a little bit about prodigy and the focus there?

23:42.640 --> 23:50.280
Is it, uh, specifically focused on annotation for NLP types of problems or, or textual data

23:50.280 --> 23:53.120
sets or, uh, is it broader than that?

23:53.120 --> 23:58.360
I mean, in general, I would say, um, more generally machine learning, but of course, I would

23:58.360 --> 24:02.760
like, I think our, of course, the NLP support is probably, um, the best because that's

24:02.760 --> 24:07.240
also, I mean, compared to the other, um, areas of machine learning, also just because that's

24:07.240 --> 24:08.320
what we also know best.

24:08.320 --> 24:13.080
So I would say, um, okay, maybe we have, we have a bit more, um, in there for, that's useful

24:13.080 --> 24:17.600
for NLP compared to, uh, computer vision, um, but the idea is basically, yes, it's an annotation

24:17.600 --> 24:22.080
tool for data science and machine learning and, um, it was basically inspired by us, like,

24:22.080 --> 24:25.960
you know, very early on the company for a few months, we took on some consulting projects

24:25.960 --> 24:29.520
and we saw that like one topic that always came up in every single, or everyone we

24:29.520 --> 24:35.320
talked to, um, was labeling data and also this all like, okay, you know, a lot of companies

24:35.320 --> 24:39.160
would either do it in like Excel spreadsheets or they just send it off to mechanical Turk,

24:39.160 --> 24:44.440
then they'd get it back, train a model, wouldn't work, um, people with a, yeah, we're not very

24:44.440 --> 24:45.960
happy with their workflows around that.

24:45.960 --> 24:51.680
And there was, we kind of saw a gap for like, um, actually a tool that lets the data scientists

24:51.680 --> 24:56.760
get a bit closer to that sort of data collection process because, um, if you just, a lot, if

24:56.760 --> 25:01.400
you outs, just outsource that completely, you're actually outsourcing a lot of the decisions

25:01.400 --> 25:05.840
about how your model is going to perform and what, what your model is going to do because

25:05.840 --> 25:09.720
the, you know, ultimately the labels are, uh, what you're going to predict and how your

25:09.720 --> 25:11.280
application is going to work.

25:11.280 --> 25:12.280
Right.

25:12.280 --> 25:13.280
And that's actually quite ineffective.

25:13.280 --> 25:18.000
So instead, um, what we, what we're suggesting is a much, much closer workflow, um, where

25:18.000 --> 25:23.360
the data scientists can, or the, um, developers, engineer, whatever, uh, can we bait them involved

25:23.360 --> 25:27.960
in the initial, uh, labeling process, um, SIT, you know, you can, you can write little

25:27.960 --> 25:29.800
Python scripts that queue up the work.

25:29.800 --> 25:34.040
You can try out concepts, um, much more quickly because we've built a very, very efficient,

25:34.040 --> 25:35.040
very fast interface.

25:35.040 --> 25:39.640
So let's you move through the examples quickly, um, we have some approaches where you can

25:39.640 --> 25:44.640
try and put a model in the loop and, um, instead of, you know, doing everything from scratch

25:44.640 --> 25:50.080
correcting the model's predictions and BIDs, sure, we're not saying all the data scientists

25:50.080 --> 25:55.200
just have to do it all themselves by hand, but you can actually, you know, you can label

25:55.200 --> 26:00.440
a few thousand examples in an hour and then train your model, see if your idea worked.

26:00.440 --> 26:04.080
Most likely you won't work because nothing ever works on the first try or most things.

26:04.080 --> 26:08.160
We'll never work at all in data science and that's just the reality of things.

26:08.160 --> 26:12.360
And you say, okay, you need to, you know, if you can find what fails quicker and find

26:12.360 --> 26:16.920
what succeeds quicker as well, um, you're actually going to be more successful.

26:16.920 --> 26:22.200
And that was what motivated, um, Prodigy and the way we set it up as a developer tool and

26:22.200 --> 26:24.520
not just as some like platform.

26:24.520 --> 26:30.040
It's interesting that you describe it like that as a developer tool and not just some

26:30.040 --> 26:34.160
platform, because when I think about the things that you've done, it, in my head, it sounds

26:34.160 --> 26:38.360
a lot more like a platform than a developer tool in a sense of, you know, for example,

26:38.360 --> 26:42.440
you talk about how you can put the model in a loop and I've heard Prodigy come up in

26:42.440 --> 26:48.000
a number of conversations in the context of active learning and that starts to sound

26:48.000 --> 26:53.160
to me a lot more like platform than, you know, tool like in Excel or some other kind of

26:53.160 --> 26:58.400
desktop thing that's just a lie me to like crank through a bunch of text or images and

26:58.400 --> 26:59.640
put labels next to stuff.

26:59.640 --> 27:00.640
Yeah.

27:00.640 --> 27:03.720
I mean, I think that one of the big differences as well is that like, okay, we build developer

27:03.720 --> 27:06.960
tools and all our tools are very privacy, day privacy focused.

27:06.960 --> 27:10.040
Like, you know, space you in full that you run it on your machine.

27:10.040 --> 27:14.160
Um, it's not just like some software as a service API and also it's, you know, it's

27:14.160 --> 27:19.400
just like an open source, um, and the same with, uh, Prodigy is, it's not like, you

27:19.400 --> 27:23.480
know, an open, free open source product, but it's a product and it's a library as well

27:23.480 --> 27:26.840
and you can download it, you install it on your own machine.

27:26.840 --> 27:31.080
It works completely offline and it just like runs on your hardware.

27:31.080 --> 27:34.640
And so in that sense, you know, it feels a bit more, you know, like, I was often compared

27:34.640 --> 27:39.280
to like, you know, this, remember Adobe Creative Suite before they went all cloud, you

27:39.280 --> 27:42.440
know, you could actually, you could buy Photoshop and then you would download Photoshop and

27:42.440 --> 27:43.440
then you would have it.

27:43.440 --> 27:44.440
Right.

27:44.440 --> 27:47.600
And then they wouldn't take it away from you and you could use it.

27:47.600 --> 27:52.040
And then if in two years, you pick up your design project, it's all still there because

27:52.040 --> 27:56.400
you still have Photoshop and that's also, that's kind of, that's, that's also how we see

27:56.400 --> 28:00.560
these things and that's also how Prodigy functions, at least, uh, you know, the developer tool

28:00.560 --> 28:01.560
version.

28:01.560 --> 28:02.560
Got it.

28:02.560 --> 28:03.560
And, yeah.

28:03.560 --> 28:07.600
And also because, you know, people, yeah, another thing is actually, so I'll, um, we

28:07.600 --> 28:09.720
call this let them write code.

28:09.720 --> 28:16.480
It's basically developers can program and they like to program and often instead of coming

28:16.480 --> 28:23.080
up with like very complex arbitrary configuration languages and APIs to do stuff, often the best

28:23.080 --> 28:27.040
way to configure a program or configure something that you want to do is to write a few lines

28:27.040 --> 28:28.040
of code.

28:28.040 --> 28:31.680
So, um, Prodigy can be configured fully in a Python script.

28:31.680 --> 28:36.120
So if you, you want to let load some data from some arbitrary database that you have and

28:36.120 --> 28:40.200
then like filter it that way, we're like, cool, can you write that in Python?

28:40.200 --> 28:41.200
Yes.

28:41.200 --> 28:42.200
Cool.

28:42.200 --> 28:43.200
You can use it.

28:43.200 --> 28:47.200
So, that's, that's another thing where I think the developer tool, um, angle comes in

28:47.200 --> 28:49.960
and also it's something that people actually really, really like about this.

28:49.960 --> 28:54.520
Developers generally like tools that don't lock them in and tools that they can interact

28:54.520 --> 28:58.160
with via a programming language naturally.

28:58.160 --> 29:04.640
Can you elaborate on that last, uh, example and maybe, or maybe provide an example of,

29:04.640 --> 29:10.000
you know, is this the user experience of, of Prodigy and, you know, for a given use case

29:10.000 --> 29:14.200
and what are, what's the code that you might need to write and how you might integrate

29:14.200 --> 29:15.200
a model in a loop?

29:15.200 --> 29:16.640
I had all the pieces fit together.

29:16.640 --> 29:17.640
Yeah.

29:17.640 --> 29:21.120
So, we have, um, we do have a few like built-in workflows, so it's like, you know, you can

29:21.120 --> 29:25.040
use it and maybe you never, you know, you don't often have to really write your own code

29:25.040 --> 29:30.480
from scratch, but the idea is at the center of it are recipes, we call it which are Python

29:30.480 --> 29:31.480
functions.

29:31.480 --> 29:35.360
So there are Python functions that we turn into, um, a command.

29:35.360 --> 29:40.400
So one of them could be, okay, let's say you have some raw text you want to load in and

29:40.400 --> 29:45.280
you have a pre-trend model that you've downloaded from Spacey that can predict, uh, person names.

29:45.280 --> 29:48.440
But because your text is like obviously quite specific and maybe you're working in like

29:48.440 --> 29:53.160
finance or something and it has like person names or organization names that are quite

29:53.160 --> 29:55.640
different from like some generic pre-trend model.

29:55.640 --> 30:00.320
So you're like, okay, you want to see, hmm, can I improve that pre-trend model on my data?

30:00.320 --> 30:02.080
So it performs a bit better.

30:02.080 --> 30:07.160
So you can run one of these command line scripts, you, um, load pass in the path to your data

30:07.160 --> 30:12.240
file, you pass in the pre-trend model you want to use, you pass in some labels and then

30:12.240 --> 30:17.040
you start that up and then you get the annotation interface and it will highlight a prediction

30:17.040 --> 30:22.080
from the model and you can say, yep, that's correct or you can say no, that's wrong.

30:22.080 --> 30:26.800
And what under the hood, what we do there is we load up the model and we'll get all possible

30:26.800 --> 30:33.120
predictions, um, for your, for each example and then, um, all of these, uh, possible predictions

30:33.120 --> 30:37.600
will come with a score and then we've, um, by default, we'll focus on the scores that

30:37.600 --> 30:39.320
are closest to 0.5.

30:39.320 --> 30:45.040
So the ones where, um, the model is most uncertain, um, basically so that's, that's also what's

30:45.040 --> 30:48.680
referred to us, uh, uncertainty sampling in active learning.

30:48.680 --> 30:53.480
So the idea is if we focus on the ones where like, um, the model isn't sure, that's also

30:53.480 --> 30:55.880
where you decision will have the highest impact.

30:55.880 --> 30:59.720
If you're only labeling things where the model is like super confident, that is correct.

30:59.720 --> 31:04.600
The labels and the annotations you provide have like, um, you know, the gradient from

31:04.600 --> 31:11.000
that is just less significant than if you focus on the ones, um, where the model, um, yeah,

31:11.000 --> 31:15.440
isn't sure at all whether it's like A or B or nothing or, um, and so yeah.

31:15.440 --> 31:18.640
So that's, that's one possible workflow that you could use and then, you know, that's

31:18.640 --> 31:21.800
actually super fast, you know, you're just clicking yes or no, you're focusing on one

31:21.800 --> 31:28.000
thing at a time can easily collect a few hundred annotations in like, uh, 10, 15 minutes.

31:28.000 --> 31:33.400
And then you can run a little training, uh, command, update your model and just see, um,

31:33.400 --> 31:34.440
what the results look like.

31:34.440 --> 31:37.360
They're obviously not going to be like the most, you know, they're not going to be the definitive

31:37.360 --> 31:41.880
results that you can report at the end, but they give you some idea whether what you had

31:41.880 --> 31:46.640
in mind, there is good or not, but you know, if you see that like the model is not learning

31:46.640 --> 31:51.080
anything, then you have at least some idea that like maybe, um, my idea wasn't that great

31:51.080 --> 31:53.840
or maybe it's just more difficult than I thought it would be.

31:53.840 --> 31:56.040
Or if you're like, Oh, accuracy is going up.

31:56.040 --> 31:57.040
That looks promising.

31:57.040 --> 31:58.840
I should spend a bit more time on that.

31:58.840 --> 32:06.080
One of the things I hear from folks is about the need to kind of drive repeatability

32:06.080 --> 32:15.480
into the process of collecting and labeling data and producing models does the fact that

32:15.480 --> 32:21.440
prodigies a standalone tool, get in the way of doing that or are there ways to kind of fit

32:21.440 --> 32:26.280
it into a broader pipeline or workload that allow you to establish, uh, some degree of

32:26.280 --> 32:27.840
repeatability or consistency?

32:27.840 --> 32:28.840
Yeah.

32:28.840 --> 32:31.880
No, I think, um, in the end, you know, if you, for example, if you're writing your own

32:31.880 --> 32:35.800
functions, you can actually have, you know, the script that you can, you know, you can

32:35.800 --> 32:39.400
commit your script to your GitHub repository and you have that and everyone can always,

32:39.400 --> 32:44.640
you know, reproduce the logic you use to, for example, select your examples, um, and

32:44.640 --> 32:49.640
also, I mean, another thing, um, that we think is quite important is that a lot of problems

32:49.640 --> 32:55.840
people have down the line often come down to, um, problems with, uh, you know, the label

32:55.840 --> 32:58.840
scheme and how the task is defined in the first place.

32:58.840 --> 33:03.360
Um, so, uh, you know, often you're like, Oh, I want a label like, you know, I want my

33:03.360 --> 33:04.360
model to predict this.

33:04.360 --> 33:09.480
So my system needs to do X and often people approach this from the very end to end viewpoint

33:09.480 --> 33:14.040
and often that's not necessarily with the one that like, uh, works best on any label scheme,

33:14.040 --> 33:17.520
any, anything, you know, basically defining what you want your model to predict often

33:17.520 --> 33:19.120
needs lots of iterations.

33:19.120 --> 33:23.200
And once you, you know, once you get that right, you're often, um, that's where it really

33:23.200 --> 33:24.200
starts working.

33:24.200 --> 33:27.520
Is there a specific example of that, uh, that comes to mind?

33:27.520 --> 33:31.960
Um, so for example, I mean, one, um, one thing we see a lot is that like people, people

33:31.960 --> 33:36.480
often start, you know, a machine or a data science project often starts with like, um,

33:36.480 --> 33:40.720
you know, so a defined set of categories that you want to, uh, for example, uh, categorize

33:40.720 --> 33:45.760
your text into so you might have like something like, you know, um, different type, different

33:45.760 --> 33:50.560
types of clothing, for example, and you want to, you know, extract, uh, that from like,

33:50.560 --> 33:52.120
your customer emails.

33:52.120 --> 33:55.400
And so you have like, you know, you start, the data scientist starts off with like a very

33:55.400 --> 34:01.000
broad catalog of like every type of clothing we offer and every type of clothing that

34:01.000 --> 34:02.480
like the system needs to categorize.

34:02.480 --> 34:07.520
And then often, you know, one approach could be, okay, well, we need to take a few million

34:07.520 --> 34:13.600
examples or, you know, emails and have someone label them and select out of our, um, hundreds

34:13.600 --> 34:17.280
of clothing types, what clothing types are mentioned.

34:17.280 --> 34:21.400
And I mean, it sounds like a very straightforward approach, but often probably, you know, at

34:21.400 --> 34:24.200
some point down the line, you'll notice that like your machine learning model is actually

34:24.200 --> 34:30.800
really, really bad at distinguishing adult shoes from kids shoes, uh, for example, in,

34:30.800 --> 34:36.760
you know, like brand names or, um, you know, summer code and winter codes, you know, that's

34:36.760 --> 34:37.760
something.

34:37.760 --> 34:41.200
Maybe, maybe you can, you know, but like that's probably something that's very quite,

34:41.200 --> 34:45.680
that could be quite difficult to predict just on the basis of like the raw text and the

34:45.680 --> 34:47.560
surrounding words.

34:47.560 --> 34:51.840
So, you know, one, one approach that you could then after, you know, you try this out,

34:51.840 --> 34:53.720
you realize our model's not learning anything.

34:53.720 --> 34:56.200
And then, you're like, okay, how could I improve that?

34:56.200 --> 34:59.680
One approach could be, you start with a bunch more broader definition.

34:59.680 --> 35:04.840
You start, okay, first, I'll let my model label whether something is clothing, you know,

35:04.840 --> 35:09.400
you can start, okay, start collecting some data for that, um, and then train it.

35:09.400 --> 35:11.200
Okay, actually looks pretty good.

35:11.200 --> 35:12.200
Um, next step.

35:12.200 --> 35:18.320
Okay, maybe we can add another model component that then given a clothing, um, item or clothing

35:18.320 --> 35:23.280
brand can then, um, you know, assign it to one of our, um, you know, entries in a knowledge

35:23.280 --> 35:26.680
base or to a more fine grained, uh, category and so on.

35:26.680 --> 35:30.320
Like, that's just one, one example that just came, that came to mind based.

35:30.320 --> 35:32.920
And in the end, you know, that, that, that stuff really matters.

35:32.920 --> 35:37.640
Like, you know, you end up at the same results, but, um, the process, how you work there

35:37.640 --> 35:38.960
is very, very different.

35:38.960 --> 35:44.000
And it takes, it can easily take a few iterations, uh, to get to the point, uh, where you,

35:44.000 --> 35:48.960
you kind of, you have a good idea for what, what can my model learn and, um, what's actually

35:48.960 --> 35:53.800
feasible and what machine learning tasks do I have to break this larger, they abstract

35:53.800 --> 35:55.320
business goal into?

35:55.320 --> 36:02.880
I'm curious, what are some of the thing, you know, the, the NLP space as, with all of, uh,

36:02.880 --> 36:06.920
machine learning is, you know, changes rapidly, lots of exciting stuff happening.

36:06.920 --> 36:11.600
We talked about, uh, some of that in terms of these new language models.

36:11.600 --> 36:16.080
I'm curious, what are you most excited about in this space?

36:16.080 --> 36:20.960
Um, so definitely, I mean, the transfer learning stuff was definitely like a big, um, breakthrough

36:20.960 --> 36:23.760
because we've always, for quite a long time, we're like, okay, this should, this should

36:23.760 --> 36:27.600
be possible and, um, it was kind of, you know, I think for, for many people in the space,

36:27.600 --> 36:30.840
it was kind of clear, like, okay, at some point, hopefully someone's going to show here's

36:30.840 --> 36:32.640
how we should do it.

36:32.640 --> 36:37.600
And, um, especially the fact that like, um, you know, we can potentially pre-trained, um,

36:37.600 --> 36:42.120
embeddings that would, um, allow us to get much, much better results, much more quickly

36:42.120 --> 36:45.480
with, um, significant fewer examples.

36:45.480 --> 36:49.480
And that doesn't mean that like, um, you know, labeling examples becomes less relevant,

36:49.480 --> 36:53.440
actually, um, you know, I think it, it means it, you know, you can try out more and

36:53.440 --> 36:57.960
it becomes a lot more relevant because, um, you know, cool, if you only need like 200 labeled

36:57.960 --> 37:02.920
examples to really get a, um, very definitive idea of whether, um, what you're trying to train

37:02.920 --> 37:06.600
works or not, that means you can like, you know, you can train much more, more quickly

37:06.600 --> 37:11.520
and you can train so many more models, so much faster, um, you can try out so many more

37:11.520 --> 37:12.520
ideas.

37:12.520 --> 37:15.440
Um, and I think, I think that's like, that's super exciting.

37:15.440 --> 37:19.000
And, um, yeah, it's really cool to see this already working quite well.

37:19.000 --> 37:24.080
Is there other things happening that are, that you're particularly paying attention to?

37:24.080 --> 37:29.920
Mm, let me think, um, so I mean, one, one thing we, like, I can, I can talk about one

37:29.920 --> 37:33.920
thing we're working on at the moment is entity linking, which I also think is really

37:33.920 --> 37:34.920
cool.

37:34.920 --> 37:38.720
So basically, you know, the concept of you have like a person name and you want to link

37:38.720 --> 37:40.560
that back to a knowledge base.

37:40.560 --> 37:44.400
And it sounds, um, you know, the kind of concept sounds, sounds quite simple, but it's

37:44.400 --> 37:46.960
actually, you know, there's a lot you have to consider and you actually, you know, you

37:46.960 --> 37:52.440
want to, you have a mention of, um, Apple or like, actually, I'm trying to think of it

37:52.440 --> 37:56.120
better, like more, um, you know, ambiguous example, but like there are a lot of these,

37:56.120 --> 37:59.960
like names and their different options, it depends on the context and, you know, you

37:59.960 --> 38:02.160
want to assign those back to large knowledge bases.

38:02.160 --> 38:07.360
Yeah, that's a feature, um, that's, yeah, maybe not as like, oh, shiny, um, new cutting

38:07.360 --> 38:11.320
edge stuff, but it's actually another one that like people really need, people really

38:11.320 --> 38:17.080
want, and that's going to make a huge difference for people using NLP, uh, for variety of like

38:17.080 --> 38:19.080
business use cases and industry use cases.

38:19.080 --> 38:24.800
A feature like that is, are you typically or not typically, but in this case, are you

38:24.800 --> 38:31.000
attacking that using traditional rules based or heuristic types of approaches or machine

38:31.000 --> 38:36.000
learning or neural nets, like we're in a spectrum, uh, you know, what, which of the tools

38:36.000 --> 38:39.360
do you use to, you know, build out a feature like that?

38:39.360 --> 38:43.320
Um, I mean, well, it depends on the feature, like, um, you know, in this case, it's, it

38:43.320 --> 38:48.400
is a combination of machine learning and, um, kind of, uh, kind of ties in, uh, with

38:48.400 --> 38:52.200
the rule based approaches, it also ties in with like the neural network models we already

38:52.200 --> 38:56.640
have, uh, which are the models that actually predict entities in the first place.

38:56.640 --> 39:03.080
Um, so, I mean, it really, like, it always depends on the, um, on the use case, but like,

39:03.080 --> 39:08.120
what, you know, for us, what matters is, well, what works best and what's, what's fast,

39:08.120 --> 39:14.520
what's efficient and what actually, um, works best, what generalizes best and what's, um,

39:14.520 --> 39:17.960
customizable because, you know, ultimately, it's nice if you can provide people with

39:17.960 --> 39:22.760
a pre-train model that happens to work quite nicely on, you know, some academic benchmark

39:22.760 --> 39:27.360
task, but what people really want to do is they want to plug in their own data and they

39:27.360 --> 39:30.880
want to plug in their own stuff and they want to plug in their own, like ideas and, uh,

39:30.880 --> 39:31.880
goals.

39:31.880 --> 39:35.080
And so that, that's also kind of how we decide how to approach a thing.

39:35.080 --> 39:38.760
Like, you know, we're not, we're in, you know, we're not in position where we have to,

39:38.760 --> 39:41.520
you know, come up with like, what's, what's a good paper to write?

39:41.520 --> 39:45.120
Like, that's, you know, that's another way, um, and I'm not even, you know, dismissing

39:45.120 --> 39:46.120
that.

39:46.120 --> 39:50.160
That's a very like, um, you know, genuine, like, um, you know, valid motivation that

39:50.160 --> 39:54.320
people in research would have, but what's, you know, good papers, not necessarily what

39:54.320 --> 40:00.360
like, you know, people actually will find like the most useful as a, in a practical application.

40:00.360 --> 40:06.880
If you were starting over with spacey or they're things that you do very differently.

40:06.880 --> 40:09.280
Oh, that's, that's a really good question, actually.

40:09.280 --> 40:11.880
I'm not, I'm not sure if I thought about this much.

40:11.880 --> 40:17.400
I mean, they're just, they obviously some API decisions that like, um, uh, I would have,

40:17.400 --> 40:22.040
I would have done differently or we, we should have, we would have probably, um, done

40:22.040 --> 40:23.040
differently.

40:23.040 --> 40:25.960
Just like, I mean, it's mostly just like small, small stuff where, you know, you design

40:25.960 --> 40:29.080
something one way and then you realize, ah, that's actually super, that's kind of confusing

40:29.080 --> 40:34.040
or like, kind of taking on this life of its own and sensor on, doesn't send a right message,

40:34.040 --> 40:36.520
um, math, we should have done this differently.

40:36.520 --> 40:40.120
Otherwise, you know, it, of course, it depends on like, it always depends on, okay, what

40:40.120 --> 40:45.960
you have like available and, you know, what was like possible at the time.

40:45.960 --> 40:49.560
But actually, I think I'm quite happy with like, you know, the progression, like sure,

40:49.560 --> 40:53.360
there's sometimes I wish like, you know, we would have had like more time, uh, that we

40:53.360 --> 40:57.920
could have like, you know, spend on the project, uh, to work on that because, okay, you

40:57.920 --> 41:01.000
know, it was very important for us to stay independent and be independent.

41:01.000 --> 41:05.680
And so, um, you know, while we were like initially, like bootstrapping the company, um,

41:05.680 --> 41:11.480
yeah, we had a bit less time, um, but yeah, like in hindsight, like, I'm very happy with

41:11.480 --> 41:18.720
how things turned out and, um, yeah, um, on that theme of independence and you previously

41:18.720 --> 41:25.520
mentioned that you intend for, uh, explosion to remain a small company.

41:25.520 --> 41:34.160
We talk a little bit about that, uh, and your motivation or philosophy there and, um, you

41:34.160 --> 41:39.640
know, maybe, you know, any thoughts for folks that are also interested in kind of contributing

41:39.640 --> 41:45.680
in the space, um, you know, but aren't necessarily excited about doing in the context of a large

41:45.680 --> 41:46.680
company.

41:46.680 --> 41:47.680
Yeah.

41:47.680 --> 41:50.960
I mean, for us, like we've, um, basically, I mean, you already, you already see this in

41:50.960 --> 41:54.520
all kinds of other software projects that like most, a little software is actually written

41:54.520 --> 41:58.440
by a very, very small number of people, like even if you look at very large, like libraries,

41:58.440 --> 42:02.320
it's, um, you know, it's not like, you know, thousands of people kind of wrote on, you

42:02.320 --> 42:04.160
know, worked on the same piece of code.

42:04.160 --> 42:08.800
Um, it's like often development teams are very small and like for a reason because, you

42:08.800 --> 42:11.880
know, it's like, you know, writing a novel with like 200 people.

42:11.880 --> 42:15.280
That's like, you know, that's a fun art project, but that's not, that's not necessarily

42:15.280 --> 42:18.600
like, you know, that's not going to be the best novel, you know, right?

42:18.600 --> 42:23.720
So, um, you know, software teams, I often by definition are quite small.

42:23.720 --> 42:27.640
And, um, another thing is that actually by being quite small, you can really take a lot

42:27.640 --> 42:33.320
of advantage of, um, you know, very diverse skill sets that, that large companies can't

42:33.320 --> 42:34.320
necessarily.

42:34.320 --> 42:37.800
So, you know, large companies often hire in a very particular way, um, because you have

42:37.800 --> 42:40.480
to hire in a way that makes your team more interchangeable.

42:40.480 --> 42:44.480
Like you, you know, you need, you need a lot of people that are quite similar because,

42:44.480 --> 42:48.920
you know, if you're scaling this up, um, that's kind of the most efficient, but if you,

42:48.920 --> 42:54.080
a small team, you can actually, um, you know, hire a lot of people with way, um, specific

42:54.080 --> 42:57.880
skills that work for, um, you know, specific tasks, then you can have people with kind of

42:57.880 --> 43:03.200
overlapping skills, people with a broad foundation in one, um, technology, but who also have

43:03.200 --> 43:07.960
done like other things, like it's typically, it's often referred to as t-shaped skills

43:07.960 --> 43:09.400
because, you know, kind of like a t-shirt.

43:09.400 --> 43:13.160
So, you have like, I've always found these a super weird metaphor because like, it's

43:13.160 --> 43:17.240
a t-shirt, but like, you know, you're brought kind of a broad foundation and then like

43:17.240 --> 43:22.600
these like arms, but, um, I've, I've started calling it more like, you know, I think of it

43:22.600 --> 43:26.640
more as like tree-shaped skills, you know, you have like the stem and then you have all

43:26.640 --> 43:30.680
these like branches and you can have like, um, you know, you can have small branches, you

43:30.680 --> 43:34.800
can have big branches, you can have like different branches and different directions, branches

43:34.800 --> 43:39.640
can overlap overlap with like some other tree, you can grow new branches, which actually

43:39.640 --> 43:43.080
this is another reason like, yeah, I hate the t-shirt metaphor because it's like a t-shirt

43:43.080 --> 43:48.520
that can only like get worse once it's like there for a tree, you know, a tree can grow,

43:48.520 --> 43:52.000
this is like life in it, but basically that's sort of, that's the idea we've had like,

43:52.000 --> 43:58.160
um, for our team, we can actually, you know, really have like, um, you know, complimentary

43:58.160 --> 44:03.840
skills, um, in a team, um, and you know, really take advantage of that and it's not like,

44:03.840 --> 44:06.720
you know, it's not like large companies are not doing that because they're like stupid

44:06.720 --> 44:11.440
and don't see this, they like, aren't because of, you know, they operate slightly differently.

44:11.440 --> 44:17.400
So, um, yeah, like we don't, we are small, but we're still, you know, we can still do things

44:17.400 --> 44:20.920
and it's still, I, yeah, there's one anecdote that like I sometimes tell in this kind of

44:20.920 --> 44:26.920
context, which is, um, once we were asked, um, whether our company would pass the bus test

44:26.920 --> 44:31.640
because for someone who wanted to buy our software, this was like, um, this was important

44:31.640 --> 44:35.120
and yeah, to, yeah, if someone, yeah, for anyone who doesn't know what the bus test is,

44:35.120 --> 44:39.000
it's like, it's a varying number of people, but it's basically if four people were run

44:39.000 --> 44:42.840
over by a bus tomorrow, would your company still exist? And at that time, we were like

44:42.840 --> 44:48.480
two people were like, no, we'd be minus two. But it's also, it's a very weird concept.

44:48.480 --> 44:53.800
The person ended up buying prodigy anyways, but like, um, it's, it's an interesting framework

44:53.800 --> 44:57.280
that some people use and I don't think makes much sense because essentially you're always

44:57.280 --> 45:01.320
asking like, well, how interchangeable are like your people and, um, you know, who could

45:01.320 --> 45:05.640
you afford to like spare in a bus accident? Mm-hmm. And yeah, yeah, so we, I've always

45:05.640 --> 45:09.920
find this kind of weird and like we don't pass, we probably do not pass the bus test. Um,

45:09.920 --> 45:14.680
we kind of pass it now, but like, we'd be in a pretty bad state. And interesting anecdote

45:14.680 --> 45:21.680
along those lines, I was just this morning reading, uh, an article about, uh, long story

45:21.680 --> 45:28.600
this lawsuit that, uh, hurts is apparently suing Accenture for botching this, uh, digital

45:28.600 --> 45:35.360
transformation project. It was going around on Twitter. And if you read the, as a $35 million

45:35.360 --> 45:41.320
project to build some websites, uh, that kind of integrates into, uh, their reservation

45:41.320 --> 45:48.360
systems, kind of, you know, update their website. Uh, and you read the lawsuit and all of

45:48.360 --> 45:52.880
the things that, you know, could have been done so much better on, on both sides, but,

45:52.880 --> 45:57.280
you know, in particular, there's this one point where they talked about how kind of Accenture

45:57.280 --> 46:03.040
had full ownership of this project. And there were two people that knew the project and

46:03.040 --> 46:06.840
they pulled them off and put them onto something else. And that was one of the reasons why this

46:06.840 --> 46:11.360
thing got delayed by two years and never got finished. Yeah. And then, I mean, they built

46:11.360 --> 46:16.000
a website. There wasn't responsive and like everything was, we were so insecure. It

46:16.000 --> 46:19.920
was like unusable when like, wow, that's like, that's almost, that's a skill. Like, you

46:19.920 --> 46:23.960
know, it's, you can build so much stuff nowadays that like works okay, even if it's kind

46:23.960 --> 46:29.840
of crap. So there's so many lessons there, but the thing that, that connected to what

46:29.840 --> 46:34.160
you were speaking was, you know, even Accenture, you know, in this case, couldn't pass the

46:34.160 --> 46:40.000
bus tests. Yeah. Hold these two people off. And, you know, that was a significant contributor

46:40.000 --> 46:46.880
to the failure of this project. So, yeah. So I think it's a very bizarre metric. And yeah,

46:46.880 --> 46:49.920
so that was one of the things we saw this early on. We're like, well, we could, you know,

46:49.920 --> 46:53.200
we already do it. We were already doing great stuff when we're two people. Okay. If we

46:53.200 --> 46:56.640
have a few more people and they're the right people, we can do even more stuff. And that's

46:56.640 --> 47:01.040
like fine, we also get to, you know, focus a lot more on the core work because we have fewer

47:01.040 --> 47:05.440
distractions that, you know, you'd normally have if you, you know, not like a few, for example,

47:05.440 --> 47:09.120
if you're running at a loss, which is also something we said, okay, we don't want to be doing

47:09.120 --> 47:13.920
we actually, because I think, you know, for there are many legitimate reasons why your company

47:13.920 --> 47:18.640
would want to start and run at a loss or at a significant loss fairly on and why you would

47:18.640 --> 47:23.040
have to, you know, where you need capital and why you would have to make the decision to sell

47:23.040 --> 47:27.920
equity in order to function. But we're always in a, you know, very good position that we didn't

47:27.920 --> 47:33.680
have to do that. And so also we thought, okay, for what we're doing, there's absolutely no logical

47:33.680 --> 47:38.880
reason we would have to be running at a loss. We can actually run at a profit because we can have

47:38.880 --> 47:44.240
a product and people can buy our product. And then, yeah, we can sell more products and we can

47:44.240 --> 47:48.560
make more products and do more things. And then people can, you know, give us money and then we

47:48.560 --> 47:53.200
can spend less money than that. And then we'll have some money. It's kind of, it's a very crazy

47:53.200 --> 47:58.800
concept, but like, you know, it works. Virtua cycle. Yeah. Yeah. So, so that was, that was another

47:59.600 --> 48:06.080
thing that really helped us, you know, stay focused and do our things and also being able to really,

48:06.080 --> 48:11.040
you know, it's one thing you can validate your ideas. Like, by, I don't know, talking to people,

48:11.040 --> 48:16.480
doing like surveys and doing like all kinds of things, but like in the end, making a profit and

48:16.480 --> 48:20.960
making money is like a very, very good way to validate what you're doing. And it's also a very

48:20.960 --> 48:24.960
honest way of validate. Like, you know, you, money doesn't really lie. Like, if nobody wants to buy

48:24.960 --> 48:28.560
your product, then well, nobody wants to buy your product. And then, you know, that's, that's a

48:28.560 --> 48:34.560
pre-clear sign. And on the other hand, okay, if you, if you see cool, what I'm doing works, people

48:34.560 --> 48:39.040
like it so far, people are interested in buying that. That's a very good, you know, that's a very

48:39.040 --> 48:45.600
good way to validate your ideas. And yeah, yeah, so it's like, you know, we see this, that's,

48:45.600 --> 48:50.240
that's a much better KPI than a lot of other things. Well, you know, thank you so much for

48:50.240 --> 48:56.960
taking the time to share what you're up to is great getting to know you and explosion and

48:57.520 --> 49:02.720
spacey and prodigy a little bit better. I really enjoyed our chat. Yeah, thanks.

49:06.560 --> 49:11.280
All right, everyone. That's our show for today. If you like what you've heard here,

49:11.280 --> 49:16.400
please do us a huge favor and tell your friends about the show. And if you haven't already

49:16.400 --> 49:21.280
hit that subscribe button yourself, make sure you do so you don't miss any of the great episodes

49:21.280 --> 49:42.320
we've got in store for you. As always, thanks so much for listening and catch you next time.

