WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:32.240
I'm your host Sam Charrington.

00:32.240 --> 00:36.980
If you missed our last show and if you did you definitely want to go check it out because

00:36.980 --> 00:42.340
it was a great conversation but if you missed that show you missed the first of the many

00:42.340 --> 00:45.760
exciting updates we have for you this summer.

00:45.760 --> 00:50.720
Last time we announced Twimble's third birthday and our 5 millionth download which happened

00:50.720 --> 00:53.080
right around the same time.

00:53.080 --> 00:58.320
To help us celebrate this occasion and to request your commemorative Twimble birthday sticker

00:58.320 --> 01:02.840
visit twimbleai.com slash birthday 3.

01:02.840 --> 01:09.280
This week we're continuing the action by kicking off volume 2 of our AI platform series.

01:09.280 --> 01:14.440
You recall that last fall we brought you AI platform's volume 1 featuring conversations

01:14.440 --> 01:21.420
with platform builders from Facebook, Airbnb, LinkedIn, OpenAI, Shell and Comcast.

01:21.420 --> 01:27.620
This series turned out to be one of our most popular series of shows ever and over 1000

01:27.620 --> 01:33.040
of you downloaded our first ebook on machine learning platforms, Kubernetes for machine

01:33.040 --> 01:35.920
learning, deep learning and AI.

01:35.920 --> 01:41.280
Well we'll be back at it over the next few weeks sharing more experiences from teams working

01:41.280 --> 01:46.880
to scale and industrialize data science and machine learning at their companies.

01:46.880 --> 01:51.320
And we've got even more in store on this topic so if it's an area you're interested

01:51.320 --> 01:53.880
in be sure to stay tuned.

01:53.880 --> 02:00.760
You can follow along with the series at twimbleai.com slash AI platforms 2 and by following us on

02:00.760 --> 02:07.720
Twitter at at Sam Charrington and at Twimbleai.

02:07.720 --> 02:12.800
Before we dive in, I'd like to send a giant thanks to our friends over at Sigopt.

02:12.800 --> 02:16.960
They've been huge supporters of my work in this area and I'm really excited to have them

02:16.960 --> 02:21.840
as a sponsor of this series of shows on machine learning and AI platforms.

02:21.840 --> 02:27.640
If you don't know Sigopt, I spoke with their CEO Scott Clark back on show number 50.

02:27.640 --> 02:31.480
Their software is used by enterprise teams to standardize and scale machine learning

02:31.480 --> 02:37.680
experimentation and optimization across any combination of modeling frameworks, libraries,

02:37.680 --> 02:40.560
computing infrastructure and environment.

02:40.560 --> 02:45.680
Teams like 2 Sigma who will hear from later in this series rely on Sigopt software to

02:45.680 --> 02:50.520
realize better modeling results much faster than previously possible.

02:50.520 --> 02:56.000
Of course to fully grasp the potential of a tool like Sigopt is best to try it yourself.

02:56.000 --> 03:01.280
That's why Sigopt is offering you the twimble community an exclusive opportunity to try

03:01.280 --> 03:06.280
their product on some of your toughest modeling problems for free.

03:06.280 --> 03:13.280
Take advantage of this offer, visit twimbleai.com slash Sigopt.

03:13.280 --> 03:16.160
All right, everyone.

03:16.160 --> 03:23.160
I am here in Montreal for the NERB's conference and I am with Alex Ratner, Alex as a PhD student

03:23.160 --> 03:24.160
at Stanford.

03:24.160 --> 03:26.640
Alex, welcome to this week in machine learning and AI.

03:26.640 --> 03:28.400
Thank you so much for having me.

03:28.400 --> 03:29.400
Awesome.

03:29.400 --> 03:32.880
We're going to talk a bit about one of the projects you're working on at Stanford, a project

03:32.880 --> 03:34.440
called Snorkel.

03:34.440 --> 03:38.240
Before we do, I'd love to hear a bit about your background and how you got started working

03:38.240 --> 03:39.240
in ML.

03:39.240 --> 03:40.240
Great.

03:40.240 --> 03:44.960
So like many at the NERB's conference, I was a reformed physicist for my undergrad days.

03:44.960 --> 03:49.360
Went out, financed for a bit and then crawled my way back in academia where I've been for

03:49.360 --> 03:53.800
the past four plus wonderful years at Stanford where there's a ton of exciting stuff going

03:53.800 --> 03:58.440
on and that kind of led to the current work which I guess we'll talk about today around

03:58.440 --> 04:00.280
a system called Snorkel.

04:00.280 --> 04:01.280
It's also about the system.

04:01.280 --> 04:03.360
What is Snorkel trying to do?

04:03.360 --> 04:07.640
So the idea that Snorkel's predicated on is that one of the biggest bottlenecks that

04:07.640 --> 04:13.720
people face right now in the current era of these highly automated deep learning algorithms

04:13.720 --> 04:16.920
is getting sufficient amounts of labeled training data.

04:16.920 --> 04:21.360
So if you want to train one of these, especially here at NERB's, if you want to train one of

04:21.360 --> 04:26.440
these fancy architectures, a lot of them require very, very complex.

04:26.440 --> 04:31.000
They do a lot of stuff like picking out all the features to look at and taking in the

04:31.000 --> 04:33.000
raw data and transforming it properly.

04:33.000 --> 04:36.440
They do this automatically, but this of course comes at a cost which is that they generally

04:36.440 --> 04:39.920
need lots of training data to learn from.

04:39.920 --> 04:44.480
And this training data often needs to be labeled by people who have some kind of domain

04:44.480 --> 04:45.480
expertise.

04:45.480 --> 04:50.800
So if you want to train a model to outperform a radiologist at some mammography task for

04:50.800 --> 04:56.520
example where there are some narrow results on things like these, you need months and

04:56.520 --> 05:01.880
months and months of or longer of radiologists sitting there labeling data.

05:01.880 --> 05:05.680
So this has become a significant capital expenditure for big companies.

05:05.680 --> 05:11.320
It's become a significant bottleneck for people like scientists or clinicians from actually

05:11.320 --> 05:14.000
applying these awesome new ML techniques.

05:14.000 --> 05:19.160
And so the question with Snorkel that we tried to address was, can we enable subject matter

05:19.160 --> 05:26.280
expert users to give kind of higher level inputs, things like rules or patterns or noisy

05:26.280 --> 05:30.680
signals from other models that they have lying around and use this to train up and leverage

05:30.680 --> 05:34.440
these awesome new machine learning models that are out there.

05:34.440 --> 05:35.440
Okay.

05:35.440 --> 05:41.200
I'm intrigued by this idea of allowing subject matter experts to work kind of in the domain

05:41.200 --> 05:48.040
of rules that their expertise, I often characterize one of the things I see in this space is kind

05:48.040 --> 05:55.040
of this swing from model based approaches to machine learning or to systems more broadly

05:55.040 --> 06:01.000
to kind of these purely statistical based approaches that have no, they don't really

06:01.000 --> 06:07.800
attempt to capture subject matter expertise and it sounds like Snorkel is part of a bit

06:07.800 --> 06:11.880
of the pendulum returning to the center which is trying to incorporate in some of this domain

06:11.880 --> 06:12.880
expertise.

06:12.880 --> 06:14.680
Yeah, I think that's a great way of putting it.

06:14.680 --> 06:18.960
I mean, this is, this is really an age old question in, you know, the field of AI more

06:18.960 --> 06:24.720
broadly is how do you inject domain expert knowledge into a system and, you know, ever

06:24.720 --> 06:29.680
since statistical learning techniques have become so powerful and useful in some areas,

06:29.680 --> 06:33.000
how do you inject this domain knowledge into them, right?

06:33.000 --> 06:34.000
Right.

06:34.000 --> 06:37.000
And, you know, more broadly than Snorkel, you can see this pendulum beginning to swing

06:37.000 --> 06:40.760
back a little bit when you go look around the poster session here at Nareps, you know,

06:40.760 --> 06:47.160
there's definitely more work out there around explicitly defined, say, generative models

06:47.160 --> 06:51.200
where, you know, someone has set some explicit structure rather than just learning all that

06:51.200 --> 06:54.040
structure from data.

06:54.040 --> 06:59.360
And, you know, Snorkel is definitely fitting into that narrative in that we're trying to

06:59.360 --> 07:04.200
bridge the gap between the two, we're trying to use domain expert knowledge that is,

07:04.200 --> 07:06.960
you know, expressed in a really simple way.

07:06.960 --> 07:11.040
We have experts or, you know, we have, you know, whether they're clinicians or journalists

07:11.040 --> 07:17.360
or, you know, whoever these subject matter experts are, they write what we call labeling functions.

07:17.360 --> 07:21.680
So just simple little functions that, you know, could express a pattern or a rule or they

07:21.680 --> 07:26.000
could call some other classifier and they just take a data point and say, you know, say

07:26.000 --> 07:29.800
it's a binary classification problem, yes, no, or I don't know, that's all.

07:29.800 --> 07:33.360
And they just, they can be Python functions, whatever they are, they just dump them into

07:33.360 --> 07:34.360
the system.

07:34.360 --> 07:35.360
Okay.

07:35.360 --> 07:37.760
And then we try to use that to take advantage of these statistical models.

07:37.760 --> 07:43.240
So we're trying to kind of bridge the two worlds via this very simple conduit of training

07:43.240 --> 07:44.240
data.

07:44.240 --> 07:49.960
Well, before we get too deep into Snorkel and how it works, it's a successor to an earlier

07:49.960 --> 07:51.840
project called Deep Dive.

07:51.840 --> 07:59.560
There's a clear theme that I hear somebody likes to swim or dive or snorkel or something.

07:59.560 --> 08:06.200
But maybe tell us a little bit about Deep Dive and its origins and trajectory.

08:06.200 --> 08:11.520
Deep Dive, like many, you know, great initiatives and computer science these days, it was kind

08:11.520 --> 08:17.440
of, in large part, based on or based around this big DARPA project, one that's still ongoing

08:17.440 --> 08:21.040
that actually snorkels being used in right now called Memic. So it's this big project

08:21.040 --> 08:24.280
that is run by DARPA around anti-human trafficking.

08:24.280 --> 08:25.280
Okay.

08:25.280 --> 08:28.120
And it's had actually, it's actually in, you know, the hands of law enforcement and making

08:28.120 --> 08:29.920
a really big impact.

08:29.920 --> 08:30.920
And the problem.

08:30.920 --> 08:34.120
So I'm familiar with like the DARPA, like the autonomous vehicles challenge and some

08:34.120 --> 08:36.000
of the others, I'm not familiar with Memic.

08:36.000 --> 08:37.000
So.

08:37.000 --> 08:38.000
Yeah, yeah.

08:38.000 --> 08:44.480
So the Memic challenge, brother has been focused on kind of targeted search trying to extract

08:44.480 --> 08:50.000
information from the dark web and use it to actually aid law enforcement and identifying

08:50.000 --> 08:54.200
individuals that are potentially being trafficked and interceding.

08:54.200 --> 08:59.320
So it's really an incredible project and there's a lot of teams, you know, across both

08:59.320 --> 09:01.080
academia and industry that have contributed.

09:01.080 --> 09:07.840
I know, you know, I wasn't so directly involved, but in our lab, Deep Dive had contributed

09:07.840 --> 09:13.400
around trying to map from what we sometimes call dark data or unstructured data.

09:13.400 --> 09:17.600
So things like websites and just this kind of messy data that's really tough for computers

09:17.600 --> 09:21.920
to deal with and actually pull out structured stuff like imagine pulling out an Excel spreadsheet

09:21.920 --> 09:27.600
with well-defined columns or a graph of entities and their relations from this messy unstructured

09:27.600 --> 09:28.600
data.

09:28.600 --> 09:32.280
And that's a really tough problem that machine learning often does really well at.

09:32.280 --> 09:36.560
But you know, when we tried to do this, it wasn't the, you know, lacking a fancy model

09:36.560 --> 09:37.560
architecture to do this.

09:37.560 --> 09:43.440
So it was really needing training data and, you know, asking, you know, people to look

09:43.440 --> 09:48.600
at these terrible websites for, you know, weeks or months on end to label a training set

09:48.600 --> 09:52.120
and then find out that actually one week later, we don't need that training set anymore.

09:52.120 --> 09:53.120
We need a different training set.

09:53.120 --> 09:54.920
So throw it out and start over again.

09:54.920 --> 09:58.800
You know, that, and this was somewhat surprising because, you know, we had been working on

09:58.800 --> 10:02.400
all these fancy modeling and inference improvements.

10:02.400 --> 10:07.480
That ends up being in that and many other projects that the biggest pain point, the biggest

10:07.480 --> 10:12.600
blocker, right, like when we started moving into snorkel, we would sit down with clinicians

10:12.600 --> 10:16.720
from the Stanford hospital system and, you know, we would be really eager to tell them

10:16.720 --> 10:20.320
about our new fancy model and they'd say, wait, hold up, you know, you said something

10:20.320 --> 10:22.040
about I have to have a large label training set.

10:22.040 --> 10:24.600
I don't have months to sit down and do that.

10:24.600 --> 10:25.600
What gives?

10:25.600 --> 10:27.120
Like, you know, what do I do?

10:27.120 --> 10:33.480
So we realized that all these incredible advances in the models and how they, how easy to

10:33.480 --> 10:38.320
use they were, were coming about in this wave over the last couple of years, but everyone

10:38.320 --> 10:42.040
was blocked on this first step of getting training data for them, right?

10:42.040 --> 10:46.600
You know, and people ignored this for a long time because you had things like ImageNet,

10:46.600 --> 10:50.320
which was a really, you know, incredible resource that jump started.

10:50.320 --> 10:54.320
That and other data sets jump started this, this current, you know, wave of deep learning

10:54.320 --> 10:59.120
progress took several years to create, you know, I know my advisor, Chris was involved

10:59.120 --> 11:03.680
a little bit, you know, downstairs from us was where a lot of this happened.

11:03.680 --> 11:07.720
If you're working on that, that's great, but then you want to take the models that are

11:07.720 --> 11:10.760
doing, you know, you want to take that incredible progress and you want to translate it into

11:10.760 --> 11:14.600
a real world problem where there's no labeled benchmark training set.

11:14.600 --> 11:15.600
It's a huge problem.

11:15.600 --> 11:21.080
So we sort of shifted gears a little bit, you know, deep dive went out into the world

11:21.080 --> 11:27.440
and then, you know, we decided with this new project snorkel to really tackle this problem

11:27.440 --> 11:31.880
of creating training data and rather than viewing training data as this thing that just sort

11:31.880 --> 11:36.320
of existed before you came to the problem, we decided we wanted to make it kind of the

11:36.320 --> 11:40.040
first class citizen of our new framework.

11:40.040 --> 11:44.920
And so in snorkel, really the main activity, you know, snorkel supports arbitrary models

11:44.920 --> 11:50.040
you can plug in your favorite model downloaded from online, plug it into PyTorch or TensorFlow

11:50.040 --> 11:55.240
or whatnot, but really the thing that users do in snorkels, they write these labeling functions.

11:55.240 --> 12:00.840
And the goal is to get subject matter experts to as quickly as possible, dump in all of

12:00.840 --> 12:05.280
the signal and the knowledge that they have in a much kind of higher density way than

12:05.280 --> 12:10.080
if they were just sitting saying yes, no, yes, no, on radiology images for months.

12:10.080 --> 12:15.920
And so you have subject matter experts producing these labeling functions, you know, so you

12:15.920 --> 12:20.760
see any, and so that provides, you know, some degree of abstraction over the labels themselves.

12:20.760 --> 12:21.760
Exactly.

12:21.760 --> 12:22.760
Right.

12:22.760 --> 12:25.240
I can imagine a bunch of different directions you might want to go with that.

12:25.240 --> 12:29.200
Like, are you using these probabilistically, are you like active learning, incorporating

12:29.200 --> 12:32.560
some kind of active, like what's next, what's next, what's next, what's next.

12:32.560 --> 12:33.560
Yeah, that's a great question.

12:33.560 --> 12:37.600
And actually, I mean, there are ongoing projects on kind of like all those and too many other

12:37.600 --> 12:38.600
fronts.

12:38.600 --> 12:39.600
Okay.

12:39.600 --> 12:41.400
This is such a thing is too much fun.

12:41.400 --> 12:45.600
You know, my advisor has a story called the, you know, we call it parable the burritos

12:45.600 --> 12:50.000
that he had a burrito eating contest and then he, you know, finally asks his friend,

12:50.000 --> 12:51.000
why are we eating all these burritos?

12:51.000 --> 12:52.000
What's their reward?

12:52.000 --> 12:53.000
His friend was like, well, it's more burritos.

12:53.000 --> 12:56.440
Kind of how research feels, you know, you work, you work and you work and you work and

12:56.440 --> 12:57.440
well, what's their reward?

12:57.440 --> 12:59.160
You get to do more work.

12:59.160 --> 13:02.000
So it's, you know, you hope that you like the work you're doing, right?

13:02.000 --> 13:05.880
But we have a ton of stuff we're trying to do on, on top of it, you know, I'll go back

13:05.880 --> 13:10.160
to the first thing you said, which is that you have this abstraction away from labels.

13:10.160 --> 13:14.400
And that's one of the things we're most excited about is that the big thing that we're trying

13:14.400 --> 13:21.280
to do with snorkel is turn training data labeling from a hand labeling, you know, hand

13:21.280 --> 13:23.720
annotation activity to a coding one.

13:23.720 --> 13:27.880
And this code is supervision paradigm, this shift, then, you know, we hope and we've seen

13:27.880 --> 13:32.240
with some of our prototypes allows you to use all the benefits of code, different abstraction

13:32.240 --> 13:36.840
layers, modularity, you know, increased interpretability.

13:36.840 --> 13:42.160
So when your training set is 20 labeling functions applied over unlabeled data rather than

13:42.160 --> 13:48.320
a million label data points, if you find out that your modeling goals change, you can

13:48.320 --> 13:51.680
try to change your labeling functions in half an hour rather than having to throw out

13:51.680 --> 13:56.040
your training data and start over again, which is a massive problem in real world deployments

13:56.040 --> 13:58.680
of ML as far as we see.

13:58.680 --> 14:05.360
And so does this apply most directly to a certain type of problem or use case I'm thinking

14:05.360 --> 14:10.440
of, for example, you know, the reason why deep learning has been so effective in the computer

14:10.440 --> 14:17.520
vision realm is because creating, you know, rules for these types of problems like, you

14:17.520 --> 14:19.240
know, where's the cat in this picture?

14:19.240 --> 14:20.480
It's like super hard.

14:20.480 --> 14:21.480
How do you do that?

14:21.480 --> 14:23.120
Well, it's a great question.

14:23.120 --> 14:24.120
It's a great question.

14:24.120 --> 14:28.400
So this, and it really ties in with that notion of like building higher level abstractions

14:28.400 --> 14:29.400
on top.

14:29.400 --> 14:30.720
So we started with text.

14:30.720 --> 14:34.120
We started with these, you know, this like, you know, Memex problem of, okay, we need

14:34.120 --> 14:38.960
to quickly classify our to pull out names of entities or relations, you know, we've

14:38.960 --> 14:42.760
done projects over electronic health records at the VA at Stanford where we want to pull

14:42.760 --> 14:48.000
out mentions of, you know, there was pain in this joint or this area of the body, right?

14:48.000 --> 14:51.320
This is actually kind of messy because language is messy, but you can imagine how you'd write

14:51.320 --> 14:52.560
rules over text, right?

14:52.560 --> 14:57.520
You, you know, you, you give some rules and the model then, you know, learns to generalize

14:57.520 --> 14:58.520
beyond it.

14:58.520 --> 15:01.720
Now images, we've done some interesting stuff.

15:01.720 --> 15:06.640
One thing that we've done, this was a Neurip's paper last year, actually, an extension

15:06.640 --> 15:12.120
called Coral built on top of snorkel where we basically applied a bunch of unsupervised

15:12.120 --> 15:17.280
algorithms to kind of get macro level features of images.

15:17.280 --> 15:21.160
So imagine that, um, and then we had people write labeling functions over these.

15:21.160 --> 15:25.360
So there's a tutorial we have online and all of this, there's a lot of material at Stanford,

15:25.360 --> 15:31.280
uh, snorkel.stanford.edu, um, so this exact demo is there as little toy demo, but imagine

15:31.280 --> 15:35.640
you want to classify, you want to use a, you know, a deep neural network to classify

15:35.640 --> 15:39.680
when people are writing bikes, like you want to do activity detection.

15:39.680 --> 15:44.080
So we just use an off the shelf, uh, bounding box thing to put, you know, bounding boxes

15:44.080 --> 15:48.320
around a person in a bike and then people would write labeling functions that say, okay,

15:48.320 --> 15:53.520
if person is, you know, above bike vertically and centered, then label true else label

15:53.520 --> 15:54.520
false.

15:54.520 --> 15:57.600
So you can write these labeling, and again, this is the abstraction level thing.

15:57.600 --> 16:01.760
You can write labeling functions over these kind of building boxes or if it's mammography,

16:01.760 --> 16:06.080
you know, we could pre tag all the blobs in the image and then the, you know, domain

16:06.080 --> 16:10.000
act, the clinician writes labeling functions about properties of those blobs.

16:10.000 --> 16:11.000
Mm-hmm.

16:11.000 --> 16:12.520
And then of course, this is a pipeline.

16:12.520 --> 16:16.320
So we're just trying to generate training data for some, some things, right?

16:16.320 --> 16:20.280
And then the goal, and this is what we see empirically, is that the deep neural network

16:20.280 --> 16:22.800
will learn to generalize beyond that training data.

16:22.800 --> 16:27.480
So you write these rules, capture some small portion of your data set, and then you use

16:27.480 --> 16:31.520
it to train a model that learns to cover the whole data set.

16:31.520 --> 16:36.960
And so you just, you're just trying to generate training data, are you actually generating

16:36.960 --> 16:43.760
the training data or have you integrated these labeling functions into the training process?

16:43.760 --> 16:44.760
That's a great question.

16:44.760 --> 16:46.960
There's definitely stuff where we want to close the loop.

16:46.960 --> 16:47.960
Yeah.

16:47.960 --> 16:51.680
Um, the basic, you know, the basic setup is that these labeling functions and generating

16:51.680 --> 16:55.600
is maybe a load of term, we're, we're trying to label training data sets.

16:55.600 --> 16:59.880
So what these methods rely on is, or the way that we mostly do is unlabeled data.

16:59.880 --> 17:03.080
To describe another project that I'm quite excited about at the moment, we're collaborating

17:03.080 --> 17:07.120
with the radiology department at Stanford and actually a bunch of teams around Stanford

17:07.120 --> 17:08.120
hospital.

17:08.120 --> 17:13.480
Um, but I'll focus on the radiology applications where we have, they have troves of unlabeled

17:13.480 --> 17:14.480
data.

17:14.480 --> 17:18.440
And what the sum label data looks like is generally comes in pairs of an image and then

17:18.440 --> 17:21.720
a text report that the doctor wrote, right?

17:21.720 --> 17:25.680
And so you can think of that text report as like kind of a messy, jumbled version of

17:25.680 --> 17:27.880
the label that you actually want.

17:27.880 --> 17:32.080
And so there were efforts, which are really cool, where, you know, I think there was one

17:32.080 --> 17:36.360
where they took, you know, a couple of years and we actually have a paper out in radiology

17:36.360 --> 17:42.040
from someone in our lab on using this labeling effort that took years of, you know, radiologist

17:42.040 --> 17:44.240
sitting and labeling data.

17:44.240 --> 17:48.800
With snorkelway access question, could we have a radiology fellow spend a week or two,

17:48.800 --> 17:53.440
write these labeling functions over those text reports and generate labels that were almost

17:53.440 --> 17:55.160
as good.

17:55.160 --> 18:00.080
And then if we piped in 10x the amount of unlabeled data, could we even do better?

18:00.080 --> 18:01.080
Mm-hmm.

18:01.080 --> 18:04.320
You know, this is this intuition, which is an old one in ML of like, well, maybe a larger

18:04.320 --> 18:08.520
amount of noisier data can be a smaller amount of ground truth data, especially if we use

18:08.520 --> 18:12.840
a technique like snorkel that kind of, you know, learns to reweight and combine the labeling

18:12.840 --> 18:15.400
functions, kind of denoises it automatically.

18:15.400 --> 18:19.320
And so the answer was yes, it's actually, you know, we just dump in as much unlabeled data

18:19.320 --> 18:23.720
we can get our hands on, we apply the labeling functions and dump it into snorkel, which

18:23.720 --> 18:26.600
kind of reweights and recombines them.

18:26.600 --> 18:31.160
And then you get a better training set that can be used almost as effectively or sometimes

18:31.160 --> 18:34.880
even more effectively than that hand labeled training set that would have taken months

18:34.880 --> 18:35.880
or years.

18:35.880 --> 18:36.880
Okay.

18:36.880 --> 18:43.120
So we've talked about defining these labeling functions and it sounds like the most

18:43.120 --> 18:49.520
basic uses to use these labeling functions to label data, but it's not a straight application

18:49.520 --> 18:50.520
of this labeling function.

18:50.520 --> 18:54.240
And there's this reweating that you've alluded to a couple of times, what exactly is happening

18:54.240 --> 18:55.240
there?

18:55.240 --> 18:56.240
Yeah, great question.

18:56.240 --> 19:01.440
And that's a part that we really like to get deep into the math on that front.

19:01.440 --> 19:06.840
So this was, I mean, I guess the first paper was at NURPS in 2016, it was called data programming.

19:06.840 --> 19:11.640
So we have a method which, you know, it's based on old intuition.

19:11.640 --> 19:17.640
So if you, you know, the intuition is this, is that if you have a bunch of sources, you

19:17.640 --> 19:22.320
have a bunch of, say, a bunch of crowd lablers and you don't have any ground truth, but

19:22.320 --> 19:24.480
you want to know who to trust.

19:24.480 --> 19:30.440
You can start under some assumptions and just say, okay, say all that they're all independent.

19:30.440 --> 19:32.320
None of them are colluding with each other.

19:32.320 --> 19:35.400
Just say, okay, well, I'm going to trust the ones that are in the majority more often.

19:35.400 --> 19:36.400
Sure.

19:36.400 --> 19:39.480
And if one of the crowd lablers is almost always in the minority, I'm going to discount

19:39.480 --> 19:40.480
them.

19:40.480 --> 19:41.480
Maybe think that they're adversarial.

19:41.480 --> 19:44.440
Whereas if someone is always in the majority on every data point, I'm going to trust

19:44.440 --> 19:45.440
them more.

19:45.440 --> 19:46.440
Okay.

19:46.440 --> 19:47.440
Yeah.

19:47.440 --> 19:48.440
Yeah.

19:48.440 --> 19:51.800
This is, you know, a big area of work in the past and crowd sourcing.

19:51.800 --> 19:58.040
So in our NURPS 2016 paper, what we were doing was kind of extending this to this more,

19:58.040 --> 20:03.520
this kind of more tangled setting of having functions rather than people because these

20:03.520 --> 20:06.680
functions can have all kinds of weird correlations, right?

20:06.680 --> 20:10.080
You know, two people we've had this happen before, two people can write two labeling functions

20:10.080 --> 20:14.000
that are near duplicates of each other or exact duplicates.

20:14.000 --> 20:15.920
And you don't want to double count their votes.

20:15.920 --> 20:19.400
You could have whole clumps of labeling functions that are using the same kinds of patterns

20:19.400 --> 20:21.120
or the same data resources.

20:21.120 --> 20:22.120
It's code, right?

20:22.120 --> 20:24.360
Code can have arbitrary weird correlations and overlaps.

20:24.360 --> 20:31.240
So is it fundamental to the model or the way you envision the model being used that for

20:31.240 --> 20:38.960
a given problem, you'd have multiple subject matter expertise, SMEs kind of creating labeling

20:38.960 --> 20:40.280
functions.

20:40.280 --> 20:43.440
It's almost like instead of crowd sourcing labels, you're crowd sourcing labeling functions.

20:43.440 --> 20:44.440
Yeah.

20:44.440 --> 20:46.880
We're actually doing a study on that idea like meta crowd sourcing that we actually

20:46.880 --> 20:52.960
had a workshop a couple of weeks ago at Stanford where we had 15 teams come and they were

20:52.960 --> 20:57.600
doing stuff around text extraction from in the bio domain.

20:57.600 --> 21:02.840
And we actually have now post hoc collected all 15, like the labeling functions from all

21:02.840 --> 21:07.760
15 teams and actually does better if you just dump them in all and all and together.

21:07.760 --> 21:11.760
But you know, practically, it's usually, you know, with a lot of our engagements, it's

21:11.760 --> 21:13.600
just one subject matter expert.

21:13.600 --> 21:16.760
But what is essential is that they write more than one labeling function, right?

21:16.760 --> 21:19.200
So they usually write for the same problem.

21:19.200 --> 21:20.200
For the same problem.

21:20.200 --> 21:21.200
Yeah.

21:21.200 --> 21:24.160
So, you know, we'll have the, in that example, I gave about, you know, classifying chest

21:24.160 --> 21:29.640
x-rays, for example, the radiology fellow wrote 20 labeling functions.

21:29.640 --> 21:33.200
And they were all, you know, they were a mix of things like looking for certain words

21:33.200 --> 21:37.920
or matching against certain ontologies of diseases or checking how many times the word

21:37.920 --> 21:40.800
normal is said, all these kinds of messy heuristics.

21:40.800 --> 21:47.640
And so, in a sense, you're, you know, it's that you're trying to apply, you know, what

21:47.640 --> 21:54.840
you consider to be like, it's just a good programming, like a single labeling function has

21:54.840 --> 21:59.080
like conceptual boundaries, it's trying to generate a label based on this as opposed

21:59.080 --> 22:04.720
to some, you know, single mango labeling function that takes in everything you know about

22:04.720 --> 22:07.320
the data set and tries to label it.

22:07.320 --> 22:11.200
And that is, that is such a great example because that speaks exactly the kind of our motivation

22:11.200 --> 22:17.240
in that, you know, we, you know, I was kind of glossing over a little bit like we didn't

22:17.240 --> 22:20.720
just go from, okay, people only hand labeled to now we're doing what we didn't snorkel.

22:20.720 --> 22:26.320
We saw that people were trying these, what's often called weaker ways of supervising models

22:26.320 --> 22:28.160
where they were writing code.

22:28.160 --> 22:32.040
But the big pain point there, including our lab with, with the previous system D type

22:32.040 --> 22:36.840
and the problem there was that exactly if you try to make one big mango program to produce

22:36.840 --> 22:40.640
the labels, this becomes the same kind of spaghetti code that you were trying to avoid in the

22:40.640 --> 22:43.760
first place by using a machine learning model.

22:43.760 --> 22:47.760
So the idea of these labeling functions is yes, you're, you're just writing little snippets

22:47.760 --> 22:51.480
and you're leaving it up to snorkel to figure out how to wait them, how to combine them.

22:51.480 --> 22:55.000
You don't have to sit there, again, you know, it's not magic, it doesn't work always

22:55.000 --> 22:58.640
right there, you know, rather than if I have two labeling functions and I want, you know,

22:58.640 --> 23:01.320
I rather than sitting there and being like, well, which one do I trust more?

23:01.320 --> 23:06.160
Or one example is say you have one labeling function that, you know, labels 10,000 points

23:06.160 --> 23:10.760
and you trust it way more and one that labels a million points and you trust it less.

23:10.760 --> 23:13.320
You know, how do you combine, what's the right way to combine them?

23:13.320 --> 23:14.320
Right.

23:14.320 --> 23:15.320
You don't need to worry about that.

23:15.320 --> 23:17.360
You just dump it into snorkel and snorkel waits them accordingly.

23:17.360 --> 23:21.480
Or you have 10 labeling functions and you don't, you don't want to like sit there thinking,

23:21.480 --> 23:24.640
okay, which one should override which one and which combination?

23:24.640 --> 23:26.680
You just dump it into snorkel.

23:26.680 --> 23:27.680
It's interesting.

23:27.680 --> 23:33.600
So I did an interview last week, I think, with Rich Zemel at the University of Toronto

23:33.600 --> 23:43.040
and he's doing some work on fairness and one of his papers is about a system that is trying

23:43.040 --> 23:51.400
to create an unbiased system by having the system refer decisions to kind of human participants

23:51.400 --> 23:57.320
in the system but start to learn their biases and refer things to them based on those biases.

23:57.320 --> 24:03.440
It almost sounds like there's some application of that here where the system can learn which

24:03.440 --> 24:10.000
of the functions work best given a certain type of input data and then dynamically use

24:10.000 --> 24:11.000
these.

24:11.000 --> 24:12.000
Yes.

24:12.000 --> 24:18.280
I mean, no, that's, your questions are uncannily good in this, you're also, you're also asking

24:18.280 --> 24:23.720
all about projects that were currently underway, so it's almost like my advisor paid you.

24:23.720 --> 24:25.560
This is one thing that we're very excited about.

24:25.560 --> 24:29.360
So the base thing, so I'm sure also, I haven't read that particular paper, but it sounds

24:29.360 --> 24:34.240
like I'm quite sure there are lots of parallels in the ideas and stuff.

24:34.240 --> 24:38.680
And in our setting, we start by learning an accuracy for every labeling function, right?

24:38.680 --> 24:45.560
And again, it's that we use some matrix completion style techniques in 2016, we're using

24:45.560 --> 24:51.800
Sephiron Gibbs sampling, we have our various fancy ways of doing it, but the intuition

24:51.800 --> 24:59.160
is that you try to learn the accuracy based on trusting the majority and having some

24:59.160 --> 25:03.480
assumption that they're kind of independent or learning which ones aren't, which ones

25:03.480 --> 25:04.920
are correlated with each other.

25:04.920 --> 25:08.760
But we're increasingly moving into this area where we are learning actually like biases

25:08.760 --> 25:10.040
that are conditioned on data.

25:10.040 --> 25:14.240
So you can learn that, you know, this labeling function is much better for daytime conditions

25:14.240 --> 25:16.160
than nighttime conditions, right?

25:16.160 --> 25:18.360
That's where it's kind of expertise is.

25:18.360 --> 25:22.240
So that's exactly something that we're, you know, playing around with right now.

25:22.240 --> 25:23.240
Okay.

25:23.240 --> 25:30.400
And I would imagine that some of these biases could be explicit, like the SME could

25:30.400 --> 25:38.040
consciously say, oh, if I was looking at this, you know, this radiological image, I guess

25:38.040 --> 25:41.400
that's not a great example, but if I was looking at this picture of a person on a bicycle

25:41.400 --> 25:46.280
and it was dark, you know, I'd look for reflectors, but then there are these implicit biases

25:46.280 --> 25:49.040
that you just kind of, it's better to learn.

25:49.040 --> 25:53.360
Anything that's simple for an SME to write down in code or even, and I should mention one

25:53.360 --> 25:56.360
of the other things we're doing going back to that point of abstraction layers, I guess

25:56.360 --> 26:01.200
I'll briefly go on that tangent, which is that, you know, one of the things we're really

26:01.200 --> 26:04.960
excited about is kind of building up this programming stack.

26:04.960 --> 26:08.000
So you know, if you think of a traditional programming stack, you go from like, you know,

26:08.000 --> 26:11.800
machine language all the way to increasingly higher and higher and more declarative levels

26:11.800 --> 26:14.840
until you get to like, I know, voice commands or GUIs, right?

26:14.840 --> 26:15.840
Yeah.

26:15.840 --> 26:17.120
We're trying to think about the same thing with training data.

26:17.120 --> 26:19.880
The training data is the sort of machine code that's like the common thing you compile

26:19.880 --> 26:20.880
to.

26:20.880 --> 26:24.080
Labeling functions are like the lowest level thing you can program in.

26:24.080 --> 26:25.680
How can you go higher and higher, right?

26:25.680 --> 26:26.680
So that's interesting.

26:26.680 --> 26:27.680
Yeah.

26:27.680 --> 26:30.280
And it's, I mean, a lot of these are still, you know, because they're kind of prototype

26:30.280 --> 26:35.080
level, but like, my lab made a presented a paper called, it's a great name, better than

26:35.080 --> 26:42.360
snorkeling and babble level at ACL, which is one of the big NLP conferences this year,

26:42.360 --> 26:46.920
where the idea is that you give explanations for why you're labeling data points.

26:46.920 --> 26:48.080
And these are compiled.

26:48.080 --> 26:52.440
They're parsed automatically into labeling functions and then dumped into snorkel.

26:52.440 --> 27:00.160
So we want to make the SME provides explanations as to why they're labeling manuals.

27:00.160 --> 27:02.960
Why they would label something, they don't actually have to do the manual, they're just

27:02.960 --> 27:06.720
looking at examples and they're giving explanations and those are then parsed using

27:06.720 --> 27:11.600
something called a semantic parser into labeling functions, which are, of course, are super

27:11.600 --> 27:14.480
noisy, but that's what snorkel is meant to deal with, right?

27:14.480 --> 27:19.480
So whatever the level that the SME can provide this stuff, the goal of snorkel is just to,

27:19.480 --> 27:23.320
you know, whatever they can provide, take it and whatever is too laborious to provide,

27:23.320 --> 27:28.720
like those exact conditions or those exact sort of if-then clauses, just kind of learn

27:28.720 --> 27:29.720
that, right?

27:29.720 --> 27:31.080
Kind of fill that in.

27:31.080 --> 27:32.080
Yeah.

27:32.080 --> 27:35.040
And another practical tool there is that these labeling functions kind of stain.

27:35.040 --> 27:40.360
So, you know, if you know the labeling function is really good for daytime, but not nighttime,

27:40.360 --> 27:44.400
and you have a way to express that, then you can just write a labeling function that says,

27:44.400 --> 27:49.960
if daytime, you know, vote on my, you know, output-alabel else, just abstain.

27:49.960 --> 27:50.960
Right, right.

27:50.960 --> 27:57.440
Yeah, that was another feature of this rich, simple paper that I was referring to, the,

27:57.440 --> 28:01.080
one of the things that they did with their models that it could say yes, nor pass, and kind

28:01.080 --> 28:05.280
of defer to another model or in their case of human.

28:05.280 --> 28:09.040
And we know in our setting, we find that this, you know, this abstention is actually like

28:09.040 --> 28:13.360
a very, very critical tool in practice, this ability to say, you know, I pass, or I don't

28:13.360 --> 28:14.360
know.

28:14.360 --> 28:18.360
And in their case, I imagine in your case, it's, you know, when I first heard that, I was

28:18.360 --> 28:22.840
like, okay, well, okay, if it's, you know, below a threshold of 50% confidence or something

28:22.840 --> 28:23.840
like that, you abstain.

28:23.840 --> 28:25.680
But it was way more nuanced than that.

28:25.680 --> 28:28.680
I imagine that it's similarly nuanced in your case.

28:28.680 --> 28:33.360
Yeah, it's, it's so much because the, the, the place where you pass on or the place

28:33.360 --> 28:35.720
where you abstain on does have some bias to it.

28:35.720 --> 28:39.320
It's where, you know, where the expert thinks this heuristic doesn't really apply, I guess.

28:39.320 --> 28:40.320
Yeah.

28:40.320 --> 28:43.560
And it's a, you know, it's a rough version of that.

28:43.560 --> 28:44.560
Right.

28:44.560 --> 28:45.560
Right.

28:45.560 --> 28:49.800
And again, you know, our goal here is to speed up in a human-in-the-loop process.

28:49.800 --> 28:54.240
And to fundamentally bring it to the level of coding rather than labeling, not to obviate

28:54.240 --> 28:55.240
it.

28:55.240 --> 28:56.240
Right.

28:56.240 --> 28:58.520
So, you know, people have to, you know, people iterate on these labeling functions.

28:58.520 --> 29:04.200
But this ends up taking, you know, days or a week or two, not months or years.

29:04.200 --> 29:08.440
And then it can be repurposed or reapplied when your next problem comes along.

29:08.440 --> 29:16.920
So this conversation about programming levels of abstraction and, and functions in particular

29:16.920 --> 29:22.400
is kind of pulling me towards like an infrastructure path and thinking of like serverless.

29:22.400 --> 29:23.800
Is that mean anything to you?

29:23.800 --> 29:27.400
Like lambda functions, AWS lambda and that kind of thing.

29:27.400 --> 29:28.400
Yeah.

29:28.400 --> 29:30.000
I wonder if there's an intersection here somewhere out of it.

29:30.000 --> 29:34.280
It's not obvious to me what it would be, rather than that functions are the primary currency

29:34.280 --> 29:35.280
of both systems.

29:35.280 --> 29:36.280
Yeah.

29:36.280 --> 29:41.120
There's a lot of interesting stuff we want to do, I don't have any directions we've explored

29:41.120 --> 29:42.120
around that.

29:42.120 --> 29:43.200
I mean, it's certainly an interesting area.

29:43.200 --> 29:45.960
We haven't tried that out with Snorkel yet.

29:45.960 --> 29:49.840
I will say this is, you know, a bit of a right-hand turn.

29:49.840 --> 29:53.040
But something I think is important is that, or that we think is important, is that Snorkel

29:53.040 --> 29:57.440
is very much what we think of as a system's ML type contribution, right?

29:57.440 --> 30:01.400
Like, you know, one of the initial papers or the initial paper was at NUREPS in 2016.

30:01.400 --> 30:02.600
It was about the algorithm.

30:02.600 --> 30:08.040
But the real contribution that we're excited about here is really a merger of sort of,

30:08.040 --> 30:12.680
you know, machine learning algorithms and theory, but with systems and framework constraints.

30:12.680 --> 30:16.600
And that's something that I, you know, a lot of us feel pretty excited about.

30:16.600 --> 30:21.560
We're actually, you know, there's a PC meeting for this new CISML conference here, you

30:21.560 --> 30:24.280
know, dovetailed on with NUREPS.

30:24.280 --> 30:25.800
And this is a conference.

30:25.800 --> 30:28.640
It's, I mean, unfortunately, the call for submission already happens.

30:28.640 --> 30:29.640
I can't advertise it.

30:29.640 --> 30:34.680
I can't say it's here, but, you know, at NUREPS, at the workshops, there are actually two

30:34.680 --> 30:39.520
different systems ML conferences, systems ML and ML for systems.

30:39.520 --> 30:45.280
And then there's this CISML conference happening at Stanford in the spring.

30:45.280 --> 30:47.040
And, you know, those of us involved things that-

30:47.040 --> 30:48.600
Separate from the scaled ML?

30:48.600 --> 30:49.600
Yes, separate, yeah.

30:49.600 --> 30:50.600
Oh, really?

30:50.600 --> 30:51.600
Okay.

30:51.600 --> 30:52.600
And I think a little bit of a broader umbrella.

30:52.600 --> 30:53.600
Okay.

30:53.600 --> 30:55.960
We're going to be releasing a white paper soon on sort of what we see the scope as.

30:55.960 --> 30:58.440
But I would kind of pitch it this way.

30:58.440 --> 31:02.840
There's so many fundamental core problems in core ML that still need to be solved.

31:02.840 --> 31:07.880
They're almost more so because, you know, deep learning came in and made such a splash

31:07.880 --> 31:13.200
and such an empirical impact on certain areas, but we still understand it so, so poorly.

31:13.200 --> 31:16.720
And, you know, we need to work on so many problems around that that are really fascinating.

31:16.720 --> 31:20.640
But it's kind of had an impact enough that a lot of us are saying, look, it's time to

31:20.640 --> 31:22.880
build the engineering infrastructure around it.

31:22.880 --> 31:23.880
Right?

31:23.880 --> 31:24.880
Right?

31:24.880 --> 31:29.400
It's valuable enough that people want to use it and they can't- and it's not because

31:29.400 --> 31:31.600
they don't understand- they don't have a fancine of algorithms.

31:31.600 --> 31:32.600
It reaches the core.

31:32.600 --> 31:33.600
Yeah.

31:33.600 --> 31:34.600
Yeah.

31:34.600 --> 31:39.120
So, you know, I- I think this was, you know, shot down by some of my core organizers.

31:39.120 --> 31:41.320
But I like the metaphor of like a sandwich almost.

31:41.320 --> 31:43.520
Like, you know, the core is the ML stuff.

31:43.520 --> 31:47.320
But, you know, on the bottom you have the, you know, you have the lower level concerns

31:47.320 --> 31:51.920
of how do you- how do you build the hardware for modern ML, you know, algorithms?

31:51.920 --> 31:53.440
How do you- how do you serve it?

31:53.440 --> 31:55.720
How do you set up the distributed systems?

31:55.720 --> 31:59.440
On the top level you have- how do you, you know, put together- put it together in end-to-end

31:59.440 --> 32:00.760
workflows?

32:00.760 --> 32:05.440
Things like snorkel or things for data preprocessing or interpretability or serving or monitoring,

32:05.440 --> 32:06.440
right?

32:06.440 --> 32:07.440
Right.

32:07.440 --> 32:12.040
So, you have these sort of types of considerations that that's not kind of what NERF specializes

32:12.040 --> 32:13.360
in, usually.

32:13.360 --> 32:17.920
And we think there's an exciting area to really fill out these engineering or systems aspects

32:17.920 --> 32:18.920
of ML.

32:18.920 --> 32:22.360
So, that's definitely kind of where we see a lot of the interesting questions around snorkel.

32:22.360 --> 32:23.360
I mean, yeah.

32:23.360 --> 32:27.680
This is the ML algorithm side, which we love too, but also these like, you know, we haven't

32:27.680 --> 32:30.600
dealt with a serverless question yet, but those kinds of questions.

32:30.600 --> 32:39.440
So, we started talking about the way that it kind of chooses between these labeling functions.

32:39.440 --> 32:42.000
And you mentioned that it's evolved.

32:42.000 --> 32:44.760
You started with Gibbs sampling and some other things.

32:44.760 --> 32:49.360
And- but it's an area that, you know, folks enjoy- folks on a team enjoy kind of geeking

32:49.360 --> 32:53.320
out about, like, can you go into some more detail on what exactly is happening there?

32:53.320 --> 32:54.320
Yeah, yeah.

32:54.320 --> 32:59.320
So, you know, I'd say that, again, you know, if you're into this area, one of the things

32:59.320 --> 33:04.920
that we're quite excited about is this handling correlations between the labeling functions.

33:04.920 --> 33:10.120
So, if you think about this as a modeling problem, you know, you could kind of- we call it

33:10.120 --> 33:12.120
weekly supervised.

33:12.120 --> 33:16.880
And this is one of the, you know, areas or little sub-communities that we're quite excited

33:16.880 --> 33:17.880
about.

33:17.880 --> 33:22.280
Ransom workshop to actually at last NERFs and at IClear coming up this year on week supervision.

33:22.280 --> 33:27.040
This idea of noisier or cheaper or higher level supervision.

33:27.040 --> 33:30.360
But the core model in Snarkle that learns the accuracy of the labeling functions, you

33:30.360 --> 33:35.440
could think almost of unsupervised in that we don't have any ground truth labels.

33:35.440 --> 33:38.840
But either way, what it looks like is you have- what you observe is you observe the votes

33:38.840 --> 33:40.360
of these labeling functions.

33:40.360 --> 33:44.480
What you don't observe is this latent variable of the ground truth.

33:44.480 --> 33:48.760
So it fits into this tradition of latent variable models, but in this new kind of way where

33:48.760 --> 33:52.560
these labeling functions can also be correlated with each other.

33:52.560 --> 33:57.360
And so we've done work on, you know, if you know the correlations, if your SME user says,

33:57.360 --> 34:00.240
look, these two labeling functions are basically the same.

34:00.240 --> 34:03.360
I just tweaked the number or I tweaked the threshold.

34:03.360 --> 34:07.200
And then our system can take that into account and learn the model knowing to expect that

34:07.200 --> 34:12.320
these two labeling functions are very correlated that we shouldn't double count their votes basically.

34:12.320 --> 34:13.320
We've also done work.

34:13.320 --> 34:17.560
There is an ICML 2017 paper and all this is up at snarkle.sanford.edu.

34:17.560 --> 34:24.480
Just before you get to the next paper, when you're talking about kind of these correlations,

34:24.480 --> 34:34.320
you've got these functions that are originally at least provided in the Python domain, the programming domain.

34:34.320 --> 34:39.960
Are you kind of projecting them into like a linear algebra domain?

34:39.960 --> 34:41.320
Yeah, so it makes sense to you.

34:41.320 --> 34:45.360
I think, yeah, I mean, that's a definitely a great way of putting it.

34:45.360 --> 34:52.600
I mean, but concretely, just to keep it simple, what we're doing is we're just taking their labels

34:52.600 --> 34:55.160
and then we basically just leave them as black boxes.

34:55.160 --> 34:58.880
Right, so you've got some transformation from some input to the label.

34:58.880 --> 35:00.400
We have a bunch of functions.

35:00.400 --> 35:01.800
We have a bunch of unlabeled data.

35:01.800 --> 35:04.000
That's another critical ingredient.

35:04.000 --> 35:05.480
Apply the functions to the data.

35:05.480 --> 35:08.400
And then we have a basically a matrix of noisy labels.

35:08.400 --> 35:09.800
Yeah, and that's what we work with.

35:09.800 --> 35:16.880
Although we have done one of the past nerfs papers last year was looking at what if we actually

35:16.880 --> 35:18.920
use information in these functions.

35:18.920 --> 35:20.960
So we can actually do static analysis on them.

35:20.960 --> 35:21.960
They're not black boxes.

35:21.960 --> 35:25.560
This is another interesting facet of our kind of unique facet of our setting.

35:25.560 --> 35:27.480
They're not black boxes, right?

35:27.480 --> 35:31.840
I can have a really pretty simple static analysis program that looks at two labeling functions

35:31.840 --> 35:36.720
and says, hey, they're nearly identical except that one number was tweaked.

35:36.720 --> 35:39.600
Therefore, I should model them as correlated.

35:39.600 --> 35:42.200
So we can open that black box.

35:42.200 --> 35:46.560
But at the end of the day, we just have this matrix of noisy labels.

35:46.560 --> 35:51.680
And we just need to know how to re-weight them according to the different sources they

35:51.680 --> 35:54.200
came, the different labeling functions they came from.

35:54.200 --> 36:00.920
Do you apply traditional PCA or things that dimensionality reduction or things that are

36:00.920 --> 36:07.720
trying to find these correlations or some of the things that you've mentioned, I guess

36:07.720 --> 36:14.720
are their unique aspects of this noisy matrix that make other techniques better than

36:14.720 --> 36:17.920
the more generic ways of finding these correlations?

36:17.920 --> 36:18.920
Yeah, yeah.

36:18.920 --> 36:22.400
So, I mean, that's a great intuition as well, and some of the techniques we're looking

36:22.400 --> 36:28.040
into are connections to a sign known as robust PCA for learning the structure.

36:28.040 --> 36:35.200
The ICML paper I mentioned from last year on learning the structure was building on classic

36:35.200 --> 36:39.840
techniques and probabilistic graphical models for learning the structure of the models,

36:39.840 --> 36:42.800
except our setting, we don't have ground truth labels.

36:42.800 --> 36:47.440
So that kind of fundament, that's like the fundamental change here is that we're missing

36:47.440 --> 36:48.440
the ground truth.

36:48.440 --> 36:53.080
And so then we show that we can still learn the structure from data.

36:53.080 --> 36:57.720
And so, you know, again, you either learn the structure or you're given it, and then

36:57.720 --> 36:59.600
you need to take it into account in the modeling.

36:59.600 --> 37:03.080
You don't want to effectively, if we go back to that majority vote intuition, you don't

37:03.080 --> 37:07.480
want to double count two labeling functions that are basically the same in Roots, and

37:07.480 --> 37:10.880
are always going to give the same answer, that'll throw your model off.

37:10.880 --> 37:15.240
And our motivation, once again, is really grounded in developer process.

37:15.240 --> 37:18.440
We've seen failure modes happen according to this.

37:18.440 --> 37:26.400
If you want to have three developers, or if you want to, we just post online about a

37:26.400 --> 37:28.560
report of some of our collaborations with Teams at Google.

37:28.560 --> 37:34.080
So you have a huge scale where you have Teams of multiple people working on these labeling

37:34.080 --> 37:36.440
functions, and they're all different types.

37:36.440 --> 37:39.880
You want to be able to just dump them in and not worry about if some of them are too correlated

37:39.880 --> 37:40.880
or not.

37:40.880 --> 37:44.320
You want to have the system take care of that for you, not because it's going to quadruple

37:44.320 --> 37:48.480
performance necessarily, but because it's going to avoid catastrophic failure modes.

37:48.480 --> 37:53.800
And so that kind of like increasing robustness in a human and the loop driven process is really

37:53.800 --> 37:55.360
our kind of motivation.

37:55.360 --> 38:00.880
You mentioned you just posted this paper or summary of some work done with Google.

38:00.880 --> 38:02.200
What can you share about that?

38:02.200 --> 38:09.440
Yeah, I mean, so at a high level, the interesting kind of academic thread there, I would say,

38:09.440 --> 38:17.800
is that we refer to this sort of how do you leverage organization scale resources?

38:17.800 --> 38:20.920
So I can talk high level about some of the ideas I think are interesting there, and the

38:20.920 --> 38:22.320
details are on our archive.

38:22.320 --> 38:30.600
But one aspect is this notion that if you go to any organization, or many organizations

38:30.600 --> 38:36.080
these days are dealing with this ML question.

38:36.080 --> 38:42.120
We have all these data resources, a lot of companies or labs or whatever, a lot of organizations

38:42.120 --> 38:48.040
they have troves of rules that their chunks of code that their experts wrote from before.

38:48.040 --> 38:52.480
They may have messy labels that are kind of outdated or noisy, but are sitting around.

38:52.480 --> 38:56.880
They may have even other classifiers that are too brittle to really be the solution,

38:56.880 --> 38:58.800
but have some signal.

38:58.800 --> 39:02.600
And then on the other end, you have these shiny new deep learning models, or they could

39:02.600 --> 39:09.480
be complex models of any sort, random, you know, forest, XG boost, whatever it is.

39:09.480 --> 39:11.680
And the question is, how do you bridge that gap there?

39:11.680 --> 39:14.600
And a lot of organizations are just told, okay, we'll throw out the old stuff, that's

39:14.600 --> 39:15.600
useless.

39:15.600 --> 39:17.760
It's legacy.

39:17.760 --> 39:23.000
And an enormous amount of resources, hand labelling training data, and then jump onto the new

39:23.000 --> 39:24.200
train.

39:24.200 --> 39:29.720
And I think what we showed, at least in some cases in this collaboration, was that you

39:29.720 --> 39:34.160
really can bridge the two using techniques like Snarkle, where you take that and use it

39:34.160 --> 39:38.600
as a weak supervision for training these modern models.

39:38.600 --> 39:43.280
And one of the other cool aspects I'll briefly mention there is this notion of going

39:43.280 --> 39:46.520
from non-servable to servable models.

39:46.520 --> 39:51.880
So you can write this weak supervision of these labeling functions over data that you

39:51.880 --> 39:53.400
don't want to serve in production.

39:53.400 --> 39:54.920
It could be like aggregate statistics.

39:54.920 --> 40:00.720
It might be models that are expensive to run, knowledge graphs, stuff that you can't

40:00.720 --> 40:02.800
serve efficiently in production.

40:02.800 --> 40:07.560
You could use that to train a model that can then run over, you know, cheap, public,

40:07.560 --> 40:08.880
servable features.

40:08.880 --> 40:13.280
And so this seemed to be another aspect of this kind of pipeline that is very useful.

40:13.280 --> 40:15.320
That's the one thing we learned.

40:15.320 --> 40:16.320
Interesting.

40:16.320 --> 40:17.320
Interesting.

40:17.320 --> 40:19.320
Awesome.

40:19.320 --> 40:20.320
What's next?

40:20.320 --> 40:27.600
Well, it sounds like you've got a ton of threads that are already kind of spun up about,

40:27.600 --> 40:30.960
you know, pushing this reach our research in different directions.

40:30.960 --> 40:31.960
Yeah.

40:31.960 --> 40:32.960
It's Snarkle.

40:32.960 --> 40:33.960
Is it open source?

40:33.960 --> 40:35.960
I can people play with it.

40:35.960 --> 40:36.960
Yeah.

40:36.960 --> 40:37.960
For sure.

40:37.960 --> 40:38.960
And, you know, we love feedback.

40:38.960 --> 40:43.200
Proversely, like many academics, we like negative feedback even more than positive at

40:43.200 --> 40:44.200
this point.

40:44.200 --> 40:48.800
We've been fortunate to have people have, you know, wins with Snarkle.

40:48.800 --> 40:53.480
We're very interested in, you know, interesting failure modes or requests for features and

40:53.480 --> 40:54.480
anything.

40:54.480 --> 40:57.000
So it's all in line at snarkle.stanford.edu.

40:57.000 --> 40:58.400
We have tutorials.

40:58.400 --> 41:01.720
We have blog posts, links to all papers and stuff.

41:01.720 --> 41:02.720
Okay.

41:02.720 --> 41:06.920
And again, you know, it's great when people, you know, find things that they have questions

41:06.920 --> 41:09.800
or they say, oh, could be used, could it be used in this setting or it didn't work in

41:09.800 --> 41:10.800
this setting?

41:10.800 --> 41:13.360
I think I have an interesting reason why we love that stuff.

41:13.360 --> 41:18.680
So, and then in terms of what's next, I mean, so there's a whole bunch of stuff.

41:18.680 --> 41:24.000
One thing that we're working on, it's actually in a separate repot just while it's in beta

41:24.000 --> 41:27.480
for now, which is this version of snarkle called snarkle metal.

41:27.480 --> 41:30.280
And it's supposed to be the multitask version of snarkle.

41:30.280 --> 41:35.440
So this is an idea, basically, people are getting excited again about this idea, they

41:35.440 --> 41:37.680
called multitask learning.

41:37.680 --> 41:39.480
This is an idea from back in the 90s.

41:39.480 --> 41:42.880
It's just, you know, if you have multiple, and it's something that's an old theme in

41:42.880 --> 41:43.880
the area, right?

41:43.880 --> 41:49.480
If you have multiple things you're trying to do, just like how humans learn, right?

41:49.480 --> 41:51.840
What if you, you know, kind of do it all jointly?

41:51.840 --> 41:55.440
You share the learned representation between these tasks.

41:55.440 --> 41:59.240
And so there's kind of been a resurgence of interest in these techniques, you know, kind

41:59.240 --> 42:03.120
of in the realm of these new architectures, right?

42:03.120 --> 42:05.480
And often what these look like is actually kind of conceptually simple.

42:05.480 --> 42:07.440
You are the base of the vanilla version.

42:07.440 --> 42:10.040
Now, you have some deep neural network.

42:10.040 --> 42:14.320
And you have the bottom layers are all shared across K different tasks.

42:14.320 --> 42:19.480
And then you kind of split off at the end and learn these like little top task specific

42:19.480 --> 42:22.080
bits.

42:22.080 --> 42:27.720
But you benefit from kind of sharing a representation of the world or of the data between all these

42:27.720 --> 42:28.720
different tasks.

42:28.720 --> 42:35.600
So what really we're really interested in exploring this from the perspective of weak supervision.

42:35.600 --> 42:40.320
And you know, one problem that we kind of detailed in a paper that's going to be presented

42:40.320 --> 42:44.880
this year at AAAI was, okay, how do we deal with the weak supervision from multiple

42:44.880 --> 42:45.880
tasks?

42:45.880 --> 42:49.920
People are writing labeling functions for K different tasks that, you know, have different

42:49.920 --> 42:52.200
kinds of relationships to each other.

42:52.200 --> 42:53.360
Like imagine a hierarchical thing.

42:53.360 --> 43:01.080
Like I have some labeling functions that say, you know, this is a lawyer versus a doctor.

43:01.080 --> 43:05.640
This is a bank versus a hospital and then some that say person or organization.

43:05.640 --> 43:07.040
So you have different levels of granularity.

43:07.040 --> 43:08.440
That's one example, right?

43:08.440 --> 43:12.120
How can we have people dump them all in just like as in snorkel, but now in this multi-task

43:12.120 --> 43:13.240
setting and handle it?

43:13.240 --> 43:15.280
So that was one extension we worked on.

43:15.280 --> 43:20.760
But moving forwards, we really think that, you know, most of the multi-task learning

43:20.760 --> 43:24.880
work, which has been really exciting to date, has been around a couple of hand labeled

43:24.880 --> 43:25.880
datasets.

43:25.880 --> 43:27.640
They're kind of static.

43:27.640 --> 43:31.480
We think that as people begin to move towards these weak supervision methods, the number

43:31.480 --> 43:35.480
of datasets is going to explode and you're going to have now these sort of massively multi-task

43:35.480 --> 43:41.240
models where, you know, rather than saying, oh, look, we can do better on these five different

43:41.240 --> 43:44.600
datasets, you know, that are there.

43:44.600 --> 43:49.480
You're going to have tens or hundreds of, you know, training sets for tens or hundreds

43:49.480 --> 43:52.760
of tasks that are all weakly supervised, they're all changing.

43:52.760 --> 43:53.760
Okay.

43:53.760 --> 43:56.600
And the question of how you manage that all in one big model, I think is fascinating.

43:56.600 --> 44:01.160
So there's the kind of the modeling aspect of that multi-task, but also what is that

44:01.160 --> 44:05.600
training data come from and these labeling functions could help contribute to that as

44:05.600 --> 44:06.600
well?

44:06.600 --> 44:07.600
Exactly.

44:07.600 --> 44:08.600
Yeah.

44:08.600 --> 44:09.600
Yeah.

44:09.600 --> 44:10.600
And I think that that's also, again, on the system side, what's really interesting is,

44:10.600 --> 44:16.320
how do you, you know, if you, if you have people, again, it's just a big shift, right?

44:16.320 --> 44:21.640
Right now, you know, training data is, a new training data set takes, you know, months

44:21.640 --> 44:24.960
minimum to put online for a real world problem, right?

44:24.960 --> 44:30.600
And a training set can be created in hours or days, and you're going to have tens or

44:30.600 --> 44:31.600
hundreds of them.

44:31.600 --> 44:32.600
How do you manage that?

44:32.600 --> 44:33.600
Right.

44:33.600 --> 44:36.720
And so that's, again, we think there are all these interesting questions around organizational

44:36.720 --> 44:40.280
level management of new training sets that are weakly supervised.

44:40.280 --> 44:41.520
How do you put them all together?

44:41.520 --> 44:44.000
How do you amortize costs across them?

44:44.000 --> 44:48.520
We think this, you know, MTL line of thinking is one answer to that, along with our existing

44:48.520 --> 44:49.520
work on snorkel.

44:49.520 --> 44:53.240
Well, Alex, thanks so much for taking the time to chat with me about this stuff.

44:53.240 --> 44:55.080
Thank you so much for having me on the show.

44:55.080 --> 44:56.080
Great stuff.

44:56.080 --> 44:57.080
Very fun.

44:57.080 --> 44:58.080
Thank you.

44:58.080 --> 44:59.080
Awesome.

44:59.080 --> 45:00.080
Thanks so much.

45:00.080 --> 45:01.080
All right, everyone.

45:01.080 --> 45:03.480
That's our show for today.

45:03.480 --> 45:08.360
For more information about today's guests, or to follow along with our AI Platform's Volume

45:08.360 --> 45:14.480
2 series, visit twimmelai.com slash AI Platforms2.

45:14.480 --> 45:19.680
Thanks once again to SIGUP for their sponsorship of this series and support of the show.

45:19.680 --> 45:24.840
To check out what they're up to and take advantage of their exclusive offer for Twimmel listeners,

45:24.840 --> 45:28.680
visit twimmelai.com slash SIGUP.

45:28.680 --> 45:58.640
As always, thanks so much for listening and catch you next time.

