WEBVTT

00:00.000 --> 00:16.880
All right, everyone. I'm here with Gustavo Malcoms. Gustavo is a research engineer at Intel

00:16.880 --> 00:22.880
by way of their recent acquisition of Sigopt. Gustavo, welcome to the Twomol AI podcast.

00:23.520 --> 00:28.080
Thank you very much for having me in the show. Hey, I'm really looking forward to

00:28.080 --> 00:33.680
digging into our interview. But of course, I'd like to have you share a little bit about your

00:33.680 --> 00:38.960
background and give our audience an opportunity to get to know you better. Tell us a little bit

00:38.960 --> 00:46.960
about your journey to machine learning and AI. Awesome, absolutely. Well, first, I'm originally from

00:46.960 --> 00:55.360
Brazil. I'm a computer science by training. And when I did my undergrad, I went to a very good

00:55.360 --> 01:03.040
school in my region. But machine learning wasn't a strong topic. But fortunately, the internet was

01:03.040 --> 01:12.080
very generous with machine learning. We had the opportunity to basically watch Professor

01:12.080 --> 01:22.400
Angel Ng to talk about machine learning on YouTube 12 years ago, I think. So my friends and I

01:22.400 --> 01:28.480
created a study group to study machine learning. And maybe I can say that he was my first

01:28.480 --> 01:35.680
instructor to the topic. After that, I pursue, I work in many machine learning projects. I decided

01:35.680 --> 01:45.680
to do my PhD in the US. I remember checking all the faculties that I could work with that worked

01:45.680 --> 01:52.560
with machine learning and counting how many publications they had on Isomal and Neroops.

01:54.000 --> 01:58.000
I don't recommend this to be a metric to consider when you're choosing between grad schools.

01:58.960 --> 02:04.400
But seven years ago, or something, I was super excited about working with people who actually

02:04.400 --> 02:10.000
did machine learning. And that's one of the things that I actually evaluate. It seems silly to say

02:10.000 --> 02:19.520
now. And then that's how I began my journey into the field. And you ended up for grad school

02:19.520 --> 02:24.640
here in St. Louis at Wash You. Is that right? Yeah, exactly. I went to Wash You under the

02:24.640 --> 02:31.040
supervision of Professor Romanger Net. I was actually very fortunate to work with many intelligent

02:31.040 --> 02:36.880
researchers throughout America here. Of course, my advisor being one of them. But also Professor

02:36.880 --> 02:43.360
Ben Mosley, which is now at CMU, Professor Kylian Weinemberg, who is now at Cornell.

02:44.800 --> 02:49.600
So I was very happy with all the collaborations that I did for out of America here. And I continue

02:49.600 --> 02:56.800
to do so. And you mentioned your school in Brazil, where was that? It was the University, the

02:56.800 --> 03:02.240
Federal University of Seattle. In Brazil, the Federal universities are typically very good.

03:02.240 --> 03:12.080
And that's basically it. And that's North East, like Fort Eliza. Exactly. Good to know that.

03:13.680 --> 03:20.400
We had like the World Cup in my city, too. One of the big games was there. Of course,

03:20.400 --> 03:24.640
as a Brazilian, I don't want to remember the World Cup in Brazil, because we lost.

03:24.640 --> 03:34.880
That's 721 to Germany. Yeah. Nice. Nice. And for your graduate work, what did you study?

03:34.880 --> 03:40.160
What was your dissertation on? Of course, yeah. So as I said, like I worked with different

03:40.160 --> 03:46.880
topics in machine learning. Mass scale, clustering was one of them, multi-agents. But I felt in

03:46.880 --> 03:52.000
love with this topic that I like to call active learning. So my dissertation was about

03:52.000 --> 04:00.160
how we can use active machine learning to create better tools for machine learning itself.

04:00.160 --> 04:06.000
It's kind of like an automated machine learning scenario. And specifically, I think that my

04:06.000 --> 04:11.600
many areas of expertise is how we can actually make decisions under the face of uncertainty.

04:12.240 --> 04:18.080
That's what I typically call active learning. Any kind of decision tool, any kind of decision

04:18.080 --> 04:24.960
problem that we have to solve, where we want to gather new data to accomplish a specific task.

04:26.160 --> 04:34.000
And I've done this for a hearing project, where we improve the performance of a screening test

04:34.720 --> 04:44.160
for audiometry. That was very, very cool. It's under the same setting. To do model selection

04:44.160 --> 04:51.200
with the same pipeline, where you actively select models to train. And of course, with Bayesian

04:51.200 --> 04:58.400
optimization, which is what I've been doing since grad school, but also in my work at SIGOPT,

04:58.400 --> 05:04.800
how we can make effective decisions to optimize functions very, very fast, specifically black box

05:04.800 --> 05:13.920
functions. And we'll be digging into that topic in quite a bit of detail as we talk through your

05:13.920 --> 05:20.880
spotlight paper at ICML, which is beyond the Pareto efficient frontier, constraint active search

05:20.880 --> 05:28.640
for multi-objective experimental design. It is a long name and we'll unpack that name. But before

05:28.640 --> 05:36.720
we do, you reference active learning. You also reference it in the paper. But my sense is that you

05:36.720 --> 05:46.400
think of it in a slightly different way than is commonly construed. So when I think of active

05:46.400 --> 05:55.680
learning, I think of machine learning approach or algorithm that takes an active approach to data

05:55.680 --> 06:06.880
selection so that the model can be trained in a more sample efficient way to put it simply. But

06:06.880 --> 06:14.080
you think of active learning in a much more broad way, I think? Can you kind of connect the two?

06:14.080 --> 06:21.600
Yeah, of course, absolutely. You're perfectly right. Most famous examples of active learning are

06:21.600 --> 06:28.720
when you have a model and you want to select training data to create this model faster.

06:28.720 --> 06:34.720
When I mean by create, I mean, achieve some accuracy faster than if I used a whole data set.

06:36.160 --> 06:41.200
I basically want to make smart decisions about my training samples to avoid waste of resources.

06:43.120 --> 06:48.960
I think in real life, there are like many opportunities where we can use the same setting,

06:48.960 --> 06:56.320
the same tools and the same mechanism to solve more broad problems. So in the case of optimization,

06:57.200 --> 07:03.760
the data that we're going to collect are is basically parameter configurations that we can test

07:03.760 --> 07:10.880
and evaluate if they are helpful for our application, which the goal is not to improve accuracy,

07:10.880 --> 07:16.160
but it will be to, well, it could ultimately be, but typically will be to maximize the function.

07:16.160 --> 07:22.720
So any kind of sequential decision making tool, we can also call sequential decision making,

07:22.720 --> 07:28.240
but train all machine learning. I like to think that active learning is as broad as supervised learning,

07:28.240 --> 07:34.000
reinforcement learning. We can think about this very general framework that any time that we are

07:34.000 --> 07:42.320
collecting data, we can do so in an efficient way to achieve a specific goal. So three examples

07:42.320 --> 07:48.720
are, well, one tip collective learning where your goal is to give information about your model

07:48.720 --> 07:54.560
faster, that ultimately would be the case if I'm trying to learn this decision boundary,

07:54.560 --> 08:00.720
very, very fast, typical case, Bayesian optimization where we want to optimize functions.

08:00.720 --> 08:06.080
So the data is the parameter configurations and the goal is to find highest values.

08:06.080 --> 08:11.840
And another example is drug discovery where you want to find new components or biology,

08:12.800 --> 08:20.160
you want to find new chemicals to achieve some properties and or perhaps even more broadly

08:20.160 --> 08:27.600
experimental design where you want to understand the whole of the physical phenomena very, very fast.

08:28.160 --> 08:32.480
You can say that active learning is kind of science more generally. We are all,

08:32.480 --> 08:38.640
or every time building models and collecting new data to validate those models. So that's kind of

08:38.640 --> 08:44.160
my general idea for that. I know that I talk about different subjects, but I'm happy to clarify

08:44.160 --> 08:56.000
any of them. You mentioned the, you mentioned this chemical engineering scenario example,

08:56.000 --> 09:04.480
and that was one of the background problems or motivations for this paper. Can you tell us a

09:04.480 --> 09:08.800
little bit about the problem that you were trying to solve that led to the work discussed in the

09:08.800 --> 09:15.280
paper? Yeah, of course. So first, this is a joint work with my colleagues at TIGOPT, Harvey Chen,

09:15.280 --> 09:21.200
Eric Lee, and Michael McCourt. In Harvey and Mike, they had this collaboration with

09:21.200 --> 09:28.160
members of the University of Pittsburgh, the laboratory of advanced materials at Pittsburgh,

09:28.160 --> 09:35.120
directed by Professor Paul Lu at the University of Pittsburgh, and they have been collaborating

09:35.120 --> 09:41.520
with this idea of creating new materials using machine learning. It's specifically, they are

09:41.520 --> 09:49.760
interested on creating new types of glasses that can improve the performance of, for example,

09:49.760 --> 09:58.400
solar panels. The idea is to have durable, anti-reflective, anti-soiling, self-cleaning glasses

09:58.400 --> 10:06.000
for solar modules. Basically, the problem is you want to improve the efficiency of solar panels

10:07.200 --> 10:13.680
by changing the properties of the glass. You don't want, for example, glass or reflection in the glass,

10:13.680 --> 10:20.560
because the lights will, the light bulb bounces, will basically bounce off of the glass, and you

10:20.560 --> 10:27.280
basically will be losing energy. Also, if the glass is dirt, that's a problem too, because it

10:27.280 --> 10:34.720
blocks the light to coming to the solar panel, and you also lose efficiency. What the researchers

10:34.720 --> 10:40.960
from the University of Pittsburgh they work with is creating like small structures, nano

10:40.960 --> 10:48.800
structures on the top of this glass, to change the properties of light, and therefore,

10:48.800 --> 10:55.600
improve the performance of the solar panel. The idea is, and this is very common in many

10:55.600 --> 11:02.080
different material sciences and other types of science work, is they have numerical simulations,

11:02.080 --> 11:07.280
they construct designs, they can fabricate designs using computer simulation,

11:07.280 --> 11:17.760
and using the software they can undercentrate ops for ultimately creating a structure in real life.

11:18.400 --> 11:23.120
What we have observed is that this is very different. It's very different to create

11:23.920 --> 11:28.000
new material in the computer versus creating a new material in the real life.

11:28.960 --> 11:34.000
And the reason for that is, in the numerical simulation, we don't have all the properties.

11:34.000 --> 11:39.040
We cannot perfectly simulate everything. There's a correlation. We can't get a lot of this,

11:39.040 --> 11:43.760
but ultimately, the equipment that we're going to use to produce the materials will be

11:43.760 --> 11:50.640
slightly different. We don't have like infinite precision, or something different happens in real

11:50.640 --> 11:57.440
life, because that's how real life is. That being that the simulation is producing a set of candidates,

11:57.440 --> 12:02.320
but you ultimately have to fabricate some small number of those candidates and see how they

12:02.320 --> 12:09.040
perform in the real world. Perfect. That's exactly it. We have this human in the loop. That's a very

12:09.040 --> 12:16.400
common term right now that basically requires the machine learning tool to assist the decisions

12:16.400 --> 12:21.840
that the human expert that knows everything about the problem, knows everything about the domain,

12:21.840 --> 12:28.000
can ultimately do and select. I think that's the main inside that we want to bring to this

12:28.000 --> 12:35.280
paper, talking in a real high level. There is a development scenario, there is a production

12:35.280 --> 12:41.600
scenario, and there's probably a discrepancy. And ultimately, there is a human in the process,

12:41.600 --> 12:48.240
doing supervision of the whole decision making, and being powered by the experimentation process

12:48.240 --> 12:54.000
that we do offline, but which eventually will be very costly to do in real life.

12:54.000 --> 13:05.920
Let's maybe return to the title of the paper and start to unpack some of that so we can dig deeper

13:05.920 --> 13:11.680
into what you've actually done. Again, the paper is beyond the Pareto efficient frontier

13:11.680 --> 13:17.840
constraint active search for multi-objective experimental design. It sounds like the problem

13:17.840 --> 13:25.120
that you're seeking to tackle is multi-objective experimental design. How does that relate to the

13:26.160 --> 13:36.480
scenario that you just outlined for the materials? Yeah, so material, experimental design is basically

13:36.480 --> 13:43.360
the field that do with smart decisions about designs, and the designs could be like many different

13:43.360 --> 13:49.280
things. It could be actually a whole experimentation pipeline in a lab. In our case, just to give like

13:49.280 --> 13:54.000
think, just to give with a real example, it's going to be the structure that we want to really

13:54.000 --> 14:02.240
create on top of the class. The column, the box size, all the properties that we can actually

14:02.240 --> 14:06.720
use to create those structures. That's the experimental design part.

14:06.720 --> 14:16.000
Multi-metric, it's because in many problems in real life, it's very, very hard to find one thing

14:16.000 --> 14:21.440
that we care about. So there are competitive objectives. If we change all the light to reflect

14:21.440 --> 14:31.600
on this glass, another property will be different. Transparency, oil contact, cleanness, all those

14:31.600 --> 14:37.440
things really related to the subject will change. And ultimately, they will be competitive.

14:38.560 --> 14:42.960
That, what typically makes the optimization problem a little bit harder.

14:44.000 --> 14:50.720
And one thing to highlight here, which is very general, is the way that we're doing experimentation

14:50.720 --> 14:56.960
is really for smart decisions. We don't have access. We are solving an optimization problem,

14:56.960 --> 15:02.880
which is black box. We will really run the simulation to get an output. But we don't have access

15:02.880 --> 15:09.520
to gradients, for example. So it's really like a black box that we put inputs and we receive

15:09.520 --> 15:17.040
outputs back. We want to design experiments, basically designing put configurations that will give

15:17.040 --> 15:22.000
good results on the outside here, on the the Y-values. If you're talking about the optimization,

15:22.000 --> 15:28.320
we're trying to optimize, minimize or optimize one of those goals. Now, the Pareto efficient

15:28.320 --> 15:36.720
frontier, it's basically how we try to solve multi optimization problems, multi metric optimization

15:36.720 --> 15:48.080
problems. We traditionally want to find output values that can dominate the other ones.

15:48.080 --> 15:53.840
The hypothesis here is that we cannot compare the two metrics. For example, risk and return,

15:53.840 --> 16:01.200
if we're talking about finance. And there's no really like solution for this. It's really

16:01.200 --> 16:08.080
dependent on the user to decide the level of risk and the level of return it's willing to take.

16:08.960 --> 16:14.160
So in that sense, all the configurations that we can return to the customers that

16:14.160 --> 16:21.680
dominate the other ones. So if I can improve my return without reducing the risk, that's better

16:21.680 --> 16:26.320
than a suboptimal configuration that has the same risk level, but a lower return.

16:26.960 --> 16:31.280
I would want this, it doesn't make sense. So I would actually have the dominate solution,

16:31.280 --> 16:36.000
which has a higher return, but the same level of risk. That's how we construct the Pareto

16:36.000 --> 16:45.040
efficient frontier. And this makes a lot of sense if you're probably choosing maybe stocks. But in

16:46.400 --> 16:53.440
problems that we're trying to understand the metric values and the parameters, we really want to

16:53.440 --> 16:59.920
focus on the search aspect, what I mean by this. For a scientist, for example,

16:59.920 --> 17:06.160
they will be very happy if we give them a material that has very nice properties.

17:06.720 --> 17:13.040
But they will be very confused if we change the parameters that create this design,

17:14.080 --> 17:22.640
it's lily, and the results is really bad. So they're looking for really a broader sense of what's

17:22.640 --> 17:27.280
happening here, not only with the metric values, but also with the parameters. Ultimately,

17:27.280 --> 17:34.160
they want these stable parameters that can lead to consistent results. Why? Because as I said,

17:34.720 --> 17:41.520
the production and the development and the production settings won't be a perfect match.

17:42.160 --> 17:48.080
They really want consistent results. That's the motivation for why we're talking about an

17:48.080 --> 17:54.240
alternative to this multi-objective solution for experimental design. It's because people care

17:54.240 --> 17:59.680
about both the metric values, but the parameter values. They want this stability. They want to

17:59.680 --> 18:09.520
understand the problem they're trying to solve. Let me try to replay that so that I make sure I'm

18:09.520 --> 18:16.800
understanding it and we're all on the same page. You've got this note of the Pareto,

18:16.800 --> 18:21.840
Efficient Frontier. We know it from finance and economics and problems like that. And that says

18:21.840 --> 18:28.560
that in the case of a two-dimensional relationship, there's a line that is your

18:29.520 --> 18:40.080
optimal trade-off among these values. And what you're suggesting is that in the real world,

18:40.080 --> 18:47.440
for example, when you're designing a material, a value on this Pareto, Efficient Frontier,

18:47.440 --> 18:58.000
might be optimal from the perspective of the metric, but it might be unstable. You know,

18:58.000 --> 19:07.360
if we think about kind of the chart of the optimal, like a curve, it might be sitting on a spike.

19:07.360 --> 19:15.680
And so if you shift one of your parameters, your metric might drop off precipitously,

19:15.680 --> 19:22.560
whereas something that is theoretically less optimal might be sitting on a broader base.

19:22.560 --> 19:30.800
And I think ultimately, the result is it would be easier to produce in the real world because

19:30.800 --> 19:37.920
it's not quite as unstable. Is that the idea? That's the idea. If you think about, like,

19:38.800 --> 19:42.720
I think when we're talking about optimization, it's very common to think about climbing a mountain,

19:42.720 --> 19:46.720
right? Of course, in our scenario here, we don't have derivatives,

19:47.440 --> 19:53.360
but we can theoretically find blocks. Yeah, because it's a black box, but you can theoretically

19:53.360 --> 19:59.200
think about a surface of function values that exist. And we can pretend that this is like a mountain.

20:00.240 --> 20:03.360
And the metric values will be basically the height of this mountain.

20:04.000 --> 20:10.560
Right. So in a multimetric problem, it's kind of like we're trying to find the optimal of

20:10.560 --> 20:16.880
the function values between two mountains, let's say there is a mountain number one, which is one

20:16.880 --> 20:24.800
metric, there's a mountain number two, which is the second metric. In a multi metric optimization

20:24.800 --> 20:28.720
problem, we want to find really the peak of the mountain, the highest value possible.

20:29.520 --> 20:35.520
And the Pareto-efficient Frontier will be basically aligned between those two mountains

20:35.520 --> 20:42.400
on paramere space. That's exactly the Pareto-efficient Frontier on metric values, how they will be

20:42.400 --> 20:47.760
translated to the paramere space. It's going to be a line. If I navigate towards the outer mountain,

20:47.760 --> 20:51.600
I'm going to reduce the metric values here, but I'm going to improve the metric values here.

20:52.480 --> 20:56.320
Okay. So what we are trying to, yeah, to jump in there, the

20:57.520 --> 21:03.680
dimensionality of the parameter space is like the numbers, the number of dimensions of your mountain

21:03.680 --> 21:08.400
essentially, and then the number of metrics is the number of mountains. In some sense, yes.

21:08.960 --> 21:13.280
Okay. That's a very good analogy. Yeah. So in this case here, we're talking about two and two,

21:14.080 --> 21:20.080
but it could be, you know, in a more, like in a higher, in a more complicated surface

21:20.880 --> 21:28.880
in the world, will be like a three-dimensional shape. But anyway, the point is, if we have two

21:28.880 --> 21:35.280
metrics, you know, there is one optimal value here, another optimal value here. The Pareto-efficient Frontier

21:35.280 --> 21:42.720
was going to be aligned that trades those two off. Now, what we are saying is, okay, this is only true

21:42.720 --> 21:47.360
during our development setting. You find the optimal values here, doing your numerical simulation.

21:48.080 --> 21:55.760
But what if the mountain shifts a little bit? The line was going to be completely different. So,

21:55.760 --> 22:02.080
do I really want to return to the to the expert, to the human, only the points that could be,

22:02.800 --> 22:08.480
you know, sub-optimal in the real life, because the the mountains can shift a slightly.

22:09.200 --> 22:13.760
The answer is no. We probably want to give them like a more information. We want to give them

22:13.760 --> 22:19.680
enough information so that even if the mountains change a little bit, you will still be comfortable

22:19.680 --> 22:25.520
with the results that you get. Does that make sense? Yeah, I guess it raises a question for me.

22:25.520 --> 22:37.360
Are we trying to, is the idea fundamentally that we're going to be less restrictive in the values

22:37.360 --> 22:43.840
that we return? We're going to be looser and allow the human and elope to, you know, because we

22:43.840 --> 22:48.720
know there's a human and elope, they can determine ultimately what's the best point for them. Or is it

22:48.720 --> 22:57.680
that somehow that the algorithm that you've created also incorporates stability and returns

22:57.680 --> 23:05.440
better points that aren't on the Pareto efficient frontier? That's a distinction I'm getting

23:05.440 --> 23:09.920
on. Yeah, it's definitely different. I totally agree with that. And I would say it's the former.

23:10.480 --> 23:14.560
Okay. In the let the the second option, the latter could be our next paper.

23:14.560 --> 23:22.960
But it's more on the former. In the sense that we do we will do exactly what you describe. We're

23:22.960 --> 23:30.000
going to lose the definition of best to not really the peak and top of the mountain. But you know,

23:30.000 --> 23:35.760
to altitude that is good enough. So we're going to have like the whole shape of the top of the

23:35.760 --> 23:41.120
mountain. And we're going to offer this to the user somehow. That's the part that it's the problem

23:41.120 --> 23:46.320
formulation aspect of this. We are generalizing something called Bayesian optimization,

23:46.320 --> 23:51.520
which really cares about the highest values and the experimental design, which wants to understand

23:51.520 --> 23:57.360
the whole mountain, all the shapes and you know configurations of the mountain.

23:58.480 --> 24:05.120
Sorry. Constrain active search, which is exactly the problem that we are proposing to solve.

24:05.120 --> 24:10.720
It's really a search problem in the sense that we want to find structures in the parameter space

24:11.760 --> 24:17.360
in the executive learning pipeline, which are constrained, constrained by metric values.

24:18.000 --> 24:24.480
Specifically in the paper, we say that there is a region of satisfaction or a sex,

24:24.480 --> 24:31.920
sex, sex factory region where it's the parameter configurations that lie above the metric values.

24:31.920 --> 24:38.080
You can also think about this feasible region, but typically feasibility means that we have

24:38.080 --> 24:43.120
constraints on the parameters. And for some reason, we don't want the parameters that are not

24:43.120 --> 24:48.960
feasible, right? Here, we are really losing the problem from the optimization to something that

24:48.960 --> 24:55.600
is not the best, but it's a set set set, it's a set's fight of constraints. So feasibility typically

24:55.600 --> 25:01.040
speaks to the parameters satisfaction. In this case, you're more speaking to the metric or the

25:01.040 --> 25:06.880
objective. Exactly. We want to load the definition of what is best on the metrics. And again,

25:06.880 --> 25:13.280
this is black box. We don't have this beforehand. So again, with the example of the mountain, we want

25:13.280 --> 25:18.080
the whole shape of the top of the mountain, not necessarily the peak best value.

25:19.680 --> 25:26.960
And thinking about it in the context of the mountain, what's the relationship between

25:26.960 --> 25:37.520
the satisfying construct that you're creating and the idea of global optimal versus local

25:37.520 --> 25:42.480
optimal, that kind of thing? Is the thing that connects those the idea of stability that we talked

25:42.480 --> 25:51.120
about earlier? In some sense, yes. Because the optimal values will be within the satisfactory

25:51.120 --> 25:59.120
region. So we're just expanding the notion of what it's good to more values based on the constraints

25:59.120 --> 26:05.840
that the user gave us on the metric values. So for example, suppose that we want to find a

26:05.840 --> 26:14.880
high-performing machine learning models. And we care about accuracy, but also inference time.

26:14.880 --> 26:21.760
I want to give you a list of different models and diversity he hears the key for a constraint

26:21.760 --> 26:29.280
active search that have that satisfy your constraint on accuracy above 80% and inference time,

26:30.800 --> 26:37.920
less in a minute, let's say, hopefully way less than that. But I'm going to give you an option,

26:37.920 --> 26:41.600
the solution for this problem is going to be a list of options that you can trade them off,

26:41.600 --> 26:48.320
both in terms of the metric values, but also one of the choices of hyperparameters that you have.

26:49.840 --> 26:56.160
For example, number of trees, if you're talking about exuboost, and all kind of like

26:57.040 --> 27:01.520
any kind of parameter that you think is important for creating a machine learning model,

27:01.520 --> 27:03.120
which are the hyperparameters.

27:03.120 --> 27:12.400
Okay, okay. And so you've created this, you've kind of redefined or defined a new problem

27:13.440 --> 27:19.760
constrained active search. Do you also share any insights into how to solve the problem?

27:19.760 --> 27:25.280
Yeah, absolutely. That's the main difference between the workshop paper that we have published

27:25.280 --> 27:31.600
like a couple of months ago, less here. And the, you know, in a full publication that I

27:31.600 --> 27:39.360
said, well, it's the fact that we have a solution for this problem. So I hope it's very clear

27:39.360 --> 27:44.960
that like why I'm stressing the problem is because it's a different mentality. We're changing the

27:44.960 --> 27:50.880
focus from getting the best possible values to getting high performing values, high performing

27:50.880 --> 27:57.840
models, high performing designs, which means that I can accept in a continuous space a bunch of

27:57.840 --> 28:06.960
new points. And if I, I can change slightly the same configuration and or parameter and get

28:06.960 --> 28:12.880
the same results. So that's something that it doesn't make sense mathematically. So you want to

28:12.880 --> 28:17.600
incorporate something which is diversity. And I think this is really, really important for many

28:17.600 --> 28:23.680
real life applications, especially in, and I can talk more about this next in the context of

28:23.680 --> 28:30.480
developing machine learning models, developing real materials in real life. But to the technical

28:30.480 --> 28:36.400
aspect of the work, we use something called Bayesian decision theory to derive an algorithm

28:36.400 --> 28:42.640
for solving this problem. And as I said, the main property of this problem is we want to find a

28:42.640 --> 28:49.840
set of solutions in continuous space. So we want those solutions to be different in primary space.

28:49.840 --> 28:56.080
We don't want to lead to the same design. If I show this to a scientist, you know, a box of,

28:56.080 --> 29:03.520
you know, this nano structure that I've changed like one nanometer up or or left or, you know,

29:03.520 --> 29:08.880
the cone in the height of the cone or the shape. Lively they would say like, yeah, this is the

29:08.880 --> 29:13.920
same thing. I don't care about that. I can't even produce this difference. That's also important.

29:13.920 --> 29:20.560
But anyway, the way that we focus on solving tackling this problem is defining something called

29:25.360 --> 29:32.480
utility function, which defines how our active learning, active search algorithm

29:33.360 --> 29:42.560
will select the next configuration. So to give you an example in optimization, what we typically

29:42.560 --> 29:50.160
care is if I have a configuration that has this value here, I care about new configurations that

29:50.160 --> 29:57.200
can improve the value that I have observed. So this leads to a policy that is expected improvement.

29:57.200 --> 30:05.280
How much I can improve over over the last of function value. We don't care about the best values

30:05.280 --> 30:10.480
per se. We care about two things in this problem. We want to satisfy the constraints. That's the very

30:10.480 --> 30:17.840
first important thing. And two, we want the solutions, the parameters that we select, the designs

30:17.840 --> 30:25.120
that we select to be different. So if I choose two new configurations that satisfy the constraints

30:25.120 --> 30:30.160
but they're very close to each other, I don't want this. So we define something called the

30:30.160 --> 30:37.360
neighborhood of a point. So any configuration that we choose in primary space will basically

30:37.360 --> 30:44.000
induce a volume on primary space. And this volume is exactly what I want to increase. I want to

30:44.000 --> 30:50.640
increase the coverage of my configurations where coverage I'm defining as the volume on

30:50.640 --> 30:57.360
primary space that is potentially above the threshold. That's something complicated. I

30:57.360 --> 31:02.640
definitely recommend you to see the details or your audience to see the details on the paper.

31:02.640 --> 31:08.640
But that's the intuition. We want points above the constraints that satisfy all the constraints.

31:08.640 --> 31:13.680
And we want points that are not too close to each other so that they can lead to diversity.

31:14.800 --> 31:21.760
And you said that this is a complicated part but when you talk about the threshold is that a

31:21.760 --> 31:37.120
threshold, meaning the union of the volumes around the individual points and the degree to which

31:37.120 --> 31:44.560
that coverage your entire space or as the threshold specific to each point in the primary space.

31:45.840 --> 31:49.920
The threshold that I mentioned was specifically to the metric values.

31:49.920 --> 31:55.840
Okay. So basically is the level if you go back to the mountain again.

31:55.840 --> 32:00.640
Right. And I'm going to use my fingers here to point out and I definitely recommend you to check

32:00.640 --> 32:08.640
out the paper which we have better visualizations for that. But if we talk about the top of the

32:08.640 --> 32:13.920
mountain, we are chopping off the top of this mountain in some region. So the shape could be

32:13.920 --> 32:21.200
really pointy or the shape could be like really wide. So the threshold really defines the shape

32:21.200 --> 32:29.520
here, the level that we want to cut off the mountain. Now the the coverage that I was talking

32:29.520 --> 32:34.960
about is really like if I want to place a point here in this side of the this is funny.

32:34.960 --> 32:39.040
If I want to place a point on the top of this, I basically want to solve a packing problem.

32:39.040 --> 32:42.480
I want to know how many configurations I can place on the top of this mountain.

32:42.480 --> 32:45.680
Got it. In the way that it covers the whole

32:46.320 --> 32:49.520
primary space. Got it. Got it. Does that make sense?

32:52.080 --> 32:58.640
Packing or a tessellation, you want to pick your points to maximize the coverage of the

33:00.240 --> 33:03.760
I guess this part of the mountain that you've cut off. Exactly. Exactly.

33:04.400 --> 33:10.320
And you define the points by some kind of radius around the points.

33:10.320 --> 33:17.040
Right. In our algorithm specifically, we have a parameter that we call radios are

33:17.760 --> 33:24.800
which defines in your application, how much you you care about distance. So

33:25.680 --> 33:29.680
basically this parameter is telling me that if you find two configurations that are too close

33:29.680 --> 33:33.280
according to this distance, that's exactly what this parameter is measuring. I don't care

33:33.280 --> 33:37.840
about this. This does increase my knowledge about the problem. Yeah. So those radios define the

33:37.840 --> 33:45.360
minimal level of proximity that you can have between two points. And again, the top of this

33:45.360 --> 33:50.720
mountain, this region that we want to cover is really the region of parameter configurations

33:50.720 --> 33:55.840
that yields high performing values. Right. Right. Right. And

33:59.200 --> 34:05.760
is there just out of curiosity, I'm wondering to what degree you could

34:05.760 --> 34:12.480
characterize the total volume of the top of the mountain. And could you

34:14.800 --> 34:20.400
could you like back your way into R by saying you want, you know, 20 points and you know the

34:20.400 --> 34:25.600
volume of the top of the mountain. And so like divide the volume of the mountain by R.

34:26.160 --> 34:30.960
I'm sorry, divide the volume of the mountain by the number of points and kind of back into your

34:30.960 --> 34:35.200
R value. Or do we are there things there that we don't know or can't figure out or are really

34:35.200 --> 34:40.160
difficult. Right. That's an excellent question. But the setting is we don't know.

34:41.120 --> 34:47.600
Basically, we construct, um, probabilistic models that talk about the surfaces of the

34:48.320 --> 34:54.400
objective functions that we want. Basically, and the surrogate model, the probabilistic model that

34:54.400 --> 35:01.440
we have is going to give us a notion of uncertainty of the shape of that we are trying to solve for.

35:01.440 --> 35:06.560
So nothing we didn't know for sure. We are actually discovering this through experimentation.

35:06.560 --> 35:13.120
We are increasing our knowledge or our ability to model the surface of the metric, metric values.

35:14.320 --> 35:20.240
And also really the region of satisfaction. So in reality, the utility that I just described

35:20.240 --> 35:27.920
is true, fixed the mountain shape, if you will. But what we really implement is the expected

35:27.920 --> 35:33.280
gain in utility, which takes in consideration our uncertainty around the surface.

35:34.720 --> 35:40.240
Okay. So if you're asking about how many points I can place, it's really through experimentation.

35:41.120 --> 35:44.640
The more points you give us, the better to solve the problem.

35:46.160 --> 35:52.400
There is a rule of thumb of, you know, 20 to 30 times the dimension of gain put.

35:52.400 --> 35:59.360
It's a good number. Um, if we really have good priors to match our problem, but theoretically,

35:59.360 --> 36:02.400
this could be way, you might need more, way more points.

36:04.000 --> 36:11.040
And you've mentioned Bayesian optimization previously. And you know, now we're talking about surrogate

36:11.040 --> 36:17.280
models and priors. Can you talk about where Bayesian optimization fits into this and how?

36:17.920 --> 36:19.520
And where the surrogate models come from?

36:19.520 --> 36:28.240
Exactly. Yeah, absolutely. So I think it's, that's, let's think about like the complexity of those

36:28.240 --> 36:36.320
problems. If I want to solve a single problem, just one metric, I'm going to do Bayesian optimization

36:36.320 --> 36:41.280
to find the highest, the best values, what I'm going to do. I'm going to create a surrogate model

36:42.480 --> 36:47.440
that does this inference over the function values that I haven't observed yet. And I'm going to

36:47.440 --> 36:53.680
create an acquisition function, which, as I said, could be, it's basically a policy that tell us

36:53.680 --> 37:00.560
which point I'm going to choose next. When I'm talking about multi-matric problems, I can also

37:00.560 --> 37:04.880
use Bayesian optimization. I can also use Bayesian optimization with constraints. But again,

37:04.880 --> 37:09.520
everything that I'm focused here is to construct surrogate models, one for each metric.

37:09.520 --> 37:18.800
And trying to find the hypervolume of the Pareto Frontier. Again, the Pareto Frontier is this region

37:18.800 --> 37:25.120
of dominate points. The hypervolume, it's a metric that tells me if I increase the, the,

37:25.120 --> 37:30.240
the values, I will be doing a better job at finding the Pareto Frontier.

37:32.080 --> 37:38.080
The next step for this is, at least in my mind, well, there is a different problem that is

37:38.080 --> 37:42.800
important to highlight, which is called level set estimation. It's when I'm not interesting on the,

37:43.760 --> 37:51.360
the best values per se, but I'm interesting on finding the threshold really where the function

37:51.360 --> 37:56.720
values would change from the level that I stipulate, basically the constraints in this case.

37:57.520 --> 38:02.240
What we argue is constraint active search. It's a generalization of this.

38:02.240 --> 38:09.920
In hindsight, if you knew the best value, something that we don't know, but if you place the

38:09.920 --> 38:15.520
highest value, highest function value on the constraint active search formulation, we would

38:15.520 --> 38:20.880
recover Bayesian optimization. Because again, the definition will be just the peak of the mountain.

38:20.880 --> 38:25.280
I just want to return the best values. So I recover Bayesian optimization with this

38:25.280 --> 38:32.160
constraint active search formulation. The opposite of this is if I knew the minimum value of all

38:32.160 --> 38:38.880
the metrics, I could plug this in in my constraints in constraint active search, and I will recover

38:38.880 --> 38:44.160
a problem that is experimental design. It's really, I want to know the function values everywhere.

38:45.760 --> 38:49.520
Constraint active search is something in the middle. You choose the thresholds the way that you wish.

38:49.520 --> 38:55.280
And of course, we recommend you to do so in a conservative way because everything about the

38:55.280 --> 39:02.640
function we are learning on the fly. So if you start with, yeah, I was just going to say I'm not

39:02.640 --> 39:08.160
sure. I fully follow that, but I think in essence, what you're saying is that there's a relationship

39:08.160 --> 39:15.680
between this problem that you've articulated here constraint active search and other things that

39:15.680 --> 39:22.880
we've studied for a long time, Bayesian optimization, level set up estimation and experimental design.

39:24.640 --> 39:27.520
That's a digest. Yeah. Okay. Okay.

39:30.960 --> 39:41.360
And first, did we get through the kind of the explanation of the mechanism? I think we

39:41.360 --> 39:50.160
did get through it at least conceptually in talking about the volumes. If there's any pieces that

39:50.160 --> 39:56.400
we have not covered, jump in with those, but I'm starting to think about, okay, how do you

39:57.600 --> 40:05.040
assess performance here and measure the effectiveness of the method and what that even

40:05.040 --> 40:15.200
means in this context? Precisely. So for the algorithm, really, it's hard to talk more in details

40:15.200 --> 40:20.480
like in more details about it because you have to know some mathematical definitions of neighborhood.

40:20.480 --> 40:25.120
I think we covered the high level idea in a good sense, which is really trying to solve this

40:25.120 --> 40:32.800
packing problem in the high performing region of the primary space. Got it. But ultimately, we define

40:32.800 --> 40:38.800
utility function and we do something that we do in Bayesian decision theory. We select the action

40:38.800 --> 40:45.440
that maximizes my expected utility. And the utility is this volume that we define. The uncertainty

40:45.440 --> 40:52.640
on this utility is on the real region of satisfaction, which is, you know, the thresholds

40:53.920 --> 40:58.240
because we're using probabilistic models, we can compute what is the probability of any configuration

40:58.240 --> 41:06.240
to lie above the thresholds. And that's defined basically as a whole set of points in expectation

41:06.240 --> 41:12.880
that will be within the region of satisfaction. Okay. What was your next question? Sorry.

41:13.760 --> 41:20.800
So then what's what does evaluation look like? Exactly. So in our experiments, we were we tried to

41:20.800 --> 41:30.320
be very honest. We didn't try to, but basically we had multiple ways of looking how about the

41:30.320 --> 41:38.480
quality of those results. So we consider like four metrics. One of them is just the number of positive

41:38.480 --> 41:44.480
points that you get, the number of points above the threshold. If your problem is really,

41:44.480 --> 41:48.880
really difficult, that's something that you might care. But if you just optimize this metric,

41:48.880 --> 41:54.000
you might not get diversity, which I think I said, it's a very important thing in our problem.

41:54.000 --> 41:59.520
The second, the second angle that we can look at this is really what about the hypervolume?

42:00.480 --> 42:03.680
What about the quality of the points that we get above the threshold? Are they

42:04.240 --> 42:09.680
dominate points or not? This is what the hypervolume is measuring. It's a standard metric for

42:09.680 --> 42:18.080
optimization problems. But for our problem, what we really care is diversity of the points that lie

42:18.080 --> 42:24.160
above the threshold that satisfy the constraints. So we measure it in two ways. The very first one

42:24.160 --> 42:29.360
is using the field distance, which is a typical measure of diversity in many areas.

42:30.960 --> 42:39.840
It basically the radius of the largest ball you can place on the points that cover them. It's

42:39.840 --> 42:44.480
the largest radio that you can use to cover all the points. That's kind of the definition of full

42:44.480 --> 42:50.160
full field distance. And a new criteria that we use to tackle this problem, which is coverage

42:50.160 --> 42:58.720
recall, which is really how much volume I was able to recover from this satisfactory region.

42:59.280 --> 43:04.720
This is only possible to compute if we know the ground truth, of course. But it's definitely

43:04.720 --> 43:08.160
something that measures the success of constraint-active search.

43:08.160 --> 43:23.360
Yeah. And what kind of results did you see? Oh, yeah. We basically do. And maybe to jump in,

43:24.080 --> 43:32.320
are there, is the problem that you've defined close enough to existing problems that there are

43:32.320 --> 43:38.560
benchmarks that are relevant? Or is it mostly evaluation, mostly self-referential?

43:39.840 --> 43:47.360
Well, our goal with this experimentation setup was to show those formatrix and really highlight

43:47.360 --> 43:53.200
that different problems, different strategies are solving different things. So our algorithms,

43:53.200 --> 43:58.240
the algorithms that be proposed to solve constraint-active search. We actually proposed two or three

43:58.240 --> 44:05.040
alternatives. And they all do very, very well on coverage recall and field distance.

44:05.040 --> 44:11.200
Specifically, does the main algorithm that we propose, expected coverage improvement,

44:11.920 --> 44:17.920
is doing really well and minimizing the field distance and maximizing the coverage recall,

44:17.920 --> 44:24.000
which is exactly what we want. If we look at the angle of optimization, you will see that

44:24.000 --> 44:29.600
Bayesian optimization with multiple matrix will actually be the best because it's the only

44:29.600 --> 44:35.520
algorithm that is really trying to do that. And if we look at the number of sheer number of positive

44:35.520 --> 44:42.080
points, there's another line of research called active search, which optimizes the number of positive

44:42.080 --> 44:47.680
points. The downside of that approach is diversity is compromised. And this is true for both problems.

44:47.680 --> 44:54.000
Bayesian optimization doesn't have as much diversity as constraint-active search. Active search

44:54.000 --> 45:02.320
doesn't have the same ability to optimize hyper-volume, nor increase diversity as active search.

45:02.320 --> 45:06.080
It just finds a bunch of positive points and they are close together.

45:06.800 --> 45:13.040
Right. Restating Bayesian optimization will give you the points that are optimal we talked about,

45:13.040 --> 45:20.400
but not necessarily stable or diverse. Active search just gives you back a bunch of positive points,

45:20.400 --> 45:25.760
and so creates a lot of noise for the human and the loop to go through. Because the points are

45:25.760 --> 45:33.840
cluster together, it's not particularly meaningful distinctions. And so the diversity formulation

45:33.840 --> 45:39.920
and constraint-active search produces something that is much more useful in a real-world human

45:39.920 --> 45:44.960
and a loop scenario. Exactly. And I would like to dive deeper on that. Why do we think this is

45:44.960 --> 45:52.560
very useful? Just in benefit of active search, this is typically a solution that it's offered

45:52.560 --> 45:59.120
for discrete points. So if you have discrete points, maybe you should do active search,

45:59.120 --> 46:04.960
and they're very rare to find. In this scenario where we have parameters that are continues,

46:04.960 --> 46:09.520
then constraint-active search will be the best trade-off between finding good values,

46:09.520 --> 46:16.560
kind of the hyper-volume and diversity. Now if we go back to how this is really useful in practice

46:16.560 --> 46:24.000
when we have a human and loop, the reason for that is if we actually solve optimization problems

46:24.000 --> 46:32.400
and we offer experts the decision on the Pereiro-efficient frontier, they typically will think that they

46:32.400 --> 46:38.880
can choose metric values in the specifically in this case of design. They would try to see metric

46:38.880 --> 46:44.960
values that, you know, satisfy their preferences in some way. They will look at the function values here.

46:44.960 --> 46:50.000
Oh yeah, this configuration is really good. And I see a couple of points nearby. They have the same

46:50.000 --> 46:57.280
performance of this one. But the problem that they could face is when they map back to find what exactly

46:57.280 --> 47:04.000
what kind of how I'm going to produce this design. Maybe those metric values that were close

47:04.560 --> 47:10.160
here in the metric space could be really all over the place on the pyramid space. And this

47:10.160 --> 47:16.240
doesn't increase their confidence about the ability to produce a specific design with this height

47:16.240 --> 47:23.360
or this width. On the opposite, constraint-active search will provide not only points on the

47:23.360 --> 47:29.920
Pereiro frontier, but also a bunch of points in, they're not, they're like

47:31.360 --> 47:35.440
dominated by the points in the Pereiro frontier, but they are a bunch of points that in the

47:35.440 --> 47:40.880
primary space, they will offer you insights on how I can actually produce and create this design.

47:42.480 --> 47:48.560
That's one of the things we think this is important. The other one, it's really respect to the

47:48.560 --> 47:57.120
application. For example, some of those metrics that they care to, so basically we have this

47:57.120 --> 48:02.640
humidity loop. We want to use this experimentation to guide them their choices. Eventually they

48:02.640 --> 48:09.120
will choose five or ten designs to create to produce in real life. They will fabricate the

48:09.120 --> 48:15.280
designs. Diversity plays a really important role here because when we actually compute

48:15.280 --> 48:22.560
the designs, you can further measure properties of those designs. If they are all very different,

48:22.560 --> 48:27.680
then you can further do like a more expensive test to really find your best solution.

48:29.440 --> 48:32.960
Now, we can also translate this to machine learning in real life.

48:34.320 --> 48:39.840
Ultimately, we have business metrics that we care about, and the validation metrics that we use

48:39.840 --> 48:46.160
are a good proxy of what we can do during production, but maybe they're not perfect. What we

48:46.160 --> 48:53.440
wanted is offer users the possibility of having very different models so that they can use those

48:53.440 --> 49:01.520
models in a more complicated testing setting. For example, as a shadow of a current

49:01.520 --> 49:09.760
system or in an AB scenario where they want to evaluate things that they couldn't during development

49:09.760 --> 49:19.200
because the data is different. Having the ability to test more different models in the semi-production

49:19.200 --> 49:25.200
system is really, really helpful for them to make sure that the models that they created using all

49:25.200 --> 49:30.320
the metrics developed previously are actually helping them to achieve the business goals.

49:32.720 --> 49:40.000
So, returning to this theme of performance and development versus performance in the real world,

49:40.640 --> 49:46.480
but here in the broader machine learning application as opposed to the engineering application.

49:46.480 --> 49:58.880
Yes, exactly. Awesome, awesome. My next question would be to ask about where you go from here

49:58.880 --> 50:04.720
in future directions, but you already said that it's returning back to the objective and trying to

50:04.720 --> 50:11.520
understand stability for some of these points as one potential direction. Any other thoughts there?

50:11.520 --> 50:16.800
Well, this is a new formulation, so we are excited to invite researchers for a new community to

50:16.800 --> 50:24.480
think about different properties, different ideas. In this current formulation, we have this

50:24.480 --> 50:31.360
parameter R, which is something that is a function of your application. In real life, we can probably

50:31.360 --> 50:36.320
design a schedule for this parameter. We start with very large R values that will do a lot of

50:36.320 --> 50:42.800
exploration, and then we reduce the R values, so we can actually find a bunch of models more

50:42.800 --> 50:49.680
similar in some sense. We have some also theoretical understanding of the problem. We prove that

50:49.680 --> 50:57.040
this algorithm has a bound on the field distance, which means that it's able to converge in the sense

50:57.040 --> 51:04.560
of covering the satisfactory region, but you can also think about developing all the results,

51:04.560 --> 51:10.080
which we haven't done in this paper about how many other theoretical results, about the number

51:10.080 --> 51:17.280
of points that I need to at least get a notion of convergence closer to the results that we get

51:17.280 --> 51:25.360
on Bayesian organization. For example, yeah. Awesome, awesome. Bogusavo, thanks so much for

51:25.360 --> 51:31.120
taking the time to share a bit about your paper. Very interesting stuff. Thank you very much.

51:31.120 --> 51:35.120
We really appreciate it. That was a great conversation.

