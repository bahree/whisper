WEBVTT

00:00.000 --> 00:15.920
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

00:15.920 --> 00:20.880
people doing interesting things in machine learning and artificial intelligence.

00:20.880 --> 00:23.280
I'm your host Sam Charrington.

00:23.280 --> 00:26.920
The show you're about to hear is part of a series recorded at the Georgian Partners

00:26.920 --> 00:30.120
Portfolio Conference last week in Toronto.

00:30.120 --> 00:34.720
My guess for this interview is Kenneth Conroy, VP of Data Science at VancouverBased

00:34.720 --> 00:39.280
Fin.AI, a company building a chatbot system for banks.

00:39.280 --> 00:43.920
Kenneth and I spoke about how Fin.AI built its core conversational platform.

00:43.920 --> 00:49.160
We spoke in depth about the requirements and challenges of conversational applications

00:49.160 --> 00:53.760
and how and why they transitioned off of a commercial chatbot platform, in their case,

00:53.760 --> 00:59.720
API.AI, and built their own custom platform based on deep learning, word-to-vec, and other

00:59.720 --> 01:02.840
natural language understanding technologies.

01:02.840 --> 01:07.080
Georgian Partners is a venture capital firm whose investment thesis is that certain tech

01:07.080 --> 01:12.980
trends change every aspect of a software business over time, including business goals, product

01:12.980 --> 01:18.600
plans, people in skills, technology platforms, pricing and packaging.

01:18.600 --> 01:23.400
Georgian invests in those companies best positioned to take advantage of these trends and then works

01:23.400 --> 01:27.840
closely with those companies to develop and execute the strategies necessary to make

01:27.840 --> 01:29.640
it happen.

01:29.640 --> 01:34.640
Applied AI is one of the trends they're investing in as our conversational business and security

01:34.640 --> 01:36.600
first.

01:36.600 --> 01:39.760
Georgian sponsored this series and we thank them for their support.

01:39.760 --> 01:45.520
To learn more about Georgian, visit twimmolai.com slash Georgian, where you'll also be able to

01:45.520 --> 01:51.600
download white papers on their principles of applied AI and conversational business.

01:51.600 --> 01:56.040
Before we jump in, if you're in New York City on October 30th and 31st, we hope you'll

01:56.040 --> 02:00.440
join us at the NYU Future Labs AI Summit and Happy Hour.

02:00.440 --> 02:04.360
As you may remember, we attended the inaugural summit back in April.

02:04.360 --> 02:08.800
The fall event features more great speakers, including Karina Cortez, head of research at

02:08.800 --> 02:14.040
Google New York, David Venturelli, science operations manager at NASA Ames Quantum

02:14.040 --> 02:20.280
AI Lab, and Dennis Mortensen, CEO and founder of startup x.ai.

02:20.280 --> 02:28.400
For the event homepage, visit AISummit2017.futurelabs.nyc, and for 25% off tickets, use the

02:28.400 --> 02:30.920
code twimmol25.

02:30.920 --> 02:36.680
For details on the Happy Hour, visit our events page at twimmolai.com slash events.

02:36.680 --> 02:40.520
And now on to the show.

02:40.520 --> 02:47.040
All right, everyone.

02:47.040 --> 02:52.720
I am here at the Georgian Partners Portfolio Conference in Toronto, Canada, where I'll

02:52.720 --> 02:57.920
be doing a few interviews, and I am excited to be here with Kenneth Conroy.

02:57.920 --> 03:02.840
Kenneth is the VP of Data Science at fin.ai.

03:02.840 --> 03:05.400
Kenneth, welcome to this week in Machine Learning and AI.

03:05.400 --> 03:06.800
Thanks for having me.

03:06.800 --> 03:07.800
Awesome.

03:07.800 --> 03:10.040
And so you're in from Vancouver.

03:10.040 --> 03:11.040
Yeah.

03:11.040 --> 03:16.600
So stand from Vancouver from last night, so still filling out a bit, but happy to be here.

03:16.600 --> 03:17.600
Hi.

03:17.600 --> 03:19.880
Why don't we get started by having you tell us a little bit about your background and

03:19.880 --> 03:22.720
how you got involved in data science and machine learning?

03:22.720 --> 03:23.720
Sure.

03:23.720 --> 03:29.160
Well, I'm from Ireland, and I did my PhD in Dublin City University in the area of heterogeneous

03:29.160 --> 03:30.640
sensor data.

03:30.640 --> 03:36.080
So I was in a research lab called the Clarity Center for Sensor Web Technologies.

03:36.080 --> 03:40.800
And I was involved with coming up with a way of aggregating sensor content from multiple

03:40.800 --> 03:44.120
different devices that were not in any way connected.

03:44.120 --> 03:49.040
And doing that, I ended up coming up with machine learning strategies for close string

03:49.040 --> 03:52.680
and have one of the supervised learnings for finding out things that researchers wanted

03:52.680 --> 03:53.680
to detect.

03:53.680 --> 03:58.400
The researchers in this case would be domain experts in sports science.

03:58.400 --> 04:03.280
And from there, when I finished my PhD, I continued working in the same university, but for

04:03.280 --> 04:06.200
the inside center for data analytics.

04:06.200 --> 04:12.920
And that's where I moved way into the NLP machine learning, sends with analysis, projects.

04:12.920 --> 04:18.080
It was a commercialization wing of the university essentially.

04:18.080 --> 04:23.880
And I ended up moving to Vancouver maybe three years ago, now I'm at FinAI and leading the

04:23.880 --> 04:27.760
data science team as we create conversational assistance for banks.

04:27.760 --> 04:28.760
Nice.

04:28.760 --> 04:32.360
Is there a lot of machine learning and AI activity in Ireland?

04:32.360 --> 04:33.360
Yes.

04:33.360 --> 04:34.360
This is a very big hub actually in Dublin.

04:34.360 --> 04:35.360
OK.

04:35.360 --> 04:39.880
I'm hoping that we set up a Dublin branch for our Amia headquarters in the future.

04:39.880 --> 04:44.200
I know a lot of people in the field and the universities very qualified people there.

04:44.200 --> 04:47.800
So yeah, it's a bit of a hope right now for machine learning.

04:47.800 --> 04:48.800
Nice.

04:48.800 --> 04:51.600
So tell us a little bit more about what Fin is up to.

04:51.600 --> 04:56.160
So we're creating conversational assistance for banks, so think of a Siri for your bank.

04:56.160 --> 05:00.040
We provide things like day to day banking, your basic banking needs, like checking your

05:00.040 --> 05:05.400
balance online or paying bills or transferring money from friends to friends, as well as

05:05.400 --> 05:10.240
more kind of day to day kind of Q&A type stuff you would ask a bank, what your fees are

05:10.240 --> 05:13.680
for your credit cards, product information, stuff like that.

05:13.680 --> 05:19.000
We integrate with the bank's APIs for security, logging in, if we have any interactions

05:19.000 --> 05:21.120
with your bank accounts.

05:21.120 --> 05:26.000
And essentially, yeah, we're just kind of expanding our product base beyond the initial

05:26.000 --> 05:28.800
NLU side of things for detecting intents.

05:28.800 --> 05:33.040
So having recommendation engines in the future as well as credit score coach, moving

05:33.040 --> 05:34.800
more into voice platforms.

05:34.800 --> 05:39.120
So right now we're NLP based text interface mostly.

05:39.120 --> 05:44.240
We have experimented with some voice interfaces, but our primary platform is Facebook for

05:44.240 --> 05:51.040
which we launched a production bot for ATB financial as of yesterday, so we're in production

05:51.040 --> 05:52.040
as of yesterday.

05:52.040 --> 05:53.040
Nice.

05:53.040 --> 05:54.040
Nice.

05:54.040 --> 05:59.280
So you're here at the conference as a portfolio company of George and Partners, but

05:59.280 --> 06:02.200
you're also speaking at the conference later on today.

06:02.200 --> 06:05.000
What's the topic of your talk?

06:05.000 --> 06:08.240
The talk topic title went through some iterations.

06:08.240 --> 06:13.320
So I think it's a how we built a virtual banking assistant or virtual financial assistant

06:13.320 --> 06:14.320
for banks.

06:14.320 --> 06:15.320
Okay.

06:15.320 --> 06:17.520
So it sounds like that's the story, the fin story.

06:17.520 --> 06:18.520
Essentially, yeah.

06:18.520 --> 06:23.360
So one of our co-founders, Natalie Cartwright, she'll be introducing the talk and giving

06:23.360 --> 06:27.400
a lot of the business insight into why we went down the path we went down and then I'll

06:27.400 --> 06:32.720
talk more to the data sign side of things and how the technical challenges arose along

06:32.720 --> 06:37.720
the way and how we make the decisions we made and how we're kind of continually improving

06:37.720 --> 06:38.720
on that process.

06:38.720 --> 06:39.720
Okay.

06:39.720 --> 06:40.720
Well, let's dig into that.

06:40.720 --> 06:46.280
What were some of the major goals and challenges on the data sign side?

06:46.280 --> 06:52.600
So I think we kind of reduced the problem to its core issue, which was how do you design

06:52.600 --> 06:56.600
a taxonomy of intense for which you want to get answers?

06:56.600 --> 07:00.560
It's a bit of a complex task because you've got to, for us, we were a closed domain.

07:00.560 --> 07:03.560
We wanted to stay a closed domain and stay in retrieval-based systems.

07:03.560 --> 07:09.440
So it was banking only and the responses are pre-written, no generative responses at

07:09.440 --> 07:10.440
all.

07:10.440 --> 07:11.440
Okay.

07:11.440 --> 07:15.720
So when we have that as our canvas and we want to create a taxonomy to kind of drill

07:15.720 --> 07:21.360
down into individual branches of what the conversational tree might be, there were a lot

07:21.360 --> 07:25.120
of challenges involved in that, where you draw the boundaries between things.

07:25.120 --> 07:31.000
At what stage or at what extent do you want to make it conversational with one-to-one responses?

07:31.000 --> 07:35.360
So the bulk of our functionality in terms of intense would be one level.

07:35.360 --> 07:38.200
You would say question and you get an answer.

07:38.200 --> 07:40.000
But some of them will have flows.

07:40.000 --> 07:43.600
So if you want to make a bill payment, you can say something like, I want to pay my BC

07:43.600 --> 07:48.440
hydro bill $50 and it will pre-fill those things using the entity recognition and ask you

07:48.440 --> 07:49.440
to confirm.

07:49.440 --> 07:53.480
Or if you don't give enough details, we'll ask you for more input and that kind of two

07:53.480 --> 07:56.520
and throw conversational side of things comes into it.

07:56.520 --> 08:01.560
So in that case, it's almost like walking through a wizard in a traditional, you always

08:01.560 --> 08:06.360
got a set of questions that represent information that's needed to fulfill the transaction

08:06.360 --> 08:08.920
and you just go one to the next to the next.

08:08.920 --> 08:09.920
Exactly.

08:09.920 --> 08:14.400
And based on conversations we have with customer service agents, so a lot of our functionality

08:14.400 --> 08:19.200
is to kind of help the CSAs answer questions in doing that.

08:19.200 --> 08:24.360
And we got a list of questions that they get on a daily basis and we could waste them

08:24.360 --> 08:29.420
based on how frequent they came in and from that was kind of like the seed of how we

08:29.420 --> 08:33.800
would build this taxonomy that wants one communication with banks.

08:33.800 --> 08:38.000
And as we speak to more and more people in different banks, we're seeing the commonality

08:38.000 --> 08:40.200
between the banks is very strong.

08:40.200 --> 08:45.160
There's maybe 85, 90% commonality in what they want, what they want to achieve.

08:45.160 --> 08:48.760
So that's the good side about having this taxonomy in place.

08:48.760 --> 08:55.760
You can bootstrap a bot fairly quickly and get it up to a reasonable level of performance

08:55.760 --> 08:56.920
very quickly.

08:56.920 --> 09:01.800
It's then when you want to build out those more kind of fully featured functions and those

09:01.800 --> 09:03.880
conversational side of things.

09:03.880 --> 09:09.040
That's when the complexities come into it and where really kind of future is for the business.

09:09.040 --> 09:10.720
A bunch of questions.

09:10.720 --> 09:15.040
I guess one question is not necessarily related to the data science side of things, but

09:15.040 --> 09:21.000
are you integrating one-to-one with the banks or are you using some kind of intermediary

09:21.000 --> 09:23.640
like a yodulee or something like that?

09:23.640 --> 09:24.640
I think so.

09:24.640 --> 09:28.880
I don't know too much about the what goes on behind the scenes and the engineering side

09:28.880 --> 09:29.880
of things.

09:29.880 --> 09:34.400
So the engineering team will do a lot of the interactions with the banks themselves.

09:34.400 --> 09:40.680
A lot of our bots are completely done by us, hosted by us and accessible by anybody because

09:40.680 --> 09:44.840
they're not personally, no personally identifiable information in there.

09:44.840 --> 09:49.200
So for banks that require API integrations with the banks themselves, we provide an

09:49.200 --> 09:55.600
interface for the banks to give the security credential requirements and login functionality.

09:55.600 --> 09:56.840
So all that stuff is done by them.

09:56.840 --> 10:01.920
We do not take the responsibility of authenticating the users and that's up to the banks to

10:01.920 --> 10:05.320
do if they want to have integrations with their systems.

10:05.320 --> 10:11.000
What does it mean to have a banking bot that doesn't deal with any personally identifiable

10:11.000 --> 10:12.000
information?

10:12.000 --> 10:17.200
You're saying that you're just passing requests to the bank and they're answering them or

10:17.200 --> 10:21.520
are you talking about bots that just don't deal with account information that are like

10:21.520 --> 10:24.280
telling you where to find branches and ATMs and that kind of thing?

10:24.280 --> 10:29.680
Yeah, so some of our functionality will be finding ATMs or just basic questions about

10:29.680 --> 10:31.480
the products and services they offer.

10:31.480 --> 10:34.000
And that stuff is not confidential in any way.

10:34.000 --> 10:39.560
It's open information that may exist on an FAQ in a different format on their site.

10:39.560 --> 10:44.040
So it's still a conversational way of talking to your bank or a bank doesn't necessarily

10:44.040 --> 10:46.360
have to be your bank if you're not authenticated with it.

10:46.360 --> 10:48.240
But yeah, that's what I mean.

10:48.240 --> 10:49.240
Okay.

10:49.240 --> 10:55.000
What percentage of the banks you're working with are taking this approach where it's just

10:55.000 --> 10:58.760
that surface level interaction versus account level detail?

10:58.760 --> 11:05.520
Typically, when we do POCs, so for banks, the first version will not have banking integrations.

11:05.520 --> 11:09.520
Banks move a lot slower than startups, for instance.

11:09.520 --> 11:13.600
So if they want to integrate their systems with us, we have to have a lot of trust between

11:13.600 --> 11:14.600
us.

11:14.600 --> 11:20.000
So we've had a relationship with ATB financial for over a year now and based on that level

11:20.000 --> 11:25.960
of trust and that level of working collaboratively together, we've been able to create a production

11:25.960 --> 11:28.640
bot that uses all of that API integration.

11:28.640 --> 11:29.640
Okay.

11:29.640 --> 11:33.880
Yeah, building up that trust and building up that system for them and allowing them to test

11:33.880 --> 11:37.960
it and kind of iterate on it before it goes to production is kind of key.

11:37.960 --> 11:38.960
Okay.

11:38.960 --> 11:46.720
So we started talking about the data science side of things in terms of identifying the

11:46.720 --> 11:48.120
intents.

11:48.120 --> 11:57.480
In what way can you characterize the breadth of the intents or the interactions that you

11:57.480 --> 12:00.040
have for a typical customer?

12:00.040 --> 12:05.840
How many of these intents are there in a realm like banking?

12:05.840 --> 12:07.840
So this question comes up a lot.

12:07.840 --> 12:08.840
What is an intent?

12:08.840 --> 12:12.320
So we use a lot of entity recognition to reduce the amount of intents.

12:12.320 --> 12:14.520
We do not want a lot of intents in our system.

12:14.520 --> 12:19.560
We want to break down the problem into kind of smaller subsets, more consumable subsets.

12:19.560 --> 12:23.320
So the amount of intents is actually quite low compared to what you would think based

12:23.320 --> 12:26.960
the amount of responses we can give, we give thousands of responses.

12:26.960 --> 12:31.520
But there might only be a few hundred intents and it depends on the agent to functionality

12:31.520 --> 12:32.520
that we have.

12:32.520 --> 12:38.720
It depends on how many kind of FAQ type questions they want in there and what subset of

12:38.720 --> 12:43.120
all functionality that we can offer they want to make use of.

12:43.120 --> 12:48.280
So yeah, the amount of intents is kind of a wishy-washy number.

12:48.280 --> 12:52.760
The amount of responses is a solid number that we can give per agent basis.

12:52.760 --> 12:57.640
But the amount of potential intents is kind of set at a certain value for our core basic

12:57.640 --> 12:59.120
banking needs.

12:59.120 --> 13:03.280
So the taxonomy tree has an empty list of responses.

13:03.280 --> 13:07.640
So anywhere you could put a response in any of those leaves, that's another response.

13:07.640 --> 13:12.520
And that's what the banks decide what they want to support.

13:12.520 --> 13:18.000
And the banks come to us with their call logs information, analytics on what the subject

13:18.000 --> 13:20.240
matter is for their chat logs, for instance.

13:20.240 --> 13:26.400
And then they can see the subset of the taxonomy that would best meet their needs.

13:26.400 --> 13:28.520
What level of abstraction is an intent?

13:28.520 --> 13:33.680
Is it something like, you know, I want to ask a question about an FAQ or is it like

13:33.680 --> 13:39.360
individual questions, you know, does it map more closely to individual FAQ questions

13:39.360 --> 13:40.960
or responses?

13:40.960 --> 13:42.800
So it depends.

13:42.800 --> 13:46.760
Things like if you want to find an ATM would have like a find ATM intent, it's fairly

13:46.760 --> 13:48.000
well defined.

13:48.000 --> 13:52.600
If you want to find out your fees for your master card, for instance, the intent might

13:52.600 --> 13:53.600
be fees.

13:53.600 --> 13:54.600
Okay.

13:54.600 --> 13:57.840
The anti-recognition would find what the master card is or means and provide a different

13:57.840 --> 14:00.280
response based on master card rather than visa.

14:00.280 --> 14:01.280
Okay.

14:01.280 --> 14:04.160
Maybe we break it down into smaller bite size chunks.

14:04.160 --> 14:05.160
Okay.

14:05.160 --> 14:06.160
Interesting.

14:06.160 --> 14:12.120
So you've got this tree structure, you've got these entities, well, I guess a kind of basic

14:12.120 --> 14:13.120
question.

14:13.120 --> 14:21.400
Are you using any of the commercial platforms to do any of this stuff like the API data

14:21.400 --> 14:24.000
AI is of the world and others?

14:24.000 --> 14:25.000
Not anymore.

14:25.000 --> 14:26.000
So we did.

14:26.000 --> 14:27.000
Interesting.

14:27.000 --> 14:29.240
Initially we used API AI way back when.

14:29.240 --> 14:32.680
So they're great for what they're built to do.

14:32.680 --> 14:37.800
They allow you to create bots fairly quickly, not much data involved, accuracy isn't too

14:37.800 --> 14:42.800
bad, fairly customizable, but they weren't the way that we could continue.

14:42.800 --> 14:45.640
They were too limited in terms of what we wanted to achieve.

14:45.640 --> 14:48.560
We had no idea what was in their model, for instance.

14:48.560 --> 14:52.800
We had no secondary match for what their primary intent match would be.

14:52.800 --> 14:59.200
You said no idea what was in their model, meaning, you know, they identified intents using

14:59.200 --> 15:02.880
NLP, whatever, but it was all a black box to you.

15:02.880 --> 15:11.440
They just gave you an API and told you, hey, bot user initiated this intent and we found

15:11.440 --> 15:14.920
these entities and figured out, but you couldn't tweak or tune that at all.

15:14.920 --> 15:15.920
Exactly, yeah.

15:15.920 --> 15:18.800
There was limitations on where we could go with it.

15:18.800 --> 15:19.800
Okay.

15:19.800 --> 15:24.160
If you wanted to have multi-layer models, for instance, or focus on or upweight specific

15:24.160 --> 15:28.880
types of intents, the functionality was wasn't there to be in a scalable enterprise

15:28.880 --> 15:33.080
product within our domain, and because we were in our domain, we wanted to have a system

15:33.080 --> 15:38.000
where we could reuse as much of what we were providing for each bank across banks.

15:38.000 --> 15:44.760
API is quite complex when it comes to sharing data for one agent to another, and you need

15:44.760 --> 15:46.480
individual agents for that.

15:46.480 --> 15:47.480
Okay.

15:47.480 --> 15:51.400
There's also a limitation on the amount of data you can upload to it, and the rate limitation

15:51.400 --> 15:55.960
on how often you can request, model matches and so on.

15:55.960 --> 16:01.520
So they're the reason why we moved away, and that was the move to our production system

16:01.520 --> 16:02.520
was 100%.

16:02.520 --> 16:04.120
It's our own now.

16:04.120 --> 16:05.120
Okay.

16:05.120 --> 16:11.120
You mentioned in there, multi-layer models, what would that entail, or what does that represent?

16:11.120 --> 16:17.440
So in place of our entity recognition, we are building up data sets to find how the

16:17.440 --> 16:20.440
user kind of goes down a certain tree.

16:20.440 --> 16:21.440
Okay.

16:21.440 --> 16:24.960
Right now, we're using a deregnation to do that, but we could use a model to do that.

16:24.960 --> 16:30.320
It's like a subset of all available intents, but narrowed down to those individual entities.

16:30.320 --> 16:33.960
Once the data set is a bit more richer and a bit more well defined and developed and

16:33.960 --> 16:38.200
we have more user data, we can use that as an additional layer in the model.

16:38.200 --> 16:43.360
So there'd be the existing model, which is the top layer intent match, and then within

16:43.360 --> 16:48.920
each conversational flow, there are kind of submodels that have all available actions

16:48.920 --> 16:50.920
there as well as a few escape actions.

16:50.920 --> 16:56.160
So rather than having to cancel out of that flow to query something else, you get a focused

16:56.160 --> 16:59.440
way of finding what the user's next input is.

16:59.440 --> 17:06.240
I'm still trying to wrap my head around what the idea of multi-layer, meaning you've

17:06.240 --> 17:11.680
got your entities that you're kind of extracting out traditionally, but then you're applying

17:11.680 --> 17:16.760
other probabilistic models to try to identify where the entities are, is that the idea of

17:16.760 --> 17:17.760
a multi-layer?

17:17.760 --> 17:24.040
The multi-layer model isn't in production, but this is a replacement for part of that

17:24.040 --> 17:26.080
entity recognition modules.

17:26.080 --> 17:30.520
So given enough data and enough information on what the synonyms and ABSs are for different

17:30.520 --> 17:35.640
entities in our system, we can further define and automate that process rather than using

17:35.640 --> 17:39.840
the existing one, because you got to update things like synonyms over time, and you might

17:39.840 --> 17:41.840
miss certain things.

17:41.840 --> 17:47.360
You might not always find MasterCard if it's miss belts, for instance.

17:47.360 --> 17:53.520
But that said, both that approach and the existing approach, if you miss Bell MasterCard,

17:53.520 --> 17:57.760
because we're using the intent level at a higher level, we're still finding what the

17:57.760 --> 18:03.400
intent of the user is, which is safe ease, and we can just guide the user via UX to the

18:03.400 --> 18:06.320
specific response they're actually looking for.

18:06.320 --> 18:13.720
And as part of that shift to the multi-layer, is there kind of an underlying shift in

18:13.720 --> 18:20.280
an approach from something analogous to NLTK on Python to something that's more like

18:20.280 --> 18:23.960
a homegrown deep learning entity recognizer?

18:23.960 --> 18:26.160
Yeah, so we have two tracks for right now.

18:26.160 --> 18:32.440
We have our production track, which is kind of a SPARK Python pipeline, using word embeddings

18:32.440 --> 18:36.720
and using word-to-vec for other algorithms like that.

18:36.720 --> 18:39.520
And then we have our research or in deep learning track.

18:39.520 --> 18:42.880
In that track, we're working on deep learning stuff.

18:42.880 --> 18:47.480
We're working on MXNet and TensorFlow in parallel.

18:47.480 --> 18:51.880
We're experimenting on where we're going to get the best accuracy over time and where

18:51.880 --> 18:54.720
this can fit into our multi-layer approach.

18:54.720 --> 18:57.000
And why MXNet and TensorFlow?

18:57.000 --> 19:03.400
So TensorFlow is very popular, and MXNet is very good.

19:03.400 --> 19:04.400
So we are...

19:04.400 --> 19:07.040
Now, I've heard MXNet is very fast.

19:07.040 --> 19:12.520
I don't know that I've heard very good, necessarily, not that it's not, but...

19:12.520 --> 19:15.000
I can't speak with too much confidence on the subject.

19:15.000 --> 19:16.600
Maybe define good.

19:16.600 --> 19:17.600
I can't.

19:17.600 --> 19:18.600
Okay.

19:18.600 --> 19:19.600
Got it.

19:19.600 --> 19:20.600
Interesting.

19:20.600 --> 19:24.000
Yeah, I mean, there are tons of lots of framework choices out there.

19:24.000 --> 19:25.600
There are a lot there.

19:25.600 --> 19:30.000
Yeah, it's kind of early days for our deep learning path.

19:30.000 --> 19:34.920
But the goal was to get this into production in a usable state and have our stakeholders

19:34.920 --> 19:37.400
happy with the performance of it, which is there, which is great.

19:37.400 --> 19:39.400
But this is the exciting kind of future side.

19:39.400 --> 19:41.440
It's getting everyone on the team very excited.

19:41.440 --> 19:43.680
Looking on the deep learning side of things.

19:43.680 --> 19:44.680
Nice.

19:44.680 --> 19:45.680
Nice.

19:45.680 --> 19:51.440
Are you able to characterize, in some way, the benefit that you, you know, besides from

19:51.440 --> 19:56.840
kind of the flexibility and visibility, agility, all that,ility kind of things?

19:56.840 --> 20:04.080
Like in going from api.ai, where you didn't kind of control the model to, you know, that

20:04.080 --> 20:08.920
first pipeline that you just mentioned where you're using Word2vec and stuff like that.

20:08.920 --> 20:13.920
Are there quantitative, was there specific quantitative advantages that you saw?

20:13.920 --> 20:14.920
Yeah.

20:14.920 --> 20:19.720
So when we're evaluating, we couldn't evaluate api.ai in the same way that we didn't have

20:19.720 --> 20:24.280
the ability to see, exploit the training test data on their side and find out what the

20:24.280 --> 20:26.760
cross validation score would be for instance.

20:26.760 --> 20:27.760
We can do that.

20:27.760 --> 20:31.520
An objective, the evaluate our own models against our own models, which is great.

20:31.520 --> 20:36.040
But we do analyze logs and we take a snapshot of everything that's gone through our system

20:36.040 --> 20:40.640
as it exists in api.ai and then put it into our new model as well and then compare the

20:40.640 --> 20:42.520
results of that in real world terms.

20:42.520 --> 20:47.200
We take a snapshot of a week's worth of data that goes into an agent, see how accurate

20:47.200 --> 20:49.200
it is based on that.

20:49.200 --> 20:53.680
That's what the banks are interested to see to, they're interested to see the real world

20:53.680 --> 21:01.760
accuracy of something without kind of adjusting for duplication in the data or however

21:01.760 --> 21:06.680
cross-fold validation kind of, it's hard for them to visualize how that's working.

21:06.680 --> 21:09.200
So real world, they need to see what those values are.

21:09.200 --> 21:14.760
So in doing that, we can see that our models are outperforming what was existing for api.ai.

21:14.760 --> 21:15.760
Okay.

21:15.760 --> 21:18.680
So we started down the path of challenges.

21:18.680 --> 21:24.240
Are there other things that come to mind in terms of challenges that you've come across?

21:24.240 --> 21:25.240
I guess.

21:25.240 --> 21:29.120
We haven't seen it too much, but it can happen and we're quite wary of it and we're kind

21:29.120 --> 21:33.800
of getting ahead of the curve by cautioning against it is intent drift.

21:33.800 --> 21:41.560
So when the banks themselves have the ability to map odorances to intense, we are at risk

21:41.560 --> 21:47.240
of having our taxonomy start to diverge based on how they write the response and how they

21:47.240 --> 21:51.520
think that should be the answer for that specific intent.

21:51.520 --> 21:55.520
If you've got a bunch of data in there that's labeled for an intent and all those pieces

21:55.520 --> 21:59.920
are answered by that response and then part of that response gets taken away then doesn't

21:59.920 --> 22:04.720
make sense for those things that were in there initially to still map to the same place.

22:04.720 --> 22:09.020
And it'll look like it's doing the right thing, but the response isn't given to the user.

22:09.020 --> 22:14.160
So to kind of counteract that we are building tools for the banks to be able to do this

22:14.160 --> 22:15.160
themselves.

22:15.160 --> 22:22.160
So the CSAs with our human and loop infrastructure will be able to correct errors made and

22:22.160 --> 22:27.920
map things to the correct intent and then feed that back into our system.

22:27.920 --> 22:32.560
And we also have methods of coming up with approximations about those things that are

22:32.560 --> 22:36.400
kind of prompting the user to pick from some subset of those things.

22:36.400 --> 22:41.400
But we want to have a two or three level deep kind of verification on anything they map

22:41.400 --> 22:48.040
to make sure that is appropriate response to what the user's odorance was.

22:48.040 --> 22:53.720
So can you give me an example of where they might change something that disrupts that

22:53.720 --> 22:54.720
relationship?

22:54.720 --> 22:55.720
Sure.

22:55.720 --> 23:01.920
We have things like tell me about you and who are you and sometimes the response to that

23:01.920 --> 23:05.080
gives us the same thing, but they're separate intents.

23:05.080 --> 23:07.680
Tell me about you and who are you.

23:07.680 --> 23:11.120
So tell me about you and be like, what can you do?

23:11.120 --> 23:12.120
Okay.

23:12.120 --> 23:17.200
Whereas who are you is just an introduction to the bot itself.

23:17.200 --> 23:21.400
But sometimes who are you means who are you, the bank, right?

23:21.400 --> 23:25.840
So how, what training that goes in for that is important depending on the context of

23:25.840 --> 23:28.200
what that response is.

23:28.200 --> 23:38.280
And so you mentioned that the CSAs, it sounds like to some extent the customer service teams

23:38.280 --> 23:47.400
at the bank have some role in kind of defining out the hierarchy and the responses.

23:47.400 --> 23:52.520
Is that correct or are you doing this all as a service for them?

23:52.520 --> 23:58.800
So earlier collaborations, very heavily involved with meeting with the bank's CSAs, talking

23:58.800 --> 24:04.720
through their issues, how their data forms, their opinions on what should be in there

24:04.720 --> 24:10.480
or whatnot, but we do have a base taxonomy based on those consultations with multiple

24:10.480 --> 24:11.480
banks at that point.

24:11.480 --> 24:12.480
Okay.

24:12.480 --> 24:15.160
And we can see about 85, 90% of commonality across all the banks.

24:15.160 --> 24:16.160
Okay.

24:16.160 --> 24:17.160
So that's kind of our core taxonomy.

24:17.160 --> 24:21.760
And if if banks want to extend beyond that, they just know that they'll have, we'll

24:21.760 --> 24:26.440
have fewer data entries for those things, fewer utterances to train, it would be a little

24:26.440 --> 24:28.000
less accurate at first.

24:28.000 --> 24:31.720
But if it makes sense, we can build that in as part of our core offering.

24:31.720 --> 24:36.240
In other cases, it might be locale based or it might just be for that one bank.

24:36.240 --> 24:37.240
Okay.

24:37.240 --> 24:39.480
And in those cases, they're just one-offs kind of customizations.

24:39.480 --> 24:40.480
Okay.

24:40.480 --> 24:47.800
And so this case where you get kind of drift in the intent, is that because of changes

24:47.800 --> 24:54.120
that the customer service people are able to make in the underlying system or is it the

24:54.120 --> 24:59.040
training data that they feed to you, that you are putting through your pipeline?

24:59.040 --> 25:04.080
So the customer, which is the bank, has the ability to change the responses, if they want

25:04.080 --> 25:05.680
to change the responses.

25:05.680 --> 25:09.120
We kind of monitor that to make sure it doesn't go too far away from the meaning of what

25:09.120 --> 25:10.120
that intent is.

25:10.120 --> 25:11.120
Okay.

25:11.120 --> 25:15.440
But they're also able to use our systems to manually answer questions.

25:15.440 --> 25:20.400
So if a query comes in and we do not have the high enough confidence to give the answer,

25:20.400 --> 25:22.760
it gets handed off to our human and the loop system.

25:22.760 --> 25:23.760
Okay.

25:23.760 --> 25:27.000
And then at that point, they can answer the question and then recommend an intent or utterance

25:27.000 --> 25:28.840
to map to that.

25:28.840 --> 25:31.840
For time as well, they can also monitor their own logs.

25:31.840 --> 25:36.000
And if they have people who are qualified to do so, you can educate them to do so.

25:36.000 --> 25:42.360
They can mark those logs for us, for themselves, and then that can be fed back into their model.

25:42.360 --> 25:47.880
So this happens a lot in pre-production when we have user acceptance testing with our

25:47.880 --> 25:48.880
banks.

25:48.880 --> 25:53.600
They kind of pre-train the bot by interacting with it time and time again.

25:53.600 --> 25:57.720
Typically, we annotate that, but we want to hand over some of that to the banks to give

25:57.720 --> 26:01.360
them an insight into the type of things that are being asked and how we best answer those

26:01.360 --> 26:02.360
questions.

26:02.360 --> 26:03.360
Okay.

26:03.360 --> 26:09.960
And so is there a, you know, it sounds like the intent drift challenges, you know, almost

26:09.960 --> 26:15.680
like a, you know, skill slash cultural slash focus kind of thing?

26:15.680 --> 26:20.880
How much of that is addressed by, you know, educating the customer service folks, you

26:20.880 --> 26:24.160
know, versus a technology solution?

26:24.160 --> 26:27.840
It's a bit of both, and it's not just the customer service folks, too.

26:27.840 --> 26:29.320
It's anybody in the organization.

26:29.320 --> 26:30.320
Okay.

26:30.320 --> 26:35.840
They might say they want a thousand questions answered, but that isn't one thousand distinct

26:35.840 --> 26:41.800
intents in any way, or even sometimes they're exact same intent and the exact same subset

26:41.800 --> 26:42.800
of intents.

26:42.800 --> 26:43.800
Okay.

26:43.800 --> 26:47.200
So I think part of it is to frame the problem differently.

26:47.200 --> 26:52.480
People still kind of tend to think of things like FAQs in a chat box if it's an FAQ

26:52.480 --> 26:56.320
in a web page, but those type of questions don't get asked in the same way as they would

26:56.320 --> 26:57.640
be listed on a web page.

26:57.640 --> 26:59.320
You got to structure things differently.

26:59.320 --> 27:00.320
It's not conversational.

27:00.320 --> 27:01.320
It's not intuitive.

27:01.320 --> 27:04.160
And the user doesn't just doesn't do it.

27:04.160 --> 27:09.840
So part of it is managing the expectations from the start, training the users, the customer

27:09.840 --> 27:16.000
is on how we best organize this information and why we do that, as well as because we

27:16.000 --> 27:20.920
have to got the taxonomy that's kind of shared across banks, we can reuse the data across

27:20.920 --> 27:21.920
banks.

27:21.920 --> 27:26.280
And that's mutually beneficial for everyone involved because that means the accuracy of

27:26.280 --> 27:31.240
all of those intents improve as data from each of those banks come in.

27:31.240 --> 27:32.400
Interesting.

27:32.400 --> 27:39.560
In your presentation, will you be outlining, do you have any kind of prescriptive, you

27:39.560 --> 27:46.480
know, if you're looking at doing chatbots or maybe even ML or AI generally like to, you

27:46.480 --> 27:48.240
know, things one through end?

27:48.240 --> 27:49.560
Kind of, yeah.

27:49.560 --> 27:54.760
It's obviously heavily weighted in the way we actually did it and how we tried it and

27:54.760 --> 27:59.320
how it didn't work and then how we did it and seemed to be working pretty well.

27:59.320 --> 28:05.360
So yeah, I'll talk about exactly how we did it as well as how we're best seeing rolling

28:05.360 --> 28:07.840
this out works to customers.

28:07.840 --> 28:11.840
So seeing this in the real world, seeing how customers interact with it and help you

28:11.840 --> 28:16.600
get to where you need to go and where themselves need to go, it's really cool to see.

28:16.600 --> 28:21.640
So what are your top three, you know, make sure you do this or don't make this mistake,

28:21.640 --> 28:26.720
kind of advice to startups that are trying to get systems like this up and running.

28:26.720 --> 28:28.000
Don't rush into it.

28:28.000 --> 28:31.960
So make sure the taxonomy is well defined.

28:31.960 --> 28:34.800
You will spend a lot of time researching this at the start.

28:34.800 --> 28:37.880
The two is you got to get some good data in there.

28:37.880 --> 28:44.160
We looked at lots of sources of information including previous chat logs or transcripts

28:44.160 --> 28:45.160
from calls.

28:45.160 --> 28:49.360
They're not great, even as C did it, they're not very good and they're often unstructured

28:49.360 --> 28:52.200
and difficult to even annotate in any way.

28:52.200 --> 28:57.240
We found for the cold star problem, crowdsourcing is key.

28:57.240 --> 29:02.600
Getting a list of different ways of saying different things can get you very far, very

29:02.600 --> 29:03.600
quickly.

29:03.600 --> 29:09.320
And then, did you crowdsource among the customer service agents that customers are like

29:09.320 --> 29:11.480
Amazon Turk or something like that?

29:11.480 --> 29:12.480
Yeah, both.

29:12.480 --> 29:13.480
Okay.

29:13.480 --> 29:14.480
So interesting.

29:14.480 --> 29:20.240
For kind of things that customers weren't helping build, maybe their features for our

29:20.240 --> 29:23.480
core platform that have not been released yet.

29:23.480 --> 29:29.120
And then often customers would have their own ideas and they would submit those ideas.

29:29.120 --> 29:34.320
We would build on those by submitting mechanical jobs to get more data.

29:34.320 --> 29:35.320
Okay.

29:35.320 --> 29:40.560
I guess then the third thing would be to consider where you draw the line between intense

29:40.560 --> 29:48.120
and entities, how you reduce the problem space and increase the accuracy by customizing

29:48.120 --> 29:51.040
to a certain extent to the domain you're working in.

29:51.040 --> 29:54.760
So get that taxonomy up and running, get that dictionary of terms for banking up and

29:54.760 --> 29:56.280
running if you're in banking.

29:56.280 --> 30:00.080
Obviously, I don't like to do a banking buff.

30:00.080 --> 30:01.480
But you said a bunch of stuff in there.

30:01.480 --> 30:09.640
So the first thing was the line between the entities and the intents.

30:09.640 --> 30:11.240
And we haven't talked about that yet.

30:11.240 --> 30:15.280
Is there like a trade-off dial in there somewhere that you have to kind of find the

30:15.280 --> 30:16.280
right place?

30:16.280 --> 30:20.320
It's not a straightforward task to find out where to do that or what the top intent should

30:20.320 --> 30:21.320
be.

30:21.320 --> 30:26.760
Like, do you focus on a product and then have a bunch of sub entities that have from features

30:26.760 --> 30:32.280
of that product or you talk about the features and products that correspond to that feature

30:32.280 --> 30:34.200
or things like fees, whatever.

30:34.200 --> 30:40.040
So the way you segment that stuff, you've got to be able to kind of keep track of what

30:40.040 --> 30:41.040
you've done as well.

30:41.040 --> 30:44.640
And if you ever want to go back again and change things, you don't want to be doing that

30:44.640 --> 30:48.120
when you've got a few million data entries in there to an entity.

30:48.120 --> 30:50.040
It's just going to be an impossible task.

30:50.040 --> 30:56.360
So that's an issue with a lot of the kind of first-time bot builder.

30:56.360 --> 30:59.160
You just build a bot in it works and you're like, okay, cool, it works.

30:59.160 --> 31:01.920
Then you want to add another 10 or 20 questions.

31:01.920 --> 31:05.400
Then you get a lot of conflicts because there's lots of similarity between those questions

31:05.400 --> 31:06.920
and existing questions.

31:06.920 --> 31:11.520
And that's the downside to doing that approach and the upside to having a vertical and a

31:11.520 --> 31:16.640
well-defined taxonomy to take into account everything that could be asked in that vertical.

31:16.640 --> 31:25.720
And is there a right or a wrong way to approach building out that taxonomy in terms of this

31:25.720 --> 31:32.160
line between the intents and the entities or is it more, you just have to do something

31:32.160 --> 31:38.080
and stick to it and be absolutely consistent as you expand out your vocabulary?

31:38.080 --> 31:40.440
Yeah, I mean, there's no right answer to this.

31:40.440 --> 31:43.320
It's a very difficult problem to solve.

31:43.320 --> 31:46.600
It's not that you can't change it afterwards, but you want to change it a little bit.

31:46.600 --> 31:47.600
You want to tweak it.

31:47.600 --> 31:50.200
You might split some intents or combine other intents.

31:50.200 --> 31:53.760
But you don't want to completely rebuild the system every few weeks or months.

31:53.760 --> 31:54.760
Sure.

31:54.760 --> 31:56.880
It's a bit of both.

31:56.880 --> 32:01.880
But there was another question that I wanted to ask that's maybe going a little bit back

32:01.880 --> 32:10.240
to, you know, so you kind of, you scrapped API.ai and built your own system for doing

32:10.240 --> 32:11.240
this.

32:11.240 --> 32:15.360
And you said it was, you said it was spark and Python.

32:15.360 --> 32:21.720
Did you also invest in building like, you know, almost like a user interface or kind

32:21.720 --> 32:30.440
of a higher level platform tools for both your internal people and the banks or your, you

32:30.440 --> 32:35.480
know, how sophisticated it does that layer need to be in order to have a usable system?

32:35.480 --> 32:37.720
Yeah, it's a very complex system.

32:37.720 --> 32:40.720
And it's, I guess, 70% built right now.

32:40.720 --> 32:41.720
Okay.

32:41.720 --> 32:43.040
And mostly the internal functionality.

32:43.040 --> 32:46.720
We don't have the external bank facing side of things for running it.

32:46.720 --> 32:47.720
Okay.

32:47.720 --> 32:49.440
But it's essentially our interface to our database.

32:49.440 --> 32:54.280
Where we define what intents belong to each customer, what the taxonomy is for that, for

32:54.280 --> 33:00.200
instance, what entities are in there, where they apply, what the response content is, and

33:00.200 --> 33:05.680
the ability to map from utterance to those intents and support the user in making those

33:05.680 --> 33:06.680
decisions too.

33:06.680 --> 33:09.960
So to make sure that you got the context is what that intent means.

33:09.960 --> 33:13.640
If there are a few hundred intents, it might be difficult to know exactly what an utterance

33:13.640 --> 33:17.120
should go into if you're not, you know, fluent in the system.

33:17.120 --> 33:20.600
So we have some supporting information, metadata associated with that, or examples that

33:20.600 --> 33:23.240
already exist to help you make that decision.

33:23.240 --> 33:24.880
So yeah, that's called the Atlas project.

33:24.880 --> 33:30.440
That's kind of our, I guess, the heart behind everything.

33:30.440 --> 33:31.440
Hmm.

33:31.440 --> 33:32.440
Interesting.

33:32.440 --> 33:33.440
Interesting.

33:33.440 --> 33:39.160
And then in terms of, we were speaking upstairs earlier, and you mentioned that you, as

33:39.160 --> 33:44.800
part of, you know, getting to this initial production customer, you kind of replatformed

33:44.800 --> 33:45.960
everything.

33:45.960 --> 33:50.760
How did you have things deployed before and how are they deployed now?

33:50.760 --> 33:56.720
So before we had APII for doing a lot of our functionality for entity recognition, for

33:56.720 --> 34:02.120
instance, as well as the model itself, but now we have that entirely ours.

34:02.120 --> 34:03.120
It's a rebuild.

34:03.120 --> 34:04.120
Okay.

34:04.120 --> 34:10.040
Yeah, I guess I was wondering in terms of, I guess, now that you've kind of built your own

34:10.040 --> 34:18.120
platform for a place, APII.AI, what processes and automation have you built up around deploying

34:18.120 --> 34:20.000
models up into production?

34:20.000 --> 34:21.000
Yeah.

34:21.000 --> 34:27.040
The offline stuff, so the training of the model, we don't have kind of well-defined release

34:27.040 --> 34:28.640
processes for that side of things.

34:28.640 --> 34:32.600
But any model we build and we release, we have a strict release process that's done

34:32.600 --> 34:37.880
with engineering and DevOps, and we ensure that we have a record of what models deployed

34:37.880 --> 34:43.520
in which environment, what was trained on, what the results of evaluation were over time,

34:43.520 --> 34:44.800
and it's controlled.

34:44.800 --> 34:49.600
We don't just release models whenever we feel like it.

34:49.600 --> 34:54.000
We also have test suites that we must run through before we ever release anything to

34:54.000 --> 34:56.800
production to make sure we've not broken anything.

34:56.800 --> 35:02.720
If any intent has reduced in accuracy in the effects, something else down the line in

35:02.720 --> 35:07.360
terms of maybe a flow, a conversational flow, or some keyword isn't working at some point

35:07.360 --> 35:11.600
in the flow, we've got to make sure that's caught and not deployed.

35:11.600 --> 35:18.880
Though I think we're maturing as a company, and that we're a lot more strict on our deployment

35:18.880 --> 35:23.080
environments and how we're actually doing things, but yeah, everything is hosted up on the

35:23.080 --> 35:30.320
cloud and got a serialized model to produce the intent recognition side of things.

35:30.320 --> 35:32.440
Yeah, it's working pretty well.

35:32.440 --> 35:37.880
You mentioned that you're also able to catch when intense change meaning and things like

35:37.880 --> 35:43.320
that, and testing, but are you also able to, do you have machinery in place that is able

35:43.320 --> 35:49.760
to identify, I guess I'm thinking of it like kind of the long tail of intense or entities

35:49.760 --> 35:56.040
that aren't being caught by the system, like how automated does that need to be?

35:56.040 --> 36:03.240
Is that something where you're running a weekly or monthly report and just look at what

36:03.240 --> 36:08.920
isn't being caught correctly or is there an automated process in place that is always

36:08.920 --> 36:14.840
up to date and you're always trying to catch up to build out that long tail?

36:14.840 --> 36:19.840
Yeah, I think to some extent some of the long tail, we're never going to go down to.

36:19.840 --> 36:21.080
It's a long tail.

36:21.080 --> 36:22.640
It's a long tail, for sure.

36:22.640 --> 36:28.440
When we do have the human and loop functionality, it works really well for our use case.

36:28.440 --> 36:31.760
When it comes to finding the things that we probably should support, oftentimes we will

36:31.760 --> 36:37.440
have that ability to run it through our actual model, our kind of model trained on everything

36:37.440 --> 36:41.520
that we have, rather than the model of things that we support for that agent.

36:41.520 --> 36:45.000
Then we can find out if there are things that we're accurately catching, but they just

36:45.000 --> 36:47.600
don't have a response for.

36:47.600 --> 36:51.880
So it looks like we just don't support it, that catches some of those things.

36:51.880 --> 36:57.400
We can also use unsupervised kind of clustering to find groups of things or questions that

36:57.400 --> 37:02.640
converge around a new topic or a new kind of question type that we may want to suggest

37:02.640 --> 37:08.880
as a customer to include or for us to include in our taxonomy if it does not already.

37:08.880 --> 37:11.720
We do also do manual log analysis.

37:11.720 --> 37:14.520
For the time being, we're keeping an eye on the data.

37:14.520 --> 37:18.880
A lot of the data is, especially now we've got a production data coming in, it's interesting

37:18.880 --> 37:19.880
to see.

37:19.880 --> 37:24.960
Just hand, help you make decisions on how we further the product from a customer point

37:24.960 --> 37:25.960
of view.

37:25.960 --> 37:26.960
Interesting.

37:26.960 --> 37:27.960
Interesting.

37:27.960 --> 37:33.800
It sounds like you guys are doing some really interesting things, and in particular it's

37:33.800 --> 37:38.560
interesting to hear some of the background behind kind of the platform shift and what

37:38.560 --> 37:43.840
that's enabled you to do, so thanks so much for sharing that and I'm looking forward to

37:43.840 --> 37:44.840
catching your talk.

37:44.840 --> 37:45.840
Awesome.

37:45.840 --> 37:46.840
It's a pleasure.

37:46.840 --> 37:51.840
Awesome.

37:51.840 --> 37:54.920
All right everyone, that's our show for today.

37:54.920 --> 37:59.400
Thanks so much for listening and for your continued feedback and support.

37:59.400 --> 38:04.400
For more information on Kenneth or any of the topics covered in this episode, head on

38:04.400 --> 38:08.840
over to twimlai.com slash talk slash 61.

38:08.840 --> 38:16.680
To follow along with the Georgian partner series, visit twimlai.com slash gppc 2017.

38:16.680 --> 38:22.520
Of course, you can send along feedback or questions via Twitter, at twimlai, or at Sam

38:22.520 --> 38:26.520
Charrington, or leave a comment on the show notes page.

38:26.520 --> 38:30.000
Thanks once again to Georgian partners for their sponsorship of the show.

38:30.000 --> 38:35.040
Be sure to check out their white papers, which you can find by visiting twimlai.com slash

38:35.040 --> 38:36.040
Georgian.

38:36.040 --> 38:46.680
Thanks again for listening and catch you next time.

