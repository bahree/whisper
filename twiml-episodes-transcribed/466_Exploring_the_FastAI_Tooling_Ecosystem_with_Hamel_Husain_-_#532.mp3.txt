All right, everyone, I am here with Hamil Hussein.
Hamil is a staff machine learning engineer at GitHub.
Hamil, welcome to the Twimal AI podcast.
Thank you for having me. I'm excited to be here.
I'm excited for this conversation and in
particularly because we've had a couple of reschedules due to
technical issues. So this is a hotly anticipated
conversation on my part. It was anticipated prior to all that, but
really looking forward to digging into the chat. Let's jump right in and
have you share a little bit about what you do at GitHub.
Yeah, yeah, thanks for asking. So I get up, I've been doing a
couple of different things. So I spent a long time at GitHub doing
open-source work. So I've worked a lot on fast AI, so
GitHub sponsored me to work on fast AI for a large period of time.
And then I also did a lot of work with GitHub actions, integrating those with
different data science, open-source projects, like
great expectations, Jupyter, Kubeflow, so on and so forth.
Now that I've been working a lot internally on our ML infrastructure,
so those are kind of like different flavors of things. Currently I'm on
paternity leave, so I had a new born two months ago.
So I technically have not been doing anything
work related for a couple of months. I won't get
I was going to go down to Rathole and ask you how your sleep was, but
well, that's actually despisely not so bad compared to
my first child, so. Oh, that's awesome. That's awesome.
I guess I wanted to, I want to kind of start out with the fast AI
work that you've been doing and how that came about, but
it may be useful context for you to share a little bit about your
background and kind of how you came to work on the infrastructure side of
machine learning. Yeah, so I started in data science
a long time ago, around 2003 or so when I graduated from
undergrad, and back then I was working as a
as a statistician predicting a loan defaults for a large bank.
After that, I went on to work on work and management consulting,
doing like a data science flavor of things. I had a brief hiatus where I
tried out a different career, which we don't have to get into right now.
And then we're back to the technical consulting and then I decided
after doing so many data science projects at different companies and
different industries, I knew that tooling was like really far behind because
people always struggled with deploying models,
monitoring them, doing things in a systematic way.
There was a lot of open source tools, but not really good systems.
And so at that time, in 2014 or so, I was happy to be living in
Boston at that time and at that time, and there was a startup called data robot
which was building ML tooling, specifically is auto ML tooling.
So they got a bunch of people that are really good at Kaggle,
three or four different grandmasters, all of who which were like number one at some
point, decided to bake in a lot of their best practices with regards to
modeling to a product. And I thought that was really interesting.
So I joined them. I learned a lot there about how to create software for data
science. It's spent a lot of time talking to
kind of implementing these systems at different companies that are trying to
use it, trying to automate some of their machine learning processes.
And then I ended up moving to the Bay Area because of my wife.
She was doing medicine and she's in a fellowship program so we had to move to the Bay Area.
Then I decided, I would like to experience one of these
Bay Area companies that keep hearing about, like it's some kind of like a
different, you know, from the outside Silicon Valley looks like a
really different and kind of amazing experience.
You know, when you hear about it, like at least like when you're
yeah, when you're living somewhere else or you're not part of that.
So I thought I have to like experience this. So I joined Airbnb as a data
scientist shortly after coming to the Bay Area.
And that was a really interesting experience.
When I found the Airbnb, like, so when I first got to Airbnb, I thought
it would be really advanced in terms of like ML tooling, ML infrastructure.
I thought how won't need any tools and infrastructure.
You know, they already have those because it's you know, it's Silicon Valley.
And so when I got there, you know, I just, the first project
there it gave to me was this model that forecast LTV.
And they said like, hey, can you just review this model? Yeah, lifetime value.
Yeah, for marketing, for growth marketing.
And they asked me to kind of take a look at it, you know, see if
you can make any improvements on the model, kind of like your first, you know,
getting your feet wet into the place.
And so actually this particular model was a guy who ran an R
script on his laptop, it's about coefficients,
any copy and paste coefficients into an Excel spreadsheet,
which had like formulas that would like materialize these coefficients into
a SQL query that didn't copy and paste it into airflow.
And it like really blew my mind and I thought, wow, like there's
made it to Silicon Valley. Yeah, I thought I made Silicon Valley.
And you know, working at a very celebrated tech company
and it's like, wow, okay, like there's no ML tooling at all whatsoever.
Like it's the most bit, you know, it's kind of,
you can't really imagine anything more basic than that.
And so then I started to build tooling at Airbnb.
And then, you know, kind of got back into tooling.
And then eventually, and then I created a lot of things,
a lot of like artifacts that ended up being used for big head.
And then after that, I ended up going to GitHub,
which is where I'm at now. And then I started working on infrastructure
there and tooling there, ended up working on a lot of open-source stuff
through regards to tooling. And so at this point, I'm pretty much
sold myself or convinced myself that I will be tooling,
doing ML tooling for the foreseeable feature.
Because I keep somehow floating back into that no matter how hard I try to do
anything else.
At GitHub, what are the main kind of use cases that
ML is being used for nowadays? I mean, there's stuff that we hear about like
co-pilot. But I imagine that probably most of the use cases that,
you know, GitHub, ML engineers and data scientists are working on are kind of,
you know, internal types of use cases. And then maybe not dissimilar from the kind of thing you did at
Airbnb, supporting growth and kind of platform
health and that kind of thing. Yeah, so there's a bunch of different use cases
that GitHub, some of them you touched on. So a lot of forecasting of various things
in terms of like infrastructure usage. Also, there's a lot of platform health
stuff like detecting spam, detecting bots of various kinds.
Apparently, people like to buy stars, things like that, you know, like,
you know, catching things like that or catching abuse of the platform.
That was a thing. Yeah, I didn't know that was a thing either.
Seems like a pretty low point in your life if you had to go buy stars.
But and then there's some there's actually some user-facing stuff
that are not known so widely. So if you go to github.com slash explore,
you'll see kind of a recommendation of different repositories you might be
interested in based upon your activity on GitHub. And then also,
like another example is if you create a new repository,
you can attach topics to it like different tags. And so there's a small
recommendation system that will recommend other tags you should apply.
So there's some things like that. So these are the kind of things that data
scientists work on inside GitHub. And there still is pretty a
pretty new thing for GitHub. Yeah. It's not really,
it's something they're actually building up right now. It's in this most
nascent stages, I would say. And so with that in mind,
what does the platform look like at GitHub? Yeah, so it's been
changing quite a bit. So we were on AWS before. And then we had kind of
our own homegrown infrastructure that was composed of using a bunch of
different things like cooflow, in some other stuff.
And then we got Bob on Microsoft. And then we started transitioning
everything over to Azure and using Azure ML. And so
Azure ML is kind of like is the managed service with the Azure
provides. And it kind of is white labels a lot of ML flow stuff as
well. So with regards to the experiment tracking and the model
registry and things like that, it has your ML more or less adopts
that behind the scenes. And so that's what that's what they're
using. And so how did your work with the fast AI
team and the fast AI tools generally come about? Yeah, it was
really organic. So the way that happened was when I first got to
GitHub, you know, I think GitHub was still trying to find that
like kind of get a sense for what it wanted to do with ML.
There was definitely a lot of prototyping and sort of exploration of
the space of like different ML projects, but it wasn't quite
solidified yet. And so in the meantime, what I did was kind of do
work in open source to kind of, you know, just for fun or just kind of
see, you know, what, you know, and also look for opportunities for things that
might integrate with GitHub. So at some point, it's always been
like a student of Jeremy's like from a long time ago.
And so one of the things that we, one of the things I ended up
learning like a long time ago and one of his classes was
about how to do semantic search. So he showed something in one of his classes
where he had like photos of different objects and you could search those
photos semantically using natural language, but also like, you know,
even if the photo, you know, if you construct a shared web vector space,
you know, you can create a semantic search. And so this is back in, I don't know,
like 2017 or something. It was a little bit of a newer concept.
And so I decided to try that out with code. So I thought that was be really
interesting. And at that time, like, no one has really used GitHub's public
data set before. It wasn't really, for whatever reason, like, I don't know,
ML people have like ignored GitHub data set. Maybe it just wasn't obvious
that you could get it and do something interesting with it.
So the thing that's really interesting about GitHub's data says you can,
you can actually construct a really interesting parallel corpus out of it
with regards to, so you can get a bunch of you code. So like, for example, Python code,
you can get pairs of doc strings and code. It takes some work. You have to like,
get the code, clean it, you have to parse it out, you have to parse the doc
strings out from the code and like, you know, and then remove the,
you get a lot of duplicates and do all that stuff. So I mean, that's a
tremendous amount of work, but you can actually get a very interesting
parallel corpus. And then you can do a lot of representation learning on that
code. And then you can produce some things that are
really interesting. So then I started to work on that
in open source. And then what eventually happened is we got bought by Microsoft
and then there were some people on Microsoft research that are interested in
that. We're going to be using like, fast AI in that. And that was one of the things
that I think Jeremy was really excited about, like, one of the things that,
you know, like an example of a use of this library in the, you know, kind of in the wild.
So first, this is my first involvement. And then at some point, get up, release,
GitHub actions. And so then I started going around to all these open source projects, like Jupiter,
Great Expectations, Scoop Flows, so on and so forth. And started making integrations between
GitHub actions in these various data science projects. So like, for example, there's a,
there's a project called Great Expectations that is like, testing for data quality.
So I thought, okay, it would be really interesting to do like CICD for data quality,
like, let's say if you're like updating a SQL query or something like that,
like it wouldn't be cool if you had a test that could run, you know, if you're changing,
you know, changing SQL code in a PR, you know, when you could trigger that test,
things like that. So like, and then I started helping Jeremy out with his CICD.
And then one thing led to another and then start working on more and more things.
Like, once you start working on someone's CICD, you have to like, understand like,
whole their code, how it runs, like, you know, how the tests are run, what they mean,
what's breaking, you know, and then I started helping with this documentation.
Even going back quite a few years, they've been doing pretty interesting things like
integrating in documentation and code and doing that all in notebooks as opposed to kind of
traditional code files. So I imagine you'd have, you got sucked into that and that led to,
you know, some of the things like MBDev and FastPages.
Yeah, yeah, yeah. No, that's a good, yeah. So fast forwarding, that stuck, you know,
went into a big rabbit hole on all these things that you described.
Because then I started wondering like, well, how is all this stuff created?
Like, it's not that clear to me because actually, you know, like, they're doing a lot of interesting
things using a very unique tech stack. And so then I went and learned that tech stack and then
I got really involved in things like MBDev and FastCore and started working on that.
And then subsequently, I work on a bunch of other projects. So yeah, it was just very organic.
Kind of went into, you know, you see one thing, interesting, another thing,
and at least some things pull in threads. Yes, yeah. Yeah. So what is MBDev?
Yeah, MBDev is a development environment that all of FastAI is built in. And it's a
literate programming environment. So the idea is you should be able to write your code in
your documentation and test all in a single context. And not have to write, you know, your code in
a different place, your test in a different place in your documentation in yet a different place.
And keep those all in sync yourself. But like, that should be more natural. Like, hey, write some
code, explain it to yourself, into your users, and then have like inside the documentation,
have some runnable code that explains like how this code runs, like by example.
And then, you know, also make those tests, if you can as well, but make it very natural,
like a conversation with your users. And have that be run every single time your code,
you want to, you know, update your library and have those tests always run. And so,
so basically what MBDev is is built on some of the things that Jupiter for the interactive aspect
of like writing code, but also being able to write prose alongside your code. So it integrates
that with a static site generator that renders documentation, and then also some other things that
export notebook code to plain, you know, like modules like to Python modules, like that you would
write in the ID like VS code. So it's a system that like glues together these things to create a new
development environment, that is this literate programming environment. And it's kind of hard to
explain like in this abstract sense, like I would definitely say something to experience.
Because when someone explained it to me, I was really skeptical. It's like, well,
it sounds like Jupiter. Yeah, you're like, well, what do you mean like MBDev? You just write
everything in notebook. And that's not really what it is. It's, it's, it's happens to be using a
notebook, but that's not the central point of it. The central point of it is like it's an experience
where you write, yes, you are, in this specific case, you're writing in a notebook, but you're writing
your tests and documentation in the notebook with some special sugar in syntax that's available to you
with for various options. And then that all gets that automatically like gets create like documentation
gets created and tests will get run NCI for you automatically. And the result of that is like
much higher quality software and also like much lower iteration cycles. Because what happens is
okay, it's like most people don't write documentation and most people don't write tests. And why is that?
Because like writing documentation sucks. Like you write your code. And then now you're asking
the developer to like, well, just go write this other documentation somewhere else and then
keep that in sync yourself. And like, that's a pain. Like, you know, no one does that properly.
Like very few people do that properly. And same thing with tests. So like, it's really like a new,
it's a new development workflow. And it's like one of the secrets behind how fast the eye,
like you might be wondering, like, how does Jeremy and like maybe one other person,
depending on who's on it and fast the eye at the time, develop all of the software.
And one of the secrets behind that is MBDEF because it helps make you a lot more productive.
Yeah, like I mentioned, it does sound quite a lot like Jupiter or maybe Jupiter with some,
you know, annotation types of things that let you say, hey, this is doc, this is code,
this is test. But it sounds like it's more of a system than that. You mentioned literate programming
a couple of times. You know, what is that and how does that play into what they're really trying
to do with MBDEF? Yeah, literate programming is this like big concept. I don't know who invented it.
You know, I have to look that up, but it's this concept where like your programming environment
should not be dead. Like it shouldn't be completely static. You should be able to see the result of
your code and how that changes, you know, inputs and outputs in real time as you're as you're programming
and not have it be, yeah, like and be able to experiment on the fly. Then also like pros and
code should be able to be intermingled naturally because you want to be able to like talk to
your users and talk to yourself and document your code. Beyond, let's just say like comments
necessarily like and you want to be able to kind of have this expository like form of programming
where you can kind of show your code in the same context as like writing code. And yes,
that sounds a lot like Jupiter, but like it's Jupiter like with some other things to allow it to
go the whole way because like Jupiter in it by itself is not necessarily like taking it doesn't
doesn't allow you to software engineering completely the way you might want to do it. Like it's
not necessarily the best suited ID just to create like Python modules and you have to export that
somehow out of a Jupiter notebook if you're just using Jupiter. And then it's not necessarily
straightforward like how would you write tests in Jupiter? And it's not necessarily straightforward
like how would you how would you create like yes it looks like when you if you write a really
polished Jupiter notebook it can look a lot like documentation within like how do you actually like
create documentation out of that in a systematic way in a reliable way and then give users a lot
of different options like how to control that documentation because like you said like
might not want to show all the code in the documentation or might want to show certain things
like how do you do that. So it's kind of like you know that friction you feel like and everyone
that may have may feel this like you're in the notebook you're developing some code and then
at certain point you're like oh my god goodness I need to take this code and make it into plain
text and you refactor it and you're going back and forth a lot. And I think everybody's like
a little bit frustrated in that process. You know intuitively like can there be a better way
but we have all learned to ignore that and just like say well that's just part of life. So MB
Dev is kind of this answer to no like we shouldn't ignore that like let's try to find a way.
So my no means MB Dev perfect. It's kind of like the best kind of thing that we can have
with gluing together existing technologies. But I think you know someone could definitely take
the concept of MB Dev and build something from first principles that may work even better.
But yeah MB Dev is kind of like the thing that just can work with just like kind of hacking
some stuff together right now. From the description it sounds like yes it's this tool that
the fast AI team built to allow them to build the fast AI library but it can be used more broadly
you know by anyone for anything. Is that yeah absolutely yeah. Yeah I mean it's not just for data
science at all. In fact I feel like it's been used for more regular software projects than it has
been for anything related to data science. So there's been a lot of like API clients written
with MB Dev. There's been all kinds of other software that's been written with MB Dev.
And so yeah I really think like it's a window you know of course it only works with Python
at the moment. But I think it's general software development. It's a way it's a development
environment for general software development. When I think about some of the activity in the space
you know I think of things like Netflix's and Compass like these and in fact
this was probably after your time at Airbnb but at some point they were kind of going down the
path of trying to like production eyes notebooks. A lot of people have made attempts at that.
This would you say that MB Dev is in the same vein. You know in some ways it's more like what
fast AI was actually trying to do was like write books and courses and you know things like that
more so than production software. Even the the the framework the library you know they weren't
necessarily they were authoring it they weren't necessarily trying to productionalize it
in the traditional sense of the word. Is there a productionalization or operationalization
aspect to MB Dev at all? As far as MB Dev is concerned it is it's all it is definitely about
you know making proper Python modules and allowing you to I mean it is definitely all very much
about productionizing software in terms of making Python modules and packages pushing them to
pypy making sure you have good documentation and good CI because like when you start an MB Dev
project it automatically stubs out like CI for you so that it's kind of already there and so
it's very much geared towards nudging you towards productionization. Now as far as fast AI is
concerned I think one of your observations is definitely correct like I don't know that fast
AI has been overly concerned about productionization of of applications with fast AI like like you
know there's relative to other tools that you might see so for example you know like TensorFlow has
like TFX and TensorFlow serving and stuff like that so definitely desktop does not there's not
that those kind of things don't are not there for a fast AI and you're right like one of the things
that was like really important in a fast AI is to be able to have really good documentation
and also like good tests because especially like with the service area and then like only being like
one or two contributors full time and so one of the goals is like okay like the the docs have to be
really good because after all it is a you know this is used for education and the docs are not good
you know people are going to get lost very quickly but then you know the the problem is with docs
is like how do you keep those in sync with the code with in the code is changing so rapidly
because the fast AI changes quite rapidly you know it's they're always keeping up with state of the
art things and making their own state of the art things and so the kind of the answer to that was
like hey let's make documentation of first class citizen like you should be doing it while you're
writing software like you should be really natural there should be no friction in introducing
documentation and so that's kind of exactly what yeah that's why MBDev allowed yeah is a what
are how to fast core on fast pages relate to MBDev yeah so so one background of Jeremy is he has
programmed a lot of different languages prior to Python well he he I think he says like and you
know he says it sometimes that he's been programming every day since he was I don't know what it is
yeah I was laughing because it's probably been a couple of years now but in our in the
tumult community we you know very early on kind of recognize the you know the importance of what
he was doing with the library and hosted a study group around the course and I remember kind of
vividly you know my early experience with the library and and other people's and I remember
making a comment on our slack like why does he name these parameter names like this why does he name
stuff like and someone was like yeah he was a pro contributor back in the day and I'm pretty
far at some about this in a in in one of the past interviews with with him um but uh yeah
he's been programming for for quite a long time and and and he's um you know he draws a lot of
inspiration from uh kind of classical computer science like the um the literate programming is done
new thin um there are a bunch of other folks that like he's a big fan of APL yeah is you know
took a half a semester or a quarter of a semester and like a survey course in school and it's like
the only thing I remember about APL is that it had the weirdest keyboard you had all these symbols
uh you basically you know programming and you know Greek symbols uh with APL and like Jeremy
Supern of that um so uh yes yeah no and this shows up and so like you know um and he's not exaggerating
when he says that because I've spent a lot of time per program per program with him and you know he
actually spends a lot of time hacking in different languages even right now and so he's
what that ends up when it's happening is he whenever he uses a new language he always like creates
like a very he tries to hack the language deeply and create a bunch of utilities that bring in
like other aspects of different like paradigms so like you know the one thing he misses about
Python is like he well you know he wants more functional programming tools or he wants more
like macro like meta programming abilities and things like that um and so you know that's what
Fastcore is it's like hacking Python you know deeply to give you like some more functionality or
some different types of functionality that you know you you might want and then he ends up using
in the using everywhere but um this is pretty like so if you just read fast AI code
you know a lot of it may look pretty foreign uh not only in syntax but in style
uh you know like you said like you know so there's like some things like succinctness which you
know he really values he really likes to keep likes to keep uh lines of code like make things
on one line and the idea is like you could see all the code in like one page or it's close to one
page as possible or something like this and so um that's where fastcore comes from it's a very
interesting so like to understand it was a deep rabbit hole like to understand fast AI deeply
I had to understand development environment which is then be dead of then all of a sudden
but then when you start to look at the source code you have to understand like this fastcore
uh to understand like the source code and then like yeah it just goes from there so like
it's pretty interesting if you're if you're trying to like understand more about the Python
programming language like a little bit deeper level it's pretty interesting to look at fastcore to
see like all the things you can do and then try to you can like get some insight and like how some
of these things are done it is pretty interesting uh it's a way to definitely learn more Python even if
you're like using it every day yeah yeah I remember having that experience going through uh through
the course like you know hacked a little bit with Python or you know it kind of your typical Python
stuff right um you know as far as maybe calling a name function or whatever to get a list of
methods or something like that but you listen to Jeremy kind of talk about Python and work
with it in these you know using all kinds of exotic dunder functions and stuff like that that
it's like okay yeah yeah no that existed it's really interesting like and then you might wonder
okay like well why is this even a good idea like well why why does this like does this this is
actually make this person more productive the cost and benefits of these things and so one thing
I will say is like a lot of this like actually like isn't like isn't service of some kind of learning
as well like doing this whole thing like is a journey of like also continuously learning the Python
programming language at a deep level and uh he engages he does that like really soon like anytime
he's frustrated with anything in Python he'll stop say okay can I like change it whereas like
someone like me would be like okay like well just let's just let's just move on let's just do it
but then like the thing is like it adds up really fast like then he ends up becoming really like he
ends up knowing a lot about Python like really fast um even like very esoteric things out because
they're esoteric like he'll know it like and so you know I think that adds to the productivity
productivity component um but you know it does have the cost of like other new covers okay like if
you want to contribute to a fast AI library you kind of learn this other thing and you know so
the rabbit hole is deep it sounds like yes yeah very deep yes yeah so that's fast core fast pages
you know one thing that is really important is I find as a data scientist writing blocks like
it's it's really useful to like share your knowledge and so you know whenever written blogs before
um you know I used to use medium and like you always want to you know a lot of times you want
to put code in your blocks but then you know the process of writing is not linear like you start
writing it down you're like oh you know actually this code like I don't like it anymore like maybe
I'm this doesn't really make the point that I was thinking or whatever and you change your code then
you get like copy and paste all your code again into this thing and then like update your words
around it and like update the output and you're like this is a big mess you're like copying
and pasting constantly and then you're like you you realize like why am I doing this like
like I'm a programmer why am I copying and pasting like charts and graphs and things into this
things I can like write a blog post like doesn't make any sense like if I'm changing can I just like
change all of this stuff with code and then you also realize like hey there's like Jupiter like I can
write work I can just run a Jupiter no it like isn't a Jupiter notebook like a block like I can't
why can't a Jupiter notebook be like a block like it's pretty obvious like and then I start looking
around like how do I turn a Jupiter notebook into a block and actually there was not good answer
for that it's like well you know like it was like very hacky like nothing really works very well
there's some like here and there are different things as I look I just want something that just like
I save a notebook somewhere and it just becomes a blog and then I have some ability to like hide
cells and show cells and do some things like that and then so I took some of the ideas from
MBDev with regards to how it renders docs and I said well why can't I just be a blogging platform
and then all the conversion process and all that you know can you just automate that with
GitHub actions can we have like triggers to say okay when you update something in your repo it
just re-renders the notebook and re-processes it and makes it into a page and so that was the
general idea of that it was just like making it easier for you to write your blog as a notebook I've
always appreciated how weights and biases does that they have a nice implementation of being able
to kind of blog your experiments and things like that is it in a similar vein yeah yeah I really
like weights and biases too one of my favorite tools it's it's similar to that I'll say weights
and biases more of a you don't really have to even you don't really have to write any code really
if you don't want to you can just start typing like a Google doc and you know plus a plus stuff in
there so I think that's really good at a lower level yeah I said lower level it's like you make
it proper duper a notebook and you save it um weights and biases the visualization layer is a
bit different um they're not really just like using like Python in there it's like some other syntax uh
you know and you can use Vega and something like that to create custom visualizations and you know
it's kind of this middle ground yeah so yeah it's it's a bit different but similar kind of a
similar genre I guess and then you mentioned uh GitHub actions in oh you've mentioned it a few
times but you know most recently kind of as a um part of the the fast pages process you know
talk through GitHub actions and some of the ways you've used them to support data science
yeah um so the idea is like can we use like can we have CICD in various like
data science workflows like doesn't make sense so for example so while we're talking about weights
and biases um so one integration that I've made is something that will uh you know ping weights
and biases for experiment tracking results and bring those into the PR and render them in the PR
uh so that you can view them and then have a discussion so the idea is like uh the example that I
showed was you know you bake a PR against a modeling code I don't know if you've seen PRs like this
but I've seen a lot of different PRs that for someone makes change to a model and then you know
what the the review is like hey like what happened is make the model better and their response is
yeah it makes it better and you just emerge it but like you know that is broken like we know
that's broken like we can't do that we can't do have this like you know this like uh you know
hearsay conversation about code like it should be something that's very objective like more objective
and so the idea is like okay like can you bring your experiment tracking results into the PR
to you know accomplish to like bring more visibility into the results of workflow and there's a lot
and there's a lot of different um nuances there like I don't want to just give you the impression
it's just like something is triggered on every push or something like that just like normal code
like machine learning is a little bit different so the idea is like can we deserve an integration
that makes sense and those those are the kind of things that worked on uh for example
um there's another like there's another thing where um this is a project called repo to docker
that takes like that takes uh any repository like data science repository and dockerize it
and this is for the purpose like this is what binder uses like if you try to go to binder and like
give it uh get up url it what we'll do is like it'll give you a jupiter notebook but it'll try
it's best to like build the dependencies by introspecting your repo so you don't need docker file
there you're just you know giving it a typical python repo maybe it has a requirements txt file
and it's gonna figure it all out yeah it'll try to guess like it'll you know as a hierarchy like
it'll encourage requirements txt file if it doesn't find that it'll like look for a condo file
it doesn't find that it'll like look for something else and look for like these things
and like you know it also supports docker files or you know if you have that it'll look for that
or do whatever but you know a lot of people don't have that stuff like my that data scientist
just have requirements txt or something and you want to reproducible environment so it's like okay
can you have get up actions automatically build that for you and deploy it somewhere um so that's
being used uh get up actions you know and so the get up action is interesting because like you can
pre-package them and like make them modular so like this weights and biases thing like you don't
have to like you can just call the weights and biases action and like say okay like you give it like
some like three or four parameters to get it working you don't have to like use all the code that
I created for to to ping the weights and biases API similarly like for this is duper example
you know you just just give it like whatever parameters like let's say you're trying to push
this thing to a docker repo this image that you automatically build you just give it like your
docker credentials and off you go you don't have to like so like that's that's the kind of power
of get up actions is like you don't have to worry about the complexity of these things you can just
use them in your work about it so high level you've got uh various life cycle triggers on the
get hub side whether that's you know code being pushed to something or a new comment in an issue
and then the action itself kind of encapsulates integrations with other things and so you can
basically hook all your other things into various stages of your of interacting with get hub
yeah absolutely yeah that's a good explanation and then um so some of the ones you mentioned
and did you mention actions for great expectations yeah yeah yeah yeah yeah so you can say you can
let's say you have like a SQL file in your repo you can set up an action to trigger like if you
change this equal file uh you know let's say and then you know you want to validate the data that
is like emitted by this equal file or maybe it's even a table definition that you have in your get
a repo um you can have that validated by great expectations and then you can have the action
like tell you whether a pastor failed the expectations check if it fails you can actually have it
place a link to the the dashboard that great expectations produces um and you know
things like that so just make it a little bit easier for you as a data scientist like when you're
doing something to have it more integrated uh you know where it makes sense yeah maybe kind of
wrap things up do you have visibility into kind of the direction that Jeremy and the the team are
headed with fast API I'm wondering like you know what you're excited about there or um you know
what you're looking for to taking on once you're back from paternity oh yeah that's a good question
I haven't you know I've tried to stay true to my paternity leave and try to not pay too much
attention to the outside world it's been hard um but actually don't know to be honest with you like
what necessarily they're gonna focus on the most I would actually have talked to Jeremy
yeah to ask him about that to be honest um what uh what what was on your list of things that you
were kind of looking forward to and excited about before you left do you remember yeah so I was
actually looking so one thing I've been really like interested in is like the explosion of different
ML tooling out there mm-hmm and how this space is going to evolve yeah uh and you know um and then
also like I was looking into like because like uh you know I haven't mentioned like GitHub is
moved on to Azure using Azure ML I was actually looking at all these different alternative workflow
tools for ML mm-hmm it's I was exploring a lot of them and one of the one that was most excited
about so far is Metaflow mm-hmm from Netflix team so uh yeah that's one of the things we've been
playing with most recently nice so we'll see maybe I will do something in that with that project
in the future nice I had I interviewed recently Vela Toulouse who is the the founder that he's
no longer in Netflix now he's kind of doing a startup based on Metaflow so um you know I'm sure
there'll be lots of opportunity to dig into what they're up to there yeah yeah there definitely is
and uh yeah I've been uh talking to Vela as well with the great interests and so yeah I think
that's a really you know I'm really excited about their project and what in particular uh out of
curiosity uh you mentioned all of the projects that are out there there are a ton of projects out
there what in particular about that one uh catches your interest yeah so a lot of projects uh they're
out there so like before this I was actually involved in Coopflow um and and so and then I've also
used MLflow uh because of Azure and things like that and so one of the things that really impresses
me about Metaflow is where how they meet the user where they are and so what I mean by that is
for example Coopflow kind of tells the data scientists hey you should learn
Kubernetes yeah um you know they may not say that explicitly but that is
that is definitely like lurking in the room right and the ultimately like that makes it
difficult can make it very difficult for adoption it's kind of like saying hey like I want to drive
this car but I need to have a mechanic sitting in the passenger seat next to me the whole time
mm-hmm and like no I don't want to drive a car like I cannot drive a car like that like can I just
drive a car and so um you know I think with a lot of the Netflix info uh like that that you see
you know it's kind of different like in terms of you know they try to meet the user where they are
some might argue they made to try to meet the user too much where they are maybe like with this
notebook info I think that's really cool like maybe some of those things are like experiments to
try to see how far they can push the envelope either way I really like the the whole uh notion
of meeting the user where they are and thinking about what like the user experience looks like
and so like at their APIs and their workflow the design of the API uh is very intuitive and it
doesn't require the user to really learn some like galaxy brain thing like Kubernetes
um and I think that sounds really simple but I don't see that really any other that many tools do
that um now MLflow is is there too um but I feel that MLflow is behind in a lot of their features
versus metal flow in this regard um and I'm not a big you know the API something that I don't find
as intuitive and so yeah that's it I mean this is like you know it's a good it's an open source
project that seems like has a good traction I really like their API I like their philosophy of
meeting the user where they are um yeah and so that's that's them apart uh so yeah I'm excited
about it awesome awesome uh well Hamel it's been great catching up with you um excited we finally
got to record this conversation and uh you know thanks for joining the show all right thank you for
having me thank you
