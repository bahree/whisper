1
00:00:00,000 --> 00:00:15,920
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

2
00:00:15,920 --> 00:00:20,880
people doing interesting things in machine learning and artificial intelligence.

3
00:00:20,880 --> 00:00:23,280
I'm your host Sam Charrington.

4
00:00:23,280 --> 00:00:26,920
The show you're about to hear is part of a series recorded at the Georgian Partners

5
00:00:26,920 --> 00:00:30,120
Portfolio Conference last week in Toronto.

6
00:00:30,120 --> 00:00:34,720
My guess for this interview is Kenneth Conroy, VP of Data Science at VancouverBased

7
00:00:34,720 --> 00:00:39,280
Fin.AI, a company building a chatbot system for banks.

8
00:00:39,280 --> 00:00:43,920
Kenneth and I spoke about how Fin.AI built its core conversational platform.

9
00:00:43,920 --> 00:00:49,160
We spoke in depth about the requirements and challenges of conversational applications

10
00:00:49,160 --> 00:00:53,760
and how and why they transitioned off of a commercial chatbot platform, in their case,

11
00:00:53,760 --> 00:00:59,720
API.AI, and built their own custom platform based on deep learning, word-to-vec, and other

12
00:00:59,720 --> 00:01:02,840
natural language understanding technologies.

13
00:01:02,840 --> 00:01:07,080
Georgian Partners is a venture capital firm whose investment thesis is that certain tech

14
00:01:07,080 --> 00:01:12,980
trends change every aspect of a software business over time, including business goals, product

15
00:01:12,980 --> 00:01:18,600
plans, people in skills, technology platforms, pricing and packaging.

16
00:01:18,600 --> 00:01:23,400
Georgian invests in those companies best positioned to take advantage of these trends and then works

17
00:01:23,400 --> 00:01:27,840
closely with those companies to develop and execute the strategies necessary to make

18
00:01:27,840 --> 00:01:29,640
it happen.

19
00:01:29,640 --> 00:01:34,640
Applied AI is one of the trends they're investing in as our conversational business and security

20
00:01:34,640 --> 00:01:36,600
first.

21
00:01:36,600 --> 00:01:39,760
Georgian sponsored this series and we thank them for their support.

22
00:01:39,760 --> 00:01:45,520
To learn more about Georgian, visit twimmolai.com slash Georgian, where you'll also be able to

23
00:01:45,520 --> 00:01:51,600
download white papers on their principles of applied AI and conversational business.

24
00:01:51,600 --> 00:01:56,040
Before we jump in, if you're in New York City on October 30th and 31st, we hope you'll

25
00:01:56,040 --> 00:02:00,440
join us at the NYU Future Labs AI Summit and Happy Hour.

26
00:02:00,440 --> 00:02:04,360
As you may remember, we attended the inaugural summit back in April.

27
00:02:04,360 --> 00:02:08,800
The fall event features more great speakers, including Karina Cortez, head of research at

28
00:02:08,800 --> 00:02:14,040
Google New York, David Venturelli, science operations manager at NASA Ames Quantum

29
00:02:14,040 --> 00:02:20,280
AI Lab, and Dennis Mortensen, CEO and founder of startup x.ai.

30
00:02:20,280 --> 00:02:28,400
For the event homepage, visit AISummit2017.futurelabs.nyc, and for 25% off tickets, use the

31
00:02:28,400 --> 00:02:30,920
code twimmol25.

32
00:02:30,920 --> 00:02:36,680
For details on the Happy Hour, visit our events page at twimmolai.com slash events.

33
00:02:36,680 --> 00:02:40,520
And now on to the show.

34
00:02:40,520 --> 00:02:47,040
All right, everyone.

35
00:02:47,040 --> 00:02:52,720
I am here at the Georgian Partners Portfolio Conference in Toronto, Canada, where I'll

36
00:02:52,720 --> 00:02:57,920
be doing a few interviews, and I am excited to be here with Kenneth Conroy.

37
00:02:57,920 --> 00:03:02,840
Kenneth is the VP of Data Science at fin.ai.

38
00:03:02,840 --> 00:03:05,400
Kenneth, welcome to this week in Machine Learning and AI.

39
00:03:05,400 --> 00:03:06,800
Thanks for having me.

40
00:03:06,800 --> 00:03:07,800
Awesome.

41
00:03:07,800 --> 00:03:10,040
And so you're in from Vancouver.

42
00:03:10,040 --> 00:03:11,040
Yeah.

43
00:03:11,040 --> 00:03:16,600
So stand from Vancouver from last night, so still filling out a bit, but happy to be here.

44
00:03:16,600 --> 00:03:17,600
Hi.

45
00:03:17,600 --> 00:03:19,880
Why don't we get started by having you tell us a little bit about your background and

46
00:03:19,880 --> 00:03:22,720
how you got involved in data science and machine learning?

47
00:03:22,720 --> 00:03:23,720
Sure.

48
00:03:23,720 --> 00:03:29,160
Well, I'm from Ireland, and I did my PhD in Dublin City University in the area of heterogeneous

49
00:03:29,160 --> 00:03:30,640
sensor data.

50
00:03:30,640 --> 00:03:36,080
So I was in a research lab called the Clarity Center for Sensor Web Technologies.

51
00:03:36,080 --> 00:03:40,800
And I was involved with coming up with a way of aggregating sensor content from multiple

52
00:03:40,800 --> 00:03:44,120
different devices that were not in any way connected.

53
00:03:44,120 --> 00:03:49,040
And doing that, I ended up coming up with machine learning strategies for close string

54
00:03:49,040 --> 00:03:52,680
and have one of the supervised learnings for finding out things that researchers wanted

55
00:03:52,680 --> 00:03:53,680
to detect.

56
00:03:53,680 --> 00:03:58,400
The researchers in this case would be domain experts in sports science.

57
00:03:58,400 --> 00:04:03,280
And from there, when I finished my PhD, I continued working in the same university, but for

58
00:04:03,280 --> 00:04:06,200
the inside center for data analytics.

59
00:04:06,200 --> 00:04:12,920
And that's where I moved way into the NLP machine learning, sends with analysis, projects.

60
00:04:12,920 --> 00:04:18,080
It was a commercialization wing of the university essentially.

61
00:04:18,080 --> 00:04:23,880
And I ended up moving to Vancouver maybe three years ago, now I'm at FinAI and leading the

62
00:04:23,880 --> 00:04:27,760
data science team as we create conversational assistance for banks.

63
00:04:27,760 --> 00:04:28,760
Nice.

64
00:04:28,760 --> 00:04:32,360
Is there a lot of machine learning and AI activity in Ireland?

65
00:04:32,360 --> 00:04:33,360
Yes.

66
00:04:33,360 --> 00:04:34,360
This is a very big hub actually in Dublin.

67
00:04:34,360 --> 00:04:35,360
OK.

68
00:04:35,360 --> 00:04:39,880
I'm hoping that we set up a Dublin branch for our Amia headquarters in the future.

69
00:04:39,880 --> 00:04:44,200
I know a lot of people in the field and the universities very qualified people there.

70
00:04:44,200 --> 00:04:47,800
So yeah, it's a bit of a hope right now for machine learning.

71
00:04:47,800 --> 00:04:48,800
Nice.

72
00:04:48,800 --> 00:04:51,600
So tell us a little bit more about what Fin is up to.

73
00:04:51,600 --> 00:04:56,160
So we're creating conversational assistance for banks, so think of a Siri for your bank.

74
00:04:56,160 --> 00:05:00,040
We provide things like day to day banking, your basic banking needs, like checking your

75
00:05:00,040 --> 00:05:05,400
balance online or paying bills or transferring money from friends to friends, as well as

76
00:05:05,400 --> 00:05:10,240
more kind of day to day kind of Q&A type stuff you would ask a bank, what your fees are

77
00:05:10,240 --> 00:05:13,680
for your credit cards, product information, stuff like that.

78
00:05:13,680 --> 00:05:19,000
We integrate with the bank's APIs for security, logging in, if we have any interactions

79
00:05:19,000 --> 00:05:21,120
with your bank accounts.

80
00:05:21,120 --> 00:05:26,000
And essentially, yeah, we're just kind of expanding our product base beyond the initial

81
00:05:26,000 --> 00:05:28,800
NLU side of things for detecting intents.

82
00:05:28,800 --> 00:05:33,040
So having recommendation engines in the future as well as credit score coach, moving

83
00:05:33,040 --> 00:05:34,800
more into voice platforms.

84
00:05:34,800 --> 00:05:39,120
So right now we're NLP based text interface mostly.

85
00:05:39,120 --> 00:05:44,240
We have experimented with some voice interfaces, but our primary platform is Facebook for

86
00:05:44,240 --> 00:05:51,040
which we launched a production bot for ATB financial as of yesterday, so we're in production

87
00:05:51,040 --> 00:05:52,040
as of yesterday.

88
00:05:52,040 --> 00:05:53,040
Nice.

89
00:05:53,040 --> 00:05:54,040
Nice.

90
00:05:54,040 --> 00:05:59,280
So you're here at the conference as a portfolio company of George and Partners, but

91
00:05:59,280 --> 00:06:02,200
you're also speaking at the conference later on today.

92
00:06:02,200 --> 00:06:05,000
What's the topic of your talk?

93
00:06:05,000 --> 00:06:08,240
The talk topic title went through some iterations.

94
00:06:08,240 --> 00:06:13,320
So I think it's a how we built a virtual banking assistant or virtual financial assistant

95
00:06:13,320 --> 00:06:14,320
for banks.

96
00:06:14,320 --> 00:06:15,320
Okay.

97
00:06:15,320 --> 00:06:17,520
So it sounds like that's the story, the fin story.

98
00:06:17,520 --> 00:06:18,520
Essentially, yeah.

99
00:06:18,520 --> 00:06:23,360
So one of our co-founders, Natalie Cartwright, she'll be introducing the talk and giving

100
00:06:23,360 --> 00:06:27,400
a lot of the business insight into why we went down the path we went down and then I'll

101
00:06:27,400 --> 00:06:32,720
talk more to the data sign side of things and how the technical challenges arose along

102
00:06:32,720 --> 00:06:37,720
the way and how we make the decisions we made and how we're kind of continually improving

103
00:06:37,720 --> 00:06:38,720
on that process.

104
00:06:38,720 --> 00:06:39,720
Okay.

105
00:06:39,720 --> 00:06:40,720
Well, let's dig into that.

106
00:06:40,720 --> 00:06:46,280
What were some of the major goals and challenges on the data sign side?

107
00:06:46,280 --> 00:06:52,600
So I think we kind of reduced the problem to its core issue, which was how do you design

108
00:06:52,600 --> 00:06:56,600
a taxonomy of intense for which you want to get answers?

109
00:06:56,600 --> 00:07:00,560
It's a bit of a complex task because you've got to, for us, we were a closed domain.

110
00:07:00,560 --> 00:07:03,560
We wanted to stay a closed domain and stay in retrieval-based systems.

111
00:07:03,560 --> 00:07:09,440
So it was banking only and the responses are pre-written, no generative responses at

112
00:07:09,440 --> 00:07:10,440
all.

113
00:07:10,440 --> 00:07:11,440
Okay.

114
00:07:11,440 --> 00:07:15,720
So when we have that as our canvas and we want to create a taxonomy to kind of drill

115
00:07:15,720 --> 00:07:21,360
down into individual branches of what the conversational tree might be, there were a lot

116
00:07:21,360 --> 00:07:25,120
of challenges involved in that, where you draw the boundaries between things.

117
00:07:25,120 --> 00:07:31,000
At what stage or at what extent do you want to make it conversational with one-to-one responses?

118
00:07:31,000 --> 00:07:35,360
So the bulk of our functionality in terms of intense would be one level.

119
00:07:35,360 --> 00:07:38,200
You would say question and you get an answer.

120
00:07:38,200 --> 00:07:40,000
But some of them will have flows.

121
00:07:40,000 --> 00:07:43,600
So if you want to make a bill payment, you can say something like, I want to pay my BC

122
00:07:43,600 --> 00:07:48,440
hydro bill $50 and it will pre-fill those things using the entity recognition and ask you

123
00:07:48,440 --> 00:07:49,440
to confirm.

124
00:07:49,440 --> 00:07:53,480
Or if you don't give enough details, we'll ask you for more input and that kind of two

125
00:07:53,480 --> 00:07:56,520
and throw conversational side of things comes into it.

126
00:07:56,520 --> 00:08:01,560
So in that case, it's almost like walking through a wizard in a traditional, you always

127
00:08:01,560 --> 00:08:06,360
got a set of questions that represent information that's needed to fulfill the transaction

128
00:08:06,360 --> 00:08:08,920
and you just go one to the next to the next.

129
00:08:08,920 --> 00:08:09,920
Exactly.

130
00:08:09,920 --> 00:08:14,400
And based on conversations we have with customer service agents, so a lot of our functionality

131
00:08:14,400 --> 00:08:19,200
is to kind of help the CSAs answer questions in doing that.

132
00:08:19,200 --> 00:08:24,360
And we got a list of questions that they get on a daily basis and we could waste them

133
00:08:24,360 --> 00:08:29,420
based on how frequent they came in and from that was kind of like the seed of how we

134
00:08:29,420 --> 00:08:33,800
would build this taxonomy that wants one communication with banks.

135
00:08:33,800 --> 00:08:38,000
And as we speak to more and more people in different banks, we're seeing the commonality

136
00:08:38,000 --> 00:08:40,200
between the banks is very strong.

137
00:08:40,200 --> 00:08:45,160
There's maybe 85, 90% commonality in what they want, what they want to achieve.

138
00:08:45,160 --> 00:08:48,760
So that's the good side about having this taxonomy in place.

139
00:08:48,760 --> 00:08:55,760
You can bootstrap a bot fairly quickly and get it up to a reasonable level of performance

140
00:08:55,760 --> 00:08:56,920
very quickly.

141
00:08:56,920 --> 00:09:01,800
It's then when you want to build out those more kind of fully featured functions and those

142
00:09:01,800 --> 00:09:03,880
conversational side of things.

143
00:09:03,880 --> 00:09:09,040
That's when the complexities come into it and where really kind of future is for the business.

144
00:09:09,040 --> 00:09:10,720
A bunch of questions.

145
00:09:10,720 --> 00:09:15,040
I guess one question is not necessarily related to the data science side of things, but

146
00:09:15,040 --> 00:09:21,000
are you integrating one-to-one with the banks or are you using some kind of intermediary

147
00:09:21,000 --> 00:09:23,640
like a yodulee or something like that?

148
00:09:23,640 --> 00:09:24,640
I think so.

149
00:09:24,640 --> 00:09:28,880
I don't know too much about the what goes on behind the scenes and the engineering side

150
00:09:28,880 --> 00:09:29,880
of things.

151
00:09:29,880 --> 00:09:34,400
So the engineering team will do a lot of the interactions with the banks themselves.

152
00:09:34,400 --> 00:09:40,680
A lot of our bots are completely done by us, hosted by us and accessible by anybody because

153
00:09:40,680 --> 00:09:44,840
they're not personally, no personally identifiable information in there.

154
00:09:44,840 --> 00:09:49,200
So for banks that require API integrations with the banks themselves, we provide an

155
00:09:49,200 --> 00:09:55,600
interface for the banks to give the security credential requirements and login functionality.

156
00:09:55,600 --> 00:09:56,840
So all that stuff is done by them.

157
00:09:56,840 --> 00:10:01,920
We do not take the responsibility of authenticating the users and that's up to the banks to

158
00:10:01,920 --> 00:10:05,320
do if they want to have integrations with their systems.

159
00:10:05,320 --> 00:10:11,000
What does it mean to have a banking bot that doesn't deal with any personally identifiable

160
00:10:11,000 --> 00:10:12,000
information?

161
00:10:12,000 --> 00:10:17,200
You're saying that you're just passing requests to the bank and they're answering them or

162
00:10:17,200 --> 00:10:21,520
are you talking about bots that just don't deal with account information that are like

163
00:10:21,520 --> 00:10:24,280
telling you where to find branches and ATMs and that kind of thing?

164
00:10:24,280 --> 00:10:29,680
Yeah, so some of our functionality will be finding ATMs or just basic questions about

165
00:10:29,680 --> 00:10:31,480
the products and services they offer.

166
00:10:31,480 --> 00:10:34,000
And that stuff is not confidential in any way.

167
00:10:34,000 --> 00:10:39,560
It's open information that may exist on an FAQ in a different format on their site.

168
00:10:39,560 --> 00:10:44,040
So it's still a conversational way of talking to your bank or a bank doesn't necessarily

169
00:10:44,040 --> 00:10:46,360
have to be your bank if you're not authenticated with it.

170
00:10:46,360 --> 00:10:48,240
But yeah, that's what I mean.

171
00:10:48,240 --> 00:10:49,240
Okay.

172
00:10:49,240 --> 00:10:55,000
What percentage of the banks you're working with are taking this approach where it's just

173
00:10:55,000 --> 00:10:58,760
that surface level interaction versus account level detail?

174
00:10:58,760 --> 00:11:05,520
Typically, when we do POCs, so for banks, the first version will not have banking integrations.

175
00:11:05,520 --> 00:11:09,520
Banks move a lot slower than startups, for instance.

176
00:11:09,520 --> 00:11:13,600
So if they want to integrate their systems with us, we have to have a lot of trust between

177
00:11:13,600 --> 00:11:14,600
us.

178
00:11:14,600 --> 00:11:20,000
So we've had a relationship with ATB financial for over a year now and based on that level

179
00:11:20,000 --> 00:11:25,960
of trust and that level of working collaboratively together, we've been able to create a production

180
00:11:25,960 --> 00:11:28,640
bot that uses all of that API integration.

181
00:11:28,640 --> 00:11:29,640
Okay.

182
00:11:29,640 --> 00:11:33,880
Yeah, building up that trust and building up that system for them and allowing them to test

183
00:11:33,880 --> 00:11:37,960
it and kind of iterate on it before it goes to production is kind of key.

184
00:11:37,960 --> 00:11:38,960
Okay.

185
00:11:38,960 --> 00:11:46,720
So we started talking about the data science side of things in terms of identifying the

186
00:11:46,720 --> 00:11:48,120
intents.

187
00:11:48,120 --> 00:11:57,480
In what way can you characterize the breadth of the intents or the interactions that you

188
00:11:57,480 --> 00:12:00,040
have for a typical customer?

189
00:12:00,040 --> 00:12:05,840
How many of these intents are there in a realm like banking?

190
00:12:05,840 --> 00:12:07,840
So this question comes up a lot.

191
00:12:07,840 --> 00:12:08,840
What is an intent?

192
00:12:08,840 --> 00:12:12,320
So we use a lot of entity recognition to reduce the amount of intents.

193
00:12:12,320 --> 00:12:14,520
We do not want a lot of intents in our system.

194
00:12:14,520 --> 00:12:19,560
We want to break down the problem into kind of smaller subsets, more consumable subsets.

195
00:12:19,560 --> 00:12:23,320
So the amount of intents is actually quite low compared to what you would think based

196
00:12:23,320 --> 00:12:26,960
the amount of responses we can give, we give thousands of responses.

197
00:12:26,960 --> 00:12:31,520
But there might only be a few hundred intents and it depends on the agent to functionality

198
00:12:31,520 --> 00:12:32,520
that we have.

199
00:12:32,520 --> 00:12:38,720
It depends on how many kind of FAQ type questions they want in there and what subset of

200
00:12:38,720 --> 00:12:43,120
all functionality that we can offer they want to make use of.

201
00:12:43,120 --> 00:12:48,280
So yeah, the amount of intents is kind of a wishy-washy number.

202
00:12:48,280 --> 00:12:52,760
The amount of responses is a solid number that we can give per agent basis.

203
00:12:52,760 --> 00:12:57,640
But the amount of potential intents is kind of set at a certain value for our core basic

204
00:12:57,640 --> 00:12:59,120
banking needs.

205
00:12:59,120 --> 00:13:03,280
So the taxonomy tree has an empty list of responses.

206
00:13:03,280 --> 00:13:07,640
So anywhere you could put a response in any of those leaves, that's another response.

207
00:13:07,640 --> 00:13:12,520
And that's what the banks decide what they want to support.

208
00:13:12,520 --> 00:13:18,000
And the banks come to us with their call logs information, analytics on what the subject

209
00:13:18,000 --> 00:13:20,240
matter is for their chat logs, for instance.

210
00:13:20,240 --> 00:13:26,400
And then they can see the subset of the taxonomy that would best meet their needs.

211
00:13:26,400 --> 00:13:28,520
What level of abstraction is an intent?

212
00:13:28,520 --> 00:13:33,680
Is it something like, you know, I want to ask a question about an FAQ or is it like

213
00:13:33,680 --> 00:13:39,360
individual questions, you know, does it map more closely to individual FAQ questions

214
00:13:39,360 --> 00:13:40,960
or responses?

215
00:13:40,960 --> 00:13:42,800
So it depends.

216
00:13:42,800 --> 00:13:46,760
Things like if you want to find an ATM would have like a find ATM intent, it's fairly

217
00:13:46,760 --> 00:13:48,000
well defined.

218
00:13:48,000 --> 00:13:52,600
If you want to find out your fees for your master card, for instance, the intent might

219
00:13:52,600 --> 00:13:53,600
be fees.

220
00:13:53,600 --> 00:13:54,600
Okay.

221
00:13:54,600 --> 00:13:57,840
The anti-recognition would find what the master card is or means and provide a different

222
00:13:57,840 --> 00:14:00,280
response based on master card rather than visa.

223
00:14:00,280 --> 00:14:01,280
Okay.

224
00:14:01,280 --> 00:14:04,160
Maybe we break it down into smaller bite size chunks.

225
00:14:04,160 --> 00:14:05,160
Okay.

226
00:14:05,160 --> 00:14:06,160
Interesting.

227
00:14:06,160 --> 00:14:12,120
So you've got this tree structure, you've got these entities, well, I guess a kind of basic

228
00:14:12,120 --> 00:14:13,120
question.

229
00:14:13,120 --> 00:14:21,400
Are you using any of the commercial platforms to do any of this stuff like the API data

230
00:14:21,400 --> 00:14:24,000
AI is of the world and others?

231
00:14:24,000 --> 00:14:25,000
Not anymore.

232
00:14:25,000 --> 00:14:26,000
So we did.

233
00:14:26,000 --> 00:14:27,000
Interesting.

234
00:14:27,000 --> 00:14:29,240
Initially we used API AI way back when.

235
00:14:29,240 --> 00:14:32,680
So they're great for what they're built to do.

236
00:14:32,680 --> 00:14:37,800
They allow you to create bots fairly quickly, not much data involved, accuracy isn't too

237
00:14:37,800 --> 00:14:42,800
bad, fairly customizable, but they weren't the way that we could continue.

238
00:14:42,800 --> 00:14:45,640
They were too limited in terms of what we wanted to achieve.

239
00:14:45,640 --> 00:14:48,560
We had no idea what was in their model, for instance.

240
00:14:48,560 --> 00:14:52,800
We had no secondary match for what their primary intent match would be.

241
00:14:52,800 --> 00:14:59,200
You said no idea what was in their model, meaning, you know, they identified intents using

242
00:14:59,200 --> 00:15:02,880
NLP, whatever, but it was all a black box to you.

243
00:15:02,880 --> 00:15:11,440
They just gave you an API and told you, hey, bot user initiated this intent and we found

244
00:15:11,440 --> 00:15:14,920
these entities and figured out, but you couldn't tweak or tune that at all.

245
00:15:14,920 --> 00:15:15,920
Exactly, yeah.

246
00:15:15,920 --> 00:15:18,800
There was limitations on where we could go with it.

247
00:15:18,800 --> 00:15:19,800
Okay.

248
00:15:19,800 --> 00:15:24,160
If you wanted to have multi-layer models, for instance, or focus on or upweight specific

249
00:15:24,160 --> 00:15:28,880
types of intents, the functionality was wasn't there to be in a scalable enterprise

250
00:15:28,880 --> 00:15:33,080
product within our domain, and because we were in our domain, we wanted to have a system

251
00:15:33,080 --> 00:15:38,000
where we could reuse as much of what we were providing for each bank across banks.

252
00:15:38,000 --> 00:15:44,760
API is quite complex when it comes to sharing data for one agent to another, and you need

253
00:15:44,760 --> 00:15:46,480
individual agents for that.

254
00:15:46,480 --> 00:15:47,480
Okay.

255
00:15:47,480 --> 00:15:51,400
There's also a limitation on the amount of data you can upload to it, and the rate limitation

256
00:15:51,400 --> 00:15:55,960
on how often you can request, model matches and so on.

257
00:15:55,960 --> 00:16:01,520
So they're the reason why we moved away, and that was the move to our production system

258
00:16:01,520 --> 00:16:02,520
was 100%.

259
00:16:02,520 --> 00:16:04,120
It's our own now.

260
00:16:04,120 --> 00:16:05,120
Okay.

261
00:16:05,120 --> 00:16:11,120
You mentioned in there, multi-layer models, what would that entail, or what does that represent?

262
00:16:11,120 --> 00:16:17,440
So in place of our entity recognition, we are building up data sets to find how the

263
00:16:17,440 --> 00:16:20,440
user kind of goes down a certain tree.

264
00:16:20,440 --> 00:16:21,440
Okay.

265
00:16:21,440 --> 00:16:24,960
Right now, we're using a deregnation to do that, but we could use a model to do that.

266
00:16:24,960 --> 00:16:30,320
It's like a subset of all available intents, but narrowed down to those individual entities.

267
00:16:30,320 --> 00:16:33,960
Once the data set is a bit more richer and a bit more well defined and developed and

268
00:16:33,960 --> 00:16:38,200
we have more user data, we can use that as an additional layer in the model.

269
00:16:38,200 --> 00:16:43,360
So there'd be the existing model, which is the top layer intent match, and then within

270
00:16:43,360 --> 00:16:48,920
each conversational flow, there are kind of submodels that have all available actions

271
00:16:48,920 --> 00:16:50,920
there as well as a few escape actions.

272
00:16:50,920 --> 00:16:56,160
So rather than having to cancel out of that flow to query something else, you get a focused

273
00:16:56,160 --> 00:16:59,440
way of finding what the user's next input is.

274
00:16:59,440 --> 00:17:06,240
I'm still trying to wrap my head around what the idea of multi-layer, meaning you've

275
00:17:06,240 --> 00:17:11,680
got your entities that you're kind of extracting out traditionally, but then you're applying

276
00:17:11,680 --> 00:17:16,760
other probabilistic models to try to identify where the entities are, is that the idea of

277
00:17:16,760 --> 00:17:17,760
a multi-layer?

278
00:17:17,760 --> 00:17:24,040
The multi-layer model isn't in production, but this is a replacement for part of that

279
00:17:24,040 --> 00:17:26,080
entity recognition modules.

280
00:17:26,080 --> 00:17:30,520
So given enough data and enough information on what the synonyms and ABSs are for different

281
00:17:30,520 --> 00:17:35,640
entities in our system, we can further define and automate that process rather than using

282
00:17:35,640 --> 00:17:39,840
the existing one, because you got to update things like synonyms over time, and you might

283
00:17:39,840 --> 00:17:41,840
miss certain things.

284
00:17:41,840 --> 00:17:47,360
You might not always find MasterCard if it's miss belts, for instance.

285
00:17:47,360 --> 00:17:53,520
But that said, both that approach and the existing approach, if you miss Bell MasterCard,

286
00:17:53,520 --> 00:17:57,760
because we're using the intent level at a higher level, we're still finding what the

287
00:17:57,760 --> 00:18:03,400
intent of the user is, which is safe ease, and we can just guide the user via UX to the

288
00:18:03,400 --> 00:18:06,320
specific response they're actually looking for.

289
00:18:06,320 --> 00:18:13,720
And as part of that shift to the multi-layer, is there kind of an underlying shift in

290
00:18:13,720 --> 00:18:20,280
an approach from something analogous to NLTK on Python to something that's more like

291
00:18:20,280 --> 00:18:23,960
a homegrown deep learning entity recognizer?

292
00:18:23,960 --> 00:18:26,160
Yeah, so we have two tracks for right now.

293
00:18:26,160 --> 00:18:32,440
We have our production track, which is kind of a SPARK Python pipeline, using word embeddings

294
00:18:32,440 --> 00:18:36,720
and using word-to-vec for other algorithms like that.

295
00:18:36,720 --> 00:18:39,520
And then we have our research or in deep learning track.

296
00:18:39,520 --> 00:18:42,880
In that track, we're working on deep learning stuff.

297
00:18:42,880 --> 00:18:47,480
We're working on MXNet and TensorFlow in parallel.

298
00:18:47,480 --> 00:18:51,880
We're experimenting on where we're going to get the best accuracy over time and where

299
00:18:51,880 --> 00:18:54,720
this can fit into our multi-layer approach.

300
00:18:54,720 --> 00:18:57,000
And why MXNet and TensorFlow?

301
00:18:57,000 --> 00:19:03,400
So TensorFlow is very popular, and MXNet is very good.

302
00:19:03,400 --> 00:19:04,400
So we are...

303
00:19:04,400 --> 00:19:07,040
Now, I've heard MXNet is very fast.

304
00:19:07,040 --> 00:19:12,520
I don't know that I've heard very good, necessarily, not that it's not, but...

305
00:19:12,520 --> 00:19:15,000
I can't speak with too much confidence on the subject.

306
00:19:15,000 --> 00:19:16,600
Maybe define good.

307
00:19:16,600 --> 00:19:17,600
I can't.

308
00:19:17,600 --> 00:19:18,600
Okay.

309
00:19:18,600 --> 00:19:19,600
Got it.

310
00:19:19,600 --> 00:19:20,600
Interesting.

311
00:19:20,600 --> 00:19:24,000
Yeah, I mean, there are tons of lots of framework choices out there.

312
00:19:24,000 --> 00:19:25,600
There are a lot there.

313
00:19:25,600 --> 00:19:30,000
Yeah, it's kind of early days for our deep learning path.

314
00:19:30,000 --> 00:19:34,920
But the goal was to get this into production in a usable state and have our stakeholders

315
00:19:34,920 --> 00:19:37,400
happy with the performance of it, which is there, which is great.

316
00:19:37,400 --> 00:19:39,400
But this is the exciting kind of future side.

317
00:19:39,400 --> 00:19:41,440
It's getting everyone on the team very excited.

318
00:19:41,440 --> 00:19:43,680
Looking on the deep learning side of things.

319
00:19:43,680 --> 00:19:44,680
Nice.

320
00:19:44,680 --> 00:19:45,680
Nice.

321
00:19:45,680 --> 00:19:51,440
Are you able to characterize, in some way, the benefit that you, you know, besides from

322
00:19:51,440 --> 00:19:56,840
kind of the flexibility and visibility, agility, all that,ility kind of things?

323
00:19:56,840 --> 00:20:04,080
Like in going from api.ai, where you didn't kind of control the model to, you know, that

324
00:20:04,080 --> 00:20:08,920
first pipeline that you just mentioned where you're using Word2vec and stuff like that.

325
00:20:08,920 --> 00:20:13,920
Are there quantitative, was there specific quantitative advantages that you saw?

326
00:20:13,920 --> 00:20:14,920
Yeah.

327
00:20:14,920 --> 00:20:19,720
So when we're evaluating, we couldn't evaluate api.ai in the same way that we didn't have

328
00:20:19,720 --> 00:20:24,280
the ability to see, exploit the training test data on their side and find out what the

329
00:20:24,280 --> 00:20:26,760
cross validation score would be for instance.

330
00:20:26,760 --> 00:20:27,760
We can do that.

331
00:20:27,760 --> 00:20:31,520
An objective, the evaluate our own models against our own models, which is great.

332
00:20:31,520 --> 00:20:36,040
But we do analyze logs and we take a snapshot of everything that's gone through our system

333
00:20:36,040 --> 00:20:40,640
as it exists in api.ai and then put it into our new model as well and then compare the

334
00:20:40,640 --> 00:20:42,520
results of that in real world terms.

335
00:20:42,520 --> 00:20:47,200
We take a snapshot of a week's worth of data that goes into an agent, see how accurate

336
00:20:47,200 --> 00:20:49,200
it is based on that.

337
00:20:49,200 --> 00:20:53,680
That's what the banks are interested to see to, they're interested to see the real world

338
00:20:53,680 --> 00:21:01,760
accuracy of something without kind of adjusting for duplication in the data or however

339
00:21:01,760 --> 00:21:06,680
cross-fold validation kind of, it's hard for them to visualize how that's working.

340
00:21:06,680 --> 00:21:09,200
So real world, they need to see what those values are.

341
00:21:09,200 --> 00:21:14,760
So in doing that, we can see that our models are outperforming what was existing for api.ai.

342
00:21:14,760 --> 00:21:15,760
Okay.

343
00:21:15,760 --> 00:21:18,680
So we started down the path of challenges.

344
00:21:18,680 --> 00:21:24,240
Are there other things that come to mind in terms of challenges that you've come across?

345
00:21:24,240 --> 00:21:25,240
I guess.

346
00:21:25,240 --> 00:21:29,120
We haven't seen it too much, but it can happen and we're quite wary of it and we're kind

347
00:21:29,120 --> 00:21:33,800
of getting ahead of the curve by cautioning against it is intent drift.

348
00:21:33,800 --> 00:21:41,560
So when the banks themselves have the ability to map odorances to intense, we are at risk

349
00:21:41,560 --> 00:21:47,240
of having our taxonomy start to diverge based on how they write the response and how they

350
00:21:47,240 --> 00:21:51,520
think that should be the answer for that specific intent.

351
00:21:51,520 --> 00:21:55,520
If you've got a bunch of data in there that's labeled for an intent and all those pieces

352
00:21:55,520 --> 00:21:59,920
are answered by that response and then part of that response gets taken away then doesn't

353
00:21:59,920 --> 00:22:04,720
make sense for those things that were in there initially to still map to the same place.

354
00:22:04,720 --> 00:22:09,020
And it'll look like it's doing the right thing, but the response isn't given to the user.

355
00:22:09,020 --> 00:22:14,160
So to kind of counteract that we are building tools for the banks to be able to do this

356
00:22:14,160 --> 00:22:15,160
themselves.

357
00:22:15,160 --> 00:22:22,160
So the CSAs with our human and loop infrastructure will be able to correct errors made and

358
00:22:22,160 --> 00:22:27,920
map things to the correct intent and then feed that back into our system.

359
00:22:27,920 --> 00:22:32,560
And we also have methods of coming up with approximations about those things that are

360
00:22:32,560 --> 00:22:36,400
kind of prompting the user to pick from some subset of those things.

361
00:22:36,400 --> 00:22:41,400
But we want to have a two or three level deep kind of verification on anything they map

362
00:22:41,400 --> 00:22:48,040
to make sure that is appropriate response to what the user's odorance was.

363
00:22:48,040 --> 00:22:53,720
So can you give me an example of where they might change something that disrupts that

364
00:22:53,720 --> 00:22:54,720
relationship?

365
00:22:54,720 --> 00:22:55,720
Sure.

366
00:22:55,720 --> 00:23:01,920
We have things like tell me about you and who are you and sometimes the response to that

367
00:23:01,920 --> 00:23:05,080
gives us the same thing, but they're separate intents.

368
00:23:05,080 --> 00:23:07,680
Tell me about you and who are you.

369
00:23:07,680 --> 00:23:11,120
So tell me about you and be like, what can you do?

370
00:23:11,120 --> 00:23:12,120
Okay.

371
00:23:12,120 --> 00:23:17,200
Whereas who are you is just an introduction to the bot itself.

372
00:23:17,200 --> 00:23:21,400
But sometimes who are you means who are you, the bank, right?

373
00:23:21,400 --> 00:23:25,840
So how, what training that goes in for that is important depending on the context of

374
00:23:25,840 --> 00:23:28,200
what that response is.

375
00:23:28,200 --> 00:23:38,280
And so you mentioned that the CSAs, it sounds like to some extent the customer service teams

376
00:23:38,280 --> 00:23:47,400
at the bank have some role in kind of defining out the hierarchy and the responses.

377
00:23:47,400 --> 00:23:52,520
Is that correct or are you doing this all as a service for them?

378
00:23:52,520 --> 00:23:58,800
So earlier collaborations, very heavily involved with meeting with the bank's CSAs, talking

379
00:23:58,800 --> 00:24:04,720
through their issues, how their data forms, their opinions on what should be in there

380
00:24:04,720 --> 00:24:10,480
or whatnot, but we do have a base taxonomy based on those consultations with multiple

381
00:24:10,480 --> 00:24:11,480
banks at that point.

382
00:24:11,480 --> 00:24:12,480
Okay.

383
00:24:12,480 --> 00:24:15,160
And we can see about 85, 90% of commonality across all the banks.

384
00:24:15,160 --> 00:24:16,160
Okay.

385
00:24:16,160 --> 00:24:17,160
So that's kind of our core taxonomy.

386
00:24:17,160 --> 00:24:21,760
And if if banks want to extend beyond that, they just know that they'll have, we'll

387
00:24:21,760 --> 00:24:26,440
have fewer data entries for those things, fewer utterances to train, it would be a little

388
00:24:26,440 --> 00:24:28,000
less accurate at first.

389
00:24:28,000 --> 00:24:31,720
But if it makes sense, we can build that in as part of our core offering.

390
00:24:31,720 --> 00:24:36,240
In other cases, it might be locale based or it might just be for that one bank.

391
00:24:36,240 --> 00:24:37,240
Okay.

392
00:24:37,240 --> 00:24:39,480
And in those cases, they're just one-offs kind of customizations.

393
00:24:39,480 --> 00:24:40,480
Okay.

394
00:24:40,480 --> 00:24:47,800
And so this case where you get kind of drift in the intent, is that because of changes

395
00:24:47,800 --> 00:24:54,120
that the customer service people are able to make in the underlying system or is it the

396
00:24:54,120 --> 00:24:59,040
training data that they feed to you, that you are putting through your pipeline?

397
00:24:59,040 --> 00:25:04,080
So the customer, which is the bank, has the ability to change the responses, if they want

398
00:25:04,080 --> 00:25:05,680
to change the responses.

399
00:25:05,680 --> 00:25:09,120
We kind of monitor that to make sure it doesn't go too far away from the meaning of what

400
00:25:09,120 --> 00:25:10,120
that intent is.

401
00:25:10,120 --> 00:25:11,120
Okay.

402
00:25:11,120 --> 00:25:15,440
But they're also able to use our systems to manually answer questions.

403
00:25:15,440 --> 00:25:20,400
So if a query comes in and we do not have the high enough confidence to give the answer,

404
00:25:20,400 --> 00:25:22,760
it gets handed off to our human and the loop system.

405
00:25:22,760 --> 00:25:23,760
Okay.

406
00:25:23,760 --> 00:25:27,000
And then at that point, they can answer the question and then recommend an intent or utterance

407
00:25:27,000 --> 00:25:28,840
to map to that.

408
00:25:28,840 --> 00:25:31,840
For time as well, they can also monitor their own logs.

409
00:25:31,840 --> 00:25:36,000
And if they have people who are qualified to do so, you can educate them to do so.

410
00:25:36,000 --> 00:25:42,360
They can mark those logs for us, for themselves, and then that can be fed back into their model.

411
00:25:42,360 --> 00:25:47,880
So this happens a lot in pre-production when we have user acceptance testing with our

412
00:25:47,880 --> 00:25:48,880
banks.

413
00:25:48,880 --> 00:25:53,600
They kind of pre-train the bot by interacting with it time and time again.

414
00:25:53,600 --> 00:25:57,720
Typically, we annotate that, but we want to hand over some of that to the banks to give

415
00:25:57,720 --> 00:26:01,360
them an insight into the type of things that are being asked and how we best answer those

416
00:26:01,360 --> 00:26:02,360
questions.

417
00:26:02,360 --> 00:26:03,360
Okay.

418
00:26:03,360 --> 00:26:09,960
And so is there a, you know, it sounds like the intent drift challenges, you know, almost

419
00:26:09,960 --> 00:26:15,680
like a, you know, skill slash cultural slash focus kind of thing?

420
00:26:15,680 --> 00:26:20,880
How much of that is addressed by, you know, educating the customer service folks, you

421
00:26:20,880 --> 00:26:24,160
know, versus a technology solution?

422
00:26:24,160 --> 00:26:27,840
It's a bit of both, and it's not just the customer service folks, too.

423
00:26:27,840 --> 00:26:29,320
It's anybody in the organization.

424
00:26:29,320 --> 00:26:30,320
Okay.

425
00:26:30,320 --> 00:26:35,840
They might say they want a thousand questions answered, but that isn't one thousand distinct

426
00:26:35,840 --> 00:26:41,800
intents in any way, or even sometimes they're exact same intent and the exact same subset

427
00:26:41,800 --> 00:26:42,800
of intents.

428
00:26:42,800 --> 00:26:43,800
Okay.

429
00:26:43,800 --> 00:26:47,200
So I think part of it is to frame the problem differently.

430
00:26:47,200 --> 00:26:52,480
People still kind of tend to think of things like FAQs in a chat box if it's an FAQ

431
00:26:52,480 --> 00:26:56,320
in a web page, but those type of questions don't get asked in the same way as they would

432
00:26:56,320 --> 00:26:57,640
be listed on a web page.

433
00:26:57,640 --> 00:26:59,320
You got to structure things differently.

434
00:26:59,320 --> 00:27:00,320
It's not conversational.

435
00:27:00,320 --> 00:27:01,320
It's not intuitive.

436
00:27:01,320 --> 00:27:04,160
And the user doesn't just doesn't do it.

437
00:27:04,160 --> 00:27:09,840
So part of it is managing the expectations from the start, training the users, the customer

438
00:27:09,840 --> 00:27:16,000
is on how we best organize this information and why we do that, as well as because we

439
00:27:16,000 --> 00:27:20,920
have to got the taxonomy that's kind of shared across banks, we can reuse the data across

440
00:27:20,920 --> 00:27:21,920
banks.

441
00:27:21,920 --> 00:27:26,280
And that's mutually beneficial for everyone involved because that means the accuracy of

442
00:27:26,280 --> 00:27:31,240
all of those intents improve as data from each of those banks come in.

443
00:27:31,240 --> 00:27:32,400
Interesting.

444
00:27:32,400 --> 00:27:39,560
In your presentation, will you be outlining, do you have any kind of prescriptive, you

445
00:27:39,560 --> 00:27:46,480
know, if you're looking at doing chatbots or maybe even ML or AI generally like to, you

446
00:27:46,480 --> 00:27:48,240
know, things one through end?

447
00:27:48,240 --> 00:27:49,560
Kind of, yeah.

448
00:27:49,560 --> 00:27:54,760
It's obviously heavily weighted in the way we actually did it and how we tried it and

449
00:27:54,760 --> 00:27:59,320
how it didn't work and then how we did it and seemed to be working pretty well.

450
00:27:59,320 --> 00:28:05,360
So yeah, I'll talk about exactly how we did it as well as how we're best seeing rolling

451
00:28:05,360 --> 00:28:07,840
this out works to customers.

452
00:28:07,840 --> 00:28:11,840
So seeing this in the real world, seeing how customers interact with it and help you

453
00:28:11,840 --> 00:28:16,600
get to where you need to go and where themselves need to go, it's really cool to see.

454
00:28:16,600 --> 00:28:21,640
So what are your top three, you know, make sure you do this or don't make this mistake,

455
00:28:21,640 --> 00:28:26,720
kind of advice to startups that are trying to get systems like this up and running.

456
00:28:26,720 --> 00:28:28,000
Don't rush into it.

457
00:28:28,000 --> 00:28:31,960
So make sure the taxonomy is well defined.

458
00:28:31,960 --> 00:28:34,800
You will spend a lot of time researching this at the start.

459
00:28:34,800 --> 00:28:37,880
The two is you got to get some good data in there.

460
00:28:37,880 --> 00:28:44,160
We looked at lots of sources of information including previous chat logs or transcripts

461
00:28:44,160 --> 00:28:45,160
from calls.

462
00:28:45,160 --> 00:28:49,360
They're not great, even as C did it, they're not very good and they're often unstructured

463
00:28:49,360 --> 00:28:52,200
and difficult to even annotate in any way.

464
00:28:52,200 --> 00:28:57,240
We found for the cold star problem, crowdsourcing is key.

465
00:28:57,240 --> 00:29:02,600
Getting a list of different ways of saying different things can get you very far, very

466
00:29:02,600 --> 00:29:03,600
quickly.

467
00:29:03,600 --> 00:29:09,320
And then, did you crowdsource among the customer service agents that customers are like

468
00:29:09,320 --> 00:29:11,480
Amazon Turk or something like that?

469
00:29:11,480 --> 00:29:12,480
Yeah, both.

470
00:29:12,480 --> 00:29:13,480
Okay.

471
00:29:13,480 --> 00:29:14,480
So interesting.

472
00:29:14,480 --> 00:29:20,240
For kind of things that customers weren't helping build, maybe their features for our

473
00:29:20,240 --> 00:29:23,480
core platform that have not been released yet.

474
00:29:23,480 --> 00:29:29,120
And then often customers would have their own ideas and they would submit those ideas.

475
00:29:29,120 --> 00:29:34,320
We would build on those by submitting mechanical jobs to get more data.

476
00:29:34,320 --> 00:29:35,320
Okay.

477
00:29:35,320 --> 00:29:40,560
I guess then the third thing would be to consider where you draw the line between intense

478
00:29:40,560 --> 00:29:48,120
and entities, how you reduce the problem space and increase the accuracy by customizing

479
00:29:48,120 --> 00:29:51,040
to a certain extent to the domain you're working in.

480
00:29:51,040 --> 00:29:54,760
So get that taxonomy up and running, get that dictionary of terms for banking up and

481
00:29:54,760 --> 00:29:56,280
running if you're in banking.

482
00:29:56,280 --> 00:30:00,080
Obviously, I don't like to do a banking buff.

483
00:30:00,080 --> 00:30:01,480
But you said a bunch of stuff in there.

484
00:30:01,480 --> 00:30:09,640
So the first thing was the line between the entities and the intents.

485
00:30:09,640 --> 00:30:11,240
And we haven't talked about that yet.

486
00:30:11,240 --> 00:30:15,280
Is there like a trade-off dial in there somewhere that you have to kind of find the

487
00:30:15,280 --> 00:30:16,280
right place?

488
00:30:16,280 --> 00:30:20,320
It's not a straightforward task to find out where to do that or what the top intent should

489
00:30:20,320 --> 00:30:21,320
be.

490
00:30:21,320 --> 00:30:26,760
Like, do you focus on a product and then have a bunch of sub entities that have from features

491
00:30:26,760 --> 00:30:32,280
of that product or you talk about the features and products that correspond to that feature

492
00:30:32,280 --> 00:30:34,200
or things like fees, whatever.

493
00:30:34,200 --> 00:30:40,040
So the way you segment that stuff, you've got to be able to kind of keep track of what

494
00:30:40,040 --> 00:30:41,040
you've done as well.

495
00:30:41,040 --> 00:30:44,640
And if you ever want to go back again and change things, you don't want to be doing that

496
00:30:44,640 --> 00:30:48,120
when you've got a few million data entries in there to an entity.

497
00:30:48,120 --> 00:30:50,040
It's just going to be an impossible task.

498
00:30:50,040 --> 00:30:56,360
So that's an issue with a lot of the kind of first-time bot builder.

499
00:30:56,360 --> 00:30:59,160
You just build a bot in it works and you're like, okay, cool, it works.

500
00:30:59,160 --> 00:31:01,920
Then you want to add another 10 or 20 questions.

501
00:31:01,920 --> 00:31:05,400
Then you get a lot of conflicts because there's lots of similarity between those questions

502
00:31:05,400 --> 00:31:06,920
and existing questions.

503
00:31:06,920 --> 00:31:11,520
And that's the downside to doing that approach and the upside to having a vertical and a

504
00:31:11,520 --> 00:31:16,640
well-defined taxonomy to take into account everything that could be asked in that vertical.

505
00:31:16,640 --> 00:31:25,720
And is there a right or a wrong way to approach building out that taxonomy in terms of this

506
00:31:25,720 --> 00:31:32,160
line between the intents and the entities or is it more, you just have to do something

507
00:31:32,160 --> 00:31:38,080
and stick to it and be absolutely consistent as you expand out your vocabulary?

508
00:31:38,080 --> 00:31:40,440
Yeah, I mean, there's no right answer to this.

509
00:31:40,440 --> 00:31:43,320
It's a very difficult problem to solve.

510
00:31:43,320 --> 00:31:46,600
It's not that you can't change it afterwards, but you want to change it a little bit.

511
00:31:46,600 --> 00:31:47,600
You want to tweak it.

512
00:31:47,600 --> 00:31:50,200
You might split some intents or combine other intents.

513
00:31:50,200 --> 00:31:53,760
But you don't want to completely rebuild the system every few weeks or months.

514
00:31:53,760 --> 00:31:54,760
Sure.

515
00:31:54,760 --> 00:31:56,880
It's a bit of both.

516
00:31:56,880 --> 00:32:01,880
But there was another question that I wanted to ask that's maybe going a little bit back

517
00:32:01,880 --> 00:32:10,240
to, you know, so you kind of, you scrapped API.ai and built your own system for doing

518
00:32:10,240 --> 00:32:11,240
this.

519
00:32:11,240 --> 00:32:15,360
And you said it was, you said it was spark and Python.

520
00:32:15,360 --> 00:32:21,720
Did you also invest in building like, you know, almost like a user interface or kind

521
00:32:21,720 --> 00:32:30,440
of a higher level platform tools for both your internal people and the banks or your, you

522
00:32:30,440 --> 00:32:35,480
know, how sophisticated it does that layer need to be in order to have a usable system?

523
00:32:35,480 --> 00:32:37,720
Yeah, it's a very complex system.

524
00:32:37,720 --> 00:32:40,720
And it's, I guess, 70% built right now.

525
00:32:40,720 --> 00:32:41,720
Okay.

526
00:32:41,720 --> 00:32:43,040
And mostly the internal functionality.

527
00:32:43,040 --> 00:32:46,720
We don't have the external bank facing side of things for running it.

528
00:32:46,720 --> 00:32:47,720
Okay.

529
00:32:47,720 --> 00:32:49,440
But it's essentially our interface to our database.

530
00:32:49,440 --> 00:32:54,280
Where we define what intents belong to each customer, what the taxonomy is for that, for

531
00:32:54,280 --> 00:33:00,200
instance, what entities are in there, where they apply, what the response content is, and

532
00:33:00,200 --> 00:33:05,680
the ability to map from utterance to those intents and support the user in making those

533
00:33:05,680 --> 00:33:06,680
decisions too.

534
00:33:06,680 --> 00:33:09,960
So to make sure that you got the context is what that intent means.

535
00:33:09,960 --> 00:33:13,640
If there are a few hundred intents, it might be difficult to know exactly what an utterance

536
00:33:13,640 --> 00:33:17,120
should go into if you're not, you know, fluent in the system.

537
00:33:17,120 --> 00:33:20,600
So we have some supporting information, metadata associated with that, or examples that

538
00:33:20,600 --> 00:33:23,240
already exist to help you make that decision.

539
00:33:23,240 --> 00:33:24,880
So yeah, that's called the Atlas project.

540
00:33:24,880 --> 00:33:30,440
That's kind of our, I guess, the heart behind everything.

541
00:33:30,440 --> 00:33:31,440
Hmm.

542
00:33:31,440 --> 00:33:32,440
Interesting.

543
00:33:32,440 --> 00:33:33,440
Interesting.

544
00:33:33,440 --> 00:33:39,160
And then in terms of, we were speaking upstairs earlier, and you mentioned that you, as

545
00:33:39,160 --> 00:33:44,800
part of, you know, getting to this initial production customer, you kind of replatformed

546
00:33:44,800 --> 00:33:45,960
everything.

547
00:33:45,960 --> 00:33:50,760
How did you have things deployed before and how are they deployed now?

548
00:33:50,760 --> 00:33:56,720
So before we had APII for doing a lot of our functionality for entity recognition, for

549
00:33:56,720 --> 00:34:02,120
instance, as well as the model itself, but now we have that entirely ours.

550
00:34:02,120 --> 00:34:03,120
It's a rebuild.

551
00:34:03,120 --> 00:34:04,120
Okay.

552
00:34:04,120 --> 00:34:10,040
Yeah, I guess I was wondering in terms of, I guess, now that you've kind of built your own

553
00:34:10,040 --> 00:34:18,120
platform for a place, APII.AI, what processes and automation have you built up around deploying

554
00:34:18,120 --> 00:34:20,000
models up into production?

555
00:34:20,000 --> 00:34:21,000
Yeah.

556
00:34:21,000 --> 00:34:27,040
The offline stuff, so the training of the model, we don't have kind of well-defined release

557
00:34:27,040 --> 00:34:28,640
processes for that side of things.

558
00:34:28,640 --> 00:34:32,600
But any model we build and we release, we have a strict release process that's done

559
00:34:32,600 --> 00:34:37,880
with engineering and DevOps, and we ensure that we have a record of what models deployed

560
00:34:37,880 --> 00:34:43,520
in which environment, what was trained on, what the results of evaluation were over time,

561
00:34:43,520 --> 00:34:44,800
and it's controlled.

562
00:34:44,800 --> 00:34:49,600
We don't just release models whenever we feel like it.

563
00:34:49,600 --> 00:34:54,000
We also have test suites that we must run through before we ever release anything to

564
00:34:54,000 --> 00:34:56,800
production to make sure we've not broken anything.

565
00:34:56,800 --> 00:35:02,720
If any intent has reduced in accuracy in the effects, something else down the line in

566
00:35:02,720 --> 00:35:07,360
terms of maybe a flow, a conversational flow, or some keyword isn't working at some point

567
00:35:07,360 --> 00:35:11,600
in the flow, we've got to make sure that's caught and not deployed.

568
00:35:11,600 --> 00:35:18,880
Though I think we're maturing as a company, and that we're a lot more strict on our deployment

569
00:35:18,880 --> 00:35:23,080
environments and how we're actually doing things, but yeah, everything is hosted up on the

570
00:35:23,080 --> 00:35:30,320
cloud and got a serialized model to produce the intent recognition side of things.

571
00:35:30,320 --> 00:35:32,440
Yeah, it's working pretty well.

572
00:35:32,440 --> 00:35:37,880
You mentioned that you're also able to catch when intense change meaning and things like

573
00:35:37,880 --> 00:35:43,320
that, and testing, but are you also able to, do you have machinery in place that is able

574
00:35:43,320 --> 00:35:49,760
to identify, I guess I'm thinking of it like kind of the long tail of intense or entities

575
00:35:49,760 --> 00:35:56,040
that aren't being caught by the system, like how automated does that need to be?

576
00:35:56,040 --> 00:36:03,240
Is that something where you're running a weekly or monthly report and just look at what

577
00:36:03,240 --> 00:36:08,920
isn't being caught correctly or is there an automated process in place that is always

578
00:36:08,920 --> 00:36:14,840
up to date and you're always trying to catch up to build out that long tail?

579
00:36:14,840 --> 00:36:19,840
Yeah, I think to some extent some of the long tail, we're never going to go down to.

580
00:36:19,840 --> 00:36:21,080
It's a long tail.

581
00:36:21,080 --> 00:36:22,640
It's a long tail, for sure.

582
00:36:22,640 --> 00:36:28,440
When we do have the human and loop functionality, it works really well for our use case.

583
00:36:28,440 --> 00:36:31,760
When it comes to finding the things that we probably should support, oftentimes we will

584
00:36:31,760 --> 00:36:37,440
have that ability to run it through our actual model, our kind of model trained on everything

585
00:36:37,440 --> 00:36:41,520
that we have, rather than the model of things that we support for that agent.

586
00:36:41,520 --> 00:36:45,000
Then we can find out if there are things that we're accurately catching, but they just

587
00:36:45,000 --> 00:36:47,600
don't have a response for.

588
00:36:47,600 --> 00:36:51,880
So it looks like we just don't support it, that catches some of those things.

589
00:36:51,880 --> 00:36:57,400
We can also use unsupervised kind of clustering to find groups of things or questions that

590
00:36:57,400 --> 00:37:02,640
converge around a new topic or a new kind of question type that we may want to suggest

591
00:37:02,640 --> 00:37:08,880
as a customer to include or for us to include in our taxonomy if it does not already.

592
00:37:08,880 --> 00:37:11,720
We do also do manual log analysis.

593
00:37:11,720 --> 00:37:14,520
For the time being, we're keeping an eye on the data.

594
00:37:14,520 --> 00:37:18,880
A lot of the data is, especially now we've got a production data coming in, it's interesting

595
00:37:18,880 --> 00:37:19,880
to see.

596
00:37:19,880 --> 00:37:24,960
Just hand, help you make decisions on how we further the product from a customer point

597
00:37:24,960 --> 00:37:25,960
of view.

598
00:37:25,960 --> 00:37:26,960
Interesting.

599
00:37:26,960 --> 00:37:27,960
Interesting.

600
00:37:27,960 --> 00:37:33,800
It sounds like you guys are doing some really interesting things, and in particular it's

601
00:37:33,800 --> 00:37:38,560
interesting to hear some of the background behind kind of the platform shift and what

602
00:37:38,560 --> 00:37:43,840
that's enabled you to do, so thanks so much for sharing that and I'm looking forward to

603
00:37:43,840 --> 00:37:44,840
catching your talk.

604
00:37:44,840 --> 00:37:45,840
Awesome.

605
00:37:45,840 --> 00:37:46,840
It's a pleasure.

606
00:37:46,840 --> 00:37:51,840
Awesome.

607
00:37:51,840 --> 00:37:54,920
All right everyone, that's our show for today.

608
00:37:54,920 --> 00:37:59,400
Thanks so much for listening and for your continued feedback and support.

609
00:37:59,400 --> 00:38:04,400
For more information on Kenneth or any of the topics covered in this episode, head on

610
00:38:04,400 --> 00:38:08,840
over to twimlai.com slash talk slash 61.

611
00:38:08,840 --> 00:38:16,680
To follow along with the Georgian partner series, visit twimlai.com slash gppc 2017.

612
00:38:16,680 --> 00:38:22,520
Of course, you can send along feedback or questions via Twitter, at twimlai, or at Sam

613
00:38:22,520 --> 00:38:26,520
Charrington, or leave a comment on the show notes page.

614
00:38:26,520 --> 00:38:30,000
Thanks once again to Georgian partners for their sponsorship of the show.

615
00:38:30,000 --> 00:38:35,040
Be sure to check out their white papers, which you can find by visiting twimlai.com slash

616
00:38:35,040 --> 00:38:36,040
Georgian.

617
00:38:36,040 --> 00:38:46,680
Thanks again for listening and catch you next time.

