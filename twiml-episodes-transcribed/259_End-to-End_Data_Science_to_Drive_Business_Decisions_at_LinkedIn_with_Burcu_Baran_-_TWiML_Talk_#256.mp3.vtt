WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:28.720
I'm your host Sam Charrington.

00:28.720 --> 00:33.040
I want to send a quick thanks to our friends at Cloud Era for their sponsorship of this

00:33.040 --> 00:39.760
series of podcasts from the Stratidata conference, which they present along with O'Reilly media.

00:39.760 --> 00:41.960
Cloud Era is long been a supporter of the podcast.

00:41.960 --> 00:47.760
In fact, they sponsored the very first episode of Twimble Talk back in 2016.

00:47.760 --> 00:51.920
Since that time, Cloud Era has continued to invest in and build out its platform, which

00:51.920 --> 00:57.680
already securely hosts huge volumes of enterprise data, to provide enterprise customers with

00:57.680 --> 01:01.920
a modern environment for machine learning and analytics that works both in the cloud

01:01.920 --> 01:04.200
as well as in the data center.

01:04.200 --> 01:09.640
In addition, Cloud Era Fast Forward Labs provides research and expert guidance that helps enterprises

01:09.640 --> 01:14.040
understand the realities of building with AI technologies without needing the higher

01:14.040 --> 01:16.400
and in-house research team.

01:16.400 --> 01:19.840
To learn more about what the company is up to and how they can help, visit Cloud Era's

01:19.840 --> 01:25.280
Machine Learning Resource Center at cladera.com slash ML.

01:25.280 --> 01:29.920
I'd also like to send a huge thanks to LinkedIn for their continued support and sponsorship

01:29.920 --> 01:30.920
of the show.

01:30.920 --> 01:34.560
Now that I've had a chance to interview several of the folks on LinkedIn's data science

01:34.560 --> 01:39.720
and engineering teams, it's really put into context the complexity and scale of the problems

01:39.720 --> 01:44.520
that they get to work on in their efforts to create enhanced economic opportunities for

01:44.520 --> 01:46.520
every member of the global workforce.

01:46.520 --> 01:51.360
AI and machine learning are integral aspects of almost every product that LinkedIn builds

01:51.360 --> 01:56.040
for its members and customers, and their massive, highly structured data set gives their

01:56.040 --> 02:00.960
data scientists and researchers the ability to conduct applied research to improve member

02:00.960 --> 02:02.800
experiences.

02:02.800 --> 02:09.320
To learn more about the work of LinkedIn Engineering, please visit engineering.linkedin.com slash

02:09.320 --> 02:10.800
blog.

02:10.800 --> 02:16.600
Alright everyone, I am on the line with Burju Bottom.

02:16.600 --> 02:19.640
Burju is a senior data scientist at LinkedIn.

02:19.640 --> 02:23.000
Burju, welcome to this week in Machine Learning and AI.

02:23.000 --> 02:24.000
Thank you very much.

02:24.000 --> 02:26.000
Thanks for having me.

02:26.000 --> 02:27.000
Absolutely.

02:27.000 --> 02:32.040
So, you gave a presentation at Shrata, was it yesterday?

02:32.040 --> 02:34.720
Yes, it was yesterday afternoon.

02:34.720 --> 02:40.440
And you're actually part of a group of folks at LinkedIn talking about using the full spectrum

02:40.440 --> 02:44.120
of data science to drive business decisions.

02:44.120 --> 02:52.320
And so we'll dig into that topic in a lot more detail, but before we do, how did you get

02:52.320 --> 02:55.920
started working in data science and machine learning?

02:55.920 --> 02:56.920
Yeah.

02:56.920 --> 03:03.320
So, yeah, so I work as a data scientist with the data mining team at LinkedIn, but actually

03:03.320 --> 03:10.440
I am a mathematician, so I did my PhD in math in number theory and algebraic geometry,

03:10.440 --> 03:15.880
which actually is a pure math, nothing to do with the applied math, we just prove theorems

03:15.880 --> 03:17.200
and stuff.

03:17.200 --> 03:18.720
And then after my PhD...

03:18.720 --> 03:22.280
I still have nightmares of real analysis in grad school.

03:22.280 --> 03:23.280
Oh.

03:23.280 --> 03:25.160
And that was probably your favorite topic.

03:25.160 --> 03:28.520
Actually, I don't like real algorithms also.

03:28.520 --> 03:31.680
Like, what kind of linear algebra kind of stuff?

03:31.680 --> 03:32.680
Yeah.

03:32.680 --> 03:33.680
Okay.

03:33.680 --> 03:41.440
So, yeah, I was still, yeah, I can understand your pain though.

03:41.440 --> 03:42.440
Yeah.

03:42.440 --> 03:51.920
So, I did my PhD in Europe, and then I came to US as a postdoc at Stanford Math Department.

03:51.920 --> 03:57.040
I was there for two years, and then I went to University of Michigan.

03:57.040 --> 04:03.360
And again, I stayed there another two years, but I was still thinking about being

04:03.360 --> 04:04.360
mathematician.

04:04.360 --> 04:08.520
I didn't have any idea about going in the industry, being data scientists, et cetera.

04:08.520 --> 04:13.720
But during my time at Stanford Math Department, I had some friends in this area who are working

04:13.720 --> 04:14.720
with me.

04:14.720 --> 04:15.720
You make it sound like prison.

04:15.720 --> 04:16.960
You don't have time.

04:16.960 --> 04:23.360
And this was like five, seven years ago, I think, yeah.

04:23.360 --> 04:28.240
So during my deadline, I had some friends, and they already know like, we're much into

04:28.240 --> 04:33.040
this machine learning techniques, and whenever they have this math problem related to

04:33.040 --> 04:36.040
their machine learning problem, they were bringing to me.

04:36.040 --> 04:39.480
And that's where I started to understand like how machine learning works, but only the

04:39.480 --> 04:41.400
math side of it, of course.

04:41.400 --> 04:46.040
And then like during my time at Michigan, I was really very much into this machine learning.

04:46.040 --> 04:48.360
I started thinking more about that.

04:48.360 --> 04:54.120
I slowly, I slowly, you know, like, move toward this applied side of math, like, oh, you

04:54.120 --> 04:58.360
know, by using math, you can also solve that kind of interesting problems.

04:58.360 --> 05:02.840
And then I decided to, you know, like, one day actually I decided that I will quit

05:02.840 --> 05:08.320
math, and then I will go into the machine learning.

05:08.320 --> 05:14.200
But saying that, of course, not that easy, like having all this theoretical math background,

05:14.200 --> 05:20.000
no coding or nothing, no sense of skill knowledge, just knowing the math, like, you cannot

05:20.000 --> 05:22.240
just go and do a machine learning.

05:22.240 --> 05:27.720
I came to this area again, I talked to my friends, and I asked them like, what else I should

05:27.720 --> 05:29.280
learn them.

05:29.280 --> 05:34.000
And I realized it will, this transition will not be that easy.

05:34.000 --> 05:38.120
But then I was lucky that I, at that time, I heard about this inside data science fellow

05:38.120 --> 05:39.120
program.

05:39.120 --> 05:45.800
So this program helps people who has PhD in quantitative sciences to do the transitioning

05:45.800 --> 05:47.200
to data science.

05:47.200 --> 05:52.840
So I was accepted to that program, luckily, and they helped me actually to do the transition.

05:52.840 --> 05:56.680
So they helped me to build the network and, you know, like, learn the right stuff and

05:56.680 --> 06:01.840
then have some data science project, and then, you know, start to talk to companies about

06:01.840 --> 06:05.920
being data scientists, going into interview and stuff.

06:05.920 --> 06:12.080
And my first job was at a startup, which was, it's a six ounce, which is located in San

06:12.080 --> 06:13.080
Francisco.

06:13.080 --> 06:15.600
They are just be to be intelligence company.

06:15.600 --> 06:22.160
So we were doing a lot of machine learning there, actually, like, I, I mean, I had learned

06:22.160 --> 06:26.840
about the theory of machine learning, but of course, like, applying it, like coding and

06:26.840 --> 06:30.680
dying of getting the results with the real data is completely different.

06:30.680 --> 06:34.920
So this is like where I really learned how to do machine learning.

06:34.920 --> 06:40.720
And then after two years working there, three years ago, I started to work at LinkedIn.

06:40.720 --> 06:44.760
And since then, I'm working with the, with the data mining team at LinkedIn.

06:44.760 --> 06:45.760
Okay.

06:45.760 --> 06:46.760
Awesome.

06:46.760 --> 06:54.920
I've had a number of folks from, they went through the insight program on the show.

06:54.920 --> 07:03.880
I've also interviewed, I think Ross Fadley is at his name out of New York.

07:03.880 --> 07:13.800
And I know a manual who runs the AI program or track out of the Bay area.

07:13.800 --> 07:18.200
And I've had a bunch of really great conversations with folks affiliated with, uh, with insight

07:18.200 --> 07:20.640
in, in one capacity or another.

07:20.640 --> 07:24.880
It seems like a great program for folks that are kind of finishing, you know, transitioning

07:24.880 --> 07:29.480
from academia to, you know, their data science or machine learning or they've got a bunch

07:29.480 --> 07:31.680
of other projects now or programs now.

07:31.680 --> 07:32.680
Yeah.

07:32.680 --> 07:33.680
Exactly.

07:33.680 --> 07:36.320
So actually, when I was in this inside, they were pretty new.

07:36.320 --> 07:37.320
It was there.

07:37.320 --> 07:38.320
I was there.

07:38.320 --> 07:41.520
Second group, actually, like, this was four years ago.

07:41.520 --> 07:42.520
Yeah.

07:42.520 --> 07:45.760
And now they are pretty big actually, like, they have a lot of programs going on.

07:45.760 --> 07:46.760
Yeah.

07:46.760 --> 07:47.760
Yeah.

07:47.760 --> 07:55.640
So maybe before we dive into kind of this, your session and, and data mining, I'm curious

07:55.640 --> 08:05.080
about the, you know, this transition from kind of theoretical mathematician to data scientists.

08:05.080 --> 08:07.760
Do you use any of the theoretical math?

08:07.760 --> 08:12.480
Does it kind of impact at all the way you think about data science or not really?

08:12.480 --> 08:19.120
Oh, honestly, the math that I learned at the PhD level, I don't use that at all.

08:19.120 --> 08:24.920
Like, no, unfortunately, I wish I could do it, but no, because I really spent a lot of

08:24.920 --> 08:27.840
time to, you know, understand those concepts.

08:27.840 --> 08:33.720
But, but of course, like being in math, like, having math education for almost 15, 16

08:33.720 --> 08:36.600
years, I'm being in math professionally for 10 years.

08:36.600 --> 08:40.720
Of course, it has a lot of effect on how I do data science.

08:40.720 --> 08:45.760
So obviously, like, I'm used to have this analytic thinking kind of thing.

08:45.760 --> 08:50.880
So when I have the problem, I can put a structure on it and I can, I can see the big picture.

08:50.880 --> 08:53.600
And then I can try to solve it.

08:53.600 --> 08:59.640
And also, I have, I all the time do this reasoning thing, because no, I'm used to prove theorems

08:59.640 --> 09:01.840
know, just combine all these logics.

09:01.840 --> 09:03.880
If this is this, then this is that.

09:03.880 --> 09:09.320
So this also helped me to think not only about house, but I also care about why.

09:09.320 --> 09:15.760
So that helps me to have the understanding about the problem and also about their solution.

09:15.760 --> 09:20.080
And also, of course, I'm very comfortable with the mathematical concept.

09:20.080 --> 09:21.880
And actually, I have a story.

09:21.880 --> 09:28.200
So this was my interview with this, with the startup, this is my first job as a data scientist.

09:28.200 --> 09:32.440
So there was a lead data scientist there and he was interviewing me about machine learning

09:32.440 --> 09:33.840
techniques.

09:33.840 --> 09:39.520
And in the first half of the interview, he started to ask me about questions about those

09:39.520 --> 09:41.200
machine learning algorithms.

09:41.200 --> 09:44.440
And he was always asked me why you do this, why you do that?

09:44.440 --> 09:47.400
And I was so comfortable to explain those.

09:47.400 --> 09:48.960
No, I was comfortable with teaching.

09:48.960 --> 09:50.760
I was comfortable with the math concepts.

09:50.760 --> 09:54.160
And it was like, I was like, wow, I'm really rough in the interview.

09:54.160 --> 09:58.840
Like, I know everything, like, and I like, okay, first half was great.

09:58.840 --> 10:03.360
And then in the second half, he said, okay, you know, all these algorithms well.

10:03.360 --> 10:09.280
Now let's go to the easy part, he said, now I want you to implement this, you know, algorithm

10:09.280 --> 10:10.280
on the watch.

10:10.280 --> 10:14.000
I was like, oops, there's not that easy for me.

10:14.000 --> 10:18.480
And yeah, and I explained to him like, yeah, you think it's the easiest, not easy for

10:18.480 --> 10:19.480
me.

10:19.480 --> 10:27.480
And actually, it took a whole lot of time to implement this on the white board.

10:27.480 --> 10:31.600
And then he explained to me that he said that, yeah, this is, I can understand that you

10:31.600 --> 10:35.680
don't have any coding experience, because I had just told myself half the code.

10:35.680 --> 10:41.080
So it was not really easy for me just to do it on the internet, especially on the interviews.

10:41.080 --> 10:46.920
And but he said that the direction that you come from is completely different.

10:46.920 --> 10:51.760
Usually people learns about these algorithms, how they work, how to code, and then maybe

10:51.760 --> 10:54.040
they dig into the math of those.

10:54.040 --> 10:56.280
So you are completely coming from different directions.

10:56.280 --> 10:58.880
So you had a deeper understanding of how they work.

10:58.880 --> 11:03.800
But now you also have to understand like, you know, like how to write the code and stuff.

11:03.800 --> 11:06.440
So, and this is true, like, this is helping now.

11:06.440 --> 11:10.240
I'm much more comfortable with the coding, obviously.

11:10.240 --> 11:14.600
But this heading is deeper understanding of all these mathematical concepts behind those

11:14.600 --> 11:20.200
algorithms is really helping me a lot, like, you know, like, because when you do the modeling,

11:20.200 --> 11:22.520
it's, there's always some problems.

11:22.520 --> 11:28.800
So if you know, like, where the problem comes from, it'll be, you save a lot of time,

11:28.800 --> 11:29.800
actually.

11:29.800 --> 11:33.560
Otherwise, it's really hard to debug everything and then try to find out what's going

11:33.560 --> 11:34.560
on.

11:34.560 --> 11:35.560
Yeah.

11:35.560 --> 11:42.000
Um, so this, the, the session that you, uh, did at strata was called using the full

11:42.000 --> 11:45.600
spectrum of data science to drive business decisions.

11:45.600 --> 11:46.600
Yeah.

11:46.600 --> 11:47.800
Let's just kind of pick that apart.

11:47.800 --> 11:49.360
Let's start with full spectrum.

11:49.360 --> 11:54.360
When you talk about full spectrum of data science, uh, what are you referring to?

11:54.360 --> 11:59.480
And it almost implies that you, you, you think that at a lot of places, people don't use

11:59.480 --> 12:04.760
the full spectrum of data science, maybe, um, you know, what, what are you getting at with

12:04.760 --> 12:05.760
that?

12:05.760 --> 12:09.320
So with the full spectrum, we are talking about the whole process.

12:09.320 --> 12:14.880
Actually, we talk about this, how we do this production modeling, like the whole machine

12:14.880 --> 12:20.320
learning process, not only just the algorithm part, but we start from the, uh, actually,

12:20.320 --> 12:25.480
the problem definition part, how we clearly, when the business people bring us the problem,

12:25.480 --> 12:30.280
how we clearly define the problem, so that we can convert into the mathematical problem

12:30.280 --> 12:32.360
so that we can solve it.

12:32.360 --> 12:36.400
And once we have the problem, we have the full definition, then we have to think about

12:36.400 --> 12:38.120
the data that we have.

12:38.120 --> 12:42.400
So for example, the label, if this will be the supervised learning, the label preparation

12:42.400 --> 12:43.400
is very important.

12:43.400 --> 12:47.960
So every, every business problem has different way of preparing the label.

12:47.960 --> 12:51.520
So we should be very careful about this label preparation.

12:51.520 --> 12:55.840
And once we had the label preparation, then we had to think about the features.

12:55.840 --> 13:00.920
So, um, and when you had the features, how do you integrate with the labels, like, how

13:00.920 --> 13:03.720
do you do the alignments on the timeline?

13:03.720 --> 13:09.040
Uh, and you had the static features, dynamic features, how would you combine those static

13:09.040 --> 13:11.160
and dynamic features?

13:11.160 --> 13:17.040
And once you, you know, settle all those, then we start with the modeling techniques,

13:17.040 --> 13:22.840
like training and we talk about the data partitioning and, uh, and, uh, we, we talk about,

13:22.840 --> 13:28.640
like, the common mistakes that first we did and that, then, like, um, then, now, like,

13:28.640 --> 13:33.240
we have a lesson, uh, so that, uh, we don't do it anymore.

13:33.240 --> 13:37.280
And, uh, and then after the training, we talk about the model deployment.

13:37.280 --> 13:42.920
So how do we give our results to, to our business partners?

13:42.920 --> 13:48.720
And the most important part and actually the, um, most, um, challenging part is when you

13:48.720 --> 13:54.160
give the results, your business, uh, business partners, uh, when you solve the problem, it's

13:54.160 --> 13:55.320
not finished yet.

13:55.320 --> 14:00.840
So because they use this, uh, this, uh, solution over and over again.

14:00.840 --> 14:06.920
So you have to check the, if the, if the features are more, or the models is doing good.

14:06.920 --> 14:11.560
So because you had the results the first day, everybody's confident about results, model

14:11.560 --> 14:12.560
is fresh.

14:12.560 --> 14:13.560
It's perfect.

14:13.560 --> 14:17.040
But after 30 days, oops, something going on, the red flag.

14:17.040 --> 14:18.240
So what's going on now?

14:18.240 --> 14:20.920
So, so we have to monitor the features.

14:20.920 --> 14:25.960
We have to monitor the model performance and there, we have to just run basic statistics

14:25.960 --> 14:31.360
about, like, is everything stable or there's some degradation somewhere.

14:31.360 --> 14:36.520
And, um, and once you do this, maybe you make, you might decide to do a model refresh.

14:36.520 --> 14:41.560
When you do the model refresh, uh, you need to do the AB testing with the current model

14:41.560 --> 14:44.800
and then decide which model to, to release.

14:44.800 --> 14:49.600
But sometimes the, it's not the model that the problem, where the problem is, sometimes

14:49.600 --> 14:52.080
it is the feature logic is different.

14:52.080 --> 14:59.280
So for example, uh, let's say, um, your, one of the feature is the checking the traffic

14:59.280 --> 15:06.400
of your web page, let's say, uh, and, uh, let's say your web page is just one page

15:06.400 --> 15:10.760
web page, but after a month, it has just three pages.

15:10.760 --> 15:15.160
But then checking the traffic of the first page is now changing the meaning.

15:15.160 --> 15:19.640
So you should be aware of those kind of changes if it is, if it is there.

15:19.640 --> 15:24.720
So, uh, because you need to, you need to be aware of the content, if you are giving the

15:24.720 --> 15:28.040
right content to your machine learning model or not.

15:28.040 --> 15:33.360
So, so we talk about whole this process and each steps, like in detail.

15:33.360 --> 15:39.280
And then we also talk about some, uh, common pitfalls and challenges that we have during

15:39.280 --> 15:40.280
this process.

15:40.280 --> 15:43.760
Like, uh, for example, the model interpretation is one of the biggest challenges that

15:43.760 --> 15:49.640
we have here, uh, because when we present our results, the business partners, they don't

15:49.640 --> 15:53.960
only care about the results, they also care about why we get these results.

15:53.960 --> 15:55.880
What are the key drivers?

15:55.880 --> 16:01.600
So it's pretty challenging to, to, to find, especially, uh, when you have the more complex

16:01.600 --> 16:05.160
models, it's, it's getting harder to explain what's going on.

16:05.160 --> 16:10.400
So you cannot just, you know, use models as a black box, uh, for those kind of problems.

16:10.400 --> 16:13.520
It's also data quality is very important and it's another challenge.

16:13.520 --> 16:18.560
The more data is much harder to maintain the quality of the data.

16:18.560 --> 16:22.920
So yeah, we talk about whole this process by giving examples and the, um, the things that

16:22.920 --> 16:27.600
we need to care for what, but this was the whole, like, how we use the whole spectrum of

16:27.600 --> 16:30.400
data science to, to give business decisions.

16:30.400 --> 16:35.840
Well, that's a lot of, I think you're like, now that, now I understand why there are

16:35.840 --> 16:40.440
like five or six people presenting this, uh, yeah, I thought it was at a full day tutorial

16:40.440 --> 16:44.240
or a half day or something, three hours, actually, three hours.

16:44.240 --> 16:45.240
Okay.

16:45.240 --> 16:46.240
Yeah.

16:46.240 --> 16:47.240
Uh, a lot will be online soon.

16:47.240 --> 16:48.240
So, yeah.

16:48.240 --> 16:49.240
Okay.

16:49.240 --> 16:50.240
Oh, cool.

16:50.240 --> 16:55.160
So, uh, let's maybe walk through some of these points, um, you know, you started, uh,

16:55.160 --> 16:59.200
at the beginning, right, problem formulation, a lot of people, you know, we talk a lot

16:59.200 --> 17:05.760
about algorithms, um, but that initial, you know, phase of really understanding the problem

17:05.760 --> 17:11.400
that you're trying to solve and translating that into, you know, kind of mathematical

17:11.400 --> 17:15.360
or data science thinking can be, uh, a challenge.

17:15.360 --> 17:21.400
What, how do you approach that and, you know, what have you learned, uh, you know, what,

17:21.400 --> 17:24.400
what do you think that people get wrong about that?

17:24.400 --> 17:30.560
Um, actually, the, what I learned is that the domain knowledge is very important.

17:30.560 --> 17:35.360
So it's not only only the business partner can, you know, make it like a good problem

17:35.360 --> 17:40.200
to solve or it's not only data scientists who can, you know, just make it into math problem

17:40.200 --> 17:41.720
and then start solving it.

17:41.720 --> 17:43.560
It's the conversation is very important.

17:43.560 --> 17:47.920
So you should, data scientists should really understand what is really the business partners

17:47.920 --> 17:52.000
trying to solve, what is the background, where this problem is coming from.

17:52.000 --> 17:58.040
And then, uh, once the data science understand that data science understand this, then, uh,

17:58.040 --> 18:02.200
she needs to convert this into mathematical problem, but then she needs to explain like

18:02.200 --> 18:07.640
how she views it, like where the solution is going is a solution that she's trying to

18:07.640 --> 18:12.560
go, is the direction is the same as the business partners thinking about, I think the conversation

18:12.560 --> 18:14.040
is really very important.

18:14.040 --> 18:19.280
The, the, when data scientists try to try to convert this problem into mathematical problem,

18:19.280 --> 18:22.800
she needs to understand the domain knowledge from the business partner.

18:22.800 --> 18:27.400
So, uh, for example, I will give a very, very easy example.

18:27.400 --> 18:33.480
So let's say, uh, LinkedIn talent, LinkedIn talent has this product called Curious Suscription.

18:33.480 --> 18:37.800
So it's usually the people who are job-seeker by this products.

18:37.800 --> 18:42.400
It's more about you can be the third degree connections profile and you can do advanced

18:42.400 --> 18:44.360
job search, etc.

18:44.360 --> 18:49.360
So let's say, uh, LinkedIn talent wants to make an email campaign for the product, uh,

18:49.360 --> 18:55.840
Curious Suscription and, uh, they want to send email for this and how do they send, who,

18:55.840 --> 18:59.560
who they should send those emails, basically, this, this is the question that they bring

18:59.560 --> 19:00.560
up to us.

19:00.560 --> 19:06.120
So obviously, for example, they cannot send it to all like 610 million members.

19:06.120 --> 19:12.240
So we would have a, we would have another problem if they would do this.

19:12.240 --> 19:16.520
So they, they bring this problem to us and then we start to ask this question, oh, do

19:16.520 --> 19:19.040
we also have historical data about this?

19:19.040 --> 19:21.480
Did you already sell this product before?

19:21.480 --> 19:24.920
So if you sell this product before, can we get the data?

19:24.920 --> 19:29.720
So are these people are the member, LinkedIn member, can we get more data about those people?

19:29.720 --> 19:34.280
Once we are able to get the answer for this down, we slowly say, okay, we had the data

19:34.280 --> 19:35.520
down, we can solve this problem.

19:35.520 --> 19:40.840
We can just apply machine learning techniques and then, um, get the solution and then, uh,

19:40.840 --> 19:46.760
it results, but then they say, okay, I don't only care about who, who, who, who will, who

19:46.760 --> 19:51.600
I'm going to send this email, but I also care about why I send this email to these people

19:51.600 --> 19:55.720
that I said, oops, then they want the model interpretation also.

19:55.720 --> 19:57.720
So then, uh, the problem is different.

19:57.720 --> 20:00.920
So I don't only care the performance of the model.

20:00.920 --> 20:04.840
I also care about the interpretation of the model.

20:04.840 --> 20:09.600
So when I'm doing the modeling, I need to balance between the, uh, performance and

20:09.600 --> 20:16.240
also interpretation, because, um, without experience like, we, like models like random

20:16.240 --> 20:21.960
forums, uh, XG booths are, uh, performance much better than the logistic regression, linear

20:21.960 --> 20:27.560
regression, those kind of models, but, uh, the, this kind of ran, it's, it's hard to use

20:27.560 --> 20:31.400
the, it's hard to do the model interpretation with the random forest.

20:31.400 --> 20:36.160
Um, of course, there are these, uh, future importance coming from these machine learning

20:36.160 --> 20:39.800
techniques, but we should be careful about the bias coming from them also.

20:39.800 --> 20:42.400
So it's, it's hard to use them as a black box.

20:42.400 --> 20:48.840
So we try to, we try to get use more, much simpler model, maybe sacrifice some of the

20:48.840 --> 20:50.600
performance of the model.

20:50.600 --> 20:54.200
So yeah, those are the things like, you know, they tell us the problem and then we think

20:54.200 --> 21:00.000
about the mathematical solution, but then we, we, we, we drive the conversation from

21:00.000 --> 21:03.840
their own and then try to find solution together, basically.

21:03.840 --> 21:10.120
And is, is this a process that you usually able to, you know, you, you have an hour meeting

21:10.120 --> 21:14.760
scheduled and they come to you and tell you their problem and you kind of, you're all

21:14.760 --> 21:21.000
on the same page by the end of that meeting or is it a, a, a process that, you know, continues

21:21.000 --> 21:24.320
uh, for an extended period of time?

21:24.320 --> 21:31.120
Actually, yeah, so, um, it's usually like, my team is more like, uh, more like, uh,

21:31.120 --> 21:36.760
help say, like horizontal team. So for example, LinkedIn turned ahead on data science team.

21:36.760 --> 21:39.960
So they are in conversation with their data science team.

21:39.960 --> 21:45.680
So this data science team already had them to convert this problem into mathematical problems

21:45.680 --> 21:49.040
and this team is aware of all the data, everything that they have.

21:49.040 --> 21:52.360
So they are in contact with them all the time, basically.

21:52.360 --> 21:53.920
So this is a vertical data science team.

21:53.920 --> 21:58.320
I am more horizontal data science team, we are more, um, technical.

21:58.320 --> 22:02.520
So when they, when this, their data science team had this machine learning problem and

22:02.520 --> 22:07.880
if it is a little bit more complicated than they expect, than they bring this problem

22:07.880 --> 22:12.800
to our team and then we try to solve this together with their data science team.

22:12.800 --> 22:17.200
So when we had the question, we usually contact with the data science team, but yeah, data

22:17.200 --> 22:20.160
science team is all the time in contact with business partners.

22:20.160 --> 22:24.040
So they are a way of what's going on on their side, yeah.

22:24.040 --> 22:30.640
Do you often find that, um, that folks are kind of going down, you know, blind alleys

22:30.640 --> 22:36.360
and you have to like, you know, you're, you're, you're engaged with folks that are kind

22:36.360 --> 22:42.040
of far into the modeling process, but in order to actually make progress on what the,

22:42.040 --> 22:46.720
the business is trying to do, you have to kind of start all the way over from the definition

22:46.720 --> 22:55.360
of the product or, um, do, you know, just having kind of a data science team that you're

22:55.360 --> 22:57.880
working with kind of alleviate that issue.

22:57.880 --> 23:03.720
I, I guess I, I get finding conversations, you know, with, uh, you know, folks that are

23:03.720 --> 23:08.200
in data science, supporting, you know, business units that often the business units will come

23:08.200 --> 23:13.280
to them with kind of, you know, wild half, you know, thought out, you know, hey, I want

23:13.280 --> 23:18.840
a model that does this and there's really this kind of walking back that you need to do

23:18.840 --> 23:24.440
to get them away from thinking about a specific solution to what the problem that they're actually

23:24.440 --> 23:29.600
trying to solve is, um, and I'm wondering how that manifests for you with the kind of two

23:29.600 --> 23:33.400
layers that you have to get back to that, the business itself.

23:33.400 --> 23:34.400
Yeah.

23:34.400 --> 23:39.680
I mean, those things happen so few times it happens, for example, like, uh, the, the problem,

23:39.680 --> 23:43.640
the way that they convert it doesn't make sense and we realize it when we start to check

23:43.640 --> 23:44.640
the data.

23:44.640 --> 23:49.480
So we realize it's something going something is wrong, you know, like it's not maybe these

23:49.480 --> 23:53.320
are not the, um, these are not the results that they expect.

23:53.320 --> 23:59.640
So and then you start to slowly debug then on the process from problem formulation to

23:59.640 --> 24:05.080
getting the data, something must be broken there, then we slowly debug and a few times

24:05.080 --> 24:09.520
you realize the problem preparation problem, there is a problem with the problem, the

24:09.520 --> 24:13.840
definition, then we go back there together all together and we sit together.

24:13.840 --> 24:17.560
We try to understand now we try to convert the problem together there.

24:17.560 --> 24:19.920
Yeah, it happened actually a few times.

24:19.920 --> 24:25.800
And is there a, you kind of talk about this debugging process?

24:25.800 --> 24:29.720
Is it, uh, you know, what is that process?

24:29.720 --> 24:36.280
Is there kind of a set way that you go about that or is it kind of systematically, you

24:36.280 --> 24:41.680
know, checking your various assumptions into you, find something that doesn't line up?

24:41.680 --> 24:47.320
So, uh, so there is some parts that we do manually and the other parts are done in the

24:47.320 --> 24:48.320
platform.

24:48.320 --> 24:52.080
So the ones that we do the manually, we really check if we are doing it correctly or not.

24:52.080 --> 24:55.480
For example, the, the logic on the label preparation.

24:55.480 --> 24:58.960
So is it, is it really the, the logic there is the right logic?

24:58.960 --> 25:04.240
Um, I'm usually like, you know, the models that I'm talking about, they are done like many

25:04.240 --> 25:05.240
times.

25:05.240 --> 25:09.560
But when you do it for the first time, then there might be a problem.

25:09.560 --> 25:16.480
So we are very careful about the, the, the problem, for example, uh, on B2B business or even

25:16.480 --> 25:23.640
B2C like acquiring a new customer or empowering a new customer, uh, empowering, empowering

25:23.640 --> 25:28.320
existing customer of like a turn model, uh, we have done those models before.

25:28.320 --> 25:33.800
So we know how to, we know the label logic, we know how to do the problem definition.

25:33.800 --> 25:38.920
But if you are, if the new problem comes and it's the first time that they have this problem,

25:38.920 --> 25:40.240
there we need to be careful.

25:40.240 --> 25:44.120
Like they're actually, uh, you don't immediately put the definition and then start the

25:44.120 --> 25:45.120
soul.

25:45.120 --> 25:46.120
So this is ongoing process.

25:46.120 --> 25:50.120
You start to think about it and then you maybe try one prototype model and discuss

25:50.120 --> 25:54.600
about the results and you go back again, like, okay, if we, if I had changed a problem

25:54.600 --> 25:57.360
to this, then would I get the same result?

25:57.360 --> 26:03.080
So, um, this, this is not a, in that sense, like, uh, it's not the all the time, like,

26:03.080 --> 26:08.200
debugging issue doesn't come very often, but, uh, we know actually when it can come,

26:08.200 --> 26:14.200
it's the problem generation was the first time that we might have this problem.

26:14.200 --> 26:19.880
A lot of the issues that you describe, you, you mentioned kind of this label preparation,

26:19.880 --> 26:25.080
uh, stage a couple of times, it seems like, especially when you start tackling a new business

26:25.080 --> 26:29.800
problem, it's one of the areas where technical or process problems tend to creep in.

26:29.800 --> 26:35.240
Can you talk a little bit about that label, uh, prep stage and the, the kinds of things

26:35.240 --> 26:38.360
you're doing there in the way you approach that at LinkedIn?

26:38.360 --> 26:39.360
Yeah.

26:39.360 --> 26:45.000
So, um, so label preparation, for example, I will explain it with the example that I,

26:45.000 --> 26:50.600
that I gave about the, the slink and talent once to, to the email campaign about the product

26:50.600 --> 26:52.600
career subscription.

26:52.600 --> 26:56.000
Um, for example, they say that they have data.

26:56.000 --> 27:03.760
So the data is like they send this email before, um, and, um, how, how do you, how do you

27:03.760 --> 27:05.520
prepare the label from that?

27:05.520 --> 27:09.840
So this question has, uh, yes or no answer, right?

27:09.840 --> 27:14.560
It's, it will be, it will be a binary classification, it will be either positive or negative.

27:14.560 --> 27:18.240
So, but how do you define the positive, how do you define the negative?

27:18.240 --> 27:21.240
For example, you send the email and then what?

27:21.240 --> 27:22.240
What is positive there?

27:22.240 --> 27:28.680
Just reading the email, clicking the, the, the link that we send or buying the product.

27:28.680 --> 27:33.000
And what is the timeline that you're going to put like it, are if they buy, for example,

27:33.000 --> 27:34.000
do you decide it?

27:34.000 --> 27:37.360
Okay, if they buy, it will be positive for me, this will be my label.

27:37.360 --> 27:40.960
Then are you going to wait for a day, for a week, for a month?

27:40.960 --> 27:42.360
So what's the timeline for this?

27:42.360 --> 27:44.000
You have to stop somewhere.

27:44.000 --> 27:47.120
So deciding those things are, um, are important.

27:47.120 --> 27:52.120
So again, you, you check the data, uh, when you are defining the label, uh, so this, this

27:52.120 --> 27:56.440
is very important actually, this label preparation part.

27:56.440 --> 28:04.280
And the example you just gave, those are labels that you can acquire, define programmatically

28:04.280 --> 28:09.680
by, you know, presumably running some, you know, SQL queries against your data warehouse

28:09.680 --> 28:11.120
or something like that.

28:11.120 --> 28:16.280
Is that the, the majority of the types of problems that you tackle within the data mining

28:16.280 --> 28:20.880
domain, or do you ever have, um, kind of these problems where you have to go back and manually

28:20.880 --> 28:23.880
label, uh, a bunch of data?

28:23.880 --> 28:24.880
Yeah.

28:24.880 --> 28:30.240
So the logic is done manually, but as you say, the, after you have this logic done, then

28:30.240 --> 28:35.240
you just write the code and then code just runs on the, on the, on the Hadoop or like

28:35.240 --> 28:39.680
on, on HDFS and then, yeah, automatically we get the data.

28:39.680 --> 28:43.880
But one, but we did, the, the logic is the most important part.

28:43.880 --> 28:48.120
So once you had the logic, you discuss the logic and you get the code review on the logic,

28:48.120 --> 28:52.640
if everybody agrees, this is the right logic, then the code just goes on, just we use the

28:52.640 --> 28:56.640
same code over and over for the same kind of problem.

28:56.640 --> 28:57.640
Mm-hmm.

28:57.640 --> 29:06.160
And is the, you mentioned kind of this issue of, um, in the talent example, kind of attribution,

29:06.160 --> 29:13.640
when do we say that someone's bought, uh, and also I frequently kind of hear about, um,

29:13.640 --> 29:19.320
you know, issues around features with like, uh, point in time, correctness and, um, you

29:19.320 --> 29:24.520
know, the whole time machine thing, uh, is that something that comes up in the types

29:24.520 --> 29:26.920
of problems you're dealing with?

29:26.920 --> 29:27.920
Yeah.

29:27.920 --> 29:30.320
Those, uh, time alignment is really, really important.

29:30.320 --> 29:37.800
So again, with the same example, so for example, um, let's say you will, you will also look

29:37.800 --> 29:43.720
at the, the behavioral features of those people who you want to send the email, uh, because

29:43.720 --> 29:48.160
it's important to check if they did the recent day job search or if they had a network,

29:48.160 --> 29:51.960
and recently, for example, with the recruiters, so it's a really big indication that they

29:51.960 --> 29:56.760
might buy this product, uh, but then the time is very important.

29:56.760 --> 30:02.920
So, uh, you have to put some, some time and you are going to look at the, the, the, the,

30:02.920 --> 30:07.560
um, action that they did before that time, right?

30:07.560 --> 30:09.720
But why, why do you put this time?

30:09.720 --> 30:17.480
Do you, do you put it when you send the email or, or like, when they clicked the link or,

30:17.480 --> 30:19.760
or one day did a subscription?

30:19.760 --> 30:25.200
Because after you send the email, till to the point that they buy, uh, if you look at

30:25.200 --> 30:29.720
the, the, the action, their behavior is during that time, it might be biased.

30:29.720 --> 30:33.520
It might be that they are just curious about the product and they might, I don't know,

30:33.520 --> 30:37.640
wonder about something and go and check and do the search, it might not be that they

30:37.640 --> 30:40.640
are planning to change their job or something.

30:40.640 --> 30:44.760
So maybe it's a good idea to check those, you know, all these kind of behaviors before

30:44.760 --> 30:48.240
you send the email, before they become aware of this product.

30:48.240 --> 30:54.560
So deciding those kind of, um, time and then, uh, when you combine it with the label,

30:54.560 --> 31:01.680
the feature and just putting, putting the, the, the, the, the timeline on the correct

31:01.680 --> 31:04.840
place is, is also, it's also very important.

31:04.840 --> 31:11.680
Uh, and of course, these are more for, uh, more for, uh, dynamic features like for snapshot

31:11.680 --> 31:17.760
features like, uh, where they live, um, their job title, things like that, which doesn't,

31:17.760 --> 31:23.360
uh, change very often, uh, these are not the big huge problem, but the dynamic features

31:23.360 --> 31:26.920
are, yeah, this won't, won't be very careful about those.

31:26.920 --> 31:31.880
So you've got your problem defined, you've got your, uh, labels generated, you've dealt

31:31.880 --> 31:37.560
with alignment issues, uh, around your features, then it's time to, you know, start modeling

31:37.560 --> 31:43.160
and training a model, you know, what are some of the, the kind of gotchas that come up

31:43.160 --> 31:44.160
there?

31:44.160 --> 31:45.160
Yeah.

31:45.160 --> 31:50.160
So, um, so the first thing is, of course, like partitioning the data, like training,

31:50.160 --> 31:56.680
evaluation and testing, um, of course, like this, the sizes depends on, on your data size

31:56.680 --> 32:04.400
and, um, but one thing that we are very careful, um, uh, for example, if you had to duplicates

32:04.400 --> 32:10.360
in your data, you should really need to deduct all this kind of data, because, um, let's

32:10.360 --> 32:16.440
say you have same to same data and one goes to training set and the other goes to testing

32:16.440 --> 32:17.440
set.

32:17.440 --> 32:18.440
Right.

32:18.440 --> 32:19.440
This is a problem.

32:19.440 --> 32:20.440
Exactly.

32:20.440 --> 32:21.440
Then this is the data leakage.

32:21.440 --> 32:26.760
You should really, you should be careful all those kind of, uh, and, um, and after the

32:26.760 --> 32:31.360
partition, then in the model training part, there are a few things that you have to be

32:31.360 --> 32:37.720
careful, uh, like, um, for example, you have to check your system requirements.

32:37.720 --> 32:43.440
So do you really need very fast algorithm or just your system is really, does, you don't

32:43.440 --> 32:50.600
care about the speed of the algorithm, um, and, um, also, uh, I only talk about the

32:50.600 --> 32:55.680
performance, why is the, uh, interpretation of the model, do you need the interpretation

32:55.680 --> 33:00.440
or the, for your the performance is the most important one, because here at LinkedIn,

33:00.440 --> 33:04.840
like, we usually sacrifice the performance of the model, like, because the interpretation

33:04.840 --> 33:09.600
for most of the problem interpretation is really, very important, uh, but we also have

33:09.600 --> 33:13.160
other problems where, for example, interpretation doesn't have anything to do.

33:13.160 --> 33:15.880
So we really focus moral on the performance.

33:15.880 --> 33:18.640
I wonder on that interpretability point.

33:18.640 --> 33:26.720
Does that, is that static for a given problem or does it change and I'm kind of envisioning

33:26.720 --> 33:29.960
where, you know, a problem is new to the business.

33:29.960 --> 33:34.040
They don't really understand the, the data and the underlying behaviors.

33:34.040 --> 33:38.520
And so they want something really interpretable to help them build up and intuition.

33:38.520 --> 33:44.280
But then, you know, over time, they start to get a better feel for, you know, the, what

33:44.280 --> 33:48.520
they're trying to model and maybe they're willing to, you know, sacrifice some of that

33:48.520 --> 33:50.920
interpretability for additional performance.

33:50.920 --> 33:52.920
Is that a common trajectory?

33:52.920 --> 33:53.920
Exactly.

33:53.920 --> 33:54.920
Exactly.

33:54.920 --> 33:56.800
So this is, this is a very common actually.

33:56.800 --> 34:01.720
So it happens a few times, for example, we propose them to send emails to some certain

34:01.720 --> 34:05.080
customer and they say, no, we shouldn't send this to this customer.

34:05.080 --> 34:07.320
Like, I'm pretty sure it's not the right one.

34:07.320 --> 34:08.320
What do you say?

34:08.320 --> 34:11.320
But the model says, really, you should send an email to this one.

34:11.320 --> 34:12.760
So then they ask, why?

34:12.760 --> 34:17.560
So those examples, we should be ready because of this and this.

34:17.560 --> 34:23.600
So, and if we use algorithms as a black box, we can't answer those kind of questions.

34:23.600 --> 34:25.560
We say, sorry, the algorithm says this.

34:25.560 --> 34:28.240
So they say, no, I'm not going to send this email.

34:28.240 --> 34:33.720
So we should also comies our sales representatives, like, like, these people are really important

34:33.720 --> 34:38.320
and these are the reasons that, that, that they are important.

34:38.320 --> 34:44.520
So actually, we have some in-house solution to that because sometimes like the, for example,

34:44.520 --> 34:52.520
the performance of the, the performance of the models, which has good interpretations,

34:52.520 --> 34:53.920
is really very low.

34:53.920 --> 34:55.120
We cannot use them.

34:55.120 --> 34:59.760
So we need to use, like, a good performer algorithm.

34:59.760 --> 35:03.880
So we have a solution for that in-house solution.

35:03.880 --> 35:13.000
Sorry, for example, let's say we have, let's say we have 300 features in our master model.

35:13.000 --> 35:20.360
And we model with all these 300 features and we score, you know, the customers.

35:20.360 --> 35:25.560
And then we say, and then we try to predict if they will buy some certain product or not.

35:25.560 --> 35:27.640
And we want to know why they buy this product.

35:27.640 --> 35:35.480
So what we do is that we divide the features into different buckets, where each bucket

35:35.480 --> 35:41.080
has like semantic business meaning, like, you know, those features are like behavioral

35:41.080 --> 35:42.080
features.

35:42.080 --> 35:43.560
All features are social features.

35:43.560 --> 35:45.640
All features are identity features.

35:45.640 --> 35:50.200
And let's say I divide into three different buckets.

35:50.200 --> 35:54.640
And then I build a model with the features within each of these buckets.

35:54.640 --> 36:00.440
So I have like three different models, apart from the master model that I have.

36:00.440 --> 36:06.280
And the important thing is that each of these models has their own semantic meaning.

36:06.280 --> 36:12.480
And in this way, I, you know, like, stopped the correlation between the features, between

36:12.480 --> 36:14.120
the groups of the features.

36:14.120 --> 36:16.760
And I, this also reduced the noise.

36:16.760 --> 36:22.280
And for example, when I score with my master model, each customer, I also scored them

36:22.280 --> 36:25.240
with this, this, we called them component model.

36:25.240 --> 36:30.120
I also scored them with these three component models, which has different meaning.

36:30.120 --> 36:36.680
So for example, few times I realize that some, for example, certain person has a high score

36:36.680 --> 36:43.600
with the master model, because they also have a high score coming from the behavioral feature

36:43.600 --> 36:45.000
model.

36:45.000 --> 36:51.280
On the other hand, somebody has another customer has the same thing for the social feature model.

36:51.280 --> 36:56.280
So this tells us it, okay, so the first one got a high score because of the behavioral features

36:56.280 --> 37:00.640
and the other person got high score because of the social features.

37:00.640 --> 37:04.240
And this also helped us to send personalized emails.

37:04.240 --> 37:09.040
So when we are trying to sell the product to this person, for example, in the email, we

37:09.040 --> 37:11.240
talk about more like behavioral features.

37:11.240 --> 37:16.920
We said, oh, you can do that much more search in your, with this product, actually.

37:16.920 --> 37:20.480
And we thought that person might be more interested on search.

37:20.480 --> 37:25.160
On the other hand, for the person who got high score because of the social features, we

37:25.160 --> 37:30.160
more talk about what kind of networking that person can do, you know, if he buys this

37:30.160 --> 37:31.160
product.

37:31.160 --> 37:33.080
So this really helped us a lot, actually.

37:33.080 --> 37:38.280
So yeah, this is our in-house solution that we use for now.

37:38.280 --> 37:40.800
Up to now, it worked pretty well.

37:40.800 --> 37:49.560
And so is this component model, is this, are you using it strictly for kind of interpretability

37:49.560 --> 37:54.800
signal, or are you then like training some ensemble of these components, and then using

37:54.800 --> 38:00.760
it to maybe replace the original model or supplement it in some way?

38:00.760 --> 38:04.480
I mean, for now, we only use interpretive purposes.

38:04.480 --> 38:10.080
Few times, if the master model does not do good, but we see a very good performance coming

38:10.080 --> 38:12.840
from the component models, we try to combine.

38:12.840 --> 38:19.600
So because I'm realize it, there is really big noise, you know, when all the features are

38:19.600 --> 38:20.600
together.

38:20.600 --> 38:26.760
So like the models became much better when you separate the features from each other.

38:26.760 --> 38:32.080
But up to now, we couldn't say good performance coming from combination of those models.

38:32.080 --> 38:34.640
So we just use them separately after now.

38:34.640 --> 38:35.640
Okay.

38:35.640 --> 38:36.640
Yeah.

38:36.640 --> 38:37.640
Yeah.

38:37.640 --> 38:43.360
I mentioned data partitioning, and, you know, there's kind of the usual, you know, test

38:43.360 --> 38:51.000
train split kind of issues there, but I imagine that you have to do things somewhat differently

38:51.000 --> 38:57.640
when you're working with $660 million, you know, users, and you have graphs and things

38:57.640 --> 38:58.640
like that.

38:58.640 --> 39:06.080
You know, beyond the de-duplication, are there, you know, ways that you deal with data

39:06.080 --> 39:09.080
partitioning that are kind of unique to LinkedIn scale?

39:09.080 --> 39:10.080
Yeah.

39:10.080 --> 39:11.080
Yeah.

39:11.080 --> 39:19.480
So, for example, a few times, since usually we collected data in the US, we should be careful

39:19.480 --> 39:23.360
about, for example, if we are using the geolocation as a feature.

39:23.360 --> 39:29.440
So it's usually its US, but we have also a lot of data coming from Europe or Asia.

39:29.440 --> 39:31.360
So we should also be careful.

39:31.360 --> 39:38.400
So we also, in order to have the good representative of each feature, we also do like certified random

39:38.400 --> 39:44.240
sampling for each of the both train set, testing set, and validation set.

39:44.240 --> 39:48.360
So we're also careful that each feature is representative.

39:48.360 --> 39:49.360
Yeah.

39:49.360 --> 39:54.720
This is also something that we are, we are very careful, you know, other than the de-duplication

39:54.720 --> 39:55.720
of the data.

39:55.720 --> 40:02.120
Are you typically building models against all of the data or are you, you know, sampling

40:02.120 --> 40:04.560
and training on subsets?

40:04.560 --> 40:07.920
We usually random, we do random sampling and training on subset.

40:07.920 --> 40:08.920
Yeah.

40:08.920 --> 40:12.640
Especially if we do the model on the member level.

40:12.640 --> 40:19.040
So we are trying to, actually, we are trying to be careful about timeline also.

40:19.040 --> 40:26.640
So, for example, let's say if you want to sell the product today, we look at the people

40:26.640 --> 40:30.360
who bought last year and we only focus those members.

40:30.360 --> 40:32.840
We don't go and check every member.

40:32.840 --> 40:36.600
And now we do the model on those people who bought last year.

40:36.600 --> 40:42.360
But of course, in terms of scoring, down we use most of our members in order to score

40:42.360 --> 40:49.520
and then see who will get the highest score, who has the most probability to buy this product.

40:49.520 --> 40:58.960
And is that the kind of locking in on a specific year is that because the, you know, your distribution

40:58.960 --> 41:04.760
will have changed over time and you don't want to kind of confuse your model by pulling

41:04.760 --> 41:08.800
in users from a broad period of time?

41:08.800 --> 41:14.040
Yeah, exactly. We just define a certain period of time, that time, like we saw in this email,

41:14.040 --> 41:17.800
did they buy in the next month or not?

41:17.800 --> 41:23.480
So we make this definition very clear and then this would be our labels associated with

41:23.480 --> 41:29.320
the members and then we start from there, then we attach the features to those members.

41:29.320 --> 41:32.400
So, but the timeline is very clear, yeah.

41:32.400 --> 41:37.840
And so the next thing on your list was kind of sharing the results to business partners.

41:37.840 --> 41:43.960
Is this usually in the form of a kind of a deployed model that's like a service that

41:43.960 --> 41:49.920
is integrated into some application or is it more, you know, like business intelligence

41:49.920 --> 41:56.560
reports and, you know, decision criteria or what are the different ways that you, you

41:56.560 --> 42:01.160
know, both deploy and communicate results to the business?

42:01.160 --> 42:07.240
Yeah. So we show our results on our testing set, of course.

42:07.240 --> 42:11.760
You know, we never touch the testing set during the training purposes or choosing hyper

42:11.760 --> 42:14.600
parameter or like algorithm.

42:14.600 --> 42:22.160
So like we have completely independent testing set and we, we apply this testing set, the

42:22.160 --> 42:27.240
model that we chose, we think it's the best performance model.

42:27.240 --> 42:33.920
And then this results, we need to, we need to show some results to our business partners.

42:33.920 --> 42:39.320
So since we are, since this is a business problems, we also consider the business metrics.

42:39.320 --> 42:42.360
So for example, the conversion rate is very important for them.

42:42.360 --> 42:44.320
So we had to show them the conversion rate.

42:44.320 --> 42:47.880
So it's also, they are interested in the ROC curve.

42:47.880 --> 42:54.440
So it's a little bit technical, but they have a way to see the compare to models, because

42:54.440 --> 42:58.680
when we present the model, probably there is another model coming from the last year.

42:58.680 --> 43:00.600
So this is our baseline model.

43:00.600 --> 43:05.800
So they, they are, they will be able to compare, oh, this model is doing good or bad than

43:05.800 --> 43:06.800
last year.

43:06.800 --> 43:07.800
Why is this so?

43:07.800 --> 43:11.760
So this is all, you know, this will be all the discussion between the business people

43:11.760 --> 43:13.120
and us.

43:13.120 --> 43:16.480
So yeah, we, we prepare our, you know, the performance evaluation.

43:16.480 --> 43:22.280
If it's a binary classification model, it will be probably a ROC curve and the, um, and

43:22.280 --> 43:23.280
the conversion rate.

43:23.280 --> 43:26.640
We also, of course, prepare the key drivers.

43:26.640 --> 43:29.560
We showed the key drivers if they make sense to them or not.

43:29.560 --> 43:33.200
So they, they have really a good domain knowledge.

43:33.200 --> 43:36.240
So they can, so this feature doesn't have anything to do with the results.

43:36.240 --> 43:37.760
Why did come up?

43:37.760 --> 43:41.920
And now we go over, for example, they want to see the people who has the highest scores.

43:41.920 --> 43:44.440
So we go over them and they check them.

43:44.440 --> 43:48.960
So, uh, and if they see any red flag or not, then they let us know.

43:48.960 --> 43:53.440
So we sit together for an hour and we discuss all those things and they go over the, the,

43:53.440 --> 43:56.280
the companies which had the highest score.

43:56.280 --> 43:58.200
And then we get the feedback from them.

43:58.200 --> 44:03.360
And if the feedback is positive, then we release models to them, then scoring process

44:03.360 --> 44:06.440
start and we can deploy our models.

44:06.440 --> 44:11.680
Maybe we can kind of wrap things up with talking about how you ensure that these models,

44:11.680 --> 44:13.360
uh, remain fresh.

44:13.360 --> 44:17.680
You mentioned, uh, AB testing is something that you do.

44:17.680 --> 44:18.680
Yeah.

44:18.680 --> 44:19.680
Yeah.

44:19.680 --> 44:25.240
So we use, we use AB testing in order to, if, if we need to refresh the model, then we

44:25.240 --> 44:31.080
use the AB testing to see if the current model is better or the one that I, that we built,

44:31.080 --> 44:33.880
uh, if the new model that we built is doing good.

44:33.880 --> 44:39.960
But before that, we, once we had the model, we, we constantly do the future monitoring

44:39.960 --> 44:44.720
and the model performance monitoring, we, we want to see the trends on the features.

44:44.720 --> 44:50.520
Anything is decreasing or increasing, if there is an spike on the features, uh, it's because

44:50.520 --> 44:54.600
of the, uh, I'm, I know, holiday season or something else going on.

44:54.600 --> 44:57.360
So we should be aware all those kind of things.

44:57.360 --> 45:01.200
Same thing with the model performance, there's something might be broken somewhere.

45:01.200 --> 45:05.440
So it is really important to go and see, uh, to see if it's coming from the features or

45:05.440 --> 45:07.960
it's coming from the model.

45:07.960 --> 45:13.240
And then once we are aware of all those, then we might decide to refresh the model and do

45:13.240 --> 45:17.880
the AB testing and decide to go with the current model or with a new model.

45:17.880 --> 45:18.880
Yeah.

45:18.880 --> 45:26.280
This AB testing is this, is it primarily offline AB testing or are you, um, doing it online

45:26.280 --> 45:27.280
as well?

45:27.280 --> 45:33.720
And, uh, if you're doing it online, how do you ensure I, I imagine at your scale, like ensuring

45:33.720 --> 45:38.440
kind of statistical significance probably isn't something, you know, it happens probably

45:38.440 --> 45:39.440
pretty quickly.

45:39.440 --> 45:40.440
Yeah.

45:40.440 --> 45:41.440
Yeah.

45:41.440 --> 45:42.440
Yeah.

45:42.440 --> 45:42.440
Maybe depending on the problem.

45:42.440 --> 45:47.040
But like, how do you address the, those kind of practical issues associated with AB testing?

45:47.040 --> 45:52.440
Yeah, from, from the customers, they just do the random sampling and then start, you

45:52.440 --> 45:59.720
know, show, start to use the results from, from both, from both models, like we, they

45:59.720 --> 46:04.560
get the results from the existing models, they get the results from the new model.

46:04.560 --> 46:10.680
And then with this results, they, the sales scientists, they try to use both, both

46:10.680 --> 46:17.120
models, um, and we, the way we design a sign, though, the results coming from the both models

46:17.120 --> 46:18.120
are really random.

46:18.120 --> 46:23.160
So sales representatives are not aware if they are using the current or the new model.

46:23.160 --> 46:28.080
And then we just compare the results, like if, if the, if the results are coming same

46:28.080 --> 46:37.240
or, or, or, or there is any, um, the significance level of confirmation that, that one can, one

46:37.240 --> 46:40.360
should be able to use the new one.

46:40.360 --> 46:45.160
Any, any parting thoughts, um, we covered a lot of ground and you certainly covered a lot

46:45.160 --> 46:50.360
of ground in your presentation, any, did you leave the audience with kind of key takeaways

46:50.360 --> 46:53.640
of things that they needed to be thinking about as they're implementing this in their

46:53.640 --> 46:54.640
own companies?

46:54.640 --> 46:55.640
Yeah.

46:55.640 --> 46:56.640
So, okay.

46:56.640 --> 47:02.720
So we talk about, you know, the each step of this machine learning process for the model,

47:02.720 --> 47:05.160
for production, the model for business problems.

47:05.160 --> 47:12.000
But actually, we can pack all those things, which will be, which will, which can serve not

47:12.000 --> 47:15.480
only to you, but everybody in your team.

47:15.480 --> 47:21.680
So because if one person goes all of this process once, it's okay, but if everybody in your

47:21.680 --> 47:26.400
team does this over and over, then, um, it's, it's not really efficient.

47:26.400 --> 47:31.600
So we should build something which is better, smarter, and which can, which can do this

47:31.600 --> 47:32.920
process.

47:32.920 --> 47:33.920
And it is doable.

47:33.920 --> 47:35.280
So there are some platforms.

47:35.280 --> 47:36.280
So does this?

47:36.280 --> 47:42.760
So like AWS, Microsoft Azure, Google Cloud, you can consider to buy those platforms, being

47:42.760 --> 47:48.360
aware their limitations, their data source, the algorithms that they use, or one can build

47:48.360 --> 47:51.520
their own platform, which will do this process.

47:51.520 --> 47:56.280
Or you can do something in the middle, like, uh, you can assemble both existing platforms

47:56.280 --> 47:57.840
with your in-house solution.

47:57.840 --> 48:03.680
So why should, um, consider what their problem is, their timeline, their budget.

48:03.680 --> 48:09.080
And then, uh, instead of, you know, going over this, each of the set, the step manually one

48:09.080 --> 48:11.800
by one, just make this a service.

48:11.800 --> 48:15.480
And then, uh, one can use this service over and over.

48:15.480 --> 48:20.640
But of course, um, uh, one should be careful about the, uh, uh, synthesis is the ultimate

48:20.640 --> 48:22.120
sophistication.

48:22.120 --> 48:27.600
So it is very important to make this platform as simple as possible, because it's important

48:27.600 --> 48:33.480
to maintain this platform, also simplicity is important for the user experience.

48:33.480 --> 48:38.120
But yeah, like, instead of going this step, this process one by one, just consider this

48:38.120 --> 48:41.160
as a service is the best way to look at it, I think.

48:41.160 --> 48:42.160
Agreed.

48:42.160 --> 48:43.160
Awesome.

48:43.160 --> 48:50.000
Well, Bertu, thank you so much for, uh, for walking me through all this.

48:50.000 --> 48:53.760
Um, sounds like a really good presentation.

48:53.760 --> 48:59.920
And, uh, I love the kind of closing imperative to, you know, think about how to make this process

48:59.920 --> 49:03.600
more efficiently by supporting it via some platform.

49:03.600 --> 49:04.600
Well, thank you very much.

49:04.600 --> 49:06.920
It was a good pleasure to be here.

49:06.920 --> 49:13.200
All right, everyone, that's our show for today.

49:13.200 --> 49:17.360
If you like what you've heard here, please do us a favor and tell your friends about the

49:17.360 --> 49:18.600
show.

49:18.600 --> 49:23.160
And if you haven't already hit the subscribe button yourself, make sure to do so.

49:23.160 --> 49:27.040
So you won't miss any of the great episodes we've got in store for you.

49:27.040 --> 49:32.200
For more information on any of the shows in our strata data series, visit twomolei.com

49:32.200 --> 49:34.520
slash strata sf19.

49:34.520 --> 49:37.880
Thanks once again to Cloud Error for sponsoring this series.

49:37.880 --> 49:42.080
Be sure to check them out at cloud error.com slash ml.

49:42.080 --> 49:59.240
As always, thanks so much for listening and catch you next time.

