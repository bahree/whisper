1
00:00:00,000 --> 00:00:15,920
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:15,920 --> 00:00:20,880
people doing interesting things in machine learning and artificial intelligence.

3
00:00:20,880 --> 00:00:23,280
I'm your host Sam Charrington.

4
00:00:23,280 --> 00:00:28,480
I'd like to start off this show by sending out a huge thank you to everyone listening.

5
00:00:28,480 --> 00:00:32,800
We've dropped a ton of great interviews over the past few weeks and through your dedication

6
00:00:32,800 --> 00:00:39,040
we continue to see a growing outpouring of feedback comments and shares with each release.

7
00:00:39,040 --> 00:00:43,600
If you're a regular listener but don't normally send in feedback we'd really love to hear

8
00:00:43,600 --> 00:00:44,640
from you.

9
00:00:44,640 --> 00:00:50,560
So please head on over to Apple Podcasts or wherever you listen and leave us a review.

10
00:00:50,560 --> 00:00:55,760
A five star review is of course appreciated but what's most important is that your voice

11
00:00:55,760 --> 00:00:56,960
is heard.

12
00:00:56,960 --> 00:01:01,840
It lets us know what you like or what you feel we can improve on and it also lets those

13
00:01:01,840 --> 00:01:06,880
looking for a new machine learning and AI podcast know that they should join the Twimble

14
00:01:06,880 --> 00:01:09,120
community.

15
00:01:09,120 --> 00:01:15,040
Speaking of community, the details of our next Twimble online meetup have been posted.

16
00:01:15,040 --> 00:01:22,480
On Tuesday November 14th at 3pm pacific time, we'll be joined by Kevin T who will be presenting

17
00:01:22,480 --> 00:01:28,080
his paper, active preference learning for personalized portfolio construction.

18
00:01:28,080 --> 00:01:32,000
If you've already registered for the meetup, you should have received an invitation

19
00:01:32,000 --> 00:01:33,960
with all the details.

20
00:01:33,960 --> 00:01:39,840
If you still need to register, head on over to twimbleai.com slash meetup to do so.

21
00:01:39,840 --> 00:01:41,480
We hope to see you there.

22
00:01:41,480 --> 00:01:45,760
Now as some of you may know, we spent a few days last week in New York City hosted by

23
00:01:45,760 --> 00:01:49,120
our great friends at NYU Future Labs.

24
00:01:49,120 --> 00:01:53,920
About six months ago, we covered their inaugural AI Summit and event they hosted to showcase

25
00:01:53,920 --> 00:01:58,960
the startups in the first batch of their AI Nexus Lab program as well as the impressive

26
00:01:58,960 --> 00:02:02,080
AI talent in the New York City ecosystem.

27
00:02:02,080 --> 00:02:06,160
While we were more than excited when we found out they would be having a second summit

28
00:02:06,160 --> 00:02:11,360
so soon, this time we had the pleasure of interviewing the four startups of the second

29
00:02:11,360 --> 00:02:13,520
AI Nexus Lab batch.

30
00:02:13,520 --> 00:02:23,840
We also interviewed a bunch of the speakers from the event and we'll be sharing those discussions

31
00:02:23,840 --> 00:02:25,840
over the upcoming weeks.

32
00:02:25,840 --> 00:02:32,080
In this episode, you hear from bite.ai, a startup founded by Vene Anantharaman and Michael

33
00:02:32,080 --> 00:02:38,280
Walski, founders who met working at Clarify, another NYU Future Labs alumni company,

34
00:02:38,280 --> 00:02:43,200
whose CEO Matt Zealer, I interviewed on twimbletalk number 22.

35
00:02:43,200 --> 00:02:47,320
Data is using conversational neural networks and other machine learning to help computers

36
00:02:47,320 --> 00:02:49,920
understand and reason about food.

37
00:02:49,920 --> 00:02:54,920
Their product is an app called BiteSnap, which provides users with detailed nutritional

38
00:02:54,920 --> 00:03:00,240
information about the food they're about to eat using just a photo and a serving size.

39
00:03:00,240 --> 00:03:04,560
We dive into the details of their app and service, the machine learning models and pipeline

40
00:03:04,560 --> 00:03:16,640
that enable it and how they plan to compete with other apps targeting dieters and more.

41
00:03:16,640 --> 00:03:23,360
Alright everyone, I am here at NYU Future Labs in New York City and I am with the co-founders

42
00:03:23,360 --> 00:03:25,120
of BiteAI.

43
00:03:25,120 --> 00:03:29,720
In particular, I'm with Vene Anantharaman and Michael Walski.

44
00:03:29,720 --> 00:03:32,240
Guys, welcome to this weekend machine learning and AI.

45
00:03:32,240 --> 00:03:33,240
Thanks for having us.

46
00:03:33,240 --> 00:03:38,120
Awesome, awesome, why don't we get started by having you tell us a little bit about

47
00:03:38,120 --> 00:03:42,160
your backgrounds and we'll get to what the company is up to.

48
00:03:42,160 --> 00:03:47,160
Cool, as I was introduced, my name is Vene and I kind of work on data infrastructure

49
00:03:47,160 --> 00:03:51,000
and for the last 10 years I've been crawling the web trying to turn that into structured

50
00:03:51,000 --> 00:03:57,200
data and currently what we're working on is building a food intelligence platform that

51
00:03:57,200 --> 00:03:58,960
can understand the world's food.

52
00:03:58,960 --> 00:04:03,400
Okay, so I'm Michael, actually two of us met here in this building at Clarify where the

53
00:04:03,400 --> 00:04:09,000
first 10 threes and I got to work this together for 10 years before starting this company.

54
00:04:09,000 --> 00:04:12,960
Before joining Clarify I was at Columbia studying the pipeline and computer science, the focus

55
00:04:12,960 --> 00:04:13,960
on computer vision.

56
00:04:13,960 --> 00:04:15,960
Okay, awesome, awesome.

57
00:04:15,960 --> 00:04:18,800
You said understanding food, tell me a little bit more about what that means.

58
00:04:18,800 --> 00:04:22,440
I'm assuming since you met at Clarify, you're doing something visual.

59
00:04:22,440 --> 00:04:27,680
Yes, exactly, so to understand the world's food we need to be able to have examples of

60
00:04:27,680 --> 00:04:31,480
what people are eating day to day and most ways that we communicate about food these days

61
00:04:31,480 --> 00:04:32,800
is with pictures.

62
00:04:32,800 --> 00:04:38,040
So we started by building an image recognition model that can understand what we're eating,

63
00:04:38,040 --> 00:04:41,680
which means that we can take something that we're eating and translate into a set of

64
00:04:41,680 --> 00:04:44,320
tags and also give you nutritional information.

65
00:04:44,320 --> 00:04:47,120
And where we're going with that is actually we'd love to be able to take in other ways

66
00:04:47,120 --> 00:04:48,120
we talk about food.

67
00:04:48,120 --> 00:04:52,600
It could be through menus or through text and be able to say, hey, you know, it's XYZ,

68
00:04:52,600 --> 00:04:58,120
it could be made with these ingredients and we want to build a system that can let other

69
00:04:58,120 --> 00:05:02,600
people also be able to, you know, use the intelligence and understanding we have about food

70
00:05:02,600 --> 00:05:04,040
to power their food application.

71
00:05:04,040 --> 00:05:07,280
So it could be a nutrition tracker in a healthcare setting.

72
00:05:07,280 --> 00:05:10,400
It could also be for a recipe website, they have a bunch of pictures, they want to know

73
00:05:10,400 --> 00:05:12,200
what ingredients it is.

74
00:05:12,200 --> 00:05:14,000
That's kind of what we're working on.

75
00:05:14,000 --> 00:05:15,000
Interesting, interesting.

76
00:05:15,000 --> 00:05:18,520
Now, I don't know if you've come across Hillary Mason.

77
00:05:18,520 --> 00:05:22,920
She has a company called Fast Forward Labs here in New York that was actually recently

78
00:05:22,920 --> 00:05:28,560
acquired, but they do kind of, they do data science experiments, if you will.

79
00:05:28,560 --> 00:05:30,520
That's one of the things they do at least.

80
00:05:30,520 --> 00:05:35,200
And they experimented with trying to do this, determine nutritional information based

81
00:05:35,200 --> 00:05:37,720
on pictures of food.

82
00:05:37,720 --> 00:05:41,040
And I think she mentioned this on the podcast I did with her.

83
00:05:41,040 --> 00:05:43,360
She said it was an incredibly difficult prop walk.

84
00:05:43,360 --> 00:05:47,240
Like they end up, I think they end up giving up on it and moving on to something else.

85
00:05:47,240 --> 00:05:50,480
What are you doing differently that makes it tractable?

86
00:05:50,480 --> 00:05:53,600
We kind of approach this from a consumer side of the product called BitesNap.

87
00:05:53,600 --> 00:05:56,560
It's a nap that helps you to track what they're eating, kind of like a knife in this

88
00:05:56,560 --> 00:05:58,480
palette alternative, using images as input.

89
00:05:58,480 --> 00:05:59,480
Okay.

90
00:05:59,480 --> 00:06:02,320
What we do is every time a user comes in and wants to log in the meal, they take a picture

91
00:06:02,320 --> 00:06:06,560
of their food, we give them suggestions of what might be, users that they can correct

92
00:06:06,560 --> 00:06:11,200
this, like the correct choice or kind of pick something else that we didn't predict.

93
00:06:11,200 --> 00:06:12,240
Tell us the portion size.

94
00:06:12,240 --> 00:06:15,800
So every time some bugs in the meal would get training data to improve the algorithm.

95
00:06:15,800 --> 00:06:19,000
And what we do in the app now is, if you take a picture of the meal that we haven't

96
00:06:19,000 --> 00:06:20,840
seen before, we can't recognize.

97
00:06:20,840 --> 00:06:24,320
We allow you to tell us what it is and now the variance to recognize it.

98
00:06:24,320 --> 00:06:25,320
So we do one shot learning.

99
00:06:25,320 --> 00:06:27,400
So the next time you come around, we can recognize it.

100
00:06:27,400 --> 00:06:30,960
And in doing this, we collect all this data, the users on our take about three or four

101
00:06:30,960 --> 00:06:31,960
pictures a day.

102
00:06:31,960 --> 00:06:32,960
Okay.

103
00:06:32,960 --> 00:06:35,440
We're going to have this human loop system to help us keep improving.

104
00:06:35,440 --> 00:06:36,440
Interesting.

105
00:06:36,440 --> 00:06:37,440
How do you measure accuracy?

106
00:06:37,440 --> 00:06:42,960
On the image recognition or on the nutrition side, like kind of the full loop.

107
00:06:42,960 --> 00:06:47,640
So portion size are important and for now we have the users toss the portion size.

108
00:06:47,640 --> 00:06:52,800
So we have a prior, there's this big study called inhanes where the government collected

109
00:06:52,800 --> 00:06:55,080
all this data on people eat, how much they eat.

110
00:06:55,080 --> 00:06:59,720
So we have kind of a distribution of, for example, a fries, how many fries some of my food

111
00:06:59,720 --> 00:07:00,720
for dinner.

112
00:07:00,720 --> 00:07:04,200
And using that as a prior, as like an example of what the portion size might be, okay,

113
00:07:04,200 --> 00:07:07,920
we ask these just to correct that, okay, so it's still on then to kind of tell us how

114
00:07:07,920 --> 00:07:11,320
much they, because it's so professional these days, I mean, just in general, to be able

115
00:07:11,320 --> 00:07:15,480
to measure food and get the accurate numbers, you have to be able to tell us how much

116
00:07:15,480 --> 00:07:16,480
there is.

117
00:07:16,480 --> 00:07:20,800
But we're hoping that by getting this data later on, we actually start using computer

118
00:07:20,800 --> 00:07:22,400
vision to predict the portion size.

119
00:07:22,400 --> 00:07:23,400
Okay.

120
00:07:23,400 --> 00:07:27,040
You know, I'll definitely be downloading this and playing around with this.

121
00:07:27,040 --> 00:07:33,120
So I've been experimenting with a ketogenic diet, which my use fitness pal, like if you're

122
00:07:33,120 --> 00:07:38,280
really into it, you're tracking your macronutrients with every meal and it's a pain in the

123
00:07:38,280 --> 00:07:39,280
butt.

124
00:07:39,280 --> 00:07:44,080
And so I've experimented with just taking a picture of the things that I eat and then

125
00:07:44,080 --> 00:07:47,480
going back afterwards and then trying to look at it and figure out, and it's hard for

126
00:07:47,480 --> 00:07:52,200
me to figure out, okay, what the portion size was, but then also, like, you know, what the

127
00:07:52,200 --> 00:07:53,200
fat content was.

128
00:07:53,200 --> 00:07:57,840
If you go to a restaurant, the fat content and a given meal can vary, you know, pretty

129
00:07:57,840 --> 00:07:58,840
dramatically.

130
00:07:58,840 --> 00:08:03,200
I mean, those aren't things that you can address just by training data, because in those

131
00:08:03,200 --> 00:08:05,880
cases, the users don't even know themselves.

132
00:08:05,880 --> 00:08:09,480
So we're hoping to use the data we call some users and start integrating location into

133
00:08:09,480 --> 00:08:10,720
the system.

134
00:08:10,720 --> 00:08:13,560
So if you know that you go to ShakeShack and you have a burger at ShakeShack, and we've

135
00:08:13,560 --> 00:08:17,560
seen an example of that burger at ShakeShack and some print information, we'll be able

136
00:08:17,560 --> 00:08:20,120
to say it's not just a general burger, it's the ShakeShack burger of the interesting

137
00:08:20,120 --> 00:08:22,920
data that we get from there many.

138
00:08:22,920 --> 00:08:23,920
Okay.

139
00:08:23,920 --> 00:08:30,040
I was going to ask if you were targeting, like, chain types of meals as a, it seems like

140
00:08:30,040 --> 00:08:34,440
that's easier than, so we haven't gotten to it yet, but it's kind of on our roadmap

141
00:08:34,440 --> 00:08:38,280
in the next few months, it's still kind of pulling in information, starting to location.

142
00:08:38,280 --> 00:08:41,640
I kind of have the other signals to improve the accuracy.

143
00:08:41,640 --> 00:08:42,640
Okay.

144
00:08:42,640 --> 00:08:46,360
So tell me a little bit about what some of the big challenges have been for you.

145
00:08:46,360 --> 00:08:49,440
I think for us, the biggest one is just, like you said, it's a hard problem.

146
00:08:49,440 --> 00:08:51,120
The coverage is an issue.

147
00:08:51,120 --> 00:08:54,560
People eat all kinds of foods, there's probably millions of combinations.

148
00:08:54,560 --> 00:08:56,520
And kind of the first explanation that matters.

149
00:08:56,520 --> 00:09:00,080
If someone comes in, they try it, it doesn't work the first time, they might not come

150
00:09:00,080 --> 00:09:01,080
back.

151
00:09:01,080 --> 00:09:03,800
So for us, making sure we have good coverage of all the foods and they have high accuracy

152
00:09:03,800 --> 00:09:08,040
and stuff that you had at home, that it's not at our start menu, this is important.

153
00:09:08,040 --> 00:09:09,040
Right.

154
00:09:09,040 --> 00:09:11,080
How about for you, Bina?

155
00:09:11,080 --> 00:09:16,480
I would say that for us, because we do have a consumer app, I think marketing is pretty

156
00:09:16,480 --> 00:09:19,960
difficult in the consumer space, and our background is a little more technical.

157
00:09:19,960 --> 00:09:25,160
So it's kind of new for us to be marketing a consumer app, and for us, if the more consumers

158
00:09:25,160 --> 00:09:26,880
we get, the more data we can get.

159
00:09:26,880 --> 00:09:31,120
So we're, at least we've been lucky with the futures lab, we've been getting advisors

160
00:09:31,120 --> 00:09:35,640
and help, but it's still kind of an ongoing process that we're learning, how to actually

161
00:09:35,640 --> 00:09:37,880
market the app and get it out there.

162
00:09:37,880 --> 00:09:38,880
Interesting.

163
00:09:38,880 --> 00:09:45,440
Can you talk a little bit about the pipelines that you've created to process all the data?

164
00:09:45,440 --> 00:09:46,920
Yeah, sure.

165
00:09:46,920 --> 00:09:50,840
I mean, we, as we mentioned, we, you know, we scraped a bunch of images from that.

166
00:09:50,840 --> 00:09:54,520
We basically built our own tools to annotate and clean data.

167
00:09:54,520 --> 00:09:56,400
I guess Michael can fill in there.

168
00:09:56,400 --> 00:10:00,840
We built this tool to pull in images, use active learning to help us quickly annotate

169
00:10:00,840 --> 00:10:05,280
millions of images, the two of us managed to annotate three million labeled images of

170
00:10:05,280 --> 00:10:06,280
the different foods.

171
00:10:06,280 --> 00:10:11,040
The two of you met three million over how long it was about a week.

172
00:10:11,040 --> 00:10:12,040
Wow.

173
00:10:12,040 --> 00:10:15,800
So we just clustered and some classifiers to rank and be smart about how we're doing this.

174
00:10:15,800 --> 00:10:17,800
I've kind of done it before, I'd clarify.

175
00:10:17,800 --> 00:10:18,800
Yeah.

176
00:10:18,800 --> 00:10:21,000
I have an idea of how to handle this scale of a data set.

177
00:10:21,000 --> 00:10:22,000
Okay.

178
00:10:22,000 --> 00:10:27,000
And we went from a model of 60 classes to now a bit of over 1500 different foods.

179
00:10:27,000 --> 00:10:30,800
Now that that is out, we're getting all this data from users as well, and we're starting

180
00:10:30,800 --> 00:10:33,120
to chain known that data as well.

181
00:10:33,120 --> 00:10:35,960
I used to say 1500 different foods.

182
00:10:35,960 --> 00:10:41,160
When I think about like how many different foods fitness palette has in it, it's multiple

183
00:10:41,160 --> 00:10:42,160
of that, isn't it?

184
00:10:42,160 --> 00:10:43,160
Yeah.

185
00:10:43,160 --> 00:10:44,160
So there's two issues.

186
00:10:44,160 --> 00:10:45,160
There's whole food state.

187
00:10:45,160 --> 00:10:46,160
You might, you know, go get a grocery store.

188
00:10:46,160 --> 00:10:47,160
There's homey meals.

189
00:10:47,160 --> 00:10:48,160
That's where we focus on.

190
00:10:48,160 --> 00:10:49,160
Right now.

191
00:10:49,160 --> 00:10:50,160
Okay.

192
00:10:50,160 --> 00:10:51,160
And most of these are basic ingredients.

193
00:10:51,160 --> 00:10:55,800
So if you take a play of pasta, tomatoes, we might say it's pasta, but also give you

194
00:10:55,800 --> 00:10:58,840
options for the noodles, the sauce, the cheese on top.

195
00:10:58,840 --> 00:10:59,840
Okay.

196
00:10:59,840 --> 00:11:00,840
Okay.

197
00:11:00,840 --> 00:11:01,840
Okay.

198
00:11:01,840 --> 00:11:02,840
Okay.

199
00:11:02,840 --> 00:11:04,840
So kind of a combination between the food detection as well as like a Google look on

200
00:11:04,840 --> 00:11:05,840
most.

201
00:11:05,840 --> 00:11:06,840
Yeah.

202
00:11:06,840 --> 00:11:07,840
I can't find the products.

203
00:11:07,840 --> 00:11:08,840
Yeah.

204
00:11:08,840 --> 00:11:09,840
Interesting.

205
00:11:09,840 --> 00:11:11,840
And do you also, are you also allowing them?

206
00:11:11,840 --> 00:11:12,840
Yeah.

207
00:11:12,840 --> 00:11:13,840
I do.

208
00:11:13,840 --> 00:11:14,840
I do.

209
00:11:14,840 --> 00:11:15,840
I do.

210
00:11:15,840 --> 00:11:16,840
I do.

211
00:11:16,840 --> 00:11:17,840
I do.

212
00:11:17,840 --> 00:11:18,840
I do.

213
00:11:18,840 --> 00:11:19,840
I do.

214
00:11:19,840 --> 00:11:20,840
I do.

215
00:11:20,840 --> 00:11:21,840
I do.

216
00:11:21,840 --> 00:11:22,840
I do.

217
00:11:22,840 --> 00:11:23,840
I do.

218
00:11:23,840 --> 00:11:24,840
I do.

219
00:11:24,840 --> 00:11:25,840
I do.

220
00:11:25,840 --> 00:11:26,840
I do.

221
00:11:26,840 --> 00:11:33,660
Also are you also allowing them to track the nutritional information over time?

222
00:11:33,660 --> 00:11:38,000
Is it kind of like take plane that role as well or just do they take the data and plug

223
00:11:38,000 --> 00:11:39,000
it into something else.

224
00:11:39,000 --> 00:11:41,200
It's a full tracker flagger.

225
00:11:41,200 --> 00:11:44,480
Logger will give you the breakdowns for the day, for the week and you can see your history

226
00:11:44,480 --> 00:11:45,480
every time.

227
00:11:45,480 --> 00:11:46,460
Okay.

228
00:11:46,460 --> 00:11:47,460
I need this.

229
00:11:47,460 --> 00:11:48,460
Yeah.

230
00:11:48,460 --> 00:11:51,680
And you should go after this keto market like there's an out of news that something

231
00:11:51,680 --> 00:11:52,680
that's on your radar.

232
00:11:52,680 --> 00:11:54,560
We're actually getting feedback from our users a lot of them.

233
00:11:54,560 --> 00:11:55,800
We're doing keto chains diet, okay.

234
00:11:55,800 --> 00:12:01,200
And this first division for that in the future is kind of build it up to start putting communities together.

235
00:12:01,200 --> 00:12:01,700
Yeah.

236
00:12:01,700 --> 00:12:05,500
We have users who have all this content in their pictures, and we know that a person's a key to giant diet,

237
00:12:05,500 --> 00:12:08,000
you might be able to connect them to other people who are doing keto,

238
00:12:08,000 --> 00:12:11,800
help them discover foods, share up their eating, start recommending other stuff to them.

239
00:12:11,800 --> 00:12:12,800
Okay.

240
00:12:12,800 --> 00:12:17,100
What are some of the techniques that you're using on the ML and AI side here?

241
00:12:17,100 --> 00:12:21,800
So for image recognition, we're just using standard neural networks, conversion neural nets.

242
00:12:21,800 --> 00:12:26,200
Stories of the I know might have to switch since it tends to fall apart by turrets.

243
00:12:26,200 --> 00:12:33,500
For active learning, just simple like logistic regression, simple like logistic regression to rank the results based on the embedding.

244
00:12:33,500 --> 00:12:35,600
Yeah, it's pretty much a lot of neural networks.

245
00:12:35,600 --> 00:12:36,700
Okay.

246
00:12:36,700 --> 00:12:37,600
Cool.

247
00:12:37,600 --> 00:12:42,500
Where are you kind of in the lifecycle of product is out and on the various app stores,

248
00:12:42,500 --> 00:12:44,800
both you're not going to tell me that you don't support Android.

249
00:12:44,800 --> 00:12:47,400
No, we actually do support iOS and Android.

250
00:12:47,400 --> 00:12:48,900
We realize this is incredibly important.

251
00:12:48,900 --> 00:12:52,100
Okay. So we wear on both things because we're using React Native,

252
00:12:52,100 --> 00:12:58,100
which for a small team, it really helps us because we can have an app that's available for both platforms.

253
00:12:58,100 --> 00:13:01,500
In terms of the product, we actually launched an MVP earlier this year,

254
00:13:01,500 --> 00:13:06,100
and we've kind of been developing that towards kind of product market fit with other people,

255
00:13:06,100 --> 00:13:09,100
for with other apps like my fitness pal, people have some expectations.

256
00:13:09,100 --> 00:13:12,200
So we're really, really close on kind of closing that out.

257
00:13:12,200 --> 00:13:17,000
And in terms of the product, we're now actually focusing to start launching an API

258
00:13:17,000 --> 00:13:20,100
so that people can use our technology and other applications.

259
00:13:20,100 --> 00:13:21,900
That's interesting.

260
00:13:21,900 --> 00:13:24,600
I think I look for an API for my fitness pal.

261
00:13:24,600 --> 00:13:30,100
And if there was one, it was like you had to submit a form and get approved

262
00:13:30,100 --> 00:13:34,000
and talk to their BD people and see what's pretty painful.

263
00:13:34,000 --> 00:13:37,900
Yeah, I mean, I think that with because we're taking a little bit of different approach

264
00:13:37,900 --> 00:13:43,000
in terms of our app strategy, because we actually are fine with giving people macros

265
00:13:43,000 --> 00:13:43,900
and micronutrients.

266
00:13:43,900 --> 00:13:47,800
We find that the information is currently valuable for people to make decisions

267
00:13:47,800 --> 00:13:48,600
about what they're eating.

268
00:13:48,600 --> 00:13:50,300
So we're offering that up.

269
00:13:50,300 --> 00:13:55,400
And we do have plans and thoughts about opening up the API to users themselves

270
00:13:55,400 --> 00:13:58,400
so that they can be creative, so that they can view and visualize their data

271
00:13:58,400 --> 00:13:59,300
in their own ways.

272
00:13:59,300 --> 00:14:03,100
We've experimented with that because we can let you export to CSV or JSON.

273
00:14:03,100 --> 00:14:05,700
So you can pull that in and kind of build your own visualizations

274
00:14:05,700 --> 00:14:09,700
and a few people from the self-quantified community are really excited about it

275
00:14:09,700 --> 00:14:13,300
because they can actually then kind of make their own collages and their own charts

276
00:14:13,300 --> 00:14:16,700
and integrate that into their own self-quantified solutions

277
00:14:16,700 --> 00:14:18,500
because you know, that's not our focus.

278
00:14:18,500 --> 00:14:22,000
But we would love to enable creativity for them around what they're eating

279
00:14:22,000 --> 00:14:24,000
and that's kind of a big part of their life.

280
00:14:24,000 --> 00:14:30,300
And so do you, you know, thinking about again, where you're coming from with Clarify,

281
00:14:30,300 --> 00:14:38,000
do you see the bite snap product is kind of just bootstrapping an API business

282
00:14:38,000 --> 00:14:40,000
or is that the product?

283
00:14:40,000 --> 00:14:41,600
It's a core product for us.

284
00:14:41,600 --> 00:14:45,000
But we see that it's a great way to get data to have this human look system.

285
00:14:45,000 --> 00:14:46,000
It keeps improving.

286
00:14:46,000 --> 00:14:50,300
We've gotten a lot of inbound requests for an API from customer research firms,

287
00:14:50,300 --> 00:14:54,500
from healthcare side, from hospitals, people dealing with diabetic patients.

288
00:14:54,500 --> 00:14:57,500
So we're kind of looking to open it up to other people.

289
00:14:57,500 --> 00:15:00,400
There's a lot of core technology building up to other people using other ways.

290
00:15:00,400 --> 00:15:01,400
Okay.

291
00:15:01,400 --> 00:15:01,900
Interesting.

292
00:15:01,900 --> 00:15:06,700
Maybe we can spend some time and you can kind of walk me through the annotation framework

293
00:15:06,700 --> 00:15:09,100
that you built out for getting through those images.

294
00:15:09,100 --> 00:15:11,900
But like I'm still that's an impressive feat.

295
00:15:11,900 --> 00:15:12,900
Yeah.

296
00:15:12,900 --> 00:15:15,900
The tool pretty much, we get content from the web or you have a class.

297
00:15:15,900 --> 00:15:19,200
If I was to say you have a new one hour day chain before, what you do is you predict

298
00:15:19,200 --> 00:15:22,400
on the other images, you get some kind of ranking for each class.

299
00:15:22,400 --> 00:15:27,000
So let's say for strawberries, we'll take a classifier that's a week classifier for

300
00:15:27,000 --> 00:15:31,100
strawberries, rank all of our images throughout, get a signal of what might be a strawberry.

301
00:15:31,100 --> 00:15:32,400
We use that to rank.

302
00:15:32,400 --> 00:15:34,600
We also do visual clustering.

303
00:15:34,600 --> 00:15:38,500
So we can say, you know, for all these images, food, these are the similar looking cluster

304
00:15:38,500 --> 00:15:42,200
for images of strawberries that are in the middle of these strawberries.

305
00:15:42,200 --> 00:15:46,500
Let me look at that cluster and for the whole cluster and make a response of yes, this

306
00:15:46,500 --> 00:15:47,500
is a strawberry.

307
00:15:47,500 --> 00:15:51,700
Then we have a classifier that is that input to train and improve.

308
00:15:51,700 --> 00:15:54,000
So now we can re-rank the results again.

309
00:15:54,000 --> 00:15:57,000
And also get to a high enough accuracy, you can say for the rest of the image, because

310
00:15:57,000 --> 00:16:01,600
the classifier is 99% accurate, or let's say it's 95%, you know, whatever the prediction

311
00:16:01,600 --> 00:16:03,600
is, assume it's a cooling label.

312
00:16:03,600 --> 00:16:04,600
Got it.

313
00:16:04,600 --> 00:16:11,500
So when you annotated 3 million images, like that initial, you look at the cluster of

314
00:16:11,500 --> 00:16:14,500
strawberries and say, yes, these are strawberries.

315
00:16:14,500 --> 00:16:18,500
That might have knocked out 100,000 images for you, or some large number.

316
00:16:18,500 --> 00:16:19,500
Right.

317
00:16:19,500 --> 00:16:23,600
So if you take the ranking for the images, for let's say the strawberries, you kind of see

318
00:16:23,600 --> 00:16:26,800
stuff on the bottom that's definitely not strawberries, so you can say, let's say the

319
00:16:26,800 --> 00:16:28,800
top of the bottom 20%, it's negative data now.

320
00:16:28,800 --> 00:16:29,800
Right.

321
00:16:29,800 --> 00:16:32,800
You take the top 10%, if you look at it and see that, it looks like positives.

322
00:16:32,800 --> 00:16:38,200
You assume that's positive, you update your classifier based on that data, and you retrain

323
00:16:38,200 --> 00:16:42,720
and re-rank again, kind of moving that data away, and kind of keep diving into a clustering

324
00:16:42,720 --> 00:16:46,120
we found was working literally as well, because now you can, instead of looking at single

325
00:16:46,120 --> 00:16:50,320
image at a time, you can say, oh, for this cluster, so all the images look similar, they

326
00:16:50,320 --> 00:16:51,320
look like strawberries.

327
00:16:51,320 --> 00:16:55,280
Yeah, I'm sure you've seen like clustering on the vetting space, so now you can, instead

328
00:16:55,280 --> 00:16:58,600
of responding to an image at a time for a whole cluster, say, yes, this is a strawberry

329
00:16:58,600 --> 00:16:59,600
and opposite strawberry.

330
00:16:59,600 --> 00:17:00,600
Okay.

331
00:17:00,600 --> 00:17:08,800
And so you annotate your strawberries, and then you have all that information for kind

332
00:17:08,800 --> 00:17:14,400
of the next thing you're looking at, so what extent does the annotation for strawberries

333
00:17:14,400 --> 00:17:17,400
impact bananas if that's what you're doing next?

334
00:17:17,400 --> 00:17:18,400
Doesn't at all.

335
00:17:18,400 --> 00:17:20,400
So we've probably started again with some bananas.

336
00:17:20,400 --> 00:17:21,400
Okay.

337
00:17:21,400 --> 00:17:25,000
It turns out in the opposite, very good at handling noise, so if you have a classifier

338
00:17:25,000 --> 00:17:29,600
you're trying on the dirty data, there's probably 60% probably that the thing that mentions

339
00:17:29,600 --> 00:17:31,600
strawberry has strawberries in the image.

340
00:17:31,600 --> 00:17:35,600
If you're trying to go already getting pretty good signal to recognize those items, so you

341
00:17:35,600 --> 00:17:39,600
can kind of push up with that and then kind of keep improving it with the actual annotations.

342
00:17:39,600 --> 00:17:44,000
The other one for us is like we'd like to be able to do segmentation or bounding boxes,

343
00:17:44,000 --> 00:17:46,520
but it's really expensive to get that data at scale.

344
00:17:46,520 --> 00:17:50,600
For us, we want to recognize like thousands of different foods and take us forever and

345
00:17:50,600 --> 00:17:53,960
write some of these at dollars, it's actually annotated at not level.

346
00:17:53,960 --> 00:17:55,640
So yeah, that's what I envision you were doing.

347
00:17:55,640 --> 00:18:00,640
So right now you're identifying images that have a single thing and using that to train.

348
00:18:00,640 --> 00:18:05,240
So even if you have multiple items in an image, what do you want class at a time?

349
00:18:05,240 --> 00:18:06,240
Okay.

350
00:18:06,240 --> 00:18:08,840
So we'll do multiple passes over it if it has multiple items.

351
00:18:08,840 --> 00:18:09,840
Okay.

352
00:18:09,840 --> 00:18:12,240
So most of the time we've released stuff, it's like four or five items on the plate.

353
00:18:12,240 --> 00:18:13,240
Right.

354
00:18:13,240 --> 00:18:15,480
Or it would be a soda, you know, a program fries.

355
00:18:15,480 --> 00:18:17,960
So an example like that would do all the fries first.

356
00:18:17,960 --> 00:18:21,480
We might be able to pick up on correlations, they're super good as well, but we do want

357
00:18:21,480 --> 00:18:24,000
class at a time when you do sweet love.

358
00:18:24,000 --> 00:18:28,400
When you say you look at the plate and you do all the fries first, are you talking about

359
00:18:28,400 --> 00:18:31,200
when you're training or when you're doing inference?

360
00:18:31,200 --> 00:18:35,240
Oh, no, when we're doing the cleaning annotations, the cleaning annotation phase.

361
00:18:35,240 --> 00:18:36,240
Yeah.

362
00:18:36,240 --> 00:18:39,440
But kind of we're hoping that if the class arrives good, the next time we go around,

363
00:18:39,440 --> 00:18:40,960
the burger class five picks it up.

364
00:18:40,960 --> 00:18:41,960
So we'll see that image again.

365
00:18:41,960 --> 00:18:42,960
Right.

366
00:18:42,960 --> 00:18:44,800
We'll see if the burger prediction is correct or not.

367
00:18:44,800 --> 00:18:45,800
Okay.

368
00:18:45,800 --> 00:18:51,560
And so this kind of iterative process, so what the degree is it, like have you automated

369
00:18:51,560 --> 00:18:56,600
all that into some kind of pipeline or is it still, are you like manually kicking off

370
00:18:56,600 --> 00:19:01,800
runs to do annotate for object X or so we kind of have a batch job to do the initial

371
00:19:01,800 --> 00:19:02,800
annotations.

372
00:19:02,800 --> 00:19:07,040
We have a system that's called a Persian Django, like a React front end that will take

373
00:19:07,040 --> 00:19:11,600
those annotations and then have a simpler class of like an SVM or a logistic regression

374
00:19:11,600 --> 00:19:13,200
to do ranking after.

375
00:19:13,200 --> 00:19:17,120
So once you have the initial like suggestions for labels, it doesn't have to be a little

376
00:19:17,120 --> 00:19:18,120
network.

377
00:19:18,120 --> 00:19:19,120
It could be just web data.

378
00:19:19,120 --> 00:19:23,120
You pick up on keywords of strawberries and images on the website that also matches

379
00:19:23,120 --> 00:19:24,120
strawberry.

380
00:19:24,120 --> 00:19:28,080
You kind of, it seems to weak label as a chance of it having a stripper.

381
00:19:28,080 --> 00:19:31,840
And so you index that in this database, you do the skins and kind of can go class by

382
00:19:31,840 --> 00:19:32,840
class.

383
00:19:32,840 --> 00:19:33,840
Okay.

384
00:19:33,840 --> 00:19:34,840
So that pretty much is what I mean.

385
00:19:34,840 --> 00:19:35,840
Okay.

386
00:19:35,840 --> 00:19:36,840
Interesting.

387
00:19:36,840 --> 00:19:38,160
And how about the crawling part?

388
00:19:38,160 --> 00:19:41,640
Was that where there are any challenges involved in that or was that pretty straightforward?

389
00:19:41,640 --> 00:19:46,680
I mean, for the most part, it's just, it's not a challenge to download lots of stuff.

390
00:19:46,680 --> 00:19:51,200
What the real challenge is actually getting decent labels and, you know, we figured out

391
00:19:51,200 --> 00:19:55,440
some techniques to basically, you know, the right sites and the right places that actually

392
00:19:55,440 --> 00:19:56,800
have decent labels.

393
00:19:56,800 --> 00:20:00,600
And we actually even took some unlabeled data so that we could actually supplement the

394
00:20:00,600 --> 00:20:02,280
weak labels we have.

395
00:20:02,280 --> 00:20:05,560
So we can get more examples and that's kind of how we started.

396
00:20:05,560 --> 00:20:08,480
It's just, you know, it takes a little bit of time to get it right.

397
00:20:08,480 --> 00:20:09,480
Mm-hmm.

398
00:20:09,480 --> 00:20:10,480
Okay.

399
00:20:10,480 --> 00:20:11,480
Interesting.

400
00:20:11,480 --> 00:20:13,960
What else are you doing that's cool and interesting and that we should know about?

401
00:20:13,960 --> 00:20:16,680
So right now, we have an issue with package products.

402
00:20:16,680 --> 00:20:19,480
We have a model that works well on whole foods, people seem pretty happy with it.

403
00:20:19,480 --> 00:20:20,480
Okay.

404
00:20:20,480 --> 00:20:23,320
But one, we don't have a huge database of bulk of products, of scans and distribution

405
00:20:23,320 --> 00:20:24,320
data.

406
00:20:24,320 --> 00:20:28,920
So now we're also working on being able to use OCR and computer vision to kind of scan

407
00:20:28,920 --> 00:20:32,800
a product, be able to index it, be able to tell what brand it is, what the health claims

408
00:20:32,800 --> 00:20:36,200
are, what the ingredients are just using computer vision.

409
00:20:36,200 --> 00:20:39,800
Another thing we're playing with is using a ARCAD, and you say, our technologies to do

410
00:20:39,800 --> 00:20:41,280
the portion size estimation.

411
00:20:41,280 --> 00:20:42,280
Interesting.

412
00:20:42,280 --> 00:20:45,480
You know, we have an entire working, you know, an initial idea for this, but the idea

413
00:20:45,480 --> 00:20:50,520
does it will be, we take a picture, we'll get a point cloud, we have a user, pick a portion

414
00:20:50,520 --> 00:20:54,000
size for now, but now we have a point cloud, we have the image, we can do some segmentation

415
00:20:54,000 --> 00:20:55,680
and we have the portion size.

416
00:20:55,680 --> 00:21:00,920
So over time, we'll get a more data to actually nail that part of the problem.

417
00:21:00,920 --> 00:21:01,920
How does ARCAD work?

418
00:21:01,920 --> 00:21:04,400
I haven't had a chance to look under the cover, sir.

419
00:21:04,400 --> 00:21:06,960
We have, we have an intern environment now.

420
00:21:06,960 --> 00:21:11,280
For now, you can get horizontal planes and if you only get a point cloud.

421
00:21:11,280 --> 00:21:15,640
So for us, like, we have a camera open, not only to get picture, but also to get a point

422
00:21:15,640 --> 00:21:16,640
cloud.

423
00:21:16,640 --> 00:21:19,440
So we can get some depth information and figure out the size of the items.

424
00:21:19,440 --> 00:21:21,320
Oh, interesting.

425
00:21:21,320 --> 00:21:25,680
And are you like thinking about taking it the next step where you kind of project on

426
00:21:25,680 --> 00:21:29,800
top of the, like use ARCAD the way it's designed and like project something on top of the

427
00:21:29,800 --> 00:21:35,960
plate that says like, don't need this or, you know, put an X over the surprise.

428
00:21:35,960 --> 00:21:41,240
Yeah, that would be a great, I mean, we were, in terms of ARCAD, we've

429
00:21:41,240 --> 00:21:43,120
we're playing with a different user interfaces.

430
00:21:43,120 --> 00:21:47,560
So one would, one is like Michael's mentioning is that we could project a cup to help you

431
00:21:47,560 --> 00:21:52,080
understand what a 12-ounce cup versus a 16-ounce cup is and kind of put that next to each

432
00:21:52,080 --> 00:21:53,080
other.

433
00:21:53,080 --> 00:21:55,760
So you can select, oh, yeah, this is, you know, a pint glass versus this.

434
00:21:55,760 --> 00:21:59,160
There's like another mode where maybe we need to also do measuring because it's not

435
00:21:59,160 --> 00:22:01,320
perfectly a cup or perfectly a plate.

436
00:22:01,320 --> 00:22:02,560
We can allow people to do measurement.

437
00:22:02,560 --> 00:22:06,880
I don't know if you've ever played with these measurement apps are pretty easy to use.

438
00:22:06,880 --> 00:22:08,880
That's kind of how we envision using AR now.

439
00:22:08,880 --> 00:22:13,120
I mean, in the future, if there were AR glasses, we'd actually love to be able to project

440
00:22:13,120 --> 00:22:17,440
like the information that we know about food onto the real world and that's like a friction

441
00:22:17,440 --> 00:22:18,440
free environment.

442
00:22:18,440 --> 00:22:23,440
A, we're recording what you're eating so you don't have to log because if you have another

443
00:22:23,440 --> 00:22:27,280
passive device absorbing that information, it can now understand, hey, you're eating

444
00:22:27,280 --> 00:22:32,160
pizza with burgers today, maybe tomorrow, you should eat something else, you know, to,

445
00:22:32,160 --> 00:22:33,400
you know, feel better.

446
00:22:33,400 --> 00:22:37,040
So I said, General, the goal is to get to this very passive mode, right now we still

447
00:22:37,040 --> 00:22:39,900
give you suggestions, but for some classes, we're pretty much at a Himalayan lackier

448
00:22:39,900 --> 00:22:40,900
seat.

449
00:22:40,900 --> 00:22:44,120
It's kind of things like burgers fries, like when we predict it from the most part, it

450
00:22:44,120 --> 00:22:45,120
is accurate.

451
00:22:45,120 --> 00:22:46,120
Okay.

452
00:22:46,120 --> 00:22:48,120
So we want to get to a point where this promotional user interaction, you take a picture

453
00:22:48,120 --> 00:22:51,760
or you have some classes, you go by your daily and you're able to measure all the stuff

454
00:22:51,760 --> 00:22:55,560
about your diet, tell if there's weaknesses, tell you how to improve, kind of have this

455
00:22:55,560 --> 00:22:57,520
dashboard where you, track it, don't have to do any work.

456
00:22:57,520 --> 00:23:01,960
The other thing we've noticed is people tend to eat similar stuff every day.

457
00:23:01,960 --> 00:23:05,360
So soon we'll be able to predict where you ate before eating.

458
00:23:05,360 --> 00:23:08,800
If you sit around at home, if you go to coffee shop and you always have a lot to have this

459
00:23:08,800 --> 00:23:12,200
coffee shop, we should be able to predict that you had it and log it for you without

460
00:23:12,200 --> 00:23:13,200
too many of the work.

461
00:23:13,200 --> 00:23:17,000
Like using location services, you just walked in a Starbucks and I had a pumpkin spice

462
00:23:17,000 --> 00:23:18,000
latte to your daily.

463
00:23:18,000 --> 00:23:19,000
Yeah.

464
00:23:19,000 --> 00:23:20,000
Yeah.

465
00:23:20,000 --> 00:23:21,000
Yeah.

466
00:23:21,000 --> 00:23:27,440
I mean, even actually for other meals like, you know, during the week you usually eat XYZ,

467
00:23:27,440 --> 00:23:29,320
so why should you have to go and tap stuff?

468
00:23:29,320 --> 00:23:33,760
We can just kind of fill that in so that, you know, the meals that really are different

469
00:23:33,760 --> 00:23:35,440
or the ones you have to actually log.

470
00:23:35,440 --> 00:23:38,400
We can actually kind of build part of that experience already now, because, you know,

471
00:23:38,400 --> 00:23:41,080
we don't need necessarily AR glasses.

472
00:23:41,080 --> 00:23:45,960
We can just do that based on location, post time, day, you know, what meal it is.

473
00:23:45,960 --> 00:23:46,960
Hmm.

474
00:23:46,960 --> 00:23:51,080
So you mentioned some of the challenges you're seeing in terms of getting this out to

475
00:23:51,080 --> 00:23:52,080
market.

476
00:23:52,080 --> 00:23:56,520
Like what are the top, you know, end things, top three things that you feel like you need

477
00:23:56,520 --> 00:23:59,640
to be successful based on where you are now?

478
00:23:59,640 --> 00:24:03,440
I would say that we need to have product market fit, like relative to the other food

479
00:24:03,440 --> 00:24:04,440
logging apps.

480
00:24:04,440 --> 00:24:06,960
We just can't be, you know, having features missing because people say, oh, I'm so used

481
00:24:06,960 --> 00:24:07,960
to this.

482
00:24:07,960 --> 00:24:08,960
Yeah.

483
00:24:08,960 --> 00:24:09,960
I need it.

484
00:24:09,960 --> 00:24:10,960
That's kind of a, that's a known known.

485
00:24:10,960 --> 00:24:11,960
We know how to do it.

486
00:24:11,960 --> 00:24:15,000
We just, it just takes us a little bit of time to get the features right and, you know,

487
00:24:15,000 --> 00:24:16,000
make them look beautiful.

488
00:24:16,000 --> 00:24:19,560
I mean, that's another very important thing with consumer apps is that it has to look

489
00:24:19,560 --> 00:24:20,560
really good.

490
00:24:20,560 --> 00:24:22,040
The bar is really high now.

491
00:24:22,040 --> 00:24:25,680
Secondly, the thing is there is a lot of other apps in this space.

492
00:24:25,680 --> 00:24:27,840
And for us, you know, they're incumbents.

493
00:24:27,840 --> 00:24:30,520
People know them by name brands like my fitness pal.

494
00:24:30,520 --> 00:24:34,720
So well, for us, it's we have to, you know, kind of become visible and we probably have

495
00:24:34,720 --> 00:24:38,920
to become visible through some other, through other channels and then just pure search because

496
00:24:38,920 --> 00:24:40,920
most people are searching for those main brands.

497
00:24:40,920 --> 00:24:44,520
So I think those are kind of our top two challenges in terms of marketing and the app out

498
00:24:44,520 --> 00:24:45,520
there.

499
00:24:45,520 --> 00:24:50,120
And on the tech side, data is always, for us it's always about having data.

500
00:24:50,120 --> 00:24:53,240
So there's, right now for some of the classes that we predict, we don't have the niche

501
00:24:53,240 --> 00:24:54,240
for data.

502
00:24:54,240 --> 00:24:55,240
So we don't need to show us suggestions.

503
00:24:55,240 --> 00:24:59,160
So we might be able to predict that data, but because we don't have niche for data tied

504
00:24:59,160 --> 00:25:00,160
to it.

505
00:25:00,160 --> 00:25:02,840
Like, we don't have to show that prediction to users.

506
00:25:02,840 --> 00:25:08,520
So did you, did you gather a database of nutrition data by searching and that kind of thing

507
00:25:08,520 --> 00:25:11,120
or by just finding a database?

508
00:25:11,120 --> 00:25:14,120
So the USD has a very big and detailed data set.

509
00:25:14,120 --> 00:25:17,920
It's about a hundred thousand different common things people eat in America.

510
00:25:17,920 --> 00:25:18,920
Oh wow.

511
00:25:18,920 --> 00:25:20,720
And it's broken down by ingredients.

512
00:25:20,720 --> 00:25:24,080
The common portion size is, it has the full nutritional breakdown.

513
00:25:24,080 --> 00:25:25,080
So we're using that for now.

514
00:25:25,080 --> 00:25:26,080
Okay.

515
00:25:26,080 --> 00:25:30,000
But now we're working ways to like pull in restaurant data, to pull in product data and

516
00:25:30,000 --> 00:25:32,240
kind of help us increase that database.

517
00:25:32,240 --> 00:25:33,240
Okay.

518
00:25:33,240 --> 00:25:34,240
Shout out to the USDA.

519
00:25:34,240 --> 00:25:35,240
They do really good work.

520
00:25:35,240 --> 00:25:37,880
Like, their nutrition database is quite complete.

521
00:25:37,880 --> 00:25:41,400
What's interesting is that actually we learn that other nutrition databases for other

522
00:25:41,400 --> 00:25:43,520
countries actually depend on the USDA database.

523
00:25:43,520 --> 00:25:49,640
They actually have references to the English database and that's long term international

524
00:25:49,640 --> 00:25:53,640
expansion is a little bit more tough for problem for us than most people A, we have to convert

525
00:25:53,640 --> 00:25:54,640
our labels.

526
00:25:54,640 --> 00:25:57,560
So the things that we call pizza is probably universal.

527
00:25:57,560 --> 00:26:01,120
But you know, in the morning pastries, people call those things different things in different

528
00:26:01,120 --> 00:26:02,120
languages.

529
00:26:02,120 --> 00:26:04,920
We have to do all that translation, not only that with the nutritional facts, there's

530
00:26:04,920 --> 00:26:08,080
regional variations with how things are prepared.

531
00:26:08,080 --> 00:26:12,360
And then of course, regional dishes, which actually vary by look depending on where you

532
00:26:12,360 --> 00:26:13,520
are.

533
00:26:13,520 --> 00:26:17,400
And we've been getting a lot of requests from international users, hey, can you recognize

534
00:26:17,400 --> 00:26:18,720
XYZ for me?

535
00:26:18,720 --> 00:26:20,760
And we're like, we don't even know what that is.

536
00:26:20,760 --> 00:26:21,760
Nice.

537
00:26:21,760 --> 00:26:26,120
Do you have any, there's so many challenges there like all kinds of foods that are, you

538
00:26:26,120 --> 00:26:29,160
know, look like one thing on the outside, but they have stuff inside.

539
00:26:29,160 --> 00:26:30,160
Yeah.

540
00:26:30,160 --> 00:26:31,160
All right.

541
00:26:31,160 --> 00:26:34,560
The nice part about having this app that you get to control yourself is that we get to

542
00:26:34,560 --> 00:26:39,200
consider correlations, we get seeding patterns, and I use other signals to improve the

543
00:26:39,200 --> 00:26:40,200
predictions.

544
00:26:40,200 --> 00:26:44,640
Based on the time of day, you can say this is probably a coffee, not say hot chocolate.

545
00:26:44,640 --> 00:26:47,720
Kind of using other signals to improve the predictions.

546
00:26:47,720 --> 00:26:51,040
We're hoping that one point will be able to say given, given that you selected these

547
00:26:51,040 --> 00:26:54,880
foreign ingredients, we can figure out the portion size based on how we see it calling.

548
00:26:54,880 --> 00:26:55,880
Okay.

549
00:26:55,880 --> 00:26:56,880
Yeah.

550
00:26:56,880 --> 00:27:00,440
I mean, just basically taking a recipe, you know, the ratios, and this is actually like,

551
00:27:00,440 --> 00:27:04,000
you know, this is actually integrated into some of the USDA data, like you have, they have

552
00:27:04,000 --> 00:27:08,080
some internal equations, basically from that we realize, hey, you can actually take recipes

553
00:27:08,080 --> 00:27:12,360
and understand what the ratios are, and we can integrate that to things that the, you

554
00:27:12,360 --> 00:27:17,360
know, other new things that we learn about from restaurant menus or from web recipes,

555
00:27:17,360 --> 00:27:18,840
which makes it even easier to log.

556
00:27:18,840 --> 00:27:21,520
You just take a picture of this sandwich, which is probably, you know, these things.

557
00:27:21,520 --> 00:27:26,120
For most people, that accuracy is great, you know, because otherwise, they have no infertional

558
00:27:26,120 --> 00:27:27,600
information in front of them.

559
00:27:27,600 --> 00:27:28,600
Okay.

560
00:27:28,600 --> 00:27:29,600
Awesome.

561
00:27:29,600 --> 00:27:34,600
Well, Vinay and Michael, thanks so much for taking the time to chat with us, really appreciate

562
00:27:34,600 --> 00:27:36,800
it, and really enjoyed longing about your company.

563
00:27:36,800 --> 00:27:37,800
Cool.

564
00:27:37,800 --> 00:27:38,800
Thank you for your time.

565
00:27:38,800 --> 00:27:39,800
Thanks.

566
00:27:39,800 --> 00:27:45,400
All right, everyone, that's our show for today.

567
00:27:45,400 --> 00:27:50,400
Thanks so much for listening and for your continued feedback and support.

568
00:27:50,400 --> 00:27:56,240
For more information on Michael, Vinay, bite.ai, or any of the topics covered in this episode,

569
00:27:56,240 --> 00:28:00,640
head on over to twomolei.com slash talk slash 65.

570
00:28:00,640 --> 00:28:05,760
To follow along with the NYU Future Labs AI Summit series, which will be piping to your

571
00:28:05,760 --> 00:28:12,120
favorite pod catcher all week, visit twomolei.com slash AI Nexus Lab 2.

572
00:28:12,120 --> 00:28:17,760
Of course, you can send along your feedback or questions via Twitter to add Twomolei or

573
00:28:17,760 --> 00:28:23,040
at Sam Charrington or leave a comment right on the show notes page.

574
00:28:23,040 --> 00:28:27,160
Thanks again to NYU Future Lab for their sponsorship of the show.

575
00:28:27,160 --> 00:28:33,640
For more information on the AI Nexus Lab program, visit futurelabs.nyc.

576
00:28:33,640 --> 00:28:50,800
And of course, thanks again for listening, and catch you next time.

