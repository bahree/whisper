1
00:00:00,000 --> 00:00:06,640
It's hard to believe, but this is the last podcast episode you will hear before I kick off our inaugural

2
00:00:06,960 --> 00:00:12,520
Twimmelcon conference on Tuesday morning with my on-stage interviews with Anjuang,

3
00:00:13,160 --> 00:00:20,840
co-founder of Landing AI and Coursera, and Deepak Agarwal, vice-president of artificial intelligence at LinkedIn.

4
00:00:22,440 --> 00:00:27,220
This has shaped up to be an incredible event with speakers from Airbnb,

5
00:00:27,220 --> 00:00:34,580
capital-1, Facebook, Levi Strauss, Stripe, SurveyMonkey, Twitter, Uber, and many more companies,

6
00:00:34,580 --> 00:00:41,780
all detailing how they're moving ML and AI out of the lab and driving real value by accelerating,

7
00:00:41,780 --> 00:00:46,180
automating, and scaling their ability to get models into production.

8
00:00:46,900 --> 00:00:49,060
It is not too late to join us.

9
00:00:49,060 --> 00:00:56,020
Register for Twimmelcon today using the code I Want In for 20% off of registration

10
00:00:56,020 --> 00:01:00,500
and a ticket to the hottest enterprise machine learning conference of the year.

11
00:01:01,380 --> 00:01:03,380
Hope to see you there.

12
00:01:05,860 --> 00:01:11,460
All right, everyone. I am on the line with Alex Bann. Alex is a professor of electrical

13
00:01:11,460 --> 00:01:16,740
engineering and computer science at UC Berkeley. Alex, welcome to this weekend machine learning

14
00:01:16,740 --> 00:01:21,060
in AI. Hi, good morning. Thank you for having me. It's fun to be here today.

15
00:01:21,060 --> 00:01:28,340
I am actually in Las Vegas, but you are no longer in Las Vegas, but the thing that

16
00:01:28,340 --> 00:01:34,820
kind of brings us together is you were recently speaking at the AI summit that Amazon put together

17
00:01:34,820 --> 00:01:41,060
here at the reinvent conference. We're going to dig into your presentation, but before we do,

18
00:01:41,060 --> 00:01:45,780
I'd love to hear a little bit about your background and how you got involved in machine learning.

19
00:01:45,780 --> 00:01:50,420
While I was a control theorist by training, which means essentially learning how to

20
00:01:50,420 --> 00:01:54,500
build algorithms to control machines, to control processes, to control robots,

21
00:01:55,460 --> 00:02:01,140
and it's a discipline which is fairly optimization based that finds its roots in the 90s.

22
00:02:01,140 --> 00:02:06,660
And so with the current revolution we are experiencing in AI and machine learning,

23
00:02:07,700 --> 00:02:12,580
I think it became almost obvious that all these fields are progressively merging.

24
00:02:12,580 --> 00:02:17,060
So you think about robotics, about perception and action, optimization, control.

25
00:02:17,060 --> 00:02:22,500
It's all becoming one. And so like many others in this field, I was drawn to it because it provided

26
00:02:22,500 --> 00:02:27,300
a lot of opportunities for new breakthroughs and revisiting all the problems with new techniques

27
00:02:27,300 --> 00:02:33,540
that will clearly advance the field. Great. And so what are your research interests?

28
00:02:34,340 --> 00:02:41,620
So I'm interested in two topics which are interconnected. The first one is the large-scale

29
00:02:41,620 --> 00:02:46,740
impacts of traffic routing apps. When it happens with many, many people use the same apps on the road,

30
00:02:47,300 --> 00:02:52,020
what it does to mobility at super large scale. And then the second topic, which probably is the

31
00:02:52,020 --> 00:02:58,660
topic we're going to talk most today, is the notion of mixed autonomy. What do you do if you have

32
00:02:58,660 --> 00:03:03,700
self-driving vehicles or vehicles with some level of automation interact with manned vehicles?

33
00:03:03,700 --> 00:03:09,380
Your car, my car, car driven by human. And so these two interact because if you think about mobility,

34
00:03:09,380 --> 00:03:15,060
mobility obviously has a lot of large scale aspects. How do you solve the traffic jams in LA?

35
00:03:15,060 --> 00:03:20,420
But mobility also has a lot of local aspects. How do you make traffic flow more efficiently at

36
00:03:20,420 --> 00:03:25,220
a local level? How do you manage an intersection better? How you smooth traffic on the freeway

37
00:03:25,220 --> 00:03:30,100
and so on and so forth? And both of these scales are deeply impacted by machine learning and AI

38
00:03:30,100 --> 00:03:38,980
these days. Interesting. So I'm originally from New York and my wife will on occasion

39
00:03:38,980 --> 00:03:44,820
remind me that I am also a New York driver to her that has a very particular meaning.

40
00:03:45,780 --> 00:03:53,460
But not long ago, there was some research. Actually, it was long ago. Many years ago, I came across

41
00:03:53,460 --> 00:04:00,260
some research study that said that a single aggressive driver can dramatically improve

42
00:04:00,260 --> 00:04:05,780
traffic flow on a highway. And I've always kind of presented her with that fact when she kind of

43
00:04:05,780 --> 00:04:12,900
says that I'm doing this New York driving thing. And I've more recently seen some research that

44
00:04:12,900 --> 00:04:18,820
talks about kind of applies the same idea to autonomous vehicles. Like a single or small number

45
00:04:18,820 --> 00:04:24,580
of autonomous vehicles can also dramatically improve traffic flow. Is that the kind of thing that

46
00:04:24,580 --> 00:04:29,940
you look at near research? Totally. And we must be cousins because I'm a Paris driver. So I think

47
00:04:29,940 --> 00:04:34,900
we share a lot of things in common here. But yeah, no, totally. So it's interesting. In fact,

48
00:04:34,900 --> 00:04:41,460
what you're saying is so true. I would say a single driver can affect traffic very positively

49
00:04:41,460 --> 00:04:46,340
and very negatively. And obviously with self-driving features that are coming on board vehicles,

50
00:04:46,340 --> 00:04:51,060
we're trying to really steer the system towards the better. But we'll have been in a case where

51
00:04:51,620 --> 00:04:55,380
someone does something really strange and it creates some breakdown. It creates a shock wave.

52
00:04:55,380 --> 00:04:59,220
It creates some congestion. It creates some strange phenomenon on the freeway that we did not

53
00:04:59,220 --> 00:05:05,700
anticipate. That happens every day. What we're trying to do here is, in fact, the opposite, which is

54
00:05:05,700 --> 00:05:12,660
trying to understand how the level of automation that is progressively entering the vehicles

55
00:05:12,660 --> 00:05:19,140
could be used to essentially improve things. Whether it's aggressive or not, it's almost a

56
00:05:19,140 --> 00:05:25,140
technicality. But it's more to do something that a human might not necessarily think to do,

57
00:05:25,140 --> 00:05:31,700
but that is actually proven to improve things. And I think the most counter-intuitive things nowadays

58
00:05:31,700 --> 00:05:36,260
in self-driving vehicles is that slowing down in some circumstances might actually improve

59
00:05:36,260 --> 00:05:42,820
traffic flow. Now, it's something that people in 2018 might have a difficult time to conceive.

60
00:05:42,820 --> 00:05:47,620
But it's not that different that maybe 50 years ago when someone came up, or maybe 80 years ago,

61
00:05:47,620 --> 00:05:52,660
when someone came up with a traffic light which had a red as a color and that meant you have to stop,

62
00:05:52,660 --> 00:05:56,740
maybe people didn't realize right away. Well, actually, that will make traffic better because

63
00:05:56,740 --> 00:06:02,020
traffic lights are better than stop signs or unmanaged intersections. What's exactly the same

64
00:06:02,020 --> 00:06:08,500
with self-driving vehicles? It's just not in our culture yet. It's not even in our DNA yet.

65
00:06:08,500 --> 00:06:13,620
But the very same thing we've done with ramped metering or coordinated traffic light signals

66
00:06:13,620 --> 00:06:19,700
in cities in New York, obviously, is one of them. That can also be applied at the level of cars

67
00:06:19,700 --> 00:06:24,340
on the freeways. In fact, it's something that is known and has been known by truckers for a while

68
00:06:24,340 --> 00:06:30,740
because truckers are known to be flow pacifiers. They all maintain a given speed. They usually go on

69
00:06:30,740 --> 00:06:35,860
the same lane. That lane really doesn't have many breakdowns. It's a very smooth lane. So it's

70
00:06:35,860 --> 00:06:41,140
something which has been known in some quote subcommunities of motorists, if you will, over the years.

71
00:06:42,580 --> 00:06:47,300
But that's something that with the self-driving features we see coming into cars is going to become

72
00:06:47,300 --> 00:06:53,700
a reality of our future driving life and have really great potential to make things much better.

73
00:06:54,580 --> 00:07:00,980
That's what we're doing. We're trying to understand how AI can help solve that problem and how can

74
00:07:00,980 --> 00:07:05,860
AI provide solutions which are really innovative in the way we look at that problem?

75
00:07:06,500 --> 00:07:10,820
It makes me think a little bit about the concept of swarming behaviors.

76
00:07:10,820 --> 00:07:22,580
In particular, the idea that you can have these individual agents that have a set of behaviors

77
00:07:22,580 --> 00:07:30,740
that they are program or train or whatever to do. But when you put them in a system together,

78
00:07:30,740 --> 00:07:36,100
they can work towards some kind of broader goal. It's like the self-driving car that you're

79
00:07:36,100 --> 00:07:42,580
describing. It's not just trying to get its passenger from point A to point B, but it's also

80
00:07:44,260 --> 00:07:48,020
well, I mean, that's part of the question. Is it also trying explicitly to

81
00:07:49,540 --> 00:07:55,700
help manage the traffic or is that just a property or an emergent property or something that

82
00:07:55,700 --> 00:08:03,380
happens? That's such a beautiful analogy. Actually, metaphorical and actual. First because swarming

83
00:08:03,380 --> 00:08:11,300
is meant among birds, for example, to reduce drag. The reason why birds swarm is they can fly

84
00:08:11,300 --> 00:08:18,180
much longer. Information is almost like formation flight and reduce the drag. It's not even a metaphor.

85
00:08:18,180 --> 00:08:23,940
It's real. Trucks do platoon to reduce drag. That's beautiful analogy of something real.

86
00:08:23,940 --> 00:08:29,540
But it's also metaphorical. That's really what I like about what you just said. Swarming,

87
00:08:29,540 --> 00:08:35,140
in a sense, attempts among the species that do that to optimize some cost function that might

88
00:08:35,140 --> 00:08:40,020
not be necessarily revealed. It's not that a fish or bird has a cost function that they can compute,

89
00:08:40,020 --> 00:08:46,020
because obviously, even it's implicitly there, it's not explicitly stated in the way they act

90
00:08:46,020 --> 00:08:51,620
to it. But at the end of the day, the swarming achieves a higher objective amongst the swarms.

91
00:08:51,620 --> 00:09:00,180
That's what the self-driving vehicle approach we're following is attempting to do. In swarming,

92
00:09:00,180 --> 00:09:05,300
there's leaders, there's followers. You can view the self-driving analogy in the same way.

93
00:09:05,300 --> 00:09:10,820
If you have, say, 5-10% of vehicles acting in a very specific way to improve the flow,

94
00:09:10,820 --> 00:09:15,140
you could view them as leaders in a kind of a leader following game in a game theoretic sense of

95
00:09:15,140 --> 00:09:21,300
the term. Then the manned vehicles who have to react to this by maybe being surprised,

96
00:09:21,300 --> 00:09:24,980
but if people are driving slower in front of you, you can't pass them, so you'll have to drive

97
00:09:24,980 --> 00:09:32,100
slow as well, or followers in that type of two-team games. The swarming analogy is actually a very

98
00:09:32,100 --> 00:09:38,100
good analogy in that process as that. With a small number of self-driving vehicles, we could

99
00:09:38,100 --> 00:09:44,020
induce the whole population to behave collectively better because of that steering that is done by

100
00:09:44,020 --> 00:09:48,580
these few agents that are able to work with this higher degree of intelligence in the traffic flow.

101
00:09:48,580 --> 00:09:56,260
So, coming back to your presentation at the conference, can you give us an overview of the

102
00:09:57,060 --> 00:10:02,260
general aim and flow of the presentation? Yeah, what we're trying to convey in the

103
00:10:02,980 --> 00:10:08,100
presentation is that AI is going to drive us through a few successive revolutions that are

104
00:10:08,100 --> 00:10:13,540
going to deeply impact the way mixed up to many traffic is studied and eventually how it happens.

105
00:10:13,540 --> 00:10:20,020
The first revolution is models are potentially going away, and what that means is that if you think

106
00:10:20,020 --> 00:10:25,300
about the history of engineering, in engineering, in every subfield whether you work in fluid mechanics,

107
00:10:25,300 --> 00:10:29,940
in structural engineering, and mechanical engineering, or whatever it is, you usually start with an

108
00:10:29,940 --> 00:10:34,740
equation, the model of water, with Navier Stokes' equation, the model of a car, the model of thermodynamics,

109
00:10:34,740 --> 00:10:40,020
whatever it is. There's been hundreds of years of people modeling these things so that you can

110
00:10:40,020 --> 00:10:44,820
inherit the equation and you use the equation to control it, to optimize it, to make things better.

111
00:10:45,540 --> 00:10:50,660
But it turns out that with deeper and first point learning, if you can inherit a simulator

112
00:10:51,220 --> 00:10:57,620
that was built, you know, by experts, you don't need to have actual knowledge of the equation

113
00:10:57,620 --> 00:11:04,260
to improve things. So, in other words, this notion of model-free learning, where you can actually

114
00:11:04,260 --> 00:11:10,740
improve a scoring function without having actually visibility on what the model does, but just

115
00:11:10,740 --> 00:11:16,660
on seeing its output is something that is going to deeply change traffic engineering. And that's

116
00:11:16,660 --> 00:11:20,500
mostly because if you think about the phenomena of traffic, you know, changing lane,

117
00:11:20,500 --> 00:11:26,260
decelerating, routing, deciding to go or not go, stop, accelerate, all these things,

118
00:11:26,820 --> 00:11:31,220
these are very, they're not necessarily complicated to model, but there's a lot of different

119
00:11:31,220 --> 00:11:35,300
actions a human can take. So, if you can get rid of all that modeling and all those

120
00:11:35,300 --> 00:11:40,260
bullion variables corresponding to these decision factors and just learn over simulation,

121
00:11:41,140 --> 00:11:46,660
that's going to make things much easier. And that's what we showed in the talk is that, you know,

122
00:11:46,660 --> 00:11:52,020
simple cases where humans have spent decades to research on how to control, with deeper and

123
00:11:52,020 --> 00:11:56,820
first point learning, we could redo within a few months and we could actually beat. And that's

124
00:11:56,820 --> 00:12:02,420
the beginning of this first revolution where by simulation and by deeper and first point learning

125
00:12:02,420 --> 00:12:08,260
over high fidelity simulators, it will become possible to solve a lot of problems that are

126
00:12:08,260 --> 00:12:13,460
currently unsolved with AI. And the list is long, I mean, the list could include coordination

127
00:12:13,460 --> 00:12:19,140
of traffic light much better than currently done, insertion of self-driving vehicles inside traffic,

128
00:12:19,140 --> 00:12:24,740
control of traffic by self-driving vehicles, automated intersections, and so on and so forth.

129
00:12:24,740 --> 00:12:29,540
So, that's the first revolution I try to explain in the talk saying that, you know,

130
00:12:29,540 --> 00:12:35,060
there's a whole legacy of work that maybe will become obsolete or maybe will just be used for

131
00:12:35,060 --> 00:12:40,340
other things, but there's this new body of work that is progressively emerging where we can beat

132
00:12:40,340 --> 00:12:45,940
the past and do things which are way more innovative. And then beyond that, there's a second

133
00:12:45,940 --> 00:12:51,780
revolution that is maybe a bit further away, which is, well, what if in addition to just forgetting

134
00:12:51,780 --> 00:12:56,740
about the models we could learn from pictures? And that's something that a lot of people have done.

135
00:12:56,740 --> 00:13:01,060
I mean, obviously supervised learning has done a lot of phase recognition and object recognition

136
00:13:01,060 --> 00:13:07,060
and so on and so forth. Well, we're not that far from being able to do the same for traffic management

137
00:13:07,060 --> 00:13:13,700
and traffic control. What if after watching enough videos of traffic, whether these are videos

138
00:13:13,700 --> 00:13:17,860
rendered because they're part of a simulation that produces things or whether they are actual

139
00:13:17,860 --> 00:13:22,980
videos, you know, video cameras deployed in the street or dash car or cams or stuff like that.

140
00:13:24,260 --> 00:13:30,980
Over time, we should be able to learn how to manage streams of vehicles from that data

141
00:13:30,980 --> 00:13:35,700
and potentially from these simulations. And that is likely to be the second revolution we see in

142
00:13:35,700 --> 00:13:41,540
traffic control and traffic management over time. And that revolution is likely to have a much

143
00:13:41,540 --> 00:13:48,100
bigger set of consequences because with the liquidity of cameras and connectivity, we're not that far

144
00:13:48,100 --> 00:13:52,740
from the world where, you know, every vehicle will have cameras and multiple cameras, probably.

145
00:13:53,700 --> 00:13:58,580
And that could help the management of traffic at the scale of cities in ways that have never even

146
00:13:58,580 --> 00:14:04,020
been possible or conceivable before. That's what's going to happen over the next five to ten years.

147
00:14:04,020 --> 00:14:08,900
And it's just the beginning, but that's going to accelerate drastically with the rapid pace of

148
00:14:08,900 --> 00:14:16,660
technology here. So with regard to the first of the two revolutions that you outlined, I think

149
00:14:17,700 --> 00:14:23,460
long-term listeners of the show probably kind of know the direction that I'm going ahead in

150
00:14:23,460 --> 00:14:30,820
and the question that I'm going to ask. And it relates to this notion of model-free.

151
00:14:31,620 --> 00:14:38,420
In particular, it seems to be, I guess in a lot of ways, like a very Berkeley-oriented idea.

152
00:14:38,420 --> 00:14:43,620
And I guess I'm rarely extrapolating from maybe very few conversations.

153
00:14:43,620 --> 00:14:47,300
You know, one of the conversations that I had very early on was with Peter Abiel,

154
00:14:47,300 --> 00:14:51,700
who, you know, believes very strongly in this idea of kind of model-free approaches and

155
00:14:51,700 --> 00:15:00,500
reinforcement learning-based approaches. And since then, I kind of test that idea with a lot

156
00:15:00,500 --> 00:15:07,620
of people. And the kind of conclusion that I've come to is that, A, this is a major kind of theme

157
00:15:07,620 --> 00:15:15,540
and where we are in the AI community. And it seems like for many, like we had this

158
00:15:16,500 --> 00:15:21,620
model-oriented view of the world as you described. It goes back many, many years.

159
00:15:22,500 --> 00:15:29,700
And then we've been more recently very excited about deep learning and deep reinforcement

160
00:15:29,700 --> 00:15:32,980
learning and other approaches and have kind of thrown away the models.

161
00:15:32,980 --> 00:15:40,500
You know, I guess ultimately what it comes down to is overcome the, you know, some of the,

162
00:15:40,500 --> 00:15:45,460
you know, I guess basically just get the best of both worlds, right? Overcome the computational

163
00:15:45,460 --> 00:15:51,700
challenges of deep learning, deep reinforcement learning, and take advantage of the many years of

164
00:15:51,700 --> 00:15:57,380
models. And I'm just curious now that I've got another opportunity to talk to someone at Berkeley

165
00:15:57,380 --> 00:16:04,340
having kind of put all of this together, you know, what your take is. Right. Well, first go bears

166
00:16:04,340 --> 00:16:11,780
and thank you for mentioning Berkeley. Couldn't resist doing this one. So it's very interesting

167
00:16:11,780 --> 00:16:17,780
what you're saying because first, maybe the first point that is important to mention is

168
00:16:18,740 --> 00:16:24,340
model-free works for certain things might not work as well for some other things. And for example,

169
00:16:24,340 --> 00:16:28,260
you think about safety critical systems for many years. I used to work in traffic management.

170
00:16:29,220 --> 00:16:34,100
If you think about autopilot certification, about a lot of medical devices, which are, you know,

171
00:16:34,100 --> 00:16:39,860
safety critical, well, maybe people need to think twice about, you know, forgetting about the model

172
00:16:40,580 --> 00:16:45,220
because there's real laws of physics involved and there's real certification issues there.

173
00:16:45,220 --> 00:16:51,220
And so we have embraced this model-free approach for what we do just because we have evidence that

174
00:16:51,220 --> 00:16:58,340
in many of the known cases, it already beats half a century or more of work of the modeling community.

175
00:16:59,140 --> 00:17:05,060
And we want to really point out that we use it for a very specific purpose. We are not in the

176
00:17:05,060 --> 00:17:11,860
business of doing autopilot collision avoidance, anti-crash systems, safety systems for cars.

177
00:17:12,420 --> 00:17:17,460
These systems have a lot of different degrees of certification requirements

178
00:17:17,460 --> 00:17:24,020
that come with a lot of constraints. It's unclear whether what we do would apply there and it's

179
00:17:24,020 --> 00:17:29,940
really not our job. Our job is to be able to come up with new methods that can coordinate hundreds

180
00:17:29,940 --> 00:17:35,700
of thousands of vehicles or maybe more local scales, maybe dozens of vehicles or hundreds of vehicles.

181
00:17:36,340 --> 00:17:40,580
And you could really view this as a planning tool. A planning tool in a sense in the old

182
00:17:40,580 --> 00:17:45,220
sense of the term is like you were planning train schedules or airline schedules. And if you're off

183
00:17:45,220 --> 00:17:50,900
by three minutes and you manage it properly on the ground, it's not a big deal. If your train is

184
00:17:50,900 --> 00:17:56,100
laid by 30 minutes, as long as you have the right away and you have the space on the railway, no problem.

185
00:17:57,060 --> 00:18:04,180
So here that's the same idea. It's like probably in 99% of the cases what we come up with will provide

186
00:18:04,180 --> 00:18:09,460
substantially better solutions than the state of the art. And maybe in 1% it will do something

187
00:18:09,460 --> 00:18:14,820
really strange. And because it's not safety critical, well, that's not a big deal. I mean,

188
00:18:14,820 --> 00:18:18,980
what will happen as well? Maybe there will be three cars stuck on the freeway for five minutes

189
00:18:18,980 --> 00:18:24,580
in a very strange way and we didn't understand why. But nobody died. It's a planning problem.

190
00:18:24,580 --> 00:18:28,980
And so I think the point is that, you know, there's this ongoing debate that you really mentioned

191
00:18:28,980 --> 00:18:34,580
about model base versus non-model based. Obviously both approaches have their sweet spots.

192
00:18:34,580 --> 00:18:42,900
I think the model free approaches like we're using now clearly have demonstrated a very

193
00:18:42,900 --> 00:18:48,820
disruptive nature in the industry in which we are and in the world in which we live for coordination

194
00:18:48,820 --> 00:18:55,060
of multiple vehicles. But you know, if you're doing precision chemistry or physics, we probably

195
00:18:55,060 --> 00:18:59,860
need a pretty good model of what you're doing because it's material science, because it's laws

196
00:18:59,860 --> 00:19:05,380
of physics. And there it's maybe the story is different. The second part of what you mentioned

197
00:19:05,380 --> 00:19:10,660
is also very interesting is like, well, you know, how can we live in a place where we take the best

198
00:19:10,660 --> 00:19:15,620
of both worlds? And I really think about the fact that, you know, we're not going to throw all the

199
00:19:15,620 --> 00:19:21,380
models and everything we've been doing for half a century in the trash right away. These can be

200
00:19:21,380 --> 00:19:26,660
used to accelerate machine learning in many ways. And so if you think about warm start,

201
00:19:26,660 --> 00:19:31,220
if you think about transfer learning where you learn on some specific setting and apply to

202
00:19:31,220 --> 00:19:37,060
a different setting, if you think about reward shaping and many different, you know, sub-approaches

203
00:19:37,060 --> 00:19:43,060
of making deeper enforcement learning more efficient, that's I think where model based can help.

204
00:19:43,940 --> 00:19:49,380
There's no reason to just get a deeper enforcement learning algorithm searching in the wild when

205
00:19:49,380 --> 00:19:55,220
you already have the good baseline that can be inherited from the past. So in a sense, you can view

206
00:19:55,220 --> 00:20:01,380
this as a way to accelerate the convergence of the algorithm. And that's exactly the sweet spot in

207
00:20:01,380 --> 00:20:08,980
which you want, in fact, AI to augment what the human could not finish. And so maybe, you know,

208
00:20:08,980 --> 00:20:13,300
half a century of research in coordination of traffic lights and coordination of vehicles

209
00:20:13,300 --> 00:20:20,100
and platooning and automated intersections made us come that far. And that's where it's platoon,

210
00:20:20,100 --> 00:20:26,020
that's where it's as I'm told it in a sense. And maybe the next stage is what AI brings us to.

211
00:20:26,020 --> 00:20:31,620
And so that's where I think the two can coexist quite nicely. And that's part of what we're doing

212
00:20:31,620 --> 00:20:36,100
as well as like there's no reason to start from scratch. We could start from what the human has come

213
00:20:36,100 --> 00:20:43,620
up with and let machine learning do the rest. I like that nuance in the context of reinforcement

214
00:20:43,620 --> 00:20:52,260
learning. The idea that, you know, maybe, you know, it's not worth trying to bolt these, you know,

215
00:20:52,260 --> 00:20:58,660
the model together with the learner inherently. But, you know, we can use it in these supporting

216
00:20:59,460 --> 00:21:07,860
functions like cold start, warm start, or, you know, giving hints of some sort, as well as the model

217
00:21:07,860 --> 00:21:14,180
may play a role in whatever the simulation environment is and the way that it presents the real

218
00:21:14,180 --> 00:21:21,300
world to the learning agent. Exactly. And so the second revolution that you described,

219
00:21:22,260 --> 00:21:27,780
you didn't say this explicitly, but I was hearing the theme of imitation learning,

220
00:21:27,780 --> 00:21:33,540
is that kind of the direction you're heading or something else? Well, more specifically,

221
00:21:33,540 --> 00:21:37,700
we're really interested in end-to-end pixel learning. What's the distinction between those two?

222
00:21:37,700 --> 00:21:42,740
Well, it's hard to make a general statement, but the one thing I could say is that in the context

223
00:21:42,740 --> 00:21:53,060
of traffic, what would be a holy grail to M4 is a system in which by looking at pictures,

224
00:21:53,060 --> 00:22:00,900
videos rendering, whatever it is, you can provide the same level of efficiency as by having access

225
00:22:00,900 --> 00:22:06,340
to the state space. I mean, so the previous part of the conversation, essentially, we still,

226
00:22:06,340 --> 00:22:10,900
we maybe got rid of some of the models or all of the models, but we kept the state space. We have

227
00:22:10,900 --> 00:22:18,340
access to vehicle velocity, position, and all the parameters. These almost disappear in an image.

228
00:22:18,340 --> 00:22:24,100
So if you think about a movie of traffic that either was shot from a video or from the rendering

229
00:22:24,100 --> 00:22:31,060
of a simulation software, that video, you could say implicitly contains these parameters because

230
00:22:31,060 --> 00:22:35,620
technically you could re-infer the speed, you could re-infer the position, but the point is

231
00:22:35,620 --> 00:22:40,420
they've been blended in the rendering. Or if this was a video shot from a video camera,

232
00:22:40,420 --> 00:22:45,220
well, you never had access to them in the first place. And so this end-to-end pixel learning

233
00:22:45,220 --> 00:22:53,700
to us is very important because it would almost enable us to extend or build on the very famous

234
00:22:53,700 --> 00:22:59,460
work we've seen all over the social media recently about, you know, Q learning applications for

235
00:22:59,460 --> 00:23:05,460
playing video games. I mean, the Atari games, the pong, and they were probably the first successes.

236
00:23:05,460 --> 00:23:10,820
And now we see there's a lot of progress with Mario and, you know, more and more elaborate video games.

237
00:23:11,460 --> 00:23:17,860
And so obviously, pong and Atari and all these, it's the early ages of video gaming. It's

238
00:23:17,860 --> 00:23:25,860
still pretty simple games, but if you think about traffic, traffic is not, you know, it's not the

239
00:23:25,860 --> 00:23:30,660
state of the art video gaming with a lot of levels of sophistication, decision, 3D rendering,

240
00:23:30,660 --> 00:23:35,300
and all kinds of strategic decisions. It's something which is clearly more complex than an Atari

241
00:23:35,300 --> 00:23:41,860
video game, but it's not something which is on a different scale either. And so that's where

242
00:23:41,860 --> 00:23:49,460
we see the most interesting next revolution is demonstrating that just by working directly on

243
00:23:49,460 --> 00:23:53,780
rendering of traffic, we could achieve the same performance as having access to the state space

244
00:23:53,780 --> 00:23:59,220
because then I will provide proof that, well, maybe you don't need that ubiquitous connectivity

245
00:23:59,220 --> 00:24:04,020
anymore. All you need is an image. And then if you push this even further,

246
00:24:05,460 --> 00:24:09,700
onboard all the self-driving vehicles or vehicles with high level of automation, there's obviously

247
00:24:09,700 --> 00:24:15,940
a lot of sensing and part of that sensing is video-based. And then there's this segmentation problem,

248
00:24:15,940 --> 00:24:20,260
trying to understand how to isolate pedestrians from cars, directions of movement and everything.

249
00:24:21,060 --> 00:24:26,340
That is a field that is moving super fast. That in a sense, we don't want to touch, but we would

250
00:24:26,340 --> 00:24:32,500
love to, at some point, acquire the outputs of once there is software out there or enough data

251
00:24:32,500 --> 00:24:38,100
out there so that we can recuperate all these segmented images and treat them as inputs for what

252
00:24:38,100 --> 00:24:44,260
we do. Because then we have closed the loop. Essentially, we have first demonstrated, we don't

253
00:24:44,260 --> 00:24:48,660
need the old models. Second demonstrated, we don't even need the state space, we can just work with

254
00:24:48,660 --> 00:24:55,620
the image of the state space. And third, finally, linked that with the physical hardware sensing of

255
00:24:55,620 --> 00:25:00,580
the world, which produces these images in a way that these images can be treated in real time.

256
00:25:00,580 --> 00:25:05,300
And that's why I was saying a few minutes ago that it's going to take probably five to ten years

257
00:25:05,300 --> 00:25:10,260
because there's these two revolutions I mentioned before, but that third bridge with the rest of

258
00:25:10,260 --> 00:25:15,460
the community that is doing machine vision, I mean, that's that field is far from being solved.

259
00:25:15,460 --> 00:25:22,580
I mean, there's super rapid progress, but there's still a lot of work to be done for it to become

260
00:25:22,580 --> 00:25:29,300
operational, to run online, to run onboard the platforms, to be fast enough that it can be integrated

261
00:25:29,300 --> 00:25:33,540
in a real-time traffic management system. So there's all these steps, which each of them are

262
00:25:33,540 --> 00:25:38,980
pre-challenging there. But I think what's really nice is to have this overarching vision of where

263
00:25:38,980 --> 00:25:46,500
that whole system will go within the next five to ten years. So you mentioned earlier that the models

264
00:25:46,500 --> 00:25:52,260
that you're building are not intended to be these core control systems that are controlling the

265
00:25:52,260 --> 00:26:02,260
vehicles, collision avoidance, and I took it to be a fundamental mobility. I guess I'm trying to

266
00:26:02,260 --> 00:26:07,540
get at, I also get the impression that you're not talking about kind of an offline, you know,

267
00:26:07,540 --> 00:26:14,660
traffic system that is, you know, looking at these vehicles and providing some analysis and

268
00:26:14,660 --> 00:26:20,500
telling some other system what to do. Like, you're trying to integrate this into an online system.

269
00:26:21,060 --> 00:26:26,820
What are the relationships between these two systems and how does that interface work?

270
00:26:26,820 --> 00:26:32,580
Yeah, absolutely. So maybe the first part of the question, the reason why we don't do collision

271
00:26:32,580 --> 00:26:40,100
avoidance is it's really not our job. But also, if you think about the process of control of vehicles,

272
00:26:40,100 --> 00:26:44,260
I mean, there is what's called the low-level controller acceleration, acceleration, automated

273
00:26:44,260 --> 00:26:48,260
braking, co-operative, adaptive cruise control, and all these tools that are, some of them have

274
00:26:48,260 --> 00:26:53,140
been part of our life for more than ten years. Some of them are just coming now. A lot of it is

275
00:26:53,140 --> 00:26:58,820
really based on very classical control theory, PID control, lead lag, I mean, you know, stuff that

276
00:26:58,820 --> 00:27:03,460
came from the sixties that works well, and there's no reason to change it. Of course, the most

277
00:27:03,460 --> 00:27:08,660
the more recent work of collision avoidance and, you know, trajectory planning at super short-term

278
00:27:08,660 --> 00:27:14,500
horizons to make sure that trajectories are safe. Okay, that requires a little bit more sophistication,

279
00:27:14,500 --> 00:27:21,540
both in terms of the sensing and the learning. But that's really, that's really an area for which

280
00:27:21,540 --> 00:27:28,340
the tools you need are very specific. You need very fast controllers. You need super fast sensing

281
00:27:28,340 --> 00:27:34,100
loops that can provide almost immediate detection of anti-positioning of collisions and things like

282
00:27:34,100 --> 00:27:39,060
this. So the tools for that are very different. The architecture is probably also very different

283
00:27:39,060 --> 00:27:43,380
because you need something to run onboard on the specific chip to be certified and so on and so

284
00:27:43,380 --> 00:27:53,380
forth. So that's why, in a sense, we assume that we are, that that job has been taken care of. There's

285
00:27:53,380 --> 00:27:59,060
the auto manufacturer, there's the autopilot manufacturer, whoever is in charge here. And our job

286
00:27:59,060 --> 00:28:03,700
is more of the coordination. So the analogy would be, you know, if you're running an airline

287
00:28:05,140 --> 00:28:11,220
and you're doing the scheduling of an airline, you don't really care about the speed of landing

288
00:28:11,220 --> 00:28:17,780
of an aircraft because that's going to be taken care by the mechanical crew. And there's essentially

289
00:28:17,780 --> 00:28:22,980
a controller for that. But if you're planning the whole airline, all you want is landing

290
00:28:24,020 --> 00:28:26,500
a window of two minutes the rest. That's not your problem.

291
00:28:27,540 --> 00:28:34,340
Right. I guess so maybe the question that I was getting at more directly was is the system that

292
00:28:34,340 --> 00:28:41,700
you're looking at and trying to build analogous to kind of planning, you know, at the level of the

293
00:28:41,700 --> 00:28:48,580
airline, like a centralized planning system that knows about all the planes and is trying to do

294
00:28:48,580 --> 00:28:54,020
kind of high order scheduling or is it something that is, you know, the back to this distributed

295
00:28:54,020 --> 00:28:59,220
and swarming thing that we talked about at the level of the vehicle that is kind of feeding into

296
00:28:59,220 --> 00:29:04,740
the first person navigation, but, you know, is kind of aware of these broader impacts.

297
00:29:05,380 --> 00:29:09,780
Yeah. So now the question you're asking is a really deep question and it's a question about

298
00:29:09,780 --> 00:29:14,020
what will the future of our transportation system look like and that answer will be very

299
00:29:14,020 --> 00:29:19,460
different on the place depending on the place and the, I would say, involvement that cities will

300
00:29:19,460 --> 00:29:26,580
get. So imagine a world in which maybe 5% of the vehicles are automated. You know, it doesn't

301
00:29:26,580 --> 00:29:33,220
mean that the government, the city or the company that built the vehicles can decide unilaterally

302
00:29:33,220 --> 00:29:38,580
to connect all of these, which is just pushing some code and have them do some traffic flow

303
00:29:38,580 --> 00:29:43,460
regulation, which is pushing another piece of code and turning it on. Obviously, there needs to be

304
00:29:43,460 --> 00:29:50,100
partnerships. The city needs to agree that on these 10 miles of freeways, every connected car

305
00:29:50,100 --> 00:29:56,180
from brand ABC will automatically turn a flow pacifier algorithm that smooths its traffic.

306
00:29:56,180 --> 00:30:00,500
And then every participant will have to at some point agree when maybe they buy the car or they

307
00:30:00,500 --> 00:30:04,580
turn on the car, you know, like when you're downloading an app on your iPhone or your Android,

308
00:30:04,580 --> 00:30:09,380
you click yes, yes, yes, yes, yes. In the same way when you buy the car, you might agree that at

309
00:30:09,380 --> 00:30:13,780
some point you might release the autonomy of the car to higher authority, which will do things,

310
00:30:13,780 --> 00:30:20,340
where things is smoothing traffic. So I think in the situation in which you have 5% of

311
00:30:20,340 --> 00:30:26,180
willing to participate vehicles and vehicle owners, the, you know, the institutional framework in

312
00:30:26,180 --> 00:30:31,300
which you built an online controller, real-time controller like this, that leverages all these

313
00:30:31,300 --> 00:30:36,180
vehicles. That's still a big institutional question mark. Is that going to be run by the state,

314
00:30:36,180 --> 00:30:41,300
is that going to be run by the city, by the local MPO, or by the car company, or by a third party

315
00:30:41,300 --> 00:30:46,900
that is almost like a global scheduler, like the FAA or Euro-controlled for air traffic.

316
00:30:46,900 --> 00:30:51,860
And, you know, if you push this to the extreme and you look at places in the Middle East,

317
00:30:51,860 --> 00:30:57,940
like a Neum city, they're building in the north of the kingdom of Saudi Arabia or Dubai or Abu Dhabi

318
00:30:57,940 --> 00:31:02,740
and places which are very forward looking in the way they think about their urbanization,

319
00:31:02,740 --> 00:31:06,500
because they're building cities from scratch or they're building at a rate which supersedes

320
00:31:06,500 --> 00:31:12,500
anything we've seen before. Then you could envision networks which have a sub portion that is

321
00:31:12,500 --> 00:31:18,340
fully automated, like a place where you could not go if you don't have a vehicle of a certain level

322
00:31:18,340 --> 00:31:23,620
of automation, say four or five, and within that district, there's only five pre-proved models.

323
00:31:24,180 --> 00:31:29,460
And once you enter the district, not only does it take over your routing, but it takes over

324
00:31:29,460 --> 00:31:32,900
everything, like, you know, you punch a destination, you'll figure out the route, you'll figure out

325
00:31:32,900 --> 00:31:37,780
the speed and you'll figure out how to coordinate you with the other vehicles. So that paradigm,

326
00:31:37,780 --> 00:31:42,820
where you have automation on steroids and, you know, every vehicle is automated, that's actually

327
00:31:42,820 --> 00:31:49,220
much more in reach than mixed autonomy. And that's because having vehicles avoid pedestrians,

328
00:31:49,220 --> 00:31:54,580
bikes, scooters, cows or whatever animal is running on the street, that's hard. That's something

329
00:31:54,580 --> 00:32:00,340
which is not easy to certify and to do. But having a city or a guided community or district

330
00:32:00,340 --> 00:32:05,940
or boulevard or whatever it is, where all the vehicles are automated and they have a specific

331
00:32:05,940 --> 00:32:10,180
push of the software, that's something we could do tomorrow. The technology is there, there's

332
00:32:10,180 --> 00:32:14,420
car manufacturing companies there that have enough level of automation to enforce that.

333
00:32:15,460 --> 00:32:20,260
And that's, you know, something where an online system, like I would just been discussing

334
00:32:20,260 --> 00:32:25,460
for the last few minutes, is going to change mobility entirely. I mean, the notion that, you know,

335
00:32:25,460 --> 00:32:30,820
you enter the center city, you push the destination and the rest is taken care of,

336
00:32:30,820 --> 00:32:36,500
that's what happens essentially to a certain extent with airlines. I mean, obviously there's

337
00:32:36,500 --> 00:32:43,700
ways to fly, file flight plans, there's ways you fly, but you file a flight plan and then the FA

338
00:32:43,700 --> 00:32:48,660
will maybe give you an amended flight plan. And if there's weather to have a, again, amended

339
00:32:48,660 --> 00:32:54,740
flight plan, that paradigm essentially will work in a self-driving district. And that's in reach.

340
00:32:54,740 --> 00:32:59,300
And so you can see walking from 5% where we're now to 100%.

341
00:32:59,300 --> 00:33:03,860
But there'll be different paradigms. And there'll be places which are very forward looking and

342
00:33:03,860 --> 00:33:08,580
we'll allow that. There'll be places where they will allow flow pacifiers. And there'll be places

343
00:33:08,580 --> 00:33:12,980
where they won't. And so the answer to the question really will depend on the city,

344
00:33:14,020 --> 00:33:18,820
not just the technology readiness, but also the willingness to embrace these new paradigms.

345
00:33:19,620 --> 00:33:25,620
So kind of within these, these, you know, two plus one, revolutions that you've talked about,

346
00:33:25,620 --> 00:33:33,460
what are some of the key research challenges and which in particular are the ones that you and

347
00:33:33,460 --> 00:33:43,460
your group are digging into? So there's every problem is hard. That's why it's exciting to be

348
00:33:43,460 --> 00:33:48,100
in this field right now. And let me just list a few, you know, which will be my top five of the

349
00:33:48,100 --> 00:33:53,700
moment. And if we talk again in a week, maybe there'll be different. So, you know, the first thing is

350
00:33:53,700 --> 00:34:00,900
this notion of multi agent learning. It's one thing to learn a global policy and to say every

351
00:34:00,900 --> 00:34:06,980
car of a given brand, you know, it's going to deploy the same policy. But the truth is it doesn't

352
00:34:06,980 --> 00:34:12,180
work this way. There's different types of cars. There's different types of ways people want to

353
00:34:12,180 --> 00:34:17,380
use their cars. So the notion that we can do learning multi agent learning where some are

354
00:34:17,380 --> 00:34:21,620
cooperative, some are not cooperative, that's inherently hard. And people who've been in game

355
00:34:21,620 --> 00:34:27,860
theory and non-cooperative games know this. There's all kinds of notions of sub-optimality,

356
00:34:27,860 --> 00:34:34,260
Nash equilibrium, price of unarchy, prisoners, many things like this. Well, these don't go away

357
00:34:34,260 --> 00:34:40,260
with machine learning because the uncooperative nature of the agents just make it hard. So that's one

358
00:34:40,260 --> 00:34:47,380
thing. It kind of drags me right back to, you know, this point about model free. Like, I'd love to

359
00:34:47,380 --> 00:34:54,740
be able to give the agent the hint that, hey, there are these, you know, 10 things that we know

360
00:34:54,740 --> 00:35:02,820
from game theory that may play out here. And so if you, you know, if you see one of these, you can

361
00:35:02,820 --> 00:35:09,540
kind of get a shortcut to learning. Exactly. And that's exactly the way we want to use game theory.

362
00:35:09,540 --> 00:35:17,860
By, for example, one example would be how you steer to more cooperativeness between the agents

363
00:35:17,860 --> 00:35:26,340
and how thereby, you know, more optimality and choose from that behavior. Another really

364
00:35:27,620 --> 00:35:34,980
problematic part of this work is that it needs to scale up the simulations. They're still

365
00:35:34,980 --> 00:35:39,940
quite expensive. I mean, if you're going to simulate the I 210 freeway in Los Angeles, you know,

366
00:35:39,940 --> 00:35:46,100
it's a five lane freeway to directions. Freeway lane carries 2000 vehicles an hour. So essentially,

367
00:35:46,100 --> 00:35:51,060
if you're just standing on the bridge in the middle, you've watched 10,000 vehicles go by in one hour.

368
00:35:51,060 --> 00:35:58,020
And now that freeway extends for dozens of kilometers. So creating a simulator that is able to do

369
00:35:58,020 --> 00:36:04,580
this efficiently and being able to learn over that simulator efficiently is very hard. So if you're

370
00:36:04,580 --> 00:36:09,540
running simulations with, say, a hundred thousand vehicles and you're trying to learn over it,

371
00:36:09,540 --> 00:36:13,620
you probably don't need to re-simulate the hundred thousand vehicles. You're probably going to

372
00:36:13,620 --> 00:36:18,900
learn over 1000 vehicles or hybrid vehicles that are actually key to what's happening there.

373
00:36:19,540 --> 00:36:26,100
But the process of it's people call this learning how to learn. So it's like there's this thing in

374
00:36:26,100 --> 00:36:30,340
supervised learning where, you know, which images should you train on or what is the training data

375
00:36:30,340 --> 00:36:35,220
you should select to train. That's a completely open problem in traffic. It's like, is there a

376
00:36:35,220 --> 00:36:41,140
process by which you could determine how should you learn to learn more efficiently given that

377
00:36:41,140 --> 00:36:47,140
probably 95% of what you're simulating there is useless. And that's a whole area of

378
00:36:48,900 --> 00:36:52,980
meta-learning, active learning, curriculum learning, all of these types of things.

379
00:36:52,980 --> 00:36:56,660
And we've not even scratched the surface there. Like when I say we is like our group,

380
00:36:56,660 --> 00:37:00,980
that's not, I mean, we're not there yet. Just because we have so many other problems,

381
00:37:00,980 --> 00:37:08,180
we need to solve first. But clearly, once people start to do optimization of traffic and mobility

382
00:37:08,180 --> 00:37:13,700
at the scale of a city, that's going to be one of the big elephants in the room if we want to

383
00:37:13,700 --> 00:37:21,860
achieve scalability ultimately. And so that's another really big one. The third one is this end-to-end

384
00:37:21,860 --> 00:37:27,460
pixel learning right now seems in reach. But I think we've again just scratched the surface. I mean,

385
00:37:27,460 --> 00:37:32,740
you know, we've done some moderately difficult cases. Just like people with video games,

386
00:37:32,740 --> 00:37:37,940
they've done pong, they've done Mario, they've probably done a few others. So, you know, how do we

387
00:37:37,940 --> 00:37:42,900
make it work for real? How do we make it work for something which has, you know, hundreds of thousands

388
00:37:42,900 --> 00:37:51,300
of vehicles? So that's another big challenge that make it hard. So I think what's exciting is that

389
00:37:51,300 --> 00:37:57,300
the rate at which innovations happen in AI is so high that there are a lot of tools that appear

390
00:37:58,660 --> 00:38:04,020
quite often that, you know, weren't not really obvious before, like this pixel learning just

391
00:38:04,020 --> 00:38:10,180
had major breakthroughs. And so I think there's a hope that over the next couple of years we'll see

392
00:38:10,180 --> 00:38:14,980
things come from fields we didn't even think would be relevant that actually matter for what we do.

393
00:38:16,020 --> 00:38:21,220
And so we're far from being done, but things are moving so rapidly that I think the progress

394
00:38:21,220 --> 00:38:28,900
rate is quite quite amazing. I feel like we could have spent, you know, entire hours and podcasts

395
00:38:28,900 --> 00:38:35,140
on any of these topics. And so we've just kind of scratched the surface here. Any

396
00:38:35,940 --> 00:38:41,220
suggestions or pointers or words of wisdom for folks that are intrigued by this and want to

397
00:38:41,220 --> 00:38:46,820
dig in deeper? Well, I think from a technical standpoint, we've covered a lot of ground, but I

398
00:38:46,820 --> 00:38:51,940
think the maybe higher level point of wisdom that I would really like to convey is that this

399
00:38:51,940 --> 00:38:58,980
paradigm really can only work if we have cooperation between very different animals. And these

400
00:38:58,980 --> 00:39:04,100
animals include obviously academia or tech or research wherever that happens, whether it's in

401
00:39:04,100 --> 00:39:09,540
the private sector or the public sector, that's us. It involves the car manufacturing industry

402
00:39:09,540 --> 00:39:16,660
because at the end, someone has to push a new release of the autopilot software to make it work

403
00:39:16,660 --> 00:39:21,940
in the field. And to make it work in the field means on the freeway, not in a content test facility

404
00:39:21,940 --> 00:39:28,500
like for real. And the third animal is the government, whether it's federal regulations, whether

405
00:39:28,500 --> 00:39:35,540
state regulation, MPO, city ordinance, wherever it is, there needs to be buy-in so that first it's

406
00:39:35,540 --> 00:39:40,660
actually agreeable to the city to operate this way. There's mobility on demand and cars are

407
00:39:40,660 --> 00:39:46,820
cooperative for 10 miles where the city takes over the automation or something. So it's hard,

408
00:39:46,820 --> 00:39:50,740
because you have academics like us that are pushing new paradigms. You have the private sector,

409
00:39:50,740 --> 00:39:55,380
which has its own constraint. Obviously, they have to go through certification. It's got to be

410
00:39:55,380 --> 00:40:00,580
aligned with their market strategy. Any of the government, which essentially has to regulate

411
00:40:00,580 --> 00:40:05,860
and make sure that we don't kill people and that things are fair and equitable. So the word of

412
00:40:05,860 --> 00:40:11,540
wisdom is that we need to create a community so that these three types of animals start talking

413
00:40:11,540 --> 00:40:17,380
about these things. AI is changing cities, is changing a lot of different urban problems.

414
00:40:17,380 --> 00:40:24,260
And mostly in good ways. We've seen some cases of TNCs and mobility test demand companies,

415
00:40:24,260 --> 00:40:30,500
right-hailing companies or Airbnb styles of this world, how it can be complicated for a city to

416
00:40:30,500 --> 00:40:37,540
regulate over these new technologies and services. And the same is true for this mixed autonomy.

417
00:40:37,540 --> 00:40:42,740
And that's why it's very important to get that conversation started early so that all protagonists

418
00:40:42,740 --> 00:40:49,060
are ready for the time when it becomes a technological reality. And is this conversation happening

419
00:40:49,060 --> 00:40:59,220
today in some centralized place or is it just this highly local set of conversations that are

420
00:40:59,220 --> 00:41:06,180
happening? How can folks plug into whatever or wherever is the best place to kind of tap into

421
00:41:06,180 --> 00:41:11,940
this conversation now? Yes, this is a super interesting question because there is no institutional

422
00:41:12,500 --> 00:41:17,300
place or way to have these conversations. I think what's very encouraging is that you see a lot

423
00:41:17,300 --> 00:41:21,380
of forums where these conversations happen, the transportation research board in Washington every

424
00:41:21,380 --> 00:41:28,820
year. The IEEE intelligent transportation systems conference every year from the IEEE some

425
00:41:28,820 --> 00:41:38,660
specific state driven programs like the Institute of Transportation Studies forums and workshop

426
00:41:38,660 --> 00:41:44,820
in California, ITS America and the ITS World Congress and so on and so forth. But the truth is these

427
00:41:44,820 --> 00:41:51,140
conversations are still I would say boutique sessions in these venues or special sessions in

428
00:41:51,140 --> 00:41:58,260
these conferences. But there's not been a forum, like a worldwide forum on how are we going to

429
00:41:58,260 --> 00:42:04,820
bring this to reality. And I think it will probably emerge. I think we all have a responsibility

430
00:42:04,820 --> 00:42:11,780
to do this. The difficulty is that the AI community is fascinated with research and technological

431
00:42:11,780 --> 00:42:17,220
advances and that's what we should be doing. And obviously public agencies have to deal with

432
00:42:17,220 --> 00:42:21,780
public infrastructure and policy and that's what they've been elected for or that's what they've

433
00:42:21,780 --> 00:42:27,700
been hired for. And the private sector is driven by their products. And so obviously there is

434
00:42:27,700 --> 00:42:32,260
common ground and there's common interest, but these are three orthogonal directions in a 3D

435
00:42:32,260 --> 00:42:39,300
vector space. And so it's hard to institutionalize this until there is a real need for it. And

436
00:42:39,300 --> 00:42:45,140
anticipation is maybe sometimes not the forte of these three actors that are working on different

437
00:42:45,140 --> 00:42:53,140
time scales. It does sound like a massively complex game theory problem. Totally is with three

438
00:42:53,140 --> 00:42:59,460
players that want to be cooperative. Well, Alex, thanks so much for taking the time to chat with us

439
00:42:59,460 --> 00:43:05,860
about this. It's a super interesting conversation and I look forward to kind of keeping tabs on the

440
00:43:05,860 --> 00:43:10,100
field as it evolves. Thank you so much. It was really fun conversation. Really, I appreciate

441
00:43:10,100 --> 00:43:18,420
the time this morning. Thank you. Thank you. All right, everyone. That's our show for today.

442
00:43:18,420 --> 00:43:26,180
For more information about today's show, visit twomelai.com. Thanks so much for listening and see you

443
00:43:26,180 --> 00:43:36,180
next week at Twomelcon.

