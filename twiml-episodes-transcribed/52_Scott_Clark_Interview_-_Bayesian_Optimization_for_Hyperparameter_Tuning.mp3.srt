1
00:00:00,000 --> 00:00:15,920
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

2
00:00:15,920 --> 00:00:20,880
people doing interesting things in machine learning and artificial intelligence.

3
00:00:20,880 --> 00:00:23,880
I'm your host Sam Charrington.

4
00:00:23,880 --> 00:00:27,880
This past week, the conference finally came to me.

5
00:00:27,880 --> 00:00:33,080
Over the weekend, the great and not-so-little anymore strange loop conference graced downtown

6
00:00:33,080 --> 00:00:34,400
St. Louis.

7
00:00:34,400 --> 00:00:40,240
I got a chance to meet with a bunch of the speakers, including Sumeet Chintala, a Facebook,

8
00:00:40,240 --> 00:00:44,160
Allison Parish of NYU, and Sam Richie of Stripe.

9
00:00:44,160 --> 00:00:50,120
I had a ton of fun and I can't wait to share some of these great interviews from the conference.

10
00:00:50,120 --> 00:00:54,880
Before we move on to the show, speaking of conferences, we're going into conference

11
00:00:54,880 --> 00:00:57,560
giveaway mode for a few days.

12
00:00:57,560 --> 00:01:02,800
Next week, October 10th through 11th, I'll be in Montreal for the rework deep learning

13
00:01:02,800 --> 00:01:08,040
summit and one lucky listener will get a chance to join me there.

14
00:01:08,040 --> 00:01:10,200
Entering the contest is simple.

15
00:01:10,200 --> 00:01:17,480
Just head on over to twimlai.com slash dl summit and choose any of up to four methods

16
00:01:17,480 --> 00:01:19,680
of entry and voila.

17
00:01:19,680 --> 00:01:25,280
While there are only four ways to enter this time around, by sharing the contest with friends,

18
00:01:25,280 --> 00:01:29,280
each participant can get up to 14 entries.

19
00:01:29,280 --> 00:01:34,680
This giveaway will only be open until noon central time on Wednesday the 4th, so make

20
00:01:34,680 --> 00:01:37,480
sure you get your entries and ASAP.

21
00:01:37,480 --> 00:01:38,480
Good luck.

22
00:01:38,480 --> 00:01:43,720
This week, I'd like to introduce a new sponsor, Nexosis, and thank them for sponsoring

23
00:01:43,720 --> 00:01:45,560
this week's show.

24
00:01:45,560 --> 00:01:50,760
Nexosis is a company of developers focused on providing easy access to machine learning.

25
00:01:50,760 --> 00:01:55,760
The Nexosis machine learning API meet to developers where they're at, regardless of

26
00:01:55,760 --> 00:02:01,200
their mastery of data science, so they can start coding up predictive applications today

27
00:02:01,200 --> 00:02:03,760
and their preferred programming language.

28
00:02:03,760 --> 00:02:08,520
It's as simple as loading your data and selecting the type of problem you want to solve.

29
00:02:08,520 --> 00:02:12,960
Their automated platform trains and selects the best model fit for your data and then

30
00:02:12,960 --> 00:02:15,040
outputs predictions.

31
00:02:15,040 --> 00:02:20,200
Get your free API key and discover how to start leveraging machine learning in your next

32
00:02:20,200 --> 00:02:24,320
project at nexosis.com slash twimmel.

33
00:02:24,320 --> 00:02:30,880
That's n-e-x-o-s-i-s.com slash T-w-i-m-l.

34
00:02:30,880 --> 00:02:34,880
Head on over, check them out, and be sure to let them know who sent you.

35
00:02:34,880 --> 00:02:41,680
Finally, before we dive into the show, a reminder about the upcoming twimmel online meetup.

36
00:02:41,680 --> 00:02:48,120
On Wednesday, October 18th, at 3pm Pacific time, we'll discuss the paper visual attribute

37
00:02:48,120 --> 00:02:54,320
transfer through deep image analogy by Jing Liyao and others from Microsoft Research.

38
00:02:54,320 --> 00:02:57,000
The discussion will be led by Duncan Stothers.

39
00:02:57,000 --> 00:02:58,520
Thanks, Duncan.

40
00:02:58,520 --> 00:03:02,760
To join the meetup or to catch up on what you missed from the first two meetups, visit

41
00:03:02,760 --> 00:03:05,720
twimmelai.com slash meetup.

42
00:03:05,720 --> 00:03:10,720
As you all know, a few weeks ago, I spent some time in San Francisco at the Artificial

43
00:03:10,720 --> 00:03:14,560
Intelligence Conference by O'Reilly and Intel Nirvana.

44
00:03:14,560 --> 00:03:20,120
While I was there, I had just enough time to sneak away and catch up with Scott Clark,

45
00:03:20,120 --> 00:03:25,680
co-founder and CEO of Sigopt, a company whose software is focused on automatically tuning

46
00:03:25,680 --> 00:03:29,880
your model's parameters through Bayesian optimization.

47
00:03:29,880 --> 00:03:35,400
We dive pretty deeply into how they do that through the course of this discussion.

48
00:03:35,400 --> 00:03:40,440
I had a great time and learned a ton, but before warned, this is definitely a nerd alert

49
00:03:40,440 --> 00:03:41,440
show.

50
00:03:41,440 --> 00:03:45,360
And so without further ado, on to the show.

51
00:03:45,360 --> 00:03:55,480
Hey, everyone, I am here with Scott Clark.

52
00:03:55,480 --> 00:04:03,440
Scott is the founder and CEO of a company called Sigopt and he was gracious enough to spend

53
00:04:03,440 --> 00:04:09,000
some time with me this morning to talk about his background, the company, and the topic

54
00:04:09,000 --> 00:04:13,800
that I am very interested in learning more about Bayesian optimization.

55
00:04:13,800 --> 00:04:16,400
We're sitting in his office in San Francisco.

56
00:04:16,400 --> 00:04:22,280
I happen to be in town for the AI conference and I'm really looking forward to this interview.

57
00:04:22,280 --> 00:04:23,280
So welcome, Scott.

58
00:04:23,280 --> 00:04:25,760
Thank you so much for really looking forward to it as well.

59
00:04:25,760 --> 00:04:26,760
Awesome.

60
00:04:26,760 --> 00:04:27,760
Awesome.

61
00:04:27,760 --> 00:04:31,680
So let's just jump right in and have you tell us a little bit about your background and

62
00:04:31,680 --> 00:04:34,040
how you got involved in machine learning.

63
00:04:34,040 --> 00:04:35,040
Definitely.

64
00:04:35,040 --> 00:04:38,400
I first got really excited about this while I was in grad school.

65
00:04:38,400 --> 00:04:42,800
So I was pursuing a PhD in applied math at Cornell University.

66
00:04:42,800 --> 00:04:43,800
Go upstate New York.

67
00:04:43,800 --> 00:04:44,800
Yeah, exactly.

68
00:04:44,800 --> 00:04:48,720
Cornell is great because there's not a lot to do and it's super bad weather all the time.

69
00:04:48,720 --> 00:04:52,040
So you just focus on studying and you graduate as soon as possible.

70
00:04:52,040 --> 00:04:56,120
I went to RPI undergrad, also upstate New York and had the same experience.

71
00:04:56,120 --> 00:04:57,120
Nice.

72
00:04:57,120 --> 00:04:58,120
Nice.

73
00:04:58,120 --> 00:05:00,280
I highly recommend it for efficient degrees.

74
00:05:00,280 --> 00:05:07,120
RPI had the added advantage of it was hugely skewed towards Nell students and so they

75
00:05:07,120 --> 00:05:11,560
were even less distractions and that's excellent.

76
00:05:11,560 --> 00:05:15,960
So basically I was applying math to a variety of different things.

77
00:05:15,960 --> 00:05:18,960
One of the focuses of my degree was bioinformatics.

78
00:05:18,960 --> 00:05:22,880
So I had a fellowship from the Department of Energy.

79
00:05:22,880 --> 00:05:27,560
So the problem I was trying to attack was genome assembly and you can think of this as

80
00:05:27,560 --> 00:05:30,360
trying to solve a jigsaw puzzle on a supercomputer.

81
00:05:30,360 --> 00:05:34,920
So basically we have a bunch of DNA and we have to reassemble it into some genome and the

82
00:05:34,920 --> 00:05:39,680
Department of Energy cares about this because if you know the genome it might be a path towards

83
00:05:39,680 --> 00:05:42,400
more efficient biofuels or something like that.

84
00:05:42,400 --> 00:05:46,640
The problem was lots of tunable knobs and levers with these various systems and we had

85
00:05:46,640 --> 00:05:51,040
to configure those to get the best possible performance out of them.

86
00:05:51,040 --> 00:05:54,200
And you were the grunt in grad school exactly to tune all these levers.

87
00:05:54,200 --> 00:05:57,200
We jokingly call this graduate student descent.

88
00:05:57,200 --> 00:06:01,120
The idea being we just need to get to the best configuration and it doesn't matter how

89
00:06:01,120 --> 00:06:02,120
you get there.

90
00:06:02,120 --> 00:06:03,120
Yeah.

91
00:06:03,120 --> 00:06:06,120
There's a good way to attack this problem and a lot of get your field value for your

92
00:06:06,120 --> 00:06:07,120
paper.

93
00:06:07,120 --> 00:06:08,120
Something like that.

94
00:06:08,120 --> 00:06:09,120
Yeah.

95
00:06:09,120 --> 00:06:12,120
I mean academic incentives are a completely different topic.

96
00:06:12,120 --> 00:06:13,120
Yeah.

97
00:06:13,120 --> 00:06:15,120
I just thought I tossed it in there.

98
00:06:15,120 --> 00:06:16,120
Fair enough.

99
00:06:16,120 --> 00:06:20,040
But the idea is there's a couple standard ways people go about attacking a problem like

100
00:06:20,040 --> 00:06:21,040
this.

101
00:06:21,040 --> 00:06:22,520
You can try to brute force the problem.

102
00:06:22,520 --> 00:06:28,000
So just lay down a grade of all possible options for every configuration and try them all.

103
00:06:28,000 --> 00:06:32,160
This was intractable for us because it took 24 hours on a government supercomputer.

104
00:06:32,160 --> 00:06:36,960
Every single time we wanted to try a single configuration, randomized search has become

105
00:06:36,960 --> 00:06:40,960
very popular, especially in the deep learning literature for trying to come up with different

106
00:06:40,960 --> 00:06:45,160
configurations of hyper parameters and architectures and things like that.

107
00:06:45,160 --> 00:06:49,600
Turns out much more efficient than grid search, but this is still like trying to climb a mountain

108
00:06:49,600 --> 00:06:52,960
by jumping out of an airplane and hoping you land at the peak.

109
00:06:52,960 --> 00:06:56,800
Not necessarily the most intuitive way to go about optimizing something.

110
00:06:56,800 --> 00:07:01,640
A lot of the different algorithms we use randomized initialization.

111
00:07:01,640 --> 00:07:03,440
That's different from randomized search.

112
00:07:03,440 --> 00:07:04,440
Correct.

113
00:07:04,440 --> 00:07:08,040
So when you're building a neural network, you might use randomized initialization on the

114
00:07:08,040 --> 00:07:13,040
individual weights and then use some sort of secastic gradient descent optimizer within

115
00:07:13,040 --> 00:07:14,720
that underlying system.

116
00:07:14,720 --> 00:07:19,040
This is more of a black box parameter optimization problem I'm talking about where we're not

117
00:07:19,040 --> 00:07:24,160
introspecting the underlying model, but just tuning the higher level configuration parameters.

118
00:07:24,160 --> 00:07:28,640
So some of those configuration parameters might have to do with that random initialization

119
00:07:28,640 --> 00:07:32,160
or the secastic gradient descent parameters or something like that.

120
00:07:32,160 --> 00:07:37,360
You definitely need to be able to bootstrap efficiently from no data, but doing purely

121
00:07:37,360 --> 00:07:42,560
randomized search is not necessarily the most efficient thing you can do.

122
00:07:42,560 --> 00:07:47,200
So maybe before we move on, since I think we're going to be spending a lot of time talking

123
00:07:47,200 --> 00:07:54,200
about hyper parameter optimization here, maybe dig into grid search a little bit more so

124
00:07:54,200 --> 00:07:59,080
that we're all starting from the same place.

125
00:07:59,080 --> 00:08:03,120
Basically, as I understand it, the idea is you've got some set of hyper parameters, those

126
00:08:03,120 --> 00:08:13,040
form an n-dimensional, n-dimensional, not a cube, but a lattice, thank you.

127
00:08:13,040 --> 00:08:17,920
Grid search is basically systematically going from point to point, like if you were searching

128
00:08:17,920 --> 00:08:23,520
for someone in a forest, you'd form a grid and attack all those points.

129
00:08:23,520 --> 00:08:28,560
And random is you're basically picking points, and the idea is statistically, if you pick

130
00:08:28,560 --> 00:08:34,280
enough points, you'll get some level of coverage of all of the combinations of these hyper

131
00:08:34,280 --> 00:08:35,280
parameters.

132
00:08:35,280 --> 00:08:36,280
Exactly.

133
00:08:36,280 --> 00:08:39,200
So back to your searching and a forest analogy, this is jumping out of a helicopter and

134
00:08:39,200 --> 00:08:42,760
seeing if the person's there, getting back in and like continuing to do that over and

135
00:08:42,760 --> 00:08:43,760
over again.

136
00:08:43,760 --> 00:08:44,760
That's random search.

137
00:08:44,760 --> 00:08:45,760
That's randomized search.

138
00:08:45,760 --> 00:08:47,760
Another popular method is just manual today.

139
00:08:47,760 --> 00:08:49,880
So trying to do this in your head.

140
00:08:49,880 --> 00:08:53,920
And in the forest example, when there's only two dimensions, you might have a lot of intuition

141
00:08:53,920 --> 00:08:57,800
about maybe the person's going to be up on a hill or something like that, it can actually

142
00:08:57,800 --> 00:08:59,280
be somewhat effective.

143
00:08:59,280 --> 00:09:03,280
But once you start to look at 20-dimensional problems, a lot of human intuition starts

144
00:09:03,280 --> 00:09:07,880
to break down, and you might not be able to have some of that expert knowledge in the

145
00:09:07,880 --> 00:09:13,320
searching for a human and a forest setting, how to set stochastic gradient descent parameters

146
00:09:13,320 --> 00:09:17,320
and number of hidden layers and learning rates, and all these sorts of things, it starts

147
00:09:17,320 --> 00:09:19,400
to get very convoluted very quickly.

148
00:09:19,400 --> 00:09:25,280
And so manual search, well, it can be effective to kind of resolve very localized solutions

149
00:09:25,280 --> 00:09:28,040
is not a great global optimization strategy.

150
00:09:28,040 --> 00:09:34,720
And for the typical model that you are seeing, like, how many hyperparameters are there?

151
00:09:34,720 --> 00:09:37,080
Yeah, so it really depends on the underlying system.

152
00:09:37,080 --> 00:09:40,880
So something simple like a random forest might only have a couple that you care about,

153
00:09:40,880 --> 00:09:45,240
number of trees, number of samples needed to split a node, something like that.

154
00:09:45,240 --> 00:09:49,320
As you start to advance, maybe integrate in boosting methods and also you have learning rates

155
00:09:49,320 --> 00:09:51,600
and other sorts of parameters you can tune.

156
00:09:51,600 --> 00:09:55,480
But once you get into the deep learning and reinforcement learning regimes, there can

157
00:09:55,480 --> 00:10:00,760
be dozens of individual parameters, especially if you start to think of the system as a whole.

158
00:10:00,760 --> 00:10:06,160
So when you're doing an NLP or computer vision type problem, all of a sudden you have different

159
00:10:06,160 --> 00:10:09,240
ways you can parameterize the data as well.

160
00:10:09,240 --> 00:10:14,480
And so by looking at that system and its entirety, all of a sudden there can be dozens of parameters

161
00:10:14,480 --> 00:10:19,200
and something that grows exponentially like a grid search is completely intractable.

162
00:10:19,200 --> 00:10:25,200
The human manual intuition starts to break down and randomize search is just too slow to

163
00:10:25,200 --> 00:10:26,960
luck into a reasonable solution.

164
00:10:26,960 --> 00:10:27,960
Okay.

165
00:10:27,960 --> 00:10:34,720
Can you give an example of in the case of NLP how the way you look at the data set changes

166
00:10:34,720 --> 00:10:36,760
and increases your parameter space?

167
00:10:36,760 --> 00:10:37,760
Yeah.

168
00:10:37,760 --> 00:10:39,560
So how you tokenize the text itself.

169
00:10:39,560 --> 00:10:42,760
So do you look at different in-gram sizes?

170
00:10:42,760 --> 00:10:47,160
The idea being do you look at one word at a time, pairs of words, triples words, do you

171
00:10:47,160 --> 00:10:51,480
maybe do different thresholds for the frequency within the corpus itself?

172
00:10:51,480 --> 00:10:56,800
So maybe cut out words like the because they're too common and then also cut out words like

173
00:10:56,800 --> 00:10:59,240
bananza because they're too rare.

174
00:10:59,240 --> 00:11:04,520
And so you can kind of change the actual feature representation itself before you even feed

175
00:11:04,520 --> 00:11:06,240
it into the machine learning algorithm.

176
00:11:06,240 --> 00:11:08,000
But these are all tunable moms and lovers.

177
00:11:08,000 --> 00:11:09,000
Got it.

178
00:11:09,000 --> 00:11:10,000
Okay.

179
00:11:10,000 --> 00:11:15,960
So you were stuck in grad school like again, twiddling these lovers and you know as all

180
00:11:15,960 --> 00:11:18,920
innovation happened, you thought there's got to be a better way.

181
00:11:18,920 --> 00:11:19,920
Exactly.

182
00:11:19,920 --> 00:11:23,160
So went around the department and found that this was a very common problem.

183
00:11:23,160 --> 00:11:27,000
People in machine learning, people in financial engineering, like everybody were building

184
00:11:27,000 --> 00:11:30,600
these these expert systems, but they needed to be fine tuned.

185
00:11:30,600 --> 00:11:33,400
But everybody was using these kind of standard techniques.

186
00:11:33,400 --> 00:11:37,840
So expanded my search outside the department and eventually found who would become my PhD

187
00:11:37,840 --> 00:11:40,680
advisor in the operations research field.

188
00:11:40,680 --> 00:11:43,280
So they've been attacking this problem for decades.

189
00:11:43,280 --> 00:11:47,000
If you have a time consuming and expensive disamples system, how do you most efficiently

190
00:11:47,000 --> 00:11:48,760
get to the best configuration?

191
00:11:48,760 --> 00:11:52,720
So this crops up if you're tuning a particle accelerator, it crops up if you're trying

192
00:11:52,720 --> 00:11:56,720
to decide where to place a gold mine, which is where some of the original research came

193
00:11:56,720 --> 00:12:01,800
from in the 50s, but it maps extremely well on to a wide variety of computational problems.

194
00:12:01,800 --> 00:12:02,800
Okay.

195
00:12:02,800 --> 00:12:05,520
You have some input that comes in, some output that you care about.

196
00:12:05,520 --> 00:12:09,920
How do you get to the best output in as few input attempts as possible?

197
00:12:09,920 --> 00:12:12,520
So I started working in this field of optimal learning.

198
00:12:12,520 --> 00:12:17,280
This is called an operations research, or sequential model based optimization or Bayesian

199
00:12:17,280 --> 00:12:18,280
optimization.

200
00:12:18,280 --> 00:12:22,160
A lot of fields have different names for it, but the idea is, how do you do this as efficiently

201
00:12:22,160 --> 00:12:23,160
as you can?

202
00:12:23,160 --> 00:12:27,760
Ended up pivoting my PhD towards working on this problem, ended up being one of the chapters

203
00:12:27,760 --> 00:12:29,560
of my thesis.

204
00:12:29,560 --> 00:12:34,200
And after graduating, I realized that a lot of different people in a lot of different industries

205
00:12:34,200 --> 00:12:35,200
had this issue.

206
00:12:35,200 --> 00:12:39,720
So I spent two and a half years at Yelp working on their advertising team, applying these

207
00:12:39,720 --> 00:12:43,560
same techniques to help do more perform into advertising.

208
00:12:43,560 --> 00:12:44,560
Okay.

209
00:12:44,560 --> 00:12:48,080
The idea being, if you think about it mathematically, an advertising system is very similar

210
00:12:48,080 --> 00:12:52,640
to a genome assembly system, insofar as a lot of experts spend a lot of time building

211
00:12:52,640 --> 00:12:53,640
something.

212
00:12:53,640 --> 00:12:56,520
There's a bunch of inputs, and there's an output you care about.

213
00:12:56,520 --> 00:12:59,480
In genome assembly, it's better papers because you get a better genome.

214
00:12:59,480 --> 00:13:02,280
In advertising system, a bunch of money comes out the other end.

215
00:13:02,280 --> 00:13:06,000
I mean, clearly, there are tons of problems that fit the general exactly.

216
00:13:06,000 --> 00:13:07,000
Exactly.

217
00:13:07,000 --> 00:13:10,040
And so you started Sigopt.

218
00:13:10,040 --> 00:13:11,920
How long have you been at it here?

219
00:13:11,920 --> 00:13:12,920
Yeah.

220
00:13:12,920 --> 00:13:16,760
So immediately after Yelp started Sigopt about three years ago, went through a Y Combinator

221
00:13:16,760 --> 00:13:20,200
and Winter 15, raised a few rounds of funding.

222
00:13:20,200 --> 00:13:23,040
Most recently, a series A led by Andreessen Horowitz.

223
00:13:23,040 --> 00:13:25,120
And now we're 16 people in San Francisco.

224
00:13:25,120 --> 00:13:26,120
Perfect.

225
00:13:26,120 --> 00:13:28,880
That sounded like a steamboat.

226
00:13:28,880 --> 00:13:35,240
I swear it's not normally this bad.

227
00:13:35,240 --> 00:13:41,280
And so I guess I want to kind of jump into the main crux of this interview, which is

228
00:13:41,280 --> 00:13:43,840
around this Bayesian optimization.

229
00:13:43,840 --> 00:13:49,000
Walk me through the way, folks like Pedro Domingo also talk about the Bayesians as this

230
00:13:49,000 --> 00:13:57,960
one tribe within machine learning, and as opposed to others, walk me through, I guess

231
00:13:57,960 --> 00:14:02,720
what I'm trying to get at is I've had a couple of conversations with folks about different

232
00:14:02,720 --> 00:14:11,160
aspects of Bayesian program learning and other things, but I feel like there's still

233
00:14:11,160 --> 00:14:17,960
some ethos of what it means to be Bayesian and think about things from that perspective

234
00:14:17,960 --> 00:14:20,400
that we haven't fully captured on the podcast.

235
00:14:20,400 --> 00:14:25,400
So if we can start there and then get to the optimization, that would be pretty cool.

236
00:14:25,400 --> 00:14:26,400
Definitely.

237
00:14:26,400 --> 00:14:31,320
So the way a lot of those other techniques work like grid search or random search is there's

238
00:14:31,320 --> 00:14:32,960
no learning happening.

239
00:14:32,960 --> 00:14:36,640
And I think that's one of the major differences between the Bayesian optimization approach

240
00:14:36,640 --> 00:14:40,720
or the Bayesian approach to this problem and some of those more traditional techniques.

241
00:14:40,720 --> 00:14:46,040
The idea being every single time I evaluate this underlying machine learning pipeline

242
00:14:46,040 --> 00:14:49,600
or whatever it is, it's extremely time consuming and expensive.

243
00:14:49,600 --> 00:14:54,240
And I want to be able to leverage that data to decide what to do next.

244
00:14:54,240 --> 00:14:59,320
And so a lot of the Bayesian methods rely on this concept of trading off exploration versus

245
00:14:59,320 --> 00:15:00,920
exploitation.

246
00:15:00,920 --> 00:15:05,480
So we want to be able to learn as much as we can about that underlying response surface,

247
00:15:05,480 --> 00:15:10,720
how it varies, how all the parameters interact over what length scales, how certain we are

248
00:15:10,720 --> 00:15:17,360
about specific configurations and how well they'll perform and learn about that while

249
00:15:17,360 --> 00:15:22,200
also exploiting localized information to drive you to better results.

250
00:15:22,200 --> 00:15:27,320
And by constantly trading off these two facets, we're able to exponentially faster than

251
00:15:27,320 --> 00:15:31,440
something like an exhaustive grid search, arrive at better solutions.

252
00:15:31,440 --> 00:15:35,920
And the main difference here is the fact that we're learning from the past and using that

253
00:15:35,920 --> 00:15:38,600
to influence what we do in the future.

254
00:15:38,600 --> 00:15:43,160
And now when I think about this kind of explore, explore exploit trade off one of the things

255
00:15:43,160 --> 00:15:46,440
that jumps to mind for me is reinforcement learning.

256
00:15:46,440 --> 00:15:53,400
Is that coming in play here or maybe less so because the environment itself, the problem

257
00:15:53,400 --> 00:15:57,560
itself doesn't necessarily change in response to the inputs?

258
00:15:57,560 --> 00:16:00,840
So the underlying system can change pretty dramatically.

259
00:16:00,840 --> 00:16:06,800
So you can think of this as this larger system that fits around any underlying pipeline.

260
00:16:06,800 --> 00:16:09,280
That could be a reinforcement learning pipeline.

261
00:16:09,280 --> 00:16:12,840
It could be just a standard deep learning or it could be something as simple as a logistic

262
00:16:12,840 --> 00:16:15,080
regression or a random forest.

263
00:16:15,080 --> 00:16:19,840
And you can think about the fact that every single time we try a new configuration, we

264
00:16:19,840 --> 00:16:22,960
want to observe some sort of output at the end that the user defines.

265
00:16:22,960 --> 00:16:27,520
It could be something simple like accuracy, could be the sharp ratio of a back test of

266
00:16:27,520 --> 00:16:30,280
an algorithmic trading strategy or whatever it may be.

267
00:16:30,280 --> 00:16:33,800
And so we use that to kind of influence what we do next.

268
00:16:33,800 --> 00:16:38,760
You can think of this as this kind of reinforcement loop as a whole over that entire system.

269
00:16:38,760 --> 00:16:41,320
But we're agnostic to what the underlying method is.

270
00:16:41,320 --> 00:16:49,280
And so the underlying method could be reinforcement learning or any number of other things.

271
00:16:49,280 --> 00:16:55,400
But it also sounds, I guess what I was asking was, are you or could you do reinforcement

272
00:16:55,400 --> 00:17:02,280
learning at the top level to optimize the thing that you're optimizing, which could be reinforcement

273
00:17:02,280 --> 00:17:03,280
learning as well?

274
00:17:03,280 --> 00:17:08,400
So reinforcement learning on the hyperparameter space as opposed to the actual model itself?

275
00:17:08,400 --> 00:17:09,560
Yeah, definitely.

276
00:17:09,560 --> 00:17:12,520
And there's a lot of different approaches to this underlying problem.

277
00:17:12,520 --> 00:17:16,080
There's a lot of very cool papers that are all the top machine learning conferences

278
00:17:16,080 --> 00:17:17,480
for attacking this.

279
00:17:17,480 --> 00:17:23,480
The way that we attack it is via this consequential model based optimization.

280
00:17:23,480 --> 00:17:25,520
And this is a very Bayesian approach.

281
00:17:25,520 --> 00:17:30,880
And the idea is we're sequentially learning as much as we can about this underlying system.

282
00:17:30,880 --> 00:17:35,640
So once again, using the history to decide what to do in the future, it's model based

283
00:17:35,640 --> 00:17:40,440
in the sense that we're building up different surrogate models for how we think individual

284
00:17:40,440 --> 00:17:46,200
configurations are going to respond when we actually sample the underlying system.

285
00:17:46,200 --> 00:17:51,080
We can use various different things here like Gaussian processes or other kind of Bayesian

286
00:17:51,080 --> 00:17:53,840
regression type systems.

287
00:17:53,840 --> 00:17:59,760
And we want to be able to say, given what we think is going to happen, how do we sample

288
00:17:59,760 --> 00:18:01,080
as efficiently as possible?

289
00:18:01,080 --> 00:18:06,040
Then we want to say, what do we think is going to improve in expectation the most?

290
00:18:06,040 --> 00:18:11,080
What's the highest probability of improvement in terms of that new configuration to suggest?

291
00:18:11,080 --> 00:18:15,440
And then that loops back into the underlying system after you sample it.

292
00:18:15,440 --> 00:18:21,520
And we learn, update the posterior of these individual surrogate methods, optimize on them,

293
00:18:21,520 --> 00:18:23,800
and repeat that entire process.

294
00:18:23,800 --> 00:18:32,320
So how do you get to the proposed model for the model based piece of this?

295
00:18:32,320 --> 00:18:36,800
In general, in Bayesian optimization, usually you pick a specific type of model and go

296
00:18:36,800 --> 00:18:37,800
from there.

297
00:18:37,800 --> 00:18:42,480
So in some of the open source work I did at Yelp, it was kind of very cut and dry, use

298
00:18:42,480 --> 00:18:47,640
a Gaussian process, use expected improvement to optimize, and go through kind of extremely

299
00:18:47,640 --> 00:18:48,640
sequentially.

300
00:18:48,640 --> 00:18:51,960
This is very similar to Spearment, another popular library.

301
00:18:51,960 --> 00:18:56,080
Let's say that one again, Spearment, it was an open source library out of Harvard, very

302
00:18:56,080 --> 00:19:00,720
similar to the metric optimization engine, or MO, which I wrote at Yelp, also similar

303
00:19:00,720 --> 00:19:03,840
to like G-Pie opt, which is kind of a more recent one.

304
00:19:03,840 --> 00:19:08,360
This is kind of the bread and butter Bayesian optimization approach, Gaussian process

305
00:19:08,360 --> 00:19:10,160
is expected improvement.

306
00:19:10,160 --> 00:19:13,680
What SIGUP represents, though, is this ensemble based approach.

307
00:19:13,680 --> 00:19:17,600
So different surrogate models, different acquisition functions, different covariance

308
00:19:17,600 --> 00:19:23,320
kernels for learning how the parameters interact, as well as not just kind of that standard

309
00:19:23,320 --> 00:19:28,800
build us a single sequential surrogate model based approach, but really taking all of these

310
00:19:28,800 --> 00:19:32,640
different optimizers and optimizing and making it automatic.

311
00:19:32,640 --> 00:19:38,200
So you can select something ahead of time because you know you want to take a very specific

312
00:19:38,200 --> 00:19:42,920
approach, or you can take the more generalized approach and say, we're not necessarily going

313
00:19:42,920 --> 00:19:46,120
to say, we're going to use this specific surrogate model.

314
00:19:46,120 --> 00:19:50,960
We want to learn along the way it was the best possible thing for that underlying system

315
00:19:50,960 --> 00:19:51,960
that we're optimizing.

316
00:19:51,960 --> 00:19:52,960
Right.

317
00:19:52,960 --> 00:20:00,320
So to take a step back, you are in the former case where you're picking a model, a specific

318
00:20:00,320 --> 00:20:01,320
model.

319
00:20:01,320 --> 00:20:07,360
You know, let's say we're assuming a Gaussian distribution, then basically we've got this

320
00:20:07,360 --> 00:20:14,000
hyperparameter space, we are, I'm trying to get at like how, you know, so the parameters

321
00:20:14,000 --> 00:20:19,560
of your Gaussian distribution will be your meaning, your standard deviation, and how

322
00:20:19,560 --> 00:20:26,760
are we, like what's the process for identifying those that is then, you know, that we're

323
00:20:26,760 --> 00:20:27,760
doing sequentially?

324
00:20:27,760 --> 00:20:28,760
Gotcha.

325
00:20:28,760 --> 00:20:33,480
So the way that a Gaussian process works is that it's assuming that the response of that

326
00:20:33,480 --> 00:20:38,000
underlying system that we're sampling is going to be Gaussian distributed at any given

327
00:20:38,000 --> 00:20:39,000
point.

328
00:20:39,000 --> 00:20:43,640
So it's not a single Gaussian distribution or something similar to like a Gaussian mixture

329
00:20:43,640 --> 00:20:48,960
model, what it actually is is an infinite number of potential Gaussian responses for every

330
00:20:48,960 --> 00:20:51,080
potential input.

331
00:20:51,080 --> 00:20:55,960
And then the way the Gaussian processes are analytically defined, once you start to sample

332
00:20:55,960 --> 00:21:02,160
underlying points, you can explicitly build up what that distribution is at sample points

333
00:21:02,160 --> 00:21:04,120
or unsampled points.

334
00:21:04,120 --> 00:21:08,280
The main thing that controls this is what's called a covariance kernel.

335
00:21:08,280 --> 00:21:14,440
And what that is is how much information do I get from sampling point A about some

336
00:21:14,440 --> 00:21:16,240
other point B?

337
00:21:16,240 --> 00:21:18,680
So does it decay exponentially?

338
00:21:18,680 --> 00:21:22,120
Is there some sort of high variance or noise associated with it?

339
00:21:22,120 --> 00:21:26,160
What are the length scales over which all the different parameters interact?

340
00:21:26,160 --> 00:21:30,920
This becomes doubly complicated once you start to look at heterogeneous configuration spaces

341
00:21:30,920 --> 00:21:35,920
with integers and continuous variables and categorical variables and things like that.

342
00:21:35,920 --> 00:21:38,720
Is this covariance matrix?

343
00:21:38,720 --> 00:21:41,720
Is this something that you're learning as part of the process?

344
00:21:41,720 --> 00:21:44,760
It's not something that you know our priority.

345
00:21:44,760 --> 00:21:45,760
Exactly.

346
00:21:45,760 --> 00:21:50,640
So you can set it, but you can also learn as you go.

347
00:21:50,640 --> 00:21:55,000
So there are tunable parameters around these covariance curves.

348
00:21:55,000 --> 00:21:57,280
And so it's, yeah, it's turtles all the way down.

349
00:21:57,280 --> 00:22:03,960
But the idea here is, once you can analytically define, this is maybe a surrogate function.

350
00:22:03,960 --> 00:22:06,200
I may use a Gaussian process.

351
00:22:06,200 --> 00:22:10,920
Here's a specific class of covariance kernels, like an ARD kernel or something like that.

352
00:22:10,920 --> 00:22:17,240
Then you can explicitly say, OK, how good is the fit given what I've observed so far?

353
00:22:17,240 --> 00:22:22,000
And because you're defining the system analytically and you've effectively mapped the problem

354
00:22:22,000 --> 00:22:28,920
from this extremely sparse time-consuming, expensive underlying system that you're sampling,

355
00:22:28,920 --> 00:22:32,280
and now you've mapped it over to this surrogate space, you can start to throw kind of the

356
00:22:32,280 --> 00:22:35,000
kitchen sink of mathematics at the problem.

357
00:22:35,000 --> 00:22:39,960
And use that to kind of optimize the underlying covariance kernels, pick the correct ones, find

358
00:22:39,960 --> 00:22:45,480
the right surrogate functions, and then ultimately leverage that information to decide what's

359
00:22:45,480 --> 00:22:49,720
the point that has the highest probability of improvement or expected improvement or whatever

360
00:22:49,720 --> 00:22:50,720
it may be.

361
00:22:50,720 --> 00:22:58,120
So is the surrogate space, in this case, the covariance kernel or the kind of this vector,

362
00:22:58,120 --> 00:23:00,920
this infinite vector of the distributions?

363
00:23:00,920 --> 00:23:06,840
So the covariance kernel defines that infinite vector or that functional distribution.

364
00:23:06,840 --> 00:23:08,920
So there's two ways to think about Gaussian processing.

365
00:23:08,920 --> 00:23:13,920
So your covariance kernel is infinite by infinite dimensions or something on that order?

366
00:23:13,920 --> 00:23:20,440
Or I mean, it can, how do you, is part of the goal to kind of constrain the dimensionality

367
00:23:20,440 --> 00:23:22,360
of this covariance kernel?

368
00:23:22,360 --> 00:23:26,760
So the covariance kernel itself will take in inputs in the configuration space and basically

369
00:23:26,760 --> 00:23:30,800
say how much covariance can I expect between these two points.

370
00:23:30,800 --> 00:23:33,320
So it does map into a real number.

371
00:23:33,320 --> 00:23:38,280
Technically for various types of covariance kernels, there are these tunable parameters

372
00:23:38,280 --> 00:23:39,720
that are continuous.

373
00:23:39,720 --> 00:23:44,320
So like technically, yes, there's an infinite number of different ways you can parameterize

374
00:23:44,320 --> 00:23:45,640
that.

375
00:23:45,640 --> 00:23:51,920
But what we're able to do is say, given what we've observed so far, what's the most likely

376
00:23:51,920 --> 00:23:57,800
parameterization or what's a distribution of likely parameterizations and leverage that

377
00:23:57,800 --> 00:24:00,760
to decide, okay, this is what we think is a.

378
00:24:00,760 --> 00:24:04,920
A reasonable surrogate function and then once again, do that across a wide variety of

379
00:24:04,920 --> 00:24:05,920
them.

380
00:24:05,920 --> 00:24:06,920
Okay.

381
00:24:06,920 --> 00:24:12,400
I'm still not fully getting where the infinite distributions come in.

382
00:24:12,400 --> 00:24:13,400
Yeah.

383
00:24:13,400 --> 00:24:15,360
So there's two ways to think about a Gaussian process.

384
00:24:15,360 --> 00:24:17,200
One is from the point wise perspective.

385
00:24:17,200 --> 00:24:22,520
And so the idea is at every single point, we're going to assume the response from this underlying

386
00:24:22,520 --> 00:24:26,280
system that we're sampling is going to be Gaussian distribution.

387
00:24:26,280 --> 00:24:31,440
But every single potential configuration has a different potential Gaussian response to

388
00:24:31,440 --> 00:24:32,440
it.

389
00:24:32,440 --> 00:24:34,040
So there's some mean in this.

390
00:24:34,040 --> 00:24:41,200
So you've got an input point and then you've got the space of configurations and each

391
00:24:41,200 --> 00:24:47,920
of those configurations translates this input point to a different distribution.

392
00:24:47,920 --> 00:24:51,040
So the input point is a potential configuration.

393
00:24:51,040 --> 00:24:55,120
So maybe I'll take a step back and do an example here.

394
00:24:55,120 --> 00:24:59,440
So let's say we're tuning some neural network and we want to find the optimal learning

395
00:24:59,440 --> 00:25:00,800
rate.

396
00:25:00,800 --> 00:25:06,120
So maybe initially we try something like just point five or something like that and we

397
00:25:06,120 --> 00:25:07,120
get a response back.

398
00:25:07,120 --> 00:25:08,120
Okay.

399
00:25:08,120 --> 00:25:11,400
And we're optimizing for the accuracy of a fraud detection pipeline.

400
00:25:11,400 --> 00:25:16,720
And so we're like, okay, we get.7 cross validated AUC that looks all right.

401
00:25:16,720 --> 00:25:22,920
So the thing that we're optimizing for is our learning rate and the input is, you know,

402
00:25:22,920 --> 00:25:26,600
we're not talking about inputs to our neural network and our neural network.

403
00:25:26,600 --> 00:25:28,720
We're talking about an aggregate, the error.

404
00:25:28,720 --> 00:25:33,600
Well, so the inputs are, we're going to be tuning this machine learning pipeline.

405
00:25:33,600 --> 00:25:38,360
And so at this high like meta optimization layer, we're going to be saying, okay, we're

406
00:25:38,360 --> 00:25:41,840
going to put in a learning rate and then we're going to go through the training and cross

407
00:25:41,840 --> 00:25:46,360
validation and all sorts of things and come up with some metric that we care about.

408
00:25:46,360 --> 00:25:48,960
So maybe cross validated AUC.

409
00:25:48,960 --> 00:25:53,920
And our goal is to find the learning rate that tunes this entire pipeline in such a way

410
00:25:53,920 --> 00:25:57,080
that it maximizes that output.

411
00:25:57,080 --> 00:26:02,400
And so the way that this works in the sequential model based optimization framework is, okay,

412
00:26:02,400 --> 00:26:07,440
so we sampled.5 learning rate and got.7 out as the result.

413
00:26:07,440 --> 00:26:10,720
And maybe there's a little bit of uncertainty associated with that.

414
00:26:10,720 --> 00:26:16,240
So then let's say we want to model what we think is going to happen if we try.6.

415
00:26:16,240 --> 00:26:19,720
So we have a little bit of information because we've already sampled.5.

416
00:26:19,720 --> 00:26:25,440
So what we do is we build up this Gaussian process that says, okay, I'm pretty sure that

417
00:26:25,440 --> 00:26:29,840
it's going to pass near this point that I've already sampled, but then maybe the information

418
00:26:29,840 --> 00:26:32,040
decays pretty rapidly.

419
00:26:32,040 --> 00:26:40,040
So I expect to see maybe.6 plus or minus.1 if I were to sample a point further away

420
00:26:40,040 --> 00:26:41,520
from it.

421
00:26:41,520 --> 00:26:47,600
And what you can think of is every potential input learning rate to tune this pipeline

422
00:26:47,600 --> 00:26:51,200
has its own Gaussian response that we're expecting.

423
00:26:51,200 --> 00:26:54,360
Has its own mean, it has its own variance.

424
00:26:54,360 --> 00:26:59,880
And so we can explicitly build that up once we define the covariance kernel.

425
00:26:59,880 --> 00:27:02,520
And of course, as you expand this out into more dimensions.

426
00:27:02,520 --> 00:27:07,080
And so in this example, we're talking about what does the covariance kernel look like?

427
00:27:07,080 --> 00:27:08,080
Yeah.

428
00:27:08,080 --> 00:27:13,200
So we would explicitly set a covariance kernel like an ARD kernel that says, okay, we're

429
00:27:13,200 --> 00:27:19,640
expecting some sort of like squared exponential decay of this kind of information from sampling

430
00:27:19,640 --> 00:27:20,840
these different points.

431
00:27:20,840 --> 00:27:25,360
And so is the covariance kernel, again, in this particular case, it's going to be, it's

432
00:27:25,360 --> 00:27:31,440
going to describe the relationship between the learning rate and the output.

433
00:27:31,440 --> 00:27:36,760
So it's going to describe the relationship between like individual samples of that learning

434
00:27:36,760 --> 00:27:37,760
rate.

435
00:27:37,760 --> 00:27:44,440
So let's set that very where we expect wildly different results after 0.01 increments.

436
00:27:44,440 --> 00:27:46,320
Or is it 0.1 increments?

437
00:27:46,320 --> 00:27:51,840
Do we expect it to be an extremely noisy response, or do we expect it to be fairly well behaved?

438
00:27:51,840 --> 00:27:55,600
There's various different parameters of this covariance kernel that basically say, how

439
00:27:55,600 --> 00:28:02,960
much information effectively do I get after sampling point A about some other point B?

440
00:28:02,960 --> 00:28:10,800
Is the dimensionality of the covariance kernel fixed when we start or does it increase in

441
00:28:10,800 --> 00:28:13,360
dimensionality as we sample?

442
00:28:13,360 --> 00:28:18,000
So it takes in the input, which is the actual configurations.

443
00:28:18,000 --> 00:28:21,640
So in this case, it would just be a one-dimensional, just the learning rate, but you can imagine

444
00:28:21,640 --> 00:28:23,200
us extending this out.

445
00:28:23,200 --> 00:28:28,240
So it takes in a vector, which is a specific configuration, or two vectors actually, and

446
00:28:28,240 --> 00:28:34,640
says, OK, how much covariance is there between these two points, these two potential configurations?

447
00:28:34,640 --> 00:28:39,400
That being said, you can parameterize that covariance kernel in different ways, depending

448
00:28:39,400 --> 00:28:42,400
on which specific kernel you've picked.

449
00:28:42,400 --> 00:28:47,280
So in something like an ARD kernel, which is the squared exponential drop off, there's

450
00:28:47,280 --> 00:28:49,520
various length scales that you can tune.

451
00:28:49,520 --> 00:28:52,080
So maybe we know how many of these drop off is that kind of?

452
00:28:52,080 --> 00:28:56,680
Yeah, does it vary over 0.1, but then something like the number of hidden layers might vary

453
00:28:56,680 --> 00:28:59,000
over orders of magnitude larger.

454
00:28:59,000 --> 00:29:04,920
So like 100 hidden layers is very similar to 101, but very different than 200.

455
00:29:04,920 --> 00:29:12,720
I'm so not sure that I'm very clear on the kernel, in this specific example, the dimensionality

456
00:29:12,720 --> 00:29:19,400
of the kernel is 1 by 1, like is it a scalar, or is it takes in a single value, so that's

457
00:29:19,400 --> 00:29:21,120
just the learning rate.

458
00:29:21,120 --> 00:29:28,200
So I guess I'm thinking of it as a matrix.

459
00:29:28,200 --> 00:29:31,880
Is it a function, or is it something, or should I not be thinking of it as a matrix?

460
00:29:31,880 --> 00:29:37,240
So you can define it as a matrix, where it's every point, the pairwise covariance of

461
00:29:37,240 --> 00:29:39,600
every point you've sampled so far.

462
00:29:39,600 --> 00:29:40,600
Right.

463
00:29:40,600 --> 00:29:43,920
So as you sample the dimensionality of this thing is growing.

464
00:29:43,920 --> 00:29:48,560
Of the underlying covariance matrix, but the underlying covariance function is just a function,

465
00:29:48,560 --> 00:29:51,080
so there's no kind of dimensionality associated with it.

466
00:29:51,080 --> 00:29:52,080
Okay.

467
00:29:52,080 --> 00:29:57,520
So it's basically, if I've sampled 10 different points, then I could have a 10 by 10 matrix,

468
00:29:57,520 --> 00:30:04,360
which is the covariance matrix, where every single actual instance inside that matrix is,

469
00:30:04,360 --> 00:30:08,960
how does 0.7 covariance with 0.3, or whatever it may be?

470
00:30:08,960 --> 00:30:16,200
And this, as a whole, helps us define the Gaussian process, which then gives us this

471
00:30:16,200 --> 00:30:21,400
sarcastic, surrogate function for what we think is going to happen if we sample outside

472
00:30:21,400 --> 00:30:23,840
of the points that we've already explicitly observed.

473
00:30:23,840 --> 00:30:24,840
Okay.

474
00:30:24,840 --> 00:30:28,280
And it does that by way of defining the kernel.

475
00:30:28,280 --> 00:30:32,280
So how do we get from the kernel, from the matrix to the kernel?

476
00:30:32,280 --> 00:30:33,280
Is that done explicitly?

477
00:30:33,280 --> 00:30:34,280
Yeah, the way around.

478
00:30:34,280 --> 00:30:37,760
So you start with a kernel, and then the kernel defines the matrix.

479
00:30:37,760 --> 00:30:44,320
So every single individual value within that matrix is defined as, I got it.

480
00:30:44,320 --> 00:30:49,080
So we're specifying the kernel, in this case, you said ADR is ARD.

481
00:30:49,080 --> 00:30:52,080
So it's the, what is ARD sample?

482
00:30:52,080 --> 00:30:53,080
I said that.

483
00:30:53,080 --> 00:30:54,080
Blinking on that, all right.

484
00:30:54,080 --> 00:30:55,080
Okay.

485
00:30:55,080 --> 00:30:56,240
But it's the squared Gaussian falloff.

486
00:30:56,240 --> 00:30:57,240
Yeah.

487
00:30:57,240 --> 00:30:58,240
Yeah.

488
00:30:58,240 --> 00:31:04,120
So what's now unclear for me is if you've picked a sample in your input space, and you've

489
00:31:04,120 --> 00:31:11,200
run your underlying process, and you have an output value from that sample, is the covariance

490
00:31:11,200 --> 00:31:15,840
kernel used to build up like what you expected to see, and then you push that all through

491
00:31:15,840 --> 00:31:18,400
and you get what you actually saw.

492
00:31:18,400 --> 00:31:21,240
And then you can update the covariance kernel.

493
00:31:21,240 --> 00:31:25,760
And then that covariance matrix gets one more row and one more column.

494
00:31:25,760 --> 00:31:32,720
Because now we have how this new point varies with all of the previously observed points.

495
00:31:32,720 --> 00:31:35,920
And then we can use that to update our Gaussian process.

496
00:31:35,920 --> 00:31:43,840
And then we have this new posterior result that we can use to decide what we sample next.

497
00:31:43,840 --> 00:31:47,920
And what we're doing is we're not just kind of doing naive optimization on that Gaussian

498
00:31:47,920 --> 00:31:49,400
process response itself.

499
00:31:49,400 --> 00:31:53,240
We don't just want to find the point with highest mean or something like that.

500
00:31:53,240 --> 00:31:58,800
What we want to do is apply an acquisition function to it and say, given this is what

501
00:31:58,800 --> 00:32:04,120
I think is going to happen if I sample any of these potential input points, how do I find

502
00:32:04,120 --> 00:32:09,160
the point with the highest expected improvement or the highest probability of improvement?

503
00:32:09,160 --> 00:32:13,720
Or which one's going to give me the most knowledge about the eventual optimise, the knowledge

504
00:32:13,720 --> 00:32:15,320
gradient method?

505
00:32:15,320 --> 00:32:19,240
And so acquisition function is the new term that you just introduced.

506
00:32:19,240 --> 00:32:25,640
Is that something that is model based like the covariance kernel is model based on this

507
00:32:25,640 --> 00:32:26,640
ADR?

508
00:32:26,640 --> 00:32:30,080
Do you pick a model that you use for your acquisition function as well?

509
00:32:30,080 --> 00:32:31,080
Yeah.

510
00:32:31,080 --> 00:32:35,840
This is the optimization part of, so the sequential part of sequential model based optimization

511
00:32:35,840 --> 00:32:39,400
is leveraging the history to build up these surrogate models.

512
00:32:39,400 --> 00:32:42,240
The covariance kernel is keeping it updated and all that stuff.

513
00:32:42,240 --> 00:32:47,520
The model based part is actually deciding, okay, this is what we think the response is

514
00:32:47,520 --> 00:32:51,000
going to be in these unsampled configurations.

515
00:32:51,000 --> 00:32:52,480
So that's the Gaussian process.

516
00:32:52,480 --> 00:32:59,320
Then the optimization component is given that surrogate model, what do we actually optimise

517
00:32:59,320 --> 00:33:03,320
for sampling next, before we repeat this entire process?

518
00:33:03,320 --> 00:33:10,320
And so that particular piece is really focused on, you know, you've got this massive potential

519
00:33:10,320 --> 00:33:15,840
state space for your hyperparameters, you know, how do we, how do we choose a sample

520
00:33:15,840 --> 00:33:21,080
path through the hyperparameter space that minimises basically wasting time and not adding

521
00:33:21,080 --> 00:33:22,600
information to-

522
00:33:22,600 --> 00:33:23,600
Exactly.

523
00:33:23,600 --> 00:33:27,520
And this is what really controls that Explorer exploit trade off.

524
00:33:27,520 --> 00:33:32,680
So a popular acquisition function is expected improvement, and that is basically how much

525
00:33:32,680 --> 00:33:37,080
do I think I'm going to beat the best thing I've seen so far by?

526
00:33:37,080 --> 00:33:42,000
So if I've seen a pretty good AUC in my fraud detection pipeline, now all of a sudden

527
00:33:42,000 --> 00:33:44,920
I want to be able to do it as well as possible beyond that.

528
00:33:44,920 --> 00:33:47,560
We're playing King of the Hill effectively.

529
00:33:47,560 --> 00:33:52,080
Another popular one that's kind of maybe a little bit more intuitive to grasp is probability

530
00:33:52,080 --> 00:33:53,240
of improvement.

531
00:33:53,240 --> 00:33:57,480
If I were to sample this unsampled point, what's the probability that I beat the best

532
00:33:57,480 --> 00:33:59,440
thing I've seen so far?

533
00:33:59,440 --> 00:34:04,640
And so these have different exploration, exploitation trade-offs, you know, so far as probability

534
00:34:04,640 --> 00:34:08,800
improvement might be a little bit more conservative, like we're going to kind of keep edging it

535
00:34:08,800 --> 00:34:13,960
up slowly, whereas expected improvement kind of takes the magnitude of the gain into account.

536
00:34:13,960 --> 00:34:17,600
So it might try something far away because it thinks there could be something great that

537
00:34:17,600 --> 00:34:19,120
it has just never seen before.

538
00:34:19,120 --> 00:34:20,120
Yeah, yeah.

539
00:34:20,120 --> 00:34:23,200
And are there other common examples?

540
00:34:23,200 --> 00:34:24,200
Yeah.

541
00:34:24,200 --> 00:34:28,160
And unfortunately, they get a little bit more complicated to internalize, but another

542
00:34:28,160 --> 00:34:29,840
popular one is Knowledge Gradient.

543
00:34:29,840 --> 00:34:33,560
This is what my PhD advisor worked on during his PhD.

544
00:34:33,560 --> 00:34:34,560
The idea is...

545
00:34:34,560 --> 00:34:38,520
I'm imagining from the name like that's kind of based on information theory and like how

546
00:34:38,520 --> 00:34:40,880
much we're going to learn by checking this point.

547
00:34:40,880 --> 00:34:41,880
Exactly.

548
00:34:41,880 --> 00:34:46,760
And the goal is to learn as much as we can about that eventual best point.

549
00:34:46,760 --> 00:34:50,040
And so there's more information theoretic acquisition function.

550
00:34:50,040 --> 00:34:55,200
And then you can kind of define anything that you want with the goal of eventually getting

551
00:34:55,200 --> 00:34:56,200
to this best one.

552
00:34:56,200 --> 00:35:00,040
So these are probably the three most popular, but you could imagine doing composites of this

553
00:35:00,040 --> 00:35:03,880
or some sort of like upper confidence bound based acquisition function.

554
00:35:03,880 --> 00:35:09,480
And the idea is you want it to as efficiently as possible trade off exploration and exploitation

555
00:35:09,480 --> 00:35:13,200
because learning about that underlying system and how it performs and things like that's

556
00:35:13,200 --> 00:35:14,200
important.

557
00:35:14,200 --> 00:35:16,840
But at the end of the day, you just want the best performing model.

558
00:35:16,840 --> 00:35:17,840
Yeah.

559
00:35:17,840 --> 00:35:22,840
Yeah, I think turtles all the way down strikes me as app like you've got hyperparameters

560
00:35:22,840 --> 00:35:23,840
for your model.

561
00:35:23,840 --> 00:35:26,360
You've got hyperparameters for your pipeline.

562
00:35:26,360 --> 00:35:30,200
And then you've got hyperparameters for your optimization system.

563
00:35:30,200 --> 00:35:31,200
Yeah.

564
00:35:31,200 --> 00:35:37,200
And presumably, I'm imagining that you are also trying to optimize the hyperparameters at

565
00:35:37,200 --> 00:35:40,760
that top layer for your optimization system as well.

566
00:35:40,760 --> 00:35:46,480
And this is exactly why Stegopt exists because there's some incredible research out there.

567
00:35:46,480 --> 00:35:50,440
A lot of members of our team have contributed to the academic research and a lot of the

568
00:35:50,440 --> 00:35:51,920
open source out there.

569
00:35:51,920 --> 00:35:54,800
There's a lot of promise that Bayesian optimization has.

570
00:35:54,800 --> 00:36:00,320
But unfortunately, a lot of expert time is wasted optimizing the optimizer, figuring out

571
00:36:00,320 --> 00:36:03,840
the best way to tune all of these turtles all the way down.

572
00:36:03,840 --> 00:36:07,200
And I think that's one of the places where at least the open source that I released to

573
00:36:07,200 --> 00:36:11,360
the metric optimization engine, even though it was very popular on GitHub, it kind of failed

574
00:36:11,360 --> 00:36:16,040
to deliver on that promise because it required an expert to sit and fine tune all these

575
00:36:16,040 --> 00:36:17,280
different things.

576
00:36:17,280 --> 00:36:22,240
So the goal of a company like Stegopt is, can we optimize the optimizer for you and create

577
00:36:22,240 --> 00:36:27,440
this automatic ensemble that makes all of these trade-offs so that you as an expert can

578
00:36:27,440 --> 00:36:33,800
focus on fraud detection and we'll focus on black box optimization for you.

579
00:36:33,800 --> 00:36:40,320
And so we've described a bunch of different kind of variants in this process.

580
00:36:40,320 --> 00:36:47,600
Are there specific, you know, invariants for Stegopt in your process like, you know,

581
00:36:47,600 --> 00:36:50,640
like for example, you know, basing everything on a Bayesian process.

582
00:36:50,640 --> 00:36:58,240
That's one way of doing this is the product based around that and what other kind of

583
00:36:58,240 --> 00:37:00,800
invariants are there in the way you approach this.

584
00:37:00,800 --> 00:37:01,800
Yeah.

585
00:37:01,800 --> 00:37:04,760
So at the very highest level, we're just black box optimization.

586
00:37:04,760 --> 00:37:06,440
So there's inputs to a system.

587
00:37:06,440 --> 00:37:08,880
There's an output or set of outputs that we want to optimize.

588
00:37:08,880 --> 00:37:12,200
And we're going to try to come up with the best set of inputs.

589
00:37:12,200 --> 00:37:17,480
So Bayesian optimization is an extremely efficient way to do this, especially when it's time-consuming

590
00:37:17,480 --> 00:37:19,840
and expensive to sample that underlying system.

591
00:37:19,840 --> 00:37:23,480
There's lots of different variants of Bayesian optimization.

592
00:37:23,480 --> 00:37:27,080
So instead of using like a Gaussian process, we could use a Bayesian neural network for

593
00:37:27,080 --> 00:37:29,200
the underlying circuit function.

594
00:37:29,200 --> 00:37:33,560
Instead of using Bayesian optimization, we could use a genetic algorithm or particle swarm

595
00:37:33,560 --> 00:37:38,600
or simulated annealing or even just a convex gradient based method.

596
00:37:38,600 --> 00:37:44,760
The idea being, SIGUP takes care of that optimization of the optimizer and automatically

597
00:37:44,760 --> 00:37:46,880
selects the best one for you.

598
00:37:46,880 --> 00:37:51,920
Most of our methods or almost all of our methods are Bayesian in nature, but we're not constrained

599
00:37:51,920 --> 00:37:52,920
to that necessarily.

600
00:37:52,920 --> 00:37:53,920
Yeah.

601
00:37:53,920 --> 00:37:55,920
I guess that was the question that I was trying to get at.

602
00:37:55,920 --> 00:37:57,720
How far do you go?

603
00:37:57,720 --> 00:38:07,640
Do you also now or envision a future where, because you're providing this black box capability,

604
00:38:07,640 --> 00:38:16,000
you may do the Bayesian optimization, but also sample or test the results that you get

605
00:38:16,000 --> 00:38:20,120
from particle swarms and other types of methods.

606
00:38:20,120 --> 00:38:21,120
Definitely.

607
00:38:21,120 --> 00:38:26,800
In-house, we built this very robust evaluation framework for deciding whether or not specific

608
00:38:26,800 --> 00:38:29,640
algorithms fare well in different contexts.

609
00:38:29,640 --> 00:38:33,560
This is what we use when we integrate a new paper and want to make sure that with high

610
00:38:33,560 --> 00:38:37,600
statistical confidence, it actually outperforms what we're currently doing.

611
00:38:37,600 --> 00:38:42,960
We use this as our internal metric for deciding what to do.

612
00:38:42,960 --> 00:38:44,760
But we're agnostic to the underlying methods.

613
00:38:44,760 --> 00:38:47,520
We just want the best possible thing for our customers.

614
00:38:47,520 --> 00:38:51,960
It turns out for the types of problems that we're attacking, Bayesian optimization is an incredibly

615
00:38:51,960 --> 00:38:57,320
good fit and it's underutilized because it's so difficult to get up and running and

616
00:38:57,320 --> 00:39:01,960
optimized, but we have and will continue to employ whatever the best method is for the

617
00:39:01,960 --> 00:39:03,920
problems that we're attacking.

618
00:39:03,920 --> 00:39:09,280
Because we define this barrier in this way where it's just black box optimization, the underlying

619
00:39:09,280 --> 00:39:14,640
system is a black box to us, but we're also a black box to our customers.

620
00:39:14,640 --> 00:39:20,040
This allows us to hotswap in the best possible technique to solve their problem and not be

621
00:39:20,040 --> 00:39:21,040
constrained in that way.

622
00:39:21,040 --> 00:39:22,040
Okay.

623
00:39:22,040 --> 00:39:23,040
Okay.

624
00:39:23,040 --> 00:39:24,040
Cool.

625
00:39:24,040 --> 00:39:26,440
Can you talk a little bit about the model evaluation framework that you built?

626
00:39:26,440 --> 00:39:27,440
Yeah.

627
00:39:27,440 --> 00:39:31,480
There's some I-C-Mail workshop papers from 2016 that go into quite a bit more detail

628
00:39:31,480 --> 00:39:36,400
and are available on our website, but the idea is, I've just told you that we have an

629
00:39:36,400 --> 00:39:41,000
optimization framework that can solve any underlying black box function.

630
00:39:41,000 --> 00:39:45,240
The first response should be, I don't know whether or not it's working, so internally

631
00:39:45,240 --> 00:39:50,000
we built up the system where traditionally to publish papers, and I'm guilty of doing

632
00:39:50,000 --> 00:39:56,000
this, is you would come up with some strategy, pick three to six of your favorite functions,

633
00:39:56,000 --> 00:40:00,240
show that you can outperform some specific techniques on those functions, publish a paper,

634
00:40:00,240 --> 00:40:01,560
rinse and repeat.

635
00:40:01,560 --> 00:40:05,320
So when we built this up internally, we took the superset of all of those different functions

636
00:40:05,320 --> 00:40:06,840
from the academic literature.

637
00:40:06,840 --> 00:40:09,480
We took functions that look similar to our customer's data.

638
00:40:09,480 --> 00:40:13,840
We took a bunch of open machine learning data sets and strategies, and we basically piled

639
00:40:13,840 --> 00:40:14,920
them all together.

640
00:40:14,920 --> 00:40:18,680
So instead of comparing against three or four different response surfaces, now we're

641
00:40:18,680 --> 00:40:21,120
looking at hundreds or thousands of them.

642
00:40:21,120 --> 00:40:25,040
In addition to that, we wanted to make sure against all of these different open source

643
00:40:25,040 --> 00:40:29,520
methods and against all of these other kind of different global optimization strategies

644
00:40:29,520 --> 00:40:32,840
that we could very robustly outperform them.

645
00:40:32,840 --> 00:40:38,520
So what we do in the internal evaluation framework is we independently optimize these hundreds

646
00:40:38,520 --> 00:40:45,440
of different pathological and real world problems, many times with sigups and many times with

647
00:40:45,440 --> 00:40:49,480
another method, and that other method might be just a new version of sigopt.

648
00:40:49,480 --> 00:40:54,240
And then with high statistical confidence, we can say, which one got to the best value

649
00:40:54,240 --> 00:40:59,880
fastest, which one got to the ultimate best result, which one was the most robust, so it

650
00:40:59,880 --> 00:41:04,560
didn't have an inter-core tile ranges or all above a specific value.

651
00:41:04,560 --> 00:41:08,560
It sounds like to draw an analogy from software engineering, you've built a regression testing

652
00:41:08,560 --> 00:41:10,520
framework for optimizer.

653
00:41:10,520 --> 00:41:15,120
Yeah, so we do use it for regression testing, it's run nightly, but it's also a way to

654
00:41:15,120 --> 00:41:17,720
basically AB test optimizers as well.

655
00:41:17,720 --> 00:41:18,720
Right.

656
00:41:18,720 --> 00:41:28,040
And not using it to, or to what extent are you using it to inform model choices, or I

657
00:41:28,040 --> 00:41:32,400
guess the, you know, what I'm struggling a little bit with is, you know, so you've got

658
00:41:32,400 --> 00:41:37,480
this, you've got this, you know, this heap of data sets and functions and things like

659
00:41:37,480 --> 00:41:38,480
that.

660
00:41:38,480 --> 00:41:46,120
And if you were trying to optimize across all of those, then you've got a least common

661
00:41:46,120 --> 00:41:50,680
denominator kind of problem, right, or in a local maxima or something like that.

662
00:41:50,680 --> 00:41:51,680
Yeah.

663
00:41:51,680 --> 00:41:54,440
So we do have to be wary that we don't overfit to this data set.

664
00:41:54,440 --> 00:41:55,640
That's definitely true.

665
00:41:55,640 --> 00:42:00,440
One thing that we found though is the reason why we built an ensemble based approach.

666
00:42:00,440 --> 00:42:04,440
So let me just, just poke at that, like I'm not sure, is overfitting the right word for

667
00:42:04,440 --> 00:42:10,360
what I'm thinking of is, is that, you know, some of it strikes me as the opposite of overfitting,

668
00:42:10,360 --> 00:42:13,520
whereas like if I were to just look at, I don't really care about all this other data,

669
00:42:13,520 --> 00:42:19,440
I care about my problem, like if you're optimizing for this kind of broad spectrum and I can,

670
00:42:19,440 --> 00:42:24,240
you know, outperform you by just focusing on my problem, you know, I'd probably do that.

671
00:42:24,240 --> 00:42:25,240
Yeah.

672
00:42:25,240 --> 00:42:26,240
That makes it complete sense.

673
00:42:26,240 --> 00:42:27,080
I see where you're coming at here.

674
00:42:27,080 --> 00:42:31,120
So this is why we take this ensemble based approach, because it turns out like the most

675
00:42:31,120 --> 00:42:35,840
popular approach to invasion optimization, like Gaussian processes with aarity kernel with

676
00:42:35,840 --> 00:42:41,360
expected improvement actually doesn't do super well in a wide variety of different contexts.

677
00:42:41,360 --> 00:42:46,080
So by slotting in the right tool for the job, we can actually hit all of these different

678
00:42:46,080 --> 00:42:49,760
facets of different types of problems extremely well.

679
00:42:49,760 --> 00:42:54,320
That being said, the no free lunch theorem and computer science still applies here in

680
00:42:54,320 --> 00:42:58,960
so far as if you do have expert knowledge about your underlying system and you build a bespoke

681
00:42:58,960 --> 00:43:04,760
optimizer to solve that one specific problem, you are going to outperform a general technique.

682
00:43:04,760 --> 00:43:09,000
That being said, you would have to repeat that for the next problem that you attack and

683
00:43:09,000 --> 00:43:10,520
the next one and the next one.

684
00:43:10,520 --> 00:43:15,600
And so the idea is by having an ensemble of different optimizers, we use the right one

685
00:43:15,600 --> 00:43:20,000
for specific contexts and then a different one for a different context, et cetera.

686
00:43:20,000 --> 00:43:23,760
So instead of having like the lowest common denominator, like you said, just the one size

687
00:43:23,760 --> 00:43:29,600
fits all, what we're doing is actually putting in the right tool and automatically learning

688
00:43:29,600 --> 00:43:31,000
when we trade it off.

689
00:43:31,000 --> 00:43:34,840
So when you're tuning a gradient boosted method, you're getting the right tool, but when

690
00:43:34,840 --> 00:43:39,040
you tune a neural network, it's still the same API and stay interface, but you're getting

691
00:43:39,040 --> 00:43:40,720
the right optimizer out of it.

692
00:43:40,720 --> 00:43:45,680
So what I'm hearing is in response to my question, like a little bit of both, right?

693
00:43:45,680 --> 00:43:50,680
Like you're, you've built this model evaluation framework because fundamentally you're not

694
00:43:50,680 --> 00:43:57,080
necessarily trying to outperform a handcrafted model that 50 PhDs has been five years developing

695
00:43:57,080 --> 00:44:05,040
whatever you're trying to build a system that can deliver good performance on, you know,

696
00:44:05,040 --> 00:44:07,040
in general what someone throws at it.

697
00:44:07,040 --> 00:44:11,120
And so you want to test it against a bunch of, you know, hey, these are things that someone

698
00:44:11,120 --> 00:44:15,840
might throw at it and make sure that you get good performance.

699
00:44:15,840 --> 00:44:21,600
And the way that you do that is under the covers, you're not just relying on, you know,

700
00:44:21,600 --> 00:44:26,440
one specific set of choices, but you're taking an ensemble approach and your optimizer

701
00:44:26,440 --> 00:44:34,120
can swap in and out different decisions to produce a result that that's best.

702
00:44:34,120 --> 00:44:38,640
That's exactly it because what we find more often than not is that people don't assign

703
00:44:38,640 --> 00:44:44,480
50 PhDs for five years for every single optimization problem that they have more often than not.

704
00:44:44,480 --> 00:44:49,640
They're using grid search, random search, manual tuning, maybe an open source solution,

705
00:44:49,640 --> 00:44:53,760
maybe they have part of their team part time working on an internal optimizer or something

706
00:44:53,760 --> 00:44:54,760
like that.

707
00:44:54,760 --> 00:44:57,400
And those are the things that we can vastly outperform.

708
00:44:57,400 --> 00:45:01,160
If you know it's convex and you have gradient information and you have a bunch of expert knowledge,

709
00:45:01,160 --> 00:45:05,280
like there is specific tools that you can use to get there, and this is probably a little

710
00:45:05,280 --> 00:45:09,720
heavy handed to use in that situation, but more often than not what we're doing is we're

711
00:45:09,720 --> 00:45:15,800
coming and replacing these very exhaustive, very expensive, very domain expert intensive

712
00:45:15,800 --> 00:45:20,000
systems, and we can generally outperform those to a high degree.

713
00:45:20,000 --> 00:45:24,600
Yeah, now often like to think of the the tool space in general is like there's, you know,

714
00:45:24,600 --> 00:45:31,920
for many enterprises, there's such a huge potential opportunity to apply ML that their

715
00:45:31,920 --> 00:45:36,640
ability to staff up, you know, is far outpaced by the opportunity.

716
00:45:36,640 --> 00:45:41,160
So at a given staffing level, like you've got this choice, you can either like, you know,

717
00:45:41,160 --> 00:45:47,000
take only the biggest opportunity and apply all your resources to that in a very manual

718
00:45:47,000 --> 00:45:54,080
way, or you can, you know, utilize tools that allow folks to be more effective and

719
00:45:54,080 --> 00:45:59,280
light off some of these, you know, some of the, you know, it's like the, a lot of,

720
00:45:59,280 --> 00:46:02,360
you know, I'll talk to folks and they'll talk about it like we only go after home runs

721
00:46:02,360 --> 00:46:08,200
versus, you know, base hits, right, and this, it sounds like this is a tool for allowing

722
00:46:08,200 --> 00:46:14,560
people to, you know, both go after home runs as well as try to increase their hit rate

723
00:46:14,560 --> 00:46:15,560
for bases.

724
00:46:15,560 --> 00:46:16,560
Definitely.

725
00:46:16,560 --> 00:46:19,360
And what we find with a lot of the firms that we work with is how they differentiate

726
00:46:19,360 --> 00:46:24,240
themselves from their competitors is not by black box Bayesian optimization.

727
00:46:24,240 --> 00:46:28,480
It's by creating a great recommendation engine or a great algorithmic trading strategy.

728
00:46:28,480 --> 00:46:34,240
And if you can hire five more PhDs to work on that core differentiator or free up five

729
00:46:34,240 --> 00:46:39,560
PhDs to do that, and then just use SIGOP to tune it, they work very additively and hand

730
00:46:39,560 --> 00:46:44,600
in hand, we can accelerate that time to market, accelerate the results, getting to the best

731
00:46:44,600 --> 00:46:46,760
performance and all of these different things.

732
00:46:46,760 --> 00:46:51,440
And I think more and more companies are becoming aware of this and using the right tool for

733
00:46:51,440 --> 00:46:52,440
the job.

734
00:46:52,440 --> 00:46:54,640
Why rewrite TensorFlow when you can use it?

735
00:46:54,640 --> 00:46:59,600
Why write your own Bayesian optimizer when you can use a best in class, easy, rest API?

736
00:46:59,600 --> 00:47:00,600
Awesome.

737
00:47:00,600 --> 00:47:01,600
Awesome.

738
00:47:01,600 --> 00:47:03,440
So what's the, what's the best way for folks to learn more?

739
00:47:03,440 --> 00:47:04,440
I'm assuming the website.

740
00:47:04,440 --> 00:47:05,440
Yep.

741
00:47:05,440 --> 00:47:10,760
SIGOP.com or just contact at SIGOP.com if you want to shoot us an email, we run a complimentary

742
00:47:10,760 --> 00:47:14,520
proof of concept pilot like we can throw these peer reviewed papers at you to prove that

743
00:47:14,520 --> 00:47:18,120
we're as good as we say we are, but at the end of the day, we want to prove it with their

744
00:47:18,120 --> 00:47:20,240
underlying models themselves.

745
00:47:20,240 --> 00:47:25,280
So we can work with any enterprise, any underlying system, cloud agnostic, model agnostic.

746
00:47:25,280 --> 00:47:28,800
It's also free for students, so if there are any people at universities or researchers

747
00:47:28,800 --> 00:47:33,280
at national labs or whatever it is listening to the podcast, SIGOP.com slash EDU gets you

748
00:47:33,280 --> 00:47:34,680
a free enterprise account.

749
00:47:34,680 --> 00:47:38,920
I wasted way too much of my PhDs on this problem, don't want to do that for anybody else.

750
00:47:38,920 --> 00:47:44,040
And what about for folks that are interested in learning about the theoretical foundations

751
00:47:44,040 --> 00:47:45,040
of the work?

752
00:47:45,040 --> 00:47:46,040
Where would you point them?

753
00:47:46,040 --> 00:47:48,840
Are there like three canonical papers or something like that that they should look

754
00:47:48,840 --> 00:47:49,840
for?

755
00:47:49,840 --> 00:47:50,840
Yeah.

756
00:47:50,840 --> 00:47:53,760
So if you go to SIGOP.com slash research, those all of our papers, we also have a Bayesian

757
00:47:53,760 --> 00:47:57,600
optimization primer there that kind of goes into more detail about some of the things

758
00:47:57,600 --> 00:48:01,480
I said verbally sometimes is a little bit hard to describe the action processes and things

759
00:48:01,480 --> 00:48:02,480
like that.

760
00:48:02,480 --> 00:48:03,480
The math is there.

761
00:48:03,480 --> 00:48:07,320
There's references for all those papers as well, so that can kind of take you down the

762
00:48:07,320 --> 00:48:10,320
rabbit hole of all the different ways that this has been applied to the story.

763
00:48:10,320 --> 00:48:11,320
Okay.

764
00:48:11,320 --> 00:48:12,320
Awesome.

765
00:48:12,320 --> 00:48:15,120
Glad it's been a great conversation and I've learned a ton.

766
00:48:15,120 --> 00:48:16,120
Excellent.

767
00:48:16,120 --> 00:48:17,120
Thank you so much.

768
00:48:17,120 --> 00:48:18,120
I really appreciate it.

769
00:48:18,120 --> 00:48:19,120
Thanks.

770
00:48:19,120 --> 00:48:23,080
All right, everyone.

771
00:48:23,080 --> 00:48:25,520
That's our show for today.

772
00:48:25,520 --> 00:48:31,920
Thank you so much for listening and of course, for your continued feedback and support.

773
00:48:31,920 --> 00:48:38,120
For more information on Scott and the topics covered in this episode, head on over to twimmolaii.com

774
00:48:38,120 --> 00:48:41,240
slash talk slash 50.

775
00:48:41,240 --> 00:48:46,240
This week on Tuesday and Wednesday, October 3rd and 4th, I'll be at the Gartner Symposium

776
00:48:46,240 --> 00:48:51,120
in Orlando, where I'll be on a panel on how to get started with AI.

777
00:48:51,120 --> 00:48:55,080
If you'd like to meet up there, please send me a shout.

778
00:48:55,080 --> 00:49:00,080
The following week, I'll be in Montreal for the rework, deep learning summit, and hope

779
00:49:00,080 --> 00:49:03,320
to be joined by at least one lucky listener.

780
00:49:03,320 --> 00:49:08,080
Remember to visit twimmolaii.com slash dl summit to enter.

781
00:49:08,080 --> 00:49:12,040
It ends at noon central on October 4th.

782
00:49:12,040 --> 00:49:40,480
Thanks again for listening and catch you next time.

