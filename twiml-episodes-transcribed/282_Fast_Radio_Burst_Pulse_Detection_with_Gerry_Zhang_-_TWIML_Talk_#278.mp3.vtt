WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:31.920
I'm your host Sam Charrington.

00:31.920 --> 00:36.760
You are invited to join us for the very first Twimblecon conference which will focus on the

00:36.760 --> 00:41.200
tools, technologies and practices necessary to scale the delivery of machine learning

00:41.200 --> 00:43.720
and AI in the enterprise.

00:43.720 --> 00:48.600
The event will be held October 1st and 2nd in San Francisco and early bird registration

00:48.600 --> 00:56.400
is open today at twimblecon.com, again that's t-w-i-m-l-c-o-n.com.

00:56.400 --> 00:58.880
I can't wait to see you there.

00:58.880 --> 01:02.880
Alright everyone, I am on the line with Yun Fan, Jerry Zhang.

01:02.880 --> 01:09.720
Yun Fan is a PhD student in the Department of Astrophysics at the University of California

01:09.720 --> 01:16.280
at Berkeley and is also affiliated with the SETI Research Center at Berkeley.

01:16.280 --> 01:21.040
You're welcome to this week in machine learning and AI.

01:21.040 --> 01:25.280
You spend your days searching for extraterrestrial intelligence.

01:25.280 --> 01:27.280
Let's just start right there.

01:27.280 --> 01:33.240
Tell us about that effort at Berkeley and how you got involved in applying machine learning

01:33.240 --> 01:34.760
to that search.

01:34.760 --> 01:36.560
Right, absolutely.

01:36.560 --> 01:42.080
So SETI, which is short for the search for extraterrestrial intelligence, is about

01:42.080 --> 01:45.360
the question are we alone in the universe?

01:45.360 --> 01:50.720
So the search for extraterrestrial life comes in many different forms.

01:50.720 --> 01:58.000
Many searches involve searching for simpler life by looking at the biosignatures or by

01:58.000 --> 02:05.320
going inside of our solar system, doing insitial sampling in the soils on Mars, for example.

02:05.320 --> 02:08.560
SETI takes a slightly different approach.

02:08.560 --> 02:17.000
SETI is the main idea behind SETI is that a lot of technological signature or radio emissions

02:17.000 --> 02:22.400
or whether intentional or non-intentional could potentially be detected from very far

02:22.400 --> 02:23.400
away.

02:23.400 --> 02:30.320
Therefore, if there are advanced civilizations within our galaxy, we could hope to detect

02:30.320 --> 02:34.920
their technical signatures with or existing telescopes.

02:34.920 --> 02:41.640
So these ideas have been proposed since the 1950s, and since then, we have greatly increased

02:41.640 --> 02:47.080
the computational as well as the analog capabilities.

02:47.080 --> 02:56.320
And in 2015, the breakthrough initiatives was funded by Yuri Milner.

02:56.320 --> 03:01.640
The breakthrough listen project in particular is a $100 million project to conduct the

03:01.640 --> 03:05.520
most comprehensive SETI to date.

03:05.520 --> 03:10.720
And the main headquarters is here in Berkeley at a breakthrough SETI research center, where

03:10.720 --> 03:18.960
we analyze the data that we collected from currently two main telescopes, the Greenbank

03:18.960 --> 03:25.720
Telescope in West Virginia, the Parks Telescope in Australia, and most recently announced

03:25.720 --> 03:32.560
the Miracat Telescope Array in South Africa, which is a precursor to the Square Kilometer

03:32.560 --> 03:33.560
Array.

03:33.560 --> 03:34.560
Interesting.

03:34.560 --> 03:41.920
Now, I remember back in the early 2000s, I guess, there was a SETI at home project which

03:41.920 --> 03:48.400
basically kind of distributed that there was this client you can download, and it would

03:48.400 --> 03:53.320
the SETI at home project would kind of parcel out these mathematical equations, basically

03:53.320 --> 04:02.640
analysis of some set of these signal to the, I don't know, millions of people who downloaded

04:02.640 --> 04:03.640
this SETI at home.

04:03.640 --> 04:05.680
I think it was a screensaver or something like that.

04:05.680 --> 04:06.680
Right.

04:06.680 --> 04:07.680
Right.

04:07.680 --> 04:08.680
Does that thing still exist?

04:08.680 --> 04:09.680
Yeah.

04:09.680 --> 04:10.680
Yeah.

04:10.680 --> 04:14.080
SETI at home is still operating, also based out of Berkeley.

04:14.080 --> 04:15.080
Okay.

04:15.080 --> 04:23.280
So SETI at home was actually one of the earlier deployments of distributed DECES.

04:23.280 --> 04:25.880
Centralized computing.

04:25.880 --> 04:34.000
And it employs a set of match filters that people use to, that people have engineered

04:34.000 --> 04:40.760
a signal that could potentially be interesting, potentially be sources of ETI.

04:40.760 --> 04:45.200
And that effort is still going on today.

04:45.200 --> 04:49.880
Interesting, but your focus is on the application of machine learning to this.

04:49.880 --> 04:53.080
How did you, you know, what sparked your interest in this area?

04:53.080 --> 04:54.080
Absolutely.

04:54.080 --> 05:02.080
So, so in, as machine learning applied to SETI, for example, SETI at home, as we just

05:02.080 --> 05:04.600
discussed, employs a set of match filters.

05:04.600 --> 05:10.840
And very few listen also mainly revolve, searching for particular types of signals, which

05:10.840 --> 05:14.200
we can go into one more detail in a bit.

05:14.200 --> 05:22.360
The idea is that using machine learning, we can potentially find signals where we don't

05:22.360 --> 05:26.840
exactly know the type of signal that we're looking for.

05:26.840 --> 05:32.680
So that's, that's one of the main reasons that a more flexible and versatile technique

05:32.680 --> 05:36.400
like modern machine learning could potentially help.

05:36.400 --> 05:43.520
For me personally, my background was actually originally in particle physics.

05:43.520 --> 05:52.080
So the, my career track is sort of, I started very young, being interested in big

05:52.080 --> 06:02.240
ideas, ideas that, that based on a set of principles, mathematics, we're able to derive highly

06:02.240 --> 06:09.880
non-trivial understandings of the universe and really shape the course of human history.

06:09.880 --> 06:15.560
So that really got me interested in the success stories of 20th century physics.

06:15.560 --> 06:24.440
During my time at Berkeley, I started to realize that in the 21st century data has become

06:24.440 --> 06:31.160
a new tool to solve these very complex problems more effectively, efficiently.

06:31.160 --> 06:38.600
And that's how I got myself involved in machine learning and data science.

06:38.600 --> 06:47.000
And I started by, I, I took some classes at Berkeley on seminars of deep learning where

06:47.000 --> 06:53.720
we looked at most recent, some recent papers and we have invited talks from researchers

06:53.720 --> 06:59.240
at Microsoft and Amazon and we design our own research projects.

06:59.240 --> 07:05.560
And that's, that started my, my, my interest in passion for modern deep learning.

07:05.560 --> 07:15.400
And within my department, the, one of the groups that was in need the most of these techniques

07:15.400 --> 07:18.800
was breakthrough listen, the SETI project.

07:18.800 --> 07:21.000
And that's how I started my involvement.

07:21.000 --> 07:22.000
Okay.

07:22.000 --> 07:29.600
And within the department just out of curiosity is deep learning, is it a, you know, a

07:29.600 --> 07:36.480
still a rare skill or is it becoming a, to what degree is it becoming a standard piece

07:36.480 --> 07:40.080
of the astrophysics toolkit?

07:40.080 --> 07:41.080
Right.

07:41.080 --> 07:42.080
Right.

07:42.080 --> 07:43.080
Right.

07:43.080 --> 07:50.200
To my understanding, I would say the, it's, I would not call deep learning a standard

07:50.200 --> 07:52.080
toolkit in astronomy quite yet.

07:52.080 --> 07:58.000
I would say the application in astronomy is just starting to take off.

07:58.000 --> 08:06.040
The good thing is we have very nicely built algorithms from the computer vision community

08:06.040 --> 08:13.120
from the voice recognition language processing community that we can tie in to the kind

08:13.120 --> 08:16.320
of problems that astronomers are interested in.

08:16.320 --> 08:24.320
So I think the progress will be very fast, however, I would describe the, the degree of

08:24.320 --> 08:28.240
maturity to be still at early stages.

08:28.240 --> 08:33.640
From my previous conversations with folks applying machine learning to astronomy, one of

08:33.640 --> 08:41.000
the challenges that, of course, isn't unique to astronomy, but is accentuated in astronomy,

08:41.000 --> 08:47.960
I believe, is the, you know, the issue of the data, the cleanliness of the data.

08:47.960 --> 08:53.760
Can you talk a little bit about the data sources that you're working with and, you know,

08:53.760 --> 08:58.240
what they look like, how you have to deal with them and the challenges that they create

08:58.240 --> 08:59.240
for you?

08:59.240 --> 09:00.240
Absolutely.

09:00.240 --> 09:05.880
So, because, I think, because we, the algorithm side is so developed, well developed from

09:05.880 --> 09:14.080
the computer vision folks, I think, for us, really forming, formalizing the problem and

09:14.080 --> 09:19.720
putting the data in the form is, I think, the main effort in applying machine learning.

09:19.720 --> 09:29.520
And so for us, in the radio frequency setting, the data are collected as complex raw voltages.

09:29.520 --> 09:36.400
So these are time series, very high data rate time series that we collect from, from

09:36.400 --> 09:37.400
the telescope.

09:37.400 --> 09:42.520
So the raw data rate would be about half petabyte per day.

09:42.520 --> 09:48.120
And we take these complex time series and we, we essentially take Fourier transforms

09:48.120 --> 09:51.960
on these time series to form spectrograms.

09:51.960 --> 09:57.160
So spectrograms are intensity as a function of frequency and time.

09:57.160 --> 10:02.560
They are essentially two-dimensional data, sort of like images where we do a lot of, a

10:02.560 --> 10:04.040
lot of our analysis.

10:04.040 --> 10:10.920
So these two types of data products, the time series and the, the, the waterfall plot,

10:10.920 --> 10:15.480
the spectrograms are the two main types of data that we work with.

10:15.480 --> 10:19.880
The spectrogram is that a native output of the telescope, or is that a product that

10:19.880 --> 10:22.760
you have to create through processing?

10:22.760 --> 10:25.200
So it's a product that you create through processing.

10:25.200 --> 10:28.800
It's, you can think of it as sort of a feature extraction.

10:28.800 --> 10:35.560
So it's a Fourier transform to, to represent time series, essentially, by the type of

10:35.560 --> 10:40.960
periodicities, the type of frequencies that's, that's present in the data.

10:40.960 --> 10:47.520
It's a kind of feature extraction, but it's a very, it's a very efficient one because

10:47.520 --> 10:54.120
of the way the, the, the, the, the Fourier nature of, of wave, wave physics, essentially.

10:54.120 --> 11:01.520
And so you've got this, this half a petabyte of data per day that's coming off of these

11:01.520 --> 11:03.800
telescopes that you're using.

11:03.800 --> 11:07.040
Do you have to work with all of that?

11:07.040 --> 11:13.440
Are you able to, are the, the telescopes themselves like the organizations that run those telescopes

11:13.440 --> 11:20.880
producing products that are, you know, already processed and lower volume, or do you just

11:20.880 --> 11:22.680
kind of work with raw data?

11:22.680 --> 11:23.680
Right.

11:23.680 --> 11:30.440
So the, the spectrograms I mentioned, that's already 100 times smaller in terms of data

11:30.440 --> 11:32.000
volume than the raw data.

11:32.000 --> 11:36.680
We do this simply by averaging once the spectrograms are formed.

11:36.680 --> 11:41.720
So that makes the data storage problem a little more manageable.

11:41.720 --> 11:45.880
So, and by, by doing so, you do destroy some information.

11:45.880 --> 11:54.320
So, you know, the, the spectrograms that we work with, we designed them from the get go

11:54.320 --> 12:02.680
for a particular type of observation in that we try to isolate the signals that are coming

12:02.680 --> 12:08.960
from the sky, aside from the signal that are coming from the side lobes.

12:08.960 --> 12:15.440
There's these signals, terrestrial signals from cell phones, satellites, from airplanes.

12:15.440 --> 12:21.360
We try to isolate these interference away from, from signal that's actually coming from

12:21.360 --> 12:22.960
space.

12:22.960 --> 12:31.120
So we do this by a spatial filtering technique where we, to simply put, we look at multiple

12:31.120 --> 12:33.400
patches of sky at the same time.

12:33.400 --> 12:38.160
And if a signal shows up in all patches of sky, then we conclude that this signal is

12:38.160 --> 12:40.800
actually not localized in the sky.

12:40.800 --> 12:48.040
So, so the, the spectrograms are, are designed to look for these particular types of signals

12:48.040 --> 12:53.320
and we have a set of match filters that operate on these spectrograms to look for them.

12:53.320 --> 13:00.880
However, the nature of the problem is, is not so well defined because we don't exactly

13:00.880 --> 13:07.640
know for sure that the type of signals that, that the event civilization could be sending

13:07.640 --> 13:11.280
matches the, the match filter that we're deploying.

13:11.280 --> 13:16.520
So we do store all of these spectrograms for later inspection with more events techniques

13:16.520 --> 13:23.800
such as deep learning, even on supervised learning to, to look through them more exhaustively.

13:23.800 --> 13:34.120
The, you mentioned that one of the big challenges besides from kind of just the data processing

13:34.120 --> 13:40.840
piece is problem formulation and you alluded to that again and that you, you know, this

13:40.840 --> 13:44.280
is something that will change as we get more sophisticated.

13:44.280 --> 13:48.920
How do you approach that part of the problem though in your research?

13:48.920 --> 13:54.680
Right, right. So the fact that the data comes very unstructured, so these are essentially

13:54.680 --> 14:01.520
just images and images and images where you don't exactly know what to look for in the

14:01.520 --> 14:12.080
image. It requires essentially different problems being formulated depending on what, what

14:12.080 --> 14:13.080
the goal is.

14:13.080 --> 14:20.800
One particular project that we recently did press release on was detection of a signal

14:20.800 --> 14:22.280
known as a fast radio burst.

14:22.280 --> 14:29.080
So these are a particular type of signals that astronomers have detected since 2007.

14:29.080 --> 14:33.480
So these, what they look like is in the spectrogram that we just mentioned, these are roughly

14:33.480 --> 14:34.480
a parabola.

14:34.480 --> 14:38.760
So these are quadratic form signals.

14:38.760 --> 14:45.920
So to look for these type of signals, we know what type of signal we're looking for.

14:45.920 --> 14:54.200
So to use machine learning, we can simulate the type of signal and the reason we want

14:54.200 --> 14:59.960
to do this is one that we know what to simulate and also because the signals are themselves

14:59.960 --> 15:00.960
very rare.

15:00.960 --> 15:06.720
So to date, they're only about 50 different fast radio bursts ever detected.

15:06.720 --> 15:12.200
And from one of these sources, there have been about 200 to 300 detection.

15:12.200 --> 15:18.600
So this is not a lot of samples to go off from a deep learning perspective.

15:18.600 --> 15:25.720
And therefore, simulation would be needed to greatly expand the positive examples.

15:25.720 --> 15:32.120
On the other hand, we do collect, in terms of spectrograms, we collect about petabyte

15:32.120 --> 15:35.000
per year of spectrograms.

15:35.000 --> 15:41.960
And there are many, many examples, there are terabytes and terabytes of interference, the

15:41.960 --> 15:44.840
signals that we don't want to pick up in this data.

15:44.840 --> 15:50.160
And by using the real background, the real interference background, and simulating

15:50.160 --> 15:57.000
on top of the, simulating fake signals on top of the interference background, we train

15:57.000 --> 16:02.960
the trained these networks to reject the signals that are actually interference and uninteresting.

16:02.960 --> 16:08.240
So that's one particular example how to look for signal that are rare, but we know what

16:08.240 --> 16:09.800
to look for.

16:09.800 --> 16:19.240
Sometimes we detect certain signals, and we don't exactly know if this signal is interesting.

16:19.240 --> 16:22.160
That requires a slightly different problem formulation.

16:22.160 --> 16:29.280
And that way, we have to first design a match filter, or we can design a machine learning

16:29.280 --> 16:33.360
algorithm to pick out these signals, then we do anomaly detection.

16:33.360 --> 16:39.000
So we do a future prediction type of anomaly detection, where based on the past observation,

16:39.000 --> 16:43.960
we try to predict the future observation, and then we compare against the real observation

16:43.960 --> 16:47.360
to see if there's any significant discrepancies.

16:47.360 --> 16:50.240
And if there is, then anomaly is triggered.

16:50.240 --> 16:55.800
And we will look at the signal more closely.

16:55.800 --> 17:04.360
There are also problems where we collected a great deal of signals, and we don't know exactly

17:04.360 --> 17:09.960
how to characterize them, whether they can be classified, or some of them maybe we can

17:09.960 --> 17:10.960
classify.

17:10.960 --> 17:19.640
And that could be treated as more of a semi-supervised clustering type of problem, where we try to

17:19.640 --> 17:25.880
characterize the signals and try to put them into different classes.

17:25.880 --> 17:35.360
In the case of the fast radio bursts work, is the idea that you're able to train a detector

17:35.360 --> 17:41.560
for these radio bursts, we then take that detector that you've trained and run it

17:41.560 --> 17:49.200
against the petabytes and petabytes of historical data to identify instances where it occurred

17:49.200 --> 17:55.040
before you started paying attention to it, or is it more just, you know, from now on we're

17:55.040 --> 17:59.800
going to start looking at these things by running this detector against them.

17:59.800 --> 18:05.080
This particular announcement was about, so a particular observation that we performed

18:05.080 --> 18:06.080
about a year ago.

18:06.080 --> 18:11.440
So for that observation, we collected about eight terabytes of spectrogram data that's now

18:11.440 --> 18:14.440
all open to public from our website.

18:14.440 --> 18:20.440
So in this observation, we previously had a match filtering technique that detected 21

18:20.440 --> 18:22.320
signals.

18:22.320 --> 18:30.160
And by training this network, we re-analyzed the same data and detected 72 more.

18:30.160 --> 18:34.480
So all of these detections were from the same source.

18:34.480 --> 18:39.320
So they have certain characteristics, they're all similar to each other, which made the

18:39.320 --> 18:44.800
design of the, both in terms of the problem formulation, what kind of resolution should

18:44.800 --> 18:51.720
I feed in the spectrogram in, you know, how many layers we should have to make the entire

18:51.720 --> 18:54.000
design a little simpler.

18:54.000 --> 18:57.240
We will also like to do both of those things that you suggested.

18:57.240 --> 19:04.800
One is to search blindly in all the archival data for similar signals.

19:04.800 --> 19:12.240
And another is to use this in the real-time serial for future service.

19:12.240 --> 19:18.600
Both of those will be a little more challenging, for example, one difficulty is the problem

19:18.600 --> 19:19.840
of scale.

19:19.840 --> 19:28.480
When you don't know, essentially, the curvature of this parabola, the signal could be even

19:28.480 --> 19:35.840
100 times longer than the signals we detected in this case, or it'd be much narrower, so

19:35.840 --> 19:36.840
on and so forth.

19:36.840 --> 19:45.760
And that requires sort of a multi-scale kind of input in order to have the same sensitivity

19:45.760 --> 19:48.920
across all of the parameter spaces.

19:48.920 --> 19:51.400
So that we haven't done yet.

19:51.400 --> 19:59.360
So you formulate your problem into one of these broad categories of identifying the patterns

19:59.360 --> 20:09.280
or doing anomaly detection, and then you have the two different types of data, the time

20:09.280 --> 20:13.680
series data, and the spectrogram data.

20:13.680 --> 20:16.800
Are there other things that you're doing?

20:16.800 --> 20:24.680
What are also you doing on the data processing side to before you are putting data into kind

20:24.680 --> 20:32.520
of, it sounds like you're using traditional, more or less, CNNs and those types of neural

20:32.520 --> 20:33.520
networks?

20:33.520 --> 20:34.520
Is that right?

20:34.520 --> 20:36.320
Right, right, right.

20:36.320 --> 20:44.800
So some of these require, so both in terms of the pre-processing, in terms of the future

20:44.800 --> 20:48.920
extraction, and in terms of the deep learning, depending on the problem, they're different

20:48.920 --> 20:50.320
uses.

20:50.320 --> 20:58.840
So for the fast radio burst work, we used a typical CNN, it was a residual network.

20:58.840 --> 21:03.760
For a anomaly detection, because there's a temporal component to it, we use a convolutional

21:03.760 --> 21:13.680
LSTN, and it's also trained in an adversarial way, like again, because the loss function

21:13.680 --> 21:18.720
when, so these spectrograms, they aren't image, there are two dimensional image data,

21:18.720 --> 21:21.080
but they are very, very noisy.

21:21.080 --> 21:27.880
So that makes direct comparison in terms of the pixel-wise L1 or L2 loss, that makes

21:27.880 --> 21:34.640
that not very useful, because noise, you cannot predict noise, right?

21:34.640 --> 21:42.120
So we use sort of adversarial loss to train these type of networks.

21:42.120 --> 21:50.120
For the clustering type, depending on, we want to be a robust, for example, to a variety

21:50.120 --> 21:58.000
of things, to how the signal was filtered on the analog side, and to how we processed

21:58.000 --> 22:05.640
them, and what was the fractional bandwidth to be robust to a wide range of parameter there.

22:05.640 --> 22:13.080
We do some feature space techniques, use some additional loss to regulate what the feature

22:13.080 --> 22:14.280
space looks like.

22:14.280 --> 22:20.840
We also try to use some of the adversarial techniques called domain transfers.

22:20.840 --> 22:25.880
These are the same techniques that people use to do.

22:25.880 --> 22:33.200
So if the training set, say, was rolled images taken during the day, how would you be able

22:33.200 --> 22:39.720
to do inference for when you, how would you be able to inference when your camera is recording

22:39.720 --> 22:40.720
at night, right?

22:40.720 --> 22:47.160
So to be able to cross this domain, we try some of the techniques that people develop

22:47.160 --> 22:51.360
in computer vision as well to do this, yeah.

22:51.360 --> 22:52.360
Okay.

22:52.360 --> 22:54.680
You mentioned GANS.

22:54.680 --> 22:58.480
Can you elaborate on what you're doing with GANS?

22:58.480 --> 23:05.480
So yeah, so the particular work I mentioned has an adversarial component to it.

23:05.480 --> 23:14.240
So again, the original GANS is meant to generate new data that conforms to the distribution

23:14.240 --> 23:16.680
of the data set.

23:16.680 --> 23:20.160
It's not quite exactly what we're doing.

23:20.160 --> 23:23.880
This is a future prediction type of network.

23:23.880 --> 23:29.000
So what we're trying to do is to give in the past observation predict what a future observation

23:29.000 --> 23:30.640
look like.

23:30.640 --> 23:34.600
So you will still want to compare this prediction with the actual observations.

23:34.600 --> 23:40.120
So in a way, this is a self-supervised type of technique.

23:40.120 --> 23:49.280
We use an adversarial loss in that the generator that we have that generates this future prediction,

23:49.280 --> 23:57.280
we also introduce a discriminator that looks at the real observation and the predicted observation

23:57.280 --> 23:59.520
and try to tell which one is which.

23:59.520 --> 24:07.760
And by having the generator trying to fool this discriminator, we essentially generate

24:07.760 --> 24:12.880
more realistic looking future predictions.

24:12.880 --> 24:20.200
And is this GAN operating like in the frequency domain, is it trying to predict spectrogram

24:20.200 --> 24:22.720
samples or something else?

24:22.720 --> 24:23.720
Right, right.

24:23.720 --> 24:28.800
So this was a convolutional LSTM that was making the prediction.

24:28.800 --> 24:32.160
So that's just the generator I is.

24:32.160 --> 24:36.280
The GAN component of this is just an additional term in the loss function.

24:36.280 --> 24:42.280
So the discriminator is a CNN that looks at the spectrogram that's predicted.

24:42.280 --> 24:46.360
You talked about domain transfer, domain adaptation.

24:46.360 --> 24:49.840
How are you approaching that in this use case?

24:49.840 --> 24:55.640
So the main idea of domain transfer is that when your training data has certain characteristics

24:55.640 --> 25:01.400
and your test set data is from a different distribution, you want to be able to correctly

25:01.400 --> 25:07.520
do inference on this new, slightly differently distributed data sets.

25:07.520 --> 25:15.440
I think this problem we face a lot in the radio frequency domain because the signals could

25:15.440 --> 25:22.360
potentially look very different if you, if a different sensor was used, if a different

25:22.360 --> 25:29.720
bandwidth was used, essentially the same signal can look completely different in the time

25:29.720 --> 25:36.400
domain, which may be the original, the data that was, that was feed-in, that was fed

25:36.400 --> 25:38.000
into the network.

25:38.000 --> 25:45.760
So we use these techniques to essentially do the same thing as a computer vision to be

25:45.760 --> 25:53.600
able to do inference more effectively in a domain that the training data was not collected

25:53.600 --> 25:54.600
on.

25:54.600 --> 26:04.200
And is this primarily happening at the kind of as feature pre-processing or adding, subtracting

26:04.200 --> 26:11.400
gain from your signal or applying filters or things like that, or is this stuff that's

26:11.400 --> 26:15.400
done in the training process?

26:15.400 --> 26:23.240
So this is done in the in the training process when we, so also we, for example, we use a

26:23.240 --> 26:29.920
lot of, we use a lot of simulated data because it's hard to collect ground truth labels for

26:29.920 --> 26:36.960
real data. And to, when, when we train with this loss function that, that has knowledge

26:36.960 --> 26:42.960
of what the, what the, the, the real data, the, essentially the target has looks like, but

26:42.960 --> 26:48.840
we don't know the labels, you can add this additional loss to the, to the training process

26:48.840 --> 26:55.120
so that the, the learned model is, is more aware of, of the target domain.

26:55.120 --> 27:00.480
I guess I'm trying to get a sense for how many features these models tend to have.

27:00.480 --> 27:04.480
Cute are they, you know, huge, very high dimension or not necessarily?

27:04.480 --> 27:16.720
That's a very good question. So, the, in some of my experiments in these type of classification

27:16.720 --> 27:21.600
and semi supervised clustering algorithms, we find that this type of domain adaptation

27:21.600 --> 27:29.440
we typically use on the, on the last layer, essentially. We, we find that around 128 features

27:29.440 --> 27:37.880
was probably was the most efficient in terms of using this technique. But that doesn't

27:37.880 --> 27:45.280
mean that this is a general statement about all of these applications. It could simply

27:45.280 --> 27:55.280
be the tackle signals that I was deploying this technique to classify, you know, roughly

27:55.280 --> 28:06.520
had many dimensions. So, I think there's still a, still an open question to, to, to the,

28:06.520 --> 28:10.920
the degree of variability in the number of features.

28:10.920 --> 28:17.920
In the, the fast radio burst paper, there was a mention of new periodicity search technique

28:17.920 --> 28:23.160
based on rally tests. Is that, is that related to machine learning or is that more kind of

28:23.160 --> 28:25.160
domain specific?

28:25.160 --> 28:31.120
I would say that's, that's more of a data mining technique that's not really machine learning.

28:31.120 --> 28:37.080
However, it is a technique that's new to the astronomy community. So, this is, so we,

28:37.080 --> 28:41.840
detected all these signals. And we would try to see one of the main questions we want

28:41.840 --> 28:47.080
to see is, is there any regularity? Do you see periodically appearing signals? And,

28:47.080 --> 28:53.840
because these signals come from very, very far away. So, the source, I should say for

28:53.840 --> 28:58.760
this particular signal has been localized in the dwarf galaxy. That's three billion

28:58.760 --> 29:05.240
liars away. So, and the signal, when they, when they come to us, many of them are very,

29:05.240 --> 29:11.400
very weak. So, we don't exactly know how many of the signals that was emitted was actually

29:11.400 --> 29:19.560
detected. And that makes searching for periodicity in, in the signal, relatively difficult. So,

29:19.560 --> 29:27.120
we, we use this technique based on the railings test to see if we can detect any periodisties.

29:27.120 --> 29:33.400
If not, if we can put a signal, significance level in terms of, they're not existing

29:33.400 --> 29:39.640
a periodicity. And, in the end, we went with a later one. It does not look like any of

29:39.640 --> 29:47.800
the periodicities that, in the range that physically was sensible, was a statistically

29:47.800 --> 29:51.240
good match for the data that we collected.

29:51.240 --> 29:58.480
So, what degree is the periodicity represented in the spectrograph? Like, I would have

29:58.480 --> 30:04.480
imagined that the frequency component, you know, the stronger frequency components would

30:04.480 --> 30:10.560
represent periodicity that is kind of readily apparent from the spectrograph. What does this

30:10.560 --> 30:17.920
technique do for you kind of beyond what is available via your Fourier transform types

30:17.920 --> 30:24.400
of techniques? Right, right, right. So, that's, that's a very bad question. So, in the, in the

30:24.400 --> 30:34.400
spectrograph domain, if you see a very regular period, then it will show up very clearly.

30:34.400 --> 30:41.520
So, in, in our case, these are very rare signals. So, in these six hours of observation around

30:41.520 --> 30:48.560
a petabytes of data, we have about 100 detections. So, these are very rare on very weak signals.

30:48.560 --> 30:57.280
So, similar techniques that have been applied to finding pulsars, which are radiobursts.

30:57.280 --> 31:04.560
There are some differences. Well, pulsars are, are, their source are situated within our galaxy,

31:04.560 --> 31:11.120
and most of them you can see clearly a regular period. And some of these techniques in spectrograph,

31:11.120 --> 31:15.200
that works on spectrographs could work there. But for us, because of the amount of noise

31:15.200 --> 31:23.600
as present, it's, it just was not nearly powerful enough to put a constraint. Got it, got it.

31:23.600 --> 31:29.600
Yeah. And I imagine that there's, I don't have the, the words for it, but I imagine that there's

31:29.600 --> 31:37.280
some notion of kind of a complex periodicity that's not, you know, just a regular time domain

31:37.280 --> 31:43.280
frequency, but maybe has other components that might be harder to detect, but still interesting.

31:43.280 --> 31:46.480
Is that something that you're able to detect in this data?

31:47.280 --> 31:52.480
Right, right. So, I mean, essentially, if you have, if you have many parameters,

31:52.480 --> 32:02.480
you can always fit the data, right? So, yeah, yeah. So, it's, that is one issue. And the way we,

32:02.480 --> 32:07.760
so, so, I should just mention some factor that could potentially cost this type of complex

32:07.760 --> 32:13.600
periodicity. One is, you know, the emission could not have been periodic, but maybe it was,

32:14.400 --> 32:19.760
you know, the emission itself was, was some of, was pseudo periodic. There was a window in which,

32:19.760 --> 32:26.160
through which the, the signal was emitted. And during the, during the propagation process,

32:27.200 --> 32:32.160
there could have been processes that made some of these, that delayed some of these signals more

32:32.160 --> 32:37.920
than the others. So, when they, by the time they arrive, they appear to, essentially, you smeared out

32:37.920 --> 32:44.320
any, any periodicity that was in, in at the time of emission. So, we don't exactly know,

32:45.920 --> 32:51.520
there are some physical, there are some models that are based on astrophysics, to model these

32:51.520 --> 32:59.440
more complex type of periodicities. There hasn't been enough evidence to support any of them. And

32:59.440 --> 33:06.160
even though we have the most amount of detections from a single observation, it still would not be

33:06.160 --> 33:14.560
able to constrain these models. So, what, what we did is to essentially put all the complexities

33:14.560 --> 33:21.200
in the same parameter. In, in our case, is the uncertainty is the uncertainty in the arrival times

33:22.480 --> 33:28.080
that we picked up. And, you know, all of these different models, they would map onto this

33:28.080 --> 33:34.160
uncertainty in a way. And we constrained, we, we derive a final constraint as a function of

33:34.160 --> 33:41.440
this uncertainty. And that way, this measurement could contribute to, to, to putting limits on

33:41.440 --> 33:49.280
these individual complex periodicity models. So, you see kind of in parallel to the application

33:49.280 --> 33:57.680
of machine learning and deep learning to astronomy, the application happening in domains like

33:57.680 --> 34:04.240
computer vision that's moving very quickly are there. Technique, and your, your, sounds like

34:04.240 --> 34:10.080
you're staying very well current to some of those techniques by applying gans and domain,

34:10.880 --> 34:16.240
transfer and things like that. Are there things that you're excited about happening outside of

34:17.520 --> 34:22.800
particular things that you're excited about happening outside of astronomy? Did you think we'll

34:22.800 --> 34:28.800
have big impacts on this field? Yeah, absolutely. So, I should say the, the radio frequency

34:30.720 --> 34:36.080
AI applied to radio frequency data is not only something that's done in astronomy.

34:37.040 --> 34:42.400
In recent years, there's, there's so a lot of interest in the defense sector as well as

34:42.400 --> 34:50.720
in telecommunications. And there are, there are a few companies that I know, mostly in Washington,

34:50.720 --> 34:56.480
DC area that, that specialize in this type of signal recognition. And for them,

34:57.440 --> 35:02.800
they want to be able to classify all the signals that they detect and see if there are any anomalies.

35:04.160 --> 35:11.040
For, for, for, for us in, in, in radial setting, we will also like to do that. They may not be

35:11.040 --> 35:17.920
the signals that we're looking for, but we, we typically, we will describe this as a, as a

35:17.920 --> 35:26.240
needle in a haystack, kind of a problem. And by classifying all of the signals,

35:26.240 --> 35:31.040
there are terrestrial signal communication signals. We're able to, we will be able to understand

35:31.040 --> 35:38.400
the hay in the problem very well. And this would help us narrow down or surge greatly in terms

35:38.400 --> 35:45.280
of understanding, you know, potentially interesting signals in our data. And are there

35:45.280 --> 35:54.160
things, are there techniques that are emerging or evolving in the broader, or out of the broader

35:54.160 --> 35:57.760
deep learning community that you see having a big impact in this area?

35:59.600 --> 36:04.480
Outside of deep learning. No, inside of, you know, within deep learning, but outside of

36:05.360 --> 36:12.400
the astronomy in particular. So, so, for example, these applications I mentioned are,

36:12.400 --> 36:20.400
our works that are in, they're engineering, more from engineering signal processing point of view.

36:20.400 --> 36:29.200
So, they are a bit outside of astronomy themselves. And in fact, we, we, we try to pay close attention

36:29.200 --> 36:39.120
to, to some of the recent progresses. It's, usually, I think, we're late enough to the game that

36:39.120 --> 36:46.560
they're still enough cherries to pick from well-established ideas. I think, you know, it could be,

36:46.560 --> 36:51.520
it's both a good thing and a bad thing. A good thing is that, you know, we do have a lot of

36:51.520 --> 36:56.640
established techniques that we can apply effectively by designing the problem appropriately.

36:57.360 --> 37:02.960
A difficult part is that, you know, the data was not collected with machine learning in mind.

37:02.960 --> 37:12.080
So, you know, the, first of all, there's not any labels and things have vastly different scales

37:12.080 --> 37:19.360
compared to one another. I think the, the putting the data in a form that's, that's suitable for,

37:19.360 --> 37:28.080
for these, you know, by this point, well-established ideas is, it's still a very fruitful effort, I think.

37:28.080 --> 37:32.320
Well, Jerry, thanks so much for taking the time to chat with us about what you're up to.

37:32.320 --> 37:35.440
It's very cool stuff. Great, yeah, thanks a lot for having me.

37:39.280 --> 37:44.160
All right, everyone, that's our show for today. For more information about today's show,

37:44.160 --> 37:50.400
visit twimmolai.com. Be sure to visit twimmolcan.com for information or to register for

37:50.400 --> 37:56.640
Twimmolcan AI platforms. Thanks again to C3 for their sponsorship of today's episode.

37:56.640 --> 38:04.240
To check out what they're up to, visit c3.ai. As always, thanks so much for listening and catch you next time.

