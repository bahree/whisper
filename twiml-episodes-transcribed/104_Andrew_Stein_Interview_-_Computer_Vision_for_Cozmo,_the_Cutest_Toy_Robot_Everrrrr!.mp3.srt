1
00:00:00,000 --> 00:00:16,120
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

2
00:00:16,120 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:29,320
I'm your host Sam Charrington.

4
00:00:29,320 --> 00:00:37,600
This week we have a jam-packed intro including a new contest we're launching, so please

5
00:00:37,600 --> 00:00:41,400
bear with me, you don't want to miss this one.

6
00:00:41,400 --> 00:00:44,720
First, a bit about this week's shows.

7
00:00:44,720 --> 00:00:49,400
As you may know, I spent a few days at CES earlier this month.

8
00:00:49,400 --> 00:00:54,240
While there, I spoke with a bunch of folks applying AI in the consumer electronics industry

9
00:00:54,240 --> 00:00:59,040
and I'm including you in those conversations via this series of shows.

10
00:00:59,040 --> 00:01:03,480
Stay tuned as we explore some of the very cool ways that machine learning and AI are being

11
00:01:03,480 --> 00:01:06,600
used to enhance our everyday lives.

12
00:01:06,600 --> 00:01:11,320
This includes work being done at Anki, who built Cosmo, the cutest little computer vision

13
00:01:11,320 --> 00:01:13,280
powered robot.

14
00:01:13,280 --> 00:01:18,840
Lighthouse, whose smart home security camera combines 3D sensing with deep learning and

15
00:01:18,840 --> 00:01:19,840
NLP.

16
00:01:19,840 --> 00:01:25,760
Intel, who's using the single shot multi-box image detection algorithm to personalize

17
00:01:25,760 --> 00:01:29,680
video fees for the Ferrari Challenge North America.

18
00:01:29,680 --> 00:01:34,480
First beat, a company whose machine learning algorithms analyzed your heartbeat data to

19
00:01:34,480 --> 00:01:40,360
provide personalized insights into stress, exercise, and sleep patterns.

20
00:01:40,360 --> 00:01:45,520
Reality AI and Coeto, who have partnered to bring machine learning based adaptive driving

21
00:01:45,520 --> 00:01:50,240
beams or automatically adjusting high beams to the U.S.

22
00:01:50,240 --> 00:01:57,480
In last but not least, aerial.ai, who applies sophisticated analytics to Wi-Fi signals to

23
00:01:57,480 --> 00:02:03,640
enable some really interesting home automation and healthcare applications.

24
00:02:03,640 --> 00:02:09,320
Now as if six amazing interviews wasn't enough, a few of these companies have been so kind

25
00:02:09,320 --> 00:02:13,520
as to provide us with products for you, the Twimal Community.

26
00:02:13,520 --> 00:02:18,280
In keeping with the theme of this series, our contest will be a little different this time.

27
00:02:18,280 --> 00:02:23,400
To enter, we want to hear from you about the role AI is playing in your home in personal

28
00:02:23,400 --> 00:02:26,640
life and where you see it going.

29
00:02:26,640 --> 00:02:33,240
Just head on over to Twimalai.com slash My AI Contest, fire up your webcam or smartphone

30
00:02:33,240 --> 00:02:37,120
camera and tell us your story in two minutes or less.

31
00:02:37,120 --> 00:02:41,600
We'll post the videos to YouTube and the video with the most likes wins their choice of

32
00:02:41,600 --> 00:02:48,120
great prizes including an Anki Cosmo, a lighthouse smart home camera, and more.

33
00:02:48,120 --> 00:02:53,160
The missions will be taken until February 11th and voting will remain open until February

34
00:02:53,160 --> 00:02:54,480
18th.

35
00:02:54,480 --> 00:03:00,160
Good luck.

36
00:03:00,160 --> 00:03:04,560
Before we dive into today's show, I'd like to thank our friends at Intel AI for their

37
00:03:04,560 --> 00:03:07,560
continued support of this podcast.

38
00:03:07,560 --> 00:03:12,800
Intel was extremely active at this year's CES, with a bunch of AI, autonomous driving

39
00:03:12,800 --> 00:03:15,240
and VR related announcements.

40
00:03:15,240 --> 00:03:18,960
One of the more interesting partnerships they announced was a collaboration with the

41
00:03:18,960 --> 00:03:22,720
Ferrari Challenge North America race series.

42
00:03:22,720 --> 00:03:27,440
Along with the folks at Ferrari Challenge, Intel AI aspires to make the race viewing experience

43
00:03:27,440 --> 00:03:33,720
more personalized by using deep computer vision to detect and monitor individual race cars

44
00:03:33,720 --> 00:03:38,840
via camera feeds and allow viewers to choose the specific cars feeds that they'd like

45
00:03:38,840 --> 00:03:40,880
to watch.

46
00:03:40,880 --> 00:03:45,800
Look for my conversation with Intel's Andy Keller and Emil Chindicki later in this series

47
00:03:45,800 --> 00:03:52,520
for an in-depth discussion about this project and be sure to visit ai.intel.com where you'll

48
00:03:52,520 --> 00:03:56,080
find Andy's technical blog post on the topic.

49
00:03:56,080 --> 00:03:59,360
And now a bit about today's show.

50
00:03:59,360 --> 00:04:04,800
In this episode, I'm joined by Andrew Stein, computer vision engineer at Anki and is partnering

51
00:04:04,800 --> 00:04:09,240
crime Cosmo, a toy robot with tons of personality.

52
00:04:09,240 --> 00:04:13,480
Andrew joined me during the hustle and bustle of CES a few weeks ago to give me some insight

53
00:04:13,480 --> 00:04:18,440
into how Cosmo works, plays and learns, and how he's different from other consumer robots

54
00:04:18,440 --> 00:04:20,680
you may know like the Roomba.

55
00:04:20,680 --> 00:04:25,920
We discussed the different types of algorithms that help power Cosmo, like facial identification,

56
00:04:25,920 --> 00:04:31,120
3D pose recognition, reasoning, and even some simple emotional AI.

57
00:04:31,120 --> 00:04:37,200
We also cover Cosmo's functionality and programmability, including a cool feature called CodeLab.

58
00:04:37,200 --> 00:04:41,640
This was a really fun interview and you should also check out the companion video on YouTube

59
00:04:41,640 --> 00:04:46,200
starring Cosmo himself, which of course will link to in the show notes page.

60
00:04:46,200 --> 00:04:53,200
Alright everyone, I am here at CES and I am with Andrew Stein.

61
00:04:53,200 --> 00:04:59,280
Andrew is a computer vision engineer at Anki and Anki is, well I'll let Andrew tell

62
00:04:59,280 --> 00:05:00,680
you all about Anki.

63
00:05:00,680 --> 00:05:03,280
Andrew, welcome to this weekend machine learning and AI.

64
00:05:03,280 --> 00:05:05,080
Thanks, thanks, it's cool to be here.

65
00:05:05,080 --> 00:05:09,120
Yeah, I can tell you a little bit about Anki's background and then a little bit about

66
00:05:09,120 --> 00:05:13,800
our products and Cosmo specifically.

67
00:05:13,800 --> 00:05:18,400
Anki is a consumer robotics company and we currently have two products that are both

68
00:05:18,400 --> 00:05:20,800
in the entertainment space.

69
00:05:20,800 --> 00:05:23,800
One is Anki Overdrive, which is a car racing game.

70
00:05:23,800 --> 00:05:27,920
It's been out for several years and you can control the cars from your phone and they

71
00:05:27,920 --> 00:05:31,840
can drive themselves and you play against them like you would play in a video game but instead

72
00:05:31,840 --> 00:05:35,040
of looking at a screen you've got actual cars driving around on a real track and you

73
00:05:35,040 --> 00:05:37,040
are living.

74
00:05:37,040 --> 00:05:41,080
And sort of along those same lines which in some sense is bringing a physical product

75
00:05:41,080 --> 00:05:42,080
to life.

76
00:05:42,080 --> 00:05:48,360
Cosmo is a little robot character like you would see on the big screen but brought to life

77
00:05:48,360 --> 00:05:49,360
and real.

78
00:05:49,360 --> 00:05:53,360
So the goal is to really try to take this little robot character, the kinds of things we've

79
00:05:53,360 --> 00:05:55,760
seen in movies but actually make a real one.

80
00:05:55,760 --> 00:06:00,640
And I think it's kind of a core tenant of the company is trying to bring physical products

81
00:06:00,640 --> 00:06:07,320
to life, trying to deliver on this promise of robotics and AI in consumer products.

82
00:06:07,320 --> 00:06:11,600
And specifically Cosmo is very focused on character and personality.

83
00:06:11,600 --> 00:06:14,920
So he can play little games with him, he can recognize your face, he can play little

84
00:06:14,920 --> 00:06:15,920
games.

85
00:06:15,920 --> 00:06:18,600
If you leave him alone he can sort of do his own thing, he has three little cubes that

86
00:06:18,600 --> 00:06:22,320
he can carry around and make stacks out of and they have lights on them, you can play

87
00:06:22,320 --> 00:06:23,320
games with them.

88
00:06:23,320 --> 00:06:25,120
And also he gets a little feisty doesn't he?

89
00:06:25,120 --> 00:06:27,800
Yes he has a lot of personality and that is a big part of it.

90
00:06:27,800 --> 00:06:36,280
So I would say that we're half core robotics company with all the tech that goes with robotics

91
00:06:36,280 --> 00:06:41,480
which is very multi-disciplinary, it brings together a lot of different disciplines.

92
00:06:41,480 --> 00:06:46,640
And we all add to that whole team of animators and character designers who are focused on

93
00:06:46,640 --> 00:06:51,360
the character of Cosmo, who is he and what is his personality and what does he like?

94
00:06:51,360 --> 00:06:55,560
And that's sort of another big part of the company and the experience and I think that's

95
00:06:55,560 --> 00:06:58,400
what's sort of cool about the company is bringing those two sides of things together.

96
00:06:58,400 --> 00:06:59,400
Wow, wow.

97
00:06:59,400 --> 00:07:00,880
And you work on computer vision.

98
00:07:00,880 --> 00:07:05,960
Can you tell us a little bit about your background and how you got involved in CV?

99
00:07:05,960 --> 00:07:06,960
Sure.

100
00:07:06,960 --> 00:07:12,240
So going way back in undergrad, for whatever reason I took a class, I think it was

101
00:07:12,240 --> 00:07:15,080
might have been a graduate level class but it sounded cool on computer vision.

102
00:07:15,080 --> 00:07:16,080
Okay.

103
00:07:16,080 --> 00:07:19,040
Really liked the professor, he ended up working with him as a sort of an undergraduate

104
00:07:19,040 --> 00:07:25,360
researcher and stayed and did a master's degree there at Georgia Tech and had always enjoyed

105
00:07:25,360 --> 00:07:30,440
like working with robotics, I actually had a job in high school doing robotics for sorting

106
00:07:30,440 --> 00:07:34,080
hangard garments actually, both giant industrial robots.

107
00:07:34,080 --> 00:07:39,480
And those two things I think both kind of struck a chord with me and then went to Carnegie

108
00:07:39,480 --> 00:07:43,720
Mellon to pursue my PhD in robotics and focused on computer vision there.

109
00:07:43,720 --> 00:07:44,720
Okay.

110
00:07:44,720 --> 00:07:50,160
And so how does computer vision fit into Cosmo, like Cosmo is so small, I don't even see

111
00:07:50,160 --> 00:07:51,160
a camera anywhere.

112
00:07:51,160 --> 00:07:52,160
Yes, a new one.

113
00:07:52,160 --> 00:07:55,360
It has actually in his face, if you look at him, the little hole there that kind of looks

114
00:07:55,360 --> 00:08:01,160
like a mouth is his camera, so creepily enough he has his eye in his mouth.

115
00:08:01,160 --> 00:08:06,680
But yeah, so it's a pretty core piece of the robot because it's really his main input,

116
00:08:06,680 --> 00:08:09,000
his main source of sensor input.

117
00:08:09,000 --> 00:08:14,840
So cameras are by their nature a very data rich source of information and they're also

118
00:08:14,840 --> 00:08:16,960
very inexpensive, so that's a good combination.

119
00:08:16,960 --> 00:08:21,320
So he is, that's his primary way of sensing the world is through vision.

120
00:08:21,320 --> 00:08:25,640
So that's how he knows where his cubes are, he can see them, he estimates their poses

121
00:08:25,640 --> 00:08:30,120
in three dimensions very accurately so that he can pick them up, stack them.

122
00:08:30,120 --> 00:08:36,840
He can perceive motion and he also sees faces, both human faces and cat and dog faces.

123
00:08:36,840 --> 00:08:40,200
And beyond detecting faces, he can also learn to recognize human faces so you can teach

124
00:08:40,200 --> 00:08:42,000
him your name and he'll remember you.

125
00:08:42,000 --> 00:08:43,320
Oh wow.

126
00:08:43,320 --> 00:08:49,000
What some of the technologies that go into making this happen from a CV and an algorithmic

127
00:08:49,000 --> 00:08:50,000
perspective?

128
00:08:50,000 --> 00:08:51,000
Sure.

129
00:08:51,000 --> 00:08:54,280
And face detection is certainly a big one face detection, face recognition.

130
00:08:54,280 --> 00:08:57,640
There's a lot of sort of proprietary stuff around how we do the 3D pose estimation of

131
00:08:57,640 --> 00:08:59,600
the cubes.

132
00:08:59,600 --> 00:09:06,720
There's intelligent reasoning about, given the geometry we know of the robot and the specifics

133
00:09:06,720 --> 00:09:09,600
of the camera, which we know, the intrinsic parameters of the camera, we can do things

134
00:09:09,600 --> 00:09:12,720
like reason about the ground plane in front of the robot, even though he doesn't have a

135
00:09:12,720 --> 00:09:17,080
depth sensor, we can start reasoning about the ground plane in front of him, which turns

136
00:09:17,080 --> 00:09:19,240
out to be pretty powerful.

137
00:09:19,240 --> 00:09:23,600
And then we'll layer on top of this, right, all these lots of other technologies including

138
00:09:23,600 --> 00:09:27,520
sort of low-level motor controls, path planning.

139
00:09:27,520 --> 00:09:31,880
And has they used the word AI because or the acronym AI, it's still overloaded at this

140
00:09:31,880 --> 00:09:32,880
point.

141
00:09:32,880 --> 00:09:33,880
Yeah.

142
00:09:33,880 --> 00:09:38,840
But sort of the AI behind how Cosmo models his emotional state and how that drives what

143
00:09:38,840 --> 00:09:41,040
behavior he chooses to do at any moment.

144
00:09:41,040 --> 00:09:43,640
Like I said, he is sort of, if you leave him alone, he is sort of on his own.

145
00:09:43,640 --> 00:09:46,200
You're not remote controlling this robot, he's his character.

146
00:09:46,200 --> 00:09:50,440
So what makes him decide to do, you know, A or B at any given moment, and how do we keep

147
00:09:50,440 --> 00:09:51,440
that making sense?

148
00:09:51,440 --> 00:09:56,560
It can't just be random and it can't also can't be scripted, so how to drive that behavior

149
00:09:56,560 --> 00:09:57,560
system?

150
00:09:57,560 --> 00:10:01,520
Well, let's maybe start with the computer vision stuff.

151
00:10:01,520 --> 00:10:05,840
You know, there are lots of ways to do computer vision, traditional stuff and convolution

152
00:10:05,840 --> 00:10:06,840
on neural nets.

153
00:10:06,840 --> 00:10:07,840
They're obviously very popular.

154
00:10:07,840 --> 00:10:13,400
When I look at this thing and think about like the, you know, price point power, stuff

155
00:10:13,400 --> 00:10:16,120
like that, I'm guessing that you're not running.

156
00:10:16,120 --> 00:10:20,320
You know, there's another reason for that, actually, which people tend to forget, given

157
00:10:20,320 --> 00:10:22,200
how popular they are in the news now.

158
00:10:22,200 --> 00:10:26,520
So this product actually started before we even launched Drive, which was back in 2013.

159
00:10:26,520 --> 00:10:30,080
So I was the first person working on the product, there was nobody else doing anything

160
00:10:30,080 --> 00:10:31,080
yet.

161
00:10:31,080 --> 00:10:32,080
There was no code yet.

162
00:10:32,080 --> 00:10:33,080
Okay.

163
00:10:33,080 --> 00:10:36,480
There was also no really no, you know, okay, so I shouldn't say there was no deporting

164
00:10:36,480 --> 00:10:40,280
because neural nets have been around a long time, but there was no, the revolution if

165
00:10:40,280 --> 00:10:41,880
I, if you will, hadn't occurred yet.

166
00:10:41,880 --> 00:10:43,480
We forget that we're still at that level.

167
00:10:43,480 --> 00:10:44,480
It's so early.

168
00:10:44,480 --> 00:10:45,480
Right.

169
00:10:45,480 --> 00:10:46,480
There's a lot of flow that didn't exist yet.

170
00:10:46,480 --> 00:10:47,480
Right.

171
00:10:47,480 --> 00:10:50,880
Like all these things people are, you know, so familiar with now and it wasn't even around

172
00:10:50,880 --> 00:10:51,880
yet.

173
00:10:51,880 --> 00:10:57,680
So yeah, I'm what's known as a classically trained computer vision, which is kind of ridiculous.

174
00:10:57,680 --> 00:11:01,320
So yeah, we certainly, when we started all this and started picking hardware and nailing

175
00:11:01,320 --> 00:11:07,120
down price points and what sort of processing power he was going to have, we actually did

176
00:11:07,120 --> 00:11:11,680
start to do a lot of the vision on board, but again, with more classical techniques, you

177
00:11:11,680 --> 00:11:15,040
know, for face detection, more things more like Vila Joe and space detection.

178
00:11:15,040 --> 00:11:16,040
Like what?

179
00:11:16,040 --> 00:11:17,040
Vila Jones.

180
00:11:17,040 --> 00:11:18,320
It's sort of a classical way of doing face.

181
00:11:18,320 --> 00:11:19,320
What is that?

182
00:11:19,320 --> 00:11:26,000
It's a means of progressively filtering an image with more and more very, very simple,

183
00:11:26,000 --> 00:11:32,160
simply designed filters that are very, very fast in order to Vila cascade sort of rule

184
00:11:32,160 --> 00:11:38,040
things out slowly over time, but be very efficient and eventually learn the pattern in the image,

185
00:11:38,040 --> 00:11:42,720
it's basically looking at local contrast patterns in the image that look like a face, works

186
00:11:42,720 --> 00:11:44,840
very well and it's still often used today.

187
00:11:44,840 --> 00:11:46,760
So that's the kind of thing that we would use.

188
00:11:46,760 --> 00:11:50,280
Face or no face or is it what allows you to identify individual people?

189
00:11:50,280 --> 00:11:51,280
Can you guys?

190
00:11:51,280 --> 00:11:52,280
So yeah, that is face or no face.

191
00:11:52,280 --> 00:11:55,960
So that's what I would call face detection and then I would, I would contrast that with

192
00:11:55,960 --> 00:11:58,760
face recognition, which is given a face who is it?

193
00:11:58,760 --> 00:11:59,760
Okay.

194
00:11:59,760 --> 00:12:00,760
Exactly.

195
00:12:00,760 --> 00:12:04,440
So anyway, we sort of started by doing that in the market detection, trying to do it on

196
00:12:04,440 --> 00:12:05,640
the robot.

197
00:12:05,640 --> 00:12:08,800
We were able to get actually quite far with that, but at some point realized, okay, this

198
00:12:08,800 --> 00:12:10,280
is just, this is just too limiting.

199
00:12:10,280 --> 00:12:13,840
We always knew there would be a companion app the same way that there is overdrive.

200
00:12:13,840 --> 00:12:19,240
And at some point we decided, all right, we're going to take the punch and just put all

201
00:12:19,240 --> 00:12:21,160
of the smarts really in the device.

202
00:12:21,160 --> 00:12:26,000
So the way the product works is that you have an app that connects to, you connect your

203
00:12:26,000 --> 00:12:31,000
device to Cosmos, Wi-Fi, hotspot, and he's actually streaming his images to your device

204
00:12:31,000 --> 00:12:34,880
and all of the computer vision, path planning, et cetera, is actually happening on your

205
00:12:34,880 --> 00:12:35,880
device.

206
00:12:35,880 --> 00:12:36,880
Oh, interesting.

207
00:12:36,880 --> 00:12:40,080
And that's what, again, as you pointed out, that's what allows us to sell it at a price

208
00:12:40,080 --> 00:12:42,320
point and a scale that we're able to.

209
00:12:42,320 --> 00:12:46,960
Otherwise, especially given hardware from three plus years ago, there's just no way we

210
00:12:46,960 --> 00:12:50,400
could have gotten all the capability on the robot.

211
00:12:50,400 --> 00:12:51,400
Right, right.

212
00:12:51,400 --> 00:12:56,720
Is there some limited ability to operate if the, you know, so your iPad runs out of battery

213
00:12:56,720 --> 00:12:57,720
or something like that?

214
00:12:57,720 --> 00:13:00,360
Is it able to go into some kind of autonomous mode?

215
00:13:00,360 --> 00:13:01,360
Very, very little.

216
00:13:01,360 --> 00:13:03,400
So I mean, you sort of like shut himself down.

217
00:13:03,400 --> 00:13:05,760
We try not to just have them die.

218
00:13:05,760 --> 00:13:09,680
But it really is quite tied to the device because so much of it lives there.

219
00:13:09,680 --> 00:13:13,720
All the animation, in fact, so we've been talking a lot about the animation, but the animations

220
00:13:13,720 --> 00:13:19,040
that play on him, the sound, his facial animations are also actually all stored on the device.

221
00:13:19,040 --> 00:13:20,040
Oh, really?

222
00:13:20,040 --> 00:13:22,920
So while those are streaming to him, his images are streaming back to the device, so there's

223
00:13:22,920 --> 00:13:24,240
a lot of data going back and forth.

224
00:13:24,240 --> 00:13:25,240
Oh, wow.

225
00:13:25,240 --> 00:13:27,240
Now I should say it's all within that network.

226
00:13:27,240 --> 00:13:28,640
There's no cloud, anything.

227
00:13:28,640 --> 00:13:29,640
Yeah.

228
00:13:29,640 --> 00:13:30,640
So this is sort of a closed network.

229
00:13:30,640 --> 00:13:31,640
And that's Bluetooth or?

230
00:13:31,640 --> 00:13:32,640
That's pure Wi-Fi.

231
00:13:32,640 --> 00:13:33,640
Pure Wi-Fi.

232
00:13:33,640 --> 00:13:37,360
Yeah, the problem with Bluetooth, which is actually what we use for overdrive, is just bandwidth

233
00:13:37,360 --> 00:13:41,440
to send, we couldn't stream the images at full-frame rate over Bluetooth.

234
00:13:41,440 --> 00:13:45,040
So the rollback controls we could, but the actual image data we couldn't.

235
00:13:45,040 --> 00:13:46,040
Okay.

236
00:13:46,040 --> 00:13:50,880
So you started looking at, for the image detection, the VL and Norbert.

237
00:13:50,880 --> 00:13:51,880
The VL and Jones.

238
00:13:51,880 --> 00:13:52,880
VL and Jones.

239
00:13:52,880 --> 00:13:54,880
Well, I'm more thinking of Norbert.

240
00:13:54,880 --> 00:13:55,880
Oh, man.

241
00:13:55,880 --> 00:13:56,880
Yeah.

242
00:13:56,880 --> 00:14:02,760
Well, we should, that's a new algorithm, we'll have to develop it ourselves.

243
00:14:02,760 --> 00:14:08,000
And so is that what you ended up doing on the device, or now that you have access to

244
00:14:08,000 --> 00:14:11,560
the device, you're able to do more sophisticated things?

245
00:14:11,560 --> 00:14:16,600
That's, I mean, without going into too much detail, that's basically what's running for

246
00:14:16,600 --> 00:14:17,600
the detection.

247
00:14:17,600 --> 00:14:19,440
But cubes is a completely different thing.

248
00:14:19,440 --> 00:14:24,080
Those are detected via a sort of proprietary method that both allows us to detect the

249
00:14:24,080 --> 00:14:28,040
cubes and then estimate their pose in 3D.

250
00:14:28,040 --> 00:14:31,880
And then again, that's super important because his little fingers that he has to get in

251
00:14:31,880 --> 00:14:34,520
the little slots to pick up the cubes, you know, there's only a couple of millimeters

252
00:14:34,520 --> 00:14:35,520
of slot there.

253
00:14:35,520 --> 00:14:39,120
And we've got a robot driving around on treads and treads are really hard to model.

254
00:14:39,120 --> 00:14:43,800
So the way he moves, we really have to be able to get feedback constantly about where

255
00:14:43,800 --> 00:14:47,720
the cube actually is so that we can drive him accurately and pick up the cubes.

256
00:14:47,720 --> 00:14:50,960
That was just a huge part of the project for a very long time, was just how do we make

257
00:14:50,960 --> 00:14:52,360
this thing pick up cubes?

258
00:14:52,360 --> 00:14:53,360
Wow.

259
00:14:53,360 --> 00:14:56,920
Can you understanding that it's a proprietary approach?

260
00:14:56,920 --> 00:15:02,080
Can you give us some analogies that help us understand, you know, what are the technical

261
00:15:02,080 --> 00:15:08,840
challenges beyond, you know, obviously the precision that you just imagined.

262
00:15:08,840 --> 00:15:12,920
You know, what are some of the kind of algorithmic approaches you looked at before you went

263
00:15:12,920 --> 00:15:17,320
down the path of needing to roll your own, you know, what might you consider if you

264
00:15:17,320 --> 00:15:18,320
are starting again?

265
00:15:18,320 --> 00:15:19,320
That kind of thing.

266
00:15:19,320 --> 00:15:24,960
Well, so the obvious thing if you look at these cubes is probably maybe a QR code.

267
00:15:24,960 --> 00:15:29,880
So it's sort of along those lines, there's one big reason we didn't go QR code is the

268
00:15:29,880 --> 00:15:30,880
appearance.

269
00:15:30,880 --> 00:15:34,320
And, you know, we are a tech company, we're building technical products, but there's

270
00:15:34,320 --> 00:15:37,360
a big design component to this, how the robot looks, how he behaves and what we wanted

271
00:15:37,360 --> 00:15:43,360
the cubes to look like and stylistically, nobody liked the QR codes, they just, they

272
00:15:43,360 --> 00:15:45,520
sort of screamed the wrong thing for the product.

273
00:15:45,520 --> 00:15:49,720
So one of the things we wanted to develop was a similar idea that allowed us to encode

274
00:15:49,720 --> 00:15:54,560
information on the sides of the cubes that gave him information, but that gave us aesthetic

275
00:15:54,560 --> 00:15:56,760
control over what they looked like.

276
00:15:56,760 --> 00:16:01,640
And so it's a similar idea to QR codes in some sense, but with the sort of aesthetic

277
00:16:01,640 --> 00:16:02,880
component.

278
00:16:02,880 --> 00:16:09,040
And then as far as estimating the 3D pose, what it effectively comes down to is that we

279
00:16:09,040 --> 00:16:13,280
know points on the cube, points on the marker that are on the side of the cube, and we know

280
00:16:13,280 --> 00:16:18,640
the intrinsic calibration of the camera, basically it's focal length.

281
00:16:18,640 --> 00:16:21,920
And that's a whole other interesting issue, we have to calibrate every robot individually

282
00:16:21,920 --> 00:16:24,320
in the factory to get that.

283
00:16:24,320 --> 00:16:29,160
And given those two things, we can see where those known 3D locations on the cube project

284
00:16:29,160 --> 00:16:30,160
into the image.

285
00:16:30,160 --> 00:16:35,360
So once we find them in the image, and we know the 3D shape they belong to via that correspondence

286
00:16:35,360 --> 00:16:40,920
and some math, you can sort of back out where that 3D object must be in order to have projected

287
00:16:40,920 --> 00:16:42,600
that pattern.

288
00:16:42,600 --> 00:16:45,600
And the 3D points that you're referring to are...

289
00:16:45,600 --> 00:16:50,360
So any of that, sort of anything, no decals, or anything we know, you could use anything

290
00:16:50,360 --> 00:16:54,280
really, but you just want a very accurate notification on the cube.

291
00:16:54,280 --> 00:17:00,320
So you've got these known graphics, we can call them codes, they're not QR codes.

292
00:17:00,320 --> 00:17:06,920
When you look at them, you think that these are just graphical flourishes, but you look

293
00:17:06,920 --> 00:17:10,560
more closely, and you can see that each of the sides is unique, and there can be some

294
00:17:10,560 --> 00:17:11,560
better information.

295
00:17:11,560 --> 00:17:12,560
Well, don't over notice that.

296
00:17:12,560 --> 00:17:15,840
It's one of the challenges of designing them is that we had competing goals.

297
00:17:15,840 --> 00:17:18,880
One was that we wanted all sides of the cube to sort of look the same, so that this cube

298
00:17:18,880 --> 00:17:22,720
had sort of one marker on it, but we also wanted Cosmo to be able to tell the difference

299
00:17:22,720 --> 00:17:26,800
from the different sides, because he can control the lights, and we want to know which

300
00:17:26,800 --> 00:17:28,200
light he's turning on, for example.

301
00:17:28,200 --> 00:17:29,560
Oh, yeah, I didn't even notice that.

302
00:17:29,560 --> 00:17:30,560
So this is your...

303
00:17:30,560 --> 00:17:32,040
So the other is four lights on top.

304
00:17:32,040 --> 00:17:33,040
Okay.

305
00:17:33,040 --> 00:17:36,920
But I was also noticing that this cube in the middle is kind of like your paperclip cube.

306
00:17:36,920 --> 00:17:38,680
Yeah, that's exactly what I see.

307
00:17:38,680 --> 00:17:42,320
That one looks like kind of a stack of things.

308
00:17:42,320 --> 00:17:44,320
Everybody's got their own, what they see in these things.

309
00:17:44,320 --> 00:17:45,320
They were a shark.

310
00:17:45,320 --> 00:17:46,320
Or a shark.

311
00:17:46,320 --> 00:17:47,320
Exactly.

312
00:17:47,320 --> 00:17:51,440
This one looks like a baby and a fetal pose.

313
00:17:51,440 --> 00:17:52,440
Yes.

314
00:17:52,440 --> 00:17:53,440
That's a common one, too.

315
00:17:53,440 --> 00:17:55,680
It is funny when people see these things, yeah.

316
00:17:55,680 --> 00:18:01,640
It was hard because part of the design here was, I guess if we wanted to aesthetic component,

317
00:18:01,640 --> 00:18:06,960
but we also at the time we were walking down, making all the hardware, we didn't necessarily

318
00:18:06,960 --> 00:18:09,440
want to commit ourselves to a particular meaning.

319
00:18:09,440 --> 00:18:13,640
So you know, if you made it the treasure chest cube, it's like, well, it does everything

320
00:18:13,640 --> 00:18:14,640
you do.

321
00:18:14,640 --> 00:18:16,640
It does with the cube, you have to relate some out of it treasure chest.

322
00:18:16,640 --> 00:18:19,840
You didn't want to get too much iconography.

323
00:18:19,840 --> 00:18:23,440
So yeah, these are sort of these general purpose designs.

324
00:18:23,440 --> 00:18:26,720
The challenge that we sort of realized later is that exactly what you just experienced

325
00:18:26,720 --> 00:18:29,560
is how to refer to them is very technical.

326
00:18:29,560 --> 00:18:30,560
Yeah.

327
00:18:30,560 --> 00:18:33,400
Customers carry, you know, when they get a call about a cube or something, they're always

328
00:18:33,400 --> 00:18:36,760
like, right, there's actually a number engraved in there that you can find so you can actually

329
00:18:36,760 --> 00:18:37,760
get one.

330
00:18:37,760 --> 00:18:39,720
Well, obviously, it would have been like make them different colors.

331
00:18:39,720 --> 00:18:42,160
Did that mess up your algorithms or something?

332
00:18:42,160 --> 00:18:43,160
No, no.

333
00:18:43,160 --> 00:18:44,160
Color would have been okay.

334
00:18:44,160 --> 00:18:45,160
I think again, it's just from a design perspective.

335
00:18:45,160 --> 00:18:46,680
I think they wanted them to match more.

336
00:18:46,680 --> 00:18:47,680
Yeah.

337
00:18:47,680 --> 00:18:48,680
Yeah.

338
00:18:48,680 --> 00:18:49,680
Interesting.

339
00:18:49,680 --> 00:18:53,280
And so I understand for the people that are listening that this is a very visual conversation.

340
00:18:53,280 --> 00:18:54,280
Yeah.

341
00:18:54,280 --> 00:18:55,280
So I'm talking about computer vision.

342
00:18:55,280 --> 00:18:56,280
Yeah.

343
00:18:56,280 --> 00:18:57,280
Exactly.

344
00:18:57,280 --> 00:19:03,720
So we'll definitely, I'm going to, at the very minimum, include some pictures of what

345
00:19:03,720 --> 00:19:08,620
we're talking about on the show notes page, but I'm more likely, or as well, going to maybe

346
00:19:08,620 --> 00:19:14,040
shoot some video of this thing in action and post it up on, up on our YouTube channel.

347
00:19:14,040 --> 00:19:17,800
One thing that often, I think, surprises people after hearing it, talked about or referred

348
00:19:17,800 --> 00:19:20,120
to, I don't think they realize how small it is.

349
00:19:20,120 --> 00:19:21,120
I didn't either.

350
00:19:21,120 --> 00:19:22,120
I was really surprised.

351
00:19:22,120 --> 00:19:23,120
So I like to bring one.

352
00:19:23,120 --> 00:19:27,400
Generally people, I think, imagine him much larger, but for the listeners, he's actually

353
00:19:27,400 --> 00:19:32,000
sort of fits in the size of your palm of your hand, so he's quite tiny.

354
00:19:32,000 --> 00:19:34,400
And that's for a couple of reasons.

355
00:19:34,400 --> 00:19:38,640
One is actually maybe non-obvious, which is for him to have the personality he does and

356
00:19:38,640 --> 00:19:43,000
to move around as fast as he does to exhibit that personality and be, you know, sort of cute

357
00:19:43,000 --> 00:19:45,400
and playful, he has to move quickly.

358
00:19:45,400 --> 00:19:49,600
And if you build a heavy big robot, you know, if his little lifter here moved too fast

359
00:19:49,600 --> 00:19:51,920
and you got your finger in there, you would actually hurt yourself.

360
00:19:51,920 --> 00:19:56,000
So in some sense, there's a safety component to it.

361
00:19:56,000 --> 00:19:59,760
But also, it's also just part of his personality.

362
00:19:59,760 --> 00:20:01,240
It makes sense for him to be cute.

363
00:20:01,240 --> 00:20:02,240
It's sort of big.

364
00:20:02,240 --> 00:20:03,240
It's too big.

365
00:20:03,240 --> 00:20:06,520
And we have, I mean, I don't remember if it's 40 or 60 or something, different design

366
00:20:06,520 --> 00:20:08,200
iterations on this thing.

367
00:20:08,200 --> 00:20:12,320
And some of them were much bigger and the smaller ones always went out.

368
00:20:12,320 --> 00:20:14,520
It just feels right for him to be in the palm of your hand.

369
00:20:14,520 --> 00:20:19,520
And then that, in turn, sort of, has impact on the way the sound design is done.

370
00:20:19,520 --> 00:20:21,800
What should he sound like given how big he is?

371
00:20:21,800 --> 00:20:25,480
The difficult side, of course, is really for the manufacturing and mechanical engineers

372
00:20:25,480 --> 00:20:30,480
to squeeze in all the 300 and something parts into this tiny little robot.

373
00:20:30,480 --> 00:20:32,520
There's like no free space inside that thing.

374
00:20:32,520 --> 00:20:33,520
I can imagine.

375
00:20:33,520 --> 00:20:35,360
I can imagine.

376
00:20:35,360 --> 00:20:38,920
So we were talking about the size of the thing of the cubes.

377
00:20:38,920 --> 00:20:43,160
So you've got these, and this kind of algorithm is kind of interesting.

378
00:20:43,160 --> 00:20:47,840
So you've got these, you know, each of the cubes has six sides.

379
00:20:47,840 --> 00:20:54,920
It has kind of a QR code like thing that is a consistent design element for each cube.

380
00:20:54,920 --> 00:20:58,800
And then this thing can look at a cube.

381
00:20:58,800 --> 00:21:03,480
And it is probably relatively easy to identify if a cube is in the frame.

382
00:21:03,480 --> 00:21:09,120
And then it can kind of pick out the, you know, the kind of infer the angle of the different

383
00:21:09,120 --> 00:21:11,520
sides that it's able to see.

384
00:21:11,520 --> 00:21:17,720
And from that kind of figure out, you can create a model, a model like a projection I'm

385
00:21:17,720 --> 00:21:18,720
thinking of that.

386
00:21:18,720 --> 00:21:19,720
Exactly.

387
00:21:19,720 --> 00:21:21,360
This project of geometry is what it all comes down to.

388
00:21:21,360 --> 00:21:22,360
Okay.

389
00:21:22,360 --> 00:21:26,400
The projection of 3D points onto the 2D plane of the image, and given we know what the

390
00:21:26,400 --> 00:21:27,400
3D points are.

391
00:21:27,400 --> 00:21:28,400
And you can back your control.

392
00:21:28,400 --> 00:21:29,400
Figure out, okay.

393
00:21:29,400 --> 00:21:30,400
Exactly.

394
00:21:30,400 --> 00:21:31,400
You can rotate your translation.

395
00:21:31,400 --> 00:21:32,400
Yep.

396
00:21:32,400 --> 00:21:33,400
Okay.

397
00:21:33,400 --> 00:21:38,720
So you would feed that into whatever like like classical control algorithms to make it,

398
00:21:38,720 --> 00:21:40,320
you know, move to the thing, lift it up and get it.

399
00:21:40,320 --> 00:21:41,320
Yeah.

400
00:21:41,320 --> 00:21:43,800
Plan a path into a known location with respect to that cube.

401
00:21:43,800 --> 00:21:47,240
And then yeah, it's sort of a control problem of, as I'm driving forward, make sure I keep

402
00:21:47,240 --> 00:21:51,240
it in the right place until I think my fingers get in there and pick it up.

403
00:21:51,240 --> 00:21:52,240
Yeah.

404
00:21:52,240 --> 00:21:53,840
That's just amazingly sophisticated for this little.

405
00:21:53,840 --> 00:21:54,840
Yeah.

406
00:21:54,840 --> 00:21:55,840
People don't understand how hard that is.

407
00:21:55,840 --> 00:21:58,360
One of the things that I think actually is pretty interesting about this, and it's,

408
00:21:58,360 --> 00:22:02,720
I think more for robotics geeks than, than, the average consumer is that one of the

409
00:22:02,720 --> 00:22:08,640
things that holds robotics back from doing more and more, I think, consumer products is

410
00:22:08,640 --> 00:22:12,200
manipulation, is the ability to change the world around you.

411
00:22:12,200 --> 00:22:16,960
It's still a very, very hard problem both mechanically and from sort of an AI standpoint, from

412
00:22:16,960 --> 00:22:19,160
a software standpoint.

413
00:22:19,160 --> 00:22:24,160
So I would argue this is sort of the first little mobile manipulator, especially at this

414
00:22:24,160 --> 00:22:25,160
scale and this price point.

415
00:22:25,160 --> 00:22:29,800
I mean, Roomba's are effectively a manipulator in that they suck up stuff, so they're doing

416
00:22:29,800 --> 00:22:30,800
some work.

417
00:22:30,800 --> 00:22:36,000
But, you know, Cosmo can actually do this very hard problem of driving up, picking up a,

418
00:22:36,000 --> 00:22:39,680
picking up a cube and then stacking on top of another cube and that's, it's not an easy

419
00:22:39,680 --> 00:22:40,680
thing to do.

420
00:22:40,680 --> 00:22:41,520
It is definitely an easy thing to do.

421
00:22:41,520 --> 00:22:45,280
The other half though that may not be obvious, it's definitely not obvious, about the

422
00:22:45,280 --> 00:22:46,280
cubes.

423
00:22:46,280 --> 00:22:50,120
So not only do they have lights, they also have an accelerometer inside of them.

424
00:22:50,120 --> 00:22:56,400
So Cosmo talks to them over a radio connection, which is kind of like Bluetooth.

425
00:22:56,400 --> 00:23:00,320
And that allows him to know via the accelerometer if the cube has moved.

426
00:23:00,320 --> 00:23:02,640
So if I pick him the cube, he's aware.

427
00:23:02,640 --> 00:23:06,640
And what that means is that if, so if I've seen the cube and I've estimated it's 3D

428
00:23:06,640 --> 00:23:12,040
pose with respect to the robot, and the cube doesn't move, now I can also do the reverse.

429
00:23:12,040 --> 00:23:14,800
If I drive around and Cosmo's, all right, pick up Cosmo and put it in.

430
00:23:14,800 --> 00:23:15,960
You can open a Cosmo based on that.

431
00:23:15,960 --> 00:23:19,320
Once he sees the cube again, if it hasn't moved, he now knows his position with respect

432
00:23:19,320 --> 00:23:22,960
to the cube, which means he now knows his position with respect to the old map he was

433
00:23:22,960 --> 00:23:23,960
building.

434
00:23:23,960 --> 00:23:28,440
So he, it's something that I think people tend to forget is it's not just like pure stimulus

435
00:23:28,440 --> 00:23:29,440
response.

436
00:23:29,440 --> 00:23:32,280
You face, whatever, he's remembering all of this, right?

437
00:23:32,280 --> 00:23:34,720
He's keeping up with the 3D poses of the cubes.

438
00:23:34,720 --> 00:23:37,560
He's keeping up with where you are in space once he sees you.

439
00:23:37,560 --> 00:23:38,800
And there's just big reasons for that.

440
00:23:38,800 --> 00:23:40,360
It makes him look smarter.

441
00:23:40,360 --> 00:23:45,440
It allows him to do behaviors which turn out to be super important.

442
00:23:45,440 --> 00:23:50,080
So for example, if right before he decides he's going to go pick up this cube and he

443
00:23:50,080 --> 00:23:54,320
knows you're, you know, off to his right, he might stop and do the same thing a little

444
00:23:54,320 --> 00:23:57,920
kid does, which is look, look up, look up at you and make sure you're watching him.

445
00:23:57,920 --> 00:24:03,280
And that little moment of eye contact makes it more about this, this sort of interactive

446
00:24:03,280 --> 00:24:06,520
experience where you're drawn in and he, you know, you're very aware that, oh, he knows

447
00:24:06,520 --> 00:24:07,520
I'm here.

448
00:24:07,520 --> 00:24:11,320
As opposed to, I'm just a spectator watching a robot pick up a cube.

449
00:24:11,320 --> 00:24:13,520
It's like, oh, Cosmonose, I'm watching him.

450
00:24:13,520 --> 00:24:18,720
And that little bit of the mixture of sort of that technical component, that technical

451
00:24:18,720 --> 00:24:23,800
capability with the character and personality, I think is a really good example of like,

452
00:24:23,800 --> 00:24:25,640
how this starts to fit together.

453
00:24:25,640 --> 00:24:26,800
Interesting.

454
00:24:26,800 --> 00:24:32,640
So you kind of, you didn't actually literally use air quotes when you said AI with related

455
00:24:32,640 --> 00:24:39,160
with relation to the personality, but, you know, clearly there's a connection between,

456
00:24:39,160 --> 00:24:43,800
you know, the way we think about AI and, you know, the idea of personality.

457
00:24:43,800 --> 00:24:47,880
Like, what are some of the, you know, how are you doing that?

458
00:24:47,880 --> 00:24:52,360
What are some of the approaches to give a personality personality?

459
00:24:52,360 --> 00:24:53,360
Yeah.

460
00:24:53,360 --> 00:24:59,640
But maybe I mentioned there's a, there's this notion of Cosmo having emotion.

461
00:24:59,640 --> 00:25:03,400
So he does, we do internally model his emotional state.

462
00:25:03,400 --> 00:25:10,640
You know, how happy versus sad it is, how calm versus anxious he is, how socialized versus

463
00:25:10,640 --> 00:25:11,640
lonely he is.

464
00:25:11,640 --> 00:25:14,840
I don't remember those are all the same words we actually use in the code, but he effectively

465
00:25:14,840 --> 00:25:20,360
has the set of traits or properties which are changing all the time and different things

466
00:25:20,360 --> 00:25:22,360
that happen to Cosmo affect them.

467
00:25:22,360 --> 00:25:27,040
So another good example involving faces is that, you know, he's sort of designed to be

468
00:25:27,040 --> 00:25:29,080
a social, friendly robot.

469
00:25:29,080 --> 00:25:34,280
And so he, we've sort of, you know, defined his personality to be one that enjoys, you

470
00:25:34,280 --> 00:25:35,800
know, being surrounded by people.

471
00:25:35,800 --> 00:25:38,880
So if he's driving around for a long time, he doesn't see anyone.

472
00:25:38,880 --> 00:25:42,520
At some point his, his loneliness may creep up.

473
00:25:42,520 --> 00:25:46,200
And once it gets high enough, it may trigger him to switch into a behavior which is look

474
00:25:46,200 --> 00:25:48,280
for faces because he's, he's lonely.

475
00:25:48,280 --> 00:25:51,680
So he'll, he'll, that'll, that'll change him to a mode where now he keeps, he's keeping

476
00:25:51,680 --> 00:25:55,680
his head tilted up and he's looking around and he, you know, he's not distracted by

477
00:25:55,680 --> 00:25:56,680
his cubes or whatever.

478
00:25:56,680 --> 00:25:58,400
He wants to find a person.

479
00:25:58,400 --> 00:25:59,560
He's a person.

480
00:25:59,560 --> 00:26:04,240
And now that sort of triggers an emotional change where his, his social, his socialization

481
00:26:04,240 --> 00:26:07,520
goes up and his, his loneliness goes back down.

482
00:26:07,520 --> 00:26:09,760
That allows him to switch out of the behavior and do something else.

483
00:26:09,760 --> 00:26:15,480
So that's sort of an idea of what I was referring to earlier of preventing it from being either

484
00:26:15,480 --> 00:26:20,440
just random behaviors, which, right, over time you can tell his random or being fully scripted

485
00:26:20,440 --> 00:26:21,800
which also doesn't feel natural.

486
00:26:21,800 --> 00:26:26,480
So it is in response to what's been happening and what is currently happening to him.

487
00:26:26,480 --> 00:26:34,080
Is there a notion of like a kind of a long-term personality, meaning the thing that came

488
00:26:34,080 --> 00:26:38,960
to mind is like the Microsoft Tay Chapat, they got trained by, you know, Twitter to be,

489
00:26:38,960 --> 00:26:41,480
you know, a Nazi, right?

490
00:26:41,480 --> 00:26:47,680
Like if you, you know, if you ignore your Cosmo long enough, like will it become like permanently

491
00:26:47,680 --> 00:26:48,680
sad or something like that?

492
00:26:48,680 --> 00:26:49,680
It's a very good example.

493
00:26:49,680 --> 00:26:54,400
You hit exactly, so the answer is no, you hit exactly the reason.

494
00:26:54,400 --> 00:26:59,200
We were concerned, like what happens if you just, your robot ends up like irreparably depressed.

495
00:26:59,200 --> 00:27:00,920
It's not, it's not really what we wanted.

496
00:27:00,920 --> 00:27:06,440
And we felt like what we were trying to create was there is a definition we have of who

497
00:27:06,440 --> 00:27:08,000
Cosmo is and what his personality is.

498
00:27:08,000 --> 00:27:10,200
We have, you know, character designers who that is their job.

499
00:27:10,200 --> 00:27:13,240
They are the owner of what, who is Cosmo?

500
00:27:13,240 --> 00:27:15,080
What are his motivations and these sorts of questions?

501
00:27:15,080 --> 00:27:16,680
And it's not, it's not, it's Cosmo.

502
00:27:16,680 --> 00:27:17,680
It's not my Cosmo.

503
00:27:17,680 --> 00:27:21,320
Like when I take it, take it out of the box, there's not like a random seed that, or, you

504
00:27:21,320 --> 00:27:26,080
know, something that on us, maybe more continuous than a random seed, but that says, you know,

505
00:27:26,080 --> 00:27:30,080
this is, you know, my Cosmo's personality is more Cosmo's personality.

506
00:27:30,080 --> 00:27:33,080
And I think that's something we're interested in exploring, but at this point, right, the,

507
00:27:33,080 --> 00:27:36,000
sort of the, what I would call the personality is more fixed.

508
00:27:36,000 --> 00:27:37,000
Yeah.

509
00:27:37,000 --> 00:27:38,000
We're in more control of that.

510
00:27:38,000 --> 00:27:42,440
The mood, I would call it, which is more transient, is what you're controlling by what you do

511
00:27:42,440 --> 00:27:43,440
with them.

512
00:27:43,440 --> 00:27:46,880
You know, if you keep falling on the floor, or, yeah, if he doesn't see me by for a while,

513
00:27:46,880 --> 00:27:48,800
again, he might get, might get lonely.

514
00:27:48,800 --> 00:27:53,280
Those sorts of things, but they don't, they don't exhibit sort of a long-term effect,

515
00:27:53,280 --> 00:27:56,720
but because it can be very hard to control, like, wait, what, where does that go?

516
00:27:56,720 --> 00:27:59,920
And so, yeah, we sort of, I think, we're a little cautious about that.

517
00:27:59,920 --> 00:28:00,920
Okay.

518
00:28:00,920 --> 00:28:05,880
And so you kind of, you know, on one end, you've got, you know, random on another end,

519
00:28:05,880 --> 00:28:10,560
you've got totally scripted, you know, imagining somewhere in the middle is like a state

520
00:28:10,560 --> 00:28:14,040
machine that's sufficiently complex, that it doesn't seem like either of the two, is

521
00:28:14,040 --> 00:28:15,040
it kind of like that?

522
00:28:15,040 --> 00:28:16,040
Yeah.

523
00:28:16,040 --> 00:28:17,320
I think that's a fair, that's a fair comparison.

524
00:28:17,320 --> 00:28:22,080
There are sort of, there are sort of predefined behaviors, and, and for example, games that

525
00:28:22,080 --> 00:28:25,560
he can play, which themselves are little state machines, which are, which are very much

526
00:28:25,560 --> 00:28:26,560
engineered.

527
00:28:26,560 --> 00:28:31,160
And the look for faces thing, right, like, he didn't sort of, we didn't learn that

528
00:28:31,160 --> 00:28:34,240
behavior of how to look for exactly, okay, what, what it means is you need to look

529
00:28:34,240 --> 00:28:38,800
up and kind of look around in this way, and those things sort of are sort of tuned.

530
00:28:38,800 --> 00:28:44,200
So yeah, I think, looking at it as a state machine, where the transitions between states

531
00:28:44,200 --> 00:28:48,520
are very much driven by not only his sensor input, but also the sort of underlying motion

532
00:28:48,520 --> 00:28:51,640
engine is sort of good to think about it.

533
00:28:51,640 --> 00:28:55,520
You know, I guess one of the questions that jumps out to me as, you know, as a geek, I

534
00:28:55,520 --> 00:28:57,680
guess, is like, is this thing programmable?

535
00:28:57,680 --> 00:29:02,560
Can I like, you know, try to, can I use it as an experimentation platform?

536
00:29:02,560 --> 00:29:03,560
Absolutely.

537
00:29:03,560 --> 00:29:07,160
That's actually one of the, one thing that I'm super excited about that we have done

538
00:29:07,160 --> 00:29:09,720
with the product, and actually we did from day one.

539
00:29:09,720 --> 00:29:12,400
So when we launched it, Cosmo comes with an SDK.

540
00:29:12,400 --> 00:29:13,400
Okay.

541
00:29:13,400 --> 00:29:16,400
So in fact, not everyone realizes it, but in the app that you used to talk to Cosmo, if

542
00:29:16,400 --> 00:29:19,840
you go to settings and you scroll over, there's a button which says enable SDK, everybody

543
00:29:19,840 --> 00:29:21,640
has this out of the box.

544
00:29:21,640 --> 00:29:27,160
So you enable the SDK, you plug your device into your computer over USB, and then you

545
00:29:27,160 --> 00:29:28,560
can program in with Python.

546
00:29:28,560 --> 00:29:33,600
And it is an extremely full-featured and ever-expanding SDK.

547
00:29:33,600 --> 00:29:36,320
It's actually totally incredible all the things you can do.

548
00:29:36,320 --> 00:29:41,320
Having done a PhD in robotics on, you know, sort of research platforms which cost tens

549
00:29:41,320 --> 00:29:47,600
of thousands of dollars, usually broken, the fact that this $179 robot allows you to do,

550
00:29:47,600 --> 00:29:52,320
you know, totally low-level motion control or motor control all the way up to just flip

551
00:29:52,320 --> 00:29:57,000
on face recognition and just use it and path planning is crazy.

552
00:29:57,000 --> 00:30:01,120
And it's designed for, you know, six-year-olds, so it can fall off the table and not break.

553
00:30:01,120 --> 00:30:03,720
So it is an awesome programming platform.

554
00:30:03,720 --> 00:30:10,000
It's actually being used both at Carnegie Mellon and Georgia Tech, I guess, both my alumni.

555
00:30:10,000 --> 00:30:15,240
In their programming classes, both at undergrad and graduate level, we've got some cool, I can't

556
00:30:15,240 --> 00:30:19,400
think of the name right now of programming camps in the summer.

557
00:30:19,400 --> 00:30:22,760
They're starting to adopt Cosmo as their platform.

558
00:30:22,760 --> 00:30:28,840
And so, in concert with all this, so I've mentioned the SDK, you know, that's sort of full-blown,

559
00:30:28,840 --> 00:30:34,840
geek-level robotics program you can do as a sort of an expert, but, you know, someone

560
00:30:34,840 --> 00:30:38,480
at a graduate or undergraduate level or someone who really knows Python.

561
00:30:38,480 --> 00:30:42,200
People, by the way, are also writing, creating movies with him online by scripting him with

562
00:30:42,200 --> 00:30:43,880
the SDK, which is really cute.

563
00:30:43,880 --> 00:30:44,880
Oh, really?

564
00:30:44,880 --> 00:30:46,880
Yeah, there's actually a whole YouTube channel.

565
00:30:46,880 --> 00:30:49,960
Oh, yeah, there's a life with Cosmo is one worth checking out.

566
00:30:49,960 --> 00:30:55,280
It's really, really, really creative videos done with him, super impressive stuff.

567
00:30:55,280 --> 00:30:57,080
And it's all through the SDK.

568
00:30:57,080 --> 00:31:01,040
So it's really cool to see both, it used for research and also for creative outlets like

569
00:31:01,040 --> 00:31:02,040
that.

570
00:31:02,040 --> 00:31:03,040
Yeah.

571
00:31:03,040 --> 00:31:08,600
But so, beyond that, there's a whole bunch of other stuff, which is scratch-based programming.

572
00:31:08,600 --> 00:31:16,040
So scratch is a drag-and-drop block-based visual programming language developed by MIT

573
00:31:16,040 --> 00:31:17,040
and Google.

574
00:31:17,040 --> 00:31:21,400
In the last summer, we actually released an early version of that where you could effectively

575
00:31:21,400 --> 00:31:22,400
sequence the robots.

576
00:31:22,400 --> 00:31:26,440
You had a few very basic blocks and you could sort of, you know, do things like drive

577
00:31:26,440 --> 00:31:32,800
straight, turn right, look up, you could do fun things like wait until you see face smiling.

578
00:31:32,800 --> 00:31:36,480
So you could actually have Cosmo do, you know, drive straight, look up, and then sit there,

579
00:31:36,480 --> 00:31:38,600
and then once you saw face smiling, you would proceed to the next block.

580
00:31:38,600 --> 00:31:40,640
So you could do fun little programs like that.

581
00:31:40,640 --> 00:31:42,680
And that was meant for the other end of the spectrum.

582
00:31:42,680 --> 00:31:45,840
People have never written a line of code, have no idea about it, and it teaches you how

583
00:31:45,840 --> 00:31:49,480
to break a problem down into steps, how to write a sequence of, you know, how to sequence

584
00:31:49,480 --> 00:31:53,760
that, and some of the basics that you can do with a robot.

585
00:31:53,760 --> 00:31:58,400
So now, at that point, we had sort of the very beginning end of the spectrum and the, you

586
00:31:58,400 --> 00:32:02,240
know, the sort of graduate level, programming level, end of the spectrum.

587
00:32:02,240 --> 00:32:07,720
And last fall, we actually released what we call code lab, which took that early version

588
00:32:07,720 --> 00:32:10,720
of scratch and added to another mode, which is more advanced.

589
00:32:10,720 --> 00:32:14,280
So we have what we call now sandbox mode and constructor mode.

590
00:32:14,280 --> 00:32:18,720
And for listeners who know those basically correspond to horizontal and vertical grammar

591
00:32:18,720 --> 00:32:20,040
and scratch.

592
00:32:20,040 --> 00:32:23,280
Horizontal is sort of sequencing and vertical allows you to actually do branching in loops

593
00:32:23,280 --> 00:32:26,280
and more complex structures, but still visually.

594
00:32:26,280 --> 00:32:29,960
So we took code lab constructor and really basically enabled almost anything you could do

595
00:32:29,960 --> 00:32:34,240
in the SDK, but in drag and drop programming with both.

596
00:32:34,240 --> 00:32:38,800
So it's actually, the first time I used it, I was kind of blown away at how easy it was

597
00:32:38,800 --> 00:32:42,200
and how much you could build, how quickly you could do math in there, you can do, you know,

598
00:32:42,200 --> 00:32:45,920
vertical operations, you can really do whatever it's got, you know, trig functions in it,

599
00:32:45,920 --> 00:32:47,120
you can do whatever you want.

600
00:32:47,120 --> 00:32:53,120
So now we sort of have this full spectrum of, you know, very beginner level drag and

601
00:32:53,120 --> 00:32:58,120
drop sequencing to really full blown programming with, but still with drag and drop blocks, so

602
00:32:58,120 --> 00:32:59,520
that you can kind of see how that works.

603
00:32:59,520 --> 00:33:03,040
And then, you know, once you're, once you're sort of comfortable there, you could easily

604
00:33:03,040 --> 00:33:06,560
transition into Python and understand how to, how to write code there.

605
00:33:06,560 --> 00:33:12,800
So it's a really nice transition and to sort of move that along in code lab, we've also

606
00:33:12,800 --> 00:33:18,080
reached, released these featured products or projects and we're continuing to do that.

607
00:33:18,080 --> 00:33:22,920
So it's cool because we can build a little fun activity with code lab, but in the app,

608
00:33:22,920 --> 00:33:25,760
it comes up as a little, you know, icon, you open it up, oh, this sounds fun.

609
00:33:25,760 --> 00:33:29,400
You can play it, it's a little game or a little activity like making Cosmo play different

610
00:33:29,400 --> 00:33:33,920
instruments when you tap on the blocks, for example, all written in code lab.

611
00:33:33,920 --> 00:33:36,800
And the cool thing is there's a button on all of them that says, see inside.

612
00:33:36,800 --> 00:33:42,480
So you click that button and then it actually shows you the full scratch block based program.

613
00:33:42,480 --> 00:33:45,280
And you can sort of see like, oh, now I see how they did that.

614
00:33:45,280 --> 00:33:49,240
And you can customize it or whatever, but it's sort of like the old way we all learned

615
00:33:49,240 --> 00:33:53,400
to write web pages is the source and like, oh, I see how they did that.

616
00:33:53,400 --> 00:33:57,280
And so it's, it's again, a really cool way to kind of dive in and get some ideas for

617
00:33:57,280 --> 00:33:59,280
what's, what's possible.

618
00:33:59,280 --> 00:34:07,960
Now, with the SDK and the scratch piece, you mentioned a little of a motor control.

619
00:34:07,960 --> 00:34:12,600
Can you also get a feed of the images and like try to, you know, say you want to play

620
00:34:12,600 --> 00:34:14,600
with your own facial recognition?

621
00:34:14,600 --> 00:34:15,600
Yeah, absolutely.

622
00:34:15,600 --> 00:34:20,360
And the SDK, yeah, you can get the image feed, a little harder to do that in scratch to

623
00:34:20,360 --> 00:34:21,360
display it.

624
00:34:21,360 --> 00:34:22,920
That's something that I think is worth exploring.

625
00:34:22,920 --> 00:34:27,640
But yes, in the SDK, absolutely, we've had people do that, you know, people who are computer

626
00:34:27,640 --> 00:34:31,180
vision researchers in grad school who want a robot, they don't want to deal with the path

627
00:34:31,180 --> 00:34:32,180
planning part of it, right?

628
00:34:32,180 --> 00:34:33,180
Right.

629
00:34:33,180 --> 00:34:36,600
I found the thing and I know it's an obstacle in 3D and I want to drive a path around it.

630
00:34:36,600 --> 00:34:37,600
I'm focused on the vision.

631
00:34:37,600 --> 00:34:38,600
I don't care about the path planning.

632
00:34:38,600 --> 00:34:41,800
They can use the path planning, but they get the right image feed and they can do their

633
00:34:41,800 --> 00:34:42,800
own detection.

634
00:34:42,800 --> 00:34:47,200
So people have done, there's been interesting work like taking Cosmos image feed and running

635
00:34:47,200 --> 00:34:51,800
it through, you know, some of the popular deep learning networks and learning to recognize

636
00:34:51,800 --> 00:34:52,800
objects and things.

637
00:34:52,800 --> 00:34:55,840
Again, they have the power of a whole laptop to run it on.

638
00:34:55,840 --> 00:34:59,200
But yeah, we've seen people do some really interesting projects and we have a very active

639
00:34:59,200 --> 00:35:01,080
developer form on our website.

640
00:35:01,080 --> 00:35:05,160
People post this kind of stuff all the time and we've had really, really great response.

641
00:35:05,160 --> 00:35:06,160
Huh.

642
00:35:06,160 --> 00:35:07,160
Interesting.

643
00:35:07,160 --> 00:35:13,280
So what's next for the, you know, either this product or the company, like, is it building

644
00:35:13,280 --> 00:35:18,160
on this as a platform or coming out with the next, you know, the next robot or the next

645
00:35:18,160 --> 00:35:19,160
thing?

646
00:35:19,160 --> 00:35:20,160
Yes, yes and yes.

647
00:35:20,160 --> 00:35:24,760
You know, it's not so much I can say about too far down the road, but I will say, yes,

648
00:35:24,760 --> 00:35:28,680
we're adding, we're definitely expanding Cosmos capabilities.

649
00:35:28,680 --> 00:35:32,080
We want to be able to, you know, see and understand more.

650
00:35:32,080 --> 00:35:37,800
And a lot of that, a lot of the user-facing stuff in the near future is focused around

651
00:35:37,800 --> 00:35:38,800
code lab.

652
00:35:38,800 --> 00:35:43,640
One of the benefits of having this code lab universe where we have these projects is that

653
00:35:43,640 --> 00:35:46,960
it also makes it easier for us to release new content.

654
00:35:46,960 --> 00:35:51,400
We don't need a C++ developer who knows all about robotics to write a new little fun

655
00:35:51,400 --> 00:35:52,400
activity.

656
00:35:52,400 --> 00:35:58,200
We're going to have a designer, a game developer who may not be as much of a hardcore coder,

657
00:35:58,200 --> 00:36:02,240
but has a cool idea, right, and they can drag and drop box and make a project and that

658
00:36:02,240 --> 00:36:03,400
can be part of the app.

659
00:36:03,400 --> 00:36:04,840
We can also take user content.

660
00:36:04,840 --> 00:36:09,080
So we can send us your content, you can share your projects and, you know, cool stuff

661
00:36:09,080 --> 00:36:10,600
that actually is neat.

662
00:36:10,600 --> 00:36:13,160
We might actually deploy with the next version of the app.

663
00:36:13,160 --> 00:36:18,600
So there's a lot of stuff around code lab coming and there are new things coming in the

664
00:36:18,600 --> 00:36:23,560
Cosmic Protocol, which I can't say too much about, and then I guess long-term, I would

665
00:36:23,560 --> 00:36:27,680
go back to saying how at the beginning, I said we're a consumer robotics company, I

666
00:36:27,680 --> 00:36:30,360
didn't say we were a toy company.

667
00:36:30,360 --> 00:36:34,920
We're currently focused in entertainment, and that's very deliberate for a couple of

668
00:36:34,920 --> 00:36:35,920
reasons.

669
00:36:35,920 --> 00:36:43,080
One, we felt that, to develop the capabilities we needed both technically and from a manufacturing

670
00:36:43,080 --> 00:36:46,880
scale and price point perspective, this was a good place for us to start building an

671
00:36:46,880 --> 00:36:52,240
actual product that we could sell and market and build a successful company on as opposed

672
00:36:52,240 --> 00:36:55,080
to jumping to the far end of like, we're going to have a humanoid in your home and it's

673
00:36:55,080 --> 00:36:56,280
going to clean your house.

674
00:36:56,280 --> 00:36:57,280
Right.

675
00:36:57,280 --> 00:36:59,040
Yeah, and how are we going to fund that company, right?

676
00:36:59,040 --> 00:37:04,240
So they're trying to keep an eye on building a business at the same time and how to take

677
00:37:04,240 --> 00:37:08,840
steps, you know, sort of build products of stepping stones as we build out core technologies

678
00:37:08,840 --> 00:37:13,720
and core capabilities to get to those big fancy robots everybody wants.

679
00:37:13,720 --> 00:37:18,480
It seems like a lot of the companies in this space take that approach in some way, shape

680
00:37:18,480 --> 00:37:19,480
or form.

681
00:37:19,480 --> 00:37:23,320
Like, I robots got, you know, we know them for the vacuum cleaner, but they've got, you

682
00:37:23,320 --> 00:37:30,080
know, a lot of government robots and defense robots and I'm sure they're kind of eyeing

683
00:37:30,080 --> 00:37:34,160
this, you know, the home robotics market and as that grows and creates opportunities.

684
00:37:34,160 --> 00:37:39,560
Yeah, I think that, and that's, you know, I think it's a necessary, a necessary thing.

685
00:37:39,560 --> 00:37:44,080
People often, you know, that everyone sees what the stuff in movies and TV, right, and

686
00:37:44,080 --> 00:37:45,080
that's where they want.

687
00:37:45,080 --> 00:37:46,080
Right.

688
00:37:46,080 --> 00:37:49,320
But, you know, despite all the headlines about AI and deep learning, et cetera, we're still

689
00:37:49,320 --> 00:37:50,320
a long way off.

690
00:37:50,320 --> 00:37:51,320
Yeah.

691
00:37:51,320 --> 00:37:56,920
And so I think, you know, being careful about building that technology out in a very deliberate

692
00:37:56,920 --> 00:38:02,440
manner and creating products along the way that make good products themselves is important.

693
00:38:02,440 --> 00:38:05,040
Because, you know, to us, a robot is not a product.

694
00:38:05,040 --> 00:38:06,040
It is a technology.

695
00:38:06,040 --> 00:38:07,040
Right.

696
00:38:07,040 --> 00:38:11,080
It's a installation of technologies to gather which make a product, but you still need a

697
00:38:11,080 --> 00:38:12,640
product idea.

698
00:38:12,640 --> 00:38:17,720
And I think to that, to that end, it's not only are we trying to build those technologies,

699
00:38:17,720 --> 00:38:20,760
the other thing that we feel is important, you know, we like to say sort of not only

700
00:38:20,760 --> 00:38:25,720
is the IQ of the robot important, the techie smart AI, but the EQ is also important.

701
00:38:25,720 --> 00:38:28,480
We're going to build these robots and they're going to be living in our homes and that is

702
00:38:28,480 --> 00:38:29,480
our goal.

703
00:38:29,480 --> 00:38:31,000
We want a robot in every home.

704
00:38:31,000 --> 00:38:35,680
Those robots, we don't want them to be weird appliances that sit off in the corner that,

705
00:38:35,680 --> 00:38:36,680
right.

706
00:38:36,680 --> 00:38:39,160
It's this strange thing that you don't interact with.

707
00:38:39,160 --> 00:38:40,920
It's, we've seen this with Cosmo.

708
00:38:40,920 --> 00:38:45,320
It's a really interesting moment when you make eye contact with the robot or you assign

709
00:38:45,320 --> 00:38:49,360
personality to it or, you know, have a bond with it and we definitely see it with this

710
00:38:49,360 --> 00:38:51,640
little robot.

711
00:38:51,640 --> 00:38:52,640
It's a whole different experience.

712
00:38:52,640 --> 00:38:59,440
And so I think that expertise we're building and how to take things we know about movies

713
00:38:59,440 --> 00:39:04,200
and character design and deploy them in hardware and deal with that side of the human robot

714
00:39:04,200 --> 00:39:09,960
interaction piece of the puzzle is also super important and I think will, you know, be important

715
00:39:09,960 --> 00:39:12,160
for all our products in the future.

716
00:39:12,160 --> 00:39:18,880
Are there any kind of learnings that you can kind of encapsulate for us on, I guess,

717
00:39:18,880 --> 00:39:25,640
the intersection of AI and consumer electronics or like, you know, the challenges of putting

718
00:39:25,640 --> 00:39:30,880
AI and consumer electronics in this podcast, we talk a lot about, you know, enterprise-y stuff

719
00:39:30,880 --> 00:39:37,160
and industrial robots and things like that and I'm wondering about, you know, the specifics

720
00:39:37,160 --> 00:39:43,080
of, you know, AI and, you know, games and entertainment and toys and electronics and that kind

721
00:39:43,080 --> 00:39:44,080
of thing.

722
00:39:44,080 --> 00:39:45,080
Yeah.

723
00:39:45,080 --> 00:39:49,240
I think a few things, consumers don't actually care about, I mean, I think your listeners

724
00:39:49,240 --> 00:39:53,920
do and I do, but at large, consumers don't care about the actual tech, right?

725
00:39:53,920 --> 00:39:54,920
Yeah.

726
00:39:54,920 --> 00:39:55,920
Yeah.

727
00:39:55,920 --> 00:39:57,920
They just wanted to work and be cool and we all walk around cell phones and I'm talking

728
00:39:57,920 --> 00:40:00,560
how many people have any idea how that technology works, right?

729
00:40:00,560 --> 00:40:04,320
It's ridiculous what we do every day on our cell phones, but people just want like it

730
00:40:04,320 --> 00:40:09,720
to do all that awesome stuff and I think that is one thing is, you, as engineers working

731
00:40:09,720 --> 00:40:13,240
on their product, I have to remember, computer vision is not the product.

732
00:40:13,240 --> 00:40:18,280
There's a product and it has goals and computer vision is in service of those goals, not

733
00:40:18,280 --> 00:40:19,280
the other way around.

734
00:40:19,280 --> 00:40:26,320
So we often, you know, it don't use sort of the latest and greatest tech or idea because

735
00:40:26,320 --> 00:40:29,200
it's like, well, can the users are going to be able to tell if we're doing that?

736
00:40:29,200 --> 00:40:32,080
Like, what is the actual end result of using that technology?

737
00:40:32,080 --> 00:40:36,320
So I think keeping a mind that, you know, in the consumer space, you're building a consumer

738
00:40:36,320 --> 00:40:40,680
product, you're not necessarily building a technology that's sort of B2B and will be

739
00:40:40,680 --> 00:40:45,520
used in other products and keeping that, that end goal in mind is probably one of the

740
00:40:45,520 --> 00:40:46,520
big ones.

741
00:40:46,520 --> 00:40:50,600
I think another big thing about using AI and particularly, you know, everything over

742
00:40:50,600 --> 00:40:55,400
the last in years is about probabilistic reasoning, effectively, right?

743
00:40:55,400 --> 00:41:01,140
And people want a yes or a no or a guaranteed, it's going to work in these cases and it

744
00:41:01,140 --> 00:41:02,240
won't work in those cases.

745
00:41:02,240 --> 00:41:06,880
And if there's anything we know, it's that you, it's very hard to nail that down.

746
00:41:06,880 --> 00:41:11,200
You can say it's based on our data, it's going to work 95% of the time.

747
00:41:11,200 --> 00:41:14,880
Well, like enumerating the 5% of the cases, you can't do it.

748
00:41:14,880 --> 00:41:18,920
And so a lot of what we spend our time doing is, you know, it's, it's sort of easy to get

749
00:41:18,920 --> 00:41:21,320
the early prototype of the cool behavior.

750
00:41:21,320 --> 00:41:28,760
So what do you do in the weird edge case and 5% of the time that it doesn't work, situations,

751
00:41:28,760 --> 00:41:30,320
all those edge cases are really complicated.

752
00:41:30,320 --> 00:41:34,640
You know, we have kid picks up a robot, right, in the middle of behavior X or animation

753
00:41:34,640 --> 00:41:35,640
Y.

754
00:41:35,640 --> 00:41:36,640
It's like, okay, wait.

755
00:41:36,640 --> 00:41:37,640
So what happens then?

756
00:41:37,640 --> 00:41:40,760
And, you know, just enumerating all possible states in the state machine is not really

757
00:41:40,760 --> 00:41:43,120
a viable solution either.

758
00:41:43,120 --> 00:41:47,720
So I think edge case handling is a big, big deal when you start trying to deploy these

759
00:41:47,720 --> 00:41:51,960
things that you know will have failures or have false positives.

760
00:41:51,960 --> 00:41:55,560
How do you, how do you incorporate that into the product as opposed to pretending it

761
00:41:55,560 --> 00:41:56,560
doesn't exist?

762
00:41:56,560 --> 00:41:57,560
Because it will happen.

763
00:41:57,560 --> 00:42:05,240
And have you developed any methodology for tackling that specific issue or is it, you

764
00:42:05,240 --> 00:42:11,000
know, each behavior, each edge case is different and it's just knowing that you need to think

765
00:42:11,000 --> 00:42:12,000
that through this.

766
00:42:12,000 --> 00:42:14,400
That's a good, that's a good question.

767
00:42:14,400 --> 00:42:19,120
I think we have, particularly our guys that work on more specifically and focused on

768
00:42:19,120 --> 00:42:21,120
that behavior system.

769
00:42:21,120 --> 00:42:26,240
I would say a little bit of both, over time, the way that our behaviors encode or engineered

770
00:42:26,240 --> 00:42:32,440
are designed to sort of handle things better, naturally just by virtue of the way, you

771
00:42:32,440 --> 00:42:34,600
know, the system architecture is set up.

772
00:42:34,600 --> 00:42:38,200
So there are sort of ways to build what we have learned, I think, into the system.

773
00:42:38,200 --> 00:42:41,880
But there is a lot of, you know, that sort of secret sauce, black magic, thing with sort

774
00:42:41,880 --> 00:42:42,880
of like deep-burning.

775
00:42:42,880 --> 00:42:44,960
There's things that I feel like people can't quite explain yet.

776
00:42:44,960 --> 00:42:49,160
It's just sort of like, I've just done this enough, I kind of know what is and isn't going

777
00:42:49,160 --> 00:42:50,160
to happen.

778
00:42:50,160 --> 00:42:56,960
And so some of it, I think, is just at this point, you know, our internal knowledge of how

779
00:42:56,960 --> 00:42:57,960
it works.

780
00:42:57,960 --> 00:43:01,800
But yeah, I think actually over time, as you start to codify what those things are, there

781
00:43:01,800 --> 00:43:05,200
are definitely places in the code where the architecture, again, supports that or makes

782
00:43:05,200 --> 00:43:08,880
it easier or handles things for you that you've sort of realized this always happens.

783
00:43:08,880 --> 00:43:11,800
We need to wait it, just automatically detect and handle that.

784
00:43:11,800 --> 00:43:12,800
Yeah.

785
00:43:12,800 --> 00:43:13,800
Okay.

786
00:43:13,800 --> 00:43:18,880
Anything else on your things to think about from a consumer products perspective?

787
00:43:18,880 --> 00:43:19,880
Hmm.

788
00:43:19,880 --> 00:43:22,320
I think those are probably the big ones.

789
00:43:22,320 --> 00:43:27,240
I guess the other one, given that data is such a huge thing, right, for training all

790
00:43:27,240 --> 00:43:30,480
these models and labeling is such a huge thing.

791
00:43:30,480 --> 00:43:37,720
I think for robots in particular, you know, in images in particular, within that, getting

792
00:43:37,720 --> 00:43:44,200
training data is, I think, even harder on robots because the degree to which the robots

793
00:43:44,200 --> 00:43:48,560
view of the world and images mind from the web differ is huge.

794
00:43:48,560 --> 00:43:53,880
So the statistics of the data that a robot sees, it's all motion blurry or terribly exposed

795
00:43:53,880 --> 00:43:57,360
or like half your arm or what I'm like, nobody has actually pointed the camera at something

796
00:43:57,360 --> 00:43:58,680
and taken a picture.

797
00:43:58,680 --> 00:44:02,480
There's, I think people tend to forget that like, there's already some selection bias

798
00:44:02,480 --> 00:44:07,680
in mining images from the web or images from Facebook, because somebody helped

799
00:44:07,680 --> 00:44:12,120
the camera and took the photo, framed the shot, and decided to upload it.

800
00:44:12,120 --> 00:44:14,200
And decided to upload it, exactly, very true.

801
00:44:14,200 --> 00:44:17,400
And so, you know, Cosmos is driving around, taking images all the time.

802
00:44:17,400 --> 00:44:21,360
And so you just get weird, random garbage all the time and terrible exposures and, you

803
00:44:21,360 --> 00:44:25,600
know, bad white balance and lots of motion blur and a weird perspective, he's looking

804
00:44:25,600 --> 00:44:26,600
up at the world.

805
00:44:26,600 --> 00:44:28,040
Nobody takes pictures from there.

806
00:44:28,040 --> 00:44:34,480
So gathering that data is a big challenge and I think it's not to be underestimated

807
00:44:34,480 --> 00:44:40,680
that it, how much it matters to try to get, to try to get data appropriate for, you

808
00:44:40,680 --> 00:44:44,720
know, your problem when it's robotics and not, you know, something else.

809
00:44:44,720 --> 00:44:45,920
It feels like that'd be easy.

810
00:44:45,920 --> 00:44:50,760
Like you just make, you know, a hundred of these and throw a bunch of blocks around and

811
00:44:50,760 --> 00:44:52,960
like, have them run around and shoot a bunch of video.

812
00:44:52,960 --> 00:44:54,560
I mean, it's the problem you're trying to solve, right?

813
00:44:54,560 --> 00:44:58,440
If it's the block, you can probably sort of design a scenario.

814
00:44:58,440 --> 00:44:59,440
You're right.

815
00:44:59,440 --> 00:45:00,440
Some situations that they care.

816
00:45:00,440 --> 00:45:02,640
If it's the people interaction thing, that's the people very lot of hard work.

817
00:45:02,640 --> 00:45:05,120
That varies a whole lot.

818
00:45:05,120 --> 00:45:07,520
All these things are challenging just different types of rooms.

819
00:45:07,520 --> 00:45:09,480
You know, we're building it in an office, right?

820
00:45:09,480 --> 00:45:10,480
Yeah.

821
00:45:10,480 --> 00:45:12,080
The office environment looks very different from people's homes.

822
00:45:12,080 --> 00:45:13,080
Right.

823
00:45:13,080 --> 00:45:14,080
Right.

824
00:45:14,080 --> 00:45:16,760
So, but we also don't, for privacy reasons, we're not just going to gather people, data from

825
00:45:16,760 --> 00:45:18,160
people's homes and upload it to our servers.

826
00:45:18,160 --> 00:45:19,160
Right.

827
00:45:19,160 --> 00:45:21,960
So, yeah, the data collection problem is a, is a, is a big one.

828
00:45:21,960 --> 00:45:22,960
Mm-hmm.

829
00:45:22,960 --> 00:45:23,960
Yeah.

830
00:45:23,960 --> 00:45:24,960
Makes sense.

831
00:45:24,960 --> 00:45:27,120
Well, Andrew, this has been a great, a great conversation.

832
00:45:27,120 --> 00:45:32,280
What I'm going to do now is I'm going to hit pause and go grab my camera and

833
00:45:32,280 --> 00:45:37,040
we'll kind of let you fire this thing up and see it in action.

834
00:45:37,040 --> 00:45:41,720
So for the folks that are listening on the podcast, they may not catch this part.

835
00:45:41,720 --> 00:45:46,120
But jump over to our YouTube channel and you'll check this out.

836
00:45:46,120 --> 00:45:51,760
But for those who aren't going to do that, or we'll be doing that later once they're

837
00:45:51,760 --> 00:45:56,160
off the train or whatever, thank you so much for taking the time to chat with me.

838
00:45:56,160 --> 00:45:57,160
Sure.

839
00:45:57,160 --> 00:45:58,160
No, it's been fun.

840
00:45:58,160 --> 00:45:59,160
Lots of good questions.

841
00:45:59,160 --> 00:46:00,160
Awesome.

842
00:46:00,160 --> 00:46:05,000
All right, everyone, that's our show for today.

843
00:46:05,000 --> 00:46:09,480
Thanks so much for listening and for your continued feedback and support.

844
00:46:09,480 --> 00:46:16,000
Remember, for your chance to win in our AI at home giveaway, head on over to twimmaleye.com

845
00:46:16,000 --> 00:46:20,440
slash my AI contest for complete details.

846
00:46:20,440 --> 00:46:25,440
For more information on Andrew, Cosmo, or any of the topics covered in this episode,

847
00:46:25,440 --> 00:46:29,760
head on over to twimmaleye.com slash talk slash 102.

848
00:46:29,760 --> 00:46:34,040
Thanks once again to Intel AI for their sponsorship of this series.

849
00:46:34,040 --> 00:46:38,400
To learn more about their partnership with Ferrari North America Challenge and the other things

850
00:46:38,400 --> 00:46:42,640
they've been up to, visit ai.intel.com.

851
00:46:42,640 --> 00:46:47,720
Of course, we'd be delighted to hear from you, either via a comment on the show notes page

852
00:46:47,720 --> 00:46:54,160
or via Twitter directly to me at at Sam Sherrington or to the show at at twimmaleye.

853
00:46:54,160 --> 00:47:01,160
Thanks once again for listening and catch you next time.

