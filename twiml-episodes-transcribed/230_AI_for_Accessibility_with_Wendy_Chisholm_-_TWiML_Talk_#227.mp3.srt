1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:31,080
I'm your host Sam Charrington.

4
00:00:31,080 --> 00:00:35,720
Today we're joined by Wendy Chisholm, Lois Brady, and Matthew Gugamas.

5
00:00:35,720 --> 00:00:40,800
Wendy is a principal accessibility architect at Microsoft and one of the chief proponents

6
00:00:40,800 --> 00:00:47,280
of the AI for accessibility program, which extends grants to AI-powered accessibility projects

7
00:00:47,280 --> 00:00:52,640
within the areas of employment, daily life, and communication and connection.

8
00:00:52,640 --> 00:00:58,480
Lois and Matthew are co-founders and CEO and CTO respectively of Itherapy, an AI for

9
00:00:58,480 --> 00:01:04,080
accessibility grantee and creator of the inner voice app, which utilizes visual language

10
00:01:04,080 --> 00:01:08,280
to strengthen communication and children on the autism scale.

11
00:01:08,280 --> 00:01:13,240
In our conversation we discuss the intersection of AI and accessibility, the lasting impact

12
00:01:13,240 --> 00:01:18,080
that innovation in AI can have for people with disabilities and society as a whole, and

13
00:01:18,080 --> 00:01:24,760
the importance of programs like AI for accessibility and bringing projects in this area to fruition.

14
00:01:24,760 --> 00:01:29,800
This episode is part of a series of shows on the topic of AI for the benefit of society

15
00:01:29,800 --> 00:01:33,840
that we're excited to have partnered with Microsoft to produce.

16
00:01:33,840 --> 00:01:37,840
Before we proceed, I'd like to thank Microsoft for their support and their sponsorship

17
00:01:37,840 --> 00:01:40,160
of this series.

18
00:01:40,160 --> 00:01:44,480
Microsoft is committed to ensuring the responsible development and use of AI and is empowering

19
00:01:44,480 --> 00:01:50,640
people around the world with intelligent technology to solve previously intractable societal

20
00:01:50,640 --> 00:01:57,040
challenges, spanning sustainability, accessibility, and humanitarian action.

21
00:01:57,040 --> 00:02:01,200
Learn more about their plan at Microsoft.ai.

22
00:02:01,200 --> 00:02:06,200
Enjoy the show.

23
00:02:06,200 --> 00:02:15,080
All right, everyone, I am here with Wendy Chisholm, Lois Brady, and Matthew Gugamis.

24
00:02:15,080 --> 00:02:23,040
Wendy is a principal accessibility architect at Microsoft, and Lois is co-founder and CEO

25
00:02:23,040 --> 00:02:29,840
of Itherapy, and Matthew is a co-founder and CEO at Itherapy.

26
00:02:29,840 --> 00:02:33,280
Welcome all of you to this week in machine learning and AI.

27
00:02:33,280 --> 00:02:34,280
Thank you.

28
00:02:34,280 --> 00:02:35,280
Yeah.

29
00:02:35,280 --> 00:02:36,280
Fantastic.

30
00:02:36,280 --> 00:02:37,280
Fantastic.

31
00:02:37,280 --> 00:02:42,840
I think five people is the largest interview that I've done, but we had the advantage of

32
00:02:42,840 --> 00:02:45,400
all being in the same room.

33
00:02:45,400 --> 00:02:54,960
In this case, I'm seated with Wendy, actually in a studio in Redmond, and Lois and Matthew

34
00:02:54,960 --> 00:02:57,440
are joining us remotely.

35
00:02:57,440 --> 00:03:01,720
And today we'll be talking about some of the work that Microsoft is doing around AI for

36
00:03:01,720 --> 00:03:02,720
accessibility.

37
00:03:02,720 --> 00:03:08,120
We're really looking forward to digging into that, but before we do, I'd like for our audience

38
00:03:08,120 --> 00:03:12,560
to get to know each of you a little bit better and what you're working on.

39
00:03:12,560 --> 00:03:14,800
So, let's start with you, Wendy.

40
00:03:14,800 --> 00:03:19,640
How did you get involved in working on this intersection of accessibility and artificial

41
00:03:19,640 --> 00:03:20,640
intelligence?

42
00:03:20,640 --> 00:03:23,760
Yeah, it's a fun story.

43
00:03:23,760 --> 00:03:29,920
It starts 25 years ago when I was working on my computer science degree, and I've just

44
00:03:29,920 --> 00:03:35,520
always been very curious about not only technology, but the humans that use them.

45
00:03:35,520 --> 00:03:39,040
And if we're building technology and no one's using it, why are we doing it?

46
00:03:39,040 --> 00:03:44,640
So, I was studying computer science and psychology, and one of my professors asked me to tutor

47
00:03:44,640 --> 00:03:47,160
a student in statistics.

48
00:03:47,160 --> 00:03:52,120
And I said, yes, and I met him, and he was blind.

49
00:03:52,120 --> 00:03:56,440
And I had not ever met anyone who was blind before.

50
00:03:56,440 --> 00:04:02,320
I wasn't really sure what I was doing, but I was very curious to learn about his experience

51
00:04:02,320 --> 00:04:04,560
and what I could do.

52
00:04:04,560 --> 00:04:11,440
So we got very creative and used Legos to teach bar graphs, and I used a pen to poke holes

53
00:04:11,440 --> 00:04:14,800
in a piece of paper to create a scatter plot.

54
00:04:14,800 --> 00:04:19,120
And with the backdrop of my computer science degree, I was like, there's got to be something

55
00:04:19,120 --> 00:04:21,200
that computers can do.

56
00:04:21,200 --> 00:04:24,280
And that really has been my trajectory ever since.

57
00:04:24,280 --> 00:04:27,080
And it's taken me around the world.

58
00:04:27,080 --> 00:04:29,840
I got to work at MIT with Tim Berners-Lee.

59
00:04:29,840 --> 00:04:32,520
I got to write an O'Reilly book and go to Food Camp.

60
00:04:32,520 --> 00:04:35,960
I got to do a lot of really cool things.

61
00:04:35,960 --> 00:04:43,360
And so what that eventually did was by understanding the diversity of human experience worldwide,

62
00:04:43,360 --> 00:04:50,200
and how culture and language can play into that experience, and trying to shift how people

63
00:04:50,200 --> 00:04:56,080
think and understand the experience of the billion people on the planet who have disabilities,

64
00:04:56,080 --> 00:04:58,800
myself included.

65
00:04:58,800 --> 00:05:00,520
It's just been a very interesting thing.

66
00:05:00,520 --> 00:05:07,520
So what I ended up doing was consulting for a while and helping companies try to make

67
00:05:07,520 --> 00:05:09,960
their websites more accessible.

68
00:05:09,960 --> 00:05:14,560
And in realizing that people get very excited about it, they think, yeah, I want to do

69
00:05:14,560 --> 00:05:19,200
us a great idea, but then not a lot would change.

70
00:05:19,200 --> 00:05:25,120
And so I decided to join a large corporation to understand those decisions are made.

71
00:05:25,120 --> 00:05:30,840
And quickly learned that it's the tooling that can really help people make better decisions.

72
00:05:30,840 --> 00:05:36,280
And a lot of times it's not that people are making decisions that make the world less

73
00:05:36,280 --> 00:05:40,440
accessible out of malice, just a lot of folks don't know.

74
00:05:40,440 --> 00:05:47,000
And so the more that we can infuse our engineering systems with the knowledge and information

75
00:05:47,000 --> 00:05:51,120
that's needed to help people make good decisions, then it's more likely that we'll end up with

76
00:05:51,120 --> 00:05:53,040
more accessible outcomes.

77
00:05:53,040 --> 00:05:55,920
So that's kind of what I've been doing the last while.

78
00:05:55,920 --> 00:05:58,240
And that's what led me to AI and machine learning.

79
00:05:58,240 --> 00:06:04,760
Because to me, the real juice in this, again, is how we bring technology together with

80
00:06:04,760 --> 00:06:09,240
humans, and it's about helping people make good decisions.

81
00:06:09,240 --> 00:06:10,880
So that's kind of how I ended up there.

82
00:06:10,880 --> 00:06:18,120
And so maybe to contextualize what I therapy is up to, I'll have you just talk a little

83
00:06:18,120 --> 00:06:25,760
bit about the AI for accessibility project at Microsoft and your role in particular with

84
00:06:25,760 --> 00:06:26,760
that project.

85
00:06:26,760 --> 00:06:27,760
Yeah.

86
00:06:27,760 --> 00:06:34,880
What's super cool about the program is that there's been this long history of innovation

87
00:06:34,880 --> 00:06:39,320
that for people with disabilities that ends up impacting all of us.

88
00:06:39,320 --> 00:06:46,560
And my favorite example of that is that smartphones wouldn't exist if it weren't for people

89
00:06:46,560 --> 00:06:47,880
disabilities.

90
00:06:47,880 --> 00:06:54,120
And the reason is that when you use an on-screen keyboard to text or to type, that keyboard

91
00:06:54,120 --> 00:06:58,840
was actually created a long time ago for people with physical disabilities who couldn't

92
00:06:58,840 --> 00:07:04,720
actually type whether for weakness or loss of a limb or anything.

93
00:07:04,720 --> 00:07:10,320
And now it's being used by all of us because we're not carrying keyboards around with us

94
00:07:10,320 --> 00:07:12,560
so we can type on our phones.

95
00:07:12,560 --> 00:07:16,320
The phones create such a limiting experience for us.

96
00:07:16,320 --> 00:07:21,120
And that's what technology for people with disabilities is about is just really what

97
00:07:21,120 --> 00:07:23,880
abilities do you have and let's amplify those.

98
00:07:23,880 --> 00:07:30,360
So because of that long history of innovation, what we're doing in the AI for accessibility

99
00:07:30,360 --> 00:07:38,160
program is just funding projects that are working on that next wave of innovation.

100
00:07:38,160 --> 00:07:43,720
And so I get to spend my time talking to people who are working on that next wave and then

101
00:07:43,720 --> 00:07:49,560
kind of figuring out who to fund and how to piece that all together into this, what this

102
00:07:49,560 --> 00:07:51,960
future is going to look like for all of us.

103
00:07:51,960 --> 00:07:55,640
Because like I said, when we innovate for people with disabilities, we end up impacting

104
00:07:55,640 --> 00:07:56,880
all of us.

105
00:07:56,880 --> 00:08:01,200
So I get to kind of look into the future and place some bets basically.

106
00:08:01,200 --> 00:08:04,040
That sounds like a ton of fun.

107
00:08:04,040 --> 00:08:05,040
It is.

108
00:08:05,040 --> 00:08:06,040
Yeah.

109
00:08:06,040 --> 00:08:10,760
I get to talk to really smart people like Lois and Matthew and give them money and support

110
00:08:10,760 --> 00:08:12,880
to do cool stuff.

111
00:08:12,880 --> 00:08:17,920
Lois, can you share a bit about your background and I therapy?

112
00:08:17,920 --> 00:08:20,040
Absolutely Sam.

113
00:08:20,040 --> 00:08:26,840
Like Wendy, our journey started about 25 years ago and I became a speech language pathologist.

114
00:08:26,840 --> 00:08:31,840
I'm working with people who had communication challenges in one way or another.

115
00:08:31,840 --> 00:08:40,160
At that time, technology was all about getting the old technology from the general population

116
00:08:40,160 --> 00:08:46,800
and then we had to adapt it to our students who needed communication technology.

117
00:08:46,800 --> 00:08:52,880
When the iPad came out, that kind of flipped the model for us and it was very impressive.

118
00:08:52,880 --> 00:08:59,000
When I noticed how a lot of my students who had significant challenges, complex communication

119
00:08:59,000 --> 00:09:05,680
needs were gravitating towards the iPad and it encouraged me to write a book called Apps

120
00:09:05,680 --> 00:09:06,680
Fraudism.

121
00:09:06,680 --> 00:09:13,160
So as I was writing that book, I noticed that there are certain features that kids would

122
00:09:13,160 --> 00:09:17,840
attend to and use and they'll use it without even us prompting them to use it and there

123
00:09:17,840 --> 00:09:20,600
are certain features that they don't really care about.

124
00:09:20,600 --> 00:09:25,560
So taking all of those things that all my students really loved, we put them into inner

125
00:09:25,560 --> 00:09:30,840
voice to capture their attention and teach them communication and also just to give kids

126
00:09:30,840 --> 00:09:37,080
with complex communication needs or complex sensory needs, the latest, greatest technology

127
00:09:37,080 --> 00:09:42,360
and just let them communicate more or less like everyone else.

128
00:09:42,360 --> 00:09:49,320
So we created the app in our voice and then when we saw the artificial intelligence grant,

129
00:09:49,320 --> 00:09:54,080
we thought it was absolutely perfect to just keep the students, keep our ideas rolling

130
00:09:54,080 --> 00:09:59,880
along, make it easier, faster, more fluent and really put our kids with communication

131
00:09:59,880 --> 00:10:06,560
challenges at the forefront of technology instead of ten years behind everyone else using

132
00:10:06,560 --> 00:10:09,840
all the equipment that everyone else no longer uses.

133
00:10:09,840 --> 00:10:16,400
So this has been wonderful for us because as our kids use this, they really draw in everybody

134
00:10:16,400 --> 00:10:20,280
around them thinking, oh this is so cool, I want to see what you're doing, I want to

135
00:10:20,280 --> 00:10:21,280
come and use it also.

136
00:10:21,280 --> 00:10:24,760
So it's been a big boost for us.

137
00:10:24,760 --> 00:10:31,080
And I understand that you're also trained in animal assistive therapy and you have a

138
00:10:31,080 --> 00:10:34,200
therapy pig named Buttercup.

139
00:10:34,200 --> 00:10:35,880
This is that correct?

140
00:10:35,880 --> 00:10:36,880
Absolutely.

141
00:10:36,880 --> 00:10:41,880
Buttercup is more famous than anything else I've ever done.

142
00:10:41,880 --> 00:10:47,360
He's absolutely wonderful and I chose a pot belly pig because I specifically work and

143
00:10:47,360 --> 00:10:49,600
I specialize in autism.

144
00:10:49,600 --> 00:10:54,240
And a lot of kids with autism definitely have trouble with dogs because they've heard them

145
00:10:54,240 --> 00:11:00,160
bark before or they've been jumped on or some things happen so they have already a preconceived

146
00:11:00,160 --> 00:11:06,560
notion about a dog or a cat, they may have gotten scratched but a pig, they have absolutely

147
00:11:06,560 --> 00:11:13,960
no idea what to do with a pig and it was breaking new ground and it's just a matter of getting

148
00:11:13,960 --> 00:11:19,800
something that captures their attention and using it to create communication opportunities,

149
00:11:19,800 --> 00:11:20,800
much like the iPad.

150
00:11:20,800 --> 00:11:25,840
When the iPad came along it was the exact same thing, we're using this high interest item

151
00:11:25,840 --> 00:11:30,880
whether it's a pig or an iPad to capture their interest and then teach them communication

152
00:11:30,880 --> 00:11:31,880
with it.

153
00:11:31,880 --> 00:11:33,200
But he's great.

154
00:11:33,200 --> 00:11:34,200
He's great.

155
00:11:34,200 --> 00:11:41,600
So I bring that up mostly because I have a daughter who is studying psychology and loves animals

156
00:11:41,600 --> 00:11:49,880
and her goal is to do animal assisted therapy and I can now tell her that I interviewed an

157
00:11:49,880 --> 00:11:53,440
animal assisted therapist and finally get her to listen to one of my podcasts.

158
00:11:53,440 --> 00:11:54,440
Perfect.

159
00:11:54,440 --> 00:11:58,120
We're here to help.

160
00:11:58,120 --> 00:12:05,280
So Matthew, how about you, can you speak a little bit about your background and maybe

161
00:12:05,280 --> 00:12:12,640
go and take us into a little bit more detail into the I therapy app and how it uses AI?

162
00:12:12,640 --> 00:12:14,040
Absolutely.

163
00:12:14,040 --> 00:12:18,760
My background first actually was as a musician.

164
00:12:18,760 --> 00:12:21,400
So I am actually a drummer.

165
00:12:21,400 --> 00:12:25,800
So I really have been interested in just how you learn skills.

166
00:12:25,800 --> 00:12:30,960
Learning takes a long time to learn, takes a lot of study and that's very similar to how

167
00:12:30,960 --> 00:12:32,560
speech and language develops.

168
00:12:32,560 --> 00:12:37,000
I mean, speech and language, those are probably two of the most difficult skills people

169
00:12:37,000 --> 00:12:38,000
can learn.

170
00:12:38,000 --> 00:12:43,240
So I was really fascinated by how do you actually learn to communicate and using words.

171
00:12:43,240 --> 00:12:49,160
And just like Lois, I specialize with people with autism, I'm a certified autism specialist

172
00:12:49,160 --> 00:12:52,000
in addition to being a speech pathologist.

173
00:12:52,000 --> 00:12:56,920
And early on, when I started working with kids with autism, one of the most difficult

174
00:12:56,920 --> 00:13:05,000
things about teaching them skills was to show them things that captured their interests and

175
00:13:05,000 --> 00:13:10,160
interests leads to learning because if you're not interested in something, it's hard to

176
00:13:10,160 --> 00:13:11,160
pay attention.

177
00:13:11,160 --> 00:13:15,640
It's hard to learn things you don't pay attention to.

178
00:13:15,640 --> 00:13:21,560
So when the iPad came out, I noticed, wow, and this, you could really capture people's

179
00:13:21,560 --> 00:13:25,040
interests with the iPad, just like Lois was saying.

180
00:13:25,040 --> 00:13:33,960
And so we started, the first version of inner voice was just using facial recognition technology

181
00:13:33,960 --> 00:13:37,440
to model speech.

182
00:13:37,440 --> 00:13:41,520
And so this is kind of similar, how a musician learns, you go to a drum teacher, he shows

183
00:13:41,520 --> 00:13:44,280
you something, you copy it, and then you practice.

184
00:13:44,280 --> 00:13:52,760
And it was really interesting that you could, I can get tons of kids to imitate what was

185
00:13:52,760 --> 00:13:55,960
on the screen, but not necessarily what I would model for them.

186
00:13:55,960 --> 00:14:03,920
And so how we've kind of woven in the AI component using the Azure vision services, this

187
00:14:03,920 --> 00:14:09,800
is to me really, it's great because we've been testing it with users now.

188
00:14:09,800 --> 00:14:15,320
And it kind of mimics the way people learn language.

189
00:14:15,320 --> 00:14:20,000
So for example, you look at something, let's say you're a child, you look at something,

190
00:14:20,000 --> 00:14:24,880
you point to it, your parents call it, you point to an animal, your parents say that's

191
00:14:24,880 --> 00:14:29,320
a pig, and then the child says, pig, and then they know what a pig is.

192
00:14:29,320 --> 00:14:37,080
So what we've done with the vision services is that now a user, let's say a kid who's

193
00:14:37,080 --> 00:14:43,680
using the, using inner voice, can use the speech we've called visual language.

194
00:14:43,680 --> 00:14:48,600
And here she can take a picture of a pig, for example.

195
00:14:48,600 --> 00:14:53,640
And what will happen is this will, the photo will get sent to a cloud, and then I'll get

196
00:14:53,640 --> 00:14:58,520
paired with text in the text appears back on the screen.

197
00:14:58,520 --> 00:15:04,560
And the avatar, which was from our original version, will read the text so they can see

198
00:15:04,560 --> 00:15:12,560
themselves saying the word, and then pair that word with the image and written text.

199
00:15:12,560 --> 00:15:17,440
And this is something that we've built up, it's called multi-sensory semiotics.

200
00:15:17,440 --> 00:15:20,960
So semiotics is how you assign meaning to a symbol.

201
00:15:20,960 --> 00:15:31,840
So by using this AI technology, we've been able to pair speech and language with photos.

202
00:15:31,840 --> 00:15:33,920
And it can be interest driven.

203
00:15:33,920 --> 00:15:37,840
So let's say a kid wants to know what something is in the room, he can take a picture of it,

204
00:15:37,840 --> 00:15:40,840
and it can be labeled and spoken for him or her.

205
00:15:40,840 --> 00:15:47,600
And then they can imitate it and learn kind of through self-motivation, what things are

206
00:15:47,600 --> 00:15:53,440
called and how to label or describe things in their environment.

207
00:15:53,440 --> 00:15:59,760
Wendy, I'm curious when you think about, again, this intersection of AI and accessibility,

208
00:15:59,760 --> 00:16:10,240
on the one hand, AI presents an opportunity to allow us to connect more directly or to

209
00:16:10,240 --> 00:16:14,280
provide better support for people that need it.

210
00:16:14,280 --> 00:16:21,080
On the other hand, there's also a risk that the people that need support get left behind

211
00:16:21,080 --> 00:16:24,680
or left out of the innovation that's happening with AI.

212
00:16:24,680 --> 00:16:30,120
And I'm curious, how do you think about those who are there other factors that you think

213
00:16:30,120 --> 00:16:36,080
are like, what's the perspective that you bring to supporting organizations that are trying

214
00:16:36,080 --> 00:16:40,600
to do work in kind of the confluence of these fields?

215
00:16:40,600 --> 00:16:43,280
That's a great question.

216
00:16:43,280 --> 00:16:46,360
And there are several different ways that we can go with that.

217
00:16:46,360 --> 00:16:51,920
On the one hand, the people being left behind and not included is near and dear at my

218
00:16:51,920 --> 00:17:03,240
heart, because as low as talked about technology and how people use it, it's just, it's really,

219
00:17:03,240 --> 00:17:09,040
what I guess what I really want to focus on is that it's so important for us to, as we're

220
00:17:09,040 --> 00:17:14,560
building new technology that we're really bringing everyone who's going to be using it

221
00:17:14,560 --> 00:17:18,840
into get them around the table and involved in the process.

222
00:17:18,840 --> 00:17:23,920
And I think that's why when we see these amazing innovations like the on-screen keyboard,

223
00:17:23,920 --> 00:17:30,240
that was because someone, a developer, was working with someone with a disability.

224
00:17:30,240 --> 00:17:35,400
And so I think one of the things I'm excited about that we're doing is we're specifically

225
00:17:35,400 --> 00:17:40,520
looking for projects that are firmly grounded in the community in which they're intending

226
00:17:40,520 --> 00:17:42,600
to benefit.

227
00:17:42,600 --> 00:17:47,320
And ideally, I want to be a shark tank of entrepreneurs with disabilities.

228
00:17:47,320 --> 00:17:52,160
And so part of that is just making sure that folks have the skills to really contribute.

229
00:17:52,160 --> 00:17:57,280
It also means that we're looking at data sets and we're looking at bias in data sets.

230
00:17:57,280 --> 00:18:03,040
And I think one of the things that we're excited about is the photographs that are taken

231
00:18:03,040 --> 00:18:08,600
by people who are blind or have low vision, they're not going to be perfectly framed.

232
00:18:08,600 --> 00:18:13,880
And so how are they going to, how does that affect the models and the training that's

233
00:18:13,880 --> 00:18:15,560
been done before?

234
00:18:15,560 --> 00:18:20,920
So we want to make sure that there's a good diversity there so that folks are included.

235
00:18:20,920 --> 00:18:24,760
And then we get all the good, innovative, juicy stuff too.

236
00:18:24,760 --> 00:18:29,360
And I have so many great stories about that where when you really include people and bring

237
00:18:29,360 --> 00:18:33,800
them around the table that you just, you get to do some really good stuff.

238
00:18:33,800 --> 00:18:36,040
I'd love to hear some of those stories.

239
00:18:36,040 --> 00:18:42,640
Yeah, and I think the other thing about it too is just, so Sikib, who's one of our engineers

240
00:18:42,640 --> 00:18:46,920
that worked on the Seeing AI project is still working on that.

241
00:18:46,920 --> 00:18:49,160
And I'm not sure if you're familiar with Seeing AI.

242
00:18:49,160 --> 00:18:50,360
Tell us about that.

243
00:18:50,360 --> 00:18:51,360
Yeah.

244
00:18:51,360 --> 00:18:53,320
So it's an iPhone app right now.

245
00:18:53,320 --> 00:18:57,760
And there's a really great demo of Sasha and one of my colleagues and Taylor.

246
00:18:57,760 --> 00:19:03,040
And the reason I love this demo is that, so she's blind, she's using Seeing AI.

247
00:19:03,040 --> 00:19:07,640
And he writes on a piece of paper, accessibility is awesome.

248
00:19:07,640 --> 00:19:12,000
And so she's able to feel where the paper is, take a picture of it.

249
00:19:12,000 --> 00:19:16,120
And the text, the handwriting is recognized and read out loud to her.

250
00:19:16,120 --> 00:19:24,840
And for her, that means now that she can read cards or business cards or letters from family

251
00:19:24,840 --> 00:19:25,840
and friends.

252
00:19:25,840 --> 00:19:28,360
And so I think it's really, it's empowering.

253
00:19:28,360 --> 00:19:29,600
And I think that's really cool.

254
00:19:29,600 --> 00:19:35,720
And I think when you start looking at the dream that Sikib has of when he's walking around

255
00:19:35,720 --> 00:19:41,920
with a friend who knows him and his preferences, his friend is able to say,

256
00:19:41,920 --> 00:19:46,560
he's able to recognize what he's interested in and maybe tell him, this is what's changed

257
00:19:46,560 --> 00:19:52,800
since the last time we were here, or give some color about what's happening in the space.

258
00:19:52,800 --> 00:19:57,960
But when you look at that, that's just another eyes free interface.

259
00:19:57,960 --> 00:19:59,920
And it's something that I think we'd all use.

260
00:19:59,920 --> 00:20:06,160
When I'm touristing in a new place, and I don't know the language, or I don't want to

261
00:20:06,160 --> 00:20:09,960
be looking at my phone for directions because I don't want to appear to be a tourist.

262
00:20:09,960 --> 00:20:14,600
And I want some of that feedback in my ear and getting it tailored to me.

263
00:20:14,600 --> 00:20:16,720
That's something we can all use.

264
00:20:16,720 --> 00:20:22,040
So again, that's kind of what I feel the power is for us is, and that goes kind of back

265
00:20:22,040 --> 00:20:23,840
to the decision making as well.

266
00:20:23,840 --> 00:20:27,080
In those instances, we're helping people make better decisions because we're giving them

267
00:20:27,080 --> 00:20:30,560
information that they didn't have before.

268
00:20:30,560 --> 00:20:33,120
So it doesn't really matter if you're disabled or not, right?

269
00:20:33,120 --> 00:20:35,200
You want information so you can make better decisions.

270
00:20:35,200 --> 00:20:37,480
And that's really what this is about, I think.

271
00:20:37,480 --> 00:20:48,440
Yeah, I love this recurring theme of the innovations that we are creating to support

272
00:20:48,440 --> 00:20:54,040
people with disabilities, kind of coming back full circle and impacting the way we use

273
00:20:54,040 --> 00:20:55,040
technology.

274
00:20:55,040 --> 00:20:56,960
The way everyone uses technology.

275
00:20:56,960 --> 00:20:57,960
Exactly.

276
00:20:57,960 --> 00:21:05,880
And I mean, what I really hope the world goes is that by making sure that we're all at

277
00:21:05,880 --> 00:21:11,480
the table and contributing, we're not creating barriers and disability kind of disappears.

278
00:21:11,480 --> 00:21:16,600
Because one of my favorite quotes is, it's the stairs that make the building inaccessible,

279
00:21:16,600 --> 00:21:18,000
not the wheelchair.

280
00:21:18,000 --> 00:21:19,800
And to me, that's the beauty of it, right?

281
00:21:19,800 --> 00:21:25,280
If we can really design the world such that everyone can participate, it's just not really

282
00:21:25,280 --> 00:21:26,280
a thing anymore.

283
00:21:26,280 --> 00:21:32,120
We're all benefiting from these connections with other people.

284
00:21:32,120 --> 00:21:35,040
So again, that's the juicy part with AI.

285
00:21:35,040 --> 00:21:39,400
Because our devices now have so many sensors in them and can give us information that we

286
00:21:39,400 --> 00:21:43,280
may miss, whether we're eyes busy or we're blind.

287
00:21:43,280 --> 00:21:47,560
And that's, there's just so much opportunity there.

288
00:21:47,560 --> 00:21:48,560
Absolutely.

289
00:21:48,560 --> 00:21:56,040
Lois, can you elaborate on the kind of experiences you've seen with the users of the inner voice

290
00:21:56,040 --> 00:22:00,040
app and the kind of impact it's had for them?

291
00:22:00,040 --> 00:22:01,040
Absolutely.

292
00:22:01,040 --> 00:22:06,480
We've been using this in our clinic and in school districts.

293
00:22:06,480 --> 00:22:12,160
And we're even branching out now into hospitals with folks who may have had strokes or head injuries.

294
00:22:12,160 --> 00:22:18,440
But initially, it was made for video self modeling when you take a picture and you see yourself

295
00:22:18,440 --> 00:22:23,880
producing the target language or the target word.

296
00:22:23,880 --> 00:22:28,040
And then we added in the vision where they can take a picture.

297
00:22:28,040 --> 00:22:34,040
Just like Wendy said, it's amazing they can take a picture of words or a thing.

298
00:22:34,040 --> 00:22:37,040
And then the avatar says what that is.

299
00:22:37,040 --> 00:22:43,400
And across the board from the youngest student which we have is probably around two to some

300
00:22:43,400 --> 00:22:46,840
of the oldest which are in their 80s, it's amazement.

301
00:22:46,840 --> 00:22:50,440
They get so that their mouths just drop.

302
00:22:50,440 --> 00:22:56,400
And it becomes then the, I call it like an electric communication environment.

303
00:22:56,400 --> 00:23:00,400
Now everyone's coming over asking about it wanting to use it.

304
00:23:00,400 --> 00:23:05,400
And it just produces this place where now we want to talk and the students want to talk

305
00:23:05,400 --> 00:23:07,400
about what they're doing.

306
00:23:07,400 --> 00:23:11,600
And then our students start adding in characters that they like and they make their characters

307
00:23:11,600 --> 00:23:12,600
talk.

308
00:23:12,600 --> 00:23:17,600
So it's all about just providing these wonderful opportunities for not only the student

309
00:23:17,600 --> 00:23:20,960
to talk but people to come in and say, oh my gosh, show me what you're doing, what's

310
00:23:20,960 --> 00:23:21,960
going on.

311
00:23:21,960 --> 00:23:26,960
So there are kids quite literally never had those opportunities before.

312
00:23:26,960 --> 00:23:29,960
So they're leading the pack in that manner.

313
00:23:29,960 --> 00:23:35,960
So because they do have all this wonderful AI embedded because of the Azure services.

314
00:23:35,960 --> 00:23:38,960
So they're reading the way and nobody's ever seen this.

315
00:23:38,960 --> 00:23:42,960
So they get to be the cool kid.

316
00:23:42,960 --> 00:23:48,960
And I think Wendy hit it a little bit before when she was talking about the universal design.

317
00:23:48,960 --> 00:23:54,960
And I went and used it with a student who was bilingual and didn't have any English at all

318
00:23:54,960 --> 00:24:00,960
and using a translator app, we were able to put in one language and speak a different language.

319
00:24:00,960 --> 00:24:07,360
So the technology is just absolutely amazing and we can almost hit any kind of a challenge

320
00:24:07,360 --> 00:24:09,360
and overcome it right now.

321
00:24:09,360 --> 00:24:12,280
And it's never happened that way for us before.

322
00:24:12,280 --> 00:24:15,960
Technology was something that was cumbersome and hard to use but no more.

323
00:24:15,960 --> 00:24:18,960
Everyone has it in the palm of their hands.

324
00:24:18,960 --> 00:24:22,960
And again, our kids are like leading the way at this point in time.

325
00:24:22,960 --> 00:24:31,560
Matthew, can you share a little bit about your experience in using this using AI as a technologist

326
00:24:31,560 --> 00:24:35,560
building it into the application?

327
00:24:35,560 --> 00:24:42,560
What was your background with regards to AI and how did that inform the way you incorporated

328
00:24:42,560 --> 00:24:43,960
it into the app?

329
00:24:43,960 --> 00:24:46,960
Well, I've always loved technology.

330
00:24:46,960 --> 00:24:52,960
I've always been someone who just loves to read about technology or learn how it works.

331
00:24:52,960 --> 00:24:57,960
My first and foremost background in terms of, I guess, scientific background

332
00:24:57,960 --> 00:24:59,960
and its communication sciences.

333
00:24:59,960 --> 00:25:05,960
And so I looked into how AI could be used for that field.

334
00:25:05,960 --> 00:25:13,960
And probably the one that first caught my eye and then how Lois and I developed our visual language

335
00:25:13,960 --> 00:25:20,960
feature was the character recognition, like describing the feature where I was talking about

336
00:25:20,960 --> 00:25:24,960
before, pairing images to text.

337
00:25:24,960 --> 00:25:29,960
So I thought, wow, that is a fantastic way to help with literacy and help with possibly

338
00:25:29,960 --> 00:25:32,960
help people who maybe just want to learn a different language.

339
00:25:32,960 --> 00:25:36,960
It could be applied, and if you have no disability, oh, it could be applied to that.

340
00:25:36,960 --> 00:25:42,960
The other aspect was I got really fascinated by the smart bot technology that particularly

341
00:25:42,960 --> 00:25:44,960
Microsoft has now.

342
00:25:44,960 --> 00:25:50,960
So they have a number of these services, text, speech, and then the language understanding

343
00:25:50,960 --> 00:25:53,960
and Q&A frameworks.

344
00:25:53,960 --> 00:26:00,960
And it's almost sort of like you can see a lot of this in their Cortana app that they've released.

345
00:26:00,960 --> 00:26:06,960
And that, back to kind of tying back to my background as a musician, you have to practice

346
00:26:06,960 --> 00:26:08,960
things to be good at them.

347
00:26:08,960 --> 00:26:14,960
And I thought, well, what a great way to make practice motivational for kids or anyone

348
00:26:14,960 --> 00:26:17,960
by, you know, you can make a bot that will interact with you.

349
00:26:17,960 --> 00:26:19,960
You can ask questions.

350
00:26:19,960 --> 00:26:21,960
You can find out information.

351
00:26:21,960 --> 00:26:28,960
And one of the trickiest things to teach any person with communication challenges

352
00:26:28,960 --> 00:26:31,960
is to initiate a communication exchange.

353
00:26:31,960 --> 00:26:34,960
But a bot is kind of a friendly place to start.

354
00:26:34,960 --> 00:26:39,960
You can say, what's the weather, what time is it, or what's a platypus, or, you know, what's a pot belly

355
00:26:39,960 --> 00:26:40,960
pig.

356
00:26:40,960 --> 00:26:43,960
And then the bot, or the bot, I had to tie that.

357
00:26:43,960 --> 00:26:46,960
And so the bot can come back with an answer.

358
00:26:46,960 --> 00:26:52,960
And it's motivating because being motivated really is a huge factor in communication.

359
00:26:52,960 --> 00:26:59,960
And AI can, can answer infinite questions about a subject that may be an individual's only interested in.

360
00:26:59,960 --> 00:27:04,960
I mean, so I, I think it's sort of a long answer to your question.

361
00:27:04,960 --> 00:27:10,960
But there's a host of reasons why I got into AI and particularly for communication sciences.

362
00:27:10,960 --> 00:27:16,960
We're going to see how many times we can say pig in this podcast.

363
00:27:16,960 --> 00:27:34,960
Did you specifically work on the integration with the Azure services into the app, or was that work that was done by other folks or via Microsoft?

364
00:27:34,960 --> 00:27:49,960
Oh, so we, our role, specifically, lowest and I do this, we work on the UX UI design first and foremost, and then we work closely with a developer who has helped us from the beginning design interboys.

365
00:27:49,960 --> 00:27:51,960
His name is Junichi Fujita.

366
00:27:51,960 --> 00:27:52,960
He's an amazing guy.

367
00:27:52,960 --> 00:28:11,960
And so we went through some of these tutorials about how to integrate the Azure services into our existing code because basically we're leveraging the cloud-based services into our iOS code because it's currently intervoices in iOS.

368
00:28:11,960 --> 00:28:22,960
And so we contracted with Junichi who did the coding first because I'm actually not a coder. I'm a speech pathologist.

369
00:28:22,960 --> 00:28:28,960
And so we come up with the designs and find the technology to make sure it's feasible for what we want to do.

370
00:28:28,960 --> 00:28:35,960
And then he is barely being able to translate that pretty much exactly to our specifications who work with them for a long time.

371
00:28:35,960 --> 00:28:49,960
Are you aware of any challenges or impediments that you and he ran into in incorporating AI and these cognitive services into the application?

372
00:28:49,960 --> 00:28:52,960
They were actually stunningly easy to integrate.

373
00:28:52,960 --> 00:29:06,960
The biggest problem was the UI UX stuff. So that will be kept going back and forth. Well, how should it look? What's the easiest way for it to be used by users? Because we do a lot of user testing.

374
00:29:06,960 --> 00:29:21,960
We don't just think, hey, I think people will like this. We actually designed something based on observation and interviews with people and we try it with them. And then they either like it or think, oh, this is no good. And then we go back and redesign itself.

375
00:29:21,960 --> 00:29:30,960
Most of the challenges were just in that aspect. But in terms of integrating the the Azure services into our code, it was really easy.

376
00:29:30,960 --> 00:29:40,960
And they've had an easy time, which is great. I think when I look to some of our other grantees, I think they're going to be pushing the limits of the technology.

377
00:29:40,960 --> 00:29:50,960
In particular, when we look at some of the work that Zyrobotics is doing, they're looking at speech recognition for students with non-typical speech patterns.

378
00:29:50,960 --> 00:30:08,960
And so they're really having to train the data and expand what it can recognize. We've got another grantee from the University of Iowa. And she's using a camera to help athletes who are blind and running around jogging tracks.

379
00:30:08,960 --> 00:30:25,960
And so the cool part about that one is with a jogging track, you have clear lines in most tracks, right, kind of indicating where the lanes are. So once they get those recognizes working in real time, they will be able to tell someone they're starting to veer out of their lane.

380
00:30:25,960 --> 00:30:35,960
Now, the problem is getting that working fast enough on the device in real time so that you're not getting it like, oops, a few seconds later and you run into somebody.

381
00:30:35,960 --> 00:30:44,960
And these are athletes who are actively competing. And if we can solve some of those issues, the independence is great.

382
00:30:44,960 --> 00:31:00,960
That's incredible. I happen to live very close to a school for the blind and I see their track all the time and they've got these, I don't know if listeners have ever seen these, but they've basically got these guide wires along the lanes.

383
00:31:00,960 --> 00:31:20,960
And so they can still participate in the activity. But I can envision bringing AI to a device that the athlete can can wear totally eliminates the need for a specialized setup.

384
00:31:20,960 --> 00:31:31,960
They can compete with other athletes and, you know, be on a level playing ground with the help of a model that's running in a phone.

385
00:31:31,960 --> 00:31:44,960
Exactly. Yeah. So there's some going to be some really hard challenges with that one. And I can't talk yet about this next round, but we're in the midst of interviewing our basically what we do, we kind of are operating like a shark tank.

386
00:31:44,960 --> 00:31:53,960
And so after we review a bunch of the applications, we'll invite them in for a pitch meeting, just to kind of meet folks and get a sense of what they're really doing.

387
00:31:53,960 --> 00:32:02,960
And so I'm very excited about some of the ones we're hearing this week. This is pitch week for us. And so we'll be announcing in January, then this kind of next round.

388
00:32:02,960 --> 00:32:08,960
But people, and again, now that there's some maturity to the program.

389
00:32:08,960 --> 00:32:15,960
And, you know, it helps that, you know, Sasha has been out there talking about it too. We're getting some really cool applications.

390
00:32:15,960 --> 00:32:25,960
So I think we were very lucky with a therapy in our first round in Zyrobotics. And now we're just, it's really growing. And so we've got, we've got some fun things in the works.

391
00:32:25,960 --> 00:32:46,960
But yeah, I think too, there's just so many opportunities to use, you know, internet of things and just all these sensors. And, you know, from my own. So I have PTSD. And so I have so many sensors, kind of monitoring different aspects of heart rate and, you know, trying to predict just how I'm feeling.

392
00:32:46,960 --> 00:33:03,960
And I still have not been able to pull together a dashboard that pulls together all my calendar and health data and, you know, mood data and all of this stuff. And I think like, I just, I'm looking forward to some of what we can do.

393
00:33:03,960 --> 00:33:16,960
There's just so much more that we know. And there's so many patterns that we can recognize. And then if we can kind of pull that together, again, it's about the decisions that it allows us to make. And so I'm really excited about that.

394
00:33:16,960 --> 00:33:38,960
It's funny that you mentioned patterns because that's the word that was floating in my mind around this next question. And that's really about the patterns that you see as you work with organizations that are using AI in an accessibility context.

395
00:33:38,960 --> 00:34:00,960
And I think that the broader part of the question is around, you know, as we've started to work with accessibility in the broader computing context, we've developed, you know, specifications and guidelines that at this point are fairly well understood and codified.

396
00:34:00,960 --> 00:34:14,960
And I'm curious, do you, do you see AI for accessibility evolving in a similar way, or is there not a need for that? How do you see that evolving?

397
00:34:14,960 --> 00:34:35,960
That's a really great question. And my work at MIT was on some of those standards. And so that's right in my will house. I'm not sure about that. Honestly, I do think, though, as I'm reviewing, so part of my time too is giving feedback to folks who, well, let me put it this way.

398
00:34:35,960 --> 00:34:50,960
I do a lot of educating about possibilities. And so I do spend time when people are creating plans for how to use AI in their organizations, making sure that they're considering all scenarios and not accidentally creating more barriers.

399
00:34:50,960 --> 00:35:11,960
And so I know there's work going on with other types of guidelines, like there are some, there's some work right now at W3C in terms of cognitive disabilities and some new suggestions on how to make websites more accessible for folks who have learning disabilities or even emotional disabilities.

400
00:35:11,960 --> 00:35:28,960
I am very curious to see where things go in terms of augmented reality in VR. I was looking at a manufacturing, someone talking about manufacturing the other day and how to bring AI into the floor, the manufacturing floor.

401
00:35:28,960 --> 00:35:41,960
And really looking at, there's opportunities here, I think, for people with disabilities to have the employed in some of these new jobs, as long as people really consider how it's being designed.

402
00:35:41,960 --> 00:36:02,960
So for example, in a manufacturing scenario, getting feedback from a bot about how something is working or being notified that, hey, we've noticed, we've detected that this run has some errors and we're seeing some patterns. And just making sure that the information is being presented, if it's audible, well, but it's also going to be intact.

403
00:36:02,960 --> 00:36:12,960
So what's interesting to me is that I think a lot of the potential issues I'm seeing have already been documented and it's kind of just the same things over and over.

404
00:36:12,960 --> 00:36:25,960
And it doesn't surprise me because that's kind of what I've seen in my career, right? I did, I analyzed Java years ago and said, here are the things that we need to do to make sure that if you're using Java, your applications are going to be accessible.

405
00:36:25,960 --> 00:36:35,960
And the concepts haven't really shifted that much, you know, I think if you have visual information, you need to make sure you also have auditory and tactile information.

406
00:36:35,960 --> 00:36:39,960
And just because you never know the scenario, someone's going to be in.

407
00:36:39,960 --> 00:36:45,960
And again, I just, I'm going to tie it back because I really want to drive the point home that any time you do that, huh?

408
00:36:45,960 --> 00:36:55,960
Oh, a pig. Yeah. Oh, my God. How can I integrate pig into that? That's a good challenge.

409
00:36:55,960 --> 00:37:02,960
Because no matter what you're doing, it could be used by a pig. No, I'm kidding.

410
00:37:02,960 --> 00:37:10,960
You never know the scenario that someone's going to be in. And you never know the opposite, the kind of scenario, the environment that someone's in, right?

411
00:37:10,960 --> 00:37:20,960
So for captions, especially on that manufacturing floor, it's got to be really loud. So I was actually really surprised that they were designing something that was audible without being visual because I'm like, isn't it going to be noisy?

412
00:37:20,960 --> 00:37:28,960
I mean, I think everyone is going to be experiencing hearing loss in, you know, on this floor. So, you know, it was just surprising, surprising to me.

413
00:37:28,960 --> 00:37:35,960
So, yeah, I don't know that we'll have new standards, but you never know. It kind of depends on what evolves.

414
00:37:35,960 --> 00:37:46,960
I do actually know I think about it. I think the data sets, I think we are going to have to have some standards that clearly ensure that we have good diversity and all the conversations going on about bias.

415
00:37:46,960 --> 00:37:54,960
I mean, that that's a big part of it right there. It's just making sure that we aren't accidentally continuing to discriminate against people with disabilities.

416
00:37:54,960 --> 00:38:08,960
Because unfortunately, that is quite a reality, especially when you look at, yeah, well, I'll just say that. And that's part of the culture change. I think AI can really help with is ensuring that we're supporting a culture of more diversity.

417
00:38:08,960 --> 00:38:18,960
Yeah, I think one of the things that's most exciting about all the work that's happening in so many places about AI for social good.

418
00:38:18,960 --> 00:38:37,960
And the various aspects of it is just how intersectional it is that, you know, the issues that the folks that are working on AI ethics and AI bias and now the work that we're discussing here around accessibility at ties in so many ways.

419
00:38:37,960 --> 00:38:51,960
And I guess what's kind of bringing that thought to mind is just that I have lots of conversations about bias and bias and data sets, bias and AI systems and you know, think about how important that is in this context.

420
00:38:51,960 --> 00:39:04,960
And then how, you know, as we overcome those issues and create new technologies here, how that feeds into the technologies that we all benefit from.

421
00:39:04,960 --> 00:39:11,960
Yeah, I can't help but think it creates exciting opportunities for folks that want to kind of jump into this field.

422
00:39:11,960 --> 00:39:17,960
Well, that's the thing. And I think that's when I've been talking. So some of our applicants aren't as familiar with disabilities.

423
00:39:17,960 --> 00:39:23,960
And that's great. They're familiar with AI and machine learning and they can see, oh, this is how I can get the data you're looking for.

424
00:39:23,960 --> 00:39:39,960
And that's really a very cool thing is that if we can bring together people who are looking for ways that their work in AI and machine learning can impact humans all over the planet.

425
00:39:39,960 --> 00:39:46,960
I think that that's a very exciting opportunity where we can really start making those partnerships and bringing people together kind of matchmaking.

426
00:39:46,960 --> 00:40:01,960
You know, like, hey, we see over here that this community has this need. Is there anyone out there doing something similar and we can pair you together and then, you know, you can test this out and continue to evolve your work in a way that's really going to be impactful for somebody.

427
00:40:01,960 --> 00:40:08,960
And, you know, one of the things we keep saying is we're funding projects that are developed with or by people with disabilities.

428
00:40:08,960 --> 00:40:19,960
And again, that's because it's when it's grounded in reality, then you know, you get something good. You know, Lois and Matthew talk about how much time is around the UX.

429
00:40:19,960 --> 00:40:33,960
And I think that's so important. You know, that's where the really good stuff comes from is when you're really looking at how people use this and how they are going to integrate it into their daily lives. What it allows people to do.

430
00:40:33,960 --> 00:40:47,960
Lois, when you look forward, what's, you know, what do you see in terms of incorporating AI more deeply in what I therapies doing?

431
00:40:47,960 --> 00:40:54,960
Well, we have we have plans probably up and through the next 10 years.

432
00:40:54,960 --> 00:41:14,960
We continue using this. We have great plans. It's really made, you know, it's made a big difference with a lot of our students. However, one of the main, the main pain points that they have is by the time they come up with something to say are there they can't or join a conversation.

433
00:41:14,960 --> 00:41:30,960
The conversation is done. It's fluency. It's the rate that they speak. And that's across the board and across abilities and ages is that if you're using a device to speak and not using your own voice, it takes a lot longer.

434
00:41:30,960 --> 00:41:47,960
That is probably the gap I would love to bridge is that someone who cannot use their natural voice can jump into a conversation and speak like anyone else. That's going to be difficult and that's absolutely going to be AI.

435
00:41:47,960 --> 00:42:04,960
Currently that it takes so long for for people to either generate a sentence or search for the word they want to say that most folks check out of the conversation and our folks don't really get to have one on one conversations unless they're pre made and scripted.

436
00:42:04,960 --> 00:42:11,960
So that's our I think my ultimate ultimate goal is folks who have challenges speaking can speak like just about anyone else.

437
00:42:11,960 --> 00:42:23,960
Yeah, that's a really beautiful moonshot. There's a lot of these things in AI where we look for that real time with the jogging track that real time feedback and hear real time speech generation.

438
00:42:23,960 --> 00:42:31,960
And we see that in a lot of scenarios. And I think that's yeah, I agree. That's that's the that's the vision. That's a good vision.

439
00:42:31,960 --> 00:42:49,960
Matthew, what's what are you most excited about from an AI perspective? Well, we are looking into coming up with some diagnostic tools, which I think are going to be really cool.

440
00:42:49,960 --> 00:43:12,960
I think they so we're hoping to come up with we're just in the preliminary pieces of this now, but using AI to analyze data through possibly a Q&A framework and to help people create solutions for communication delays or disorders.

441
00:43:12,960 --> 00:43:24,960
So basically one of the ways that we as speech pathologist evaluate people now it's the kind of paper and pencil test and then you have to score it and then it just becomes kind of cumbersome.

442
00:43:24,960 --> 00:43:30,960
And so what we're hoping is we're taking a look at some kind of far out ideas.

443
00:43:30,960 --> 00:43:46,960
In fact, I read this article in wired magazine about a guy named Carl Friston who's into this concept called free energy. And so we're thinking of some ways to take that concept and apply that to diagnosing communication disorder.

444
00:43:46,960 --> 00:43:59,960
So I think that's pretty exciting. So we're that should be in the next few years. So that's that's my I guess goal for the future is to develop that among other things.

445
00:43:59,960 --> 00:44:14,960
Nice. Nice. So one day I gather that by the time folks get an opportunity to listen to this podcast, you'll be just in the midst of finalizing your next round of grantees.

446
00:44:14,960 --> 00:44:29,960
Yeah. Yeah. Before the for folks that hear this and are interested in working with this program, what is the process to look like and you know, when should they start looking for the next round to open up?

447
00:44:29,960 --> 00:44:45,960
Oh, really? Yeah. We're constantly kind of reviewing them. And the link to apply is really easy. It's aka.ms slash grant. Super easy. So aka.ms slash grant.

448
00:44:45,960 --> 00:45:03,960
Yeah. So you pull together an application and we'll review that. We're really looking for projects that are going to elevate the industry. We're not as interested in funding just someone to develop an application.

449
00:45:03,960 --> 00:45:23,960
Not someone who is going to contribute something back because for us, that's really how we're going to raise the water and bring up the boat. You know, and so that's part of what we're looking at is either someone willing to contribute a data set or a model or some other learning, whether research paper or something like that.

450
00:45:23,960 --> 00:45:36,960
And obviously someone who's whether by themselves or through partnership or grounded in community. And that it's something that'll be feasible to accomplish in a year.

451
00:45:36,960 --> 00:45:49,960
So while we in tip, we really are looking for projects that will go beyond a year and there's something that can be built on the grants are your long grants. And so there needs to be some deliverable in that year.

452
00:45:49,960 --> 00:46:00,960
But yeah, and we encourage everyone to apply. I mean, literally anyone from anywhere. So we've done a push in Latin America. We're going to be reaching out to Asia soon.

453
00:46:00,960 --> 00:46:16,960
We do have grantees in different regions. We have a few folks in Europe, one in India. And we're really looking to expand that because especially I'd really encourage folks in Asia and Latin America because

454
00:46:16,960 --> 00:46:28,960
I recently learned and just to spend a moment on Latin America that the unemployment rate in general for people with disabilities is usually twice that of people without.

455
00:46:28,960 --> 00:46:37,960
And the average age is 30 years old in Latin America. And to me, that's like prime employment age. And so we really want to shift those employment numbers to that point.

456
00:46:37,960 --> 00:46:47,960
We really are looking for people for applications and projects that are going to have an impact in our focus areas, which are employment, daily life and communication and connection.

457
00:46:47,960 --> 00:46:58,960
So for example, Lois and Matthew, this is communication and connection, the jogging track that's daily life because that's out and about being independent.

458
00:46:58,960 --> 00:47:13,960
And then employment is another one we've got from Vanderbilt is a good example where they're building a bot that can help someone who has autism and, you know, it's interested in practicing for job interviews and stuff like that.

459
00:47:13,960 --> 00:47:21,960
So it's going to it does some really cool modification of the interview to help someone practice.

460
00:47:21,960 --> 00:47:33,960
So, yeah, I encourage anybody and it NGO nonprofit, individuals, companies, slings, you meet some of those criteria, go for it.

461
00:47:33,960 --> 00:47:36,960
And are they fixed size grants or what's the range?

462
00:47:36,960 --> 00:47:44,960
Yeah, so right now we have a couple categories. We've got one set of grants where we're, it's just called an Azure credits.

463
00:47:44,960 --> 00:47:51,960
And so we're just giving folks credits to just play and learn and see what they come up with, make some progress on their idea.

464
00:47:51,960 --> 00:47:59,960
The other one is kind of an Azure credits plus. And in that one, that's the category that Matthew and Lois are in.

465
00:47:59,960 --> 00:48:16,960
Is we have a community we have a lot of support in terms of education and we've got on staff folks who can help with technical questions integration with Azure. We've got great connections with cognitive services, Microsoft research.

466
00:48:16,960 --> 00:48:29,960
So we can really support folks in their development and give them cash for engineering costs or data acquisition data cleaning data labeling, you know, kind of some of those pieces just needed to build.

467
00:48:29,960 --> 00:48:41,960
And right now we don't we're not really saying much about how much it is we're new we're kind of experimenting with how much we give people and what results we got.

468
00:48:41,960 --> 00:48:46,960
So yeah, we'll see how it goes.

469
00:48:46,960 --> 00:48:52,960
Do you by any chance have a wish list of ideas that you'd love to fund?

470
00:48:52,960 --> 00:49:00,960
I do. Yes, we have several moonshots that I'd love to see. I want to see a self-driving wheelchair.

471
00:49:00,960 --> 00:49:14,960
I want to see a dashboard for people with PTSD like I said that I want that dashboard for myself that pulls together all the data that I have and really learns and can start recommending and predicting.

472
00:49:14,960 --> 00:49:25,960
I want to keep to get his digital assistant so that he can be out and about as he's traveling and get you know information to make decisions.

473
00:49:25,960 --> 00:49:33,960
I love for my friend who is deaf who recently went in for a surgery and her sign language interpreter was late.

474
00:49:33,960 --> 00:49:38,960
So she had to lip read and it was very scary she didn't have all the information.

475
00:49:38,960 --> 00:49:43,960
But if she had had kind of a backup interpreter that could help her in that situation.

476
00:49:43,960 --> 00:49:49,960
And you know the doctor couldn't wait, you know, so those are some of the things that we're looking for.

477
00:49:49,960 --> 00:49:57,960
And then I'm just curious to learn what other ideas people have out there. Like I said, there's some things I heard this week I hadn't even thought were needed.

478
00:49:57,960 --> 00:50:01,960
And now I really want to fund them. So fantastic.

479
00:50:01,960 --> 00:50:11,960
Well, Wendy, Lois and Matthew, thank you so much for taking the time to chat with us about AI for accessibility.

480
00:50:11,960 --> 00:50:12,960
Thank you.

481
00:50:12,960 --> 00:50:21,960
Lois and Matthew, in particular, congratulations for what you're doing. It sounds like a great application with a lot of impact and Wendy great program.

482
00:50:21,960 --> 00:50:22,960
Thank you.

483
00:50:22,960 --> 00:50:23,960
Yeah, thanks.

484
00:50:23,960 --> 00:50:24,960
Thanks so much.

485
00:50:24,960 --> 00:50:25,960
Thank you, Sam.

486
00:50:29,960 --> 00:50:32,960
All right, everyone, that's our show for today.

487
00:50:32,960 --> 00:50:42,960
For more information on Wendy, Lois, Matthew or any of the topics covered in this episode, visit twimlai.com slash talk slash 227.

488
00:50:42,960 --> 00:50:51,960
To follow along with our AI for the benefit of society with Microsoft series, visit twimlai.com slash AI for society.

489
00:50:51,960 --> 00:50:59,960
Thanks once again to Microsoft for sponsoring this show and series. Learn more about their plan for AI at Microsoft.ai.

490
00:50:59,960 --> 00:51:03,960
As always, thanks so much for listening and catch you next time.

