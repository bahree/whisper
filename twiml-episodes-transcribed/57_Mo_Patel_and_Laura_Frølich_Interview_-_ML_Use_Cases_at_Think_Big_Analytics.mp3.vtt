WEBVTT

00:00.000 --> 00:15.920
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

00:15.920 --> 00:20.880
people doing interesting things in machine learning and artificial intelligence.

00:20.880 --> 00:23.240
I'm your host Sam Charrington.

00:23.240 --> 00:27.480
This show you are about to hear as part of a series of shows recorded in San Francisco

00:27.480 --> 00:32.000
at the Artificial Intelligence Conference, which was hosted by our friends at O'Reilly

00:32.000 --> 00:33.800
in Intel Nirvana.

00:33.800 --> 00:39.000
In addition to their support for the event itself, Intel Nirvana is also our sponsor for this

00:39.000 --> 00:41.560
series of podcasts from the event.

00:41.560 --> 00:45.920
A huge thanks to them for their continued support of this show.

00:45.920 --> 00:50.960
Make sure you check out my interview with Navine Rao, VP and GM of Intel's AI products

00:50.960 --> 00:56.280
group, and Scott Appland, director of Intel's developer network, which you can find at

00:56.280 --> 01:00.880
Twimbleai.com slash talk slash 51.

01:00.880 --> 01:06.800
At the AI conference, Intel Nirvana announced DevCloud, a cloud hosted hardware and software

01:06.800 --> 01:13.680
platform for learning, sandboxing and accelerating the development of AI solutions.

01:13.680 --> 01:19.920
The DevCloud will be available to 200,000 developers, researchers, academics and startups

01:19.920 --> 01:23.760
via the Intel Nirvana AI Academy this month.

01:23.760 --> 01:30.400
For more information on the DevCloud or the AI Academy, visit intelnervana.com slash

01:30.400 --> 01:32.480
DevCloud.

01:32.480 --> 01:35.360
Our first multi-person interview.

01:35.360 --> 01:41.120
I speak with Mo Patel, practice director of AI and deep learning and Laura Forelich,

01:41.120 --> 01:44.840
data scientist of Think Big Analytics.

01:44.840 --> 01:50.120
Mo and Laura joined me at the AI conference after their session on training vision models

01:50.120 --> 01:53.440
with public transportation data sets.

01:53.440 --> 01:57.320
We talked about this and a bunch of other interesting use cases they worked on involving

01:57.320 --> 02:02.440
image analysis and deep learning, including an assisted driving system.

02:02.440 --> 02:07.040
We also talked through the practical challenges faced when working on real machine learning

02:07.040 --> 02:11.480
problems by feature detection, data augmentation and training data.

02:11.480 --> 02:12.960
All right, everyone.

02:12.960 --> 02:18.520
I am here at the AI conference, and I am with a couple of guests this time.

02:18.520 --> 02:23.080
I am with Laura Forelich and Mo Patel with Think Big Analytics.

02:23.080 --> 02:28.440
In fact, Mo and I, we had an opportunity to meet at a conference a while back, and you

02:28.440 --> 02:32.960
kind of came up to me and introduced yourself as a listener of the podcast, which I think

02:32.960 --> 02:36.800
that was maybe the first time that ever happened to me, and I was like, excited out of my

02:36.800 --> 02:37.800
mind.

02:37.800 --> 02:44.200
Yeah, I remember you were actually talking to the people that chain the deep learning

02:44.200 --> 02:51.680
framework, and I was like, I recognize that voice, you know, it's a very recognizable

02:51.680 --> 02:52.680
voice.

02:52.680 --> 02:56.520
And we had an interesting conversation about the industrial AI stuff that I was working

02:56.520 --> 02:59.280
on at the time, and some of the work that you were doing there.

02:59.280 --> 03:04.960
So then when we saw that you and Laura were doing a presentation here at this conference

03:04.960 --> 03:07.520
in San Francisco, I thought, oh, we got to get you on the show.

03:07.520 --> 03:08.520
So welcome.

03:08.520 --> 03:09.520
Thank you.

03:09.520 --> 03:10.520
Thank you.

03:10.520 --> 03:15.520
This is actually the first time I'm doing an interview with two guests, so to be interesting

03:15.520 --> 03:18.960
to just how the kind of traffic management works.

03:18.960 --> 03:23.280
But why don't we start by having Laura introduce yourself?

03:23.280 --> 03:30.400
OK, so currently I'm a data scientist working with Think Big Analytics, as you just mentioned.

03:30.400 --> 03:33.120
So I work on all types of projects.

03:33.120 --> 03:37.360
Whenever a customer or company has a lot of data that they want to gain insight from

03:37.360 --> 03:41.840
to solve some use case, I can help them out.

03:41.840 --> 03:47.320
It doesn't have to be deep learning, like any sort of method that tries to reveal relevant

03:47.320 --> 03:52.960
patterns using some method that makes sense, given the use case and the data at hand,

03:52.960 --> 03:54.520
we'll go with that.

03:54.520 --> 04:01.480
Before joining Think Big, I spent half a year in a research group where they investigated

04:01.480 --> 04:05.160
something called non-specific effects of vaccines, which is basically vaccines turn

04:05.160 --> 04:09.680
out to affect the immune system in a general way, not just protecting against the targeted

04:09.680 --> 04:10.680
disease.

04:10.680 --> 04:12.880
So very interesting research.

04:12.880 --> 04:19.280
That I did a PhD at the Technical University of Denmark using various machine learning techniques

04:19.280 --> 04:21.880
to analyze brain activity data.

04:21.880 --> 04:22.880
Oh, wow.

04:22.880 --> 04:23.880
Yeah.

04:23.880 --> 04:25.320
So that's sort of my background.

04:25.320 --> 04:26.320
OK.

04:26.320 --> 04:27.320
Enemote?

04:27.320 --> 04:32.560
Yeah, I am currently the practice director for AI with Think Big Analytics, mostly looking

04:32.560 --> 04:34.600
at America's customers.

04:34.600 --> 04:41.520
And part of that is probably not as working on projects as much, but doing more of the

04:41.520 --> 04:45.560
proof-of-concept type work, so taking some of the most advanced things that are going

04:45.560 --> 04:50.000
out there and see if we can apply them to our clients' problems, so part of that.

04:50.000 --> 04:54.240
So there's a hands-on portion of it, but then there's also the dreaded power-pointing

04:54.240 --> 04:59.480
of things, character-version of that highly technical stuff, into things that people don't

04:59.480 --> 05:03.840
understand, which is a kind of a fascinating part of it, because I really love that trying

05:03.840 --> 05:07.400
to lower the barriers, because there's a lot of hyperion, I try to lower the barriers

05:07.400 --> 05:11.720
so that people can understand that this is not terminated or it's actually just math,

05:11.720 --> 05:12.720
right?

05:12.720 --> 05:18.000
So that's kind of my day-to-day, I really like doing that, and my background is I come

05:18.000 --> 05:23.720
from, if you look at data science, machine learning type things, I come from more of

05:23.720 --> 05:28.000
the computer science side, compared to people who come from statistics or maybe from some

05:28.000 --> 05:34.040
sciences, the hard sciences, or the years software engineering, into transitioning into more

05:34.040 --> 05:40.080
math type software engineering, and then into analytics, and yeah, oh, nice, nice.

05:40.080 --> 05:46.880
And so the two of you did a talk yesterday, it was actually a tutorial, yeah, what was

05:46.880 --> 05:48.520
the tutorial about?

05:48.520 --> 05:54.160
The tutorial yesterday was on image analysis using deep learning methods, in brief.

05:54.160 --> 06:00.560
So we had both the general introduction, making sure that everyone was on the same level,

06:00.560 --> 06:06.120
agreed on what is an image, what are pixels, what sorts of values are we dealing with,

06:06.120 --> 06:15.040
and so on and so forth like, and also going into what sorts of problems can we talk about

06:15.040 --> 06:20.400
in the image analysis, and then we went into more detail on one particular topic, object

06:20.400 --> 06:25.480
detection, and zoomed back out a bit in the end.

06:25.480 --> 06:29.920
So that's how I sort of see the whole framing of the talk, I don't know if you have anything

06:29.920 --> 06:30.920
to them.

06:30.920 --> 06:36.240
Yeah, absolutely, I think, but just kind of making sure that people are aware of the computer

06:36.240 --> 06:43.440
vision basics, and then diving into something that is fairly cutting edge, object detection,

06:43.440 --> 06:50.000
and a lot of applications out there, and not only the theoretical part, but also in a notebook

06:50.000 --> 06:54.400
style kind of layout saying, hey, this is how you can actually do it yourself as well,

06:54.400 --> 06:55.400
right?

06:55.400 --> 06:58.400
I felt that was very compelling, and then towards the end, talked about some of the challenges

06:58.400 --> 07:03.680
around training models, you know, it's like, we make it sound so easy, but to do it for

07:03.680 --> 07:08.280
real data, there are many challenges, and so we talked about that and we can go into

07:08.280 --> 07:09.280
that detail if you want.

07:09.280 --> 07:11.280
Yeah, what are some of the challenges?

07:11.280 --> 07:16.920
Yeah, absolutely, you know, for example, there was a paper that came out or the weekend,

07:16.920 --> 07:22.920
how this team trained image net data set in 24 minutes, right, and, and, I mean, you

07:22.920 --> 07:23.920
look a bit of a controversy.

07:23.920 --> 07:28.320
Yeah, yeah, it was, of course, yeah, because, you know, it's like, well, they used that

07:28.320 --> 07:32.920
headline was Alex Net, not ResNet, which is like more of the current state of the art,

07:32.920 --> 07:36.880
and, and what kind of hardware you use, and all sorts of different things, but that is

07:36.880 --> 07:40.960
exactly the type of thing, right, is that what are all the different parameters, like

07:40.960 --> 07:47.440
batch sizes and, and different processors and, and multi GPU, multi server, because most

07:47.440 --> 07:52.840
of the things you see the examples of tutorials, it's like, just run this code, right?

07:52.840 --> 07:57.360
But if you in production, even you have like a million images, and you need to make sure

07:57.360 --> 08:01.920
that this will train over like days and not weeks, you know, you may have to scale it,

08:01.920 --> 08:05.920
and how do you do the scaling, and those are all the challenges that's kind of like more

08:05.920 --> 08:10.600
engineering style challenges, but then there's also challenges around annotation, right?

08:10.600 --> 08:15.720
It's like, well, this is supervised learning, you have to annotate the data, and that could

08:15.720 --> 08:20.720
mean anything from, it's like, you know, simple classification, kind of easy, so to speak,

08:20.720 --> 08:21.720
right?

08:21.720 --> 08:23.520
But there's a picture, and there's a label, right?

08:23.520 --> 08:28.280
Now you, for object detection, there could be bounding boxes, so you draw squares around

08:28.280 --> 08:32.440
the objects like our balls, and, and, you know, like umbrella, and, and things like that,

08:32.440 --> 08:36.760
to make sure, and then label it that this is what the object is, and then the, even something

08:36.760 --> 08:40.680
more advanced, which is kind of drawing the polygons around the objects itself, which

08:40.680 --> 08:45.080
is the segmentation, kind of like the holy grail of, of, toward getting towards being able

08:45.080 --> 08:46.960
to do object detection.

08:46.960 --> 08:50.640
Many challenges in, and of course, you can try to do it internally or externally, we

08:50.640 --> 08:55.480
actually, for a project, we actually built a segmentation tool that allowed people to

08:55.480 --> 09:00.200
go ahead and draw boxes around cars, and pedestrians, and things like that.

09:00.200 --> 09:04.760
So, you know, as much as we talk about the deep learning parts, right, there's all sorts

09:04.760 --> 09:09.920
of many data engineering, data prep, data cleaning, things that were, have been around,

09:09.920 --> 09:12.560
and also the traditional data science for a while, right?

09:12.560 --> 09:15.280
So very much of, of, of, challenge.

09:15.280 --> 09:19.600
And so that's that a bit with the annotation tool that we built internally.

09:19.600 --> 09:24.880
We have that tool, and we were using it internally, but our team was just not large enough to

09:24.880 --> 09:30.320
annotate enough images quickly enough, so we had to both use that and go to an external

09:30.320 --> 09:35.600
company to help, get help from them to annotate all the images, and that was a lot of back and

09:35.600 --> 09:38.960
forth with them just defining their requirements.

09:38.960 --> 09:41.000
What sorts of things do we want labeled?

09:41.000 --> 09:46.080
How do we want them labeled, like, what's the smallest size of object that we require

09:46.080 --> 09:47.400
labels on?

09:47.400 --> 09:51.720
What do we do if it's partially obscured, like, if there's a car blocking another car?

09:51.720 --> 09:56.120
Those sorts of things, because you may have difficulties if you have a really small object,

09:56.120 --> 10:00.960
and you label it, then during the training phase, you'll be punished.

10:00.960 --> 10:04.560
The model will be punished if you don't detect that object, but it may actually not be

10:04.560 --> 10:09.480
very interesting to detect that object at test time, because small image, small objects

10:09.480 --> 10:14.160
are far away, so you may want to focus on objects that are closer.

10:14.160 --> 10:19.120
One way to handle that would be to put an extra label and small objects, saying, difficult,

10:19.120 --> 10:24.640
in that way you might handle such objects differently from normally labeled objects by not punishing

10:24.640 --> 10:28.720
the model if it doesn't detect them, but also not punishing the model if it does detect

10:28.720 --> 10:29.720
them.

10:29.720 --> 10:36.400
Yeah, I've had some interesting conversations with folks that specialize in labeling data

10:36.400 --> 10:42.040
for folks, and it really opened my eyes to just this process that you're describing.

10:42.040 --> 10:46.120
If you think of, hey, just label my data, but if you're talking about images, all different

10:46.120 --> 10:51.480
kinds of ways that you can do it, and they have direct impact on the types of, you know,

10:51.480 --> 10:54.560
not just the types of models that you're creating in their performance, but the cost of the

10:54.560 --> 10:55.560
labeling process.

10:55.560 --> 10:56.560
Yeah, exactly.

10:56.560 --> 11:01.640
So, this company that we worked with had this quite elaborate pricing scheme, I never

11:01.640 --> 11:05.440
really looked at the details of it, but if you increase the number of classes, you would

11:05.440 --> 11:08.600
sort of get an extra cost to the first classes as well.

11:08.600 --> 11:12.760
So you really had to consider, like, more maybe can we sort of have this external company

11:12.760 --> 11:17.680
to part of the labeling and then do some further post processing in our own tool, like

11:17.680 --> 11:18.680
a way.

11:18.680 --> 11:22.440
We needed a machine learning model to optimize the processing for vendor tool.

11:22.440 --> 11:23.440
Yeah, exactly.

11:23.440 --> 11:27.200
And, you know, there are some interesting projects around that, you know, there's that

11:27.200 --> 11:32.160
snorkel project from the Don Lab at Stanford, they're trying to do some stuff around kind

11:32.160 --> 11:37.240
of, you know, around the training data and building, building more training data, which

11:37.240 --> 11:42.000
just reminded me, another big one is a data augmentation, which is another thing that,

11:42.000 --> 11:47.360
you know, if your data doesn't have, I example, I gave, is that having the road data for when

11:47.360 --> 11:49.800
it's foggy versus when it's not, right?

11:49.800 --> 11:53.680
And what if we never capture the fog based, which is, it should be hard to do in San Francisco,

11:53.680 --> 11:58.520
but, you know, what it's so, so those are all the type of things that, so luckily, you

11:58.520 --> 12:02.960
know, at least what's great is that a lot of money, much of this knowledge has been encoded

12:02.960 --> 12:07.840
now where they're just in chaos, there's just a function for data augmentation, sure,

12:07.840 --> 12:11.440
maybe you could add your own, but there is that state of the art, like might as well just

12:11.440 --> 12:15.000
use that when you're training process, but these are all the things and it's like when

12:15.000 --> 12:17.960
you think about simply, it's like, yeah, just take the images, run it through a deep learning

12:17.960 --> 12:23.360
model and outcomes your, your trained model after you do all the deep learning things,

12:23.360 --> 12:27.840
like generalization and, and, and loss optimization, all those things, but then there's all these

12:27.840 --> 12:31.960
other things that you have to kind of worry about, yeah.

12:31.960 --> 12:35.800
And regarding data augmentation, even though people have made tools that you can sort of

12:35.800 --> 12:40.560
just use, you of course have to think about all of the data augmentation steps, do they

12:40.560 --> 12:41.560
make sense?

12:41.560 --> 12:46.680
For traffic scenes, do you really want to flip your images horizontally to teach the

12:46.680 --> 12:49.200
model that an upside down car is also a car?

12:49.200 --> 12:51.960
Well, maybe you do, but it depends on your use case, right?

12:51.960 --> 12:52.960
Right.

12:52.960 --> 12:53.960
That would depend on your use case.

12:53.960 --> 12:54.960
Yeah.

12:54.960 --> 12:55.960
I mentioned action movies, you know?

12:55.960 --> 12:56.960
Yeah.

12:56.960 --> 13:00.440
I'm going to get those upside down cars, yeah.

13:00.440 --> 13:06.480
And so these are, these are just some of the issues that you run into in the training phase

13:06.480 --> 13:08.880
of building and deploying a deep learning model.

13:08.880 --> 13:12.640
And then there's the whole, you know, how do you actually get this out into the wall to

13:12.640 --> 13:13.800
do inference?

13:13.800 --> 13:19.000
Like, are there, you know, best practices, tips, tools of the trade or, you know, tricks

13:19.000 --> 13:20.320
that you've come across for that?

13:20.320 --> 13:21.320
Yeah.

13:21.320 --> 13:26.520
I mean, actually, as much as, as much knowledge there's out there about the training aspects

13:26.520 --> 13:29.280
of it, there's actually not as much.

13:29.280 --> 13:33.920
And something that like even even traditional machine learning in production, I think we

13:33.920 --> 13:37.840
always, we heard this thing about data science and like, there's not a, you know, there's

13:37.840 --> 13:42.320
a lot of talk about it, but the in production is still not, you know, you could do a survey

13:42.320 --> 13:46.680
and you probably find that only maybe off all the people who actually say they do data science

13:46.680 --> 13:50.360
only 25 to 30% maybe actually put it into production.

13:50.360 --> 13:53.760
And then once you get to deep learning, that could, that number could start even going

13:53.760 --> 13:54.760
lower.

13:54.760 --> 13:58.520
And I think that's just because as you were saying that there are, there is a whole different

13:58.520 --> 14:02.040
set of challenges when you're trying to put models into production, right?

14:02.040 --> 14:03.960
So number one, where are you going to put it?

14:03.960 --> 14:07.240
Are you going to put it on some beefy servers in a data center?

14:07.240 --> 14:11.160
Then maybe you have lesser problems because you could take those big, gigabyte size models

14:11.160 --> 14:16.640
and, and stupid, Democrats, containers and kind of a lot of the traditional way of apps

14:16.640 --> 14:17.640
are served.

14:17.640 --> 14:20.120
But then you start talking about, well, we're going to do mobile.

14:20.120 --> 14:22.600
Well, that's, you know, that becomes another challenge.

14:22.600 --> 14:27.400
How do you compress the models, maybe quantization, you know, lowering the floating point and

14:27.400 --> 14:28.400
things like that?

14:28.400 --> 14:31.600
So, you know, that's another, and somebody actually asked this question, they're like,

14:31.600 --> 14:35.440
I was like, can I take this and put it into a card to, you know, do this?

14:35.440 --> 14:39.600
And we're like, there is a lot more that would go into it before you be able to do that.

14:39.600 --> 14:42.000
So the training is definitely challenging.

14:42.000 --> 14:46.600
But being able to serve the models at scale, brings in kind of all your traditional DevOps

14:46.600 --> 14:51.600
and data ops, kind of bringing it all in, model management, version control of the models

14:51.600 --> 14:55.960
and data lineage, traceability, everything that we've been discussing for any other data

14:55.960 --> 14:57.160
science type things.

14:57.160 --> 14:59.640
Those are all bring, they're back on the table, right?

14:59.640 --> 15:01.880
And how complex those can be.

15:01.880 --> 15:06.800
Are there emerging or accepted tools or open source projects for doing that kind of thing?

15:06.800 --> 15:11.640
I know that, you know, some of the folks, some of the vendors that focus on, you know,

15:11.640 --> 15:15.920
machine learning platforms, they've got some of that stuff built in or integrated into

15:15.920 --> 15:16.920
their tool set.

15:16.920 --> 15:22.520
But it's all like, you know, within that tool set, are there, you know, is there a kind

15:22.520 --> 15:27.480
of open source model management framework, for example, that's kind of emerging as a

15:27.480 --> 15:32.240
standard or does it have to be kind of custom cut for an individual use case?

15:32.240 --> 15:34.240
At least I haven't come across.

15:34.240 --> 15:39.280
I know we built one internally, yeah, from just a lot of our projects, right?

15:39.280 --> 15:43.560
Because we saw this need of model management and, you know, it's internally called Tink

15:43.560 --> 15:48.480
Deep, you know, for managing models, you know, it's maybe, maybe we'll become a

15:48.480 --> 15:52.280
open source, you know, you know, how these things go, you know, I think big we have tried

15:52.280 --> 15:56.080
to make things open source, for example, the Kylo Framework for data lakes, you know,

15:56.080 --> 16:00.240
so this could be another path on that roadmap, but, you know, there's a lot of polishing

16:00.240 --> 16:01.760
that needs to be done before it gets.

16:01.760 --> 16:05.360
So folks should reach out to you if they want to get their hands on this open source.

16:05.360 --> 16:10.560
Yeah, possibly, possibly, I'm not the operator, so I can definitely put in touch.

16:10.560 --> 16:14.200
But I have not come across, there are definitely some projects.

16:14.200 --> 16:19.080
Once again, the formally amp lab, the UCB rise now, right, and then, and then Stanford

16:19.080 --> 16:20.080
Don, right?

16:20.080 --> 16:25.440
They, they have, I can't remember the names of the projects of my top of my head, but

16:25.440 --> 16:31.160
I've seen that in, that's in their program agenda for being able to serve large scale machine

16:31.160 --> 16:34.960
learning models and you can consider deep learning into that, into that.

16:34.960 --> 16:39.360
And I will, you know, I'm not, not do a commercial plug, but that's actually one of the things

16:39.360 --> 16:43.400
that we are also focused on because when we look at things, it's like, yeah, training

16:43.400 --> 16:48.360
is, is there, but we work with traditional customers, enterprise customers who want to

16:48.360 --> 16:52.600
put all that stuff into production because all the investment, investment they make on

16:52.600 --> 16:57.320
AI or deep learning, data science is useless unless they actually put the models into production,

16:57.320 --> 16:58.320
right?

16:58.320 --> 17:02.920
So building the tooling around that, monitoring the models and all of those things are

17:02.920 --> 17:03.920
interpreglability.

17:03.920 --> 17:05.160
It's a huge part.

17:05.160 --> 17:10.240
All of those being able to kind of have one stop shop for that is very attractive.

17:10.240 --> 17:13.880
So there's commercial aspects to it.

17:13.880 --> 17:14.880
Interesting, interesting.

17:14.880 --> 17:20.360
So we, before we got started, we mentioned a few use cases that you would be able to

17:20.360 --> 17:24.840
kind of talk to us about and walk us through and the first one is one that you worked on

17:24.840 --> 17:29.120
Laura as a traffic project that you worked on with an automotive parts manufacturer and

17:29.120 --> 17:33.720
it sounds like this was in some ways an inspiration for the session, the tutorial that you did

17:33.720 --> 17:34.720
here.

17:34.720 --> 17:35.720
Can you tell us about them?

17:35.720 --> 17:41.480
So this project was for an assisted driving system.

17:41.480 --> 17:47.880
So that self-driving at all, we didn't want to go there, but just to help each other

17:47.880 --> 17:48.880
essentially.

17:48.880 --> 17:54.520
So the idea was that you have a car that's connected to the system and it's driving along

17:54.520 --> 17:59.920
like doing whatever it's doing, going where it's going and it has a camera recording whatever

17:59.920 --> 18:01.400
it passes.

18:01.400 --> 18:06.880
If it happens to pass a stop car that's on the road, it might be a good thing to be able

18:06.880 --> 18:10.840
to detect that, to tell other cars, hey, look out.

18:10.840 --> 18:15.160
If you're in this lane, you might want to change lanes already now, so you don't sort of

18:15.160 --> 18:18.200
get a surprise when you get to that stop car.

18:18.200 --> 18:24.240
You could even have that indicate this an accident or just congestion.

18:24.240 --> 18:30.600
So stop cars on the road is definitely something that you might want to tell other cars about.

18:30.600 --> 18:35.000
So the project was about trying to detect this and there are a lot of steps to this.

18:35.000 --> 18:40.000
First, a video is of course a lot of images that come in one at a time.

18:40.000 --> 18:45.800
So the first step was trying to look at, okay, so how well can we detect the objects

18:45.800 --> 18:51.400
and trying to compare the various object detection methods that were out there, see how fast

18:51.400 --> 18:57.200
are they, how accurate are they, all of these things and also try to get an idea of how

18:57.200 --> 18:59.440
might we be able to improve them.

18:59.440 --> 19:05.680
Then subsequently you have to be able to tell is this part of the picture part of the

19:05.680 --> 19:06.680
road?

19:06.680 --> 19:07.960
Or is it not part of the road?

19:07.960 --> 19:12.960
Because if it's not part of the road, if it's parking, you don't care so much whether

19:12.960 --> 19:16.640
there are stopped cars in that car's in there, so that's another thing.

19:16.640 --> 19:19.360
Thirdly, you'll want to be able to tell is the car moving.

19:19.360 --> 19:22.600
So one thing is detecting the cars in each image.

19:22.600 --> 19:28.040
Another thing is seeing, so this is the same car that I just saw in the previous image.

19:28.040 --> 19:33.880
And then estimating the distance, the difference in distance from when you saw it last, trying

19:33.880 --> 19:36.040
to estimate its speed.

19:36.040 --> 19:43.360
So this comes into object tracking, which is synced to from the research that we were

19:43.360 --> 19:49.720
able to do to be still quite immature compared to object detection.

19:49.720 --> 19:54.120
So far, the detection there are already a lot of methods, a lot of research out there.

19:54.120 --> 19:58.840
For object tracking, it seemed to be less solved.

19:58.840 --> 20:01.040
So we spent some time looking into that.

20:01.040 --> 20:08.000
And so in the end, we had a demo that was able to detect most cars and sort of give an

20:08.000 --> 20:11.960
estimate of is it moving, how fast is it moving?

20:11.960 --> 20:14.200
And that was basically where we stopped.

20:14.200 --> 20:15.200
Okay.

20:15.200 --> 20:20.240
And were you exclusively trying to detect cars or other obstacles in the road?

20:20.240 --> 20:25.040
So we did want to detect other objects in the start of the practice as well, turned out

20:25.040 --> 20:29.120
that there were some difficulties with that because in traffic data sets, you tend to have

20:29.120 --> 20:30.120
a lot of cars.

20:30.120 --> 20:31.120
Right?

20:31.120 --> 20:33.040
You don't have as many people.

20:33.040 --> 20:34.160
You don't have as many bikes.

20:34.160 --> 20:36.120
You don't have as many buses.

20:36.120 --> 20:39.760
So your training data has a high imbalance.

20:39.760 --> 20:45.320
And that just makes it more difficult to learn those other classes that are not cars.

20:45.320 --> 20:52.080
So in the end, we ended up focusing more just the car part of it and not so much on detecting

20:52.080 --> 20:55.120
all the other classes that we were initially interested in.

20:55.120 --> 20:56.120
Okay.

20:56.120 --> 20:57.120
Interesting.

20:57.120 --> 21:02.400
So you mentioned the object detection methods that you came across.

21:02.400 --> 21:09.160
Can you kind of summarize the state of object detection and what are the main methods and

21:09.160 --> 21:12.240
what you found as you compared them one to the other?

21:12.240 --> 21:17.880
So the methods that we looked into most were the ones that were quite recent at the time

21:17.880 --> 21:22.160
of the project, which was taking the beginning of this year.

21:22.160 --> 21:26.640
So at that time, there were a lot of what's referred to as single shot methods.

21:26.640 --> 21:31.600
So you have two versions of one called YoLiLook1s, YoLo.

21:31.600 --> 21:35.160
There's one called single shot multi-box detector.

21:35.160 --> 21:41.160
And what these methods have in common is that they just look at the image once.

21:41.160 --> 21:44.280
So you'll take the image that you're trying to analyze and pass it through the model

21:44.280 --> 21:46.400
once to extract features.

21:46.400 --> 21:50.120
And then based on those features, you'll predict the coordinates of the bounding box as

21:50.120 --> 21:53.680
well as the class of the object within the bounding box.

21:53.680 --> 21:58.360
And you'll do that for a bunch of predefined boxes on the image.

21:58.360 --> 22:04.280
So before like seeing the image, you'll already have to find a large number of what's called

22:04.280 --> 22:08.160
prior boxes or default boxes, their various names.

22:08.160 --> 22:13.920
So for one particular method, it's around 7,300 prior boxes.

22:13.920 --> 22:20.000
For each of these boxes, you give a prediction of the class that it might contain and a

22:20.000 --> 22:24.480
correction to the predefined coordinates to match the object better.

22:24.480 --> 22:29.080
And that's sort of the general theme for these for these single shot methods.

22:29.080 --> 22:30.080
Okay.

22:30.080 --> 22:36.240
Is that they generally they'll predefined some large set of boxes and then detect objects

22:36.240 --> 22:37.720
relative to those boxes?

22:37.720 --> 22:38.720
Yeah.

22:38.720 --> 22:39.720
Exactly.

22:39.720 --> 22:40.720
Okay.

22:40.720 --> 22:41.720
Interesting.

22:41.720 --> 22:47.360
And then on the object tracking side, what was the method that you found and how did you,

22:47.360 --> 22:49.880
what was your experience with it, how did it perform?

22:49.880 --> 22:52.320
So we ended up using a heuristic approach.

22:52.320 --> 22:57.800
So basically looking at the detected objects and a number of frames, I think we ended up

22:57.800 --> 23:01.760
with Iran looking back at the past 20 frames.

23:01.760 --> 23:07.480
Basically trying to match the current car that we're looking at to the car in the previous

23:07.480 --> 23:13.800
images that matches the color of the best and has the closest Euclidean distance and those

23:13.800 --> 23:17.760
sorts of heuristics that turned out to work pretty well.

23:17.760 --> 23:18.760
Okay.

23:18.760 --> 23:22.960
And you mentioned kind of doing a scan of the literature.

23:22.960 --> 23:27.720
Was that one of the methods that you found and the researcher, were you not able to get

23:27.720 --> 23:29.320
any of that stuff to work while?

23:29.320 --> 23:30.320
Yeah, exactly.

23:30.320 --> 23:35.320
So the methods that we found and tried out, we spent quite a while trying to get them

23:35.320 --> 23:37.480
to work and didn't really work out.

23:37.480 --> 23:42.280
So in the end, we just thought, okay, let's try heuristically see how it works.

23:42.280 --> 23:43.960
And it ended up working pretty well.

23:43.960 --> 23:48.040
So then in the interest of time, we went with that.

23:48.040 --> 23:52.560
And of course, we're hoping to get some of the more advanced methods to work in the future.

23:52.560 --> 23:58.440
But the heuristic approach turned out to really give quite good results.

23:58.440 --> 24:02.160
Which is also an important lesson for folks that actually have problems to solve.

24:02.160 --> 24:03.160
Yeah.

24:03.160 --> 24:04.160
Yeah.

24:04.160 --> 24:10.760
So I was observing that project mostly and of course, as you were just saying, for

24:10.760 --> 24:16.720
an outsider, I was like, oh, this is clearly, you need to use the Eurusing Conventional

24:16.720 --> 24:22.360
Networks, but then use recurrent on top of that because you're trying to track something

24:22.360 --> 24:26.720
and then maybe do the predictions for future frames and things of that sort.

24:26.720 --> 24:31.880
And that was the kind of the common, and actually, of course, that's what I searched for.

24:31.880 --> 24:35.000
There is somebody who was working on a recurrent yolo, right?

24:35.000 --> 24:36.000
We did try that, actually.

24:36.000 --> 24:40.040
That was what it means we tried, and yeah, it didn't work, and that's what we mean.

24:40.040 --> 24:44.720
That maybe, you know, this is something that will, as more people, experiment and it will

24:44.720 --> 24:45.720
start evolving.

24:45.720 --> 24:49.400
And because object tracking is another great area for computer vision.

24:49.400 --> 24:55.680
That's a big challenge for folks that are implementing this stuff like in real use cases

24:55.680 --> 25:00.600
is that, you know, I've heard it described and repeated it as kind of overfitting on

25:00.600 --> 25:01.600
a data set, right?

25:01.600 --> 25:04.240
Like, hey, this works great for MSNet, right?

25:04.240 --> 25:06.800
But, you know, for another data set, it doesn't.

25:06.800 --> 25:09.400
It's hard to reproduce the results.

25:09.400 --> 25:11.360
And that's actually another issue that we ran into.

25:11.360 --> 25:16.600
So we took this pre-trained model that someone had under GitHub repo just to see how it worked

25:16.600 --> 25:17.920
and it didn't detect anything.

25:17.920 --> 25:22.840
So this was a sanitation model, and we wanted it to detect roads, and it just didn't detect

25:22.840 --> 25:23.840
anything.

25:23.840 --> 25:27.280
And, of course, in our images, we had a lot of roads because this was a traffic data

25:27.280 --> 25:28.280
set.

25:28.280 --> 25:32.200
And we were like, why is this, and one of the team members wrote the author, and he was

25:32.200 --> 25:37.360
like, oh, well, that's because it didn't do data augmentation, because I wanted to improve

25:37.360 --> 25:42.840
the performance as much as possible to the data set that I'm submitting this entry to.

25:42.840 --> 25:48.440
So this was a competition, and he was just optimizing to these lighting conditions and so

25:48.440 --> 25:50.760
on that the data set had.

25:50.760 --> 25:57.720
So when we retrained the model with data augmentation, it was actually able to detect

25:57.720 --> 26:02.160
a lot more road, even we didn't add any data, we just used data augmentation.

26:02.160 --> 26:04.840
And what is data augmentation doing in this process?

26:04.840 --> 26:09.520
So I think some of the parameters that we tuned in this case was suggesting the brightness

26:09.520 --> 26:11.200
of the training images.

26:11.200 --> 26:17.760
So like we had the original training images that this guy had trained on, but then we added

26:17.760 --> 26:22.760
the same images, but with different levels of brightness and other things to the training

26:22.760 --> 26:23.760
set.

26:23.760 --> 26:30.600
So essentially to deal with things like glare, nighttime, twilight, and all sorts of other

26:30.600 --> 26:32.720
lighting type situations, right?

26:32.720 --> 26:38.400
So just do a bunch of different transformations on the image to adjust the brightness by

26:38.400 --> 26:42.600
a few plus minus a few stops, or maybe apply some cool Instagram filters.

26:42.600 --> 26:43.600
There you go.

26:43.600 --> 26:48.760
Actually, so what's great, once again, I love this field and everything people are doing

26:48.760 --> 26:54.560
because there is a paper around this topic of data augmentation and best practices.

26:54.560 --> 26:59.240
And much of has been codified in Keras and some of the other computer vision libraries.

26:59.240 --> 27:02.000
So you don't have to do imagination.

27:02.000 --> 27:08.560
It's like, let's just apply this best-in-class data augmentation and then we'll just see

27:08.560 --> 27:09.560
if it works.

27:09.560 --> 27:13.040
Of course, if it doesn't, then you may have to go inside and tweak some things.

27:13.040 --> 27:14.040
Yeah.

27:14.040 --> 27:15.040
Okay.

27:15.040 --> 27:16.040
Awesome.

27:16.040 --> 27:17.040
Anything else on that project?

27:17.040 --> 27:19.640
I can think of right now.

27:19.640 --> 27:20.640
Yeah.

27:20.640 --> 27:31.040
I think another thing from just my observations was that, you know, everybody has their local

27:31.040 --> 27:32.040
perspective, right?

27:32.040 --> 27:39.280
And we have a kind of a U.S.-based, U.S. centric viewpoint on traffic and driving.

27:39.280 --> 27:43.840
And I think there's just a different set of things in countries, right?

27:43.840 --> 27:47.360
And one actually, one good example of that is traffic science, right?

27:47.360 --> 27:51.920
You know, like a stop sign is, you know, the concept is somewhat universal, but it is

27:51.920 --> 27:53.320
different in other countries.

27:53.320 --> 27:56.680
So these are the type of things that you heard or account for if you're trying to do more

27:56.680 --> 27:59.920
like sign detection or other types of things.

27:59.920 --> 28:00.920
Yeah.

28:00.920 --> 28:01.920
Excellent.

28:01.920 --> 28:02.920
Excellent.

28:02.920 --> 28:07.400
So you mentioned a project called Lost and Found that was for a logistics company?

28:07.400 --> 28:08.400
Yeah.

28:08.400 --> 28:09.400
Yeah.

28:09.400 --> 28:13.080
And that one, you know, as much as this kind of object detection type things, that one

28:13.080 --> 28:15.520
had a little bit of a different type of challenge.

28:15.520 --> 28:19.240
And that is that it's the type of thing that you were trying to find, right?

28:19.240 --> 28:24.320
So it's like, imagine your shipping packages and then, you know, somehow the package loses

28:24.320 --> 28:27.160
it's tracking label drips off or box break.

28:27.160 --> 28:30.480
And then so this company finds the item and that's like, okay, what is this?

28:30.480 --> 28:32.760
Because a lot of times it's not really clearly.

28:32.760 --> 28:37.840
Or you as a customer will call and say, I'm missing like, you know, a brown pair of shoes,

28:37.840 --> 28:41.040
you know, but this isn't this, you know, and somebody's manually going through all the

28:41.040 --> 28:42.640
stuff to find it, right?

28:42.640 --> 28:44.400
And just, yeah, it's a very tedious process.

28:44.400 --> 28:49.920
And so how do you build a system that could give you like, you know, based on some description?

28:49.920 --> 28:53.040
And I know Google image search is this great, but, you know, we don't have, you know,

28:53.040 --> 28:54.040
it's not available.

28:54.040 --> 28:58.200
It's not available as API even, you know, Google is not giving it to everybody.

28:58.200 --> 29:02.800
And so there's some cloud APIs, but still not this, the point I'm trying to make is that

29:02.800 --> 29:06.960
the universe of items you could lose is infinite, right?

29:06.960 --> 29:09.800
It's not like a 10 class, 90 class, 9000 class.

29:09.800 --> 29:10.800
It's like infinite.

29:10.800 --> 29:15.600
So doing object detection model that will say, oh, we'll just be, we'll just detect the

29:15.600 --> 29:19.080
label of the item and we'll just be able to find it.

29:19.080 --> 29:25.760
So the approach was a little bit of a combination of transfer learning and feature matching as

29:25.760 --> 29:28.760
opposed to like feature detection, feature engineering, feature learning.

29:28.760 --> 29:33.360
So you know, one thing that customers do when they ask the question is they actually

29:33.360 --> 29:37.640
could provide a photo from the internet or they may actually have the item.

29:37.640 --> 29:42.240
And you know, this all sounds like probably somewhat easy for commercial items, right?

29:42.240 --> 29:46.960
But if you think about industrial items or niche things or collectibles and stuff like

29:46.960 --> 29:51.600
that, that's where you really start getting into the problems finding these items.

29:51.600 --> 29:55.080
Certainly, you're not going to have them just sitting around in your training data.

29:55.080 --> 29:56.080
Yeah, yeah.

29:56.080 --> 30:00.040
The way to kind of tackle this problem, it's like an image search problem, right?

30:00.040 --> 30:05.080
And previously, previous generation techniques were doing, you know, a lot of the handcrafted

30:05.080 --> 30:12.040
features, there are algorithms like SIFT, Surf and Orb and some of these previous generation

30:12.040 --> 30:19.640
feature detection algorithms, I believe if you open SIFT, yeah, SIFT, SURF and ORB, these

30:19.640 --> 30:25.480
are all acronyms for feature detection in previous generation computer vision.

30:25.480 --> 30:29.320
Matter of fact, I think, and you know, of course, I don't know the details, but when I look

30:29.320 --> 30:34.160
at it, the Amazon app, when you open up the visual search, I think they're not using

30:34.160 --> 30:35.160
deep learning.

30:35.160 --> 30:38.840
They're using that previous generation because of the dots it's showing.

30:38.840 --> 30:42.920
And based on just my knowledge, that's exactly how it works.

30:42.920 --> 30:47.600
So I don't know if somebody, maybe somebody from Amazon can verify or maybe not, they probably

30:47.600 --> 30:48.600
don't want to.

30:48.600 --> 30:52.440
But yeah, so we were like, well, we don't, those, one of them I forget which one is actually

30:52.440 --> 30:56.840
proprietary, so we can't use it, you know, without getting a license and all sorts of challenges

30:56.840 --> 30:57.840
like that.

30:57.840 --> 30:58.840
And we have deep learning now.

30:58.840 --> 31:03.240
So being able to extract using some of the straight up state of the art models such

31:03.240 --> 31:07.640
as ResNet or Inception, and you know, it's really thinking about this problem.

31:07.640 --> 31:10.640
It's like, well, what are those models doing, right?

31:10.640 --> 31:15.320
You have high level, high dimensional data images.

31:15.320 --> 31:19.880
And the point of generalization is to come up with low level features that you can generalize

31:19.880 --> 31:25.240
so that it will work on not just that data on much wider data.

31:25.240 --> 31:31.280
So well, why don't we just try to take our target and the source and essentially extract

31:31.280 --> 31:34.880
those low level features and create a feature store, right?

31:34.880 --> 31:39.120
So the next time you have a search for something, you say, okay, let me, it's like, it's almost

31:39.120 --> 31:42.080
like fingerprint matching type, if that's one way to think about it, right?

31:42.080 --> 31:45.160
It's like creating the fingerprint of the search.

31:45.160 --> 31:49.400
And then we have the entire database of fingerprints and you just say, okay, find the one that's

31:49.400 --> 31:50.400
the closest match.

31:50.400 --> 31:54.320
And we didn't have to get it 100% right because there was a human in the loop that somebody

31:54.320 --> 31:57.800
would say, okay, all right, I can tell between these five images that this is the one,

31:57.800 --> 31:58.800
right?

31:58.800 --> 32:04.000
Find your features a priori or where the, the training process.

32:04.000 --> 32:06.200
Yeah, we just use, we didn't do any training.

32:06.200 --> 32:10.280
We just use the pre-trained model, for example, ResNet or, or inception.

32:10.280 --> 32:13.800
We removed some of the, some of the classification layers because we weren't interested in the

32:13.800 --> 32:14.800
classification, right?

32:14.800 --> 32:18.640
Because if you look at the learning model, that's what the lower layers are doing.

32:18.640 --> 32:22.600
It's eventually, after the features are, you get to the low level, you then do a, you

32:22.600 --> 32:24.560
do your classic classification.

32:24.560 --> 32:26.520
And then, so we said, we're not interested in that.

32:26.520 --> 32:30.840
Let's freeze the model at certain level and then then see what the features are coming

32:30.840 --> 32:32.240
out of that.

32:32.240 --> 32:35.960
Store those and then let's do the same thing for the search candidate.

32:35.960 --> 32:40.280
And then the object tracking, there's a lot of similarities as far as the Euclidean distance

32:40.280 --> 32:44.080
type thing where you're trying to make sure that it's the same car from the previous image

32:44.080 --> 32:45.240
to this image.

32:45.240 --> 32:49.400
And then, so once you extract the features, you try to do a distance and see how close,

32:49.400 --> 32:50.600
closely they match.

32:50.600 --> 32:53.960
And that's essentially what you're trying to do is that you, in this case, we were doing

32:53.960 --> 33:00.320
a cosine distance between both of the features, feature vectors, or the kind of the customers

33:00.320 --> 33:04.840
feature vector and then the entire database of images, objects that we have to find the

33:04.840 --> 33:05.840
closest ones.

33:05.840 --> 33:10.320
So that's kind of like, you know, in that cell, that's how that problem was solved.

33:10.320 --> 33:16.720
On that one, did you determine where you were going to freeze your network based on experimentation

33:16.720 --> 33:21.080
or was it more kind of intuitive, you know, this is where the classification starts, so

33:21.080 --> 33:22.440
we're just going to stop here.

33:22.440 --> 33:27.040
Yeah, so yeah, if you ever kind of dissect one of these models, it's all, you can read

33:27.040 --> 33:28.040
all the layers.

33:28.040 --> 33:32.560
And yeah, you can tell which layers is when the kind of the feature extraction stops and

33:32.560 --> 33:38.040
the classification starts typically around kind of densely connecting and softmax classifier.

33:38.040 --> 33:40.320
Those are the kind of the later, later stages.

33:40.320 --> 33:44.400
So once you start kind of stop your convolution layers, you know, that's when you can, that's

33:44.400 --> 33:45.400
when you can stop.

33:45.400 --> 33:50.400
And yeah, we, you know, we, so we try to experiment with like, like till the very end or somewhere

33:50.400 --> 33:54.480
in the middle, you know, because these models are also, the state of the art have 50 layers,

33:54.480 --> 33:55.720
you know, like many layers.

33:55.720 --> 33:59.640
So it's like, you know, because we were not really interested in doing the classification.

33:59.640 --> 34:05.920
So at what level of feature, raw features that, that our, our search works in a good performance,

34:05.920 --> 34:07.000
yeah, right?

34:07.000 --> 34:10.720
Because once again, like if you get to like, really low level, then our search results

34:10.720 --> 34:12.880
will be like all over the place, right?

34:12.880 --> 34:15.640
So we want to capture at some, some good level.

34:15.640 --> 34:21.800
So they're not a, not scientific way, it's very much was a trial and error to come up with

34:21.800 --> 34:23.960
where, where it was giving us the best results.

34:23.960 --> 34:28.640
So I was actually wondering just now, did you use the features from many layers at one,

34:28.640 --> 34:31.680
so did you pick just one layer and take the features from, from that?

34:31.680 --> 34:35.920
Yeah, after, after several layers, so like 25 or 30 layers, we said, okay, now let's see

34:35.920 --> 34:40.800
what the output of the images, you know, the feature vector and said, now this is the

34:40.800 --> 34:41.800
one we want to use.

34:41.800 --> 34:46.320
Yeah, I'm, I'm thinking inspired by these object detection methods that sense to use features

34:46.320 --> 34:51.120
from different layers to capture both large and small objects in the amic.

34:51.120 --> 34:55.920
But I guess it's not so important if you know that you have one object in the amic, and

34:55.920 --> 34:58.120
you're just trying to find that one object, right?

34:58.120 --> 35:03.120
Yeah, typically the, so, so what I didn't mention is that this company, when they get the

35:03.120 --> 35:06.840
item, they take photos of it, right, multiple angles and everything.

35:06.840 --> 35:12.240
So typically that's the only thing that's in there, once again, all classic problems still

35:12.240 --> 35:18.800
are there, like data cleaning and, and background removal and all sorts of things like that, yeah.

35:18.800 --> 35:21.520
Yeah, yeah, interesting, interesting.

35:21.520 --> 35:26.480
And you mentioned one more, which was a fraud detection app for a bank.

35:26.480 --> 35:30.360
Yeah, yeah, and, and did you want to talk about, I can also talk about it, you know, if

35:30.360 --> 35:34.360
you could start to talk, yeah, so I, I wasn't on the topic, I, I know about the project,

35:34.360 --> 35:38.680
yeah, I, I just felt like, because you, it's in Denmark, right?

35:38.680 --> 35:44.760
And, and, yeah, is this, I think more details can be found, because it's the video off

35:44.760 --> 35:49.400
this project, there was a talk at the O'Reilly conference in New York in June, and it's available

35:49.400 --> 35:53.280
online, so those who are interested into this technique, I think what's really neat about

35:53.280 --> 35:56.960
this is that in the previous two cases, we talked about computer vision, right, which

35:56.960 --> 36:01.480
is kind of the, the cool factor, right, because everybody is excited about being, being able

36:01.480 --> 36:05.680
to do things with images, right? But now this is, here comes like fraud detection, which

36:05.680 --> 36:08.880
is, you know, through the common person, it's like, who cares, right?

36:08.880 --> 36:13.080
As long as my career card works, and nobody, you know, anybody who defros me, but banks,

36:13.080 --> 36:16.080
of course, are very much concerned with that, right?

36:16.080 --> 36:20.760
So, so in this case, you're like, well, I mean, so of course, fraud detection is not new,

36:20.760 --> 36:21.760
right?

36:21.760 --> 36:26.200
People have been doing this for decades, all sorts of things like human created, curated

36:26.200 --> 36:32.080
rules, right? It's like you swipe a card in San Francisco, and then you swipe it in, you

36:32.080 --> 36:34.840
know, Bombay, right? It's like, obviously, there is a problem, right? And so, you know,

36:34.840 --> 36:38.680
it's, you know, things like that, you can always have those handcrafted rules, but, you

36:38.680 --> 36:43.240
know, those can become like, you have 20,000 rules, and it's like, you know, it becomes

36:43.240 --> 36:47.040
a real cumbersome process, you start applying some traditional machine learning aspects to

36:47.040 --> 36:50.680
it, so you do a lot of feature engineering on the data to say, okay, these are the, these

36:50.680 --> 36:55.520
are the features that contribute to fraud, and we should flag for that, right? And then

36:55.520 --> 37:00.520
we're like, well, what are the ways you can improve upon this? Now, we have deep learning,

37:00.520 --> 37:06.240
feature learning, are there ways to actually improve upon the model? And so, you know, we

37:06.240 --> 37:10.160
said, well, let's try a couple of things. So, one of the things, and this is a classic

37:10.160 --> 37:14.200
by the object tracking example as well, like, so it's like, well, what is the first thing

37:14.200 --> 37:20.000
I would do? And most people with transactional data or sequential data, the go to technique

37:20.000 --> 37:25.000
is using some kind of a curl model, right? Where LSTM or something like that, right? So,

37:25.000 --> 37:28.440
that you have that recent history, and then you can be, you should be able to tell, oh,

37:28.440 --> 37:34.040
this is fraudulent, or it's about to be fraudulent. So, we tried that, and actually, there's the

37:34.040 --> 37:38.440
model result, if I recall correctly, there's a chart in that talk, which shows you all the

37:38.440 --> 37:42.840
different approaches. I think it was on par with the traditional machine learning, so not

37:42.840 --> 37:47.240
really, not promising, but then, like, well, creative way of, like, well, what if we could

37:47.240 --> 37:52.440
apply some of the vision-based techniques? So, it's, you know, vision, there are certain

37:52.440 --> 37:57.720
properties that are necessary for a conditional model to work, shift very invariant statistics

37:57.720 --> 38:02.040
and locally curated values. Those are the two things that famously, Yamakun tweeted

38:02.040 --> 38:07.240
out a few months ago, which I remember very well, right? I'm not coming from research, right?

38:07.240 --> 38:10.200
And those things really made a lot of sense to me, it's like, okay, all right, so those are

38:10.200 --> 38:14.640
the properties you need, because traditionally, the type of data we have, even in credit

38:14.640 --> 38:18.600
credit transaction, it's just some kind of a time series, you know, you have, you have

38:18.600 --> 38:24.200
amount and location and all sorts of things like that, but not like a picture, right? And,

38:24.200 --> 38:28.520
you know, this technique is detailed in, if you, you know, even five minutes of that talk,

38:28.520 --> 38:32.600
there is a couple of slides on it, which will, this, like, visually, it's very intuitive,

38:32.600 --> 38:38.840
is to come up with a feature map of the transactions, using some history. So, then idea is to create,

38:38.840 --> 38:44.840
like, a visual image of the recent transactions, and then feed it through the convolutional

38:44.840 --> 38:49.880
neural network to see if you could detect fraud. When you think about this, and this is something

38:49.880 --> 38:54.440
that I would, I would ponder others to think about, right, is that think about this as,

38:54.440 --> 38:59.480
as how we would do something like that, right? And one example I always talk about is that

38:59.480 --> 39:03.880
people who sit in, like, operations controls, right? And they're looking at those 50 screens,

39:03.880 --> 39:08.200
right? Or even traders when they look at, like, all these charts and all these things, right?

39:08.200 --> 39:12.520
You know, they're visually also trying to look for some changes in signals that will allow,

39:12.520 --> 39:17.960
say, oh, you know, I need to take some action. And the idea is very similar here, right? Is that

39:17.960 --> 39:22.280
if we could convert, I mean, there's data behind those charts, right? If we could somehow create

39:22.280 --> 39:26.840
the, and we just, like, we'll create charts out of the data, and then feed it through the,

39:26.840 --> 39:31.480
through the convolutional neural network, and then tell it what abnormal looks like, right?

39:31.480 --> 39:36.040
And then now I'll ask it to flag it. So, it's super interesting. I think those traders would be

39:36.040 --> 39:40.040
a lot less effective if they were looking at a spreadsheet. Yeah, well, and we know, we know that,

39:40.040 --> 39:44.680
right? It's like, yeah, it's like, I imagine if I gave you, like, a trend chart versus, like,

39:44.680 --> 39:48.920
all the data in a table, right? How quickly could you make a decision, right? Yeah, so

39:48.920 --> 39:54.440
put like that, it's super intuitive that a neural net would, you know, vision-focused

39:54.440 --> 39:58.200
neural net would be effective in solving these kinds of problems. Yeah, yeah. And, you know,

39:58.200 --> 40:02.920
it's a, it's a, it's a great, I love talking about this because it's a great example of,

40:02.920 --> 40:06.840
of applying some of these kind of what the research there and the progress that we are making

40:06.840 --> 40:11.560
in computer vision towards the problem that you were to think is in that realm, right? And you

40:11.560 --> 40:15.400
can talk about, I mean, you know, and when you start thinking about this way, there are many more

40:15.400 --> 40:20.040
things that open up, like, you know, anomaly detection and anything that you can, essentially,

40:20.040 --> 40:24.280
you can visualize, like, if you had like a heat map, right? So, yeah, we go up shore, we can generate

40:24.280 --> 40:29.320
a heat map of a lot of data, right? I think the big trick over there is that you have to be consistent

40:29.320 --> 40:34.280
in the way you feed the data because remember the properties of the common neural networks

40:34.280 --> 40:40.200
require that it's like, think of it, it's, it is an image. If you start shifting around the bits,

40:40.760 --> 40:44.760
the image will stop making sense, right? And that's what we are really banking on, that it is

40:44.760 --> 40:49.240
the image that could, that makes sense to us and we are trying to find those patterns. So,

40:49.240 --> 40:54.360
it is very important that you don't use another technique the next time around. You keep the feature

40:54.360 --> 41:00.200
map same for the, even throughout the production cycle, right? Not, not change it around, not change

41:00.200 --> 41:06.280
the sequence of transactions and things like that. Okay. Yeah, it's detailed much more in that talk

41:06.280 --> 41:12.440
if anybody's interested. We'll try to track down the line. Yeah. Yeah. Awesome. Well, these are all

41:12.440 --> 41:18.440
really, really interesting use cases. Thank you both for taking the time to kind of talk through

41:18.440 --> 41:24.360
them. Is there anything else that you wanted to mention? Either of you. Nothing comes to mind right

41:24.360 --> 41:29.080
now. Probably something built in like half an hour? Yeah, of course, of course. I'll take Sam's

41:29.080 --> 41:35.080
role and I'll ask you, what has your impression been in this, I guess, day or half or so far at the

41:35.080 --> 41:41.000
conference? Well, I have enjoyed it personally. I think there are a lot of really interesting

41:41.000 --> 41:45.880
talks and some that I would have liked to go to but that were just filled up by the time I got there.

41:45.880 --> 41:51.400
There was one on what to do if you don't have a lot of data because there are some ways around

41:51.400 --> 41:55.880
that I gather and something that a lot of people are starting to talk about as well as the use of

41:55.880 --> 42:01.080
unsupervised learning. I don't remember the details but I ran into this really interesting

42:01.080 --> 42:07.720
paper where they started so they wanted to train some kind of image analysis, object detection,

42:07.720 --> 42:13.320
something method. I don't recall the details. The insight that they had was that well, how do

42:13.320 --> 42:19.640
children learn to associate shapes that sort of belong together? So if a child sees a cat the first

42:19.640 --> 42:26.520
time, it may not know that the legs and the head and sort of everything goes together into being a cat.

42:26.520 --> 42:32.040
But then when the child sees the cat move a lot, it sort of realizes, okay, so this is the cat

42:32.040 --> 42:36.280
and these parts belong together. So this is one object. So this is essentially learning how to

42:36.280 --> 42:43.800
detect a whole object. And there is some research that shows that this is indeed how children learn

42:43.800 --> 42:50.520
to recognize shapes or people who regain sight. Like there is actually some research showing that

42:50.520 --> 42:57.560
this is how it might work for humans. So based on that insight, what these authors did was just

42:57.560 --> 43:06.360
show videos to a deep learning model and it did learn to recognize objects in this way.

43:06.360 --> 43:11.880
And then once, of course, once it learned how to recognize objects, then it's easier for it to

43:11.880 --> 43:18.760
learn that, okay, so this object is a cat. This object is a house. So that was a really cool

43:18.760 --> 43:24.600
application of using unsupervised learning to gain momentum. Yeah, like a little bit of a roundabout

43:24.600 --> 43:30.120
way of going around labeling aspect. Yeah, it's pretty neat. And I think that's a, it's great,

43:30.120 --> 43:35.080
you know, some of these research moving forward around, you know, because we've been talking about

43:35.080 --> 43:41.560
big data related, you know, machine learning, right, deep learning. But there is a lot of data

43:41.560 --> 43:46.040
class and balance is a huge, huge thing, right, just that there's some places where there's

43:46.040 --> 43:50.600
just not enough things to detect, you know, how do you handle those things? Yeah, so it's very

43:50.600 --> 43:55.960
fascinating. And I'll say that for me today, it was really fascinating, the keynote for Andrew

43:55.960 --> 44:01.640
Ing, right, kind of very non-traditional, right? You know, he wrote out the white words and I would

44:01.640 --> 44:06.040
recommend a lot of people to check out that because I really felt that, of course, you know, he's

44:06.040 --> 44:10.920
well-informed, suspected, and things like that. But the things that he highlighted, I really felt

44:10.920 --> 44:15.400
they really hit home because, you know, you know, you know, of course, people give great

44:15.400 --> 44:19.880
keynotes and I think they're good. But I think he really said, these are the real things that you

44:19.880 --> 44:26.040
need to do, you need to worry about or look at that are very relevant versus let's just try to

44:26.040 --> 44:30.040
write, you know, increase the hype curve further and further, right? I thought that was very,

44:30.040 --> 44:34.760
you know, that's something that I know I will kind of reference several times watching the video

44:34.760 --> 44:39.480
because he really brought some of the key points out there. Awesome. Awesome. Great. Well,

44:39.480 --> 44:43.960
thanks both of you. Thank you for having us come. Yeah, thank you. You know, long time listener

44:43.960 --> 44:49.320
and finally hearing my voice, you know, it's going to be weird. Thank you so much for having us.

44:49.320 --> 44:51.480
Awesome. Enjoy the rest of the conference. Thank you.

44:55.320 --> 45:01.560
All right, everyone. That's our show for today. Thanks so much for listening and of course,

45:01.560 --> 45:07.480
for your ongoing feedback and support. For more information on Mo and Laura or any of the other

45:07.480 --> 45:13.560
topics covered in this episode, head on over to twimlai.com slash talk slash 54.

45:14.280 --> 45:23.000
For the rest of this series, head over to twimlai.com slash AI SF 2017. And please, please, please,

45:23.000 --> 45:28.200
send us any questions or comments that you may have for us or our guests, be a Twitter,

45:28.200 --> 45:36.200
at twimlai or at Sam Charington or leave a comment on the show notes page. There are a ton of great

45:36.200 --> 45:41.640
conferences coming up through the end of the year to stay up to date on which events will be attending

45:41.640 --> 45:49.160
and hopefully to meet us there, check out our new events page at twimlai.com slash events

45:49.160 --> 46:03.800
twimlai.com slash events. Thanks again for listening and catch you next time.

