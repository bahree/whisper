1
00:00:00,000 --> 00:00:03,080
All right, everyone. I'm on the line with Kelly Revoir.

2
00:00:03,080 --> 00:00:06,080
Kelly is an engineering manager at Stripe,

3
00:00:06,080 --> 00:00:08,360
working on machine learning infrastructure.

4
00:00:08,360 --> 00:00:11,360
Kelly, welcome to this week in machine learning and AI.

5
00:00:11,360 --> 00:00:14,720
Thanks for having me. I'm really excited to chat.

6
00:00:14,720 --> 00:00:17,480
Same here. Same here.

7
00:00:17,480 --> 00:00:20,640
We got in touch with you,

8
00:00:20,640 --> 00:00:23,560
kind of occasioned by a talk you're giving at

9
00:00:23,560 --> 00:00:27,080
Strata, which is actually happening as we speak.

10
00:00:27,080 --> 00:00:32,160
I'm not physically in SF for it this time, but your talk,

11
00:00:32,160 --> 00:00:33,880
which is going to be later today,

12
00:00:33,880 --> 00:00:37,720
is on scaling model training from flexible training APIs

13
00:00:37,720 --> 00:00:40,520
to resource management with Kubernetes.

14
00:00:40,520 --> 00:00:42,760
And of course, machine learning infrastructure and AI

15
00:00:42,760 --> 00:00:46,960
platforms is a very popular topic here on the podcast.

16
00:00:46,960 --> 00:00:51,440
And so I'm looking forward to digging into the way Stripe is

17
00:00:51,440 --> 00:00:55,760
platforming its machine learning processes and operations.

18
00:00:55,760 --> 00:00:57,120
But before we do that,

19
00:00:57,120 --> 00:00:59,400
I'd love to hear a little bit about your background

20
00:00:59,400 --> 00:01:02,680
and how you got started working in this space.

21
00:01:02,680 --> 00:01:03,720
Yeah, sounds great.

22
00:01:03,720 --> 00:01:06,320
Maybe I'll say a little bit about what I do now

23
00:01:06,320 --> 00:01:08,800
and then kind of work backward from that.

24
00:01:08,800 --> 00:01:10,280
Awesome.

25
00:01:10,280 --> 00:01:13,080
So right now, I'm an engineering manager at Stripe,

26
00:01:13,080 --> 00:01:16,040
and I work with our data infrastructure group,

27
00:01:16,040 --> 00:01:19,640
which is seven teams kind of at the lowest level things like

28
00:01:19,640 --> 00:01:21,880
our production databases or things like

29
00:01:21,880 --> 00:01:26,280
Elasticsearch clusters and then kind of working up through batch

30
00:01:26,280 --> 00:01:31,640
and streaming platforms, core ETL data pipelines and libraries,

31
00:01:31,640 --> 00:01:34,600
and also machine learning infrastructure.

32
00:01:34,600 --> 00:01:38,880
I've been at Stripe for very close to six years now

33
00:01:38,880 --> 00:01:41,200
from when the company was about 50 people

34
00:01:41,200 --> 00:01:43,280
and have basically worked on a bunch of different things

35
00:01:43,280 --> 00:01:48,920
in sort of like risk data and machine learning,

36
00:01:48,920 --> 00:01:51,280
both as an engineer and engineering manager

37
00:01:51,280 --> 00:01:55,880
and also initially more on kind of like the application side

38
00:01:55,880 --> 00:01:59,560
and then over time moving over to the infrastructure side.

39
00:02:01,720 --> 00:02:06,440
By training, I'm like a kind of research scientist person,

40
00:02:06,440 --> 00:02:10,000
so I studied physics and electrical engineering in school.

41
00:02:10,000 --> 00:02:12,720
Did my PhD at Stanford working on nanopatonics

42
00:02:12,720 --> 00:02:15,720
and then did a short postdoc at HP labs

43
00:02:15,720 --> 00:02:17,760
on nanopatonics?

44
00:02:17,760 --> 00:02:19,320
Yeah, I think you had,

45
00:02:19,320 --> 00:02:22,160
like I could have an oscanon recently who works on optics,

46
00:02:22,160 --> 00:02:23,680
which is not too far away,

47
00:02:23,680 --> 00:02:25,720
so maybe that gives you a little bit of an idea.

48
00:02:27,560 --> 00:02:29,600
And then yeah, I was at HP labs for a year

49
00:02:29,600 --> 00:02:31,280
so working on sort of similar things

50
00:02:31,280 --> 00:02:33,240
and also some 3D imaging.

51
00:02:33,240 --> 00:02:36,000
And I guess I like to call what I did,

52
00:02:36,000 --> 00:02:38,360
although I don't know that anyone else calls it that,

53
00:02:38,360 --> 00:02:42,760
sort of like full stack science where like you have an idea

54
00:02:42,760 --> 00:02:45,880
and then you do some theory or modeling or simulation

55
00:02:45,880 --> 00:02:47,640
and then you use that to design a device

56
00:02:47,640 --> 00:02:48,800
and then you actually go in the clean room

57
00:02:48,800 --> 00:02:50,600
and like make the device and then you actually go

58
00:02:50,600 --> 00:02:53,280
in the optics lab and like shoot a bunch of lasers

59
00:02:53,280 --> 00:02:54,880
at your device and measure it.

60
00:02:54,880 --> 00:02:56,680
And then you sort of like process the data

61
00:02:56,680 --> 00:02:59,000
and compare it to your theory and simulation.

62
00:02:59,000 --> 00:03:02,280
And I was like, I found like kind of the two ends the most,

63
00:03:03,400 --> 00:03:07,120
like sort of the magical moment where like, you know,

64
00:03:07,120 --> 00:03:09,160
the data that you collected like matches

65
00:03:09,160 --> 00:03:12,400
what you thought was gonna happen from your modeling.

66
00:03:12,400 --> 00:03:14,680
And I kind of decided that I wanted to do more of that

67
00:03:14,680 --> 00:03:16,360
and a little less of like fabrication

68
00:03:16,360 --> 00:03:18,120
or material science and I was kind of sitting

69
00:03:18,120 --> 00:03:20,760
in Silicon Valley and started looking around

70
00:03:20,760 --> 00:03:24,800
and like Stripe was super exciting in terms of its mission,

71
00:03:24,800 --> 00:03:28,280
like having interesting data and just like having amazing people.

72
00:03:28,280 --> 00:03:30,240
Awesome, awesome, Stripe sounds really interesting

73
00:03:30,240 --> 00:03:34,800
but shooting lasers at stuff also sounds really, really cool.

74
00:03:34,800 --> 00:03:38,280
Yeah, people get really excited when you tell them that.

75
00:03:38,280 --> 00:03:40,640
So that was fun for a while.

76
00:03:40,640 --> 00:03:41,760
Nice, nice.

77
00:03:41,760 --> 00:03:46,760
And so maybe tell us a little bit about Stripe's,

78
00:03:49,160 --> 00:03:51,440
kind of machine learning journey

79
00:03:51,440 --> 00:03:54,120
from an infrastructure perspective.

80
00:03:55,120 --> 00:03:59,440
How did it, it sounds like you're doing

81
00:03:59,440 --> 00:04:00,920
a bunch of interesting things

82
00:04:00,920 --> 00:04:03,040
both from a training perspective,

83
00:04:03,040 --> 00:04:06,480
from a data management perspective inference,

84
00:04:06,480 --> 00:04:08,560
but how did it evolve?

85
00:04:08,560 --> 00:04:10,280
Yeah, I think one thing that's interesting

86
00:04:10,280 --> 00:04:12,320
about machine learning at Stripe,

87
00:04:12,320 --> 00:04:14,920
like I think a lot of places you talk to machine learning

88
00:04:14,920 --> 00:04:18,320
kind of like started out as being for some,

89
00:04:18,320 --> 00:04:20,560
some kind of like offline analytics

90
00:04:20,560 --> 00:04:23,600
and more like internal business questions,

91
00:04:23,600 --> 00:04:25,440
like maybe like you're trying to calculate

92
00:04:25,440 --> 00:04:27,240
long-term value of your users.

93
00:04:27,240 --> 00:04:28,680
And we do stuff like that now,

94
00:04:28,680 --> 00:04:31,160
but we actually started like our kind of core uses

95
00:04:31,160 --> 00:04:35,400
have always been very much on kind of the production side,

96
00:04:35,400 --> 00:04:37,720
like our kind of most business critical

97
00:04:37,720 --> 00:04:40,720
and first machine learning use cases were things

98
00:04:40,720 --> 00:04:44,000
like scoring transactions in the charge flow

99
00:04:44,000 --> 00:04:46,240
to evaluate whether they're fraudulent or not.

100
00:04:47,360 --> 00:04:50,080
We're doing kind of like internal risk management

101
00:04:50,080 --> 00:04:55,160
of like making sure our users are selling things

102
00:04:55,160 --> 00:04:57,080
that we can support from our terms of service

103
00:04:57,080 --> 00:04:59,560
or that they're kind of like good users

104
00:04:59,560 --> 00:05:01,320
that we want to support.

105
00:05:01,320 --> 00:05:04,280
And so we started out from having kind of a lot

106
00:05:04,280 --> 00:05:06,600
of these more like production requirements

107
00:05:06,600 --> 00:05:07,720
but it needs to be this fast

108
00:05:07,720 --> 00:05:09,040
and it needs to be this reliable.

109
00:05:09,040 --> 00:05:10,600
And I think our machine learning platform

110
00:05:10,600 --> 00:05:12,360
kind of like evolved from that side

111
00:05:13,840 --> 00:05:17,000
where initially we had kind of like one machine learning team

112
00:05:17,000 --> 00:05:19,040
and then even just having a couple of applications

113
00:05:19,040 --> 00:05:22,680
we started seeing like here are some commonalities

114
00:05:22,680 --> 00:05:24,800
like everyone needs to be able to score models

115
00:05:24,800 --> 00:05:28,880
or even like having some notion of shared features

116
00:05:28,880 --> 00:05:31,920
could be really valuable across just a couple of applications.

117
00:05:31,920 --> 00:05:34,240
And then as we split our machine learning team,

118
00:05:34,240 --> 00:05:38,320
one piece of that became machine learning infrastructure

119
00:05:38,320 --> 00:05:39,720
which we've developed since then.

120
00:05:39,720 --> 00:05:42,000
And it's really important for that team to work

121
00:05:42,000 --> 00:05:44,320
both with the teams doing the business applications

122
00:05:44,320 --> 00:05:46,400
which now include a bunch of other things

123
00:05:47,520 --> 00:05:49,560
in our user-facing products like radar and billing

124
00:05:49,560 --> 00:05:53,120
as well as internally and also it's important

125
00:05:53,120 --> 00:05:54,560
for the machine learning infrastructure

126
00:05:54,560 --> 00:05:56,600
to build on the rest of your data infrastructure

127
00:05:56,600 --> 00:05:59,120
and really the rest of all of your infrastructure.

128
00:05:59,120 --> 00:06:00,200
And we've worked really closely

129
00:06:00,200 --> 00:06:02,880
with like our orchestration team on,

130
00:06:02,880 --> 00:06:05,200
as you said in chatting about my talk

131
00:06:05,200 --> 00:06:07,320
like getting training to run on Kubernetes.

132
00:06:09,560 --> 00:06:12,040
Yeah man, that's maybe an interesting place to start.

133
00:06:13,880 --> 00:06:16,520
You kind of alluded to the interfaces

134
00:06:16,520 --> 00:06:20,120
between machine learning infrastructure as a team

135
00:06:20,120 --> 00:06:22,800
and you know data infrastructure, you know,

136
00:06:22,800 --> 00:06:24,280
just infrastructure.

137
00:06:27,120 --> 00:06:32,120
How do they connect, you know, maybe even organizationally

138
00:06:32,120 --> 00:06:36,400
and how do they tend to work with them

139
00:06:36,400 --> 00:06:37,400
with one another.

140
00:06:37,400 --> 00:06:41,160
For example, you know, in, you know,

141
00:06:41,160 --> 00:06:43,000
training on Kubernetes, you know,

142
00:06:43,000 --> 00:06:46,320
where's the line between what the ML infrastructure team

143
00:06:46,320 --> 00:06:49,800
is doing and, you know, what it's requiring

144
00:06:49,800 --> 00:06:54,160
of some, you know, broader technology infrastructure group?

145
00:06:54,160 --> 00:06:56,520
Yeah, I think the Kubernetes case is really interesting

146
00:06:56,520 --> 00:07:00,040
and it's one that's been super successful for us.

147
00:07:00,040 --> 00:07:03,160
So I guess maybe like a year or two ago,

148
00:07:03,160 --> 00:07:06,000
we'd initially focused on the kind of scoring,

149
00:07:06,000 --> 00:07:07,560
like real-time inference part of models,

150
00:07:07,560 --> 00:07:08,400
because that's the hardest.

151
00:07:08,400 --> 00:07:10,080
And we'd sort of left people on their own.

152
00:07:10,080 --> 00:07:12,160
It's like, well, you figure out how to train a model

153
00:07:12,160 --> 00:07:13,720
and then, you know, if you manage to do that,

154
00:07:13,720 --> 00:07:15,320
we'll help you score it.

155
00:07:15,320 --> 00:07:18,920
And we realized that that wasn't like great, right?

156
00:07:18,920 --> 00:07:21,000
So we started thinking, you know, what can we do?

157
00:07:21,000 --> 00:07:22,800
And at first, we built some CLI tools

158
00:07:22,800 --> 00:07:25,080
to kind of like wrap the Python people were doing,

159
00:07:25,080 --> 00:07:26,640
but then we wanted to kind of do more.

160
00:07:26,640 --> 00:07:28,000
So eventually we built an API

161
00:07:28,000 --> 00:07:30,760
and then a big hassle had been the resource management.

162
00:07:30,760 --> 00:07:33,480
And we just kind of wanted to like abstract that all the way.

163
00:07:33,480 --> 00:07:36,080
And as it happened at that time, our orchestration team

164
00:07:36,080 --> 00:07:38,520
had gotten like really interested in Kubernetes.

165
00:07:38,520 --> 00:07:41,040
And I think they wrote a blog post like maybe a year

166
00:07:41,040 --> 00:07:43,320
and a half ago, they had kind of just

167
00:07:43,320 --> 00:07:45,360
moved our first application to Kubernetes,

168
00:07:45,360 --> 00:07:46,880
which was some of our conjobs that we

169
00:07:46,880 --> 00:07:48,960
used in our financial infrastructure.

170
00:07:48,960 --> 00:07:50,440
And so we ended up collaborating.

171
00:07:50,440 --> 00:07:53,040
This was kind of like a great next step

172
00:07:53,040 --> 00:07:55,400
of a second application they could work on.

173
00:07:55,400 --> 00:08:00,200
And we had some details, we had to work out,

174
00:08:00,200 --> 00:08:03,360
we had to figure out how do we package up all of our Python code

175
00:08:03,360 --> 00:08:06,320
and to some Docker file we can deploy.

176
00:08:06,320 --> 00:08:10,280
And it was really useful to be able to work with them on that.

177
00:08:10,280 --> 00:08:12,240
But I think we have found really good interfaces

178
00:08:12,240 --> 00:08:14,760
in working with them where we wrote a client

179
00:08:14,760 --> 00:08:18,320
for the community's API, but it's like anytime we need help

180
00:08:18,320 --> 00:08:20,800
or anytime there's management of the Kubernetes cluster,

181
00:08:20,800 --> 00:08:22,320
they take care of all of that.

182
00:08:22,320 --> 00:08:24,520
So it's kind of given us this flexibility

183
00:08:24,520 --> 00:08:27,080
where we can define different instance and resource types

184
00:08:27,080 --> 00:08:29,920
and swap them out really easily if we need CPUs or GPUs

185
00:08:29,920 --> 00:08:31,680
or we need to expand the cluster.

186
00:08:31,680 --> 00:08:34,160
But we as machine learning infrastructure

187
00:08:34,160 --> 00:08:36,880
kind of don't have to deal with managing Kubernetes

188
00:08:36,880 --> 00:08:38,560
or updating it, we have this amazing team

189
00:08:38,560 --> 00:08:42,000
of people who are totally focused on that for Stripe.

190
00:08:42,000 --> 00:08:43,800
Awesome, awesome.

191
00:08:43,800 --> 00:08:52,920
And then actually let's maybe stay on this topic for a moment.

192
00:08:52,920 --> 00:08:58,720
So your talk at Strato was focused on this area.

193
00:08:58,720 --> 00:09:00,560
What was kind of the flow of your talk?

194
00:09:00,560 --> 00:09:04,280
What were the main points that you're planning

195
00:09:04,280 --> 00:09:07,600
to go through with the audience there?

196
00:09:07,600 --> 00:09:09,640
Yeah, great question.

197
00:09:09,640 --> 00:09:12,360
So we kind of think about this in two pieces.

198
00:09:12,360 --> 00:09:15,880
And maybe that's because that's how we actually did it.

199
00:09:15,880 --> 00:09:18,400
So one piece was the resource management

200
00:09:18,400 --> 00:09:21,800
that I talked about was getting things to run on Kubernetes.

201
00:09:21,800 --> 00:09:24,520
That was actually kind of the second piece for us.

202
00:09:24,520 --> 00:09:29,320
The first piece was figuring out how should the user interact

203
00:09:29,320 --> 00:09:32,440
with things and where should we give them flexibility

204
00:09:32,440 --> 00:09:34,960
and where should we constrain things.

205
00:09:34,960 --> 00:09:37,280
And so we ended up building what we call internally

206
00:09:37,280 --> 00:09:40,400
rail yard, which is a model training API.

207
00:09:40,400 --> 00:09:42,600
And it goes with, there's two pieces.

208
00:09:42,600 --> 00:09:45,000
There's what you put in the API request.

209
00:09:45,000 --> 00:09:47,080
And then there's what we call a workflow.

210
00:09:47,080 --> 00:09:49,800
And the API request is a little bit more constrained.

211
00:09:49,800 --> 00:09:52,400
You have to say you're meta data for who's training

212
00:09:52,400 --> 00:09:53,480
so we can track it.

213
00:09:53,480 --> 00:09:56,400
You have to tell us where your data is,

214
00:09:56,400 --> 00:09:58,760
how you're doing things like hold out.

215
00:09:58,760 --> 00:10:00,840
Just kind of basic things that you'll always need.

216
00:10:00,840 --> 00:10:02,560
But then we have this workflow piece

217
00:10:02,560 --> 00:10:06,920
that people can write whatever Python they want

218
00:10:06,920 --> 00:10:08,760
as long as they define a train method in it

219
00:10:08,760 --> 00:10:12,440
that will hand us back the fitted model.

220
00:10:12,440 --> 00:10:14,600
And we definitely have found that initially,

221
00:10:14,600 --> 00:10:17,240
we were very focused on binary classifiers for things

222
00:10:17,240 --> 00:10:20,640
fraud, but people have done things like word embeddings.

223
00:10:20,640 --> 00:10:23,480
We have people doing time series forecasting.

224
00:10:23,480 --> 00:10:26,800
We're using things like psychic learn,

225
00:10:26,800 --> 00:10:29,680
actually used fast text, PyTorch profit.

226
00:10:29,680 --> 00:10:32,520
So this has worked pretty well in terms of providing enough

227
00:10:32,520 --> 00:10:34,800
flexibility that people can do things that we actually

228
00:10:34,800 --> 00:10:37,840
didn't anticipate originally, but it's constrained enough

229
00:10:37,840 --> 00:10:43,120
that we can run it and sort of track what's going on.

230
00:10:43,120 --> 00:10:46,320
And give them what they need and be able to automate the things

231
00:10:46,320 --> 00:10:48,040
that we need to automate.

232
00:10:48,040 --> 00:10:51,040
OK, and so your interface you're describing

233
00:10:51,040 --> 00:10:56,040
is this kind of Python and this train method.

234
00:10:56,040 --> 00:11:03,720
Are you expecting the, well, actually that's maybe a question.

235
00:11:03,720 --> 00:11:06,360
Are the users, do you think of your users

236
00:11:06,360 --> 00:11:09,640
as more kind of the data science type of user

237
00:11:09,640 --> 00:11:11,920
or machine learning engineer type of user,

238
00:11:11,920 --> 00:11:17,680
or is there a mix of those two types of backgrounds?

239
00:11:17,680 --> 00:11:20,040
Yeah, it's a mix, which has been really interesting.

240
00:11:20,040 --> 00:11:22,560
And I think coming back to what I said earlier,

241
00:11:22,560 --> 00:11:26,320
because we initially focused on these critical production

242
00:11:26,320 --> 00:11:29,800
use cases, we started out where the team's users were really

243
00:11:29,800 --> 00:11:31,600
pretty much all machine learning engineers

244
00:11:31,600 --> 00:11:33,880
and very highly skilled machine learning engineers,

245
00:11:33,880 --> 00:11:36,240
like people who are excellent programmers

246
00:11:36,240 --> 00:11:41,200
and they know stats in ML and they're the unicorns to hire.

247
00:11:41,200 --> 00:11:43,880
And over time, we've been able to broaden that

248
00:11:43,880 --> 00:11:47,600
and I think having things like this tooling

249
00:11:47,600 --> 00:11:50,040
has made that possible in our user survey

250
00:11:50,040 --> 00:11:52,320
right after we first shipped.

251
00:11:52,320 --> 00:11:55,320
Even just the API workflow piece, and we were actually

252
00:11:55,320 --> 00:11:57,600
just running it on some boxes of sidecar process

253
00:11:57,600 --> 00:11:59,480
we hadn't even done Kubernetes yet.

254
00:11:59,480 --> 00:12:01,200
But a lot of the feedback we got was like,

255
00:12:01,200 --> 00:12:02,960
oh, this new person started on my team,

256
00:12:02,960 --> 00:12:06,120
and I just pointed them to the directory where the workflows are.

257
00:12:06,120 --> 00:12:07,520
And I didn't have to think about how

258
00:12:07,520 --> 00:12:10,240
to split all these things out because you

259
00:12:10,240 --> 00:12:11,960
just pointed me in the right direction

260
00:12:11,960 --> 00:12:14,040
and I could point them in the right direction.

261
00:12:14,040 --> 00:12:17,680
So I think that having these common ways of doing things

262
00:12:17,680 --> 00:12:20,200
has been a way to broaden our user set.

263
00:12:20,200 --> 00:12:22,920
And as our data science team, which is more internally

264
00:12:22,920 --> 00:12:26,560
focused has grown, they've been able to start picking up

265
00:12:26,560 --> 00:12:29,760
increasingly large pieces of what we've

266
00:12:29,760 --> 00:12:31,840
built for the ML engineers as well.

267
00:12:31,840 --> 00:12:34,600
And we've been excited to see that and work with them.

268
00:12:34,600 --> 00:12:36,080
Awesome, awesome.

269
00:12:36,080 --> 00:12:40,600
And so the interface then is kind of Python code.

270
00:12:40,600 --> 00:12:46,800
And our is the platform containerizing that code?

271
00:12:46,800 --> 00:12:48,960
Or is the user expected to do it?

272
00:12:48,960 --> 00:12:51,600
Or is it integrated into some kind of workflow

273
00:12:51,600 --> 00:12:53,240
like they check it in?

274
00:12:53,240 --> 00:12:58,520
And then it becomes available to the platform via a check

275
00:12:58,520 --> 00:13:00,880
in or a CICD type of process.

276
00:13:00,880 --> 00:13:05,160
Yeah, so we still have the experimental flow

277
00:13:05,160 --> 00:13:07,840
where people can kind of try things out.

278
00:13:07,840 --> 00:13:10,040
But when you're ready to productionize your workflow,

279
00:13:10,040 --> 00:13:13,080
basically what you do is you get your code reviewed,

280
00:13:13,080 --> 00:13:15,240
you merge it.

281
00:13:15,240 --> 00:13:17,120
We ended up using Google's subpar library

282
00:13:17,120 --> 00:13:18,840
because it works really well with Bazel,

283
00:13:18,840 --> 00:13:23,600
which we use for a lot of our build tooling to be able to kind

284
00:13:23,600 --> 00:13:26,000
of, what are those two?

285
00:13:26,000 --> 00:13:29,400
Yeah, so subpar is a Google library

286
00:13:29,400 --> 00:13:33,560
that helps us package Python code into like a self-contained

287
00:13:33,560 --> 00:13:36,600
executable, both the source code and any dependencies

288
00:13:36,600 --> 00:13:40,120
like if you're running PyTorch and you need some CUDA stuff.

289
00:13:40,120 --> 00:13:42,360
And it works kind of out of the box with Bazel,

290
00:13:42,360 --> 00:13:45,960
which is the open source version of Google's build system,

291
00:13:45,960 --> 00:13:49,200
which we have started to use at Stripe a few years ago

292
00:13:49,200 --> 00:13:50,960
and have expanded since.

293
00:13:50,960 --> 00:13:54,000
It's really nice for like speed, reproducibility,

294
00:13:54,000 --> 00:13:56,920
and working with multiple languages.

295
00:13:56,920 --> 00:13:59,960
So this is where our ML info team kind of worked with our

296
00:13:59,960 --> 00:14:02,960
orchestration team to figure out the details here,

297
00:14:02,960 --> 00:14:05,320
to be able to kind of like package up all this Python code

298
00:14:05,320 --> 00:14:07,840
and have it so that basically, almost like a service

299
00:14:07,840 --> 00:14:10,800
deploy, you can kind of like have it turn into a Docker image

300
00:14:10,800 --> 00:14:14,360
that you can deploy to like Amazon's ECR.

301
00:14:14,360 --> 00:14:17,360
And then Kubernetes will kind of like know how to pull that

302
00:14:17,360 --> 00:14:19,000
down and be able to run it.

303
00:14:19,000 --> 00:14:21,760
So the ML engineer, the data scientist,

304
00:14:21,760 --> 00:14:23,440
doesn't really have to think about any of that.

305
00:14:23,440 --> 00:14:25,760
It just kind of works as part of the, you know,

306
00:14:25,760 --> 00:14:27,920
you get your PR emerged and you deploy something

307
00:14:27,920 --> 00:14:29,840
if you need to change the workflow.

308
00:14:29,840 --> 00:14:34,320
OK, but earlier on in the process, when you're experimenting,

309
00:14:34,320 --> 00:14:39,040
the currency is a, you know, some Python code.

310
00:14:39,040 --> 00:14:48,840
Are you, um, does the, are you, like what kind of tooling

311
00:14:48,840 --> 00:14:52,200
have you built up around experiment management

312
00:14:52,200 --> 00:14:56,920
and automatically tracking various experiment parameters

313
00:14:56,920 --> 00:15:01,120
or hyper parameters, hyper parameter optimization,

314
00:15:01,120 --> 00:15:02,720
that kind of thing, are you doing all that

315
00:15:02,720 --> 00:15:06,480
or is that all on the, the user to, to do?

316
00:15:06,480 --> 00:15:08,920
Yeah, that's a really good question.

317
00:15:08,920 --> 00:15:12,360
So one of the things that we added in our API for training

318
00:15:12,360 --> 00:15:14,040
is we found it was really useful to have

319
00:15:14,040 --> 00:15:17,680
this like custom prams field, especially

320
00:15:17,680 --> 00:15:19,480
because we eventually people ended up

321
00:15:19,480 --> 00:15:21,280
and, you know, we have some shared services

322
00:15:21,280 --> 00:15:23,400
to support this, like sort of a retraining service

323
00:15:23,400 --> 00:15:26,720
that can automate your training requests.

324
00:15:26,720 --> 00:15:27,640
OK.

325
00:15:27,640 --> 00:15:30,480
And so one of the things that people, from the beginning,

326
00:15:30,480 --> 00:15:34,080
used the custom programs for was hyper parameter optimization.

327
00:15:34,080 --> 00:15:35,960
We are kind of working toward building that out

328
00:15:35,960 --> 00:15:37,120
as a first class thing.

329
00:15:37,120 --> 00:15:40,560
Like, we now have like evaluation workflows

330
00:15:40,560 --> 00:15:42,720
that can be integrated with all of this as well.

331
00:15:42,720 --> 00:15:44,040
And that's kind of like the first step

332
00:15:44,040 --> 00:15:45,840
you need for hyper parameter optimization

333
00:15:45,840 --> 00:15:47,600
if you want to do it as a service is like,

334
00:15:47,600 --> 00:15:48,600
what are you optimizing?

335
00:15:48,600 --> 00:15:51,600
If you don't know what metrics people are looking at.

336
00:15:51,600 --> 00:15:53,640
So that's something we hope to do like over the next,

337
00:15:53,640 --> 00:15:55,400
you know, three to six months is to make that

338
00:15:55,400 --> 00:15:58,560
like a little bit more of first class support.

339
00:15:58,560 --> 00:16:03,280
And you mentioned this directory of workflows.

340
00:16:03,280 --> 00:16:06,000
Elaborate on that a little bit.

341
00:16:06,000 --> 00:16:06,520
Yeah.

342
00:16:06,520 --> 00:16:08,920
So one of the nice things is, you know,

343
00:16:08,920 --> 00:16:10,120
when you're writing your workflow,

344
00:16:10,120 --> 00:16:14,120
if you put it in the right place, then our, like,

345
00:16:14,120 --> 00:16:17,280
our Scala service really will know where to find it.

346
00:16:17,280 --> 00:16:19,000
But one of the side benefits has also

347
00:16:19,000 --> 00:16:22,960
just been that there is one place where people's workflows are.

348
00:16:22,960 --> 00:16:25,000
And so that's been kind of like a nice place

349
00:16:25,000 --> 00:16:26,880
for people to get started and see like,

350
00:16:26,880 --> 00:16:28,840
you know, what models are other people using

351
00:16:28,840 --> 00:16:31,760
or like what preprocessing or kind of what other things

352
00:16:31,760 --> 00:16:35,760
are they doing or what types of parameters,

353
00:16:35,760 --> 00:16:38,480
like estimator parameters, are they looking at changing

354
00:16:38,480 --> 00:16:40,720
to just kind of, you know,

355
00:16:40,720 --> 00:16:42,760
have that be like a little bit more available

356
00:16:42,760 --> 00:16:44,880
to our users or internal users.

357
00:16:44,880 --> 00:16:45,840
Mm-hmm.

358
00:16:45,840 --> 00:16:50,840
And the workflow element of this is it,

359
00:16:50,840 --> 00:16:55,280
uh, is it graph-based? Is it something like Airflow?

360
00:16:55,280 --> 00:16:57,320
Um, how's that implemented?

361
00:16:57,320 --> 00:16:59,360
Yeah. So in this case, by workflow,

362
00:16:59,360 --> 00:17:02,680
all I mean is just like Python code that, you know,

363
00:17:02,680 --> 00:17:04,680
you give it, like, we're actually,

364
00:17:04,680 --> 00:17:08,200
Rayard, our API passes to it, um,

365
00:17:08,200 --> 00:17:10,640
like, what are your features or what are your labels?

366
00:17:10,640 --> 00:17:13,600
And then your Python code returns, like,

367
00:17:13,600 --> 00:17:16,120
here is the fitted pipeline or model.

368
00:17:16,120 --> 00:17:20,200
And, um, like, usually something like the evaluation data set

369
00:17:20,200 --> 00:17:24,800
that we can pass back, um, we have had,

370
00:17:24,800 --> 00:17:27,880
so we've, people have kind of built us and users,

371
00:17:27,880 --> 00:17:31,720
like, interesting things on top of having a training API.

372
00:17:31,720 --> 00:17:33,640
So some of our users built out, um,

373
00:17:33,640 --> 00:17:35,080
actually the folks working on radar,

374
00:17:35,080 --> 00:17:37,400
our fraud product built out like an auto retraining service

375
00:17:37,400 --> 00:17:40,040
that we've since kind of taken over and generalized,

376
00:17:40,040 --> 00:17:42,600
um, where they schedule like,

377
00:17:42,600 --> 00:17:45,880
nightly retraining of all the tens and hundreds of models,

378
00:17:45,880 --> 00:17:49,440
um, and, you know, that's integrated to be able to even like,

379
00:17:49,440 --> 00:17:52,480
if the evaluation looks better, like potentially automatically

380
00:17:52,480 --> 00:17:56,080
to play them, um, we do also have people who have put like,

381
00:17:56,080 --> 00:17:59,840
training models via our service into like air flow decks.

382
00:17:59,840 --> 00:18:02,000
If they have, um, you know, some,

383
00:18:02,000 --> 00:18:05,920
some slightly more complicated set of things that they want to run, um,

384
00:18:05,920 --> 00:18:07,760
so we're definitely seeing that as well.

385
00:18:07,760 --> 00:18:10,360
Okay. And you've mentioned radar a couple of times.

386
00:18:10,360 --> 00:18:12,520
Is that a, uh, uh, product that stripe,

387
00:18:12,520 --> 00:18:13,800
or an internal project?

388
00:18:13,800 --> 00:18:18,280
Yeah, radar is our, um, like user facing fraud product.

389
00:18:18,280 --> 00:18:22,520
It, um, runs on all of our machine learning infrastructure.

390
00:18:22,520 --> 00:18:26,520
And, you know, every charge that goes through stripe within,

391
00:18:26,520 --> 00:18:28,280
usually a hundred milliseconds or so,

392
00:18:28,280 --> 00:18:31,000
we've kind of like done a bunch of real time feature generation

393
00:18:31,000 --> 00:18:35,560
and evaluated, um, like kind of all of the models that are appropriate.

394
00:18:35,560 --> 00:18:38,840
And, um, in addition to sort of the machine learning piece,

395
00:18:38,840 --> 00:18:41,000
there's also a product piece for it,

396
00:18:41,000 --> 00:18:44,920
where users can get more visibility into what our ML has done.

397
00:18:44,920 --> 00:18:47,960
They can kind of like write their own rules, um,

398
00:18:47,960 --> 00:18:49,640
and like set block thresholds on them.

399
00:18:49,640 --> 00:18:53,160
And there's, there's sort of like a manual review functionality.

400
00:18:53,160 --> 00:18:55,160
So they're kind of some more product pieces

401
00:18:55,160 --> 00:18:57,880
that are complimentary to the underlying machine learning.

402
00:18:57,880 --> 00:19:00,240
Okay. Interesting.

403
00:19:00,240 --> 00:19:02,040
And so the, uh,

404
00:19:04,280 --> 00:19:06,440
just trying to complete the picture here,

405
00:19:06,440 --> 00:19:08,880
you've got these workflows,

406
00:19:08,880 --> 00:19:10,520
which are essentially Python.

407
00:19:10,520 --> 00:19:14,600
They expose a train, uh, entry point.

408
00:19:14,600 --> 00:19:18,920
And do you, um,

409
00:19:19,960 --> 00:19:23,400
are they, you mentioned as directory of workflows,

410
00:19:23,400 --> 00:19:26,120
is that like a directory like on a server somewhere,

411
00:19:26,120 --> 00:19:27,640
with just like dot py files,

412
00:19:27,640 --> 00:19:31,640
or is that, are they, do you require that they be versioned?

413
00:19:31,640 --> 00:19:34,840
Um, and are you kind of managing those versions?

414
00:19:35,560 --> 00:19:37,880
Yeah. So that, that's just like actually like,

415
00:19:37,880 --> 00:19:39,320
in a code, basically.

416
00:19:39,320 --> 00:19:42,200
So that's like, yeah, the workflows live together in code.

417
00:19:42,200 --> 00:19:47,160
As part of, um, as part of, um, kind of our training API,

418
00:19:47,160 --> 00:19:48,440
it's like, when you submit,

419
00:19:48,440 --> 00:19:50,920
here's my training request, which has, you know,

420
00:19:50,920 --> 00:19:53,320
here's my data, here's my metadata.

421
00:19:53,320 --> 00:19:55,400
This is the workflow I want you to run.

422
00:19:55,400 --> 00:19:57,880
We give you back, um, a job ID,

423
00:19:57,880 --> 00:19:59,640
which then you can check the status of,

424
00:19:59,640 --> 00:20:00,840
you can check the result.

425
00:20:00,840 --> 00:20:02,600
The result will have things in it like,

426
00:20:02,600 --> 00:20:05,000
what was the getcha, um,

427
00:20:05,000 --> 00:20:07,480
and so that's like something that we can track as well.

428
00:20:08,360 --> 00:20:12,040
Got it. So you're submitting the job,

429
00:20:12,040 --> 00:20:14,920
with the code itself as opposed to a getcha.

430
00:20:17,240 --> 00:20:19,160
Um, so I guess it depends a little bit,

431
00:20:19,160 --> 00:20:21,000
which workflow you're running through,

432
00:20:21,000 --> 00:20:24,760
like, um, in the case where you're running on Kubernetes,

433
00:20:24,760 --> 00:20:26,440
you've merged your code to master.

434
00:20:27,320 --> 00:20:29,320
Um, and then we kind of package up all this code

435
00:20:29,320 --> 00:20:31,240
and, um, deploy the Docker image.

436
00:20:31,240 --> 00:20:34,200
And then from there, you can kind of make requests to our service,

437
00:20:35,000 --> 00:20:37,480
um, which will run the job on Kubernetes.

438
00:20:37,480 --> 00:20:39,800
So at that point, your code, it's, you know,

439
00:20:39,800 --> 00:20:41,400
whatever's on master for the workflow,

440
00:20:41,400 --> 00:20:43,240
plus whatever you've put in the request.

441
00:20:43,240 --> 00:20:44,360
Oh, got it.

442
00:20:45,160 --> 00:20:52,280
Okay. Um, and so that's the, the kind of the,

443
00:20:52,280 --> 00:20:54,520
the shape of the training infrastructure.

444
00:20:54,520 --> 00:20:57,320
You've mentioned a couple of times that you,

445
00:20:57,320 --> 00:21:00,920
it sounds like there's some degree to which,

446
00:21:00,920 --> 00:21:01,800
actually, I'm not sure.

447
00:21:01,800 --> 00:21:04,600
Maybe I'm, um, uh, inferring a lot here.

448
00:21:04,600 --> 00:21:06,680
But, uh, let's talk about the,

449
00:21:06,680 --> 00:21:11,000
where the, the data comes from for training and what kind of, uh,

450
00:21:11,000 --> 00:21:14,200
uh, you know, platform support your offering folks.

451
00:21:14,200 --> 00:21:16,840
Yeah, that, that's a really interesting question.

452
00:21:16,840 --> 00:21:20,200
Um, kind of within the framework of like,

453
00:21:20,200 --> 00:21:24,440
what do you need for a, um, like really RDPI request,

454
00:21:24,440 --> 00:21:27,240
we support two different types of data sources.

455
00:21:27,240 --> 00:21:31,000
Um, one is more for experimentation,

456
00:21:31,000 --> 00:21:33,720
which is like, you can kind of tell us how to make

457
00:21:33,720 --> 00:21:35,480
this equal to query the data warehouse.

458
00:21:35,480 --> 00:21:39,000
Um, and that's kind of nice for experimentation,

459
00:21:39,000 --> 00:21:41,080
but not so nice for production.

460
00:21:41,080 --> 00:21:44,120
Um, what pretty much everyone uses for production is,

461
00:21:44,120 --> 00:21:46,120
um, the other data source we support,

462
00:21:46,120 --> 00:21:48,840
which is parquet, um, from S3.

463
00:21:48,840 --> 00:21:51,080
So it's like, you tell us, you know,

464
00:21:51,080 --> 00:21:54,200
where to find that and what your future names are.

465
00:21:54,200 --> 00:21:57,160
And usually that's generated by, um,

466
00:21:57,160 --> 00:21:59,560
our features framework that we call semblance,

467
00:21:59,560 --> 00:22:04,760
which is basically, um, like a DSL that helps,

468
00:22:04,760 --> 00:22:07,320
you know, gives you a lot of ways to write complex features.

469
00:22:07,320 --> 00:22:09,880
Like, think, have things like counters,

470
00:22:09,880 --> 00:22:11,320
be able to do things like joins,

471
00:22:11,320 --> 00:22:13,240
do a lot of transformations,

472
00:22:13,240 --> 00:22:14,920
and then, um, you know,

473
00:22:14,920 --> 00:22:17,320
the ML infrastructure team figures out like,

474
00:22:17,320 --> 00:22:19,720
how to run that code in batch,

475
00:22:19,720 --> 00:22:22,680
if you are doing training or, um,

476
00:22:22,680 --> 00:22:25,800
like, there's a way to run it in real time,

477
00:22:25,800 --> 00:22:27,960
basically, and kind of like a Kafka consumer setup.

478
00:22:28,600 --> 00:22:30,440
Um, but you only have to write your code,

479
00:22:30,440 --> 00:22:31,720
future code, like once.

480
00:22:33,400 --> 00:22:34,200
Okay, and so,

481
00:22:34,200 --> 00:22:39,080
um, do you, are you also,

482
00:22:39,080 --> 00:22:43,640
is it the user that's only writing a future code once,

483
00:22:43,640 --> 00:22:46,760
or are you going after kind of sharing features

484
00:22:46,760 --> 00:22:49,000
across the user based to what extent,

485
00:22:49,000 --> 00:22:52,600
or are you seeing, uh, shared features?

486
00:22:52,600 --> 00:22:55,720
Yeah, that's like a really excellent question.

487
00:22:55,720 --> 00:22:58,920
Um, yeah, so the user writes their code once,

488
00:22:58,920 --> 00:23:01,000
and like also, I think having a framework

489
00:23:01,000 --> 00:23:02,440
similar to the training workflows,

490
00:23:02,440 --> 00:23:03,880
where people can see what other people

491
00:23:03,880 --> 00:23:05,400
have done has been really powerful.

492
00:23:06,200 --> 00:23:09,720
Um, so we do have people who are, like,

493
00:23:09,720 --> 00:23:11,640
definitely kind of sharing features

494
00:23:11,640 --> 00:23:13,000
across applications,

495
00:23:13,000 --> 00:23:14,440
and there's, there's a little bit of a trade-off,

496
00:23:14,440 --> 00:23:15,880
like it's like a huge amount of leverage

497
00:23:15,880 --> 00:23:17,720
if you don't have to rewrite some complicated

498
00:23:17,720 --> 00:23:18,840
business logic.

499
00:23:18,840 --> 00:23:20,680
Um, you do have to manage a little bit of

500
00:23:20,680 --> 00:23:22,920
making sure that, um, you know,

501
00:23:22,920 --> 00:23:24,120
everything is versioned,

502
00:23:24,120 --> 00:23:25,880
and that you're paying attention to, like,

503
00:23:25,880 --> 00:23:28,200
not deprecate someone else is using,

504
00:23:28,200 --> 00:23:29,720
and that you're not, like,

505
00:23:29,720 --> 00:23:31,880
just like changing a definition in place,

506
00:23:31,880 --> 00:23:34,440
and that you are kind of like creating a new version

507
00:23:34,440 --> 00:23:36,040
every time you are changing something.

508
00:23:36,040 --> 00:23:36,440
Right.

509
00:23:36,440 --> 00:23:38,280
So there's a little bit more management there,

510
00:23:38,280 --> 00:23:39,240
and hopefully over time,

511
00:23:39,240 --> 00:23:41,000
we can improve our tooling around that.

512
00:23:41,000 --> 00:23:42,920
But I think it's, you know, even,

513
00:23:42,920 --> 00:23:44,520
even since before we had a feature streamwork,

514
00:23:44,520 --> 00:23:46,840
like being able to kind of share some of that stuff,

515
00:23:46,840 --> 00:23:48,680
has been, like, hugely valuable for us.

516
00:23:50,680 --> 00:23:52,040
And are you,

517
00:23:54,280 --> 00:23:58,600
so what, uh, is the features framework,

518
00:23:58,600 --> 00:24:02,280
is that, uh, is that a set of APIs,

519
00:24:02,280 --> 00:24:05,560
or is that, uh, kind of a runtime,

520
00:24:06,520 --> 00:24:09,320
uh, thing, like, what, what exactly is it?

521
00:24:09,320 --> 00:24:10,760
Yeah, there's kind of two pieces.

522
00:24:10,760 --> 00:24:14,040
So, um, which is basically sort of what you said,

523
00:24:14,040 --> 00:24:17,400
like, you know, one is more like the API, um,

524
00:24:17,400 --> 00:24:18,760
like, what are, what are the things we,

525
00:24:18,760 --> 00:24:20,360
you know, let users express?

526
00:24:20,360 --> 00:24:22,360
And one thing we've tried to do there

527
00:24:22,360 --> 00:24:24,520
is actually constrain not a little bit.

528
00:24:24,520 --> 00:24:26,920
So we like, you have to use events for everything,

529
00:24:26,920 --> 00:24:29,160
and we don't really let you express notions of time,

530
00:24:29,160 --> 00:24:32,040
so you kind of can't mess up that time machine

531
00:24:32,040 --> 00:24:34,280
of, like, what was the state of the features

532
00:24:34,280 --> 00:24:35,720
at some time in the past,

533
00:24:35,720 --> 00:24:37,000
where you want to be training your model,

534
00:24:37,000 --> 00:24:38,680
we kind of, like, take care of that for you.

535
00:24:39,480 --> 00:24:41,480
Um, so that's kind of one piece,

536
00:24:41,480 --> 00:24:43,480
and then, you know, we kind of compile that

537
00:24:43,480 --> 00:24:45,080
into, like, an AST,

538
00:24:45,080 --> 00:24:47,160
and then we use that to essentially write,

539
00:24:47,160 --> 00:24:49,800
like, a compiler to be able to run it on different backends.

540
00:24:50,520 --> 00:24:51,880
And then we can kind of, like, you know,

541
00:24:51,880 --> 00:24:53,240
write tests and try and check,

542
00:24:53,240 --> 00:24:56,760
um, at the framework level that, that things are going to be

543
00:24:56,760 --> 00:24:59,880
as close as possible to the same across those different backends.

544
00:24:59,880 --> 00:25:02,200
So backend could be, um,

545
00:25:02,200 --> 00:25:04,200
something for training where you're going to materialize,

546
00:25:04,200 --> 00:25:06,200
like, what was the value of the features

547
00:25:06,200 --> 00:25:08,040
at each point in time in the past

548
00:25:08,040 --> 00:25:10,040
that you want as inputs to training your model,

549
00:25:10,040 --> 00:25:12,280
um, or another backend could be, like,

550
00:25:12,280 --> 00:25:13,640
I mentioned, we have kind of this

551
00:25:13,640 --> 00:25:15,640
cock consumer-based backend that we use,

552
00:25:15,640 --> 00:25:17,400
like, for example, um,

553
00:25:17,400 --> 00:25:18,920
for radar to be able to, like,

554
00:25:18,920 --> 00:25:20,040
evaluate these features,

555
00:25:20,040 --> 00:25:21,320
like, as a charge is happening?

556
00:25:21,320 --> 00:25:27,480
Uh, and so, to what extent do you find that, um,

557
00:25:27,480 --> 00:25:31,080
that, that limitation of everything being event-based

558
00:25:31,080 --> 00:25:33,640
gets in the way of what folks want to do?

559
00:25:33,640 --> 00:25:36,280
Yeah, that, that's a really good question to you.

560
00:25:36,280 --> 00:25:38,040
Um, it's definitely, uh,

561
00:25:38,040 --> 00:25:40,840
was originally a little bit of a paradigm shift for people,

562
00:25:40,840 --> 00:25:41,640
because they were like, oh,

563
00:25:41,640 --> 00:25:43,480
I just want to use this thing from the database,

564
00:25:43,480 --> 00:25:43,800
right?

565
00:25:43,800 --> 00:25:49,480
But we found that actually it's worked out pretty well,

566
00:25:49,480 --> 00:25:52,120
and that, especially when you have users who are ML engineers,

567
00:25:52,120 --> 00:25:54,520
like, they do really understand the value of,

568
00:25:54,520 --> 00:25:57,000
like, why you want to have things be event-based,

569
00:25:57,000 --> 00:26:00,200
and, like, the sort of gotchas that that helps prevent,

570
00:26:00,200 --> 00:26:02,600
um, because I think everyone has their story

571
00:26:02,600 --> 00:26:04,120
about how you were just looking something up

572
00:26:04,120 --> 00:26:06,280
in the database, but then, you know,

573
00:26:06,280 --> 00:26:07,880
the value changed, uh,

574
00:26:07,880 --> 00:26:08,840
and you didn't realize it,

575
00:26:08,840 --> 00:26:09,480
so it's kind of like,

576
00:26:09,480 --> 00:26:12,600
you're leaking future information into your training data,

577
00:26:12,600 --> 00:26:14,120
and then your model is not going to do

578
00:26:14,120 --> 00:26:15,320
as well as you thought it did.

579
00:26:15,320 --> 00:26:20,440
Um, uh, so, like, I think moving to a more event-based world,

580
00:26:20,440 --> 00:26:21,960
and, I mean, I think in general,

581
00:26:21,960 --> 00:26:24,920
shape has also kind of been doing more streaming work,

582
00:26:24,920 --> 00:26:27,720
and, um, more having, like, good support.

583
00:26:27,720 --> 00:26:29,160
Also, as, as, uh,

584
00:26:29,160 --> 00:26:30,200
at the infrastructure level,

585
00:26:30,200 --> 00:26:32,200
with Kafka has been really helpful with that.

586
00:26:33,480 --> 00:26:35,160
And so does that mean that the, uh,

587
00:26:36,520 --> 00:26:39,160
the models that they're building

588
00:26:40,600 --> 00:26:43,960
need to be aware of kind of this streaming paradigm

589
00:26:43,960 --> 00:26:45,480
during training?

590
00:26:46,280 --> 00:26:49,000
Or did they get a static data set to train?

591
00:26:49,000 --> 00:26:51,000
Yeah, so basically, um,

592
00:26:51,000 --> 00:26:53,240
you can kind of use our future's framework to just generate,

593
00:26:53,240 --> 00:26:56,360
like, per K and S3 that has materialized,

594
00:26:56,360 --> 00:26:58,280
like, all of the information you want

595
00:26:58,280 --> 00:27:00,200
of what was the value of each of the features

596
00:27:00,200 --> 00:27:03,160
that you want at all the points in time that you want,

597
00:27:03,160 --> 00:27:06,200
and then, yeah, your input to the training API is,

598
00:27:06,200 --> 00:27:08,280
like, please use this per K from S3.

599
00:27:09,000 --> 00:27:10,920
We could make it a little more seamless than that,

600
00:27:10,920 --> 00:27:12,120
but that's worked pretty well.

601
00:27:12,120 --> 00:27:15,000
Um, in part, it's just like a, uh,

602
00:27:15,000 --> 00:27:17,160
serialized, like, a file format.

603
00:27:17,160 --> 00:27:18,440
Yeah, it's pretty efficient.

604
00:27:18,440 --> 00:27:22,680
Um, you know, I think it's used in a lot of kind of big data uses.

605
00:27:22,680 --> 00:27:25,240
Um, you can also do things like predicate pushdown,

606
00:27:25,240 --> 00:27:27,000
and we have, like, a way in the training API

607
00:27:27,000 --> 00:27:28,680
to kind of specify some filters there,

608
00:27:28,680 --> 00:27:31,320
um, to just kind of, like, save, save some effort.

609
00:27:31,320 --> 00:27:34,200
Uh, use a predicate pushdown?

610
00:27:34,200 --> 00:27:37,000
Yeah, so if you know you only need certain columns

611
00:27:37,000 --> 00:27:38,600
or something, like, you know, you can,

612
00:27:38,600 --> 00:27:40,280
you can load it a little bit more efficiently

613
00:27:40,280 --> 00:27:42,600
and not have to carry around a lot of extra data.

614
00:27:42,600 --> 00:27:43,320
Got it. Okay.

615
00:27:44,440 --> 00:27:49,000
Um, the other interesting thing that you talked about

616
00:27:49,000 --> 00:27:51,960
in the context of this event,

617
00:27:51,960 --> 00:27:55,880
base framework is the whole, um, you know,

618
00:27:55,880 --> 00:27:57,880
time machine is the way you said it.

619
00:27:57,880 --> 00:28:01,640
Kind of alluding to the point and time correctness

620
00:28:01,640 --> 00:28:05,640
of, uh, you know, a feature snapshot.

621
00:28:05,640 --> 00:28:07,240
Can you elaborate a little bit on?

622
00:28:07,240 --> 00:28:10,360
Um, um, did you, did you start there

623
00:28:10,360 --> 00:28:12,440
or did you evolve to that?

624
00:28:12,440 --> 00:28:16,360
That seems to be in my conversations kind of, uh,

625
00:28:16,360 --> 00:28:19,000
I don't know, maybe you'd like one of the,

626
00:28:19,000 --> 00:28:21,080
the cutting edges or bleeding edges

627
00:28:21,080 --> 00:28:24,040
that people are trying to deal with as they scale up these,

628
00:28:24,040 --> 00:28:27,240
um, these data management systems for features.

629
00:28:28,280 --> 00:28:31,320
Yeah, for this particular project, um,

630
00:28:31,320 --> 00:28:33,480
in this version, we started there.

631
00:28:33,480 --> 00:28:35,560
Straight previously had kind of looked at something

632
00:28:35,560 --> 00:28:38,440
a little bit related a couple years before, um,

633
00:28:38,440 --> 00:28:40,120
and in a lot of ways, we kind of learned from that.

634
00:28:40,120 --> 00:28:42,200
So we ended up with something that was more,

635
00:28:42,200 --> 00:28:45,080
more powerful and sort of solved some of these issues

636
00:28:45,080 --> 00:28:46,120
at the platform level.

637
00:28:46,920 --> 00:28:49,240
Um, we did, you know, at that point,

638
00:28:49,240 --> 00:28:50,920
we had been running machine learning applications

639
00:28:50,920 --> 00:28:52,440
in production for a few years.

640
00:28:52,440 --> 00:28:55,240
So I think everyone has their horror stories, right?

641
00:28:55,240 --> 00:28:58,520
Of like all the things that can go wrong, um,

642
00:28:58,520 --> 00:29:00,440
especially kind of at a correctness level,

643
00:29:00,440 --> 00:29:01,720
and like everyone has their story

644
00:29:01,720 --> 00:29:03,080
about like re-implementing features

645
00:29:03,080 --> 00:29:04,040
in different languages,

646
00:29:04,040 --> 00:29:05,960
which we, we did for a while too,

647
00:29:05,960 --> 00:29:08,200
and kind of like all the things that can go wrong there.

648
00:29:08,200 --> 00:29:10,680
So, um, you know, I think we,

649
00:29:10,680 --> 00:29:13,080
we really tried to learn from both like,

650
00:29:13,080 --> 00:29:14,840
what are all the things we'd seen go well

651
00:29:14,840 --> 00:29:17,480
or go wrong in individual applications,

652
00:29:17,480 --> 00:29:20,120
and then also from kind of like our previous attempts,

653
00:29:20,120 --> 00:29:21,960
um, at some of this type of thing,

654
00:29:21,960 --> 00:29:23,480
like what, what was good,

655
00:29:23,480 --> 00:29:24,920
and you know, what could still be better?

656
00:29:24,920 --> 00:29:25,800
Mm-hmm.

657
00:29:26,840 --> 00:29:28,600
And, uh, out of curiosity,

658
00:29:28,600 --> 00:29:31,000
what do you use for data warehouse,

659
00:29:31,000 --> 00:29:32,120
and are there multiple,

660
00:29:32,120 --> 00:29:33,640
or is it, is there just one?

661
00:29:34,680 --> 00:29:37,160
Um, we've used a combination of Redshift and Presto,

662
00:29:37,160 --> 00:29:39,800
um, over the past couple of years,

663
00:29:39,800 --> 00:29:43,640
um, you know, they have a little bit of sort of like,

664
00:29:43,640 --> 00:29:45,160
different abilities and strengths,

665
00:29:45,160 --> 00:29:46,760
um, and those are,

666
00:29:46,760 --> 00:29:48,840
those are things that people like to use

667
00:29:48,840 --> 00:29:50,200
to experiment with machine learning,

668
00:29:50,200 --> 00:29:51,240
although like, you know,

669
00:29:51,240 --> 00:29:53,480
we generally don't use them in our production flows,

670
00:29:53,480 --> 00:29:55,560
because we kind of prefer the event-based model.

671
00:29:55,560 --> 00:29:56,760
Mm-hmm.

672
00:29:56,760 --> 00:29:59,960
And so as the event-based model,

673
00:29:59,960 --> 00:30:03,640
uh, is it kind of parallel,

674
00:30:03,640 --> 00:30:06,760
or orthogonal to Redshift or Presto,

675
00:30:06,760 --> 00:30:10,200
is there, or is it a front end to either of these two systems?

676
00:30:12,520 --> 00:30:13,720
Yeah, I guess we have,

677
00:30:13,720 --> 00:30:15,320
we actually have a front end that we've built

678
00:30:15,320 --> 00:30:17,400
for Redshift and Presto, um,

679
00:30:18,520 --> 00:30:20,360
you know, separately from machine learning,

680
00:30:20,360 --> 00:30:21,160
that's really nice,

681
00:30:21,160 --> 00:30:22,760
and lets people like, um,

682
00:30:22,760 --> 00:30:26,280
you know, to the extent they have permissions to do so,

683
00:30:26,280 --> 00:30:27,880
like explore tables,

684
00:30:27,880 --> 00:30:29,480
or put annotations on tables.

685
00:30:29,480 --> 00:30:30,280
Mm-hmm.

686
00:30:30,280 --> 00:30:32,600
Um, we haven't integrated our,

687
00:30:32,600 --> 00:30:35,400
in general, I would say we could do some work on our UIs

688
00:30:35,400 --> 00:30:37,080
for, for our ML stuff.

689
00:30:37,080 --> 00:30:38,760
We've definitely focused more on the back end,

690
00:30:38,760 --> 00:30:40,280
and in front of an API side,

691
00:30:40,280 --> 00:30:41,400
although we do have some things,

692
00:30:41,400 --> 00:30:43,240
like our auto-retreating service has a UI,

693
00:30:43,240 --> 00:30:45,080
where you can see like, um,

694
00:30:45,080 --> 00:30:46,440
what's the status of my job?

695
00:30:46,440 --> 00:30:48,200
Like, was it, you know,

696
00:30:48,200 --> 00:30:49,800
did it finish, um,

697
00:30:49,800 --> 00:30:52,280
did it produce a model that was better than the previous model?

698
00:30:52,280 --> 00:30:53,720
Mm-hmm.

699
00:30:53,720 --> 00:30:56,360
I think I'm just trying to wrap my head around

700
00:30:56,360 --> 00:30:58,840
the, the event-based model here,

701
00:30:58,840 --> 00:31:02,680
uh, you know, as an example of a question that's coming to mind,

702
00:31:02,680 --> 00:31:05,240
uh, in an event-based world,

703
00:31:05,240 --> 00:31:08,440
are you regenerating the features,

704
00:31:08,440 --> 00:31:10,200
you know, every time,

705
00:31:10,200 --> 00:31:11,720
and if you've got, you know,

706
00:31:11,720 --> 00:31:15,160
some complex feature that involves a lot of transformation,

707
00:31:15,160 --> 00:31:17,160
or you have the backfill of ton of data,

708
00:31:17,160 --> 00:31:20,200
like, what does that even mean in an event-based world,

709
00:31:20,200 --> 00:31:21,080
where I think of, like,

710
00:31:21,080 --> 00:31:22,600
you have events, and they go away.

711
00:31:22,600 --> 00:31:23,560
Yeah.

712
00:31:23,560 --> 00:31:25,720
If there's some kind of store for all that,

713
00:31:25,720 --> 00:31:27,640
that isn't Redshift or Presto?

714
00:31:27,640 --> 00:31:30,280
Um, well, whenever we say event,

715
00:31:30,280 --> 00:31:32,280
you know, we're publishing something to Kafka,

716
00:31:32,280 --> 00:31:34,280
and then we're archiving it to S3,

717
00:31:34,280 --> 00:31:36,760
uh, then that persists, like, you know,

718
00:31:36,760 --> 00:31:37,960
as long as we want it to,

719
00:31:37,960 --> 00:31:40,600
um, in some cases, basically, forever.

720
00:31:40,600 --> 00:31:43,800
Um, and so that is available.

721
00:31:43,800 --> 00:31:45,880
We do, do, end up doing, um,

722
00:31:45,880 --> 00:31:49,160
a decent amount of backfilling of kind of,

723
00:31:49,160 --> 00:31:51,640
like, you know, you define the transform features you want,

724
00:31:51,640 --> 00:31:53,720
but then, um, you need, you know,

725
00:31:53,720 --> 00:31:55,400
you need to run that back over all the data,

726
00:31:55,400 --> 00:31:56,680
you'll need for your training set.

727
00:31:56,680 --> 00:31:58,600
That's something that we've actually done a lot of

728
00:31:58,600 --> 00:32:01,320
from the beginning, partly because of our applications,

729
00:32:01,320 --> 00:32:04,280
like, when you're looking at fraud, um,

730
00:32:04,280 --> 00:32:06,520
you know, the way you find out if you were right or not,

731
00:32:06,520 --> 00:32:09,560
is that, like, in some time period,

732
00:32:09,560 --> 00:32:10,920
usually within 90 days,

733
00:32:10,920 --> 00:32:12,200
but sometimes longer than that,

734
00:32:12,200 --> 00:32:13,640
the cardholder decides,

735
00:32:13,640 --> 00:32:15,720
um, whether they're going to dispute something

736
00:32:15,720 --> 00:32:18,840
as fragile or not, um,

737
00:32:18,840 --> 00:32:20,680
and that's compared to, like, you know,

738
00:32:20,680 --> 00:32:22,440
if you're doing ads or trying to get clicks,

739
00:32:22,440 --> 00:32:24,120
like, you kind of get the result right away,

740
00:32:24,120 --> 00:32:27,160
um, and we, you know,

741
00:32:27,160 --> 00:32:28,600
so I think we've always, like,

742
00:32:28,600 --> 00:32:30,200
been interested in kind of, like,

743
00:32:30,200 --> 00:32:31,800
being able to backfill so that,

744
00:32:31,800 --> 00:32:33,560
is, you know, you can log things forward,

745
00:32:33,560 --> 00:32:35,000
but then it's like, you'll probably have to wait

746
00:32:35,000 --> 00:32:37,080
a little bit of time before you have enough of the data set

747
00:32:37,080 --> 00:32:38,120
that you can train on it.

748
00:32:40,840 --> 00:32:42,040
Okay. Um,

749
00:32:42,040 --> 00:32:44,600
cool, so we talked about the data,

750
00:32:44,600 --> 00:32:46,600
uh, side of things we talked about,

751
00:32:46,600 --> 00:32:48,200
training and experiments,

752
00:32:48,200 --> 00:32:49,720
uh, how about inference?

753
00:32:49,720 --> 00:32:53,480
Yeah, that's, that's a really great question,

754
00:32:53,480 --> 00:32:55,640
and that's, that's kind of like the first thing

755
00:32:55,640 --> 00:32:59,560
that we built infrastructure support for, um,

756
00:32:59,560 --> 00:33:01,480
at first, a decent number of years ago,

757
00:33:01,480 --> 00:33:03,640
like, I think even before things like TensorFlow

758
00:33:03,640 --> 00:33:06,440
were really popular, um,

759
00:33:06,440 --> 00:33:08,920
and so we have, um,

760
00:33:08,920 --> 00:33:10,840
like our own Scala service that we use

761
00:33:10,840 --> 00:33:14,520
to do our production real-time inference,

762
00:33:14,520 --> 00:33:17,080
um, and, you know, we started out,

763
00:33:17,080 --> 00:33:18,120
especially because we have, like,

764
00:33:18,120 --> 00:33:19,320
mostly transactional data.

765
00:33:19,320 --> 00:33:20,360
We don't have a lot of things,

766
00:33:20,360 --> 00:33:23,320
like images, at least as our most critical applications,

767
00:33:23,320 --> 00:33:24,760
at this point, um,

768
00:33:24,760 --> 00:33:25,960
a lot of our early models,

769
00:33:25,960 --> 00:33:28,200
and even still today, like most of our production models

770
00:33:28,200 --> 00:33:29,480
are kind of like tree-based models,

771
00:33:29,480 --> 00:33:31,080
like initially things like random forest,

772
00:33:31,080 --> 00:33:32,680
and now things more like XG boost.

773
00:33:33,400 --> 00:33:36,120
Um, and so, you know, we've kind of like, um,

774
00:33:37,000 --> 00:33:38,680
we have the serialization for that,

775
00:33:38,680 --> 00:33:40,680
built into our training workflows,

776
00:33:40,680 --> 00:33:42,520
and, um, we've optimized that to run

777
00:33:42,520 --> 00:33:45,080
pretty efficiently in our Scala inference service,

778
00:33:45,080 --> 00:33:47,240
and then we've built some kind of nice layers

779
00:33:47,240 --> 00:33:49,080
on top of that, um,

780
00:33:49,080 --> 00:33:51,160
for things like model composition,

781
00:33:51,160 --> 00:33:52,840
kind of what we call meta models,

782
00:33:52,840 --> 00:33:54,440
where, you know, you can kind of, like,

783
00:33:54,440 --> 00:33:56,040
take your machine learning model,

784
00:33:56,040 --> 00:33:58,440
and, um, kind of, like, almost, like,

785
00:33:58,440 --> 00:33:59,400
within the model, sort of,

786
00:33:59,400 --> 00:34:00,760
compose something, like,

787
00:34:00,760 --> 00:34:02,920
add a threshold to it, um,

788
00:34:02,920 --> 00:34:04,440
or, like, for radar,

789
00:34:04,440 --> 00:34:05,800
we train, you know,

790
00:34:05,800 --> 00:34:06,840
some array of, like,

791
00:34:06,840 --> 00:34:07,480
in some cases,

792
00:34:07,480 --> 00:34:08,680
user-specific models,

793
00:34:08,680 --> 00:34:09,480
along with, like,

794
00:34:09,480 --> 00:34:11,560
maybe more of some global models,

795
00:34:11,560 --> 00:34:13,240
and so, you can kind of incorporate

796
00:34:13,240 --> 00:34:14,520
in the framework of a model,

797
00:34:15,240 --> 00:34:16,840
doing that dispatch for your kind of,

798
00:34:16,840 --> 00:34:18,360
like, if it matches these conditions

799
00:34:18,360 --> 00:34:20,040
that score with these models,

800
00:34:20,040 --> 00:34:21,640
otherwise score with this model,

801
00:34:21,640 --> 00:34:23,240
and, like, here's how you combine it.

802
00:34:23,240 --> 00:34:24,440
Um,

803
00:34:24,440 --> 00:34:26,840
and then the way that interfaces with your application,

804
00:34:26,840 --> 00:34:28,680
is that each application has,

805
00:34:29,480 --> 00:34:30,840
uh, what we call a tag,

806
00:34:30,840 --> 00:34:33,720
and basically the tag points to the model identifier,

807
00:34:33,720 --> 00:34:35,480
which is kind of, like, immutable,

808
00:34:35,480 --> 00:34:36,920
and then whenever you have a new model,

809
00:34:36,920 --> 00:34:37,720
or you're ready to ship,

810
00:34:37,720 --> 00:34:38,600
you just, like, update,

811
00:34:38,600 --> 00:34:39,960
what does that tag point to?

812
00:34:40,600 --> 00:34:42,280
Um, and then, you know,

813
00:34:42,280 --> 00:34:43,080
in production,

814
00:34:43,080 --> 00:34:44,040
you're just saying, like,

815
00:34:44,040 --> 00:34:45,560
score the model for this tag.

816
00:34:47,480 --> 00:34:50,120
Okay, and that

817
00:34:50,120 --> 00:34:52,360
I think that's pretty similar to, like,

818
00:34:52,360 --> 00:34:53,880
you know, if you read about Uber's Michelangelo

819
00:34:53,880 --> 00:34:54,680
and things like that,

820
00:34:54,680 --> 00:34:55,240
sometimes we're like,

821
00:34:55,240 --> 00:34:57,000
oh, we all came up with the same thing.

822
00:34:57,000 --> 00:34:58,680
I think that's pretty odd.

823
00:34:58,680 --> 00:34:59,080
I think that's pretty good.

824
00:34:59,080 --> 00:35:00,360
We had also sounds a little bit like,

825
00:35:00,360 --> 00:35:02,680
uh, sorry, say that again.

826
00:35:02,680 --> 00:35:04,200
Yeah, I think that, like,

827
00:35:04,200 --> 00:35:05,720
a lot of people have kind of come up

828
00:35:05,720 --> 00:35:06,600
with some of these,

829
00:35:06,600 --> 00:35:07,720
these ways of doing things

830
00:35:07,720 --> 00:35:08,760
that just kind of make sense.

831
00:35:08,760 --> 00:35:09,720
Mm-hmm.

832
00:35:09,720 --> 00:35:10,680
Mm-hmm.

833
00:35:10,680 --> 00:35:12,120
It also sounds a little bit like,

834
00:35:12,120 --> 00:35:13,880
uh, some of what,

835
00:35:13,880 --> 00:35:14,840
uh,

836
00:35:14,840 --> 00:35:16,200
seldom is trying to capture

837
00:35:16,200 --> 00:35:17,720
in a Kubernetes environment.

838
00:35:17,720 --> 00:35:19,080
Um,

839
00:35:19,080 --> 00:35:21,480
uh, which I guess brings you to is the

840
00:35:22,200 --> 00:35:24,680
inference running in Kubernetes

841
00:35:24,680 --> 00:35:26,680
or is that a separate, um,

842
00:35:27,720 --> 00:35:29,000
separate infrastructure?

843
00:35:29,000 --> 00:35:30,040
It's not right now,

844
00:35:30,040 --> 00:35:31,640
but I think that's mostly like a matter

845
00:35:31,640 --> 00:35:33,160
of time and prioritization.

846
00:35:33,160 --> 00:35:35,000
Um, like, the first thing we move to

847
00:35:35,000 --> 00:35:36,920
Kubernetes was, uh,

848
00:35:36,920 --> 00:35:37,720
the training piece

849
00:35:37,720 --> 00:35:39,320
because the workflow management piece

850
00:35:39,320 --> 00:35:40,120
was so powerful,

851
00:35:40,120 --> 00:35:41,560
or sorry, the resource management piece

852
00:35:41,560 --> 00:35:42,680
was so powerful,

853
00:35:42,680 --> 00:35:44,360
like being able to swap out CPU,

854
00:35:44,360 --> 00:35:45,400
GPU, high memory.

855
00:35:45,400 --> 00:35:46,120
Mm-hmm.

856
00:35:46,120 --> 00:35:48,920
Um, we've moved some of our

857
00:35:48,920 --> 00:35:49,880
like, um,

858
00:35:49,880 --> 00:35:51,720
sort of real-time feature evaluation

859
00:35:51,720 --> 00:35:52,440
to Kubernetes,

860
00:35:52,440 --> 00:35:53,720
which has, um,

861
00:35:53,720 --> 00:35:55,400
been really great and made it like a lot

862
00:35:55,400 --> 00:35:56,920
less toil to kind of deploy

863
00:35:56,920 --> 00:35:58,200
new feature versions.

864
00:35:58,200 --> 00:35:58,760
At some point,

865
00:35:58,760 --> 00:36:00,360
we will probably also move

866
00:36:00,360 --> 00:36:01,880
the inference service to Kubernetes.

867
00:36:01,880 --> 00:36:03,320
We just kind of haven't gotten there yet

868
00:36:03,320 --> 00:36:05,000
because it is still some work to do that.

869
00:36:05,000 --> 00:36:05,720
Mm-hmm.

870
00:36:06,760 --> 00:36:07,640
Um,

871
00:36:07,640 --> 00:36:08,600
and is

872
00:36:09,960 --> 00:36:11,160
the, uh,

873
00:36:11,160 --> 00:36:14,040
the inferences happening on AWS as well,

874
00:36:14,040 --> 00:36:16,200
and are you using kind of standard

875
00:36:16,200 --> 00:36:17,480
CPU instances

876
00:36:17,480 --> 00:36:19,560
or are you doing anything fancy there?

877
00:36:20,520 --> 00:36:22,120
Yeah, so, um,

878
00:36:23,000 --> 00:36:24,520
we ran on cloud

879
00:36:25,080 --> 00:36:26,360
for pretty much everything,

880
00:36:26,360 --> 00:36:27,320
and, um,

881
00:36:27,320 --> 00:36:29,240
definitely use a lot of AWS.

882
00:36:29,640 --> 00:36:30,680
Um,

883
00:36:30,680 --> 00:36:32,360
for the real-time inference

884
00:36:32,360 --> 00:36:33,640
of the most sensitive,

885
00:36:33,640 --> 00:36:35,320
like production use cases,

886
00:36:35,320 --> 00:36:38,200
um, we're definitely mostly using, um,

887
00:36:38,200 --> 00:36:38,920
CPU,

888
00:36:38,920 --> 00:36:41,320
and we've done a lot of optimization work,

889
00:36:41,320 --> 00:36:41,880
um,

890
00:36:41,880 --> 00:36:43,480
so that has worked pretty well for us.

891
00:36:43,480 --> 00:36:44,280
Um,

892
00:36:44,280 --> 00:36:45,400
I think we do have some folks

893
00:36:45,400 --> 00:36:46,840
who've kind of experimented

894
00:36:46,840 --> 00:36:48,600
a little bit with, like,

895
00:36:48,600 --> 00:36:50,600
hourly or batch scoring, um,

896
00:36:51,480 --> 00:36:52,600
using some other things.

897
00:36:52,600 --> 00:36:53,480
So I think that's something

898
00:36:53,480 --> 00:36:54,680
that we're definitely thinking about

899
00:36:54,680 --> 00:36:56,920
as we have more people productionizing,

900
00:36:56,920 --> 00:36:57,800
um,

901
00:36:57,800 --> 00:36:59,720
kind of like more complex types of models

902
00:36:59,720 --> 00:37:01,560
where, you know, we might want something different.

903
00:37:03,000 --> 00:37:04,760
You mentioned a lot of optimization

904
00:37:04,760 --> 00:37:06,840
that you've done is that, uh,

905
00:37:06,840 --> 00:37:10,040
on a model by model-by-model basis

906
00:37:10,040 --> 00:37:12,600
or are there, uh,

907
00:37:12,600 --> 00:37:14,040
platform, uh,

908
00:37:14,040 --> 00:37:17,160
things that you've done that, um,

909
00:37:17,160 --> 00:37:19,720
help optimize across the various models

910
00:37:19,720 --> 00:37:21,000
that you're deploying, uh,

911
00:37:21,000 --> 00:37:22,200
for instance.

912
00:37:22,200 --> 00:37:23,320
Yeah, definitely.

913
00:37:23,320 --> 00:37:24,840
A lot of things at the platform level,

914
00:37:24,840 --> 00:37:26,520
like, I think the first models

915
00:37:26,520 --> 00:37:27,560
that we ever,

916
00:37:27,560 --> 00:37:29,480
ever scored in our inference service,

917
00:37:29,480 --> 00:37:30,920
um, were serialized with YAML,

918
00:37:31,640 --> 00:37:33,320
and they were like really huge,

919
00:37:33,320 --> 00:37:34,200
and, um,

920
00:37:34,200 --> 00:37:35,320
they caused a lot of garbage

921
00:37:35,320 --> 00:37:36,920
when we tried to load them,

922
00:37:36,920 --> 00:37:37,720
and so, like,

923
00:37:37,720 --> 00:37:38,600
we did some work there

924
00:37:38,600 --> 00:37:40,120
for kind of tree-based models,

925
00:37:40,120 --> 00:37:41,640
um,

926
00:37:41,640 --> 00:37:43,800
to be able to load things

927
00:37:43,800 --> 00:37:45,560
from disk to memory really quickly

928
00:37:45,560 --> 00:37:47,480
and, like, not producing much garbage.

929
00:37:47,480 --> 00:37:48,280
Um, so that,

930
00:37:48,280 --> 00:37:48,920
that kind of thing

931
00:37:48,920 --> 00:37:49,640
are things that we did,

932
00:37:49,640 --> 00:37:50,360
especially, kind of,

933
00:37:50,360 --> 00:37:51,320
like, in the earlier days.

934
00:37:52,280 --> 00:37:52,760
Okay.

935
00:37:52,760 --> 00:37:53,480
And are you,

936
00:37:54,680 --> 00:37:55,400
what are you using

937
00:37:55,400 --> 00:37:57,240
for querying the models?

938
00:37:57,240 --> 00:37:58,440
Are you doing rest

939
00:37:58,440 --> 00:38:00,040
or GRPC

940
00:38:00,040 --> 00:38:01,320
or, uh,

941
00:38:01,320 --> 00:38:03,480
something altogether different?

942
00:38:03,480 --> 00:38:05,800
Yeah, we use rest right now, um,

943
00:38:06,920 --> 00:38:08,040
I think GRPC is, like,

944
00:38:08,040 --> 00:38:09,480
something that we're interested in,

945
00:38:09,480 --> 00:38:11,000
um, but we haven't done yet.

946
00:38:11,000 --> 00:38:11,320
Okay.

947
00:38:11,320 --> 00:38:12,840
Uh,

948
00:38:12,840 --> 00:38:13,880
and are you,

949
00:38:14,840 --> 00:38:15,800
is all of your,

950
00:38:16,360 --> 00:38:18,280
all of the inference done

951
00:38:19,240 --> 00:38:20,200
via, um,

952
00:38:21,720 --> 00:38:23,160
kind of via rest and, like,

953
00:38:23,160 --> 00:38:24,600
a kind of microservice style,

954
00:38:24,600 --> 00:38:26,680
or do you also do, um,

955
00:38:26,680 --> 00:38:27,080
more,

956
00:38:27,960 --> 00:38:29,560
I guess, embedded types of,

957
00:38:30,360 --> 00:38:31,640
uh, inference for,

958
00:38:31,640 --> 00:38:34,600
like, where you need to have super low latency requirements.

959
00:38:34,600 --> 00:38:36,200
Does rest kind of meet the need

960
00:38:36,200 --> 00:38:38,520
across the application portfolio?

961
00:38:38,520 --> 00:38:40,520
Yeah, um,

962
00:38:40,520 --> 00:38:42,360
even for our most critical applications,

963
00:38:42,360 --> 00:38:43,880
like, shield things have worked pretty well.

964
00:38:43,880 --> 00:38:45,960
One other thing our orchestration team has done

965
00:38:45,960 --> 00:38:47,320
that's worked really well for us

966
00:38:47,320 --> 00:38:47,880
is, um,

967
00:38:47,880 --> 00:38:49,480
migrating a lot of things to OnVoy.

968
00:38:49,480 --> 00:38:50,680
Um,

969
00:38:50,680 --> 00:38:51,880
so we've seen some,

970
00:38:51,880 --> 00:38:52,760
some things where, like,

971
00:38:52,760 --> 00:38:54,760
we didn't understand why there was some delay,

972
00:38:54,760 --> 00:38:55,880
like, in what we measured

973
00:38:55,880 --> 00:38:56,920
for how long things tricks,

974
00:38:56,920 --> 00:38:58,440
versus, like, what it took to the user.

975
00:38:58,440 --> 00:39:00,120
There's just kind of one away,

976
00:39:00,120 --> 00:39:01,320
as we move to OnVoy.

977
00:39:01,320 --> 00:39:02,680
Um,

978
00:39:02,680 --> 00:39:03,560
and what is OnVoy?

979
00:39:03,560 --> 00:39:05,240
Uh,

980
00:39:05,240 --> 00:39:05,960
OnVoy is, like,

981
00:39:05,960 --> 00:39:07,880
a service service networking mesh

982
00:39:07,880 --> 00:39:09,320
that was developed by Lyft,

983
00:39:09,320 --> 00:39:09,880
um,

984
00:39:09,880 --> 00:39:11,880
and is kind of like an open source,

985
00:39:11,880 --> 00:39:12,920
open source library.

986
00:39:13,640 --> 00:39:14,120
Um,

987
00:39:14,120 --> 00:39:15,560
and so it handles a lot of,

988
00:39:15,560 --> 00:39:16,520
it can handle a lot of things,

989
00:39:16,520 --> 00:39:18,360
like service to service communication.

990
00:39:18,360 --> 00:39:19,560
Okay.

991
00:39:19,560 --> 00:39:21,400
Cool. Um,

992
00:39:21,400 --> 00:39:23,400
and so the,

993
00:39:23,400 --> 00:39:24,200
the inference,

994
00:39:26,360 --> 00:39:27,720
the inference environment,

995
00:39:27,720 --> 00:39:28,680
does it,

996
00:39:28,680 --> 00:39:30,520
is it doing,

997
00:39:31,160 --> 00:39:32,200
absent of Kubernetes,

998
00:39:32,200 --> 00:39:34,200
all the things that you'd expect Kubernetes to do

999
00:39:34,200 --> 00:39:35,320
in terms of, like,

1000
00:39:35,320 --> 00:39:36,440
auto scaling,

1001
00:39:36,440 --> 00:39:37,800
and, um,

1002
00:39:37,800 --> 00:39:38,440
you know,

1003
00:39:38,440 --> 00:39:39,400
load balancing,

1004
00:39:39,400 --> 00:39:40,520
uh,

1005
00:39:40,520 --> 00:39:43,000
across the different service instances,

1006
00:39:43,000 --> 00:39:43,880
or,

1007
00:39:43,880 --> 00:39:45,320
is that stuff all done,

1008
00:39:45,320 --> 00:39:46,440
um,

1009
00:39:46,440 --> 00:39:47,080
statically?

1010
00:39:47,080 --> 00:39:48,680
Um,

1011
00:39:48,680 --> 00:39:50,440
we take care of the routing,

1012
00:39:50,440 --> 00:39:51,320
um,

1013
00:39:51,320 --> 00:39:52,280
ourselves,

1014
00:39:52,280 --> 00:39:53,880
and we also, at this point,

1015
00:39:53,880 --> 00:39:54,520
have kind of, like,

1016
00:39:54,520 --> 00:39:55,640
charted our inference service,

1017
00:39:55,640 --> 00:39:57,400
so not all models are stored

1018
00:39:57,400 --> 00:39:58,920
on every host,

1019
00:39:58,920 --> 00:39:59,560
so that, you know,

1020
00:39:59,560 --> 00:40:00,280
we don't need hosts

1021
00:40:00,280 --> 00:40:01,480
with, like, infinite memory.

1022
00:40:01,480 --> 00:40:03,160
Um,

1023
00:40:03,160 --> 00:40:05,080
and so that we take care of ourselves,

1024
00:40:05,080 --> 00:40:06,120
um,

1025
00:40:06,120 --> 00:40:08,200
the scaling, we,

1026
00:40:08,200 --> 00:40:09,800
is not fully automated at this point.

1027
00:40:09,800 --> 00:40:10,760
We do, we have kind of, like,

1028
00:40:10,760 --> 00:40:11,640
quality of service,

1029
00:40:11,640 --> 00:40:12,200
so we have, like,

1030
00:40:12,200 --> 00:40:13,240
multiple,

1031
00:40:13,240 --> 00:40:14,680
kind of clusters of machines,

1032
00:40:14,680 --> 00:40:16,760
and we tear a little bit by, like,

1033
00:40:16,760 --> 00:40:17,080
you know,

1034
00:40:17,080 --> 00:40:18,600
how sensitive your application is

1035
00:40:18,600 --> 00:40:19,720
and what you need from it,

1036
00:40:19,720 --> 00:40:20,520
um,

1037
00:40:20,520 --> 00:40:21,880
so that we can be a little bit more

1038
00:40:21,880 --> 00:40:22,680
relaxed with people

1039
00:40:22,680 --> 00:40:23,480
who are developing

1040
00:40:23,480 --> 00:40:24,200
and want to test

1041
00:40:24,200 --> 00:40:25,160
and not have that,

1042
00:40:25,160 --> 00:40:25,640
like,

1043
00:40:25,640 --> 00:40:26,840
potentially have any impact

1044
00:40:26,840 --> 00:40:28,280
on more critical applications,

1045
00:40:28,280 --> 00:40:29,080
um,

1046
00:40:29,080 --> 00:40:30,280
but we haven't done, like,

1047
00:40:30,280 --> 00:40:31,480
totally automated scaling,

1048
00:40:31,480 --> 00:40:32,360
that's something we kind of

1049
00:40:32,360 --> 00:40:33,880
still look at a little bit ourselves.

1050
00:40:33,880 --> 00:40:35,720
Awesome. Awesome.

1051
00:40:35,720 --> 00:40:36,600
Um,

1052
00:40:36,600 --> 00:40:39,240
so if you were kind of just starting

1053
00:40:39,240 --> 00:40:41,080
down this journey,

1054
00:40:41,080 --> 00:40:42,760
uh, without having done all the,

1055
00:40:42,760 --> 00:40:43,640
the things that,

1056
00:40:43,640 --> 00:40:45,400
that you've done at Stripe,

1057
00:40:45,400 --> 00:40:46,680
where do you think you would start?

1058
00:40:46,680 --> 00:40:48,680
If you just, um,

1059
00:40:48,680 --> 00:40:50,120
you know,

1060
00:40:50,120 --> 00:40:51,480
you're, you're at an organization

1061
00:40:51,480 --> 00:40:53,880
that's kind of increasingly invested in

1062
00:40:53,880 --> 00:40:55,880
or investing in machine learning

1063
00:40:55,880 --> 00:40:57,160
and, you know,

1064
00:40:57,160 --> 00:40:58,120
needs to try to,

1065
00:40:58,120 --> 00:40:59,400
uh,

1066
00:40:59,400 --> 00:41:00,840
you know, gain some efficiencies.

1067
00:41:03,320 --> 00:41:05,160
Yeah, I mean, I think if you're just starting out,

1068
00:41:05,160 --> 00:41:06,520
like, it's good to think about,

1069
00:41:06,520 --> 00:41:08,520
like, what are your requirements, right?

1070
00:41:08,520 --> 00:41:09,720
Um,

1071
00:41:09,720 --> 00:41:10,440
and, you know,

1072
00:41:10,440 --> 00:41:11,880
if you're just trying to iterate quickly,

1073
00:41:11,880 --> 00:41:12,280
it's like,

1074
00:41:12,280 --> 00:41:14,040
do the simplest thing possible, right?

1075
00:41:14,040 --> 00:41:15,400
So, you know,

1076
00:41:15,400 --> 00:41:16,600
if you can do things in batch,

1077
00:41:16,600 --> 00:41:18,120
like, great, do things in batch,

1078
00:41:18,120 --> 00:41:19,160
um,

1079
00:41:19,160 --> 00:41:19,960
I think a lot of,

1080
00:41:19,960 --> 00:41:21,400
there are a lot of both

1081
00:41:21,400 --> 00:41:22,440
open-source libraries

1082
00:41:22,440 --> 00:41:24,200
as well as managed solutions,

1083
00:41:24,680 --> 00:41:25,640
um,

1084
00:41:25,640 --> 00:41:27,640
like, on all the different cloud providers,

1085
00:41:27,640 --> 00:41:28,520
so I think, you know,

1086
00:41:29,400 --> 00:41:30,280
I don't know, you know,

1087
00:41:30,280 --> 00:41:31,640
if you're only one person,

1088
00:41:31,640 --> 00:41:32,680
then I think that those

1089
00:41:32,680 --> 00:41:33,720
could make a lot of sense,

1090
00:41:33,720 --> 00:41:35,080
also, for people starting out,

1091
00:41:35,080 --> 00:41:36,440
because I think one of the interesting things

1092
00:41:36,440 --> 00:41:37,720
with machine learning applications

1093
00:41:37,720 --> 00:41:38,920
is that, um,

1094
00:41:38,920 --> 00:41:40,200
it takes a little bit of work,

1095
00:41:41,080 --> 00:41:41,720
like, usually,

1096
00:41:41,720 --> 00:41:43,000
there's sort of this threshold

1097
00:41:43,000 --> 00:41:43,720
of, like, your modeling

1098
00:41:43,720 --> 00:41:44,760
has to be good enough

1099
00:41:44,760 --> 00:41:45,720
for this to be, like,

1100
00:41:45,720 --> 00:41:47,480
a useful thing for you to do,

1101
00:41:47,480 --> 00:41:48,440
like, for fraud detection,

1102
00:41:48,440 --> 00:41:50,120
that's, like, if we can't catch any fraud

1103
00:41:50,120 --> 00:41:50,840
with our models,

1104
00:41:50,840 --> 00:41:51,640
then, like, you know,

1105
00:41:51,640 --> 00:41:52,600
we probably shouldn't have,

1106
00:41:52,600 --> 00:41:54,120
like, a fraud detection product,

1107
00:41:54,600 --> 00:41:55,160
um,

1108
00:41:55,160 --> 00:41:56,680
so I think it is useful to kind of have,

1109
00:41:56,680 --> 00:41:58,280
like, a quick iteration cycle

1110
00:41:58,280 --> 00:41:59,240
to find out, like,

1111
00:41:59,240 --> 00:42:00,280
is this a viable thing

1112
00:42:00,280 --> 00:42:01,800
that you even want to pursue,

1113
00:42:01,800 --> 00:42:03,080
and if you have an infrastructure team,

1114
00:42:03,080 --> 00:42:03,880
they can kind of, like,

1115
00:42:03,880 --> 00:42:05,320
help, um,

1116
00:42:05,320 --> 00:42:06,360
lower the bar for that,

1117
00:42:06,360 --> 00:42:08,120
but I think there are other ways to do that,

1118
00:42:08,120 --> 00:42:09,240
especially as, you know,

1119
00:42:09,240 --> 00:42:09,640
there's been, like,

1120
00:42:09,640 --> 00:42:10,760
this Cambrian explosion

1121
00:42:10,760 --> 00:42:11,720
in the ecosystem

1122
00:42:11,720 --> 00:42:13,160
of different open source platforms,

1123
00:42:13,160 --> 00:42:14,760
as well as different managed solutions.

1124
00:42:15,720 --> 00:42:16,360
Yeah, how do you,

1125
00:42:16,360 --> 00:42:17,480
how do you think

1126
00:42:17,480 --> 00:42:18,840
an organization knows

1127
00:42:19,640 --> 00:42:21,000
when they should have

1128
00:42:21,000 --> 00:42:21,960
an infrastructure team,

1129
00:42:23,320 --> 00:42:24,440
ML in particular?

1130
00:42:25,320 --> 00:42:27,480
Yeah, I think that's a really interesting question,

1131
00:42:27,480 --> 00:42:29,720
um, I guess, uh,

1132
00:42:29,720 --> 00:42:30,920
in our case, I think, um,

1133
00:42:30,920 --> 00:42:32,040
you know,

1134
00:42:32,040 --> 00:42:33,960
the person who originally founded the,

1135
00:42:33,960 --> 00:42:35,400
and she learning infrastructure team,

1136
00:42:36,120 --> 00:42:39,480
um, had worked in this area before at Twitter,

1137
00:42:39,480 --> 00:42:41,000
and kind of had a sense of, like,

1138
00:42:41,000 --> 00:42:41,880
this is going to be a thing

1139
00:42:41,880 --> 00:42:43,560
that we're really going to want to invest in,

1140
00:42:43,560 --> 00:42:45,480
given how important it is for our business,

1141
00:42:45,480 --> 00:42:46,520
and also that,

1142
00:42:46,520 --> 00:42:47,480
if you don't kind of, like,

1143
00:42:47,480 --> 00:42:48,680
dedicate some folks to it,

1144
00:42:48,680 --> 00:42:50,600
it's easy for them to kind of get sucked up

1145
00:42:50,600 --> 00:42:51,400
in other things,

1146
00:42:51,400 --> 00:42:52,920
like, if you just have data infrastructure,

1147
00:42:52,920 --> 00:42:54,200
that's undifferentiated.

1148
00:42:55,080 --> 00:42:56,040
Um,

1149
00:42:56,040 --> 00:42:57,640
so I think it's a really interesting question.

1150
00:42:58,360 --> 00:43:00,200
There probably is this business piece, right,

1151
00:43:00,200 --> 00:43:00,520
of, like,

1152
00:43:00,520 --> 00:43:02,040
what are your ML applications?

1153
00:43:02,040 --> 00:43:04,520
Like, how critical are they to your business?

1154
00:43:04,520 --> 00:43:07,400
And, like, how difficult are your infrastructure

1155
00:43:07,400 --> 00:43:09,240
requirements for them as well?

1156
00:43:09,240 --> 00:43:10,760
I think a lot of companies develop

1157
00:43:10,760 --> 00:43:11,880
their ML infrastructure,

1158
00:43:12,600 --> 00:43:13,960
like, starting out with things,

1159
00:43:13,960 --> 00:43:15,800
like, making the notebook experience really great,

1160
00:43:15,800 --> 00:43:16,680
because they want to support,

1161
00:43:16,680 --> 00:43:17,880
like, a lot of data scientists

1162
00:43:17,880 --> 00:43:19,640
who are doing a lot of analysis.

1163
00:43:19,640 --> 00:43:21,480
And so that's, like, a little bit of a different arc

1164
00:43:21,480 --> 00:43:23,080
from the one that we've been on.

1165
00:43:23,080 --> 00:43:24,120
And I think that's, like,

1166
00:43:24,120 --> 00:43:26,040
actually a pretty business-dependent thing.

1167
00:43:26,440 --> 00:43:26,920
Okay.

1168
00:43:28,440 --> 00:43:29,320
Awesome. Awesome.

1169
00:43:29,320 --> 00:43:31,560
Well, Kelly, thanks so much for taking the time

1170
00:43:31,560 --> 00:43:34,120
to chat with me about this really interesting

1171
00:43:35,240 --> 00:43:37,080
story, and I've enjoyed learning about it.

1172
00:43:37,800 --> 00:43:39,640
Cool. Thanks so much for chatting.

1173
00:43:39,640 --> 00:43:40,760
Really enjoyed it.

1174
00:43:40,760 --> 00:44:08,200
Awesome.

