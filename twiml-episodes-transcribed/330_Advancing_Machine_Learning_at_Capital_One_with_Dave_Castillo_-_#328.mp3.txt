Welcome to the Tumel AI Podcast.
I'm your host Sam Charrington.
Hey, what's up everyone?
I recently attended the AWS Reinvent Conference in Las Vegas, and I'm excited to share
a few of my many interesting conversations from that event here on the podcast this week.
Before we dive in, I'd like to thank our friends at Capital One for sponsoring our Reinvent
series.
Capital One has been a huge friend and supporter of this podcast for some time now, and
I'm looking forward to sharing my interview with Dave Castillo, Capital One's managing
VP of machine learning with you on Thursday.
Dave and I discussed the unique approach being taken at the company's center for machine
learning, as well as some of the interesting AI use cases being developed at the bank,
and the platform they're building to support their ML and AI efforts.
To learn more about Capital One's machine learning and AI efforts and research, visit capitalone.com
slash tech slash explore.
And now on to the show.
All right, everyone.
We are here at Reinvent in Las Vegas, and I am with Dave Castillo.
Dave is the managing vice president for machine learning at Capital One.
Dave, welcome to the Twimal AI podcast.
Oh, thanks, Sam.
Happy to be here.
Let's just jump right in and talk a little bit about your background.
Tell us about your work in the machine learning field.
Absolutely.
So I'm actually very fortunate.
I got to start machine learning way back when it was still handcrafted knowledge, and
we were really focused on knowledge representation.
So I started out in the NASA days.
I did a lot of work for NASA, and it was about solving problems that were very theoretical,
but never really saw the light of day in a production setting.
That wasn't NASA?
Actually, I worked with all the NASA bureaus, but I was stationed actually in Florida,
and I kept the Kennedy Space Center, Johnson Space Center, and JPL, Jet Propulsion Lab.
So I worked with all those three, and it was a lot of fun.
We did robotic vision systems, which are obviously a whole different technology set back
then, than convolutional known.
That sort of annihilated all of that work, and put a lot of people out of work in the
process.
I started with the start of there, and really watched the transition go from knowledge representation
into statistical learning, into machine learning, into deep learning, and then explainability
on top of that, and then more recently, just really looking into how do we do large-scale
graph related machine learning with graph machine learning.
So I've had this very diverse career.
graph had two startups, wind up in the media industry, as a CTO of an advertising company
in New York City for several years, and I left that in 2015 and joined banking with a company
called Early Warning, most popular for Zell, the master payment system, and I ran machine
learning there, the innovation labs, and their data transformation.
That company's owned by the seven largest banks in the U.S., including Capital One.
That's how I got familiar with Capital One.
I started here last June in 2019, 2018, sorry.
Right, right.
So what's your role at Capital One?
I run what's called the Center for Machine Learning, and it's a fairly large organization.
It's 200 plus people focused on a center of excellence, and I can get into a little bit
more of what that means later if you like.
Yeah.
It's folks to Adam Wenzhel on the podcast about a year and a half ago, and he went off
to do a startup, I think, now, is that the same, are you in the same role?
I'm in the same role, absolutely.
I actually met Adam, and I thank Adam for the incredible job he did in amassing a great
talent to sort of incubate the Center for Machine Learning, and Adam had to start in
a place where he was really the skill set, and the expertise around machine learning,
so the machine learning opportunities and solutions all came in and fanned into Adam's organization.
And that's no longer the case now.
We've been able to transform that where we can scale it, and we federated a lot of
capability out.
So our model is more of a model of enablement now, where we actually join teams.
We provide skill sets, technology, platforms, tools, education, boot camps, basically just
trying to empower the other teams to be self-sufficient, and we stay with them for a
period of time, and then we extract ourselves.
Yeah, one of the things that I'm seeing all over the enterprise landscape, it's happening
right now is this kind of transition from doing machine learning in kind of a lab type
of environment, doing a lot of experimentation to, and alongside that, you know, selling
it across the enterprise, and now it seems like everyone's bought in, everyone wants to
figure out how to do it, how to build models, get their pet model into production, and
it's causing shifts in the way organizations are organizing it to support that.
It sounds like you're going through a similar transition.
Yeah, so 18 months ago, we had a lot of sighted desks, bespoke initiatives, where people
were creating their own solutions, they were very narrow, solve very narrow use cases,
and they had to go through all the pain associated with getting something from a proof of concept
into whether it be a challenger model or ultimately into production, and what's happened since
then is that we've become highly collaborative because we understand the challenges associated
with getting a machine learning into production in a well-managed, compliant way, and that's
not an easy task, especially when you have a material model, a model that's under regulatory
scrutiny, and even our immaterial models, which are not so heavily scrutinized, but still
require a well-managed discipline about them.
Anyway, there was a sentiment about how do we actually take all these learnings and come
together as an enterprise and leverage what each other has done, and throw away some
of these sighted desks solutions that don't scale, and really look toward more of an enterprise
offering.
And we've done a lot of work in that area, so now we have collaboration, Center for Machine
Learning Collaborates with all the lines of business, we're driving an enterprise, what
we call the enterprise machine learning ecosystem now, it's driven by myself and another guy
named Annie Gupta, who's in our card business, and underneath that initiative, we have our
feature platform, our machine learning platform, and our monitoring platform, all really
looking at how do you go from inception to deployment, and then keep the 360 moving through
monitoring and refit and retraining.
So there's been a huge sort of awakening that has happened in Capital One, it's really
exciting to see everyone coming together, it's not so territorial anymore, it's really,
how do we help each other actually get to the finish line?
Awesome, awesome.
Before we dig into a little bit of the platform that you've built, can we talk a little
bit about the use cases?
I have spoken to folks at Capital One that are doing things like Fraud and AML, and there
are a bunch of things that are kind of obvious ones for a financial services company, maybe
we can talk about the broad landscape, but I'm also curious if you can share any ones
that are maybe less obvious or more interesting or that you're personally excited about.
We've been Capital One, we are looking at applying machine learning across every facet
of our business, and we've done some very cool and interesting things that you wouldn't
think it would be associated with a bank, so for example, when you join Capital One,
you get assigned access privileges to data and to systems, that's all done by machine
learning today.
And many as an employee, as an employee, when you join, and that's something that we built.
So that's in production, and it's actually compressed the time for associates to get
up to speed and actually be productive because they've had to wait weeks and weeks and weeks
to get access to certain data, to certain systems, and now it's all assigned based on these
algorithms.
That's kind of cool.
We have space allocation that happens when we look at how badges are navigating through
our buildings, and we can look at how to plan space for people, and that's an interesting
application of machine learning.
We did one last year where we're assigning our first year associates, they go on a rotation.
So the next job is an assignment that's actually a recommendation engine that's actually
made by a machine learning algorithm for that job assignment.
That was all done manually on a huge spreadsheet, it was very painful for people to do that
across the board.
That's all automated.
When we're doing, what I used to do in the ad tech industry, we're doing adward bidding
with multi-arm bandits, we're doing creative and personalization, aspiring toward getting
granular and personalization with multi-arm bandits, a tiny bit of reinforcement learning.
So those are not typical of mapping, but I think it's a testimony of that we're serious
about where we want to apply this technology.
There's a plethora of other examples I could give you on reading documents from our vendors
and extracting salient information out of those documents, etc.
The thing that jumped out to me about a couple of those examples, the space planning and
the employee example, the onboarding example, is that the functions that own those processes
are HR and facilities, probably not necessarily the most technology forward or AI-enabled organizations.
So did they come to you with those opportunities and ideas, or is this part of the COE process
where you're already embedded with them?
How does the ideation process work there?
Yeah, it was really an outward reach on our part.
And then once we started to educate as to what was possible, then dialogue started happening
within these non-technical organizations, and then something was more and out of that.
So yeah, it was an outward reach.
We started up a year ago, we started up what we call advanced ML within the Center for
Machine Learning.
This is a new group that is focused on three things.
One is we had to get better about managing our university research partnerships, and
we can talk about that a little bit later.
The second item was we wanted to initiate an advocacy function where we could talk to
our lines of businesses about what we were doing and how we might look at doing their
jobs a little bit differently with machine learning, not necessarily automating the tasks
that they're doing, but thinking about their jobs differently.
The third component of that was really focused on getting a collaboration across Capital
One on what are the challenges that we're all facing when it comes to machine learning,
whether it is at the beginning of the machine learning lifecycle or at the end, let's identify
what those challenges are, and then let's look at trying to come together as an organization
rather than as individual victims to solve them.
Yeah, it strikes me that when thinking about the types of examples that you gave, there
have to be so many examples like that.
But there are also these very high value, cord of financial services, types of use cases
that I guess I'm trying to formulate a question around how do you prioritize when you've
got this broad portfolio of opportunities, some of which are cord of the business and
drive revenue and profitability and others are supporting organizations that aren't necessarily
central to that conversation or aren't not often central to that conversation.
Again, the HR facilities, that kind of thing.
This group that I mentioned earlier, the advocacy group, is really was meant to bring all
these people together, and then what that group also does is it opines on what are the
higher priority areas that we should be focused on.
There's a lot of discussion, the group got very large, it got to like 35 people across
the company, and so we actually split it up into sort of a hierarchy of groups.
But the idea is that there are high priority opportunities for us that we definitely have
to be plugged into, but there is also enough bandwidth with this new enablement model that
we can actually address some of these non-high priority use cases, just to really allow us
to get some bedrock out there in terms of proliferating and democratizing ML.
But certainly the high-price items get discussed and they are triaged, and it's no longer
someone in the center for machine learning saying, I think this is the highest priority,
this is coming from the business now.
That's a flip on how we operated a year and a half ago.
So it sounds like kind of putting some of the pieces together, transitioning the models
of one where you don't necessarily own the development of the model and getting it into production,
but you're supporting the business, as well as the platform and infrastructure pieces
that you mentioned have created a velocity or acceleration or efficiency to being able
to work on these projects that allows you to get more done in more areas.
So most of the models are owned by the owners of the use cases, so the lines of business
if you will, or even our tech partners, because we often partner with our tech partners
for anomaly detection, let's say.
So they own those use cases and they will typically own those models.
There are some models that we own as well, and that we will start and take into production.
But what we're trying to do really is to empower others to be self-sufficient and to be able
to leverage these best practices, leverage the tools and tech that either are emerging
or have been built so that we can do things in a very consistent, well-managed and again,
compliant way.
Can you give us a sense of scope for how many data scientists exist within Capital One
relative to the number within your COE?
Just trying to understand the leverage that you're trying to create with the COE, and
maybe to just tack another question onto that.
One of the things that I see a lot of in industry is the shifting away from thinking of the
data scientists as this monolithic unicorn that can do everything from statistical analysis
to production-ready code, and you are starting to see a lot more of machine learning engineers
as a separate and distinct role that works with the data scientists as part of the team
and brings more of a software engineering perspective and wondering how that plays out
at Capital One.
There are data scientists within the lines of business that have come up through the traditional
ranks of statistical analysis and data science.
There have been transformations in those skill sets to more toward understanding how to
address this life cycle for machine learning, so the machine learning engineering part
if you will.
We have worked very closely with our tech college organization to do a couple of things.
One is to provide curriculum on how to round out a data scientist to understand what that
whole spectrum looks like, and also a rescilling program that we have not officially launched
yet, we developed all the content for, but to take data engineers or software engineers
and to get them converted into machine learning engineers, this rescilling program is all
about that.
Within the Center for Machine Learning, we do focus on bringing in machine learning engineers
so that they will have a little software engineering, they will have data science, they will have
DevOps, data engineering, and so they tend to cover all the entire life cycle of machine
learning if you will.
But as you might expect, there isn't enough supply of those types of people, but we are
seeing the lines of business actually hiring this type of talent and then it becomes sort
of viral, it's contagious and they are able to leverage that skill set and teach others
and get some critical mass around the MLE.
We still call our machine learning engineers software engineers from an organizational
perspective, it's just kind of a legacy thing, but what I would say is that the concentration
of machine learning engineers within the Center for machine learning is probably at
par with some of the largest lines of business that we have.
Now they certainly have many more business analysts, many more data scientists than we have
because they have to.
And as we begin to automate a lot of these processes involved in the machine learning life cycle,
these data scientists are going to be a lot more capable of doing much more than they
have before because they don't know how to do a deployment, it's going to be push button.
If they don't know how to access a feature set, that's going to be a library call from
a Python notebook, it's going to be fairly easy for them.
And so part of our strategy for our platform or our MLE ecosystem is to really take a
giant step, a step function, if you will, to make these data scientists a lot more capable.
While we're also teaching them the rest of the, all the other parts that encompass what
you need to know for machine learning engineering.
Because your organization end up owning the MLE ecosystem, the platform and responsibility
for its maintenance and upkeep and all that, or you more defining the requirements and
partnering with an IT or other technology organization to get it out and keep it up.
Now we're an enterprise function, so that's part of the new identity we've taken on is
that we are going to own and support production systems, production machine learning systems.
That is a new responsibility that has come into our organization and we embrace that and
we look forward to dealing with that.
Yeah, going back to the platform you mentioned, feature store feature component.
And I guess this is fresh on my mind because of a conversation I had yesterday.
But when a data scientist or an MLE engineer builds a feature and contributes it to a feature
store type of environment, there's a certain level of responsibility now for that feature
it becomes kind of a mini product in a sense and it limits them in the way they evolve it
potentially.
They are maybe an implied support requirement.
Anything necessarily specific to features but anytime you're trying to take advantage
of reuse, there's this implied contract that comes from kind of contributing your code
or your feature.
Is that an issue that you grapple with and how does it play out at Capital One?
Yeah, that's actually a very good point and it's like careful what you wish for, because
there's always the flip side of something that you have to deal with.
One who contributes a feature to the feature platform has to understand the responsibility
that goes with that and there is a responsibility.
There's a responsibility to be able to field questions on that feature.
There's a responsibility stand behind the engine that calculates that feature.
There's a responsibility to have gone through the governance associated with that feature
and the use cases that it serves.
And so it's a much bigger deal.
We can't just casually commit something back, you have to understand exactly what you're
doing and where that accountability lies.
The same thing is true with the platform.
When we took that on, we had to understand that there may be calls at two o'clock in the
morning associated with this platform.
The Center for Machine Learning has never had that before.
And when we added talent to the Center for Machine Learning, we brought people in who
had production experience, enterprise, platform experience, because a lot of people there were
machine learning engineers, some of them were fresh out of school, some of them were fresh
out of their PhD programs.
Not many really had that level of experience, so we had to retool and we brought in a very
large group to integrate into the Center for Machine Learning.
But the mindset is that there is an operational accountability that we have and that anyone
is going to have who contributes features into the feature platform.
Now if you think about our data transformation, the same thing is true there.
If you manufacture data, you're almost in the same position where you have to be able
to, you know, you're going to put data into an ecosystem and make it available for someone
else and there has to be some level of accountability that goes with that.
It just can't be something that you casually contribute.
So this is all part of our well-managed initiative and I think, you know, to scale machine learning
across our organization to really transform banking, we have, we understand that we're
going to have to be more disciplined about how we conduct ourselves.
You mentioned something interesting in there.
It sounded like you brought in an organization that had existing platform capability.
Was this kind of an internal transfer of a team?
It was, that's exactly what it was, there was a platform team that was in another group.
And when I started to have these conversations with our executive management, we knew that
we had to seed our talent with this other type of talent.
And so we went in and started to look at organizational adjustments and we wound up integrating
an entire group and we actually did it in two ways.
We brought in, brought in half the group and then we brought in the second half of the
group after we had built up some critical mass.
And so now what we've done is we actually have a platform's organization within the
center for machine learning that is all about enterprise level, enterprise platform.
So we're talking about resilience, scalability, logging, you know, all the things that you'd
expect to see with the platform.
This team has the experience in actually doing all those things.
Yeah, it's a really great example of something that I talked to folks about all the time,
you know, whereas machine learning and building out machine learning platforms might be new
to an organization, the core kind of requirements and engineering practices probably aren't
new.
Capital One, for example, has, you know, I've known Capital One for many years to be investing
heavily in platform as a service and container orchestration and all kinds of, not to mention
we're here at Reinvent Cloud and building, you know, platforms to support traditional enterprise
applications.
A lot of the principles that go into supporting, you know, enterprise apps, web apps are similar
to, you know, some of the things you need to be thinking about when you're supporting machine
learning and AI-based systems, is that your experience as well?
Absolutely.
Yeah.
A spot on.
It's definitely my experience.
One of the things that you've mentioned is kind of a common thread throughout the discussion
is the interface with risk and governance.
Can you talk a little bit about more about that process?
Yeah, absolutely.
I believe that we are actually in a very unique and interesting position at Capital One when
it comes to the governance around machine learning.
We have been living in a regulated world for many, many years, obviously, and with varying
degrees of regulatory oversight, as I mentioned before, material models and non- and immaterial
models, the ones that don't have to go through such high levels of regulatory scrutiny, but
we understand the process and we understand all these little sort of phases and artifacts
and responsibilities and the laws of making sure that at the end of the day, we are compliant
with the regulatory frameworks that we have to navigate within today manually.
So let me give you an example.
When we create a machine learning model, we have to go through a process to validate
the outcomes and how this model has actually performed.
And one way one of the approaches that we might take is to build what are called these
surrogate validation models.
So we go in and handcraft these other models and these other models either support the
outcomes of the model that you are trying to get through governance or they might refute
it.
They might show something that is a little bit different.
And then you have to write all this stuff up in a document and you have to get that document
through and you have to defend it and so on and so forth.
Is the surrogate validation model, is that like a test suite or is it?
You can think of it.
You can think of it as kind of model or yeah, you can think of it as that, right?
But like for example, if you're doing a gradient boosted machine, you might have surrogate
models that are logistic regression models that are something that are types of models
that we've been able to linear models that we've been able to deal with for many, many
years and we can see how these two models behave with, you know, again, certain types
of data sets that they're scoring.
The opportunity for us is because we know this process so well, we can actually use ML
for governing ML.
We can use natural language processing for auto-document generation.
We can use auto ML to generate the surrogate models automatically and then run them.
You know, and we can interpret those documents on the other side.
We can double click into the validation models and surface the, either the supporting argument
or for those models.
If you think about it even beyond that, when you talk to these model risk officers, their
minds are, I mean, the wheels are turning in their heads.
They see so many opportunities for doing some really cool things like one of one model
risk officers said to me, I'd like to have this sort of surrogate recommendation engine
that's saying, hey, I just picked up this bias in this data set and your feature set.
Here are the artifacts that I picked up.
This thing's running kind of alongside you, you know, and it's picking this kind of
bias up and recommend you make these changes or you take a look at these particular features.
That's cool stuff.
Then you can actually do, if you could actually do something like that.
So we're looking into piloting and doing some POCs around a lot of these kind of interesting
model governance kinds of tasks.
Now I don't think we'll ever take the human out of the loop, especially for those highly
regulated, regulated use cases, but I think we're going to make their workload significantly
less laborious.
If you think about the proliferation of machine learning models at Capital One, we don't
want to just stack them up on the model risk officers back door and we're in the same
boat we're in today.
We're just, they just have a huge backlog that they have to work through.
We want to give them the tools to actually get through this and we want to be able to
build that right into our platform.
I think that's where we are thinking about the ideas that we're thinking about are far
beyond what others are, as they're looking at machine learning, just based on the conversations
that I've had with them and that I'm seeing in the trade racks, is that the regulated,
highly regulated models are certainly going to undergo tremendous scrutiny.
We know that.
But there's this other class of models that they're starting to look at as well and they're
saying even though the regulatory frameworks don't cover those models, they need to be
explained and interpreted and bias detected just like these other models and I think there's
going to be, the sentiment is going to be that all models have to go through this sort
of scrutiny and I think that tech companies are going to be facing the same thing.
So what kind of advice would you give them, companies that don't have the history of
operating in a regulatory framework but want to either see the writing on the wall or
they are internally motivated to use machine learning in a responsible way.
How do they kind of bootstrap the internal frameworks to do so?
There are some, I mentioned earlier about the rate of innovation in the industry.
There are some emerging companies that are providing some libraries for some of this,
some types of bias detection.
So there's some basic functions that you can do today with libraries and Python and then
there's companies that are springing up weekly, it seems like that are addressing explainable
and interpretable AI.
So I would say that to those companies that don't have the expertise to just get, at
least get savvy about what's happening and there's so much literature out there about
this.
So if you're in the cloud with the AWS, AWS does have some basic capability with Shapley
values that you can use to help explain or interpret your models.
So there's some fundamental pieces there that I think people should at least become aware
of.
But it's certainly something you should not ignore because I believe that this is going
to be, in five years from now, this is going to be something that is expected of everything
that we do with machine learning.
We're going to have to be able to explain that model and I think it's going to be all
be built in.
Well, Dave, thanks so much for taking the time to share what you're up to.
It sounds like it continues to be an interesting run and you're doing a lot of interesting things
there at Capital One.
I appreciate the opportunity to learn about it.
Thanks for having me, Sam.
Appreciate it.
Thank you.
All right, everyone, that's our show for today to follow along with our reinvent series.
Visit twimmelai.com slash reinvent 2019.
Thanks once again to Capital One for their sponsorship of this series.
Be sure to check out capital one calm slash tech slash explore to learn more about their
ML and AI research.
Thanks so much for listening and catch you next time.
