1
00:00:00,000 --> 00:00:15,920
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

2
00:00:15,920 --> 00:00:20,880
people doing interesting things in machine learning and artificial intelligence.

3
00:00:20,880 --> 00:00:23,480
I'm your host Sam Charrington.

4
00:00:23,480 --> 00:00:28,040
A quick thanks to everyone who participated in last week's Twimble Online Meetup.

5
00:00:28,040 --> 00:00:29,960
It was another great one.

6
00:00:29,960 --> 00:00:35,480
If you missed it, the recording will be posted to the Meetup page at twimbleai.com slash

7
00:00:35,480 --> 00:00:36,480
meetup.

8
00:00:36,480 --> 00:00:37,880
Definitely check it out.

9
00:00:37,880 --> 00:00:43,680
I never cease to be amazed by the generosity and creativity of the Twimble community.

10
00:00:43,680 --> 00:00:48,480
And I'd like to send a special shout out to listener Sharon Glander for her exceptional

11
00:00:48,480 --> 00:00:50,200
sketch notes.

12
00:00:50,200 --> 00:00:55,120
Sharon has been creating beautiful hand sketch notes of her favorite Twimble episodes

13
00:00:55,120 --> 00:00:57,160
and sharing them with the community.

14
00:00:57,160 --> 00:01:00,400
Sharon, we truly love and appreciate what you're doing with those.

15
00:01:00,400 --> 00:01:02,920
So please keep up the great work.

16
00:01:02,920 --> 00:01:06,040
We'll link to her sketch notes in the show notes for this episode.

17
00:01:06,040 --> 00:01:11,440
And you should definitely follow her on Twitter at sharingglander for more.

18
00:01:11,440 --> 00:01:15,840
This is your last chance to register for the rework, deep learning and AI assistant

19
00:01:15,840 --> 00:01:22,200
summits in San Francisco, which are this Thursday and Friday, January 25th and 26th.

20
00:01:22,200 --> 00:01:26,600
These events feature leading researchers and technologists like the ones you heard in

21
00:01:26,600 --> 00:01:29,720
our Deep Learning Summit series last week.

22
00:01:29,720 --> 00:01:34,680
The San Francisco event is headlined by Ian Goodfellow of Google Brain, Daphne Kohler

23
00:01:34,680 --> 00:01:37,560
of Calico Labs and more.

24
00:01:37,560 --> 00:01:43,040
Definitely check it out and use the code Twimbleai for 20% off of registration.

25
00:01:43,040 --> 00:01:45,880
Now, a bit about today's show.

26
00:01:45,880 --> 00:01:51,080
In this episode, I speak with Thomas Sanholm, Carnegie Mellon University professor and

27
00:01:51,080 --> 00:01:56,720
founder and CEO of startups optimized markets and strategic machine.

28
00:01:56,720 --> 00:02:03,800
Thomas, along with his PhD student, Noam Brown, won a 2017 NIPPS Best Paper Award for their

29
00:02:03,800 --> 00:02:09,680
paper, Safe and Nested Subgames Solving for Imperfect Information Games.

30
00:02:09,680 --> 00:02:14,200
Thomas and I dig into the significance of the paper, including a breakdown of perfect

31
00:02:14,200 --> 00:02:19,880
versus imperfect information games, the role of abstractions in game solving, and how

32
00:02:19,880 --> 00:02:23,280
the concept of safety applies to gameplay.

33
00:02:23,280 --> 00:02:27,680
We discuss how all these elements and techniques are applied to poker, and how the algorithm

34
00:02:27,680 --> 00:02:33,200
described in this paper was used by Noam and Thomas to create LeBrotus, the first AI

35
00:02:33,200 --> 00:02:39,720
to beat top human pros and no limit Texas Holdum, a particularly difficult game to beat

36
00:02:39,720 --> 00:02:42,280
due to its large state space.

37
00:02:42,280 --> 00:02:54,280
This was a fascinating interview that I'm really excited to share with you.

38
00:02:54,280 --> 00:03:01,240
Alright everyone, after a busy week at NIPPS, I am back home, and on the line with

39
00:03:01,240 --> 00:03:07,600
Tuomas Sanholm, Tuomas is a professor in the computer science department at Carnegie

40
00:03:07,600 --> 00:03:13,680
Mellon University, as well as founder and CEO of two start-ups, Strategic Machine, and

41
00:03:13,680 --> 00:03:21,720
Optimize Markets, as well as an author of the Best Paper Award winning Safe and Nested

42
00:03:21,720 --> 00:03:26,560
Subgames Solving for Imperfect Information Games at this year's NIPPS.

43
00:03:26,560 --> 00:03:28,840
Tuomas, welcome to the podcast.

44
00:03:28,840 --> 00:03:30,240
Thank you for having me.

45
00:03:30,240 --> 00:03:31,240
Absolutely.

46
00:03:31,240 --> 00:03:35,480
It's a little bit of a tradition here to have our guests get started by telling us a

47
00:03:35,480 --> 00:03:40,240
little bit about their backgrounds and how they got involved in machine learning, and

48
00:03:40,240 --> 00:03:45,720
you sound like quite a busy guy, who with your two start-ups and posts at CMU, so feel

49
00:03:45,720 --> 00:03:49,680
free to take some time and let us know how all that fits together.

50
00:03:49,680 --> 00:03:51,280
Yeah, happy to.

51
00:03:51,280 --> 00:03:59,000
So I've been working on AI as in around 1989, and in my lab at CMU there are maybe 25

52
00:03:59,000 --> 00:04:02,920
different research trends, maybe six of them active at any one time.

53
00:04:02,920 --> 00:04:09,600
We're probably best known for combinatorial auctions and kidney exchange, so we run the

54
00:04:09,600 --> 00:04:15,680
nation what kidney exchange for units with our algorithms and game solving.

55
00:04:15,680 --> 00:04:21,600
So solving these large imperfect information games where we actually reach superhuman level

56
00:04:21,600 --> 00:04:27,760
at strategic reasoning, this January by beating the top players in Heads Up No Limit

57
00:04:27,760 --> 00:04:29,320
Texas Holder.

58
00:04:29,320 --> 00:04:34,520
And my two start-ups, well, the first one of my current ones, I'm also a serial entrepreneur

59
00:04:34,520 --> 00:04:39,640
with successful start-ups in the past, but the first one, Optimized Markets, is really

60
00:04:39,640 --> 00:04:46,280
like a combinatorial sales support system for advertising campaigns, cross media.

61
00:04:46,280 --> 00:04:55,480
So in TV, both linear TV and non-linear, streaming, both TV and radio and display advertising

62
00:04:55,480 --> 00:05:00,440
and so forth, and where we're optimizing the allocation of inventory to campaigns and

63
00:05:00,440 --> 00:05:03,480
pricing and scheduling and so forth.

64
00:05:03,480 --> 00:05:08,720
And the newer start-up, which is really brand new, is called strategic machine, where we

65
00:05:08,720 --> 00:05:13,920
have taken this strategic reasoning technology that we have developed in my lab here at Carnegie

66
00:05:13,920 --> 00:05:21,160
Milan over the last 14 years, and we are commercializing it across a wide range of applications, ranging

67
00:05:21,160 --> 00:05:28,560
from, of course, recreational games like poker to business applications and automated negotiation,

68
00:05:28,560 --> 00:05:34,720
strategic pricing, product portfolio construction, auctions and so on, all the way to military

69
00:05:34,720 --> 00:05:41,160
applications like cyber security, physical security, physical military, and even in steering

70
00:05:41,160 --> 00:05:44,720
biological evolution and adaptation for treatment planning.

71
00:05:44,720 --> 00:05:46,840
Well, that's a pretty broad set of applications.

72
00:05:46,840 --> 00:05:51,120
Yeah, when you're doing the early stages of our start-up with a platform technology like

73
00:05:51,120 --> 00:05:56,120
this, really the first challenge and the first order to do after the technology is ready,

74
00:05:56,120 --> 00:06:01,200
is to really prioritize our markets and pick and choose where it makes the most benefit

75
00:06:01,200 --> 00:06:05,840
and where you can penetrate the fastest and doing that prioritization.

76
00:06:05,840 --> 00:06:08,440
And we're actually in that process right now.

77
00:06:08,440 --> 00:06:12,840
So the paper that we want to talk about is safe and nested sub-game, solving for information

78
00:06:12,840 --> 00:06:18,200
in perfect games and it sounds like the big distinction there between what you're working

79
00:06:18,200 --> 00:06:23,680
on and some of the other things we've seen in the kind of machine learning apply to game

80
00:06:23,680 --> 00:06:27,040
arena is in that imperfect information part.

81
00:06:27,040 --> 00:06:29,600
Can you tell us a little bit about that and why that's important?

82
00:06:29,600 --> 00:06:31,480
Yeah, that's exactly right.

83
00:06:31,480 --> 00:06:39,320
So when you talk about games like checkers, chess or go where AI has seen a lot of success,

84
00:06:39,320 --> 00:06:42,320
they are what's called perfect information games.

85
00:06:42,320 --> 00:06:47,200
So when it is a player's turn to move, the player knows the exact state of the world.

86
00:06:47,200 --> 00:06:52,880
In contrast, in most real world applications where you have more than one party acting,

87
00:06:52,880 --> 00:06:58,280
they're what's called imperfect information games where when it's your turn to move,

88
00:06:58,280 --> 00:07:01,880
you don't really know the state of the world exactly.

89
00:07:01,880 --> 00:07:07,600
So there's hidden information and that can come from us not observing what chance has

90
00:07:07,600 --> 00:07:13,640
done so far, as in let's say pomity peas, but there's an additional element that there

91
00:07:13,640 --> 00:07:19,360
are other players, at least one other player and you may not even observe what the other

92
00:07:19,360 --> 00:07:23,480
player has done in the game so far.

93
00:07:23,480 --> 00:07:27,800
And also the other player may have observed different things about what chance has done

94
00:07:27,800 --> 00:07:29,640
so far than you have.

95
00:07:29,640 --> 00:07:34,760
So now you have private information, you know things that your opponent or opponents don't

96
00:07:34,760 --> 00:07:38,200
know and vice versa, they know things that you don't know.

97
00:07:38,200 --> 00:07:43,720
So now it becomes much harder to solve, because you have to think about issues not present

98
00:07:43,720 --> 00:07:45,720
in perfect information games.

99
00:07:45,720 --> 00:07:50,400
Like how do my actions signal to my opponent about my private information?

100
00:07:50,400 --> 00:07:56,640
And conversely how do my opponent's actions, how should they signal to me about the opponent's

101
00:07:56,640 --> 00:07:57,640
private information?

102
00:07:57,640 --> 00:08:02,080
And so the approaches that you need to take to solve these games are these two different

103
00:08:02,080 --> 00:08:04,040
classes of games are very different than?

104
00:08:04,040 --> 00:08:09,160
They are exactly very, very different and one difference at an intuitive level is that

105
00:08:09,160 --> 00:08:14,240
in a complete perfect information game, which is also called a complete information game,

106
00:08:14,240 --> 00:08:19,440
you can actually solve a sub game over the game tree with information from that sub tree

107
00:08:19,440 --> 00:08:20,440
only.

108
00:08:20,440 --> 00:08:24,080
That is not true in imperfect information games.

109
00:08:24,080 --> 00:08:29,080
In perfect information games you have to balance your strategies across the different

110
00:08:29,080 --> 00:08:34,720
sub games and that ties the whole game together so it doesn't decompose.

111
00:08:34,720 --> 00:08:40,480
The idea being that you've got a given player only has access to private information, but

112
00:08:40,480 --> 00:08:45,120
there's some other broader set of information that the other player has that you can't

113
00:08:45,120 --> 00:08:47,320
use in solving the sub tree.

114
00:08:47,320 --> 00:08:48,320
Yes, that's right.

115
00:08:48,320 --> 00:08:52,960
And conversely there's information you have that the other player or players don't have.

116
00:08:52,960 --> 00:08:57,560
And so you've applied this with pretty great success to poker.

117
00:08:57,560 --> 00:09:03,120
Can you talk a little bit about the poker as a field of application for these types of

118
00:09:03,120 --> 00:09:07,920
approaches and what some of the past approaches have been to solving it?

119
00:09:07,920 --> 00:09:09,320
Yeah, happy to.

120
00:09:09,320 --> 00:09:12,360
So to me, poker is not really an application.

121
00:09:12,360 --> 00:09:18,480
To me, poker is the benchmark and in particular heads up no limit Texas Holden has become the

122
00:09:18,480 --> 00:09:25,160
leading benchmark in the AI community for testing these application independent algorithms

123
00:09:25,160 --> 00:09:27,960
for solving imperfect information games.

124
00:09:27,960 --> 00:09:28,960
Okay.

125
00:09:28,960 --> 00:09:32,320
And poker actually goes way back in the history of your game theory.

126
00:09:32,320 --> 00:09:39,360
So if you think about early pioneers like for Neumann, Morgan Stern, Nash and so on,

127
00:09:39,360 --> 00:09:45,160
they actually were working on poker as perhaps the lead application of game theory.

128
00:09:45,160 --> 00:09:49,480
And they were working on small, very small variants of poker that could be solved by hand

129
00:09:49,480 --> 00:09:51,480
like what's called corn poker.

130
00:09:51,480 --> 00:09:56,120
But now we're able to solve these much larger games where you have a full deck and you have

131
00:09:56,120 --> 00:09:59,680
the full complexity of let's say no limit Texas Holden.

132
00:09:59,680 --> 00:10:05,320
If I can interrupt briefly, one of the distinctions you make in the paper is that with is between

133
00:10:05,320 --> 00:10:11,120
limit Texas Holden and no limit Texas Holden and I am not a poker aficionado, but what

134
00:10:11,120 --> 00:10:17,800
you specifically call out that the former that limit Texas Holden has 10 to the 13 decision

135
00:10:17,800 --> 00:10:24,800
points, whereas no limit creates a much bigger game of 10 to 161 decision points.

136
00:10:24,800 --> 00:10:25,800
What does all that mean?

137
00:10:25,800 --> 00:10:30,200
And what's different about the games that makes them so different in terms of the number

138
00:10:30,200 --> 00:10:31,200
of possibilities?

139
00:10:31,200 --> 00:10:32,200
Yeah.

140
00:10:32,200 --> 00:10:33,200
That's right.

141
00:10:33,200 --> 00:10:34,200
Those numbers are exactly right.

142
00:10:34,200 --> 00:10:38,400
So we can talk about the size of the game based on the number of different situations

143
00:10:38,400 --> 00:10:40,640
that the player can face.

144
00:10:40,640 --> 00:10:46,920
And in limit, it's 10 to the 13 in no limit, it's 10 to the 161.

145
00:10:46,920 --> 00:10:51,800
So fundamentally different and what makes it different is that in limit Texas Holden,

146
00:10:51,800 --> 00:10:56,920
whenever it is your turn to bet or raise, there's only one size that you can make.

147
00:10:56,920 --> 00:11:01,080
So the branching factor in your actions is like two or three.

148
00:11:01,080 --> 00:11:07,360
In contrast, in no limit, you can bet any number of your chips up to all of your chips.

149
00:11:07,360 --> 00:11:10,560
So the branching factor is much larger.

150
00:11:10,560 --> 00:11:15,080
And so based on the different kind of sizes and scopes of these games with the smaller

151
00:11:15,080 --> 00:11:19,280
games, one way to solve it is to just solve the whole game.

152
00:11:19,280 --> 00:11:20,280
Is that right?

153
00:11:20,280 --> 00:11:21,480
Yes, that's exactly right.

154
00:11:21,480 --> 00:11:28,800
So like in 2005, my student Andrew Gilpin and I, we solved exactly in previous AI challenge

155
00:11:28,800 --> 00:11:31,640
problem called Rhode Island Holden.

156
00:11:31,640 --> 00:11:36,480
And that has 10 to the power of nine different situations.

157
00:11:36,480 --> 00:11:41,160
And we solved it as a whole using first technique called lossless abstraction.

158
00:11:41,160 --> 00:11:45,880
And then the remaining game, which was about 10 to the 7 or 10 to the 8, that we could

159
00:11:45,880 --> 00:11:47,960
solve holistically.

160
00:11:47,960 --> 00:11:53,400
And similarly, Michael Bowling's research group from Alberta, near optimally, solved

161
00:11:53,400 --> 00:11:59,920
the two player limit Texas Holden by first doing the lossless abstraction and then having

162
00:11:59,920 --> 00:12:05,480
a custom algorithm for holistically solving the whole game near optimally.

163
00:12:05,480 --> 00:12:09,440
And what does it mean to do abstraction as a solution for a game like this?

164
00:12:09,440 --> 00:12:16,200
Yeah, abstraction means that you are generating a smaller but strategically similar game.

165
00:12:16,200 --> 00:12:22,520
And then you are solving that smaller but similar game using a Nash equilibrium finding

166
00:12:22,520 --> 00:12:23,760
algorithm.

167
00:12:23,760 --> 00:12:27,560
And the first work on abstraction really in games was manual.

168
00:12:27,560 --> 00:12:33,920
So people did the abstraction phase manually and equilibrium finding phase computationally.

169
00:12:33,920 --> 00:12:37,920
And they started around really over 15 years ago.

170
00:12:37,920 --> 00:12:46,800
And nowadays for the last I would say 12 years or 13 years, both phases had been done computationally.

171
00:12:46,800 --> 00:12:52,640
So there are abstraction algorithms that will find just from the rules of the game, find

172
00:12:52,640 --> 00:12:59,000
a strategically similar but small enough game to solve or almost exactly solve using

173
00:12:59,000 --> 00:13:01,160
equilibrium finding algorithms.

174
00:13:01,160 --> 00:13:06,080
Is there a simple example of abstraction applied to poker that you can give?

175
00:13:06,080 --> 00:13:09,120
Yes, let me give you two kinds of examples.

176
00:13:09,120 --> 00:13:16,320
So one kind of example is information abstraction or abstracting the actions of chance.

177
00:13:16,320 --> 00:13:22,240
So I might say that in poker, you are dealt ace ace or you dealt king king.

178
00:13:22,240 --> 00:13:25,600
Those are different situations but they're really very similar.

179
00:13:25,600 --> 00:13:29,520
So I could say that, okay, I'm going to treat them as if they were the same.

180
00:13:29,520 --> 00:13:36,840
And the other form also known as action abstraction is abstracting out the players actions.

181
00:13:36,840 --> 00:13:42,520
So for example, I might say that if you bet 200 chips, it's almost the same as if you

182
00:13:42,520 --> 00:13:44,280
bet 201 chips.

183
00:13:44,280 --> 00:13:46,480
So I'm going to treat them as if they were the same.

184
00:13:46,480 --> 00:13:47,480
Okay.

185
00:13:47,480 --> 00:13:52,600
And so does that tend to manifest itself like some kind of binning or quantization type

186
00:13:52,600 --> 00:13:53,600
of approach?

187
00:13:53,600 --> 00:13:58,240
You could call it that but the abstraction techniques are really much more sophisticated

188
00:13:58,240 --> 00:13:59,840
than just clustering.

189
00:13:59,840 --> 00:14:03,120
You have to think about their downstream effects and all of that.

190
00:14:03,120 --> 00:14:08,600
So for example, if I have the ace of spades and ace of hearts and king of spades and king

191
00:14:08,600 --> 00:14:12,760
of hearts, those might seem very similar in the beginning.

192
00:14:12,760 --> 00:14:17,560
But depending on whether they end up in a flush later, they might look very different.

193
00:14:17,560 --> 00:14:21,880
I mean, depending on whether they end up in a flush or a straight and so on, well,

194
00:14:21,880 --> 00:14:26,040
the other hand that was original is similar might actually be very different later.

195
00:14:26,040 --> 00:14:32,760
And so the abstraction is, it sounds like a key piece in solving these types of games,

196
00:14:32,760 --> 00:14:36,160
but not something that scales for the very large games.

197
00:14:36,160 --> 00:14:41,880
No, I would say almost opposite is that for the very large games, you need to do some

198
00:14:41,880 --> 00:14:47,560
form of abstraction because you cannot holistically solve these very large games.

199
00:14:47,560 --> 00:14:51,800
So this information abstraction, we talked about an action abstraction and then there's

200
00:14:51,800 --> 00:14:57,080
also a third approach, which is what has traditionally been called phase-based abstraction,

201
00:14:57,080 --> 00:15:02,160
where you solve some head of the game and have some sort of approximation for the rest

202
00:15:02,160 --> 00:15:04,560
of it instead of solving the rest of it exactly.

203
00:15:04,560 --> 00:15:06,560
And then you keep doing it over and over.

204
00:15:06,560 --> 00:15:07,560
I got it.

205
00:15:07,560 --> 00:15:13,480
And so the approach that you describe in the paper that uses abstraction as a way, as

206
00:15:13,480 --> 00:15:17,280
kind of a framework for getting to the solution.

207
00:15:17,280 --> 00:15:22,960
It can, it can, although just to be clear, abstraction algorithms were not the contribution

208
00:15:22,960 --> 00:15:25,360
of this particular paper.

209
00:15:25,360 --> 00:15:32,840
Abstraction in perfect information game solving and poker goes way back at least to 2001,

210
00:15:32,840 --> 00:15:34,080
if not earlier.

211
00:15:34,080 --> 00:15:37,360
So the new contribution in this paper was a little different.

212
00:15:37,360 --> 00:15:42,240
So why don't you tell us a little bit about what this paper contributes to this broader

213
00:15:42,240 --> 00:15:46,200
problem and with the example application and poker?

214
00:15:46,200 --> 00:15:47,200
Say yeah.

215
00:15:47,200 --> 00:15:51,920
So all of these algorithms are game independent, so they're not specific to poker, but we have

216
00:15:51,920 --> 00:15:55,360
a lot of experiments in poker in the paper.

217
00:15:55,360 --> 00:16:01,600
So what the new techniques are in this paper, they are what we call safe and nested sub-game

218
00:16:01,600 --> 00:16:03,080
solving techniques.

219
00:16:03,080 --> 00:16:05,920
So let me try to unpack that a little bit here.

220
00:16:05,920 --> 00:16:14,640
So safe means that we can guarantee that as we refine our solution, so again, they start

221
00:16:14,640 --> 00:16:20,360
by computing a core solution or what we call a blueprint solution for the whole game and

222
00:16:20,360 --> 00:16:26,480
then you start refining your strategy to make it better in sub-games that you reach during

223
00:16:26,480 --> 00:16:27,480
play.

224
00:16:27,480 --> 00:16:32,120
So offline you compute the blueprint and then online when you're playing, you refine

225
00:16:32,120 --> 00:16:36,120
the strategy in those parts of the search space that you actually reach.

226
00:16:36,120 --> 00:16:41,880
And you can afford to do that because there's less game tree lift than in the whole game.

227
00:16:41,880 --> 00:16:47,240
And you can also afford to do it in a finer and finer model or finer and finer abstraction,

228
00:16:47,240 --> 00:16:49,480
the closer to the end of the game you are.

229
00:16:49,480 --> 00:16:54,880
But the problem is, as we talked about earlier in the podcast, in that these imperfect information

230
00:16:54,880 --> 00:16:59,320
games, the sub-games don't separate out, they don't decompose.

231
00:16:59,320 --> 00:17:04,400
So how I should play in this current sub-game depends on how I should play in other sub-games,

232
00:17:04,400 --> 00:17:07,040
so I can't really reason about them independently.

233
00:17:07,040 --> 00:17:12,200
And here what we're doing, we're taking the blueprint strategy that gives values for different

234
00:17:12,200 --> 00:17:16,640
alternatives that the opponent could have taken to get here.

235
00:17:16,640 --> 00:17:22,600
And we use that type of reasoning to enable sub-game solving that has guarantees.

236
00:17:22,600 --> 00:17:28,200
So it guarantees that the solution quality is no worse than that of the blueprint strategy.

237
00:17:28,200 --> 00:17:33,840
So even our worst case Nemesis couldn't take us for more than it could take the blueprint.

238
00:17:33,840 --> 00:17:40,440
And similarly, if the values from the blueprint are off by a little bit compared to what ideal

239
00:17:40,440 --> 00:17:45,480
play would give for different states, we can guarantee that the answers that come out

240
00:17:45,480 --> 00:17:51,600
of the end-game solver or sub-game solver also are off by only a little bit.

241
00:17:51,600 --> 00:17:56,400
So that's a safe part, then there are two other innovations in the paper.

242
00:17:56,400 --> 00:18:02,600
One is that we can do much better than prior safe end-game solving techniques by taking

243
00:18:02,600 --> 00:18:07,000
into account the fact that actually there's several techniques there to do so, but one

244
00:18:07,000 --> 00:18:12,800
of them I'd like to highlight here, which is what we call taking into account the gifts

245
00:18:12,800 --> 00:18:15,560
that the opponent has given us so far.

246
00:18:15,560 --> 00:18:20,600
So if the opponent has made a mistake in the game so far, we can afford to give back

247
00:18:20,600 --> 00:18:27,320
to the opponent as much payoff as the expected mistake cost our opponent so far.

248
00:18:27,320 --> 00:18:30,080
And you might say, why do we want to give anything back?

249
00:18:30,080 --> 00:18:35,440
Now that allows us to have a bigger space of safe strategies to optimize over and we can

250
00:18:35,440 --> 00:18:42,280
do better against other hands or other private information in general that the opponent might

251
00:18:42,280 --> 00:18:43,280
have.

252
00:18:43,280 --> 00:18:47,880
So that gives us more opportunity to worry about hands that the opponent is really actually

253
00:18:47,880 --> 00:18:53,520
likely to have and do even better against those hands when we can, for some unlikely hands

254
00:18:53,520 --> 00:18:58,360
that the opponent is going to have, which would have been mistakes to play into this situation,

255
00:18:58,360 --> 00:19:00,040
we can afford to give some money back.

256
00:19:00,040 --> 00:19:03,880
If I'm understanding this piece, it's a bit counterintuitive.

257
00:19:03,880 --> 00:19:08,040
Can you provide some intuition or example of how this plays out in a game?

258
00:19:08,040 --> 00:19:09,360
Yeah, absolutely.

259
00:19:09,360 --> 00:19:15,120
So if you're a poker player, you know that that 2-7 offsuit is the worst starting hand

260
00:19:15,120 --> 00:19:16,640
in Texas holder.

261
00:19:16,640 --> 00:19:18,680
And that should be folded right away.

262
00:19:18,680 --> 00:19:25,080
But let's say we get later into the game and there are 2-7s and a 2 on the board.

263
00:19:25,080 --> 00:19:29,280
Now if you're there with a 2-7, that's a great hand because you have a full house.

264
00:19:29,280 --> 00:19:33,400
But if I think about it, I don't know your cards, but I can pretty much figure out that

265
00:19:33,400 --> 00:19:38,200
you don't have the full house because if you had 2-7 in your hand, you would have already

266
00:19:38,200 --> 00:19:39,520
folded.

267
00:19:39,520 --> 00:19:44,360
So let's say at the mistake of getting to this current situation with 2-7 would have

268
00:19:44,360 --> 00:19:49,680
been $100 for you, then I can afford to give you $100 back just in case in that scenario

269
00:19:49,680 --> 00:19:51,640
where you have that full house.

270
00:19:51,640 --> 00:19:57,240
In other words, I have to not be as defensive against that 2-7 hand and because I don't

271
00:19:57,240 --> 00:20:02,520
have to be as defensive there, I can use the flexibility of balancing my strategies to

272
00:20:02,520 --> 00:20:06,880
play better against you, against other hands you are more likely to have, like for example

273
00:20:06,880 --> 00:20:09,000
a pair of aces or a pair of kings.

274
00:20:09,000 --> 00:20:10,000
Right.

275
00:20:10,000 --> 00:20:11,000
Got it.

276
00:20:11,000 --> 00:20:15,120
And then the final piece in this paper, final conceptual piece is this nested end game

277
00:20:15,120 --> 00:20:20,600
solving or nested sub-game solving where we are not just taking the traditional approach

278
00:20:20,600 --> 00:20:24,680
of solving the end game, a new and then playing it out.

279
00:20:24,680 --> 00:20:29,960
But we are actually resolving it over and over every time the opponent has made a move.

280
00:20:29,960 --> 00:20:35,040
So as we get closer and closer to the end of the game, we can actually add the opponent's

281
00:20:35,040 --> 00:20:40,080
moves into our model if the opponent has played actions that were not in our model in the

282
00:20:40,080 --> 00:20:41,240
first place.

283
00:20:41,240 --> 00:20:45,680
So that way we don't get confused as to what the opponent has exactly done and how much

284
00:20:45,680 --> 00:20:48,240
money is in the pot and so forth.

285
00:20:48,240 --> 00:20:52,200
And we can still do this in a way that is probably safe.

286
00:20:52,200 --> 00:20:57,520
And a lot of the paper is concerned with this formal guarantees.

287
00:20:57,520 --> 00:20:59,560
How does this method perform?

288
00:20:59,560 --> 00:21:01,920
Oh, it performs very well.

289
00:21:01,920 --> 00:21:06,920
So we actually reach superhuman level with this technique.

290
00:21:06,920 --> 00:21:12,840
And just to be clear, we reach superhuman level by playing our AI called Liberatus against

291
00:21:12,840 --> 00:21:18,360
four of the top 10 human players at Hedge-Up No Limit Texas Holden in January in this huge

292
00:21:18,360 --> 00:21:21,760
120,000-hand 20-day event.

293
00:21:21,760 --> 00:21:27,200
And we beat them with high statistical significance and by a big margin.

294
00:21:27,200 --> 00:21:32,880
And this end game solving technique was one of the three new algorithms that we had in

295
00:21:32,880 --> 00:21:36,080
the three different modules of Liberatus.

296
00:21:36,080 --> 00:21:37,080
Okay.

297
00:21:37,080 --> 00:21:43,600
And this algorithm, does the paper give someone what they would need to implement the algorithm?

298
00:21:43,600 --> 00:21:44,600
Yes.

299
00:21:44,600 --> 00:21:48,880
Well, actually, let me go back on your previous question also in addition to humans, we have

300
00:21:48,880 --> 00:21:55,240
shown that Liberatus beats the best prior AI, which was called Baby Targaryen 8, which

301
00:21:55,240 --> 00:21:59,160
won the annual computer poker competition in 2016.

302
00:21:59,160 --> 00:22:04,720
So Liberatus actually beats Baby Targaryen 8 by a huge margin of 63 millibig blinds per

303
00:22:04,720 --> 00:22:05,720
hand.

304
00:22:05,720 --> 00:22:10,240
So just to clarify, we're not just able to beat the best humans, we're also able to beat

305
00:22:10,240 --> 00:22:11,440
the best prior AI.

306
00:22:11,440 --> 00:22:12,440
Got it.

307
00:22:12,440 --> 00:22:14,040
And what was that unit 63?

308
00:22:14,040 --> 00:22:15,040
Yeah, good.

309
00:22:15,040 --> 00:22:16,040
Good question.

310
00:22:16,040 --> 00:22:18,840
63 millibig blinds per game.

311
00:22:18,840 --> 00:22:24,360
And that's a big blind is a measure of the size of the ante in poker.

312
00:22:24,360 --> 00:22:28,440
And millibig blind is 1,000th of that.

313
00:22:28,440 --> 00:22:32,760
And if you're a poker player and you don't like to use millibig blinds per game as we

314
00:22:32,760 --> 00:22:37,960
do in AI, it's called 6.3 big blinds per 100.

315
00:22:37,960 --> 00:22:40,680
That's just another way of saying the same thing.

316
00:22:40,680 --> 00:22:42,720
That's a big margin of victory.

317
00:22:42,720 --> 00:22:47,640
So typically when the AIs play each other in the annual computer poker competition, the

318
00:22:47,640 --> 00:22:53,000
top two AIs are separated maybe by 10 or 20 millibig blinds per hand.

319
00:22:53,000 --> 00:22:59,960
But Liberatus beats Baby Targaryen 8, which was the best prior AI by 63 millibig blinds

320
00:22:59,960 --> 00:23:00,960
per hand.

321
00:23:00,960 --> 00:23:07,240
And so you were about to describe how someone might go about implementing this for poker

322
00:23:07,240 --> 00:23:08,480
or another game.

323
00:23:08,480 --> 00:23:14,760
Yeah, so we do lay out the algorithms in the paper and we prove their safety.

324
00:23:14,760 --> 00:23:19,160
Of course these are fairly complex algorithms to be honest, especially if you run them on

325
00:23:19,160 --> 00:23:20,160
a super computer.

326
00:23:20,160 --> 00:23:24,920
So it's not that easy to implement, but we try to make it do our best to explain how

327
00:23:24,920 --> 00:23:25,920
they're done.

328
00:23:25,920 --> 00:23:29,880
And are they, is that the typical way that you'd run them on a super computer?

329
00:23:29,880 --> 00:23:31,360
Depends on the game.

330
00:23:31,360 --> 00:23:36,480
So most games you probably could run on a laptop, but when we get into these very large

331
00:23:36,480 --> 00:23:41,440
games, you can still run them on a laptop, but then you're not in doing as well as you

332
00:23:41,440 --> 00:23:43,680
would on a super computer.

333
00:23:43,680 --> 00:23:46,600
And for the competition, were you running them on a super computer?

334
00:23:46,600 --> 00:23:47,600
Yes, that's right.

335
00:23:47,600 --> 00:23:52,760
We were running on bridges, which is the newly super computer at the Pittsburgh Super

336
00:23:52,760 --> 00:23:54,240
Computing Center.

337
00:23:54,240 --> 00:23:55,240
Okay.

338
00:23:55,240 --> 00:23:57,960
And, you know, this is an evolving game with humans.

339
00:23:57,960 --> 00:24:03,360
So each of the moves was then input into the, you know, the super computer and it would

340
00:24:03,360 --> 00:24:09,760
run what's the typical response time between, you know, after entering the humans' latest

341
00:24:09,760 --> 00:24:13,840
move to getting back what the machines next move should be.

342
00:24:13,840 --> 00:24:19,080
Yeah, just to be clear, so the humans played through a browser-based UI.

343
00:24:19,080 --> 00:24:23,640
So there was no human actually entering the moves into the super computer, like there

344
00:24:23,640 --> 00:24:26,160
was with deep lose, a playing chess.

345
00:24:26,160 --> 00:24:27,320
So it goes quite quickly.

346
00:24:27,320 --> 00:24:32,840
The entry of data back and forth goes very quickly because it's all automated.

347
00:24:32,840 --> 00:24:37,360
And the thinking time, well, in the first two betting rounds, the AI doesn't think at

348
00:24:37,360 --> 00:24:38,360
all.

349
00:24:38,360 --> 00:24:40,320
It has pre-computed its strategy.

350
00:24:40,320 --> 00:24:44,480
And then when it, or as you say, typically, it doesn't think at all.

351
00:24:44,480 --> 00:24:50,080
And then it typically starts thinking on the first move of the third betting round.

352
00:24:50,080 --> 00:24:52,520
And that's where it thinks the longest.

353
00:24:52,520 --> 00:24:56,400
Overall, if you think about a game of heads up, no limit, Texas hold them.

354
00:24:56,400 --> 00:25:01,480
These top humans were playing on average at 20 seconds per game.

355
00:25:01,480 --> 00:25:04,080
So not per move, 20 seconds per game.

356
00:25:04,080 --> 00:25:05,760
And there's a big difference between the humans.

357
00:25:05,760 --> 00:25:10,280
Some of them may have been going at like 17 seconds, others may have taken 25 seconds

358
00:25:10,280 --> 00:25:14,240
by on average, but pretty much 20 or 21 seconds on average.

359
00:25:14,240 --> 00:25:18,320
Liberators played at 13 seconds per average, a per per game.

360
00:25:18,320 --> 00:25:23,280
So we were playing a little bit faster than the top humans, but by and large at the same

361
00:25:23,280 --> 00:25:24,680
speed on average.

362
00:25:24,680 --> 00:25:27,960
But it's interesting, the thinking pattern is very different.

363
00:25:27,960 --> 00:25:33,280
So humans think also on the first two betting rounds while we don't typically, or sometimes

364
00:25:33,280 --> 00:25:37,360
in certain situations, the AI will think there too, but typically not.

365
00:25:37,360 --> 00:25:42,760
And the funny part, in my opinion, is that humans typically think the longest when there's

366
00:25:42,760 --> 00:25:46,160
a lot of money in the pot, because that is a big decision.

367
00:25:46,160 --> 00:25:48,560
In contrast, the AI does the opposite.

368
00:25:48,560 --> 00:25:52,760
The AI thinks longer if there's less money in the pot, because that's when there is

369
00:25:52,760 --> 00:25:54,480
more game tree left.

370
00:25:54,480 --> 00:25:56,880
So there's more to be thinking about.

371
00:25:56,880 --> 00:26:00,760
So it can be quite frustrating for humans when they're used to playing other humans who

372
00:26:00,760 --> 00:26:05,520
think a lot on the big pots and go fast on the small pots when the AI does the opposite.

373
00:26:05,520 --> 00:26:08,560
It makes big decisions instantaneously almost.

374
00:26:08,560 --> 00:26:11,800
And then on the tiny decisions, it can take a long time to think.

375
00:26:11,800 --> 00:26:19,040
And so this is one of three modules that the Bratis used in this, this most recent match

376
00:26:19,040 --> 00:26:21,880
are the other two published, or are there plans to publish them?

377
00:26:21,880 --> 00:26:23,200
We have talked about them.

378
00:26:23,200 --> 00:26:28,920
So for example, in my keynote talk at the International Joint Conference on Artificial Intelligence,

379
00:26:28,920 --> 00:26:34,080
in August, I talked about all three modules, so you can find that on YouTube.

380
00:26:34,080 --> 00:26:36,880
And we are about to publish the whole thing.

381
00:26:36,880 --> 00:26:39,040
It's currently still under review.

382
00:26:39,040 --> 00:26:40,040
Okay.

383
00:26:40,040 --> 00:26:44,560
And going back to you mentioning this running on a super computer, what language or other

384
00:26:44,560 --> 00:26:45,880
tools does it use?

385
00:26:45,880 --> 00:26:49,520
Is it written in something like a Python or something totally different?

386
00:26:49,520 --> 00:26:51,200
Python would be a way too slow for this.

387
00:26:51,200 --> 00:26:52,760
So we wrote it in C++.

388
00:26:52,760 --> 00:26:53,760
Okay.

389
00:26:53,760 --> 00:26:59,080
And does it use like an MPI for interprocess communications or something like that?

390
00:26:59,080 --> 00:27:00,080
Okay.

391
00:27:00,080 --> 00:27:01,080
Interesting.

392
00:27:01,080 --> 00:27:02,080
Interesting.

393
00:27:02,080 --> 00:27:06,600
And do you are there any plans to publish source code for this and the other algorithms?

394
00:27:06,600 --> 00:27:08,000
No, not really.

395
00:27:08,000 --> 00:27:09,920
And it wouldn't be usually that helpful.

396
00:27:09,920 --> 00:27:12,960
The super computing codes, they're very, very complex.

397
00:27:12,960 --> 00:27:14,960
We don't really have any plans to do that.

398
00:27:14,960 --> 00:27:19,240
But with some other students in my lab, we're writing a game solving framework that's kind

399
00:27:19,240 --> 00:27:23,880
of easier to understand, wouldn't be as scalable as this.

400
00:27:23,880 --> 00:27:27,520
But we might open source something like that so people can use it for teaching.

401
00:27:27,520 --> 00:27:33,080
And like I use in my AI courses, when I teach AI, we do some amount of imperfect information

402
00:27:33,080 --> 00:27:35,680
game solving there as well for small games.

403
00:27:35,680 --> 00:27:39,800
And there we do provide source code so that the students can start from that.

404
00:27:39,800 --> 00:27:42,680
Yeah, I would think folks would be very interested in that.

405
00:27:42,680 --> 00:27:46,080
Where can folks learn more about your lab and your work?

406
00:27:46,080 --> 00:27:50,880
I would say at the best spot to start, would be my homepage.

407
00:27:50,880 --> 00:27:57,440
So www.cs.cmu.edu slash till the suned column.

408
00:27:57,440 --> 00:28:01,640
So S-A-N-D-H-O-L-M.

409
00:28:01,640 --> 00:28:08,440
And if you go into the section on equilibrium finding and abstraction in games on my homepage,

410
00:28:08,440 --> 00:28:11,000
that's where you can find our papers on this topic.

411
00:28:11,000 --> 00:28:15,240
But there's a section for all the different strands of research going on in my lab so you

412
00:28:15,240 --> 00:28:18,080
can find papers on all of the different topics.

413
00:28:18,080 --> 00:28:19,080
Awesome.

414
00:28:19,080 --> 00:28:23,160
Well, to all of us, thank you so much for taking some time to chat with us about your

415
00:28:23,160 --> 00:28:25,240
paper and congratulations on the award.

416
00:28:25,240 --> 00:28:26,240
My pleasure.

417
00:28:26,240 --> 00:28:27,240
Thank you very much.

418
00:28:27,240 --> 00:28:28,240
Thanks.

419
00:28:28,240 --> 00:28:35,200
Alright, everyone, that's our show for today.

420
00:28:35,200 --> 00:28:40,360
Thanks so much for listening and for your continued feedback and support.

421
00:28:40,360 --> 00:28:44,760
For more information on to all of us or any of the topics covered in this episode, head

422
00:28:44,760 --> 00:28:49,440
on over to twomolei.com slash talk slash 99.

423
00:28:49,440 --> 00:28:54,600
Of course, we'd be delighted to hear from you, either via comment on the show notes page

424
00:28:54,600 --> 00:29:01,240
or via Twitter directly to me at At Sam Charrington or to the show at At Twomolei.

425
00:29:01,240 --> 00:29:21,200
Thanks once again for listening and catch you next time.

