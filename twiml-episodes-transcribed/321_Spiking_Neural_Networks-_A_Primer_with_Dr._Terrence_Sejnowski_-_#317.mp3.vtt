WEBVTT

00:00.000 --> 00:13.400
Welcome to the Twomo AI Podcast.

00:13.400 --> 00:16.400
I'm your host Sam Charrington.

00:16.400 --> 00:24.360
Hey, what's up Twomo listeners?

00:24.360 --> 00:28.720
I've got a super busy few weeks ahead of me as I head back out on the road to close out

00:28.720 --> 00:31.640
the 2019 conference season.

00:31.640 --> 00:35.520
Next week I'll be at CUBEcon, hanging out with my Kubanot friends and getting caught

00:35.520 --> 00:40.280
up on how the open source Kuban80's project is evolving to support machine learning at

00:40.280 --> 00:41.880
scale.

00:41.880 --> 00:45.840
Then the week of December 2nd, I'll be turning my attention to machine learning and AI

00:45.840 --> 00:50.160
in the cloud at the AWS re-invent conference.

00:50.160 --> 00:54.040
In the following week, the week of the 9th, I'll be hanging out with the AI research

00:54.040 --> 00:56.880
community at NURRIPS.

00:56.880 --> 01:04.040
Definitely reach out if you'll be at any of these events I'd really love to meet you.

01:04.040 --> 01:09.880
Before we get to today's show, a quick plug for the TwomoCon AI Platforms video packages

01:09.880 --> 01:12.840
that we've currently got available for pre-order.

01:12.840 --> 01:17.080
If you're working in an organization where productivity, efficiency, or scale of your machine

01:17.080 --> 01:22.960
learning efforts matters, please hit the pause button and check out twomocon.com slash

01:22.960 --> 01:27.240
videos where you can take a look at what we've got on offer.

01:27.240 --> 01:31.840
While I could list a ton of reasons why you should get these for yourself or your team,

01:31.840 --> 01:36.120
instead I thought I'd share a few of my favorite attendee quotes.

01:36.120 --> 01:39.880
Very, very relevant for my day-to-day work.

01:39.880 --> 01:45.000
Practical information for those trying to scale AI in their organization.

01:45.000 --> 01:50.240
If you were to plot out quality versus density, this is up and to the right.

01:50.240 --> 01:54.400
More pricing goes away as soon as we get the videos posted, which is likely within

01:54.400 --> 01:55.400
a week.

01:55.400 --> 02:00.880
So don't miss this opportunity to get a great deal on this amazing resource and of course

02:00.880 --> 02:04.160
to support your favorite ML&AI podcast.

02:04.160 --> 02:09.960
Once again, visit twomocon.com slash videos for more information on individual and team

02:09.960 --> 02:10.960
pricing.

02:10.960 --> 02:14.160
All right, on to the show.

02:14.160 --> 02:20.400
All right, everyone, I am on the line with Terry Stenobsky.

02:20.400 --> 02:25.920
Terry is the Frances Crick Chair and Head of the Computational Neurobiology Lab at Salk

02:25.920 --> 02:32.480
Institute for Biological Studies, as well as he's on the faculty at UC San Diego.

02:32.480 --> 02:35.400
Terry, welcome to the Twomo AI podcast.

02:35.400 --> 02:37.040
Wonderful to be here.

02:37.040 --> 02:40.720
I'm really excited about jumping into our conversation.

02:40.720 --> 02:44.360
Why don't we start by having you share a little bit about your background.

02:44.360 --> 02:49.880
You are one of the founders of the field of computational neuroscience.

02:49.880 --> 02:51.720
How did that come to be?

02:51.720 --> 02:58.720
Yes, it is a combination of my training first in physics.

02:58.720 --> 03:06.000
My PhD is from Princeton University and then postdoctoral work afterwards at Harvard Department

03:06.000 --> 03:07.800
of Neurobiology.

03:07.800 --> 03:13.200
And it was at a time when neuroscience was really heavily dominated by empirical studies

03:13.200 --> 03:20.240
and it still is, but I felt that with my training in physics and developing models that this

03:20.240 --> 03:30.400
could be another part of enhanced neuroscience and help go from the biological substrate

03:30.400 --> 03:35.400
to a more computational perspective on the function of the neural circuits that we were

03:35.400 --> 03:36.400
trying to study.

03:36.400 --> 03:45.360
And so are you fundamentally trying to apply computation to better understand the neurons

03:45.360 --> 03:53.720
and how they operate within a biological context or to use neurological function as we understand

03:53.720 --> 03:56.520
it to improve computation?

03:56.520 --> 03:57.960
You know, it's really both.

03:57.960 --> 04:00.120
It's a two-way street.

04:00.120 --> 04:04.200
And Richard Feynman once said that how do you know whether you really understand something

04:04.200 --> 04:09.560
is when you can build it based on the principles that you've uncovered and it works and it has

04:09.560 --> 04:11.640
the same functionality.

04:11.640 --> 04:19.320
And so we've been trying to do that with building, you know, very detailed models of neurons,

04:19.320 --> 04:27.960
but also synapses, but also developing larger-scale, neural, spiking neural models, which help

04:27.960 --> 04:30.960
the experimental people interpret their data.

04:30.960 --> 04:39.880
And at the same time, because we have computational applications, we can use that to develop much

04:39.880 --> 04:46.160
more powerful systems for being able to do things like control robots, vision systems,

04:46.160 --> 04:49.800
and all of the recent advances that have been occurring in deep learning have basically

04:49.800 --> 04:52.560
come from that direction.

04:52.560 --> 04:53.560
Interesting.

04:53.560 --> 04:54.560
Interesting.

04:54.560 --> 05:01.760
A few chats about spiking neural nets on the show before, most recently, the podcast

05:01.760 --> 05:07.440
I did with Jeff Gellhar from Qualcomm and it came up in a very tangential ways.

05:07.440 --> 05:12.120
So this would be the first time that I've had an opportunity to really, really dig into

05:12.120 --> 05:13.120
the topic.

05:13.120 --> 05:20.760
My understanding of the general idea of spiking neural nets as it applies to machine learning

05:20.760 --> 05:29.240
is that in a lot of ways deep learning and artificial neural nets are inspired by biological

05:29.240 --> 05:36.840
systems, but one key difference is that biological systems exhibit the spiking behavior.

05:36.840 --> 05:43.880
And so the field of spiking neural nets is trying to come up with computational analogs

05:43.880 --> 05:51.840
for the spiking system that can do, that can act or perform like artificial, or that

05:51.840 --> 05:59.760
can perform as artificial neural nets and hopefully lead us to more performing and

05:59.760 --> 06:03.800
more efficient artificial neural net systems.

06:03.800 --> 06:10.840
Is that kind of a good, super high level synopsis of the general direction of research in

06:10.840 --> 06:11.840
this area?

06:11.840 --> 06:21.160
Yes, I think you've set up the issues, which really are based on efficiency.

06:21.160 --> 06:23.200
So let's just make a few comparisons.

06:23.200 --> 06:32.640
So your brain runs on about 20 watts of power, and that should be compared to the enormous

06:32.640 --> 06:36.360
amount of power right now that's going into deep learning in the cloud.

06:36.360 --> 06:41.800
There's an article in today's paper that it's increasing at a phenomenal rate.

06:41.800 --> 06:48.040
I mean, it's not just it's a lot, but it keeps growing and it's been an effort to create

06:48.040 --> 06:52.320
special purpose machine learning chips, which of course are more efficient.

06:52.320 --> 06:58.880
But it doesn't even come close to the efficiency that nature has achieved with regard to how

06:58.880 --> 07:04.640
the brain is able to accomplish all it does in real time with so little power.

07:04.640 --> 07:14.240
And the real secret turns out to be to use signaling, electrical signaling very sparingly.

07:14.240 --> 07:16.680
So it's very sparse.

07:16.680 --> 07:25.160
But they able to encode information in a way that is highly able to represent the information

07:25.160 --> 07:29.080
but also to compute with spikes.

07:29.080 --> 07:34.320
And with the spike, a spike is an all-in-one event.

07:34.320 --> 07:37.240
It's technically called an action potential.

07:37.240 --> 07:38.560
And we know a lot about it.

07:38.560 --> 07:44.920
We know the biophysical mechanisms underlying it last for about a millisecond.

07:44.920 --> 07:54.640
It travels down nerves at variable speed depending on the diameter of the axon, the nerve,

07:54.640 --> 07:56.400
bundle.

07:56.400 --> 07:59.960
And it's relatively slow by computer standards.

07:59.960 --> 08:05.440
So you have signaling within chips at something close to the speed of light.

08:05.440 --> 08:14.760
But if you look at a nerve, the typical speeds are on the order of meters per second.

08:14.760 --> 08:21.400
So you might say, gee, can't neurons do better?

08:21.400 --> 08:29.920
Well, in fact, one of the fastest nerves that's been studied is that the giant axon of

08:29.920 --> 08:37.400
the squid that's used for when the squid has to flee is an escape response.

08:37.400 --> 08:40.840
And this nerve is a millimeter in diameter.

08:40.840 --> 08:45.120
And in fact, when the anonymous looked at it, they mistook it for a blood vessel.

08:45.120 --> 08:56.000
But later, the neurophysiologist, Alan Hodgkin and Huxley, Hugh Huxley, were able to use

08:56.000 --> 09:00.120
this as a model system for understanding the mechanisms.

09:00.120 --> 09:04.280
And they wrote down a set of equations, how are the Hodgkin Huxley equations, which have

09:04.280 --> 09:09.480
served as the foundation for all of signaling, electrical signaling, many other types of

09:09.480 --> 09:14.000
channels and pathways that have been built on top of that.

09:14.000 --> 09:16.280
So that really was foundational.

09:16.280 --> 09:20.480
But now the question is, how do you compute with those spikes?

09:20.480 --> 09:25.000
And that's really an interesting problem.

09:25.000 --> 09:26.920
Let me jump in with a quick question.

09:26.920 --> 09:35.000
When we're talking about these spikes, are they fundamentally digital in nature, a spike

09:35.000 --> 09:37.520
occurred, or a spike didn't occur?

09:37.520 --> 09:43.680
Or are there other characteristics that may be important, at least biologically, such

09:43.680 --> 09:46.960
as the amplitude of the spike or the duration of the spike?

09:46.960 --> 09:50.920
Or I can imagine there might be others, some intensity.

09:50.920 --> 09:58.320
How do we characterize these spikes, and what do we think might be part of the information

09:58.320 --> 10:00.440
that's transmitted with them?

10:00.440 --> 10:01.440
Right.

10:01.440 --> 10:07.520
Well, all of the above, certainly, they're all or none, that's the characteristic of

10:07.520 --> 10:08.520
a spike.

10:08.520 --> 10:11.200
However, they come in many different sizes and shapes.

10:11.200 --> 10:16.600
In fact, the fast sodium spike I was talking about on the millisecond time scale has

10:16.600 --> 10:23.160
variable width, also a calcium spike, which is much broader, and in fact, your heart uses

10:23.160 --> 10:30.480
the calcium spike hundreds of milliseconds long in order to maintain a heartbeat.

10:30.480 --> 10:35.040
But the first approximation that you should think of it, yes, it is a digital signal.

10:35.040 --> 10:37.120
There's either a signal there or not.

10:37.120 --> 10:41.600
But it occurs at an analog time, because the spiking is asynchronous.

10:41.600 --> 10:45.320
There is no clock, master clock in the brain.

10:45.320 --> 10:50.120
There may be local synchronization that takes place in small circuits.

10:50.120 --> 10:54.680
But the idea, though, is that, and this is something that's actually a very powerful way

10:54.680 --> 11:01.040
to think about computing, which now that, for example, machine learning chips are being

11:01.040 --> 11:02.040
developed.

11:02.040 --> 11:07.320
There's 100 startup companies out there right now that are all vying for this big market

11:07.320 --> 11:10.320
that people see.

11:10.320 --> 11:17.640
And once you've gone to an asynchronous system, it just makes designing chips much more easy

11:17.640 --> 11:23.840
in a sense that you no longer have to have a signal that is transmitted all over the

11:23.840 --> 11:31.000
chip that allows you to get the transistor on and off.

11:31.000 --> 11:34.160
But there are other things, too, which are very important.

11:34.160 --> 11:39.240
It's not just the spike itself, but what happens to the spike when it reaches the synapse.

11:39.240 --> 11:45.840
And there, there's an even more complex dynamical system that controls the release of neurotransmitter.

11:45.840 --> 11:53.320
And depending on the rate of firing of these spikes and depending on the signaling to

11:53.320 --> 12:02.720
the postsynaptic cell, you have a very wide range of not just strengths, but temporal modulation

12:02.720 --> 12:05.320
of that signal.

12:05.320 --> 12:07.400
So, you know, you elaborate on that bit a bit?

12:07.400 --> 12:12.440
Yeah, okay, so, you know, in neural network models, we have learning algorithms, and the

12:12.440 --> 12:17.560
idea here is that these are slow changes in the weights and they're permanent, but that

12:17.560 --> 12:20.480
is to say they'll last for, you know, many days.

12:20.480 --> 12:26.360
But there are the short-term synaptic plasticity mechanisms that occur on less than a second

12:26.360 --> 12:27.520
scale.

12:27.520 --> 12:32.800
For example, if you have a burst of firing of a bunch of spikes at a high rate, then the

12:32.800 --> 12:38.480
strength of the synapse facilitates, you know, it could double in size, which means that

12:38.480 --> 12:45.880
a burst of spikes has actually has much more impact than an isolated spike or a same number

12:45.880 --> 12:48.800
of spikes that are spaced in time.

12:48.800 --> 12:58.840
And this is an example of a mechanism which is very important for timing and also for regulating

12:58.840 --> 13:05.840
the flow of information, which isn't incorporated right now in traditional neural network models

13:05.840 --> 13:11.840
that use graded activity rather than spiking activity.

13:11.840 --> 13:19.400
So just to try to capture that, it sounds like one first order difference between the way

13:19.400 --> 13:26.520
the biological systems work and the neural network, artificial neural networks are work

13:26.520 --> 13:34.080
is that in the latter, there's no notion of kind of this, even a dual time scale, kind

13:34.080 --> 13:42.160
of a short-term accumulation effect in changes to inputs versus kind of a long-term adjustment

13:42.160 --> 13:43.160
of weights.

13:43.160 --> 13:44.160
Right.

13:44.160 --> 13:49.480
Actually, Jeff Hinton has a paper, very old paper, probably going back more than 20 years,

13:49.480 --> 13:55.360
where he showed that the short-term changes actually could be helpful for networks that

13:55.360 --> 13:57.320
have dynamical outputs.

13:57.320 --> 14:05.440
By the way, there's another very important degree of freedom here that we, as we know,

14:05.440 --> 14:12.000
is used at various places in the brain, and I actually think it adds a computational,

14:12.000 --> 14:14.480
a very powerful computational dimension.

14:14.480 --> 14:18.600
So that has to do with the relative timing of spikes.

14:18.600 --> 14:24.440
So what's known, this is a mechanism for synaptic plasticity, which depends on spike timing.

14:24.440 --> 14:31.040
It's known that if the spike coming into a neuron occurs within a very brief 10 millisecond

14:31.040 --> 14:39.480
window before the output neuron spikes, pre-before post, and if that's repeated at 10 hertz or

14:39.480 --> 14:44.400
above, that that will increase the strength of the synapse, long-term potentiation.

14:44.400 --> 14:49.320
That means that it will increase in strength and will stay elevated for many hours.

14:49.320 --> 14:57.480
However, if you reverse the order of the two spikes so that the output neuron spikes

14:57.480 --> 15:05.600
before the synaptic input spikes, and you pair that at 10 hertz with a time window here

15:05.600 --> 15:11.400
from 10 to 50 milliseconds depending on the neuron, then that will decrease the strength

15:11.400 --> 15:14.640
of the synapse, and that's a long-term depression.

15:14.640 --> 15:21.640
So it means that the brain is able to use these relative times to regulate the neuron,

15:21.640 --> 15:29.400
the house of strength of a synapse is either increasing or decreasing it, and it can

15:29.400 --> 15:31.560
do that very, very rapidly.

15:31.560 --> 15:38.800
And if you think about it, having, there must be a discriminator sitting in the synapse

15:38.800 --> 15:44.880
that can, is literally able to tell the order of the pre-imposed synaptic activity within

15:44.880 --> 15:53.040
a few milliseconds, which is pretty good for biology, that's a very fast timescale.

15:53.040 --> 15:59.640
The conclusion that you just mentioned suggests that what we're talking about with these spikes

15:59.640 --> 16:06.880
and whether they're pre-imposed isn't kind of the result of, again, kind of some kind

16:06.880 --> 16:14.040
of internal accumulator, like some chemical thing where the spikes are coming in faster

16:14.040 --> 16:17.760
than they're going out, there's a build-up of something.

16:17.760 --> 16:24.560
It's more about the proximity of input and output timings relative to one another that

16:24.560 --> 16:33.600
isn't related to just thinking about the input and output of a bucket like a drain or something

16:33.600 --> 16:34.600
like that.

16:34.600 --> 16:42.040
Well, those are all good analogies, but the reality is that the synapse is a very complex

16:42.040 --> 16:49.800
biochemical machine that has components in small numbers, like there's, in the post-ynaptic

16:49.800 --> 16:56.680
site, for example, there's an area of very dense structure that shows up in the EM as it's

16:56.680 --> 17:02.360
kind of a black surface, the EM block with proteins, electron microscopy.

17:02.360 --> 17:08.680
This is a very high-resolution way of looking inside of cells, nanometer scale, and there's

17:08.680 --> 17:13.760
like 300 different proteins in that post-ynaptic density.

17:13.760 --> 17:22.040
They're all there to work, as you say, doing all of the functions that accumulating information,

17:22.040 --> 17:27.760
that's an integration step, but also keeping track of what's been happening over a longer

17:27.760 --> 17:35.520
time scale and through a downstream pathways can increase the size of the synapse through

17:35.520 --> 17:40.960
this potentiation mechanism that I was telling you about.

17:40.960 --> 17:48.040
People think of, in networks, as a weight, a single connection strength is one number,

17:48.040 --> 17:53.960
but the reality is, as I said, the synapse is a dynamical system with probably dozens

17:53.960 --> 18:00.240
of degrees of freedom, different timescales, and those are all there for a variety of reasons

18:00.240 --> 18:05.800
which have to do with being able to have what's called traces.

18:05.800 --> 18:09.080
You want to keep traces of something without permanently changing the strength.

18:09.080 --> 18:14.800
You want to keep track of things that have happened maybe over the last 10 minutes, and

18:14.800 --> 18:17.920
this actually comes up in reinforcement learning algorithms.

18:17.920 --> 18:22.600
This is Andy Bartow and Rich Sutton, developed a whole series of reinforcement algorithms

18:22.600 --> 18:29.560
that use trace conditioning, these mechanisms for keeping track of information within the

18:29.560 --> 18:33.320
synapse itself, so that you can make decisions later.

18:33.320 --> 18:42.680
Again, to kind of summarize thus far, there's work happening on the biological side to

18:42.680 --> 18:51.480
understand these neurons, and we've identified a whole set of phenomena, our characteristic

18:51.480 --> 19:01.200
of the way these systems work, including the timing of spikes and the duration of spikes

19:01.200 --> 19:09.280
and frequency of spikes, and we have some sense of how they translate into behavior within

19:09.280 --> 19:17.800
the biological system, and then there's this whole other set of work and activity to

19:17.800 --> 19:23.280
try to replicate that on the computational side, and I say, and then there's this not

19:23.280 --> 19:31.120
to artificially separate the two, but let's maybe talk a little bit about the state of

19:31.120 --> 19:38.880
the R and major research directions on that other side, the replication or modeling of

19:38.880 --> 19:42.520
the biological systems on the computational side.

19:42.520 --> 19:50.520
Well, this is an area that is very active right now, that has to say there's a number

19:50.520 --> 19:57.280
of groups around the world who have recognized that if we can build deep learning networks

19:57.280 --> 20:05.800
of spiking units rather than these graded ones, then not only would there be a tremendous

20:05.800 --> 20:14.280
energy savings, but now you could use these deep networks in edge devices like your watch

20:14.280 --> 20:22.600
or sensors directly at the point where the information is coming in, and that would

20:22.600 --> 20:26.640
allow a tremendous amount of compression to occur, and as much more efficient in terms

20:26.640 --> 20:33.000
of just how to get the bandwidth, reduce the bandwidth that you're going to need to get

20:33.000 --> 20:36.800
the information into the internet.

20:36.800 --> 20:43.440
So my own group, over the last few years, has put some effort into being able to do

20:43.440 --> 20:47.040
stochastic gradient descent, which is the algorithm that's used for most deep learning

20:47.040 --> 20:53.240
networks for being able to adjust the weights, but to do that with spiking units rather

20:53.240 --> 20:57.560
than graded units, and we've had some success.

20:57.560 --> 21:07.200
This is Ben Ha, who is a former graduate student of mine who's now working at IBM, but that

21:07.200 --> 21:14.640
looked very promising in a sense that we were able to generalize the algorithm so that

21:14.640 --> 21:17.000
it would be able to work near thresholds.

21:17.000 --> 21:21.440
See, the neurons have these very sharp thresholds where if you're below it, nothing happens,

21:21.440 --> 21:25.640
and as soon as you go above it, you get a spike, all in non-spike, but we showed that if

21:25.640 --> 21:33.000
you have a blurry region, a window in between those two states, that you could use it in

21:33.000 --> 21:36.800
an analog way in order to be able to compute gradients.

21:36.800 --> 21:38.320
So that was very exciting.

21:38.320 --> 21:41.440
To have that, it was a Neurip's paper a few years ago.

21:41.440 --> 21:48.600
If I can pause there with a few questions about that work, is that work, or even today,

21:48.600 --> 21:55.320
are we talking about a handful of, I guess I'm curious about the complexity of the

21:55.320 --> 22:01.000
systems that we're establishing, is this a couple of layers, a couple of neurons?

22:01.000 --> 22:06.000
Are we experimenting with deep systems?

22:06.000 --> 22:14.560
So that's kind of A, and then B, I'm assuming you're not doing this on new hardware by one

22:14.560 --> 22:22.000
of the hundred or so startups that's working in this area, but that you're using traditional

22:22.000 --> 22:31.240
clocked computing, are we talking about simulation-based experiments, or are you building custom

22:31.240 --> 22:38.640
hardware, or what's the kind of hardware at side of this?

22:38.640 --> 22:45.440
Right, well, my lab isn't a hardware lab, but we do collaborate with others, and the

22:45.440 --> 22:51.360
work I was talking about was all done with simulations with fully recurrent networks

22:51.360 --> 23:02.560
having sizes in the several hundred spiking units that were trained to do simple tasks.

23:02.560 --> 23:07.560
Simple in the sense that it's certainly not at the level of deep learning, but these

23:07.560 --> 23:13.400
are benchmark tasks that have been just to show that for one of the issues, and a very

23:13.400 --> 23:20.040
important one with recurrent network is whether you can take input and store it over some

23:20.040 --> 23:24.160
length of time, and then use that to make a decision when another input comes in, say

23:24.160 --> 23:31.800
a second or two later, and that's, we demonstrated that, so it's, it has a lot of the strengths

23:31.800 --> 23:38.680
of these recurrent neural networks that are used right now for language translation.

23:38.680 --> 23:44.440
Now that having been said, we still haven't scaled it up yet, in principle, it should

23:44.440 --> 23:48.920
be possible to have layers, multiple layers of these recurrent networks, but that's not

23:48.920 --> 23:54.360
something unfortunately been left before he could get to that point, but that's not

23:54.360 --> 23:55.920
the only approach.

23:55.920 --> 24:03.480
We have also recently with a graduate student taken another attack, and the idea here

24:03.480 --> 24:08.160
is that, hey, we already have ways of training up these recurrent networks with back propagation

24:08.160 --> 24:09.160
and time.

24:09.160 --> 24:16.640
Why not take one of them that already exists and convert it into a spiking network?

24:16.640 --> 24:19.400
And that's a difficult problem.

24:19.400 --> 24:25.880
Many people have tried to do this, and one typical approach was to say, okay, we'll just

24:25.880 --> 24:35.720
replace every graded unit with 100 spiking units, which then will have stochastic variability,

24:35.720 --> 24:43.320
but it will get the same message through with some degree of variability or noise.

24:43.320 --> 24:47.560
And yeah, if you have enough units, you can do that, but it's very, very expensive because

24:47.560 --> 24:51.440
you're just throwing away a tremendous number of units.

24:51.440 --> 25:00.760
So Robert Kim, who's a graduate student in my lab, came up with a really efficient and

25:00.760 --> 25:02.920
elegant solution to the problem.

25:02.920 --> 25:08.080
So here's what he did, and this is a paper that will be out very soon in the proceedings

25:08.080 --> 25:14.120
of the National Academy of Sciences, before you dive into the approach he took, I want

25:14.120 --> 25:22.440
to make sure that we understand the context so that we understand how important it is.

25:22.440 --> 25:29.360
This kind of assumption that for each of a traditional kind of artificial neuron, we

25:29.360 --> 25:32.960
would need hundreds of spiking units.

25:32.960 --> 25:37.960
Does that come from the idea, roughly, that if you've

25:37.960 --> 25:44.600
got a system that, let's say it's an eight-bit, it can handle eight-bit weights or inputs

25:44.600 --> 25:53.360
or is quantized in some way, and we need to represent that with a system that is essentially

25:53.360 --> 25:54.360
binary.

25:54.360 --> 26:01.600
We'll need many of those binary kind of spiking neurons or spiking units to achieve the

26:01.600 --> 26:08.720
same amount of information storage or flow as in the traditional graded neuron.

26:08.720 --> 26:15.480
Well, that would be a very direct digital solution, just to have each unit representing

26:15.480 --> 26:24.720
a different unit, to represent, for example, eight bits, you need eight units being on

26:24.720 --> 26:25.720
or off.

26:25.720 --> 26:30.520
But if you have spiking units that are asynchronous, you need a lot more because you're averaging

26:30.520 --> 26:36.200
over spikes, and you might need for eight bits, you may need, I'd have to calculate it,

26:36.200 --> 26:43.560
but something like maybe 25 or 50 in order to get, you reduce the noise by square to

26:43.560 --> 26:44.560
Venn.

26:44.560 --> 26:48.040
I'll elaborate on this a little bit more because there's a piece that I think is important

26:48.040 --> 26:55.640
here and not obvious, the averaging over spikes and that kind of driving this fan out

26:55.640 --> 26:57.240
and the number of spiking units.

26:57.240 --> 26:59.240
Why does that come about?

26:59.240 --> 27:06.720
Well, in fact, it's called a population code, and a lot of it was one of the early ideas

27:06.720 --> 27:12.680
in the neural modeling going back to Jack Cohen, which is that we have a lot of neurons,

27:12.680 --> 27:13.680
right?

27:13.680 --> 27:18.440
We have 100 billion, so you might think that you have a lot of units to spare, so it's

27:18.440 --> 27:19.440
redundancy.

27:19.440 --> 27:25.080
You can have the same signal being carried by 100 neurons.

27:25.080 --> 27:32.840
And then if you want to get an accurate estimate for an output, like for a motor neuron, then

27:32.840 --> 27:43.040
you just average over all those spikes, and one of the drawbacks of that approach is that

27:43.040 --> 27:50.600
if you look at how good the variance is, the variability in the estimate for the average,

27:50.600 --> 27:57.360
it goes down as 1 over n, and that means that if you want to reduce it by 10%, you've got

27:57.360 --> 27:59.120
to have 100 units.

27:59.120 --> 28:00.120
Got it.

28:00.120 --> 28:04.080
That's the problem that we're trying to overcome.

28:04.080 --> 28:10.320
By the way, I don't believe for a minute that the brain uses units so profilically.

28:10.320 --> 28:12.000
It just doesn't make any sense to me.

28:12.000 --> 28:16.560
It's just like throwing away tremendous amount of machinery.

28:16.560 --> 28:21.840
And so that's why Robert's solution to the problem, I think, is so elegant.

28:21.840 --> 28:29.520
What he showed was that you don't need to throw in a bunch of spiking units.

28:29.520 --> 28:36.480
You can get by with one spiking unit per one analog graded unit.

28:36.480 --> 28:42.040
But now here's the simple solution, which is that you have to decrease the strength of

28:42.040 --> 28:46.960
the weight, and typically by factor of 10.

28:46.960 --> 28:52.040
And what you find is that if you do this right and tune it up a little bit, you can get

28:52.040 --> 28:58.200
performance which is good, in some cases, a little better than the original network.

28:58.200 --> 29:05.760
And that is truly, from my perspective, it's revealing because it means that it is possible

29:05.760 --> 29:07.680
for the brain to compute with spikes.

29:07.680 --> 29:14.400
It can actually replace the very, the eight-bit kind of, and the throughput that it would

29:14.400 --> 29:16.560
need if you were just averaging.

29:16.560 --> 29:22.360
So in common deep learning, neural nets, you've mentioned gradient descent.

29:22.360 --> 29:29.160
You mentioned back prop, the core problem that we've overcome that allowed us to have

29:29.160 --> 29:35.400
the success we've seen with deep learning is this idea of diminishing and exploding

29:35.400 --> 29:46.000
gradients in these neural networks is do you get the same problem in when you've got networks

29:46.000 --> 29:50.360
of spiking units or is there an analogous kind of definitional problem that we need to

29:50.360 --> 29:51.360
figure out?

29:51.360 --> 29:52.360
Right.

29:52.360 --> 29:58.160
Well, you know, there have been mech ways to overcome the diminishing gradient.

29:58.160 --> 30:04.400
So we have various ways of being able to get the gradient using skip connections back

30:04.400 --> 30:11.600
down to the early layers and also by starting out with the right set of connections so that

30:11.600 --> 30:15.600
it has favorable properties for transmitting information back down.

30:15.600 --> 30:18.280
So we have the same things kind of work?

30:18.280 --> 30:22.800
We haven't done it yet, but that will certainly be our starting point too.

30:22.800 --> 30:25.400
We think that the same principles should apply.

30:25.400 --> 30:32.400
I think what we have already is a good indication that there's a great future ahead for spiking

30:32.400 --> 30:37.080
networks and this feeds into the hardware side, which is analog vealous eye chips that

30:37.080 --> 30:41.520
are now becoming very efficient.

30:41.520 --> 30:46.040
And there are many companies now that are beginning to explore this.

30:46.040 --> 30:51.440
You may know that Intel has a whole group which are neuromorphic engineering group that

30:51.440 --> 30:58.440
is built a chip that is of use of spiking units and also has implemented a lot of the

30:58.440 --> 31:03.520
other details I was telling you about, like short term plasticity, spiked time dependent

31:03.520 --> 31:04.880
plasticity.

31:04.880 --> 31:10.960
And so, you know, we have, we do have a platform now that we could take our simulations

31:10.960 --> 31:19.400
to and demonstrate that we get this great advantage in terms of energy and efficiency.

31:19.400 --> 31:28.520
And so, what would you say are the, is there a way to kind of characterize the major research

31:28.520 --> 31:35.200
problems or directions that folks are currently working on in the space?

31:35.200 --> 31:45.360
Right, I think that the, you know, the problem that we're facing now is architectural

31:45.360 --> 31:46.360
and systems.

31:46.360 --> 31:53.840
In other words, we can put together densely connect small, densely connected networks.

31:53.840 --> 32:00.680
And this is a problem that's faced by deep learning as well as the spiking version,

32:00.680 --> 32:07.240
which has to do with the fact that the biggest deep learning networks today have on the order

32:07.240 --> 32:13.360
of a billion weights, you know, thinking of as parameters, a billion parameters.

32:13.360 --> 32:20.200
Well, in a cubic millimeter of the cerebral cortex, which is what the deep learning emulates,

32:20.200 --> 32:25.240
in a single cubic millimeter, there's a billion synapses.

32:25.240 --> 32:36.800
And what that tells me is that the cortex has the capacity to create, you know, many thousands,

32:36.800 --> 32:40.160
maybe, you know, hundreds of thousands of deep learning networks.

32:40.160 --> 32:46.760
And now the question that hasn't yet been solved or confronted even is, how do you control

32:46.760 --> 32:50.960
the flow of information through a hundred thousand deep learning networks?

32:50.960 --> 32:51.960
Right, right.

32:51.960 --> 32:54.480
And that's a systems level problem.

32:54.480 --> 32:59.800
And, you know, that's a problem that nature solved a long time ago.

32:59.800 --> 33:03.720
And it's one that we're just beginning to come to grips with.

33:03.720 --> 33:11.040
Yeah, I mean, when you think about the kind of, you know, even the most basic kind of picture

33:11.040 --> 33:19.720
of neurons, you know, that you might, might see in a book or article for lay people, you

33:19.720 --> 33:25.840
know, it becomes clear that, or at least it, that system seems a lot less orderly than

33:25.840 --> 33:29.560
the things that we've put in place for deep learning, right?

33:29.560 --> 33:35.520
We've got these neurons that have many connections by directional.

33:35.520 --> 33:43.560
What do we know about the architecture of these neurons with regard to, I'm not articulating

33:43.560 --> 33:47.480
this question, but it feels like it, it feels like those systems are a lot more chaotic

33:47.480 --> 33:49.040
than the things that we're doing.

33:49.040 --> 33:54.560
And, you know, what kind of directions are, you know, do we think will allow us to build

33:54.560 --> 33:58.360
and manage systems with those many, that many degrees of freedom?

33:58.360 --> 33:59.920
Does that question make any sense?

33:59.920 --> 34:01.160
Yes, makes a lot of sense.

34:01.160 --> 34:08.840
In fact, you know, if you look at an electron microscopic image of the cortex, it looks

34:08.840 --> 34:09.920
like spaghetti.

34:09.920 --> 34:16.040
In other words, there's axons and dendrites and synapses all kind of mishmash together.

34:16.040 --> 34:22.440
But as we develop tools and techniques that allow us to dissect out the actual circuits,

34:22.440 --> 34:24.080
you know, the wiring.

34:24.080 --> 34:28.480
Also, not just local, but the long range connections.

34:28.480 --> 34:33.480
What we're discovering is that what looked like it was a mishmash is actually incredibly

34:33.480 --> 34:36.760
precisely put together.

34:36.760 --> 34:44.160
It's all done with molecular systems that are like lock and keys that allow one neuron

34:44.160 --> 34:46.960
to find another.

34:46.960 --> 34:52.640
And that can be over, you know, centimeters, you know, you have this little axon that's

34:52.640 --> 34:59.160
traveling over many centimeters and has to, it's like finding, it's, you know, going from

34:59.160 --> 35:05.160
San Diego and having a little string going up to L.A. and finding a particular address

35:05.160 --> 35:06.160
up in L.A.

35:06.160 --> 35:09.320
I mean, that, that's the level of precision with which the brain is put together.

35:09.320 --> 35:12.560
This is an incredible device we have.

35:12.560 --> 35:19.640
And we will know very soon, sometime next year, Clay Reed, who's at the Allen Institute

35:19.640 --> 35:22.480
for Brain Science, is going to,

35:22.480 --> 35:26.800
you know, announce a connectomic reconstruction.

35:26.800 --> 35:33.080
This is a tour de force because this is something that requires like a petabyte of data

35:33.080 --> 35:37.960
to be computationally stitched together.

35:37.960 --> 35:42.560
But he'll be able to have the entire wiring diagram for a cubic millimeter of cortex.

35:42.560 --> 35:47.160
And as I said before, this contains about a billion synapses and about a hundred thousand

35:47.160 --> 35:49.880
pieces of a hundred thousand neurons.

35:49.880 --> 35:56.080
So we're, you know, we're reaching at a point now where we will have real detailed ideas

35:56.080 --> 36:03.680
for what's the real complexity of these neural circuits.

36:03.680 --> 36:10.280
What makes it, you know, the brain, I think, powerful is that it's not, it's not the case

36:10.280 --> 36:14.920
like they are in deep learning networks where the units are more or less the same, you

36:14.920 --> 36:19.520
know, with different parameters, but more or less the same input output and so forth.

36:19.520 --> 36:25.240
But the, there's hundreds, in fact, thousands of different types of neurons, specialized

36:25.240 --> 36:26.240
neurons.

36:26.240 --> 36:32.680
There's just within inhibitory neurons, there's about 20 different types that have separate

36:32.680 --> 36:37.840
functions and are integrated into a circuit with a great precision.

36:37.840 --> 36:43.720
And so nature has had much more time to evolve and optimize the circuit for the particular

36:43.720 --> 36:45.320
function that it has.

36:45.320 --> 36:47.320
And that's different, different parts of the brain.

36:47.320 --> 36:53.240
The cortex has a different circuit from the, for example, another visual area called

36:53.240 --> 36:58.480
the superior colloculus, which is used in lower vertebrates for their visual system.

36:58.480 --> 37:02.720
And there are hundreds of brain areas, each of which has a different type of neuron and

37:02.720 --> 37:03.880
type of circuit.

37:03.880 --> 37:06.880
So this is a very highly evolved system.

37:06.880 --> 37:08.360
Right now we're at the very beginning.

37:08.360 --> 37:12.560
In fact, I think you could compare where we are now, you know, the deep learning networks

37:12.560 --> 37:17.200
where the right brothers were back in 1903 when they had their first flight, right?

37:17.200 --> 37:24.080
It was a proof of principle, but it was far, far away from where we end up today.

37:24.080 --> 37:29.360
There are a couple of papers that I wanted to make sure that we covered.

37:29.360 --> 37:35.080
One of those was, it's called a simple framework for constructing functional spiking RNNs.

37:35.080 --> 37:40.640
I feel like we talked about some of that stuff, but did we talk about this paper, the key

37:40.640 --> 37:41.640
results of this paper?

37:41.640 --> 37:43.360
Is this one of the ones that you mentioned?

37:43.360 --> 37:49.800
It's a foundational paper for this new method for replacing graded units with spiking units,

37:49.800 --> 37:59.360
but we went through a very millions and millions of simulations in order to pin down the robustness.

37:59.360 --> 38:05.960
I mean, how many networks, you know, when you put them together will work as advertised

38:05.960 --> 38:10.880
and it turns out to be a very high percentage, but also varying a lot of the parameters.

38:10.880 --> 38:14.000
And so this is something you do when you just get something, you know, you have to prove

38:14.000 --> 38:15.480
that it actually works.

38:15.480 --> 38:21.560
But now what we've done is to a paper that we're just preparing is to apply that to much

38:21.560 --> 38:28.120
more complex problems and also compare it to recordings from neurons in different parts

38:28.120 --> 38:29.520
of the cortex.

38:29.520 --> 38:34.440
And what we're finding is something that is happening not just in our lab, but many other places

38:34.440 --> 38:39.920
in the world like Jim DeCarlo at MIT is that when you train up one of these networks,

38:39.920 --> 38:43.760
either deep learning for the visual system or recurrent networks, which is what we're

38:43.760 --> 38:48.920
studying here, which is relevant for the prefrontal cortex, what you find is that the properties

38:48.920 --> 38:56.840
of the units in these networks are phenomenally similar, statistically similar to the recordings

38:56.840 --> 39:04.040
that are made from the brains of monkeys and other species that are solving specific

39:04.040 --> 39:11.160
problems, visual recognition problems or memory problems.

39:11.160 --> 39:15.920
So this is really exciting because it means that there's this is very close conversions

39:15.920 --> 39:22.520
that's occurring between neuroscience on one hand and machine learning and deep learning

39:22.520 --> 39:29.040
on the other hand, which I think is really going to be very, you know, the interaction

39:29.040 --> 39:37.040
the synergies, the fantastic opportunities that are opening up now for the first time in

39:37.040 --> 39:44.040
AI that are going to be sending, you know, information and talent back and forth.

39:44.040 --> 39:50.280
And this is, there's been a couple dozen AI and neuroscience meetings that I've been

39:50.280 --> 39:55.040
to a few of them, but there are many others, you know, I think that there's going to be

39:55.040 --> 40:00.640
a career path here for other people who have an interest in this convergence that's going

40:00.640 --> 40:01.960
on.

40:01.960 --> 40:10.320
And then you've got another couple of collaborations that are focused on this idea of the

40:10.320 --> 40:16.760
application of spiking neural networks to sensory motor control and kind of this, what

40:16.760 --> 40:19.200
you call a sweet spot.

40:19.200 --> 40:21.600
And I guess there's a tradeoff between speed and accuracy.

40:21.600 --> 40:23.360
Can you talk a little bit about that work?

40:23.360 --> 40:30.440
Yes, this is a collaboration with John Doyle, who's a control theorist at Caltech.

40:30.440 --> 40:40.000
And we're looking at the problem of how animals are able to be both fast and accurate, despite

40:40.000 --> 40:49.080
the fact that as I was saying earlier, axons are very limited either they're very fast

40:49.080 --> 40:54.920
but very inaccurate because they take up a lot of space and you can only pump so many spikes

40:54.920 --> 41:01.680
down them or if you have very thin axons like in the alfactory bulb where receptors coming

41:01.680 --> 41:05.680
in have very, very small caliber.

41:05.680 --> 41:10.320
So you have, but you have a hundred million of them and they're very, very, very slow.

41:10.320 --> 41:13.000
So they're very accurate but very, very, very slow.

41:13.000 --> 41:16.760
And the visual system itself, there's a time to leave about a hundred milliseconds.

41:16.760 --> 41:21.160
So you have these built-in limitations in the hardware.

41:21.160 --> 41:28.280
But how is it that you can, for example, mountain bike down a mountain side where you're getting

41:28.280 --> 41:34.000
jostled on a very fast timescale and you have to maintain your balance and at the same

41:34.000 --> 41:45.200
time, you have to navigate down a very winding and perhaps dangerous trail that, and you

41:45.200 --> 41:49.880
know, keep the plant, you have to plan ahead as well as respond to things that are happening.

41:49.880 --> 41:55.280
So in any case, we've developed a theoretical model that can accomplish that and we have

41:55.280 --> 41:56.280
a game.

41:56.280 --> 42:01.680
It's a driving game but it has a lot of the elements of mountain biking in terms of the fast

42:01.680 --> 42:07.240
timescales with jitter of the wheel and also planning ahead the path.

42:07.240 --> 42:13.640
And what we've uncovered in developing the model is something that we call the diversity

42:13.640 --> 42:16.160
enabled sweet spot.

42:16.160 --> 42:17.160
So what does that mean?

42:17.160 --> 42:20.240
First of all, diversity is something we're all familiar with.

42:20.240 --> 42:28.520
You have a very wide range of axon diameters that you see in the brain.

42:28.520 --> 42:36.680
And the question is, can you, if you have the right combination, can you incorporate

42:36.680 --> 42:42.760
them into a control model that takes into account two things, signaling right and speed

42:42.760 --> 42:44.480
and optimize that?

42:44.480 --> 42:46.960
And that's the speed accuracy trade-off.

42:46.960 --> 42:54.560
And what we showed is that once you set up that system, you can reproduce one of the most

42:54.560 --> 43:01.280
celebrated speed accuracy trade-offs in the motor control literature called, this is

43:01.280 --> 43:10.320
something that goes back, you know, 50 years, called FIT's law, if ITTS fits law.

43:10.320 --> 43:17.360
And it's a logarithmic law and it's very, very, a general trade-off between the accuracy

43:17.360 --> 43:19.160
and the speed.

43:19.160 --> 43:24.240
And we've shown now that mathematically and politically, we can achieve that with the

43:24.240 --> 43:28.040
kind of diversity of hardware that's seen in the brain.

43:28.040 --> 43:29.640
Now this is a general principle.

43:29.640 --> 43:36.240
In fact, these logarithmic laws that, like FIT's law, are found throughout sensory and

43:36.240 --> 43:37.240
motor systems.

43:37.240 --> 43:42.840
You know, this is a FECKNERS law and vision, for example, sensory systems.

43:42.840 --> 43:50.160
And we think that not just biology, but we think that a lot of engineered control systems

43:50.160 --> 43:52.560
can benefit from this principle.

43:52.560 --> 43:53.560
Interesting.

43:53.560 --> 43:54.560
Interesting.

43:54.560 --> 44:00.520
So this idea of a speed accuracy trade-off is something that's been well studied in

44:00.520 --> 44:08.440
biology and has resulted in a number of laws, like FIT's laws, that kind of govern the

44:08.440 --> 44:12.880
way we see this trade-off in biological systems.

44:12.880 --> 44:22.280
And you've been able to kind of recreate that using diversity as your control parameter,

44:22.280 --> 44:23.280
if you will.

44:23.280 --> 44:24.280
Exactly.

44:24.280 --> 44:25.280
Exactly.

44:25.280 --> 44:31.760
This optimizing, the sweet spot, is optimizing those two different constraints.

44:31.760 --> 44:35.880
One of the constraints has to do with speed and the other one with accuracy, you know,

44:35.880 --> 44:39.520
the signaling, the accuracy.

44:39.520 --> 44:44.040
And, and by the way, one of the, for me, one of the satisfying parts was that this was

44:44.040 --> 44:49.200
a marriage of two important parts in engineering that are separate from each other.

44:49.200 --> 44:52.680
One of them is control theory, which is all about time delays.

44:52.680 --> 44:58.800
Very rarely do they worry about the signaling pathways because they're using digital logic

44:58.800 --> 45:00.040
and so forth.

45:00.040 --> 45:04.720
And then on the other hand, there's information theory, which is all about information and

45:04.720 --> 45:08.320
how much information you can get through a channel.

45:08.320 --> 45:09.600
But they never worry about time delay.

45:09.600 --> 45:10.600
This is not interesting.

45:10.600 --> 45:15.880
So you have to do extremes and we put the two together and we find this beautiful sweet

45:15.880 --> 45:16.880
spot.

45:16.880 --> 45:17.880
Awesome.

45:17.880 --> 45:18.880
Awesome.

45:18.880 --> 45:23.200
So before we go, one of the things that you mentioned, as we were chatting before we

45:23.200 --> 45:29.800
started the interview was that you are one of the founders of what sounds like a really

45:29.800 --> 45:33.600
interesting workshop focused on neuromorphic engineering.

45:33.600 --> 45:39.320
Can you talk a little bit about the field and the workshop and what you're up to there?

45:39.320 --> 45:40.640
Right.

45:40.640 --> 45:49.440
So I was a visiting professor at Caltech back in the 80s or actually it was a fair trial

45:49.440 --> 45:53.040
this thing was scholar and was actually in the 90s, early 90s.

45:53.040 --> 45:57.880
And I used to go to a Carver Meads lab meetings and I was fascinated.

45:57.880 --> 46:05.840
This is an error when he created the first, you know, vision chip that was able to replicate

46:05.840 --> 46:10.440
some of the things that happened in the retina with asynchronous spiking coming out.

46:10.440 --> 46:14.600
And a cochlear chip for auditory processing.

46:14.600 --> 46:20.560
And this turned out to be a kind of a seed.

46:20.560 --> 46:27.680
He published a book around that era on analog VLSI neural systems, which really started

46:27.680 --> 46:33.160
a whole new branch of analog VLSI design.

46:33.160 --> 46:37.560
And that his students went off to the four corners of the world, but wanted to continue

46:37.560 --> 46:43.000
meeting. So I helped organize an NSF sponsored workshop at Telluride.

46:43.000 --> 46:49.200
It has been meeting for the last 25 years during the first three weeks of July.

46:49.200 --> 46:50.680
And it's a real workshop.

46:50.680 --> 46:56.560
People go there, they bring equipment, they bring robots, they bring all sorts of devices

46:56.560 --> 46:58.960
and oscilloscopes and so forth.

46:58.960 --> 47:00.480
And they work on projects.

47:00.480 --> 47:05.200
We have about 50 students and about 50 faculty who give lectures.

47:05.200 --> 47:08.960
And it's just a wonderful atmosphere because if you've been to Telluride, you're up there

47:08.960 --> 47:14.960
in the mountains and you're kind of it's isolated, but it's a beautiful place outdoors

47:14.960 --> 47:15.960
in the summer.

47:15.960 --> 47:18.280
Now I know where your mountain biking references are coming from.

47:18.280 --> 47:19.280
Yes.

47:19.280 --> 47:25.200
Well, we do a lot of, I don't do personally a lot of biking, but I do a lot of hiking.

47:25.200 --> 47:29.920
But the spirit there is very intense and the students are basically there.

47:29.920 --> 47:33.760
They're not just learning, they're collaborating, they're creating new projects, they take

47:33.760 --> 47:39.160
them home with them, and it's created an international community, which I think is very vibrant

47:39.160 --> 47:43.520
and very, very exciting right now because it's become clear that Moore's law has come

47:43.520 --> 47:49.680
to an end in terms of how being able to reduce the line widths any further is already reaching

47:49.680 --> 47:56.480
the point where you have leakage and so forth that is becoming an energy problem.

47:56.480 --> 48:04.880
But this is having these chips which are incredibly power efficient because you're working not

48:04.880 --> 48:11.280
at saturation, but right at the beginning of the non-linear activation and you're dealing

48:11.280 --> 48:22.400
with microwatts rather than watts to be able to do a decision down at the level of a spike.

48:22.400 --> 48:27.000
So this is really, I think, ultimately this is going to be the technology that's going

48:27.000 --> 48:32.840
to be out there in robots someday because as you know, robots are also have to worry about

48:32.840 --> 48:33.840
power.

48:33.840 --> 48:40.120
They can't take a super computer around with them if you want them to perform properly.

48:40.120 --> 48:41.120
Awesome.

48:41.120 --> 48:46.920
Well, we will include a link to that workshop as well as the papers that we've discussed

48:46.920 --> 48:48.920
here in our show notes.

48:48.920 --> 48:53.720
Terri, thanks so much for taking the time to chat really, really interesting conversation.

48:53.720 --> 49:00.520
Well, thank you very much, I really enjoyed it.

49:00.520 --> 49:07.640
All right everyone, that's our show for today to learn more about this episode visit Twomolaii.com.

49:07.640 --> 49:12.560
Once again, if you missed Twomolcan or want to share what you learned with your team, be

49:12.560 --> 49:19.800
sure to visit twomolcan.com slash videos for more information about our video packages.

49:19.800 --> 49:46.560
As always, thanks so much for listening and catch you next time.

