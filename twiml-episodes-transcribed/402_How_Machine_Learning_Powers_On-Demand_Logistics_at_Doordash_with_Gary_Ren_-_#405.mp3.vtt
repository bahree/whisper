WEBVTT

00:00.000 --> 00:09.240
All right, everyone, I am on the line with Gary Ren.

00:09.240 --> 00:12.400
Gary is a machine learning engineer at DoorDash.

00:12.400 --> 00:15.160
Gary, welcome to the Twomla AI podcast.

00:15.160 --> 00:15.880
Hey, Sam.

00:15.880 --> 00:16.800
Thanks for having me.

00:16.800 --> 00:20.640
I'm glad to get a chance to speak with you.

00:20.640 --> 00:23.600
Yeah, imagine DoorDash is having a bit of a moment.

00:23.600 --> 00:27.440
Nowadays, you've been pretty, things been pretty crazy there.

00:27.440 --> 00:33.000
Yeah, there's definitely been an unprecedented need for our services lately.

00:33.000 --> 00:35.880
And yeah, we've definitely done, we're definitely doing our best

00:35.880 --> 00:40.160
to make sure that we're available for our consumers, for our merchants and our dashers.

00:40.160 --> 00:41.160
Awesome, awesome.

00:41.160 --> 00:47.040
Well, why don't we start by, as we typically do here on the show,

00:47.040 --> 00:49.200
having you share a little bit about your background

00:49.200 --> 00:52.280
and how you came to work in machine learning?

00:52.280 --> 00:52.960
Cool.

00:52.960 --> 00:55.760
Yeah, so I don't have any kind of super inspirational story

00:55.760 --> 00:58.200
about how I got into machine learning.

00:58.200 --> 01:03.000
But I will say that I first found out about machine learning when I was in college.

01:03.000 --> 01:07.040
I was immediately super interested because it seemed to combine computer science,

01:07.040 --> 01:10.160
which is what I was studying at the time, with math,

01:10.160 --> 01:12.880
which is a subject that I've always enjoyed.

01:12.880 --> 01:17.200
So after college, I joined the Microsoft being search relevance team.

01:17.200 --> 01:20.480
And while I was there, I got some really good hands-on experience

01:20.480 --> 01:23.800
applying machine learning and especially deep learning

01:23.800 --> 01:29.360
to search ranking and different natural language processing type of problems.

01:29.360 --> 01:32.160
And then I joined DoorDouch about two years ago.

01:32.160 --> 01:36.000
And since then, I've worked on a completely different set of problems,

01:36.000 --> 01:38.360
focusing on problems with logistics.

01:38.360 --> 01:41.160
And yeah, even though from my work experience,

01:41.160 --> 01:46.600
I haven't really used that much math for machine learning like I initially expected.

01:46.600 --> 01:50.640
All these different ML packages kind of take care of the math for you.

01:50.640 --> 01:54.480
But it's still been super cool to see how with some lines of code

01:54.480 --> 01:56.360
and some math in the background,

01:56.360 --> 02:02.320
you can create these models that can do everything from predict what users are searching for,

02:02.320 --> 02:06.160
to predict how long it will take for you to be delivered.

02:06.160 --> 02:09.400
So yeah, I'm fortunate enough to work on a range of machine learning problems.

02:09.400 --> 02:11.080
And yeah, I've really enjoyed it.

02:11.080 --> 02:11.760
Cool, cool.

02:11.760 --> 02:15.000
How long were you at Microsoft before DoorDouch?

02:15.000 --> 02:18.160
Yeah, I've brought two and a half years.

02:18.160 --> 02:23.920
It's interesting, I talked to a lot of folks at Microsoft and beyond.

02:23.920 --> 02:26.880
But Microsoft in particular,

02:26.880 --> 02:31.520
there's a ton of talented people that kind of got their start working on Bing.

02:31.520 --> 02:36.040
And I think we like to beat up on Bing's search engine.

02:36.040 --> 02:39.360
But the folks that were working on that team

02:39.360 --> 02:42.880
are doing pretty incredible things all over the place.

02:42.880 --> 02:46.320
Yeah, I definitely learn a lot from my time there at Bing.

02:46.320 --> 02:49.400
And there are tons of smart people working there as well.

02:49.400 --> 02:51.200
So it was a great experience for me.

02:51.200 --> 02:52.680
Awesome, awesome.

02:52.680 --> 03:00.880
And so I think we'll be following along a general kind of general discussion

03:00.880 --> 03:05.360
that you led at the recent Nvidia GTC conference

03:05.360 --> 03:11.920
talking about how machine learning powers on demand logistics at DoorDouch.

03:11.920 --> 03:17.640
But before we dig into the specifics of the logistics applications there,

03:17.640 --> 03:25.400
maybe tell us a little bit about the kind of the general landscape for ML at the company.

03:25.400 --> 03:30.120
Yeah, so I think to better understand how we're using machine learning at DoorDouch,

03:30.120 --> 03:33.360
it's best to start by first understanding our business,

03:33.360 --> 03:36.000
which consists of a three-sided marketplace.

03:36.000 --> 03:40.600
So this includes consumers, merchants and dashers.

03:40.600 --> 03:44.760
And each of these sites, they use DoorDouch for a different reason.

03:44.760 --> 03:49.560
For example, consumers want the convenience of being able to stay at home

03:49.560 --> 03:52.440
while still having access to all their favorite merchants.

03:52.440 --> 03:55.720
Dashers want flexible work opportunities.

03:55.720 --> 03:59.920
And merchants want to increase the reach and revenue of their business.

03:59.920 --> 04:03.200
And dashers are the folks that are delivering the food?

04:03.200 --> 04:04.040
Yep, sorry to clarify.

04:04.040 --> 04:06.520
So dashers are the drivers who deliver the food, correct?

04:06.520 --> 04:07.800
Got it, got it.

04:07.800 --> 04:08.720
OK.

04:08.720 --> 04:12.560
And so, yeah, so this three-sided marketplace leads to many interesting problems

04:12.560 --> 04:14.560
that machine learning is applied to.

04:14.560 --> 04:17.360
So for example, between consumers and merchants,

04:17.360 --> 04:21.040
there's a lot of your traditional e-commerce type of problems.

04:21.040 --> 04:25.520
For example, recommendations, search ranking,

04:25.520 --> 04:28.880
those are some things that are pretty standard in e-commerce.

04:28.880 --> 04:31.200
And those are problems that we have as well.

04:31.200 --> 04:33.760
And then between consumers and dashers,

04:33.760 --> 04:37.320
there's a lot of problems around balancing supply and demand.

04:37.320 --> 04:40.280
How do we make sure that we have enough dashers supply

04:40.280 --> 04:42.080
to meet the consumer demand?

04:42.080 --> 04:43.360
And some of the ways that we do that

04:43.360 --> 04:46.520
is by forecasting demand, forecasting supply.

04:46.520 --> 04:51.280
And there is leverage such as dynamic pricing to try and balance it too.

04:51.280 --> 04:53.480
And then between dashers and merchants,

04:53.480 --> 04:57.600
there's a lot of your traditional dispatch type of problems,

04:57.600 --> 05:00.080
such as the core Simon algorithm, which

05:00.080 --> 05:03.960
is how we find the optimal matching between dashers and deliveries.

05:03.960 --> 05:05.960
And so each of these three sides as well,

05:05.960 --> 05:08.560
they also individually have their own interesting problems

05:08.560 --> 05:10.480
that we can apply machine learning to.

05:10.480 --> 05:13.160
For example, for merchants, one challenge of problem

05:13.160 --> 05:15.680
is how do we predict how long it would take merchants

05:15.680 --> 05:17.680
to prepare the food?

05:17.680 --> 05:20.520
If it's a patai, if it's a pizza, if it's just ice cream,

05:20.520 --> 05:21.840
that's ready to go.

05:21.840 --> 05:24.480
How do we actually predict this as the merchant?

05:24.480 --> 05:26.080
Yeah, so we do ask them.

05:26.080 --> 05:27.520
But merchants, a lot of times, you know,

05:27.520 --> 05:29.800
it's very hectic, very busy in the kitchen.

05:29.800 --> 05:33.720
And they're not able to provide an accurate estimate either.

05:33.720 --> 05:36.360
And so it's super important.

05:36.360 --> 05:40.000
I think about one of my favorite restaurants here in town.

05:40.000 --> 05:41.800
It's a Jamaican restaurant.

05:41.800 --> 05:44.680
And they are particularly notorious for,

05:44.680 --> 05:45.960
oh, it'll take an hour.

05:45.960 --> 05:47.160
You get there.

05:47.160 --> 05:50.640
And you're waiting, you know, another hour, you know,

05:50.640 --> 05:52.760
for the food.

05:52.760 --> 05:54.400
So I need to apply machine learning to that

05:54.400 --> 05:55.680
is what I'm hearing.

05:55.680 --> 05:57.960
Yeah, and that's exactly what we do.

05:57.960 --> 06:01.200
We're definitely taking input from the merchants.

06:01.200 --> 06:03.160
And we also use our own historical data

06:03.160 --> 06:05.200
to try and augment that and come

06:05.200 --> 06:07.720
of the most accurate predictions possible.

06:07.720 --> 06:08.720
Mm-hmm.

06:08.720 --> 06:10.200
Cool.

06:10.200 --> 06:15.680
So the particular application that you presented on

06:15.680 --> 06:17.560
was on-demand logistics.

06:17.560 --> 06:19.760
Is this one that you personally work on,

06:19.760 --> 06:25.120
or is this just one of the many applications at DoorDash?

06:25.120 --> 06:27.320
Yeah, so this is one that I personally work on.

06:27.320 --> 06:29.800
So I work on the logistics team.

06:29.800 --> 06:31.920
And so logistics.

06:31.920 --> 06:33.480
Yeah, the way I'll explain it is,

06:33.480 --> 06:36.280
it's kind of the core engine that powers

06:36.280 --> 06:39.560
the fulfillment of deliveries on DoorDash.

06:39.560 --> 06:42.360
And so logistics includes many of the problems

06:42.360 --> 06:46.040
I mentioned before, such as balancing dashed supply

06:46.040 --> 06:50.200
and consumer demand, as well as the core assignment problem,

06:50.200 --> 06:52.680
which again is how we often find the matching

06:52.680 --> 06:54.520
between dashes and deliveries.

06:54.520 --> 06:56.520
Mm-hmm.

06:56.520 --> 07:00.440
And so kind of walk us through how

07:00.440 --> 07:03.440
to approach those kinds of problems.

07:03.440 --> 07:04.400
Mm-hmm.

07:04.400 --> 07:06.160
Yeah, so I'll say, I'll start by saying

07:06.160 --> 07:09.840
that the high-level goal of the logistics engine

07:09.840 --> 07:14.800
is to make sure that we have fast and efficient deliveries.

07:14.800 --> 07:17.520
And so what this means is that obviously consumers

07:17.520 --> 07:20.800
will hate it if their order takes a long time to be delivered.

07:20.800 --> 07:23.640
And so we want our deliveries to be as fast as possible.

07:23.640 --> 07:25.480
But at the same time, we want our marketplace

07:25.480 --> 07:29.000
to be operating as efficiently as possible, as well.

07:29.000 --> 07:33.560
And so the way that we do that is in a few different stages.

07:33.560 --> 07:36.320
So first is setting up the marketplace

07:36.320 --> 07:38.840
by balancing supply and demand.

07:38.840 --> 07:43.080
So you can imagine that if we have 100 deliveries

07:43.080 --> 07:45.720
but only 10 dashers, then no matter what

07:45.720 --> 07:48.440
else we do in the rest of our logistics system,

07:48.440 --> 07:50.280
we're now going to have fast deliveries.

07:50.280 --> 07:51.680
Because there's 100 deliveries out there

07:51.680 --> 07:54.280
and only 10 dashes available to fulfill them.

07:54.280 --> 07:57.760
And vice versa, if we have 100 dashers,

07:57.760 --> 08:00.880
the only 10 deliveries, then a lot of these dashers

08:00.880 --> 08:02.120
will be sitting around idle.

08:02.120 --> 08:05.360
And it won't be a very efficient use of their time.

08:05.360 --> 08:07.120
So balancing supply and demand and setting up

08:07.120 --> 08:10.360
the marketplace for success is kind of first step

08:10.360 --> 08:12.800
in our logistics system.

08:12.800 --> 08:15.800
The second step would be route planning.

08:15.800 --> 08:19.760
So once you have these dashers and once you have these deliveries,

08:19.760 --> 08:21.280
it's super important for us to plan out

08:21.280 --> 08:25.520
the optimal routes for each of these dashers and deliveries.

08:25.520 --> 08:28.800
And so you can imagine that there's thousands of thousands

08:28.800 --> 08:32.720
routes that we need to account for in real time.

08:32.720 --> 08:36.560
For example, between the dasher and the merchant

08:36.560 --> 08:39.040
and between the merchant and consumer.

08:39.040 --> 08:41.520
And so with the plan for all these routes in real time,

08:41.520 --> 08:45.560
and once these are ready, they all get fed into the final stage,

08:45.560 --> 08:48.360
which is where the optimal matching happens.

08:48.360 --> 08:51.520
So once we have all these deliveries, all these dashers,

08:51.520 --> 08:54.960
and all these data about these deliveries and dashers,

08:54.960 --> 08:56.720
how do we find the optimal matching

08:56.720 --> 08:59.480
between dashers and deliveries in order

08:59.480 --> 09:02.760
to have the fastest deliveries possible

09:02.760 --> 09:05.400
while having an efficient marketplace?

09:05.400 --> 09:07.160
And so yeah, those are good.

09:07.160 --> 09:09.200
I was just going to say a couple of questions jump out of me.

09:09.200 --> 09:12.480
One is you've referred a couple of times

09:12.480 --> 09:15.720
to a logistics engine or a logistics system.

09:15.720 --> 09:19.640
Is this kind of a single piece of technology

09:19.640 --> 09:21.920
or a single literally a single system,

09:21.920 --> 09:25.240
or is it a suite of different applications

09:25.240 --> 09:29.640
that are used to perform all these different tasks?

09:29.640 --> 09:32.200
Yeah, so it's a suite of different applications.

09:32.200 --> 09:34.760
So we have multiple systems that kind of take care

09:34.760 --> 09:37.360
of each of these individual components I mentioned.

09:37.360 --> 09:39.720
So we have one system that takes care of balance

09:39.720 --> 09:43.440
and supply demand, another that takes care of route planning,

09:43.440 --> 09:47.280
and another that takes care of the actual matching itself.

09:47.280 --> 09:52.280
And the way you described it happening in series,

09:54.840 --> 09:56.720
I'm envisioning something that,

09:56.720 --> 10:01.720
or well, the question is are you doing the balancing

10:02.760 --> 10:07.760
and matching and all this in batches, hourly or something?

10:08.040 --> 10:09.680
That doesn't seem like it would work, right?

10:09.680 --> 10:12.440
Or is there a way that you're doing it real time

10:12.440 --> 10:14.720
or what's the granularity that you're making

10:14.720 --> 10:16.120
these kinds of decisions?

10:16.120 --> 10:18.080
Yeah, that's a good question.

10:18.080 --> 10:21.040
So I'll start by talking about how we do the balancing

10:21.040 --> 10:22.120
for supply and demand.

10:23.080 --> 10:27.720
So for this, we actually do it over a pretty wide time range.

10:27.720 --> 10:30.440
So several days out, that's when we first start

10:30.440 --> 10:32.760
to try and balance a pandemic.

10:32.760 --> 10:35.560
So for example, starting today,

10:35.560 --> 10:38.920
we'll try to make predictions for what will happen next week.

10:38.920 --> 10:41.600
And based on that, we'll already start taking actions

10:41.600 --> 10:43.360
to try and balance a pandemic.

10:43.360 --> 10:45.080
For example, if we predict that

10:45.080 --> 10:48.000
we're gonna get a huge spike in demand next week,

10:48.000 --> 10:49.400
then we can take different actions

10:49.400 --> 10:52.240
to make sure that we try and get more dashes on the road.

10:52.240 --> 10:54.880
And the reason that we do it so far in advance

10:54.880 --> 10:58.240
is because for our dashers, it's useful for them

10:58.240 --> 11:01.560
to be able to know when it's gonna be busy in the future

11:01.560 --> 11:04.240
and better plan out their own schedules that way.

11:04.240 --> 11:07.480
And then once we make this initial prediction,

11:07.480 --> 11:12.120
we also continue to update these predictions as we go.

11:12.120 --> 11:14.080
And all the way up to real time.

11:14.080 --> 11:17.000
And so in real time, we continue to monitor

11:17.000 --> 11:18.440
the state of the market.

11:18.440 --> 11:20.200
And so we see that we try to check

11:20.200 --> 11:23.400
if there's an imbalance between dashers and deliveries.

11:23.400 --> 11:25.920
And if so, again, we take different actions

11:25.920 --> 11:27.280
to try and balance it.

11:27.280 --> 11:30.280
So in real time, if we notice that there's not

11:30.280 --> 11:32.880
a dashes on the road, we'll take different actions

11:32.880 --> 11:35.520
to maybe message dashers, telling them

11:35.520 --> 11:39.680
that it's very busy right now, or creating more incentives.

11:39.680 --> 11:43.080
And vice versa, if there's too many deliveries,

11:43.080 --> 11:46.760
then we have lovers such as search pricing,

11:46.760 --> 11:48.760
where we'll increase pricing,

11:48.760 --> 11:50.840
in order to hopefully curb them in.

11:50.840 --> 11:52.640
And we can also do messaging to dashers

11:52.640 --> 11:55.600
to let them know that, hey, it's not that busy right now.

11:55.600 --> 11:57.640
So it might not be the best time to dash.

11:57.640 --> 11:58.960
Yeah, okay.

12:00.520 --> 12:05.560
And so that is that part of the problem is done

12:05.560 --> 12:08.360
kind of over this extended time period.

12:09.360 --> 12:10.720
I'm imagining other parts of it,

12:10.720 --> 12:15.720
like the core matching has to happen kind of on the fly.

12:17.680 --> 12:20.640
Yeah, so core matching is definitely more real time.

12:21.480 --> 12:23.840
So as deliveries come in,

12:23.840 --> 12:26.600
as we predict that they'll be available to pick up,

12:26.600 --> 12:29.160
so kind of going back to the food preparation time

12:29.160 --> 12:31.040
that we were talking about before.

12:31.040 --> 12:34.440
Obviously, we don't want to assign delivery right away

12:34.440 --> 12:36.680
after the order has been submitted,

12:36.680 --> 12:39.200
because a lot of times the food takes an hour

12:39.200 --> 12:42.120
to be prepared, then we will be assigning a dasher

12:42.120 --> 12:43.480
way too early.

12:43.480 --> 12:46.880
And so once we have these raw inputs from the deliveries,

12:46.880 --> 12:49.640
we also make a bunch of different predictions,

12:49.640 --> 12:52.480
one of which is the food preparation time.

12:52.480 --> 12:55.800
And then again, all these raw data along these predictions

12:55.800 --> 12:58.680
get fed into our matching system,

12:58.680 --> 13:00.440
which we'll find the optimal matching.

13:00.440 --> 13:02.240
And yeah, this is all done in real time.

13:02.240 --> 13:05.520
We get inputs from deliveries and dashers in real time,

13:05.520 --> 13:07.200
make the predictions in real time,

13:07.200 --> 13:09.240
and also do the matching real time.

13:09.240 --> 13:10.880
One thing we are moving towards though,

13:10.880 --> 13:14.760
and that we are exploring is you can imagine that,

13:14.760 --> 13:17.040
for example, as we've grown,

13:17.040 --> 13:20.400
we've noticed patterns and where our demand

13:20.400 --> 13:22.480
is comes in throughout the day.

13:22.480 --> 13:25.200
So for example, if there's a really popular merchant,

13:25.200 --> 13:27.440
then it's not that hard to expect

13:27.440 --> 13:29.400
that that merchant will receive some orders

13:29.400 --> 13:32.080
during a Friday dinner, for example.

13:32.080 --> 13:34.040
And so one of the things that we're exploring

13:34.040 --> 13:37.640
is trying to anticipate these orders ahead of time.

13:37.640 --> 13:40.400
And then that way, we can better position our fleet

13:40.400 --> 13:42.400
and better make our assignments to account

13:42.400 --> 13:44.680
for these future deliveries.

13:44.680 --> 13:46.600
Yeah, I was going to ask about that.

13:46.600 --> 13:51.600
I noticed for scheduled ubers, for example,

13:52.840 --> 13:57.360
the impression that I get is not that it actually schedules

13:57.360 --> 14:01.800
the ride, but that it inserts the order for me at the time,

14:01.800 --> 14:04.800
you know, before I need the ride,

14:04.800 --> 14:06.600
but, you know, kind of real time.

14:06.600 --> 14:10.400
There's not really any notion of scheduling.

14:10.400 --> 14:12.680
And I don't know if DoorDash has a notion of scheduling,

14:12.680 --> 14:14.560
like I'd like my dinner at seven o'clock tonight

14:14.560 --> 14:17.200
and so figure out all the kind of working backwards.

14:17.200 --> 14:18.680
And I was curious if that's a,

14:20.960 --> 14:24.440
is that a, you know, based on,

14:26.480 --> 14:28.920
you know, a lot of experimentation on how to do that,

14:28.920 --> 14:30.320
or is it just a simplification

14:30.320 --> 14:32.280
that kind of works in the industry

14:32.280 --> 14:35.560
for these marketplace types of applications?

14:36.600 --> 14:39.720
Yeah, so we do have scheduled deliveries as well.

14:39.720 --> 14:40.560
Okay.

14:40.560 --> 14:42.120
And thanks so much to Wages ascribe.

14:42.120 --> 14:44.480
Yeah, we kind of just treat them as a regular delivery

14:44.480 --> 14:46.880
that happens sometimes in the future.

14:46.880 --> 14:47.720
Okay.

14:47.720 --> 14:50.680
And so for some of the future, predicting future deliveries

14:50.680 --> 14:54.120
work that I was mentioning, basically,

14:54.120 --> 14:55.840
you can think of as scheduled deliveries,

14:55.840 --> 14:58.000
a kind of future deliveries that we know

14:58.000 --> 15:01.320
with pretty much 100% certainty will happen.

15:01.320 --> 15:04.160
Whereas any prediction that we end up making

15:04.160 --> 15:06.280
will have some kind of confidence interval

15:06.280 --> 15:08.760
if that delivery will actually occur or not.

15:08.760 --> 15:11.520
And so we can treat them a pretty similar way.

15:11.520 --> 15:13.360
But yeah, in the end, they are all accounted

15:13.360 --> 15:15.200
for pretty dynamically.

15:15.200 --> 15:17.240
Again, we try to, we ultimately try to predict

15:17.240 --> 15:19.160
when the food will be ready to pick up

15:19.160 --> 15:21.240
and assign the dash of base on that time.

15:23.320 --> 15:27.760
So one of the most interesting aspects of your approach

15:27.760 --> 15:29.960
and you spend quite a bit of time

15:29.960 --> 15:31.600
talking about this in your presentation

15:31.600 --> 15:36.560
is that you are pairing machine learning

15:36.560 --> 15:38.720
with kind of traditional approaches

15:38.720 --> 15:40.960
to logistics optimization.

15:40.960 --> 15:43.800
So you know, let's dive into that a little bit.

15:43.800 --> 15:44.760
Yeah, awesome.

15:44.760 --> 15:47.280
Yeah, so definitely we do make a lot of use

15:47.280 --> 15:48.600
of combining machine learning

15:48.600 --> 15:51.000
and traditional operations research.

15:51.000 --> 15:54.120
And so I'll talk about how we apply this combination

15:54.120 --> 15:58.160
to both supply and demand as well as the optimal matching problem.

15:58.160 --> 16:00.840
So for supply and demand, like I mentioned,

16:00.840 --> 16:04.120
we try and forecast out supply and demand multiple days

16:04.120 --> 16:05.280
and events.

16:05.280 --> 16:07.680
And when we determine that we'll have more deliveries

16:07.680 --> 16:10.480
than dashers, we'll create these incentives

16:10.480 --> 16:12.720
to try and get more dashes on the road.

16:12.720 --> 16:15.200
And again, we do that upfront and in advance

16:15.200 --> 16:17.960
so that dashes have time to plan on their schedules.

16:17.960 --> 16:20.560
And so what this means is that we have to forecast out

16:20.560 --> 16:21.720
what the men will be.

16:21.720 --> 16:24.680
And forecast out what supply will be and determine

16:24.680 --> 16:26.640
what the right incentive is.

16:26.640 --> 16:29.200
And so this gets very challenging

16:29.200 --> 16:31.160
one because of the complexity.

16:31.160 --> 16:35.720
So for example, if you want to determine the optimal incentive

16:35.720 --> 16:39.240
for every single region and every single time of day,

16:39.240 --> 16:40.960
that obviously gets very complicated.

16:40.960 --> 16:42.880
And there's lots of possible combinations

16:42.880 --> 16:44.760
that you can choose.

16:44.760 --> 16:46.200
Another reason it's so challenging

16:46.200 --> 16:50.200
is because forecasting itself is always a challenging problem.

16:50.200 --> 16:53.200
Forecasting, future demand, forecasting, future supply.

16:53.200 --> 16:55.160
There are a lot of factors that go into it.

16:55.160 --> 16:56.920
And especially when you're predicting these things

16:56.920 --> 17:00.160
that are so heavily influenced by the real world,

17:00.160 --> 17:01.600
it makes it even harder.

17:01.600 --> 17:05.880
There's super high variance from things such as weather,

17:05.880 --> 17:10.360
traffic, special events, a pandemic.

17:10.360 --> 17:12.000
So all these things can have huge impact

17:12.000 --> 17:13.840
on our future supply demand.

17:13.840 --> 17:15.280
And so being able to handle all these things

17:15.280 --> 17:17.280
are super challenging.

17:17.280 --> 17:19.360
And so how we try to solve it is

17:19.360 --> 17:22.480
by combining machine learning and operations research.

17:22.480 --> 17:25.400
So with machine learning, we try to build our models

17:25.400 --> 17:29.600
that accurately forecast that demand a supply.

17:29.600 --> 17:33.600
And so once we have these models, what we can do

17:33.600 --> 17:36.240
is feed them into operations research system

17:36.240 --> 17:39.240
in order to find the optimal incentives.

17:39.240 --> 17:42.640
And so the way we do that is by framing it

17:42.640 --> 17:45.760
as a traditional operations research problem,

17:45.760 --> 17:47.920
where we have some objective.

17:47.920 --> 17:50.640
And so in this case, our objective

17:50.640 --> 17:54.080
would be to maximize our delivery quality.

17:54.080 --> 17:56.240
And we also have some constraints.

17:56.240 --> 18:00.840
For example, we can't create $20 incentives.

18:00.840 --> 18:03.240
We want to keep cost low as well.

18:03.240 --> 18:07.560
And so given this objective of maximizing delivery quality

18:07.560 --> 18:09.720
and given this constraint of cost,

18:09.720 --> 18:13.840
we can feed our inputs from our machine learning model

18:13.840 --> 18:15.800
into this system.

18:15.800 --> 18:18.960
And then we can ultimately solve for the optimal incentives

18:18.960 --> 18:21.320
by using integer programming.

18:21.320 --> 18:26.160
And so this basically treats the problem as a math problem,

18:26.160 --> 18:28.480
where you have some objective function,

18:28.480 --> 18:30.800
you have some constraints, and you solve it

18:30.800 --> 18:33.040
through these mathematical methods.

18:33.040 --> 18:34.960
And so yeah, super interesting, because otherwise,

18:34.960 --> 18:37.880
you can imagine that how would you

18:37.880 --> 18:41.560
pick the optimal incentives for every city that DoorDash

18:41.560 --> 18:43.840
operates in for every single time of day?

18:43.840 --> 18:45.480
It gets very challenging.

18:45.480 --> 18:46.760
There's so many combinations.

18:46.760 --> 18:49.320
And if you have human operators do it,

18:49.320 --> 18:52.880
they will have to manually go through every single region.

18:52.880 --> 18:54.560
They will somehow have to try and balance that,

18:54.560 --> 18:57.760
OK, show that at $1 here in San Francisco,

18:57.760 --> 19:01.000
or is it better to spend that extra dollar in San Jose?

19:01.000 --> 19:04.280
And so by feeding into, by using operations research,

19:04.280 --> 19:06.640
we're able to better make these trade-offs

19:06.640 --> 19:10.440
and ultimately come up the optimal set of incentives

19:10.440 --> 19:14.520
that, again, maximize the delivery quality.

19:14.520 --> 19:15.960
And yeah, sorry.

19:15.960 --> 19:16.760
Oh, no.

19:16.760 --> 19:24.080
I was just going to ask, you mentioned integer programming.

19:24.080 --> 19:26.320
Is it also linear, like you're using linear programming

19:26.320 --> 19:32.520
models, or is it nonlinear OR stuff?

19:32.520 --> 19:34.080
Yeah, so we have a mix.

19:34.080 --> 19:36.480
Some's linear, some's nonlinear.

19:36.480 --> 19:39.240
And sometimes we also do mixed-anger programming as well.

19:39.240 --> 19:40.400
OK.

19:40.400 --> 19:43.640
And so essentially, you've got kind of these tried-entry

19:43.640 --> 19:48.960
techniques for solving these systems of equations,

19:48.960 --> 19:51.520
where you have known quantities.

19:51.520 --> 19:54.360
But in your case, some of the quantities you don't actually

19:54.360 --> 19:56.560
know, so you use machine learning

19:56.560 --> 19:58.960
to try to predict what those quantities are.

19:58.960 --> 20:03.960
And then you kind of pump those into the traditional OR

20:03.960 --> 20:05.520
types of tools.

20:05.520 --> 20:06.720
Yep, exactly.

20:06.720 --> 20:09.680
And because of these natural errors in machine learning

20:09.680 --> 20:12.080
models, unfortunately, obviously,

20:12.080 --> 20:14.240
our predictions are not perfect.

20:14.240 --> 20:16.320
So because of that, it's super important for us

20:16.320 --> 20:20.000
to have real-time systems in place to kind of adjust

20:20.000 --> 20:21.640
for these errors.

20:21.640 --> 20:24.200
And so some examples are what I mentioned earlier

20:24.200 --> 20:28.160
where in real-time, we also have monitoring in place

20:28.160 --> 20:31.720
to see if there's imbalance in or supply in demand.

20:31.720 --> 20:34.880
And it will take different actions and response

20:34.880 --> 20:38.680
to essentially try and correct for the mistakes

20:38.680 --> 20:42.520
that are more predictive systems have made.

20:42.520 --> 20:46.720
And so when it's in the case of a monitoring system

20:46.720 --> 20:50.120
identifying an imbalance, does it

20:50.120 --> 20:56.240
is it trying to correct that by, does it just take an action?

20:56.240 --> 20:59.400
You've got some kind of program behavior

20:59.400 --> 21:01.440
that is based on what it observes?

21:01.440 --> 21:04.680
Or does it tweak the inputs and run it

21:04.680 --> 21:08.520
through the same system, hoping that you get a better

21:08.520 --> 21:10.560
output?

21:10.560 --> 21:12.280
Yeah, so currently the way that we do it

21:12.280 --> 21:16.760
is we basically, once we determine that there's an imbalance,

21:16.760 --> 21:20.280
we try to measure how much that imbalance is.

21:20.280 --> 21:23.200
And from there, we have a set of actions

21:23.200 --> 21:25.120
that we have available to us.

21:25.120 --> 21:27.280
And for each of these actions, we try

21:27.280 --> 21:30.440
to understand the impact of each of these actions.

21:30.440 --> 21:33.280
Again, that becomes like a prediction in some ways

21:33.280 --> 21:36.240
where we're predicting what the impact will be of different actions.

21:36.240 --> 21:38.680
For example, if we message dashers,

21:38.680 --> 21:41.360
how many more dashers will we get on the road versus

21:41.360 --> 21:43.560
if we add an extra dollar incentive?

21:43.560 --> 21:45.680
How many more dashers will we get on the road?

21:45.680 --> 21:47.680
And so we have all these different actions,

21:47.680 --> 21:50.120
estimates for the impact of each of these

21:50.120 --> 21:51.280
and based on that.

21:51.280 --> 21:53.800
And again, matching that with how much imbalance

21:53.800 --> 21:56.040
there is currently will pick the action

21:56.040 --> 21:58.680
that tries to fix the imbalance.

21:58.680 --> 22:00.840
Yeah, there's something that we're actively working on

22:00.840 --> 22:02.720
and something that we're building out.

22:02.720 --> 22:04.240
But that's kind of a general framework

22:04.240 --> 22:08.720
where we monitor and we determine how much imbalance there is

22:08.720 --> 22:11.400
and choose the action or the set of actions

22:11.400 --> 22:14.080
that we think will help us fix the imbalance.

22:14.080 --> 22:17.800
And do you incorporate aspects of control systems,

22:17.800 --> 22:18.800
control theory in there?

22:18.800 --> 22:22.880
I'm imagining you're monitoring, observing,

22:22.880 --> 22:26.000
you take some action based on what you think is going to happen.

22:26.000 --> 22:29.280
You kind of overshoot, you might want some dampening in there

22:29.280 --> 22:31.280
or you might need to overcompensate.

22:31.280 --> 22:36.600
Do you just think of systems in that way

22:36.600 --> 22:39.000
or are you just kind of taking a snapshot in time

22:39.000 --> 22:41.880
and if you're oscillating or not,

22:41.880 --> 22:43.200
you're not paying attention to that.

22:43.200 --> 22:44.880
You're just doing making the correction

22:44.880 --> 22:47.640
that needs to happen at a given time.

22:47.640 --> 22:49.640
Yeah, so we definitely, we frequently

22:49.640 --> 22:52.320
check the state of our markets in order

22:52.320 --> 22:55.480
to try and correct for these actions

22:55.480 --> 22:59.200
that maybe we went too far in one direction.

22:59.200 --> 23:03.320
And so yeah, we very frequently check the state of the market.

23:03.320 --> 23:06.480
And if we notice that say we measure dashers

23:06.480 --> 23:09.280
but that result in us having too many dashers on the road

23:09.280 --> 23:12.680
actually, at that point, yeah, we can take additional actions

23:12.680 --> 23:16.120
to try and either reduce the number of dashers on the road

23:16.120 --> 23:20.440
or maybe curb demand at that point.

23:20.440 --> 23:24.120
And so, yeah, and so another approach

23:24.120 --> 23:26.680
that we're exploring as well is framing it

23:26.680 --> 23:29.640
as a reinforcement learning problem.

23:29.640 --> 23:33.480
So you can imagine this problem fits pretty well

23:33.480 --> 23:35.440
into the reinforcement learning framework

23:35.440 --> 23:37.160
where you have some state,

23:37.160 --> 23:39.640
which is essentially the state of our marketplace,

23:39.640 --> 23:42.920
how many dashers there are, how many deliveries there are.

23:42.920 --> 23:44.320
You have a set of actions,

23:44.320 --> 23:46.240
which are these different levers that we have

23:46.240 --> 23:48.160
to try and correct for supply and demand.

23:49.120 --> 23:51.760
And then you have your reward.

23:51.760 --> 23:53.280
In our case, it will be metrics

23:53.280 --> 23:57.520
about delivery quality and efficiency of the marketplace.

23:57.520 --> 23:59.560
And so given these settings,

23:59.560 --> 24:02.920
it fits pretty nicely into reinforcement learning framework

24:02.920 --> 24:07.920
where we can explore and exploit, try out different actions,

24:07.920 --> 24:11.480
see what the reward is, what the impact is of those actions.

24:11.480 --> 24:14.200
And based on that, we can update our models

24:14.200 --> 24:17.000
to one, have better estimates of what the impact

24:17.000 --> 24:18.320
of different actions are,

24:18.320 --> 24:21.240
and two, also allow models to intelligently

24:21.240 --> 24:24.360
take what the best action is at any given state.

24:24.360 --> 24:27.160
And so yeah, this is something we're exploring.

24:27.160 --> 24:29.920
There's other problems with the logistics as well,

24:29.920 --> 24:33.440
that fits pretty nicely into the reinforcement learning framework.

24:33.440 --> 24:35.280
So we think that will be a pretty powerful tool

24:35.280 --> 24:36.440
for us moving forward.

24:37.520 --> 24:39.600
You mentioned that you,

24:39.600 --> 24:42.800
it sounds like you have kind of boiled

24:42.800 --> 24:45.480
all of your customer,

24:45.480 --> 24:50.240
sat metrics into a delivery quality metric.

24:50.240 --> 24:54.280
Is that a metric that you use across the board

24:54.280 --> 24:56.600
in assessing the performance of these kind of systems

24:56.600 --> 25:01.360
or is it specific to the reinforcement learning implementation

25:01.360 --> 25:03.200
that you're looking at?

25:03.200 --> 25:05.840
Yeah, so it's not specific to the reinforcement learning

25:05.840 --> 25:06.680
implementation.

25:07.680 --> 25:11.400
We do have these shared metrics that we commonly look at.

25:11.400 --> 25:13.480
For example, how fast does it take

25:13.480 --> 25:15.280
for a delivery to be delivered?

25:15.280 --> 25:17.320
From time when you place an order

25:17.320 --> 25:19.200
to when it arrives at your doorstep,

25:19.200 --> 25:22.720
we want to minimize that time as much as possible.

25:22.720 --> 25:24.480
And there's other consumer facing metrics

25:24.480 --> 25:25.680
as well that we care about.

25:25.680 --> 25:27.760
For example, cancellations.

25:27.760 --> 25:30.720
We want to reduce cancellations as much as possible,

25:30.720 --> 25:33.840
whether it's because the merchant was actually close

25:33.840 --> 25:37.120
or maybe the consumer got sick of waiting for so long.

25:37.120 --> 25:39.120
And so a lot of these metrics are pretty common

25:39.120 --> 25:41.960
and are shared across the board by different teams,

25:41.960 --> 25:43.280
whenever they work on something that

25:43.280 --> 25:45.400
could impact these metrics.

25:45.400 --> 25:47.400
But again, depending on the project,

25:47.400 --> 25:50.680
there could also be more specific metrics that you look at.

25:50.680 --> 25:53.680
You can think of these delivery times, cancellations,

25:53.680 --> 25:56.920
metrics like that as more of output metrics.

25:56.920 --> 25:59.040
But a lot of times we might want a more granular look

25:59.040 --> 26:01.880
at what the input metrics look like.

26:01.880 --> 26:04.400
And so some examples would be maybe

26:04.400 --> 26:07.560
in self looking at delivery times directly.

26:07.560 --> 26:10.280
Maybe we want to focus on looking at how long it took

26:10.280 --> 26:11.920
to drop off to happen.

26:11.920 --> 26:13.880
So say we're working on a product that

26:13.880 --> 26:16.160
tries to speed up the drop off process.

26:16.160 --> 26:17.840
How long it takes the dash to drop off

26:17.840 --> 26:19.880
the delivery to the consumer.

26:19.880 --> 26:21.440
And so in that case, it will be useful to look

26:21.440 --> 26:24.840
at this more specific metric.

26:24.840 --> 26:27.400
And so tell me a little bit about your experiences

26:27.400 --> 26:30.200
with the reinforcement learning approach.

26:30.200 --> 26:32.120
What have you found there?

26:32.120 --> 26:35.360
Yeah, so it's been still in a more exploratory face

26:35.360 --> 26:36.640
at this point.

26:36.640 --> 26:39.360
And I can maybe talk a bit more about some of the results

26:39.360 --> 26:42.000
that we got when we tried to apply reinforcement learning

26:42.000 --> 26:44.320
to the Simon problem.

26:44.320 --> 26:47.080
So again, here, it was a pretty natural fit

26:47.080 --> 26:49.920
because we have these states, which, again,

26:49.920 --> 26:54.960
is all the existing deliveries and dashers at any given time.

26:54.960 --> 26:56.840
We have these different actions, which

26:56.840 --> 26:59.360
would be all the different possible matching

26:59.360 --> 27:01.520
between dashes and deliveries.

27:01.520 --> 27:03.160
And so what we've actually tried is,

27:03.160 --> 27:07.800
because as you can imagine, if you treat every single combination

27:07.800 --> 27:11.480
of dashed delivery pair as the different actions,

27:11.480 --> 27:14.320
that action space becomes very huge.

27:14.320 --> 27:17.080
So even with 15 deliveries and 15 dashers,

27:17.080 --> 27:20.120
there's actually over one trillion possible combinations.

27:20.120 --> 27:22.840
And so obviously, working with that large of action spaces

27:22.840 --> 27:24.200
is very challenging.

27:24.200 --> 27:26.560
And so what we did was actually, we tried to simplify

27:26.560 --> 27:29.680
and reduce action space by, instead

27:29.680 --> 27:33.680
of using the different combinations of matching as the actions,

27:33.680 --> 27:36.640
we just used different variants of the Simon system,

27:36.640 --> 27:40.080
of the Simon algorithm, as the different actions.

27:40.080 --> 27:41.480
And so those were actions.

27:41.480 --> 27:45.160
And again, our reward in this case was delivery speeds

27:45.160 --> 27:47.680
and marketplace efficiency.

27:47.680 --> 27:50.480
And so once we sell the problem this way,

27:50.480 --> 27:54.760
we tried using pretty standard reinforcement learning methods.

27:54.760 --> 27:59.000
Specifically, we tried using deep reinforcement learning

27:59.000 --> 28:02.200
where our agent was a deep neural network

28:02.200 --> 28:04.200
that took in a bunch of features

28:04.200 --> 28:06.560
and tried to learn for any given state

28:06.560 --> 28:08.480
what was the optimal action to take.

28:08.480 --> 28:10.960
And then again, in this case, the optimal action

28:10.960 --> 28:14.560
is the optimal variant of the Simon algorithm.

28:14.560 --> 28:17.800
So yeah, we've done some exploratory work with this.

28:17.800 --> 28:19.720
We have a blog post about this on our website,

28:19.720 --> 28:21.800
actually, as well with more details.

28:21.800 --> 28:23.960
But we did see pretty problems and results

28:23.960 --> 28:26.240
where we saw some few seconds improvements

28:26.240 --> 28:28.800
and delivery speeds as well as efficiency.

28:28.800 --> 28:31.480
And so a few seconds doesn't sound like much.

28:31.480 --> 28:33.800
But when you scale it up to millions of deliveries.

28:33.800 --> 28:35.920
I want to leave my pizza.

28:35.920 --> 28:37.400
Yeah, definitely.

28:37.400 --> 28:39.880
But yeah, when you scale it up to millions of deliveries,

28:39.880 --> 28:42.760
it definitely adds up.

28:42.760 --> 28:43.280
Interesting.

28:43.280 --> 28:46.960
And so what are the challenges?

28:46.960 --> 28:50.640
What's keeping you from putting that into production?

28:50.640 --> 28:52.480
Yeah, so I think one is we definitely

28:52.480 --> 28:54.320
just need to keep doing more work

28:54.320 --> 28:57.040
to improve each other components within that reinforcement

28:57.040 --> 29:02.320
learning system, improving the deep neural network agent,

29:02.320 --> 29:05.720
improving the different features that we have.

29:05.720 --> 29:08.080
And of course, our system right now,

29:08.080 --> 29:12.720
we don't have a lot of these infrastructure pieces set up.

29:12.720 --> 29:15.040
So it would have to require some restructuring

29:15.040 --> 29:17.640
and we're working on the system, which again, right now

29:17.640 --> 29:20.960
is very much based on using machine learning

29:20.960 --> 29:23.120
plus operations research.

29:23.120 --> 29:25.360
And so yeah, there's definitely a lot of investment

29:25.360 --> 29:28.200
that needs to be made to move away from the current framework

29:28.200 --> 29:29.600
that we have.

29:29.600 --> 29:31.920
But again, yeah, we're always exploring

29:31.920 --> 29:34.160
trying new techniques to do things,

29:34.160 --> 29:35.960
including reinforcement learning.

29:35.960 --> 29:38.800
And as we do more of these explorations,

29:38.800 --> 29:41.520
at some point, if we feel that the improvements

29:41.520 --> 29:44.160
that we'll get is worth this long-term investment,

29:44.160 --> 29:47.400
we'll definitely make this switch then.

29:47.400 --> 29:56.720
Is it possible to, in thinking about kind of the way

29:56.720 --> 29:58.960
you've paired this machine learning system

29:58.960 --> 30:01.880
and the operations research system?

30:01.880 --> 30:04.600
Is it a future direction or of interest

30:04.600 --> 30:08.320
to try to kind of collapse this down

30:08.320 --> 30:10.400
to a single machine learning system?

30:10.400 --> 30:13.760
Is that something that is worth exploration

30:13.760 --> 30:15.920
or if not, why not?

30:15.920 --> 30:22.200
Yeah, I think it is something worth exploring.

30:22.200 --> 30:25.600
I do feel that the challenging part of doing that

30:25.600 --> 30:29.280
would be that there's certain aspects of the problem

30:29.280 --> 30:33.800
that it's just very naturally suited for operations research.

30:33.800 --> 30:36.680
And what I mean by that is whenever you have a problem

30:36.680 --> 30:40.240
where you have a very clear objective function

30:40.240 --> 30:43.040
that you're either trying to maximize or minimize

30:43.040 --> 30:47.440
and use a very clear constraints, it's

30:47.440 --> 30:50.160
much easier to frame as operations research problem

30:50.160 --> 30:52.280
because that's exactly the kind of problems

30:52.280 --> 30:54.480
that they're meant to solve.

30:54.480 --> 30:57.960
Where you have some objective, you have some constraints,

30:57.960 --> 31:01.080
and you basically frame as a math problem

31:01.080 --> 31:03.560
that's much easier to solve.

31:03.560 --> 31:07.120
And so I do think there could be potential

31:07.120 --> 31:10.840
for maybe having some kind of like one shot ML model

31:10.840 --> 31:13.960
that can kind of do everything end to end.

31:13.960 --> 31:17.720
But right now, I haven't found any great ways

31:17.720 --> 31:21.680
of using ML to completely solve these type of problems

31:21.680 --> 31:23.920
where you have objective, but then you also

31:23.920 --> 31:27.560
have these sort of constraints that you must abide by.

31:27.560 --> 31:31.080
And so for us, we found that yeah, combining machine learning

31:31.080 --> 31:34.600
to try and make these predictions, augment the raw data

31:34.600 --> 31:38.840
that we have and feeding it into an optimization system

31:38.840 --> 31:41.960
that can take care of handling these constraints for us,

31:41.960 --> 31:45.480
take care of maximizing and minimizing the objective function.

31:45.480 --> 31:49.200
We found that this approach has worked really well for us.

31:49.200 --> 31:55.440
And the operations research elements of this,

31:55.440 --> 31:58.320
do they, I'm imagining with the, you know,

31:58.320 --> 31:59.880
the kind of the machine learning world,

31:59.880 --> 32:02.040
where, you know, this is all very new.

32:02.040 --> 32:04.880
We're kind of constantly iterating our systems and models

32:04.880 --> 32:06.760
and things like that.

32:06.760 --> 32:12.000
Is your OR system kind of equal in that way?

32:12.000 --> 32:14.760
Are you kind of constantly, you know, tweaking

32:14.760 --> 32:16.200
and iterating, or is it, you know,

32:16.200 --> 32:19.360
because it's a kind of more mature approach,

32:19.360 --> 32:23.280
is it something that once you've identified your constraints

32:23.280 --> 32:25.240
and build this pipeline for your inputs,

32:25.240 --> 32:26.560
it kind of just does this thing

32:26.560 --> 32:29.600
and you don't have to worry about it as much.

32:29.600 --> 32:30.800
Yeah, that's a good question.

32:30.800 --> 32:33.920
So it is definitely a more mature field, like you said.

32:34.840 --> 32:38.520
But our team is definitely always trying new improvements to it.

32:38.520 --> 32:41.440
Some of it could be very small tweaks to the system.

32:41.440 --> 32:43.440
For example, tweaking different settings,

32:43.440 --> 32:47.000
tweaking different parameters, tweaking different ways

32:47.000 --> 32:49.200
of calculating the objective function.

32:49.200 --> 32:51.040
And so we're always trying these things.

32:51.040 --> 32:54.280
And yeah, you'll be surprised sometimes, even the smallest changes

32:54.280 --> 32:57.200
can lead to some of the biggest gains.

32:57.200 --> 32:59.680
Some of the most improvements that we've gotten

32:59.680 --> 33:03.400
over the past year or so have been from very simple changes

33:03.400 --> 33:05.320
on two different systems.

33:05.320 --> 33:07.760
So I can't go into the details, unfortunately,

33:07.760 --> 33:09.760
but some examples are basically just tweaking

33:09.760 --> 33:13.840
a single parameter, say going from like four to five

33:13.840 --> 33:16.320
and that bands up leading to a pretty big result.

33:16.320 --> 33:21.120
And so yeah, so we always do tweaks like that.

33:21.120 --> 33:24.040
And we also, we're always exploring brand new ways

33:24.040 --> 33:26.840
of doing the operations research piece as well.

33:26.840 --> 33:31.160
So actually, the switch to using mixed integer programming

33:31.160 --> 33:34.600
for our dispatch system, that switch was actually made

33:34.600 --> 33:36.680
not too long ago.

33:36.680 --> 33:41.680
So we used to use a simpler algorithm that wasn't as efficient

33:41.920 --> 33:45.080
because it could only do a single matching at a time.

33:45.080 --> 33:47.640
And kind of recently, we transitioned

33:47.640 --> 33:50.040
to this mixed integer programming approach

33:50.040 --> 33:53.600
where we can handle multiple deliveries, multiple dashers

33:53.600 --> 33:55.920
and create multiple matching at a time.

33:55.920 --> 34:00.240
And so yeah, so yeah, so we've always explored new options.

34:00.240 --> 34:03.680
And yeah, I wouldn't be surprised if sometime down the line,

34:03.680 --> 34:07.200
we find some new way of doing this optimization

34:07.200 --> 34:09.160
that nets us some really big gains.

34:10.120 --> 34:12.720
And the mixed and mixed integer programming

34:12.720 --> 34:16.120
does that relate to this idea of multiple inputs

34:16.120 --> 34:16.960
and multiple outputs?

34:16.960 --> 34:18.160
Or I forget what that's specifically,

34:18.160 --> 34:21.280
is that partial some floating point, some integer

34:21.280 --> 34:23.440
or is it related to the inputs outputs?

34:23.440 --> 34:24.280
Yeah, exactly.

34:24.280 --> 34:26.880
So it's related to the variables in the optimization form.

34:26.880 --> 34:29.520
So some of them integers and some of them are floats.

34:29.520 --> 34:30.760
Okay, okay.

34:32.560 --> 34:37.560
And so how does the, how does incorporating floats

34:37.560 --> 34:42.560
into your problem allow you to kind of what I heard

34:44.200 --> 34:49.200
was like optimize multiple variables in parallel?

34:51.400 --> 34:55.200
Yeah, so that component isn't what ultimately

34:55.200 --> 34:58.960
and allows us to make multiple matching in parallel.

34:58.960 --> 35:01.760
So the main change is moving towards this

35:01.760 --> 35:05.760
just general mixed integer slash integer programming approach.

35:05.760 --> 35:10.760
And so before, where again, our system

35:12.120 --> 35:14.680
could only make one pair of matching at a time.

35:14.680 --> 35:16.520
And the reason that this was the case

35:16.520 --> 35:18.120
was because we were using this algorithm

35:18.120 --> 35:20.240
called the Hungarian algorithm.

35:20.240 --> 35:21.240
Okay.

35:21.240 --> 35:25.720
Where one kind of runs pretty slow,

35:25.720 --> 35:28.400
especially when you're running it at scale.

35:29.400 --> 35:32.400
And then yeah, again, it only does one matching at a time.

35:32.400 --> 35:36.360
And so instead by formulating a problem as a mixed-anger program

35:36.360 --> 35:40.120
problem, we're able to not just speed up

35:40.120 --> 35:42.840
how fast variable solve these problems.

35:42.840 --> 35:45.160
But again, also have multiple matching.

35:45.160 --> 35:47.880
And once we frame at this problem,

35:47.880 --> 35:50.240
we can continue to have machine learning

35:51.320 --> 35:54.800
generate predictions to use as different inputs in this system.

35:54.800 --> 35:57.800
For example, we can predict food preparation times.

35:57.800 --> 36:00.800
We can predict how long we'll take the delivery to be delivered.

36:00.800 --> 36:04.280
And based on that, we can create our cost functions,

36:04.280 --> 36:07.320
our objective functions, and optimize that way.

36:07.320 --> 36:08.320
Okay.

36:08.320 --> 36:09.160
Very cool.

36:09.160 --> 36:10.000
Very cool.

36:11.760 --> 36:15.760
Were there other points that you covered

36:15.760 --> 36:18.520
in your presentation that we should make sure to touch on?

36:19.520 --> 36:24.520
Yeah, so I would say one thing that I wanted to stress

36:24.960 --> 36:27.000
as well is kind of just how challenging

36:27.000 --> 36:28.360
a lot of these problems are.

36:28.360 --> 36:31.360
So I think one thing that I've touched on

36:31.360 --> 36:35.800
is the high variance of our systems.

36:37.000 --> 36:40.000
So because we operate in a real world,

36:40.000 --> 36:45.000
lots of factors such as weather, such as traffic,

36:45.920 --> 36:50.360
special events, yeah, one fun example is one game

36:50.360 --> 36:51.880
of throwing things to be on.

36:51.880 --> 36:54.640
Every Sunday evening, we'll see huge spike in demand.

36:55.640 --> 36:58.000
And so even though the last couple of seasons,

36:58.000 --> 37:01.680
maybe one that great, we still had a huge surge in demand.

37:01.680 --> 37:03.520
And people are definitely tuning in.

37:03.520 --> 37:06.600
Yeah, people are still hungry, people are still tuning in.

37:06.600 --> 37:09.200
And I like this one, we have like the Super Bowl.

37:09.200 --> 37:12.840
People definitely tend to order delivery.

37:12.840 --> 37:14.440
And so counting for all these different factors

37:14.440 --> 37:16.800
has been super challenging for us.

37:16.800 --> 37:19.240
That's kind of interesting from the perspective of,

37:19.240 --> 37:22.800
we tend to think about you kind of build this model

37:22.800 --> 37:26.200
and then you put it in a production

37:26.200 --> 37:28.160
and you want to keep an eye on it and make sure

37:28.160 --> 37:30.480
that the data that it sees, you know,

37:30.480 --> 37:32.840
looks like the data that you trained it on.

37:32.840 --> 37:37.640
But it sounds like you've got all these real world factors

37:37.640 --> 37:40.240
that are making the data that the models are seeing

37:40.240 --> 37:42.360
in production, you know, look very different.

37:42.360 --> 37:45.000
Like how do you approach, is there a different way

37:45.000 --> 37:47.000
you need to think about model monitoring

37:47.000 --> 37:49.000
in a high variance environment?

37:50.160 --> 37:52.960
Yeah, I would say you just need to be very careful

37:52.960 --> 37:56.680
and very thorough how you monitor your models.

37:56.680 --> 37:59.600
So I think, yeah, definitely.

37:59.600 --> 38:02.320
Yeah, so I think, so I think one general point

38:02.320 --> 38:04.960
that I want to bring up to is one challenge

38:04.960 --> 38:07.480
I found with machine learning in the industry

38:07.480 --> 38:11.960
is it's not just about finding the right hyper parameters

38:11.960 --> 38:14.720
or finding the right model algorithm to use.

38:15.680 --> 38:18.680
It's also involves a lot of general engineering principles

38:18.680 --> 38:21.920
as well to deploy machine learning

38:21.920 --> 38:25.960
to solve your problems in a reliable and scalable way.

38:25.960 --> 38:29.400
There's a lot of systems that you have to set up in place.

38:29.400 --> 38:32.640
Yeah, one example would be how do you make sure

38:32.640 --> 38:37.880
that you monitor any degradation in your models?

38:37.880 --> 38:39.720
How do you make sure that there's consistency

38:39.720 --> 38:42.080
between the data that you saw during training

38:42.080 --> 38:45.200
and the data that you see during prediction?

38:45.200 --> 38:47.360
How do we manage and run experiments

38:47.360 --> 38:50.560
with different versions of many different models?

38:50.560 --> 38:52.960
How do we periodically retrain these models?

38:52.960 --> 38:55.440
As they degrade, how do we make sure that they get retrained

38:55.440 --> 38:57.920
and updated with the latest data?

38:57.920 --> 38:59.800
And of course, yeah, how do we protect against

38:59.800 --> 39:01.280
incorrect predictions?

39:01.280 --> 39:04.400
In cases such as, yeah, when a pandemic hits,

39:04.400 --> 39:07.800
our models are always going to struggle at predicting that.

39:07.800 --> 39:10.960
So how do we make sure that we account for these

39:10.960 --> 39:13.520
incorrect predictions and adjust accordingly?

39:13.520 --> 39:16.040
And so we've invested a lot of time and effort

39:16.040 --> 39:18.520
into building out engineering systems

39:18.520 --> 39:20.880
that can take care of these things for us.

39:20.880 --> 39:23.840
So setting up monitoring of our model predictions,

39:23.840 --> 39:26.480
monitoring of our model inputs,

39:26.480 --> 39:31.400
making sure that the data that the model sees

39:31.400 --> 39:33.800
is always what it expects.

39:33.800 --> 39:37.240
And if we notice anything wrong, anything that deviates

39:37.240 --> 39:39.680
from what's expected, whether it's the model output

39:39.680 --> 39:42.120
or the input data into the models,

39:42.120 --> 39:44.840
we can take different actions to try and fix that.

39:44.840 --> 39:48.120
So one example is if we see that the model accuracy

39:48.120 --> 39:52.160
is slowly degrade over time, then we can retrain the model.

39:52.160 --> 39:54.080
And we have systems that have been placed as well

39:54.080 --> 39:56.600
so that these models are automatically retrained.

39:56.600 --> 39:58.200
And so when it's time to replace it,

39:58.200 --> 40:01.200
it's a pretty simple switch where we just plug

40:01.200 --> 40:03.600
and play in the new model.

40:03.600 --> 40:06.400
Other cases, it might be more complicated.

40:06.400 --> 40:10.280
So for example, if, yeah, when there's a pandemic again,

40:10.280 --> 40:13.480
our model obviously didn't generate very accurate predictions

40:13.480 --> 40:15.400
in those cases.

40:15.400 --> 40:18.600
And so that might prompt us to look into,

40:18.600 --> 40:20.760
maybe there's some features that we want to add

40:20.760 --> 40:24.960
that will help us better correct for any errors we have.

40:24.960 --> 40:28.720
And maybe, aside from just improving the model itself,

40:28.720 --> 40:30.520
maybe that tells us that we need to build

40:30.520 --> 40:33.040
more real-time systems in place.

40:33.040 --> 40:35.840
And these can be augmented with machine learning

40:35.840 --> 40:39.560
or they could just be using simple heuristics

40:39.560 --> 40:43.960
that try and detect model errors

40:43.960 --> 40:47.080
and then take different actions to account for them.

40:47.080 --> 40:48.440
And so this kind of goes back as well

40:48.440 --> 40:50.840
to how we balance up the time demand.

40:50.840 --> 40:53.040
Where, again, we have all these predictions.

40:53.040 --> 40:54.880
We do all these things ahead of time.

40:54.880 --> 40:57.480
But ultimately, in real-time, we know

40:57.480 --> 40:59.920
that we're not going to have a perfect system.

40:59.920 --> 41:03.040
And there's still going to be imbalance real-time.

41:03.040 --> 41:05.880
And so we spend a lot of time in building

41:05.880 --> 41:08.960
on this real-time monitoring, this real-time system

41:08.960 --> 41:12.960
that can take actions to correct for any issues that we see.

41:12.960 --> 41:13.960
OK.

41:13.960 --> 41:20.920
In the case of the onset of coronavirus did,

41:20.920 --> 41:24.480
I'm imagining you saw your models not working the way

41:24.480 --> 41:28.800
that they otherwise would have was

41:28.800 --> 41:35.600
were your existing model monitoring and retraining

41:35.600 --> 41:38.280
tech and procedures kind of enough?

41:38.280 --> 41:42.920
Or did you find you had to do a lot of manual overrides?

41:42.920 --> 41:48.880
To kind of make it through because it was unprecedented times?

41:48.880 --> 41:51.640
Yeah, so we definitely used a mix of relying

41:51.640 --> 41:55.560
on our existing systems that automates a lot of this

41:55.560 --> 42:01.360
monitoring, retraining, plus some manual actions

42:01.360 --> 42:03.360
on top of it as well.

42:03.360 --> 42:06.920
So a lot of times, like the day of, for example,

42:06.920 --> 42:09.680
when Shelter Place first started,

42:09.680 --> 42:12.720
or when the stimulus checks first went out,

42:12.720 --> 42:16.240
those are things that we're not able to, our systems

42:16.240 --> 42:19.640
are not always able to react as quickly as we would like.

42:19.640 --> 42:22.120
For example, if we were to retrain the model,

42:22.120 --> 42:24.080
we would need new data to come in first

42:24.080 --> 42:25.880
before we can retrain it.

42:25.880 --> 42:28.040
And so in those cases, we definitely

42:28.040 --> 42:32.200
have operators who will, again, help

42:32.200 --> 42:34.080
with monitoring our systems.

42:34.080 --> 42:37.200
And if they notice any drastic changes

42:37.200 --> 42:40.280
that our automated systems are not accounting for

42:40.280 --> 42:43.120
and are not adjusting well enough for,

42:43.120 --> 42:46.360
they will take additional actions on top of that.

42:46.360 --> 42:49.360
And so this is something that we always have in place.

42:49.360 --> 42:53.840
It's not something that we just do because of COVID.

42:53.840 --> 42:57.680
There's always interesting cases here and there

42:57.680 --> 43:01.240
where we have these super drastic events that

43:01.240 --> 43:05.200
requires additional manual intervention.

43:05.200 --> 43:09.200
And so we do still rely on a mix of automated systems,

43:09.200 --> 43:11.360
as well as human intervention.

43:11.360 --> 43:12.000
Got it.

43:12.000 --> 43:13.080
Got it.

43:13.080 --> 43:14.160
Cool.

43:14.160 --> 43:15.720
Well, Gary, thanks so much for taking

43:15.720 --> 43:18.280
the time to share some of that with us.

43:18.280 --> 43:18.560
Yeah.

43:18.560 --> 43:19.080
Thanks, Sam.

43:19.080 --> 43:19.880
Thanks for having me.

43:19.880 --> 43:20.360
Awesome.

43:20.360 --> 43:21.280
Thank you.

43:21.280 --> 43:22.200
Cool.

43:22.240 --> 43:25.120
for your own convenience

43:25.400 --> 43:29.420
to live a happy life,

43:29.420 --> 43:32.660
a happy life with your wife

43:33.500 --> 43:35.520
I'm tired

43:38.800 --> 43:40.700
I need you

43:43.120 --> 43:46.640
I don't want to give you my away

43:48.660 --> 43:50.000
Just listen

43:50.000 --> 43:51.740
or you'll just come

