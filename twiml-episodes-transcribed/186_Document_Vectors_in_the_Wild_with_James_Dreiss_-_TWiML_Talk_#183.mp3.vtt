WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:31.640
I'm your host Sam Charrington.

00:31.640 --> 00:36.280
A couple of weeks ago I spent some time at the Stratidata conference in New York City, presented

00:36.280 --> 00:40.800
by O'Reilly and Claude Error, and over the course of the next few shows we'll be bringing

00:40.800 --> 00:46.880
you my interviews with some of the awesome speakers that I had the pleasure to meet with.

00:46.880 --> 00:52.560
In this episode of our Stratidata series, we're joined by James Drice, senior data scientist

00:52.560 --> 00:55.960
at International News Syndicate Reuters.

00:55.960 --> 01:00.200
James and I sat down to discuss this talk at the conference, document vectors in the

01:00.200 --> 01:06.080
wild, building a content recommendation system, in which he details how Reuters implemented

01:06.080 --> 01:12.240
document vectors to recommend content to users of their new infinite scroll page layout.

01:12.240 --> 01:16.400
In our conversation we take a look at what document vectors are and how they're used,

01:16.400 --> 01:20.920
how they tested the accuracy of their models, and the future of embeddings for natural

01:20.920 --> 01:23.440
language processing.

01:23.440 --> 01:27.760
Before we move on, I'd like to send a quick shout out to our friends at Claude Error and

01:27.760 --> 01:34.240
Capital One for their continued support of the podcast and their sponsorship of this series.

01:34.240 --> 01:39.880
Claude Error's modern platform for machine learning and analytics optimized for the cloud

01:39.880 --> 01:47.160
that you build and deploy AI solutions at scale efficiently and securely anywhere you want.

01:47.160 --> 01:52.840
In addition, Claude Error Fast Forward Labs' expert guidance helps you realize your AI

01:52.840 --> 01:54.800
future faster.

01:54.800 --> 02:02.680
To learn more, visit Claude Error's machine learning resource center at cloudera.com-ml.

02:02.680 --> 02:07.960
At the NIPPS conference in Montreal this December, Capital One will be hosting a workshop focused

02:07.960 --> 02:14.080
on challenges and opportunities for AI in financial services and the impact of fairness,

02:14.080 --> 02:17.520
explainability, accuracy, and privacy.

02:17.520 --> 02:21.720
A call for papers is open now through October 25th.

02:21.720 --> 02:30.440
For more information on submitting, visit twimmelai.com-c-number-one-NIPPS.

02:30.440 --> 02:33.440
And now onto the show.

02:33.440 --> 02:39.700
All right, everyone, I am in New York for the Stratocomference and I am here with James

02:39.700 --> 02:40.700
Drice.

02:40.700 --> 02:43.680
James is a senior data scientist at Reuters.

02:43.680 --> 02:45.960
James, welcome to this week in machine learning and AI.

02:45.960 --> 02:46.960
Hi, Sam.

02:46.960 --> 02:47.960
It's great to be here.

02:47.960 --> 02:48.960
Thank you very much.

02:48.960 --> 02:49.960
Awesome.

02:49.960 --> 02:50.960
Awesome.

02:50.960 --> 02:53.480
So, James, you've got a background in art history.

02:53.480 --> 02:57.440
You've studied economics at graduate school.

02:57.440 --> 02:59.920
You currently work at Reuters doing data science.

02:59.920 --> 03:01.680
Tell us a little bit about your background.

03:01.680 --> 03:02.680
Yeah, sure.

03:02.680 --> 03:07.160
So I think it is sort of a weird background of the art history and English and sort of

03:07.160 --> 03:08.160
the humanities.

03:08.160 --> 03:11.040
But that's what I studied in undergrad and I sort of kicked around in those worlds for

03:11.040 --> 03:12.840
a while in New York City.

03:12.840 --> 03:18.880
And eventually I started a nonprofit with a friend that was focused on international development.

03:18.880 --> 03:20.920
And that is what led me to grad school.

03:20.920 --> 03:24.840
So I studied econometrics and statistics in London.

03:24.840 --> 03:29.920
And that was sort of my first exposure to, you know, this sort of world of data science

03:29.920 --> 03:34.760
although at the time it wasn't really talked about as much.

03:34.760 --> 03:37.520
And it also first exposed me a little bit to programming.

03:37.520 --> 03:43.040
We use something called STATA, which is like a SAS sort of, you know, statistical software.

03:43.040 --> 03:45.000
But you do do some coding.

03:45.000 --> 03:48.520
So that was a really good sort of skill acquisition period.

03:48.520 --> 03:53.320
And after school, yeah, I learned art.

03:53.320 --> 03:57.280
And there was this great job at the Met Museum in New York that opened up and they were

03:57.280 --> 04:00.000
hiring for predictive analysts.

04:00.000 --> 04:04.640
And that was, so given my art history background and also having studied what I studied, this

04:04.640 --> 04:07.720
was sort of a perfect combination of those two things.

04:07.720 --> 04:08.720
And yeah, that was great.

04:08.720 --> 04:12.720
I mean, it's, you know, you work at the museum sort of ruined me for any future office.

04:12.720 --> 04:13.720
That was awesome.

04:13.720 --> 04:15.720
Yeah, it was really short.

04:15.720 --> 04:18.960
Like, you know, like, whatever, like, I don't really care, like, you know, if you have

04:18.960 --> 04:23.200
any like, Fuseball tables you have, or a bigger like one-coil tower is because, you

04:23.200 --> 04:26.560
know, I'm like, I can go like, look at like five premieres and my, you know, my lunch

04:26.560 --> 04:27.560
break.

04:27.560 --> 04:29.240
So that was amazing.

04:29.240 --> 04:37.040
And was your, was your focus there on kind of operational analysis or marketing analysis,

04:37.040 --> 04:38.640
or was it art related?

04:38.640 --> 04:45.400
It was, it was, yeah, more, more focused on administration and specifically fundraising.

04:45.400 --> 04:50.840
So trying to match donors with the museum, people who really love the museum and have

04:50.840 --> 04:56.720
capacity to give, and yeah, it was interesting because the data there is really, really rich.

04:56.720 --> 05:02.120
You know, I work in web analytics now, but, you know, there it's, you have postal addresses

05:02.120 --> 05:04.720
and, you know, these people really love the museum too.

05:04.720 --> 05:07.360
So it's not, they're happy to work with you.

05:07.360 --> 05:08.680
So that was great.

05:08.680 --> 05:12.800
But yeah, a few years ago, I moved to Raiders and that's where I am now.

05:12.800 --> 05:19.240
So we've done a lot of stuff we had a big redesign in the website last year and built

05:19.240 --> 05:23.800
it out, the design platform and there's been a lot of stuff in NLP, obviously.

05:23.800 --> 05:29.000
And yeah, I'm here giving a talk tomorrow and that's, that's what I'm focusing on.

05:29.000 --> 05:30.000
Fantastic.

05:30.000 --> 05:34.480
And for those who don't know Raiders, what does Raiders do or what is the part of Raiders

05:34.480 --> 05:36.000
that you work with?

05:36.000 --> 05:37.000
Yeah.

05:37.000 --> 05:39.400
So Raiders is a news organization.

05:39.400 --> 05:43.840
It's an international, there's a lot of, do a lot of syndicated news.

05:43.840 --> 05:49.120
So we have reporters all over the world stationed in, you know, many, many different countries.

05:49.120 --> 05:52.720
So wherever there's breaking news report, it will be their end filing stories.

05:52.720 --> 05:53.720
And they go to different outlets.

05:53.720 --> 05:56.560
But we also obviously publish ourselves.

05:56.560 --> 06:00.840
And it's, you know, we've been around for well over 150 years, I think.

06:00.840 --> 06:01.840
Awesome, awesome.

06:01.840 --> 06:06.960
And so the talk that you're giving tomorrow is called Document Vectors in the Wild, building

06:06.960 --> 06:09.160
a content recommendation system.

06:09.160 --> 06:12.040
Tell us a little bit about the motivation for this project.

06:12.040 --> 06:13.040
Sure.

06:13.040 --> 06:18.800
So last year, we decided to redesign the website and to move to something called

06:18.800 --> 06:21.720
an infinite scroll model.

06:21.720 --> 06:25.680
A lot of online publishers have moved to this model.

06:25.680 --> 06:29.680
Basically, it's one where you click on an article and then you read it.

06:29.680 --> 06:33.760
And then you have a string of articles that come after it.

06:33.760 --> 06:36.880
So it's a really, it's a big misdemeanor because it's, you know, it's, of course, it's

06:36.880 --> 06:37.880
not an infinite.

06:37.880 --> 06:42.840
In fact, we just, we wanted to just give five to ten articles for the user.

06:42.840 --> 06:48.360
And yeah, so my job is really to figure out what articles to give to them.

06:48.360 --> 06:54.240
And specifically, so we, we don't have registration on the website, meaning we're really, we're

06:54.240 --> 07:00.440
not doing too much personalization, about 75% of our users have two or fewer articles

07:00.440 --> 07:01.920
that they read.

07:01.920 --> 07:04.720
So it's really a content recommendation system.

07:04.720 --> 07:10.400
So we did some tests previously and found out that if a user is on a page, you know,

07:10.400 --> 07:14.440
if it's a business page or tech page, they're going to probably want more of that content,

07:14.440 --> 07:15.600
which it makes sense.

07:15.600 --> 07:23.640
So we started out thinking, okay, we want to find some more content into the slide programmatically.

07:23.640 --> 07:29.680
And the other challenges were, well, you know, news is breaking and happens quickly.

07:29.680 --> 07:33.360
And editors can always provide tags metadata to the articles.

07:33.360 --> 07:38.600
So essentially, we need to do categorization just purely based on the text of the article.

07:38.600 --> 07:40.560
And maybe some tags as well.

07:40.560 --> 07:45.400
So the challenge is really how do you get at specific sub topics within these larger

07:45.400 --> 07:51.360
topics that we have like tech and business, and how do we find articles about discrimination

07:51.360 --> 07:55.240
and tech, which is not something that would necessarily be tagged by an editor.

07:55.240 --> 07:56.240
Okay.

07:56.240 --> 07:57.240
Yeah.

07:57.240 --> 08:01.280
And so presumably based on the talk title, you did this using document vectors.

08:01.280 --> 08:02.280
Yes.

08:02.280 --> 08:04.440
We've talked quite a bit about word vectors.

08:04.440 --> 08:06.680
What's a document vector?

08:06.680 --> 08:08.600
It's very similar to a word vector.

08:08.600 --> 08:10.480
It's sort of like a sidecar or two word vector.

08:10.480 --> 08:14.000
In fact, the document vector is treated as another word.

08:14.000 --> 08:21.080
So yeah, we, you know, this is like the problem in NLP is that if you just tokenize tags

08:21.080 --> 08:25.400
and you're just looking at the trading the words as these atomic objects, you're losing

08:25.400 --> 08:31.120
so much information, you know, if a build a vector that has the word president and another

08:31.120 --> 08:35.960
one that has the word Trump, you know, those two vectors can't, they don't know that Trump

08:35.960 --> 08:40.280
is president, which is, you know, good for them, but that's, we need to know that sort

08:40.280 --> 08:41.280
of thing.

08:41.280 --> 08:47.600
So, yeah, I mean, word embeddings, which encode semantic meeting, get at this, but the

08:47.600 --> 08:52.560
challenges for us were that we have, the length of our articles are highly variable.

08:52.560 --> 08:55.600
We have really short articles, really long articles.

08:55.600 --> 09:00.040
So doing something like just taking the first hundred words of an article and taking

09:00.040 --> 09:03.720
the embeddings for those words, wasn't really going to cut it.

09:03.720 --> 09:10.040
And you know, having done some research into document vectors, I also knew that performance

09:10.040 --> 09:15.160
in these sorts of tasks was higher than just using, you know, word embeddings that were

09:15.160 --> 09:19.160
cut off at a certain length or average word embeddings or that sort of thing.

09:19.160 --> 09:21.040
So this is something we wanted to explore.

09:21.040 --> 09:25.720
Is that pretty typical for using word embeddings to cut them off at a certain lengthwise

09:25.720 --> 09:27.320
their requirement to do that?

09:27.320 --> 09:31.840
I think, well, if you wanted to compare two articles that were different lengths, you

09:31.840 --> 09:35.240
had to, you know, they had to have similar sizes, the same sizes.

09:35.240 --> 09:43.960
So I'm not sure how wide that is in the industry, but document vectors allow you to obtain

09:43.960 --> 09:47.880
vectors that are the same size, where the articles would be different lengths.

09:47.880 --> 09:52.040
And so how do you go about creating these document vectors?

09:52.040 --> 09:58.120
So word vectors, the way, you know, I'm sure your audience knows how they are graded, but

09:58.120 --> 09:59.520
it's, you know, they're very similar.

09:59.520 --> 10:01.520
Document vectors are very, happen in very similar ways.

10:01.520 --> 10:07.720
Essentially, you know, word vectors are getting at a semantic meeting of words.

10:07.720 --> 10:13.400
I usually call them, I treat them as, you know, their address is basically in this multi-dimensional

10:13.400 --> 10:14.400
space.

10:14.400 --> 10:19.240
So you know that the word dog and the word cat are close together because the model on

10:19.240 --> 10:24.400
which they were trained determined that their co-occurrence happens frequently.

10:24.400 --> 10:29.800
So in the model specifically, it's calculating the probability of co-occurrence and that's

10:29.800 --> 10:32.040
the output layer.

10:32.040 --> 10:36.760
And the middle layer is the embedding layer and that layer is being maximized.

10:36.760 --> 10:42.160
So it's sort of set up as this fake prediction task where you're predicting words from

10:42.160 --> 10:44.640
context or the opposite.

10:44.640 --> 10:49.520
And as a result, you have these weights that are richer with all that semantic information.

10:49.520 --> 10:53.280
Now word, excuse me, document vectors are very similar.

10:53.280 --> 10:57.560
You're doing, the training is virtually the same, but you're just adding an additional

10:57.560 --> 11:03.400
vector at the input layer that is representative of the document.

11:03.400 --> 11:08.800
So you train in a similar way, you have a context window, you sort of scan across the

11:08.800 --> 11:14.160
article, the document, you know, doing the predictions.

11:14.160 --> 11:17.480
And at the end, after you've gone through the entire corpus, you have this additional

11:17.480 --> 11:21.160
vector that is sort of picked up all of the semantic information that was not picked

11:21.160 --> 11:23.200
up by the word vectors.

11:23.200 --> 11:28.640
And you can make these comparisons between articles, between documents, because all the

11:28.640 --> 11:31.000
documents have shared context and words.

11:31.000 --> 11:36.160
So if they have shared context, then the article should be similar.

11:36.160 --> 11:41.560
So you're doing, you're able to do kind of similar vector operations on these documents.

11:41.560 --> 11:47.640
You know, there's the classic word embedding, our word vector examples like, you know,

11:47.640 --> 11:51.760
man, king, woman, queen, kind of thing, you're able to do those similar kinds of things

11:51.760 --> 11:52.760
with documents.

11:52.760 --> 11:53.760
Yeah.

11:53.760 --> 12:00.840
You're able to compare to articles where they don't share any, to any pieces of text that

12:00.840 --> 12:04.200
may not share any words at all in maybe different lengths, and you can get it.

12:04.200 --> 12:09.920
You can know that they have similar meaning, and that's how we got at these subtopics.

12:09.920 --> 12:13.400
There are some sort of peculiarities with them, especially with inference.

12:13.400 --> 12:18.880
So when you want to make a prediction for a new document that you haven't seen before,

12:18.880 --> 12:22.120
you're essentially running a new training step, an additional training step.

12:22.120 --> 12:26.960
Or maybe many 10 to 20 training steps depending on how many of us you had when you're training

12:26.960 --> 12:29.240
the original model.

12:29.240 --> 12:33.760
You're also holding the word vectors and the output weights constant.

12:33.760 --> 12:39.040
So you hold this constant, you do an additional training step, and this new document vector

12:39.040 --> 12:46.200
that was initialized randomly comes to, you know, it essentially picks up all the information

12:46.200 --> 12:50.520
that is present in the context and the output layer.

12:50.520 --> 12:52.040
Can you elaborate on that?

12:52.040 --> 12:58.000
This is when you're during inference time, you're also, there's a training step?

12:58.000 --> 13:02.080
Yeah, there is.

13:02.080 --> 13:09.120
Essentially, so that new vector is initialized randomly, the other weights are held constant.

13:09.120 --> 13:11.520
And it's sort of strange.

13:11.520 --> 13:15.280
Essentially, you're going to have a new document vector that you're obtaining is going

13:15.280 --> 13:21.200
to be a little different each time if you do new references, which is a little strange,

13:21.200 --> 13:27.840
but there are ways of getting to sort of do like sanity checks to know that, okay, this

13:27.840 --> 13:33.640
new document vector that I just inferred should be similar to itself essentially.

13:33.640 --> 13:39.480
So once sort of sanity check is, you have your model, you've trained it, make inferences

13:39.480 --> 13:46.240
on all the training documents that you trained on, and then ensure that those new inferred

13:46.240 --> 13:50.120
document vectors are, their nearest neighbors are themselves.

13:50.120 --> 13:54.360
So if that's the case, then your model should be trained correctly.

13:54.360 --> 14:01.720
And so how did you get from these document vectors to the categories, to the larger topic

14:01.720 --> 14:02.720
categories?

14:02.720 --> 14:05.440
Or to the subcategories?

14:05.440 --> 14:11.040
So they're not really, we don't have labels for the subcategories, it just sort of

14:11.040 --> 14:12.040
happens.

14:12.040 --> 14:14.560
It's a result of cutting the model, yeah.

14:14.560 --> 14:20.520
Clustering in this document space and then manually associating a label with individual

14:20.520 --> 14:21.520
clusters.

14:21.520 --> 14:27.120
Yeah, so we put the unsupervised learning model in production, which is, I think, some

14:27.120 --> 14:33.360
unique and mostly often embeddings are used for downstream tasks as part of the future

14:33.360 --> 14:37.760
of the model, but we're actually using the cluster strictly.

14:37.760 --> 14:43.400
We got at, we tried to ensure that it was accurate and I can get into that, but one

14:43.400 --> 14:51.360
thing that we did, so we're only make, when we rank the article scrolls, we're ensuring

14:51.360 --> 14:56.600
we're just, we're just pulling all tech articles, for instance, and then within tech we rank,

14:56.600 --> 15:02.240
okay, based on the very, the article that these are requested, what are the nearest articles

15:02.240 --> 15:05.600
that are, you know, within the last 24 hours that are also tech, and, you know, there's

15:05.600 --> 15:08.280
also like a popularity filter there as well, so.

15:08.280 --> 15:14.000
So the example you gave earlier where you were interested in a subtopic discrimination

15:14.000 --> 15:19.440
in tech, for example, that subtopic is never explicitly identified.

15:19.440 --> 15:24.080
It's just based on, it's determined based on this, the document space.

15:24.080 --> 15:25.080
Right, exactly.

15:25.080 --> 15:30.560
And we can go back and look at the labels that were applied by editorial after the fact

15:30.560 --> 15:35.520
and get that, that sort of thing, but, you know, similarly to something like LDI, like

15:35.520 --> 15:39.560
it's not, you know, that's not, there's not an automatic assignment of label, like this

15:39.560 --> 15:40.560
is discrimination tech.

15:40.560 --> 15:44.760
You have to sort of, if you're looking at trying to identify subtopics in LDI, you're

15:44.760 --> 15:49.000
really just looking at the words, you know, that were assigned for that topic.

15:49.000 --> 15:51.520
So, it's a similar sort of thing.

15:51.520 --> 15:56.200
You were mentioning some of the testing that you were doing around this.

15:56.200 --> 16:02.720
Yeah, it was interesting, so, you know, measuring performance of unsupervised learning models

16:02.720 --> 16:08.080
is always a little tricky, there's always some eyeballing that goes, goes on, you know,

16:08.080 --> 16:12.560
like something like doing the elbow method for k-means, like that's always been sort of

16:12.560 --> 16:13.560
hard for me.

16:13.560 --> 16:16.160
It's never actually like, you never get like a true elbow, like to determine the right

16:16.160 --> 16:20.360
number of clusters, you know, there should be even like this break and in the graph of

16:20.360 --> 16:24.960
clusters versus how dispersed they are.

16:24.960 --> 16:30.320
But, you know, looking through the literature and also remembering other methods, something

16:30.320 --> 16:37.560
like a silhouette index, which is unsupervised learning metric, where you're essentially comparing

16:37.560 --> 16:42.840
the average distance of a point, a data point, and between it and its own cluster and its

16:42.840 --> 16:46.840
neighboring clusters, and you're trying to get at how close it is between its own cluster

16:46.840 --> 16:51.000
and its neighboring ones, and you're assigning accuracy based on that.

16:51.000 --> 16:57.360
In one of the Doctavec papers, the authors used something called triplet accuracy, where

16:57.360 --> 17:04.240
they took Wikipedia articles and found articles that were in the same topic, and then they

17:04.240 --> 17:08.240
took a randomly drawn non-topic article.

17:08.240 --> 17:13.560
And if the distance between the two similar topic articles was closer than the non-topic

17:13.560 --> 17:17.520
article, then that counted as an accuracy point for the model.

17:17.520 --> 17:18.520
Okay.

17:18.520 --> 17:19.520
So we did something similar.

17:19.520 --> 17:26.080
We knew that we wanted to do subtopics, so, you know, we, we, for the document doctor

17:26.080 --> 17:30.560
model, would take two articles in tech, and one that was not tech.

17:30.560 --> 17:36.200
And if it determined that those two same articles were closer than the one in business or,

17:36.200 --> 17:39.920
you know, sports or something, then that counted as a, as a point to the accuracy.

17:39.920 --> 17:45.960
And we ended up with, I think it was about 77%, accuracy, which is very close to what the

17:45.960 --> 17:49.560
authors who devised the triplet accuracy down as well.

17:49.560 --> 17:56.120
So you're basing this model on accuracy at the category level, but ultimately you're

17:56.120 --> 17:59.960
trying to make inferences at a sub-category level.

17:59.960 --> 18:05.120
Did that play into, did that play into it at all?

18:05.120 --> 18:06.560
In terms of looking at accuracy?

18:06.560 --> 18:11.120
In terms of looking at accuracy or the model, you know, construction or performance?

18:11.120 --> 18:16.680
Yeah, we definitely did some, some sort of, we couldn't have done too many, but yeah,

18:16.680 --> 18:21.720
we looked at, you know, just the performance generally, relying on the editors as well,

18:21.720 --> 18:26.520
to sort of say, like, well, this is a good, you know, this is a good match, this isn't.

18:26.520 --> 18:31.320
But ultimately, the real test of any models when you put in productions who did performance

18:31.320 --> 18:36.440
and if it's performing well, you know, if the topic assigned it is not good, then, you

18:36.440 --> 18:39.960
know, it should not really, it should perform less well than your controller, your other

18:39.960 --> 18:40.960
test branch.

18:40.960 --> 18:43.440
So that was the ultimate test for us.

18:43.440 --> 18:46.160
And so what was the metric for that test?

18:46.160 --> 18:48.520
What are you ultimately trying to drive?

18:48.520 --> 18:52.880
We, so ultimately we want to drive engagement on our site.

18:52.880 --> 18:57.920
There's a lot of ways of, a lot of ways we can optimize, you know, the way users interact

18:57.920 --> 19:04.280
with their website, but engagement is the sort of catch all thing that if you try to get

19:04.280 --> 19:08.160
at that, then you're going to lift all the other ships of, you know, whatever, looking

19:08.160 --> 19:10.800
at ads and engaging with the content itself.

19:10.800 --> 19:16.360
So, so that was ultimately what we were trying to get at in that, their proxies for that.

19:16.360 --> 19:22.200
So specifically how deep an art, a user would get into the article scroll and also how deep

19:22.200 --> 19:24.400
they're getting into the articles themselves.

19:24.400 --> 19:30.000
We did three different test branches, one where we're having similar scrolls and one

19:30.000 --> 19:34.320
where we have, where we have, we have what I was calling dissimilar scrolls.

19:34.320 --> 19:40.440
So I had this sort of theory that users would get sort of tired of reading the same content

19:40.440 --> 19:44.840
so if you were reading an article about like Trump's cabinet was, maybe you want to move

19:44.840 --> 19:47.760
on to something else after you read that article.

19:47.760 --> 19:49.640
So that was the intuition behind that.

19:49.640 --> 19:55.440
So we would, and essentially that's same topic articles just sorted in reverse cosine order,

19:55.440 --> 20:00.600
which essentially what you're obtaining is there's a lot of randomness there.

20:00.600 --> 20:06.160
It sort of doesn't seem, you know, you can't immediately tell that two articles are very

20:06.160 --> 20:07.160
dissimilar.

20:07.160 --> 20:08.160
It's sort of a strange thing.

20:08.160 --> 20:11.880
They're just going to seem like that they were randomly drawn.

20:11.880 --> 20:17.880
So that was one test branch and then as a control, we had top of these articles.

20:17.880 --> 20:21.720
And yeah, the end result was sort of, you know, what we expected, which is good, which

20:21.720 --> 20:27.040
is that similar articles really upformed the scrolls outperform both of these, these

20:27.040 --> 20:29.240
other test branches.

20:29.240 --> 20:36.200
And within topic categories as well, things like sports and culture, those performed

20:36.200 --> 20:37.520
especially well.

20:37.520 --> 20:40.560
Those are sort of on writers, they're a little harder to find on our sites.

20:40.560 --> 20:47.000
So if users are going to those topics, it's likely that, you know, they're going to

20:47.000 --> 20:48.640
be highly engaged.

20:48.640 --> 20:51.760
So that was the intuition behind that as well.

20:51.760 --> 20:59.280
And to what, to what degree did the similar school model outperform the other models?

20:59.280 --> 21:04.640
It was a few fractions of percentage, but it's, you know, when you're looking at statistically

21:04.640 --> 21:08.120
significant results, that's what you would expect.

21:08.120 --> 21:15.160
We were lucky in that, so essentially every article page was a randomized test.

21:15.160 --> 21:18.760
So user comes to the page and they're served one of the three test branches.

21:18.760 --> 21:21.600
And that randomization happens at the article level.

21:21.600 --> 21:24.680
So we ran hundreds of tests.

21:24.680 --> 21:30.080
And that was the real, you know, no matter the, the lift, I mean, that was very important

21:30.080 --> 21:31.360
as well, of course.

21:31.360 --> 21:36.920
But in terms of like winning pages, the similar scrolls blew the other two out of the water.

21:36.920 --> 21:41.600
So that was, that was a very good, similarly about that winning pages.

21:41.600 --> 21:48.080
That the one test branch was significant over the other two in terms of these metrics

21:48.080 --> 21:49.080
that I mentioned.

21:49.080 --> 21:51.120
So that was counted as a winner.

21:51.120 --> 21:54.640
And then if you look at all the pages in aggregate, that was the result.

21:54.640 --> 21:59.760
A couple of random things I remember from flipping through your presentation, there was a reference

21:59.760 --> 22:01.400
to Kung Fifi.

22:01.400 --> 22:02.400
I know.

22:02.400 --> 22:10.080
I was trying to, I was like, I really want to use this, this tweet as an example, you know,

22:10.080 --> 22:12.400
because a lot of people, the wedding events have been around for a while now.

22:12.400 --> 22:15.120
I wanted to sort of, I don't know, live in another bit.

22:15.120 --> 22:19.480
But yeah, I, Kung Fifi, I don't know what would add or subtract, what vectors would add

22:19.480 --> 22:20.840
or subtract to, to equal that.

22:20.840 --> 22:23.280
I think it's this, it's completely nonsense.

22:23.280 --> 22:28.360
So I know, I want to dig into that a little bit more.

22:28.360 --> 22:32.040
I'm glad that you pronounce it the way I'm going to pronounce it, because I'm not entirely

22:32.040 --> 22:33.040
sure.

22:33.040 --> 22:39.080
So I think I pronounce it differently every time I say it, which is not very often.

22:39.080 --> 22:42.680
Well, that's NLP is hard for the story, I mean, this is like, we're getting at this,

22:42.680 --> 22:48.680
like what, you know, pronunciation, meaning, like this is, yeah, I mean, someone described

22:48.680 --> 22:53.200
English to me the other day, and this is any language, but there's a connotative sort

22:53.200 --> 22:57.640
of system, and it really gets at it for me, like in a pithy way, like, it's all built

22:57.640 --> 23:02.920
around these connotations, everything has higher, higher meaning, you know, and they're

23:02.920 --> 23:08.560
also the, the, the meaning may depend on cultural associations, yeah, all sorts of things.

23:08.560 --> 23:14.400
What, what kind of interesting or surprising really things that you have, did you learn

23:14.400 --> 23:16.560
along the way with this project?

23:16.560 --> 23:20.960
Probably the most surprising was that, you know, people were just sort of consumed, they,

23:20.960 --> 23:24.280
they come to a website that, you know, in terms of news, at least, they really go after

23:24.280 --> 23:26.200
one subject.

23:26.200 --> 23:29.160
And I think that that makes sense, and they've seen sort of the development of, like,

23:29.160 --> 23:33.600
the media ecosystem generally, and, you know, it's, they have, like, these one track minds

23:33.600 --> 23:38.440
and they keep delivering on, you know, certain subjects over a certain time period.

23:38.440 --> 23:44.080
So that was, I don't know if it's surprising, but maybe, like, I don't know, but disheartening.

23:44.080 --> 23:50.440
You know, I was hoping that, you know, we want to get a sort of variety, and, you know,

23:50.440 --> 23:54.160
especially when we have, like, these long investigative pieces that, during those

23:54.160 --> 23:58.640
events, have worked on for a while, you know, we want to sort of get at, when is the

23:58.640 --> 24:01.240
best time to serve them?

24:01.240 --> 24:06.040
But I think that is, to do that, you really, that's that personalization.

24:06.040 --> 24:09.560
And we do want to get more into personalization, but it is difficult given that, you know, we're

24:09.560 --> 24:12.520
entirely cookie based, and we don't have registration.

24:12.520 --> 24:18.400
Yeah, really, I think speaks to a lot of what we see with the whole, you know, filter

24:18.400 --> 24:23.840
bubble kind of situation that if you, if you see such strong results by serving up more

24:23.840 --> 24:24.840
of the same.

24:24.840 --> 24:28.800
You know, you want to see the same kind of results and that's just, we're all getting

24:28.800 --> 24:30.800
every time we're the same, right?

24:30.800 --> 24:31.800
Exactly.

24:31.800 --> 24:32.800
Yeah, yeah.

24:32.800 --> 24:33.800
But what can you do?

24:33.800 --> 24:34.800
I don't know.

24:34.800 --> 24:37.800
Talk to the editors about that one.

24:37.800 --> 24:38.800
Yeah, so.

24:38.800 --> 24:42.400
You mentioned inference, stochasticity at some point in your talk.

24:42.400 --> 24:43.400
What was that reference?

24:43.400 --> 24:49.200
Yeah, that was, so I was trying to get this, it's really about, when you make an inference

24:49.200 --> 24:50.720
on a new document vector.

24:50.720 --> 24:56.320
So it's initialized randomly, and if you do the inference multiple times, it's going

24:56.320 --> 24:58.760
to be a bit random each time.

24:58.760 --> 25:01.400
And that was a bit strange to me.

25:01.400 --> 25:05.520
You can look at the variance of the vector, the document vector, but, you know, it's always

25:05.520 --> 25:08.240
going to be a little different.

25:08.240 --> 25:14.560
We tried to get at this by just having a higher number of training iterations.

25:14.560 --> 25:19.440
And that was, I think, especially important because we were working with 100-length vectors

25:19.440 --> 25:20.440
for a number of reasons.

25:20.440 --> 25:21.440
I mean, we looked at it.

25:21.440 --> 25:26.760
I looked at longer vectors, but surprisingly, they didn't really perform too much better.

25:26.760 --> 25:32.000
So given that would have just taken up more memory, we went with the shorter one.

25:32.000 --> 25:33.000
And it was unusual.

25:33.000 --> 25:37.480
I mean, I was actually trying to, I was looking into why shorter vectors, you know, there's

25:37.480 --> 25:45.480
a limit to how long they can be and why shorter vectors tend to perform better.

25:45.480 --> 25:48.560
And it's, no one really has really gotten at that.

25:48.560 --> 25:52.680
And maybe something about overtraining, I don't know.

25:52.680 --> 25:57.640
But just surprising, that's 100 dimensions is commonly used for word vectors.

25:57.640 --> 26:03.960
And I would think that for a document, you'd want kind of a richer space.

26:03.960 --> 26:07.120
And so you'd want a lot more, a lot higher dimension.

26:07.120 --> 26:11.040
Yeah, I agree, but that's not what we saw.

26:11.040 --> 26:13.120
So which was fine.

26:13.120 --> 26:19.920
And in terms of the SOCasticity, there is another source of randomness in the context window.

26:19.920 --> 26:24.360
So we use Gensum for the document vectors and the way the author is simple.

26:24.360 --> 26:25.360
What is that?

26:25.360 --> 26:33.160
It's a topic modeling library in Python, which is really, really terrific, it's very fast.

26:33.160 --> 26:38.080
And yeah, so it handles LDA and word vectors and document vectors.

26:38.080 --> 26:42.400
But the way that they implemented it was, so when you're training, there's a context

26:42.400 --> 26:44.360
window that you can specify.

26:44.360 --> 26:49.040
But it doesn't always draw, say, if you say, okay, well, five words should be the window.

26:49.040 --> 26:50.240
It doesn't always draw five words.

26:50.240 --> 26:57.320
It draws randomly based on how, so the near words, the word, the center of the window

26:57.320 --> 27:00.720
will be, there's a higher likelihood that they'll be drawn.

27:00.720 --> 27:05.880
And this is how the original word detect authors implemented there, the model.

27:05.880 --> 27:07.120
So that's what they did.

27:07.120 --> 27:11.960
So that is also, even if you weren't, you know, even if you could see the document vector

27:11.960 --> 27:14.640
at inference, you would still have the source of randomness.

27:14.640 --> 27:20.760
So, yeah, I mean, you can, another tactic would be to average the vectors, but, you know,

27:20.760 --> 27:28.200
we did the sanity check where you're comparing the inferred vectors to the vectors of training.

27:28.200 --> 27:33.120
And in every case, they were, you know, that you came up as the result where, you know,

27:33.120 --> 27:34.640
the nearest neighbor was the, themselves.

27:34.640 --> 27:39.080
So that was, that was the check and we figured we didn't have to do that.

27:39.080 --> 27:40.080
So.

27:40.080 --> 27:46.120
I still have some fuzziness around the inference thing in this, in this case, what is the,

27:46.120 --> 27:50.440
what's the input and what's the output of this inference step?

27:50.440 --> 27:56.840
So the input is, is all the vectors that were trained previously.

27:56.840 --> 28:01.120
So it's really, it's not too complicated because this is, these are really pretty simple

28:01.120 --> 28:02.120
models.

28:02.120 --> 28:03.120
Mm-hmm.

28:03.120 --> 28:08.040
Yeah, you're just keeping constant the words that were trained.

28:08.040 --> 28:11.680
So you, you're only looking up the words that are in a particular document they were trying

28:11.680 --> 28:13.000
to infer.

28:13.000 --> 28:17.160
So those, you know, those vectors already.

28:17.160 --> 28:23.560
And you know the output, the probability of co-carns for word-to-word pairings with those

28:23.560 --> 28:29.560
two weights established, just their gradient descent, the, the vector that can change,

28:29.560 --> 28:33.920
which is the document vector that was newly initialized, that will change, that will sort

28:33.920 --> 28:37.320
of converge to the result they found in training.

28:37.320 --> 28:38.320
Okay.

28:38.320 --> 28:41.960
Yeah, I don't know why I was, why I was kind of weighing out on that.

28:41.960 --> 28:48.480
So basically you, you trained this set of document vectors based on some number of articles.

28:48.480 --> 28:50.600
I think it was 350,000 or something.

28:50.600 --> 28:51.600
Yeah.

28:51.600 --> 28:52.600
Mm-hmm.

28:52.600 --> 28:56.640
And then you've got some new article that was just someone, some editor just hit Publish

28:56.640 --> 28:58.120
or Submit or whatever.

28:58.120 --> 29:01.280
You've got this new document you're trying to figure out where it fits and you need to

29:01.280 --> 29:04.560
produce a document vector for it and that's the inference step.

29:04.560 --> 29:05.560
Yeah.

29:05.560 --> 29:06.560
Exactly.

29:06.560 --> 29:11.320
But it's quite, another way was, because we're doing this in production, another way was,

29:11.320 --> 29:14.040
you know, just speed at which you can infer.

29:14.040 --> 29:19.280
But it was, it's quite fast, it was less than 10 milliseconds and we do this asynchronously.

29:19.280 --> 29:25.920
So there isn't, you know, if you're going to see a page, the inference has already been

29:25.920 --> 29:26.920
done.

29:26.920 --> 29:28.720
So we're just pulling that from a database, essentially.

29:28.720 --> 29:34.360
And we also are, this, we can also were caching frequently and we can catch at the future

29:34.360 --> 29:35.360
level.

29:35.360 --> 29:40.400
If your request is made for a particular article, I mean, if the request is, okay, we want

29:40.400 --> 29:43.760
to sell in our scroll, if it's not cash, we'll just pull it from the database and it's

29:43.760 --> 29:44.760
very fast.

29:44.760 --> 29:49.680
But after the fact that response is, that's, spring of articles, this is cash so we can

29:49.680 --> 29:54.080
just serve it subsequently to users who come after that first one.

29:54.080 --> 30:01.360
Meaning for a given article, you cash the preferred similar scroll articles, yes, exactly.

30:01.360 --> 30:07.720
And do you, do you cash kind of the exact order or do you cash of, you know, some number

30:07.720 --> 30:11.480
of similar ones in a randomized or something like that?

30:11.480 --> 30:13.400
It's the exact response.

30:13.400 --> 30:17.320
So yeah, there's a, there's a filtering step where, yeah, we're, like, we're only pulling

30:17.320 --> 30:23.800
from our, so the, the tech stack is, and this is sort of one of the more interesting parts

30:23.800 --> 30:27.480
in this whole development is that we had to build out a data science platform.

30:27.480 --> 30:31.240
And it was great because it's, it's just a Python web app and it's serving, knowing

30:31.240 --> 30:33.360
you need users today.

30:33.360 --> 30:37.560
So to get actually, you know, to come upon the realization that you can, you know, build

30:37.560 --> 30:41.080
a Python web app and scale in that way, that was great.

30:41.080 --> 30:47.240
And is it, is it kind of a spoke Python or something like Django or something?

30:47.240 --> 30:53.200
We use a web app framework called Pyramid, which is, it's like Django, except there

30:53.200 --> 30:57.040
are significant differences, one of which is, you can use something called SQL Alchemy,

30:57.040 --> 31:04.200
which is a, allows you to do database queries by writing Python, so ORM.

31:04.200 --> 31:05.880
And that's very powerful.

31:05.880 --> 31:09.160
So that was one of the main reasons for going at that.

31:09.160 --> 31:16.840
Other than that, we use Amazon, AWS, we have a MySQL database that stores all of the

31:16.840 --> 31:18.240
articles.

31:18.240 --> 31:23.520
And then we use RDS, a Redis cache for responses.

31:23.520 --> 31:24.440
And that also stores.

31:24.440 --> 31:29.600
So when we do, we do personalize, to some extent, for like sponsored stories, and, you

31:29.600 --> 31:34.280
know, we serve up sponsored stories based on where users in the world.

31:34.280 --> 31:36.880
So that's a user level feature.

31:36.880 --> 31:37.880
So we do do that.

31:37.880 --> 31:40.760
And there's, Redis is caching those responses as well.

31:40.760 --> 31:43.200
So we're able to scale with the users as well.

31:43.200 --> 31:44.200
Okay.

31:44.200 --> 31:49.000
So you've got this Python based web framework website.

31:49.000 --> 31:53.240
And it sounds like you're saying kind of starting this effort up.

31:53.240 --> 31:59.200
You didn't have a data science stack built up around this, this website around the project.

31:59.200 --> 32:05.680
So what were, what were some of the steps in thinking it went into building up that stack?

32:05.680 --> 32:08.240
It sort of was built out feature by feature.

32:08.240 --> 32:13.200
The original feature was making recommendations for videos.

32:13.200 --> 32:18.440
Because so I started with, at Reuters with one of their apps called Reuters TV, okay.

32:18.440 --> 32:22.560
And we put the Reuters TV player on the website.

32:22.560 --> 32:25.520
And we wanted to, so there's algorithms that go into that.

32:25.520 --> 32:29.880
There's a program, something called a program assembly algorithm that takes all the available

32:29.880 --> 32:34.720
videos that we can show and builds the best program based on the time that the user selects.

32:34.720 --> 32:36.840
And there's other sort of recommendations that go into that.

32:36.840 --> 32:44.120
So we needed to have a system to build that for the website and also for Reuters TV.

32:44.120 --> 32:49.680
Meaning a user goes to the website and to some TV section and they say how long they

32:49.680 --> 32:50.680
intend to watch.

32:50.680 --> 32:54.000
Yeah, that's one of the key features of the app.

32:54.000 --> 32:55.000
Okay.

32:55.000 --> 32:59.080
And that was one of the, that was a really interesting data science problem as well, because it's

32:59.080 --> 33:05.680
actually, so to determine, you know, based on these 25 stories that have three links each

33:05.680 --> 33:07.480
of their variants.

33:07.480 --> 33:11.480
How do you, you know, if user wants to watch a program that's 10 minutes long, how do

33:11.480 --> 33:15.360
you take all of that content and get as close to 10 minutes as possible without going

33:15.360 --> 33:16.360
over?

33:16.360 --> 33:20.360
And how do you also make sure that you're filling the editorial requests of, well, we

33:20.360 --> 33:24.320
want to show X number of world stories and this many culture stories and that sort of

33:24.320 --> 33:25.320
thing.

33:25.320 --> 33:27.600
Kind of like we did been packing kind of thing.

33:27.600 --> 33:28.600
Mm-hmm.

33:28.600 --> 33:29.600
Yeah.

33:29.600 --> 33:30.600
It's called a napsack problem.

33:30.600 --> 33:34.200
And it sort of comes up in, you know, like these coding interviews where you think,

33:34.200 --> 33:35.800
like, I'm never going to have to use this.

33:35.800 --> 33:36.800
Right.

33:36.800 --> 33:41.040
But it was, I used it and it was, and there was some sort of new, what I thought were

33:41.040 --> 33:42.200
new things that went into it.

33:42.200 --> 33:47.400
Like there's a multiple choice component where you're choosing because each main story

33:47.400 --> 33:48.480
has three different variants.

33:48.480 --> 33:58.680
So that was very interesting, but yeah, the framework was really built out, yeah, feature

33:58.680 --> 33:59.680
by feature.

33:59.680 --> 34:03.040
So there's that, there's the scroll model.

34:03.040 --> 34:09.000
Meaning, so you started with this video, we're talking features at that level that, you

34:09.000 --> 34:15.320
know, there's a, the framework has this video optimization feature that scroll optimization

34:15.320 --> 34:20.880
feature, or are you talking about lower level features that support the building of these

34:20.880 --> 34:24.520
different higher level features, I guess.

34:24.520 --> 34:25.520
I guess, I guess both.

34:25.520 --> 34:26.920
I mean, it's all contained there.

34:26.920 --> 34:31.040
So even the models, models are loaded into memory, which we're trying to actually get

34:31.040 --> 34:35.880
away from that and build out another framework where requests were just made to a machine

34:35.880 --> 34:41.880
learning app for, you know, give us a scroll for this article and the rest of the business

34:41.880 --> 34:49.240
logic that was built out during this building, the state of science framework is still there.

34:49.240 --> 34:53.960
So yeah, there's that there's other, I'm trying to think of other data science things

34:53.960 --> 34:56.200
that live on this, this web app.

34:56.200 --> 35:04.600
We do something called a trending people module, so where we're doing name entity recognition

35:04.600 --> 35:08.840
on articles and we're also looking at how articles are trending.

35:08.840 --> 35:15.960
And we have a little module on one of the sites on the website where we show people who

35:15.960 --> 35:20.440
are trending and that's just based on the articles that they've been in and the fact that

35:20.440 --> 35:24.680
we've determined, okay, this person is being referenced and also that they're the subject

35:24.680 --> 35:26.520
of this lead of the article.

35:26.520 --> 35:27.520
Okay.

35:27.520 --> 35:28.520
Yeah.

35:28.520 --> 35:34.480
And are you, are you doing that using that same document toolkit that you mentioned or

35:34.480 --> 35:37.200
how are you doing the any our stuff?

35:37.200 --> 35:44.880
Well, we have some in-house and some using spacey, which is sort of a general really great

35:44.880 --> 35:51.820
NLP library, but Thomson Reuters, which is the larger company of Reuters, they have, they

35:51.820 --> 35:56.960
built on a really terrific name entity system, so for any given article, they will tell

35:56.960 --> 36:05.160
you who's in itch and that's done in, you know, in the typical ways, but from that, there's

36:05.160 --> 36:10.920
also something that I built out was determining, you know, we don't want to just pull out

36:10.920 --> 36:15.000
all the people in an article and show them like, okay, all these people are trending.

36:15.000 --> 36:18.920
The task is really, okay, well, we know these people are in the article, but who are the

36:18.920 --> 36:20.720
main subjects of it?

36:20.720 --> 36:25.560
And that is, that's a task of dependency parsing and saying, okay, well, if you'd like

36:25.560 --> 36:30.240
at the lead of the article, this person is performing the action on this person.

36:30.240 --> 36:35.560
So let's take the subject and say that this person's trending and that's sort of how we

36:35.560 --> 36:36.880
get at that.

36:36.880 --> 36:42.440
And so you've got these different components that you use, you mentioned spacey, and I forget

36:42.440 --> 36:44.680
the name of the other Gremlin?

36:44.680 --> 36:45.680
Jensen.

36:45.680 --> 36:46.680
Jensen, Jensen.

36:46.680 --> 36:48.680
Maybe Jensen, I'm not sure.

36:48.680 --> 36:49.680
Jensen or Jensen?

36:49.680 --> 36:50.680
Jensen again.

36:50.680 --> 36:51.680
Okay.

36:51.680 --> 36:52.680
Perfect.

36:52.680 --> 36:53.680
Yeah.

36:53.680 --> 36:58.960
You describe this kind of data science platform, trying to get at kind of what really

36:58.960 --> 37:04.200
characterizes this platform is at this high, these higher level features that you're offering

37:04.200 --> 37:10.200
through the site or are there lower level components that you've pulled together that

37:10.200 --> 37:13.680
accelerate the ability to make the N plus 1 feature?

37:13.680 --> 37:14.680
Mm-hm.

37:14.680 --> 37:18.240
I think it's probably the features that characterize the web app.

37:18.240 --> 37:19.240
Okay.

37:19.240 --> 37:27.000
Yeah, I mean, just thinking in terms of the end users, that's sort of what they care about.

37:27.000 --> 37:28.000
And who are they?

37:28.000 --> 37:30.000
Are they developers on the web app?

37:30.000 --> 37:31.000
Mm-hm.

37:31.000 --> 37:37.080
Oh, they're, so I built the web app, but they're front-end, mostly, developers.

37:37.080 --> 37:44.440
But yeah, I mean, if there's the sort of the check that goes into the modeling, the lower

37:44.440 --> 37:49.080
level stuff, yeah, I mean, I think down the line that could be something that, you know,

37:49.080 --> 37:55.480
we want to try to build out and Riders is, you know, we have a lot of resources and even

37:55.480 --> 37:57.760
though the team is very small.

37:57.760 --> 38:01.040
That's something that I think that would be good to, you know, if you wanted to think

38:01.040 --> 38:05.320
about contributing to the community, the science community, that would be really terrific.

38:05.320 --> 38:06.320
Mm-hm.

38:06.320 --> 38:09.480
How big is the data science team there?

38:09.480 --> 38:10.800
It's not big.

38:10.800 --> 38:16.080
It's less than 10 people, so we're, you know, trying to grow in different ways.

38:16.080 --> 38:21.320
But yeah, and then the developer team is also not big, but it's good to, you know, be

38:21.320 --> 38:24.040
small and agile in that way.

38:24.040 --> 38:28.440
Cool, anything else that we, that you plan to cover in the presentation that we haven't

38:28.440 --> 38:30.120
already talked about?

38:30.120 --> 38:31.720
I think we got to most of it.

38:31.720 --> 38:36.880
At the end, I do talk about just sort of the future of embeddings.

38:36.880 --> 38:42.200
And I think that there's some question now because they have been outperformed in some

38:42.200 --> 38:44.280
ways by different types of embeddings.

38:44.280 --> 38:48.400
There it's sort of a suite of models.

38:48.400 --> 38:53.600
One of the better known ones is something called Elmo, which is an acronym called Elmo.

38:53.600 --> 38:54.600
Elmo.

38:54.600 --> 38:55.600
Okay.

38:55.600 --> 38:56.600
It's a language model.

38:56.600 --> 38:57.600
It's types of embeddings.

38:57.600 --> 39:02.520
And essentially, it's getting at, essentially, just deeper context.

39:02.520 --> 39:10.000
So, you know, with normal word vectors, you capture the context and of that word in a data

39:10.000 --> 39:11.000
set.

39:11.000 --> 39:12.320
But this actually gets at multiple contexts.

39:12.320 --> 39:18.400
So the, something called a polysemi, which is the multiple meanings of individual words.

39:18.400 --> 39:23.960
So it's, it's, it's more advanced models, more complex.

39:23.960 --> 39:28.280
There are also some sort of structural things about it that allow it to be used in downstream

39:28.280 --> 39:31.160
tasks, a variety of downstream tasks.

39:31.160 --> 39:36.320
And it seems that it's, it's really outperforming in these tasks.

39:36.320 --> 39:39.080
Word embeddings, just sort of an yellow word embeddings.

39:39.080 --> 39:44.240
And I think a lot of the inspiration, this is coming, just lifting this from this guy,

39:44.240 --> 39:49.720
Sebastian Reuters, I could have that, and he developed Elmo and he had a blog post talking

39:49.720 --> 39:56.360
about when his NLP is going to have, it's image net moment, referring to, yeah, it's

39:56.360 --> 40:02.680
really thought provoking and, yeah, getting at, you know, when we, when is NLP really

40:02.680 --> 40:07.080
going to break out and in terms of, you know, a single type of model or a single data

40:07.080 --> 40:09.160
set, that's why he was talking about image net.

40:09.160 --> 40:13.320
And, you know, for computer vision, it was really both like the acceleration that happened

40:13.320 --> 40:21.240
so, swiftly there was because of the data set, and then, and also the models, but, yeah,

40:21.240 --> 40:26.000
and then, but, you know, moving that, doing transfer learning, moving those models and

40:26.000 --> 40:30.160
the weights that were trained on this very rich data set, to other tasks, that was sort

40:30.160 --> 40:32.320
of the image net moment.

40:32.320 --> 40:36.080
And with these embeddings, you know, they're trying to get it, universal embeddings that

40:36.080 --> 40:42.360
can be used in a variety of different tasks downstream, and they're similar to, they're,

40:42.360 --> 40:46.800
you know, they're looking in context, they're, they're sequence models, so you're predicting

40:46.800 --> 40:50.840
words based on context, but it's in a much deeper way and it's, um, my directional

40:50.840 --> 40:56.240
LSTMs. So, you know, given that they, you know, it seems like they've, the metrics are much

40:56.240 --> 41:00.360
higher for these, um, there's a lot of question about, like, you know, what's going to happen

41:00.360 --> 41:04.840
with, with the NLP were embedding some document vectors, so, but, yeah, we'll see.

41:04.840 --> 41:11.040
Yeah, Sebastian and I are, uh, over due to doing interview, we're supposed to be getting

41:11.040 --> 41:12.480
back in touch now, I think.

41:12.480 --> 41:13.480
Fantastic.

41:13.480 --> 41:15.080
Well, I'll tell you much more than I go to.

41:15.080 --> 41:16.080
Yeah.

41:16.080 --> 41:20.320
Anyone listening to this that was intrigued by the comment, um, we should be diving into

41:20.320 --> 41:21.320
that set.

41:21.320 --> 41:22.320
Cool.

41:22.320 --> 41:23.320
I'm looking forward to that.

41:23.320 --> 41:24.320
Awesome.

41:24.320 --> 41:25.320
Well, thanks so much.

41:25.320 --> 41:26.320
It was great to have you on the show.

41:26.320 --> 41:27.920
I appreciate you stopping by and, uh, looking forward to your talk.

41:27.920 --> 41:28.920
Yeah.

41:28.920 --> 41:29.920
Thanks, Simon.

41:29.920 --> 41:30.920
Appreciate it.

41:30.920 --> 41:36.480
All right, everyone, that's our show for today.

41:36.480 --> 41:42.640
For more information on James or any of the topics covered in this show, visit twimlai.com

41:42.640 --> 41:46.120
slash talk slash one 83.

41:46.120 --> 41:52.360
For more information on the Stratidata podcast series, visit twimlai.com slash Stratid and

41:52.360 --> 41:54.880
Y 2018.

41:54.880 --> 42:08.840
As always, thanks so much for listening and catch you next time.

