All right, everyone. I am here with Shion More Tazavi. Shion is a data science manager at Accenture, and Shion, I'm excited to welcome you onto the podcast.
Oh, wow. It's pleasure to be here. I'm really thrilled to talk to you. And yeah, looking forward to it.
Let's do it. So you recently presented at Sigops AI and HPC Summit, and we're going to dig into your presentation and some of the work that you're doing there at Accenture.
But to get us started, why don't you share a little bit about your background and how you came to work in data science?
Sure. Well, I'm an engineer by background, and I started as a mechanical engineer in energy domain, building structures and pressurized systems in energy sector oil and gas industry, and then I moved slightly into simulation of the structures and components that are used mostly in the heavy industry domain.
And then I got interested into material science and worked a little bit conjunction between the simulation and the software is built for analyzing basically structures in that domain and material in terms of the characteristics, the properties, and then through that, I do work a lot with the data and doing a lot of tests.
And these structures and the material properties and making sure that there are fit for their service and integrity.
So dealing with a lot of data kind of got me to think about are there other applications for these data that we receive, which in the engineering domain, it's usually people working with this formula and this scary calculation,
chips and software and simulations. So yeah, and then I got excited about using data to solve some of the difficult problems that exist in engineering domain, slowly slowly moved into machine learning and statistical learning, and then yeah.
Nice, nice. Well, tell us a little bit about your group at Accenture and your role there.
Which is primarily focusing on application machine learning and statistical inference in the heavy industry and resources, what we call kind of covering mining sector, oil and gas, renewables, every, every sort of manufacturing base that have some assets heavy, heavy assets.
And yeah, in there, we kind of look into multiple different type of problems from production efficiency, supply chain, predictive maintenance and optimization of the production plants and, yeah, these sort of things.
Got it. And predictive maintenance, which you mentioned was the topic that you focused on for your talk at the Sega summit.
Can you give us a little background on predictive maintenance and in particular, some of the use cases that you've worked on.
Well, that's an interesting topic because especially in oil and gas and energy sector, because they're heavily regulated and are, you know, decades of applying best practices into the operations and the maintenance systems.
It is kind of, there is a inertia and changing or shifting the two towards more advanced sort of solutions.
So maintenance itself as a problem is trying to maximize or increase the reliability of assets. And this can be cars could be trucks could be stationary static sort of equipment tanks and towers and drums could be some rotating machines.
So, if the objective is to maximize the reliability, increase their availability and efficiency.
There has been traditionally kind of a myriad of strategies that asset operators depends on complexity of assets and they have applied traditional practices like fixed space maintenance where you let the machine run to failure and then you fix when it is broken.
There are costly and you don't have any view what is the state of the machine and then there are some kind of more clever, more systematic sort of approaches and maintenance that are called time based maintenance or scheduled maintenance where you define a sort of strategy of hope to regularly.
It's kind of getting it set for the meantime, the failure of different components and using that to build up to.
Exactly.
One thing might break and.
Absolutely.
Yeah, these sort of things.
So, in the past, let's say three, four decades, when IOT and the SCADA systems came into heavy industry domain, a branch of, let's say, preventative maintenance emerged called condition based monitoring where you the objective is to monitor the health of the equipment at any level.
And using the sensor sensor data to receive and then use some early warning sort of functionality on top of that to detect any problems at system level or different hierarchy and then act on top of that.
And the maintenance under the condition based monitoring, these CBMs are kind of resolved a lot of the traditional issues in the in this domain.
And predictive maintenance is a child of the CBM systems like the condition based monitoring, which simply the objectives can be used a fully data driven system to.
And predict when assets are going to fail in future.
And based on that, optimize their maintenance actions and optimize over the resources and costs.
So, yeah.
And so your presentation.
The long title, a novel framework for predictive maintenance using deep learning and reliability engineering.
So the kind of the broad context or problem that you're working on is predictive maintenance.
What was the specific use case that gave rise to some of the work that you talked about.
So, in this work, we try to not just fully rely on a data driven machine learning sort of approach, but see how we can combine and marry the domain knowledge exist for decades and been built up with the sort of capabilities we get from machine learning.
To address this very specific problem of can we detect failures at different levels of these machineries in advance and provide some insights that can be meaningfully taken as maintenance actions in order to move away from like reactive sort of maintenance or.
And also to let them to judge whether they can delay the maintenance actions or interventions or shutdown of their plans.
So this framework was specifically trying to break down the systems, these complex systems into multiple different levels in terms of the complexity and functionality in the system.
And then use machine learning to kind of monitor the performance of these little building blocks and then by by the means of aggregation through the science of reliability engineering then make sense of what is the global picture.
This framework, specifically, yes, was applied into rotating machineries, which we use everywhere in the petrochemical plants and power plants and refineries pharmaceutical industry everywhere.
It likes generators, turbo generators, pumps, compressors and turbines, this type of thing, exactly.
So these are complex, these machineries are, you can look at them like the turbo generators is jet engines, they have a very high RPM, rotating parts like 20,000 to 30,000 sometimes RPM, like exactly like a jet engine, lots of moving parts, high vibration on the significant loads, temperature, pressure and yeah, heavily censored.
I don't remember the specific stat, but, you know, a few years ago when in the early days of IOT, like there was this Boeing jet engine or GE aircraft engine example that we would throw around all the time and just how many sensors were in this engine and it was an astounding number.
And so this is all time series data that you're collecting.
So this is an interesting point because these these machines are, let's say in the energy sector, there are heavily censored up to 2,000, 3,000 sometimes, number of sensors monitoring,
pressure, temperature, vibration, flow rate, some process parameters, but the purpose of these sensors are not necessarily to provide maintenance inputs into maintenance engineers that are there to, for safety purposes,
or to regulate the process.
So, in order to address a problem of maintenance, we don't necessarily have the adequate type, location of the sensors in terms of the type of time series that we want, or the parameters we want to monitor.
Also, the redundancy in the type of sensors that we want to have the monitor specific modes of failures, for example, and also there is no scope for retrofitting type of sensors onto these complex machines.
So, yeah, we receive a lot of time series data and we have to apply a predictive solution, which is a kind of new generation approach on top of an old fashioned censoring sort of practices.
And that makes it a little bit interesting.
And it's really interesting that you put it like that, the idea that the sensors that are in these machines aren't necessarily there for you to make predictions from that that
that was always left out of this narrative of like IoT and predictive maintenance and digital twins that I've heard over and over and over again, but what you're describing is like you've got all these data points that are being spun out of these machines.
We've got a bunch of, you know, many, many years of equations to predict the reliability of the machines and when you might need to repair them, the whole field of reliability engineering that's evolved.
But there's a gap, it's like the bridge was built from two shores and doesn't meet in the middle and it sounds like that's what the core of your presentation was you're using predictive models to map from the data you're collecting off of these sensors to the equations that you would traditionally use.
Precisely, that's a very good summary of, yeah, and of the problem itself, yeah, maybe going forward into future where operators and the manufacturers of these machines realize the necessity of censoring the machines adequately for the specific purpose of predictive maintenance.
Which I think it's a trend in advanced sort of manufacturing fields in robotics and the machines which are employing a lot of robotics in them.
There are some sort of monitor the health of the machines and parts of them.
But in this specific case, exactly to bridge this gap, we wanted to really connect the failure mechanics, the knowledge within the failure mechanics with predictions from machine learning.
And what do we mean by the failure mechanics, so there is a type of analysis in the domain of engineering of machineries and a structure design, which is called FNA failure mode and effect analysis.
So what is that? It is basically a procedure to utilize the research and the standard exists to analyze the modes of failures of the machine, break down the modes of failures and the effect of each failure mode onto these specific type of equipment,
components from bottom up, and then identify the indicators that can kind of provide a bit of symptom of these type of failure modes and then act on top of that.
So this is a very rigid structural engineering practice that is performed in the beginning of the design or operation and then gets updated.
So we were thinking kind of the novelty of the thinking that maybe we try to deploy was can we use this failure mode and effect analysis and
build a sort of matrix that from all sort of information you get at component level, we provide a kind of more insightful picture of what can go wrong.
This is building blocks of the machines and then again by the use of the reliability engineering concepts, how we can combine these information at these building block levels and make sense from maintenance engineering point of view, what is going on at higher hierarchies like assembly levels or at system level.
So yeah, this was the perhaps the core novelty of the approach.
And so the matrix that you described is that part of the traditional way of solving like is that the input to the traditional reliability engineering approach or is that
an artifact of the solution that you've applied using deep learning new this was let's say one of the pillars of this of this approach.
This didn't exist so the FMEA does exist that's failure mode analysis that kind of cause and effect relationship mapping which you may in like the science domain use different approaches like Bayesian approaches to map or build the causal mapping of the system.
But in our case we adopted the cause and effect maps from engineering domain and we built something called false matrix and this false matrix is relational matrix map between the failure modes and really the sensors.
So in this matrix what you have is a map of what are the importance of each sensor in terms of redundancy and the influence in ability to detect some of the failure mode at component level.
So this can be very static matrix in terms of the importance relationship between the sensors and failure mode or it could be learn matrix or it could be probabilistic.
Let's say importance factor in terms of sensor to failure mode could be kind of incorporating uncertainty through the means of probably probability density functions.
And so going back to the long title that I mentioned where does deep learning come in one of the first steps of kind of detecting the problem.
Is it still an open question for us how we can detect accurately the problem and then link it to you know an understandable mode for engineers but to detect it I think traditionally at least in the field of condition based monitoring.
I have been applying some fixed thresholds onto sensors and then by this means of like operating bands they were able to detect animals behavior and then based on some rules acts upon those animals sequences or so on so far.
In our case through some literature review we wanted to see can we predict the behavior of these machines in their all possible states so these machines as you know they are operated in multiple different modes in terms of operation depends on how much load they want to apply to the machine.
And also because they are in operation for 30 years many several hundred thousands of hours in operation they see multiple different changes in the state of operation in the entire assets.
For example oil and gas industry the reservoir pressure temperature depletes the regime operation changes so whatever sensor reading that you receive from these all all part of the machines is subject to shift or drift or change.
So setting fixed let's say set of thresholds on these first would require continuous maintenance and observation of the false alarms and so on so forth and also it may not be fully kind of aware of all possible modes of operation.
So we were thinking we haven't seen everything of these machines operations should we use machine learning to learn from the past of these machines do we know the entire state of the data.
The answer was knew we were in the best case we only knew 10 15 to 20% of the entire operation state of these complex machine sensor.
I mean 10 15% of the operational state as defined by a specific set of sensors over a lifetime meaning you have the 10% of the lifetime of the machine or that the sensors themselves only capture some small percent of the operational state of the machine itself.
That's a very good question. I think it's exactly the combination of both. If there is a machine which has been just in operation you can have some prior belief about how the sensor should behave or how should receive the data but the rest is mystery and
the two identical machines have different sensor readings if you start them at the same time even set set up on the same plant. So this is one side of the unknown uncertainty and also a lot of operational modes as you said in terms of the state of operation is unknown throughout life of the life span.
The other thing is the more interesting one is the failures the patterns of failures trends in majority of the cases when you want to cover the entire let's say 200 or 300 different individual components of these
series you haven't seen failures of a lot of these components in their in their life so to maximize the coverage and also not make rigid assumptions you have to move away from traditional supervised that learning
to detect failures that doesn't work or if it works it covers maybe 5% of the problem. So where did machine learning and deep learning came to help us was we said okay let's let's say do we know what is
going to our best of knowledge what is the temporal transient healthy behavior of these machines and the sensor observations that we get we said possibly yes we have good knowledge of that to some degree.
Okay let's let's build these models which in this case we use recurrent neural network LSTM's at sensor level to monitor and learn the healthy behavior kind of sequences of these machines.
So from what we get in terms of the sensor will either stream data let's say if we build these representative model of the sensor from purely healthy behavior point of view can we predict a healthy vector into future and then checking that sort of sequence of time series versus what we actually
received we were able to predict any deviation so yes this kind of difference or residual signal for us was the outcome of using machine learning in the case of
the outcome of this book LSTM's to detect abnormalities got it got it and so it's a playback at least one part of that you started talking about the traditional approach and like setting these thresholds you know like you might see in other places where you you would use anomaly detection.
And you know one approach might be to like automatically set the threshold but that's not what you did here what you did is create a maybe lower level or kind of a richer model of the machine itself and didn't use a threshold based approach you use this more residual based approach to determine when an anomaly was happening exactly so.
Basically this detection of abnormalities was the first sort of step let's say in this workflow as soon as you detect some sort of abnormal or outliers within your residual signal which is the error signal then what we could do was to use some
parametric sort of techniques that you build a distribution of what is your error signal and then set some parameter around the distribution and whatever goes out of the sort of the threshold bands you detect them as abnormalities but again we found
we don't know a lot about these signals this is going to produce a lot of false alarms so what what else is out there so we got into this novel approach that scientists in NASA
developed and applied to their telemetry data received from the space shuttles which is called non parametric thresholding it is a kind of a dynamic non parametric thresholding and what is this is basically trying to fit a dynamic sort of set of bands around your residual error signal
and then these dynamic bands then allow you to detect any sort of abnormalities or outlier sequences that sort of is more robust in terms of not reacting to sort of temporal behavior of the sensor data that you see
as some cushioning sort of kind of buffer zone to prevent false alarms and also it is able to with the help of LSTM to capture the multimodal operational base like the heterogeneity in the data
so the technique itself is very simple but kind of beautiful technique it is at any given time define a wide range of threshold bands and then try to maximize a criteria by analyzing the whole historical distribution of the error
and then that criteria is can we detect any sort of new set of observation that can deviate the properties of the error distribution most at any given time
that set of band is set as the new threshold dynamically so once you have this set of thresholds then you detect the strings that sits outside of the threshold and then you calculate the score for the for the sequence
itself is calculated based on the second moment of area of the sequence outside of the threshold band
so you mentioned in their LSTMs that's the way that you're modeling the state of the individual components sure yeah exactly so the use of LSTMs was to exactly to what sort of algorithms are out there
that can understand the temporality in the signal and the multiple modes and provide the best representation of these noisy sensor readings
so in our case it was very important for us to make these predictions in future of the healthy bit pattern by understanding the kind of the historical changes in the signal
so long term short term memory type signals allowed us to kind of use the previous states of them of the system and incorporate that because of this specific architecture of these algorithms to provide the correct representation of the signal
and it was very expensive to build LSTMs at sensor level so we talked about few hundreds and few thousands of sensors per compressor or in our case we had to monitor about 200 sensors or 100-200 sensors per machine
so building these number of LSTMs and optimize them based on few years of time series data with high sampling rate was a challenge
the question I have about that is the you mentioned that you the each of the LSTMs is mapping to a sensor the it's kind of like you have the hierarchy right
we got the sensors the sensors presumably map to components and the components map to whatever the machine is I guess the reason why you do it at the sensor level is because you really don't know the relationship between the sensors and the components per se
the good point because we adapted this reliability based system which is aiming to detect the modes of failure that are active at any given time
we had to go from to a bottom-up approach we had to utilize the entire sensors that are monitoring one component
let's say in a compressor we have shafts we have bearings we have seal systems and impellers of the compressors
so let's say in a bearing case of bearings you have bearings on either side of the shaft and you have multiple different sensors monitoring the behavior of these components
a bunch of temperature sensors a bunch of flow rate that are injecting lubricants the component a lot of vibration type sensors in multiple different directions
so making sense of these active failure mode at any given time is a complex problem
we had to understand what sort of abnormalities working together would relate to which failure modes for that we needed to know abnormalities at bottom layer at sensor layer
so you created these kind of models or representations of your sensors and I'm trying to put the pieces together now
you've got these representations somewhere in the middle you're trying to get to the fault matrices or
you've got on the other side of the fault matrices your traditional reliability engineering equations
how do you get from the LSTM output to the fault matrices?
yes so I think the keys LSTMs are providing these healthy sequences of healthy behavior as a kind of mimicking the machine behavior from healthy point of view
just where the non-parametric came in you've got this and yes
by creating this residual signal or error signal and then applying the parametric thresholding on top of that
comparing the healthy from actual then you calculate the score what we call anomaly score let's say at sensor level
so any sequence of time at any time stamp let's say you have an anomaly score at sensor level
so feeding anomaly scores from 10 sensors related to one component into the fault matrix or this cause and effect sort of matrix
then you get a score per component per failure mode at any given time
so this is let's call it like component defector score or failure score and then having all of this failure mode lined up and components accordingly
then you can have a representation of a ranking of what are the anomalies at any component level
and then as you said by the use of the reliability engineering logic we can aggregate the scores at component level
let's say lots of different bearings and multiple different seal systems together and aggregate their abnormality scores together
and then roll it up into the assembly level then you can aggregate again at assembly level into the system level which is compressor
you can follow the same and go and cover your entire asset
by entire asset we're talking about like a gigantic oil rig or something
exactly have you gotten that far?
we've gone up to critical pass machineries and critical pass machineries means those which are sitting on the critical production line
you've talked a little bit about the kind of the challenge of just training all of the LSTMs that are involved in doing the kind of modeling here
can you elaborate a little bit on what some of the biggest challenges were?
well LSTMs are not easy to train and optimize especially that we are dealing with quite a lot of data
we're talking about one second sampling rate of few years of one sensor and when we talk about thousands of sensors
it's quite extensive so LSTMs have multiple different hyper parameters and to get the best results
you have to really invest time to optimize them
the thing was we are dealing with multiple different type of parameters we want to build these representations
vibration types sensors are very different in terms of the noise patterns and temporality
and the condition dependence is historically to what has happened in order to build a more accurate representation in the future
as opposed to for example temperature type signals which have a weak delay and there is not much temporality in it
the noise characteristics is different so optimizing LSTMs at these sensor levels was a challenge
for that we are lucky to collaborate with SIGOP which is one of the black box optimization platform
and then that helps us a lot using the Bayesian type optimization to quickly learn the
computer optimization parameters space very quickly and efficiently because there we have the ability to optimize
over multiple different objectives training time was one of our main objective as well as reducing the loss
you just said something interesting the optimization problem that you the way you ultimately frame your optimization problem wasn't solely constrained to system level criteria
but you also had this was it a train time criteria or compute train time?
yeah exactly so I think this this is a complex sort of pipeline of connected pieces together
performance of LSTMs in order to detect healthy patterns or sequences and detecting the residual or error
and feeding that into the kind of this cause and effect matrix and calculating the scores and evaluating these is
entirely together is one massive optimization group so you can look at the LSTMs itself and optimize the
hyper parameters there but getting the best fit there may not necessarily you know give you a global optimized path
so you may get into a local optimization here so connecting all of these together building this
gigantic sort of optimization loop with multiple different hyper parameters which are not necessarily all from coming from the LSTM
sort of hyper parameters was was a big challenge and not so not just from the LSTM but not just from a single LSTM you've
got parameters from multiple LSTMs say 50 or 100 plus these kind of broader constraints on your run time
was your your accuracy represented as a threshold or constraint or how did you incorporate that into your optimization
the ultimate ultimate kind of objectives were into two different dimensions
we had to have the human in the loop in order to evaluate the entire optimization
and that was what is the intuition and engineering domain knowledge in checking whether an abnormality score at system level or
assembly level is really an abnormality based on their experience and their knowledge of failure more than
analysis so that was our ultimate objective that let's say we introduced a bit of supervised sort of training into the loop
so we had a bit of labeling going on here in terms of what is this ultimate score at system or assembly or
component level and then we had multiple hyper parameter sets at LSTM stage at the scoring calculation stage
and so yes we were ultimately optimizing over the frontier of reducing the false alarms for indications and
maximizing the correct detection per failure so that was our frontier
can you elaborate a little bit on the human in the loop aspect of that how many you know how much labeling had to go into being able to build these models
that's a very good question I think we built some blueprints in hours and hours of discussions with
lateritating machinery those who have spent designing these machines for 20 or 30 years so we had lots of workshops to go through these
patterns historical patterns of past 10 years or so of the machine operation and then get all of these experts in
agreement of what is their final judgment of which sort of sequences are abnormal sequences which are kind of
noise artifacts which are sensor drifts and so on so forth which of them combined together are representative of failure mode
so through that process we labeled several of these examples and then it was a labor intensive process for sure
but to be clear what your labeling is a time series data set from of what all of the sensors in a given machine or
a particular sensor or I guess it couldn't it would have to be system level
yeah so we covered 15 or 20 critical components of these let's say turbo compressors which are sitting on the
critical path of the machine itself failure of each would result in the failure of the entire machinery
down time so we identified those and some high critical failure modes that statistically are from reliable to
point of view resulted in majority of the failures and then we focused on that
and ultimately what the what the SIGAP element of the optimization process was was kind of narrowing in on the
point on the frontier that you had to care about and optimizing across that so you weren't trying optimize across the entire
state space of hundreds of LSTMs and these constraints and all that stuff is that the general idea?
that's very true yeah so hyperparameters that we're talking about are like learning rate and look back look back sequence which in the case of
recurring neural network is important also increase the time training time and regularization parameters and so on so forth
it was about 12 15 number hyperparameters per LSTMs to optimize and multi-objective basically multi-metric optimization
so using the Bayesian optimization definitely helped a lot to quickly reduce the space of exploration
and so what's what's next for this effort?
Sure it's very exciting actually so what we what we talked about today so far is primarily focusing on one aspect of
let's say predictive maintenance domain there are multiple different things you can do if the main objective is to
make the best maintenance action this is a very difficult question to answer
because detecting problem is one thing making action and correct action is a different thing
and the action space is influenced by what sort of resources do you have available
which part of the geography you are operating are you in the island or an offshore 200 kilometers away from everything
which apply complexity and the complexity of the maintenance team and the maintenance tools that you have to have on board
the lead time of the components that you need to order and be built and tested to come may take 10 months or 12 months to come
so you're saying that you've solved the easy part of the problem
that's correct that's correct and this is a very complex question to answer
so what other things that can help in terms of prediction side on this first aspect
before getting into prescriptive sort of side of maintenance is how much how much time do I have to
wait till ultimate failure this is a very valuable information
so we talked about I think a lot of of the shelf tools that you see existing in the market
the GE tools and so many other things are very good in detecting the anomalies
but detecting what how much time do I have at component level and failure mode
from that point of view is a very valuable because it allows them to safely operate their systems without shutdown
because these machines are not designed to kind of constantly shut them down to repair or do some interventions
so yeah predicting time to failure is and linking that to the knowledge of failure mechanics is an interesting topic
and then and then you get to take on the what to do about it
that's very true yes and I think there have been a lot of efforts in research
and also beautiful tools exist at the moment which are trying to optimize the action
over cost over resource availability and over health
so health sort of let's say at system level health plot or health indicator can come from these sort of approaches
in the early detection time to failure aggregation and system level
but understanding the cost this is the whole set of you know new sort of formulation
of what is the my cost function from operational plan point of view
the revenue that the system is generating the criticality so on so forth
but to build this cost function and then resources also is also a majority of the cases is human related
and we are talking about the materials like the spare parts point of view
and also human repair experts who are going to be deployed on shore or on site or off shore kind of external software
and building a function massacizing that is a task
and do you expect to be able to apply similar ideas meaning introduce machine learning or deep learning
to complement existing domain knowledge to solve those other problems as well
definitely definitely I think a series of like probabilistic approaches
a Bayesian based and Bayesian networks for example or even a lot of machine learning applications
in predicting different aspects of the cost function in terms of the supply chain representation of the supply chain
as a kind of sequential model and also reinforcement learning can come into effect
in building the function of your own in learning your cost function and supply chain
also a lot of NLP people are applying in kind of feeding into sort of knowledge graphs
and by building these knowledge graphs you can link the entire asset data in terms of the operational plans
what is going on in terms of you know the inner outputs and then driving information
kind of from these knowledge graphs and feeding that into some sort of analytical layers
to predict what is the consequences of actions and on top of these knowledge graphs is another thing
got it got it awesome awesome
well Cheyenne thanks so much for taking the time to share a bit about your experiences in this area
very cool stuff
pleasure
pleasure talking to you
thank you
thanks
