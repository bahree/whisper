1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:31,800
I'm your host Sam Charrington.

4
00:00:31,800 --> 00:00:35,880
Over the past few months we've been working hard to craft an agenda for Twimblecon AI

5
00:00:35,880 --> 00:00:40,680
platforms that's both practical and interactive and I encourage you to check out what we've

6
00:00:40,680 --> 00:00:45,600
pulled together over at Twimblecon.com if you haven't recently.

7
00:00:45,600 --> 00:00:50,760
But Twimblecon is about more than great content, it's also about community and in that vein

8
00:00:50,760 --> 00:00:54,960
we'll be creating numerous opportunities for attendees to engage with one another and

9
00:00:54,960 --> 00:00:57,480
the broader Twimble universe.

10
00:00:57,480 --> 00:01:02,560
One of the things I am most excited about is that at Twimblecon we'll be joined by a bunch

11
00:01:02,560 --> 00:01:05,360
of formal Twimble podcast guests.

12
00:01:05,360 --> 00:01:09,520
This esteemed group will be there to take in all that Twimblecon has to offer including

13
00:01:09,520 --> 00:01:14,760
the opportunity to learn from and share their experiences with the entire AI platforms

14
00:01:14,760 --> 00:01:16,080
community.

15
00:01:16,080 --> 00:01:19,160
We'll be hosting an unconference at Twimblecon as well.

16
00:01:19,160 --> 00:01:22,760
This is a community driven segment of the event where attendees will have the opportunity

17
00:01:22,760 --> 00:01:27,760
to propose and vote on topics that they want to further explore in small group discussions

18
00:01:27,760 --> 00:01:29,280
and presentations.

19
00:01:29,280 --> 00:01:34,400
Finally, after kicking off the first day with great keynote interviews and breakout sessions

20
00:01:34,400 --> 00:01:38,680
we wanted to make sure that attendees have the opportunity to unwind and connect.

21
00:01:38,680 --> 00:01:45,360
Plus, we also want it and excuse to celebrate our first conference third birthday and 300th

22
00:01:45,360 --> 00:01:47,280
episode of the podcast.

23
00:01:47,280 --> 00:01:52,200
Also we'll be concluding day one with a Twimblecon happy hour par day.

24
00:01:52,200 --> 00:01:56,880
Of course, there will be food and drinks but also fun activities like an AWS deep racer

25
00:01:56,880 --> 00:02:02,520
contest, a Twimble interview booth and photo booth, a DJ and more.

26
00:02:02,520 --> 00:02:05,040
You definitely don't want to miss out.

27
00:02:05,040 --> 00:02:11,120
There's still time to register at Twimblecon.com which takes place on October 1st and 2nd in San

28
00:02:11,120 --> 00:02:19,160
Francisco, hit pause now and head over to twimblecon.com slash register to secure your spot.

29
00:02:19,160 --> 00:02:22,480
We'll wait for you.

30
00:02:22,480 --> 00:02:23,480
Great.

31
00:02:23,480 --> 00:02:30,600
Now that you're all registered and ready to go, please enjoy today's show.

32
00:02:30,600 --> 00:02:33,360
All right everyone, I am on the line with Greg Wilcox.

33
00:02:33,360 --> 00:02:36,360
Greg is director of R&D at unanimous AI.

34
00:02:36,360 --> 00:02:38,920
Greg, welcome to this week in machine learning and AI.

35
00:02:38,920 --> 00:02:39,920
Hi.

36
00:02:39,920 --> 00:02:40,920
Thanks for having me.

37
00:02:40,920 --> 00:02:41,920
Absolutely.

38
00:02:41,920 --> 00:02:42,920
Absolutely.

39
00:02:42,920 --> 00:02:49,240
So before we started this call, I went over to your LinkedIn and saw that you did your

40
00:02:49,240 --> 00:02:54,960
thing undergrad and grad work at Wash You in St. Louis, which I'm in St. Louis recording

41
00:02:54,960 --> 00:02:58,120
this as we speak and based here in St. Louis.

42
00:02:58,120 --> 00:02:59,120
Yeah.

43
00:02:59,120 --> 00:03:03,440
So maybe tell us a little bit about your your background and kind of how you got started

44
00:03:03,440 --> 00:03:04,440
in AI.

45
00:03:04,440 --> 00:03:05,440
Sure.

46
00:03:05,440 --> 00:03:06,840
Yeah, absolutely.

47
00:03:06,840 --> 00:03:12,000
So I got started, I was doing my bachelor's in systems engineering and physics at Wash

48
00:03:12,000 --> 00:03:13,000
You.

49
00:03:13,000 --> 00:03:15,320
And I was really enjoying it.

50
00:03:15,320 --> 00:03:17,520
And I had the opportunity to do my masters there as well.

51
00:03:17,520 --> 00:03:20,440
And I wanted to get into robotics.

52
00:03:20,440 --> 00:03:22,160
Robotics had always interest me.

53
00:03:22,160 --> 00:03:26,680
I had done some electrical engineering and my dad's an electrical engineer.

54
00:03:26,680 --> 00:03:31,960
And I got thinking and started like doing some research and artificial intelligence

55
00:03:31,960 --> 00:03:32,960
as a result.

56
00:03:32,960 --> 00:03:38,640
Robotics research is focused around machine learning and obviously artificial intelligence.

57
00:03:38,640 --> 00:03:42,360
So through that process, I took a couple of machine learning courses, got more and more

58
00:03:42,360 --> 00:03:43,360
interested.

59
00:03:43,360 --> 00:03:49,800
And obviously started hearing about things like like deep learning and AlphaGo and stuff

60
00:03:49,800 --> 00:03:50,800
like that.

61
00:03:50,800 --> 00:03:55,640
Obviously, just super motivating results that I think a lot of students these days are

62
00:03:55,640 --> 00:04:01,480
noticing and taking note of and really motivating them to get started in AI research.

63
00:04:01,480 --> 00:04:06,520
So I followed that same path and got my masters in robotics from Wash You.

64
00:04:06,520 --> 00:04:12,080
And then, yeah, and then joined unanimous tell us a little bit about what unanimous is

65
00:04:12,080 --> 00:04:13,080
up to.

66
00:04:13,080 --> 00:04:19,560
I'm looking at this paper that you wrote with the CEO and founder of the company Lewis Rosenberg

67
00:04:19,560 --> 00:04:22,720
on artificial swarm intelligence.

68
00:04:22,720 --> 00:04:23,720
What is that?

69
00:04:23,720 --> 00:04:26,760
And what are you trying to do at the company?

70
00:04:26,760 --> 00:04:28,160
Yeah, absolutely.

71
00:04:28,160 --> 00:04:35,120
So most AI companies take the approach that we can use artificial intelligence and machine

72
00:04:35,120 --> 00:04:41,800
learning to automate human processes, right, to do things that are easy or hard to do,

73
00:04:41,800 --> 00:04:48,040
but that are fairly automatable, such as making predictions or learning about the world and

74
00:04:48,040 --> 00:04:50,480
making decisions as a result of that.

75
00:04:50,480 --> 00:04:55,280
At unanimous, we treat humans a little differently, right, rather than data labelled, rather than

76
00:04:55,280 --> 00:04:59,320
as data labellers, we think that humans are really, really fundamentally very smart and

77
00:04:59,320 --> 00:05:04,040
have knowledge and wisdom about the world that state of the art machine learning algorithms

78
00:05:04,040 --> 00:05:06,160
just don't have access to you.

79
00:05:06,160 --> 00:05:13,880
And so by thinking about humans in this way, by thinking about them as really, really smart,

80
00:05:13,880 --> 00:05:17,800
we can actually use them as data processors rather than data points.

81
00:05:17,800 --> 00:05:23,360
So when you're, as one example, when you're on surfing Google, Google's tracking your

82
00:05:23,360 --> 00:05:28,040
clicks, they're treating your behaviors as just a data point.

83
00:05:28,040 --> 00:05:33,360
And trying to learn, like, market using machine learning algorithms to market to you based

84
00:05:33,360 --> 00:05:36,640
on your data points that you leave behind.

85
00:05:36,640 --> 00:05:38,440
We do things very differently.

86
00:05:38,440 --> 00:05:44,240
We connect people using AI algorithms and allow them to think together as a group.

87
00:05:44,240 --> 00:05:48,800
So what we've, like, we've devised this swarm AI algorithm that's based off of algorithms

88
00:05:48,800 --> 00:05:55,760
and nature that allow human groups to make more optimal forecasts, decisions, or prioritizations.

89
00:05:55,760 --> 00:06:01,000
And it's all really based on this idea in nature that organisms are better collectively

90
00:06:01,000 --> 00:06:02,960
thinking than thinking alone.

91
00:06:02,960 --> 00:06:08,480
And some examples of that are bees, fish, schools of fish, flocks of birds.

92
00:06:08,480 --> 00:06:14,360
All of these natural organisms have developed systems that allow themselves to think together

93
00:06:14,360 --> 00:06:17,240
more accurately than individuals.

94
00:06:17,240 --> 00:06:22,720
So a bee, when trying to be colony, when trying to think about, well, where should we position

95
00:06:22,720 --> 00:06:24,320
our hive next year?

96
00:06:24,320 --> 00:06:27,360
A single bee just can't make that decision.

97
00:06:27,360 --> 00:06:29,640
They're just not intelligent enough.

98
00:06:29,640 --> 00:06:33,240
They have a brain, the size of a grain of rice.

99
00:06:33,240 --> 00:06:36,960
And so they can't think of, oh, there are 17 different locations and let's weigh those

100
00:06:36,960 --> 00:06:43,080
on different factors, including the height from the ground, the size of the hive itself,

101
00:06:43,080 --> 00:06:44,200
et cetera, et cetera.

102
00:06:44,200 --> 00:06:49,520
So the individuals are not smart enough to make this decision accurately.

103
00:06:49,520 --> 00:06:52,400
And so what they do is they form this real-time system.

104
00:06:52,400 --> 00:06:59,760
They actually, an immersion intelligence forms because the group thinks together as a whole.

105
00:06:59,760 --> 00:07:01,960
And the way they do that is by communicating.

106
00:07:01,960 --> 00:07:06,480
They form a swarm intelligence by almost debating the answers in real time.

107
00:07:06,480 --> 00:07:11,600
I don't know if you're familiar with a waggle dance, but essentially they are dancing

108
00:07:11,600 --> 00:07:16,920
to express their conviction in a certain site.

109
00:07:16,920 --> 00:07:22,640
Yeah, so bees do this in one way, fish to another way, birds do it in a different way.

110
00:07:22,640 --> 00:07:28,600
But really what we see is that these real-time systems of independent thinkers and decision

111
00:07:28,600 --> 00:07:32,760
makers, the real-time systems, there's a whole form of smarter, super intelligence,

112
00:07:32,760 --> 00:07:38,240
a hive mind that is smarter than the individuals in the group.

113
00:07:38,240 --> 00:07:44,200
And so we based our technology off that phenomenon called swarm intelligence.

114
00:07:44,200 --> 00:07:49,640
And all we do is because humans hasn't evolved that method themselves of forming swarms,

115
00:07:49,640 --> 00:07:53,640
we've created an artificial swarm intelligence, which is really connecting humans with an

116
00:07:53,640 --> 00:08:00,160
AI algorithm so that the humans can become a hive mind.

117
00:08:00,160 --> 00:08:04,600
They can group together into hive mind that is more accurate as a whole than any individual

118
00:08:04,600 --> 00:08:08,440
as a group, or then the group as just as if they were taking a vote.

119
00:08:08,440 --> 00:08:15,520
I don't think anyone would argue your kind of base premises that humans are smart and

120
00:08:15,520 --> 00:08:21,160
that they communicate and when they communicate they can make each other smarter or make better

121
00:08:21,160 --> 00:08:24,120
decisions, things like that.

122
00:08:24,120 --> 00:08:32,160
Beyond that though, the notion of kind of this confluence of swarm and AI is still abstract.

123
00:08:32,160 --> 00:08:35,440
How can we make that more concrete?

124
00:08:35,440 --> 00:08:36,440
Sure.

125
00:08:36,440 --> 00:08:41,000
So you can think of language as one form of swarming.

126
00:08:41,000 --> 00:08:44,680
So you can think that when we're communicating everyone is thinking together as a group,

127
00:08:44,680 --> 00:08:47,560
let's say we're a group of five people trying to make a decision.

128
00:08:47,560 --> 00:08:50,000
We would start talking and coming up with the best answer.

129
00:08:50,000 --> 00:08:52,080
So that's a form of swarming.

130
00:08:52,080 --> 00:08:57,200
The problem is, it's basically a focus group or a debate.

131
00:08:57,200 --> 00:09:02,680
The loudest person in the room exerts the most influence, our biases come into play.

132
00:09:02,680 --> 00:09:09,240
So age, ethnicity, the background of a human determines how you judge that human.

133
00:09:09,240 --> 00:09:13,320
And so realistically, that's not an effective form of decision making.

134
00:09:13,320 --> 00:09:19,040
The groups, insights are not aggregated in a good way.

135
00:09:19,040 --> 00:09:23,880
So what we've done is we've designed a graphical interface, an online interface in which all

136
00:09:23,880 --> 00:09:26,160
participants are anonymous.

137
00:09:26,160 --> 00:09:31,400
And this interface contains a puck and everyone has a magnet that they can pull on a puck

138
00:09:31,400 --> 00:09:32,400
on the puck.

139
00:09:32,400 --> 00:09:37,600
And so in an anonymous way, in a very democratic way, where everyone's exerting influence

140
00:09:37,600 --> 00:09:44,880
in real time synchronously, we can reach optimal decisions collectively together.

141
00:09:44,880 --> 00:09:50,240
So it's an anonymous democratic form of communication.

142
00:09:50,240 --> 00:09:55,040
So we've got a decision that needs to be made.

143
00:09:55,040 --> 00:09:57,320
Where should we build our hive?

144
00:09:57,320 --> 00:10:03,880
We've all got, say, there are half a dozen options and we've all got access to some magnets

145
00:10:03,880 --> 00:10:07,440
where we can pull this puck.

146
00:10:07,440 --> 00:10:13,560
It sounds like you're, it's kind of a sophisticated voting scheme in some way.

147
00:10:13,560 --> 00:10:14,560
Sure.

148
00:10:14,560 --> 00:10:17,160
Yeah, you can consider it.

149
00:10:17,160 --> 00:10:22,880
It's real time voting, but where the consensus is being represented on the screen.

150
00:10:22,880 --> 00:10:26,680
And so yeah, it's, yeah, it's similar to that.

151
00:10:26,680 --> 00:10:29,120
And so where does AI come into play?

152
00:10:29,120 --> 00:10:34,040
So what we're really doing with the AI is moderating the discussion.

153
00:10:34,040 --> 00:10:38,400
The puck is sort of a representation of the consensus of the swarm.

154
00:10:38,400 --> 00:10:44,560
And so as that approaches a target, the swarm is choosing that one as the puck approaches

155
00:10:44,560 --> 00:10:47,360
an answer, the swarm is choosing that answer.

156
00:10:47,360 --> 00:10:52,920
So where the AI really comes into play is moderating the strength of each user.

157
00:10:52,920 --> 00:10:58,560
So as we, as we notice, one user is more convicted than another or really, really has a strong

158
00:10:58,560 --> 00:11:03,560
belief in one of the answers, they'll get more strength and more weight into the decision

159
00:11:03,560 --> 00:11:06,000
or forecast.

160
00:11:06,000 --> 00:11:12,280
And so we've designed a number of AI algorithms that using this graphical interface sort

161
00:11:12,280 --> 00:11:14,200
of measure users' conviction.

162
00:11:14,200 --> 00:11:19,280
For example, if they're switching between multiple answers, they're probably less convicted.

163
00:11:19,280 --> 00:11:23,200
They've less strength of belief than someone who is pulling for the same answer in the

164
00:11:23,200 --> 00:11:24,600
whole swarm.

165
00:11:24,600 --> 00:11:28,640
Someone that's really entrenched and really, really wants one answer is more convicted than

166
00:11:28,640 --> 00:11:30,920
someone who's wishy-washy.

167
00:11:30,920 --> 00:11:35,200
So we have some algorithms that measure conviction in that way.

168
00:11:35,200 --> 00:11:39,400
Another one is that you really have to be close to this puck with your magnet, the closer

169
00:11:39,400 --> 00:11:42,000
your magnet, the more force you have.

170
00:11:42,000 --> 00:11:43,800
The problem is the puck moving.

171
00:11:43,800 --> 00:11:48,360
And so you have to be really thinking and really putting effort into controlling the location

172
00:11:48,360 --> 00:11:51,680
of your magnet, really trying to pull as hard as you can at all times.

173
00:11:51,680 --> 00:11:58,080
And that dynamic system, really, we've shown that it is very useful in finding the conviction

174
00:11:58,080 --> 00:11:59,080
of a user.

175
00:11:59,080 --> 00:12:03,240
The user that are more convicted will put more effort and mentally into trying to exert

176
00:12:03,240 --> 00:12:05,160
their will on the puck.

177
00:12:05,160 --> 00:12:10,480
And so when we're talking about moving this puck, are we talking about with a video game

178
00:12:10,480 --> 00:12:17,760
controller or like slamming down on the down arrow keys or just using your mouse or using

179
00:12:17,760 --> 00:12:18,760
your mouse?

180
00:12:18,760 --> 00:12:21,440
So you're physically doing some action.

181
00:12:21,440 --> 00:12:27,920
So this is kind of like a real time voting thing where you've got, I'm trying to remember

182
00:12:27,920 --> 00:12:31,200
the name of this video game that I'm thinking about where you have like multiple players

183
00:12:31,200 --> 00:12:36,400
and you end up like, it has one of these track balls and you just end up slamming this

184
00:12:36,400 --> 00:12:40,400
track ball as hard as you can to try to move whatever it is in your direction.

185
00:12:40,400 --> 00:12:43,440
Like, that's the picture that's forming for me.

186
00:12:43,440 --> 00:12:44,440
Yeah.

187
00:12:44,440 --> 00:12:49,520
So it's, I think rather than slamming a track ball, it's pretty calm and it's pretty fun.

188
00:12:49,520 --> 00:12:52,000
Users really enjoy using the system, I think.

189
00:12:52,000 --> 00:12:59,080
Yeah, but I think it is like a very engaging experience where people really are like, are

190
00:12:59,080 --> 00:13:03,040
feel a sense of emotion when the swarm is not going their way and they're really forced

191
00:13:03,040 --> 00:13:07,480
to think about the options it played and how they can reach and answer that's good for

192
00:13:07,480 --> 00:13:09,720
them, even if it's not their best answer.

193
00:13:09,720 --> 00:13:14,120
And so it's about at this game of compromise, a game is maybe a good word for it when

194
00:13:14,120 --> 00:13:19,440
we're thinking about compromise and entrenchment and all these human factors.

195
00:13:19,440 --> 00:13:23,800
So it really at the end of the day comes back to humans and emotions.

196
00:13:23,800 --> 00:13:30,920
So you mentioned compromise and previously you mentioned that the part of the dynamic

197
00:13:30,920 --> 00:13:40,320
of this game or system is that the more convicted user, you know, gets more strength and has

198
00:13:40,320 --> 00:13:44,440
more greater ability to influence the outcome.

199
00:13:44,440 --> 00:13:49,880
You know, if the political climate is any indication, you know, strength of conviction

200
00:13:49,880 --> 00:13:57,040
isn't necessarily tied to, you know, judgment or, you know, willingness to compromise.

201
00:13:57,040 --> 00:14:00,080
How does that play out in this environment?

202
00:14:00,080 --> 00:14:05,080
Yeah, so well, strength of conviction isn't always correlated to accuracy.

203
00:14:05,080 --> 00:14:09,720
In general, we find that it is specifically when there's a, when we're forecasting.

204
00:14:09,720 --> 00:14:17,080
So if we're like trying to forecast the outcome of a sports game, generally we find that

205
00:14:17,080 --> 00:14:20,840
the strength of someone's conviction is correlated to their accuracy.

206
00:14:20,840 --> 00:14:25,040
People who don't know what they're talking about are more likely to switch than people

207
00:14:25,040 --> 00:14:28,000
who do know what they're talking about.

208
00:14:28,000 --> 00:14:31,240
All that in certain cases is not true.

209
00:14:31,240 --> 00:14:34,480
As a general rule, we find it to be the case.

210
00:14:34,480 --> 00:14:35,480
And you mentioned sports.

211
00:14:35,480 --> 00:14:41,000
Maybe that's a good segue to talking about some use cases that will help make this even

212
00:14:41,000 --> 00:14:43,760
more concrete.

213
00:14:43,760 --> 00:14:46,520
It sounds like you're doing some work in the sports arena.

214
00:14:46,520 --> 00:14:47,520
Absolutely.

215
00:14:47,520 --> 00:14:48,520
Yeah.

216
00:14:48,520 --> 00:14:56,120
So every week we predict a number of sports, the five main sports in the US, NHL, NBA,

217
00:14:56,120 --> 00:15:01,200
MLB, NFL, and EPL, English Premier League.

218
00:15:01,200 --> 00:15:06,640
We've done some really, really interesting research that shows that swarms are very,

219
00:15:06,640 --> 00:15:09,240
very accurate at forecasting sports.

220
00:15:09,240 --> 00:15:13,640
And so we're predicting March madness this year.

221
00:15:13,640 --> 00:15:17,800
And actually last year, maybe a good, a good point of conversation is that we went up

222
00:15:17,800 --> 00:15:18,800
against ESPN.

223
00:15:18,800 --> 00:15:21,720
And ESPN has this bracket.

224
00:15:21,720 --> 00:15:27,040
Anyone can make a bracket on ESPN and 17 million people did last year.

225
00:15:27,040 --> 00:15:32,080
What's crazy about that is that we got a group of 50 people to forecast this bracket as

226
00:15:32,080 --> 00:15:33,080
well.

227
00:15:33,080 --> 00:15:35,680
That's a full 63 games.

228
00:15:35,680 --> 00:15:39,240
And that's really, you have to forecast the first round then based on your picked winners

229
00:15:39,240 --> 00:15:42,080
from the first round or the second round.

230
00:15:42,080 --> 00:15:49,080
And so forecasting these 63 games, we find that the 17 million people, if you calculate

231
00:15:49,080 --> 00:15:52,360
their average, they would have performed in the 50th percentile.

232
00:15:52,360 --> 00:15:59,200
But when making a decision, when making a forecast as a swarm, we can increase the forecasting

233
00:15:59,200 --> 00:16:04,760
accuracy of just 50 regular fans all the way up to the 92nd percentile.

234
00:16:04,760 --> 00:16:09,840
So really we're aggregating the wisdom and the insights of participants to make more

235
00:16:09,840 --> 00:16:12,000
accurate forecasts.

236
00:16:12,000 --> 00:16:16,160
The point of conversation normally comes up, well, what happens if you're just taking

237
00:16:16,160 --> 00:16:18,480
a vote of that 17 million people, right?

238
00:16:18,480 --> 00:16:21,680
That's a huge base of knowledge and wisdom.

239
00:16:21,680 --> 00:16:23,280
How well would they have done?

240
00:16:23,280 --> 00:16:28,920
Well, we find that if the ESPN has a people's bracket, which is like basically a wisdom

241
00:16:28,920 --> 00:16:32,640
that crowd and an average of the most people's brackets.

242
00:16:32,640 --> 00:16:36,680
So if you had taken a vote, the people's bracket is what you would have received.

243
00:16:36,680 --> 00:16:39,040
And that only scored in the 60th percentile.

244
00:16:39,040 --> 00:16:45,200
So we get an extra 32% improvement upon that by aggregating knowledge and wisdom in

245
00:16:45,200 --> 00:16:51,160
a real time swarming system rather than just taking a vote.

246
00:16:51,160 --> 00:16:58,640
And so the 50 people that participate in this, where they somehow randomly chosen from

247
00:16:58,640 --> 00:17:03,040
the 17 million or is there a relationship between them?

248
00:17:03,040 --> 00:17:06,560
Yeah, they weren't, they were sampled from a similar population, right?

249
00:17:06,560 --> 00:17:09,120
They just as self identified as enthusiasts.

250
00:17:09,120 --> 00:17:16,000
They were not experts, they weren't paid to participate or compensated for their accuracy.

251
00:17:16,000 --> 00:17:22,360
They were just regular NBA fans who signed up VR and newsletter and wanted to forecast

252
00:17:22,360 --> 00:17:25,280
these games and see what the swarm would have predicted.

253
00:17:25,280 --> 00:17:34,160
And so predicting, trying to predict the outcome of sports games is one application or what

254
00:17:34,160 --> 00:17:35,160
are some others?

255
00:17:35,160 --> 00:17:36,160
Sure.

256
00:17:36,160 --> 00:17:42,000
So what's really powerful about this technology is that it's usable across really any domain,

257
00:17:42,000 --> 00:17:46,080
any question that a human can answer, a group of humans can also answer.

258
00:17:46,080 --> 00:17:49,720
So swarm, therefore, can also answer.

259
00:17:49,720 --> 00:17:55,280
So we see applications of this from sports as one example, but medical is another.

260
00:17:55,280 --> 00:18:02,280
We did a study with Stanford that showed we can reduce the diagnostic error of doctors

261
00:18:02,280 --> 00:18:05,880
by 33% when diagnosing pneumonia.

262
00:18:05,880 --> 00:18:14,080
We can amplify the accuracy of financial traders by 26% when thinking together as a swarm.

263
00:18:14,080 --> 00:18:20,200
So medicine, finance, business decision making is another where we're thinking about making

264
00:18:20,200 --> 00:18:25,960
business forecast or prioritizations or really decisions in a swarm.

265
00:18:25,960 --> 00:18:28,520
And we've shown that that's also significantly more accurate.

266
00:18:28,520 --> 00:18:33,200
So really the applications for this technology are vast.

267
00:18:33,200 --> 00:18:38,800
And so yeah, we're really at the moment hoping to bring that to more and more people.

268
00:18:38,800 --> 00:18:39,800
Okay.

269
00:18:39,800 --> 00:18:43,880
So I'm getting kind of my picture of what you're doing continues to refine.

270
00:18:43,880 --> 00:18:53,760
I guess my current sound bite maybe would be that it's kind of like a real time nonverbal

271
00:18:53,760 --> 00:19:00,320
collaboration tool in a sense where you're collaborating over or voting tool where you're

272
00:19:00,320 --> 00:19:05,760
like collaborating or voting on kind of simple questions as opposed to projects or something

273
00:19:05,760 --> 00:19:06,760
like that.

274
00:19:06,760 --> 00:19:07,760
Yeah.

275
00:19:07,760 --> 00:19:11,400
And I think collaboration is absolutely the way to think about this because we're not just

276
00:19:11,400 --> 00:19:12,400
taking a simple vote.

277
00:19:12,400 --> 00:19:17,000
We're asking people to behave like and the behaviors here are the really, really important

278
00:19:17,000 --> 00:19:18,000
part.

279
00:19:18,000 --> 00:19:19,000
Yeah.

280
00:19:19,000 --> 00:19:23,800
This maybe goes back to this idea of conviction, but do you find that is there some dynamic

281
00:19:23,800 --> 00:19:27,240
where a person's participation in this?

282
00:19:27,240 --> 00:19:30,920
Is it again like slamming the track ball as hard as you can or moving the mouse as hard

283
00:19:30,920 --> 00:19:41,600
as you can or just kind of in other words, as vigorously as you desire, trying to impose

284
00:19:41,600 --> 00:19:48,200
your conviction on the other participants or is there some kind of dynamic nature where

285
00:19:48,200 --> 00:19:54,640
people you've demonstrated that people see what other people are also convicted about

286
00:19:54,640 --> 00:19:58,920
and kind of change the way they express themselves?

287
00:19:58,920 --> 00:20:04,400
So we find that people are very sort of empathetic when using the system.

288
00:20:04,400 --> 00:20:08,960
They're more easily able to consider other people's viewpoints and so they're instead of

289
00:20:08,960 --> 00:20:15,160
the idea of slamming a track ball, really trying to impose your will on other people.

290
00:20:15,160 --> 00:20:19,720
When using the system, you only have, let's say, there are 40 people in the system, you

291
00:20:19,720 --> 00:20:24,440
have one 40th of the control, right?

292
00:20:24,440 --> 00:20:30,040
So you really are not in complete control, it's the will of that hive mind, if you will,

293
00:20:30,040 --> 00:20:34,480
that determines the decisions or forecasts or outputs of the system.

294
00:20:34,480 --> 00:20:40,320
And so really you are just a small part of a larger tool, of a larger system.

295
00:20:40,320 --> 00:20:45,560
And so you need to work with the system by thinking how could I best direct this towards

296
00:20:45,560 --> 00:20:51,000
what I would like rather than trying to exert your will on the system and make other people

297
00:20:51,000 --> 00:20:52,000
believe you?

298
00:20:52,000 --> 00:20:53,000
Yeah.

299
00:20:53,000 --> 00:20:58,000
And I guess that's kind of the question that I'm trying to ask, you know, and the one

300
00:20:58,000 --> 00:21:06,080
end, there's just, you know, say that there are, you know, six possible responses.

301
00:21:06,080 --> 00:21:10,600
You know, the one end is like a one-dimensional input where I'm just pressing CCC or, you

302
00:21:10,600 --> 00:21:15,280
know, trying to direct somehow this puck to C. But it sounds like you're describing

303
00:21:15,280 --> 00:21:21,680
a world in which it's almost like a strategy game in the small where I'm trying to exert

304
00:21:21,680 --> 00:21:27,360
influence indirectly, but it's not clear to me how that plays out in the scenarios we've

305
00:21:27,360 --> 00:21:28,360
talked about.

306
00:21:28,360 --> 00:21:29,360
Sure.

307
00:21:29,360 --> 00:21:30,360
Yeah.

308
00:21:30,360 --> 00:21:37,160
So let's imagine, let's imagine that there are three options and they're equally spaced

309
00:21:37,160 --> 00:21:43,480
and what we're like, let's say that 30% of people are pulling towards answer one and

310
00:21:43,480 --> 00:21:46,360
70% of people are pulling towards answer two.

311
00:21:46,360 --> 00:21:48,720
And let's say I'm pulling towards answer three.

312
00:21:48,720 --> 00:21:55,040
So as the swarm is evolving, the puck is moving towards answer two because most people are

313
00:21:55,040 --> 00:21:57,040
pulling towards that outcome.

314
00:21:57,040 --> 00:21:59,600
But if I really don't like answer two, I could oppose it.

315
00:21:59,600 --> 00:22:03,280
I could pull against it rather than pulling four or something, right?

316
00:22:03,280 --> 00:22:05,720
Or I could switch to answer one.

317
00:22:05,720 --> 00:22:10,160
Really what I'm, what I'm engaging in is this behavior that is really, really complex.

318
00:22:10,160 --> 00:22:15,960
It's like a game in which I'm deciding how do I want to try to influence the swarm?

319
00:22:15,960 --> 00:22:20,440
And so concretely, this could be if we're talking about a puck moving around a decision

320
00:22:20,440 --> 00:22:25,760
space on a screen, I could just be pulling directly against an answer that I don't want.

321
00:22:25,760 --> 00:22:30,080
Or I could be switching and pulling four and answer I do want.

322
00:22:30,080 --> 00:22:32,640
In real time, everyone's making these decisions.

323
00:22:32,640 --> 00:22:35,720
Everyone's thinking together and behaving together.

324
00:22:35,720 --> 00:22:43,920
And so it's, it forms a very complex system where there are an infinite number of ways to

325
00:22:43,920 --> 00:22:44,920
reach an answer.

326
00:22:44,920 --> 00:22:50,160
But the way that I behave is going to be reflective of my beliefs on that question.

327
00:22:50,160 --> 00:22:54,240
If I am pulling against an answer, I'm showing I really don't want that answer.

328
00:22:54,240 --> 00:22:58,680
If I'm pulling, if I switch from one answer to another, I'm saying, well, I value this

329
00:22:58,680 --> 00:22:59,680
answer.

330
00:22:59,680 --> 00:23:05,680
But if forced to choose a different answer, I would choose this one, this other answer.

331
00:23:05,680 --> 00:23:11,960
So yeah, I think you're on the spot on that it is really like a decision space where

332
00:23:11,960 --> 00:23:19,120
people are trying to come to come to an answer that's not necessarily their first choice.

333
00:23:19,120 --> 00:23:22,120
We're talking because there's AI involved in this.

334
00:23:22,120 --> 00:23:32,560
Let's maybe dig into where exactly you're using AI and what types of AI are at play here.

335
00:23:32,560 --> 00:23:39,680
So our research and AI focus mainly on three components, right?

336
00:23:39,680 --> 00:23:43,040
We are studying what happens before a swarm.

337
00:23:43,040 --> 00:23:46,040
How do we select the right participants to join a swarm?

338
00:23:46,040 --> 00:23:49,600
So a swarm of experts, we like can really only amplify intelligence.

339
00:23:49,600 --> 00:23:53,440
And so if people are flipping coins and they have no idea, we can't amplify that.

340
00:23:53,440 --> 00:23:59,800
So we have to find experts, people who know enough about a question, experts are enthusiasts

341
00:23:59,800 --> 00:24:01,280
in order to amplify intelligence.

342
00:24:01,280 --> 00:24:05,640
So finding the right people is really important and finding enough of them is really important.

343
00:24:05,640 --> 00:24:08,880
Swarms are more accurate with more people.

344
00:24:08,880 --> 00:24:12,880
So that's the first stage, finding the right people for a swarm.

345
00:24:12,880 --> 00:24:19,440
Then our AI system in the during the swarm phase is really really important.

346
00:24:19,440 --> 00:24:23,800
This is the phase where we're waiting people's contributions to the swarm when they're

347
00:24:23,800 --> 00:24:29,080
swarming, really engaging in deliberation and devising the algorithms that constitute

348
00:24:29,080 --> 00:24:30,080
that deliberation.

349
00:24:30,080 --> 00:24:32,840
So that's like, who has the most conviction?

350
00:24:32,840 --> 00:24:38,200
What is the right way to ask questions in order to get really accurate intelligence out?

351
00:24:38,200 --> 00:24:43,160
So that's a level of real time AI that we've devised and we continue to iterate upon

352
00:24:43,160 --> 00:24:45,400
and make more and more accurate.

353
00:24:45,400 --> 00:24:51,200
And then the final stage that we focus on researching is post processing.

354
00:24:51,200 --> 00:24:56,480
And so post processing can take any number of forms from visualization of the deliberation.

355
00:24:56,480 --> 00:25:04,000
Why did the swarm choose this? How did they reach this answer to more complex machine learning?

356
00:25:04,000 --> 00:25:08,920
Which is, what is the probability that the answer is correct?

357
00:25:08,920 --> 00:25:13,480
One of the really interesting projects that we did over the past couple months was training

358
00:25:13,480 --> 00:25:14,960
a conviction network.

359
00:25:14,960 --> 00:25:20,000
So this is a behavioral neural network that looks at the aggregate behaviors of all of these

360
00:25:20,000 --> 00:25:26,360
individuals in the swarm and tries to say, what is the probability in abstract terms

361
00:25:26,360 --> 00:25:29,040
that the swarm was correct?

362
00:25:29,040 --> 00:25:32,520
So to make this more concrete, let's take an example.

363
00:25:32,520 --> 00:25:36,200
Let's say we're predicting hockey and HL.

364
00:25:36,200 --> 00:25:40,120
And the swarm is considering will team A or team B win, right?

365
00:25:40,120 --> 00:25:47,200
So as the swarm behaves, you'll see people pulling for team A high confidence, team

366
00:25:47,200 --> 00:25:52,640
A low confidence, they're really expressing different levels of conviction in the right

367
00:25:52,640 --> 00:25:53,640
answer.

368
00:25:53,640 --> 00:25:58,920
We've trained a machine learning algorithm to predict the probability that that pick will

369
00:25:58,920 --> 00:25:59,920
be correct.

370
00:25:59,920 --> 00:26:04,680
So if they choose the nights to win a game, we may be able to say, not only, oh, we think

371
00:26:04,680 --> 00:26:09,360
the nights will win, but they'll win with a 64% probability.

372
00:26:09,360 --> 00:26:13,400
Now that's really, really interesting because it's a level deeper, it's a level more

373
00:26:13,400 --> 00:26:15,800
precise than what the swarm is giving.

374
00:26:15,800 --> 00:26:21,840
We're really using these complex behaviors, the acquiescence, the entrenchment of users

375
00:26:21,840 --> 00:26:28,320
to get an understanding of what is the real world probability of this event.

376
00:26:28,320 --> 00:26:34,200
And so with this model, with this probabilistic forecast, which we call conviction, we're

377
00:26:34,200 --> 00:26:38,720
able to significantly amplify the precision of swarms.

378
00:26:38,720 --> 00:26:42,640
One specific example of that was NBA last year.

379
00:26:42,640 --> 00:26:48,880
So we predicted 238 games over 25 weeks in NBA.

380
00:26:48,880 --> 00:26:51,720
So team A or team B, who will win.

381
00:26:51,720 --> 00:26:55,920
And we find that as a baseline, the swarm returns to 25% ROI.

382
00:26:55,920 --> 00:27:01,880
So betting on the swarm's picks, you would have made 25% of return on investment.

383
00:27:01,880 --> 00:27:06,040
That means if you bet $100 at the start of the season, and bet evenly across all of

384
00:27:06,040 --> 00:27:12,000
the swarm's picks, by the end of the season, you would have $125.

385
00:27:12,000 --> 00:27:16,840
Which is pretty impressive result, and we find statistically significant result that the

386
00:27:16,840 --> 00:27:21,080
swarm outperformed the large-scale Vegas application.

387
00:27:21,080 --> 00:27:26,600
But when we apply this machine learning model conviction to select the games that we

388
00:27:26,600 --> 00:27:32,160
think are more probable than Vegas suggests, like when we really devise it precise forecast

389
00:27:32,160 --> 00:27:39,280
and then bet based on that forecast, we can increase this ROI significantly to 52%.

390
00:27:39,280 --> 00:27:45,800
So really, that's a very, very interesting result to us because it means that the behaviors

391
00:27:45,800 --> 00:27:52,920
in swarms are more interesting and more important than just the raw result itself.

392
00:27:52,920 --> 00:27:57,160
It's how people interact with one another, how they weigh their levels of conviction, and

393
00:27:57,160 --> 00:28:03,520
how they behave that is the primary functionality of the swarm.

394
00:28:03,520 --> 00:28:08,200
It's why that's the reason this is so accurate.

395
00:28:08,200 --> 00:28:13,040
It sounds a little bit like kind of the mythical perpetual money machine.

396
00:28:13,040 --> 00:28:17,360
And whenever I hear that, I wonder, why are you bothering trying to sell software, or

397
00:28:17,360 --> 00:28:21,600
whatever you're doing, and that's just like playing your own bank?

398
00:28:21,600 --> 00:28:23,840
Yeah, absolutely.

399
00:28:23,840 --> 00:28:27,800
It's partly because this is a really experimental technology.

400
00:28:27,800 --> 00:28:29,400
This is also a very recent result.

401
00:28:29,400 --> 00:28:32,480
We published this conviction result recently.

402
00:28:32,480 --> 00:28:39,680
And so we're just starting to, we are always surprised by the accuracy of this technology.

403
00:28:39,680 --> 00:28:44,720
And so it is a, we're still growing our levels of confidence in this.

404
00:28:44,720 --> 00:28:48,920
Really, we're still experimenting and analyzing post-humorously these results.

405
00:28:48,920 --> 00:28:53,920
Sports forecasting and financial forecasting is definitely on our roadmap for the future.

406
00:28:53,920 --> 00:28:58,480
But we're a small team, and it's going to take a little bit more time before we're ready

407
00:28:58,480 --> 00:29:00,760
to put company money on that.

408
00:29:00,760 --> 00:29:06,440
Although I can share that our internal team is betting small amounts with our own money

409
00:29:06,440 --> 00:29:09,160
just as an office pool.

410
00:29:09,160 --> 00:29:10,960
Like just for fun.

411
00:29:10,960 --> 00:29:12,880
But before we're like, we're not ready to go.

412
00:29:12,880 --> 00:29:15,120
Kind of the unanimous version of dog fooding.

413
00:29:15,120 --> 00:29:16,600
Oh, yeah, absolutely.

414
00:29:16,600 --> 00:29:20,400
Puppy Chow is something we engage in regularly.

415
00:29:20,400 --> 00:29:29,040
So this conviction network, maybe talk a little bit about the inputs of this network,

416
00:29:29,040 --> 00:29:34,880
the architecture or structure of the network, anything unique about how it's trained, that

417
00:29:34,880 --> 00:29:35,880
kind of stuff.

418
00:29:35,880 --> 00:29:42,040
Yeah, so really it's a neural network that's training on the behaviors of swarms.

419
00:29:42,040 --> 00:29:47,160
So what I mean by that is it's looking at aggregate statistics, like how long a swarm

420
00:29:47,160 --> 00:29:53,200
took to reach an answer, how much support there was for each answer, and the changes in

421
00:29:53,200 --> 00:29:55,520
that support over time.

422
00:29:55,520 --> 00:30:02,160
And it uses these features, this set of features, and trains on the outcome of the games.

423
00:30:02,160 --> 00:30:07,680
So if the swarm reaches an answer very quickly with high support for a single team, that's

424
00:30:07,680 --> 00:30:12,320
a very high conviction answer and it's going to give a high probability that the swarm gets

425
00:30:12,320 --> 00:30:13,320
that answer correct.

426
00:30:13,320 --> 00:30:18,080
And historically, we've seen that high support for an answer and short time to reach that

427
00:30:18,080 --> 00:30:21,840
answer is associated with a very accurate forecast.

428
00:30:21,840 --> 00:30:29,720
So it's a standard machine learning program, like inputs as behaviors, outputs as probability

429
00:30:29,720 --> 00:30:34,080
trained on a binary representation of, was this game correct?

430
00:30:34,080 --> 00:30:35,080
It was a loss.

431
00:30:35,080 --> 00:30:42,680
Yeah, it went to losses, exactly, with the special sauce really being the behaviors of individuals

432
00:30:42,680 --> 00:30:43,680
in the swarm, right?

433
00:30:43,680 --> 00:30:49,200
The special component of this is the data that we have access to as part of treating

434
00:30:49,200 --> 00:30:53,280
humans as data processors rather than data points.

435
00:30:53,280 --> 00:30:57,560
So the inputs are essentially kind of meta features of the swarm itself.

436
00:30:57,560 --> 00:31:01,000
Yep, exactly.

437
00:31:01,000 --> 00:31:06,400
And so we're kind of digging into the various places that machine learning expresses itself

438
00:31:06,400 --> 00:31:14,000
in the platform, the conviction network, you kind of went through these three finding

439
00:31:14,000 --> 00:31:18,160
the right people waiting for their contributions and post processing and then it sounds like

440
00:31:18,160 --> 00:31:24,000
the conviction network is a separate thing if I'm understanding that correctly.

441
00:31:24,000 --> 00:31:25,000
Yeah.

442
00:31:25,000 --> 00:31:29,800
Maybe let's kind of dig into a little bit the, you know, those first three finding the

443
00:31:29,800 --> 00:31:32,760
right people like, where does machine learning come in there?

444
00:31:32,760 --> 00:31:34,600
Well, we can start there.

445
00:31:34,600 --> 00:31:35,600
Sure.

446
00:31:35,600 --> 00:31:36,600
Yeah.

447
00:31:36,600 --> 00:31:42,600
So conviction is like a one part of the post processing in the pre-processing section.

448
00:31:42,600 --> 00:31:49,240
We want actually my first project with unanimous was as like a master's project in my program

449
00:31:49,240 --> 00:31:52,760
was to identify the right users, right?

450
00:31:52,760 --> 00:31:57,920
So let's, we get a number of surveys every week, every, every week before our sports

451
00:31:57,920 --> 00:31:58,920
warms.

452
00:31:58,920 --> 00:32:02,840
We do a survey and we say, who do you think will win, team A or team B for each of the

453
00:32:02,840 --> 00:32:04,520
games that we're predicting?

454
00:32:04,520 --> 00:32:09,640
Obviously, over time, we find that some users are better than others.

455
00:32:09,640 --> 00:32:15,640
And so part of our statistics and machine learning efforts focus on how do we identify

456
00:32:15,640 --> 00:32:20,160
the right like users that will perform well?

457
00:32:20,160 --> 00:32:23,400
One way to do that is by saying, okay, what's your historical accuracy?

458
00:32:23,400 --> 00:32:28,400
And we can use a Bayesian framework for that or we can use like other statistical frameworks

459
00:32:28,400 --> 00:32:31,120
to say, what is your average accuracy over time?

460
00:32:31,120 --> 00:32:32,960
And we can use those users?

461
00:32:32,960 --> 00:32:38,360
Or we could look a little deeper into the data that we're collecting and say for a specific

462
00:32:38,360 --> 00:32:43,480
survey, what is the probability that you are like a good user?

463
00:32:43,480 --> 00:32:48,480
How, how well are you expected to perform relative to average?

464
00:32:48,480 --> 00:32:53,480
We've made some really interesting strides in that space as well by treating humans as like

465
00:32:53,480 --> 00:32:59,160
again, as data processors rather than data points.

466
00:32:59,160 --> 00:33:04,000
And so like to give an example of one of the ways we're doing that, we designed recently

467
00:33:04,000 --> 00:33:11,880
a dynamic survey that uses a novel nonlinear scale to make humans really think about to

468
00:33:11,880 --> 00:33:20,600
weigh their risk and reward, to say they are essentially wagering on games, but the more

469
00:33:20,600 --> 00:33:27,320
that they wager on one team, the amount that they win if the other team is actually wins

470
00:33:27,320 --> 00:33:30,280
and is successful decreases even more.

471
00:33:30,280 --> 00:33:36,760
And so there's this nonlinear dichotomy that they have to think about and be faced with

472
00:33:36,760 --> 00:33:38,560
in order to make a decision.

473
00:33:38,560 --> 00:33:45,600
And so we found that this method of wagering, which if you go on our blog and take one of

474
00:33:45,600 --> 00:33:50,680
these sports predictions, you actually be directed to this novel scale, we found that

475
00:33:50,680 --> 00:33:57,920
this method of asking people to behave in a survey allows us to identify the good versus

476
00:33:57,920 --> 00:34:01,440
the bad performers on a specific week more accurately.

477
00:34:01,440 --> 00:34:06,640
So more than just saying, oh, you've performed well in the past, we have methods that allow

478
00:34:06,640 --> 00:34:12,800
us to identify, oh, on the specific week, are you likely to perform well?

479
00:34:12,800 --> 00:34:17,040
You know, say going back to kind of our predicting sports games, it strikes me that one of

480
00:34:17,040 --> 00:34:22,880
the keys would be figuring out the right representation or features for the games themselves.

481
00:34:22,880 --> 00:34:30,400
Like, how do you, what makes a given, you know, we talking about even the right people

482
00:34:30,400 --> 00:34:35,080
for hockey versus basketball, and I guess, you know, we can just label those as hockey

483
00:34:35,080 --> 00:34:40,040
and basketball, but if we're talking about a specific basketball game, are we, you

484
00:34:40,040 --> 00:34:41,560
know, is it kind of a naive thing?

485
00:34:41,560 --> 00:34:47,160
Well, this person, you know, bets correctly with regards to this team or, you know, I

486
00:34:47,160 --> 00:34:54,480
guess how rich is the feature space for that you're looking at for games or, you know,

487
00:34:54,480 --> 00:34:58,240
any of these things that you're trying to optimize the people choices around?

488
00:34:58,240 --> 00:34:59,240
Yeah, absolutely.

489
00:34:59,240 --> 00:35:00,840
That's a great question.

490
00:35:00,840 --> 00:35:05,960
So the data set is getting richer as we clutch more data.

491
00:35:05,960 --> 00:35:13,320
What I think you're moving towards is, can we wait the contributions of individuals for

492
00:35:13,320 --> 00:35:14,440
specific games?

493
00:35:14,440 --> 00:35:21,120
So if we notice that one of, like, this one user, let's call them user A, is great at predicting

494
00:35:21,120 --> 00:35:27,400
the outcome of night's games, maybe because there are nights fan, but really terrible at predicting

495
00:35:27,400 --> 00:35:31,800
Raptor games or, like, so those are two hockey teams.

496
00:35:31,800 --> 00:35:35,760
So they're great at predicting one hockey team, but really bad at predicting another hockey

497
00:35:35,760 --> 00:35:39,240
team, like, because they're fans of one team and maybe don't know anything about the other

498
00:35:39,240 --> 00:35:41,800
team.

499
00:35:41,800 --> 00:35:47,920
It's like, so could we wait that user in this form, highly on one question, give that sort

500
00:35:47,920 --> 00:35:53,480
of an expert level on one question and give them a novice level on another question, which

501
00:35:53,480 --> 00:36:04,480
is sort of yes we can, but we find that generally, we want to, we want to curate a diverse population

502
00:36:04,480 --> 00:36:07,960
so in order to make the most accurate predictions.

503
00:36:07,960 --> 00:36:13,920
And so the factors that I would highlight as being the most key to accurate swarm forecasting

504
00:36:13,920 --> 00:36:20,480
are the average level of knowledge of participants, the average, the size of the group as the two

505
00:36:20,480 --> 00:36:24,240
primary factors, and then the third is the diversity of beliefs.

506
00:36:24,240 --> 00:36:29,240
So the more, or the diversity of information sources, and what I would say about that

507
00:36:29,240 --> 00:36:35,640
is if everyone is answering questions from the same news source, so if everyone's getting

508
00:36:35,640 --> 00:36:40,640
their news from Fox News or something and there's no diversity, no one's getting from CNN

509
00:36:40,640 --> 00:36:46,040
or BBC or LG Zero, then they're all going to have the same belief and they may all be

510
00:36:46,040 --> 00:36:47,920
right or they may all be wrong.

511
00:36:47,920 --> 00:36:53,040
What swarms are really good at is aggregating from really diverse information sets, really

512
00:36:53,040 --> 00:36:54,120
diverse sources.

513
00:36:54,120 --> 00:37:00,840
And so if we have one night's fan and one raptors fan, that's probably going to be better

514
00:37:00,840 --> 00:37:06,920
than just having all really accurate night's fans in a group.

515
00:37:06,920 --> 00:37:12,600
So we've talked about post processing and pre processing, what are, what are kind of

516
00:37:12,600 --> 00:37:16,320
the underlying mechanisms of the waiting component?

517
00:37:16,320 --> 00:37:23,320
So the most important, so in during the swarm and the optimization of the swarm, which

518
00:37:23,320 --> 00:37:31,080
is the central component to our technology, the most important thing are these algorithms

519
00:37:31,080 --> 00:37:39,160
that we've discussed around how do we allow groups to deliberate, how do we engage them

520
00:37:39,160 --> 00:37:45,560
in a real time system, so the real time component of this algorithm is really the most important,

521
00:37:45,560 --> 00:37:51,240
but then second to that is how do we allow them to see each other's beliefs and how do

522
00:37:51,240 --> 00:37:52,880
we aggregate those beliefs?

523
00:37:52,880 --> 00:38:00,080
And so those are really systems level components that I think are the most important.

524
00:38:00,080 --> 00:38:06,640
And so is machine learning a component in doing those system level things or are they

525
00:38:06,640 --> 00:38:10,240
more deterministic in some way or?

526
00:38:10,240 --> 00:38:14,760
Yeah, so we use machine learning to understand what makes an accurate swarm.

527
00:38:14,760 --> 00:38:19,920
We use data science to do that as well as we are developed and as we become more complex

528
00:38:19,920 --> 00:38:25,720
as a company, we may be able to use machine learning within the algorithm itself.

529
00:38:25,720 --> 00:38:31,440
At the moment, what we've has gotten us to this point though has been just allowing,

530
00:38:31,440 --> 00:38:32,960
just having static algorithms.

531
00:38:32,960 --> 00:38:39,200
So algorithms that there's a list of I think 30 algorithms that determine how the swarm

532
00:38:39,200 --> 00:38:46,640
evolves determines the weight of individuals that determines the location of the puck,

533
00:38:46,640 --> 00:38:50,280
all of these different factors, and while we use data science and machine learning to

534
00:38:50,280 --> 00:38:57,600
optimize those factors, we don't use machine learning in the process of a swarm.

535
00:38:57,600 --> 00:39:05,840
And so we've talked about kind of sports betting as one area of use for this, you're building

536
00:39:05,840 --> 00:39:10,800
this for some customer, maybe you're building it ultimately to build a perpetual money

537
00:39:10,800 --> 00:39:15,960
machine and just get rich with compounding winnings.

538
00:39:15,960 --> 00:39:20,640
But perhaps is there a customer that you've got in mind for this?

539
00:39:20,640 --> 00:39:23,960
And if so, who is that customer?

540
00:39:23,960 --> 00:39:28,240
Is it the sports world or is that kind of a demonstration?

541
00:39:28,240 --> 00:39:33,120
Is there some other kind of customer who do you think needs this?

542
00:39:33,120 --> 00:39:38,840
Yeah, so I think it was Einstein that said compounding interest is the most powerful force

543
00:39:38,840 --> 00:39:42,040
in the universe, but that's not really our goal here.

544
00:39:42,040 --> 00:39:45,040
Our goal is to make humans smarter.

545
00:39:45,040 --> 00:39:53,360
It's to keep humans relevant in a time where AI is becoming very dominant or very powerful.

546
00:39:53,360 --> 00:39:57,520
This system follows by being based off of humans.

547
00:39:57,520 --> 00:40:03,000
It has human ethics, human morals, and it's able to make decisions that AI, I don't

548
00:40:03,000 --> 00:40:08,040
believe should, because it keeps humans in the loop.

549
00:40:08,040 --> 00:40:14,640
As a result of that, what we're really targeting with this platform is allowing human teams

550
00:40:14,640 --> 00:40:15,960
to access this tool.

551
00:40:15,960 --> 00:40:20,960
And so one of the exciting news and outs we have is that in the next two weeks we'll

552
00:40:20,960 --> 00:40:25,720
be opening this system up, this platform up for beta customers.

553
00:40:25,720 --> 00:40:31,680
So any business team that wants to amplify their accuracy of their forecasts or prioritizations

554
00:40:31,680 --> 00:40:36,760
or get consumer research in a more accurate way to understand that beliefs and needs

555
00:40:36,760 --> 00:40:43,880
of their consumers, all of these applications can be used by subscribers to this software.

556
00:40:43,880 --> 00:40:48,800
So really what we're focusing on is making humans smarter and having as broad a reach

557
00:40:48,800 --> 00:40:54,920
in terms of the teams and the applications that we can help people make good decisions

558
00:40:54,920 --> 00:40:56,560
with as possible.

559
00:40:56,560 --> 00:41:03,920
A link to that, the artificial swarm intelligence paper in the show notes and that one has a

560
00:41:03,920 --> 00:41:13,240
ton of references by yourself and Lewis in a variety of kind of peer reviewed conferences

561
00:41:13,240 --> 00:41:18,640
and journals and the like for folks that want to dig in deeper.

562
00:41:18,640 --> 00:41:23,360
But if you were to, is there any other kind of singular reference that you would point

563
00:41:23,360 --> 00:41:28,760
folks to who want to learn more about this way of kind of building systems or thinking

564
00:41:28,760 --> 00:41:29,760
about systems?

565
00:41:29,760 --> 00:41:35,000
Yeah, I think the white paper is the best resource for just understanding.

566
00:41:35,000 --> 00:41:40,640
And other than that, I would refer you to our website, unanimous.ai or our publications

567
00:41:40,640 --> 00:41:45,360
page, unanimous.ai slash publications, those both are great resources for understanding

568
00:41:45,360 --> 00:41:51,440
how this works, the applications for where this can be applied and sort of why it works.

569
00:41:51,440 --> 00:41:52,440
Awesome.

570
00:41:52,440 --> 00:41:53,440
So great.

571
00:41:53,440 --> 00:41:57,440
Thanks so much for taking the time to chat with me really interesting stuff.

572
00:41:57,440 --> 00:41:59,200
Thank you so much for having me.

573
00:41:59,200 --> 00:42:04,760
Alright, everyone, that's our show for today.

574
00:42:04,760 --> 00:42:10,640
For more information on this guest or any of our guests, visit twimmelai.com.

575
00:42:10,640 --> 00:42:14,720
Be sure to register for Twimmelcon AI platforms today.

576
00:42:14,720 --> 00:42:17,680
You can do that at twimmelcon.com.

577
00:42:17,680 --> 00:42:23,120
As always, thanks so much for listening and catch you next time.

