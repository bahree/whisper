1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:28,720
I'm your host Sam Charrington.

4
00:00:28,720 --> 00:00:33,040
I want to send a quick thanks to our friends at Cloud Era for their sponsorship of this

5
00:00:33,040 --> 00:00:39,760
series of podcasts from the Stratidata conference, which they present along with O'Reilly media.

6
00:00:39,760 --> 00:00:41,960
Cloud Era is long been a supporter of the podcast.

7
00:00:41,960 --> 00:00:47,760
In fact, they sponsored the very first episode of Twimble Talk back in 2016.

8
00:00:47,760 --> 00:00:51,920
Since that time, Cloud Era has continued to invest in and build out its platform, which

9
00:00:51,920 --> 00:00:57,680
already securely hosts huge volumes of enterprise data, to provide enterprise customers with

10
00:00:57,680 --> 00:01:01,920
a modern environment for machine learning and analytics that works both in the cloud

11
00:01:01,920 --> 00:01:04,200
as well as in the data center.

12
00:01:04,200 --> 00:01:09,640
In addition, Cloud Era Fast Forward Labs provides research and expert guidance that helps enterprises

13
00:01:09,640 --> 00:01:14,040
understand the realities of building with AI technologies without needing the higher

14
00:01:14,040 --> 00:01:16,400
and in-house research team.

15
00:01:16,400 --> 00:01:19,840
To learn more about what the company is up to and how they can help, visit Cloud Era's

16
00:01:19,840 --> 00:01:25,280
Machine Learning Resource Center at cladera.com slash ML.

17
00:01:25,280 --> 00:01:29,920
I'd also like to send a huge thanks to LinkedIn for their continued support and sponsorship

18
00:01:29,920 --> 00:01:30,920
of the show.

19
00:01:30,920 --> 00:01:34,560
Now that I've had a chance to interview several of the folks on LinkedIn's data science

20
00:01:34,560 --> 00:01:39,720
and engineering teams, it's really put into context the complexity and scale of the problems

21
00:01:39,720 --> 00:01:44,520
that they get to work on in their efforts to create enhanced economic opportunities for

22
00:01:44,520 --> 00:01:46,520
every member of the global workforce.

23
00:01:46,520 --> 00:01:51,360
AI and machine learning are integral aspects of almost every product that LinkedIn builds

24
00:01:51,360 --> 00:01:56,040
for its members and customers, and their massive, highly structured data set gives their

25
00:01:56,040 --> 00:02:00,960
data scientists and researchers the ability to conduct applied research to improve member

26
00:02:00,960 --> 00:02:02,800
experiences.

27
00:02:02,800 --> 00:02:09,320
To learn more about the work of LinkedIn Engineering, please visit engineering.linkedin.com slash

28
00:02:09,320 --> 00:02:10,800
blog.

29
00:02:10,800 --> 00:02:16,600
Alright everyone, I am on the line with Burju Bottom.

30
00:02:16,600 --> 00:02:19,640
Burju is a senior data scientist at LinkedIn.

31
00:02:19,640 --> 00:02:23,000
Burju, welcome to this week in Machine Learning and AI.

32
00:02:23,000 --> 00:02:24,000
Thank you very much.

33
00:02:24,000 --> 00:02:26,000
Thanks for having me.

34
00:02:26,000 --> 00:02:27,000
Absolutely.

35
00:02:27,000 --> 00:02:32,040
So, you gave a presentation at Shrata, was it yesterday?

36
00:02:32,040 --> 00:02:34,720
Yes, it was yesterday afternoon.

37
00:02:34,720 --> 00:02:40,440
And you're actually part of a group of folks at LinkedIn talking about using the full spectrum

38
00:02:40,440 --> 00:02:44,120
of data science to drive business decisions.

39
00:02:44,120 --> 00:02:52,320
And so we'll dig into that topic in a lot more detail, but before we do, how did you get

40
00:02:52,320 --> 00:02:55,920
started working in data science and machine learning?

41
00:02:55,920 --> 00:02:56,920
Yeah.

42
00:02:56,920 --> 00:03:03,320
So, yeah, so I work as a data scientist with the data mining team at LinkedIn, but actually

43
00:03:03,320 --> 00:03:10,440
I am a mathematician, so I did my PhD in math in number theory and algebraic geometry,

44
00:03:10,440 --> 00:03:15,880
which actually is a pure math, nothing to do with the applied math, we just prove theorems

45
00:03:15,880 --> 00:03:17,200
and stuff.

46
00:03:17,200 --> 00:03:18,720
And then after my PhD...

47
00:03:18,720 --> 00:03:22,280
I still have nightmares of real analysis in grad school.

48
00:03:22,280 --> 00:03:23,280
Oh.

49
00:03:23,280 --> 00:03:25,160
And that was probably your favorite topic.

50
00:03:25,160 --> 00:03:28,520
Actually, I don't like real algorithms also.

51
00:03:28,520 --> 00:03:31,680
Like, what kind of linear algebra kind of stuff?

52
00:03:31,680 --> 00:03:32,680
Yeah.

53
00:03:32,680 --> 00:03:33,680
Okay.

54
00:03:33,680 --> 00:03:41,440
So, yeah, I was still, yeah, I can understand your pain though.

55
00:03:41,440 --> 00:03:42,440
Yeah.

56
00:03:42,440 --> 00:03:51,920
So, I did my PhD in Europe, and then I came to US as a postdoc at Stanford Math Department.

57
00:03:51,920 --> 00:03:57,040
I was there for two years, and then I went to University of Michigan.

58
00:03:57,040 --> 00:04:03,360
And again, I stayed there another two years, but I was still thinking about being

59
00:04:03,360 --> 00:04:04,360
mathematician.

60
00:04:04,360 --> 00:04:08,520
I didn't have any idea about going in the industry, being data scientists, et cetera.

61
00:04:08,520 --> 00:04:13,720
But during my time at Stanford Math Department, I had some friends in this area who are working

62
00:04:13,720 --> 00:04:14,720
with me.

63
00:04:14,720 --> 00:04:15,720
You make it sound like prison.

64
00:04:15,720 --> 00:04:16,960
You don't have time.

65
00:04:16,960 --> 00:04:23,360
And this was like five, seven years ago, I think, yeah.

66
00:04:23,360 --> 00:04:28,240
So during my deadline, I had some friends, and they already know like, we're much into

67
00:04:28,240 --> 00:04:33,040
this machine learning techniques, and whenever they have this math problem related to

68
00:04:33,040 --> 00:04:36,040
their machine learning problem, they were bringing to me.

69
00:04:36,040 --> 00:04:39,480
And that's where I started to understand like how machine learning works, but only the

70
00:04:39,480 --> 00:04:41,400
math side of it, of course.

71
00:04:41,400 --> 00:04:46,040
And then like during my time at Michigan, I was really very much into this machine learning.

72
00:04:46,040 --> 00:04:48,360
I started thinking more about that.

73
00:04:48,360 --> 00:04:54,120
I slowly, I slowly, you know, like, move toward this applied side of math, like, oh, you

74
00:04:54,120 --> 00:04:58,360
know, by using math, you can also solve that kind of interesting problems.

75
00:04:58,360 --> 00:05:02,840
And then I decided to, you know, like, one day actually I decided that I will quit

76
00:05:02,840 --> 00:05:08,320
math, and then I will go into the machine learning.

77
00:05:08,320 --> 00:05:14,200
But saying that, of course, not that easy, like having all this theoretical math background,

78
00:05:14,200 --> 00:05:20,000
no coding or nothing, no sense of skill knowledge, just knowing the math, like, you cannot

79
00:05:20,000 --> 00:05:22,240
just go and do a machine learning.

80
00:05:22,240 --> 00:05:27,720
I came to this area again, I talked to my friends, and I asked them like, what else I should

81
00:05:27,720 --> 00:05:29,280
learn them.

82
00:05:29,280 --> 00:05:34,000
And I realized it will, this transition will not be that easy.

83
00:05:34,000 --> 00:05:38,120
But then I was lucky that I, at that time, I heard about this inside data science fellow

84
00:05:38,120 --> 00:05:39,120
program.

85
00:05:39,120 --> 00:05:45,800
So this program helps people who has PhD in quantitative sciences to do the transitioning

86
00:05:45,800 --> 00:05:47,200
to data science.

87
00:05:47,200 --> 00:05:52,840
So I was accepted to that program, luckily, and they helped me actually to do the transition.

88
00:05:52,840 --> 00:05:56,680
So they helped me to build the network and, you know, like, learn the right stuff and

89
00:05:56,680 --> 00:06:01,840
then have some data science project, and then, you know, start to talk to companies about

90
00:06:01,840 --> 00:06:05,920
being data scientists, going into interview and stuff.

91
00:06:05,920 --> 00:06:12,080
And my first job was at a startup, which was, it's a six ounce, which is located in San

92
00:06:12,080 --> 00:06:13,080
Francisco.

93
00:06:13,080 --> 00:06:15,600
They are just be to be intelligence company.

94
00:06:15,600 --> 00:06:22,160
So we were doing a lot of machine learning there, actually, like, I, I mean, I had learned

95
00:06:22,160 --> 00:06:26,840
about the theory of machine learning, but of course, like, applying it, like coding and

96
00:06:26,840 --> 00:06:30,680
dying of getting the results with the real data is completely different.

97
00:06:30,680 --> 00:06:34,920
So this is like where I really learned how to do machine learning.

98
00:06:34,920 --> 00:06:40,720
And then after two years working there, three years ago, I started to work at LinkedIn.

99
00:06:40,720 --> 00:06:44,760
And since then, I'm working with the, with the data mining team at LinkedIn.

100
00:06:44,760 --> 00:06:45,760
Okay.

101
00:06:45,760 --> 00:06:46,760
Awesome.

102
00:06:46,760 --> 00:06:54,920
I've had a number of folks from, they went through the insight program on the show.

103
00:06:54,920 --> 00:07:03,880
I've also interviewed, I think Ross Fadley is at his name out of New York.

104
00:07:03,880 --> 00:07:13,800
And I know a manual who runs the AI program or track out of the Bay area.

105
00:07:13,800 --> 00:07:18,200
And I've had a bunch of really great conversations with folks affiliated with, uh, with insight

106
00:07:18,200 --> 00:07:20,640
in, in one capacity or another.

107
00:07:20,640 --> 00:07:24,880
It seems like a great program for folks that are kind of finishing, you know, transitioning

108
00:07:24,880 --> 00:07:29,480
from academia to, you know, their data science or machine learning or they've got a bunch

109
00:07:29,480 --> 00:07:31,680
of other projects now or programs now.

110
00:07:31,680 --> 00:07:32,680
Yeah.

111
00:07:32,680 --> 00:07:33,680
Exactly.

112
00:07:33,680 --> 00:07:36,320
So actually, when I was in this inside, they were pretty new.

113
00:07:36,320 --> 00:07:37,320
It was there.

114
00:07:37,320 --> 00:07:38,320
I was there.

115
00:07:38,320 --> 00:07:41,520
Second group, actually, like, this was four years ago.

116
00:07:41,520 --> 00:07:42,520
Yeah.

117
00:07:42,520 --> 00:07:45,760
And now they are pretty big actually, like, they have a lot of programs going on.

118
00:07:45,760 --> 00:07:46,760
Yeah.

119
00:07:46,760 --> 00:07:47,760
Yeah.

120
00:07:47,760 --> 00:07:55,640
So maybe before we dive into kind of this, your session and, and data mining, I'm curious

121
00:07:55,640 --> 00:08:05,080
about the, you know, this transition from kind of theoretical mathematician to data scientists.

122
00:08:05,080 --> 00:08:07,760
Do you use any of the theoretical math?

123
00:08:07,760 --> 00:08:12,480
Does it kind of impact at all the way you think about data science or not really?

124
00:08:12,480 --> 00:08:19,120
Oh, honestly, the math that I learned at the PhD level, I don't use that at all.

125
00:08:19,120 --> 00:08:24,920
Like, no, unfortunately, I wish I could do it, but no, because I really spent a lot of

126
00:08:24,920 --> 00:08:27,840
time to, you know, understand those concepts.

127
00:08:27,840 --> 00:08:33,720
But, but of course, like being in math, like, having math education for almost 15, 16

128
00:08:33,720 --> 00:08:36,600
years, I'm being in math professionally for 10 years.

129
00:08:36,600 --> 00:08:40,720
Of course, it has a lot of effect on how I do data science.

130
00:08:40,720 --> 00:08:45,760
So obviously, like, I'm used to have this analytic thinking kind of thing.

131
00:08:45,760 --> 00:08:50,880
So when I have the problem, I can put a structure on it and I can, I can see the big picture.

132
00:08:50,880 --> 00:08:53,600
And then I can try to solve it.

133
00:08:53,600 --> 00:08:59,640
And also, I have, I all the time do this reasoning thing, because no, I'm used to prove theorems

134
00:08:59,640 --> 00:09:01,840
know, just combine all these logics.

135
00:09:01,840 --> 00:09:03,880
If this is this, then this is that.

136
00:09:03,880 --> 00:09:09,320
So this also helped me to think not only about house, but I also care about why.

137
00:09:09,320 --> 00:09:15,760
So that helps me to have the understanding about the problem and also about their solution.

138
00:09:15,760 --> 00:09:20,080
And also, of course, I'm very comfortable with the mathematical concept.

139
00:09:20,080 --> 00:09:21,880
And actually, I have a story.

140
00:09:21,880 --> 00:09:28,200
So this was my interview with this, with the startup, this is my first job as a data scientist.

141
00:09:28,200 --> 00:09:32,440
So there was a lead data scientist there and he was interviewing me about machine learning

142
00:09:32,440 --> 00:09:33,840
techniques.

143
00:09:33,840 --> 00:09:39,520
And in the first half of the interview, he started to ask me about questions about those

144
00:09:39,520 --> 00:09:41,200
machine learning algorithms.

145
00:09:41,200 --> 00:09:44,440
And he was always asked me why you do this, why you do that?

146
00:09:44,440 --> 00:09:47,400
And I was so comfortable to explain those.

147
00:09:47,400 --> 00:09:48,960
No, I was comfortable with teaching.

148
00:09:48,960 --> 00:09:50,760
I was comfortable with the math concepts.

149
00:09:50,760 --> 00:09:54,160
And it was like, I was like, wow, I'm really rough in the interview.

150
00:09:54,160 --> 00:09:58,840
Like, I know everything, like, and I like, okay, first half was great.

151
00:09:58,840 --> 00:10:03,360
And then in the second half, he said, okay, you know, all these algorithms well.

152
00:10:03,360 --> 00:10:09,280
Now let's go to the easy part, he said, now I want you to implement this, you know, algorithm

153
00:10:09,280 --> 00:10:10,280
on the watch.

154
00:10:10,280 --> 00:10:14,000
I was like, oops, there's not that easy for me.

155
00:10:14,000 --> 00:10:18,480
And yeah, and I explained to him like, yeah, you think it's the easiest, not easy for

156
00:10:18,480 --> 00:10:19,480
me.

157
00:10:19,480 --> 00:10:27,480
And actually, it took a whole lot of time to implement this on the white board.

158
00:10:27,480 --> 00:10:31,600
And then he explained to me that he said that, yeah, this is, I can understand that you

159
00:10:31,600 --> 00:10:35,680
don't have any coding experience, because I had just told myself half the code.

160
00:10:35,680 --> 00:10:41,080
So it was not really easy for me just to do it on the internet, especially on the interviews.

161
00:10:41,080 --> 00:10:46,920
And but he said that the direction that you come from is completely different.

162
00:10:46,920 --> 00:10:51,760
Usually people learns about these algorithms, how they work, how to code, and then maybe

163
00:10:51,760 --> 00:10:54,040
they dig into the math of those.

164
00:10:54,040 --> 00:10:56,280
So you are completely coming from different directions.

165
00:10:56,280 --> 00:10:58,880
So you had a deeper understanding of how they work.

166
00:10:58,880 --> 00:11:03,800
But now you also have to understand like, you know, like how to write the code and stuff.

167
00:11:03,800 --> 00:11:06,440
So, and this is true, like, this is helping now.

168
00:11:06,440 --> 00:11:10,240
I'm much more comfortable with the coding, obviously.

169
00:11:10,240 --> 00:11:14,600
But this heading is deeper understanding of all these mathematical concepts behind those

170
00:11:14,600 --> 00:11:20,200
algorithms is really helping me a lot, like, you know, like, because when you do the modeling,

171
00:11:20,200 --> 00:11:22,520
it's, there's always some problems.

172
00:11:22,520 --> 00:11:28,800
So if you know, like, where the problem comes from, it'll be, you save a lot of time,

173
00:11:28,800 --> 00:11:29,800
actually.

174
00:11:29,800 --> 00:11:33,560
Otherwise, it's really hard to debug everything and then try to find out what's going

175
00:11:33,560 --> 00:11:34,560
on.

176
00:11:34,560 --> 00:11:35,560
Yeah.

177
00:11:35,560 --> 00:11:42,000
Um, so this, the, the session that you, uh, did at strata was called using the full

178
00:11:42,000 --> 00:11:45,600
spectrum of data science to drive business decisions.

179
00:11:45,600 --> 00:11:46,600
Yeah.

180
00:11:46,600 --> 00:11:47,800
Let's just kind of pick that apart.

181
00:11:47,800 --> 00:11:49,360
Let's start with full spectrum.

182
00:11:49,360 --> 00:11:54,360
When you talk about full spectrum of data science, uh, what are you referring to?

183
00:11:54,360 --> 00:11:59,480
And it almost implies that you, you, you think that at a lot of places, people don't use

184
00:11:59,480 --> 00:12:04,760
the full spectrum of data science, maybe, um, you know, what, what are you getting at with

185
00:12:04,760 --> 00:12:05,760
that?

186
00:12:05,760 --> 00:12:09,320
So with the full spectrum, we are talking about the whole process.

187
00:12:09,320 --> 00:12:14,880
Actually, we talk about this, how we do this production modeling, like the whole machine

188
00:12:14,880 --> 00:12:20,320
learning process, not only just the algorithm part, but we start from the, uh, actually,

189
00:12:20,320 --> 00:12:25,480
the problem definition part, how we clearly, when the business people bring us the problem,

190
00:12:25,480 --> 00:12:30,280
how we clearly define the problem, so that we can convert into the mathematical problem

191
00:12:30,280 --> 00:12:32,360
so that we can solve it.

192
00:12:32,360 --> 00:12:36,400
And once we have the problem, we have the full definition, then we have to think about

193
00:12:36,400 --> 00:12:38,120
the data that we have.

194
00:12:38,120 --> 00:12:42,400
So for example, the label, if this will be the supervised learning, the label preparation

195
00:12:42,400 --> 00:12:43,400
is very important.

196
00:12:43,400 --> 00:12:47,960
So every, every business problem has different way of preparing the label.

197
00:12:47,960 --> 00:12:51,520
So we should be very careful about this label preparation.

198
00:12:51,520 --> 00:12:55,840
And once we had the label preparation, then we had to think about the features.

199
00:12:55,840 --> 00:13:00,920
So, um, and when you had the features, how do you integrate with the labels, like, how

200
00:13:00,920 --> 00:13:03,720
do you do the alignments on the timeline?

201
00:13:03,720 --> 00:13:09,040
Uh, and you had the static features, dynamic features, how would you combine those static

202
00:13:09,040 --> 00:13:11,160
and dynamic features?

203
00:13:11,160 --> 00:13:17,040
And once you, you know, settle all those, then we start with the modeling techniques,

204
00:13:17,040 --> 00:13:22,840
like training and we talk about the data partitioning and, uh, and, uh, we, we talk about,

205
00:13:22,840 --> 00:13:28,640
like, the common mistakes that first we did and that, then, like, um, then, now, like,

206
00:13:28,640 --> 00:13:33,240
we have a lesson, uh, so that, uh, we don't do it anymore.

207
00:13:33,240 --> 00:13:37,280
And, uh, and then after the training, we talk about the model deployment.

208
00:13:37,280 --> 00:13:42,920
So how do we give our results to, to our business partners?

209
00:13:42,920 --> 00:13:48,720
And the most important part and actually the, um, most, um, challenging part is when you

210
00:13:48,720 --> 00:13:54,160
give the results, your business, uh, business partners, uh, when you solve the problem, it's

211
00:13:54,160 --> 00:13:55,320
not finished yet.

212
00:13:55,320 --> 00:14:00,840
So because they use this, uh, this, uh, solution over and over again.

213
00:14:00,840 --> 00:14:06,920
So you have to check the, if the, if the features are more, or the models is doing good.

214
00:14:06,920 --> 00:14:11,560
So because you had the results the first day, everybody's confident about results, model

215
00:14:11,560 --> 00:14:12,560
is fresh.

216
00:14:12,560 --> 00:14:13,560
It's perfect.

217
00:14:13,560 --> 00:14:17,040
But after 30 days, oops, something going on, the red flag.

218
00:14:17,040 --> 00:14:18,240
So what's going on now?

219
00:14:18,240 --> 00:14:20,920
So, so we have to monitor the features.

220
00:14:20,920 --> 00:14:25,960
We have to monitor the model performance and there, we have to just run basic statistics

221
00:14:25,960 --> 00:14:31,360
about, like, is everything stable or there's some degradation somewhere.

222
00:14:31,360 --> 00:14:36,520
And, um, and once you do this, maybe you make, you might decide to do a model refresh.

223
00:14:36,520 --> 00:14:41,560
When you do the model refresh, uh, you need to do the AB testing with the current model

224
00:14:41,560 --> 00:14:44,800
and then decide which model to, to release.

225
00:14:44,800 --> 00:14:49,600
But sometimes the, it's not the model that the problem, where the problem is, sometimes

226
00:14:49,600 --> 00:14:52,080
it is the feature logic is different.

227
00:14:52,080 --> 00:14:59,280
So for example, uh, let's say, um, your, one of the feature is the checking the traffic

228
00:14:59,280 --> 00:15:06,400
of your web page, let's say, uh, and, uh, let's say your web page is just one page

229
00:15:06,400 --> 00:15:10,760
web page, but after a month, it has just three pages.

230
00:15:10,760 --> 00:15:15,160
But then checking the traffic of the first page is now changing the meaning.

231
00:15:15,160 --> 00:15:19,640
So you should be aware of those kind of changes if it is, if it is there.

232
00:15:19,640 --> 00:15:24,720
So, uh, because you need to, you need to be aware of the content, if you are giving the

233
00:15:24,720 --> 00:15:28,040
right content to your machine learning model or not.

234
00:15:28,040 --> 00:15:33,360
So, so we talk about whole this process and each steps, like in detail.

235
00:15:33,360 --> 00:15:39,280
And then we also talk about some, uh, common pitfalls and challenges that we have during

236
00:15:39,280 --> 00:15:40,280
this process.

237
00:15:40,280 --> 00:15:43,760
Like, uh, for example, the model interpretation is one of the biggest challenges that

238
00:15:43,760 --> 00:15:49,640
we have here, uh, because when we present our results, the business partners, they don't

239
00:15:49,640 --> 00:15:53,960
only care about the results, they also care about why we get these results.

240
00:15:53,960 --> 00:15:55,880
What are the key drivers?

241
00:15:55,880 --> 00:16:01,600
So it's pretty challenging to, to, to find, especially, uh, when you have the more complex

242
00:16:01,600 --> 00:16:05,160
models, it's, it's getting harder to explain what's going on.

243
00:16:05,160 --> 00:16:10,400
So you cannot just, you know, use models as a black box, uh, for those kind of problems.

244
00:16:10,400 --> 00:16:13,520
It's also data quality is very important and it's another challenge.

245
00:16:13,520 --> 00:16:18,560
The more data is much harder to maintain the quality of the data.

246
00:16:18,560 --> 00:16:22,920
So yeah, we talk about whole this process by giving examples and the, um, the things that

247
00:16:22,920 --> 00:16:27,600
we need to care for what, but this was the whole, like, how we use the whole spectrum of

248
00:16:27,600 --> 00:16:30,400
data science to, to give business decisions.

249
00:16:30,400 --> 00:16:35,840
Well, that's a lot of, I think you're like, now that, now I understand why there are

250
00:16:35,840 --> 00:16:40,440
like five or six people presenting this, uh, yeah, I thought it was at a full day tutorial

251
00:16:40,440 --> 00:16:44,240
or a half day or something, three hours, actually, three hours.

252
00:16:44,240 --> 00:16:45,240
Okay.

253
00:16:45,240 --> 00:16:46,240
Yeah.

254
00:16:46,240 --> 00:16:47,240
Uh, a lot will be online soon.

255
00:16:47,240 --> 00:16:48,240
So, yeah.

256
00:16:48,240 --> 00:16:49,240
Okay.

257
00:16:49,240 --> 00:16:50,240
Oh, cool.

258
00:16:50,240 --> 00:16:55,160
So, uh, let's maybe walk through some of these points, um, you know, you started, uh,

259
00:16:55,160 --> 00:16:59,200
at the beginning, right, problem formulation, a lot of people, you know, we talk a lot

260
00:16:59,200 --> 00:17:05,760
about algorithms, um, but that initial, you know, phase of really understanding the problem

261
00:17:05,760 --> 00:17:11,400
that you're trying to solve and translating that into, you know, kind of mathematical

262
00:17:11,400 --> 00:17:15,360
or data science thinking can be, uh, a challenge.

263
00:17:15,360 --> 00:17:21,400
What, how do you approach that and, you know, what have you learned, uh, you know, what,

264
00:17:21,400 --> 00:17:24,400
what do you think that people get wrong about that?

265
00:17:24,400 --> 00:17:30,560
Um, actually, the, what I learned is that the domain knowledge is very important.

266
00:17:30,560 --> 00:17:35,360
So it's not only only the business partner can, you know, make it like a good problem

267
00:17:35,360 --> 00:17:40,200
to solve or it's not only data scientists who can, you know, just make it into math problem

268
00:17:40,200 --> 00:17:41,720
and then start solving it.

269
00:17:41,720 --> 00:17:43,560
It's the conversation is very important.

270
00:17:43,560 --> 00:17:47,920
So you should, data scientists should really understand what is really the business partners

271
00:17:47,920 --> 00:17:52,000
trying to solve, what is the background, where this problem is coming from.

272
00:17:52,000 --> 00:17:58,040
And then, uh, once the data science understand that data science understand this, then, uh,

273
00:17:58,040 --> 00:18:02,200
she needs to convert this into mathematical problem, but then she needs to explain like

274
00:18:02,200 --> 00:18:07,640
how she views it, like where the solution is going is a solution that she's trying to

275
00:18:07,640 --> 00:18:12,560
go, is the direction is the same as the business partners thinking about, I think the conversation

276
00:18:12,560 --> 00:18:14,040
is really very important.

277
00:18:14,040 --> 00:18:19,280
The, the, when data scientists try to try to convert this problem into mathematical problem,

278
00:18:19,280 --> 00:18:22,800
she needs to understand the domain knowledge from the business partner.

279
00:18:22,800 --> 00:18:27,400
So, uh, for example, I will give a very, very easy example.

280
00:18:27,400 --> 00:18:33,480
So let's say, uh, LinkedIn talent, LinkedIn talent has this product called Curious Suscription.

281
00:18:33,480 --> 00:18:37,800
So it's usually the people who are job-seeker by this products.

282
00:18:37,800 --> 00:18:42,400
It's more about you can be the third degree connections profile and you can do advanced

283
00:18:42,400 --> 00:18:44,360
job search, etc.

284
00:18:44,360 --> 00:18:49,360
So let's say, uh, LinkedIn talent wants to make an email campaign for the product, uh,

285
00:18:49,360 --> 00:18:55,840
Curious Suscription and, uh, they want to send email for this and how do they send, who,

286
00:18:55,840 --> 00:18:59,560
who they should send those emails, basically, this, this is the question that they bring

287
00:18:59,560 --> 00:19:00,560
up to us.

288
00:19:00,560 --> 00:19:06,120
So obviously, for example, they cannot send it to all like 610 million members.

289
00:19:06,120 --> 00:19:12,240
So we would have a, we would have another problem if they would do this.

290
00:19:12,240 --> 00:19:16,520
So they, they bring this problem to us and then we start to ask this question, oh, do

291
00:19:16,520 --> 00:19:19,040
we also have historical data about this?

292
00:19:19,040 --> 00:19:21,480
Did you already sell this product before?

293
00:19:21,480 --> 00:19:24,920
So if you sell this product before, can we get the data?

294
00:19:24,920 --> 00:19:29,720
So are these people are the member, LinkedIn member, can we get more data about those people?

295
00:19:29,720 --> 00:19:34,280
Once we are able to get the answer for this down, we slowly say, okay, we had the data

296
00:19:34,280 --> 00:19:35,520
down, we can solve this problem.

297
00:19:35,520 --> 00:19:40,840
We can just apply machine learning techniques and then, um, get the solution and then, uh,

298
00:19:40,840 --> 00:19:46,760
it results, but then they say, okay, I don't only care about who, who, who, who will, who

299
00:19:46,760 --> 00:19:51,600
I'm going to send this email, but I also care about why I send this email to these people

300
00:19:51,600 --> 00:19:55,720
that I said, oops, then they want the model interpretation also.

301
00:19:55,720 --> 00:19:57,720
So then, uh, the problem is different.

302
00:19:57,720 --> 00:20:00,920
So I don't only care the performance of the model.

303
00:20:00,920 --> 00:20:04,840
I also care about the interpretation of the model.

304
00:20:04,840 --> 00:20:09,600
So when I'm doing the modeling, I need to balance between the, uh, performance and

305
00:20:09,600 --> 00:20:16,240
also interpretation, because, um, without experience like, we, like models like random

306
00:20:16,240 --> 00:20:21,960
forums, uh, XG booths are, uh, performance much better than the logistic regression, linear

307
00:20:21,960 --> 00:20:27,560
regression, those kind of models, but, uh, the, this kind of ran, it's, it's hard to use

308
00:20:27,560 --> 00:20:31,400
the, it's hard to do the model interpretation with the random forest.

309
00:20:31,400 --> 00:20:36,160
Um, of course, there are these, uh, future importance coming from these machine learning

310
00:20:36,160 --> 00:20:39,800
techniques, but we should be careful about the bias coming from them also.

311
00:20:39,800 --> 00:20:42,400
So it's, it's hard to use them as a black box.

312
00:20:42,400 --> 00:20:48,840
So we try to, we try to get use more, much simpler model, maybe sacrifice some of the

313
00:20:48,840 --> 00:20:50,600
performance of the model.

314
00:20:50,600 --> 00:20:54,200
So yeah, those are the things like, you know, they tell us the problem and then we think

315
00:20:54,200 --> 00:21:00,000
about the mathematical solution, but then we, we, we, we drive the conversation from

316
00:21:00,000 --> 00:21:03,840
their own and then try to find solution together, basically.

317
00:21:03,840 --> 00:21:10,120
And is, is this a process that you usually able to, you know, you, you have an hour meeting

318
00:21:10,120 --> 00:21:14,760
scheduled and they come to you and tell you their problem and you kind of, you're all

319
00:21:14,760 --> 00:21:21,000
on the same page by the end of that meeting or is it a, a, a process that, you know, continues

320
00:21:21,000 --> 00:21:24,320
uh, for an extended period of time?

321
00:21:24,320 --> 00:21:31,120
Actually, yeah, so, um, it's usually like, my team is more like, uh, more like, uh,

322
00:21:31,120 --> 00:21:36,760
help say, like horizontal team. So for example, LinkedIn turned ahead on data science team.

323
00:21:36,760 --> 00:21:39,960
So they are in conversation with their data science team.

324
00:21:39,960 --> 00:21:45,680
So this data science team already had them to convert this problem into mathematical problems

325
00:21:45,680 --> 00:21:49,040
and this team is aware of all the data, everything that they have.

326
00:21:49,040 --> 00:21:52,360
So they are in contact with them all the time, basically.

327
00:21:52,360 --> 00:21:53,920
So this is a vertical data science team.

328
00:21:53,920 --> 00:21:58,320
I am more horizontal data science team, we are more, um, technical.

329
00:21:58,320 --> 00:22:02,520
So when they, when this, their data science team had this machine learning problem and

330
00:22:02,520 --> 00:22:07,880
if it is a little bit more complicated than they expect, than they bring this problem

331
00:22:07,880 --> 00:22:12,800
to our team and then we try to solve this together with their data science team.

332
00:22:12,800 --> 00:22:17,200
So when we had the question, we usually contact with the data science team, but yeah, data

333
00:22:17,200 --> 00:22:20,160
science team is all the time in contact with business partners.

334
00:22:20,160 --> 00:22:24,040
So they are a way of what's going on on their side, yeah.

335
00:22:24,040 --> 00:22:30,640
Do you often find that, um, that folks are kind of going down, you know, blind alleys

336
00:22:30,640 --> 00:22:36,360
and you have to like, you know, you're, you're, you're engaged with folks that are kind

337
00:22:36,360 --> 00:22:42,040
of far into the modeling process, but in order to actually make progress on what the,

338
00:22:42,040 --> 00:22:46,720
the business is trying to do, you have to kind of start all the way over from the definition

339
00:22:46,720 --> 00:22:55,360
of the product or, um, do, you know, just having kind of a data science team that you're

340
00:22:55,360 --> 00:22:57,880
working with kind of alleviate that issue.

341
00:22:57,880 --> 00:23:03,720
I, I guess I, I get finding conversations, you know, with, uh, you know, folks that are

342
00:23:03,720 --> 00:23:08,200
in data science, supporting, you know, business units that often the business units will come

343
00:23:08,200 --> 00:23:13,280
to them with kind of, you know, wild half, you know, thought out, you know, hey, I want

344
00:23:13,280 --> 00:23:18,840
a model that does this and there's really this kind of walking back that you need to do

345
00:23:18,840 --> 00:23:24,440
to get them away from thinking about a specific solution to what the problem that they're actually

346
00:23:24,440 --> 00:23:29,600
trying to solve is, um, and I'm wondering how that manifests for you with the kind of two

347
00:23:29,600 --> 00:23:33,400
layers that you have to get back to that, the business itself.

348
00:23:33,400 --> 00:23:34,400
Yeah.

349
00:23:34,400 --> 00:23:39,680
I mean, those things happen so few times it happens, for example, like, uh, the, the problem,

350
00:23:39,680 --> 00:23:43,640
the way that they convert it doesn't make sense and we realize it when we start to check

351
00:23:43,640 --> 00:23:44,640
the data.

352
00:23:44,640 --> 00:23:49,480
So we realize it's something going something is wrong, you know, like it's not maybe these

353
00:23:49,480 --> 00:23:53,320
are not the, um, these are not the results that they expect.

354
00:23:53,320 --> 00:23:59,640
So and then you start to slowly debug then on the process from problem formulation to

355
00:23:59,640 --> 00:24:05,080
getting the data, something must be broken there, then we slowly debug and a few times

356
00:24:05,080 --> 00:24:09,520
you realize the problem preparation problem, there is a problem with the problem, the

357
00:24:09,520 --> 00:24:13,840
definition, then we go back there together all together and we sit together.

358
00:24:13,840 --> 00:24:17,560
We try to understand now we try to convert the problem together there.

359
00:24:17,560 --> 00:24:19,920
Yeah, it happened actually a few times.

360
00:24:19,920 --> 00:24:25,800
And is there a, you kind of talk about this debugging process?

361
00:24:25,800 --> 00:24:29,720
Is it, uh, you know, what is that process?

362
00:24:29,720 --> 00:24:36,280
Is there kind of a set way that you go about that or is it kind of systematically, you

363
00:24:36,280 --> 00:24:41,680
know, checking your various assumptions into you, find something that doesn't line up?

364
00:24:41,680 --> 00:24:47,320
So, uh, so there is some parts that we do manually and the other parts are done in the

365
00:24:47,320 --> 00:24:48,320
platform.

366
00:24:48,320 --> 00:24:52,080
So the ones that we do the manually, we really check if we are doing it correctly or not.

367
00:24:52,080 --> 00:24:55,480
For example, the, the logic on the label preparation.

368
00:24:55,480 --> 00:24:58,960
So is it, is it really the, the logic there is the right logic?

369
00:24:58,960 --> 00:25:04,240
Um, I'm usually like, you know, the models that I'm talking about, they are done like many

370
00:25:04,240 --> 00:25:05,240
times.

371
00:25:05,240 --> 00:25:09,560
But when you do it for the first time, then there might be a problem.

372
00:25:09,560 --> 00:25:16,480
So we are very careful about the, the, the problem, for example, uh, on B2B business or even

373
00:25:16,480 --> 00:25:23,640
B2C like acquiring a new customer or empowering a new customer, uh, empowering, empowering

374
00:25:23,640 --> 00:25:28,320
existing customer of like a turn model, uh, we have done those models before.

375
00:25:28,320 --> 00:25:33,800
So we know how to, we know the label logic, we know how to do the problem definition.

376
00:25:33,800 --> 00:25:38,920
But if you are, if the new problem comes and it's the first time that they have this problem,

377
00:25:38,920 --> 00:25:40,240
there we need to be careful.

378
00:25:40,240 --> 00:25:44,120
Like they're actually, uh, you don't immediately put the definition and then start the

379
00:25:44,120 --> 00:25:45,120
soul.

380
00:25:45,120 --> 00:25:46,120
So this is ongoing process.

381
00:25:46,120 --> 00:25:50,120
You start to think about it and then you maybe try one prototype model and discuss

382
00:25:50,120 --> 00:25:54,600
about the results and you go back again, like, okay, if we, if I had changed a problem

383
00:25:54,600 --> 00:25:57,360
to this, then would I get the same result?

384
00:25:57,360 --> 00:26:03,080
So, um, this, this is not a, in that sense, like, uh, it's not the all the time, like,

385
00:26:03,080 --> 00:26:08,200
debugging issue doesn't come very often, but, uh, we know actually when it can come,

386
00:26:08,200 --> 00:26:14,200
it's the problem generation was the first time that we might have this problem.

387
00:26:14,200 --> 00:26:19,880
A lot of the issues that you describe, you, you mentioned kind of this label preparation,

388
00:26:19,880 --> 00:26:25,080
uh, stage a couple of times, it seems like, especially when you start tackling a new business

389
00:26:25,080 --> 00:26:29,800
problem, it's one of the areas where technical or process problems tend to creep in.

390
00:26:29,800 --> 00:26:35,240
Can you talk a little bit about that label, uh, prep stage and the, the kinds of things

391
00:26:35,240 --> 00:26:38,360
you're doing there in the way you approach that at LinkedIn?

392
00:26:38,360 --> 00:26:39,360
Yeah.

393
00:26:39,360 --> 00:26:45,000
So, um, so label preparation, for example, I will explain it with the example that I,

394
00:26:45,000 --> 00:26:50,600
that I gave about the, the slink and talent once to, to the email campaign about the product

395
00:26:50,600 --> 00:26:52,600
career subscription.

396
00:26:52,600 --> 00:26:56,000
Um, for example, they say that they have data.

397
00:26:56,000 --> 00:27:03,760
So the data is like they send this email before, um, and, um, how, how do you, how do you

398
00:27:03,760 --> 00:27:05,520
prepare the label from that?

399
00:27:05,520 --> 00:27:09,840
So this question has, uh, yes or no answer, right?

400
00:27:09,840 --> 00:27:14,560
It's, it will be, it will be a binary classification, it will be either positive or negative.

401
00:27:14,560 --> 00:27:18,240
So, but how do you define the positive, how do you define the negative?

402
00:27:18,240 --> 00:27:21,240
For example, you send the email and then what?

403
00:27:21,240 --> 00:27:22,240
What is positive there?

404
00:27:22,240 --> 00:27:28,680
Just reading the email, clicking the, the, the link that we send or buying the product.

405
00:27:28,680 --> 00:27:33,000
And what is the timeline that you're going to put like it, are if they buy, for example,

406
00:27:33,000 --> 00:27:34,000
do you decide it?

407
00:27:34,000 --> 00:27:37,360
Okay, if they buy, it will be positive for me, this will be my label.

408
00:27:37,360 --> 00:27:40,960
Then are you going to wait for a day, for a week, for a month?

409
00:27:40,960 --> 00:27:42,360
So what's the timeline for this?

410
00:27:42,360 --> 00:27:44,000
You have to stop somewhere.

411
00:27:44,000 --> 00:27:47,120
So deciding those things are, um, are important.

412
00:27:47,120 --> 00:27:52,120
So again, you, you check the data, uh, when you are defining the label, uh, so this, this

413
00:27:52,120 --> 00:27:56,440
is very important actually, this label preparation part.

414
00:27:56,440 --> 00:28:04,280
And the example you just gave, those are labels that you can acquire, define programmatically

415
00:28:04,280 --> 00:28:09,680
by, you know, presumably running some, you know, SQL queries against your data warehouse

416
00:28:09,680 --> 00:28:11,120
or something like that.

417
00:28:11,120 --> 00:28:16,280
Is that the, the majority of the types of problems that you tackle within the data mining

418
00:28:16,280 --> 00:28:20,880
domain, or do you ever have, um, kind of these problems where you have to go back and manually

419
00:28:20,880 --> 00:28:23,880
label, uh, a bunch of data?

420
00:28:23,880 --> 00:28:24,880
Yeah.

421
00:28:24,880 --> 00:28:30,240
So the logic is done manually, but as you say, the, after you have this logic done, then

422
00:28:30,240 --> 00:28:35,240
you just write the code and then code just runs on the, on the, on the Hadoop or like

423
00:28:35,240 --> 00:28:39,680
on, on HDFS and then, yeah, automatically we get the data.

424
00:28:39,680 --> 00:28:43,880
But one, but we did, the, the logic is the most important part.

425
00:28:43,880 --> 00:28:48,120
So once you had the logic, you discuss the logic and you get the code review on the logic,

426
00:28:48,120 --> 00:28:52,640
if everybody agrees, this is the right logic, then the code just goes on, just we use the

427
00:28:52,640 --> 00:28:56,640
same code over and over for the same kind of problem.

428
00:28:56,640 --> 00:28:57,640
Mm-hmm.

429
00:28:57,640 --> 00:29:06,160
And is the, you mentioned kind of this issue of, um, in the talent example, kind of attribution,

430
00:29:06,160 --> 00:29:13,640
when do we say that someone's bought, uh, and also I frequently kind of hear about, um,

431
00:29:13,640 --> 00:29:19,320
you know, issues around features with like, uh, point in time, correctness and, um, you

432
00:29:19,320 --> 00:29:24,520
know, the whole time machine thing, uh, is that something that comes up in the types

433
00:29:24,520 --> 00:29:26,920
of problems you're dealing with?

434
00:29:26,920 --> 00:29:27,920
Yeah.

435
00:29:27,920 --> 00:29:30,320
Those, uh, time alignment is really, really important.

436
00:29:30,320 --> 00:29:37,800
So again, with the same example, so for example, um, let's say you will, you will also look

437
00:29:37,800 --> 00:29:43,720
at the, the behavioral features of those people who you want to send the email, uh, because

438
00:29:43,720 --> 00:29:48,160
it's important to check if they did the recent day job search or if they had a network,

439
00:29:48,160 --> 00:29:51,960
and recently, for example, with the recruiters, so it's a really big indication that they

440
00:29:51,960 --> 00:29:56,760
might buy this product, uh, but then the time is very important.

441
00:29:56,760 --> 00:30:02,920
So, uh, you have to put some, some time and you are going to look at the, the, the, the,

442
00:30:02,920 --> 00:30:07,560
um, action that they did before that time, right?

443
00:30:07,560 --> 00:30:09,720
But why, why do you put this time?

444
00:30:09,720 --> 00:30:17,480
Do you, do you put it when you send the email or, or like, when they clicked the link or,

445
00:30:17,480 --> 00:30:19,760
or one day did a subscription?

446
00:30:19,760 --> 00:30:25,200
Because after you send the email, till to the point that they buy, uh, if you look at

447
00:30:25,200 --> 00:30:29,720
the, the, the action, their behavior is during that time, it might be biased.

448
00:30:29,720 --> 00:30:33,520
It might be that they are just curious about the product and they might, I don't know,

449
00:30:33,520 --> 00:30:37,640
wonder about something and go and check and do the search, it might not be that they

450
00:30:37,640 --> 00:30:40,640
are planning to change their job or something.

451
00:30:40,640 --> 00:30:44,760
So maybe it's a good idea to check those, you know, all these kind of behaviors before

452
00:30:44,760 --> 00:30:48,240
you send the email, before they become aware of this product.

453
00:30:48,240 --> 00:30:54,560
So deciding those kind of, um, time and then, uh, when you combine it with the label,

454
00:30:54,560 --> 00:31:01,680
the feature and just putting, putting the, the, the, the, the timeline on the correct

455
00:31:01,680 --> 00:31:04,840
place is, is also, it's also very important.

456
00:31:04,840 --> 00:31:11,680
Uh, and of course, these are more for, uh, more for, uh, dynamic features like for snapshot

457
00:31:11,680 --> 00:31:17,760
features like, uh, where they live, um, their job title, things like that, which doesn't,

458
00:31:17,760 --> 00:31:23,360
uh, change very often, uh, these are not the big huge problem, but the dynamic features

459
00:31:23,360 --> 00:31:26,920
are, yeah, this won't, won't be very careful about those.

460
00:31:26,920 --> 00:31:31,880
So you've got your problem defined, you've got your, uh, labels generated, you've dealt

461
00:31:31,880 --> 00:31:37,560
with alignment issues, uh, around your features, then it's time to, you know, start modeling

462
00:31:37,560 --> 00:31:43,160
and training a model, you know, what are some of the, the kind of gotchas that come up

463
00:31:43,160 --> 00:31:44,160
there?

464
00:31:44,160 --> 00:31:45,160
Yeah.

465
00:31:45,160 --> 00:31:50,160
So, um, so the first thing is, of course, like partitioning the data, like training,

466
00:31:50,160 --> 00:31:56,680
evaluation and testing, um, of course, like this, the sizes depends on, on your data size

467
00:31:56,680 --> 00:32:04,400
and, um, but one thing that we are very careful, um, uh, for example, if you had to duplicates

468
00:32:04,400 --> 00:32:10,360
in your data, you should really need to deduct all this kind of data, because, um, let's

469
00:32:10,360 --> 00:32:16,440
say you have same to same data and one goes to training set and the other goes to testing

470
00:32:16,440 --> 00:32:17,440
set.

471
00:32:17,440 --> 00:32:18,440
Right.

472
00:32:18,440 --> 00:32:19,440
This is a problem.

473
00:32:19,440 --> 00:32:20,440
Exactly.

474
00:32:20,440 --> 00:32:21,440
Then this is the data leakage.

475
00:32:21,440 --> 00:32:26,760
You should really, you should be careful all those kind of, uh, and, um, and after the

476
00:32:26,760 --> 00:32:31,360
partition, then in the model training part, there are a few things that you have to be

477
00:32:31,360 --> 00:32:37,720
careful, uh, like, um, for example, you have to check your system requirements.

478
00:32:37,720 --> 00:32:43,440
So do you really need very fast algorithm or just your system is really, does, you don't

479
00:32:43,440 --> 00:32:50,600
care about the speed of the algorithm, um, and, um, also, uh, I only talk about the

480
00:32:50,600 --> 00:32:55,680
performance, why is the, uh, interpretation of the model, do you need the interpretation

481
00:32:55,680 --> 00:33:00,440
or the, for your the performance is the most important one, because here at LinkedIn,

482
00:33:00,440 --> 00:33:04,840
like, we usually sacrifice the performance of the model, like, because the interpretation

483
00:33:04,840 --> 00:33:09,600
for most of the problem interpretation is really, very important, uh, but we also have

484
00:33:09,600 --> 00:33:13,160
other problems where, for example, interpretation doesn't have anything to do.

485
00:33:13,160 --> 00:33:15,880
So we really focus moral on the performance.

486
00:33:15,880 --> 00:33:18,640
I wonder on that interpretability point.

487
00:33:18,640 --> 00:33:26,720
Does that, is that static for a given problem or does it change and I'm kind of envisioning

488
00:33:26,720 --> 00:33:29,960
where, you know, a problem is new to the business.

489
00:33:29,960 --> 00:33:34,040
They don't really understand the, the data and the underlying behaviors.

490
00:33:34,040 --> 00:33:38,520
And so they want something really interpretable to help them build up and intuition.

491
00:33:38,520 --> 00:33:44,280
But then, you know, over time, they start to get a better feel for, you know, the, what

492
00:33:44,280 --> 00:33:48,520
they're trying to model and maybe they're willing to, you know, sacrifice some of that

493
00:33:48,520 --> 00:33:50,920
interpretability for additional performance.

494
00:33:50,920 --> 00:33:52,920
Is that a common trajectory?

495
00:33:52,920 --> 00:33:53,920
Exactly.

496
00:33:53,920 --> 00:33:54,920
Exactly.

497
00:33:54,920 --> 00:33:56,800
So this is, this is a very common actually.

498
00:33:56,800 --> 00:34:01,720
So it happens a few times, for example, we propose them to send emails to some certain

499
00:34:01,720 --> 00:34:05,080
customer and they say, no, we shouldn't send this to this customer.

500
00:34:05,080 --> 00:34:07,320
Like, I'm pretty sure it's not the right one.

501
00:34:07,320 --> 00:34:08,320
What do you say?

502
00:34:08,320 --> 00:34:11,320
But the model says, really, you should send an email to this one.

503
00:34:11,320 --> 00:34:12,760
So then they ask, why?

504
00:34:12,760 --> 00:34:17,560
So those examples, we should be ready because of this and this.

505
00:34:17,560 --> 00:34:23,600
So, and if we use algorithms as a black box, we can't answer those kind of questions.

506
00:34:23,600 --> 00:34:25,560
We say, sorry, the algorithm says this.

507
00:34:25,560 --> 00:34:28,240
So they say, no, I'm not going to send this email.

508
00:34:28,240 --> 00:34:33,720
So we should also comies our sales representatives, like, like, these people are really important

509
00:34:33,720 --> 00:34:38,320
and these are the reasons that, that, that they are important.

510
00:34:38,320 --> 00:34:44,520
So actually, we have some in-house solution to that because sometimes like the, for example,

511
00:34:44,520 --> 00:34:52,520
the performance of the, the performance of the models, which has good interpretations,

512
00:34:52,520 --> 00:34:53,920
is really very low.

513
00:34:53,920 --> 00:34:55,120
We cannot use them.

514
00:34:55,120 --> 00:34:59,760
So we need to use, like, a good performer algorithm.

515
00:34:59,760 --> 00:35:03,880
So we have a solution for that in-house solution.

516
00:35:03,880 --> 00:35:13,000
Sorry, for example, let's say we have, let's say we have 300 features in our master model.

517
00:35:13,000 --> 00:35:20,360
And we model with all these 300 features and we score, you know, the customers.

518
00:35:20,360 --> 00:35:25,560
And then we say, and then we try to predict if they will buy some certain product or not.

519
00:35:25,560 --> 00:35:27,640
And we want to know why they buy this product.

520
00:35:27,640 --> 00:35:35,480
So what we do is that we divide the features into different buckets, where each bucket

521
00:35:35,480 --> 00:35:41,080
has like semantic business meaning, like, you know, those features are like behavioral

522
00:35:41,080 --> 00:35:42,080
features.

523
00:35:42,080 --> 00:35:43,560
All features are social features.

524
00:35:43,560 --> 00:35:45,640
All features are identity features.

525
00:35:45,640 --> 00:35:50,200
And let's say I divide into three different buckets.

526
00:35:50,200 --> 00:35:54,640
And then I build a model with the features within each of these buckets.

527
00:35:54,640 --> 00:36:00,440
So I have like three different models, apart from the master model that I have.

528
00:36:00,440 --> 00:36:06,280
And the important thing is that each of these models has their own semantic meaning.

529
00:36:06,280 --> 00:36:12,480
And in this way, I, you know, like, stopped the correlation between the features, between

530
00:36:12,480 --> 00:36:14,120
the groups of the features.

531
00:36:14,120 --> 00:36:16,760
And I, this also reduced the noise.

532
00:36:16,760 --> 00:36:22,280
And for example, when I score with my master model, each customer, I also scored them

533
00:36:22,280 --> 00:36:25,240
with this, this, we called them component model.

534
00:36:25,240 --> 00:36:30,120
I also scored them with these three component models, which has different meaning.

535
00:36:30,120 --> 00:36:36,680
So for example, few times I realize that some, for example, certain person has a high score

536
00:36:36,680 --> 00:36:43,600
with the master model, because they also have a high score coming from the behavioral feature

537
00:36:43,600 --> 00:36:45,000
model.

538
00:36:45,000 --> 00:36:51,280
On the other hand, somebody has another customer has the same thing for the social feature model.

539
00:36:51,280 --> 00:36:56,280
So this tells us it, okay, so the first one got a high score because of the behavioral features

540
00:36:56,280 --> 00:37:00,640
and the other person got high score because of the social features.

541
00:37:00,640 --> 00:37:04,240
And this also helped us to send personalized emails.

542
00:37:04,240 --> 00:37:09,040
So when we are trying to sell the product to this person, for example, in the email, we

543
00:37:09,040 --> 00:37:11,240
talk about more like behavioral features.

544
00:37:11,240 --> 00:37:16,920
We said, oh, you can do that much more search in your, with this product, actually.

545
00:37:16,920 --> 00:37:20,480
And we thought that person might be more interested on search.

546
00:37:20,480 --> 00:37:25,160
On the other hand, for the person who got high score because of the social features, we

547
00:37:25,160 --> 00:37:30,160
more talk about what kind of networking that person can do, you know, if he buys this

548
00:37:30,160 --> 00:37:31,160
product.

549
00:37:31,160 --> 00:37:33,080
So this really helped us a lot, actually.

550
00:37:33,080 --> 00:37:38,280
So yeah, this is our in-house solution that we use for now.

551
00:37:38,280 --> 00:37:40,800
Up to now, it worked pretty well.

552
00:37:40,800 --> 00:37:49,560
And so is this component model, is this, are you using it strictly for kind of interpretability

553
00:37:49,560 --> 00:37:54,800
signal, or are you then like training some ensemble of these components, and then using

554
00:37:54,800 --> 00:38:00,760
it to maybe replace the original model or supplement it in some way?

555
00:38:00,760 --> 00:38:04,480
I mean, for now, we only use interpretive purposes.

556
00:38:04,480 --> 00:38:10,080
Few times, if the master model does not do good, but we see a very good performance coming

557
00:38:10,080 --> 00:38:12,840
from the component models, we try to combine.

558
00:38:12,840 --> 00:38:19,600
So because I'm realize it, there is really big noise, you know, when all the features are

559
00:38:19,600 --> 00:38:20,600
together.

560
00:38:20,600 --> 00:38:26,760
So like the models became much better when you separate the features from each other.

561
00:38:26,760 --> 00:38:32,080
But up to now, we couldn't say good performance coming from combination of those models.

562
00:38:32,080 --> 00:38:34,640
So we just use them separately after now.

563
00:38:34,640 --> 00:38:35,640
Okay.

564
00:38:35,640 --> 00:38:36,640
Yeah.

565
00:38:36,640 --> 00:38:37,640
Yeah.

566
00:38:37,640 --> 00:38:43,360
I mentioned data partitioning, and, you know, there's kind of the usual, you know, test

567
00:38:43,360 --> 00:38:51,000
train split kind of issues there, but I imagine that you have to do things somewhat differently

568
00:38:51,000 --> 00:38:57,640
when you're working with $660 million, you know, users, and you have graphs and things

569
00:38:57,640 --> 00:38:58,640
like that.

570
00:38:58,640 --> 00:39:06,080
You know, beyond the de-duplication, are there, you know, ways that you deal with data

571
00:39:06,080 --> 00:39:09,080
partitioning that are kind of unique to LinkedIn scale?

572
00:39:09,080 --> 00:39:10,080
Yeah.

573
00:39:10,080 --> 00:39:11,080
Yeah.

574
00:39:11,080 --> 00:39:19,480
So, for example, a few times, since usually we collected data in the US, we should be careful

575
00:39:19,480 --> 00:39:23,360
about, for example, if we are using the geolocation as a feature.

576
00:39:23,360 --> 00:39:29,440
So it's usually its US, but we have also a lot of data coming from Europe or Asia.

577
00:39:29,440 --> 00:39:31,360
So we should also be careful.

578
00:39:31,360 --> 00:39:38,400
So we also, in order to have the good representative of each feature, we also do like certified random

579
00:39:38,400 --> 00:39:44,240
sampling for each of the both train set, testing set, and validation set.

580
00:39:44,240 --> 00:39:48,360
So we're also careful that each feature is representative.

581
00:39:48,360 --> 00:39:49,360
Yeah.

582
00:39:49,360 --> 00:39:54,720
This is also something that we are, we are very careful, you know, other than the de-duplication

583
00:39:54,720 --> 00:39:55,720
of the data.

584
00:39:55,720 --> 00:40:02,120
Are you typically building models against all of the data or are you, you know, sampling

585
00:40:02,120 --> 00:40:04,560
and training on subsets?

586
00:40:04,560 --> 00:40:07,920
We usually random, we do random sampling and training on subset.

587
00:40:07,920 --> 00:40:08,920
Yeah.

588
00:40:08,920 --> 00:40:12,640
Especially if we do the model on the member level.

589
00:40:12,640 --> 00:40:19,040
So we are trying to, actually, we are trying to be careful about timeline also.

590
00:40:19,040 --> 00:40:26,640
So, for example, let's say if you want to sell the product today, we look at the people

591
00:40:26,640 --> 00:40:30,360
who bought last year and we only focus those members.

592
00:40:30,360 --> 00:40:32,840
We don't go and check every member.

593
00:40:32,840 --> 00:40:36,600
And now we do the model on those people who bought last year.

594
00:40:36,600 --> 00:40:42,360
But of course, in terms of scoring, down we use most of our members in order to score

595
00:40:42,360 --> 00:40:49,520
and then see who will get the highest score, who has the most probability to buy this product.

596
00:40:49,520 --> 00:40:58,960
And is that the kind of locking in on a specific year is that because the, you know, your distribution

597
00:40:58,960 --> 00:41:04,760
will have changed over time and you don't want to kind of confuse your model by pulling

598
00:41:04,760 --> 00:41:08,800
in users from a broad period of time?

599
00:41:08,800 --> 00:41:14,040
Yeah, exactly. We just define a certain period of time, that time, like we saw in this email,

600
00:41:14,040 --> 00:41:17,800
did they buy in the next month or not?

601
00:41:17,800 --> 00:41:23,480
So we make this definition very clear and then this would be our labels associated with

602
00:41:23,480 --> 00:41:29,320
the members and then we start from there, then we attach the features to those members.

603
00:41:29,320 --> 00:41:32,400
So, but the timeline is very clear, yeah.

604
00:41:32,400 --> 00:41:37,840
And so the next thing on your list was kind of sharing the results to business partners.

605
00:41:37,840 --> 00:41:43,960
Is this usually in the form of a kind of a deployed model that's like a service that

606
00:41:43,960 --> 00:41:49,920
is integrated into some application or is it more, you know, like business intelligence

607
00:41:49,920 --> 00:41:56,560
reports and, you know, decision criteria or what are the different ways that you, you

608
00:41:56,560 --> 00:42:01,160
know, both deploy and communicate results to the business?

609
00:42:01,160 --> 00:42:07,240
Yeah. So we show our results on our testing set, of course.

610
00:42:07,240 --> 00:42:11,760
You know, we never touch the testing set during the training purposes or choosing hyper

611
00:42:11,760 --> 00:42:14,600
parameter or like algorithm.

612
00:42:14,600 --> 00:42:22,160
So like we have completely independent testing set and we, we apply this testing set, the

613
00:42:22,160 --> 00:42:27,240
model that we chose, we think it's the best performance model.

614
00:42:27,240 --> 00:42:33,920
And then this results, we need to, we need to show some results to our business partners.

615
00:42:33,920 --> 00:42:39,320
So since we are, since this is a business problems, we also consider the business metrics.

616
00:42:39,320 --> 00:42:42,360
So for example, the conversion rate is very important for them.

617
00:42:42,360 --> 00:42:44,320
So we had to show them the conversion rate.

618
00:42:44,320 --> 00:42:47,880
So it's also, they are interested in the ROC curve.

619
00:42:47,880 --> 00:42:54,440
So it's a little bit technical, but they have a way to see the compare to models, because

620
00:42:54,440 --> 00:42:58,680
when we present the model, probably there is another model coming from the last year.

621
00:42:58,680 --> 00:43:00,600
So this is our baseline model.

622
00:43:00,600 --> 00:43:05,800
So they, they are, they will be able to compare, oh, this model is doing good or bad than

623
00:43:05,800 --> 00:43:06,800
last year.

624
00:43:06,800 --> 00:43:07,800
Why is this so?

625
00:43:07,800 --> 00:43:11,760
So this is all, you know, this will be all the discussion between the business people

626
00:43:11,760 --> 00:43:13,120
and us.

627
00:43:13,120 --> 00:43:16,480
So yeah, we, we prepare our, you know, the performance evaluation.

628
00:43:16,480 --> 00:43:22,280
If it's a binary classification model, it will be probably a ROC curve and the, um, and

629
00:43:22,280 --> 00:43:23,280
the conversion rate.

630
00:43:23,280 --> 00:43:26,640
We also, of course, prepare the key drivers.

631
00:43:26,640 --> 00:43:29,560
We showed the key drivers if they make sense to them or not.

632
00:43:29,560 --> 00:43:33,200
So they, they have really a good domain knowledge.

633
00:43:33,200 --> 00:43:36,240
So they can, so this feature doesn't have anything to do with the results.

634
00:43:36,240 --> 00:43:37,760
Why did come up?

635
00:43:37,760 --> 00:43:41,920
And now we go over, for example, they want to see the people who has the highest scores.

636
00:43:41,920 --> 00:43:44,440
So we go over them and they check them.

637
00:43:44,440 --> 00:43:48,960
So, uh, and if they see any red flag or not, then they let us know.

638
00:43:48,960 --> 00:43:53,440
So we sit together for an hour and we discuss all those things and they go over the, the,

639
00:43:53,440 --> 00:43:56,280
the companies which had the highest score.

640
00:43:56,280 --> 00:43:58,200
And then we get the feedback from them.

641
00:43:58,200 --> 00:44:03,360
And if the feedback is positive, then we release models to them, then scoring process

642
00:44:03,360 --> 00:44:06,440
start and we can deploy our models.

643
00:44:06,440 --> 00:44:11,680
Maybe we can kind of wrap things up with talking about how you ensure that these models,

644
00:44:11,680 --> 00:44:13,360
uh, remain fresh.

645
00:44:13,360 --> 00:44:17,680
You mentioned, uh, AB testing is something that you do.

646
00:44:17,680 --> 00:44:18,680
Yeah.

647
00:44:18,680 --> 00:44:19,680
Yeah.

648
00:44:19,680 --> 00:44:25,240
So we use, we use AB testing in order to, if, if we need to refresh the model, then we

649
00:44:25,240 --> 00:44:31,080
use the AB testing to see if the current model is better or the one that I, that we built,

650
00:44:31,080 --> 00:44:33,880
uh, if the new model that we built is doing good.

651
00:44:33,880 --> 00:44:39,960
But before that, we, once we had the model, we, we constantly do the future monitoring

652
00:44:39,960 --> 00:44:44,720
and the model performance monitoring, we, we want to see the trends on the features.

653
00:44:44,720 --> 00:44:50,520
Anything is decreasing or increasing, if there is an spike on the features, uh, it's because

654
00:44:50,520 --> 00:44:54,600
of the, uh, I'm, I know, holiday season or something else going on.

655
00:44:54,600 --> 00:44:57,360
So we should be aware all those kind of things.

656
00:44:57,360 --> 00:45:01,200
Same thing with the model performance, there's something might be broken somewhere.

657
00:45:01,200 --> 00:45:05,440
So it is really important to go and see, uh, to see if it's coming from the features or

658
00:45:05,440 --> 00:45:07,960
it's coming from the model.

659
00:45:07,960 --> 00:45:13,240
And then once we are aware of all those, then we might decide to refresh the model and do

660
00:45:13,240 --> 00:45:17,880
the AB testing and decide to go with the current model or with a new model.

661
00:45:17,880 --> 00:45:18,880
Yeah.

662
00:45:18,880 --> 00:45:26,280
This AB testing is this, is it primarily offline AB testing or are you, um, doing it online

663
00:45:26,280 --> 00:45:27,280
as well?

664
00:45:27,280 --> 00:45:33,720
And, uh, if you're doing it online, how do you ensure I, I imagine at your scale, like ensuring

665
00:45:33,720 --> 00:45:38,440
kind of statistical significance probably isn't something, you know, it happens probably

666
00:45:38,440 --> 00:45:39,440
pretty quickly.

667
00:45:39,440 --> 00:45:40,440
Yeah.

668
00:45:40,440 --> 00:45:41,440
Yeah.

669
00:45:41,440 --> 00:45:42,440
Yeah.

670
00:45:42,440 --> 00:45:42,440
Maybe depending on the problem.

671
00:45:42,440 --> 00:45:47,040
But like, how do you address the, those kind of practical issues associated with AB testing?

672
00:45:47,040 --> 00:45:52,440
Yeah, from, from the customers, they just do the random sampling and then start, you

673
00:45:52,440 --> 00:45:59,720
know, show, start to use the results from, from both, from both models, like we, they

674
00:45:59,720 --> 00:46:04,560
get the results from the existing models, they get the results from the new model.

675
00:46:04,560 --> 00:46:10,680
And then with this results, they, the sales scientists, they try to use both, both

676
00:46:10,680 --> 00:46:17,120
models, um, and we, the way we design a sign, though, the results coming from the both models

677
00:46:17,120 --> 00:46:18,120
are really random.

678
00:46:18,120 --> 00:46:23,160
So sales representatives are not aware if they are using the current or the new model.

679
00:46:23,160 --> 00:46:28,080
And then we just compare the results, like if, if the, if the results are coming same

680
00:46:28,080 --> 00:46:37,240
or, or, or, or there is any, um, the significance level of confirmation that, that one can, one

681
00:46:37,240 --> 00:46:40,360
should be able to use the new one.

682
00:46:40,360 --> 00:46:45,160
Any, any parting thoughts, um, we covered a lot of ground and you certainly covered a lot

683
00:46:45,160 --> 00:46:50,360
of ground in your presentation, any, did you leave the audience with kind of key takeaways

684
00:46:50,360 --> 00:46:53,640
of things that they needed to be thinking about as they're implementing this in their

685
00:46:53,640 --> 00:46:54,640
own companies?

686
00:46:54,640 --> 00:46:55,640
Yeah.

687
00:46:55,640 --> 00:46:56,640
So, okay.

688
00:46:56,640 --> 00:47:02,720
So we talk about, you know, the each step of this machine learning process for the model,

689
00:47:02,720 --> 00:47:05,160
for production, the model for business problems.

690
00:47:05,160 --> 00:47:12,000
But actually, we can pack all those things, which will be, which will, which can serve not

691
00:47:12,000 --> 00:47:15,480
only to you, but everybody in your team.

692
00:47:15,480 --> 00:47:21,680
So because if one person goes all of this process once, it's okay, but if everybody in your

693
00:47:21,680 --> 00:47:26,400
team does this over and over, then, um, it's, it's not really efficient.

694
00:47:26,400 --> 00:47:31,600
So we should build something which is better, smarter, and which can, which can do this

695
00:47:31,600 --> 00:47:32,920
process.

696
00:47:32,920 --> 00:47:33,920
And it is doable.

697
00:47:33,920 --> 00:47:35,280
So there are some platforms.

698
00:47:35,280 --> 00:47:36,280
So does this?

699
00:47:36,280 --> 00:47:42,760
So like AWS, Microsoft Azure, Google Cloud, you can consider to buy those platforms, being

700
00:47:42,760 --> 00:47:48,360
aware their limitations, their data source, the algorithms that they use, or one can build

701
00:47:48,360 --> 00:47:51,520
their own platform, which will do this process.

702
00:47:51,520 --> 00:47:56,280
Or you can do something in the middle, like, uh, you can assemble both existing platforms

703
00:47:56,280 --> 00:47:57,840
with your in-house solution.

704
00:47:57,840 --> 00:48:03,680
So why should, um, consider what their problem is, their timeline, their budget.

705
00:48:03,680 --> 00:48:09,080
And then, uh, instead of, you know, going over this, each of the set, the step manually one

706
00:48:09,080 --> 00:48:11,800
by one, just make this a service.

707
00:48:11,800 --> 00:48:15,480
And then, uh, one can use this service over and over.

708
00:48:15,480 --> 00:48:20,640
But of course, um, uh, one should be careful about the, uh, uh, synthesis is the ultimate

709
00:48:20,640 --> 00:48:22,120
sophistication.

710
00:48:22,120 --> 00:48:27,600
So it is very important to make this platform as simple as possible, because it's important

711
00:48:27,600 --> 00:48:33,480
to maintain this platform, also simplicity is important for the user experience.

712
00:48:33,480 --> 00:48:38,120
But yeah, like, instead of going this step, this process one by one, just consider this

713
00:48:38,120 --> 00:48:41,160
as a service is the best way to look at it, I think.

714
00:48:41,160 --> 00:48:42,160
Agreed.

715
00:48:42,160 --> 00:48:43,160
Awesome.

716
00:48:43,160 --> 00:48:50,000
Well, Bertu, thank you so much for, uh, for walking me through all this.

717
00:48:50,000 --> 00:48:53,760
Um, sounds like a really good presentation.

718
00:48:53,760 --> 00:48:59,920
And, uh, I love the kind of closing imperative to, you know, think about how to make this process

719
00:48:59,920 --> 00:49:03,600
more efficiently by supporting it via some platform.

720
00:49:03,600 --> 00:49:04,600
Well, thank you very much.

721
00:49:04,600 --> 00:49:06,920
It was a good pleasure to be here.

722
00:49:06,920 --> 00:49:13,200
All right, everyone, that's our show for today.

723
00:49:13,200 --> 00:49:17,360
If you like what you've heard here, please do us a favor and tell your friends about the

724
00:49:17,360 --> 00:49:18,600
show.

725
00:49:18,600 --> 00:49:23,160
And if you haven't already hit the subscribe button yourself, make sure to do so.

726
00:49:23,160 --> 00:49:27,040
So you won't miss any of the great episodes we've got in store for you.

727
00:49:27,040 --> 00:49:32,200
For more information on any of the shows in our strata data series, visit twomolei.com

728
00:49:32,200 --> 00:49:34,520
slash strata sf19.

729
00:49:34,520 --> 00:49:37,880
Thanks once again to Cloud Error for sponsoring this series.

730
00:49:37,880 --> 00:49:42,080
Be sure to check them out at cloud error.com slash ml.

731
00:49:42,080 --> 00:49:59,240
As always, thanks so much for listening and catch you next time.

