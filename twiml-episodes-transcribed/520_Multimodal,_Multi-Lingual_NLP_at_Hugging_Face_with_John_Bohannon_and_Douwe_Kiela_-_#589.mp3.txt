All right. Let's get this started. Hi, Dawa. Hi. So I'm talking to you from my home in San Francisco. Where are you?
I'm in Palo Alto, not too far away from you actually. Also at your home. Also at my home, yes.
The new office. The new office, yeah. So we do actually have an office hugging face Silicon Valley
office in Palo Alto, not too far away from here, which we opened recently. But yeah, it's I'm still
getting used to going to an actual office. I really like my home office. Yeah, it's kind of here
to stay. So this is really exciting for me because for a number of reasons, one hugging face is one of
the most interesting companies today. So especially in the machine learning space, but most especially in
the natural language processing space, which is where I work. And yeah, I saw the tweet in January
that you sent out announcing that you were the new head of research at hugging face. And I've
been dying to talk to you ever since. And it's been a good six months. So you've had times to
settle in, find your feet, get up to speed, actually maybe make an agenda and plan for yourself
at hugging face. So it seems like a great time to catch up. And also a lot of the listeners of this
podcast will have heard Tomas Wolf from Hugging Face, one of the founders. Is that right? How would
you describe Tomas? He's one of the three co-founders. And he's our chief science officer.
So many on this in listening to us right now will have heard Tomas interviewed by Sam three months
ago. And so this is and he had a lot to say about research. And so it's a perfect time to dig deeper
into some of the things that he got into. And also to just open up new territory, find out what's
on your mind. How's that sound? Yeah, for sure. Yeah, I thought it was the podcast with Tom was
really amazing. So if people haven't listened to that, I highly recommend people listen to that too.
Yeah. You and I spoke briefly a week or two back. And I took some notes. And I want to give you the
and the listeners kind of the menu of things that came to mind for me that we could touch on. So
big themes I would love to know more about you as a human. And you and Hugging Face, I think a lot
of people probably have a name recognition for Hugging Face, but probably don't know really what
it is. So it'd be good to dig into that a little bit. And then the main dish of the course,
let's dig into the future of NLP. Yeah, one thing I'd like to emphasize is that Hugging Face is
no longer an NLP company per se. So we are doing a lot of very interesting work in computer vision
and speech and other areas of AI. So I like to think of Hugging Face as an AI company.
Yeah. And so that's a perfect seg. Let's dig into that. So Hugging Face used to be an NLP
company. I think it's safe to say. And it's really been expanding. I looked on CrunchBase
just to see what the basic stats are these days. It's like somewhere between a hundred and 200
people, Series C, and based in New York officially, although quite remote now like the rest of us.
Yeah. And so when you joined, it was already transitioning into something bigger than NLP.
Yeah. What was your perception of Hugging Face? How would you have described it like before
you joined and now that you've joined? Yeah. So I've always been impressed by Hugging Face and how
it presents itself to the outside world. It's a very open and transparent organization
where it really is about a community effort to democratize a lot of the tools that everybody
uses. So from data sets to models, so Transformers Library, of course, also the Hub, which is really
a crucial part of the AI ecosystem these days, I think. So I've just always been very impressed
by it. And so that's why I chose to join this company. I think it really is a special
special place and it really plays a special role in the community. So I don't think that a company
like Google or Meta could play the same role that Hugging Face plays in this ecosystem.
I agree. I agree. It's a pioneer with open source for sure. So something else that I really
like about Hugging Face is how European it is and now actually very international. The people
are just, they come from all over the place. Did you know any of the core Hugging Face people
before you joined? Yeah. So I mean, I met Tom a few times before and I knew Victor and a bunch
of others Victor San. So it's funny actually that you mentioned the Europeanness. So I'm a European
as you can tell from my accent. I'm originally from Holland, but I live in California and I spent
some time in the UK and in New York before I moved to California. But Tom, my boss, actually lives
in Utrecht in the Netherlands, which is where I studied for my undergrad. So and Tom is not
Dutch. But you didn't cross paths during your years in the Netherlands? No, no, no. I left
Holland more than 10 years ago. So I don't think Tom's been living here for 10 years. So it's not
a Dutch mafia. It's a coincidence. It's a French mafia if anything. So the founders are French.
So in terms of the company at large, what I find fascinating is that we have people I think in
Morgan 25 countries all over the world. So in the science team, we have people on the west coast,
on the east coast of the US and in Canada and lots of different places in Europe and in South
Korea. And Turkey as well. I have a friend based in Istanbul. Yeah. Let's see. What is your job?
Good question. I wish I knew. So broadly speaking, I'm just trying to help the team realize this
very ambitious vision that the founders have for the company and for the science team inside the
company. So yeah, it's not really a well-defined role. I think it also kind of depends on what stage
we're in in a given research project, for example. So I'm kind of discovering that as I go along.
So the official title is Head of Research. That's right. And so then comes the question,
what is research at Hugging Face? How is it different from research at a university or research
at a big company like Facebook slash meta, which is where you came from before this?
Yeah. So we're trying to go for a bit of a different model. I think if you want to compare it to
to a single place, then maybe something like DeepMind or OpenAI is closer to what we're trying to do
than meta. So yeah, as you mentioned, I've been at Fair for five years and it was a wonderful time.
But one of the things that was difficult at Fair was that it's very bottom up, which in theory
sounds really nice, but it makes it very difficult to do very big ambitious projects. So if you really
want to create step change research artifacts, which is what we're trying to do, then you need to
pull together big groups of people and then make sure that they're all aligned in realizing this
vision. And in a bottom up research organization, that's very difficult to do. So what we're trying
to do is find the optimal place between the bottom up approach that Fair and Google Brain and
places like that have and the top down approach, which are DeepMind and OpenAI have, where they have
a benevolent dictator like Demis or Ilya, basically telling people what to do and what the
vision is. And we're trying to occupy the middle ground a little bit there and really try to use
the things that make us special. So that's the ability to move fast, the ability to work with
the community, like we've been doing with projects like big science, and to really to exploit the
things that make us unique. What's the difference between big science, which is a project involving
lots of external people, as many as a thousand or signed up from what I heard from Thomas,
probably more like hundreds that are active participants on a daily basis, but that's big.
And then the research team at Hugging Face, describe your actual, what would you call the
actual research team at Hugging Face? Is it like 10 people, 20? So I think last count was 30,
35 people actually. Okay, big group. Science is one of the projects we have going on. So I can tell
you a bit about the other projects we have going on. So one of the advantages of being at Hugging
Face is that it's a super transparent and open company. So I can just tell you everything that
we're doing without feeling bad about it. So no secret sauce revealed. So we have a project around
multimodal models. So multimodality, I think everyone agrees is very important for the future
of AI. And when you say multimodality, for those listening in, you're referring to more than
just text, more than just images, all kinds of sensory, what we would think of as sensory modalities
or information modalities for humans, you're trying to capture that for models, but all at once.
Yeah, all at once. So I think if you look at more recent multimodal work, it's very often just
text and images, but there are all kinds of different modalities that you all might want to
integrate into one single model. So how many modalities are you stuffing in?
So right now, it's images, text, videos, and audio, because those are the main ones. And then once
you have those, then you can start thinking about other specific modalities, maybe sort of submodalities,
right? So it's unclear whether code as a modality is a part of text or if it's something else.
So there's all kinds of interesting questions about what the modality really is. So my PhD thesis
actually was about grounding meaning in perceptual modalities, where I also incorporated all
factory semantics. So you can build a bag of chemical compounds model and build smell vectors,
essentially, and do interesting things with that. So that's a long time ago, but yeah, there's
a lot of potential there. What does the word grounded mean in this context? So let's use NLP.
Let's use an example like you have a model that, you know, like GPT-3. So it's learned how to
generate text. What does it mean for that model to be grounded? Yeah, so I was going to say,
I think the word grounded isn't pretty well defined, but I'm a philosopher by training originally,
so I would argue that most things are not well defined. But in my thesis, I make an explicit
distinction between referential grounding and representational grounding. And so I think
referential grounding is what people often think about with like referral data sets. So those
exist in computer vision, for example, where you have to pick out the object. So when someone says
banana, then you have to be able to point into image where the banana is. But I think the
much more interesting type of grounding is representational grounding where you have a holistic
meaning representation of a concept like elephant and you or violin, maybe it's a better example.
And so you know the semantic meaning of violin, you can go to Wikipedia and look up what violin is,
what that means. But you also have a visual representation of it and you know what it looks like,
you know, what it sounds like, maybe you know what it smells like, what it feels like, what it's
like to play it, all of these different modalities are a part of your overarching meaning representation
of the concept of violin. And I think that is the much more interesting type of meaning representation.
And so that's the meaning we should try to get into machines if we want them to be able to
really understand humans. So what are the, what are some of the problems you see with today's
models that reveal that they're insufficiently grounded? Yeah, so I don't know if we're sure
that models are insufficiently grounded. I think that's still an empirical question,
but my hunch and I think a lot of people in the field share that hunch is that you need to have
some understanding of the world as humans perceive it if you really want to understand humans.
And so there's a lot of communication that happens between humans that never really
becomes explicit. So people call this common sense, for example. So the example I always use is
coffee and what coffee smells like. Everybody knows what coffee smells like. So I never have to
explain that to anyone. And so for that reason, I also just have no idea how to describe the smell of
coffee. I don't know if you can try that or describe the smell of a banana in one sentence.
Like you've never had to do that because you know that everybody knows what banana smell like.
And if you could pull it off, we would call you a poet. Yeah, exactly. So I think you're
totally right. So you have to fall back to associations then because there is no descriptive language
for this sort of stuff. And I think this happens all over the place in natural language communication
between humans. And that makes it very hard for machines to learn this stuff just from reading Wikipedia
or whatever corpus they're trained on. It's funny. You're very much coming at this as a philosopher,
I could see. There's another angle, which is where I'm coming from. So you know, I'm at a company
that is on the applied side. So we're using NLP to try and solve problems. And where I see what
seems to be the grounded problem is the model clearly, if you just poke a little bit, it clearly
doesn't understand what it's talking about. You know, it'll say all the right things. And then
it reveals that it actually has no common sense understanding of what coffee is. Because it'll say
something that's a human would find crazy. Yeah, but so I think the word understanding,
what does understanding even mean there? I mean, so I think what you're maybe talking about.
And that's so I think there are two main things missing in our current paradigm. One is
multimodal understanding of concepts. And the other is the intentionality with a T of language.
So the fact that we use language with an intent to change the mental state of whoever we're
talking to, right? So I'm using my voice now to change your brain essentially. And so that intent
is is crucial for real meaning and real understanding. And it's something that doesn't exist
in language models. Do you reckon that we have to give real agency to systems to achieve that?
To like have them care about something? And maybe with reinforcement learning or other paradigms?
I think so. Yeah. So I don't know if agency, I mean, I don't want to keep like going on the
definitions, but so agency is also a bit unclear, I think. So it's more, yeah, you can model the
intent of communication when you're trying to model human communication. You can try to model
the intent as a part of the interaction. So you could think of so the two things I just talked
about you could integrate them in language models pretty easily, right? So you could have a language
model that also has a multimodal input. Maybe you can put it in an embodied environment where it
can walk around. And then maybe you can have multiple of these language models walking around
in that world and interacting with each other and other humans. So if you put all of that together,
then I think you get something very close to how humans learn language. Is this where you think
Hugging Face is headed? Is this one of the grand directions? This is definitely one of the grand
directions. Yeah. So one of our projects is multimodal. As I said, another one is about
embodied learning. Thomas also talked about this when he spoke on this podcast. Yeah, the way he
described it was, maybe we need to teach models language more like we teach humans language,
which is in the world trying to get things done. Exactly. Yeah. So and that's because we want
the models to use the kind of language that's useful for interacting with humans. So people sort
of gloss over it, but the reason we want to have natural language understanding and natural
language generation capabilities in these models because we want them to interact with humans.
And so I mean, one of the other things I've been pushing a lot for is a more holistic evaluation
of these models where rather than just evaluating them on static test sets, we actually expose them
to real humans and we see how well they do in that setting. And as you as you mentioned,
those models very quickly break down if you try to actually do that.
All right. So a different question. I was really curious. So I consider you a very multilingual
person. I mean, all Dutch people are. If you've ever met a Dutch person, you've met multilingual
people. And here you are in NLP and adjacent. You know, you're you're definitely expanding
beyond that. But you would consider yourself an NLP practitioner. Yeah. I think so. Yeah, kind of.
I mean, I've been branching out for a long time. So I would consider myself an AI person like
so a lot of my work is multimodal, but this is language first. Yeah, language is my my main
interest. How frustrating or bizarre has it felt to be a deeply multi-lingual person in like
a time and science where it's just so English dominated, the research itself, the tools down to
the very data that we're training these things on. And I'm asking this as an obvious
seg to this really exciting, you know, project that's underway to perhaps create the first truly
multilingual based language model as that's my understanding of the project. But I first wanted
to hear just like you, Dawa, like as a deeply multilingual person, you know, like what does it feel
like? What has it felt like to be in this weirdly accidentally English dominated space?
Yeah, so that's a very interesting question, but I don't know if I'm the right person to ask it
because I moved to the UK for my PhD and then I moved to the US and so most Dutch people speak
pretty decent English, I think. So I think where the accessibility of language models and the
multilinguality of language models where that really matters is for people who are
monolingual and who don't speak English. So people who can't easily access this technology
because it's limited only to English. But I think that doesn't really apply to
most Dutch people because they go very easily switch over as you mentioned.
But also like using these things to make sense of the world that's not written in English.
Like I could tell you how hard it is because that's my day to day is like dealing with Chinese,
Russian or other languages like the tools and the data is far, far weaker.
Oh yeah, yeah for sure and I think there's also very interesting underlying questions there about
the cultural differences that manifest themselves in languages. So English as a language is very
explicit so you can be relatively low context in how you communicate. So you're just very explicit
or you know some people would consider Americans relatively blunt. I think in how they communicate
same for Dutch people anyway. But if you think about like Japanese language which is very sort of
indirect and very different in a sense from English I think that also manifests itself in the culture.
So maybe there are just things that you can really capture about Japanese culture because you have
a specific type of language model. So tell us a bit about the ongoing experiment to make a truly
multilingual model. Yeah so this is the big science model. It has a name now it's called Bloom
which I think is a really nice name because the logo of big science has also always been a flower.
So the flower is starting to bloom and so this language model it's as you said the first
big multilingual language model and it is only a few weeks away from being done training so
it's been very cool you can just follow it on Twitter. There's a regular Twitter update whereas
like we're at like 87% or something now and so have you been playing with checkpoints?
Yeah so there's something called the Bloom book where people have been able to just submit
problems and then someone would run them and store their output somewhere for people to inspect
and so we're releasing some checkpoints soon as well for people to talk to and then when the final
model comes out it's also going to be released so that people can play with it themselves.
Cool. Is it a basic text-to-text autogressive model? Same architecture as your typical big text-to-text
models? Yeah basically yeah so it's I think by design that there hasn't been too much divergence
from the sort of standard language model that people are used to but there are some nifty new things
in there so it uses like a LMI for like how to do the token embeddings and things like that so there
are a couple of nice different things in there but yeah the main architecture is exactly what you
would expect. Let's dig into that. A lot of people on this call won't really even know what a token
or a tokenizer is. I think this is a really neat part of NLP. It's just very much like the tools
you use kind of talk but let's just like take a moment. Tell us what is a token, what is a tokenizer
and then like how did you do it differently with this this big bloom model and why did you have to?
Yeah so I'm not I'm not the the right person to really answer detailed questions about the tokenization
of the language model but that so I can explain what what tokenization is so it's basically just how
do you cut up your your text so you know a sentence consists of words so you could just cut it up
in the white space and and just every word is a token but that is inefficient so what people have
been doing is trying to chunk it up in smarter ways because then you'd have like a vocabulary of
millions right and with multiple languages it could be huge. Yeah so especially if it's multilingual
maybe you just don't see words often enough to really have a very good understanding of their
meeting so a good representation of their meeting and so what you can do is you can chunk
different segments of words together in smart ways so so this is BPE by parent coding and things
like that and so there has been a working group in the big science workshop so it's like a one-year
workshop is how we're thinking about it and so I think there are 40 50 different working groups
and there was one working group working on tokenization they wrote a very nice survey paper
they did a big analysis of what the right tokenization is and one of the things that they found
I think also together with under like the main model working group is that these alibi
positional embeddings that really help so this was just an empirical finding and and so so
you know there's just a lot of this small research that went into this this whole endeavor.
So why not just go all the way down to the individual character? Why mess with tokens at all?
Yeah it's a good question I mean there are admin efforts in this direction or like
so back in the days there were like character RNNs before Transformers and people were trying
to get this to work it sort of worked but it didn't really really work. It was a great way to
generate made-up silly words. Yeah yeah for sure yeah and so yeah I think there's also an
interesting possibility there where we reduce everything to the byte level and so when you think
about like Unicode or or UTF-8 or things like that like in theory every single character can just
be be modeled at the byte level and then maybe that's the future and then maybe you could even like
put images and audio and everything is just bytes and so basically you can just have a
pre-trained byte level model so I think that's an interesting research direction and there's
been some work on that but it so far it hasn't really proven to be better than just smart ways
of tokenizing your data. So maybe the real explanation for it not working yet is that we haven't
used enough data yet so maybe we just need even more data as always Ben. Thomas mentioned 800
gigabytes. What does that actually translate to in terms of like how much of the internet did you
grab for this? I understand you crowdsourced it. Yeah so it was crowdsourced with a big community
of collaborators who were part of this big science effort and so it's not really a crawl so it's
very hard to say like what percentage of the internet is this it really depends on the language
and the folks who contributed the data for their own language. I think some of them also had
different approaches so it's a very kind of targeted way of collecting data and that's one of the
beauties of this big science effort. So I think there's a lot of emphasis on this bloom model
but what's also very interesting about the overarching endeavor is that we have this data set which
is really beautiful and curated by experts in those languages. It has a very interesting coverage
of different languages geographically over the whole world. I don't know what the latest numbers
know in the 40s or 50s I think 45. Wow so this is a huge collection of languages and it includes
like low resource African languages and things like that so I think that's really great and so
there's the data effort but then like the the legal side of this like how do you distribute the
model the governance side of the data itself. All of these the super intriguing questions have just
been explored by the community completely in the open so it's just fascinating for me I'm sort
of an outsider right so just yeah so I mean me too in a way like this started about a year ago
I think or more than that and so I've just been following it from the sidelines and I'm still
kind of like not directly involved in it that much and it's just amazing to see.
So okay now back to you so here you are six months into your new role at Hugging Face.
Give us a sense of like what you thought your job would be when you started and now six months
later like what has changed what's the newest thing that you've learned about yourself and Hugging
Face and the mission you know like what gets you out of bed in the morning that's changed.
Yeah no that's a very interesting question I mean I think the job has been what I expected sort of
so I knew going into this that it's just an amazing team and like we really have some some
brilliant researchers in this team so I was very excited about getting to work with those folks
and so that's been really awesome. I think one thing that I maybe didn't really expect is
when you're a company like Hugging Face and you're this distributed all across the globe
you have to be very decentralized so a lot of the communication happens asynchronously
on Slack in public channels which I think is great and so Hugging Face really has a unique culture
that supports this way of working together but if you come from a different working culture like
me coming from Mehta that is quite the transition to make and so especially you can't just go to
a whiteboard with people. Yeah so everything is remote but it's not even just remote where you're
both like talking to your computer or resume it's like it's remote also in time so one of the things
I'm struggling with is just time zone I think so I'm in California right so I'm sort of trailing
the world and and so when when I wake up or when my son wakes me up at around 7 a.m. then I check
my phone and I have like a million Slack messages and emails and things to read through and then
usually my meetings start at 8 a.m. because I need to make sure I can talk to the Europeans
and then they stop working soon after that and so I'm always kind of like trailing in time
which is which is not easy. So you didn't see that coming? I was not prepared for that yeah I'm
I'm still still adjusting but I mean it's an interesting learning experience and it's just
fascinating I think to see like where the world is going with remote work and so this is the
future way I think in which a lot of companies are going to be doing this. So what's it like
running and building and nurturing a research team at a startup? I think that's something that people
will be really curious about. I think a lot of a lot of people will be familiar directly or
indirectly with how a research group even 30 strong like you said at a university works you know
you've got a PI and that PI's job is mostly to get grant money and then you've got the postdocs
who actually run the show and then you've got like grad students who are ranging from miserable to
pretty happy and then you've got like interns and undergrads. Does it have anything like that
structure? Is it just a totally different beast? Yeah and it's very different so I am definitely not
a PI so I'm more a facilitator I think or a coordinator and so we have a very flat non-hierarchical
organization. We do have team leads so those those would be closer to PIs I think so we have a
multimodal project and it has very clear team leads and you know things like that. So my role
is it's more like a sort of serving leader where I just try to to help people the best way I
possibly can and to make sure they don't have roadblocks and and that people are talking to
each other and that I'm aware of what's going on and I try to connect people to the right people
and connect ideas to the right ideas. So it sounds like pretty normal management actually.
Yeah but yeah I guess you could say that but it's very different from normal management at the
same time I think because of how decentralized the company is and because of all of the other
things that are just very different from from a traditional management role it like a big tech
company. Well and also the fact that there's like a thousand strong group of people outside the
company that you actually have to work with and coordinate with. Yeah but that's just a big
science project right so I think I mean you make an interesting point that one of the things that
makes hugging phase so special is that the community plays such a big role in the company and that's
not just big science right so like if you look at Transformers the library and the open source ecosystem
and data sets and things like that that's a huge community and all of these people are also
contributing actively to making these tools so awesome. Yeah no I remember the day we first
started using your Transformers library at my company primer it was a revelation you just like I
can't under it I can't say enough about how positive the open sourcing of Transformer language
models was and I think hugging phase deserves most of the credit just like yeah. I think one of the
the the reasons that Burke became so popular so quickly was because of the Transformers Library
or the predecessor right so Pythorch pre-trained bird I remember I was at a workshop at this
Santa Fe Institute they do these workshops where they invite a bunch of people and they talk
about some stuff and Fernando Pereira was there the the Google director of research I think
and he was saying like we have this thing coming out and it's going to like blow everything out
of the water it's amazing it's going to revolutionize NLP and like I've heard people say that before
and I never really believed it but in this case he was right so so birds yeah so it dropped like
I think two weeks later or something and then so everyone wanted to play with it and being in
fair obviously Pythorch was the preferred framework and and it took like I don't know like a week or
two before there was this Pythorch pre-trained bird model that everyone was playing with so it's
amazing and so I did some snooping your most cited paper at least according to Google scholar
is this 2017 paper on sentence representations why I think that's so so notable is that that's
like just on the before side of Bert so you know Bert comes out in October 2018 something like that
and so like well a full year before that you were deep in NLP solving hard NLP problems
do you remember how crazy it was when suddenly like on the other side of that line when we had
language models all the things in NLP that were really hard and tedious and you needed so much
data to even barely get some performance suddenly became kind of routine and fun and easy like
I'm not hiding I'm not hiding the reality that like tons of stuff doesn't work and tons of stuff
is still hard but the the things that are hard are new things largely yeah so I agree with with
that but so so to me as a researcher it didn't feel like a very abrupt transition actually so
I think that was much more the case for NLP practitioners that more applied people trying to
use the tools yeah but so for me as a researcher I think like the transition was was actually very
natural and so we were doing things with LSTMs and then okay transformers so LSTMs didn't really
work so you needed attention and so there were so even in infrecent we were also experimenting
with self-attention and things like that and then what the transformers paper did is it basically
removed the recurrent so rather than having an LSTM we did it forward just a normal NLP feed
forward network and so it turned out that attention on its own is actually okay right so
from that it became natural to try to do this on just language modeling test so that's GPT
and then if you can do language modeling why not do it bi-directionally because we were playing
with bi-directional LSTMs all the time infrecent is a bi-directional LSTM so birth is just a bi-directional
GPT so it all was very natural I think when it came up so it felt it felt naturally from the point
of view of like no understanding the science but I can tell you from the point of view of people
trying to solve pay solve problems that people will pay you money for no yeah for sure it changed
everything what there is an aspect though scientifically that is new right I was delighted when
this little cottage industry of Bertology suddenly kind of sprouted out of nowhere so here's the
thing you know it struck me that deep learning used to be very much like a branch of mathematics
right because it was part of statistics you know so like all of ML was just math and it felt like
the math world and then suddenly here we are today with models that are so complicated they're more
like biology artifacts we're like kind of prodding them and probing them and trying to understand
things like how how the heck does Bert you know does it understand grammar to what extent does it
do it differently than us suddenly it's feeling more like an empirical science and less like a
branch of math yeah I'm not I'm not sure I'm happy with that actually I also think that that is this
so yeah I have a couple of things to say about that actually so I think this cottage industry of
Bertology is interesting because a few years before that we had a cottage industry in Wortevek
right so Wortevek kind of blew everyone away and then there were a couple of ACLs in the
EMNOPs where just everything was something to veck and it was all just trying to analyze what
Wortevek really did and so I think that's just kind of the progression of science where you have
a big breakthrough model and then there's some consolidation right in the sort of Thomas Kuhn
paradigm shift so there's a real paradigm shifting artifact like Wortevek or Bert and then
there's a lot of consolidation where people try to understand this better so I think that's just
the natural progression and that's just going to continue happening but about Bert specifically
so so we just don't have the correct mathematical tools I think to really understand what it's
learning and so there are some efforts now from like Chris Ola and trying to understand better
what transformers are really learning but so we have a very interesting paper called
Mass Language Modeling and a distributional hypothesis order work does not matter much or something
like that so what we basically show is that you shuffle if you shuffle a corpus and so all of the
senses are not in the right order anymore and you train a Bert model on it it just does just
as well as a regular Bert so you mentioned like does Bert learn grammar which seem like weirdly
seems to suggest that it doesn't matter like that it's clearly doing something differently than
humans do because if you imagine trying to learn language with shuffled language it'd be a nightmare
exactly yeah so so I think yeah maybe we're also over yeah I don't know like oh thinking that
Bert is better than it really is or these sorts of models that they're actually better than
they really are and I think like when you think about GPT-3 and how much of a splash that made
there's also this this element that people just have a natural tendency to anthropomorphize
everything like you do this to like your robot vacuum cleaner and things that you give it a name
and right so that in the the words of Daniel Dennett the philosopher you're ascribing intentionality
and and so I think we do that all the time through everything and we do it especially to
things that produce language because language is essentially the only thing we know that is really
really human only and and so when something produces language we just go out there has to please
something brilliant behind that but very often it's just a higher order distributional statistics
it's just clever hans that's basically we we create these benchmark tests and we watch the
performance on these tests going up up up up and we attribute you know a model like GPT-3
on these language tests as getting truly more clever it truly has a deeper quote-unquote
understanding of the task at hand but then you do these clever experiments like the one you
described with scrambling and it reveals well surely actually it's just using distributional tricks
yeah but so I don't know I think the jury still I wouldn't put a debt strongly I think the jury's
still out so I definitely think that there's an evaluation crisis in NLP and I mean I've been
doing a lot of work with lots of folks in trying to improve that through things like Dynabench where
we do a different we try to rethink benchmarking essentially but I mean it's undeniable that
progress in NLP has just been insane so if you look at like what GPT-3 can do compared to GPT-1
or what we can do now with Dali too compared to I don't know the earlier text to image synthesis models
it's just crazy how fast we're yeah so the progress is real but we should be careful to not
not kind of over-interpret what we're seeing so there's still a lot of stuff that
so there's a headline there's a headline going around just this week about
researcher from Google essentially attributing sentience to the Lambda language model
and I think that's really to your point like what we're talking about it's these things actually
know how to work with language and we humans are language machines we're like completely geared
towards understanding and transmitting receiving and sending information with language that is the
most human information you know intentionality and understand the world around us getting stuff
done and so when some mathematical object is doing it it's I feel it too I can't help it have
you ever kind of like had that feeling that you you just like have to push away of like man I'm
talking to this thing but what do you mean by a mathematical object I mean I think you can argue
that your brain is also a mathematical object or at least you can write your brain
you took the bait I was hoping you shake the bait this is like philosopher catnip
well yeah I don't know so I think this it's very interesting because there's a very nice
theory of consciousness that says that we take the intentional stance towards ourselves as
rational agents and that's what consciousness is there's a strange loop as Douglas Hofstetter calls
it so yeah maybe we're we're evolutionarily hardwired to take an intentional stance towards
things and that's why we're so confused by the NLP progress we've been seeing does it also hint
that a way to achieve artificial intelligence of a more AGI flavor oh yeah so I yeah again like
I don't really know what AGI even means and I think it's very premature to to start thinking
about it and so so we have a philosopher slash ethicist who joined having faced recently
Jado Pestili so she has has made this point on Twitter too I think where there are real problems
right now with the deployment of AI and and so when we're thinking about the applied ethics of
these systems there are just real things we need to fix right now and they are much more
salient and much more important right now than thinking about AGI and paperclip maximizers
and things like that I agree I agree completely there's just I think actually the biggest problem
to solve from an ethics point of view is these systems not working that well on narrow tasks and
people over trusting them that's where a lot of harm can come from not from bias even that's
another level of problem just like over trusting systems misunderstanding their limits
yeah true but so there's a trade-off here too right so we shouldn't hype them up too much
because people will just misunderstand what these systems are capable of but we also shouldn't
underhyped them too much so Sam Bowman professor at NYU is a very nice paper where he talks about
the dangers of underhyping so if we all just pretend that there is no progress at all then at
some point we are going to be very surprised when AGI suddenly emerges and we have sent
you into AI so we definitely should think about this stuff and so AI alignment is a very active
research area and it's a very important research area but it's all about finding that balance I think
sure okay lightning round most exciting things on the horizon for research in NLP that you're
either working towards now or you'd like to go a little bit further than what you're you know
just about to ship just about to publish yeah so I'm very excited in multi-modality obviously
I think that there's a lot of interesting work coming out in semi-parametric models where you
have retriever components and some sort of lightweight reader model on top of that retriever so there
is a paper from DeepMind coming out a couple days it came out a couple days ago the idea and a
nutshell there is it that these language models are basically frozen in time based on the data you
give them and so we need some way to help them keep refreshing what they understand about the world
oh yeah that's just one application I think it's much much more so so it's I think it's much
more about how you learn different things so so as humans we have different kinds of memory we have
a semantic memory and an episodic memory and so we can we also have a library and the internet where
we can look up stuff right so we don't have to store all of it in our parameters our brain so I
think if you do this with models too where you have a big index where you can invest a lot of heavy
compute in having a very high quality index then you can have lots of lighter weight reader models
on top of this so this is also going to have lots of repercussions I think for industry where if
you're a company like Facebook you want to have a million classifiers from all of these different
teams all trying to do cool stuff with their classifier if they have a big index that they can
rely on then you kind of do the computing in a much more intelligent way I think so so it's about
finding the mix between the retriever which will be a big big sort of language model and the
reader model on top which will also be a big sort of language model and just for people who are
unfamiliar with the current status quo you what we have right now is a basically just two kinds
of of information storage you've got the model itself which has been pre-baked with just an
understanding of language and whatever emerges from that just basically predicting missing words
and then you've got what people usually call the prompt which is whatever you can cram into the
attention window at inference time so you can actually put a whole conversation there you can put
example problems you could do a lot of neat things in the prompt but it's pretty darn limited right
it's it's aside from your pre-baked knowledge that's crystallized all these things can do is whatever
you can cram into the prompt and what you're suggesting is hey maybe we could actually build a
whole separate system where they could retrieve knowledge at game time yeah so so there are some
interesting so I've been involved in a model called rag retrieval augmented generation and there's
also realm from from Google and yeah so the basic ideas that you can so you have your your
language model which would be parametric and then you have your K&N like a nearest neighbor search
algorithm essentially which is non-parametric and if you put those two approaches together you get
a semi-parametric model and I think there's there's a lot of potential applications for that
down the line so that's one thing and then the other thing so I said multimodal semi-parametric
and I think the other thing that's going to be interesting and there's a lot of attraction
happening there now too is around data-centric AI so I'm still rooting for things like active learning
becoming much more mainstream measuring our data much more carefully so so we have folks like
make Mitchell in hugging face working on data measurement tools and things like that so really trying
to understand much better what's really happening in our data and trying to do things to the data
or curate the data in different ways so that we can have better models in yet yeah I I quickly before
calling you I actually refreshed my knowledge of what this data tool looks like it's kind of like
an x-ray for data sets and it's a really beautiful idea I'm surprised that no one you know you know
what an idea is a good one when you're like why haven't we been doing this for ages it's just like
all the automatic obvious things you can measure about a data set that that's composed of language
like let's put that all in one toolkit and then you can keep adding to it and make it more and
more sophisticated that's the basic idea right yeah that that's exactly it and and so I think that
it's just nice that so this isn't in a space so it has a graphical user interface it just
exists maybe in the longer term it will be a natural part of the hugging face hub where you can
just upload any data set to the hub and start measuring what's actually in your data and you have
a nice interface where you can just inspect it on the fly so we have have a lot of interesting
things going on in the direction of evaluation and measurement so so I think what's really crucial
when you think about the AI pipeline of the future is that you have raw data which you turn into
data sets and those data sets you turn into models which you want to measure your data sets and
your models and you want to understand what's in there and how well they perform and then you want
to based on your measurement deployed the best model to production so for making predictions with
your model and so so measurement is really absolutely crucial in all of the decisions that you're
making there but measurement is also very difficult and and so that's something that we're we're
trying to address so we have an evaluate library that came up a couple of weeks ago we have some
very exciting announcements coming up soon I don't know when this podcast comes out it might
already be out by that time but we're working on evaluation on the hub so that you can essentially
evaluate any model on any data set using any metric just at the click of a button so you don't
have to do any manual stuff there well surely people are going to miss having to go and copy-paste
massive chunks of scikit-learn code into their Jupyter notebooks come on dour yeah yeah no I think
like lower lowering the barrier to doing proper evaluation according to best practices I think
that's that's a hugely impactful thing to do and that's something that hugging faces uniquely
equipped to do so so that's one of the things I've been excited about also in the science team
you mentioned active learning I'd love to dig into that a little bit that's something I've
worked with myself and it's an enticing idea just for those listening at home who aren't familiar
you know usually when you want to make a data set to train a model you the human have to select
the samples of data from your raw data pool that you're going to gold label and you know train
your model on the idea of active learning in a nutshell is let's put a model between you and the
data sometimes the model you're training and it will decide which ones to put in front of you the
human whose time is expensive and you know whose site is limited and make good choices and try
and find the most instructive examples from the data to labels so that you get the most bang for
buck because no one wants to spend their whole life labeling data in fact there's there's some
problems that that's just prohibitive you literally just can't do it true positives are too rare
etc etc so is there some like really exciting new developments in active learning I feel like
like it's kind of like a done deal is there is there something new and exciting on the horizon you think
yeah I'm not so I think it just has a lot of potential and so what you described is a specific
kind of active learning I think where you have an acquisition function that scores examples and
you just decide which example you want to label but I think there are extensions of these algorithms
where you can think not about the labeling part but about the pre-training part so maybe I can
pick parts of a large corpus that I should be pre-training on now because I know what downstream
task I care about in the end and so so there's a mismatch currently between the pre-training phase where
we just do language modeling or so causal or mess language modeling and then we fine tune it on
something that might be very different from what we're training on so we're we don't really know
what to train on so I think if we can connect the pre-training phase to what we know we are going
to care about then you can do very interesting things and so the way to to do that selection so
data selection is true in acquisition function type of things so that's why it's related to active
learning another interesting thing that I've been working on as well with some folks is dynamic
adversarial data collection where you have a model in the loop and and a human is trying to
fool the model and so if you take the the model fooling examples or or so if you take all the
examples including the ones that didn't fool the model but that are still kind of intended to
try to probe the model for a weakness if you train on that data and you keep updating the model as
you're doing the training so that's the dynamic component then you get a much better model out
in the end so it's really like 10 percent better so we have a nice paper where we try to do this
in the limit over like 20 rounds of natural language inference and you just get a much much
better model out in the end so I think the future of data collection the way we think about it now
in the field is going to be changed a little bit where everything is just always going to be
with models in the loop and that maybe ties back to this long term vision of having language
models interacting with each other in some environment but if you can have humans and models
together interacting with each other and learning from each other and maybe trying to also kind
of probe each other and and be on the decision boundaries of certain things then you can learn
much more efficiently I think it sounds like you're describing education like a school
exactly yeah yeah so yeah so so in terms of education one of the important things is also a
curriculum right so I think one thing you could do with this pre-training like the active learning
of pre-training and connecting that to fine tuning is you could try to have a smarter curriculum
so your if your acquisition function changes over time essentially you're designing a curriculum
or you're learning a curriculum on the fly that helps your language model be as good as possible
on the downstream test as you might care about okay and final question at least that I can think of
is something that Thomas mentioned that intrigued me which is he said that there seems to be
something missing with NLP you know like we making these language models bigger and bigger and bigger
and yes we're improving the data and we're getting more data centric but he gave the impression
that he really believes that there's something fundamentally missing it's not just more data
it's not just more text and you've hinted at least yourself with multimodality and interaction
agency or whatever that means so yeah if you if you had to make a guess 10 years from now
like what do you think the paradigm is going to be will we even talk about NLP I suspect NLP
will be a historical footnote they'll just be AI right and text will be just one of the many
crucial developmental raw material for for artificial intelligence yeah but I still think
that text will just remain a dominant modality so even as it is with humans
exactly right so so language really is very crucial so I don't think NLP itself is going
away but I think yeah in order to get to real meaning all of these other fields are probably going
to be subsumed into NLP when it comes to language understanding so yeah I don't know in 10 years
or now I think we're going to have very very different models in a sense but I think a lot of the
the building blocks that we have now are still going to exist in those models do you think it'll
just be all eventually robotics either real world and or virtual world robots like taking in all
the sensory information virtual robots I definitely buy but so I think for actual physical robots
I think like learning from that doesn't really scale that well so I think one of the big problems
in robotics is similar to real right how do you transfer from a simulation to a real environment
and so as our simulations become reader and reader that problem is going to become smaller and
smaller so I don't think we need physical embodiment in any real sense in order to get to meaning but
we'll probably definitely need virtual embodiment where you have an environment where you can interact
with each other but maybe that environment already exists right so it maybe that environment is
just the internet or maybe that environment will come into existence very soon in the form of
the metaverse or whatever you want to call it any final thoughts you want to share with tens of
thousands of people I think so I think one of the things that I think is important and that's
kind of what hugging face also stands for is just open source and open science and so if I were to
give any parting thoughts I would encourage people to always embrace openness because that really
is crucial to making progress but also making sure that the progress that we make doesn't end up
in the wrong hands or go in the wrong direction so just for those listening at home Daoah where can
we find out more about you and what you do yeah so I have a website it's daoakila.github.io it has
a couple of links to relevant social media profiles also have a Twitter account so that's Daoakila
my name so D-O-U-W-E-K-I-E-L-A and so I'm trying to be more active on Twitter I'm still working
on that and I'm bohan and bot on Twitter and you'll see me probably asking follow up questions
out in the open following your advice Daoah thank you so much this was this was a blast thank you
thanks for having me
