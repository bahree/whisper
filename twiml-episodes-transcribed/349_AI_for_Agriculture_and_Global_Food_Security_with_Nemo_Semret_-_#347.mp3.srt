1
00:00:00,000 --> 00:00:13,380
Welcome to the Twomo AI Podcast.

2
00:00:13,380 --> 00:00:15,740
I'm your host, Sam Charrington.

3
00:00:15,740 --> 00:00:23,720
Hey, what's up everyone?

4
00:00:23,720 --> 00:00:28,880
It's been nearly three years since we launched the Twomo Online Meetup, initially as a way

5
00:00:28,880 --> 00:00:34,040
for listeners to connect with one another and study academic research papers together.

6
00:00:34,040 --> 00:00:39,440
The group really took off in mid-2018 though when I mentioned off-handedly in my interview

7
00:00:39,440 --> 00:00:44,820
with fast.ai's Rachel Thomas that I'd be taking their course and I invited the Twomo

8
00:00:44,820 --> 00:00:47,480
listener community to join me.

9
00:00:47,480 --> 00:00:52,200
That led to the very first Twomo study group and the folks who came together for that group

10
00:00:52,200 --> 00:00:57,960
have become the backbone of a community that's now over 3,000 members strong.

11
00:00:57,960 --> 00:01:02,600
Fast forward 18 months and we've supported each other on our personal learning journeys

12
00:01:02,600 --> 00:01:10,640
and a wide variety of courses from stanfordfast.ai, deeplearning.ai, on Kaggle projects and much

13
00:01:10,640 --> 00:01:11,880
more.

14
00:01:11,880 --> 00:01:16,040
I say all that to say that I am humbled by the role that we've been able to play in helping

15
00:01:16,040 --> 00:01:21,400
folks learn machine learning and I am excited about the new educational programs that we're

16
00:01:21,400 --> 00:01:24,320
bringing to the Twomo community this year.

17
00:01:24,320 --> 00:01:28,440
We recently launched a collaboration to bring you the causal modeling and machine learning

18
00:01:28,440 --> 00:01:32,880
course and study group which I've mentioned here before and today I'd like to share some

19
00:01:32,880 --> 00:01:37,600
new details on the AI enterprise workflow study group that we're launching in just a

20
00:01:37,600 --> 00:01:39,200
few weeks.

21
00:01:39,200 --> 00:01:42,600
If you've been listening for a while you know that I am very excited about the work going

22
00:01:42,600 --> 00:01:47,360
on in ML and AI communities to make developing and deploying machine learning and deep learning

23
00:01:47,360 --> 00:01:51,640
models in the enterprise more accessible and efficient.

24
00:01:51,640 --> 00:01:59,320
In fact we hosted an entire conference TwomoCon AI platforms on this topic just last fall.

25
00:01:59,320 --> 00:02:03,720
Until now there have been very few formal resources that folks could turn to to learn

26
00:02:03,720 --> 00:02:08,360
real world machine learning workflows and deployment strategies.

27
00:02:08,360 --> 00:02:13,760
Our folks at IBM are working to change this though with the AI enterprise workflow specialization

28
00:02:13,760 --> 00:02:17,760
that they recently made available on Coursera.

29
00:02:17,760 --> 00:02:21,920
And I am super excited to share that we've partnered with them to host a study group for

30
00:02:21,920 --> 00:02:27,720
this six course specialization program which I will personally be hosting.

31
00:02:27,720 --> 00:02:31,880
The courses in the sequence teach real world machine learning and an enterprise environment

32
00:02:31,880 --> 00:02:37,320
including applying the scientific process to understanding business use cases and structuring

33
00:02:37,320 --> 00:02:45,160
data collection visualizing and analyzing data and hypothesis testing feature engineering

34
00:02:45,160 --> 00:02:51,320
and identifying and addressing data biases selecting the best models for machine learning

35
00:02:51,320 --> 00:02:59,640
vision and NLP use cases and using ensembles deploying models using microservices and containers

36
00:02:59,640 --> 00:03:06,720
Kubernetes and Apache spark and applying unit testing to ML models and monitoring model

37
00:03:06,720 --> 00:03:09,400
performance in production.

38
00:03:09,400 --> 00:03:13,440
I am really looking forward to working through these courses and I would love for anyone

39
00:03:13,440 --> 00:03:15,920
interested in these topics to join me.

40
00:03:15,920 --> 00:03:20,200
If this sounds interesting and you'd like to learn more, I invite you to join a webinar

41
00:03:20,200 --> 00:03:26,880
that I'm hosting with Ray Lopez, the courses instructor on Saturday, February 15th at 9.30

42
00:03:26,880 --> 00:03:29,160
a.m. Pacific time.

43
00:03:29,160 --> 00:03:34,360
To register, visit twimmelai.com slash AI workflow.

44
00:03:34,360 --> 00:03:43,680
And now on to the show, all right, everyone, I am on the line with Nemo, Nemo is the CTO

45
00:03:43,680 --> 00:03:44,680
at Grow Intelligence.

46
00:03:44,680 --> 00:03:47,120
Nemo, welcome to the twimmelai podcast.

47
00:03:47,120 --> 00:03:48,120
Thanks.

48
00:03:48,120 --> 00:03:49,120
Happy to be here.

49
00:03:49,120 --> 00:03:50,120
Awesome.

50
00:03:50,120 --> 00:03:55,640
Let's jump right in and have you share with us a bit of your background and how you came

51
00:03:55,640 --> 00:04:02,800
to work and the intersection of machine learning, AI and global food security.

52
00:04:02,800 --> 00:04:04,800
Great.

53
00:04:04,800 --> 00:04:10,720
So I've been at Grow Intelligence for about four years now, four and a half years.

54
00:04:10,720 --> 00:04:15,840
And before that, for many years, I was an engineer and tech lead at Google.

55
00:04:15,840 --> 00:04:20,360
And obviously working on a lot of things that are technically similar in terms of machine

56
00:04:20,360 --> 00:04:27,080
learning, using data, mathematical algorithms, what brought me to Grow Intelligence, well,

57
00:04:27,080 --> 00:04:33,400
first I met, it was the founder, Sarah Manker had a really compelling vision for why this

58
00:04:33,400 --> 00:04:36,480
is an important area to be working on today.

59
00:04:36,480 --> 00:04:41,040
And what brought me here was that AI were solving some really important problems, some

60
00:04:41,040 --> 00:04:44,640
of the biggest problems affecting the world.

61
00:04:44,640 --> 00:04:51,200
And secondly, I think that the timing of the problems that we're trying to tackle is

62
00:04:51,200 --> 00:04:55,920
really appropriate, meaning maybe 10 years ago, what we're trying to do today would

63
00:04:55,920 --> 00:04:59,160
not have been realistic or would not have made sense.

64
00:04:59,160 --> 00:05:04,720
And 10 years of the future would probably be not so interesting anymore because it hopefully

65
00:05:04,720 --> 00:05:05,720
will have been done.

66
00:05:05,720 --> 00:05:09,480
So I think we'll kind of have a sweet spot for this industry.

67
00:05:09,480 --> 00:05:16,760
And then thirdly, I think what makes it technically interesting is that from various perspectives,

68
00:05:16,760 --> 00:05:24,160
whether it's computer science, satellite hardware, data storage and infrastructure, a lot

69
00:05:24,160 --> 00:05:29,720
of different enabling technologies are available to us today.

70
00:05:29,720 --> 00:05:37,000
And so make this problem not just important, but also feasible, I mean, addressable today.

71
00:05:37,000 --> 00:05:42,960
You mentioned Sarah, I had the opportunity to hear her speak at the Black and AI workshop

72
00:05:42,960 --> 00:05:46,080
at last year's Neurip's conference.

73
00:05:46,080 --> 00:05:50,400
And so had a chance to learn a little bit about what Grow is up to.

74
00:05:50,400 --> 00:05:56,520
And so all she seems like an amazing person to work with, but also she does a very good

75
00:05:56,520 --> 00:06:03,280
job at articulating the motivation behind what you're doing and the importance of the

76
00:06:03,280 --> 00:06:04,280
work you're doing.

77
00:06:04,280 --> 00:06:06,520
Can you share a bit of that with us?

78
00:06:06,520 --> 00:06:12,600
Yeah, I guess the one way of putting it is what we do for getting the technical aspects

79
00:06:12,600 --> 00:06:17,800
is basically we help people make better decisions in the world of food and agriculture.

80
00:06:17,800 --> 00:06:25,400
So motivations, I think, are that the data-driven decision making hasn't quite taken hold in

81
00:06:25,400 --> 00:06:26,400
this industry.

82
00:06:26,400 --> 00:06:30,000
And obviously it's one of the largest industries in the world.

83
00:06:30,000 --> 00:06:36,000
Think about two billion people in the world are involved in the whole industry of food

84
00:06:36,000 --> 00:06:41,760
and agriculture from production all the way through its redistribution and so on.

85
00:06:41,760 --> 00:06:50,280
And this world is a number one, changing pretty rapidly as economies develop and culture

86
00:06:50,280 --> 00:06:54,720
has changed, people's diets and what type of food they eat change.

87
00:06:54,720 --> 00:07:02,200
So people need to make better decisions about what's going on in the world of food.

88
00:07:02,200 --> 00:07:08,280
Besides this, social and cultural changes and economic changes, another aspect is obviously

89
00:07:08,280 --> 00:07:15,080
global warming has thrown a lot of uncertainty in many different food related scenarios.

90
00:07:15,080 --> 00:07:20,480
And then maybe even more short-term, you know, you have trade wars and tariffs and deforestation

91
00:07:20,480 --> 00:07:22,480
and things like that.

92
00:07:22,480 --> 00:07:26,240
So a lot of locusts, is that something you're involved in?

93
00:07:26,240 --> 00:07:32,440
There's apparently a massive locust swarm currently in Eastern Africa and it's expected

94
00:07:32,440 --> 00:07:34,520
to make its way all the way to India.

95
00:07:34,520 --> 00:07:35,680
Yeah, absolutely.

96
00:07:35,680 --> 00:07:40,440
This is a huge topic in the last couple of weeks and that's exactly the type of problem

97
00:07:40,440 --> 00:07:42,800
where we would help people make better decisions on.

98
00:07:42,800 --> 00:07:49,520
So if suddenly this infestation shows up, you know, if you are trying to decide, well,

99
00:07:49,520 --> 00:07:56,560
what does it really mean in terms of food supply or not just in total but like how it affects?

100
00:07:56,560 --> 00:08:00,600
This region, that region, this type of crop, other types of crops, what will they do to

101
00:08:00,600 --> 00:08:03,480
prices, imports, exports.

102
00:08:03,480 --> 00:08:09,520
So yeah, connecting all those dots together and trying to make more informed decisions

103
00:08:09,520 --> 00:08:15,360
regardless of whether you're a supplier or a consumer or a processor is basically the

104
00:08:15,360 --> 00:08:19,480
type of problem we help to solve.

105
00:08:19,480 --> 00:08:21,520
But yeah, I think that's a great example.

106
00:08:21,520 --> 00:08:28,080
You know, a few months ago maybe you would have chosen to mention the US China trade wars

107
00:08:28,080 --> 00:08:37,480
as an example or the swine flu that's affecting pigs in Asia or the forest fires in Brazil

108
00:08:37,480 --> 00:08:38,480
and the Amazon.

109
00:08:38,480 --> 00:08:44,440
All of those are really great examples of the type of really huge events that affect our

110
00:08:44,440 --> 00:08:47,760
users and that we try to help them deal with.

111
00:08:47,760 --> 00:08:53,720
And so who are the typical users and maybe a bit more concretely, what are the specific

112
00:08:53,720 --> 00:08:57,080
types of problems that they're trying to solve?

113
00:08:57,080 --> 00:08:58,080
Okay, great.

114
00:08:58,080 --> 00:09:03,000
So yeah, I think one thing that's important, there's quite a lot of buzz in this world

115
00:09:03,000 --> 00:09:07,000
of agriculture these days, ag tech.

116
00:09:07,000 --> 00:09:13,960
So one distinction that I want to make is sort of this ecosystem is can roughly be split

117
00:09:13,960 --> 00:09:15,960
into two categories.

118
00:09:15,960 --> 00:09:19,800
There's one that you hear a lot about which is precision ag.

119
00:09:19,800 --> 00:09:23,960
So this is the type of, this is what we don't do, I'll start with that.

120
00:09:23,960 --> 00:09:30,480
And so there's a lot of really cool tech related to helping farmers make very, very local

121
00:09:30,480 --> 00:09:36,040
decisions, even every square foot of your field, you could say, well, should I put more water

122
00:09:36,040 --> 00:09:37,040
here?

123
00:09:37,040 --> 00:09:38,360
Should I put more fertilizer there?

124
00:09:38,360 --> 00:09:44,880
And so you'd have instruments and measurements on the field level and down to subfield level

125
00:09:44,880 --> 00:09:45,880
decision making.

126
00:09:45,880 --> 00:09:46,880
Exactly.

127
00:09:46,880 --> 00:09:51,440
Here might be like Blue River, which was acquired by John Deere.

128
00:09:51,440 --> 00:09:57,080
And they had a technology that you put on the back of a vehicle that would like, they

129
00:09:57,080 --> 00:10:01,080
would identify weeds and spray fertilizer on the weeds to make them burn out or something

130
00:10:01,080 --> 00:10:02,080
like that.

131
00:10:02,080 --> 00:10:03,080
Exactly.

132
00:10:03,080 --> 00:10:07,320
So it's a different, but then so that's what we call precision ag or what the world in

133
00:10:07,320 --> 00:10:12,880
general calls precision eggs is really advising things maybe on a few feet at a time.

134
00:10:12,880 --> 00:10:17,920
We're dealing with a different class of problems, which we, which we don't think there are any

135
00:10:17,920 --> 00:10:20,320
great solutions for right now, but it's more macro.

136
00:10:20,320 --> 00:10:25,760
So maybe you're not trying to decide what to do on every square foot, but if you have

137
00:10:25,760 --> 00:10:31,760
a chunk of land and you're trying to decide what is the best use of this land, or then

138
00:10:31,760 --> 00:10:38,680
in terms of what types of crops are suitable in this place, what other parts of the world

139
00:10:38,680 --> 00:10:41,560
have had success with this type of crop.

140
00:10:41,560 --> 00:10:46,120
What are the environmental conditions that make one type of crop versus another?

141
00:10:46,120 --> 00:10:51,200
So basically, one example is, what should I do with this land?

142
00:10:51,200 --> 00:10:52,680
Six months, one year.

143
00:10:52,680 --> 00:10:57,960
Another example is, well, if you've been producing a certain type of crop and you're concerned

144
00:10:57,960 --> 00:11:04,560
about the trends in production of that crop in other parts of the world, let's say you're

145
00:11:04,560 --> 00:11:10,600
a coffee producer from Vietnam, which is a very large coffee producer, and you're worried

146
00:11:10,600 --> 00:11:16,720
about oversupply or shortages, well, you should be able to quickly analyze what's going

147
00:11:16,720 --> 00:11:21,560
on in Brazil, even though you're in Vietnam, because you're essentially working on the

148
00:11:21,560 --> 00:11:24,000
same commodity.

149
00:11:24,000 --> 00:11:28,320
So that type of decision, you know, you say, well, will the production this year be greater

150
00:11:28,320 --> 00:11:30,640
than expected, less than expected?

151
00:11:30,640 --> 00:11:33,160
What's the weather like in the different producing countries?

152
00:11:33,160 --> 00:11:35,200
What are the expected yields?

153
00:11:35,200 --> 00:11:41,560
So those types of decisions in terms of what crops to plant, how much to expect in terms

154
00:11:41,560 --> 00:11:47,840
of supply and demand are another category, and then going on down the line, you know,

155
00:11:47,840 --> 00:11:53,480
you could be, let's say, a food processor and you're buying a wholesale wheat, let's say

156
00:11:53,480 --> 00:11:58,640
from corn, and you want to know where to buy it from, and maybe you're importing it from

157
00:11:58,640 --> 00:12:03,040
different places, so you want to predict which countries or which parts of the world

158
00:12:03,040 --> 00:12:12,000
will have shortages or excess supply, that's another example, or, you know, in continuing

159
00:12:12,000 --> 00:12:15,960
in other domains, you could have a financial application where you're, let's say, lending

160
00:12:15,960 --> 00:12:22,280
money to farmers, so if you want to know the probability that these loans will become

161
00:12:22,280 --> 00:12:27,440
delinquent, and that means you need to understand, you know, the environment and what the climate

162
00:12:27,440 --> 00:12:32,360
is doing to the farmers, and the probability that their crops will fail, for example,

163
00:12:32,360 --> 00:12:36,200
or that they will be a drought, or things like that, or that they're on the contrary,

164
00:12:36,200 --> 00:12:40,000
that there will be a huge production, and then the prices will be low.

165
00:12:40,000 --> 00:12:44,080
So all these things obviously affect the livelihood of the farmer, and therefore, as a lender,

166
00:12:44,080 --> 00:12:48,280
you would want to know the probability of those things, whether you're, or even if you're

167
00:12:48,280 --> 00:12:53,440
providing insurance, crop insurance, and you could be a bank, you could be a government,

168
00:12:53,440 --> 00:12:57,440
you could be all kinds of different entities that deal with that.

169
00:12:57,440 --> 00:13:02,440
So, yeah, there's a long list and another macro type of decision that we enable is, you

170
00:13:02,440 --> 00:13:07,600
know, impacts of diseases, you know, that I mentioned swine flu, this was a big topic

171
00:13:07,600 --> 00:13:12,560
in the world of agriculture last year, there is aflatoxins, there's like all kinds of

172
00:13:12,560 --> 00:13:18,080
different pests and diseases and things that affect crops that are affected by weather

173
00:13:18,080 --> 00:13:23,560
and climate, so, or the locust that you mentioned is also, you know, it's a typical phenomenon,

174
00:13:23,560 --> 00:13:28,800
but the intensity depends on weather, so if you wanted to know that it was going to be

175
00:13:28,800 --> 00:13:33,760
more severe or less severe than usual, those are the types of decisions that we would

176
00:13:33,760 --> 00:13:34,760
help you make.

177
00:13:34,760 --> 00:13:41,080
And now you started with talking about kind of macro level land use and how that's different

178
00:13:41,080 --> 00:13:43,160
from the precision egg.

179
00:13:43,160 --> 00:13:50,960
Are you, does that, is implication in part that you're less worried about the actual

180
00:13:50,960 --> 00:13:56,000
land itself, like it's clear that a big part of what you do is like market analytics,

181
00:13:56,000 --> 00:14:01,800
if you will, and like thing entire like supply chain of agriculture and different forces

182
00:14:01,800 --> 00:14:07,200
that play there, but are you also looking at the nutrients in a kind of macro plot of

183
00:14:07,200 --> 00:14:10,000
land, or is that all left to like the precision egg piece?

184
00:14:10,000 --> 00:14:15,080
No, no, that's really important actually, yeah, even on, so for example, let's say you're

185
00:14:15,080 --> 00:14:21,920
trying to understand if there's a shortage of one crop, how much will people substitute,

186
00:14:21,920 --> 00:14:25,560
how much substitution would there be in another crop, right?

187
00:14:25,560 --> 00:14:30,120
And a big part of that equation is understanding the content of it.

188
00:14:30,120 --> 00:14:37,920
So for example, we don't just try to predict the how much wheat will be produced, but

189
00:14:37,920 --> 00:14:42,240
we try to predict how much certain types of wheat would be produced because they have

190
00:14:42,240 --> 00:14:48,280
different protein content, and that affects a lot of things, everything from how much

191
00:14:48,280 --> 00:14:54,600
will be consumed for different uses, and as well as what the prices will be for different

192
00:14:54,600 --> 00:14:56,200
categories of things.

193
00:14:56,200 --> 00:15:02,640
So yeah, protein content or calorie content of different crops are, is a huge part of it.

194
00:15:02,640 --> 00:15:08,920
Also things like, you know, if what's the trade off between, I'll give you an example,

195
00:15:08,920 --> 00:15:16,520
I mentioned the swine flu, so that's a disease that's been affecting the pigs in China,

196
00:15:16,520 --> 00:15:22,520
and it's a huge deal because that's the main type of meat that's consumed there.

197
00:15:22,520 --> 00:15:26,960
Well you might want to know, well, okay, if there's suddenly a shortage of pork, would

198
00:15:26,960 --> 00:15:31,480
that translate into an increase in chicken demand, right?

199
00:15:31,480 --> 00:15:36,520
Because people, if pork becomes very expensive, maybe people will start eating more chicken.

200
00:15:36,520 --> 00:15:41,320
Now there's obviously many variables there, culture, and so on, but one of the key components

201
00:15:41,320 --> 00:15:43,480
is, well, how much nutrition do you get?

202
00:15:43,480 --> 00:15:48,800
Like what's the equivalent amount in terms of grams of protein between these two things?

203
00:15:48,800 --> 00:15:59,080
So the biology of plants and understanding the content is critical, even at the macro level.

204
00:15:59,080 --> 00:16:04,880
Now when I think about all of the problems that you just described, and then think about

205
00:16:04,880 --> 00:16:10,600
data that I might want to have access to in order to begin to try to solve these problems

206
00:16:10,600 --> 00:16:16,360
or, you know, provide some insights about them, you know, that seems huge, almost, you

207
00:16:16,360 --> 00:16:21,760
know, I don't want to be hyperbolic, but like infinite, like there's so much data that

208
00:16:21,760 --> 00:16:27,200
you could plug into or might want to plug into, you know, a system that solves these

209
00:16:27,200 --> 00:16:28,200
kind of problems.

210
00:16:28,200 --> 00:16:31,000
Like, what are your typical data sources?

211
00:16:31,000 --> 00:16:35,440
How do you approach data acquisition?

212
00:16:35,440 --> 00:16:36,440
That's a great question.

213
00:16:36,440 --> 00:16:39,600
So I think that, you know, just to cover the types of data.

214
00:16:39,600 --> 00:16:46,120
So the first thing people think of and, you know, that jumps to mind because it's visually

215
00:16:46,120 --> 00:16:50,360
important and quantity wise, it's important is satellite data.

216
00:16:50,360 --> 00:16:55,480
We have, you know, in terms of just sheer volume of data, that's the majority of our data,

217
00:16:55,480 --> 00:16:56,480
obviously.

218
00:16:56,480 --> 00:17:02,680
There's incredible amounts of information about every pixel on Earth, and it's not just

219
00:17:02,680 --> 00:17:08,760
images in terms of, you know, visual photography that as you, most people would imagine when

220
00:17:08,760 --> 00:17:15,040
you think of a satellite picture, some of it is infrared and ultraviolet and, you know,

221
00:17:15,040 --> 00:17:22,120
so different, all the entire frequency range of the electromagnetic spectrum has information

222
00:17:22,120 --> 00:17:24,520
about what's going on.

223
00:17:24,520 --> 00:17:30,960
So what happens is that you have different satellite hardware, which is, which is able to

224
00:17:30,960 --> 00:17:36,680
capture different bands of this electromagnetic signal is bouncing off the Earth.

225
00:17:36,680 --> 00:17:42,560
And from that, some of it is visible, so, you know, so, and some of it is not visible,

226
00:17:42,560 --> 00:17:47,520
but from that you can derive really complicated and very useful things.

227
00:17:47,520 --> 00:17:52,200
For example, you know, obviously you can derive temperature, which, well, maybe it's not

228
00:17:52,200 --> 00:17:56,520
so obvious, like how can a satellite that's way up in orbit know what's the temperature

229
00:17:56,520 --> 00:18:03,160
on the ground, but it looks at various signals bouncing off the Earth, and, you know, there's

230
00:18:03,160 --> 00:18:07,520
a well-established science that says, okay, but, you know, we fit a mathematical model

231
00:18:07,520 --> 00:18:13,320
around that, and we can determine based on the electromagnetic signature, what is the

232
00:18:13,320 --> 00:18:16,320
temperature at this, on each point on Earth.

233
00:18:16,320 --> 00:18:21,840
Similar to how, you know, you can look at a planet or a star and figure out its chemical

234
00:18:21,840 --> 00:18:27,840
composition just by looking at the electromagnetic signals that come out of it, we can do the

235
00:18:27,840 --> 00:18:29,480
same thing with the Earth.

236
00:18:29,480 --> 00:18:36,000
So it's temperature, rainfall, you know, including microwave signals, so you can get an idea

237
00:18:36,000 --> 00:18:40,440
of what kind of clouds there, how much rain is there, and how much humidity is coming out

238
00:18:40,440 --> 00:18:42,000
of the ground and so on.

239
00:18:42,000 --> 00:18:46,960
So you can estimate temperature, rainfall are more complicated things like evapotranspiration,

240
00:18:46,960 --> 00:18:49,640
which is an extremely important signal.

241
00:18:49,640 --> 00:18:56,600
It tells us how much, as the name implies, how much water is being released into the atmosphere

242
00:18:56,600 --> 00:19:01,120
from the transpiration or like sweating of plants.

243
00:19:01,120 --> 00:19:07,920
That's a really important indicator of plant health, and similarly, there's another signal

244
00:19:07,920 --> 00:19:13,360
called vegetation index, so again, looking at just the colors and the infrared signals,

245
00:19:13,360 --> 00:19:20,400
the red and green and infrared, you can determine how much biomass there is, like how much

246
00:19:20,400 --> 00:19:24,160
living matter there is in the flesh of these plants.

247
00:19:24,160 --> 00:19:28,520
That's also an extremely important signal, and you can get this information from satellites

248
00:19:28,520 --> 00:19:33,120
at an individual pixel level and covering almost the entire world.

249
00:19:33,120 --> 00:19:37,880
So there's enormous amounts of data that's from satellites, and that's, yeah.

250
00:19:37,880 --> 00:19:46,640
That's rapidly changing, and probably the biggest part in terms of volume, not probably.

251
00:19:46,640 --> 00:19:52,920
It's way more than half of our data, but in terms of importance, and this is a key point

252
00:19:52,920 --> 00:19:59,760
for us, is that, well, the economic data and social data is all equally important.

253
00:19:59,760 --> 00:20:08,360
So prices, for example, or commodity prices, or retail prices, or production, quantity,

254
00:20:08,360 --> 00:20:14,520
or yield, historical yields, or how much fertilizer has been used in one place or another.

255
00:20:14,520 --> 00:20:18,440
What is the cost of transportation from one place to another?

256
00:20:18,440 --> 00:20:25,000
All of these things fit together to enable people to answer these complex questions, typically

257
00:20:25,000 --> 00:20:30,680
involve climate, weather, economics, and that society.

258
00:20:30,680 --> 00:20:37,200
Even within economic and social, you've got wildly disparate data types.

259
00:20:37,200 --> 00:20:42,640
You've got an imagining time series data that you need to deal with, as well as documents

260
00:20:42,640 --> 00:20:47,440
that are best considered from an NLP type of perspective.

261
00:20:47,440 --> 00:20:56,680
One of the challenges is just as a baseline, many countries, governments, and non-governmental

262
00:20:56,680 --> 00:21:01,840
organizations and companies have been collecting enormous amounts of just basic agricultural

263
00:21:01,840 --> 00:21:09,000
data, in some cases for a really long time, like the US Department of Agriculture, for example,

264
00:21:09,000 --> 00:21:16,520
has over 150 years of data on everything from the yields of every single crop in every

265
00:21:16,520 --> 00:21:24,320
single county in the United States, to the production, and how much area was planted,

266
00:21:24,320 --> 00:21:32,960
and the crop conditions, where they're healthy, unhealthy, what percentage of the corn in

267
00:21:32,960 --> 00:21:38,440
this particular county was considered good as of July 3rd of this year, for every year

268
00:21:38,440 --> 00:21:39,440
going back.

269
00:21:39,440 --> 00:21:44,680
So there's incredibly granular data that we're tapping into.

270
00:21:44,680 --> 00:21:49,400
And same thing, from the United Nations, from the World Bank, from all kinds of different

271
00:21:49,400 --> 00:21:53,040
organizations, academia.

272
00:21:53,040 --> 00:21:58,840
So besides the obvious satellite data, there's enormous, enormously amounts of ground-based

273
00:21:58,840 --> 00:22:00,520
data that have been collected.

274
00:22:00,520 --> 00:22:09,000
And as you mentioned, some of it is really organized nicely and has modern APIs, let's

275
00:22:09,000 --> 00:22:12,920
say for exchange rates, we have excellent APIs, and we're not reinventing the wheel, you

276
00:22:12,920 --> 00:22:16,840
can figure out, you can get currency exchange rates in a really good way.

277
00:22:16,840 --> 00:22:23,120
But in some cases, it's obscure data sets that were typed up 75 years ago, and now exist

278
00:22:23,120 --> 00:22:29,080
as some text that's been scanned into an image, and then the image has been put into a PDF,

279
00:22:29,080 --> 00:22:37,120
and maybe it's in a different language, so you would have to do a combination of OCR, optical

280
00:22:37,120 --> 00:22:43,480
character recognition to extract the text from the images, and then do MLT to interpret that

281
00:22:43,480 --> 00:22:48,480
text and then extract structured data at the end of the day from that, which could be

282
00:22:48,480 --> 00:22:51,360
yields, for example.

283
00:22:51,360 --> 00:22:56,280
So the data itself is often a big part of the challenge.

284
00:22:56,280 --> 00:23:01,800
We probably could spend a whole hour talking about the data, but let's maybe take a step

285
00:23:01,800 --> 00:23:06,880
back and contextualize this by looking at the types of problems you solve.

286
00:23:06,880 --> 00:23:14,000
So we've talked about this from an end user perspective, but are there, do you approach

287
00:23:14,000 --> 00:23:20,960
each of the problems that your customers are looking to solve as kind of one-offs,

288
00:23:20,960 --> 00:23:27,920
like do you do consulting, or do you have specific categories of products that you offer,

289
00:23:27,920 --> 00:23:30,680
and most of the work you do kind of falls into different types?

290
00:23:30,680 --> 00:23:32,680
Yeah, and on a great question.

291
00:23:32,680 --> 00:23:39,200
So the first point, I think, is that we're offering a platform, so everything we do,

292
00:23:39,200 --> 00:23:46,280
as much as possible, except for some rare exceptions, everything we do, we attempt to really

293
00:23:46,280 --> 00:23:52,560
productize it and make it scalable and make it available to all our users, and we're

294
00:23:52,560 --> 00:23:56,720
going to talk a lot about machine learning and AI, but I think one important point is

295
00:23:56,720 --> 00:24:04,120
that we offer a platform where people can access all of this data in a highly organized

296
00:24:04,120 --> 00:24:11,360
way, and then they can access it visually through a web application or through an API,

297
00:24:11,360 --> 00:24:14,720
and we expect our customers to also build their models.

298
00:24:14,720 --> 00:24:19,760
So in a way, we're providing sort of this platform that gives you access to a normal wealth

299
00:24:19,760 --> 00:24:27,520
of data, enormous wealth of data, creating value by deriving data on top of these existing

300
00:24:27,520 --> 00:24:33,640
data sets, but also making you able to access it in a really organized way.

301
00:24:33,640 --> 00:24:43,880
So one of the applications that we have for AI is we've structured this information into

302
00:24:43,880 --> 00:24:49,120
a knowledge graph, so we have what some people call an ontology.

303
00:24:49,120 --> 00:24:54,720
So we have the grow ontology, which organizes data from hundreds and hundreds of different

304
00:24:54,720 --> 00:25:01,400
sources into a common language, so if we're talking about wheat, and there's many dozens

305
00:25:01,400 --> 00:25:07,640
of varieties of wheat, you know that a bit of data from one source that tells you maybe

306
00:25:07,640 --> 00:25:12,040
the protein content of wheat, and then another source that tells you the price of wheat,

307
00:25:12,040 --> 00:25:16,040
well, we have to make sure that the specific type of wheat that these two things are talking

308
00:25:16,040 --> 00:25:18,360
about is the same item.

309
00:25:18,360 --> 00:25:27,360
So also organizing all of that information into a structured knowledge base or in the form

310
00:25:27,360 --> 00:25:34,280
of a knowledge graph that relates all of these entities is a key part, and then our users

311
00:25:34,280 --> 00:25:44,440
can use that through an API or a web app to find insights in the data, and in some cases

312
00:25:44,440 --> 00:25:53,120
we will do the extra work for them in terms of like building forecasting models, predicting

313
00:25:53,120 --> 00:25:58,400
things that the world is interested in and making that part of the platform as well.

314
00:25:58,400 --> 00:26:04,280
And so for the different types of modeling tasks and the machine learning applications,

315
00:26:04,280 --> 00:26:09,080
what are the types of problems that you're typically attacking?

316
00:26:09,080 --> 00:26:12,480
So roughly, I think there's four classes of problems.

317
00:26:12,480 --> 00:26:18,160
One that the first one is yields, agricultural yields, which is a hugely important.

318
00:26:18,160 --> 00:26:27,680
We've been now doing that for about a live in production for a little over three years.

319
00:26:27,680 --> 00:26:33,640
And so this is things like for the first example was, can you predict the yield of corn

320
00:26:33,640 --> 00:26:37,200
in the US in three years?

321
00:26:37,200 --> 00:26:47,800
So in February 2020, we already have a prediction of what the final yield of the US corn production

322
00:26:47,800 --> 00:26:53,200
will be, meaning how many bushels or how many tons of corn will be produced per acre

323
00:26:53,200 --> 00:26:58,760
on average across the United States, as well as down to every single county.

324
00:26:58,760 --> 00:27:04,800
Now we're in February, so nothing has been planted yet, so we have a model that's based

325
00:27:04,800 --> 00:27:10,880
on historical trends, but as the season progresses and we get into March and April and things

326
00:27:10,880 --> 00:27:18,520
are getting planted and they're starting to grow and we see the weather, our prediction

327
00:27:18,520 --> 00:27:20,880
gets constantly refined.

328
00:27:20,880 --> 00:27:25,200
So when we say yield models, basically telling you what everybody will, the conclusion

329
00:27:25,200 --> 00:27:31,720
that we will reach a year from now, meaning how good was the corn yield in the US in 2020,

330
00:27:31,720 --> 00:27:35,280
we're constantly estimating that through a yield model.

331
00:27:35,280 --> 00:27:40,440
So if you log into our product every day, whatever little bit of information comes from the

332
00:27:40,440 --> 00:27:46,880
world that would help us better forecast the US corn yield will be incorporated and this

333
00:27:46,880 --> 00:27:53,680
is fully productized so that there is an answer updating itself every day.

334
00:27:53,680 --> 00:27:58,800
So while this is interesting, obviously people have been concerned with US corn yields for

335
00:27:58,800 --> 00:28:05,360
a really long time, but traditionally it's been done through very slow processes where

336
00:28:05,360 --> 00:28:12,800
there's a lot of human and subjective elements and maybe you'll have official updates on

337
00:28:12,800 --> 00:28:17,480
this year's forecast will be updated maybe once and once throughout the course of the year.

338
00:28:17,480 --> 00:28:22,360
So we're saying that we'll make that completely objective, automate it and do it every day.

339
00:28:22,360 --> 00:28:28,360
So we did that for corn in the US and started out putting our predictions in real time

340
00:28:28,360 --> 00:28:36,800
and it proved to be enormously successful in 2017, 18, 19, then those seasons are we correctly

341
00:28:36,800 --> 00:28:45,040
anticipated the final result or in several instances before the market or any other forecast

342
00:28:45,040 --> 00:28:51,480
or the traditional forecast had detected them and when the truth finally came out in terms

343
00:28:51,480 --> 00:28:58,240
of when at the end of the season when the full crop was realized in each time we'd sort

344
00:28:58,240 --> 00:29:03,520
of been out on a limb and predicting something unusual, it turns out we were right ahead of

345
00:29:03,520 --> 00:29:04,520
the curve.

346
00:29:04,520 --> 00:29:09,880
So that was an enormous success so that's yields and then we've done that now 10 times.

347
00:29:09,880 --> 00:29:19,640
We did it for corn in the US, soybeans in the US, in Argentina and in Brazil, wheat in

348
00:29:19,640 --> 00:29:25,480
India, in Russia, in Ukraine and corn in China as well.

349
00:29:25,480 --> 00:29:30,680
So again, a number of different cases where we've managed to build really good yield models

350
00:29:30,680 --> 00:29:37,280
that are sort of the state of the art and have been able to predict real world events before

351
00:29:37,280 --> 00:29:38,840
anybody else was.

352
00:29:38,840 --> 00:29:45,720
So that's been one area of huge success yields and in each case, like I said, our customers

353
00:29:45,720 --> 00:29:50,440
would also look at maybe they'll look at, you know, bananas and Ecuador tomorrow and

354
00:29:50,440 --> 00:29:55,440
we may not have already built a model for that particular case but we've shown a general

355
00:29:55,440 --> 00:30:00,480
framework that applies to many crops across the whole world and more importantly we're

356
00:30:00,480 --> 00:30:06,640
providing you all of the data so that you can use our models and use our outputs or you

357
00:30:06,640 --> 00:30:14,920
can also use the data and produce predictions of your own if it happens to be a series

358
00:30:14,920 --> 00:30:17,840
that we are not explicitly forecasting.

359
00:30:17,840 --> 00:30:21,720
So that's yield and well, before I move on to the second area, one thing I want to say

360
00:30:21,720 --> 00:30:25,760
is we were very strategic about what we choose to model.

361
00:30:25,760 --> 00:30:31,160
So as in, for example, in the yield case, you know, I gave you a bunch of examples.

362
00:30:31,160 --> 00:30:35,160
Each one sort of pushes the envelope in a new interesting way.

363
00:30:35,160 --> 00:30:46,920
So for example, compared to the US, let's say one of the key pieces when we started modeling

364
00:30:46,920 --> 00:30:52,760
wheat in India as well, a big difference is in the US, you know, most of the heartland,

365
00:30:52,760 --> 00:30:58,240
the corn belt or the wheat belt and so on, especially corn is concentrated in the Midwest.

366
00:30:58,240 --> 00:31:04,480
So even though it's a huge area, the climate in the major producing areas doesn't change

367
00:31:04,480 --> 00:31:05,960
that much.

368
00:31:05,960 --> 00:31:12,240
So, but then you go to India and you say, okay, India produces a lot of wheat, but it's

369
00:31:12,240 --> 00:31:15,960
planted all over the country from the north to the south.

370
00:31:15,960 --> 00:31:22,640
So it's actually a key technical challenge that this new example introduced is that, well,

371
00:31:22,640 --> 00:31:29,720
how do you do accurate crop masks, you know, how do you model the effect, you know, when

372
00:31:29,720 --> 00:31:35,560
it's a wide range of latitudes from north to south and the climate is very different.

373
00:31:35,560 --> 00:31:39,800
And then the second piece there is, unlike the US, you know, the farms tend to be really

374
00:31:39,800 --> 00:31:41,120
small.

375
00:31:41,120 --> 00:31:49,400
So figuring out, you know, which points have wheat versus rice versus corn and so on or

376
00:31:49,400 --> 00:31:53,880
just forest and, you know, other things is much more difficult in India.

377
00:31:53,880 --> 00:31:58,960
So just all that to say that each of these examples is sort of pushes the technical envelope

378
00:31:58,960 --> 00:31:59,960
in a different way.

379
00:31:59,960 --> 00:32:06,400
And so that was, and so yield is that that's one big area where we've done a lot of work

380
00:32:06,400 --> 00:32:12,840
and if you go to our website, we've published a bunch of papers on that and in our products

381
00:32:12,840 --> 00:32:19,760
where, like I said, you know, these forecasts are there on a daily basis fully automated.

382
00:32:19,760 --> 00:32:29,440
The second area, fairly closely related is crop masking, so that is a key piece of yields,

383
00:32:29,440 --> 00:32:32,960
but it's yield forecasting, but it's its own problems.

384
00:32:32,960 --> 00:32:40,080
It's basically looking at satellite imagery as I described before, not just visible, but

385
00:32:40,080 --> 00:32:43,920
all the whole spectrum across time.

386
00:32:43,920 --> 00:32:52,640
We try to predict what is or ought to figure out what is going on in each pixel in terms

387
00:32:52,640 --> 00:32:59,680
of is there wheat being planted, is there sugar, is it bananas, is it coffee, is it what

388
00:32:59,680 --> 00:33:00,680
the crop is.

389
00:33:00,680 --> 00:33:05,600
And this is extremely important and we do that by looking and that's called crop masking.

390
00:33:05,600 --> 00:33:10,960
So it's an important point because by itself, it's a really useful bit of information

391
00:33:10,960 --> 00:33:11,960
to have.

392
00:33:11,960 --> 00:33:15,640
You're essentially trying to label each pixel with a crop?

393
00:33:15,640 --> 00:33:16,640
Yeah.

394
00:33:16,640 --> 00:33:23,480
And what makes it complicated is that, well, first of all, a lot of crops look the same

395
00:33:23,480 --> 00:33:29,720
in terms of, so you use things of how they evolve over time, you know, if it peaks in,

396
00:33:29,720 --> 00:33:34,520
you know, if a certain signal peaks in July versus it peaks in August, then it tells you

397
00:33:34,520 --> 00:33:40,520
whether it's this crop or that plant, this other crop.

398
00:33:40,520 --> 00:33:46,360
But yeah, so we're trying to map the figure and then secondly, is that if you could assume

399
00:33:46,360 --> 00:33:52,600
it's all constant, then it's a fairly well solved problem, you know, you could, but the problem

400
00:33:52,600 --> 00:33:54,560
is, you know, the world is dynamic.

401
00:33:54,560 --> 00:33:59,160
So even in the same form, there's such a, there's a thing called crop rotation where

402
00:33:59,160 --> 00:34:03,840
people, for various reasons, will plant different things every year and sometimes it will be

403
00:34:03,840 --> 00:34:09,240
a predictable cycle or sometimes it's driven by the weather and sometimes it's driven by

404
00:34:09,240 --> 00:34:10,520
market conditions.

405
00:34:10,520 --> 00:34:15,560
So that happens a lot in the US with corn and soy, for example, the same farmer could

406
00:34:15,560 --> 00:34:19,040
choose to use this land for corn or use it for soybeans.

407
00:34:19,040 --> 00:34:25,360
So if you're trying to predict the corn yield of this year, 2020, knowing which pixels are

408
00:34:25,360 --> 00:34:31,640
corn and which pixels are soybeans, obviously has a huge impact because when you then apply

409
00:34:31,640 --> 00:34:35,640
the other signals, let's say the temperature, you know, you need to know, am I looking at

410
00:34:35,640 --> 00:34:39,800
a temperature in a spot where there's corn or am I looking at a temperature in a spot

411
00:34:39,800 --> 00:34:43,640
where there is soy beans because we will have a different effect.

412
00:34:43,640 --> 00:34:49,200
So crop masking is its own problem, even though it's an important input to yield, it's its

413
00:34:49,200 --> 00:34:55,480
own huge problem and so that's a big area where we're doing a lot of work in and that's

414
00:34:55,480 --> 00:34:57,480
a different type of machine learning.

415
00:34:57,480 --> 00:35:05,040
So yields that I mentioned before is you often using regression methods, whereas crop masking

416
00:35:05,040 --> 00:35:15,960
is heavy on image processing and in season crop masking is a combination of, you know,

417
00:35:15,960 --> 00:35:22,640
these image cubes of the same place over time, you apply with neural network techniques

418
00:35:22,640 --> 00:35:29,120
applied to it, help you make a much better guess than otherwise in terms of what each pixel

419
00:35:29,120 --> 00:35:30,120
is.

420
00:35:30,120 --> 00:35:36,080
So that's so crop masking is another example and that one is uses a lot of image processing.

421
00:35:36,080 --> 00:35:41,760
A third example of a class of problems we work on is droughts.

422
00:35:41,760 --> 00:35:49,040
That's very similar to yields, but for different applications that predicting droughts, there

423
00:35:49,040 --> 00:35:56,320
are standard international classifications of, and these are discrete classifications.

424
00:35:56,320 --> 00:36:02,120
This is a drought of level one or level two, level three, you know, these are the correspond

425
00:36:02,120 --> 00:36:06,880
to severities kind of like you have hurricanes, severities and so on.

426
00:36:06,880 --> 00:36:14,240
So unfortunately, the world doesn't have a single, automated, fully objective way to

427
00:36:14,240 --> 00:36:19,280
classify the entire world and say, okay, is there a drought, yes or no, how intense is

428
00:36:19,280 --> 00:36:20,280
it?

429
00:36:20,280 --> 00:36:26,280
Is it a one, two, three, four, five, or zero, or, you know, meaning it's totally normal.

430
00:36:26,280 --> 00:36:30,760
So what we're trying to do, but there is some manual processes that have been developed

431
00:36:30,760 --> 00:36:37,000
over time, historically, for example, governments like the US government will pay or many governments

432
00:36:37,000 --> 00:36:41,880
will pay farmers if there is a drought, it's a, you know, drought insurance.

433
00:36:41,880 --> 00:36:48,320
So that type of stuff, you know, is very inefficient because there isn't a single benchmark.

434
00:36:48,320 --> 00:36:54,840
So we're trying to create a completely objective drought index that the entire world can agree

435
00:36:54,840 --> 00:37:03,800
on and it applies for every place in the world, takes into account all the weather and environmental

436
00:37:03,800 --> 00:37:10,720
signals and produces a consistent labeling, you know, drought severity.

437
00:37:10,720 --> 00:37:17,520
And so that's an interesting class of problems that we're working on.

438
00:37:17,520 --> 00:37:23,720
And the fourth category that I haven't mentioned yet is a completely different type of problem,

439
00:37:23,720 --> 00:37:28,560
which is the knowledge graph automation.

440
00:37:28,560 --> 00:37:34,960
So as I mentioned, you know, we bring in data from, you know, dozens and dozens of sources

441
00:37:34,960 --> 00:37:41,520
all the time and we want to organize that into a common ontology so that if we have some

442
00:37:41,520 --> 00:37:45,480
data, like I mentioned about corn, we know it's about corn.

443
00:37:45,480 --> 00:37:50,360
If it's yellow corn, we know it's about yellow corn, et cetera, or we know if it's temperature

444
00:37:50,360 --> 00:37:56,240
on the ground versus temperature, you know, on the land surface versus temperature, you

445
00:37:56,240 --> 00:38:01,400
know, in a weather station, a couple of meters above ground, it's a totally different concept

446
00:38:01,400 --> 00:38:04,120
like the temperature of the ground and the temperature of the air.

447
00:38:04,120 --> 00:38:09,160
So we, you know, our system has to know what exactly you mean by temperature.

448
00:38:09,160 --> 00:38:13,280
So this means it's highly, highly structured.

449
00:38:13,280 --> 00:38:18,760
That means all these data that come from outside sources have to be mapped and transformed

450
00:38:18,760 --> 00:38:24,920
into this common structure so that we're referring to the same entities.

451
00:38:24,920 --> 00:38:32,160
And that, as, you know, we're growing exponentially, we currently have about 55 million data series

452
00:38:32,160 --> 00:38:37,480
a little over that in our platform and it's doubling every six to nine months.

453
00:38:37,480 --> 00:38:44,280
So one of the key pieces is that, you know, we want to be really accurate but also efficient

454
00:38:44,280 --> 00:38:50,480
about mapping, you know, outside knowledge into our internal knowledge graph.

455
00:38:50,480 --> 00:38:56,640
So that means we have a whole class of problems related to knowledge graph automation.

456
00:38:56,640 --> 00:39:07,680
So that involves graph algorithms and NLP and, you know, slightly less structured neural

457
00:39:07,680 --> 00:39:09,400
network approaches and so on.

458
00:39:09,400 --> 00:39:16,400
That will help us, you say, when we have a source that says, you know, if some of it is just

459
00:39:16,400 --> 00:39:22,760
plain language translation as well, but it's really understanding that, hey, if we have

460
00:39:22,760 --> 00:39:30,560
a Vietnamese data series that talks about, you know, the yields of rice and there's three

461
00:39:30,560 --> 00:39:36,120
varieties of rice, it's really important that, you know, we map that correctly into the

462
00:39:36,120 --> 00:39:41,200
items that we call these three or 10 varieties of rice and making sure that, you know, the

463
00:39:41,200 --> 00:39:45,640
Vietnamese word and the English word, you know, are referring to the same thing.

464
00:39:45,640 --> 00:39:46,640
Right.

465
00:39:46,640 --> 00:39:51,080
So in addition to any models that you're using to kind of extract the data, for example,

466
00:39:51,080 --> 00:39:59,440
you talked about pulling tab your data from PDFs, you're also using models to kind of

467
00:39:59,440 --> 00:40:06,880
dynamically update the way data is kind of ingested into this knowledge graph and how it's

468
00:40:06,880 --> 00:40:08,960
labeled and things like that.

469
00:40:08,960 --> 00:40:09,960
Exactly.

470
00:40:09,960 --> 00:40:10,960
Exactly.

471
00:40:10,960 --> 00:40:15,880
So the knowledge graph, you can think of it as the knowledge graph is sort of the foundation

472
00:40:15,880 --> 00:40:19,240
and then using that knowledge graph, we map stuff.

473
00:40:19,240 --> 00:40:25,400
So and we automatically try to learn what the description of things that come from outside

474
00:40:25,400 --> 00:40:31,600
and map that into our into our ontology so that, but this part, by the way, I think is

475
00:40:31,600 --> 00:40:37,840
an important thing to note is we, you know, AI will help us get 80, 90% of the way there,

476
00:40:37,840 --> 00:40:44,680
but we still have human beings really review and understand these things so that if our

477
00:40:44,680 --> 00:40:50,640
knowledge graph automation says that, oh, a maze is the same thing as corn, well, there's

478
00:40:50,640 --> 00:40:57,200
still going to be, you know, unless it's like 99.99% confidence, there will still be a

479
00:40:57,200 --> 00:41:01,440
human who says, is really is a maze really the same thing as corn, yes, it makes sense

480
00:41:01,440 --> 00:41:02,440
and proves that.

481
00:41:02,440 --> 00:41:07,560
Well, it's a lot easier to fix those problems before you pollute the pool, so to speak,

482
00:41:07,560 --> 00:41:11,920
when you have, was it say, 55 million data series that you're mapping?

483
00:41:11,920 --> 00:41:12,920
Yeah, exactly.

484
00:41:12,920 --> 00:41:13,920
Exactly.

485
00:41:13,920 --> 00:41:20,000
So I think the, sometimes, and those, the way the data comes in from outside, sometimes

486
00:41:20,000 --> 00:41:26,600
it's not clear if, or, you know, the, the, the, not every source has a cleanly organized

487
00:41:26,600 --> 00:41:32,880
way of representing how, what something is versus how it's measured and things like that.

488
00:41:32,880 --> 00:41:38,560
So yeah, so yeah, that's, that's, we're creating the, the transformation instruction set,

489
00:41:38,560 --> 00:41:41,760
if you will, through AI.

490
00:41:41,760 --> 00:41:48,120
Speaking about kind of that quality of that data set that you're working with, how do

491
00:41:48,120 --> 00:41:54,520
you try to account for noise or missing values in the data that you collect?

492
00:41:54,520 --> 00:41:55,520
Do you try?

493
00:41:55,520 --> 00:41:59,400
Do you kind of have a principle that says, we're just going to record what we're given?

494
00:41:59,400 --> 00:42:02,280
Or do you try to correct it on ingest?

495
00:42:02,280 --> 00:42:03,440
What's your approach there?

496
00:42:03,440 --> 00:42:05,000
Yeah, no, great question.

497
00:42:05,000 --> 00:42:12,440
So I think that, for us, reproducibility and attribution is really, really important.

498
00:42:12,440 --> 00:42:16,880
So at the bottom layer, you know, or I should say that the first layer in our platform

499
00:42:16,880 --> 00:42:24,440
after the data has been transformed, the values that we, we have are can be directly traced

500
00:42:24,440 --> 00:42:27,760
to, to where it came from.

501
00:42:27,760 --> 00:42:34,320
So if we say, you know, the MDVI of, you know, the meaning of the amount of vegetation in

502
00:42:34,320 --> 00:42:41,360
this particular pixel is, you know, 0.5 or whatever, like then, then, then, we'll have

503
00:42:41,360 --> 00:42:43,480
that value where it came from.

504
00:42:43,480 --> 00:42:48,240
If the source revised it, we'll also annotate that and say, okay, this was the yesterday

505
00:42:48,240 --> 00:42:52,080
they said it was this much and then today they revised it to this much and this applies

506
00:42:52,080 --> 00:42:58,960
to, you know, economic data as well as satellite data, you know, hardware or changes or algorithm

507
00:42:58,960 --> 00:42:59,960
changes.

508
00:42:59,960 --> 00:43:06,600
So, and so even after transformation, we always have the original value and we annotate it

509
00:43:06,600 --> 00:43:10,640
with things like when it was reported, when it was revised, etc.

510
00:43:10,640 --> 00:43:16,800
So all our data series are actually three-dimensional in the sense that there's the value, there's

511
00:43:16,800 --> 00:43:21,560
the time and then there's also the potential revisions that could have occurred in the past

512
00:43:21,560 --> 00:43:25,200
on that particular point.

513
00:43:25,200 --> 00:43:28,600
And that, that's really, really important when, especially when you're dealing with things

514
00:43:28,600 --> 00:43:32,360
like estimates or forecasts and so on.

515
00:43:32,360 --> 00:43:37,760
And then, like, and of course, it's very important because we don't know in advance every single

516
00:43:37,760 --> 00:43:42,240
use case that people will be using it. So if you've, if you've done some analysis and

517
00:43:42,240 --> 00:43:47,000
then the data changes because the source made some corrections, it's really important

518
00:43:47,000 --> 00:43:52,280
that you can, as a user, you can totally see why that happened and where it came from.

519
00:43:52,280 --> 00:43:58,760
That said, on top of that, we add, so we do a bunch of things.

520
00:43:58,760 --> 00:44:04,760
One is that, as I mentioned, you know, we build models, so we create brand new data that

521
00:44:04,760 --> 00:44:10,360
are forecasts and predictions and so on from the existing data and those are available in

522
00:44:10,360 --> 00:44:13,880
the data in the platform, just like other things.

523
00:44:13,880 --> 00:44:18,040
So as I mentioned, the yield and the drought index and all these things that I mentioned.

524
00:44:18,040 --> 00:44:26,840
We also do a lot of grow derived, which is grow derived data series, which are like basic

525
00:44:26,840 --> 00:44:33,520
operations that combine data from multiple sources.

526
00:44:33,520 --> 00:44:41,280
So for example, you know, you may have a trivial example would be, you know, we have population

527
00:44:41,280 --> 00:44:45,440
data from, let's say, the World Bank about every country in the world and how it's growing

528
00:44:45,440 --> 00:44:48,560
and including projecting it into the future.

529
00:44:48,560 --> 00:44:53,800
And then you have consumption data, let's say, from some other organization or then, you

530
00:44:53,800 --> 00:44:58,480
know, and well, if you join those two, you can get per capita consumption, which, you

531
00:44:58,480 --> 00:45:01,960
know, so you get some data from one source, some data from another source.

532
00:45:01,960 --> 00:45:06,400
You combine them and you create a new data series that's of independent interest.

533
00:45:06,400 --> 00:45:10,880
So that's, so we do a lot of those types of things as well.

534
00:45:10,880 --> 00:45:14,960
And then finally, I think the most basic answer to your question, though, is that, you

535
00:45:14,960 --> 00:45:21,480
know, we try, if something is fundamentally difficult data, we often try to get multiple

536
00:45:21,480 --> 00:45:22,480
sources.

537
00:45:22,480 --> 00:45:28,840
So if you go into our product and you say, how much sugar was produced in Brazil last

538
00:45:28,840 --> 00:45:33,920
year or even, you know, last month, you use probably five different sources that will

539
00:45:33,920 --> 00:45:38,320
tell you that we have that, give you that number and, you know, they might differ by a few

540
00:45:38,320 --> 00:45:41,840
percent because we use different methodologies and so on.

541
00:45:41,840 --> 00:45:48,760
And you can, you can take them each individually or we can give you the average of them or we

542
00:45:48,760 --> 00:45:54,080
can give you what we've selected as sort of the best combination of things.

543
00:45:54,080 --> 00:46:01,360
So yeah, the answer is, you know, often you triangulate the truth from multiple sources.

544
00:46:01,360 --> 00:46:04,480
And that's often the big part of the value, right?

545
00:46:04,480 --> 00:46:10,840
You know, if you look at, especially these hugely important economic, hugely economically important

546
00:46:10,840 --> 00:46:15,160
commodities, you know, there's a lot of speculation and hidden information and so on.

547
00:46:15,160 --> 00:46:21,560
So a lot of the use cases are about getting the same information from multiple sources

548
00:46:21,560 --> 00:46:26,480
to get a better version of the truth and then building decisions on top of that.

549
00:46:26,480 --> 00:46:34,320
And with that, you know, the speculation and competition, even on a kind of nation state

550
00:46:34,320 --> 00:46:41,080
stage, do you worry about adversarial use cases or data poisoning or anything like that?

551
00:46:41,080 --> 00:46:47,840
Yeah, I mean, I think, I mean, we don't have any specific concerns, but it is the type

552
00:46:47,840 --> 00:46:52,240
of thing that each customer would have their own concerns. So we try to make sure that

553
00:46:52,240 --> 00:46:59,960
if there's, if there are multiple versions of the truth, we try to get all of them or

554
00:46:59,960 --> 00:47:08,640
all the relevant ones. So, but at the end, so I think at the end of the day, also satellites

555
00:47:08,640 --> 00:47:17,040
are, it's hard to lie to a satellite. Although it's possible, it's possible, you'd be amazed

556
00:47:17,040 --> 00:47:22,560
that are the adversarial things that can be done. But yeah, I think the, there is, there

557
00:47:22,560 --> 00:47:27,400
is no magic answer. It's trying to get the best possible information, the most objective

558
00:47:27,400 --> 00:47:36,280
possible sources and then make sure that it's interpreted and mapped and organized correctly.

559
00:47:36,280 --> 00:47:44,480
And then obviously, then when we do modeling, we spend an enormous amount of time backtesting,

560
00:47:44,480 --> 00:47:51,560
looking at historical data, looking at different algorithms. And I think this touches on another

561
00:47:51,560 --> 00:47:56,560
point, which is really important that we haven't discussed yet, is that we try to avoid black

562
00:47:56,560 --> 00:48:03,040
box models. If it's possible to predict something or forecast something with a model that

563
00:48:03,040 --> 00:48:11,760
has, you know, more explanatory power, slightly transparent model, we will, versus a black box

564
00:48:11,760 --> 00:48:17,600
model, we will prefer the former, all else being equal. So, for example, you know, we talked

565
00:48:17,600 --> 00:48:22,880
a lot about yield. If we say, well, the yield, we think the yield is going to be higher than

566
00:48:22,880 --> 00:48:27,840
expected this year, you know, all of a sudden, then we want to be able to say, well, the reason

567
00:48:27,840 --> 00:48:33,800
why our forecast is optimistic or whatever, or just change yesterday relative to today

568
00:48:33,800 --> 00:48:41,080
is because this signal moved, right? And that's a hugely important thing in terms of building

569
00:48:41,080 --> 00:48:46,120
confidence in the models, and also letting people use them in the real world. So, if you

570
00:48:46,120 --> 00:48:53,560
have a model that says, for example, the yield of soybeans in the US was dramatically

571
00:48:53,560 --> 00:48:59,720
affected by the temperature in November, and that doesn't make sense, like physically,

572
00:48:59,720 --> 00:49:03,840
because by November, all the soybeans have finished growing, and they should be, you

573
00:49:03,840 --> 00:49:08,120
know, harvested by that point, so that why would the temperature affect it physically

574
00:49:08,120 --> 00:49:12,200
biologically? So, our model is kind of, are not just black boxes where you just throw

575
00:49:12,200 --> 00:49:18,080
tons of data and see what comes out. It's really saying, like, well, we want the model

576
00:49:18,080 --> 00:49:23,800
to model reality and understand the signals that go in or signals that make sense from

577
00:49:23,800 --> 00:49:29,160
a process, physical point of view, and then we can also open the box and see what it's

578
00:49:29,160 --> 00:49:34,880
doing and understand it, and it makes sense from a biological and economic point of view.

579
00:49:34,880 --> 00:49:40,080
It certainly makes sense that all things being equal, you'd prefer the more explainable

580
00:49:40,080 --> 00:49:48,080
things, but often, all things aren't equal to find that you have specific use cases where

581
00:49:48,080 --> 00:49:54,200
the advantages, performance, or otherwise, lead you to use black box models.

582
00:49:54,200 --> 00:50:04,680
Yeah, so I think, yes. And, you know, then it's a trade-off, but, you know, we'll do whatever

583
00:50:04,680 --> 00:50:09,720
is the best trade-off. So, there are cases where it's a little bit black boxy and neural

584
00:50:09,720 --> 00:50:17,400
networky, but, like I mentioned, for example, the image processing and crop masking over

585
00:50:17,400 --> 00:50:27,280
time, you know, it could be, if it's sometimes you would be able to explain it, because let's

586
00:50:27,280 --> 00:50:31,480
say, you know, like I mentioned, there's rotation between crops, sometimes it's a very

587
00:50:31,480 --> 00:50:36,360
regular thing, you know, let's say, one year, you plan, sorry, one year, you plan corn

588
00:50:36,360 --> 00:50:41,360
and you add her. And so, if it's a very predictable pattern and that comes out of it, then you're

589
00:50:41,360 --> 00:50:48,200
like, oh, okay, that pattern was picked up. But, if it's much more, but sometimes in this

590
00:50:48,200 --> 00:50:54,800
case, this is an example of, we've tried both approaches, and there are cases where,

591
00:50:54,800 --> 00:51:00,280
I shouldn't say both, both classes of approaches, and there are some cases where, so we reach

592
00:51:00,280 --> 00:51:05,480
the limit. So, we went through a classical approach where it's not black box and we're

593
00:51:05,480 --> 00:51:11,640
explicitly modeling every single signal and looking at its temporal signature and saying,

594
00:51:11,640 --> 00:51:15,960
you know, when did it turn on, when did it turn off and try and to fit it into very specific

595
00:51:15,960 --> 00:51:21,880
models of behavior. So, we've done a really, we've gotten, we've gotten really great results,

596
00:51:21,880 --> 00:51:27,000
but sort of we got to the point where we want to go even further and get higher accuracy.

597
00:51:27,000 --> 00:51:35,080
And in that case, you have to take models with, you know, many thousands of, there are

598
00:51:35,080 --> 00:51:39,560
tens of thousands of signals, so you're not necessarily going to be able to interpret

599
00:51:39,560 --> 00:51:47,480
it every time. And do your models tend to be, you know, wide or monolithic types of models,

600
00:51:47,480 --> 00:51:53,400
or do you rely heavily on hierarchy and assembling and things like that?

601
00:51:53,400 --> 00:52:01,560
More of the latter. So, for example, when we work, so hierarchy, time scale hierarchy is

602
00:52:01,560 --> 00:52:07,880
really important because the nature of the, for example, let's go back to the yield example.

603
00:52:07,880 --> 00:52:13,560
If you look at the, and yield, by the way, is super important because that's the hard variable.

604
00:52:13,560 --> 00:52:20,200
If you ultimately care about how much food will be produced, but the amount produced is yield

605
00:52:20,200 --> 00:52:27,480
multiplied by area, right? So, the area is relatively easy to estimate. Again, there's parts of

606
00:52:27,480 --> 00:52:32,760
the world where that's hard too, but if the, but so the yield is the sort of the magic variable

607
00:52:32,760 --> 00:52:37,400
that everybody is paying attention to a lot because that's the one that changes year to year if it's

608
00:52:37,400 --> 00:52:43,000
too cold, too hot, et cetera. And so yields that are driven by two very different time scales.

609
00:52:43,640 --> 00:52:49,800
One is if you look at the yield over a hundred years, you'll see just dramatic improvements,

610
00:52:49,800 --> 00:52:55,080
you know, and depending on the crop, that curve will look like an exponential or a straight line

611
00:52:55,080 --> 00:52:59,800
or a sigmoid shape. It's kind of like how you have more's law in electronics. There's like,

612
00:53:00,360 --> 00:53:06,360
there's similar things happening in crops because people get better at breeding the right seeds and

613
00:53:06,360 --> 00:53:15,160
figuring out what seeds work where and things like irrigation comes in or pesticides or fertilizers.

614
00:53:15,160 --> 00:53:21,320
So, there's just long-term trends that are very important. So, that's the long-term trend model,

615
00:53:21,320 --> 00:53:27,560
and that's one time scale, but that will only give you the, that won't tell you what changed

616
00:53:27,560 --> 00:53:35,400
unexpectedly in 2020 or in 2019. So, so we do construct yield models explicitly as two levels.

617
00:53:35,400 --> 00:53:39,880
One is a long-term trend model that's saying even even on, you know, the first day of the year

618
00:53:39,880 --> 00:53:44,920
before a single seed has been planted, we already have an idea of where long-term

619
00:53:44,920 --> 00:53:49,640
progress should be, and it's different for every country and every crop. And then off of that

620
00:53:49,640 --> 00:53:54,200
baseline, so that, you know, that that by itself is valuable, right? Like you could just have long-term

621
00:53:54,200 --> 00:53:58,680
forecasts, I can say, okay, this is what it's going to be like, you know, in Germany in 2021,

622
00:53:58,680 --> 00:54:06,120
and in India or Pakistan in 2022, etc., you can have forecasts. But then the short, the intra-year

623
00:54:06,120 --> 00:54:10,920
part is saying, okay, what's going on this year? How much has been planted? What's what was the

624
00:54:10,920 --> 00:54:16,920
temperature, the time, you know, at different point, reason and so on? So the in-season model is

625
00:54:16,920 --> 00:54:22,760
taking a whole bunch of other daily and weekly and so on signals, whereas the long-term model is

626
00:54:22,760 --> 00:54:29,960
taking, you know, annual and historical trends. So, so yeah, for yield is an example where

627
00:54:29,960 --> 00:54:35,720
decoupling those two, and you could try to model just the, just model it as a time series without

628
00:54:35,720 --> 00:54:43,800
doing that. But then you're just, the problem becomes way, way noisier and harder and you just

629
00:54:43,800 --> 00:54:52,920
don't get good results. And so, so it's very much, yeah, so that's that's one example. Another

630
00:54:52,920 --> 00:54:59,400
example is demand, on the demand side, which we haven't talked too much about, but, you know,

631
00:54:59,400 --> 00:55:04,040
if you are trying to forecast consumption of different things, similarly again, there is some

632
00:55:04,040 --> 00:55:12,920
long-term trends that are driven by like economics, you know, and and culture. So, for example,

633
00:55:12,920 --> 00:55:19,640
you know, the many countries throughout the world, you know, as the GDP, as the income per capita

634
00:55:19,640 --> 00:55:26,920
increases, and people rise out of poverty, the amount of meat that they eat is going to increase

635
00:55:26,920 --> 00:55:34,440
because when very poor people generally can't afford to eat meat or any kind. So, as countries develop,

636
00:55:34,440 --> 00:55:39,400
the first thing, one of the things you see is the, the diets start to change. So, those types of

637
00:55:39,400 --> 00:55:44,680
things are macro long-term trends, so you definitely need a long-term model for that. But then on

638
00:55:44,680 --> 00:55:49,800
top of that, you know, on any given year, prices could be high, and so the demand for one thing

639
00:55:49,800 --> 00:55:55,400
could be high or lower, or things, you know, trends can change. So, similarly on the demand side,

640
00:55:55,400 --> 00:56:00,760
there is also these short and long-term timescales, and modeling them explicitly makes the

641
00:56:01,480 --> 00:56:07,880
the problem much more solvable. And then I think more generally, you know, if we're trying to,

642
00:56:07,880 --> 00:56:14,920
we feature engineering and hierarchical modeling is really important. Again, it goes back to the

643
00:56:14,920 --> 00:56:22,040
point about black boxes, you know, we could, we have, as I mentioned, 50s or 56 million data

644
00:56:22,040 --> 00:56:27,240
series, and if you translate that into different values, it's in the hundreds of trillions

645
00:56:27,240 --> 00:56:33,560
of data points. So, one approach would be, hey, for every problem we have, just throw every data

646
00:56:33,560 --> 00:56:39,160
point that exists in our country to it and say, yeah, sure, let the machine learn it, right?

647
00:56:40,360 --> 00:56:44,760
But the problem is you can't give a machine like 600 trillion data points and say, okay,

648
00:56:44,760 --> 00:56:50,360
predict one value, it needs a lot of help. So, we have enormous amounts of expertise in the

649
00:56:50,360 --> 00:56:58,680
company in terms of, you know, remote sensing experts, agronomists, hydrologists, some people

650
00:56:58,680 --> 00:57:03,960
like that who are saying, okay, well, don't just throw a million features, these are the 100

651
00:57:03,960 --> 00:57:09,640
features that really should matter, right? And then when we see impact of different features,

652
00:57:09,640 --> 00:57:15,640
we can say, oh, yes, that makes sense. But this feature, this phenomenon, this cause, you know,

653
00:57:15,640 --> 00:57:21,640
this cause has this effect because we understand how these, whether it's biology or economics

654
00:57:21,640 --> 00:57:26,840
or transportation or what have you. There is some domain knowledge that that says, yes,

655
00:57:26,840 --> 00:57:32,280
this makes sense. Well, I know we're running a bit long here. If you've got time for one more

656
00:57:32,280 --> 00:57:38,040
question, I'd be curious to have you, you know, just give us a sense for your overall modeling

657
00:57:38,040 --> 00:57:45,080
process. And in particular, if there are any unique aspects to the way you approach models

658
00:57:45,080 --> 00:57:50,120
beyond the things that we've talked about as far systematically. Yeah, I think, I guess,

659
00:57:50,120 --> 00:57:54,920
the one of the key things is what we choose to model. As I mentioned, you know, we have a platform

660
00:57:54,920 --> 00:58:00,680
where you could really be modeling a million different things every day because we're giving

661
00:58:01,560 --> 00:58:05,960
this highly organized platform that allows you to answer all kinds of questions.

662
00:58:06,520 --> 00:58:14,040
There's a few things we do before we decide to model something. One is, is it an important problem

663
00:58:14,040 --> 00:58:19,880
to model, right? Like all the examples that I gave, they're not just, they're economically

664
00:58:19,880 --> 00:58:25,720
really interesting for our user base. So, you know, I'm like, for example, I mentioned a couple of

665
00:58:25,720 --> 00:58:30,520
times wheat in India. Well, you know, there, of course, there's really cool scientific and technical

666
00:58:30,520 --> 00:58:36,920
challenges, but the first question is, does anybody care? And in that case, the answer is, yes,

667
00:58:36,920 --> 00:58:42,840
it's a huge question because historically, you know, India obviously is one of, you know,

668
00:58:42,840 --> 00:58:48,920
one of the largest countries in the world in terms of population and the second largest.

669
00:58:50,440 --> 00:59:00,360
Historically, and wheat is a big staple there, you know, for the people of India. And historically,

670
00:59:00,360 --> 00:59:07,880
though, for the last 50 years, India has been self-sufficient mostly. So, they produce a lot of wheat,

671
00:59:07,880 --> 00:59:11,960
and they consume a lot of wheat, but it doesn't quite interact too much with the rest of the

672
00:59:11,960 --> 00:59:19,560
world's wheat. But now, you know, because India's continues to develop economically,

673
00:59:21,080 --> 00:59:27,480
and as well as, you know, there are some theories that their green revolution of the last 50 years

674
00:59:27,480 --> 00:59:33,800
is sort of leveling off, and they're kind of, some people are concerned that their production

675
00:59:33,800 --> 00:59:40,040
will not continue to rise as it has, but the demand will continue to rise. So, if that happens,

676
00:59:40,040 --> 00:59:47,400
and suddenly a small percentage change in the supply and demand of wheat in India

677
00:59:47,400 --> 00:59:52,200
could translate into enormous amounts of imports, right? Because it's sort of like, you know,

678
00:59:52,200 --> 00:59:56,680
you have this huge number of production and a huge number of consumption that are kind of

679
00:59:56,680 --> 01:00:02,920
well balanced, but if there's a small change, even a 5% or 10% difference shortage, and then they

680
01:00:02,920 --> 01:00:08,120
need to import that much, then that means, you know, a huge new source of demand in the world,

681
01:00:08,120 --> 01:00:15,000
and maybe Australians will start producing a lot more wheat to export to India or Canada and other

682
01:00:15,000 --> 01:00:20,840
countries who are importing will have to import from other places. So, it has, it's sort of like

683
01:00:20,840 --> 01:00:26,840
this big iceberg that's hiding under the water that could have a big impact. So, all that to say

684
01:00:26,840 --> 01:00:32,040
is that the first part of modeling process is, is it an interesting thing to model from a business

685
01:00:32,040 --> 01:00:40,440
point of view, and is it fundamentally? And so, you know, and that, and there's a lot of them,

686
01:00:40,440 --> 01:00:46,360
but it's important that we work on the right ones. And secondly, is then we, like I said,

687
01:00:46,360 --> 01:00:53,480
we don't come at a problem with a solution, which I think distinguishes us from many companies

688
01:00:53,480 --> 01:00:59,800
where we didn't start out as an AI company saying, well, you know, let's just find the

689
01:00:59,800 --> 01:01:07,000
problem and say to work on and stumble into agriculture, it was more a joint thing of figuring out

690
01:01:07,000 --> 01:01:13,560
that, you know, this particular domain needs these answers and needs better decisions, but we don't

691
01:01:13,560 --> 01:01:21,640
care if we end up using neural networks or gradient descent algorithm xg boosts our random forest

692
01:01:21,640 --> 01:01:28,440
algorithms and components, but we're agnostic to technology, but we want to solve the problem.

693
01:01:28,440 --> 01:01:34,600
So, I think that the second part of our approach is where every single new problem were prepared

694
01:01:34,600 --> 01:01:41,960
to use different approaches. But third, third piece is that when we build a particular model,

695
01:01:41,960 --> 01:01:50,280
we do try to build a framework that helps us experiment and reuse things in different situations.

696
01:01:50,920 --> 01:01:57,720
And so, for example, even though each country and crop is different for a yield modeling,

697
01:01:57,720 --> 01:02:04,680
we do have a basic framework that applies across the board and some, you know, the input signals

698
01:02:04,680 --> 01:02:13,320
will change, but there's two or three key algorithms that we will always use and then the specific

699
01:02:13,320 --> 01:02:19,960
inputs will be different, but the back testing and how we evaluate our results and so on

700
01:02:19,960 --> 01:02:28,920
will be following that process. And yeah, we try to look at, finally, when we're getting close to

701
01:02:30,520 --> 01:02:38,680
having something that we like and that we're ready to launch, we look at performance in very

702
01:02:38,680 --> 01:02:46,200
unique ways. So, for example, you know, we don't look at just the average value of our error or

703
01:02:46,200 --> 01:02:51,000
just the signal. But, you know, even when we're predicting a single number, let's say the wheat

704
01:02:51,000 --> 01:02:58,840
yield of Russia or the Black Sea region, it might be a single number at the end, but underneath it,

705
01:02:58,840 --> 01:03:03,240
we're actually making that same prediction in a much more granular way. So, we look at,

706
01:03:03,240 --> 01:03:08,840
oh, how is the error distributed spatially? Does that make sense? How's the error distributed in

707
01:03:08,840 --> 01:03:14,760
the back testing? Like, when we run it, when we back test historically, does it, you know, what are

708
01:03:14,760 --> 01:03:19,720
the years where our model would have performed better or worse? And why is that? And does that,

709
01:03:19,720 --> 01:03:25,080
does it just random noise? Or is it like, does it give us features that we should model?

710
01:03:25,080 --> 01:03:30,920
So, we have a very iterative process where we look at spatial temporal distribution

711
01:03:30,920 --> 01:03:37,000
performance and bring in a lot of domain expertise to sort of figure out the feature engineering

712
01:03:37,000 --> 01:03:46,120
and tweaks that we need to do to have a good model. Is it hard in your case to know when to stop?

713
01:03:46,120 --> 01:03:52,760
When it's good enough? No, I think we're lucky because, again, from the first point I started with,

714
01:03:52,760 --> 01:03:59,320
we usually have a very clear idea of why this is interesting. And together with that comes an idea

715
01:03:59,320 --> 01:04:06,360
of what's reasonable to move the needle, right? So, in terms of to add value to the world.

716
01:04:06,360 --> 01:04:11,880
So, you know, like, let's say if you're trying to model something in the United States, then,

717
01:04:12,520 --> 01:04:18,600
you know, there's typically going to be a lot of really good inputs, a lot of historical data,

718
01:04:18,600 --> 01:04:24,600
and better than most other places in the world. So, we will, our expectation will be like,

719
01:04:24,600 --> 01:04:28,280
well, okay, to make a difference in this case, we really make, we've got to make sure that our

720
01:04:28,280 --> 01:04:36,440
errors less than 0.5 percent, right? Because anybody can get to within 2 percent or whatever, right? Like,

721
01:04:36,440 --> 01:04:43,080
the data is so good. Yeah, exactly. And conversely, you go to a country where, or part of the world,

722
01:04:43,080 --> 01:04:49,080
where there's very little data and there's no, or maybe, maybe no ground truth at all,

723
01:04:49,720 --> 01:04:55,800
so on. And then you're like, well, okay, everybody's the best anybody in the world can do is 10 percent.

724
01:04:55,800 --> 01:05:01,320
So, or 20 percent, or they have, or maybe 50 percent, because they have absolutely no idea what's

725
01:05:01,320 --> 01:05:06,920
going on. And then in that case, we're like, well, okay, can we consistently robustly make a

726
01:05:06,920 --> 01:05:11,720
forecast that has an error of 10 percent? And that's, maybe that's awesome. That would be terrible

727
01:05:11,720 --> 01:05:17,320
for for something that, you know, that everybody else has a 1 percent error on, but if it's

728
01:05:17,320 --> 01:05:22,120
everywhere else has a 20 percent error, then we'll put it and we'll be confident that we're adding

729
01:05:22,120 --> 01:05:29,000
value. So, so we always know when when we're adding value and when we're not adding value. And so

730
01:05:29,000 --> 01:05:32,760
that gives us an easy way to say, okay, let's launch this. Even though there's a million things

731
01:05:32,760 --> 01:05:37,480
that we could do to improve, we're already ahead of the, you know, we're adding value.

732
01:05:38,200 --> 01:05:45,640
Well, Nemo, thanks so much for being so generous with your time and sharing with us what you're

733
01:05:45,640 --> 01:05:51,560
up to there at Grow. Very much appreciated. Yeah, thanks, Sam. And yeah, I enjoyed it. I hope

734
01:05:51,560 --> 01:05:55,400
it was informative and inspiring. Absolutely. Thanks so much. Thank you.

735
01:05:59,400 --> 01:06:05,080
All right, everyone. That's our show for today. For more information about today's guest or

736
01:06:05,080 --> 01:06:10,120
any of the topics mentioned in the interview, visit twomelai.com slash shows.

737
01:06:11,400 --> 01:06:15,880
To learn more about the IBM AI Enterprise workflow study group, I'll be leading.

738
01:06:15,880 --> 01:06:22,920
Visit twomelai.com slash AI workflow. Of course, if you like what you hear on the podcast,

739
01:06:22,920 --> 01:06:27,080
please subscribe, rate, and review the show on your favorite pod catcher.

740
01:06:27,080 --> 01:06:45,880
Thanks so much for listening and catch you next time.

