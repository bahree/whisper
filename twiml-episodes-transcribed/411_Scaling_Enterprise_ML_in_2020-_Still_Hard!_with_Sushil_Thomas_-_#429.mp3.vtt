WEBVTT

00:00.000 --> 00:11.600
Hi everyone, I am joined by Sushil Thomas, who is the VP of engineering for machine learning

00:11.600 --> 00:16.140
at Cladera. A little bit of background on this interview earlier this summer, Cladera

00:16.140 --> 00:20.920
invited me to host a series of roundtable discussions with enterprise data leaders from

00:20.920 --> 00:27.280
a variety of industries to explore their experiences, building the foundation for success with machine

00:27.280 --> 00:33.920
learning and advanced analytics. Sushil and I had a bunch of great conversations in that context

00:33.920 --> 00:40.440
and I invited him here to join me for a deeper conversation on the topics. Sushil, welcome

00:40.440 --> 00:46.040
to the 12 more AI podcast. Thank you Sam, very nice to talk to you again. I had a good

00:46.040 --> 00:51.280
time at that roundtable talk too and I wish we could do this in person, it's kind of insane

00:51.280 --> 00:57.600
in the world we're living in now. It is insane the world we're living in and a little bit

00:57.600 --> 01:02.880
of background on the data leader roundtable program. It was originally envisioned to

01:02.880 --> 01:10.400
be an in-person series of events that we did with folks that were in leadership positions

01:10.400 --> 01:20.800
in machine learning and AI and data and we pivoted that to accommodate the pandemic and

01:20.800 --> 01:26.720
one of the things that I'm curious about and we'll ask you about momentarily is what you're

01:26.720 --> 01:32.720
seeing, how you're seeing folks adapt to the pandemic and those kinds of roles but before

01:32.720 --> 01:40.000
we do that, let's get a little bit of introduction into your background and your role at Cladera.

01:40.000 --> 01:48.640
As you said before, I'm VP engineering for machine learning here at Cladera. We've increased

01:48.640 --> 01:54.560
the scope of that a little bit recently to include a visualization, data visualization platform

01:54.560 --> 02:00.320
as well because it's such a strong part of the machine learning workflow. In my past, so I've

02:00.320 --> 02:06.800
always been very close to data but in different aspects of it, I started out very early working

02:06.800 --> 02:14.000
on Solaris and in Sun Microsystems in the first internet boom. So I saw people serving up

02:14.000 --> 02:20.160
web pages at massive quantity for the first time on these monster sun machines and it was a ton of

02:20.160 --> 02:26.960
fun to work on those challenges moved into a systems storage company called three-power data.

02:26.960 --> 02:32.640
So worked on enterprise storage for a long time where you would run the backbone of these

02:32.640 --> 02:38.560
data centers from a storage systems perspective and that was a really interesting set of

02:38.560 --> 02:44.400
challenges as well where you have like 30, 40 seconds to respond to every single request and you

02:44.400 --> 02:49.280
miss even one and the entire data center is down because there's all these dependencies

02:49.280 --> 02:53.040
built into the stack and different layers. So anyway, that was a lot of fun as well,

02:53.040 --> 02:59.280
dealing with big data but in a different kind of way and then moved from there once I saw the

02:59.280 --> 03:05.280
scale at which these platforms were being built at places like Google and Yahoo very early on

03:05.280 --> 03:12.000
moved into working on distributed systems. So started with a startup called Jovian Data

03:12.000 --> 03:17.840
that's got acquired since by a new start at this point but essentially working on very large

03:17.840 --> 03:22.960
scale data processing to help the early ad networks process through their data and understand their

03:22.960 --> 03:28.320
data. Moved to a company called Aster Data that builds distributed databases got acquired

03:28.320 --> 03:35.280
into Teradata. So saw a lot of the old school data warehousing stuff at Teradata as well and

03:35.280 --> 03:39.120
I have a lot of appreciation for all that technology from seeing it from the inside as well and

03:39.120 --> 03:44.160
seeing how hard it is to do a lot of that stuff. And then of course started my own company.

03:44.160 --> 03:50.880
It's called Arcadia Data. We did visualization and analytics on large data sets. The challenge

03:50.880 --> 03:56.320
there was to get business users into the Hadoop platform which was at the point at a crazy

03:56.320 --> 04:01.440
growth stage. And now at Cloud Data continuing on into the enterprise data cloud,

04:01.440 --> 04:06.400
Arcadia got acquired into Cloud Data. So continuing on with the enterprise data cloud and helping

04:06.400 --> 04:11.440
enterprises work on this hybrid story. They have a bunch of data on prem. They have a bunch of

04:11.440 --> 04:17.600
data in the cloud infinite requirements on what they want to do with that data and so trying to

04:17.600 --> 04:22.400
help them through all of that and working specifically on machine learning AI visualization as a part

04:22.400 --> 04:29.600
of that. Got it. Got it. And in your role as VP of engineering is that primarily focused on

04:29.600 --> 04:36.560
engineering the internal products that are offered to customers or how close do you get to the

04:36.560 --> 04:42.080
the problems that customers are facing from a machine learning lifecycle perspective?

04:43.120 --> 04:49.280
Right. So there's a few groups that that report up to me. One of them is the machine learning

04:49.280 --> 04:54.720
product itself. So we have a product called CML Cloud data machine learning which is a hybrid

04:54.720 --> 04:58.800
platform. It works on prem. It works on the cloud. It's it's very much our product within the

04:58.800 --> 05:03.760
market for a long time that targets machine learning developers and data scientists to actually be

05:03.760 --> 05:08.320
productive and get a lot of the development a lot of the production stuff going. We'll talk about

05:08.320 --> 05:15.120
that a little bit later perhaps in some pieces. And then the other group one of the other groups is

05:15.120 --> 05:21.840
fast-power labs. So this is a machine learning research team. We do applied research towards a bunch

05:21.840 --> 05:27.120
of topics all open source all available. We run webinars every month every few months. We present

05:27.120 --> 05:33.840
a lot of conferences. So that just helps customers like the goal of that organization is to take what

05:34.480 --> 05:39.680
is maybe two years ahead in terms of machine learning theory right in terms of how quickly it's

05:39.680 --> 05:43.840
going to get applied to customers and try to accelerate that process a little bit show people

05:43.840 --> 05:49.360
a glimpse of the future and help them get to solutions on their in their enterprises that that

05:49.360 --> 05:54.240
help with that right that that we can augment them on. And there's a lot of possibilities there.

05:54.240 --> 05:59.280
There's a lot of stuff you're doing in terms of making that even easier especially as it comes to

06:00.160 --> 06:03.920
leveraging all of this stuff on the cloud where everything is very easy, very self-service

06:03.920 --> 06:08.720
and should be trivial to get started. And then the third team that's new is the data visualization

06:08.720 --> 06:13.760
team. We just announced this like basically post the Arcadia acquisition. We've been working on

06:13.760 --> 06:19.200
integrating that technology into cloud-era stack stack as well. So now we've integrated data

06:19.200 --> 06:23.760
visualization into both the machine learning platform and the core data warehousing platform.

06:23.760 --> 06:30.080
And so as machine learning engineers as data scientists you now get to look at the data in a very

06:30.080 --> 06:37.040
very easy way build these end applications that work for end users business users and connect the

06:37.040 --> 06:42.400
sort of the descriptive data analysis that's always been possible with more prescriptive models

06:42.400 --> 06:46.720
and and mesh that data together and and make these beautiful applications for the organization.

06:48.000 --> 06:53.600
Okay, great. But there's a part of that like as to your questions you know we always work very

06:53.600 --> 07:00.320
closely with customers like my strong push on engineering organizations is always that you

07:00.320 --> 07:04.560
cannot just build these products in isolation right so you have to continuously be talking to

07:04.560 --> 07:10.240
customers. If I don't have you know two or three customer meetings every week then I'm really

07:10.240 --> 07:14.560
disappointed essentially and typically it's more than that. And you work in customers at different

07:14.560 --> 07:18.560
phases like so you work with the customers that have never heard of you and never used your products.

07:18.560 --> 07:22.640
You work with customers that are three years into using your products and that know the ins and outs

07:22.640 --> 07:28.240
of of of your product and their business and have very specific suggestions on what you should do

07:28.240 --> 07:36.000
next. So there's like there's there's a high number of customer correlations always ongoing. So

07:36.000 --> 07:42.320
so I mentioned the the data leaders roundtable program earlier and again we wanted to chat a

07:42.320 --> 07:49.600
little bit about that and get your key takeaways and in particular that event took place

07:49.600 --> 07:58.240
earlier in the the COVID pandemic this was earlier in the summer and folks were you know in the

07:58.240 --> 08:04.960
process of adjusting to working from home and getting their teams set up to to work from home.

08:04.960 --> 08:12.080
Now we've got quite a bit more distance under our belts now and a lot of the organizations that

08:12.080 --> 08:18.800
I'm talking to are not planning to return back to offices until sometime mid to late next year

08:18.800 --> 08:25.760
at the earliest yes and I'm just curious in the the conversations that you're having what kind of

08:25.760 --> 08:35.600
impact all of this disruption has been having on on data organizations is it you know has it

08:35.600 --> 08:42.560
been impacting them much at all is it industry by industry or you know our folks still working

08:42.560 --> 08:49.200
through what that mean what this all means yeah so so I think one thing that I didn't know going

08:49.200 --> 08:54.880
in it did surprise me a little bit but maybe in retrospect it's obvious I think one thing is that

08:55.680 --> 09:03.360
data has become so core to organizations now and storing all their data and analyzing it processing

09:03.360 --> 09:08.480
it using it to predict outcomes using it to understand their business is so central to how

09:08.480 --> 09:16.960
organizations work now that at least the cloud era we have seen surprisingly little or no impact

09:16.960 --> 09:23.520
to our customers like even the ones in industries where you would think these industries are substantially

09:23.520 --> 09:28.480
impacted guess what they still have all of that data they still have to worry about securing it

09:28.480 --> 09:34.560
and using it and leveraging it for for future planning stuff the one thing I of course as you

09:34.560 --> 09:40.080
said there's been so many changes at organizations just trying to figure out how to get everyone

09:40.080 --> 09:45.760
working from home and working remotely and some organizations do it better than others but we are

09:45.760 --> 09:51.760
all in this place where no one quite we are still learning right and it's not just the right it's

09:51.760 --> 09:56.160
not just the architecture right it's just it's just living with the pandemic and and all your

09:56.160 --> 10:02.240
employees being a little like their lives being so different right and as that goes on and on and on

10:02.240 --> 10:07.520
I think you have to like continually manage people's expectations and psychology and make sure

10:07.520 --> 10:11.840
work is not a drain on them I think we've all gone through how difficult it is to just stay on

10:11.840 --> 10:18.240
zoom the entire day or stay on video conferencing the entire day it's kind of crazy so I mean there's

10:18.240 --> 10:26.640
all of that but on the other side on the actual challenges of working with data on the on the actual

10:26.640 --> 10:31.760
concept of getting all these things going there's not much has changed all the data teams that I

10:31.760 --> 10:38.240
work with have not you know reduced or changed in size substantially if anything the big differences

10:38.240 --> 10:42.640
I'm hearing of a lot of use cases that are specifically related to the pandemic as you would expect

10:43.440 --> 10:49.280
again I think just highlighting how central data has become to organizations and how much people

10:49.280 --> 10:55.520
start with data I love that notion right like it used to be you know 20 years ago you you want to

10:55.520 --> 11:00.800
decide something about your business you know you want to let's say your retail store and you're

11:00.800 --> 11:05.600
trying to figure out where you open the next 10 locations I think 20 years ago you would have

11:05.600 --> 11:09.840
exact sitting in a room you would have regional leads right you would be discussing you should

11:09.840 --> 11:14.560
be do it right and you would pick like a few locations that people have people think I interesting

11:14.560 --> 11:19.120
people would drive out to it like things like that right and now it's so different the first thing

11:19.120 --> 11:24.400
is like where's the data where are competitors where where is the spend high right and where should

11:24.400 --> 11:28.960
be open and then you start with like shortlisting just based on the data and then maybe you do a

11:28.960 --> 11:34.400
sanity test at the end to just make sure you know you're not building on a on a radioactive site

11:34.400 --> 11:39.200
or something like that at the end but like the the fundamentals are so different in how people

11:39.200 --> 11:48.560
run their businesses now you mentioned that you are seeing some covid related use cases pop up are

11:48.560 --> 11:55.840
these primarily in the industries like health care and the industries that are part of the

11:55.840 --> 12:01.360
response to covid or is it broader than that I actually meant health care because that is so central

12:01.360 --> 12:06.960
like we are we are also you know I think it's natural to try to be particularly supportive to

12:06.960 --> 12:10.960
these industries that are there are trying to help all of us out through this right and you see

12:10.960 --> 12:16.720
that they have a lot of interesting work that's ongoing now and that that work is very compelling

12:16.720 --> 12:20.320
so I actually meant health care cloud has a large health care business and so there's a lot of

12:21.120 --> 12:25.680
companies talking to us about their challenges here and the extra kinds of work and processing

12:25.680 --> 12:28.880
they need to do and seeing if we can help and of course we are more than happy to help

12:30.080 --> 12:36.640
and so yeah so just seeing a lot of those use cases either around planning for for the number of

12:38.560 --> 12:42.640
folks that come into hospitals now and have to be processed and you have to do all of this

12:42.640 --> 12:47.360
planning and forecasting you know things like when do the how many doctors do you need to get

12:47.360 --> 12:51.840
what how do you do the scheduling for this stuff what what your expectations on on workloads

12:51.840 --> 12:56.160
and then of course going all the way into the research side and trying to understand which of these

12:56.160 --> 13:00.480
are which of these possibilities might work towards vaccines which of these are good

13:01.840 --> 13:06.080
treatments options like all of this analysis that's done with the data as well and of course

13:06.080 --> 13:10.960
everything is again just related to data right they have at this point there's a ton of data out

13:10.960 --> 13:14.960
there on people who've come in on the kinds of treatments that we've done on them on remission on

13:14.960 --> 13:18.560
any sort of remission that's happened on on what the outcomes have been and so there's a lot of

13:18.560 --> 13:23.120
analysis you can do to get to a place where where you where you can make better decisions about what

13:23.120 --> 13:30.240
you're doing forward which is the important thing. So for the round table I structured the conversation

13:30.240 --> 13:37.840
broadly in terms of these three core themes people process and technology you know certainly themes

13:37.840 --> 13:45.760
that we talk about a lot and the in technology and I thought we'd spend some time talking through

13:45.760 --> 13:54.160
your key takeaway for you know in those themes from our discussion and as well as your broader

13:54.160 --> 14:04.400
experience talking to the customers you know over the past few months we touched on some of the

14:04.400 --> 14:11.760
impacts of COVID to people but more broadly what are some of the key trends you're seeing in

14:11.760 --> 14:19.200
organizations that are trying to deploy machine learning go further with their ability to

14:19.200 --> 14:28.000
make use of data deploy advanced analytics how are they dealing with the organizational issues

14:28.000 --> 14:35.040
that arise and what are those issues yeah. So the round table was great and I think it was at

14:35.040 --> 14:41.120
least to me very different setting talking to a bunch of data leaders together versus talking

14:41.120 --> 14:46.720
one-on-one to a single organization and maybe a few people at different levels within that organization

14:46.720 --> 14:49.920
of course you've done this a lot more so I'll give you my takeaways but I'd love to hear

14:49.920 --> 14:54.080
your perspective on whether this was different from the others you've done I'm not either also.

14:54.080 --> 14:59.920
So the one thing that was super interesting to me was you know this is obvious when I do the

14:59.920 --> 15:07.200
one-on-one conversations like ML&EI within organizations is is still very very nascent and people

15:07.200 --> 15:12.800
are still figuring out what the right way is to do things and I would contrast this with something

15:12.800 --> 15:18.080
like data warehousing right where this is a very very well understood thing you know exactly how

15:18.080 --> 15:23.440
to set up these organizations you know exactly what to expect at the end of that but for the for

15:23.440 --> 15:30.480
ML&EI it's much more it's much more subtle like no one exactly knows what the expectations are like

15:30.480 --> 15:35.280
normally teams are set up with very very high expectations on this is just going to magically

15:35.280 --> 15:40.400
make everything better the teams are struggling through like we heard that all the time like the

15:40.400 --> 15:47.120
teams are struggling with where is the actual data is the data clean like how do I get rid of all

15:47.120 --> 15:52.560
this noise from the data then what kind of use cases can I do and then continuing on even after

15:52.560 --> 15:56.720
you do the first rare off that work how do you get feedback back into the system how do you

15:56.720 --> 16:01.440
continuously improve these models how do you serve all this stuff at scale and how do you keep

16:01.440 --> 16:07.360
doing this like for new newer use cases that come up while maintaining the older use cases so

16:07.360 --> 16:12.240
that they continue to be relevant and how do you keep all of this going at organizational scale

16:12.240 --> 16:17.840
and so I think industry wide all of us are in the process of figuring a lot of these things out

16:17.840 --> 16:23.040
and what the best practices are here these are not very well written out today and so what I heard

16:23.040 --> 16:29.840
in the roundtable was initially I thought all the participants were a little bit hesitant

16:29.840 --> 16:34.240
because they didn't know if they were the only ones that that were in a little bit of trouble

16:34.240 --> 16:38.960
and that didn't quite know how to solve all these problems right but I think as they heard from

16:38.960 --> 16:44.960
everybody that we are all in the same boat it was a lot more like I think there was a lot more

16:44.960 --> 16:48.960
discussion about the real challenges that everybody hits right because you just don't know if it's

16:48.960 --> 16:52.880
just you but it's just good to know that like everyone's in a very very similar boat there's very

16:52.880 --> 16:57.760
similar set of challenges across the board so that that is really interesting to me like seeing

16:57.760 --> 17:01.360
that dynamic layout and I don't know if you've seen that in the other round tables you've done as well

17:02.320 --> 17:08.160
yeah you know one of the things that jumps out at me on this particular point and in particular

17:08.160 --> 17:16.320
the way you framed it is there's this back and forth in industries one thing that we're grappling

17:16.320 --> 17:23.200
with is thinking about machine learning as an engineering discipline versus thinking about it as

17:23.200 --> 17:31.120
a science and an exploratory process and different organizations take different

17:32.080 --> 17:37.280
different approaches in how they you know synthesize these two perspectives but

17:38.320 --> 17:44.720
in a lot of ways it's it requires synthesizing these two perspectives you can't just approach it

17:44.720 --> 17:54.320
as a traditional engineering task and you can't just approach it as a unstructured exploration

17:54.320 --> 18:01.440
if you hope to achieve any scale and you know I'm curious how that resonates for you as someone who

18:01.440 --> 18:09.040
is you know if you have engineering for machine learning right so it is fascinating we are also

18:09.040 --> 18:15.920
I would say while we have a machine learning product team what the machine learning product

18:15.920 --> 18:23.040
that cloud ourselves does is it helps engineers around all of the problems of machine learning right

18:23.040 --> 18:27.360
so there's the actual machine learning code that you have to write but then there's everything else

18:27.360 --> 18:31.920
there's where's my data there's how do I clean it there's how do I move these models of production

18:31.920 --> 18:38.480
how do I run metrics how do I do ground tracking like all of these problems around the

18:38.480 --> 18:44.800
actual you know 200 500 lines of code that you'll write to train your model and to serve your model

18:44.800 --> 18:49.120
so I think there's a lot around it that's that's what we deal with so so very much the thing

18:49.120 --> 18:54.080
that our product works on is I would say very much the engineering and the science part of it

18:54.080 --> 19:00.080
and less of the art part of it we are very flexible there we let you do anything you want to

19:00.080 --> 19:05.440
particularly because there's this problem where nobody quite knows that this is the one way

19:05.440 --> 19:09.120
in which machine learning is to be done and I don't think that's going to happen but I think what

19:09.120 --> 19:14.480
will happen over time is from my industry perspective these best practices will be will be better

19:14.480 --> 19:20.640
known over time how these organizations the ML data scientists organizations get set up will be

19:20.640 --> 19:27.520
better known over time and there will be like less of that less of the expectation difference

19:27.520 --> 19:31.840
between what is possible and what is achievable which is kind of very prevalent today

19:31.840 --> 19:36.880
you have some execs that will just think this will just work magically I'll just throw two or three

19:36.880 --> 19:41.920
people at this problem and then you find all of these issues around data and what's needed and what

19:41.920 --> 19:46.240
the expectations are on what the what's on the other side and how you to continuously manage this

19:46.240 --> 19:50.560
and stuff like that so we're going to get better than that in fact at loud era you know we have

19:50.560 --> 19:54.880
these ps offerings we work very closely with customers not just on the tech but we also have ps

19:54.880 --> 19:59.040
offerings that that try to get them closer to solving their problems and one of our very popular

19:59.040 --> 20:04.720
ps offerings is a strategy engagement for machine learning which literally boils down to you know

20:04.720 --> 20:09.760
I want more machine learning in my organization how do I get there right and so we do we speak with

20:09.760 --> 20:13.760
execs we speak with business themes that are looking for some of these solutions we try to

20:14.400 --> 20:18.800
meld everyone's expectations together and make suggestions that are right for the organization

20:18.800 --> 20:23.520
on how they should structure their their ML org because that's a challenge too like for many

20:23.520 --> 20:28.640
of these companies that we work with they they don't have a thriving ML practice now they would

20:28.640 --> 20:31.680
love to have one but they don't quite know how to get from where they are to that

20:32.560 --> 20:40.160
yeah one of the recurring themes that struck me from the round tables and for context we were

20:40.960 --> 20:47.680
largely talking to folks from traditional enterprises as opposed to the Facebooks and Google's

20:47.680 --> 20:54.880
of the world and you know no surprise they find it very difficult to compete with those organizations

20:54.880 --> 21:02.480
for talent and so there was a lot of discussion around how they you know groom and upskill and

21:02.480 --> 21:12.000
cross train internal talent from within historical or traditional data organizations to start to

21:12.000 --> 21:20.320
enable the the organization to move more quickly from a machine learning perspective curious

21:20.320 --> 21:26.240
what you've seen working well from that perspective and any takeaways that you had from that part

21:26.240 --> 21:32.080
of that conversation yeah I see a lot of that for sure it's super hard to get

21:32.880 --> 21:38.640
enough machine learning talent enough AI talent also lots of confusion in the industry as you know

21:38.640 --> 21:44.320
around terminology right so you have you have you know teams of data scientists that are really

21:45.600 --> 21:49.360
either data analysts or the like data warehousing folks were just trying to help with

21:49.360 --> 21:53.760
cleaning up the data and getting some basic statistical stuff going you have teams of people that

21:53.760 --> 21:57.680
actually said an IT but it turns out they are amazing data scientists and the use cases they do

21:57.680 --> 22:02.320
a lot more predictive and stuff like that right there's people who have a hub and spoke model right

22:02.320 --> 22:06.320
where they have a central sort of center of excellence these are the guys who set up the best

22:06.320 --> 22:11.760
practices around technologies they use and and and deployment practices and stuff like that

22:11.760 --> 22:16.880
and then business units will have their own individual data scientists that that they work with

22:16.880 --> 22:21.760
for for their actual use cases so yeah I see I see a lot of that also in the industry in terms of

22:21.760 --> 22:27.040
just not there's no standard set of terms on on who these folks are and when you hear someone's

22:27.040 --> 22:30.880
a data scientist or if you hear someone's not a data scientist they could be one it's just like

22:30.880 --> 22:36.800
it's all over the place and in terms of attracting training and retaining people I think that's

22:36.800 --> 22:44.400
a that's a substantial challenge as well I do think it's a very very good idea to to help people

22:44.400 --> 22:49.440
that are in your organization already that work with data on a data day basis and that want to

22:49.440 --> 22:54.560
up level their skills into into machine learning and into AI I I'm a big fan of being very supportive

22:54.560 --> 22:59.840
of that and getting people trained to a level where they want to I guess the good news about it is

22:59.840 --> 23:04.480
everyone who works close to data is interested in understanding more of our machine learning

23:04.480 --> 23:11.120
understanding more about AI and moving closer and closer to to to to being productive there so I

23:11.120 --> 23:15.760
think as a organization the opportunity is that you can actually train your people there because

23:15.760 --> 23:21.120
they want to be trained in in those fields and then the still the tricky bits is just having the

23:21.120 --> 23:26.480
structure around this practice so that you can actually use them productively at the end of that

23:26.480 --> 23:31.280
they can do interesting things while they're learning and then you can get more people in that area

23:32.880 --> 23:38.960
you've talked about some of the different organizational models hub and spoke versus centralized

23:38.960 --> 23:47.280
historically one of the challenges within traditional enterprises and IT is kind of

23:48.080 --> 23:54.080
breaking down silos and enabling organizations to communicate and work together effectively

23:54.080 --> 23:58.560
are there any things that you've seen work better than others or is it

23:58.560 --> 24:06.400
you know very very organizational dependent yeah and it is today it's organizational dependent

24:06.400 --> 24:14.480
I do think if you think about similar things that that organizations have wrestled with before

24:14.480 --> 24:18.880
and the ways in which they've set it up I think you get some clues around what might work better

24:19.600 --> 24:25.520
so in my mind for example if I think about data warehousing and data platforming

24:26.400 --> 24:31.760
it feels like a very centralized model has worked pretty well there for large organizations

24:31.760 --> 24:38.480
where most of your expertise is in a is in a central team they run your your data platforms

24:38.480 --> 24:42.560
and anytime you reach a place where there's a bunch of data silos around the place it's a little

24:42.560 --> 24:47.520
bit of a disaster right because you have to then figure out how to make sense of these these

24:47.520 --> 24:52.080
different deportations of all this data and all of these things in place but that's after many

24:52.080 --> 24:58.080
years of data warehousing practice yeah exactly and I think it's it worked very well there but if I

24:58.080 --> 25:04.000
can take the opposite side on something similar if you look at business analytics as a practice

25:04.000 --> 25:11.040
and BI as a practice it's very much the case that people might build central BI tools and do

25:11.600 --> 25:16.000
large contracts or that there's standardization on sort of what the tool is that you're using

25:16.000 --> 25:22.400
but once you've done that the actual use cases the actual end use cases are typically don't come

25:22.400 --> 25:27.040
from a central organization there's there's a few people that work in marketing and a few people

25:27.040 --> 25:31.840
work in sales and a few people work in product who are actually doing the day-to-day analysis of

25:31.840 --> 25:39.280
what's actually happening using those central platforms and I think that's because the data warehousing

25:39.280 --> 25:45.680
and data platforming is very much a problem of scale and standardization and and reducing costs

25:45.680 --> 25:51.120
and trying to make everything very secure and things like that but business analytics and BI

25:51.120 --> 25:56.480
is very much a problem of what do my users actually need and I need to move really really quickly

25:56.480 --> 26:00.880
really close to the users and these requirements change every day the questions change every day so

26:00.880 --> 26:05.520
so the the folks that work on this problem have to be really close to those business units

26:05.520 --> 26:13.120
so I am biased towards thinking that that's a better model for for ML and AI where the actual outcomes

26:13.120 --> 26:18.560
are really close to the business you need people right next to the business who will work with the

26:18.560 --> 26:22.960
business understand their urgency build the models show them the outcomes do the predictions all

26:22.960 --> 26:29.120
of that stuff and of course at the same time I do very much like this notion of let's standardize

26:29.120 --> 26:33.760
on tools and let's standardize on processes and let's make sure once these things are built out

26:33.760 --> 26:38.400
that there's a standard way in which we manage and monitor and track these things and and augment

26:38.400 --> 26:44.480
them over time right so that sort of that that that I think it's closer to BI and business analytics

26:44.480 --> 26:48.160
then data warehousing but you know that's my opinion we'll find out right we have we have a ways to

26:48.160 --> 26:57.360
go in figuring yeah yeah but you know building on that assuming a future that has data scientists

26:57.360 --> 27:03.440
you know very closely aligned to the line of business and what its needs are and platform

27:03.440 --> 27:08.880
organizations or machine learning engineering or data engineering you know those organizations

27:08.880 --> 27:15.280
that are building out the central capability existing centrally you know what are the

27:15.280 --> 27:23.680
the practices that allow folks to effectively operate that at scale based on these analogies that

27:23.680 --> 27:29.120
you just mentioned what does that life cycle look like what are those the relationships between

27:29.120 --> 27:34.880
those orgs look like in order to allow folks to get things done more quickly yeah and and again

27:34.880 --> 27:40.640
here I think we can take cues from from what's been done previously for analytics as well

27:40.640 --> 27:46.480
essentially the thing that seems to work well is having a standard set of definitions that

27:46.480 --> 27:52.960
are organization wide around the data having a standard set of security practices and access policies

27:52.960 --> 27:59.520
and all that stuff in place that are very strong and very central but then letting the analysts

27:59.520 --> 28:07.760
themselves very liberally work within that framework right so there is typically no standard policy

28:07.760 --> 28:12.880
on this is exactly what your BI dashboard must look like right you must have sort of one

28:12.880 --> 28:18.240
KPI on top and three bar charts in this and that right you want to be you want to be a lot more

28:18.240 --> 28:24.240
flexible on that entire use case and that entire surface area and be a lot more prescriptive

28:24.240 --> 28:29.920
about what you want the tools you want to use and the the practices around access and security

28:29.920 --> 28:35.280
to data so I think there are ways of of slicing this in a very similar way for ML you don't want

28:35.280 --> 28:39.840
to be prescriptive to the data scientists to say that this is the kind of model you'll use this

28:39.840 --> 28:43.600
is the kind of training you'll do this is the kind of hardware you will use to do the training

28:43.600 --> 28:48.400
because I think it's a evolving field and a lot of that is is continuously changing over time

28:48.400 --> 28:53.520
and you want to have that flexibility there at the same time when you talk about how you access

28:53.520 --> 28:58.320
data and when you talk about how you move something to production and how you monitor the

28:58.320 --> 29:03.120
performance of something going ahead and what the standards are for interpretability that I have

29:03.120 --> 29:09.680
to be built into whatever whatever you're publishing and how do you you know manage in a central way

29:09.680 --> 29:14.960
like uptime and all of these things I think there's a strong case to be made that that should be

29:14.960 --> 29:20.320
formalized standardized centralized it's also something that most data scientists I mean

29:20.320 --> 29:24.160
it's a little bit of a hassle for them right like that's something that that hopefully just works like

29:24.160 --> 29:28.080
if I want to get data hopefully it's well understood where that data is and how I get to it

29:28.080 --> 29:33.040
and if it's not there like who do I complain to about right so that it shows up essentially over time

29:33.040 --> 29:39.600
so I think it's all about like I think from the the other angle of people and hiring people

29:39.600 --> 29:44.880
and retaining people it's also important that when you get data scientists in that they work

29:44.880 --> 29:49.680
in a productive environment and one way to make that environment productive is to have very clear

29:49.680 --> 29:54.960
boundaries around a lot of these problem statements so that what they're working on is much more

29:54.960 --> 29:59.440
aligned to what they're good at and what they want to do essentially which is to do the actual

29:59.440 --> 30:05.840
data science build the use cases like that's the exciting bit for them so yeah yeah one of the

30:05.840 --> 30:13.440
recurring challenges that we talked about during the around tables was the challenge to getting

30:13.440 --> 30:23.440
models in a production the I think all of the organizations kind of reference store at least

30:23.440 --> 30:29.600
agreed with this idea that you have many more models that you've tried or that you've experimented

30:29.600 --> 30:36.320
with then have made it into production and some of that is just the natural process of experimentation

30:36.320 --> 30:43.440
but there are also issues that organizations run into when trying to get models into production

30:43.440 --> 30:49.040
you know can you speak to some of the you know the stories that you heard at the round tables and

30:49.040 --> 30:55.200
more broadly the issues that are preventing organizations from effectively fielding their models

30:55.680 --> 31:02.000
yeah absolutely so this is something which is essentially like so you know this as I said there's

31:02.000 --> 31:06.000
a few classes of customers we work with we work with organizations that are really early in their

31:06.000 --> 31:10.400
journey that are trying to build something build an initial practice out on how to use these

31:10.400 --> 31:16.400
technologies there are other organizations who've you know used our product for multiple years

31:16.400 --> 31:22.880
right who have teams of 50 people in that central team and then they have some a large number of

31:22.880 --> 31:27.440
users data scientists in the spoke teams right so we work with fairly large organizations as well

31:27.440 --> 31:33.200
who are pretty far along in their practice the feedback is pretty consistent that production

31:33.200 --> 31:38.080
is still something that's very very very important to them essentially right production ML all of

31:38.080 --> 31:43.200
these issues and there's a category there's a set there's sets of issues around first of all it's

31:43.200 --> 31:46.880
just metrics like what is the standard way in which you're going to publish and look at metrics

31:47.760 --> 31:52.960
there's a whole thing about monitoring how when you deploy this first of all how do you deploy it

31:52.960 --> 31:56.240
what's the platform in which you deploy something to production and then how do you monitor

31:56.960 --> 32:00.320
what's in production over time how do you scale it up and down elastically how do you

32:00.960 --> 32:06.800
do all of that stuff and then the third large thing is governance like if you are so so there's

32:06.800 --> 32:10.800
two challenges right the first challenge is getting your initial monitor production that's

32:10.800 --> 32:14.640
typically a really large challenge if you've not dealt with it if you've not solved those problems

32:14.640 --> 32:19.840
the second thing is one something in is in production how do you change it right because changing

32:19.840 --> 32:27.120
is super complicated it implies that you know how the your model is performing in production now

32:27.120 --> 32:31.920
and you have a theory that the modification is going to make it better like that's one

32:31.920 --> 32:36.000
so that means you have to have good measurement practices before and after and comparison

32:36.000 --> 32:41.680
second there's the entire workflow of this is not a one-off change typically changes could happen

32:41.680 --> 32:45.840
multiple times a week multiple times a day depending on the organization that you are in the type

32:45.840 --> 32:50.080
of model you're building so this is not a one-off problem where you get together and fix it this is

32:50.080 --> 32:56.320
complete like CICD versioning it's like standard software development practices that have to be

32:56.320 --> 33:00.720
applied here and you'll see many many data scientists who are just not familiar with software

33:00.720 --> 33:06.240
development practices at that level because that's not the kind of work that they have done prior and

33:06.240 --> 33:11.280
then there's the challenge of once everything is running in production how do you keep monitoring

33:11.280 --> 33:17.840
that over time how do you compare that to ground truth right how do you run all these metrics not

33:17.840 --> 33:22.880
just on an instant basis in terms of timeliness and how reasonable the predictions are but also

33:22.880 --> 33:27.040
compare to ground truth and understand if you're doing things overall better or worse things like

33:27.040 --> 33:31.920
that and if you've not solved these problems these are massive problems and these are things that

33:31.920 --> 33:36.000
you must solve through standardized tooling right organization wide it's pointless to have

33:36.640 --> 33:41.120
each of your business teams solve these separately it's it's pointless to not have a

33:41.920 --> 33:47.360
org-wide policy on how this stuff is done of course the cloudware product do it other products do it

33:47.360 --> 33:51.680
as well the more important thing from the organizational perspective is just to have a stance on

33:51.680 --> 33:56.880
these things so that your data scientists less spend less spend less time being frustrated about

33:56.880 --> 34:02.960
these practices and more time being productive and what your sense for how far along

34:02.960 --> 34:10.880
organizations are on that journey in Silicon Valley you know we've got as we alluded to a little

34:10.880 --> 34:16.480
earlier like very distinct roles there's the data scientists that's focused on one part of the

34:16.480 --> 34:22.800
process and you know to your earlier point the definitions you know very fairly widely but then

34:22.800 --> 34:28.160
you've got machine learning engineers that tend to be more familiar with concepts like CICD

34:28.160 --> 34:36.080
and DevOps and platform technologies and things like that my sense at least is that in more

34:36.080 --> 34:44.080
traditional organizations that those the distinction and those roles is evolving but yet at the same

34:44.080 --> 34:50.080
time a lot of these same organizations have gone through this process and you know considering

34:50.080 --> 34:55.200
like the evolution in the way they feel web applications there used to be just developers then

34:55.200 --> 35:02.800
they started to you know have platform teams and build out internal platforms and so I'm curious

35:02.800 --> 35:10.080
what you're you're seeing in terms of you know how mature our you know enterprises and along this

35:10.080 --> 35:17.120
in this journey and you know where they need to evolve yeah and as you said it very so much

35:17.760 --> 35:23.200
interestingly if you look at any of these organizations that you would think are doing these

35:23.200 --> 35:27.760
this well right that in the valley right these these orgs that have been doing it maybe

35:27.760 --> 35:33.520
five ten years and have fairly large teams at this point that deal with this what you will see is

35:33.520 --> 35:38.160
that they have their own internal tooling they built for a bunch of this because when they started

35:38.160 --> 35:43.440
out there there's really was not something that worked well for them in this area right so I guess

35:43.440 --> 35:50.080
what's challenging from a from a from a larger industry perspective is if you're not a crazy

35:50.080 --> 35:56.640
Silicon Valley tech company with like 300 data scientists that you've solved for by spending large

35:56.640 --> 36:01.520
amounts of treasure and building custom tooling I think the challenges of just finding that like

36:01.520 --> 36:06.080
figuring out what that process is that works for you at the scale that you're at and I think there's

36:06.080 --> 36:13.440
the other overlapping point here is that you're right of many of these organizations have

36:13.440 --> 36:17.280
standard ways in which they've done web app development and internal product development and

36:17.280 --> 36:22.160
stuff like that for themselves before so I think another challenge is just trying to understand

36:22.160 --> 36:27.680
what's different between that standard web app sort of development and product development versus

36:27.680 --> 36:35.440
like a MLAI model going into production because there are large substantial differences that are

36:35.440 --> 36:40.560
really important to internalize and understand so that you can focus on different aspects of it as

36:40.560 --> 36:46.560
well and as an art that's starting out with this if you're bringing up a team which is like you

36:46.560 --> 36:52.080
know five ten data scientists in size to begin with it's so hard to plan ahead for all of these

36:52.080 --> 36:57.760
issues before you know them or before you hit them and so I think I that is a lot of audience in

36:57.760 --> 37:03.360
terms of where people are with this yeah it's interesting in that it's different enough that you

37:03.360 --> 37:08.960
certainly can't you know take a snapshot of your you know DevOps process and apply it to machine

37:08.960 --> 37:15.200
learning and that leads folks to think that it's you know holy new and magic and it needs some

37:15.200 --> 37:20.000
totally new thing but yet there still is a lot that you can learn about the experience you had

37:20.000 --> 37:26.160
yes you know going through the past ten years of you know DevOps exactly exactly and I think

37:26.160 --> 37:30.000
that's like as you said like that's both good and bad like the good thing is you don't have to

37:30.000 --> 37:33.760
reinvent everything the bad thing is you might think you're already there and you don't understand

37:33.760 --> 37:41.200
the differences well enough and you know the it's it's it's it's also one of these areas in tech

37:41.200 --> 37:47.120
which unlike most of the areas in tech like you know you can have technologists that have been in

37:47.120 --> 37:54.080
the industry for twenty thirty years right and if you asked them about Docker and Kubernetes and

37:54.080 --> 37:59.120
a bunch of these areas that are fairly new right people are fairly familiar with them like it's fine

37:59.120 --> 38:04.640
I understand it it maps to something we've done before you know short we've used VMs for a long

38:04.640 --> 38:09.200
time now like Docker Kubernetes like you know I understand all the stuff right it's straightforward

38:09.840 --> 38:14.240
if you talk to most engineers who've been in around for twenty thirty years and you start talking

38:14.240 --> 38:20.240
what machine learning you will find there's a level of of you know of of discomfort right with

38:20.240 --> 38:26.160
that technology right people are not completely certain how it works what it does what it can actually

38:26.160 --> 38:32.400
do for them there's all these reports in the news about how tech is how ML and AI is used which always

38:32.400 --> 38:38.000
seem so far fetch like suddenly it's beating the best go player in the world right and and it's

38:38.000 --> 38:43.040
like it's it's totally on top of anything that's just later and then you look at what you're doing

38:43.040 --> 38:48.000
and you're looking at even dog fights in the air force there you go right it's it's yeah it's it's

38:48.000 --> 38:53.200
I don't know how that went but yes like even the possibility that is doing that is it's crazy yeah

38:53.840 --> 39:03.440
and and then you look at your organization internally and you're having challenges just

39:03.440 --> 39:08.880
getting a real-time feed of like sales over time right and just understanding like what happened

39:08.880 --> 39:13.360
yesterday versus today and what's different and where the outliers are and it seems so far away

39:13.360 --> 39:17.360
and so I think you see a lot of that discomfort reflected internally in organizations where

39:17.360 --> 39:22.080
people are just not sure how they should move forward and that just also slows down a little bit

39:22.080 --> 39:28.240
of the cadence on on how they can do it yeah one of the no sorry I was just going to say that as

39:28.240 --> 39:33.120
as like the leaders were telling us on the on that round table as well like their challenges

39:33.120 --> 39:37.600
just trying to map those expectations to the teams they're building like making sure everyone

39:37.600 --> 39:43.360
everything moves up and they can keep hiring and and and getting best practices in

39:43.360 --> 39:47.600
as the teams grow to what is the most size and it's just a set of one challenge after another

39:47.600 --> 39:52.560
but that's what makes it fun I guess yeah yeah yeah one of the things that I noticed in the

39:52.560 --> 40:01.600
conversations that we had at the round table is that the the folks that we spoke to were fairly

40:01.600 --> 40:09.040
mature on the the core data you know from a core data maturity perspective just kind of by

40:09.040 --> 40:17.600
selection and I'm wondering that may also be the case with you know in your experience with

40:17.600 --> 40:23.440
the folks that you talked to by virtue of the fact that you're at cladera and I'm curious

40:23.440 --> 40:30.800
your take on you know this idea that you know centralizing your data is a prerequisite to doing

40:30.800 --> 40:36.640
ML and events analytics at scale and you know what exactly that means how mature you you need to be

40:36.640 --> 40:42.960
you mentioned that folks still struggle with some fairly basic things that that is all a shifting

40:42.960 --> 40:51.200
landscape yeah any reflections on that yeah so as you said like certainly cladera works with

40:51.200 --> 40:56.800
the fortune 500 the fortune 2000 and and and these are organizations that have typically got their

40:56.800 --> 41:01.920
data story together over the last 20 years let's say right not just regular data where I was

41:01.920 --> 41:06.080
in kind of data but also they know how to integrate with these big data technologies how to store

41:06.080 --> 41:10.720
massive amounts of data how to secure analyze all of this stuff as well so they are they are

41:10.720 --> 41:16.560
pretty far along but I don't think I think even if you are a smaller company starting out or if

41:16.560 --> 41:24.080
you're you know SMB I think the patterns around data are reasonably well understood now people will

41:24.080 --> 41:29.200
still argue about one tech versus the other but there's a fairly well understood notion of you

41:29.200 --> 41:35.280
know like a data lake you know a warehouse where things are a lot more structured a transactional store

41:35.280 --> 41:41.360
which is maybe you know using like a key value store that that's that for much faster accesses

41:41.360 --> 41:48.800
and I think that high level thing is understood any in fact typically the data silos problem that

41:48.800 --> 41:54.960
you see tends to be in larger companies where the data teams are so disconnected from business

41:54.960 --> 42:00.000
that business feels compelled to to take on like some of that challenge themselves just so they

42:00.000 --> 42:04.800
can get more responsiveness but even then the business teams are working within the constraints

42:04.800 --> 42:08.560
of these well understood patterns right they're setting up their own little data mark somewhere

42:08.560 --> 42:13.920
on the side without talking to central IT but the patterns still are pretty well understood

42:13.920 --> 42:19.920
so I think in terms of the on getting their data story together I would say most organizations are

42:20.480 --> 42:26.720
are in reasonably even shape in terms of solving that that core problem it's of course it's a

42:26.720 --> 42:31.120
much harder challenge to solve for the larger companies which is why it's sort of admirable that

42:31.120 --> 42:36.400
they've done it over the last you know a couple of decades but that is reasonably in good shape

42:36.400 --> 42:41.680
the continuing challenge in both large companies and small companies is okay yes you have data

42:41.680 --> 42:47.680
but if you want to run a particular kind of analysis on it that data has to be transformed in some

42:47.680 --> 42:53.920
way first just to make things efficient and to make things manageable and as those use cases come

42:53.920 --> 43:00.080
in every single day from every single part of your company what happens over three four five years

43:00.080 --> 43:04.800
is you have you know the same data is now like stored in these different forms it's used for these

43:04.800 --> 43:10.400
different use cases as a massive ETL and pipelining thing that you're running to just make sure everything

43:10.400 --> 43:15.760
stays up to date and then this continuously there are new requirements where you to figure out does

43:15.760 --> 43:20.400
this have I already solved this somewhere and that's a hard problem to like that's a hard ask right

43:20.400 --> 43:25.040
because no one quite understands the catalog as well as they showed and things like that

43:25.040 --> 43:29.120
and then if I've solved this somewhere but there are some small changes neither how difficult it

43:29.120 --> 43:35.120
is to make that change so just change management structure management data management at that level

43:35.120 --> 43:39.280
I think is super hard for companies at all levels right it doesn't matter how large you are

43:39.280 --> 43:43.680
the requirements keep changing there's no you cannot have solved this problem completely it's just

43:43.680 --> 43:49.920
not possible yeah I'm just reflecting on you know many years ago talking to folks at you know

43:49.920 --> 43:56.160
cloud era horton works about you know data lakes when we were first starting to talk about this as

43:56.160 --> 44:01.120
an idea and how it was going to going to be the end of ETL we wouldn't need to do ETL anymore

44:01.120 --> 44:09.760
um I think companies are doing a lot more ETL to your point not less yes and uh you know machine

44:09.760 --> 44:15.280
learning is is just one more driver for that yeah it turns out like the data explosion was just step

44:15.280 --> 44:20.880
one step two was the use case explosion right and every use case brought like this massive numbers

44:20.880 --> 44:24.400
of changes that had to be made to how you store and manage this data so that the use case

44:24.400 --> 44:30.880
been more efficient and yeah so I think that's you're right like so ML AI is just another explosion

44:30.880 --> 44:36.400
in terms of like what's possible now and that leads to a bunch of changes you know and the challenges

44:36.400 --> 44:42.640
are so basic right like I was speaking to an organization um a couple of months back where they have

44:42.640 --> 44:48.240
a bunch they have these data scientists their challenge was like I asked them like what what is your

44:48.240 --> 44:52.560
hardware set up look like they describe the hardware set up to me I said like so where are your

44:52.560 --> 44:56.000
GPUs they're like we don't have GPUs I said why don't you have GPUs it makes no sense because

44:56.000 --> 44:59.680
they're it's really advanced they're doing a lot of really interesting work uh clearly they could

44:59.680 --> 45:08.400
use it and the response was like our IT um doesn't like GPUs are not on the approved purchase list

45:08.400 --> 45:15.040
by IIT right so it doesn't matter like I have asked multiple people you have gone through the channels

45:15.040 --> 45:20.160
like it is just not approved like there is no approved GPU that they can purchase and so they were

45:20.160 --> 45:25.600
really excited because I was also talking to them at the time about our hybrid cloud story and how

45:25.600 --> 45:29.600
we work on the cloud and on-prem and all these things and the the only question during the

45:29.600 --> 45:35.760
presentation was okay so in your cloud platform how can I prove it's a GPU and I showed them

45:35.760 --> 45:41.200
there's a slider right and and that's it and then they were like and then the second set of

45:41.200 --> 45:47.120
challenges of okay I have to convince my central data teams that it's okay to move to the cloud

45:47.120 --> 45:50.880
for some of this data that I need they were willing to take that on because they were like okay

45:50.880 --> 45:54.080
it solves all these other problems for us at least that we don't have a little bit right so

45:54.880 --> 46:00.160
I don't know it's that's going to be my question yeah right it's such an interesting world we

46:00.160 --> 46:04.000
live in right and things change all the time and and all these organizations have to try to move

46:04.000 --> 46:09.440
with it and and there's yeah it's it's fascinating yeah well just to wrap things up we started talking

46:09.440 --> 46:16.160
about use cases and then you brought up this very uh you know if we can call it a mundane challenge

46:16.160 --> 46:22.560
that organizations have to deal with and there is this tension uh yes you get this especially when

46:22.560 --> 46:29.760
talking to folks at the leadership levels of data and MLAI organizations between kind of these

46:30.960 --> 46:36.160
inspirational use cases that get folks excited and you know get them all their funding

46:37.200 --> 46:45.520
and the you know the mundane get on first base low hanging fruit that still abounds in many many

46:45.520 --> 46:54.080
organizations and I'm curious your you know perspective on how the organizations that you talk to

46:55.600 --> 47:01.760
you know manage the you know the tension between these two types of use cases and you know if there

47:01.760 --> 47:08.000
are any you know stories that you've heard about how folks have you know have moved forward given

47:08.000 --> 47:15.840
how that right so I think the the one thing I've seen that's um that's changed recently is that

47:15.840 --> 47:22.640
MLAI techniques are becoming a standard part of the typical business analysis business

47:22.640 --> 47:27.600
intelligence that organizations do as well so I guess what's happening is it's it's genuinely

47:27.600 --> 47:31.840
getting you know this is a very overuse term but those those requirements are getting a lot more

47:31.840 --> 47:36.160
democratized and a lot more people are thinking about how can I do more of this just because

47:36.160 --> 47:40.720
us the state that the technology is in so from an organizational perspective I think there are two

47:40.720 --> 47:47.360
things happening there continues to be this high level pie in the sky sort of thing off like

47:47.360 --> 47:53.760
here's this amazing thing that we can do right with AI and ML there's also this on the ground

47:53.760 --> 47:59.680
consistent movements towards more and more advanced analytics and more and more interesting

47:59.680 --> 48:05.360
insights and predictions that can be made from the data today that's also an ongoing movement

48:05.360 --> 48:11.200
I certainly think that that latter part is the way for most organizations to get started

48:11.200 --> 48:15.360
just be a little more grounded in where you are try to make that a little bit better try to add

48:15.360 --> 48:20.720
in these things that makes sense and then sure you can have the the visionary thought on on what

48:20.720 --> 48:26.240
else you can do and you can spend you know some of your cycles on that but it's important to just

48:26.240 --> 48:32.080
up level org wide uh what you can do with all of your data and and how you can understand your

48:32.080 --> 48:37.120
business by using all of these techniques rather than just you don't go for the one or two crazy

48:37.120 --> 48:42.320
ideas which you know which work as we know sometimes also so yeah it's it's impossible to say don't

48:42.320 --> 48:49.120
do them either so great great well so she was great catching up with you thanks so much for taking

48:49.120 --> 48:55.840
a time to reflect on this series of round tables with me yeah very nice talking to you as well

48:55.840 --> 49:07.760
Sam thanks for your time thank you

