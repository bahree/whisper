WEBVTT

00:00.000 --> 00:15.920
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

00:15.920 --> 00:20.880
people doing interesting things in machine learning and artificial intelligence.

00:20.880 --> 00:23.640
I'm your host Sam Charrington.

00:23.640 --> 00:28.200
This week on the podcast, we're featuring a series of conversations from the Nips conference

00:28.200 --> 00:30.480
in Long Beach, California.

00:30.480 --> 00:34.400
This was my first time at Nips and I had a great time there.

00:34.400 --> 00:37.600
I attended a bunch of talks and of course learned a ton.

00:37.600 --> 00:43.800
I organized an impromptu roundtable on building AI products and I met a bunch of wonderful

00:43.800 --> 00:47.920
people including some former Twimble Talk guests.

00:47.920 --> 00:52.760
I'll be sharing a bit more about my experiences at Nips via my newsletter, which you should

00:52.760 --> 00:59.440
take a second right now to subscribe to at twimblei.com slash newsletter.

00:59.440 --> 01:05.080
This week through the end of the year, we're running a special listener appreciation contest

01:05.080 --> 01:09.840
to celebrate hitting one million listens on the podcast and to thank you all for being

01:09.840 --> 01:11.800
so awesome.

01:11.800 --> 01:16.480
Tweet to us using the hashtag twimble1mil to enter.

01:16.480 --> 01:21.120
Everyone who enters is a winner and we're giving away a bunch of cool Twimble swag and

01:21.120 --> 01:23.120
other mystery prizes.

01:23.120 --> 01:29.920
If you're not on Twitter or want more ways to enter, visit twimblei.com slash twimble1mil

01:29.920 --> 01:32.360
for the full rundown.

01:32.360 --> 01:36.720
Before we dive in, I'd like to thank our friends over at Intel Nirvana for their sponsorship

01:36.720 --> 01:39.920
of this podcast and our Nips series.

01:39.920 --> 01:44.960
While Intel was very active at Nips with a bunch of workshops, demonstrations and poster

01:44.960 --> 01:50.680
sessions, their big news this time was the first public viewing of the Intel Nirvana

01:50.680 --> 01:54.480
Neural Network Processor or NNP.

01:54.480 --> 01:59.400
The goal of the NNP architecture is to provide the flexibility needed to support deep learning

01:59.400 --> 02:04.520
primitives while making the core hardware components as efficient as possible, giving

02:04.520 --> 02:10.000
neural network designers powerful tools for solving larger and more difficult problems

02:10.000 --> 02:14.640
while minimizing data movement and maximizing data reuse.

02:14.640 --> 02:20.480
To learn more about Intel's AI products group and the Intel Nirvana NNP, visit Intel

02:20.480 --> 02:22.640
Nirvana.com.

02:22.640 --> 02:28.640
In this episode, I'm joined by Sarah Jennings, Timothy Sebrick and Andres Rodriguez to discuss

02:28.640 --> 02:32.560
NASA's Frontier Development Lab or FDL.

02:32.560 --> 02:39.000
The FDL is an intense eight week applied AI research accelerator, focusing on tackling

02:39.000 --> 02:42.480
knowledge gaps useful to the space program.

02:42.480 --> 02:47.640
In our discussion, Sarah, producer at the FDL, provides some insight into its goals

02:47.640 --> 02:49.320
and structure.

02:49.320 --> 02:54.440
Timothy, a researcher at FDL, describes his involvement with the program, including

02:54.440 --> 02:57.680
some of the projects he worked on while on-site.

02:57.680 --> 03:03.120
He also provides a look into some of this year's FDL projects, including planetary defense,

03:03.120 --> 03:07.600
solar storm prediction and lunar water location.

03:07.600 --> 03:13.880
Last but not least, Andres, senior principal engineer at Intel's AI products group joins

03:13.880 --> 03:19.080
us to detail Intel's support of the FDL and how the various elements of the Intel AI

03:19.080 --> 03:22.080
stack supported the FDL research.

03:22.080 --> 03:26.920
This is a jam-packed conversation, so be sure to check out the show notes at twimlai.com

03:26.920 --> 03:32.200
slash talk slash 89 for all the links and tidbits from this episode.

03:32.200 --> 03:35.520
And now on to the show.

03:35.520 --> 03:46.080
Alright everyone, I'm here in Long Beach at the Nip's conference, and I have the pleasure

03:46.080 --> 03:51.040
of being joined by Sarah Jennings, who is the producer and NASA's Frontier Development

03:51.040 --> 03:58.120
Lab, Timothy Seabrook, NASA Frontier Development Lab researcher via the City Institute at University

03:58.120 --> 04:05.960
of Oxford, and Andres Rodriguez, senior principal engineer at Intel's AIPG.

04:05.960 --> 04:10.040
And I am really excited to have a chance to talk a little bit about this program that

04:10.040 --> 04:15.280
you're all involved in and share it with the folks listening to the podcast.

04:15.280 --> 04:16.280
So welcome everyone.

04:16.280 --> 04:17.280
Thank you.

04:17.280 --> 04:18.280
Happy to be here.

04:18.280 --> 04:19.280
Absolutely.

04:19.280 --> 04:22.600
Why don't we get started by just kind of going around the table and doing intros.

04:22.600 --> 04:24.600
We'll start with you Sarah.

04:24.600 --> 04:28.720
Great, so I'm the producer for NASA Frontier Development Lab, which means I get the really

04:28.720 --> 04:33.520
cool job of working with the researchers for different challenges over the summer throughout

04:33.520 --> 04:35.120
our program.

04:35.120 --> 04:40.080
And previously I've worked in emerging tech and innovation at X-Prize, where I did prize

04:40.080 --> 04:44.520
design and operations, and I've done a lot of work with the private space industry

04:44.520 --> 04:45.520
as well.

04:45.520 --> 04:46.520
Awesome.

04:46.520 --> 04:47.520
Awesome.

04:47.520 --> 04:48.520
Andres?

04:48.520 --> 04:49.520
Yeah, thanks for having me here.

04:49.520 --> 04:55.000
As engineering and intelligent engineering tell me with various customers to understand their

04:55.000 --> 04:57.880
workloads and build solutions for them.

04:57.880 --> 05:03.320
And I work with a lot of other Intel teams to provide to build a solution for our customers.

05:03.320 --> 05:09.520
The solutions may be anywhere from designing models for their particular problems.

05:09.520 --> 05:16.720
So deep learning models or optimizing their algorithms so that they run efficiently on Intel

05:16.720 --> 05:17.920
architecture.

05:17.920 --> 05:24.920
I've been working on AI for about 13 years in an exciting area to be especially over the

05:24.920 --> 05:30.360
past four years, five years to see the tremendous growth and interest for the community in this

05:30.360 --> 05:31.360
area.

05:31.360 --> 05:32.360
Absolutely.

05:32.360 --> 05:33.360
How about you, Tim?

05:33.360 --> 05:38.560
So, as you mentioned previously during my PhD at the University of Oxford, I come from

05:38.560 --> 05:41.640
quite a multi-disciplinary background.

05:41.640 --> 05:46.560
So I've studied under engineering, computer science and communication systems, and that's

05:46.560 --> 05:51.920
given me quite a broad view of technology and also of the machine learning field.

05:51.920 --> 05:57.880
So right now I'm focusing and I'm super interested in verification of learning and multi-agent

05:57.880 --> 06:03.040
systems so that hopefully we can have a bit of specification about these learning agents

06:03.040 --> 06:07.680
so that they might be able to be deployed and used in public grounds because of the minute

06:07.680 --> 06:11.800
you know, it can be a little bit risky to put something out that learns without knowing

06:11.800 --> 06:12.800
what it could learn.

06:12.800 --> 06:14.560
So that's my focus there.

06:14.560 --> 06:19.520
Yeah, I was super happy to go along to the Frontier Development Lab over the summer being

06:19.520 --> 06:20.920
based at NASA.

06:20.920 --> 06:26.080
That was a great opportunity and a great experience and I'm happy to be continuing involvement

06:26.080 --> 06:27.080
with that going forward.

06:27.080 --> 06:29.040
And what was your role with the program?

06:29.040 --> 06:30.080
I was a researcher there.

06:30.080 --> 06:35.440
I applied through the normal means, the application process, got to meet James and Sarah first

06:35.440 --> 06:37.200
online and then in person.

06:37.200 --> 06:41.200
So there were a number of projects that were involved at the Frontier Development Lab and

06:41.200 --> 06:45.480
I was involved in one of those which was the exploration of lunar water and volatiles.

06:45.480 --> 06:46.480
Okay.

06:46.480 --> 06:50.000
Actually, I'll talk a little bit, I guess a little bit about that now.

06:50.000 --> 06:51.560
We can dig into that in a second.

06:51.560 --> 06:56.080
For now probably makes sense to get a little bit more context on FDL as a whole and what

06:56.080 --> 06:59.480
the mission is, Sarah, what can you tell us about FDL?

06:59.480 --> 07:06.880
Yeah, so FDL is an applied artificial intelligence research accelerator and it was kind of

07:06.880 --> 07:13.160
started with the premise of bringing back the Apollo era of interdisciplinary teams paired

07:13.160 --> 07:17.560
with rapid innovation and so during that time they would bring together the comms team

07:17.560 --> 07:21.480
with the life support team and the propulsion team all in the same room so that they could

07:21.480 --> 07:24.160
work on advancing things faster.

07:24.160 --> 07:27.360
And so that was really where this started from.

07:27.360 --> 07:33.680
It started in 2016 with asteroid grant challenge where they mostly focused on planetary defense

07:33.680 --> 07:39.440
problems and now we're moving on to your three because the program has been so successful.

07:39.440 --> 07:45.160
So we bring together researchers from AI fields and we pair them with planetary scientists

07:45.160 --> 07:49.240
and we work on challenges that are of interest to NASA.

07:49.240 --> 07:50.240
Hmm.

07:50.240 --> 07:54.600
And now I've heard this description before and every time planetary defense is said I

07:54.600 --> 07:57.280
think of like defending us against aliens.

07:57.280 --> 07:59.480
What does that mean to you?

07:59.480 --> 08:04.440
Yeah, so the challenges that we focused on were asteroids and long period comms for this

08:04.440 --> 08:05.440
past year.

08:05.440 --> 08:06.440
Okay.

08:06.440 --> 08:09.720
So it's mainly detection and understanding them a little bit better.

08:09.720 --> 08:14.960
So if there was an asteroid that was coming towards us we'd have a little bit more of understanding

08:14.960 --> 08:17.360
of mitigation strategies and things like that.

08:17.360 --> 08:18.360
Okay.

08:18.360 --> 08:23.720
So it actually is protecting us from things that are hurling towards us from space.

08:23.720 --> 08:30.880
And so tell us about the program, what's the structure of the FDL program and how, you

08:30.880 --> 08:33.320
know, how's it organized, who's involved?

08:33.320 --> 08:36.760
Yeah, so it is a public private partnership.

08:36.760 --> 08:41.600
So it's with NASA Ames and hosted at the study institute and then we are able to bring

08:41.600 --> 08:46.760
a lot of our private partners and which allows us to bring in researchers and mentors from

08:46.760 --> 08:48.080
around the world.

08:48.080 --> 08:53.560
It is an eight week program that takes place out at NASA Ames and Silicon Valley where

08:53.560 --> 08:58.360
we bring in about 24 researchers and put them on teams of four.

08:58.360 --> 09:02.120
For that eight week program it starts out with a bootcamp where everybody gets an understanding

09:02.120 --> 09:07.400
of all the problems and then it goes into brainstorming different approaches to work

09:07.400 --> 09:08.840
on solutions for them.

09:08.840 --> 09:09.840
Okay.

09:09.840 --> 09:12.560
And then they do rapid prototyping during that time.

09:12.560 --> 09:15.960
But then after the program ends it doesn't, the work doesn't end.

09:15.960 --> 09:19.560
We do a lot of continuity work and Tim will talk a little bit more about what he's doing

09:19.560 --> 09:20.560
with Intel later.

09:20.560 --> 09:26.200
Okay, and the researchers that you've referred to, they're all or predominantly PhD students

09:26.200 --> 09:27.200
or it is a very.

09:27.200 --> 09:28.200
It varies.

09:28.200 --> 09:32.760
We had a mix of PhDs, postdocs, and individuals in the industry that actually took sabbaticals

09:32.760 --> 09:33.760
from their job.

09:33.760 --> 09:34.760
Oh wow.

09:34.760 --> 09:37.480
And we had an astronomer from Brazil, so it's quite a combination.

09:37.480 --> 09:40.000
It's a really high caliber of people that we bring in.

09:40.000 --> 09:41.000
Oh, very cool.

09:41.000 --> 09:42.000
Very cool.

09:42.000 --> 09:46.000
So Tim, why don't you give us an overview of the types of research that the different teams

09:46.000 --> 09:47.000
worked on?

09:47.000 --> 09:51.840
Sure, so I'm sure you're aware there's a lot of excitement around the field of deep learning

09:51.840 --> 09:52.840
at the moment.

09:52.840 --> 09:53.840
Really?

09:53.840 --> 09:57.200
I'm not sure if you noticed.

09:57.200 --> 10:05.200
Yeah, so I guess to start off with expanding what Sarah mentioned was, it seemed like the

10:05.200 --> 10:08.760
goal of the Frontier Development Lab was really to empower talented scientists who have

10:08.760 --> 10:14.120
been working the field for a long time with these new technologies and enable them to

10:14.120 --> 10:16.960
achieve more than they've been able to previously.

10:16.960 --> 10:23.160
So we were very much looking, and the bootcamp was incredibly helpful to be talking to

10:23.160 --> 10:27.000
NASA scientists and really understand the state of the game when it comes to space and

10:27.000 --> 10:28.960
what's been done and what needs to be done next.

10:28.960 --> 10:31.720
Was that an area that you had any experience with going in?

10:31.720 --> 10:36.400
I mean, as a hobbyist, you know, we're all nerds at the Frontier Development Lab.

10:36.400 --> 10:40.800
We all have a little bit of space, a bit of Star Trek, a bit of Star Wars and stuff

10:40.800 --> 10:41.800
like that.

10:41.800 --> 10:47.240
I don't know, yeah, as a hobbyist from Space News, I was fairly aware of things, but not

10:47.240 --> 10:50.640
to the depth of NASA scientists, of course, have been working a field for 40 years.

10:50.640 --> 10:55.480
Throughout that bootcamp week, we really did come to understand what was going on and sort

10:55.480 --> 10:57.920
of did have to explore where we could contribute.

10:57.920 --> 11:03.960
So we had the artistic freedom to explore and do the prototyping and work out where our

11:03.960 --> 11:07.760
skills as individuals aligned with the needs of the group.

11:07.760 --> 11:12.040
So each individual team came up with their own custom solution to the problems they

11:12.040 --> 11:13.040
were facing.

11:13.040 --> 11:17.600
So a lot of it was, so for my team, it was image classification, similarly for long period

11:17.600 --> 11:21.360
comments, looking at cameras situated around the world.

11:21.360 --> 11:25.040
Sarah, do you know what the name of the camera's project?

11:25.040 --> 11:26.040
Cam's project.

11:26.040 --> 11:27.040
Okay.

11:27.040 --> 11:34.720
Yeah, so what the goal of that is is to detect objects coming through the atmosphere and

11:34.720 --> 11:38.600
identifying when it isn't object and it's not just a bat or a firebug that's gone in

11:38.600 --> 11:42.400
front of the lens and doing that autonomously because people have been doing that for 40

11:42.400 --> 11:45.160
years by hand, which is incredibly arduous.

11:45.160 --> 11:52.040
The asteroid shape modeling team were using variational auto encoders to try and transfer

11:52.040 --> 11:57.760
Doppler shift images, which are incredibly unintuitive into a 3D model so that the shapes

11:57.760 --> 12:01.520
of asteroids and the distribution of the shapes of asteroids can be better understood

12:01.520 --> 12:07.520
the team was working on invasion techniques to ensure that there was, to encode the knowledge

12:07.520 --> 12:12.760
of the NASA scientists into a prior distribution so that the shapes that came out made sense.

12:12.760 --> 12:16.720
So the weather prediction teams, they were looking at predicting when a coronal mass

12:16.720 --> 12:20.680
ejection might come out, which would be quite catastrophic if it does, when a coronal

12:20.680 --> 12:22.160
mass ejection.

12:22.160 --> 12:27.160
So when a magnetic band within the sun sort of snaps and it ejects a huge plume of

12:27.160 --> 12:32.000
heart plasma through the solar system and the Earth luckily has a magnetic field that

12:32.000 --> 12:37.040
protects us from most of that, but if we get hit by a 1 or 2 or several waves then it

12:37.040 --> 12:42.760
can be quite catastrophic and damage satellites of course, it could be dangerous for people

12:42.760 --> 12:43.760
on space stations.

12:43.760 --> 12:46.040
How often does this kind of thing happen?

12:46.040 --> 12:48.240
So there was the Carrington event in...

12:48.240 --> 12:49.240
The Carrington event.

12:49.240 --> 12:50.240
Carrington event.

12:50.240 --> 12:51.240
Yeah, that was the...

12:51.240 --> 12:52.240
No relation to Carrington.

12:52.240 --> 12:53.240
My last name.

12:53.240 --> 12:59.440
Yeah, that was the last major one, but they haven't happened quite frequently.

12:59.440 --> 13:03.840
So I think it was around late 19th century, so there wasn't too much electricity around

13:03.840 --> 13:06.200
by then, so it wasn't too damaging to that.

13:06.200 --> 13:09.880
It went largely under my notice, apart from in Canada I believe, it was where it was

13:09.880 --> 13:11.120
noticed the most.

13:11.120 --> 13:16.880
So that caused some great northern lights to show up, so people were really loving that,

13:16.880 --> 13:19.840
but it would be a little bit more damaging now.

13:19.840 --> 13:26.160
But yeah, I believe there are smaller events happening quite a lot, and I mean, we're

13:26.160 --> 13:31.400
a small dart in a solar system, so a lot of the time they'll miss us, which is fortunate.

13:31.400 --> 13:36.120
Yeah, I mean, in day-to-day life, they can affect things like GPS, mobile phone signals,

13:36.120 --> 13:37.120
things like that.

13:37.120 --> 13:38.120
Okay.

13:38.120 --> 13:41.880
So we really need to have a prediction of when one of these events might happen, and

13:41.880 --> 13:46.360
the way you do that is by monitoring the hyperspecial images of the sun's surface

13:46.360 --> 13:47.880
what you can see.

13:47.880 --> 13:54.520
So we had the team there was using LSTM, which is a type of neural network, often used

13:54.520 --> 13:56.360
for neural linguistic programming.

13:56.360 --> 14:01.640
It's long short-term memory, that's what the LSTM stands for, so that takes into account

14:01.640 --> 14:05.800
the long-term history of the sun's activity as well as the short-term, so it is quite

14:05.800 --> 14:08.600
useful in financial predictions as well.

14:08.600 --> 14:13.960
We also had the other teams, so the terrestrial interaction, they had a hard time.

14:13.960 --> 14:14.960
Terrestrial interactions?

14:14.960 --> 14:15.960
So the terrestrial.

14:15.960 --> 14:16.960
Terrestrial interaction.

14:16.960 --> 14:20.440
So that happens when the solar activity does hit the earth.

14:20.440 --> 14:24.880
And how that might affect electrical companies, how that might affect markets and things

14:24.880 --> 14:26.280
like this.

14:26.280 --> 14:30.160
And it's really difficult to get a hold of the law of that data.

14:30.160 --> 14:33.920
I mean, and then just for that problem or for all of these problems that we've discussed?

14:33.920 --> 14:38.400
Well, luckily there is a huge wealth of public data for most of these things, particularly

14:38.400 --> 14:40.000
when it comes to looking at the moon.

14:40.000 --> 14:44.000
It's up there we've got, it's fortunately NASA's a public entity.

14:44.000 --> 14:46.000
So all the work they do, well, a lot of the data that they do, they do, they do, they

14:46.000 --> 14:51.280
are a lot of the data that they do is available to the public, which is great for hobbyists.

14:51.280 --> 14:57.000
So yeah, the solar terrestrial interaction team was pulling as much data as they could

14:57.000 --> 15:02.200
from disparate sources, from insurance companies, from claims of damage that have been done

15:02.200 --> 15:08.360
to transformers and things like this and trying to find a model to describe, particularly

15:08.360 --> 15:12.960
what the cost of damage could be if one of these events happens, so they ended up using

15:12.960 --> 15:16.560
a wide variety of techniques and machine learning and, for instance, and funding together

15:16.560 --> 15:18.880
and see where they could come out with.

15:18.880 --> 15:22.680
And I guess last but not least the work that the team I was on was working on.

15:22.680 --> 15:23.680
We had a good team.

15:23.680 --> 15:29.000
There's Deep Mar Backus, who is a, he does a lot of mapping problems and a lot of, yeah,

15:29.000 --> 15:31.680
a lot of synthesis of maps and working on those.

15:31.680 --> 15:36.160
Eleni Beowichek, who does computer vision for Mars Rovers.

15:36.160 --> 15:42.120
We had Nate Amusa, who was one of those, for those from industry, who comes from a strong

15:42.120 --> 15:44.160
understanding of computer vision.

15:44.160 --> 15:49.200
Myself and also we were supported by Tony Dubovowski, who is a planetary scientist, particularly

15:49.200 --> 15:52.720
interested in creative formations, which was incredibly useful.

15:52.720 --> 15:54.240
And so what was your project?

15:54.240 --> 16:00.200
So the project was to find a way to facilitate the investigation and the quantification

16:00.200 --> 16:07.720
of how much water or volatile is refocused on water is on the lunar surface.

16:07.720 --> 16:09.880
And there's potentially quite a lot.

16:09.880 --> 16:14.480
I was surprised to learn this because you know, there's a lot of discussion about, maybe

16:14.480 --> 16:19.160
there's water on Mars, maybe there's water on one of the moons of Jupiter or Saturn.

16:19.160 --> 16:23.640
But it seems there's a lot, quite a lot closer to home.

16:23.640 --> 16:29.400
Sarah, I'm curious from your perspective, why is, you know, in one sense, there's, you

16:29.400 --> 16:32.520
know, it's obvious that we'd be interested in exploring, you know, water on the moon,

16:32.520 --> 16:37.600
but how, you know, what are, how does NASA think about the reason why this is important

16:37.600 --> 16:42.680
and maybe you can also touch on some of the, you know, how do we know there's water

16:42.680 --> 16:43.680
on the moon?

16:43.680 --> 16:44.680
Yeah.

16:44.680 --> 16:50.080
So I can touch a little bit on that without overstepping, but so the reason NASA is focused

16:50.080 --> 16:54.480
on the moon currently is because with this new administration we're focused on going

16:54.480 --> 16:55.640
back to the moon.

16:55.640 --> 17:00.680
So the reason why later resources is important and Tim can also share a little bit more about

17:00.680 --> 17:06.120
that is that those resources are very expensive to move from the earth into space.

17:06.120 --> 17:11.360
And so if you already have those resources there, then you could utilize them for fuel

17:11.360 --> 17:16.920
or for other things potentially like settlements and things where you don't have to import those

17:16.920 --> 17:17.920
materials there.

17:17.920 --> 17:18.920
Mm-hmm.

17:18.920 --> 17:21.560
So that's another, another way there.

17:21.560 --> 17:22.560
Okay.

17:22.560 --> 17:27.440
And I heard an anecdote about the first discovery of water on the moon, like how do we,

17:27.440 --> 17:28.440
Oh.

17:28.440 --> 17:29.440
Yeah.

17:29.440 --> 17:31.000
So it was the lacrosse mission.

17:31.000 --> 17:35.880
So the Apollo, some Apollo 15 rock samples showed water in them, but, you know, there was

17:35.880 --> 17:38.920
disputed whether or not they've been contaminated and things like this.

17:38.920 --> 17:39.920
Right.

17:39.920 --> 17:42.480
So there was seeking for further evidence.

17:42.480 --> 17:47.200
So there were a couple more missions, one from NASA, one from the Indian Space Agency,

17:47.200 --> 17:53.200
which involved sending an impactor into a crater on the South Pole that never sees sunlight.

17:53.200 --> 17:58.280
So I can explain a little bit maybe why that was the reason, but why that was chosen.

17:58.280 --> 18:04.240
So the impactor wouldn't hit the surface, it was basically crashing a ship into a vehicle

18:04.240 --> 18:06.560
of some sort into the side of the crater.

18:06.560 --> 18:07.560
Yeah.

18:07.560 --> 18:11.080
And the ejecto plume that came out, all the dust that was kicked up, spectral reading

18:11.080 --> 18:16.760
was taken of that and showed, I believe, about 4.6 percent water in a form of ice particles.

18:16.760 --> 18:17.760
I imagine.

18:17.760 --> 18:18.760
Yeah.

18:18.760 --> 18:22.640
I'm not sure because the impact of the energy might have vaporized some of it, but yeah,

18:22.640 --> 18:26.040
in its stable form it would have been ice, yeah.

18:26.040 --> 18:31.080
So yeah, the reason that they were targeting permanently shadowed craters is because I

18:31.080 --> 18:36.200
mean, if you consider that of the last 4 billion years, every meteor and comet that's impacted

18:36.200 --> 18:40.720
on the moon has had the potential to contain some rare earth metals and some water.

18:40.720 --> 18:42.640
All of that's been deposited.

18:42.640 --> 18:47.480
Some of it will evaporate, some of it will escape the atmosphere, but some of it will get stuck

18:47.480 --> 18:50.280
in the bottom of the craters that are at 40 Kelvin.

18:50.280 --> 18:54.000
So anything that goes in there freezes and gets stuck there potentially forever.

18:54.000 --> 18:55.000
Okay.

18:55.000 --> 18:58.640
So it's considered that might be, you know, the great wealth, the bank of resources that

18:58.640 --> 19:01.240
was available on the moon.

19:01.240 --> 19:05.960
And the role of your team was to basically figure out how much of this stuff might exist.

19:05.960 --> 19:09.640
And the role of our team was to work out how we could contribute to the accessing of

19:09.640 --> 19:10.640
it, right?

19:10.640 --> 19:11.640
Using machine learning.

19:11.640 --> 19:12.640
Right.

19:12.640 --> 19:13.720
So yeah, we started off.

19:13.720 --> 19:21.320
So right now, as I understand, an objective would be to exactly investigate, understand

19:21.320 --> 19:26.840
how much there is, understand if it's economically viable to set up a base there or to send

19:26.840 --> 19:32.720
further missions, the way you do that is with rovers, is with in situ resource measurements.

19:32.720 --> 19:37.080
So we were looking firstly, looking at traverse planning, rovers have to stay in sunlight

19:37.080 --> 19:40.880
all the whole time with a solar powered or for as long as possible anyway.

19:40.880 --> 19:44.480
They have to stay in direct communication with the earth a lot of the time, so the moon's

19:44.480 --> 19:45.480
quite close.

19:45.480 --> 19:47.080
So usually it's still human operated.

19:47.080 --> 19:49.800
When there's a rover up there, it's only a second or two delay.

19:49.800 --> 19:53.880
So we were looking at that problem and then we realized that, you know, there were some

19:53.880 --> 19:59.160
other work that needed to be done before that to facilitate that sort of advancement.

19:59.160 --> 20:00.520
And what was that other work?

20:00.520 --> 20:06.400
So in doing the traverse planning, we realized that it's the maps weren't in the highest

20:06.400 --> 20:11.480
quality that we had come to expect, you know, maybe lately we thought the moon's just above

20:11.480 --> 20:16.520
us that the maps should be complete, right, right, regions where there is permanent shadow,

20:16.520 --> 20:21.720
visual images are difficult to to grab and also as the, you know, reconnaissance orbiter,

20:21.720 --> 20:25.840
which is where we took our data from, as that's orbited the moon, thousands and thousands

20:25.840 --> 20:31.640
of time and built a laser altimeter sort of height map readings, a stitching and the composite

20:31.640 --> 20:36.880
images that are formed have created artifacts which to a rover and a rover's eyes look like

20:36.880 --> 20:38.960
20 foot clips and 20 foot digits.

20:38.960 --> 20:39.960
So when you're trying to...

20:39.960 --> 20:40.960
They aren't actually there.

20:40.960 --> 20:41.960
That may not be.

20:41.960 --> 20:42.960
Yeah, actually there.

20:42.960 --> 20:44.920
Yeah, but a lot of them aren't.

20:44.920 --> 20:48.960
So you can just smooth over because, I mean, a rovers an expensive thing to put on a moon

20:48.960 --> 20:53.560
you don't have to fall down one of these digits, if it is real, but also you can't do an automated

20:53.560 --> 20:57.320
plan until you've worked out which ones are your own which ones aren't.

20:57.320 --> 20:59.760
Okay, so that became the focus of our continued work.

20:59.760 --> 21:00.760
Okay.

21:00.760 --> 21:05.400
And there was also an element of your work that involved trying to count the number of

21:05.400 --> 21:06.760
craters on the moon.

21:06.760 --> 21:08.640
So where did that come in?

21:08.640 --> 21:09.640
The lunar surface.

21:09.640 --> 21:13.640
I suppose every time a picture of the lunar surface has been taken, there's no GPS,

21:13.640 --> 21:14.640
right?

21:14.640 --> 21:17.240
So you don't know exactly where that photo is.

21:17.240 --> 21:22.160
But thankfully, craters being so abundant, form a sort of fingerprint that allows you

21:22.160 --> 21:25.000
to uniquely identify what you're looking at.

21:25.000 --> 21:30.080
And by matching that in a visual image with the elevation model, then you can compare

21:30.080 --> 21:34.520
what the artifacts might be in the elevation model with the visual images.

21:34.520 --> 21:38.840
And then if it's in one but not the other, then you know it doesn't exist.

21:38.840 --> 21:42.800
If it's in both, then you know, okay, that is a ditch that I need to watch out for.

21:42.800 --> 21:47.840
And maybe going back to more fundamental kind of space question, like how many craters

21:47.840 --> 21:48.840
are on the moon?

21:48.840 --> 21:49.840
Oh gosh.

21:49.840 --> 21:51.160
More than we can count.

21:51.160 --> 21:52.360
More than we can count.

21:52.360 --> 21:57.640
Are these craters that were all created with the creation of the moon itself or are these

21:57.640 --> 22:01.480
craters a result of impact like comments or other things?

22:01.480 --> 22:05.880
So I believe there's 10 notable fresh impacts per day.

22:05.880 --> 22:10.920
So we looked at around 40 to 100,000 craters.

22:10.920 --> 22:13.760
And that was around 1,000th of a percent of the lunar surface.

22:13.760 --> 22:14.760
Wow.

22:14.760 --> 22:15.760
Yeah.

22:15.760 --> 22:16.760
They're coming every day.

22:16.760 --> 22:18.800
But I think a lot of it was historical.

22:18.800 --> 22:22.000
A lot of it has been in the past and it's come down a bit.

22:22.000 --> 22:23.000
But it's still going.

22:23.000 --> 22:24.600
There's still impacts every day, yes.

22:24.600 --> 22:25.600
Okay.

22:25.600 --> 22:28.520
Is the earth impacted that much by craters?

22:28.520 --> 22:31.720
Is it our magnetic field as you were describing earlier that protects us from that?

22:31.720 --> 22:34.920
Or do we get our fair share of those crater impacts as well?

22:34.920 --> 22:37.640
Like certainly the earth is in pocket with craters like the moon is.

22:37.640 --> 22:39.720
So we do get a lot of things coming through the atmosphere.

22:39.720 --> 22:43.360
You might see a shooting star every now again that's a small meteoroid coming through

22:43.360 --> 22:44.360
the atmosphere.

22:44.360 --> 22:47.400
The atmosphere is another protective shield for us.

22:47.400 --> 22:52.600
You know, the friction that the meteoroid comes under as it's entering causes it to burn

22:52.600 --> 22:54.400
up a lot of the time or break apart.

22:54.400 --> 22:56.160
So we do have that minor protection.

22:56.160 --> 23:00.800
Yeah, the planetary defense team, they're really looking at bigger asteroids that could

23:00.800 --> 23:02.120
be more deadly.

23:02.120 --> 23:06.360
So I think it was 10 years ago we thought there were maybe 16,000 of these.

23:06.360 --> 23:11.240
Now we know there's hundreds of thousands of potentially dangerous objects floating

23:11.240 --> 23:13.280
around the space.

23:13.280 --> 23:18.120
Luckily we've gotten much better at modeling where these are and understanding which ones

23:18.120 --> 23:23.360
could be dangerous and it looks like we're in a clearer at least for now.

23:23.360 --> 23:33.480
So to kind of take a step back, you're trying to ultimately understand the available resources

23:33.480 --> 23:36.400
on the moon in order to do that.

23:36.400 --> 23:42.880
One of the techniques involved was trying to understand actually was trying to plan out

23:42.880 --> 23:48.800
the rover mission or provide information that would be used in planning a rover mission.

23:48.800 --> 23:53.200
In order to do that, we need to understand how the maps all fit together.

23:53.200 --> 23:56.560
And in order to do that, we need to be able to identify the craters.

23:56.560 --> 23:57.560
Yeah.

23:57.560 --> 24:01.600
So this was really a keystone that would open up the possibility for future works to go

24:01.600 --> 24:02.600
ahead.

24:02.600 --> 24:10.120
And so what were the techniques and challenges involved in identifying the craters?

24:10.120 --> 24:13.280
I mean, main challenges came to even understanding the problem.

24:13.280 --> 24:16.960
I mean, it took a lot of, thank God we had the prototype in process.

24:16.960 --> 24:21.120
So we only came to understand that problem by trying to do the diverse plans.

24:21.120 --> 24:25.080
When it came to it, I think we were five weeks in program already.

24:25.080 --> 24:26.280
There were three weeks left.

24:26.280 --> 24:29.440
So we had a lot of late nights labeling all the data.

24:29.440 --> 24:34.080
So for any machine learning algorithm, you need to give it training examples, right?

24:34.080 --> 24:37.120
You need to teach it as though it's going through school.

24:37.120 --> 24:38.120
Right.

24:38.120 --> 24:42.800
So we had to collect images, representative images of craters and come to an

24:42.800 --> 24:48.120
agreeance of what the crater looks like so that we could feed that to our algorithm.

24:48.120 --> 24:49.120
Okay.

24:49.120 --> 24:50.760
That was surprisingly difficult actually.

24:50.760 --> 24:55.640
We had five people on the team and several others were helping us label these images.

24:55.640 --> 25:00.800
And to come to a consensus on which should be considered to be good representations of

25:00.800 --> 25:06.120
craters and which weren't and which were too ambiguous was a long process actually.

25:06.120 --> 25:11.080
Meaning full-fledged craters versus, you know, dips in the terrain or something like that.

25:11.080 --> 25:16.560
So one interesting thing we came across was that actually hills look exactly like craters

25:16.560 --> 25:18.880
depending on the angle of the light.

25:18.880 --> 25:22.360
So that was a little bit, after you were looking through thousands of these, everything started

25:22.360 --> 25:23.760
looking like a hill and you weren't sure anymore.

25:23.760 --> 25:28.080
You have to take a break every now and again to, you know, let me perception rest again.

25:28.080 --> 25:33.120
So yeah, it was the sheer number of training examples that we had to label ourselves and

25:33.120 --> 25:34.120
then.

25:34.120 --> 25:36.160
And so how many of these craters did you personally label?

25:36.160 --> 25:37.520
I looked through 40,000.

25:37.520 --> 25:38.520
Wow.

25:38.520 --> 25:43.240
There was a bottle of scotch nearby that definitely helped me through that process.

25:43.240 --> 25:44.240
Yeah.

25:44.240 --> 25:45.240
So we got through that.

25:45.240 --> 25:49.320
And then once we got to that training data, then it went through the iteration process of

25:49.320 --> 25:55.360
developing a computational network classifier, and thankfully we had Intel, Nirvana, and

25:55.360 --> 25:59.520
the technology there to help us go through that process quickly and we had the support

25:59.520 --> 26:04.680
of the Intel engineers to give us advice and support on how to use their framework most

26:04.680 --> 26:05.920
effectively.

26:05.920 --> 26:12.040
Was there anything that came up as kind of unique about training a model in this situation

26:12.040 --> 26:15.760
that you wouldn't expect in other, you know, applications of CNNs?

26:15.760 --> 26:22.200
I would imagine one of the things that is unique compared to what you usually find in academia

26:22.200 --> 26:24.880
you're focusing on two aspects.

26:24.880 --> 26:29.160
One is it's a binary, is this a crater or not?

26:29.160 --> 26:34.280
You're not trying to classify between thousands or hundreds of classes.

26:34.280 --> 26:38.320
And the second one is you are also doing detection.

26:38.320 --> 26:43.480
You don't, you're looking for the craters in large images.

26:43.480 --> 26:46.280
So the project essentially has these two steps.

26:46.280 --> 26:53.400
First, can you classify craters versus non-creators and second, can you then detect them in a large

26:53.400 --> 26:54.400
image?

26:54.400 --> 26:55.400
I don't know.

26:55.400 --> 26:57.160
If you have other things to add to.

26:57.160 --> 26:58.160
Yeah.

26:58.160 --> 27:03.000
So one of the particular problems with the crater detection was that there's just so many

27:03.000 --> 27:08.000
of them and they're all overlaying on each other and that's quite a difficult image classification

27:08.000 --> 27:09.000
problem.

27:09.000 --> 27:11.480
So if you're doing facial recognition, for example, you don't expect to see a face in

27:11.480 --> 27:16.120
a face in a face in a face or like a cluster of faces altogether.

27:16.120 --> 27:21.000
So that was definitely a challenge for the image classifier.

27:21.000 --> 27:27.600
Andres, maybe give us some perspective on why does Intel support a program like this?

27:27.600 --> 27:31.640
How does Intel think about engaging with programs like FTL?

27:31.640 --> 27:39.000
Intel wants to advance science and this is a great opportunity for Intel to partner

27:39.000 --> 27:46.920
both with researchers, with NASA engineers, with the NASA program to advance science.

27:46.920 --> 27:50.840
And in addition, Intel wants to democratize machine learning.

27:50.840 --> 27:57.320
So it was a great opportunity to work with engineers that many of them had not to not have

27:57.320 --> 28:03.800
a background in machine learning and give them the knowledge and the tools to use machine

28:03.800 --> 28:06.760
learning for a particular problem.

28:06.760 --> 28:10.640
And how did your team in particular get involved with the projects?

28:10.640 --> 28:19.960
So we were invited, one of our team managers received an invitation for Intel to participate

28:19.960 --> 28:23.000
and we were very excited to join the opportunity.

28:23.000 --> 28:32.240
I went to the kickoff meeting and got to meet the researchers in the program and invited

28:32.240 --> 28:35.360
a couple of my colleagues to come and participate.

28:35.360 --> 28:42.960
One who couldn't be here unfortunately, his name is Najib Hakim, who was the main Intel

28:42.960 --> 28:49.000
engineer, his principal engineer, with a strong background in machine learning and deep

28:49.000 --> 28:50.160
learning.

28:50.160 --> 28:56.800
And he provided a lot of the mentorship and guidance that the engineers needed, along

28:56.800 --> 29:05.120
with Ravi, Panchamarthi and Hanlin, they provided additional assistance, engineering assistance

29:05.120 --> 29:07.440
to the teams.

29:07.440 --> 29:14.120
You mentioned a moment ago the kind of the unique challenges of this problem with regard

29:14.120 --> 29:19.600
to clusters of craters and craters and all that kind of stuff.

29:19.600 --> 29:23.200
How did you overcome those problems?

29:23.200 --> 29:27.440
So thankfully the problem that we were trying to solve was the co-registration improvement

29:27.440 --> 29:28.760
of maps.

29:28.760 --> 29:33.200
So so long as we could get a reliable fingerprint for an image that could be matched in the

29:33.200 --> 29:36.760
elevation model, then that would satisfy our goals.

29:36.760 --> 29:44.480
So when there was particularly rough areas, then it didn't matter so much that maybe the

29:44.480 --> 29:48.720
quality of our image classified suffered in those regions because we were able to make

29:48.720 --> 29:50.160
up for it elsewhere.

29:50.160 --> 29:56.640
So it would definitely be a problem for research question almost and when it comes to building

29:56.640 --> 30:02.560
an application in a short period of time, sometimes we had to make do with what we had and

30:02.560 --> 30:06.480
do it quickly, rather than trying to buy it off more than we could chew an identity

30:06.480 --> 30:07.800
up, not contributing anything.

30:07.800 --> 30:08.800
Right.

30:08.800 --> 30:09.800
Right.

30:09.800 --> 30:16.600
And so how do you envision, I understand there's an ongoing role for you in particular in

30:16.600 --> 30:19.920
this project with FDL, how does it move forward?

30:19.920 --> 30:25.400
So I mean, identifying the issues that we had with the time constraints, we all invited

30:25.400 --> 30:29.120
individually to continue to contribute if we would like to.

30:29.120 --> 30:34.040
I think for many of us, it's, you know, this really stirred up our passion and our excitement

30:34.040 --> 30:35.840
about the whole field.

30:35.840 --> 30:41.720
So since the end of the project, we've been working to, you know, tidy up the code, make

30:41.720 --> 30:46.520
it publicly available, and we've been working alongside the folks at Intel to improve

30:46.520 --> 30:51.360
the algorithm to be able to detect clusters of creators and creators within creators using

30:51.360 --> 30:55.400
our newer techniques, single-shot detector, it's a modipox.

30:55.400 --> 31:00.000
Which allows you to identify lots of creators in the same image.

31:00.000 --> 31:05.960
So moving forward, I suppose we're looking forward to a fronted development of 2018, we're

31:05.960 --> 31:10.880
going to be taking applications for that currently up until March.

31:10.880 --> 31:16.200
And really what we're looking for is to see what ideas people come with and how the

31:16.200 --> 31:20.360
ways that they can contribute to the continuation of this project.

31:20.360 --> 31:26.320
Andreas, were there any kind of unique properties of the Intel AI stack that lent themselves

31:26.320 --> 31:32.160
to solving this problem or that, you know, helped in helping these research teams advance

31:32.160 --> 31:33.160
their research?

31:33.160 --> 31:38.800
Yeah, until we have the full solution stack anywhere from starting at the bottom with

31:38.800 --> 31:47.000
our hardware, we have our general purpose CPU, such as young processors, we're also developing

31:47.000 --> 31:52.200
a deep learning accelerator, specific target for the learning world, that was not available

31:52.200 --> 31:58.000
in 2017 when these researchers were working on this problem, we hope that they'll be able

31:58.000 --> 32:04.320
to use it in the following summer, but we have our CPUs in addition to that, we have libraries

32:04.320 --> 32:11.160
that are optimized to run deep learning functions efficiently on our CPUs, you might have heard

32:11.160 --> 32:17.400
of the Intel math kernel library, we in addition we have deep learning frameworks that we've

32:17.400 --> 32:24.440
optimized, such as cafe, TensorFlow, MxNet, and we have an in-house framework called NEON,

32:24.440 --> 32:32.160
which was the framework that was made available, FTL for the researchers to use, NEON's unique

32:32.160 --> 32:38.760
in the sense that it's a framework that is highly optimized, but Intel for both CPUs and

32:38.760 --> 32:45.160
CPUs, you can get very high throughput and high utilization, regardless of the hardware

32:45.160 --> 32:52.400
backend that you use, and in addition to that, we actually have a Nirvana offering called

32:52.400 --> 33:00.200
the Intel AI cloud, it used to be called the Intel Nirvana cloud, and this cloud where

33:00.200 --> 33:07.480
our partners can log in and easily load their jobs and they have the tools to easily experiment

33:07.480 --> 33:13.400
with various models and various hyperparameters, meaning various knobs that you need to often

33:13.400 --> 33:16.880
tweak in order to get your models to officially train.

33:16.880 --> 33:23.840
So we spend some time getting the engineers and have the alab to speed on how to use the

33:23.840 --> 33:32.400
tools, but once you spend a few days or even less a couple of days or day, you can start

33:32.400 --> 33:39.320
training your own models, so you usually start by training a simple model like Lynette,

33:39.320 --> 33:44.120
which is an all model that was developed a couple decades ago, and you can do that

33:44.120 --> 33:50.840
your first couple of hours, you train that model on image recognition, and then you can

33:50.840 --> 33:56.800
actually modify it a little bit to start getting a baseline on how well does this work

33:56.800 --> 34:05.040
on our crater images, and do I need to add more layers, do I need to add more units or

34:05.040 --> 34:12.400
neurons in its layer, once you can do crater classification then you can move into detection,

34:12.400 --> 34:20.560
which as Tim was talking about, initially we use single shot detection algorithm or SSD,

34:20.560 --> 34:28.360
and there are newer algorithms that are better for this type of workloads, where you have

34:28.360 --> 34:33.240
small craters, some large craters, and you don't have a diversity of classes, you're

34:33.240 --> 34:39.360
trying to classify, and so that's going to be the next step of classifiers or detectors

34:39.360 --> 34:41.560
that we're going to be using.

34:41.560 --> 34:43.680
Awesome, awesome.

34:43.680 --> 34:50.200
This sounds like an amazing program, maybe we can close out by having you Sarah tell

34:50.200 --> 34:55.800
us like for folks that want to learn more about participating in the 2018 program, is there

34:55.800 --> 34:59.040
a site they can go to, or what's the process there?

34:59.040 --> 35:04.800
Yeah, so if you're interested in the program, you would go to frontchairdevelopmentlab.org,

35:04.800 --> 35:09.280
and like Tim said, we do have our applications open, we're currently doing our planning

35:09.280 --> 35:12.960
for next year, and so our challenges should be launched here soon as well.

35:12.960 --> 35:20.160
Okay, and Tim from you, any final thoughts or advice for folks that might be interested

35:20.160 --> 35:24.760
in pursuing, either getting involved in FDL or doing similar research?

35:24.760 --> 35:31.240
Yeah, I'd say, just go for it, you know, I grew up in the UK, I never imagined for a

35:31.240 --> 35:36.240
second that I could be working alongside NASA scientists or living on a NASA facility.

35:36.240 --> 35:38.360
Similar program was absolutely excellent.

35:38.360 --> 35:44.240
If you're wanting to get involved in machine learning, start reading online, take small

35:44.240 --> 35:46.120
goals, keep assuring them.

35:46.120 --> 35:50.000
It's very easy to be like, should I learn this machine learning algorithm today, or

35:50.000 --> 35:54.920
should I watch another season of my favorite TV show, put short-term goals, keep going

35:54.920 --> 35:59.200
for it, and you'll be able to contribute in this new and exciting field as well.

35:59.200 --> 36:00.200
Awesome, awesome.

36:00.200 --> 36:03.200
And how about from you, any parting thoughts?

36:03.200 --> 36:08.680
Yeah, in total doing a lot of exciting work to advance AI, and you can check out what

36:08.680 --> 36:15.840
we're doing at internalrunner.com, in addition of developing this new, the Blurnexelerator,

36:15.840 --> 36:22.360
we've optimized the framework, so if you were to do deep learning on CPUs, today you'll

36:22.360 --> 36:28.400
see significant gains in performance, and if you were, if you had tried to do deep learning

36:28.400 --> 36:34.560
on CPUs a year ago, or even six months ago, so it's an exciting time.

36:34.560 --> 36:42.920
We want to democratize the use of deep learning, and most facilities have Intel CPUs, so we

36:42.920 --> 36:48.720
hope that they can be put to good use, such as we did with FDL.

36:48.720 --> 36:52.720
On that note, for the hobbyist, Intel does have an AI bootcamp that provides a lot of

36:52.720 --> 36:57.400
resources available for people to learn how to use Intel Nirvana, oh, Intel AI, I think

36:57.400 --> 37:02.200
it's called now, and yeah, get involved and get their hands dirty with the final points

37:02.200 --> 37:03.920
of learning machine learning.

37:03.920 --> 37:09.560
Awesome, as well as the dev cloud offering, which I did an interview, I forget which episode

37:09.560 --> 37:13.440
it was, but we'll put that in the show notes as well, folks can sign up for access to that

37:13.440 --> 37:14.440
too.

37:14.440 --> 37:15.440
Thanks.

37:15.440 --> 37:16.440
Awesome.

37:16.440 --> 37:20.080
Well, Sarah Andres, Tim, thanks so much for taking the time to chat.

37:20.080 --> 37:21.080
Thank you.

37:21.080 --> 37:24.080
Thank you for trying that out.

37:24.080 --> 37:29.920
All right, everyone, that's our show for today.

37:29.920 --> 37:34.960
Thanks so much for listening, and for your continued feedback and support.

37:34.960 --> 37:41.240
For more information on Sarah, Timothy, Andres, or any of the topics covered in this episode,

37:41.240 --> 37:45.840
head on over to twimlai.com slash talk slash 89.

37:45.840 --> 37:52.760
To follow along with the nip series, visit twimlai.com slash nips 2017.

37:52.760 --> 37:59.400
To enter our twimla 1 mil contest, visit twimlai.com slash twimla 1 mil.

37:59.400 --> 38:04.160
Of course, we'd be delighted to hear from you either via a comment on the show notes

38:04.160 --> 38:10.320
page or via a tweet to at twimlai or at Sam Charrington.

38:10.320 --> 38:14.880
Thanks once again to Intel Nirvana for their sponsorship of this series.

38:14.880 --> 38:19.560
To learn more about the Intel Nirvana NNP and the other things Intel's been up to in

38:19.560 --> 38:23.800
the AI arena, visit intel Nirvana.com.

38:23.800 --> 38:28.560
As I mentioned a few weeks back, this will be our final series of shows for the year.

38:28.560 --> 38:33.800
So take your time and take it all in and get caught up on any of the old pods you've been

38:33.800 --> 38:35.400
saving up.

38:35.400 --> 38:37.840
Happy Holidays and Happy New Year.

38:37.840 --> 38:40.120
See you in 2018.

38:40.120 --> 39:06.880
And of course, thanks once again for listening and catch you next time.

