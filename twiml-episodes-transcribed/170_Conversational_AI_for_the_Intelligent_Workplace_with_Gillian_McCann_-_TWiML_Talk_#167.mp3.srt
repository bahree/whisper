1
00:00:00,000 --> 00:00:05,860
Hey everybody, Sam here. We've got some great news to share, and also a favorite

2
00:00:05,860 --> 00:00:12,120
to ask. We're in the running for this year's People's Choice Podcast Awards, in both the

3
00:00:12,120 --> 00:00:16,360
People's Choice and Technology Categories, and we would really appreciate your

4
00:00:16,360 --> 00:00:22,960
support. To nominate us, you'll just head over to Twomlai.com slash nominate, where we've

5
00:00:22,960 --> 00:00:28,600
linked to and embedded the nomination form from the award site. There, you'll need to input

6
00:00:28,600 --> 00:00:34,560
your information and create a listener nomination account. Once you get to the ballot, just find

7
00:00:34,560 --> 00:00:40,160
and select this week in machine learning and AI on the nomination list for both the Adam

8
00:00:40,160 --> 00:00:47,500
Curry People's Choice Award and the this week in tech technology category. As you know,

9
00:00:47,500 --> 00:00:52,400
we really, really appreciate each listener and would love to share in this accomplishment

10
00:00:52,400 --> 00:01:00,860
with you. Remember, that url is twomlai.com slash nominate. Feel free to hit pause and take

11
00:01:00,860 --> 00:01:04,960
a moment to nominate us now.

12
00:01:04,960 --> 00:01:20,480
Hello and welcome to another episode of Twomletalk, the podcast why interview interesting people,

13
00:01:20,480 --> 00:01:25,840
doing interesting things in machine learning and artificial intelligence. I'm your host

14
00:01:25,840 --> 00:01:35,320
Sam Charington.

15
00:01:35,320 --> 00:01:40,160
For those interested in our fast.ai study group, but who haven't been able to make it to our

16
00:01:40,160 --> 00:01:46,720
live sessions, make sure you check out our recap videos via either the meetup page or our

17
00:01:46,720 --> 00:01:54,440
YouTube channel at youtube.com slash twomlai.

18
00:01:54,440 --> 00:02:00,400
In this episode, I'm joined by Jillian McCann, head of cloud engineering and AI at Workgrid

19
00:02:00,400 --> 00:02:05,200
software, which offers an intelligent workplace assistant that integrates with a variety

20
00:02:05,200 --> 00:02:10,380
of business tools and systems. In our discussion, which focuses on work

21
00:02:10,380 --> 00:02:16,040
grid use of cloud based AI services, Jillian details some of the underlying systems that

22
00:02:16,040 --> 00:02:22,120
make work grid tick, including a breakdown of its conversational interface. We also take

23
00:02:22,120 --> 00:02:26,960
a look at their engineering pipeline and how they build high quality systems that depend

24
00:02:26,960 --> 00:02:33,820
upon external APIs. Finally, Jillian shares her view on some of the factors that contribute

25
00:02:33,820 --> 00:02:40,720
to misunderstandings and impatience on the part of users of AI based products. And now on

26
00:02:40,720 --> 00:02:49,540
to the show, all right, everyone, I am on the line with Jillian McCann. Jillian is head

27
00:02:49,540 --> 00:02:55,360
of cloud engineering and AI at Workgrid software. Jillian, welcome to this weekend machine learning

28
00:02:55,360 --> 00:02:56,360
in AI.

29
00:02:56,360 --> 00:02:58,080
Thank you. Thanks for having me.

30
00:02:58,080 --> 00:03:02,440
It's great to have you on the show. Why don't we get started out by having you tell us

31
00:03:02,440 --> 00:03:07,800
a little bit about your background and how you got involved in AI?

32
00:03:07,800 --> 00:03:14,360
Yes, so I have been working. I'm an engineer at Harvard, really. I've been working very

33
00:03:14,360 --> 00:03:19,920
much in the public cloud space last couple of years. But recently, I've started to look

34
00:03:19,920 --> 00:03:27,520
at how we can use conversational AI. Specifically, I write chatbots and voice within the employee

35
00:03:27,520 --> 00:03:35,440
space. So I have Workgrid software is a wholly owned company of Liberty Mutual Insurance.

36
00:03:35,440 --> 00:03:41,120
And what we've done there is a lot of the great products that we've built internally

37
00:03:41,120 --> 00:03:46,920
for employees that have used different aspects of conversational AI. We've decided that

38
00:03:46,920 --> 00:03:52,120
it solved a lot of problems for us within the enterprise within a large global company

39
00:03:52,120 --> 00:03:59,200
that there is potential there to create a product that can be used across companies worldwide.

40
00:03:59,200 --> 00:04:05,360
So last year, we created that company that's separate and today, and that's now my focus.

41
00:04:05,360 --> 00:04:11,680
It's cloud engineering and AI. And it's really how you can apply artificial intelligence

42
00:04:11,680 --> 00:04:14,760
within employee focused products.

43
00:04:14,760 --> 00:04:18,840
Can you give some examples of the types of employee focused products that you're working

44
00:04:18,840 --> 00:04:19,840
on there?

45
00:04:19,840 --> 00:04:25,520
Yes, so our initial product is called the Workgrid Assistant. And the aim of that is really

46
00:04:25,520 --> 00:04:30,600
like building an intelligent workplace assistant. You know, not everybody is fortunate enough

47
00:04:30,600 --> 00:04:35,920
to have PA, you know, a person who is able to, you know, take notes for them or create

48
00:04:35,920 --> 00:04:41,360
them to do lists. So we're looking for a way to create, you know, a product that can

49
00:04:41,360 --> 00:04:49,440
really help employees, you know, with productivity gains and engagement and job satisfaction.

50
00:04:49,440 --> 00:04:55,640
And some of the care is that the product we have, you know, focuses on its, you know, approvals

51
00:04:55,640 --> 00:05:01,360
and workflows and really automation and the aggregation of a lot of internal systems

52
00:05:01,360 --> 00:05:07,040
in that one place with a really, you know, modern and intelligent intuitive interface

53
00:05:07,040 --> 00:05:13,400
of which includes, you know, a chatbot. So conversation, conversational interface is

54
00:05:13,400 --> 00:05:20,000
part of this as well, which is really where our initial focus of AI is.

55
00:05:20,000 --> 00:05:24,720
So I mean, some of the use cases that we talk about. So as I say, this is Stan from, you

56
00:05:24,720 --> 00:05:29,840
know, work with them within Liberty Mutual is that we really focus on some of our site's

57
00:05:29,840 --> 00:05:36,440
central employee functions like HR, IT help desk, just general product evidence and how

58
00:05:36,440 --> 00:05:44,480
we can, you know, automate and provide also like a conversation interface to many systems

59
00:05:44,480 --> 00:05:48,720
so that, you know, employees can find the information they need when they need it, you

60
00:05:48,720 --> 00:05:53,920
know, on the questions that are asked across offices day and day out, can be very simply

61
00:05:53,920 --> 00:05:58,480
automated and give them, you know, again, that engaging experience.

62
00:05:58,480 --> 00:06:04,960
And is work grid primarily building software for the use of Liberty Mutual or are you,

63
00:06:04,960 --> 00:06:09,240
you know, is it more like a spin out where you're commercializing this for the broader

64
00:06:09,240 --> 00:06:10,240
marketplace?

65
00:06:10,240 --> 00:06:16,280
It's the commercialization, really, of a product that we built internally for ourselves.

66
00:06:16,280 --> 00:06:17,280
Okay.

67
00:06:17,280 --> 00:06:20,880
It's actually getting back several years ago, you know, we went through a transformation,

68
00:06:20,880 --> 00:06:26,040
I think around 2014. When we looked at the marketplace, we didn't see anything there

69
00:06:26,040 --> 00:06:31,160
that really would, you know, benefit us in the way that we wanted, we wanted to bring

70
00:06:31,160 --> 00:06:35,760
all our underlying enterprise systems in tools that, you know, we used day and day out.

71
00:06:35,760 --> 00:06:41,320
And I could give it and give a simple place for people to go and do their daily work,

72
00:06:41,320 --> 00:06:45,120
you know, so instead of going into many different applications, where you've literally just

73
00:06:45,120 --> 00:06:49,720
gone in success screen to click a few buttons, it just brings that one place that you can

74
00:06:49,720 --> 00:06:51,520
actually achieve your daily work.

75
00:06:51,520 --> 00:06:59,560
And we evolved that, you know, when last year into building into part of it as a chatbot,

76
00:06:59,560 --> 00:07:05,000
which is, you know, it's a conversation like, and it's using like natural language processing

77
00:07:05,000 --> 00:07:11,120
and conversation analytics to really, you know, try to find what our employees and pin

78
00:07:11,120 --> 00:07:14,720
points are and also to help automate some of that.

79
00:07:14,720 --> 00:07:22,360
And what's been the adoption like of the chatbot interface in particular, there's, there's

80
00:07:22,360 --> 00:07:28,280
an article recently, it was in Ink magazine and it was an article with a guy who was like

81
00:07:28,280 --> 00:07:33,240
founder of a startup and the headline of the article was something like chat box killed

82
00:07:33,240 --> 00:07:34,880
my company or killed my startup.

83
00:07:34,880 --> 00:07:39,720
And the idea was that like he built his startup around this, you know, what he now sees

84
00:07:39,720 --> 00:07:44,640
as a fad and he found that people really didn't want to use chatbots.

85
00:07:44,640 --> 00:07:50,320
And so I've been asking folks ever since seeing that about conversational interfaces like,

86
00:07:50,320 --> 00:07:55,320
where do they think, you know, where do you think we are in terms of adoption or and

87
00:07:55,320 --> 00:08:00,280
is this a way that people want to engage with software?

88
00:08:00,280 --> 00:08:01,800
What have you seen?

89
00:08:01,800 --> 00:08:07,160
So I would say chatbots to me are, you know, the future.

90
00:08:07,160 --> 00:08:09,640
When I say that, what do I mean by a chatbot?

91
00:08:09,640 --> 00:08:14,360
I think everybody has different perceptions of what a chatbot is, you know, is it a simple

92
00:08:14,360 --> 00:08:18,680
bot you order flour so I'm on Facebook Messenger or is it Alexa?

93
00:08:18,680 --> 00:08:24,560
It's literally, you know, the definition is like your ability to talk to and machine

94
00:08:24,560 --> 00:08:26,600
to natural language.

95
00:08:26,600 --> 00:08:31,480
So we do have, you know, on many levels of that, if you know what I mean.

96
00:08:31,480 --> 00:08:38,560
So I say it's very much voice is the future, future interface.

97
00:08:38,560 --> 00:08:44,720
So we talk about chatbots, that's what I have in my head, but it does make sense in a lot

98
00:08:44,720 --> 00:08:45,720
of different contexts.

99
00:08:45,720 --> 00:08:51,200
But it also, you know, it doesn't mean you have to have one sometimes as a visual interface

100
00:08:51,200 --> 00:08:52,200
works better.

101
00:08:52,200 --> 00:08:57,800
So it's not like everybody has to rush out and build a chatbot, but I think everybody

102
00:08:57,800 --> 00:09:04,000
should consider when the conversation interface actually works better, you know, very much,

103
00:09:04,000 --> 00:09:09,720
you know, like the one we have you sitting at your desk, you want to ask a simple question,

104
00:09:09,720 --> 00:09:13,760
maybe about an HR policy or you want to get some information about how do we have like

105
00:09:13,760 --> 00:09:19,160
reset passwords from the IT health desk, we do valor, how about two seconds chat with

106
00:09:19,160 --> 00:09:24,760
a chatbot or a ten minute phone call, so people are, it's the use case that really drives

107
00:09:24,760 --> 00:09:26,440
the use of the chatbot.

108
00:09:26,440 --> 00:09:33,280
So we have, you know, it's still in, I would say it's like an evolving technology, but

109
00:09:33,280 --> 00:09:38,840
it's not really the end of your AI piece that's evolving, it's the use case, understanding

110
00:09:38,840 --> 00:09:45,640
when that context or when that conversation interface makes more sense, and also the actual

111
00:09:45,640 --> 00:09:50,480
piece of the conversation design, what does the chatbot say?

112
00:09:50,480 --> 00:09:56,720
If you don't design it well, the conversation doesn't flow well, and then chatbots do fail,

113
00:09:56,720 --> 00:10:00,360
you know, it flows a lot more than just the AI piece it is.

114
00:10:00,360 --> 00:10:05,600
I think good conversation design, good understanding of your users and understanding the benefits

115
00:10:05,600 --> 00:10:10,680
it this will bring, and then also as I say, you know, the evolution of chatbots into

116
00:10:10,680 --> 00:10:15,600
a voice, I definitely think, I mean, you can just, I don't know if you're seeing the

117
00:10:15,600 --> 00:10:20,760
figures of, you know, hi, many Alexa's, we're bought a Chris's, you know, so there's

118
00:10:20,760 --> 00:10:25,800
like, I think there's staff like one in sex, American high schools, have a smart speaker,

119
00:10:25,800 --> 00:10:30,040
you know, so you think about that, those are all chatbots.

120
00:10:30,040 --> 00:10:35,880
In the definition of, you know, using natural language to talk, you know, interface with

121
00:10:35,880 --> 00:10:36,880
computers.

122
00:10:36,880 --> 00:10:39,120
So, don't have that answer to your question.

123
00:10:39,120 --> 00:10:46,000
Yeah, no, it does, I appreciate that broader definition of chatbot, and I think, you

124
00:10:46,000 --> 00:10:51,120
know, when we vision kind of the future of human computer interaction, I don't think

125
00:10:51,120 --> 00:10:57,640
that there's much of a question for most people that it's a natural language-based conversation

126
00:10:57,640 --> 00:11:02,720
that, you know, extends beyond kind of the, you know, like the example you gave, the

127
00:11:02,720 --> 00:11:08,200
Facebook messenger bot, it's not so much that, you know, that rectangular interface that

128
00:11:08,200 --> 00:11:14,400
defines chatbot, but this means of interacting with the computer via natural language.

129
00:11:14,400 --> 00:11:24,000
You mentioned that the first step is understanding when to apply this type of approach to a given

130
00:11:24,000 --> 00:11:25,000
use case.

131
00:11:25,000 --> 00:11:29,040
Do you have any guidelines that tell you when, or is it kind of, I'll know it when I see

132
00:11:29,040 --> 00:11:30,040
it?

133
00:11:30,040 --> 00:11:34,200
I think it's a bit of both, like really, some use cases just don't make sense.

134
00:11:34,200 --> 00:11:42,120
You know, I think about things that, you know, that you're used to seeing, like, lists

135
00:11:42,120 --> 00:11:47,200
of things, like, something that's very visual, if that makes sense, you know, like, we

136
00:11:47,200 --> 00:11:53,400
talk about, like, if you were to ask about all the, for example, like, the Amazon days

137
00:11:53,400 --> 00:11:57,240
of the day, you know, you know, the way you see everything's like cards, there's a lot

138
00:11:57,240 --> 00:12:02,800
of visual input that you can take, you can ask that in a chatbot, what, how could you

139
00:12:02,800 --> 00:12:05,280
get that sort of information in the same way?

140
00:12:05,280 --> 00:12:10,000
You know, it just be a big list of words that it doesn't really make sense.

141
00:12:10,000 --> 00:12:14,360
But, you know, we have find, like, with the employee space, it has been, like, really

142
00:12:14,360 --> 00:12:19,240
listening to what employees are asked for, or some of the things are just, like, very

143
00:12:19,240 --> 00:12:26,600
simple, one-off sort of actions, or, like, require, so you do find a lot of, of the use

144
00:12:26,600 --> 00:12:30,920
cases within the work, basically, to be centered around a more intelligent search, you

145
00:12:30,920 --> 00:12:36,760
know, actually, we know we'll have more direction into more directed questions, really, than

146
00:12:36,760 --> 00:12:40,040
just, you know, type it in a search bar.

147
00:12:40,040 --> 00:12:44,440
So, you know, essentially, we just have worked through them and decided, like, what makes

148
00:12:44,440 --> 00:12:45,440
sense?

149
00:12:45,440 --> 00:12:46,440
What doesn't make sense?

150
00:12:46,440 --> 00:12:51,040
I do think there is a, especially in some of the arguments on, like, you do realize

151
00:12:51,040 --> 00:12:57,680
that the user's expectations are sometimes, like, very, there will be very high, they're

152
00:12:57,680 --> 00:13:02,640
very high, when you start talking about, um, any form of AI, and I don't know if you've

153
00:13:02,640 --> 00:13:09,760
come across this, it's like, it's either very high or low, um, this is not a success.

154
00:13:09,760 --> 00:13:17,160
So, like, from a chat board perspective, um, like, I think we've had an education ourselves,

155
00:13:17,160 --> 00:13:22,520
you know, we have, like, like, the development team, and, and the guys really, like, how do

156
00:13:22,520 --> 00:13:27,280
you build, like, intense and utterances and fulfilments and train the model?

157
00:13:27,280 --> 00:13:32,600
What technologies do you use, do you build your own, do you use somebody else's, um, you

158
00:13:32,600 --> 00:13:36,520
know, so there's a lot of that, but, like, when we're talking with the users, it's, it's

159
00:13:36,520 --> 00:13:40,760
like an expectation that it's all going to magically, like, it's magic.

160
00:13:40,760 --> 00:13:46,200
If you type something in, um, you know, like, what's the weather, that the chat bottle

161
00:13:46,200 --> 00:13:50,240
know how to answer it, and there's a sort of explanation, well, guys, it's still cold,

162
00:13:50,240 --> 00:13:55,120
we still have to write that if you want a chat box to actually know the weather, we have

163
00:13:55,120 --> 00:13:59,680
to program, we have to train the model, and we have to ultimately call an API that tells

164
00:13:59,680 --> 00:14:04,200
us what the weather is, but it's, it's that perception of, like, if I repeatedly ask

165
00:14:04,200 --> 00:14:08,600
it what the weather is, it'll learn that we've heard that, like, it'll learn what I say,

166
00:14:08,600 --> 00:14:11,600
says, well, they'll not learn until we update it.

167
00:14:11,600 --> 00:14:14,920
It's not a magical box, it just learns things.

168
00:14:14,920 --> 00:14:19,800
So I think there's, like, the expectations, if that makes sense, it's being very interesting

169
00:14:19,800 --> 00:14:20,800
to see.

170
00:14:20,800 --> 00:14:26,960
And then on the other side is, you know, people just think that they're not very good,

171
00:14:26,960 --> 00:14:32,240
chat box aren't very good, the L&U is not very good, but we're sort of in a place

172
00:14:32,240 --> 00:14:36,000
where it's never been any better, and it's only going to get better.

173
00:14:36,000 --> 00:14:40,680
So, you know, I think what we find also is the very importance of, like, what we call

174
00:14:40,680 --> 00:14:46,640
conversational analytics in that you're understanding what it's being, and you're understanding

175
00:14:46,640 --> 00:14:51,440
what the box saying, or what's being said to the box, box, you know, you may not be able

176
00:14:51,440 --> 00:14:55,640
to answer, but if everybody's asking for what's the weather, then potentially that's the

177
00:14:55,640 --> 00:14:56,640
feature you add.

178
00:14:56,640 --> 00:15:03,880
And so, you know, just that, analytics of what's being said, missed audiences, missed intents,

179
00:15:03,880 --> 00:15:09,680
how well are you fulfilling the actual user intent, how well are you performing, and that's

180
00:15:09,680 --> 00:15:15,920
really a driven user case as to just refine what we have, because it is a great way if

181
00:15:15,920 --> 00:15:22,000
you, you know, give the box to like a pilot group, you know, you can actually through what

182
00:15:22,000 --> 00:15:26,040
they're asking and how they're chatting to it, actually see maybe what they wanted to

183
00:15:26,040 --> 00:15:27,040
do.

184
00:15:27,040 --> 00:15:32,040
And it does surprise you in some ways, and also the realisation that, you know, different

185
00:15:32,040 --> 00:15:35,520
cultures and different language of different ways of even saying hello.

186
00:15:35,520 --> 00:15:39,720
So, we find all that, like, if we've ruled it out, it's still in the pilot, but in the

187
00:15:39,720 --> 00:15:45,200
Liberty Mutual, you know, we see that because it's a global component, but it's been very

188
00:15:45,200 --> 00:15:46,200
interesting.

189
00:15:46,200 --> 00:15:52,640
And I do think chatbots, if they're designed well, they perform real actions are very powerful.

190
00:15:52,640 --> 00:16:00,200
Do you feel that the, this magic that some users expect, where the chatbot is going to

191
00:16:00,200 --> 00:16:07,480
learn how to understand what the user is asking, do you feel that that is just kind of organic

192
00:16:07,480 --> 00:16:14,600
or does it, has it come about because we throw around terms like machine learning that people

193
00:16:14,600 --> 00:16:15,600
don't really understand?

194
00:16:15,600 --> 00:16:16,600
I would, yes.

195
00:16:16,600 --> 00:16:17,600
That's right.

196
00:16:17,600 --> 00:16:19,600
In short, yes.

197
00:16:19,600 --> 00:16:28,240
And I think AI, artificial intelligence, machine learning, deep learning, you know, there's

198
00:16:28,240 --> 00:16:30,040
a lot of words about need about it.

199
00:16:30,040 --> 00:16:36,280
And I do think there is, you know, if we say machine learning that somehow it's going

200
00:16:36,280 --> 00:16:40,040
to learn how to do these things, but like when you, you know, and I'm not an expert,

201
00:16:40,040 --> 00:16:44,920
you know, but I've read some stuff, you know, the differences between supervised and unsupervised

202
00:16:44,920 --> 00:16:49,760
machine learning and deep learning is different for is that when she start getting into it,

203
00:16:49,760 --> 00:16:57,240
it is much more evolved, you know, the data that you have, the training data, it can only,

204
00:16:57,240 --> 00:17:02,840
it can only be as good as the data you have and the historical data for supervised learning.

205
00:17:02,840 --> 00:17:07,280
So I don't think everybody really, you know, they don't need to know that, but I think,

206
00:17:07,280 --> 00:17:11,680
um, like once you start having an interest in it, then you do start reading these things,

207
00:17:11,680 --> 00:17:17,640
you do get a better awareness of it, but I doubt I think, yeah, the terms and just everything

208
00:17:17,640 --> 00:17:22,600
has got some element of AI apparently, I don't know, you know, there's a lot of products

209
00:17:22,600 --> 00:17:23,600
say that.

210
00:17:23,600 --> 00:17:29,720
And we need to dive into, I think a lot of it is really automation and workflow and

211
00:17:29,720 --> 00:17:37,840
the real great things, but I think, you know, there's a bit of a buzz, as you know, um, and

212
00:17:37,840 --> 00:17:41,440
it's applied when potentially it's not, it's not our first intelligence, something else.

213
00:17:41,440 --> 00:17:48,480
So, you know, I say some great, the script product center and a lot of it, you know, it seems

214
00:17:48,480 --> 00:17:52,800
more like process automation, which is very valuable to.

215
00:17:52,800 --> 00:17:59,520
Yeah, basically every enterprise software product is some automation, some more slow automation.

216
00:17:59,520 --> 00:18:01,160
Uh, underneath, right?

217
00:18:01,160 --> 00:18:02,160
All right.

218
00:18:02,160 --> 00:18:09,440
So, you've, you've got some use case, you think it could be a good fit for some type of

219
00:18:09,440 --> 00:18:16,840
chatbot, then the, the next question is, how do you get there, uh, and you were speaking

220
00:18:16,840 --> 00:18:23,280
at the AWS conference, so you went the cloud direction, there's also, um, you know, building

221
00:18:23,280 --> 00:18:29,200
your own, how did you evaluate the, the different options and come to the conclusion that you came

222
00:18:29,200 --> 00:18:30,200
to?

223
00:18:30,200 --> 00:18:31,200
Yeah.

224
00:18:31,200 --> 00:18:32,200
So, that's a good question.

225
00:18:32,200 --> 00:18:38,000
Um, so I did look at a lot of different options, um, I think really, you know, the first

226
00:18:38,000 --> 00:18:44,160
thing was, and it's written general about chatbot, I think you have to think about where

227
00:18:44,160 --> 00:18:47,960
are the channels or the clients that you want to put that chatbot in, you know, who's

228
00:18:47,960 --> 00:18:48,960
the customer?

229
00:18:48,960 --> 00:18:53,480
Is it a, like a customer facing, or is it an internal one that, like more like the employee

230
00:18:53,480 --> 00:18:58,000
stuff that I have been working on, you know, just an understanding of generally what

231
00:18:58,000 --> 00:19:03,600
the chatbot, um, is going to do, but also those channels, because a lot of the, like the

232
00:19:03,600 --> 00:19:08,360
channels have their built-in frameworks that really make it easier to build.

233
00:19:08,360 --> 00:19:12,320
Um, I think, you know, if you're thinking about building chatbots, you have to set your

234
00:19:12,320 --> 00:19:19,320
development capabilities as well, like I was like, um, I'm working from a, like an architect,

235
00:19:19,320 --> 00:19:23,360
engineer, you know, I know how to write code, solutions are not going to put me off, but

236
00:19:23,360 --> 00:19:26,680
if you're just in general interested by chatbots, there are a lot of great frameworks out

237
00:19:26,680 --> 00:19:28,480
there that can get you up and running.

238
00:19:28,480 --> 00:19:34,440
Um, I obviously then, um, some of the research we did is into, well, understands what type

239
00:19:34,440 --> 00:19:37,600
of chatbot you're trying to build, so you know, and there is a framework, you can sort

240
00:19:37,600 --> 00:19:43,640
of assess it against an open-demand chatbot, versus a close-demand chatbot, um, close-demand

241
00:19:43,640 --> 00:19:51,080
is, um, a lot easier in that it's like a very set purpose, as I mentioned, order floors

242
00:19:51,080 --> 00:19:56,680
or, um, order of pizza order attacks, so those types of chatbots are a lot simpler, because

243
00:19:56,680 --> 00:20:02,440
they're only expected to do one thing, and if you started to ask a pizza bot about the

244
00:20:02,440 --> 00:20:08,840
politics, you're not really expecting that to do what I mean, just expectations, um, but

245
00:20:08,840 --> 00:20:13,240
what we were working in was more open-demand in that there's a wide range of questions

246
00:20:13,240 --> 00:20:19,320
that an employee in a large company can ask, even within HR or IT help desk, um, use cases.

247
00:20:19,320 --> 00:20:24,440
So, you know, we looked, we need to find something then that would help us build, um, a more

248
00:20:24,440 --> 00:20:30,080
open-demand chatbot, um, and then also, you know, we're not really into the differences,

249
00:20:30,080 --> 00:20:34,440
so the difference between, like, retrieval and generative, you know, most chatbots in

250
00:20:34,440 --> 00:20:39,560
production today are retrieval-based, um, like, a generative one is, you know, we're really

251
00:20:39,560 --> 00:20:45,200
arguing into, you know, um, absolute true artificial intelligence in that, you know, something

252
00:20:45,200 --> 00:20:49,520
like, like, it didn't go very well, Microsoft, hey, but they've built, you know, the chatbot

253
00:20:49,520 --> 00:20:55,920
itself is generating a response, first is retrieval-based, um, and retrieval-based is obviously

254
00:20:55,920 --> 00:21:01,360
in a professional workplace, um, you know, it's, it's the thing that we initially, you

255
00:21:01,360 --> 00:21:05,600
know, we need to deliver that, so you can't really start looking at how can I build chatbots

256
00:21:05,600 --> 00:21:11,440
going to, you know, come up with the answers itself, you know, that's out the rounds of the,

257
00:21:11,440 --> 00:21:18,160
uh, AI capabilities of where we are today, from what company perspective I would say, um,

258
00:21:18,160 --> 00:21:24,800
but then I looked at, um, so, you know, we wanted a, um, a natural language chatbot rather

259
00:21:24,800 --> 00:21:31,440
than, like, a command, sort of, you know, do this, do that, um, so we want the natural language,

260
00:21:31,440 --> 00:21:39,280
looked at, um, the main cloud providers, I suppose, we say Google Microsoft Amazon, um, so,

261
00:21:39,280 --> 00:21:46,880
you know, I, um, an AWS Cloud Architects, I asked lightly by this towards one, but, um, we did,

262
00:21:46,880 --> 00:21:52,560
I did look at, um, Microsoft's cognitive services, a really great Google's, um, you know,

263
00:21:52,560 --> 00:21:58,480
there's some great stuff there, but with Amazon, an AWS was what was chosen, because it's more than,

264
00:21:58,480 --> 00:22:05,520
it takes more than an LU to build a chatbot for thousands of people. It takes, um, many different

265
00:22:05,520 --> 00:22:11,440
services and capabilities, um, you know, AWS was our provider of choice at that time,

266
00:22:11,440 --> 00:22:17,360
so it really made sense just to, you know, work with them and pack a technology that sort of

267
00:22:17,360 --> 00:22:23,680
fitted that AWS ecosystem, and luckily enough, um, it's not last year of the year before

268
00:22:23,680 --> 00:22:30,880
they announced Amazon Lex, um, as a new service, uh, in preview, um, immediately that was the

269
00:22:30,880 --> 00:22:35,840
ones at the end we wanted to work with, um, and we partnered really with them to develop,

270
00:22:35,840 --> 00:22:39,920
you know, they were in preview to develop the capabilities that we needed, um,

271
00:22:39,920 --> 00:22:44,960
I must say it worked really well because it's more than AWS Lex, the builds it, it's,

272
00:22:44,960 --> 00:22:50,080
it's a wide range of the services, um, it gives us that real scale ability, um,

273
00:22:50,080 --> 00:22:53,360
on analytics and good engineering practices.

274
00:22:53,360 --> 00:22:59,120
What have been some of the things that you've needed to build around it to arrive at a complete

275
00:22:59,120 --> 00:23:05,760
solution? Yeah, so interesting. I thought that was really what the, um, the session, uh,

276
00:23:05,760 --> 00:23:13,440
re-embed was, but like the last year was, it's more than Alexa. Um, so, so, I mean, what we had to

277
00:23:13,440 --> 00:23:19,680
provide was really, um, I think the analytics was very important, you know, been able to, um,

278
00:23:19,680 --> 00:23:28,800
analyze and store, um, elements of conversation so we could get insights, um, we use like APIs,

279
00:23:28,800 --> 00:23:37,520
um, and storage, um, so that we actually can, you know, um, review conversations. Um, so,

280
00:23:37,520 --> 00:23:44,480
we essentially built an architecture serverless architecture around Alexa. Um, so Alexa provided

281
00:23:44,480 --> 00:23:50,640
the NLU, um, but then also like if we wanted to, it's initially we focused on, um,

282
00:23:51,600 --> 00:23:55,360
text chatbot, but obviously then voice, as they mentioned, you know, obviously,

283
00:23:55,360 --> 00:24:02,720
as a, as a, the next step. So, you know, using AWS Poly, um, to really, you know, have both

284
00:24:02,720 --> 00:24:10,160
experiment with both, and then as we move into, you know, really looking at the devices in the

285
00:24:10,160 --> 00:24:15,680
home. I said beside her is the Google Assistant, um, which I have started looking at too. So,

286
00:24:15,680 --> 00:24:20,000
there's really powerful technology out there, um, and it's just, you know, as I said,

287
00:24:20,000 --> 00:24:27,360
taking the things that worked for you, um, and ultimately AWS, um, ecosystem was very

288
00:24:27,360 --> 00:24:32,560
much in place for us. So, so the, the lacks was the extra piece and once they, they brought that

289
00:24:32,560 --> 00:24:37,760
out, that seemed to definitely make sense. Um, and then, you know, as I said, we're talking

290
00:24:37,760 --> 00:24:43,680
at re-invent. Some of the things to talk about re-invent wasn't really, um, you know, the AI aspect

291
00:24:43,680 --> 00:24:50,880
offer, it was, how do you build chatbot scale? How do you test the chatbot? How do you have

292
00:24:50,880 --> 00:24:57,280
CI, CD pipelines for chatbots? Um, so it was really about good engineering practices applied to,

293
00:24:58,080 --> 00:25:03,760
um, like new technology like this. And also very importantly, I'm asking the before, is the

294
00:25:03,760 --> 00:25:09,200
conversation design, you know, what does it say? How does it interact with you? You know,

295
00:25:09,200 --> 00:25:14,320
you want to give your users a very good experience. Um, and what you have really have to do is just

296
00:25:14,320 --> 00:25:20,640
between the team is, you know, talk it out, script it out, um, potentially the bot. Um, so it's

297
00:25:20,640 --> 00:25:29,120
actually quite fun. Um, it's a fun way to develop. But, um, you can definitely see that it's a scale

298
00:25:29,120 --> 00:25:34,480
that, you know, we've had to build within a small team. Um, but I definitely have to say voice, um,

299
00:25:34,480 --> 00:25:40,720
the centerpiece, um, you know, it's a capability that we need to grow, um, just in general, I'd say within

300
00:25:40,720 --> 00:25:46,240
the engineering community. How big is your team now? So work red software, nice. So the original

301
00:25:46,240 --> 00:25:52,560
living neutral team was four or five work red software. No, we have, um, see boy, year or nine,

302
00:25:52,560 --> 00:25:58,160
so slightly bigger. But as I say, the conversation layout is just one piece of that. It's a larger

303
00:25:58,160 --> 00:26:04,240
assistant. Um, so we're all working hard, um, to really bring this because I really, I mean, we do

304
00:26:04,240 --> 00:26:08,960
honestly believe that, you know, you should value your employees, you should value their time,

305
00:26:09,840 --> 00:26:14,960
um, and you'd really try and help them, um, you know, when they need to have, when they've

306
00:26:14,960 --> 00:26:19,440
questions, they need answers, you can answer them quickly. But also, you know, providing that one

307
00:26:19,440 --> 00:26:24,880
place to go so they can do their, you know, to do this, notifications, provokes all those things

308
00:26:24,880 --> 00:26:31,920
that are a day-to-day, um, hassle sometimes, but you still have to do them. Um, you mentioned

309
00:26:31,920 --> 00:26:37,600
analytics on a number of occasions. Can you talk a little bit about the analytics that you use,

310
00:26:37,600 --> 00:26:44,960
and, um, what frameworks or tooling you've built to, um, support the way you want to analyze the

311
00:26:44,960 --> 00:26:53,120
conversations? Yeah, so, um, so I was at the moment, I've classified them as, um, quite well,

312
00:26:53,120 --> 00:26:58,880
standard analytics with the plan for more improved insights. So now let's have at the moment,

313
00:26:59,520 --> 00:27:06,960
so we're using, um, things like Amazon's, Elasticsearch, and Athena, um, to give us,

314
00:27:06,960 --> 00:27:11,120
you know, real time, so it's in real time that we can actually see, so the key things are in

315
00:27:11,120 --> 00:27:18,800
chat, what is the, um, the conversation flow, um, they missed other answers, and missed intense,

316
00:27:18,800 --> 00:27:26,480
where that terminology is, if you're not aware, um, like if you say something like book me a meeting

317
00:27:26,480 --> 00:27:31,600
with Gillian McCann, and it goes, sorry, I didn't understand, and it repeatedly says that is that,

318
00:27:31,600 --> 00:27:37,200
that we haven't modeled that conversation within the chat box. So we're going to say, you know,

319
00:27:37,200 --> 00:27:42,880
what people are asking that doesn't match, or what we actually find more important was,

320
00:27:42,880 --> 00:27:48,960
miss, we call them mismatch intense, it did match something, but it matched the wrong thing. So,

321
00:27:48,960 --> 00:27:54,720
you're trying to book a meeting, and it's given you the cafe menu, so, yeah, just, so this,

322
00:27:54,720 --> 00:28:00,080
so it's, it's the, to me, that's the performance of lags, the performance of the analytics itself,

323
00:28:00,080 --> 00:28:06,000
how well have we created, um, the model, what sample utterances have we provided, is something

324
00:28:06,000 --> 00:28:12,160
we can train, are people say things in a different way than you actually expected? So then we,

325
00:28:12,160 --> 00:28:16,240
we see those, we're able to say that, and we're able to, you know, bring that back into the

326
00:28:16,240 --> 00:28:22,480
lags model and immediately retrain it, um, but then we have analytics on more, I'd say, for me,

327
00:28:22,480 --> 00:28:29,920
you search, you search context, sort of like, um, very high level, you know, job roles or location,

328
00:28:29,920 --> 00:28:34,880
it's your specific questions are coming from a specific office, you know, that maybe you'll help

329
00:28:34,880 --> 00:28:42,000
you get insights into, well, what is the problem there, I'm not here, why are they asking that? Um, so,

330
00:28:42,000 --> 00:28:46,800
that's the, um, that's where we're at the moment, I also say to me, it was quite standard stuff,

331
00:28:46,800 --> 00:28:54,400
but with the plan to be more involved, um, where really it gets into what I call the key thing in

332
00:28:54,400 --> 00:29:00,560
any conversation is context, right? So the context, and we have different levels of context,

333
00:29:00,560 --> 00:29:07,280
um, at the moment it would be things like the user, like the office, location, um, job role,

334
00:29:07,280 --> 00:29:13,200
um, how does that context impact the answer or the conversation? So really, when I talk about

335
00:29:13,200 --> 00:29:18,960
a personal assistant, you want it personalized to you, so it understands, you know, you,

336
00:29:18,960 --> 00:29:24,400
so context from a user perspective, um, then context also could include the device that you're

337
00:29:24,400 --> 00:29:31,520
on, and the capabilities that it has, um, and then getting into what I like to call, it's like

338
00:29:31,520 --> 00:29:38,320
the short term and the long term memory, the conversational context, um, where we can understand,

339
00:29:38,320 --> 00:29:42,640
you know, what you've previously said is in this conversation, there's nothing worse than somebody

340
00:29:42,640 --> 00:29:46,640
you say, something to somebody in that two minutes later, they can completely say the same thing

341
00:29:46,640 --> 00:29:50,960
and ask the same question again, they haven't remembered what you said, so it's really, you know,

342
00:29:50,960 --> 00:29:57,520
how do we tree in the chat box to not be annoying like that? So look, you know, in that example,

343
00:29:57,520 --> 00:30:03,120
can I book a meeting with you? I'm a can, yes, what time would you like? And then you say something,

344
00:30:03,120 --> 00:30:10,640
and then jump back to, is she free at 3 p.m. tomorrow? The she has to refer to me. Do you know what

345
00:30:10,640 --> 00:30:15,520
of me? We need to build that in, and that's the context, and then longer term is where I would like

346
00:30:15,520 --> 00:30:21,840
to get to, is that we can start using predictive analytics, you know, we understand your patterns,

347
00:30:21,840 --> 00:30:27,600
we understand that you ask for the coffee menu for Friday, um, why don't we send you that

348
00:30:27,600 --> 00:30:32,160
in advance? Why don't we talk to you? Um, so it's getting, that's why being sort of, it's an

349
00:30:32,160 --> 00:30:39,120
evolving path, and that's where, you know, we start looking at other areas of AI, you know,

350
00:30:39,120 --> 00:30:43,520
potentially machine learning, if we've got like a history of conversations, can you predict

351
00:30:43,520 --> 00:30:49,840
what the next conversation's going to be? Would that be useful even? What would that do? So I think

352
00:30:49,840 --> 00:30:55,440
the base of all this is getting, um, that's what putting place is the foundations of what I say,

353
00:30:55,440 --> 00:31:00,160
good quality analytics, and then we can evolve up, look for insights, and hopefully, you know,

354
00:31:00,160 --> 00:31:07,200
again, employees that better experience, as it learns, as it gets better. You mentioned also that

355
00:31:07,200 --> 00:31:14,960
one of the topics you covered was about the deployment, scale, CICD pipelines, all that kind of stuff.

356
00:31:15,520 --> 00:31:22,400
Can you give us an overview of the kind of things that you have done there to facilitate

357
00:31:22,960 --> 00:31:29,360
building out these kinds of applications on the engineering side? Yeah, um, so, um, like for any

358
00:31:29,360 --> 00:31:36,960
standard, um, application, you know, we have certain practices, um, we would run unit tests,

359
00:31:36,960 --> 00:31:43,200
integration tests, we would run those locally, you check your code in, the bell pipeline,

360
00:31:43,200 --> 00:31:49,600
picks those up, runs more tests, um, and then pushes through the environment. So that's the general,

361
00:31:49,600 --> 00:31:54,560
you know, process. Um, so what we had to do was come up with like a test framework essentially

362
00:31:54,560 --> 00:32:01,680
for less itself, um, you know, a unit testing conversation. So that's what we built into the

363
00:32:01,680 --> 00:32:09,520
pipeline was, um, the ability to, um, you know, we had scripted conversations that we would run

364
00:32:09,520 --> 00:32:14,720
on every single build to make sure that a change, you know, we may have added new utterances or new

365
00:32:14,720 --> 00:32:21,760
intents, hadn't impacted the model and the answers for all the other intents, and we did find that,

366
00:32:21,760 --> 00:32:28,400
you know, a real, um, a real benefit because, you know, we were making changes, we were,

367
00:32:28,960 --> 00:32:33,760
what made one thing work, made a different thing break. So we're finding it and constantly having

368
00:32:33,760 --> 00:32:39,920
that, um, backup of, we're not breaking it. And that's a standard process, but it was in a new

369
00:32:39,920 --> 00:32:45,600
world and a new, sorry, technology. So we had to think about how to apply those, but I would say

370
00:32:45,600 --> 00:32:52,960
good practices to this new, new way of creating software. Um, so we did that. The other thing that

371
00:32:52,960 --> 00:32:58,640
was very important was the building of the bought itself, um, you know, for anybody who has worked

372
00:32:58,640 --> 00:33:05,440
in a large enterprise company, um, there is certain rules and standards and things have to be

373
00:33:05,440 --> 00:33:10,800
put in place. And one of them is very specific, a runner usage of the public load in that we have

374
00:33:10,800 --> 00:33:19,680
a sandbox environment for people to prototype POC and, um, learn about how to use new services,

375
00:33:19,680 --> 00:33:27,120
but beyond that, everything has to be pushed through those accounts, um, through code. So we had

376
00:33:27,120 --> 00:33:33,760
to come up with a whole build pipeline for Amazon Lacks and the bought itself, um, which we created,

377
00:33:33,760 --> 00:33:40,320
um, when we were waiting on, literally, um, 19th of April, because I was waiting on the date,

378
00:33:40,320 --> 00:33:46,560
when it went GA and the build SDKs were released. Um, I think that's, I think it surprised

379
00:33:46,560 --> 00:33:51,360
Amazon because we've heard from them, um, after fact, that, you know, they just thought people

380
00:33:51,360 --> 00:33:56,960
would do it in the console. It's like, well, that's great for POC. It's not going to get us into

381
00:33:56,960 --> 00:34:03,040
production. So that's where we worked, um, on those aspects of it, which in the scheme of things

382
00:34:03,040 --> 00:34:07,280
when you hear people talk about chat box, it's not the things we talk about, but those are the

383
00:34:07,280 --> 00:34:12,800
practices that we'll get to into, you know, a, a chat box environment that will, you know,

384
00:34:12,800 --> 00:34:17,680
scale the thousands of employees and then with work rates off, where obviously thousands of

385
00:34:17,680 --> 00:34:22,640
employees across multiple countries, some companies, so you're in their multi-tenant chat box

386
00:34:22,640 --> 00:34:29,040
environment. So it's really taken, you know, best practices, I think is what I would say,

387
00:34:29,040 --> 00:34:33,600
and bring it into a chat box world. Um, and when they were experimenting, I said,

388
00:34:33,600 --> 00:34:39,600
voice, um, how do you test the speech recognition, how do you do those things. So it's all very

389
00:34:39,600 --> 00:34:45,360
interesting, very exciting, um, to be honest. Um, and I think it's probably clear, like the,

390
00:34:45,360 --> 00:34:50,880
the driver or the, not the driver, the enabler for a list, to me, it's, it's public cloud.

391
00:34:50,880 --> 00:34:56,240
Whichever one that you're working in is, you know, they're all comparative and competitive services.

392
00:34:57,040 --> 00:35:03,360
But really, to me, it's the, the place that enablers developers just even get started,

393
00:35:03,360 --> 00:35:10,400
with aspects of AI. Um, you know, if you do have an interest, it definitely is a place to experiment

394
00:35:10,400 --> 00:35:17,280
with. Have you run into any downsides or limitations associated with running in the

395
00:35:17,280 --> 00:35:24,000
public cloud or depending on the public cloud services? Um, I think the, I don't know if it's

396
00:35:24,000 --> 00:35:30,640
done, there's no real dying science because, um, you know, as I talked about, I like to,

397
00:35:30,640 --> 00:35:38,160
I, I personally feel that from an AI perspective, um, that there's few companies that would be able

398
00:35:38,160 --> 00:35:44,560
to compete with some of the capabilities that are being made available in public cloud. Um,

399
00:35:44,560 --> 00:35:49,360
just from the ease of use, um, the, the rollout, like the new service of the release,

400
00:35:49,360 --> 00:35:54,960
the re-infair for example, just so many new stuff. Um, you know, but I think the,

401
00:35:54,960 --> 00:36:00,880
the, the guy inside, it's not dying science, it's just an awareness of where your data is, you know,

402
00:36:00,880 --> 00:36:06,960
um, make sure that you thoroughly think through what data you're trying to store. Um, you know,

403
00:36:06,960 --> 00:36:12,560
it doesn't need to be anonymized. So it's just, you know, I think a general understanding of how

404
00:36:12,560 --> 00:36:18,640
the cloud works needs to be there before you just start turning things on, um, sending data everywhere.

405
00:36:18,640 --> 00:36:26,480
Um, buzzer say, like, I have that. So, you know, every service we use, um, and it is assessed

406
00:36:26,480 --> 00:36:33,120
through a security process that we will have. Um, I don't think not a dying site, but just have

407
00:36:33,120 --> 00:36:39,840
an awareness, um, of all the different services that you potentially use in your, um, product.

408
00:36:40,560 --> 00:36:46,640
Well, Jillian, thanks so much for taking the time to chat with us. So there are any final thoughts

409
00:36:46,640 --> 00:36:52,560
or things that you'd like to add? Um, I think as far as I have said it several times, I just see,

410
00:36:52,560 --> 00:36:58,960
you know, the voice, um, as the future interface, um, for people who are interested, you know,

411
00:36:58,960 --> 00:37:05,360
in the ability, not the, you know, it lacks, um, the developer skills SDK and the Google Assistant,

412
00:37:05,360 --> 00:37:11,200
you know, if anybody's any interest, they literally can start tomorrow and create simple skills

413
00:37:11,200 --> 00:37:18,720
and have a go because it really opens your eyes to the potential, um, of high, you know,

414
00:37:18,720 --> 00:37:24,160
certain aspects of AI I want to change your lives. Awesome. Well, Jillian, thank you. Thank you so

415
00:37:24,160 --> 00:37:33,680
much. It was great chatting with you. Thank you. All right, everyone. That's our show for today.

416
00:37:33,680 --> 00:37:39,360
For more information on Jillian or any of the topics covered in this episode, head on over to

417
00:37:39,360 --> 00:37:48,800
twimmelai.com slash talk slash 167. Don't forget to visit twimmelai.com slash nominate to cast

418
00:37:48,800 --> 00:37:56,400
your vote for us for this year's People's Choice Podcast Awards. As always, thanks so much for

419
00:37:56,400 --> 00:38:11,360
listening and catch you next time.

