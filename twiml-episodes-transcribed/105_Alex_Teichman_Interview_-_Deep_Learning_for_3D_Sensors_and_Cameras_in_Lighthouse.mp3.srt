1
00:00:00,000 --> 00:00:16,120
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

2
00:00:16,120 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:32,440
I'm your host Sam Charrington.

4
00:00:32,440 --> 00:00:33,840
Contest alert.

5
00:00:33,840 --> 00:00:38,960
This week we have a jam-packed intro, including a new contest we're launching.

6
00:00:38,960 --> 00:00:43,040
So please bear with me, you don't want to miss this one.

7
00:00:43,040 --> 00:00:46,720
First, a bit about this week's shows.

8
00:00:46,720 --> 00:00:51,440
As you may know, I spent a few days at CES earlier this month.

9
00:00:51,440 --> 00:00:56,400
While there, I spoke with a bunch of folks applying AI in the consumer electronics industry,

10
00:00:56,400 --> 00:01:01,040
and I'm including you in those conversations via this series of shows.

11
00:01:01,040 --> 00:01:05,440
Stay tuned as we explore some of the very cool ways that machine learning and AI are being

12
00:01:05,440 --> 00:01:08,600
used to enhance our everyday lives.

13
00:01:08,600 --> 00:01:13,680
This includes work being done at Anki, who built Cosmo, the cutest little computer vision-powered

14
00:01:13,680 --> 00:01:15,280
robot.

15
00:01:15,280 --> 00:01:22,120
Nighthouse, whose smart home security camera combines 3D sensing with deep learning and NLP.

16
00:01:22,120 --> 00:01:28,120
Intel, who's using the single-shot multi-box image detection algorithm to personalize video

17
00:01:28,120 --> 00:01:31,680
fees for the Ferrari Challenge North America.

18
00:01:31,680 --> 00:01:36,480
First beat, a company whose machine learning algorithms analyzed your heartbeat data to

19
00:01:36,480 --> 00:01:42,360
provide personalized insights into stress, exercise, and sleep patterns.

20
00:01:42,360 --> 00:01:48,400
3AI and Koito, who have partnered to bring machine learning-based adaptive driving beams

21
00:01:48,400 --> 00:01:52,280
or automatically adjusting high beams to the U.S.

22
00:01:52,280 --> 00:01:59,480
And last but not least, aerial.ai, who applies sophisticated analytics to Wi-Fi signals to

23
00:01:59,480 --> 00:02:05,640
enable some really interesting home automation and healthcare applications.

24
00:02:05,640 --> 00:02:11,000
Now, as if six amazing interviews wasn't enough, a few of these companies have been so

25
00:02:11,000 --> 00:02:15,520
kind as to provide us with products for you, the Twimmel community.

26
00:02:15,520 --> 00:02:19,360
And keeping with the theme of this series, our contest will be a little different this

27
00:02:19,360 --> 00:02:20,360
time.

28
00:02:20,360 --> 00:02:25,400
To enter, we want to hear from you about the role AI is playing in your home and personal

29
00:02:25,400 --> 00:02:28,640
life, and where you see it going.

30
00:02:28,640 --> 00:02:36,200
Just head on over to twimmelai.com slash myaicontest, fire up your webcam or smartphone camera,

31
00:02:36,200 --> 00:02:39,120
and tell us your story in two minutes or less.

32
00:02:39,120 --> 00:02:43,600
Go post the videos to YouTube, and the video with the most likes wins their choice of

33
00:02:43,600 --> 00:02:50,480
great prizes, including an Anki Cosmo, a lighthouse smart home camera, and more.

34
00:02:50,480 --> 00:02:55,040
Submissions will be taken until February 11th, and voting will remain open until February

35
00:02:55,040 --> 00:02:56,040
18th.

36
00:02:56,040 --> 00:03:02,360
Good luck.

37
00:03:02,360 --> 00:03:06,560
Before we dive into today's show, I'd like to thank our friends at Intel AI for their

38
00:03:06,560 --> 00:03:09,520
continued support of this podcast.

39
00:03:09,520 --> 00:03:14,760
Intel was extremely active at this year's CES, with a bunch of AI autonomous driving

40
00:03:14,760 --> 00:03:17,200
and VR-related announcements.

41
00:03:17,200 --> 00:03:21,440
One of the more interesting partnerships they announced was a collaboration with the Ferrari

42
00:03:21,440 --> 00:03:24,720
Challenge North America race series.

43
00:03:24,720 --> 00:03:29,440
Along with the folks at Ferrari Challenge, Intel AI aspires to make the race viewing experience

44
00:03:29,440 --> 00:03:35,360
more personalized by using deep computer vision to detect and monitor individual race

45
00:03:35,360 --> 00:03:40,680
cars via camera feeds, and allow viewers to choose the specific cars feeds that they'd

46
00:03:40,680 --> 00:03:42,920
like to watch.

47
00:03:42,920 --> 00:03:47,800
Look for my conversation with Intel's Andy Keller and Emil Chindicki later in this series

48
00:03:47,800 --> 00:03:54,480
for an in-depth discussion about this project, and be sure to visit ai.intel.com, where you'll

49
00:03:54,480 --> 00:03:58,080
find Andy's technical blog post on the topic.

50
00:03:58,080 --> 00:04:01,760
And now a bit about today's show.

51
00:04:01,760 --> 00:04:07,280
In this episode, I sit down with Alex Teichmann, CEO and co-founder of Lighthouse, a company

52
00:04:07,280 --> 00:04:11,480
taking a new approach to the in-home smart security camera.

53
00:04:11,480 --> 00:04:16,040
Alex and I dig into what exactly the Lighthouse product is, and all of the interesting stuff

54
00:04:16,040 --> 00:04:22,000
inside, including its combination of 3D sensing, computer vision, and natural language processing.

55
00:04:22,000 --> 00:04:26,320
We also talk about Alex's process for building the Lighthouse network architecture.

56
00:04:26,320 --> 00:04:30,440
The tech stack the product is based on, and some things that surprised him in their efforts

57
00:04:30,440 --> 00:04:33,640
to get AI into a consumer product.

58
00:04:33,640 --> 00:04:35,880
And now on to the show.

59
00:04:35,880 --> 00:04:37,880
All right, everyone.

60
00:04:37,880 --> 00:04:42,240
I am here at CES, and I've got the pleasure of being seated with Alex Teichmann.

61
00:04:42,240 --> 00:04:45,440
Alex is the CEO and co-founder of Lighthouse.

62
00:04:45,440 --> 00:04:47,840
Alex, welcome to this weekend machine learning and AI.

63
00:04:47,840 --> 00:04:48,840
Excellent.

64
00:04:48,840 --> 00:04:49,840
Thank you.

65
00:04:49,840 --> 00:04:50,840
Absolutely.

66
00:04:50,840 --> 00:04:52,160
Great to have you on the show.

67
00:04:52,160 --> 00:04:57,600
So, why don't we get started by having you tell us a little bit about your background.

68
00:04:57,600 --> 00:05:00,200
You've done some interesting things in the AI sphere.

69
00:05:00,200 --> 00:05:01,200
Oh, thanks.

70
00:05:01,200 --> 00:05:02,200
Thanks.

71
00:05:02,200 --> 00:05:03,200
Yeah.

72
00:05:03,200 --> 00:05:07,160
So, my background is in perception systems for self-driving cars.

73
00:05:07,160 --> 00:05:11,840
This is all about getting them to understand what they see in the world.

74
00:05:11,840 --> 00:05:16,320
What is a car, and what is a bicyclist, and what is a pedestrian, and that sort of thing.

75
00:05:16,320 --> 00:05:23,720
So, I joined Sebastian Thruns Lab back in 2007, right when the DARPA challenges were

76
00:05:23,720 --> 00:05:24,720
wrapping up.

77
00:05:24,720 --> 00:05:28,240
What were some of the specific things you were working on there?

78
00:05:28,240 --> 00:05:34,440
So, my focus was on how you use 3D sensing, lidar in particular, in that case, to do a better

79
00:05:34,440 --> 00:05:39,160
job of understanding what you're seeing in the world, you being a self-driving car or

80
00:05:39,160 --> 00:05:40,640
a computer more generally.

81
00:05:40,640 --> 00:05:45,680
So, this is very different from using a regular color camera to understand what you see in

82
00:05:45,680 --> 00:05:47,280
the world.

83
00:05:47,280 --> 00:05:53,480
When you have a 3D sensor, you've got the full structure to work with in real time.

84
00:05:53,480 --> 00:05:57,560
And that opens up a variety of different computer vision techniques, and it makes many of

85
00:05:57,560 --> 00:06:04,200
the very difficult computer vision subproblems quite easy, not all of them, but it makes many

86
00:06:04,200 --> 00:06:05,200
of them easy.

87
00:06:05,200 --> 00:06:06,560
Can you give us an example of that?

88
00:06:06,560 --> 00:06:07,560
Yeah.

89
00:06:07,560 --> 00:06:12,400
So, for example, segmentation and tracking of objects for which you have no computer vision

90
00:06:12,400 --> 00:06:18,720
model is extraordinarily difficult with regular video, but when you have a 3D sensor and when

91
00:06:18,720 --> 00:06:23,040
certain assumptions are met, then you could do a very good job segmenting and tracking

92
00:06:23,040 --> 00:06:27,240
objects, even if you have no idea what they are, if you have no semantic information whatsoever.

93
00:06:27,240 --> 00:06:32,720
And this is something that's made use so very heavily in the self-driving car world, where

94
00:06:32,720 --> 00:06:35,960
you can see that there is a physical thing in the structure of the environment, and it's

95
00:06:35,960 --> 00:06:36,960
moving around.

96
00:06:36,960 --> 00:06:40,040
You don't have to know what it is to drive safely around it.

97
00:06:40,040 --> 00:06:47,760
Yeah, there seems to be a, you know, there's a school of thought in and around the self-driving

98
00:06:47,760 --> 00:06:53,320
cars that is taking advantage of what you're describing using LIDAR and things like that,

99
00:06:53,320 --> 00:06:56,560
but then there's another school of thought where folks are saying LIDAR is too expensive

100
00:06:56,560 --> 00:07:05,360
to be on every production vehicle, and we're going to try and do things with just cameras.

101
00:07:05,360 --> 00:07:06,600
Any thoughts on that?

102
00:07:06,600 --> 00:07:07,600
It's hard.

103
00:07:07,600 --> 00:07:08,600
Which one?

104
00:07:08,600 --> 00:07:09,600
That's all of it.

105
00:07:09,600 --> 00:07:10,600
Yeah, no, no.

106
00:07:10,600 --> 00:07:15,360
Well, getting all this stuff to work with just regular color cameras, it will eventually

107
00:07:15,360 --> 00:07:16,360
happen, right?

108
00:07:16,360 --> 00:07:20,640
The information is all there, and humans do it with what essentially amounts to just a

109
00:07:20,640 --> 00:07:21,640
camera.

110
00:07:21,640 --> 00:07:26,840
It's not very effective at that range, right?

111
00:07:26,840 --> 00:07:31,080
We are just machines in some sense, very complex, very sophisticated machines, but we are

112
00:07:31,080 --> 00:07:32,080
able to do it.

113
00:07:32,080 --> 00:07:35,760
The information is there, and eventually we will get computers to be able to do that sort

114
00:07:35,760 --> 00:07:40,120
of thing, but we seem to be a long way off from that.

115
00:07:40,120 --> 00:07:40,960
It is quite hard.

116
00:07:40,960 --> 00:07:46,960
This is why virtually every self-driving car project is using LIDAR, because it makes

117
00:07:46,960 --> 00:07:50,440
many of those hard problems a lot easier.

118
00:07:50,440 --> 00:07:54,360
So, fast forward to LIDAR, what's LIDAR up to?

119
00:07:54,360 --> 00:08:01,560
Yeah, so the story of LIDAR, so we were talking a lot about self-driving cars here.

120
00:08:01,560 --> 00:08:07,480
What we're doing is basically we're taking that set of computer vision and machine perception

121
00:08:07,480 --> 00:08:12,840
techniques, and we're translating that from the self-driving car world into the home.

122
00:08:12,840 --> 00:08:18,560
That's the technology perspective on what LIDAR is, that's the machine learning perspective.

123
00:08:18,560 --> 00:08:24,760
From the customer perspective, LIDAR is, imagine you had a traditional home camera, but it

124
00:08:24,760 --> 00:08:28,680
had the intelligence of something like Alexa or Google Home.

125
00:08:28,680 --> 00:08:33,520
It's a new kind of interactive assistant that's based on this 3D sensing and computer vision

126
00:08:33,520 --> 00:08:39,600
and cameras that lets you tell it what you care about, and then it tells you when it sees

127
00:08:39,600 --> 00:08:41,200
those things happen.

128
00:08:41,200 --> 00:08:49,760
And is the application, is it security or personal virtual assistant or something beyond?

129
00:08:49,760 --> 00:08:50,760
It's both.

130
00:08:50,760 --> 00:08:51,760
Okay.

131
00:08:51,760 --> 00:08:52,760
Okay.

132
00:08:52,760 --> 00:08:56,000
So, give me an example of how I might use it.

133
00:08:56,000 --> 00:08:57,000
Yeah.

134
00:08:57,000 --> 00:09:01,440
So, one thing you can do with Lighthouse is you can say, tell me if you don't see the kids

135
00:09:01,440 --> 00:09:06,240
by 4 p.m. on weekdays, and you literally just say those words, that's it.

136
00:09:06,240 --> 00:09:08,160
It understands what you're asking for.

137
00:09:08,160 --> 00:09:11,400
It has a very good computer vision model for what children are, it knows what they look

138
00:09:11,400 --> 00:09:15,360
like, and it knows that you're asking for, you know, by 4 p.m. on weekdays, Monday

139
00:09:15,360 --> 00:09:20,200
through Friday, and if it doesn't see children by that time, Monday through Friday, it'll

140
00:09:20,200 --> 00:09:21,200
send you a notification.

141
00:09:21,200 --> 00:09:22,200
Okay.

142
00:09:22,200 --> 00:09:23,960
And if it does, then it won't bother you.

143
00:09:23,960 --> 00:09:24,960
Right.

144
00:09:24,960 --> 00:09:25,960
Interesting.

145
00:09:25,960 --> 00:09:32,320
A few years ago, I was, I had some crazy project that I was going to do around the house

146
00:09:32,320 --> 00:09:37,920
and one of the first things I started trying to figure out was presence, and this was

147
00:09:37,920 --> 00:09:45,840
pre-deep learning, CNNs, all that kind of stuff, and I started looking at NFC and all

148
00:09:45,840 --> 00:09:51,480
these other kinds of things, and it's just so obvious now that the cameras and vision

149
00:09:51,480 --> 00:09:54,240
is the way to do this.

150
00:09:54,240 --> 00:09:58,960
What are some of the challenges associated with deploying a kind of a vision appliance,

151
00:09:58,960 --> 00:10:02,000
I guess, in the home environment?

152
00:10:02,000 --> 00:10:06,560
Well, everything in computer vision is hard to celebrate, because it's new or kind of

153
00:10:06,560 --> 00:10:11,360
just like the dawn of artificial intelligence here, and all of these different techniques

154
00:10:11,360 --> 00:10:13,880
are very cutting edge.

155
00:10:13,880 --> 00:10:18,000
So we're really pushing the boundaries in what's possible with deep learning, and combining

156
00:10:18,000 --> 00:10:24,200
that intelligently with the sorts of techniques you can use with 3D sensing, in particular

157
00:10:24,200 --> 00:10:27,640
around segmentation and tracking.

158
00:10:27,640 --> 00:10:32,120
There is a lot of complexity and a lot of difficulty around building the hardware to do this, too,

159
00:10:32,120 --> 00:10:39,040
because this is the first 3D sensor that has a 95-degree diagonal field of view that

160
00:10:39,040 --> 00:10:45,600
can see how it depends on the details, but 7 to 10 meters is typical.

161
00:10:45,600 --> 00:10:48,040
It's quite challenging to put all that stuff together.

162
00:10:48,040 --> 00:10:51,760
Hardware is hard, is the phrase for a reason.

163
00:10:51,760 --> 00:10:52,760
Right.

164
00:10:52,760 --> 00:10:57,840
So is the device itself a kind of a connect-plus-a-camera?

165
00:10:57,840 --> 00:11:03,520
You can actually kind of think of it that way, so it uses a different underlying depth

166
00:11:03,520 --> 00:11:04,520
sensing technique.

167
00:11:04,520 --> 00:11:09,160
It actually depends on which connect you're referring to.

168
00:11:09,160 --> 00:11:13,240
So the original connect was structured lights, and it's kind of like stereo.

169
00:11:13,240 --> 00:11:17,160
There's like a texture pattern going out, a projector, and you know where that projector

170
00:11:17,160 --> 00:11:20,160
is, and there's an infrared camera, and you can triangulate from that.

171
00:11:20,160 --> 00:11:21,160
That was the original connect.

172
00:11:21,160 --> 00:11:25,560
It was actually what we prototyped Lighthouse on in the very beginning, and what we're

173
00:11:25,560 --> 00:11:29,200
using now is a time-of-flight camera, where that sends out modulated light, and then you

174
00:11:29,200 --> 00:11:34,400
look at the phase shift between that modulated light as it returns, and a reference signal

175
00:11:34,400 --> 00:11:38,760
in that phase shift, tells you how far away things are, essentially.

176
00:11:38,760 --> 00:11:44,600
So at every pixel in the image, not only do you see, you know, oh, it's like this shade

177
00:11:44,600 --> 00:11:50,680
of brown, you also see it's 3.72 meters away, you get that for the whole scene.

178
00:11:50,680 --> 00:11:51,680
Interesting.

179
00:11:51,680 --> 00:11:55,800
Trying to remember the name of this thing, there was a kickstarter that I backed.

180
00:11:55,800 --> 00:11:59,360
I haven't done anything with this thing yet, but it was like a mini-lightar scans, I think,

181
00:11:59,360 --> 00:12:00,360
was the name of it.

182
00:12:00,360 --> 00:12:01,360
Have you ever come across that?

183
00:12:01,360 --> 00:12:02,960
I haven't come across that one.

184
00:12:02,960 --> 00:12:05,400
Was it for scanning your face or your self?

185
00:12:05,400 --> 00:12:06,400
No.

186
00:12:06,400 --> 00:12:11,600
It was kind of, you know, for hobbyists, you could, you know, put it on a mobile robot and

187
00:12:11,600 --> 00:12:13,120
just experiment with it, that kind of thing.

188
00:12:13,120 --> 00:12:17,560
I don't think there was any, like, specific end user use case associated with it.

189
00:12:17,560 --> 00:12:18,560
Okay.

190
00:12:18,560 --> 00:12:23,640
So it was focused on kind of, I think it was just an example of, you know, the, the, you

191
00:12:23,640 --> 00:12:29,080
know, how to scale, light our down to something that fits in upon your hand and is relatively

192
00:12:29,080 --> 00:12:30,080
cheap.

193
00:12:30,080 --> 00:12:31,080
I see.

194
00:12:31,080 --> 00:12:32,080
Yeah.

195
00:12:32,080 --> 00:12:34,880
Yeah, I'm not familiar with that one, but, you know, both generations of the Connector,

196
00:12:34,880 --> 00:12:39,080
a good example, the iPhone X, there's a 3D sensor built into it and that's also a good

197
00:12:39,080 --> 00:12:40,080
example.

198
00:12:40,080 --> 00:12:43,360
They use that to make face ID actually reliable.

199
00:12:43,360 --> 00:12:47,560
And then, you know, self-driving cars, obviously, with all the different varieties of light

200
00:12:47,560 --> 00:12:53,400
that's out there, you know, maybe a little bit more detail around the, the, some more

201
00:12:53,400 --> 00:12:58,640
examples of kind of use cases for the device itself might be helpful.

202
00:12:58,640 --> 00:12:59,640
Yeah.

203
00:12:59,640 --> 00:13:00,640
Yeah.

204
00:13:00,640 --> 00:13:02,880
So I mentioned the one about, like, if the children don't come home by a particular time.

205
00:13:02,880 --> 00:13:07,120
And is it just children or is it like if Bobby doesn't come home or Susie doesn't come

206
00:13:07,120 --> 00:13:08,120
home?

207
00:13:08,120 --> 00:13:13,960
Like, do you, are you able to identify specific faces and associate them with, with kids or

208
00:13:13,960 --> 00:13:15,200
is it just children?

209
00:13:15,200 --> 00:13:16,200
Yeah.

210
00:13:16,200 --> 00:13:19,600
So you can do either, in fact, with lighthouse.

211
00:13:19,600 --> 00:13:23,160
So lighthouse has the ability to understand, oh, that is a child generally, it also has

212
00:13:23,160 --> 00:13:27,800
the ability to understand faces of specific people.

213
00:13:27,800 --> 00:13:32,880
And in particular, what, what that is most useful for is so you can do something like

214
00:13:32,880 --> 00:13:37,880
say to lighthouse, you know, hey, tell me if you see someone you don't recognize while

215
00:13:37,880 --> 00:13:41,280
Cindy and I are away, for example.

216
00:13:41,280 --> 00:13:45,760
And that lets you get at, you know, I don't know if your children bring home a new friend

217
00:13:45,760 --> 00:13:48,720
while you and your wife are out at work or something and you might just want to know,

218
00:13:48,720 --> 00:13:52,200
like, oh, who is this new person and it'll tell you about it, it'll send you a push notification

219
00:13:52,200 --> 00:13:53,960
when it sees that.

220
00:13:53,960 --> 00:13:57,560
Or if, you know, you have a dog walker or a babysitter and one day it's somebody different

221
00:13:57,560 --> 00:13:59,320
or somebody new is there, right?

222
00:13:59,320 --> 00:14:01,280
It'll proactively notify you about this.

223
00:14:01,280 --> 00:14:03,640
You don't have to go back and check every day, right?

224
00:14:03,640 --> 00:14:06,720
Because you have set up this alert with natural language.

225
00:14:06,720 --> 00:14:07,720
Mm-hmm.

226
00:14:07,720 --> 00:14:11,120
Yeah, it was just occurring to me that as you were describing these use cases that, you

227
00:14:11,120 --> 00:14:17,840
know, as complex as the, you know, the computer vision and the 3D sensing is there's also an

228
00:14:17,840 --> 00:14:24,680
NLP challenge like how do you capture, you know, the full breadth of what someone's going

229
00:14:24,680 --> 00:14:27,720
to want to ask this thing?

230
00:14:27,720 --> 00:14:33,360
Are there, you know, we've talked a bit on the podcast about some of the underlying

231
00:14:33,360 --> 00:14:37,200
NLP technologies and spoke with someone on the Alexa team.

232
00:14:37,200 --> 00:14:43,040
Like are there unique challenges associated with the way you're using NLP in the context

233
00:14:43,040 --> 00:14:45,040
of this device?

234
00:14:45,040 --> 00:14:49,760
So I wouldn't say there's necessarily, I don't know, unique research challenges on

235
00:14:49,760 --> 00:14:52,360
the natural language process inside.

236
00:14:52,360 --> 00:14:58,480
There are difficult and important engineering challenges that we need to nail on that side

237
00:14:58,480 --> 00:14:59,480
of things.

238
00:14:59,480 --> 00:15:04,280
It's the computer vision where the really, the really heavy duty, you know, research

239
00:15:04,280 --> 00:15:09,640
grade techniques are being deployed, at least for the current generation of Lighthouse.

240
00:15:09,640 --> 00:15:14,320
I mean, you can imagine, you know, Google Assistant needs to answer virtually any question

241
00:15:14,320 --> 00:15:15,320
you could throw away.

242
00:15:15,320 --> 00:15:16,320
Right.

243
00:15:16,320 --> 00:15:17,320
Right.

244
00:15:17,320 --> 00:15:19,480
With Lighthouse, there's actually a more restricted set of things.

245
00:15:19,480 --> 00:15:22,800
You know, if you ask Lighthouse for, you know, directions from like, you know, here or

246
00:15:22,800 --> 00:15:26,680
two, wherever, like we don't do that, that's not what we do.

247
00:15:26,680 --> 00:15:30,240
But for the set of things that we understand on the perception side, like we're, you know,

248
00:15:30,240 --> 00:15:33,960
it's actually we're very good at being able to answer those questions.

249
00:15:33,960 --> 00:15:34,960
It's a more constrained space.

250
00:15:34,960 --> 00:15:35,960
That makes the problem easier.

251
00:15:35,960 --> 00:15:36,960
There's more structure in it.

252
00:15:36,960 --> 00:15:37,960
Okay.

253
00:15:37,960 --> 00:15:42,600
And so do you, you know, when you're providing kind of the user manual for this thing, like

254
00:15:42,600 --> 00:15:48,160
are you telling someone these are the 10 things you could ask it or are you setting the expectation

255
00:15:48,160 --> 00:15:52,880
that they should just be able to ask it, things related to the kinds of stuff that it can

256
00:15:52,880 --> 00:15:53,880
do.

257
00:15:53,880 --> 00:15:54,880
Yeah.

258
00:15:54,880 --> 00:15:58,880
So we float rotating suggestions in front of people in the app, right?

259
00:15:58,880 --> 00:16:03,240
So like, so when you're in the kind of the natural language interface screen, you'll see

260
00:16:03,240 --> 00:16:07,080
here is, you know, here's the set of things you might consider asking some examples of

261
00:16:07,080 --> 00:16:11,280
these things in this category and it kind of guides you through what categories of things

262
00:16:11,280 --> 00:16:12,280
we understand.

263
00:16:12,280 --> 00:16:18,240
And that includes, you know, for object recognition, it's, you know, people and children and pets

264
00:16:18,240 --> 00:16:22,680
and that kind of thing for action recognition, recognize waving at the device.

265
00:16:22,680 --> 00:16:26,200
So you can say something like, hey, tell me if you see someone waving hello while I'm

266
00:16:26,200 --> 00:16:27,200
out.

267
00:16:27,200 --> 00:16:28,200
Okay.

268
00:16:28,200 --> 00:16:29,200
That kind of thing.

269
00:16:29,200 --> 00:16:36,280
I understand, you know, time ranges, we allow you to set up alerts for things that happen

270
00:16:36,280 --> 00:16:37,280
in the future.

271
00:16:37,280 --> 00:16:40,880
And so I'm going to kind of guide you through those different categories of what we do.

272
00:16:40,880 --> 00:16:42,400
Okay.

273
00:16:42,400 --> 00:16:48,520
And so on the computer vision side, what are kind of the key research level challenges

274
00:16:48,520 --> 00:16:51,040
that you're tackling?

275
00:16:51,040 --> 00:16:57,640
So what it is really coming down to is applying deep learning at a large scale with 3D sensors

276
00:16:57,640 --> 00:16:59,840
combined with color cameras.

277
00:16:59,840 --> 00:17:04,720
And there's, there are particular things that this set up let you do that you just can't

278
00:17:04,720 --> 00:17:06,560
do in any other domain.

279
00:17:06,560 --> 00:17:12,080
So for example, the 3D sensor lets you segment and track objects through the space without

280
00:17:12,080 --> 00:17:14,080
you having to have any sort of semantic understanding.

281
00:17:14,080 --> 00:17:16,240
You don't have to know what that thing is.

282
00:17:16,240 --> 00:17:18,640
You just know it's a thing and it's moving through the space.

283
00:17:18,640 --> 00:17:24,120
Now your unit of classification from a deep learning point of view is that segmented object

284
00:17:24,120 --> 00:17:26,360
track through space and time.

285
00:17:26,360 --> 00:17:28,640
And this enables several things.

286
00:17:28,640 --> 00:17:32,800
One, it's just more accurate because you have more views of an object as it's moving

287
00:17:32,800 --> 00:17:35,440
about and you can integrate all of that information.

288
00:17:35,440 --> 00:17:40,400
And two, it's a very, very natural setup for doing action recognition because you've got

289
00:17:40,400 --> 00:17:44,480
this thing moving through space and time and you can ask questions like is this a dog

290
00:17:44,480 --> 00:17:49,240
but also is this a dog jumping up on my couch or is this a person waving hello or you

291
00:17:49,240 --> 00:17:51,880
know, and so on.

292
00:17:51,880 --> 00:17:58,120
So it's a great setup for working on these kinds of very challenging computer vision problems.

293
00:17:58,120 --> 00:17:59,120
Okay.

294
00:17:59,120 --> 00:18:04,240
You've talked about kind of segmenting these objects and I'm thinking about this primarily

295
00:18:04,240 --> 00:18:06,640
being driven by the 3D sensor.

296
00:18:06,640 --> 00:18:12,720
In what ways does having the camera augment what you're able to do beyond just the 3D point

297
00:18:12,720 --> 00:18:13,720
cloud?

298
00:18:13,720 --> 00:18:20,320
Oh, well, so at deep learning time, it's a specialized architecture that's using both

299
00:18:20,320 --> 00:18:21,800
of those channels.

300
00:18:21,800 --> 00:18:27,880
So the almost the attentional mechanism, if you want to, if you want to call it that,

301
00:18:27,880 --> 00:18:29,960
that's primarily driven by the 3D sensor.

302
00:18:29,960 --> 00:18:33,600
But then once you're kind of analyzing what is this thing, now we use everything we

303
00:18:33,600 --> 00:18:34,600
have.

304
00:18:34,600 --> 00:18:35,600
Okay.

305
00:18:35,600 --> 00:18:39,600
And that is including the 3D sensor data, the point cloud of the object.

306
00:18:39,600 --> 00:18:43,440
As well as the color camera data, we combine these things in a deep learning architecture

307
00:18:43,440 --> 00:18:48,640
that uses both of those and then, you know, merges them and then goes into an LSTM

308
00:18:48,640 --> 00:18:54,600
for doing like, you know, understanding of what is happening over time, right?

309
00:18:54,600 --> 00:18:55,600
Okay.

310
00:18:55,600 --> 00:19:01,720
And so how do you, what was the process for kind of coming up with the network architecture

311
00:19:01,720 --> 00:19:03,480
for this thing?

312
00:19:03,480 --> 00:19:10,400
Did you start with something off the shelf like inception or, you know, name your network

313
00:19:10,400 --> 00:19:12,440
architecture or did you build it up from the ground up?

314
00:19:12,440 --> 00:19:13,440
Yeah.

315
00:19:13,440 --> 00:19:17,640
So, I mean, in this kind of context, it always makes sense to start from a baseline.

316
00:19:17,640 --> 00:19:21,760
It's reasonably easy to just, you know, pull a thing out of the box and deploy it, see

317
00:19:21,760 --> 00:19:22,760
what happens, right?

318
00:19:22,760 --> 00:19:25,840
And so we did that with, you know, Google and that 100 years ago just to see what would

319
00:19:25,840 --> 00:19:27,320
occur.

320
00:19:27,320 --> 00:19:30,480
And yeah, it was, you know, it did something, it was good.

321
00:19:30,480 --> 00:19:34,440
But it was pretty clear that we need to customize this thing to get the level of accuracy

322
00:19:34,440 --> 00:19:35,520
that we really want.

323
00:19:35,520 --> 00:19:36,520
Yeah.

324
00:19:36,520 --> 00:19:42,560
And then the process from there is, well, are you familiar with the phrase graduate student

325
00:19:42,560 --> 00:19:43,560
descent?

326
00:19:43,560 --> 00:19:44,560
Sure.

327
00:19:44,560 --> 00:19:45,560
Okay.

328
00:19:45,560 --> 00:19:46,560
Yes.

329
00:19:46,560 --> 00:19:55,400
But, I mean, it really, it's, you know, it's intuition combined with significant perseverance

330
00:19:55,400 --> 00:19:57,200
combined with lots of compute, right?

331
00:19:57,200 --> 00:20:02,800
Yeah, I think the current way of saying that post-Nips 2017 is alchemy.

332
00:20:02,800 --> 00:20:03,800
Yes.

333
00:20:03,800 --> 00:20:05,800
There's a lot of that.

334
00:20:05,800 --> 00:20:10,080
I mean, it's kind of sad, actually, in that like a lot of my, a lot of my PhD work was

335
00:20:10,080 --> 00:20:13,360
kind of like during the age when, you know, proper machine learning techniques should

336
00:20:13,360 --> 00:20:17,160
be, you know, convex and just like, yeah, it's a descent method, like you're always going

337
00:20:17,160 --> 00:20:20,000
downhill and just like roll to the bottom and you'll find the solution.

338
00:20:20,000 --> 00:20:21,000
It'll be great.

339
00:20:21,000 --> 00:20:22,000
Right.

340
00:20:22,000 --> 00:20:23,000
Right.

341
00:20:23,000 --> 00:20:25,600
And now it's just, it's non-convex and just like, maybe it's working and maybe it's not

342
00:20:25,600 --> 00:20:26,600
working.

343
00:20:26,600 --> 00:20:29,720
And, you know, oh, I don't know, try a, try a different momentum term and like maybe

344
00:20:29,720 --> 00:20:30,720
it'll work this time.

345
00:20:30,720 --> 00:20:31,720
Yeah.

346
00:20:31,720 --> 00:20:32,720
Right.

347
00:20:32,720 --> 00:20:35,560
And then it has, it has challenges and advantages too, right?

348
00:20:35,560 --> 00:20:36,960
Like now things actually work.

349
00:20:36,960 --> 00:20:37,960
That's pretty cool.

350
00:20:37,960 --> 00:20:38,960
Mm-hmm.

351
00:20:38,960 --> 00:20:45,520
So folks that are trying to productize around deep neural networks, like what, I mean,

352
00:20:45,520 --> 00:20:50,560
I just, you know, I guess I struggle with the, the graduate student descent as the answer,

353
00:20:50,560 --> 00:20:51,560
right?

354
00:20:51,560 --> 00:20:54,520
I guess, probably we all do a little bit.

355
00:20:54,520 --> 00:21:01,480
Have you developed, you know, any intuition or rigor around or methodology rather around

356
00:21:01,480 --> 00:21:07,720
kind of the way you, you know, the way you build out network architectures for, for

357
00:21:07,720 --> 00:21:12,840
this problem space or even maybe another question as background is like, was the network

358
00:21:12,840 --> 00:21:17,800
architecture like up front work that you did and it's kind of static or is it, what, how,

359
00:21:17,800 --> 00:21:19,600
how rapidly does that evolve?

360
00:21:19,600 --> 00:21:23,840
So, so that is an ongoing effort in many different ways.

361
00:21:23,840 --> 00:21:31,080
So in one way, we are, you know, collecting new annotated data all the time, you know,

362
00:21:31,080 --> 00:21:35,840
both from our own early access testers who provide us access to their data for us to

363
00:21:35,840 --> 00:21:37,600
use for training purposes.

364
00:21:37,600 --> 00:21:41,600
And also, if there is a mistake in the field, you can, you can annotate it as such and

365
00:21:41,600 --> 00:21:44,560
we'll make use of it and improve the models and we have, we have a stream of annotated

366
00:21:44,560 --> 00:21:45,560
data coming in.

367
00:21:45,560 --> 00:21:50,080
And so we're always taking the same network structure and taking that new training data

368
00:21:50,080 --> 00:21:52,440
and turning the crank and redeploying.

369
00:21:52,440 --> 00:21:57,320
And that cycle, I mean, it depends on the details, but that's on the order of days, right?

370
00:21:57,320 --> 00:22:03,680
The new architecture deployment cycle, that's more like weeks or months as we, you know,

371
00:22:03,680 --> 00:22:06,520
we come up with some new idea of like, oh, what if, you know, maybe we can compress the

372
00:22:06,520 --> 00:22:09,840
network this way or maybe it would make a lot of sense to, you know, build out this piece

373
00:22:09,840 --> 00:22:13,760
of the network and then we'll go work very hard and validate that new network and find

374
00:22:13,760 --> 00:22:17,320
out, oh, indeed, this, you know, reduces compute time on our end and produces a better

375
00:22:17,320 --> 00:22:18,320
experience for the customer.

376
00:22:18,320 --> 00:22:19,320
Great.

377
00:22:19,320 --> 00:22:20,320
Let's go deploy this.

378
00:22:20,320 --> 00:22:23,280
You know, it's all about large scale quantitative testing.

379
00:22:23,280 --> 00:22:26,320
And you mentioned compressing the architecture.

380
00:22:26,320 --> 00:22:32,200
Are you deploying the network on the device or are you doing inference in the cloud or something

381
00:22:32,200 --> 00:22:33,200
like that?

382
00:22:33,200 --> 00:22:34,200
It's largely in the cloud.

383
00:22:34,200 --> 00:22:35,200
Okay.

384
00:22:35,200 --> 00:22:38,880
There's a variety of reasons that make sense, although I should mention it is not entirely

385
00:22:38,880 --> 00:22:40,200
in the cloud.

386
00:22:40,200 --> 00:22:44,280
It really is a distributed computer vision system to squeeze all the last, you know, bits

387
00:22:44,280 --> 00:22:46,240
of performance out of it that we can.

388
00:22:46,240 --> 00:22:48,920
You really do want it to not all run in one place.

389
00:22:48,920 --> 00:22:52,720
It makes sense to have some of it run the device, some run in the backend.

390
00:22:52,720 --> 00:22:56,200
So talk a little bit about that in more detail, like how do you, you know, what is running

391
00:22:56,200 --> 00:23:00,560
on the device, how do you partition, what's running on the device and what's running in

392
00:23:00,560 --> 00:23:01,560
the cloud?

393
00:23:01,560 --> 00:23:02,560
Yeah.

394
00:23:02,560 --> 00:23:06,240
So the device is doing the attentional mechanism.

395
00:23:06,240 --> 00:23:09,400
It's doing the segmentation and tracking of what is interesting and new.

396
00:23:09,400 --> 00:23:10,400
Okay.

397
00:23:10,400 --> 00:23:14,600
And then there's nuance here, but at a high level, it's doing that.

398
00:23:14,600 --> 00:23:20,160
So at kind of a simplistic perspective, you're not sending a bunch of frames out to the

399
00:23:20,160 --> 00:23:23,160
cloud if there's nothing happening.

400
00:23:23,160 --> 00:23:24,160
That's largely correct.

401
00:23:24,160 --> 00:23:25,160
Yeah.

402
00:23:25,160 --> 00:23:30,200
We do have to send some data once in a while, you know, one frame every, you know, a few

403
00:23:30,200 --> 00:23:31,200
seconds, basically.

404
00:23:31,200 --> 00:23:32,200
Okay.

405
00:23:32,200 --> 00:23:33,200
Okay.

406
00:23:33,200 --> 00:23:35,520
This is actually so we can present to you a beautiful summary of the day.

407
00:23:35,520 --> 00:23:36,520
Okay.

408
00:23:36,520 --> 00:23:37,520
Right.

409
00:23:37,520 --> 00:23:41,560
So you, we call it a smart time lapse or a daily recap where you, you know, you press one

410
00:23:41,560 --> 00:23:46,000
button and you get a, you know, a 10 second or one minute kind of summary of what happened

411
00:23:46,000 --> 00:23:49,240
during the day and it goes fast during the boring parts and it goes slow when there's

412
00:23:49,240 --> 00:23:50,240
something of interest to you.

413
00:23:50,240 --> 00:23:51,240
Oh, interesting.

414
00:23:51,240 --> 00:23:52,240
Yeah.

415
00:23:52,240 --> 00:23:53,240
Okay.

416
00:23:53,240 --> 00:23:56,360
But yeah, generally, we actually, we don't have to stream 30 frames per seconds because

417
00:23:56,360 --> 00:23:59,520
it's actually not what customers really care about.

418
00:23:59,520 --> 00:24:07,200
Users don't care about, you know, what were the RGB pixel values at like 3.47 AM, you

419
00:24:07,200 --> 00:24:11,520
know, yesterday, what they care about is, you know, did my kids come home on time and

420
00:24:11,520 --> 00:24:14,560
what has the dog done since I left the house because I just think it makes me feel warm

421
00:24:14,560 --> 00:24:17,360
and fuzzy inside or, you know, was anybody new here?

422
00:24:17,360 --> 00:24:18,760
Who was new here last week?

423
00:24:18,760 --> 00:24:19,760
Just, you know, show me these things.

424
00:24:19,760 --> 00:24:20,760
Yeah.

425
00:24:20,760 --> 00:24:21,760
That's what they care about.

426
00:24:21,760 --> 00:24:26,240
We're, with traditional home cameras, we're kind of a wash in, in data, but we don't

427
00:24:26,240 --> 00:24:31,240
have much, you know, useful information and that's what Lighthouse is all about is taking

428
00:24:31,240 --> 00:24:36,600
that enormous stream of data and compressing it down into just the bits that you actually

429
00:24:36,600 --> 00:24:37,600
care about.

430
00:24:37,600 --> 00:24:38,600
Interesting.

431
00:24:38,600 --> 00:24:44,360
One thing that I'm curious about, you know, being kind of here at CES and seeing, you

432
00:24:44,360 --> 00:24:49,760
know, tons of different consumer-oriented products that are trying to incorporate AI

433
00:24:49,760 --> 00:24:55,760
in one way or another, are there any things that you've kind of learned that were surprising

434
00:24:55,760 --> 00:25:00,520
about, you know, pulling AI into consumer-oriented products?

435
00:25:00,520 --> 00:25:01,520
Yes.

436
00:25:01,520 --> 00:25:08,320
I actually, when we started Lighthouse, myself and my co-founder, I thought it would be

437
00:25:08,320 --> 00:25:12,920
the AI problems that were the hardest across the board.

438
00:25:12,920 --> 00:25:14,320
And they are hard, for sure.

439
00:25:14,320 --> 00:25:15,840
There's no question of that.

440
00:25:15,840 --> 00:25:19,240
It turns out there's other hard problems that you have to solve along the way.

441
00:25:19,240 --> 00:25:25,440
For example, getting the UX right, like getting the UI and the interface and the user experience

442
00:25:25,440 --> 00:25:27,680
really right, that's really quite difficult.

443
00:25:27,680 --> 00:25:32,880
It's something we spend a lot of time on because what we, you know, ultimately the reason

444
00:25:32,880 --> 00:25:37,280
we exist is to deliver a delightful and useful experience to our customers.

445
00:25:37,280 --> 00:25:40,720
And we're able to do that with AI, but like that's not the only thing.

446
00:25:40,720 --> 00:25:41,720
Yeah.

447
00:25:41,720 --> 00:25:44,200
And it's actually, it can be quite hard to get those things right.

448
00:25:44,200 --> 00:25:50,160
Especially in, you know, breaking new ground in a new kind of interactive assistance,

449
00:25:50,160 --> 00:25:53,960
how does one actually, you know, build the best interface to this kind of thing?

450
00:25:53,960 --> 00:25:55,880
It takes a lot of work and iteration.

451
00:25:55,880 --> 00:26:01,720
You know, do you have kind of the lighthouse laws of effective, intelligent user experience

452
00:26:01,720 --> 00:26:02,720
design?

453
00:26:02,720 --> 00:26:08,360
Like, have you, you know, boiled, you know, what you've learned down into key ideas that

454
00:26:08,360 --> 00:26:13,320
you tell a new team member?

455
00:26:13,320 --> 00:26:17,520
You know, I'm not sure we've refined it to that point, where I could concisely communicate

456
00:26:17,520 --> 00:26:18,520
something.

457
00:26:18,520 --> 00:26:19,520
Yeah.

458
00:26:19,520 --> 00:26:20,520
Yeah.

459
00:26:20,520 --> 00:26:29,840
I've asked people this on and off for the last couple of years, I think that it strikes

460
00:26:29,840 --> 00:26:37,720
me that, you know, we've developed a fair amount of, you know, fair amount of methodology

461
00:26:37,720 --> 00:26:41,680
around traditional user experience via mobile, via the web.

462
00:26:41,680 --> 00:26:49,520
And it strikes me that there's, you know, some sort of rules that will evolve around designing

463
00:26:49,520 --> 00:26:56,520
intelligent systems, or not that's kind of too broad, but presenting intelligent experiences

464
00:26:56,520 --> 00:27:01,640
to consumers, but I haven't really found, you know, no one said, oh, yeah, I read this

465
00:27:01,640 --> 00:27:02,640
book about it.

466
00:27:02,640 --> 00:27:04,440
We're still too early for that.

467
00:27:04,440 --> 00:27:05,440
Too early for this.

468
00:27:05,440 --> 00:27:10,880
There is one guiding principle, actually, that is worthy of mention here, that's something

469
00:27:10,880 --> 00:27:14,520
that's always kind of in the back of my mind with this kind of interface.

470
00:27:14,520 --> 00:27:22,400
The reason it exists is to make useful information accessible to you as quickly as possible.

471
00:27:22,400 --> 00:27:24,840
That's the reason natural language interfaces are good.

472
00:27:24,840 --> 00:27:30,720
So, you know, stepping outside of lighthouse, looking at something like Alexa or Google Home,

473
00:27:30,720 --> 00:27:34,880
one of the reasons they're so good is because, you know, you don't have to go find your phone

474
00:27:34,880 --> 00:27:37,720
or pull your phone out of your pocket and like unlock it and go to this, you know, go

475
00:27:37,720 --> 00:27:41,440
to the right app and then play your music and say, no, like, play it on this interface

476
00:27:41,440 --> 00:27:44,480
and then finally, it comes out where, you know, no, you just, you know, you just yell

477
00:27:44,480 --> 00:27:47,600
across the room, hey, play this thing and it just works, right?

478
00:27:47,600 --> 00:27:50,760
And the reason that's amazing is because it saves you 10 seconds.

479
00:27:50,760 --> 00:27:51,760
Right.

480
00:27:51,760 --> 00:27:52,760
And it seems so trivial, right?

481
00:27:52,760 --> 00:27:53,760
But it's not.

482
00:27:53,760 --> 00:27:56,240
It really, really, really matters.

483
00:27:56,240 --> 00:28:00,920
And when you look at this from the, I don't know if you want to call it the nerd point

484
00:28:00,920 --> 00:28:02,560
of view, certainly says me, right?

485
00:28:02,560 --> 00:28:11,600
But it's all about reducing latency and increasing bandwidth in the human machine interface.

486
00:28:11,600 --> 00:28:16,640
That's the point of natural language is that you have a thought in your mind.

487
00:28:16,640 --> 00:28:18,800
There's a thing you want to do.

488
00:28:18,800 --> 00:28:23,560
And right now, generally, you have to translate that into, okay, I'm going to pull up my phone.

489
00:28:23,560 --> 00:28:26,880
I'm going to tap on these buttons to get to the right app and then I'm going to tap on

490
00:28:26,880 --> 00:28:30,040
some more buttons to do the thing I'm trying to do and I have to go to this menu and adjust

491
00:28:30,040 --> 00:28:31,040
the slider buttons.

492
00:28:31,040 --> 00:28:32,040
It's like, right?

493
00:28:32,040 --> 00:28:33,040
It's just like, it's terrible.

494
00:28:33,040 --> 00:28:34,320
What you should do is there's that thought in your mind.

495
00:28:34,320 --> 00:28:35,320
Just say the thought.

496
00:28:35,320 --> 00:28:36,320
Right.

497
00:28:36,320 --> 00:28:37,320
And it just happens.

498
00:28:37,320 --> 00:28:38,320
Right.

499
00:28:38,320 --> 00:28:39,320
That's what that is.

500
00:28:39,320 --> 00:28:40,320
That is just so much better.

501
00:28:40,320 --> 00:28:44,840
But I don't know, it's an order of magnitude improvements in latency in that interface

502
00:28:44,840 --> 00:28:49,080
between this intelligence and my head and this intelligence in my phone.

503
00:28:49,080 --> 00:28:57,520
On the NLP side of things, did you start out with any of the kind of popular cloud-based

504
00:28:57,520 --> 00:28:59,600
platforms for doing that kind of stuff?

505
00:28:59,600 --> 00:29:04,880
Like the, I forget what it's called, not x.ai, what that is, but all the cloud vendors

506
00:29:04,880 --> 00:29:05,880
have their own.

507
00:29:05,880 --> 00:29:07,640
Or did you kind of roll your own?

508
00:29:07,640 --> 00:29:11,240
You know, they are useful prototyping platforms.

509
00:29:11,240 --> 00:29:14,960
And there may even be some applications where they get you all the way.

510
00:29:14,960 --> 00:29:17,920
But that is not the case for Lighthouse.

511
00:29:17,920 --> 00:29:23,440
I mean, I can tell you that for sure because I used one of them over a weekend to produce

512
00:29:23,440 --> 00:29:25,680
a little demo of like, hey, this is what I have in mind.

513
00:29:25,680 --> 00:29:30,880
I think this might be a way to really nail the user interface for this thing.

514
00:29:30,880 --> 00:29:34,920
By the way, actually, I mean, when we started Lighthouse, we knew the direction to go

515
00:29:34,920 --> 00:29:39,520
into to solve the perception problems, but we didn't know how to solve the UX problems.

516
00:29:39,520 --> 00:29:43,760
And it was only along the way that we discovered that like, oh, my God, natural language interfaces

517
00:29:43,760 --> 00:29:49,160
are the way to do this, like it is actually not possible as far as we are aware to produce

518
00:29:49,160 --> 00:29:53,960
an interface with buttons and sliders and whatever else it might be to get you to be able

519
00:29:53,960 --> 00:29:57,600
to say, hey, tell me if you're seeing anyone new at the doorstep while Cindy and I are

520
00:29:57,600 --> 00:29:58,600
away next week.

521
00:29:58,600 --> 00:29:59,600
Oh, yeah.

522
00:29:59,600 --> 00:30:00,600
Right?

523
00:30:00,600 --> 00:30:01,600
Like, how would you do that?

524
00:30:01,600 --> 00:30:02,600
Like, you just can't, right?

525
00:30:02,600 --> 00:30:03,600
But with natural language, it just works.

526
00:30:03,600 --> 00:30:04,600
It just works.

527
00:30:04,600 --> 00:30:05,600
Yep.

528
00:30:05,600 --> 00:30:06,600
Right.

529
00:30:06,600 --> 00:30:10,360
I've gotten that feedback quite a lot from folks that are trying to productize NLP, like

530
00:30:10,360 --> 00:30:18,800
the platforms are an interesting way to start, but you run out of runway in terms of their

531
00:30:18,800 --> 00:30:21,640
flexibility and ability to get you all the way.

532
00:30:21,640 --> 00:30:22,640
Yeah.

533
00:30:22,640 --> 00:30:23,640
So we built all around.

534
00:30:23,640 --> 00:30:24,640
Okay.

535
00:30:24,640 --> 00:30:25,960
It's the only thing to do in this area.

536
00:30:25,960 --> 00:30:30,640
Can you tell me a little bit about your tech stack generally?

537
00:30:30,640 --> 00:30:31,640
Yeah.

538
00:30:31,640 --> 00:30:32,640
Yeah.

539
00:30:32,640 --> 00:30:33,640
Happy to.

540
00:30:33,640 --> 00:30:39,840
We use a lot of C++, because this is build on device and in cloud.

541
00:30:39,840 --> 00:30:40,840
Both.

542
00:30:40,840 --> 00:30:41,840
Okay.

543
00:30:41,840 --> 00:30:46,280
It's a real-time, performance, memory-intensive, computer vision, right?

544
00:30:46,280 --> 00:30:53,080
Running at scale, well, either at scale on the back end or on a limited compute device

545
00:30:53,080 --> 00:30:55,720
out on the front end that is touching hardware, right?

546
00:30:55,720 --> 00:31:00,680
And so in both of these places, C++ is the right thing to use at that level.

547
00:31:00,680 --> 00:31:07,080
Now when we're prototyping a new architecture for our deep learning system, it's totally

548
00:31:07,080 --> 00:31:13,880
reasonable to twitle around in Python to have faster iterations on that.

549
00:31:13,880 --> 00:31:21,120
But ultimately when it's building and deploying real systems, it ends up being C++.

550
00:31:21,120 --> 00:31:27,560
So did you build out the NLP platform on C++ as well, like the whole system for intense

551
00:31:27,560 --> 00:31:28,560
and all that kind of stuff?

552
00:31:28,560 --> 00:31:29,920
I'm simplifying a bit, of course.

553
00:31:29,920 --> 00:31:34,560
So the core computer vision system is in C++, there's a Java layer around that because

554
00:31:34,560 --> 00:31:38,040
that's easier to interface with your phones, for example.

555
00:31:38,040 --> 00:31:42,080
And it turns out that's also a good place to build your natural language processing.

556
00:31:42,080 --> 00:31:48,960
For whatever reason, in academia, at least my circles of academia back in my Stanford days,

557
00:31:48,960 --> 00:31:52,040
natural language processing was generally done in Java.

558
00:31:52,040 --> 00:31:56,720
And computer vision on self-driving cars, for example, was like all C++.

559
00:31:56,720 --> 00:32:01,400
And it probably is the case that on self-driving cars, C++ is a more natural fit because

560
00:32:01,400 --> 00:32:04,200
you have to interface with sensors and you have real time requirements.

561
00:32:04,200 --> 00:32:08,880
And it's like very heavy data, whereas natural language processing is often less.

562
00:32:08,880 --> 00:32:14,280
So in any case, that is a natural fit, our natural language system is lives out there.

563
00:32:14,280 --> 00:32:21,480
And is the Java ecosystem for the natural language stuff as mature as the Python ecosystem?

564
00:32:21,480 --> 00:32:22,480
Or more maybe?

565
00:32:22,480 --> 00:32:24,480
That's a good question.

566
00:32:24,480 --> 00:32:26,280
I don't think I actually know.

567
00:32:26,280 --> 00:32:31,760
They were from a company perspective, where are you in kind of the life cycle of bringing

568
00:32:31,760 --> 00:32:33,280
this product to market?

569
00:32:33,280 --> 00:32:36,240
We are very close to general availability.

570
00:32:36,240 --> 00:32:42,160
So in fact, you can go to our website right now, www.light.house and enter your email.

571
00:32:42,160 --> 00:32:48,400
And we will add you to our special offer lists and if you're lucky, you might get one.

572
00:32:48,400 --> 00:32:54,800
And if not, we will be available for anybody to buy in the not too distant future.

573
00:32:54,800 --> 00:32:56,440
We are quite close now.

574
00:32:56,440 --> 00:32:57,440
Nice.

575
00:32:57,440 --> 00:33:01,120
As seen pictures of the device, it's like it looks like a, it's not a mobile device.

576
00:33:01,120 --> 00:33:02,120
It's stationary.

577
00:33:02,120 --> 00:33:05,320
You put it on a countertop or something like that.

578
00:33:05,320 --> 00:33:09,520
You know, you either have to be very, very strategic about where you put this thing or

579
00:33:09,520 --> 00:33:13,400
you have to envision a world where you've got ten of these all over the place.

580
00:33:13,400 --> 00:33:14,840
Kind of like a Lexus becoming, right?

581
00:33:14,840 --> 00:33:16,960
You have one in every room or something like that.

582
00:33:16,960 --> 00:33:18,520
Is that the way you're thinking about the world?

583
00:33:18,520 --> 00:33:26,400
Like you've got, you eventually have a full 3D and, you know, three color map of everyone's

584
00:33:26,400 --> 00:33:28,880
home or is it something different?

585
00:33:28,880 --> 00:33:29,880
Yeah, actually not.

586
00:33:29,880 --> 00:33:33,080
I mean, maybe I'm not doing my job as like, you know, CEO of this company and like, oh,

587
00:33:33,080 --> 00:33:37,560
you should have one in every room or something, but I actually don't see it that way.

588
00:33:37,560 --> 00:33:43,600
I think several in a normal sized, you know, middle class American house, two to three is

589
00:33:43,600 --> 00:33:44,600
probably the right number.

590
00:33:44,600 --> 00:33:46,400
And you get a ton of value out of one.

591
00:33:46,400 --> 00:33:48,840
And so you can kind of, you know, you get one, you play with it and you're like, oh my

592
00:33:48,840 --> 00:33:49,840
god, this is amazing.

593
00:33:49,840 --> 00:33:51,480
You get two and two and three.

594
00:33:51,480 --> 00:33:57,760
I actually don't think it makes that much sense to have every single room covered.

595
00:33:57,760 --> 00:34:02,160
It's usually particular areas of interest.

596
00:34:02,160 --> 00:34:06,040
And so, you know, we often see the first one goes in an area that is kind of near the front

597
00:34:06,040 --> 00:34:07,040
door.

598
00:34:07,040 --> 00:34:10,040
So you see like what traffic is coming and going, but you also see a reasonable amount

599
00:34:10,040 --> 00:34:12,000
of the kind of the floor plan of the home.

600
00:34:12,000 --> 00:34:14,800
So you get a sense of what's going on there.

601
00:34:14,800 --> 00:34:19,880
What other common places for Lighthouse to end up in or in the garage, because often

602
00:34:19,880 --> 00:34:25,400
the door might get left open and you want to know if somebody's in there or you might

603
00:34:25,400 --> 00:34:29,840
have tools out there and children and you want to know like, you know, are the kids going

604
00:34:29,840 --> 00:34:32,800
out there when I'm at home, things like that.

605
00:34:32,800 --> 00:34:36,760
Or, you know, upstairs in the kids room or just outside of the kids room to see if they're

606
00:34:36,760 --> 00:34:38,240
getting up out of bed in the middle of the night.

607
00:34:38,240 --> 00:34:41,160
I mean, you would literally just say, you know, hey, Lighthouse, you know, tell me if you

608
00:34:41,160 --> 00:34:46,600
see the kids out in the hallway between, you know, 10 p.m. and 6 a.m. and then it works.

609
00:34:46,600 --> 00:34:51,840
We need to implement the call me if you see this features coming down the road.

610
00:34:51,840 --> 00:34:56,160
But it's those kind of areas of, you know, particular interests and it depends on the

611
00:34:56,160 --> 00:34:57,720
particular homeowner.

612
00:34:57,720 --> 00:35:02,360
Another common place is kind of in the living room, looking into the area where the dog

613
00:35:02,360 --> 00:35:06,520
hangs out so that you can, you know, just get the warm and fuzzy feelings of like, hey,

614
00:35:06,520 --> 00:35:08,320
what's my dog been up to since I left home?

615
00:35:08,320 --> 00:35:09,320
Right.

616
00:35:09,320 --> 00:35:16,400
So if you had this and you pointed it at the front door, can it, you know, can it effectively,

617
00:35:16,400 --> 00:35:24,480
you know, track the state of the home and kind of be a general purpose presence detector

618
00:35:24,480 --> 00:35:27,360
like, you know, keep track of someone walked in.

619
00:35:27,360 --> 00:35:31,120
That person walked out so they're no longer inside and at any given time, like query it

620
00:35:31,120 --> 00:35:33,400
and determine who's in the house.

621
00:35:33,400 --> 00:35:37,120
So we can make that query and that does work.

622
00:35:37,120 --> 00:35:39,800
But we don't do it with computer vision, actually.

623
00:35:39,800 --> 00:35:40,800
Okay.

624
00:35:40,800 --> 00:35:44,640
And the, you know, the reason is we, there's often many entrances and exits to a home

625
00:35:44,640 --> 00:35:49,280
and we don't expect that you buy one lighthouse for every entrance and exit, necessarily.

626
00:35:49,280 --> 00:35:50,280
Right.

627
00:35:50,280 --> 00:35:54,920
So the way we do presence, absence detection is just, you know, is with phone presence

628
00:35:54,920 --> 00:35:55,920
and absence.

629
00:35:55,920 --> 00:35:59,520
GPS is part of that, but also looking at blue to the signals coming out of the devices.

630
00:35:59,520 --> 00:36:00,520
All right.

631
00:36:00,520 --> 00:36:04,520
Just going to say I just started playing with the Samsung smart things and it does it the

632
00:36:04,520 --> 00:36:08,360
same way and it kind of sucks like it's, it's very coarse.

633
00:36:08,360 --> 00:36:11,560
You have to work hard at it to get to work well, but I mean, there is a big advantage

634
00:36:11,560 --> 00:36:13,880
in that we have a blue to the signal coming out of the device.

635
00:36:13,880 --> 00:36:14,880
Ah, okay.

636
00:36:14,880 --> 00:36:19,200
That's going to work a lot better than, you know, the GPS you're within a mile of your

637
00:36:19,200 --> 00:36:20,200
house.

638
00:36:20,200 --> 00:36:21,200
So therefore you're in your house.

639
00:36:21,200 --> 00:36:26,280
If you just use location services, like as provided by the standard phone API's on

640
00:36:26,280 --> 00:36:29,200
its own, it would be hard to make it really good.

641
00:36:29,200 --> 00:36:30,200
Yeah.

642
00:36:30,200 --> 00:36:33,440
Now to be fair, also like we will not cover the case where you walk out of your house

643
00:36:33,440 --> 00:36:36,680
and you go to your neighbor's house, it's going to be hard for us to tell.

644
00:36:36,680 --> 00:36:37,680
Right.

645
00:36:37,680 --> 00:36:38,680
And like it will still think you're home.

646
00:36:38,680 --> 00:36:43,040
But when you get far enough away, then it, you know, this gets you almost all of the

647
00:36:43,040 --> 00:36:44,040
way.

648
00:36:44,040 --> 00:36:45,040
Right.

649
00:36:45,040 --> 00:36:46,560
Assuming that you've got your phone with you.

650
00:36:46,560 --> 00:36:47,560
That is correct.

651
00:36:47,560 --> 00:36:48,560
Yep.

652
00:36:48,560 --> 00:36:49,560
Interesting.

653
00:36:49,560 --> 00:36:52,600
I mean, that's one of the reasons that the children in classifier is a big deal because

654
00:36:52,600 --> 00:36:55,400
they often don't have phones at all.

655
00:36:55,400 --> 00:36:58,840
And you want to know what are they up to and did they get home on this, you know, on their

656
00:36:58,840 --> 00:37:01,240
schedule and so on.

657
00:37:01,240 --> 00:37:04,640
And so does this, does the lighthouse have an API?

658
00:37:04,640 --> 00:37:11,640
Is it something that you envision people kind of getting and hacking on or is it more,

659
00:37:11,640 --> 00:37:15,080
you know, just kind of the stated use cases as far?

660
00:37:15,080 --> 00:37:21,920
You know, we have seen a tremendous enthusiasm for adding lighthouse capabilities to other

661
00:37:21,920 --> 00:37:25,720
parts of the, the IoT world of the smart home.

662
00:37:25,720 --> 00:37:26,720
Right.

663
00:37:26,720 --> 00:37:30,440
You know, actually to this smart home, you know, device when you see something or other

664
00:37:30,440 --> 00:37:32,640
kind of thing.

665
00:37:32,640 --> 00:37:37,240
And I'm really excited to get to the point where we can actually start to tap into that.

666
00:37:37,240 --> 00:37:40,920
We're not there just yet, but it's certainly on the roadmap.

667
00:37:40,920 --> 00:37:46,280
We will be deploying something like that, some integration with other smart home capabilities

668
00:37:46,280 --> 00:37:50,200
that, you know, that early adopters can plug together.

669
00:37:50,200 --> 00:37:53,440
We will be providing that sometime this year.

670
00:37:53,440 --> 00:37:54,440
It will not be immediate.

671
00:37:54,440 --> 00:37:55,440
Yeah.

672
00:37:55,440 --> 00:37:56,440
Yeah.

673
00:37:56,440 --> 00:37:58,320
What's the long term, you know, view further company?

674
00:37:58,320 --> 00:37:59,600
What are you trying to accomplish?

675
00:37:59,600 --> 00:38:06,000
So when I take a step back and look at why lighthouse exists, the home is a piece of it,

676
00:38:06,000 --> 00:38:07,000
for sure.

677
00:38:07,000 --> 00:38:10,360
And it's a very exciting piece, but it's not the only thing.

678
00:38:10,360 --> 00:38:16,120
The reason lighthouse exists is to improve human life by augmenting our physical spaces

679
00:38:16,120 --> 00:38:19,360
with useful and accessible intelligence.

680
00:38:19,360 --> 00:38:22,320
And that stated very broadly, quite deliberately.

681
00:38:22,320 --> 00:38:28,800
Like there's sensors beyond computer, beyond cameras, beyond time of flight cameras, and

682
00:38:28,800 --> 00:38:33,800
you know, beyond vision generally that are very interesting and that we absolutely should

683
00:38:33,800 --> 00:38:37,120
integrate into this kind of thing.

684
00:38:37,120 --> 00:38:39,400
And it also goes beyond the home.

685
00:38:39,400 --> 00:38:45,800
There's many different AI service domains that are quite interesting to us.

686
00:38:45,800 --> 00:38:48,440
We're not spending a lot of time there right now because, you know, it's hard enough to do

687
00:38:48,440 --> 00:38:49,440
one of these things.

688
00:38:49,440 --> 00:38:53,000
So we're very, very focused on delivering the home product into the world and having

689
00:38:53,000 --> 00:38:57,160
that be a big success and make people's lives better.

690
00:38:57,160 --> 00:39:02,160
But once that is established and growing more or less on its own, then it'll be time

691
00:39:02,160 --> 00:39:05,280
to take our attention to another AI service domain.

692
00:39:05,280 --> 00:39:08,880
What's an example of another one beyond the home that's interesting?

693
00:39:08,880 --> 00:39:10,160
Elderly care is a big deal.

694
00:39:10,160 --> 00:39:11,160
Okay.

695
00:39:11,160 --> 00:39:16,760
It is a particularly big deal and we are particularly well suited to solve problems in that area.

696
00:39:16,760 --> 00:39:21,160
And we're actually, we're starting to see hints of this already, even in the home,

697
00:39:21,160 --> 00:39:29,160
we're aging in place in particular where you have an elderly loved one who may be there,

698
00:39:29,160 --> 00:39:34,440
maybe they might need to go into a facility, like a nursing care facility, but you kind

699
00:39:34,440 --> 00:39:38,400
of want to extend their time in their own home as long as you possibly can.

700
00:39:38,400 --> 00:39:45,680
And a system like Lighthouse is actually really good for this use case because they get

701
00:39:45,680 --> 00:39:50,080
a great security camera out of it or a camera they can see what their dog was up to or

702
00:39:50,080 --> 00:39:51,560
whatever it might be.

703
00:39:51,560 --> 00:39:59,320
And then the adult child gets the early warning system where you don't have to be looking

704
00:39:59,320 --> 00:40:00,320
at it every day.

705
00:40:00,320 --> 00:40:03,360
You just say, hey, Lighthouse, if you don't see anyone in the kitchen by 8 a.m. every day,

706
00:40:03,360 --> 00:40:05,080
just let me know.

707
00:40:05,080 --> 00:40:09,640
And then it might be that they just let in, but maybe today is a good day for you to call

708
00:40:09,640 --> 00:40:11,280
and just see how are you doing?

709
00:40:11,280 --> 00:40:12,280
Yeah.

710
00:40:12,280 --> 00:40:13,280
Yeah.

711
00:40:13,280 --> 00:40:18,880
Now, it seems like there are tons of folks kind of nibbling away at pieces of this space,

712
00:40:18,880 --> 00:40:22,240
like how many devices does Amazon have alone?

713
00:40:22,240 --> 00:40:28,600
Like they've got the key thing, which has a camera, they've got the look thing, which

714
00:40:28,600 --> 00:40:34,800
is your kind of fashion visual system, but you know, they seem to be very gung ho of

715
00:40:34,800 --> 00:40:36,720
getting cameras in your home, right?

716
00:40:36,720 --> 00:40:41,800
You know, how does a consumer react to all these people trying to push cameras into

717
00:40:41,800 --> 00:40:44,360
their houses and point clouds and all of this stuff?

718
00:40:44,360 --> 00:40:45,360
Yeah.

719
00:40:45,360 --> 00:40:52,840
So, there is a very fundamentally different perspective on the space when you're at a

720
00:40:52,840 --> 00:40:54,920
place like Amazon.

721
00:40:54,920 --> 00:41:01,440
Their goal is to magnify their marketplace, right?

722
00:41:01,440 --> 00:41:03,080
Like they're trying to sell things.

723
00:41:03,080 --> 00:41:06,840
That's why they're trying to put a camera into your house so that, oh, we can deliver more

724
00:41:06,840 --> 00:41:08,400
things to you, right?

725
00:41:08,400 --> 00:41:12,240
Or we can, you know, understand that like, oh, this scarf would look really good on you,

726
00:41:12,240 --> 00:41:14,360
I'll try to sell this to you, or whatever it might be, right?

727
00:41:14,360 --> 00:41:18,640
I mean, that's legitimately the stated purpose of that device.

728
00:41:18,640 --> 00:41:21,960
With Lighthouse, it's very different.

729
00:41:21,960 --> 00:41:26,560
We exist to provide this delightful AI service to you in return for money, and that's

730
00:41:26,560 --> 00:41:28,560
the end of the transaction.

731
00:41:28,560 --> 00:41:33,720
We're not looking to, you know, sell you a better hat or something, but, you know, taking

732
00:41:33,720 --> 00:41:40,000
a step back from all that, it is super interesting what's happening in the home generally,

733
00:41:40,000 --> 00:41:44,280
you know, at this CES in particular, there's this, you know, I, I, I, I, I, I, I, I, I, I,

734
00:41:44,280 --> 00:41:48,720
I almost want to describe it as an epic slug fast between, you know, Alexa and Google

735
00:41:48,720 --> 00:41:53,400
assistance to, to like, you know, with, like, oh, this is the AI is coming to the home in

736
00:41:53,400 --> 00:41:54,400
this particular form.

737
00:41:54,400 --> 00:41:55,400
Right.

738
00:41:55,400 --> 00:41:56,400
And it's really interesting.

739
00:41:56,400 --> 00:41:59,680
And, you know, who knows where it's going to be in a year from now, but what is very

740
00:41:59,680 --> 00:42:04,560
clear is that adding perception capabilities and having, then that same kind of conversational

741
00:42:04,560 --> 00:42:07,680
capability is super exciting, and that's going to write where Lighthouse is.

742
00:42:07,680 --> 00:42:08,680
Mm-hmm.

743
00:42:08,680 --> 00:42:12,480
Yeah, there's often this question about, like, is, you know, thing X, is it like a product

744
00:42:12,480 --> 00:42:17,080
or a feature, and, you know, what you're doing in a lot of ways is, like, bringing together

745
00:42:17,080 --> 00:42:23,600
the, you know, the vision piece, which is, you know, I guess I'm wondering, like, long

746
00:42:23,600 --> 00:42:28,840
term, like, does, you know, does something like Lighthouse and Alexa, do they converge?

747
00:42:28,840 --> 00:42:34,520
Like, do you, do you want to, if Alexa was more open, like, do you want to have to deal

748
00:42:34,520 --> 00:42:40,880
with the NLP, you know, or do you, you know, want the, the vision to, to kind of tack

749
00:42:40,880 --> 00:42:46,040
on to that or take advantage of the broader ecosystem, and I guess I'm mostly thinking

750
00:42:46,040 --> 00:42:50,720
about this from the perspective of a consumer, like, how many of these devices do I want

751
00:42:50,720 --> 00:42:56,120
in my house listening to, you know, listening to everything, and, you know, already I've got

752
00:42:56,120 --> 00:43:01,200
like, you know, the, the Google Home, and you have to, it has its wake word, and Alexa,

753
00:43:01,200 --> 00:43:04,560
I've got two different wake words in the house, it's like, it's already getting a bit

754
00:43:04,560 --> 00:43:05,560
maddening.

755
00:43:05,560 --> 00:43:06,560
Mm-hmm.

756
00:43:06,560 --> 00:43:07,560
Yeah.

757
00:43:07,560 --> 00:43:11,600
You know, with, with Lighthouse, you actually don't talk to the device itself.

758
00:43:11,600 --> 00:43:12,600
Oh, really?

759
00:43:12,600 --> 00:43:13,600
Yeah.

760
00:43:13,600 --> 00:43:18,360
But because usually the responses we're providing are video, and there's, there's no, there's

761
00:43:18,360 --> 00:43:19,360
no screen.

762
00:43:19,360 --> 00:43:20,360
Like talking to your device.

763
00:43:20,360 --> 00:43:21,360
Yeah.

764
00:43:21,360 --> 00:43:23,200
And, and usually you're out and about, right?

765
00:43:23,200 --> 00:43:24,200
That makes a lot of sense.

766
00:43:24,200 --> 00:43:27,040
It's usually, you're, you're at work or, you know, you're, you're on a train or something,

767
00:43:27,040 --> 00:43:29,960
and you're just like, you know, hey, what did the dog do since I left, or like, you

768
00:43:29,960 --> 00:43:32,640
know, hey, it had, you know, what did the kids do while it was out yesterday?

769
00:43:32,640 --> 00:43:33,640
I got it.

770
00:43:33,640 --> 00:43:34,640
And then you, you see the results there.

771
00:43:34,640 --> 00:43:35,640
Right.

772
00:43:35,640 --> 00:43:38,040
And it's all about delivering video, answers in video form.

773
00:43:38,040 --> 00:43:39,040
Mm-hmm.

774
00:43:39,040 --> 00:43:40,040
Right.

775
00:43:40,040 --> 00:43:43,720
So, so we won't be adding to that confusion about like so many different things that, that

776
00:43:43,720 --> 00:43:45,440
like can respond to you in the home.

777
00:43:45,440 --> 00:43:46,440
Mm-hmm.

778
00:43:46,440 --> 00:43:49,200
I don't have an answer to that problem, but I don't know, a good chat with the Alexa folks,

779
00:43:49,200 --> 00:43:50,200
I guess.

780
00:43:50,200 --> 00:43:51,200
Mm-hmm.

781
00:43:51,200 --> 00:43:52,200
Interesting.

782
00:43:52,200 --> 00:43:53,200
Interesting.

783
00:43:53,200 --> 00:43:54,200
All right.

784
00:43:54,200 --> 00:43:55,520
Well, Alex, thank you so much for taking the time to chat with me.

785
00:43:55,520 --> 00:44:00,040
I enjoyed learning about you, your background, Lighthouse, sounds like an interesting space,

786
00:44:00,040 --> 00:44:01,040
and good luck here at CES.

787
00:44:01,040 --> 00:44:02,040
Cool.

788
00:44:02,040 --> 00:44:03,040
Well, thank you so much.

789
00:44:03,040 --> 00:44:04,040
It's been fun.

790
00:44:04,040 --> 00:44:05,040
All right.

791
00:44:05,040 --> 00:44:08,200
All right, everyone.

792
00:44:08,200 --> 00:44:10,360
That's our show for today.

793
00:44:10,360 --> 00:44:14,760
Thanks so much for listening and for your continued feedback and support.

794
00:44:14,760 --> 00:44:21,360
Remember, for your chance to win in our AI at home giveaway, head on over to twimolei.com

795
00:44:21,360 --> 00:44:25,920
slash my AI contest for complete details.

796
00:44:25,920 --> 00:44:30,560
For more information on Alex, Lighthouse, or any of the topics covered in this episode,

797
00:44:30,560 --> 00:44:35,000
head on over to twimolei.com slash talk slash 103.

798
00:44:35,000 --> 00:44:39,200
Thanks once again to Intel AI for their sponsorship of this series.

799
00:44:39,200 --> 00:44:43,200
To learn more about their partnership with Ferrari North America Challenge and the other

800
00:44:43,200 --> 00:44:47,800
things they've been up to, visit ai.intel.com.

801
00:44:47,800 --> 00:44:52,880
Of course, we'd be delighted to hear from you, either via a comment on the show notes page

802
00:44:52,880 --> 00:44:59,320
or via Twitter directly to me at at Sam Sharrington or to the show at at twimolei.

803
00:44:59,320 --> 00:45:06,320
Thanks once again for listening and catch you next time.

