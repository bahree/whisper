1
00:00:00,000 --> 00:00:01,520
All right, everyone.

2
00:00:01,520 --> 00:00:04,960
Welcome to another episode of the Twimmel AI podcast.

3
00:00:04,960 --> 00:00:07,680
I am your host, Sam Charrington,

4
00:00:07,680 --> 00:00:09,040
and today I'm joined by

5
00:00:09,040 --> 00:00:11,200
Cedric Coco, Chief Engineer of

6
00:00:11,200 --> 00:00:13,600
the Wayfinder Group at Acubed.

7
00:00:13,600 --> 00:00:15,680
Cedric, welcome to the podcast.

8
00:00:15,680 --> 00:00:16,880
Thank you for having me.

9
00:00:16,880 --> 00:00:19,040
I'm looking forward to digging into our conversation.

10
00:00:19,040 --> 00:00:20,640
We'll be talking about a lot of

11
00:00:20,640 --> 00:00:22,960
cool things that you are doing with

12
00:00:22,960 --> 00:00:25,360
data-centric AI in particular,

13
00:00:25,360 --> 00:00:27,520
your journey with data labeling for

14
00:00:27,520 --> 00:00:29,280
your specific use case,

15
00:00:29,280 --> 00:00:30,320
to get us started.

16
00:00:30,320 --> 00:00:32,800
I'd love to have you share a little bit about your background

17
00:00:32,800 --> 00:00:35,440
and how you came to work in ML&AI.

18
00:00:35,440 --> 00:00:36,960
Yes, thank you.

19
00:00:36,960 --> 00:00:38,320
My name is Cedric Coco.

20
00:00:38,320 --> 00:00:41,440
I'm the Chief Engineer of the Wayfinder Group at Acubed,

21
00:00:41,440 --> 00:00:44,480
and that is Airbus Innovation Center in Silicon Valley.

22
00:00:45,360 --> 00:00:48,640
My background, I have a PhD in computer vision navigation,

23
00:00:48,640 --> 00:00:51,120
and I used to come from the space sector,

24
00:00:51,120 --> 00:00:54,320
so I spent part of my life trying to land spacecraft

25
00:00:54,320 --> 00:00:57,760
autonomously using one camera on near-Earth asteroids.

26
00:00:57,760 --> 00:01:02,720
I lowered my altitude of interest in 2016

27
00:01:02,720 --> 00:01:06,960
when I joined Airbus and we started to work

28
00:01:06,960 --> 00:01:09,120
on aviation rather than spacecraft.

29
00:01:09,120 --> 00:01:12,000
The thing that really attracted me there

30
00:01:12,000 --> 00:01:16,560
was the UAM concept, the urban air mobility or air taxis.

31
00:01:16,560 --> 00:01:19,040
At the time, there was this new project

32
00:01:19,040 --> 00:01:20,640
that started called Bahana.

33
00:01:20,640 --> 00:01:22,880
It was a technology demonstrator,

34
00:01:22,880 --> 00:01:26,000
basically a first prototype of one of those air taxis.

35
00:01:26,000 --> 00:01:30,720
The whole goal is to provide a completely new way

36
00:01:30,720 --> 00:01:34,480
of commuting people within urban areas and suburban areas,

37
00:01:34,480 --> 00:01:39,520
and this time at scale in the sense of really having thousands

38
00:01:39,520 --> 00:01:42,880
of vehicles in a city trying to have passenger

39
00:01:42,880 --> 00:01:46,240
going from one area to another to solve the congestion problem

40
00:01:46,240 --> 00:01:48,000
that we have in all big urban centers.

41
00:01:48,000 --> 00:01:52,000
I was part of the sense and avoid crew back in the days,

42
00:01:52,000 --> 00:01:56,400
and the central focus was basically developing machine learning

43
00:01:56,400 --> 00:02:00,320
and vision for the sense avoid system for urban air mobility.

44
00:02:00,320 --> 00:02:05,520
As we moved forward, we realized that this technology

45
00:02:05,520 --> 00:02:08,160
was really applicable to a larger range of application

46
00:02:08,160 --> 00:02:10,000
for aviation and airbus,

47
00:02:10,000 --> 00:02:12,320
and we started to apply the same technology

48
00:02:12,320 --> 00:02:13,760
to commercial aircraft.

49
00:02:13,760 --> 00:02:16,240
This is where we are now,

50
00:02:16,240 --> 00:02:19,600
the focus of Wayfinder is to build more autonomy

51
00:02:19,600 --> 00:02:22,240
into commercial aircraft.

52
00:02:22,240 --> 00:02:26,960
So you mentioned you got started in this air taxi project,

53
00:02:26,960 --> 00:02:31,120
Bahana, what were the key technology innovations

54
00:02:32,080 --> 00:02:36,400
that drove that project that ultimately led to what you're working on now?

55
00:02:36,400 --> 00:02:40,240
Yeah, so air taxis is a completely new breed of aircraft.

56
00:02:41,040 --> 00:02:44,880
We're looking at an electric propulsion system.

57
00:02:44,880 --> 00:02:50,640
We're looking at basically a vertical take-off and landing system

58
00:02:50,640 --> 00:02:54,480
that can be converted into a fixed wing

59
00:02:54,480 --> 00:02:58,320
during the cruise phase for efficiency purposes.

60
00:02:58,320 --> 00:03:02,640
But the other aspect that is driving this innovation

61
00:03:02,640 --> 00:03:05,120
and this revolution in the aviation sector

62
00:03:05,120 --> 00:03:06,240
is how you build them.

63
00:03:06,240 --> 00:03:09,680
Currently commercial aircraft are built

64
00:03:09,680 --> 00:03:11,920
in the hundreds every year.

65
00:03:11,920 --> 00:03:17,840
You could hit the 1000, but we're not at the 10,000 or even more

66
00:03:17,840 --> 00:03:19,680
in terms of scale.

67
00:03:19,680 --> 00:03:24,880
So one of the key concepts that most urban air mobility companies

68
00:03:24,880 --> 00:03:27,520
in the area and across the world are thinking about it

69
00:03:27,520 --> 00:03:31,120
as how to combine forces with the automotive industry

70
00:03:31,120 --> 00:03:34,560
and with their skills and their production capabilities

71
00:03:34,560 --> 00:03:36,480
to be able to scale up production

72
00:03:36,480 --> 00:03:38,960
while having the safety standard

73
00:03:38,960 --> 00:03:41,520
and the reliability standard of aviation.

74
00:03:41,520 --> 00:03:47,440
So this is a huge challenge and on the technology side

75
00:03:47,440 --> 00:03:49,440
there's two aspects that are really important.

76
00:03:49,440 --> 00:03:51,760
One of them is the electric propulsion system

77
00:03:51,760 --> 00:03:56,480
which is quite new and the other one is autonomy.

78
00:03:56,480 --> 00:04:01,680
So one of the key and fundamental of air taxis to make it viable

79
00:04:01,680 --> 00:04:04,240
is to have a fully autonomous solution down the road.

80
00:04:05,200 --> 00:04:08,320
Many are taking roads where they go through an intermediate step

81
00:04:08,320 --> 00:04:09,360
where it's going to be piloted.

82
00:04:09,360 --> 00:04:11,920
But the end goal is clear for everybody

83
00:04:11,920 --> 00:04:14,720
we need to go for a fully autonomous system.

84
00:04:14,720 --> 00:04:18,720
And so that has multiple objectives.

85
00:04:18,720 --> 00:04:22,000
One of them is how do you handle traffic at scale

86
00:04:22,000 --> 00:04:24,080
over a city with all those aircraft?

87
00:04:24,080 --> 00:04:29,200
The other one is when that system fails to ensure

88
00:04:29,200 --> 00:04:31,200
the proper distances between all the vehicle,

89
00:04:31,200 --> 00:04:33,200
what do you have on board to detect

90
00:04:33,200 --> 00:04:37,040
that such distances have been so violated

91
00:04:37,040 --> 00:04:40,400
and how do you respond adequately

92
00:04:40,400 --> 00:04:44,000
so that you don't create more risks to other vehicles.

93
00:04:44,000 --> 00:04:47,840
So you have this layered approach between air traffic control,

94
00:04:47,840 --> 00:04:50,080
between deconfliction, reserving the airspace

95
00:04:50,080 --> 00:04:52,160
and then ultimately your sense and avoid

96
00:04:52,160 --> 00:04:54,160
on the aircraft itself,

97
00:04:54,160 --> 00:04:58,080
and then you have to have the ability to perceive your environment

98
00:04:58,080 --> 00:05:00,480
on the aircraft to understand what it is

99
00:05:00,480 --> 00:05:03,360
and to make the proper decisions that minimize risks

100
00:05:03,360 --> 00:05:05,840
and ensure that the passenger is delivered safely

101
00:05:05,840 --> 00:05:07,520
to its destination.

102
00:05:07,520 --> 00:05:11,280
So my role and the role that the team I was in at the time

103
00:05:11,280 --> 00:05:13,280
was ready to develop that sense and avoid system

104
00:05:13,280 --> 00:05:16,320
that last piece of this onion model

105
00:05:16,320 --> 00:05:18,080
for ensuring the safety of passengers.

106
00:05:18,960 --> 00:05:22,880
And I imagine that translating that

107
00:05:22,880 --> 00:05:26,560
into the commercial side of things,

108
00:05:26,560 --> 00:05:32,080
there are some foundational elements that translate,

109
00:05:32,080 --> 00:05:35,120
but it sounds like a very different problem.

110
00:05:35,120 --> 00:05:36,320
It is a very different problem

111
00:05:36,320 --> 00:05:38,240
because commercial aircraft operates

112
00:05:38,240 --> 00:05:40,080
in a completely different airspace

113
00:05:40,080 --> 00:05:42,320
and that airspace is highly controlled.

114
00:05:43,280 --> 00:05:45,760
So from the time that you take off from the airport

115
00:05:45,760 --> 00:05:48,240
where the tower helps you and guides you,

116
00:05:48,240 --> 00:05:50,880
you have already corridors that are reserved for you.

117
00:05:51,680 --> 00:05:54,240
So this is a very interesting problem

118
00:05:54,240 --> 00:05:57,680
because bringing autonomy to commercial aircraft

119
00:05:57,680 --> 00:06:00,000
when you really look at it

120
00:06:00,000 --> 00:06:04,240
is probably not as hard as autonomous or self-driving cars.

121
00:06:04,240 --> 00:06:06,400
Our environment is a lot more structured.

122
00:06:07,120 --> 00:06:10,800
We have autopilot that can fly the aircraft

123
00:06:10,800 --> 00:06:12,800
when you're in the air during the cruise phase

124
00:06:12,800 --> 00:06:14,480
and we had them for decades now.

125
00:06:15,440 --> 00:06:17,280
And they are up to the safety level

126
00:06:17,280 --> 00:06:18,720
and the reliability level that you need

127
00:06:18,720 --> 00:06:22,320
to be able to transport 350 passengers.

128
00:06:23,440 --> 00:06:25,280
The other aspect is our pilot

129
00:06:25,280 --> 00:06:28,160
are actually skilled, trained professionals

130
00:06:28,960 --> 00:06:31,680
not to criticize anybody driving in the area,

131
00:06:31,680 --> 00:06:34,800
but depending on our expertise,

132
00:06:34,800 --> 00:06:37,280
our level of being tired or not,

133
00:06:38,720 --> 00:06:41,120
let's say drivers are more at risk for this.

134
00:06:41,760 --> 00:06:44,560
So we have those very skilled pilots.

135
00:06:44,560 --> 00:06:46,800
We have this aircraft that already has

136
00:06:47,280 --> 00:06:49,040
a good level of autonomy built in.

137
00:06:49,760 --> 00:06:51,440
But now what we need to tackle

138
00:06:51,440 --> 00:06:55,040
is when you increase the scale of this air traffic,

139
00:06:55,040 --> 00:06:56,400
you decrease the distances

140
00:06:56,400 --> 00:06:58,160
and especially in terminal areas,

141
00:06:58,960 --> 00:07:01,120
how many aircraft can you actually land

142
00:07:01,120 --> 00:07:04,400
at an airport and how many can take off

143
00:07:04,400 --> 00:07:05,680
within this small volume

144
00:07:06,240 --> 00:07:08,400
without creating risks for anyone.

145
00:07:09,200 --> 00:07:11,440
And there is certain volume

146
00:07:11,440 --> 00:07:16,000
that manual operation can control

147
00:07:16,000 --> 00:07:17,280
and can tackle.

148
00:07:17,280 --> 00:07:19,280
But if you want to go beyond that,

149
00:07:19,280 --> 00:07:21,280
then autonomy is a must go

150
00:07:22,080 --> 00:07:24,000
to be able to maintain the same level of safety

151
00:07:24,640 --> 00:07:27,280
while increasing volume, while increasing air traffic.

152
00:07:27,920 --> 00:07:29,840
And this is where we come into play

153
00:07:29,840 --> 00:07:33,520
because we are looking at a range of autonomous functions

154
00:07:33,520 --> 00:07:37,120
to be able to take that leap toward this next generation aircraft

155
00:07:37,120 --> 00:07:40,240
and this future where basically

156
00:07:40,240 --> 00:07:43,120
the air traffic would increase significantly.

157
00:07:43,120 --> 00:07:45,680
And just to give you some numbers,

158
00:07:45,680 --> 00:07:49,280
based on the trends that we've seen before COVID,

159
00:07:50,000 --> 00:07:52,720
the air traffic doubled every 15 years.

160
00:07:53,440 --> 00:07:55,120
And right in 2019,

161
00:07:55,120 --> 00:08:00,080
commercial aircraft carried 4.9 billion passengers.

162
00:08:00,800 --> 00:08:03,680
So the application that we're working on

163
00:08:03,680 --> 00:08:08,320
is technically going to touch about 60% of the planet

164
00:08:08,320 --> 00:08:10,640
if you look at the numbers in 2019.

165
00:08:10,640 --> 00:08:12,800
And then if you look at doubling that,

166
00:08:12,800 --> 00:08:18,400
meaning that roughly you would touch 9 to 10 billion people a year,

167
00:08:18,400 --> 00:08:21,840
the need in terms of safety,

168
00:08:21,840 --> 00:08:23,840
the needs in terms of making sure

169
00:08:23,840 --> 00:08:26,720
that this fully-autonomated system works well

170
00:08:26,720 --> 00:08:28,720
is orders of magnitude beyond

171
00:08:28,720 --> 00:08:30,720
most of the other application that we see there.

172
00:08:30,720 --> 00:08:33,760
And when you talk about increasing the volume

173
00:08:34,640 --> 00:08:37,760
and the requirements that that places

174
00:08:37,760 --> 00:08:39,680
especially around the terminal,

175
00:08:40,480 --> 00:08:42,480
the terminals in the terminal area,

176
00:08:42,480 --> 00:08:46,960
I'm thinking that one of the major factors we're talking about

177
00:08:46,960 --> 00:08:51,200
is like the spacing and approaches and landings

178
00:08:51,200 --> 00:08:52,160
and things like that.

179
00:08:52,160 --> 00:08:56,320
And there are parameters around where you want that to be

180
00:08:56,320 --> 00:08:58,560
if it's being done manually.

181
00:08:58,560 --> 00:09:01,600
And the idea is that if it's fully autonomous

182
00:09:01,600 --> 00:09:05,280
that you can kind of shrink that spacing, is that the idea?

183
00:09:05,280 --> 00:09:08,800
So there's two things that we're really trying to achieve.

184
00:09:08,800 --> 00:09:11,520
One of them is that there is a lot of things

185
00:09:11,520 --> 00:09:14,640
that the pilot must do when he approaches the terminal,

186
00:09:14,640 --> 00:09:17,520
the airport, and when he navigates either.

187
00:09:17,520 --> 00:09:19,120
So either when he's doing,

188
00:09:19,120 --> 00:09:22,720
he's landing the aircraft, he's in the taxi phase, or he's taking off.

189
00:09:23,360 --> 00:09:27,200
And what we want to build is enough autonomy in those aircraft

190
00:09:27,200 --> 00:09:29,840
so that the pilot stops being worried

191
00:09:29,840 --> 00:09:33,360
about all those small details plus the strategic aspects

192
00:09:33,360 --> 00:09:36,240
and can really focus only on the strategic part.

193
00:09:37,120 --> 00:09:39,360
For that, there's a range of functions

194
00:09:39,360 --> 00:09:40,400
that needs to be built in.

195
00:09:40,400 --> 00:09:42,560
So for example, autonomous landing

196
00:09:42,560 --> 00:09:46,160
so that the person can focus on other aspects

197
00:09:46,160 --> 00:09:49,280
than just controlling the aircraft toward the right light slope

198
00:09:49,280 --> 00:09:52,320
to be able to touch the runway at the right point.

199
00:09:52,320 --> 00:09:53,920
All of that can be abstracted out.

200
00:09:54,560 --> 00:09:56,160
The aircraft can take care of it

201
00:09:56,160 --> 00:09:57,920
and the pilot can focus his attention

202
00:09:57,920 --> 00:10:01,360
on more strategic aspects of the flight.

203
00:10:02,160 --> 00:10:03,200
One of them is, for example,

204
00:10:03,200 --> 00:10:05,280
what is the route that he will need to take

205
00:10:05,280 --> 00:10:07,520
to confirm that this is the right runway

206
00:10:07,520 --> 00:10:10,640
that he needs to land at, for instance.

207
00:10:10,640 --> 00:10:12,720
And during the taxi phase, especially,

208
00:10:12,720 --> 00:10:16,640
it's pretty crowded on the runway

209
00:10:16,640 --> 00:10:19,040
and especially when you're getting close to the gates.

210
00:10:19,040 --> 00:10:22,720
So being able to have a system that keeps an eye

211
00:10:22,720 --> 00:10:24,480
on all that traffic around you

212
00:10:24,480 --> 00:10:27,680
and alerts you when really your attention is needed

213
00:10:27,680 --> 00:10:29,920
for one particular aspect

214
00:10:29,920 --> 00:10:33,120
is really going to help lower the workload of the pilots

215
00:10:33,120 --> 00:10:35,760
and help the overall operation to be more efficient

216
00:10:35,760 --> 00:10:37,120
and safer as well.

217
00:10:37,120 --> 00:10:39,680
I'm going to say this is where ML becomes

218
00:10:39,680 --> 00:10:41,200
a critical component of the system

219
00:10:41,200 --> 00:10:44,160
because doing all of that autonomous detection

220
00:10:44,160 --> 00:10:48,480
of the runway, autonomous assessment of where your aircraft is

221
00:10:48,480 --> 00:10:51,200
during that landing segment

222
00:10:51,200 --> 00:10:52,720
and during the taxi phase,

223
00:10:52,720 --> 00:10:54,320
making sure that the aircraft is really

224
00:10:54,320 --> 00:10:56,400
where it's supposed to be on the runway

225
00:10:56,400 --> 00:10:58,080
that there's no object around.

226
00:10:58,080 --> 00:11:02,240
So the collision protection function is key.

227
00:11:02,240 --> 00:11:04,720
So all of those requires a heavy dose

228
00:11:04,720 --> 00:11:06,320
of perception decision making.

229
00:11:07,040 --> 00:11:09,760
And the range of things that you see

230
00:11:09,760 --> 00:11:12,320
in the complexity of the situation

231
00:11:12,320 --> 00:11:16,720
makes it hard for classical approaches to work

232
00:11:16,720 --> 00:11:19,360
and really requires the power of ML

233
00:11:19,360 --> 00:11:21,920
to be able to ensure the performance

234
00:11:21,920 --> 00:11:24,640
and the reliability that we expect out of that function.

235
00:11:24,640 --> 00:11:27,520
Yeah, let's dig into that a little bit more deeply.

236
00:11:27,520 --> 00:11:32,080
You reference autonomous vehicles earlier

237
00:11:32,080 --> 00:11:38,800
as kind of a comparison in urban taxi contexts.

238
00:11:38,800 --> 00:11:41,360
There's obviously a lot of investment happening

239
00:11:41,360 --> 00:11:44,560
in that type of autonomy right now

240
00:11:44,560 --> 00:11:46,960
from an ML and AI perspective.

241
00:11:48,240 --> 00:11:50,800
But again, this sounds like a very different problem.

242
00:11:50,800 --> 00:11:52,880
Can you kind of elaborate on some of the ways

243
00:11:52,880 --> 00:11:54,960
that from a technical perspective,

244
00:11:54,960 --> 00:11:57,120
the problem that you're dealing with

245
00:11:57,120 --> 00:12:03,040
differs from what someone who's working on AV cars

246
00:12:03,040 --> 00:12:05,120
is worth thinking about?

247
00:12:05,120 --> 00:12:07,440
Yeah, that's a very interesting question

248
00:12:07,440 --> 00:12:10,240
because one of the strategies here

249
00:12:10,240 --> 00:12:11,760
is to leverage a lot of the work

250
00:12:11,760 --> 00:12:14,880
that has been done in the self-driving car industry.

251
00:12:14,880 --> 00:12:18,160
They've been starting this decades ago.

252
00:12:18,800 --> 00:12:21,360
And so there's a lot of legacy, a lot of system

253
00:12:21,360 --> 00:12:22,560
that is available.

254
00:12:22,560 --> 00:12:25,120
And so for us to be able to speed up our development,

255
00:12:25,120 --> 00:12:27,760
being able to leverage all of that work

256
00:12:27,760 --> 00:12:28,720
is to our benefit.

257
00:12:28,720 --> 00:12:31,280
However, there's a certain limit

258
00:12:31,280 --> 00:12:34,240
at which we can transfer and re-adapt that technology

259
00:12:34,240 --> 00:12:36,400
without tuning it and actually

260
00:12:36,400 --> 00:12:38,320
or changing it from the bottom up.

261
00:12:38,320 --> 00:12:43,120
So for instance, cars needs to see in 2D plus heights,

262
00:12:43,120 --> 00:12:45,360
but it's a 2.5D problem.

263
00:12:46,160 --> 00:12:49,920
They need to see, you know, 200, 300 meters in front of them.

264
00:12:49,920 --> 00:12:53,760
And maybe the autonomous trucks needs to see a little further.

265
00:12:53,760 --> 00:12:57,200
But in our case, when the aircraft gets close to an airport,

266
00:12:57,200 --> 00:12:59,680
we need to see kilometers ahead of time.

267
00:12:59,680 --> 00:13:03,200
And the object that we're trying to see

268
00:13:03,200 --> 00:13:06,160
are actually very small in the image.

269
00:13:06,160 --> 00:13:08,720
And we need very high-resolution image

270
00:13:08,720 --> 00:13:12,080
to be able to have just enough pixel enough information

271
00:13:12,080 --> 00:13:14,720
to give to the ML or other algorithms

272
00:13:14,720 --> 00:13:16,400
to be able to make heads and tails

273
00:13:16,400 --> 00:13:17,920
of everything that they see in there.

274
00:13:17,920 --> 00:13:21,600
So typically, the cameras that we need to use

275
00:13:21,600 --> 00:13:23,120
to be able to do those functions

276
00:13:24,320 --> 00:13:26,880
are in the order of 10 to 15 megapixels

277
00:13:27,680 --> 00:13:30,880
versus in the car industry in the order of two,

278
00:13:30,880 --> 00:13:33,680
maybe five megapixels for very high-resolution.

279
00:13:34,240 --> 00:13:37,040
And then in our case, because we operate in 3D,

280
00:13:37,040 --> 00:13:38,880
we need more, of course, than one camera.

281
00:13:38,880 --> 00:13:42,640
We need cameras to cover the full space ahead of us.

282
00:13:43,520 --> 00:13:47,840
So that is one differentiator between our use case

283
00:13:47,840 --> 00:13:50,400
and the self-driving car use case

284
00:13:51,040 --> 00:13:53,360
is just the sheer number of pixels

285
00:13:53,360 --> 00:13:55,840
that we need to deal with in real time.

286
00:13:55,840 --> 00:14:00,320
The other aspect is real-time performance.

287
00:14:00,320 --> 00:14:04,320
We need to guarantee that our algorithm

288
00:14:04,320 --> 00:14:07,840
perform adequately at the frame rate that we have.

289
00:14:07,840 --> 00:14:11,680
So basically, we need to guarantee real-time performances.

290
00:14:11,680 --> 00:14:15,680
And for that, the level of guarantee that we need to provide

291
00:14:15,680 --> 00:14:18,720
depends on what we call the design assurance level,

292
00:14:18,720 --> 00:14:20,880
which is basically a gauge on the safety

293
00:14:20,880 --> 00:14:23,040
and the process that we've put behind

294
00:14:23,040 --> 00:14:25,600
to guarantee the safety of those systems.

295
00:14:25,600 --> 00:14:29,360
And the autonomous, the aviation industry

296
00:14:29,360 --> 00:14:31,920
actually has very stringent standards on that.

297
00:14:31,920 --> 00:14:36,480
And what happens is before we can even use an aircraft,

298
00:14:36,480 --> 00:14:39,840
the certification authorities need to stamp our system.

299
00:14:39,840 --> 00:14:42,000
So they need to look at all the details.

300
00:14:42,000 --> 00:14:43,680
Because of all the guarantees that we need to give

301
00:14:43,680 --> 00:14:45,440
to certification authorities,

302
00:14:45,440 --> 00:14:47,840
and because of the fact that they need to stamp our design

303
00:14:47,840 --> 00:14:52,320
and they need to stamp the way we are writing the software

304
00:14:52,320 --> 00:14:54,720
before we can even start using the aircraft,

305
00:14:54,720 --> 00:14:57,760
there's a lot more that we need to put

306
00:14:57,760 --> 00:15:00,480
into those developments and a lot more proof

307
00:15:00,480 --> 00:15:02,640
on the safety and the performance of those algorithms

308
00:15:02,640 --> 00:15:05,120
that we need to provide than any other application.

309
00:15:05,120 --> 00:15:07,520
I was just going to jump in there.

310
00:15:07,520 --> 00:15:14,000
I remember hearing presentations around

311
00:15:14,000 --> 00:15:17,760
the kind of verification and validation that happens,

312
00:15:17,760 --> 00:15:21,440
for example, by NASA software engineers

313
00:15:21,440 --> 00:15:25,200
building those kinds of systems and classical,

314
00:15:25,200 --> 00:15:27,360
aeronautic systems.

315
00:15:27,360 --> 00:15:30,720
And that seems, I guess, like a culture clash,

316
00:15:30,720 --> 00:15:33,120
when you're thinking about machine learning

317
00:15:33,120 --> 00:15:35,520
and probabilistic types of systems.

318
00:15:35,520 --> 00:15:40,080
And I'm wondering how you bring those two worlds together

319
00:15:40,080 --> 00:15:42,880
in areas like this.

320
00:15:42,880 --> 00:15:45,120
That is a fundamental challenge for us.

321
00:15:45,120 --> 00:15:49,040
So our team is at the crossroad

322
00:15:49,040 --> 00:15:51,440
between two very different worlds.

323
00:15:51,440 --> 00:15:55,600
Our team is drawing people from software companies

324
00:15:55,600 --> 00:16:00,080
such as Google, Facebook, the sell-driving companies

325
00:16:00,080 --> 00:16:03,120
in the area, they're used to create software

326
00:16:03,120 --> 00:16:06,400
in a certain way, a very rapid way,

327
00:16:06,400 --> 00:16:09,440
and exactly, exactly.

328
00:16:09,440 --> 00:16:12,720
That doesn't work when you're carrying 300 people.

329
00:16:12,720 --> 00:16:16,480
This is exactly the problem is destructive flight test

330
00:16:16,480 --> 00:16:19,120
is not really an option for us.

331
00:16:19,120 --> 00:16:22,320
And then on the aerospace side, the people that you have there

332
00:16:22,320 --> 00:16:26,080
are used to do things right the first time.

333
00:16:26,080 --> 00:16:29,280
And to have everything deterministic,

334
00:16:29,280 --> 00:16:32,320
everything planned, and everything verified.

335
00:16:32,320 --> 00:16:34,480
And so what we're doing right now is

336
00:16:34,480 --> 00:16:37,440
we are proposing those new algorithms based on machine learning

337
00:16:37,440 --> 00:16:40,160
that are completely probabilistic based.

338
00:16:40,160 --> 00:16:42,880
And we're saying it's going to work.

339
00:16:42,880 --> 00:16:47,360
We can predict that it will work to a certain performance

340
00:16:47,360 --> 00:16:50,640
standard, but we don't have any formal proof for you.

341
00:16:50,640 --> 00:16:52,720
We can only do that statistically.

342
00:16:52,720 --> 00:16:54,880
What does that even mean now?

343
00:16:54,880 --> 00:17:01,280
Are you referring to the application of formal methods

344
00:17:01,280 --> 00:17:07,040
to provide performance envelopes and guarantees to your system?

345
00:17:07,040 --> 00:17:07,520
Exactly.

346
00:17:07,520 --> 00:17:09,560
So right now, there's a lot of work that

347
00:17:09,560 --> 00:17:11,200
is being done in formal methods.

348
00:17:11,200 --> 00:17:15,560
And those methods have proven to be very useful for,

349
00:17:15,560 --> 00:17:20,560
let's say, algorithms of low to medium complexity.

350
00:17:20,560 --> 00:17:23,680
But when we're tackling autonomous landing,

351
00:17:23,680 --> 00:17:26,440
autonomous taxi function, for example,

352
00:17:26,440 --> 00:17:29,280
the sheer number of pixels and the image size

353
00:17:29,280 --> 00:17:31,360
that we need to deal with and the speed at which we need

354
00:17:31,360 --> 00:17:35,000
to deal with them makes those applications

355
00:17:35,000 --> 00:17:38,000
for now barely usable.

356
00:17:38,000 --> 00:17:40,520
We basically don't have the right tool

357
00:17:40,520 --> 00:17:44,040
to be able to apply it on very complex neural network

358
00:17:44,040 --> 00:17:48,560
that would be based on architectures like ResNet or VGG

359
00:17:48,560 --> 00:17:53,280
or all the newest flavor as well.

360
00:17:53,280 --> 00:17:56,800
So at that point, since we can't rely on those formal methods,

361
00:17:56,800 --> 00:17:59,360
what we're left with is those statistical methods.

362
00:17:59,360 --> 00:18:01,720
And one of the things that makes it really hard

363
00:18:01,720 --> 00:18:04,560
is that we don't know the distribution of the events

364
00:18:04,560 --> 00:18:05,840
beforehand.

365
00:18:05,840 --> 00:18:09,040
So we need to be able to do those data collection

366
00:18:09,040 --> 00:18:11,840
to be able to understand what is our environment,

367
00:18:11,840 --> 00:18:14,400
as far as our function, our concerns,

368
00:18:14,400 --> 00:18:18,040
what is the, let's call it for a Gaussian distribution,

369
00:18:18,040 --> 00:18:21,640
what is the nominal case that gives you your 60%,

370
00:18:21,640 --> 00:18:24,960
but also what is the long tail events?

371
00:18:24,960 --> 00:18:28,360
And one of the interesting examples

372
00:18:28,360 --> 00:18:32,240
that we have is we've captured on video and elephant

373
00:18:32,240 --> 00:18:35,880
walking on taxiways in Africa just behind

374
00:18:35,880 --> 00:18:38,480
some commercial aircraft at an airport.

375
00:18:38,480 --> 00:18:41,240
And there's no way any of our engineers at least

376
00:18:41,240 --> 00:18:43,640
in Silicon Valley could have figured this one out.

377
00:18:43,640 --> 00:18:46,640
But these are cases that our system for object detection,

378
00:18:46,640 --> 00:18:48,800
for example, will have to tackle.

379
00:18:48,800 --> 00:18:52,320
So this is the challenge is that we

380
00:18:52,320 --> 00:18:54,600
can't use those formal approaches

381
00:18:54,600 --> 00:18:56,680
because we don't know what the world is made of

382
00:18:56,680 --> 00:18:58,800
until you've done that data collection.

383
00:18:58,800 --> 00:19:04,000
And that data collection really gives you just the statistical

384
00:19:04,000 --> 00:19:06,360
the means to do a statistical approach.

385
00:19:06,360 --> 00:19:10,960
And in terms of that statistical approach,

386
00:19:10,960 --> 00:19:16,160
what are some of the tools that you're using?

387
00:19:16,160 --> 00:19:19,880
Early on when we started to do flight tests

388
00:19:19,880 --> 00:19:22,280
and one of the greatest achievements that we've done

389
00:19:22,280 --> 00:19:24,320
in our team is actually work on the AI

390
00:19:24,320 --> 00:19:27,720
that completed the very first autonomous landing

391
00:19:27,720 --> 00:19:31,120
of an A350 with a camera system.

392
00:19:31,120 --> 00:19:33,720
And to give you an idea that the A350

393
00:19:33,720 --> 00:19:38,720
is this aircraft that carries between 300 and 350 passengers.

394
00:19:38,720 --> 00:19:41,840
So it's a fairly big beast to land.

395
00:19:41,840 --> 00:19:44,040
Now, when we did that, one of the first things

396
00:19:44,040 --> 00:19:47,840
that we noticed is flying an A350 is quite costly.

397
00:19:47,840 --> 00:19:50,680
It's time consuming and to ensure safety,

398
00:19:50,680 --> 00:19:54,400
it takes quite a bit of time to go through all the hoops

399
00:19:54,400 --> 00:19:56,560
to have the authorization to fly it.

400
00:19:56,560 --> 00:20:00,400
So doing data collection using flight test aircraft

401
00:20:00,400 --> 00:20:03,360
is a lengthy and time consuming process.

402
00:20:03,360 --> 00:20:05,640
So what we have developed here in Silicon Valley

403
00:20:05,640 --> 00:20:07,840
is this hybrid approach where we said,

404
00:20:07,840 --> 00:20:10,120
well, the software engineers here

405
00:20:10,120 --> 00:20:12,760
are used to those two weeks development cycle

406
00:20:12,760 --> 00:20:14,760
or those very short development cycle

407
00:20:14,760 --> 00:20:17,600
where there's a new release every couple weeks.

408
00:20:17,600 --> 00:20:20,880
And how can we do that for aerospace?

409
00:20:20,880 --> 00:20:23,680
So what we did is we acquired our own aircraft

410
00:20:23,680 --> 00:20:25,600
that we own and operate.

411
00:20:25,600 --> 00:20:28,680
And we've modified that aircraft to be equipped

412
00:20:28,680 --> 00:20:32,000
with all the sensors that we need to perform those functions.

413
00:20:32,000 --> 00:20:34,680
And we are now flying this aircraft throughout the area

414
00:20:34,680 --> 00:20:38,680
to be able to do data collection in those different conditions

415
00:20:38,680 --> 00:20:40,480
that we're gonna see in the field.

416
00:20:40,480 --> 00:20:44,280
So it can range from clear conditions during daytime

417
00:20:44,280 --> 00:20:48,360
to night conditions, but also what we call the graded conditions.

418
00:20:48,360 --> 00:20:52,800
So fog, low ceiling, rain, and all those.

419
00:20:52,800 --> 00:20:55,000
And to be able to have real data

420
00:20:55,000 --> 00:20:58,320
and to be able to acquire the volume necessary

421
00:20:58,320 --> 00:21:01,040
to start doing those statistical proofs

422
00:21:01,040 --> 00:21:04,520
of reliability and performance is essential for us

423
00:21:04,520 --> 00:21:06,520
to push the maturity of those functions.

424
00:21:06,520 --> 00:21:11,320
Are you saying, or is it the case that you have to fly?

425
00:21:11,320 --> 00:21:13,280
If you want to do this on A350s,

426
00:21:13,280 --> 00:21:15,480
you have to fly A350s for data collection

427
00:21:15,480 --> 00:21:20,480
or are you flying cheaper vehicles for data collection?

428
00:21:20,480 --> 00:21:23,840
And in our case, when we started in flight test aircraft,

429
00:21:23,840 --> 00:21:27,080
we started doing data collection on A350s

430
00:21:27,080 --> 00:21:30,720
and other big commercial aircraft.

431
00:21:30,720 --> 00:21:33,240
But it's quite costly to do so.

432
00:21:33,240 --> 00:21:35,640
And after analyzing the problem,

433
00:21:35,640 --> 00:21:39,080
we saw that we don't actually need to use such an aircraft

434
00:21:39,080 --> 00:21:41,520
to collect data that is applicable and usable

435
00:21:41,520 --> 00:21:43,280
to develop those functions.

436
00:21:43,280 --> 00:21:45,320
And the reason is, in our case,

437
00:21:45,320 --> 00:21:46,840
we're using a beachcraft barren

438
00:21:46,840 --> 00:21:51,680
to collect the data for the visual landing system.

439
00:21:51,680 --> 00:21:56,240
And the barren, although less stable than an A350,

440
00:21:56,240 --> 00:22:00,080
can replicate the approach that an A350 would do,

441
00:22:00,080 --> 00:22:03,920
can explore the full service volume that we need to explore

442
00:22:03,920 --> 00:22:06,280
and can cover pretty much all of the conditions

443
00:22:06,280 --> 00:22:08,560
that an A350 would encounter.

444
00:22:08,560 --> 00:22:11,280
And even to a certain extent,

445
00:22:11,280 --> 00:22:15,280
because the beachcraft barren is less stable than an A350,

446
00:22:15,280 --> 00:22:18,200
we cover a wider range of conditions

447
00:22:18,200 --> 00:22:20,960
than what we would be able to do with an A350.

448
00:22:20,960 --> 00:22:24,320
So on that respect, it's actually a way

449
00:22:24,320 --> 00:22:28,760
of building a more robust system using a cheaper aircraft

450
00:22:28,760 --> 00:22:30,800
that is available for us anytime.

451
00:22:30,800 --> 00:22:31,800
Yeah, yeah.

452
00:22:31,800 --> 00:22:33,480
Going back to the previous question

453
00:22:33,480 --> 00:22:35,280
about statistical tools,

454
00:22:37,320 --> 00:22:39,640
I'm trying to get a little bit more clarity

455
00:22:39,640 --> 00:22:41,520
on what that looks like.

456
00:22:41,520 --> 00:22:46,520
Like I'm envisioning you're using something akin

457
00:22:47,760 --> 00:22:50,960
to like, you know, confidence testing

458
00:22:50,960 --> 00:22:52,120
or something like that.

459
00:22:52,120 --> 00:22:56,200
But it's not clear to me how you ever have confidence

460
00:22:56,200 --> 00:23:00,160
if you don't know what your plane is going to be able to see.

461
00:23:00,160 --> 00:23:03,000
So I'm looking for kind of names of,

462
00:23:03,000 --> 00:23:05,360
oh, we use this statistical method or this

463
00:23:05,360 --> 00:23:09,520
or that to produce these guarantees.

464
00:23:09,520 --> 00:23:12,600
Is that something that you can elaborate on?

465
00:23:12,600 --> 00:23:14,120
Yes.

466
00:23:14,120 --> 00:23:16,480
So first thing is we need to identify

467
00:23:16,480 --> 00:23:19,160
what are the dimensions of the problem

468
00:23:19,160 --> 00:23:21,280
that affects the performance of,

469
00:23:21,280 --> 00:23:24,640
in this case, the ML model or the perception stack.

470
00:23:24,640 --> 00:23:26,040
So one of the things that we've observed

471
00:23:26,040 --> 00:23:29,680
is the configuration of the airport is critical.

472
00:23:29,680 --> 00:23:31,520
If you have only one runway,

473
00:23:31,520 --> 00:23:34,240
it's easier to identify than when you're in Chicago

474
00:23:34,240 --> 00:23:36,960
where you have like seven with runways

475
00:23:36,960 --> 00:23:38,640
that are crossing each other

476
00:23:38,640 --> 00:23:41,280
and taxiways that are confusing everything.

477
00:23:41,280 --> 00:23:43,800
So the airport configuration is, for example,

478
00:23:43,800 --> 00:23:45,440
one of those dimensions.

479
00:23:45,440 --> 00:23:48,800
The other one is lighting conditions,

480
00:23:48,800 --> 00:23:50,520
weather conditions.

481
00:23:50,520 --> 00:23:53,240
So and you have also those,

482
00:23:53,240 --> 00:23:54,680
I'm going to call it corner cases.

483
00:23:54,680 --> 00:23:56,600
So when you have the sun in view

484
00:23:56,600 --> 00:23:59,080
or when you have the moon in view

485
00:23:59,080 --> 00:24:00,800
and you're trying to perform this function,

486
00:24:00,800 --> 00:24:02,680
that will affect the performance of the ML

487
00:24:02,680 --> 00:24:06,240
if it has never seen such occurrences.

488
00:24:06,240 --> 00:24:10,320
Now, once we have identified those dimensions,

489
00:24:10,320 --> 00:24:13,200
we need to understand what is the amount of data

490
00:24:13,200 --> 00:24:16,320
that we need to be able to be representative

491
00:24:16,320 --> 00:24:20,680
of our environment for each of those dimensions.

492
00:24:20,680 --> 00:24:26,840
And then what we can do is using a representative statistical set.

493
00:24:26,840 --> 00:24:29,200
So a number of population of images

494
00:24:29,200 --> 00:24:32,000
that represent our space.

495
00:24:32,000 --> 00:24:34,960
We can take the ML,

496
00:24:34,960 --> 00:24:38,200
do the test over a percentage of that

497
00:24:38,200 --> 00:24:40,880
with a holdout at the end.

498
00:24:40,880 --> 00:24:43,880
And then by having multiple folds

499
00:24:43,880 --> 00:24:45,800
and basically reshuffling this,

500
00:24:45,800 --> 00:24:49,080
we can understand what is the degree of generalization

501
00:24:49,080 --> 00:24:51,560
of the ML model.

502
00:24:51,560 --> 00:24:53,560
And using that statistic,

503
00:24:53,560 --> 00:24:58,160
we can derive from there how many airports do we need to see

504
00:24:58,160 --> 00:25:00,000
to guarantee to a certain probability

505
00:25:00,000 --> 00:25:02,880
that we will meet our performance.

506
00:25:02,880 --> 00:25:04,960
So to give you an example,

507
00:25:04,960 --> 00:25:09,840
let's say that we've collected data on 100 different airports.

508
00:25:09,840 --> 00:25:13,120
We can use that 100 airports and say,

509
00:25:13,120 --> 00:25:15,400
let's try to train only on 30

510
00:25:15,400 --> 00:25:17,480
and check how we perform on the rest.

511
00:25:17,480 --> 00:25:22,200
And then we do that again saying we take 40, 50, et cetera.

512
00:25:22,200 --> 00:25:24,360
From there you can draw a curve.

513
00:25:24,360 --> 00:25:27,760
And at some point that curve will hit an asymptote

514
00:25:27,760 --> 00:25:31,840
that tells you I've reached my target performance

515
00:25:31,840 --> 00:25:34,960
and any additional airport on top of that

516
00:25:34,960 --> 00:25:37,360
will increase or improve it.

517
00:25:37,360 --> 00:25:38,840
But you're already there.

518
00:25:38,840 --> 00:25:41,200
So from there we can backtrack how many airports

519
00:25:41,200 --> 00:25:44,320
or how many samples we need in each of those dimensions.

520
00:25:44,320 --> 00:25:49,320
And so that's one of the approach that we're exploring

521
00:25:49,320 --> 00:25:51,360
to be able to provide this statistical proof.

522
00:25:51,360 --> 00:25:54,400
Thus far in the conversation you've kind of connected

523
00:25:54,400 --> 00:25:57,280
the safety, critical nature of what you're doing

524
00:25:57,280 --> 00:26:00,920
and the need to provide these performance guarantees

525
00:26:00,920 --> 00:26:03,760
to kind of this very fundamental task

526
00:26:03,760 --> 00:26:08,440
that all ML practitioners are worried about data collection.

527
00:26:10,120 --> 00:26:12,720
And you've talked a little bit about how you collect

528
00:26:12,720 --> 00:26:15,000
the data.

529
00:26:15,000 --> 00:26:17,680
There's also the aspect of labeling the data

530
00:26:17,680 --> 00:26:21,080
which is a big deal as well.

531
00:26:21,080 --> 00:26:24,200
Can you talk a little bit about some of the challenges

532
00:26:24,200 --> 00:26:26,800
of labeling for your use case?

533
00:26:26,800 --> 00:26:28,120
Absolutely.

534
00:26:28,120 --> 00:26:30,640
And I think anybody that has worked in ML

535
00:26:30,640 --> 00:26:33,600
fully understand that getting the right data

536
00:26:33,600 --> 00:26:36,480
and getting the good labels is half of the work.

537
00:26:37,400 --> 00:26:39,320
And the other half being able to train it

538
00:26:39,320 --> 00:26:40,440
and test it properly.

539
00:26:40,440 --> 00:26:43,480
So labeling and acquiring that data

540
00:26:43,480 --> 00:26:46,280
is one of the major challenges for our industry.

541
00:26:47,240 --> 00:26:50,960
The car industry has the luxury of being able to collect data

542
00:26:50,960 --> 00:26:54,120
in a fairly cheap way because they need to equip a car

543
00:26:54,120 --> 00:26:56,200
that's certainly an expensive piece of equipment

544
00:26:56,200 --> 00:26:59,800
but after that driving around is not an expensive operation.

545
00:26:59,800 --> 00:27:02,400
In our case, flying is an expensive operation

546
00:27:02,400 --> 00:27:05,600
meaning that getting data is time consuming.

547
00:27:05,600 --> 00:27:08,720
It's we need to put a lot of resources behind it.

548
00:27:08,720 --> 00:27:11,880
And then after that, we need to label that data

549
00:27:11,880 --> 00:27:14,200
and we need to label to a level of precision

550
00:27:14,200 --> 00:27:18,560
that has rarely been seen in other use cases.

551
00:27:18,560 --> 00:27:20,160
And I'm going to give you an example

552
00:27:20,160 --> 00:27:25,880
of the typical classifier and bounding box sort of ML model

553
00:27:25,880 --> 00:27:26,800
that you have out there.

554
00:27:26,800 --> 00:27:29,480
So for detecting cats and dogs.

555
00:27:29,480 --> 00:27:31,120
So most of the time to be able to do

556
00:27:31,120 --> 00:27:33,360
those typical classification problem

557
00:27:33,360 --> 00:27:35,600
and to put a bounding box on it.

558
00:27:35,600 --> 00:27:39,520
Using, for example, the typical YOLO architecture,

559
00:27:39,520 --> 00:27:45,440
your labeling needs is basically you need to fit a box

560
00:27:45,440 --> 00:27:49,240
on an image that mainly contains the object of interest.

561
00:27:49,240 --> 00:27:52,680
So for example, your dog may be half of the image

562
00:27:52,680 --> 00:27:55,560
or may be 40% of all your pixels.

563
00:27:55,560 --> 00:27:58,640
And so that means at the end, if you put a bounding box on it

564
00:27:58,640 --> 00:28:01,880
as a manual operator would, even if the bounding box

565
00:28:01,880 --> 00:28:03,800
is not well fitted over the object

566
00:28:03,800 --> 00:28:06,680
and you're taking another 70 pixels on the side

567
00:28:06,680 --> 00:28:10,200
of your image for, for example, an HD image

568
00:28:10,200 --> 00:28:14,600
that's still more or less within the 2% or 5% margin.

569
00:28:14,600 --> 00:28:17,720
And your ML model will be able to generalize

570
00:28:17,720 --> 00:28:19,360
over all of those samples assuming

571
00:28:19,360 --> 00:28:23,560
that you don't have an inherent bias into your images.

572
00:28:23,560 --> 00:28:29,760
So the classical approach makes it, if you forgive the term,

573
00:28:29,760 --> 00:28:34,440
makes sloppy labels still OK to achieve the right performance.

574
00:28:34,440 --> 00:28:38,280
Now, in our case, if you take a 12 megapixel image,

575
00:28:38,280 --> 00:28:41,720
which is the typical range of resolution

576
00:28:41,720 --> 00:28:43,960
that we need for lending an aircraft

577
00:28:43,960 --> 00:28:48,840
and being able to provide the navigational parameter for it,

578
00:28:48,840 --> 00:28:54,360
the airport can be as small as 20 pixel by 20 pixel in this image.

579
00:28:54,360 --> 00:28:58,480
So at the end, if you want to keep your error bounded,

580
00:28:58,480 --> 00:29:00,440
your bounding box on that object needs

581
00:29:00,440 --> 00:29:04,880
to be within maybe 5 pixels or 3 pixels.

582
00:29:04,880 --> 00:29:06,920
So what does it mean in terms of labeling

583
00:29:06,920 --> 00:29:11,080
is that the manual labeler needs to take that 12 megapixel

584
00:29:11,080 --> 00:29:14,920
or even 15 megapixel image, needs to zoom in as soon

585
00:29:14,920 --> 00:29:18,160
as he has identified where the object and the tiny object

586
00:29:18,160 --> 00:29:22,000
is in the image, and then needs to work

587
00:29:22,000 --> 00:29:25,320
on putting this bounding box as tight as possible around it

588
00:29:25,320 --> 00:29:29,320
within a 3 pixel accuracy.

589
00:29:29,320 --> 00:29:32,600
And so that is quite a challenge as anybody

590
00:29:32,600 --> 00:29:35,040
has worked with manual labeling knows,

591
00:29:35,040 --> 00:29:36,600
and it's also time-consuming.

592
00:29:36,600 --> 00:29:41,440
And I'm going to add that most of our crowd sourcing

593
00:29:41,440 --> 00:29:43,360
strategies to be able to do that,

594
00:29:43,360 --> 00:29:47,280
so meaning gathering a large population of manual annotator

595
00:29:47,280 --> 00:29:51,440
is not a good method to do this because the level of accuracy

596
00:29:51,440 --> 00:29:55,880
required requires a lot more time than they will spend

597
00:29:55,880 --> 00:29:58,120
because of the money that they're getting out of it.

598
00:29:58,120 --> 00:30:04,120
I mean, there are even simpler challenges

599
00:30:04,120 --> 00:30:09,880
like most of the folks that we're paying to do manual labeling.

600
00:30:09,880 --> 00:30:12,280
I'm imagining a 12 megapixel image

601
00:30:12,280 --> 00:30:14,480
is going to take a long time to download

602
00:30:14,480 --> 00:30:16,720
and is going to choke their machine.

603
00:30:16,720 --> 00:30:18,080
That is absolutely right.

604
00:30:18,080 --> 00:30:22,000
The whole pipeline behind it of being able to transfer

605
00:30:22,000 --> 00:30:25,680
those data to the annotator is a challenge in itself.

606
00:30:25,680 --> 00:30:28,480
We could, and one of the strategies, for example,

607
00:30:28,480 --> 00:30:32,560
to break it down into a sub-grid, but it gives you

608
00:30:32,560 --> 00:30:36,320
more images at the end, more images to annotate,

609
00:30:36,320 --> 00:30:39,040
still meaning more time to do so.

610
00:30:39,040 --> 00:30:43,840
And the problem is, at scale, it doesn't work at all.

611
00:30:43,840 --> 00:30:46,560
If you're at a point where you're collecting

612
00:30:46,560 --> 00:30:50,320
literally millions of images every week,

613
00:30:50,320 --> 00:30:53,640
it is totally impossible to break down those images

614
00:30:53,640 --> 00:30:57,280
into those 500 by 500, for example, pixel images

615
00:30:57,280 --> 00:31:01,760
and have this army of human annotators looking at each of them.

616
00:31:01,760 --> 00:31:05,760
The throughput is just going to break the whole chain,

617
00:31:05,760 --> 00:31:08,240
which forces us at that point to think

618
00:31:08,240 --> 00:31:13,240
about auto labeling approach or semi-automated approach.

619
00:31:13,240 --> 00:31:16,640
And I'm going to say this is not a binary problem,

620
00:31:16,640 --> 00:31:20,600
in the sense you can think about it as a spectrum.

621
00:31:20,600 --> 00:31:25,880
In the very first stage, when your ML models are immature

622
00:31:25,880 --> 00:31:27,960
and you're just learning how to do this,

623
00:31:27,960 --> 00:31:29,480
you're going to need a human annotator

624
00:31:29,480 --> 00:31:31,200
for pretty much every frame.

625
00:31:31,200 --> 00:31:34,040
But then, as you're starting to build some autonomy

626
00:31:34,040 --> 00:31:36,680
on top of it, in the sense, you have algorithms,

627
00:31:36,680 --> 00:31:39,720
heuristics that can start to make sense of the data

628
00:31:39,720 --> 00:31:44,880
and give you a first guess of what you need to annotate,

629
00:31:44,880 --> 00:31:48,360
then you can increase the number of images

630
00:31:48,360 --> 00:31:49,720
that you're automatically annotating

631
00:31:49,720 --> 00:31:52,920
and have the human annotator only checking every one image

632
00:31:52,920 --> 00:31:54,000
out of 10.

633
00:31:54,000 --> 00:31:56,560
And then, as those algorithms, again, mature,

634
00:31:56,560 --> 00:31:58,360
you can push the cursor further

635
00:31:58,360 --> 00:32:01,680
and have the annotator looking at one image over 100,

636
00:32:01,680 --> 00:32:03,880
over 1,000, et cetera.

637
00:32:03,880 --> 00:32:05,600
And then the ultimate goal for us

638
00:32:05,600 --> 00:32:10,400
is when you reach the millions, one image out of 1 million

639
00:32:10,400 --> 00:32:12,840
is still something that a human annotator can do.

640
00:32:12,840 --> 00:32:15,120
But how do you ensure the quality and the consistency

641
00:32:15,120 --> 00:32:16,960
of the million of images behind it?

642
00:32:16,960 --> 00:32:19,440
And that is the fundamental challenge

643
00:32:19,440 --> 00:32:23,560
for the labeling parts that we are addressing.

644
00:32:23,560 --> 00:32:28,080
And before we jump into the automatic labeling,

645
00:32:28,080 --> 00:32:31,720
automated labeling, and more detail,

646
00:32:31,720 --> 00:32:33,880
speaking to the previous comment,

647
00:32:33,880 --> 00:32:37,240
do you, both from a labeling perspective,

648
00:32:37,240 --> 00:32:42,280
as well as from a model perspective?

649
00:32:42,280 --> 00:32:44,120
Do you tile the images?

650
00:32:44,120 --> 00:32:49,920
Or do you keep the images whole?

651
00:32:49,920 --> 00:32:54,200
So for the labeling, this, I'm going to use an expression

652
00:32:54,200 --> 00:32:55,840
that everybody hates.

653
00:32:55,840 --> 00:32:56,520
It depends.

654
00:32:59,320 --> 00:33:02,920
So for the images, the concept that we've seen

655
00:33:02,920 --> 00:33:06,200
is because our use case for commercial aviation

656
00:33:06,200 --> 00:33:08,280
is within a very structured environment

657
00:33:08,280 --> 00:33:11,600
compared to others, we have a pre-array knowledge

658
00:33:11,600 --> 00:33:14,680
on the environment that we can leverage

659
00:33:14,680 --> 00:33:16,680
to actually break it down.

660
00:33:16,680 --> 00:33:20,160
So in the sense, to be more practical here,

661
00:33:20,160 --> 00:33:22,160
we know exactly where the airport is

662
00:33:22,160 --> 00:33:24,960
because we have the lat long coordinates,

663
00:33:24,960 --> 00:33:27,040
and this is in a database.

664
00:33:27,040 --> 00:33:30,280
Now, where should it be in the image is the question.

665
00:33:30,280 --> 00:33:33,480
So as soon as we know the GPS coordinate of the aircraft,

666
00:33:33,480 --> 00:33:36,680
we know its attitude, heading, and all that stuff, yeah.

667
00:33:36,680 --> 00:33:37,520
Exactly.

668
00:33:37,520 --> 00:33:39,520
And then if we have the camera calibrated,

669
00:33:39,520 --> 00:33:40,640
and we know exactly where it is,

670
00:33:40,640 --> 00:33:42,800
and where it's pointing at on the aircraft,

671
00:33:42,800 --> 00:33:44,920
then we roughly know where the airport

672
00:33:44,920 --> 00:33:47,400
is supposed to be within the image.

673
00:33:47,400 --> 00:33:50,280
Now, there's still sufficient amount of errors in there

674
00:33:50,280 --> 00:33:52,440
so that we can't just rely on that system

675
00:33:52,440 --> 00:33:55,280
to guide the aircraft all the way to the runway.

676
00:33:55,280 --> 00:33:57,920
Many, you can't do a full geometric solution

677
00:33:57,920 --> 00:34:00,640
because there's a lot of noise and uncertainty in the system.

678
00:34:00,640 --> 00:34:01,880
Exactly.

679
00:34:01,880 --> 00:34:04,520
This is where the ML component becomes necessary

680
00:34:04,520 --> 00:34:08,480
because we need to go from a rough region of interest

681
00:34:08,480 --> 00:34:11,640
to the exact position of the runway within the image.

682
00:34:11,640 --> 00:34:13,560
But that gives us a first guess,

683
00:34:13,560 --> 00:34:15,880
and this is a region of interest that we can cut out

684
00:34:15,880 --> 00:34:18,760
from that 12-megapixel image,

685
00:34:18,760 --> 00:34:21,280
and then have the annotators annotate

686
00:34:21,280 --> 00:34:23,240
instead of looking at the whole image.

687
00:34:23,240 --> 00:34:27,400
So that is one technique to reduce the amount of pixels

688
00:34:27,400 --> 00:34:30,520
that we need to process when we're labeling things.

689
00:34:30,520 --> 00:34:34,320
So in other words, what you primarily care about

690
00:34:34,320 --> 00:34:37,520
for the task that we're discussing,

691
00:34:37,520 --> 00:34:42,360
eG landing is the airport and the runways,

692
00:34:42,360 --> 00:34:44,440
and a lot of your images are gonna have,

693
00:34:44,440 --> 00:34:47,000
by definition, a lot of sky, for example,

694
00:34:47,000 --> 00:34:49,360
and you don't really care about having that annotated

695
00:34:49,360 --> 00:34:51,480
so you can kind of crop that out.

696
00:34:51,480 --> 00:34:52,800
Exactly.

697
00:34:52,800 --> 00:34:55,880
One additional thing is, as you're pointing out,

698
00:34:55,880 --> 00:34:58,320
during crews where you can only see sky,

699
00:34:58,320 --> 00:35:00,280
this is something that we're not even recording

700
00:35:00,280 --> 00:35:04,600
because there is no task to be done when you're in crews.

701
00:35:04,600 --> 00:35:06,440
It's all the airspace is controlled,

702
00:35:06,440 --> 00:35:09,680
so you know that your separation is guaranteed.

703
00:35:09,680 --> 00:35:12,680
So on that case, it's a very safe environment.

704
00:35:12,680 --> 00:35:15,720
So you need to start recording as soon as you are

705
00:35:15,720 --> 00:35:19,040
in the terminal area and you're in the last stretch

706
00:35:19,040 --> 00:35:22,400
to be able to land that aircraft on the airport.

707
00:35:22,400 --> 00:35:24,320
And even in there, as you said,

708
00:35:24,320 --> 00:35:27,440
there's a large portion that might be the sky of the beginning.

709
00:35:27,440 --> 00:35:30,640
As you get closer, the scale of the runway will change

710
00:35:30,640 --> 00:35:35,200
and the runway will take the full field of view of your image.

711
00:35:35,200 --> 00:35:36,680
And this is also one of the challenges

712
00:35:36,680 --> 00:35:40,080
for the ML on the ML side, as a side note is,

713
00:35:40,080 --> 00:35:42,400
you start looking at the tiny little box

714
00:35:42,400 --> 00:35:44,240
in the middle of your image,

715
00:35:44,240 --> 00:35:46,480
and the ML has to recognize that as a runway

716
00:35:46,480 --> 00:35:48,120
and then do the math behind it

717
00:35:48,120 --> 00:35:50,200
to be able to give you exactly your position

718
00:35:50,200 --> 00:35:51,800
with respect to it.

719
00:35:51,800 --> 00:35:53,520
And then you have to go all the way

720
00:35:53,520 --> 00:35:56,240
to the point that you don't even see the full runway,

721
00:35:56,240 --> 00:35:58,480
you only see a portion of it.

722
00:35:58,480 --> 00:36:00,920
And yet, all the way to the landing,

723
00:36:00,920 --> 00:36:04,320
your ML model still needs to take that partial image

724
00:36:04,320 --> 00:36:05,720
and compute the exact same thing

725
00:36:05,720 --> 00:36:07,360
of where you are with respect to it

726
00:36:07,360 --> 00:36:09,160
to be able to land your aircraft.

727
00:36:09,160 --> 00:36:13,480
So the scaling factor is a major challenge,

728
00:36:13,480 --> 00:36:16,560
both for the ML part but also for the annotation.

729
00:36:16,560 --> 00:36:20,600
Because we need to ensure that our error on the labels

730
00:36:20,600 --> 00:36:24,400
are tightly controlled over this entire range of scales.

731
00:36:24,400 --> 00:36:26,400
And then the other side of my question

732
00:36:26,400 --> 00:36:31,160
was with regard to building and training the model,

733
00:36:31,160 --> 00:36:36,360
your typical computer vision networks

734
00:36:36,360 --> 00:36:40,680
or hundreds of pixel-wide images

735
00:36:40,680 --> 00:36:44,640
is kind of what they're tuned for.

736
00:36:44,640 --> 00:36:47,880
Are you tiling or are you using techniques

737
00:36:47,880 --> 00:36:50,840
that work at full-scale images?

738
00:36:50,840 --> 00:36:53,040
So this is a very good question

739
00:36:53,040 --> 00:36:55,520
because it taps into the real-time performance

740
00:36:55,520 --> 00:36:58,200
with respect to the onboard compute power

741
00:36:58,200 --> 00:37:00,360
that we have available.

742
00:37:00,360 --> 00:37:01,200
And I'm going to...

743
00:37:01,200 --> 00:37:03,040
The flip side of that is inference, right?

744
00:37:03,040 --> 00:37:04,720
Exactly, exactly.

745
00:37:04,720 --> 00:37:07,080
And I'm going to make a little digression here

746
00:37:07,080 --> 00:37:09,240
just to understand the fundamental problem.

747
00:37:09,240 --> 00:37:13,160
So on an aircraft, everything needs to be certified

748
00:37:13,160 --> 00:37:15,400
and everything needs to be deterministic,

749
00:37:15,400 --> 00:37:17,160
which means that the type of computer

750
00:37:17,160 --> 00:37:20,280
that we can use to run the ML algorithms

751
00:37:20,280 --> 00:37:24,720
are not the typical GPU that you use on your gaming laptop.

752
00:37:24,720 --> 00:37:28,280
They're much less powerful and there's redundancy

753
00:37:28,280 --> 00:37:29,600
built into it.

754
00:37:29,600 --> 00:37:32,320
And so essentially, it's a big constraint

755
00:37:32,320 --> 00:37:34,800
to be able to achieve the real-time performance

756
00:37:34,800 --> 00:37:36,240
that we need to have.

757
00:37:36,240 --> 00:37:40,000
So having said that processing 12 megapixel

758
00:37:40,000 --> 00:37:42,880
or 15 megapixel images in real time

759
00:37:42,880 --> 00:37:44,400
when you have three cameras, for example,

760
00:37:44,400 --> 00:37:46,040
processing it at the same time,

761
00:37:46,040 --> 00:37:48,600
is a major challenge for us.

762
00:37:48,600 --> 00:37:51,000
So there's different approaches of doing this.

763
00:37:51,000 --> 00:37:54,080
Tiling is definitely one of the first methods

764
00:37:54,080 --> 00:37:56,240
that we are using.

765
00:37:56,240 --> 00:38:00,880
But also, the other aspect is to exploit the scale.

766
00:38:00,880 --> 00:38:05,880
So if we can shrink the image and we can use the image

767
00:38:05,880 --> 00:38:10,880
at different scales, it also provides you a filter

768
00:38:10,880 --> 00:38:14,520
that lets information at different frequencies pop out.

769
00:38:14,520 --> 00:38:18,080
So for example, when you're pretty far from the runway,

770
00:38:18,080 --> 00:38:20,400
if you shrink the image, it actually

771
00:38:20,400 --> 00:38:23,360
blurs out the high frequency item that are actually noise

772
00:38:23,360 --> 00:38:25,320
and that you don't really care about.

773
00:38:25,320 --> 00:38:29,000
And you can see more clearly the runway down the road.

774
00:38:29,000 --> 00:38:30,880
Now, that's one approach.

775
00:38:30,880 --> 00:38:33,760
The other approach is really to take the full image,

776
00:38:33,760 --> 00:38:37,720
just cut it in grids that overlap each other

777
00:38:37,720 --> 00:38:41,320
and to basically brute force it over the entire thing.

778
00:38:41,320 --> 00:38:43,400
But again, like here, this approach

779
00:38:43,400 --> 00:38:46,520
where the bottleneck is the compute power that is available.

780
00:38:46,520 --> 00:38:49,880
And we don't have the luxury of having

781
00:38:49,880 --> 00:38:52,880
a full server of GPUs in the trunk.

782
00:38:52,880 --> 00:38:55,520
Like, we would another application.

783
00:38:55,520 --> 00:39:00,280
And so kind of getting back to the labeling task,

784
00:39:00,280 --> 00:39:02,680
to the label, I guess the labels would translate

785
00:39:02,680 --> 00:39:07,400
from you're essentially down sampling your images.

786
00:39:07,400 --> 00:39:09,960
You know the label is, it's kind of a one-way,

787
00:39:09,960 --> 00:39:10,800
one-to-one mapping.

788
00:39:10,800 --> 00:39:14,680
So that's not, you don't have to manually label

789
00:39:14,680 --> 00:39:17,880
down-sampled images separate from the full resolution

790
00:39:17,880 --> 00:39:18,480
images.

791
00:39:18,480 --> 00:39:19,200
No, that's right.

792
00:39:19,200 --> 00:39:21,600
You would sample the images only once

793
00:39:21,600 --> 00:39:23,400
at the highest resolution.

794
00:39:23,400 --> 00:39:26,760
And then you could reuse that as you down sample it.

795
00:39:26,760 --> 00:39:31,440
However, I have to say you can down-sample it

796
00:39:31,440 --> 00:39:33,960
so that basically you have this filtering effect

797
00:39:33,960 --> 00:39:36,320
that happens, and that enables you

798
00:39:36,320 --> 00:39:39,040
to go faster in processing the image.

799
00:39:39,040 --> 00:39:41,560
But it's not sufficient, and you can't just

800
00:39:41,560 --> 00:39:44,680
use the output of that, because the resolution

801
00:39:44,680 --> 00:39:49,000
and the precision of the output parameter that we need

802
00:39:49,000 --> 00:39:52,760
is such that we also need the full resolution imagery

803
00:39:52,760 --> 00:39:55,840
and to have a pixel-level accuracy

804
00:39:55,840 --> 00:39:57,680
in the detection at the end.

805
00:39:57,680 --> 00:40:00,760
So I guess what I'm saying is, you

806
00:40:00,760 --> 00:40:03,760
can use those different techniques of, for example,

807
00:40:03,760 --> 00:40:06,720
cutting out a region of interest out of your image,

808
00:40:06,720 --> 00:40:08,600
of down-sampling it as well.

809
00:40:08,600 --> 00:40:10,320
But it's not sufficient.

810
00:40:10,320 --> 00:40:12,400
You need at the end, once you've defined

811
00:40:12,400 --> 00:40:14,680
really the region of interest, to get back

812
00:40:14,680 --> 00:40:18,240
to the original image with the highest resolution possible,

813
00:40:18,240 --> 00:40:20,440
to get that last piece of precision

814
00:40:20,440 --> 00:40:23,320
that you need for your autopilot, for instance.

815
00:40:23,320 --> 00:40:25,600
I think what I'm hearing you say is that you

816
00:40:25,600 --> 00:40:28,960
use these tricks like the down-sampling

817
00:40:28,960 --> 00:40:32,680
more to identify regions of interest,

818
00:40:32,680 --> 00:40:37,000
and then you pass full resolution images

819
00:40:37,000 --> 00:40:43,120
to your models, as opposed to some funky model

820
00:40:43,120 --> 00:40:46,120
that knows how to deal with both full resolution

821
00:40:46,120 --> 00:40:48,320
and down-sample images or something like that.

822
00:40:48,320 --> 00:40:51,000
So we're exploring different ways of doing that.

823
00:40:51,000 --> 00:40:53,520
But essentially, what I'm saying is,

824
00:40:53,520 --> 00:40:56,240
those are a range of techniques that you can use.

825
00:40:56,240 --> 00:40:59,400
And then there's different architectures behind it,

826
00:40:59,400 --> 00:41:04,000
where you can paralyze some of those from that processing.

827
00:41:04,000 --> 00:41:07,600
And that is the way for us to achieve both the precision

828
00:41:07,600 --> 00:41:11,320
that we need at the frame rates that we need

829
00:41:11,320 --> 00:41:13,200
to process all of that information.

830
00:41:13,200 --> 00:41:17,480
So that means that, and this is the second big challenge

831
00:41:17,480 --> 00:41:21,480
for us, we can't just reuse ML models out of the shelf

832
00:41:21,480 --> 00:41:25,520
from the fresh from the press, from Google or Facebook,

833
00:41:25,520 --> 00:41:28,440
because they're essentially on fit for our application.

834
00:41:28,440 --> 00:41:32,040
So there's definitely some big segments that we can reuse

835
00:41:32,040 --> 00:41:35,200
that is very useful for us, but at the end,

836
00:41:35,200 --> 00:41:37,000
because of the performance constraints

837
00:41:37,000 --> 00:41:38,440
that we have, the compute constraints,

838
00:41:38,440 --> 00:41:42,560
the huge images, we need to significantly rethink

839
00:41:42,560 --> 00:41:46,480
the architecture and create sort of novel architectures

840
00:41:46,480 --> 00:41:48,960
that really matches our needs.

841
00:41:48,960 --> 00:41:52,440
We started talking a bit about automated labeling,

842
00:41:52,440 --> 00:41:57,440
and you mentioned the kind of using the geometry

843
00:41:57,440 --> 00:42:00,920
to identify where an airport is.

844
00:42:00,920 --> 00:42:03,920
Is there more to the automated labeling?

845
00:42:03,920 --> 00:42:08,760
Is that automated labeling, or is that just focusing

846
00:42:08,760 --> 00:42:12,760
on what needs to be labeled, and then you're doing more

847
00:42:12,760 --> 00:42:14,920
from an automated labeling perspective?

848
00:42:14,920 --> 00:42:16,920
The way I'm going to answer the question is,

849
00:42:16,920 --> 00:42:21,080
it's an evolution of our pipeline.

850
00:42:21,080 --> 00:42:22,880
At the very beginning, as I said,

851
00:42:22,880 --> 00:42:25,400
everything was labeled manually,

852
00:42:25,400 --> 00:42:29,120
actually, everyone's going to say, in-house,

853
00:42:30,080 --> 00:42:34,240
until we ran out in interns, no, this is a joke,

854
00:42:34,240 --> 00:42:37,960
until basically people said that it's completely

855
00:42:37,960 --> 00:42:39,640
unfeasible to scale it up.

856
00:42:39,640 --> 00:42:42,560
So after that, this is, well, actually soon after that,

857
00:42:42,560 --> 00:42:45,480
we started looking into those heuristics

858
00:42:45,480 --> 00:42:48,200
and those semi-automated processes

859
00:42:48,200 --> 00:42:51,520
to be able to label the images

860
00:42:51,520 --> 00:42:55,680
with as few human or manual label as possible.

861
00:42:55,680 --> 00:42:58,560
And we are building the stack

862
00:42:58,560 --> 00:43:00,840
so that we use more of those algorithms,

863
00:43:00,840 --> 00:43:04,560
more of those heuristics to be able to increase

864
00:43:04,560 --> 00:43:06,280
the precision of our label,

865
00:43:06,280 --> 00:43:08,880
to be able to increase the consistency of them,

866
00:43:08,880 --> 00:43:11,440
and to be able to do that at greater scale

867
00:43:11,440 --> 00:43:13,640
with fewer human supervision.

868
00:43:13,640 --> 00:43:16,040
So the middle portion of that journey

869
00:43:16,040 --> 00:43:19,080
is what we call weak supervision, for example,

870
00:43:19,080 --> 00:43:20,760
or pragmatic means.

871
00:43:20,760 --> 00:43:22,920
So we're starting to have

872
00:43:22,920 --> 00:43:25,520
some of those heuristics applied,

873
00:43:25,520 --> 00:43:28,160
and it gives us enough consistency

874
00:43:28,160 --> 00:43:30,200
and enough accuracy so that we can meet

875
00:43:30,200 --> 00:43:33,400
the performance requirements that we have.

876
00:43:33,400 --> 00:43:36,640
But again, there's a scaling challenge here

877
00:43:36,640 --> 00:43:41,640
because, for example, along one lending,

878
00:43:41,760 --> 00:43:46,760
we might have to pick 20 or 50 images

879
00:43:46,920 --> 00:43:48,920
that are manually labeled

880
00:43:48,920 --> 00:43:52,400
so that we can recalibrate all of the entire sequence.

881
00:43:52,400 --> 00:43:56,680
So that would be a mix of programmatic aspect

882
00:43:56,680 --> 00:43:59,760
or weak supervision with the manual labelers

883
00:43:59,760 --> 00:44:01,920
sort of going back at it

884
00:44:01,920 --> 00:44:06,000
and sort of giving you some pointers to the algorithm

885
00:44:06,000 --> 00:44:08,680
so that everything is re-adjusted

886
00:44:08,680 --> 00:44:11,440
and all the errors are minimized in your sequence.

887
00:44:11,440 --> 00:44:13,880
Can you elaborate on that recalibration?

888
00:44:13,880 --> 00:44:16,120
One of the things is there's a lot of vibration,

889
00:44:16,120 --> 00:44:17,840
for instance, on an aircraft,

890
00:44:17,840 --> 00:44:21,680
and what you need to know to be able to label things properly

891
00:44:21,680 --> 00:44:24,760
is what is your camera position on the aircraft

892
00:44:24,760 --> 00:44:26,840
and what is this orientation with respect

893
00:44:26,840 --> 00:44:28,920
to your frame of reference?

894
00:44:28,920 --> 00:44:31,160
And that thing moves over time.

895
00:44:31,160 --> 00:44:34,080
So when we're doing data collection,

896
00:44:34,080 --> 00:44:36,840
our aircraft will do maybe 50 landings

897
00:44:36,840 --> 00:44:38,800
during that data collection.

898
00:44:38,800 --> 00:44:42,600
And the exact position and the exact calibration matrix

899
00:44:42,600 --> 00:44:44,840
that we need to apply for that camera

900
00:44:44,840 --> 00:44:46,960
will not be the same between the first flight test

901
00:44:46,960 --> 00:44:48,640
and the last flight test.

902
00:44:48,640 --> 00:44:50,560
The only way to compensate for that

903
00:44:50,560 --> 00:44:55,000
is to, in retrospect, analyze the full sequence

904
00:44:55,000 --> 00:44:57,280
and do what we call the bundle adjustment over it.

905
00:44:57,280 --> 00:45:00,840
So recalculate what would be the calibration

906
00:45:00,840 --> 00:45:04,960
for that sequence and then using that optimized calibration

907
00:45:04,960 --> 00:45:07,840
matrix, recompute where all the labels should be.

908
00:45:07,840 --> 00:45:10,200
And that is one way of minimizing the error

909
00:45:10,200 --> 00:45:11,280
over those labels.

910
00:45:11,280 --> 00:45:14,960
And this is for the programmatic labels.

911
00:45:14,960 --> 00:45:15,960
That's correct.

912
00:45:15,960 --> 00:45:19,320
So that is our way of using heuristics

913
00:45:19,320 --> 00:45:23,800
to be able to automatically label those images.

914
00:45:23,800 --> 00:45:27,720
But unlike a programmatic labeling task on NLP

915
00:45:27,720 --> 00:45:29,800
where you've got your heuristics,

916
00:45:29,800 --> 00:45:34,840
you apply them to your data and you get some labels,

917
00:45:34,840 --> 00:45:40,360
you've got this loop where just that one shot data point

918
00:45:40,360 --> 00:45:44,880
isn't sufficient because you think you know where your camera

919
00:45:44,880 --> 00:45:49,000
is but you don't really until you analyze a sequence

920
00:45:49,000 --> 00:45:52,480
of images and then you have to go back and correct.

921
00:45:52,480 --> 00:45:53,080
Exactly.

922
00:45:53,080 --> 00:45:55,200
And this is why we often have the question

923
00:45:55,200 --> 00:45:58,280
saying, if you can auto label your images,

924
00:45:58,280 --> 00:46:01,000
why don't you use your auto labeling algorithm

925
00:46:01,000 --> 00:46:04,040
in inference to actually do the function?

926
00:46:04,040 --> 00:46:09,280
And the simple answer is, well, that algorithm only works

927
00:46:09,280 --> 00:46:12,000
once you have the full sequence and you've already landed

928
00:46:12,000 --> 00:46:15,280
and you can sort of recalculate all of it

929
00:46:15,280 --> 00:46:18,400
and then subtract the error out of your sequence.

930
00:46:18,400 --> 00:46:21,560
So essentially, it's completely inapplicable

931
00:46:21,560 --> 00:46:24,920
to the inference case.

932
00:46:24,920 --> 00:46:28,400
But one additional thing is the heuristics

933
00:46:28,400 --> 00:46:31,160
have some limitations, especially when

934
00:46:31,160 --> 00:46:34,560
you're starting to look at long tail events.

935
00:46:34,560 --> 00:46:36,680
This is where typically they fail.

936
00:46:36,680 --> 00:46:41,120
And also at larger scales to be able to ensure

937
00:46:41,120 --> 00:46:43,280
the consistency and the quality of your labels

938
00:46:43,280 --> 00:46:46,480
using those heuristics might prove of a challenge.

939
00:46:46,480 --> 00:46:49,080
And this is where the journey that I was talking about

940
00:46:49,080 --> 00:46:51,160
keeps on going because at some point,

941
00:46:51,160 --> 00:46:55,800
if you have enough data and your ML is mature enough,

942
00:46:55,800 --> 00:46:59,160
you can start to use your ML to go back into your data set

943
00:46:59,160 --> 00:47:01,360
and start doing auto labeling.

944
00:47:01,360 --> 00:47:05,600
And using the output of your ML with the uncertainty

945
00:47:05,600 --> 00:47:08,160
or the confidence depending on the metrics

946
00:47:08,160 --> 00:47:11,320
and how you factor in those output for your ML,

947
00:47:11,320 --> 00:47:14,600
you can identify pieces or groups of data

948
00:47:14,600 --> 00:47:17,880
that needs further attention for labeling.

949
00:47:17,880 --> 00:47:19,840
And so this is the entire journey

950
00:47:19,840 --> 00:47:23,640
from your very first image that you hand label

951
00:47:23,640 --> 00:47:27,200
to the batch of images that you're programmatically labeling

952
00:47:27,200 --> 00:47:30,680
with some human supervision all the way to the grail

953
00:47:30,680 --> 00:47:33,480
where you have your ML automatically annotating

954
00:47:33,480 --> 00:47:37,920
your data sets with very specialized ML trained for that

955
00:47:37,920 --> 00:47:40,360
that wouldn't run on your aircraft.

956
00:47:40,360 --> 00:47:44,120
And the journey here is that we're trying to get

957
00:47:44,120 --> 00:47:47,760
to that point where ML is usable in that way,

958
00:47:47,760 --> 00:47:50,760
while guaranteeing again the precision and accuracy

959
00:47:50,760 --> 00:47:53,440
that we need for our use case, which is extremely high.

960
00:47:53,440 --> 00:47:55,680
Is it fair to characterize that last stage

961
00:47:55,680 --> 00:47:59,320
as kind of a hybrid of programmatic labeling

962
00:47:59,320 --> 00:48:00,520
and active learning?

963
00:48:00,520 --> 00:48:01,360
Exactly.

964
00:48:01,360 --> 00:48:05,280
And the active learning is a very interesting approach

965
00:48:05,280 --> 00:48:08,240
which has been implemented in various flavors

966
00:48:08,240 --> 00:48:11,880
across the industry, especially in industries

967
00:48:11,880 --> 00:48:14,520
where you have a vast amount of data

968
00:48:14,520 --> 00:48:16,480
or when the data is cheap to acquire

969
00:48:16,480 --> 00:48:18,720
and you have more data on your hand than you actually need

970
00:48:18,720 --> 00:48:20,480
and you want to sort out which one is useful

971
00:48:20,480 --> 00:48:22,040
and which one is not.

972
00:48:22,040 --> 00:48:25,680
In our case, we're not in this data rich environment,

973
00:48:25,680 --> 00:48:29,520
data is hard to get, data is costly to get.

974
00:48:29,520 --> 00:48:31,120
So active learning in our case

975
00:48:31,120 --> 00:48:33,440
means something slightly different.

976
00:48:33,440 --> 00:48:36,160
It's like active labeling in a sense.

977
00:48:36,160 --> 00:48:39,720
That would be a new label that would really fit our purpose.

978
00:48:39,720 --> 00:48:42,280
Active labeling, it's true that during one sequence,

979
00:48:42,280 --> 00:48:44,640
during one lending, if you're capturing images

980
00:48:44,640 --> 00:48:47,600
at, for example, 20 frame per second,

981
00:48:47,600 --> 00:48:51,920
your frame one will not be very different from frame two.

982
00:48:51,920 --> 00:48:55,080
So in that respect, active learning,

983
00:48:55,080 --> 00:48:58,120
if you follow the concept, would say, well,

984
00:48:58,120 --> 00:49:01,920
sub-sample your images because what you want is diversity.

985
00:49:01,920 --> 00:49:04,360
But you also need to guarantee volume in a certain way

986
00:49:04,360 --> 00:49:07,040
and this one is also kind of a challenge for us to get.

987
00:49:07,040 --> 00:49:09,720
So we have to have this balance between labeling

988
00:49:09,720 --> 00:49:11,800
enough to get the critical volume,

989
00:49:11,800 --> 00:49:14,840
but then ensuring diversity by looking at which data

990
00:49:14,840 --> 00:49:17,880
provides the most learning value over it.

991
00:49:17,880 --> 00:49:19,960
So our implementation is going to be slightly different

992
00:49:19,960 --> 00:49:22,440
from other industries, but it's still very relevant

993
00:49:22,440 --> 00:49:23,720
to be able to pick the right data

994
00:49:23,720 --> 00:49:25,880
that you want to have in your data set at the end.

995
00:49:25,880 --> 00:49:28,600
Part of what I heard when you describe

996
00:49:28,600 --> 00:49:32,560
the way you apply programmatic labeling is that

997
00:49:32,560 --> 00:49:36,080
you're applying these heuristics to these images,

998
00:49:36,080 --> 00:49:39,080
you're kind of going back through a second time

999
00:49:39,080 --> 00:49:44,080
or end time in a loop to calibrate or recalibrate.

1000
00:49:46,200 --> 00:49:49,360
But it almost sounded like then you have these labels

1001
00:49:49,360 --> 00:49:54,360
which you have a very high degree of confidence about.

1002
00:49:54,720 --> 00:49:57,160
I guess that's prompting the thought,

1003
00:49:57,160 --> 00:49:59,720
are you then when you're training,

1004
00:49:59,720 --> 00:50:03,200
do you consider that weak supervision in the sense

1005
00:50:03,200 --> 00:50:06,400
that the labels are noisy or are you still worried

1006
00:50:06,400 --> 00:50:08,800
about noise and if so, how do you deal with that?

1007
00:50:08,800 --> 00:50:11,480
So noise is still going to be in there.

1008
00:50:11,480 --> 00:50:14,960
And but to a degree that we have control over.

1009
00:50:14,960 --> 00:50:17,640
So essentially the whole point is to be able

1010
00:50:17,640 --> 00:50:20,600
to quantify the error and understand that

1011
00:50:20,600 --> 00:50:23,720
at the end of labels are going to have some amount of error

1012
00:50:23,720 --> 00:50:27,080
but not beyond a certain threshold that we've specified.

1013
00:50:27,080 --> 00:50:29,560
Now this is extremely hard to do

1014
00:50:29,560 --> 00:50:32,560
because when you're meeting new conditions

1015
00:50:32,560 --> 00:50:35,120
that you haven't encountered in the past,

1016
00:50:35,120 --> 00:50:37,160
you're not sure that your labeling pipeline

1017
00:50:37,160 --> 00:50:38,960
and your heuristics are going to provide

1018
00:50:38,960 --> 00:50:40,920
the same level of quality and consistency

1019
00:50:40,920 --> 00:50:44,280
as known environments, known conditions

1020
00:50:44,280 --> 00:50:46,920
and images coming from this operational domain.

1021
00:50:46,920 --> 00:50:49,560
So to give you a concrete example,

1022
00:50:49,560 --> 00:50:53,600
labeling daytime images for landing

1023
00:50:53,600 --> 00:50:56,120
is something that we understand how to do

1024
00:50:56,120 --> 00:50:57,720
and we understand how to provide

1025
00:50:57,720 --> 00:51:00,920
the sufficient precision and consistency on it.

1026
00:51:00,920 --> 00:51:03,760
But nighttime is an entirely new ball game here.

1027
00:51:03,760 --> 00:51:06,600
So this is an exercise that we've done as well.

1028
00:51:06,600 --> 00:51:09,520
And what we've seen is that our labeling pipeline

1029
00:51:09,520 --> 00:51:12,160
for daytime doesn't work during nighttime.

1030
00:51:12,160 --> 00:51:13,960
You don't see the same features.

1031
00:51:15,040 --> 00:51:17,760
And for example, one of the things is trying to put

1032
00:51:17,760 --> 00:51:21,760
a, trying to identify the corner points of the runway

1033
00:51:21,760 --> 00:51:23,160
is not feasible during nighttime

1034
00:51:23,160 --> 00:51:24,600
because you don't actually see it.

1035
00:51:24,600 --> 00:51:27,200
All you see is the lights around.

1036
00:51:27,200 --> 00:51:30,560
So as soon as it's going to be an iterative process,

1037
00:51:30,560 --> 00:51:32,800
each time we're pushing further,

1038
00:51:32,800 --> 00:51:36,720
the operational domain that our function needs to operate in,

1039
00:51:36,720 --> 00:51:39,600
we're going to encounter those new conditions,

1040
00:51:39,600 --> 00:51:43,200
those new images and we will have to assess

1041
00:51:43,200 --> 00:51:45,400
whether the current labeling pipeline

1042
00:51:45,400 --> 00:51:48,120
can still provide the same quality

1043
00:51:48,120 --> 00:51:51,360
and basically the same bound on the error.

1044
00:51:51,360 --> 00:51:54,640
And most likely, we're going to have to iterate on this.

1045
00:51:54,640 --> 00:51:57,320
And so in that way, I guess the point

1046
00:51:57,320 --> 00:52:00,320
that I'm trying to make here is that it's a full loop.

1047
00:52:00,320 --> 00:52:03,640
You are using your labeling pipeline to provide labels

1048
00:52:03,640 --> 00:52:06,480
with a certain error, a certain consistency.

1049
00:52:06,480 --> 00:52:09,120
But then at the same time, you need to test your labeling

1050
00:52:09,120 --> 00:52:12,000
pipeline to see what kind of error it induces

1051
00:52:12,000 --> 00:52:14,840
in your labels based on those conditions.

1052
00:52:14,840 --> 00:52:16,560
And for that, you need reliable data.

1053
00:52:16,560 --> 00:52:18,800
So it's kind of a chicken and a neck problem.

1054
00:52:18,800 --> 00:52:21,960
You need well-labeled data to test your labeling pipeline

1055
00:52:21,960 --> 00:52:23,520
and you need a good labeling pipeline

1056
00:52:23,520 --> 00:52:26,320
to provide you right labels and right images.

1057
00:52:26,320 --> 00:52:29,640
So that is the challenge that we're facing.

1058
00:52:29,640 --> 00:52:35,280
I'm also wondering about the use of or thoughts

1059
00:52:35,280 --> 00:52:40,480
on the role of synthetic data for your use case.

1060
00:52:40,480 --> 00:52:43,800
In a sense, I guess the thought is coming from,

1061
00:52:43,800 --> 00:52:47,680
I would think there are fairly small number of airports

1062
00:52:47,680 --> 00:52:51,120
that can accommodate an Airbus 350.

1063
00:52:51,120 --> 00:52:53,440
Why don't you send someone around?

1064
00:52:53,440 --> 00:52:55,240
And in fact, there may be survey data

1065
00:52:55,240 --> 00:52:57,160
that knows where the corner points are

1066
00:52:57,160 --> 00:52:59,600
once you can localize the airport.

1067
00:52:59,600 --> 00:53:02,160
Can you then just generate synthetically

1068
00:53:02,160 --> 00:53:03,760
all the training data that you need?

1069
00:53:03,760 --> 00:53:05,520
That is a very good point.

1070
00:53:05,520 --> 00:53:09,120
And I'm going to say you're ties into two things.

1071
00:53:09,120 --> 00:53:13,120
One is we can absolutely replicate all the airport

1072
00:53:13,120 --> 00:53:16,840
across the world because there's database of them.

1073
00:53:16,840 --> 00:53:19,680
So this is a capability that we have.

1074
00:53:19,680 --> 00:53:23,040
And the other point is we, it's going

1075
00:53:23,040 --> 00:53:25,720
to be very challenging to be able to collect real data

1076
00:53:25,720 --> 00:53:28,600
at all the airports in the world that we operate at

1077
00:53:28,600 --> 00:53:30,800
or that we want to operate at.

1078
00:53:30,800 --> 00:53:32,960
So this is where it really is helpful

1079
00:53:32,960 --> 00:53:36,720
because you can collect data on a sub portion

1080
00:53:36,720 --> 00:53:38,320
of those airport.

1081
00:53:38,320 --> 00:53:41,440
You can generate the synthetic data for all of them

1082
00:53:41,440 --> 00:53:43,600
and using those two data sets and verifying

1083
00:53:43,600 --> 00:53:46,480
that your synthetic data is actually representative

1084
00:53:46,480 --> 00:53:50,040
of your real data, you can create a very extensive data

1085
00:53:50,040 --> 00:53:54,360
set to train the neural network, but also to test it.

1086
00:53:54,360 --> 00:53:56,000
And this is the point that I want to make

1087
00:53:56,000 --> 00:53:59,240
is the difficulty in the challenges

1088
00:53:59,240 --> 00:54:04,160
in improving the safety and the reliability of the algorithm

1089
00:54:04,160 --> 00:54:08,280
requires a large data set that needs to be shown

1090
00:54:08,280 --> 00:54:10,400
as representative of your environment

1091
00:54:10,400 --> 00:54:13,760
and dense enough to be able to give you

1092
00:54:13,760 --> 00:54:15,560
the statistical proof at the end.

1093
00:54:15,560 --> 00:54:18,800
And this is extremely hard to do with real data

1094
00:54:18,800 --> 00:54:20,760
because of the challenge of collecting it.

1095
00:54:20,760 --> 00:54:23,800
And this is where synthetic data can be very useful

1096
00:54:23,800 --> 00:54:28,800
because from a sparse population of samples,

1097
00:54:30,160 --> 00:54:32,880
you can recreate that population with synthetic data,

1098
00:54:32,880 --> 00:54:34,920
make it a very dense population

1099
00:54:34,920 --> 00:54:37,800
and make your case based on that population

1100
00:54:37,800 --> 00:54:40,680
with a mix of real and synthetic data.

1101
00:54:40,680 --> 00:54:44,080
So this is one of the avenue that self-driving cars

1102
00:54:44,080 --> 00:54:47,080
have taken is, for example, for one mile

1103
00:54:47,080 --> 00:54:49,880
that a typical autonomous car is driving,

1104
00:54:49,880 --> 00:54:53,920
they're probably generating a 1,000 mile of simulated driving

1105
00:54:53,920 --> 00:54:56,640
and they're testing their algorithm on all of that.

1106
00:54:56,640 --> 00:54:59,560
So that gives you a 1,000 to 1,000 leverage

1107
00:55:00,560 --> 00:55:03,680
and that enables you to have the statistical

1108
00:55:04,840 --> 00:55:09,200
meaningfulness that you need to start to trust your system.

1109
00:55:09,200 --> 00:55:12,120
And so in our case, we are looking at the same approach

1110
00:55:12,120 --> 00:55:15,880
of leveraging synthetic data not only for the training

1111
00:55:15,880 --> 00:55:17,600
but also for the testing.

1112
00:55:17,600 --> 00:55:21,480
Are there other techniques or approaches or ways

1113
00:55:21,480 --> 00:55:24,360
that you see your pipeline evolving

1114
00:55:24,360 --> 00:55:25,680
that we haven't touched on?

1115
00:55:25,680 --> 00:55:29,400
So one of the other alternative to purity synthetic data

1116
00:55:29,400 --> 00:55:32,080
and real data is data augmentation.

1117
00:55:32,920 --> 00:55:36,160
And that is a very nice, and I'm gonna say,

1118
00:55:36,160 --> 00:55:38,640
cheap way of reusing your real data

1119
00:55:38,640 --> 00:55:41,600
and creating new data that has learning values.

1120
00:55:41,600 --> 00:55:43,760
So you've got daytime images,

1121
00:55:43,760 --> 00:55:45,480
make them look like nighttime images

1122
00:55:45,480 --> 00:55:46,840
and put them through the pipeline.

1123
00:55:46,840 --> 00:55:47,680
Exactly.

1124
00:55:47,680 --> 00:55:50,920
And one of the challenges as well that might not necessarily

1125
00:55:50,920 --> 00:55:53,920
come to mind is you're using one type of camera

1126
00:55:53,920 --> 00:55:55,320
when you're recording the imagery.

1127
00:55:55,320 --> 00:55:57,640
It might not be the same that you're using at inference

1128
00:55:57,640 --> 00:56:01,080
and actually as the generation of aircraft goes on

1129
00:56:01,080 --> 00:56:03,720
and your new cameras comes in,

1130
00:56:03,720 --> 00:56:05,120
it might be a completely different camera

1131
00:56:05,120 --> 00:56:07,520
that are gonna be using 10 years or 15 years from now

1132
00:56:07,520 --> 00:56:09,840
but you still wanna be able to use the data

1133
00:56:09,840 --> 00:56:12,800
that you've collected because of all the energy

1134
00:56:12,800 --> 00:56:14,840
and the resources that you've put into it.

1135
00:56:14,840 --> 00:56:17,280
And so being able to reuse that real data

1136
00:56:17,280 --> 00:56:19,680
post-processing it so that the noise, for example,

1137
00:56:19,680 --> 00:56:22,600
looks different and matches your new camera.

1138
00:56:22,600 --> 00:56:24,760
You can induce chromatic aberration,

1139
00:56:24,760 --> 00:56:27,400
so change and shifts in RGB.

1140
00:56:27,400 --> 00:56:29,240
And you can also warp those images

1141
00:56:29,240 --> 00:56:32,680
so that they look different in terms of perspective.

1142
00:56:32,680 --> 00:56:36,760
There is some studies to put rain on top of good

1143
00:56:36,760 --> 00:56:39,080
and clear condition imagery.

1144
00:56:39,080 --> 00:56:41,000
And then you can put some fog, et cetera.

1145
00:56:41,000 --> 00:56:43,080
Now the challenge at some point is

1146
00:56:43,080 --> 00:56:45,640
you can do all those fancy things on top

1147
00:56:45,640 --> 00:56:47,520
but you always need to validate

1148
00:56:47,520 --> 00:56:50,200
that they are representative of the real data.

1149
00:56:50,200 --> 00:56:53,960
And this is where it, you cannot just start

1150
00:56:53,960 --> 00:56:55,840
with synthetic and stick in synthetic

1151
00:56:55,840 --> 00:56:58,200
and then deploy it in the real world.

1152
00:56:58,200 --> 00:57:01,800
This validation is the thing that is somewhat taxing

1153
00:57:01,800 --> 00:57:03,320
because you need all that real data

1154
00:57:03,320 --> 00:57:06,000
to prove that you're still in the real world.

1155
00:57:06,000 --> 00:57:09,080
Well, Cedric, lots of exciting stuff there, sounds like

1156
00:57:09,080 --> 00:57:12,200
you've got enough to keep you busy for quite a while.

1157
00:57:12,200 --> 00:57:13,600
We are indeed.

1158
00:57:13,600 --> 00:57:18,040
And I must add, this is a very exciting time for us

1159
00:57:18,040 --> 00:57:22,960
because in contrast with the car industry,

1160
00:57:22,960 --> 00:57:24,720
we're really at the beginning of this.

1161
00:57:24,720 --> 00:57:29,400
And this is a brand new revolution of autonomy in aviation.

1162
00:57:29,400 --> 00:57:32,960
And so we are building the foundation block

1163
00:57:32,960 --> 00:57:35,480
of how to use ML and how to use

1164
00:57:35,480 --> 00:57:38,440
artificial intelligence into not only commercial aircraft

1165
00:57:38,440 --> 00:57:42,040
but a wide range of aviation products.

1166
00:57:42,040 --> 00:57:45,840
And so the other mission that for me is really exciting

1167
00:57:45,840 --> 00:57:50,760
at A Cube in particular is we're drawing all those engineers

1168
00:57:50,760 --> 00:57:54,840
from other fields such as Google, Facebook,

1169
00:57:54,840 --> 00:57:58,680
the self-driving car industry that have a big knowledge

1170
00:57:58,680 --> 00:58:01,520
and a significant amount of experience in those industries

1171
00:58:01,520 --> 00:58:03,600
and we're pulling them into the aviation industry

1172
00:58:03,600 --> 00:58:05,400
and we're saying, OK, so you have

1173
00:58:05,400 --> 00:58:09,000
those 10-year cycle to produce a new aircraft

1174
00:58:09,000 --> 00:58:12,560
but we want to use all those new techniques that Silicon Valley

1175
00:58:12,560 --> 00:58:16,640
has created to be able to do, let's say, one new release

1176
00:58:16,640 --> 00:58:18,320
every three weeks.

1177
00:58:18,320 --> 00:58:20,440
And we're going to be able to push that to an aircraft

1178
00:58:20,440 --> 00:58:22,280
and test those things.

1179
00:58:22,280 --> 00:58:25,440
And so just the pipeline and the processes

1180
00:58:25,440 --> 00:58:28,880
are going to be revolutioning the aviation industry.

1181
00:58:28,880 --> 00:58:30,840
It's basically a brand new world for us

1182
00:58:30,840 --> 00:58:33,280
so it's quite exciting to be in this year.

1183
00:58:33,280 --> 00:58:37,320
And I'm going to say as well, just as a last note,

1184
00:58:37,320 --> 00:58:40,520
A Cube and Wayfinder is actively recruiting.

1185
00:58:40,520 --> 00:58:43,800
So if you're interested in facing all those challenges

1186
00:58:43,800 --> 00:58:45,520
and working with us, it will be a pleasure

1187
00:58:45,520 --> 00:58:47,120
to have your application.

1188
00:58:47,120 --> 00:58:47,880
Where should they go?

1189
00:58:47,880 --> 00:58:49,920
Well, make sure to include it in the show notes page.

1190
00:58:49,920 --> 00:58:52,680
Yes, so A Cube as its own websites

1191
00:58:52,680 --> 00:58:56,240
and if you actually type Wayfinder.error,

1192
00:58:56,240 --> 00:59:00,440
it will redirect you directly to our page with our blogs

1193
00:59:00,440 --> 00:59:03,960
and the join the team section.

1194
00:59:03,960 --> 00:59:05,240
Awesome, awesome.

1195
00:59:05,240 --> 00:59:07,400
Well, Cedric, thanks so much for joining

1196
00:59:07,400 --> 00:59:10,920
and sharing a bit about what you're up to, very cool stuff.

1197
00:59:10,920 --> 00:59:39,440
Thank you very much for inviting me.

