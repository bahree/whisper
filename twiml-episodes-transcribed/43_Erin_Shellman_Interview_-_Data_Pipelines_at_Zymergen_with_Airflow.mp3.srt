1
00:00:00,000 --> 00:00:15,840
Hello and welcome to another episode of Twimmel Talk, the podcast where I interview

2
00:00:15,840 --> 00:00:21,200
interesting people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,200 --> 00:00:23,760
I'm your host Sam Charrington.

4
00:00:23,760 --> 00:00:29,600
This is the third and final show in our series of podcasts from the recent Wrangle Conference.

5
00:00:29,600 --> 00:00:34,080
As you might know, a few weeks ago I was in San Francisco for Wrangle, which is a great

6
00:00:34,080 --> 00:00:38,480
little conference brought to you by our friends over at Cloud Era.

7
00:00:38,480 --> 00:00:43,280
This is the second time I've attended a Wrangle, and each year it brings an interesting and

8
00:00:43,280 --> 00:00:48,640
diverse community of data scientists to an intimate and informal setting for great talks

9
00:00:48,640 --> 00:00:54,520
on real data science issues and projects, not to mention cowboy hats and barbecue.

10
00:00:54,520 --> 00:00:59,960
If you haven't yet caught the first two episodes in our Wrangle series, Twimmel Talk No. 39

11
00:00:59,960 --> 00:01:05,600
with Drew Conway and Twimmel Talk No. 40 with Sheriff Rao, you'll want to be sure to check

12
00:01:05,600 --> 00:01:06,600
those out.

13
00:01:06,600 --> 00:01:10,640
They're both great interviews and the intro to the first show in the series includes

14
00:01:10,640 --> 00:01:15,920
important announcements about the series as well as our latest ticket giveaway, our online

15
00:01:15,920 --> 00:01:19,960
research paper discussion group, and my email newsletter.

16
00:01:19,960 --> 00:01:24,600
To show you're listening to now features my interview with Aaron Schelman. Aaron is a

17
00:01:24,600 --> 00:01:30,480
statistician and data science manager with Zymergen, a company using robots and machine

18
00:01:30,480 --> 00:01:33,400
learning to engineer better microbes.

19
00:01:33,400 --> 00:01:38,200
If you're wondering what exactly that means and involves, I was too, and we talk about

20
00:01:38,200 --> 00:01:40,000
it in the interview.

21
00:01:40,000 --> 00:01:45,920
Our conversation focuses on Zymergen's use of a patchy airflow, an open source data management

22
00:01:45,920 --> 00:01:49,440
platform originating at Airbnb.

23
00:01:49,440 --> 00:01:54,920
Aaron and her team uses airflow to create reliable, repeatable data pipelines for their machine

24
00:01:54,920 --> 00:01:59,200
learning applications, and we explore all that in the interview.

25
00:01:59,200 --> 00:02:04,080
A quick note before we dive in, as is the case with my other field recordings, there's

26
00:02:04,080 --> 00:02:08,560
a bit of unavoidable background noise in this interview, sorry about that.

27
00:02:08,560 --> 00:02:37,600
And now on to the show.

28
00:02:37,600 --> 00:02:40,760
Now we start by having you tell us a little bit about your background.

29
00:02:40,760 --> 00:02:41,760
Sure.

30
00:02:41,760 --> 00:02:47,520
So my background sort of at the intersection of computer science, statistics, and biology.

31
00:02:47,520 --> 00:02:49,800
So I went to graduate school at the University of Michigan.

32
00:02:49,800 --> 00:02:54,480
I did my masters in biostatistics, and then my PhD in bioinformatics.

33
00:02:54,480 --> 00:03:01,080
So always kind of working at the intersection of data and biology, and when I graduated

34
00:03:01,080 --> 00:03:05,560
sort of maybe counterintuitively, I came out to the West Coast, I live in Seattle, and

35
00:03:05,560 --> 00:03:08,280
I worked at Nordstrom in Nordstrom technology.

36
00:03:08,280 --> 00:03:09,280
Interesting.

37
00:03:09,280 --> 00:03:10,280
Yeah.

38
00:03:10,280 --> 00:03:13,400
And I was on a really cool team called the Data Lab there and built product recommendations

39
00:03:13,400 --> 00:03:14,400
for Nordstrom.com.

40
00:03:14,400 --> 00:03:15,400
Okay.

41
00:03:15,400 --> 00:03:18,360
And then did a stint at AWS, and now I'm at Symargin.

42
00:03:18,360 --> 00:03:19,360
Okay.

43
00:03:19,360 --> 00:03:20,360
Nice.

44
00:03:20,360 --> 00:03:22,000
And what specifically do you do at Symargin?

45
00:03:22,000 --> 00:03:23,000
Yeah.

46
00:03:23,000 --> 00:03:27,840
So I was initially, I was the first data scientist at the company, and I was a data scientist

47
00:03:27,840 --> 00:03:32,680
there for the better part of nearly two years, and then recently I've transitioned into

48
00:03:32,680 --> 00:03:34,560
managing the data science group there.

49
00:03:34,560 --> 00:03:38,400
And we're now eight people including myself, so a lot of growth since I started.

50
00:03:38,400 --> 00:03:39,400
Okay.

51
00:03:39,400 --> 00:03:40,400
So yeah.

52
00:03:40,400 --> 00:03:45,880
So a friend of mine and a former, a previous podcast guest, Josh Blum, has said that the worst

53
00:03:45,880 --> 00:03:49,280
job in the world is to be a company's first data scientist.

54
00:03:49,280 --> 00:03:50,800
Do you agree with me?

55
00:03:50,800 --> 00:03:53,840
That is a, there's a lot of truth to that.

56
00:03:53,840 --> 00:03:56,720
It really depends, yeah, it depends on what you like.

57
00:03:56,720 --> 00:04:02,400
So what I like about, so actually maybe surprisingly all of the jobs that I've had, I've been

58
00:04:02,400 --> 00:04:08,120
the first onto that team, and that wasn't really on purpose, but what I like about it is

59
00:04:08,120 --> 00:04:13,640
that you really have the ability to kind of structure what the goals and what the mission

60
00:04:13,640 --> 00:04:16,640
is, who you hire and how you build out that team.

61
00:04:16,640 --> 00:04:22,160
And I really enjoy that part of the job, sort of the higher level, maybe not so data-centric

62
00:04:22,160 --> 00:04:23,160
parts of the job.

63
00:04:23,160 --> 00:04:24,160
Okay.

64
00:04:24,160 --> 00:04:26,160
And you definitely have that kind of stuff more available to you when you're the only

65
00:04:26,160 --> 00:04:28,160
person on the team.

66
00:04:28,160 --> 00:04:32,640
It hasn't been like building out a team from having that experience as being the very

67
00:04:32,640 --> 00:04:33,640
first.

68
00:04:33,640 --> 00:04:37,880
Does it change your perspective on team composition and how you build it out?

69
00:04:37,880 --> 00:04:41,960
Yeah, it definitely changes your perspective because when you're the only person you're

70
00:04:41,960 --> 00:04:48,240
quite resource-constrained, and so the hiring matters in some sense more than when you

71
00:04:48,240 --> 00:04:54,280
have quite a bit more staff because every, you know, you double to two people that's

72
00:04:54,280 --> 00:04:58,120
still quite, not very many people, and so it's really important that you get somebody

73
00:04:58,120 --> 00:05:02,080
who has skills that complement your own or somebody who can teach you a lot of things

74
00:05:02,080 --> 00:05:04,520
that you don't know to make everybody more productive.

75
00:05:04,520 --> 00:05:09,480
So it's definitely a different experience than being in a big group with lots of people,

76
00:05:09,480 --> 00:05:10,680
but I actually, I think I like it more.

77
00:05:10,680 --> 00:05:11,680
I prefer it.

78
00:05:11,680 --> 00:05:12,680
Okay.

79
00:05:12,680 --> 00:05:13,680
Awesome.

80
00:05:13,680 --> 00:05:14,680
Awesome.

81
00:05:14,680 --> 00:05:17,920
Now, Zymergen, I'm betting is a company that not a lot of people in our audience know

82
00:05:17,920 --> 00:05:19,600
about what does the company do?

83
00:05:19,600 --> 00:05:20,600
Yeah.

84
00:05:20,600 --> 00:05:24,840
We're a little bit different than, you know, the Airbnb's and the Facebook's and all

85
00:05:24,840 --> 00:05:29,200
of those type of those companies, though we use a lot of Airbnb's technology, so kind

86
00:05:29,200 --> 00:05:33,360
of like Airbnb for microbes, not really.

87
00:05:33,360 --> 00:05:39,080
But yeah, so at Zymergen, what we're doing is we partner with companies who use industrial

88
00:05:39,080 --> 00:05:45,920
fermentation to make materials and molecules, and so what we do is we operate, we optimize

89
00:05:45,920 --> 00:05:52,800
strains, microbial strains, to be more efficient or more effective at producing molecules

90
00:05:52,800 --> 00:05:55,680
of interest to our customers through fermentation.

91
00:05:55,680 --> 00:06:00,680
So often these are companies who are already using fermentation at scale to produce molecules.

92
00:06:00,680 --> 00:06:01,680
So it turns out-

93
00:06:01,680 --> 00:06:02,680
I'm thinking beer.

94
00:06:02,680 --> 00:06:03,680
Yeah, exactly.

95
00:06:03,680 --> 00:06:04,680
Is it beer?

96
00:06:04,680 --> 00:06:05,680
Yeah.

97
00:06:05,680 --> 00:06:06,680
Another use case is zero.

98
00:06:06,680 --> 00:06:07,680
Yeah.

99
00:06:07,680 --> 00:06:11,680
So, you know, we, the common application, right, of fermentation is to make alcohols,

100
00:06:11,680 --> 00:06:16,440
alcoholic beverages, but it turns out that you can use that process to create lots of

101
00:06:16,440 --> 00:06:20,800
different types of molecules, and you can use that to make molecules that can be precursors

102
00:06:20,800 --> 00:06:24,400
for pretty complicated materials as well, and so that's what we do.

103
00:06:24,400 --> 00:06:28,200
We kind of do the same process, but we're making all kinds of different types of molecules

104
00:06:28,200 --> 00:06:29,520
for different applications.

105
00:06:29,520 --> 00:06:31,720
What are some examples of those applications?

106
00:06:31,720 --> 00:06:36,200
So examples of applications in general, not specific to Zymergen, are, well, for example,

107
00:06:36,200 --> 00:06:43,160
insulin is sort of a classical example of using fermentation in health sciences to produce

108
00:06:43,160 --> 00:06:44,160
insulin.

109
00:06:44,160 --> 00:06:49,320
So that was a huge revolution in terms of being able to create it because it was a very

110
00:06:49,320 --> 00:06:53,640
expensive and kind of grew some way that we used to do it in the past, which is largely

111
00:06:53,640 --> 00:06:56,760
through extracting it from pigs, which is not pretty.

112
00:06:56,760 --> 00:07:01,300
Obviously, if you feel it's a lot better if you can, you know, use microbes and do it in

113
00:07:01,300 --> 00:07:05,280
giant fermenters, and you can produce a lot more at lower costs, so it's kind of the

114
00:07:05,280 --> 00:07:06,480
same thing, yeah.

115
00:07:06,480 --> 00:07:12,000
And so is it a direct byproduct of fermentation, or is it, is there a byproduct that's used

116
00:07:12,000 --> 00:07:13,000
in its creation?

117
00:07:13,000 --> 00:07:18,440
Yeah, it kind of depends on the microbe and the molecule that you're producing, but

118
00:07:18,440 --> 00:07:24,040
often what we're doing is sort of augmenting or kind of ramping up normal metabolic processes

119
00:07:24,040 --> 00:07:29,880
in the cell, so these microbes will ingest, you know, sugars, metabolize things like that

120
00:07:29,880 --> 00:07:35,600
to create these molecules, sort of as sometimes their waste products, it really depends, and

121
00:07:35,600 --> 00:07:39,960
they excrete those into the surrounding fluid inside the tank, and then we harvest that

122
00:07:39,960 --> 00:07:40,960
or we extract that.

123
00:07:40,960 --> 00:07:41,960
Oh, wow.

124
00:07:41,960 --> 00:07:43,720
Yeah, to get those molecules.

125
00:07:43,720 --> 00:07:44,720
Wow.

126
00:07:44,720 --> 00:07:46,200
So what was your talk about?

127
00:07:46,200 --> 00:07:50,840
Yeah, so I was talking about some of the sort of the challenges that we face.

128
00:07:50,840 --> 00:07:55,160
So I was talking a little bit about our mission, actually, of the Data Science Teams mission,

129
00:07:55,160 --> 00:07:59,440
and our goal is to use our testing platform.

130
00:07:59,440 --> 00:08:04,440
So the way that we do what we do as I imagine stepping back for a second is that we rely

131
00:08:04,440 --> 00:08:10,880
on robotic automation, sort of combined with machine learning to build this test platform

132
00:08:10,880 --> 00:08:15,720
that allows us to simultaneously measure the performance of lots of different strains

133
00:08:15,720 --> 00:08:16,720
in parallel.

134
00:08:16,720 --> 00:08:17,720
Okay.

135
00:08:17,720 --> 00:08:21,320
And we use our goal on the Data Science team is to use all of that data that we're generating

136
00:08:21,320 --> 00:08:26,840
through this high throughput screening process, use all of that to then make machine learning

137
00:08:26,840 --> 00:08:31,960
models or make predictive models to help us make better decisions about the experiments,

138
00:08:31,960 --> 00:08:33,600
the strains that we design in the first place.

139
00:08:33,600 --> 00:08:37,840
So basically to help the scientists design better strains so that we don't have to spend

140
00:08:37,840 --> 00:08:42,440
as much time experimenting if we could get to the solution or get to the answer faster,

141
00:08:42,440 --> 00:08:43,440
that's really our goal.

142
00:08:43,440 --> 00:08:48,840
That's an ambitious goal, it's not easy to do, and so part of what I was talking about

143
00:08:48,840 --> 00:08:52,280
was sort of the things that make it hard to accomplish that.

144
00:08:52,280 --> 00:08:57,120
So what are sort of the practical data issues that we encounter and how we're solving those

145
00:08:57,120 --> 00:09:03,440
so that we get really clean in analysis ready or modeling ready data for those complicated

146
00:09:03,440 --> 00:09:04,440
models.

147
00:09:04,440 --> 00:09:05,440
Okay.

148
00:09:05,440 --> 00:09:10,400
And so what are some specific examples of the data sources and data types that feed your

149
00:09:10,400 --> 00:09:11,400
models?

150
00:09:11,400 --> 00:09:18,000
Yeah, so by and large, a lot of the data that we're consuming is really kind of measurements

151
00:09:18,000 --> 00:09:19,960
that represent concentrations.

152
00:09:19,960 --> 00:09:27,840
So we've got these microbes, they're metabolizing things and they're excreting these compounds

153
00:09:27,840 --> 00:09:32,040
or these molecules into the solution around them and then we measure the concentration

154
00:09:32,040 --> 00:09:37,080
of that so that we can tell whether the microbe has improved over its predecessor and then

155
00:09:37,080 --> 00:09:40,720
move that into make a decision based on that essentially.

156
00:09:40,720 --> 00:09:44,320
And so for the most part, the data that we're working with is some measurement, is some

157
00:09:44,320 --> 00:09:45,320
measure of concentration.

158
00:09:45,320 --> 00:09:46,320
Got it.

159
00:09:46,320 --> 00:09:49,720
And what's the scale that this is happening at?

160
00:09:49,720 --> 00:09:56,320
Like is this concentrations in vats of things or like microarrays or somewhere in between?

161
00:09:56,320 --> 00:09:57,960
Yeah, that's a really great question.

162
00:09:57,960 --> 00:10:00,720
So it's kind of all of those things.

163
00:10:00,720 --> 00:10:07,120
So what we do practically in our testing platform is we kind of do it more, not quite as dense

164
00:10:07,120 --> 00:10:11,160
as a microarray, but typically it's something like 96-well plates.

165
00:10:11,160 --> 00:10:17,400
So we have these kind of plates that have 96-wells, each of those wells contains fluid, contains

166
00:10:17,400 --> 00:10:20,880
the microbe and sort of the experimental input.

167
00:10:20,880 --> 00:10:25,720
And that's the level that initially when we're doing our initial screens that we're experimenting

168
00:10:25,720 --> 00:10:26,720
at.

169
00:10:26,720 --> 00:10:32,840
Once a strain, for example, demonstrates improvement compared to its predecessor, it'll go into

170
00:10:32,840 --> 00:10:37,080
another round of that testing, we basically want to validate or replicate that performance

171
00:10:37,080 --> 00:10:38,080
again.

172
00:10:38,080 --> 00:10:42,280
Once it's done that, we actually validate those strains in fermenters.

173
00:10:42,280 --> 00:10:47,120
And so it's kind of a challenge to, you know, the size of a fermentation tank is much

174
00:10:47,120 --> 00:10:50,120
larger than that of a tiny well on a plate.

175
00:10:50,120 --> 00:10:54,560
And so we always want to validate those strains before we deliver them to a customer, for

176
00:10:54,560 --> 00:10:59,800
example, to make sure that the performance and the plate actually represents the performance

177
00:10:59,800 --> 00:11:03,120
that we expect in the fermentation tanks.

178
00:11:03,120 --> 00:11:08,160
And so we do both at Xymrgin, and then we also like to partner with people and run them

179
00:11:08,160 --> 00:11:10,520
at scale in their tanks, too, when possible.

180
00:11:10,520 --> 00:11:11,520
Okay.

181
00:11:11,520 --> 00:11:12,520
Interesting.

182
00:11:12,520 --> 00:11:16,880
And so you started your talk, talking a little bit about kind of the context and your

183
00:11:16,880 --> 00:11:20,360
mission, and then what?

184
00:11:20,360 --> 00:11:25,680
Oh, and then, yeah, and so I was talking a little about some of the challenges we face

185
00:11:25,680 --> 00:11:31,880
with our data, some kind of practical challenges, and how we're using Airflow to build a pipeline

186
00:11:31,880 --> 00:11:33,560
that addresses some of those challenges.

187
00:11:33,560 --> 00:11:34,560
Okay.

188
00:11:34,560 --> 00:11:35,560
What's Airflow?

189
00:11:35,560 --> 00:11:39,160
So Airflow is, it's a Apache incubating project.

190
00:11:39,160 --> 00:11:45,400
It's a Python module, basically, that allows you to construct data processing workflows,

191
00:11:45,400 --> 00:11:50,800
and you're basically constructed DAG of that workflow, and allows you to do things like

192
00:11:50,800 --> 00:11:55,920
scheduling, monitor the progress of those jobs, and even a little bit of reporting.

193
00:11:55,920 --> 00:11:56,920
Yeah.

194
00:11:56,920 --> 00:12:00,720
So it basically helps us orchestrate all of our sort of complicated ETL steps.

195
00:12:00,720 --> 00:12:01,720
Okay.

196
00:12:01,720 --> 00:12:03,520
Where are you eating the data from?

197
00:12:03,520 --> 00:12:05,280
Where does it tend to live?

198
00:12:05,280 --> 00:12:13,240
Yeah, so, and mostly, so we have what's called a limbs, it's sort of a biology, that's

199
00:12:13,240 --> 00:12:14,240
right.

200
00:12:14,240 --> 00:12:15,240
Okay.

201
00:12:15,240 --> 00:12:19,040
I've never met anyone who was, like, not a biologist who knew what that was.

202
00:12:19,040 --> 00:12:20,560
Yes, that's exactly what it is.

203
00:12:20,560 --> 00:12:24,720
So we have a, we have a limbs, and we have a corresponding front end that the scientists

204
00:12:24,720 --> 00:12:29,360
can upload and sort of download data from, and then that gets persisted to a sort of a single

205
00:12:29,360 --> 00:12:33,160
source of truth, like a data warehouse, and that's, for the most part, with the data scientists

206
00:12:33,160 --> 00:12:34,160
access the data from.

207
00:12:34,160 --> 00:12:35,160
From a data warehouse?

208
00:12:35,160 --> 00:12:36,160
Okay.

209
00:12:36,160 --> 00:12:39,520
So you use Airflow, how long have you been using that?

210
00:12:39,520 --> 00:12:42,400
We've been using it, I guess, almost about a year.

211
00:12:42,400 --> 00:12:43,400
Okay.

212
00:12:43,400 --> 00:12:46,000
And that's, you mentioned earlier, you use AirBnB stuff.

213
00:12:46,000 --> 00:12:47,600
Airflow is an AirBnB product?

214
00:12:47,600 --> 00:12:48,600
Yeah, it was a project.

215
00:12:48,600 --> 00:12:52,500
Yeah, exactly, it was an AirBnB product that I think they opened source, and then it was

216
00:12:52,500 --> 00:12:57,360
picked up by Apache, and now it's kind of an incubating project, which, yeah.

217
00:12:57,360 --> 00:13:04,120
And how does it compare to, I'm trying to remember the name of the product that complements,

218
00:13:04,120 --> 00:13:09,280
like Google Cloud, has their data flow, and there's an open source, it's also Apache,

219
00:13:09,280 --> 00:13:10,280
it's not.

220
00:13:10,280 --> 00:13:13,000
It's like oozee or, yeah, no.

221
00:13:13,000 --> 00:13:14,320
It's comparable to that.

222
00:13:14,320 --> 00:13:15,320
It's comparable to oozee?

223
00:13:15,320 --> 00:13:16,320
Yeah.

224
00:13:16,320 --> 00:13:17,320
Okay.

225
00:13:17,320 --> 00:13:22,560
And it's agnostic to sort of, I think oozee is sort of a part of the Hadoop ecosystem.

226
00:13:22,560 --> 00:13:23,560
Airflow is not.

227
00:13:23,560 --> 00:13:27,600
So it's pretty generic in that sense, so you can really use it, it's pretty powerful

228
00:13:27,600 --> 00:13:28,600
in that sense.

229
00:13:28,600 --> 00:13:32,960
So it doesn't have any opinions, really, about the platform when where your data come

230
00:13:32,960 --> 00:13:33,960
from.

231
00:13:33,960 --> 00:13:34,960
Okay.

232
00:13:34,960 --> 00:13:43,160
And so what are the implications on the way you kind of craft and deploy the analytics that

233
00:13:43,160 --> 00:13:51,320
sit on top of the underlying, you know, the data, kind of the data engineering pieces?

234
00:13:51,320 --> 00:13:55,800
Like does airflow, does the weight, any of the semantics of airflow have direct impact

235
00:13:55,800 --> 00:14:00,800
on the way you view the analytics, or is it, you know, kind of separate concerns?

236
00:14:00,800 --> 00:14:01,800
I don't know.

237
00:14:01,800 --> 00:14:05,880
I think maybe they're largely separate concerns, although I guess one of some one of the sort

238
00:14:05,880 --> 00:14:11,960
of use cases that I described was, you know, we do a lot of experimentation as I'm

239
00:14:11,960 --> 00:14:14,600
origin, lots of different types of experiments.

240
00:14:14,600 --> 00:14:19,040
And our scientists use lots of different types of tools to work with data.

241
00:14:19,040 --> 00:14:23,080
And the result of that is sometimes the data doesn't make it into our limbs, so it doesn't

242
00:14:23,080 --> 00:14:24,840
make it into the warehouse.

243
00:14:24,840 --> 00:14:28,640
And one way that we've addressed that is that airflow has all these nice sort of hooks

244
00:14:28,640 --> 00:14:32,640
or operators into third party things like Dropbox.

245
00:14:32,640 --> 00:14:37,800
And so one thing that we've had success with is to be able to work with the scientists

246
00:14:37,800 --> 00:14:43,400
and get them to make some standards around where they put their data in Dropbox, and then

247
00:14:43,400 --> 00:14:48,240
we make really lightweight ingestion pipelines to grab that data and ingest it into our limbs

248
00:14:48,240 --> 00:14:49,240
for them.

249
00:14:49,240 --> 00:14:53,840
And then we're using also a NARB&B product called SuperSet, which is sort of a dashboarding

250
00:14:53,840 --> 00:14:54,840
tool.

251
00:14:54,840 --> 00:14:59,040
So we've now hooked that up so that we can ingest data from Dropbox, and then we can

252
00:14:59,040 --> 00:15:03,160
produce dashboards for the scientists to actually consume their own data that way.

253
00:15:03,160 --> 00:15:07,920
And that's been kind of a success story, making really lightweight stuff, doesn't take

254
00:15:07,920 --> 00:15:12,760
very long to make it all, and can surface the results right there pretty quickly.

255
00:15:12,760 --> 00:15:13,760
Okay.

256
00:15:13,760 --> 00:15:18,000
And so what were some of the insights that you were sharing about using airflow?

257
00:15:18,000 --> 00:15:23,200
Yeah, so I was sharing, I was kind of stepping through a couple of use cases that we, well,

258
00:15:23,200 --> 00:15:28,880
I was describing some of the our limitate or the challenges that we face with our data.

259
00:15:28,880 --> 00:15:33,520
And then sort of the challenges we had when we were working on our own sort of homegrown

260
00:15:33,520 --> 00:15:40,200
ETL solution or platform, and why we eventually sort of abandoned that and adopted airflow.

261
00:15:40,200 --> 00:15:43,840
And so I imagine that a lot of people start there.

262
00:15:43,840 --> 00:15:44,840
Yeah.

263
00:15:44,840 --> 00:15:45,840
Like what are some of those challenges?

264
00:15:45,840 --> 00:15:46,840
Yeah.

265
00:15:46,840 --> 00:15:53,080
So one of the, I think more difficult challenges was that, I mentioned that largely the,

266
00:15:53,080 --> 00:15:56,560
a lot of the data that we're working with is concentrations of things, so we're measuring

267
00:15:56,560 --> 00:16:01,000
how much of something there is in a certain volume of solution.

268
00:16:01,000 --> 00:16:05,280
It turns out measuring concentration of something is not that straightforward, so there are

269
00:16:05,280 --> 00:16:09,680
a lot of different ways that you can measure the concentration of a solution, of something

270
00:16:09,680 --> 00:16:11,480
in a solution.

271
00:16:11,480 --> 00:16:16,480
And depending on the group and whether, like who they're working with and sort of the

272
00:16:16,480 --> 00:16:20,960
way that they choose to measure that, that has implications for the data that we can

273
00:16:20,960 --> 00:16:21,960
expect.

274
00:16:21,960 --> 00:16:25,520
But we need to basically process everything the same way, regardless of the sort of the

275
00:16:25,520 --> 00:16:28,640
format or the type of experiment that they used.

276
00:16:28,640 --> 00:16:33,040
And so that was challenging to kind of articulate ourselves, there's just a lot of overhead

277
00:16:33,040 --> 00:16:36,560
and there's sort of a lot of logic that we would have to encode to do that.

278
00:16:36,560 --> 00:16:42,080
Another challenge was describing this sort of complex dependencies in between our processing

279
00:16:42,080 --> 00:16:43,080
steps.

280
00:16:43,080 --> 00:16:46,080
So, you know, I need this to happen and then that's going to kick off another job that

281
00:16:46,080 --> 00:16:50,360
does this and that's going to kick off something else, but orchestrating sort of that communication

282
00:16:50,360 --> 00:16:54,800
and writing all the logic to, for what do I do if the first thing fails or what if I,

283
00:16:54,800 --> 00:16:59,240
what do I do if the second thing fails and doing all of that ourselves is challenging.

284
00:16:59,240 --> 00:17:02,760
And we have all the, we have data coming in at different velocities and that's also hard

285
00:17:02,760 --> 00:17:03,760
to orchestrate.

286
00:17:03,760 --> 00:17:09,040
So some of our products, they start processing data as soon as a scientist uploads data

287
00:17:09,040 --> 00:17:11,480
into the limbs or into the warehouse.

288
00:17:11,480 --> 00:17:16,440
Others can be scheduled and so it runs nightly or weekly and, or doing all that orchestration

289
00:17:16,440 --> 00:17:19,280
ourselves was, was very challenging.

290
00:17:19,280 --> 00:17:25,160
And, and so I imagine the upside is that airflow kind of handles, handles all of this for you.

291
00:17:25,160 --> 00:17:30,280
It, you know, does the impedance matching from, you know, the different, different velocities

292
00:17:30,280 --> 00:17:32,400
of information coming in and things like that.

293
00:17:32,400 --> 00:17:33,400
Yeah.

294
00:17:33,400 --> 00:17:39,240
So, airflow does a lot of things for us in terms of sort of handling different data inputs

295
00:17:39,240 --> 00:17:42,200
and being sort of agnostic to that.

296
00:17:42,200 --> 00:17:44,040
It's been huge for us for that.

297
00:17:44,040 --> 00:17:49,160
So, we've basically in our processing steps, we have created sort of a generic interface.

298
00:17:49,160 --> 00:17:52,600
So we have sort of three big processing nodes that need to happen.

299
00:17:52,600 --> 00:17:54,280
And they all have very generic interfaces.

300
00:17:54,280 --> 00:17:57,160
So they don't know anything about the data that they're going to receive.

301
00:17:57,160 --> 00:18:01,160
And then basically we, we contextualize it at the time that we've received data.

302
00:18:01,160 --> 00:18:06,560
And so, and that, that has made it very flexible and modular for us so that we can, you know,

303
00:18:06,560 --> 00:18:08,760
a new experimental platform comes online.

304
00:18:08,760 --> 00:18:12,160
It will be very easy for us to apply the same, well, I wouldn't say very easy.

305
00:18:12,160 --> 00:18:16,280
It will be much easier for us to apply the same set of processing steps with a new data

306
00:18:16,280 --> 00:18:20,880
set just because we've, we've gone through the effort of making the interface generic.

307
00:18:20,880 --> 00:18:23,520
So that, and that was something that's harder to do.

308
00:18:23,520 --> 00:18:24,520
Yeah.

309
00:18:24,520 --> 00:18:25,520
Sorry.

310
00:18:25,520 --> 00:18:26,520
Are these three, you said nodes?

311
00:18:26,520 --> 00:18:31,760
Are the three nodes, are they, is this an artifact of kind of the way you would ideal

312
00:18:31,760 --> 00:18:36,400
or design your own processes or is this something that's kind of imposed on you by the way air

313
00:18:36,400 --> 00:18:37,400
flow does things?

314
00:18:37,400 --> 00:18:38,400
Oh, no.

315
00:18:38,400 --> 00:18:42,600
It's, it's more just like sort of the flow of the pipeline, the processing pipeline.

316
00:18:42,600 --> 00:18:45,480
And it, which so happens to have three steps.

317
00:18:45,480 --> 00:18:46,480
Yeah.

318
00:18:46,480 --> 00:18:50,240
So like the, the initial step, one of the, one of the things that we see, you know, I

319
00:18:50,240 --> 00:18:53,720
mentioned, I think that we use, part of the reason we're able to do what we do is that

320
00:18:53,720 --> 00:18:58,600
we rely heavily on robotic automation to do a lot of the heavy lifting in the lab, but

321
00:18:58,600 --> 00:19:04,680
robots fail sometimes or weird things happen in the lab, you know, it's a, it's, the experimentation

322
00:19:04,680 --> 00:19:06,160
is, is challenging.

323
00:19:06,160 --> 00:19:10,640
And so the result of that is we'll see sort of extreme values or like outlying values

324
00:19:10,640 --> 00:19:13,520
that, you know, typically indicate a process failure.

325
00:19:13,520 --> 00:19:16,600
And so that first step is really just an outlier detection step.

326
00:19:16,600 --> 00:19:21,840
So let's, let's identify those process failures and filter those out of any downstream processes.

327
00:19:21,840 --> 00:19:26,440
The second step of that pipeline is something called normalization.

328
00:19:26,440 --> 00:19:30,520
And that's really meant to address sort of another challenge that we face, which are batch

329
00:19:30,520 --> 00:19:35,240
effects, which is a very common phenomenon and high throughput screening environment.

330
00:19:35,240 --> 00:19:41,320
So, you know, you've got a bunch of, you've got a chip with a lot of samples or a lot

331
00:19:41,320 --> 00:19:44,320
of, you know, probes or on it.

332
00:19:44,320 --> 00:19:47,000
And you're asking a lot of questions in a very tight space.

333
00:19:47,000 --> 00:19:51,280
And so these types of environments tend to have strong temporal effects.

334
00:19:51,280 --> 00:19:55,680
So even if you imagine you do the exact same experiment this week and next week, they

335
00:19:55,680 --> 00:19:58,160
might look like they're coming from different distributions.

336
00:19:58,160 --> 00:20:02,600
And that doesn't actually reflect meaningful biological variability.

337
00:20:02,600 --> 00:20:07,360
It's actually just kind of a reflection of the process or of the temperature in the room

338
00:20:07,360 --> 00:20:08,360
at the time.

339
00:20:08,360 --> 00:20:12,000
So yeah, the person who ran it or all these other things that we don't actually care

340
00:20:12,000 --> 00:20:13,000
about.

341
00:20:13,000 --> 00:20:14,000
They're kind of nuisance things.

342
00:20:14,000 --> 00:20:15,000
Right.

343
00:20:15,000 --> 00:20:19,240
And so the second step of that processing pipeline is normalizing the data to try to

344
00:20:19,240 --> 00:20:22,280
eliminate those process, process-related biases.

345
00:20:22,280 --> 00:20:23,280
Okay.

346
00:20:23,280 --> 00:20:26,880
And then sort of the third step and sort of the third challenge that we face with our

347
00:20:26,880 --> 00:20:32,640
data is we have a motto at Zymrogen that is any micro, any molecule.

348
00:20:32,640 --> 00:20:38,240
And what that means is that we, we've built a testing platform that is agnostic to

349
00:20:38,240 --> 00:20:41,560
our customers, microbe, and to the molecule that they're making.

350
00:20:41,560 --> 00:20:48,080
We think that we have a process that will allow us to optimize those strains regardless

351
00:20:48,080 --> 00:20:51,080
of the actual application.

352
00:20:51,080 --> 00:20:55,680
That's amazing from a sort of a business strategy point of view because we can work in lots

353
00:20:55,680 --> 00:20:56,680
of different industries.

354
00:20:56,680 --> 00:21:00,920
We can work with lots of different bugs and make lots of different types of molecules.

355
00:21:00,920 --> 00:21:06,320
But it can be challenging from a data perspective because it can result in a proliferation

356
00:21:06,320 --> 00:21:07,320
of solutions.

357
00:21:07,320 --> 00:21:14,160
So we don't always have agreement on what the right way or whether something that constitutes

358
00:21:14,160 --> 00:21:18,640
an improvement for one group might not be considered an improvement in another group.

359
00:21:18,640 --> 00:21:22,960
And from a modeler's perspective, it's not always clear what the result of the experiment

360
00:21:22,960 --> 00:21:26,520
it is to us as consumers of that test data in a way.

361
00:21:26,520 --> 00:21:31,200
And so one way that we're addressing that is this sort of third piece of that processing

362
00:21:31,200 --> 00:21:36,200
pipeline where we actually do the matching up of the candidate strain with its reference

363
00:21:36,200 --> 00:21:40,560
strain, and we do that testing, and we, like statistical hypothesis testing, and we write

364
00:21:40,560 --> 00:21:46,360
that result so that regardless, sort of independent of the decisions that our scientists make,

365
00:21:46,360 --> 00:21:50,960
we have some indication of what we think happened in the experiment in a sort of a consistent

366
00:21:50,960 --> 00:21:54,840
view of what improvement looks like for our models.

367
00:21:54,840 --> 00:22:01,960
Interesting is it from a modeling and statistical perspective, is it challenging to imagine

368
00:22:01,960 --> 00:22:07,680
it to be challenging to kind of normalize results from comparing one molecule to another

369
00:22:07,680 --> 00:22:11,000
or one biological process to another?

370
00:22:11,000 --> 00:22:12,480
Is that challenging?

371
00:22:12,480 --> 00:22:19,600
So in general, we're not doing that, so we don't share data at all between sort of projects

372
00:22:19,600 --> 00:22:20,600
or...

373
00:22:20,600 --> 00:22:27,480
I guess what I understood you to say that, you know, you've built this general platform for

374
00:22:27,480 --> 00:22:35,320
testing the results of these molecule production, microptomolecule production processes,

375
00:22:35,320 --> 00:22:40,720
and then as a way to make sure that you understand their efficacy, you know, you're kind of

376
00:22:40,720 --> 00:22:46,000
taking that analysis all the way to, you know, what would tell me, what is that end result

377
00:22:46,000 --> 00:22:48,320
that you're driving for?

378
00:22:48,320 --> 00:22:54,520
Yeah, so that note or that last step in the pipeline is often called hit detection in

379
00:22:54,520 --> 00:22:59,120
sort of the biology, the high throughput screening literature, and that's really just

380
00:22:59,120 --> 00:23:05,560
the process of identifying in your screen, which of those candidates that you were exploring

381
00:23:05,560 --> 00:23:08,160
seem to have the characteristics that you're looking for.

382
00:23:08,160 --> 00:23:14,160
And so it's sort of a, it's not as, because it's a screening scenario where our statistical

383
00:23:14,160 --> 00:23:17,360
criteria isn't quite as high as it would be if you were doing a single test, like I

384
00:23:17,360 --> 00:23:21,960
want to know, you know, we're screening, and so actually we care more about keeping false

385
00:23:21,960 --> 00:23:27,320
negatives low than we do about having high false positive rate and you know, retesting

386
00:23:27,320 --> 00:23:29,720
something that actually wasn't a very good strength.

387
00:23:29,720 --> 00:23:34,400
We would rather waste some resources testing something that wasn't good than lose the

388
00:23:34,400 --> 00:23:38,320
opportunity to test again something that actually was good.

389
00:23:38,320 --> 00:23:42,240
Meaning you're screening for possibilities, and the more possibilities you have, the

390
00:23:42,240 --> 00:23:45,520
more opportunity you have to find the thing that actually works.

391
00:23:45,520 --> 00:23:50,560
Yeah, exactly, yeah, yeah, yeah, so it's kind of a different, like way of thinking about

392
00:23:50,560 --> 00:23:55,320
it then, you know, often like in an A, B test, for example, you want to know the right

393
00:23:55,320 --> 00:23:56,320
answer.

394
00:23:56,320 --> 00:23:57,320
Right, right.

395
00:23:57,320 --> 00:23:58,400
Okay, got it.

396
00:23:58,400 --> 00:24:04,560
And so you talked about the challenges that led to deploying airflow.

397
00:24:04,560 --> 00:24:09,200
What about the challenges of deploying airflow and kind of building out this system?

398
00:24:09,200 --> 00:24:11,400
Did you encounter anything in particular there?

399
00:24:11,400 --> 00:24:16,640
Yeah, so, you know, it's sort of probably challenges that are typical of adopting anything

400
00:24:16,640 --> 00:24:19,200
that's kind of an early project.

401
00:24:19,200 --> 00:24:20,200
Right.

402
00:24:20,200 --> 00:24:26,440
One of our bigger challenges was really just finding non-trivial examples of how it's

403
00:24:26,440 --> 00:24:27,920
used in production.

404
00:24:27,920 --> 00:24:33,840
So what I think was some of, at least I experienced this, I feel like this was sort of the general

405
00:24:33,840 --> 00:24:38,160
experience of everybody on the team is that, you know, there's a certain way you're supposed

406
00:24:38,160 --> 00:24:43,880
to write these DAGs or these workflows in airflow every time I would write when I felt

407
00:24:43,880 --> 00:24:45,040
like it was the wrong way.

408
00:24:45,040 --> 00:24:50,560
So I would either try to, it felt like I was putting too little processing sort of in one

409
00:24:50,560 --> 00:24:56,560
node and kind of making too many nodes or it felt like I had one big node that did everything.

410
00:24:56,560 --> 00:25:00,840
And so it was really hard to like get a sense for what the right way to construct, what

411
00:25:00,840 --> 00:25:06,760
unit of work was appropriate and was sort of intended by the design of airflow.

412
00:25:06,760 --> 00:25:08,840
That was challenging, took some getting used to it.

413
00:25:08,840 --> 00:25:13,360
The team is using it a lot now, so I feel like we've got that a pretty good handle on

414
00:25:13,360 --> 00:25:14,360
that now.

415
00:25:14,360 --> 00:25:20,440
That was certainly challenging, sort of getting familiar with it and finding good examples

416
00:25:20,440 --> 00:25:25,440
of non-trivial examples of its use, which I don't know.

417
00:25:25,440 --> 00:25:30,880
It's interesting, it's something that comes up a lot in my conversations with folks in

418
00:25:30,880 --> 00:25:31,880
different domains.

419
00:25:31,880 --> 00:25:42,080
You know, both in take as an example, architecting neural nets or this, there's the documentation

420
00:25:42,080 --> 00:25:48,840
and there's the research and the literature, so much of adopting these new technologies,

421
00:25:48,840 --> 00:25:54,120
like tribal knowledge or black art, or it just practice that, you know, you often don't

422
00:25:54,120 --> 00:25:56,920
find good sources for how to do that stuff.

423
00:25:56,920 --> 00:26:03,040
Yeah, and that makes it, I don't know, that's kind of a friction on adopting this stuff.

424
00:26:03,040 --> 00:26:08,400
Like you want to see some success stories of somebody having used it so that you can

425
00:26:08,400 --> 00:26:14,920
be sure that before abandoning, like our home grown ETL system, we want to be reasonably

426
00:26:14,920 --> 00:26:21,200
sure that the thing that we move to works isn't going to be suffer from the same problems.

427
00:26:21,200 --> 00:26:25,120
And of course, at the understanding that it is a new project and that there will be

428
00:26:25,120 --> 00:26:27,720
sort of foibles as a result of that.

429
00:26:27,720 --> 00:26:31,520
But in general, we want to make sure it solves the bulk of the problems that we have with

430
00:26:31,520 --> 00:26:33,000
our own solution.

431
00:26:33,000 --> 00:26:35,200
And that can be hard to demonstrate sometimes.

432
00:26:35,200 --> 00:26:39,600
But in our case, it worked out Airflow is a really powerful tool for our group.

433
00:26:39,600 --> 00:26:44,360
Has that changed at all since you started to use it, are you seeing more of these examples

434
00:26:44,360 --> 00:26:50,720
or more, you know, better documentation of these more subtle, either use case examples

435
00:26:50,720 --> 00:26:55,720
like you described, or kind of some of these more subtle design philosophies and decisions?

436
00:26:55,720 --> 00:27:01,280
Yeah, I mean, even today, like I was the speaker right before me to talk a lot about Airflow

437
00:27:01,280 --> 00:27:04,520
and then right after me, it was a panel where they talked a bit about Airflow.

438
00:27:04,520 --> 00:27:10,160
So it seems like it is now becoming quite a popular tool and being used pretty pervasively.

439
00:27:10,160 --> 00:27:14,720
So I expect that we'll see more and more, more and more of these kind of stories of how

440
00:27:14,720 --> 00:27:16,320
it's being used in production.

441
00:27:16,320 --> 00:27:19,840
And it's a very flexible tool and it has a lot of functionality.

442
00:27:19,840 --> 00:27:23,640
And so we're using it in ways that we didn't actually expect initially.

443
00:27:23,640 --> 00:27:25,920
And so I'm excited to see how other people are using it.

444
00:27:25,920 --> 00:27:30,600
I'm sure there are a lot of really creative things that are being developed on it.

445
00:27:30,600 --> 00:27:31,600
Nice.

446
00:27:31,600 --> 00:27:39,040
And for the, or is it intended, do you think that the main consumer of the tool is a data

447
00:27:39,040 --> 00:27:45,440
science team, as opposed to a data engineering team or some other variation on the term?

448
00:27:45,440 --> 00:27:48,320
Yeah, I think that's a good question.

449
00:27:48,320 --> 00:27:53,400
I'm not totally sure what the intentions were, but it's definitely a tool that's very

450
00:27:53,400 --> 00:27:59,000
powerful for data scientists in terms of just like the way that we think and being able

451
00:27:59,000 --> 00:28:02,800
to construct workflows that way, it just feels very natural.

452
00:28:02,800 --> 00:28:07,800
I guess it's even a hard question to answer because data science and data scientist means

453
00:28:07,800 --> 00:28:10,200
so many different things.

454
00:28:10,200 --> 00:28:12,200
This actually came up in my last interview as well.

455
00:28:12,200 --> 00:28:17,840
We talked about how this has evolved since five years ago when everything was considered

456
00:28:17,840 --> 00:28:24,000
data science, or data science was considered needing to know all of the different bits

457
00:28:24,000 --> 00:28:30,280
and pieces of moving the data around and doing the analytics and getting it to production.

458
00:28:30,280 --> 00:28:38,520
When I hear you describe the tool, I think plumbing, I think kind of no-level stuff.

459
00:28:38,520 --> 00:28:44,520
And that was really the source of the question, like, is it is, do you think that that is typical

460
00:28:44,520 --> 00:28:51,200
for data science to kind of dive into that level, or is our data scientist typically

461
00:28:51,200 --> 00:28:56,560
that's supported by other groups that are kind of putting the plumbing in place?

462
00:28:56,560 --> 00:29:03,160
Yeah, so for us, the way that we ended up kind of productionizing our airflow environment

463
00:29:03,160 --> 00:29:06,360
was with the collaboration with data engineering.

464
00:29:06,360 --> 00:29:11,560
We have, our group is pretty engineering-heavy anyway, all the data scientists are fairly

465
00:29:11,560 --> 00:29:12,920
do a lot of engineering.

466
00:29:12,920 --> 00:29:18,280
And so of course we had help from actual data engineers, and then members of the team

467
00:29:18,280 --> 00:29:24,000
who have that skill set as well, are responsible for sort of doing all the configuration and

468
00:29:24,000 --> 00:29:25,960
the start-up scripts for people.

469
00:29:25,960 --> 00:29:32,400
Because our group is pretty mixed in terms of the background and interests and the skills.

470
00:29:32,400 --> 00:29:38,000
And so that's been great, like, they spent a lot of time really developing structure

471
00:29:38,000 --> 00:29:42,320
around how to get it set up, and so that all of the data scientists, when they come

472
00:29:42,320 --> 00:29:46,920
online, can easily set it up and then start doing what they already know how to do,

473
00:29:46,920 --> 00:29:49,880
which is construct the workflows and Python.

474
00:29:49,880 --> 00:29:51,240
So it's kind of two levels.

475
00:29:51,240 --> 00:29:55,800
I think we did probably need help from data engineers to actually get it up and get it

476
00:29:55,800 --> 00:30:00,160
running consistently, and sort of in a production level of an environment.

477
00:30:00,160 --> 00:30:05,520
But then once it's there, it's actually, I think, a very simple tool for the average

478
00:30:05,520 --> 00:30:11,200
data scientist to quickly start making processing workflows.

479
00:30:11,200 --> 00:30:15,600
And part of that is that it has a really cool out-of-the-box UI, so you can write your

480
00:30:15,600 --> 00:30:19,760
workflow in Python, and then you can go to the UI, you can run it there, you can view

481
00:30:19,760 --> 00:30:24,440
all kinds of metrics about the pipeline, there's even stuff about sort of which tasks in

482
00:30:24,440 --> 00:30:28,080
that pipeline are sort of the bottlenecks, and what are the performance metrics of each

483
00:30:28,080 --> 00:30:29,360
of the individual tasks.

484
00:30:29,360 --> 00:30:35,240
So it allows you to kind of see, get visibility into those workflows that, in the past, I

485
00:30:35,240 --> 00:30:38,880
haven't had actually really anywhere, so it's great for that.

486
00:30:38,880 --> 00:30:39,880
Interesting.

487
00:30:39,880 --> 00:30:46,520
Is that user experience, is it kind of analogous to a notebook, or is it more like a job processing

488
00:30:46,520 --> 00:30:47,520
type of tool?

489
00:30:47,520 --> 00:30:52,000
No, it's more like a bonafide application.

490
00:30:52,000 --> 00:30:59,160
So it's got sort of a table of all of the jobs that are around, and you can kind of change

491
00:30:59,160 --> 00:31:04,600
the scheduling right there in the UI, turn them on and off, and then tab over to metrics

492
00:31:04,600 --> 00:31:05,800
and all kinds of other things.

493
00:31:05,800 --> 00:31:11,560
You can view the logs from there, so if something failed, obviously you can log into the machine

494
00:31:11,560 --> 00:31:16,320
and view the logs there, or you can just use the UI and view the logs directly, see what

495
00:31:16,320 --> 00:31:20,800
happened with your job, you'll get a bunch of rich diagnostics about which part of the

496
00:31:20,800 --> 00:31:23,560
workflow failed, and all kinds of stuff right there in the UI.

497
00:31:23,560 --> 00:31:25,560
So it's actually, it's a pretty developed tool.

498
00:31:25,560 --> 00:31:26,560
Oh wow.

499
00:31:26,560 --> 00:31:27,560
It's really helpful.

500
00:31:27,560 --> 00:31:28,560
Oh, very nice.

501
00:31:28,560 --> 00:31:29,560
Very nice.

502
00:31:29,560 --> 00:31:32,520
Anything else you'd like to share with the audience, or leave with the audience?

503
00:31:32,520 --> 00:31:38,960
I guess just check it out, it's been a really great tool for us, so the reason that we

504
00:31:38,960 --> 00:31:44,600
invested in it really is to support our work in predictive strain design, that is sort

505
00:31:44,600 --> 00:31:50,800
of our mission is to use machine learning so that we can construct better strains and help

506
00:31:50,800 --> 00:31:54,120
our scientists get to the solution faster.

507
00:31:54,120 --> 00:31:58,480
And airflow has been incredible in helping us solidify that processing pipeline to support

508
00:31:58,480 --> 00:31:59,480
that work.

509
00:31:59,480 --> 00:32:04,280
It's a clean analysis ready or modeling ready data that's consumable directly from this

510
00:32:04,280 --> 00:32:10,320
pipeline, and a lot of it, a lot of the headache of what's sort of traditionally, or maybe

511
00:32:10,320 --> 00:32:13,920
not associated with being a data scientist, but with data scientists know it's actually

512
00:32:13,920 --> 00:32:18,600
about, can be sort of addressed with airflow, or at least can be ameliorated some so that

513
00:32:18,600 --> 00:32:23,800
it's not, so that 90% of your time isn't actually spent cleaning data and munging it and moving

514
00:32:23,800 --> 00:32:24,800
it around.

515
00:32:24,800 --> 00:32:29,720
We can do, it's very flexible, can do all kinds of different types of tasks, and that's

516
00:32:29,720 --> 00:32:35,040
been really helpful for getting, sort of, trying to eliminate sort of the boring stuff so

517
00:32:35,040 --> 00:32:37,000
that we can do the cool stuff.

518
00:32:37,000 --> 00:32:38,760
Awesome, awesome.

519
00:32:38,760 --> 00:32:43,400
If I can draw you back in, that was kind of a great summary, but we haven't really

520
00:32:43,400 --> 00:32:48,600
talked a lot about the specific models that you use, like we've talked about this tool

521
00:32:48,600 --> 00:32:50,600
that helps you get the data to the models.

522
00:32:50,600 --> 00:32:51,600
Yeah.

523
00:32:51,600 --> 00:32:55,600
A bit about the types of models that you're building, the modeling techniques you're

524
00:32:55,600 --> 00:32:57,160
using, things like that.

525
00:32:57,160 --> 00:33:04,480
Yeah, I can't talk a ton about them, but the conceptually what we're doing is we're

526
00:33:04,480 --> 00:33:09,000
taking information about what we know the scientists are engineering into the strains,

527
00:33:09,000 --> 00:33:15,200
so the type of change that they're making, where it is, so what gene is it that's being

528
00:33:15,200 --> 00:33:21,400
perturbed, or being engineered, and we're basically making models to predict combinations

529
00:33:21,400 --> 00:33:28,800
of those changes, so the typical microbe has something between three and 5,000 genes in

530
00:33:28,800 --> 00:33:35,000
it, and so if we were to perturb each of those individually and then start perturbing

531
00:33:35,000 --> 00:33:40,480
each pairwise combination, that's an infinite, combinatorical space to explore, and so what

532
00:33:40,480 --> 00:33:44,000
we're trying to do instead is take all of the information about the things that we know

533
00:33:44,000 --> 00:33:48,200
we've already done, and then make predictions about how we think those are going to perform

534
00:33:48,200 --> 00:33:49,720
when they're combined.

535
00:33:49,720 --> 00:33:54,760
So a little bit of evolutionary genetic algorithm types of things, or...

536
00:33:54,760 --> 00:34:02,400
A lot of things, actually, so we have a lot of different types of models and some work

537
00:34:02,400 --> 00:34:07,560
in better context than others, so we have models that kind of address different things.

538
00:34:07,560 --> 00:34:11,040
Some work better when you have a bunch more information, so after a project is fairly

539
00:34:11,040 --> 00:34:15,600
mature, and we have a whole lot of test data that we can use to train on, our models are

540
00:34:15,600 --> 00:34:20,280
different than when we're at the cold start problem, where really all we know, maybe

541
00:34:20,280 --> 00:34:24,440
is the metabolic structure of the microbe, we haven't started doing anything yet, so

542
00:34:24,440 --> 00:34:30,920
how do we guide the experimentation in that case when we don't know at all about really

543
00:34:30,920 --> 00:34:36,240
where to start, and so those suite of models are a little bit different and they rely

544
00:34:36,240 --> 00:34:42,000
more on structural information about metabolism than experimental information, which can

545
00:34:42,000 --> 00:34:45,840
happen later, after we've collected a bunch of information from experiments.

546
00:34:45,840 --> 00:34:48,880
Okay, all right, very cool, very cool.

547
00:34:48,880 --> 00:34:52,040
Thank you so much, everyone, for taking the time to jump on the podcast with me.

548
00:34:52,040 --> 00:34:53,680
Yeah, thanks so much for having me.

549
00:34:53,680 --> 00:34:55,680
There's a lot of fun, thank you.

550
00:34:55,680 --> 00:34:56,680
Yeah.

551
00:34:56,680 --> 00:35:02,680
All right, everyone, that's our show for today.

552
00:35:02,680 --> 00:35:07,880
Thanks so much for listening and for your continued support of this podcast.

553
00:35:07,880 --> 00:35:12,320
For the notes for this episode, or for any feedback or questions, please leave a comment

554
00:35:12,320 --> 00:35:18,000
on the show notes page at twimmaleye.com slash talk slash 41.

555
00:35:18,000 --> 00:35:23,520
Thanks again to Cloud Era, our sponsor for the Rangle Conference series of podcasts.

556
00:35:23,520 --> 00:35:28,400
To learn more about Cloud Era and the company's data science workbench products, visit them

557
00:35:28,400 --> 00:35:34,760
at cloudera.com and be sure to tweet at them using at cloud era to thank them for their

558
00:35:34,760 --> 00:35:37,120
support of this podcast.

559
00:35:37,120 --> 00:35:41,800
If you're interested in joining the twimmale online meetup, we'll discuss research papers

560
00:35:41,800 --> 00:35:46,320
like Apple's recent paper on generative adversarial networks.

561
00:35:46,320 --> 00:35:50,400
You can register for that at twimmaleye.com slash meetup.

562
00:35:50,400 --> 00:35:56,280
And don't forget to sign up for the newsletter at twimmaleye.com slash newsletter.

563
00:35:56,280 --> 00:35:58,520
Thanks again for listening and catch you next time.

