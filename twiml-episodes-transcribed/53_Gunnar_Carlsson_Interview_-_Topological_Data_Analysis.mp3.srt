1
00:00:00,000 --> 00:00:15,920
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

2
00:00:15,920 --> 00:00:20,880
people doing interesting things in machine learning and artificial intelligence.

3
00:00:20,880 --> 00:00:23,360
I'm your host, Sam Charrington.

4
00:00:23,360 --> 00:00:27,600
This show you are about to hear as part of a series of shows recorded in San Francisco

5
00:00:27,600 --> 00:00:32,080
at the Artificial Intelligence Conference, which was hosted by our friends at O'Reilly

6
00:00:32,080 --> 00:00:33,920
and Intel Nirvana.

7
00:00:33,920 --> 00:00:39,200
In addition to their support for the event itself, Intel Nirvana is also our sponsor for this

8
00:00:39,200 --> 00:00:41,680
series of podcasts from the event.

9
00:00:41,680 --> 00:00:46,240
A huge thanks to them for their continued support of this show.

10
00:00:46,240 --> 00:00:51,280
Make sure you check out my interview with Navine Rao, VP and GM of Intel's AI Products

11
00:00:51,280 --> 00:00:56,640
Group, and Scott Appland, Director of Intel's Developer Network, which you can find at

12
00:00:56,640 --> 00:01:00,000
Twimbleai.com slash talk slash 51.

13
00:01:00,880 --> 00:01:07,120
At the AI conference, Intel Nirvana announced DevCloud, a cloud hosted hardware and software

14
00:01:07,120 --> 00:01:12,800
platform for learning, sandboxing, and accelerating the development of AI solutions.

15
00:01:13,440 --> 00:01:20,080
The DevCloud will be available to 200,000 developers, researchers, academics, and startups via

16
00:01:20,080 --> 00:01:26,400
the Intel Nirvana AI Academy this month. For more information on the DevCloud or the AI

17
00:01:26,400 --> 00:01:32,560
Academy, visit intelnervana.com slash dev cloud for machine intelligence.

18
00:01:33,360 --> 00:01:39,040
In our talk, we take a super deep dive on the mathematical underpinnings of TDA

19
00:01:39,040 --> 00:01:44,800
and its practical application in software. Nerd alert, all right, onto the show.

20
00:01:44,800 --> 00:01:57,440
Hey everyone, I am here at the O'Reilly and Intel Nirvana AI conference,

21
00:01:57,440 --> 00:02:03,200
and I've got the pleasure to be seated here with Gunner Carlson, who is the president of IASD.

22
00:02:03,200 --> 00:02:07,920
Welcome, Gunner. Thank you. Great to be here. Absolutely. Great to have you.

23
00:02:07,920 --> 00:02:12,320
So why don't we start with having you tell us a little bit about your background and your

24
00:02:12,320 --> 00:02:19,600
areas of research? So I come from an academic background. I did my PhD in mathematics, and for

25
00:02:19,600 --> 00:02:25,280
the first 20, 25 years of my career worked very much in pure mathematics. Over time, I started to

26
00:02:25,280 --> 00:02:30,080
become more interested in how could we apply things that we were doing in the pure math side,

27
00:02:30,080 --> 00:02:35,440
down a shorter time frame, because oftentimes the applications have a very long, you know,

28
00:02:35,440 --> 00:02:42,880
long time to go. So I tried to do some things more quickly, and my main area within mathematics

29
00:02:42,880 --> 00:02:47,280
is topology, which is the study of shape. In a generalized sense, one can talk about shapes

30
00:02:47,280 --> 00:02:53,120
and higher dimensions, and so I wanted to apply that to the study of large and complex data.

31
00:02:53,120 --> 00:02:57,600
It turned out it led to a lot of things, basically a big career change. It wasn't just a little

32
00:02:57,600 --> 00:03:03,680
hobby thing. You know, we found that it was a very hot topic, both for the National Science Foundation

33
00:03:03,680 --> 00:03:10,720
and DARPA, the research arm, or the innovation arm within DOD. In the middle of that, we spun out

34
00:03:10,720 --> 00:03:16,160
a company, a Yazdi Incorporated, which is so commercializing the ideas coming out of there,

35
00:03:16,160 --> 00:03:21,440
and other things as well. So that's kind of where we are. I live in the Stanford campus,

36
00:03:21,440 --> 00:03:26,000
a math professor at Stanford, or a retired math professor at Stanford, I should say,

37
00:03:26,000 --> 00:03:31,360
and they've got the three grown kids who are in the area, and so. Yeah, awesome. So I'm like a busy

38
00:03:31,360 --> 00:03:37,120
guy. A busy guy, but I don't want to not be busy. Absolutely. Absolutely. So let's talk a little

39
00:03:37,120 --> 00:03:43,360
bit about topological data analysis and topology in general, which was a topic of a tutorial that

40
00:03:43,360 --> 00:03:48,240
you did here at the conference today. You mentioned the study of shapes. The first thing that comes to

41
00:03:48,240 --> 00:03:53,600
my mind is like high school geometry and trigonometry, but I imagine it gets a lot more interesting

42
00:03:53,600 --> 00:03:57,360
when you're talking about higher dimensions and lots of data. It is, on the other hand,

43
00:03:57,360 --> 00:04:03,360
sometimes what you can do is get very simple, small representations of complex data sets by

44
00:04:03,360 --> 00:04:10,960
the things, the simple things that you mentioned. So what we do is we represent data by network

45
00:04:10,960 --> 00:04:15,520
model. So when you think about mathematical modeling, one often thinks about algebra, one

46
00:04:15,520 --> 00:04:21,520
thinks about equations, one thinks about various kinds of equations and so forth. But maybe one

47
00:04:21,520 --> 00:04:25,920
should try to model data by something else, maybe something with a richer output than just

48
00:04:25,920 --> 00:04:32,160
equations. And for us, the output of our models is a network in the computer science sense that

49
00:04:32,160 --> 00:04:38,400
is nodes and edges. And it turns out to be a very useful, compressed representations and data sets

50
00:04:38,400 --> 00:04:43,920
for many different applications. Okay. Interesting. Now, when you say network and nodes and edges,

51
00:04:43,920 --> 00:04:50,160
I think of graphs, is this graph theory we're talking about? Well, one can view it in that way,

52
00:04:50,160 --> 00:04:56,320
but you know, a lot of times graph theory deals with very nitty-gritty local discussions of degree

53
00:04:56,320 --> 00:05:00,960
and so forth. Right. You know, this is sometimes thinking of it as a higher-dimensional shape. So

54
00:05:00,960 --> 00:05:06,640
for example, you know, a graph with four nodes and it might actually encode a tetrahedron rather

55
00:05:06,640 --> 00:05:12,640
than just its edges. And so we kind of think in those terms. So yeah, it is graph theory in some

56
00:05:12,640 --> 00:05:16,720
sense that in the sense that we study graphs, I would say that we do it in a way that's different

57
00:05:16,720 --> 00:05:23,120
from what is usually meant by graph theory in the math side. It's more a lot's meant by shape

58
00:05:23,120 --> 00:05:28,640
and topology on the topology side of math, if that makes sense. Okay. And so how does this all play

59
00:05:28,640 --> 00:05:35,040
into machine learning? One of the big things about machine learning is that it's great, but many

60
00:05:35,040 --> 00:05:41,040
people, including people like regulators, like MDs, you know, all the people that one might want to

61
00:05:41,040 --> 00:05:46,560
use it with often regarded as a black box. They regarded it as something which, you know, although it

62
00:05:46,560 --> 00:05:52,000
seems to produce good answers, they can't put their head around, understand where it came from.

63
00:05:52,000 --> 00:05:57,600
And that means that sometimes there's some difficulty in, you know, making use of it for those

64
00:05:57,600 --> 00:06:04,560
reasons. And so we view ourselves, we view the topological data analysis as, you know, a part of

65
00:06:04,560 --> 00:06:10,560
the growing area of machine learning. You know, we believe that it produces richer models than just

66
00:06:10,560 --> 00:06:16,240
simply classifiers or linear regression models that come out or clustering that comes out of machine

67
00:06:16,240 --> 00:06:22,160
learning. And so, you know, it's just augmenting and helping machine learning develop over time.

68
00:06:22,160 --> 00:06:27,840
That's how we view it. Okay. So I heard a couple of things in there. I heard one that the models are

69
00:06:27,840 --> 00:06:34,800
richer, and I'd like you to explain or elaborate on why that is, but I also heard that you suggest

70
00:06:34,800 --> 00:06:41,200
that this approach, the taking things from a topological perspective, aids in explainability. And

71
00:06:41,200 --> 00:06:46,240
that's a, you know, a huge issue for, you know, the, the constituencies that you mentioned,

72
00:06:46,240 --> 00:06:51,680
the regulators, but also, you know, a business that's going to depend on, you know, machine learning

73
00:06:51,680 --> 00:06:56,800
or artificial intelligence, whatever we want to call it. You know, they, they want more than just

74
00:06:56,800 --> 00:07:03,280
the box set it, right? You know, kind of walk us through, you know, the next level of what TDA is

75
00:07:03,280 --> 00:07:07,600
all about and how it lends itself to achieving those goals for machine learning.

76
00:07:07,600 --> 00:07:12,240
So let me talk about an example, you know, for the explainability part for the machine learning.

77
00:07:12,240 --> 00:07:18,080
So, and let me say, by the way, so what would produce a network? It can be viewed as a map

78
00:07:18,080 --> 00:07:23,760
of your data in a sense. And so, okay, you know, for us, we're working with a bank that had failed

79
00:07:23,760 --> 00:07:29,120
the stress testing, seek our stress testing process two years in a row. They had failed it in

80
00:07:29,120 --> 00:07:35,520
part, most part because they had produced machine learning models, which, you know, were

81
00:07:36,560 --> 00:07:41,040
reasonably, which were predictive, but which were non-understandable. That is to say, they came

82
00:07:41,040 --> 00:07:46,640
as a large vector of numbers, vector of coefficients, if you like, and regulators couldn't understand.

83
00:07:46,640 --> 00:07:52,560
So the stress testing process is the bank basically has to say, I've got this much reserves

84
00:07:52,560 --> 00:07:58,160
based on my risk, and I've got to justify that some kind of way, and they produced this model,

85
00:07:58,160 --> 00:08:02,480
but they couldn't explain what the model was doing. That's right. It wasn't explainable enough

86
00:08:02,480 --> 00:08:09,440
for it. That's correct. And so, for us, now, the model was actually based on a lot of

87
00:08:09,440 --> 00:08:14,160
features, a lot of macroeconomic and other kind of global economic indicators.

88
00:08:14,800 --> 00:08:21,120
And so, we built one of our models on that. And within that model, we found several hot spots

89
00:08:21,120 --> 00:08:27,120
for a correlation with revenue and a business unit. And, but more than one. And so, for each one of

90
00:08:27,120 --> 00:08:33,760
those, we might join one or two features from each of those hot spots, those groups. And let me say,

91
00:08:33,760 --> 00:08:39,200
and so the hot spot itself turns out to be a large collection of, you know, of these economic

92
00:08:39,200 --> 00:08:46,320
indicators, but they were understandable to the regulators. So we tell them, look, we have a

93
00:08:46,320 --> 00:08:52,160
model with four features, okay, first of all, much small. And then each feature is representative of,

94
00:08:52,160 --> 00:08:57,840
you know, some class of features, which are recognizable as similar or related by regulators.

95
00:08:58,480 --> 00:09:03,760
And that is what we would call, you know, an understandable model, a low-dimensional and

96
00:09:04,400 --> 00:09:09,840
annotation in terms of a group for each one of the features. Okay. I've got some questions.

97
00:09:09,840 --> 00:09:14,240
So you started out by saying you built, you were talking about their model and you said,

98
00:09:14,240 --> 00:09:20,240
you built a model on on that. Did you build your model on their model? No, sorry, no, no,

99
00:09:20,240 --> 00:09:24,000
we're building separate models. We're building their data. Building, you know, very,

100
00:09:24,000 --> 00:09:28,240
yes, on their data, but not on their model. That's right. We're building, you know, there, we

101
00:09:28,240 --> 00:09:34,080
involved many hundreds or even thousands of variables. You know, ours was, is a small number of

102
00:09:34,080 --> 00:09:39,680
variables. And each one is understood as being representative of a class of indicators,

103
00:09:39,680 --> 00:09:45,200
all of which have strong correlation. Yeah. It almost sounds like what you're doing is

104
00:09:45,200 --> 00:09:51,920
you're like semantically clustering the features. That's correct. And kind of ranking the features in

105
00:09:51,920 --> 00:09:57,360
their relevance to the prediction. That's correct. But here's the interesting feature in this.

106
00:09:57,360 --> 00:10:01,120
You might say, well, why don't you just take all the features and find the ones that are the most

107
00:10:01,120 --> 00:10:05,520
correlated? Right. You know, why do you need them? Well, the reason is that

108
00:10:06,560 --> 00:10:11,360
features are perhaps correlated with revenue for different reasons. And so you have different

109
00:10:11,360 --> 00:10:16,240
groups of things, which are correlated in different ways. If you put them all together, you know,

110
00:10:16,240 --> 00:10:21,760
you don't get nearly the same kind of explainability as you do when you have to separate them out

111
00:10:21,760 --> 00:10:27,520
and understand that, you know, each one is representative of a particular class of things that are

112
00:10:27,520 --> 00:10:34,320
similar. So that's the key thing there. So I get the example and I kind of get what you're doing.

113
00:10:34,320 --> 00:10:40,800
But still, how do you explain the TDA part of that? Like to at the next level of detail,

114
00:10:40,800 --> 00:10:46,880
what do we do? What do we do? Let me tell you. And again, this may get a little geeky,

115
00:10:46,880 --> 00:10:53,440
but let's go ahead. We love geeky. We love geeky. So, you know, the starting point for us is

116
00:10:53,440 --> 00:10:58,880
always a data set equipped with a similarity measure of some kind. So we encode that as actually a

117
00:10:58,880 --> 00:11:03,680
distance function, mathematical sense, which is an abstraction of ordinary distance that we have,

118
00:11:03,680 --> 00:11:09,680
you know, in the plane or in space. And is this is your distance function? Something that might be like

119
00:11:09,680 --> 00:11:16,320
your error function or is it distance of the, you know, your rows or your points within the

120
00:11:16,320 --> 00:11:22,320
data set itself? It's distance of one row to another. Okay. Yeah. And so, so, you know, a normal

121
00:11:22,320 --> 00:11:27,360
thing is supposing that it were, that we really only had two coordinates, you know, two or two

122
00:11:27,360 --> 00:11:34,000
features. Then my rows would be two vectors, you know, with two entries and I could compute their

123
00:11:34,000 --> 00:11:38,800
distance regarding them as being in the plane. And that distance would be, that would be a

124
00:11:38,800 --> 00:11:44,160
perfectly good distance that we could work with. Right. Now, the thing is that oftentimes for,

125
00:11:44,160 --> 00:11:49,280
you know, for different phenomena with more features, by the way, those formulas for distance

126
00:11:49,280 --> 00:11:53,920
and dimension two, they extend to any number of dimensions. So if I have a spreadsheet with numbers,

127
00:11:53,920 --> 00:11:57,120
you know, it doesn't matter whether I've got, you know, five or ten or even a thousand

128
00:11:57,920 --> 00:12:02,720
fields, it's all for good. You can go ahead and compute with it. But supposing that you're in a

129
00:12:02,720 --> 00:12:09,280
situation instead, you know, like you are in the study of genetics, where you have long sequences

130
00:12:09,280 --> 00:12:13,840
and an alphabet of symbols, you know, you want what you might do is you might take the two sequences

131
00:12:13,840 --> 00:12:19,520
and say, well, how many spots do they differ in? I keep a count of that. And that is a distance or

132
00:12:19,520 --> 00:12:25,040
similarity measure as well. That's one that wouldn't be using that context. So in fact, you know,

133
00:12:25,040 --> 00:12:29,280
for us, there are sort of many different choices of these distance functions, there's libraries

134
00:12:29,280 --> 00:12:33,840
of them and so on. But, you know, I've just given you kind of two important ones. The first one

135
00:12:33,840 --> 00:12:38,240
would be called Euclidean or general Euclidean. Second one would be called hamming. So it's called

136
00:12:38,240 --> 00:12:43,760
correlation angle and cosine and so on. So there's a lot of variety of them. But the idea is always

137
00:12:43,760 --> 00:12:50,160
to get at some notion of similarity of data points. So where the distance is small, we regard the

138
00:12:50,160 --> 00:12:54,960
data points as similar. And if they're far apart, we regard them as dissimilar. So maybe let's take

139
00:12:54,960 --> 00:13:04,800
this back to your example with the bank, you know, given a data set that consists of macroeconomic

140
00:13:04,800 --> 00:13:11,280
factors and transactions, perhaps and portfolios and the like, like, what does a distance mean in

141
00:13:11,280 --> 00:13:15,520
that context? So all those things though are their numbers, their hearts. So this is really just

142
00:13:15,520 --> 00:13:20,880
a spreadsheet. So I could do the Euclidean distance there. I think there's a variant on Euclidean

143
00:13:20,880 --> 00:13:24,800
distance, which is called, you know, variance normalized Euclidean, which means that if you've

144
00:13:24,800 --> 00:13:29,360
got some variables that have much larger range than others, you might want to make those ranges

145
00:13:29,360 --> 00:13:33,840
the same so that the one variable doesn't swamp the others. But fundamentally, it would be the

146
00:13:33,840 --> 00:13:37,760
first one that I talked about, you know, in the notion of Euclidean. Yeah. But I guess maybe the

147
00:13:37,760 --> 00:13:46,080
question that I'm asking is does Euclidean distance or any distance, I guess, in the general case,

148
00:13:46,080 --> 00:13:54,000
have like a semantic meaning in a highly high-dimensional data set, or is it just the distance between

149
00:13:54,640 --> 00:14:00,720
points and data set? You know, I think it does. It's not that one justifies it in terms of

150
00:14:00,720 --> 00:14:07,360
semantics or theory, but what one observes is that, you know, it does typically coincide with one's

151
00:14:07,360 --> 00:14:13,120
notion of similarity. If it does not, then, you know, maybe this is a data set for which some other

152
00:14:13,120 --> 00:14:19,520
metric is, or distance is more usable. Again, it's more what you actually see in the data,

153
00:14:19,520 --> 00:14:24,720
it's not about the theory that says, oh yes, you know, this is the one you want to use.

154
00:14:24,720 --> 00:14:30,480
Okay. Got it. So you define this distance metric and apply it to the data and then what?

155
00:14:30,480 --> 00:14:35,920
And then what? So now, what we want to do is, well, we have a projection of the data set,

156
00:14:35,920 --> 00:14:41,120
which, and I won't go into detail on that, Scott, but basically what we do is we find we've been

157
00:14:41,120 --> 00:14:46,400
the data set into overlapping bins. We do that in a systematic way, and it has to do with a

158
00:14:46,400 --> 00:14:52,160
projection of some kind. And once that's done, we perform a clustering step within each of those

159
00:14:52,160 --> 00:15:00,080
bins. Each cluster is now made the node of a network, and we connect to nodes if they share a

160
00:15:00,080 --> 00:15:06,720
data point. So, you know, that's a short version of it. But it's a kind of what we call partial

161
00:15:06,720 --> 00:15:11,040
clustering. They say we don't apply clustering to the whole data set. We apply it to a bunch of

162
00:15:11,040 --> 00:15:16,560
pieces, and those produce points for a network or nodes for a network. Okay. Makes sense.

163
00:15:16,560 --> 00:15:21,920
It does. It almost, it makes me think of a number of things, things like word embeddings.

164
00:15:21,920 --> 00:15:26,800
It makes me think of things like, I don't even know what, I don't remember the general

165
00:15:27,440 --> 00:15:33,600
terminology for it, but there's a company called cortical or nementa. Like they, they do something

166
00:15:33,600 --> 00:15:40,160
similar to word embeddings. It kind of evokes that for me, but it also evokes for me like a

167
00:15:40,160 --> 00:15:44,800
convolutional neuron that where you're like a windowing your bins or kind of like your

168
00:15:44,800 --> 00:15:50,000
convolution windows that you're moving across your image. It is a little bit, I think they're,

169
00:15:50,000 --> 00:15:54,880
actually, I think there are a lot of connections with that. We're just starting to develop those

170
00:15:54,880 --> 00:16:00,320
now. So, you know, it's a slightly different, it goes through a part of this whole TDA business,

171
00:16:00,320 --> 00:16:04,400
which we haven't talked about, which is about measuring shape through what's called persistent

172
00:16:04,400 --> 00:16:10,880
homology. And, you know, that's, this is a very kind of, it's always been regarded as the most

173
00:16:10,880 --> 00:16:17,840
esoteric part of mathematics for reasons that are kind of quite necessary to it, but nevertheless,

174
00:16:17,840 --> 00:16:21,760
it's very powerful. It allows you to measure shape. It allows you to say, look, is there a loop

175
00:16:21,760 --> 00:16:26,480
in your data? Is there a sphere in your data? You know, are there connected components in your,

176
00:16:26,480 --> 00:16:30,960
all those kind of things that we think about? It allows you to actually measure those in a formal way.

177
00:16:32,160 --> 00:16:37,360
So, this, this last step you describe your, taking your, your bins and I, I heard that is a

178
00:16:37,360 --> 00:16:42,560
windowing kind of effective. It's kind of, it's key that the bins be overlapping. In this case,

179
00:16:42,560 --> 00:16:46,400
that not that they'd be this joint is key that they'd be overlapping. Okay. Because we want the

180
00:16:46,400 --> 00:16:51,040
clusters to have the ability to overlap so we can draw edges between them. Yeah. Okay. Yeah.

181
00:16:51,680 --> 00:16:56,160
So, then tell me where you, what you do with your distance metric once you have these

182
00:16:56,160 --> 00:17:00,880
bins. Actually, now we, that's how we use, that we only use the distance metric so to be able to

183
00:17:00,880 --> 00:17:05,920
get the bins. Okay. And perform clustering within the bins. Got it. Once I've performed clustering

184
00:17:05,920 --> 00:17:11,840
within the bins, you know, at this point, I can, for the time being, shelve the, the metric and say,

185
00:17:11,840 --> 00:17:17,040
look, the representation I'm interested in, which can be thought of as a generalized Venn diagram.

186
00:17:17,040 --> 00:17:20,880
If you like, you know, is this network model and this network model is something that we now want

187
00:17:20,880 --> 00:17:26,480
to examine. Okay. All right. So let's talk a little bit more about that examination process. That

188
00:17:26,480 --> 00:17:31,040
sounds like that's what's next. That's right. So, so let me say, by the way, first of all, that I'm

189
00:17:31,040 --> 00:17:34,880
going to, what I'm going to describe is sort of the way to sort of interact with the model,

190
00:17:34,880 --> 00:17:40,160
you know, visually and on the screen and so on. But one can also interact with it programmatically.

191
00:17:40,160 --> 00:17:45,280
And that's what one wants to do to build applications, ultimately. But, you know, for some kind of,

192
00:17:45,280 --> 00:17:52,080
some manual data analysis, what one does is one puts the network on a screen through a layout

193
00:17:52,080 --> 00:17:57,680
algorithm. And now there's lots of things that capabilities that you have, you're able to select

194
00:17:57,680 --> 00:18:02,160
parts of the network the way you would in Photoshop or Illustrator. And once I do that, I can

195
00:18:02,160 --> 00:18:06,720
make that into a set of data points because the nodes correspond to collections of data points.

196
00:18:06,720 --> 00:18:13,040
Okay. So now I have new sets that I can either perform other analysis on or I can ask for their

197
00:18:13,040 --> 00:18:19,360
explanation. That is to say, what is, what are the features that characterize this subset?

198
00:18:19,360 --> 00:18:24,560
And that's done in an appropriate mathematical and statistical sense. You know, there are some

199
00:18:24,560 --> 00:18:29,440
choices on that, but we've made one particular choice. But now what's that choice? And one of the

200
00:18:29,440 --> 00:18:34,960
same choices. Well, the main thing is that we're deciding we're selecting, you know, we have

201
00:18:34,960 --> 00:18:39,760
distributions on the group of a particular variable on the groups. And the question is to choose

202
00:18:39,760 --> 00:18:44,800
those variables, which are maximally different in terms of a so-called Comma-Gorov-Smirinov

203
00:18:44,800 --> 00:18:49,360
distance on distributions. I'm just saying that I think there are other notions of distance on

204
00:18:49,360 --> 00:18:55,600
distributions one could use to list those. And so when you say you've made that choice, you mean

205
00:18:56,320 --> 00:19:01,680
in a given use case, you've selected one of many or the company's approach. The company's

206
00:19:01,680 --> 00:19:05,920
approach is that one. Got it. That's right. Okay. That's right. But it tends to do a good job of

207
00:19:05,920 --> 00:19:10,720
maximizing the distance for the cluster problems that you're going off. It does. We find that again,

208
00:19:10,720 --> 00:19:16,160
yes, we find that the explain capability is quite useful. It works well. Okay. Yeah. Okay. Yeah.

209
00:19:16,160 --> 00:19:20,080
So anyway, so that's something one can do with it. You can actually color by quantities of

210
00:19:20,080 --> 00:19:25,280
interest. So if I'm interested in things like revenue new or survival or whatever it is,

211
00:19:25,280 --> 00:19:31,600
I can color a node by the average value of quantity for each of the data points. And so that

212
00:19:31,600 --> 00:19:36,720
becomes quite informative. And often what you see in the network is collections of hot spots,

213
00:19:36,720 --> 00:19:42,000
you know, where some values high and more than one place. And it turns out that they're different,

214
00:19:42,000 --> 00:19:46,880
they're high there for different reasons often. And that's what's quite why the network is so

215
00:19:46,880 --> 00:19:51,360
informative. Because otherwise you would just take any aggregate you would study this quantity. And

216
00:19:51,360 --> 00:19:56,720
since you're then, you know, putting together all the different ways in which that thing goes

217
00:19:56,720 --> 00:20:01,120
high, you can't understand. You can't make sense of it in the way that you can when it's

218
00:20:01,120 --> 00:20:07,360
split out like that. You've mentioned that that's this kind of ad hoc interaction with the

219
00:20:07,360 --> 00:20:13,200
model is just one of one way to interact with the model. But the way you describe that makes me think

220
00:20:13,200 --> 00:20:20,000
of use cases like forensic types of use cases like I associate with a company like Palantir. Do

221
00:20:20,000 --> 00:20:26,080
you overlap with with them and the types of use cases you go after? Yeah. So, you know,

222
00:20:26,080 --> 00:20:30,560
I think the answer is we don't fully know the interconnection. We know, I mean, what they're doing

223
00:20:30,560 --> 00:20:35,520
is to sort of searching data that comes as a network. You know what I mean? Whereas in our case,

224
00:20:35,520 --> 00:20:40,640
we're saying, well, actually all data can be represented as networks. And it provides a compression.

225
00:20:40,640 --> 00:20:45,360
I actually think there are connections there between those things that could make things efficient. But

226
00:20:45,360 --> 00:20:49,920
wouldn't want to speak to them because I don't, sorry, I don't have firm ideas in mind.

227
00:20:49,920 --> 00:20:55,120
Do you tend to find yourself pursuing a lot of forensic types of use cases? Or, you know,

228
00:20:55,120 --> 00:21:01,440
at the moment, we have been focusing on, you know, health care and financial services. We are

229
00:21:01,440 --> 00:21:07,200
moving back into government in various ways. And so we may very well hit that. Okay. So we talked

230
00:21:07,200 --> 00:21:12,000
a little bit about this, the ways that you can interact with this network that's created out of the

231
00:21:12,000 --> 00:21:17,520
data. How else can you use these models? So, you know, another thing that one could do is suppose

232
00:21:17,520 --> 00:21:23,120
that you have a linear regression or predictive model. Most likely, you know, it's gotten by

233
00:21:23,120 --> 00:21:28,400
optimizing something and some kind of error function. But it's probably not also not perfect. It's

234
00:21:28,400 --> 00:21:33,920
probably also the case that there are some areas within your data set, you know, some particular

235
00:21:33,920 --> 00:21:38,240
phenomena that happen that make that there are some systematic errors that happen. You know,

236
00:21:38,240 --> 00:21:42,960
you can't correct them within your own model and with the features that you've got. But what it

237
00:21:42,960 --> 00:21:47,920
allows us to do is it allows us to say, let's take a network and let's color it by that model error.

238
00:21:47,920 --> 00:21:52,400
Maybe we find some hot spots for model error. And maybe I try to correct around those hot spots

239
00:21:52,400 --> 00:21:56,640
by adding features somehow. So that's another point of view. I would put it under the general

240
00:21:56,640 --> 00:22:04,080
heading of model diagnosis and model improvement. So that's another situation. Interesting.

241
00:22:04,080 --> 00:22:08,080
You mentioned health care. What are some of the use cases in health care? So we have something

242
00:22:08,080 --> 00:22:14,320
called clinical variation management, which, you know, helps study both finding new and optimizing

243
00:22:14,320 --> 00:22:20,000
care pads for particular, you know, procedures as well as tracking adherence to them. We have a

244
00:22:20,000 --> 00:22:25,120
population health kind of application that is working on trying to understand trends in

245
00:22:25,120 --> 00:22:31,680
population health. Who is going to go to the 5% group who are the most expensive? Who, you know,

246
00:22:31,680 --> 00:22:37,840
is getting these on track to go bad and how can we improve their chances? That's a couple of

247
00:22:37,840 --> 00:22:42,160
things. There are some on the financial side as well. We work with hospitals as well as payers

248
00:22:42,160 --> 00:22:48,000
and the, you know, providers as well as payers and the health care side. And can you maybe just to

249
00:22:48,000 --> 00:22:54,480
kind of tie all the terminology together? Maybe pick one of those examples and walk us through,

250
00:22:55,120 --> 00:23:00,480
you know, what the data tends to look like, what the clusters might represent, what are some of

251
00:23:00,480 --> 00:23:06,240
the findings that someone might see? Yeah. So let's talk about the clinical variation management,

252
00:23:06,240 --> 00:23:11,840
for example. So, you know, the data there consists basically in all the events that happen during

253
00:23:11,840 --> 00:23:16,480
the course of someone's stay. Say for some particular surgical procedure, lie in the replacement,

254
00:23:16,480 --> 00:23:22,320
like bowel surgery and so forth. And so, what one can then do is one needs to put on, you know,

255
00:23:22,320 --> 00:23:26,800
that set of things, some appropriate similarity measure and that, you know, distance function.

256
00:23:26,800 --> 00:23:32,160
And that turns out to be, you know, quite a tricky, interesting problem. Probably maybe the key

257
00:23:32,160 --> 00:23:38,240
part in solving that problem. And then ultimately it produces for us then sort of a consensus

258
00:23:38,240 --> 00:23:45,040
care pass, maybe a few hair paths that are very good and one consensus together with some explanations

259
00:23:45,040 --> 00:23:50,320
of what are the key features that differentiate it from others. So it's almost allowing you to

260
00:23:50,960 --> 00:23:58,000
identify, you know, which outcomes or which features of the care, if you will, kind of correlated

261
00:23:58,000 --> 00:24:04,080
with success and, you know, maybe where some outliers are. And the features might be, you know,

262
00:24:04,080 --> 00:24:08,560
what drugs are administered, what doses they're administered, when they're administered,

263
00:24:08,560 --> 00:24:13,120
things like that. That's exactly right. And just to give you a sense of how it can work in one

264
00:24:13,120 --> 00:24:17,600
situation. When hospital systems are deciding on care paths, what they usually do is they get

265
00:24:17,600 --> 00:24:23,920
together sort of the people, the smartest people that they can say who are working on this and they

266
00:24:23,920 --> 00:24:28,640
get together in a room and they discuss it out and, you know, ultimately come to some kind of

267
00:24:28,640 --> 00:24:33,120
answer about what it should be. There are a couple of problems with that model, you know, you may,

268
00:24:33,120 --> 00:24:36,640
and maybe you haven't found all the best people who are doing this procedure. Maybe you haven't

269
00:24:36,640 --> 00:24:41,040
chosen exactly the right group. And anyway, it's also the case that when people are just sort of

270
00:24:41,040 --> 00:24:46,240
arguing things out in a room, sometimes, you know, it's the strongest personality rather than the

271
00:24:46,240 --> 00:24:50,000
strongest case that comes out. So there's all sorts of issues with that. I think there's like

272
00:24:50,000 --> 00:24:56,160
implicit versus explicit knowledge, right? I mean, there could just be things that some people do

273
00:24:56,160 --> 00:24:59,840
and they don't really realize that that's that they're doing it different from the other doctors.

274
00:24:59,840 --> 00:25:04,240
And so they don't know to argue it. Exactly. And then so in fact, that was, you know, what happened

275
00:25:04,240 --> 00:25:09,920
for us with one of our customers was, you know, exactly some of that. We found that for one

276
00:25:09,920 --> 00:25:14,400
surgical procedure, there was a group, a small group kind of out in the periphery of the system

277
00:25:14,400 --> 00:25:19,840
that people hadn't really observed so much, but they were doing something that had good improved

278
00:25:19,840 --> 00:25:25,840
effect on length of stay. Okay. And so, you know, so that was found. That was, you know, quite an

279
00:25:25,840 --> 00:25:30,720
important contribution to them. So even just in terms of kind of a search thing like that, it was

280
00:25:30,720 --> 00:25:37,680
quite quite useful that way. Interesting. So if someone wants to learn more about this, it sounds

281
00:25:37,680 --> 00:25:43,040
like there's, it sounds like topology is, you know, an interesting place to start. Like what,

282
00:25:43,040 --> 00:25:49,760
is there a canonical paper or a reference? Let me warn you that of course, if you go to study

283
00:25:49,760 --> 00:25:56,720
topology, you'll be involved for years before you get to the case. So, so I wouldn't necessarily,

284
00:25:56,720 --> 00:26:01,520
I mean, one could certainly read some things about it. But what I would say is, well, first of all,

285
00:26:01,520 --> 00:26:05,200
our company has a lot of stuff on the web, on its website, basically, you can sort of acknowledge

286
00:26:05,200 --> 00:26:11,040
Center a lot of technical papers and somewhat less technical as well. So I would kind of recommend

287
00:26:11,040 --> 00:26:16,480
the reading survey paper route as opposed to, you know, taking a textbook and kind of chugging through.

288
00:26:17,600 --> 00:26:22,480
Because this is a newly developing subject. And so, there are some textbooks in this persistent

289
00:26:22,480 --> 00:26:28,320
homology side that I talked about. But, you know, the general notion of topological modeling,

290
00:26:28,320 --> 00:26:34,160
you know, I think we have a lot of stuff on our web creating it. But actually come to think of it.

291
00:26:34,160 --> 00:26:40,320
Oh, here we do have my colleague, FX Campion, Francis Campion, and I have written a book,

292
00:26:40,320 --> 00:26:44,960
which is called Machine Intelligence for Healthcare. And so, it's available on Amazon, you know,

293
00:26:44,960 --> 00:26:49,760
and I recommend that it's got the first half is kind of a discussion of this mathematical modeling.

294
00:26:49,760 --> 00:26:53,600
And then the second half is specifically, how does this work in healthcare?

295
00:26:53,600 --> 00:26:59,440
Okay. So, that sounds really interesting. Yeah. And did you elaborate on persistent

296
00:26:59,440 --> 00:27:06,080
homology? Or did we, you know, I think we had to get, it's, let me just say that it is, it is a

297
00:27:06,080 --> 00:27:13,920
very interesting way of sort of detecting shape features, certain kinds of shape features in the

298
00:27:13,920 --> 00:27:19,280
data. And as it is, you know, on the pure math side, it detects features in, you know, in regular

299
00:27:19,280 --> 00:27:23,280
spaces, spaces with complete information and where you've got the whole, the whole thing.

300
00:27:23,840 --> 00:27:28,640
It can be used in two ways. The one way is it can be used as a way of recognizing what the

301
00:27:28,640 --> 00:27:34,480
overall organization of the data set is, you know, is it, we found that, for example, in studying some

302
00:27:34,480 --> 00:27:39,680
image processing data sets that, you know, the frequently occurring phenomena in three by three

303
00:27:39,680 --> 00:27:45,680
patches lined around, you know, one circumstance, the circle in a slightly higher, you know,

304
00:27:45,680 --> 00:27:49,920
level, understand around a mathematical object called a climb model, which is, you know, very,

305
00:27:49,920 --> 00:27:55,200
it was very interesting for us. We used it for understanding image compression and also texture

306
00:27:55,200 --> 00:27:59,920
recognition. So that was quite interesting. The second thing, though, is that it can be used,

307
00:27:59,920 --> 00:28:05,280
and this I think is going to be a much more rapid application is where it gets used to generate

308
00:28:05,280 --> 00:28:11,440
features in unstructured data. So when you have data that is complicated, but that somehow carries

309
00:28:11,440 --> 00:28:15,760
a notion of distance on it, like molecules, you know, where the atoms can be regarded as the

310
00:28:15,760 --> 00:28:21,600
points in the distance has to do with the bonds, then you can attach, so-called persistence

311
00:28:21,600 --> 00:28:26,560
barcodes to those points, and that's quite useful in organizing and understanding, you know,

312
00:28:26,560 --> 00:28:32,960
those kind of unstructured databases, databases of unstructured data. Interesting. You mentioned

313
00:28:33,920 --> 00:28:41,120
earlier, and I saw it in the description of your session as well, something that I think is

314
00:28:41,120 --> 00:28:45,520
related to this, like identifying loops in data. What does that even mean, loops in data?

315
00:28:45,520 --> 00:28:50,560
Well, imagine, you know, I had a slide, imagine that you have a picture, you see your data,

316
00:28:50,560 --> 00:28:55,680
suppose the data is actually in 2D, and supposing that you've got a bunch of dots,

317
00:28:55,680 --> 00:29:00,480
so the data is a bunch of dots, and it looks like it's kind of surrounding, like it's a circle,

318
00:29:00,480 --> 00:29:05,120
we see it as a circle. Right, right. So something that like a clustering algorithm

319
00:29:05,120 --> 00:29:10,480
doesn't really know how to deal with very well, but you can identify this higher order primitive,

320
00:29:10,480 --> 00:29:16,240
that hey, this is a, like a geometrical primitive, essentially. Exactly. That's exactly right,

321
00:29:16,240 --> 00:29:19,840
and that's what we're trying to do. We're trying to mimic that fact. You know, we know what a loop

322
00:29:19,840 --> 00:29:25,680
looks like, but we don't know what it is our brain does to recognize that, and so therefore,

323
00:29:25,680 --> 00:29:31,120
you do this homology. So imagine that you're trying to understand how do you recognize a letter A

324
00:29:31,120 --> 00:29:37,440
from a letter B. Right. That letter A has two loops, sorry, a loop and two legs, and the B has two

325
00:29:37,440 --> 00:29:43,440
loops in it. So if you can find something that counts for you, the number of loops, you're going to

326
00:29:43,440 --> 00:29:47,440
be able to characterize letter A from a letter B, you'll be able to differentiate it, and you'll

327
00:29:47,440 --> 00:29:52,080
be able to differentiate it in a way that's font independent. That's independent of the fact that

328
00:29:52,080 --> 00:29:56,800
you see it from, you know, one from an angle, perhaps, or that it's sitting in the surface of a

329
00:29:56,800 --> 00:30:01,840
soccer ball. It's kind of, it's miraculously kind of deformation. It doesn't, it doesn't, it's not

330
00:30:01,840 --> 00:30:07,520
sensitive to those deformations, and that's what homology is. And so that sounds promising,

331
00:30:07,520 --> 00:30:13,520
but it also sounds, I guess I think about it in the context of deep learning, right? A deep learning

332
00:30:13,520 --> 00:30:18,160
purist would say, well, you know, it's going to be a lot easier to just throw tons and tons of data

333
00:30:18,160 --> 00:30:25,120
that have like all different kinds of Bs, you know, and A's, and just let the network teach it.

334
00:30:25,120 --> 00:30:31,280
And I've had this conversation with some folks that specialize in deep learning around

335
00:30:31,920 --> 00:30:38,320
combining other approaches to create higher level insights with the deep learning. And one of the

336
00:30:38,320 --> 00:30:43,120
entrances, I just throw the data at it, and I think I'll figure it out. Of course, what you find is that,

337
00:30:43,120 --> 00:30:47,760
you know, they're adversarial approaches to that way, you know, so, you know, even for something as

338
00:30:47,760 --> 00:30:53,840
simple as MNIST, the MNIST dataset, which is of hand drawn numbers, where you find that if you

339
00:30:53,840 --> 00:30:58,800
just mess with the background a little bit, in a way that, you know, people wouldn't see the

340
00:30:58,800 --> 00:31:03,040
difference. People will see that, you know, a one is a one and a two is a two, but it messes up

341
00:31:03,040 --> 00:31:09,520
the deep learner. Oh, yeah, absolutely. And that's a feature question. You see, it's doing a certain kind

342
00:31:10,720 --> 00:31:16,080
overfitting is perhaps the wrong term, but it's focusing on some features that have to do with

343
00:31:16,080 --> 00:31:21,200
the background that are not really relevant. And so to the extent that you can feed it features

344
00:31:21,200 --> 00:31:26,000
that are kind of background independent like that, then you're in good shape. And that's what persistent

345
00:31:26,000 --> 00:31:31,120
homology is a perfect tool for providing features to a deep learner, because in fact,

346
00:31:31,120 --> 00:31:35,520
the output of the persistence thing can be regarded as an image, so it kind of fits

347
00:31:35,520 --> 00:31:42,800
directly into that. So, yeah. Is this an application in like theory, in theory, in principle,

348
00:31:42,800 --> 00:31:50,560
or are there demonstrable situations using, you know, MNIST or some other dataset that says

349
00:31:50,560 --> 00:31:55,680
persistent homology outperforms deep learning or has some cost benefit analysis relative?

350
00:31:55,680 --> 00:31:59,520
Well, remember, it's not outperforming deep learning. It is feeding into deep learning and

351
00:31:59,520 --> 00:32:05,120
using it. So, the example I would point to. So, we're using the persistent homology to create

352
00:32:05,120 --> 00:32:11,280
features that either replace the raw images or augment the raw images, and then we're still

353
00:32:11,280 --> 00:32:16,240
using deep learning to learn. That's correct. Got it. That's correct. Now, again, most of this is

354
00:32:16,240 --> 00:32:21,440
sort of looking into the future. However, this exact thing has been carried out by, you know,

355
00:32:21,440 --> 00:32:27,120
a friend of mine or a colleague of mine at Michigan State in a gooey way, who has taken databases

356
00:32:27,120 --> 00:32:32,560
of molecules, you know, candidates for drugs, you know, and kind of drug discovery, and build

357
00:32:32,560 --> 00:32:37,440
persistent homology barcodes on them, and then use those, use deep learning on those,

358
00:32:37,440 --> 00:32:42,320
extremely successfully. Okay. All right. I'll ask you afterwards for the spelling of that name

359
00:32:42,320 --> 00:32:46,560
so we can... Sure. I'll write it down for you. Yeah. Included. That's right. Awesome.

360
00:32:46,560 --> 00:32:53,280
Well, it was great to have you here. I learned a ton, and I feel like there's so much more to

361
00:32:53,280 --> 00:32:58,240
learn about this stuff. There's a lot to learn. I feel that way every day. So, and you know,

362
00:32:58,240 --> 00:33:01,840
thanks very much. I enjoyed the conversation. Great. Thanks a ton. Sorry. Thank you.

363
00:33:05,520 --> 00:33:11,760
All right, everyone. That's our show for today. Thanks so much for listening, and of course,

364
00:33:11,760 --> 00:33:17,840
for your ongoing feedback and support. For more information on Gunner and any of the other topics

365
00:33:17,840 --> 00:33:25,920
covered in this episode, head on over to twomolei.com slash talk slash 53. For the rest of this series,

366
00:33:25,920 --> 00:33:34,560
head over to twomolei.com slash AI SF 2017. And please, please, please send us any questions or

367
00:33:34,560 --> 00:33:41,600
comments that you may have for us or our guests via Twitter, at twomolei or at Sam Charrington,

368
00:33:42,240 --> 00:33:47,520
or leave a comment on the show notes page. There are a ton of great conferences coming up

369
00:33:47,520 --> 00:33:52,800
through the end of the year to stay up to date on which events will be attending. And hopefully,

370
00:33:52,800 --> 00:33:59,360
to meet us there, check out our new events page at twomolei.com slash events,

371
00:33:59,360 --> 00:34:20,320
twomolei.com slash events. Thanks again for listening, and catch you next time.

