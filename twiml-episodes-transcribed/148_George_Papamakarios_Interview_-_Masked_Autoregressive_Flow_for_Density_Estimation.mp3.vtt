WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:31.340
I'm your host Sam Charrington.

00:31.340 --> 00:36.960
In this episode, University of Edinburgh PhD student George Papa Mercarios and I discuss

00:36.960 --> 00:41.760
his paper, Masked Autoregressive Flow for Density Estimation.

00:41.760 --> 00:46.040
George walks us through the idea of Masked Autoregressive Flow, which uses neural networks

00:46.040 --> 00:51.000
to produce estimates of probability densities from a set of input examples.

00:51.000 --> 00:55.080
We discuss some of the related work that's laid the groundwork for his research, including

00:55.080 --> 01:00.440
inverse autoregressive flow, real MVP and masked auto encoders.

01:00.440 --> 01:04.440
We also look at some of the properties of probability density networks and discuss some

01:04.440 --> 01:08.440
of the challenges associated with this effort.

01:08.440 --> 01:13.640
This Friday, June 1st, we'll begin working through the fast AI practical deep learning

01:13.640 --> 01:15.280
for coders course.

01:15.280 --> 01:19.360
A bunch of you have already signed up and the Slack channel has been hosting some very

01:19.360 --> 01:21.440
lively discussion.

01:21.440 --> 01:25.920
If you'd like to learn deep learning with us, there are just three simple steps to join.

01:25.920 --> 01:31.960
First, sign up for the meetup at tumma.ai.com slash meetup, noting fast.ai in the what

01:31.960 --> 01:33.840
you hope to learn box.

01:33.840 --> 01:38.400
Second, use the email invitation you'll receive to join our Slack group.

01:38.400 --> 01:42.800
And third, once you're there, join the fast AI channel.

01:42.800 --> 01:46.600
I'll be publishing some additional information about how we'll work through the course and

01:46.600 --> 01:49.160
the next day or so, so stay tuned.

01:49.160 --> 01:54.120
If you have questions, feel free to shoot me a message on Twitter at Sam Charrington or

01:54.120 --> 01:57.280
via the contact form at tumma.ai.com.

01:57.280 --> 01:58.280
See you soon.

01:58.280 --> 02:03.360
Finally, we continue to celebrate the second anniversary of the podcast and we want to

02:03.360 --> 02:04.520
hear from you.

02:04.520 --> 02:06.200
Have you found this podcast useful?

02:06.200 --> 02:08.800
If so, we want to hear how.

02:08.800 --> 02:13.840
Post a comment over at tumma.ai.com slash 2av to let us know.

02:13.840 --> 02:20.200
And now on to the show.

02:20.200 --> 02:21.200
All right, everyone.

02:21.200 --> 02:24.920
I am here at Nips and I'm with George Papamacarios.

02:24.920 --> 02:27.440
Good to be here.

02:27.440 --> 02:33.080
George is a PhD student at the School of Informatics at the University of Edinburgh.

02:33.080 --> 02:39.960
And he's here at Nips, having just presented a paper on mast auto regressive flow for

02:39.960 --> 02:40.960
a density estimation.

02:40.960 --> 02:43.880
And I'm looking forward to learning more about what that's all about.

02:43.880 --> 02:45.400
George, welcome.

02:45.400 --> 02:46.400
Great to be here.

02:46.400 --> 02:47.400
Thanks for inviting.

02:47.400 --> 02:48.400
Absolutely.

02:48.400 --> 02:50.320
So, you're in the School of Informatics.

02:50.320 --> 02:55.680
How did you get involved in, you know, what's the intersection between Informatics and,

02:55.680 --> 02:59.880
you know, your research and how did you come to get interested in machine learning?

02:59.880 --> 03:03.280
Informatics is quite a general time.

03:03.280 --> 03:11.200
In Edinburgh, where I'm doing my PhD, the School of Informatics, essentially came to be

03:11.200 --> 03:17.760
by combining computer science, artificial intelligence, and cognitive science, and an

03:17.760 --> 03:23.040
umbrella term for everything that has to with information, either artificial information

03:23.040 --> 03:28.160
or, you know, natural information, came to be known as Informatics.

03:28.160 --> 03:31.520
So my background, though, was in, actually, was in electrical engineering.

03:31.520 --> 03:35.480
So I did my undergraduate studies in electrical engineering.

03:35.480 --> 03:41.720
And then I, after I graduated, I was working as a research assistant doing computer vision.

03:41.720 --> 03:45.560
And I was actually working in a project where it was a fun project.

03:45.560 --> 03:51.280
We were trying to detect activities and classify activities.

03:51.280 --> 03:53.440
So we had, in smart homes.

03:53.440 --> 03:59.440
So we had, we put sensors and cameras in, you know, people's flats.

03:59.440 --> 04:05.280
And we could, you know, take measurements such as temperature and humidity, and we could

04:05.280 --> 04:07.560
track the person's location in the flat.

04:07.560 --> 04:11.360
And we wanted to infer what they were doing.

04:11.360 --> 04:16.440
Were they sleeping, watching television, doing the dishes, eating, et cetera.

04:16.440 --> 04:18.080
And that was a fun project.

04:18.080 --> 04:24.320
But it became obvious to me that it was very difficult to, you know, to figure out what

04:24.320 --> 04:26.760
the person was doing and being certain about it.

04:26.760 --> 04:27.760
Right.

04:27.760 --> 04:29.920
Because they could be doing anything, right?

04:29.920 --> 04:33.240
Does it write in temperature mean, for instance?

04:33.240 --> 04:40.720
And so that's how I got into machine learning and tried to infer information from data in

04:40.720 --> 04:46.160
a more principled way, and trying to quantify the uncertainty of that information.

04:46.160 --> 04:50.640
For instance, a person might be doing, you know, might be doing the dishes, but I was

04:50.640 --> 04:52.680
sure that they're doing the dishes.

04:52.680 --> 04:53.680
Or maybe I'll be cooking.

04:53.680 --> 04:54.680
Or maybe they're cooking.

04:54.680 --> 04:58.400
Or have to be, we have to be able to quantify uncertainty.

04:58.400 --> 05:02.800
That's how I got into machine learning and in particular, based in inference.

05:02.800 --> 05:06.560
And that's what brought me to Edinburgh to a PhD.

05:06.560 --> 05:10.680
How is that interest kind of flowed into your current line of research?

05:10.680 --> 05:19.880
So my, so I got interested in based in inference, which is a principled way of making predictions

05:19.880 --> 05:23.000
at the same time, quantifying uncertainty.

05:23.000 --> 05:28.160
And this has all to do with, you know, probability distributions and probability densities.

05:28.160 --> 05:32.680
And, you know, a lot of probabilistic modeling.

05:32.680 --> 05:36.400
And it's difficult to get these probabilities.

05:36.400 --> 05:42.760
We have to, how do we, how do we obtain the probability of data in the first place?

05:42.760 --> 05:50.160
And that's what brought me into doing research in density estimation, which is what my,

05:50.160 --> 05:56.080
which is what the research I'm presenting here at NIPS is about.

05:56.080 --> 05:59.960
And here we're talking about probability densities as opposed to material.

05:59.960 --> 06:00.960
That's correct.

06:00.960 --> 06:02.040
That's correct.

06:02.040 --> 06:09.240
And so the technique you're using to estimate probability densities is mass, autoregressive

06:09.240 --> 06:10.240
flow.

06:10.240 --> 06:11.240
What does that mean?

06:11.240 --> 06:12.240
That's correct.

06:12.240 --> 06:15.520
So, mass autoregressive flow is, it's a deep neural network.

06:15.520 --> 06:16.520
That's why it is.

06:16.520 --> 06:23.200
So, it's a deep neural network, which takes data point, could be an image, could be a

06:23.200 --> 06:30.160
time series, could be a piece of information, and spits out a number.

06:30.160 --> 06:35.440
And that number is the probability density associated with this data point.

06:35.440 --> 06:40.640
Essentially, it's a score that says how likely is this data point.

06:40.640 --> 06:46.120
For instance, if I'm trying to learn the probability density of our images, an actual

06:46.120 --> 06:51.360
image, like say an image of a person, I would score high so that the network would return

06:51.360 --> 06:53.240
a high score.

06:53.240 --> 06:59.320
And a random image, an image of random noise would return almost zero score.

06:59.320 --> 07:05.600
That tells you how plausible, how likely the image is, so that's what probability density

07:05.600 --> 07:06.600
is.

07:06.600 --> 07:14.240
And you can learn, you can train such a network directly on data and get an estimate

07:14.240 --> 07:18.240
of what their probability density should be.

07:18.240 --> 07:30.320
And so, the probability density that the network is producing is a vector of, what does it

07:30.320 --> 07:31.320
look like?

07:31.320 --> 07:36.960
I guess, when I think of probability densities, I think of them in terms of, from an analytical

07:36.960 --> 07:42.600
sense, like, is it, you know, it could be a Gaussian with a certain set of parameters

07:42.600 --> 07:46.720
or some other kind of probability function.

07:46.720 --> 07:54.840
Is this telling you the distribution as well as its parameters or is it telling you something

07:54.840 --> 07:55.840
else?

07:55.840 --> 08:01.640
Yeah, there are many ways to go about doing this.

08:01.640 --> 08:07.480
So it could be that the neural network spits out the parameters of a distribution.

08:07.480 --> 08:12.760
For example, if that distribution were a Gaussian, it would spit out the mean and the variance

08:12.760 --> 08:15.800
that Gaussian, which defines that Gaussian.

08:15.800 --> 08:22.800
There are many ways of doing this, the challenge here, so if you chose, let's say, a particular

08:22.800 --> 08:29.080
type of distribution, say, a Gaussian, that network would only be able to spit out

08:29.080 --> 08:30.080
Gaussian's.

08:30.080 --> 08:31.080
Right.

08:31.080 --> 08:38.080
The challenge here is to make it more flexible, because the data might follow a different

08:38.080 --> 08:39.280
distribution, right?

08:39.280 --> 08:45.560
So how can we make it flexible enough so that it can spit out whatever distribution, the

08:45.560 --> 08:48.000
data happens to follow?

08:48.000 --> 08:52.480
And that's the challenge here, and that's what this paper was about, essentially, was

08:52.480 --> 09:00.000
proposing a very flexible mechanism, so a particular architecture that would spit out

09:00.000 --> 09:05.440
parameters that would describe a distribution that was very flexible.

09:05.440 --> 09:11.720
Is it picking from some catalog of distributions that it knows about, or is there a type of

09:11.720 --> 09:19.800
distribution that is essentially high-dimensional, very flexible, lots of parameters that every

09:19.800 --> 09:25.920
other distribution is kind of a degenerate version of, if you will?

09:25.920 --> 09:28.560
It's a bit like, well, it's more like the second one.

09:28.560 --> 09:37.280
So it is parametric, and it is described by a set of parameters, but these parameters

09:37.280 --> 09:39.640
can adapt themselves in what ways.

09:39.640 --> 09:42.400
So they can change, so you can imagine.

09:42.400 --> 09:46.080
They can change in value, or they can change in meaning in a patient.

09:46.080 --> 09:47.080
In value.

09:47.080 --> 09:53.240
So you can imagine a distribution being sort of like a rubber sheet that you put over data,

09:53.240 --> 09:58.520
and you can stretch that and squash it in many ways, and that's what the parameters

09:58.520 --> 09:59.520
describe.

09:59.520 --> 10:06.360
The stretching is the squashing of this flexible object, and by transforming this object,

10:06.360 --> 10:11.040
you can form it into a distribution that fits the data well.

10:11.040 --> 10:12.040
So that's the idea.

10:12.040 --> 10:20.360
This parameters describe how I would need to stretch and bend a simple distribution like

10:20.360 --> 10:23.760
a Gaussian in order to get a complicated distribution.

10:23.760 --> 10:25.520
That's essentially the idea.

10:25.520 --> 10:28.400
What's this distribution called?

10:28.400 --> 10:33.640
This distribution is the model, is mass-totary-gressive flow.

10:33.640 --> 10:42.000
So as part of this research, you identified or created this distribution, but also demonstrated

10:42.000 --> 10:44.480
how to calculate it from a data set.

10:44.480 --> 10:50.240
So mass-totary-gressive flow is essentially this neural network that squashes and stretches

10:50.240 --> 10:55.800
a simple distribution to form it into a more complicated distribution.

10:55.800 --> 10:57.880
It's free to learn what transformation to do.

10:57.880 --> 11:01.880
So you don't know what the end distribution is going to look like.

11:01.880 --> 11:10.200
But you know that the more simple distribution, the starting distribution, you know that.

11:10.200 --> 11:15.880
Just so I'm clear on this, is mass-totary-gressive flow your creation or is that an existing thing

11:15.880 --> 11:17.560
that you then applied to density estimate?

11:17.560 --> 11:24.840
This is my creation, which was inspired by very similar models in the literature.

11:24.840 --> 11:29.480
So there was a model before that, which was very similar, which is called inverse autoregressive

11:29.480 --> 11:36.040
flow, another model, which is called real MVP, and another model, which is called massed

11:36.040 --> 11:38.360
autoencoder for distribution estimation.

11:38.360 --> 11:44.280
So all these are, you know, in the same family of models.

11:44.280 --> 11:52.120
And this one is essentially a continuation of the same idea and an application of previous

11:52.120 --> 11:54.840
ideas in the problem of density estimation.

11:54.840 --> 12:00.440
And the paper, did you, did you base your results on a particular input distribution,

12:00.440 --> 12:04.680
such as a Gaussian, or did you do something else?

12:04.680 --> 12:12.280
The paper did use Gaussian's as, you know, as base distribution, but that's fine because

12:12.280 --> 12:17.080
the idea of these models is that they're not limited by what a distribution you start

12:17.080 --> 12:23.880
with, because if you, you know, form it, if you transform it in many ways, you can in the

12:23.880 --> 12:27.160
end get almost any distribution you like.

12:27.160 --> 12:33.640
So in the paper, what, what we did is we took various data sets, some of which were images,

12:33.640 --> 12:40.360
like MNIST or CIFAR, others were time series, and there were two more data sets that

12:40.360 --> 12:47.800
described collisions in particle physics. So these data sets are all publicly available.

12:48.440 --> 12:56.280
And we trained the same model, so same, same neural networks, same deep model to each one of them,

12:56.280 --> 13:03.880
and saw that it works well across a range of, of domains. So it's not particularly engineered

13:03.880 --> 13:09.720
to work well with images or anything. So one, one of the motivations in the paper was to

13:09.720 --> 13:11.480
demonstrate generality as well.

13:11.480 --> 13:14.120
And what was your metric of working well?

13:14.120 --> 13:22.680
Test log likelihood. So having trained this deep neural network on training data and having,

13:23.560 --> 13:28.840
you know, tried to estimate the probability density in training data,

13:29.640 --> 13:38.920
does that probability density assign high scores to held out data? So this is the metric.

13:38.920 --> 13:44.760
So if we, let's say, have a data set of images, and we know they should all have high scores

13:44.760 --> 13:51.560
because they're all plausible images. And I, I don't use like 10% of them for training,

13:52.760 --> 13:58.920
then the model I learn should assign high scores to these images that I held out as well.

13:58.920 --> 14:01.080
And let me take a step back.

14:01.080 --> 14:05.560
In this case, the, what does it mean to have a score for a given?

14:05.560 --> 14:10.520
It's the, the score is the, the value of the probability density.

14:10.520 --> 14:14.280
The value of the problem, the value of the probability density where?

14:15.160 --> 14:15.880
Or for what?

14:15.880 --> 14:23.640
At the, for that particular data point. So the probability density assigns a value to each data point.

14:23.640 --> 14:29.480
And these values should be high for, for, for data points that are typical,

14:29.480 --> 14:36.680
natural looking, if, if we're talking about images, and very small, unlikely objects.

14:36.680 --> 14:42.760
So in the case of your test data, you've got an image, a complete image. And when you talk about

14:42.760 --> 14:49.160
the score, are we looking at like an arbitrary pixel and the, the probability value for,

14:49.160 --> 14:54.520
we're looking at the whole image, the whole image. And so kind of an, an average score across

14:54.520 --> 15:00.360
all of the pixels or kind of, yeah, kind of, kind of each pixel would get an individual score.

15:01.240 --> 15:07.240
And the, the, the product of the scores would be the score of an image.

15:08.120 --> 15:11.880
And so how's this, how would you envision this being applied?

15:11.880 --> 15:16.680
That's a very good question. So, so what, what I described is one

15:17.480 --> 15:21.240
way to do unsupervised learning, right? So in unsupervised learning,

15:21.240 --> 15:27.160
what you have is, what you have data, like unlabeled data, like a bunch of images,

15:27.800 --> 15:32.120
that you downloaded from, from the web. Yeah. And you want to know something about the data.

15:32.120 --> 15:38.440
You don't have a specific, you know, goal in mind. You, you want to learn something about

15:38.440 --> 15:45.480
the structure of the data. So one way of doing this is by density estimation, because the density,

15:45.480 --> 15:51.960
which the probability density that describes the data probabilistically tells you that structure.

15:51.960 --> 15:56.040
So it's one way of doing generative modeling and unsupervised learning.

15:57.240 --> 16:03.400
For example, GANs and VAEs would be similar ways, but slightly different approaches.

16:05.000 --> 16:10.520
But what I'm particularly interested in and the reason I got involved with density estimation

16:10.520 --> 16:17.960
to begin with is for doing inference, as I said at the beginning. The probabilistic way of doing

16:17.960 --> 16:25.800
inference is, you know, recovering distributions of unknown information. So if we want to,

16:25.800 --> 16:30.680
for example, in the, in the examples I was, I was talking about in the beginning,

16:32.440 --> 16:37.960
where you want to infer what activity a person is doing. Mathematically, what you want to recover

16:37.960 --> 16:45.960
is a distribution over possible activities. And you could use these type of models. So these density

16:45.960 --> 16:52.920
estimators, these neural networks that learn densities in order to learn densities over things

16:52.920 --> 16:58.440
that you, that you don't know that you want to recover. So this is, this is my motivation of

16:58.440 --> 17:05.800
using neural density estimation to do probabilistic inference. So I'm thinking of applications that,

17:05.800 --> 17:13.400
you know, we see a lot of, for example, GANs apply to, you've got incomplete images and you're

17:13.400 --> 17:18.440
trying to reconstruct those images in some kind of way and you want to infer some of the missing data.

17:18.440 --> 17:24.200
That's an example of how you might apply this. That would exactly be, yeah. So for example,

17:24.200 --> 17:29.560
you've, you've seen half of the image and you want to know, you want to infer what the other half

17:29.560 --> 17:34.920
would be. So what you want is a distribution or a density. Right. Over the pixels that you haven't

17:34.920 --> 17:44.040
seen, for instance, and that could be done potentially with this kind of models. So the, the density

17:44.040 --> 17:49.960
that you, this, the mass-auto-regressive flow distribution, how many, does that have a fixed

17:49.960 --> 17:54.680
number of parameters or a variable number? It has a fixed number of parameters. This is a

17:54.680 --> 18:00.760
design choice. So it's, it's, it's a neural network, it's a deep neural network, which

18:00.760 --> 18:09.880
essentially implements this transformation of the base density. And the parameters of that neural

18:09.880 --> 18:16.280
network is the parameters of density. So then maybe not parameters in the way we're used to

18:16.280 --> 18:22.040
thinking about them for probability densities, but you know, they are hyperparameters for a neural

18:22.040 --> 18:28.440
network. They are, they are the, the weights and the biases of that neural network. It's, it's

18:28.440 --> 18:33.880
difficult to, to interpret them. Yeah, that was my question. Like, is there like an intuitive,

18:33.880 --> 18:40.440
you know, transformation between those and what we might think of as the, you know, the parameters

18:40.440 --> 18:46.120
of a probability distribution. Yeah. Sounds like no, not really. It's, yeah, yeah. So if we,

18:46.120 --> 18:50.600
let's say if the probability distribution is a Gaussian, then we can interpret the parameters.

18:50.600 --> 18:55.800
So the mean is, you know, the descent multiplication. Right. Yeah, standard deviation is the width.

18:55.800 --> 19:00.920
Right. But now it's difficult to interpret. What, what, what are the parameters of the neural

19:00.920 --> 19:08.360
network that, you know, describes this density do? Yeah, you're right. And so is, is it even correct

19:08.360 --> 19:15.800
to think of this, these parameters as describing a density as opposed to describing a machine that

19:15.800 --> 19:21.080
spits out densities? It's, it's, it's, it's how you think it's, it's, it's, it's, it's, it's mostly

19:21.080 --> 19:29.080
semantics. Yeah. And you can think of them either way. Okay. I think. And so what's the

19:30.200 --> 19:36.920
dimensionality of this parameter space? It's, it's huge. It's, it's, it's, however big you design

19:36.920 --> 19:43.640
your neural network to be. So it's, think of it as, it's, it's, it's a modification over a standard

19:43.640 --> 19:51.000
fit forward neural network. And the parameters are the weights and the biases of this neural network.

19:51.000 --> 19:58.200
So you could have potentially thousands or millions of parameters. And so what, what characterizes

19:58.200 --> 20:09.480
the architecture of this network relative to others? So, um, if I, let's say I take an arbitrary

20:09.480 --> 20:16.280
fit forward neural network, like standard, you know, standard stuff that we use, for example,

20:16.280 --> 20:23.400
for regression. And what we want, if, if we want this network to represent, if we want the output

20:23.400 --> 20:28.360
of this network to represent a probability density, then it has to have some properties.

20:29.080 --> 20:34.120
The first property is that it has to be non negative. And the second property, which,

20:34.120 --> 20:40.920
which is a difficult one, is that it has to, the, or the set of all outputs, the set of all

20:41.640 --> 20:48.920
possible probabilities have to sum to one. And this, these two properties are not, not trivial

20:50.280 --> 20:57.800
to ensure. And that's exactly what the research is about. How, how can we design the architecture

20:57.800 --> 21:02.040
of this neural network? So that's kind of your starting point. Yeah. And you design from there.

21:02.040 --> 21:05.800
Yeah. There are other requirements like, uh, that the outputs have to be continuous. Like,

21:05.800 --> 21:11.480
is that of interest or is that trivial? They will be continuous. And they will be

21:11.480 --> 21:16.600
differentiable because otherwise we wouldn't be able to learn the neural network. So given that,

21:17.480 --> 21:23.160
the, the functions represented by neural networks are differentiable. Yeah. Then, yeah,

21:23.160 --> 21:27.640
this is a requirement for being able to learn it. Right. Well, by learning, I mean, you know,

21:27.640 --> 21:32.840
by training. Yeah. Yeah. So like, what was your, what was your process in

21:32.840 --> 21:39.320
then architecting a network to meet these criteria? There is a, uh, there is a line of research.

21:40.280 --> 21:48.760
For instance, the, uh, the methods I, I mentioned before. So essentially, we, we continued from,

21:49.400 --> 21:55.320
you know, rely on the shoulders of giants. Sure. People have, they've been there before you.

21:55.320 --> 22:03.960
Um, so there were, in the literature, there were two types, um, of models. The first one

22:05.160 --> 22:10.760
is called autoregressive model. And the second one, the second one is called a normalizing flow.

22:11.880 --> 22:19.320
Um, and these were, these are ideas of how to design the neural networks to satisfy these

22:19.320 --> 22:25.480
requirements. So what are these individual ideas mean or represent? Yeah. So the, the, the

22:25.480 --> 22:34.520
autoregressive, um, model is essentially a, it's a neural net that has as many outputs as inputs.

22:35.640 --> 22:41.880
And each output is, uh, the parameters of a simple density of the corresponding input.

22:41.880 --> 22:50.200
So for instance, the, the first input would be a mean and a variance of a Gaussian for the,

22:50.200 --> 22:54.040
uh, so the first output would be a mean and a variance of a Gaussian for the first input.

22:54.040 --> 22:59.000
And the second output would be a mean and a variance of a Gaussian for the second input.

22:59.560 --> 23:06.680
So they essentially break down the problem in estimating simple, simple densities for each

23:06.680 --> 23:13.480
variable for, for each input. If they, if the input were an image, then that would be individual

23:13.480 --> 23:20.440
densities over each pixel. So they break down the problem, the problem of estimating,

23:20.440 --> 23:26.760
enjoying density of all inputs into the simpler problem of estimating a density of one,

23:26.760 --> 23:32.600
of only one input at a time. So that's, that's the idea. Do you keep the parameters at each

23:32.600 --> 23:37.480
level, or are you only keeping ones at the end? Or you keep, uh, keep all of them, right? Yeah,

23:37.480 --> 23:42.200
that's your, yeah, so your information comes from. Exactly. Okay. Got it. Um, yeah. So the collection

23:42.200 --> 23:47.880
of all of them, right, describes your density. Okay. So that's auto-aggressive models. And the,

23:47.880 --> 23:56.520
and, uh, there are many examples. So wave units is, is a model like this. Okay. Pixel RNN is a

23:56.520 --> 24:02.680
model like this. Pixel RNN. So these, these, these, these models are great learning complex

24:02.680 --> 24:09.960
distributions over images or sound or, uh, other types of data as well. Um, so that's one, one

24:09.960 --> 24:16.920
approach. The other approach is the normalizing flow approach. This is essentially what I was

24:16.920 --> 24:23.880
describing before. These, these, these take, these, these neural networks take a, a random

24:23.880 --> 24:30.040
input coming from a simple distribution like a Gaussian, and they transform it and produce a

24:30.040 --> 24:37.560
data point. So essentially, they implement what I was describing before they take a simple density,

24:37.560 --> 24:44.760
for instance, a Gaussian, and transforming it, stretching it, like a rubber band, you know,

24:44.760 --> 24:54.920
in order to form a different density. Um, so real and vaping was this type of model. So our work

24:54.920 --> 25:01.560
is, was based on the idea that we can actually, before you, before you go to your, the, this

25:01.560 --> 25:11.560
latter model normalizing flow is a normalizing flow. Are you, is your, your input data just sampling

25:11.560 --> 25:17.000
from a input distribution or is there some kind of training data set or something? It's the random

25:17.000 --> 25:22.520
noise from an input distribution. It's like the generator of a gun. So it's just random noise.

25:23.560 --> 25:36.760
Um, and the output is data. Okay. Um, and so now work, what, what we, the idea, um, that we use

25:36.760 --> 25:43.160
is that you can actually, it turns out that some autoregressive models are actually normalizing

25:43.160 --> 25:48.520
flows. So there's a deep connection between this two type of model, which was really cool.

25:49.480 --> 25:56.920
And that gave us an, an idea of how to make normalizing flows better. And the idea was to use

25:57.480 --> 26:02.680
autoregressive models as normalizing flows. So that was, and that, that's exactly what we

26:02.680 --> 26:07.320
called this thing, an autoregressive flow. And so when you, you started with this idea of making

26:07.320 --> 26:12.520
them better, what was, what were the particular things that you wanted to improve on? So, um,

26:13.640 --> 26:20.360
the, the challenge with designing, uh, neural density estimators, neural networks that,

26:20.360 --> 26:28.520
estimate densities is exactly that it's difficult to ensure that the outputs are actual densities,

26:28.520 --> 26:34.920
that they satisfy this, this, this properties of summing to one and being non-negative. Um,

26:36.280 --> 26:42.040
and if you try to impose restrictions on the architecture in order to achieve that,

26:42.040 --> 26:48.920
you end up hurting expressivity. So you end up making the networks very rigid, um,

26:49.720 --> 26:54.680
very difficult to express complicated distributions. That's why we're trying to improve, we're

26:54.680 --> 27:02.760
trying to improve, uh, the expressivity of these type of models without hurting, um, without,

27:03.320 --> 27:08.040
violating, violating, well, exactly with, uh, violation of the requirements. And when you hurt

27:08.040 --> 27:15.240
expressivity, um, does that lead to a model that tends to underfit, a model that doesn't generalize?

27:15.240 --> 27:21.480
Exactly. What are, what are all of the above? Yeah. Uh, uh, underfitting could happen because

27:21.480 --> 27:26.440
the model is not expressive enough. Right. To represent a complicated density. So, for instance,

27:26.440 --> 27:33.640
a complicated density can have a, you know, a very strange shape in space, right? If, if the,

27:34.680 --> 27:40.360
if the model can only represent gousians, then it will underfit, it will,

27:40.840 --> 27:46.840
right, you know, uh, force fit everything. Exactly. Yeah. So you will try to sort of cover

27:46.840 --> 27:53.560
everything, in the space, and it will end up, um, assigning lots of probability to

27:54.360 --> 28:00.360
unlikely, uh, objects, like unlikely images, for instance. Yeah, that's what underfitting means

28:00.360 --> 28:06.040
in this, in this context. Are there other areas of your paper or presentation that we haven't

28:06.040 --> 28:12.520
covered thus far? That's well, that was pretty much, uh, everything. And so this work is, uh,

28:12.520 --> 28:17.800
uh, kind of a stepping stone and a sequence of stepping stones, you know, where do you see it going?

28:18.520 --> 28:23.960
Um, I'm hoping that it will, it will prove useful in, uh, doing inference.

28:25.160 --> 28:31.240
Uh, and they're, there are many ways you can use it for doing inference. So last year we,

28:31.880 --> 28:37.560
say, last year nips, we had another paper where we used a neural density estimator

28:37.560 --> 28:45.640
to learn, uh, posterior distributions. So that would be one way we can use it to, to do inference.

28:46.600 --> 28:52.600
What's the difference between learning a density estimator and learning in the posterior?

28:52.600 --> 28:58.920
The posterior is a density. Uh, it's a particular, uh, particular density that describes

28:59.640 --> 29:05.240
your beliefs about something you haven't seen. For instance, if you have an image and you've

29:05.240 --> 29:14.280
observed, you have half of it and the other half is corrupted. Then the density of the corrupted

29:14.920 --> 29:23.000
bit of the image would be the posterior of that, uh, part of the image given the, the part you've

29:23.000 --> 29:29.400
seen. Uh, so that, that would be a posterior. Um, but we use that same example to describe or to

29:29.400 --> 29:35.960
illustrate the work that you've done. Uh, so, uh, but it sounded like you were drawing a distinction

29:35.960 --> 29:42.440
between the work that you done and the work that you did, uh, with this paper and the previous one

29:42.440 --> 29:47.240
that was focused on, uh, uh, past, past areas. What's the distinction between the two?

29:48.200 --> 29:54.360
So the distinction is that the previous paper was, was mainly on how to train it for inference,

29:54.360 --> 30:00.440
how to train, it's a given and you're a density estimator. How can you train it, uh, to learn

30:00.440 --> 30:06.680
posterior? Uh, and this one was, how can we design a good density estimator? Got it, got it, got it,

30:06.680 --> 30:12.920
got it. So if we have a good one, we have a good density estimator and we also have a good way

30:12.920 --> 30:18.600
of training, training it to learn posterior. Right. Maybe we can, then we can actually use the

30:18.600 --> 30:25.320
reference. Yeah, we can use the reference. Exactly. So that's the idea. Okay. Um, how did you benchmark

30:25.320 --> 30:33.880
the performance of the, uh, the, uh, the mast auto regressive flow model? Uh, the, the benchmarking

30:33.880 --> 30:41.000
was, was done on general purpose density estimation tasks. So it was, what I was describing before,

30:41.000 --> 30:48.280
we took with these three different tasks. Yeah. We took a number of data sets. And so how well,

30:48.280 --> 30:54.280
how well mast auto regressive flow can fit the density of, of the data set. The density of, of

30:54.280 --> 31:01.000
data is something we don't know, right? It's, we know that, you know, we, we stipulate that, uh,

31:01.720 --> 31:09.400
that data comes from, from a density, um, but we don't know which, what, what, what it is,

31:09.960 --> 31:16.360
and we try to learn it by, but by these type of models by mast auto regressive flow. And if it has

31:16.360 --> 31:22.920
done a good job at learning the underlying density of the data, then it should assign high density

31:22.920 --> 31:30.760
to unseen data. And that, that's the, uh, that's, that's a, uh, benchmark, uh, we can use to test these

31:30.760 --> 31:37.320
models. Uh, and so presumably you compare the results you saw with the, the previous generations of,

31:37.320 --> 31:44.040
yeah, exactly, perform favorably. Yeah. Um, competitive. Okay. It's, it's not clear what's the best

31:44.040 --> 31:50.360
model for, so given a data set, right? It's not clear what the best model is because depending on

31:50.360 --> 31:57.240
the structure, some, some density models are better at, um, estimating cluster structure, structure,

31:57.960 --> 32:06.760
uh, other, um, models are better at estimating manifold structure. And some models work better in

32:06.760 --> 32:13.640
high dimensions, some models work better in low dimensions. So it's not easy. It's, it's, it's difficult to

32:13.640 --> 32:21.320
design a, a model that rules them all, right? That fits everything. Um, so there is, there's always, um,

32:22.280 --> 32:29.160
the question, what do I use for my data set? Uh, we, we saw that mast auto regressive load does well

32:29.800 --> 32:35.080
across a range of data sets, but it's not necessarily the best for each particular case of steel.

32:35.080 --> 32:41.640
If, if I'm interested in a particular data set, then I, I need to think, um, what I should use.

32:41.640 --> 32:46.600
If I'm interested in a range of data sets, then something like mascot or aggressive flow,

32:46.600 --> 32:52.440
as a starting point is something I would probably use. And did we explicitly cover what the

32:52.440 --> 32:59.880
mast in mast auto regressive load, uh, where that comes from? Um, so this comes from a previous

32:59.880 --> 33:08.040
model that we used ideas from. So that previous model was called a mast auto encoder for distribution

33:08.040 --> 33:16.600
estimation. So we took the mast bit from that. And so that model was an auto regressive model.

33:16.600 --> 33:24.840
So it predicted one density at a time. So one, one density. So it had one output for every input.

33:24.840 --> 33:33.080
And that output was a density over the corresponding input. So the, the, the restriction that these

33:33.080 --> 33:43.240
models have is that the, so the, the fifth output is only allowed to be connected to the first four.

33:43.240 --> 33:55.160
It's not allowed to receive, um, input from the fifth, the sixth, the seventh, uh, input. And the,

33:55.160 --> 34:03.400
in, in that, uh, in that particular paper, they, they enforced this restriction by masking out

34:04.200 --> 34:11.000
weights, connections in the network by removing, uh, connections. And that forces kind of like a

34:11.000 --> 34:16.840
summarization at different levels or, uh, it forces, it forces the concentration or something.

34:17.720 --> 34:27.640
It forces, uh, that the fifth output doesn't change by looking, so by looking at the, at the

34:27.640 --> 34:35.560
actual value of the fifth input. Um, that, that's, that's what, that's what it does. And it's,

34:35.560 --> 34:40.760
in, in technical terms, what it does, it, it, it decomposes a, a joint density into a product of

34:40.760 --> 34:49.400
conditionals, um, each, uh, output density is one of those conditionals. And conditionals are,

34:50.120 --> 34:59.720
um, conditioned on only previously seen inputs and not on future ones. Um, so masking was the,

34:59.720 --> 35:05.880
the technique they used for, for doing the sense, it's a very clever idea. And we, we took this idea

35:05.880 --> 35:12.040
from there. Awesome. Well, George, thanks so much for, uh, taking some time, uh, to chat with me

35:12.040 --> 35:16.360
about this. I really enjoyed learning about what you're up to. It was a pleasure for, uh, for me.

35:16.360 --> 35:23.560
Great. Thank you. Thanks very much. All right, everyone. That's our show for today.

35:23.560 --> 35:28.280
For more information on George or any of the topics covered in this episode,

35:28.280 --> 35:36.120
head on over to twimmolai.com slash talk slash 145. Also, take a moment to show us some love for

35:36.120 --> 35:42.920
the podcast's second anniversary and share how it's been helpful to you over at twimmolai.com slash

35:42.920 --> 35:58.840
2av. And finally, thanks so much for listening and catch you next time.

