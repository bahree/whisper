Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington. A few weeks ago we celebrated the podcast's second anniversary
and asked listeners to send us some ways that they've applied what they've learned on
the podcast to their work. We've seen some great responses and for those of you that did
take the time to reach out, thanks so much. An example I've heard several times, including
most recently from Kelvin Ross, who presented at the last meetup, is from folks who learned
about and gone on to implement the Lime Model Explanability Technique, which stands for
Local Interpretable Model Ignostic Explanations, from my interview with Carlos Guestrin.
One of our favorite comments on the anniversary page came from listener Yuri Gorin, who mentioned
that something clicked for him after hearing Jeff Dean discuss embedding categorical features
with Word to Vec. After listening to that podcast, he was able to implement that technique
to represent various features in one of his models as dense vectors. Fast AI's Rachel
Thomas also referenced the interview with Jeff in her recent blog post about that technique,
which we'll link to in the show notes. In keeping with the theme of listener sharing,
for today's show, I'm super excited to share this interview with Nick Osborne, a long
time listener of the show, and leader of the global machine learning project management
office at AES Corporation, a Fortune 200 power company. Nick and I met at my AI summit
a few weeks back, and after a brief chat about some of the things he was up to at AES,
I knew that I needed to get him on the show. In this interview, Nick and I explore how
AES is implementing machine learning across multiple domains at the company. We dig into
several examples falling under the natural language, computer vision, and cognitive assets
categories that he's established for his projects. Along the way, we cover some of the key
podcast episodes that help Nick discover potentially applicable ML techniques and how
those are helping his team broaden the use of machine learning at AES. This was a fun
and informative conversation that has a lot to offer. Thanks so much, Nick. Alright, let's
do it.
Alright, everyone, I am on the line with Nick Osborne. Nick is the leader of the global
machine learning project management office with AES. Nick, welcome to this week in machine
learning and AI. Thanks for having me. I'm really excited.
Same here. So you are a long time listener of the podcast, who I finally had an opportunity
to meet at my AI some of the few weeks ago, and we got into a really interesting discussion
about some of the things that you're working on at AES. So I'm really looking forward to
digging into that, but before we do, why don't you give us an overview of how you got
started working in machine learning and AI?
Sure. So my start in machine learning and AI is maybe a little bit different from the
typical interview you have on in that I've come from the business analyst side. So my
background is very much finance and consulting. I worked actually in restructuring, which
is working with distressed businesses. But in that work, one of the things that we always
end up doing is a lot of analysis, a lot of work with big data sets. And so when I think
about my background and data science broadly, I think of it from that perspective and really
understanding the value that this type of analysis can add to a business, the real value
it can add for an organization long term and the real financial and practical business
applications. So from that background and really over the last five years now, I've been
working closely with the CTO of our organization to do various strategy initiatives. And one
of those about two years ago, actually a little more than two years ago now, we got started
in looking at machine learning, AI and advanced analytics. And really that effort has continued
to where we are now. And so it's gone from just trying to understand the space to doing
a series of pilots. We've had some some initial successes with our pilot efforts and practical
applications to now where we're really starting to dig in on the companies, making a more
cognizant and more focused investment in upgrading our digital capabilities.
Fantastic. So I think it will help contextualize the discussion of the things that you're
working on for folks to better understand AES and what the company's focus is.
Sure. So AES is a global power company. That's power generation. So we own power plants
and utilities in 15 countries around the world. That's down. Our footprints shrunk a little
bit over the last several years, but we're now currently operating in 15 countries. We
own generation assets that span the spectrum of from solar wind to natural gas and coal.
We are making a very cognizant effort in the in the business to invest in in greener
technologies and transitioning more of our fleet away from coal to cleaner and and a
big focus on renewable renewable energy. And I think one other thing to add in there is
that we are the world's leader in battery energy storage.
What aspect of battery energy storage? So we focus on primarily utility scale, battery
energy storage. So these are the grid facilities that go in. They're usually tensed to hundreds
of megawatts in scale. And they provide a spectrum of services for the grid from balancing
to frequency regulation. And really what we're starting to see now is that these energy storage
assets can actually replace or take the place of a thermal or a natural gas peaking plant.
So it's really one of the ways we are starting to shift the energy networks away from thermal
to cleaner and more renewable technologies.
When you first started to think about applying machine learning and AI to AES's business,
how did you how did you think about it? Where did you think the opportunities were and
what was the initial driver?
Yeah, so you know I think the at the very beginning you know it was much more of a research
effort. And then we kind of slowly began to add additional things that we saw that could
be applicable across the enterprise. And I think where we've gotten to and where we're
current thinking is is that AI can play a role really across the full spectrum of the
enterprise. So currently we have projects going on in language, we have projects going
on in vision, and then we have projects going on in a theme that we call cognitive assets,
which is where we you know try to bring intelligence to our machines. So our power plants right
and that's where we get into maybe the most the clearest or the first area that maybe
came to mind was how could we make our power plants more efficient? How could we operate
them more effectively over the long term and that's where we get into predictive analytics
type initiatives and projects. But really we're looking across the full breadth of the organization
of from HR to strategy. You know being in generation safety is a you know critical piece of how
we operate. And so we've had a few projects take a look at at safety and how we can improve
safety using AI techniques. Before we go to the your first projects you mentioned that the
initial emphasis was research and really learning how did you go about that that learning phase
of this? Well Sam I would say your podcast was that wasn't a softball. Oh no but seriously this
podcast was was a great way to learn about the industry and you know really going back to your
tagline you know interesting people doing interesting things and machine learning and that's
that's really you know the role played for for me and I know several other people in the company
you know listen to the podcast as well. And it was really a great way to get exposed I mean there's
so much activity in the space right now and the filtering and the interview you do with you
know with kind of key people in each of these businesses. It was a great way for us to get our
our heads around you know the breadth of everything going on and and maybe even give us a little bit
of focus on to on the companies that we're doing you know the actual interesting work or some of
the interesting work. And how about coursework have you had various people in the company taken
or pursued kind of formal coursework in the area or research efforts? So yeah people have been
doing coursework formally and informally. We were lucky to have a few people who actually had
some data science as part of their graduate graduate studies and so that that was very helpful
but people have been working through the you know Andrew Hings Coursera work. I know I've
taken a look at some of the stuff on edX and and whatnot and then we've also been just using
you know using some of the like some of the free tutorials that are available like through Azure
and through some of the other platforms and really trying to focus on getting people's hands dirty
with these tools and that's that's something that we actually have done a number of times now where
we lead what we call cohorts which are about a month long where we focus on getting people hands
on with machine learning tools. So we've used you know things like the Azure platform we've gotten
people into Google and some of their tools and TensorFlow we've done work with a cortical and some
of the free APIs they have and getting people to use them IBM Bluemix we did work with some of
their cognitive tools and just just really trying to get people you know past you know reading about
it and getting people to use some of these tools and see how they work and see how people can
interact with them and that's been something that's been you know very helpful for people in the
company. Awesome awesome so you mentioned cortical and this was a great story that you told me at the
at the air summit and I guess it ties to that language that first of the three main areas that you've
dug into. Yeah can you start by talking a little bit about where you see the use cases for
NLP NLU types of technologies and language and then some of the things that you've done. Sure.
So I think language in particular is one of the ones where we see some broad applications and so
just initially we've done some some piloting and some testing and language is actually one of
the areas where we've done some work around safety and seeing if we can you know improve safety or
find some predictive capabilities through language and so so that's one area and I can go into more
depth if you want on that but you know we're also looking at strategy I think there's a number of
possibilities within HR. I think there's a tremendous opportunity for AI and machine learning to
help with the recruiting and the evaluation of candidates through their the resume submissions
and then a lot of my current thinking is around the strategy effort and how can we you know
understand the the exponential content that is going out there or that is coming in and really
provide a you know I'm meaningful way to to understand that content and to get it in front of
our decision-makers in a timely and relevant fashion. So maybe start with safety and take us a
little deeper into what you're what you've done and what you're hoping to achieve there.
Yeah so so safety actually ended up not being one of our more successful projects okay
but you know what the way we work is are one of the things that we do throughout our company is
our things called safety rocks and we also do a lot of just safety monitoring where people go out
and they they will document any safety findings throughout the company and so one of the things
that we are hoping to do is could we could we look at that data set it's a written data set to
understand if there were any triggers or our identifiers in those data sets that could lead us to
understanding you know either really really good safety environments or versus poor safety
environments and what would be an example of a trigger or identifier that you might expect to
correlate to safety. Yeah and and maybe some of that's why that project wasn't as successful as
you know trying to understand the way people are talking about safety and the words that
they're using are writing about the safety of their of their facilities or plants right so
it was a bit nebulous and we didn't get super far on on that project before it was kind of deemed
not not super feasible however so maybe switching over to areas where we did make a little more
progress was we did and this was one of the projects we did with with cortical are using some
of the tools from cortical but we also do periodic culture surveys throughout the organization
and so you know we're a global company with a lot of people so we received 13,000 surveys
back in our last cultural survey effort most of that is multiple choice but we also had four
open entry text fields that people could respond to four questions we were opposing so which ended
up what that's receiving about 30,000 written written responses right so that's a lot of
just data for anyone to kind of sort through or mine through it's very hard to be consistent in
that evaluation even with even if one person read it all and so what we you know we use the tool
from cortical and what we did a number of different analyses but you know what we were looking to do
is benchmark those statements against 60 other statements that we had and so one of the things that
cortical allows you to do is compared two different text you know text documents or text fields
paragraphs or whatever and compare them on a semantic level right so this is where you get your
your overlap between the two and basically by understanding the overlap we were able to benchmark
the responses that we were getting against a series of 60 criteria which are helping us to evaluate
the culture in each of our facilities and so since each of those responses came back with
with the demographic information not anything identifiable to an individual but with kind of broad
demographics male female kind of rough age ranges and those sort of things we were able to kind
of peel the onion a little bit deeper and try to identify on a comparative basis you know which
locations are you know caring about different parts of our culture right so just an example here is
you know one facility could really care about advancement opportunities other facilities could
care about benefits and this was a way for us to really mine that 30,000 comments or questions
that we received back to to really understand the business on a deeper level and so
so that was one part of the analysis we also pulled in some additional tools we pulled in
and before you before you get too far from this particular piece part of what was exciting
for media here from you was that you initially came across the work that cortical was doing
around their semantic folding and semantic NLP stuff yeah through the podcast actually
twin will talk number 10 with their founder Francisco Weber is that right yeah so that is where we
first we first learned about it and I want to say you also had a talk with Numenta on later which
is kind of the founding company are the research institute but yeah so twin will talk 10 with
Francisco Weber was I found it to be incredibly fascinating one of the other you know people in
our company also listen to that podcast and also found it really interesting and we kind of kept
bringing it up to the CTO of our organization on like this is this is different the way they are
thinking about language is just fundamentally different than a lot of the other language tools
that we had seen and at the time we had also spent a fair amount of effort looking into like the IBM
tools and just saw this as something really different and something that to me just kind of
fundamentally makes more sense in the understanding of language so I found it to be really interesting
and for this particular project it sounds like you had good result in understanding
these survey responses did you come up with a measure of you know the results or how good
the results were and had you tried other approaches previously that you know we're we're
that you also measured and like could compare the success so no so we didn't do a comparative analysis
against a different tool but the speed we were able to work through on the tool was much faster
than what we were seeing with other tools and our ability to use it and we were and we were
primarily using just the free API and doing some coding on our side to to make it all work and
manipulate the data into it but it worked great and the and you know we didn't
there wasn't an easy like precision or yeah precision type measure that we could get but we
we spent a fair amount of time validating it just one on one on one going through the responses
and seeing seeing the comparison that it was providing or the prediction that it was providing
through the tool and making sure that it it lined up with what we were seeing so we did a
you know we did some a fair amount of data testing or testing you know once we had
worked through the tool but we didn't have a defined prediction measure for it.
Awesome and I cut you off you were talking you were about to mention other tools I think you were
saying that you were looking at. Yeah so we used some other tools to bring in sentiment analysis
into it right so running the same question through a tool to get sentiment so positive negative
sentiment and the emotional state that was coming back so that was you know again that's just
providing another layer of information on it so we could you know understand whether or not people
were talking positively or negatively about management versus just saying oh that person's
you know talking about management. Okay and so that was that was a you know a helpful layer to add
in there and then the second big piece of the analysis was trying to pull out what we were calling
the meta nouns and meta adjectives from the sentences which were you know the primary topics
and the primary descriptors of the topics that were being used in those statements and so
if you think about the different ways a person could talk about you know their boss right it could
be their leader it could be management manager it could be you know a lot of different descriptors
and so we were able to pull out what we were returning meta nouns and meta adjectives and combine
them together to what we were what we were terming at the time caveman speak which was you know
stuff like you know management good development bad right or something along those lines right so
really basic understanding of the thematic content of the of their responses and again that
that helped us really narrow down what was what was being said because then we could look at
across the organization or across the sample that we are working with on you know what were the
the key things that people were saying right so trying to replicate how a human would go through
that data set and you know pull out the the major themes and you know and this is exactly what
we saw when we talked to the actual humans were who were going through it as they were going through
and they were you know basically tick marking every time that they came across you know a response
with a particular topic in it and so we we tried to use the the cortical tool to basically do
the same thing for us is provide us an understanding of the topics that were coming back in the in
the responses okay interesting interesting yeah and so you you've mentioned safety you've mentioned
this I kind of assuming that is a HR use case and you mentioned strategy as well which it sounds
like that is related to kind of content management is not the right word but kind of content understanding
I guess talk a little bit about that strategy use case and what you did there yeah so this is one
of the ones where we're still working and we had a fair amount of success at the end of last year
and we're kind of reevaluating next steps on this project but basically what we were able to do
is we were able to we we built a scraper to go scrape and we limited you know where we were scraping
the information from for this pilot but we were able to pull out new new news articles from a
from a data source we're then able to evaluate those news articles against and we're going down to
the I think the paragraph level but we were pulling out the are comparing those new at our articles
against specific strategic scenarios that we were for seeing in the next three to five years
for that space and so you know we had gone through an an effort of you know putting the other
and like a red scenario green scenario blue scenario that we were comparing these news articles
against right so we were able to say you know does this you know news article lineup with
you know our green scenario which maybe our green scenario is you know full transition to
clean energy right and these are just very theoretical examples but and so we were able to kind
of understand you know what the news article was about put a categorize it against us like a
strategic outcome that we saw you know in the next three to five years and then what we also did
is we built we built in the ability to present this to a user so we built a little slack interface
to present the news article and the prediction to a user and whether or not to find out whether
or not they agreed or disagreed with our prediction and then we use that prediction to further
hone our our initial and our initial you know pick our prediction okay we're using any particular
tools as part of that or did you develop the tooling for that internally yeah we're working with
corticals API okay again for that one okay but we built a lot of the a lot of the other tooling
was done in-house I think we were using scraping to do the actual web you know crawl and scrape
function but yeah which I've heard great things about yeah it worked really well it was very
quick for us to get up and running I didn't do the actual work with it but it was fast and easy
so that's a good thing okay cool so that's some of the things that you've done on the language
side of things how about vision yeah so visions really interesting and that's one of the areas
we're currently pretty active on so and actually so maybe one one thing Sam we did really early on
and this was just another example of where your podcast came in but you did an interview with
Clarify with Matt Ziller and so we were able to just using again the free the free tooling from
Clarify we were able to prove out a use case and safety where we could detect hard hats right so
we could detect whether or not people were wearing their their PPE their protective equipment
and I mean it was it's like built in the tool just does it for you automatically and so we
we were able to prove out really quickly that yeah this is something that we could do is you know
basically set up a camera to detect whether or not people are wearing their hard hats or
their work gloves or work boots right but yeah I mean it was again it was a really easy tool just
to get up and running we didn't we haven't like pursued that use case but yeah I mean really
and just another example of kind of one of the ways you know we listen to the podcast learned
about a company and then try to you know check it out and bring it into a business application
awesome awesome and so what else have you done on the vision front so yeah so right now we are
working heavily on a project where we are trying to detect damage and drone drone inspection
footage and so we have we have some good data sets that we're working on and we're currently
primarily working with with Google on this effort but we're looking at some other applications are
you know potential applications but Google has been really helpful and working with us we're hoping
to do a few more projects in the coming weeks but you know where this project started off is we
started off with with TensorFlow and with the inception model there and that's specifically for
our use case which was this damage detection project we were able to you you know prove out
that it worked our initial couple models we're working but we were getting problems with
high false positive rates so that's really where we've we've focused in now we're spending a
lot of time working on our labeling and so the labeling has been a big part of the data cleanup
and I'm sure it's not a surprise for anyone who's worked on data science that getting your data
set correct is incredibly important especially when the data set wasn't necessarily built for
for data science right it was the data set we were starting from was just it was built for for
humans and for human inspectors to understand what was going on with the pictures
and so it was it was I mean it's messy and inconsistent what's an example of the kind of damage
that you were looking to determine and what specifically did that data set look like
sure so so our data set right now is you know we own win facilities across the United States
we have three primary projects and about 500 turbines in the US and so the data set we are
looking at is the inspection footage of those of those blades and just for just for sizing each
of the three facilities when we do an inspection we'll come back between 10 and 20,000 images
of those inspections and the supremacally blade inspections right and so the these are images
taken via drone of the blades while they're stopped you know they take pictures of all aspects
so the four kind of different directions of the blade so you know the high pressure side
low pressure side leading and trailing edges the damage can be surprising you know for you know
for for a for a turbine blade that I mean is kind of just going through air there's there's a lot
of different damage types that we see this can you know be like erosion and so some of our facilities
are in our very area or desert landscapes and there's a fair amount of dust in particular matter
so you can get erosion you can get bird strikes so birds hitting the turbine blades which can
do a fair amount of damage lightning lightning strikes and so you I mean you will see you will
see things from you know small you know divots and dense and coating penetrations to kind of
large scale delamination of sections of the blade and so yeah I mean that's that's the that's the
data set and then you know traditionally so I mean if we go backwards a little bit Sam so before
drones these were all these inspections were done manually so someone would climb up the tower
and go down and you know look for damage that way so dangerous time consuming work
when we switched over to drones that was a tremendous tremendous time saver
but had the had the side effect on while now now someone has to review you know 10 to 20
thousand images right and the drones are capturing still images or video so in this application it's
still but you know we we actually have a drone partner that we work with measure and so they can
do different you know image types they can do video or my understanding is they can do video and
infrared and so infrared you know is infrared's actually really important for solar applications
and it's the infrared's a really great way to spot problems on a solar field and I'm assuming
that they're the drones are manually operated as opposed to you know autonomously kind of going
through a field of of turbines yeah correct yeah this is all they're all manually flown
they fly a defined flight pattern when they when they do the inspections but yes it's all manual
and so the you you started with TensorFlow and there's been some that the main issue you're
focusing on now is addressing some issues with your labeling how was the labeling done previously
are these the either your engineers or the drone providers kind of manually writing up a report of
some sort are they coded or something what were you starting yeah so it's changed and it's changing
so it it started off I mean really pretty rudimentary on just people entering information and an
Excel worksheet as they were going through the images our drone partner that we work with now
has some tools to allow them to be kind of more to be you know bounding boxes and to be systematically
labeled with very defined categories and so that's that's helping us really get get where we need to
get to go on the on the labeling side or we hope we'll get us where we need to go on the labeling
side so yeah we're working on getting consistent labels getting those damage instances bounded
to help which we think will be helpful and I'm curious have you explored any of this use case or
any of the others active learning specifically meaning so you train a model based on some set of
data and then you have incremental you basically have a human kind of correct the models decision
on an incremental basis and feed that back in to the model training have you done anything at all
with that actually who we just we just kind of looked at that maybe starting last week okay so
so we've kind of switched over to using auto m auto ml from with google okay and so that has some
of that functionality built right in and so that's that's that's how we're proceeding on that path
is we I won't say we're we've done much with it yet but that's that's part of the plan at this
point once we kind of got our heads around that like we were really excited yeah yeah yeah I mean
it's potentially interesting and I'm hearing some some interesting stories of folks starting to
see good results with it all right cool are there any other any other vision use cases that you've
looked at not not that we're actively working on but I think the applications for drawing
inspection footage is something that we're kind of looking at broadly yeah and there's there's a
lot of different use use cases within the the power space and utility space in general so I
could imagine yeah so it's it's dangerous work it's high voltages high pressures so any anytime we
can take a human like a remote or take them out of that situation is generally seen as a positive
thing and drones are a big part of that and then the flip side of that is taking advantage of the
onboard sensor data to predict machine failure and that kind of leads us to that third category
of cognitive assets can you talk a little bit about what you're doing there yeah so cognitive
assets is a bit of a broad category for us where we we look at a number of or we look at a
number of prediction type capabilities there and really looking at that you know anomaly detection
in a in a facility predictive maintenance and those sort of things but we've also been able to
do some tuning of our assets and that's really where we've seen the most progress and so this is
one of the ones I think I mentioned to you at the at the interop conference but you know I'm sure
you're familiar with the Google data center use case whether they were able to I believe improve
PUE by 40 percent that's right and PUE is the power or something efficiency correct yeah so
you know it's it's not the exact same application but when you think about our battery energy
storage facilities they are very similar to a data center just without the the compute right they're
just big the racks and racks of batteries and so we we were able to you know use a
developer model that first predicted our power usage and power efficiency and then we were
able to use that model to then improve power efficiency and I believe where last update I had
is we were able to show a 20 percent improvement in in efficiency you know with with an algorithm
that we built largely trying to you know copy Google's work in the area and so
that's something that has now moved on into our energy storage business and our energy
storage business got spun out over this past past year into a new enterprise called
Fluence with partnering with Siemens and so it's on joint joint bench and they've they've taken
that project and they continue to to run with it and run with deeper applications of machine learning
on on their what they call their advanced on software interesting so the can you talk a little bit
about the how that project evolved and the data assessment and collection phase the modeling phase
how did you dig into it and how did you get started with it really so yeah I mean it started off
just you know getting access to the data and so one of the great things about our energy storage
facilities is that they're they're digitally native and so all the control systems have been
digital since the very beginning and so we have literally you know tens of terabytes of of information
just from our energy storage assets and so that's a tremendous data set for people to start working
with one of the things that we were or one of the initial kind of difficulties we came across as
that we had always had like a single set point on our on our basically our HVAC system right so
we didn't have a very we didn't have a very diverse data set on on how to manipulate our HVAC
system right so it always had a fixed set point and so one of the things that we had done is we
we did modify our control software to allow to allow some variability in that HVAC setting and so
that that was kind of one of the initial things that we had to work through on on getting a
more meaningful data set for a modeling effort and really once we got beyond there it kind of
all kind of clicked into space and to place on improving our predictive capability on our model
and then and then being able to use that model to tune the system so was the HVAC
system the primary system that you were controlling to increase power efficiency or was it
something related to the batteries themselves or something else yeah no it was primarily the HVAC
system so we were we were really focused on what we call in the in the power industry our auxiliary
load which is the you know it's basically the power we use to well yeah to make power right
and that's kind of the so yeah that's that's what we were really focusing on and you know any time
we can reduce that ox load means we can put more of that power into the into the marketplace
and it's really an efficiency thing for for power plants and do you have a sense for off the
top of your head what that 20% improvement translates into from a business perspective in terms of
you know dollars per year or x per x yeah I I don't have a good I don't have a good figure for that
but it's got to be it's meaningful yeah I mean that's it's meaningful I don't know what the
dollar impact is though maybe taking a step back from these three use case categories
mm-hmm I'm curious if you can speak to running a ML PMO in an organization that you know has
another business your business isn't you know you're not a software company machine learning
company anything like that like how do you approach portfolio management of all these
individual efforts and and you know how do you see that evolving as you gain maturity sure so
you know really on you know we when I worked with our our CTO and defining the you know the
what the PMO would do and what my role would be the role and was really to be to you know facilitate
coordinate and accelerate these projects and so you know being such a distributed business
it was really important that we helped help the businesses foster their own projects and help
them find resources they need and open their eyes to some of the capabilities but to allow for
some organic growth and or organic direction from from the businesses so that was one area where
we've really tried to I don't want to say be hands off but instead of directing each of our
businesses to do something with with ML we've tried to kind of open their eyes to the technology
and to be available to them to help foster or to help facilitate any of these projects coming forward
that said we've also done kind of taking the lead on several projects right so we couldn't let
everything just be you know wait for wait to come to us so we we kind of took a dual approach where
we've led some projects but then we've also put a fairly cognizant effort into raising awareness
of of ML technologies and tools and the business applications and the potential to our senior leaders
and to really some some broad user groups across the company so trying to trying to raise awareness
while also trying to show some successes with our with our pilots and do you have any advice or
kind of lessons learned you know from that perspective the portfolio perspective or the like
introducing ML and AI to a large organization perspective that you would share with folks that
are maybe similarly situated but earlier on in the process. Sure well I think the the biggest
thing is to talk about it and to you know communicate I'm I think just in general that's that's
the biggest thing I find between you know successful efforts and non successful efforts this goes
well before my time at AAS is the clarity of that communication across the organization is key
we've really tried to get our senior leaders on board and I've seen some really great commitment by
our our COO in particular and even our CEO and talking about the capabilities and the need for
our business to be to move kind of higher up the digital mastery you know curve and with with
machine learning and AI being central to that and so getting that executive buy-in is always critical
but then really starting to talk you know down down in the business where where stuff tends to happen
right so the executive support is really important but there's people who are you know working in
this data on a day-to-day basis who have some incredible you know sector matter expertise and
some incredible fundamental knowledge of how the data works and getting those people engaged has
been really important as well because I mean those are those are the people that usually end up
doing the work and and getting them excited about it has been a great avenue for us. That's fantastic
well congratulations on the success you've seen with these projects it sounds like you're doing
really incredible work is there anything else that you'd want to leave folks with?
maybe just you know I'm really committed to the value of of digital and the incredible power that
you know analytics can add to a business you know I've seen firsthand the value it can drive
you know in a variety industries and businesses and you know I just rude highly recommend to
you know to business to business people out there that you know they spend the time to to
understand the technology to demystify it because I think that's something that you know a lot of
people you know if they're just reading kind of the news headlines are are kind of focused on
the kind of the mystical aspect but at the end of the day this is just another or these are just
more tools that you can have in your in your tool belt and you know really drive a lot of value
in your organization for sure for sure well Nick thank you so much for taking the time and
really for being so open with what you've been able to share with us I'm sure it's going to be
very helpful to folks yeah now I'm really excited to be to be here and talk with people about it
and um you know I hope to be able to share some more stuff in the future awesome thank you
all right everyone that's our show for today for more information on Nick or any of the topics
covered in this episode head on over to twimlai.com slash talk slash 150 as always thanks so much
for listening and catch you next time
