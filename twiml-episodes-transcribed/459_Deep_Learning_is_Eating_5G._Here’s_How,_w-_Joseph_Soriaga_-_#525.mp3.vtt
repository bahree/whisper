WEBVTT

00:00.000 --> 00:14.080
All right, everyone, I am here with Joseph Soriaga.

00:14.080 --> 00:17.680
Joseph is Senior Director of Technology at Qualcomm.

00:17.680 --> 00:20.340
Joseph, welcome to the Twinmore AI podcast.

00:20.340 --> 00:23.280
Great. Yeah. Thank you for having me. It's great to be here.

00:23.280 --> 00:25.800
Looking forward to jumping into our conversation.

00:25.800 --> 00:29.080
We'll be talking about a couple of very interesting papers that you and

00:29.080 --> 00:33.720
your team have that will be published later in the year at Globecom.

00:33.720 --> 00:37.560
Before we dig into those, though, I'd love to have you share a bit about your

00:37.560 --> 00:42.280
background. Tell us how you came to work in the field of machine learning.

00:42.280 --> 00:49.320
Yeah, sure. I'd be happy to. So I've actually been working for a while and

00:49.320 --> 00:54.360
wireless. And when I started, I actually started in coding and

00:54.360 --> 00:59.400
information theory a while ago, even and well before in the deep learning revolution.

00:59.400 --> 01:02.720
But there were some interesting parallels, I'd say, with machine learning.

01:02.720 --> 01:09.040
Because at the time, it was really exciting where belief propagation was

01:09.040 --> 01:13.960
very popular. And it was essentially being used to achieve shanty capacity

01:13.960 --> 01:21.160
and a lot of different use cases. And the trick was trying to find the right

01:21.160 --> 01:25.600
graphical model for the particular problem to achieve that.

01:25.600 --> 01:29.680
This is coming from TurboCodes and rediscovered LDPC.

01:29.680 --> 01:36.360
Another nice parallel was that our kind of community was getting used to

01:36.360 --> 01:39.920
and embracing a lot of like experiment-driven research.

01:39.920 --> 01:48.200
Like really extensive coding up of experiments to prove something could work.

01:48.200 --> 01:52.400
Because it was very difficult to prove rigorously and mathematically that

01:52.400 --> 01:54.600
this belief propagation would achieve shanty capacity.

01:54.600 --> 01:59.680
But through a lot of extensive experiments, you could go and simulate it and

01:59.680 --> 02:06.120
design things and then for all practical purposes show that you were achieving it.

02:06.120 --> 02:10.600
There were a lot of relationships to machine learning of belief propagation at

02:10.600 --> 02:15.560
the time, but I was really more on the communication side.

02:15.560 --> 02:22.240
And then coming out of school, my PhD, I joined a Qualcomm corporate R&D.

02:22.240 --> 02:30.440
And that was where I was really excited and exposed to this industrial

02:30.440 --> 02:34.920
research. And one of the great things about Qualcomm is that they not only

02:34.920 --> 02:39.200
invest substantially in research, but it's a very open, collaborative environment

02:39.200 --> 02:46.280
where we would really focus on taking a fundamental research idea

02:46.280 --> 02:48.280
and then proving it out.

02:48.280 --> 02:53.280
See how far you can go and making the system more complicated, more realistic.

02:53.280 --> 02:57.160
And to the point where you're actually going to build it and test it and

02:57.160 --> 02:58.880
demonstrate it.

02:58.880 --> 03:03.200
And that's been kind of a core philosophy that they've continued to do

03:03.200 --> 03:06.040
through, I don't know, my 15 plus years at the company.

03:06.040 --> 03:09.280
So that's kind of been a great thing.

03:09.280 --> 03:13.160
Through that course, I touched a lot of different things on the system,

03:13.160 --> 03:20.120
like the base station, the modem, the entire air interface system.

03:20.120 --> 03:24.240
And then most recently, at 5G, I worked closely with the

03:24.240 --> 03:26.800
research and then coming to participate in standards.

03:26.800 --> 03:29.880
So I did a lot of work in that.

03:29.880 --> 03:36.240
And through the course of that, I'd say, you know, it's 5G's, of course, very

03:36.240 --> 03:40.280
amazing things have opened up in this technology, new frequencies, new

03:40.280 --> 03:46.360
spectrums, new paradigms for how we do things, new services, of course.

03:46.360 --> 03:52.200
And through that, we started to see that we have this very large bandwidth.

03:52.200 --> 03:57.440
We have lots of directionality now with the millimeter wave.

03:57.440 --> 04:03.480
And the system itself, becoming lower latency more precise, it actually is

04:03.480 --> 04:07.000
very sophisticated for understanding the environment too.

04:07.000 --> 04:11.520
So positioning was one of the first, you know, interesting use cases of

04:11.520 --> 04:15.360
trying to understand the environment that the 5G system was able to

04:15.360 --> 04:20.120
demonstrate with these really large antenna rays and wide bandwidths.

04:20.120 --> 04:24.120
And so, you know, as the system gets more complicated and the capability

04:24.120 --> 04:29.520
of the system also grows, it just became more obvious that, like, there's a

04:29.520 --> 04:37.360
lot that can happen with AI and wireless and so, and so I kind of, over time,

04:37.360 --> 04:43.760
transition to doing much more AI in this space as opposed to being more

04:43.760 --> 04:45.640
wireless driven.

04:45.640 --> 04:50.440
And that was kind of one reason to moving more directly into Qualcomm AI

04:50.440 --> 04:52.640
research.

04:52.640 --> 04:58.520
Another, you know, important, you know, motivation I had was that this

04:58.520 --> 05:06.600
interface, it actually does help accelerate, you know, the developments in AI and

05:06.600 --> 05:09.640
the ability of certain applications.

05:09.640 --> 05:14.960
So, because, you know, at the start, it just is a better link to the cloud.

05:14.960 --> 05:17.960
Things can be more interactive and more direct.

05:17.960 --> 05:21.720
But then over time, as the devices also become more capable and we start

05:21.720 --> 05:26.760
moving more of the, you know, lower level perception tests, for instance, locally

05:26.760 --> 05:34.440
to the devices, then it enables, like, the next stage of AI, the cloud can

05:34.440 --> 05:41.760
concentrate on the more complicated and emerging research advances, like

05:41.760 --> 05:46.720
understanding reasoning and generalizing beyond what has been trained on.

05:46.720 --> 05:51.640
And so, it's very natural to think, okay, let's get

05:51.640 --> 05:56.640
more involved in this and write the kind of the next wave of where things are.

05:56.640 --> 06:03.520
Yeah, what I'm really looking forward to digging into in this discussion is what I

06:03.520 --> 06:10.720
think of as the other side of the AI 5G coin, specifically, I spoke not too

06:10.720 --> 06:17.520
long ago with your colleagues, he had about how 5G can be used to accelerate

06:17.520 --> 06:24.520
distributed AI applications that was episode 489 back in June.

06:24.520 --> 06:31.000
But we'll be talking about here, again, the flip side, the ability for machine

06:31.000 --> 06:38.840
learning and AI to help enable 5G and make it more efficient.

06:38.840 --> 06:44.920
You mentioned in your introductions, Shannon capacity, that's kind of a key

06:44.920 --> 06:49.720
concept that flows throughout your work, would you like to take a second to explain

06:49.720 --> 06:50.720
that?

06:50.720 --> 06:51.720
Yeah, sure.

06:51.720 --> 06:58.200
And the Shannon capacity is one of these amazing results from cloud Shannon is being

06:58.200 --> 07:03.640
able to characterize how well, for a particular channel, you know,

07:03.640 --> 07:08.760
conveying information from a transmitter receiver, how well can you hope to

07:08.760 --> 07:15.840
achieve, you know, throughput without actually, you know, building a system to do

07:15.840 --> 07:16.840
it.

07:16.840 --> 07:20.920
And then it becomes a question of like exactly what do we do to build a system to

07:20.920 --> 07:21.920
achieve that.

07:21.920 --> 07:27.760
And one of the really important advances from Shannon was that we know when to give

07:27.760 --> 07:32.000
up and to focus on different things, because if it's beyond the capacity, we

07:32.000 --> 07:35.080
shouldn't, you know, bother and move to the next problem.

07:35.080 --> 07:41.520
And if it's well within the capacity, then we know that we're what potential is

07:41.520 --> 07:43.920
there and what we have to realize.

07:43.920 --> 07:49.480
So yeah, so kind of the theoretical bandwidth limit, let's say between the

07:49.480 --> 07:56.280
between two communication devices or entities, I guess, exactly.

07:56.280 --> 08:02.960
As the channels become more complicated to characterize, some of these principles,

08:02.960 --> 08:07.400
you know, they could become more difficult to evaluate to some level.

08:07.400 --> 08:12.680
You start doing Monte Carlo integration and then some level, you know, this is

08:12.680 --> 08:16.400
where machine learning can start to come in and help us to understand what's the

08:16.400 --> 08:21.200
best representation for this particular system, which has now become so

08:21.200 --> 08:27.680
complicated to really get the right heuristic and the right abstraction.

08:27.680 --> 08:32.640
So that's, that's, yeah, that's how things have evolved.

08:32.640 --> 08:38.920
One of the papers that will dig into, or the first of the papers that will dig

08:38.920 --> 08:45.120
into is one on deep learning based network augmentation.

08:45.120 --> 08:47.960
Can you introduce that topic to us?

08:47.960 --> 08:53.560
We spoke to your former colleague, Max Walling, about that about a year ago.

08:53.560 --> 08:57.400
At the time, it was kind of this interesting idea that was being pursued in

08:57.400 --> 08:59.880
research.

08:59.880 --> 09:03.800
And it sounds like it's matured quite a bit in a year and now you've got a

09:03.800 --> 09:06.400
paper about some of the results you're seeing.

09:06.400 --> 09:08.800
Yeah, yeah, I'm glad you brought it up.

09:08.800 --> 09:16.040
So yeah, last year, Max did bring up this topic and the importance of it in

09:16.040 --> 09:22.600
communication is that, so the idea of neural augmentation is you want to,

09:22.600 --> 09:29.240
whenever a particular problem has some abstraction where we have a good

09:29.240 --> 09:34.680
algorithm that's perfectly matched to that abstraction, there's no reason to

09:34.680 --> 09:37.200
change that algorithm anymore.

09:37.200 --> 09:42.640
But if the abstraction itself is a little mismatched with reality, we can

09:42.640 --> 09:48.800
augment that algorithm with some neural networks so that we can make the

09:48.800 --> 09:53.200
right adaptation of the algorithm for the mismatch instead of kind of

09:53.200 --> 09:55.440
redesigning the whole thing.

09:55.440 --> 10:00.800
And there's still ways to make that say end to end trainable with the real world.

10:00.800 --> 10:06.280
So one really nice benefit of this that plays well with the

10:06.280 --> 10:11.000
communication, you know, academic community and industry is that there's a

10:11.000 --> 10:19.000
long history of abstracting different problems in wireless and domain where

10:19.000 --> 10:23.920
we know that we're doing exactly the right thing and it's just a matter of,

10:23.920 --> 10:27.520
how do we adapt our domain knowledge now that the channels are becoming even

10:27.520 --> 10:31.720
wider bandwidth or even higher frequency and there's more non-linearities

10:31.720 --> 10:38.480
being introduced or more more sophistication in the model itself that we

10:38.480 --> 10:43.640
weren't really able to capture properly in our abstraction.

10:43.640 --> 10:48.600
And so this is where that idea of the paper is coming in.

10:48.600 --> 10:54.520
And the idea there is that, you know, we often see in academic papers

10:54.520 --> 10:59.320
relative to kind of real world deployment in many fields is that the

10:59.320 --> 11:06.920
papers out of necessity in order to get clean mathematical results will

11:06.920 --> 11:11.560
simplify the real world ignoring any number of factors.

11:11.560 --> 11:17.040
And what this work is suggesting is that deep learning can be used to kind

11:17.040 --> 11:21.840
of map the simple models to what's seen in the real world to make them

11:21.840 --> 11:26.920
more, to make them match better and ultimately kind of more predictive.

11:26.920 --> 11:27.920
Is that the idea?

11:27.920 --> 11:29.040
Yeah, that's right.

11:29.040 --> 11:31.760
To make it more predictive.

11:31.760 --> 11:38.360
Actually, in the paper what's interesting is, you know, initially we were

11:38.360 --> 11:43.080
just naturally it's thinking that, okay, this is, so we were trying to track

11:43.080 --> 11:48.440
a channel and then the speed at which you move, you know, affects the

11:48.440 --> 11:53.320
Doppler of that channel, how fast it's changing.

11:53.320 --> 12:00.200
And if we know the Doppler, then the dynamics are well suited to the

12:00.200 --> 12:05.240
common filter in one particular example.

12:05.240 --> 12:08.800
So it's just a matter of making sure we have the right, you know,

12:08.800 --> 12:13.400
parameters for a common filter for that particular speed that we're at.

12:13.400 --> 12:18.920
And, and so when we're talking about Doppler, we're talking about the

12:18.920 --> 12:28.400
communication between like a fixed base station and a moving communicator

12:28.400 --> 12:31.880
like, you know, someone on a mobile device in a car and you're using the

12:31.880 --> 12:38.720
Doppler shift to, to kind of localize that, that device.

12:38.720 --> 12:39.720
Yeah, exactly.

12:39.720 --> 12:40.720
Is that the general idea?

12:40.720 --> 12:42.720
That's one, one example.

12:42.720 --> 12:44.440
Surprisingly, Doppler is everywhere.

12:44.440 --> 12:49.720
So wireless, a nice thing about wireless is you get great coverage because it

12:49.720 --> 12:54.080
bounces off a lot of things and sometimes transmitter and receiver aren't

12:54.080 --> 12:57.000
moving, but they're bouncing off of things that are moving.

12:57.000 --> 12:59.680
And so then we get Doppler again there.

12:59.680 --> 13:04.400
So, so it is a very ubiquitous problem that we do with even, even when I'm

13:04.400 --> 13:07.880
talking to you today, if we're on a, on a cellular system, we'd have to do

13:07.880 --> 13:10.880
with that to some degree.

13:10.880 --> 13:15.320
And so when you talk about channel tracking and Doppler and all that stuff,

13:15.320 --> 13:17.480
like why do, why do we care?

13:17.480 --> 13:19.480
Why do you care?

13:19.480 --> 13:24.400
As a, you know, someone who's building systems to help people communicate?

13:24.400 --> 13:25.800
Yeah, good question.

13:25.800 --> 13:31.640
So we always want to, like coming back to that shannan capacity, we always want to

13:31.640 --> 13:34.400
operate at that shannan capacity.

13:34.400 --> 13:40.920
And so it's evolved in our system to track this channel so that we know, don't

13:40.920 --> 13:43.920
put too much information if the channel is not very good.

13:43.920 --> 13:47.120
And then if the channel is really good, you know, let's put as much information as we

13:47.120 --> 13:52.840
can and opportunistically, you know, ride the wave of when it's good and when it's bad.

13:52.840 --> 13:53.840
And this is really.

13:53.840 --> 13:56.520
And how does that tie to Doppler?

13:56.520 --> 14:03.880
Doppler, the dynamic of the channel helps us to be able to predict how well.

14:03.880 --> 14:13.480
And then when we're actually trying to decode the signals themselves, we'll be able to

14:13.480 --> 14:19.320
resolve some of that signal better once we know how the channel has rotated through

14:19.320 --> 14:21.760
the course of time.

14:21.760 --> 14:25.160
And so those are the two aspects of it.

14:25.160 --> 14:31.160
And in this particular paper, we were deciding, we were looking more at the tracking the

14:31.160 --> 14:37.880
rotation so that we can resolve the signals that have been degraded.

14:37.880 --> 14:42.560
And when you say rotation in this instance, are you talking like phase shift or something

14:42.560 --> 14:43.560
like that?

14:43.560 --> 14:51.000
Yeah, probably using a lot of jargon, but you know, we'll send our communication signal

14:51.000 --> 15:02.080
usually, you know, your message that you want to convey goes through a very sophisticated

15:02.080 --> 15:11.520
remapping of bits into constellation and a MIMO transmission across antennas.

15:11.520 --> 15:15.000
And that's the signal that we're trying to get to the receiver.

15:15.000 --> 15:21.280
And then we want to be able to decode that original, you know, set of points that convey

15:21.280 --> 15:22.280
the message.

15:22.280 --> 15:25.920
And if that gets through, then we can always remap that back to the original information

15:25.920 --> 15:29.320
that was to convey it.

15:29.320 --> 15:38.680
Yeah, so maybe to kind of try to recap the setting here, going back to this Shannon model,

15:38.680 --> 15:43.880
you've got this transmitter, the transmitter is pumping information into this channel.

15:43.880 --> 15:48.200
There's a receiver that's trying to capture as much of that information as possible and

15:48.200 --> 15:51.920
kind of maximize the bandwidth or throughput in this channel.

15:51.920 --> 15:57.960
And there's inherently this assumption of a noise source that's like disrupting the communication

15:57.960 --> 15:59.600
between the two.

15:59.600 --> 16:09.120
I think we kind of think of, you know, as lay people, a straight line between the, you

16:09.120 --> 16:13.120
know, a cell tower and a mobile, but you know, as you've talked about the signals bouncing

16:13.120 --> 16:19.120
all over the place, you know, even if it wasn't bouncing, you just talked about MIMO and

16:19.120 --> 16:25.800
these other technologies, really the, there's multiple signals or channels kind of between

16:25.800 --> 16:31.440
the cell tower and the device and, you know, there's noise being inserted.

16:31.440 --> 16:36.000
The signals are all going different directions and the ideas that you have to figure all

16:36.000 --> 16:43.480
that you, the more you can kind of take the information you're getting about the network

16:43.480 --> 16:49.560
and the devices, Doppler and all this stuff, you can use that to ultimately kind of statistically

16:49.560 --> 16:54.640
predict what was sent at the device and vice versa.

16:54.640 --> 16:58.600
And that's how you, you maximize the, your bandwidth or throughput.

16:58.600 --> 16:59.600
Yes.

16:59.600 --> 17:00.600
I think you put it well.

17:00.600 --> 17:01.600
Yeah.

17:01.600 --> 17:02.600
Exactly.

17:02.600 --> 17:03.600
Got it.

17:03.600 --> 17:04.600
Got it.

17:04.600 --> 17:10.200
You know, common filter, where does common filter come into play in all this?

17:10.200 --> 17:11.200
Sure.

17:11.200 --> 17:19.320
So, the way the, the channel is evolving, this, you know, you fade up and you fade down,

17:19.320 --> 17:26.240
it's very well modeled in some cases, in a lot of cases, by an autoregressive model.

17:26.240 --> 17:34.560
And then common filters are very well studied and optimal way of tracking that dynamic

17:34.560 --> 17:36.320
system.

17:36.320 --> 17:42.320
And so, so that's, that's where kind of that solution is coming to play.

17:42.320 --> 17:44.160
Got it.

17:44.160 --> 17:52.200
And so, kind of going back to this idea of neural augmentation, talk about the kind of the gap

17:52.200 --> 17:56.400
between the common filter and what's observed in real world.

17:56.400 --> 17:57.400
Sure.

17:57.400 --> 17:58.400
Sure.

17:58.400 --> 18:02.280
So, in the real world, you're going to move, or things around, you're going to move at

18:02.280 --> 18:12.960
different speeds, which implies that your common filter should be using parameters for

18:12.960 --> 18:16.880
each speed, you know, nominally, that would be the best thing to do.

18:16.880 --> 18:23.160
And so, so like a very natural, you know, first attempt at this problem is you, you have

18:23.160 --> 18:27.200
a bank of common filters and you have a bank of speeds and then you, you have a two-part

18:27.200 --> 18:28.200
problem.

18:28.200 --> 18:29.200
What speed are you at?

18:29.200 --> 18:32.840
You figure that out, what common filter should you use.

18:32.840 --> 18:37.480
This is a, you know, it's a very simple, nice intuitive, but it's a bit, it's a two-part

18:37.480 --> 18:44.920
problem and it's also, doesn't necessarily scale as well because you have to go and train

18:44.920 --> 18:50.320
all this, this whole bank and, and then you have to figure out, exactly, you can't have

18:50.320 --> 18:55.840
an infinitely, you know, resume, resolve banks, so you, to figure out what kind of bins

18:55.840 --> 18:59.840
are you going to have to cover, what you need to cover.

18:59.840 --> 19:06.920
Then the other, so it's, it's very natural and, and you look at how people can just have

19:06.920 --> 19:12.000
deep learning, try to solve the system, so you can remove the common filter and say, okay,

19:12.000 --> 19:17.320
we have to deal with Doppler and common filter changing, why don't we just put an RNN

19:17.320 --> 19:23.320
in the system and then train it on all this data of the channel changing and then have

19:23.320 --> 19:26.200
it figure out what it should be doing.

19:26.200 --> 19:31.120
And it is a universal approximator, so if we give it the right amount of data, it should

19:31.120 --> 19:34.640
figure out to do what the common filter does, right?

19:34.640 --> 19:42.920
And specifically, would you be using the RNN to predict, to predict the, the channel characteristics

19:42.920 --> 19:47.160
or to predict the ultimate output bits, for example?

19:47.160 --> 19:53.280
So just the, just the channel itself, and then we would feed that into the rest of the,

19:53.280 --> 19:56.160
demodulator that would get the bits.

19:56.160 --> 19:57.160
Yeah.

19:57.160 --> 19:58.160
Okay.

19:58.160 --> 19:59.160
Got it.

19:59.160 --> 20:05.360
And so again, kind of universal approximator, given enough data and RNN should work, but,

20:05.360 --> 20:10.640
but, I think is where you were going.

20:10.640 --> 20:15.720
What, what we, the other thing we tried was let's just have an RNN to take the observations

20:15.720 --> 20:19.960
and then tell us what kind of common filter we should use.

20:19.960 --> 20:23.680
And then, you know, the nice thing now is we have somewhat of a continuum of parameters

20:23.680 --> 20:29.640
for the common filter and then we also can still have a nice way of making it end to

20:29.640 --> 20:30.640
end trainable.

20:30.640 --> 20:37.920
So unlike the two-stage approach where you have to go and have some kind of, you're sick

20:37.920 --> 20:42.720
of, of training things and building up different parts of the system, here we have one that

20:42.720 --> 20:48.440
we just give data to it and then give, you know, let it train.

20:48.440 --> 20:54.520
And, and so we, we tried all of these and, you know, the nice, there were some interesting

20:54.520 --> 20:56.200
things that actually came up.

20:56.200 --> 21:00.920
So, you know, naturally we, we want to see that we're doing better than everything.

21:00.920 --> 21:05.880
And, you know, we were able to show that this, what we're calling this neural augmented

21:05.880 --> 21:10.440
common filter, specifically we're calling it a hypernet common filter, since we have

21:10.440 --> 21:14.920
an RNN that's setting the parameters, it's kind of a hypernet.

21:14.920 --> 21:21.600
And then, you know, interestingly, so, so, you know, the benefit over the traditional

21:21.600 --> 21:26.320
approach is that it's end to end trainable, so it's much more straightforward.

21:26.320 --> 21:31.480
You can just expose it to data and then it learns and then, you know, it's ready to go.

21:31.480 --> 21:36.720
It makes the offline process much simpler.

21:36.720 --> 21:43.800
And it ends up being also, because there's a continuum of settings, you're not limited

21:43.800 --> 21:51.040
by the coarseness of binning that typically comes up from, you know, practical reduction

21:51.040 --> 21:55.080
of the problem of the solution.

21:55.080 --> 22:00.480
Now when we look at how it compares with the LSTM, which is what we used in this particular

22:00.480 --> 22:10.760
solution, one thing that was really interesting was that our hypernet common filter actually

22:10.760 --> 22:14.560
addressed unseen cases a lot better.

22:14.560 --> 22:22.040
And so, one important detail I didn't going to get to you earlier, but what happens when

22:22.040 --> 22:28.640
we're actually tracking the channel is that we don't, we don't get to, we usually use

22:28.640 --> 22:33.880
pilot symbols, so something that we know at the transmitter and the receiver, we send

22:33.880 --> 22:34.880
it.

22:34.880 --> 22:39.200
And then we use that pilot to figure out what the channel looks like, the fade and the

22:39.200 --> 22:41.760
phase shift and so forth.

22:41.760 --> 22:48.520
And that, you know, the frequency at which we send a pilot is a trade-off, we always have

22:48.520 --> 22:49.520
to deal with.

22:49.520 --> 22:53.680
Like if we send more, then we have a great look at the channel, but we don't have much

22:53.680 --> 22:58.560
information that we can send, and if we send less, the opposite.

22:58.560 --> 23:08.400
And so, one interesting thing was when we had the LSTM train on one particular pilot density

23:08.400 --> 23:13.760
or frequency at which we send these pilots, and we gave it a different density, one that

23:13.760 --> 23:18.520
was higher or one that was lower, it didn't just perform worse, it actually in some cases

23:18.520 --> 23:24.360
was somewhat significantly lower in performance.

23:24.360 --> 23:29.120
And so it was, you know, seemed like it was probably learning some things that would

23:29.120 --> 23:34.840
help it to track the particular case it was given for the training set.

23:34.840 --> 23:38.400
But yeah, but maybe you was using maybe the wrong features or is over-fitting in such

23:38.400 --> 23:41.560
a way that it was not good at generalizing.

23:41.560 --> 23:46.840
Whereas when we constrained it to be this hypernet common filter, it actually performed

23:46.840 --> 23:54.840
well, like it gracefully degraded when it went to actually did well when it went to this

23:54.840 --> 24:01.760
lower density or this higher density without having seen these in the training set.

24:01.760 --> 24:11.920
And so the two cases we're comparing here are the LSTM alone to predict the channel

24:11.920 --> 24:19.200
versus the model that's predicting the common filter characteristics.

24:19.200 --> 24:28.120
And the idea maybe is that in a sense, it kind of relates to this conversation I have

24:28.120 --> 24:29.120
in the podcast.

24:29.120 --> 24:34.280
A lot like we know a lot about the physical world and its behavior, and we've developed

24:34.280 --> 24:40.320
these models that, you know, are representative, that in this case, the common filter.

24:40.320 --> 24:46.680
So how do we couple kind of statistical approaches and physics-based approaches so that we're

24:46.680 --> 24:50.560
not, you know, kind of throwing out the baby with the bath water, right?

24:50.560 --> 24:57.480
And in this case, it sounds like the common filters providing some constraints or guardrails

24:57.480 --> 25:04.320
to the RNN that allow it to perform better even when it's or to generalize better.

25:04.320 --> 25:11.320
Yeah, exactly. I think it as well put exactly the point of what we're doing.

25:11.320 --> 25:18.120
And we tried other situations where not just the pilot density change, but even the strength

25:18.120 --> 25:20.560
of the signal to noise change.

25:20.560 --> 25:25.360
So we, you know, we could train it at one signal to noise ratio and then test it at a lower

25:25.360 --> 25:27.400
one or test it at a higher one.

25:27.400 --> 25:35.480
And we saw, again, a similar robustness from having a hypernet common filter versus just

25:35.480 --> 25:40.640
a pure neural network.

25:40.640 --> 25:49.480
And this idea of, you know, what you're calling neural augmentation or hypernet augmentation,

25:49.480 --> 25:56.400
are you applying it to, or have you applied it to other types of models or other problems?

25:56.400 --> 26:01.800
Yeah, I think that it's a great that you brought that up.

26:01.800 --> 26:07.960
I like to think of this particular paper and, you know, all the things also from the

26:07.960 --> 26:10.160
podcast a year ago with Max.

26:10.160 --> 26:17.120
This is kind of a seed idea and we wanted to really go deep in one particular problem

26:17.120 --> 26:21.040
so that people can see, you know, the different trade-offs that we were trying to understand

26:21.040 --> 26:24.680
and see how things were doing.

26:24.680 --> 26:28.160
But then it's not that a common filter is going to solve every problem, but there are

26:28.160 --> 26:31.840
going to be these other core algorithms in different problems.

26:31.840 --> 26:37.280
And we want this philosophy of, you know, don't forsake all the domain knowledge you've

26:37.280 --> 26:38.280
built at this point.

26:38.280 --> 26:40.280
It's really just a little bit of mismatch.

26:40.280 --> 26:45.440
You have to figure out what that is and put the neural network such that we give it,

26:45.440 --> 26:50.960
you know, the right amount of flexibility to learn how to adapt, but not too much that

26:50.960 --> 26:59.800
it might, you know, learn the wrong things and kind of adapt the solution the wrong way.

26:59.800 --> 27:05.560
Before we jump into the next paper, can you speak specifically to the results you saw

27:05.560 --> 27:06.560
with this?

27:06.560 --> 27:14.080
You kind of spoke generally to it, it performed better than the LSTM alone, but how did

27:14.080 --> 27:20.200
it perform relative to the original common filter implementation?

27:20.200 --> 27:27.780
The original, like the classical solution where you can classify it, that one, the short

27:27.780 --> 27:31.280
coming is more in how coarse the bins are.

27:31.280 --> 27:39.280
And so it's a very nice smooth degradation now, or I should say smooth interpolation across

27:39.280 --> 27:45.880
these bins, because we can't, in the classical approach, we can't quite just, you know, have

27:45.880 --> 27:52.760
a very fine resolution of speeds from 0 to, you know, 500 kilometers per hour.

27:52.760 --> 27:58.600
We have to somehow make that practical and do, you know, a dozen bins or less.

27:58.600 --> 28:03.960
And so there's no, there's a lot of trial and error or a lot of heuristic behind solving

28:03.960 --> 28:12.400
that, and the hypernet actually is able to give us a different way of having, like, almost

28:12.400 --> 28:14.680
a continuous interpolation there.

28:14.680 --> 28:17.920
That's really where we saw a nice, healthy gain over that.

28:17.920 --> 28:18.920
Got it.

28:18.920 --> 28:19.920
Got it.

28:19.920 --> 28:20.920
Awesome.

28:20.920 --> 28:21.920
Awesome.

28:21.920 --> 28:29.800
So the next paper we want to talk about is focused on RF sensing and communication.

28:29.800 --> 28:33.920
Introduce us to the setup here and the problem that you're trying to solve.

28:33.920 --> 28:34.920
Yeah, yeah.

28:34.920 --> 28:41.880
This is another, this is kind of a fun area, I would say, because, so we've, I kind of

28:41.880 --> 28:48.280
walked you through the idea that signals degrade environment, interacts with the signal

28:48.280 --> 28:55.120
going from the transmitter receiver, and we have to be able to track that well and deal

28:55.120 --> 29:00.280
with it so that we get the information through efficiently.

29:00.280 --> 29:07.880
One interesting, you know, the dual of this kind of is that, the environment interacts

29:07.880 --> 29:12.200
and it, you know, can degrade our signal, it hurts the information that we send.

29:12.200 --> 29:16.240
But at the same time, there's a lot of information about the environment when it's degraded

29:16.240 --> 29:17.640
the signal.

29:17.640 --> 29:23.800
And so, so then, oh, how much can we learn about the environment whenever it degrades the

29:23.800 --> 29:28.640
signal, becomes like a question that we want to get to.

29:28.640 --> 29:36.440
And now when we go to 5G, we have like a much larger antenna raise, much wider bandwidth.

29:36.440 --> 29:42.600
It's like a richer signal set now that we have to really understand how things are being

29:42.600 --> 29:46.280
interfered with from the environment to the communication system.

29:46.280 --> 29:49.920
And so we flip this around and we say, well, instead of trying to get the information

29:49.920 --> 29:56.920
through, let's try to learn what's in, what's in the environment as much as we can to see,

29:56.920 --> 30:01.840
you know, what, what can we, how far can we go at this, essentially?

30:01.840 --> 30:07.360
And so, you know, a very simple, you know, the very starting point where they both interact,

30:07.360 --> 30:13.160
you know, is that can we try to predict when the fate is going to come and go and then

30:13.160 --> 30:15.280
you know, very simply like that.

30:15.280 --> 30:22.920
But as you may have seen, even industries are like small companies are starting to introduce

30:22.920 --> 30:24.400
this.

30:24.400 --> 30:31.040
There are different other levels of more sophisticated inference that can be done, like understanding

30:31.040 --> 30:38.640
the presence of a person in a particular space or the activity of detecting an activity

30:38.640 --> 30:42.600
in a particular space.

30:42.600 --> 30:48.800
There has been gesture recognition, I believe that you've probably seen this on phones

30:48.800 --> 30:51.440
and other places.

30:51.440 --> 30:57.000
And then a location in position is another very interesting use case where it's, you know,

30:57.000 --> 31:02.120
called RF fingerprinting sometimes where you actually try to pinpoint where the activity

31:02.120 --> 31:06.000
is happening relative to the environment.

31:06.000 --> 31:13.000
I assume the gesture, all the gesture stuff was based on sensors in the phone, like,

31:13.000 --> 31:14.800
you know, camera or a light or something.

31:14.800 --> 31:22.040
It never occurred to me that they might be using RF interference to, to track gestures.

31:22.040 --> 31:31.600
Yeah, that's more recent, I would say, relatively speaking, but there's a technology.

31:31.600 --> 31:36.880
As you move higher in frequency, you can actually separate the transmitter from the receiver

31:36.880 --> 31:38.480
in a very small space.

31:38.480 --> 31:44.800
So a phone can transmit and receive without jamming it so too much.

31:44.800 --> 31:48.520
And that's the technology behind some of the recent gesture recognition.

31:48.520 --> 31:53.520
So a phone will transmit at a millimeter wave frequency and listen at the same time.

31:53.520 --> 31:58.640
And then from that, it can see signatures of things moving.

31:58.640 --> 32:02.640
And then, of course, by machine learning to figure out, is that signature, you know,

32:02.640 --> 32:05.640
a swipe left or a swipe right or?

32:05.640 --> 32:06.640
Oh, wow.

32:06.640 --> 32:07.640
Wow.

32:07.640 --> 32:08.640
Yeah.

32:08.640 --> 32:15.040
And you mentioned some other companies working on this a couple of years ago, back in February

32:15.040 --> 32:22.320
18, I did an interview with a company called Ariel that is in this space, like using Wi-Fi

32:22.320 --> 32:31.000
and home or commercial buildings to detect presence and motion and, you know, in an elder

32:31.000 --> 32:35.280
care scenario, if someone falls, that kind of thing.

32:35.280 --> 32:41.240
It sounds like that's the same kind of problem or same kind of result you're tackling.

32:41.240 --> 32:46.240
It's different about the work that you, that's in this paper.

32:46.240 --> 32:47.240
Yeah.

32:47.240 --> 32:49.240
Great point.

32:49.240 --> 32:50.240
Yeah.

32:50.240 --> 33:00.440
So a lot of really nice use cases, our knowledge are supervised and very densely labeled.

33:00.440 --> 33:07.680
And so, which is a great solution, but it's not necessarily something that scales.

33:07.680 --> 33:15.360
So what we did here was the team, it came back to the problem and they asked, is there

33:15.360 --> 33:19.360
any way we can reduce the requirement to labeling?

33:19.360 --> 33:24.280
If we can make it completely unsupervised with the proper loss function or if we can have

33:24.280 --> 33:27.040
some weak labeling.

33:27.040 --> 33:31.160
And that's, and we looked at, you know, instead of looking at, you know, all the problems

33:31.160 --> 33:32.800
in the space, we looked at positioning.

33:32.800 --> 33:40.360
So this seemed like a pretty challenging problem, but at the same time, a really nice one that

33:40.360 --> 33:48.440
has a lot of commonality with other applications at bar, since, and so, and so, you know, there

33:48.440 --> 33:56.000
was a prior result where, since you know that what you're tracking is moving in time, they

33:56.000 --> 34:02.760
looked at using a triplet loss to try to space things out so that in the latent space,

34:02.760 --> 34:08.880
so in, in the real space, we can kind of assume that samples are close together because

34:08.880 --> 34:10.040
they're close in time.

34:10.040 --> 34:15.360
And so in the latent space, we, it should be that they're also close in the latent space

34:15.360 --> 34:17.600
because they're close in time.

34:17.600 --> 34:22.640
And then, and then in these previous results, they had a, you know, a nice first step

34:22.640 --> 34:31.080
in showing that, okay, we can get a reasonably good similarity between the latent space

34:31.080 --> 34:35.800
distance and in the real distance in, in the real world.

34:35.800 --> 34:40.000
But it wasn't, you know, perfect because it wasn't geometrically consistent.

34:40.000 --> 34:46.720
So a floor plan may not look like a floor plan, even though you are moving around and close

34:46.720 --> 34:49.680
distances were close.

34:49.680 --> 34:55.920
The, the part that was missing is that, you know, sometimes you may be close in distance

34:55.920 --> 34:59.720
but not necessarily close in time because you may have walked in a circle or you may have

34:59.720 --> 35:03.640
come back somehow to the point that you were at.

35:03.640 --> 35:09.720
So our team looked at, um, clustering, a lot of deep cluster, you know, really interesting

35:09.720 --> 35:14.040
technology that's been used for other things and self-supervised learning.

35:14.040 --> 35:19.680
And, and looked and say, what if we put triplet loss together with this deep cluster so

35:19.680 --> 35:25.200
that we can address this problem when we do come back to the same space that we know

35:25.200 --> 35:29.680
that, okay, they actually should be close together and not for our part because of their,

35:29.680 --> 35:32.160
their cluster in another dimension.

35:32.160 --> 35:40.440
And so, uh, and so putting those two together, uh, now our latent space, which, um, uh, looks

35:40.440 --> 35:48.600
a lot better, a lot closer to reality of, of distance and position than, um, then before

35:48.600 --> 35:51.800
and then, you know, previous methods before.

35:51.800 --> 35:57.400
And so now you can go and just, in theory, you just walk around a room and then you're

35:57.400 --> 36:02.480
just listening to all the RF signals and with the loss functions and so forth training

36:02.480 --> 36:07.840
it, you come back and you see, okay, the latent space looks a lot like the room and where

36:07.840 --> 36:09.240
you were in the room.

36:09.240 --> 36:13.640
And it's not perfect, but it's a lot better than, than previous by doing this, both this

36:13.640 --> 36:16.720
triplet loss and then this clustering.

36:16.720 --> 36:21.680
And then our team won a, you know, one step further and they said, um, what if we just,

36:21.680 --> 36:26.680
what if we just coarsely told you, okay, you're in a room and the room has this shape and

36:26.680 --> 36:29.200
then you, you moved to another room and the room has this shape.

36:29.200 --> 36:34.320
So it's, it's much, it's still, it now becomes labeling, but it's a much lighter labeling

36:34.320 --> 36:40.760
instead of having, uh, some way of annotating exactly where this, um, person was moving around

36:40.760 --> 36:41.920
the room.

36:41.920 --> 36:45.880
You just tell it, okay, I'm in a room, I'm moving around, but the room has this boundary

36:45.880 --> 36:48.520
and that's all I'm going to know.

36:48.520 --> 36:55.640
And then, you know, the really cool thing was that now they actually could get to, um,

36:55.640 --> 37:00.320
you know, within one or two meters, which was as good as the supervised case where we

37:00.320 --> 37:06.400
did have a very precise tracking of the user and the labeling.

37:06.400 --> 37:11.400
And so by putting all these things together, then the idea is that, um, it's very simple

37:11.400 --> 37:18.720
to go in and, and build up, um, I know that they can infer where you are from the interference

37:18.720 --> 37:28.120
in the RF, uh, that it sees, um, and so the, the two parts of that are the, the triplet

37:28.120 --> 37:36.400
loss and the clustering, the deep clustering, that's fully unsupervised and then the, the,

37:36.400 --> 37:41.080
what you described there towards the end of, um, oh, that's like some labeling, localizing

37:41.080 --> 37:42.080
in the room.

37:42.080 --> 37:43.080
Yeah.

37:43.080 --> 37:44.080
It's done labeling.

37:44.080 --> 37:45.080
That's the weak labeling part.

37:45.080 --> 37:46.080
That's right.

37:46.080 --> 37:47.080
Yeah.

37:47.080 --> 37:49.080
Got it.

37:49.080 --> 37:57.080
And, uh, were those, uh, were those done successively or were those done, was the system

37:57.080 --> 38:05.000
trained with kind of two components to, to the, the training process, this unsupervised

38:05.000 --> 38:07.640
part and the weak supervised part.

38:07.640 --> 38:08.800
It was done together.

38:08.800 --> 38:12.720
So there, there is one, I should say, if you read the paper a little bit further, there

38:12.720 --> 38:17.040
are some things we do to initialize one other loss function that we put in.

38:17.040 --> 38:22.600
It's a jumpstart it, but overall those two key, key parts that we're doing together.

38:22.600 --> 38:31.080
I should mention that there's a, uh, a video of this system, um, that will post a link

38:31.080 --> 38:33.080
to in the show notes page.

38:33.080 --> 38:37.080
It was demonstrated at, uh, MWC, uh, Mobile World Congress.

38:37.080 --> 38:38.080
Is that right?

38:38.080 --> 38:39.080
Yeah, yeah.

38:39.080 --> 38:40.080
Thank you for reminding me.

38:40.080 --> 38:41.080
That's right.

38:41.080 --> 38:46.080
Um, you know, one of the really exciting things about this was, um, we had a whole team

38:46.080 --> 38:53.600
that could give us real world data and then different locations and, um, and we can really

38:53.600 --> 38:57.880
prove out these ideas is this, how robust is this an approach?

38:57.880 --> 39:04.840
And although the, the paper and the demo probably showed two particular types of layouts, um,

39:04.840 --> 39:09.720
we did test them on more and also the situations within each layout will also play around with

39:09.720 --> 39:15.200
like, you know, someone holding a, a metal sheet, for instance, and, and so if you go to

39:15.200 --> 39:22.200
that, uh, MWC demo, you can, you can get a nice, um, feel for, you know, what it, how does

39:22.200 --> 39:23.200
it look?

39:23.200 --> 39:27.720
You know, they have a nice animation of a person walking around, which is the ground truth

39:27.720 --> 39:31.920
and then you can see where, like, a dot to tell you where should you be?

39:31.920 --> 39:36.840
And, uh, it's pretty amazing thinking that, unfortunately, the MWC doesn't quite tell

39:36.840 --> 39:41.920
you that it's unsupervised or weekly supervised, which I personally feel like even more amazing

39:41.920 --> 39:47.360
than even the idea is, like, you're being able to be tracked with just RF signals is amazing

39:47.360 --> 39:48.720
in its own right, I think.

39:48.720 --> 39:53.560
But then when you go a little deeper and you realize, oh, this is something that they've

39:53.560 --> 40:00.400
gone and made it, you know, much more, um, scalable in a sense, um, that's, that's really

40:00.400 --> 40:03.400
a, uh, amazing that the team was able to do that.

40:03.400 --> 40:04.400
Yeah.

40:04.400 --> 40:13.000
I've wondered in thinking about these applications, like, do you, uh, to what degree do you need

40:13.000 --> 40:20.880
kind of inside access to the, to the devices or the, the Wi-Fi access point in the case

40:20.880 --> 40:26.160
if Wi-Fi is the, the signal that you're using in order to do the, or is there some, you

40:26.160 --> 40:32.680
know, net flow or logging or something, I can turn on in my, my unify system that will,

40:32.680 --> 40:37.040
uh, collect all the data and I could try to replicate what you're doing and build some

40:37.040 --> 40:41.080
system that tracks presence within, within my building here.

40:41.080 --> 40:46.160
There are some standards activities happening to, to make this somewhat, um, I guess like

40:46.160 --> 40:47.640
a standard that's accessible.

40:47.640 --> 40:50.280
I think we mentioned that a little bit in our paper.

40:50.280 --> 40:56.600
Um, I, I know that, uh, so I can't speak on, like, our product and other products in

40:56.600 --> 40:57.600
the field.

40:57.600 --> 41:01.240
It's, uh, I don't know that very well, but I do know that there are these capabilities

41:01.240 --> 41:06.680
and, you know, we've had the benefit of working with the, those, those, um, like we have counter

41:06.680 --> 41:11.600
parts on like a wireless research team and they really help us to enable us to get the

41:11.600 --> 41:14.920
right data and, and clean up the signal and make sure.

41:14.920 --> 41:19.680
So, um, you know, in theory, you should be able to do some of these, I, I think, but

41:19.680 --> 41:25.680
I, you know, the, the actual execution, uh, I have to have another show with some other

41:25.680 --> 41:26.680
experts.

41:26.680 --> 41:33.600
Maybe that's awesome, yeah, awesome, you know, maybe to kind of wrap, wrap things up, um,

41:33.600 --> 41:41.680
you know, these two papers are, again, kind of under this theme of, you know, how machine

41:41.680 --> 41:50.040
learning can be used to enable, you know, the more effective delivery of network services

41:50.040 --> 42:01.600
like 5G, um, and in some ways, a lot of that is enabled by increasing sophistication on,

42:01.600 --> 42:08.360
on the devices themselves, uh, and, um, machine learning capabilities on device.

42:08.360 --> 42:12.160
Uh, I'd love to hear you kind of riff on, you know, where you see all that going and what's

42:12.160 --> 42:13.160
possible.

42:13.160 --> 42:14.160
Yeah.

42:14.160 --> 42:23.000
Um, uh, I should say that, like, when, when you see this demo, MWC, it's part of, uh,

42:23.000 --> 42:29.200
I would say like a series of four or five demos in machine learning, uh, and 5G.

42:29.200 --> 42:35.760
And there's a lot of, uh, really, you know, cool applications, um, across, uh, like,

42:35.760 --> 42:40.800
for instance, like, there's outdoor positioning, there's, um, milling away beam forming.

42:40.800 --> 42:43.520
There's, um, you know, efficient channel state feedback.

42:43.520 --> 42:52.840
A lot of these have core designs enabled from deep learning and, um, they are also relying

42:52.840 --> 43:00.520
on, uh, the device having a very capable AI, um, and, you know, that's been, uh, a core

43:00.520 --> 43:06.280
you've probably seen on the show, uh, from, uh, many of our, um, you know, Qualcomm

43:06.280 --> 43:12.360
participants were focused on making sure that, uh, what AI can do, it becomes ubiquitous

43:12.360 --> 43:18.360
so we can bring it to mobile and, and have it in as many places as we can, and it, um,

43:18.360 --> 43:23.520
not only are the use cases that we come to associate with AI, like, you know, not language

43:23.520 --> 43:29.000
processing or computer vision, perception, but even making, you know, the wireless system

43:29.000 --> 43:35.840
better also is now benefiting, or potentially going to benefit from having, uh, a very capable

43:35.840 --> 43:45.760
device. And, um, and in this, um, this area of, say, you know, joint RF sensing are using

43:45.760 --> 43:53.080
the COM system for RF sensing, um, this is, uh, like, like, like other things I talk about,

43:53.080 --> 43:59.840
it's this very simple, um, example, and it's a seed idea, but there's certainly more things

43:59.840 --> 44:05.840
that can come from it, and we didn't demonstrate it on devices, mobile devices, we actually

44:05.840 --> 44:10.000
demonstrate on base stations, but you can imagine that, um, there are other things that

44:10.000 --> 44:14.960
you can have the mobile device get involved. And, you know, building up an awareness of

44:14.960 --> 44:19.320
the environment, here where we're showing that you can track people, uh, you can imagine

44:19.320 --> 44:25.760
over, uh, over the course of this that you can, you can start, um, understanding environment

44:25.760 --> 44:31.640
and, um, making the whole communication system more efficient, because now you don't have

44:31.640 --> 44:36.440
to serve, for instance, you don't have to blindly search for, whereas the best, um,

44:36.440 --> 44:40.040
where's the base station coming from, or where's the best direction to have a communication

44:40.040 --> 44:45.680
link, because, uh, you've established an awareness of where strong reflectors are, where blockers

44:45.680 --> 44:50.360
are, and, and where you're moving in the environment. So that's something we're really excited

44:50.360 --> 44:55.600
about moving forward to see, um, this, um, joint interaction between, you know, sensing

44:55.600 --> 45:00.160
helping to communicate AI, and sensing helping communication, and, you know, AI on device

45:00.160 --> 45:08.000
helping this, this, um, enable this, mm-hmm. Awesome, awesome. Well, Joseph, thanks so much

45:08.000 --> 45:13.680
for joining us and sharing a bit about what you're up to, uh, and walking through these

45:13.680 --> 45:19.360
two papers with us. Great, um, I hope, uh, hope you enjoyed it, and, uh, hope you look

45:19.360 --> 45:22.360
forward to seeing more stuff that we're going to do, because we have a lot more coming.

45:22.360 --> 45:50.360
Awesome. Thanks so much. I certainly did.

