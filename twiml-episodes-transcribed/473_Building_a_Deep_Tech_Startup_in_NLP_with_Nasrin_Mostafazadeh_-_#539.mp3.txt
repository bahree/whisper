All right, everyone. I am here with Nestreen, most of the
day. Nestreen is the co-founder of Vernique. Nestreen, welcome back to the
Twonwall AI podcast.
Thanks so much for having me again, Sam.
For those that recognize the name, Nestreen is a long-time friend of the show and
this is your third interview maybe. The last time we caught up was in January of
2020 before so much in the world changed and we were talking about trends and
natural language processing and today we'll of course be talking a little bit
about that but we'll be focusing on some big changes in your world since we
last spoke and starting with the company that you founded. So maybe catch us up
a little bit on big changes in your world since the last time.
Absolutely. Well, it's so interesting that the last time that I talked with you
was January 2020. It was precisely third of January 2020 and the reason I
remember this is that you may recall it was literally the day after U.S.
basically went on the brink of having a war with Iran. So we were all extremely
stressed. That was a night. I literally didn't sleep. We were all like checking
our phones trying to see whether or not there will be literally a war and it
was just a very bizarre time. So that's kind of how 2020 started for a bunch of
us not even knowing where it's headed. So I'm even third of January was a very
very weird year. So anyways since then that that very even actually played a
major role in how the rest of my life went on from that point on. So
basically diverse so many other things that happened like on eighth of January
there was this plane that was downed with like 176 people on it. A lot of them
Iranians some of whom I literally went to school with you know who could have
been literally me. So after so much thinking I always you know I've been
working in the startup scene for the last five years or so and I truly
believe in wanting to make impact through the power of startups and through
being able to laser focus of the particular fundamental problem in real
world. So anyways I always wanted to do this and this whole series of events
around like January and February 2020 made me kind of think how blessed I am as
an individual and the kind of opportunities that I have and I'm not
necessarily leveraging with older people that didn't even get to live to want
to fulfill their dreams like it felt like it's time so I should just just do
it and go for it. So anyways the process of starting learning was so many you
know years of in progress basically but it was always about waiting for the
right time for the right time. And then in February 2020 I was like that's it I'm
gonna start it. And hilariously the first day basically official first day of
Bernic is March 1st 2020. Not knowing what we are really up for so we had all
these omit my co-founder and I've had a New York City. Yeah we had all these
grand plans of starting this deep tech AI company in New York City with like
you know a bunch of plans as to when we go fundraising, when we go hire our team
and of course March 2020 the you know shutdowns started and then we in April
so we realized that okay we are in the middle of a global pandemic so the rest
is kind of history it's the timing was impeccable to say the least so we
basically kind of put everything on hold for a couple of months just to see
where the world is going like it wasn't necessarily clear that anyone wanted
to even think about a brand new AI company while everyone was basically
looking their booms. So yeah we just waited a couple of months and then around
like late 2020 we were like okay let's just go for it so we started a fundraiser
fundraising and in about a month or so we could like close around and then we
started hiring and now we are based in New York City if you're in flat iron
specifically it's like the dream neighborhood we're working in a physical
office and this is our space and it's been just a really really great time to
to want to do this honestly despite all the hurdles how hard it was to go
through the pandemic to start a pandemic company basically I think it has
helped us build all sorts of muscles that we never thought we can
and hence we are really in a very good shape in terms of all the other
hurdles that we have to overcome moving forward. That's awesome that's awesome
congratulations on that. So the company is as yet stealth and not much is
known publicly about what you're up to but you've promised that you're going to
share a little bit of pull back the kimono a bit so to speak.
What's the company up to? What are the challenges that you're hoping to take on?
Absolutely so our mission is to enable anyone to make data informed decisions
be for their personal matters or for their businesses without having
any kind of technical background and what that means is that we are
basically innovating in the human machine interfaces area where we want to
replace hard to grasp things such as programming languages with other
intuitive modalities of interaction including of course human natural
language which you know given our backgrounds is abundantly clear but we are
not just you know biased thinking that natural language is the
answer to anything and everything in terms of intuitiveness we are thinking
actively and working at simply towards other like modalities of interaction
that would be really easy to use and intuitive in the given context.
So basically this is like two degrees how much we usually share publicly but
I love talking with you so I would love to start sharing a little bit more in
terms of our vision for Verneak and what kind of a technology
of your building so very deep tech company meaning that we are really
we are overcoming various like scientific and engineering challenges
that would ultimately enable us to build such a platform that I was talking
for data informed decision making so what does data informed decision
making means it means that there's all sorts of data out there they can come in
any shape or form they can basically have any format they could be any small
any large they could basically be anything and everything and
when you want to put an interface on top of it and enable anyone to use it
like let's say get and the little calls insights about it or like just ask
any kind of questions that they can they have that can help them
better their lives or their better their businesses that means that you have
to have interoperability and that means that you have to be domain general
we are not trying to build like something that will be just working in one
sector we don't want to build something that is going to be just in a
particular domain operation we want to build a truly domain general AI
platform that can have interoperability across all sorts of data so it's a pretty
grand mission in terms of the technology that it needs and we are actively
working on all sorts of problems that in the academic sense has been
you know an issue for the past couple of years as well so we are working
on basically building for some foremost intuitive and easy to use
interfaces including natural language building a domain general natural
language interface in and of itself is very very challenging
but mainly if you're trying to make it controllable we're trying to make
sure to be assigned provenance as to where the data source comes from
and what kind of data you're basically putting in the loop
on top of it we're trying to make sure that these
basically interfaces that we put are controllable
meaning that we can have interaction with them and we can teach them
or help them forget something that they've learned that was wrong
you're also trying to make sure that these models are actually
able to get all sorts of feedback and make better decisions down the road for
the sake of the user so basically they should be able to not just
base their decisions that they help the user make on one source but like just
bring all the bits and pieces together and basically do reasoning
but so many other characteristics that this kind of a fundamental AI
platform of your building should have including the fact that it should be
amenable to data privacy issues and so there's so many other things if you're
actively working on but in terms of our lines of AI research we are
of course working on conversational agents you're building basically dialogue
systems that have these features that I was just
outlining you're also working on like old sorts of zoning phenomena that are
not data hungry that actually can help us go from it domain to another with
like the least amount of time and the least amount of
supervision of course but we also have problems on the data side itself so
building a platform that has interoperability
across the board requires like innovations in distributed systems
requires innovations in building like runtime run time engines
that can actually digest all sorts of data and understand it so
it's not just AI research that is a problem that we are tackling but also
you know other kind of computer science
issues that we have to grapple with on a day-to-day basis and I will
add that we are very mindful of having it like design
elements and design driven thinking to be the front of the center of what we
are building so that we don't kind of like repeat the mistakes that have been
made in general in the texting of like bunch of technical people getting
together thinking they have a intuitive solution and then turns out
it's really not usable so that's that's our front and center we are really
striving to build something that works for the masses as opposed to
something that is just you know for the sake of pushing the boundaries of AI
how big is the team so far? we were total of eight people we had like six or
so interns also that loved us so we are very small we're
hiring across the board we used to be just hiring on for like research team and
the engineering team but now we're also hiring on the business side so we are
hoping to grow to to over so more people as soon as possible we wanted it
yesterday but hiring is the toughest one of the toughest things in
my experience yeah I ask because the you've outlined a pretty broad
set of areas not just that you want to build product in but that you need to
do fundamental research in and that sounds like a ton for eight people
oh my god how do you yeah before we get to kind of how you take that on
maybe another way of coming out that is like how do you think about the
MVP for the product like when I think of you know the simplest
thing that you know kind of the simplest version of the the vision you
outlined I think of something like a you know natural language query generator
but those you know exist they're not without
challenges like how do you think about the the MVP and how do you
contrast with something like natural language query generation good question
so I will just first inform us say something as a in like in
parentheses we call MVP legum at Bernie so legum is this Swedish term I don't
know if you're familiar with it that means just to write them out and just
there's only like we take issues over the night we take
issues on like minimum viable product often not be really minimum and not
being really viable so anyway the question is what's just to write
them on for us right just what we've been dealing with for the past
like year now doing like R&D until we get to a point that we're
comfortable with taking our product out so it's a very
evasive complex question what the logon basically should be for our domain
on the business side what we're doing is that we're very practical we are taking
this technology one domain at a time we're like right now focusing on a
particular domain for example that we're hoping to come out with in the next
couple of months and in that particular domain then you have this
you know flexibility of narrowing down the data that you're training on narrowing
down basically the capabilities as well right so for example right now
we we know that we want our system to be instantaneous and it is so we have
like a threshold that we know okay if it's responding after one second
it's like definitely a downer but if it is like we can just keep pushing the
boundaries so there are such parameters that we are kind of tuning but
anyways so in terms of the it taking it one domain at a time
we are doing that but we have this rule in house that we are like if it is
basically diverging more than 20% from the general domain general platform
we are just working too much on one particular domain so basically we are
making our logon or MVP to be an 80% of the same kind of code base same kind of
technology that we would have and spending 20% of time in a particular
domain without it generalizing out of it so it's it's been it's not easy I
would say and I think I will have a more clear answer to that when we are out
with our product I know what I said is a little vague as to what the MVP should
be but there's so much to talk about in terms of how to
curate the exact packaging of such a technology
so that is still meaningful you can get enough
signal back from the market and from the actual users and then keep iterating
and is the example of some kind of natural language query is that
directionally you know accurate accurate enough to give us some to provide some
concrete grounding for the conversation you're going domain at a time some
envisioning you pick a domain who knows what that domain is let's say
contracts you know legal contracts right and so you know some lawyers want to
do discovery and it's hard for them to find what they want and so
you're essentially giving them a box to type in and you're doing smarter
things with what they type in to get them to you know to turn that into a
query that you can run against whatever systems they're trying to search
against as an example but that's you know that's the unstructured text
example you know there's the structure text example you're
working with you know power companies and you're trying to help them manage
their grids better or something and you give them a box to
you know tell me the you know aggregate power across whatever whatever
six regions I guess I'm you know the picture that
is coming to mind is maybe you know
AI or natural language interfaces for like business intelligence types of
schools or problems yes that's that's very close
that we can talk for hours and hours right about the state of the field like
what are the relevant technologies how they're failing and why they're
failing and why what you're doing is is really different but yes at the end of
the day it's it resembles that so basically let me
move you an example this is not what we are doing right now
but one of the reasons we wanted to do what we are doing is that even as
technologists it's so hard to make decisions based off of your data
because it just requires so many bells and whistles so
for example you just asked me right before this like what did you eat for breakfast
right and I told you well I don't eat breakfast so as an individual I
do intermittent fasting I have this app that I'm recording
the number of hours that I'm not eating a day I've been just doing it
abitually in the past couple of years then I have this other app for I'm
recording what I'm eating every day and then just because I have some like
underlying conditions that I have to be careful with whatever x, y and z
that I'm like putting in my body basically and then I have this other app
where I'm like basically recording my late I hop on a scale rate to scale
every morning personally so there's this app that is capturing
the data from my health on a day-to-day basis on my bait on a day-to-day
basis so anyways as an individual like myself although I'm a
technical person it's so hard for me to get the answer to a question like
I don't know what is there any correlation between my weight loss and the
number of hours that I'm intermittent fasting right
and why is it hard because it requires me figuring out how to download the
data from all of those apps if you even can if you even can exactly
and then maybe I don't know going to a like opening up
like a ipython book and trying to remember what is the correlation function or
some sort and then trying to call it and then coming up with the
answer right it just takes so much time and I am a
technical person so imagine what the world looks like for other individuals and
small businesses who have all these kinds of data and they are making wrong
decisions on a day-to-day basis because of their lack of access to such
easy-to-use interfaces so anyways we want to very much in line be what you
said you're not like you know basically doing any of these things that I
mentioned right now but in the long run for the company that's
division we want it to be that we have this one
interface that we can put on top of anything and everything and it can
smartly navigate its way to find the right sources
and then come back with the with their results
but it definitely is basically like a natural language
quarrying interface but as I mentioned we believe
tremendous we believe in the tremendous value that other modalities of
interaction bring into the scene and that's something that has been
definitely neglected but on top of it you know I've worked on
natural language understanding basically my whole
like life like not even adult life like like whatever 15 years right there
just no one knows how to build a domain general
language interface like that we've had tremendous
progress in the field in the past couple of years which is why
likes of myself are motivated to want to finally take
of you know this kind of technology to the market so that we can get
you know clear signal as to the flaws right and the problems and the
solutions of feedback into that basically academic AI world
we could go down the rabbit hole of
wearables and personal health tech and all that kind of stuff and maybe that's a
a fourth conversation but for now I think the the thread that I want to pull a
little bit on is the the state of AI research
in the domains relevant to what you're trying to build
because a lot of what you're I think your
contention is is hey that you know the idea of a search box that
you know lets you find things out right that's something we've been pursuing
for a while but we've been failing and some of that is
execution and you know or different execution and different vision
but some of it is that the research or the technology just
fundamentally isn't there and so maybe a next place to explore is
you know where you see the gaps in the technology and how you're
using you know that assessment to kind of prioritize the way
you're approaching research at Verneak.
Absolutely so I think this is very much actually
continuation of the conversation we had in January 2020
when you know I was reviewing basically the state of the field
if you you may recall so my net was that we've come a very long way
in natural language understanding and natural language processing in general
in the past like now six years or so it's been tremendous
how much progress we've made not on just down a stream past but also in real
world products basically that have been impacted by these kind of
technologies but I characterized like the flaws in a few ways that I think
some of which are now kind of being
addressed by the recent developments so like just to
backtrack a little bit so it's kind of interesting so I started my personal
work in natural language understanding
because I was back in times is back in high school I used to work in robotics
then I switched to natural language understanding and comments this
reasoning in particular because I came across this motivating example that
I saw in a random book that was like for an AI system for a machine to understand
natural language it requires to put together lots of bits and pieces about
the world that it is grounded in and hence it's a so-called AI
complete problem so the motivating example was that
the monkey ate the banana because it was hungry and
is the it referring to the you know monkey or the banana
basically was the the the riddle for the AI system
so I literally literally started my life in AI in
sorry natural language understanding for for that very same problem
we're tackling that very same problem which I found fascinating
and then fast forward these kind of problems were really not the focus for
the field for a very long time until in 2015 and
16 or so that these you know at the time it was like
biolistiums that were suddenly starting to to to leave their mark on
some comments this reasoning in natural language understanding benchmarks
so much so that it was touted as the
solution but then of course with the transformers in 2017 or so
everything changed for the better so much so
that it just kept kept going right we had all these other models and
for me personally always I was on the camp of
questioning but they're not any of this is real progress as someone that
cared about comments and reasoning which is
sort of historically been this line of thinking about reasoning which
supposedly conflicts with like you know
machine learning and stochastic and like look into to the data etc
so anyways for me it was very natural to want to be biased against the
progress so much so that in 2016 basically the work that I
personally did was on building a the story close test benchmark
which was basically trying to push these systems to showcase whether or not
they have any sort of comments is reasoning by continuing this
like a short story and basically finishing the story
right in a right way that is like reasonable and logical
so anyways then we then I did that work the intention was to
assess whether or not these models of common sense and I wasn't that
convinced that they do I wasn't that convinced that they have any reason in
capabilities and then the transformers came of course GPT-1
did a great job on story close test and then we were like oh is it just
picking up on the intricacies of the data is it just
basically learning the biases that exist in the data
data sad not doing true national language understanding
and then turned out that it maybe was to a degree but we even changed the test
said to another version of story close test that was kind of
debiased and then GPT-1 was basically the only model that could sustain its performance
and anyways still I'm an skeptical let's say and I'm like okay I want to see
deeper language understanding and deeper comments as reasoning
and then GPT-3 came out basically this in 2020
that was doing zero shot performance on story close test meaning using none of the
training data at all and it was getting to 80 something percent performance
which if you had told me in grad school I would not have
taught as possible right in 2020 so these this is tremendous progress
right I think it's really hard for us to try to
sweep it under a rug that these models are not showing any
fundamental language understanding and all they're doing is pattern recognition
because one can even argue what it is that we do as
understanding human beings and how much of it is recognizing patterns and
the piers we have built on the world throughout our lifetime
so anyways I think this is tremendous progress and I'll add one other note
that since to me the progress of the field of natural
language understanding has been so intertwined with my personal line of
research as well so in 2020 I also did this really
interesting work that I personally believe then with my great colleagues at
elemental cognition called glucose that was basically
about building these world models while you're reading a story so story
closest was all about read for sentences predicting but now let's go
maybe on that that's just not just predicting but also come up with these
deep like a world model of the you know a person's kind of set of
states and like events and their causal chains and like draw a coherent picture
of the narrative that you're building let's make this as the new
basically benchmark for evaluating whether or not a system is showing
any sort of deep understanding so anyways this was we you know came up with this
work and basically did all of it which you know we can delve deeper dive deeper
into but it when it came out was like two or three months
after the GPT-3 work and it's fascinating how GPT-3
was doing better than GPT-2 on even in this particular basically task of ours
and how far it has gone in showing that it has some sort of a world model so
I personally think that whoever kind of claims that these models do not have
any world model don't have any kind of a human like cognition don't have
any deep understanding of language it's it's really incorrect to say the least
of course these models are fundamentally flawed no question right we talked
about this in the last session that these models are extremely biased
they are really easy to get tricked which makes them in my opinion brittle
you know how like it was the thing to call symbolic models back in time
brittle I think these models are also quite brittle right it's easy to
for them to get sidetracked and make really stupid mistakes although they
work say well like often so these and you know of course these models are
also really not controllable which as I mentioned is something that we are
working actively at brain ink on so these are all flaws that they have
no question but I think saying that these models do not have a world
model do not have any understanding is is really not correct so those are the
contentions of the stochastic parrots paper wasn't it?
yes and I so it's it's we can talk for hours and hours about this as well so
many things I personally think that look
these these models are really great pattern recognizers
and one can argue that recognizing patterns and then trying to
stitch them together is not real understanding but I would
refute that and I would say that look at the end of the day for me as a researcher
old I could do throughout the past six years or so
was to think about ways of evaluating
and like NOU systems for deeper understanding and these models are proving
consistently that they're making progress
towards doing what constitutes as having understanding so we can of course
argue what is a good benchmark I think benchmarking is one of the problems
we've had for years and years we are making progress but
for me one of the reasons that why I want to work in startups is to
you know build something in real work that actually works for end users
in the messy noisy real-world environments as opposed to our lab settings
so that's definitely a problem we have that we have really narrow inherently
narrow and bias benchmarks but setting data side I think that
you know this is like a kind of theoretical right like
there are people who don't believe in distributional semantics being the
like expression kind of meaning that you can represent
and believe that formal semantics and formal kind of meaning representation is
the way to go which I would argue against I think having
a way of representing meaning distributionally sort of representing a word
by the context in which it just is often occurring at is
is a viable representation of meaning so I think as at the end of the day
if we have the right benchmarks for evaluating
representation of meaning we have the right benchmarks for
evaluating common sense reasoning and if these models pass
past them that that tells you something and this is to take I had been
GPT-3 work came out so many people were asking my opinion as to
how I think about this because you know I was one of the
proponents of less push-d systems for deeper understanding and like
you know they're not they're really lacking it but the truth is we
have made progress I would say that we need to move the
basically the the bar you should you know raise the bar of course as to
pushing these models to go further and further but they've definitely come
very far already so I don't think that these models are
parrots really it depends on the definition of course of
a parrot but if it means that it's really just repeating
without having any kind of an understanding I think that's
that's not the case so going back to kind of the
the state of research broadly and the gaps
that need to be overcome for you to accomplish what you're trying to do at
Vernique it sounds like you know the first one of those is
or the first you know area you know of exploration is
just understanding in general in order for you to do what you're trying to
do you need a system to be able to understand to some degree or
another or according to some you know metrics the
what the user is trying to express in whatever box they're typing in or
whatever interface they're using and it sounds like
you're saying that models that you would lean on for that
understanding are broken in lots of ways and
that's part of what you need to research is how to fix
the ways that they're broken you know bias and
transparency explainability however you want to to put that
but you are you have seen enough evidence of
enough understanding for you to do what you're trying to do for them to be
promising yes absolutely and honestly not even
just talking about the particular technology that you're building at
Vernique but generally for the field I think that
well first and foremost I hope that so many people
work on so many other directions of AI so that we really have diversity of
thought we have diversity of thinking we have other
models that may get to flourish if anything deep learning
trend has taught us that by a couple of people not giving up on what they
believe then they could prove us all wrong right and then
like all the amazing progress that we're seeing is the
fruits of that basically but anyways on our end in particular
for the sake of natural language understanding yes I think these
models are to have tremendous flaws but they've shown
him enough evidence of being basically
foundational to say the least so I know that this is also something
pretty controversial right now like you know when
Stanford start calling these this whole like transfer learning and
pre-training and fine-tuning paradigm foundation models
so many people started raising eyebrows as to okay fund foundation should be
reliable foundations should be that you can poke in like
just just change things which I completely agree
but setting the kind of arguing over the terminology aside
I think that these models have shown enough evidence that they can give us
like lexical and word knowledge which I think are
very foundational for for building natural language understanding and
dialogue systems like you know I come from the school of
thought of people who have spent their lifetime trying to build
semantic parsers which is which has to do with these formal
like semantics of representing each and every word
in a way that like conforms to an ontology and then
how you would go about like representing a verb and
conjunction with something else and like connecting the dots and
everything so that you can represent the meaning and then on top of it
building a dialogue system that recognizes intents and like tracks and
those planning and everything so I think that
what these models are doing and you know they are even
very promising in doing things in a multilingual sense
but anyways these what these models are doing is that they're enabling us to
really let go of some of these pipeline like
things that we had in an LP and just not starting from scratch basically
starting from a model that comes at some sort of a
lexical and word knowledge and turns out comments this knowledge baked in
inish you know I they have flaws as you mentioned and we've talked about
the fact that they're not controllable the fact that they're not transparent
and the fact that you can't let them like teach them
intractively and let them forget about things that they're doing wrongly these
are old problems that need to be fixed which may require its own paradigm shift
could be architecturally could be on the data side
but I think yes to answer your question in one final sentence
these models have shown enough evidence that they could be used as
foundations so that we don't start from scratch
yeah yeah maybe in kind of keeping conscious of time
maybe we can switch gears from talking about kind of the
research broadly to the the research that you're pursuing
and you know I think we can infer from there what you think is
missing in the the research broadly so it sounds like some controllability of
language models is one of the areas what are some of the other areas
of research that you're digging into so yes controllability is one
absolutely we are so our line of thinking is that we believe in
I think I've seen people use this terminology so I'll try to repeat it
a retrieval augmented generation so we want to make sure that we don't
build you know like visci washi language models at the end of the day just
you don't know where the information is coming from we want our models to be
able to retrieve from existing data sources as I mentioned the
soul about data and from decision making we want to
you as a user to know where your information is coming from
or if we are like actively like telling you what
basically rethink we want you to know the source of it
so we want to basically work on ways of retrieving what is out there
with the resource and the provenance intact this is another thing that we're
pursuing and in general generalization right we want to build a
domain general platform how do you make it so that the models
that you have are truly generalizable right this has been an ongoing line of
work for in deep learning for many years but it's
you know of course not solved I think last two years or so has been phenomenal
in terms of how how much more flexible and generalizable these models are
but it's still not you know there's a very very long way to go
the other thing is a data array these models are extremely data hungry
I love how there has been a lot of progress on kind of zero shot and in
context learning kind of paradigm at paradigms but at the end of the day
still the wherever you go to a new domain and you see this first of the
first hand when you work in a real-world setting like in startups
these models are truly data hungry right how can you make it so that these
models are more sample efficient and they don't really need that much
training data for adapting to a new domain and this is for us
of utmost priority because we literally want to make a domain general model
so how do we just go from a domain to another
on the technology side without spending a lot of time just collecting data
and then tuning models learning like new intricacies of that that
existing domain and although I see a lot of value
and someone like myself having spent time thinking about
problems that like a pure deep learning person would not have had and the
value that it kind of brings to building a real-world product so
like we need to work on how to build conversational agents right it's not just
about natural language understanding like one utterance at the time
but it has a lot to do with word modeling really and
kind of building a belief system right the old-school kind of dialog systems
had this framework called BDI that was really cool so belief desire
intention so when you have a full-fished
conversation with someone you basically think about
building models basically and you think about them about what the other
party knows what they don't know what you know how you can help them reach
to a certain goal and you plan right so the existing systems out there
don't really do any planning right these are all
kinds of things that need to to be worked on how do you basically
and build a sustainable word model that includes the sets of belief desires
and intentions and you dynamically basically
monitor right what's happening and another thing is this is also very important
is that we need to have memory right systems at the end of the day
controllability comes from them being able to store what they've learned
from the interactions separate from their actual
like prior knowledge separate from their other kind of conditions so that they
can make an important basically decision and these are also
all kinds of things that are not in these so-called like foundation models
right and need to be worked on and so given
the again kind of the breadth of all of these things that you need to figure
out in order to to build a product how do you
how do you scope that down like you know each of those could be a you know a
four-year PhD effort right or or many right how do you scope that down and
connect that to you know your your mission as a startup founder
to get a product out the door that meets a need
yes so we are not of course I outlined our years of planning right
outlined the kind of problems that we have to work on it doesn't mean that
we're working on it at this moment or we need to work on it
immediately so that just to answer you on the business side how we are
practical but to be honest we do so last like year and half now has been
truly the most rewarding part of my entire life literally in terms of
just seeing firsthand how far you can go then you have no other choice but to
innovate but to just keep working at what you need to and
the truth is although you're very small and which is the nature of a lot of
startups anyways there's so much you can do if you really
you know gets scrappy and like know where to spend your time and
effort so we have this thing and at very need that I don't know if you know
what I'm gonna just mention so there used to be this meme going on
that was the sketching of spider-man that was done in 10 seconds versus
the sketching of it in 10 minutes by an actual artist so even if you are
the master of your skill being art you can always produce something in
10 seconds and you should be always able to to do it and then there is a
10 minute version of course that would be your best work so that's the
person we take at Vernon for anything and we say this to all of our
employees and we even said it to all of our interns
that look you have you don't have 10 minutes you have 10 seconds you have to
have a first version of this go go for it you you've done it on the
design side as well like we have an exceptional designer and then she
started we were like you have two weeks you have to come up with a full
pledge okay UI UX and just go for it and she really did it and this is a test
we do even when we are doing interviews so anyways we we're not working on
everything and anything at once a lot of what I outline or honor and in our kind
of a longer term planning but I think we've gotten really good at
trying to to do a 10 second version of everything just to to know that we
have something in place you know if you were advising
you know someone who was thinking about starting a deep tech type of
start-up what are kind of the general principles that you would
suggest or or put forth for translating you know going from this
kind of gap in the research to product like what are the general ideas
there to me honestly so there there there were so many reasons why I wanted
to embed myself in this start-up scene as opposed to like other maybe
industry research labs or even academia and I think the main driver
is and should be the fact that you want to build an AI
system that actually works so I think for anyone who is working on a
fundamental like a research at a fundamental research setting
they can see what kind of thing they're really passionate about and see how
far it has gone in like you know lab settings and see if it makes sense for it
to want to to be basically in an actual product so I don't know if I have
necessarily principles but I can just talk a little bit more about
my own frustration as to the progress that I couldn't make
outside of this this kind of start-up world that may resonate with someone
out there that we might see it themselves as well. I would say that so I
spend about like a year and a half or so back when I was in grad school
and industry research labs and to me at the end of the day
publishing for the sake of publishing was not really satisfactory so as much
as the we are all seeing the fruits of academic like scientific research
right then sharing which we will you know do at Bernic as well as part of our
I think duty right as researchers to contribute back
like having it as the the main thing that drives you the main thing that you
have to report on the main thing that you care about
is very counterproductive to me right and I feel like okay I'm spending all of
this time of mine on basically this this line of work
where is it going right what kind of value am I bringing to the
broader world so that's like one of the reasons I
felt like personally the kind of research I was doing for the sake of
publishing is not really a good like bar to have for my life
I want to do it for the sake of making a progress but if you had something
worthy of saying you should say it I think it's
our you know duty as I mentioned to to contribute back
so that's an argument maybe for having a product to focus
your research and I think maybe put differently from principles
trying to get at the kernel of like you have so much that you could possibly
research like just how do you prioritize how do you
lead or focus a research team that could go in lots of
different directions like you can't be Bell Labs and just
do a little bit of everything and kind of have it
well I guess that's the the example that you were just talking about you know
with a product in mind like how do you prioritize
what you're going to spend your time on so I think actually so
we should talk in a few months when we have the actual product and then I would
love to be more specific about how we did that because I think that
answers a lot of these questions so the truth is honestly having a
product helps with narrowing down the focus so much we are
we are a truly laser focus right now on a particular domain
which drives a lot of our decisions and gives us a lot of insights as to
what to prioritize and what not to so just talking about the issues that I
was outlining that we have with the existing you know models which kind of
applies to the internal and house models that we have as well
like lack of control lack of transparency like not being able to for them to
work fast enough right because your user has a certain level of
expectation as to how quickly they should respond this completely
change when you go to a new domain so that just dictates our
basically priorities it's like we it's so funny about like
year and a half ago or so when Omid and I we were sitting down to
just outline these features that we want our AI platform to have
we literally wrote down the list like it should be instantaneous in terms of
response time we should have controllability it should be I don't know first
start being like single turn and then multi turn and then it should be
domain general from the get go blah blah and we literally on the notion
page which is the software we use for knowledge
management we have a priority assigned to them which is like high media
blah and then it changes per domain so if I could share that with you that
notion page you would see that we are literally doing it like the
features that even we care about in terms of the
the technology itself is very much dependent on the domain and then we keep
going back and forth on them depending of what we're focusing on
for a particular basically quarter got it got it got it
so so summary there is you know if you're very focused on kind of product and
features then that will tell you what you need to figure out to
deliver those and in order to tell me more detail you'd have to talk about the
specific features and research and that's going to come soon
yes yeah because I think actually you would really like it
for us we had this dilemma of what our first kind of
sector would be first domain would be and probably will be even couple when we
come up with it or regardless the the thing that is the closest to our
hearts is the one that has a lot to do with some of the things that we were
just discussing and it really applies to everyone's day-to-day
decision-making and it's really exciting so that's another thing there's like
this kind of hidden decision like a feature right when you're
prioritizing this gigantic space in this gigantic space which has to do
with your personal passion it really is right when you're especially
so people call this product market fit but I think in our more or less
called technology market fit that like founders like us you have a
particular technology that could be fitted into any market but in any product
and now you have this dilemma of even thinking about the technology being
fitted into market not just to the product being fitted into markets it's
really even a larger search of space for a founder to want to to navigate
but yeah I think that personal passion and personal care is something that
will play a role and has played a role then you know hopefully a couple
months from now and be chattel happily spill all the beans
awesome awesome well Nestreen it was wonderful catching up with you as always
thanks so much for taking time and looking forward to next time
absolutely pleasure with mine yeah looking forward to next time
awesome thank you
