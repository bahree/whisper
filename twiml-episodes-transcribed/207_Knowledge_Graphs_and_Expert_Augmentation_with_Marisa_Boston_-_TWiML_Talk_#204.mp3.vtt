WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:31.640
I'm your host Sam Charrington.

00:31.640 --> 00:36.720
Today we're joined by Marissa Boston, Director of Cognitive Technology in KPMG's Cognitive

00:36.720 --> 00:38.320
Automation Lab.

00:38.320 --> 00:42.480
Marissa and I caught up to discuss some of the ways that KPMG's using AI to build tools

00:42.480 --> 00:47.240
that help augment the knowledge of their various teams of professionals.

00:47.240 --> 00:51.360
We start out with a discussion of knowledge graphs and how they can be used to map out

00:51.360 --> 00:53.520
and relate various concepts.

00:53.520 --> 00:58.880
We then explore how they use these in conjunction with NLP to create insight engines, tools

00:58.880 --> 01:04.160
that curate and contextualize news and other text-based data sources to produce a series

01:04.160 --> 01:08.680
of content recommendations that help their users work more effectively.

01:08.680 --> 01:16.080
Finally, Marissa shares some great general principles for using AI to augment human experts.

01:16.080 --> 01:19.920
Before we dive in, over the next few weeks, I'll be bringing you some great interviews

01:19.920 --> 01:27.160
from the road, including AWS re-invent, NURRIPS and CUBECON, and I would love to connect

01:27.160 --> 01:29.600
with any listeners and attendants.

01:29.600 --> 01:35.600
Feel free to shoot me a message via at Sam Charrington on Twitter, email, the Twimble website,

01:35.600 --> 01:40.240
LinkedIn, or if you just see me walking by, don't be afraid to say hi.

01:40.240 --> 01:45.000
If you're heading to NURRIPS, look for the listener meetup and the AI platforms meetup

01:45.000 --> 01:47.600
that I've posted in the Hoover app.

01:47.600 --> 01:49.280
See you around.

01:49.280 --> 01:52.000
And now on to the show.

01:52.000 --> 01:55.360
All right, everyone.

01:55.360 --> 01:57.520
I am on the line with Marissa Boston.

01:57.520 --> 02:04.080
Marissa is director of Cognitive Technology for KPMG's Cognitive Automation Lab.

02:04.080 --> 02:07.200
Marissa, welcome to this Weekend Machine Learning and AI.

02:07.200 --> 02:08.440
Thank you.

02:08.440 --> 02:10.400
It is great to chat with you.

02:10.400 --> 02:13.520
Why don't we get started with a little bit of your background?

02:13.520 --> 02:19.280
I understand you spent some time studying at Cornell in upstate New York.

02:19.280 --> 02:20.280
That's right.

02:20.280 --> 02:22.600
I did my PhD at Cornell.

02:22.600 --> 02:29.160
My area of focus was computational linguistics, which is a mouthful, but it's essentially

02:29.160 --> 02:36.600
building out computer, basically computational models of how humans understand sentences

02:36.600 --> 02:39.000
was the work that I was doing.

02:39.000 --> 02:46.400
So it was a really interesting way to take technology and try to see how we can investigate

02:46.400 --> 02:53.320
scientific matters, how the human is understanding language and things like that.

02:53.320 --> 03:00.480
And in your work there, were you focused primarily on traditional linguistic models or were

03:00.480 --> 03:02.480
you working with statistical models?

03:02.480 --> 03:05.400
Yeah, I actually built out statistical parsers.

03:05.400 --> 03:09.120
So it was kind of like this, we did both essentially.

03:09.120 --> 03:16.240
So I worked on statistical sentence parsers, but what I would do is I would use theories

03:16.240 --> 03:24.480
from cycle linguistics and from linguistics to help determine where difficulty might be

03:24.480 --> 03:25.840
in a sentence.

03:25.840 --> 03:31.840
And then I would actually test if that difficulty is coming through in the same way for the human

03:31.840 --> 03:37.680
as it would be for the computer based on how I encoded those both the linguistic structures

03:37.680 --> 03:41.960
and the psychological theories as well.

03:41.960 --> 03:43.840
Oh, interesting, interesting.

03:43.840 --> 03:45.760
And after your PhD?

03:45.760 --> 03:49.280
After my PhD, I decided to go into industry research.

03:49.280 --> 03:53.960
I went to the nuanced communications where I worked in their AI and NLP labs, and that

03:53.960 --> 03:54.960
was really fun.

03:54.960 --> 04:01.240
I got to do all sorts of things I worked on, the original Watson system, helping to tune

04:01.240 --> 04:03.920
it to healthcare.

04:03.920 --> 04:09.840
And I worked on other types of question answering and textual inference systems and also virtual

04:09.840 --> 04:13.120
assistance for customer service centers.

04:13.120 --> 04:16.560
And then you moved over to KPMG, right?

04:16.560 --> 04:17.560
I did.

04:17.560 --> 04:25.800
I ended up moving out of tech and I wanted to go into more of a consulting firm and a professional

04:25.800 --> 04:30.920
services firm because I wanted to get more of a sense of how we can build out the

04:30.920 --> 04:37.800
appropriate environment for these technologies and what are the business models that can

04:37.800 --> 04:42.480
support them in order to ensure that they are actually being used appropriately.

04:42.480 --> 04:47.360
So I was kind of getting sick of, you know, I realized fairly quickly that no matter

04:47.360 --> 04:51.640
how good my designs are, my architecture is my implementations.

04:51.640 --> 04:55.560
If the business model doesn't support it, then you're not really going to be able to

04:55.560 --> 04:57.480
get much use out of it.

04:57.480 --> 05:01.720
So I really wanted to get a better sense of how we can build these tools more appropriately.

05:01.720 --> 05:08.280
When you say the business model needs to support it and creating the appropriate environment,

05:08.280 --> 05:10.440
what all is involved in that?

05:10.440 --> 05:16.280
I think it really comes down to, first of all, having the appropriate boundaries.

05:16.280 --> 05:22.600
So one of the things that interested me about coming to KPMG is that they're an audit

05:22.600 --> 05:24.240
firm, audit and tax accounting.

05:24.240 --> 05:28.720
And so they have a lot of regulatory pressures on them.

05:28.720 --> 05:32.760
And I find this interesting because a lot of times in tech, we think that we have to invent

05:32.760 --> 05:33.760
everything.

05:33.760 --> 05:38.560
And I think that usually this leads to some kind of a wild west mentality in terms of what

05:38.560 --> 05:41.920
technologies are out there and whether they're appropriate or not.

05:41.920 --> 05:46.800
I was really interested in seeing what kind of human boundaries might be there in terms

05:46.800 --> 05:53.560
of regulations and in terms of the types of technologies we can actually provide.

05:53.560 --> 05:54.560
So that was one thing.

05:54.560 --> 05:59.880
The other thing is that in a lot of ways, it teaches you to be an ambassador, not just

05:59.880 --> 06:04.200
for what the technologies can do, but also what the technologies can't do.

06:04.200 --> 06:10.080
And you start to be able to ask the question of whether these technologies should be employed

06:10.080 --> 06:11.320
in this way.

06:11.320 --> 06:18.280
Or is this really going to, I find in tech often, everybody's going after accuracy or specific

06:18.280 --> 06:20.680
requirements along those lines.

06:20.680 --> 06:24.880
But instead, when you're at a professional services firm, you start to think about things

06:24.880 --> 06:32.520
in terms of more human metrics like, you know, are we actually leading to higher quality?

06:32.520 --> 06:36.960
Things like that that I think is really key in helping to understand things.

06:36.960 --> 06:43.920
And finally, I do think that it's about helping the business transform digitally so that

06:43.920 --> 06:45.560
they can help support these systems.

06:45.560 --> 06:49.320
So just like anything else, I mean, they need the appropriate data.

06:49.320 --> 06:54.600
They need the appropriate improvement methodologies so that they can go forward.

06:54.600 --> 06:58.560
And actually, you know, you have all of this beautiful technology and all these beautiful

06:58.560 --> 06:59.560
methods.

06:59.560 --> 07:03.000
Can you actually implement them, but then also improve them so that they can realize their

07:03.000 --> 07:04.000
real potential?

07:04.000 --> 07:05.000
Yeah.

07:05.000 --> 07:06.000
I like the way you put that.

07:06.000 --> 07:13.680
One of the things that I am finding, you know, interesting and inspiring or I've been

07:13.680 --> 07:20.360
inspiring is maybe not the word but heartening is that we're starting to hear more of a

07:20.360 --> 07:27.120
shift from the kind of asking the Ken Wee question to the should we question, and maybe

07:27.120 --> 07:30.920
it's not even a shift, but you know, we're at least starting to hear the should we question

07:30.920 --> 07:40.680
in the context of AI and thinking about ethics and appropriateness and, you know, the implications

07:40.680 --> 07:46.280
of some of this, some of these technologies are those questions that you're focused on

07:46.280 --> 07:47.280
answering as well?

07:47.280 --> 07:48.280
Yeah.

07:48.280 --> 07:54.280
And in fact, KPMG even before I started was already going down this line.

07:54.280 --> 08:02.360
So they're backing and data analytics has always been around the trust aspect, right?

08:02.360 --> 08:07.160
And really about the fact that their clients employ them not for, you know, efficiency or

08:07.160 --> 08:10.280
something along those lines, but really for trust.

08:10.280 --> 08:19.360
And also KPMG de-auditors, especially, you know, we are responsible for trust in the capital

08:19.360 --> 08:26.000
markets because we audit financial statements, you know, we have that responsibility.

08:26.000 --> 08:32.160
And so this has been a part of the conversation at KPMG for a long time and it really intrigued

08:32.160 --> 08:39.280
me because when we, when they were embarking on building out these types of technologies,

08:39.280 --> 08:41.440
they already had that mindset.

08:41.440 --> 08:46.160
And it was now really a question of how do we bring in the appropriate people to help

08:46.160 --> 08:49.400
us build these out in this way that we want to do.

08:49.400 --> 08:54.480
And I find that really, you know, at first it might have felt a little bit like a step

08:54.480 --> 08:58.120
backward because it means that, you know, you don't have the gobs of data.

08:58.120 --> 09:01.880
You can't use the way to state-of-the-art everything, right?

09:01.880 --> 09:06.960
It means that a lot of times you have to specifically pick your partners for, according

09:06.960 --> 09:10.400
to a different criteria than you normally would.

09:10.400 --> 09:17.160
But in the end, I think that what we're seeing, especially now, and this is now two years

09:17.160 --> 09:23.160
after I started at the firm and probably, you know, several years before that KPMG had

09:23.160 --> 09:28.520
already started on this journey, now you're actually seeing that that others are catching

09:28.520 --> 09:30.840
up to that way of thinking as well.

09:30.840 --> 09:36.280
So one of the main topics that we wanted to jump into in this conversation is some work

09:36.280 --> 09:42.080
that you've been doing recently around the idea of knowledge graphs.

09:42.080 --> 09:46.480
Can you start us off by explaining what a knowledge graph is?

09:46.480 --> 09:47.480
Sure.

09:47.480 --> 09:52.960
So a knowledge graph, I think a very simple way of thinking of a knowledge graph is essentially

09:52.960 --> 09:55.760
just a network of concepts.

09:55.760 --> 10:04.800
And knowledge graphs are a simplification of more formal ways of defining relationships

10:04.800 --> 10:08.400
between concepts and entities.

10:08.400 --> 10:15.240
But that simplification allows us to use a variety of techniques that might not always

10:15.240 --> 10:18.680
be possible if we go for the stronger versions.

10:18.680 --> 10:26.360
And so for at KPMG, for example, we have a lot of processes and a lot of expertise and

10:26.360 --> 10:31.040
knowledge that we want to have encoded in a way that we can make use of.

10:31.040 --> 10:37.440
And a lot of times, it's already been put into something like a taxonomy that someone

10:37.440 --> 10:43.240
somewhere in the organization has to keep up to date in some way.

10:43.240 --> 10:49.320
And what we try to do is we've also hired an oncologist to come in and not only help

10:49.320 --> 10:55.120
formalize that knowledge in a way that's actually a little bit better.

10:55.120 --> 11:03.280
But we also use take that kind of stronger version and we simplify it into knowledge graphs

11:03.280 --> 11:09.680
to allow us to, for example, take our knowledge about one area and apply it to our knowledge

11:09.680 --> 11:16.400
about another area or take internal knowledge and apply it to external news, for example.

11:16.400 --> 11:22.600
So we use knowledge graphs to be able to take our internal taxonomies, ontologies about

11:22.600 --> 11:28.120
client issues and be able to map them to news that is out there.

11:28.120 --> 11:32.680
And the knowledge graph is actually a much easier way to do this than a more formal method.

11:32.680 --> 11:39.800
And it also allows us to work with a variety of news vendors that are already using these

11:39.800 --> 11:42.160
types of technologies.

11:42.160 --> 11:50.200
So when I think of things like taxonomies and ontologies, one of the first things that

11:50.200 --> 11:53.400
I think of is this idea of knowledge management.

11:53.400 --> 11:58.280
It's an area that I did some work in a long time ago.

11:58.280 --> 12:01.480
Knowledge management and document management, there's, you know, those are, that's a kind

12:01.480 --> 12:04.040
of mature space unto itself.

12:04.040 --> 12:07.360
Where does cognitive come into all this?

12:07.360 --> 12:11.280
So it is a mature place, you know, a mature space.

12:11.280 --> 12:16.000
Those technologies are mature, but that doesn't necessarily mean that everybody has implemented

12:16.000 --> 12:22.520
them appropriately and that that implementation extends across the whole enterprise.

12:22.520 --> 12:28.320
And so one of the things that we found and I admit, this is not my specific area of expertise.

12:28.320 --> 12:34.360
This is, we have others within my lab, even, who have years of expertise in this area,

12:34.360 --> 12:37.160
but I had the opportunity to work with them.

12:37.160 --> 12:45.800
But the main challenge with knowledge management is that it's not necessarily done in a way

12:45.800 --> 12:50.800
or if it has been done, it hasn't necessarily been done in a way that allows us to take

12:50.800 --> 12:58.200
advantage of the data or the information that's available for artificial intelligence systems.

12:58.200 --> 13:01.640
A lot of times, that's one of the problems.

13:01.640 --> 13:07.720
Now at KPMG, and I think that you see this set of variety of other firms and organizations

13:07.720 --> 13:12.800
as well, that digital transformation hasn't necessarily happened evenly.

13:12.800 --> 13:18.240
So while there might be certain places where we have, say, data lakes, in the end, we don't

13:18.240 --> 13:19.960
have them everywhere.

13:19.960 --> 13:25.800
On top of that, we have another issue, which is that we have a lot of restrictions when

13:25.800 --> 13:27.880
it comes to client information.

13:27.880 --> 13:32.360
We are very restrictive and risk averse when it comes to client information.

13:32.360 --> 13:36.360
And so a lot of the processes end up being manual because of that.

13:36.360 --> 13:39.400
So there has to be a culture shift there as well.

13:39.400 --> 13:44.880
So you're absolutely right, some of these methods are fairly mature.

13:44.880 --> 13:48.800
And we know what the methods are, we just have to implement them.

13:48.800 --> 13:54.240
And I'd say, for example, in the way that we're using knowledge graphs, this is not something

13:54.240 --> 13:55.240
that we're making up.

13:55.240 --> 13:59.000
In fact, if you look at a lot of CRM solutions, this is how they operate.

13:59.000 --> 14:05.440
They have some kind of an internal taxonomy or internal idea of what are important concepts.

14:05.440 --> 14:11.520
You can go off and look at external news or else you can look at information between services

14:11.520 --> 14:15.040
and engagements and you try to map them out appropriately.

14:15.040 --> 14:16.760
We're doing exactly the same thing.

14:16.760 --> 14:21.160
But I think the main distinction is that we're putting our own spin on it.

14:21.160 --> 14:25.120
We're taking information that has long been internal to KPMG.

14:25.120 --> 14:29.880
And now we have the technology to be able to use that information and map it out to external

14:29.880 --> 14:33.760
news in a way that actually benefits our workers.

14:33.760 --> 14:39.440
So taking advantage of these techniques that have matured under the banner of knowledge

14:39.440 --> 14:48.160
management, are you also then incorporating in artificial intelligence and cognitive

14:48.160 --> 14:49.160
technologies?

14:49.160 --> 14:50.160
Well, presumably you are.

14:50.160 --> 14:51.160
Is that correct?

14:51.160 --> 14:52.160
Yes.

14:52.160 --> 14:53.160
Yeah, we do.

14:53.160 --> 14:56.840
So this is one particular project where we're using knowledge graphs.

14:56.840 --> 15:00.520
Now, we don't just serve up the information, right?

15:00.520 --> 15:06.720
So it's not just that we have external news and we say, hey, here's a bunch of news articles.

15:06.720 --> 15:11.760
We actually do this in a way that allows us to contextualize it according to specific

15:11.760 --> 15:15.200
recommendations that will help our account leads.

15:15.200 --> 15:19.400
So we have information about the services KPMG offers.

15:19.400 --> 15:22.480
We have information about previous engagements.

15:22.480 --> 15:24.680
We have information about the clients.

15:24.680 --> 15:29.360
We have now external news and we're able to use the knowledge graph to try to map all

15:29.360 --> 15:34.960
of these appropriately and then also try to see what are the top recommendations we have

15:34.960 --> 15:36.120
for services.

15:36.120 --> 15:41.080
And then we use our news articles or previous engagements as support for that, right?

15:41.080 --> 15:44.920
So it's kind of like evidence for why we're giving this recommendation.

15:44.920 --> 15:51.240
And all of this, so it not just the ability to use knowledge graphs in this way, to be

15:51.240 --> 15:57.760
able to map across all of these different areas, but also the recommendation engines use

15:57.760 --> 16:03.960
a variety of techniques that, you know, whether they're, it's kind of difficult to say where

16:03.960 --> 16:09.440
they fit in, right, to AI, but they're within the context of general machine learning and

16:09.440 --> 16:10.440
general practice.

16:10.440 --> 16:14.400
It's more a question of how do we apply it to our specific business?

16:14.400 --> 16:19.720
Maybe let's take a step back and kind of put a fine point on this project.

16:19.720 --> 16:26.000
You are essentially building up a, you know, would you call it a dashboard for these account

16:26.000 --> 16:33.760
managers that helps them kind of stay on top of news that affects their clients?

16:33.760 --> 16:35.000
Yeah, exactly.

16:35.000 --> 16:40.960
So this is kind of an additional insight engine that we provide to our account managers.

16:40.960 --> 16:47.120
And one of the things to take into account is that especially when these systems go live,

16:47.120 --> 16:51.840
you know, we would put this up and, you know, our top account managers say for our, you

16:51.840 --> 16:56.520
know, most, you know, our top 100 or 200 accounts, right?

16:56.520 --> 17:00.760
These are people who really know their clients, these are people who really know what's going

17:00.760 --> 17:01.760
on.

17:01.760 --> 17:04.560
They are reading the news and they have their own intuitions.

17:04.560 --> 17:07.800
These are our top experts in terms of what's important.

17:07.800 --> 17:13.920
Now this system is likely not going to provide that much insight for these top accounts where

17:13.920 --> 17:19.000
we already have a lot of people looking into this and a lot of this information isn't

17:19.000 --> 17:20.000
missed.

17:20.000 --> 17:24.120
So where you really start to see the advantage of this is when you extend past that and

17:24.120 --> 17:28.080
what we're really trying to think of is how do we take the quality that we're able to

17:28.080 --> 17:33.520
provide for our top, from our top experts to our top clients and how do we expand that

17:33.520 --> 17:34.520
beyond?

17:34.520 --> 17:39.320
And when you think further back, so when you think about the fact that, you know, other

17:39.320 --> 17:43.840
account managers might have, you know, like 20 accounts that they have to, you know,

17:43.840 --> 17:49.040
20 clients that they that they have to somehow manage and juggle and they might not have

17:49.040 --> 17:53.560
to be able to, for example, look into the news every single day for those.

17:53.560 --> 17:58.200
At that point, you start to see why this kind of a recommendation engine might help us find

17:58.200 --> 18:04.360
things that we might have normally missed and help us expand our quality beyond the what

18:04.360 --> 18:07.800
we're currently able to provide to only a few clients.

18:07.800 --> 18:08.800
Right.

18:08.800 --> 18:09.800
Right.

18:09.800 --> 18:15.120
Well, I can relate very personally to the challenge that you're trying to address here, just

18:15.120 --> 18:22.160
in my own role as an industry analyst and, you know, someone that needs to stay on top

18:22.160 --> 18:28.680
of, you know, not just kind of what the large vendors are doing in AI, but what the smaller

18:28.680 --> 18:35.440
vendors are doing, what the, you know, the major technology platforms and frameworks and

18:35.440 --> 18:38.880
there's just a ton of information out there.

18:38.880 --> 18:43.400
And, you know, like you said, I've got some kind of go to sources and some go to feeds

18:43.400 --> 18:52.680
that and tools, even that I can rely on to help me stay informed, but I am often, you

18:52.680 --> 18:58.120
know, almost daily, you know, wishing that I had something that was smarter, that was

18:58.120 --> 19:04.840
more intelligent, more connected, more tied into the things that I need to stay on top

19:04.840 --> 19:10.000
of that could be almost like a, you know, a personal agent, a personal assistant, a

19:10.000 --> 19:15.520
dashboard that surfaced all of the things that I need to, needed to know, but also, you

19:15.520 --> 19:21.360
know, pushed down the things that aren't as important for me and was able to learn

19:21.360 --> 19:23.760
the difference between the two over time.

19:23.760 --> 19:24.760
Exactly.

19:24.760 --> 19:27.760
And I think there's two important things about you're saying there.

19:27.760 --> 19:33.520
One is, I think just the process of understanding how to encode the expertise that you have,

19:33.520 --> 19:34.520
right?

19:34.520 --> 19:38.720
So the process that we have, our experts go through, like especially with our chief

19:38.720 --> 19:43.800
ontologist in terms of being able to better hone, what are the important concepts?

19:43.800 --> 19:45.760
How are they doing their jobs right now?

19:45.760 --> 19:51.600
How do we take that important information and how do we build out exactly what those intuitions

19:51.600 --> 19:52.600
might be?

19:52.600 --> 20:00.560
I think that's one really good thing that comes out of transforming, say your, you know,

20:00.560 --> 20:08.680
what you yourself do as an analyst into something that could be more like a digital

20:08.680 --> 20:09.680
process, right?

20:09.680 --> 20:15.800
Then the other thing as you're saying is absolutely, once you have that, you can really start

20:15.800 --> 20:22.520
to play with how do we start thinking about how we can expand the quality, you know, you

20:22.520 --> 20:27.080
want to be able to focus your attention and your top quality to the best things.

20:27.080 --> 20:32.920
And this really gets into the expert augmentation space, which is a key tenet of how we approach

20:32.920 --> 20:38.320
building these systems at KPMG for, say, our auditors, right?

20:38.320 --> 20:45.840
You want to be able to take your expertise, try to be able to go out and discover as much

20:45.840 --> 20:51.320
information as you can, but then also allow the human to come back and make conclusions

20:51.320 --> 20:52.320
on that.

20:52.320 --> 20:56.480
And hopefully through the process of, there would be an iterative process where you would

20:56.480 --> 21:00.600
be training, say, this assistant, you know, we try to make it out so that it would be

21:00.600 --> 21:03.120
more like an intern at first, right?

21:03.120 --> 21:05.640
So what could you expect of your intern?

21:05.640 --> 21:10.520
We try to get our systems to a level where on day one, they'd be kind of like an intern,

21:10.520 --> 21:11.520
right?

21:11.520 --> 21:15.200
But hopefully through the process, we would improve it to the point where they could become

21:15.200 --> 21:17.160
relied on more and more.

21:17.160 --> 21:19.000
And that's really what you want to get to.

21:19.000 --> 21:20.880
I love that idea.

21:20.880 --> 21:28.400
So what are some of the, some of the technology pieces upon which you built this.

21:28.400 --> 21:33.360
You mentioned Watson earlier and working with some of the first Watson technologies for

21:33.360 --> 21:37.160
healthcare are using Watson in here as well.

21:37.160 --> 21:43.400
So we had originally done, so I had previously done work with Watson.

21:43.400 --> 21:48.760
And now when it was a lot of the work that we're doing at KPMG, some of it goes with IBM

21:48.760 --> 21:51.280
products and various things in Watson.

21:51.280 --> 21:57.920
Now this particular one, we originally, the original prototype was with Watson company

21:57.920 --> 22:04.360
Analyzer, which was, they had bought Alchemy News, which was a news service and they were

22:04.360 --> 22:08.640
able, they were essentially doing this, they had a knowledge graph, Alchemy News had a

22:08.640 --> 22:13.280
knowledge graph of news articles for the news, and they were able to deliver content

22:13.280 --> 22:15.240
in a specific way.

22:15.240 --> 22:21.640
And what we wanted to do is we, you know, their knowledge graph wasn't quite as extensive

22:21.640 --> 22:25.760
for financial services or for the information we had, right?

22:25.760 --> 22:31.280
So it was definitely good because it allowed you to have a general view of news, which is

22:31.280 --> 22:33.000
something KPMG can't have.

22:33.000 --> 22:37.960
We don't have that kind of taxonomy, but we definitely have much more specificity when

22:37.960 --> 22:41.840
it comes to client issues with financial services.

22:41.840 --> 22:47.000
And it turned out that being able to map those two across was not working out very well.

22:47.000 --> 22:55.080
So what we ended up doing was we ended up bringing it in-house and we built, we've played

22:55.080 --> 22:59.160
with Watson Discovery services and using that here.

22:59.160 --> 23:05.960
We use Watson Knowledge Studio for Entity Extraction and the actual knowledge graph and the

23:05.960 --> 23:10.880
reasoning components actually aren't Watson components right now, but that was mostly

23:10.880 --> 23:18.160
because of just the difficulty and, you know, making sure that IP, RIP state, R's and

23:18.160 --> 23:21.520
their IP state there's, so it was more of that kind of a concern.

23:21.520 --> 23:26.040
Oh, it makes sense. And so what is the Watson Discovery service and what's the role

23:26.040 --> 23:28.120
that that piece plays for you?

23:28.120 --> 23:35.640
So Watson Discovery service is where IBM has put a lot of their search works recently.

23:35.640 --> 23:41.960
So they used to have something called Retrieven Rank and they've built out Watson Discovery

23:41.960 --> 23:47.000
service to be kind of a much stronger search engine.

23:47.000 --> 23:51.720
And the advantage is that you can use Watson Knowledge Studio.

23:51.720 --> 23:56.160
So Entity Recognition, you kind of can train your own Entity Recognizers.

23:56.160 --> 24:00.680
You can do a search over, you know, it allows you to index.

24:00.680 --> 24:07.480
It allows you to create a ranking engine over what's searched and it allows you to build

24:07.480 --> 24:08.480
out queries.

24:08.480 --> 24:13.680
It's kind of like a big search interface, but they also call it the Discovery service

24:13.680 --> 24:15.520
because they've also expanded that.

24:15.520 --> 24:19.560
So that now you can kind of, there's also an interactive quality.

24:19.560 --> 24:23.960
So it's not just the delivery of a search engine, but there's also an interactive quality

24:23.960 --> 24:28.320
in terms of you're being able to look through your data and find insights from it.

24:28.320 --> 24:31.280
So they've combined a few services through it.

24:31.280 --> 24:37.240
And so how does the Knowledge Studio interact with the Discovery service?

24:37.240 --> 24:42.120
What you can do with Knowledge Studio is, Knowledge Studio allows you to build out Entity

24:42.120 --> 24:45.240
Recognition, essentially, or Entity Extraction models.

24:45.240 --> 24:50.640
One of the first use cases or examples I think of when I hear that is like a chat bot

24:50.640 --> 24:57.920
where you're trying to identify like intense or, you know, entities that you're, that

24:57.920 --> 25:02.120
someone is asking about via a chat conversation.

25:02.120 --> 25:07.160
Is it also, in this case, is it used in that context or like in a search context where

25:07.160 --> 25:09.520
you're refining search results based on entities?

25:09.520 --> 25:13.960
So what you can do is you can actually use those entities to index what you're searching

25:13.960 --> 25:18.720
over so that you could, just like in a, in a chat bot, you would sit there and you'd

25:18.720 --> 25:24.120
say, you know, you want to mark out the, the fact that, you know, somebody wants to fly

25:24.120 --> 25:28.360
to Calgary, say Calgary would be where they're flying to, right?

25:28.360 --> 25:32.560
So what's a Knowledge Studio would be able to tell you that that would be like the location.

25:32.560 --> 25:36.760
To similarly, you could mark up, say, all of the search pages that you're searching

25:36.760 --> 25:37.760
over, right?

25:37.760 --> 25:41.320
So all of the content you're trying to search through, and what's a Knowledge Studio

25:41.320 --> 25:45.400
could go through and say, oh, well, you know, every time you seek Calgary, that's actually

25:45.400 --> 25:48.600
a location that someone could fly to or something like that.

25:48.600 --> 25:54.760
So it's, it's basically the same thing and it allows you to augment your search appropriately

25:54.760 --> 25:58.600
with, with concepts that, you know, you can train on yourself.

25:58.600 --> 26:06.080
So for example, for us, you know, a specific individual could be a corporation and you

26:06.080 --> 26:11.400
might be able to find that from just any named entity recognizer, but for our purposes,

26:11.400 --> 26:15.000
we really could think of that person as a borrower, as a borrower.

26:15.000 --> 26:20.320
So that's like a borrower in a loan agreement, say, and we would want to capture that information.

26:20.320 --> 26:22.800
That's what Watson Knowledge Studio would allow you to do.

26:22.800 --> 26:24.680
It would take that information, say, you know what?

26:24.680 --> 26:30.680
This is the borrower and this is the guarantor name in this, in this loan agreement.

26:30.680 --> 26:34.720
Watson Knowledge Studio allows you to, to find that information and to train models that

26:34.720 --> 26:39.960
can, that can help you find the information for the concepts that you're interested in.

26:39.960 --> 26:42.920
And then from that, you can build out our Knowledge Graph, of course.

26:42.920 --> 26:43.920
Okay, interesting.

26:43.920 --> 26:49.520
And so presumably with this example you gave of the, the borrower and the creditor, it's

26:49.520 --> 26:52.040
not like a place, you know, versus a company name.

26:52.040 --> 26:57.520
They're both company names and so presumably it's able to figure out the specific entity

26:57.520 --> 26:59.240
types based on context.

26:59.240 --> 27:00.320
Yeah, exactly.

27:00.320 --> 27:07.640
So essentially in the back end, it has, it uses features of, you know, different types

27:07.640 --> 27:09.760
of, of sentence based features.

27:09.760 --> 27:15.000
So I assume they have ngrams of some kind and other things that allows them to differentiate

27:15.000 --> 27:16.000
that.

27:16.000 --> 27:20.920
And then in terms of how you train it, right, it's all about you, you annotate yourself

27:20.920 --> 27:24.280
and you, you train it based on lots of information.

27:24.280 --> 27:30.400
And so if you provide it with the appropriate types of information that can differentiate

27:30.400 --> 27:36.480
those two, you should be able to arrive at a model for borrower and a model for guarantee.

27:36.480 --> 27:44.880
Do you have a sense for the number of training examples that are required kind of per entity

27:44.880 --> 27:49.400
in order to get a reasonable level of accuracy?

27:49.400 --> 27:52.680
So yeah, generally what they recommend IBM.

27:52.680 --> 27:58.560
So to be clear, I've never worked with IBM for IBM, but I have worked with their products.

27:58.560 --> 28:03.760
Generally, it's going to be about 50 positive examples that you want to provide.

28:03.760 --> 28:08.520
And for each entity and a positive example, of course, means that it's actually there.

28:08.520 --> 28:14.080
So you can't just like provide 50 documents and sometimes the guarantee name is there and

28:14.080 --> 28:15.360
sometimes it isn't, right?

28:15.360 --> 28:19.240
So you want to have at least 50 examples.

28:19.240 --> 28:27.600
In practice, we actually, it really does depend on a lot of variables in terms of where

28:27.600 --> 28:33.640
that entity shows up and what you're trying to differentiate it from in order to determine

28:33.640 --> 28:40.200
what the appropriate number are, but I would be hesitant to even rely on results if

28:40.200 --> 28:43.280
you don't have at least 50 positive examples.

28:43.280 --> 28:46.080
We usually go for about 200 to start.

28:46.080 --> 28:47.880
I imagine it's per entity.

28:47.880 --> 28:49.840
Yeah, per entity, exactly.

28:49.840 --> 28:50.840
So you're right.

28:50.840 --> 28:55.720
You could have a document where you're trying to get 10 things out.

28:55.720 --> 28:57.160
You can't just go for 50 of those.

28:57.160 --> 28:58.160
You might have to end up.

28:58.160 --> 29:02.400
That's why I say we usually end up with about 200 documents, and hopefully through there

29:02.400 --> 29:07.440
we can find at least 50 positive examples for each of the things we're trying to pull.

29:07.440 --> 29:10.240
You have the entity recognition system.

29:10.240 --> 29:15.600
You've got the discovery service, which is kind of a search engine that can take advantage

29:15.600 --> 29:17.760
of these entities.

29:17.760 --> 29:21.720
We've experimented with what's in discovery service, but I don't think actually right

29:21.720 --> 29:27.560
now we have that in play, but that's one possible way that you could actually build out this

29:27.560 --> 29:28.880
kind of thing.

29:28.880 --> 29:35.400
Essentially, what we've built out is it's a typical recommendation engine, but we also

29:35.400 --> 29:42.480
have a graph-based database for the, that represents the knowledge graph.

29:42.480 --> 29:51.360
We essentially pull in, we pull in specific articles, we rank them, and we rank them according

29:51.360 --> 29:53.840
to what the recommendation is for the service.

29:53.840 --> 30:00.440
So for example, it's not, we want to recommend a specific service that KPMG offers for a client.

30:00.440 --> 30:06.320
And then once we've made that recommendation, we show as evidence, news articles, or say

30:06.320 --> 30:12.360
history of engagements, other engagements that are similar, a variety of other factors

30:12.360 --> 30:15.840
that may come into play to determine that recommendation.

30:15.840 --> 30:21.160
So as you can see here, the knowledge graph is not in and of itself what we're delivering

30:21.160 --> 30:29.880
is more of a way for us to rank appropriately the evidence for us to recommend a service

30:29.880 --> 30:31.560
for a client.

30:31.560 --> 30:36.040
Where do the, where do the news feeds come from?

30:36.040 --> 30:43.200
So we have, we use the news feeds that are most important for KPMG, but you can imagine

30:43.200 --> 30:48.760
they're, they're very similar to what you would normally expect, but it's not going to

30:48.760 --> 30:53.160
be like tech news feeds, it's going to be more business oriented news feeds.

30:53.160 --> 30:54.160
Right.

30:54.160 --> 30:58.920
So maybe like a Thompson Reuters or something like that, that is like a third party feed

30:58.920 --> 31:00.600
that you're pulling in.

31:00.600 --> 31:01.600
Exactly.

31:01.600 --> 31:02.600
Something like that.

31:02.600 --> 31:06.960
I've talked a little bit about in the ideal world you've got.

31:06.960 --> 31:13.200
This is able to learn over time from the interactions with the actual users.

31:13.200 --> 31:15.560
Have you implemented that part of it yet?

31:15.560 --> 31:22.680
So we actually just went live across 700 accounts just about a month ago.

31:22.680 --> 31:29.200
So we, we're still very much new in terms of the improvement strategy, but we have piloted

31:29.200 --> 31:30.440
that.

31:30.440 --> 31:35.800
And now it's a question of how much, you know, what, what it really comes down to is you,

31:35.800 --> 31:41.440
we're not just going to accept, for example, any feedback as some, as a corrective measure

31:41.440 --> 31:43.640
for our recommendation engine.

31:43.640 --> 31:47.720
So it's really going to be a process where the technologists and the data scientists

31:47.720 --> 31:53.000
work hand in hand with the, with our best experts to determine, you know, based on the

31:53.000 --> 31:57.400
use and the patterns that we're seeing, what are the things that will allow us to best

31:57.400 --> 32:04.720
optimize and improve the system without, for example, going too far down edge cases or,

32:04.720 --> 32:10.400
you know, being, you know, really looking at the data, but having an expert side over

32:10.400 --> 32:11.400
it.

32:11.400 --> 32:14.200
That's really going to be a key part of the improvement strategy.

32:14.200 --> 32:21.200
You mentioned the entity recognition piece, and I recently did some work with actually

32:21.200 --> 32:28.320
a group of accounting firms talking to them about AI and its implications in that space.

32:28.320 --> 32:35.560
And one of the use cases that came up quite a bit, and KPMG has been very active in this

32:35.560 --> 32:44.120
area as well, has been using natural language processing for document and contract review.

32:44.120 --> 32:52.320
And in particular, lease review and lease abstraction, there's been some recent regulatory

32:52.320 --> 32:58.640
changes that go into effect the beginning of next year, I believe, that change the way

32:58.640 --> 33:08.080
leases are accounting for and many of the firms have jumped on AI as a way to automate

33:08.080 --> 33:14.320
the review of, you know, in some cases, tens of thousands or hundreds of thousands of leases

33:14.320 --> 33:22.280
to figure out what those, the terms of those leases are, and this concept of entity recognition

33:22.280 --> 33:24.680
plays pretty heavily in that whole use case.

33:24.680 --> 33:28.080
Have you been involved in any of the work on that type of application?

33:28.080 --> 33:29.080
Absolutely.

33:29.080 --> 33:30.160
Yeah, you're absolutely right.

33:30.160 --> 33:36.920
So the changes in IFRS 16 are what are causing all of everybody to kind of go around

33:36.920 --> 33:39.520
in a panic here about this.

33:39.520 --> 33:43.640
Yeah, so this, you're right.

33:43.640 --> 33:49.440
So I think at the end, what everybody would love to see is an automatic way of finding

33:49.440 --> 33:54.400
this information and a contract pulling it out appropriately and then determining based

33:54.400 --> 33:58.880
on it what the appropriate treatment is.

33:58.880 --> 34:01.320
And KPMG has a few different options.

34:01.320 --> 34:07.520
So one thing is we have the KPMG leasing tool, which is really once, you know, you have

34:07.520 --> 34:12.480
the, the terms and all of the, and all of the options and all of this information out

34:12.480 --> 34:16.120
of the lease, it's able to tell you what the appropriate treatment is.

34:16.120 --> 34:21.520
But one of the difficulties is that it's actually a manual process to go from the contract

34:21.520 --> 34:26.320
itself, the language in the contract, into an understanding of that contract to the

34:26.320 --> 34:31.760
point where you could actually say extract entities or facts from it in a way that would

34:31.760 --> 34:38.840
make the meaningful input into the KPMG leasing tool or any other, let's call it calculator

34:38.840 --> 34:42.600
of what the appropriate treatment would be for the leases.

34:42.600 --> 34:51.480
So this lease abstraction or we call it extraction work is something that my group has been

34:51.480 --> 34:52.480
involved in.

34:52.480 --> 34:58.080
There's a variety of groups who are involved in it across the firm with a variety of different

34:58.080 --> 34:59.280
ways of doing it.

34:59.280 --> 35:06.640
So we have people who are going after this from a very specific, you know, delivery model

35:06.640 --> 35:12.560
where, you know, you have 10,000 leases and you want this particular, you know, just

35:12.560 --> 35:18.520
a few entities abstracted from them, then we'll be able to deliver something that gives

35:18.520 --> 35:20.800
you like a spreadsheet of all of that.

35:20.800 --> 35:26.920
Now the work that I've been working on has been more, I'd say, more at the managed service

35:26.920 --> 35:33.000
or more at the expert augmentation level where I haven't just been focused on lease contracts.

35:33.000 --> 35:39.440
I've been working for the past few years on trying to build out a contract reading tool

35:39.440 --> 35:42.920
more generally for auditors.

35:42.920 --> 35:49.400
Where the idea is that I'm coming from the perspective that the facts that have to be extracted

35:49.400 --> 35:52.880
actually require a significant amount of human interpretation.

35:52.880 --> 35:59.280
Like so, usually with extraction, you have, let's say an entity and it's fairly easy to

35:59.280 --> 36:04.080
take, pull that string out of the text and then it's even better if that's the exact

36:04.080 --> 36:09.400
string that you would want to use further down the process, like whether, you know, input

36:09.400 --> 36:14.160
it into an Excel or put it into a calculation, but generally there's some level of human

36:14.160 --> 36:20.760
interpretation in terms of taking the that, say, entity and applying a calculation or

36:20.760 --> 36:25.560
resolving it in some way so that it's meaningful later on.

36:25.560 --> 36:31.560
My feeling especially when you look across the space of contracts is that, you know, maybe

36:31.560 --> 36:39.120
about 20 to 30 of these entities and leases are fairly easy to extract, but just based

36:39.120 --> 36:46.040
on the, you know, the differences in language around real estate leases versus equipment

36:46.040 --> 36:52.080
leases, for example, it's very difficult to build models once you get beyond those

36:52.080 --> 36:53.080
20 and 30.

36:53.080 --> 36:58.080
And a lot of times you do have to go beyond that to build up the calculations appropriately.

36:58.080 --> 37:03.560
So we build out expert augmentation systems for auditors where it helps them find the information

37:03.560 --> 37:04.880
in the original document.

37:04.880 --> 37:09.280
When we're able to find it, we take them there when we're able to, when we can't find

37:09.280 --> 37:14.200
the exact information, we try to take them to where in the text we think it is.

37:14.200 --> 37:19.120
And even better when it's something that requires several pieces of text that need to be resolved,

37:19.120 --> 37:23.240
we try to bring them to all of that text so that they can resolve it more appropriately.

37:23.240 --> 37:27.280
So we don't kind of, we really keep our knowledge workers in the system.

37:27.280 --> 37:32.480
This is very much expert augmentation for a managed service, which means a human's always

37:32.480 --> 37:35.320
going to be the person who's the ultimate arbiter.

37:35.320 --> 37:41.000
We're not really looking for automatic extraction, but there are other parts of the organization

37:41.000 --> 37:45.440
that are using very different techniques in order to be able to do that as well.

37:45.440 --> 37:53.120
Can you give us a specific example of where you need this expert's perspective to fully

37:53.120 --> 37:54.960
resolve an entity?

37:54.960 --> 37:59.440
Yeah, I think a lot of it comes down to.

37:59.440 --> 38:07.400
So sometimes you have to determine, for example, what is the, I'm thinking of service contracts,

38:07.400 --> 38:11.600
but there are other contracts where you have specific terms and you have to think about

38:11.600 --> 38:13.280
the frequency of something.

38:13.280 --> 38:18.760
A lot of times the way to determine the frequency usually involves a few different areas where

38:18.760 --> 38:23.160
they'll, they'll name a frequency, a specific frequency, but then later on they'll say, except

38:23.160 --> 38:27.600
in the case where you have this in which case it goes to this other type of frequency.

38:27.600 --> 38:32.840
Well, this is exactly the kind of thing where when you look at what the input these calculators

38:32.840 --> 38:35.440
are, it's going to be something like monthly.

38:35.440 --> 38:41.520
When you look at the text, it requires a significant amount of human interpretation to get

38:41.520 --> 38:47.320
from say three paragraphs to be able to determine that it's actually monthly for this

38:47.320 --> 38:49.360
specific period.

38:49.360 --> 38:53.000
This is the kind of thing that I'm thinking of as being somewhat difficult.

38:53.000 --> 38:58.600
Now, you could argue that these might be edge cases and it could be when it comes to

38:58.600 --> 39:01.120
the IFRS 16 changes, right?

39:01.120 --> 39:07.400
So I'm thinking about this from the perspective of auditors who have to go through a lease

39:07.400 --> 39:13.640
and find all of the information very, you know, very specifically they can't miss information.

39:13.640 --> 39:14.640
Right?

39:14.640 --> 39:18.880
It's a different perspective if you're looking at this from the advisory case where it's

39:18.880 --> 39:25.160
kind of like, I got 10,000 things to go through like just find me, you know, the top 10 and

39:25.160 --> 39:27.680
then I'll figure out what to do with the rest.

39:27.680 --> 39:30.520
Just I need to, you know, I need to do this quickly.

39:30.520 --> 39:37.160
So it's a different use case, but I come at it from the perspective of the auditor and

39:37.160 --> 39:43.840
helping them not miss information rather than just trying to get the information as quickly

39:43.840 --> 39:44.840
as possible.

39:44.840 --> 39:53.720
It's an interesting idea, a lot of the lease extraction or contract extraction products,

39:53.720 --> 40:00.480
projects that I've seen are kind of pulling out this simple, you know, some simple entity

40:00.480 --> 40:09.160
or trying to do simple calculations to resolve, call it first degree abstract entities

40:09.160 --> 40:15.360
like, you know, the contract duration is a year, you know, and you've got the date that

40:15.360 --> 40:20.440
the contract is signed, you can figure out the end date of the contract, for example.

40:20.440 --> 40:28.640
But it does strike me that I definitely can see how in some scenarios what you really need

40:28.640 --> 40:36.080
is to pull out the rules themselves because that's what the person who's going to end up

40:36.080 --> 40:41.680
reviewing this, you know, needs to be able to think about are the, you know, the different,

40:41.680 --> 40:44.200
you know, scenarios.

40:44.200 --> 40:49.880
And even the representation of that, like, how do you stick a rule into an excels, you

40:49.880 --> 40:50.880
know.

40:50.880 --> 40:51.880
Exactly.

40:51.880 --> 40:52.880
Exactly.

40:52.880 --> 40:56.920
And when you look at some of the excels sell spreadsheets that are being input into these

40:56.920 --> 41:01.400
tools, I mean, it's really ridiculous how they try to break this apart because you

41:01.400 --> 41:07.560
can see the kind of contortions they had to go through in order to build this out appropriately

41:07.560 --> 41:12.840
to get all of the information they need to apply the appropriate treatment, the calculation

41:12.840 --> 41:16.640
that determines the appropriate treatment and the fact that there's a lot of complexity

41:16.640 --> 41:17.640
there.

41:17.640 --> 41:18.800
I think that it's important.

41:18.800 --> 41:22.560
And I should say, for the easier entities, we're doing the same thing as everyone else.

41:22.560 --> 41:26.720
We're using entity extraction and we're doing fairly well with it.

41:26.720 --> 41:33.640
But the difference is that we're, we want to be able to provide a tool or tooling that

41:33.640 --> 41:40.440
allows our auditors to read any type of contract and find the appropriate information.

41:40.440 --> 41:43.840
And I think that's a slightly different take on it.

41:43.840 --> 41:51.040
But, but yeah, believe me, everyone in KPMG, well, a lot of people in KPMG are very much

41:51.040 --> 41:54.240
interested in what the appropriate way to do this is.

41:54.240 --> 42:00.000
And I think it really does make sense for KPMG to have a variety of business models depending

42:00.000 --> 42:02.000
on what the client needs.

42:02.000 --> 42:03.000
Absolutely.

42:03.000 --> 42:05.480
And as you will know, not just KPMG.

42:05.480 --> 42:06.480
Right.

42:06.480 --> 42:08.480
Very, very fast.

42:08.480 --> 42:09.480
Interesting.

42:09.480 --> 42:16.720
So I'm curious as we maybe start to wrap up, like, you know, a lot of what you are focused

42:16.720 --> 42:24.720
on here is this idea of expert augmentation or augmented intelligence, you know, have

42:24.720 --> 42:34.080
you want to describe it, are there some general principles that you've taken away from the

42:34.080 --> 42:41.840
various places that you've worked to use AI to, to augment experts?

42:41.840 --> 42:42.840
Yeah.

42:42.840 --> 42:48.160
I think so. I mean, I know that there are some tenets that I really feel strongly about

42:48.160 --> 42:54.040
in the systems that I design and that I try to push for.

42:54.040 --> 42:58.720
One of them, I mean, it comes back to what we had discussed early in the conversation.

42:58.720 --> 43:06.000
It really is about the appropriate way to codify knowledge and expertise and finding the

43:06.000 --> 43:08.240
best way you can do that.

43:08.240 --> 43:14.240
And I think at KPMG, what we've learned is that we try to employ various techniques, but

43:14.240 --> 43:18.800
we really want to make sure that we use the best possible technique for posterity.

43:18.800 --> 43:25.440
So we do use ontologies and we try to encode our information in ontologies as much as we

43:25.440 --> 43:26.440
can.

43:26.440 --> 43:31.440
But at the same time, we try to extract away from those or simplify those when it's needed

43:31.440 --> 43:34.080
for a very specific technical implementation.

43:34.080 --> 43:39.520
So we understand the limitations of both and we try to be able to use them appropriately

43:39.520 --> 43:42.280
in the right context.

43:42.280 --> 43:50.040
The other thing that I think is really important is I'm very interested in the type of human

43:50.040 --> 43:54.800
that we are augmenting and the role that this augmentation has.

43:54.800 --> 43:59.520
So I think that it's very different building out systems for efficiencies versus building

43:59.520 --> 44:01.600
out systems for quality.

44:01.600 --> 44:07.600
And I personally have always kind of been intrigued by expert augmentation for quality.

44:07.600 --> 44:12.240
So like I said, this might come back to the fact that I was working on Watson for health

44:12.240 --> 44:13.480
care originally.

44:13.480 --> 44:16.040
And that's one of the driving questions, right?

44:16.040 --> 44:21.600
You don't necessarily, you want to make a doctor's life easier, but so that you can

44:21.600 --> 44:27.320
increase the quality of what they're able to provide.

44:27.320 --> 44:32.920
And so it's very similar for me, I really think about the fact that our end result, for

44:32.920 --> 44:36.600
example, when we're looking at audit, is not to miss information.

44:36.600 --> 44:43.000
We, you know, that is the biggest risk for audit is we have to be able to say we've looked

44:43.000 --> 44:47.280
at all the information we're able to deliver the appropriate opinion based on it.

44:47.280 --> 44:52.080
And I find that is a very intriguing way to build out these systems.

44:52.080 --> 44:55.800
And I really want to make sure that the knowledge workers are in that system and are being

44:55.800 --> 44:58.400
there to train the system appropriately.

44:58.400 --> 45:03.960
So I've been, I talk a lot about machine teaching versus machine learning and this whole idea

45:03.960 --> 45:08.720
of having the system as kind of an intern at first for our engagement teams.

45:08.720 --> 45:12.840
This is the kind of thing that I think will help us build out the next generation of

45:12.840 --> 45:13.840
systems.

45:13.840 --> 45:16.600
Because in the end, there are, there are a few of these experts.

45:16.600 --> 45:21.080
You know, I'm not, I'm not working with like say in the consumer space where we have

45:21.080 --> 45:25.760
millions of users, you know, in the end, there might be only a handful of experts

45:25.760 --> 45:29.600
in the world with this particular who understand this.

45:29.600 --> 45:31.920
And so how do we encode that information?

45:31.920 --> 45:36.480
How do we capture the decisions they're making and how do we, and how do we make their

45:36.480 --> 45:41.000
lives easier so that they can, in the end, deliver higher quality decisions?

45:41.000 --> 45:42.480
Yeah, really interesting.

45:42.480 --> 45:46.720
I can, you know, I can continue to talk about this forever.

45:46.720 --> 45:53.080
Like I said, a lot of it, I can relate to very personally and, you know, one of the things

45:53.080 --> 45:59.200
I'm most, yeah, I tell people all the time, like I think the exciting thing about AI is

45:59.200 --> 46:02.200
its ability to give people superpowers.

46:02.200 --> 46:09.280
And it's particularly the case for, you know, or at least I think about it most frequently,

46:09.280 --> 46:15.480
you know, for folks like me that are trying to manage these torrents of information.

46:15.480 --> 46:25.280
And AI is a really powerful, you know, set of tools to help us do that.

46:25.280 --> 46:31.600
In fact, there's so many different ways that AI can be used to, you know, augment, you

46:31.600 --> 46:36.480
know, expert workers or knowledge workers.

46:36.480 --> 46:40.800
And so it's really interesting to learn a bit about the different ways that you're enabling

46:40.800 --> 46:41.800
that.

46:41.800 --> 46:42.800
Well, thank you.

46:42.800 --> 46:48.760
It's a pleasure talking to you as well, and it's exciting to hear that there's interest

46:48.760 --> 46:52.280
in this little corner of the world that I'm excited about it.

46:52.280 --> 46:53.280
Absolutely.

46:53.280 --> 46:54.880
Thanks so much, Marisa.

46:54.880 --> 46:56.120
Thank you, Sam.

46:56.120 --> 47:02.080
All right, everyone, that's our show for today.

47:02.080 --> 47:07.560
For more information on Marisa or any of the topics covered in this episode, head on over

47:07.560 --> 47:12.480
to twimolei.com slash talk slash 204.

47:12.480 --> 47:17.040
If you're a fan of the show and you haven't already done so or you're a new listener

47:17.040 --> 47:22.200
and you like what you hear, please head over to your Apple or Google podcast app and leave

47:22.200 --> 47:24.920
us a five-star rating and review.

47:24.920 --> 47:30.240
Your reviews help inspire us to create more and better content and they help new listeners

47:30.240 --> 47:32.040
find the show.

47:32.040 --> 47:36.240
As always, thanks so much for listening and catch you next time.

