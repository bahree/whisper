1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:28,720
I'm your host Sam Charrington.

4
00:00:28,720 --> 00:00:33,040
I want to send a quick thanks to our friends at Cloud Era for their sponsorship of this

5
00:00:33,040 --> 00:00:39,760
series of podcasts from the Stratidata conference, which they present along with O'Reilly media.

6
00:00:39,760 --> 00:00:41,960
Cloud Era is long been a supporter of the podcast.

7
00:00:41,960 --> 00:00:47,760
In fact, they sponsored the very first episode of Twimble Talk back in 2016.

8
00:00:47,760 --> 00:00:51,920
Since that time, Cloud Era has continued to invest in and build out its platform, which

9
00:00:51,920 --> 00:00:57,680
already securely hosts huge volumes of enterprise data, to provide enterprise customers with

10
00:00:57,680 --> 00:01:01,920
a modern environment for machine learning and analytics that works both in the cloud

11
00:01:01,920 --> 00:01:04,240
as well as in the data center.

12
00:01:04,240 --> 00:01:09,680
In addition, Cloud Era Fast Forward Labs provides research and expert guidance that helps enterprises

13
00:01:09,680 --> 00:01:14,080
understand the realities of building with AI technologies without needing the higher

14
00:01:14,080 --> 00:01:16,440
and in-house research team.

15
00:01:16,440 --> 00:01:19,840
To learn more about what the company is up to and how they can help, visit Cloud Era's

16
00:01:19,840 --> 00:01:32,080
machine learning resource center at cloudera.com slash ml.

17
00:01:32,080 --> 00:01:33,080
All right, everyone.

18
00:01:33,080 --> 00:01:35,080
I am on the line with Eric Colson.

19
00:01:35,080 --> 00:01:39,560
Eric is the chief algorithms officer at StitchFix.

20
00:01:39,560 --> 00:01:44,560
And Eric and I are here today to talk a little bit about some of the work the company's

21
00:01:44,560 --> 00:01:51,080
done around algorithms and organizing for success in data science.

22
00:01:51,080 --> 00:01:54,200
And I suspect some other stuff will come up as well.

23
00:01:54,200 --> 00:01:57,400
Eric, welcome to this week in machine learning and AI.

24
00:01:57,400 --> 00:02:01,560
It's fun to be here with you and thanks for having me on board.

25
00:02:01,560 --> 00:02:02,560
Absolutely.

26
00:02:02,560 --> 00:02:03,560
Absolutely.

27
00:02:03,560 --> 00:02:06,200
Why don't we start by learning a little bit about your background.

28
00:02:06,200 --> 00:02:11,320
You spent what, five or six years at Netflix before joining StitchFix.

29
00:02:11,320 --> 00:02:17,080
How did you kind of get started in data science and machine learning and kind of work your

30
00:02:17,080 --> 00:02:18,760
way to Netflix and StitchFix?

31
00:02:18,760 --> 00:02:19,760
I don't know.

32
00:02:19,760 --> 00:02:20,760
Okay.

33
00:02:20,760 --> 00:02:21,760
You want to go way back.

34
00:02:21,760 --> 00:02:23,920
Well, let's see.

35
00:02:23,920 --> 00:02:29,000
To be honest, data science is kind of what I wanted to do from the very beginning, even

36
00:02:29,000 --> 00:02:34,960
back 20 years ago, undergrad days, I'm not the closer to 25 now, that we didn't have

37
00:02:34,960 --> 00:02:36,760
the word data science back then.

38
00:02:36,760 --> 00:02:44,120
But when I majored in my undergrad was economics, and particularly micro economics was a passion

39
00:02:44,120 --> 00:02:45,120
of mine.

40
00:02:45,120 --> 00:02:47,960
I thought this is something that I wanted to do for companies, right?

41
00:02:47,960 --> 00:02:52,440
Go in there and it seems like such a, what I call a noble way to compete, to be used

42
00:02:52,440 --> 00:02:58,720
data and statistics and things to operate a business better more efficiently.

43
00:02:58,720 --> 00:03:02,680
And that's a win-win because it would be better for the consumers better for the company

44
00:03:02,680 --> 00:03:05,120
hence a noble way to compete.

45
00:03:05,120 --> 00:03:06,680
And I thought that'd be great.

46
00:03:06,680 --> 00:03:11,040
And so I learned as much as I could in my micro economics, I maybe took a few courses

47
00:03:11,040 --> 00:03:13,080
in statistics, but that was about it.

48
00:03:13,080 --> 00:03:21,160
I graduated and I got into the industry, into companies, I got a gig consulting, helping

49
00:03:21,160 --> 00:03:22,320
companies do this.

50
00:03:22,320 --> 00:03:27,200
And it turns out that micro economic stuff was pretty much all theory.

51
00:03:27,200 --> 00:03:30,920
Nobody was doing this stuff yet.

52
00:03:30,920 --> 00:03:35,360
You talk about being born at the right time, however, you know, right when I got out

53
00:03:35,360 --> 00:03:39,080
of undergrad was right when things were starting to turn.

54
00:03:39,080 --> 00:03:43,960
The stuff was still highly theoretical, but data was becoming available and the cost

55
00:03:43,960 --> 00:03:47,760
of the process it was becoming affordable.

56
00:03:47,760 --> 00:03:50,960
And so now you could actually start to do these things.

57
00:03:50,960 --> 00:03:56,120
Again, these were represented as graphs in economics textbooks.

58
00:03:56,120 --> 00:03:57,720
Nobody actually really did them.

59
00:03:57,720 --> 00:04:02,480
They were just kind of conceptual, but for the first time ever it was becoming possible.

60
00:04:02,480 --> 00:04:06,920
So it was kind of fun to be, you know, entering the workforce at exactly that moment where

61
00:04:06,920 --> 00:04:10,520
I got to do something that the time was very novel.

62
00:04:10,520 --> 00:04:16,720
But I learned sort of the hard way that economics did not properly prepare me for this.

63
00:04:16,720 --> 00:04:21,080
The required skills were sort of distributed into several fields.

64
00:04:21,080 --> 00:04:27,600
I mentioned statistics, there's also computer science and then more of a business domain

65
00:04:27,600 --> 00:04:29,640
expertise type of thing.

66
00:04:29,640 --> 00:04:32,920
And I found out that economics alone was just completely impractical.

67
00:04:32,920 --> 00:04:37,960
You needed, you know, the statistics to actually quantify the exact curves and the shapes

68
00:04:37,960 --> 00:04:41,920
of those curves and where points intersect, so we find the top of a curve that type of

69
00:04:41,920 --> 00:04:42,920
thing.

70
00:04:42,920 --> 00:04:47,720
And then to do anything, you need a computer science to process that data to allow those statistics

71
00:04:47,720 --> 00:04:50,000
to compute, et cetera.

72
00:04:50,000 --> 00:04:54,720
And then of course you needed domain expertise in the business, which I got through my consulting

73
00:04:54,720 --> 00:04:55,720
path.

74
00:04:55,720 --> 00:05:02,520
But my whole career has been that quest to kind of combine those three things all in the

75
00:05:02,520 --> 00:05:07,080
quest to do these micro economic type of models to put them into production and make them

76
00:05:07,080 --> 00:05:08,080
a reality.

77
00:05:08,080 --> 00:05:09,080
So that's my background.

78
00:05:09,080 --> 00:05:15,320
It goes back, you know, 25 years ago consulting and then, you know, going back to school to

79
00:05:15,320 --> 00:05:20,960
get better computer science skills and better statistic skills, et cetera.

80
00:05:20,960 --> 00:05:28,600
And sort of meandered across business domains to consulting later into the world of big

81
00:05:28,600 --> 00:05:32,880
data when I time at Yahoo or learning how to process petabytes of data.

82
00:05:32,880 --> 00:05:38,720
And then later when I got to Netflix actually putting things into production through algorithms

83
00:05:38,720 --> 00:05:44,440
actually having, you know, systems that would take automated action on things to actually

84
00:05:44,440 --> 00:05:48,360
do things in response to these micro economic trends and so forth.

85
00:05:48,360 --> 00:05:53,240
And so that was kind of my amalgam of stuff that I had to come together with.

86
00:05:53,240 --> 00:05:57,240
And then my latest thing is figuring out how to organize for this.

87
00:05:57,240 --> 00:06:01,440
So it's been a long road with a lot of things coming together nicely and again completely

88
00:06:01,440 --> 00:06:02,440
unplanned by my part.

89
00:06:02,440 --> 00:06:06,360
This was all just a silly quest to do these micro economic things.

90
00:06:06,360 --> 00:06:11,560
But along the path I got meds into different directions to acquire different skills and

91
00:06:11,560 --> 00:06:16,920
the experiences that kind of have all now culminated into where I am today.

92
00:06:16,920 --> 00:06:24,320
But you talk about micro economics and algorithms, at least the kinds of algorithms that we tend

93
00:06:24,320 --> 00:06:31,920
to see at companies like Yahoo and Netflix and StitchFix as almost one in the same.

94
00:06:31,920 --> 00:06:36,600
But I never hear that characterization as you know what we're trying to do is put micro

95
00:06:36,600 --> 00:06:39,080
economics into practice.

96
00:06:39,080 --> 00:06:45,160
You suppose there's any kind of unique perspective that your passion for micro economics and

97
00:06:45,160 --> 00:06:50,600
background in that field that you bring to data science?

98
00:06:50,600 --> 00:06:52,600
Yeah, because you're corrected.

99
00:06:52,600 --> 00:06:57,520
I believe the things like recommendation systems really were born out of schools of computer

100
00:06:57,520 --> 00:06:59,720
science as opposed to economics.

101
00:06:59,720 --> 00:07:05,160
But if you think about what they're doing is they're making an organization more efficient

102
00:07:05,160 --> 00:07:10,440
right, which is really micro economics is the classic micro economics which are the things

103
00:07:10,440 --> 00:07:13,600
that are in my textbooks where things like pricing efficiency.

104
00:07:13,600 --> 00:07:19,560
Figure out your base price elasticity and setting prices appropriately or more from the

105
00:07:19,560 --> 00:07:24,160
school of operations research how to run your operations more efficiently.

106
00:07:24,160 --> 00:07:31,320
And they all use the same concepts from math and statistics to and leverage data to materialize

107
00:07:31,320 --> 00:07:37,440
those concepts and then you take action them through automated means or algorithms.

108
00:07:37,440 --> 00:07:43,080
So all those things kind of I put under this kind of superheading of micro economics.

109
00:07:43,080 --> 00:07:47,880
And if those textbooks were written now, I think they could include things like recommendation

110
00:07:47,880 --> 00:07:50,280
systems because they are doing a similar thing.

111
00:07:50,280 --> 00:07:55,640
They're leveraging a company's internal asset data in order to be more efficient figuring

112
00:07:55,640 --> 00:07:58,520
out what to show different customers and say.

113
00:07:58,520 --> 00:08:01,360
You've been at Citrix for how long now?

114
00:08:01,360 --> 00:08:03,920
Coming up on seven years now.

115
00:08:03,920 --> 00:08:09,160
Yeah, it's a little I you know I first started actually as an advisor to the company and

116
00:08:09,160 --> 00:08:11,640
that was a little over seven years ago.

117
00:08:11,640 --> 00:08:13,600
I was at Netflix prior to this.

118
00:08:13,600 --> 00:08:19,680
So it was the VP of data science and engineering at Netflix for six or six and a half years.

119
00:08:19,680 --> 00:08:24,680
No interest in actually leaving Netflix, but I got a call and you get calls a lot, but

120
00:08:24,680 --> 00:08:26,800
Netflix, you're pretty busy.

121
00:08:26,800 --> 00:08:30,440
You work a lot of hours is hard and the company is a fast pace.

122
00:08:30,440 --> 00:08:35,480
And so you don't really participate in a lot of things outside of Netflix, so things

123
00:08:35,480 --> 00:08:36,480
like advising.

124
00:08:36,480 --> 00:08:41,000
So I would pretty quickly turn these things down and wouldn't even listen to most of them.

125
00:08:41,000 --> 00:08:45,320
But I do remember receiving a particular call from a venture capitalist was in the parking

126
00:08:45,320 --> 00:08:47,840
of Netflix trying to leave to go home.

127
00:08:47,840 --> 00:08:53,680
And I took the call and he told me about Citrix and its founder Katrina Lake, who's trying

128
00:08:53,680 --> 00:08:57,760
to do this interesting thing with clothing.

129
00:08:57,760 --> 00:08:59,480
And instantly it struck a chord.

130
00:08:59,480 --> 00:09:04,200
It was sort of a fortuitous timing that very day, some of the meetings I walked out of

131
00:09:04,200 --> 00:09:09,440
earlier that day, we were stumbling on some problems, things like more opportunities

132
00:09:09,440 --> 00:09:13,480
I should call them, you know, we talked about our recommendations as the meta Netflix.

133
00:09:13,480 --> 00:09:18,240
And you know, at the time most of the recommendations were there on the website as well as in the

134
00:09:18,240 --> 00:09:19,240
mobile app.

135
00:09:19,240 --> 00:09:23,920
But what we would do is we'd cast a wide net with the recommendations, because we're

136
00:09:23,920 --> 00:09:27,160
not that confident in what somebody wants to watch a meta predict for a moment.

137
00:09:27,160 --> 00:09:31,200
So on the website, you might be met with a hundred recommendations that want a hundred

138
00:09:31,200 --> 00:09:34,720
box shots of different movies and might be interested in.

139
00:09:34,720 --> 00:09:35,720
We used to joke.

140
00:09:35,720 --> 00:09:39,120
There's a product manager still at Netflix today that would joke, you know, if we are

141
00:09:39,120 --> 00:09:43,400
more confident in our recommendations, we wouldn't show so many a hundred.

142
00:09:43,400 --> 00:09:49,240
We would show maybe like five or even one if we're super confident in our recommendations,

143
00:09:49,240 --> 00:09:52,840
we could just play the very thing the person wants to see.

144
00:09:52,840 --> 00:09:56,480
And you can imagine that you open up the app and the very thing you wanted to see just

145
00:09:56,480 --> 00:09:57,480
starts playing.

146
00:09:57,480 --> 00:09:58,840
Now that would be bold.

147
00:09:58,840 --> 00:10:04,080
All right, so this was a conversation we had just had and I get the call about Citrix,

148
00:10:04,080 --> 00:10:06,840
which is doing this very thing, but with clothing, right?

149
00:10:06,840 --> 00:10:10,880
They're going to be so bold is not to actually just recommend the clothes to you, but they're

150
00:10:10,880 --> 00:10:13,800
rather going to ship them to your door side unseen.

151
00:10:13,800 --> 00:10:17,520
So I found that was interesting and, you know, hearing about their business model was

152
00:10:17,520 --> 00:10:20,200
very interesting.

153
00:10:20,200 --> 00:10:24,880
And you know, again, they caught me at the right timing that, you know, this sounds like

154
00:10:24,880 --> 00:10:28,080
something that I'd like to participate in, not as an employee.

155
00:10:28,080 --> 00:10:29,080
That sounds crazy.

156
00:10:29,080 --> 00:10:34,720
I'm not going to leave Netflix for this, you know, risky startup, but I'll be an advisor.

157
00:10:34,720 --> 00:10:37,680
And so I, well, even that didn't happen immediately.

158
00:10:37,680 --> 00:10:43,320
I had the first research Katrina, the founder, our CEO, which is very impressive on paper,

159
00:10:43,320 --> 00:10:46,000
but she hadn't run a company before.

160
00:10:46,000 --> 00:10:47,680
This was her first startup.

161
00:10:47,680 --> 00:10:52,480
And so, you know, I was actually even reluctant to even take the meeting with her because

162
00:10:52,480 --> 00:10:54,320
of time, I just never had time.

163
00:10:54,320 --> 00:10:59,600
But we finally ended up meeting up in San Francisco and we hit it off and once I met her

164
00:10:59,600 --> 00:11:06,720
in person, I realized there's a lot more thought put into this than I had first believed.

165
00:11:06,720 --> 00:11:09,120
And, you know, I was very inspired by her.

166
00:11:09,120 --> 00:11:11,160
And anyways, we made it happen.

167
00:11:11,160 --> 00:11:12,920
I became an advisor to the company.

168
00:11:12,920 --> 00:11:15,520
I still wasn't going to joke.

169
00:11:15,520 --> 00:11:19,640
And I last said, merely four or five months as a big advisor, one of the conditions of

170
00:11:19,640 --> 00:11:22,320
my advising is I needed access to the data.

171
00:11:22,320 --> 00:11:27,240
I wanted to be able to see what's going on in there and how, you know, the quality of

172
00:11:27,240 --> 00:11:31,360
the data, how predictive it can be, and what it could be useful with.

173
00:11:31,360 --> 00:11:36,120
And she complied and was able to access the data and I looked at things.

174
00:11:36,120 --> 00:11:38,640
And I never seen data like this before.

175
00:11:38,640 --> 00:11:42,880
It was like straight out of the textbook, those old, like those microeconomic textbooks,

176
00:11:42,880 --> 00:11:48,080
things that were supposed to be theory, where it's clear as day, the curves looked like

177
00:11:48,080 --> 00:11:53,120
the curves they're supposed to be had gouches, you had, you know, power laws, you had all

178
00:11:53,120 --> 00:11:56,920
the things right there staring at the face, you didn't even have to do much to reveal

179
00:11:56,920 --> 00:12:00,840
that we just kind of query the data in there, it was presented to you and a lot of this

180
00:12:00,840 --> 00:12:01,840
is fun.

181
00:12:01,840 --> 00:12:06,120
There's a lot of predictive power once you have that data that's so well behaved and I

182
00:12:06,120 --> 00:12:11,120
loved explaining the novel and so I get hooked on this data pretty quickly over my four

183
00:12:11,120 --> 00:12:12,120
months of the advisor.

184
00:12:12,120 --> 00:12:15,160
I'm supposed to be spending like an hour a month with the company.

185
00:12:15,160 --> 00:12:16,160
That's my contract.

186
00:12:16,160 --> 00:12:20,840
I was spending more like 25 hours a month, just tinkering and again, I'm a busy guy.

187
00:12:20,840 --> 00:12:25,560
I had things going on at Netflix, but I found the time to tinker with this stuff and I

188
00:12:25,560 --> 00:12:26,560
got hooked.

189
00:12:26,560 --> 00:12:30,640
The other thing that happened over this four or five months as an advisor is I had my

190
00:12:30,640 --> 00:12:32,040
wife try the service.

191
00:12:32,040 --> 00:12:37,960
It was women only at the time, so I had my wife try it and a few of the ladies in my neighborhood

192
00:12:37,960 --> 00:12:38,960
try.

193
00:12:38,960 --> 00:12:43,120
Of course, they try it the first time because I asked them to, but I watched them and I

194
00:12:43,120 --> 00:12:49,080
watched how the anticipation when they're waiting to receive their fix, their shipment

195
00:12:49,080 --> 00:12:53,480
and I watched the joy as they open these things and I watched how they talked about how

196
00:12:53,480 --> 00:12:58,880
it made them feel and then I watched most importantly how it changed their behaviors.

197
00:12:58,880 --> 00:13:00,960
All of a sudden they stop going to stores.

198
00:13:00,960 --> 00:13:05,800
This becomes their primary means of shopping and this is something Katrina tried to tell

199
00:13:05,800 --> 00:13:09,640
me from the very beginning to say, we're going to change the way people shop and I thought

200
00:13:09,640 --> 00:13:14,440
that was just a founder aspiration and I go, that's great, you should believe that because

201
00:13:14,440 --> 00:13:15,440
you're the founder.

202
00:13:15,440 --> 00:13:19,520
I don't want to believe it because I'm just an advisor, but I found that she was not

203
00:13:19,520 --> 00:13:24,760
just one smoke, she meant it and it took me five months and staring at data to be convinced

204
00:13:24,760 --> 00:13:30,480
of it and seeing some anecdotal examples of my wife and neighborhood ladies to really

205
00:13:30,480 --> 00:13:31,480
find it compelling.

206
00:13:31,480 --> 00:13:36,680
I said, wow, she's onto something and that's when I approached Katrina, who's August of 2012

207
00:13:36,680 --> 00:13:42,000
is, hey, Katrina, if you'll have me in as an employee, I'd love to do this.

208
00:13:42,000 --> 00:13:45,800
We figured out how to make that work and it's been a fun ride ever since.

209
00:13:45,800 --> 00:13:47,680
Oh, what a great story.

210
00:13:47,680 --> 00:13:55,040
So since then, you've done quite a bit with algorithms and data science at StitchFix.

211
00:13:55,040 --> 00:14:00,560
Can you kind of give us an overview of the different ways that data science plays out

212
00:14:00,560 --> 00:14:02,040
within StitchFix?

213
00:14:02,040 --> 00:14:07,320
Yeah, so StitchFix, the fun thing is, is we found these applications of data science

214
00:14:07,320 --> 00:14:08,920
throughout the company.

215
00:14:08,920 --> 00:14:13,720
So what had originally started is the most ostensible thing we could do is a recommendation

216
00:14:13,720 --> 00:14:14,720
system, right?

217
00:14:14,720 --> 00:14:18,600
We're going to be picking out clothes for people and we're going to be paying, you know,

218
00:14:18,600 --> 00:14:20,720
this is the start contrast to Netflix.

219
00:14:20,720 --> 00:14:24,520
Netflix, we recommend things just digitally, bits and bytes, we recommend things through

220
00:14:24,520 --> 00:14:30,640
a web page or a map, but with StitchFix, we're actually going to send it to you, right?

221
00:14:30,640 --> 00:14:35,440
So we need to pay the shipping to get it to your house and that is expensive, right?

222
00:14:35,440 --> 00:14:39,440
So we got the shipping in both directions we're paying for, plus that cost of the physical

223
00:14:39,440 --> 00:14:43,400
inventory being unavailable to other clients for a period of time, right?

224
00:14:43,400 --> 00:14:47,840
So this is getting expensive, plus we have a much bigger investment on the part of our

225
00:14:47,840 --> 00:14:49,480
client, right?

226
00:14:49,480 --> 00:14:53,400
So our client is expecting a very relevant box of clothes.

227
00:14:53,400 --> 00:14:56,520
She's going to be very upset if we get this wrong.

228
00:14:56,520 --> 00:15:00,360
Contrast to Netflix, people, you know, there's going to be recommendations that happen, but

229
00:15:00,360 --> 00:15:01,560
it's sort of a shoulder shrug.

230
00:15:01,560 --> 00:15:06,120
You move on, you know, as a consumer or a client at Netflix, you know, that's weird.

231
00:15:06,120 --> 00:15:07,120
Why are you recommending that?

232
00:15:07,120 --> 00:15:08,120
And you move on.

233
00:15:08,120 --> 00:15:12,080
And on Netflix, I didn't really cost them much on that, at least on the margin for an

234
00:15:12,080 --> 00:15:15,160
incremental bad recommendation, not a big deal.

235
00:15:15,160 --> 00:15:20,880
Of course, an aggregate, it could be pretty bad, but on the margin, not a big deal.

236
00:15:20,880 --> 00:15:26,520
So Citrix has this interesting nuance that, oh, we're actually, we have bigger penalties

237
00:15:26,520 --> 00:15:27,520
for getting it wrong.

238
00:15:27,520 --> 00:15:29,520
And it turns out this is a good thing.

239
00:15:29,520 --> 00:15:32,560
This makes you pay attention as an algorithm developer.

240
00:15:32,560 --> 00:15:38,120
You want a penalty so that you really have to, you have the screen incentive to get it

241
00:15:38,120 --> 00:15:39,120
right.

242
00:15:39,120 --> 00:15:42,560
You don't want the penalties to be too high because then you won't take any risk.

243
00:15:42,560 --> 00:15:44,880
And that's why you get them like financial loans, right?

244
00:15:44,880 --> 00:15:50,280
They don't want a single default that ever happened because while the defaults will

245
00:15:50,280 --> 00:15:55,960
probably evoke great learnings, it's still very costly, it could be $50,000.

246
00:15:55,960 --> 00:16:00,600
So Citrix is right in a sweet spot with our recommendations, the penalties are severe.

247
00:16:00,600 --> 00:16:03,600
You don't want to have many of them, but not so severe they're not going to take any

248
00:16:03,600 --> 00:16:04,600
risk.

249
00:16:04,600 --> 00:16:05,800
You want to learn, they'll do those things.

250
00:16:05,800 --> 00:16:08,760
So okay, this is interesting now.

251
00:16:08,760 --> 00:16:13,200
And so we started, you know, again, this was the most obvious thing we can do is start

252
00:16:13,200 --> 00:16:16,120
to build a recommendation engine.

253
00:16:16,120 --> 00:16:17,120
And we've done that.

254
00:16:17,120 --> 00:16:19,440
We did that from the very beginning and it was great.

255
00:16:19,440 --> 00:16:23,600
We started out with very simple methods and started getting more and more leverage.

256
00:16:23,600 --> 00:16:25,920
Of course, we have a new ones with our humans in the loop.

257
00:16:25,920 --> 00:16:31,200
We also have stylists because there's things that machines can't do, things like empathizing

258
00:16:31,200 --> 00:16:33,280
and relating to other humans, right?

259
00:16:33,280 --> 00:16:38,160
So we still need that, but we need machines to do all the things that are more quantitative

260
00:16:38,160 --> 00:16:39,440
and paracol.

261
00:16:39,440 --> 00:16:42,760
And so there's this whole challenge of combining those two different process.

262
00:16:42,760 --> 00:16:45,920
There's machine hardware with human hardware.

263
00:16:45,920 --> 00:16:49,320
And so we've figured out how to do that over the years.

264
00:16:49,320 --> 00:16:54,480
But that was just our initial foot in the water on algorithms.

265
00:16:54,480 --> 00:16:59,240
We quickly learned that there's a whole bunch of other things we can do.

266
00:16:59,240 --> 00:17:04,400
And things like inventory management algorithms, things like demand forecasting algorithms,

267
00:17:04,400 --> 00:17:06,200
things like escalation algorithms.

268
00:17:06,200 --> 00:17:10,000
Or even, we even have algorithms that are designing the closed now.

269
00:17:10,000 --> 00:17:15,400
So the algorithms proliferated and we can talk about how that happens in a pit.

270
00:17:15,400 --> 00:17:20,640
But we now have several dozen algorithmic capabilities that are running various parts

271
00:17:20,640 --> 00:17:22,040
of the company.

272
00:17:22,040 --> 00:17:24,200
And not much of it was planned for.

273
00:17:24,200 --> 00:17:27,320
They all sort of emerged kind of naturally.

274
00:17:27,320 --> 00:17:30,280
And so I can't take credit for planning this all out.

275
00:17:30,280 --> 00:17:35,680
This was having the right people around and the right motivations for them to figure

276
00:17:35,680 --> 00:17:38,680
this stuff out, not eating without being asked to.

277
00:17:38,680 --> 00:17:42,000
So a lot of these things that you'll see on that algorithms tour, if you go check that

278
00:17:42,000 --> 00:17:48,360
out, they just emerged on their own, not driven by top down processes.

279
00:17:48,360 --> 00:17:51,480
And that's the conversation that we'll get into in a bit.

280
00:17:51,480 --> 00:17:57,520
But I want the main thing to convey now is that it's not just the recommendation system.

281
00:17:57,520 --> 00:18:01,600
We have over a hundred algorithm developers at StitchFix and we only have about seven

282
00:18:01,600 --> 00:18:03,520
that are working on the recommendation system.

283
00:18:03,520 --> 00:18:07,360
And the other 93 are doing other types of algorithms that are equally important.

284
00:18:07,360 --> 00:18:09,440
They're just a little bit more behind the scenes.

285
00:18:09,440 --> 00:18:15,560
They're not ostensible to the outside world as much as our recommendation system is.

286
00:18:15,560 --> 00:18:17,440
And you mentioned the algorithms tour.

287
00:18:17,440 --> 00:18:23,920
That's a post that you put up on the StitchFix blog a couple of years back.

288
00:18:23,920 --> 00:18:27,840
And we will link to that in the show notes so folks can check it out.

289
00:18:27,840 --> 00:18:30,080
It's definitely pretty interesting.

290
00:18:30,080 --> 00:18:37,280
But when you think about these hundreds of algorithms, how do you think about them from

291
00:18:37,280 --> 00:18:40,840
a portfolio and value perspective?

292
00:18:40,840 --> 00:18:49,640
Is the recommendation system kind of the big value driver and then you've got a bunch

293
00:18:49,640 --> 00:18:59,360
of low hanging fruit smaller systems or are there other kind of big value drivers in there?

294
00:18:59,360 --> 00:19:03,840
How do you think about that algorithmic landscape, if you will?

295
00:19:03,840 --> 00:19:04,840
Well, you can see.

296
00:19:04,840 --> 00:19:11,960
So there are ones that are equally valuable to even a recommendation system.

297
00:19:11,960 --> 00:19:15,240
And there are smaller ones, bigger ones, etc.

298
00:19:15,240 --> 00:19:16,400
So they're kind of all of them out.

299
00:19:16,400 --> 00:19:20,200
Now they are nicely, most of the time, nicely quantifiable.

300
00:19:20,200 --> 00:19:24,360
You can do things like A, B, Testum to find out what would happen in the absence of their

301
00:19:24,360 --> 00:19:29,440
presence and you can find out what they're worth to the company.

302
00:19:29,440 --> 00:19:34,600
That's how most of them emerge as we can say things like, we develop this new algorithm.

303
00:19:34,600 --> 00:19:38,120
And if we use it, it will generate X.

304
00:19:38,120 --> 00:19:39,920
So it becomes what we call no-brainer.

305
00:19:39,920 --> 00:19:45,520
There's no cost or the cost has already been born and we know the value.

306
00:19:45,520 --> 00:19:46,720
That's what you call no-brainer.

307
00:19:46,720 --> 00:19:53,280
Of course, we're going to push that to production and get the benefits.

308
00:19:53,280 --> 00:19:57,360
To give you a little more context of some of the value it's driving, so you have things

309
00:19:57,360 --> 00:20:01,320
like inventory algorithms that manage the inventory or buying algorithms.

310
00:20:01,320 --> 00:20:02,720
So we do hold inventory.

311
00:20:02,720 --> 00:20:07,520
So what happens is we buy things at wholesale, sell them at retail, right?

312
00:20:07,520 --> 00:20:11,680
Same business model that's existed for hundreds of years, but we do it more efficiently.

313
00:20:11,680 --> 00:20:16,920
So when we buy things at wholesale, we need to decide what to go buy.

314
00:20:16,920 --> 00:20:20,600
And we crudely break it into two classes of purchases.

315
00:20:20,600 --> 00:20:25,280
We'll be called rebuys, things that we've had some experience before, such as dresses

316
00:20:25,280 --> 00:20:29,440
and jeans and things that we've actually tried out in the past, and we've got data on

317
00:20:29,440 --> 00:20:30,440
it now.

318
00:20:30,440 --> 00:20:33,360
So those things can be managed algorithmically.

319
00:20:33,360 --> 00:20:37,440
And so we have an algorithm that says what to go buy.

320
00:20:37,440 --> 00:20:40,960
And that is tremendously valuable.

321
00:20:40,960 --> 00:20:44,440
I hadn't had an appreciation of this before working in retail.

322
00:20:44,440 --> 00:20:47,960
I've heard from others that hadn't worked in retail about what a challenge it says,

323
00:20:47,960 --> 00:20:51,560
but I didn't have the appreciation until I got to live and breathe it.

324
00:20:51,560 --> 00:20:53,360
Buying is tricky.

325
00:20:53,360 --> 00:20:58,000
Buying your merchandise is one of the most critical things you can do for a company, right?

326
00:20:58,000 --> 00:20:59,560
This is your big capital outlay.

327
00:20:59,560 --> 00:21:03,680
You're going to buy this inventory and then you're going to sell it.

328
00:21:03,680 --> 00:21:06,680
And if it doesn't sell, you're stocked with a lot of inventory.

329
00:21:06,680 --> 00:21:10,040
And if you buy the wrong sizes of stuff, it could be way off, right?

330
00:21:10,040 --> 00:21:16,400
So most companies, most retailers buy this kind of standard distribution of sizes, you

331
00:21:16,400 --> 00:21:19,480
know, you have things like extra small, small, medium, large, and extra large.

332
00:21:19,480 --> 00:21:24,040
And you get like a bell shaped curve over that, you know, the quantity you're going to

333
00:21:24,040 --> 00:21:25,040
buy.

334
00:21:25,040 --> 00:21:29,480
But it turns out that that's not necessarily what's going to get sold.

335
00:21:29,480 --> 00:21:33,840
And so rather than buy in a traditional bell shaped curve, we'll buy in the distributions

336
00:21:33,840 --> 00:21:36,040
that are clients exhibit.

337
00:21:36,040 --> 00:21:41,640
So in some cases, we may choose to get no extra large at all in some particular bios

338
00:21:41,640 --> 00:21:45,040
because we've learned that it doesn't fit well.

339
00:21:45,040 --> 00:21:51,240
Or we'll buy twice as many smalls as mediums because we know that our clients will demonstrate

340
00:21:51,240 --> 00:21:52,400
that behavior.

341
00:21:52,400 --> 00:21:57,640
And so this is really a lot more efficient when you can buy the right things that you know

342
00:21:57,640 --> 00:22:00,480
we're going to sell in the right amount of time.

343
00:22:00,480 --> 00:22:05,520
And so again, we use a myriad of algorithms and some of them were borrowed from the area

344
00:22:05,520 --> 00:22:11,880
of Operation Research to figure out how frequently to buy things, what quantities to buy in,

345
00:22:11,880 --> 00:22:16,440
and what overall distributions of what we call an assortment to buy.

346
00:22:16,440 --> 00:22:22,200
And this makes a humongous difference in providing value to our clients and to our economic

347
00:22:22,200 --> 00:22:23,680
sense, the checks.

348
00:22:23,680 --> 00:22:30,280
Now as you describe these hundreds of algorithms or 800 algorithms constantly at work at Stitch

349
00:22:30,280 --> 00:22:37,320
Fix, I'm thinking of, it calls to mind for me, you know, these hundreds of individual

350
00:22:37,320 --> 00:22:44,120
applications and is there a common operating system that all of these applications run

351
00:22:44,120 --> 00:22:45,120
on?

352
00:22:45,120 --> 00:22:53,360
Can you speak a little bit to the way you support the different algorithmic efforts from

353
00:22:53,360 --> 00:22:55,360
a technology perspective?

354
00:22:55,360 --> 00:22:56,360
Right.

355
00:22:56,360 --> 00:23:03,320
So that is a critical point of success for any algorithms team is to have a great algorithms

356
00:23:03,320 --> 00:23:05,040
platform team.

357
00:23:05,040 --> 00:23:08,920
And so we have that, they're also part of the department, right, so they're not a separate

358
00:23:08,920 --> 00:23:15,480
team, they're within us and they call them data platform or algorithms platform.

359
00:23:15,480 --> 00:23:20,560
And these folks are a little bit more computer science oriented.

360
00:23:20,560 --> 00:23:24,080
They're great generalizers, they'll build things that run that algorithm or that algorithm

361
00:23:24,080 --> 00:23:25,080
or that one, right.

362
00:23:25,080 --> 00:23:26,360
So they know how to generalize things.

363
00:23:26,360 --> 00:23:31,960
They also build the infrastructure that runs all the algorithms as well as other tooling

364
00:23:31,960 --> 00:23:39,280
like, you know, job schedules and job sequencers, things that will handle data distribution.

365
00:23:39,280 --> 00:23:43,160
What they're doing is encapsulating all the things that are more computer sciencey in

366
00:23:43,160 --> 00:23:47,880
nature so that the data scientists don't need to worry about them as much, right.

367
00:23:47,880 --> 00:23:53,760
They can go focus most of their time on science and statistics and math and they don't

368
00:23:53,760 --> 00:24:00,400
need to know the innards of containerization, for example, or parallel processing.

369
00:24:00,400 --> 00:24:05,320
So that can be encapsulated for them so they can get back to working on science.

370
00:24:05,320 --> 00:24:08,080
And so that has been a wonderful compliment.

371
00:24:08,080 --> 00:24:11,080
And again, having them as part of the same team is key.

372
00:24:11,080 --> 00:24:14,600
That way they can adopt the same priorities and values.

373
00:24:14,600 --> 00:24:20,520
And we come up with a much better solution, sort of a mantra we use at Cishfix, an algorithms

374
00:24:20,520 --> 00:24:22,480
team is no handoffs.

375
00:24:22,480 --> 00:24:27,640
So we don't want to hand off things between teams and so we want to build and design the

376
00:24:27,640 --> 00:24:29,360
rules for autonomy.

377
00:24:29,360 --> 00:24:35,360
And so when you think about our algorithms platform, a lot of people mistakenly think, oh,

378
00:24:35,360 --> 00:24:36,360
you know, I get it.

379
00:24:36,360 --> 00:24:38,600
They're the data engineers that build the pipelines for the data scientists.

380
00:24:38,600 --> 00:24:39,600
Like, no, that's not true.

381
00:24:39,600 --> 00:24:41,840
They build the data platform.

382
00:24:41,840 --> 00:24:45,840
The data scientists have to build their own data pipelines, but they can run them on

383
00:24:45,840 --> 00:24:46,840
the platform.

384
00:24:46,840 --> 00:24:48,760
So it is a platform of a mature sense.

385
00:24:48,760 --> 00:24:50,080
And it's all homegrown.

386
00:24:50,080 --> 00:24:57,280
We're, of course, in the cloud and AWS and we've, you know, we've found as much as

387
00:24:57,280 --> 00:25:01,520
we can promote this community spark and all the usual players are in there.

388
00:25:01,520 --> 00:25:05,200
And then we've augmented with our own stuff as we've needed to.

389
00:25:05,200 --> 00:25:11,600
And so that was maybe a side door segue and they're talking about organizations and the

390
00:25:11,600 --> 00:25:19,840
way you organize data science, a part of that being have a team that supports them from

391
00:25:19,840 --> 00:25:22,080
a platform perspective.

392
00:25:22,080 --> 00:25:27,240
What are some of the other things that you've learned from an organizational perspective

393
00:25:27,240 --> 00:25:32,520
that have contributed to the success of the data science team there?

394
00:25:32,520 --> 00:25:37,160
Yeah, there's a few things that we've learned over the years.

395
00:25:37,160 --> 00:25:40,000
Roughly, I'll put them into three big buckets.

396
00:25:40,000 --> 00:25:44,720
They are have your own department, reporting to the CEO.

397
00:25:44,720 --> 00:25:51,880
Second, when it comes down to individual roles of the data scientist, we tend to leverage

398
00:25:51,880 --> 00:25:55,920
what we call data science generalist or full stack data scientist.

399
00:25:55,920 --> 00:26:03,320
And then finally is more of a statement about how process we prefer a more bottoms of

400
00:26:03,320 --> 00:26:05,520
approach versus central planning.

401
00:26:05,520 --> 00:26:07,480
So we can go into each of those.

402
00:26:07,480 --> 00:26:12,600
Let's start with our own department, reporting to the CEO.

403
00:26:12,600 --> 00:26:16,920
Now this isn't something I would say I would endorse for every company, but when data

404
00:26:16,920 --> 00:26:22,560
science is part of your competitive differentiation, then you want to take it seriously and give

405
00:26:22,560 --> 00:26:27,040
it its own department, reporting to the CEO, whatever your differentiation is, you want

406
00:26:27,040 --> 00:26:30,040
to make it its own department, reporting to the CEO.

407
00:26:30,040 --> 00:26:35,200
Because in that way, you get to develop your own tooling and workflows, ways of working

408
00:26:35,200 --> 00:26:36,200
right.

409
00:26:36,200 --> 00:26:38,880
Data science is not like any other field, right?

410
00:26:38,880 --> 00:26:39,880
It's not like engineering.

411
00:26:39,880 --> 00:26:41,600
It's not like marketing or product.

412
00:26:41,600 --> 00:26:43,920
It has its own way of working.

413
00:26:43,920 --> 00:26:49,280
The biggest distinction is that most of its capabilities when you design a data product

414
00:26:49,280 --> 00:26:52,520
or an algorithmic product, it usually can't be designed.

415
00:26:52,520 --> 00:26:56,160
Up front, it needs to be learned as you go.

416
00:26:56,160 --> 00:27:01,320
And this warrants a very different work style, and it's one that just doesn't fit into

417
00:27:01,320 --> 00:27:06,120
a lot of engineering workflows or marketing or others.

418
00:27:06,120 --> 00:27:10,200
And so if it's tucked, if you have your data science team tucked under a different department

419
00:27:10,200 --> 00:27:16,000
like that, it'll be forced to inherit the work style of the parent organization.

420
00:27:16,000 --> 00:27:18,760
And so that won't work for data science.

421
00:27:18,760 --> 00:27:22,600
I think it needs to have its own ethos and ways of working.

422
00:27:22,600 --> 00:27:24,840
And so you've got to make it its own.

423
00:27:24,840 --> 00:27:33,200
Now, to be clear, when you say these projects need to be learned, we're not talking strictly

424
00:27:33,200 --> 00:27:34,200
about machine learning.

425
00:27:34,200 --> 00:27:37,040
We're talking about learning in the broader sense.

426
00:27:37,040 --> 00:27:38,040
Is that right?

427
00:27:38,040 --> 00:27:39,040
That's correct.

428
00:27:39,040 --> 00:27:43,320
I mean, even inherent to machine learning, there is uncertainty, right?

429
00:27:43,320 --> 00:27:44,840
You don't know if this thing's going to work or not.

430
00:27:44,840 --> 00:27:48,720
You may think, well, gosh, it'd be great if we can develop an algorithm to do whatever

431
00:27:48,720 --> 00:27:53,400
and you may find that at least what the data you have, there's no predicted power.

432
00:27:53,400 --> 00:27:56,400
So it's not going to help, right?

433
00:27:56,400 --> 00:27:57,960
So that does happen.

434
00:27:57,960 --> 00:28:02,080
But even when you have success, you found predictive capabilities within your data and

435
00:28:02,080 --> 00:28:05,240
you start to build your algorithm.

436
00:28:05,240 --> 00:28:10,000
Oftentimes, each individual parameter or even the type of model or even the hyper parameters

437
00:28:10,000 --> 00:28:12,320
that all need to be learned, right?

438
00:28:12,320 --> 00:28:14,200
You can't design them up front.

439
00:28:14,200 --> 00:28:19,840
You get any to try things in the data and see what it tells you and then iterate and

440
00:28:19,840 --> 00:28:20,840
go back.

441
00:28:20,840 --> 00:28:26,000
Often, there's a lot of feature engineering that is done through trial and error.

442
00:28:26,000 --> 00:28:32,600
Like you make your best attempt in your first pass and then you learn something by looking

443
00:28:32,600 --> 00:28:37,400
at the results of trying that feature in a model and you're saying, wow, it must be

444
00:28:37,400 --> 00:28:39,920
something different than I had originally thought.

445
00:28:39,920 --> 00:28:43,360
I'm going to try it this way now and you keep going and iterating.

446
00:28:43,360 --> 00:28:46,280
And then you usually find a bunch that doesn't know the things that you didn't anticipate

447
00:28:46,280 --> 00:28:48,760
trying at all in the process, right?

448
00:28:48,760 --> 00:28:54,040
So it's a heavy iterative process to develop an algorithm.

449
00:28:54,040 --> 00:28:57,280
It's not something that you spec out and hand off to somebody else.

450
00:28:57,280 --> 00:28:58,280
It's a, here you go.

451
00:28:58,280 --> 00:28:59,280
Here's your algorithm.

452
00:28:59,280 --> 00:29:00,280
I'll just go implement it.

453
00:29:00,280 --> 00:29:03,920
Now, you have to kind of learn it as you go.

454
00:29:03,920 --> 00:29:08,560
And so this is something that when you have a property like that where it can't be designed

455
00:29:08,560 --> 00:29:13,320
up front, then you're going to want to organize very differently and that's where

456
00:29:13,320 --> 00:29:17,720
we get into that full stack data scientist.

457
00:29:17,720 --> 00:29:24,840
The full stack data science thing is a, you know, it's sort of a, it's a generous role

458
00:29:24,840 --> 00:29:30,440
as opposed to way a lot of other companies are doing things specializing their data science

459
00:29:30,440 --> 00:29:31,440
teams.

460
00:29:31,440 --> 00:29:37,560
We got like data engineering or ML engineering or inference engineer or research scientist

461
00:29:37,560 --> 00:29:45,200
and each plays a smaller part and a big collection of capability where all those things need

462
00:29:45,200 --> 00:29:47,720
to come together as a single capability.

463
00:29:47,720 --> 00:29:51,960
But you got the different pieces farmed out to different specialists and it, we do that

464
00:29:51,960 --> 00:29:53,800
because it makes a lot of sense to us.

465
00:29:53,800 --> 00:30:00,160
We learned from Adam Smith and we were taught that, oh, you know, we get these process efficiencies

466
00:30:00,160 --> 00:30:03,560
due to the division of labor and it sounds really good.

467
00:30:03,560 --> 00:30:07,280
But how many works when you know exactly what it is you're building, right?

468
00:30:07,280 --> 00:30:11,680
And you have specs that are crystal clear down to the millimeter of precision, then you

469
00:30:11,680 --> 00:30:13,640
can divide and conquer like that.

470
00:30:13,640 --> 00:30:18,120
But when you need to learn as you go, you have to rely on iteration and the challenge

471
00:30:18,120 --> 00:30:21,680
with specialists is they have a high coordination cost.

472
00:30:21,680 --> 00:30:25,600
It's a lot more expensive to coordinate in multiple people than it is just one.

473
00:30:25,600 --> 00:30:30,360
Even worse, even more nefarious than those coordination costs are a wait times.

474
00:30:30,360 --> 00:30:32,480
This is the time in between work.

475
00:30:32,480 --> 00:30:37,920
So let's suppose you have a data engineer that builds a new data pipeline and, you know,

476
00:30:37,920 --> 00:30:43,400
maybe a research scientist is now going to construct a model from that data.

477
00:30:43,400 --> 00:30:47,920
And the research scientist says, well, she discovers that, oh, she needs a few more features

478
00:30:47,920 --> 00:30:49,920
that are not manifest in the data.

479
00:30:49,920 --> 00:30:53,720
So she goes back to the data engineers and you add these things in.

480
00:30:53,720 --> 00:30:57,200
Data engineer says, yes, I can, but I'm busy on a different project right now.

481
00:30:57,200 --> 00:30:59,360
I'll get back to you next week.

482
00:30:59,360 --> 00:31:05,920
And so a week goes by and it may have only been a few hours of work to add the new features,

483
00:31:05,920 --> 00:31:07,320
but a week goes by.

484
00:31:07,320 --> 00:31:11,960
So that's a week of wait time for what is just a few hours of work.

485
00:31:11,960 --> 00:31:13,640
And that is expensive.

486
00:31:13,640 --> 00:31:18,720
And that's the cost of specialization is you're coordinating these disparate resources that

487
00:31:18,720 --> 00:31:24,040
all work on other projects because they're specialists and you end up with long gaps in

488
00:31:24,040 --> 00:31:25,560
between the work.

489
00:31:25,560 --> 00:31:31,040
And it's very costly, especially when you benefit so much from learning and iteration.

490
00:31:31,040 --> 00:31:35,280
So that's the reason we don't do the data science specialist roles instead.

491
00:31:35,280 --> 00:31:41,280
We do the full stack data scientists that can take the initiative from conception, you

492
00:31:41,280 --> 00:31:46,120
know, coming up with the idea and framing the problem to doing the modeling, to doing

493
00:31:46,120 --> 00:31:50,440
the data engineering, to even putting it in production.

494
00:31:50,440 --> 00:31:55,080
One person to or one are very few people to go through all those steps.

495
00:31:55,080 --> 00:32:00,520
We find is a lot more effective than dealing with other coordination costs than wait times.

496
00:32:00,520 --> 00:32:11,200
One of the perhaps most prominent trends in organizing data science efforts, and you spoke

497
00:32:11,200 --> 00:32:16,320
to this, but is that aspect of specialization?

498
00:32:16,320 --> 00:32:22,440
I feel like, you know, when we first started talking about this, whatever, 10 years ago,

499
00:32:22,440 --> 00:32:27,360
someone was looking for kind of this unicorn data scientist, and maybe you can talk about

500
00:32:27,360 --> 00:32:32,000
if that's the same or different than a full stack data scientist, but everyone was looking

501
00:32:32,000 --> 00:32:38,160
for this unicorn that knew the business, knew the stats, knew how to code.

502
00:32:38,160 --> 00:32:44,480
And in a lot of ways, I think part of the progress that we've made is splitting out these skill

503
00:32:44,480 --> 00:32:54,560
sets and allowing for some of that specialization so that, you know, we don't have to find these

504
00:32:54,560 --> 00:33:01,840
kind of Swiss Army knife ninja, whatever's that can do everything.

505
00:33:01,840 --> 00:33:07,360
And as the most recent element of that, you know, we've seen the, you know, for the past

506
00:33:07,360 --> 00:33:15,080
two years, this role of machine learning engineer has really kind of taken off.

507
00:33:15,080 --> 00:33:19,360
And that is someone that kind of knows the machine learning stuff, you know, well not

508
00:33:19,360 --> 00:33:26,240
as much as maybe a research scientist or someone, or not as deeply as a research scientist

509
00:33:26,240 --> 00:33:31,160
or someone that has, you know, the statistical background, but knows how to build systems

510
00:33:31,160 --> 00:33:37,640
with it and can also code, you know, in a production ready way.

511
00:33:37,640 --> 00:33:44,280
And you know, that seems to have driven a lot of the scale at some of the companies that

512
00:33:44,280 --> 00:33:48,160
are really heavily invested in machine learning and data science.

513
00:33:48,160 --> 00:33:53,840
And I'm wondering are there things that you, in particular that you kind of attribute

514
00:33:53,840 --> 00:33:55,360
your different way of seeing things?

515
00:33:55,360 --> 00:34:00,480
Is it an issue of scale or your team smaller than, you know, the teams at some of the companies

516
00:34:00,480 --> 00:34:06,960
that are taking a more specialized approach or, you know, is it just a fundamentally different

517
00:34:06,960 --> 00:34:10,960
way of looking at kind of the efficiencies of an organization?

518
00:34:10,960 --> 00:34:11,960
Yeah.

519
00:34:11,960 --> 00:34:15,200
Well, first of all, yes, your unicorn analogy is correct.

520
00:34:15,200 --> 00:34:17,400
Those are the type of people we look for.

521
00:34:17,400 --> 00:34:21,320
They can, you know, frame the problems, have enough business context and speak business

522
00:34:21,320 --> 00:34:29,600
enough to be credible, but also do the math and the statistics to build and select models

523
00:34:29,600 --> 00:34:33,080
and train models, but also put them into production, right?

524
00:34:33,080 --> 00:34:37,320
We don't like handoffs between those rules, because it slows us down.

525
00:34:37,320 --> 00:34:42,000
So we do hire unicorns, now we've been adding that unicorns do exist.

526
00:34:42,000 --> 00:34:44,040
It's just that they're a little horn.

527
00:34:44,040 --> 00:34:50,640
It's not always visible in early stages development, you can train people, right?

528
00:34:50,640 --> 00:34:56,880
So we can hire folks, very smart folks, that are willing to learn these things.

529
00:34:56,880 --> 00:34:59,520
And it's sort of a trait that we look for.

530
00:34:59,520 --> 00:35:04,760
It's a tough one to really identify in interviews, but you can pull out of them in clever ways,

531
00:35:04,760 --> 00:35:09,560
asking them about a time where they've had to go way outside of their, you know, purview

532
00:35:09,560 --> 00:35:10,560
to get something done.

533
00:35:10,560 --> 00:35:11,560
And we look for that.

534
00:35:11,560 --> 00:35:17,760
We've hired a lot of physicists, for example, that have gone way outside of their purview

535
00:35:17,760 --> 00:35:18,760
to get something done.

536
00:35:18,760 --> 00:35:24,280
You know, they might have to go their job is to, you know, get satellite imagery.

537
00:35:24,280 --> 00:35:30,440
And because they didn't have any, you know, support to process the data, they took it upon

538
00:35:30,440 --> 00:35:36,640
themselves to build structures and packages to make the processing more efficient.

539
00:35:36,640 --> 00:35:42,840
Or because, you know, they needed to more machines than their organization was providing

540
00:35:42,840 --> 00:35:43,840
them with.

541
00:35:43,840 --> 00:35:46,840
They took it upon themselves to go get into the cloud and provision their own machines,

542
00:35:46,840 --> 00:35:47,840
right?

543
00:35:47,840 --> 00:35:51,080
So these are examples of folks that will do whatever it takes to get that thing up and

544
00:35:51,080 --> 00:35:52,080
running.

545
00:35:52,080 --> 00:35:56,400
And that's what we look for, and that's what we provide them with all the tools that

546
00:35:56,400 --> 00:36:01,120
they need to be effective at doing an end-to-end solution.

547
00:36:01,120 --> 00:36:03,400
Now we're not crazy here.

548
00:36:03,400 --> 00:36:07,320
We do know that there are boundary conditions to this, and we're well aware of them.

549
00:36:07,320 --> 00:36:10,000
We do benefit from a few things at StitchFix.

550
00:36:10,000 --> 00:36:13,000
Number one, our data is not particularly among us.

551
00:36:13,000 --> 00:36:16,280
We deal with terabytes of data, not pediments.

552
00:36:16,280 --> 00:36:23,080
And this makes it much more feasible to have these unicorn types do, you know, code well

553
00:36:23,080 --> 00:36:30,200
enough to, you know, do their own data pipelines, as well as implement them in a production

554
00:36:30,200 --> 00:36:31,920
framework, et cetera.

555
00:36:31,920 --> 00:36:36,640
Now if there is a point where the data gets so big that you really need to get highly

556
00:36:36,640 --> 00:36:41,400
specialized, you know, you can no longer do this stuff in Python, you have to resort to

557
00:36:41,400 --> 00:36:48,520
C++ or heavily typed languages where the processing could be a lot more efficient.

558
00:36:48,520 --> 00:36:49,880
We're not in that place.

559
00:36:49,880 --> 00:36:55,120
We deal with terabytes, not pedabytes, and so we can get away with this for that reason.

560
00:36:55,120 --> 00:36:58,680
That's the data volume effect.

561
00:36:58,680 --> 00:37:02,920
The other thing we benefit is availability requirements.

562
00:37:02,920 --> 00:37:04,240
So we do have the gamut.

563
00:37:04,240 --> 00:37:08,560
We do have some algorithms that are extremely highly available, or need to be extremely

564
00:37:08,560 --> 00:37:12,880
highly available, very high SLAs.

565
00:37:12,880 --> 00:37:20,120
Others are low availability, meaning they're, like I described earlier, a buying algorithm

566
00:37:20,120 --> 00:37:28,200
on our middle, go and purchase, or, you know, give out a buy sheet of what to go buy.

567
00:37:28,200 --> 00:37:33,440
And that algorithm does not need to be nearly as highly available, because it's only used

568
00:37:33,440 --> 00:37:36,360
internally by about 30 merchants, right?

569
00:37:36,360 --> 00:37:42,160
So it spits out their buy sheets for them, and that one, you know, it could break, and

570
00:37:42,160 --> 00:37:46,840
our algorithm developer can send out a note to the 30 people and says, hey, I'm on it,

571
00:37:46,840 --> 00:37:49,840
it'll be back up and running in an hour, and that's fine.

572
00:37:49,840 --> 00:37:55,200
So that, in that scenario, it's a much lower availability requirement, and it allows us

573
00:37:55,200 --> 00:38:01,520
to be, to make judgment calls on, you know, the level of support we need, it needs to provide.

574
00:38:01,520 --> 00:38:05,080
So those are two examples of boundary conditions.

575
00:38:05,080 --> 00:38:10,120
Okay, our data is not that big, that you need specialization, nor is it, in some cases,

576
00:38:10,120 --> 00:38:14,120
need to be so highly available that it can never fail, right?

577
00:38:14,120 --> 00:38:20,080
You have different engineering requirements based on those parameters.

578
00:38:20,080 --> 00:38:21,880
And so it allows us to do things different.

579
00:38:21,880 --> 00:38:27,800
We also, oftentimes, don't have the same consequences as other companies were, I mentioned

580
00:38:27,800 --> 00:38:33,120
our styling, our rhythm is pretty sensitive to failures, we don't want to get that one

581
00:38:33,120 --> 00:38:34,120
wrong.

582
00:38:34,120 --> 00:38:36,360
But failures are not so bad.

583
00:38:36,360 --> 00:38:42,400
You know, in fact, I would say, we would do things differently if we were in manufacturing

584
00:38:42,400 --> 00:38:43,720
or medical.

585
00:38:43,720 --> 00:38:49,240
In those two domains, you want to be far more buttoned up, you don't want to do the

586
00:38:49,240 --> 00:38:52,160
amount of risk taking that we do with our algorithms.

587
00:38:52,160 --> 00:38:56,440
In those areas, you need to be ironclad because the cost of getting something wrong, it

588
00:38:56,440 --> 00:38:58,840
could be devastating to the company.

589
00:38:58,840 --> 00:39:04,480
So we're aware of these boundary conditions, and I think that's a key message to get

590
00:39:04,480 --> 00:39:08,920
out there is you want to do what's appropriate for your environment.

591
00:39:08,920 --> 00:39:14,120
And for us, we found that, given those different requirements, we don't need to be as highly

592
00:39:14,120 --> 00:39:18,400
available in some cases, and we don't have as big a data in some cases, and we don't

593
00:39:18,400 --> 00:39:21,880
have the big consequences in other cases.

594
00:39:21,880 --> 00:39:28,480
And so that means we can get by with doing things and a more generalist model, which allows

595
00:39:28,480 --> 00:39:31,760
us to innovate much faster.

596
00:39:31,760 --> 00:39:35,560
The good side of generalist roles is you can innovate much faster, you can try things

597
00:39:35,560 --> 00:39:40,240
much quicker, you can tail quicker, and also lead to successes quicker.

598
00:39:40,240 --> 00:39:42,400
And it also leads to very fulfilling roles.

599
00:39:42,400 --> 00:39:46,560
There's nothing more satisfying than owning something from end to end.

600
00:39:46,560 --> 00:39:51,720
It gives you the three properties of job satisfaction that Dan Ping talks about in his book

601
00:39:51,720 --> 00:39:52,720
drive.

602
00:39:52,720 --> 00:39:56,280
You get autonomy because you are no longer depending on something else for success.

603
00:39:56,280 --> 00:40:01,680
You get mastery because you know this thing from end to end and you get purpose or impact.

604
00:40:01,680 --> 00:40:05,880
You get to impact the company in a very measurable way.

605
00:40:05,880 --> 00:40:11,800
And all those three things combine to make it one sweet role in data science and statistics.

606
00:40:11,800 --> 00:40:19,960
And you mentioned you've got this platform's team that is part of the algorithms organization.

607
00:40:19,960 --> 00:40:25,880
Is that team staff with the same type of generalist could they swap out and take the

608
00:40:25,880 --> 00:40:36,480
place of one of the algorithms folks that's working on a modeling problem in vice versa?

609
00:40:36,480 --> 00:40:43,720
Less so why there is that is a more clear distinction and skill set.

610
00:40:43,720 --> 00:40:50,760
I would say that our algorithms platform team it tends to be much better computer scientist

611
00:40:50,760 --> 00:40:56,760
than our data science side of the house which tend to be in you know some of the sciences

612
00:40:56,760 --> 00:41:02,280
either statistics or math or even neuroscience or some of the physics domains.

613
00:41:02,280 --> 00:41:05,280
But they usually don't come from a computer science background.

614
00:41:05,280 --> 00:41:08,440
And that's why they're very complimentary as well you know one team is building all the

615
00:41:08,440 --> 00:41:12,880
tooling to enable data scientists to not have to worry about the internet.

616
00:41:12,880 --> 00:41:14,440
And so there is a bit of a distinction there.

617
00:41:14,440 --> 00:41:20,720
Now happily we've had some migration between the groups and to our surprise it's more

618
00:41:20,720 --> 00:41:27,240
or so from the data science side to the data platform or our own platform side.

619
00:41:27,240 --> 00:41:30,160
We thought that there would be the other way.

620
00:41:30,160 --> 00:41:35,160
It seems like everybody wants to be a data scientist these days and less an out a platform

621
00:41:35,160 --> 00:41:36,160
developer.

622
00:41:36,160 --> 00:41:40,160
But happily we found the office that we've had more migration the other way.

623
00:41:40,160 --> 00:41:44,640
Now not everyone can transition back and forth I think there has to be you know a little

624
00:41:44,640 --> 00:41:49,440
bit of skills that people either have picked up or have been classically trained you know

625
00:41:49,440 --> 00:41:54,240
computer science is one of those things where I think it matters that you get some real

626
00:41:54,240 --> 00:42:01,080
training real academic training not just hack your way into things it can really matter

627
00:42:01,080 --> 00:42:03,680
and the way you design and write code.

628
00:42:03,680 --> 00:42:10,360
But happily it's we've had some malleability across those two pieces of the team.

629
00:42:10,360 --> 00:42:18,160
But I guess the key distinction is that typically the data scientist that's working on a problem

630
00:42:18,160 --> 00:42:22,280
isn't waiting for platform features or capabilities there.

631
00:42:22,280 --> 00:42:27,600
The platform team is outside of that innovation loop for getting projects done.

632
00:42:27,600 --> 00:42:28,600
That's right.

633
00:42:28,600 --> 00:42:34,200
There's no handoffs between the teams right you're not going to data scientists isn't going

634
00:42:34,200 --> 00:42:39,720
to go to a data platform engineer and say here's what I need from you right that data

635
00:42:39,720 --> 00:42:44,200
rather than the short term hopefully there's some long term communication there.

636
00:42:44,200 --> 00:42:48,560
Long term what happens actually is it's the data platform that figured out what needs

637
00:42:48,560 --> 00:42:49,560
to be built.

638
00:42:49,560 --> 00:42:52,160
They build all the things that aren't asked for.

639
00:42:52,160 --> 00:42:57,040
So nobody asked for you know a containerization package they just realized you know that's

640
00:42:57,040 --> 00:43:00,440
probably hard for the data scientists to do that we should do that for them.

641
00:43:00,440 --> 00:43:05,600
Well nobody asked for you know a distributed processing engine you know the data platform

642
00:43:05,600 --> 00:43:09,320
folks just observed the yeah the running of some issues let's take care of that for

643
00:43:09,320 --> 00:43:10,320
them right.

644
00:43:10,320 --> 00:43:16,480
They do all these wonderful things by just being good listeners good observers and build

645
00:43:16,480 --> 00:43:19,720
what's not asked for but it's desperately going to be needed.

646
00:43:19,720 --> 00:43:25,440
And so that's how things get done is we just keep people very closely working together.

647
00:43:25,440 --> 00:43:31,360
They do have some different seal sets and they watch for where they can add value.

648
00:43:31,360 --> 00:43:37,680
And so you talked about three kind of characteristics that the way you organize and we've touched

649
00:43:37,680 --> 00:43:44,480
on two of them the third is around kind of supporting emergent behaviors in the organization

650
00:43:44,480 --> 00:43:45,480
what does that mean.

651
00:43:45,480 --> 00:43:52,600
Yeah so you know I mentioned we have several dozen algorithmic capabilities and I can only

652
00:43:52,600 --> 00:43:58,600
think of one of them that was actually asked for all the others were emergent meaning

653
00:43:58,600 --> 00:44:01,720
they came from data science tinkering.

654
00:44:01,720 --> 00:44:06,120
So what that means is we have data scientists and we hire them to do something they have

655
00:44:06,120 --> 00:44:09,840
some stated priorities and they'll be working on that stuff.

656
00:44:09,840 --> 00:44:14,280
And along the way they'll come across some data that was curious or interesting to them

657
00:44:14,280 --> 00:44:16,560
you know not what they're supposed to be doing but they stumble and say I wonder why

658
00:44:16,560 --> 00:44:18,920
that turned out to be as big as it was.

659
00:44:18,920 --> 00:44:23,680
And they might follow that path and go explore it and then so doing they might trip across

660
00:44:23,680 --> 00:44:29,840
some unexplained phenomenon and it leads to the development of a new capability you know

661
00:44:29,840 --> 00:44:33,560
just at nobody asked them to do it just curiosity ensued.

662
00:44:33,560 --> 00:44:38,800
And the next thing you know they've discovered you know the next capability that we're going

663
00:44:38,800 --> 00:44:40,440
to be leveraging.

664
00:44:40,440 --> 00:44:49,960
In example being we have somebody named Dara he was working on these purchasing algorithms

665
00:44:49,960 --> 00:44:54,240
and as a side project he sort of tinkered and he said I wonder if I could use an algorithm

666
00:44:54,240 --> 00:44:56,440
to design clothing.

667
00:44:56,440 --> 00:45:01,640
And so then he started tinkering and figured out that this looks pretty good that if he

668
00:45:01,640 --> 00:45:07,400
used this form of genetic algorithm he can recombine old styles together in new ways

669
00:45:07,400 --> 00:45:11,120
that nobody's ever seen before to create something new.

670
00:45:11,120 --> 00:45:16,440
And you know we're all kind of skeptical of it but the nice thing with data is it comes

671
00:45:16,440 --> 00:45:17,440
with evidence.

672
00:45:17,440 --> 00:45:22,080
These aren't just opinionated ideas they come with evidence right.

673
00:45:22,080 --> 00:45:25,920
So by the time he's coming to talk to us about it he's already proven it out to you

674
00:45:25,920 --> 00:45:31,560
know for the most part you know we have measures and statistics like AUC and RMSC

675
00:45:31,560 --> 00:45:35,560
that kind of tell us we're on the right path this has predictive value and then the next

676
00:45:35,560 --> 00:45:41,240
that might be to try it out in real life you know try it out on the AV test on real clients

677
00:45:41,240 --> 00:45:46,400
and that'll you know either validate or reject your earlier evidence and then from that

678
00:45:46,400 --> 00:45:50,680
point it becomes really easy back to that part where I call it a no-brainer it's already

679
00:45:50,680 --> 00:45:55,120
been built so there's no cost to build it and you have evidence of the impact it'll have

680
00:45:55,120 --> 00:45:58,920
once you launch it live and so usually it just kind of goes right into production from

681
00:45:58,920 --> 00:45:59,920
that.

682
00:45:59,920 --> 00:46:04,160
What I described there was an example of a success of course there's failures we have

683
00:46:04,160 --> 00:46:09,720
lots of failures in fact they they outnumber the successes by some magnitude I don't know

684
00:46:09,720 --> 00:46:13,760
if it's three to one or five one we've never really kept track but the thing is they're

685
00:46:13,760 --> 00:46:18,640
very low cost they fail and he probably not even think to tell anybody about it because

686
00:46:18,640 --> 00:46:22,600
you just tried some curiosity thing anytime I didn't go anywhere you shut it down you move

687
00:46:22,600 --> 00:46:29,040
on and that's the beauty I've learned of these data products is they're extremely low

688
00:46:29,040 --> 00:46:34,240
cost to explore and yet they come with this evidence that show when you're on the right

689
00:46:34,240 --> 00:46:38,680
path and then you can easily even build and productionize them for barely you know cheap

690
00:46:38,680 --> 00:46:44,240
they don't take a lot of upfront cost it's just somebody's tinkering and then you can

691
00:46:44,240 --> 00:46:50,480
try them out you know an AV test that really get the true measure and then you know push

692
00:46:50,480 --> 00:46:57,200
it live to the rest of the company if it really holds up and so low cost exploration

693
00:46:57,200 --> 00:47:03,520
with evidence and then the last little bit that I think is an important thing is these asymmetric

694
00:47:03,520 --> 00:47:08,560
outcomes right to cost the failures small the costs are the benefits of success are big

695
00:47:08,560 --> 00:47:15,840
and so you can have that sort of losing ratio you might have you know three to one failures

696
00:47:15,840 --> 00:47:22,520
to success rate and the one success will pay for all the failures and it's a way to really

697
00:47:22,520 --> 00:47:28,680
kind of endorse innovation and foster rich in your organization is to you know those three

698
00:47:28,680 --> 00:47:34,840
properties of low cost exploration evidence of their efficacy and asymmetric outcomes.

699
00:47:34,840 --> 00:47:41,400
And so to maybe wrap things up you know much of the way you've talked about these organizational

700
00:47:41,400 --> 00:47:49,800
principles is unconventional in the well I don't yeah it's even unconventional the right word

701
00:47:49,800 --> 00:47:55,800
here in the sense of all the stuff is new and I don't know that there's necessarily a convention

702
00:47:55,800 --> 00:48:04,440
but it's it certainly goes against the direction that things are headed you know if someone

703
00:48:04,440 --> 00:48:14,200
out there has heard what you are describing and is in or runs an organization that is not organized

704
00:48:14,200 --> 00:48:21,240
like this at all but is kind of interested in these ideas any advice for them. Yeah you really

705
00:48:21,240 --> 00:48:30,360
got to be thoughtful about your environment you know no way of working is necessarily better than

706
00:48:30,360 --> 00:48:37,160
any other it has to be a good fit for your environment and so you know even what we've done here

707
00:48:37,160 --> 00:48:41,720
it's districts if we didn't do this from the beginning I'm not sure it would have been

708
00:48:41,720 --> 00:48:47,960
the company would have been as amenable to it right we were you know here from the very beginning

709
00:48:47,960 --> 00:48:53,000
we established some of these ways of working and then we had a lot of successes to build on and I

710
00:48:53,000 --> 00:48:59,560
think that's what allowed us to pave the way to learn and foster the parts that worked and get rid

711
00:48:59,560 --> 00:49:06,120
of the parts that didn't work so well so we have to be very reflective on that like you have to

712
00:49:06,120 --> 00:49:12,520
figure out well why is there friction when we try to do this and why is there you know resistance

713
00:49:12,520 --> 00:49:16,600
when we try to do this other way and figure out what it is is going on you know it's kind of like

714
00:49:16,600 --> 00:49:22,920
the study of incentives within an organization figure out what works so you need to do the right

715
00:49:22,920 --> 00:49:27,880
thing for your environment is one thing and then be aware of those boundary conditions right that

716
00:49:27,880 --> 00:49:34,200
I mentioned you know we can are able to do this for you know various reasons of our data is not

717
00:49:34,200 --> 00:49:39,800
big we don't have in most cases the availability requirements etc so you have to really be thoughtful

718
00:49:39,800 --> 00:49:46,760
about this and figure out you know we've spent significant time on this debating and a

719
00:49:46,760 --> 00:49:53,720
entire day off sites just to talk about org structure and process and the main credit I will give

720
00:49:53,720 --> 00:50:00,040
us is we didn't do the default thing we didn't just say well let's do it we did our last companies

721
00:50:00,040 --> 00:50:05,800
in fact I explicitly came to stitch fix partially for that reason I mentioned all that all my

722
00:50:05,800 --> 00:50:11,000
rational for joining but there was one other nice thing and that was that I'd made a lot of

723
00:50:11,000 --> 00:50:16,680
mistakes in my press career at Netflix and Yahoo or you know they weren't really mistakes until

724
00:50:16,680 --> 00:50:22,200
hindsight gave me the clarity I needed I looked back and said gosh if I could start over I would

725
00:50:22,200 --> 00:50:27,240
do things differently at all these companies and sometimes it's hard to start over at your existing

726
00:50:27,240 --> 00:50:33,960
place because you just have a lot of legacy code you need to support and so forth but I remember

727
00:50:33,960 --> 00:50:39,320
that when I went to stitch fix I said wow I have a clean slate right now I'm going to leverage

728
00:50:39,320 --> 00:50:44,760
everything I learned in my career and do this very intentionally from the beginning and set up

729
00:50:44,760 --> 00:50:49,320
all the stuff that I thought would always be a good idea that I learned only learned you know

730
00:50:49,320 --> 00:50:55,000
three years of experience and so that thoughtfulness I think is what brought on a lot of this and

731
00:50:55,000 --> 00:51:01,080
again not I couldn't claim to have foreseen everything that we've done it was just a matter of

732
00:51:01,080 --> 00:51:06,120
keeping our eyes open and keep you know a good group of people that I was fortunate enough to

733
00:51:06,120 --> 00:51:12,680
hire and have them to debate things with and you know collaborate with on setting up the right

734
00:51:12,680 --> 00:51:18,040
structures and incentives to do this you know way there was a hundred percent appropriate for our

735
00:51:18,040 --> 00:51:23,640
environment and I think that paid off pretty well so don't ever underestimate the amount of

736
00:51:23,640 --> 00:51:29,000
thought and work it takes it takes to put something like this together and don't accept the defaults

737
00:51:29,000 --> 00:51:34,120
don't just do it like you did at your last company do it intentionally correct for your environment

738
00:51:34,120 --> 00:51:39,640
well Eric thanks so much for taking the time to chat with me about what you've been up to

739
00:51:41,400 --> 00:51:46,040
I think there are really some interesting learnings in here for folks that are on their own

740
00:51:46,040 --> 00:51:53,080
processes of or their own paths of organizing for data science sounds good well thanks for having

741
00:51:53,080 --> 00:52:01,880
me on it's been fun all right everyone that's our show for today if you like what you've heard

742
00:52:01,880 --> 00:52:07,640
here please do us a favor and tell your friends about the show and if you haven't already

743
00:52:07,640 --> 00:52:12,680
hit the subscribe button yourself make sure to do so so you won't miss any of the great episodes

744
00:52:12,680 --> 00:52:18,040
we've got in store for you for more information on any of the shows in our strata data series

745
00:52:18,040 --> 00:52:25,400
visit twomolei.com slash strata sf19 thanks once again to cloud error for sponsoring this series

746
00:52:25,400 --> 00:52:32,120
be sure to check them out at cloud error.com slash ml as always thanks so much for listening

747
00:52:32,120 --> 00:52:49,400
and catch you next time

