It's hard to believe, but this is the last podcast episode you will hear before I kick off our inaugural
Twimmelcon conference on Tuesday morning with my on-stage interviews with Anjuang,
co-founder of Landing AI and Coursera, and Deepak Agarwal, vice-president of artificial intelligence at LinkedIn.
This has shaped up to be an incredible event with speakers from Airbnb,
capital-1, Facebook, Levi Strauss, Stripe, SurveyMonkey, Twitter, Uber, and many more companies,
all detailing how they're moving ML and AI out of the lab and driving real value by accelerating,
automating, and scaling their ability to get models into production.
It is not too late to join us.
Register for Twimmelcon today using the code I Want In for 20% off of registration
and a ticket to the hottest enterprise machine learning conference of the year.
Hope to see you there.
All right, everyone. I am on the line with Alex Bann. Alex is a professor of electrical
engineering and computer science at UC Berkeley. Alex, welcome to this weekend machine learning
in AI. Hi, good morning. Thank you for having me. It's fun to be here today.
I am actually in Las Vegas, but you are no longer in Las Vegas, but the thing that
kind of brings us together is you were recently speaking at the AI summit that Amazon put together
here at the reinvent conference. We're going to dig into your presentation, but before we do,
I'd love to hear a little bit about your background and how you got involved in machine learning.
While I was a control theorist by training, which means essentially learning how to
build algorithms to control machines, to control processes, to control robots,
and it's a discipline which is fairly optimization based that finds its roots in the 90s.
And so with the current revolution we are experiencing in AI and machine learning,
I think it became almost obvious that all these fields are progressively merging.
So you think about robotics, about perception and action, optimization, control.
It's all becoming one. And so like many others in this field, I was drawn to it because it provided
a lot of opportunities for new breakthroughs and revisiting all the problems with new techniques
that will clearly advance the field. Great. And so what are your research interests?
So I'm interested in two topics which are interconnected. The first one is the large-scale
impacts of traffic routing apps. When it happens with many, many people use the same apps on the road,
what it does to mobility at super large scale. And then the second topic, which probably is the
topic we're going to talk most today, is the notion of mixed autonomy. What do you do if you have
self-driving vehicles or vehicles with some level of automation interact with manned vehicles?
Your car, my car, car driven by human. And so these two interact because if you think about mobility,
mobility obviously has a lot of large scale aspects. How do you solve the traffic jams in LA?
But mobility also has a lot of local aspects. How do you make traffic flow more efficiently at
a local level? How do you manage an intersection better? How you smooth traffic on the freeway
and so on and so forth? And both of these scales are deeply impacted by machine learning and AI
these days. Interesting. So I'm originally from New York and my wife will on occasion
remind me that I am also a New York driver to her that has a very particular meaning.
But not long ago, there was some research. Actually, it was long ago. Many years ago, I came across
some research study that said that a single aggressive driver can dramatically improve
traffic flow on a highway. And I've always kind of presented her with that fact when she kind of
says that I'm doing this New York driving thing. And I've more recently seen some research that
talks about kind of applies the same idea to autonomous vehicles. Like a single or small number
of autonomous vehicles can also dramatically improve traffic flow. Is that the kind of thing that
you look at near research? Totally. And we must be cousins because I'm a Paris driver. So I think
we share a lot of things in common here. But yeah, no, totally. So it's interesting. In fact,
what you're saying is so true. I would say a single driver can affect traffic very positively
and very negatively. And obviously with self-driving features that are coming on board vehicles,
we're trying to really steer the system towards the better. But we'll have been in a case where
someone does something really strange and it creates some breakdown. It creates a shock wave.
It creates some congestion. It creates some strange phenomenon on the freeway that we did not
anticipate. That happens every day. What we're trying to do here is, in fact, the opposite, which is
trying to understand how the level of automation that is progressively entering the vehicles
could be used to essentially improve things. Whether it's aggressive or not, it's almost a
technicality. But it's more to do something that a human might not necessarily think to do,
but that is actually proven to improve things. And I think the most counter-intuitive things nowadays
in self-driving vehicles is that slowing down in some circumstances might actually improve
traffic flow. Now, it's something that people in 2018 might have a difficult time to conceive.
But it's not that different that maybe 50 years ago when someone came up, or maybe 80 years ago,
when someone came up with a traffic light which had a red as a color and that meant you have to stop,
maybe people didn't realize right away. Well, actually, that will make traffic better because
traffic lights are better than stop signs or unmanaged intersections. What's exactly the same
with self-driving vehicles? It's just not in our culture yet. It's not even in our DNA yet.
But the very same thing we've done with ramped metering or coordinated traffic light signals
in cities in New York, obviously, is one of them. That can also be applied at the level of cars
on the freeways. In fact, it's something that is known and has been known by truckers for a while
because truckers are known to be flow pacifiers. They all maintain a given speed. They usually go on
the same lane. That lane really doesn't have many breakdowns. It's a very smooth lane. So it's
something which has been known in some quote subcommunities of motorists, if you will, over the years.
But that's something that with the self-driving features we see coming into cars is going to become
a reality of our future driving life and have really great potential to make things much better.
That's what we're doing. We're trying to understand how AI can help solve that problem and how can
AI provide solutions which are really innovative in the way we look at that problem?
It makes me think a little bit about the concept of swarming behaviors.
In particular, the idea that you can have these individual agents that have a set of behaviors
that they are program or train or whatever to do. But when you put them in a system together,
they can work towards some kind of broader goal. It's like the self-driving car that you're
describing. It's not just trying to get its passenger from point A to point B, but it's also
well, I mean, that's part of the question. Is it also trying explicitly to
help manage the traffic or is that just a property or an emergent property or something that
happens? That's such a beautiful analogy. Actually, metaphorical and actual. First because swarming
is meant among birds, for example, to reduce drag. The reason why birds swarm is they can fly
much longer. Information is almost like formation flight and reduce the drag. It's not even a metaphor.
It's real. Trucks do platoon to reduce drag. That's beautiful analogy of something real.
But it's also metaphorical. That's really what I like about what you just said. Swarming,
in a sense, attempts among the species that do that to optimize some cost function that might
not be necessarily revealed. It's not that a fish or bird has a cost function that they can compute,
because obviously, even it's implicitly there, it's not explicitly stated in the way they act
to it. But at the end of the day, the swarming achieves a higher objective amongst the swarms.
That's what the self-driving vehicle approach we're following is attempting to do. In swarming,
there's leaders, there's followers. You can view the self-driving analogy in the same way.
If you have, say, 5-10% of vehicles acting in a very specific way to improve the flow,
you could view them as leaders in a kind of a leader following game in a game theoretic sense of
the term. Then the manned vehicles who have to react to this by maybe being surprised,
but if people are driving slower in front of you, you can't pass them, so you'll have to drive
slow as well, or followers in that type of two-team games. The swarming analogy is actually a very
good analogy in that process as that. With a small number of self-driving vehicles, we could
induce the whole population to behave collectively better because of that steering that is done by
these few agents that are able to work with this higher degree of intelligence in the traffic flow.
So, coming back to your presentation at the conference, can you give us an overview of the
general aim and flow of the presentation? Yeah, what we're trying to convey in the
presentation is that AI is going to drive us through a few successive revolutions that are
going to deeply impact the way mixed up to many traffic is studied and eventually how it happens.
The first revolution is models are potentially going away, and what that means is that if you think
about the history of engineering, in engineering, in every subfield whether you work in fluid mechanics,
in structural engineering, and mechanical engineering, or whatever it is, you usually start with an
equation, the model of water, with Navier Stokes' equation, the model of a car, the model of thermodynamics,
whatever it is. There's been hundreds of years of people modeling these things so that you can
inherit the equation and you use the equation to control it, to optimize it, to make things better.
But it turns out that with deeper and first point learning, if you can inherit a simulator
that was built, you know, by experts, you don't need to have actual knowledge of the equation
to improve things. So, in other words, this notion of model-free learning, where you can actually
improve a scoring function without having actually visibility on what the model does, but just
on seeing its output is something that is going to deeply change traffic engineering. And that's
mostly because if you think about the phenomena of traffic, you know, changing lane,
decelerating, routing, deciding to go or not go, stop, accelerate, all these things,
these are very, they're not necessarily complicated to model, but there's a lot of different
actions a human can take. So, if you can get rid of all that modeling and all those
bullion variables corresponding to these decision factors and just learn over simulation,
that's going to make things much easier. And that's what we showed in the talk is that, you know,
simple cases where humans have spent decades to research on how to control, with deeper and
first point learning, we could redo within a few months and we could actually beat. And that's
the beginning of this first revolution where by simulation and by deeper and first point learning
over high fidelity simulators, it will become possible to solve a lot of problems that are
currently unsolved with AI. And the list is long, I mean, the list could include coordination
of traffic light much better than currently done, insertion of self-driving vehicles inside traffic,
control of traffic by self-driving vehicles, automated intersections, and so on and so forth.
So, that's the first revolution I try to explain in the talk saying that, you know,
there's a whole legacy of work that maybe will become obsolete or maybe will just be used for
other things, but there's this new body of work that is progressively emerging where we can beat
the past and do things which are way more innovative. And then beyond that, there's a second
revolution that is maybe a bit further away, which is, well, what if in addition to just forgetting
about the models we could learn from pictures? And that's something that a lot of people have done.
I mean, obviously supervised learning has done a lot of phase recognition and object recognition
and so on and so forth. Well, we're not that far from being able to do the same for traffic management
and traffic control. What if after watching enough videos of traffic, whether these are videos
rendered because they're part of a simulation that produces things or whether they are actual
videos, you know, video cameras deployed in the street or dash car or cams or stuff like that.
Over time, we should be able to learn how to manage streams of vehicles from that data
and potentially from these simulations. And that is likely to be the second revolution we see in
traffic control and traffic management over time. And that revolution is likely to have a much
bigger set of consequences because with the liquidity of cameras and connectivity, we're not that far
from the world where, you know, every vehicle will have cameras and multiple cameras, probably.
And that could help the management of traffic at the scale of cities in ways that have never even
been possible or conceivable before. That's what's going to happen over the next five to ten years.
And it's just the beginning, but that's going to accelerate drastically with the rapid pace of
technology here. So with regard to the first of the two revolutions that you outlined, I think
long-term listeners of the show probably kind of know the direction that I'm going ahead in
and the question that I'm going to ask. And it relates to this notion of model-free.
In particular, it seems to be, I guess in a lot of ways, like a very Berkeley-oriented idea.
And I guess I'm rarely extrapolating from maybe very few conversations.
You know, one of the conversations that I had very early on was with Peter Abiel,
who, you know, believes very strongly in this idea of kind of model-free approaches and
reinforcement learning-based approaches. And since then, I kind of test that idea with a lot
of people. And the kind of conclusion that I've come to is that, A, this is a major kind of theme
and where we are in the AI community. And it seems like for many, like we had this
model-oriented view of the world as you described. It goes back many, many years.
And then we've been more recently very excited about deep learning and deep reinforcement
learning and other approaches and have kind of thrown away the models.
You know, I guess ultimately what it comes down to is overcome the, you know, some of the,
you know, I guess basically just get the best of both worlds, right? Overcome the computational
challenges of deep learning, deep reinforcement learning, and take advantage of the many years of
models. And I'm just curious now that I've got another opportunity to talk to someone at Berkeley
having kind of put all of this together, you know, what your take is. Right. Well, first go bears
and thank you for mentioning Berkeley. Couldn't resist doing this one. So it's very interesting
what you're saying because first, maybe the first point that is important to mention is
model-free works for certain things might not work as well for some other things. And for example,
you think about safety critical systems for many years. I used to work in traffic management.
If you think about autopilot certification, about a lot of medical devices, which are, you know,
safety critical, well, maybe people need to think twice about, you know, forgetting about the model
because there's real laws of physics involved and there's real certification issues there.
And so we have embraced this model-free approach for what we do just because we have evidence that
in many of the known cases, it already beats half a century or more of work of the modeling community.
And we want to really point out that we use it for a very specific purpose. We are not in the
business of doing autopilot collision avoidance, anti-crash systems, safety systems for cars.
These systems have a lot of different degrees of certification requirements
that come with a lot of constraints. It's unclear whether what we do would apply there and it's
really not our job. Our job is to be able to come up with new methods that can coordinate hundreds
of thousands of vehicles or maybe more local scales, maybe dozens of vehicles or hundreds of vehicles.
And you could really view this as a planning tool. A planning tool in a sense in the old
sense of the term is like you were planning train schedules or airline schedules. And if you're off
by three minutes and you manage it properly on the ground, it's not a big deal. If your train is
laid by 30 minutes, as long as you have the right away and you have the space on the railway, no problem.
So here that's the same idea. It's like probably in 99% of the cases what we come up with will provide
substantially better solutions than the state of the art. And maybe in 1% it will do something
really strange. And because it's not safety critical, well, that's not a big deal. I mean,
what will happen as well? Maybe there will be three cars stuck on the freeway for five minutes
in a very strange way and we didn't understand why. But nobody died. It's a planning problem.
And so I think the point is that, you know, there's this ongoing debate that you really mentioned
about model base versus non-model based. Obviously both approaches have their sweet spots.
I think the model free approaches like we're using now clearly have demonstrated a very
disruptive nature in the industry in which we are and in the world in which we live for coordination
of multiple vehicles. But you know, if you're doing precision chemistry or physics, we probably
need a pretty good model of what you're doing because it's material science, because it's laws
of physics. And there it's maybe the story is different. The second part of what you mentioned
is also very interesting is like, well, you know, how can we live in a place where we take the best
of both worlds? And I really think about the fact that, you know, we're not going to throw all the
models and everything we've been doing for half a century in the trash right away. These can be
used to accelerate machine learning in many ways. And so if you think about warm start,
if you think about transfer learning where you learn on some specific setting and apply to
a different setting, if you think about reward shaping and many different, you know, sub-approaches
of making deeper enforcement learning more efficient, that's I think where model based can help.
There's no reason to just get a deeper enforcement learning algorithm searching in the wild when
you already have the good baseline that can be inherited from the past. So in a sense, you can view
this as a way to accelerate the convergence of the algorithm. And that's exactly the sweet spot in
which you want, in fact, AI to augment what the human could not finish. And so maybe, you know,
half a century of research in coordination of traffic lights and coordination of vehicles
and platooning and automated intersections made us come that far. And that's where it's platoon,
that's where it's as I'm told it in a sense. And maybe the next stage is what AI brings us to.
And so that's where I think the two can coexist quite nicely. And that's part of what we're doing
as well as like there's no reason to start from scratch. We could start from what the human has come
up with and let machine learning do the rest. I like that nuance in the context of reinforcement
learning. The idea that, you know, maybe, you know, it's not worth trying to bolt these, you know,
the model together with the learner inherently. But, you know, we can use it in these supporting
functions like cold start, warm start, or, you know, giving hints of some sort, as well as the model
may play a role in whatever the simulation environment is and the way that it presents the real
world to the learning agent. Exactly. And so the second revolution that you described,
you didn't say this explicitly, but I was hearing the theme of imitation learning,
is that kind of the direction you're heading or something else? Well, more specifically,
we're really interested in end-to-end pixel learning. What's the distinction between those two?
Well, it's hard to make a general statement, but the one thing I could say is that in the context
of traffic, what would be a holy grail to M4 is a system in which by looking at pictures,
videos rendering, whatever it is, you can provide the same level of efficiency as by having access
to the state space. I mean, so the previous part of the conversation, essentially, we still,
we maybe got rid of some of the models or all of the models, but we kept the state space. We have
access to vehicle velocity, position, and all the parameters. These almost disappear in an image.
So if you think about a movie of traffic that either was shot from a video or from the rendering
of a simulation software, that video, you could say implicitly contains these parameters because
technically you could re-infer the speed, you could re-infer the position, but the point is
they've been blended in the rendering. Or if this was a video shot from a video camera,
well, you never had access to them in the first place. And so this end-to-end pixel learning
to us is very important because it would almost enable us to extend or build on the very famous
work we've seen all over the social media recently about, you know, Q learning applications for
playing video games. I mean, the Atari games, the pong, and they were probably the first successes.
And now we see there's a lot of progress with Mario and, you know, more and more elaborate video games.
And so obviously, pong and Atari and all these, it's the early ages of video gaming. It's
still pretty simple games, but if you think about traffic, traffic is not, you know, it's not the
state of the art video gaming with a lot of levels of sophistication, decision, 3D rendering,
and all kinds of strategic decisions. It's something which is clearly more complex than an Atari
video game, but it's not something which is on a different scale either. And so that's where
we see the most interesting next revolution is demonstrating that just by working directly on
rendering of traffic, we could achieve the same performance as having access to the state space
because then I will provide proof that, well, maybe you don't need that ubiquitous connectivity
anymore. All you need is an image. And then if you push this even further,
onboard all the self-driving vehicles or vehicles with high level of automation, there's obviously
a lot of sensing and part of that sensing is video-based. And then there's this segmentation problem,
trying to understand how to isolate pedestrians from cars, directions of movement and everything.
That is a field that is moving super fast. That in a sense, we don't want to touch, but we would
love to, at some point, acquire the outputs of once there is software out there or enough data
out there so that we can recuperate all these segmented images and treat them as inputs for what
we do. Because then we have closed the loop. Essentially, we have first demonstrated, we don't
need the old models. Second demonstrated, we don't even need the state space, we can just work with
the image of the state space. And third, finally, linked that with the physical hardware sensing of
the world, which produces these images in a way that these images can be treated in real time.
And that's why I was saying a few minutes ago that it's going to take probably five to ten years
because there's these two revolutions I mentioned before, but that third bridge with the rest of
the community that is doing machine vision, I mean, that's that field is far from being solved.
I mean, there's super rapid progress, but there's still a lot of work to be done for it to become
operational, to run online, to run onboard the platforms, to be fast enough that it can be integrated
in a real-time traffic management system. So there's all these steps, which each of them are
pre-challenging there. But I think what's really nice is to have this overarching vision of where
that whole system will go within the next five to ten years. So you mentioned earlier that the models
that you're building are not intended to be these core control systems that are controlling the
vehicles, collision avoidance, and I took it to be a fundamental mobility. I guess I'm trying to
get at, I also get the impression that you're not talking about kind of an offline, you know,
traffic system that is, you know, looking at these vehicles and providing some analysis and
telling some other system what to do. Like, you're trying to integrate this into an online system.
What are the relationships between these two systems and how does that interface work?
Yeah, absolutely. So maybe the first part of the question, the reason why we don't do collision
avoidance is it's really not our job. But also, if you think about the process of control of vehicles,
I mean, there is what's called the low-level controller acceleration, acceleration, automated
braking, co-operative, adaptive cruise control, and all these tools that are, some of them have
been part of our life for more than ten years. Some of them are just coming now. A lot of it is
really based on very classical control theory, PID control, lead lag, I mean, you know, stuff that
came from the sixties that works well, and there's no reason to change it. Of course, the most
the more recent work of collision avoidance and, you know, trajectory planning at super short-term
horizons to make sure that trajectories are safe. Okay, that requires a little bit more sophistication,
both in terms of the sensing and the learning. But that's really, that's really an area for which
the tools you need are very specific. You need very fast controllers. You need super fast sensing
loops that can provide almost immediate detection of anti-positioning of collisions and things like
this. So the tools for that are very different. The architecture is probably also very different
because you need something to run onboard on the specific chip to be certified and so on and so
forth. So that's why, in a sense, we assume that we are, that that job has been taken care of. There's
the auto manufacturer, there's the autopilot manufacturer, whoever is in charge here. And our job
is more of the coordination. So the analogy would be, you know, if you're running an airline
and you're doing the scheduling of an airline, you don't really care about the speed of landing
of an aircraft because that's going to be taken care by the mechanical crew. And there's essentially
a controller for that. But if you're planning the whole airline, all you want is landing
a window of two minutes the rest. That's not your problem.
Right. I guess so maybe the question that I was getting at more directly was is the system that
you're looking at and trying to build analogous to kind of planning, you know, at the level of the
airline, like a centralized planning system that knows about all the planes and is trying to do
kind of high order scheduling or is it something that is, you know, the back to this distributed
and swarming thing that we talked about at the level of the vehicle that is kind of feeding into
the first person navigation, but, you know, is kind of aware of these broader impacts.
Yeah. So now the question you're asking is a really deep question and it's a question about
what will the future of our transportation system look like and that answer will be very
different on the place depending on the place and the, I would say, involvement that cities will
get. So imagine a world in which maybe 5% of the vehicles are automated. You know, it doesn't
mean that the government, the city or the company that built the vehicles can decide unilaterally
to connect all of these, which is just pushing some code and have them do some traffic flow
regulation, which is pushing another piece of code and turning it on. Obviously, there needs to be
partnerships. The city needs to agree that on these 10 miles of freeways, every connected car
from brand ABC will automatically turn a flow pacifier algorithm that smooths its traffic.
And then every participant will have to at some point agree when maybe they buy the car or they
turn on the car, you know, like when you're downloading an app on your iPhone or your Android,
you click yes, yes, yes, yes, yes. In the same way when you buy the car, you might agree that at
some point you might release the autonomy of the car to higher authority, which will do things,
where things is smoothing traffic. So I think in the situation in which you have 5% of
willing to participate vehicles and vehicle owners, the, you know, the institutional framework in
which you built an online controller, real-time controller like this, that leverages all these
vehicles. That's still a big institutional question mark. Is that going to be run by the state,
is that going to be run by the city, by the local MPO, or by the car company, or by a third party
that is almost like a global scheduler, like the FAA or Euro-controlled for air traffic.
And, you know, if you push this to the extreme and you look at places in the Middle East,
like a Neum city, they're building in the north of the kingdom of Saudi Arabia or Dubai or Abu Dhabi
and places which are very forward looking in the way they think about their urbanization,
because they're building cities from scratch or they're building at a rate which supersedes
anything we've seen before. Then you could envision networks which have a sub portion that is
fully automated, like a place where you could not go if you don't have a vehicle of a certain level
of automation, say four or five, and within that district, there's only five pre-proved models.
And once you enter the district, not only does it take over your routing, but it takes over
everything, like, you know, you punch a destination, you'll figure out the route, you'll figure out
the speed and you'll figure out how to coordinate you with the other vehicles. So that paradigm,
where you have automation on steroids and, you know, every vehicle is automated, that's actually
much more in reach than mixed autonomy. And that's because having vehicles avoid pedestrians,
bikes, scooters, cows or whatever animal is running on the street, that's hard. That's something
which is not easy to certify and to do. But having a city or a guided community or district
or boulevard or whatever it is, where all the vehicles are automated and they have a specific
push of the software, that's something we could do tomorrow. The technology is there, there's
car manufacturing companies there that have enough level of automation to enforce that.
And that's, you know, something where an online system, like I would just been discussing
for the last few minutes, is going to change mobility entirely. I mean, the notion that, you know,
you enter the center city, you push the destination and the rest is taken care of,
that's what happens essentially to a certain extent with airlines. I mean, obviously there's
ways to fly, file flight plans, there's ways you fly, but you file a flight plan and then the FA
will maybe give you an amended flight plan. And if there's weather to have a, again, amended
flight plan, that paradigm essentially will work in a self-driving district. And that's in reach.
And so you can see walking from 5% where we're now to 100%.
But there'll be different paradigms. And there'll be places which are very forward looking and
we'll allow that. There'll be places where they will allow flow pacifiers. And there'll be places
where they won't. And so the answer to the question really will depend on the city,
not just the technology readiness, but also the willingness to embrace these new paradigms.
So kind of within these, these, you know, two plus one, revolutions that you've talked about,
what are some of the key research challenges and which in particular are the ones that you and
your group are digging into? So there's every problem is hard. That's why it's exciting to be
in this field right now. And let me just list a few, you know, which will be my top five of the
moment. And if we talk again in a week, maybe there'll be different. So, you know, the first thing is
this notion of multi agent learning. It's one thing to learn a global policy and to say every
car of a given brand, you know, it's going to deploy the same policy. But the truth is it doesn't
work this way. There's different types of cars. There's different types of ways people want to
use their cars. So the notion that we can do learning multi agent learning where some are
cooperative, some are not cooperative, that's inherently hard. And people who've been in game
theory and non-cooperative games know this. There's all kinds of notions of sub-optimality,
Nash equilibrium, price of unarchy, prisoners, many things like this. Well, these don't go away
with machine learning because the uncooperative nature of the agents just make it hard. So that's one
thing. It kind of drags me right back to, you know, this point about model free. Like, I'd love to
be able to give the agent the hint that, hey, there are these, you know, 10 things that we know
from game theory that may play out here. And so if you, you know, if you see one of these, you can
kind of get a shortcut to learning. Exactly. And that's exactly the way we want to use game theory.
By, for example, one example would be how you steer to more cooperativeness between the agents
and how thereby, you know, more optimality and choose from that behavior. Another really
problematic part of this work is that it needs to scale up the simulations. They're still
quite expensive. I mean, if you're going to simulate the I 210 freeway in Los Angeles, you know,
it's a five lane freeway to directions. Freeway lane carries 2000 vehicles an hour. So essentially,
if you're just standing on the bridge in the middle, you've watched 10,000 vehicles go by in one hour.
And now that freeway extends for dozens of kilometers. So creating a simulator that is able to do
this efficiently and being able to learn over that simulator efficiently is very hard. So if you're
running simulations with, say, a hundred thousand vehicles and you're trying to learn over it,
you probably don't need to re-simulate the hundred thousand vehicles. You're probably going to
learn over 1000 vehicles or hybrid vehicles that are actually key to what's happening there.
But the process of it's people call this learning how to learn. So it's like there's this thing in
supervised learning where, you know, which images should you train on or what is the training data
you should select to train. That's a completely open problem in traffic. It's like, is there a
process by which you could determine how should you learn to learn more efficiently given that
probably 95% of what you're simulating there is useless. And that's a whole area of
meta-learning, active learning, curriculum learning, all of these types of things.
And we've not even scratched the surface there. Like when I say we is like our group,
that's not, I mean, we're not there yet. Just because we have so many other problems,
we need to solve first. But clearly, once people start to do optimization of traffic and mobility
at the scale of a city, that's going to be one of the big elephants in the room if we want to
achieve scalability ultimately. And so that's another really big one. The third one is this end-to-end
pixel learning right now seems in reach. But I think we've again just scratched the surface. I mean,
you know, we've done some moderately difficult cases. Just like people with video games,
they've done pong, they've done Mario, they've probably done a few others. So, you know, how do we
make it work for real? How do we make it work for something which has, you know, hundreds of thousands
of vehicles? So that's another big challenge that make it hard. So I think what's exciting is that
the rate at which innovations happen in AI is so high that there are a lot of tools that appear
quite often that, you know, weren't not really obvious before, like this pixel learning just
had major breakthroughs. And so I think there's a hope that over the next couple of years we'll see
things come from fields we didn't even think would be relevant that actually matter for what we do.
And so we're far from being done, but things are moving so rapidly that I think the progress
rate is quite quite amazing. I feel like we could have spent, you know, entire hours and podcasts
on any of these topics. And so we've just kind of scratched the surface here. Any
suggestions or pointers or words of wisdom for folks that are intrigued by this and want to
dig in deeper? Well, I think from a technical standpoint, we've covered a lot of ground, but I
think the maybe higher level point of wisdom that I would really like to convey is that this
paradigm really can only work if we have cooperation between very different animals. And these
animals include obviously academia or tech or research wherever that happens, whether it's in
the private sector or the public sector, that's us. It involves the car manufacturing industry
because at the end, someone has to push a new release of the autopilot software to make it work
in the field. And to make it work in the field means on the freeway, not in a content test facility
like for real. And the third animal is the government, whether it's federal regulations, whether
state regulation, MPO, city ordinance, wherever it is, there needs to be buy-in so that first it's
actually agreeable to the city to operate this way. There's mobility on demand and cars are
cooperative for 10 miles where the city takes over the automation or something. So it's hard,
because you have academics like us that are pushing new paradigms. You have the private sector,
which has its own constraint. Obviously, they have to go through certification. It's got to be
aligned with their market strategy. Any of the government, which essentially has to regulate
and make sure that we don't kill people and that things are fair and equitable. So the word of
wisdom is that we need to create a community so that these three types of animals start talking
about these things. AI is changing cities, is changing a lot of different urban problems.
And mostly in good ways. We've seen some cases of TNCs and mobility test demand companies,
right-hailing companies or Airbnb styles of this world, how it can be complicated for a city to
regulate over these new technologies and services. And the same is true for this mixed autonomy.
And that's why it's very important to get that conversation started early so that all protagonists
are ready for the time when it becomes a technological reality. And is this conversation happening
today in some centralized place or is it just this highly local set of conversations that are
happening? How can folks plug into whatever or wherever is the best place to kind of tap into
this conversation now? Yes, this is a super interesting question because there is no institutional
place or way to have these conversations. I think what's very encouraging is that you see a lot
of forums where these conversations happen, the transportation research board in Washington every
year. The IEEE intelligent transportation systems conference every year from the IEEE some
specific state driven programs like the Institute of Transportation Studies forums and workshop
in California, ITS America and the ITS World Congress and so on and so forth. But the truth is these
conversations are still I would say boutique sessions in these venues or special sessions in
these conferences. But there's not been a forum, like a worldwide forum on how are we going to
bring this to reality. And I think it will probably emerge. I think we all have a responsibility
to do this. The difficulty is that the AI community is fascinated with research and technological
advances and that's what we should be doing. And obviously public agencies have to deal with
public infrastructure and policy and that's what they've been elected for or that's what they've
been hired for. And the private sector is driven by their products. And so obviously there is
common ground and there's common interest, but these are three orthogonal directions in a 3D
vector space. And so it's hard to institutionalize this until there is a real need for it. And
anticipation is maybe sometimes not the forte of these three actors that are working on different
time scales. It does sound like a massively complex game theory problem. Totally is with three
players that want to be cooperative. Well, Alex, thanks so much for taking the time to chat with us
about this. It's a super interesting conversation and I look forward to kind of keeping tabs on the
field as it evolves. Thank you so much. It was really fun conversation. Really, I appreciate
the time this morning. Thank you. Thank you. All right, everyone. That's our show for today.
For more information about today's show, visit twomelai.com. Thanks so much for listening and see you
next week at Twomelcon.
