1
00:00:00,000 --> 00:00:15,280
All right, everyone, I'm here with Brian Granger. Brian is a senior principle technologist

2
00:00:15,280 --> 00:00:19,520
with Amazon Web Services. Brian, welcome to the Twoma AI podcast.

3
00:00:19,520 --> 00:00:26,140
Hi, Sam. Thanks so much for having me. Looking forward to jumping into our discussion.

4
00:00:26,140 --> 00:00:32,180
You are a co-founder of Project Jupiter, and that is, of course, the topic that we will

5
00:00:32,180 --> 00:00:37,340
be digging into in this conversation. But to get us started, I'd love to have you share

6
00:00:37,340 --> 00:00:42,900
a bit about your background and how you came to work in machine learning, and we'll

7
00:00:42,900 --> 00:00:46,260
make our way to the founding of Jupiter as well.

8
00:00:46,260 --> 00:00:51,860
Yeah, definitely can walk through that. So, as you mentioned, I'm a senior principle

9
00:00:51,860 --> 00:00:59,180
technologist at AWS, and I've been here at AWS for three years, coming up in February.

10
00:00:59,180 --> 00:01:06,300
Before that, for the sort of decade and a half prior, I was a physics professor, most recently

11
00:01:06,300 --> 00:01:13,460
at Cal Poly San Luis Obispo, and then before that, it set a clear university. Even though

12
00:01:13,460 --> 00:01:19,940
as a physics professor, most of the time at university, I built open source tools for

13
00:01:19,940 --> 00:01:26,980
data science, machine learning, and scientific computing. And so I have a background in theoretical

14
00:01:26,980 --> 00:01:33,020
physics, but that's evolved over time through software engineering, building tools, and

15
00:01:33,020 --> 00:01:37,660
more recently, I spent a lot of time on UX design and research.

16
00:01:37,660 --> 00:01:42,500
Nice. Nice. And so, how did Jupiter come to be?

17
00:01:42,500 --> 00:01:51,220
Yeah, so it's a fun story. So if you rewind back to the early 2000s, Linux was really taking

18
00:01:51,220 --> 00:01:58,100
off. Python had been around for a few years, but it became visible in the scientific computing

19
00:01:58,100 --> 00:02:05,660
community. And a classmate of mine at CU Boulder in grad school, Fernando Perez, had started

20
00:02:05,660 --> 00:02:13,020
to use Python in his research. And he's really the one that introduced me to Python, both

21
00:02:13,020 --> 00:02:22,780
he and I during our physics education used Mathematica a lot. And we, even though we were doing

22
00:02:22,780 --> 00:02:29,340
computational physics in other languages, we weren't necessarily using Mathematica, we had

23
00:02:29,340 --> 00:02:35,180
always missed the notebook interface that Mathematica had. And in 2001, Fernando released

24
00:02:35,180 --> 00:02:41,940
IPython, which is an improved and enhanced command line REPL for Python, that had some

25
00:02:41,940 --> 00:02:47,540
of the ideas from Mathematica in it, although it didn't have the full notebook interface.

26
00:02:47,540 --> 00:02:51,940
And so in those early years, I started to play with Python a bit, Fernando was working

27
00:02:51,940 --> 00:02:58,500
on IPython. And then in 2004, he visited me in the Bay Area. I was a young professor at

28
00:02:58,500 --> 00:03:05,140
Santa Clara University. And while he was there, we spent a lot of time talking about computing

29
00:03:05,140 --> 00:03:11,980
what we were doing in our research, how we were using these tools. And it was really then

30
00:03:11,980 --> 00:03:19,780
where the vision of creating a web-based notebook for Python came into focus. And there was

31
00:03:19,780 --> 00:03:23,980
a couple different factors in that one. It was something that we wanted to use in our

32
00:03:23,980 --> 00:03:31,860
own research. We have found over the years that this interactive computing in a notebook

33
00:03:31,860 --> 00:03:36,740
-based interface, where you also have a document, was extremely useful. And we just wanted

34
00:03:36,740 --> 00:03:44,820
it to exist. The other dimension was that by 2004, rich web applications were starting

35
00:03:44,820 --> 00:03:51,300
to appear. And so it started to make a lot of sense to us at that time, that if we were

36
00:03:51,300 --> 00:03:57,220
going to build something like this, it should be entirely web-based. Now, that was 2004.

37
00:03:57,220 --> 00:04:03,940
It took us until 2011 to release the first version of the IPython notebook. And some of

38
00:04:03,940 --> 00:04:10,340
it was us learning about this space. We were theoretical, computational physicists,

39
00:04:10,340 --> 00:04:16,180
not web developers. We wrote a lot of code as physicists, but of a very different nature

40
00:04:16,180 --> 00:04:23,860
than this, obviously. And the other is that modern web technologies, even in 2011, were

41
00:04:23,860 --> 00:04:33,300
relatively primitive. And from 2004 to 2011, we were really waiting for modern web technology

42
00:04:33,300 --> 00:04:40,500
to catch up to what we needed. And even in 2011, state-of-the-art at the time was JQuery

43
00:04:40,500 --> 00:04:46,260
and Bootstrap. Web Sockets had just been turned on and all the browsers. And we were using

44
00:04:46,260 --> 00:04:53,620
all the latest stuff in 2011, which now seems rather primitive compared to what we have today.

45
00:04:53,620 --> 00:05:00,580
When we think about Jupiter or talk about Jupiter today, it's often in the context of ideas

46
00:05:00,580 --> 00:05:07,300
like literate programming. Were you thinking about it from the perspective of literate programming

47
00:05:07,300 --> 00:05:13,780
and some of the theoretical foundations of why a tool like this makes sense? Or is it

48
00:05:15,540 --> 00:05:22,900
kind of strictly scratching your own itch and trying to bring to Python this interface that you

49
00:05:22,900 --> 00:05:27,940
loved in Mathematica? The connection to traditional literate programming

50
00:05:28,740 --> 00:05:39,460
came much, much later. And I think we, and so the phrase that we use, there's sort of two phrases

51
00:05:39,460 --> 00:05:47,620
that we use. One would be literate computing rather than programming. And the other is distinction.

52
00:05:47,620 --> 00:05:54,260
So in the traditional literate programming paradigm, there's nothing interactive about it.

53
00:05:55,220 --> 00:06:01,060
You're not actually, as a human, interacting with the live code as you would in a repel.

54
00:06:01,060 --> 00:06:05,620
You just write a source code file and then you use the literate programming tool to compile that

55
00:06:05,620 --> 00:06:11,780
to the actual source code file that can run. There's nothing interactive about it. And in scientific

56
00:06:11,780 --> 00:06:18,580
computing and data science and machine learning, that interactive experience of writing and running

57
00:06:18,580 --> 00:06:25,300
a bit of code, seeing what the output is and having a stateful process that holds the state

58
00:06:25,300 --> 00:06:30,660
of the program in memory that you can then write more code against. And so that's where we've

59
00:06:30,660 --> 00:06:38,260
always thought of it as literate computing or interactive computing. Another phrase that we talk

60
00:06:38,260 --> 00:06:44,580
about a lot is the idea of a computational narrative. And again, the focus there is on a narrative

61
00:06:44,580 --> 00:06:50,180
that's contained in a document, but it's not about mirror programming as in typing code. It's

62
00:06:50,180 --> 00:06:55,060
about actual computing. It's about writing code and running it, seeing the result of that and

63
00:06:55,060 --> 00:07:00,820
using that to think about data in the case of machine learning. So I think you got us through

64
00:07:00,820 --> 00:07:09,860
2011, 2012, all these new web tools kind of catching up to what you needed around that time. We also

65
00:07:09,860 --> 00:07:16,340
saw an explosion in machine learning, deep learning interests. How did that shift? What was happening

66
00:07:16,340 --> 00:07:23,620
with the Jupyter project? Yeah. So in the early years, when we thought about what would success

67
00:07:23,620 --> 00:07:31,300
look like for us in building this web-based notebook for Python, I think our market, if you want

68
00:07:31,300 --> 00:07:38,740
to phrase it that way, would have been academic researchers who are doing scientific computing.

69
00:07:39,620 --> 00:07:43,620
That's the universe we were in at the time. Those were all the people we were talking to.

70
00:07:45,140 --> 00:07:49,780
And every time, all through the early 2000s, whenever we talked to people in the industry,

71
00:07:49,780 --> 00:07:58,500
they looked at interactive computing with a bit of a sort of, well, that's nice, but we never

72
00:07:58,500 --> 00:08:05,860
need to do that. I think Fernando even had a conversation with Guido Van Rossum, who was the

73
00:08:05,860 --> 00:08:13,620
creator of Python. And when Fernando described how we use Python interactively, Guido said,

74
00:08:13,620 --> 00:08:18,580
wow, I always thought of the Python REPL as being a bit of a toy that no one would actually use for

75
00:08:18,580 --> 00:08:25,700
real work. It's amazing to see how in the scientific computing context, you live in these interactive

76
00:08:25,700 --> 00:08:34,020
shells. And so we had always thought that the commercial adoption of these tools would be very

77
00:08:34,020 --> 00:08:44,020
slow at best. Now, it sort of came in from the side that around the same time, commercial entities

78
00:08:44,020 --> 00:08:49,940
discovered the power of data through data science and machine learning in a way that they hadn't

79
00:08:49,940 --> 00:08:55,780
before. And so they ended up needing these same tools for interactive computing, and they quickly

80
00:08:55,780 --> 00:09:04,420
discovered Jupiter as one of the tools that they could use for this. But it took, I remember in the

81
00:09:04,420 --> 00:09:13,620
early, so starting in 2011, going up to maybe 2015, was an amazing time for us in that it felt like

82
00:09:13,620 --> 00:09:20,020
every month a new major organization discovered interactive computing and Jupiter and Python.

83
00:09:20,660 --> 00:09:29,700
And by the time we got to 2015, 2016, it was a lot of people, a lot of companies were using these

84
00:09:29,700 --> 00:09:35,940
tools as well. But it happened. It was a transition and growth that we had not seen coming and

85
00:09:35,940 --> 00:09:40,180
definitely hadn't planned on. And it created a lot of challenges for Jupiter as a project.

86
00:09:40,180 --> 00:09:50,420
Was it obvious that you should embrace these new use cases and new user communities,

87
00:09:50,420 --> 00:09:58,100
or was there a bit of tension between kind of staying the course and building the thing that

88
00:09:58,100 --> 00:10:05,300
your scientific computing users needed versus things that machine learning users might need.

89
00:10:05,300 --> 00:10:13,140
It's in the extent that those are divergent in any way. Yeah, so I don't want to imply that

90
00:10:13,140 --> 00:10:21,940
there's never been tension there. I think that the I don't want to speak for all Jupiter contributors,

91
00:10:21,940 --> 00:10:31,380
but I can try to summarize some of the sentiments in the community. We even today, so today, Jupiter

92
00:10:31,380 --> 00:10:37,620
is used by many large corporations and many contributors to Jupiter today work at those large

93
00:10:37,620 --> 00:10:46,180
corporations. Back in 2011, it was close to 100% academics working on project Jupiter. And

94
00:10:46,980 --> 00:10:54,340
even today, I think the core Jupiter team deeply values the role of Jupiter in research and education.

95
00:10:54,340 --> 00:10:59,780
We recognize it's important in the commercial space. We definitely want to address those usage

96
00:10:59,780 --> 00:11:07,380
cases, but I think broadly speaking, the Jupiter community holds the research and educational

97
00:11:07,380 --> 00:11:14,820
usages with special importance. And so there has been some tension there. Now, the other question

98
00:11:14,820 --> 00:11:22,100
you brought up is the potential for divergence between the needs of the academic users and commercial

99
00:11:22,100 --> 00:11:30,900
users. I think to first order, the experience we've had is that there's no substantial difference

100
00:11:30,900 --> 00:11:36,180
in the needs of those communities. It's even to the point where it's a little humorous in the

101
00:11:36,180 --> 00:11:44,020
sense that even still to this day, we regularly talk to organizations that will tell us how they're

102
00:11:44,020 --> 00:11:49,140
using Jupiter and start out by saying, you know, the way we're using Jupiter is really weird and

103
00:11:49,140 --> 00:11:54,820
special and probably unlike anything you've ever heard. And then they'll tell us a story that we've

104
00:11:54,820 --> 00:11:59,780
heard hundreds of times about. They're doing all the same things everyone on the planet's doing

105
00:11:59,780 --> 00:12:07,220
with Jupiter. That's not to say that they're not differences. For example, in the academic context,

106
00:12:08,180 --> 00:12:12,900
the requirements of teaching are really unique. And so when you're teaching a large class and

107
00:12:12,900 --> 00:12:18,660
university with notebooks, being able to manage homework, assign homework that involves notebooks,

108
00:12:18,660 --> 00:12:23,700
grade the homework involving notebooks. And so we've built special capabilities for things like

109
00:12:23,700 --> 00:12:29,540
that. But at the core, I would say most of the functionality is common across to all Jupiter users.

110
00:12:30,260 --> 00:12:38,820
Got it. Got it. And so you're now at AWS and you continue to work on Jupiter. How did that come

111
00:12:38,820 --> 00:12:49,780
to be? Yeah. So as I mentioned, by the somewhere in maybe 2015, 2016 commercial and enterprise

112
00:12:49,780 --> 00:12:59,300
usages of Jupiter had really taken off. And what that meant is that the Jupiter developers were talking

113
00:12:59,300 --> 00:13:05,300
to a lot of users that were no longer individual users, but were people maintaining and operating

114
00:13:05,300 --> 00:13:10,260
large scale Jupiter deployments in their enterprise. And the pain points and struggles that they were

115
00:13:10,260 --> 00:13:17,540
having sometimes were related to Jupiter and would be either bugs or feature requests or enhancements

116
00:13:17,540 --> 00:13:22,900
that we could make on the Jupiter side. In other cases, their challenges that they were running into

117
00:13:23,620 --> 00:13:30,820
really were not a Jupiter problem or challenge. It was more of a deploying and maintaining

118
00:13:30,820 --> 00:13:37,060
cloud infrastructure type of problems. A great example of that would be entities that have

119
00:13:38,100 --> 00:13:43,780
some manner of private or sensitive data and need to deploy Jupiter to meet a certain compliance

120
00:13:43,780 --> 00:13:52,740
regime such as HIPAA. And that's not really a problem that Jupiter's an open source project is

121
00:13:52,740 --> 00:13:57,940
going to solve in an end to end way. Jupiter may offer building blocks that can be used to assemble

122
00:13:57,940 --> 00:14:05,060
such a system. And so that was one of the, for me personally, starting to talk to these

123
00:14:05,060 --> 00:14:10,580
enterprise users and realize, okay, there's a huge need here. We're probably not going to be

124
00:14:10,580 --> 00:14:15,140
that the Jupiter open source community is not going to fully solve these needs. I'd love to start

125
00:14:15,140 --> 00:14:20,340
to work in an organization that's really good at all those enterprise cloud computing challenges.

126
00:14:20,340 --> 00:14:28,420
That was one dimension. The other dimension was us thinking about the long-term sustainability.

127
00:14:30,180 --> 00:14:36,980
The as a result of the adoption and the enterprise commercial space, the user base of Jupiter

128
00:14:36,980 --> 00:14:45,460
grew far, far faster than the size of the development team of Jupiter. I think that the Jupiter

129
00:14:45,460 --> 00:14:51,940
user base has been growing exponentially with a doubling period of, I don't remember, it's about

130
00:14:51,940 --> 00:15:02,900
a year since I think 2015. The Jupiter contributor population has not grown exponentially. We've grown

131
00:15:02,900 --> 00:15:10,180
a lot. And so we've really faced a resourcing issue where we just as an open source project have

132
00:15:10,180 --> 00:15:17,060
not been able to keep up. I love by the way that you said it was growing exponentially and

133
00:15:17,780 --> 00:15:26,260
actually meant exponentially. I can show you the plot where I'm getting this from

134
00:15:27,060 --> 00:15:37,060
is we have a chart that we periodically gather and that is the number of public notebooks on GitHub.

135
00:15:37,060 --> 00:15:41,860
There's a number of different ways we measure how big the Jupiter user base is.

136
00:15:42,980 --> 00:15:48,260
But you can see we have a chart in this repository in a notebook that shows

137
00:15:49,300 --> 00:15:53,940
the growth of notebooks, public notebooks on GitHub, and it's been growing exponentially since I

138
00:15:53,940 --> 00:16:02,660
think somewhere around 2015. So yeah, and so part of this was the Jupiter governance model has

139
00:16:02,660 --> 00:16:08,820
always been multi-stakeholder. We've designed it and some of this came out of our own needs.

140
00:16:09,300 --> 00:16:14,740
Fernando was at Berkeley. I was at Cal Poly. So almost by definition, there's multiple stakeholders

141
00:16:14,740 --> 00:16:20,580
in organizations involved. As additional academic contributors came on board and then eventually

142
00:16:21,140 --> 00:16:26,180
contributors from companies came on board, we embraced that multi-stakeholder nature.

143
00:16:26,180 --> 00:16:33,460
And I think from this perspective, my moving to Amazon was an opportunity to bring a new stakeholder

144
00:16:33,460 --> 00:16:38,980
into the mix of improving and making Jupiter sustainable and growing open source project.

145
00:16:40,660 --> 00:16:48,340
And the governance model is it's Jupiter's part of the numfocus foundation. Is that correct?

146
00:16:48,340 --> 00:16:55,540
Yeah, numfocus is a 501c3 nonprofit that's the umbrella organization for a number of open source

147
00:16:55,540 --> 00:17:04,260
projects in this space that would include NumPy, SciPy, Pandis, SimPy, Jupiter, and dozens of others.

148
00:17:04,260 --> 00:17:09,780
I know I'm forgetting. There's more than I can possibly name. So Jupiter's one of those

149
00:17:11,700 --> 00:17:17,780
Jupiter in numfocus, each of those open source projects has its own governance model. It's not like

150
00:17:17,780 --> 00:17:22,580
the Apache foundation where there's a single governance model that everyone adopts under the

151
00:17:22,580 --> 00:17:31,380
foundation. And we actually in the Jupiter side have been refactoring and designing a new

152
00:17:31,380 --> 00:17:36,980
governance model over the last two years to address the scope and scale of Jupiter.

153
00:17:36,980 --> 00:17:44,740
And we've been rolling that out incrementally over the last year and still doing work to

154
00:17:44,740 --> 00:17:52,020
finish that up. But the core idea is that it is multi-stakeholder and we're trying to build checks

155
00:17:52,020 --> 00:17:59,460
and balances to include cooperation in a vibrant community among all these stakeholders.

156
00:18:00,100 --> 00:18:10,660
So you've talked about the kind of what's in it for Jupiter in finding kind of an enterprise

157
00:18:10,660 --> 00:18:20,820
cloud home, if you will. What's in it for AWS and how and why does AWS invest in Jupiter?

158
00:18:20,820 --> 00:18:27,620
Yeah, this is this is a great question. So the story of Jupiter and AWS actually began before I

159
00:18:27,620 --> 00:18:37,620
joined. And as AWS was diving into machine learning and data science, the question came up of what

160
00:18:37,620 --> 00:18:44,260
do we do? Our customers are asking us about notebook platforms. What are we going to offer for

161
00:18:44,260 --> 00:18:51,460
that? And a decision was made before I joined to embrace Jupiter. And it really came from feedback

162
00:18:51,460 --> 00:19:01,540
from customers. The leadership team and the org that I'm in the AI ML org at AWS. But we spent a

163
00:19:01,540 --> 00:19:06,180
lot of time talking to customers, understanding what they're doing, what their pain points are,

164
00:19:06,180 --> 00:19:12,020
what existing open source technologies they're using. And like I said, even before I joined,

165
00:19:12,020 --> 00:19:18,180
we heard the resounding chorus that people were using Jupiter and they needed help deploying Jupiter

166
00:19:18,180 --> 00:19:24,740
in a secure cost effective way. And that they wanted actual Jupiter. They didn't want a notebook

167
00:19:24,740 --> 00:19:30,420
like solution. They wanted real Jupiter. This is also something that made it possible for me to

168
00:19:30,420 --> 00:19:36,580
join AWS and very attractive to join AWS. I didn't need to start at the sort of very beginning and

169
00:19:36,580 --> 00:19:43,300
argue and make a case at AWS for why Jupiter? Why should we ship Jupiter versus build our own notebook?

170
00:19:43,300 --> 00:19:50,900
That was already done and settled. And so since I joined AWS, it's more been a question of how do we

171
00:19:50,900 --> 00:19:58,980
at AWS make sure that Jupiter continues to be the best notebook platform in a vibrant and growing

172
00:19:58,980 --> 00:20:06,180
open source community? And at AWS, there, you know, across different projects, there are different

173
00:20:06,180 --> 00:20:19,700
approaches to engaging with open source communities. It sounds like the way that AWS is engaging

174
00:20:19,700 --> 00:20:28,900
with Jupiter in terms of, or rather, the way that AWS is incorporating Jupiter into its projects is

175
00:20:28,900 --> 00:20:36,340
to try to stick close to kind of the core Jupiter as opposed to forking it off into something else.

176
00:20:37,380 --> 00:20:45,300
Absolutely. Yep. Now, one of the things that, and this gets back to a technical and architectural

177
00:20:45,300 --> 00:20:53,460
principle that Jupiter has used since its founding. And that is Jupiter at the end of the day builds

178
00:20:53,460 --> 00:21:00,260
Lego building Lego pieces for notebook platforms or for interactive computing platforms. And the

179
00:21:00,260 --> 00:21:05,300
idea is that enterprises and organizations can take those building blocks and assemble them in

180
00:21:05,300 --> 00:21:10,500
different ways. And at AWS, that's exactly what we're doing. We're taking the open source building

181
00:21:10,500 --> 00:21:17,060
blocks and assembling them in a particular way to serve the needs of our customers. And so we may

182
00:21:17,060 --> 00:21:24,500
build, and we do, in fact, build additional things on top of it using the various extensibility APIs

183
00:21:24,500 --> 00:21:33,060
that Jupiter has. So for example, our machine learning IDE at AWS is SageMaker Studio. It's based

184
00:21:33,060 --> 00:21:39,140
on Jupiter Lab. But then on top of that, in the SageMaker team, we've written a bunch of Jupiter

185
00:21:39,140 --> 00:21:44,740
Lab extensions that add machine learning specific capabilities to make it an end-to-end solution for

186
00:21:44,740 --> 00:21:52,740
machine learning. And those extensions that we're building wouldn't make sense to be in Jupiter

187
00:21:52,740 --> 00:22:01,220
from an open source perspective. They are, a lot of them are specific to AWS. Jupiter as an open

188
00:22:01,220 --> 00:22:08,660
source project works really hard to have a essentially vendor neutral perspective. So if you look

189
00:22:08,660 --> 00:22:14,180
across Jupiter's different code bases, you're not going to find a lot of code that's specifically

190
00:22:14,180 --> 00:22:23,140
tuned to a particular cloud platform or deployment context. And so at Amazon, we're extending Jupiter,

191
00:22:23,140 --> 00:22:29,860
we're building additional domain specific capabilities on top of that. But anytime we're looking at

192
00:22:30,580 --> 00:22:35,460
either bugs or enhancements to the core of Jupiter itself, our approach is to work with the

193
00:22:35,460 --> 00:22:42,100
Jupiter open source community and contribute back to those changes. And so we have a dedicated

194
00:22:42,100 --> 00:22:48,100
team of engineers. It's a small team, but they're 100% focused on upstream contributions to

195
00:22:48,100 --> 00:22:53,700
Jupiter. With the goal of making sure that Jupiter continues to be the best notebook platform out

196
00:22:53,700 --> 00:23:00,340
there. And that is, and it's again, not just about the software, but it's also about the community,

197
00:23:00,340 --> 00:23:07,780
the open source community. And so we're participating in that open source community in a way that we

198
00:23:07,780 --> 00:23:16,260
hope makes sustainable and growing inclusive and diverse. Zooming out a bit, I'm curious how you

199
00:23:16,260 --> 00:23:26,260
think about the broader ML tooling space. And you know, Jupiter is just one piece of what data

200
00:23:26,260 --> 00:23:34,660
scientists or machine learning engineer might interact with to get an idea for a model from

201
00:23:34,660 --> 00:23:40,740
that idea into production. How do you think about that broader space?

202
00:23:42,020 --> 00:23:51,140
Yeah. And so for this, I'll start with the landscape of products we have at AWS for machine

203
00:23:51,140 --> 00:23:59,540
learning under the SageMaker umbrella. And what we're seeing from customers is that there's

204
00:23:59,540 --> 00:24:06,740
a bunch of different tools and capabilities they need to go all the way from the beginning of

205
00:24:06,740 --> 00:24:13,140
the machine learning workflow where they're preparing data, importing data all the way to

206
00:24:13,140 --> 00:24:17,620
building models and then deploying them and then using them to make predictions, whether it's

207
00:24:17,620 --> 00:24:25,300
in a product through an API or make predictions that are more consumed by humans and something

208
00:24:25,300 --> 00:24:34,580
like a dashboard. And we've been building the tools at AWS and SageMaker for the different parts

209
00:24:34,580 --> 00:24:40,820
of that machine learning workflow in close collaboration with customers. As you know, one of the AWS

210
00:24:40,820 --> 00:24:47,620
leadership principles is customer obsession, which means that we spend a lot of time talking to

211
00:24:47,620 --> 00:24:53,220
customers and understanding what they're doing, what their needs are. And so all the different

212
00:24:53,220 --> 00:24:58,900
things we're building in SageMaker are a response to what our customers need. Now with that said,

213
00:24:59,940 --> 00:25:06,180
I think that the challenge that's emerging more broadly is one of complexity, that if you look

214
00:25:06,180 --> 00:25:13,460
at all the tools, a large organization would have to string together to cover and span the complete

215
00:25:13,460 --> 00:25:18,980
end-to-end machine learning workflow to have those tools address the different personas that

216
00:25:18,980 --> 00:25:24,900
are participating in machine learning, whether it's data engineers, data scientists, ML scientists,

217
00:25:24,900 --> 00:25:33,140
ML ops engineers, etc. There's just incredible complexity. And the complexity is along a number of

218
00:25:33,140 --> 00:25:39,860
different dimensions. There's fundamental complexity in the data. People are working with,

219
00:25:39,860 --> 00:25:44,820
there's complexity in the algorithms they're working with, there's workflow complexity,

220
00:25:44,820 --> 00:25:51,540
and then there's the reality that this nice picture that we have about the machine learning workflow

221
00:25:51,540 --> 00:25:57,380
that starts from importing data to exploratory data analysis, to data preparation, to model training,

222
00:25:57,380 --> 00:26:04,420
to model evaluation, deployment, it's never linear in practice, right? Someone starts working with

223
00:26:04,420 --> 00:26:10,740
a data set and the initial questions are going to be asking are very basic, such as what's even

224
00:26:10,740 --> 00:26:16,180
in this data? What might we predict? What business questions might we predict with this data?

225
00:26:16,900 --> 00:26:22,900
And they may get to the end of that initial pass and discover we're not even close to being ready

226
00:26:22,900 --> 00:26:27,700
to building a model that we can deploy and make predictions against. We have to go back to the

227
00:26:27,700 --> 00:26:33,460
beginning, clean up the data, gather more data, join it with other data that we don't have available,

228
00:26:34,100 --> 00:26:37,940
and then they're come back and do that again. And maybe this time they get a little further

229
00:26:37,940 --> 00:26:43,460
and start to feel like, okay, we may be able to predict this. Let's dive in and see how far we

230
00:26:43,460 --> 00:26:49,380
can push it in terms of the quality of the model we can build. And then after that, they may have

231
00:26:49,380 --> 00:26:56,980
to look at questions around bias and explainability and understand, okay, we have a model that's performing

232
00:26:56,980 --> 00:27:03,220
well, but can we use it responsibly and ethically? And they may have to do another cycle through all of

233
00:27:03,220 --> 00:27:10,500
this. And this iterative nature, and then the complexity of the overall workflow, I think is

234
00:27:10,500 --> 00:27:17,780
something that we at AWS and everyone across this entire industry is just starting to grapple with.

235
00:27:18,660 --> 00:27:23,540
I'm hoping that 10 years from now, we look back on this stage and say, wow, we've made incredible

236
00:27:23,540 --> 00:27:31,220
progress. Really on the side of UX design and human computer interaction that our systems will

237
00:27:31,220 --> 00:27:36,900
evolve to the point where they still have these capabilities, but allow human workers who are using

238
00:27:36,900 --> 00:27:42,020
the tools to have a much simpler experience. And I think that's the main challenge we have right now.

239
00:27:42,980 --> 00:27:49,700
Digging into the user experience and HCI aspects of this, I know that's something that you

240
00:27:50,340 --> 00:27:56,260
are very passionate about and spend a lot of time researching. What,

241
00:27:56,260 --> 00:28:04,500
you know, what, you know, have we learned or what have you learned and have applied into

242
00:28:05,540 --> 00:28:12,500
Jupiter or, you know, what's kind of changed the way you think about Jupiter or, you know, what

243
00:28:12,500 --> 00:28:20,980
from those spaces do you think will kind of impact the way that you, you know, build these tools

244
00:28:20,980 --> 00:28:27,540
and guide these tools in the future? Yeah, there's a number of different dimensions here.

245
00:28:30,020 --> 00:28:38,500
All maybe pick two, two of them to talk about briefly. One is that in organizations that are doing

246
00:28:38,500 --> 00:28:46,100
machine learning and building machine learning tools, you're pretty much guaranteed that by definition,

247
00:28:46,100 --> 00:28:53,380
they're engineering heavy. You, if you look at these organizations, you're not going to find a lot

248
00:28:53,380 --> 00:28:59,700
of UX designers that just naturally work into the process. So that's the first challenge is that

249
00:28:59,700 --> 00:29:04,500
is sort of the way to engineering required to build these systems and use these systems is massive.

250
00:29:05,220 --> 00:29:14,020
And even in, even in organizations like SageMaker in the AWS AIML org, we have been very deliberate

251
00:29:14,020 --> 00:29:19,780
to build out UX design teams. And yet, if you look across our organization, we're still very

252
00:29:19,780 --> 00:29:26,740
engineering heavy because the problem requires it to be so. And so just the weight and momentum of

253
00:29:26,740 --> 00:29:34,580
engineering presents, presents a lot of challenges to prioritizing the human experience of these tools.

254
00:29:34,580 --> 00:29:42,500
And so a lot of what I'm working on right now at AWS is building mechanisms to help us include

255
00:29:42,500 --> 00:29:51,620
the consideration of the human experience in this. And it's a lot of fun to be diving into that,

256
00:29:51,620 --> 00:29:58,100
but certainly very challenging. And I think that the key is that at least at AWS,

257
00:29:58,900 --> 00:30:06,420
it's rather new to build tools where the human experience is so primary and important.

258
00:30:06,420 --> 00:30:13,700
And it's a growth area for us and something that we're spending a lot of time and energy and

259
00:30:13,700 --> 00:30:24,100
investment on to improve in this space. The other dimension of this is I think that there's very

260
00:30:24,100 --> 00:30:36,180
few situations where we as humans have tried to design tools that are this technically complex.

261
00:30:36,180 --> 00:30:41,780
And what I mean, I'll use an analogy here. I'm a car nerd in addition to being a

262
00:30:43,380 --> 00:30:51,620
data nerd. And if you think about how people approach car design, if you're designing a hatchback

263
00:30:51,620 --> 00:30:59,300
for mass-produced market, you can have UX designers come in and look at the human needs.

264
00:30:59,300 --> 00:31:04,260
And those UX designers will not need to know much about the technical implementation of that car.

265
00:31:04,260 --> 00:31:09,540
They're not going to need to know about that. They can work with engineers who can handle all that

266
00:31:09,540 --> 00:31:15,300
and it will work wonderfully. If on the other hand, your job is to design a formula and racing car,

267
00:31:16,420 --> 00:31:20,180
anyone involved in that product, I mean, if you want to think of it as a product,

268
00:31:21,220 --> 00:31:25,940
has to have an incredibly high level of technical knowledge. For example,

269
00:31:25,940 --> 00:31:33,220
let's say you're the UX designer who's designing the steering wheel for an F1 racing car,

270
00:31:34,260 --> 00:31:39,620
you need to understand what are all the technical capabilities that the driver needs to have

271
00:31:39,620 --> 00:31:48,980
at their fingertips. What are the principles on the human side, the human factors that would enable

272
00:31:48,980 --> 00:31:55,860
a driver to manage dozens of buttons driving 200 miles an hour. How on earth do they do

273
00:31:55,860 --> 00:32:01,300
that? They're going to have to glance down in a split second to find that button to change the

274
00:32:01,300 --> 00:32:07,780
brake bias or to change how the engine is tuned. And the designer going through that has to become

275
00:32:08,420 --> 00:32:12,740
an expert in the technical details of that platform. They're going to need to know about

276
00:32:12,740 --> 00:32:18,580
tire wear, brake bias. When do the drivers need to use these things? And this is, I think,

277
00:32:18,580 --> 00:32:24,980
another fundamental challenge is that the designers who are helping to design these tools

278
00:32:24,980 --> 00:32:31,780
need over time to get that technical expertise to understand these technical users and what they're

279
00:32:31,780 --> 00:32:40,580
doing with the code and the data and the tools we're building. In kind of talking about the first of

280
00:32:40,580 --> 00:32:50,660
those, the first of those directions for incorporating user experience into product,

281
00:32:50,660 --> 00:32:59,140
the recent Canvas announcement came to mind. Can you talk a little bit about the way that

282
00:33:00,100 --> 00:33:08,100
user experience design went into that product? Yeah, absolutely. So at reinvent this year,

283
00:33:08,100 --> 00:33:14,340
we launched Amazon SageMaker Canvas, which is a tool that enables business analysts to train

284
00:33:14,340 --> 00:33:19,700
machine learning models. So these are users that spent a lot of time working with tabular

285
00:33:19,700 --> 00:33:26,420
data sets. And they're focused on answering significant business questions with tabular data sets.

286
00:33:26,420 --> 00:33:32,900
Maybe Excel spreadsheets. They may have data in relational databases and running SQL queries

287
00:33:32,900 --> 00:33:42,020
against them. And what we're hearing from customers is that these business analysts often would work

288
00:33:42,020 --> 00:33:50,660
with data scientists or machine learning practitioners who can build models. But there's never enough data

289
00:33:50,660 --> 00:33:58,260
scientists and machine learning practitioners to support the business analysts. And so the vision

290
00:33:58,260 --> 00:34:05,460
of Canvas is basically let one of these analysts import a tabular data set. And then pick a target

291
00:34:05,460 --> 00:34:13,460
column. We suggest what type of prediction is relevant, whether that's classification or regression.

292
00:34:13,460 --> 00:34:18,340
And then we train a model and enable the business analyst to quickly make predictions. And it's a

293
00:34:18,340 --> 00:34:25,300
no-code interface. And what's exciting about it is that use the same underlying platform

294
00:34:26,100 --> 00:34:31,780
of SageMaker. So the models that are trained in Canvas use SageMaker Autopilot, which is our

295
00:34:31,780 --> 00:34:40,020
AutoML service. And so the analysts when they train a model can then hand it off to the data scientists

296
00:34:40,020 --> 00:34:45,540
who can then do additional work on that model as needed. For example, if there's multiple model

297
00:34:45,540 --> 00:34:50,420
candidates that autopilot is suggested, the data scientists can come in and help the analysts at

298
00:34:50,420 --> 00:34:56,020
that point figure out what for this business use case, what is the best possible model at that time.

299
00:34:56,020 --> 00:35:02,740
And what we're seeing is that Canvas enables these analyst users to focus on the business

300
00:35:02,740 --> 00:35:07,220
questions that they want to answer. And then understanding what types of things they can

301
00:35:07,220 --> 00:35:16,340
predict using machine learning. And the, yes, even the name of the product kind of elicits this

302
00:35:16,340 --> 00:35:27,940
visual approach to building machine learning. Do you see that as extending beyond what Canvas is

303
00:35:27,940 --> 00:35:37,860
today, which is frankly a very simple approach to solving relatively simple problems?

304
00:35:37,860 --> 00:35:46,820
The question that I would come back to is, is for these analysts, what are they doing on a daily

305
00:35:46,820 --> 00:35:52,740
basis that where machine learning could help them? And how do we make them successful in doing that?

306
00:35:53,620 --> 00:36:03,300
And today, Canvas does have some data preparation capabilities, but it's not as sophisticated,

307
00:36:03,300 --> 00:36:09,620
for example, as the, what data scientists would do in a notebook or what they would do in a tool

308
00:36:09,620 --> 00:36:19,540
like SageMaker Data Wrangler, which is a low-code data preparation tool we have in SageMaker Studio.

309
00:36:20,580 --> 00:36:27,220
And so I think we have a question in Canvas right now around, or I guess it's more of a hypothesis,

310
00:36:27,220 --> 00:36:34,180
that the analyst personas don't need to do heavy-duty data preparation, but now that we've

311
00:36:34,180 --> 00:36:38,180
launched a product, we're going to get to figure out how much data preparation do they need?

312
00:36:38,820 --> 00:36:44,420
Do they want to do it themselves? Do they want to be assisted in doing data preparation by data

313
00:36:44,420 --> 00:36:50,660
scientists? At this point, our hypothesis is that they don't, they don't need to do a heavy-duty

314
00:36:50,660 --> 00:36:57,620
data preparation. And a lot of this, you know, this is not just sort of a wild gas, but we spent a

315
00:36:57,620 --> 00:37:04,820
lot of time talking to customers who have analysts who would be using a tool like this, and that's

316
00:37:04,820 --> 00:37:10,660
our sense right now. And so, you know, I think part of what you're asking is how might, where might

317
00:37:11,540 --> 00:37:19,380
Canvas evolve to over time? I think that's one question we have. Another question is the role of

318
00:37:19,380 --> 00:37:27,220
collaboration between the business analysts and data scientists. We have collaboration capabilities

319
00:37:27,220 --> 00:37:33,860
built into Canvas and SageMaker Studio to enable this to happen. I think our hypothesis is that

320
00:37:33,860 --> 00:37:40,100
these users do need to work together. Time will tell, tell us more about the nature of that

321
00:37:40,100 --> 00:37:47,140
collaboration and what additional things customers need. Yeah, I'd love to maybe spend a bit talking

322
00:37:47,140 --> 00:37:56,420
a little bit more about collaboration and the way you see collaboration kind of taking place

323
00:37:56,420 --> 00:38:04,420
in the context of the machine learning workflow in general, and notebooks in particular. I think

324
00:38:04,420 --> 00:38:14,100
when we, it's easy to look at notebooks and what they, you know, taking you from this IDE and

325
00:38:14,100 --> 00:38:20,980
a terminal or terminal that's kind of, you know, landlocked to your computer to a web page that,

326
00:38:20,980 --> 00:38:26,660
you know, could be anywhere and offers the idea of, or the possibility of collaboration.

327
00:38:28,580 --> 00:38:36,100
It strikes me that while that is a natural idea for notebooks, it's under-implemented maybe.

328
00:38:36,100 --> 00:38:41,700
I don't see it being used in that way as often as, you know, I might expect. It's like the promise

329
00:38:41,700 --> 00:38:46,100
of a Google Doc, but, you know, everyone just uses it as a regular word processor.

330
00:38:47,380 --> 00:38:55,140
And I'm wondering, you know, what you observe about collaboration and the ML process in general,

331
00:38:55,140 --> 00:38:59,940
and the way you see that applying to, you know, tools and notebooks in particular.

332
00:39:00,580 --> 00:39:04,580
When we released the, the Python notebook in 2011,

333
00:39:04,580 --> 00:39:10,900
and users started to work with it and began to open issues on GitHub to give us feedback.

334
00:39:10,900 --> 00:39:17,220
And within a very short period of time, I think it was a month or two, one of the earliest feature

335
00:39:17,220 --> 00:39:22,340
requests we had was for real-time collaborations similar to what you would have in something like

336
00:39:23,300 --> 00:39:30,500
Google Docs. And it has continued to be probably the most significant feature requests we have

337
00:39:30,500 --> 00:39:37,060
from the Jupyter community. And so we heard from the Jupyter user base very early on that they

338
00:39:37,060 --> 00:39:41,940
wanted real-time collaboration, that they looked at these notebook documents in a similar way to how

339
00:39:41,940 --> 00:39:48,580
they look at documents that they work within a word processor and wanted to collaborate with that,

340
00:39:48,580 --> 00:39:54,980
that mode of interaction. And so we've, on the Jupyter side, we spent many years working on this,

341
00:39:54,980 --> 00:40:01,780
we've had a number of sort of false starts. It's compounded by the fact that building a,

342
00:40:01,780 --> 00:40:08,260
the needed infrastructure and architecture for real-time collaboration from a, from an algorithm

343
00:40:08,260 --> 00:40:14,740
perspective is quite complex. Thankfully, the underlying algorithms have improved over the years.

344
00:40:15,540 --> 00:40:23,140
And so it, just this year in Jupyter Lab 3, we've launched the first support for real-time

345
00:40:23,140 --> 00:40:28,980
collaboration. And we're using a, another open source library that's been fantastic for this,

346
00:40:28,980 --> 00:40:38,100
called YGS. It offers a very high-performance CRDT implementation in JavaScript. And so that's

347
00:40:38,100 --> 00:40:45,300
really what is enabled us to build real-time collaboration in Jupyter Lab 3. And so if you,

348
00:40:45,300 --> 00:40:51,140
any user of Jupyter Lab downloads the latest version of Jupyter Lab 3, there's a special flag

349
00:40:51,140 --> 00:40:56,340
you can issue at the command line that enables the collaboration feature. With that said,

350
00:40:56,340 --> 00:41:01,060
we're just getting started in terms of the full experience of this. There's a lot of additional

351
00:41:01,060 --> 00:41:08,020
user experience, dimensions that we need to add, other technical dimensions, but it continues to be

352
00:41:08,020 --> 00:41:14,500
a major focus of the Jupyter community. And something that users want and have wanted since the

353
00:41:14,500 --> 00:41:21,060
very beginning. Now, the broader picture of collaboration that you mentioned in machine learning,

354
00:41:21,060 --> 00:41:27,940
I think what, what we see both at AWS and in Jupyter is that there are many different personas

355
00:41:27,940 --> 00:41:33,700
that participate in the overall machine learning workflow. And the key points of collaboration

356
00:41:33,700 --> 00:41:39,380
are between those different personas. So, for example, one, a data engineer who's been

357
00:41:39,380 --> 00:41:45,620
preparing and getting the data ready, hands off a data set to a data scientist for them to work on

358
00:41:45,620 --> 00:41:53,380
it. And I think that that mode of collaboration between personas is really one of the main challenges

359
00:41:53,380 --> 00:42:00,740
we see both in Project Jupyter and in in SageMaker products on the AWS side. And it's very different

360
00:42:00,740 --> 00:42:06,260
from environments where collaboration happens primarily among the same persona.

361
00:42:06,260 --> 00:42:13,940
And it adds that it's not to say that that that pattern of collaboration never happens in data

362
00:42:13,940 --> 00:42:19,380
science and machine learning, but I think that the more the more challenging one is the cross

363
00:42:19,380 --> 00:42:26,740
persona collaboration. Yeah, I could see arguments for that making things

364
00:42:26,740 --> 00:42:37,700
easier in that you have these well-defined interfaces between, you know, not that they're inherently

365
00:42:37,700 --> 00:42:43,380
well-defined, but there's an opportunity to define an interface between the personas, whereas

366
00:42:44,500 --> 00:42:49,620
if you have people in the same, with the same role in the process working on the same thing,

367
00:42:49,620 --> 00:42:57,300
it's easier for them to kind of walk on one another's work, so to speak. But it also defining

368
00:42:57,300 --> 00:43:04,660
those interfaces can be challenging. Absolutely. And that's, it really is, and there's both the

369
00:43:05,540 --> 00:43:12,740
interface from the perspective of a programmatic API, and then also from the perspective of a

370
00:43:12,740 --> 00:43:20,420
like a graphical application. And the other, you know, we quickly get into the challenges of

371
00:43:20,420 --> 00:43:28,580
distributed and shared data structures, and that is some personas tend to work with entities

372
00:43:28,580 --> 00:43:36,580
that are immutable, others with entities that are immutable, and figure out how to

373
00:43:36,580 --> 00:43:43,700
get those personas to collaborate, when the underlying entities that they're dealing with

374
00:43:43,700 --> 00:43:49,860
are fundamentally different. So for example, software engineers are completely familiar with

375
00:43:49,860 --> 00:43:56,660
collaborating using Git and a version control system. But when you look at other stakeholders

376
00:43:56,660 --> 00:44:00,580
that want to interact with maybe the notebooks the data scientists are working with,

377
00:44:00,580 --> 00:44:06,580
they're not going to be using Git, right? They probably want a graphical interface that allows

378
00:44:06,580 --> 00:44:12,660
them to comment on a notebook in the same way that you comment on a word processing document,

379
00:44:13,220 --> 00:44:17,540
right? They're not going to be on GitHub. They're not submitting pull requests and using the

380
00:44:17,540 --> 00:44:22,420
Git command line or anything like that. And yet it's still the same entity underneath. It's still

381
00:44:22,420 --> 00:44:29,060
a notebook at the end of the day. And so figuring out how even what the entities and data structures

382
00:44:29,060 --> 00:44:32,980
are underneath the cross-role collaboration, I think is a really major challenge.

383
00:44:33,540 --> 00:44:40,820
Nariah that I wanted to talk with through with you is the role of the notebook overall.

384
00:44:40,820 --> 00:44:46,980
It's maybe circling back to the very beginning of the conversation. But this is I think a

385
00:44:46,980 --> 00:44:53,940
conversation that's happening fairly broadly in our community. And that is, you know,

386
00:44:53,940 --> 00:44:59,060
often comes up as, you know, our notebooks, the right tool for machine learning or, you know,

387
00:44:59,060 --> 00:45:06,900
notebooks versus IDE's. And, you know, when you think about Canvas in the mix, you know,

388
00:45:06,900 --> 00:45:13,700
maybe the question is, you know, no code versus notebooks versus IDE's. How do you react to

389
00:45:14,500 --> 00:45:22,340
those types of questions? Yeah, this is a great one. So first, I'll tackle the question of

390
00:45:22,340 --> 00:45:29,300
when should you use a notebook versus IDE or is the notebook a substitute for the IDE?

391
00:45:30,180 --> 00:45:38,740
And really here, I think that the question to ask is, what is the fundamental activity or task

392
00:45:38,740 --> 00:45:44,340
you're performing? And in the case of an IDE, typically that task is that you're building something.

393
00:45:44,340 --> 00:45:50,260
You're building software, you're building a service, an API, a software product. And so the

394
00:45:50,260 --> 00:45:57,780
fundamental verb of an IDE, I would say is build. Now, maybe the secondary verbs that would be test,

395
00:45:57,780 --> 00:46:04,980
deploy, debug, et cetera, that go along with that. Whereas if you look at a notebook and what

396
00:46:04,980 --> 00:46:11,700
the notebook was built for and how people use it, I would say that build is probably not even

397
00:46:11,700 --> 00:46:19,460
secondary. And so what is the sort of fundamental activity? I think it's really that the notebook

398
00:46:19,460 --> 00:46:26,340
is a tool for thinking with code and data. That when a user's working with a notebook at the end

399
00:46:26,340 --> 00:46:33,620
of the day, they're trying to work in parallel with the computer to understand what is in the data

400
00:46:33,620 --> 00:46:39,060
and what they might predict. And what the meaning of that prediction is, is their causation there,

401
00:46:39,060 --> 00:46:44,740
is their bias. How can they use this to explain the result? Do they trust the prediction that the

402
00:46:44,740 --> 00:46:52,020
model is making? Can they use it? Essically, these are all human questions. And so the notebook

403
00:46:52,020 --> 00:46:58,180
really is a tool for thinking. And when you have this perspective, there's not really any confusion

404
00:46:58,180 --> 00:47:04,260
between an IDE and a notebook. There are two different tools that are used for two very

405
00:47:04,260 --> 00:47:12,980
different tasks. In the same way that an SUV and a two-seater sports car are two very different

406
00:47:12,980 --> 00:47:19,460
vehicles use for a different set of purposes. And if you try to take an SUV and drive it and get

407
00:47:19,460 --> 00:47:24,260
the sports car experience out of it, it's going to be pretty disappointing and vice versa.

408
00:47:25,460 --> 00:47:31,140
And so when I want to hear people sort of complaining that Jupiter's not a very good IDE,

409
00:47:32,020 --> 00:47:38,020
my sort of the filter I read that with is more along the lines of someone saying that an SUV is not

410
00:47:38,020 --> 00:47:45,780
a very good sports car, namely, yeah, it's not. It wasn't designed to be, Jupiter was not designed

411
00:47:45,780 --> 00:47:52,180
to be an IDE in the same sense that it's used for building and deploying and debugging software

412
00:47:52,180 --> 00:48:01,140
products. With that said, there is a gray zone where users start to work in a notebook interactively

413
00:48:01,140 --> 00:48:06,020
thinking about code and data. And at some point, a project gets to the point where it's mature enough

414
00:48:06,020 --> 00:48:14,900
that people start to build things. That transition is still really painful. And it's painful whether

415
00:48:14,900 --> 00:48:22,260
you try to keep working in Jupiter or you go from working in Jupiter with notebooks over traditional IDE.

416
00:48:22,820 --> 00:48:28,980
And I think that's a major area of innovation that there's a lot of potential for the Jupiter

417
00:48:28,980 --> 00:48:34,260
open source community and others to dive into and figure out what does this transition look like

418
00:48:34,260 --> 00:48:40,420
from thinking with code and data to building software products. And how do you make that transition

419
00:48:40,420 --> 00:48:49,620
and work in that sort of in between zone? Yeah, I was thinking there are a number of efforts,

420
00:48:49,620 --> 00:48:55,620
you know, taking different approaches to try to productionize the notebook.

421
00:48:55,620 --> 00:49:04,900
And I'm sure you've seen these as well. And up until the very end of your comment, I would have

422
00:49:04,900 --> 00:49:09,620
thought you were thinking that those are all misguided. But it sounds like rather,

423
00:49:10,980 --> 00:49:14,980
there's just attempts to figure out this confusing thing that we don't really know what it needs to

424
00:49:14,980 --> 00:49:22,020
look like just yet. Yeah, there's a number of efforts in the Jupiter open source community and

425
00:49:22,020 --> 00:49:28,340
other open source projects around taking notebooks and using them in a more production oriented way.

426
00:49:29,460 --> 00:49:38,020
So one idea that's a it's a Jupiter sub project called voila, it allows users to tag cells in a

427
00:49:38,020 --> 00:49:43,620
notebook and then turn those cells into an interactive dashboard that looks like a web application,

428
00:49:43,620 --> 00:49:48,820
does not look like a notebook and deploy that to users. So that would be more of a human oriented

429
00:49:48,820 --> 00:49:55,860
deployment of a notebook to a group of users who never want to look at the code and and the

430
00:49:55,860 --> 00:50:01,140
notebook, but who want to interact with the outputs of that notebook. Maybe another example,

431
00:50:01,140 --> 00:50:06,820
as you brought up was idea of scheduling notebooks. And that is that that at some level,

432
00:50:06,820 --> 00:50:12,260
you can write a notebook like you can write a Python function, a notebook could be parametrized

433
00:50:12,260 --> 00:50:16,580
by a set of arguments. And then you might want to run that notebook for a different set of

434
00:50:16,580 --> 00:50:23,860
arguments on some schedule. And both of those usage cases are things that we're seeing. And I think

435
00:50:24,820 --> 00:50:32,740
different Jupiter users and AWS customers are doing things like that. I think the more

436
00:50:33,620 --> 00:50:37,860
challenging cases in this space are where you want to

437
00:50:39,540 --> 00:50:44,740
build a machine learning model initially in a notebook, but eventually transition to

438
00:50:44,740 --> 00:50:51,540
building a model as part of a broader pipeline that leads to the deployment of a model with an end

439
00:50:51,540 --> 00:50:57,620
point, that transition between a notebook and the more traditional building that you do in an IDE

440
00:50:58,180 --> 00:51:04,420
is still quite painful. And I don't know that these notebook-driven dashboards or notebook

441
00:51:04,420 --> 00:51:10,660
scheduling are really the right answer to tackle those. Before we wrap up, I wanted to cover another

442
00:51:10,660 --> 00:51:18,660
of the announcements that was made at ReInvent. And that is the new Amazon SageMaker Studio Lab

443
00:51:19,300 --> 00:51:25,380
product that you and your team worked on. Tell us a little bit about Studio Lab and how it came about.

444
00:51:25,380 --> 00:51:31,220
Yeah. So as you mentioned, Amazon SageMaker Studio Lab was launched at ReInvent this year.

445
00:51:32,020 --> 00:51:38,100
And the origin of this really comes back to the following question. And that is

446
00:51:38,100 --> 00:51:43,700
what's the minimum set of things that someone needs to get started with machine learning?

447
00:51:44,420 --> 00:51:48,740
And I'm using the phrase getting started with machine learning very broadly here. This could be

448
00:51:49,860 --> 00:51:54,980
students who are learning about machine learning and data science in a university class.

449
00:51:54,980 --> 00:52:00,100
They could be learning on their own in a self-paced way. Or it even extends to

450
00:52:00,980 --> 00:52:07,220
people who already have a good amount of machine learning expertise and are more enthusiast. And not

451
00:52:07,220 --> 00:52:13,060
doing machine learning though in enterprise context where they have a support staff that maintains

452
00:52:13,060 --> 00:52:18,500
cloud-based infrastructure for them. And really, if you look at how people learn machine learning

453
00:52:18,500 --> 00:52:24,340
these days, there's a small set of things they need. One, they need notebooks. They need some

454
00:52:24,340 --> 00:52:31,140
way of using Jupyter notebooks. Two, they need open source packages for machine learning.

455
00:52:31,140 --> 00:52:38,900
They need tools such as NumPy, Pandas, TensorFlow, Scikit-learn, PyTorch, etc.

456
00:52:39,620 --> 00:52:45,220
And then they need some place to run the code. They need compute of some sort and storage that

457
00:52:45,220 --> 00:52:52,980
goes along with it. And those basic ingredients are really what is how we approach SageMaker Studio Lab.

458
00:52:52,980 --> 00:52:59,460
So it really is an abbreviated version of SageMaker Studio that provides a notebook-based

459
00:52:59,460 --> 00:53:06,900
development environment for users where they can use a Jupyter Lab-based environment.

460
00:53:07,460 --> 00:53:15,220
And we offer free compute and free storage along with this. And so the real significance here

461
00:53:15,220 --> 00:53:22,260
is that users don't need to have an AWS account for this. They can sign up with an email,

462
00:53:22,820 --> 00:53:28,820
no credit card required. There's a simple account approval step that takes a few hours.

463
00:53:28,820 --> 00:53:34,180
Once you have an account, you get 15 gigs of persistent storage for your project.

464
00:53:34,820 --> 00:53:42,260
And then you can attach that storage to either a CPU or a GPU runtime and do data science

465
00:53:42,260 --> 00:53:48,340
in machine learning and work with it in that context. And it's all free. And because there's

466
00:53:48,340 --> 00:53:54,100
persistent storage behind this, even though we obviously behind the scenes, we shut down the

467
00:53:54,100 --> 00:53:59,380
instance when you're not working, when you come back, all your files will still be there. And so

468
00:53:59,380 --> 00:54:05,460
this is a real file system that's persistent and allocated to your project. You can check out

469
00:54:06,660 --> 00:54:12,180
Git repositories locally. You can install Python packages persistently and save your data sets

470
00:54:12,180 --> 00:54:18,660
and notebooks, notebooks alongside of all those things. And is it from the perspective of

471
00:54:18,660 --> 00:54:32,020
building the products for the intended scale? Is it a, how did you think about this as a product?

472
00:54:32,020 --> 00:54:41,700
Is it a ground up effort starting from components like EC2 and all the other components that AWS

473
00:54:41,700 --> 00:54:49,220
has in Jupyter or, you know, is it a starting from SageMaker and kind of trim back? How should we

474
00:54:49,220 --> 00:54:54,420
think about the way this came together? Yeah, that's a great question. So when we built Amazon

475
00:54:54,420 --> 00:55:01,140
SageMaker Studio, that was launched at Reinvent two years ago, we built a platform that enabled us

476
00:55:01,140 --> 00:55:07,300
to build these types of applications where you have an interactive user interface connected to

477
00:55:07,300 --> 00:55:14,820
compute underneath with a persistent file system. And so that platform was already there with

478
00:55:14,820 --> 00:55:21,700
SageMaker Studio. And we've reused that platform for SageMaker Studio Lab. Now there's some key

479
00:55:21,700 --> 00:55:27,540
differences between the two and some common points. I'll start with the common points. So part of

480
00:55:27,540 --> 00:55:35,140
the reason we built this platform for SageMaker Studio was that when we talked to customers,

481
00:55:35,140 --> 00:55:40,900
they had security needs that could not be satisfied in a traditional Kubernetes environment.

482
00:55:41,540 --> 00:55:48,900
And so the platform that we're using for SageMaker Studio and for Studio Lab is we're not using

483
00:55:48,900 --> 00:55:55,380
Kubernetes. It's based on instances. Our customers have told us that they need instance level

484
00:55:55,380 --> 00:56:01,780
isolation from a security perspective. And so a lot of the work we've put in on the SageMaker

485
00:56:01,780 --> 00:56:10,020
Studio side with encryption at rest, encryption at transit, VPC support, instance level isolation.

486
00:56:10,980 --> 00:56:16,820
We've been able to take that and apply it in the SageMaker Studio Lab case. And so one of the

487
00:56:16,820 --> 00:56:23,300
sort of hidden features of SageMaker Studio Lab, even though it's not focused on large enterprise

488
00:56:23,300 --> 00:56:29,220
usage cases, it still has all the enterprise security instance level isolation that we have on

489
00:56:29,220 --> 00:56:36,820
the SageMaker side of things. So we we're able to reuse that. A lot of the the magic of this

490
00:56:36,820 --> 00:56:44,580
platform is because it's instance space, there's a potential for to take a long time to start

491
00:56:44,580 --> 00:56:52,420
instances. We've done a lot of work and innovated pretty incredible stuff that enables the

492
00:56:52,420 --> 00:56:57,460
instance start times in SageMaker Studio Lab to be fast enough that it's not really going to get

493
00:56:57,460 --> 00:57:02,820
in the way of most people. Obviously, it can't be hundreds of milliseconds or something like that,

494
00:57:02,820 --> 00:57:08,020
but it's fast enough. I find when I'm using SageMaker Studio Lab that the the runtime

495
00:57:08,980 --> 00:57:13,300
an instance start time is fast enough that I don't really think about it. And so we have been

496
00:57:13,300 --> 00:57:20,820
able to reuse that platform for SageMaker Studio Lab. And the other point where the enterprise

497
00:57:20,820 --> 00:57:26,500
security is important is that we wanted SageMaker Studio Lab to be a place where we could tell users

498
00:57:26,500 --> 00:57:33,620
it's fine if you want to install your AWS credentials to another AWS account that you have a paid

499
00:57:33,620 --> 00:57:40,980
AWS account and make calls out from the AWS SDK or command line from SageMaker Studio Lab.

500
00:57:41,540 --> 00:57:46,820
And if we didn't have that enterprise security in place, we could not tell users great install

501
00:57:46,820 --> 00:57:54,660
your AWS credentials on the on Studio Lab. Does that mean that there's a key store feature or that

502
00:57:54,660 --> 00:58:02,020
you consider the instance level security to be robust enough that I can just put my

503
00:58:03,140 --> 00:58:10,660
AWS keys in a cell in the Jupyter Notebook. So please don't put your credentials in a cell in

504
00:58:10,660 --> 00:58:22,020
the Jupyter Notebook. That is definitely an anti-pattern. And we regularly see customers who do that

505
00:58:22,020 --> 00:58:27,620
and then later forget about it and version control the notebook in the end of yeah the credentials

506
00:58:27,620 --> 00:58:39,780
end up on GitHub. So that's why I was asking. It's a great question. So the model is that your project

507
00:58:39,780 --> 00:58:48,260
gets 15 gigs of persistent storage and that storage is encrypted. And so you can install your AWS

508
00:58:48,260 --> 00:58:55,380
credentials just like you normally would on your laptop. And because the entire drive is encrypted

509
00:58:56,260 --> 00:59:01,860
and we handle it with all the necessary security precautions, you can install your credentials

510
00:59:01,860 --> 00:59:08,180
that way. But yes, putting them directly in a notebook obviously is not a recommended.

511
00:59:08,180 --> 00:59:13,140
In theory, not because it's any less encrypted, but because you're more likely to put it

512
00:59:13,140 --> 00:59:18,740
someplace where it shouldn't be. Yes, if you never move a notebook out of SageMaker Studio Lab,

513
00:59:18,740 --> 00:59:23,300
that notebook will be saved on that same encrypted volume and it will be fine. The risk is more

514
00:59:23,300 --> 00:59:29,140
that that users would later do something with the notebook that expose those credentials outside

515
00:59:29,140 --> 00:59:37,540
their original context. Maybe just one more kind of to wrap things up. Where do you see all this going?

516
00:59:37,540 --> 00:59:43,140
What are you most excited about in terms of the future of ML development and

517
00:59:44,900 --> 00:59:49,700
human computer interfaces for machine learning? I'll answer this personally.

518
00:59:51,460 --> 01:00:01,140
And for me, I thrive on ambiguity and challenge. I want to be working on things where the answer

519
01:00:01,140 --> 01:00:08,340
is not known, or it's not obvious, or there's significant challenges involved in coming to an answer.

520
01:00:10,340 --> 01:00:16,580
I, when I look at this space, the amount of challenge in ambiguity that we have left is vast.

521
01:00:17,380 --> 01:00:21,860
And so I find a lot of just a lot of enjoyment in working in a space where there's so many

522
01:00:21,860 --> 01:00:27,460
unanswered questions. And some of it, this does come from my background in physics and

523
01:00:27,460 --> 01:00:35,780
I love physics. And at the end of the day, I'm probably still a physicist. One of the challenges

524
01:00:35,780 --> 01:00:44,500
in physics, though, is that as the field has grown and more and more is known in the physics space,

525
01:00:44,500 --> 01:00:50,500
there are fewer and fewer unanswered questions that are available to be answered that are really

526
01:00:50,500 --> 01:00:56,900
deep and interesting. Now, there are some obviously, but you really have to hunt in physics, honestly,

527
01:00:56,900 --> 01:01:02,660
is my, my sense as a physicist is that you have to work really hard to find good problems to solve,

528
01:01:03,300 --> 01:01:08,820
whereas in this space, there's an abundance of problems. And they're all really challenging

529
01:01:08,820 --> 01:01:13,780
and really interesting. And there's a lot of people who will benefit by solving those problems.

530
01:01:13,780 --> 01:01:19,060
So that, that's what I'm excited about in terms of looking forward in this space.

531
01:01:19,540 --> 01:01:25,940
Awesome. Awesome. Brian, thanks so much for joining us and sharing a bit about what you've

532
01:01:25,940 --> 01:01:33,380
been working on and some of the new stage maker and studio announcements coming out of reinvent.

533
01:01:34,100 --> 01:01:38,180
Thank you so much, Sam. It's really great to be here and talk to you about all these things.

534
01:01:38,180 --> 01:01:44,660
And I appreciate your time and questions about the early history of Jupiter, which is really a fun

535
01:01:44,660 --> 01:01:56,100
story to tell.

