Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington, they say that time waits for no one and that is also true
of our discounted pricing for the upcoming Twimblecon AI Platforms conference.
If you've been holding off on getting registered, you have until midnight tonight, that's
Friday, September 6th, to take advantage of our early registration rate of $5.99.
With your registration, you'll see my keynote interviews with industry luminaries like Andruing.
You'll get presentations and panels from presenters at great companies like Levi Strauss,
Capital One, Twitter, StitchFix, Airbnb, Nvidia, and a whole bunch more.
And you'll get to meet and network with an amazing community of folks that includes
our speakers, a bunch of former podcast guests that'll be in attendance, and your peers
working at the cutting edge of building and enabling real-world enterprise machine learning
and AI.
To register, visit twimblecon.com slash register.
And while you're there, hit me up on the chat where I'd be happy to answer any questions
or provide an extra special podcast listener only discount for you.
All right, on to the show.
All right, everyone.
I am on the line with Brian Burke.
Brian is a senior analytics specialist at ESPN.
Brian, welcome to this week in machine learning and AI.
Hi, Sam.
Thanks for having me.
Just as we started, you mentioned that you've been listening to the show for a couple of
years.
That being the case, you know that we speak to a lot of folks with really varied backgrounds
on the show, but I think this may be the first time that we've ever talked to someone
who started their career as a jet pilot, or at least no one's mentioned it thus far.
How did you get from being a jet pilot to working in deep learning?
I'd love to hear the story.
Yeah, sure.
I left the Navy in around 2005 and did some work in the defense industry.
After flying jets in the Navy off of carriers, what I was doing was pretty boring.
I had a lot of spare, you know, megahertz left over at the end of the day.
And I was a big football fan.
I noticed that the kind of the level of statistical analysis and common in the media was pretty
lacking.
I was pretty frustrated with it.
I was like, the Navy had earlier had sent me to graduate school and put me through a program
that was heavy in statistics.
I had never used any of those in my career in the Navy, but once I left, I said, why don't
we use some of the stuff that the military uses to win battles and wins wars to help
win football games?
And that was pretty ignorant of the money ball revolution and Sabre metrics and Bill
James.
I was completely unaware of that stuff.
So it was kind of, but that was a big advantage because a lot of the baseball people were
looking at football research and they were trying to use that same cookie cutter on football
and just didn't work.
It's a very different kind of sport.
I kind of had this military background that was more appropriate way of looking at it.
It was kind of two players, zero sum game theory approach.
And you know, kind of like we say in a dogfight, like, you know, it's a it's a knife fight
in a phone booth.
You know, one guy's not going home that day.
So that's kind of like that's kind of like a football game.
That's football is probably the most, you know, martial sport there is.
So that's what the motivation was.
So I had some software left over from, you know, the trial period had ended from grad school
and I was having a debate.
I remember with a coworker of mine and we were talking about this defense win championships.
And we were just going around in circles, just like most water cooler conversations like
that.
And I said, wait a minute, we can answer this.
Let's just download the stats.
I've got the software left in where we'll run over aggression.
We'll have an answer by the end of lunch.
And I just I love that.
Yeah, I just got hooked.
And I was like, we can do more.
Oh, we can predict games with this.
We can do all these sorts of things.
And so I really got in on the ground floor of football analytics and a lot of the core
models that are that are in use today throughout the league, you know, that the teams use
themselves, I was I was the developer of things like that.
So expected points, win probability model, some of the core metrics that all came out
of that period.
So a few years later, did you, you know, is it still as easy as, hey, let's just run
a quick regression on that?
Or did you learn from from that initial experience that it's there's a lot more to it?
Well, that was that was it.
I mean, it was I was mostly self taught a lot of these modeling approaches.
And the world has really changed since 2005, just the explosion of data and tools and
modeling approaches.
And so you have to learn them as bad as quickly as they come out.
And the paper we'll talk about today was no exception.
I had to go learn, teach myself neural networks, just to kind of keep up with the state of
the art.
Yeah, well, let's dive into that.
You wrote a paper called deep QB deep learning with player tracking to quantify quarterback
decision making and performance.
Tell us a little bit about the background of that paper.
Well, at ESPN, we got access to player tracking data from the National Football League.
So we have up to about four seasons worth of data now.
We had about two and a half at the time into the paper.
It's proprietary data.
There are chips on each shoulder pad of each player and in every game for every play.
And so we have a really accurate position, velocity, acceleration, orientation, data at
10 hertz, 10 times per second, it updates.
So and it's almost real time too.
So we had there's an API we can tap into.
And so when we got access to this data, this was even before the teams had access.
So it was it was a lot.
It was kind of the first true big data set that we had to wrestle with at ESPN on the
sports side.
How long have those chips been been in the, you know, been available?
I think it's 2016, I think was the first full season that they did it.
Yeah, so I think we have four full seasons now.
And it was, I think the first season was a little bit more of a trial and the data is
a little bit spotty, but 17, 18, 19, they've been improving it.
So, so we got this data, we were like, well, we have to exploit it somehow.
That's, that's getting advantage.
What are we going to do?
We came up with some, some pretty good ideas.
Some things, some of our best things aren't even kind of machine learning.
It's just simple geometry.
So we can analyze blocks, for example, like, before we do that, I'm like, I'm trying
to figure out the scale of this data in terms of, you know, number of teams, by number
of games, by number of players, by 10 measurements a second.
Can you help us kind of think through, you know, or get a sense for how much data we're
actually talking about here?
About one game would be about four gigabytes, I guess.
So we can put, you can put one game at a time in your laptop and kind of chew on it.
So that's kind of what I do.
Okay.
Yeah.
So, yeah, to span across games, though, you have to, you have to really digest, you know,
I would say 80% of the effort on this project was just digesting the data and processing
it in a way that was manageable for, for analysis.
You mentioned an API, like, are you going and downloading all the data from a giving game
or do you need to, like, collect it in real time or something like that?
No, it doesn't need to be collected in real time, although it could be.
And we have been doing that for some spot analysis.
So for money and I football, for example, okay.
But yeah, we will, you can go back and get past games as well.
So the system is called Next Gen Stats, that's the NFL's brand for the stats.
It's highly proprietary, but as a media partner at the NFL, you know, we negotiated access.
And so, yeah, we typically, I think we download a play at a time.
Okay.
And is the API or the, does the API allow you to download a specific play or do you have
to do, like, play segmentation on your own at the game level to figure out, you know,
when a play starts and when a play stops or do they, like, code that when they're collecting
the data?
No, they code that.
Okay.
They do an excellent job.
I can't give them enough credit.
So the certain events are tagged as well.
So when the snap occurs, when there's, when the huddle breaks, you know, when a tackle
occurs, all these, all these events are tagged.
So we don't have to do a lot of our own kind of tagging.
Okay.
Okay.
Great.
Yeah.
So apologies for interrupting you.
I just, it was kind of curious about the data that you're working with.
So you're saying that some of the things that you're working with, you know, don't
even require a machine learning.
You're able to do things just based on the geometry of the, is it the player formations
that you're looking at from a geometry perspective?
But that's one thing you can do, yeah.
So for example, one of the keys advantages to the Los Angeles Rams offense last year was
they were doing a couple of things.
They would sprint from their huddle straight to the line of scrimmage and snap the ball
real quick.
And that wouldn't give defense as times to kind of swap what we call strong and weak sides
and do a lot of last second preparation before the ball snapped.
The other thing they would do is compress their formations, very tight formations, which
made it difficult for past coverage players to play man-to-man defense.
So it forced the hand of the defenses.
So just very simple things, we could just measure the time between the huddle break and when
the ball snapped for all the different teams and see which teams stand out and do analysis
like that that doesn't really require any sort of number crunching beyond simple, you
know, averages, you know, summary statistics or, you know, the width of form, you know, mean
width of formations for different teams and see how things stand out.
My favorite thing so far has been something that's been a bit of a holy grail on football
for a long time, which is stats for linemen.
So so much of football is kind of what we say in the trenches and it's these, these, the
big guys who get no credit, you only hear their name when they mess up but they do so
much of the work to make teams successful.
But there's no real statistic, maybe for defensive past rushers, they're sacks and some other
things like that, but they're not very telling, they're not very representative of overall
performance.
So what we did was we created a past blocking and past rushing metric that just looked
at the geometry of the player.
So I can tell who's blocking who, I can see who's being double teamed, I can see how
long blocks are being held.
So part of the problem in football is they're analyzing things the wrong way.
You have to look at an offensive line as like a survival system.
So it's like a systems engineering problem.
It's kind of like a chain, right?
And the first chain that breaks the weakest link in that chain is the one that really matters.
So we look at how long that system can survive and do analysis like that.
And it's no more than, I know if you're very, very close to me and your shoulders are oriented
to me, then you must be trying to block me.
And if I get closer to the quarterback than you are, then I've won that block or you're
holding me either way, it's a win for me.
So we can see how long those, those blocks are held and we do align in the sand just
to keep things simple at 2.5 seconds, which is average time to throw, which is kind of
benchmarking the league for how long you have to sustain a block and passing situation.
And it's really taken off.
We published like a first article about it on our website.
And that afternoon we had NFL general manager's calling looking for full lists for all the
players in the league.
Oh, wow.
Yeah, one of the things that strikes me hearing your description of this that, you know,
is not all that dissimilar from the application of machine learning and the business type
of context.
You know, traditional business type of context is you're often needing to, you know, define
the problem, formulate the problem, define the metrics that are important.
And it sounds like, yeah, I would have thought coming into this conversation that, you know,
we pretty well defined the important, you know, metrics in sports.
Although, you know, now that I'm saying that, that's, you know, the whole thing with
money ball was that we had all those metrics wrong, right?
And it was really this, you know, get on first base probability that, you know, that hadn't
really been looked at and kind of redefined the game.
We figured out, you know, is there that, you know, one standout metric, kind of money ball
metric and football?
Have you figured that out yet?
Or have you found several of these like the, the blocking example you just gave?
Well, the blocking is really just an individual performance metric, which has been football.
Baseball is really unique with exception of cricket in that it's really a simple sequential
matchup problem between kind of pitcher and batter.
And so you can isolate individual performance very, very easily in baseball.
Football is a parallel system, right?
There's 22 players on the field.
There's 21 factorial interaction terms occurring between all the players.
It's extremely chaotic.
So we can't just, you know, run over aggression on certain things and different players
have different roles, very specialized roles during plays or very different kinds of
plays.
So that's part of the, part of the distinction between, you know, the saber metrics
guys trying to get into football, they couldn't really do that.
The big breakthrough happened, I would say in 2009, and I was, I had just developed a
win probability model and was really the first one that really worked that, that didn't
give you kind of junky, you know, nonsense answers.
And I was wondering what we can do with it.
And so I thought this would be a really good decision analysis tool as far as the fourth
down problem.
So what to do on fourth down was this classic problem in football.
You can punt, you can attempt a field goal or you can try to go for it and keep the ball.
And there were, there was earlier research that said, well, you should be going for it,
so a whole lot more often, stop hunting so frequently.
That was a big believer in this research, but coaches would, we're rejecting it because
the model, those models could not handle time and score.
So depending on the time and score, you have different kind of risk tolerance.
And that makes a huge difference, especially towards the end of the game.
So we kind of went from Newtonian football analytics into relativity, football analytics,
and we could kind of adapt things for time and score.
And once we were able to do that, it basically gave us a general theory of football decision-making.
And we could, we could decide what to do on fourth down, no one to go for a two point
conversion, when to call a time out, any kind of game-level decision that a coach needs
to make, we can analyze it.
And so what allowed us to do that is that it was there, it sounds like data-driven models
based on that, but was this machine learning or was this some other kind of technique that
allowed us to get there?
And what was the before, how sophisticated was the use of analytics that, in the theory
that said that we were not passing enough?
Yeah, well, there was, there was prior research by an economist named, named Romer, not
the Nobel Laureate, but another one, he looked at using what's called an expected points
model, which takes into account kind of field position, and the point value, the net expected
point value of having the ball and having a first down at every single yardline on the
field.
From that, you could deduce, if you assume that the game is a point optimization contest
for an infinite amount of time, then that model would apply.
And that assumption of point maximization and infinite time works fairly well through
the first three quarters of a game, and when the score is relatively close.
But when a team is trailing by a lot of points, or well ahead by a lot of points, or in
the end game in the fourth quarter, when time is a big factor.
So for example, point maximization doesn't work if you, if you're down by one point, with
one second left to play, you're not going to, you don't want to optimize your points,
that might mean try for a touchdown.
You just want to win the game.
So going from point maximization to win probability maximization was this big jump.
And yes, that was a big machine learning model.
I was pretty new to all this.
R was just kind of coming online.
I used SPSS in grad school.
But what I wanted for my purposes didn't really exist.
I wanted to use non-parametric regressions.
And so I taught myself, what's they called the Excel Basic Plug-in.
Okay.
And I created my own lowest function and use that to build out the models.
And the other thing is that football scoring happens in these chunks, like seven points
and three points.
And so you can't regress over points that they're discrete chunks.
So being ahead by two points is not twice as good as being ahead by one point, for example.
You mentioned wanting to apply a non-parametric regression to this.
Why non-parametric?
Because these curves were, you could use splined regressions.
You could use, it was very non-linear.
It was not something that they say quadratics or polynomial type regression lines would
adapt well to.
So I wanted something more flexible, especially towards the end game, things get very dynamic.
And so these curves, these wind probability curves, basically the thing of a chart of maybe
the y-axis is wind probability, the x-axis is field position, and we're looking at slices
of time and score.
And so basically you get a bunch of curves, and those curves can get pretty dynamic toward
the end game.
And so this was, did you say 2009 that the wind probability model, you came out with that?
Yeah, I think I started working on that, and what I was able to do is acquire a big
library of play by play data, and that was, it was just this confluence of computing power
and tools and the data that's being available online.
So it was just kind of these things just all happened at the same time, and I just happened
to have the spare time and the interest to tackle that.
And yeah, so it was 2009, and I'll never forget, I had a brief 15 minutes of notoriety,
the Patriots, and Bill Belichick went for an infamous fourth down, a lateening game against
Peyton Manning's Colts in 2009, was November 2009.
And I was already fairly established, I was writing for the New York Times and doing
analysis for them.
And I wrote, I said, everybody thought that Bill Belichick going for it with a lead was
a fourth and two on his own, 36, something like that.
And by the book, you always plan.
And I wrote an article.
I said, no, actually, it was a good decision to go for it, even though it failed.
And here's why.
And it was just, you know, once you do, once you build the models to apply them, it only
requires a tiny bit of, you know, algebra.
And it's one line of algebra.
And the next thing I knew, Sports Illustrator was calling.
He expanded a big feature on me the next Sunday.
And so it was just by luck that this happened.
And I think that got a lot of attention throughout the league.
And teams started thinking about analytics at that point.
So I think we digress a little bit from deep QB.
So you have all this data, well, it was deep QB based on only the shoulder chip data
or there are other sources that you pulled into that model.
Well, we used some of the metadata from the play itself, so down distance, yard line.
And we also collect by hand at ESPN, we call it video analysis tracking.
And we have a human person looking at each play in near real time.
And they'll say, was this, you know, play action pass or was this a drop?
So it was a good pass.
It landed right in the receiver's hands and you should have caught it, but you just didn't
make the play.
So little things like that was added to the, added to the player tracking data.
Got it, got it.
And I think we skipped past the punch line.
What's the key problem that you're trying to solve or answer that you're trying to get
at with deep QB?
Well, I was interested in quarterback decision making.
That's probably the most mysterious yet most important part of football, especially in
the NFL where it's really a passing game and the quarterback is so important.
And that decision making, you can, you can analyze physical skills, right, like running
and jumping and strength and things like that.
But it's really hard to quantify decision making, especially under pressure in a highly
dangerous situation.
So it reminded me of my days as a fighter pilot.
I wasn't the athlete that Cam Newton is, but when I strapped an F-18 on my back, you
know, we were all Cam Newton's out there.
And we all had to make kind of life and death decisions under, you know, great dress.
And then, you know, under, under uncertainty as well.
And so I saw the parallels.
I was very interested in that and so I thought, okay, look, how would we, how would we
examine quarterback decision making?
And so what are the, tell us about the model that you came up with to, to do that?
Well, what I wanted to do is predict, use a model to try to predict which quarterbacks,
or which receiver of the five eligible receivers a quarterback would throw to.
The idea was that I wanted to identify those quarterbacks who are making good reads and
identifying the best receiver to throw to.
So this is a decision, the SMA.
He has to choose between one and five to try to throw to.
And that's the key decision I wanted to look at.
So what the model was trying to do is try to look at the play itself, look at the presentation,
the geometry, the velocities, the positions of all the players on the field and say, who
should an NFL quarterback throw to, given this picture presented to the quarterback?
The idea was, it was kind of a epistemological sleight of hand, it was like, well, these
quarterbacks are all really, really good, they're the best in the world.
So the average typical quarterback is probably making the right decision.
And therefore I'm going to compare each individual quarterback's performance, who, you know,
which receiver he does throw to with what the model suggests the best receiver to throw
to would be.
And so that was the idea.
And did your data include characteristics of the receiver or is it solely based on the
play geometry and the options available from a field position perspective as opposed to
the, you know, some kind of data talking about the receiver's performance historically
in that kind of situation?
No, unfortunately, no, the, there's really no, like, the data has no like Z axis.
So there's no, we don't know how high or how high jumps or how high the ball was thrown
or we don't, we don't know that we do know things about the receiver as far as what's
his velocities and accelerations and things like that, which his individual talents certainly
are big influences on.
So, you know, but what we don't, what we don't have is the hands, you know, some receivers
are just have better hands, they just have a knack for catching balls.
So unfortunately, you know, but we're aggregating over, you know, a large, very large data set.
So the, you know, the idea there is that it's going to average out.
So you create this model that is trained on the historical decisions that quarterbacks
make again with this assumption that they're all good quarterbacks and then you want to
be able to compare any given quarterback decision with this model to see if it was, you
know, a good decision or maybe the quarterback kind of, you know, made a bad decision under
pressure or something.
That's the general idea.
Yeah.
So the idea is to isolate the contribution of quarterback decision making to, so performance.
So we can observe the performance on the field.
We see, okay, that was a ten yard catch or that was incomplete pass, for example.
How much was the quarterback decision contributing to success and failure in these plays?
So I was thinking of a quarterback, if you're a football fan, you may be familiar with
a quarterback named Tyrod Taylor, who is infamous for overlooking open receivers.
And instead of throwing an open receiver, he was a little bit gun shy, he would take
off of running.
He was a very fast runner.
And it was not a bad quarterback, but he just got, he was, coaches were very frustrated
with him for that.
And so I thought, can we identify something like this?
Who's a good, who's making good reads and who's making poor reads?
And so let's say, in the case of Tyrod Taylor, there is a receiver that's open, the model
sees it.
It says, hey, a typical NFL quarterback has an eight would throw to this receiver, 80%
of the time.
Tyrod is throwing to some, you know, running back, who's, you know, two yards deep instead,
who the model doesn't think he should throw to.
And then we would use those comparisons to make a judgment about quarterback decision-making
abilities.
Yeah.
Does the model also work the other way, meaning can it identify quarterbacks that are able
to, you know, have a higher than normal success percentage throwing to unlikely receivers
or something like that?
Yeah, absolutely. And in fact, that's, that's what happened.
So the assumption about that kind of, you know, hand waving, I mentioned earlier, it wasn't
really true.
And what happens is, like, you want to say, like, hey, Aaron Rodgers is really good quarterback,
he makes good reads, do what Aaron Rodgers would do.
Just make the same decision he would make and you, you would tell it rookie to do that.
But that would be calamitous because that rookie doesn't have the same skills and you
have the same accuracy, the same arm strength, necessarily as Aaron Rodgers.
So Aaron Rodgers is making different reads, making more aggressive reads than, say, a typical
quarterback because he can't, right?
There's a selection effect.
And so, yeah, so, you know, the, the insight is in the difference, you know, from the, from
the predicted.
So the model is just there to establish a baseline.
And then what's interesting is, are the deviations from the base?
Right.
Right.
Like, yeah, tell us more about this model, what, what kind of model is it?
It's, it's a neural network, very vanilla.
It's just a feed forward network.
I was really just getting started and I just wanted something that would work.
So there's some other, other, you know, different kinds of models you could use.
Some of the, the previous work in soccer and basketball had, would take the player tracking
data kind of create a graphical image of player trajectories from that and then use
convolutional neural networks or LSTM type recurrent neural networks.
I just, I just took a snapshot in time and pass release and looked at the play and looked
at where the receivers were, where the defenders were, all the relative geometries and velocities
and built a, built a, I think it's this four layer feed forward network.
And at the, at the end of it, you could ask it just about any question.
So it was, what's kind of modular, I would say, tell me like we've been talking about
until now, predict which of the five receivers you think this quarterback should throw
to.
And or I could replace a predict the, the mean yardage gained you see on this play.
Or predict the whether or not this is going to be intercepted or not or completed or incomplete.
So you could ask the model the same question and the, what really surprised me was that when
I was going through and kind of tuning all the hyper parameters, all the, you know, number
of nodes and layers and things like that, it was really in, the results were invariant
to that structure, where the structure was really dependent on the, the data.
And since I was feeding it the same data, but asking it different questions, I could keep
the same network structure and just kind of change the, the final layer and get, get
very good results.
The network was relatively straightforward.
Did you, you mentioned R earlier?
Did you end up doing this in R or something else?
Yeah.
Well, it's a plug in through Python, but I used to say an Excel plug.
Yeah, no, I've graduated from those days.
I'm on R cripple.
I mean, I'm fluent in R and, but I can probably, you know, order dinner in Python, but that's
about it.
But there's a great plug in through R. So, and since I was doing all the data, building
and processing through R, it was very handy to just stay in that environment.
So, yeah, Keras with, with TensorFlow on the, on the back end, and it, it, it, it, it's,
it converged and started giving me result.
I was very surprised.
I'm my first try.
Um, I was very excited when I started getting, uh, good results.
You know, we talked a little bit about the structure of this data.
You've got kind of games that are aggregates of plays and then you've got, um, you know,
four years worth of games.
How much of this data did you use to train on and what, did you find that, uh, you know,
how much of it kind of got you to the point of diminishing returns?
Uh, well, I used all the data I could.
I didn't, I didn't really try to find out how little data I needed.
Um, so I, I got, I guess, so I was using, um, I split the data into the three parts.
So, you know, training, validation, and then test, and the test was set aside as just
the, um, the, the current season at the time.
So when I was writing up the paper, so that was the 2018 season.
So I've got about three quarters of that 2018 season is, or it's kind of a test set.
Then all the training and validation, all the tweaking and things that was done using,
like about a 70, 30 split of, uh, the, the two seasons of 2020, 16 and 17, I suppose.
And then, uh, and that, that, that was useful because the, the test results, right, which
hadn't touched any of the, the training or validation data, it'd never been seen by the
model in any, in any form.
Um, that was the current season.
So we could do actual analysis, like real world analysis using, using the test results.
Is the model trained on a play at a time or, uh, and do you, is it trained, I'm assuming
it's trained on only passing play, so you're filtering out that out based on these tags
and, and you're training it as a, on a play at a time, or is there some other structure
for the training data?
Yeah, it's, it's only passing plays.
And, in fact, it's only targeted passing plays.
So any, any plays that were kind of throw away, um, got it throw away.
So quarterback just didn't want to get sacked, so he throws it out of bounds.
Yeah.
Uh, those were discussed.
So there was no target on it.
I couldn't predict what, what the target was.
Theoretically, you could make that a sixth option.
I, I retrospect, but that wasn't really what I was interested in at the time.
Yeah.
Yeah.
And then, um, yeah.
So it's, it's trained, uh, yeah, basically a play, you know, the, the atom of this
model is, is one play.
Um, and, and, you know, but there was a batch of plays, obviously, that was fed through,
um, you know, for the, for the, for the training.
And how many plays total?
Did you have access to your data, Seth?
How, I think about a little bit foggy, but totally, about 36,000, wow.
Okay.
Plays, past plays.
Yeah.
And which I think is more than sufficient.
Um, but I also had, I, I did this trick, um, where I just took the mirror image of every
play and added that, uh, to, to the, uh, to the data, um, yet to be careful not to have
a mirror, uh, have the mirror image be both in the validation or, um, or training, right?
So you have to, you have to segregate those.
But that way you're, you're getting even, you're getting even more data, um, with the
assumption that there's symmetry, uh, to a play.
So somebody who's wide open on the right side of the field would be wide open, just as wide
open on the left side of the field.
And that's generally true, except for quarterback handedness, you can have right handed
quarterbacks, left handed quarterbacks, that might have an effect, um, but they're, they
have to be no left handed quarterbacks for the last few years.
So.
Okay.
That's an interesting approach to data augmentation.
So when you do that mirroring given the handedness of the quarterbacks, are you just mirroring
the line structure?
I guess you're, the quarterback is just a point here so that doesn't matter, right?
Yeah.
Just like I was, you know, I just picked up this common technique with, um, you know, like,
computer vision techniques, right?
So if you want to identify a picture of a dog, you know, the dog kind of looking to the
right, if you flip that image with a dog looking to the left, they're both dogs.
Right.
Um, so that, that was the idea, um, but it, it's complicated like I had to do it by hand
essentially.
So I have to, you know, do all these kind of geometric transformations, uh, including
with all the angles as well.
So, um, if you're heading, if you're heading zero, three zero on the, on the true play,
on the mirrored play, you're heading, uh, you know, three, three zero, right?
So, um, yeah, I was a little bit laborious, but, but, uh, it was in, in the interest of
eating up the, the performance metric by one or two points.
Okay.
Uh, and you mentioned that you're, you segregated your, uh, validation and test sets based
on the season, did you, uh, explore, you know, something that was more randomized or the,
you know, any kind of implications of kind of bias season to season, like over a long
time periods of time, players get, you know, better and stronger.
Does that have any effect in a, a short term season to season?
Well, yeah, I didn't do that, um, but it is well known that, um, quarterbacks to take
a jump after their rookie year.
So they're basically there, from their second year on, it's kind of their, their steady
state performance level.
So if you really want to know, like what, what, what is this quarterbacks career going
to look like?
With, with very rare exceptions, his, his second full season is very representative of,
you know, he's pretty much hit his, his steady state at that point.
So, um, but now, so because, you know, we, we, we aggregated the, the, the idea at first,
anyway, there's a fourth variant of them I'll haven't talked about, but, um, there's
a, uh, uh, it's basically the aggregation, the average quarterback, all kind of blended
into one, um, was, was kind of like the, the proto, uh, deep QB.
Okay.
And so you kind of ignored the, you know, any implications of testing based on the totally
separate season, as opposed to kind of randomized testing.
We did, we did find that the, the 2018 performance was, we're, there was a drop in performance
like you, you would typically expect, um, but there was an unusual, unusually high number
of rookies, um, there was, it was it, it was generally an up year for passing.
So there's year to year variants, um, due to things like, uh, just randomness, rule
changes, uh, injuries to some of the elite quarterbacks will change, um, overall passing,
the level of passing performance, uh, for the league as a whole year to year, uh, last
year was a, was a big up year.
Um, so yeah, there might be something, uh, to that, uh, you mentioned a fourth variant
to the model.
Yeah.
This was the coolest one, but it didn't really, it didn't work as well as I had hoped,
but it was so, I thought the idea was so cool.
I had to put it in the paper anyway, people were like, yeah, there's two longer papers
you got to cut it out, um, cut this part out and I was like, no, it's too cool.
Um, so the idea was to use, uh, transfer learning.
So, um, it's, it's kind of inspired by the same way, let's say biological brains work.
So think of quarterback has to have these very intuitive and distinctive parts of his brain
that understand things like distance and motion and, um, you know, speeds and this kind
of intuitive, uh, physics model in, in our brains and we generally share those, right?
We're all pretty good drivers, right?
We're all, you can't, you know, humans have these share these, these faculties, but we
don't all have the same decision-making, uh, I have an 18 year old son.
So I know we don't all share the same decision, he's a very, he's, he's a very good decision
maker actually for, for an 18 year old, but I was 18 once too, uh, so we don't all share
the same, um, decision-making abilities, uh, so those executive functions may tend to
differ much more than the, the lower level, uh, functions and those are the, you, you could
model it the same way with neural networks.
So the, so what I did was trained the lower level, the lower layers, lower level layers
of the model on the, on the data set as a whole, just like I had done with the, that we've
been talking about.
And then what I would do is take the, the, like the top layers, which we could think of
as the, the executive functions, the ones that, okay, we've digested this play.
We understand, um, you know, where people are and what's important to look at and the
relative velocities and things like that.
Now, let's make a decision about who to throw to.
And so those top layer, we, we froze the base layers, retrain the top layers, uh, just
on the, um, on an individual quarterback.
Uh-huh.
And then we could, we could say, we could take like a Tom Brady or like I did with a paper,
I took Drew Breeze and, um, uh, you could, you could basically download Drew Breeze's
brain into, uh, you know, into a USB, um, drive or something like that would be the idea.
And then just like we said before, like do what Aaron Rogers would do, right?
So we, now we have a model of what Aaron Rogers would do or what Drew Breeze would do, given
certain situations.
So we could actually take a situation that Tom Brady was in and replace him with a rookie
and say now, you know, what would the rookie do compared to Tom Brady in this same exact
situation?
Um, um, it was pretty ambitious, uh, the, the results weren't as interesting as I, as
I thought, um, partially because the rookie, the rookies tend to throw a lot of checkdowns,
which means they, they throw to, they throw short passes to relatively safe receivers,
um, rather than taking a lot of risks.
And the Saints offense happens to do that by design a lot, uh, they like, they have very
good running backs last year and so, uh, Drew Breeze came up, so we ran a similarity
metrics and all the rookies, uh, came up very similar to, to do Breeze, which is not
what I, I had hope to see.
And was that the only quarterback you tried to apply it to or was, or did you apply it
to all of them and you found that it was kind of similarly not all that interesting for
all of them?
Yeah.
Well, I tried some of the, uh, consensus elite, uh, quarterbacks of Brady's, um, Rogers,
um, Breeze, and I can't think, I can't remember if I did with anyone else, but, uh, you
know, I, I, I chose Breeze, the results were, were decent with him.
And so, uh, researchers, progative, that's the one I, I put in the paper.
Interesting.
Yeah.
That would have been really interesting if it were to, yeah, but it was just, it was just
the first stab.
I mean, really, this is the first, um, research like this is, uh, uh, beyond this is common
place in basketball and soccer, but this is just the first stab at it with, with football
or just kind of like, what's the, let's take a moonshot here.
If we could do something, the coolest thing we, we want to do, uh, go, go run with it and,
and see how far you can, you can carry the ball.
What are your priorities for kind of pushing this further?
Do you, do you use a relatively simple model?
Do you think, uh, kind of a deeper, you know, state of the art, CNN might perform better
or, you know, doing different things with the data and, you know, finding, uh, additional
data sources to, uh, kind of supplement what you already have, like what, what do you
have in mind for pushing this further?
Well, the, the next step would be something that we, we could run this, what first time
you say, we can run this model at 18 kind of time step in the play, you know, well before
the past actually takes place, and so we can have a continuous analysis as the plague
goes on.
Um, but it's only trained on when, when the past is actually released.
Um, the, the next step I would do if I had the time, um, would apply LSTM, um, models
to, to the data, uh, throughout the, you know, so it would be continuous from the snap
all the way, uh, through past release, and so we're accumulating information from the
entire play, not just a time sliver at, um, past release, but, but do you keep in mind
we do have velocity and acceleration information on each player, which kind of gives us, you
know, back, you know, two time steps, I guess, right, uh, worth of information.
But I think we can accumulate even more information.
I, I don't think CNN's would be, would perform as well in theory because what the CNN's are
trying to do is, is to get position and get the geometries, get the relative information
from, from a graphic, uh, and then you, you, you apply that, um, you know, further down
stream in a model, whereas we, we'd already have the X's and Y's and the distances and
geometries and angles that, CNN would have to learn along the way.
Um, so we can, uh, so I think using the raw inputs, the X Y's, the distances, uh,
some, some features that are engineered, uh, kind of relative distances to nearest past
coverage, uh, player, things like that, I think, would, uh, perform best.
And I'm curious to, the extent to which explainability has come up, um, for, for you, do you
get asked to, you know, be able to produce, uh, some justification for the predictions
that the model is making and how have you, uh, have you handled that?
Yeah, that's a tough question.
Um, you, sometimes there's some head, head scratching results, you know, you don't
under, why is the model saying that?
And most of the time, though, it's very understandable and plausible, kind of obvious, um, but
the, uh, on a case by case basis, you can look at these plays and, and, you know, make
it, make a human judgment.
Oh, if you know enough football, you understand why it's, it's making the decision it is,
the model's working the way it is.
Um, but, you know, unfortunately, explainability is a tough problem with neural networks.
Um, there, you know, if, if I had the time, what I would do is I'd build like a, an app
and application where you could kind of dial in, you could just drag and drop, um, players
on a screen.
And, uh, some of the Disney research guys I talked to had actually done this with, with
basketball, or you could kind of move the players around and then see how that affects
the, the model outputs.
And that way you can directly, um, you know, test well, if I make this player closer
to this other player, how does that affect things?
If I make them further away, if I make them faster, how does that?
So just by trial and error, you can, you can come to some form of understanding, but
some general understanding about it is, is, uh, um, a difficult task.
Awesome project or what suggestions would you have for, uh, folks that, you know, are listening
to this also have a passion for sports and want to, uh, experiment with, uh, these types
of models, uh, applied to, to sports.
Well, there is player tracking data available, um, even for football, even for NFL football,
but there are databases out there, some soccer, basketball is a little bit harder to get
a hold of.
I can't give you any, you know, I don't have a URL for you right now, but, um, except in
football.
So the NFL at the combine, um, uh, in the spring, late winter, early spring, the, at the
combine, they held a, what they called a big data bowl.
And with that, they released a subset of games, I think maybe about nine weeks, um, worth
of games, and they released that data, uh, for, um, it basically caggle type competition.
And then they, they had their winners and, um, you know, their finalists and announced
the winner there at the combine.
So that data, um, still exists out there on the, on the, on the web somewhere, so just
Google, uh, big NFL big data bowl, um, and, uh, it'll take you to, um, it'll take you
to that, that site.
And I think it's still available.
There are definite limitations on what you can do with that data.
Um, the other thing is the NFL put out a punt play data in caggle, and that may still be
available as well.
So if you're interested, um, that, that's a, that's a great place to get started, just,
just with the, with the data, um, but it, it's, uh, it's a lot to get your arm around.
You have to start, you know, learning like, okay, that zero, zero point, where is that
on the field?
Is that at the back of the end zone?
Is that, is this left oriented, right oriented?
Is it, you know, which way is the, the zero?
A degree, uh, heading access on here and, uh, is this in degrees or radiant?
You know, all those things, that takes a while.
So it's, it's definitely a chore, but, um, it was, it was a lot of fun.
Well, Brian, thanks so much for taking the time to chat with us really, really interesting
stuff.
Yeah.
Thanks for having me on, Tim.
All right, everyone, that's our show for today.
For more information on Brian or any of our guests, visit twimmelai.com.
Be sure to register for twimmelcom AI platforms right now before prices go up to night.
As always, thanks so much for listening and catch you next time.
