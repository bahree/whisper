Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting
people doing interesting things in machine learning and artificial intelligence.
I'm your host, Sam Charrington.
A quick thanks to everyone who participated in last week's Twimble Online Meetup.
It was another great one.
If you missed it, the recording will be posted to the Meetup page at twimbleai.com slash
meetup.
Definitely check it out.
I never cease to be amazed by the generosity and creativity of the Twimble community.
And I'd like to send a special shout out to listener Sharon Glander for her exceptional
sketch notes.
Sharon has been creating beautiful hand sketch notes of her favorite Twimble episodes
and sharing them with the community.
Sharon, we truly love and appreciate what you're doing with those.
So please keep up the great work.
We'll link to her sketch notes in the show notes for this episode.
And you should definitely follow her on Twitter at sharingglander for more.
This is your last chance to register for the rework, deep learning and AI assistant
summits in San Francisco, which are this Thursday and Friday, January 25th and 26th.
These events feature leading researchers and technologists like the ones you heard in
our Deep Learning Summit series last week.
The San Francisco event is headlined by Ian Goodfellow of Google Brain, Daphne Kohler
of Calico Labs, and more.
Definitely check it out and use the code Twimbleai for 20% off of registration.
In this episode, I'm joined by Inmar Gavoni, Autonomy Engineering Manager at Uber ATG to
discuss her work on the paper MinMax Propagation, which was presented at Nip's last month
in Long Beach.
And more and I get into a really media discussion about graphical models, including what they
are, how they're used, some of the challenges they present for both training and inference,
and how and where they can be best applied.
Then we jump into an in-depth look at the key ideas behind the MinMax Propagation paper
itself, including the relationship to the broader domain of belief propagation and ideas
like affinity propagation, and how all these can be applied to a use case example like
the Makesband problem.
This was a really fun conversation, and now on to the show.
All right, everyone, I am on the line with Inmar Gavoni.
Inmar is the Autonomy Engineering Manager at Uber ATG, that's Uber's Advanced Technology
Group in Toronto, Canada.
Inmar, welcome to this week in Machine Learning and AI.
Thank you, Sam.
It's great to be here.
It's awesome to have you on the show.
You've been trying to get this coordinated for quite a while, so I'm glad we're able
to make it happen early in the new year.
Absolutely.
I'm excited about this.
As is our tradition here, why don't we get started by having you tell the audience a
little bit about your background and how you got interested in machine learning?
Sure.
So, for me, it actually started pretty early on, in the sense that back in high school,
I thought I wanted to be a neuroscientist, and I was pretty sure that understanding and
researching the brain is the most interesting thing that I could apply myself to.
So going into university, I chose the areas of computer science and biology, because
I thought of brains as machines and thinking that the computer science and engineering
approaches would be useful for understanding them and biology because it is, after all,
a biological substance.
And I spend a lot of my time taking neuroscience courses and talking to your neuroscientists
and trying to understand how they approach solving the problem.
At the same time, towards the end of my undergraduate degrees of the last year, I also took a machine
learning course.
And first of all, the machine learning course was really interesting.
It was such a different way of thinking about how to solve problems that really appeal
to me.
The mathematics of it were beautiful.
It combines a lot of things that I previously learned, and they never really clicked into
one place.
So anything from linear algebra, calculus, probability theory, statistics, graph theory,
computer torques, all of it is used in one way or the other in machine learning.
And also, it allows us to solve problems that you can't really solve with traditional
programming or engineering approaches.
So it's a whole new mathematical way of looking at these problems and then coming up with
really beautiful solutions.
And as for the neuroscience, I felt like maybe instead of trying to understand the brain,
a different way of doing it would be to try and build software that exhibits intelligent
behavior.
So that drove my decision to do a PhD in machine learning.
And so I moved to Toronto, which is one of the best places in the world to do machine learning
research and did that for a few years.
And while I was in school, I did a few internships and I also realized that I really like working
towards a specific product and towards something that is tangible and is out there in the world
and people use and is also up for that type of scrutiny.
So after graduation, I worked in various companies on applications of machine learning to
real world products and I like physical things, so in all of them, there was some sort of
a physical product that you can actually touch.
And of course, self-driving cars is one of the most exciting new technologies.
I mean, maybe the technology itself is not that new or the idea of doing it is not
that new.
It's been around for about a decade at least, but it's now really coming into full attention
from everyone in the world and I thought joining this office would be an incredible opportunity.
So I've been here for a few months now.
Oh, wow.
And what specifically do you do there?
So the office in Toronto is a research and development office.
It's led by Raquel Ortison who is one of the world experts in the intersection of self-driving,
deep learning and computer vision.
And there is a research group of researchers who are working on creating new innovative
cutting edge algorithms for using deep learning for self-driving.
My role is helping take this product, this research prototypes and first phase algorithms
and actually get them into the car.
So get them into production.
Oh, wow.
I manage a team of applied researchers and software engineers who help with everything
that has to happen in order to take a prototype, something that resembles what you would get
out of a publication and actually make it into a production feature.
Hmm.
And we've talked about, we did a series on autonomous driving last year, I think in the fall
towards the end of last year, and one of the things that jumped out of that was the different
approaches and philosophies to doing machine learning for autonomous driving, kind of,
you know, N10 versus integrating different systems, you know, versus, you know, and camera,
camera first versus, you know, sensor fusion approaches.
Does Uber have a kind of a, what's Uber's approach to?
Autonomous vehicles and in that domain.
So we're definitely as a place that specializes in deep learning.
We believe that deep learning approaches for the various aspects of technologies you
need to introduce, you know, around perception, understanding where the car is understanding
who the actors are, can all benefit from deep learning in terms of what kind of architecture
specifically or, you know, the sensors and so on.
I think this is still something that is an ongoing research and understanding what are the
benefits of the different sensors and when is there a time to use them and in what configuration?
So I would say that's still an open question.
And so one of the things that we wanted to dig into in this conversation was a paper that
you co-author that was released that nips or was in the nips proceedings on minmax propagation.
One of the things that I observed that nips was a lot of conversations around graphical
models and graphical approaches in general for machine learning.
And as maybe a segue into that conversation, I wanted to get a sense from you, is that,
would you say that there was a kind of heightened interest in graphical models this year or
is it a conversation that has been, you know, continuing on, you know, without, I guess
is there a heightened level of interest in this particular type of modeling approach?
Right.
So here is my take on it.
Visual models are very powerful mathematical tools to represent our understanding of the
world and our understanding of what we don't understand and the fact that there is uncertainty
and noise.
So as modeling tools, they're very powerful.
The problem has been that they're very difficult to train and to do learning and inferencing.
So they are computationally expensive and they do not scale up to full blown industrial
purposes.
So it was a, there has always been, not always, but you know, there's been an ongoing
flourishing and research in graphical models for a long time.
I entered the field doing research.
I would say around 2006 and these were very popular and like a big area of focus and
in fact my thesis focuses on application of graphical models to clustering.
Okay.
But it remained within, I would say primarily within academia with the exception of specific
models that were simpler to use than others and were used in industry.
And then we had, you know, over the last few years, obviously, we had this intense focus
on deep learning and neural networks and a lot of people worked on them.
And people shifted from working sound graphical models to focusing on innovation in deep learning.
And I think now that we are kind of getting to a place where a lot of the groundwork has
been done and a lot of the, let's call it the low hanging fruits have been picked.
Now there is going interest in looking again at graphical models and then asking, given
all we've learned about how to do deep learning at scale and how to use it and how to be
able to solve difficult problems with it, can we now merge better the two strategies and
can we create new types of models that leverage the leverage both so that maybe graphical models
can become as useful as deep learning models.
And what are the types of applications that lend themselves most readily to use of graphical
models?
There are many different applications, one that is commonly I would say looked at is in,
let's say, healthcare.
So understanding or predicting whether a particular patient has that particular type of cancer,
you can describe all that you know about the different measurements you've taken and
so on using a graphical model and then you can try to infer the actual underlying state
of their illness if they have on the type, the stage and so on.
And the main idea as I understand it behind the application of graphical models is as
opposed to traditional, I guess traditional, we'll start with calling it traditional,
with a typical data set, let's say where you've got data points and the data set doesn't
really express any inherent relationship between the data points as opposed to a relationship
between you know features within those data points within, well graphical models are
really trying to do is identify relationships between the data points and the data set
is that an accurate assessment?
Yes, yes, they deal with representing all sorts of quantities in the world as variables
and either explicitly saying that there are known complex relationships between these
variables or trying to learn the complex relationships between these variables.
And when you say explicitly saying that there are known complex relationships is, are
you there describing kind of pulling in prior knowledge about the relationships between
these variables into the models or?
Yeah, that would be one way of doing it where you represent all sorts of prior knowledge
given with distributions that you believe are well suited to represent your prior knowledge
and also representing the actual relationships between the variables.
So if we're trying to think of a relatively simple example, let's say that I'm trying
to represent an image in terms of a graph.
So maybe every pixel in the image will be a node in the graph and every pixel will be connected
to the pixel that are around it and these connections, these edges on the graph represent
the fact that we think that the value of the pixel is highly correlated to the value of
the pixel or is around it, right? So for example, if we know about the pixels around it,
we can make guesses as to the value of the pixel or we can represent the possible values
of it as a distribution that is not uniform, it learned, it knows something from it's
surrounding.
So that would be one way of representing relationships between variables.
And our images is that a common application area for graphical models?
So images used to be before we were able to successfully work with neural networks.
But in terms of performance right now, I would say that convolutional neural networks
are much better at tasks around predictions and prediction and detection and various tasks
that have to do with images.
So what have been some of the biggest achievements to date of this renewed interest in graphical
models with the background of the progress and deep learning over the recent years?
I think one interesting idea is to allow for neural networks to operate over graphs.
So there is a new researcher in graph neural networks and graph convolutional neural networks.
And other ideas are that within the network queue represents some of the new model, some
of the network explicitly using some formulation of a graphical model.
And so what does it mean to have the network operate over a graph?
So again, going back to the example of images.
If you think about it as a graph, it's a grid, right?
It's a simple graph and so we can very easily do operations on it like convolutional operations
because we just shift them, shift the filter over and it's the same operation.
But you can also obstruct this notion of a convolution to something where it's not
a nice grid, but it's still a graph.
So but that requires the mathematics to be developed for it and to be made efficient.
So then so is the idea then to kind of replicate what a convolutional network is doing, but
with graphical models?
Not necessarily.
It's just to use the, I guess the body of knowledge and work from graphical models and maybe
we can get into inference a little bit in a moment.
So for doing inference in graphical models, that is not really captured within neural networks.
So so neural networks, people talk about doing learning and inference in neural networks,
but really I think that it's come to mean that learning is when you train the algorithm.
Right.
And inference is when at test time you basically run forward propagations, your network
can come up with a prediction.
You know, it's it's a correct use of the term, but it's in the context of neural networks
that the inference part is easy because it's just a straightforward calculation.
Sometimes computing this prediction, so computing in the case of neural networks, like what
is the probability that there is a particular object in the image, let's say, right?
And then it speeds out a probability of whether it's there or not in this particular place,
let's say.
So in some cases, let's say when when the underlying model is a graphical model, computing this
probability is in and on itself a difficult sub problem.
And then there is a large body of work on computing, running this algorithm.
And in some cases, in particular, in graphical models, the within training itself, so not
just when you're a test time, you're interliving the learning and inference part.
So the learning is often referred to coming up with estimates over the hidden variables.
And we didn't really talk about what hidden variables are, but sorry, coming with estimates
of the parameters governing the behavior of the hidden variables, the parameters in
a neural network would be the weights.
And so we're learning, we're basically optimizing the weights.
And in graphical models, the parameters can be, for example, parameters that govern
distribution.
Like, I assume that there is a Gaussian and I don't know what is the mean and the variance
of the Gaussian.
So that would be the parameters that I'm trying to learn.
But then there is also an inference part, which is computing all sorts of typically predictions
or probability distributions on the variables of interest and that requires running some
sort of a sometimes complex computation.
And when I'm done with that, I sometimes iterate back to the learning part.
So given that I've refined my estimate of the probabilities, now I refine my estimate
of the learning part of the parameters and go back and forth between the two.
So what I've just described is a very high level and algorithm called the expectation
maximization algorithm or EM algorithm, which is used for doing learning and inference in
graphical models like a Gaussian mixture model, for instance.
And if you want, we can talk a little bit about what is a Gaussian mixture model.
Yeah, before we do that, so the expectation maximization that you were just just describing,
this is trying to contextualize this.
We were talking about training and inference and you started to talk about inference.
But this is, this is used as part of training, but it includes inference calculations.
Is that the?
Yeah, so again, in non neural network world, where you're talking about the training procedure
itself may include both learning and inference.
Got it.
And so you need to maybe the Gaussian mixture model is a good example to run through for
that.
So in Gaussian mixture models, we basically have a whole bunch of data.
It's a way of clustering the data, let's say.
So in clustering, we assume that the data can naturally be divided into groups, right?
Or clusters.
And what makes a good cluster is that the points in the cluster are quite similar to each
other.
And they're quite different from other points in other clusters.
But now that I'm given a whole bunch of data, how do I go about actually finding these
different clusters?
And in a Gaussian mixture model, I basically make an assumption that there was some process
that generated the data.
Which is, let's say that the data happens to have five clusters.
So so someone, you know, flipped the coin or all the dice and sampled the centers of
the clusters.
Right.
Right.
And then from each center, a bunch of data points were sampled, but there are some noise
involved, right?
And so now if all I get to see is the end result is I get to see a lot of points and I need
to infer.
I need to learn the parameters, so I need to learn the means of the clusters, the centers
of the clusters and their variances, how noisy the cluster are.
And then I need to infer the probability that each point came from anyone particular cluster.
So that would be a distribution over the clusters.
You're typically, are you also inferring the number of latent variables or processes that
are producing your data, or is that always an assumption that you make in your modeling?
Oh, so that's a good question.
So the traditional algorithm assumes that this is actually given as an input somehow,
I figured out that there are five clusters.
Right.
But of course, that's not really a good assumption because I typically don't know.
Right.
Right.
And so the next obvious step is to, you know, run it with a whole bunch of possible number
of clusters and figure out how to measure which one is best, but that's not naturally,
that's not necessarily easy to do.
And then there is a very interesting literature on what's called non-parametric approaches
or non-parametric Bayesian approaches, which basically say we don't want to make the
assumption that we know the number of clusters ahead of time.
And so we're going to also inject that and because it's Bayesian, they're not actually
inferring the number of clusters.
They are integrating over the number of clusters.
So it gets to fairly complicated math, but there's definitely the attempt to try to accommodate
for that.
And going back to what I was saying before, that's an example of some really interesting
and fairly, you know, beautiful mathematics round that area, but it's not yet practical
to run these algorithms at scale.
Is that when you're saying these algorithms in this case, so you're referring to non-parametric
in particular, the Gaussian mixture models are fairly widely used.
Is that right?
Yeah, if you know the number of clusters, or if you're going to assume that you give
it as an input to the algorithm, then that is an algorithm that can be applied quite
successfully to data.
And so going back to this thing, the EM algorithm, what you typically end up doing is
iterating between two types of computations.
One is given some estimate of different means and variances of each cluster.
I will compute, I will do the inference, so I will compute what is the probability for
each point to be associated with each one of the clusters.
And then after I'm done computing that, I go back to re-estimating my parameters and
refining the estimates of the parameters, and I do that until convergence.
So does that mean you're iterating on the cluster centers and the parameters of your distributions
for each of the clusters as you're incorporating the point into the clusters?
So this is for training time.
So in training time, in this case, I assume I have access to all of my data, and I'm just
trying to figure out where are these cluster centers and their variances, and which point
belongs where?
So I will train by running the EM algorithm, I will end up with estimates of the cluster
centers and their variances, and then if I'm getting a new data point, then I can do
the prediction of what is the probability that it came from cluster 1, 2, 3, 4?
So where does minmax propagation fit in?
Right, so now we kind of have to step quite a bit back.
So at a very, because we kind of dove into one particular example.
And even with Gaussian mixture model, the inference itself is relatively straightforward,
let's say.
So at a very high level, this is a very, very high level novel algorithm to approximately
solve a particular set of NP-hard problems, and the algorithm is a new variant of belief
propagation, and the problems that we're looking at are minmax problems, and in particular,
we've demonstrated on makespan.
Now in order to parse through all of them, we have to talk about what each of these things
mean, right?
Right, right.
So I can start talking about it, and you can interrupt me with questions, but I'll try
to take us through all of it.
So NP-hard problems are, you know, roughly speaking problems for which we don't know
if there exists an efficient solution that will run in a reasonable amount of time.
We typically know a brute force solution, so the problem with brute force is that as
the problem scales, it takes longer and longer in a typically exponential manner, so it's
just not practical.
And so finding solutions that are approximations to NP-hard problems that run in a reasonable
amount of time is a pretty big research area in theoretical computer science and other
disciplines like operational research.
Okay, so that's the hard.
Now if you look about minmax problems, they appear a lot in game theory, decision theory,
and other math and science domain.
And the technical definition is that you have a function of two sets of variables.
Let's call them x and y, and you want to find the min over x max over y of the function
xy.
But that doesn't really give a lot of intuition, so let's try and look at an example.
So in the paper, we'll look at a problem called makespan, which should be fairly easy
to grasp.
So let's say you have a bunch of incoming jobs, and I'm talking about jobs in the computer
science sense, so some automated tasks that need to be executed on a computer, and each
will require some amount of resources.
So let's think about CPU or memory to run.
And we have a bunch of machines, sort of like a computing cluster to run it.
And maybe each machine has slightly different capabilities, so each will take slightly
different time to run each one of these jobs, okay?
So we want to run all of them, so we obviously want to divide up the jobs in a way that everything
finishes as soon as possible.
And if we think about it, that time will be determined by the bottleneck, the machine
that will take the longest to process all the jobs that were assigned to that machine.
So what we want to do is we want to minimize the maximum time it could possibly take.
We want to find a way to split up the jobs across the machine so that we minimize the
maximum time it would possibly take to execute the jobs.
And you call this problem, what makes span?
Makes span.
Makes span, okay, it sounds like a job stop problem.
Yeah, yeah, it's related to that, yeah.
And notice that there is a simple brute force solution, which is, you know, try out all
the different ways you can divide up the load, right?
But a problem of course is that this will be exponential into a number of jobs.
And so it becomes very intractable very quickly.
Okay.
So, okay, so now we understand at least one example of a minmax problem.
And so the algorithm we presented is again in the context of it's to solve the minmax
problem and the paper demonstrated on the makes span problem, but it's a little bit more,
it's more relevant than that.
It's relevant for a set of minmax problems and it goes into the technical properties of
which kind of minmax problems can be addressed.
So I think we can skip that.
So now we can talk about the algorithm.
What can you give us a high level characterization of those types?
Minmax problems.
The types of minmax problems just to get a sense for, you know, even what are the, you
know, what are the dimensions, you know, around what you're thinking about characterizing
these problems?
So they are often notion of, I want to minimize my worst case scenario.
Right.
So, another, another example of minmax problems is when you have some sort of a two-player
game and you're trying to come up with a strategy so that whatever the other player can do,
which is some sort of, you know, I will incur some loss.
Right.
So the maximum loss, I want to minimize that.
Okay.
So that's kind of the most abstract formulation for that problem.
So then it sounds like what you've done in the paper in terms of characterizing the types
of minmax problems to which this particular method applies, it's not necessarily an intuitive
characterization.
It's more mathematical detail, I guess.
Yeah.
Yeah, exactly.
It's a settle.
Okay.
Yeah.
There's restrictions, let's say.
Okay.
And you mentioned belief propagation.
Right.
Let's talk a little bit about that.
So now we can talk about the algorithm we actually propose.
So it is a variant of belief propagation.
Okay.
And so in order to understand belief propagation, we need to know a little bit about inference
in graphical models and message passing algorithms.
And we talked already a little bit about inference in graphical models.
In the context of describing, going back again to the notion of, you know, we have data
or observation and we assume that there is some noise in these observations in these measurements
and then there is some uncertainty and we assume that there are some quantities that
we don't have direct way to measure, but are depend, they have dependencies with relationships
with the quantities we're able to measure.
We often talk about these in terms of observed and hidden variables and they are in graphical
models, we try to capture the way in which they are related using a graph.
So basically every variable, whether it's something that we've observed or something
that we can't observe is represented as a node in the graph.
And then the interactions between these variables are represented as edges in the graph.
And once we describe the problem in that manner, we can start borrowing from, you know, graph
theory and graph algorithms to answer different questions about the graph that we have described,
which is basically a representation of the probability distribution over all of these variables.
So belief propagation is a general algorithm.
It has several existing variants that are quite well known.
One of them is the max product belief propagation and another one is some product belief propagation.
And they are algorithms or recipes for computing these quantities of interest.
So let's say that we have a bunch of these hidden variables and one question we can ask
is, you know, let's say that they are binary.
So they can either take the value zero or one.
We can ask what is the particular setting of all of these variables that yields the highest
probability, this is kind of like the mode of the distribution.
And in order to compute that, we can use something like the max product algorithm.
And at an intuitive level, the way these algorithms work is, again, going back to this
graph that we have in mind, they send messages between the nodes.
So the nodes exchange numerical quantities sometimes in an iterative fashion.
And then eventually they reach some kind of a decision.
So the nodes are variables observed in hidden variables.
And can you give an example of a scenario that includes both these observed and hidden
variables?
Are these hidden variables in a sense of latent variables and a different sense?
Yeah, latent variables.
Okay.
And the observed variables are, what's an example where you'd have both observed and
hidden variables.
So I can actually go back to my graphic, a Gaussian mixture model and I can represent that
as a graphical model where my observed variables is the data that I'm trying to cluster.
And the hidden variables are the clusters that I, that are represented by, by, you know,
these parameters.
And, and maybe I can talk in order to kind of segue into, into this particular, the,
the minmax inference, I'd like to talk about another clustering algorithm, which I think
would really focus us on the, the inference side of the, the hidden variables.
Okay.
So, so that, that's a different clustering algorithm.
And this was actually the focus of my thesis work and it's called affinity propagation.
Okay.
And this is an algorithm that was first presented by my supervisor, Brendan Frye, and his
graduate student, Delbert Duke.
And I focused on various extensions of the algorithm and reformulating of them mathematics.
So anyways, the, the way we represent clustering in that algorithm is we basically say, okay,
we have a bunch of, a bunch of data points who want to split it into groups that make sense.
And instead of talking about means and variances, we're going to say that each cluster is basically
best represented by an exemplar.
So this is like the representative of the cluster.
And so really the problem becomes, can we find the right set of representatives?
And then every point that is not a representative just needs to be associated with the representative
that is closest to it, that is most similar to it.
Okay.
Okay.
So the problem, of course, is you don't know which subset of points is best to represent
these clusters, right?
So in, when you do this max product, belief propagation in the context of this graph, your
variables are basically the data points.
The hidden variables are for each point which cluster should it be assigned to?
Okay.
Okay.
So that's something you don't know.
And for each point, which, right.
And so that specifically, as opposed to the parameters of the cluster itself, right?
Okay.
So we're not using parameters anymore for this algorithm.
So you can see that here, here we'll be doing inference.
We're going to come up with estimates of, for each point, what is the cluster it's going
to be assigned to without talking about a notion of means and variances.
So there is no learning here.
It's only inference.
Right.
Okay.
And so the way the algorithm ends up working is basically, again, sending messages.
So the nodes send messages to each other and the messages come out of a mathematical
derivation.
You look at them, you can kind of give them, give an intuitive explanation of what they're
really trying to say, which is they, it's an iterative process where first, all the nodes
send a message to all of their neighbors, to each one of their neighbors saying, to what
extent do I want you to be my representative, right?
And after collecting all the information from my neighbors, so all my neighbors have told
me to what extent they want me to be the representative.
Now I send all my neighbors a message back saying to what extent do I want to be a representative.
Right.
And so you iterate back and forth on these messages until you converge.
So something back and then in belief propagation, we end up having these messages that are exchanged
between the nodes in the graphical model for the purpose of doing inference for the purpose
of computing these quantities that we care about.
So I think now we might be ready to talk about the mean max propagation.
Yeah.
So just to make sure I'm on the same page.
So we're talking about messages and message passing and things like that.
This is basically a computational tool or an accounting tool that we're using to just
keep track of quantities in this algorithm, really, as we're trying to do the inference.
And the side of my brain that thinks about distributed computing is thinking about real
things, passing messages, and it's like, that's not really what we're doing here.
Right.
These are not text messages or JSON messages.
These are numerical quantities that are computed and then used.
But it's convenient to think about them as, you know, there is a numerical quantity computed
for each one of these nodes.
And then there is another one computed which relies on the previous computation.
So it's almost as if the node sent that numerical representation may be a vector of numbers
to all of its neighbors and said, you know, this is my message.
So now you're ready to do your computation in the next iteration of the algorithm.
Okay.
Great.
So now I think we have all the building blocks.
So we have, you know, these graphical models and we know a little bit about message passing
algorithms and the question we ask in this paper is, can we take this belief propagation
type algorithms and we understand that they can work for the four types of questions
that were interested in the context of, you know, finding the assignment of the variable
that gives us the maximum probability or computing marginals and other tasks.
Can we somehow formulate it to solve the mean max problem?
And so it turns out that we can, it's not by running the same algorithm.
It's by borrowing the general idea and kind of the sum of the mathematics around it and
writing down the mean max problem as a graphical model.
And then deriving the form of the messages that need to be sent in order to compute what
should be the solution to the mean max problem.
So they are similar in principle to the messages you send when you're doing max product or
some product.
But of course, it's its own flavor that required figuring out the right derivation.
And another interesting thing is what we do when we have interaction that are between
quite a few variables, right?
So if we have in our graph an interaction between a subset of variables that is more than
just two, some of the computations can on the surface seem like they are exponential in
the number of the variables.
So in order to be able to actually apply this framework to mean max, we had to recognize
that what looks like it's going to be an exponentially expensive computation can be actually done
by some, you know, a little bit of cleverness and bookkeeping in non-exponential time.
So in something that is reasonable to compute.
Okay.
Just kind of summarizing basically what you did with mean max propagation was you borrowed
from this message passing approach that comes out of belief propagation and applied it to
this makespan problem and in addition, you've kind of mathematically characterized the
more broader set of min max problems to which this model would also apply.
Yes.
And importantly, derive the form.
The messages need to take if you're doing a min max computation as opposed to a sound
product computation or a max product computation.
And what is that form?
So that's in the technical details, so it's basically an equation that describes, you
know, some form of a, you know, operations as minimums and maximums that can be computed
in, let's call it linear time for the purposes of this stuff, but it's an equation, right?
It's an equation that when you go about implementing the algorithm, you will just write in
some code.
Okay.
So given the computation requirements of this and the space of potential application,
where do you think this paper and algorithm will have the broadest impact?
So I think it will be interesting to see what kind of things people use it for because
it's relatively, it's a new formulation.
We wanted to look at the case of, you know, max, max span as a particular application,
which is actually, it is useful for things like scheduling tasks.
It's useful for workload in terms of power consumption on turbines and power plants.
So in the operational research world, I believe, you know, they look at these types of applications.
But from, I think one of the interesting things you get to do as a researcher is sometimes
focus more on, you know, the core algorithm and the mathematics of it and, you know, post
it out there for the world to see so that various people who are looking at, you know,
different problem domains can recognize that this actually matches to their problem of
interest and then take it into interesting places.
Right.
Right.
Maybe worth mentioning that this is all work that you did in the U of T context as opposed
to the Uber context, is that right?
Right.
Right.
And it's also worth mentioning my co-author, Christopher, Siamuk and Brendan.
Okay.
Awesome.
Very cool.
You know, it strikes me that this is a little bit of an aside, but I'm not sure that you
know, but we do a monthly meetup where we kind of dig into research papers and we've
done a bunch of kind of deep learning focus ones, but it strikes me that this would be an
interesting one to maybe have you or one of your co-authors present to the group to really
dig into some of the details here.
A lot of it, it seems like a lot of it is in the details.
Yeah, and I would be happy to talk about that and to look into this opportunity.
I think one of the, again, as a side note, one of the exciting things about deep learning
is that they're so successful in terms of, you know, how applicable they are to problems
that we care about.
The one thing that is that they don't have as much as other algorithms is kind of, you
know, deep mathematics and kind of challenging representations that you really need a lot
of time to wrap your head around and so it's really nice to dig into these papers and
there's typically quite a bit of math in them as well, so I think it'll probably be interesting
and we'll challenge people a little bit in a way that's interesting to look into these
types of papers.
Awesome, where do you go from here with this particular work and your research?
Is this something that you're kind of finishing up that relates back to your time at Toronto
or is this ongoing work that you're involved in?
I would say this is more of a, you know, what I call recreational research.
It's something that I worked with on with Chris in the past was a graduate student as
well in the lab and he kind of took it off from there.
And from me right now, the main focus is definitely ear at work and working on self-driving
cars.
Awesome.
Awesome.
Well, I really appreciate you taking the time to walk through this with me.
I know I've had a lot of questions and I still have a lot of questions there, so this
is not a topic that we've gone into in a lot of detail here on the podcast, but I think
I did.
I had several conversations on graphical models at NipSive, forget how many of those came
out in our Nip series off the top of my head, but we've got a few more to release over
the next few weeks or months.
You know, it seems to be, I don't know, I was surprised to, I guess I was going back
to our earlier conversation, I was surprised by this kind of undercurrent of work happening
in graphical models at NipSive and how often I heard it, although I don't know that that
means anything is the first, it was the first time I was at NipSive, so my baseline is
not exactly, you know, it was not exactly very, you know, dialed in, but they're definitely
seats.
There's a lot of people interested in this area.
Yeah.
Yeah, absolutely.
I mean, again, neural networks have kind of taken from stage for the last few years,
but there's always ongoing research on graphical models and on an array of other problems in machine
learning, and so I think it's kind of nice to see things like the focus going back to
some of these models and seeing what can we do with them now.
Absolutely.
Well, on that note, Emar, thank you so much for joining us.
Absolutely.
Thank you for having me, and I hope it makes for an interesting listening, or at least if
not everything was super clear as an introduction to go and explore some more.
Absolutely.
Absolutely.
Thank you.
Thank you, bye-bye.
All right, everyone, that's our show for today.
Thanks so much for listening, and for your continued feedback and support.
For more information on Emar, or any of the topics covered in this episode, head on over
to twimlai.com slash talk slash 101.
Of course, we'd be delighted to hear from you, either via comment on the show notes page,
or via Twitter, directly to me at At Sam Charrington, or to the show at At Twimlai.
Thanks once again for listening, and catch you next time.
