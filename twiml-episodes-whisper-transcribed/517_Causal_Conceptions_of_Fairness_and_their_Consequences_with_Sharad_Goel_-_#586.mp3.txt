Hey, what's up everyone? Welcome to another episode of the Twomo AI podcast. I am your host,
Sam Charrington, and today I'm joined by Sharred Goyle. Sharred is a professor of public policy
at Harvard University. He and I last spoke just over a couple of years ago about his paper,
The Measure and Mismeasure of Fairness, and today we'll be talking about a follow-on work that
recently won the ICML 2022 Outstanding Paper Award, causal conceptions of fairness and their
consequences. I'll say that this paper surfaced some really surprising results for me, and I'm looking
forward to digging into it and sharing a bit of those with you. Sharred, welcome back to the podcast.
Thanks, Sam. Thanks for having me back. Awesome. For those who didn't catch our last conversation,
how about you spend a little bit of time introducing yourself and talking about how you came to work on
understanding machine learning and fairness in their intersections? Yeah, so I've had a pretty
roundabout path towards this. I would say recovering mathematician. I did my PhD in math,
many years ago, and then slowly drifted towards the policy realm over the last 10, 15 years,
and somewhere in between started to think more seriously about discrimination and human
decisions, and particularly in the criminal justice system. Then all of these discussions about
algorithmic fairness, not just discrimination and human decisions, but how do you conceptualize
discrimination, fairness, and machine systems had started coming to light, and that's where
me and my collaborators came into this emerging area and debate about how do we conceptualize
discrimination, how do we measure it, how do we design more equitable systems?
Yeah, I think if I can maybe summarize our last conversation and how it leads into this one,
I think a big theme out of that last paper in conversation was that, hey, we've been spending
a lot of time as a community, as a field, trying to characterize fairness in mathematical terms,
and you found those lacking in a lot of ways. More recently, this idea of causality and causal
approaches has been presented as, in some ways, almost sounded like a silver bullet, like,
hey, we didn't get it before, but we just sprinkle causality dust on everything, and that's
going to fix all of our problems, and I think this paper saying not so fast.
Yeah, causality dust is nice often, I think it definitely brings nuance and often it's important
nuance to add, and so I'm glad that people are thinking about causality in these discussions,
but I think you said it well that there's still this idea that the solution to designing
equitable algorithms is to just come up with a better mathematician of fairness.
That, again, I don't want to make a too strong claim, but I would say what we're finding is at least
for the existing definitions, causal or non-causal, those definitions, when you use them as design
principles to help you create algorithms, those can end up in many cases causing more problems
than they solve, and so I don't think this closes the door on that approach, but it definitely
should give people pause on pursuing this formalization of fairness.
And it sounds like embarking on this endeavor, a big part of the challenge you ran into is
just understanding what it means to apply causality to this idea of fairness in machine learning
or algorithmic fairness. Yeah, I mean, you're exactly right. I mean, this is this kind of subfield
has been progressing at a breakneck pace. There's lots of papers out there, people quite
understandably are using different terms, different ways of describing the same phenomenon or
the same ideas, and so a large part of this project was to go through that literature and make
sense of it for ourselves. And in the process, what we hope to do is help other people who are new
to this area understand it themselves. And at the end of the day, I think we ended up finding a
reasonably concise way of describing this area of causal fairness. And I would say roughly,
there are two classes of definition, there are two classes of approaches to causal fairness,
and that's kind of the shorthand that I'm using to describe this subfield. So the first is
the idea that that we want to eliminate or reduce the effect of legally protected traits,
like race or gender on our decisions. It's a very natural idea that we don't want race, for example,
if we're in some sort of hiring context, we don't want race to affect our decisions. That's
again, one big class of definitions, either directly or indirectly. And so maybe race indirectly
affects our decisions through opportunities that are afforded to folks, and then that changes
the amount of experience that people have. So even if some sense hiring decisions are based
on Leon, quote unquote, experience, race still might enter the equation through these indirect
paths. And so there's a sense that we want to reduce those types of direct or indirect effects.
And in the second, big class of causal fairness definitions aims to reduce what we call counterfactual
disparities. And so in a world where different decisions were made, what would these different,
what would the effect of those decisions be, for example, on error rates? And so that's another
kind of big class of definition. So these are the two ways that we've conceptualized
this subfield of causal fairness. Can you characterize the things that you saw in the literature,
like the ways in which they differed underneath these two broad classes of intent?
Yeah. So even saying what does it mean to limit the effect, the direct or indirect effect of race
on a decision, that statement is very, very hard to make precise. And so there are many reasons for
that. I mean, one is this kind of mantra of no causation without manipulation. This kind of famous
statistical mantra. And the idea there is this kind of point to this fact of, if I can't manipulate
something, what do I even mean when I say the cause of this thing on something else? And so in our
setting, what does it even mean to say the cause of the effect of race on some decision? How do we
manipulate race? And that is not a thing that we can easily manipulate. And so even saying what,
you know, what are we talking about when we're talking about the effect of race? That's kind of a
big open question. Now, even if we were to say, okay, but let's pretend we understand what that
means. And we might pretend we understand what that means by saying there's these kind of famous
audit studies that say, well, the way we're going to manipulate it is by changing somebody's name.
We're going to imagine an employer or someone who's screening CVs. And we can say we're going
to change the name on a somebody's CV. The only thing that the employer gets to see is a CV.
And we're going to change the name to suggest to the employer's mind and the employer's mind
that this person is black or white, for example. And then if we see differences in decisions,
we're going to say that, well, this is what the effective race means. It's really the effect
a name change on the perception of race, which again induces this change in the decision. But
that's at least one way of narrowly describing what we mean there. Okay, so there are ways that we
can understand what is the effect of race, at least if we kind of suspend a little bit of disbelief
and kind of go down the sort of accept these proxies. So there's that. But now what do we mean when we
say, let's limit the indirect effect of race through certain paths. So now this is an even more
nuanced idea of what exactly doesn't mean to say, well, race could have affected where
what opportunities you had in high school, which affected what colleges you went to, which affected,
which test scores you got, which affected all this other stuff. And so now we might want to say
what we don't want race to affect decisions through some of these pathways. But we are going to
allow race to affect decisions through other pathways. So for example, we might allow, again,
let's go back to this hypothetical of college admissions. We might say, well, we're going to allow
for affirmative action. So we're going to allow race to directly be taken account into account
by admissions officers when deciding whom to enact. But we're not going to allow race to affect
decisions through these quote unquote unfair pathways. And now we have to define exactly what those
unfair pathways are. For example, reduced opportunity resources, which means potentially
lower test scores or whatever those other other potential pathways are that we want to block.
And so that was a lot for us. We had to kind of really unpack all of these formal ways of
making those statements precise. And then in our paper, we tried to convey those to people.
We don't want to kind of read through all of that literature, but you know, what the two-page
summary of how you might do this. Are you saying that all of the definitions that are out there
boil down to two definitions or are there two broad classes of ways that people are defining
or treating the topic? Yeah, so I would say they're really two broad classes. There are many,
many, there are dozens of sub definitions in each of these categories. But at the end of the day,
I think the kind of statistical structural properties really depends on which of these two classes
you're talking about. But I would say there really are. If you were to enumerate them,
you would get to dozens pretty quickly. And a part of what you are doing is presenting
mathematical formulations for these definitions or these formulations that were generally present
in the literature that you were reviewing or were they where they, you know, scenarios that were
proposed less rigorously and you're trying to bring some of that rigor to them.
I would say a little bit about that. I would say maybe 80% there were already out there in various,
you know, using various notation and kind of various setups. And so we definitely tried to consolidate
these, put them on a common footing and then present them all coherently. And in the process,
we, I would say we did clarify some of some of these definitions and hopefully make them a
little bit more rigorous. But I'd say by and large, that part of the paper was bringing in these ideas
that other people had had put out there. And so, you know, these could be extended in various ways,
but we were really trying to represent what other people had already said rather than
introduce our new conceptualizations of these ideas. Got it, got it. And were there particularly notable
areas where you kind of added to definitions or clarified or extended definitions?
Yeah. So again, I mean, I think much of this was already out there. And in many of the authors
of the papers that we cite, you know, probably for various reasons, including space, didn't give
all the details. And so we tried to give many of the details. But I would say especially these kind
of past specific notions of fairness where I'm trying to say, here is I want, I want to limit
the effective race along certain causal paths. That is a definition, a style of definition,
which we found to be quite hard to make rigorous. Once you write it all down, it's pretty compact.
You can say it in a page, but actually getting all that machinery and writing it down and saying
this is exactly what we mean by this definition, that certainly took us a fair amount of time.
And while we were figuring out, hopefully, we were able to communicate that to others.
And so there's on the one hand, there's defining these particular problems in terms of
in kind of using the machinery of causality. There's also defining policies that, you know,
that act on those problems using the same causal machinery. Were you also looking to kind of
clarify and define the policies or are you promoting or discussing, you're not really proposing
new policies. This is also kind of a surveying aspect of the paper, is that right?
So I think this is a really good distinction that you're raising. I mean, there's the use of
causality to define very mathematical notions of fairness. And then there's this way of using
causality that is core to how we are thinking of this project, of saying, you a policy maker
need to do something. And now, the way I think about that is you're asking, what is the causal
effect of implementing a certain policy on the world? And so again, using this kind of idea of
admissions, college admissions, we can say, if I were to admit students according to this policy,
what would happen? What would the demographic composition of my class look like?
You know, what would the graduation rate look like? You know, what would the world very broadly
look like? And that, I would say, is there a notion of a causal policy or is it rather a causal
approach to analyzing the impacts of a policy? Yeah, I would say the latter. And so I would say
here, it's what is the causal effect of implementing a policy? And here, this is a very different
style of reasoning than one that we regularly see in computer science. It's very kind of, I would say,
an economic style or a policy style or reasoning where, you know, you have a menu of options,
and we can say we can do A, B, or C, what is the world going to look like? Or what do we think the
world will look like under each of these potential policies that we could implement? And that's very
different from, I would say, the style of causality or the use of causality in creating these
these algorithmic definitions of fairness. And you mentioned this distinction between the way
causalities treated in economic and statistical context and kind of computer science and algorithmic
context. Did your, your review kind of focus on or find more of one or the other? Yeah, I mean,
I would say we, you know, our perspective was was really coming from the policymaker
of saying we would like to design a more equitable world, you know, whatever that means,
it's a hard amorphous concept, but that is what we are going for. And so the person a question
to a policymaker to a set of stakeholders is what do we do? Now, that is our kind of overarching
perspective when you're coming to this problem. I would say the use of causality in the formal
definitions that we're reviewing are not asking about the consequences of implementing certain things.
They're really saying we want to procedurally reduce the impact of race on certain decisions.
You know, that's kind of roughly what that style of computer science, algorithmic fairness
is doing at least one broad class of things that's happening there. And the key distinction is that
one is procedural. This is the computer science notion of it. And, you know, if you want to be
philosophical about this, you know, sometimes it's called a dantological perspective of saying these
are rules. There are certain things that we think of as being good or bad. And we might say that
it is it is bad to allow race to affect decisions through certain pathways. And then there's this
alternative consequentialist perspective of saying the procedure is really only important to
the extent that it brings about good outcomes. And that's where we were really coming from. And
we're saying we want to create this. We care about certain outcomes being equitable.
And what we found though is quite surprising is that by constraining yourself procedurally
to certain kind of definitions of fairness, even though on the surface, they might seem quite
reasonable. In fact, those constraints are so strong that almost always in a kind of rigorous sense,
they would lead to bad outcomes. And so there's this this dark tension between process fairness
and outcome fairness. And in general, I think, you know, in the criminal legal system,
this is something that often comes up. And I think there's a lot of nuance and whether or not you
want to favor a quote unquote fair process or a quote unquote fair outcomes. Here, the process
in my mind, at least, was was an unintuitive enough that I would prefer having better outcomes
rather than saying, let's equalize error rates or something like that. So where it's unclear to
me, why do you want that thing? Like, you know, presumably you want that thing because precisely,
it leads to these better outcomes. And to the extent that it doesn't lead to these better outcomes,
maybe we should revisit those definitions, those rules that we bound ourselves to at the beginning.
Yeah, and this was a big result in the paper. Can you talk a little bit more about how you
demonstrated that? And it sounds like you did so both the experimentation as well as kind of
mathematically that, you know, these these process definitions were insufficient relative to
the outcome definitions. So the way we did that is that that we kind of use this idea of
pre-dodominance, which is popular in the economics literature. And roughly, this is saying, you
imagine you have a set of stakeholders. And you know, to ground everything, let's let's go back
to our kind of college admissions example. All of what we wrote in the paper is quite general,
but I think it's helpful to keep things grounded with this one example. And so imagine we have an
admissions committee and they all have different preferences, but they agree on two things. So they
agree that they want to have, they want to admit students who are likely to succeed in their
program. And so you might operationalize this by saying that you that they that they have a
preference for people graduate. That's like one way to to say that that we can operationalize
success. And the second thing that they agree on to some extent is a preference for diversity.
And, but they disagree on the extent to which they're willing to trade these two things off.
And so some people are saying, okay, it's like we really want to prioritize, you know, one over
the other and other people say, no, let's not really, let's, you know, kind of we really mostly care
about one and not the other. And so we have this kind of, I would say realistic scenario of stakeholders
who have differing opinions, but they're kind of reasonable in the sense that their preferences aren't
all over the place. They kind of have rough alignment on these critical dimensions. And so now,
what we say is that I am going to in some sense randomly draw a state of the world for you.
And so what does that mean? I'm going to kind of, you know, tell you the relationship between,
you know, demographic groups and all these covariates that are observable and everything that
admissions committees can make their decisions on. And there's kind of this infinite
dimensional space of distributions that I can consider. And we're saying just pick some of
these things randomly. And our result in the nutshell is saying almost always, no matter what
state of the world you randomly draw, if you were to limit yourself to these causal definitions
of fairness, the policies that will result, the only policies that satisfy your causal definition
of fairness will be perito-dominated, meaning that everybody on the admissions committee
will think it's a bad idea. And so what does that mean to be concrete? So if I give you any policy
that satisfies your causal definition of fairness, I can come up with another policy that has both
greater student body diversity and higher admissions or graduation rates. And because it has both
of these two things, everybody on the admissions committee will think that it's better than the
policy that you generated through this causal fairness mechanism. With that result in mind,
you're kind of suggesting here that these causal policies traded in the context of causal
definitions are suboptimal broadly. But we've talked about all of the work that's gone into these
causal policies. Certainly, those folks thought they were onto something. Like, is it, what is your
results, what light does your result shed on all the results that you looked at when you were
kind of coming up with your definitions? I completely agree that there's been a lot of effort,
probably thousands of hours, since thousands of hours of effort collectively going into this
subfield of causal fairness. And I don't think that was wasted effort in any way. I mean, I think
these are this is an emerging field. And we have to learn and understand what we're doing. That's
a messy process. And so in some sense, not at all surprising that our first stab at this is going
to fall short. That being said, I do think, and again, this is my own view, is that our results
really cast them down on the value of this approach going forward for informing policy decisions.
I don't think that that's not a mathematical statement. It's not a formal statement. And I
would encourage other people who are interested in this area, you know, to continue pursuing it
and to read carefully the literature, to read carefully what we've written and make up their
own mind. But for me personally, having gone through that process, I do think there's a real risk
of causing harm and particularly causing harm to groups that, ostensibly, we are trying to not
harm by using these definitions. If we were to go down this path of mathematicizing fairness in
these ways, you mentioned in the paper that you show the Pareto dominance both analytically
and empirically, is the are you empirical results based on simulation or yes, this is simulation.
So we mostly use this as is an intuition pump. And so this is how we started the mouth turns out
to be hard. And so this is the way that we started building a tuition for the problem is let
simulate things and we hope that that approach is also illuminating to other people who are coming
to this field. Can you talk a little bit more about how you built out the simulations?
Yeah, and so it's pretty straightforward. We basically formalized the setting that we've
been talking about about college admissions. And it's very much mirror discussion. So we just
imagine there's some population of people. We imagine that there are various things that
admissions can be considered. For example, test scores or GPA and race. And we imagine some
relationship between these things. And then once we write this thing down, and again, I don't
even pretend that this is realistic in a literal sense, but I think it captures some of the structure
of these problems in the real world. But once we write it down, then we can just kind of draw
outcomes from this generative model. We can say, given that you observe these outcomes and you
implement this policy that is derived through these causal fairness definitions, what would you
get? How would that compare to things that you could do alternatively? And like I said, you know,
if you, anything you do, if you restrict yourself to the class of policies that are attainable
through a causal fairness definition, you are guaranteed in a mathematical sense to have
lower student body diversity and lower graduation rates than what you can do if you don't restrict
yourself to that class of policies, which Toss was a kind of surprisingly strong result.
Yeah, yeah. I mentioned when we were chatting earlier that it was very surprising for me reading
the abstract you used to seeing results that are talking about how something is better.
And I had to read Pareto dominance, you know, though that the causally defined results were
Pareto dominated by other policies several times before I realized what you were saying. And hey,
these are always worse. They're always worse. Yeah, they're always worse. And even formalizing,
what does that mean that these are technically almost always worse, like going back to the
statement I made before it's like if you were to draw these policy, draw the state of the world
at random, you will almost always end up with something that is Pareto dominated, meaning it's
actually strongly pre-dodaminated, meaning everybody on our admissions committee and that hypothetical
would disfavor that policy. So what does that even mean? And this is where we had to kind of dig
into the decades old mathematical literature on formalizing what does that mean almost every
policy. And so that kind of goes down this whole rabbit hole, which again, to us at a technical
level was super interesting because from our previous work, we had this intuition that often
these things are bad. But we didn't quite have that language to say, well, what does that mean
often? You know, what does that mean typically? What does that mean bad? And here the insight was,
I mean, putting together this idea of Pareto dominance, you know, coming from the economics literature
and this idea of almost everywhere on these kind of infinite dimensional spaces, coming for
the mathematics literature, and kind of putting all these pieces together, we, you know, found a
this, you know, surprisingly strong result. I'm trying to think back to the previous results,
and if you could have said something similar, or did you need the constraint of causality to
provide a mathematical framework for you to even get this far? Yeah, that's a really good
question. And so I would say yes and no. So yes, much of what we, many of the causal, money
of the non-causal definitions that are out there are subject to the same critique that we're
offering in our current paper. And so at the time, you know, a few years ago when we were writing
those older papers, we just didn't understand what we now understand. And so in that sense,
these results translate. But in another sense, there is something about these causal definitions
of fairness, which is does not apply to the non-causal definitions. And so it turns out that these
causal definitions of fairness, at least many of them, have such strong requirements on what they
allow that the only policies which satisfy them end up being kind of random policies that say that
the only policy that will satisfy, you know, one of these particular definitions of causal fairness
has to admit everybody with equal probability, regardless of qualification, regardless of
demographics, everybody's admitted with the exact same probability. And that result was extremely
surprising to us. And it really stems from the fact that these definitions are implicitly
imposing so many constraints on your policy that you kind of have no way out because this is
the only thing left to do. And as far as I know, I don't know of any non-causal definitions
that impose so many restrictions that this is the only thing that you end up with.
Okay, so that kind of gets at the second question I had, which was kind of some intuition around
why causality or causal policies perform so poorly. And it's this idea of restriction,
it sounds like, can you kind of speak more directly to this? Yeah, that's exactly right,
that's exactly right, that this is really about constraints. And so every time you add a constraint,
you're restricting the space of policies that you can consider. And it turns out that especially
for these, you know, past specific notions of fairness, or any of these things where I say,
if I change your race, counterfactually, I have to see exactly the same outcomes in my decision.
It turns out if you unpack that definition, that really implies a huge number of constraints.
It sounds like one constraint, but really it's many, many, many constraints that are tied
into that one notion. And so when you do that and you kind of, you know, internalize that bit any
further, like what is it that is what's the mechanism of kind of that constraint mapping to many
other things? Yeah, so one way to think about it, and again, this gets a little bit technical
and pictures is worth a thousand words here, but I'll try to do it through audio is that you
can imagine a graph, a DAG, a causal DAG that says, well, we have various features, attributes,
and we're trying to say, you know, we're drawing arrows between everything that has an effect
on everything else. And now we have, you know, race is one of these nodes in this graph and race
affects all these other things. And now if you think about all these kind of pads that race can
go through to affect your decisions, if you kind of look at that graph, it turns out that this
definition is saying that your decisions can only depend on things that are not downstream of race.
But mostly when people write down these types of DAGs, everything is downstream of race.
And so you have to say, well, you know, it's like where you went to school and then, you know,
your test scores because of where you went to school. And then all these other things like the
neighborhood you live in, all of these things are somehow tied to race. At least this is how
people conceptualize it in many of these papers. And once you write that down, that is implicitly
constraining your policy in a way that leaves no other option. But you have to make decisions that
don't depend on that race or anything downstream of race, which basically doesn't leave you with much.
Is there a notion that makes sense of kind of rating or parameterizing,
now less parameterizing than rating or categorizing, I guess, these causal policies based on
their degree of constraint? Yeah. So definitely, this one that I've been describing right now,
I would say it's the most extreme and that literally the only thing you can do is make decisions
purely randomly, no differentiation. And so I would say that's the most extreme. There's more or
or less unique policy that satisfies this causal definition of fairness. For everything else that we
looked at, there's a little bit of wiggle room. But all of that wiggle room, all of those policies
that are allowable are still pre-dominated. And so they're still all, you know, quote-unquote bad
in some sense, but they're, I would say not as bad, they're not as, you know, there's more than one
choice. And you kind of touched on this earlier in saying that, you know, this work isn't necessarily
meant to, you know, say that there's no value in this research, but do you see, does this work
point you in a direct, you know, if you're interested in causal policies, do you see, you know,
something in this work that says, well, maybe we should be looking here, or is it more, you know,
is it not really providing you that that shining light, so to speak?
No, I mean, I think there are at least a couple things that are that are important at first,
just to highlight the introduction of causality into this conversation is an important one, I think.
And it's, it was too much about, I would say pure prediction before, without thinking about
the effects of interventions. And so I think that, that idea at a very high level is an important one.
Now, the other thing that I think is at least in some of this literature, but, you know,
perhaps not highlighted the extent that I would like it to be, is, is let's think about outcomes.
And so there are these process oriented views of fairness. And in some context, those might make
a lot of sense, but I think it's important to understand what we're, we're leaving on the table,
when we think in terms of pure process, as opposed to at least acknowledging the effects of policies
generated by using these design principles that are being put out there. And at the end, I think
a reason we're going to disagree about whether or not one should focus on processor outcomes,
but what I would personally like to see is more discussion, more engagement,
around these two different ways of thinking about these problems. But that is something I think
this literature at least is alluding to, even if it's also directly engaged with.
Is there some idea in which if you start with outcomes, then there is some role of causality as
a tool to taking from those outcomes to policies that aren't limited by the constraints that we've
talked about and are dominated in the way that we talked about. Definitely. I think it's very hard,
but at least in theory, you can do this. And so here, the idea is if we agree, and this is a big if,
if we agree what we want the world to look like, and again, different people are going to disagree
about that. But let's assume that we have some consensus on where we want to get to.
Then you can say, well, we could implement all these different interventions. How do we get to
this place that we agree we want to get to? Which one of these interventions is going to get us
closest to that place or fastest to that place? And that's a causal question. That's purely a
causal question. It's a hard question, but I don't think it's impossible in all scenarios to
answer. And some of our other work is actually directly trying to take that perspective to design
policy interventions. What's next for you in this line of research? Yeah, so there's a lot of
stuff kind of that we're actively pushing on right now. And the one thing that I'm quite excited
about is designing interventions that can get us to a better place. And so this is a theme of
much of my work. And so to give one specific example, we are working with a public defender
in California, the Santa Clara County Public Defender office to help their clients make it to court.
And so why is that? Well, we, when you miss court, all sorts of bad things happen. And so you can
know a bench ward is often issued. And now if you're pulled over for a minor traffic violation,
you could get arrested and thrown into jail. And so obviously, I would say the right solution here
is to not have those outcomes given the, you know, if you miss court, in my mind, I think of that
as like a tantamount to missing a doctor's appointment. It's not like people are trying to flee
the jurisdiction. They have complicated lives. They, they forget about their appointments, all
sorts of things happen. And I don't think it's kind of, it's, it's, it's not humane. It's not just
to lock somebody up for that. That's a harder policy discussion. And so the way that we're addressing
it is we're saying, well, given that this is the way the system works, we're not happy with it,
but given the way that this is the way the system works, let's try to help people make it to court.
And so we're doing that through two different means where we're working to send out text message
reminders so people can help them plan. And we're also providing free door to door ride share
from someone's home to court and back. And that is now, now the question is, how do you,
how do you allocate this limited benefit of ride? So unfortunately, we can't offer the ride
to everybody. And so who do we offer the rides to? And this is fundamentally a causal question.
It's like there are various policies that we can implement. Which ones of these policies
are we happier with? Which ones are going to get us closer to a world that we want to be in?
Awesome. Awesome. Well, Sharad, congrats again on the outstanding paper award. That's huge.
And it was great catching up and learning a bit about your latest work. Thanks. It's always fun chatting.
