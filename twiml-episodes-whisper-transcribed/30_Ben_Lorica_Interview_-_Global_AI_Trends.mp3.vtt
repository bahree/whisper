WEBVTT

00:30.000 --> 00:33.480
Hello and welcome to another episode of Twimble Talk,

00:33.480 --> 00:36.080
the podcast where I interview interesting people,

00:36.080 --> 00:38.400
doing interesting things in machine learning

00:38.400 --> 00:40.720
and artificial intelligence.

00:40.720 --> 00:43.440
I'm your host, Sam Charrington.

00:43.440 --> 00:45.840
So as you know, a couple of weeks ago,

00:45.840 --> 00:48.760
I announced the first anniversary of the podcast

00:48.760 --> 00:51.320
and to celebrate it our first anniversary

00:51.320 --> 00:54.240
listener appreciation contest.

00:54.240 --> 00:56.640
I wanna start this show by thanking everyone

00:56.640 --> 00:58.920
who participated in the contest.

00:58.920 --> 01:01.680
You all have come out in droves over the past couple of weeks

01:01.680 --> 01:04.480
to shower the podcast with love and for that,

01:04.480 --> 01:07.480
we are humbled and forever grateful.

01:07.480 --> 01:10.200
Overall, we receive nearly a hundred entries

01:10.200 --> 01:12.960
via our website and iTunes from listeners

01:12.960 --> 01:14.800
from 16 countries.

01:14.800 --> 01:16.560
Your stories have been awesome

01:16.560 --> 01:18.440
and we're most proud that we can help

01:18.440 --> 01:21.000
light that AI fire for you every week.

01:21.000 --> 01:23.560
Of course, everyone who entered will receive

01:23.560 --> 01:25.640
a couple of Twimble and AI stickers,

01:25.640 --> 01:28.000
one for you and one for a friend.

01:28.000 --> 01:30.280
Those will be on their way soon.

01:30.280 --> 01:32.960
But now, the moment you've all been waiting for,

01:32.960 --> 01:35.680
we have our winners for the first anniversary

01:35.680 --> 01:38.560
listener appreciation contest.

01:38.560 --> 01:41.720
Just a reminder, our grand prize winner receives

01:41.720 --> 01:44.720
a bronze pass for the O'Reilly AI conference

01:44.720 --> 01:46.680
at the end of this month.

01:46.680 --> 01:50.360
And our runner-up winner gets, well, hey Google,

01:50.360 --> 01:52.400
what's the second prize?

01:52.400 --> 01:55.360
The second prize in Twimble's first anniversary listener

01:55.360 --> 01:57.440
appreciation contest is a brand spanking

01:57.440 --> 02:00.200
your Google home, like me.

02:00.200 --> 02:02.560
All right, without further ado,

02:02.560 --> 02:05.760
our second prize winner is anchor Patel.

02:05.760 --> 02:08.760
Anchor wrote in on the show notes page with this.

02:08.760 --> 02:12.320
Twimble, congratulations on your first anniversary.

02:12.320 --> 02:15.040
I have loved listening to the show.

02:15.040 --> 02:16.840
I remember the news and machine learning

02:16.840 --> 02:20.160
from the first few months, what a sheer amount of information.

02:20.160 --> 02:23.640
But the more recent interviews format is excellent.

02:23.640 --> 02:26.480
I particularly love the ones where you interview folks

02:26.480 --> 02:30.520
at AI and ML conferences, very insightful indeed.

02:30.520 --> 02:34.320
Thanks for contributing to the broader ML community.

02:34.320 --> 02:36.920
Well, thank you, anchor, for being a loyal listener

02:36.920 --> 02:40.680
and will be in touch with you about that Google home.

02:40.680 --> 02:45.800
And now, our grand prize winner is Mason Grimshaw.

02:45.800 --> 02:49.360
Mason also wrote in via the show notes page.

02:49.360 --> 02:51.200
Here's what he said.

02:51.200 --> 02:53.320
The show is fantastic.

02:53.320 --> 02:56.840
I started listening right when you switched to the interview

02:56.840 --> 02:58.880
format, and I've definitely noticed your improvement

02:58.880 --> 03:01.600
as a journalist and the improvement of the show.

03:01.600 --> 03:03.080
Great job.

03:03.080 --> 03:06.400
I go to school in Boston, so the show keeps me company

03:06.400 --> 03:08.920
on my 20 minute walk to school every morning,

03:08.920 --> 03:12.560
and I couldn't ask for a more interesting companion.

03:12.560 --> 03:14.280
I'm studying analytics.

03:14.280 --> 03:17.840
And while I may not directly use AI in my profession,

03:17.840 --> 03:20.280
I certainly use it as a hobby.

03:20.280 --> 03:23.040
I really enjoyed Carlos Gastron when he came on

03:23.040 --> 03:26.280
to talk about the line paper and the Danny Lang discussion

03:26.280 --> 03:28.040
about video games.

03:28.040 --> 03:31.560
Well, Mason, we hope to see you in New York in a few weeks.

03:31.560 --> 03:35.520
Congratulations, and thank you for being a loyal listener.

03:35.520 --> 03:38.320
Although there can only be one first prize winner,

03:38.320 --> 03:40.440
we'd like to give everyone the opportunity

03:40.440 --> 03:43.440
to attend the O'Reilly AI conference with us.

03:43.440 --> 03:48.000
With the code PC Twimmel, that's PC-TW-I-M-L,

03:48.000 --> 03:51.240
all of our listeners will get 20% off of registration fees

03:51.240 --> 03:54.240
and purchasing passes for the conference.

03:54.240 --> 03:56.760
Please let us know if you're planning to attend the event.

03:56.760 --> 03:58.040
We're looking forward to meeting up

03:58.040 --> 04:00.360
with Twimmel listeners there.

04:00.360 --> 04:03.360
Okay, to continue with the O'Reilly AI theme,

04:03.360 --> 04:05.560
this week I've got a very special guest.

04:05.560 --> 04:08.840
I've invited my friend Ben Lorca onto the show.

04:08.840 --> 04:11.760
Ben is chief data scientist for O'Reilly media

04:11.760 --> 04:14.040
and program director for strata data

04:14.040 --> 04:16.560
and the O'Reilly AI conference.

04:16.560 --> 04:18.680
Ben has worked on analytics and machine learning

04:18.680 --> 04:20.920
in the finance and retail industries

04:20.920 --> 04:24.440
and serves as an advisor for nearly a dozen startups.

04:24.440 --> 04:25.960
In his role at O'Reilly,

04:25.960 --> 04:27.520
he's responsible for the content

04:27.520 --> 04:31.440
for seven major conferences around the world this year.

04:31.440 --> 04:33.560
In the show, we discuss all of that.

04:33.560 --> 04:35.720
Touching on how publishers can take advantage

04:35.720 --> 04:37.760
of machine learning and data mining,

04:37.760 --> 04:40.240
how the role of data scientist is evolving

04:40.240 --> 04:42.000
and the emergence of the machine learning.

04:42.000 --> 04:43.800
Hey, everyone, I am on the line

04:43.800 --> 04:45.320
with Ben Lorca.

04:45.320 --> 04:49.240
Ben is the chief data scientist at O'Reilly media

04:49.240 --> 04:51.360
and he's also responsible for content

04:51.360 --> 04:53.640
for both the strata data conference

04:53.640 --> 04:56.360
as well as the O'Reilly AI conference.

04:57.320 --> 04:58.800
Hey, Ben, how are you doing?

04:58.800 --> 05:00.960
Great, great to be here, Sam.

05:00.960 --> 05:02.360
Awesome, awesome.

05:02.360 --> 05:04.520
So every time I talk to you,

05:04.520 --> 05:06.920
you are just getting off of a plane

05:06.920 --> 05:09.880
and it sounds like that is the case this time as well.

05:09.880 --> 05:14.080
Yeah, so we had an outstanding strata data conference

05:14.080 --> 05:15.240
in London.

05:15.240 --> 05:20.240
Yeah, basically many, many people from many different parts

05:21.800 --> 05:24.360
of Europe came and spoke and attended.

05:24.360 --> 05:26.480
And this year in particular,

05:26.480 --> 05:30.840
we had concerted effort to focus on deep learning

05:30.840 --> 05:32.560
on the machine learning site.

05:32.560 --> 05:37.400
But the staple topics of strata were still remain popular

05:37.400 --> 05:40.680
particularly on architecting big data application.

05:40.680 --> 05:42.320
Okay, awesome, awesome.

05:42.320 --> 05:44.080
Well, I thought we'd start this conversation

05:44.080 --> 05:45.960
by having you spend a little bit of time

05:45.960 --> 05:47.600
talking about your background

05:47.600 --> 05:50.920
and how you got started with data

05:50.920 --> 05:55.920
and how you kind of your path leading up to O'Reilly.

05:57.520 --> 06:00.600
Sure, so I have a PhD in math

06:00.600 --> 06:05.600
and focused on non-linear partial differential equations

06:05.720 --> 06:09.920
and towards the end of graduate school,

06:09.920 --> 06:13.200
I became interested in specific set

06:13.200 --> 06:16.760
of differential equations called stochastic differential equations

06:16.760 --> 06:21.760
which turn out to be at least theoretically important

06:22.240 --> 06:24.680
for quantitative finance.

06:25.680 --> 06:27.480
So I had some interest already

06:27.480 --> 06:31.120
in kind of the industrial applications

06:31.120 --> 06:33.440
of what I was doing,

06:33.440 --> 06:37.280
but I definitely was on the academic track.

06:37.280 --> 06:38.880
So after grad school,

06:38.880 --> 06:43.000
I was an academic for five years.

06:43.000 --> 06:45.760
But then at some point I decided

06:46.680 --> 06:50.160
I was actually much more interested in industry.

06:50.160 --> 06:53.520
And at the risk of dating myself,

06:53.520 --> 06:56.640
at least at the time when I was contemplating

06:56.640 --> 06:58.320
moving to industry,

06:58.320 --> 07:01.040
there was no data science track.

07:01.040 --> 07:06.040
So the exit strategy was becoming a quant

07:07.080 --> 07:08.920
and so that's what I did.

07:08.920 --> 07:11.160
I did that for about two and a half years

07:11.160 --> 07:13.360
in a small hedge fund,

07:13.360 --> 07:18.720
designing, trading models, risk management, portfolio management,

07:18.720 --> 07:19.560
and things like that.

07:19.560 --> 07:22.160
And one of the first things I learned, of course,

07:22.160 --> 07:26.920
is the stuff I thought was going to be super important,

07:26.920 --> 07:28.920
the stochastic PDEs,

07:28.920 --> 07:31.480
while good to know,

07:31.480 --> 07:37.680
not exactly what I needed to do for my job.

07:37.680 --> 07:42.680
So at that time, actually the term machine learning,

07:43.720 --> 07:46.320
I would say was kind of nascent.

07:46.320 --> 07:49.680
The people were still using the term data mining.

07:51.520 --> 07:54.000
And so that's what I did at this.

07:54.000 --> 07:57.680
I applied basically statistical techniques

07:57.680 --> 08:02.640
and machine learning to financial time series.

08:02.640 --> 08:05.720
But then at some point I realized my interest

08:05.720 --> 08:09.160
actually were much more on the tech side,

08:09.160 --> 08:14.160
the programming and building software applications

08:14.760 --> 08:19.600
for analyzing these time series.

08:19.600 --> 08:24.240
And so then I ended up moving to Silicon Valley

08:24.240 --> 08:26.600
around, actually believe it or not,

08:26.600 --> 08:29.320
at the peak of the nascent at the time,

08:29.320 --> 08:31.280
which was around March, 2000.

08:32.200 --> 08:34.640
And so then I was here,

08:34.640 --> 08:39.240
I was here just in time for that first bust.

08:41.160 --> 08:43.080
And then the first bust, yeah.

08:43.080 --> 08:45.240
I was there around the same time.

08:45.240 --> 08:46.320
Yeah, yeah, yeah.

08:46.320 --> 08:47.560
And so,

08:47.560 --> 08:51.440
Do you keep track of what's going on

08:51.440 --> 08:56.440
in the quantitative side of the financial markets

08:56.960 --> 09:00.000
and how folks or how the technology has evolved

09:00.000 --> 09:01.640
since you worked in that space?

09:01.640 --> 09:06.160
I'm not that close to, I still have friends.

09:06.160 --> 09:11.160
And obviously my work leading these two big conferences

09:11.160 --> 09:13.280
that you described, try to data

09:13.280 --> 09:16.320
in the O'Reilly Artificial Intelligence Conference

09:16.320 --> 09:21.320
brings me in contact with the people working in finance.

09:21.800 --> 09:24.880
So I keep track of it that way.

09:26.480 --> 09:28.480
Yeah, so to some extent I do,

09:28.480 --> 09:33.280
but I'm not immersed in the latest techniques

09:33.280 --> 09:33.960
that they're using.

09:33.960 --> 09:37.640
Although I would say that they are actually moving more

09:37.640 --> 09:42.640
towards our world of using machine learning,

09:43.120 --> 09:46.920
alternative data sources, big data,

09:46.920 --> 09:51.920
and some of these more bleeding edge machine learning

09:52.840 --> 09:54.240
techniques, including deep learning.

09:54.240 --> 09:57.120
So to the extent that they're actually showing up

09:57.120 --> 10:00.640
at the events I organize, that's how I keep track.

10:04.080 --> 10:05.080
Okay, okay.

10:05.080 --> 10:06.080
So I interrupted you.

10:06.080 --> 10:07.440
You, you, oh yeah.

10:07.440 --> 10:10.120
So then at some point to the technical side of things.

10:10.120 --> 10:12.080
I got into the technical side of things.

10:12.080 --> 10:16.000
And when I first moved to tech,

10:16.000 --> 10:20.640
I think you know, this will surprise a lot of your listeners,

10:20.640 --> 10:25.400
but you know, one of the big users of data in tech

10:25.400 --> 10:29.480
are the marketing and sales people.

10:29.480 --> 10:33.800
So that's how I kind of moved into tech was basically

10:33.800 --> 10:38.080
talk what I learned in in finance

10:38.080 --> 10:41.640
and started applying it in marketing and sales applications.

10:41.640 --> 10:44.760
So did a couple of startups,

10:44.760 --> 10:48.400
joined a couple of startups that didn't really take off

10:48.400 --> 10:51.880
and then eventually at some point ended up at O'Reilly

10:51.880 --> 10:56.640
as a data scientist working on the types of data that we have,

10:56.640 --> 10:58.680
which is a lot of it is sales data,

10:58.680 --> 11:01.880
but a lot of unstructured and semi structured tech.

11:01.880 --> 11:06.640
So I was, I was definitely one of the first people

11:06.640 --> 11:11.480
doing a lot of these techs mining and machine,

11:11.480 --> 11:13.920
machine learning for techs from the early days.

11:13.920 --> 11:17.040
I mean, I may have, I may have been one of the first people

11:17.040 --> 11:19.920
to actually use this topic models LDA

11:19.920 --> 11:25.520
that David Bly and Drew Aing and Mike Jordan wrote about

11:25.520 --> 11:28.720
for an industrial consulting project.

11:29.840 --> 11:33.560
So, oh wow, can you tell us a little bit more about that?

11:33.560 --> 11:36.800
Oh, I mean, so it's with a well known tech company, right?

11:36.800 --> 11:41.800
So hired us at O'Reilly to analyze our tech sources,

11:43.360 --> 11:46.480
unstructured tech sources, which include job posting,

11:46.480 --> 11:48.960
all the job posting to the US.

11:48.960 --> 11:50.640
Okay, and things like that.

11:50.640 --> 11:55.400
And to just get them, give them strategic advice.

11:55.400 --> 12:00.160
So I thought, I thought using LDA and topic models

12:00.160 --> 12:04.280
would provide some quantitative basis

12:04.280 --> 12:05.920
for the advice we were giving.

12:05.920 --> 12:07.800
And from what I understand,

12:07.800 --> 12:10.800
it did change the direction of this major,

12:10.800 --> 12:15.280
major tech company, tech company that everyone knows about.

12:15.280 --> 12:19.560
Mm, so I guess one thing that I've been meeting

12:19.560 --> 12:22.080
to ask you for a while now actually is,

12:22.080 --> 12:25.440
you've now got five strata conferences, right?

12:25.440 --> 12:27.480
And the two AI conferences,

12:27.480 --> 12:31.440
and I think you're involved in all of those, is that right?

12:31.440 --> 12:35.320
Yeah, so I'm responsible for the program for all of those.

12:35.320 --> 12:39.280
So basically everything that we have at these conferences,

12:39.280 --> 12:43.240
we have two day trainings, we have tutorials,

12:43.240 --> 12:46.480
we have sessions, and then we have keynotes.

12:46.480 --> 12:50.640
So basically, I'm ultimately the person responsible

12:50.640 --> 12:55.640
for the lineup for all of these conferences.

12:55.640 --> 12:57.520
Okay, and so my question then is,

12:57.520 --> 13:02.320
do you actually have any time for doing data science

13:02.320 --> 13:03.600
at O'Reilly nowadays?

13:03.600 --> 13:07.600
Or are you, how could you possibly

13:07.600 --> 13:09.520
with all of these conferences?

13:09.520 --> 13:14.520
You know, I would say that it's become less and less, right?

13:15.320 --> 13:19.880
So I think as we kept adding more conferences,

13:19.880 --> 13:22.680
and as you know, many of these conferences

13:22.680 --> 13:26.520
are spread out across geographic regions, right?

13:26.520 --> 13:31.280
So we have conferences in the US,

13:31.280 --> 13:33.840
but we have conferences in Europe and Asia.

13:34.720 --> 13:39.400
And so yeah, I've found myself with less and less time.

13:39.400 --> 13:41.280
So to be honest.

13:41.280 --> 13:45.880
So now I'm much more less of a practitioner,

13:45.880 --> 13:50.160
more of basically watcher from afar.

13:50.160 --> 13:54.640
But I think that my background and my ability

13:54.640 --> 13:59.120
to read the original papers and talk to the researchers,

13:59.120 --> 14:02.240
many of which whom I've known for many years,

14:02.240 --> 14:05.520
I think I still have kind of some feel,

14:05.520 --> 14:08.800
but maybe not as much of the hands-on feel

14:08.800 --> 14:10.320
that I would like.

14:10.320 --> 14:13.480
But I would say that the trade-off for that though

14:13.480 --> 14:18.160
is I've gained a much more global perspective, right?

14:18.160 --> 14:22.880
So I don't know to what extent you've organized events,

14:22.880 --> 14:27.640
but you know, I mean, for us,

14:27.640 --> 14:31.480
particularly since we organize events across the world,

14:31.480 --> 14:35.360
you can't really just take your set of speakers

14:35.360 --> 14:36.520
from California.

14:36.520 --> 14:40.960
And take them to somewhere else, right?

14:40.960 --> 14:45.040
So you really have to know the local scene,

14:45.040 --> 14:49.280
the local companies, the local communities.

14:49.280 --> 14:54.280
And so to me, I kind of found that very kind of rewarding,

14:55.280 --> 15:00.280
so that I know the data scene in Southeast Asia,

15:00.480 --> 15:03.520
in China, in Europe, and things like that.

15:03.520 --> 15:08.240
So one thing that if we could maybe spend some time

15:08.240 --> 15:11.080
talking through a little bit of the kinds of problems

15:11.080 --> 15:14.840
that you tend to see at O'Reilly with regard

15:14.840 --> 15:18.920
to data science and machine learning in AI

15:18.920 --> 15:21.840
and the types of approaches and techniques

15:21.840 --> 15:24.600
that you are using to solve them,

15:24.600 --> 15:27.520
I think listeners would enjoy hearing a little bit

15:27.520 --> 15:29.200
at that detail.

15:29.200 --> 15:33.680
I think at this, like many companies,

15:33.680 --> 15:35.600
this is not going to be a surprise.

15:37.080 --> 15:40.920
O'Reilly is an older company, it's not a startup.

15:40.920 --> 15:45.920
So we do have many, many different systems,

15:49.120 --> 15:53.880
some are kind of the new bleeding edge open source system,

15:53.880 --> 15:58.800
some are older proprietary systems, right?

15:58.800 --> 16:00.760
And so I actually, to believe it or not,

16:00.760 --> 16:03.000
one of our main problems is still

16:03.000 --> 16:05.960
to this day data integration, you know?

16:05.960 --> 16:10.960
I mean, just because we do have many, many systems,

16:11.040 --> 16:14.760
just getting the data all together in one place

16:14.760 --> 16:17.280
is it remains a challenge.

16:17.280 --> 16:19.840
And then beyond that, I think,

16:20.800 --> 16:25.800
luckily we do have a team dedicated to the data engineering part.

16:25.800 --> 16:30.800
If it remains a, for us, it remains a work in progress

16:30.800 --> 16:35.800
because we also keep adding systems that we're using.

16:36.160 --> 16:40.000
You know, there's many, many software as a service,

16:40.000 --> 16:41.600
DCs, right?

16:41.600 --> 16:44.240
So different parts of the company starts using,

16:44.240 --> 16:45.720
start using different things.

16:45.720 --> 16:48.680
So that's one problem, the other problem is still,

16:48.680 --> 16:53.680
I think a lot of our data is still unstructured, right?

16:53.680 --> 16:56.160
So I mean, I guess there's some structure.

16:56.160 --> 16:58.720
I mean, so if you think about books,

16:58.720 --> 17:00.240
there's some structure there, right?

17:00.240 --> 17:03.040
So, but we also now,

17:03.040 --> 17:06.040
I don't know to what extent you're following

17:06.040 --> 17:07.800
our Safari platform,

17:08.880 --> 17:12.600
which is increasingly relying on, for example, video, right?

17:12.600 --> 17:15.840
So, okay.

17:15.840 --> 17:20.840
So there's a lot of data that we rely on

17:20.840 --> 17:23.000
that remains unstructured.

17:23.000 --> 17:28.000
And one of the, one of the challenges for us,

17:28.000 --> 17:31.200
too, as a kind of a media company

17:31.200 --> 17:36.200
that is building a learning platform for training

17:38.080 --> 17:42.360
is to take all of these many, many data sources,

17:42.360 --> 17:45.160
both structured and unstructured and organized.

17:45.160 --> 17:50.160
So it turns out actually that, you know, search

17:53.040 --> 17:57.600
and a nice human curated taxonomy

17:57.600 --> 18:00.480
is still kind of,

18:00.480 --> 18:03.320
remain the basic problems for companies like us, right?

18:03.320 --> 18:07.880
So let's say, for example, you wanted to learn something

18:07.880 --> 18:11.880
in a new field of machine learning, right?

18:11.880 --> 18:14.560
So we may have thousands and thousands of sources

18:14.560 --> 18:18.160
because our Safari platform doesn't just rely on our content,

18:18.160 --> 18:20.760
it relies on our content partners as well.

18:21.880 --> 18:25.200
So we will have to organize, you can do a search,

18:25.200 --> 18:28.200
so that's one way for you to probably navigate

18:28.200 --> 18:29.960
our Safari platform.

18:29.960 --> 18:33.680
But increasingly, we've, we're finding that

18:33.680 --> 18:36.840
people want kind of curated content, right?

18:36.840 --> 18:39.880
So how do I learn about this new topic?

18:39.880 --> 18:43.960
Well, we'll use kind of the combination

18:43.960 --> 18:47.680
of humans and machines to organize a learning path for you

18:47.680 --> 18:52.680
or a resource center inside Safari.

18:53.360 --> 18:58.360
So I think that whole taxonomy creation

19:01.320 --> 19:05.080
and grappling with data integration

19:05.080 --> 19:10.080
and unstructured data, those are our main challenges.

19:10.080 --> 19:15.080
And have you invested much in personalization using

19:16.760 --> 19:19.720
some of the machine learning and AI techniques

19:19.720 --> 19:21.880
that folks are using for that kind of stuff?

19:21.880 --> 19:26.880
I think I would say we're still in the early phases

19:26.920 --> 19:28.640
work in progress.

19:28.640 --> 19:30.560
Yeah, that's a good point to be honest

19:30.560 --> 19:34.160
because people learn differently, right?

19:34.160 --> 19:38.720
So each individual learn differently from another.

19:38.720 --> 19:42.360
And so to the extent that we are,

19:42.360 --> 19:45.160
at least on our online division,

19:45.160 --> 19:49.720
we are trying to build the best learning platform.

19:49.720 --> 19:52.040
So a lot of that will increasingly

19:52.040 --> 19:54.160
have to rely on personalization.

19:54.160 --> 19:58.000
But I would say we're still in the early, early stages.

19:59.480 --> 20:03.800
And do you have a particular vision in mind

20:03.800 --> 20:08.800
for how the technology is put to use,

20:09.680 --> 20:14.120
to enable a certain kind of experience?

20:14.120 --> 20:16.960
Like do you have a sense for what that experience

20:16.960 --> 20:18.680
looks and feels like and how it's different

20:18.680 --> 20:21.040
from what someone might experience today

20:21.040 --> 20:25.000
and then what the supporting pieces might need to be?

20:25.000 --> 20:27.680
Yeah, in our case, because for example,

20:27.680 --> 20:32.680
many Safari users use them through their companies.

20:32.680 --> 20:34.560
Let's say you work for a large company

20:34.560 --> 20:39.560
that has a subscription to Safari.

20:40.560 --> 20:41.560
Right.

20:41.560 --> 20:44.960
So it will be kind of a combination of you

20:44.960 --> 20:48.480
us serving you content personalized to you,

20:48.480 --> 20:51.360
but us also serving you content

20:51.360 --> 20:56.520
that kind of reflects what your particular organization

20:56.520 --> 21:01.520
is emphasizing or the rest of your team members

21:01.520 --> 21:03.680
are learning about.

21:03.680 --> 21:07.160
So, yeah.

21:07.160 --> 21:08.760
And then the other thing Sam actually,

21:08.760 --> 21:10.840
I should mention is that inside Safari,

21:10.840 --> 21:15.920
we now have live online training on many of the topics

21:15.920 --> 21:18.000
that your listeners might be interested in,

21:18.000 --> 21:23.000
including big data, infrastructure and architecture,

21:24.560 --> 21:28.440
machine learning, data science,

21:28.440 --> 21:32.360
and increasingly we're finding actually

21:32.360 --> 21:37.200
there's a lot of demand for content

21:37.200 --> 21:41.320
that I would describe as much more non-technical.

21:41.320 --> 21:44.440
So a lot of people are grappling with.

21:44.440 --> 21:46.760
They read about a specific topic.

21:48.040 --> 21:51.640
They may not need to implement it right away,

21:51.640 --> 21:55.160
but they need to know at a high level what it is about

21:55.160 --> 21:59.400
and should they be bringing that into their company.

21:59.400 --> 22:04.400
And if so, what are some of the steps they should do

22:05.480 --> 22:08.840
to integrate such and such technology

22:08.840 --> 22:11.520
or technique into their existing products?

22:15.040 --> 22:20.040
Well, so you talked a little bit about the kind of exposure

22:20.360 --> 22:23.880
you get in terms of in your roles

22:23.880 --> 22:25.800
with the different conferences.

22:26.800 --> 22:30.920
I'm interested in kind of taking your temperature on,

22:30.920 --> 22:33.080
you know, the various trends you're seeing out there

22:33.080 --> 22:36.560
and what you're finding most interesting.

22:36.560 --> 22:37.560
Ah, so good.

22:37.560 --> 22:41.040
So I just gave a keynote about this in Israel yesterday.

22:41.040 --> 22:41.880
Oh, really?

22:41.880 --> 22:42.880
Oh, awesome.

22:42.880 --> 22:47.880
Yeah, so I would say on the machine learning side,

22:49.720 --> 22:52.560
last year I kind of told people that this year

22:52.560 --> 22:56.800
I think deep learning will become a machine learning technique

22:56.800 --> 22:59.640
that the people in the data science community

22:59.640 --> 23:00.800
will start using.

23:02.600 --> 23:05.200
So as you know, deep learning is a lot more associated

23:05.200 --> 23:06.800
with the other conference that I run,

23:06.800 --> 23:10.360
which is the AI conference, where they're grappling

23:10.360 --> 23:15.360
with data from images and video and audio,

23:17.480 --> 23:20.640
also computer vision and speech technologies

23:20.640 --> 23:21.920
and things like that.

23:21.920 --> 23:25.160
So what we're seeing is there's a lot of hunger

23:25.160 --> 23:28.640
in the data science community to see

23:28.640 --> 23:32.600
if they can take deep learning and use it

23:32.600 --> 23:36.480
to replace some other existing machine learning technique

23:36.480 --> 23:37.840
that they're using.

23:37.840 --> 23:40.360
So for example, some people are looking at it

23:40.360 --> 23:43.640
in terms of recommender systems.

23:43.640 --> 23:45.880
Some people are looking at it to replace

23:45.880 --> 23:48.600
how they do search rankings and things like that.

23:48.600 --> 23:52.080
So that's one trend.

23:52.080 --> 23:55.720
And so on the data science side,

23:55.720 --> 23:58.160
the other thing we're kind of seeing,

23:58.160 --> 24:02.880
and this might at this point be much more of a day area thing

24:02.880 --> 24:08.200
is that people are starting to talk about a role

24:08.200 --> 24:13.040
that is a hybrid between the classic data scientists

24:13.040 --> 24:14.440
and the data engineer.

24:14.440 --> 24:19.440
So a lot of people use the term machine learning engineer.

24:19.440 --> 24:24.440
So what it is is basically someone who is maybe

24:24.440 --> 24:27.440
a little stronger on the software engineering side.

24:27.440 --> 24:32.240
So they write code with the express intention

24:32.240 --> 24:36.160
that this might or this will be deployed into production.

24:36.160 --> 24:38.920
So it's not one off, sloppy.

24:39.920 --> 24:42.680
And then they also tend to think much more holistically.

24:42.680 --> 24:46.400
So if we're going to deploy this into production,

24:46.400 --> 24:49.240
what is our logging infrastructure,

24:49.240 --> 24:52.560
what is our AB testing infrastructure and so on.

24:52.560 --> 24:56.800
And then, yeah.

24:56.800 --> 25:01.800
So then the emphasis is on production

25:03.680 --> 25:05.960
and less on prototypes.

25:05.960 --> 25:06.960
Okay.

25:06.960 --> 25:11.960
And it's interesting how the role, you know,

25:12.960 --> 25:16.000
these roles just keep being redefined, right?

25:16.000 --> 25:18.040
I think a few years ago,

25:19.040 --> 25:21.960
the big conversation was that we saw,

25:21.960 --> 25:23.880
we actually thought of the data scientists

25:23.880 --> 25:25.600
as this monolithic person, right?

25:25.600 --> 25:27.360
They needed to know how to do everything, right?

25:27.360 --> 25:30.880
They needed to be, you know, statistically savvy,

25:32.000 --> 25:34.560
you know, and know the math behind, you know,

25:34.560 --> 25:37.080
the analytics and the machine learning stuff,

25:37.080 --> 25:41.240
they needed to, you know, understand how to get data

25:41.240 --> 25:43.560
from all these systems because, you know,

25:43.560 --> 25:45.920
their reality was that they spent, you know,

25:45.920 --> 25:47.480
80% of their time or more,

25:47.480 --> 25:49.560
just kind of shuffling data around.

25:50.080 --> 25:52.680
And then we started to get the, you know,

25:52.680 --> 25:55.480
the role started to split off a little bit.

25:55.480 --> 25:59.400
And you started to see, you know, data engineers,

25:59.400 --> 26:02.320
you know, being thought of as separate from, you know,

26:02.320 --> 26:03.560
machine learning people.

26:03.560 --> 26:05.840
And in some places, you'd pair those, you know,

26:05.840 --> 26:10.080
those two with, or I'm sorry, data engineers being,

26:10.080 --> 26:11.960
you know, separate from your data scientists.

26:11.960 --> 26:14.320
And in some places, you'd pair those two with, you know,

26:14.320 --> 26:17.840
your real professional programmers, software engineers.

26:17.840 --> 26:20.040
You know, now it sounds like you're saying,

26:20.040 --> 26:21.920
you know, we kind of came up with a new name.

26:21.920 --> 26:24.640
And it's, you know, again, it's this kind of unicorn

26:24.640 --> 26:26.560
that's supposed to know how to do everything.

26:27.560 --> 26:28.240
Am I reading it?

26:28.240 --> 26:29.400
Am I reading that right?

26:29.400 --> 26:33.720
I would say, no, I mean, I slightly, yeah,

26:33.720 --> 26:36.920
but I think the original term of data scientists

26:36.920 --> 26:40.000
was exactly what you described, which was the unicorn.

26:40.000 --> 26:44.400
This is not someone who has a PhD in machine learning

26:44.400 --> 26:45.320
necessarily, right?

26:45.320 --> 26:47.160
So maybe the background here is much more

26:47.160 --> 26:49.760
of us on the engineering side.

26:49.760 --> 26:54.800
And then they learn it enough machine learning

26:54.800 --> 26:59.800
to know how to basically build machine learning

26:59.840 --> 27:00.880
enabled products.

27:00.880 --> 27:01.880
Got it, got it.

27:01.880 --> 27:04.960
And part of that is that, you know,

27:04.960 --> 27:09.440
the emphasis on production means also knowing

27:09.440 --> 27:13.120
what to do with these models once they hit production, right?

27:13.120 --> 27:18.120
So how to tell when a model gets stale, you know,

27:18.120 --> 27:21.400
and things like that, and when do we need to retrain it?

27:21.400 --> 27:25.240
So, but I would say the background might be much more

27:25.240 --> 27:29.800
on the engineering side and then learn enough machine learning

27:29.800 --> 27:34.800
to start being able to move much more fast, right?

27:36.440 --> 27:39.960
And there might still be data scientists in the organization

27:39.960 --> 27:44.960
to kind of build the prototypes,

27:45.960 --> 27:50.880
but increasingly, I think at least a simpler machine learning

27:50.880 --> 27:54.760
things, maybe this machine learning engineer can take on.

27:54.760 --> 27:58.200
And in fact, actually, if you talk to companies

27:58.200 --> 28:01.400
that use a lot of deep learning,

28:01.400 --> 28:04.600
they even have a much more specific role,

28:04.600 --> 28:06.760
which they call the deep learning engineer, right?

28:08.360 --> 28:10.920
Okay, so then other trends.

28:10.920 --> 28:15.440
So on the data, so the other thing that I pointed,

28:15.440 --> 28:17.960
I've been pointing out to people is this notion

28:17.960 --> 28:22.320
that we've had a lot of progress in machine learning, right?

28:22.320 --> 28:26.280
So you can just read online publications

28:26.280 --> 28:28.440
and there's all sorts of papers being released,

28:28.440 --> 28:30.520
lots of interesting developments, right?

28:30.520 --> 28:33.440
So, and that's great, right?

28:33.440 --> 28:37.360
So, but then I've been, what I've been telling people,

28:37.360 --> 28:41.320
there's an imagine a scenario where nothing happens

28:41.320 --> 28:44.600
on the research front for the next five to 10 years,

28:44.600 --> 28:45.880
or next five years, right?

28:45.880 --> 28:50.880
So, I mean, so my position is that there's still

28:52.080 --> 28:54.560
so much low-hanging fruit in many companies,

28:54.560 --> 28:59.560
including us or Riley, that you can just take what we know now,

29:00.560 --> 29:02.680
you can take what we know now and implement it,

29:02.680 --> 29:05.640
implement it, and we're going to be fine.

29:06.720 --> 29:08.160
We're still going to be fine, right?

29:08.160 --> 29:10.800
So, like I said earlier, we're still grappling

29:10.800 --> 29:12.920
with data integration, right?

29:12.920 --> 29:14.800
Yeah, and I don't think that you guys

29:14.800 --> 29:18.880
are necessarily unique among enterprises.

29:18.880 --> 29:23.880
I think there are some large sophisticated enterprises

29:24.160 --> 29:28.320
that are kind of at the front edge of this thing,

29:28.320 --> 29:31.080
but a lot of folks are really just in the stage

29:31.080 --> 29:33.880
of trying to figure out where it fits

29:33.880 --> 29:37.600
and how to best apply it and where they can extract

29:37.600 --> 29:42.600
the most value and how to put together the teams

29:42.600 --> 29:47.600
to be able to do it because of the talent shortages

29:48.200 --> 29:50.080
as you're well aware.

29:50.080 --> 29:53.080
Yeah, and then to be honest, there's been a lot of progress.

29:53.080 --> 29:57.400
So, now we have to take a lot of those ideas and use them.

29:59.040 --> 30:02.920
And to a large extent, actually, I think that

30:02.920 --> 30:07.920
while we have been fascinated with kind of horizontal platforms,

30:08.480 --> 30:11.800
I think a lot of the interesting applications

30:11.800 --> 30:13.800
of these machine learning models

30:13.800 --> 30:17.320
will be in kind of verticalized applications, right?

30:17.320 --> 30:21.320
So, and I think we'll increasingly see companies

30:24.080 --> 30:28.600
specialized in inserving these industries.

30:28.600 --> 30:32.760
And interestingly, actually, there's a intersection

30:32.760 --> 30:36.760
with the AI community in the sense that

30:36.760 --> 30:41.760
while we read a lot about the general AI,

30:43.600 --> 30:47.880
actually the way the DC community and investors,

30:47.880 --> 30:50.200
at least when you talk to them, have been investing

30:50.200 --> 30:54.720
is they're investing in focused applications, right?

30:54.720 --> 30:59.720
So, whatever that might be, security, drug discovery

31:00.120 --> 31:01.200
and things like that.

31:01.200 --> 31:06.200
So, the other thing that I've been talking to people

31:06.960 --> 31:10.080
about is training data, right?

31:10.080 --> 31:14.200
So, we sometimes forget that a lot of the developments

31:14.200 --> 31:17.360
in deep learning really relied on the existence

31:17.360 --> 31:20.000
of large labeled training data sets.

31:20.000 --> 31:22.920
And to the extent that if you survey companies,

31:22.920 --> 31:25.920
I think that still remains the bottleneck, right?

31:25.920 --> 31:27.800
So, it's not the model.

31:27.800 --> 31:31.520
It's not delivering great models.

31:31.520 --> 31:34.400
It's just coming up with training data.

31:34.400 --> 31:38.160
And there's a lot of interesting things happening, right?

31:38.160 --> 31:39.680
So, in the deep learning community,

31:39.680 --> 31:43.280
you have these generative models

31:43.280 --> 31:48.280
to mostly around generative adversarial networks, right?

31:49.160 --> 31:52.240
But then also in the data science community,

31:52.240 --> 31:54.600
there's interesting work, for example,

31:54.600 --> 31:59.600
by my friend Chris Ray at Stanford, who had a system

32:00.200 --> 32:04.840
called deep dive, and now the next generation is snorkel,

32:04.840 --> 32:08.160
where they basically are able to take

32:09.840 --> 32:11.280
noisier data sources.

32:11.280 --> 32:14.240
So, they start with less labeled data,

32:14.240 --> 32:17.520
supplemented with noisier data sources,

32:17.520 --> 32:20.120
and then they're able to build much more accurate models.

32:20.120 --> 32:22.240
So, I think there's a lot of,

32:22.240 --> 32:24.720
we sometimes forget the importance of data.

32:24.720 --> 32:25.560
Yeah.

32:25.560 --> 32:30.560
And so, I think there'll be still a lot of interesting research

32:30.560 --> 32:35.560
in how we get to training data sets much more efficiently.

32:35.560 --> 32:37.840
And then on the machine learning side,

32:37.840 --> 32:41.520
the other thing that I've been talking a lot about recently

32:41.520 --> 32:45.200
is real time or live data.

32:45.200 --> 32:49.600
So, here I owe my inspiration to the rice lab,

32:49.600 --> 32:52.560
the successor to the amp lab.

32:52.560 --> 32:54.560
So, the amp lab, as people know,

32:54.560 --> 32:57.520
is developed that originated Apache Mesos,

32:57.520 --> 32:59.520
Apache Spark in Alaxia.

33:00.480 --> 33:02.320
So, the new lab, rice,

33:02.320 --> 33:06.720
stands for real time, intelligent, secure execution.

33:06.720 --> 33:10.720
So, live data is basically,

33:10.720 --> 33:14.800
basically think about an agent interacting with an environment,

33:14.800 --> 33:17.680
right, so a user interacting with a website,

33:17.680 --> 33:22.400
a robot navigating its environment, self-driving car,

33:22.400 --> 33:25.840
a player playing a computer assistant player,

33:25.840 --> 33:28.560
playing a computer game,

33:28.560 --> 33:31.240
like an Atari game or go.

33:31.240 --> 33:33.800
So, there you have an environment,

33:33.800 --> 33:36.800
you have an agent interacting with an environment.

33:36.800 --> 33:40.520
So, in the classic reinforcement learning sense,

33:40.520 --> 33:42.600
you're trying to learn a policy, right?

33:42.600 --> 33:44.360
So, given a state of the environment,

33:44.360 --> 33:47.560
what action should, what action should I take?

33:47.560 --> 33:49.960
But, you know, if you actually take a step back

33:49.960 --> 33:53.960
and kind of look at the flow of data

33:53.960 --> 33:56.000
in these types of applications,

33:56.000 --> 33:59.640
the first part looks a little bit like what we've been dealing

33:59.640 --> 34:01.320
with in recent years.

34:01.320 --> 34:04.240
So, it might look like a streaming application.

34:05.240 --> 34:08.440
So, you have data ingestion and things like that,

34:08.440 --> 34:10.280
stream processing and things like that.

34:10.280 --> 34:13.240
But the machine learning part is slightly different, right?

34:13.240 --> 34:15.520
So, in the reinforcement learning sense,

34:15.520 --> 34:17.880
you're trying to learn this policy,

34:17.880 --> 34:20.520
you have to run a lot of simulations,

34:20.520 --> 34:23.400
you have heterogeneous computer graphs,

34:23.400 --> 34:27.000
and if it's truly a live application,

34:27.000 --> 34:31.120
you need to have merely second latency, right?

34:31.120 --> 34:35.280
So, then it turns out the existing frameworks

34:35.280 --> 34:39.200
we have are not able to do machine learning

34:39.200 --> 34:42.640
in these really live dynamic environments.

34:42.640 --> 34:46.280
Yeah, so the classic tools that we've been using

34:46.280 --> 34:50.480
aren't able to do the machine learning

34:50.480 --> 34:51.840
you need in these environments,

34:51.840 --> 34:56.280
which I think increasingly will be much more common, right?

34:56.280 --> 35:00.400
So, as the tools get better,

35:00.400 --> 35:03.360
the use cases will make up much more clear.

35:03.360 --> 35:06.560
So, the people at Rice Lab,

35:06.560 --> 35:08.800
took a look and kind of surveyed,

35:08.800 --> 35:09.640
so what's out there,

35:09.640 --> 35:12.800
and then they realized the computational framework

35:12.800 --> 35:15.960
for these types of applications don't exist, right?

35:15.960 --> 35:20.960
So, then they ended up building one called Ray,

35:21.480 --> 35:23.520
which is out in Alpha,

35:23.520 --> 35:27.360
and Ashley, we're gonna do a tutorial

35:27.360 --> 35:31.800
on reinforcement learning using Ray

35:31.800 --> 35:35.000
at our AI conference in San Francisco.

35:35.000 --> 35:38.080
But the other thing I wanted to emphasize here

35:38.080 --> 35:43.520
is that the interesting thing to me

35:43.520 --> 35:46.880
is kind of machine learning in this live environment, right?

35:46.880 --> 35:47.880
Sorry.

35:47.880 --> 35:49.640
It turns out right now that people

35:49.640 --> 35:51.240
are using reinforcement learning,

35:51.240 --> 35:55.200
but there's other techniques that might emerge.

35:55.200 --> 35:58.240
And the interesting thing about Ray

35:58.240 --> 36:02.080
is that you can use it for reinforcement learning

36:02.080 --> 36:04.240
or other approaches.

36:04.240 --> 36:06.840
So, for example, the OpenAI folks

36:06.840 --> 36:08.560
recently published a paper

36:08.560 --> 36:11.360
where they use evolutionary algorithms, right?

36:11.360 --> 36:14.560
So to solve some of the things

36:14.560 --> 36:17.120
that you would do with reinforcement learning.

36:17.120 --> 36:21.400
But the interesting thing is that Rice Lab people

36:21.400 --> 36:25.200
took that paper and basically they just implemented

36:25.200 --> 36:29.800
this evolutionary algorithm in Ray, no problem.

36:29.800 --> 36:33.080
So, like I said,

36:33.080 --> 36:37.920
I think that the tools are kind of a work in progress

36:37.920 --> 36:40.960
and that includes Ray and as the tools get better,

36:40.960 --> 36:45.040
then people will start using these tools

36:45.040 --> 36:48.360
and then the use cases will be much more clear.

36:48.360 --> 36:53.200
But basically think about any kind of dynamic setting

36:53.200 --> 36:56.800
where you want to be able to take advantage

36:56.800 --> 36:58.160
of machine learning.

36:58.160 --> 36:59.680
And right now I would say Sam,

36:59.680 --> 37:03.320
that my other conference, the AI conference is definitely

37:03.320 --> 37:07.400
much more aware and interested in focus

37:07.400 --> 37:09.400
on these types of applications.

37:09.400 --> 37:11.800
So, for example, we're already seeing

37:11.800 --> 37:14.960
that reinforcement learning content in tutorials

37:14.960 --> 37:17.600
are very popular at that conference.

37:17.600 --> 37:19.520
But I think as the tools get better,

37:19.520 --> 37:23.200
maybe we'll start seeing the data science community

37:23.200 --> 37:25.000
start using them to write.

37:25.000 --> 37:29.000
So, for example, look back three years ago,

37:29.000 --> 37:31.240
deep learning would have been inaccessible

37:31.240 --> 37:33.040
to the data science community.

37:33.040 --> 37:36.840
We didn't write the tools, like TensorFlow, MxNet,

37:36.840 --> 37:39.440
BigDL, and PyTorch, and all these things.

37:39.440 --> 37:41.600
But as the tools got better,

37:41.600 --> 37:43.560
people start kicking the tires, right?

37:43.560 --> 37:45.920
So, go ahead, Sam.

37:45.920 --> 37:49.960
I was just going to drill into your comment

37:49.960 --> 37:52.040
about reinforcement learning.

37:52.040 --> 37:55.480
You know, typically the literature in talking

37:55.480 --> 37:58.840
about reinforcement learning is looking at kind of an agent

37:58.840 --> 38:05.320
exploring an environment and trying to maximize some policy.

38:05.320 --> 38:09.920
So, the off-sighted example is like an agent

38:09.920 --> 38:12.440
being trained to play Atari video games,

38:12.440 --> 38:15.160
like breakout and maximize their score.

38:16.960 --> 38:18.720
Do you have a sense for how this translates

38:18.720 --> 38:23.720
into the real-time streaming machine learning example

38:23.720 --> 38:28.720
that, or even industrial enterprise type scenarios?

38:31.120 --> 38:36.120
You know, I think that the use cases still need to be worked out

38:37.520 --> 38:41.320
by you can imagine a personalization

38:41.320 --> 38:43.160
on the website, maybe, right?

38:43.160 --> 38:46.720
So, where you're interacting with a website,

38:46.720 --> 38:48.720
much like you're interacting with a game.

38:48.720 --> 38:49.720
Right.

38:49.720 --> 38:54.720
I mean, it's on the AI side, you're gonna see applications

38:55.680 --> 38:59.800
in autonomous vehicles and drones.

38:59.800 --> 39:00.640
Sure.

39:02.480 --> 39:04.560
Maybe in inventory management,

39:04.560 --> 39:08.760
if you really need real-time inventory management,

39:08.760 --> 39:13.400
definitely the finance people might be interested in this

39:13.400 --> 39:17.120
from trading strategies or portfolio design.

39:17.120 --> 39:22.120
And then resource allocation, if you imagine the scenario

39:22.600 --> 39:27.600
where resource allocation with live data becomes prevalent.

39:30.280 --> 39:35.280
But definitely robots are in any kind of robotic environment,

39:35.280 --> 39:38.560
so a robotic application is already using it.

39:38.560 --> 39:43.560
But I think I imagine a place, a scenario where

39:43.560 --> 39:48.560
if the tools get better, the people will probably

39:51.240 --> 39:53.520
find the right use cases.

39:53.520 --> 39:55.080
Sure, sure.

39:55.080 --> 39:57.080
Yeah, one of the other things that I find interesting

39:57.080 --> 40:00.800
about the whole real-time machine learning scenario,

40:00.800 --> 40:03.560
and let me know if you have come across this

40:03.560 --> 40:04.680
or have any thoughts on this,

40:04.680 --> 40:06.320
but there seems to be,

40:07.760 --> 40:10.560
there seems to be in those kinds of environments,

40:10.560 --> 40:15.080
a merging of traditionally your training and inference

40:15.080 --> 40:16.760
are two totally different things.

40:16.760 --> 40:19.520
And when we're talking about kind of real-time streaming data

40:19.520 --> 40:22.400
more and more, I see people wanting to do things

40:22.400 --> 40:24.400
like active learning where they're,

40:25.840 --> 40:30.840
the learning is real-time in addition to the inference,

40:30.840 --> 40:35.640
which folks more easily do real-time now.

40:35.640 --> 40:37.320
Is that what you're seeing as well?

40:37.320 --> 40:41.360
Uh, yes, to some extent.

40:41.360 --> 40:46.360
I mean, I think that the use cases that I'm interested in

40:47.880 --> 40:50.720
tend to still separate the training inference.

40:50.720 --> 40:53.720
I mean, the use cases that I'm much more familiar with

40:53.720 --> 40:58.240
tend to still separate the training inference.

40:58.240 --> 41:01.360
I think there are people who are kind of pushing

41:01.360 --> 41:06.280
the envelope towards much more of this online learning scenario.

41:06.280 --> 41:08.840
But then, but then now we start getting into the scenario

41:08.840 --> 41:10.040
I just described, right?

41:10.040 --> 41:13.720
So we're just kind of learning really with live data

41:13.720 --> 41:17.960
and interacting with an environment, right?

41:17.960 --> 41:21.200
So where you have,

41:21.200 --> 41:24.560
where simulations and explorations,

41:24.560 --> 41:28.040
the ability to do those at large scale at very low latency

41:29.560 --> 41:31.720
come into play and those scenarios

41:31.720 --> 41:33.400
are really quite different.

41:33.400 --> 41:34.880
Yeah.

41:34.880 --> 41:37.080
And actually, this is a good tag way

41:37.080 --> 41:38.720
to the last thing I wanted to emphasize,

41:38.720 --> 41:42.000
which is compute, right?

41:42.000 --> 41:45.840
So you were in the age of big models,

41:45.840 --> 41:47.680
which is deep learning, big data,

41:47.680 --> 41:52.920
which is the training data and live data and big compute,

41:52.920 --> 41:54.320
right? So as you mentioned,

41:57.480 --> 42:00.480
in this scenario, we need everything, right?

42:00.480 --> 42:03.160
So we need scale, throughput, latency,

42:03.160 --> 42:05.600
all of that with low power consumption.

42:05.600 --> 42:08.040
So I think there's a lot of interesting things

42:08.040 --> 42:12.560
happening there like what is the future infrastructure

42:12.560 --> 42:13.840
for machine learning, right?

42:13.840 --> 42:18.840
So I think those are still very active areas.

42:19.560 --> 42:23.240
A lot of things happening at a rapid clip, right?

42:23.240 --> 42:28.240
So both from the GPU side, the CPU side,

42:28.240 --> 42:33.240
the CPU side, FPGAs and ASICs and all of that, right?

42:33.240 --> 42:38.240
So, yeah, so I think sometimes people forget

42:38.240 --> 42:41.480
that to make all of this work,

42:41.480 --> 42:42.960
you still need hardware, right?

42:45.960 --> 42:50.840
And hardware, there's a lot of trade offs

42:50.840 --> 42:51.920
when you get to hardware.

42:51.920 --> 42:54.880
Yeah, yeah, and unfortunately, I think for a lot of people

42:54.880 --> 42:57.640
working in the space, you can't forget it enough, right?

42:57.640 --> 43:02.640
I think over time, the level of abstraction

43:02.880 --> 43:06.480
is gonna have to raise where people can just have

43:06.480 --> 43:09.200
the full flexibility to do the things that they wanna do

43:09.200 --> 43:14.200
without having to think about how they can figure their jobs

43:14.560 --> 43:19.120
to run on GPUs or distributed or what have you.

43:19.120 --> 43:22.480
But still, I think a lot of thoughts still has to happen.

43:22.480 --> 43:26.160
More thought than it should be, right?

43:26.160 --> 43:30.240
Yeah, but I think, I think we're getting to the point

43:30.240 --> 43:32.440
where you got these tools for hardware

43:32.440 --> 43:37.440
and software acceleration and then the software libraries.

43:38.120 --> 43:43.120
So I think that for most practitioners,

43:43.640 --> 43:45.280
the only time they'll think about it

43:45.280 --> 43:47.080
is when they look at their bill, right?

43:47.080 --> 43:51.280
So, it's nice.

43:51.280 --> 43:54.560
At least for most practitioners, right?

43:54.560 --> 43:57.560
But then for the bleeding edge researchers

43:57.560 --> 43:59.920
who have to worry really at the low level,

43:59.920 --> 44:03.440
like at the level of interconnects and things like that,

44:03.440 --> 44:06.600
because they're trying to break or set the record

44:06.600 --> 44:09.560
for speech recognition a lot of that still matters.

44:09.560 --> 44:13.280
But for regular people, it's just the cost,

44:13.280 --> 44:16.560
I think, is what they're gonna end up.

44:16.560 --> 44:18.960
That's how they're gonna know what they're using, right?

44:18.960 --> 44:25.960
So the other thing that, or another thing that I often enjoy

44:26.080 --> 44:30.480
chatting with you about is the interesting startups

44:30.480 --> 44:33.480
that are doing interesting things,

44:33.480 --> 44:36.360
both in Silicon Valley and around the world.

44:36.360 --> 44:39.240
What, anything come to mind there,

44:39.240 --> 44:43.840
or I'm particularly interested in ones that we don't hear

44:43.840 --> 44:48.840
about all the time that may be in other parts of the world.

44:51.920 --> 44:55.720
You know, there's a bunch of startups in China

44:57.000 --> 45:02.000
that I'm not sure people here have heard of,

45:04.720 --> 45:09.720
but just generally around applying deep learning

45:09.720 --> 45:13.720
to whatever vertical, right?

45:13.720 --> 45:17.080
So manufacturing, drones.

45:18.920 --> 45:23.520
And to some extent, there's similar applications

45:23.520 --> 45:26.120
that we would see here, but for that market, right?

45:26.120 --> 45:31.120
So for speech recognition and intelligent chatbots

45:34.080 --> 45:35.080
and things like that.

45:35.080 --> 45:40.080
But I would say, actually, so if you look at the AI,

45:42.040 --> 45:46.720
so the one country that I think is really interesting

45:46.720 --> 45:50.560
in terms of its excitement and fascination for AI

45:50.560 --> 45:51.600
is China, right?

45:51.600 --> 45:55.880
So just organizing a conference there

45:55.880 --> 46:00.880
and people just are dying for content in this area.

46:00.880 --> 46:05.880
So in terms of startups, I would say,

46:06.200 --> 46:07.600
I don't know how you feel about it,

46:07.600 --> 46:10.240
but I'm really interested in the startups

46:10.240 --> 46:12.400
that are much more focused.

46:12.400 --> 46:16.240
Yeah, because you know, I think the whole,

46:16.240 --> 46:17.520
if you're gonna do a platform,

46:17.520 --> 46:21.480
it's gonna be tough to compete with these cloud providers,

46:21.480 --> 46:24.320
right, so unless you have a platform

46:24.320 --> 46:26.720
that's focused on a vertical maybe, right?

46:26.720 --> 46:31.320
But, you know, I mean, Amazon, Google, Microsoft,

46:31.320 --> 46:34.400
they have pretty impressive tools for doing,

46:35.280 --> 46:40.080
for doing almost the end to end, right?

46:40.080 --> 46:43.640
So for building these applications.

46:43.640 --> 46:46.240
But if you were very, very focused,

46:46.240 --> 46:48.600
I think that's where you can excel.

46:49.600 --> 46:54.600
So you might be a focused startup on drug discovery

46:54.600 --> 46:58.600
or even actually you can take an area like computer vision, right?

46:58.600 --> 47:01.600
So I happen to advise a startup called Matroid

47:01.600 --> 47:07.600
that's trying to be kind of a computer-fishing enabler

47:08.600 --> 47:10.600
for many companies.

47:11.600 --> 47:13.600
So then they can, they can,

47:13.600 --> 47:17.600
they can, they can take kind of much more of the product approach

47:17.600 --> 47:20.600
in terms of how do companies use this easily

47:20.600 --> 47:22.600
to solve problems, right?

47:22.600 --> 47:27.600
So whatever, whatever, it might be summarizing surveillance cameras

47:27.600 --> 47:29.600
and things like that.

47:29.600 --> 47:33.600
I mean, I guess you can build all of these things yourself

47:33.600 --> 47:36.600
using existing tools or the cloud,

47:36.600 --> 47:39.600
but they already have a product

47:39.600 --> 47:43.600
that your analysts can use, non-programmers, right?

47:44.600 --> 47:49.600
So I'm quite interested in companies like that.

47:49.600 --> 47:52.600
I've been trying to kind of get a,

47:52.600 --> 47:54.600
as you mentioned earlier,

47:54.600 --> 47:57.600
as to whether I pay attention to finance.

47:57.600 --> 47:59.600
I've been recently trying to figure out

47:59.600 --> 48:02.600
what's happening in finance on some of these technologies

48:02.600 --> 48:04.600
and I haven't.

48:04.600 --> 48:07.600
I don't have a quick answer, right?

48:07.600 --> 48:11.600
So it seems like there's a mix of hype and reality.

48:12.600 --> 48:17.600
But finance is kind of also a peculiar industry

48:17.600 --> 48:20.600
in the sense that maybe the most interesting things

48:20.600 --> 48:23.600
are happening in companies who don't want to talk to you.

48:23.600 --> 48:24.600
Yeah, yeah.

48:24.600 --> 48:25.600
Finance can be like.

48:25.600 --> 48:26.600
I know what I mean.

48:26.600 --> 48:29.600
So, so recently, for example, I tried to,

48:29.600 --> 48:32.600
I had one of my editors,

48:32.600 --> 48:38.600
I introduced him to a bunch of companies, right?

48:38.600 --> 48:43.600
So in finance and to try to get a handle on what's happening.

48:43.600 --> 48:45.600
It's just hard.

48:45.600 --> 48:48.600
The people that we think are doing interesting things

48:48.600 --> 48:49.600
don't want to talk.

48:49.600 --> 48:50.600
So.

48:50.600 --> 48:51.600
Yeah.

48:51.600 --> 48:52.600
Yeah.

48:54.600 --> 48:55.600
What else?

48:55.600 --> 48:56.600
So I think,

48:56.600 --> 48:57.600
I think,

48:57.600 --> 48:59.600
like I said, data,

48:59.600 --> 49:03.600
is still going to be an important thing.

49:03.600 --> 49:06.600
So I think people who have interesting data

49:06.600 --> 49:11.600
who are able to take public data and make it usable.

49:11.600 --> 49:12.600
Right?

49:12.600 --> 49:15.600
I guess Chris Ray and Mike Afarella

49:15.600 --> 49:18.600
have this notion of dark data.

49:18.600 --> 49:19.600
Right?

49:19.600 --> 49:20.600
So,

49:20.600 --> 49:23.600
taking data that's very unstructured

49:23.600 --> 49:24.600
in making,

49:24.600 --> 49:26.600
in infusing it with structure

49:26.600 --> 49:29.600
so that you can use it for applications.

49:29.600 --> 49:30.600
Of course,

49:30.600 --> 49:32.600
I think there's still a lot of,

49:32.600 --> 49:36.600
there's still a lot of competitive advantage

49:36.600 --> 49:40.600
to people who have good data.

49:40.600 --> 49:42.600
So what's next?

49:42.600 --> 49:45.600
Well, the AI conference is next literally.

49:45.600 --> 49:48.600
It's coming up at the end of June.

49:48.600 --> 49:50.600
And I mentioned to you

49:50.600 --> 49:54.600
that this podcast is going to be published

49:54.600 --> 49:57.600
at the same time we're announcing a winner

49:57.600 --> 49:59.600
of a giveaway,

49:59.600 --> 50:02.600
a ticket giveaway for the AI conference.

50:02.600 --> 50:05.600
And one question that I had for you was,

50:05.600 --> 50:07.600
you know, I attended the first one.

50:07.600 --> 50:08.600
It was a great event.

50:08.600 --> 50:10.600
I had lots of great conversations there.

50:10.600 --> 50:11.600
I heard great talks.

50:11.600 --> 50:12.600
Yeah.

50:12.600 --> 50:13.600
What's going to be different

50:13.600 --> 50:15.600
about the second event?

50:15.600 --> 50:16.600
So a few things.

50:16.600 --> 50:17.600
One,

50:17.600 --> 50:19.600
the first event was a 2D event.

50:19.600 --> 50:21.600
We did not have training

50:21.600 --> 50:23.600
or tutorials.

50:23.600 --> 50:24.600
So at this event,

50:24.600 --> 50:25.600
we will have both.

50:25.600 --> 50:26.600
So for example,

50:26.600 --> 50:28.600
we have 2D training

50:28.600 --> 50:33.600
on deep learning with TensorFlow.

50:33.600 --> 50:35.600
And then a bunch of other trainings.

50:35.600 --> 50:40.600
And one that stands out is 2D training on,

50:40.600 --> 50:43.600
on NLP with deep learning

50:43.600 --> 50:45.600
with my friend Delip Brown.

50:45.600 --> 50:46.600
Along.

50:46.600 --> 50:48.600
And Delip is also,

50:48.600 --> 50:50.600
Delip is also the organizer of

50:50.600 --> 50:54.600
a fake, fake news challenge.

50:54.600 --> 50:56.600
And so the winners of which

50:56.600 --> 50:59.600
will present at the conference.

50:59.600 --> 51:01.600
Is this generating on the tutorial side?

51:01.600 --> 51:02.600
Detecting.

51:02.600 --> 51:03.600
Yeah.

51:03.600 --> 51:05.600
Yeah, yeah.

51:05.600 --> 51:07.600
And on the tutorial side,

51:07.600 --> 51:10.600
we have a bunch of interesting tutorials

51:10.600 --> 51:13.600
from reinforcement learning.

51:13.600 --> 51:16.600
In this particular edition of the conference,

51:16.600 --> 51:20.600
we're actually going to offer tutorials on a variety of

51:20.600 --> 51:21.600
deep learning frameworks.

51:21.600 --> 51:22.600
Right.

51:22.600 --> 51:23.600
So not just TensorFlow.

51:23.600 --> 51:24.600
We have.

51:24.600 --> 51:25.600
Okay.

51:25.600 --> 51:28.600
Big D L and MX net.

51:28.600 --> 51:29.600
Okay.

51:29.600 --> 51:31.600
We're also trying not to be a deep,

51:31.600 --> 51:36.600
we're trying to be the industry gathering place for AI

51:36.600 --> 51:39.600
where you can learn about many,

51:39.600 --> 51:41.600
many different techniques in AI

51:41.600 --> 51:45.600
and how to use it in your organization or your company.

51:45.600 --> 51:46.600
Okay.

51:46.600 --> 51:47.600
So to that,

51:47.600 --> 51:48.600
and we're also,

51:48.600 --> 51:51.600
we're also going to offer trainings in non-deep learning techniques

51:51.600 --> 51:53.600
like probabilistic programming.

51:53.600 --> 51:54.600
Uh-huh.

51:54.600 --> 51:56.600
And what else?

51:56.600 --> 51:57.600
So the other actually,

51:57.600 --> 52:00.600
so reinforcement learning is a popular tutorial.

52:00.600 --> 52:01.600
It's emerging.

52:01.600 --> 52:02.600
As I mentioned earlier,

52:02.600 --> 52:05.600
and the other popular tutorials have

52:05.600 --> 52:08.600
are once aimed at the non-technical audience, right?

52:08.600 --> 52:09.600
So how do I bring,

52:09.600 --> 52:11.600
how do I manage an AI project?

52:11.600 --> 52:14.600
How do I bring AI back into my company?

52:14.600 --> 52:15.600
Right.

52:15.600 --> 52:16.600
Um,

52:16.600 --> 52:20.600
and then all the keynotes are going to be great.

52:20.600 --> 52:21.600
Right.

52:21.600 --> 52:22.600
So we have,

52:22.600 --> 52:23.600
uh,

52:23.600 --> 52:25.600
David Farucci,

52:25.600 --> 52:26.600
Dave Farucci,

52:26.600 --> 52:28.600
who led the IBM team,

52:28.600 --> 52:30.600
uh, that one jeopardy,

52:30.600 --> 52:31.600
the quiz show.

52:31.600 --> 52:32.600
Okay.

52:32.600 --> 52:33.600
So he hasn't spoken in many,

52:33.600 --> 52:34.600
in many years,

52:34.600 --> 52:36.600
but he has a new research outset

52:36.600 --> 52:38.600
called elemental cognition.

52:38.600 --> 52:39.600
Mm-hmm.

52:39.600 --> 52:41.600
So he's going to give a keynote about what they're up to,

52:41.600 --> 52:42.600
which is basically,

52:42.600 --> 52:43.600
they're trying,

52:43.600 --> 52:45.600
they're taking one of the grand challenges

52:45.600 --> 52:48.600
of AI natural language understanding

52:48.600 --> 52:49.600
and, and basically,

52:49.600 --> 52:50.600
uh,

52:50.600 --> 52:52.600
trying to,

52:52.600 --> 52:53.600
uh,

52:53.600 --> 52:54.600
come up with a system

52:54.600 --> 52:55.600
that can,

52:55.600 --> 52:56.600
uh,

52:56.600 --> 52:57.600
do that well.

52:57.600 --> 52:58.600
Um,

52:58.600 --> 52:59.600
um,

52:59.600 --> 53:01.600
and then, uh,

53:01.600 --> 53:02.600
besides Dave giving a talk,

53:02.600 --> 53:03.600
uh,

53:03.600 --> 53:04.600
one of his colleagues

53:04.600 --> 53:06.600
will do a 40-minute session,

53:06.600 --> 53:07.600
deep dive,

53:07.600 --> 53:08.600
uh,

53:08.600 --> 53:09.600
what, uh,

53:09.600 --> 53:11.600
the technology and techniques

53:11.600 --> 53:12.600
elemental cognition,

53:12.600 --> 53:13.600
uh,

53:13.600 --> 53:14.600
is doing to,

53:14.600 --> 53:15.600
to correct natural language understanding.

53:15.600 --> 53:16.600
Okay.

53:16.600 --> 53:17.600
Uh,

53:17.600 --> 53:18.600
Josh,

53:18.600 --> 53:18.600
uh,

53:18.600 --> 53:20.600
Josh Tanenbaum of MIT,

53:20.600 --> 53:22.600
uh,

53:22.600 --> 53:23.600
you know,

53:23.600 --> 53:25.600
I've long been fascinated by,

53:25.600 --> 53:26.600
uh, what they do.

53:26.600 --> 53:27.600
So basically,

53:27.600 --> 53:28.600
they're trying to develop,

53:28.600 --> 53:29.600
uh,

53:29.600 --> 53:31.600
techniques

53:31.600 --> 53:32.600
that make,

53:32.600 --> 53:34.600
that help machines learn

53:34.600 --> 53:35.600
and think like people.

53:35.600 --> 53:36.600
So one,

53:36.600 --> 53:38.600
I think one of the things that,

53:38.600 --> 53:39.600
uh,

53:39.600 --> 53:40.600
deep learning is great at,

53:40.600 --> 53:41.600
is,

53:41.600 --> 53:42.600
uh,

53:42.600 --> 53:42.600
uh,

53:42.600 --> 53:43.600
perception

53:43.600 --> 53:44.600
and large scale,

53:44.600 --> 53:45.600
uh,

53:45.600 --> 53:46.600
and pattern recognition.

53:46.600 --> 53:48.600
But it's still,

53:48.600 --> 53:51.600
it's still relies on a lot of data.

53:51.600 --> 53:52.600
And so,

53:52.600 --> 53:53.600
Josh and his crew

53:53.600 --> 53:54.600
are trying to come up

53:54.600 --> 53:55.600
with alternative methods

53:55.600 --> 53:57.600
for maybe taking deep learning

53:57.600 --> 53:58.600
and infusing it

53:58.600 --> 54:00.600
with startup knowledge,

54:00.600 --> 54:01.600
uh,

54:01.600 --> 54:02.600
making it,

54:02.600 --> 54:03.600
uh,

54:03.600 --> 54:04.600
much more efficient,

54:04.600 --> 54:05.600
and much more similar

54:05.600 --> 54:06.600
to how people think.

54:06.600 --> 54:07.600
Okay.

54:07.600 --> 54:08.600
And then,

54:08.600 --> 54:08.600
uh,

54:08.600 --> 54:10.600
I don't know if you followed recently,

54:10.600 --> 54:12.600
but a group at Carnegie Mellon,

54:12.600 --> 54:13.600
uh,

54:13.600 --> 54:15.600
led by Thomas Sandholm,

54:15.600 --> 54:16.600
one,

54:16.600 --> 54:17.600
uh,

54:17.600 --> 54:18.600
uh,

54:18.600 --> 54:19.600
I'm not a poker player,

54:19.600 --> 54:20.600
but,

54:20.600 --> 54:21.600
uh,

54:21.600 --> 54:22.600
one of these poker tournaments,

54:22.600 --> 54:23.600
uh,

54:23.600 --> 54:25.600
where they beat out a bunch of,

54:25.600 --> 54:26.600
uh,

54:26.600 --> 54:27.600
human,

54:27.600 --> 54:28.600
human top human players.

54:28.600 --> 54:29.600
Okay.

54:29.600 --> 54:30.600
Uh,

54:30.600 --> 54:31.600
so similar in,

54:31.600 --> 54:32.600
you can think of this achievement

54:32.600 --> 54:33.600
that's basically almost

54:33.600 --> 54:34.600
at the scale of AlphaGo.

54:34.600 --> 54:35.600
Right.

54:35.600 --> 54:36.600
Right.

54:36.600 --> 54:37.600
People don't,

54:37.600 --> 54:38.600
uh,

54:38.600 --> 54:39.600
aren't as aware of it.

54:39.600 --> 54:40.600
So he's giving

54:40.600 --> 54:41.600
a key note about this.

54:41.600 --> 54:42.600
A lot.

54:42.600 --> 54:43.600
About,

54:43.600 --> 54:44.600
uh,

54:44.600 --> 54:45.600
how they,

54:45.600 --> 54:46.600
uh,

54:46.600 --> 54:47.600
won the tournament.

54:47.600 --> 54:48.600
Sounds like a great line up.

54:48.600 --> 54:49.600
And so,

54:49.600 --> 54:50.600
yeah,

54:50.600 --> 54:51.600
and just like the previous conference,

54:51.600 --> 54:53.600
we have,

54:53.600 --> 54:55.600
sessions on many of the techniques

54:55.600 --> 54:57.600
that the people are interested in,

54:57.600 --> 54:58.600
but much more,

54:58.600 --> 54:59.600
our focus is,

54:59.600 --> 55:00.600
uh,

55:00.600 --> 55:01.600
you know,

55:01.600 --> 55:03.600
we're also going to try to provide

55:03.600 --> 55:05.600
a track for people who are interested in,

55:05.600 --> 55:06.600
uh,

55:06.600 --> 55:08.600
how to bring these ideas

55:08.600 --> 55:09.600
and,

55:09.600 --> 55:10.600
uh,

55:10.600 --> 55:11.600
technologies and methods

55:11.600 --> 55:13.600
back into their organizations

55:13.600 --> 55:14.600
and,

55:14.600 --> 55:15.600
uh,

55:15.600 --> 55:17.600
implement them into their products.

55:17.600 --> 55:18.600
Okay.

55:18.600 --> 55:19.600
But, uh,

55:19.600 --> 55:20.600
we also try to,

55:20.600 --> 55:21.600
uh,

55:21.600 --> 55:23.600
I invited a bunch of my academic friends,

55:23.600 --> 55:24.600
uh,

55:24.600 --> 55:26.600
are going to be speaking at the conference about,

55:26.600 --> 55:27.600
uh,

55:27.600 --> 55:28.600
really cool things that,

55:28.600 --> 55:29.600
uh,

55:29.600 --> 55:30.600
industry people

55:30.600 --> 55:31.600
will find interesting,

55:31.600 --> 55:32.600
and maybe,

55:32.600 --> 55:34.600
kind of spark a conversation

55:34.600 --> 55:35.600
and,

55:35.600 --> 55:36.600
and see how,

55:36.600 --> 55:37.600
uh,

55:37.600 --> 55:38.600
we can,

55:38.600 --> 55:39.600
uh,

55:39.600 --> 55:40.600
you know,

55:40.600 --> 55:42.600
be a true gathering place for industry,

55:42.600 --> 55:43.600
uh,

55:43.600 --> 55:44.600
interested in,

55:44.600 --> 55:45.600
uh,

55:45.600 --> 55:46.600
building AI products.

55:46.600 --> 55:47.600
Awesome.

55:47.600 --> 55:48.600
Uh,

55:48.600 --> 55:49.600
it sounds like it's going to be a great time,

55:49.600 --> 55:50.600
and I'm,

55:50.600 --> 55:52.600
certainly looking forward to it.

55:52.600 --> 55:53.600
Um,

55:53.600 --> 55:54.600
and it'll be great to,

55:54.600 --> 55:55.600
you know,

55:55.600 --> 55:56.600
catch up with you in person once again.

55:56.600 --> 55:57.600
Cool.

55:57.600 --> 55:58.600
Yeah, yeah, yeah.

55:58.600 --> 55:59.600
And, uh,

55:59.600 --> 56:00.600
at the risk of,

56:00.600 --> 56:01.600
uh,

56:01.600 --> 56:02.600
being, uh,

56:02.600 --> 56:03.600
putting another plugin,

56:03.600 --> 56:04.600
but, uh,

56:04.600 --> 56:06.600
we also have an AI conference in San Francisco,

56:06.600 --> 56:07.600
in September.

56:07.600 --> 56:08.600
Absolutely.

56:08.600 --> 56:09.600
Uh,

56:09.600 --> 56:10.600
and we're still,

56:10.600 --> 56:11.600
uh,

56:11.600 --> 56:12.600
uh,

56:12.600 --> 56:13.600
where I would say 80%

56:13.600 --> 56:14.600
there,

56:14.600 --> 56:15.600
as far as completing the lineup,

56:15.600 --> 56:17.600
but it's already looking great.

56:17.600 --> 56:18.600
And,

56:18.600 --> 56:19.600
I'm sure you're,

56:19.600 --> 56:20.600
you'll be there too, right?

56:20.600 --> 56:21.600
Of course.

56:21.600 --> 56:22.600
Yep.

56:22.600 --> 56:23.600
Looking forward to it.

56:23.600 --> 56:24.600
Um, is,

56:24.600 --> 56:25.600
is there,

56:25.600 --> 56:26.600
uh,

56:26.600 --> 56:27.600
CFP still open for that,

56:27.600 --> 56:28.600
or has that been closed out?

56:28.600 --> 56:29.600
That's been closed out for,

56:29.600 --> 56:30.600
okay.

56:30.600 --> 56:31.600
San Francisco.

56:31.600 --> 56:32.600
Okay.

56:32.600 --> 56:33.600
All right.

56:33.600 --> 56:34.600
Great.

56:34.600 --> 56:35.600
Well, Ben,

56:35.600 --> 56:36.600
thanks so much for,

56:36.600 --> 56:37.600
uh,

56:37.600 --> 56:39.600
taking the time to be on the podcast.

56:39.600 --> 56:41.600
It was wonderful having you on,

56:41.600 --> 56:42.600
and again,

56:42.600 --> 56:44.600
looking forward to seeing you in a few weeks.

56:44.600 --> 56:45.600
Thank you, sir.

56:45.600 --> 56:46.600
Thanks.

56:46.600 --> 56:47.600
Bye-bye.

56:47.600 --> 56:48.600
Yeah.

56:48.600 --> 56:49.600
Yeah.

56:49.600 --> 56:50.600
Yeah.

56:50.600 --> 56:51.600
Yeah.

56:51.600 --> 56:52.600
Yeah.

56:52.600 --> 56:53.600
Yeah.

56:53.600 --> 56:54.600
Yeah.

56:54.600 --> 56:55.600
Yeah.

56:55.600 --> 56:56.600
Yeah.

56:56.600 --> 56:57.600
Yeah.

56:57.600 --> 56:58.600
Yeah.

56:58.600 --> 56:59.600
Yeah.

56:59.600 --> 57:00.600
Yeah.

57:00.600 --> 57:01.600
Yeah.

57:01.600 --> 57:02.600
Yeah.

57:02.600 --> 57:03.600
Yeah.

57:03.600 --> 57:04.600
Yeah.

57:04.600 --> 57:05.600
All right, everyone.

57:05.600 --> 57:07.600
That's our show for today.

57:07.600 --> 57:08.600
We love, love, love,

57:08.600 --> 57:11.600
caring from listeners about the show.

57:11.600 --> 57:13.600
You can leave your questions and comments

57:13.600 --> 57:14.600
over on the show notes page

57:14.600 --> 57:16.600
at twimmalai.com slash talks,

57:16.600 --> 57:17.600
slash 26,

57:17.600 --> 57:19.600
where you'll find links to Ben

57:19.600 --> 57:22.600
and the various resources we mentioned in the show.

57:22.600 --> 57:23.600
And as always,

57:23.600 --> 57:25.600
our quote contest continues.

57:25.600 --> 57:27.600
Just drop us your favorite quote

57:27.600 --> 57:28.600
on the show notes page

57:28.600 --> 57:31.600
or your social media network of choice

57:31.600 --> 57:33.600
and we'll send you a laptop sticker.

57:33.600 --> 57:34.600
Once again,

57:34.600 --> 57:36.600
thanks so much for listening

57:36.600 --> 57:47.600
and catch you next time.

