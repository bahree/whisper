Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
I'd like to start out by thanking Siemens for sponsoring today's show.
You probably know Siemens as a global leader in the area of industrial electrification,
automation and digitalization, or as a supplier of systems for power generation and transmission,
as well as medical diagnosis.
I recently had an opportunity to attend the company's spotlight on innovation event down
in Orlando, Florida and learn about some of the interesting work happening within the
R&D branch of the company.
I'm happy to be able to share a bit of that with you via today's conversation with Batu,
a computer-visant research manager there.
To find out more about what Siemens is up to in areas like AI, digital twin, cybersecurity,
smart city infrastructure and more, visit twimbleai.com slash Siemens.
Alright everyone, I've got Batu, our soy on the show.
Batu is a research manager for vision technologies and solutions at Siemens Corporate Technology.
Batu, welcome to this week of machine learning and AI.
Sure, it's great to be here.
It's great to have you on the show and I'm looking forward to this conversation.
How do we start with having you share a little bit about your background and how you came
to work in computer vision and machine learning?
Sure.
So, actually I started my education and career in the field of electrical and computer
engineering with the focus on computer vision topics in Turkey.
And after finishing up my Bachelor of Science there, I joined Siemens and started working
on compensation geometric problems such as 3D reconstruction from point class and geometrical
shape matching.
And at that point deep learning was taking off every day and at that point we were mostly
using the traditional machine learning algorithms and that's how my interest started.
At that time we're always using okay, can we extract some hand carved features in order
to represent the geometries, but then we realized that there might be a better way of doing
this and that's how I started this machine learning journey.
So, after I received my PhD in computational geometry at CMU, I joined Siemens corporate
technology and I started integrating artificial intelligence and computational geometry together.
And right now I'm technology manager for vision, technologies and solutions team in Siemens
corporate technology which is actually R&D hub for Siemens and we are providing high quality
research development and consulting services for our business units within the Siemens.
Okay, you mentioned that a big part of your focus is kind of merging, did I interpret
this right kind of merging the traditional computational geometry approaches and deep
learning?
Is that how you're approaching the various problems you're working on?
That's correct, that's one facade of our approach, but basically our team is known
as the computer vision with limited data problem.
Okay, so our team is working on how to solve computer vision problems by leveraging some
simulation methods to generate synthetic data or by developing intelligent AI algorithms
to eliminate the need of large amount of training data set collection.
Because you might be seeing in most of the domains that this is one of the obstacles
to actually deploy AI systems in industry.
We have to collect a large amount of training data sets for a specific custom task for
your interest, but at the same time after collecting this data, you also have to annotate
this data.
So we are working closely with academia and researchers within Siemens to tackle this
problem from multiple angles, how to solve learning or computer vision with limited
data problem.
Is your use of simulation primarily focused on synthetic data or are you using simulation
in other ways as well?
So we use simulation in two different ways.
The first way of we use the simulation is actually to generate synthetic data.
And one great example use case that we had all have developed in the past is about spare
part recognition.
This is a problem if you have a mechanical object that you deployed in the field and
you need to perform maintenance and service operations on this mechanical functional object
over time.
In order to solve this problem, what we are working on is using simulation to synthetically
generate a training data set for object recognition for large amount of entities.
In other words, we synthetically generate images as if these images are collected in real
word from an expert and they are annotated from an expert.
And this actually comes for free using the simulation.
We have developed a system together with our Siemens colleagues where we deployed this
for the maintenance applications of the trains.
And the main goal is a service engineer goes to the field.
He takes his tablet, he takes a picture, then he draws a rectangle box.
And the system automatically identifies what is the object of interest that the service
engineer would like to replace.
And in order to make the system reliable, we have to take into consideration different
lightning conditions, texture, colors, or whatever these parts can look like in a real world
environment.
Okay, so you've got some ground truth data, which is the parts itself, you know, from,
you know, these could be imagining you have them both from a, like, maybe catalog image
as perspective, but for some of them, you probably have down to a CAD description of these
parts.
And you want the service engineer to be able to take a picture of the parts in place,
not having, you know, taking the part out and putting it on a white background or something
like that, but just in place and then draw a bounding box of some sort around it.
And your system should be able to identify what the part in question is.
That's exactly the case.
So we are interested for the built-in case.
So you like to eliminate the need of this assembling and mechanical object in order to identify
the object of interest, because sometimes people might have already engraved some QR codes
on these parts.
However, we are targeting the application scenario where this object will take so much time
to disassemble or the QR code is not visible or due to some customer preferences, we cannot
print any QR code and ID tags on this part.
Our system is designed to be able to work on such scenarios.
I can see how generating synthetic data, particularly your kind of typical data augmentation
types of synthetic data where you're doing shifts and changing the lighting conditions
and things like that would help a model solve this problem.
But you also have, I would imagine the issue of kind of occlusion of your part is a big
challenge to overcome.
Is that dealt with via synthetic data or other methods?
So that's a great question actually.
Yes, so that was actually the first step that we took was data augmentation methods to
be able to actually use some previous catalog images or CAD models to generate synthetic
images.
However, the real challenge is modeling also the sensor structure.
So what are these sensor noise that you are going to get when you are in the field?
Because if you synthetically generate images, you don't consider the noise that comes from
your acquisition device or you don't consider the distortion that comes from your acquisition
device or some other electromagnetic field effect.
And this is where we published a paper in 2016 that's called depth synth and where we
modeled with very high detail how a depth sensor works, such that are simulator generates
very high detailed depth images from the CAD model renderings.
So that's what it makes it really successful.
We are not only generating or augmenting data by creating different scales, different
rotations, but even we take into account the parameters that affects the image acquisition.
And that way we were able to achieve success to deploy such a system in real world applications.
And so does the depth characteristic address the occlusion of your part by other parts
in assembly?
Or how do those two factors tie together?
Sure.
Sure.
Actually, when we synthetically render these images, we render the entire assembly so that
even though we see the objects itself, we synthetically simulate as if there are occlusions
from the neighboring parts.
So our synthetic database does not only consist of clean images.
We also take into account all these cases where you synthetically simulate this corner
cases as well.
So this is all baked into the simulation platform that we have.
I'm curious with depth synth paper, what the general approach was.
How did you incorporate the characteristics of the sensor into the training of the models
to get better results?
Sure.
For example, in our paper, we talk about the representation of the depth synth pipeline
which consists of the projector modeling, camera modeling, object modeling, and reconstruction
and post-processing models.
And each of these models takes as input a cat model and synthetically generates a rendering
of a depth image corresponding to this cat model.
And during the projector modeling, for example, we simulate the patterns motion between exposures,
vector and lens effects.
In the camera modeling, we take into account distortion, motion blur and other noises that
are coming from the environment.
In the object modeling, we take into account motion control, illumination, material properties
and also even the surface microgeometer modeling properties.
And at the end of the day, we even apply how this geometry or how this image will look
like if our device is applying some post-processing steps like the smoothing or hole filling.
And that's how we actually get depth images that looks really realistic.
And in our paper, we show the comparison our simulation results with the real data acquisition.
And we even simulate what if somebody is using a hand-held device and he walks within
the building, we take into account the vibration that comes from walking within the environment
or the motion between the exposures as well.
And that's make it really strong.
And so are the modules that you described, are these modules steps in a pipeline, or are
they more like layers in a deep learning model?
So for this one, this is not based on the deep learning model.
But right now, this is still into a pipeline.
But during that time, we actually modeled this mathematically, these behaviors.
Cool.
We dove right into a pretty detailed use case.
But maybe before we talk about more use cases, I can have you take a step back and talk
a little bit more broadly about what your group at Siemens does.
Sure.
Sure.
In our group, actually, every day, we have three different type of interactions or activities.
And in our group, as I mentioned before, we are targeting the computer vision with limited
data problem.
However, what are the different venues where we actually execute this work?
And this can be grouped in under the three different project categories or activities.
Our first activity involves day-to-day interaction with our business units, Siemens business units
to understand their needs and try to identify which computer vision research topics can make
the largest business impact for them.
After identifying such opportunities, we formulate proof-of-concept projects with them to improve
their competitive advantage.
But this is one type of the interaction that we have within the company for our scientists.
The second type of interaction that also excites many of our scientists here is our interaction
for more fundamental research topics.
We are very active and engaged with subsidies and grants in USA with screen potential
call for proposal issued by U.S. government entities that align with our long-term vision.
And if there is anything relevant for us, we collaborate with multiple universities and
Dinosaur partners to drive wide-papers and full proposals.
And a great example of such activity was, right now, we are one of the performance within
DARPA Physics of AI Project, together with Cornell University.
And we are also part of the DARPA Automatic Scientology Extraction Project program as well.
This actually concludes our second type of activities.
And the third type of activity is more about how can our researchers and scientists work
on the topics that are going to create a business impact in the next two, three years for Siemens?
For these topics, our teams are collaborating with universities and other industrial partners
to innovate and publish research results in top conferences.
For example, the last year our team had three CVPR-1 ECCV publication and presentation.
And this year, we had one CVPR publication and we also organized a computer vision with
by a state of workshop led by our principal scientist Dr. Jan Ernst and with our team member
Dr. Kondron Pank in Long Beach, California last week.
Okay.
What was your CVPR paper this time?
Sure.
This time, it was actually on a very, very interesting topic and what we called learning
without memorizing.
So this project is also an important, incremental learning is an important task aimed at
increasing the capability of a trained model in terms of the number of classes recognizable
by the model.
So what it means is the key problem is the requirement of storing the training data associated
with existing classes while teaching the classifier to learn new classes.
And this is a work jointly done by Rajat Vikram Singh and Kondron Pank.
And what they actually invented is they find that they find that a way of emulating the
relationship between a student and the teacher, how it works in real world.
And they apply that to artificial intelligence.
So the way the system works is there is one teacher model which tries to explain what it
learned so far, but it doesn't want the student to just learn everything by heart.
It wants the student to understand why he makes this decisions.
And that way, if you actually keep able of teaching the neural network, how a neural network
makes decision, then you can actually pass the inherited information from the previous
experiences we do not require access to the previous data sets.
Are there maybe correlations between the student teacher type of an approach and something
like an auto encoder where you're kind of trying to map what the primary model learns
into some lower dimensional space and then kind of build that back out?
Yes, it's similar because actually this work is built upon one of our previous publications
which was trying to do attention modeling and attention modeling is actually trying to
understand where does our neural network pay most of the attention when it makes a decision.
And we are capable of highlighting, oh, okay, these are the set of the pixels that contributes
to the most of the decision.
And this is the paper that we published last year, it's called the Tanme Ver to look.
And in this paper, by leveraging this powerful explanation mechanism, we are able to encapsulate
knowledge that's very unique from the training data set in a lower dimensional representation
step.
And that's how it works actually, that's why it's so relevant to the auto encoder what
we are using another mechanism to actually encapsulate the knowledge coming from the training
data sets.
Okay.
And so how does that mechanism work in the learning without memorizing paper?
Sure.
The way this work works is actually, first of all, what's the real use case?
The real use case is, you might be familiar with all these edge devices where we are capable
of performing real-time computer vision tasks on them.
And if you'd like to improve your model, for example, you'd like to train or teach this
model classification or recognition of the new objects, you don't want to retrain your
system using the previous training data set first, it takes too much time again.
And you might be not have a connectivity or you might not have access to this data.
And there's also memory limitations on your edge device, which prevents you to actually
store the data on your device for further training purposes.
So the main idea is, can we encapsulate the knowledge that was already inherited from
a previous training stage and pass it to the next stage of the training?
And the way the algorithm works is, it tries to memorize, actually we call it learning
without memorization, but it tries to always consistently pay attention to the same regions
of the image pixels to make the decision.
So it doesn't allow its attention mechanism to divert too much by looking at the new observed
data.
So that way by keeping our attention consistent, we are preventing our attention to be heard
or disturbed.
And by preventing that, we are capable of actually maintaining the data as much as possible.
Of course, this is something at research stage and we are working on it further for more
industrial use cases.
Going back to the, tell me where to look paper, what's the key innovation there?
So the key innovation there was, it was a very interesting paper because, I don't know
if you are familiar with the attention modeling frameworks, but what they are trying to do
is, the famous example is you'd like to recognize the ship.
And in your training dataset, you always have the ships that are on the sea.
Then you'd like to see, okay, let me show me the, what are the pixels that my neural network
is paying attention and you realize that all my neural network is paying attention to
the sea because it's actually learning the patterns of the sea instead of the geometrical
features of a ship.
So existing algorithms until our development, the attention models were not extracting
the boundaries of the object of interest, they were more noisy compared to our recent
development, but we did that work was we demonstrated that we can actually mask or hide some
pixels of the objects or some pixels of the image.
And then we sent back this information, this mask or altered image back to the class
fire until it's not capable of recognizing it any of the correct classes.
That way in an iterative fashion, we remember more pixels from the images until our class
fire starts failing to making the right decision.
And at that moment said, okay, we are successfully recovered all the set of pixels, which impacts
the decision of making, this is a cat, this is a ship, or etc.
This is the one branch of our rock.
The second branch of the box, okay, the masking is done as part of the process, it's
not like a labeling type of a step, is that correct?
That's correct.
It was completely trained and where the system optimizes jointly trying to identify where
to pay attention pixels.
And at the same time, I removed some pixels to see if it needs to grow these pixels over
time.
And this way, it actually corrects and improves its attention mechanism, and we realized
that we were able to get much more accurate boundaries of the attention.
And they were much more clustered together, such that they are more compact representation
of the knowledge.
And it also provides explainability to aspect.
And I think at least some folks in our audience will be familiar with the line paper, which
is Carlos Gastron and his folks from the University of Washington.
And they do something similar where they kind of perturb aspects of the inputs to determine
which are the pixels that are most relevant to the classifier decision.
And you relate this work to that?
Sure.
From a higher level, we are trying to solve a similar problem.
But I don't know the exact details of that paper, so that's why I won't be comfortable
to directly compare them to here.
Cool.
And then you mentioned a computer vision with bias data workshop that you did at CVPR this
year.
Can you talk a little bit about that?
Yes.
And actually, this was the second series of this workshop organized by our principal scientist
Jan Ernst.
And actually, the main objective of this workshop was bringing together people from industry
academia.
And also, students as well to identify what are the big problems right now in the computer
vision with limited and biased data.
And one famous example is like, if you have a training database, you always have a class
imbalance problem.
You always have so many data points of the nice results.
But you don't have enough number of samples of the negative samples or the problematic cases
or out of distribution cases or the unique rare cases.
So we had the list of speakers.
You can also find it online, the list of speakers from the website, CVPR 2019 workshop website.
And we discussed together what are the some common problems that the academia and industry
is facing right now.
And what are the some approaches that academia and industry tried so far to tackle this problem?
That was the main objective of the workshop.
Now these kind of class imbalance problems that you've described.
They come up all over the place, but they are particularly present in what I imagine are
pretty common use cases for you at Siemens, like industrial inspection where you're trying
to identify damaged parts or, you know, damaged products coming off of an inspection line
or maybe looking for damage on wind turbine rotors, things like that, like you've got
so many pictures of the, you know, the good parts and very few pictures of the different
types of damaged parts.
What are some of the key ways that you're able to deal with this?
Sure, actually, some people call this problem out of distribution learning.
Some people call it novel to detection or animal detection as well.
And yes, you're right, because it's always easy to say, okay, this is something normal
looking versus this is something defective, but there might be a hundred different ways
this defect might look like, right?
So and if you'd like to try to annotate all this together, it might take too much time
and you might not even able to recover entire problem space.
So for this one, we are working some animal detection algorithms in order to learn representations
similar approaches, what you mentioned previously using auto encoders, such that you learn
visual trends and then being able to identify, okay, if this is how the normal scene looks
like, how can we identify this sample does not fit to this distribution and the data that
we learned from and that's labeled as the normal.
And this is a very, very powerful technology if you can scale it different use cases as
well.
So what are some of the most interesting, you know,
use cases or case studies that you've had a chance to work on at Siemens, you know,
what's most exciting of the various applications of computer vision there?
Sure.
And actually, this is a very hot area and the computer vision and we always try to do research
that's grounded to the industrial needs and business needs.
And we usually take approaches together with government as well and we are one of the
performance in one of the programs by Office of Naval Research and this is called the
Activity Recognition Project where we are trying to develop a system, the user will interact
with an AI system where the user will tell, okay, I'm looking for an object and the user
will be able to define this object, okay, it's going to have red short, it's going to
have blonde hair or it's going to say short, tall, these attributes or I'm looking for
a white car or etc.
Then the system automatically filters our or distals, millions of video images or millions
of the videos in order to identify and locate your object of interest that you defined.
But the nice thing, an interesting thing is this is a problem that's actually two way
where we believe and this is very exciting, we call this human in the loop idea.
So what we believe is you or the user can provide all this information to the system but
we don't want AI system to just return, okay, these are the results.
We want AI system to come back and counter back saying that did you mean by this and such
that they are going to have a conversation between the user and the AI system until they
actually filter out and locate the object of interest because sometimes we also observe
that people are not good at it by describing what they are looking for and the system might
be able to correct it saying that did you mean by that test and we are trying to actually
map human input to the visual search queries and having a conversation between these two
agents.
Yeah, I'm envisioning a lot of moving parts here between the natural language elements
of it and the visual querying and choosing the right examples to maximize information
transfer between the humans and the computer.
What are the different elements of solving a problem like that?
Sure, and actually that's what makes CMAS really unique because CMAS corporate technology
is a research R&D hub for CMAS and we are actually investing in research and development
in the domain of artificial intelligence and there are multiple teams contributing all
over the world with diverse backgrounds and as you have seen here, this problem requires
a natural language processing background.
This requires computer vision background.
This problem requires also the person identification or this kind of application backgrounds.
So that's why the main team consists of multiple subgroups and one of the team is focusing
on identifying attributes from multi-camera streams so that actually you need to still train
these systems on some training datasets such that you can learn what does mean really
having a red car, what does mean really having a blue car.
So the first part of the computer vision element is being able to identify the objects
and then being able to identify the features of these objects.
Other words, after you identify this and you are capable of actually now processing the
human input where the user says I'm looking for, after you see that sentence, you look
for the verbs and the nouns and our natural language processing experts are working on
how to relate the user queries to the mathematical queries in order to actually find the objects
of interest that are found by this computer vision modules.
Other words, of course, there is another team which is the user interaction team which
is focusing on, okay, what is the information exchange efficiency?
So are we actually going to be able to find a solution if you go down to this route or
should the system come back and ask the user, did you mean by this or such that it actually
improve the quality of the search results?
And along the lines of government projects, you mentioned earlier DARPA Physics of AI
project and I wanted to ask you a little bit about that.
What's that project about?
So DARPA Physics of AI is a program where multiple university partners are contributing
and we have our team member, Dr. Tichun Chang is the PI for that project and this project
is actually trying to incorporate physics into the artificial intelligence systems in order
to eliminate the deed of large training datasets.
And as I explained at the beginning of my discussion, so this is really what excites us learning
with limited data and whenever there is such a program, we try our best to be part of
it and here we are working with the Cornell University and actually this project is trying
to reconstruct 3D images from a sub sampled resolution sensor data where they know some
physics constraints but they don't know they don't have the full visibility to the data
for reconstruction and they are focusing on how to incorporate the physics in order to
be able to reconstruct 3D by knowing the relationship within the elements in this data
and etc.
Okay, I find this general direction of research to be really interesting in that we were
kind of coming from a history of building systems based on very robust models of the physical
world and then we, the pendulum kind of swung to let's throw away all the physics and
just use statistical models, you know, from, you know, just building up from data.
And I find that there's a lot of interesting work happening in the middle now kind of
the pendulum is kind of swung into the middle where we're trying to integrate these two
and attach the physical knowledge of the world or the way whatever system that we're modeling
works with the statistical information or statistical modeling techniques.
There are a bunch of really interesting applications there.
Yes, and actually one everyday example that I use is like, you don't need to observe
1000 times a car is driving on the road in order to understand a regular car does not
fly.
So if you can integrate some, if you can integrate some knowledge about, okay, there's
gravity, there are roads and etc.
You won't need that much data, that's something that excites us and we definitely interested
in this time of topics.
You know, I was at the Siemens spotlight on innovation event not too long ago and one
of the use cases that our application areas that I saw Siemens talking quite a bit about
was smart cities and a lot of kind of a broad much broader array of applications and I usually
see when smart cities comes up.
Is that an area that your group works in?
Not at the moment, but we believe the technology that we develop can be applied there as well.
You also mentioned a project automating scientific knowledge extraction.
What's that one about?
Sure, that's a project that we are collaborating with our sister group here in Siemens CT and
actually, that's the PR is the Dr Janis and actually what we are trying to in that project
is another DARPA effort and the objective is if you have list of papers, how can you
make sure that the knowledge that extracted from this papers corresponds to the code that
you actually get delivered at the end of the day or how can you make sure that you can
automatically understand what is actually explained in this paper by looking at the images,
the text and making its relationship to the software.
And our team is contributing to the recognition of and the composition of the neural network
images on these papers.
And these papers are mostly scientific papers where you have the multiple layers and actually
we are working on developing a system that's capable of taking as input such a scientific
paper and then process the images on these papers and tell you okay, this paper is leveraging
and neural network architecture X with this many layers and they are using this dropout
and this pooling layer and etc.
So we are working on that component to be able to automatically screen such scientific
knowledge papers and try to summarize the content and knowledge in them.
My sense is that a lot of people who are listening to this podcast will probably be really
interested in a system like that, particularly with all of the papers that come up in our
space and that are published to archive, it's super difficult to keep up with even a subset
of those papers.
Yes, that's true, but of course now we are at the resource stage of this algorithm.
In the future we are going to see hopefully more and more examples of such work because
right now if I remember correctly in CVPR there were 9,300 attendees and over 1000 different
papers and right now if you spend three or four days it really takes too much time to
even figure out what are the papers that you like to attend and visit.
So such a solution would be even good if it can actually screen what are the titles and
then does really fit my interest and then I can go there.
It is kind of towards the basic research side of the spectrum, you know at least relative
to what some other corporate research arms are doing.
What is the, how do you ensure that this stuff is tied into and aligned with the actual
stuff that Siemens is doing and for that matter how important you've mentioned that that's
important to you but you know how do you strike a balance between contributing in these broader
efforts and collaborations and doing things that ultimately has an impact on the kind of
stuff that Siemens cares about.
Sure, and actually with government and also other research projects we are more tackling
the lower tier out projects which means the lower technology readiness levels where we
develop some proof of concept and we publish some papers.
Of course we secure the IP and that's the one of the important metrics for us.
How many new ideas or IPs can be actually contributed to our Siemens business units to increase
their competitive advantages.
From a grounding perspective any topic that we invest we always first think about does
it really relate to the problem that we have in-house or does it really have some potential
to be converted into a product in the future and that's always our grounding mechanism.
Our team is working all these papers that we publish even though they sound on their
cool research projects they all get into the real world as one component of a product
that you experience in the world.
And actually the spare part recognition algorithm that I discussed at the beginning of our
interview that's actually called is spare idea.
If you go online and Google it you can see that's actually a product that our business
units right now actually leveraging and providing the service.
So that's how the technology transition happens first.
We actually perform the research internally and in collaboration with the academicians.
And then our job is transferring this research to relevant products but we always keep
in mind that whatever we do needs to provide some impact hopefully in the next two years
for Siemens overall.
When you're taking an idea like this at the you know later stages of this process like
the Easy Spares are there unique challenges that you run into kind of in those final steps
of commercialization always.
And that's why we always have support from other experts from our business units who
are really know how to productize something.
And we definitely experienced some challenges like one of the challenges is with the neural
networks, the memory or the processing times.
So we experienced such challenges during the end of the proof of concept phase before
demonstrating that to our business units.
Well I want to thank you so much for taking the time to share a bit of what you're up
to.
Sounds like a lot of really interesting stuff and I'm imagining some folks will be interested
in digging into some of the recent CVPR papers that you'll be sharing with us.
Yes, thank you very much for your time as well.
And I would like to also point out that in case if there are any other additional questions
your audience is free to reach me out and I think you can also post my email your website
so that I would be happy to connect with them afterwards.
We'll include it in the show notes.
Thanks about to.
Thank you.
Alright everyone that's our show for today.
For more information on today's guests visit twomolai.com slash shows.
Thanks again to Siemens for sponsoring today's episode.
Be sure to check them out at twomolai.com slash Siemens.
As always thanks so much for listening and catch you next time.
