WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:31.520
I'm your host Sam Charrington.

00:31.520 --> 00:36.400
I'd like to start out by thanking everyone who joined me last week at the Twimble AI Summit

00:36.400 --> 00:37.960
in Las Vegas.

00:37.960 --> 00:39.960
It was a great event.

00:39.960 --> 00:44.920
For a summary of the event and my key takeaways from each of the event sessions, sign up for

00:44.920 --> 00:49.840
my newsletter at twimbleai.com slash newsletter.

00:49.840 --> 00:54.160
I wrote about it right after returning from the event last week and when you sign up,

00:54.160 --> 00:58.720
you'll automatically get an email telling you how to get access to back issues.

00:58.720 --> 01:04.480
Again, that's twimbleai.com slash newsletter.

01:04.480 --> 01:06.480
Event season continues this week.

01:06.480 --> 01:11.320
Tomorrow I'm key noting at the Prepare AI event here in St. Louis and then making my way

01:11.320 --> 01:15.840
out to San Francisco for Figure H's Train AI Conference.

01:15.840 --> 01:21.320
The Train AI agenda looks awesome and I'll be on site all day podcasting so if you're

01:21.320 --> 01:25.400
in the Bay area, you should definitely plan to stop by.

01:25.400 --> 01:31.680
Of course, if you do, use the discount code Twimbleai for 30% off of registration.

01:31.680 --> 01:35.040
Be sure to give me a shout if you're planning to be around.

01:35.040 --> 01:41.720
In this episode, I'm joined by John Bohannon, Director of Science at AI Startup Primer.

01:41.720 --> 01:46.000
As you all may know, a few weeks ago, we released my interview with Google Legend, Jeff

01:46.000 --> 01:51.080
Dean, which by the way, you should definitely check out if you haven't already.

01:51.080 --> 01:56.040
Anyway, in that interview, Jeff mentions the recent explosion of machine learning papers

01:56.040 --> 02:00.760
on archive, which I responded to jokingly by asking whether Google had already developed

02:00.760 --> 02:04.680
the AI system to help them summarize and track all of them.

02:04.680 --> 02:08.720
While Jeff didn't have anything specific to offer, a listener reached out and let me

02:08.720 --> 02:12.920
know that John was in fact already working on this problem.

02:12.920 --> 02:18.120
In our conversation, John and I discuss his work on Primer Science, a tool that harvests

02:18.120 --> 02:24.000
content uploaded to archive, sorts it into natural topics using unsupervised learning,

02:24.000 --> 02:28.640
then gives relevant summaries of the activity happening in different innovation areas.

02:28.640 --> 02:32.520
We spend a good amount of time on the inner workings of Primer Science, including their

02:32.520 --> 02:36.920
data pipeline and some of the tools they use, how they determine ground truth for training

02:36.920 --> 02:41.720
their models, and the use of heuristics to supplement NLP in their processing.

02:41.720 --> 02:43.920
Alright, let's do it.

02:43.920 --> 02:52.200
Alright, everyone, I am on the line with John Bohannon.

02:52.200 --> 02:56.360
John is Director of Science at a startup called Primer.

02:56.360 --> 02:59.200
John, welcome to this week in machine learning and AI.

02:59.200 --> 03:00.200
Hey!

03:00.200 --> 03:01.840
So this conversation is an interesting one.

03:01.840 --> 03:08.440
They grew out of a listener response to a comment made in my recent interview with Jeff Dean.

03:08.440 --> 03:13.680
Jeff commented on the explosion of machine learning papers on archive, and I jokingly

03:13.680 --> 03:18.320
asked if Google had already developed the deep learning based summarization techniques

03:18.320 --> 03:20.080
to help us all keep up.

03:20.080 --> 03:24.080
And it turns out that one of your colleagues, John, reached out to let me know that you

03:24.080 --> 03:27.120
have been working on this and have built it.

03:27.120 --> 03:30.560
And I think just before we got started, you showed it to me and it's pretty cool.

03:30.560 --> 03:37.080
So here we are, but before we get into the details of that project, you've got an interesting

03:37.080 --> 03:40.840
background in molecular biology and data journalism.

03:40.840 --> 03:45.320
How did you find your way to AI?

03:45.320 --> 03:53.280
It's a long journey, but I think it started in computer camp when I was nine years old.

03:53.280 --> 03:56.040
So that's the kind of summer camp I went to.

03:56.040 --> 04:04.520
And yeah, as my studies progressed, I actually drifted away into biology in a PhD in molecular

04:04.520 --> 04:11.720
biology, and then before doing my next postdoc, I wanted to take a break and do something

04:11.720 --> 04:12.720
different.

04:12.720 --> 04:18.760
So I tried being a journalist, a science journalist, and fell in love with it and basically jumped

04:18.760 --> 04:24.040
off the academic track and became eventually a computational journalist, basically using

04:24.040 --> 04:31.120
data and code to find and tell stories that are impossible to tell otherwise.

04:31.120 --> 04:37.280
And a friend of mine named Sean Gorley, who did his PhD with me in England at the same

04:37.280 --> 04:44.640
time, I actually lived in the same house, our fate eventually became intertwined again.

04:44.640 --> 04:51.280
I moved to the Bay area to do a visiting scholar stint at Berkeley, and he's in San Francisco.

04:51.280 --> 04:54.920
He says, hey, John, I've got this startup called Primer.

04:54.920 --> 04:58.000
And you really should come by and check out what we're doing.

04:58.000 --> 05:04.120
I think you're going to find that the stuff we're working on really, really matches with

05:04.120 --> 05:06.040
the stuff you work on.

05:06.040 --> 05:11.040
And so eventually I had some time and I was like, okay, I'll pop over there for a week.

05:11.040 --> 05:18.960
And sure enough, within one day, it was clear that they were solving problems that I just

05:18.960 --> 05:25.080
find so hard and I wanted so badly to solve myself, that basically if you can't beat

05:25.080 --> 05:26.680
them, join them.

05:26.680 --> 05:29.280
Nice, nice.

05:29.280 --> 05:36.560
So maybe for context, you can tell us a little bit about what the company does and the

05:36.560 --> 05:40.080
kinds of problems that they're working on or you're working on.

05:40.080 --> 05:41.080
Yeah.

05:41.080 --> 05:48.200
So Primer at its core is an AI company that's trying to make machines that read and write.

05:48.200 --> 05:51.520
That's the fundamental problem that underlies all this.

05:51.520 --> 05:58.800
In terms of a business model, we, for example, automate a lot of the work that a junior analyst

05:58.800 --> 06:03.520
would do in, say, a bank or the intelligence community.

06:03.520 --> 06:06.280
Also frankly, what a journalist does.

06:06.280 --> 06:11.560
I feel like I'm reverse engineering myself every day because a lot of what you have to

06:11.560 --> 06:12.560
do.

06:12.560 --> 06:19.560
It's also somewhat automating a lot of what you do, Sam, like all of our jobs, what we

06:19.560 --> 06:24.360
have in common is that we have to read a ton of stuff, often very technical stuff, and

06:24.360 --> 06:25.760
makes sense of it.

06:25.760 --> 06:30.720
And then tell stories, like that is the fundamental unit of information.

06:30.720 --> 06:33.800
That's our data structure, a story.

06:33.800 --> 06:38.040
And that is really hard for computers to do.

06:38.040 --> 06:40.600
It's really hard for people to do.

06:40.600 --> 06:41.600
Exactly.

06:41.600 --> 06:45.080
Yeah, it's one of those things that's both, that's hard for everyone.

06:45.080 --> 06:53.400
So I think you're relatively new to this podcast, but those that have been around for a while

06:53.400 --> 06:59.440
from the beginning know that it started out as more of a news-oriented format as opposed

06:59.440 --> 07:01.920
to an interview format.

07:01.920 --> 07:08.160
And basically, my mission was to kind of summarize the most interesting AI and ML tidbits from

07:08.160 --> 07:09.880
the previous week's news.

07:09.880 --> 07:15.480
But that is super, super hard, especially with so much news happening all the time.

07:15.480 --> 07:25.640
It would take a ton of time to curate all of that information and digest it and turn it

07:25.640 --> 07:28.360
into stories as you're saying.

07:28.360 --> 07:29.360
Exactly.

07:29.360 --> 07:33.000
And so, like you face several problems, and what we're trying to do at Primer is break

07:33.000 --> 07:36.720
it down into reasonable problems that you can actually attack.

07:36.720 --> 07:40.880
So one is, for example, what's relevant?

07:40.880 --> 07:43.000
What are you telling a story about?

07:43.000 --> 07:47.240
It's not enough to just say, I want to tell a story about last week's AI research.

07:47.240 --> 07:50.680
It's like, okay, well, what documents are relevant?

07:50.680 --> 07:54.320
Even if you could get the papers, then it's like, well, where do you get all the conversations

07:54.320 --> 07:55.640
about those papers?

07:55.640 --> 07:58.040
How do you figure out what those papers were about?

07:58.040 --> 08:01.720
If there were a thousand papers published over the past several months and you wanted to

08:01.720 --> 08:06.400
tell a story of a thousand papers, I don't know how a human would do that.

08:06.400 --> 08:08.800
Well, actually, I can tell you, humans simply don't do that.

08:08.800 --> 08:11.600
What we do is we take shortcuts.

08:11.600 --> 08:12.960
We sort of fly blind.

08:12.960 --> 08:19.320
We grab the zeitgeist, and that's kind of a random process.

08:19.320 --> 08:25.040
It's like, well, I overheard some conversations, and this seems to be a hot topic, I'm going

08:25.040 --> 08:27.400
to decide, and so I'm going to amplify it.

08:27.400 --> 08:33.800
And what you end up with are coherent stories, but they're not necessarily what actually was

08:33.800 --> 08:35.840
the most important thing that happened.

08:35.840 --> 08:40.920
It's just some strange sampling of the space of all things that happened, and that's the

08:40.920 --> 08:41.920
best you can do.

08:41.920 --> 08:47.360
But what if you had a machine that could actually read everything and show you, in some sense,

08:47.360 --> 08:48.760
everything that happened?

08:48.760 --> 08:49.760
That's the goal.

08:49.760 --> 08:56.200
So you showed me a kind of a portal into research papers, is the idea to provide that

08:56.200 --> 09:01.760
as a service or more of the platform that allows someone to create that thing.

09:01.760 --> 09:08.080
So we're in a pretty privileged position, we're privileged in the sense that we've already

09:08.080 --> 09:09.920
got some really big customers.

09:09.920 --> 09:18.720
So the federal government, Walmart, Singapore's sovereign trust, with several others coming

09:18.720 --> 09:24.520
online soon, those are the relationships that actually pay the bills.

09:24.520 --> 09:29.400
And so we do things like if you have a portfolio manager who's trying to keep track of a ton

09:29.400 --> 09:37.000
of companies, that portfolio manager needs to stay on top of all the relevant developments

09:37.000 --> 09:40.760
in the space roughly defined by all those companies.

09:40.760 --> 09:48.560
All the news about them, maybe SEC filings, if you want to assess changes in risk profile,

09:48.560 --> 09:50.960
it's sort of an overwhelming task.

09:50.960 --> 09:57.720
And so primer basically superpowers those analysts by automating all the things that are really

09:57.720 --> 10:03.480
hard and tedious and time consuming, and it basically reduces the cost of curiosity.

10:03.480 --> 10:08.920
It allows those analysts to not spend half their day reading a million things just to find

10:08.920 --> 10:17.760
out what was worth reading, instead they can see summaries of 100 papers at once, get

10:17.760 --> 10:22.880
a sense of whether it's worth diving deeper or look at another batch of 100 papers.

10:22.880 --> 10:32.320
It also gives alerts with predefined conditions so that you don't lose a second if something

10:32.320 --> 10:37.440
that you know in retrospect is going to be a situation worth knowing about, you'll get

10:37.440 --> 10:38.760
a heads up.

10:38.760 --> 10:44.000
So meanwhile though, you can use the same machinery that does reading and writing and

10:44.000 --> 10:49.360
summarization to do things like the thing I sent you, like read all of archive.

10:49.360 --> 10:56.040
So we do have a business model for this system going forward, we're going to be developing

10:56.040 --> 11:00.920
it into products for, for example, the pharmaceutical industry.

11:00.920 --> 11:07.040
But for the time being, we just have this beautiful laboratory where we get to really push the

11:07.040 --> 11:09.960
edge of natural language processing.

11:09.960 --> 11:14.840
Tell us more about this archive project that you've built.

11:14.840 --> 11:20.440
Yeah, archive is a really good illustration of this problem that we all face of too much

11:20.440 --> 11:21.760
information.

11:21.760 --> 11:28.520
If you ever go to the archive website, you basically see a fire hose of research coming in.

11:28.520 --> 11:37.120
Archive is amazing because it is literally the place where research gets debuted.

11:37.120 --> 11:44.800
It's the first place you'll see a paper coming out from Google or Microsoft or MIT on

11:44.800 --> 11:52.600
topics that are basically going to define machine learning progress over the next 10 years.

11:52.600 --> 11:59.440
In retrospect, you can look back and you can see the timeline of this amazing scientific

11:59.440 --> 12:01.960
revolution unfolding.

12:01.960 --> 12:04.400
But it's not at all human readable.

12:04.400 --> 12:11.040
Even if you are an expert, even if you have a PhD in machine learning, you just can't

12:11.040 --> 12:13.000
make sense of all of archive.

12:13.000 --> 12:18.480
You might be able to make sense of the papers in your own subdomain, but even there, it's

12:18.480 --> 12:19.480
tough.

12:19.480 --> 12:20.480
You've got to find them.

12:20.480 --> 12:23.480
Archive isn't designed for humans in a way.

12:23.480 --> 12:29.720
I mean, it is, but it's just not user friendly.

12:29.720 --> 12:34.120
Primer science is a stab at making sense of that.

12:34.120 --> 12:40.880
Basically, it's a really hard problem that's well-scoped.

12:40.880 --> 12:48.720
But what it does is it harvests all these papers and it does unsupervised learning on the

12:48.720 --> 12:53.400
content of the papers to try and figure out what are the topics that this naturally falls

12:53.400 --> 12:54.400
into.

12:54.400 --> 12:59.160
Within machine learning, for example, I'm just looking now at some of the latest.

12:59.160 --> 13:04.800
The system has discovered that there are not only image reconstruction papers.

13:04.800 --> 13:09.920
There's like 58 papers actually in this bag that are on that theme, but it has discovered

13:09.920 --> 13:15.880
that there's a whole bunch of research on traffic and temporal analysis.

13:15.880 --> 13:18.080
There's something on mathematical optimization.

13:18.080 --> 13:23.720
There's a whole bunch of papers about semantic segmentation.

13:23.720 --> 13:28.640
All of this is happening without an ontology or a knowledge base.

13:28.640 --> 13:35.600
You're going to have to have such a system if you want it to work on any corpus of papers.

13:35.600 --> 13:41.840
You could imagine building some super ontology that captures everything there is to know

13:41.840 --> 13:47.200
about science, but then it's going to be out of date next month.

13:47.200 --> 13:51.320
I wouldn't want to build that thing because maintaining it would be a nightmare.

13:51.320 --> 13:55.320
Instead, you need a system that does more or less what humans do on a smaller scale.

13:55.320 --> 13:59.840
What we do is we look at things and we just sort of eyeball it and say, these are kind

13:59.840 --> 14:07.200
of about this and these are about that, so you get a natural segmentation of the space.

14:07.200 --> 14:13.120
Within each of these topics, it does a time series analysis and it tries to figure out,

14:13.120 --> 14:19.720
if I take all the news and the social media signal, all the tweets about this research

14:19.720 --> 14:27.880
as it was published and afterwards, all the commentary, all the real-time online critique,

14:27.880 --> 14:35.440
sort of the peer review that's happening in real time out in the open, can I detect events?

14:35.440 --> 14:39.360
And so an event can be more than just the publication of a paper.

14:39.360 --> 14:47.560
It could be that, for example, a self-driving car crashes somewhere and suddenly the world

14:47.560 --> 14:55.840
is looking intensely at an issue related to what we do and don't know about these systems.

14:55.840 --> 14:58.960
And some of this research may get pulled into that.

14:58.960 --> 15:04.920
If you want to detect that real-world event, you need a system that can actually divide

15:04.920 --> 15:09.800
all those documents, all those tweets, all those things that are relevant to the same thing

15:09.800 --> 15:12.800
and figure out how to segment them in time.

15:12.800 --> 15:14.080
And so it does that too.

15:14.080 --> 15:17.280
It tries to figure out, essentially, what were the big events in this space?

15:17.280 --> 15:24.680
How was human attention in the world divided in relation to this corpus of papers?

15:24.680 --> 15:30.760
And then it does some other cute tricks to make it useful to you as you dive into all

15:30.760 --> 15:32.480
of this information.

15:32.480 --> 15:36.760
It pulls out all the people and tries to tell you what it knows about them, just based

15:36.760 --> 15:38.880
on the corpus, mind you.

15:38.880 --> 15:42.560
We're also developing a version of this that is building a knowledge base and actually

15:42.560 --> 15:47.040
learning about people as it reads the news and as papers are published.

15:47.040 --> 15:55.400
And what I sent you this morning is just, essentially, out of the box, I don't know anything about

15:55.400 --> 15:59.360
the world, but I know this group of thousands of papers you sent me.

15:59.360 --> 16:01.680
And this is what I can tell you about them.

16:01.680 --> 16:03.840
These are all the people.

16:03.840 --> 16:05.600
These are all the topics.

16:05.600 --> 16:10.360
These are the events that seem to all of this information seems to be pointing at out

16:10.360 --> 16:12.280
in the real world.

16:12.280 --> 16:18.360
And another cute one is, if you're finding the jargon really hard to understand, I've

16:18.360 --> 16:23.560
generated a dictionary for you that is kind of a magical dictionary where if you click

16:23.560 --> 16:30.800
on a technical term, it actually shows you who coined that term, how is it defined?

16:30.800 --> 16:34.960
Give me some context about how to use this kind of like a Oxford English dictionary on

16:34.960 --> 16:35.960
steroids.

16:35.960 --> 16:36.960
Nice.

16:36.960 --> 16:37.960
Nice.

16:37.960 --> 16:42.240
I'm finding this interview more challenging than most because as you're speaking, I've

16:42.240 --> 16:49.920
got the tool in the background and I keep seeing papers that look really interesting.

16:49.920 --> 16:51.560
It's working.

16:51.560 --> 16:53.400
Super, super distracting.

16:53.400 --> 16:59.400
So maybe can you tell us a little bit about the technology that's making it all happen?

16:59.400 --> 17:00.400
Yeah.

17:00.400 --> 17:02.840
You know, what does the stack look like?

17:02.840 --> 17:04.560
What does the pipeline look like?

17:04.560 --> 17:08.560
How are you approaching the unsupervised learning piece?

17:08.560 --> 17:14.080
So it all begins with a gigantic elastic search index.

17:14.080 --> 17:15.080
Okay.

17:15.080 --> 17:21.800
I think if you talk to a lot of the people that you've interviewed, even already about what's

17:21.800 --> 17:27.320
at the bottom of this whole stack, there's often like some massive index of documents.

17:27.320 --> 17:35.480
So we're ingesting the news and blogs and tweets and scientific papers every day.

17:35.480 --> 17:37.400
And that's the starting point of this whole system.

17:37.400 --> 17:40.280
It has this growing corpus.

17:40.280 --> 17:48.280
And so if you query, as we've done today on artificial intelligence, for example, the

17:48.280 --> 17:53.280
first thing it has to do is retrieve all the information that is relevant.

17:53.280 --> 18:02.480
And then kicks off this pipeline where basically the first thing it does is it tries with unsupervised

18:02.480 --> 18:09.640
learning plus several other steps to divide all the information up into natural topics.

18:09.640 --> 18:18.200
So within each topic, it then tries to detect the events in the real world that any of these

18:18.200 --> 18:20.640
documents might be referring to.

18:20.640 --> 18:26.880
So if you've got like 100 documents that might be news documents and scientific papers

18:26.880 --> 18:32.400
and social media signal about all the above, you do a time series analysis.

18:32.400 --> 18:37.920
And you try and figure out, are there real world events?

18:37.920 --> 18:39.320
It's trying to make an inference here.

18:39.320 --> 18:46.120
Are there real world events that all of this information is pointing at and describing?

18:46.120 --> 18:52.080
It looks at events basically from the perspective of news articles, is that right?

18:52.080 --> 19:00.840
The system you're looking at does, yeah, but you can imagine any document that has a meaningful

19:00.840 --> 19:07.680
publication timestamp and includes a description or commentary about something that happened

19:07.680 --> 19:09.040
in the real world.

19:09.040 --> 19:12.920
It could in principle be mapped to something called an event.

19:12.920 --> 19:19.520
The concept of an event is bigger than what a human intuitively would call event.

19:19.520 --> 19:25.840
It might actually be, for example, an explosion of discussion around an issue.

19:25.840 --> 19:31.760
For example, the Me Too movement is not just an event, right? It's made up of many events.

19:31.760 --> 19:35.320
And some of these events might not even be something that could have been observed in

19:35.320 --> 19:41.160
one place at one time, but there is a natural segmentation of all the things happening

19:41.160 --> 19:44.560
in the world into something that we call events.

19:44.560 --> 19:47.960
So that's the theory behind this.

19:47.960 --> 19:58.240
Then if you click over to overview, sorry to distract you again, then it tries to tell

19:58.240 --> 19:59.240
you a story.

19:59.240 --> 20:01.880
So we've got many versions of this.

20:01.880 --> 20:07.840
What you're looking at is basically the one of the earliest versions of this.

20:07.840 --> 20:14.960
But basically, if you asked a machine to go and read thousands of things and you give

20:14.960 --> 20:21.200
it a budget of one page to tell you what it learned, this is starting to get at what

20:21.200 --> 20:23.440
you'd expect to come back.

20:23.440 --> 20:25.120
This is what you get.

20:25.120 --> 20:34.040
It's basically, and it's kind of like a technical report on these are things that I learned.

20:34.040 --> 20:35.040
These are the big events.

20:35.040 --> 20:36.040
These are the big papers.

20:36.040 --> 20:37.040
This is what's getting us attention.

20:37.040 --> 20:44.680
Oh, and then by the way, my topic analysis has revealed that there are some changes

20:44.680 --> 20:51.800
of foot in artificial intelligence, and these are the things that seem to be trending

20:51.800 --> 20:53.520
upwards and are really interesting.

20:53.520 --> 20:59.200
And oh, by the way, I discovered there's this weird paper that seems to fall in this topic,

20:59.200 --> 21:03.520
but it's deeply connected to this other topic, and that's statistically strange.

21:03.520 --> 21:05.640
I need to tell you about it.

21:05.640 --> 21:11.520
And by the way, here's some people who seem to be getting a ton of attention, and here's

21:11.520 --> 21:17.240
another person who has collaborated with them on a high profile paper, and they've never

21:17.240 --> 21:18.640
worked together before.

21:18.640 --> 21:19.640
That's interesting.

21:19.640 --> 21:25.720
So you can see what's going on here is the system has a model of what humans find interesting.

21:25.720 --> 21:29.440
And of course, we humans at Primer built that in.

21:29.440 --> 21:32.000
There's a story logic that I don't realize this.

21:32.000 --> 21:34.120
You don't want a system to tell you everything it learned.

21:34.120 --> 21:36.640
It's just going to be another fire hose.

21:36.640 --> 21:39.000
You've made no progress.

21:39.000 --> 21:42.120
A one-to-one map of the world is not a useful map.

21:42.120 --> 21:47.280
So you need something that will compress the information and try and tell you a story.

21:47.280 --> 21:48.960
So that's what the system does.

21:48.960 --> 21:54.640
I think I interrupted you as you were about to start talking about the pipeline that you're

21:54.640 --> 21:58.040
sending some of this stuff through.

21:58.040 --> 22:04.360
And just going back to the beginning with archives, are you ingesting all of the archive

22:04.360 --> 22:07.920
papers or crawling that site?

22:07.920 --> 22:08.920
Yeah.

22:08.920 --> 22:16.400
So Paul Ginsberg, who founded and still runs archive, is a friend of mine from a good

22:16.400 --> 22:18.600
while back.

22:18.600 --> 22:21.040
And he uses Primer Science as well.

22:21.040 --> 22:25.200
I think actually he's the very first one I made a user account for.

22:25.200 --> 22:26.200
Oh wow.

22:26.200 --> 22:27.200
Yeah.

22:27.200 --> 22:34.080
And so he's really helped out over the past year, making sure that we have direct access.

22:34.080 --> 22:37.760
So we don't have to scrape the site.

22:37.760 --> 22:45.920
We basically just pull down the entire day's new papers on one go.

22:45.920 --> 22:52.440
And we do the same with news, except it arrives more or less in real time.

22:52.440 --> 22:59.880
So we have a real-time stream, more or less, of the news with maybe a 10 minute delay.

22:59.880 --> 23:06.440
And we've got a real-time stream of all the tweets that are relevant to the space.

23:06.440 --> 23:11.000
Yeah, those via commercial APIs of some sort.

23:11.000 --> 23:13.080
We get them directly from Twitter.

23:13.080 --> 23:14.080
Okay.

23:14.080 --> 23:16.360
So yeah, we have a data deal with them.

23:16.360 --> 23:17.360
Okay.

23:17.360 --> 23:18.360
And the news?

23:18.360 --> 23:21.720
The news we actually have several sources of.

23:21.720 --> 23:24.040
One of the most convenient is Lexus Nexus.

23:24.040 --> 23:26.000
They have a service called Morover.

23:26.000 --> 23:29.840
You can actually purchase a fire hose of news.

23:29.840 --> 23:31.480
They do a really good job, actually.

23:31.480 --> 23:32.480
Oh wow.

23:32.480 --> 23:33.480
Okay.

23:33.480 --> 23:39.920
So you pull all that into your Elasticsearch index and maybe talk a little bit about some

23:39.920 --> 23:44.200
of the underlying NLP bits that are enabling all this.

23:44.200 --> 23:45.200
Yeah.

23:45.200 --> 23:50.080
So when you kick off a query, what's happening is you're making a lot of reading happening.

23:50.080 --> 23:57.240
So for example, if you take a look at the topics that have been generated, text and word

23:57.240 --> 24:03.440
embeddings, quantum, and all of those topic labels that is generated, it actually

24:03.440 --> 24:09.080
discovered and chose those from the content of the articles themselves.

24:09.080 --> 24:18.640
So the first step in any NLP task on documents is to tokenize the entire document.

24:18.640 --> 24:21.400
So are you familiar with tokenizing?

24:21.400 --> 24:22.400
Mm-hmm.

24:22.400 --> 24:23.400
Yeah.

24:23.400 --> 24:28.760
So you basically discover all the words and punctuation and you run an analysis that

24:28.760 --> 24:30.040
gets you the parts of speech.

24:30.040 --> 24:35.200
It's kind of like what you did in grade school when you made the sentence diagrams to try

24:35.200 --> 24:40.800
and make sense of all the different parts of what someone says.

24:40.800 --> 24:44.000
And then a whole bunch of things happen in parallel.

24:44.000 --> 24:51.360
Basically, there's some things that are useful if you give it a bag of words so you can

24:51.360 --> 24:55.440
take an entire scientific paper or even a thousand scientific papers.

24:55.440 --> 24:58.080
They turn into bags of words.

24:58.080 --> 25:06.200
And with that kind of analysis, you could, for example, discover the groups of words,

25:06.200 --> 25:13.440
the Ngrams, that basically best describe this space and you can generate a label.

25:13.440 --> 25:20.520
So if you go into any of those topics, it has decided to give that topic a name based

25:20.520 --> 25:25.000
on the language within the documents themselves within the topic.

25:25.000 --> 25:29.880
So I'm still amazed that it works, frankly.

25:29.880 --> 25:33.880
NLP is kind of magical.

25:33.880 --> 25:37.520
When something makes sense to a human, when there's a machine that didn't really understand

25:37.520 --> 25:42.200
it in the same way you did, it's kind of magical.

25:42.200 --> 25:50.560
Are you using kind of off-the-shelf NLP toolkits, NLTK-5000 stuff, or are you rolling your

25:50.560 --> 25:51.560
arms off?

25:51.560 --> 25:54.040
No, we started off that way.

25:54.040 --> 25:59.560
So we've been using this tool Spacey from the very beginning.

25:59.560 --> 26:03.120
It's free, it's open source, and it's really powerful.

26:03.120 --> 26:10.320
And it's really what shocks me is that there are just two people at the heart of this project,

26:10.320 --> 26:14.720
a fellow named Hannibal and a gal named Enis, who live in Berlin.

26:14.720 --> 26:18.200
Not far from where I lived for a few years, and I've gotten to know them a little bit

26:18.200 --> 26:20.000
just recently.

26:20.000 --> 26:24.640
And it does the nuts and bolts NLP that you need.

26:24.640 --> 26:29.440
So it will tokenize, but it'll also discover named entities.

26:29.440 --> 26:34.440
It'll help you find the people and organizations and so forth.

26:34.440 --> 26:35.600
But you need to train it.

26:35.600 --> 26:41.040
That's something that we have discovered is just probably like everyone else.

26:41.040 --> 26:45.240
It'll get you started, but then you need to solve your own problems.

26:45.240 --> 26:46.920
It's only a starting point.

26:46.920 --> 26:55.200
So for example, with the people and all the information that we can extract about them

26:55.200 --> 27:00.160
and tell you a story based on the people in this space.

27:00.160 --> 27:05.200
Spacey is one of the things that we use early in the pipeline, but then there's a ton

27:05.200 --> 27:12.280
of custom code that we had to build to basically get the kind of information that Spacey can't

27:12.280 --> 27:20.840
get to clean up the stuff that Spacey gets wrong to link it with all the other information

27:20.840 --> 27:23.960
we're extracting by other means.

27:23.960 --> 27:29.840
And it's a mixture of machine learning and good old fashioned regular expressions.

27:29.840 --> 27:36.000
What I find so fun about being at an AI startup is the goal here is not to generate research

27:36.000 --> 27:37.000
papers.

27:37.000 --> 27:41.600
The goal is to just solve problems really well by whatever means you can.

27:41.600 --> 27:44.800
So which I think is like the right motivation to have.

27:44.800 --> 27:52.840
If you're just motivated to publish cutting-edge papers, you don't care if it works.

27:52.840 --> 27:58.840
I went to this conference called NIPS, which is essentially where all this cutting-edge

27:58.840 --> 28:03.080
research is being debuted, and something that really struck me is like half the stuff

28:03.080 --> 28:08.120
that people are bragging about doesn't even really practically work.

28:08.120 --> 28:14.720
Or works within such a narrowly constrained way of a problem that will work, but it's

28:14.720 --> 28:16.720
computationally intractable.

28:16.720 --> 28:18.800
That's fine.

28:18.800 --> 28:23.760
That's the whole point is to debut tomorrow's technology, but it's frustrating when you're

28:23.760 --> 28:27.480
trying to build something.

28:27.480 --> 28:33.240
You get excited about some new idea and you chase it down, only to discover, oh, this

28:33.240 --> 28:36.680
actually never could have worked.

28:36.680 --> 28:37.680
I've had that experience.

28:37.680 --> 28:42.440
I've found a paper using primer science, of course.

28:42.440 --> 28:45.800
It's a pretty weird situation to have AI eating itself.

28:45.800 --> 28:50.160
We basically have an AI system that reads AI papers, which we then used to try and improve

28:50.160 --> 28:55.520
the AI that reads papers.

28:55.520 --> 29:01.880
We came across a really exciting paper and fully replicated it, and it just doesn't work.

29:01.880 --> 29:02.880
That's okay.

29:02.880 --> 29:08.000
But how it goes in this space, when you're right at the edge of knowledge, it's not all

29:08.000 --> 29:09.800
going to work.

29:09.800 --> 29:15.440
We have this principle, a primer, of always trying to find the practical solution as quickly

29:15.440 --> 29:16.440
as possible.

29:16.440 --> 29:21.880
Don't get seduced by ideas that are sexy to talk about, but it's not actually solving

29:21.880 --> 29:22.880
your problem.

29:22.880 --> 29:23.880
Yeah.

29:23.880 --> 29:25.880
I should throw in a plug for my newsletter.

29:25.880 --> 29:33.880
I've recently written on this topic of reproducibility in both science and AI, drawing off of a

29:33.880 --> 29:40.360
recent interview I did with Claire Galnick on this same topic.

29:40.360 --> 29:45.720
But I really appreciate you owning up to that broader pipeline.

29:45.720 --> 29:54.640
One of the questions I get a lot when talking with folks about their products or projects

29:54.640 --> 30:02.040
is people want to know like, okay, granted you've applied some great cutting edge machine

30:02.040 --> 30:06.640
learning AI stuff, but what else is there required to make it work?

30:06.640 --> 30:13.880
What are the, how much heuristics are kind of in and around these tools to actually make

30:13.880 --> 30:14.880
it work?

30:14.880 --> 30:23.960
So to hear you note that, yeah, good old regular expressions are used liberally to make

30:23.960 --> 30:25.520
sure that this all works.

30:25.520 --> 30:31.840
I think it's important for, it's important to realize that and, oh, yeah, absolutely.

30:31.840 --> 30:38.720
I guarantee you, you go into some of the biggest, most cutting edge groups at giant tech

30:38.720 --> 30:39.720
companies.

30:39.720 --> 30:43.760
You think that they're doing some kind of pristine AI that you just press a button and

30:43.760 --> 30:46.000
it understands things.

30:46.000 --> 30:50.240
I guarantee you look under the hood and there's just a ton of regular expressions.

30:50.240 --> 30:55.840
Now, that's not to say that machine learning isn't the way forward, like it totally is,

30:55.840 --> 31:02.320
but to make these things work on actual problems, it's still a labor of love.

31:02.320 --> 31:09.520
So you're doing a lot with Spacey, are you also, which I'm assuming is more traditional

31:09.520 --> 31:12.320
NLP technology approach?

31:12.320 --> 31:21.240
Are you also doing things with, like, word-to-vec and deep learning based approaches?

31:21.240 --> 31:23.040
Yeah.

31:23.040 --> 31:29.480
In particular, as we've expanded into other languages beyond English, Spacey is just

31:29.480 --> 31:36.640
not going to cut it when you want to make something that understands Russian and Chinese.

31:36.640 --> 31:45.480
So we've actually had to pretty much make a bunch of tools from scratch, but it relies

31:45.480 --> 31:54.720
on word vectors and word embeddings and where things get complicated is actually where

31:54.720 --> 31:59.040
you try and pull this all together.

31:59.040 --> 32:10.320
If you use deep learning to extract, for example, some pattern in a corpus of 10,000 documents,

32:10.320 --> 32:15.200
the harder thing, once you've extracted, is knowing whether you're right and whether

32:15.200 --> 32:17.160
it's worth saying.

32:17.160 --> 32:25.720
I can find a bunch of patterns in text pretty easily, but the harder thing is assessing

32:25.720 --> 32:31.320
how confident am I that I've found something that I haven't just misextracted.

32:31.320 --> 32:32.880
It's not just a spurious pattern.

32:32.880 --> 32:37.800
And then even harder than that, is it worth telling you, like, how do I square this with

32:37.800 --> 32:41.040
my model of what humans are interested in?

32:41.040 --> 32:42.040
Right.

32:42.040 --> 32:46.880
Where we're headed with this is basically a model of stories, which ultimately is a model

32:46.880 --> 32:48.280
of humans.

32:48.280 --> 32:49.440
Humans are storytellers.

32:49.440 --> 32:51.600
We've evolved to do this thing.

32:51.600 --> 32:53.080
We just take it for granted.

32:53.080 --> 32:58.320
What we're doing right now, this conversation, is incredibly high tech.

32:58.320 --> 33:02.400
You and I, in real time, are gliding through a narrative that this is.

33:02.400 --> 33:04.400
Many years of technology evolution.

33:04.400 --> 33:05.400
It's amazing.

33:05.400 --> 33:06.400
Yeah.

33:06.400 --> 33:07.400
It's amazing.

33:07.400 --> 33:12.800
So I think this is actually the next frontier of AI decoding what story is.

33:12.800 --> 33:13.800
Yeah.

33:13.800 --> 33:15.640
So what does that mean practically?

33:15.640 --> 33:18.560
How are you approaching that?

33:18.560 --> 33:27.200
Yeah, so here's a bite-sized example, if you make something that reads scientific papers

33:27.200 --> 33:34.880
and tries to tell you what you need to know about AI research last week, for example.

33:34.880 --> 33:39.080
It's not enough to just give you a dashboard of, here's the most shared paper.

33:39.080 --> 33:42.160
Here's the paper that got the most news.

33:42.160 --> 33:45.360
Here's the paper that currently has the most citations.

33:45.360 --> 33:49.040
That's not doing much heavy lifting for you.

33:49.040 --> 33:54.760
If you were to hire a thousand human analysts to just work for you, like imagine you had

33:54.760 --> 33:59.520
that luxury, what would you ask them to do?

33:59.520 --> 34:06.360
That's kind of the better guiding question and what sort of story would they tell you?

34:06.360 --> 34:07.360
What would the format be?

34:07.360 --> 34:10.800
I guarantee the humans wouldn't come back and give you a dashboard.

34:10.800 --> 34:19.640
They would say, okay, the big deal last week is that a self-driving car crashed and it's

34:19.640 --> 34:26.160
kicked off a huge discussion about quality control and where system errors are going to

34:26.160 --> 34:32.080
creep in and how you can make machine learning systems understandable from an engineering

34:32.080 --> 34:33.080
point of view.

34:33.080 --> 34:36.120
How are we going to deal with this emerging problem?

34:36.120 --> 34:40.720
The people who are weighing in on this are the following researchers in deep learning,

34:40.720 --> 34:45.720
but here's some other people who are very knowledgeable, but they're in a adjacent domain.

34:45.720 --> 34:49.720
We think this is really worth knowing, but meanwhile, by the way, we discovered a paper

34:49.720 --> 34:56.000
published by a couple of researchers that you've rarely heard of, but it's getting a lot

34:56.000 --> 35:01.840
of traction and it seems to be on a topic that is emerging and you're probably going to

35:01.840 --> 35:05.240
care about this.

35:05.240 --> 35:10.520
It's basically, it has to do with voice recognition and we know that that's an interesting topic,

35:10.520 --> 35:15.920
but the more interesting thing is that this researcher is really well known in a totally

35:15.920 --> 35:20.240
different field and is just like diving into this and that's unusual.

35:20.240 --> 35:21.240
So check it out.

35:21.240 --> 35:22.240
Here's the paper.

35:22.240 --> 35:25.600
I'm just going to go out on a limb here and say, you really should read this paper.

35:25.600 --> 35:36.480
By the way, here's basically a new concept that is creeping into the space and we haven't

35:36.480 --> 35:37.640
seen it before.

35:37.640 --> 35:42.080
This might be a fluke, but I think this is actually something that's worth knowing

35:42.080 --> 35:43.080
about.

35:43.080 --> 35:45.760
Here are five papers that you should read.

35:45.760 --> 35:48.760
I'm working within your budget here.

35:48.760 --> 35:50.080
That's what all the humans would do.

35:50.080 --> 35:56.360
It's basically the one-to-two-page presidential intelligence briefing.

35:56.360 --> 35:57.960
Ideally, that's what it would look like.

35:57.960 --> 36:04.200
A ton of research has gone into boiling things down to a very tight story and that's all

36:04.200 --> 36:06.600
you need to know.

36:06.600 --> 36:15.000
The idea then is that you've got some kind of generative model for creating these, basically

36:15.000 --> 36:18.840
you're briefing over and it has two steps.

36:18.840 --> 36:21.000
Like at least two steps.

36:21.000 --> 36:26.880
One is what information can I find that's truly relevant, the wrong ingredients of a story.

36:26.880 --> 36:30.720
And then the next step is, well, how can I synthesize this into an actual story?

36:30.720 --> 36:34.560
I have to do text generation, document planning.

36:34.560 --> 36:40.120
You give me a budget, a page, a paragraph, maybe you just want a bullet point and I'll

36:40.120 --> 36:41.120
work with it.

36:41.120 --> 36:46.320
I'll be able to express this as a story given that constraint.

36:46.320 --> 36:54.840
And so kind of going back to our earlier exchange about good old fashion heuristics, how to

36:54.840 --> 36:55.840
what degree?

36:55.840 --> 37:03.680
I haven't looked at compared one of these briefing pages versus another, but how much is

37:03.680 --> 37:10.200
generation and how much is more templates and things like that?

37:10.200 --> 37:20.000
Yeah, so the philosophy we followed is always start fast and doable, put another way.

37:20.000 --> 37:25.320
You always want to start with a model that you can fully understand yourself and implement

37:25.320 --> 37:29.240
quickly so that you have some baseline.

37:29.240 --> 37:37.520
So yeah, we've always started with, first can you do it yourself as a human, maybe even

37:37.520 --> 37:40.080
no computer involved.

37:40.080 --> 37:46.800
If you were to read 10 papers and try and say something intelligent about them, for example,

37:46.800 --> 37:54.160
tell me, tell me, for example, what, if you were to classify events and I gave you a

37:54.160 --> 38:00.840
pile of papers and I said, how would you classify these events, kind of tags would you attach

38:00.840 --> 38:01.840
to them?

38:01.840 --> 38:08.520
Or if you were looking for a particular kind of event, could you divide papers into yes

38:08.520 --> 38:11.040
and no?

38:11.040 --> 38:14.640
Always start with yourself, you the engineer, can you yourself do it?

38:14.640 --> 38:18.000
Because if you can't, you're probably going to have a hard time teaching a computer

38:18.000 --> 38:19.000
do it.

38:19.000 --> 38:24.880
And then if you get some other humans, probably the person just to chairs away from you,

38:24.880 --> 38:29.440
if you can get someone else to do the same task independently and get the same ideally

38:29.440 --> 38:32.800
or a similar answer, okay, now you're in good shape.

38:32.800 --> 38:39.360
Only then do you start building a computational system to try and do this automatically.

38:39.360 --> 38:42.120
And your first stab at that should be something's great forward.

38:42.120 --> 38:51.160
A set of regular expressions, heuristics, can you actually find this yourself using rules

38:51.160 --> 38:53.000
that you yourself devise?

38:53.000 --> 38:58.680
And then if the only way really to get beyond that, to really tackle increasing complexity

38:58.680 --> 39:02.200
is to have something that will learn on its own, you'll never do that with regular

39:02.200 --> 39:03.200
expressions.

39:03.200 --> 39:09.520
You have to use machine learning to have a system find patterns itself in a changing

39:09.520 --> 39:11.080
world.

39:11.080 --> 39:17.200
So I think you're saying then that there's, you know, you're somewhere on the spectrum

39:17.200 --> 39:20.320
of templates and machine learning.

39:20.320 --> 39:21.720
Oh yeah, always.

39:21.720 --> 39:28.160
In fact, I think the best things out there are always somewhere in the middle.

39:28.160 --> 39:29.160
Right.

39:29.160 --> 39:30.160
Right.

39:30.160 --> 39:31.160
I think by definition.

39:31.160 --> 39:34.480
And essentially it becomes a race.

39:34.480 --> 39:42.840
Can we build something that can learn faster and output better, smarter content than the

39:42.840 --> 39:44.440
system we have?

39:44.440 --> 39:51.880
We had a little race actually recently to try and build an event classifier and a brilliant

39:51.880 --> 39:58.640
engineer named Leonard Appleton took a stab at just using regular expressions, no machine

39:58.640 --> 39:59.640
learning.

39:59.640 --> 40:05.360
And another brilliant engineer named Yash took on the task of solving the same problem

40:05.360 --> 40:14.600
using a really complicated machine learning graphical model and sometimes John Henry wins

40:14.600 --> 40:15.600
the race.

40:15.600 --> 40:24.360
Frankly, Yash could not build a system at least last I checked that could do better than Leonard's

40:24.360 --> 40:29.360
massive, complicated, regular expression, heuristic engine.

40:29.360 --> 40:33.480
But eventually, eventually machine learning will win.

40:33.480 --> 40:36.000
Like we all know that, right.

40:36.000 --> 40:43.160
But that's the beauty of a practical approach when you're really driven by practical principles.

40:43.160 --> 40:47.560
You're willing to say, well, we've got a better solution that's actually simpler and

40:47.560 --> 40:49.120
easier to understand.

40:49.120 --> 40:51.160
Let's use that for now.

40:51.160 --> 40:52.480
Keep trying.

40:52.480 --> 40:57.440
But it's never long before a machine learning based system does better.

40:57.440 --> 41:00.080
It's just an incredibly powerful tool.

41:00.080 --> 41:06.920
When you're using machine learning for tasks like summarization where you referenced earlier,

41:06.920 --> 41:11.560
you know, first you do it, then you get someone else to do it and you compare them.

41:11.560 --> 41:17.000
You know, your summary of a given paper or a given paragraph is likely to be very different

41:17.000 --> 41:18.000
from mine.

41:18.000 --> 41:23.720
What do you find ground truth so that you can train learning models?

41:23.720 --> 41:24.720
Yeah.

41:24.720 --> 41:29.240
You've really put your finger on the hardest problem.

41:29.240 --> 41:34.640
Stories by their nature can be told infinite ways.

41:34.640 --> 41:39.800
There are some automated techniques that have been around for a decade.

41:39.800 --> 41:41.280
They have French color names.

41:41.280 --> 41:44.800
I don't know how that came about, but there's something called russian, something called

41:44.800 --> 41:46.280
blue.

41:46.280 --> 41:53.640
What they do is they treat the output as bag of word problems and they try and find out

41:53.640 --> 41:55.640
how much information overlap.

41:55.640 --> 42:00.240
There is between a human summary and a computer summary.

42:00.240 --> 42:04.440
As you can imagine, that's great if you're trying to measure whether you got it terribly

42:04.440 --> 42:05.440
wrong.

42:05.440 --> 42:06.440
Right.

42:06.440 --> 42:10.680
If we make two summaries and they have nothing to do with each other, then they're probably

42:10.680 --> 42:13.000
they're probably not talking about the same thing.

42:13.000 --> 42:14.000
Maybe.

42:14.000 --> 42:15.000
That's right.

42:15.000 --> 42:16.000
That's right.

42:16.000 --> 42:22.680
For summarizing fiction, we could be summarizing on two totally different levels and both be

42:22.680 --> 42:23.680
right.

42:23.680 --> 42:24.680
That's true.

42:24.680 --> 42:25.680
That's absolutely true.

42:25.680 --> 42:29.320
I think the same holds true for news.

42:29.320 --> 42:36.560
I'll let you continue, but that seems like a very, very rudimentary metric.

42:36.560 --> 42:41.800
Well, you'd be surprised then to learn that the latest greatest papers in this field are

42:41.800 --> 42:46.720
still using those metrics, because they're easy.

42:46.720 --> 42:54.720
It's a one click measurement, but it really doesn't help when you want to assess a subtle

42:54.720 --> 42:59.320
output of a story that could be sliced and diced in sort of infinite ways.

42:59.320 --> 43:01.120
Fortunately, it becomes a capture.

43:01.120 --> 43:06.560
You need some human to read it and go, oh yeah, that makes sense, or that's crazy.

43:06.560 --> 43:15.520
But there are some techniques you can use, so one is you can actually crowdsource assessment

43:15.520 --> 43:16.600
of narrative.

43:16.600 --> 43:24.080
You can give human annotators and scorers a system, a rigorous system, so like you can

43:24.080 --> 43:33.280
measure the coherence, you can measure the sophistication, whether or not you've really

43:33.280 --> 43:36.240
summarized the space well in various ways.

43:36.240 --> 43:40.480
So those sounds like they would require a fairly sophisticated crowdsource.

43:40.480 --> 43:47.160
Yeah, so that's right, like the more technical and sophisticated this task becomes, the less

43:47.160 --> 43:49.160
you can rely on mechanical Turk.

43:49.160 --> 43:56.800
In fact, eventually you've got your own engineers doing this, so it's definitely not scalable.

43:56.800 --> 44:02.800
But there are some tricks that you can use.

44:02.800 --> 44:10.920
So for example, if I generate a bunch of summaries on a topic that I've already summarized, for

44:10.920 --> 44:16.480
example, if I have a Wikipedia article about it, I can at least find out if the most important

44:16.480 --> 44:20.120
entities in the narrative have been represented.

44:20.120 --> 44:25.720
And I can also turn the system around and do extraction on the summary.

44:25.720 --> 44:31.720
You can even, I will suggest to make a generative adversarial network that generates stories

44:31.720 --> 44:33.640
and critiques them.

44:33.640 --> 44:35.360
You can see where this is going.

44:35.360 --> 44:42.400
Eventually, you can have a system that tries to check off all the boxes of what counts

44:42.400 --> 44:46.560
as a good story, like you've talked about the most important entities and you've expressed

44:46.560 --> 44:54.240
their relationships, you've come in under budget in terms of space on the page.

44:54.240 --> 44:59.000
But ultimately, you're going to need a human to assess whether it's a well-written story.

44:59.000 --> 45:06.880
Until we can crack the code of text style transfer, where you can actually say, tell me the

45:06.880 --> 45:12.520
story and the style of a New York Times reporter, or tell me the story and the style of a, you

45:12.520 --> 45:15.760
know, a terse military briefing.

45:15.760 --> 45:18.560
Send on my text in Hemingway style.

45:18.560 --> 45:19.560
Exactly.

45:19.560 --> 45:27.640
Until we can actually have networks that can both detect and reproduce narrative style.

45:27.640 --> 45:32.720
I think we're for the time being stuck in a world where it's really hard to assess how

45:32.720 --> 45:34.760
well our systems are doing.

45:34.760 --> 45:40.840
Ultimately, you want to hook this up to your users and either passively or actively

45:40.840 --> 45:44.240
harvest their feedback.

45:44.240 --> 45:47.040
The simplest version of this, of course, is A-B testing.

45:47.040 --> 45:53.720
If you write many versions of a summary and you expose a large number of humans to A versus

45:53.720 --> 45:57.560
B, you can just find out what they think of it by, for example,

45:57.560 --> 45:59.800
whether they click through and read it.

45:59.800 --> 46:01.800
You can also make it active.

46:01.800 --> 46:05.560
You can let users say, yeah, that was good or that was bad.

46:05.560 --> 46:10.240
We're going back to my Hemingway text summaries.

46:10.240 --> 46:15.840
Google inbox presenting you three choices for how to summarize the appropriate response

46:15.840 --> 46:16.840
to an email.

46:16.840 --> 46:17.840
Yep.

46:17.840 --> 46:19.720
And we've played with that as well.

46:19.720 --> 46:26.720
We generate alternative summaries to events, for example.

46:26.720 --> 46:32.440
It's a really powerful way of real-time, effortless, quality checking.

46:32.440 --> 46:37.360
You don't want to have to pause your whole engineering operation in order, all the time,

46:37.360 --> 46:38.720
just to assess how well you're doing.

46:38.720 --> 46:40.920
You really want it to be continual.

46:40.920 --> 46:45.880
You want to always be reading the output of your own computational systems.

46:45.880 --> 46:47.680
We call it dog fooding.

46:47.680 --> 46:50.200
You've got to be real-time dog fooding.

46:50.200 --> 46:56.760
The nice thing about primary science is this thing that I'm building is we use it to

46:56.760 --> 47:01.080
discover the research that is going to help us make it better.

47:01.080 --> 47:06.160
And so if you keep on using the thing, you are your own quality assessor.

47:06.160 --> 47:07.160
That really helps.

47:07.160 --> 47:08.160
Right.

47:08.160 --> 47:09.160
But hard to scale.

47:09.160 --> 47:15.720
I wish I could clone myself in some way to assess sort of at 1,000X.

47:15.720 --> 47:24.000
Now one thing that I didn't see in what you've built, it seems like it is, it does a really

47:24.000 --> 47:32.720
good job at this meta characterization of archive and what's happening in different categories.

47:32.720 --> 47:36.640
But I didn't see it attempting to summarize individual papers.

47:36.640 --> 47:39.960
Which is the thing that Jeff Dean and I were originally talking about.

47:39.960 --> 47:42.160
Is it trying to do that somewhere?

47:42.160 --> 47:43.760
Not in what you're looking at.

47:43.760 --> 47:48.200
But we are actually working on that summarization problem.

47:48.200 --> 47:54.040
Yeah, so we've taken two strategies and they're kind of running in parallel.

47:54.040 --> 48:02.680
One is extractive summarization where you, the system is allowed to pull words and even

48:02.680 --> 48:07.400
whole sentences directly from the text and then kind of pull them together into a summary.

48:07.400 --> 48:11.720
That works extremely well when you have a large number of docs.

48:11.720 --> 48:18.320
If you have 100 documents all about the same thing, extractive summarization is really powerful

48:18.320 --> 48:20.160
and really efficient.

48:20.160 --> 48:25.120
And then the alternative is abstractive summarization where the system is going to write its own words,

48:25.120 --> 48:28.400
often character by character, out of thin air.

48:28.400 --> 48:29.680
And it has a language model.

48:29.680 --> 48:35.520
So it reads all these things and it basically makes a prediction about what it should say

48:35.520 --> 48:38.520
next as it generates a summary.

48:38.520 --> 48:44.200
A really nice bit of progress in this field that we've been using is abstractive summarization

48:44.200 --> 48:45.800
with pointers.

48:45.800 --> 48:51.560
So the idea here is you also have a sense of your confidence about whether the word or

48:51.560 --> 48:58.040
phrase that you're putting into the summary at any given time is going to be a good choice.

48:58.040 --> 49:02.480
And if you're not so confident, you point back to the text and you grab the thing itself.

49:02.480 --> 49:11.320
So for example, if you had a sentence that said one of the most exciting areas of artificial

49:11.320 --> 49:17.280
intelligence these days is generative adversarial networks.

49:17.280 --> 49:21.240
If generative adversarial networks, that phrase is something that you haven't encountered

49:21.240 --> 49:27.520
or your model basically says, I'm not sure if I can actually paraphrase that.

49:27.520 --> 49:29.680
Then what you want to do is what a good human writer would do.

49:29.680 --> 49:31.920
You just go back and you grab that thing.

49:31.920 --> 49:40.720
So you can summarize while also having some of the advantages of extractive.

49:40.720 --> 49:47.640
So summarizing basically around the entities that you aren't too sure about.

49:47.640 --> 49:48.640
Exactly.

49:48.640 --> 49:52.200
It basically becomes a sliding scale between abstractive and extractive.

49:52.200 --> 49:56.000
The more confident it gets, the more abstractive it gets, the more flexible it gets, which

49:56.000 --> 50:01.880
will allow you to summarize a single scientific paper, for example, in a couple of sentences.

50:01.880 --> 50:08.240
And if you're not so sure, then it slides over to extractive and it will just pull out

50:08.240 --> 50:14.440
the sentences that it deem and the phrases that it deems are the most central and informative.

50:14.440 --> 50:15.440
Interesting.

50:15.440 --> 50:16.440
It's a hard problem though.

50:16.440 --> 50:17.440
It's a really hard problem.

50:17.440 --> 50:22.720
Another thing that makes it hard when it comes to scientific papers is they already have

50:22.720 --> 50:23.720
their own summaries.

50:23.720 --> 50:26.720
They're called abstracts.

50:26.720 --> 50:32.760
And you'd think that, oh, great, this job done, but as you know, abstracts themselves

50:32.760 --> 50:38.400
can be so riddled with jargon and references to arcane things that it's hardly a summary

50:38.400 --> 50:39.400
at all.

50:39.400 --> 50:42.200
It's really only a summary for the authors of the paper.

50:42.200 --> 50:43.200
Right.

50:43.200 --> 50:45.960
So you really need a summary of the summary.

50:45.960 --> 50:46.960
Right.

50:46.960 --> 50:48.440
And that's what we're working on.

50:48.440 --> 50:52.000
We're finding that you really do need to power this with an ontology and a knowledge base

50:52.000 --> 50:53.000
though.

50:53.000 --> 50:54.360
A library on that.

50:54.360 --> 51:00.680
Okay, so let's take, for example, a problem that I'm just starting to work on.

51:00.680 --> 51:07.480
How do you summarize and make sense of pharmaceutical research papers?

51:07.480 --> 51:15.720
So there is an ontology that is available to everyone that basically the NIH paid for

51:15.720 --> 51:17.680
called MASH.

51:17.680 --> 51:28.080
And it's kind of like every jargon term in biochemistry and molecular biology, gene names and gene

51:28.080 --> 51:35.040
types, all of that is captured in this very rich ontology that was hand-built by no

51:35.040 --> 51:40.160
doubt by un thanked graduate students.

51:40.160 --> 51:45.240
And something that's really nice about MASH is that it's actually a subset of wiki data.

51:45.240 --> 51:52.720
And wiki data is the database that stands behind wikipedia.

51:52.720 --> 51:57.000
Now I say that in an idealistic way because actually, in reality, that's the way it was

51:57.000 --> 51:58.000
dreamed up.

51:58.000 --> 52:01.120
Oh, wiki data is going to basically be the database that powers wikipedia.

52:01.120 --> 52:04.000
But in fact, it's not there yet.

52:04.000 --> 52:13.080
Humans vastly prefer to update wikipedia with content and wiki data basically plays catch-up.

52:13.080 --> 52:19.800
Nonetheless, it is a huge powerful open source knowledge base and the MASH ontology is a

52:19.800 --> 52:21.640
subset of it.

52:21.640 --> 52:28.480
And so if you want to summarize a scientific paper, just a single scientific paper, the

52:28.480 --> 52:31.400
first thing you need to do is make sense of it.

52:31.400 --> 52:36.600
You need to map all of those words which to the computer or just, it could be random numbers

52:36.600 --> 52:39.200
for all they cares, has no idea what it means.

52:39.200 --> 52:44.200
You need to map them to concepts and that's what systems like MASH were designed to help

52:44.200 --> 52:45.440
us do.

52:45.440 --> 52:52.160
So the idea of being instead of what you're doing in science primer, and doing this in

52:52.160 --> 52:57.080
a totally unsupervised manner, here you're using the additional information you're getting

52:57.080 --> 53:05.600
from the pre-existing ontology to help the machine make sense of the various documents.

53:05.600 --> 53:06.920
And to paraphrase it.

53:06.920 --> 53:12.600
So like a good summary is something that doesn't just say less.

53:12.600 --> 53:17.200
It also says just as much but in a compressed way.

53:17.200 --> 53:18.200
Right.

53:18.200 --> 53:21.200
If I just tell you the beginning of a story, I haven't really compressed that story for

53:21.200 --> 53:22.880
you.

53:22.880 --> 53:26.720
I need to give you the sense of the beginning, middle, and end and compress that all

53:26.720 --> 53:29.040
down into three sentences.

53:29.040 --> 53:35.200
And you're not going to be able to do that just using the standard NLP techniques on a

53:35.200 --> 53:36.200
scientific paper.

53:36.200 --> 53:39.120
You're just not going to be able to do it, no way.

53:39.120 --> 53:44.960
You have to map that out to an ontology and say, oh, you know, this long sentence describing

53:44.960 --> 53:50.720
this genetic pathway, I can boil that down to a single sentence that says, the genetic

53:50.720 --> 53:57.800
pathway X, you know, interesting, but yeah, you need a lot of tacit knowledge to be able

53:57.800 --> 53:58.800
to do that.

53:58.800 --> 54:01.440
So that's what we're working on.

54:01.440 --> 54:02.440
Awesome.

54:02.440 --> 54:03.440
Well, John, this has been super interesting.

54:03.440 --> 54:06.120
I really appreciate you taking the time.

54:06.120 --> 54:07.120
Thank you.

54:07.120 --> 54:09.760
Anything else you'd like to share with the audience?

54:09.760 --> 54:14.360
Oh, just that I'd like to make a prediction.

54:14.360 --> 54:15.360
Go ahead.

54:15.360 --> 54:25.680
Well, I predict that the kind of stuff we're working on is going to accelerate artificial

54:25.680 --> 54:27.760
intelligence research more than anything else.

54:27.760 --> 54:34.680
I think building AI that can read the latest research on AI and help the engineers who

54:34.680 --> 54:42.240
build it, build it faster is going to vastly accelerate the whole process.

54:42.240 --> 54:43.240
Awesome.

54:43.240 --> 54:51.920
Well, we will put your prediction on the blockchain and just to make sure we get all the jargon

54:51.920 --> 54:52.920
in.

54:52.920 --> 54:53.920
Exactly.

54:53.920 --> 54:54.920
Then we'll do an ICU.

54:54.920 --> 54:57.520
We'll do an ICU, right?

54:57.520 --> 54:58.520
Awesome.

54:58.520 --> 55:00.320
Thanks so much, John.

55:00.320 --> 55:01.320
Thanks, Sam.

55:01.320 --> 55:06.560
All right, everyone.

55:06.560 --> 55:08.600
That's our show for today.

55:08.600 --> 55:13.560
For more information on John or any of the topics covered in this episode, head on over

55:13.560 --> 55:19.360
to twomolei.com slash talk slash one, three, six.

55:19.360 --> 55:37.000
Thanks so much for listening and catch you next time.

