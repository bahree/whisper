1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:31,640
I'm your host Sam Charrington.

4
00:00:31,640 --> 00:00:36,720
Today we're joined by Marissa Boston, Director of Cognitive Technology in KPMG's Cognitive

5
00:00:36,720 --> 00:00:38,320
Automation Lab.

6
00:00:38,320 --> 00:00:42,480
Marissa and I caught up to discuss some of the ways that KPMG's using AI to build tools

7
00:00:42,480 --> 00:00:47,240
that help augment the knowledge of their various teams of professionals.

8
00:00:47,240 --> 00:00:51,360
We start out with a discussion of knowledge graphs and how they can be used to map out

9
00:00:51,360 --> 00:00:53,520
and relate various concepts.

10
00:00:53,520 --> 00:00:58,880
We then explore how they use these in conjunction with NLP to create insight engines, tools

11
00:00:58,880 --> 00:01:04,160
that curate and contextualize news and other text-based data sources to produce a series

12
00:01:04,160 --> 00:01:08,680
of content recommendations that help their users work more effectively.

13
00:01:08,680 --> 00:01:16,080
Finally, Marissa shares some great general principles for using AI to augment human experts.

14
00:01:16,080 --> 00:01:19,920
Before we dive in, over the next few weeks, I'll be bringing you some great interviews

15
00:01:19,920 --> 00:01:27,160
from the road, including AWS re-invent, NURRIPS and CUBECON, and I would love to connect

16
00:01:27,160 --> 00:01:29,600
with any listeners and attendants.

17
00:01:29,600 --> 00:01:35,600
Feel free to shoot me a message via at Sam Charrington on Twitter, email, the Twimble website,

18
00:01:35,600 --> 00:01:40,240
LinkedIn, or if you just see me walking by, don't be afraid to say hi.

19
00:01:40,240 --> 00:01:45,000
If you're heading to NURRIPS, look for the listener meetup and the AI platforms meetup

20
00:01:45,000 --> 00:01:47,600
that I've posted in the Hoover app.

21
00:01:47,600 --> 00:01:49,280
See you around.

22
00:01:49,280 --> 00:01:52,000
And now on to the show.

23
00:01:52,000 --> 00:01:55,360
All right, everyone.

24
00:01:55,360 --> 00:01:57,520
I am on the line with Marissa Boston.

25
00:01:57,520 --> 00:02:04,080
Marissa is director of Cognitive Technology for KPMG's Cognitive Automation Lab.

26
00:02:04,080 --> 00:02:07,200
Marissa, welcome to this Weekend Machine Learning and AI.

27
00:02:07,200 --> 00:02:08,440
Thank you.

28
00:02:08,440 --> 00:02:10,400
It is great to chat with you.

29
00:02:10,400 --> 00:02:13,520
Why don't we get started with a little bit of your background?

30
00:02:13,520 --> 00:02:19,280
I understand you spent some time studying at Cornell in upstate New York.

31
00:02:19,280 --> 00:02:20,280
That's right.

32
00:02:20,280 --> 00:02:22,600
I did my PhD at Cornell.

33
00:02:22,600 --> 00:02:29,160
My area of focus was computational linguistics, which is a mouthful, but it's essentially

34
00:02:29,160 --> 00:02:36,600
building out computer, basically computational models of how humans understand sentences

35
00:02:36,600 --> 00:02:39,000
was the work that I was doing.

36
00:02:39,000 --> 00:02:46,400
So it was a really interesting way to take technology and try to see how we can investigate

37
00:02:46,400 --> 00:02:53,320
scientific matters, how the human is understanding language and things like that.

38
00:02:53,320 --> 00:03:00,480
And in your work there, were you focused primarily on traditional linguistic models or were

39
00:03:00,480 --> 00:03:02,480
you working with statistical models?

40
00:03:02,480 --> 00:03:05,400
Yeah, I actually built out statistical parsers.

41
00:03:05,400 --> 00:03:09,120
So it was kind of like this, we did both essentially.

42
00:03:09,120 --> 00:03:16,240
So I worked on statistical sentence parsers, but what I would do is I would use theories

43
00:03:16,240 --> 00:03:24,480
from cycle linguistics and from linguistics to help determine where difficulty might be

44
00:03:24,480 --> 00:03:25,840
in a sentence.

45
00:03:25,840 --> 00:03:31,840
And then I would actually test if that difficulty is coming through in the same way for the human

46
00:03:31,840 --> 00:03:37,680
as it would be for the computer based on how I encoded those both the linguistic structures

47
00:03:37,680 --> 00:03:41,960
and the psychological theories as well.

48
00:03:41,960 --> 00:03:43,840
Oh, interesting, interesting.

49
00:03:43,840 --> 00:03:45,760
And after your PhD?

50
00:03:45,760 --> 00:03:49,280
After my PhD, I decided to go into industry research.

51
00:03:49,280 --> 00:03:53,960
I went to the nuanced communications where I worked in their AI and NLP labs, and that

52
00:03:53,960 --> 00:03:54,960
was really fun.

53
00:03:54,960 --> 00:04:01,240
I got to do all sorts of things I worked on, the original Watson system, helping to tune

54
00:04:01,240 --> 00:04:03,920
it to healthcare.

55
00:04:03,920 --> 00:04:09,840
And I worked on other types of question answering and textual inference systems and also virtual

56
00:04:09,840 --> 00:04:13,120
assistance for customer service centers.

57
00:04:13,120 --> 00:04:16,560
And then you moved over to KPMG, right?

58
00:04:16,560 --> 00:04:17,560
I did.

59
00:04:17,560 --> 00:04:25,800
I ended up moving out of tech and I wanted to go into more of a consulting firm and a professional

60
00:04:25,800 --> 00:04:30,920
services firm because I wanted to get more of a sense of how we can build out the

61
00:04:30,920 --> 00:04:37,800
appropriate environment for these technologies and what are the business models that can

62
00:04:37,800 --> 00:04:42,480
support them in order to ensure that they are actually being used appropriately.

63
00:04:42,480 --> 00:04:47,360
So I was kind of getting sick of, you know, I realized fairly quickly that no matter

64
00:04:47,360 --> 00:04:51,640
how good my designs are, my architecture is my implementations.

65
00:04:51,640 --> 00:04:55,560
If the business model doesn't support it, then you're not really going to be able to

66
00:04:55,560 --> 00:04:57,480
get much use out of it.

67
00:04:57,480 --> 00:05:01,720
So I really wanted to get a better sense of how we can build these tools more appropriately.

68
00:05:01,720 --> 00:05:08,280
When you say the business model needs to support it and creating the appropriate environment,

69
00:05:08,280 --> 00:05:10,440
what all is involved in that?

70
00:05:10,440 --> 00:05:16,280
I think it really comes down to, first of all, having the appropriate boundaries.

71
00:05:16,280 --> 00:05:22,600
So one of the things that interested me about coming to KPMG is that they're an audit

72
00:05:22,600 --> 00:05:24,240
firm, audit and tax accounting.

73
00:05:24,240 --> 00:05:28,720
And so they have a lot of regulatory pressures on them.

74
00:05:28,720 --> 00:05:32,760
And I find this interesting because a lot of times in tech, we think that we have to invent

75
00:05:32,760 --> 00:05:33,760
everything.

76
00:05:33,760 --> 00:05:38,560
And I think that usually this leads to some kind of a wild west mentality in terms of what

77
00:05:38,560 --> 00:05:41,920
technologies are out there and whether they're appropriate or not.

78
00:05:41,920 --> 00:05:46,800
I was really interested in seeing what kind of human boundaries might be there in terms

79
00:05:46,800 --> 00:05:53,560
of regulations and in terms of the types of technologies we can actually provide.

80
00:05:53,560 --> 00:05:54,560
So that was one thing.

81
00:05:54,560 --> 00:05:59,880
The other thing is that in a lot of ways, it teaches you to be an ambassador, not just

82
00:05:59,880 --> 00:06:04,200
for what the technologies can do, but also what the technologies can't do.

83
00:06:04,200 --> 00:06:10,080
And you start to be able to ask the question of whether these technologies should be employed

84
00:06:10,080 --> 00:06:11,320
in this way.

85
00:06:11,320 --> 00:06:18,280
Or is this really going to, I find in tech often, everybody's going after accuracy or specific

86
00:06:18,280 --> 00:06:20,680
requirements along those lines.

87
00:06:20,680 --> 00:06:24,880
But instead, when you're at a professional services firm, you start to think about things

88
00:06:24,880 --> 00:06:32,520
in terms of more human metrics like, you know, are we actually leading to higher quality?

89
00:06:32,520 --> 00:06:36,960
Things like that that I think is really key in helping to understand things.

90
00:06:36,960 --> 00:06:43,920
And finally, I do think that it's about helping the business transform digitally so that

91
00:06:43,920 --> 00:06:45,560
they can help support these systems.

92
00:06:45,560 --> 00:06:49,320
So just like anything else, I mean, they need the appropriate data.

93
00:06:49,320 --> 00:06:54,600
They need the appropriate improvement methodologies so that they can go forward.

94
00:06:54,600 --> 00:06:58,560
And actually, you know, you have all of this beautiful technology and all these beautiful

95
00:06:58,560 --> 00:06:59,560
methods.

96
00:06:59,560 --> 00:07:03,000
Can you actually implement them, but then also improve them so that they can realize their

97
00:07:03,000 --> 00:07:04,000
real potential?

98
00:07:04,000 --> 00:07:05,000
Yeah.

99
00:07:05,000 --> 00:07:06,000
I like the way you put that.

100
00:07:06,000 --> 00:07:13,680
One of the things that I am finding, you know, interesting and inspiring or I've been

101
00:07:13,680 --> 00:07:20,360
inspiring is maybe not the word but heartening is that we're starting to hear more of a

102
00:07:20,360 --> 00:07:27,120
shift from the kind of asking the Ken Wee question to the should we question, and maybe

103
00:07:27,120 --> 00:07:30,920
it's not even a shift, but you know, we're at least starting to hear the should we question

104
00:07:30,920 --> 00:07:40,680
in the context of AI and thinking about ethics and appropriateness and, you know, the implications

105
00:07:40,680 --> 00:07:46,280
of some of this, some of these technologies are those questions that you're focused on

106
00:07:46,280 --> 00:07:47,280
answering as well?

107
00:07:47,280 --> 00:07:48,280
Yeah.

108
00:07:48,280 --> 00:07:54,280
And in fact, KPMG even before I started was already going down this line.

109
00:07:54,280 --> 00:08:02,360
So they're backing and data analytics has always been around the trust aspect, right?

110
00:08:02,360 --> 00:08:07,160
And really about the fact that their clients employ them not for, you know, efficiency or

111
00:08:07,160 --> 00:08:10,280
something along those lines, but really for trust.

112
00:08:10,280 --> 00:08:19,360
And also KPMG de-auditors, especially, you know, we are responsible for trust in the capital

113
00:08:19,360 --> 00:08:26,000
markets because we audit financial statements, you know, we have that responsibility.

114
00:08:26,000 --> 00:08:32,160
And so this has been a part of the conversation at KPMG for a long time and it really intrigued

115
00:08:32,160 --> 00:08:39,280
me because when we, when they were embarking on building out these types of technologies,

116
00:08:39,280 --> 00:08:41,440
they already had that mindset.

117
00:08:41,440 --> 00:08:46,160
And it was now really a question of how do we bring in the appropriate people to help

118
00:08:46,160 --> 00:08:49,400
us build these out in this way that we want to do.

119
00:08:49,400 --> 00:08:54,480
And I find that really, you know, at first it might have felt a little bit like a step

120
00:08:54,480 --> 00:08:58,120
backward because it means that, you know, you don't have the gobs of data.

121
00:08:58,120 --> 00:09:01,880
You can't use the way to state-of-the-art everything, right?

122
00:09:01,880 --> 00:09:06,960
It means that a lot of times you have to specifically pick your partners for, according

123
00:09:06,960 --> 00:09:10,400
to a different criteria than you normally would.

124
00:09:10,400 --> 00:09:17,160
But in the end, I think that what we're seeing, especially now, and this is now two years

125
00:09:17,160 --> 00:09:23,160
after I started at the firm and probably, you know, several years before that KPMG had

126
00:09:23,160 --> 00:09:28,520
already started on this journey, now you're actually seeing that that others are catching

127
00:09:28,520 --> 00:09:30,840
up to that way of thinking as well.

128
00:09:30,840 --> 00:09:36,280
So one of the main topics that we wanted to jump into in this conversation is some work

129
00:09:36,280 --> 00:09:42,080
that you've been doing recently around the idea of knowledge graphs.

130
00:09:42,080 --> 00:09:46,480
Can you start us off by explaining what a knowledge graph is?

131
00:09:46,480 --> 00:09:47,480
Sure.

132
00:09:47,480 --> 00:09:52,960
So a knowledge graph, I think a very simple way of thinking of a knowledge graph is essentially

133
00:09:52,960 --> 00:09:55,760
just a network of concepts.

134
00:09:55,760 --> 00:10:04,800
And knowledge graphs are a simplification of more formal ways of defining relationships

135
00:10:04,800 --> 00:10:08,400
between concepts and entities.

136
00:10:08,400 --> 00:10:15,240
But that simplification allows us to use a variety of techniques that might not always

137
00:10:15,240 --> 00:10:18,680
be possible if we go for the stronger versions.

138
00:10:18,680 --> 00:10:26,360
And so for at KPMG, for example, we have a lot of processes and a lot of expertise and

139
00:10:26,360 --> 00:10:31,040
knowledge that we want to have encoded in a way that we can make use of.

140
00:10:31,040 --> 00:10:37,440
And a lot of times, it's already been put into something like a taxonomy that someone

141
00:10:37,440 --> 00:10:43,240
somewhere in the organization has to keep up to date in some way.

142
00:10:43,240 --> 00:10:49,320
And what we try to do is we've also hired an oncologist to come in and not only help

143
00:10:49,320 --> 00:10:55,120
formalize that knowledge in a way that's actually a little bit better.

144
00:10:55,120 --> 00:11:03,280
But we also use take that kind of stronger version and we simplify it into knowledge graphs

145
00:11:03,280 --> 00:11:09,680
to allow us to, for example, take our knowledge about one area and apply it to our knowledge

146
00:11:09,680 --> 00:11:16,400
about another area or take internal knowledge and apply it to external news, for example.

147
00:11:16,400 --> 00:11:22,600
So we use knowledge graphs to be able to take our internal taxonomies, ontologies about

148
00:11:22,600 --> 00:11:28,120
client issues and be able to map them to news that is out there.

149
00:11:28,120 --> 00:11:32,680
And the knowledge graph is actually a much easier way to do this than a more formal method.

150
00:11:32,680 --> 00:11:39,800
And it also allows us to work with a variety of news vendors that are already using these

151
00:11:39,800 --> 00:11:42,160
types of technologies.

152
00:11:42,160 --> 00:11:50,200
So when I think of things like taxonomies and ontologies, one of the first things that

153
00:11:50,200 --> 00:11:53,400
I think of is this idea of knowledge management.

154
00:11:53,400 --> 00:11:58,280
It's an area that I did some work in a long time ago.

155
00:11:58,280 --> 00:12:01,480
Knowledge management and document management, there's, you know, those are, that's a kind

156
00:12:01,480 --> 00:12:04,040
of mature space unto itself.

157
00:12:04,040 --> 00:12:07,360
Where does cognitive come into all this?

158
00:12:07,360 --> 00:12:11,280
So it is a mature place, you know, a mature space.

159
00:12:11,280 --> 00:12:16,000
Those technologies are mature, but that doesn't necessarily mean that everybody has implemented

160
00:12:16,000 --> 00:12:22,520
them appropriately and that that implementation extends across the whole enterprise.

161
00:12:22,520 --> 00:12:28,320
And so one of the things that we found and I admit, this is not my specific area of expertise.

162
00:12:28,320 --> 00:12:34,360
This is, we have others within my lab, even, who have years of expertise in this area,

163
00:12:34,360 --> 00:12:37,160
but I had the opportunity to work with them.

164
00:12:37,160 --> 00:12:45,800
But the main challenge with knowledge management is that it's not necessarily done in a way

165
00:12:45,800 --> 00:12:50,800
or if it has been done, it hasn't necessarily been done in a way that allows us to take

166
00:12:50,800 --> 00:12:58,200
advantage of the data or the information that's available for artificial intelligence systems.

167
00:12:58,200 --> 00:13:01,640
A lot of times, that's one of the problems.

168
00:13:01,640 --> 00:13:07,720
Now at KPMG, and I think that you see this set of variety of other firms and organizations

169
00:13:07,720 --> 00:13:12,800
as well, that digital transformation hasn't necessarily happened evenly.

170
00:13:12,800 --> 00:13:18,240
So while there might be certain places where we have, say, data lakes, in the end, we don't

171
00:13:18,240 --> 00:13:19,960
have them everywhere.

172
00:13:19,960 --> 00:13:25,800
On top of that, we have another issue, which is that we have a lot of restrictions when

173
00:13:25,800 --> 00:13:27,880
it comes to client information.

174
00:13:27,880 --> 00:13:32,360
We are very restrictive and risk averse when it comes to client information.

175
00:13:32,360 --> 00:13:36,360
And so a lot of the processes end up being manual because of that.

176
00:13:36,360 --> 00:13:39,400
So there has to be a culture shift there as well.

177
00:13:39,400 --> 00:13:44,880
So you're absolutely right, some of these methods are fairly mature.

178
00:13:44,880 --> 00:13:48,800
And we know what the methods are, we just have to implement them.

179
00:13:48,800 --> 00:13:54,240
And I'd say, for example, in the way that we're using knowledge graphs, this is not something

180
00:13:54,240 --> 00:13:55,240
that we're making up.

181
00:13:55,240 --> 00:13:59,000
In fact, if you look at a lot of CRM solutions, this is how they operate.

182
00:13:59,000 --> 00:14:05,440
They have some kind of an internal taxonomy or internal idea of what are important concepts.

183
00:14:05,440 --> 00:14:11,520
You can go off and look at external news or else you can look at information between services

184
00:14:11,520 --> 00:14:15,040
and engagements and you try to map them out appropriately.

185
00:14:15,040 --> 00:14:16,760
We're doing exactly the same thing.

186
00:14:16,760 --> 00:14:21,160
But I think the main distinction is that we're putting our own spin on it.

187
00:14:21,160 --> 00:14:25,120
We're taking information that has long been internal to KPMG.

188
00:14:25,120 --> 00:14:29,880
And now we have the technology to be able to use that information and map it out to external

189
00:14:29,880 --> 00:14:33,760
news in a way that actually benefits our workers.

190
00:14:33,760 --> 00:14:39,440
So taking advantage of these techniques that have matured under the banner of knowledge

191
00:14:39,440 --> 00:14:48,160
management, are you also then incorporating in artificial intelligence and cognitive

192
00:14:48,160 --> 00:14:49,160
technologies?

193
00:14:49,160 --> 00:14:50,160
Well, presumably you are.

194
00:14:50,160 --> 00:14:51,160
Is that correct?

195
00:14:51,160 --> 00:14:52,160
Yes.

196
00:14:52,160 --> 00:14:53,160
Yeah, we do.

197
00:14:53,160 --> 00:14:56,840
So this is one particular project where we're using knowledge graphs.

198
00:14:56,840 --> 00:15:00,520
Now, we don't just serve up the information, right?

199
00:15:00,520 --> 00:15:06,720
So it's not just that we have external news and we say, hey, here's a bunch of news articles.

200
00:15:06,720 --> 00:15:11,760
We actually do this in a way that allows us to contextualize it according to specific

201
00:15:11,760 --> 00:15:15,200
recommendations that will help our account leads.

202
00:15:15,200 --> 00:15:19,400
So we have information about the services KPMG offers.

203
00:15:19,400 --> 00:15:22,480
We have information about previous engagements.

204
00:15:22,480 --> 00:15:24,680
We have information about the clients.

205
00:15:24,680 --> 00:15:29,360
We have now external news and we're able to use the knowledge graph to try to map all

206
00:15:29,360 --> 00:15:34,960
of these appropriately and then also try to see what are the top recommendations we have

207
00:15:34,960 --> 00:15:36,120
for services.

208
00:15:36,120 --> 00:15:41,080
And then we use our news articles or previous engagements as support for that, right?

209
00:15:41,080 --> 00:15:44,920
So it's kind of like evidence for why we're giving this recommendation.

210
00:15:44,920 --> 00:15:51,240
And all of this, so it not just the ability to use knowledge graphs in this way, to be

211
00:15:51,240 --> 00:15:57,760
able to map across all of these different areas, but also the recommendation engines use

212
00:15:57,760 --> 00:16:03,960
a variety of techniques that, you know, whether they're, it's kind of difficult to say where

213
00:16:03,960 --> 00:16:09,440
they fit in, right, to AI, but they're within the context of general machine learning and

214
00:16:09,440 --> 00:16:10,440
general practice.

215
00:16:10,440 --> 00:16:14,400
It's more a question of how do we apply it to our specific business?

216
00:16:14,400 --> 00:16:19,720
Maybe let's take a step back and kind of put a fine point on this project.

217
00:16:19,720 --> 00:16:26,000
You are essentially building up a, you know, would you call it a dashboard for these account

218
00:16:26,000 --> 00:16:33,760
managers that helps them kind of stay on top of news that affects their clients?

219
00:16:33,760 --> 00:16:35,000
Yeah, exactly.

220
00:16:35,000 --> 00:16:40,960
So this is kind of an additional insight engine that we provide to our account managers.

221
00:16:40,960 --> 00:16:47,120
And one of the things to take into account is that especially when these systems go live,

222
00:16:47,120 --> 00:16:51,840
you know, we would put this up and, you know, our top account managers say for our, you

223
00:16:51,840 --> 00:16:56,520
know, most, you know, our top 100 or 200 accounts, right?

224
00:16:56,520 --> 00:17:00,760
These are people who really know their clients, these are people who really know what's going

225
00:17:00,760 --> 00:17:01,760
on.

226
00:17:01,760 --> 00:17:04,560
They are reading the news and they have their own intuitions.

227
00:17:04,560 --> 00:17:07,800
These are our top experts in terms of what's important.

228
00:17:07,800 --> 00:17:13,920
Now this system is likely not going to provide that much insight for these top accounts where

229
00:17:13,920 --> 00:17:19,000
we already have a lot of people looking into this and a lot of this information isn't

230
00:17:19,000 --> 00:17:20,000
missed.

231
00:17:20,000 --> 00:17:24,120
So where you really start to see the advantage of this is when you extend past that and

232
00:17:24,120 --> 00:17:28,080
what we're really trying to think of is how do we take the quality that we're able to

233
00:17:28,080 --> 00:17:33,520
provide for our top, from our top experts to our top clients and how do we expand that

234
00:17:33,520 --> 00:17:34,520
beyond?

235
00:17:34,520 --> 00:17:39,320
And when you think further back, so when you think about the fact that, you know, other

236
00:17:39,320 --> 00:17:43,840
account managers might have, you know, like 20 accounts that they have to, you know,

237
00:17:43,840 --> 00:17:49,040
20 clients that they that they have to somehow manage and juggle and they might not have

238
00:17:49,040 --> 00:17:53,560
to be able to, for example, look into the news every single day for those.

239
00:17:53,560 --> 00:17:58,200
At that point, you start to see why this kind of a recommendation engine might help us find

240
00:17:58,200 --> 00:18:04,360
things that we might have normally missed and help us expand our quality beyond the what

241
00:18:04,360 --> 00:18:07,800
we're currently able to provide to only a few clients.

242
00:18:07,800 --> 00:18:08,800
Right.

243
00:18:08,800 --> 00:18:09,800
Right.

244
00:18:09,800 --> 00:18:15,120
Well, I can relate very personally to the challenge that you're trying to address here, just

245
00:18:15,120 --> 00:18:22,160
in my own role as an industry analyst and, you know, someone that needs to stay on top

246
00:18:22,160 --> 00:18:28,680
of, you know, not just kind of what the large vendors are doing in AI, but what the smaller

247
00:18:28,680 --> 00:18:35,440
vendors are doing, what the, you know, the major technology platforms and frameworks and

248
00:18:35,440 --> 00:18:38,880
there's just a ton of information out there.

249
00:18:38,880 --> 00:18:43,400
And, you know, like you said, I've got some kind of go to sources and some go to feeds

250
00:18:43,400 --> 00:18:52,680
that and tools, even that I can rely on to help me stay informed, but I am often, you

251
00:18:52,680 --> 00:18:58,120
know, almost daily, you know, wishing that I had something that was smarter, that was

252
00:18:58,120 --> 00:19:04,840
more intelligent, more connected, more tied into the things that I need to stay on top

253
00:19:04,840 --> 00:19:10,000
of that could be almost like a, you know, a personal agent, a personal assistant, a

254
00:19:10,000 --> 00:19:15,520
dashboard that surfaced all of the things that I need to, needed to know, but also, you

255
00:19:15,520 --> 00:19:21,360
know, pushed down the things that aren't as important for me and was able to learn

256
00:19:21,360 --> 00:19:23,760
the difference between the two over time.

257
00:19:23,760 --> 00:19:24,760
Exactly.

258
00:19:24,760 --> 00:19:27,760
And I think there's two important things about you're saying there.

259
00:19:27,760 --> 00:19:33,520
One is, I think just the process of understanding how to encode the expertise that you have,

260
00:19:33,520 --> 00:19:34,520
right?

261
00:19:34,520 --> 00:19:38,720
So the process that we have, our experts go through, like especially with our chief

262
00:19:38,720 --> 00:19:43,800
ontologist in terms of being able to better hone, what are the important concepts?

263
00:19:43,800 --> 00:19:45,760
How are they doing their jobs right now?

264
00:19:45,760 --> 00:19:51,600
How do we take that important information and how do we build out exactly what those intuitions

265
00:19:51,600 --> 00:19:52,600
might be?

266
00:19:52,600 --> 00:20:00,560
I think that's one really good thing that comes out of transforming, say your, you know,

267
00:20:00,560 --> 00:20:08,680
what you yourself do as an analyst into something that could be more like a digital

268
00:20:08,680 --> 00:20:09,680
process, right?

269
00:20:09,680 --> 00:20:15,800
Then the other thing as you're saying is absolutely, once you have that, you can really start

270
00:20:15,800 --> 00:20:22,520
to play with how do we start thinking about how we can expand the quality, you know, you

271
00:20:22,520 --> 00:20:27,080
want to be able to focus your attention and your top quality to the best things.

272
00:20:27,080 --> 00:20:32,920
And this really gets into the expert augmentation space, which is a key tenet of how we approach

273
00:20:32,920 --> 00:20:38,320
building these systems at KPMG for, say, our auditors, right?

274
00:20:38,320 --> 00:20:45,840
You want to be able to take your expertise, try to be able to go out and discover as much

275
00:20:45,840 --> 00:20:51,320
information as you can, but then also allow the human to come back and make conclusions

276
00:20:51,320 --> 00:20:52,320
on that.

277
00:20:52,320 --> 00:20:56,480
And hopefully through the process of, there would be an iterative process where you would

278
00:20:56,480 --> 00:21:00,600
be training, say, this assistant, you know, we try to make it out so that it would be

279
00:21:00,600 --> 00:21:03,120
more like an intern at first, right?

280
00:21:03,120 --> 00:21:05,640
So what could you expect of your intern?

281
00:21:05,640 --> 00:21:10,520
We try to get our systems to a level where on day one, they'd be kind of like an intern,

282
00:21:10,520 --> 00:21:11,520
right?

283
00:21:11,520 --> 00:21:15,200
But hopefully through the process, we would improve it to the point where they could become

284
00:21:15,200 --> 00:21:17,160
relied on more and more.

285
00:21:17,160 --> 00:21:19,000
And that's really what you want to get to.

286
00:21:19,000 --> 00:21:20,880
I love that idea.

287
00:21:20,880 --> 00:21:28,400
So what are some of the, some of the technology pieces upon which you built this.

288
00:21:28,400 --> 00:21:33,360
You mentioned Watson earlier and working with some of the first Watson technologies for

289
00:21:33,360 --> 00:21:37,160
healthcare are using Watson in here as well.

290
00:21:37,160 --> 00:21:43,400
So we had originally done, so I had previously done work with Watson.

291
00:21:43,400 --> 00:21:48,760
And now when it was a lot of the work that we're doing at KPMG, some of it goes with IBM

292
00:21:48,760 --> 00:21:51,280
products and various things in Watson.

293
00:21:51,280 --> 00:21:57,920
Now this particular one, we originally, the original prototype was with Watson company

294
00:21:57,920 --> 00:22:04,360
Analyzer, which was, they had bought Alchemy News, which was a news service and they were

295
00:22:04,360 --> 00:22:08,640
able, they were essentially doing this, they had a knowledge graph, Alchemy News had a

296
00:22:08,640 --> 00:22:13,280
knowledge graph of news articles for the news, and they were able to deliver content

297
00:22:13,280 --> 00:22:15,240
in a specific way.

298
00:22:15,240 --> 00:22:21,640
And what we wanted to do is we, you know, their knowledge graph wasn't quite as extensive

299
00:22:21,640 --> 00:22:25,760
for financial services or for the information we had, right?

300
00:22:25,760 --> 00:22:31,280
So it was definitely good because it allowed you to have a general view of news, which is

301
00:22:31,280 --> 00:22:33,000
something KPMG can't have.

302
00:22:33,000 --> 00:22:37,960
We don't have that kind of taxonomy, but we definitely have much more specificity when

303
00:22:37,960 --> 00:22:41,840
it comes to client issues with financial services.

304
00:22:41,840 --> 00:22:47,000
And it turned out that being able to map those two across was not working out very well.

305
00:22:47,000 --> 00:22:55,080
So what we ended up doing was we ended up bringing it in-house and we built, we've played

306
00:22:55,080 --> 00:22:59,160
with Watson Discovery services and using that here.

307
00:22:59,160 --> 00:23:05,960
We use Watson Knowledge Studio for Entity Extraction and the actual knowledge graph and the

308
00:23:05,960 --> 00:23:10,880
reasoning components actually aren't Watson components right now, but that was mostly

309
00:23:10,880 --> 00:23:18,160
because of just the difficulty and, you know, making sure that IP, RIP state, R's and

310
00:23:18,160 --> 00:23:21,520
their IP state there's, so it was more of that kind of a concern.

311
00:23:21,520 --> 00:23:26,040
Oh, it makes sense. And so what is the Watson Discovery service and what's the role

312
00:23:26,040 --> 00:23:28,120
that that piece plays for you?

313
00:23:28,120 --> 00:23:35,640
So Watson Discovery service is where IBM has put a lot of their search works recently.

314
00:23:35,640 --> 00:23:41,960
So they used to have something called Retrieven Rank and they've built out Watson Discovery

315
00:23:41,960 --> 00:23:47,000
service to be kind of a much stronger search engine.

316
00:23:47,000 --> 00:23:51,720
And the advantage is that you can use Watson Knowledge Studio.

317
00:23:51,720 --> 00:23:56,160
So Entity Recognition, you kind of can train your own Entity Recognizers.

318
00:23:56,160 --> 00:24:00,680
You can do a search over, you know, it allows you to index.

319
00:24:00,680 --> 00:24:07,480
It allows you to create a ranking engine over what's searched and it allows you to build

320
00:24:07,480 --> 00:24:08,480
out queries.

321
00:24:08,480 --> 00:24:13,680
It's kind of like a big search interface, but they also call it the Discovery service

322
00:24:13,680 --> 00:24:15,520
because they've also expanded that.

323
00:24:15,520 --> 00:24:19,560
So that now you can kind of, there's also an interactive quality.

324
00:24:19,560 --> 00:24:23,960
So it's not just the delivery of a search engine, but there's also an interactive quality

325
00:24:23,960 --> 00:24:28,320
in terms of you're being able to look through your data and find insights from it.

326
00:24:28,320 --> 00:24:31,280
So they've combined a few services through it.

327
00:24:31,280 --> 00:24:37,240
And so how does the Knowledge Studio interact with the Discovery service?

328
00:24:37,240 --> 00:24:42,120
What you can do with Knowledge Studio is, Knowledge Studio allows you to build out Entity

329
00:24:42,120 --> 00:24:45,240
Recognition, essentially, or Entity Extraction models.

330
00:24:45,240 --> 00:24:50,640
One of the first use cases or examples I think of when I hear that is like a chat bot

331
00:24:50,640 --> 00:24:57,920
where you're trying to identify like intense or, you know, entities that you're, that

332
00:24:57,920 --> 00:25:02,120
someone is asking about via a chat conversation.

333
00:25:02,120 --> 00:25:07,160
Is it also, in this case, is it used in that context or like in a search context where

334
00:25:07,160 --> 00:25:09,520
you're refining search results based on entities?

335
00:25:09,520 --> 00:25:13,960
So what you can do is you can actually use those entities to index what you're searching

336
00:25:13,960 --> 00:25:18,720
over so that you could, just like in a, in a chat bot, you would sit there and you'd

337
00:25:18,720 --> 00:25:24,120
say, you know, you want to mark out the, the fact that, you know, somebody wants to fly

338
00:25:24,120 --> 00:25:28,360
to Calgary, say Calgary would be where they're flying to, right?

339
00:25:28,360 --> 00:25:32,560
So what's a Knowledge Studio would be able to tell you that that would be like the location.

340
00:25:32,560 --> 00:25:36,760
To similarly, you could mark up, say, all of the search pages that you're searching

341
00:25:36,760 --> 00:25:37,760
over, right?

342
00:25:37,760 --> 00:25:41,320
So all of the content you're trying to search through, and what's a Knowledge Studio

343
00:25:41,320 --> 00:25:45,400
could go through and say, oh, well, you know, every time you seek Calgary, that's actually

344
00:25:45,400 --> 00:25:48,600
a location that someone could fly to or something like that.

345
00:25:48,600 --> 00:25:54,760
So it's, it's basically the same thing and it allows you to augment your search appropriately

346
00:25:54,760 --> 00:25:58,600
with, with concepts that, you know, you can train on yourself.

347
00:25:58,600 --> 00:26:06,080
So for example, for us, you know, a specific individual could be a corporation and you

348
00:26:06,080 --> 00:26:11,400
might be able to find that from just any named entity recognizer, but for our purposes,

349
00:26:11,400 --> 00:26:15,000
we really could think of that person as a borrower, as a borrower.

350
00:26:15,000 --> 00:26:20,320
So that's like a borrower in a loan agreement, say, and we would want to capture that information.

351
00:26:20,320 --> 00:26:22,800
That's what Watson Knowledge Studio would allow you to do.

352
00:26:22,800 --> 00:26:24,680
It would take that information, say, you know what?

353
00:26:24,680 --> 00:26:30,680
This is the borrower and this is the guarantor name in this, in this loan agreement.

354
00:26:30,680 --> 00:26:34,720
Watson Knowledge Studio allows you to, to find that information and to train models that

355
00:26:34,720 --> 00:26:39,960
can, that can help you find the information for the concepts that you're interested in.

356
00:26:39,960 --> 00:26:42,920
And then from that, you can build out our Knowledge Graph, of course.

357
00:26:42,920 --> 00:26:43,920
Okay, interesting.

358
00:26:43,920 --> 00:26:49,520
And so presumably with this example you gave of the, the borrower and the creditor, it's

359
00:26:49,520 --> 00:26:52,040
not like a place, you know, versus a company name.

360
00:26:52,040 --> 00:26:57,520
They're both company names and so presumably it's able to figure out the specific entity

361
00:26:57,520 --> 00:26:59,240
types based on context.

362
00:26:59,240 --> 00:27:00,320
Yeah, exactly.

363
00:27:00,320 --> 00:27:07,640
So essentially in the back end, it has, it uses features of, you know, different types

364
00:27:07,640 --> 00:27:09,760
of, of sentence based features.

365
00:27:09,760 --> 00:27:15,000
So I assume they have ngrams of some kind and other things that allows them to differentiate

366
00:27:15,000 --> 00:27:16,000
that.

367
00:27:16,000 --> 00:27:20,920
And then in terms of how you train it, right, it's all about you, you annotate yourself

368
00:27:20,920 --> 00:27:24,280
and you, you train it based on lots of information.

369
00:27:24,280 --> 00:27:30,400
And so if you provide it with the appropriate types of information that can differentiate

370
00:27:30,400 --> 00:27:36,480
those two, you should be able to arrive at a model for borrower and a model for guarantee.

371
00:27:36,480 --> 00:27:44,880
Do you have a sense for the number of training examples that are required kind of per entity

372
00:27:44,880 --> 00:27:49,400
in order to get a reasonable level of accuracy?

373
00:27:49,400 --> 00:27:52,680
So yeah, generally what they recommend IBM.

374
00:27:52,680 --> 00:27:58,560
So to be clear, I've never worked with IBM for IBM, but I have worked with their products.

375
00:27:58,560 --> 00:28:03,760
Generally, it's going to be about 50 positive examples that you want to provide.

376
00:28:03,760 --> 00:28:08,520
And for each entity and a positive example, of course, means that it's actually there.

377
00:28:08,520 --> 00:28:14,080
So you can't just like provide 50 documents and sometimes the guarantee name is there and

378
00:28:14,080 --> 00:28:15,360
sometimes it isn't, right?

379
00:28:15,360 --> 00:28:19,240
So you want to have at least 50 examples.

380
00:28:19,240 --> 00:28:27,600
In practice, we actually, it really does depend on a lot of variables in terms of where

381
00:28:27,600 --> 00:28:33,640
that entity shows up and what you're trying to differentiate it from in order to determine

382
00:28:33,640 --> 00:28:40,200
what the appropriate number are, but I would be hesitant to even rely on results if

383
00:28:40,200 --> 00:28:43,280
you don't have at least 50 positive examples.

384
00:28:43,280 --> 00:28:46,080
We usually go for about 200 to start.

385
00:28:46,080 --> 00:28:47,880
I imagine it's per entity.

386
00:28:47,880 --> 00:28:49,840
Yeah, per entity, exactly.

387
00:28:49,840 --> 00:28:50,840
So you're right.

388
00:28:50,840 --> 00:28:55,720
You could have a document where you're trying to get 10 things out.

389
00:28:55,720 --> 00:28:57,160
You can't just go for 50 of those.

390
00:28:57,160 --> 00:28:58,160
You might have to end up.

391
00:28:58,160 --> 00:29:02,400
That's why I say we usually end up with about 200 documents, and hopefully through there

392
00:29:02,400 --> 00:29:07,440
we can find at least 50 positive examples for each of the things we're trying to pull.

393
00:29:07,440 --> 00:29:10,240
You have the entity recognition system.

394
00:29:10,240 --> 00:29:15,600
You've got the discovery service, which is kind of a search engine that can take advantage

395
00:29:15,600 --> 00:29:17,760
of these entities.

396
00:29:17,760 --> 00:29:21,720
We've experimented with what's in discovery service, but I don't think actually right

397
00:29:21,720 --> 00:29:27,560
now we have that in play, but that's one possible way that you could actually build out this

398
00:29:27,560 --> 00:29:28,880
kind of thing.

399
00:29:28,880 --> 00:29:35,400
Essentially, what we've built out is it's a typical recommendation engine, but we also

400
00:29:35,400 --> 00:29:42,480
have a graph-based database for the, that represents the knowledge graph.

401
00:29:42,480 --> 00:29:51,360
We essentially pull in, we pull in specific articles, we rank them, and we rank them according

402
00:29:51,360 --> 00:29:53,840
to what the recommendation is for the service.

403
00:29:53,840 --> 00:30:00,440
So for example, it's not, we want to recommend a specific service that KPMG offers for a client.

404
00:30:00,440 --> 00:30:06,320
And then once we've made that recommendation, we show as evidence, news articles, or say

405
00:30:06,320 --> 00:30:12,360
history of engagements, other engagements that are similar, a variety of other factors

406
00:30:12,360 --> 00:30:15,840
that may come into play to determine that recommendation.

407
00:30:15,840 --> 00:30:21,160
So as you can see here, the knowledge graph is not in and of itself what we're delivering

408
00:30:21,160 --> 00:30:29,880
is more of a way for us to rank appropriately the evidence for us to recommend a service

409
00:30:29,880 --> 00:30:31,560
for a client.

410
00:30:31,560 --> 00:30:36,040
Where do the, where do the news feeds come from?

411
00:30:36,040 --> 00:30:43,200
So we have, we use the news feeds that are most important for KPMG, but you can imagine

412
00:30:43,200 --> 00:30:48,760
they're, they're very similar to what you would normally expect, but it's not going to

413
00:30:48,760 --> 00:30:53,160
be like tech news feeds, it's going to be more business oriented news feeds.

414
00:30:53,160 --> 00:30:54,160
Right.

415
00:30:54,160 --> 00:30:58,920
So maybe like a Thompson Reuters or something like that, that is like a third party feed

416
00:30:58,920 --> 00:31:00,600
that you're pulling in.

417
00:31:00,600 --> 00:31:01,600
Exactly.

418
00:31:01,600 --> 00:31:02,600
Something like that.

419
00:31:02,600 --> 00:31:06,960
I've talked a little bit about in the ideal world you've got.

420
00:31:06,960 --> 00:31:13,200
This is able to learn over time from the interactions with the actual users.

421
00:31:13,200 --> 00:31:15,560
Have you implemented that part of it yet?

422
00:31:15,560 --> 00:31:22,680
So we actually just went live across 700 accounts just about a month ago.

423
00:31:22,680 --> 00:31:29,200
So we, we're still very much new in terms of the improvement strategy, but we have piloted

424
00:31:29,200 --> 00:31:30,440
that.

425
00:31:30,440 --> 00:31:35,800
And now it's a question of how much, you know, what, what it really comes down to is you,

426
00:31:35,800 --> 00:31:41,440
we're not just going to accept, for example, any feedback as some, as a corrective measure

427
00:31:41,440 --> 00:31:43,640
for our recommendation engine.

428
00:31:43,640 --> 00:31:47,720
So it's really going to be a process where the technologists and the data scientists

429
00:31:47,720 --> 00:31:53,000
work hand in hand with the, with our best experts to determine, you know, based on the

430
00:31:53,000 --> 00:31:57,400
use and the patterns that we're seeing, what are the things that will allow us to best

431
00:31:57,400 --> 00:32:04,720
optimize and improve the system without, for example, going too far down edge cases or,

432
00:32:04,720 --> 00:32:10,400
you know, being, you know, really looking at the data, but having an expert side over

433
00:32:10,400 --> 00:32:11,400
it.

434
00:32:11,400 --> 00:32:14,200
That's really going to be a key part of the improvement strategy.

435
00:32:14,200 --> 00:32:21,200
You mentioned the entity recognition piece, and I recently did some work with actually

436
00:32:21,200 --> 00:32:28,320
a group of accounting firms talking to them about AI and its implications in that space.

437
00:32:28,320 --> 00:32:35,560
And one of the use cases that came up quite a bit, and KPMG has been very active in this

438
00:32:35,560 --> 00:32:44,120
area as well, has been using natural language processing for document and contract review.

439
00:32:44,120 --> 00:32:52,320
And in particular, lease review and lease abstraction, there's been some recent regulatory

440
00:32:52,320 --> 00:32:58,640
changes that go into effect the beginning of next year, I believe, that change the way

441
00:32:58,640 --> 00:33:08,080
leases are accounting for and many of the firms have jumped on AI as a way to automate

442
00:33:08,080 --> 00:33:14,320
the review of, you know, in some cases, tens of thousands or hundreds of thousands of leases

443
00:33:14,320 --> 00:33:22,280
to figure out what those, the terms of those leases are, and this concept of entity recognition

444
00:33:22,280 --> 00:33:24,680
plays pretty heavily in that whole use case.

445
00:33:24,680 --> 00:33:28,080
Have you been involved in any of the work on that type of application?

446
00:33:28,080 --> 00:33:29,080
Absolutely.

447
00:33:29,080 --> 00:33:30,160
Yeah, you're absolutely right.

448
00:33:30,160 --> 00:33:36,920
So the changes in IFRS 16 are what are causing all of everybody to kind of go around

449
00:33:36,920 --> 00:33:39,520
in a panic here about this.

450
00:33:39,520 --> 00:33:43,640
Yeah, so this, you're right.

451
00:33:43,640 --> 00:33:49,440
So I think at the end, what everybody would love to see is an automatic way of finding

452
00:33:49,440 --> 00:33:54,400
this information and a contract pulling it out appropriately and then determining based

453
00:33:54,400 --> 00:33:58,880
on it what the appropriate treatment is.

454
00:33:58,880 --> 00:34:01,320
And KPMG has a few different options.

455
00:34:01,320 --> 00:34:07,520
So one thing is we have the KPMG leasing tool, which is really once, you know, you have

456
00:34:07,520 --> 00:34:12,480
the, the terms and all of the, and all of the options and all of this information out

457
00:34:12,480 --> 00:34:16,120
of the lease, it's able to tell you what the appropriate treatment is.

458
00:34:16,120 --> 00:34:21,520
But one of the difficulties is that it's actually a manual process to go from the contract

459
00:34:21,520 --> 00:34:26,320
itself, the language in the contract, into an understanding of that contract to the

460
00:34:26,320 --> 00:34:31,760
point where you could actually say extract entities or facts from it in a way that would

461
00:34:31,760 --> 00:34:38,840
make the meaningful input into the KPMG leasing tool or any other, let's call it calculator

462
00:34:38,840 --> 00:34:42,600
of what the appropriate treatment would be for the leases.

463
00:34:42,600 --> 00:34:51,480
So this lease abstraction or we call it extraction work is something that my group has been

464
00:34:51,480 --> 00:34:52,480
involved in.

465
00:34:52,480 --> 00:34:58,080
There's a variety of groups who are involved in it across the firm with a variety of different

466
00:34:58,080 --> 00:34:59,280
ways of doing it.

467
00:34:59,280 --> 00:35:06,640
So we have people who are going after this from a very specific, you know, delivery model

468
00:35:06,640 --> 00:35:12,560
where, you know, you have 10,000 leases and you want this particular, you know, just

469
00:35:12,560 --> 00:35:18,520
a few entities abstracted from them, then we'll be able to deliver something that gives

470
00:35:18,520 --> 00:35:20,800
you like a spreadsheet of all of that.

471
00:35:20,800 --> 00:35:26,920
Now the work that I've been working on has been more, I'd say, more at the managed service

472
00:35:26,920 --> 00:35:33,000
or more at the expert augmentation level where I haven't just been focused on lease contracts.

473
00:35:33,000 --> 00:35:39,440
I've been working for the past few years on trying to build out a contract reading tool

474
00:35:39,440 --> 00:35:42,920
more generally for auditors.

475
00:35:42,920 --> 00:35:49,400
Where the idea is that I'm coming from the perspective that the facts that have to be extracted

476
00:35:49,400 --> 00:35:52,880
actually require a significant amount of human interpretation.

477
00:35:52,880 --> 00:35:59,280
Like so, usually with extraction, you have, let's say an entity and it's fairly easy to

478
00:35:59,280 --> 00:36:04,080
take, pull that string out of the text and then it's even better if that's the exact

479
00:36:04,080 --> 00:36:09,400
string that you would want to use further down the process, like whether, you know, input

480
00:36:09,400 --> 00:36:14,160
it into an Excel or put it into a calculation, but generally there's some level of human

481
00:36:14,160 --> 00:36:20,760
interpretation in terms of taking the that, say, entity and applying a calculation or

482
00:36:20,760 --> 00:36:25,560
resolving it in some way so that it's meaningful later on.

483
00:36:25,560 --> 00:36:31,560
My feeling especially when you look across the space of contracts is that, you know, maybe

484
00:36:31,560 --> 00:36:39,120
about 20 to 30 of these entities and leases are fairly easy to extract, but just based

485
00:36:39,120 --> 00:36:46,040
on the, you know, the differences in language around real estate leases versus equipment

486
00:36:46,040 --> 00:36:52,080
leases, for example, it's very difficult to build models once you get beyond those

487
00:36:52,080 --> 00:36:53,080
20 and 30.

488
00:36:53,080 --> 00:36:58,080
And a lot of times you do have to go beyond that to build up the calculations appropriately.

489
00:36:58,080 --> 00:37:03,560
So we build out expert augmentation systems for auditors where it helps them find the information

490
00:37:03,560 --> 00:37:04,880
in the original document.

491
00:37:04,880 --> 00:37:09,280
When we're able to find it, we take them there when we're able to, when we can't find

492
00:37:09,280 --> 00:37:14,200
the exact information, we try to take them to where in the text we think it is.

493
00:37:14,200 --> 00:37:19,120
And even better when it's something that requires several pieces of text that need to be resolved,

494
00:37:19,120 --> 00:37:23,240
we try to bring them to all of that text so that they can resolve it more appropriately.

495
00:37:23,240 --> 00:37:27,280
So we don't kind of, we really keep our knowledge workers in the system.

496
00:37:27,280 --> 00:37:32,480
This is very much expert augmentation for a managed service, which means a human's always

497
00:37:32,480 --> 00:37:35,320
going to be the person who's the ultimate arbiter.

498
00:37:35,320 --> 00:37:41,000
We're not really looking for automatic extraction, but there are other parts of the organization

499
00:37:41,000 --> 00:37:45,440
that are using very different techniques in order to be able to do that as well.

500
00:37:45,440 --> 00:37:53,120
Can you give us a specific example of where you need this expert's perspective to fully

501
00:37:53,120 --> 00:37:54,960
resolve an entity?

502
00:37:54,960 --> 00:37:59,440
Yeah, I think a lot of it comes down to.

503
00:37:59,440 --> 00:38:07,400
So sometimes you have to determine, for example, what is the, I'm thinking of service contracts,

504
00:38:07,400 --> 00:38:11,600
but there are other contracts where you have specific terms and you have to think about

505
00:38:11,600 --> 00:38:13,280
the frequency of something.

506
00:38:13,280 --> 00:38:18,760
A lot of times the way to determine the frequency usually involves a few different areas where

507
00:38:18,760 --> 00:38:23,160
they'll, they'll name a frequency, a specific frequency, but then later on they'll say, except

508
00:38:23,160 --> 00:38:27,600
in the case where you have this in which case it goes to this other type of frequency.

509
00:38:27,600 --> 00:38:32,840
Well, this is exactly the kind of thing where when you look at what the input these calculators

510
00:38:32,840 --> 00:38:35,440
are, it's going to be something like monthly.

511
00:38:35,440 --> 00:38:41,520
When you look at the text, it requires a significant amount of human interpretation to get

512
00:38:41,520 --> 00:38:47,320
from say three paragraphs to be able to determine that it's actually monthly for this

513
00:38:47,320 --> 00:38:49,360
specific period.

514
00:38:49,360 --> 00:38:53,000
This is the kind of thing that I'm thinking of as being somewhat difficult.

515
00:38:53,000 --> 00:38:58,600
Now, you could argue that these might be edge cases and it could be when it comes to

516
00:38:58,600 --> 00:39:01,120
the IFRS 16 changes, right?

517
00:39:01,120 --> 00:39:07,400
So I'm thinking about this from the perspective of auditors who have to go through a lease

518
00:39:07,400 --> 00:39:13,640
and find all of the information very, you know, very specifically they can't miss information.

519
00:39:13,640 --> 00:39:14,640
Right?

520
00:39:14,640 --> 00:39:18,880
It's a different perspective if you're looking at this from the advisory case where it's

521
00:39:18,880 --> 00:39:25,160
kind of like, I got 10,000 things to go through like just find me, you know, the top 10 and

522
00:39:25,160 --> 00:39:27,680
then I'll figure out what to do with the rest.

523
00:39:27,680 --> 00:39:30,520
Just I need to, you know, I need to do this quickly.

524
00:39:30,520 --> 00:39:37,160
So it's a different use case, but I come at it from the perspective of the auditor and

525
00:39:37,160 --> 00:39:43,840
helping them not miss information rather than just trying to get the information as quickly

526
00:39:43,840 --> 00:39:44,840
as possible.

527
00:39:44,840 --> 00:39:53,720
It's an interesting idea, a lot of the lease extraction or contract extraction products,

528
00:39:53,720 --> 00:40:00,480
projects that I've seen are kind of pulling out this simple, you know, some simple entity

529
00:40:00,480 --> 00:40:09,160
or trying to do simple calculations to resolve, call it first degree abstract entities

530
00:40:09,160 --> 00:40:15,360
like, you know, the contract duration is a year, you know, and you've got the date that

531
00:40:15,360 --> 00:40:20,440
the contract is signed, you can figure out the end date of the contract, for example.

532
00:40:20,440 --> 00:40:28,640
But it does strike me that I definitely can see how in some scenarios what you really need

533
00:40:28,640 --> 00:40:36,080
is to pull out the rules themselves because that's what the person who's going to end up

534
00:40:36,080 --> 00:40:41,680
reviewing this, you know, needs to be able to think about are the, you know, the different,

535
00:40:41,680 --> 00:40:44,200
you know, scenarios.

536
00:40:44,200 --> 00:40:49,880
And even the representation of that, like, how do you stick a rule into an excels, you

537
00:40:49,880 --> 00:40:50,880
know.

538
00:40:50,880 --> 00:40:51,880
Exactly.

539
00:40:51,880 --> 00:40:52,880
Exactly.

540
00:40:52,880 --> 00:40:56,920
And when you look at some of the excels sell spreadsheets that are being input into these

541
00:40:56,920 --> 00:41:01,400
tools, I mean, it's really ridiculous how they try to break this apart because you

542
00:41:01,400 --> 00:41:07,560
can see the kind of contortions they had to go through in order to build this out appropriately

543
00:41:07,560 --> 00:41:12,840
to get all of the information they need to apply the appropriate treatment, the calculation

544
00:41:12,840 --> 00:41:16,640
that determines the appropriate treatment and the fact that there's a lot of complexity

545
00:41:16,640 --> 00:41:17,640
there.

546
00:41:17,640 --> 00:41:18,800
I think that it's important.

547
00:41:18,800 --> 00:41:22,560
And I should say, for the easier entities, we're doing the same thing as everyone else.

548
00:41:22,560 --> 00:41:26,720
We're using entity extraction and we're doing fairly well with it.

549
00:41:26,720 --> 00:41:33,640
But the difference is that we're, we want to be able to provide a tool or tooling that

550
00:41:33,640 --> 00:41:40,440
allows our auditors to read any type of contract and find the appropriate information.

551
00:41:40,440 --> 00:41:43,840
And I think that's a slightly different take on it.

552
00:41:43,840 --> 00:41:51,040
But, but yeah, believe me, everyone in KPMG, well, a lot of people in KPMG are very much

553
00:41:51,040 --> 00:41:54,240
interested in what the appropriate way to do this is.

554
00:41:54,240 --> 00:42:00,000
And I think it really does make sense for KPMG to have a variety of business models depending

555
00:42:00,000 --> 00:42:02,000
on what the client needs.

556
00:42:02,000 --> 00:42:03,000
Absolutely.

557
00:42:03,000 --> 00:42:05,480
And as you will know, not just KPMG.

558
00:42:05,480 --> 00:42:06,480
Right.

559
00:42:06,480 --> 00:42:08,480
Very, very fast.

560
00:42:08,480 --> 00:42:09,480
Interesting.

561
00:42:09,480 --> 00:42:16,720
So I'm curious as we maybe start to wrap up, like, you know, a lot of what you are focused

562
00:42:16,720 --> 00:42:24,720
on here is this idea of expert augmentation or augmented intelligence, you know, have

563
00:42:24,720 --> 00:42:34,080
you want to describe it, are there some general principles that you've taken away from the

564
00:42:34,080 --> 00:42:41,840
various places that you've worked to use AI to, to augment experts?

565
00:42:41,840 --> 00:42:42,840
Yeah.

566
00:42:42,840 --> 00:42:48,160
I think so. I mean, I know that there are some tenets that I really feel strongly about

567
00:42:48,160 --> 00:42:54,040
in the systems that I design and that I try to push for.

568
00:42:54,040 --> 00:42:58,720
One of them, I mean, it comes back to what we had discussed early in the conversation.

569
00:42:58,720 --> 00:43:06,000
It really is about the appropriate way to codify knowledge and expertise and finding the

570
00:43:06,000 --> 00:43:08,240
best way you can do that.

571
00:43:08,240 --> 00:43:14,240
And I think at KPMG, what we've learned is that we try to employ various techniques, but

572
00:43:14,240 --> 00:43:18,800
we really want to make sure that we use the best possible technique for posterity.

573
00:43:18,800 --> 00:43:25,440
So we do use ontologies and we try to encode our information in ontologies as much as we

574
00:43:25,440 --> 00:43:26,440
can.

575
00:43:26,440 --> 00:43:31,440
But at the same time, we try to extract away from those or simplify those when it's needed

576
00:43:31,440 --> 00:43:34,080
for a very specific technical implementation.

577
00:43:34,080 --> 00:43:39,520
So we understand the limitations of both and we try to be able to use them appropriately

578
00:43:39,520 --> 00:43:42,280
in the right context.

579
00:43:42,280 --> 00:43:50,040
The other thing that I think is really important is I'm very interested in the type of human

580
00:43:50,040 --> 00:43:54,800
that we are augmenting and the role that this augmentation has.

581
00:43:54,800 --> 00:43:59,520
So I think that it's very different building out systems for efficiencies versus building

582
00:43:59,520 --> 00:44:01,600
out systems for quality.

583
00:44:01,600 --> 00:44:07,600
And I personally have always kind of been intrigued by expert augmentation for quality.

584
00:44:07,600 --> 00:44:12,240
So like I said, this might come back to the fact that I was working on Watson for health

585
00:44:12,240 --> 00:44:13,480
care originally.

586
00:44:13,480 --> 00:44:16,040
And that's one of the driving questions, right?

587
00:44:16,040 --> 00:44:21,600
You don't necessarily, you want to make a doctor's life easier, but so that you can

588
00:44:21,600 --> 00:44:27,320
increase the quality of what they're able to provide.

589
00:44:27,320 --> 00:44:32,920
And so it's very similar for me, I really think about the fact that our end result, for

590
00:44:32,920 --> 00:44:36,600
example, when we're looking at audit, is not to miss information.

591
00:44:36,600 --> 00:44:43,000
We, you know, that is the biggest risk for audit is we have to be able to say we've looked

592
00:44:43,000 --> 00:44:47,280
at all the information we're able to deliver the appropriate opinion based on it.

593
00:44:47,280 --> 00:44:52,080
And I find that is a very intriguing way to build out these systems.

594
00:44:52,080 --> 00:44:55,800
And I really want to make sure that the knowledge workers are in that system and are being

595
00:44:55,800 --> 00:44:58,400
there to train the system appropriately.

596
00:44:58,400 --> 00:45:03,960
So I've been, I talk a lot about machine teaching versus machine learning and this whole idea

597
00:45:03,960 --> 00:45:08,720
of having the system as kind of an intern at first for our engagement teams.

598
00:45:08,720 --> 00:45:12,840
This is the kind of thing that I think will help us build out the next generation of

599
00:45:12,840 --> 00:45:13,840
systems.

600
00:45:13,840 --> 00:45:16,600
Because in the end, there are, there are a few of these experts.

601
00:45:16,600 --> 00:45:21,080
You know, I'm not, I'm not working with like say in the consumer space where we have

602
00:45:21,080 --> 00:45:25,760
millions of users, you know, in the end, there might be only a handful of experts

603
00:45:25,760 --> 00:45:29,600
in the world with this particular who understand this.

604
00:45:29,600 --> 00:45:31,920
And so how do we encode that information?

605
00:45:31,920 --> 00:45:36,480
How do we capture the decisions they're making and how do we, and how do we make their

606
00:45:36,480 --> 00:45:41,000
lives easier so that they can, in the end, deliver higher quality decisions?

607
00:45:41,000 --> 00:45:42,480
Yeah, really interesting.

608
00:45:42,480 --> 00:45:46,720
I can, you know, I can continue to talk about this forever.

609
00:45:46,720 --> 00:45:53,080
Like I said, a lot of it, I can relate to very personally and, you know, one of the things

610
00:45:53,080 --> 00:45:59,200
I'm most, yeah, I tell people all the time, like I think the exciting thing about AI is

611
00:45:59,200 --> 00:46:02,200
its ability to give people superpowers.

612
00:46:02,200 --> 00:46:09,280
And it's particularly the case for, you know, or at least I think about it most frequently,

613
00:46:09,280 --> 00:46:15,480
you know, for folks like me that are trying to manage these torrents of information.

614
00:46:15,480 --> 00:46:25,280
And AI is a really powerful, you know, set of tools to help us do that.

615
00:46:25,280 --> 00:46:31,600
In fact, there's so many different ways that AI can be used to, you know, augment, you

616
00:46:31,600 --> 00:46:36,480
know, expert workers or knowledge workers.

617
00:46:36,480 --> 00:46:40,800
And so it's really interesting to learn a bit about the different ways that you're enabling

618
00:46:40,800 --> 00:46:41,800
that.

619
00:46:41,800 --> 00:46:42,800
Well, thank you.

620
00:46:42,800 --> 00:46:48,760
It's a pleasure talking to you as well, and it's exciting to hear that there's interest

621
00:46:48,760 --> 00:46:52,280
in this little corner of the world that I'm excited about it.

622
00:46:52,280 --> 00:46:53,280
Absolutely.

623
00:46:53,280 --> 00:46:54,880
Thanks so much, Marisa.

624
00:46:54,880 --> 00:46:56,120
Thank you, Sam.

625
00:46:56,120 --> 00:47:02,080
All right, everyone, that's our show for today.

626
00:47:02,080 --> 00:47:07,560
For more information on Marisa or any of the topics covered in this episode, head on over

627
00:47:07,560 --> 00:47:12,480
to twimolei.com slash talk slash 204.

628
00:47:12,480 --> 00:47:17,040
If you're a fan of the show and you haven't already done so or you're a new listener

629
00:47:17,040 --> 00:47:22,200
and you like what you hear, please head over to your Apple or Google podcast app and leave

630
00:47:22,200 --> 00:47:24,920
us a five-star rating and review.

631
00:47:24,920 --> 00:47:30,240
Your reviews help inspire us to create more and better content and they help new listeners

632
00:47:30,240 --> 00:47:32,040
find the show.

633
00:47:32,040 --> 00:47:36,240
As always, thanks so much for listening and catch you next time.

