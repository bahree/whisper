WEBVTT

00:00.000 --> 00:12.800
All right, everyone. I've got Burr settles here. Burr is research director at Duolingo. Burr,

00:12.800 --> 00:20.080
welcome to the Twomo AI podcast. Thanks for having me, Sam. I am super excited to have an

00:20.080 --> 00:29.200
opportunity to chat with you. I am a bit of an avowed lingua file myself and a user of the Duolingo

00:29.200 --> 00:34.400
app, but it has been a while. I don't know what my points are, my XP's are at this point.

00:35.680 --> 00:42.800
But super excited to chat with you about some of the ways that Duolingo uses AI to deliver the

00:42.800 --> 00:48.000
app. Before we get into that, I'd love to hear a little bit about your personal journey,

00:48.960 --> 00:55.600
how you came to work on machine learning and AI and in language education in particular.

00:55.600 --> 01:04.400
Yeah, it's not a straightforward path, as one might imagine. So my introduction, well, I've always

01:04.400 --> 01:11.360
loved languages. My aunt was bilingual in English and French and worked as a translator. So she

01:11.360 --> 01:18.720
started me on French when I was pretty young. I've always enjoyed languages, never really thought

01:18.720 --> 01:23.840
to study it and certainly knew nothing about natural language processing when I was growing up.

01:23.840 --> 01:28.640
I went to a small liberal arts school where I double majored planned to double major in art,

01:28.640 --> 01:36.400
studio art and math. But then quickly kind of fell into computer science as kind of a mathematical

01:36.400 --> 01:42.320
art form. And then ended up going to grad school, thinking I was going to go into distributed

01:42.320 --> 01:47.280
computing because I thought that was cool at the time. Again, first year, took a machine learning

01:47.280 --> 01:56.880
course, fell in love with that. And then language still wasn't in the natural language processing

01:56.880 --> 02:01.520
wasn't really in the scope just yet. I finished my master's degree at the University of Wisconsin,

02:02.080 --> 02:07.920
and intended to kind of graduate and go get a job at that point. But then I met a girl,

02:07.920 --> 02:12.080
and she still had a year left in her program. And so I stuck around and started just taking

02:12.080 --> 02:20.720
linguistics and biology classes and then fell into a, I started doing research with a professor

02:20.720 --> 02:27.200
in the biostatistics department using machine learning to do information extraction on biomedical

02:27.200 --> 02:33.440
texts. And so for several years, I worked on that. So biomedical natural language processing

02:33.440 --> 02:41.760
was a pretty big thing in the mid-2000s. And during that process, the kinds of annotations,

02:41.760 --> 02:50.160
you need to train biomedical, you know, data sets for those models. It's extremely expensive,

02:50.160 --> 02:54.880
because you have to find people with PhD level knowledge of molecular biology and enough

02:54.880 --> 03:02.080
kind of linguistic sense to know like what semantic role labeling might look like in this domain.

03:02.800 --> 03:08.800
It was very slow and expensive, which then tipped my interest into active learning,

03:08.800 --> 03:14.960
which is machine learning algorithms that participate in their own training. So they can ask questions.

03:14.960 --> 03:20.320
The typical way this is done is you've got a bunch of unlabeled data as we did it in this case.

03:21.200 --> 03:27.520
You have an oracle in this case, a human expert who's very expensive. So you have them annotate

03:27.520 --> 03:33.680
a little bit of data, and then the model learns from that, and then it can quickly analyze all

03:33.680 --> 03:39.680
of the unlabeled data. And then say, this I'm pretty squared away on this and this. I understand

03:39.680 --> 03:44.160
these things, but here's some things that confuse me. Can you please label these for me? And then that

03:44.160 --> 03:50.240
way you can kind of steepen the learning curve or flatten the learning curve depending on how

03:50.240 --> 03:56.640
you're thinking about it. And so I switched my I did my PhD and that kind of work.

03:56.640 --> 04:03.760
And in general was just kind of interested, like that was where I did kind of the language

04:03.760 --> 04:08.960
and the natural language processing. And this interaction between humans and machines.

04:10.400 --> 04:16.560
This this interplay using figuring out how to best use a human resource and training machine

04:16.560 --> 04:23.120
learning systems was something that interested me a lot. Then I came to Carnegie Mellon as a post

04:23.120 --> 04:32.080
stock for a few years to work on this read the read the web project. And then the opportunity

04:32.080 --> 04:36.960
dolingo was spinning out of Carnegie Mellon as a company about the time I post stock wrapped up,

04:36.960 --> 04:43.600
which is almost eight years ago now. And I suddenly realized I was interested in flipping the

04:44.240 --> 04:48.960
flipping the script on that learning. And instead of figuring out how to best use people to

04:48.960 --> 04:54.080
teach machines. How can we best use machines to teach people. And the fact that it was kind of

04:54.080 --> 05:01.680
this intersection of AI computer science building apps. I've never been a pure academic. Like I've

05:01.680 --> 05:07.360
always wanted to build things that like create technology that you then built something with.

05:08.480 --> 05:13.360
And then language and cognitive science. It was just like the perfect perfect combination.

05:13.360 --> 05:20.640
So I've been here ever since. That's awesome. That's great. Are you also a language hobbyist and

05:20.640 --> 05:25.760
user of the app? Where did you kind of settle in on French and kind of push deep in that direction?

05:25.760 --> 05:31.760
I've I've dabbled in many languages. I've used the app to learn a bit of German and Spanish and

05:31.760 --> 05:38.640
Portuguese. But French is the only one I could probably have any sort of conversation.

05:38.640 --> 05:44.400
Yeah, I'm probably similar. Although my French is a lot rustier than I like it to be.

05:46.240 --> 05:53.200
I picked that up in in college. I picked up Spanish was like my high school, you know, high

05:53.200 --> 05:59.200
high school language. And it tends to be generally rusty. But it kind of comes out when it,

05:59.200 --> 06:07.200
you know, needs to. But I've also I'm a dabbler as well. And my typical pattern is to,

06:07.200 --> 06:16.720
you know, spend anything from a month to three months before a trip. Kind of, you know, cramming

06:16.720 --> 06:23.600
a language essentially. And then, you know, go use that knowledge to enjoy the trip and then kind

06:23.600 --> 06:28.160
of flush the cash immediately afterwards because it's really hard to keep that, you know, to get

06:28.160 --> 06:39.040
it to stick. But I've learned a little bit of Portuguese. Do Brasil from Duolingo, a little bit of

06:39.040 --> 06:48.880
Mandarin. What else on Duolingo? A little bit of Spanish, I think, with Duolingo. I think I'm

06:48.880 --> 06:59.200
missing missing one. I've also tried to teach myself a bit of umhark and a bit of Arabic quite a

06:59.200 --> 07:06.160
while ago. But it's it's always great to kind of chat with someone else to share that interest.

07:07.280 --> 07:12.320
Yeah, well, it's pretty amazing to work at a company where everybody shares that. I mean,

07:12.320 --> 07:17.040
there, I think there's only imagine. I think there are 30 different languages spoken

07:17.040 --> 07:24.400
among the employees here. So and most of them all not most. I think there's about 30 different

07:24.400 --> 07:32.400
languages that we teach too. Not the same overlap, but there are enough people who speak a variety

07:32.400 --> 07:37.920
of languages that within the company we have these language tables, like a German stomatish

07:37.920 --> 07:47.040
or top of the Portuguese and you know, people get together. Well, back when it was possible and kosher

07:47.040 --> 07:52.480
to like physically together. Right. Actually, that's extended. I think the Portuguese table.

07:53.680 --> 08:00.000
There's a line. Yeah, just everybody orders take out from like this Portuguese restaurant

08:00.000 --> 08:10.080
and then like thousand to a zoom room. Oh, very cool. But that's awesome. And so I could geek out on

08:10.960 --> 08:15.440
just the language side of this, but I'm not sure that many of the, you know, I have no idea how

08:15.440 --> 08:21.120
many of the listeners would be interested in that conversation. So maybe let's shift gears a

08:21.120 --> 08:32.480
little bit to talking about some of the ways that Duolingo uses AI. And it may not be a surprise

08:32.480 --> 08:38.000
to folks that know the some of the history of the company and like spinning out of Carnegie Mellon,

08:38.000 --> 08:44.640
but there's a bit of machine learning focus from the very beginning to the way the company

08:44.640 --> 08:52.640
approached, you know, this problem of language learning as well as the broader issue of building

08:52.640 --> 09:01.440
a business around it. Yeah, I mean, I was one of the first folks. And let's see, I think I was

09:01.440 --> 09:07.840
number 20 or so. I joined about about six months after it spun out. Okay. And so I started working

09:07.840 --> 09:16.000
on machine learning things from day one. And I think a lot of people, this is changing, but like

09:16.000 --> 09:21.680
three or four years ago, if I'd go to an LP or machine learning conference, people would be kind

09:21.680 --> 09:26.880
of like, how does, you know, Duolingo, how would that use any machine learning? And it's sort of

09:26.880 --> 09:32.320
like surprised people. It doesn't seem to be a surprise anymore, but the way we think about it is

09:32.320 --> 09:42.800
particularly for language education, but I think any kind of education. The best kind of education

09:42.800 --> 09:48.480
you can get is a one-on-one tutor. Okay. And but the problem with that is very few people have

09:48.480 --> 09:53.040
access to a good one-on-one tutor subject matter expert for whatever they're trying to learn.

09:54.800 --> 10:01.680
And so we believe the best way that you can scale that kind of experience is with AI. So it's not

10:01.680 --> 10:07.680
necessarily to replace good teachers or good tutors, but most people don't have access to them

10:07.680 --> 10:16.240
anyway. So by using AI, we can sort of democratize education, sort of. And then if you take that

10:16.240 --> 10:22.560
sort of approach and you think, okay, well, what do good tutors do? I claim that they've got

10:22.560 --> 10:27.040
three, at least three properties, important properties. One is that they know the content

10:27.040 --> 10:32.720
really well. In this case, the language that they're teaching and how different aspects of the

10:32.720 --> 10:40.400
language align to different kind of proficiency levels. Two is they know how to keep you engaged

10:40.400 --> 10:47.360
and excited with the material. And then three, and maybe most importantly, they have a way of

10:47.360 --> 10:52.240
getting inside your head. So because of this one-on-one time that they have with you, they see what you

10:52.240 --> 10:57.520
get right. They see what you get wrong. They see what you used to be getting wrong and you're

10:57.520 --> 11:02.720
starting to get right. They get it for how quickly you forget things. I mean, a lot of educational

11:02.720 --> 11:09.600
technology is focused on assessment or like a shorter term semester long sort of learning,

11:09.600 --> 11:16.800
not lifelong learning. So forgetting usually is not baked into the models. And so anyway,

11:16.800 --> 11:21.680
going back to those three things, the content, keeping you engaged and getting inside your head,

11:22.400 --> 11:28.320
we've essentially arranged our AI kind of research program here around those three things. So we've

11:28.320 --> 11:34.400
got machine learning projects going on in those three areas, broadly speaking. So we've got

11:34.400 --> 11:41.280
projects to help develop efficiently like high quality content that's aligned to a proficiency

11:41.280 --> 11:48.320
scale and then to keep people engaged and then also to model what people know so that we can

11:48.320 --> 11:56.240
personalize their experiences. And the story that I was thinking of and I wondered the

11:56.240 --> 12:03.440
extent to which it continues. It was from years ago, it was kind of this idea that

12:03.440 --> 12:14.880
Duolingo had this, you know, the company has a whole wanted to make an impact on language learning

12:14.880 --> 12:21.360
and the recognition was that, you know, yeah, there are a bunch of, you know, folks in wealthy

12:21.360 --> 12:26.480
countries that could like spend a bunch of time, you know, hobby learning languages, but the

12:26.480 --> 12:34.560
biggest impact on them from a global perspective was helping people at massive scale learn languages

12:34.560 --> 12:42.160
that would increase their economic position, you know, languages like English. And there was,

12:43.200 --> 12:48.720
I forget the specific technique or approach that was taken, but there were some things that were

12:48.720 --> 12:56.560
that were being done early on using machine learning to like ingest articles and identify,

12:58.240 --> 13:03.360
you know, turn those articles into into lessons. Again, kind of at a scale beyond the way

13:03.360 --> 13:09.840
a handcrafted, you know, Portuguese language track might work for the Duolingo that many of us

13:09.840 --> 13:15.120
hear. No, you know, does that, does anybody of that sound familiar? Am I making that up?

13:15.120 --> 13:20.000
You're not making that up. We've kind of pivoted since then. So the original business model

13:21.120 --> 13:29.760
for Duolingo, the idea was that we can give away a free education. So the app is free and it's

13:29.760 --> 13:34.640
still free. Yeah. You can go through an entire course without ever, you know, paying us anything.

13:36.160 --> 13:44.240
And the idea at the time was that as part of doing the lessons, some of the exercises that you did

13:44.240 --> 13:51.600
were translating documents. And a lot of it was Wikipedia articles. For a while, we actually did

13:51.600 --> 13:58.400
have clients like, I think CNN was one of our clients BuzzFeed would give us articles written

13:58.400 --> 14:04.880
in English that they wanted translated into their Latin American properties. And so we had,

14:04.880 --> 14:09.760
you know, tens or hundreds of thousands of Spanish speakers who were learning English on Duolingo

14:09.760 --> 14:14.880
that as part of their exercises were translating documents kind of crowdsourced to translating

14:14.880 --> 14:21.360
documents from English into Spanish reports of ease, which then we sold back to CNN and BuzzFeed

14:21.360 --> 14:27.440
and then they published on their website. That was like the original, you know, business model

14:27.440 --> 14:33.840
idea. It ended up not really to be sustainable. So we've kind of like shut that down and pivoted

14:33.840 --> 14:44.560
it, pivoted a bit. The primary business model now is twofold. One is in, I'm trying to remember

14:44.560 --> 14:54.160
exactly when 2014, 2015 or so, we launched the Duolingo English test, which is a high stakes

14:54.800 --> 15:01.040
English language proficiency exam. And the sort of test that if you're an international

15:01.040 --> 15:06.400
student wanting to study in the United States, you could take as proof of English proficiency.

15:07.200 --> 15:15.440
But the idea again, keeping with our mission of being as accessible as possible, it was a test

15:15.440 --> 15:21.760
that was much less expensive. It was, it's $49 and you can take it online anytime anywhere

15:22.400 --> 15:29.680
and it's a computer adaptive test. And so the idea there is that the education is free and then

15:29.680 --> 15:38.240
to certify what you've learned, that is a, a small fee. So that's part of the, the business model.

15:38.240 --> 15:43.840
And then another part of the business model is a subscription service that is not a paywall

15:43.840 --> 15:50.240
on the educational content. But it does unlock certain gamified, you know, features.

15:50.240 --> 16:00.240
Not things that, you know, make it easier. I actually am not familiar with all the sets of features

16:00.240 --> 16:05.360
in the offering right now, like there's a progress quiz that you can take to sort of like track

16:05.360 --> 16:11.200
your own learning over time. I remember the big thing, I remember the big thing for me being,

16:11.840 --> 16:17.760
I think if you are a pro subscriber, you can download your lessons.

16:17.760 --> 16:21.280
Right, offline. We're not on a plane and stuff like that.

16:21.280 --> 16:28.720
Or the subway. Yeah, we're on a subway. Maybe not so big a deal now, you know, with people

16:29.680 --> 16:35.360
quarantined at home. But when I was actively using the app, that was the one thing that

16:36.240 --> 16:39.040
I think maybe even made me do pro for a little while.

16:40.080 --> 16:46.160
Yeah, in fact, lockdown has been really great for us. And a lot of, you know, most of

16:46.160 --> 16:54.080
kind of like tech app most, all the metrics that we look at have at least doubled with the

16:54.080 --> 16:59.440
Duolingo English test. That is, that's gone up, I think 2000 per cent or something like that. Wow.

16:59.440 --> 17:06.400
All the test centers for all, for the traditional tests are closed. So basically, in many parts of

17:06.400 --> 17:12.240
the world, the Duolingo English test was the only option for English language proficiency testing

17:12.240 --> 17:18.400
for people who were hopeful to study in the United States and Canada. Well, so let's push a

17:18.400 --> 17:25.440
little bit deeper into those three areas. I think the first she mentioned was the content side.

17:26.880 --> 17:34.800
Yeah, so a few examples of things that we're doing there. I mentioned earlier proficiency

17:34.800 --> 17:39.680
standards. So there's something called the Common European Framework of Reference. This is a

17:39.680 --> 17:46.240
descriptive framework of the kinds of things you can do at various levels of proficiency.

17:46.880 --> 17:52.000
So it split up into these six levels. There's an A, B and C and then a high and low for each one

17:52.000 --> 17:57.840
of those. So A1 is super, super beginner, survival English or survival Spanish.

17:59.280 --> 18:08.480
And then as you move up, A2, B1, B2 is kind of the threshold for being like you could study

18:08.480 --> 18:16.720
probably in a or work, get a job in a company or university that, where that language is the

18:16.720 --> 18:21.200
medium. You'll probably still have an accent to make your medical errors and stuff, but you can

18:22.800 --> 18:26.240
converse abstractly in that language. And then the C levels are like

18:26.240 --> 18:39.760
much closer to fluent. And so we needed tools to help align our curricula to a standard like that.

18:39.760 --> 18:48.560
So we picked the CEFR for whatever reason. It was as good as any. And there have been lots of

18:48.560 --> 18:57.040
work building vocabulary profiles. This is an A1 level piece of vocabulary like brother and sister

18:57.040 --> 19:03.200
and Monday and Tuesday. And those are kind of A1 level words, whereas contributory,

19:03.200 --> 19:08.160
well actually it's not a word. Or is it? Cropuscular. That's like a C2 level word.

19:11.440 --> 19:15.760
So lots of work had gone into creating these profiles, but only for English.

19:15.760 --> 19:23.600
And we have our in-house language and curriculum developers had put a lot of work into aligning

19:23.600 --> 19:29.200
our English curricula to the CEFR. But we wanted to then duplicate that for French and Spanish.

19:29.200 --> 19:34.720
And the data resources just didn't exist. So we could train machine learning models to project

19:34.720 --> 19:41.440
arbitrary English words onto this onto a CEFR scale, just treating it like an ordinal regression

19:41.440 --> 19:51.440
problem. But we needed to be able to do that for other languages too. And so we had this idea

19:51.440 --> 19:58.880
of using multilingual word embeddings and language normalized frequencies and things like that,

19:58.880 --> 20:04.480
as features in a model that we can essentially train on English data and then make predictions

20:04.480 --> 20:12.400
on Spanish data or French data or Portuguese data or German data. And so we created that. And

20:12.400 --> 20:20.400
there's a tool. We lovingly called it CEPFR, some people pronounce it as CEPFR.

20:21.920 --> 20:29.440
We actually released this publicly. So if you go to CEFR.duelingo.com, you can explore the English

20:29.440 --> 20:36.080
and Spanish versions of that. Internally, we also support I think half a dozen or more languages.

20:36.640 --> 20:42.400
And our curriculum developers use that. We also have features called Duelingo Stories. We

20:42.400 --> 20:48.160
have Duelingo podcasts in French and Spanish. And we have some other kind of top secret things

20:48.160 --> 20:54.960
that we're experimenting with. And the teams that develop content for that are using those tools

20:54.960 --> 21:00.800
to help make sure that, hey, this is stuff we're targeting toward A1 beginner learners.

21:00.800 --> 21:06.240
This is stuff we're targeting toward B1 intermediate learners. And we use these tools to kind of

21:06.240 --> 21:12.560
check the content. And then also highlight the things that are maybe too advanced or too simple.

21:12.560 --> 21:16.320
And those can be nudged in either direction accordingly.

21:17.280 --> 21:23.520
Interesting. So how do you go about training a multilingual word embedding? Are you doing

21:23.520 --> 21:29.120
that based on kind of bi-directional word pairs in a bunch of languages? Or is it

21:30.320 --> 21:36.080
another approach? Yeah, when we were doing this work, we actually didn't train the embeddings

21:36.080 --> 21:42.960
ourselves. I forgot which embeddings we were using at the time. This was about two or three

21:42.960 --> 21:50.880
years ago. We were first building the CEFR tool. But we used some off-the-shelf embeddings. We used

21:50.880 --> 21:59.760
some frequencies from I think Wikipedia and movie subtitles. And that provided enough information

21:59.760 --> 22:07.920
to get pretty accurate scaleings and projections in English data. And then when we qualitatively

22:07.920 --> 22:14.720
inspected the projections in the predictions and the other languages, the content matter experts

22:14.720 --> 22:24.240
found them useful. And was the idea that you would develop a word list for given

22:25.920 --> 22:33.040
course or level of a course and then feed it into the CEFR tool. And it would give you an

22:33.040 --> 22:40.240
approach. It would try to predict the language level of the person who would be taking that

22:40.240 --> 22:45.200
who would successfully complete that level. Right. So a lot of our courses when we were first

22:45.200 --> 22:52.000
developing them, and when I say first developing them, I'm talking about like seven years ago.

22:52.000 --> 22:58.080
So the Spanish for English course was built by our co-founder and CEO Luis Fanon, who's from

22:58.080 --> 23:05.040
Guatemala and bilingual in English and Spanish, as well as some other Spanish-speaking

23:05.040 --> 23:13.600
engineers that we had very early on. Before the linguists and the people with classroom

23:13.600 --> 23:20.000
experience, for example, in Spanish came in. And before I even started, and I was the one who

23:20.000 --> 23:28.960
kind of introduced the CEFR to the company. So for years, we kind of had this like things were

23:28.960 --> 23:34.720
organized in case your listeners haven't actually used a link of lessons are organized into

23:34.720 --> 23:41.120
these skills, which can be their thematic or, you know, they're, you know, like at the restaurant.

23:41.120 --> 23:47.360
And so you learn a few words about ordering food at the restaurant or animals or family or

23:48.160 --> 23:54.560
or in some cases, you know, they're more grammatical in nature. So you'll learn about the past tense

23:54.560 --> 24:02.880
in this skill. And so we had these arbitrary skills that were just like, here are 25 animals.

24:02.880 --> 24:07.440
And no matter, even though you're a beginner, and you don't really need to know how to say

24:07.440 --> 24:13.360
Pangolin in, you know, we're going to teach it to you anyway just because it was just like this

24:13.360 --> 24:19.760
vocabulary core dump. So in the process of going through and revising the courses over time to

24:19.760 --> 24:27.680
make them aligned to the CEFR, tools like this are the kinds of things that we use to both inspire

24:27.680 --> 24:33.920
and sort of quality control check the content as it's being developed. Yeah.

24:36.240 --> 24:44.000
And are there other ways that ML is used in the content development and programming scheme I'm

24:44.000 --> 24:51.680
thinking of trying to think about, you know, either experiences with the app or issues with the app

24:51.680 --> 25:00.320
or I think one kind of recurring theme is or at least something that would be important

25:00.320 --> 25:08.640
for an app like this is kind of the relevancy of the terms and the constructs that you're

25:09.520 --> 25:14.240
learning. And you kind of alluded to this with the Pangolin

25:14.240 --> 25:22.640
content. You want the sentence that the app is teaching you to be representative of the kind of

25:22.640 --> 25:29.360
language that you see out in the wild. Like I imagine that one could create a tool that would

25:29.360 --> 25:42.000
sanity check a curricula like Duolingo's for, you know, relevancy. I remember a lot of folks

25:42.000 --> 25:50.640
might not know this, but you've got there are very active Duolingo forums and entire communities

25:50.640 --> 25:55.920
around like beta versions of languages and stuff like that that most people don't see in the app.

25:57.600 --> 26:03.040
And you'll see folks talking about how, you know, either complaining about the usage in a

26:03.040 --> 26:11.120
a particular question or phrase or, you know, complaining about the relevancy of, you know,

26:11.120 --> 26:15.200
given phrases and it seems like that's something you can develop a tool that would, you know,

26:15.200 --> 26:21.360
compare against, you know, popular media and determine the relevancy.

26:22.080 --> 26:27.760
Yeah, that's something that we have talked about. We actually haven't started a project using

26:27.760 --> 26:33.760
machine learning to do that. But a very similar adjacent thing is in the questions that we give you

26:33.760 --> 26:39.440
particularly the translation exercises and then also sometimes the transcription when you listen and

26:39.440 --> 26:43.440
try to transcribe what you heard. But anytime you're entering in something in the language,

26:44.560 --> 26:50.160
you might, like you may submit something that you're pretty sure you got right, but you're

26:50.160 --> 26:59.840
graded as wrong. And it's also, it's very difficult to capture all possible, you know, language is

26:59.840 --> 27:04.560
very flexible and expressive. So if you're given a prompt in English that can be translated into

27:04.560 --> 27:10.320
Spanish, you know, there's hundreds of valid, you know, Spanish translations of the sentence.

27:11.440 --> 27:17.040
So we write things essentially like regular expressions to sort of capture all the possible

27:17.040 --> 27:23.040
different ways that you can say it. But, you know, the content matter experts who develop this

27:23.680 --> 27:28.240
might miss some or might forget some of there's one particular synonym or, you know,

27:28.240 --> 27:34.880
idiomatic turn of phrase that they skip. So when you grade it wrong, there's a little report

27:34.880 --> 27:43.280
this button. And if you hit that button, then it goes into a big queue. And we get about,

27:43.280 --> 27:51.040
I think, a half a million of those a week. And so it's impossible for the content developers.

27:51.040 --> 27:58.960
And for some of the smaller courses, like Klingon and, you know, Irish Gaelic, there are, you know,

27:58.960 --> 28:06.320
volunteers who actually contributors who maintain. Yeah, we don't have Dothraki. We do have

28:06.320 --> 28:13.600
Hyvalurian. We do have Hyvalurian, which was actually created by David Peterson Patterson,

28:13.600 --> 28:18.400
the linguist who created those languages for Game of Thrones. He approached us and said,

28:18.400 --> 28:23.760
I love the Olingo. I love the incubator, which is the platform where we crowdsource these languages.

28:24.640 --> 28:30.240
I want to create a Hyvalurian course. So we were like, yeah, have at it.

28:30.240 --> 28:35.920
And there's also like, is there Elvish and a bunch of the languages from Lord of the Rings

28:35.920 --> 28:41.120
are? I don't think we have any Lord of the Rings languages. But people, you know,

28:41.120 --> 28:45.520
criticize us all the time for, you know, you're not teaching. For a long time, we didn't have an

28:45.520 --> 28:50.720
Arabic course. We launched that last summer. So people were kind of like, what is your, you know,

28:50.720 --> 28:54.800
you're teaching Klingon, but you're not teaching Arabic. And part of it is the fact that,

28:55.680 --> 29:00.640
you know, a rabid community approached us and volunteered to create the Klingon course, right? So

29:00.640 --> 29:08.160
um, um, but getting back to the, the reports, uh, when those come in, we have a machine learning

29:08.160 --> 29:14.960
model that will probably help prioritize, uh, which are the ones that are likely to be correct

29:14.960 --> 29:21.760
translations, uh, and this uses a combination of kind of like linguistic distance from the things

29:21.760 --> 29:27.520
we do already accept and what this particular submission was, as well as, you know, who was it

29:27.520 --> 29:33.680
that submitted it? Do they have a track record of submitting, you know, good things? And then, um,

29:35.360 --> 29:42.800
uh, and then also like historical data about what did and didn't get approved. And then,

29:43.840 --> 29:49.040
so we have this tool and it's been extremely important. For a lot of the mature courses,

29:49.040 --> 29:54.320
it's, it's less important, but when a new course, like Arabic, for example, when we first launched it,

29:54.320 --> 30:02.480
um, before Latin and Arabic and Scottish Gaelic, which were the first three courses to launch

30:02.480 --> 30:08.480
that we created after we created this tool, even though we didn't have any training data in those

30:08.480 --> 30:16.400
languages yet, it generalized well to those languages. Previous to that, it took about six months

30:16.400 --> 30:21.920
for a course, a new course to graduate out of beta, which among other things, like one of the key

30:21.920 --> 30:25.600
things there is that the number of reports that comes in is below a certain threshold.

30:27.280 --> 30:33.360
Yeah, the number of reports per session or something. And after, you know, this tool was available

30:33.360 --> 30:38.320
after those courses launched and they graduated from beta in like five weeks as of the last

30:38.320 --> 30:49.760
months. Yeah. Oh, very interesting. Um, and so that's the, the content side. I'm also wondering if

30:49.760 --> 30:58.800
there are applications of, you know, language models, GPT-3 types of models on the, the content

30:58.800 --> 31:03.440
side as well. Is that something you're looking at? Uh, potentially. We're, we're looking at those

31:03.440 --> 31:11.520
sorts of models not so much for content creation, but for some, uh, some features you might be seeing

31:11.520 --> 31:17.600
over the next six months or so that are more, uh, kind of interactive feedback on things.

31:17.600 --> 31:23.120
Uh, so currently a lot of the dualingo experiences, translating or transcribing these kind of

31:23.120 --> 31:31.040
rope things and you're not necessarily producing language, uh, spontaneously. Uh, and so we're working

31:31.040 --> 31:36.560
on some, uh, features that would allow you to do that and, and some language models that can give

31:36.560 --> 31:45.840
you feedback. Interesting. Um, this is maybe the last, I'm trying to remember the buckets was

31:45.840 --> 31:51.360
assessment separate from content? Well, assessment is sort of related to the, what I said at the

31:51.360 --> 31:56.560
beginning, I think was content, uh, you know, keeping you engaged with the material and then getting

31:56.560 --> 32:01.920
inside your head. Yeah. And assessment is related to that last one. So if you think about

32:03.920 --> 32:11.200
a good interactive tutor, they're constantly assessing you as they're teaching you. Yeah. Uh,

32:11.200 --> 32:20.080
and so a good interactive, uh, personalized adaptive language system or learning, uh,

32:20.080 --> 32:25.600
educational system of any platform, which is happening to be language, uh, would be assessing

32:25.600 --> 32:33.040
you as well. Um, so we have, and it's actually very related to active learning, which is the,

32:33.040 --> 32:42.000
what I did my PhD in that we talked about earlier. If you think about, um, uh, let's,

32:43.600 --> 32:49.840
uh, like an active learning system, uh, it can look at a bunch of unlabeled data and say,

32:49.840 --> 32:54.640
this I understand, this I understand, this confuses me, please label this. Uh,

32:54.640 --> 32:59.760
a core layer to that is if, if I'm a machine learning system that is trying to teach you something,

32:59.760 --> 33:07.280
I have a, a mental model of what you know, I think you understand this. I don't think you're ready

33:07.280 --> 33:12.640
for this yet. This is in the zone, uh, a proximal development is, is what it's sometimes called.

33:13.280 --> 33:19.760
Uh, so I'm going to give you, uh, material in this area. So it's right on the margin, you know,

33:19.760 --> 33:24.960
this is something that confuses me about what you know and don't. So it probably confuses you in

33:24.960 --> 33:32.240
terms of what you know and you don't. Um, and so we use those kinds of models both for personalized

33:32.240 --> 33:35.760
learning and for computer adaptive testing in the dual and go of most tests.

33:37.200 --> 33:43.840
And one of the things that has really changed language learning over the past, I don't know,

33:43.840 --> 33:51.520
10 years, let's say, for just the number out there is I think the, um, kind of the mainstreaming

33:51.520 --> 33:58.000
of this whole idea of space repetition and kind of systems, a ton of systems that are based on

33:58.000 --> 34:05.360
space repetition. Basically, uh, some system trying to, you know, learn what you know and focus

34:05.360 --> 34:11.200
your learning effort on the things that you don't know as opposed to, uh, you know, continuing

34:11.200 --> 34:18.400
and reinforce the things that you've probably already committed to memory. Um, and this idea that,

34:18.400 --> 34:22.720
you're describing a active learning kind of takes space repetition, you know, once that

34:22.720 --> 34:27.840
further, because it's building this mental model of what you know and what you probably need to

34:27.840 --> 34:34.720
be refreshed of or on, um, versus not as opposed to, uh, I think the original spaced

34:34.720 --> 34:39.440
repetition models were based on this. The idea of a deck of cards and you would put things in

34:39.440 --> 34:43.520
different places in this deck, uh, and that would dictate how often you see them.

34:43.520 --> 34:51.280
Um, yeah, actually, so, uh, I published a paper in 2016 in the association of computational

34:51.280 --> 34:58.640
linguistics about the space repetition model that we use, uh, uh, at Duolingo. Um, so it, that

34:58.640 --> 35:03.920
was actually one of my first projects back in 2013 when I first joined. So when I first joined,

35:03.920 --> 35:10.080
we had one of these flashcard algorithms that was, you know, designed in the 70s back when you

35:10.080 --> 35:17.440
had physical flashcards. So that's what was running in production to, um, to select the exercises

35:17.440 --> 35:21.840
that you would see when you did a practice. So there were, there are lessons where you're being

35:21.840 --> 35:26.560
introduced to new material in Duolingo and then there are practice sessions, uh, where you're

35:27.200 --> 35:32.880
reviewing a old material that can either be within a particular skill that you did or you can

35:32.880 --> 35:36.800
just like the whole course, everything that you've learned so far, you can practice all of it.

35:36.800 --> 35:46.000
Um, and so the, the, the algorithm that was used in production before I started was called the

35:46.000 --> 35:50.880
lightener system. And there's a few different flavors of it, but, but the one that was in production

35:50.880 --> 35:56.560
is this idea that you've got a different box. And there's the one day box and the two day box

35:56.560 --> 36:01.600
and the four day box and they grow up, go up exponentially in powers of two. Uh, and everything

36:01.600 --> 36:05.120
starts in the one day box. And then when you practice something, if you get it right,

36:05.120 --> 36:10.880
it graduates to the two day box. And then you get the way two days to review it. And then if you

36:10.880 --> 36:14.960
practice it again two days later and you get it right, then it can graduate to the four day box

36:14.960 --> 36:21.120
and, and so on and so forth. And, and that way you can, if you consistently keep doing well,

36:21.120 --> 36:25.840
you can push it off longer and longer. Uh, but then if you get it wrong, then it demotes back to

36:25.840 --> 36:32.240
the previous box. And so it cuts the, the spacing in half. Um, so that's what we had in production.

36:32.240 --> 36:38.080
You know, there was, there was some rationale for it, but I quickly realized that that algorithm is

36:38.080 --> 36:44.640
essentially, uh, two to the power of the number of times you got it right and the number of times

36:44.640 --> 36:53.040
you got it wrong. So you can turn that into, you know, a, a model that is like, number of times

36:53.040 --> 36:57.440
right as a feature with a coefficient of plus one and number of times wrong as a feature with

36:57.440 --> 37:02.960
a coefficient of minus one. And you can learn those plus ones and minus ones from data, rather than

37:02.960 --> 37:08.640
just like picking those kind of arbitrary numbers. Yeah. It turns out the Pimsler method, um,

37:09.520 --> 37:17.200
that he published a schedule, Pimsler published a schedule on 67, I think, uh, that also turns out

37:17.200 --> 37:23.600
to be a special case of this. So we, yeah, so we called it half-life regression because it's

37:23.600 --> 37:31.200
essentially a nonlinear regression on with this kind of inductive bias of this half-life.

37:31.200 --> 37:38.000
It's not exactly a slope, but like decay rate. Um, and, and turns out both the lightener system

37:38.000 --> 37:44.800
and the Pimsler method are special cases of that model. And we were able to fit a model

37:44.800 --> 37:51.280
two data and then put, we ran a controlled AB test putting that into production. Uh, and

37:51.280 --> 37:57.360
and to this day, it's probably one of the most impactful, impactful experiments that we've done.

37:57.360 --> 38:05.840
I think there was a 12% boost in, uh, in retention. And by that, I don't mean mental retention.

38:05.840 --> 38:11.120
I mean, like a user used the actual day and going back the next day. Got it.

38:11.120 --> 38:15.600
Or in the very early days in the first year or two of the company, that's the main metric that

38:15.600 --> 38:22.160
we looked at. Well, it can be really frustrating when you're, you've got some set block of time

38:22.160 --> 38:25.920
that you want to spend, you know, learning your language, whether you're on the bus or train,

38:25.920 --> 38:30.960
or whatever, or, you know, you just block out the time. And if you spend half of that time

38:30.960 --> 38:36.320
reviewing cards that you've already committed to memory, that is terribly frustrating.

38:36.880 --> 38:43.040
Yeah. And, and one thing that we're running into now is like, we really, that was an early kind

38:43.040 --> 38:46.880
of successive mine. And I've gone on to do other things and nobody's really been working on that

38:46.880 --> 38:53.040
for seven years. And, and, and our user base has changed. We have more courses now. We've got

38:53.920 --> 39:00.480
orders of magnitude more users now. Uh, the, the amount of content has changed. So that model that

39:00.480 --> 39:07.680
was in production probably is not ecologically valid anymore. Uh, we do have a research scientist

39:07.680 --> 39:12.800
who this past quarter has started revisiting those. And we've got some promising alternatives,

39:12.800 --> 39:18.240
um, that we're about to start running some experiments to try to improve on. So that it,

39:18.240 --> 39:23.040
it's still the case that some people, you know, hey, this is basics one at the beginning of the

39:23.040 --> 39:27.600
tree. Why is it telling me I need to practice this now? I know that stuff backward and forward. And

39:27.600 --> 39:32.560
so it was just an artifact of the fact that when we first fit the models, there were like,

39:32.560 --> 39:43.200
only 100,000 users and, you know, six courses. Yeah. Wow. Um, so you, you, you made this distinction

39:43.200 --> 39:52.320
between human or learner retention and, uh, the, your SaaS metric of retention. Um, I imagine

39:52.320 --> 39:59.600
though that you are also trying to understand the human learner metrics, you know, to what degree

39:59.600 --> 40:08.080
do you, um, you know, to what degree do you go after that? How difficult is it to go after that?

40:08.080 --> 40:13.440
And is there a role, you know, of machine learning and trying to understand, um, you know,

40:13.440 --> 40:20.240
the user experience, the learner experience? Yeah. That's a very, very important question. Uh,

40:20.240 --> 40:25.360
and it's a very difficult question. So most startups, most companies really, there,

40:25.360 --> 40:31.760
there's different families of, of metrics that you look at. All right. And all companies, of course,

40:31.760 --> 40:37.920
look at revenue. That's one that's super important. Uh, most apps and things also look at

40:37.920 --> 40:43.840
engagement. So how growth, you know, how many people are using it. But we have this additional

40:43.840 --> 40:49.040
family of metrics on learning, uh, that most other companies don't have. And it's easy to kind of

40:49.040 --> 40:53.840
look at what other companies are doing to, to optimize, you know, revenue and engagement.

40:53.840 --> 41:00.400
And there's nobody else to look to to really figure out how to, to measure and improve learning.

41:01.040 --> 41:08.480
And, and one way you could do that is, you know, by looking at which exercises they get

41:08.480 --> 41:12.880
right or wrong and are these exercises that they got wrong six months ago or they get in them

41:12.880 --> 41:18.960
right now. Um, and we do do some of that. And, but it's still very challenging because this,

41:18.960 --> 41:24.160
it's this endogenous reasoning, you know, uh, what you're showing them is sort of priming them on,

41:24.160 --> 41:31.360
on what they're, uh, they're getting right and wrong. But, uh, about a year ago, we created a,

41:31.360 --> 41:39.440
an efficacy team, um, within the company that has started to do some longer term sort of research.

41:39.440 --> 41:45.600
And just a month or two ago, we, we published a white paper. Uh, I think if you go to do

41:45.600 --> 41:52.000
lingo.com slash efficacy, you can find a summary of it and, and actually download the white paper.

41:52.560 --> 41:59.040
Um, the main results were essentially for learners of French and Spanish. So English speakers

41:59.040 --> 42:08.320
learning French and Spanish. Um, there is, uh, at reaching checkpoint five, uh, of the course,

42:08.320 --> 42:16.000
which is probably, uh, I don't know exactly how many skills that is, but it's, I'm going to guess

42:16.000 --> 42:23.760
it's on the order of 20 or 25 skills. Um, so after doing 25 skills and do a lingo, you're performing

42:23.760 --> 42:29.360
at least in terms of listening and reading, uh, at the level of somebody who's finished four or

42:29.360 --> 42:36.880
five college semesters. And so there's some, there's mounting evidence that this kind of personalization

42:36.880 --> 42:43.200
that we're doing, uh, through machine learning, uh, to build good content to, you know, create

42:43.200 --> 42:50.800
engagement and to personalize through getting inside your head, um, is working. And do you also

42:50.800 --> 42:56.560
using the, uh, using the separate tools that we talked about earlier, you should be all also

42:56.560 --> 43:06.640
able to relate that level five knowledge base to, uh, a safer level. Uh, yes, you, you could.

43:06.640 --> 43:12.560
I mean, the problem, the difficulty in doing that is you need to get parallel data to do some

43:12.560 --> 43:18.880
mapping and equating, uh, but that's definitely something you could do. I mean, an analogous, uh,

43:20.320 --> 43:25.440
thing we could maybe switch gears and talk about the doing the duolingo English tests because

43:25.440 --> 43:32.480
this is related, um, you know, it is an assessment. And the idea there was, uh, before we do that,

43:32.480 --> 43:42.720
another question on assessment, uh, in some of the tests, there are, um, if I remember correctly,

43:42.720 --> 43:49.840
there are, uh, assessments where you're speaking into the, into your device. And it is, um,

43:49.840 --> 43:54.880
essentially doing a speech recognition and trying to tell you if you've got that correct. And I'm

43:54.880 --> 44:02.400
curious how, um, you know, machine learning oriented that is or technically, you know, sophisticated

44:02.400 --> 44:11.600
that is, um, I remember, I don't remember when I was trying to learn a tonal language like

44:11.600 --> 44:16.640
Mandarin, like if it was really all that sophisticated at telling one tone from another, I know that

44:16.640 --> 44:21.440
when I got there, no one understood a word that I said. So clearly the tones I was not learning

44:21.440 --> 44:31.200
them all that well, uh, but, um, you know, how, how much ML is going into like the speech side of

44:31.200 --> 44:36.880
things. In the, in the duolingo learning app up until very recently, it was fairly rudimentary

44:36.880 --> 44:44.320
and, and to be honest, we were relying on, uh, like the on app services like the Siri and the

44:44.320 --> 44:52.560
Google, uh, ASR systems and, and also relying on, um, TTS that were third party provided. Uh, this,

44:52.560 --> 44:57.600
this year we've actually hired, uh, more people, uh, and in particular, somebody who used to work

44:57.600 --> 45:04.080
on the Siri team who's starting to beef that up. And so over, uh, where, where, we, we have reached

45:04.080 --> 45:10.720
the point where we've hit a ceiling, uh, of what we can do effectively in the learning app using

45:10.720 --> 45:14.960
third party tools. And now we're starting to build it out, uh, in-house with some promising early

45:14.960 --> 45:19.600
results. So you should see that starting to be pushed out into the app, particularly for the,

45:20.240 --> 45:26.480
the more popular courses like English for Spanish and Portuguese speakers or French and Spanish

45:26.480 --> 45:34.800
for English speakers. Um, uh, but on the, on the duolingo English test side of things, there are also

45:34.800 --> 45:42.560
speaking exercises that you have to do, um, both the sort of thing where you're, you're,

45:42.560 --> 45:47.920
you're given a prompt and you have to say this kind of scripted thing as well as just completely

45:47.920 --> 45:53.760
open ended, uh, exercises like you're given, uh, an image and you just have to talk about that

45:53.760 --> 46:03.360
picture for, uh, you know, two or three minutes, uh, there may be one or two minutes. Um, so for those,

46:03.360 --> 46:10.400
we do have more. That sounds like a really interesting NLP machine learning question answering,

46:10.400 --> 46:17.040
potentially type of, uh, challenge. Yeah, yeah. So it's, it's pretty challenging and another thing

46:17.040 --> 46:23.680
that is very important to us, uh, is to make sure that those models are fair across, you know,

46:23.680 --> 46:30.800
that, that, uh, you know, uh, males and females have different vocal registers. Uh, so if you have

46:30.800 --> 46:36.640
lopsided data in some sort of way, it could, you know, be automatically scoring, uh, one group,

46:37.200 --> 46:41.600
uh, with higher scores than the other group for irrelevant reasons, different accents,

46:41.600 --> 46:47.280
so that the speech recognition that is used as a part of that, uh, scoring algorithm features

46:47.280 --> 46:52.800
are extracted from the ASR. Uh, it might work better for some accents than others and you need to

46:52.800 --> 46:57.760
make sure that it's fair. Uh, so we've put a lot of effort into making sure that happens. We've

46:57.760 --> 47:04.160
done a lot of, uh, you know, what's called differential item functioning in the psychometrics, uh,

47:04.160 --> 47:10.800
literature, uh, make sure that the items are not behaving differently, uh, for different groups.

47:10.800 --> 47:14.880
So those are some of the challenges of building the test, but another challenge is,

47:14.880 --> 47:24.080
uh, your traditional, uh, test, and this is true for like, all kinds of educational high-stakes tests.

47:24.080 --> 47:30.160
They're usually done at a test center, uh, and so that means by definition, there's only a few of

47:30.160 --> 47:34.960
them. They're in certain cities. Uh, there's a finite number of seats that are available. They're

47:34.960 --> 47:39.760
not open every day. More expensive to take and deliver. They're more expensive to take and deliver,

47:39.760 --> 47:44.960
and there's this, and the assumption is because it's in this place, it is, you know,

47:44.960 --> 47:50.240
there are security protocols that are sort of in place. Right. The day off will work usually

47:50.240 --> 47:55.360
because they're, you know, businesses. Right. But if you're, if you're from like,

47:56.560 --> 48:03.920
if you're in the rural Amazon, right, then that means you have to take a 14-hour bus ride into,

48:03.920 --> 48:07.680
I don't know, Sao Paulo or something to take the tests, probably spend the night,

48:07.680 --> 48:11.840
and then if there's a trucker strike that shuts down the highway for a day, the day before you're

48:11.840 --> 48:18.320
going to take your test, you're out of luck. Yeah. And so we, we needed, it was part of our goals in

48:18.320 --> 48:23.520
creating this test that is something that anybody anywhere, you know, could take, uh, as, I mean,

48:23.520 --> 48:31.040
as long as they had an internet connected device. Um, that also means that, you know, one way to

48:31.040 --> 48:40.000
cheat on a traditional kind of test is, uh, you know, you take the test and then you, you somehow,

48:40.000 --> 48:45.840
you know, circulate the items that were in that test online so that in very short order,

48:45.840 --> 48:51.200
anybody, you know, who is taking an administration with them in the next 48 hours has access to

48:51.200 --> 48:57.760
the questions and that can get better scores. Uh, this by definition is a test that is in an

48:57.760 --> 49:05.760
uncontrolled environment. So our strategy in combating that was to make it a computer adaptive test

49:05.760 --> 49:13.600
with a huge number of items. Um, the only way to scale it, like, and the reason that makes it

49:13.600 --> 49:19.440
more secure is when you go in and take the test, like, you're, every time you take it, if you take

49:19.440 --> 49:24.960
the test 10 times, it's going to be a different set of questions every time. I think the item exposure

49:24.960 --> 49:33.360
rate is, uh, less than a half a percent, maybe less than a tenth per percent. Yeah, you would have

49:33.360 --> 49:40.000
to take the test a thousand times to see the same item again on average. Uh, and the way we accomplish

49:40.000 --> 49:46.080
that is through machine learning. So all of, all of the items are automatically generated and then we

49:46.080 --> 49:54.880
use the same, we're very similar techniques to create the, the CEFR line tools. We also then project

49:54.880 --> 50:02.880
the items that we automatically generate onto a CEFR line scale, um, using machine learning.

50:02.880 --> 50:10.080
So this is a B2 level question and this is an A1 level question. Um, and then we can adaptively,

50:10.080 --> 50:14.560
you know, we'll start out giving you a B1 level question. If you do well on that, then we'll jump

50:14.560 --> 50:21.280
up to a B2 or a C2, C1 level question. And if you do not as well on that, you know, we'll back off

50:21.280 --> 50:29.200
to a B2 level question and we can zero in on your language proficiency. And when you're starting

50:29.200 --> 50:37.600
this process and generating, uh, questions or texts, um, what type of generation are we talking

50:37.600 --> 50:44.960
about generation from, you know, straight from the model or generation via selection from in the

50:44.960 --> 50:51.440
wild text that you know are valid and make sense and what all goes into that. So right now it's a lot

50:51.440 --> 50:56.560
of the latter, what you just said. Um, it, it depends on the item type. So there are several

50:56.560 --> 51:01.680
different item types. We actually just published a paper this year in transactions of the association

51:01.680 --> 51:08.240
of computational linguistics laying out the approach to the first version of the test. So that paper

51:08.240 --> 51:14.560
even though it was just published a few months ago is already obsolete. Uh, but, um, but there are

51:14.560 --> 51:20.000
several different item types, uh, that go back decades in the language testing literature that

51:20.000 --> 51:28.480
are things that are easy to produce automatically and to grade automatically. Um, and so we'll, we'll

51:28.480 --> 51:35.360
take texts from naturally occurring sources, authentic texts is what the language assessment folks

51:35.360 --> 51:42.400
would say. Uh, and then one of the items is called the C test where every other word you remove

51:42.400 --> 51:47.920
the second half of the word and then the task is to fill in the missing blanks, uh, which seems

51:47.920 --> 51:53.600
like a really simple task really, really hard to do if you don't know the language. Um, and,

51:53.600 --> 52:02.960
and what we can do then is we have a pretty good model to rank order. This is a, an A2 level text

52:02.960 --> 52:13.120
because the language in it is pretty concrete. Uh, it's, it's pretty, um, what, what's, what's

52:13.120 --> 52:18.880
the word I'm looking for? Um, there's not a lot of abstract ideas. It's like informational. And

52:18.880 --> 52:24.880
then as you move up, uh, the levels that can become more academic and more, not only does the

52:24.880 --> 52:30.320
vocabulary become more sophisticated, but the content, you know, it's trying to argue of viewpoint

52:30.320 --> 52:38.400
or, uh, make some abstract cons, you know, uh, discuss abstract concepts. Uh, so those are the

52:38.400 --> 52:44.640
sorts of things that the ML models pick up on. And we use these authentic text to create the

52:44.640 --> 52:51.600
items and then the ML models to project them onto the scale. And then we use adaptive, kind

52:51.600 --> 53:00.720
of active learning type algorithms to then search through that space, um, to, to, uh, efficiently

53:00.720 --> 53:10.560
figure out where you belong on that scale. Interesting. Um, so that's, uh, kind of content and assessment,

53:10.560 --> 53:17.280
a little bit of getting in your head, um, engagement. Yeah, spend a few minutes on that.

53:18.080 --> 53:26.400
Yeah. Uh, so this is probably where to date we've invested the least, uh, and I'm looking forward to,

53:26.400 --> 53:31.600
you know, uh, growing the team and, and doing more work in this. But a good example of that is,

53:32.720 --> 53:38.160
um, we, we send out these, uh, if you've used the dual and go app, you've probably gotten and

53:38.160 --> 53:42.800
maybe been annoyed by, you know, these push notifications that are practice reminders to remind you,

53:42.800 --> 53:49.360
use the app, you know, or you'll lose your streak or something like that. Um, and so we actually

53:49.360 --> 53:57.200
use, uh, machine learning to determine what message to send you when we, we send you those.

53:57.200 --> 54:02.560
We also actually experimented with using machine learning to figure out when to send those to you.

54:02.560 --> 54:10.400
Not, and we had fairly accurate models, uh, that could figure out, you know, that some people

54:10.400 --> 54:17.360
have different patterns on the weekends versus the weekdays or, uh, or whatnot. It turns out that

54:17.360 --> 54:22.880
those, that those, those timing models, even though they were very accurate, they just didn't

54:23.520 --> 54:28.160
make a difference in terms of the metrics compared to some pretty good heuristics that we'd

54:28.160 --> 54:33.280
developed that were simple heuristics. And so in the end, we actually are not using machine learning

54:33.280 --> 54:37.600
to do the timing because it wasn't worth the technical debt of the machine learning. But we do

54:37.600 --> 54:44.240
use it to pick the content and we actually have a KDD paper this year, um, about that. It's a

54:44.240 --> 54:50.320
banded algorithm that's actually a novel algorithm because there are two things in using banded

54:50.320 --> 54:56.480
algorithms for push notifications, at least the way we do it, that are kind of out of the box.

54:56.480 --> 55:04.160
And one of them is that not every template that we could send you is, is viable at every time.

55:05.040 --> 55:12.000
So we might want to send you a message that says, um, you know, uh, keep, keep your streak

55:12.560 --> 55:16.880
or, or don't forget, uh, your streak, which is like the number of consecutive days that you've

55:16.880 --> 55:21.680
been using Duolingo. But if your streak is one or zero or something, we don't want to send you

55:21.680 --> 55:29.440
that, uh, that particular one. Uh, or another one is like, if you are on the leaderboard,

55:29.440 --> 55:33.840
if you're in a certain position in the leaderboard, we might send you a message about that,

55:34.480 --> 55:40.000
but it's only eligible if you're on a leaderboard. That's right. And so that's messes up the statistics,

55:40.640 --> 55:46.080
a little bit. A universe of, uh, what, how big is the message space? I would have imagined that

55:46.080 --> 55:51.760
that would be relatively small, like half a dozen and machine learning wouldn't be all that interesting

55:51.760 --> 55:58.400
as a way to optimize these messages. No, we have hundreds. And we have hundreds. And they also

55:58.400 --> 56:04.160
are translated into all the different languages. Because remember, we've got, uh, about half of

56:04.160 --> 56:09.840
people using Duolingo are learning English from a variety of other languages from, you know,

56:09.840 --> 56:17.760
like, uh, you know, Arabic to Spanish to Chinese. Um, so, so we have to localize all of those. And

56:17.760 --> 56:25.760
the messages culturally perform differently, uh, you know, for, for different groups. Sure.

56:26.880 --> 56:31.120
And so that's one problem is the eligibility criteria, which kind of screws up the statistics

56:31.120 --> 56:37.680
a little bit. And then the other problem is this novelty effect, where, uh, if we send you the same,

56:37.680 --> 56:43.040
like the bandit algorithm figures out, oh, yeah, time for your Spanish lesson. That's the number one

56:43.040 --> 56:48.960
that we should always send that. Right. Very quickly, you'll burn out on that message. Uh, and so

56:48.960 --> 56:54.080
we've had to introduce kind of this cognitive penalty, uh, which is very related to space

56:54.080 --> 57:00.480
repetition. We actually borrowed a lot of the same work from, um, uh, seven years ago on space

57:00.480 --> 57:06.880
repetition and baked it into this bandit model. And so to us, it seemed like it was a, it was a novel

57:06.880 --> 57:13.040
algorithm. So we submitted a paper in it, uh, presented it, I guess last month. Oh, well. And in

57:13.040 --> 57:21.920
terms of the, um, you know, comparison to relatively simple, heuristic type of an approach,

57:21.920 --> 57:26.080
like, how do you characterize, I imagine you're characterized that in terms of engagement lift. Like

57:26.080 --> 57:34.320
what is that, you know, how significant, uh, is the difference of the, uh, uh,

57:34.320 --> 57:39.760
machine learning algorithms and heuristic approach? Uh, I think it was, uh, don't, you know,

57:39.760 --> 57:45.600
don't send a, a streak message if there's no streak, don't send, uh, you know, the other one,

57:45.600 --> 57:55.600
if that doesn't apply, you know, equally, I believe what we had been doing before. Uh, it wasn't

57:55.600 --> 58:01.520
a heuristic as much as like these are all the things that are eligible at this time. Uh, pick one

58:01.520 --> 58:06.080
at random. That's what we were doing. Yeah. Which gave us, you know, really good kind of like

58:06.080 --> 58:13.760
training data to start with because it was a relatively, uh, representative sample. Um,

58:15.600 --> 58:24.000
but we, in general, you try to, with, uh, in production, kind of industry, machine learning,

58:24.000 --> 58:34.800
use heuristics where possible until, until as long as you can fit it in your head. That's,

58:34.800 --> 58:40.000
that's a good heuristic, you know, heuristic can fit in your head or, or, uh, you don't have to

58:40.000 --> 58:46.960
draw a flow chart for somebody else to understand it. Uh, and if it's doing well, stick with that for

58:46.960 --> 58:52.720
now, uh, if it gets to the point where you can't keep it in your head or you have to draw a flow chart

58:52.720 --> 58:57.840
to explain it to somebody else, that's when you should start using machine learning. Uh,

58:57.840 --> 59:02.640
or when you've iterated on the heuristics to the point where you're just getting diminishing

59:02.640 --> 59:09.120
returns, usually like whatever branches are in that heuristic, turn those into features and

59:09.120 --> 59:14.080
apply machine learning, uh, and you'll usually get a lift. At least that's been our experience.

59:14.080 --> 59:22.960
So in this particular case, um, you know, we hadn't really tried any heuristics beyond, uh, randomly

59:22.960 --> 59:28.160
sampling because none of them made sense that wouldn't become immediately very complicated.

59:29.040 --> 59:33.920
So machine learning seemed like the way to go. Interesting, interesting. Any other things that

59:33.920 --> 59:40.080
you're doing on the engagement front? Uh, that's probably the best example to talk about now,

59:40.080 --> 59:48.560
all right. Yeah. I think we're going on for a while. So I don't know. Yeah, no, that is, uh,

59:48.560 --> 59:55.040
I just popped my, uh, my timer up here. We have been, um, but definitely a fascinating conversation.

59:55.040 --> 01:00:01.280
And, uh, you know, like I said at the beginning, I could continue on, uh, and definitely, but, um,

01:00:01.280 --> 01:00:09.440
um, we, uh, want to be conscious of our listeners, uh, attention span as well. Um, but it has been

01:00:10.240 --> 01:00:16.800
great chatting with you about some of the things that Duolingo's doing, uh, to, you know, help people

01:00:16.800 --> 01:00:22.160
learn languages using machine learning and AI. Well, thanks for having me, Sam. I'm a fan of the

01:00:22.160 --> 01:00:34.320
podcast. So it's pleasure to be here. Awesome. Thanks so much for.

