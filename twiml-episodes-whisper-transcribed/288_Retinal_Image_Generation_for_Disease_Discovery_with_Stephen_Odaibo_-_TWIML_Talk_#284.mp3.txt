Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
As we approach Twimblecon AI platforms, I'd like to let you all in on our first major announcement
from the conference.
Now you all love this podcast for great guests and interviews and we're bringing that concept
right to the Twimblecon stage.
I am super excited to announce that Andrew Eng will be joining me on stage at Twimblecon
for a live keynote interview.
Many of you know Andrew from his work at Stanford, Coursera or his many other efforts in the
industry including recently founding deeplearning.ai.
Andrew and his work have been super impactful on my life and career and I know that's the
case for many of you as well.
In our conversation we'll be discussing the state of AI in the enterprise, the barriers
to using deep learning and production and how to overcome them, his views on tooling and
platforms for efficient AI delivery and other topics from his recently published AI Transformation
Playbook.
Be on the lookout for more great speaker announcements rolling out over the course of the next few
weeks.
You don't want to miss this event.
Get your tickets now at twimblecon.com slash register.
Alright everyone, I am on the line with Stephen O'Diibo.
Stephen is the founder, CEO and chief software architect at Retina AI.
Stephen, welcome to this week in machine learning and AI.
Thanks so much Sam.
It's such an honor to be on the show here with you.
It's great to have you on the show.
So you are an MD, a medical doctor, in addition to having a background in math and science
or math and computer science.
Can you elaborate a bit on your background and how you kind of made your way into working
on artificial intelligence?
Yeah, most certainly.
You know, as you said, I'm a physician, I'm an ophthalmologist, a Retina specialist,
computer scientist, mathematician and a full stack AI engineer.
And you know, it all, it's sort of been a journey that I've really enjoyed along the
way.
There wasn't sort of a grand plan at the beginning to sort of do all of this.
But yeah, I started out at University of Alabama in undergrad and I was a math major, I really
enjoyed that.
But the entire way I was a pre-med student, so I was med school bound.
And the program I was in was an NSF funded program called the Fast Track Program.
So I got a master's degree in the course of that.
And it was, it was a phenomenal place, you know, great mentorship.
And it was, and I would say a little bit of a, however, it was a pure math, which it's
a, however, it's also a great advantage.
But I found that I had some work to do when I graduated.
So we were, in the course of the program, focusing on abstract algebra, topology and things
like that.
And I remember probably halfway through grad school, through the master's part of it,
looking at a friend of mine and saying, you know, where, where the heck did three go and
where's 15?
You know, there were no more numbers.
It was all, whatever happened to 71, you know, I haven't seen that number in so long.
You know, it was all symbols, you know, you know, the wheels and the complex and so on.
But from there, I went to medical school, went to Duke and was in a MDPHD program, started
out.
And I went to the biochemistry department, worked with Bob Lefkowitz, who ended up with
the Nobel Prize in chemistry in 2012.
And you know, I enjoyed the, by the time of the lab, it was phenomenal.
I was two years there.
But somewhere in that course, I had sort of a, an awakening during the grad school part
of my med school journey.
And, and it, I, I, it became clear that I sort of wanted to continue what had started
at in Alabama with the math.
And it, it was clear to me that it wasn't going to happen with the traditional pathway
in the way biology is done.
Biology is done sort of like looking for a needle in a haystack, you know what I mean?
In what sense?
It's less systematic.
I think some of that is going to change.
It's the notion of there are certain people who, by virtue of their position or insights
and prior success, judgment, whatever you want to say are, are able to pick the problems
that are interested.
And there's a lot of arbitrariness to that process and, and craft the story around it.
And something, something about that felt in, in complete, you know, to me, I, I, I wanted
a, I wanted, I, now looking back, I think I wanted the era of big data where we could
more systematically search for things, and we could more systematically draw conclusions
and have more faith in the conclusions that we draw in science.
Does that speak broadly to kind of the difference between the way we approach science generally
and more of an engineering type of an approach?
It's, it's not even science, old science procedure because the engineering thing has changed
too, right?
In the last five years, for example, in, in machine learning, there was the era of feature
engineering, which was more along the lines of the way biology was done is you manually
look for features and manually craft them even, even design them explicitly yourself versus
using an optimization type approach where you're letting the data tell its own story and
you're sort of sitting back as a judge, as opposed to you're the script writer.
Oh, got it.
Interesting analogy there.
So anyway, I, you know, I had, I had that, which coincided with the spiritual awakening
as well, and I decided, you know, I have to go back to, I, so I decided to go to the
computer science department, and you're not at that point, and I switched and, um, and
I started to re ignite the math there with numerical analysis, and I, I had worked to
do because my flavor of math was pure and abstract.
And here I was realizing that, um, if I was going to impact the world, you have to sort
of go through the computer.
And that means hard numbers.
That means matrices, you know, that means matrix matrix multiply, right?
So, you know, that was a blast, you know, I would say that was probably the hardest part
of my journey was, was getting, getting into, back into the game in terms of math computer,
because I was having to really pick up new skills as well, you know, and that was a
Duke also, you know, the computer science department, I was going to get a PhD there in computer
science.
I, I, um, passed the qualifying exams, et cetera, et cetera.
And I acquired all my skills, had to fall in out with my advisor, um, and, and then
I moved on.
At that point, I got the master's, no problem.
And, uh, and went back to medical school, uh, and I, but then I had just one more year
to finish med school, uh, finish that and, and then stayed at Duke for my intranier, uh,
and, uh, and by then I was back in the game, you know, clinically went back, went to Howard
for my ophthalmology residency, uh, which was a lot of fun.
At that point, I was already committed, right?
I was already, I already knew that I have to keep doing this math thing.
You know, I've paid enough of a price.
It was, it was never gonna, I was never gonna let it go, uh, and so even during the course
of my residency, I wrote a book on quantum mechanics, for instance, uh, and then, uh, went
to the University of Michigan for a fellowship in retina.
And I, I loved Michigan, you know, I visited an arbor, uh, it was a really intellectual
mecca was the way that I saw it.
And there was something really pure about the place in terms of what people at least
aspired to, um, sort of a, they, they really, they really took, I felt that they really
took, um, um, academic pursuit as a primary gain, as opposed to something for a secondary
gain, for recognition or money or whatever, um, at the end of the day, we're all human,
you know, and there's always that going on, right?
There's always the politics and there's always stuff, you know, but I felt Michigan stood
out in terms of its, uh, it's, uh, the genuineness of its commitment.
And so I, it was my first choice, you know, and I could, coming down to Howard, I could
have gone anywhere in the country.
Um, so I went to Michigan as my first choice for fellowship, um, and it was really good.
I wanted to stay in the academy at that point, you know, but, um, the irony was during
the course of my time there, it started to dawn on me that if I'm really gonna be able
to make a difference from really gonna be able to use computer, science, math, I didn't
know exactly what I wanted to do at that point, but it dawned on me that if I really was
going to do that, it was sort of a real epiphany, a surprise that I, I needed to sort of craft
my own career.
I really had to go into private practice to become a true academic.
I couldn't do it at the university because there were these programs that were set up,
you know, people said you have to fit into this box, right?
And there was not a, a sense of, uh, and I, you know, that's just the way it is, you
know, there was not a sense of, you know, go do whatever you want.
Nobody says that.
Right.
Nobody wants to do that.
And I, I get it, you know, so I picked the job.
I went to Iowa.
I worked three days out of the week, um, and it being private practice, you pay your, you
pay your own salary.
You wouldn't, you, and so it was no problem.
And the rest of the time I did academics on my own.
And there I wrote a book on a finite group theory, started getting more into the peer
and theoretical part, I've always sort of oscillated between, um, the, uh, applied concrete
real and the celestial ecclesiastic, the clouds, you know, I've always had a gun between
the two.
And so I was all the way in the clouds.
You know, when I was in Iowa and I wrote that book on finite group theory, um, and then
at that point, my brother, uh, David, David O'Dybo, who is co-founder of, uh, and a
little AI, you know, he was ranked 70th in the world, uh, in Kaggle.
Um, and so he started, he started telling me because I had left grad school at that point,
you know, and he started telling me that there's this thing called deep learning.
Hmm.
I, I hear I was who I was basically a guy, a PhD holder in effect in computer science,
who finished and left the computer world in 2010, and I had never heard the word deep
learning.
Right.
That's a duke for that matter.
Right.
Um, there was no such thing, you know, the whole thing about AI, so on and so forth.
There was nothing like that machine learning was the most boring class you can think about.
It was horrible.
I made it with like, uh, you know, Mark of chains and so on and things that are now so exciting,
the most exciting things in science were really, you know, we're really in the cover.
I mean, it's very deep inside of textbooks, they were gathering dust.
And so anyway, my brother told me that this thing is so exciting what he's doing because
he was in grad school at the time, you know, at the University of Alabama, I had left and
then he had, he had been working, uh, he's a year older than I am and he had gone back
to grad school and he said he's doing deep learning.
It's so exciting.
He said he's doing these things and he kept talking about it and you know, eventually
one day at, uh, Christmas, uh, I was over it.
We were spending the Christmas at their place, um, in, in Birmingham and, um, you kept
talking, I said, okay, let me take a look.
What is this?
And he said something to do with images and image classification.
And I said, you know, that's what I do in my work.
Like I basically look at a picture, depending on what the picture tells me I go, uh, and
I decide whether I'm going to stick a needle in somebody's eyeball, um, and administer
injections, uh, or I determined whether I'm going to do laser surgery on that person,
all based off of the picture.
And so he said, really?
I said, yeah, I said, it's all the picture, the picture guides the treatment.
And, um, and so he said, no kidding.
So, so you have a much more, uh, the, the, the stakes involved in image classification
are perhaps much more tangible for you.
Absolutely.
Absolutely.
And none of this was abstract at all because I'll do 40 injections in one day.
You know, sometimes see 50 patients a day and I'm literally running from room to room.
Um, um, and so I, I, so at that point, I'll study for my boards, the, uh, the biology
boards, which that's a whole different story.
We could do a whole another, uh, say a session on that, Sam.
You know, it's, you know, they, you know, they, they put you in a hotel room and they
ask you these questions.
Literally, there's, there's like a bed there at somebody's hotel.
You walk in and, uh, they're asking you questions about on the 10 different areas of the
eye.
And, and so off the body is, is, is it's own thing in that way.
Um, so anyway, I'll study for this exam.
That everybody dreads, um, and I, I, I, so I said, okay, let me finish, let me knock
the boards out of the way.
And then I'll take a look at this thing.
So, uh, finished my boards in 2016, November, uh, and I started studying, I started looking,
I said, okay, I'm going to look at deep learning, uh, and took a trip to Nigeria, um, which
was already planned.
You know, it was Christmas and, um, and that was when I first opened the book, I looked
at it.
So let me look at this deep learning thing.
And then I thought, okay, very interesting.
Do you remember the book?
Well, yeah.
Okay.
Well, you know, it's actually not a book.
It was, uh, um, nobody reads books anymore.
I was, I was curious if it was one of the kind of the classic books, but, um, okay.
Got it.
Got it.
We're speaking metaphorically.
What's the fine metaphorically?
Got it.
Yeah.
It was, it was, the book was, so the metaphoric book was the CS 231 course by, uh, Carpathy.
Ah, yeah.
That was the book.
Got it.
So I looked at the book and I said, holy smokes, this is good stuff.
Uh, and then next thing I, I pulled up a media article with, um, uh, some Keras code in
it, and the Python, uh, they actually had a tutorial on Python on the 231 course.
And so I pulled out that 231, that tutorial, you know, I have a, I have a grad degree in
computer science.
It took me a week to pick up Python and so on.
Um, and then I, I ran the M-ness training in the Keras.
It was basically like copy pasted it into, uh, into the Jupiter notebook.
And I saw the thing, you know, numbers running and, you know, I was like, wow, this is
amazing.
You know, this is fascinating.
And so I wired up actual data, actual image and data to it.
And when I saw the accuracy that was coming out, meaning clinical imagery data, clinical
or like data and M-ness data.
No, after I did the M-ness thing, okay, then I actually took clinical data, actual, you
know, actual patients, you know, data, uh, and I ran that, uh, an image classifier on
that.
And based on the accuracy that was coming out, I was, my jaw dropped, you know, Sam,
I was like, wow, okay, this is a game changer.
And I'll never forget that night in, in that point, it dawned on me that, uh, there's
about to be a revolution that really everything is going to change.
And so, um, my brother and I got to talk in, I launched out the company, retina AI, you
know, he helped me with it, um, and, uh, he, he turned out he was involved with so much
at the time, you know, he was doing his Kaggle thing.
He was ranked 70th in the world on Kaggle.
He was a part of two other startups.
Uh, he was completely his PhD and so he had a lot going on.
So he said, I should carry on on my own, you know, with it.
And you know, that, that turned out to be a good fit, you know, it was, it was challenging
for me, but I had no backup, Sam, um, so you can imagine that's really where I became
a full stack AI engineer, um, cause I had, I had left my job, you know, where, where
you know, in full disclosure, where I was probably making five or 10 times what, what I,
I thought I would ever make in my life, um, and I left that job and, uh, I, I, I left
it because I thought I had a backup.
I thought I had, there was a person who's going to be the CTO who's going to do all the
actual hard work, you know, and I'm just going to be like, you know, a talk ahead, you
know, no problem.
I enjoy that, you know, running around, you know, talk about what we're doing, you know,
connect with folks and, and kind of get things moving along and, you know, talk to investors
and that type of thing and go give some clinical talks.
Um, but here I was, you know, and I had to build a product and I had to build, I put out
an MVP, you know, and I had to, to do all of that.
And so I, I had to pick up a bunch of things along the way.
I, so we built a mobile app and I had to, I had to pick up a Swift and build the iOS and
then, you know, pick up Kotlin and, you know, and Java, uh, script and, um, you know, put
out the Android version of this and I had to learn how to host models in the web, um,
in the cloud, uh, how to serve and, you know, how I had to get into some details with
serverless stuff as well as restful APIs and the like it and, uh, dock, uh, containerization
and all the, all the needy greedy stuff that I quite honestly didn't think it was even,
I didn't even conceive that it was even possible for a physician to ever be doing anything
like that.
Um, but I was, I was sort of forced into it and, you know, I'm really thankful for that.
Um, but anyway, so our company is retina AI Health Incorporated.
Um, we, I, I, whether that storm last year and at the end of the year started, uh, talking
to investors, got a few angels together, all physicians who, you know, they wrote checks
enough that we're going to be, we're going to be around this year for sure.
And, and, you know, next year as well.
And, you know, maybe forever, maybe, you know, sounds like you've definitely made the transition
to startup life.
Yes.
Yeah.
So that's sort of the short, that's a short story.
And just in quick summary of what the company is, um, we are, we are using machine learning
to build autonomous systems that will, that diagnose retinal diseases as well as diagnosed
systemic diseases from pictures of the retina.
For example, cardiovascular risk, uh, somebody who's that guy who's playing golf and looks
really healthy and is 55.
And suddenly you find out that this person dropped dead of a heart attack, a massive heart
attack and has a young family.
Um, it turns out that we, we are coming closer to be able to accurately find out who that
person is by just looking in their eyes.
And saying, you really need to get to a heart doctor.
You really need to change your diet.
You really need to be on anti cholesterol medicines, beta blockers and the like, um, to,
to prevent something like that.
So it's a big market.
It's a big space and it's really exciting.
Can you maybe contextualize what retina AI is doing relative to some of the other activities
in the space?
Uh, as you can imagine, you are paying even more attention to it than I am.
And there are announcements happening constantly about folks using these particular types
of images to make various predictions, uh, deep mind in UK had a tie up with the, uh,
the NHS there around using retinal images.
I did an interview with, uh, a Google developer who was doing some work around some of what
you were just talking about predicting cardiovascular risk factors based on these retinal
funness images.
Can you maybe contextualize, uh, maybe talk a little bit about kind of the broad landscape
of, you know, what's happening in this space and, and how, uh, what you're doing fits into
that.
Yeah.
Great question, Sam.
Um, you know, it's, uh, it's early days and, um, there's, uh, the problem is so big
and the potential for impact, um, is so compelling that, um, both large companies as well as
small startups are interested, uh, Google has, uh, interest in this area, you know, as
you said, you know, a deep mind, uh, whereas working with the, is working with the NHS and,
um, they, you know, recently put out an image classifier with, uh, I think they said 50
different retinal diseases and that, um, sort of thin, you know, that's, uh, it's for
us a standard problem, you know, we have a similar classifier with even more diseases,
um, that, that, uh, we're about to roll out here.
Microsoft isn't interested in this as well, uh, and, you know, has a platform that they're
working on and, and Google is also working with Arvin and I Hospital in India, you know,
uh, looking at the issue of diabetic retinopathy screening, uh, there are, um, startups, some
that are large and have raised significant amount of capital, such as IDX, uh, which is
based out of Iowa City, uh, Michael Abramoff's company that received FDA approval for a
device to do autonomous screening for diabetes, um, and diabetic retinopathy.
So there are a number of people involved interested because it's such a large space in terms
of, um, both the market as well as the humanitarian potential for, for a real positive impact.
The diabetes is a big focus for a lot of these companies as well as for us.
It, uh, for instance, the US has about nine or 10% of our population, uh, is diabetic.
And you know, that, that number is, uh, over 35 million people.
And when you talk about prediabetes, there's over 86 million people.
That's people who, if not diagnosed and treated, um, will develop diabetes within five years.
That's 86 million people.
And on a worldwide scale, it's a lot larger.
It's half a billion people, you know, with diabetes, um, and about one and a half million
people die every year, you know, from the disease.
So the real issue here is that in terms of human labor physicians, it takes so long to train
a doctor, uh, and that's, there's no hope there for us to use human power to train physicians
to be able to diagnose this and to be able to, the world's population is growing much faster
than we're turning out physicians, um, and so the problem is worsening.
So AI is compelling and is actually necessary, um, to be able to address the, the problem.
And so a lot of people are working on in this area.
And we're, we, there, there's competition.
There's also collaboration.
It's all very good, um, for instance, at the National Medical, um, associations, uh, annual
meeting, which is going to be in Hawaii this year.
I'm going to be chairing a panel, um, on, on this very, on, on more broadly, innovations
in ophthalmology, but I've geared it and focused it towards diabetic retinopathy.
And so we have the, uh, technical lead from Google brain team, uh, Dale Webster working
on this diabetic retinopathy.
He's going to be there, um, on the panel and, uh, and that's, uh, Dale Webster.
And then Anushra Trivedi is, she works in Brad Smith, the president of Microsoft's office
in healthcare AI.
And she's the lead on that.
And so I invited her.
She's going to be there as well.
Uh, she's also working on diabetic retinopathy.
And then Michael Abramoff, who's the founder of IDX, he's going to be on the panel as
well.
Um, and so where we collaborate, we're, we're looking at it, we're thinking about it.
The truth of the matter is it's such an enormous problem, um, that, uh, you know, it's great
to share ideas and see how everybody can move forward together.
And so can you maybe talking a little bit more detail about your approach and some of
the research you've published in this space and how it, uh, you know, is, is everyone
kind of doing the same thing, applied to different data sets or folks taking, you know, either
dramatically different or, you know, different in novel ways, uh, types of approaches, like
what distinguishes the different things that are happening in the space.
Right.
It's great, great question, Sam.
So yeah, there's a lot of commonality, a lot of similarity.
Um, whenever one goes to these, um, machine learning conferences, you know, there's no, in
terms of the actual techniques that are being used.
There's nothing that's enormously novel, right?
Everybody, you know, there's only, there's only Python in there.
There's only Keras and, you know, PyTorch and, uh, um, there's, you know, and there's
not that many tools, um, that we're using to execute the job.
Approaches do differ, uh, and, uh, access to data, you know, uh, differs, uh, and that's,
sometimes it's not always, more data is not always necessarily a good thing, which is
a separate topic, um, it depends on the type of data that one has access to.
And then one's understanding and knowledge of the specific domain.
And so I think that's where we stand out, um, because of my experience as, uh, a physician
and a thomadist, I'm a retina specialist, also a full stackier engineer.
And I built the entire prototype of our first prototype on my own and to end, um, I think
what that does for us is it gives us a very unique perspective.
We can innovate very quickly.
For example, one of that, the papers that I just published two weeks ago was, uh, using
a generative adversarial network, um, to generate, uh, artificial data for data augmentation.
And, um, I generated a certain type of scan called an OCT of the retina.
And I passed it along to a few of my colleagues who are also retina specialists.
And, uh, I was impressed to see that, um, at least half of people, uh, didn't get all
of them right.
These are experts, you know, who look at these, these images all day, um, so there are certain
differences.
It's the smaller startups who have more integrated domain knowledge can move quicker and can
innovate, you know, uh, quicker, uh, in that space.
And so everybody's going to have to work together and that's what we're doing.
We currently have, um, we're currently in the Google Cloud, uh, platform, you know, startup
program, so we, we get some, some, some benefits from, you know, having access to, to cloud
infrastructure.
And, you know, that helps us, uh, and we're currently also looking to, to further some
ties with some of the other larger companies to see how everybody can move forward together.
So that's, that's a really interesting perspective on the way these markets, uh, will evolve.
And I want to dive into, uh, the, the GANs, uh, work that you've done.
But, but before we do that, let's linger here for a second, uh, what strikes me as interesting
is there is a period of time, maybe, you know, three, four years ago when everyone kind
of believed that, you know, the, that, that AI was going to be totally driven by access
to data and it was going to be a handful of large companies that would kind of lock up
all of the data and, you know, thus build all of the best models and everyone else would
be frozen out.
And I, I think that, that's changing, right?
That perception is changing and you touched on some of the reasons why.
Can you elaborate on, you know, what you see there?
Yeah.
Um, exactly, you know, people, it was just, it was just 24 months ago.
People were saying, oh, wow, you know, throwing the towel, don't worry about it.
You know, Google's interested, they've, they've looked at it and so it's over.
Um, and, you know, I, we always said, you know, it was, as people were saying that,
that I was leaving my job, you know, because I, I absolutely didn't believe it.
You know, I, and so one thing that I tell people is data is everywhere.
And data has always been everywhere.
And it's, it's kind of like oil, like natural gas, it's, it really is everywhere.
You know, you dig deep enough anywhere, you'll, you'll strike oil somewhere, um, but
it's really difficult to set up the rigs to know how to, to find the oil and how to, you
know, extract it and, and, uh, convert it into something useful into gas and to fuel
into natural gas for, for one's vehicle, for instance, just to jump in there.
I'm not sure that's the best analogy for your position in the sense that actual exploration
and extraction of oil is hugely resource intensive.
And it's kind of the domain of the big oil companies as opposed to, well, I don't know
this market.
So I may be totally wrong, but I'm assuming that it's, you know, that is kind of one of
these things where it's kind of dominated by, you know, huge energy companies and state
on players and things like that.
Right, right.
Yeah.
Yeah.
That's, that's one part that the analogy doesn't work because it's actually the opposite
in the case of, you know, in this era where, you know, a kid in Nigeria or Ghana who has
access to the internet, you know, and has a laptop, you know, can train a machine learning
algorithm.
Right.
Um, so it's other than that part, you know, it's, um, so yeah, the point there is that
no end to data, having domain expertise, which is what these oil companies have, um, having
domain expertise and knowing what to do with data, that's actually what's very expensive.
And in, in, in this case, it's, uh, the analogy does work where expensive in a more general
sense of the word, uh, it's hard to come by.
It's so expensive that Google can't afford it, right, um, in the sense that, and that's
part of the, the strategy they recognize that and so a lot of these big companies have
venture arms that look to partner or acquire, uh, smaller startups, um, because they, that's,
that's where the rubber hits the road is in the domain expertise coupled with the engineering
know how, uh, allows people to find meaningful insights inside of data.
And so another comment that you made was that more data is not necessarily a good thing
and it goes against kind of the common wisdom as well in this space.
Can you elaborate on that?
It totally does.
Yes, yes.
So more data is not always a good thing.
And for example, one of the reasons why, you know, uh, generative adversarial networks
have been thought of as, you know, more powerful than preceding, uh, generative models is because
they can somehow find somehow find, um, different pockets where there's, uh, an up variation inside
of, uh, a probability distribution of a certain data type.
Um, but, but they did that's, that's, that's only so true to a certain extent.
Otherwise, what, what one might be getting is sort of an averaging or blurring of, of
a certain part of the data.
Um, that's the one example where knowing how to, uh, pick the data, understanding what
the implications in the various pockets of variation within a data sample mean in the
real world, um, is priceless.
One example of where this played out is with the RSNA Kaggle competition in which, um,
the top 10, uh, finalists winners were all radiologists who have somehow along the way acquired
ML skills, uh, and there's, there's no substitute, substitute for that.
Um, and that's sort of always going to be the case.
Another example is no one went to this halt training of an algorithm, um, with your standard
supervised learning type problem, uh, you can sort of go off of your loss function.
You can say that the losses dropped, the looser and threshold we're going to stop, we're
doing great.
Um, that process is governed by the data, of course.
So assuming that you had good data, you, you can safely trust your halt point.
But in the case of, say, again, the ultimate arbiter is still the human visual cortex.
It's still a human being who understands what, um, a dog or a cat should look like because
you've got these two competing algorithms that are fighting with each other and the loss
itself is clearly now insufficient.
And so you can't, one can't stop training again when the loss drops below a certain point
because the adversariality, the push and pull that the discriminator and generator are
doing to each other continues past a certain point.
So you don't really know when to stop, uh, and there's no real quantitative approach
that we currently have for knowing when to stop training, uh, these gain algorithms.
And so because adversarial examples are another way that, that make that very apparent,
that you really ultimately still need the domain expertise.
It's an enormous value, um, in today in ML and I think we're all going to, I think people
are starting to get that, um, people, the, the initial big hype and excitement that
computers are going to take off or start into, to dampen, uh, and people are starting
to realize that, um, the only real way forward is going to be, uh, in any, is going to be
domain specific and it's going to be with really integrated interdisciplinary teams and
ideally, people who have, um, uh, detailed, uh, expert level knowledge of both the ML side
as well as whatever other field that they're looking to apply ML to be at agriculture,
you know, be a transportation, be it healthcare.
Tell me a little bit about your experience getting up to speed with, with GANs ultimately
resulting in, uh, this paper you published.
Oh, yeah.
It's, uh, yeah, you know, I basically, I, um, I, I, I thought, you know, well, this, this
could be interesting.
It started with a theoretical question.
I was, you know, I was given a talk and somebody asked me in the audience and I was actually
given talking Nigeria where I went for a data science, uh, Nigeria they invited me in
January just last month.
Oh, two months ago, we're already in March here.
Um, and, uh, and somebody, uh, somebody brought up, uh, whether GANs could be used for
augmentation of data and, you know, and my initial inkling, I hadn't really worked with
GANs at that point, um, only really a month ago.
And, uh, my inkling was to say, no, I don't see it.
I, I don't see a person pulling themselves up by their own bootstraps that it's your,
and your GAN model, your generative model, what it's able to generate is necessarily constrained
or bounded in terms of its accuracy in terms of its fidelity to the actual native data set
is bounded by these initial sample from that data distribution, which is your training
data for the discriminator.
That was my response, you know, and, you know, and, uh, but I, I kept thinking about it
though, you know, that, was that, was that correct?
You know, is that true, um, and, and, uh, it's, it is, you know, I, I'm still there.
And so I said, okay, let me, let me play with this thing.
Let me take a look at it and actually look at the details of how it works and what it
does.
Uh, and so I, I, I read up on it and, you know, trained up again model, uh, and, you
know, generating some data and I'm getting some really insights from, from that, I've
only been doing that over the last couple of weeks here.
And uh, been learning a number of things about how data works and what data is, what the
distributions are and so on and so forth.
And that only, um, strengthens my conviction that for us to go forward in ML, um, we're
going to have to understand the domain very well because they're, it's necessarily a heuristic
field.
And so, um, yes, we can come up with theories that are true to some extent.
But ultimately, only, only so much as they can somehow encapsulate the general properties
of data.
For instance, um, there's the, uh, in signals processing world, right?
Where one is looking at doing a sampling.
If your signal has a certain character to it, you know, if it's band limited, um, then
you know that if you sample a certain way with a certain frequency, you can perfectly
reconstruct that data set, you know, that type of idea, you know, the Shannon Nyquist
sampling theorem, you know, that type of idea, um, can provide some guidance about what
we can do within ML.
But it's completely clear that, you know, Google, the Googles of this world would be completely
outmatched by small teams of people, could be even two or three people who have expertise
in their area and are working on those problems.
And that's a very exciting time in history.
You mentioned this process of working with gans, you know, beyond reinforcing the, the
value of domain expertise kind of led to some insights around some of the core machine
learning problems that you're working on, can you elaborate on those a bit?
Right, right.
So I'm actually, I'm trying to, I want to write it up, you know, put it on the archive.
Some of these same type of ideas are, some of the paradoxes are that more data is not
necessarily better.
You know, that's kind of a big one.
It's what type of data, right?
And what problem are you trying to solve?
Sometimes you actually need less data of a certain type.
Sometimes when you have more data, you're diluted something, depending on what you're trying
to accomplish.
And how do you know what's the, like, this is probably what the thing that you're, that
you need to write up, or that you're kind of moving towards writing up, but like, my
sense is that there's, you know, a set of kind of disciplines behind what you're saying
that aren't really talked about a lot.
Right, right.
And this field is so nascent, you know, this field of ML and data is wide open.
Yeah.
Yeah.
It's totally wide open.
And I think there have been certain mantras that have been just, you know, just regurgitated
verbatim, but I think that, you know, the more we look at it, the more we honestly look
at it, right, as opposed to trying to force machine learning to fit a certain model, to
fit a certain way of thinking.
I think the more we honestly look at it, the more we'll be able to get deeper into what,
what the character of this thing is.
It comes down to specificity, you know, what are we trying to do, you know, and how we
trying to get there in a data set, you know, in a data distribution, for instance, there
would be certain features, certain characteristics within certain neighborhoods of the distribution,
which would be very different from other neighborhoods.
And so if you're trying to capture the essence of a certain neighborhood of the data distribution,
you're better off sampling from that area than coming up with, you know, saying I have
10 million images, you know, of this broad, ill-defined, you know, data class.
When in reality, they're truly subfamilies, multiple subfamilies within that whole area.
So one has to really understand what they're doing.
One has to really understand what the landscape of that data type is, be it language, be it
image and be it a particular type of image and then guide that.
So the human visual cortex and the human experience will remain the eye.
In my view, will remain the ultimate arbiter for at least, you know, for the next decade.
Who knows what's going to happen after that?
Well, Stephen, it was great chatting with you about all this stuff.
I'm looking forward to following along as you start to publish some of your insights
into, you know, GANS and this whole dynamic around data and domain expertise and machine
learning.
It's all really interesting stuff.
Well, thank you so much, Sam.
It's really been an honor to be on your excellent show.
And I'm looking forward to going through your entire archive.
Yeah, I am. It's really good quality, high quality stuff.
Thank you for your contribution to the community.
Thank you.
Thanks, Stephen.
You're most welcome.
All right, everyone.
That's our show for today.
For more information on today's show, visit twomolai.com slash shows.
Make sure you head over to twomolcan.com to learn more about the Twomolcan AI Platform's
conference.
As always, thanks so much for listening and catch you next time.
