WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:31.840
I'm your host Sam Charrington.

00:31.840 --> 00:37.560
In this episode we're joined by Garrett Hoffman, Director of Data Science at Stocktwitz.

00:37.560 --> 00:41.640
Garrett and I caught up at last month's Stratid Data Conference where he presented a tutorial

00:41.640 --> 00:47.800
on deep learning methods for NLP with emphasis on financial services.

00:47.800 --> 00:51.760
Garrett is a social network for the investing community which has its root in the use of

00:51.760 --> 00:54.160
the cash tag on Twitter.

00:54.160 --> 00:59.320
In our conversation we discuss applications such as Stocktwitz own use of social sentiment

00:59.320 --> 01:04.560
graphs built on multi-layer LSTM networks to gauge community sentiment about certain

01:04.560 --> 01:09.880
stocks in real time as well as the more general use of natural language processing for generating

01:09.880 --> 01:12.280
training ideas.

01:12.280 --> 01:15.920
Before we dive into the conversation I'd like to send a huge thanks to our friends at

01:15.920 --> 01:19.280
IBM for their sponsorship of this episode.

01:19.280 --> 01:24.520
Interested in exploring code patterns leveraging multiple technologies including ML and AI,

01:24.520 --> 01:26.520
then check out IBM Developer.

01:26.520 --> 01:32.040
With more than 100 open source programs, a library of knowledge resources, developer advocates

01:32.040 --> 01:37.880
ready to help and a global community of developers, what in the world will you create?

01:37.880 --> 01:46.440
Just dive in at IBM.biz slash ML AI podcast and be sure to let them know that Twimmel sent

01:46.440 --> 01:51.200
you and now on to the show.

01:51.200 --> 01:57.560
Alright everyone I am here in New York City at the Stratid Conference and I am with Garrett

01:57.560 --> 01:58.560
Hoffman.

01:58.560 --> 02:01.840
Garrett is the director of Data Science at Stocktwitz.

02:01.840 --> 02:04.280
Garrett, welcome to this week in machine learning and AI.

02:04.280 --> 02:05.280
Thanks for having me Sam.

02:05.280 --> 02:07.160
It's fantastic to be here.

02:07.160 --> 02:08.160
Awesome.

02:08.160 --> 02:12.240
I am always super excited when someone, I'm interviewing someone and they say they listen

02:12.240 --> 02:17.000
to the show and enjoy the show so thanks for offering that.

02:17.000 --> 02:23.680
Why don't we get started by having you tell us for those who aren't familiar with Stocktwitz,

02:23.680 --> 02:25.400
what's Stocktwitz all about?

02:25.400 --> 02:26.400
Yeah I'd love to.

02:26.400 --> 02:33.000
So Stocktwitz is a FinTech financial technology company we're based here in New York City

02:33.000 --> 02:38.920
and our core product is the Stocktwitz.com or the Stocktwitz mobile app which is a social

02:38.920 --> 02:42.280
network for the finance community.

02:42.280 --> 02:48.760
So kind of like a LinkedIn meets Twitter specifically for traders and investors.

02:48.760 --> 02:53.480
So people who are interested in the market can come on, connect with each other, share

02:53.480 --> 03:00.560
ideas, learn from each other and most importantly they can enjoy participating in the markets

03:00.560 --> 03:06.160
and investing even more by sharing in that experience together.

03:06.160 --> 03:13.080
Our core user is the millennial investor who we know is digitally native, increasingly

03:13.080 --> 03:14.400
social.

03:14.400 --> 03:20.520
This is a group that really loves social engagement around the decisions that they're making and

03:20.520 --> 03:26.440
we've seen companies like Amazon facilitate this and eat commerce when someone's looking

03:26.440 --> 03:30.760
to buy something through going through reviews, talking with their friends about kind of

03:30.760 --> 03:36.600
the stuff that they're purchasing and as a company we really see ourselves as a platform

03:36.600 --> 03:41.280
where people can come to engage in this type of social interaction around the decisions

03:41.280 --> 03:45.080
that they're making in investing and financial services.

03:45.080 --> 03:51.160
So right now conversation centers mostly around individual stocks but our new product

03:51.160 --> 03:56.760
that we actually just launched called rooms allows the community to start to self organize

03:56.760 --> 04:01.760
around specific topics that they're interested in and that's really exciting for us because

04:01.760 --> 04:07.240
it allows people to dive deeper in details so maybe like they want a room just to talk

04:07.240 --> 04:12.760
about Apple products and what that might mean for the stock but it actually also helps

04:12.760 --> 04:18.000
conversation grow bigger and more general maybe people want to talk about other financial

04:18.000 --> 04:23.880
services like Robo advisors like general like insurance stuff like that.

04:23.880 --> 04:30.880
So it's really giving the community a platform to talk more about financial services in

04:30.880 --> 04:34.280
general or specific topics that they're interested in.

04:34.280 --> 04:40.040
And I've got this impression that Stock Twits grew out of the stock tag on Twitter.

04:40.040 --> 04:41.560
Is that the case or?

04:41.560 --> 04:49.400
Yeah so our founder Howard lives in back I think it was 2009 invented the cash tag and

04:49.400 --> 04:56.800
so this was a dollar sign in front of a ticker symbol on Twitter and we were actually partnered

04:56.800 --> 05:04.680
with Twitter using the Twitter API to kind of search and filter Twitter for tweets specifically

05:04.680 --> 05:06.080
that had a cash tag.

05:06.080 --> 05:14.000
So it was kind of a filter on the Twitter API a few years later we actually left the

05:14.000 --> 05:19.680
Twitter API and became a standalone platform so it was born through the cash tag.

05:19.680 --> 05:26.600
The cash tag is our main mechanism for index and conversations to specific stocks but

05:26.600 --> 05:31.800
Stock Twits today it's its own standalone platform but it is that micro blogging real

05:31.800 --> 05:37.400
time Twitter like form out of discussion and what's your background?

05:37.400 --> 05:45.920
Yeah so I in undergrad I study in mathematics and finance I got exposed to a lot of like

05:45.920 --> 05:55.880
the core ML mathy concepts matrix factorization eigenvectors optimization statistical learning

05:55.880 --> 06:02.960
but I'd say my first introduction to kind of machine learning as like a field that was

06:02.960 --> 06:07.720
more than just like the sum of these individual parts that I was learning was when I started

06:07.720 --> 06:13.280
researching topics for my undergraduate thesis and came across neural networks.

06:13.280 --> 06:19.120
I really wanted to study something that was math as used in the finance industry to kind

06:19.120 --> 06:25.840
of tie both my field of study together and I saw that people were starting to like resurface

06:25.840 --> 06:32.480
neural networks to do forecasting on stock prices and I actually decided to pass on that

06:32.480 --> 06:33.480
topic.

06:33.480 --> 06:36.920
I was like oh this was done in the 80s it's kind of been explored already I couldn't

06:36.920 --> 06:42.560
have been more wrong about how prevalent it would be a few years later in fact I was

06:42.560 --> 06:48.960
more interested at the time in kind of probability theory stochastic calculus random processes

06:48.960 --> 06:57.120
um so I actually this was 2011 when I finished undergrad and at the time the default job

06:57.120 --> 07:02.640
for people who studied math and didn't really want to teach was an actuary so I got a job

07:02.640 --> 07:08.360
as an actuary at Xerox part of a smaller business group called buck consultants that they

07:08.360 --> 07:13.360
owned a lot of people don't know that Xerox played in kind of the consulting playground

07:13.360 --> 07:20.720
but I did actual consulting around benefit plans so valuing retirement plans valuing

07:20.720 --> 07:26.960
health plans executive stock option plans kind of working on the investment strategy around

07:26.960 --> 07:34.560
the funds that pay those types of benefits and being an actuary is a phenomenal profession

07:34.560 --> 07:42.160
but after a year or so I kind of realized it wasn't for me um I I wanted to have more of

07:42.160 --> 07:47.520
a tangible impact and be able to kind of like see the impact of the models that I was creating

07:47.520 --> 07:53.360
and of the analysis that I was doing so I I really liked my company and I liked the space I'm

07:53.360 --> 07:58.320
I'm very passionate about financial wellness and financial literacy and helping people

07:59.040 --> 08:03.360
get gain the knowledge and tools that they need to kind of be independent and and

08:03.360 --> 08:09.760
wait through a very complex world on their own so I really became interested in how can we help

08:09.760 --> 08:17.200
our clients help their employees make better decisions around their benefits so this was more

08:17.200 --> 08:24.000
of like a behavioral psychology behavioral economics problem and I think was my first cross in

08:24.000 --> 08:29.440
my professional life of kind of leaving actual the world of actuarial problems and the the types

08:29.440 --> 08:35.200
of stuff that actuaries normally think about to enter in kind of a data science problem a problem

08:35.200 --> 08:41.440
that could be um solved using machine learning and data science so I actually spent the next few

08:41.440 --> 08:47.040
years still at that company doing kind of like half actuarial stuff half product development for

08:47.040 --> 08:53.760
these new solutions um they actually started to take off we got a few client projects Xerox actually

08:54.400 --> 09:01.200
let me take a sabbatical they sent me to uh metastata science boot camp in New York City to kind of

09:01.200 --> 09:07.360
true up my knowledge fill in the gaps more on the product and delivery side like how are solutions

09:07.360 --> 09:13.040
in data science and machine learning scaled and delivered just because as an org we were kind of

09:13.040 --> 09:19.360
waiting through new territory no one really had that knowledge of okay once we we've done the modeling

09:19.360 --> 09:23.760
and done the technical stuff like what are clients who are looking for these solutions actually

09:23.760 --> 09:30.320
looking for what when they ask someone to help them with it um so stuff like productizing data

09:30.320 --> 09:37.200
through APIs you know building applications with data science stuff like that um ended up going

09:37.200 --> 09:44.000
back to Xerox for about six more months and realized that um I really wanted to go somewhere where

09:45.840 --> 09:54.320
where I could really shape um like a consumer facing product I wanted to be somewhere a little

09:54.320 --> 10:01.600
more closer to the technology industry the actual at the actuarial industry is um great lagging maybe

10:01.600 --> 10:07.440
a little bit behind in terms of like using cutting edge technology um so at that time I started

10:07.440 --> 10:13.040
looking for new opportunities I ended up at stock twitch it was kind of a great marriage for us where

10:13.760 --> 10:20.240
I'd have a treasure trove of data being close to like being centered around a social a social

10:20.240 --> 10:26.400
network and still kind of at an org where their goal was to help people understand this really complex

10:26.400 --> 10:35.120
world of finance and so you did a tutorial actually uh here at Strata on the use of deep learning

10:35.120 --> 10:40.560
methods for natural language processing with a particular emphasis on financial services and

10:41.200 --> 10:47.280
some of the things you're doing at stock twitch what are some of the ways that NLP that you use

10:47.280 --> 10:54.240
NLP at stock twitch yeah so um our core data that we have available to us at stock twitch is of course

10:54.240 --> 11:00.960
raw messages that people are writing ideas that they're generating um so we're working a lot with

11:00.960 --> 11:10.640
just raw text data and as a data scientist at stock twitch I see the core mission of our team is to

11:10.640 --> 11:20.320
really improve the user experience and improve the product through data and so for us and a lot

11:20.320 --> 11:26.080
of how I see machine learning like what what machine learning aims to do is to actually kind

11:26.080 --> 11:32.080
of like shrink the world and so stock twitch there's real-time information flowing by really really

11:32.080 --> 11:40.800
quickly um you know things change super quickly it's a real-time stream so to to the extent that we

11:40.800 --> 11:46.960
can use data to build data products to kind of help people discover like snapshots of what's

11:46.960 --> 11:51.920
going on right now help them really find stocks that they're interested help them find people that

11:51.920 --> 11:58.960
were they're interested in um that's really how we're using data so one of our biggest uses for NLP

11:58.960 --> 12:05.440
is actually our social sentiment model so we like to summarize the stream of what's going on with

12:06.160 --> 12:12.720
sentiment graphs so we try to keep real-time updates of how our community feels about a certain

12:12.720 --> 12:20.000
stock and we're doing NLP modeling to extract financial sentiment from all the text data that's

12:20.000 --> 12:26.480
coming in and then aggregating that at its individual stock level to kind of see how that's moving

12:26.480 --> 12:32.640
and see how that's changing over time so that lets people come in and see maybe they've done some

12:32.640 --> 12:38.480
research off platform they want to just check out what people are saying on stock twitch even before

12:38.480 --> 12:44.880
waiting through you know thousands of of messages in a real-time stream they can have this nice

12:44.880 --> 12:50.960
little little snapshot of you know how does the stock twitch community feel are they overly bullish

12:50.960 --> 12:57.760
or they more bullish than they typically are has there been a drastic like riser or fall in sentiment

12:57.760 --> 13:03.440
in the last few days um stuff like that so your your talk was on deeplining methods what are some

13:03.440 --> 13:08.880
of the methods that you apply to to solving those types of problems so when we think about um

13:09.600 --> 13:17.680
sentiment we're typically in the realm of RNN so we're using multi-layered LSTM networks to

13:17.680 --> 13:23.920
um just extract a sentiment a bullish neutral and bearish signal and we're fortunate enough

13:24.480 --> 13:33.440
that we have um users have the ability to tag their messages with sentiment when they post it so

13:33.440 --> 13:40.240
we've been able to inherently gather label training data through general usage of the app

13:41.280 --> 13:47.120
and through people tagging their messages um one of the reasons we go on to model sentiment

13:47.120 --> 13:55.440
further is only about 20 to 25% of messages are tagged so by by building a model around sentiment

13:55.440 --> 14:00.960
we can expand that coverage to a hundred percent of of the volume instead of just this very small

14:00.960 --> 14:08.640
subset of tag messages um we typically have to supplement um our tag data through manual curation

14:08.640 --> 14:17.520
just kind of validating that those tags exist so we use LSTM networks um it's really a great method

14:17.520 --> 14:26.480
for capturing those dependencies across multiple across as it changes capturing dependencies of like

14:26.480 --> 14:32.160
the language and the relationship through text through a nice sequential model like like RNNs

14:32.160 --> 14:37.920
and LSTMs help us capture more nuance in the language so sometimes you get a really straightforward

14:37.920 --> 14:45.440
message like I am bullish um maybe yeah and so that's that's really obvious and then sometimes it

14:45.440 --> 14:52.240
might not be so straightforward so so an example of that might be someone saying like oh Tesla

14:52.240 --> 14:59.280
here looks really really high right now um I don't think I'm a buyer if it dropped maybe down to

14:59.280 --> 15:05.600
like the 200 range then I would definitely get in so if I'm using a method or a model to classify

15:05.600 --> 15:12.480
that that statement um typically you know you're making classifications at the end of your sequence

15:12.480 --> 15:17.920
the the end of that sentence makes it seem like that person might not that they are bullish that

15:17.920 --> 15:24.720
they're going to be a buyer but LSTMs allow us to capture kind of the the um the state of that

15:24.720 --> 15:31.600
sentence to know you know at the start of this sentence this person was pretty bearish um and so

15:31.600 --> 15:38.320
LSTMs allow us to cat to retain that information throughout the entire sequence that we're trying

15:38.320 --> 15:44.400
to classify what challenges do you run into when you're trying to develop these these models based

15:44.400 --> 15:53.920
on LSTMs yeah so I'd say our biggest challenge is probably the domain specific nature of the language

15:53.920 --> 16:01.440
so like bear in bowl in a generic setting of of language processing or just animals um like

16:02.000 --> 16:08.000
cup and handle is a very is like a stock pattern so so the the world of finance has a ton of

16:08.000 --> 16:16.240
vocabulary that is very neat to um talking about finance itself so this is something we actually

16:16.240 --> 16:22.480
talk about at the talk uh in the training is this dealing with this domain specific language

16:22.480 --> 16:27.920
and tackling it through leveraging what we can from the open source community so there's a

16:27.920 --> 16:32.720
ton of pre-trained word vectors that exist out there but those might not get the job done when

16:32.720 --> 16:40.480
you have a domain specific language so we actually talked about the idea of starting with pre-trained

16:41.200 --> 16:47.280
word vectors but building on those through training additional word to vex on your

16:47.280 --> 16:53.520
corpus that's specific to your domain so maybe instead of seating like if you're going to train a

16:53.520 --> 16:59.760
word to vex model to get you know efficient representations of your language and your vocabulary

17:00.800 --> 17:06.000
instead of seating randomly you can see it with a pre-trained word vector maybe out of google

17:06.000 --> 17:13.360
news and then train over your corpus so that it can kind of start to learn um language that may

17:13.360 --> 17:20.240
exist in a pre-trained vector but can adjust that to specifically model your language inherently

17:20.240 --> 17:26.400
and you get a nice platform to jump off of because google's done a lot of like work to train

17:26.400 --> 17:34.000
vectors on billions and billions of news articles of the various uh pre-trained word vectors out

17:34.000 --> 17:40.240
there glove and google news and others uh is google news the one that closely most closely matched

17:40.240 --> 17:48.160
to your use case so we actually um like starting with the twitter glove vectors mostly because

17:48.160 --> 17:54.640
to capture like the syntactical nuances of how people talk in short form text over social media

17:54.640 --> 18:00.880
so we found we found that um the the twitter data glove was a good launching point and it's

18:00.880 --> 18:08.000
actually you wouldn't we saw a deep like pretty decent result just using those vectors alone

18:08.000 --> 18:13.920
so one of the takeaways um and something that i'd push to anyone who um um um talking to this stuff

18:13.920 --> 18:21.360
about it is there are people who are a lot smarter than me who have done a lot of legwork and um

18:21.360 --> 18:26.080
like us as practitioners are fortunate enough that they open that work for everyone else to use

18:26.080 --> 18:32.720
so even though stuff may not seem like it's applicable don't let that stand in your way to just

18:32.720 --> 18:39.680
get out there and getting started um training custom word vectors is no small task um it requires

18:39.680 --> 18:48.960
a ton of data it requires potentially days or weeks of training and that's the result of that

18:48.960 --> 18:53.840
you're not even positive if it's gonna make that big of a difference in your downstream modeling

18:53.840 --> 19:01.040
task so something we i like to stress is wherever you can start with like like stand on the shoulders

19:01.040 --> 19:08.400
of these giants who who did this work before us um and try to kind of start with that see where

19:08.400 --> 19:15.680
it gets you assess the situation and go on from there is there a method a method to do like composite

19:15.680 --> 19:21.680
training with multiple pre-trained word vectors like is there a way to combine glove and google news

19:23.440 --> 19:27.760
i haven't done anything like that i would imagine there could be some

19:27.760 --> 19:36.480
like meta modeling or on sampling on top of it where i this this may or may not exist there

19:36.480 --> 19:42.560
might be some research on top of this but i couldn't see why you couldn't maybe instead of

19:43.120 --> 19:48.400
you know in a traditional word-to-vec model that you're starting from scratch your input is a

19:48.400 --> 19:54.800
one-hot encoded vector of a word your output is one-hot encoded vectors of the context of that word

19:54.800 --> 20:03.200
um i could see maybe some method where the input is some like concatenation of like of existing

20:03.200 --> 20:09.440
word vectors and your kind of hidden layer is still learning like how to combine the best things

20:09.440 --> 20:14.480
from those existing word vectors to learn the context because at the end of the day what word to

20:14.480 --> 20:22.240
that what boils down to is we want to learn some efficient representation of words such that our

20:22.240 --> 20:28.640
representation reflects semantic and syntactic and contextual meaning across multiple words so

20:28.640 --> 20:35.920
i always like to say that the philosophy of word-to-vec is a quote from uh JR Firth who's a famous

20:35.920 --> 20:42.640
english linguist who said uh you shall judge a word by the company it keeps so that's that's

20:42.640 --> 20:48.880
basically the philosophy of word-to-vec is we just want to ultimately end up with representations

20:48.880 --> 20:56.720
that um kind of can be shared across syntactical meaning so if i have the word good and i have the

20:56.720 --> 21:04.080
word great i should have a representation of that word such that my LSTM model can leverage the

21:04.080 --> 21:09.040
fact that those words are similar to make the predictions that it needs to make so no matter

21:09.040 --> 21:14.720
what your input is that hidden layer by nature of the way you construct that that prediction test

21:14.720 --> 21:20.800
of predicting context it's going to force words that show up in similar context to have similar

21:20.800 --> 21:26.080
representations so i'd imagine if you start with pre-trained word vectors instead of one hot and

21:26.080 --> 21:31.680
coated it might be able to kind of pick out the best stuff even for your specific use case so

21:31.680 --> 21:36.560
that that could be a good approach maybe maybe we'll go back and i'll put that on our backlog to

21:36.560 --> 21:42.480
to experiment with you mentioned that uh you use specifically multi-layer LSTM what does the

21:42.480 --> 21:49.200
multi-layer refer to there so the multi-layer just stacks multiple LSTM layers on top of each

21:49.200 --> 21:56.480
other so something i stress in this training and and i think anyone who's kind of learning about

21:56.480 --> 22:02.720
LSTMs is there's a lot of things called like layers and like a lot of dimensions so like

22:02.720 --> 22:10.240
so like you have an LSTM cell with a hidden layer and then you might have multiple LSTM layers

22:10.240 --> 22:15.120
and then within each cell of an LSTM there's kind of like four layers that are doing their

22:15.120 --> 22:20.880
things to maintain the state and retain information from the past sequence so i try to when i'm

22:20.880 --> 22:26.000
doing this training make it super approachable like kind of make sure that people are understanding

22:26.000 --> 22:33.200
what that distinction is and so a hidden layer is just like some vector that lives inside the LSTM cell

22:33.200 --> 22:41.520
the four like feed forward layers in an LSTM cell are just kind of moving that state through

22:41.520 --> 22:48.480
different gates and through activation functions and when i say multi-layered network so now we're

22:48.480 --> 22:54.400
at a network level we're outside just a cell of an LSTM we're really talking about stacking two

22:54.400 --> 23:01.360
whole LSTM layers on top of each other so if you think of like a graph pointing upwards like you'd

23:01.360 --> 23:07.120
start with your embedding look up so you'd input your word at any time the first layer would be

23:07.120 --> 23:13.760
your embedding look up that embedding would get passed up to the first LSTM layer it would do its

23:13.760 --> 23:21.120
thing part of that is it would output the output from that LSTM layer then goes as the input of a

23:21.120 --> 23:28.480
second LSTM layer and then that LSTM layer does a thing then you take that last final state at the

23:28.480 --> 23:33.760
end of the sequence pass that up to your fully connected layer and do kind of your softmax

23:33.760 --> 23:39.040
prediction or your sigmoid prediction depending on how many levels you have so when when someone's

23:39.040 --> 23:46.960
referring to multi-layered LSTM network they're really referring to two steps of LSTM the first step

23:46.960 --> 23:52.880
where your input is actually the word vector associated with each word and the second layer is

23:52.880 --> 24:00.640
actually the LSTM output at that time being passed as the input to the next LSTM layer and how do

24:00.640 --> 24:05.840
you know when you need to do that what's the intuition for what these different layers are doing

24:05.840 --> 24:13.840
yeah so I'd say a lot of this is learned through observing what's happening cross validation

24:13.840 --> 24:23.520
performance on a validation set I do think there is this understanding of like the complexity

24:23.520 --> 24:30.800
and the nuance of the the text that you're working with basically all in LSTM is doing is it's

24:30.800 --> 24:36.800
trying to summer like trying to learn a state of your sentence that kind of summarizes all of

24:36.800 --> 24:42.720
this information and I know the word state can be so abstract so that I try to also stress like what

24:42.720 --> 24:50.400
that means when we say state basically we're trying to capture all of the semantic and contextual

24:50.400 --> 24:59.520
nuance of a sentence in like a 128-dimensional or 256-dimensional vector so your first LSTM

24:59.520 --> 25:05.600
network is going to learn a state such that you know maybe one dimension of that state refers to

25:05.600 --> 25:13.040
it was this sentence negated at any time another dimension or a linear combination of dimensions might

25:13.040 --> 25:18.720
say is the sentiment the last sentiment I saw bullish or bearish and then that state can kind of

25:18.720 --> 25:24.720
be combined and it's like okay like I saw bearish sentiment but I saw a negation so now I actually

25:24.720 --> 25:32.480
know to predict that this is something bullish and so stacking layers on top just continual like

25:32.480 --> 25:39.200
they they allow you to do more linear transformations on that state to try to learn a richer representation

25:39.920 --> 25:46.000
at the end of the day what matters is that your prediction test is as accurate as you need it to be

25:46.720 --> 25:53.840
so we're not going to you know pull out our LSTM states and examine them and be like okay like

25:53.840 --> 26:03.200
I can see everything I want to be represented so a lot of this comes down to cross like just like

26:03.200 --> 26:08.560
validation accuracy observing these things through training deep learning can be really tough

26:08.560 --> 26:14.800
to do this parameter tuning if you're a small company and you don't have a ton of GPU resources

26:14.800 --> 26:20.560
available to you these things can take a long time to train to be effective and some people can't

26:20.560 --> 26:27.840
just spin up like 10 concurrent GPUs and monitor all this stuff in as it's running so tensor board

26:27.840 --> 26:34.080
is is a great tool that we try to leverage where you can monitor something as it's training and if

26:34.080 --> 26:40.720
you can see like oh our law stopped going down you know let's cancel this and try something else

26:41.440 --> 26:45.760
so you can kind of see the model learning in real time you can benchmark it against like your

26:45.760 --> 26:50.240
current best model and if it's not on track to beat that you're saying okay like let's cut this

26:50.240 --> 26:58.560
training short try something new again I'd always recommend to start simpler maybe start with one

26:58.560 --> 27:04.080
layer get a baseline model if you need to tune that better start adding in more and more layers

27:04.080 --> 27:08.640
I would treat that architecture like you would treat any other hyper parameter that you're you're

27:08.640 --> 27:18.480
trying to tune and so the the the layers aren't differentiated anyway well of course there are

27:18.480 --> 27:23.840
their hyper parameters but other than that they're not you know fundamentally different they're

27:23.840 --> 27:28.480
just you know multiple LSTM layers stacked on one another fit or feeding into one another

27:29.360 --> 27:34.800
and like you said you treat it as a hyper parameter try adding another one how many what's the

27:34.800 --> 27:40.560
most number of stacked LSTM layers you've seen for what we do we've probably never

27:40.560 --> 27:46.640
explored anything more than three I'm not sure if other existing research out there like people

27:46.640 --> 27:52.480
using LSTMs for more complicated learning tests might be stacking on time of each other um

27:53.600 --> 28:00.160
bi-directional LSTMs is something else that we've explored and what we've found is actually

28:00.160 --> 28:05.920
if you choose to go with a bi-directional LSTM for those not familiar it's kind of a bi-directional

28:05.920 --> 28:12.960
LSTM is two LSTMs just one reads your input text forward to backwards the second reads your input

28:12.960 --> 28:18.320
text backwards to forwards so it would start with your last token in your sequence then read it

28:18.320 --> 28:25.440
backwards and then you'd kind of concatenate those into your output to pass up so we've found that

28:25.440 --> 28:31.840
bi-directional with smaller with a small with fewer actual layers stacked on top of each other

28:31.840 --> 28:39.440
can perform as good as a regular LSTM with layers stacked on top and it kind of makes sense because

28:39.440 --> 28:45.680
the goal what these LSTMs are trying to do is just learn this this representation and learn this

28:45.680 --> 28:52.160
state and passing in multiple layers you're kind of maybe maybe each network while they look

28:52.160 --> 28:57.360
the same they're learning different things so maybe you know the first LSTMs or like learning

28:57.360 --> 29:03.440
baseline state stuff the second LSTM is really taking that state and finding the interactions with

29:03.440 --> 29:09.440
each other and how how things in that state um we're working together to help in your prediction

29:09.440 --> 29:14.880
test a bi-directional LSTM can do that in fewer layers because it's kind of seeing the text twice

29:14.880 --> 29:20.800
so it's learning a state going forward it might be picking up on other nuances going backwards

29:20.800 --> 29:26.080
and then tying those things together where you where you can get away with the smaller

29:26.080 --> 29:32.320
architecture so LSTMs figure very prominently in the sentiment analysis that you're doing are there

29:32.320 --> 29:40.640
other techniques that you bring the bear yeah so something I get really excited about and this

29:40.640 --> 29:45.280
we're kind of just starting research on this it's kind of a future frontier where we're hoping to

29:45.280 --> 29:53.360
get to one of the main goals like I said before is we want to help people find what is relevant to

29:53.360 --> 30:00.240
them and wade through what seems like a suffocating amount of information to find what they need

30:00.880 --> 30:08.480
this actually aligns really well with a common problem in active investing where idea generation

30:08.480 --> 30:13.520
is almost parallelizing like it's really hard to get into investing because you need to kind of

30:13.520 --> 30:19.680
do the research come up with the ideas what do I want to invest in so to the extent that we can

30:19.680 --> 30:25.040
help people find individual stocks help people find individual content or help people connect with

30:25.040 --> 30:29.760
other people that will help them generate those ideas it's things that we're interested in so

30:30.640 --> 30:39.120
besides just sentiment we are looking at this is actually still related to we're exploring LSTMs

30:39.120 --> 30:43.920
we're exploring convolutional neural networks for this but doing more representation learning

30:44.560 --> 30:53.920
for the conversation going on or like between users on certain stock streams and we want to basically

30:53.920 --> 30:59.120
do this for recommendation purposes so this I think is this newer trend with neural networks and

30:59.120 --> 31:04.960
deep learning that we're seeing more recently where we have some prediction task we're learning

31:04.960 --> 31:10.960
is state so this this state might be like the the final hidden state in an LSTM it might be like

31:10.960 --> 31:16.960
the final fully connected layer in a convolutional neural network and you might be predicting something

31:16.960 --> 31:22.560
that thing could be arbitrary and at the end you're kind of like throwing that task away and you're

31:22.560 --> 31:28.480
left with this representation that you can put in an embedding space to kind of then do something

31:28.480 --> 31:35.040
like can yours neighbors to find similar things so through conversation we're trying we're exploring

31:35.040 --> 31:42.400
can we like embed like stock to its messages in a in a message space where we can see like the

31:42.400 --> 31:48.000
types of messages that a user typically likes to engage in maybe the types of stocks that they're

31:48.000 --> 31:53.760
engaging in maybe we have another embedding space around stocks that kind of can can say okay

31:53.760 --> 31:58.880
like you're interested in these stocks here are stocks that are similar based on this embedding

31:58.880 --> 32:04.880
and then find you know the best messages about that stock from from this message embedding space

32:04.880 --> 32:11.120
so we're exploring convolutional neural networks to basically not for a prediction task itself

32:11.120 --> 32:20.880
but to kind of create this this like embedded space of users of messages and of stocks themselves

32:20.880 --> 32:28.480
to kind of to to make recommendations and so in this case what's your input so the input would

32:28.480 --> 32:36.960
still be the text data itself so we and your convolutions are across the vectorized representation

32:36.960 --> 32:43.120
of the text input yeah so this is a technique there's a canonical paper that's convolutional

32:43.120 --> 32:48.800
neural networks for text it was kind of the first paper that explored this and basically we have a

32:48.800 --> 32:55.760
one-dimensional convolution so your input is exactly like you said it's a matrix two dimensions

32:57.280 --> 33:02.080
down the rows would be the words in your sequence across the columns is your

33:03.520 --> 33:10.480
each dimension of your word vector for that for that for each word and we do a one-dimensional

33:10.480 --> 33:17.360
convolution because we're just taking windows and sliding them down across the entire word embedding

33:17.360 --> 33:24.080
so you're kind of capturing features generated through words that appear next to each other

33:24.080 --> 33:29.120
and you would kind of have parallelized windows of different lengths just like you'd have filters

33:29.120 --> 33:35.680
of different sizes for for a two-dimensional convolution and this makes this intuitively this

33:35.680 --> 33:40.560
should make sense because when you're dealing with images in a convolutional neural network

33:40.560 --> 33:48.240
information is local to an individual pixel so an individual pixel is just one entry in your

33:48.240 --> 33:54.640
input matrix so when you have this two-dimensional window that you're sliding over it pixels go

33:54.640 --> 34:01.680
in both dimensions when you're dealing with text information isn't local to just like one

34:01.680 --> 34:09.440
dimension of your word embedding information about that word encompasses maybe like all 50 or

34:09.440 --> 34:14.640
250 dimensions of your word embedding so the one-dimensional convolution makes sense because

34:14.640 --> 34:20.720
you want to make sure when you're representing a word you're not excluding certain dimensions

34:20.720 --> 34:28.000
of your of your word embedding yeah interesting so are the network architectures here are

34:28.000 --> 34:34.160
these kind of simple CNNs or have complex network architectures like inception and all that kind

34:34.160 --> 34:41.920
of stuff evolve for textual data in my experience i've seen fairly simple sand ends we we would

34:41.920 --> 34:49.920
probably do maybe have four or five window lengths so like taking three word four word five word

34:49.920 --> 34:58.240
six word windows maybe have a hundred to a hundred and fifty filters of each size and then kind of

34:58.240 --> 35:06.160
branching off into like maybe those four or five parallel neural net like convolutional neural

35:06.160 --> 35:11.760
networks that then end up at some point like concatenating back together for like that last

35:11.760 --> 35:18.800
fully connected layer so it's i'd say it's it's a fairly simple architecture but you get a little

35:18.800 --> 35:25.600
bit additional complexity if you kind of are doing a couple different size filters in parallel

35:25.600 --> 35:30.480
and then kind of bringing them back together so i i'd think of it like four different CNNs

35:30.480 --> 35:35.760
each branching out their own direction and then ultimately coming together at some point to

35:35.760 --> 35:40.800
have a like a final prediction made i'm wondering if there are other tricks that you're kind of

35:40.800 --> 35:49.920
layering onto the CNNs to help here um no i mean we we're still pretty early in our research at

35:49.920 --> 35:56.320
stock puts on this so we're trying to start simple we drew a lot of inspiration actually from uh

35:56.320 --> 36:03.680
companies like Spotify who are using these types of methods to kind of do music recommendation

36:03.680 --> 36:13.120
and for us you know stocks are very similar to music um we so like you kind of have these like

36:13.120 --> 36:18.880
genres and and like playlist where you can kind of tie stocks together through conceptual

36:18.880 --> 36:25.520
themes so like stocks related to self-driving cars stocks related to AI tech stocks um you kind

36:25.520 --> 36:30.960
of have this engagement so like people are listening to different music people are like engaging

36:30.960 --> 36:37.280
in different stocks and then you actually have kind of a similarity for price movement of a stock

36:37.280 --> 36:44.880
like if you're analyzing music and you're actually looking like at the notes um like the the

36:44.880 --> 36:52.240
structure of a note or the structure of you know music at that level isn't that dissimilar to

36:52.240 --> 36:57.920
just like looking at a stock price change over time where like the the the chart is your your

36:57.920 --> 37:05.040
clout of it like the chart is um kind of your bars and like each time frame is kind of note so

37:05.040 --> 37:10.800
we try to draw inspiration from other leaders who are doing this type of work um so they they're

37:10.800 --> 37:16.960
probably quite a bit ahead of us they might be doing a little bit more complex things um but as far

37:16.960 --> 37:23.680
as CNNs we we try to keep it fairly simple okay so we've got LSTMs we've got CNNs are there other

37:23.680 --> 37:28.800
techniques that you tend to use to solve some of these problems yeah so another area that we're

37:28.800 --> 37:37.360
starting to research is tech summarization so like I said the streams the velocity is very very high

37:37.360 --> 37:44.000
information is coming through if if something is trending like if something crazy happened um

37:44.960 --> 37:51.920
for example like if Elon Musk is going off the deep end and and Tesla is tanking we may be seeing um

37:52.800 --> 38:00.880
like upwards of like 500 messages come in like a minute so it's it's kind of really hard for like

38:00.880 --> 38:06.880
maybe someone who hasn't developed a really refined process for how they like to use stock

38:06.880 --> 38:12.160
tweets to come on to stock tweets and not be overwhelmed by the sheer amount of information that

38:12.160 --> 38:19.280
they're seeing so so tech summarization is something that is super interesting to us um we curate

38:19.280 --> 38:25.280
news as well so news summarizations like a more well understood problem we're really curious can we

38:25.280 --> 38:31.440
apply those techniques to a stream where we can maybe extract the most important things that are

38:31.440 --> 38:37.360
going on in the last hour from what people are saying about the stock and and maybe have those

38:37.360 --> 38:43.360
as bullet points when you're going to the Tesla page the kind of ease in and still get okay what

38:43.360 --> 38:49.200
are people saying about this stock without you know being like oh man like there's just stuff

38:49.200 --> 38:55.200
coming in so fast I can't really deal with it so for our tech summarization we've been still focused

38:55.200 --> 39:02.000
in the RNN domain but more focused on kind of these in these sequence to sequence models so encoder

39:02.000 --> 39:09.280
decoder networks with um with attention uh and so how did what's the how do those work

39:10.080 --> 39:16.560
yeah so I believe it's even better how do you explain them how did you explain

39:16.560 --> 39:26.560
yeah yeah yeah yeah so RNNs are very robust they they there's a lot of different flavors of LSTN

39:26.560 --> 39:31.600
so when we're dealing with the sentiment classification problem we're dealing with kind of a

39:31.600 --> 39:39.440
many to one RNN where our input is many the different words in our sentence one at a time

39:39.440 --> 39:44.480
and then after we've seen all those words we want to make a single prediction um is this

39:44.480 --> 39:51.920
bullish as is neutral is this bearish when we're dealing with problems like text classification

39:51.920 --> 39:59.920
our input is a sequence and our output is a sequence so we're inputting the words of our original

39:59.920 --> 40:05.600
text let's just say we're dealing with the news article and then we want to output another

40:05.600 --> 40:13.120
sentence that is just a summary of that text so our output is um multiple tokens of our summary

40:13.120 --> 40:22.880
and so the way we can handle that is kind of stacking two RNNs on top of each other not like we did

40:22.880 --> 40:30.000
it before um but kind of letting it's referred to as an encoder decoder so we have a first RNN

40:30.000 --> 40:36.960
that's taking in our inputs um our input sequence and it's kind of learning a state of that input

40:36.960 --> 40:45.040
sequence and then we have a decoder RNN who is taking in that state from our encoder and kind

40:45.040 --> 40:50.480
of decoding that and picking what um kind of generating what what the best summary would be

40:51.120 --> 40:58.160
and in the past the original models of this had the encoder and the decoder talk directly to

40:58.160 --> 41:03.440
each other so the encoder would come up with a final state it would pass that final state to the

41:03.440 --> 41:09.040
decoder network that final state would be the initial input to the decoder network which would

41:09.040 --> 41:14.880
then kind of learn from like it would maintain its own internal state to try to say what word from

41:14.880 --> 41:21.120
my vocabulary has the best probability of being the next word so the decoder RNN is really trying

41:21.120 --> 41:27.440
to predict given the state that I have and what I just said the first word of this summary is

41:27.440 --> 41:34.080
what's going to be the next word in our summary so this is truly like language generative model

41:34.080 --> 41:39.440
language where we we have some vocabulary and we're trying to generate language that makes sense

41:40.400 --> 41:50.480
and this original model kind of had its drawbacks where we were asking a lot of the encoder RNN

41:50.480 --> 41:56.560
where we're saying encode everything that you have to say in this one final state that's

41:56.560 --> 42:02.560
going to be passed to the decoder network and it was actually I think neural machine translation

42:02.560 --> 42:08.400
that introduced this idea of attention and so now attention is this layer that lives between

42:08.400 --> 42:16.160
the encoder network and the decoder network that basically says at any point when we are decoding

42:16.160 --> 42:22.640
let me look back at the entire input sequence and let me focus on where in the input it is important

42:22.640 --> 42:28.560
for me to make my prediction on what the next word is going to be and how have you found this

42:30.160 --> 42:35.200
this model to perform for summarization do you have you gotten you're getting good summarization

42:35.200 --> 42:43.760
of we you can get pretty decent summarizations on news news is like a very well structured input a

42:43.760 --> 42:50.640
just random sequence of tweets is not very well structured so we're we still have quite a way to go

42:50.640 --> 42:57.920
before I think we get anything that that we would put into production for tweet summarization

42:57.920 --> 43:03.280
but and it's also you're you're not necessarily trying to summarize an individual tweet it's

43:03.280 --> 43:09.440
more like corpus summarization right you're trying to pick the main elements across multiple tweets

43:09.440 --> 43:15.600
and so I do like just concatenate them all together or is there some that that seems like you're

43:15.600 --> 43:22.000
losing something if you do that yeah so I think how we've approached it is we've tried to kind

43:22.000 --> 43:31.920
of explore with this idea of a three-dimensional input to your RNN so like traditionally inputs to

43:31.920 --> 43:39.040
RNNs are two to like two-dimensional respect that you have a sequence of words so your sequence

43:39.040 --> 43:43.920
of words is the first to mention your sentence could be 10 words and then each individual word

43:43.920 --> 43:51.360
that you're inputting is has like a one row with 300 columns of your word embedding so we were

43:51.360 --> 43:59.360
playing with kind of a three-dimensional input where your first sequence is a stream your second

43:59.360 --> 44:04.960
sequence is a tweet in the stream and like your third dimension is like the words in that tweet

44:04.960 --> 44:12.560
and I think you kind of hit the nail on the head where we are probably not being fair to our LSTM

44:12.560 --> 44:18.800
network we're probably asking it to do too much by trying to treat a stream like it is one cohesive

44:18.800 --> 44:27.200
document when in reality I think our next direction of research is gonna be more okay let maybe

44:27.200 --> 44:33.040
don't summarize a whole stream but can we pick out an individual tweet that we think is really

44:33.040 --> 44:39.280
good and let encompasses like a broader trend that we're seeing across multiple tweets so maybe

44:39.280 --> 44:46.000
it's not necessarily framing it directly like you would frame a news article summarization more

44:46.000 --> 44:53.600
framing it like a um still we're not generating new language but we're finding a tweet that is

44:53.600 --> 44:59.760
representative over like a broader concept that we can identify in a stream does transfer learning

44:59.760 --> 45:06.480
apply in the spaces at all like you know we've got the pre-trained love vectors and um it is

45:06.480 --> 45:12.960
there anything that can be used to accelerate a summarization task so that you're not pre-training

45:12.960 --> 45:17.440
everything from scratch yeah training everything from scratch yeah definitely so um

45:19.040 --> 45:26.320
the NLP community is starting to make like a lot like bigger strides in getting to effective

45:26.320 --> 45:31.920
transfer learning for language tests um I still don't think it's close to where the computer

45:31.920 --> 45:38.400
vision community is but progress is definitely being made um for for kind of generic things there are

45:38.960 --> 45:45.200
pre-trained models out there from they're not like they're not kind of like the computer vision

45:45.200 --> 45:51.120
where there's like these go-to trained models but you can find decent research out of there um

45:51.120 --> 45:57.280
there's a paper I really like um that I've drawn a lot of inspiration from from Abigail C

45:57.280 --> 46:06.400
on pointer networks and so pointer networks were um are this extension of just based like

46:06.400 --> 46:12.720
vanilla attention models where you're also kind of training this parameter called a pointer

46:12.720 --> 46:20.480
that's saying anywhere in when I'm predicting the next word in my summary do I want to just kind

46:20.480 --> 46:26.640
of generate a new word from my generic vocabulary or do I want to pick a specific word from the

46:26.640 --> 46:32.800
input text to use here so I think one of the biggest problems that people were seeing in summarization

46:32.800 --> 46:39.920
was that it was getting baseline facts wrong from from the input text um so like if I was

46:39.920 --> 46:46.000
summering a news article that Tesla dropped 10 percent pre-market the traditional techniques

46:46.000 --> 46:52.080
for having it like a tough time extracting that that 10 percent figure so this pointer can

46:52.080 --> 46:58.960
basically say okay like I know that I'm about to pull a figure out um I'm going to grab I'm

46:58.960 --> 47:06.000
going to grab um vocab from my source text and not try to like pick a needle out of a haystack

47:06.000 --> 47:11.360
of what this metric might be from like all the metrics I've ever seen that live in my vocabulary

47:11.360 --> 47:16.640
and is this all deep learning based or is there like some tokenization entity resolution that kind

47:16.640 --> 47:24.240
of thing happening up front um I believe it's all it's end-to-end deep learning based yeah so I

47:24.240 --> 47:30.720
think there's um I'm not sure what they used for the word vectors or if if the word vectors are

47:30.720 --> 47:35.760
just learned in an end-to-end fashion but there is a pre-trained model out there like they

47:35.760 --> 47:41.200
wrote they open source to all the code from this model it was trained on CNN and daily news data

47:41.200 --> 47:47.760
um and so there is a pre-trained model out there that exists that that was kind of our first step

47:47.760 --> 47:53.840
of saying okay like if we just took this model and ran financial news through it would we would

47:53.840 --> 48:00.000
we get anything like would it be able to be applied I also think you could kind of use that

48:00.000 --> 48:06.240
model as a baseline and then retrain on your specific data I do think in our case of like trying

48:06.240 --> 48:11.520
to summarize tweets we're kind of starting from scratch I don't know how much how much transfer

48:11.520 --> 48:20.080
learning is there I think the where transfer learning comes into play for NLP is really can we learn

48:20.880 --> 48:27.840
like do we have greater representations for more generic text at like a high level language modeling

48:27.840 --> 48:34.000
text so I think when you're getting to like generative language I see the future of transfer learning

48:34.000 --> 48:39.840
in NLP being like okay here are these good models that kind of like help us generate text so like

48:39.840 --> 48:45.680
they learn kind of just like the state of like a pre-trained model for computer vision is kind of

48:45.680 --> 48:52.160
learn these nice feature representations for different like parts of an image or different objects

48:52.160 --> 48:58.480
that appear in an image can we learn just like really good generic representations for how

48:58.480 --> 49:05.440
text interacts with each other how words interact with each other to generate like sentences and

49:05.440 --> 49:10.640
language that makes sense and then starting with those representations is kind of to be the first

49:10.640 --> 49:16.400
steps of your your model and and build maybe many models on top of that if that makes sense no it

49:16.400 --> 49:24.000
does it does okay this has been great are there any kind of words of inspiration or wisdom that

49:24.000 --> 49:32.080
you would leave with folks who want to start exploring some of these techniques more my best advice

49:32.080 --> 49:39.600
would be dive in I think you can spend months probably even years at this point with all the

49:39.600 --> 49:44.800
information that's out there trying to learn trying to figure out exactly what's going on trying

49:44.800 --> 49:51.280
to just become an expert but really no one's an expert we're we're applying these methods to new

49:51.280 --> 49:56.080
problems that really don't necessarily have a solution they have like the best solution that we

49:56.080 --> 50:03.760
have for them today and you're really not going to you're really not going to be able to know

50:03.760 --> 50:08.720
everything before you dive in you're going to learn a lot as you're going so so my advice would be

50:08.720 --> 50:16.000
you know don't be afraid the the training I offer tries to kind of make deep learning methods

50:16.000 --> 50:21.840
accessible because I think once you dive in you'll you'll realize that deep learning isn't that

50:21.840 --> 50:28.160
far of a jump from what you're doing today so yeah just don't be afraid just dive in head first

50:28.160 --> 50:35.280
well said and you you mentioned that the you've got code from your training in a repository and

50:35.280 --> 50:39.200
the slides and all that kind of stuff and you'll get that link to me we'll get that link on the

50:39.200 --> 50:44.800
show notes page anyone that wants to to follow along with the material that you presented they'll

50:44.800 --> 50:50.400
be able to do it there yep we'll do awesome thanks so much guys thanks for having us and it's been great

50:56.000 --> 51:01.280
all right everyone that's our show for today for more information on Garrett or any of the topics

51:01.280 --> 51:08.880
covering in this episode head over to twimmel ai.com slash talk slash 194 if you're a fan of the pod

51:08.880 --> 51:13.920
we'd like to encourage you to visit your apple or google podcast app and leave us a five star

51:13.920 --> 51:18.880
rating and review your reviews help inspire us to create more and better content and they help

51:18.880 --> 51:24.400
new listeners find the show thanks again to our friends at IBM for their sponsorship of this

51:24.400 --> 51:32.320
episode be sure to check out IBM developer at IBM dot biz slash ml ai podcast as always thanks

51:32.320 --> 51:44.080
so much for listening and catch you next time

