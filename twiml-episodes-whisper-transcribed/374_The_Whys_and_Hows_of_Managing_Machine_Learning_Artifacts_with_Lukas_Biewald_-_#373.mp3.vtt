WEBVTT

00:00.000 --> 00:12.800
Welcome to the Twimal AI Podcast. I'm your host, Sam Charrington.

00:12.800 --> 00:17.520
Hey, what's up everyone. Thanks for joining us for today's Twimal AI Podcast

00:17.520 --> 00:24.080
viewing party in Q&A with Lucas B. Wald, founder of Weights and Biases. Of course, I'm your host,

00:24.080 --> 00:29.760
Sam Charrington. While this is a pre-recorded conversation, Lucas and I are waiting for you

00:29.760 --> 00:36.400
in the live chat. There? Or maybe there? And we encourage you to reach out with your questions

00:36.400 --> 00:40.640
while we're all here together. Weights and Biases provides a great lightweight toolkit for

00:40.640 --> 00:45.120
machine learning practitioners and we thank them for sponsoring today's show. We've used it for

00:45.120 --> 00:49.200
quite a while in the Twimal community as part of our various study groups and have found it

00:49.200 --> 00:53.920
super useful for experiment tracking and collaboration. Now that they're offering dataset

00:53.920 --> 00:58.480
versioning and model management capabilities as well, you've got a one-stop shop for managing

00:58.480 --> 01:03.600
and visualizing your complete machine learning pipeline. If you'd like to learn more, Weights and

01:03.600 --> 01:09.440
Biases is extending a special offer to Twimal listeners and viewers, including unlimited private

01:09.440 --> 01:18.880
projects and priority support. For more details, visit wnb.com slash Twimal. It's w-a-n-d-b.com slash

01:18.880 --> 01:26.400
Twimal. And now on to the party. All right, everyone. I am here with Lucas B. Wald. Lucas is the CEO

01:26.400 --> 01:32.000
and co-founder of Weights and Biases. If Lucas is named sound familiar, that's because we

01:32.880 --> 01:42.000
spoke last on the podcast in August of last year, 2019, episode 295 on managing deep learning

01:42.000 --> 01:49.120
experiments. Lucas, welcome back to the Twimal AI podcast. Thanks, Sam. It's great to be back.

01:49.120 --> 01:55.840
Lucas, if folks want to catch your background, they can check out that episode and we'll link to it

01:55.840 --> 02:03.520
in the show notes. But what have you been up to since last August? I know one big thing has

02:03.520 --> 02:12.720
changed for you. Well, I had a baby. Definitely has changed my life in priorities. Maybe more

02:12.720 --> 02:19.680
work relevant, we've been working on improving the product. And I think one of the reasons I

02:19.680 --> 02:27.440
wanted to talk to you come back on your show is we just recently put out a new product called

02:27.440 --> 02:34.240
Weights and Biases artifacts that we're super excited about. Yep, and that's what we'll

02:34.240 --> 02:41.920
spend our time talking about. Tell us a little bit about the problem that you're trying to solve

02:41.920 --> 02:48.160
with artifacts. Totally, yeah. I mean, you always have such good, what did you call it? You have

02:48.160 --> 02:53.280
such good diagrams, sort of like laying out all the different pieces in the industry. I kind of,

02:53.280 --> 03:00.560
I'd love to know how it exactly fits into your diagram because it's always, it's always insightful

03:00.560 --> 03:08.880
to see that. I think you're referring to the the ebook definitive guide to machine learning

03:08.880 --> 03:16.240
platforms. And I broke out kind of at least my view of the ML tooling and platform landscaping into

03:16.240 --> 03:25.200
data acquisition and management, experimentation, and model development, and then model deployment

03:25.200 --> 03:32.000
and management. And so I would think is artifacts in the the middle of those two or the last of

03:32.000 --> 03:35.840
those two or it is a straddle? Well, I think it might kind of straddle. So let me sort of tell you

03:35.840 --> 03:39.280
the problem that we were trying to solve and you tell me how we should, how we should.

03:39.280 --> 03:48.320
So basically what happened was our experiment tracking platform, I mean, we feel super proud of

03:48.320 --> 03:53.440
it. It's been really popular. It's had faster growth than anything that I've been a part of.

03:54.320 --> 04:01.520
And so we're constantly asking our users, what else do you want? What does it feel like it's missing?

04:02.240 --> 04:08.640
And the biggest request was, from what users, we'll look like this is tracking all the experiments

04:08.640 --> 04:14.720
I do and I can compare all the models I build. But in reality, there's kind of other things that are

04:14.720 --> 04:20.320
really important for me to track. Like I want to track my data sets and I want to check the models.

04:20.320 --> 04:26.560
And I also kind of want to, in some cases, like connect steps together in kind of like a pipeline.

04:28.400 --> 04:34.480
And so, you know, we build artifacts as like in an adjacent product that's that's separate because

04:34.480 --> 04:38.720
we think that, you know, we want to keep our experiment tracking a really tight point solution that's

04:38.720 --> 04:44.160
really good. But we also want to make it really easy to kind of track, you know, more things that

04:44.160 --> 04:48.080
that you might care about. And you know, the main things, like I said, are probably data sets,

04:50.080 --> 04:56.320
models and pipelines. It's important to note, I think some people kind of compare us with like,

04:57.120 --> 05:02.240
like looked at my overview and they say, well, how is it different than something like airflow

05:02.240 --> 05:06.160
that like manages pipelines? And I think it's important to say really different, right? It just

05:06.880 --> 05:10.960
tracks it. So what it would do is like, you know, say you, you know, you have some

05:11.920 --> 05:16.800
set of data and you do some transform on it and then maybe you train a model and then maybe you

05:16.800 --> 05:21.920
like, you know, test that model on a couple different data sets and then maybe you do some quantization

05:21.920 --> 05:27.680
and then you deploy it. What W and B artifacts would do is it would basically save all those

05:27.680 --> 05:34.080
steps and save the fact that they're all connected together. So, you know, sometimes a lot like

05:34.080 --> 05:50.240
management is the difference that you're not the state machine or the graph, you're not managing

05:50.240 --> 05:56.240
that, you're not standing that up, they need an airflow or Luigi or something else that is

05:56.240 --> 06:04.480
actually tracking the state of all the objects in this pipeline and you are kind of doing what you,

06:04.480 --> 06:10.000
something similar to what you did with the experiment management product where you're,

06:11.840 --> 06:15.040
you know, capturing metrics of things as they move through this process.

06:15.840 --> 06:19.760
Yeah, and saving it, right? So, you know, if you want to save something like your data set

06:20.640 --> 06:25.520
or your model, we make it really easy for you to save it and version it. But then what a lot of

06:25.520 --> 06:29.600
our users asked for is, hey, we just want to track it. We don't want to necessarily like,

06:29.600 --> 06:34.000
you know, upload these gigantic files to your servers like we have them in a bucket somewhere,

06:34.000 --> 06:41.920
we have them on prem. And so, you know, we let you, you know, save a pointer to those things

06:42.640 --> 06:49.120
if you want to. So, you know, I think, I think model management and data set management is maybe

06:49.120 --> 06:55.120
the best way of thinking about it. I mean, I think what I know for sure is that, you know,

06:55.120 --> 06:59.920
everybody's asking us for this, so it must be, if it's not a category now, I think it's going to

06:59.920 --> 07:05.360
become a category. And there's certainly lots of tools that, you know, there's lots of tools

07:05.360 --> 07:09.360
that do pieces of this. And in some cases, like, you know, have, you know, are more ambitious

07:10.240 --> 07:13.920
than this. And it's really important to us that we work nicely with all these things. I mean,

07:13.920 --> 07:20.960
you have such a great dichotomy of sort of like, you know, sort of n10 platforms and, you know,

07:20.960 --> 07:27.120
point solutions. And, you know, one of our real core values at which advice is to be, you know,

07:27.120 --> 07:31.920
a set of interoperable point solutions that do kind of one thing really well and play nicely

07:32.560 --> 07:41.760
with all the things around it. So, let me try to put that together. The kind of core problem

07:41.760 --> 07:47.120
that you're trying to solve here is you come at it from the perspective of, again,

07:47.120 --> 07:53.440
experiment management where you had folks using your tools to track different experiments that

07:53.440 --> 07:59.680
they were running as part of their model development process. But you found that that

08:00.480 --> 08:07.520
component was used as part of a pipeline where they were getting data from somewhere. They would

08:07.520 --> 08:13.200
run it through multiple, some series of transformations. And then ultimately run an experiment.

08:13.200 --> 08:23.840
And folks wanted to track more of that process so that, yeah, I often talk to folks that are

08:23.840 --> 08:30.800
trying to do kind of providence solve this data providence problem or decision providence even

08:30.800 --> 08:38.640
where you've got a model that makes an inference and you want to kind of go all the way back from

08:38.640 --> 08:46.320
that inference, the decision to, you know, the model that was deployed, you know, the experiment

08:46.320 --> 08:52.240
that said that that model was the best model, the data that, you know, started in a training set

08:52.240 --> 08:57.680
that, you know, allowed you to train up that model that won. And, you know, the data points

08:57.680 --> 09:01.680
to influence, you know, ultimately the data points that influenced this decision. And it sounds

09:01.680 --> 09:07.280
like you're trying to solve more of that problem than you were doing before. Yeah, and I think like,

09:07.280 --> 09:13.280
you know, there's lots of really like interesting, you know, pain points here that people talk

09:13.280 --> 09:17.600
about all the time, like, you know, model explainability and model reproducibility. And those are

09:17.600 --> 09:23.120
obviously there, they're like huge problems. But I think like the sort of core thing that

09:23.120 --> 09:30.000
we see a lot of our users struggling with is just literally knowing, you know, what data set

09:30.000 --> 09:33.840
the model got trained on and what data said actually or what model actually got deployed into

09:33.840 --> 09:38.480
production. So, so that's like the core focus we have. Like, you know, we work with, you know,

09:38.480 --> 09:43.200
work with a couple of companies that do, you know, kind of retail and are trying to build systems

09:43.200 --> 09:48.800
that, you know, automatically, you know, can like detect like, you know, what you're buying as you

09:48.800 --> 09:53.520
walk out like the Amazon store. And, and, you know, one of the things that those companies

09:53.520 --> 09:56.880
all have in common is they're like constantly getting new label data, right? Because they have,

09:56.880 --> 10:01.680
you know, cashiers in their store that are labeling the data live. And they often have,

10:01.680 --> 10:06.000
they always have new products coming in, right? And so, um, what happens with them is that

10:06.560 --> 10:12.240
they really like never train the models on the same, um, data set, right? So it's actually like

10:12.240 --> 10:16.800
every single time it trains is sort of like a different basket of stuff that the models get, um,

10:16.800 --> 10:21.520
trained on. So not just incremental growth of their training data set, but they're, it's just

10:21.520 --> 10:25.680
different. It's just it, well, yeah, actually in that case, it's incremental growth. I'll say,

10:25.680 --> 10:30.400
okay, we have actually have the opposite thing where it's not incremental growth, it's actually

10:30.400 --> 10:35.600
shrinking. So, you know, some of our customers get, um, kind of privacy takedowns, right? Where,

10:35.600 --> 10:40.160
you know, people will say, um, you actually one, one company we're going to talk to,

10:40.160 --> 10:44.000
this is iRobot, right? Where, you know, people say, hey, take my data set out of, you know,

10:44.000 --> 10:48.640
iRobot data set, of course, they do that, right? But then what happens is now your,

10:48.640 --> 10:53.920
your data set has, um, you know, slightly changed, right? So it's not exactly, um,

10:53.920 --> 11:00.560
um, you know, apples to apples, um, maybe, right? Maybe it's okay, but, um, but, you know, like,

11:00.560 --> 11:07.600
I think that the overhead, it sounds simple, maybe to, to track all that, um, but the important

11:07.600 --> 11:10.560
thing is that you really, really have to do it, right? Like, you have to have a system where

11:10.560 --> 11:14.960
you're always tracking it the same way so that when you do this comparison, it's really easy to say,

11:15.760 --> 11:20.880
um, you know, which is which. I'll say, like another issue, um, is like with our, you know,

11:20.880 --> 11:25.760
a ton of vehicle companies, they don't, they have actually so much data, typically,

11:26.320 --> 11:30.480
um, that they, they never trend in all their data, right? So they're, they're actually,

11:30.480 --> 11:34.800
every time they build a model, they're like selecting pieces of it, um, and they're often selecting

11:34.800 --> 11:39.120
different pieces, like, for different purposes. So I guess like, you know, in some cases of

11:39.120 --> 11:43.120
data sets growing, in some cases it's shrinking, in some cases you're like picking and choosing

11:43.120 --> 11:49.440
from different, um, data sets, but in all these cases, um, you know, we think the really like

11:49.440 --> 11:54.800
core need here, or the, the, the pain that we want to solve is just like, we will keep track of what

11:56.080 --> 12:02.320
data sets your, your model was trained on. And then there's another, like, interesting thing,

12:02.320 --> 12:06.560
which is that, um, you know, data sets have these like pipelines where they might get modified,

12:06.560 --> 12:11.840
and those pipelines can change, right? So, um, you know, with our medical, uh, users,

12:12.400 --> 12:16.480
they often have really small data sets, like, you know, some of our, you know, some of our medical

12:16.480 --> 12:21.280
customers, like, they might say, we have this, we have big data, we have like 1000, you know,

12:21.280 --> 12:26.320
but it's like 3000, like, you know, like, um, chest x-rays, and somebody with like a horrible,

12:26.320 --> 12:30.240
you know, it's like a kind of, you know, must have been like a huge feat, um, you know, to,

12:30.240 --> 12:35.840
to get that data. Um, and so like, what they will do, like, a lot of, um, pre-processing, right?

12:35.840 --> 12:40.720
Because every record is so precious, right? So the, the pre-processing steps almost become,

12:41.600 --> 12:46.080
um, maybe more important than the, the sort of like, model architecture itself, right?

12:46.080 --> 12:50.320
So, you know, it's really important for them to, to track that. And we started to see,

12:50.880 --> 12:55.280
we started to see our users actually kind of, as an entrepreneur, this is like a real sign that,

12:55.280 --> 12:59.280
you know, you know, from the fixer. So we still, I use this sort of like, you know, kind of clinging

12:59.280 --> 13:04.240
together, um, you know, they're, they're sort of like, chains of runs, uh, or, you know,

13:04.240 --> 13:09.280
we call them runs, like, experiments in our, in our tool. Um, and so now we've kind of made that,

13:09.280 --> 13:13.120
with, with the artifact product, we made that like a first-class citizen, where you can say,

13:13.120 --> 13:18.160
you know, okay, I have these asynchronous, you know, steps that I do, um, and it might be some,

13:18.160 --> 13:24.000
you know, complicated pre-processing and then a training. And then sometimes even, um, you know,

13:24.000 --> 13:29.120
like, uh, autonomous vehicles are places that come to mind. You know, the model that you train might

13:29.120 --> 13:34.560
not really be the model you deploy, right? Because you might have to do like a whole bunch of, um,

13:34.560 --> 13:39.120
you know, kind of shrinking of your model to like, to get it to actually run. Um, or so you might

13:39.120 --> 13:45.760
have like tests that you do on the model that got trained, but then you also have, you know, more tests

13:45.760 --> 13:51.520
that you do on the model sort of just before it's deployed. And these might even be like different

13:51.520 --> 13:58.800
teams doing it. So, um, you know, connecting all these different steps, um, in a sane way actually

13:58.800 --> 14:03.280
becomes like a, you know, I think a bigger, um, a bigger problem than you might think if you're,

14:03.280 --> 14:08.240
you know, just like start now, you know, training like M-ness to, you know, a couple of times. Uh-huh. And

14:08.240 --> 14:16.640
so the, I'm curious to hear about the things that they were doing before to clooge it together.

14:17.280 --> 14:21.360
What did that look like? So I only used clooge with, with my own product, because that's the only

14:21.360 --> 14:25.040
place that I, I feel like I can actually say for sure it's clooching, right? So, you know,

14:25.040 --> 14:33.200
you know, you know, you know, you know, you know, you know, you know, you know, you could think about

14:33.200 --> 14:37.760
like, you could just sort of like name things. I was envisioning like, you know, what the way

14:37.760 --> 14:43.440
you would see folks managing experiments by putting hyperparameters and filenames. Like, is it?

14:43.440 --> 14:48.080
Yeah. Well, really common hyperparameter in ways and biases is like, you know, the, the

14:48.080 --> 14:54.320
filename of the, um, the training data, right? And so, um, you know, it's like, that's a great thing

14:54.320 --> 14:57.840
to do. For us, as people want to train there, people want to keep track of their training data

14:57.840 --> 15:02.160
and giving them a way to do it. Exactly. And we're like telling people, hey,

15:02.160 --> 15:07.920
use weights and biases because we don't think it's a good idea to use your, um, file system is like

15:07.920 --> 15:12.960
an implicit record of what you did, right? But then, you know, we're like kind of causing people to

15:12.960 --> 15:18.960
do that in some, um, in some cases, right? So that, that, you know, so yeah, so, so, you know,

15:18.960 --> 15:23.200
you can use the file, you can use like a, a Shah, you know, the file if you want to make sure that it,

15:23.920 --> 15:28.400
it doesn't change. And then there's like a whole bunch of, um, there was a whole bunch of like

15:28.400 --> 15:33.120
interesting tools out there that are like, kind of always evolving and improving, right? There's like,

15:33.120 --> 15:37.760
you know, DVC and pack-a-derm and quilt that do, um, you know, really interesting takes on

15:37.760 --> 15:43.040
sort of data set, um, versioning. And we've done, you know, light integrations with these tools

15:43.040 --> 15:49.120
to kind of make them work, um, with what we have. And then, you know, end-to-end platforms, um,

15:49.120 --> 15:54.960
you know, if you really buy into there, pause there for a second. Yeah. We're doing the, so you

15:54.960 --> 16:01.760
saw folks doing the cluages indicating that they wanted to better track training data. Um, and

16:02.720 --> 16:10.320
it sounds like also the light integrations and, and kind of joint customer work you were doing

16:10.320 --> 16:15.360
with the DVC's and pack-a-derms of the light and these other end-to-end platforms kind of indicated

16:15.360 --> 16:23.440
that, um, I was actually going to ask about that. The, the DVC's and the pack-a-derms of the world are

16:23.440 --> 16:30.640
trying to, uh, that's kind of their, that's their world, right? They're trying to help customers

16:30.640 --> 16:38.800
better track the evolution of training data through transformation processes and, and up to,

16:38.800 --> 16:44.160
up to, and in some cases, including training. All right. And so where do, where does what they're

16:44.160 --> 16:52.960
doing end and what you're doing start? Or are they kind of overlapping like our customers having

16:52.960 --> 16:58.880
to make decisions about, um, you know, which part of which product they want to use for,

17:00.080 --> 17:04.320
which part of the process? Like, it seems like there's some overlap there that I'm trying to thank.

17:04.320 --> 17:12.000
Oh yeah. So there's clearly some overlap and I feel like, um, there's probably, you know,

17:12.000 --> 17:18.240
like we're recording this one April, April 2020. I haven't feeling, you know, like June 2020,

17:18.240 --> 17:24.080
the overlap, you know, it could be more or less a different, um, you know, so like, I think that,

17:26.080 --> 17:31.840
you know, I think like one, you know, one thing, I feel super committed to making our product work

17:31.840 --> 17:36.560
with, um, kind of all the best in class tools. It's like really, really important to me. So,

17:36.560 --> 17:42.400
you know, I think that if, um, you know, if, if DVC or pack-a-derm, you know, solved all the

17:42.400 --> 17:47.840
problems that the customers were having around this, you know, we would just, you know, let them and focus on

17:48.800 --> 17:55.520
experiment tracking. I think that, you know, I think the issue, um, I think that the sort of thing

17:55.520 --> 18:01.760
that we keep finding is that, you know, it kind of reminds me of actually, um, hyper parameter search,

18:01.760 --> 18:06.560
which we also didn't expect to roll out a hyper parameter, um, search tool, but we kept, you know,

18:06.560 --> 18:10.800
we kept talking to customers and like, ah, like, I know what should be doing this, but, you know,

18:10.800 --> 18:15.680
it's like, like, I can't quite figure out how to do it. You know, and so, you know, kind of articles,

18:15.680 --> 18:21.200
like, let's make hyper parameter search just so, like, simple. I mean, that's this really easy,

18:21.200 --> 18:25.680
not like a toy, but just like, make actually the powerful, like, make it easy to make it work in

18:25.680 --> 18:31.280
a distributed fashion on lots of data and really reliable. That's sort of like our, um, you know,

18:31.280 --> 18:35.840
point of view is like, let's just like really make it, um, you know, like, like a solid product of

18:35.840 --> 18:39.840
the easy onboarding. And so, kind of felt the same way with this data set versioning stuff, where we

18:39.840 --> 18:46.320
would, you know, we were pointing people to, um, these different products. And I think that they are,

18:46.320 --> 18:49.920
I think they're a pretty steep learning curve, um, honestly. I mean, it's not like a knock on the,

18:49.920 --> 18:54.320
these are really like, you know, it's kind of complicated stuff and it's hard to get it, um,

18:55.120 --> 18:59.040
you know, it's hard to make it like really easy to, to use, but I think like, that's where I think,

18:59.040 --> 19:06.400
like, because we're like totally focused on, um, making ML researchers and practitioners happy,

19:06.400 --> 19:12.080
I think Winston-Biasis has a much more narrow, um, you know, scope here. Like we're, we're, you know,

19:12.080 --> 19:15.920
I think like, you know, DBC is like native virtual, right? So it's like, there's actually a lot of

19:15.920 --> 19:21.760
different situations you might get into and like, you know, they, they use like, um, I mean, they use

19:21.760 --> 19:26.880
Git and I, you know, I love, do I love Git? I don't know, I kind of love Git. I make a little,

19:26.880 --> 19:34.880
we all have the idea of Git until we need to do something monkey. I imagine like 2021 Lucas,

19:34.880 --> 19:40.800
just totally understands Git and, you know, it's like, but like, 2020 Lucas kind of types and commands,

19:41.520 --> 19:48.640
kind of like feels a little afraid, you know, and that's how, you know, I hope I'm not back

19:48.640 --> 19:52.400
to just doing my tools, I can tool for like idiots. I mean, it's a tool for, you know, ML researchers

19:52.400 --> 19:57.440
who want to do ML research, right? Not like, um, and we know that like, some of them are really deep

19:57.440 --> 20:01.920
on Git, but we don't want to necessarily, we want to hide as much complexity as possible and solve

20:01.920 --> 20:06.720
the core pain point, which I think really here is. I think what you're getting at there is that the

20:07.840 --> 20:18.080
DVC and, and Packaderm as examples are, uh, and some of the, and the platforms there are actually

20:18.080 --> 20:25.520
versioning the data and snapshotting the data as it, uh, transitions through a transformation process

20:25.520 --> 20:30.960
and they can, you know, go to any point in time and any place in a process and allow you to see

20:30.960 --> 20:35.920
the data as it was transformed and that's not quite what you're trying to do. Well, I just say,

20:35.920 --> 20:42.640
we do version, we do version actual data itself. Well, in a really simple way, we make copies of it

20:42.640 --> 20:47.840
and we save them. So, you know, like, like, you know, that's why again, like, you know, it's like,

20:47.840 --> 20:52.960
we keep pointers to, to different places your data was at and we let you like, split it into pieces

20:52.960 --> 20:58.080
if, if, if you think those are going to change, but I think we are not as concerned with making

20:58.080 --> 21:05.760
like really kind of sophisticated dipping. Yeah, the sort of thinking being that, um, you know,

21:05.760 --> 21:11.520
space is pretty cheap and the really important thing is that people actually, um, you know, save

21:11.520 --> 21:16.160
this stuff. And then we just, that's like our first. And if, if, you know, of course, if customers

21:16.720 --> 21:20.480
like really, really want like sophisticated dipping and that's like, you know, necessary,

21:21.520 --> 21:25.120
you know, we'll find a way to, to do it for them. But, you know, the product doesn't exist

21:25.120 --> 21:31.120
today. The idea is just like, you know, you tag every state of your data, um, and, and you can

21:31.120 --> 21:35.600
keep uploading it to us if you want to. Um, and of course, if you, if you use the same exact data

21:35.600 --> 21:40.160
in two different places, we're not going to make two, um, you know, copies of it. But I think,

21:40.960 --> 21:44.960
you know, we're not like using Git in the back end, you know, for example. Got it. Got it. So,

21:44.960 --> 21:54.000
you referenced earlier this, um, it's almost a, uh, I think I gave more energy to it, uh,

21:54.000 --> 22:00.160
in the book, the definitive guide to ML platforms. It wasn't quite a throwaway comment or a footnote.

22:00.160 --> 22:06.720
I, I spent some time with it in the last chapter of the book, but it was this idea, um, that I

22:06.720 --> 22:13.360
proposed of the wide versus deep paradox for machine learning, you know, platform and tool vendors.

22:13.360 --> 22:19.440
And this conversation is such a great example of it. Uh, the, the, the general argument for folks

22:19.440 --> 22:25.920
that haven't, um, taken a look at the book is that you've got these end and platforms that are

22:25.920 --> 22:33.920
trying to kind of own the entire machine learning process at an enterprise. Um, and,

22:35.680 --> 22:41.200
you know, if you start from, from that perspective, you know, you can end up with a simplistic

22:41.200 --> 22:47.040
solution that really is just a workflow engine that's very shallow, you know, in functionality

22:47.040 --> 22:54.720
at any particular point. And you've got specialist providers, um, who, you know, any point in that,

22:54.720 --> 22:59.120
in the end process, have gone very deep, for example, waste and biases went very deep on

22:59.120 --> 23:04.720
experiment management as their initial play. And, and the paradox, the paradoxical element of

23:04.720 --> 23:12.880
this was that the, in the end providers, you know, as we have seen, we've got a lot of end-to-end

23:12.880 --> 23:18.880
solutions and, you know, without going deep in any particular area, that tends to get commoditized.

23:19.920 --> 23:26.960
Uh, and the, uh, and so they're getting kind of pushed to specialize or differentiate in, in a

23:26.960 --> 23:33.280
slice or, you know, particular functionality. Uh, and then with the narrow, uh, providers,

23:33.280 --> 23:38.320
the specialists, you know, they're going in, they're finding that, you know, customers have all

23:38.320 --> 23:43.600
these other gaps that they need to fill in order to get value out of the core product. And so they're

23:43.600 --> 23:51.440
being pushed wider. So you've got these two kind of sides kind of, uh, converging in the middle,

23:51.440 --> 23:56.880
perhaps, uh, or in different directions. And this is such a great example of that. Yeah.

23:56.880 --> 24:03.040
Like you started in the middle, you've got the, the data side. I think you, you mentioned, uh,

24:03.040 --> 24:09.600
extending into the hyper parameter optimization piece. Uh, um, are you working on model deployment

24:09.600 --> 24:16.560
management at all? Uh, we, we, we play with the stuff we, we dabble, we dabble in the sense that

24:16.560 --> 24:21.920
I think like what, what I want, I mean, I, I feel like what I want weights and biases to be

24:21.920 --> 24:26.320
note, like what I want our, our take to be is like, you know, we're not, we don't have like a, um,

24:26.320 --> 24:32.880
we don't know like a, like a, we want to make good tools for people doing, um, machine learning

24:32.880 --> 24:37.280
that they're actually going to use and, and really want, right? So that's sort of like our, our,

24:37.280 --> 24:41.360
our process is like, you know, we spend a ton of time with our customers and we ask them,

24:42.080 --> 24:47.840
you know, what do you need? Whereas I feel like, you know, um, I, I feel like there's a surprising

24:47.840 --> 24:52.560
number of companies that it sort of seems like they have sort of like these grand plans that sort of

24:52.560 --> 24:59.920
make sense in a PowerPoint, um, but then don't really fit what people want. So anytime they're sort

24:59.920 --> 25:04.400
of like, you know, business strategy question, and it's like at all in conflict with what, um,

25:04.400 --> 25:08.880
customers are asking for, like, I'm going to do what people are actually asking for, like, you know,

25:08.880 --> 25:13.120
10 times out of 10. And so that's why I think like, you know, we thought when we started, like,

25:13.120 --> 25:17.280
this is just a point solution, we're just going to do experiment tracking, but then people are like,

25:17.280 --> 25:21.520
you know, what I really want you to do is actually, you know, make a hyper parameter,

25:21.520 --> 25:24.720
research thing for me. So we, you know, we did, and then, and then we were like, okay, what are

25:24.720 --> 25:29.760
they really asking for? Um, you know, they're absolutely like, you know, everyone is focused on

25:29.760 --> 25:34.800
just like, I want to be able to keep track of my data sets and models. I think, um, you know,

25:34.800 --> 25:40.400
some people do ask us about, you know, production monitoring or like, you know, CI, CD for, um,

25:40.400 --> 25:44.080
you know, for machine learning. I think this stuff is really interesting and cool. Um, and I don't

25:44.080 --> 25:48.640
think those problems have been been solved yet. So I'm like intrigued. Um, I'm intrigued by

25:48.640 --> 25:53.440
these directions, but I want to make sure that we do, um, well, and I also want to make sure that we are,

25:54.960 --> 26:00.400
like everything we do, you can, um, pick and choose it because I, I guess like, I really don't think

26:00.400 --> 26:08.960
in the end that, um, these kind of all-in platforms are going to be, um, long-term successful. Like,

26:08.960 --> 26:13.600
I think that, um, you know, right now people are confused. I think a lot of VPs are just like,

26:13.600 --> 26:18.320
look, just come in and solve all my ML problems that wants to that, like, feels, um, really good,

26:18.320 --> 26:22.320
but I think the practitioners don't like them because they don't feel like they're learning

26:22.320 --> 26:28.080
transferable skills. And so I think it's, it's actually hard to track the best talent if you

26:28.800 --> 26:34.240
are using, um, you know, the something that doesn't like work with other tools. And I think at the

26:34.240 --> 26:38.640
end, like, well, companies actually really care about and should care about is getting the best talent.

26:38.640 --> 26:43.680
And so I think you have to make, um, tools that make people feel like they have like,

26:43.680 --> 26:48.320
you know, or learning a transferable skill, um, to other companies. And I will say there's a

26:48.320 --> 26:53.200
natural, like, difference in go-to-market too, right? Where, um, you know, if I was selling an ML

26:53.920 --> 26:58.480
platform, you know, I would go into CIOs and I would go to, um, you know, VPs of

26:59.120 --> 27:02.480
machine learning. What are they called? These days, I feel like you have like chief AI officers and

27:02.480 --> 27:08.480
things like that. Um, and it's funny, you know, I, I guess I like, you know, these days, you know,

27:08.480 --> 27:14.800
is anybody, is that chow? Is anybody coined that? That's awesome. If they didn't, it doesn't, I

27:14.800 --> 27:21.680
think the eyes for John Gendres. And he has, I don't know, I, um, I think, definitely, I'm telling

27:21.680 --> 27:25.360
you, somebody out there is that. And then like, I, you know, Tony is like, my network is getting

27:25.360 --> 27:29.520
more and more senior. And I'm getting, um, you know, people are like introducing me to people,

27:29.520 --> 27:33.360
just like, I don't know, I don't know. You know, like, I just want to like talk to the people,

27:33.360 --> 27:37.920
you know, actually making stuff. And, um, you know, get them to want to use it first,

27:37.920 --> 27:43.760
because that's like a bread, butter for, um, you know, the hardest part about, um, ML tools right

27:43.760 --> 27:48.560
now is, is like actually getting people to, um, use the tools, because there's so many tools out

27:48.560 --> 27:54.560
there. That was part of the end, and argument that I was making as well as the end, and,

27:56.240 --> 28:00.400
platform providers, like in order for them to be successful, they'd have to get

28:01.200 --> 28:05.920
everyone to be, you know, they don't have to get folks to be willing to throw away any of the

28:05.920 --> 28:10.160
point investments they made, whether they were internally developed or, you know, they brought

28:10.160 --> 28:16.720
someone else in, whereas, uh, the, you know, specialists would need to fill these, that's,

28:16.720 --> 28:21.840
that was the other side of specialists filling the, the gaps. Um, yeah. It's a interesting.

28:21.840 --> 28:26.800
I wonder how you feel about this. Like I, so this probably happens a few old times, but like every

28:26.800 --> 28:32.080
week, my investors are like, what do you think about this, you know, ML company? And like, I,

28:32.080 --> 28:35.120
I already can prick like what the website is going to say. It's going to like list all the

28:35.120 --> 28:41.440
pain points in ML, right? And like, I know, you know, repressibility, um, explainability, um,

28:41.440 --> 28:45.760
you know, like maintainability, you know, it's like going to be like, we do ML ops, and it's going

28:45.760 --> 28:50.880
to like, and I'm like, I can't evaluate this, because I have no idea what this thing does.

28:52.640 --> 29:00.240
In the same book that you're talking about, I put, uh, uh, I included kind of a way to figure out

29:00.240 --> 29:09.360
what, uh, what a platform is really good at. And to me, I'm sorry, I haven't, I didn't come

29:09.360 --> 29:12.800
across this. I, I really want to know. It's in that same section that you refer to. It's,

29:13.600 --> 29:19.120
it's basically where did they come from? Uh, yeah, makes right. And so, you know, if you,

29:19.120 --> 29:25.440
if you, you know, if they came out of, uh, you know, data storage and snapshotting and now they've

29:25.440 --> 29:29.680
got a, and, and machine learning platform, they're probably going to be focused on the data side

29:29.680 --> 29:35.120
of things. Okay, but it's not in our case. What's that? You know, we're really good at tracking

29:35.120 --> 29:45.680
artifacts. Don't, let's do everyone else. But, you know, so that was one of several criterias,

29:45.680 --> 29:53.520
but I agree. And that's a lot of the problem with, uh, I shouldn't say problem. That is a challenge

29:53.520 --> 30:00.480
with, um, that I see folks faced with when they're looking at these and the end platforms is that

30:00.480 --> 30:08.000
they all talk about solving the same problems, you know, and workflow, uh, increasing innovation

30:08.000 --> 30:12.480
and cycles, you know, decreasing cycle times, increasing, you know, innovation and a number of

30:12.480 --> 30:19.280
experiments and, um, without going deep in, you know, particular areas, it's really difficult

30:19.280 --> 30:23.040
for them to differentiate. I mean, I'll even give you an example. I mean, you probably can't say

30:23.040 --> 30:27.600
the stuff, but, but I can, you know, like, when I, you know, I remember when SageMaker came out,

30:27.600 --> 30:32.000
and it was basically like a way to have like a nice environment to train your models. And,

30:32.000 --> 30:36.400
and my friends told me it was the fastest growing, um, AWS product that they had seen, right? It

30:36.400 --> 30:40.000
was like, it was awesome. It like really solved this, this pain point that everyone had,

30:40.000 --> 30:45.040
everyone like, you know, really wanted to use it. And, and now I'm like baffled, like what,

30:45.040 --> 30:50.160
like what SageMaker does like SageMaker, where begins and ends like, you know, honestly, you could,

30:50.160 --> 30:56.880
it might be useful for you to write it. You know, guys, like we can like figure this out, but

30:56.880 --> 31:01.360
I feel like if I'm confused, the market must be just like utterly baffled because I'm out there,

31:01.360 --> 31:05.280
like every day talking to people, like using these tools, like thinking about it. And I,

31:05.280 --> 31:10.880
I actually could not tell you, um, you know, where SageMaker begins and ends anymore. But I,

31:10.880 --> 31:15.440
I would say to someone, if you want to quickly stand up an environment to run ML models,

31:15.440 --> 31:24.240
I bet you SageMaker is a consolation still. You know, I think, I don't think anyone who follows

31:24.240 --> 31:32.480
AWS is surprised at how it's evolved because, you know, if you've used AWS at all, you go to their

31:32.480 --> 31:40.080
services page and there's like a thousand different modules, right? And, um, you know, they solve,

31:40.080 --> 31:46.480
you know, they're also a very customer-focused, but their strategy or end, their strategy for doing

31:46.480 --> 31:51.920
that is to, uh, come up with a bunch of point solutions and allow folks to kind of string them

31:51.920 --> 32:02.560
together. And they've kind of done that with SageMaker, uh, an ML in general. Um, and to some extent,

32:02.560 --> 32:08.080
or another, for better or for worse, have taken a little bit of the Watson approach where the

32:08.080 --> 32:13.120
brand gets applied to everything, your many things. And it's like, yeah, it's the one thing if Amazon,

32:13.120 --> 32:17.440
if you're listening to this podcast, dude, really, it would make my life easier if you just name them

32:17.440 --> 32:25.280
like different, different things. That's one.

32:29.920 --> 32:36.400
So going back to actually speaking of naming, so artifacts is called artifacts.

32:36.400 --> 32:42.880
Uh, right. We think, what are the artifacts? You know, so the artifact is, so we think of it as a

32:42.880 --> 32:48.480
data set or model management, um, products. And we call it artifacts. And the artifacts here

32:49.120 --> 32:54.720
is essentially a data set or a model. I mean, it really could be like anything that you can think

32:54.720 --> 33:00.160
of as a file. Um, and we kind of thought we had thought up the name artifacts by ourselves,

33:00.160 --> 33:04.560
but then we looked at, you know, Google pipelines actually calls the same thing that we talk about

33:04.560 --> 33:08.800
as artifacts artifacts. And MLflow actually also talks about these things as artifacts. So it does

33:08.800 --> 33:12.800
seem like everyone sort of independently, or we thought we invented it, but, you know, we were

33:12.800 --> 33:19.280
definitely not the first, we have maybe the first that's calling the product that, the first

33:19.280 --> 33:24.160
maybe to call the product that, but certainly we did not, um, you know, we did, you know, we saw it,

33:24.160 --> 33:28.400
we were kind of intrigued to see that other people are calling it the same thing because I think

33:28.400 --> 33:38.640
when I think of artifacts, I think first and foremost about, um, the instantiation of a model.

33:38.640 --> 33:43.200
So like, when I would, you know, outside of this, the context of this conversation, when I'd

33:43.200 --> 33:48.800
ask folks about, uh, the way they manage, managed artifacts, it would be model artifacts,

33:48.800 --> 33:54.160
like some folks would, you know, pickle, uh, python model and store that, that was the,

33:54.160 --> 33:59.600
the pickle file was the artifact. Yeah, yeah, um, folks would kind of, you know, create a doc would

33:59.600 --> 34:05.040
containerize it and the container itself was the artifact. For some folks, the artifact that

34:05.040 --> 34:12.400
they were tracking was a Shah, uh, Gita. Uh, and so I would ask that question to kind of understand,

34:12.400 --> 34:18.320
to understand, um, you know, what was the fundamental currency of whatever system that they were,

34:18.320 --> 34:27.040
um, building, it sounds like for you, an artifact is, well, what is the fun, what are you actually

34:27.040 --> 34:33.920
tracking? It's practically what we see people tracking, like practically what we see them doing,

34:33.920 --> 34:40.560
is tracking usually data sets and, um, models, right? So that's, that's what you should be like

34:40.560 --> 34:45.920
imagining. What are you tracking the data set for the model? Like, do you, do you, is artifacts,

34:45.920 --> 34:52.560
a content management system that is, you know, taking files, putting them in storage, managing that,

34:52.560 --> 34:59.120
or is it, are you tracking pointers to artifacts? Both and I think that's what's key here, right?

34:59.120 --> 35:04.240
So we do both and we also allow you to tag and version them and that's like the big,

35:05.360 --> 35:09.760
that's the big, that's the infrastructure that we've built, right? So we think that people in

35:09.760 --> 35:15.440
different cases might want to save these things on a third party server and might not want to,

35:15.440 --> 35:19.760
right? And, and in fact, even, you know, we have an on-prem version of this and even there,

35:19.760 --> 35:26.160
you might not want to move around like a petabyte, um, data file, um, but in some cases, you actually,

35:26.160 --> 35:30.240
you know, might want to do that just to make sure that it's like completely saved. So, um,

35:30.240 --> 35:34.560
that's what I think a really important feature, it's just super important to our customers is to be

35:34.560 --> 35:38.880
able to kind of handle both cases where it's like, you know, maybe it's appointed to a file or

35:38.880 --> 35:45.600
appointed to a bucket or literally, um, a file. And I think the other important, um, and maybe this

35:45.600 --> 35:51.040
is getting a little in the weeds of the engineering, but, um, I think the way that our users at least

35:51.040 --> 35:58.160
kind of conceive of it is like, you know, experiments, um, have kind of like, in input and output,

35:58.160 --> 36:02.640
typically, right? And the input might be some data sets, say, and the output might be a model,

36:02.640 --> 36:06.880
right? That'll be like sort of the classic kind of experiment that that that we think of,

36:06.880 --> 36:10.960
right? Like a training, you know, ML training run and there the inputs and the outputs are actually

36:10.960 --> 36:16.800
artifacts, right? In our vocabulary, but one of the things that we saw was actually there are

36:16.800 --> 36:20.320
other things that get general. Well, I should say there's other types of experiments that you might

36:20.320 --> 36:28.080
run, um, like a, um, like a data preprocessing step, right? So, you know, data preprocessing, it

36:28.080 --> 36:33.440
actually does have hyper parameters often, right? So like, you know, like maybe, um, if you're doing

36:33.440 --> 36:38.720
like, um, kind of image preprocessing, like, how much you jitter, you know, the images or, um,

36:38.720 --> 36:44.960
you know, with words of information or, yeah, that kind of stuff. Um, and so, you know,

36:44.960 --> 36:50.320
there are the input artifacts is like a data set and the output artifact is like a, you know,

36:50.320 --> 36:57.600
modified, um, data set. But I mean, you know, also as you know, like, um, sometimes in the course

36:57.600 --> 37:01.600
of training and like the real world, there is like other stuff that gets generated, right? There's

37:01.600 --> 37:06.320
like other files that, you know, might matter to you, like, you know, like profiling, like a huge

37:06.320 --> 37:11.920
kind of profiling, um, data set or, um, you know, in the course of model training, right? Like,

37:11.920 --> 37:17.680
you know, so there's, there's all kinds of, um, files that you, that you might generate. The

37:17.680 --> 37:22.720
idea is that, um, in a way, one really nerdy way to think about this is like, you know, the,

37:22.720 --> 37:27.520
the artifacts are like the nodes in the graph and the experiments are like the edges in the graph,

37:27.520 --> 37:32.080
right? So like, you, you think of this sort of directed, um, you know, graph that usually starts

37:32.080 --> 37:36.960
with data sets and ends with like a deployed model. And that is all kinds of chaos, you know,

37:36.960 --> 37:42.080
a long way. Um, you know, I'll say like one thing that's actually been surprisingly important to

37:42.080 --> 37:46.800
some of our, um, users and it's kind of different than, so a lot of people would call this like a

37:46.800 --> 37:51.040
pipeline, right? Like, um, you know, I think people that do this for production, they'd be like,

37:51.040 --> 37:55.680
okay, that's a pipeline. I think one difference about, you know, our artifacts or one design

37:55.680 --> 38:02.640
choice that we made is allowing people to change this type of thing on the fly. So you don't necessarily

38:02.640 --> 38:07.600
have to know exactly, um, you know, what you're going to do with your model, right? You can, you know,

38:07.600 --> 38:11.760
you can make like a game time decision to be like, okay, I'm going to like run some expert experiments

38:11.760 --> 38:17.760
on it. Um, and that's okay, right? So that's, that's a kind of really common thing, um, that we see.

38:17.760 --> 38:21.520
In fact, you might want to like even look at as like a manager, you might want to be like,

38:21.520 --> 38:27.360
like, I have this data set, I just want to see like every model that got trained on it in my company.

38:28.400 --> 38:32.320
And that's actually an easy thing for our tool to do now if you're using our artifacts product,

38:32.320 --> 38:36.400
we can actually, because we, you know, everyone that uses it gets kind of tracked now, you can say,

38:36.400 --> 38:41.280
okay, here's all the people that use that data set, um, or even, you know, you might like have, um,

38:42.560 --> 38:49.200
uh, you might have a model that gets used by, um, you know, other models downstream of it,

38:49.200 --> 38:53.520
right? And so as long as like every model that's like training up the output of a different model,

38:53.520 --> 38:59.520
as long as they declare it, um, you know, you can actually, um, visualize all that in your,

38:59.520 --> 39:08.560
in your company. You were making a point earlier about, um, the, the reason why you didn't like

39:08.560 --> 39:15.520
the terminology pipeline, because it's more dynamic than that is, is that analogous to like,

39:15.520 --> 39:23.520
I'm envisioning, uh, programmatic access to this or predefined, um, you know, access where

39:24.400 --> 39:32.720
you've got some, some pipeline, uh, you know, coded up and you're executing it versus going in via

39:32.720 --> 39:38.720
the UI and, you know, running, kicking things off manually, accessing files manually. Is, is that

39:38.720 --> 39:42.720
the distinction that you're making there? I think we made a design choice that again was just

39:42.720 --> 39:46.640
really informed by your request from, from researchers that we were working with,

39:47.520 --> 39:53.680
let the, the pipeline get defined dynamically, right? So like, you know, production pipelines,

39:53.680 --> 39:56.800
you tend to just sort of like set them and run them and then you might make a new production.

39:57.440 --> 40:01.920
Um, pipeline, whereas like our notion of pipeline, it's like maybe a little bit more like

40:01.920 --> 40:06.320
realistic kind of real world notion, where it's just sort of like that graph and that graph,

40:06.320 --> 40:10.880
you can keep, that graph can keep changing. And it's not a UI thing, like it's like, you know,

40:10.880 --> 40:15.120
you could, you know, you run things at any point, if you run a thing and you declare like,

40:15.120 --> 40:22.320
hey, I'm using, um, you know, dataset xyz, then in our product at any point, if you look at

40:22.320 --> 40:25.920
dataset xyz and you, you query it for like, what's all the stuff downstream of that? You'll see all

40:25.920 --> 40:33.920
those runs. Um, yeah, I think I was getting at, uh, predefined versus ad hoc. Yeah. And it sounds

40:33.920 --> 40:39.040
like that's kind of the distinction that you're, yeah, ad hoc, exactly, exactly. Not

40:39.040 --> 40:44.160
forgetting. Yeah. I hope I'm making sense. I, it's like, you, you're better explain

40:44.160 --> 40:52.000
the stuff than I am. And so maybe another question on that. So, but is the idea then that while

40:54.000 --> 41:01.760
the, um, you know, while you're not locking, you know, while you're not only tracking changes that

41:01.760 --> 41:10.480
happen as the result of a predefined executed pipeline, and you're allowing folks to do ad hoc,

41:11.360 --> 41:19.920
uh, manipulation of the artifacts that you are also tracking the things that they do to,

41:19.920 --> 41:26.160
that they do ad hoc with the artifacts and kind of they become those actions become part of the

41:26.160 --> 41:30.560
graph and thus part of the pipeline. You know, a core design choice, right? It's the artifacts

41:30.560 --> 41:37.600
themselves are immutable. Um, but what you can't add is like essentially like, um, edges to this

41:37.600 --> 41:41.680
graph, right? So if you decide like you built a model and you want to do one extra test on it,

41:42.080 --> 41:48.640
um, you know, before deployment, you can, um, you know, you can, you can basically do that run,

41:48.640 --> 41:53.200
and that'll notify, um, our system and the background that this is happening and we'll keep,

41:53.200 --> 42:02.080
we'll track that all, um, for you. Cool. Is artifacts out? Is it, uh, yeah, folks using it?

42:02.080 --> 42:06.880
Yeah, books are, they're using it. We've been, um, I mean, it'll say we've been like kind of testing

42:06.880 --> 42:11.680
it on early users for quite a long time. So, you know, it's just coming out and, you know,

42:11.680 --> 42:16.160
I'm sure there are some bugs, but it has been, um, you know, beaten on a fair amount of by,

42:17.120 --> 42:20.800
you know, by existing customers. We, we, we've really been trying to use the fact that we have

42:20.800 --> 42:27.040
a lot of users of our first tool to, um, you know, to kind of build it in the conversation with folks.

42:28.400 --> 42:37.040
And historically, and correct me on this, but when I think of weights and biases and the

42:37.040 --> 42:44.560
experiment management tool in particular in the broader context of experiment management,

42:44.560 --> 42:51.760
the focus was very squarely on deep learning as opposed to, uh, you know, tabular data and kind

42:51.760 --> 42:59.920
of traditional machine learning, uh, to what extent does that, if that is, in fact, true?

42:59.920 --> 43:05.760
So what, does that focus kind of carry on to artifacts as well? That's a good question.

43:05.760 --> 43:09.920
I mean, I think we designed it with sort of modern deep learning techniques in mind,

43:09.920 --> 43:15.040
but the line is not so bright. If you know what I'm saying, like, we have a lot of customers

43:15.040 --> 43:20.640
doing, you know, boosted trees and, and, um, you know, I think, I actually, it's a good point.

43:20.640 --> 43:25.040
I think like, um, you know, for a lot of people that are doing kind of boosted trees at big scale,

43:25.040 --> 43:30.720
this, this could be a really relevant, um, you know, think for them. So I think like, I would say

43:30.720 --> 43:37.360
probably most of the users that we have today are doing, um, deep learning or what you would call

43:37.360 --> 43:43.120
deep learning, um, but I don't know. I'm not so opposed to what? Well, I mean, first of all,

43:43.120 --> 43:48.320
I'm not so pure about this. I think, I mean, I think like XG boost is like a awesome tool.

43:48.320 --> 43:51.200
It's like when I started my, you know, I said, well, I started my career before I could boost,

43:51.200 --> 43:54.320
but I've probably made more boosted trees in my life than anything else.

43:54.960 --> 43:59.760
I think scikit-learn is a beautifully done, um, library that I use like all the time for just

43:59.760 --> 44:05.120
my own, um, data analysis. So, um, is it not about about whether deep learning is better than

44:05.120 --> 44:09.520
anything else, but you said deep learning or what you would call deep learning? Is there a deep

44:09.520 --> 44:16.400
learning that like a super secret deep learning or a deep learning? No, no, no, no, no, no, no.

44:16.400 --> 44:22.880
I mean, like, uh, yeah, sorry, I think about like, I think like some of our users they'll be doing,

44:24.640 --> 44:29.040
I think like, you know, I mean, deep learning, you know, as you know, it's like kind of aspirational,

44:29.040 --> 44:34.000
right? So like, you know, something to like enter a company, um, and I really should not name

44:34.000 --> 44:37.840
names here, but like, you know, we'll come in because like somebody's like, oh, I got to do deep

44:37.840 --> 44:41.840
learning. I got to use like, you know, weights and biases for my deep learning thing. But then

44:41.840 --> 44:45.760
most of the company is like using, you know, scikit-learn. And so they, you know, they pick up the

44:45.760 --> 44:51.600
tool and they use it. And I have no, you know, that's great. That's wonderful. I'm not, you know,

44:51.600 --> 44:57.280
I'm not a leadist about this, you know? Right, right. But yeah, I mean, I just honestly,

44:57.280 --> 45:00.880
I think it's probably like, you know, 80% of the people we're talking to are doing,

45:00.880 --> 45:06.960
oh, some kind of neural mat. So it's, it's okay. That are like core user personas is doing deep

45:06.960 --> 45:15.440
learning. Okay. Um, we're not going to ban you from my tool if you use non-neural methods.

45:16.720 --> 45:25.680
And do you have folks or do you anticipate, uh, users that are using artifacts independent

45:25.680 --> 45:32.640
of experiment management? Or do you see this as, uh, side dish to experiment management?

45:33.840 --> 45:37.280
Uh, I guess I view this as an adjacent product. So yeah, you can, you can use this without the

45:37.280 --> 45:41.280
experiment management, but I'm really proud of our experiment management. What I would try to,

45:41.280 --> 45:49.520
I would try to get you to use that. Um, so I mean, right, right now it's, I think that over

45:49.520 --> 45:53.280
lots of 100% because we've really targeted the people doing, you know, using our experiment

45:53.280 --> 45:58.240
management tool, uh, but you know, over time that might change. I think they're pretty similar to

45:58.240 --> 46:04.720
our hyper parameter, um, sweeps, um, is pretty deeply attached to our experiment management. So,

46:04.720 --> 46:09.360
you know, that's similar, um, overlap. Although I think the, the hyper parameter search and the

46:10.720 --> 46:15.520
artifacts is totally independent, you know, you, you could definitely, um, you know, use one or

46:15.520 --> 46:24.800
the other, or neither. Mm hmm. If folks want to, um, take advantage of, uh, artifacts,

46:25.680 --> 46:31.360
is there thinking that they need to do about the way that they process data that they've likely

46:31.360 --> 46:38.320
not done before? Well, look, I think that people should only use software where they have

46:38.320 --> 46:43.680
actual pain points that they can articulate. So, you know, this doesn't happen very often,

46:43.680 --> 46:48.000
but it happens more than, it happens occasionally, and I'm, I'm always kind of baffled by it where

46:48.000 --> 46:52.720
people are like, oh, I want to use your tool, but like, what does it do? You know, it's kind of like,

46:52.720 --> 46:57.680
okay, you probably don't want to use my tool and, you know, let me give you, let me give you an example.

46:59.360 --> 47:07.040
So, um, you know, business process management, right? It's a, it's a similar space. It's like,

47:07.040 --> 47:12.160
essentially, you know, you want to automate some workflow in your business. Maybe it's like

47:12.160 --> 47:19.600
order to cash or something like that. And you may have, you know, 100 people doing it,

47:19.600 --> 47:24.720
you know, you documented the process 10 years ago. The process has evolved for 10 years, and now you

47:24.720 --> 47:30.080
really have no idea how, you know, at a top level, like how your orders are being processed. They

47:30.080 --> 47:35.600
bounce around the organization and the first thing that you need to do to actually implement that

47:35.600 --> 47:42.720
into a tool is to go in and understand what's really being done, right? What are the connections

47:42.720 --> 47:47.600
from one thing to the next? What are the exceptions that pop up? What are the rules that people are

47:47.600 --> 47:53.440
applying implicitly? You know, all of that stuff. And I'm, you know, curious with this question,

47:53.440 --> 47:59.920
are there similar things that you run into where, you know, folks, you know, there are aspects of

47:59.920 --> 48:04.480
the way that their data is being used in this machine learning process that they haven't really

48:04.480 --> 48:09.360
thought about and need to kind of work out before they can implement something like this or,

48:10.160 --> 48:15.040
you know, it's just so, you know, it's all so new and they were doing something, you know,

48:15.040 --> 48:22.960
that was programmatic or rigid enough before that no, they just need to point your tool at some

48:22.960 --> 48:27.760
stuff and it all just works. It's interesting, is it actually a really interesting question because

48:27.760 --> 48:33.040
I think that, you know, my last company was kind of closer to business process management.

48:33.040 --> 48:40.160
And you, you had to buy into a lot to get it working. I think with this,

48:41.120 --> 48:44.560
you know, going, going back to like what I was saying around like pain point, I think the,

48:46.240 --> 48:52.240
you know, you don't have to, you don't have to have like the perfect setup or track everything

48:52.240 --> 48:58.400
to get the benefit, you know, from a tool like this. So like the, I think the point that you would

48:58.400 --> 49:03.040
want to use a tool like our artifacts is when you're asking questions like our customers are asking

49:03.040 --> 49:09.200
like, you know, do we really know exactly what data all the models are trained on or are we worried

49:09.200 --> 49:14.160
about, you know, like our data sets are changing and we're trying to track it. Are we worried that like,

49:14.160 --> 49:17.600
you know, the person who actually writes down what the different data sets are is going to leave

49:17.600 --> 49:23.600
and it's going to be able to know like what they, you know, what they actually were. And I would say

49:23.600 --> 49:29.360
that's actually the most common entry point is around data set, like worrying about data sets,

49:29.360 --> 49:37.120
right? So, you know, like you could get like all that benefit by just tracking the data sets and,

49:38.240 --> 49:42.400
and that is a fairly light instrumentation. It's actually not quite as light as our

49:42.400 --> 49:46.080
experiment management, which we've really worked hard to get down to like under, you know,

49:46.080 --> 49:52.080
five, six minutes. Like this is like slightly more involved. And, but the benefit is bigger in that

49:52.080 --> 49:58.400
you'll for now, for sure, like always know the data sets that got, you know, that you trained on.

49:58.400 --> 50:04.160
And then, you know, down the road, you may, you know, have another concern, which is like, you know,

50:04.160 --> 50:10.640
do I really know, you know, like my models to plan to production, you know, do I really know

50:10.640 --> 50:14.720
exactly what happened to them? Like, do I know like what the preprocessing was? And now you can,

50:14.720 --> 50:18.880
you know, save the model and you can, you know, start to save pipelines, but you don't have to,

50:18.880 --> 50:25.600
it's not like you have to, you know, buy into a huge process to get the benefit. I think on like

50:25.600 --> 50:32.240
other like Senate organizational things that, that teams do, this is really like, this is really some,

50:32.240 --> 50:42.160
I, in fact, I would like kind of encourage teams to adopt it one step at a time versus like trying,

50:42.160 --> 50:45.600
I mean, there's something about like, I think actually, maybe it's that ML is like sort of less,

50:45.600 --> 50:50.080
you know, understood exactly what all the best practices are. Like, you know, my recommendations

50:50.080 --> 50:55.840
always think working ends, you know, and then iterate and improve it. And, you know, part of

50:55.840 --> 51:00.480
improving it is getting better tracking and, you know, getting more organized. And I think that's

51:00.480 --> 51:09.440
the point where, you know, artifacts would make sense to you as a product. And is there a common

51:09.440 --> 51:19.040
pattern that you saw or that you can envision for folks that, you know, aren't ready to move to

51:19.040 --> 51:25.680
a full-on, you know, tool to do this, but, you know, we'll get them part of the way, you know,

51:25.680 --> 51:30.000
from nowhere. Like, what's the, what's the half step or the...

51:30.000 --> 51:34.880
Well, okay, so there's some half steps that you really, you can do. I mean, like, later on,

51:34.880 --> 51:41.520
doing them already, you should be doing what? Well, I mean, this is, I mean, this is

51:41.520 --> 51:45.360
have done, I mean, I'm like, guilty of not doing this, but it's like, you know, if we're creating

51:45.360 --> 51:49.840
your model on a data set, I mean, I don't know, like, I feel like when I have data sets, right,

51:49.840 --> 51:55.920
I start, I mean, I start naming them like, you know, like, XYZ latest, and then like, XYZ,

51:55.920 --> 52:05.600
like, really latest, like, really latest, you know, V2. And it's like, you don't do that. You know,

52:05.600 --> 52:12.160
storage is actually cheap. It's just cheaper than you think. And, you know, that, you know,

52:12.160 --> 52:17.840
that stuff saves you a few seconds or, you know, a day in the short term, and it really bites you

52:17.840 --> 52:26.000
in the medium, the short to medium term. I mean, you know, I think anyone listening that,

52:26.000 --> 52:30.000
that's trained models will kind of understand that. And I think like, you know, like, I mean,

52:30.000 --> 52:38.800
you can make a spreadsheet, and you can, you know, you can be organized about the, you know, all the

52:38.800 --> 52:42.560
model files that you have and like, what they are and what happened to them. And, you know, I think,

52:42.560 --> 52:47.920
like, most, I mean, most people that we talk to are doing some form of this because it's not like,

52:47.920 --> 52:52.080
it's not like a brilliant insight that we had that, you know, you should be organized about your

52:52.080 --> 52:57.520
training, right? So I think most people find some way to do this. And I think like, most experienced

52:57.520 --> 53:04.560
ML practitioners, as they, you know, gain more experience, they get more and more, you know,

53:04.560 --> 53:08.880
kind of paranoid and organized about, you know, about this kind of, except I think where things

53:08.880 --> 53:15.360
like really break down is like, I just, I don't know, I just remember my first job. There was like

53:15.360 --> 53:19.840
this file, like, we had like this file, it was like all the features that we had. And for some

53:19.840 --> 53:26.480
fucking like the TPS file, oh man, I remember that all the features were named like, it was like,

53:26.480 --> 53:29.840
it was like, as though, like, there's some limit on the number, like, letters you could put in the,

53:30.560 --> 53:34.480
the column name, you know what I mean? So they were like, it would literally be like five letter,

53:34.480 --> 53:39.680
you know, five letters in like a number, you know, and like, and it was like, and someone made

53:39.680 --> 53:44.560
like a wiki page of like what they meant, but like they were kind of wrong, you know, because it

53:44.560 --> 53:48.880
wasn't like the person that like made all the features, it was like someone who like kind of tried

53:48.880 --> 53:54.640
to figure it out, you know, like, and I mean, I don't know, like that, I mean, that's like where we

53:54.640 --> 54:01.040
ended up, you know, and like, you know, this is a Yahoo and in 2006, you know, like building,

54:01.040 --> 54:04.720
and it was like, you know, this was like billions of dollars, it was like the relevant engine,

54:04.720 --> 54:08.160
you know, back when Yahoo served like a ton of search traffic, so it was like, there's no joke,

54:08.160 --> 54:12.880
like, we wanted it to be good, you know, but it's just, it's so natural that like, you know,

54:12.880 --> 54:16.480
one person like makes this thing, it's like obvious to them, and they don't document it very well,

54:16.480 --> 54:21.280
and then, you know, when they leave, and another person picks it up, they don't even really know,

54:21.280 --> 54:27.760
like, what's going on? So, you know, I think, I think, you know, documenting and saving is a,

54:27.760 --> 54:35.120
uh, is it really good? Yeah. Cool. Um, well, Lucas, thanks once again for, uh, you know,

54:35.120 --> 54:41.760
joining us, sharing a bit about what you're up to with me and the listeners, and as always,

54:41.760 --> 54:45.040
it's great to catch up with you. Yeah. Real pleasure. Thank you. Thank you.

54:47.520 --> 54:52.480
All right, everyone. That's our show for today. To learn more about today's guest or the

54:52.480 --> 54:58.640
topics mentioned in this interview, visit twimmelai.com. Of course, if you like what you hear on the

54:58.640 --> 55:05.200
podcast, please subscribe, rate, and review the show on your favorite pod catcher. Thanks so much

55:05.200 --> 55:31.600
for listening, and catch you next time.

