1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:35,320
I'm your host Sam Charrington. Two weeks ago we celebrated the show's third birthday

4
00:00:35,320 --> 00:00:40,080
and a major listenership milestone. And last week we kicked off the second volume of our

5
00:00:40,080 --> 00:00:45,200
listener favorite AI platform series, sharing more stories of teams working to scale and

6
00:00:45,200 --> 00:00:49,760
industrialize data science and machine learning at their companies.

7
00:00:49,760 --> 00:00:54,120
We've been teasing that there's more to come and today I am super excited to announce

8
00:00:54,120 --> 00:00:59,360
the launch of our inaugural conference, Twimblecon AI Platforms.

9
00:00:59,360 --> 00:01:04,600
Twimblecon AI platforms will focus on the platforms, tools, technologies and practices

10
00:01:04,600 --> 00:01:09,440
necessary to scale the delivery of machine learning and AI in the enterprise.

11
00:01:09,440 --> 00:01:14,880
Now you know Twimble for bringing you dynamic practical conversations via the podcast and

12
00:01:14,880 --> 00:01:18,640
we're creating our Twimblecon events to build on that tradition.

13
00:01:18,640 --> 00:01:24,240
The event will feature two full days of community oriented discussions, live podcast interviews

14
00:01:24,240 --> 00:01:30,440
and practical presentations by great presenters sharing concrete examples from their own experiences.

15
00:01:30,440 --> 00:01:34,640
By creating a space where data science, machine learning, platform engineering and MLOPS

16
00:01:34,640 --> 00:01:39,640
practitioners and leaders can share, learn and connect, the event aspires to help see

17
00:01:39,640 --> 00:01:44,800
the development of an informed and sustainable community of technologists that is well equipped

18
00:01:44,800 --> 00:01:48,560
to meet the current and future needs of their organizations.

19
00:01:48,560 --> 00:01:52,880
Some of the topics that we plan to cover include overcoming the barriers to getting machine

20
00:01:52,880 --> 00:01:58,120
learning and deep learning models into production, how to apply MLOPS and DevOps to your machine

21
00:01:58,120 --> 00:02:03,040
learning workflow, experiences and lessons learned in delivering platform and infrastructure

22
00:02:03,040 --> 00:02:08,400
support for data management, experiment management and model deployment, the latest approaches

23
00:02:08,400 --> 00:02:14,560
platforms and tools for accelerating and scaling the delivery of ML and DL and the enterprise,

24
00:02:14,560 --> 00:02:19,200
platform deployment stories from leading companies like Google, Facebook, Airbnb as well

25
00:02:19,200 --> 00:02:24,440
as traditional enterprises like Comcast and Shell and organizational and cultural best

26
00:02:24,440 --> 00:02:27,000
practices for success.

27
00:02:27,000 --> 00:02:31,600
The two day event will be held on October 1st and 2nd in San Francisco and I would really

28
00:02:31,600 --> 00:02:33,600
love to meet you there.

29
00:02:33,600 --> 00:02:39,520
EarlyBurt Registration is open today at Twimblecon.com and we're offering the first 10 listeners

30
00:02:39,520 --> 00:02:45,720
who register the amazing opportunity to get their ticket for 75% off using the discount

31
00:02:45,720 --> 00:02:48,120
code TwimbleFirst.

32
00:02:48,120 --> 00:02:54,920
Again, the conference site is Twimblecon.com and the code is TwimbleFirst.

33
00:02:54,920 --> 00:03:00,080
I am really grateful to our friends over at Sigopt who stepped up to support this project

34
00:03:00,080 --> 00:03:01,920
in a big way.

35
00:03:01,920 --> 00:03:07,000
In addition to supporting our AI platform's podcast series and next ebook, they've made

36
00:03:07,000 --> 00:03:12,960
a huge commitment to this community by signing on as the first founding sponsor for the event.

37
00:03:12,960 --> 00:03:17,760
Sigopt Software is used by enterprise teams to standardize and scale machine learning experimentation

38
00:03:17,760 --> 00:03:23,200
and optimization across any combination of modeling frameworks, libraries, computing

39
00:03:23,200 --> 00:03:25,800
infrastructure and environment.

40
00:03:25,800 --> 00:03:31,480
Teams like Two Sigma rely on Sigopt software to realize better modeling results much faster

41
00:03:31,480 --> 00:03:33,800
than previously possible.

42
00:03:33,800 --> 00:03:38,320
Of course, to fully grasp its potential, it's best to try it yourself.

43
00:03:38,320 --> 00:03:43,360
And this is why Sigopt is offering you an exclusive opportunity to try their product on some

44
00:03:43,360 --> 00:03:46,880
of your toughest modeling problems for free.

45
00:03:46,880 --> 00:03:53,040
To learn about and take advantage of this offer, visit twimblei.com slash Sigopt.

46
00:03:53,040 --> 00:04:01,240
And now on to the show.

47
00:04:01,240 --> 00:04:06,840
Right everyone, I am here in San Francisco and I am with Matt Adarath, who is a managing

48
00:04:06,840 --> 00:04:10,160
director at Two Sigma Investments and Scott Clark.

49
00:04:10,160 --> 00:04:16,320
Scott is the founder and CEO at Sigopt and has been on this show previously.

50
00:04:16,320 --> 00:04:19,280
Matt and Scott, welcome to this week in machine learning and AI.

51
00:04:19,280 --> 00:04:20,280
Thanks for having us.

52
00:04:20,280 --> 00:04:21,280
Thank you.

53
00:04:21,280 --> 00:04:22,280
Awesome.

54
00:04:22,280 --> 00:04:25,400
So, I'm really excited about diving into this conversation.

55
00:04:25,400 --> 00:04:33,560
We'll be talking about Two Sigma's journey with regard to building out its modeling and

56
00:04:33,560 --> 00:04:36,000
machine learning platform.

57
00:04:36,000 --> 00:04:38,360
Matt, you've not been on the show before.

58
00:04:38,360 --> 00:04:42,600
We'd love to hear a little bit about your background, how you got started working in machine

59
00:04:42,600 --> 00:04:46,880
learning and at this intersection of engineering and modeling.

60
00:04:46,880 --> 00:04:53,280
Yeah, it's always been an area that I've been interested in, the intersection of computer

61
00:04:53,280 --> 00:04:57,800
science and math, that's what I studied at Carnegie Mellon.

62
00:04:57,800 --> 00:05:03,080
And I always wanted to find some place where I could apply both of those disciplines and

63
00:05:03,080 --> 00:05:05,240
learn and grow in those.

64
00:05:05,240 --> 00:05:09,640
So after school, I went to Microsoft where I was there for about four years, working

65
00:05:09,640 --> 00:05:14,920
on office, which there wasn't so much math there, unfortunately, but it was very interesting.

66
00:05:14,920 --> 00:05:19,280
And then I left Microsoft to join a startup that was spun out of Microsoft Research where

67
00:05:19,280 --> 00:05:22,760
I was doing a lot of analytics on social networks.

68
00:05:22,760 --> 00:05:29,600
And I realized that I wanted to be at a place where I'd be able to do the math that I had

69
00:05:29,600 --> 00:05:31,520
learned and loved.

70
00:05:31,520 --> 00:05:36,600
And the thing that occurred to me was that finance would be a great place to do that because

71
00:05:36,600 --> 00:05:41,080
they exist at that intersection of math and computer science.

72
00:05:41,080 --> 00:05:45,640
And then the whole world of finance was also very interesting to me.

73
00:05:45,640 --> 00:05:51,840
So about 12 years ago, I joined Two Sigma, it was much smaller than.

74
00:05:51,840 --> 00:05:59,000
And I started working on tools and infrastructure there for analyzing data and really helped

75
00:05:59,000 --> 00:06:02,280
build out the platform that we have today.

76
00:06:02,280 --> 00:06:03,280
Awesome.

77
00:06:03,280 --> 00:06:05,320
We'll definitely be coming back to that.

78
00:06:05,320 --> 00:06:11,160
But before we do, Scott, give us a refresher about your background and what Sigopt is

79
00:06:11,160 --> 00:06:12,160
up to.

80
00:06:12,160 --> 00:06:13,160
Yeah, definitely.

81
00:06:13,160 --> 00:06:17,280
So Sigopt provides an experimentation and optimization platform that can bolt on top

82
00:06:17,280 --> 00:06:20,120
of platforms like we're talking about today.

83
00:06:20,120 --> 00:06:25,000
And really help amplify and accelerate the way that you get to impact from these models.

84
00:06:25,000 --> 00:06:30,600
I came to this via grad school where basically when I was doing my PhD at Cornell, I saw that

85
00:06:30,600 --> 00:06:35,200
experimentation and optimization was a core part of every project anyone in my department

86
00:06:35,200 --> 00:06:36,200
was doing.

87
00:06:36,200 --> 00:06:39,960
That was reinforced when I went to Yelp and worked on the advertising system.

88
00:06:39,960 --> 00:06:45,200
And so decided to build Sigopt to help solve this problem in an enterprise way for universities,

89
00:06:45,200 --> 00:06:49,040
government agencies and firms like Two Sigma around the world today.

90
00:06:49,040 --> 00:06:54,320
So Matt, you started Two Sigma 12 years ago, you said.

91
00:06:54,320 --> 00:07:00,960
Where was Two Sigma kind of in the journey of a platform?

92
00:07:00,960 --> 00:07:06,680
You started there working on tools and infrastructure as opposed to coming over from data science

93
00:07:06,680 --> 00:07:11,080
where you, you know, one of the first people working on tools in emperor was there already

94
00:07:11,080 --> 00:07:14,280
an established group focused on that.

95
00:07:14,280 --> 00:07:21,840
So there were teams working on it, but it was really more spread across the teams like

96
00:07:21,840 --> 00:07:28,680
our data, we had a data engineering team and there was a modeling engineering team.

97
00:07:28,680 --> 00:07:35,320
But they would each build out their own infrastructure of varying qualities and it was a little

98
00:07:35,320 --> 00:07:41,880
later that we started really trying to find the solution that would work for everyone.

99
00:07:41,880 --> 00:07:48,000
But since the beginning, the company was founded in 2001 and it was started as a quantitative

100
00:07:48,000 --> 00:07:52,920
investment manager with a focus on building out platforms for the things that we were trying

101
00:07:52,920 --> 00:07:57,280
to do with the knowledge that we would try to expand into different businesses and want

102
00:07:57,280 --> 00:08:00,440
to be able to leverage the solutions that we had already built.

103
00:08:00,440 --> 00:08:06,600
So it was already in play when I got there 12 years ago and it was more just like picking

104
00:08:06,600 --> 00:08:10,880
up the torch on certain areas that needed more focus.

105
00:08:10,880 --> 00:08:11,880
Okay.

106
00:08:11,880 --> 00:08:12,880
Okay.

107
00:08:12,880 --> 00:08:23,280
And so maybe talk a little bit about the various constituents you serve or you, do you

108
00:08:23,280 --> 00:08:28,720
have a single type of data scientist or a single type of skill set there?

109
00:08:28,720 --> 00:08:34,040
Do you have engineers as well as data scientists as well as other types of quantitative folks

110
00:08:34,040 --> 00:08:35,960
that are using the tools that you're building?

111
00:08:35,960 --> 00:08:42,080
Yeah. So it really is a wide variety of skill sets that we're trying to serve.

112
00:08:42,080 --> 00:08:48,800
Even within our modeling discipline, there are some folks who are much more technical and

113
00:08:48,800 --> 00:08:55,240
are looking at things from a like a technique perspective and then there are other folks

114
00:08:55,240 --> 00:09:01,680
who are much more focused on understanding their data sets and trying to figure out what

115
00:09:01,680 --> 00:09:07,000
the predictive value is based off of a deep understanding of where the data comes from

116
00:09:07,000 --> 00:09:08,520
and what it means.

117
00:09:08,520 --> 00:09:12,840
And roughly how many users does your group support?

118
00:09:12,840 --> 00:09:16,560
So the company is roughly a third modeling.

119
00:09:16,560 --> 00:09:19,720
So talking around 500.

120
00:09:19,720 --> 00:09:20,720
Wow.

121
00:09:20,720 --> 00:09:21,720
Okay.

122
00:09:21,720 --> 00:09:29,000
And so I guess what I'm curious most about is how the thinking about building out tools

123
00:09:29,000 --> 00:09:34,720
and platforms to support modeling has evolved over the time that you've been there.

124
00:09:34,720 --> 00:09:40,200
So one of the things that we try to do is not be prescriptive about the tools that our

125
00:09:40,200 --> 00:09:41,200
modelers use.

126
00:09:41,200 --> 00:09:48,760
We want to hire the best and we want them to be able to apply the tools and techniques

127
00:09:48,760 --> 00:09:55,120
that they are familiar with and that they are able to leverage the most.

128
00:09:55,120 --> 00:09:58,560
So that's a challenge when we're trying to build up platforms because if we're not being

129
00:09:58,560 --> 00:10:01,000
prescriptive, we can't really limit them.

130
00:10:01,000 --> 00:10:06,760
But what we try to do is identify the common threads that will benefit the most number of

131
00:10:06,760 --> 00:10:07,760
people.

132
00:10:07,760 --> 00:10:11,960
We also try to identify what we think are going to be the winners in terms of technologies

133
00:10:11,960 --> 00:10:15,800
where we can give them a little bit more of a push or support them a little bit more

134
00:10:15,800 --> 00:10:21,040
to make those extra easy to drive people to them without being prescriptive.

135
00:10:21,040 --> 00:10:23,080
How did Sigop come into play?

136
00:10:23,080 --> 00:10:25,160
How did you find one another?

137
00:10:25,160 --> 00:10:30,560
You know, was there a search around sigmas and what companies can we find?

138
00:10:30,560 --> 00:10:33,800
We definitely ran into each other at a lot of the similar academic conferences that

139
00:10:33,800 --> 00:10:37,360
we go to in Publish, whether it's ICML, NERIPS, that kind of thing.

140
00:10:37,360 --> 00:10:41,800
But I think a lot of it, after seeing each other, what drove us together was this shared

141
00:10:41,800 --> 00:10:47,600
desire to be very modeling driven and really help augment and amplify these experts.

142
00:10:47,600 --> 00:10:51,520
So it's not about, again, being prescriptive, like Matt said, it's more about giving them

143
00:10:51,520 --> 00:10:55,400
the tools to run as fast as they can once they've picked the direction.

144
00:10:55,400 --> 00:11:01,240
And so you want to be able to unify and standardize on things that make sense to standardize

145
00:11:01,240 --> 00:11:04,040
on, but then don't do it in a constraining way.

146
00:11:04,040 --> 00:11:08,380
So you want to provide optionality so that they can use their expertise, that context

147
00:11:08,380 --> 00:11:10,760
awareness, that domain expertise.

148
00:11:10,760 --> 00:11:13,160
But at the end of the day, really run as fast as possible.

149
00:11:13,160 --> 00:11:17,720
And I think modeling platforms help with that and agnostic optimization helps with that

150
00:11:17,720 --> 00:11:21,960
and good infrastructure helps with that, but it's really about really empowering these people,

151
00:11:21,960 --> 00:11:24,200
which is that shared vision I think we both have.

152
00:11:24,200 --> 00:11:32,320
Matt, when you think about the end-to-end modeling platform that your team is offering,

153
00:11:32,320 --> 00:11:35,560
how do you articulate the various components of that?

154
00:11:35,560 --> 00:11:40,440
When I think about these kinds of platforms, I tend to think of them in terms of data management

155
00:11:40,440 --> 00:11:46,320
and transformation in those kinds of things, experiment management and production or model

156
00:11:46,320 --> 00:11:47,320
deployment.

157
00:11:47,320 --> 00:11:54,280
Do you have a similar view of the landscape or do you organize things differently?

158
00:11:54,280 --> 00:11:57,200
At a high level, that's how we look at things.

159
00:11:57,200 --> 00:11:59,160
I would break it down a little bit more.

160
00:11:59,160 --> 00:12:07,720
Even at the data management stage, we have a finer breakdown where there are things around

161
00:12:07,720 --> 00:12:13,240
like data ingestion is a big thing for us because we have so many data sets that we take

162
00:12:13,240 --> 00:12:19,640
in that's what we do is we try to bring in as many data sets as possible and find the

163
00:12:19,640 --> 00:12:21,880
value in all of them.

164
00:12:21,880 --> 00:12:30,280
So bring ingesting at scale is a challenge, cleaning at scale and making sure that that

165
00:12:30,280 --> 00:12:35,920
data is not just available for doing data science, but making sure that it's available for

166
00:12:35,920 --> 00:12:41,360
our real-time trading systems, which is an additional challenge because there is this

167
00:12:41,360 --> 00:12:45,680
timeliness aspect to how soon we process the data.

168
00:12:45,680 --> 00:12:53,840
Then on the research side, we break things down even further around not just accessing

169
00:12:53,840 --> 00:13:02,120
the data, but transforming it, sharing transformations is a big concern for us and then modeling.

170
00:13:02,120 --> 00:13:03,120
Okay.

171
00:13:03,120 --> 00:13:08,200
Then on the modeling side, do you have further distinctions within that set of capabilities?

172
00:13:08,200 --> 00:13:14,360
Yeah. So the first part of the modeling capabilities is just doing the preliminary analysis of

173
00:13:14,360 --> 00:13:20,240
the data, like explore to our data analysis that everybody does.

174
00:13:20,240 --> 00:13:23,600
We have a lot of focus on the time seriousness of everything.

175
00:13:23,600 --> 00:13:25,360
We treat everything as a time series.

176
00:13:25,360 --> 00:13:28,800
We kind of have this belief that everything is a time series and if you have something

177
00:13:28,800 --> 00:13:34,520
that you think isn't a time series, you're probably wrong and you're going to regret

178
00:13:34,520 --> 00:13:39,420
not trading it as a time series because it changes and we need to be able to do point

179
00:13:39,420 --> 00:13:43,200
and time simulations and back testing for everything.

180
00:13:43,200 --> 00:13:49,520
So there's this whole phase of analysis and modeling and then once you have something

181
00:13:49,520 --> 00:13:56,280
that you think has predictive value, there's this second stage of seeing how it trades and

182
00:13:56,280 --> 00:14:04,440
that is really a different style of analysis than typical data science outside of

183
00:14:04,440 --> 00:14:05,440
finance.

184
00:14:05,440 --> 00:14:11,960
You mentioned previously that some of the things that you're doing are particularly challenging

185
00:14:11,960 --> 00:14:13,520
at the scale that you're doing.

186
00:14:13,520 --> 00:14:16,040
Can you give us a sense for the scale?

187
00:14:16,040 --> 00:14:21,820
So I mentioned that we have hundreds of researchers and they're each doing lots of different

188
00:14:21,820 --> 00:14:25,760
kinds of analysis at scale, whether they're doing the exploratory data analysis on large

189
00:14:25,760 --> 00:14:32,080
data sets or they're testing out their models and seeing how different parameters perform.

190
00:14:32,080 --> 00:14:37,680
In some of those cases, they may be running thousands or tens of thousands of very expensive

191
00:14:37,680 --> 00:14:39,200
simulations.

192
00:14:39,200 --> 00:14:48,760
So we have a huge demand for compute and a lot of challenges around scaling up to those

193
00:14:48,760 --> 00:14:52,080
managing that amount of compute.

194
00:14:52,080 --> 00:15:01,880
Scott, when you think about the challenges that Matt's talked about from a modeling perspective

195
00:15:01,880 --> 00:15:12,960
and curious from your perspective, having seen this play out at a number of customers, what

196
00:15:12,960 --> 00:15:18,160
of what he described would you say is unique to Sigma and what do you see broadly in the

197
00:15:18,160 --> 00:15:19,160
industry?

198
00:15:19,160 --> 00:15:20,400
Great question.

199
00:15:20,400 --> 00:15:27,320
So I think broadly, we definitely see people doing unique modeling, they're doing differentiated

200
00:15:27,320 --> 00:15:28,320
modeling.

201
00:15:28,320 --> 00:15:32,400
I think special about what they bring to the table, whether it's on the data side or whether

202
00:15:32,400 --> 00:15:37,400
it's the end application, and that's really, again, where domain expertise and contextual

203
00:15:37,400 --> 00:15:39,360
awareness plays a huge role.

204
00:15:39,360 --> 00:15:42,680
And whether that's in the asset management space or whether it's the work that we're doing

205
00:15:42,680 --> 00:15:46,800
with tech companies or the US intelligence community, everybody has something different

206
00:15:46,800 --> 00:15:48,560
they're trying to solve.

207
00:15:48,560 --> 00:15:53,440
And what we've found is more and more companies are starting to invest in platforms.

208
00:15:53,440 --> 00:15:58,560
Because of course, you've seen with the series that you're running and are continuing to run.

209
00:15:58,560 --> 00:16:02,440
And a lot of that comes down to people who are doing this already, they just might not

210
00:16:02,440 --> 00:16:05,960
have been doing it the right way, or they might not have been doing it in a way that

211
00:16:05,960 --> 00:16:09,600
could amplify across the entire organization.

212
00:16:09,600 --> 00:16:11,560
We see the same thing with experimentation.

213
00:16:11,560 --> 00:16:16,760
So there's a lot of parallels in terms of just the core concept of we have data, we're

214
00:16:16,760 --> 00:16:18,360
trying to solve a problem.

215
00:16:18,360 --> 00:16:23,640
It might be making trades in a market, it might be trying to make a recommendation for a

216
00:16:23,640 --> 00:16:24,920
streaming service.

217
00:16:24,920 --> 00:16:29,200
But at the end of the day, it's somebody trying to solve this very specific problem.

218
00:16:29,200 --> 00:16:34,000
And then teams like Matt and teams like Sigopt are trying to really just give them the tools

219
00:16:34,000 --> 00:16:39,320
to do those jobs better, without forcing them into a sandbox or without trying to give

220
00:16:39,320 --> 00:16:41,800
them a one size fits all solution.

221
00:16:41,800 --> 00:16:47,840
When I talk to folks that are trying to provide these types of tools, the goals that they

222
00:16:47,840 --> 00:16:50,400
have are all over the map.

223
00:16:50,400 --> 00:16:56,680
Some folks have these broad, I kind of asked about the different types of users that you're

224
00:16:56,680 --> 00:16:57,680
trying to support.

225
00:16:57,680 --> 00:17:04,640
Some folks, their primary goal is to make machine learning more accessible so that more teams

226
00:17:04,640 --> 00:17:08,040
can make models, can build models, that kind of thing.

227
00:17:08,040 --> 00:17:14,080
Other folks are driving towards their whole existence is around achieving some level of

228
00:17:14,080 --> 00:17:19,440
scale or kind of compressing the innovation cycle, things like that.

229
00:17:19,440 --> 00:17:26,280
How do you think about your prime directives, if you will, what is really driving to

230
00:17:26,280 --> 00:17:30,800
Sigma to continue to invest in this, if you had to stack rank them?

231
00:17:30,800 --> 00:17:35,000
Yeah, so the two things are we want to get better answers and we want to get them faster.

232
00:17:35,000 --> 00:17:43,040
We have lots of modelers, like I mentioned before, so any multiplier on their speed really

233
00:17:43,040 --> 00:17:44,040
adds up.

234
00:17:44,040 --> 00:17:46,800
Not just because there are so many of them, but because of what each of them is doing

235
00:17:46,800 --> 00:17:49,360
is so high value.

236
00:17:49,360 --> 00:17:54,360
The two things that we're looking at are getting better answers and getting them faster.

237
00:17:54,360 --> 00:18:00,360
The better answers can come from applying better techniques that may discover things that

238
00:18:00,360 --> 00:18:03,200
couldn't be discovered otherwise.

239
00:18:03,200 --> 00:18:08,080
The speed comes not just from the speed of the algorithms that are maybe doing these

240
00:18:08,080 --> 00:18:14,000
optimizations, but also the usability of the tool is really critical for us.

241
00:18:14,000 --> 00:18:19,880
It's very easy to lose a day to trying to figuring out some error message or some weird

242
00:18:19,880 --> 00:18:23,880
API that wasn't well designed, so that's something that we're also really focused on.

243
00:18:23,880 --> 00:18:31,280
A big part of that is around these kind of different elements of the platform that we've

244
00:18:31,280 --> 00:18:36,840
talked about, making sure the data is available to folks, making sure they can iterate on experiments

245
00:18:36,840 --> 00:18:37,840
very quickly.

246
00:18:37,840 --> 00:18:42,920
Do you have challenges on the production-alizing side as well, or your users mostly focused

247
00:18:42,920 --> 00:18:48,160
on analytical results in inquiry and not so much deploy models out?

248
00:18:48,160 --> 00:18:49,200
They do deploy models.

249
00:18:49,200 --> 00:18:53,040
We do have our modelers own their models end-to-end.

250
00:18:53,040 --> 00:18:57,960
That's something that we think there's a lot of value in doing, and there are challenges

251
00:18:57,960 --> 00:19:02,760
in writing a production model versus doing something in research that is another focus

252
00:19:02,760 --> 00:19:07,520
for my team, making sure that that transition is as seamless as possible.

253
00:19:07,520 --> 00:19:13,480
A lot of the benefits that you described in terms of increasing the pace of innovation

254
00:19:13,480 --> 00:19:19,400
and getting better results is focused on those researchers and their ability to turn through

255
00:19:19,400 --> 00:19:26,000
the possible solution space, if you will, for these problems that they're trying to solve.

256
00:19:26,000 --> 00:19:33,040
When you think about the things that you've done to address or attack the experimentation

257
00:19:33,040 --> 00:19:40,120
challenge, can you give us a spectrum of the types of things you've done from a platforming

258
00:19:40,120 --> 00:19:44,840
perspective to narrow in on those goals?

259
00:19:44,840 --> 00:19:46,840
Sure.

260
00:19:46,840 --> 00:19:48,840
I can give a couple examples.

261
00:19:48,840 --> 00:19:54,680
One is we focus a lot on the languages that people use, making sure that we have domain-specific

262
00:19:54,680 --> 00:20:02,800
languages that allow our modelers to express their problems really naturally, while still

263
00:20:02,800 --> 00:20:09,400
having the flexibility to cover all of the possible ideas that they might have.

264
00:20:09,400 --> 00:20:12,240
What's the native modeling environment for your folks?

265
00:20:12,240 --> 00:20:16,320
Is it primarily notebooks or something else?

266
00:20:16,320 --> 00:20:19,440
Over the last few years, there's been a big push towards notebooks.

267
00:20:19,440 --> 00:20:23,240
We've open sourced some of the stuff that we've built.

268
00:20:23,240 --> 00:20:30,240
Beaker X is one plugin that runs on top of Jupiter that allows people to work in a really

269
00:20:30,240 --> 00:20:36,880
seamless polyglot environment and has some internal things that are bespoke to our environment

270
00:20:36,880 --> 00:20:40,600
that make it just really easy for people to do the things that they need to do.

271
00:20:40,600 --> 00:20:46,040
Another example of the kinds of things that we focus on to make it easy for them is

272
00:20:46,040 --> 00:20:54,600
around running lots and lots of jobs, specifically back test simulations is a big focus for us.

273
00:20:54,600 --> 00:21:00,120
That's where a significant chunk of our compute is dedicated.

274
00:21:00,120 --> 00:21:08,760
Making that easy for modelers to interact with, to launch things at scale, to monitor and

275
00:21:08,760 --> 00:21:17,120
manage those things and to easily deploy to different cloud providers or reusing our

276
00:21:17,120 --> 00:21:21,920
in-house data centers, we just want to make that all as easy as possible so that they

277
00:21:21,920 --> 00:21:24,920
can get their jobs done quickly.

278
00:21:24,920 --> 00:21:33,520
What's the interface between the researchers and the Sigopt product and its capability?

279
00:21:33,520 --> 00:21:36,200
That's a great question.

280
00:21:36,200 --> 00:21:38,200
We have a few different solutions.

281
00:21:38,200 --> 00:21:44,800
Many folks who use the Sigopt API directly, it solves a problem that lots of people

282
00:21:44,800 --> 00:21:48,800
have and where they know that they have this problem, I have parameters I want to tune

283
00:21:48,800 --> 00:21:49,800
them.

284
00:21:49,800 --> 00:21:55,600
We also have a number of tools that are for solving specific problems that modelers

285
00:21:55,600 --> 00:21:58,560
have that use Sigopt under the hood.

286
00:21:58,560 --> 00:22:04,080
We really like that it works well as just a component in other tools where the model

287
00:22:04,080 --> 00:22:06,560
may not even know that they're using Sigopt.

288
00:22:06,560 --> 00:22:11,040
Scott, is that a pretty common experience among the folks that use Sigopt?

289
00:22:11,040 --> 00:22:17,240
Yeah, I would say there's different tools for different jobs and it's about sometimes

290
00:22:17,240 --> 00:22:23,800
to end platform that allows some flexibility for the modeler and sometimes it's something

291
00:22:23,800 --> 00:22:27,960
where it's a very point solution for a very specific problem.

292
00:22:27,960 --> 00:22:30,880
I guess I have one quick question if that's okay for me.

293
00:22:30,880 --> 00:22:35,240
As you start to build up these platforms, obviously you've been there for 12 years.

294
00:22:35,240 --> 00:22:39,160
You've seen a lot of different iterations of this over time.

295
00:22:39,160 --> 00:22:42,320
How do you like measure the efficacy of some of your efforts?

296
00:22:42,320 --> 00:22:46,000
You guys have been on the bleeding edge for a long time but I imagine there's been several

297
00:22:46,000 --> 00:22:49,120
iterations of infrastructure, of experimentation.

298
00:22:49,120 --> 00:22:55,320
How do you make sure you're making progress or how do you make decisions of what's worth

299
00:22:55,320 --> 00:22:59,080
continuing to invest in, what's worth building versus buying?

300
00:22:59,080 --> 00:23:01,560
We do have a lot of modelers.

301
00:23:01,560 --> 00:23:07,200
It is also few enough that we're able to talk to them and have conversations about what

302
00:23:07,200 --> 00:23:08,600
they find useful.

303
00:23:08,600 --> 00:23:13,640
That's something that we're always doing is just interfacing directly with our users and

304
00:23:13,640 --> 00:23:16,560
understanding what they like and what they don't like.

305
00:23:16,560 --> 00:23:18,440
We do have tons of metrics.

306
00:23:18,440 --> 00:23:22,480
We're a quantitative investment manager so we like to look at the numbers.

307
00:23:22,480 --> 00:23:29,200
We always are looking at things like usage, seeing how that's tracking to help identify

308
00:23:29,200 --> 00:23:31,400
where we should focus.

309
00:23:31,400 --> 00:23:34,640
In some cases, it's not driven by numbers.

310
00:23:34,640 --> 00:23:39,480
It's driven by just keeping an eye out on what's going on in the industry, in the broader

311
00:23:39,480 --> 00:23:44,800
ecosystem of data science and seeing what's applicable to us, and then we evaluate those

312
00:23:44,800 --> 00:23:46,920
things through experiments.

313
00:23:46,920 --> 00:23:53,880
When we were looking at Sigopt, we compared it to not just the in-house solutions that

314
00:23:53,880 --> 00:24:00,800
we were already using but also some other open source things like we looked heavily at

315
00:24:00,800 --> 00:24:07,840
GPIOP as one of the big alternatives and saw how it worked on a variety of optimization

316
00:24:07,840 --> 00:24:11,080
problems that we had identified.

317
00:24:11,080 --> 00:24:17,600
When you were looking at it relative to those other things, just curious, was there any

318
00:24:17,600 --> 00:24:18,600
particular?

319
00:24:18,600 --> 00:24:26,080
Was it a performance motivation that led you towards Sigopt or was it more of a user

320
00:24:26,080 --> 00:24:31,640
experience thing and how do you weight those things?

321
00:24:31,640 --> 00:24:32,640
Yeah.

322
00:24:32,640 --> 00:24:37,640
It's performance, both the quality of the solutions that it finds and how quickly it

323
00:24:37,640 --> 00:24:47,160
finds it, but also the usability and not just is the API sane, but things like how much

324
00:24:47,160 --> 00:24:50,720
tuning do you need to do of your hyperparameter tuning?

325
00:24:50,720 --> 00:24:57,080
We found that for a lot of other solutions, GPIOP in particular, it was very sensitive

326
00:24:57,080 --> 00:25:01,720
to its parameters that you would set it with.

327
00:25:01,720 --> 00:25:05,960
The fact that it wasn't something that we could just run and reliably get answers and

328
00:25:05,960 --> 00:25:09,560
that it was something that you had to fuss with a lot was another qualitative measure

329
00:25:09,560 --> 00:25:14,440
that kind of turned us off from pursuing those and made us go with Sigopt.

330
00:25:14,440 --> 00:25:18,160
You need a hyperparameter optimizer for your hyperparameter optimizer?

331
00:25:18,160 --> 00:25:19,160
Yes.

332
00:25:19,160 --> 00:25:20,760
It sounds like a lot of turtles.

333
00:25:20,760 --> 00:25:25,200
Yeah, the number one piece of feedback we got after I opened source Mo at Yelp was this

334
00:25:25,200 --> 00:25:29,000
is great, but you've taken my optimization problem and turned it into another optimization

335
00:25:29,000 --> 00:25:30,000
problem.

336
00:25:30,000 --> 00:25:35,840
But I guess, I mean, so you have 500 incredibly intelligent modelers, some of which have

337
00:25:35,840 --> 00:25:38,400
very deep expertise in mathematics.

338
00:25:38,400 --> 00:25:40,920
How do you decide for something like this?

339
00:25:40,920 --> 00:25:44,760
Obviously, you tried a bunch of in-house solutions, you looked at a bunch of different things.

340
00:25:44,760 --> 00:25:49,960
How do you make that trade off of, this is worth us spending up a team of 12 people and

341
00:25:49,960 --> 00:25:55,040
attacking it for years versus taking kind of a best in class solution?

342
00:25:55,040 --> 00:26:00,120
How do you make that trade off internally of, this is worth us solving internally versus

343
00:26:00,120 --> 00:26:01,720
this is worth us partnering?

344
00:26:01,720 --> 00:26:05,480
Yeah, well, we looked at the opportunity cost.

345
00:26:05,480 --> 00:26:11,360
We have these folks who we've hired who are very talented, but we want them to be working

346
00:26:11,360 --> 00:26:16,080
on specific problems with the best tools that are available.

347
00:26:16,080 --> 00:26:23,080
So if there's something that already exists and it's a lot cheaper than us paying 12

348
00:26:23,080 --> 00:26:28,120
folks to a year to build out, of course, we're going to go with it.

349
00:26:28,120 --> 00:26:37,200
Yeah, I'm curious about, certainly on the modeling side, a lot of Barton Parcel to experimentation

350
00:26:37,200 --> 00:26:43,720
is, you know, faux, you go down a path, it doesn't work out, you go down another path,

351
00:26:43,720 --> 00:26:49,640
and that's kind of inherent to the modeling process.

352
00:26:49,640 --> 00:26:54,640
I'm curious if there are any things that you can share from a platform perspective, things

353
00:26:54,640 --> 00:26:58,080
that you tried, you were very excited about, they didn't really work out.

354
00:26:58,080 --> 00:27:03,960
They didn't give you the kind of performance or the acceleration that you were looking

355
00:27:03,960 --> 00:27:04,960
for.

356
00:27:04,960 --> 00:27:09,160
One thing that I can cite that's relevant to this is we've been looking at black box

357
00:27:09,160 --> 00:27:12,720
optimization for a very long time.

358
00:27:12,720 --> 00:27:14,200
It's always been an interest of mine.

359
00:27:14,200 --> 00:27:17,320
I knew that it would be applicable to us.

360
00:27:17,320 --> 00:27:25,480
So it was about seven years ago, I started an initiative to make some more black box

361
00:27:25,480 --> 00:27:30,440
optimization algorithms broadly available at the company that, in ways that leveraged

362
00:27:30,440 --> 00:27:34,360
the rest of our platform and were just as easy as possible.

363
00:27:34,360 --> 00:27:42,160
And one of the issues that we ran into very quickly was when we started running things

364
00:27:42,160 --> 00:27:47,200
at a totally new scale that was required for doing these black box searches, a lot of

365
00:27:47,200 --> 00:27:54,800
the small pain points around having like long running simulations fail, all sorts of

366
00:27:54,800 --> 00:27:57,720
things that just go wrong when you have distributed systems.

367
00:27:57,720 --> 00:28:01,640
A lot of those things just broke the user experience completely.

368
00:28:01,640 --> 00:28:08,240
And we had to like table a lot of those initiatives around doing black box optimization to revisit

369
00:28:08,240 --> 00:28:13,560
our core platform for how we run all of these jobs.

370
00:28:13,560 --> 00:28:18,320
And what the interface was, how we deal with things like failures and just how do we make

371
00:28:18,320 --> 00:28:19,840
it work at scale.

372
00:28:19,840 --> 00:28:26,280
So it was kind of a pivot, we took this thing that we knew was a good idea but really kind

373
00:28:26,280 --> 00:28:32,720
of failed because the environment wasn't right and then focused on the environment instead.

374
00:28:32,720 --> 00:28:41,600
And then kind of tabled the black box optimization as a service because it was such a hard problem

375
00:28:41,600 --> 00:28:47,480
to fit your at the platform, which took us years to build out and get right.

376
00:28:47,480 --> 00:28:52,360
So I kind of view that as something that didn't work out, it had these additional benefits

377
00:28:52,360 --> 00:28:58,560
but it also set us up for success later on when something likes it comes along that we

378
00:28:58,560 --> 00:29:03,920
couldn't have leveraged if we didn't already experience our own failures trying to solve

379
00:29:03,920 --> 00:29:05,240
the same problem.

380
00:29:05,240 --> 00:29:06,240
Okay.

381
00:29:06,240 --> 00:29:12,880
And at the infrastructure level, are you now having gone through that process?

382
00:29:12,880 --> 00:29:18,200
Are you using something like a Kubernetes or some other open source or is it a proprietary

383
00:29:18,200 --> 00:29:20,160
distributed computing solution?

384
00:29:20,160 --> 00:29:21,160
Yeah.

385
00:29:21,160 --> 00:29:25,880
So when we started this, it was before Kubernetes was really even a thing.

386
00:29:25,880 --> 00:29:26,880
Okay.

387
00:29:26,880 --> 00:29:30,640
For a lot of the things that we're talking about, we were doing it before it really was

388
00:29:30,640 --> 00:29:31,640
a thing.

389
00:29:31,640 --> 00:29:37,840
Even the term data science wasn't really happening 12 years ago when I started and big

390
00:29:37,840 --> 00:29:42,920
data wasn't a hot phrase that everybody knew.

391
00:29:42,920 --> 00:29:51,680
So our solution was built on top of Apache Mace OS, which we built a framework on top

392
00:29:51,680 --> 00:29:52,680
of it.

393
00:29:52,680 --> 00:29:55,960
It has this nice, pluggable, like framework interface.

394
00:29:55,960 --> 00:30:00,480
So we were able to build something that handled our bespoke scheduling needs.

395
00:30:00,480 --> 00:30:05,160
We open sourced it, our scheduler that we use because we do know that there are other

396
00:30:05,160 --> 00:30:09,480
folks who have kind of similar problems and there are benefits to us to open sourcing

397
00:30:09,480 --> 00:30:10,480
it.

398
00:30:10,480 --> 00:30:11,480
Yeah.

399
00:30:11,480 --> 00:30:17,480
So you started before something like Kubernetes, you were using Mace OS, you know, in that

400
00:30:17,480 --> 00:30:23,360
kind of 12 years ago, time frame, Mace OS was the Kubernetes of distributed compute

401
00:30:23,360 --> 00:30:29,880
in the sense that it was very popular for these kinds of applications and we are investing

402
00:30:29,880 --> 00:30:32,680
heavily in Kubernetes now over the last few years.

403
00:30:32,680 --> 00:30:33,680
Okay.

404
00:30:33,680 --> 00:30:34,680
Yeah.

405
00:30:34,680 --> 00:30:35,680
Okay.

406
00:30:35,680 --> 00:30:36,680
Interesting.

407
00:30:36,680 --> 00:30:42,600
And so you went down this path to build out some distributed optimization stuff.

408
00:30:42,600 --> 00:30:49,520
You ran into limitations of the infrastructure and it sounds like you spent a few years building

409
00:30:49,520 --> 00:30:55,360
out the infrastructure to support kind of where you wanted the platform to go or the kinds

410
00:30:55,360 --> 00:30:59,560
of things that you knew you needed to be able to do.

411
00:30:59,560 --> 00:31:05,880
Can you characterize how much of your efforts are spent kind of at the low level infrastructure

412
00:31:05,880 --> 00:31:13,000
versus the higher level tools and services that are more researcher facing?

413
00:31:13,000 --> 00:31:14,160
Yeah.

414
00:31:14,160 --> 00:31:18,640
So we do have our engineering work is also roughly about a third of the company and it's

415
00:31:18,640 --> 00:31:21,640
broken up into several teams.

416
00:31:21,640 --> 00:31:26,240
I work on modeling engineering where we focus on building up the tools and infrastructure

417
00:31:26,240 --> 00:31:28,960
that are targeting our modelers.

418
00:31:28,960 --> 00:31:33,720
There is a separate team called platform engineering which is providing the platforms

419
00:31:33,720 --> 00:31:38,000
for all engineering and all of the company.

420
00:31:38,000 --> 00:31:40,440
So they're about the same size.

421
00:31:40,440 --> 00:31:42,960
I think modeling engineering might be a little larger.

422
00:31:42,960 --> 00:31:49,640
So what we find is that sometimes we will build out platform solutions to solve a specific

423
00:31:49,640 --> 00:31:54,800
modeling problem and then realize, oh, actually this is more broadly applicable and do a

424
00:31:54,800 --> 00:32:00,720
handoff to another team to the platform engineering folks which has happened with a lot

425
00:32:00,720 --> 00:32:03,880
of our compute specifically.

426
00:32:03,880 --> 00:32:10,280
Did your team kind of identify this problem or Kubernetes in particular and kind of stand

427
00:32:10,280 --> 00:32:15,080
that up and then hand that off to the platform team later or were they already kind of ahead

428
00:32:15,080 --> 00:32:20,040
of that curve or you know, you got the same point in the curve?

429
00:32:20,040 --> 00:32:25,680
So the initiative to adopt MESOS came out of modeling engineering specifically when

430
00:32:25,680 --> 00:32:31,680
we were trying to solve this modeling problem of doing black box optimization at scale

431
00:32:31,680 --> 00:32:35,160
on like simulations.

432
00:32:35,160 --> 00:32:41,200
And then it turned out, yes, this is a workable solution and it is more broadly applicable

433
00:32:41,200 --> 00:32:46,000
so we should transition it over to another work.

434
00:32:46,000 --> 00:32:54,040
Okay, got it and Scott, SIGUP has been doing some things with Kubernetes as well.

435
00:32:54,040 --> 00:33:00,320
Can you talk about that and the relationship between the work you're doing on the optimization

436
00:33:00,320 --> 00:33:07,320
side and the infrastructure do you see in particular do you see folks, other folks kind

437
00:33:07,320 --> 00:33:11,240
of express that same challenge where there's one, there are things they want to do to

438
00:33:11,240 --> 00:33:17,200
empower their modelers and their researchers, but they run into infrastructure challenges?

439
00:33:17,200 --> 00:33:18,200
Definitely.

440
00:33:18,200 --> 00:33:22,600
We see this all the time where especially if you're transitioning from a world where

441
00:33:22,600 --> 00:33:29,320
you're maybe doing manual tuning of a model where it's an expert trying to do it sequentially

442
00:33:29,320 --> 00:33:33,320
in a notebook environment or something like that doing 10-dimensional optimization in

443
00:33:33,320 --> 00:33:37,320
your head is hard enough but trying to do that maybe across a hundred different workers

444
00:33:37,320 --> 00:33:40,400
is maybe impossible.

445
00:33:40,400 --> 00:33:45,120
But in addition to that being a hard optimization problem, it becomes just a hard like resource

446
00:33:45,120 --> 00:33:49,760
management problem of SSHing into a hundred different machines and making sure that they

447
00:33:49,760 --> 00:33:52,240
don't fail like Matt said and everything like that.

448
00:33:52,240 --> 00:33:55,480
So we're seeing more folks really doing it like that.

449
00:33:55,480 --> 00:34:00,400
We've definitely had users where they want to take advantage of our ability to do high

450
00:34:00,400 --> 00:34:06,640
parallelism as part of our optimization suite when we support up to a hundred individual

451
00:34:06,640 --> 00:34:07,640
workers.

452
00:34:07,640 --> 00:34:12,440
I've seen users, yeah, literally SSHing doing a handful of different machines and trying

453
00:34:12,440 --> 00:34:17,000
to like, they're using screen to keep the sessions alive and they're trying to do everything

454
00:34:17,000 --> 00:34:19,040
like that.

455
00:34:19,040 --> 00:34:23,080
And at the end of the day you could be an expert in deep learning and expert modeling,

456
00:34:23,080 --> 00:34:27,400
but then all of a sudden there's this massive barrier of DevOps and doing this right.

457
00:34:27,400 --> 00:34:33,760
So we try to be active members in this community, we're contributors to Kubeflow, we've developed

458
00:34:33,760 --> 00:34:38,360
our own solution called orchestrate that handles all of this for you as well.

459
00:34:38,360 --> 00:34:42,040
Take something that you might have written in a notebook and then very easily you can

460
00:34:42,040 --> 00:34:47,000
containerize it up, pass it off to a Kubernetes cluster, and then sigopt acts as this distributed

461
00:34:47,000 --> 00:34:50,760
scheduler for all of your training and tuning jobs.

462
00:34:50,760 --> 00:34:55,720
And we see this as again helping just amplify what these modelers are already doing.

463
00:34:55,720 --> 00:35:00,080
Like again, you could be an expert in defining the model, understanding the data and things

464
00:35:00,080 --> 00:35:01,080
like that.

465
00:35:01,080 --> 00:35:06,040
But you don't want that barrier of parallelism, that barrier of distribution to be what

466
00:35:06,040 --> 00:35:09,520
prevents you from really getting to that best possible answer.

467
00:35:09,520 --> 00:35:13,280
So we see this as something that some people are building into their platforms.

468
00:35:13,280 --> 00:35:18,840
We see this as some individual researchers just want to be able to have this superpower,

469
00:35:18,840 --> 00:35:22,520
but we're continuing to invest in that, both in actively contributing to the open source

470
00:35:22,520 --> 00:35:27,800
community and building specific tools tailored to the enterprise that we can serve our customers

471
00:35:27,800 --> 00:35:29,800
with.

472
00:35:29,800 --> 00:35:40,360
And across the folks you talk to, how do folks know when they need to transition from this,

473
00:35:40,360 --> 00:35:46,200
I'm going to do optimization, man, I guess there's one, there's the step zero I'm doing

474
00:35:46,200 --> 00:35:51,920
in my head and I need to do it programmatically or I need to do it manually.

475
00:35:51,920 --> 00:35:56,120
And then I need to do it in a more automated fashion.

476
00:35:56,120 --> 00:36:01,080
I'm trying to get a how do folks come to terms with, folks that aren't heavily investing

477
00:36:01,080 --> 00:36:07,120
in platforms or optimization or some type of automation, what are the things that you

478
00:36:07,120 --> 00:36:13,000
see like clicking for them that motivate them to start investing?

479
00:36:13,000 --> 00:36:14,000
Yeah.

480
00:36:14,000 --> 00:36:18,440
So I think it goes back to what Matt was saying around opportunity cost and you can define

481
00:36:18,440 --> 00:36:20,680
opportunity costs in a variety of different ways.

482
00:36:20,680 --> 00:36:24,600
So for some firms we work with, it's about expert productivity.

483
00:36:24,600 --> 00:36:28,000
So we're working with a global technology consulting firm where when they rolled us out

484
00:36:28,000 --> 00:36:32,800
globally, every single team that was using SIGOP was able to complete their client engagements

485
00:36:32,800 --> 00:36:34,600
30% faster.

486
00:36:34,600 --> 00:36:40,160
We're also working with a small startup that has five PhDs doing really cutting edge AI

487
00:36:40,160 --> 00:36:44,280
and their founder says they think of SIGOP is just another member of the team because

488
00:36:44,280 --> 00:36:47,680
it's taken this burden of doing this manual tuning off of them.

489
00:36:47,680 --> 00:36:50,960
And so that expert time can be a massive opportunity cost.

490
00:36:50,960 --> 00:36:55,800
But also, just if the performance of your models matters, that's more opportunity cost

491
00:36:55,800 --> 00:36:56,800
as well.

492
00:36:56,800 --> 00:37:01,560
Because usually optimization of architectures, feature transformations, hyper parameters,

493
00:37:01,560 --> 00:37:06,400
it takes time, but it's usually also orthogonal to any of the feature engineering you're doing.

494
00:37:06,400 --> 00:37:09,680
So it's added benefit that's otherwise being left on the table.

495
00:37:09,680 --> 00:37:12,320
It's not about replacing what your data science was doing.

496
00:37:12,320 --> 00:37:14,760
It's about just adding to what they're doing.

497
00:37:14,760 --> 00:37:17,000
So that's another big opportunity cost.

498
00:37:17,000 --> 00:37:20,160
And then finally, it's time to market its compute costs, it's things like that.

499
00:37:20,160 --> 00:37:25,480
If you're spinning up GPUs and waiting around for sometimes weeks to get the results of

500
00:37:25,480 --> 00:37:31,000
something being tuned, cutting that down to days or hours can really change the way you

501
00:37:31,000 --> 00:37:32,640
do iterative modeling.

502
00:37:32,640 --> 00:37:37,120
And so I think it's really about seeing if you run into one of these pain points or if

503
00:37:37,120 --> 00:37:41,840
there's just a lot of opportunity being left on the table, expert time, compute time to

504
00:37:41,840 --> 00:37:47,800
market, or just the value of these models that you're investing so heavily in.

505
00:37:47,800 --> 00:37:54,720
And are there particular types of models that are prevalent among your researchers?

506
00:37:54,720 --> 00:38:00,920
And from a platform perspective, are you building out specific platform capabilities

507
00:38:00,920 --> 00:38:03,000
to support specific kind of models?

508
00:38:03,000 --> 00:38:09,040
Or do you think about the world more model agnostic?

509
00:38:09,040 --> 00:38:14,600
So like I said before, we try not to be prescriptive about what our modelers do and we really

510
00:38:14,600 --> 00:38:16,600
do everything.

511
00:38:16,600 --> 00:38:23,840
And obviously, over the last few years, there's been a lot of buzz around deep learning and

512
00:38:23,840 --> 00:38:28,760
it is something that we have been looking at really deeply.

513
00:38:28,760 --> 00:38:32,680
No, put on bombs.

514
00:38:32,680 --> 00:38:39,920
But that is one technique where it really did turn out that we need to build some things

515
00:38:39,920 --> 00:38:46,400
that are specific to supporting that technique.

516
00:38:46,400 --> 00:38:53,960
So it is a pretty broad class of models or a broadly applicable technique.

517
00:38:53,960 --> 00:38:54,960
Right.

518
00:38:54,960 --> 00:39:00,680
So we have had to invest into things that are targeting deep learning scenarios.

519
00:39:00,680 --> 00:39:06,080
Just to even test out whether it works on our types of problems.

520
00:39:06,080 --> 00:39:12,360
And as we all know, hyper parameter tuning there is also a big challenge.

521
00:39:12,360 --> 00:39:16,280
So that's another place where we are playing Sigopt.

522
00:39:16,280 --> 00:39:22,440
And was that something that just worked out of the box like, was it, did you have to

523
00:39:22,440 --> 00:39:29,440
do anything special to apply Sigopt or any other other things in your tool chain to deep

524
00:39:29,440 --> 00:39:36,960
learning or was it just work?

525
00:39:36,960 --> 00:39:42,440
The challenge is around getting the machines that have the GPUs that we want in order

526
00:39:42,440 --> 00:39:43,680
to use it effectively.

527
00:39:43,680 --> 00:39:48,480
So that was one thing that we had to change how we do some stuff.

528
00:39:48,480 --> 00:39:53,520
That's me sounds like infrastructure like Kubernetes and scheduling and that kind of thing.

529
00:39:53,520 --> 00:39:54,520
Yes.

530
00:39:54,520 --> 00:39:55,520
Okay.

531
00:39:55,520 --> 00:40:01,240
But as far as Sigopt goes, one of the things that we love about it is how well it works

532
00:40:01,240 --> 00:40:08,280
out of the box and how easily it integrates with so many of our existing platform solutions.

533
00:40:08,280 --> 00:40:14,240
Kind of looking back over the past 12 years are there things that you had approached

534
00:40:14,240 --> 00:40:18,640
very differently knowing what you know now?

535
00:40:18,640 --> 00:40:19,920
That's a great question.

536
00:40:19,920 --> 00:40:27,080
So the one thing that immediately comes to mind is Python and how dominant Python has

537
00:40:27,080 --> 00:40:32,800
become in the data science modeling space.

538
00:40:32,800 --> 00:40:39,200
That is something that certainly wasn't obvious back in 2001, it wasn't obvious when I had

539
00:40:39,200 --> 00:40:40,200
started.

540
00:40:40,200 --> 00:40:43,040
We've been a JVM shot since the beginning.

541
00:40:43,040 --> 00:40:50,240
So built out a lot of tools and infrastructure on the JVM for doing not just for building

542
00:40:50,240 --> 00:40:54,920
or systems, but for doing the analysis that we need to do.

543
00:40:54,920 --> 00:41:03,920
So I would say investing more in Python earlier on, getting on that train would have been

544
00:41:03,920 --> 00:41:10,640
something that I would do differently, but it really has taken over for us, our modelers

545
00:41:10,640 --> 00:41:11,640
come in.

546
00:41:11,640 --> 00:41:17,480
Everybody higher comes in with that as their language of choice, the best library, open source

547
00:41:17,480 --> 00:41:25,440
libraries are out there and obviously the deep learning world is dominated by Python as

548
00:41:25,440 --> 00:41:27,240
well.

549
00:41:27,240 --> 00:41:31,960
So having had that experience, how do you apply that forward?

550
00:41:31,960 --> 00:41:38,080
Does that lead you to wanting to touch and try everything or are there specific things

551
00:41:38,080 --> 00:41:45,440
that you now see were clear in Python and Python's rise that you can apply that pattern

552
00:41:45,440 --> 00:41:48,680
matching to other things?

553
00:41:48,680 --> 00:41:52,940
I don't think so, but I think that the one change is that it's made us approach things

554
00:41:52,940 --> 00:41:59,720
in a more language and like platform agnostic way or not relying on everything happening

555
00:41:59,720 --> 00:42:04,320
on the JVM, so you can't predict what's going to win.

556
00:42:04,320 --> 00:42:09,720
So you have to build something that's flexible and that can support some different things.

557
00:42:09,720 --> 00:42:10,720
It's interesting.

558
00:42:10,720 --> 00:42:17,920
Folks, that end up on both sides of this, it takes a lot more resources to support

559
00:42:17,920 --> 00:42:20,520
something that supports everything, right?

560
00:42:20,520 --> 00:42:27,040
Then it does to build a very targeted solution and be prescriptive.

561
00:42:27,040 --> 00:42:34,600
But this is a great argument for not doing that because you don't know what we all pronounced

562
00:42:34,600 --> 00:42:41,880
in TensorFlow, the winner without any challenges and all of a sudden PyTorch popped up, right?

563
00:42:41,880 --> 00:42:48,720
And now it's totally reasonable to allow your modelers to use that if that's their preferred

564
00:42:48,720 --> 00:42:49,720
kind of interface.

565
00:42:49,720 --> 00:42:54,360
That's just one example of how stuff you think it's a game over and stuff just pops up

566
00:42:54,360 --> 00:42:55,360
out of nowhere.

567
00:42:55,360 --> 00:43:02,000
Yeah, but that said, some of the platform agnostic choices that we make are actually just

568
00:43:02,000 --> 00:43:08,240
the right choice to make any way, or they have additional benefits aside from being somewhat

569
00:43:08,240 --> 00:43:09,240
future-proof.

570
00:43:09,240 --> 00:43:16,320
For instance, data access and doing that through services where we're not having any expectation

571
00:43:16,320 --> 00:43:22,080
of what the consumer is, is an example of a way that we're adapting based off of what

572
00:43:22,080 --> 00:43:24,120
we've observed.

573
00:43:24,120 --> 00:43:30,440
And so if you were talking to a team that has been doing modeling, has been doing data

574
00:43:30,440 --> 00:43:39,280
science, has achieved a level of success there, but is early on in thinking about formalizing

575
00:43:39,280 --> 00:43:44,280
a platform effort, what kind of advice would you give to them?

576
00:43:44,280 --> 00:43:51,600
Well, the world is so different now and also a lot of those places if they're just starting,

577
00:43:51,600 --> 00:43:53,640
they're operating at a very different scale from us.

578
00:43:53,640 --> 00:44:01,600
So the cloud providers and their solutions are wonderful, especially at smaller scales,

579
00:44:01,600 --> 00:44:05,680
but even in some cases for folks at our size.

580
00:44:05,680 --> 00:44:11,120
So picking one and really taking advantage of it and all of the services that they offer,

581
00:44:11,120 --> 00:44:16,120
while being mindful about vendor lock-in is probably what I would say to focus on.

582
00:44:16,120 --> 00:44:25,560
Yeah, when you think about the cloud providers or generally about any kind of package offering,

583
00:44:25,560 --> 00:44:30,240
they often have kind of gaps that get in your way that can be hard to feel like, how

584
00:44:30,240 --> 00:44:37,280
do you balance that concern versus, you know, kind of the ease or just kind of getting

585
00:44:37,280 --> 00:44:41,880
everything all at once, or it is, first of all, is that a challenge that you've had

586
00:44:41,880 --> 00:44:47,440
to kind of engineer around in the past and if so, how do you kind of think through all

587
00:44:47,440 --> 00:44:48,440
that?

588
00:44:48,440 --> 00:44:52,320
It hasn't been so much of a challenge for us because we have been running our own data

589
00:44:52,320 --> 00:44:53,600
centers for so long.

590
00:44:53,600 --> 00:44:59,640
So we've already got things working really well without all of the cloud provider-specific

591
00:44:59,640 --> 00:45:01,440
offerings.

592
00:45:01,440 --> 00:45:07,960
So it made leveraging the cloud provider's compute really easy because we weren't dependent

593
00:45:07,960 --> 00:45:12,920
on any of their bespoke solutions.

594
00:45:12,920 --> 00:45:17,600
More generally than cloud, there are a lot of folks that are a lot of startups and even

595
00:45:17,600 --> 00:45:27,720
mature companies that are trying to offer NN1-size-fits-all platform in a box kind of solutions.

596
00:45:27,720 --> 00:45:34,080
And the route that you've gone is to at least in the case of optimization, identify kind

597
00:45:34,080 --> 00:45:41,360
of a best of breed, you know, focused, targeted thing and kind of plug it into some broader

598
00:45:41,360 --> 00:45:42,440
thing that you're building.

599
00:45:42,440 --> 00:45:48,160
Like when you think about kind of the role of that end-to-end, you know, versus kind of

600
00:45:48,160 --> 00:45:54,160
building based on, you know, individual things that you like, like how do you kind of parse

601
00:45:54,160 --> 00:45:56,840
all of that?

602
00:45:56,840 --> 00:46:00,600
Because we've already been doing it with components, separate components and haven't

603
00:46:00,600 --> 00:46:04,680
been leveraging one end-to-end solution because nobody really does everything that we

604
00:46:04,680 --> 00:46:05,680
need.

605
00:46:05,680 --> 00:46:11,920
I mean, we like to think deeply about every step of the process and find the right solution

606
00:46:11,920 --> 00:46:14,760
for each step.

607
00:46:14,760 --> 00:46:19,960
So that's one of the things that really appealed to us about Sigopt was that it really did target

608
00:46:19,960 --> 00:46:28,200
this one problem and solved it in a way that didn't, that wasn't locking us into any particular

609
00:46:28,200 --> 00:46:34,320
technology before or after that stage, that really was a huge benefit for us.

610
00:46:34,320 --> 00:46:39,680
And then on top of that, the fact that it could be used on any of the cloud providers,

611
00:46:39,680 --> 00:46:44,920
it wasn't just one solution that was like trying to keep us locked in somewhere, it was

612
00:46:44,920 --> 00:46:46,920
also a big benefit.

613
00:46:46,920 --> 00:46:51,280
And Scott, I'm curious if you have any perspective on that, you certainly, I'm sure you get asked

614
00:46:51,280 --> 00:46:52,280
that a lot.

615
00:46:52,280 --> 00:46:53,280
Yeah, definitely.

616
00:46:53,280 --> 00:46:58,920
And I think, again, it's going back to standardizing where it makes sense, but doing so in a way

617
00:46:58,920 --> 00:47:01,280
that's non-constraining.

618
00:47:01,280 --> 00:47:06,600
So as Matt was saying, you don't want to spend all your time being future-proof, but

619
00:47:06,600 --> 00:47:11,720
you definitely need to recognize that the flavor of the month is going to change.

620
00:47:11,720 --> 00:47:16,000
Four years ago, a lot of people using Sigopt were using Psychic Learn primarily, and now

621
00:47:16,000 --> 00:47:20,840
we see a lot of TensorFlow and PyTorch, and we're already starting to see quite a bit

622
00:47:20,840 --> 00:47:25,400
to pick up of reinforcement learning, even in production, with firms like OpenAI that

623
00:47:25,400 --> 00:47:27,400
use us.

624
00:47:27,400 --> 00:47:32,040
And two years from now, it's all probably going to be different, like the landscape continues

625
00:47:32,040 --> 00:47:37,280
to change, and it's not just the landscape of tooling, it's the landscape of infrastructure

626
00:47:37,280 --> 00:47:38,760
providers as well.

627
00:47:38,760 --> 00:47:42,560
Again, four years ago, AWS was so far in front of everybody else that you didn't really

628
00:47:42,560 --> 00:47:47,880
think twice, but now there's other providers out there, people use hybrid solutions, firms

629
00:47:47,880 --> 00:47:52,560
like Dropbox are moving back off of the cloud for cost-saving measures, and it's really

630
00:47:52,560 --> 00:47:58,640
about saying, what can I bring to the problem, what do I differentiate, and then leave optionality

631
00:47:58,640 --> 00:47:59,640
everywhere else?

632
00:47:59,640 --> 00:48:04,160
And that's something that's core to us, being agnostic to the tooling, the infrastructure,

633
00:48:04,160 --> 00:48:05,160
whatever it is.

634
00:48:05,160 --> 00:48:09,800
We want to meet you where you're at and augment what you're doing, not try to fit you into

635
00:48:09,800 --> 00:48:13,000
a sandbox or lock you into something in particular.

636
00:48:13,000 --> 00:48:18,520
Well, Scott and Matt, thanks so much for taking the time to chat about this very, very interesting

637
00:48:18,520 --> 00:48:19,520
topic.

638
00:48:19,520 --> 00:48:22,960
I appreciate having you on the show.

639
00:48:22,960 --> 00:48:24,280
Thanks so much, Sam.

640
00:48:24,280 --> 00:48:25,280
Thank you.

641
00:48:25,280 --> 00:48:31,160
All right, everyone, that's our show for today.

642
00:48:31,160 --> 00:48:35,560
For more information about today's guest, or to follow along with AI Platform Volume

643
00:48:35,560 --> 00:48:40,920
2, visit twemalai.com slash AI Platforms 2.

644
00:48:40,920 --> 00:48:47,040
Make sure you visit twemalcon.com for more information or to register for Twemalcon AI

645
00:48:47,040 --> 00:48:48,040
Platforms.

646
00:48:48,040 --> 00:48:52,440
Thanks again to Sigout for their sponsorship of this series, to check out what they're

647
00:48:52,440 --> 00:48:58,080
up to and take advantage of their exclusive offer for Twemal listeners, visit twemalai.com

648
00:48:58,080 --> 00:48:59,880
slash Sigout.

649
00:48:59,880 --> 00:49:11,360
As always, thanks so much for listening and catch you next time.

