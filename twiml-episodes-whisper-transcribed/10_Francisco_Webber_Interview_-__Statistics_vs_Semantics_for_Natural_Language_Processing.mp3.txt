Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
Once again the recording you're about to hear is part of a series of interviews I've recorded
live from the O'Reilly AI and Stratocomferences in New York City.
My guess this time is Francisco Weber, who is the founder and general manager of Artificial
Intelligence Startup, cortical.io.
Francisco's presentation at O'Reilly AI was called AI is not a matter of strength but
of intelligence.
To set the stage for my conversation with Francisco, recall that in the last interview Pascal
Feng noted how recent advances in natural language understanding have been based largely
on ignoring language structure and focusing on statistics.
While in this interview you'll hear Francisco argue that the next advance in NLU will come
from shifting our attention from statistical models to models based on a more sophisticated
model of the brain.
A warning in advance, this conversation is very technical and moreover rather abstract.
Don't be afraid to listen to it a couple of times to allow the ideas and opportunity
to sink in.
You'll find this week's show notes at twimlai.com slash talk slash 10.
You might be particularly interested in a link to Francisco's presentation slides which
are helpful to review alongside the podcast.
And now on to the show.
Hello everyone here at the O'Reilly AI conference and I am with Francisco Weber, who gave a great
talk earlier on AI is not a matter of strength but of intelligence.
So welcome Francisco.
Hello, great to be here and to talk about my talk actually.
Nice, why don't we start out by learning a little bit more about you and hearing a bit
about your background?
Yeah, so I'm coming from the natural sciences, I'm trained in medicine in Vienna but I have
since ever sort of a built-in affinity to technology and ended up sort of going into
the natural language processing information retrieval domain where I'm in for like 20
years now but I've been the so cortical I always actually my third company, I previously
worked in the field of patent information which is also a sort of complex natural language
issue and that was basically where I learned of the limitations of the current systems
and that motivated me to actually try and find something substantially different.
Okay, so tell us a little bit about cortical.
Yeah, so cortical is all about two things in fact, so one thing is a theoretical framework
that we have discovered I would say and that we explore that is about how the human brain
to be more specific actually the new cortex supposedly handles language information and
the other is that we basically use this theoretical framework to also create a real technology
that we basically offer to the markets currently this is mainly for enterprise customers.
They have a lot of problems out there and so say the effort to revenue ratio makes us
work there for a while but we do also have a public API where basically everybody can play
around with our technology for free.
Yeah, so that's what the company sort of does and we try to find the really alternative
way to deep learning and to the more traditional ways of statistical modeling and machine learning
for the moment our approach doesn't actually use any statistics so which might not be
the case in the future so there are some motivations to maybe team this up with deep neural
networks or so so that's but in fact it's not our speciality so I leave this to others
to try out what we basically do is that we have solved I would say or we have found a
solution to the famous representational problem that exists in natural language understanding
since decades basically a very fundamental issue is that basically says if you find out
how to represent language which means text at some point in a way that you can actually
compute with it then many of the big problems like ambiguity like vocabulary mismatch all
the traditional problems we have in NLU basically are solved in one approach and that's what
I actually presented today is that by this little shift in how to generate the features
in falling place afterwards in a very convenient and most importantly efficient manner so tell
us about this shift yeah so our approach basically is founded on the work of Jeff Hawkins
who is a researcher in in the area of cortical processing so he works on finding out how
the human new cortex actually processes data as a data in general because one of his findings
was that regardless what kind of data so might it be hearing or seeing or touching all
of that data when it comes to the new cortex looks the same it has the same format which
is a what is called a sparse distributed representation so it's like a large vector
of binary features where you have like two of two to five percent of those features are
actually set to one and all the rest is zero and everything is encoded into such a such
an SDR and that was basically our first goal is to find a systematic unsupervised because
otherwise it's not doable in practice a systematic unsupervised way of converting text into
such an SDR okay now I've heard a couple of times even at this event there were a couple
of comments that were made that one of them was even I think in the key notes this morning
there was a comment about how you know what we've got with neural nets are don't have
the complexity and the nuance available to express what's actually happening in the brain
and and in another talk the kind of follow on statement was so therefore we shouldn't
try we should just use these as tools and now it sounds like you you have a totally different
belief system around this well I mean fundamentally what we use as neurons nowadays has in fact
very little to do with real neurons yeah so it was an abstraction that was made like 30 40
years ago on a compared to today on a very rudimentary understanding of what neurons actually
do nowadays we know more we know that for example the actual learning happens through the building
and unbuilding of synopsis between them and if you actually model a neuron not not chemically
so it's not about sort of creating all the molecules that are there because that's something
that nature uses yeah so nature you know in evolution you always have the components from
the previous evolution evolutionary state and you have to play with this kind of Lego bricks
and do something which sometimes looks a bit inefficient but what is key on the other side is what
is the mechanism that those real neurons create and that is what Jeff Hawkins actually has figured
out and is about to even figure out in more detail okay and so certain aspects like the the
sparse binary representation are actually key for this to work properly and by working on text so
our approach is basically okay if Jeff is right with his theory everything he says about the
general way how the cortex processes has also to be truthful language as the language is generated
by the cortex too and so we basically took his theoretical framework as a set of constraints and
we tried to say okay if that is the limitation how can I put everything I know about language
within this limitation and it took a while actually 25 years or so in general I mean not I know
Jeff's work since since a little bit over 10 years but everything that was sort of needed to
me at least to sort of understand and to operate at this abstraction level took a while but then I
had at some point while I was listening to his talks reading his book on intelligence and so
and it was literally sort of taking a shower and in a second I had this visual idea so to say
how this could happen okay because it boils down to a sort of visual aspect in the sense that
as a necessity we have to find a representation where two words that mean similar things have to
actually look similar and when I say look there as the hours have to be similar and literally
similar so in fact and that's also what the brain is doing to put one word representation on top
of the other word representation and by measuring the overlap how many of the bits actually stay
at the same position you get two things one is how related are those words and the second is by
looking where the overlap happens within this representation because this is a two-dimensional
it's like a bitmap with 128 times 128 pixels and like 2% of those 16,000 bits are set to one
therefore are like pixels dark pixels if you want and so it's actually a visual thing and
you can try this out on our website when you take two words that are sort of have a common context
or so you can actually literally see that they look similar yeah and interestingly I mean it's
hard to or maybe even impossible to absolutely decode what it means but if you as I have done
stare a lot into these representations you end up seeing the differences like in the blink of an
eye you might not know the details but to identify that two words are similar in this representation
takes a millisecond yeah and that is already a hint so to say that shows what the major gain is
of this approach which is efficiency and that's what our brain is famous for so I know that
on the deep learning in the deep learning community things like precision and so are the key
metrics and they are of course important it's like having glasses that are blurry nevertheless
at the very end the choice of algorithm is not so much on the precision but it relates to
down to earth energy efficiency yeah I mean the brain works with something like 10 watts or something
so I don't even want to know how much power the GPU servers
each up and that is already a very good hint of how well a certain approaches yeah if
and that's why I chose the title also of brute force because statistics especially if you do
statistics of large combinatorial spaces like like language I mean you basically can create
an indefinite number of combinations of words to make meaningful sentences so to do a statistics
on such an open system it's a real hard work because you have to provide endless examples
to have like a microbit of semantic payload in your representation yeah and it works up to a certain
point no question I mean the statistical systems work but what you see is that in order to make
the model a little bit smaller or to gain a tens of a percent in precision you have to put a lot
of effort in yeah so from to get from 60 to 61 percent precision you might even double the effort
of like going from one to 60 is the same as from 60 to 61 yeah if I could drag you drag you back
a little bit just it sounds like understanding the Jeff Hawkins stuff is important to understanding
what you guys are doing to some degree yes so they so he's defined the sparse data representation
this SDR and is there also a different concept of a neuron that underlies that absolutely so he's
modeling a real neuron but on the functional level so he's also modeling a neuron if you want
but he's modeling everything that is relevant within the neuron for processing data is part of
his model and everything that might be housekeeping building up proteins and stuff like that is not
part of the actual data processing layer and therefore not represented there so he's basically
tried to expand the simplistic concept of a neural net neuron to become a real neuron and sometimes
if you face the problem the way it is the solution is much easier to understand yeah because it's
basically a model-based approach versus a model-free approach so sort of bringing it into one
sentence yeah and so on this base of this more robust model of a neuron there's this notion of
the SDR which is capturing you know and I think of a neuron I think of the you know there's
state plus action right and so this is capturing state even more it's state action and time
that is key to what Jeff is doing okay because his networks have a time built in okay so it's not
only of deciphering a pattern of input bits but it's rather memorizing a sequence of patterns
because in reality things are interconnected so to say they have a semantics built into the system
everything and therefore it is highly improbable if not impossible that by having an initial state A
you can predict which are the let's say physical possible next steps and that's what the processing
relays are yeah the fact that not like in statistics after state A any state could happen
because I need to do the statistics for it but the reality is that after a step A there is a
certain set of steps which have all to be possible in reality and what we learn as walking brains if
you want is what are those potentials what are the potential outcomes and how many hints from the
initial state could point me to the right next state and that's in the end what the brain is doing
yeah the brain is nothing more than a sequence learning engine that does prediction based on what
it has seen so far and if you think through that on a let's say philosophical level you will find
out that you basically can solve or explain everything we do that basically follows this basic
computation yeah so there are two interesting aspects so this one is there is no processor
so the brain does this by being a memory system which is interesting I mean in computers it's
exactly the other way around yeah the processing happens in the processor and the RAM is just a
dormant store yeah and the brain obviously does this differently and the other aspect is that the prediction
is in fact the condensed intelligence because the more I'm right in predicting the more I'm intelligent
and by the way I mean there you know there have been very behavioral ways of looking at intelligence
that's the reason why the dog looks intelligent to the dog owner because the dog owner knows the
dog and knows what predictions the dog is making about things and is right in doing so and therefore
the dog indirectly so to say looks more intelligent to the owner than to everybody else yeah
yeah so does the SDR capture all of that are just the state so the SDR is all about getting a
an explicit representation of the state so that's the other difference in the world of brains
and the SDRs you only work with what is called semantically grounded information so every bit
in representation of the SDR actually corresponds to something real and concrete so for the visual
system it's pretty easy because in the end every bit of the image that is produced on the retina
if you have two dots that are close to each other and have the same color or nearly the same color
you are probably right in guessing that they are part of the same item in the physical world yeah
if you have now a representation that gives you the same phenomenon namely that two
bits that are set to one stay close to each other it's easy to guess that they are related and they
are part of the same maybe subunit of the system the only thing you have to be sure is that
the data that is provided is actually inherently semantic so it has to be part of a system in
on a very abstract level yeah so the world is a system therefore any data that I can hear or see
or so about the world is semantic because there are rules of physics rules of biology and so on
and the same thing is truthful language language is data that is inherently tied together by a
framework of grammar of syntax and all these aspects we know since a long time but we have
we had the problem on how to actually store these mechanisms and the realities don't store the
mechanism but just store the examples just store the detailed information the explicit information
and are those words or those yeah so in our approach we declare the semantic atoms in language
to be words I mean there are like smaller units like phonemes for example but they have no
meaning but themselves so the first time you actually have a meaning is when you have a word
and all the subsequent meaning of a sentence of a paragraph a document an utterance even
comes out of the sequence of those words yeah and so what we do is basically we convert every single
word into such a sparse representation we call this because it's so hard to say we call this
a semantic fingerprint okay and the interesting thing is that through the way how we convert
the semantic fingerprint you take advantage of some of the properties that are inherent of sparse
binary vectors for example you can make a union of as many sparse vectors as you want and you
don't lose information yeah you can always say from an unseen vector if it was part of the union
or not if you try to do the same thing with a dense representation let's say the the ASCII encoding
you have eight bits and every possible combination corresponds to another character if you make a
union of a couple of them no way to say what was the initial part yeah and as I said the the
generation of this pattern is done in a way that every single pixel of our fingerprints correspond
to an explicit learned context and you can infect not a word a context it's a context which is
basically technically it's a bag of words if you want it's a bag of words of utterances in which
the word occurred and so is a what's the scope of an SDR in this model is it at the level of a
corpus at the level of a language at the level of an utterance well not an utterance because
an utterance in fact all of that so the the what we do is in principle we generate the atoms which
is a fingerprint for a word but if I want to create a fingerprint for a sentence I just convert every
single word into its fingerprint I make a stack and aggregate them together I make an ore of all of
them and then I have depending on the location on the fingerprint you can do that's because of
this union property exactly exactly yeah that's the reason why we have to stay on the sparse side
yeah and if you make for example a union of let's say ten words that are in a sentence you of
course fill up the representation therefore after making the union we we do what we call resparsify
we introduce a threshold to cut away everything that fills the fingerprint on more than the two
percent and so we end up with a fingerprint for a sentence that has basically the same topology that
is directly comparable to a fingerprint of a word and we can do this with a sentence with a paragraph
with a book yeah of course the SDR for book or for whatever let's say a book is it end dimensionality
where n is the number of unique words in the book no so there is the topology and there is
that's the name why why we call it semantic folding there is this semantic space folded into the
representation so the way how we do this how we generate the word SDRs is that we take a collection
of documents which are the reference documents that's for a human that would be everything you ever
read and heard yeah all language elements that you got exposed to and we digest them and we do
this of course using machine learning because we are not like humans we have not the time to wait
20 years or so so that's in fact where we apply machine learning and what we do is that we
first of all cut the training material in little pieces and then we define the size of our
fingerprint which is a metric space so there is no dimensionality if you want it's a two-dimensional
metric space and we position all of our training snippets on this space in a very simple rule
two snippets that are similar stay close together and two snippets that are different stay far apart
from each other and then it's you know one of these classical iterative algorithms similar to
heavier learning a bit like this local inhibition mechanism and what you end up with is that you have
all snippets about animals in one region all snippets about family in another region and so on
and you get a semantic map and this semantic map is basically used to encode every word because
I can take all the words that are in my training material and for each of the words I can say light
up the positions of the snippets where this word occurs in and then you get this distributed
representation and because you have to fold it in semantics so to say two similar words like cat
and dog look similar if you look them on the on the semantic map representation of the fingerprint
so you mentioned earlier kind of a you give an example of 128 by 128 matrix at that size matrix
like what are you able to represent like is that a book all of the books I've ever read or
so what it actually represents is a semantic space because it's the fundamental of the representation
and if you just do the math of selecting 300 bits which is about close to 5% of 16,000 bits
the number of combinations you can do is like the number of stars in the Milky Way so it's a huge
combinatorial space and as you know we have not the same assumption as in statistics that in principle
every word could be combined to every other word yeah so that's one of the central
simplification methods is to say in the language statistics that every word is independent which
is absolutely not true yeah if you have on the semantic level a certain set of adjectives that
you associate to a certain noun yeah so there is semantic sort of glue between everything
and in reality that shrinks the combinatorial space and that's precisely what we need to learn
the semantics of it yeah okay okay so this there are elements of this that remind me of war
Tevac I guess it's a natural development that we have started NLP and information retrieval
with so-called document vectors everything was sort of derived from a document and we found out
over the years that word vectors the representation of individual words seems to be more appropriate
nevertheless there is a fundamental but crucial difference so word-to-veg like other word embedding
mechanisms use they try to do dimensionality reduction and they end up with a dance vector
and to put even more on it a dance vector of double of float numbers so sort of computationally
expensive representations we don't do a dimensionality reduction we might even to an increase the
dimensionality at some point if you want but we make it a sparse representation so we have
sparse binary vectors versus dance floating point value the double vectors yeah which already
sort of gives you a hint on where the efficiency will be right right so have we talked
through have we got to what you talked about in your talker is this all been back
I mean I was talking because my head already I understand I mean especially because you are
listening to this without any visual support and this is a very visual thing yeah so
typically when I when I show this and people see the the fingerprints on the screen and how they
interact and how they overlap you can see in their faces ah I understand this yeah you don't
need to know anything about machine learning or so it's so intuitive but if I imagine to sort of
follow a description that is purely verbal then you're doing a great job yeah so the rest basically
was that I gave a number of practical examples where we apply this okay and I can cite a few
for example we do pro let's say we we have certain prototype ways of solving typical problems
and what is the case is that we solve all of them with one unique operator which is similarity
yeah so we only the only sort of verb we have in our universe is is similar or is not similar
and so one thing you can do of course is search yeah so you can and since you're operating on
essentially the sparse vector representations is when you hear similar like is it fair to think
geometrically similar geographic yeah literally so so we actually measure this by calculating the
overlap between two fingerprints which is the most generic way I mean we we do offer a number of
distance metrics as I said this is a metric space so we have different ways of calculating a
distance metrics like a Euclidean distance and others but I have to say that in fact the pure
overlap count is fully sufficient to get the result out of it and it's very computationally efficient
yeah so one of the prototypes as I said is search imagine you have a collection of documents you
convert each of the documents into a fingerprint you have a user who types in a language-based query
now I'm looking for information about red spot cars you create a fingerprint of that query
and you just match how much overlap you have between all the documents and the query
and you rank all your documents according to the size of the overlap yeah very generic it's
it's a real search mechanism so what you get is really all the balanced aspects that you have
in a document so it's not just does a document contain the word sports car but it's about
the aspects that you might have developed in a document that make it match or less
and then theory the document need not even say sports car and exactly are doing theory
the similarity to the this conceptual yeah yeah yeah so it could be the race car it could be a
text about the race car and my query could be about sport cars and it would still sort of give a
good match yeah and how does it apply to non-English languages I didn't hear anything English
completely independent of languages so as I used to say it gives me enough dictionaries and
encyclopedias in klingon and I put you up a klingon system no problem the point is that we have
even brought this to a step further because we were able to not only train in different languages
the semantic spaces but to also topologically align them and as a result and I gave the example
in my talk we take the word philosophy in English has a certain representation and the
word philosophy in French has the same representation so the patterns are the same and what this means
is you could have a system that contains English documents and you can post French queries and
it will still work without any translation or or anything in between only for those words that
have a fair degree of overlap or well that the word the words with the same meaning regardless
of the language have the same fingerprint right yeah so a second prototype where I could give you
an example is classification so our classifiers are actually just fingerprints I don't need to train
my classifier if I say I want to get let's say all the tweets about mobile phones I can take the
word mobile phone create a fingerprint and then compare the fingerprint of every incoming tweet
to my fingerprint of the word mobile phone and even if it talks about iPhone it will have sufficient
overlap for me to detect it and even if the tweet is in Chinese it will be converted into something
that I can filter with my English mobile phone fingerprint even simultaneously in Chinese
because you're fingerprinting that based on its language representation and there's the
and the similarity exactly transferable from one to the next the Chinese description of the new
iPhone generates the same fingerprint as the English description of the new iPhone
why is that because the should we have surprised at that definitely you should be surprised
yes and no I mean people who know two languages are able to do this in the same way yeah so there
has to be a let's say mathematical way of doing this and the point is that we aligned the two
semantic spaces so we have one topology that we generate in one language and we can then with a
with a pure dictionary lookup mechanism which is the dumbest way of doing a translation
we can convert all the distributed snippets in the vocabulary of the other language
and use the same distribution that we have trained with for example the English method
and therefore you have now the convenience to listen let's say to the Twitter
firehose and regardless of what language message comes along you can filter it with an English
example and I've done that just to give you a feeling on efficiency I've done that in real time
on the firehose with my notebook yeah so it was sort of running locally I'm trying to run through
the I'm trying to run through the physical analogy that were the biological analogy of this like
and you know if the if the notion here is that you've kind of extracted this model that you know
more closely represents what's happening in the the brain then and you can you have this kind
of transferability across languages um is there some you know again we're kind of way beyond
you know the pale of what's actually going to happen but like is there some like you take the
you know some part of the brain from someone who learned Chinese and you transplanted into
a person you know and then you know who has some other part of the brain that is kind of
symbolically linked to English and they could then you know translate on the fly like
yeah in theory in theory that would be possible the truth is that there has been research for
example comparing the brain patterns of people who have who have been grown up with two languages
they have they have a sort of speech area in the brain that is actually
intricately mixed yeah so the two languages are represented in a mixed fashion whereas people
who have been grown up in one language and who have then learned the other one they have added the
second area so to say and that's the reason why a native speaker of two languages can actually
easily do translation on the fly and can listen or read text in two languages without even noticing
that there might be two languages right and someone who has just learned another language has
always in his head to map from the one region into the other region now interestingly there is
and I showed this also in my presentation there is sort of new research in brain science that
supports our representations strongly so they were able to do an fMRI study to be precise so
there has been an earlier version of this experiment where people were exposed to words and then they
made like snapshots from their fMRI activity and what they found out that was in counting a
melon if I remember well what they found out is that you can actually calculate starting with the
picture an fMRI picture you can say what word this person was hearing when this picture was
taken yeah so this is as you say wow but it comes better and they have sort of trained a
machine learning algorithm to make this transfer to correlate the picture with the word that the
persons have been hearing and the absolutely unbelievable thing is that let's say you have
been in the fMRI first the model has been trained on your images to map to certain terms
if now you present this very same model the images taken from my brain it will still recognize
the terms properly and that is independent of whether we speak the same language no I'm talking
about this has been done in English yeah I'm I'm pretty sure that even if I would do this with
with the portuguese meaning of your English terms it still might work out but maybe not Chinese but
but why not the the the the fact is that obviously if two individuals have been grown up
sufficiently similar from a cultural point of view yeah so we both went to school for
more or less the same time we more or less read the same stuff we've heard about the world
in the same way the representation ends up being similar across individuals and in the end it's
it makes a lot of sense I mean just imagine if we would really be wired completely different
from one to each other it's it would be very hard to have a simple conversation yeah and in fact
if you if you do the the investigation for example I'm pretty sure again this is just guessing
but the fmri pictures from I don't know some distant tribe living somewhere in the Amazon and
jungle they're the overlap between the two representations is probably less because they have
just not been exposed to a very similar kind of environment yeah and and there is a newer
publication which is I think it's from this year I think it's it's it's from a lab in the MIT
and there they were actually able to create a map of about thousand words on the basically
nearly the entire cortex and and what it shows is that every it's not like every word has a
specific position but every word has a pattern of all sorts of positions all over the cortex that
lights up which is in fact exactly what we are doing with our fingerprints yeah so I claim that
we are the first NLP algorithm that gets support by fmri so this is fascinating stuff
how do you help people make it practical like what if I'm you know if what what are the problems
that hey if I have this problem I should be looking at this as a possible approach so so as I say
earlier we are very strong with this approach in doing similarity calculation and therefore
classification and as you might know in business natural language processing nearly all problems
can be reduced to one or several classification problems okay so we do all sorts of things yeah
I mean companies who say we want to classify our inbound emails in product requests complaints
and I don't know looking for a person an individual in the company and believe it or not
I haven't seen any working machine learning solution for that problem out there I mean I've
been visiting like 150 companies over the last two years of course trying to sell our stuff
right but I haven't seen a working solution for simple I mean this is really one of the most
basic issues you could have and nearly nobody is actually using technology for that
because the statistical approach has a lot of noise that comes in has false positives which is
by the way the the biggest problem in business and we solve we solve this in a couple of weeks
so we we make use of the efficiency of the approach in solving this kind of problems within very
short time for people and so that's that's a specific use case are there is there like a higher level
characterization like you know in terms of problem yeah so we have customers in the domain in a lot of
customers for example are in the banking domain there we solve problems like compliance monitoring
nor your customer activities or automation of business processes that depend on some text input
at some point we have consumer good companies who want to know how to segment their customers for
example we have a manufacturing industry where for example in technical products the documentation
the manual of the product is so complicated good example is car industry for example a modern car
is so complicated that if something breaks you need to visit the manual or to find out what is
this funny light meaning there is this dangerous or can I just continue and people can't find
anything because they have the problem that the person in the car doesn't speak the technological
language so an example that I've that I've learned is the query where do I find the donut
in in the US yeah so I didn't know that before but obviously the donut is a spare wheel that
is sometimes pretty good hidden so if you look for donut in the in the manual you probably don't
find it yeah and there is a lot of these issues yeah I mean to be even a more extreme case a person
speaking only Spanish driving a US car and being unable to actually find the the right answer
could use our system to sort of pose a Spanish query and be pointed to an English page for
example so as I said I mean in principle we have solutions all across the domain we can do
things like for example you have a LinkedIn profile you describe yourself in your LinkedIn profile
I can make a fingerprint of your profile and if I do a fingerprint of my profile we probably have
a lot of overlap as we are interested in the same kind of topics traditionally to make matching
of people in HR for example you needed to actually if one person says I'm expert in G2E
and the other person or the other job description contains Java Enterprise there was no way of
matching it yeah in our case we matched this easily right wow so the very fascinating stuff how can
folks learn more find out more about it contact you so basically on our website cortical.io
what you find you can go there you find a white paper where you get basically a more in-depth
introduction to the whole approach you find access to a public REST API that you can play around
it's trained on Wikipedia and English Wikipedia data you can then even spin up an instance containing
the software on Amazon or Azure to play around if you have more proprietary data so that you that
you want to use and of course you can contact us if you need help to sort of get started I mean
the problem is that many of us who have been struggling using conventional tooling sometimes it
needs a little bit of help to sort of get the right angle on how to solve something yeah so we do
for example offer a keyword extraction functionality you can throw in a text and you get like the 10
most important keywords out of it and I've observed that many people try to systematically extract
keywords and then try to do some magic with that and I just told them okay that keywords you
need them if you want to show keywords at some point but you don't need them to make any computation
because you can compare to fingerprints directly so yeah it's a bit of a mind shift change of
mindset exactly yeah exactly right well thanks so much Francisco as it was great talking to you
and amazing learning a little bit about what you guys are up to thanks a lot thanks
all right everyone that's it for today's show please leave a comment on the show notes page at
twimmaleye.com slash talk slash 10 or tweet to me at at Sam Charrington or at twimmaleye to discuss
this show or just reach out let me know how you liked it thanks so much for listening and catch you
next time
