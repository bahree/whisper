1
00:00:00,000 --> 00:00:13,400
Welcome to the Twimal AI Podcast.

2
00:00:13,400 --> 00:00:15,920
I'm your host Sam Charrington.

3
00:00:15,920 --> 00:00:24,080
Hey, what's going on everyone?

4
00:00:24,080 --> 00:00:28,220
I was just checking my calendar and noticed that by this time last year, I had already

5
00:00:28,220 --> 00:00:32,060
been to about half a dozen conferences in three different cities.

6
00:00:32,060 --> 00:00:38,460
While I don't miss planes, airports or hotels at all, I really do miss the opportunities

7
00:00:38,460 --> 00:00:43,260
that conference visits created for me to really connect one-on-one with listeners and guests

8
00:00:43,260 --> 00:00:45,260
of the podcast.

9
00:00:45,260 --> 00:00:49,280
Of course, what we're all learning now is that physical separation does not need to

10
00:00:49,280 --> 00:00:51,340
mean that we're disconnected.

11
00:00:51,340 --> 00:00:55,500
So let's you and I use this as an opportunity to connect virtually.

12
00:00:55,500 --> 00:01:00,220
I'd love to hear from you, yes, you, about how things are going for you and these unique

13
00:01:00,220 --> 00:01:03,180
times we've found ourselves in.

14
00:01:03,180 --> 00:01:04,300
What are you working on?

15
00:01:04,300 --> 00:01:06,740
What new routines are you establishing?

16
00:01:06,740 --> 00:01:10,620
What new breakthroughs or realizations might you be finding in your work or personal

17
00:01:10,620 --> 00:01:11,940
life?

18
00:01:11,940 --> 00:01:19,820
Please reach out and let me know what you're up to via text or voicemail to 314-582-5935.

19
00:01:19,820 --> 00:01:25,940
via email to sam at twomolei.com or via message on our website or your favorite social media

20
00:01:25,940 --> 00:01:26,940
platform.

21
00:01:26,940 --> 00:01:31,860
I hope you're staying safe and healthy and helping others stay healthy by observing social

22
00:01:31,860 --> 00:01:33,580
distancing.

23
00:01:33,580 --> 00:01:35,820
And now on to the show.

24
00:01:35,820 --> 00:01:37,340
Alright, everyone.

25
00:01:37,340 --> 00:01:39,900
I am on the line with Karim Begear.

26
00:01:39,900 --> 00:01:44,100
Karim is co-founder and CEO at InstaDeep.

27
00:01:44,100 --> 00:01:46,580
Karim, welcome back to the Twomolei podcast.

28
00:01:46,580 --> 00:01:47,580
Hi, Sam.

29
00:01:47,580 --> 00:01:49,300
It's a pleasure to speak again.

30
00:01:49,300 --> 00:01:50,300
Absolutely.

31
00:01:50,300 --> 00:01:55,860
So if Karim's name sounds familiar, that's because we spoke, we were trying to figure

32
00:01:55,860 --> 00:01:56,860
this out.

33
00:01:56,860 --> 00:01:59,260
It was between a year and a half and a year ago.

34
00:01:59,260 --> 00:02:01,940
The show actually was published in September.

35
00:02:01,940 --> 00:02:10,780
It was number 302 and you should definitely check it out for Karim's full background.

36
00:02:10,780 --> 00:02:17,780
But Karim, why don't you give us a brief overview of what you're up to as well as an update

37
00:02:17,780 --> 00:02:19,700
from what we last spoke?

38
00:02:19,700 --> 00:02:20,700
Absolutely.

39
00:02:20,700 --> 00:02:24,740
So first, it's a pleasure to be back and continue our conversation.

40
00:02:24,740 --> 00:02:27,340
On our side, it's been pretty inventful.

41
00:02:27,340 --> 00:02:29,380
The lot has happened.

42
00:02:29,380 --> 00:02:33,780
As you know, InstaDeep is a decision-making AI startup.

43
00:02:33,780 --> 00:02:38,860
So we focus on problems related to making complex decisions.

44
00:02:38,860 --> 00:02:45,420
We also do our own innovation in AI and try to be helpful to the community.

45
00:02:45,420 --> 00:02:49,580
And we've made progress, basically, on these three areas.

46
00:02:49,580 --> 00:02:53,860
We've been able to release innovative products in decision-making AI.

47
00:02:53,860 --> 00:03:01,460
We've also been able to publish and innovate in research, publishing original pieces that

48
00:03:01,460 --> 00:03:06,180
were actually welcome, that no ribs were we got as spotlight presentation, for example,

49
00:03:06,180 --> 00:03:07,940
with Google DeepMind.

50
00:03:07,940 --> 00:03:14,420
And we've also been very active on the community side, organizing major events in Africa

51
00:03:14,420 --> 00:03:22,180
and helping basically lots of young talents find and save the opportunities in AI.

52
00:03:22,180 --> 00:03:23,180
That's right.

53
00:03:23,180 --> 00:03:29,780
And we most recently saw one another at Nurebs and had a chance to catch up briefly

54
00:03:29,780 --> 00:03:36,780
at the Black and AI dinner, where you really pick my interest around one of the company's

55
00:03:36,780 --> 00:03:42,980
new initiatives or products, which is called DeepPCB.

56
00:03:42,980 --> 00:03:45,140
Tell us about what DeepPCB is.

57
00:03:45,140 --> 00:03:46,140
Absolutely.

58
00:03:46,140 --> 00:03:50,500
So DeepPCB actually started with a conversation.

59
00:03:50,500 --> 00:03:57,820
Two years ago, I had a dinner with a good friend of mine, who is actually an expert in hardware

60
00:03:57,820 --> 00:04:03,980
design, worked on chips for well-known phones, et cetera.

61
00:04:03,980 --> 00:04:09,020
And we were speaking about what is AI doing in this particular sector.

62
00:04:09,020 --> 00:04:15,700
And he was like, not that much, like in particular, like PCBs stand for printed circuit boards.

63
00:04:15,700 --> 00:04:20,140
So basically, those are the chips that you will find with all sorts of consumer electronics

64
00:04:20,140 --> 00:04:25,060
products, iPhones, speakers, Bluetooth, et cetera.

65
00:04:25,060 --> 00:04:30,580
And you know, the situation in that market was that, you know, auto-rooters basically

66
00:04:30,580 --> 00:04:35,860
automated systems to connect the different components, like build basically the electrical

67
00:04:35,860 --> 00:04:40,740
circuitry have been going on for many years, but they were not that great.

68
00:04:40,740 --> 00:04:45,260
And we were like, hey, that sounds like an interesting problem to look at.

69
00:04:45,260 --> 00:04:51,020
We started looking to it, eventually, this good friend, Nabil Truba, who is now leading

70
00:04:51,020 --> 00:04:53,580
our hardware team, joined in steady.

71
00:04:53,580 --> 00:04:58,860
And we've worked very hard on this project, and we're very proud, you know, to have been

72
00:04:58,860 --> 00:05:00,580
able to achieve our goals.

73
00:05:00,580 --> 00:05:05,620
And in November last year, we've released it in beta form, and it is a world first.

74
00:05:05,620 --> 00:05:10,860
For the first time, we have an AI system that is end-to-end, fully deployable and scalable

75
00:05:10,860 --> 00:05:16,500
on the cloud, capable of understanding how to root chips, essentially.

76
00:05:16,500 --> 00:05:20,820
And now last time we spoke, our conversation was focused on the work your company was

77
00:05:20,820 --> 00:05:28,420
doing, applying deep reinforcement learning to logistics, is DPCB also based on deep reinforcement

78
00:05:28,420 --> 00:05:29,420
learning?

79
00:05:29,420 --> 00:05:30,420
Absolutely.

80
00:05:30,420 --> 00:05:37,140
And there is a very strong commonality and like design philosophy between our products.

81
00:05:37,140 --> 00:05:40,660
So in a sense, let me give you an example.

82
00:05:40,660 --> 00:05:46,300
We've continued to do great work in logistics, and recently last September, we've won a major

83
00:05:46,300 --> 00:05:51,180
contract, for example, with Dutchaban, the German railway company.

84
00:05:51,180 --> 00:05:57,220
And to give you an idea, this is about routing trains on a large scale, talking about 10,000

85
00:05:57,220 --> 00:06:03,700
trains a day, you know, and something on some 33,000 kilometers of railway.

86
00:06:03,700 --> 00:06:10,100
But turns out, there are commonalities between routing trains and routing chips on a board.

87
00:06:10,100 --> 00:06:14,980
And so we've realized that, you know, the projects and the type of research that InstaDep

88
00:06:14,980 --> 00:06:18,980
is doing, is actually applicable to multiple fields.

89
00:06:18,980 --> 00:06:23,260
And when it comes to in particular printed circuit boards, the opportunity was compelling.

90
00:06:23,260 --> 00:06:28,460
So we went full speed ahead and this turned out to be our first product.

91
00:06:28,460 --> 00:06:29,460
Alrighty.

92
00:06:29,460 --> 00:06:34,460
So when you initially met with your friend, your friend mentioned that they're, you

93
00:06:34,460 --> 00:06:40,860
know, while these auto routers have been in place or have been in use for many years,

94
00:06:40,860 --> 00:06:43,500
they were not without their challenges and problems.

95
00:06:43,500 --> 00:06:49,340
What were some of those challenges and problems and what was the opportunity to introduce AI?

96
00:06:49,340 --> 00:06:54,780
I think auto routers have been, you know, they've been, there's been a lot of great work done

97
00:06:54,780 --> 00:07:01,660
on auto routers, but in terms of like design philosophy, the design philosophy is all about

98
00:07:01,660 --> 00:07:04,940
essentially using heuristics to solve problems.

99
00:07:04,940 --> 00:07:09,100
And we spoke a little bit about this in our past conversation.

100
00:07:09,100 --> 00:07:15,500
So it's very similar to, let's say, what was the status of software for chess before Alpha

101
00:07:15,500 --> 00:07:20,900
Zero came out, those systems, which worked very well actually, but still are built on

102
00:07:20,900 --> 00:07:26,500
heuristics for the hardest problems, you know, heuristics have limits.

103
00:07:26,500 --> 00:07:31,660
And a system that can essentially mobilize learning and learning at scale can get better

104
00:07:31,660 --> 00:07:32,980
results.

105
00:07:32,980 --> 00:07:37,780
When it comes in particular for in the status of printed circuit boards, it is actually

106
00:07:37,780 --> 00:07:38,780
incredible.

107
00:07:38,780 --> 00:07:45,100
And we are in 2020 that actually complex circuits are still designed manually.

108
00:07:45,100 --> 00:07:50,500
And the reason why people design those manually is because auto routers essentially fail

109
00:07:50,500 --> 00:07:56,900
to deliver the goods to the degree of quality, which is expected by high quality customers.

110
00:07:56,900 --> 00:08:03,140
So as a consequence, we see a really compelling opportunity with modern AI built on the latest

111
00:08:03,140 --> 00:08:04,140
innovation.

112
00:08:04,140 --> 00:08:06,060
Some of it actually developed in house.

113
00:08:06,060 --> 00:08:09,460
We actually have patents on the work we've done for the PCB.

114
00:08:09,460 --> 00:08:15,340
There is an opportunity to like accelerate the design cycle of products, because it's

115
00:08:15,340 --> 00:08:17,420
not just about quality.

116
00:08:17,420 --> 00:08:21,820
Human engineers do absolutely amazing work and have amazing intuition.

117
00:08:21,820 --> 00:08:23,300
That's about the speed.

118
00:08:23,300 --> 00:08:28,580
A human engineer could take in certain cases multiple weeks if not months to completely

119
00:08:28,580 --> 00:08:32,060
route a complex board with modern AI.

120
00:08:32,060 --> 00:08:37,300
We do believe that instead of that, this timing can be brought to 24 hours.

121
00:08:37,300 --> 00:08:42,140
This, if done at scale, would be tremendous for the industry and it would accelerate the

122
00:08:42,140 --> 00:08:43,140
product cycle.

123
00:08:43,140 --> 00:08:48,540
We are very used in consumer electronics to have a cycle every six months or a year, there

124
00:08:48,540 --> 00:08:50,260
is a new version coming.

125
00:08:50,260 --> 00:08:55,820
We believe that AI could actually accelerate that cycle.

126
00:08:55,820 --> 00:09:00,980
And as a consequence, also make it easier to design new products and experiment and ultimately

127
00:09:00,980 --> 00:09:05,460
unleash more human creativity mobilizing AI.

128
00:09:05,460 --> 00:09:09,580
You mentioned complexity of the boards as being one of the challenges.

129
00:09:09,580 --> 00:09:12,540
What are we talking about when we talk about complexity?

130
00:09:12,540 --> 00:09:17,100
I'm assuming we're measuring that in, for example, a number of components, but having

131
00:09:17,100 --> 00:09:21,540
work with circuit boards before there are also issues like the number of layers and things

132
00:09:21,540 --> 00:09:22,540
like that.

133
00:09:22,540 --> 00:09:26,700
When you talk about a complex board, what exactly are you talking about?

134
00:09:26,700 --> 00:09:34,460
So a board really consists in basically an AI is that we need to connect and as a consequence,

135
00:09:34,460 --> 00:09:37,900
like those, they can be what needs to be connected.

136
00:09:37,900 --> 00:09:43,180
So you have pairs of components essentially that need to be connected and there could

137
00:09:43,180 --> 00:09:44,820
be thousands of those.

138
00:09:44,820 --> 00:09:48,820
And as you mentioned rightly, they could be multiple layers.

139
00:09:48,820 --> 00:09:53,940
Simple designs start with two or four layers, but you could have a lot more.

140
00:09:53,940 --> 00:09:59,820
And the more you have layers, the more components you have to connect, the harder the problem.

141
00:09:59,820 --> 00:10:01,460
It is an NP-hard problem.

142
00:10:01,460 --> 00:10:07,220
And so this is where AI can help, particularly when you're looking at the most difficult

143
00:10:07,220 --> 00:10:11,700
designs that we take human engineers' significant amount of time to solve.

144
00:10:11,700 --> 00:10:18,980
So how do you frame this problem as one that reinforcement learning can be applied to solving?

145
00:10:18,980 --> 00:10:24,260
So this is another case of needle and a haystack style problem.

146
00:10:24,260 --> 00:10:28,460
So you have an extremely large solution space to give you an idea.

147
00:10:28,460 --> 00:10:32,580
The game, of course, was 10 to the power 170, roughly.

148
00:10:32,580 --> 00:10:38,260
We are talking here at significantly more, like this can be very, very large.

149
00:10:38,260 --> 00:10:43,580
And so the question is, how can I build a system that's going to figure out what is a good

150
00:10:43,580 --> 00:10:45,460
solution to this problem?

151
00:10:45,460 --> 00:10:50,580
And of course, you have lots of rules that you need to abide by.

152
00:10:50,580 --> 00:10:59,500
We call those DRCs, like basically design rules checks that need to be absolutely verified

153
00:10:59,500 --> 00:11:04,300
for the circuit board to be valid and to be deployable in production.

154
00:11:04,300 --> 00:11:08,900
So the question is, you have this massive optimization under constraints where essentially

155
00:11:08,900 --> 00:11:11,020
you need to find a good solution.

156
00:11:11,020 --> 00:11:16,900
And we know from recent progress and from also our own experimentation that AI systems

157
00:11:16,900 --> 00:11:21,660
can be built using deeper reinforcement learning to build up intuition.

158
00:11:21,660 --> 00:11:25,700
And so it's a little bit like humans will do it, except that you have the benefits of

159
00:11:25,700 --> 00:11:29,700
doing it very consistently and importantly at a very large scale.

160
00:11:29,700 --> 00:11:36,820
We're talking about potentially like hundreds of CPUs, if not thousands working together

161
00:11:36,820 --> 00:11:43,420
with GPUs to accumulate experience and sort of build up the right knowledge base to crack

162
00:11:43,420 --> 00:11:44,420
the problem.

163
00:11:44,420 --> 00:11:49,900
And so when you talk about this knowledge base, can you go into a little bit more detail

164
00:11:49,900 --> 00:11:57,220
into how you're building the agent and the learner and how you're kind of representing

165
00:11:57,220 --> 00:11:59,740
this knowledge that's being accumulated?

166
00:11:59,740 --> 00:12:05,700
Yeah, so this is very similar to, for example, what has been done by DeepMind for the

167
00:12:05,700 --> 00:12:07,340
game of chess and Go.

168
00:12:07,340 --> 00:12:11,740
You're going to have a learner that's essentially going to play games.

169
00:12:11,740 --> 00:12:17,300
And based on the outcome of these games is going to start to learn what works and what

170
00:12:17,300 --> 00:12:18,300
doesn't.

171
00:12:18,300 --> 00:12:23,660
So you can see this problem as basically having a reward function, which is completing

172
00:12:23,660 --> 00:12:24,660
the design.

173
00:12:24,660 --> 00:12:31,700
If you've completed the design and it is DRC clean, so it satisfies to all the design rules,

174
00:12:31,700 --> 00:12:33,780
then that's a good outcome.

175
00:12:33,780 --> 00:12:39,220
And so you are effectively starting, let's say from a random point, but learning as you

176
00:12:39,220 --> 00:12:46,820
go and sort of putting more probability on the paths that are yielding a good solution.

177
00:12:46,820 --> 00:12:49,660
And of course, devil is in the detail on those systems.

178
00:12:49,660 --> 00:12:55,340
But if you do this diligently enough, you're going to get a system that's going to start

179
00:12:55,340 --> 00:13:01,620
to figure out what it should do, first on small boards and then on bigger ones, and ultimately

180
00:13:01,620 --> 00:13:03,900
get you to competitive results.

181
00:13:03,900 --> 00:13:09,660
Now, I would imagine when a human engineer is working on these kinds of problems, there

182
00:13:09,660 --> 00:13:17,460
are certainly completion of the board is a primary goal, but I'm imagining they're also

183
00:13:17,460 --> 00:13:25,460
worried about the total length of their traces, which probably corresponds to noise on the

184
00:13:25,460 --> 00:13:29,660
board or latency between components, that kind of thing.

185
00:13:29,660 --> 00:13:37,260
In other words, a lot more kind of nuance characteristics than just whether all of the

186
00:13:37,260 --> 00:13:39,300
components are connected.

187
00:13:39,300 --> 00:13:42,820
Are you able to take these kinds of things into account?

188
00:13:42,820 --> 00:13:43,820
Absolutely.

189
00:13:43,820 --> 00:13:48,980
So those actually participate into the design of the reward function.

190
00:13:48,980 --> 00:13:51,420
So this is the way to look at it.

191
00:13:51,420 --> 00:13:57,700
Of course, exactly like you said, it is desirable to have a secret length as small as possible.

192
00:13:57,700 --> 00:14:03,460
It is desirable also to have as little as possible changes from one layer to another through

193
00:14:03,460 --> 00:14:05,180
what we call VS.

194
00:14:05,180 --> 00:14:11,860
So those can actually be expressed in the design of the reward function, such that you sort

195
00:14:11,860 --> 00:14:16,020
of have everything you need and that the system has everything it needs to learn.

196
00:14:16,020 --> 00:14:23,780
But absolutely, and one of the areas where we spent a lot of time was how can we incorporate

197
00:14:23,780 --> 00:14:28,340
those into like a functional mechanism that triggers learning.

198
00:14:28,340 --> 00:14:33,300
And we're very happy to say that actually this is positive, like this is possible.

199
00:14:33,300 --> 00:14:39,820
And when we look at the first announcement we made in November last year, when we announced

200
00:14:39,820 --> 00:14:45,620
the beta release, actually many engineers came to us and they just couldn't believe that

201
00:14:45,620 --> 00:14:51,140
an AI system would go end-to-end and crack this problem.

202
00:14:51,140 --> 00:14:57,220
But this is another proof of how powerful AI can be in 2020.

203
00:14:57,220 --> 00:15:01,700
And in particular, deep reinforcement learning applied to decision-making problem is truly

204
00:15:01,700 --> 00:15:02,700
disruptive.

205
00:15:02,700 --> 00:15:08,980
So at InstaDip, we are focusing on those type of problems and we believe there is tremendous

206
00:15:08,980 --> 00:15:14,700
value to be unlocked for customers in terms of improving efficiency, accelerating design

207
00:15:14,700 --> 00:15:16,700
cycles and the like.

208
00:15:16,700 --> 00:15:23,500
If you describe the process as one of starting with simple boards and working your way up

209
00:15:23,500 --> 00:15:29,700
to more complex boards, can you elaborate that on that?

210
00:15:29,700 --> 00:15:37,300
If you've got a particular problem with a particular set of circuits that need to be

211
00:15:37,300 --> 00:15:46,380
connected to one another, is the learner that you're trying to create to route this particular

212
00:15:46,380 --> 00:15:47,380
board?

213
00:15:47,380 --> 00:15:51,100
Is it starting with the subset of components and then gradually increasing the complexity

214
00:15:51,100 --> 00:15:56,940
of what it's doing or is it are you talking, are you referring to kind of building up a

215
00:15:56,940 --> 00:16:03,140
knowledge base across multiple, maybe even theoretical, you know, board layouts that

216
00:16:03,140 --> 00:16:08,300
you have created just to train the learner and then you can take this pre-trained learner

217
00:16:08,300 --> 00:16:10,180
and apply it to new boards?

218
00:16:10,180 --> 00:16:15,780
It's not necessarily the final algorithm that we designed, but it's more like the approach

219
00:16:15,780 --> 00:16:21,700
we took, like to crank them problem like this that actually many people have tried and

220
00:16:21,700 --> 00:16:27,620
failed is in and this is a good generic principle in different foster learning.

221
00:16:27,620 --> 00:16:32,900
Start with a small problem that is almost too stupid, right?

222
00:16:32,900 --> 00:16:39,100
But make sure that it is working, make sure that what you expect to see is indeed what

223
00:16:39,100 --> 00:16:40,100
you see.

224
00:16:40,100 --> 00:16:45,540
Devil is in the detail in those systems and deep aerial systems in particular are not

225
00:16:45,540 --> 00:16:51,540
too usually tricky to train because, you know, a problem could come from multiple sources.

226
00:16:51,540 --> 00:16:57,660
It could come from this like straight out bug into your system or it could be that you

227
00:16:57,660 --> 00:17:02,780
have the wrong initialization parameters from an applied math point of view and so you're

228
00:17:02,780 --> 00:17:06,860
doing everything right, the code is right, but the system still won't learn because

229
00:17:06,860 --> 00:17:12,340
the parameters have been badly initialized, so I'm describing more philosophy.

230
00:17:12,340 --> 00:17:19,300
We really start with baby cases and build up our skills, expertise and train progressively

231
00:17:19,300 --> 00:17:21,860
the better agents, realize what work what doesn't.

232
00:17:21,860 --> 00:17:28,580
So there is a lot of like in-depth analysis and details that you need to do to be able

233
00:17:28,580 --> 00:17:34,820
to have systems that actually are ready for the real world and I think that's an interesting

234
00:17:34,820 --> 00:17:39,780
problem like, you know, when we look at the work that the Institute teams do, I think

235
00:17:39,780 --> 00:17:46,580
what is really excited about is how can we take those algorithms that have been tested

236
00:17:46,580 --> 00:17:52,860
mostly on games and very well-defined environments if you want and sort of translate them into

237
00:17:52,860 --> 00:17:57,940
the real world, you know, whether it's routine boards or trains or anything else.

238
00:17:57,940 --> 00:18:02,260
And you know, there are lots of challenges that come with that, but also at the same time,

239
00:18:02,260 --> 00:18:07,860
if you manage to overcome the challenges, it is truly an exciting time and you can see

240
00:18:07,860 --> 00:18:11,060
actually customers come back and give you great feedback.

241
00:18:11,060 --> 00:18:15,260
Customers say, please keep me in the loop for your next release and we've been constantly

242
00:18:15,260 --> 00:18:19,620
improving our product and answering recently releases, for example, supporting Altram,

243
00:18:19,620 --> 00:18:22,700
which is a key standard and so on and so forth.

244
00:18:22,700 --> 00:18:26,940
So I think there is a true excitement in doing things in the real world, even though of course

245
00:18:26,940 --> 00:18:27,940
it's much harder.

246
00:18:27,940 --> 00:18:36,220
So can you maybe compare and contrast the RL applied to games in this particular scenario?

247
00:18:36,220 --> 00:18:42,380
You know, I'm just thinking through some of the differences in the game scenario, you've

248
00:18:42,380 --> 00:18:50,500
often got, you know, other agents or things in the game, in the environment kind of respond,

249
00:18:50,500 --> 00:18:56,300
you know, randomly or probabilistically to the things you do or at least via some,

250
00:18:56,300 --> 00:18:58,700
you know, some complex function.

251
00:18:58,700 --> 00:19:05,740
In this world, you've got your set of components and unless you're doing kind of deep physics

252
00:19:05,740 --> 00:19:10,540
based, you know, simulations of the interactions between the components, you maybe you're not

253
00:19:10,540 --> 00:19:16,700
getting into kind of random responses to things like follow down that thread for me.

254
00:19:16,700 --> 00:19:22,340
So one of the key differences is when it comes to gaming, the reward system is very clear.

255
00:19:22,340 --> 00:19:26,580
You know, there is a score to maximize, there is an opponent to defeat.

256
00:19:26,580 --> 00:19:32,780
So there is full visibility in a sense on what the reward is, which is quite important.

257
00:19:32,780 --> 00:19:34,980
So you're already saving a lot of time.

258
00:19:34,980 --> 00:19:36,940
You know what's the objective.

259
00:19:36,940 --> 00:19:41,380
When it comes to the real world, if I tell you, for example, like, okay, I have this,

260
00:19:41,380 --> 00:19:42,900
you know, and this is what we were talking about.

261
00:19:42,900 --> 00:19:48,340
I have this complex board with, you know, you know, eight layers and a thousand pairs

262
00:19:48,340 --> 00:19:49,340
to connect.

263
00:19:49,340 --> 00:19:53,540
Well, what is the reward function is actually a very good question.

264
00:19:53,540 --> 00:19:57,620
You could probably work for years on what is the best reward function you could come up

265
00:19:57,620 --> 00:19:58,620
with.

266
00:19:58,620 --> 00:20:01,780
So that is one first real challenge.

267
00:20:01,780 --> 00:20:08,060
The second challenge is when you design the environment, making sure you incorporate all

268
00:20:08,060 --> 00:20:16,140
the elements that are important in actually design, like coding and modeling the environment.

269
00:20:16,140 --> 00:20:22,540
If I take the example in logistics that we did and the work we do with railway companies,

270
00:20:22,540 --> 00:20:26,500
that is actually not a trivial thing to do in games.

271
00:20:26,500 --> 00:20:32,100
The environment by construction is already given to you and is very clear, not just the reward,

272
00:20:32,100 --> 00:20:33,740
but the environment itself.

273
00:20:33,740 --> 00:20:39,660
If you're talking about, for example, a complex train network with dozens of thousands

274
00:20:39,660 --> 00:20:46,900
of trains operating every day, you know, there could be problems on one railway.

275
00:20:46,900 --> 00:20:48,620
What's the consequence of that problem?

276
00:20:48,620 --> 00:20:52,580
Just modeling the environment is a challenge in itself.

277
00:20:52,580 --> 00:20:55,820
Once in a good scenario, you've modeled the environment.

278
00:20:55,820 --> 00:20:58,860
The next challenge is speed in games.

279
00:20:58,860 --> 00:21:04,180
By construction, most games are quite fast because there are, for example, designed for

280
00:21:04,180 --> 00:21:08,660
massively online multiplayer games, for example, things of that nature.

281
00:21:08,660 --> 00:21:15,140
So the latencies are, in the order of milliseconds, sometimes, building a real-world environment

282
00:21:15,140 --> 00:21:20,780
that represents properly the problem that you're looking at, and at the same time, ensuring

283
00:21:20,780 --> 00:21:26,260
that it's quick enough so that you deploy deeper out is actually a non-trivial thing.

284
00:21:26,260 --> 00:21:32,220
So as you can see, every step of, you know, this challenge, which is kind of already pre-built

285
00:21:32,220 --> 00:21:37,540
in for games, becomes very tricky in the real world, but also very interesting.

286
00:21:37,540 --> 00:21:43,500
This is also why it's not a surprise that all the deeper out breakthroughs tend to happen

287
00:21:43,500 --> 00:21:48,060
on games, because that is sort of the ideal framework to get results.

288
00:21:48,060 --> 00:21:54,540
And so going back to my earlier question, is what you've done here that you've trained

289
00:21:54,540 --> 00:22:01,620
a model using reinforcement learning that you can then apply to kind of an arbitrary

290
00:22:01,620 --> 00:22:07,060
new board that you're presented with, or is there an element of training that has to

291
00:22:07,060 --> 00:22:13,260
happen when you see a new board, or fine-tuning, or something like that?

292
00:22:13,260 --> 00:22:15,020
It's a bit of both.

293
00:22:15,020 --> 00:22:22,660
So the right analogy is what would qualify a human expert, too, and he comes with a set

294
00:22:22,660 --> 00:22:27,780
of knowledge, a knowledge base, an intuition about how to tackle those problems, but of course

295
00:22:27,780 --> 00:22:32,900
he's going to spend time sort of fine-tuning his approach to the problem at hand.

296
00:22:32,900 --> 00:22:35,780
So our design philosophy is pretty much the same.

297
00:22:35,780 --> 00:22:41,340
There is pre-built-in experience and knowledge that comes when we tackle a new board, but

298
00:22:41,340 --> 00:22:45,500
there is also an amount of fine-tuning, basically essentially.

299
00:22:45,500 --> 00:22:50,540
This system will learn an experiment on every new board and get something out of it.

300
00:22:50,540 --> 00:22:55,220
And when you think about it and you compound those effects, this is how you build a learning

301
00:22:55,220 --> 00:23:00,980
system that can progressively tackle harder and harder problems, and together with compute,

302
00:23:00,980 --> 00:23:07,980
with more customer-served, sort of potentially redefine the standards in the industry.

303
00:23:07,980 --> 00:23:09,740
This is our goal with DPCB.

304
00:23:09,740 --> 00:23:16,980
Today DPCB is in beta format, so it's sort of still learning every day and learning quickly,

305
00:23:16,980 --> 00:23:18,420
but still learning a lot.

306
00:23:18,420 --> 00:23:24,020
We would like to bring it to a point where the tool is so useful that it is widely adopted

307
00:23:24,020 --> 00:23:29,340
by in the industry and helps the industry achieve its goals faster and more efficiently.

308
00:23:29,340 --> 00:23:35,140
If we manage to crack boards at scale in less than 24 hours, this would change the life

309
00:23:35,140 --> 00:23:41,340
of many companies operating in consumer electronics and for the better, because they could be able

310
00:23:41,340 --> 00:23:46,780
to experiment with different designs faster, maybe bring products to market that would

311
00:23:46,780 --> 00:23:54,260
have been impossible otherwise, because the cost of having a design team work for it for

312
00:23:54,260 --> 00:23:57,300
two or three months is just an affordable.

313
00:23:57,300 --> 00:24:01,860
How do you characterize where you are relative to that goal?

314
00:24:01,860 --> 00:24:07,180
How complex are you able to get now and how long does it take to do a board?

315
00:24:07,180 --> 00:24:11,140
I think it's pretty remarkable what we have achieved already, especially that we are

316
00:24:11,140 --> 00:24:16,620
a small startup and do not have access to large compute.

317
00:24:16,620 --> 00:24:21,740
The key thing for us now, if you want to take DPCB to its full potential, is really

318
00:24:21,740 --> 00:24:27,460
unleash tremendous amount of compute and train on much larger boards, so our goal for this

319
00:24:27,460 --> 00:24:34,980
year is really move from free beta, where we are effectively trying to help customers all

320
00:24:34,980 --> 00:24:40,300
over the world and getting feedback in the process, getting them to a point where we can

321
00:24:40,300 --> 00:24:46,740
compete with professional product offerings, and ultimately, if we do everything well,

322
00:24:46,740 --> 00:24:50,380
we design the state of the art in the industry.

323
00:24:50,380 --> 00:24:55,660
So I would say we are well on our way, probably more than 50 percent done, but still a lot

324
00:24:55,660 --> 00:24:56,660
of work.

325
00:24:56,660 --> 00:25:01,220
You are not going to answer my question.

326
00:25:01,220 --> 00:25:03,620
We are in beta, we didn't tell you that.

327
00:25:03,620 --> 00:25:14,260
I am trying to get a sense for how far along this is relative to both how you measure

328
00:25:14,260 --> 00:25:15,260
it.

329
00:25:15,260 --> 00:25:19,260
You talked about the number of components and layers and all that stuff, but also how

330
00:25:19,260 --> 00:25:25,220
far along you are relative to that for solving real world problems, is this something that

331
00:25:25,220 --> 00:25:31,700
is currently useful to someone that wants to route a PCB or not and how do you know

332
00:25:31,700 --> 00:25:37,740
or how would they know if their problem is practical for what you've done so far?

333
00:25:37,740 --> 00:25:43,540
Yes, so the great news is we are actually already solving real PCB boards for real customers

334
00:25:43,540 --> 00:25:45,500
and we're very proud of that.

335
00:25:45,500 --> 00:25:52,740
Those boards are still small, we're currently limiting in beta to 150 pairs and two layers

336
00:25:52,740 --> 00:25:54,860
and we're going to progressively expand that.

337
00:25:54,860 --> 00:26:00,460
So this is where we are at the moment, but the good news is that actually we've already

338
00:26:00,460 --> 00:26:06,020
received very good feedback from customers from literally everywhere at the US Asia and

339
00:26:06,020 --> 00:26:08,900
that the system works, so we're pretty excited about it.

340
00:26:08,900 --> 00:26:18,940
We made a comment that one of the limitations is access to compute or at least you gave

341
00:26:18,940 --> 00:26:25,900
the impression that this is constantly running and constantly improving, talk a little bit

342
00:26:25,900 --> 00:26:31,300
about the relationship with compute and the compute requirement and how you're addressing

343
00:26:31,300 --> 00:26:32,300
that.

344
00:26:32,300 --> 00:26:38,020
Absolutely, so if you look at how the parallel systems work, there is always this concept

345
00:26:38,020 --> 00:26:45,460
of accumulating experience through multiple simulations, gathering this experience to improve

346
00:26:45,460 --> 00:26:49,300
your model through gradient descent and iterating again.

347
00:26:49,300 --> 00:26:55,620
And if you look at the kind of amount, the kinds of amount of compute that you need to really

348
00:26:55,620 --> 00:26:59,580
have, for example, a breakthrough in DPRL, it's quite significant.

349
00:26:59,580 --> 00:27:04,900
If you look at StarCraft, for example, like DeepMind actually did spend millions of

350
00:27:04,900 --> 00:27:10,620
dollars to crack that problem, today, instead, it cannot spend millions of dollars to define

351
00:27:10,620 --> 00:27:11,620
the StarCraft.

352
00:27:11,620 --> 00:27:17,180
So what we're doing actually, we're raising funds and one of the reasons we're raising

353
00:27:17,180 --> 00:27:23,300
a series B, essentially, one of the reasons actually to have enough compute capabilities

354
00:27:23,300 --> 00:27:27,660
to push our systems to redefine the state of the art.

355
00:27:27,660 --> 00:27:32,900
So there is a real opportunity out there, but a compute is a necessary equation when it

356
00:27:32,900 --> 00:27:37,580
comes to DPRL, of course, you can focus on sample efficiency and the like, but you will

357
00:27:37,580 --> 00:27:42,500
not be able to crack those problems with, let's say, a limited amount of GPUs and CPUs

358
00:27:42,500 --> 00:27:43,500
available.

359
00:27:43,500 --> 00:27:48,900
You will need to have essentially a cloud partner to be able to progress this to the next

360
00:27:48,900 --> 00:27:49,900
level.

361
00:27:49,900 --> 00:27:54,260
And we actually don't more than that, we actually design DPCB to be fully on the cloud

362
00:27:54,260 --> 00:27:55,260
from day one.

363
00:27:55,260 --> 00:28:01,180
So every time a customer actually uploads a board, it is solved in real time on the cloud.

364
00:28:01,180 --> 00:28:08,660
And so scalability and scalability of learning is essential if you want to have systems that

365
00:28:08,660 --> 00:28:12,700
build up new state of the art per like results.

366
00:28:12,700 --> 00:28:15,340
And we're pretty excited about that.

367
00:28:15,340 --> 00:28:20,500
And we think this is actually achievable in the near term for instead, meaning something

368
00:28:20,500 --> 00:28:22,100
like a year or less.

369
00:28:22,100 --> 00:28:28,500
We talked a little bit about this kind of notion of transfer learning to use that term

370
00:28:28,500 --> 00:28:36,820
very broadly, that you're training a model and agent and you can, when you're faced with

371
00:28:36,820 --> 00:28:41,580
a new board, you can leverage the experience that you've, you know, you slash this agent

372
00:28:41,580 --> 00:28:46,380
has experienced this models experience with previous boards.

373
00:28:46,380 --> 00:28:51,300
We've also talked about, you know, in the real world, like different designs have different

374
00:28:51,300 --> 00:28:57,700
requirements, maybe, you know, one board has specific requirements around noise or, you

375
00:28:57,700 --> 00:29:02,660
know, the number of layers relative to others, you know, maybe, I guess what I'm, I'm wondering

376
00:29:02,660 --> 00:29:10,100
is if, you know, as you evolve your reward function when you're faced with new scenarios,

377
00:29:10,100 --> 00:29:15,620
does that interfere with transferability or, you know, can you transfer from one reward

378
00:29:15,620 --> 00:29:18,020
function to another?

379
00:29:18,020 --> 00:29:22,980
It really depends of like how far other reward functions are from respective to each other.

380
00:29:22,980 --> 00:29:26,300
But in general, transfer learning is pretty robust.

381
00:29:26,300 --> 00:29:31,140
So, you know, there is a remarkable ability to transfer knowledge from one problem to

382
00:29:31,140 --> 00:29:32,140
another.

383
00:29:32,140 --> 00:29:37,060
And this is something we see across the board, across the board in AI and it's the same

384
00:29:37,060 --> 00:29:38,860
in printed circuit boards.

385
00:29:38,860 --> 00:29:45,340
So if your reward function is not very dissimilar, you will be able to transfer knowledge.

386
00:29:45,340 --> 00:29:51,660
If your board is relatively similar to previously seen and solved boards, transfer learning

387
00:29:51,660 --> 00:29:53,180
will apply as well.

388
00:29:53,180 --> 00:29:59,180
And this is actually a key point, Sam, because this is what makes those systems so interesting.

389
00:29:59,180 --> 00:30:04,460
The fact that they learn, but then when faced with a very complex problem, you know, they

390
00:30:04,460 --> 00:30:10,220
won't have to necessarily burn all that compute to redo everything again.

391
00:30:10,220 --> 00:30:16,660
If you look at how optimization works in many cases today, there is no learning, no

392
00:30:16,660 --> 00:30:18,580
memory of what happened.

393
00:30:18,580 --> 00:30:23,220
And so, you know, if you have, for example, people, you know, doing optimization on boards

394
00:30:23,220 --> 00:30:28,300
or on root problem, or no matter which routing problems these are, well, essentially, you're

395
00:30:28,300 --> 00:30:31,540
burning compute overnight to solve something.

396
00:30:31,540 --> 00:30:36,780
And maybe you kind of come in the next night and do the same thing all over again.

397
00:30:36,780 --> 00:30:39,780
So the transfer learning part is actually critical.

398
00:30:39,780 --> 00:30:45,540
And this is what allows you to keep progressing, you know, as you deploy compute, sort of

399
00:30:45,540 --> 00:30:51,860
this compute is actually more wisely used, if you get two results that can improve what

400
00:30:51,860 --> 00:30:53,380
you're going to do tomorrow.

401
00:30:53,380 --> 00:30:57,900
You mentioned that you had a spotlight presentation at NURBS.

402
00:30:57,900 --> 00:31:02,260
Was that related to this work or is that something separate?

403
00:31:02,260 --> 00:31:09,980
So yeah, we were very surprised this year, actually, to have a spotlight paper at NURBS.

404
00:31:09,980 --> 00:31:15,940
And this was work done with DeepMind, with Nando Freitas and his team.

405
00:31:15,940 --> 00:31:21,940
And interestingly, we looked at, you know, deeper questions, but around compositionality.

406
00:31:21,940 --> 00:31:27,980
How can I, in a bit in the same spirit, but how can I look at certain problems?

407
00:31:27,980 --> 00:31:35,300
And while I saw simple tasks, use those as sort of like, you know, basic tasks to compose,

408
00:31:35,300 --> 00:31:37,340
more complex tasks and so on.

409
00:31:37,340 --> 00:31:43,660
So I think that we're very proud, despite our humble origins, to be able to partner with

410
00:31:43,660 --> 00:31:47,300
the world's best in AI when it comes to research and innovation.

411
00:31:47,300 --> 00:31:52,900
And one of the things, which is unusual about the company, is our ability to, on one side,

412
00:31:52,900 --> 00:31:59,140
innovate in pure research and in particular, deeper, but then productize and experiment

413
00:31:59,140 --> 00:32:02,260
with this innovation in the real world.

414
00:32:02,260 --> 00:32:08,860
And I think that's kind of something pretty exciting, because you get exposed to things

415
00:32:08,860 --> 00:32:13,060
that are both intellectually challenging, but also you have a chance to crack real world

416
00:32:13,060 --> 00:32:14,060
problems.

417
00:32:14,060 --> 00:32:18,820
And so this, you know, it was a big surprise for us, you know, first collaboration with

418
00:32:18,820 --> 00:32:25,460
DeepMind, for us in itself was a milestone, to get that distinction, which roughly is

419
00:32:25,460 --> 00:32:31,940
equivalent to being ranked in the top 2% of all worldwide papers submitted at NURBS.

420
00:32:31,940 --> 00:32:35,660
So that was one of the milestones of our, of our year.

421
00:32:35,660 --> 00:32:40,780
So can you share a little bit more detail about the, the paper and the results?

422
00:32:40,780 --> 00:32:47,220
Yeah, so the paper is called Alphine PI, you can find it on our website, and study.com.

423
00:32:47,220 --> 00:32:51,540
And what we did is we looked at, in this particular case, toy problems.

424
00:32:51,540 --> 00:32:56,900
If you remember, we were speaking about starting with relatively simple things and building

425
00:32:56,900 --> 00:33:01,060
up from there, we looked at, for example, the Hanoi Towers problem.

426
00:33:01,060 --> 00:33:05,380
So Hanoi Towers is classically, you have those disks, you need to move them from one port

427
00:33:05,380 --> 00:33:09,660
to another, and you need to respect a certain order in which you do this.

428
00:33:09,660 --> 00:33:14,460
You know, this is very difficult to solve the Hanoi Towers problem, let's say, a classic

429
00:33:14,460 --> 00:33:17,900
D-barrel album, like the DQN of PPO.

430
00:33:17,900 --> 00:33:25,900
So Alphine PI was able to crack that problem using recursion and also using planning.

431
00:33:25,900 --> 00:33:32,580
So if you look at, for example, the insights from Alphago and Alphazero planning is key.

432
00:33:32,580 --> 00:33:38,860
So the ability to look ahead and sort of build the tree of possibilities and then decide

433
00:33:38,860 --> 00:33:43,860
I'm going to act according to, you know, this path, because I really thought about it

434
00:33:43,860 --> 00:33:50,740
or another way to, to say it is like system one and system two in Daniel Kahneman's classification.

435
00:33:50,740 --> 00:33:53,580
Well, we've actually applied this.

436
00:33:53,580 --> 00:34:00,540
But rather than have just a simple planning algo, like a tree, that is, like a Monte Carlo

437
00:34:00,540 --> 00:34:05,340
tree search that is guiding the neural net, we've done multiple layers of trees.

438
00:34:05,340 --> 00:34:13,380
So as we have compositionality across multiple levels, we actually are calling trees and

439
00:34:13,380 --> 00:34:18,660
doing planning and search across multiple levels, which had never been done before.

440
00:34:18,660 --> 00:34:22,860
So if you're interested, feel free to have a look at the website, the paper is there,

441
00:34:22,860 --> 00:34:27,820
and also the code is available, we try to be very open even though we're a small startup.

442
00:34:27,820 --> 00:34:32,260
So everything is out there available on GitHub and accessible through our website.

443
00:34:32,260 --> 00:34:36,180
Well, Karim, thanks so much for taking some time to catch up.

444
00:34:36,180 --> 00:34:41,460
It's been great chatting with you as always and super excited about what you're up to.

445
00:34:41,460 --> 00:34:43,820
Thanks a lot Sam and talk to you soon.

446
00:34:43,820 --> 00:34:45,580
All right, thank you.

447
00:34:45,580 --> 00:34:51,460
All right everyone, that's our show for today.

448
00:34:51,460 --> 00:34:57,260
For more information on today's show, visit twomolai.com slash shows.

449
00:34:57,260 --> 00:35:24,020
As always, thanks so much for listening and catch you next time.

