Hello and welcome to another episode of Twymilthalk, the podcast where I interview
interesting people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
I'd really like to take a moment to thank all of you who listen to this show.
I am constantly humbled by your interest and offers of support.
Thanks to you, the show keeps reaching more and more people with last week's show being
our fastest ever to 5,000 listens in just over 24 hours.
So please, please, please keep reaching out via the show notes page, Twitter, Facebook,
YouTube, etc.
We really, really love to hear from you.
Inspired by listener Beth Ann and YC on Twitter, we want to try a little contest for you.
We've got some fresh new stickers on hand and we'd like to get them into your hands.
I've got to say they really turned out great.
So here's what you need to do to get one.
Let us know your favorite quote from today's podcast via Facebook, Twitter, YouTube or
SoundCloud comment or comment on the show notes page by midnight Sunday Pacific time and
we'll send you one.
Before we jump into our show, I wanted to remind you to check out the future of data
summit that I'm organizing.
It'll take place in Las Vegas and May at the Interop ITX conference and I'm excited to
have already heard from a bunch of Twinmal listeners making arrangements to attend.
We'll be covering some really exciting topics, including of course machine learning and AI,
but also IoT and edge computing, augmented and virtual reality, blockchain, algorithmic
IT operations, data security and more.
It's going to be a great event.
You can learn more about the summit at twinmalai.com slash future of data.
And now about today's show.
This week our guest is Stefano Irman, Assistant Professor of Computer Science at Stanford University
and fellow at Stanford's Woods Institute for the Environment.
Stefano and I met at the rework deep learning summit earlier this year where he gave a presentation
on machine learning for sustainability.
We spoke about a range of topics, including incorporating domain knowledge into your
machine learning models, dimensionality reduction and his interest in applying machine learning
and AI to addressing sustainability issues like poverty, food security and the environment.
And now on to the show.
Hello everyone, welcome to another episode of this week in machine learning and AI.
I am here with Stefano Irman, who is an Assistant Professor at Stanford University.
Stefano and I connected after his presentation at the recent rework deep learning summit
where he spoke on machine learning for sustainability.
Stefano wanted to say hi to the audience.
Hi everybody, thanks for the invitation.
It's great to be here with you today.
I'm really excited to have you on the show.
I enjoyed your presentation and I spent a little bit of time looking into some of the
work that your group is doing at Stanford and I found a really interesting mix of fundamental
research into machine learning techniques as well as a strong interest in a particular
application area, notably sustainability.
So why don't you get us started by talking about how those two kind of meld for you and
how you arrived at your area of focus?
Sure, yeah.
So a lot of the research that we do in my group is really at the foundation or artificial
intelligence machine learning.
So we do a lot of work on probabilistic modeling of data, developing scalable and accurate
inference techniques for high dimensional probabilistic models of data, knowledge representation
and decision making and uncertainty techniques.
So we're really interested in the whole pipeline of going from data to extracting knowledge
and extracting insights from the data to using these insights to improve the way we make
decisions.
And a lot of the work is really foundational, so we proved theorems, developed algorithms,
developed new models.
But we also like to think about real world problems and I'm particularly excited about new
applications areas for AI machine learning.
And as you mentioned, one that I'm really excited about is this new area of computational
sustainability, where we're trying to apply computer science techniques and generally
use ideas from computational thinking to help solve and address some of the big sustainability
issues of our times.
And these include things like poverty or environmental issues or energy, sustainable energy problems,
network resource management, a problem scene ecology and so forth.
So I'm very, very interested in finding ways to use this new amazing technologies that we've
been developing in the past 10 or 20 years in AI machine learning and use them to address
problems that are extremely important, I think, but perhaps they don't, they are not studied
as much as they should in the field of machine learning and AI.
I think you're right that they're not studied as much as they should be, how did you arrive
at that research focus as opposed to one of the more popular or buzzy buzz worthy areas
like robotics and or even here in the valley, getting people to click on ads.
You know, I have a red thread.
So I also started with my PhD actually, so I did my PhD in computer science at Cornell
University and arrived when I joined.
My advisor had just received a big grant from NSF, an expedition in computing to start
a whole new research area in computer science.
And the idea was really to try to see whether we can take all these amazing techniques and
ideas that we have and use them to address problems in the sort of in the public space.
The idea being that information technology and computers and AI have really revolutionized
the way people live and a lot of way people do businesses and they really changed the
world.
But if you think on the other hand, at the way we try to solve some of the big societal
problems that we have in the public space dealing with the environment and how we manage
our network resources or how we try to sort of close the gap between developing and
developed countries, we're still not taking advantage of all of these ideas just because
there's not so much economic incentive to sort of apply, develop the necessary models,
develop the necessary algorithms, figure out how to actually use them to solve these
problems.
And so, you know, that was kind of how I got started and I've been working on those
kind of problems basically ever since, so for almost 10 years now.
Very nice.
Now, in your presentation, you shared some statistics around the impact of the problems
that you're going after with regard to poverty and food security and the environment.
You know, in many ways, I think it's kind of obvious that these are important issues,
but like you say, in a lot of ways, they're understudied because of the lack of a driving
economic incentive.
You know, can you share some of those stats or at least the ones that inspire you to continue
pursuing this work?
Right.
Like I was actually looking at the 2030 agenda for sustainable development that was recently
adopted by the United Nations and if you look at the kind of problems that were sort of
identified as being some of the big societal challenges that sort of all the governments
in the world should be working together to address.
We see things like ending extreme poverty, there are still hundreds of millions of people
around the world living extreme poverty or eliminating hunger.
It turns out that again, there are lots of people, especially in places like Africa and
Asia and so forth that don't have enough to be.
Or you know, protecting biodiversity, there's this huge biodiversity loss and we need to
find ways to manage our resources in a more sustainable way so that we can sort of guarantee
the welfare, not just about current generation, but also our children and the generations
that will come after them.
So these are all big and problem problems and a lot of them, one of the challenges right
there.
So they figure out this partially because they involve this sort of global skill phenomena
thinking about a climate change or how to manage these very large ecosystems or the fact
that we need to deal with multiple agents that are sort of have different objective functions
than they're interacted with each other.
But there's clearly like a computational component to these problems, but so far it has
not been studied so much.
And so one of the focus of my research is really to try to find ways to apply these techniques
from AI and computer science to help address some of these issues.
And on that note, do you come at things from the perspective of, as you said, apply
applying techniques that are developed in AI and machine learning research to this application
area or the other way around, meaning identifying specific problems in the research area and
using those to drive research around specific techniques.
That's a big question.
I actually like to think of it as a two-way street, so yes and yes.
On the one hand, sometimes we start with a problem and we realize that maybe we don't
have the tools right now, or we don't have the right models to address the problem.
And that often happens because this problem haven't been studied so much with computer science.
So there's always some aspect of this problem that has not been studied before or some
variation that sort of gives rise to a new problem that will require new models, new
model algorithms, and we can sort of publish our papers in sort of top AI machine learning
conferences.
And on the other hand, we also like to do a lot of foundational research, and so sometimes
we know about all the capabilities that we have right now, the cutting edge of AI machine
learning.
So just by talking with my colleagues and Stanford, sometimes I hear about, no, I asked
them, what are the problems that they are working on?
And we tried to find ways to use this new ideas and apply them to help them solve this
very important problems.
So one reason why this, it's interesting that you take this two-way street approaches
because I spend quite a bit of time following companies that are trying to democratize machine
learning in AI, and often what they're doing is trying to create generalized machine learning
in AI platforms, and in fact, you know, all of the large cloud companies like Google
Microsoft and Amazon are trying to do that same thing.
But then we have a group like yours that has a fundamental focus on a specific application
area that drives deep, deep, unique research into the field.
I'm wondering what's your take on that?
Do you feel like what's the role of what's your take on the role of kind of generalized
machine learning in AI techniques and versus very application-specific techniques?
I think there's definitely a lot of value in developing tools that can be easily used
by people that are not necessarily the domain experts, and I will definitely help in a lot
of context, including the sustainability space, but I do believe that sometimes you really
need to develop some actual research to be done.
There are some problems that require actually new techniques, and so there's definitely
a lot of space for developing new ideas, new models that maybe are motivated by this
specific application, but then they can potentially apply it down the line to other problems
that are completely different of names.
That's kind of the beauty of computer science is this idea of abstraction to develop general
models, these general algorithms that are maybe inspired by one specific problem, but
then a few years later, somebody else comes up with a completely different new application
that you would never have thought about, and they apply exactly the same algorithm to
this new problem.
I think that's really the power of computer science, this layers of abstraction.
All right, so let's maybe try to get more concrete and talk through some of the specific
research that your group is doing and how it's uniquely applied in this application area.
One of the papers that I came across on your group's website, which I'll link to in the
show notes, is one on deep Gaussian process for crop yield prediction based on remote
sensing data.
Crop yield prediction will talk about the importance of that problem and the data source
and then walk us through kind of what the research is hoping to achieve.
Yeah, so that particular paper, we were looking at problems in the food security space.
It turns out that there are, as I mentioned earlier, there are lots of people around the
world that don't have enough to eat, or suffering from various kind of food crisis, due to
weather, climate change, like erosion, or rising waters, all sorts of problems are kind
of causing this food security issues.
And we know that the situation is going to get worse with time, but the world population
is growing and we're going to have to find a way to, there's an estimated, I think, two
billion more people that we're going to have in 2050 and we're going to have to find
ways to feed this growing population.
So the kind of problem that we looked at was that of trying to see whether we can use
inexpensive, cheap, unconventional data sources, like satellite data to keep track and predict
various food security measures and monitor agricultural outcomes.
So in particular, we try to develop these machine learning techniques to predict just
by looking at the images of the Earth from space, to predict how the kind of level of agricultural
productivity of a geographical area just by looking at it from from space, essentially
we developed some machine learning models that can track the growth of plants from space
and use that information to predict ahead of time how much in that particular application
we're looking at soybeans, but since then we've extended it to corn and other crops.
We're able to actually predict very accurately from space using cheap, unconventional data
sources, the level of productivity of different geographical regions.
And this is important because given this kind of data, we can start collecting this kind
of data, especially in developing countries, it's very expensive.
We don't have much data on this kind of measures in places like Africa.
And so if we had a way to measure these crop yields or other food security measures,
like something or things like that, that could be extremely useful to improve the kind
of policies that both governments and NGO use things like predicting whether it's going
to be a farm item, a certain region, or a certain government should stock or increase
the levels of food reserves in case there's an emergency and things like that.
And so in this particular case, remote sensing data, the satellite imagery is where did that
come from?
Is this Google Maps type data, for example, or Google Earth type data, or a government
or proprietary data source?
It's actually publicly available data.
We were using data from NASA, the MOLIS satellites.
So this is publicly available data.
It takes an image of the basically the entire world every eight days.
And this is my spectral data, so it's not just sort of like visible RGB bands, but there's
also infrared and other bands that contain additional information that we can use in our
machine learning system to make our predictions.
OK.
So you started with the goal of taking this multimodal image-sentient image data and trying
to predict crop yields based on it.
And along the way, developed some new techniques around one that was called out in the paper
is dimensionality reduction.
Can we spend some time talking about that particular technique and its novelty and even the
step before that, for folks that aren't familiar with it, what is dimensionality reduction
and why is it important in this problem space?
Yeah.
So the challenge for this kind of application is that we didn't have a whole lot of training
data available.
Like these days, if you have a lot of training data, then you can take a sufficiently high-capacity
model, like a big large amount of networks, and there is a high chance that with a sufficiently
large amount of training data, you will be able to do a pretty good job of predicting these
outcomes that we care about.
But in a lot of these sustainability applications, like in this case, for predicting crop yields
and also, we did some other work on predicting other kind of socio-economic measures of interest
like poverty, it turns out that the amount of training data available is extremely limited,
it's very, very scarce.
And so you cannot just train machine learning systems, state-of-the-art machine learning
system end-to-end from inputs to outputs.
And so what we did is we've been developing several techniques to try to get away with
less training data.
One in particular that we use the one, the particular dimension, which, and other several
ways to do it, sometimes, and essentially, in all the cases, we either do transfer learnings
or we try to use some proxy for the measures that we care about to get some signal, and
maybe pre-trained the system and learn something useful about the structure of this kind
of multispectral images that we use as input, or we use some kind of prior knowledge, maybe
something about something that we know about the outcomes that we're trying to predict,
the relationships between input and outputs, and we can use it, we can sort of put that
into the system to make sure that we can basically get very good results even when we don't
have a whole lot of training data.
In this particular context, the dimensionality reduction technique that we used was an idea
that we had to essentially reduce the dimensionality of the inputs.
An image is very high-dimensional, you have a lot of pixels, and they can take many different
values.
So it's a very high-ded sort of input data, lies in a very high-dimensional space, although
there is a lot of structure.
And so, in some sense, the information that we care about is actually can be extracted
from without really looking at the exact position of all the pixels in the image.
So what we came up with was an idea to reduce the dimensionality of the inputs while preserving
most of the information comp.
And the idea was fairly simple.
The idea was that if you care about predicting crop fields, it doesn't really matter where
the fields are in the image, so the soybean fields are in the image, their actual location
doesn't matter.
Do you say the soybean fields?
Let's say the soybean fields.
Soybean fields, okay?
The actual position in the image, whether they appear in the top right corner or the
left bottom corner doesn't matter.
So you can use this prior knowledge to essentially reduce the dimensionality of the inputs while
preserving the information content, and that makes learning the problem easier.
So when I think about the image problem, in what way is that a high dimensionality problem
and how do those dimensions correspond to the actual problem space?
Well, you have basically one dimension for a pixel in the image, so if you have a thousand
by a thousand pixels, there you have a million dimensions for the inputs, and that's essentially
what's causing the problem.
It's very high dimensional, and so it's known that there's a lot of machine learning algorithms
and a lot of algorithms in computer science.
They suffer from this curse of dimensionality problem that as the dimensionality grows, the
volume of objects grows exponentially fast.
So kind of the coverage that you have of this very high dimensional space by getting samples
that you have from your training data is extremely, extremely sparse, which is so high
dimensional that you have like so few points, but makes it very different to sort of infer
something about what is going on in this very high dimensional space.
So you have to use some kind of prior knowledge to realize that actually, well, there are certain
things that don't really matter, that we're looking for things that maybe are translational
invariant, or maybe we know that some bands don't matter, or we have some kind of inductive
bias that we can use to input that knowledge into the system so that we can still do something
useful, even though the inputs are so high dimension.
So in this case, dimensionality reduction, another way of thinking about that is just
getting your machine learning algorithm to focus on the important parts of the thing that
you're trying to train it on as opposed to the entire space of the images.
And so you mentioned another thing you mentioned in terms of techniques for accomplishing this
is transfer learning, which is applying pre-existing models as kind of starter models to training
application specific models.
Is that the way you would describe that?
So that is that you typically have a task in the case of machine learning that you want
to solve, and maybe you have limited amount of training data for the task.
So you can set up a different but related machine learning task for which you have plenty
of training data available.
And by solving, by trying to learn how to solve this new task, the hope is that you're
going to learn something useful, you're going to learn some skills that then you can transfer
to your regional machine learning problem that you care about.
And this is often done with models trained on like ImageNet data, for example, is that
something that you guys did in particular?
Or did you apply other models to this particular problem?
And how did you go about thinking about where to start?
Yeah, so that's how the ImageNet is often a great place to start with if you're looking
with, if you're dealing with sort of natural images.
One challenge in our application domain is that we're looking at satellite images, which
look very, very different from the kind of images that you can find in ImageNet.
They are not object-centric, like there's not a single object in the middle, like you typically
have ImageNet.
They are taken sort of like from this bird's eye perspective, which is very different
from ImageNet.
They have more bands, so it's not just RGB, but you have a whole set of other bands that
you don't typically have in ImageNet.
And so the kind of typical features that you, that the network say convolutional or network
pre-trained on ImageNet is able to discover, do not work well when dealing with satellite
images.
And so what we did was to come up with other transfer learning ideas.
This was actually for a slightly different problem in which we were trying to predict
the distribution of wealth and poverty, in this case, in developing countries.
Again, we were trying to do this using a cheap and conventional data sources.
In this case, we were using higher solution satellite images, while there is very little
data on poverty, there are many African countries that are not taking a nationally representative
survey, maybe in a decade or so.
Satellite images are available in basically every part of the world that they can update
it very frequently.
And they contain a lot of information about various types of socioeconomic outcomes, both
in terms of poverty, wealth, but also, yeah, agriculture outcomes, like we were just
talking about before in the context of copy and prediction.
And so the problem that we were looking at in that paper was that of trying to predict
various types of poverty estimates like asset-based measures of wealth or other measures of poverty
based on income.
Again, using raw satellite images, which are widely available.
And the challenge was that, again, we have very limited training data available to train
these models.
And so we had to do some transfer learning.
And there, the idea was that it turns out that there are satellites that take images of
the Earth both during day and during night.
And so during night, you get to see the amount of nighttime light intensity associated with
essentially every region in the world.
And it turns out that nighttime light intensity is heavily correlated with the level of economic
activity.
If you haven't seen it, you should try to see the different areas in North Korea and South
Korea.
You're going to see that South Korea almost looks like an island at night because North Korea
is so dark at night.
And so the idea there was to see whether we can train a machine learning model to predict
the amount of nighttime light intensity for many, many locations across the world just
by looking at the corresponding daytime images.
And we could do that.
And this is a task for which we have essentially an infinite amount of training data because
these satellites are continuously taking images both during day and during night.
And the hope was that by training the model to solve this task, people discover features.
They are somehow related to the level of economic activity.
And it turns out that it is indeed the case, it turns out that if you train a convolution
neural net to solve this task, and then you sort of try to visualize the features that
the network learns, you discover very features that are very semantically meaningful, like there
is a filter that learns how to recognize roads, other filters try to identify different
types of houses or other features of the landscape, like farmland, whether there are roads with
lots of traffic or not, even swimming pools.
And the nice thing was that this was all discovered in a unsupervised way.
Like we never told the network, you know, look for houses or provide labels of what a road
is or what a house is or what a swimming pool is.
It really discovered these semantically meaningful features by itself, purely by solving this
transfer learning task of trying to predict nighttime-line intensity from data and images.
And then what we did was to use these features that we learned in this transfer learning task
to actually predict the various poverty measures that we cared about.
And because we had such good features, again, we were able to get very high accuracy, even
though we had, there's limited amount of training data corresponding to these poverty metrics
that we cared about predict.
Wow, very, very interesting.
What do you call the name of the paper where you describe the transfer learning technique?
So we had two papers on this.
There was a paper, a triple AI, which is called the transfer learning from the features
for remote sensing and poverty mapping.
And then we had a follow-up paper on science called the combining satellite imagery and machine
learning to predict poverty, where we actually detailed the kind of results that we got in
predicting poverty in across five African countries.
And we showed that it can really outperform all the previously existing techniques by quite
a large margin.
So in that what were without totally losing our place on the crop yield prediction,
can you talk through some of the techniques that went into the transfer learning work?
So that's essentially the key, sort of, just of the transfer learning, trying to find
a task that is somehow correlated with the one you care about, but for which you have
a lot of training data.
We didn't actually use transfer learning for the crop yield prediction.
We just used the dimensionality reduction.
The other thing we used was an idea called semi-supervised learning, which is another approach
that you can use when you have a small amount of labeled training data and potentially
very large amount of unlabeled training data, which is, for example, the case in our applications
where we have a lot of satellite images, but we have a very small amount of labels corresponding
to the amount of soybeans that were produced in different regions or the poverty, sort
of, like, survey-based measures of poverty in developing countries.
And the kind of technique that we use to do semi-supervised learning in this case is a
combination of neural networks with Gaussian processes.
The idea is that we are trying to predict things that have a structure, like we're trying
to predict a distribution of, say, wealth or crop yields across space and time.
And we are expecting these outputs that we're trying to predict to change slowly as a function
of time and space.
And so that's some kind of microbiology that you can incorporate into the model.
And we did this using our Gaussian process, which is a probabilistic model that you can
use to model all sorts of things, but it's very popular in the Geo-statistics community
to sort of model functions that are over space and time, and then you can use this probabilistic
model to not only make predictions, but also to measure the uncertainty that you have
when you make predictions at new locations for which you don't have training data.
And so is the Gaussian process primarily used, especially, as you just mentioned, or is
it also used in time, meaning I've got a label at some point in time, but I don't know
how the value of that label changes over time.
So we apply a Gaussian to that, or both of the above.
Both of the above, yeah, in our case, we were looking both over space and time.
So in general, you can use Gaussian processes over any kind of input space.
They're often used to model functions of the change over space and time.
And the key thing that we did was to combine these with neural networks for each location
in space and time.
We have a corresponding image that is collected by a satellite, and so we somehow want to
include that information to inform the predictions that are made by the discussion process.
And the idea was that we could somehow extract features from an image using a convolution
neural network, and then use these features together sort of the spatial and temporal structure
of the problem to make predictions.
And the nice thing about the Gaussian process is that it not only allows you to make predictions,
but again, it lets you quantify the uncertainty that you have when you make predictions and
new unlabeled data points.
So our idea of doing semi-supervised learning was to sort of join to train the neural network
and the Gaussian process in order to achieve a good fit at the points for which we had actual
labels.
What at the same time, trying to minimize the uncertainty at points for which we don't
have labels, points for which we have the inputs, but we don't have the outputs.
And it turns out that even though we don't have the actual sort of output for this, for
this unlabeled data points, the Gaussian process will still be able to make a prediction and
will still be able to quantify the uncertainty of this prediction.
So we can join to train both of them to actually minimize this measure of uncertainty.
And that's essentially how we use the unlabeled data points together with the labeled ones
to in this semi-supervised learning framework.
And in some sense, it's a formal regularization that is sort of forcing the model to look for
features that are not only useful for the labeled data points, but it's sort of also, they
are also relevant for the unlabeled data points.
And it turns out that by using this framework, the semi-supervised framework we developed,
we were able to further improve the accuracy in both the power-to-tradition task and the
crop-to-tradition task.
Okay, so taking a step back, you've got this image data from the satellites that is, you
know, has pixels, but is multi-model, so it has multiple pixels for each location.
When you talk about making a prediction from a particular point, is that, what's the
granularity there?
Are you predicting the level of Walter Poverty from a pixel or are you somehow aggregating
multiple pixels to form an area?
Yeah, good question.
So we were looking, we were making predictions at the one kilometer or one kilometer sort
of areas, which correspond to multiple pixels.
So for each sort of location, we would collect multiple images that would cover that location,
and then we would sort of aggregate all the information and make a prediction for that
area.
And so you've got all this input data, you're feeding that input data into a convolutional
neural net, which is essentially taking kind of various chunks of the images and translating
them, rotating them, things like that to try to identify what are the salient features
within the images.
And then your, I guess the question that I'm getting at is how and, you know, where do
you marry the Gaussian stuff with the CNN stuff?
Is that a training?
Is that a step that's taken in the training?
Is that a feature of the model architecture?
How do they tie together?
Yeah, you can think of it as both.
So you can sort of think that there is one neural network making prediction at each
different location.
But then all the predictions that are made across different locations are all tied together,
because we know that the outputs are spatially correlated.
So if you take two locations that are close to each other, we know that we sort of expect
the outcomes that we're trying to predict to be more similar to the locations are close
to each other.
And we know that empirically, if you plot a very grand measuring place, there is a large
spatial correlation in these kind of things that we're trying to predict.
As you can imagine, the Gaussian process has an extra layer in your neural network at
the very end.
It's kind of tying together, coupling together all the outputs of these predictions made
by all these various convolutional neural networks.
And by using this, you can sort of exploit this prior knowledge that you have about the
spatial and potentially important dependencies across the outputs.
How many layers did the network end up having?
Yeah, we experimented with several architectures.
I think the one in the science paper, it was based on a BGG network.
More recently, we've been playing with Rasmash of 50 layers, and those tend to work
even better.
And what's the, do you have a sense for the relative performance within without the Gaussian
layer?
Or I imagine that's what you talked about in your paper.
Was that, you know, the, I guess, fundamentally, did the Gaussian layer make this possible?
Or was it adding an incremental boost in performance?
It's adding an incremental boosting performance.
I think you could have gotten some reasonable results, even without the Gaussian process,
but the Gaussian process definitely, definitely helped by maybe improving by maybe 10% or
15% something like that.
Is there anything in particular else that you learned about the process of architecting
networks for this type of problem in the context of this work?
Well, one thing that matters the most is that somehow it's quite interesting how we started
trying to sort of inspire the architectures and try out networks that were sort of losing
inspired by what our domain experts would tell us was important to say in the context
of crop yield prediction, there has been quite a bit of work in the remote sensing literature
in coming up with the handcrafted features and various types of indexes, combination
of various bands that they think are going to be predictive of vegetation growth and
therefore also crop yields.
And it turns out that if you actually train and the neural network to sort of discover
the features by itself just by doing representation learning using a modern machine learning approach
where we let the data speak for itself and try to identify which features are relevant
directly from data.
It turns out that our model ended up using a very, very different kind of different inputs
ended up matter, mattering much more for our model than what was previously thought in
the remote sensing literature.
So some bands that people thought were not particularly important for crop yield prediction
ended up being very, very important for our neural network and vice versa.
So I think it's similar to what's going on, what happened in computer vision, what
people for a long time were handcrafting features and then it turns out that if you sort of
train and to end the neural network you can do an out better than anything sort of people
had the all the kind of kind of crafted features that people had come up with in over the years.
And so something similar was happening in this case that using this modern machine learning
techniques we were able to come up with very different features than what was previously
thought.
And do you attribute the difference between what your models came up with and what domain
experts tended to use with biases on the part of the domain experts with confounding factors
in the model or the use case, any particular insights there?
So unfortunately this neural network is very powerful and making predictions but it can
be hard to really, they're not getting different.
It can be very hard to figure out exactly what they're doing.
We'll talk about that problem quite a bit on the shelf.
So we had the same issues and sort of trying to understand and trying to explain what this
model is doing was very hard.
And so we don't have a good sense of why at the moment is something we're actually actively
researching and really trying to understand why this model capturing and why does it perform
so much better on the previous techniques.
But I think we're going to need probably entirely new techniques to figure out these issues
in a more physical way.
When you describe the approach of using the nighttime imagery to train the model on the
daytime imagery imagery, it reminded me a little bit of another one of your recent papers.
Also AAAI paper from this year on the label-free supervision of neural networks with physics.
And so there are a lot of kind of a lot of parallels there.
But this one, the context in which it's talked about in this paper is kind of an interesting
one where you've got models that you're trying to predict, well, I guess I should allow
you to explain that.
Why don't you go ahead and explain what the focus of that paper was?
Sure.
So I mean, it fits into the general, one of the general themes that I'm excited about,
which is this idea of trying to incorporate the main knowledge into machine learning
systems.
So find ways to provide supervision that are alternative to coming up with millions of
labeled examples.
And so the idea of doing semi-supervised learning, the idea of doing transfer learning,
the idea of doing various dimensionality reduction techniques, fits into this broader
agenda.
I'm trying to see where we can go beyond this labeling, which is really a major bottleneck
and it's really preventing us from applying this machine learning techniques in domains
like the kind of applications we are interested in, this is the ability space where the labels
are just not available.
And I mean, if you wanted more labels, you could not get them.
Like we were a couple of months ago, I said, we were running our model in Somalia, we're
making poverty predictions in Somalia for the World Bank.
And that's a country where they cannot, they were telling me how they cannot even stand
that there are people on the ground to collect data because it's just too dangerous.
And so we are literally looking at problems where getting labels is not possible or is just
too expensive.
So we need to think about different ways to incorporate domain knowledge into machine learning
systems.
And this particular triple AI paper that you mentioned, we were looking at whether we
can use a prior domain knowledge, like knowledge about the laws of physics to supervise object
detectors in that case, supervise, convolutional neural networks and teach them how to recognize
objects by providing sort of this high level description of the kind of things the network
should be looking for.
So even though we don't have precise labels saying, okay, here's the object that you should
be looking for.
One thing that we tried was to see whether it's possible to learn how to recognize these
objects by providing a high level description, like something like a loose description of
the dynamics of the kinematics of the object.
And we showed in that paper that it's possible in some cases, we provide some proof of concept
demonstration that it's possible for example to train a convolutional neural network to
recognize objects moving, falling sort of through the air, just by providing some prior
knowledge about gravity essentially just by saying, well, I know that if an object is falling
and moving through the air, then there's gravity, and so the trajectory will form a parabola.
Just by using this prior knowledge, it turns out it was sufficient to learn how to recognize
objects moving in that video.
And so to be a little bit more concrete in this paper, you use the example of projectile
in particular a pillow.
And from some of the images that you had in the paper, you can imagine a neural network
getting confused between the pillow and the fluorescent lighting, and presumably the knowledge
that you're giving it about the laws of motion, if you will, the physics of a projectile
pillow will help the network figure out where the pillow is.
Exactly.
And then it strikes me that perhaps this is relatable to your research on crop yields.
And for example, you may have knowledge about seasonality in the way, or if not crop
yields the poverty piece, but you may have information about seasonality and how tree
leaf colors change over time, or there's all kinds of things that we know about the
physical world, and one would presume that the more we can incorporate that into our
models, the smarter those models would be.
Correct.
And so how exactly do you, how do you incorporate that into models that an algebraic representation
of some sort, or so, yeah.
So in the triple algorithm, we were only looking at algebraic representation in the case
of physics law, or using logical representation.
We also had another example where we showed that if you know some, you have some prior knowledge
that you can describe using logical forms, something like whenever object A appears in
an image, then object B is also present in an image.
Think this kind of relationship that can be fairly naturally captured using logic in terms
of it's a fairly natural framework for you to model and to write down some prior knowledge
of a particular domain.
That's those are the two things that we that we explore in the triple AI paper.
We are doing some work right now on using simulators.
That's another fairly common way in which we can formulate prior knowledge about domain,
especially in the physical sciences, we might have a rough simulator that gives us a sense
of how a particular physical system behaves.
And the question was whether some of the things we are exploring right now is to see how
to incorporate a simulator and put it together with data on labeled data and see whether
we can combine these things together and use the knowledge that is sort of inherently present
in the simulator to provide supervision to say neural networks.
One of the areas spending some time researching of latest industrial AI and how AI factors
into control and optimization scenarios and robotics and manufacturing and things like
that.
And the use of simulators is a key importance in those areas.
So it's interesting to see you applying that here as well.
So are you are we at the point where you have a how generalizable is the an architecture
that can incorporate these types of rules, meaning is there is the you know, a particular
law of physics, you know, baked deeply into the model architecture or the training process
or, you know, can you envision some kind of architecture or a training regime that you
can feed a somewhat generic kind of rule or law engine that can bake the stuff in.
Yeah, that's a great question.
So at the moment, it's all very much specific to particular constraints and particular forms
of domain knowledge.
At the moment, basically, you have to invest a considerable effort into the engineering
and the right objective function and figure out how to bake in the prior knowledge into
the system.
So it's a different kind of trade off where you're sort of you're still spending and seeing
significant amount of time sort of providing supervision to the system.
But the advantage is that it does not scale linearly in the number of in the size of your
training data.
Right.
So it's an interesting trade off that might be might be advantageous in some situations.
But the dream is to be as you said, sort of come up with a general language that we can
use or a general system that will make it easy to incorporate prior knowledge into
engineering systems.
But we're not there at the moment.
We don't have it.
But I think that that's what we need in order to make sure that people can use the systems
and they can really dramatically reduce the amount of training data that they need to
solve their tasks.
Maybe we're not going to be able to get away with the training data completely, like we
showed in the trip or I paper where we didn't use any label at all.
But maybe and the hope is that it would work like for us for humans where maybe a handful
of examples is enough to learn how to solve an interesting task because and maybe just
a high level description plus a few examples is enough to solve the problem as opposed
to millions of labels, which which is not how we how we learn, I think, right.
So any thoughts on where you see this all going or how you see it evolving over time or
even simply what you're most excited about right now?
Yeah, that's definitely something I'm interested in trying to understand how to put in how
to put in prior knowledge, how to combine it with labels in a most effective way, also
how to do, I mean, a super buzz learning, that's another thing we're playing with this
day is how do you discover structures from data and how far we can push this thing and
really how many, how much, why, how much can we reduce the need for training data and
these are all problems that I'm very excited about thinking about what's the right way
to represent knowledge and what's the right way to put the knowledge into the machine learning
systems and finally how to reverse the process like here we showed how we can put in some
physics and we can make the machine learning system better.
But ideally, I would like to then invert this and try to go from then try to still physics
and try to still knowledge from the from the raw data.
I want my machine learning system to come up with new hypothesis and one is to discover
where have it be just with the end of it is and I think that's what's really exciting
I think we're we're we're so far but I think that would be pretty amazing because then
we can really think about using machine learning in the most physical sciences that's a
space in which we haven't seen as much as we not not as much as in sort of other kind
of application domains I think so I think but there's a lot of potential for using AI
machine learning in the physical sciences because they're doing more and more of high
throughput experiments collecting massive amounts of data and to human time humans are
really the bottleneck trying to analyze this data trying to figure out what is going
on figure trends understand what is interesting what it's not and if we had a way to to put
in that machine learning and any AI systems to help and then sort of make the process easier
trying to automate it a little bit or as much as possible I think I think the benefits
could be could be really huge.
Yeah absolutely absolutely.
So we talked about a bunch of your work in particular several papers if someone wanted
to you know if it's possible to do this kind of get up to speed on your research and
the you know the kinds of things we've discussed are there you know one two or three papers
that would be the kind of key things to you know help them understand what you're up
to.
So if you want to learn about the physics and domain knowledge just the triple AI paper
called supervised supervising neural network with physics and other domain knowledge for
the sustainability applications so there are the papers you mentioned there's the science
paper and that there's the deep Gaussian process for property prediction which is also
triple AI showing discussing how to use the Gaussian processes and the missionality
reductions in to deal with remote sensing data.
So those are the right places to start.
And just to close out if the what's the someone wants to kind of learn more or get in touch
or kind of follow you on a social media if you're out there any particular coordinates
you would point folks to.
Yeah come to my website just to Google my name it's probably the first thing that comes
up with Google it's you can see all my papers or visit my research group website then
you can see all the latest stuff.
Well we'll link directly to it in the show notes so folks won't need to Google it.
But this was a great conversation I really enjoyed talking to you about the work and
I'm super excited about the work you're doing the papers are really interesting and I learned
a ton.
Thanks so much Stefano.
Thanks for having me.
It was a lot of fun too.
Bye bye.
Bye bye.
Alright everyone that's our show for today.
Once again thanks so much for listening and for your continued support.
Don't forget to share your favorite quote from this show to get one of our new stickers.
You can share them via the show notes page via Twitter via our Facebook page or via a
comment on YouTube or SoundCloud.
Please use the hashtag Twimlai on Twitter.
The notes for this show will be up on twimlai.com slash talk slash 15 where you'll find links
to Stefano and the various resources mentioned in the show.
Thanks so much for listening and catch you next time.
