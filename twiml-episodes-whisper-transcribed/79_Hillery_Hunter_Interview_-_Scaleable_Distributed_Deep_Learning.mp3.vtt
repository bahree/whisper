WEBVTT

00:00.000 --> 00:15.920
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

00:15.920 --> 00:20.920
people doing interesting things in machine learning and artificial intelligence.

00:20.920 --> 00:23.200
I'm your host Sam Charrington.

00:23.200 --> 00:27.360
This week on the podcast we're running a series of shows consisting of conversations

00:27.360 --> 00:33.120
with some of the impressive speakers from an event called the AI Summit in New York City.

00:33.120 --> 00:38.160
The theme of that event and of this series is AI in the Enterprise.

00:38.160 --> 00:42.240
And I think you'll find this series really interesting in that it includes a mix of both

00:42.240 --> 00:46.600
technical and case study oriented discussions.

00:46.600 --> 00:51.560
Now I won't actually be attending the AI Summit this week because I'm in Long Beach

00:51.560 --> 00:54.560
California attending the Nips Conference.

00:54.560 --> 00:59.760
There are a bunch of Twimble listeners here and I'm hoping to meet as many of you as possible.

00:59.760 --> 01:02.040
And yes, I have stickers.

01:02.040 --> 01:06.320
If you're here at Nips and you're actually listening to podcasts this week, please

01:06.320 --> 01:11.320
reach out to me either via the event app, the Nips event app where there's a Twimble

01:11.320 --> 01:16.960
listeners thread or via Twitter where my handle is at Sam Charrington.

01:16.960 --> 01:21.120
Before we proceed, let's quickly talk about the podcast schedule through the end of the

01:21.120 --> 01:22.120
year.

01:22.120 --> 01:26.080
Prior to my newsletter, you know that I've been on the road for a couple of weeks now.

01:26.080 --> 01:30.800
After this week's series, we've got two more series coming before we break for the year

01:30.800 --> 01:34.280
with our last show running on December 22nd.

01:34.280 --> 01:39.480
Now, if you're lamenting two weeks without your favorite machine learning and AI podcast,

01:39.480 --> 01:42.680
trust me with these two series.

01:42.680 --> 01:48.320
The first from the Amazon Web Services Reinvent Conference and the next one from Nips.

01:48.320 --> 01:53.440
You will have plenty of great content to tide you over until we get started again on January

01:53.440 --> 01:54.440
8th.

01:54.440 --> 02:01.000
Thanks to you, 2017 was a great year for the podcast and we plan to close it out strong.

02:01.000 --> 02:05.400
So keep your ears open the next few weeks and we hope to hear from you.

02:05.400 --> 02:11.440
Please note that on Wednesday, December 13th, we'll be holding our last Twimble Online

02:11.440 --> 02:13.760
Meetup of the Year.

02:13.760 --> 02:19.280
Bring your thoughts on the top machine learning and AI stories of 2017 for our discussion

02:19.280 --> 02:20.600
segment.

02:20.600 --> 02:25.680
And for our main presentation, Bruno Gensalvez, we'll be presenting the paper Understanding

02:25.680 --> 02:32.680
Deep Learning requires rethinking generalization by Shi Yuan Zhang from MIT and Google Brain and

02:32.680 --> 02:34.000
others.

02:34.000 --> 02:40.160
You can find more details and register for the meetup at twimlai.com slash meetup.

02:40.160 --> 02:45.520
This AI Summit series is brought to you by our friends at IBM Power Systems.

02:45.520 --> 02:50.000
IBM Power Systems offers servers designed for mission critical applications and emerging

02:50.000 --> 02:55.120
workloads, including artificial intelligence, machine learning, deep learning, advanced

02:55.120 --> 02:58.360
analytics, and high performance computing.

02:58.360 --> 03:03.720
IBM Power Systems benefit from a wide range of open technologies, many stemming from

03:03.720 --> 03:08.800
collaboration with fellow Open Power Foundation members, and they're designed to deliver

03:08.800 --> 03:15.520
performance efficiently, whether deployed in private, public, or hybrid clouds.

03:15.520 --> 03:23.120
To learn more about the IBM Power System AC-922 platform for Enterprise AI, visit twimlai.com

03:23.120 --> 03:25.360
slash IBM Power.

03:25.360 --> 03:30.920
My guess for this first show in the AI Summit series is Hillary Hunter, IBM Fellow and Director

03:30.920 --> 03:36.920
of the Accelerated Cognitive Infrastructure Group at IBM's TJ Watson Research Center.

03:36.920 --> 03:41.000
Hillary and I met a few weeks back in New York City and I am really glad we were able to

03:41.000 --> 03:42.800
get around the show.

03:42.800 --> 03:47.000
Hillary joins us to discuss our team's research into distributed deep learning, which was

03:47.000 --> 03:53.720
recently released as the Power AI Distributed Deep Learning Communication Library, or DDL.

03:53.720 --> 03:58.200
In my conversation with Hillary, we discussed the purpose and technical architecture of the

03:58.200 --> 03:59.200
DDL.

03:59.200 --> 04:04.440
It's multi-ring topology, its ability to offer synchronous distributed training of deep

04:04.440 --> 04:07.320
learning models and much more.

04:07.320 --> 04:12.680
This is for sure a nerd alert pod, especially for the performance and hardware geeks among

04:12.680 --> 04:13.680
us.

04:13.680 --> 04:17.720
Be sure to post any feedback or questions you may have to the show notes page, which

04:17.720 --> 04:22.880
you'll find at twimlai.com slash talk slash 77.

04:22.880 --> 04:25.160
And now on to the show.

04:25.160 --> 04:35.400
All right, everyone, I am on the line with Hillary Hunter.

04:35.400 --> 04:42.240
Hillary is a IBM Fellow and Director of the Accelerated Cognitive Infrastructure Group

04:42.240 --> 04:45.040
at IBM's TJ Watson Research Center.

04:45.040 --> 04:47.880
Hillary, welcome to this week in Machine Learning and AI.

04:47.880 --> 04:48.880
Thank you so much.

04:48.880 --> 04:50.200
Very excited to be here.

04:50.200 --> 04:52.880
I'm excited to have you on the show as well.

04:52.880 --> 04:56.880
Folks won't know this until I tell them, but we had an opportunity to meet just a few

04:56.880 --> 05:04.580
weeks ago in New York City at the NYU at a reception held in conjunction with the NYU Future

05:04.580 --> 05:10.560
Labs event, and it was certainly great to meet you in person and even better to have

05:10.560 --> 05:14.840
an opportunity to get you on the line and dig into some of the work that you've been

05:14.840 --> 05:15.840
up to.

05:15.840 --> 05:20.080
Yeah, it was a pleasure meeting you there and it was certainly a really interesting event

05:20.080 --> 05:24.720
and a great opportunity to see some of the exciting things going on in the New York area

05:24.720 --> 05:28.200
and AI and AI is just exploding everywhere.

05:28.200 --> 05:30.000
But it's a pleasure to be here on your podcast.

05:30.000 --> 05:31.720
I look forward to our discussion.

05:31.720 --> 05:32.720
Awesome.

05:32.720 --> 05:37.520
So why don't we get started by having you tell us a little bit about how you, your background

05:37.520 --> 05:40.520
and how you got involved in artificial intelligence?

05:40.520 --> 05:42.360
Yeah, it's interesting.

05:42.360 --> 05:46.920
I like to say that AI really has exploded for two reasons.

05:46.920 --> 05:52.280
One being the amount of data, I'm going to especially publicly available data sets and

05:52.280 --> 05:55.080
the second being the compute.

05:55.080 --> 05:59.720
And I come from a background technically that's really a mix of both those things.

05:59.720 --> 06:04.720
And AI has been an opportunity to bring together a lot of different things that I've done

06:04.720 --> 06:08.880
in prior technical work and a lot of different things done by members of my team in kind of

06:08.880 --> 06:12.160
prior technical lives before getting into AI.

06:12.160 --> 06:15.720
So I come from a systems perspective, from a hardware perspective.

06:15.720 --> 06:21.320
I was an electrical engineer by training, and so, yep, I was a doubly.

06:21.320 --> 06:28.040
Yeah, so that background is kind of where I'm coming from and approaching these problems

06:28.040 --> 06:30.400
that we're trying to tackle in AI.

06:30.400 --> 06:36.160
And I bring to the table background in performance, the background in data movement in systems,

06:36.160 --> 06:41.680
and both are proving to be really fruitful for getting some of the grand challenge kind

06:41.680 --> 06:44.360
of scale problems done that we're facing today in AI.

06:44.360 --> 06:47.600
Awesome. And have you spent most of your career at IBM?

06:47.600 --> 06:48.600
I have.

06:48.600 --> 06:49.600
Yeah.

06:49.600 --> 06:55.480
So I got my PhD at University of Illinois and started at IBM in 2005, and I've been with

06:55.480 --> 06:57.320
IBM research since then.

06:57.320 --> 06:58.320
Fantastic.

06:58.320 --> 07:04.160
And have you been working on, in the same group, working on accelerated cognitive infrastructure

07:04.160 --> 07:08.160
or have you done kind of evolved to that, this particular position?

07:08.160 --> 07:09.160
Yeah.

07:09.160 --> 07:10.720
This position has evolved.

07:10.720 --> 07:16.280
You know, we really ramped up our efforts around accelerated computing a number of years

07:16.280 --> 07:17.280
ago.

07:17.280 --> 07:22.600
Prior to that, I was working on things related to processor design and memory technologies.

07:22.600 --> 07:26.040
And it's interesting because, again, the memory relates to the data movement, relates

07:26.040 --> 07:29.720
to, you know, feeding the AI, feeding the accelerator.

07:29.720 --> 07:32.560
So it's all kind of come together in a really nice way.

07:32.560 --> 07:33.560
Great.

07:33.560 --> 07:40.240
And your group recently published some really interesting research on essentially scaling

07:40.240 --> 07:45.600
deep learning performance using distributed, distributed techniques.

07:45.600 --> 07:50.200
That was one of the big things that I wanted to spend some time talking about in this interview.

07:50.200 --> 07:53.280
Can you give us an overview of that research?

07:53.280 --> 07:54.280
Yeah.

07:54.280 --> 07:57.720
We were really excited by what we were able to publish.

07:57.720 --> 08:03.960
We're calling it the Power AI DDL or Distributed Deep Learning Capability.

08:03.960 --> 08:09.560
And basically, what we showed is that we were able to create a framework independent.

08:09.560 --> 08:14.920
So independent from TensorFlow or Cafe or PyTorch or your favorite way of doing deep learning.

08:14.920 --> 08:19.360
We were able to create a framework independent communication library that achieves close

08:19.360 --> 08:24.760
to optimal, very, very close to optimal, up to 95% scaling efficiency.

08:24.760 --> 08:31.080
So what this meant for us is that we were able to use lots of GPUs together very, very

08:31.080 --> 08:32.400
efficiently.

08:32.400 --> 08:38.760
And we were able to use those mechanisms to train a neural network, to train a ResNet

08:38.760 --> 08:44.280
to the highest published accuracy on a really hard problem.

08:44.280 --> 08:49.840
And we were also able to beat what had been shown as a record of around an hour or 66 minutes

08:49.840 --> 08:52.480
on a smaller neural network and a smaller problem.

08:52.480 --> 08:57.280
And so we really were able to show that through hardware software integration, we were able

08:57.280 --> 09:00.840
to have world-class AI capabilities.

09:00.840 --> 09:07.440
And for us, this really kind of signaled a change in the productivity curve for deep learning

09:07.440 --> 09:13.880
because most of the open source today just kind of handles a single node worth of performance.

09:13.880 --> 09:15.200
So you're kind of stuck then.

09:15.200 --> 09:18.640
You can have two GPUs, four GPUs, maybe eight.

09:18.640 --> 09:24.040
But scaling out to many, many servers has been a really big challenge.

09:24.040 --> 09:27.480
And the more servers and the more hardware you can use for a problem, the faster you get

09:27.480 --> 09:29.920
that work done and the more productive you are.

09:29.920 --> 09:34.080
Now, that last point might be one that's worth underscoring.

09:34.080 --> 09:41.520
If you look at a framework like TensorFlow, there's, as part of the open source TensorFlow,

09:41.520 --> 09:43.960
there's a distributed TensorFlow.

09:43.960 --> 09:51.440
But that's more useful for scaling across GPUs than it is across servers, is that correct?

09:51.440 --> 09:57.720
So there is a version of distributed TensorFlow and what we really are kind of looking at

09:57.720 --> 10:05.320
in that versus the DDL capabilities is the extent of scalability and ultimately the

10:05.320 --> 10:06.680
productivity of the servers.

10:06.680 --> 10:14.600
So the default distributions in TensorFlow haven't been shown to be able to use as many

10:14.600 --> 10:20.760
as 256 GPUs as far as I'm aware and based on our own internal studies.

10:20.760 --> 10:26.400
So there are X factors to be had with every extra set of servers that you can add.

10:26.400 --> 10:28.560
You get the work done faster.

10:28.560 --> 10:32.720
And also we've shown that our communication patterns and communication overheads are

10:32.720 --> 10:33.960
really close to optimal.

10:33.960 --> 10:37.920
And so the other things that are out there appear to be less efficient.

10:37.920 --> 10:41.720
And so that means at the end, a longer time to solution.

10:41.720 --> 10:42.720
Okay.

10:42.720 --> 10:48.040
And the 256 GPUs that you are running was across how many systems?

10:48.040 --> 10:49.040
Yeah.

10:49.040 --> 10:56.360
So we ran across 64 servers and we were using the Pascal P100 GPUs.

10:56.360 --> 11:00.680
The work that we did was right before, right on the cusp of Volta coming out and miss

11:00.680 --> 11:03.240
the very latest GPUs.

11:03.240 --> 11:08.160
And I like to always kind of describe why this is a hard problem because the GPUs are so

11:08.160 --> 11:11.680
fast that they all learn very quickly.

11:11.680 --> 11:16.680
And so if you think of there being 256 kind of learners in the system, the hard part

11:16.680 --> 11:21.320
is keeping everybody synced up in that process of keeping them synced up.

11:21.320 --> 11:25.600
It's really critical that that be done with as low latency of a communication as possible.

11:25.600 --> 11:30.560
And that's really the core of the technology that we showed is that the communication time

11:30.560 --> 11:31.760
is really, really low.

11:31.760 --> 11:35.880
And that enables you then to do fully synchronous training, meaning everyone is updating everyone

11:35.880 --> 11:38.920
else with all the information that's being learned.

11:38.920 --> 11:42.920
All the weights are being updated as they should after every batch.

11:42.920 --> 11:47.560
And that means at the end that you're doing a type of deep learning that is opposed to

11:47.560 --> 11:51.160
asynchronous where they're kind of occasionally updating each other in order to lower the

11:51.160 --> 11:55.760
communication overhead, when you're able to do fully synchronous, you're able to kind

11:55.760 --> 12:01.240
of keep everything moving forward a little bit more predictably, predictably, sorry, and

12:01.240 --> 12:05.240
you're able to get a higher accuracy result at the end in general.

12:05.240 --> 12:06.240
Okay.

12:06.240 --> 12:12.080
And introducing this, you said it's called Power AI DDL for those who aren't familiar

12:12.080 --> 12:13.480
with Power AI.

12:13.480 --> 12:20.760
What is Power AI and to what extent are the results that you demonstrated here tied to

12:20.760 --> 12:23.480
that Power AI architecture?

12:23.480 --> 12:24.480
Yeah.

12:24.480 --> 12:29.240
So for us, this is very much an effort of hardware and software co-design.

12:29.240 --> 12:38.240
Power AI runs on the IBM SC822LC servers, sorry, actually, S822LC servers.

12:38.240 --> 12:43.040
And those servers have two power processors, and they have four GPUs.

12:43.040 --> 12:45.880
And everything is connected by doubled up NV links.

12:45.880 --> 12:54.040
So Nvidia has this high bandwidth interconnect capability, and we have that high bandwidth connectivity

12:54.040 --> 12:58.760
not just between the GPUs, but also back to the host processor.

12:58.760 --> 13:03.040
And so that provides extra performance in moving data and moving weight updates and everything

13:03.040 --> 13:04.800
in the system.

13:04.800 --> 13:10.800
And our communication library also leverages all of that bandwidth to its max and to its

13:10.800 --> 13:12.440
full potential.

13:12.440 --> 13:17.480
And so when we talk about this whole space of deep learning and what we're doing from

13:17.480 --> 13:22.680
a systems perspective and with things like DDL, we're talking about matching the software

13:22.680 --> 13:26.160
to fully utilize the hardware capabilities.

13:26.160 --> 13:31.160
And for us, this is also a storyline around collaboration between our research division

13:31.160 --> 13:38.240
that I actually report in and our product division, our development division, because we were

13:38.240 --> 13:45.440
able to actually put this code base out for IBM customers to try and download and try

13:45.440 --> 13:51.640
themselves, try DDL on their servers or on the cloud at the same time that we made the

13:51.640 --> 13:56.880
publication and the announcement of our leadership deep learning capabilities using this framework.

13:56.880 --> 14:02.400
So Power AI is a, it's a download and go set of distributions of frameworks that run

14:02.400 --> 14:05.000
on our accelerated servers.

14:05.000 --> 14:09.440
And we now have the distributed deep learning capabilities available there as well for customers

14:09.440 --> 14:10.760
to try themselves.

14:10.760 --> 14:16.560
So we really, from a research perspective, we're very excited about this because it means

14:16.560 --> 14:21.760
that we can kind of take this rarefied skillset of distributed deep learning, this kind of

14:21.760 --> 14:26.320
grand challenge thing everyone's competing over and put it in the hands of our customers

14:26.320 --> 14:31.160
to go ahead and try out and see what they can do with it on their data with their types

14:31.160 --> 14:32.320
and neural networks.

14:32.320 --> 14:41.000
And you mentioned that the results that you saw are framework independent is, is that

14:41.000 --> 14:48.440
true in the strictest sense or is it rather that the software that you wrote was written

14:48.440 --> 14:52.560
to adapt to some fixed number of frameworks?

14:52.560 --> 14:57.600
So it's pretty true in a strict sense, but let me define strict to make sure we're not

14:57.600 --> 14:59.720
talking past each other.

14:59.720 --> 15:04.440
So what DDL is is it's a communication library.

15:04.440 --> 15:07.520
So it lets things in a system talk to each other.

15:07.520 --> 15:13.120
We have been able to use that communication library across many different frameworks.

15:13.120 --> 15:17.520
What we released is already as part of Power AI was our integration into TensorFlow and

15:17.520 --> 15:22.400
into Cafe, but we also published results using our integration into Torch and we have

15:22.400 --> 15:28.640
other integrations that we have shown work just fine as well for our internal use currently.

15:28.640 --> 15:33.200
And so it we have shown I think at this point integration into enough frameworks that I'm

15:33.200 --> 15:37.280
pretty comfortable saying that, you know, this library can be integrated into pretty much

15:37.280 --> 15:38.280
anything that you write.

15:38.280 --> 15:39.280
Right, right.

15:39.280 --> 15:42.480
Yeah, I think in the context of my question, the answer is yes and yes, right?

15:42.480 --> 15:46.720
Yes, yes and yes, there we go.

15:46.720 --> 15:47.720
Interesting.

15:47.720 --> 15:54.880
And so how does how does this compare to some of the previous and even subsequent work like

15:54.880 --> 16:04.320
you refer to Facebook and Microsoft work in the paper or in the blog posts since I think

16:04.320 --> 16:10.760
since you posted this Uber published an open source project called Haravad that seeks

16:10.760 --> 16:12.840
to do something similar.

16:12.840 --> 16:14.840
Have you are you familiar with that one?

16:14.840 --> 16:16.640
Yeah, I am.

16:16.640 --> 16:21.800
And that's obviously a great, a great result that they put out there and we love seeing

16:21.800 --> 16:26.840
all the different efforts that are going on in this space because it really is such an

16:26.840 --> 16:29.520
important area for productivity.

16:29.520 --> 16:34.520
The Haravad team showed a great set of scaling, scaling experiments with their integration

16:34.520 --> 16:36.120
essentially of an MPI.

16:36.120 --> 16:38.480
It was open MPI, right?

16:38.480 --> 16:39.480
Mm-hmm.

16:39.480 --> 16:43.560
MPI reduced and the nickel libraries into TensorFlow.

16:43.560 --> 16:50.720
We do believe that our communication topologies are a bit better than what is there.

16:50.720 --> 16:57.160
And so the net scaling efficiency will be better and we look forward to being able to talk

16:57.160 --> 17:00.560
about that in a little bit more concrete detail pretty soon here.

17:00.560 --> 17:05.040
But I think, you know, it's great to see these different efforts toward distributed deep

17:05.040 --> 17:10.280
learning happening across different types of frameworks because ultimately the community

17:10.280 --> 17:15.880
needs to have this type of productivity in order for deep learning really to take off.

17:15.880 --> 17:21.760
For us though, the positioning at Power AI is really about taking open source and taking

17:21.760 --> 17:27.880
the complexity of managing it, of installing it, tuning up the performance, optimizing it

17:27.880 --> 17:33.600
for our systems, and then ultimately providing support on it for our customers.

17:33.600 --> 17:38.680
And so, you know, we love to see improvements in open source and much of what's provided

17:38.680 --> 17:42.160
in Power AI is open source and is based on open source.

17:42.160 --> 17:46.520
And then we're, you know, providing improvements on top of that and optimizations on top of

17:46.520 --> 17:47.520
that as well.

17:47.520 --> 17:52.480
So, we want to both take the time to get going with open source way down, which is the

17:52.480 --> 17:57.560
just download and go as well as we want to then be able to provide support and optimizations

17:57.560 --> 18:02.280
and improvements that are really significant on top of what's going on in the space.

18:02.280 --> 18:03.280
Mm-hmm.

18:03.280 --> 18:09.240
In terms of DDL, I'm curious if you can kind of walk through the next level of detail and

18:09.240 --> 18:15.160
why, you know, what are some of the architectural elements that you feel given an advantage

18:15.160 --> 18:18.880
relative to, you know, other things that one could do in general?

18:18.880 --> 18:20.360
Yeah, absolutely.

18:20.360 --> 18:22.960
So, there's two things.

18:22.960 --> 18:30.320
There's one, the advantages of the hardware, which are that the GPUs are double NV linked,

18:30.320 --> 18:35.200
connected to one another, and also double NV linked connected back to the host processor.

18:35.200 --> 18:40.280
Those features provide performance if you, you know, use them with an appropriate communication

18:40.280 --> 18:43.320
topology, which we do do with DDL.

18:43.320 --> 18:48.480
And in addition, then DDL at the overall system level, when you're talking about connecting

18:48.480 --> 18:53.720
together a bunch of different learners, a bunch of different system nodes, uses a multirang

18:53.720 --> 18:59.040
topology, not a single ring, but a multirang topology, and what this results in is our ability

18:59.040 --> 19:03.520
to use all of the links to the greatest advantage possible.

19:03.520 --> 19:08.240
If you do a naive mapping onto a system, or if you have a system with, you know, PCIe

19:08.240 --> 19:11.240
interconnect, there are going to be bottlenecks.

19:11.240 --> 19:16.120
What we do is kind of maneuver around the bottlenecks, and we use all the different bandwidths

19:16.120 --> 19:21.520
so the bandwidth between the GPUs, the bandwidth on a node, the bandwidth getting out to the network,

19:21.520 --> 19:22.520
etc.

19:22.520 --> 19:25.920
We use those to their best possible efficiency.

19:25.920 --> 19:29.240
So ideally, you know, you want to use all of the hardware and all the interconnect that

19:29.240 --> 19:32.240
you have, and software doesn't naturally do that.

19:32.240 --> 19:36.080
And so we've kind of taken all that work away from the developer and said, you know, we're

19:36.080 --> 19:37.560
going to max out the system.

19:37.560 --> 19:40.760
And if you buy the hardware, it's going to work really well because of the software

19:40.760 --> 19:45.960
and the way the software is using all the, all the, the system bandwidths.

19:45.960 --> 19:46.960
Hmm.

19:46.960 --> 19:53.160
When you talk about these rings, where in the system architecture do they exist, are these

19:53.160 --> 19:57.640
at the interconnect level, are they in memory, are they someplace else?

19:57.640 --> 20:01.240
So these are all within the different interconnects of the system.

20:01.240 --> 20:02.240
Okay.

20:02.240 --> 20:07.600
So the, they're part of the double NV link that you mentioned.

20:07.600 --> 20:08.600
Yep.

20:08.600 --> 20:13.440
A part of the double NV link, a part of the connections out in the network, part of the

20:13.440 --> 20:17.920
nodes being connected to each other with network connections, that kind of layer.

20:17.920 --> 20:19.960
You know, there's another thing we could talk about.

20:19.960 --> 20:20.960
You brought up memory.

20:20.960 --> 20:24.920
There's another thing that we could talk about, which is the large model support that

20:24.920 --> 20:28.160
we do, which is also a feature in Power AI.

20:28.160 --> 20:31.880
And that is a situation where you really want to try to use the different pieces of memory

20:31.880 --> 20:32.880
in the system.

20:32.880 --> 20:36.680
So, if you think of it philosophically, it would distribute a deep learning.

20:36.680 --> 20:41.280
We're using all of the, the links in the system, all the network bandwidth, all the bandwidth

20:41.280 --> 20:43.440
available on a given system.

20:43.440 --> 20:48.480
With large memory support, we're providing an out-of-core capability, meaning capability

20:48.480 --> 20:53.920
of, of accessing other resources, other memory in the system greater than just what the GPU

20:53.920 --> 20:55.440
has all by itself.

20:55.440 --> 20:59.480
And the way to think about that is, you know, if I have a system, the GPU has a small

20:59.480 --> 21:05.440
amount of memory today about 16 gigabytes, but the host processor has a lot more memory,

21:05.440 --> 21:11.240
128 gigabytes or 256 or up to a terabyte these days, right?

21:11.240 --> 21:16.880
So we provide function that enables people to explore bigger model sizes, bigger data

21:16.880 --> 21:18.720
sizes, etc.

21:18.720 --> 21:23.720
By accessing and using actively, all of the memory and not just the GPU's memory in the

21:23.720 --> 21:24.720
system.

21:24.720 --> 21:29.640
So, generally, I would say our philosophy is to kind of use all the resources available

21:29.640 --> 21:35.440
in the system, you know, and let the AI developer explore things as bigly, you know, as bigly,

21:35.440 --> 21:41.240
as largely, as largely, as large as they'd like to go, as big as they'd like to go.

21:41.240 --> 21:46.520
And that includes dimensions of both memory and the number of systems in that, you know,

21:46.520 --> 21:49.800
that you have to tie together.

21:49.800 --> 21:56.360
And we've talked about the kind of framework transparency, nature of this.

21:56.360 --> 22:03.360
Does that mean that all of the thinking that has to go into taking advantage of these

22:03.360 --> 22:10.720
elements happens at the DDL, you know, and or framework layer?

22:10.720 --> 22:16.840
And there's no, you know, no aspects of the, you know, the problem that has to be thought

22:16.840 --> 22:22.560
through by the developer or there's still things that the developer has to be aware of in

22:22.560 --> 22:26.280
order to be able to take advantage of what you've done here.

22:26.280 --> 22:30.480
Yeah, it's a, it's such an important point in productivity, right, because you can run

22:30.480 --> 22:31.480
as fast as possible.

22:31.480 --> 22:34.480
But if you're going to sit there for multiple days, scratching your head, trying to figure

22:34.480 --> 22:38.600
out how to run fast, it doesn't do anybody any good, right?

22:38.600 --> 22:43.360
So, so one of the, one of the decisions that we made when we did the integration, for

22:43.360 --> 22:48.720
example, into TensorFlow was to leverage the slim library, which is a library that kind

22:48.720 --> 22:52.600
of creates the capability to run a particular neural network.

22:52.600 --> 22:58.800
So in that case, we have hidden the DDL capabilities completely from the developer and they just

22:58.800 --> 23:00.360
have to use slim.

23:00.360 --> 23:04.920
So we're trying to hide under in general where we can abstractions that have been created

23:04.920 --> 23:08.920
at higher levels so that people don't have to, you know, spend days and weeks trying

23:08.920 --> 23:11.880
to figure out how to, how to use this technology.

23:11.880 --> 23:16.280
I think we're, we're very focused on, you know, developer productivity was part of the

23:16.280 --> 23:20.360
reason why we, you know, went from, you know, research endeavor to very quick engagement

23:20.360 --> 23:24.280
with our development team and wanted to get it out there in the hands of people very

23:24.280 --> 23:29.160
quickly and why we're focused on speed because speed, you know, this is one of the very

23:29.160 --> 23:33.200
few areas of computing today where people sit around waiting for days, you know, to develop

23:33.200 --> 23:34.200
the capability.

23:34.200 --> 23:35.200
It's really kind of crazy.

23:35.200 --> 23:41.000
So we want to like go from days down to hours and we want to, you know, get people there

23:41.000 --> 23:45.520
as quickly as possible through downloading, go and then also through use of some of these

23:45.520 --> 23:49.440
higher level abstractions like slim, okay.

23:49.440 --> 23:55.000
One of the, one of the critiques, I guess, of some deep learning work is that, you know,

23:55.000 --> 23:59.240
you hear it described as kind of overfitting on image net and you reference image net

23:59.240 --> 24:01.040
in your results as well.

24:01.040 --> 24:06.200
Do you, you know, what gives you confidence that these results will be generally applicable

24:06.200 --> 24:10.280
beyond, you know, a specific, you know, data set and problem?

24:10.280 --> 24:11.280
Yeah.

24:11.280 --> 24:12.280
That's it.

24:12.280 --> 24:16.360
It's a, it's a great thing to talk about because it gets to why we are so passionate about

24:16.360 --> 24:21.880
the key thing here being that we were showing the capabilities, what you can do with the

24:21.880 --> 24:25.800
framework, you know, only that that's the only thing that it does, right?

24:25.800 --> 24:30.800
So, so as you start to look at other classes of neural networks, the kind of computation

24:30.800 --> 24:36.840
to communication balance changes and some classes in neural networks are known not to scale

24:36.840 --> 24:41.880
very far today, not, you know, known, you know, kind of they won't run it to 256 GPUs,

24:41.880 --> 24:44.600
they run it maybe a small number of GPUs.

24:44.600 --> 24:51.920
So what we see though is that if you're using the type of really close to optimal communication

24:51.920 --> 24:57.840
methods that we have that no matter what the kind of inherent capability of that neural

24:57.840 --> 25:02.160
network to scale is going to be, we're going to guarantee that you get, you know, out

25:02.160 --> 25:04.960
to as much scale as is possible.

25:04.960 --> 25:09.080
So if you're using a suboptimal communication method, you know, maybe you can only get

25:09.080 --> 25:14.040
to 8 or 10 GPUs for other classes of neural networks, we're going to push that number

25:14.040 --> 25:19.200
up by getting the communication latency to be as absolutely short as possible.

25:19.200 --> 25:24.200
So you know, in our view, this is really about, you know, whatever the current state is

25:24.200 --> 25:28.800
of a neural network and the scientific understanding of it and the ability to scale, we're going

25:28.800 --> 25:32.440
to push that out and get that training done, done faster.

25:32.440 --> 25:33.440
Awesome.

25:33.440 --> 25:34.440
Awesome.

25:34.440 --> 25:37.280
What other things are you working on in your group?

25:37.280 --> 25:38.280
Yeah.

25:38.280 --> 25:43.760
So, you know, I mentioned the large model support, which is something that, again, like I said,

25:43.760 --> 25:49.400
comes from the same perspective of wanting to use the available system resource and not

25:49.400 --> 25:55.880
just sort of, you know, offloading work to a GPU and being constrained by what that provides.

25:55.880 --> 26:00.800
So we want to go multi-GPU, we want to go multi-system, we also want to be able to leverage

26:00.800 --> 26:04.760
all of the capability of a system, the full system's memory capacity.

26:04.760 --> 26:09.760
You know, we are, in general, along those lines also looking at acceleration in the machine

26:09.760 --> 26:14.960
learning space, and we have some work that we've, you know, published and shown some really

26:14.960 --> 26:19.880
great results on algorithms that are a bit more chatty between the GPU and the CPU and

26:19.880 --> 26:25.640
how they leverage that NV link capability, that fat bandwidth pipe of communication between

26:25.640 --> 26:31.080
the CPU and GPU and how they kind of get in and out of memory and, you know, use the larger

26:31.080 --> 26:32.920
capability of the CPU memory.

26:32.920 --> 26:36.920
And so those are a couple of different examples, but we're really trying to kind of use the

26:36.920 --> 26:42.400
system to the max of its capability and tackle problems faster and enable people to explore

26:42.400 --> 26:44.920
problems that are larger.

26:44.920 --> 26:50.320
What's an example or some examples of, you know, particularly chatty machine learning

26:50.320 --> 26:51.640
tasks or libraries?

26:51.640 --> 26:58.120
Yeah, so in general, things like nearest neighbor computations, word-to-back technology

26:58.120 --> 27:03.560
or glove, things that are used in semantic analysis, those are a couple of different types

27:03.560 --> 27:09.280
of, you know, non-very deep neural network kind of things.

27:09.280 --> 27:16.200
And the chattyness relates to, in those network architecture is kind of the way that state

27:16.200 --> 27:18.080
needs to be shuffled around.

27:18.080 --> 27:23.880
Yeah, so it relates to how state needs to be shuffled around, but it also relates to

27:23.880 --> 27:28.560
how quickly the compute happens and, you know, how quickly the GPU needs to be supplied

27:28.560 --> 27:30.960
with more data, for example.

27:30.960 --> 27:33.600
So that's another big component in it.

27:33.600 --> 27:40.360
The faster the compute on the GPU happens, the more likely it is that you need to, you

27:40.360 --> 27:45.640
know, be feeding it data more quickly and getting that data fed to it more quickly can help

27:45.640 --> 27:50.640
it just kind of be brick-walled in its execution time and not sitting around waiting for, you

27:50.640 --> 27:53.280
know, the next data to get to it.

27:53.280 --> 28:00.440
And sort of actually profiling the execution of your, you know, your training jobs.

28:00.440 --> 28:05.120
How do you, you know, how do you develop an intuition for what's going to be chatty?

28:05.120 --> 28:09.880
Like, it's, it doesn't sound like it's just the depth of the network and the deep

28:09.880 --> 28:16.040
it is the, you know, the harder it is or is it, you know, or there are there, you know,

28:16.040 --> 28:17.040
is it, you know, is it with?

28:17.040 --> 28:18.040
Is it something else?

28:18.040 --> 28:20.520
Is it kind of, you know, memory features?

28:20.520 --> 28:25.600
Is it, are there things that, you know, you can look for it to get a sense for the kind

28:25.600 --> 28:28.520
of the chattyness of your network architecture?

28:28.520 --> 28:33.520
We like to talk about kind of the algebra of how deep learning happens or the pipeline

28:33.520 --> 28:34.920
stages.

28:34.920 --> 28:40.880
And we look at, you know, how much data is needed in order to start a computation on the

28:40.880 --> 28:41.880
GPU?

28:41.880 --> 28:47.320
How long does it take to move that data from, you know, the storage and then into the

28:47.320 --> 28:48.800
GPU?

28:48.800 --> 28:53.640
And then how long does the GPU take to communicate, sorry, to compute?

28:53.640 --> 28:55.360
How long does the GPU take to compute?

28:55.360 --> 28:59.200
And then how long does it take to communicate results, either back to the CPU or back to

28:59.200 --> 29:00.800
other GPUs?

29:00.800 --> 29:03.640
So those are kind of the canonical pieces.

29:03.640 --> 29:07.960
And so we look at, you know, how much compute is there and how long will that take?

29:07.960 --> 29:10.680
And then we look at how much data has to be moved.

29:10.680 --> 29:15.520
And we look at those as clear, you know, kind of pipeline stages or phases of the overall

29:15.520 --> 29:16.960
work you're trying to get done.

29:16.960 --> 29:24.880
But it sounds like those are, again, kind of empirical observations of a training task

29:24.880 --> 29:30.400
as opposed to, you know, being able to look at a picture of a network and tell by some

29:30.400 --> 29:35.920
characteristic of the network that, oh, this is probably going to be, you know, chatty

29:35.920 --> 29:38.280
and this kind of technology will apply well.

29:38.280 --> 29:40.080
Yeah, I mean, it's a good question.

29:40.080 --> 29:46.160
I mean, I think that we do have the ability to estimate pretty well based on the characteristics

29:46.160 --> 29:48.240
of the neural network and its data extents.

29:48.240 --> 29:53.800
I think it's, you know, it's definitely a mix of observation and the empirical characteristics.

29:53.800 --> 29:56.480
But, you know, in general, from from looking at the neural network, you should be able

29:56.480 --> 30:01.160
to figure out the, you know, volume of data, for example, that that needs to be moved

30:01.160 --> 30:06.080
to do weight updates, you know, how many nodes are in it and all that other kind of stuff.

30:06.080 --> 30:10.600
And there is, you know, some, you know, you have to figure out what the mini batch sizes

30:10.600 --> 30:12.600
are that are appropriate for that.

30:12.600 --> 30:17.240
So it's probably, I guess the, it's probably a mix of some things that can be determined,

30:17.240 --> 30:20.680
but then other things that you have to know what the training characteristics of that

30:20.680 --> 30:24.640
are and some of that is still somewhat experimental today.

30:24.640 --> 30:25.640
Okay.

30:25.640 --> 30:32.840
So what are you, you know, when you think about the, you know, this kind of work and all

30:32.840 --> 30:36.320
of the, you know, you're working on it, there are other folks working on it.

30:36.320 --> 30:43.400
Like, what do you see is the impact overall, you know, of it and, you know, what, you

30:43.400 --> 30:44.960
know, what's the, what's the time frame?

30:44.960 --> 30:50.120
Do you have a kind of a crystal ball vision around, you know, how this, you know, impacts

30:50.120 --> 30:53.160
the way folks develop deep learning models?

30:53.160 --> 30:59.480
Yeah, you know, it's, it's interesting because I think that there's been a lot of, you

30:59.480 --> 31:04.840
know, concern, as you mentioned, that, you know, folks are overfitting image net.

31:04.840 --> 31:09.280
And the question really is the rate and pace that deep learning will take off on other

31:09.280 --> 31:10.280
types of data.

31:10.280 --> 31:15.400
I mean, it's been proven as highly successful for image and speech, but we're seeing so

31:15.400 --> 31:17.280
many other use cases happen.

31:17.280 --> 31:21.960
You know, we're seeing use cases across, you know, risk and fraud and predictions and

31:21.960 --> 31:27.720
forecasting and lots of different areas that, you know, to some extent, the same thing is

31:27.720 --> 31:31.920
happening where there are classical machine learning techniques that are being subsumed

31:31.920 --> 31:36.160
by the capabilities and sort of the ease of use of deep learning.

31:36.160 --> 31:42.640
And the thing that excites me in this, in this capability conversation around DDL is

31:42.640 --> 31:49.160
the thought that with this type of speed up that we will see those fields and those use

31:49.160 --> 31:54.960
cases develop much more quickly because with a more productive system and a more productive

31:54.960 --> 32:00.360
hardware and software solution, people will be able to discover and explore their data

32:00.360 --> 32:04.000
and define the right models for those data sets more quickly, right?

32:04.000 --> 32:09.080
So if, if, you know, if you are able to get through more of your data more quickly and

32:09.080 --> 32:14.520
you are able to turn through more models and get to higher accuracy on these new types

32:14.520 --> 32:18.920
of outcomes that you're looking for around like I said, you know, risk and fraud and predictions

32:18.920 --> 32:23.600
and forecasting and those things, then those fields will develop and mature and those use

32:23.600 --> 32:26.920
cases will develop mature that much more quickly, right?

32:26.920 --> 32:33.280
And so, you know, this as an inflection point and kind of the rate and pace of enterprises

32:33.280 --> 32:38.520
ultimately, you know, to apply deep learning and increase their confidence in it and increase

32:38.520 --> 32:43.080
the accuracy and things that aren't just images and speech is ultimately what we're really

32:43.080 --> 32:44.080
excited about.

32:44.080 --> 32:47.800
And again, that, you know, that goes back to why we wanted to get it out into the hands

32:47.800 --> 32:53.080
of customers because as a productivity enabler, and we hope that it will change that rate

32:53.080 --> 32:58.040
and pace of, you know, adoption of these techniques and a productivity of data scientists

32:58.040 --> 33:00.600
teams working on their own data sets.

33:00.600 --> 33:07.240
Yeah, I think that's a really important point and one that I hear a lot in terms of,

33:07.240 --> 33:12.440
you know, deep learning becoming deeply, you know, pun intended, I guess associated with

33:12.440 --> 33:18.880
kind of image types of data, but there being these much broader applications and implications,

33:18.880 --> 33:25.120
are there any particular use cases that, you know, you think of as, you know, kind of

33:25.120 --> 33:28.080
the next big killer app for deep learning?

33:28.080 --> 33:32.920
You know, I think it's hard to necessarily forecast the next big killer app.

33:32.920 --> 33:38.080
I mean, I would say that, you know, we're seeing more than you might imagine use cases across

33:38.080 --> 33:43.640
enterprise environments of even speech and image because people want to be able to interact

33:43.640 --> 33:46.240
more, interact with us in a more natural way and such.

33:46.240 --> 33:51.480
So I would say that, you know, kind of two things, one, the speech and image, I think, is

33:51.480 --> 33:56.520
taking off and in other industries that have other data types, but that want to use more

33:56.520 --> 33:59.400
natural interaction capabilities and such.

33:59.400 --> 34:04.360
And so that's one thing that, you know, is great to see is the little bit more creative

34:04.360 --> 34:09.880
use, you know, in other contexts, especially as relates to, you know, interacting with

34:09.880 --> 34:10.880
people.

34:10.880 --> 34:15.360
The, you know, beyond just, you know, talking to your mobile phone, for example, right?

34:15.360 --> 34:17.040
So that's one thing.

34:17.040 --> 34:20.480
And then I think, you know, there's a lot of discovery and exploration right now.

34:20.480 --> 34:23.960
I think it's really hard to make a call is to, you know, what the next killer app and

34:23.960 --> 34:25.200
what the next data set is.

34:25.200 --> 34:30.640
But I think we are seeing a good degree of productivity on a lot of different types of data.

34:30.640 --> 34:34.560
And, you know, they're very interesting things happening as well in, you know, automation

34:34.560 --> 34:35.560
techniques.

34:35.560 --> 34:39.400
We have a, we have a tool set that helps to label data and other things like that.

34:39.400 --> 34:44.400
So as, as more folks adopt those techniques, you know, they'll be able to kind of get access

34:44.400 --> 34:47.120
to use of deep learning on more data sets.

34:47.120 --> 34:52.400
So as we use automation and, and tool sets like we have an AI vision to enable more quick

34:52.400 --> 34:57.760
labeling of data, then, you know, that really should also, you know, help accelerate the

34:57.760 --> 35:00.760
rate at which people enter into these new spaces.

35:00.760 --> 35:01.760
Hmm.

35:01.760 --> 35:04.840
The tool set you mentioned that helps with data annotation.

35:04.840 --> 35:06.480
Is that open source?

35:06.480 --> 35:11.160
It's not open source, but it's also available through the Power AI frameworks and folks can

35:11.160 --> 35:14.200
try it on the Nibbix cloud.

35:14.200 --> 35:17.480
They have the Power AI stuff available there.

35:17.480 --> 35:19.760
So yeah, that's, that's available for, for people to try.

35:19.760 --> 35:25.440
Yeah, it seems like that is also, you know, that clearly comes up constantly in these kind

35:25.440 --> 35:31.440
of conversations and, you know, when I think about the, you know, the full life cycle of,

35:31.440 --> 35:37.560
you know, these AI deep learning development projects, you know, there's certainly a lot

35:37.560 --> 35:43.320
of emphasis on the deep learning framework and the model development and training.

35:43.320 --> 35:48.520
But, you know, there's a much broader set of activities that has to take place and

35:48.520 --> 35:55.240
very, you know, we're just starting to see projects come on, you know, open source projects

35:55.240 --> 36:01.080
come online to provide, you know, a broader platform for handling all that.

36:01.080 --> 36:07.960
Like the data annotation is one big area, kind of model life cycle and versioning and,

36:07.960 --> 36:12.800
you know, production, performance management and tracking is another, you know, whole set

36:12.800 --> 36:19.080
of areas, you know, any thoughts on how all this stuff evolves?

36:19.080 --> 36:26.080
Yeah, I think that the, this is about maturity of the field of deep learning and it's about,

36:26.080 --> 36:30.920
you know, people moving past just fully labeled public data sets that they, you know, get

36:30.920 --> 36:32.320
online, right?

36:32.320 --> 36:39.640
And so I think, you know, the overall topic of management, of management of, you know,

36:39.640 --> 36:44.760
what models are being done when we're in how overall life cycle, integration with various

36:44.760 --> 36:50.600
data sources, all those kind of things are what we see as being necessary from an enterprise

36:50.600 --> 36:56.600
environment perspective because people will be, you know, wanting to improve the AI specific

36:56.600 --> 37:00.040
to their use cases and specific to their, to their data.

37:00.040 --> 37:05.200
So we have a good number of IBM tool sets out there today, again, folks can try them.

37:05.200 --> 37:10.080
But the data science experience is a really nice Jupyter Notebooks based environment that

37:10.080 --> 37:12.640
has a lot of the features we just discussed.

37:12.640 --> 37:17.080
You know, we also have other tool sets that are available that help with, you know, data

37:17.080 --> 37:21.720
integration from various sources through our spectrum family, for example.

37:21.720 --> 37:26.560
And then in, you know, within Power AI, you know, we have that integrated as well with,

37:26.560 --> 37:30.920
with the data science experience, the DSX that I just mentioned, and we have additional

37:30.920 --> 37:37.080
capabilities that include the, you know, sort of clicker data scientist type capabilities,

37:37.080 --> 37:40.520
including you're on data labeling and choosing your models and, you know, starting with some

37:40.520 --> 37:42.600
default models, other things like that.

37:42.600 --> 37:48.120
So we see these things, you know, that you mentioned as, you know, absolutely essential

37:48.120 --> 37:53.800
to do, you know, kind of more mature deep learning, which is, you know, going beyond,

37:53.800 --> 37:57.920
you know, just the, you know, the fully-lated label data sets that we have in the public

37:57.920 --> 37:58.920
domain.

37:58.920 --> 38:06.640
Right. And certainly enterprises need to, you know, need to get there in terms of maturity,

38:06.640 --> 38:09.880
you know, perhaps to kind of wrap things up.

38:09.880 --> 38:15.360
Any words for enterprises that are earlier on in the cycle and just getting started?

38:15.360 --> 38:22.680
Yeah, I think that one of the things that I always like to try to clarify in these discussions

38:22.680 --> 38:29.160
is that, you know, our intention in showing distributed deep learning capabilities at

38:29.160 --> 38:34.120
256GPUs was to show the capability of what you can get if you do hardware and software

38:34.120 --> 38:38.800
optimization, to show the flexibility across frameworks of what we have created, et cetera,

38:38.800 --> 38:40.880
and put it in people's hands.

38:40.880 --> 38:46.760
But everything that we did was done with kind of that enterprise consumer in mind, knowing

38:46.760 --> 38:53.080
that many, you know, may also be early in their journey. And so the, the DDL environment

38:53.080 --> 38:57.880
supports any number of notes, any number of systems that someone would like to use it

38:57.880 --> 39:02.200
on. It supports different types of networks. You don't have to use what we published our

39:02.200 --> 39:07.000
results on. And so, you know, what we really want to do is to kind of start with where people

39:07.000 --> 39:11.080
are at, start with the data volume that they have, start with the, you know, neural network

39:11.080 --> 39:15.680
capabilities that they have, and provide that ability to grow over time, you know, as they

39:15.680 --> 39:19.800
hit that stride of productivity of really figuring out how they want to do their deep learning

39:19.800 --> 39:24.480
and they want to apply it to the rest of their data sets, as they discover new areas within

39:24.480 --> 39:28.160
their enterprise that they want to apply deep learning and replace classical techniques.

39:28.160 --> 39:33.000
Perhaps they can grow out, they can scale out their deep learning environment, add more

39:33.000 --> 39:38.280
systems to it, and still get that, you know, kind of productivity. So I think, you know,

39:38.280 --> 39:41.800
that's, that's always kind of important to point out because it's not just the taking

39:41.800 --> 39:46.120
the really long day-as-long jobs down to hours for use of a huge system. It's that no

39:46.120 --> 39:50.760
matter what the system size is, you know, no matter what the data set size is, we want

39:50.760 --> 39:55.160
to try to meet people where they're at and provide, you know, this flexibility and elasticity

39:55.160 --> 40:00.920
and capability. Great, great. Well, hello, thank you so much. I really appreciate you taking

40:00.920 --> 40:06.520
the time to chat with us. I learned a ton about what you're doing with DDL and I'm looking

40:06.520 --> 40:12.440
forward to following the effort. It was a pleasure talking to you. Thanks so much for the opportunity.

40:14.280 --> 40:20.840
Alright, everyone, that's our show for today. Thanks so much for listening and for your continued

40:20.840 --> 40:26.920
feedback and support. For more information on Hillary or any of the topics covered in this

40:26.920 --> 40:35.240
episode, head on over to twomlai.com slash talk slash 77. To follow along with this AI Summit

40:35.240 --> 40:41.960
series, visit twomlai.com slash AI Summit. Of course, you're encouraged to send along your

40:41.960 --> 40:48.040
feedback or questions to us by leaving a comment right on the show notes page or via Twitter

40:48.040 --> 40:55.560
to at twomlai or at Sam Charrington. Thanks again to IBM Power for their support of this series.

40:55.560 --> 41:02.760
For more about the IBM Power Systems platform for Enterprise AI, visit twomlai.com slash IBM Power.

41:02.760 --> 41:12.760
Thanks once again for listening and catch you next time.

