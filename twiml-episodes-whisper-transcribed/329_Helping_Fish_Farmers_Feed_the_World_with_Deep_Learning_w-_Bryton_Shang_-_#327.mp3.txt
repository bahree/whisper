Welcome to the Tumel AI Podcast.
I'm your host Sam Charrington.
Hey, what's up everyone?
I recently attended the AWS Reinvent Conference in Las Vegas, and I'm excited to share
a few of my many interesting conversations from that event here on the podcast this week.
Before we dive in, I'd like to thank our friends at Capital One for sponsoring our Reinvent
series.
Capital One has been a huge friend and supporter of this podcast for some time now, and
I'm looking forward to sharing my interview with Dave Castillo, Capital One's managing
VP of Machine Learning with you on Thursday.
Dave and I discussed the unique approach being taken at the company's Center for Machine
Learning, as well as some of the interesting AI use cases being developed at the bank,
and the platform they're building to support their ML and AI efforts.
Once again, check back in on Thursday, December 19th for that conversation.
To learn more about Capital One's Machine Learning and AI efforts and research, visit capitalone.com
slash tech slash explore.
And now on to the show.
All right, everyone, I am on the line with Brighton Shang.
Brighton is the founder and CEO at AquaBite.
Brighton, welcome to the Twil AI podcast.
Yeah.
Thank you.
Great to be here.
Awesome.
So you just spoke at the Reinvent Machine Learning Summit earlier this week on a really
interesting topic, and one that we have not covered on the podcast before.
The application of deep learning to fish farming, essentially.
I'm really interested in diving into the topic, but how did you get started working in
this area?
Yeah, it's a bit of an unusual story.
So for context, the company AquaBite, we build software for fish farms.
And it's a camera-based software, so the camera goes in the fish pen.
It takes pictures of the fish.
And then using computer vision and machine learning algorithms, we process those images
to be able to determine things such as the weight of the fish, the health of the fish,
how hungry the fish is, and then ultimately the farming buys us as a subscription service.
And so it's this idea of bringing machine learning and computer vision, which is very
well-understood in other industries and bringing it to fish farming.
Now, the whole idea, I mean, so I grew up in Ithaca, New York, actually right by Cornell,
and one of our family friends was a professor of Occupial through there.
Then I ended up going to Princeton.
I studied operations research and financial engineering, which is basically like data science
and machine learning.
And then after that, pretty much since university, I've been starting various companies.
I started an algorithmic trading firm, also was a CTO of another company that was doing
deep learning for cancer detection, and then 2017, I started Occupial and the idea was
to bring the same machine learning and computer vision technologies to fish farming.
And for those who fish farming, maybe not as well known in the US, but actually is the
main way we get fish, like over half of the fish we consume is farmed.
It's not grown in the ocean.
And so the idea of being these fish, imagine they grow in these massive pens, we don't
really know how they grow.
We don't know how much to feed them.
We don't know a lot of things, and so be able to bring basic insight to the farmers using
computer vision machine learning is really like a game changer for them.
And I can share more about the progression of the company and how we progress.
But now we're selling to these salmon farmers in Norway that are using it to count sea
lice, estimate the weight of their fish.
Most of our engineering teams in San Francisco, but we actually start selling with the salmon
farms in Norway, because 99% of the industries that are national.
Well, how did you identify the opportunity?
Was it serendipity?
You met someone who was interested in or working in aquaculture and you recognized the opportunity
through those conversations, or were you actively searching for places to apply ML and AI,
and you came across this particular opportunity?
Well, generally, I've been working in the space in different companies, and conceptually
I had an idea of, well, to be able to process images and to be able to use that to deliver
some insight, that paradigm, the idea for fish farming.
So I mentioned that I grew by Cornell, but also my old co-founder, one of his classmates
had owned a fish farm, and I had heard about it from him.
And then kind of one thing led to another.
I was reading papers on how they were using camera-sized fish and then ended up at the time
incubating this out of a venture capital firm.
So they had given me some money with the idea of me coming up with a new machine learning
powered startup, and this is one of the ideas I looked into, and then one thing led to
another and then built out a simple prototype and then raised some capital.
So it was a bit of serendipity, but it was also the experience of having worked in these
other industries and seeing the parallels between, I mean, even something as foreign
as like algorithmic trading, it's conceptually similar because you're processing data in
real time that's coming in, and instead of deciding whether to buy or sell stocks, you're
just deciding how much to feed your fish or what action to take.
And so conceptually, these mental models are applicable between different industries.
And so you mentioned talking a little bit more about the evolution of the company.
Where did you start once you identified the problem?
So I started by building a simple prototype.
Okay.
So I actually talked about this at the ML Summit, but I started literally in my apartment
bathtub, so I built a simple rig, filled the bathtub with water, got some robotic fish
off of Amazon.
I was going to say, did you load some salmon into your bathtub?
Yeah, exactly.
Yeah.
I don't know if it would fit, but yeah, certainly like these tiny robotic fish that would swim
around, and it works like the camera could actually determine the length of the robotic
fish, and the proportions of the fish correlate to the weight.
It's just something that biologists know, and so then kind of that the concept was proven,
and then the idea was, okay, now I need to go from my bathtub to the ocean, where it's
rough conditions, where it's limited connectivity, where it's not just these robotic fish, but
you have live fish with behavior, minds of their own, different environmental conditions,
and a lot of practical concerns, and that was really kind of 27, 2018 was building the
first prototypes for the ocean, getting a camera there, actually finding the fish farmers,
so I don't know how many folks in the U.S. know fish farmers, but like again 99% outside
the U.S., and so imagine me and Silicon Valley, but going to Norway to talk to these fish
farmers, find them, convince them that this is like the next idea, and then start working
with them, and so actually ended up living in Norway for a number of months, and certainly
traveling back and forth since then.
Wow, wow.
Yeah, I've seen some fish farms in Asia, and what I remember of them, particularly when
the fish are being fed, and this may be the anomaly, but it was just chaos, it wasn't
like a few robotic fish in a bathtub, the density per square meter of fish or of ocean was
very, very high, it strikes me as a very challenging environment to do computer vision.
I think it is quite challenging.
I think it also depends on what type of fish are going in which environment to take an
example in Norway by law, they cannot have more than two and a half percent of their pen
be fish.
Oh, wow.
Okay.
So actually it's like, it is quite a lot of fish, but it's not super packed, and so it's
not like your fish are blocking your camera, but it is a very chaotic environment.
Going back to the bathtub, you found some success in kind of estimating the weight
of your robotic fish, maybe talk a little bit more about the kind of the process or the
challenges there, for example, even measuring the length of a fish without knowing its distance
from the camera, if you're just using the camera, like how do you overcome those kinds
of issues?
Right.
Right.
So if you look at our website, we have a picture of the camera.
It's a stereo camera, so with stereo, kind of two parallel lenses, we can send depth
using the disparity in the two images.
Oh, okay.
Now, it's a fairly straightforward geometric calculation to figure out.
Kind of if I see the pixel on one image and the pixel on the other image, I can calculate
the disparity and then use that to get the depth and then the three position and therefore
calculate the length and so on and so forth.
Now, conceptually, this makes, it's fairly straightforward.
Now, in practice, you're dealing with a number of challenges, I'll just highlight a couple
for one, optics are slightly different in water.
Water you're dealing with light scattering, turbidity, essentially particles in the water
that your photons, by the time they're hitting your lens, they're a bit distorted or they
got to, they bounce off of different particles and so to be able to get a very precise estimate
is more difficult underwater.
Also fish are shiny, they're reflective, they're very specular and so to be able to get
good detail of that specific scale on one image versus another image and get the distance,
it's actually quite challenging versus something that's more textured or that you can actually
discern a lot of detail.
These fish underwater, I mean the scales look the same, so it's a bit more challenging.
Also for those who've worked with camera-based systems, you need to calibrate them and
the calibration can be a bit sensitive and so there's a number of steps and practical
challenges that you need to work with from resolution to turbidity to calibration to
specularity, the object to lighting and a lot of this was us actually going out to the
field, dropping a camera in the water, doing a lot of experimentation because a lot of
this stuff you can calculate at a theoretical level but until you put the camera in the
water and actually image the fish, you don't know if it's going to work or not and then
compound that with this being at actual fish farm which is in the middle of the ocean,
limited connectivity, literally like you got to take a boat to get out there and so it's
not as easy as taking your autonomous vehicle and driving it around town to get data.
You need to really go through a lot of practical challenges, get on a boat, go to Norway to
actually do this type of research but once you do it then we get the data, we're able
to analyze it and actually deductively come to the best system.
As far as we've talked about deterministic approaches, geometry and optics and things
like that, where do machine learning and deep learning come into play?
It's in the perception so for example, let's just take the example of we want to figure
out the weight of a single fish.
We know from the biologist that if I get the length then I can calculate the weight
because like humans, the fish grow in proportions and so you can get that.
Now the actual detection of these points on the fish, you can imagine if we're doing this
for thousands and thousands of fish a day, we're not going to just want people to identify
the points.
This is where the computer vision comes in where we have algorithms that can automatically
detect key points on the fish and be able to then use that as inputs into the geometry
to get the lengths and the fish weight and that those are essentially deep learning, convolutional
neural net based algorithms that can do detection of different key points and be able to do
other things.
Something we'll talk a bit about later is we determine the health of the fish, it's not
just the weight, it's also the health of the fish, particles in the water, food.
I don't want to spoil too much of the other applications we'll talk about them later but
you can use computer vision as a lot of the perception input to these downstream algorithms
and we are using some supervised algorithms to be able to do things such as determine
the fish weight.
Before we leave the weight, one aspect of this that strikes me as a bit counterintuitive
when I think of a human's length or height and their weight, there's certainly a correlation
but I would think of our height as more correlated to age and our weight can kind of vary around
some midpoint pretty dramatically but that our height obviously doesn't change accordingly.
We don't grow a few inches after Thanksgiving and then take those few inches off, vertical
inches at least.
But what I'm here for you is that you're inferring the weight largely on the length of the
fish.
So to your point, we are detecting a number of different points on the fish so it's not
just the length, it's the width, it's like the eye to the fin to all these different points
on the fish that then end up forming a 3D model of the fish to get the weight.
Got it.
You talked a little bit about the relative density of the fish in the farm.
Are you using your perception models to try to create bounding boxes around multiple
fish in an image or are you throwing out images that have multiple fish?
Most of your images have single fish and how resilient are your models to the orientation
of the fish?
Are you trying to catch the fish at just the right moment?
I would say all of the above.
So if you look at one of the underwater fish image pictures, so I have one in the presentation
I was showing each one of these images has like 50 to 100 fish.
Okay.
So there's like a massive amount of fish and as you pointed out, the fish is in every
which direction.
I mean, the fish generally, they school together.
So if you put it parallel to the school of fish, you can get a nice side view.
But there are some fish that are like facing the camera away from the camera or not in
the right orientation or there's too much light or they're too dark or whatever the water
is too blurry and so the fish is too blurry.
And so there needs to be some type of process by which we can filter the images and make
sure we're getting the best fish to be analyzed.
And that's really more an art than a science where that's where you're tweaking your
hyperparameters to figure out what's the best trade-off between essentially precision
and recall of a fish detector, a clear of a clear fish.
And so whether you want more or less fish and then if you want more fish, then it's
less, the more the fish are less clear.
But then you kind of figure out what's the optimal trade-off to get you the best result.
Then is the idea that if you're capturing kind of the, again, kind of sticking to weight
and maybe this extends to health and some of the other things you're measuring.
But is the idea that you are essentially computing some kind of average weight of all the
fish or is it more trying to identify individual fish and track individual fishes weight or anything
like that?
Yes, so that's actually one of the more cool applications we're working on is fish facial
recognition.
As it turns out, the spots on the fish's face are unique.
And so you can use it like a fingerprint to be able to uniquely identify that fish.
So you can imagine what one of the questions you might ask, okay, how do you know if I
saw the same fish twice, like how do I know if it's swam by the camera twice?
So you can know from this individual fish recognition.
And so we are using that to track individual fish over time and then there's some other
interesting implications where you can use it, for example, in breeding to be able to find
the best male, the best female fish and breathe them together and to be able to do a lot
more detailed analyses if you can know not just at a population level but also at an individual
level how they're growing.
And so we are working along on a lot of these other applications that are improving our
weight estimation model, for example.
Okay, that's awesome.
Yeah, one of our most popular shows from last year was with Jason Holmberg who is the
head of engineering or was at the time at Wildme, which was applying kind of similar types
of approaches to identifying, uniquely identifying humpback whales.
And he's the same kind of fingerprint analogy based on their patterns and markings.
Wow, that's pretty cool.
Yeah, I know that there are, I mean, even WACV 2020, they're holding a specific section
on animal re-identification.
So I know there's, even like specific conferences that are focusing on this.
And so you are, you know, maybe back to kind of the fundamental use case, you describe
this.
I forget what you said, 6,000, I forget if that was like images per day or fish per day
or something like that.
But the picture that you've created for me is that you've got this online real time
application that's constantly taking pictures of fish and, you know, identifying their weight
and health and hunger levels, things like that.
And what I guess one of my fundamental questions is like, do we need to know the real time
health of the fish like with, where does it, you know, I imagine that before that someone
would like to take a boat out to the pen, you know, once a week and sample a few fish
and kind of get a sense for how they were doing, you know, where does that fall short?
Well, so to give you a sense, let's, let's take a typical salmon pen in Norway.
It's about half a football field in Damien or you could submerge an entire 737 in the
pen.
These are like massive pens.
The single pen has anywhere from 100,000 to 200,000 fish.
Okay.
So you're not going to get a representative sample if you just take a sample of even 100
fish, you need to get some representative part of the population.
Now combine that with the other fact that these fish, they're growing one to two percent
every day, just be like of their own body weight at the eats.
Okay.
So they're going pretty quickly.
And so you want to be able to sample enough every day such that you get an accurate weight
and also see a represented enough population.
Okay.
So, I mean, for, and the other thing is for us, again, because these farms were in the
middle of the ocean, it's not like we're sending these images back to the cloud to get
processed.
It's just like too much data.
And so the trade off of processing more images is just computing power and because it
is local at the farm, the computing happens for free.
So we're, we would like to process as many fish as we can.
I'm interested in exploring that the form factor of your computing system a little bit.
Do you have like a floating data center that is doing a floating kind of inference engine?
It's all on camera.
So if you look at our camera, it has the lenses, the camera sensor, there's also a computer
onboard microprocessor that's processing the images on inside the camera and underwater
camera.
So we're doing all of that compute there and then it attaches to whatever switch or power
it has and then, and then they can see all the information coming off the camera.
Got it.
And for one of these typical pens, how many cameras are located there?
It's a single camera that navigates around the pen.
Okay.
And navigates like around the edges or like some kind of autonomous thing or a Roomba fish
counter camera.
So it could be typically, so the cameras and fish pens are not new things.
They actually already have them for monitoring feeding of the fish.
So they typically have cameras on winches.
So they're essentially on rope and police systems that they, they move throughout the pen.
Okay.
So it is moving.
And then how you want to sample that is, is a more complicated question, but could
be autonomous if the farmer wants that.
But a lot of times the farmer doesn't want like autonomous moving thing.
They want to be able to like, because it becomes a liability if it can like move in and
hit things or whatever.
So you mentioned some of the other use cases beyond the weight.
One of them being counting sea lice.
What's that one about?
So sea lice is this parasite, it's a naturally occurring parasite that attaches to the fish.
It weakens in the immune system and eventually kills the fish.
In Norway, for example, it's about 25% of the costs of running the farm.
Now these farms, they need to count sea lice as a part of the legally running a farm.
Because essentially their version of the FDA nor requires them to sample sea lice every
week from all their pens.
So the typical process is fairly tedious.
So you've got to send someone out to the pen, they're netting some fish, then they
anesthetize each fish and then count the sea lice by hand and they have to do this week
over week over week.
Now the idea, we can make this process a lot simpler for farmers with the same camera footage,
be able to identify the sea lice on the fish and then be able to quantify this into a
system that then the farmers could use to manage sea lice infestations.
Now the cool thing is actually in Norway, we are the first company and I think so the
only company where you can apply to have our technology as a replacement for manual counting.
And this is saving the farmers a lot of effort in terms of being able to count the sea lice
and get accurate counts.
You mentioned that 25% of the cost of running the farm is dealing with this sea lice issue.
Is that 25% does that come from the cost of doing the sampling and all that or is that
25% of your fish die will cause of sea lice?
Oh, well, it's a combination of mortality.
So the fish die from the sea lice but also from the treatments to the fish.
They treat the fish for sea lice and it's a very stressful process.
Essentially, it's like a large washing machine that the fish need to go into to get rid
of the sea lice.
So this is a very stressful process, kills the fish.
So the fish, when they're disease, well, they're just like weaker and they eat less and
they're more susceptible.
So it's a really challenging problem and it's mandated by law because if the infestations
get too high, then they start to infect the wild fish and that's that that cannot happen.
And so they need to keep the sea lice levels low and if the infestations increase, then
they need to treat it, which is stressful, kills more fish and the treatments themselves
are quite expensive.
So overall, it's a very, very challenging thing to manage and especially because they
don't actually know the true state of the infestation.
So what the farmers are doing is because they have the more accurate numbers, they can
then forecast infestation levels and then figure out the optimal time to treat the fish
and ultimately reduce the number of treatments and improve the overall welfare of the fish.
And are those models that you're developing and providing for the farmers or the farmers
already have ways to project the intensity of infestations?
They have rudimentary models but we're providing a lot more sophisticated models to them to
be able to forecast the infestation patterns.
Cool.
Going back to the computer vision elements of this, how would you describe the general
approach or models that you're using?
And I'm curious about things like to what degree are you able to take off the shelf computer
vision models, trained on things like image net for example and apply transfer learning
or are you basically starting from scratch with known models or are you kind of inventing
your own things like how complex are the models that you're fielding to solve these problems?
We were able to transfer learn as you mentioned a pre-trained model and train it specifically
to identify fish.
And then you kind of want to go, so previous in the show you had mentioned, well, kind of
what if the fish is in the wrong orientation or if it's super area, it's too dark and
you want to start tuning your model to those nuances.
And that's where when we detect the fish, if the detector has a low confidence, we can
annotate those examples with low confidence to be able to improve the model.
And so we have done annotation to be able to improve the model and the transfer learning
techniques have worked well for us to be able to, for example, fish detection.
Now that's a relatively simple model.
Now let's talk about more complicated models.
So for example, let's just say I want to detect the different points on a fish.
And so first thing you might try is to be able to do a segmentation of the fish.
So like you get an outline of the fish and then figure out a depth mapping of the fish
so every single point what is the distance and then overlay that to get a 3D model.
Now that works, but then you run into like more complicated problem in terms of fish orientation
and you're only maybe seeing like half of the fish and then maybe it's hard to explain,
but sometimes the fish is not clear and you're not getting a good mapping.
And so it's then starting to do some filtering and and tuning of the model to make sure that
it can work in all these different edge cases.
I think another thing that has been an inspiration is let's just say that you want to look at different
poses of the fish.
So maybe the fish is straight, maybe it's curved and you can use those like pose estimation
techniques to be able to determine the orientation of your fish and consequently use that to inform
which type of fish you're accepting and what type of weight model to use.
So it can get like fairly fairly complicated.
I think the computer vision honestly is maybe like 5 to 10% of it.
Like 90 to 95% of it is the type of data you're collecting.
And so we made a massive investment in terms of establishing over half our team in Norway.
And that's because you can't have a team of computer vision engineers, machine learning
engineers in San Francisco just getting a clean data set like to train the model.
A lot of it is like practically going at the farms, collecting the data, getting the
right type of data and getting it annotated and that is just like the devils in the details
about like actually getting and actually physically going out and do the work.
And that is like 90, 95% of it.
Once the data is in a good state, then it's relatively straight forward to train your
model.
And what's been your approach to annotation?
Do you do that in-house or do you do something like a mechanical Turk or something in between
where it's a little bit more curated to your particular use case?
So it depends.
Some of the annotations we do are more general.
So identify the fish, that's not that specialized.
Now when you're identifying a sea-lice and I want you to differentiate it into the eight
different stages of sea-lice, which are millimeters in size, well that requires some special marine
biology background.
And so we work with marine biology, marine biologists in Norway to help us identify the sea
ice, but for the simpler stuff like fish, we're able to outsource those annotations to services
as he mentions.
So you describe the key challenges being the type of data that you're able to produce.
What's the nuance around type, or if there is one, is it, it sounds like it's not just
the volume of data, there's the annotations, of course, and the quality of those annotations.
Are there other aspects, qualitative aspects of the data collection that have been important
to your ability to solve this problem?
Or am I reading too much into that?
I think, and it's like, it's all sorts of things that you wouldn't expect.
It's like, for example, there's a bunch of metadata that's quite interesting.
Like does the breed of the fish matter in terms of your weight model?
Like maybe different breeds have different morphologies, have different weights.
Does the type of environment and environmental conditions affect your model?
There's a bunch of different other types of metadata and confounding factors that could
affect your ultimate model.
And so being able to test it in a wide variety of conditions is also a key part of solving
the problem.
And I think that is really the secret sauce in all of this is that we just like spent
two years banging our heads against the wall in terms of trying out every single condition
and drilling down into even the most minute factors to understand all the different variables
that might affect the problem and investigating it because chances are, it's all, again,
all the above.
Yes, the breed affects the way the fish, the time of year affects the way of the fish,
because well, the time of year affects the runoff to the oceans and the runoff affects
the turbidity under water and the turbidity under water affects what size of the fish you
can see and therefore it affects the weight.
And it's things like that that you would have never imagined the cascading effects and
to be able to investigate all those effects to figure out and again, this is not going
to be figured out by a computer scientist, machine learning scientist in San Francisco.
This is talking to tons of actual fish farmers in Norway and fish biologists who actually
know this stuff and can say, oh, well, that's probably why the reason why the model is
not working.
And so that's the type of qualitative insight that's invaluable.
How readily would you expect or have you seen the models that you've developed for the
Norwegian fish farms to translate to a fish farm in Asia, for example?
I think, well, I would say like, within a species, it's fairly transferable because the
water's the water and the fish are fish.
So actually, we we have our model that estimates for salmon.
It actually just worked out of the box for trout.
Now when you start going to Asia, Asia, they're growing fish and ponds and the ponds are
well, they're muddy and you can't really see the fish that well.
And so they're maybe optics is not the best solution.
Maybe you want some type of acoustic device, but it's really more conditioned.
It's really more dependent on the type of fish and the condition it's grown in.
But if you're going just like from the same species, from one geography to the other,
I don't think there's as much difference.
Of the many different use cases that you've mentioned, you know, weight, health, hunger,
we talked about, you know, sea likes, these are all the ones that we talked about and you
suggested that there are others.
And I'm wondering, you know, before we close out, are there others that are worth mentioning
because they introduce different types of techniques or approaches that you've had to
work with?
Yes.
So the holy grail of fish farming is a fully autonomous fish farm.
I'll explain the reason why.
So right now, the way fish farms are run is that you need people to go there.
So that's why you look at most of the fish farms, they're along the coastline.
They're in places like Norway, in places like Chile, where they have long coastline.
Now just at a macro macro level, like the earth is 70% water, we only produce about 5%
of the world's protein from the oceans.
So there's a massive potential there, but it requires us to have fully autonomous fish
farms that can be in the deep ocean or that can be on land and that requires a lot more
automation.
Now, the weight estimation, for the first time the farmer can understand the growth of
the fish and use that to benchmark the feeding of the fish.
Now feeding is about half of the cost of running a farm.
If you can start to optimize the feeding, essentially by running lots of AB tests to be
able to optimize the feeding and create an optimal feeding policy, that is the real holy
grail of fish farming.
Now the way you do that, there's biological models you can use for feeding.
You can also think of other machine learning based model, for example, reinforcement based
learning model, where you learn the policy that is the best for optimally feeding the
fish.
And I think that, for us, is like a really, really motivating factor and one of the really,
really cool applications that's coming down the pipe line.
Well, right.
And thanks so much for taking the time to share with us what you're up to.
Very cool stuff.
Yeah.
Thanks.
It is great to chat about it as well.
All right, everyone, that's our show for today.
To follow along with our reinvent series, visit twimmelai.com slash reinvent 2019.
Thanks once again to Capital One for their sponsorship of this series.
Be sure to check out capital one dot com slash tech slash explore to learn more about their
ML and AI research.
Thanks so much for listening and catch you next time.
