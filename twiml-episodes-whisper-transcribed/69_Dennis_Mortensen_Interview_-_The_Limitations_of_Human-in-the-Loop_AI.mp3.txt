Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting
people doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
Once again, let's start the show by sending some love out to you, the listeners for your
continued support over the last few weeks and months.
This community continues to amaze us, continues to grow and to engage with us, which we love
to see.
We've said it before, but please don't hesitate to reach out to us with any questions,
comments, guest or topic requests or just a friendly hello via any of our various channels.
You can reach us on our Facebook page or Twitter at Twimble AI.
You can reach me directly at Sam Charrington on Twitter or you can email us at teamattwimbleia.com.
Speaking of community, please take note, the next Twimble online meetup is coming up soon.
On Tuesday, November 14, at 3pm Pacific time, we'll be joined by Kevin T, who will be presenting
his paper active preference learning for personalized portfolio construction.
If you've already registered for the meetup, you should have received an invitation with
all the details.
If you still need to sign up, just head on over to twimbleia.com slash meetup to do so.
We hope to see you there.
Now, as you may know, a few weeks ago we spent some time in New York City hosted by our
friends at NYU Future Labs.
About six months ago, we covered their inaugural AI Summit, an event they hosted to showcase
the startups in their first batch of their AI Nexus Lab accelerator program, as well as
the impressive AI talent in the New York City ecosystem.
Well, this time we had the pleasure of interviewing the four startups from the second AI Nexus
Lab batch, Mount Cleverist, Bite AI, Second Mind, and Bowtie Labs.
We also interviewed some of the great speakers from the event, and we're presenting a couple
of those interviews to you this week.
If you missed any of the shows in the series, visit twimbleia.com slash AI Nexus Lab 2 to
get caught up.
My guess this time is Dennis Mortensen, founder and CEO of x.ai, a company whose AI-based
personal assistant Amy helps users with scheduling meetings.
I caught up with Dennis backstage at the Future Labs event a few weeks ago, right before
he went on stage to talk about investing in AI from the startup point of view.
Dennis shares some great insight into building an AI first company, not to mention his vision
for the future of scheduling, something no one actually enjoys doing, and his thoughts
on the future of human AI interaction.
This was a really fun interview, which I'm sure you'll enjoy.
A quick warning though, this might not be the show to listen to in the car with the kiddos,
as this episode does contain a few expletives.
And now on to the show.
Alright everyone, I'm here at the NYU Scurple Center, where the Future Labs group is having
their AI Summit, and I've got the pleasure of being backstage with Dennis Mortensen,
the founder and CEO of x.ai, Dennis, welcome to the podcast.
Thanks much for having me.
It's great to have you on the show.
Why don't we get started by having you tell us a little bit about your background and
what the company's up to?
Sure.
Background.
So that's the four hour version, right?
Exactly.
How do you find your way into AI?
So we've, sadly, because we are getting older, been at it for about twenty-three years.
This is our fifth venture, and they've all had really a backdrop in data, and I think
we've been able to massage data from the mid-90s all the way up to this point for
way.
If you really want to massage data in the year 2017, AI is probably the right moniker to
apply to that.
So in our prior venture, we did predictive analytics for media, trying to predict which
stories to carry where, say, on the home page of CNN, and for how long, and when you kill
it, what other story do we put in its place?
And before that, we did an enterprise web analytics company.
So go to four seasons, how do you make sure they sell as many rooms as possible, and you
try to analyze that data?
So certainly, just a lifetime around data, and we're very fond of that.
And you're saying, we, so this is a team of people that have kind of stuck together
across these five companies or so.
So we've certainly carried over team members from one venture to the next, and there's
suddenly some comfort in knowing that when I'm up here with you, the house is not at
fire at home, right?
Because, hey, I've talked to these guys for the last ten years, at least.
And for this particular venture of x.ai, it's not so much that we're an AI company.
I think we are, but it's more that we've latched on to this, I think, very obvious pain
of setting up meetings.
So it's not that we kind of invented that pain.
I think both you and I figured out exactly two hours out of college that if you go to work,
you set up meetings.
And when you set up meetings, you're not going to get a personal assistant.
It's you.
Are you?
You're going to fucking hate it.
And then you do it for 20 years straight.
And that just doesn't ring true to me, as in, do I do that task for the next 20 years?
So I think that was perhaps the catalyst to say, hey, there might be this opening for
where some intelligent agent can come along and just remove this one particular chore.
And we then spent the last four years trying to engineer that intelligent agent, a me at
x.ai.
So then when you email me saying, hey, Dennis, I'm downtown.
You've got time to meet up for a Diet Coke, I can reply back and say, yeah, I'm up for
that.
I have C.C.
didn't.
Amy.
And she can help put something on my calendar.
It is now her job to remove me from the conversation, reach out to you.
Have this very human-like negotiation, really, drive it towards conclusion and upon conclusion
send us an invite.
And it's not that you haven't seen it before.
You can buy it today if you want to.
It's just cost you $60,000 a year.
And it's called Tom.
You should have come to the office on Monday, but if you want to pay $17 instead, you should
hire you.
Yeah.
Nice.
Nice.
And you've been at it for four years.
Can people sign up for it publicly for a while?
It was like in by the only or something along those lines, right?
Very much so.
So we spent perhaps short of the first three years doing core R&D, but this is one of those
products for way.
If there's no pre-existing data set, you're going to have that chicken and egg challenge,
right?
I need the product out there to collect some data, but I can't have the product out there
because I don't have any data.
So we had this suddenly very early, early, early data that we ran with for years that became
more and more robust.
And the whole thing was based on a free wait list and we were so fortunate that people
immediately kind of recognized the pain and signed up for it.
We had a very long wait list and that's always nice.
But early this year, we commercialized that R&D and put it to market and now I've been
in market for short of three quarters and I just about to kind of tune our product tiers
and pricing just ever so slightly, but suddenly, off to the races, trying to pay back our
investors.
Nice.
Very nice.
You know, one of the dirty secrets, if you will, of AI is that at least people outside
of the industry think it's just the computer is doing the work.
I'm imagining there's a significant human and a loop component to what you're doing.
Can you tell me, you know, how much of a row, a row that plays?
Sure.
I think there's a difference between what you're trying to achieve and there's nothing wrong
with a human and loop and there's not even anything wrong with a human and loop forever.
That's called automation or augmenting the humans that they can do a job slightly faster,
slightly more accurate and so on and so forth.
I think you need to decide what you want to be.
Do I want to be a, if you're in the self-driving car space, a BMW with slightly better lane
control or do I want to be way more with a fully autonomous vehicle in place, perhaps,
in a decade from now?
But I don't think you can work on both at the same time though, because they're somewhat
in conflict and we set out to create the fully autonomous agent from day one or die-trying.
Investors fucking hate it when I say that out loud, that's in, there is no plan B here.
And I think the difference is between one of you having a fallback for where there's
something here which you didn't understand or didn't predict at a level of accuracy
for where you're willing to move forward in a fully autonomous way.
So you now send it back to a human, we need to kind of resolve that.
Or you have not a fallback, but a willingness to make errors and simply just label the
data and then upon those errors figure out how can I make that prediction slightly more
accurate tomorrow?
So we're not a self-driving car, that means self-driving cars probably don't have much room
for errors.
Perhaps some versions of an error which is that you stop or go to the side or anything
that rhymes with that.
What are you going to do as mess up my lunch tomorrow?
Yeah, exactly.
And I might even churn you as a customer and I would hate for that to kind of happen,
but I'm allowed to make mistakes here.
So we've always hunted the idea of the fully autonomous agent.
And that means of that 150 people we have in place for the team right now, about a hundred
to answer your question.
So I'm not trying to avoid it.
About a hundred of that 150 does nothing but label data.
But I think there's a distinction here between-
But they're not labeling exceptions in the loop of the customer query.
It's something that happens later and Amy does what she can to figure out.
It's certainly happening in real time as well and it's happening as double annotation
and it's happening with golden data sets where they label things that aren't even part
of a real customer query.
But all of this for this purpose of being able to come out tomorrow with a slightly more
accurate set of predictions.
Sure.
Sure.
And that's going to be going from zero data to millions of emails annotated over the
last three years and that becomes that corpus for where we can wake up one day and essentially
have this all margin type of software which we can then be in market with.
Yeah.
So what's the- I mean if you do have two thirds of your team doing annotation and some
of that is real time just like a company that might describe that as human in the loop,
what are the key distinctions between you know building a company kind of with the idea
that you're going to do that and building a company that you know does that but at
horse every minute of it?
I think certainly the difference is that if you have kind of this split setting for
where you have a human in the loop.
The human then many times is tasked to make a perfect outcome.
Whatever the implication might be on your data set.
Just make the perfect outcome.
I said right now just swing the card to the left.
I don't really care what that means to our data set.
Just swing the card to the left.
When we label data there'll be a set of intents, there'll be some entities that we try to
extract but even as they see those entities either not being there or being labeled
so that the outcome is wrong they still move forward.
I said now I'll drive that car into a wall and I'm putting this in the air force and
nobody can see this but their job is not to swing the car to the left.
That is to drive it into the wall and say I labeled it as we've agreed.
And the machinery still took a decision which was not optimal but the only way we can
kind of learn from that is if I label it per the guidelines.
So that's the difference between going all McKinsey style on automating a workforce to
do a job much faster and that of trying to train or create a corpus of data where you
can have this autonomous agent kind of operate.
So I'm hearing that as there's a difference between labeling and having a CSR jump in
and fix a situation and get it right.
And labeling is kind of you know you're positioning it as the longer term approach but certainly
is one that contributes more towards generating a bigger you know better data set whereas
having the CSR jump in and you know provide the right answer when the AI gets stuck might
not necessarily contribute to the long term solution.
Couldn't agree more and it's not that there's anything wrong with that.
I said you can create a formidable business on humans in the loop I said that exists
everywhere in the world call a taxi and there's a human in that car right so that exists
today all over the place.
My point from very early on was just that I think you have to make up your mind whether
you want to be one or the other the day you start because they are in conflict and it's
very easy to fall in love with the perfect outcome because it hurts less on the way there
so I've suddenly had emails in my inbox that have disappointment included into them.
That's the most polite way I can put it where Amy made a mistake she shouldn't have made
and the funny thing about machine mistakes and you know this obviously is that machine
mistakes don't look like human mistakes so if you email me and you and I have a dialogue
back and forth and there's a little bit of ambiguity in the way you put it you can empathize
with my decision I said oh right I see where Dennis came from on that decision but machines
make different type of mistakes for where it is much harder to empathize that's it that
is just so obvious I said why didn't you get that right because there's a difference
in the machine and you trying to kind of resolve what's being said here and that means
little things for where tonight at 1 a.m. you send me an email saying hey Dennis I got something
super important which you meet up tomorrow and talk it through the machine might just really
do that tomorrow but that's not what you're trying to do you wanted today you're just so excited
that you stayed up late and then you want to meet Dennis in eight hours from now right and that
seems like a silly machine mistake I said you saw the importance couldn't you feel the importance
in that email and then I wanted to meet with you in eight hours yeah so that is kind of the
interesting dilemma the way but we've been taking those punches to the face for three years
and we stick into it yeah and so I am imagining your response to this but based on the
the previous conversation around human and loop but for that particular type of error and those
like it is the answer labeling more data or is the answer developing some kind of front-end
set of human heuristics that can help guide the AI down the right path so that's a really good
question so I think people see this as a single problem but it's probably kind of a set-up
problem and I think if you were to simplify it perhaps there's the initial natural language
understanding challenge which is not kind of a solved science and the only hope we have is that we
picked a space so narrow that we might be able to understand everything which is being talked about
when we talk about meetings right but even as you saw that that is certainly a place for where
many times what we just need is more data as in there's things in our little universe here that
happens so rare that the data set is still so sparse and give you an example so a new meeting
intent for the very definition that a meeting is about to happen that happens in every single
meeting that we set up so that means we have a ton of new meeting intent data as in you can say
pretty much what you want hedonist let's do the hoki boki calm early next week we understand that
being you wanting to set up a new meeting but you're trying to change the pin code to the conference
call happens one out of 10,000 meetings so do a hundred thousand meetings and I have 10 data points
as in that is so sparse it's not about any type of model which I might put in place as in there's
just not enough data really to take any good decisions here so that is something for we can certainly
see we just need to keep turning through more meetings and we can see that kind of the level of
accuracy continues to increase so that's the one challenge and then if you do understand what's
being said I said that NLU engine you put in place is robust and backed by a very large data set
you need to have some sort of reasoning engine in place for where you email Amy at x3a and say hey
I'm going to be running five minutes late if I understand it that doesn't mean I know what to do
with it do I do nothing do I do something if I do something what is that something what does that
look like that is where as you alluded to there's a lot of design where I can help
take you down a dialogue path which is more likely to end up in a successful outcome versus
another dialogue path for where it is less likely to end up in a successful outcome and we can
certainly see and this sounds devious and it's not that if we help direct people down one avenue
we're both going to end up slightly happier certainly more likely to end up slightly happier
and then in the end if you take some action in your reasoning engine that is some sort of
computational outcome then you need some NLG engine that can take that computational outcome
and turn it into language so we can communicate clearly to all the constituents that is also a
place where we found that we thought it was clear what we just communicated but given that the
conversational UI is somewhat of a new UI perhaps not to you and I who started on the command line
but certainly to many people in the middle of a way they grew up in the graphical use interface
they don't have some inner connection to the conversation UI and that have been just a long
optimization path trying to figure out exactly how to put it and you describe that last step as
NLG to what extent is it real kind of NLG versus picking from a list of predefined things
we don't think there's a decision tree of sorts for where if I just do every single branch
and have enough templates in place I can find that template the matches that particular setting
that I ended up on so we've tried to create and I'm certainly not saying that we solved it
but the only way that we can be so ambitious is again we picked a single vertical
meaning that you can talk all you want about Chelsea Football Club winning the premiership
next year we don't have any idea but if you talk about meetings we can generate
tricky fluid responses that are created on the fly and the reason that we need that is that
even though meeting sounds sounds almost simple they're just not because you talk about
multiple times in multiple ways well multiple participants some mandatory some optional some assistance
sure and not to get it even get into all the rescheduling and the moving locations and all of that
and you don't follow the path that we sit forth and that means sometimes we need to talk about
fewer things sometimes I need to talk about multiple things at the same time so we assemble those
on the fly and I've been kind of forced to build this kind of design setting so if you want
some sort of visual output you know you and me will go install Photoshop and for other tools
and we'll end up with some pallet of little sprites that we can use for that kind of output
where do you design conversational UIs I said not in word but where right now you're building
your own thing to do it right you're building your own thing and the same as he goes for the
front of it here on the labeling and where do you label your data I said hopefully not in Excel
so you're going to label it somewhere else so you build your own kind of labeling piece of software
so those NLG scripts and scripting that we've invented was some sort of amalgamation of raw text
and JavaScript and our own little version of JavaScript is how we can generate these responses
hmm interesting but even they can given that they are programmatic end up sometimes not sound obvious
I said why does he say that I said that's not even a proper sentence I know I'm also sorry
but it's because we're trying to generate on the fly we actually don't know what it looks like
until she starts talking and you English only currently or multiple languages English only okay
okay we are you're you're kind of sighing back in the chair so no that is a big problem it sounds
like so we have really three dimensions for where we're going to go expand and the reason I do the
kind of slight sign because it was so visual is that whenever we raised another $2 in capital we
immediately get the hey when are you going to do more languages we could talk about the challenge
in that to when are you going to do more communication channels and we can talk about the challenge
in that we will most certainly do both of them we want the agent to be multilingual
not just so we can attack other markets but so that we can better serve the guest
so we set up meetings at about 190 countries today but we really only have customers
in English speaking nations but they meet up with people all over the world so for me up with
somebody in Germany I could actually remove some of the ambiguity for spoken in his own language
so we most certainly will do that and then the last one is that we want to make those obvious
integrations into things that revolve around the event itself say whenever you meet up with
somebody in midtown you use Uber one she set up the meeting two she know where is that three
do you know why you office is that why do I have to kind of click for the Uber you can just make
it happen or even better why do I have to spend an hour and yelp trying to figure out where we're
going to meet those little things where hey you know I eat at Harasushi whenever I meet up with
people just book the table it's not rocket science right right so those are certainly three
dimensions but to say it's all email all English very few integrations okay and you mentioned
some of the challenges on the language side is it all like doing it all over again certainly
there are some economies of scale and you have to see the face that associates this question in
particular this not you but certainly other people are from the outside if they haven't thought
about it for more than a few minutes immediately just let's on to oh so it's just about kind of
translating your templates first of all search and replace yeah yes sorry you did not respond to
Google translation yeah so I think there's two parts to it that's certainly the fact that we might
have to train on a local data set I said the way you set up meetings in northern Europe versus
southern Europe or the Caribbean or Asia might actually just be slightly different it could just
be that northern Europe we are super direct we press slightly more casual and I'm saying that as
an insults if we go to southern Europe we might just have little cues in Asia that we don't have
in the US and if I don't pick up on that I might not have the intelligent agent I had hope for
in a different language so that's certainly should yes we might have to train on a local
data set I'm imagining a country where you know the level of politeness maybe Japan might be an
example this is so high that you know someone says okay that means they don't really want that time
that's just their way of not so not to offend the Japanese we might even cut this whole segment
so now I'll give you something where both you and I are involved so it's only you and I we are
insulting now yeah so I'm Danish I assume you're American yeah and here's the thing we don't do
in northern Europe so you and me can set up a meeting for May 17th next year at my office and you'll
never hear from me I will just assume you turn up at my office and it's all good here's what most
Americans do confirm triple confer so you knew it already three weeks prior to the meeting hey Dennis
just checking in I'll see you in about three weeks the day before Dennis see you tomorrow one
o'clock the first time I'll do the yeah I know it's on my calendar the third time I have yeah
I fucking know which I'm on this like four times now and the funny thing is that we've actually had
to engineer for that in our solution because as you double confirm there's many things which you
say in that that rhyme with the reschedule so we need to be very good at picking up on the fact that
all you're doing here it's just giving me a thumbs up one of the signs that we've done to kind of
protect against that is that Amy learned this skill as well which is that she will reach out knowing
that we set up the meeting a long time ago and you are American so prior to the meeting happening
she'll reach out and say hey just give me your thumbs up the meetings for tomorrow at one o'clock
if there's no changes I'll assume you're both all good and set she'll have a better language than
that so that is one of those interesting things for me just do that for the American and
seems that the Northern European is good so right now she does it for everybody and we haven't
had any complaint for where hey don't be so overly anal they're just taking it you know that's
that but I can totally imagine and that brings me to the second part of the language challenge
outside of being able to train a new data set which is what I alluded to here is that there's
probably some product design choices that you need to make for the particular market that you're in
example take our reminder logic so I see see an Amy to set up a meeting between you and I say
for Friday you are slightly tidy or busy you're here today right doing all sorts of things
how quick can Amy not you so we can certainly see East Coast US you can be reasonably aggressive
we can certainly also see that's even just within the US there's other places for where
people are not as comfortable in her reasoning out as quick as she's doing I said she's a little
bit too bossy for them yeah and certainly people in New York sure still let's do this but there's
certainly other places where that is not the case do you find it all that people that people try to
give Amy the kind of advice that they might give an actual assistant like hey Amy you need to tone
it down a little bit or that kind of thing or to what extent does Amy blur the lines between a
virtual assistant like virtual assistants overloaded but yeah an AI and a human that's a very
interesting question now I'm not sure you me or anybody really got the answer just yet what I
don't think you should do and certainly not something which we're trying to do is to play a game
of daily twining tests for where you try to fool people into believing that this is a human
I'm finding it hard to figure out what you win on each one of those tests sure you can have a
little bit of a ha ha moment and a little bit of social fun and that's that really probably just make
your make the job harder for yourself the next time that is exactly what is happening so we try
very hard to be upfront and honest about the fact that this is machinery but do the job so well
that you kind of forget or don't care now let's give you one stat here that we did early on
so in 11% of all the meetings which we do at least one of the emails in that dialogue will have
one intent only gratitude as in somebody emailed Amy back saying thank you or appreciate you setting
this up for Friday so sorry for not getting back to you earlier even people like me I bloody work
there will start out my kind of handovers with Amy would you be so kind and it's not that I don't
know what's going on here but that is interesting and we're still so early that that's probably
going to be a half decade for we fumble a little bit until we figure out what is the right design
for this new setting for we have kind of mixed agents some human some machine have you ever thought
about whether in that particular example you're doing that for Amy or for the human that's on the
other side of the email so there's some research that suggests in any master slave relationship
if the master is acting in a aggressively demeaning way towards the slave it's actually not the
slave who's losing it's the master and that's plenty of traditional research on that for where
the more rude you turn over time the Saturday things really become for you and that's also why we
have these early suggestions for where you should probably be kind to the Alexis and the series
and the katanas of the world especially if you have kids around the house because you are in one
way certainly asking a question but you're also teaching some other human being about how to behave
in the world and there's certainly a thing missing right now for where they will not learn it otherwise
if they don't learn it from you because there's no real penalties built into these systems yet
which I think we need to have penalties for where like Amy talking back I don't think that's the
right design but yes so I don't know who you think you're talking to Buster but I'm not
scheduling anything for you if you talk to me like that well I couldn't get the point across
that would get the point across I think if you walked into the team of AI interaction designers
we have they would kind of say I hear you let's massage that a little bit and kind of see what we
can do here but my point is certainly what aligns with what you said here for where say we pick a
slightly more refined example for where you are really a super kind person but you kind of late
all the time you're a little bit tardy still nice though that means as Amy is about to suggest
you and me meeting up tomorrow if she knows that you're probably not gonna really be there for the
8 a.m. like a third of the meetings you do you reschedule it's just who you are nice but tardy
perhaps you should really just start out by suggesting how about we meet up at one worst case
then you can just continue to work as inbox you didn't have to kind of get up early and be
at the office for only to kind of sit there alone because you didn't get there and that is us
taking into consideration that people are different here and what I want is even if you kind of
perhaps even turn into an asshole perhaps the response speed just slows down as in she's super
speedy you know machine speedy right but perhaps we'll put this on the cool a little bit
I'll respond to you in half an hour and I'm not sure what those designs look like but I actually
do think they eventually will have to emerge in these systems interesting interesting before
we wrap up I want to go back to a comment that you made earlier about just about the different
machinery the different tools that you've had to build on your own I've talked to several
companies in the conversational space over the past few days and everyone's building the same
things right everyone has you know they started off they tried wit.ai api.ai you know the kind of
the black box nature of those platforms didn't work out for them you know you're saying similar
things you know the platform itself plus all of the tooling that goes around you know labeling
annotation is this all stuff that you think that everyone is doomed to reinvent for themselves
or you know or is it the nature of the problem says that you know folks will want to create these
things over and over or do you think the problem will eventually lend itself to a more of a platform
type of an approach it depends on how loaded the word platform is I suddenly believe that
the tooling will disappear as a task for the individual companies that doesn't ring true to me and
I've been around long enough to see how the first mover were forced to make all sorts of choices
for where they would go and implement things for where had they been a tool out there I wouldn't
have been implementing that but there was no tool out there so that goes from any type of labeling
or even any kind of NLG type design you would have to do I expect that type of tooling to arrive
I'm actually even surprised that more people are not trying to attack the kind of AI space
from that angle yeah and I haven't really seen anybody do anything but just do it for themselves
for where well we might even want to when they spin that out and say hey here's a tool
for where somebody else might be able to take advantage of that and go back say 30 years pretty
much any Fortune 2000 would pretty much implement their own ERP system if you did that in 2017
you'll be crazy you would install you know some Oracle people solve whatever type ERP and
hopefully be happier with that so tooling I agree should and will be commercialized
now on the generalized ability to kind of make predictions I think there's a difference
between whether you being in a high accuracy or low accuracy space higher accuracy meaning that
your product can't exist without a very high degree of accuracy in its predictions so a self-driving
car cannot live with a footnote that suggests for every one thousand miles we hit a pedestrian
even though that is a fantastic piece of software it just can't exist in market but there's
only plenty of software for where hey I pick up 80% of the faces in all of the photos that you
upload nice I said that's not too shabby I said that's really just you helping me out for where I
don't need to kind of attack those faces in most of the images which I upload that's good and for
that you should probably just go use clarify and that becomes I think a good platform play but I
think right now if you cannot live with a kind of degree of error you probably have to forget
how do I then go engineer my own high accuracy backdrop and the only way you can beat those
platforms is by being super focused on some vertical way I'm just the guy who scheduled meetings
right as we've optimized everything for that particular use case and there's not that we're
necessarily smarter than the next guys just hyper focused so yes I do think that will arrive
what I don't think will arrive is that you want to build something on Facebook messenger the tools
which they provide will be all you need sure for some nifty few basic things but not for anything
serious okay great well I really enjoy this conversation Dennis thanks so much for joining us
this was fun we should do it again awesome thank you see you
all right everyone that's our show for today thanks so much for listening and for your
continued feedback and support for more information on Dennis x.ai or any of the topics covered in
this episode head on over to twimmolai.com slash talk slash 67 we hope you've enjoyed our NYU
future labs ai summit series if you need to catch up on any of the episodes visit twimmolai.com
slash ai nexus lab 2 of course you can send along your feedback or questions via twitter to act
twimmolai or at sam charrington or leave a comment or write on the show notes or series pages thanks
again to future labs for their sponsorship of this series for more information on the program
visit futurelabs.nyc and of course thank you once again for listening and catch you next time
