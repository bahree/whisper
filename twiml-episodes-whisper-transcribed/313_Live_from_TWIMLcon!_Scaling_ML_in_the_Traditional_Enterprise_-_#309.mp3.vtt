WEBVTT

00:00.000 --> 00:15.040
Hello and welcome to another episode of the Twimble AI podcast.

00:15.040 --> 00:21.920
I'm your host, Sam Charington.

00:21.920 --> 00:28.280
So for our next panel, we're going to be talking about scaling machine learning in the traditional

00:28.280 --> 00:35.960
enterprise. So for that, I'm excited to introduce my friend Josh Bloom to moderate the panel.

00:35.960 --> 00:41.800
Josh, thank you so much for coming to this panel. We've got a real treat today, not just because

00:41.800 --> 00:46.600
we have three really interesting panelists, but because of their background and where they work,

00:46.600 --> 00:51.080
we're going to get to see a bunch of different perspectives here and sort of my challenge as a

00:51.080 --> 00:54.520
moderator is to make sure that we're not all just agreeing with each other. So I'm going to be

00:54.520 --> 01:01.240
trying to stir up some controversy. So let me invite the panelists up here and then once they

01:01.240 --> 01:07.000
take their seat, I'll have them give a little brief intro to themselves and then we'll kick this off.

01:07.000 --> 01:13.560
So Amber, why don't you get us started? Okay, my name is Amar Awadala and I'm one of the founders

01:13.560 --> 01:18.920
of Cloudera and the chief technology officer for the company and briefly for those that don't know

01:18.920 --> 01:26.600
Cloudera. We do management for data analytics and machine learning, enabling enterprises to leverage

01:26.600 --> 01:31.800
what we call the enterprise data cloud, which works both across on-premise and multiple cloud

01:31.800 --> 01:36.360
environments. Hi, my name is Paulive. I'm the director of data science at Levi Strauss.

01:36.360 --> 01:41.880
Everyone's beloved dendermaker. I started there about a couple years ago and kind of started

01:41.880 --> 01:48.520
like the data science AI function there and sort of have been focusing on building a lot of different

01:48.520 --> 01:53.080
solutions for the company and like we're just driving the transformation from like your standard

01:53.080 --> 01:57.880
enterprise into a more data driven enterprise. Hi, my name is Jürgen. I'm one of extent

01:57.880 --> 02:02.920
just global data scientists. I'm looking after the resources industry, so all in guess

02:04.040 --> 02:09.560
mining, chemists and everything, which is dirty. And my team is looking into what we call

02:09.560 --> 02:14.520
industrial analytics solution where we try to help specifically help bring this industry to make

02:14.520 --> 02:19.720
it more sustainable and especially bringing that also the solution to scale. And my name is

02:19.720 --> 02:25.240
Josh Blum. I'm a professor in astrophysics at UC Berkeley. I had a startup which is called

02:25.240 --> 02:31.320
WiseIO. I was a CTO and co-founder there, which got acquired by GE and so I served as a vice

02:31.320 --> 02:35.400
president of data analytics there for a number of years and now I'm back at the university.

02:36.200 --> 02:42.680
So one of the interesting tasks I think of this panel is for us to drill down a little bit

02:42.680 --> 02:48.760
beyond the generic challenges of digital transformation across all different industries and start

02:48.760 --> 02:54.840
thinking about and having a conversation about what's different. So the first question which I'll

02:54.840 --> 03:00.200
ask Amher to address because you are in some sense selling across all different types of industries

03:00.200 --> 03:07.160
is what makes these traditional enterprises different in how you sell, how you talk to them,

03:07.160 --> 03:12.440
what their problems are relative to what we'll call sort of the modern companies that grew up

03:12.440 --> 03:17.800
in the digital age. The talent. The talent is very different. The mix of the talent that they have

03:17.800 --> 03:23.320
is not the same kind of talent that you'd find here at Google or Facebook or whatever and that's

03:23.320 --> 03:29.720
where we need to make a lot of tools and automation around this technology to make it easier for that

03:29.720 --> 03:36.120
talent to consume the technology. I would say that's the main key difference. The other key difference

03:36.120 --> 03:44.360
is culturally just learning how to adapt to machine learning and AI and one key thing that we

03:44.360 --> 03:50.360
stress to them is you need to keep in mind that unlike other traditional software projects I'm

03:50.360 --> 03:56.040
going to build a web app that does this or a mobile app that does that or a automated certain

03:57.480 --> 04:02.680
workflow function within my organization. ML projects we like to equate them a bit more to

04:02.680 --> 04:08.360
startups and running a startup portfolio. When you're running a startup portfolio you have a bunch

04:08.360 --> 04:12.360
of very good ideas in the startup portfolio but only one of them is going to work. Maybe two are

04:12.360 --> 04:17.080
going to work and it's very important to be able to iterate quickly and the same thing happens

04:17.080 --> 04:21.720
with ML projects. We have a good hunch that this might be a good project. We're going to start it

04:21.720 --> 04:26.280
but we don't know after a few months it might actually turn out to be not good. So to change

04:26.280 --> 04:32.840
their mentality from the not just waterfall and agile but even a step further to fully iterative

04:32.840 --> 04:37.640
portfolio management of projects is a very key change that we advise these traditional

04:37.640 --> 04:42.920
organizations to start adapting to. Good. And Jürgen can you say a bit from your perspective

04:42.920 --> 04:49.960
at a censure? What you see is that is it talent the key issue or are there other challenges?

04:49.960 --> 04:56.680
So talent is definitely a big challenge because these organizations when you look at their IT

04:56.680 --> 05:03.720
departments and the departments where these solutions have to be actually used they are not prepared.

05:03.720 --> 05:09.400
They're coming from a very classic data warehousing enterprise BI background and that's what they

05:09.400 --> 05:17.480
are living in. So now you're challenging them to switch to a complete new topic and that's a

05:17.480 --> 05:22.200
barrier in their head. And the other thing is what then very often got forgotten yes they managed

05:22.200 --> 05:26.920
to build a solution but they managed to forget to talk to the operations teams who have to action

05:26.920 --> 05:32.200
eyes and use it. So they suddenly have people they're throwing that over the fence and say here it

05:32.200 --> 05:39.080
is it's cool it helps drive value but the operations sits there and says you have never asked me what I

05:40.440 --> 05:45.560
what is the heck what should I do with that and then it is three times wrong and they say thank you

05:45.560 --> 05:51.560
we're not using it anymore. So this this transformational part on the the people side is very often

05:51.560 --> 05:57.720
completely underestimated and leads then that actually good machine learning solutions have no

05:57.720 --> 06:02.280
success because people doesn't know how to use it or they were never ever asked before how to use

06:02.280 --> 06:06.280
it. Yeah that's an interesting view of talent usually when we talk about talent we think about the

06:06.280 --> 06:10.040
people are going to build these things but you're also saying the people that are already there

06:10.040 --> 06:15.880
have to learn how to accept it and become more efficient with it and and do their jobs better.

06:15.880 --> 06:21.800
Palo so you had a great talk earlier today which I really enjoyed in some sense you're kind of the

06:21.800 --> 06:30.120
marquee success story that we have 160-year-old company figuring out how to use AI to improve the

06:30.120 --> 06:35.960
bottom line and you talked really kind of fundamentally about the need for people to own a P&L

06:35.960 --> 06:39.880
that it wasn't really real sort of a research project unless there was a real dollars and cents

06:39.880 --> 06:44.440
on top of that and maybe an X on somebody's back. So I assume you've got a pretty big X on your back

06:45.960 --> 06:51.000
we talked about talent can you can you just tell us how you hire and what are the some of the

06:51.000 --> 06:56.760
challenges you see especially trying to hire in this area where you're going up against the

06:56.760 --> 07:03.960
Googles and the Facebooks of the world. Yeah for sure I mean I think talent is I would agree one

07:03.960 --> 07:09.160
of the bigger problems for sure and I think when you're trying to like build a team you have to

07:09.880 --> 07:14.680
think about what is it what is the value proposition that you're offering somebody who's

07:14.680 --> 07:20.120
who's really like you know if they're really talented they could get a job from any of the big five

07:20.120 --> 07:27.400
six ten companies right and I think at first starts before we look at before we ask like you know

07:27.400 --> 07:32.760
what can you do for us is to first try to answer what can we do for you as talent or sorry like as

07:32.760 --> 07:38.360
the company is you know looking for talent and I think the key value proposition that we bring

07:38.360 --> 07:44.920
first there is like you know is the fact that you can really be very entrepreneurial at a at a

07:44.920 --> 07:51.960
large company in certain ways and that you can have the ability to influence something end to end

07:51.960 --> 07:55.640
versus a lot more many of the established companies especially if you're starting off like maybe

07:55.640 --> 07:59.720
you're two three years into data science you would be put on like a larger team and there's already

07:59.720 --> 08:03.880
like a build product and you're like sort of like you know adjusting the nuts and bolts versus like

08:03.880 --> 08:08.360
here you can you know come and build like a end-to-end recommendation system or you can like you know

08:08.920 --> 08:13.480
change completely overhaul the way a certain business process works right and you can actually

08:13.480 --> 08:19.480
literally see the dollar impact of your work and so in that way like having a P&L does help

08:19.480 --> 08:23.480
because you know I mean what's what's cooler than like you know which one's cooler like you know

08:23.480 --> 08:27.880
saying that you know I made this algorithm five percent more efficient or saying that I drove two

08:27.880 --> 08:31.640
million dollars in criminal driving you right I think depending I guess one on which side of the

08:31.640 --> 08:35.800
data science aisle you are one would be more interesting the other but I think we try to look for

08:35.800 --> 08:39.560
like people who are really trying to drive that real world change and I think when you start

08:39.560 --> 08:44.600
looking for people I think the first thing we try to understand is you know I mean there's like a

08:44.600 --> 08:48.120
lot of paper data scientists out there right because now like data science has become the hottest thing

08:48.120 --> 08:52.120
and so anyone who takes a bootcamp wants to call them so the data scientist not that there's

08:52.120 --> 08:57.000
anything wrong with that we have a lot of people who came from the boot camps but I think more than

08:57.000 --> 09:02.520
skill sets do they have the right mindsets and you know I think in terms of mindsets there's like

09:02.520 --> 09:07.320
another the mindset of like always being learning so the example I like to give all the time and

09:07.320 --> 09:11.320
this might be a bit contentious with some of the NLP people here but like if you did your PhD in

09:11.320 --> 09:16.200
NLP like let's say June 2017 a lot of what you worked on is probably already obsolete because of

09:16.200 --> 09:20.280
you know tension and you know transformer architecture like which came around the scene like in

09:20.280 --> 09:24.600
like in November 2017 so are you really willing to like fundamentally change the way you work and

09:24.600 --> 09:33.240
you know keep learning and keep growing and I'd be willing to adapt as the business needs change

09:33.240 --> 09:37.320
and so I think those mindsets are really key to when we look for people and like probably that

09:37.320 --> 09:41.800
you know that that environment for them to like grow with the company yeah so it's interesting

09:41.800 --> 09:45.960
it's sort of counterintuitive that because you're stepping into an industry that maybe doesn't

09:45.960 --> 09:50.520
have a lot of data science and AI exposure what you're saying is that one way attract people is

09:50.520 --> 09:55.800
they can have an outsized impact on those on those companies that's that's pretty interesting

09:55.800 --> 10:00.280
what about what about the data and in the mission you're going to if I could ask you to speak to

10:00.280 --> 10:06.520
this from your experience in the mining industry and in with airlines one of the things that that

10:06.520 --> 10:11.000
we saw when we were at GE is one of the things that attracted the data science and engineering

10:11.000 --> 10:15.880
teams to our group obviously other than the the culture that we were trying to build in our teams

10:15.880 --> 10:21.640
was this idea that the data that we were working with in the problems that we were solving had

10:21.640 --> 10:30.360
the impact on people's lives as people not as consumers and so the mission behind that data

10:30.360 --> 10:35.000
actually becomes pretty interesting especially if you can have a worldwide impact what are your thoughts

10:35.000 --> 10:42.360
on that you're in so that especially in this industries that it's definitely the whole

10:42.360 --> 10:48.920
sustainability thinking about how to make a it a more sustainable carbon neutral business so

10:48.920 --> 10:55.640
you can imagine the emissions these industries blowing out of their gymnasies is not the nicest

10:55.640 --> 11:02.040
in the world but even more importantly is the aspect of safety so there's still a ton of people

11:02.040 --> 11:06.920
in dangerous places so if you send somebody an offshore oil rig in heavy weather conditions

11:06.920 --> 11:12.360
the likelihood you get injuries is high if you send somebody an underground mine a cavity collapses

11:12.360 --> 11:17.240
and thousands of tons of stone and rock comes down it's dangerous and if you're putting that

11:17.240 --> 11:21.960
in the heads of the data science team and so look what you're doing is not just manipulating

11:21.960 --> 11:27.720
some serious and ones you are driving people to safety or you're sure that people are actually

11:27.720 --> 11:32.600
safe in what they are doing so your algorithms become a new purpose and I had recently the

11:32.600 --> 11:38.840
pleasure to be invited by the United Nations Environment section where those discuss okay this

11:38.840 --> 11:44.360
combination of make it cleaner and make it safer at the same time so you can imagine that's

11:44.360 --> 11:52.360
not necessarily two paradigms which are always working simply together and here the data science

11:52.360 --> 11:59.160
talent so even untypical data scientists we are seeing here so normally everybody believes

11:59.160 --> 12:05.720
data scientists has to have a statistically or mathematically degree to be good we have found out

12:05.720 --> 12:11.400
there's tons of engineers who love to work with data they learn Python coding in no time because

12:11.400 --> 12:18.760
they were tortured with foot run in their past so they found a whole new way to look at this data

12:18.760 --> 12:25.320
and make things happen where we thought before it's not possible to do so ever um we just heard

12:25.320 --> 12:30.680
about safety as a real sort of distinguishing characteristic of the kinds of work that needs

12:30.680 --> 12:38.120
to happen in AI where real value needs to come how much does safety and maybe data privacy come up

12:38.120 --> 12:43.400
in the way that you sell to these more traditional industries and maybe just tell us more broadly

12:43.400 --> 12:50.920
about how you help them think about their data challenges yes one of the key friction points

12:50.920 --> 12:58.680
uh in almost all of the enterprises we work with is it's almost like they are schizophrenic meaning

12:58.680 --> 13:04.920
they have two personalities at the same time one personality is the innovator data science machine

13:04.920 --> 13:10.920
learning team that just want to keep making changes day in and day out and then the other personality

13:10.920 --> 13:15.960
is the operators administrators who want to minimize change they want to make sure everything is

13:15.960 --> 13:21.560
just running 24x7 without ever failing and they want to make sure it's secure and the fully locked

13:21.560 --> 13:26.200
down so that there is no data leakage or anything like that and that leads to significant problems

13:26.200 --> 13:31.640
it leads to the operators continuously saying no to the innovators so the innovators will come

13:31.640 --> 13:38.440
in and say here I would like to install this new PyTorch framework on our cluster and the operators

13:38.440 --> 13:44.200
will tell them uh uh go away I'm not going to do this you have to tell me why this is important and

13:44.200 --> 13:47.480
they can they tell them I cannot tell you how it's important until you install it for me and you

13:47.480 --> 13:53.240
get this deadlock where you just can't move forward and the the scientists and the innovators being

13:53.240 --> 13:57.640
a little smart and a little bit evil uh what they end up doing is they make copies of the data

13:57.640 --> 14:01.480
on the laptops they go home and then they install whatever they would like but then you get the

14:01.480 --> 14:06.520
leakage and you lose the provenance and the lineage of of the data so that was a very core

14:06.520 --> 14:12.120
issue that we observed in our customer base about five years ago and we start to attack head-on so

14:12.120 --> 14:17.400
we we built a framework the cloudera machine learning framework that attacks that problem how

14:17.400 --> 14:25.320
to manage the workflow of getting the operators to be able to say yes to the innovators enable them

14:25.320 --> 14:31.080
to be agile enable them to install the latest and greatest without compromising the safety

14:31.080 --> 14:35.640
reliability and security of the operational environments so how can you have multiple staging

14:35.640 --> 14:40.360
environments and a workflow that goes through all of that so that the algorithm can be tried out

14:40.360 --> 14:45.560
with the data without it being compromised in terms of security and if the if the algorithm works

14:45.560 --> 14:50.040
then how can we quickly deploy it if the algorithm does not work how can we throw it away and move on

14:50.040 --> 14:54.760
to the next one and that's the key challenge that we observed and that we focused on addressing

14:54.760 --> 15:00.760
from a build versus by perspective um you know in Paloval ask you to sort of answer this because you

15:00.760 --> 15:07.000
you kind of built a really nice system yourself you know are we at the stage now where during the

15:07.000 --> 15:11.800
evaluation process people are going to start asking those questions around safety and security

15:11.800 --> 15:18.120
and privacy of data uh in it almost from an SLA perspective of guarantee you know asking

15:18.120 --> 15:24.040
asking providers to give them guarantees I mean we ask of we ask of that of our you know platforms

15:24.040 --> 15:29.400
at the AWS and and Google level but are we going to also start asking that of solutions level

15:30.360 --> 15:35.560
so maybe you could speak a little bit to um how you think about some of these uh challenges

15:35.560 --> 15:41.640
around data and then also maybe kind of address how you decided you're kind of build by um how that

15:41.640 --> 15:48.520
how that formulated yeah definitely so I mean data security is for sure paramount and uh

15:48.520 --> 15:54.200
our chief AI officer Katia Walsh likes to call data like uranium in certain ways where you know

15:54.200 --> 15:58.280
you can get a lot of value out of it but if you don't contain it properly it can really

15:58.280 --> 16:04.680
hurt people um so yeah I think I mean you know I think some of the speakers before they mentioned

16:04.680 --> 16:09.400
like you know ISO compliance, soft compliance um GDPR compliance right especially if you're

16:09.400 --> 16:13.640
a global business so we take that very seriously and like you know I think whenever you

16:13.640 --> 16:19.160
so I think what we do is that anytime we work with a specific provider we have a questionnaire

16:19.160 --> 16:24.040
that has been sort of pre-approved by like different teams so we have information security and

16:24.040 --> 16:28.680
like you know DevOps and you know data science and so these are standard questions that we just

16:28.680 --> 16:33.000
send out to like you know before we even like have the first meeting with them that we need answers

16:33.000 --> 16:36.840
to these things before we even like you know invite you to like have like a 30-minute conversation

16:36.840 --> 16:42.120
with us so um and what that does is that you know yes it does maybe filter out some of the more

16:42.120 --> 16:47.880
new and exciting technologies and so the new providers that you know you might uh sort of want to

16:47.880 --> 16:53.400
work with uh but it doesn't work out uh which is fine but I think uh the only day like for a

16:53.400 --> 16:59.240
large company like us like in our brand and our our reputation is everything so you know um we

16:59.240 --> 17:04.520
don't want to want to like sacrifice the band brand equity just for just to like have one team

17:04.520 --> 17:07.640
move fast so I think there's a little bit of that tempering of the expectations that we have to do

17:08.280 --> 17:11.240
so uh but yeah I think a questionnaire, a standard questionnaire that's been approved

17:11.240 --> 17:15.640
really helps it takes a while to prepare to get everyone the same page and acknowledge like

17:15.640 --> 17:20.600
these are the right questions to ask um and like we need to have like six monthly reviews about

17:20.600 --> 17:24.600
the questionnaire etc but that's one thing we use and that has really helped us like weed out

17:24.600 --> 17:31.320
uh providers which might not necessarily meet certain needs um when it comes to the buy versus build

17:31.320 --> 17:38.120
I think I um uh Cassie Kozarkov actually has a great blog about uh um sort of are you in the

17:38.120 --> 17:43.000
business of you know making pizzas or are in the business of like building microwave ovens

17:43.000 --> 17:47.640
right um and so one of the key things there is that we I think the way we like to think about is like

17:47.640 --> 17:51.880
what are the core capabilities for the business like and as let's say as Levi's or you know

17:51.880 --> 17:56.360
right make you know let's say company what are the things that you feel or that we feel as a

17:56.360 --> 18:01.560
business are core capabilities we should own because those are things that we'll always uh keep

18:01.560 --> 18:05.080
improving and those are things that we'll always keep working on and those are like the key

18:05.080 --> 18:09.800
differentiators for us so like for example if he came up with a new cloud environment you know

18:09.800 --> 18:13.400
let's say we had a Levi's cloud right that we're trying to make it public that's not the business

18:13.400 --> 18:18.200
we are in so stock just went up actually I mean then I would do like something Levi's Bitcoin

18:18.200 --> 18:23.240
right uh but um it's like that's not the business we are in like we're not in the business of like

18:23.240 --> 18:28.120
you know building you know a new TensorFlow or something right you know might as well just use

18:28.120 --> 18:33.800
everything uh out of the box um and uh not really focus on like you know rebuilding things that

18:33.800 --> 18:39.720
already exist but when it comes to the core capabilities um how we do business like what are the

18:39.720 --> 18:45.560
let's say you know um how do we recommend products to people um how do we uh inform how our

18:45.560 --> 18:49.560
products are designs like those are things that are core differentiators for us and we want to keep

18:49.560 --> 18:56.360
that you know good process internal so you're gonna um you have this amazing vantage point of

18:56.360 --> 19:01.320
of uh getting to work with a bunch of companies and in some of these heavy industrial industries

19:01.960 --> 19:09.560
um as they think about build by as they think about um sort of growing things up from the grassroots

19:09.560 --> 19:15.560
um and ultimately as they think about the success of extracting value from AI in their in their

19:15.560 --> 19:21.400
company um what have you seen that works and what have you seen that that doesn't work

19:22.120 --> 19:29.000
say at the moment it's a little bit of of cyclists so there is like six oil and gas super mages in

19:29.960 --> 19:34.760
it's a bit of a chicken and egg problem that follow each other so two years ago they were in the

19:34.760 --> 19:43.560
cycle of let's buy everything and just plug it in and it's gonna work so yeah that's a dream um

19:43.560 --> 19:49.560
because their processes are too complicated the data landscape is too complicated you can just say

19:50.200 --> 19:56.280
plug in a solution and it's gonna work so um they learned that the hard way i would say they

19:56.280 --> 20:01.480
blasted a billion of couple of billions of dollars so it hasn't worked so now they made a step back

20:01.480 --> 20:07.080
and says okay we need to find what they call a hybrid approach between what can we actually buy

20:07.080 --> 20:15.880
of the shelf like cloud air solutions um and what do we have to to build ourselves because um

20:16.680 --> 20:23.000
ladies said we need to keep our personality that's what we are doing so it is finding this balance

20:23.880 --> 20:29.560
and then more importantly what they have missed so far they were all looking on building things

20:29.560 --> 20:36.600
but they were not looking at how to derive sustainable value so then does now something new is

20:36.600 --> 20:41.240
coming in where they're all scratching their heads and say what do we have to put in that all

20:41.240 --> 20:47.480
these machine learning solutions can sustainably deliver value now it's not just building it okay

20:47.480 --> 20:53.560
there's one suite of tools and stuff you need there is now a new challenge um how to turn it

20:53.560 --> 20:59.080
from what we always call the playground where you stitch all the stuff together into a scaled

20:59.080 --> 21:07.080
and delivery environment and here is at the moment as not a uniformer's opinion in the market so

21:07.080 --> 21:11.080
if you go to Microsoft they will tell you a if you go to google they tell you be and if you go

21:11.800 --> 21:17.400
to amazon they tell you see and so you be back to field one you don't really know what should i do

21:18.120 --> 21:26.280
so it's it's experimentation how to get it from the lab into a scaled delivery so as

21:26.280 --> 21:30.360
my name is called exact here is at the end of the day i need someone who owns the pnl

21:31.080 --> 21:35.880
and adds the value to it and so does this is especially with off the shelf products in this

21:35.880 --> 21:43.160
business is extremely complicated because they are not specifically made what the what these guys

21:43.160 --> 21:51.400
need so hence they tend to use smart data scientists to build tailored solutions on top of standard

21:51.400 --> 21:57.400
products i want i want to add also like within the off the shelf products there's actually two

21:57.400 --> 22:02.040
categories as well so there's the black box categories meaning we'll do everything for you just

22:02.040 --> 22:08.040
give us the data the business objective and a shitload of money and we will do it for you

22:08.040 --> 22:12.200
there's a company i'm not going to say their name they start with a p and end with a tear and

22:13.800 --> 22:19.880
that's kind of their business model and and i think that works that works when you are only

22:19.880 --> 22:25.320
trying to optimize a sideline part of your business but if they are going to do that for your core

22:25.320 --> 22:29.160
like if you're an insurance company and we're going to optimize your insurance pricing for you

22:29.160 --> 22:33.400
you're mortgaging your future like that's why you should be good at like if there is an area you

22:33.400 --> 22:37.480
should be doing yourself it's that and not giving it away and that's where i think that the

22:37.480 --> 22:44.920
open box approaches are much more appropriate so you both sort of spoke to the need for the core

22:44.920 --> 22:50.440
competency of what it is that your company does and how it makes money that's where you want to

22:50.440 --> 22:55.000
attach your data scientists that's where you want to touch your big AI initiatives that's where you

22:55.000 --> 23:02.840
want to attach your new technology how much are you all seeing in your respective worlds not just

23:03.560 --> 23:10.920
that but also saying how can we transform our business to something new so if we're selling a

23:10.920 --> 23:17.480
product now instead let's sell outcomes as a service if we're selling a service can we do

23:17.480 --> 23:22.120
something else where we're providing better and better value and creating all those positive

23:22.120 --> 23:28.040
feedback loops with data who's doing this in the in the industrial world who's actually fundamentally

23:28.040 --> 23:33.960
changing not just the efficiencies at how they sell and the talent that they they bring on but

23:33.960 --> 23:41.080
who's changing fundamentally who they are and maybe nobody is a fine answer but you know you're

23:41.080 --> 23:47.880
all exposed to this in various different ways so i think one example that i've seen is tv bank

23:48.600 --> 23:53.320
again i don't only stock with them so this is not a advertisement of tv bank but i think i read

23:53.320 --> 23:57.960
articles at least about them sort of open sourcing so on their technology and when you think about

23:57.960 --> 24:02.520
open sourcing technology like you think of like the google's the ubers the facebook's but you don't

24:02.520 --> 24:06.680
necessarily think of like traditional enterprises um and i think there's a reason for that which is

24:06.680 --> 24:12.920
like open sources um sort of a very scary term for a lot of traditional it organizations especially

24:12.920 --> 24:17.400
when you talk about like open sourcing your own technology because there have been incidents like

24:17.400 --> 24:23.000
where somebody made a git commit and like you know like and accidentally like you know committed

24:23.000 --> 24:27.480
their their secret paski or like you know they're you know they're they're public key or something

24:27.480 --> 24:31.800
uh and that has led to consequences right so i think when you talk about some of those uh

24:32.760 --> 24:37.240
external companies like it's really hard for some of these opens like some of these initiatives

24:37.240 --> 24:41.000
to become open source so i think there are probably companies which are reinventing themselves but

24:41.000 --> 24:46.600
there's like a like as i think some of the people i'd call the great filter of of it where you

24:46.600 --> 24:52.040
can't necessarily open source things but i think tdm or like td bank has done some good work there

24:52.040 --> 24:56.280
um and i know dominoes has done some work there as well where they have open source of the technology

24:56.280 --> 25:00.920
yeah so that's maybe an aspect of it but who's you know dominoes is still making money on pizza

25:01.560 --> 25:07.240
who at who else out there in the in the industrial world is actually transforming the way in which

25:07.240 --> 25:12.920
they they make money everybody does like this this ambiased i'm sorry i need to say that first

25:12.920 --> 25:17.240
but this movement about machine learning we all agree it's about the automation of decisions

25:17.240 --> 25:21.960
right it's about learning how humans make decisions at scale and the leverage machine learning

25:21.960 --> 25:29.000
to automate that at a cost and at a frequency that is just not too humanly possible so i'll give you

25:29.000 --> 25:35.160
an example there's many but luftahansa technique for maintaining airlines they automated the task

25:35.160 --> 25:40.280
of diagnosing problems based on the notes that uh that the pilots write the the sensors in the

25:40.280 --> 25:45.320
doors and the wheels and so on fully automated uh right now using this technology uh another

25:45.320 --> 25:49.640
example would be jp morgan where they build a system called coin that was able to replace

25:49.640 --> 25:54.920
lawyers in how they review contracts and write new contracts automatically uh based on historical

25:54.920 --> 25:59.960
decisions that lawyers have made in the past etc etc there's so many of these and so i think

25:59.960 --> 26:05.240
all businesses are changing their way uh the the way that they make money and do business

26:05.240 --> 26:10.760
by leveraging this technology so i think the most fundamental change is i say he's in the oil and gas

26:10.760 --> 26:16.920
business so you've been as it's oil and gas so these guys made their money and that made

26:16.920 --> 26:22.280
fortunes of money of oil and gas but when you look in all the supermages so there's one company

26:22.280 --> 26:28.440
called it equinor or we most know them under start oil they changed their name to call out

26:29.000 --> 26:35.400
we are going away from oil and gas into renewable and that means they have to completely reinvent

26:35.400 --> 26:41.240
their business model so they can no longer operate as they did the last hundred years where they were

26:41.240 --> 26:48.360
living a fortune uh of oil so in that they are in a process of a digital transformation

26:48.360 --> 26:55.000
where they are going now to say hi we are creating hydrogen cyclists to produce energy we started

26:55.000 --> 27:02.840
to uh battery trading so it's like the battery storage becomes the new oil and thus forces them

27:02.840 --> 27:09.160
to to reinvent and nobody has done battery trading so far actively in the market so it's it's

27:09.160 --> 27:16.840
completely new so they have to figure out how do we trade it where do we trade it how do we build

27:16.840 --> 27:24.280
better batteries to store energy longer so these guys are really standing in front of a transformation

27:24.280 --> 27:29.000
which is not just digital it's fundamentally changing what they have done the last hundred

27:29.000 --> 27:34.920
next years is that is that driven by a carrot or a stick in some senses that driven by a

27:34.920 --> 27:40.920
a a sense of existential threat that if they don't change their business model somebody else will

27:40.920 --> 27:47.160
and they'll go away or is that saying hey there's this big opportunity here and we have a we have

27:47.160 --> 27:52.600
a chance to grab part part of this market I mean obviously it's two sides of the same coin but

27:52.600 --> 27:59.640
from a selling perspective is a CEO making a decision uh to go that sort of fundamentally new

27:59.640 --> 28:07.400
direction based on you know that deep concern or that sort of uh other side of it so when you

28:07.400 --> 28:13.640
look at the oil and gas reserves it's not necessary to do that uh not even in the next 50 years

28:13.640 --> 28:19.560
because we saw the doing lifetime extension projects to extend their assets but the next 50 years

28:19.560 --> 28:27.240
so clearly says there is enough uh resources to not do that but they are exposed to a um a

28:27.240 --> 28:34.120
society pressure and and and sustainable and environmental pressure so if you want to be a CEO

28:34.120 --> 28:39.720
of an oil and gas company you don't want to be the dude who is polluting the environment constantly

28:40.280 --> 28:44.520
so um that level of pressure is a set of equity who are changed even their name

28:45.480 --> 28:51.080
so you don't do that lightly and a CEO doesn't take put a lot of money that's cost him 25

28:51.080 --> 28:57.800
million dollar to find a new name so it's not a cheap exercise but it's really here the pressure

28:57.800 --> 29:03.880
by society which made these guys rethink and by rethinking they have to fundamentally change

29:03.880 --> 29:12.920
and that is obviously an opportunity is uh AI an existential threat to Levi's or is it uh an

29:12.920 --> 29:19.000
enhancer that's going to allow you to leap frog for another 150 years um I think we look at it as

29:19.000 --> 29:24.920
an enhancer um you know mainly because you know the the feel that we're in you know again

29:25.720 --> 29:31.960
I I can't see in the next few years Levi's becoming a uh you know the core product being

29:31.960 --> 29:36.760
machine learning technology and not jeans um or or a parallel I should say not jeans only smart

29:36.760 --> 29:41.160
jeans smart well and we are doing a little bit of that right so I think we just did a launch

29:41.160 --> 29:45.880
for our jacquard jacket which is like a connected jacket and like in it has a you know like

29:45.880 --> 29:50.040
the sleeve actually acts almost like a touchscreen in some ways um unfortunately I don't have it on

29:50.040 --> 29:55.240
me today but uh happy to do a demo at some time but uh the point being that you know it's it's not

29:55.240 --> 29:59.560
just about like you know the company itself right it's about like at the end of the day like you know

29:59.560 --> 30:04.680
are we creating value for our customers um and are we making the customer experience better

30:04.680 --> 30:09.320
in some way shape or form so that could be through products which have embedded technology in them

30:09.320 --> 30:13.640
that could be through running a business in a way where you know we are making certain decisions

30:13.640 --> 30:18.520
that might have just led to analysis paralysis if we had a bunch of people doing it so it really

30:18.520 --> 30:23.400
is looked upon as a as a as a way to transform and set the company in the right track for the next

30:23.400 --> 30:29.080
160 years Amber it is an essential it is a potential threat even for Levi's right so the AI

30:29.080 --> 30:34.280
revolution is just like the industrial revolution right if Levi's hadn't adapted to moving from

30:34.280 --> 30:40.680
making uh I'm running Levi's right now to making the the pants using your hand versus using

30:40.680 --> 30:45.400
them with with machines it device would be that right now we all agree on that and the companies

30:45.400 --> 30:50.520
and the countries that were able to embrace the industrial revolution they became the the future

30:50.520 --> 30:56.200
leaders of the of the world and the same exact thing is going to happen with this so um biased again

30:56.200 --> 31:00.840
I was just there because I'm selling the technology that's doing this but every I mean 20 years from

31:00.840 --> 31:04.840
now every single organization that excels at this would be the ones that survives and those that

31:04.840 --> 31:09.480
don't would be the ones that fail and I think Andrew uh share the same feedback and the one

31:09.480 --> 31:15.640
accession as well great so um unfortunately I didn't drum up enough controversy here um but I

31:15.640 --> 31:21.400
want to give the panelists the last sort of 20 seconds each just to um give us their parting

31:21.400 --> 31:25.320
thoughts and what we just discussed and what you think this audience should know going forward

31:26.040 --> 31:31.720
one of the core aspects of this succeeding is the ability to manage workflows that allow machine

31:31.720 --> 31:38.680
learning and AI iterations to happen very quickly from research, AB testing, quality assurance and

31:38.680 --> 31:45.160
security production cycle and repeat and that's one of the very key missions that we are focused

31:45.160 --> 31:52.600
on enabling for our customers. So one of the things that I uh I really we really do as an exercise

31:52.600 --> 31:57.160
is that anytime we come up with a new project or a new project comes on our radar we try to

31:57.160 --> 32:02.440
sort of see where it fits under the umbrella of you know consumer desirability, business

32:02.440 --> 32:07.640
viability and technical feasibility and true magic happens when all three meet where your

32:07.640 --> 32:11.480
data scientists are intellectually challenged by the problem, your customers are guided by the

32:11.480 --> 32:15.640
problem and the business making money from it. So I think those are the best you know most fertile

32:15.640 --> 32:21.560
ground for you know for anyone who's trying to enter the field. Here again last word. So yeah for

32:21.560 --> 32:29.160
me it's very simple um AI becomes the new net uh new when it derives value and when it attracts

32:29.160 --> 32:36.200
them to build the people to create the value. So it's really the fusion of you have a fancy idea

32:36.200 --> 32:43.400
and you can translate this fancy idea in that new value which drives the business but even more

32:43.400 --> 32:48.680
importantly also goes beyond the business into the society and makes the the customers of the

32:48.680 --> 33:04.440
identity happy. Great. Well with that uh let's thank our panelists again. All right everyone

33:04.440 --> 33:10.520
that's our show for today. To learn more about today's show or any of our panelists visit

33:10.520 --> 33:19.000
twemalai.com slash shows. Head over to twemalcon.com slash news to check out twemalcon shorts.

33:19.000 --> 33:41.000
The series of short interviews recorded straight from the twemalcon community hall. Peace.

