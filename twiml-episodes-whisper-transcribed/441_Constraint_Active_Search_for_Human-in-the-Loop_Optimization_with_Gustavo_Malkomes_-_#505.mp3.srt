1
00:00:00,000 --> 00:00:16,880
All right, everyone. I'm here with Gustavo Malcoms. Gustavo is a research engineer at Intel

2
00:00:16,880 --> 00:00:22,880
by way of their recent acquisition of Sigopt. Gustavo, welcome to the Twomol AI podcast.

3
00:00:23,520 --> 00:00:28,080
Thank you very much for having me in the show. Hey, I'm really looking forward to

4
00:00:28,080 --> 00:00:33,680
digging into our interview. But of course, I'd like to have you share a little bit about your

5
00:00:33,680 --> 00:00:38,960
background and give our audience an opportunity to get to know you better. Tell us a little bit

6
00:00:38,960 --> 00:00:46,960
about your journey to machine learning and AI. Awesome, absolutely. Well, first, I'm originally from

7
00:00:46,960 --> 00:00:55,360
Brazil. I'm a computer science by training. And when I did my undergrad, I went to a very good

8
00:00:55,360 --> 00:01:03,040
school in my region. But machine learning wasn't a strong topic. But fortunately, the internet was

9
00:01:03,040 --> 00:01:12,080
very generous with machine learning. We had the opportunity to basically watch Professor

10
00:01:12,080 --> 00:01:22,400
Angel Ng to talk about machine learning on YouTube 12 years ago, I think. So my friends and I

11
00:01:22,400 --> 00:01:28,480
created a study group to study machine learning. And maybe I can say that he was my first

12
00:01:28,480 --> 00:01:35,680
instructor to the topic. After that, I pursue, I work in many machine learning projects. I decided

13
00:01:35,680 --> 00:01:45,680
to do my PhD in the US. I remember checking all the faculties that I could work with that worked

14
00:01:45,680 --> 00:01:52,560
with machine learning and counting how many publications they had on Isomal and Neroops.

15
00:01:54,000 --> 00:01:58,000
I don't recommend this to be a metric to consider when you're choosing between grad schools.

16
00:01:58,960 --> 00:02:04,400
But seven years ago, or something, I was super excited about working with people who actually

17
00:02:04,400 --> 00:02:10,000
did machine learning. And that's one of the things that I actually evaluate. It seems silly to say

18
00:02:10,000 --> 00:02:19,520
now. And then that's how I began my journey into the field. And you ended up for grad school

19
00:02:19,520 --> 00:02:24,640
here in St. Louis at Wash You. Is that right? Yeah, exactly. I went to Wash You under the

20
00:02:24,640 --> 00:02:31,040
supervision of Professor Romanger Net. I was actually very fortunate to work with many intelligent

21
00:02:31,040 --> 00:02:36,880
researchers throughout America here. Of course, my advisor being one of them. But also Professor

22
00:02:36,880 --> 00:02:43,360
Ben Mosley, which is now at CMU, Professor Kylian Weinemberg, who is now at Cornell.

23
00:02:44,800 --> 00:02:49,600
So I was very happy with all the collaborations that I did for out of America here. And I continue

24
00:02:49,600 --> 00:02:56,800
to do so. And you mentioned your school in Brazil, where was that? It was the University, the

25
00:02:56,800 --> 00:03:02,240
Federal University of Seattle. In Brazil, the Federal universities are typically very good.

26
00:03:02,240 --> 00:03:12,080
And that's basically it. And that's North East, like Fort Eliza. Exactly. Good to know that.

27
00:03:13,680 --> 00:03:20,400
We had like the World Cup in my city, too. One of the big games was there. Of course,

28
00:03:20,400 --> 00:03:24,640
as a Brazilian, I don't want to remember the World Cup in Brazil, because we lost.

29
00:03:24,640 --> 00:03:34,880
That's 721 to Germany. Yeah. Nice. Nice. And for your graduate work, what did you study?

30
00:03:34,880 --> 00:03:40,160
What was your dissertation on? Of course, yeah. So as I said, like I worked with different

31
00:03:40,160 --> 00:03:46,880
topics in machine learning. Mass scale, clustering was one of them, multi-agents. But I felt in

32
00:03:46,880 --> 00:03:52,000
love with this topic that I like to call active learning. So my dissertation was about

33
00:03:52,000 --> 00:04:00,160
how we can use active machine learning to create better tools for machine learning itself.

34
00:04:00,160 --> 00:04:06,000
It's kind of like an automated machine learning scenario. And specifically, I think that my

35
00:04:06,000 --> 00:04:11,600
many areas of expertise is how we can actually make decisions under the face of uncertainty.

36
00:04:12,240 --> 00:04:18,080
That's what I typically call active learning. Any kind of decision tool, any kind of decision

37
00:04:18,080 --> 00:04:24,960
problem that we have to solve, where we want to gather new data to accomplish a specific task.

38
00:04:26,160 --> 00:04:34,000
And I've done this for a hearing project, where we improve the performance of a screening test

39
00:04:34,720 --> 00:04:44,160
for audiometry. That was very, very cool. It's under the same setting. To do model selection

40
00:04:44,160 --> 00:04:51,200
with the same pipeline, where you actively select models to train. And of course, with Bayesian

41
00:04:51,200 --> 00:04:58,400
optimization, which is what I've been doing since grad school, but also in my work at SIGOPT,

42
00:04:58,400 --> 00:05:04,800
how we can make effective decisions to optimize functions very, very fast, specifically black box

43
00:05:04,800 --> 00:05:13,920
functions. And we'll be digging into that topic in quite a bit of detail as we talk through your

44
00:05:13,920 --> 00:05:20,880
spotlight paper at ICML, which is beyond the Pareto efficient frontier, constraint active search

45
00:05:20,880 --> 00:05:28,640
for multi-objective experimental design. It is a long name and we'll unpack that name. But before

46
00:05:28,640 --> 00:05:36,720
we do, you reference active learning. You also reference it in the paper. But my sense is that you

47
00:05:36,720 --> 00:05:46,400
think of it in a slightly different way than is commonly construed. So when I think of active

48
00:05:46,400 --> 00:05:55,680
learning, I think of machine learning approach or algorithm that takes an active approach to data

49
00:05:55,680 --> 00:06:06,880
selection so that the model can be trained in a more sample efficient way to put it simply. But

50
00:06:06,880 --> 00:06:14,080
you think of active learning in a much more broad way, I think? Can you kind of connect the two?

51
00:06:14,080 --> 00:06:21,600
Yeah, of course, absolutely. You're perfectly right. Most famous examples of active learning are

52
00:06:21,600 --> 00:06:28,720
when you have a model and you want to select training data to create this model faster.

53
00:06:28,720 --> 00:06:34,720
When I mean by create, I mean, achieve some accuracy faster than if I used a whole data set.

54
00:06:36,160 --> 00:06:41,200
I basically want to make smart decisions about my training samples to avoid waste of resources.

55
00:06:43,120 --> 00:06:48,960
I think in real life, there are like many opportunities where we can use the same setting,

56
00:06:48,960 --> 00:06:56,320
the same tools and the same mechanism to solve more broad problems. So in the case of optimization,

57
00:06:57,200 --> 00:07:03,760
the data that we're going to collect are is basically parameter configurations that we can test

58
00:07:03,760 --> 00:07:10,880
and evaluate if they are helpful for our application, which the goal is not to improve accuracy,

59
00:07:10,880 --> 00:07:16,160
but it will be to, well, it could ultimately be, but typically will be to maximize the function.

60
00:07:16,160 --> 00:07:22,720
So any kind of sequential decision making tool, we can also call sequential decision making,

61
00:07:22,720 --> 00:07:28,240
but train all machine learning. I like to think that active learning is as broad as supervised learning,

62
00:07:28,240 --> 00:07:34,000
reinforcement learning. We can think about this very general framework that any time that we are

63
00:07:34,000 --> 00:07:42,320
collecting data, we can do so in an efficient way to achieve a specific goal. So three examples

64
00:07:42,320 --> 00:07:48,720
are, well, one tip collective learning where your goal is to give information about your model

65
00:07:48,720 --> 00:07:54,560
faster, that ultimately would be the case if I'm trying to learn this decision boundary,

66
00:07:54,560 --> 00:08:00,720
very, very fast, typical case, Bayesian optimization where we want to optimize functions.

67
00:08:00,720 --> 00:08:06,080
So the data is the parameter configurations and the goal is to find highest values.

68
00:08:06,080 --> 00:08:11,840
And another example is drug discovery where you want to find new components or biology,

69
00:08:12,800 --> 00:08:20,160
you want to find new chemicals to achieve some properties and or perhaps even more broadly

70
00:08:20,160 --> 00:08:27,600
experimental design where you want to understand the whole of the physical phenomena very, very fast.

71
00:08:28,160 --> 00:08:32,480
You can say that active learning is kind of science more generally. We are all,

72
00:08:32,480 --> 00:08:38,640
or every time building models and collecting new data to validate those models. So that's kind of

73
00:08:38,640 --> 00:08:44,160
my general idea for that. I know that I talk about different subjects, but I'm happy to clarify

74
00:08:44,160 --> 00:08:56,000
any of them. You mentioned the, you mentioned this chemical engineering scenario example,

75
00:08:56,000 --> 00:09:04,480
and that was one of the background problems or motivations for this paper. Can you tell us a

76
00:09:04,480 --> 00:09:08,800
little bit about the problem that you were trying to solve that led to the work discussed in the

77
00:09:08,800 --> 00:09:15,280
paper? Yeah, of course. So first, this is a joint work with my colleagues at TIGOPT, Harvey Chen,

78
00:09:15,280 --> 00:09:21,200
Eric Lee, and Michael McCourt. In Harvey and Mike, they had this collaboration with

79
00:09:21,200 --> 00:09:28,160
members of the University of Pittsburgh, the laboratory of advanced materials at Pittsburgh,

80
00:09:28,160 --> 00:09:35,120
directed by Professor Paul Lu at the University of Pittsburgh, and they have been collaborating

81
00:09:35,120 --> 00:09:41,520
with this idea of creating new materials using machine learning. It's specifically, they are

82
00:09:41,520 --> 00:09:49,760
interested on creating new types of glasses that can improve the performance of, for example,

83
00:09:49,760 --> 00:09:58,400
solar panels. The idea is to have durable, anti-reflective, anti-soiling, self-cleaning glasses

84
00:09:58,400 --> 00:10:06,000
for solar modules. Basically, the problem is you want to improve the efficiency of solar panels

85
00:10:07,200 --> 00:10:13,680
by changing the properties of the glass. You don't want, for example, glass or reflection in the glass,

86
00:10:13,680 --> 00:10:20,560
because the lights will, the light bulb bounces, will basically bounce off of the glass, and you

87
00:10:20,560 --> 00:10:27,280
basically will be losing energy. Also, if the glass is dirt, that's a problem too, because it

88
00:10:27,280 --> 00:10:34,720
blocks the light to coming to the solar panel, and you also lose efficiency. What the researchers

89
00:10:34,720 --> 00:10:40,960
from the University of Pittsburgh they work with is creating like small structures, nano

90
00:10:40,960 --> 00:10:48,800
structures on the top of this glass, to change the properties of light, and therefore,

91
00:10:48,800 --> 00:10:55,600
improve the performance of the solar panel. The idea is, and this is very common in many

92
00:10:55,600 --> 00:11:02,080
different material sciences and other types of science work, is they have numerical simulations,

93
00:11:02,080 --> 00:11:07,280
they construct designs, they can fabricate designs using computer simulation,

94
00:11:07,280 --> 00:11:17,760
and using the software they can undercentrate ops for ultimately creating a structure in real life.

95
00:11:18,400 --> 00:11:23,120
What we have observed is that this is very different. It's very different to create

96
00:11:23,920 --> 00:11:28,000
new material in the computer versus creating a new material in the real life.

97
00:11:28,960 --> 00:11:34,000
And the reason for that is, in the numerical simulation, we don't have all the properties.

98
00:11:34,000 --> 00:11:39,040
We cannot perfectly simulate everything. There's a correlation. We can't get a lot of this,

99
00:11:39,040 --> 00:11:43,760
but ultimately, the equipment that we're going to use to produce the materials will be

100
00:11:43,760 --> 00:11:50,640
slightly different. We don't have like infinite precision, or something different happens in real

101
00:11:50,640 --> 00:11:57,440
life, because that's how real life is. That being that the simulation is producing a set of candidates,

102
00:11:57,440 --> 00:12:02,320
but you ultimately have to fabricate some small number of those candidates and see how they

103
00:12:02,320 --> 00:12:09,040
perform in the real world. Perfect. That's exactly it. We have this human in the loop. That's a very

104
00:12:09,040 --> 00:12:16,400
common term right now that basically requires the machine learning tool to assist the decisions

105
00:12:16,400 --> 00:12:21,840
that the human expert that knows everything about the problem, knows everything about the domain,

106
00:12:21,840 --> 00:12:28,000
can ultimately do and select. I think that's the main inside that we want to bring to this

107
00:12:28,000 --> 00:12:35,280
paper, talking in a real high level. There is a development scenario, there is a production

108
00:12:35,280 --> 00:12:41,600
scenario, and there's probably a discrepancy. And ultimately, there is a human in the process,

109
00:12:41,600 --> 00:12:48,240
doing supervision of the whole decision making, and being powered by the experimentation process

110
00:12:48,240 --> 00:12:54,000
that we do offline, but which eventually will be very costly to do in real life.

111
00:12:54,000 --> 00:13:05,920
Let's maybe return to the title of the paper and start to unpack some of that so we can dig deeper

112
00:13:05,920 --> 00:13:11,680
into what you've actually done. Again, the paper is beyond the Pareto efficient frontier

113
00:13:11,680 --> 00:13:17,840
constraint active search for multi-objective experimental design. It sounds like the problem

114
00:13:17,840 --> 00:13:25,120
that you're seeking to tackle is multi-objective experimental design. How does that relate to the

115
00:13:26,160 --> 00:13:36,480
scenario that you just outlined for the materials? Yeah, so material, experimental design is basically

116
00:13:36,480 --> 00:13:43,360
the field that do with smart decisions about designs, and the designs could be like many different

117
00:13:43,360 --> 00:13:49,280
things. It could be actually a whole experimentation pipeline in a lab. In our case, just to give like

118
00:13:49,280 --> 00:13:54,000
think, just to give with a real example, it's going to be the structure that we want to really

119
00:13:54,000 --> 00:14:02,240
create on top of the class. The column, the box size, all the properties that we can actually

120
00:14:02,240 --> 00:14:06,720
use to create those structures. That's the experimental design part.

121
00:14:06,720 --> 00:14:16,000
Multi-metric, it's because in many problems in real life, it's very, very hard to find one thing

122
00:14:16,000 --> 00:14:21,440
that we care about. So there are competitive objectives. If we change all the light to reflect

123
00:14:21,440 --> 00:14:31,600
on this glass, another property will be different. Transparency, oil contact, cleanness, all those

124
00:14:31,600 --> 00:14:37,440
things really related to the subject will change. And ultimately, they will be competitive.

125
00:14:38,560 --> 00:14:42,960
That, what typically makes the optimization problem a little bit harder.

126
00:14:44,000 --> 00:14:50,720
And one thing to highlight here, which is very general, is the way that we're doing experimentation

127
00:14:50,720 --> 00:14:56,960
is really for smart decisions. We don't have access. We are solving an optimization problem,

128
00:14:56,960 --> 00:15:02,880
which is black box. We will really run the simulation to get an output. But we don't have access

129
00:15:02,880 --> 00:15:09,520
to gradients, for example. So it's really like a black box that we put inputs and we receive

130
00:15:09,520 --> 00:15:17,040
outputs back. We want to design experiments, basically designing put configurations that will give

131
00:15:17,040 --> 00:15:22,000
good results on the outside here, on the the Y-values. If you're talking about the optimization,

132
00:15:22,000 --> 00:15:28,320
we're trying to optimize, minimize or optimize one of those goals. Now, the Pareto efficient

133
00:15:28,320 --> 00:15:36,720
frontier, it's basically how we try to solve multi optimization problems, multi metric optimization

134
00:15:36,720 --> 00:15:48,080
problems. We traditionally want to find output values that can dominate the other ones.

135
00:15:48,080 --> 00:15:53,840
The hypothesis here is that we cannot compare the two metrics. For example, risk and return,

136
00:15:53,840 --> 00:16:01,200
if we're talking about finance. And there's no really like solution for this. It's really

137
00:16:01,200 --> 00:16:08,080
dependent on the user to decide the level of risk and the level of return it's willing to take.

138
00:16:08,960 --> 00:16:14,160
So in that sense, all the configurations that we can return to the customers that

139
00:16:14,160 --> 00:16:21,680
dominate the other ones. So if I can improve my return without reducing the risk, that's better

140
00:16:21,680 --> 00:16:26,320
than a suboptimal configuration that has the same risk level, but a lower return.

141
00:16:26,960 --> 00:16:31,280
I would want this, it doesn't make sense. So I would actually have the dominate solution,

142
00:16:31,280 --> 00:16:36,000
which has a higher return, but the same level of risk. That's how we construct the Pareto

143
00:16:36,000 --> 00:16:45,040
efficient frontier. And this makes a lot of sense if you're probably choosing maybe stocks. But in

144
00:16:46,400 --> 00:16:53,440
problems that we're trying to understand the metric values and the parameters, we really want to

145
00:16:53,440 --> 00:16:59,920
focus on the search aspect, what I mean by this. For a scientist, for example,

146
00:16:59,920 --> 00:17:06,160
they will be very happy if we give them a material that has very nice properties.

147
00:17:06,720 --> 00:17:13,040
But they will be very confused if we change the parameters that create this design,

148
00:17:14,080 --> 00:17:22,640
it's lily, and the results is really bad. So they're looking for really a broader sense of what's

149
00:17:22,640 --> 00:17:27,280
happening here, not only with the metric values, but also with the parameters. Ultimately,

150
00:17:27,280 --> 00:17:34,160
they want these stable parameters that can lead to consistent results. Why? Because as I said,

151
00:17:34,720 --> 00:17:41,520
the production and the development and the production settings won't be a perfect match.

152
00:17:42,160 --> 00:17:48,080
They really want consistent results. That's the motivation for why we're talking about an

153
00:17:48,080 --> 00:17:54,240
alternative to this multi-objective solution for experimental design. It's because people care

154
00:17:54,240 --> 00:17:59,680
about both the metric values, but the parameter values. They want this stability. They want to

155
00:17:59,680 --> 00:18:09,520
understand the problem they're trying to solve. Let me try to replay that so that I make sure I'm

156
00:18:09,520 --> 00:18:16,800
understanding it and we're all on the same page. You've got this note of the Pareto,

157
00:18:16,800 --> 00:18:21,840
Efficient Frontier. We know it from finance and economics and problems like that. And that says

158
00:18:21,840 --> 00:18:28,560
that in the case of a two-dimensional relationship, there's a line that is your

159
00:18:29,520 --> 00:18:40,080
optimal trade-off among these values. And what you're suggesting is that in the real world,

160
00:18:40,080 --> 00:18:47,440
for example, when you're designing a material, a value on this Pareto, Efficient Frontier,

161
00:18:47,440 --> 00:18:58,000
might be optimal from the perspective of the metric, but it might be unstable. You know,

162
00:18:58,000 --> 00:19:07,360
if we think about kind of the chart of the optimal, like a curve, it might be sitting on a spike.

163
00:19:07,360 --> 00:19:15,680
And so if you shift one of your parameters, your metric might drop off precipitously,

164
00:19:15,680 --> 00:19:22,560
whereas something that is theoretically less optimal might be sitting on a broader base.

165
00:19:22,560 --> 00:19:30,800
And I think ultimately, the result is it would be easier to produce in the real world because

166
00:19:30,800 --> 00:19:37,920
it's not quite as unstable. Is that the idea? That's the idea. If you think about, like,

167
00:19:38,800 --> 00:19:42,720
I think when we're talking about optimization, it's very common to think about climbing a mountain,

168
00:19:42,720 --> 00:19:46,720
right? Of course, in our scenario here, we don't have derivatives,

169
00:19:47,440 --> 00:19:53,360
but we can theoretically find blocks. Yeah, because it's a black box, but you can theoretically

170
00:19:53,360 --> 00:19:59,200
think about a surface of function values that exist. And we can pretend that this is like a mountain.

171
00:20:00,240 --> 00:20:03,360
And the metric values will be basically the height of this mountain.

172
00:20:04,000 --> 00:20:10,560
Right. So in a multimetric problem, it's kind of like we're trying to find the optimal of

173
00:20:10,560 --> 00:20:16,880
the function values between two mountains, let's say there is a mountain number one, which is one

174
00:20:16,880 --> 00:20:24,800
metric, there's a mountain number two, which is the second metric. In a multi metric optimization

175
00:20:24,800 --> 00:20:28,720
problem, we want to find really the peak of the mountain, the highest value possible.

176
00:20:29,520 --> 00:20:35,520
And the Pareto-efficient Frontier will be basically aligned between those two mountains

177
00:20:35,520 --> 00:20:42,400
on paramere space. That's exactly the Pareto-efficient Frontier on metric values, how they will be

178
00:20:42,400 --> 00:20:47,760
translated to the paramere space. It's going to be a line. If I navigate towards the outer mountain,

179
00:20:47,760 --> 00:20:51,600
I'm going to reduce the metric values here, but I'm going to improve the metric values here.

180
00:20:52,480 --> 00:20:56,320
Okay. So what we are trying to, yeah, to jump in there, the

181
00:20:57,520 --> 00:21:03,680
dimensionality of the parameter space is like the numbers, the number of dimensions of your mountain

182
00:21:03,680 --> 00:21:08,400
essentially, and then the number of metrics is the number of mountains. In some sense, yes.

183
00:21:08,960 --> 00:21:13,280
Okay. That's a very good analogy. Yeah. So in this case here, we're talking about two and two,

184
00:21:14,080 --> 00:21:20,080
but it could be, you know, in a more, like in a higher, in a more complicated surface

185
00:21:20,880 --> 00:21:28,880
in the world, will be like a three-dimensional shape. But anyway, the point is, if we have two

186
00:21:28,880 --> 00:21:35,280
metrics, you know, there is one optimal value here, another optimal value here. The Pareto-efficient Frontier

187
00:21:35,280 --> 00:21:42,720
was going to be aligned that trades those two off. Now, what we are saying is, okay, this is only true

188
00:21:42,720 --> 00:21:47,360
during our development setting. You find the optimal values here, doing your numerical simulation.

189
00:21:48,080 --> 00:21:55,760
But what if the mountain shifts a little bit? The line was going to be completely different. So,

190
00:21:55,760 --> 00:22:02,080
do I really want to return to the to the expert, to the human, only the points that could be,

191
00:22:02,800 --> 00:22:08,480
you know, sub-optimal in the real life, because the the mountains can shift a slightly.

192
00:22:09,200 --> 00:22:13,760
The answer is no. We probably want to give them like a more information. We want to give them

193
00:22:13,760 --> 00:22:19,680
enough information so that even if the mountains change a little bit, you will still be comfortable

194
00:22:19,680 --> 00:22:25,520
with the results that you get. Does that make sense? Yeah, I guess it raises a question for me.

195
00:22:25,520 --> 00:22:37,360
Are we trying to, is the idea fundamentally that we're going to be less restrictive in the values

196
00:22:37,360 --> 00:22:43,840
that we return? We're going to be looser and allow the human and elope to, you know, because we

197
00:22:43,840 --> 00:22:48,720
know there's a human and elope, they can determine ultimately what's the best point for them. Or is it

198
00:22:48,720 --> 00:22:57,680
that somehow that the algorithm that you've created also incorporates stability and returns

199
00:22:57,680 --> 00:23:05,440
better points that aren't on the Pareto efficient frontier? That's a distinction I'm getting

200
00:23:05,440 --> 00:23:09,920
on. Yeah, it's definitely different. I totally agree with that. And I would say it's the former.

201
00:23:10,480 --> 00:23:14,560
Okay. In the let the the second option, the latter could be our next paper.

202
00:23:14,560 --> 00:23:22,960
But it's more on the former. In the sense that we do we will do exactly what you describe. We're

203
00:23:22,960 --> 00:23:30,000
going to lose the definition of best to not really the peak and top of the mountain. But you know,

204
00:23:30,000 --> 00:23:35,760
to altitude that is good enough. So we're going to have like the whole shape of the top of the

205
00:23:35,760 --> 00:23:41,120
mountain. And we're going to offer this to the user somehow. That's the part that it's the problem

206
00:23:41,120 --> 00:23:46,320
formulation aspect of this. We are generalizing something called Bayesian optimization,

207
00:23:46,320 --> 00:23:51,520
which really cares about the highest values and the experimental design, which wants to understand

208
00:23:51,520 --> 00:23:57,360
the whole mountain, all the shapes and you know configurations of the mountain.

209
00:23:58,480 --> 00:24:05,120
Sorry. Constrain active search, which is exactly the problem that we are proposing to solve.

210
00:24:05,120 --> 00:24:10,720
It's really a search problem in the sense that we want to find structures in the parameter space

211
00:24:11,760 --> 00:24:17,360
in the executive learning pipeline, which are constrained, constrained by metric values.

212
00:24:18,000 --> 00:24:24,480
Specifically in the paper, we say that there is a region of satisfaction or a sex,

213
00:24:24,480 --> 00:24:31,920
sex, sex factory region where it's the parameter configurations that lie above the metric values.

214
00:24:31,920 --> 00:24:38,080
You can also think about this feasible region, but typically feasibility means that we have

215
00:24:38,080 --> 00:24:43,120
constraints on the parameters. And for some reason, we don't want the parameters that are not

216
00:24:43,120 --> 00:24:48,960
feasible, right? Here, we are really losing the problem from the optimization to something that

217
00:24:48,960 --> 00:24:55,600
is not the best, but it's a set set set, it's a set's fight of constraints. So feasibility typically

218
00:24:55,600 --> 00:25:01,040
speaks to the parameters satisfaction. In this case, you're more speaking to the metric or the

219
00:25:01,040 --> 00:25:06,880
objective. Exactly. We want to load the definition of what is best on the metrics. And again,

220
00:25:06,880 --> 00:25:13,280
this is black box. We don't have this beforehand. So again, with the example of the mountain, we want

221
00:25:13,280 --> 00:25:18,080
the whole shape of the top of the mountain, not necessarily the peak best value.

222
00:25:19,680 --> 00:25:26,960
And thinking about it in the context of the mountain, what's the relationship between

223
00:25:26,960 --> 00:25:37,520
the satisfying construct that you're creating and the idea of global optimal versus local

224
00:25:37,520 --> 00:25:42,480
optimal, that kind of thing? Is the thing that connects those the idea of stability that we talked

225
00:25:42,480 --> 00:25:51,120
about earlier? In some sense, yes. Because the optimal values will be within the satisfactory

226
00:25:51,120 --> 00:25:59,120
region. So we're just expanding the notion of what it's good to more values based on the constraints

227
00:25:59,120 --> 00:26:05,840
that the user gave us on the metric values. So for example, suppose that we want to find a

228
00:26:05,840 --> 00:26:14,880
high-performing machine learning models. And we care about accuracy, but also inference time.

229
00:26:14,880 --> 00:26:21,760
I want to give you a list of different models and diversity he hears the key for a constraint

230
00:26:21,760 --> 00:26:29,280
active search that have that satisfy your constraint on accuracy above 80% and inference time,

231
00:26:30,800 --> 00:26:37,920
less in a minute, let's say, hopefully way less than that. But I'm going to give you an option,

232
00:26:37,920 --> 00:26:41,600
the solution for this problem is going to be a list of options that you can trade them off,

233
00:26:41,600 --> 00:26:48,320
both in terms of the metric values, but also one of the choices of hyperparameters that you have.

234
00:26:49,840 --> 00:26:56,160
For example, number of trees, if you're talking about exuboost, and all kind of like

235
00:26:57,040 --> 00:27:01,520
any kind of parameter that you think is important for creating a machine learning model,

236
00:27:01,520 --> 00:27:03,120
which are the hyperparameters.

237
00:27:03,120 --> 00:27:12,400
Okay, okay. And so you've created this, you've kind of redefined or defined a new problem

238
00:27:13,440 --> 00:27:19,760
constrained active search. Do you also share any insights into how to solve the problem?

239
00:27:19,760 --> 00:27:25,280
Yeah, absolutely. That's the main difference between the workshop paper that we have published

240
00:27:25,280 --> 00:27:31,600
like a couple of months ago, less here. And the, you know, in a full publication that I

241
00:27:31,600 --> 00:27:39,360
said, well, it's the fact that we have a solution for this problem. So I hope it's very clear

242
00:27:39,360 --> 00:27:44,960
that like why I'm stressing the problem is because it's a different mentality. We're changing the

243
00:27:44,960 --> 00:27:50,880
focus from getting the best possible values to getting high performing values, high performing

244
00:27:50,880 --> 00:27:57,840
models, high performing designs, which means that I can accept in a continuous space a bunch of

245
00:27:57,840 --> 00:28:06,960
new points. And if I, I can change slightly the same configuration and or parameter and get

246
00:28:06,960 --> 00:28:12,880
the same results. So that's something that it doesn't make sense mathematically. So you want to

247
00:28:12,880 --> 00:28:17,600
incorporate something which is diversity. And I think this is really, really important for many

248
00:28:17,600 --> 00:28:23,680
real life applications, especially in, and I can talk more about this next in the context of

249
00:28:23,680 --> 00:28:30,480
developing machine learning models, developing real materials in real life. But to the technical

250
00:28:30,480 --> 00:28:36,400
aspect of the work, we use something called Bayesian decision theory to derive an algorithm

251
00:28:36,400 --> 00:28:42,640
for solving this problem. And as I said, the main property of this problem is we want to find a

252
00:28:42,640 --> 00:28:49,840
set of solutions in continuous space. So we want those solutions to be different in primary space.

253
00:28:49,840 --> 00:28:56,080
We don't want to lead to the same design. If I show this to a scientist, you know, a box of,

254
00:28:56,080 --> 00:29:03,520
you know, this nano structure that I've changed like one nanometer up or or left or, you know,

255
00:29:03,520 --> 00:29:08,880
the cone in the height of the cone or the shape. Lively they would say like, yeah, this is the

256
00:29:08,880 --> 00:29:13,920
same thing. I don't care about that. I can't even produce this difference. That's also important.

257
00:29:13,920 --> 00:29:20,560
But anyway, the way that we focus on solving tackling this problem is defining something called

258
00:29:25,360 --> 00:29:32,480
utility function, which defines how our active learning, active search algorithm

259
00:29:33,360 --> 00:29:42,560
will select the next configuration. So to give you an example in optimization, what we typically

260
00:29:42,560 --> 00:29:50,160
care is if I have a configuration that has this value here, I care about new configurations that

261
00:29:50,160 --> 00:29:57,200
can improve the value that I have observed. So this leads to a policy that is expected improvement.

262
00:29:57,200 --> 00:30:05,280
How much I can improve over over the last of function value. We don't care about the best values

263
00:30:05,280 --> 00:30:10,480
per se. We care about two things in this problem. We want to satisfy the constraints. That's the very

264
00:30:10,480 --> 00:30:17,840
first important thing. And two, we want the solutions, the parameters that we select, the designs

265
00:30:17,840 --> 00:30:25,120
that we select to be different. So if I choose two new configurations that satisfy the constraints

266
00:30:25,120 --> 00:30:30,160
but they're very close to each other, I don't want this. So we define something called the

267
00:30:30,160 --> 00:30:37,360
neighborhood of a point. So any configuration that we choose in primary space will basically

268
00:30:37,360 --> 00:30:44,000
induce a volume on primary space. And this volume is exactly what I want to increase. I want to

269
00:30:44,000 --> 00:30:50,640
increase the coverage of my configurations where coverage I'm defining as the volume on

270
00:30:50,640 --> 00:30:57,360
primary space that is potentially above the threshold. That's something complicated. I

271
00:30:57,360 --> 00:31:02,640
definitely recommend you to see the details or your audience to see the details on the paper.

272
00:31:02,640 --> 00:31:08,640
But that's the intuition. We want points above the constraints that satisfy all the constraints.

273
00:31:08,640 --> 00:31:13,680
And we want points that are not too close to each other so that they can lead to diversity.

274
00:31:14,800 --> 00:31:21,760
And you said that this is a complicated part but when you talk about the threshold is that a

275
00:31:21,760 --> 00:31:37,120
threshold, meaning the union of the volumes around the individual points and the degree to which

276
00:31:37,120 --> 00:31:44,560
that coverage your entire space or as the threshold specific to each point in the primary space.

277
00:31:45,840 --> 00:31:49,920
The threshold that I mentioned was specifically to the metric values.

278
00:31:49,920 --> 00:31:55,840
Okay. So basically is the level if you go back to the mountain again.

279
00:31:55,840 --> 00:32:00,640
Right. And I'm going to use my fingers here to point out and I definitely recommend you to check

280
00:32:00,640 --> 00:32:08,640
out the paper which we have better visualizations for that. But if we talk about the top of the

281
00:32:08,640 --> 00:32:13,920
mountain, we are chopping off the top of this mountain in some region. So the shape could be

282
00:32:13,920 --> 00:32:21,200
really pointy or the shape could be like really wide. So the threshold really defines the shape

283
00:32:21,200 --> 00:32:29,520
here, the level that we want to cut off the mountain. Now the the coverage that I was talking

284
00:32:29,520 --> 00:32:34,960
about is really like if I want to place a point here in this side of the this is funny.

285
00:32:34,960 --> 00:32:39,040
If I want to place a point on the top of this, I basically want to solve a packing problem.

286
00:32:39,040 --> 00:32:42,480
I want to know how many configurations I can place on the top of this mountain.

287
00:32:42,480 --> 00:32:45,680
Got it. In the way that it covers the whole

288
00:32:46,320 --> 00:32:49,520
primary space. Got it. Got it. Does that make sense?

289
00:32:52,080 --> 00:32:58,640
Packing or a tessellation, you want to pick your points to maximize the coverage of the

290
00:33:00,240 --> 00:33:03,760
I guess this part of the mountain that you've cut off. Exactly. Exactly.

291
00:33:04,400 --> 00:33:10,320
And you define the points by some kind of radius around the points.

292
00:33:10,320 --> 00:33:17,040
Right. In our algorithm specifically, we have a parameter that we call radios are

293
00:33:17,760 --> 00:33:24,800
which defines in your application, how much you you care about distance. So

294
00:33:25,680 --> 00:33:29,680
basically this parameter is telling me that if you find two configurations that are too close

295
00:33:29,680 --> 00:33:33,280
according to this distance, that's exactly what this parameter is measuring. I don't care

296
00:33:33,280 --> 00:33:37,840
about this. This does increase my knowledge about the problem. Yeah. So those radios define the

297
00:33:37,840 --> 00:33:45,360
minimal level of proximity that you can have between two points. And again, the top of this

298
00:33:45,360 --> 00:33:50,720
mountain, this region that we want to cover is really the region of parameter configurations

299
00:33:50,720 --> 00:33:55,840
that yields high performing values. Right. Right. Right. And

300
00:33:59,200 --> 00:34:05,760
is there just out of curiosity, I'm wondering to what degree you could

301
00:34:05,760 --> 00:34:12,480
characterize the total volume of the top of the mountain. And could you

302
00:34:14,800 --> 00:34:20,400
could you like back your way into R by saying you want, you know, 20 points and you know the

303
00:34:20,400 --> 00:34:25,600
volume of the top of the mountain. And so like divide the volume of the mountain by R.

304
00:34:26,160 --> 00:34:30,960
I'm sorry, divide the volume of the mountain by the number of points and kind of back into your

305
00:34:30,960 --> 00:34:35,200
R value. Or do we are there things there that we don't know or can't figure out or are really

306
00:34:35,200 --> 00:34:40,160
difficult. Right. That's an excellent question. But the setting is we don't know.

307
00:34:41,120 --> 00:34:47,600
Basically, we construct, um, probabilistic models that talk about the surfaces of the

308
00:34:48,320 --> 00:34:54,400
objective functions that we want. Basically, and the surrogate model, the probabilistic model that

309
00:34:54,400 --> 00:35:01,440
we have is going to give us a notion of uncertainty of the shape of that we are trying to solve for.

310
00:35:01,440 --> 00:35:06,560
So nothing we didn't know for sure. We are actually discovering this through experimentation.

311
00:35:06,560 --> 00:35:13,120
We are increasing our knowledge or our ability to model the surface of the metric, metric values.

312
00:35:14,320 --> 00:35:20,240
And also really the region of satisfaction. So in reality, the utility that I just described

313
00:35:20,240 --> 00:35:27,920
is true, fixed the mountain shape, if you will. But what we really implement is the expected

314
00:35:27,920 --> 00:35:33,280
gain in utility, which takes in consideration our uncertainty around the surface.

315
00:35:34,720 --> 00:35:40,240
Okay. So if you're asking about how many points I can place, it's really through experimentation.

316
00:35:41,120 --> 00:35:44,640
The more points you give us, the better to solve the problem.

317
00:35:46,160 --> 00:35:52,400
There is a rule of thumb of, you know, 20 to 30 times the dimension of gain put.

318
00:35:52,400 --> 00:35:59,360
It's a good number. Um, if we really have good priors to match our problem, but theoretically,

319
00:35:59,360 --> 00:36:02,400
this could be way, you might need more, way more points.

320
00:36:04,000 --> 00:36:11,040
And you've mentioned Bayesian optimization previously. And you know, now we're talking about surrogate

321
00:36:11,040 --> 00:36:17,280
models and priors. Can you talk about where Bayesian optimization fits into this and how?

322
00:36:17,920 --> 00:36:19,520
And where the surrogate models come from?

323
00:36:19,520 --> 00:36:28,240
Exactly. Yeah, absolutely. So I think it's, that's, let's think about like the complexity of those

324
00:36:28,240 --> 00:36:36,320
problems. If I want to solve a single problem, just one metric, I'm going to do Bayesian optimization

325
00:36:36,320 --> 00:36:41,280
to find the highest, the best values, what I'm going to do. I'm going to create a surrogate model

326
00:36:42,480 --> 00:36:47,440
that does this inference over the function values that I haven't observed yet. And I'm going to

327
00:36:47,440 --> 00:36:53,680
create an acquisition function, which, as I said, could be, it's basically a policy that tell us

328
00:36:53,680 --> 00:37:00,560
which point I'm going to choose next. When I'm talking about multi-matric problems, I can also

329
00:37:00,560 --> 00:37:04,880
use Bayesian optimization. I can also use Bayesian optimization with constraints. But again,

330
00:37:04,880 --> 00:37:09,520
everything that I'm focused here is to construct surrogate models, one for each metric.

331
00:37:09,520 --> 00:37:18,800
And trying to find the hypervolume of the Pareto Frontier. Again, the Pareto Frontier is this region

332
00:37:18,800 --> 00:37:25,120
of dominate points. The hypervolume, it's a metric that tells me if I increase the, the,

333
00:37:25,120 --> 00:37:30,240
the values, I will be doing a better job at finding the Pareto Frontier.

334
00:37:32,080 --> 00:37:38,080
The next step for this is, at least in my mind, well, there is a different problem that is

335
00:37:38,080 --> 00:37:42,800
important to highlight, which is called level set estimation. It's when I'm not interesting on the,

336
00:37:43,760 --> 00:37:51,360
the best values per se, but I'm interesting on finding the threshold really where the function

337
00:37:51,360 --> 00:37:56,720
values would change from the level that I stipulate, basically the constraints in this case.

338
00:37:57,520 --> 00:38:02,240
What we argue is constraint active search. It's a generalization of this.

339
00:38:02,240 --> 00:38:09,920
In hindsight, if you knew the best value, something that we don't know, but if you place the

340
00:38:09,920 --> 00:38:15,520
highest value, highest function value on the constraint active search formulation, we would

341
00:38:15,520 --> 00:38:20,880
recover Bayesian optimization. Because again, the definition will be just the peak of the mountain.

342
00:38:20,880 --> 00:38:25,280
I just want to return the best values. So I recover Bayesian optimization with this

343
00:38:25,280 --> 00:38:32,160
constraint active search formulation. The opposite of this is if I knew the minimum value of all

344
00:38:32,160 --> 00:38:38,880
the metrics, I could plug this in in my constraints in constraint active search, and I will recover

345
00:38:38,880 --> 00:38:44,160
a problem that is experimental design. It's really, I want to know the function values everywhere.

346
00:38:45,760 --> 00:38:49,520
Constraint active search is something in the middle. You choose the thresholds the way that you wish.

347
00:38:49,520 --> 00:38:55,280
And of course, we recommend you to do so in a conservative way because everything about the

348
00:38:55,280 --> 00:39:02,640
function we are learning on the fly. So if you start with, yeah, I was just going to say I'm not

349
00:39:02,640 --> 00:39:08,160
sure. I fully follow that, but I think in essence, what you're saying is that there's a relationship

350
00:39:08,160 --> 00:39:15,680
between this problem that you've articulated here constraint active search and other things that

351
00:39:15,680 --> 00:39:22,880
we've studied for a long time, Bayesian optimization, level set up estimation and experimental design.

352
00:39:24,640 --> 00:39:27,520
That's a digest. Yeah. Okay. Okay.

353
00:39:30,960 --> 00:39:41,360
And first, did we get through the kind of the explanation of the mechanism? I think we

354
00:39:41,360 --> 00:39:50,160
did get through it at least conceptually in talking about the volumes. If there's any pieces that

355
00:39:50,160 --> 00:39:56,400
we have not covered, jump in with those, but I'm starting to think about, okay, how do you

356
00:39:57,600 --> 00:40:05,040
assess performance here and measure the effectiveness of the method and what that even

357
00:40:05,040 --> 00:40:15,200
means in this context? Precisely. So for the algorithm, really, it's hard to talk more in details

358
00:40:15,200 --> 00:40:20,480
like in more details about it because you have to know some mathematical definitions of neighborhood.

359
00:40:20,480 --> 00:40:25,120
I think we covered the high level idea in a good sense, which is really trying to solve this

360
00:40:25,120 --> 00:40:32,800
packing problem in the high performing region of the primary space. Got it. But ultimately, we define

361
00:40:32,800 --> 00:40:38,800
utility function and we do something that we do in Bayesian decision theory. We select the action

362
00:40:38,800 --> 00:40:45,440
that maximizes my expected utility. And the utility is this volume that we define. The uncertainty

363
00:40:45,440 --> 00:40:52,640
on this utility is on the real region of satisfaction, which is, you know, the thresholds

364
00:40:53,920 --> 00:40:58,240
because we're using probabilistic models, we can compute what is the probability of any configuration

365
00:40:58,240 --> 00:41:06,240
to lie above the thresholds. And that's defined basically as a whole set of points in expectation

366
00:41:06,240 --> 00:41:12,880
that will be within the region of satisfaction. Okay. What was your next question? Sorry.

367
00:41:13,760 --> 00:41:20,800
So then what's what does evaluation look like? Exactly. So in our experiments, we were we tried to

368
00:41:20,800 --> 00:41:30,320
be very honest. We didn't try to, but basically we had multiple ways of looking how about the

369
00:41:30,320 --> 00:41:38,480
quality of those results. So we consider like four metrics. One of them is just the number of positive

370
00:41:38,480 --> 00:41:44,480
points that you get, the number of points above the threshold. If your problem is really,

371
00:41:44,480 --> 00:41:48,880
really difficult, that's something that you might care. But if you just optimize this metric,

372
00:41:48,880 --> 00:41:54,000
you might not get diversity, which I think I said, it's a very important thing in our problem.

373
00:41:54,000 --> 00:41:59,520
The second, the second angle that we can look at this is really what about the hypervolume?

374
00:42:00,480 --> 00:42:03,680
What about the quality of the points that we get above the threshold? Are they

375
00:42:04,240 --> 00:42:09,680
dominate points or not? This is what the hypervolume is measuring. It's a standard metric for

376
00:42:09,680 --> 00:42:18,080
optimization problems. But for our problem, what we really care is diversity of the points that lie

377
00:42:18,080 --> 00:42:24,160
above the threshold that satisfy the constraints. So we measure it in two ways. The very first one

378
00:42:24,160 --> 00:42:29,360
is using the field distance, which is a typical measure of diversity in many areas.

379
00:42:30,960 --> 00:42:39,840
It basically the radius of the largest ball you can place on the points that cover them. It's

380
00:42:39,840 --> 00:42:44,480
the largest radio that you can use to cover all the points. That's kind of the definition of full

381
00:42:44,480 --> 00:42:50,160
full field distance. And a new criteria that we use to tackle this problem, which is coverage

382
00:42:50,160 --> 00:42:58,720
recall, which is really how much volume I was able to recover from this satisfactory region.

383
00:42:59,280 --> 00:43:04,720
This is only possible to compute if we know the ground truth, of course. But it's definitely

384
00:43:04,720 --> 00:43:08,160
something that measures the success of constraint-active search.

385
00:43:08,160 --> 00:43:23,360
Yeah. And what kind of results did you see? Oh, yeah. We basically do. And maybe to jump in,

386
00:43:24,080 --> 00:43:32,320
are there, is the problem that you've defined close enough to existing problems that there are

387
00:43:32,320 --> 00:43:38,560
benchmarks that are relevant? Or is it mostly evaluation, mostly self-referential?

388
00:43:39,840 --> 00:43:47,360
Well, our goal with this experimentation setup was to show those formatrix and really highlight

389
00:43:47,360 --> 00:43:53,200
that different problems, different strategies are solving different things. So our algorithms,

390
00:43:53,200 --> 00:43:58,240
the algorithms that be proposed to solve constraint-active search. We actually proposed two or three

391
00:43:58,240 --> 00:44:05,040
alternatives. And they all do very, very well on coverage recall and field distance.

392
00:44:05,040 --> 00:44:11,200
Specifically, does the main algorithm that we propose, expected coverage improvement,

393
00:44:11,920 --> 00:44:17,920
is doing really well and minimizing the field distance and maximizing the coverage recall,

394
00:44:17,920 --> 00:44:24,000
which is exactly what we want. If we look at the angle of optimization, you will see that

395
00:44:24,000 --> 00:44:29,600
Bayesian optimization with multiple matrix will actually be the best because it's the only

396
00:44:29,600 --> 00:44:35,520
algorithm that is really trying to do that. And if we look at the number of sheer number of positive

397
00:44:35,520 --> 00:44:42,080
points, there's another line of research called active search, which optimizes the number of positive

398
00:44:42,080 --> 00:44:47,680
points. The downside of that approach is diversity is compromised. And this is true for both problems.

399
00:44:47,680 --> 00:44:54,000
Bayesian optimization doesn't have as much diversity as constraint-active search. Active search

400
00:44:54,000 --> 00:45:02,320
doesn't have the same ability to optimize hyper-volume, nor increase diversity as active search.

401
00:45:02,320 --> 00:45:06,080
It just finds a bunch of positive points and they are close together.

402
00:45:06,800 --> 00:45:13,040
Right. Restating Bayesian optimization will give you the points that are optimal we talked about,

403
00:45:13,040 --> 00:45:20,400
but not necessarily stable or diverse. Active search just gives you back a bunch of positive points,

404
00:45:20,400 --> 00:45:25,760
and so creates a lot of noise for the human and the loop to go through. Because the points are

405
00:45:25,760 --> 00:45:33,840
cluster together, it's not particularly meaningful distinctions. And so the diversity formulation

406
00:45:33,840 --> 00:45:39,920
and constraint-active search produces something that is much more useful in a real-world human

407
00:45:39,920 --> 00:45:44,960
and a loop scenario. Exactly. And I would like to dive deeper on that. Why do we think this is

408
00:45:44,960 --> 00:45:52,560
very useful? Just in benefit of active search, this is typically a solution that it's offered

409
00:45:52,560 --> 00:45:59,120
for discrete points. So if you have discrete points, maybe you should do active search,

410
00:45:59,120 --> 00:46:04,960
and they're very rare to find. In this scenario where we have parameters that are continues,

411
00:46:04,960 --> 00:46:09,520
then constraint-active search will be the best trade-off between finding good values,

412
00:46:09,520 --> 00:46:16,560
kind of the hyper-volume and diversity. Now if we go back to how this is really useful in practice

413
00:46:16,560 --> 00:46:24,000
when we have a human and loop, the reason for that is if we actually solve optimization problems

414
00:46:24,000 --> 00:46:32,400
and we offer experts the decision on the Pereiro-efficient frontier, they typically will think that they

415
00:46:32,400 --> 00:46:38,880
can choose metric values in the specifically in this case of design. They would try to see metric

416
00:46:38,880 --> 00:46:44,960
values that, you know, satisfy their preferences in some way. They will look at the function values here.

417
00:46:44,960 --> 00:46:50,000
Oh yeah, this configuration is really good. And I see a couple of points nearby. They have the same

418
00:46:50,000 --> 00:46:57,280
performance of this one. But the problem that they could face is when they map back to find what exactly

419
00:46:57,280 --> 00:47:04,000
what kind of how I'm going to produce this design. Maybe those metric values that were close

420
00:47:04,560 --> 00:47:10,160
here in the metric space could be really all over the place on the pyramid space. And this

421
00:47:10,160 --> 00:47:16,240
doesn't increase their confidence about the ability to produce a specific design with this height

422
00:47:16,240 --> 00:47:23,360
or this width. On the opposite, constraint-active search will provide not only points on the

423
00:47:23,360 --> 00:47:29,920
Pereiro frontier, but also a bunch of points in, they're not, they're like

424
00:47:31,360 --> 00:47:35,440
dominated by the points in the Pereiro frontier, but they are a bunch of points that in the

425
00:47:35,440 --> 00:47:40,880
primary space, they will offer you insights on how I can actually produce and create this design.

426
00:47:42,480 --> 00:47:48,560
That's one of the things we think this is important. The other one, it's really respect to the

427
00:47:48,560 --> 00:47:57,120
application. For example, some of those metrics that they care to, so basically we have this

428
00:47:57,120 --> 00:48:02,640
humidity loop. We want to use this experimentation to guide them their choices. Eventually they

429
00:48:02,640 --> 00:48:09,120
will choose five or ten designs to create to produce in real life. They will fabricate the

430
00:48:09,120 --> 00:48:15,280
designs. Diversity plays a really important role here because when we actually compute

431
00:48:15,280 --> 00:48:22,560
the designs, you can further measure properties of those designs. If they are all very different,

432
00:48:22,560 --> 00:48:27,680
then you can further do like a more expensive test to really find your best solution.

433
00:48:29,440 --> 00:48:32,960
Now, we can also translate this to machine learning in real life.

434
00:48:34,320 --> 00:48:39,840
Ultimately, we have business metrics that we care about, and the validation metrics that we use

435
00:48:39,840 --> 00:48:46,160
are a good proxy of what we can do during production, but maybe they're not perfect. What we

436
00:48:46,160 --> 00:48:53,440
wanted is offer users the possibility of having very different models so that they can use those

437
00:48:53,440 --> 00:49:01,520
models in a more complicated testing setting. For example, as a shadow of a current

438
00:49:01,520 --> 00:49:09,760
system or in an AB scenario where they want to evaluate things that they couldn't during development

439
00:49:09,760 --> 00:49:19,200
because the data is different. Having the ability to test more different models in the semi-production

440
00:49:19,200 --> 00:49:25,200
system is really, really helpful for them to make sure that the models that they created using all

441
00:49:25,200 --> 00:49:30,320
the metrics developed previously are actually helping them to achieve the business goals.

442
00:49:32,720 --> 00:49:40,000
So, returning to this theme of performance and development versus performance in the real world,

443
00:49:40,640 --> 00:49:46,480
but here in the broader machine learning application as opposed to the engineering application.

444
00:49:46,480 --> 00:49:58,880
Yes, exactly. Awesome, awesome. My next question would be to ask about where you go from here

445
00:49:58,880 --> 00:50:04,720
in future directions, but you already said that it's returning back to the objective and trying to

446
00:50:04,720 --> 00:50:11,520
understand stability for some of these points as one potential direction. Any other thoughts there?

447
00:50:11,520 --> 00:50:16,800
Well, this is a new formulation, so we are excited to invite researchers for a new community to

448
00:50:16,800 --> 00:50:24,480
think about different properties, different ideas. In this current formulation, we have this

449
00:50:24,480 --> 00:50:31,360
parameter R, which is something that is a function of your application. In real life, we can probably

450
00:50:31,360 --> 00:50:36,320
design a schedule for this parameter. We start with very large R values that will do a lot of

451
00:50:36,320 --> 00:50:42,800
exploration, and then we reduce the R values, so we can actually find a bunch of models more

452
00:50:42,800 --> 00:50:49,680
similar in some sense. We have some also theoretical understanding of the problem. We prove that

453
00:50:49,680 --> 00:50:57,040
this algorithm has a bound on the field distance, which means that it's able to converge in the sense

454
00:50:57,040 --> 00:51:04,560
of covering the satisfactory region, but you can also think about developing all the results,

455
00:51:04,560 --> 00:51:10,080
which we haven't done in this paper about how many other theoretical results, about the number

456
00:51:10,080 --> 00:51:17,280
of points that I need to at least get a notion of convergence closer to the results that we get

457
00:51:17,280 --> 00:51:25,360
on Bayesian organization. For example, yeah. Awesome, awesome. Bogusavo, thanks so much for

458
00:51:25,360 --> 00:51:31,120
taking the time to share a bit about your paper. Very interesting stuff. Thank you very much.

459
00:51:31,120 --> 00:51:35,120
We really appreciate it. That was a great conversation.

