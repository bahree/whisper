Hi everyone, I am joined by Sushil Thomas, who is the VP of engineering for machine learning
at Cladera. A little bit of background on this interview earlier this summer, Cladera
invited me to host a series of roundtable discussions with enterprise data leaders from
a variety of industries to explore their experiences, building the foundation for success with machine
learning and advanced analytics. Sushil and I had a bunch of great conversations in that context
and I invited him here to join me for a deeper conversation on the topics. Sushil, welcome
to the 12 more AI podcast. Thank you Sam, very nice to talk to you again. I had a good
time at that roundtable talk too and I wish we could do this in person, it's kind of insane
in the world we're living in now. It is insane the world we're living in and a little bit
of background on the data leader roundtable program. It was originally envisioned to
be an in-person series of events that we did with folks that were in leadership positions
in machine learning and AI and data and we pivoted that to accommodate the pandemic and
one of the things that I'm curious about and we'll ask you about momentarily is what you're
seeing, how you're seeing folks adapt to the pandemic and those kinds of roles but before
we do that, let's get a little bit of introduction into your background and your role at Cladera.
As you said before, I'm VP engineering for machine learning here at Cladera. We've increased
the scope of that a little bit recently to include a visualization, data visualization platform
as well because it's such a strong part of the machine learning workflow. In my past, so I've
always been very close to data but in different aspects of it, I started out very early working
on Solaris and in Sun Microsystems in the first internet boom. So I saw people serving up
web pages at massive quantity for the first time on these monster sun machines and it was a ton of
fun to work on those challenges moved into a systems storage company called three-power data.
So worked on enterprise storage for a long time where you would run the backbone of these
data centers from a storage systems perspective and that was a really interesting set of
challenges as well where you have like 30, 40 seconds to respond to every single request and you
miss even one and the entire data center is down because there's all these dependencies
built into the stack and different layers. So anyway, that was a lot of fun as well,
dealing with big data but in a different kind of way and then moved from there once I saw the
scale at which these platforms were being built at places like Google and Yahoo very early on
moved into working on distributed systems. So started with a startup called Jovian Data
that's got acquired since by a new start at this point but essentially working on very large
scale data processing to help the early ad networks process through their data and understand their
data. Moved to a company called Aster Data that builds distributed databases got acquired
into Teradata. So saw a lot of the old school data warehousing stuff at Teradata as well and
I have a lot of appreciation for all that technology from seeing it from the inside as well and
seeing how hard it is to do a lot of that stuff. And then of course started my own company.
It's called Arcadia Data. We did visualization and analytics on large data sets. The challenge
there was to get business users into the Hadoop platform which was at the point at a crazy
growth stage. And now at Cloud Data continuing on into the enterprise data cloud,
Arcadia got acquired into Cloud Data. So continuing on with the enterprise data cloud and helping
enterprises work on this hybrid story. They have a bunch of data on prem. They have a bunch of
data in the cloud infinite requirements on what they want to do with that data and so trying to
help them through all of that and working specifically on machine learning AI visualization as a part
of that. Got it. Got it. And in your role as VP of engineering is that primarily focused on
engineering the internal products that are offered to customers or how close do you get to the
the problems that customers are facing from a machine learning lifecycle perspective?
Right. So there's a few groups that that report up to me. One of them is the machine learning
product itself. So we have a product called CML Cloud data machine learning which is a hybrid
platform. It works on prem. It works on the cloud. It's it's very much our product within the
market for a long time that targets machine learning developers and data scientists to actually be
productive and get a lot of the development a lot of the production stuff going. We'll talk about
that a little bit later perhaps in some pieces. And then the other group one of the other groups is
fast-power labs. So this is a machine learning research team. We do applied research towards a bunch
of topics all open source all available. We run webinars every month every few months. We present
a lot of conferences. So that just helps customers like the goal of that organization is to take what
is maybe two years ahead in terms of machine learning theory right in terms of how quickly it's
going to get applied to customers and try to accelerate that process a little bit show people
a glimpse of the future and help them get to solutions on their in their enterprises that that
help with that right that that we can augment them on. And there's a lot of possibilities there.
There's a lot of stuff you're doing in terms of making that even easier especially as it comes to
leveraging all of this stuff on the cloud where everything is very easy, very self-service
and should be trivial to get started. And then the third team that's new is the data visualization
team. We just announced this like basically post the Arcadia acquisition. We've been working on
integrating that technology into cloud-era stack stack as well. So now we've integrated data
visualization into both the machine learning platform and the core data warehousing platform.
And so as machine learning engineers as data scientists you now get to look at the data in a very
very easy way build these end applications that work for end users business users and connect the
sort of the descriptive data analysis that's always been possible with more prescriptive models
and and mesh that data together and and make these beautiful applications for the organization.
Okay, great. But there's a part of that like as to your questions you know we always work very
closely with customers like my strong push on engineering organizations is always that you
cannot just build these products in isolation right so you have to continuously be talking to
customers. If I don't have you know two or three customer meetings every week then I'm really
disappointed essentially and typically it's more than that. And you work in customers at different
phases like so you work with the customers that have never heard of you and never used your products.
You work with customers that are three years into using your products and that know the ins and outs
of of of your product and their business and have very specific suggestions on what you should do
next. So there's like there's there's a high number of customer correlations always ongoing. So
so I mentioned the the data leaders roundtable program earlier and again we wanted to chat a
little bit about that and get your key takeaways and in particular that event took place
earlier in the the COVID pandemic this was earlier in the summer and folks were you know in the
process of adjusting to working from home and getting their teams set up to to work from home.
Now we've got quite a bit more distance under our belts now and a lot of the organizations that
I'm talking to are not planning to return back to offices until sometime mid to late next year
at the earliest yes and I'm just curious in the the conversations that you're having what kind of
impact all of this disruption has been having on on data organizations is it you know has it
been impacting them much at all is it industry by industry or you know our folks still working
through what that mean what this all means yeah so so I think one thing that I didn't know going
in it did surprise me a little bit but maybe in retrospect it's obvious I think one thing is that
data has become so core to organizations now and storing all their data and analyzing it processing
it using it to predict outcomes using it to understand their business is so central to how
organizations work now that at least the cloud era we have seen surprisingly little or no impact
to our customers like even the ones in industries where you would think these industries are substantially
impacted guess what they still have all of that data they still have to worry about securing it
and using it and leveraging it for for future planning stuff the one thing I of course as you
said there's been so many changes at organizations just trying to figure out how to get everyone
working from home and working remotely and some organizations do it better than others but we are
all in this place where no one quite we are still learning right and it's not just the right it's
not just the architecture right it's just it's just living with the pandemic and and all your
employees being a little like their lives being so different right and as that goes on and on and on
I think you have to like continually manage people's expectations and psychology and make sure
work is not a drain on them I think we've all gone through how difficult it is to just stay on
zoom the entire day or stay on video conferencing the entire day it's kind of crazy so I mean there's
all of that but on the other side on the actual challenges of working with data on the on the actual
concept of getting all these things going there's not much has changed all the data teams that I
work with have not you know reduced or changed in size substantially if anything the big differences
I'm hearing of a lot of use cases that are specifically related to the pandemic as you would expect
again I think just highlighting how central data has become to organizations and how much people
start with data I love that notion right like it used to be you know 20 years ago you you want to
decide something about your business you know you want to let's say your retail store and you're
trying to figure out where you open the next 10 locations I think 20 years ago you would have
exact sitting in a room you would have regional leads right you would be discussing you should
be do it right and you would pick like a few locations that people have people think I interesting
people would drive out to it like things like that right and now it's so different the first thing
is like where's the data where are competitors where where is the spend high right and where should
be open and then you start with like shortlisting just based on the data and then maybe you do a
sanity test at the end to just make sure you know you're not building on a on a radioactive site
or something like that at the end but like the the fundamentals are so different in how people
run their businesses now you mentioned that you are seeing some covid related use cases pop up are
these primarily in the industries like health care and the industries that are part of the
response to covid or is it broader than that I actually meant health care because that is so central
like we are we are also you know I think it's natural to try to be particularly supportive to
these industries that are there are trying to help all of us out through this right and you see
that they have a lot of interesting work that's ongoing now and that that work is very compelling
so I actually meant health care cloud has a large health care business and so there's a lot of
companies talking to us about their challenges here and the extra kinds of work and processing
they need to do and seeing if we can help and of course we are more than happy to help
and so yeah so just seeing a lot of those use cases either around planning for for the number of
folks that come into hospitals now and have to be processed and you have to do all of this
planning and forecasting you know things like when do the how many doctors do you need to get
what how do you do the scheduling for this stuff what what your expectations on on workloads
and then of course going all the way into the research side and trying to understand which of these
are which of these possibilities might work towards vaccines which of these are good
treatments options like all of this analysis that's done with the data as well and of course
everything is again just related to data right they have at this point there's a ton of data out
there on people who've come in on the kinds of treatments that we've done on them on remission on
any sort of remission that's happened on on what the outcomes have been and so there's a lot of
analysis you can do to get to a place where where you where you can make better decisions about what
you're doing forward which is the important thing. So for the round table I structured the conversation
broadly in terms of these three core themes people process and technology you know certainly themes
that we talk about a lot and the in technology and I thought we'd spend some time talking through
your key takeaway for you know in those themes from our discussion and as well as your broader
experience talking to the customers you know over the past few months we touched on some of the
impacts of COVID to people but more broadly what are some of the key trends you're seeing in
organizations that are trying to deploy machine learning go further with their ability to
make use of data deploy advanced analytics how are they dealing with the organizational issues
that arise and what are those issues yeah. So the round table was great and I think it was at
least to me very different setting talking to a bunch of data leaders together versus talking
one-on-one to a single organization and maybe a few people at different levels within that organization
of course you've done this a lot more so I'll give you my takeaways but I'd love to hear
your perspective on whether this was different from the others you've done I'm not either also.
So the one thing that was super interesting to me was you know this is obvious when I do the
one-on-one conversations like ML&EI within organizations is is still very very nascent and people
are still figuring out what the right way is to do things and I would contrast this with something
like data warehousing right where this is a very very well understood thing you know exactly how
to set up these organizations you know exactly what to expect at the end of that but for the for
ML&EI it's much more it's much more subtle like no one exactly knows what the expectations are like
normally teams are set up with very very high expectations on this is just going to magically
make everything better the teams are struggling through like we heard that all the time like the
teams are struggling with where is the actual data is the data clean like how do I get rid of all
this noise from the data then what kind of use cases can I do and then continuing on even after
you do the first rare off that work how do you get feedback back into the system how do you
continuously improve these models how do you serve all this stuff at scale and how do you keep
doing this like for new newer use cases that come up while maintaining the older use cases so
that they continue to be relevant and how do you keep all of this going at organizational scale
and so I think industry wide all of us are in the process of figuring a lot of these things out
and what the best practices are here these are not very well written out today and so what I heard
in the roundtable was initially I thought all the participants were a little bit hesitant
because they didn't know if they were the only ones that that were in a little bit of trouble
and that didn't quite know how to solve all these problems right but I think as they heard from
everybody that we are all in the same boat it was a lot more like I think there was a lot more
discussion about the real challenges that everybody hits right because you just don't know if it's
just you but it's just good to know that like everyone's in a very very similar boat there's very
similar set of challenges across the board so that that is really interesting to me like seeing
that dynamic layout and I don't know if you've seen that in the other round tables you've done as well
yeah you know one of the things that jumps out at me on this particular point and in particular
the way you framed it is there's this back and forth in industries one thing that we're grappling
with is thinking about machine learning as an engineering discipline versus thinking about it as
a science and an exploratory process and different organizations take different
different approaches in how they you know synthesize these two perspectives but
in a lot of ways it's it requires synthesizing these two perspectives you can't just approach it
as a traditional engineering task and you can't just approach it as a unstructured exploration
if you hope to achieve any scale and you know I'm curious how that resonates for you as someone who
is you know if you have engineering for machine learning right so it is fascinating we are also
I would say while we have a machine learning product team what the machine learning product
that cloud ourselves does is it helps engineers around all of the problems of machine learning right
so there's the actual machine learning code that you have to write but then there's everything else
there's where's my data there's how do I clean it there's how do I move these models of production
how do I run metrics how do I do ground tracking like all of these problems around the
actual you know 200 500 lines of code that you'll write to train your model and to serve your model
so I think there's a lot around it that's that's what we deal with so so very much the thing
that our product works on is I would say very much the engineering and the science part of it
and less of the art part of it we are very flexible there we let you do anything you want to
particularly because there's this problem where nobody quite knows that this is the one way
in which machine learning is to be done and I don't think that's going to happen but I think what
will happen over time is from my industry perspective these best practices will be will be better
known over time how these organizations the ML data scientists organizations get set up will be
better known over time and there will be like less of that less of the expectation difference
between what is possible and what is achievable which is kind of very prevalent today
you have some execs that will just think this will just work magically I'll just throw two or three
people at this problem and then you find all of these issues around data and what's needed and what
the expectations are on what the what's on the other side and how you to continuously manage this
and stuff like that so we're going to get better than that in fact at loud era you know we have
these ps offerings we work very closely with customers not just on the tech but we also have ps
offerings that that try to get them closer to solving their problems and one of our very popular
ps offerings is a strategy engagement for machine learning which literally boils down to you know
I want more machine learning in my organization how do I get there right and so we do we speak with
execs we speak with business themes that are looking for some of these solutions we try to
meld everyone's expectations together and make suggestions that are right for the organization
on how they should structure their their ML org because that's a challenge too like for many
of these companies that we work with they they don't have a thriving ML practice now they would
love to have one but they don't quite know how to get from where they are to that
yeah one of the recurring themes that struck me from the round tables and for context we were
largely talking to folks from traditional enterprises as opposed to the Facebooks and Google's
of the world and you know no surprise they find it very difficult to compete with those organizations
for talent and so there was a lot of discussion around how they you know groom and upskill and
cross train internal talent from within historical or traditional data organizations to start to
enable the the organization to move more quickly from a machine learning perspective curious
what you've seen working well from that perspective and any takeaways that you had from that part
of that conversation yeah I see a lot of that for sure it's super hard to get
enough machine learning talent enough AI talent also lots of confusion in the industry as you know
around terminology right so you have you have you know teams of data scientists that are really
either data analysts or the like data warehousing folks were just trying to help with
cleaning up the data and getting some basic statistical stuff going you have teams of people that
actually said an IT but it turns out they are amazing data scientists and the use cases they do
a lot more predictive and stuff like that right there's people who have a hub and spoke model right
where they have a central sort of center of excellence these are the guys who set up the best
practices around technologies they use and and and deployment practices and stuff like that
and then business units will have their own individual data scientists that that they work with
for for their actual use cases so yeah I see I see a lot of that also in the industry in terms of
just not there's no standard set of terms on on who these folks are and when you hear someone's
a data scientist or if you hear someone's not a data scientist they could be one it's just like
it's all over the place and in terms of attracting training and retaining people I think that's
a that's a substantial challenge as well I do think it's a very very good idea to to help people
that are in your organization already that work with data on a data day basis and that want to
up level their skills into into machine learning and into AI I I'm a big fan of being very supportive
of that and getting people trained to a level where they want to I guess the good news about it is
everyone who works close to data is interested in understanding more of our machine learning
understanding more about AI and moving closer and closer to to to to being productive there so I
think as a organization the opportunity is that you can actually train your people there because
they want to be trained in in those fields and then the still the tricky bits is just having the
structure around this practice so that you can actually use them productively at the end of that
they can do interesting things while they're learning and then you can get more people in that area
you've talked about some of the different organizational models hub and spoke versus centralized
historically one of the challenges within traditional enterprises and IT is kind of
breaking down silos and enabling organizations to communicate and work together effectively
are there any things that you've seen work better than others or is it
you know very very organizational dependent yeah and it is today it's organizational dependent
I do think if you think about similar things that that organizations have wrestled with before
and the ways in which they've set it up I think you get some clues around what might work better
so in my mind for example if I think about data warehousing and data platforming
it feels like a very centralized model has worked pretty well there for large organizations
where most of your expertise is in a is in a central team they run your your data platforms
and anytime you reach a place where there's a bunch of data silos around the place it's a little
bit of a disaster right because you have to then figure out how to make sense of these these
different deportations of all this data and all of these things in place but that's after many
years of data warehousing practice yeah exactly and I think it's it worked very well there but if I
can take the opposite side on something similar if you look at business analytics as a practice
and BI as a practice it's very much the case that people might build central BI tools and do
large contracts or that there's standardization on sort of what the tool is that you're using
but once you've done that the actual use cases the actual end use cases are typically don't come
from a central organization there's there's a few people that work in marketing and a few people
work in sales and a few people work in product who are actually doing the day-to-day analysis of
what's actually happening using those central platforms and I think that's because the data warehousing
and data platforming is very much a problem of scale and standardization and and reducing costs
and trying to make everything very secure and things like that but business analytics and BI
is very much a problem of what do my users actually need and I need to move really really quickly
really close to the users and these requirements change every day the questions change every day so
so the the folks that work on this problem have to be really close to those business units
so I am biased towards thinking that that's a better model for for ML and AI where the actual outcomes
are really close to the business you need people right next to the business who will work with the
business understand their urgency build the models show them the outcomes do the predictions all
of that stuff and of course at the same time I do very much like this notion of let's standardize
on tools and let's standardize on processes and let's make sure once these things are built out
that there's a standard way in which we manage and monitor and track these things and and augment
them over time right so that sort of that that that I think it's closer to BI and business analytics
then data warehousing but you know that's my opinion we'll find out right we have we have a ways to
go in figuring yeah yeah but you know building on that assuming a future that has data scientists
you know very closely aligned to the line of business and what its needs are and platform
organizations or machine learning engineering or data engineering you know those organizations
that are building out the central capability existing centrally you know what are the
the practices that allow folks to effectively operate that at scale based on these analogies that
you just mentioned what does that life cycle look like what are those the relationships between
those orgs look like in order to allow folks to get things done more quickly yeah and and again
here I think we can take cues from from what's been done previously for analytics as well
essentially the thing that seems to work well is having a standard set of definitions that
are organization wide around the data having a standard set of security practices and access policies
and all that stuff in place that are very strong and very central but then letting the analysts
themselves very liberally work within that framework right so there is typically no standard policy
on this is exactly what your BI dashboard must look like right you must have sort of one
KPI on top and three bar charts in this and that right you want to be you want to be a lot more
flexible on that entire use case and that entire surface area and be a lot more prescriptive
about what you want the tools you want to use and the the practices around access and security
to data so I think there are ways of of slicing this in a very similar way for ML you don't want
to be prescriptive to the data scientists to say that this is the kind of model you'll use this
is the kind of training you'll do this is the kind of hardware you will use to do the training
because I think it's a evolving field and a lot of that is is continuously changing over time
and you want to have that flexibility there at the same time when you talk about how you access
data and when you talk about how you move something to production and how you monitor the
performance of something going ahead and what the standards are for interpretability that I have
to be built into whatever whatever you're publishing and how do you you know manage in a central way
like uptime and all of these things I think there's a strong case to be made that that should be
formalized standardized centralized it's also something that most data scientists I mean
it's a little bit of a hassle for them right like that's something that that hopefully just works like
if I want to get data hopefully it's well understood where that data is and how I get to it
and if it's not there like who do I complain to about right so that it shows up essentially over time
so I think it's all about like I think from the the other angle of people and hiring people
and retaining people it's also important that when you get data scientists in that they work
in a productive environment and one way to make that environment productive is to have very clear
boundaries around a lot of these problem statements so that what they're working on is much more
aligned to what they're good at and what they want to do essentially which is to do the actual
data science build the use cases like that's the exciting bit for them so yeah yeah one of the
recurring challenges that we talked about during the around tables was the challenge to getting
models in a production the I think all of the organizations kind of reference store at least
agreed with this idea that you have many more models that you've tried or that you've experimented
with then have made it into production and some of that is just the natural process of experimentation
but there are also issues that organizations run into when trying to get models into production
you know can you speak to some of the you know the stories that you heard at the round tables and
more broadly the issues that are preventing organizations from effectively fielding their models
yeah absolutely so this is something which is essentially like so you know this as I said there's
a few classes of customers we work with we work with organizations that are really early in their
journey that are trying to build something build an initial practice out on how to use these
technologies there are other organizations who've you know used our product for multiple years
right who have teams of 50 people in that central team and then they have some a large number of
users data scientists in the spoke teams right so we work with fairly large organizations as well
who are pretty far along in their practice the feedback is pretty consistent that production
is still something that's very very very important to them essentially right production ML all of
these issues and there's a category there's a set there's sets of issues around first of all it's
just metrics like what is the standard way in which you're going to publish and look at metrics
there's a whole thing about monitoring how when you deploy this first of all how do you deploy it
what's the platform in which you deploy something to production and then how do you monitor
what's in production over time how do you scale it up and down elastically how do you
do all of that stuff and then the third large thing is governance like if you are so so there's
two challenges right the first challenge is getting your initial monitor production that's
typically a really large challenge if you've not dealt with it if you've not solved those problems
the second thing is one something in is in production how do you change it right because changing
is super complicated it implies that you know how the your model is performing in production now
and you have a theory that the modification is going to make it better like that's one
so that means you have to have good measurement practices before and after and comparison
second there's the entire workflow of this is not a one-off change typically changes could happen
multiple times a week multiple times a day depending on the organization that you are in the type
of model you're building so this is not a one-off problem where you get together and fix it this is
complete like CICD versioning it's like standard software development practices that have to be
applied here and you'll see many many data scientists who are just not familiar with software
development practices at that level because that's not the kind of work that they have done prior and
then there's the challenge of once everything is running in production how do you keep monitoring
that over time how do you compare that to ground truth right how do you run all these metrics not
just on an instant basis in terms of timeliness and how reasonable the predictions are but also
compare to ground truth and understand if you're doing things overall better or worse things like
that and if you've not solved these problems these are massive problems and these are things that
you must solve through standardized tooling right organization wide it's pointless to have
each of your business teams solve these separately it's it's pointless to not have a
org-wide policy on how this stuff is done of course the cloudware product do it other products do it
as well the more important thing from the organizational perspective is just to have a stance on
these things so that your data scientists less spend less spend less time being frustrated about
these practices and more time being productive and what your sense for how far along
organizations are on that journey in Silicon Valley you know we've got as we alluded to a little
earlier like very distinct roles there's the data scientists that's focused on one part of the
process and you know to your earlier point the definitions you know very fairly widely but then
you've got machine learning engineers that tend to be more familiar with concepts like CICD
and DevOps and platform technologies and things like that my sense at least is that in more
traditional organizations that those the distinction and those roles is evolving but yet at the same
time a lot of these same organizations have gone through this process and you know considering
like the evolution in the way they feel web applications there used to be just developers then
they started to you know have platform teams and build out internal platforms and so I'm curious
what you're you're seeing in terms of you know how mature our you know enterprises and along this
in this journey and you know where they need to evolve yeah and as you said it very so much
interestingly if you look at any of these organizations that you would think are doing these
this well right that in the valley right these these orgs that have been doing it maybe
five ten years and have fairly large teams at this point that deal with this what you will see is
that they have their own internal tooling they built for a bunch of this because when they started
out there there's really was not something that worked well for them in this area right so I guess
what's challenging from a from a from a larger industry perspective is if you're not a crazy
Silicon Valley tech company with like 300 data scientists that you've solved for by spending large
amounts of treasure and building custom tooling I think the challenges of just finding that like
figuring out what that process is that works for you at the scale that you're at and I think there's
the other overlapping point here is that you're right of many of these organizations have
standard ways in which they've done web app development and internal product development and
stuff like that for themselves before so I think another challenge is just trying to understand
what's different between that standard web app sort of development and product development versus
like a MLAI model going into production because there are large substantial differences that are
really important to internalize and understand so that you can focus on different aspects of it as
well and as an art that's starting out with this if you're bringing up a team which is like you
know five ten data scientists in size to begin with it's so hard to plan ahead for all of these
issues before you know them or before you hit them and so I think I that is a lot of audience in
terms of where people are with this yeah it's interesting in that it's different enough that you
certainly can't you know take a snapshot of your you know DevOps process and apply it to machine
learning and that leads folks to think that it's you know holy new and magic and it needs some
totally new thing but yet there still is a lot that you can learn about the experience you had
yes you know going through the past ten years of you know DevOps exactly exactly and I think
that's like as you said like that's both good and bad like the good thing is you don't have to
reinvent everything the bad thing is you might think you're already there and you don't understand
the differences well enough and you know the it's it's it's it's also one of these areas in tech
which unlike most of the areas in tech like you know you can have technologists that have been in
the industry for twenty thirty years right and if you asked them about Docker and Kubernetes and
a bunch of these areas that are fairly new right people are fairly familiar with them like it's fine
I understand it it maps to something we've done before you know short we've used VMs for a long
time now like Docker Kubernetes like you know I understand all the stuff right it's straightforward
if you talk to most engineers who've been in around for twenty thirty years and you start talking
what machine learning you will find there's a level of of you know of of discomfort right with
that technology right people are not completely certain how it works what it does what it can actually
do for them there's all these reports in the news about how tech is how ML and AI is used which always
seem so far fetch like suddenly it's beating the best go player in the world right and and it's
like it's it's totally on top of anything that's just later and then you look at what you're doing
and you're looking at even dog fights in the air force there you go right it's it's yeah it's it's
I don't know how that went but yes like even the possibility that is doing that is it's crazy yeah
and and then you look at your organization internally and you're having challenges just
getting a real-time feed of like sales over time right and just understanding like what happened
yesterday versus today and what's different and where the outliers are and it seems so far away
and so I think you see a lot of that discomfort reflected internally in organizations where
people are just not sure how they should move forward and that just also slows down a little bit
of the cadence on on how they can do it yeah one of the no sorry I was just going to say that as
as like the leaders were telling us on the on that round table as well like their challenges
just trying to map those expectations to the teams they're building like making sure everyone
everything moves up and they can keep hiring and and and getting best practices in
as the teams grow to what is the most size and it's just a set of one challenge after another
but that's what makes it fun I guess yeah yeah yeah one of the things that I noticed in the
conversations that we had at the round table is that the the folks that we spoke to were fairly
mature on the the core data you know from a core data maturity perspective just kind of by
selection and I'm wondering that may also be the case with you know in your experience with
the folks that you talked to by virtue of the fact that you're at cladera and I'm curious
your take on you know this idea that you know centralizing your data is a prerequisite to doing
ML and events analytics at scale and you know what exactly that means how mature you you need to be
you mentioned that folks still struggle with some fairly basic things that that is all a shifting
landscape yeah any reflections on that yeah so as you said like certainly cladera works with
the fortune 500 the fortune 2000 and and and these are organizations that have typically got their
data story together over the last 20 years let's say right not just regular data where I was
in kind of data but also they know how to integrate with these big data technologies how to store
massive amounts of data how to secure analyze all of this stuff as well so they are they are
pretty far along but I don't think I think even if you are a smaller company starting out or if
you're you know SMB I think the patterns around data are reasonably well understood now people will
still argue about one tech versus the other but there's a fairly well understood notion of you
know like a data lake you know a warehouse where things are a lot more structured a transactional store
which is maybe you know using like a key value store that that's that for much faster accesses
and I think that high level thing is understood any in fact typically the data silos problem that
you see tends to be in larger companies where the data teams are so disconnected from business
that business feels compelled to to take on like some of that challenge themselves just so they
can get more responsiveness but even then the business teams are working within the constraints
of these well understood patterns right they're setting up their own little data mark somewhere
on the side without talking to central IT but the patterns still are pretty well understood
so I think in terms of the on getting their data story together I would say most organizations are
are in reasonably even shape in terms of solving that that core problem it's of course it's a
much harder challenge to solve for the larger companies which is why it's sort of admirable that
they've done it over the last you know a couple of decades but that is reasonably in good shape
the continuing challenge in both large companies and small companies is okay yes you have data
but if you want to run a particular kind of analysis on it that data has to be transformed in some
way first just to make things efficient and to make things manageable and as those use cases come
in every single day from every single part of your company what happens over three four five years
is you have you know the same data is now like stored in these different forms it's used for these
different use cases as a massive ETL and pipelining thing that you're running to just make sure everything
stays up to date and then this continuously there are new requirements where you to figure out does
this have I already solved this somewhere and that's a hard problem to like that's a hard ask right
because no one quite understands the catalog as well as they showed and things like that
and then if I've solved this somewhere but there are some small changes neither how difficult it
is to make that change so just change management structure management data management at that level
I think is super hard for companies at all levels right it doesn't matter how large you are
the requirements keep changing there's no you cannot have solved this problem completely it's just
not possible yeah I'm just reflecting on you know many years ago talking to folks at you know
cloud era horton works about you know data lakes when we were first starting to talk about this as
an idea and how it was going to going to be the end of ETL we wouldn't need to do ETL anymore
um I think companies are doing a lot more ETL to your point not less yes and uh you know machine
learning is is just one more driver for that yeah it turns out like the data explosion was just step
one step two was the use case explosion right and every use case brought like this massive numbers
of changes that had to be made to how you store and manage this data so that the use case
been more efficient and yeah so I think that's you're right like so ML AI is just another explosion
in terms of like what's possible now and that leads to a bunch of changes you know and the challenges
are so basic right like I was speaking to an organization um a couple of months back where they have
a bunch they have these data scientists their challenge was like I asked them like what what is your
hardware set up look like they describe the hardware set up to me I said like so where are your
GPUs they're like we don't have GPUs I said why don't you have GPUs it makes no sense because
they're it's really advanced they're doing a lot of really interesting work uh clearly they could
use it and the response was like our IT um doesn't like GPUs are not on the approved purchase list
by IIT right so it doesn't matter like I have asked multiple people you have gone through the channels
like it is just not approved like there is no approved GPU that they can purchase and so they were
really excited because I was also talking to them at the time about our hybrid cloud story and how
we work on the cloud and on-prem and all these things and the the only question during the
presentation was okay so in your cloud platform how can I prove it's a GPU and I showed them
there's a slider right and and that's it and then they were like and then the second set of
challenges of okay I have to convince my central data teams that it's okay to move to the cloud
for some of this data that I need they were willing to take that on because they were like okay
it solves all these other problems for us at least that we don't have a little bit right so
I don't know it's that's going to be my question yeah right it's such an interesting world we
live in right and things change all the time and and all these organizations have to try to move
with it and and there's yeah it's it's fascinating yeah well just to wrap things up we started talking
about use cases and then you brought up this very uh you know if we can call it a mundane challenge
that organizations have to deal with and there is this tension uh yes you get this especially when
talking to folks at the leadership levels of data and MLAI organizations between kind of these
inspirational use cases that get folks excited and you know get them all their funding
and the you know the mundane get on first base low hanging fruit that still abounds in many many
organizations and I'm curious your you know perspective on how the organizations that you talk to
you know manage the you know the tension between these two types of use cases and you know if there
are any you know stories that you've heard about how folks have you know have moved forward given
how that right so I think the the one thing I've seen that's um that's changed recently is that
MLAI techniques are becoming a standard part of the typical business analysis business
intelligence that organizations do as well so I guess what's happening is it's it's genuinely
getting you know this is a very overuse term but those those requirements are getting a lot more
democratized and a lot more people are thinking about how can I do more of this just because
us the state that the technology is in so from an organizational perspective I think there are two
things happening there continues to be this high level pie in the sky sort of thing off like
here's this amazing thing that we can do right with AI and ML there's also this on the ground
consistent movements towards more and more advanced analytics and more and more interesting
insights and predictions that can be made from the data today that's also an ongoing movement
I certainly think that that latter part is the way for most organizations to get started
just be a little more grounded in where you are try to make that a little bit better try to add
in these things that makes sense and then sure you can have the the visionary thought on on what
else you can do and you can spend you know some of your cycles on that but it's important to just
up level org wide uh what you can do with all of your data and and how you can understand your
business by using all of these techniques rather than just you don't go for the one or two crazy
ideas which you know which work as we know sometimes also so yeah it's it's impossible to say don't
do them either so great great well so she was great catching up with you thanks so much for taking
a time to reflect on this series of round tables with me yeah very nice talking to you as well
Sam thanks for your time thank you
