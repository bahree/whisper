1
00:00:00,000 --> 00:00:16,000
Welcome to the Twimal AI Podcast. I'm your host, Sam Charrington.

2
00:00:16,000 --> 00:00:36,000
All right, everyone. I am here in Vancouver at Neurips and I am with Kathy Wu. Kathy is the Gilbert W. Winslow Assistant Professor of Civil and Environmental Engineering at MIT.

3
00:00:36,000 --> 00:00:40,000
Kathy, welcome to the Twimal AI Podcast. Thank you so much, having to be here.

4
00:00:40,000 --> 00:00:51,000
It's great to chat with you. We're going to talk about your upcoming presentation on mixed autonomy traffic and reinforcement learning.

5
00:00:51,000 --> 00:01:02,000
But before we do that, you've recently moved over to the Civil Engineering Department at MIT from more of an EECS background.

6
00:01:02,000 --> 00:01:06,000
Tell us a little bit about your interests and your journey.

7
00:01:06,000 --> 00:01:18,000
Thanks, yeah. So I studied EECS as an undergraduate master's student, PhD, and I also, in my postdoc, and I recently joined Civil like you said.

8
00:01:18,000 --> 00:01:26,000
During undergrad, I actually had the end of undergrad. I started becoming interested in transportation in part, actually because of self-driving cars.

9
00:01:26,000 --> 00:01:44,000
And so I started shifting my work and my thinking and my research, studying still robotics oriented, machine learning oriented perspectives on the problem, but really incorporating a lot of the domain specific challenges and problems.

10
00:01:44,000 --> 00:01:51,000
And my work has gradually become a really nice integration of both sides.

11
00:01:51,000 --> 00:01:57,000
I think coming from RPI, like I think of civil engineering as like broke building bridges and things like that.

12
00:01:57,000 --> 00:02:06,000
And so it's awesome to see the kind of interdisciplinary approaches being brought to bear and thinking about autonomous vehicles at Northwestern.

13
00:02:06,000 --> 00:02:19,000
There was a really strong transportation department or planning department and thinking about how cities need to be constructed, for example, to accommodate autonomous vehicles.

14
00:02:19,000 --> 00:02:23,000
What's the focus of your particular research?

15
00:02:23,000 --> 00:02:29,000
Yeah, transportation is really right for disruption, I would say, with AI.

16
00:02:29,000 --> 00:02:38,000
What I study in particular is how can we understand the potential impact of autonomous vehicles on the rest of the system.

17
00:02:38,000 --> 00:02:55,000
I would say that most of the work done in autonomous vehicles is either studying a single vehicle and how a single vehicle should drive and recognize stop signs and stop signs and navigating in its local environment.

18
00:02:55,000 --> 00:03:05,000
Or it's about how all vehicles are already autonomous and how can we coordinate them so that we can have intersections without stoplights.

19
00:03:05,000 --> 00:03:14,000
So very little is studied and known about that intermediate region regime of partial adoption or different levels of automation.

20
00:03:14,000 --> 00:03:18,000
And so that's what we call mixed autonomy and that's what my talk will be about.

21
00:03:18,000 --> 00:03:27,000
Which I think folks are starting to come to a consensus that that's going to be the rule for quite some time.

22
00:03:27,000 --> 00:03:30,000
That's right. At least a few decades.

23
00:03:30,000 --> 00:03:42,000
I think you even see this in kind of mainstream media, going back five years, I'd ask people when they thought autonomous vehicles would be here and they thought they would dominate the streets in five years.

24
00:03:42,000 --> 00:03:43,000
That's right.

25
00:03:43,000 --> 00:03:46,000
And now folks are much more guarded.

26
00:03:46,000 --> 00:03:51,000
There's a bit more of a sobering perspective on autonomous vehicles now that's right.

27
00:03:51,000 --> 00:04:08,000
So also the autonomous vehicles interacting with human driven vehicles is going to be the role, particularly in cities and on highways, maybe in some controlled environments like airports or something like that.

28
00:04:08,000 --> 00:04:17,000
There may be lanes for AVs, but we're going to have to figure out how these two interact with each other and that's what you're focused on.

29
00:04:17,000 --> 00:04:24,000
Yeah, that's right. And actually what you're pointing out is a really good point. There are a lot of different types of scenarios.

30
00:04:24,000 --> 00:04:33,000
There are airports, there are potential changes to the urban environment where there can be dedicated lanes just for vehicles, just for autonomous vehicles.

31
00:04:33,000 --> 00:04:38,000
There can be maybe enclosed regions like campuses.

32
00:04:38,000 --> 00:04:50,000
And so one of the really nice parts and challenging parts about this particular research area is that there are just so many different varieties of traffic scenarios.

33
00:04:50,000 --> 00:04:58,000
And so we need advancements and machine learning techniques to sort of support the vast variety.

34
00:04:58,000 --> 00:05:05,000
And so your talk is particularly focused on the application of reinforcement learning models to mix autonomy?

35
00:05:05,000 --> 00:05:21,000
That's right. So what we study is how can reinforcement learning methods today help us gain insights into what could our traffic systems look like if we could control a fraction of vehicles, so a fraction of autonomous vehicles.

36
00:05:21,000 --> 00:05:36,000
We want to characterize at what point of the transition do we see benefits for traffic congestion, for travel times, for energy consumption, for safety, and things like that. Do we need 100% or is it 99%? That's really different.

37
00:05:36,000 --> 00:05:44,000
This is very important for potentially city planners, policy makers, and traffic operations, engineers.

38
00:05:44,000 --> 00:05:55,000
If that number is, if we see benefits at 5% versus 10% versus 50%, and so that's what we look at with by studying this in reinforcement learning paradigm.

39
00:05:55,000 --> 00:06:14,000
And you've focused on any particular type of environment, cities, highways. I remember seeing a demo of some research kind of along these lines that looked at like a track like environment.

40
00:06:14,000 --> 00:06:27,000
And if you've got some say 90% of cars that are modeled as human driven and then you introduce a few autonomous vehicles, they actually help with traffic circulation.

41
00:06:27,000 --> 00:06:37,000
And so the assumption there was a track like, does your talk focus on a particular scenario?

42
00:06:37,000 --> 00:06:51,000
Yeah, so we always have to start with the simplest environment that we can. So we do look at the track, we look at a variety of different scenarios as well, and we call them traffic logo blocks.

43
00:06:51,000 --> 00:07:06,000
So we'll take the full city network and we'll sort of decompose them into a simple intersection network, a simple sort of multi lane scenario, or a simple merging scenario, or a simple traffic bottleneck.

44
00:07:06,000 --> 00:07:18,000
And then the idea is that we can study each of these environments where we control a fraction of the vehicles with reinforcement learning, and we can sort of start taking insights in these smaller environments.

45
00:07:18,000 --> 00:07:34,000
And then as we were also working on developing methods that can help us scale these experiments to networks that have multiple of these components and then eventually working our way up to a city. The goal is a city.

46
00:07:34,000 --> 00:07:42,000
We got it, got it. So walk us through your presentation. What's the, how do you set up the scenario?

47
00:07:42,000 --> 00:07:52,000
Yeah, so I think a sort of hidden part of reinforcement learning is how much energy and effort goes into designing the task itself, designing the environment.

48
00:07:52,000 --> 00:08:08,000
So reinforcement learning is often formulated in this Markov decision process framework, and so we really go through and we specify each of those components of a Markov decision process. What is the state, what is the action, what is the reward, and so on and so forth.

49
00:08:08,000 --> 00:08:27,000
What does count makes sense? What horizon makes sense? What does the, what should the network look like? What should, how should we model the individual humans? And so we are, we jointly study the entire setup of the, of the Markov decision process, the MDP, as well as the choice of algorithm.

50
00:08:27,000 --> 00:08:39,000
And so we might consider, for instance, here in this scenario, let's keep, let's keep things simple, let's care, let's, let's optimize for say the average velocity of all vehicles in the system.

51
00:08:39,000 --> 00:08:47,000
In the future, we can study this, trade it off with energy consumption and human stress levels and, and whatnot.

52
00:08:47,000 --> 00:09:00,000
And so what we'll do for a lot of the effort actually goes into designing the state of the MDP. What is, what can the autonomous vehicles actually observe about the system?

53
00:09:00,000 --> 00:09:13,000
And here we do a variety of trade offs. We could give the system, we could give the autonomous vehicles full observation of the environment, but this may be less practical for deployment purposes.

54
00:09:13,000 --> 00:09:22,000
And so we may want to limit the observations to say local information around the vehicles and maybe some aggregate statistics of the system.

55
00:09:22,000 --> 00:09:26,000
And all of this needs to be, needs to be carefully thought through.

56
00:09:26,000 --> 00:09:45,000
Those assumptions are kind of models of an evolving, you know, future real world scenario right there are the automakers are dabbling in like connected car scenarios where the autonomous vehicle will have information about, you know, from the other vehicles on the road.

57
00:09:45,000 --> 00:09:46,000
Yeah.

58
00:09:46,000 --> 00:09:49,000
Is that those some of the things that you're trying to model in?

59
00:09:49,000 --> 00:10:09,000
So it's a really interesting point. One of the potentials for this work is actually to help automotive or the public sector actually understand what parts of the system actually need to be communicated to the autonomous vehicles to achieve some outcome.

60
00:10:09,000 --> 00:10:15,000
So I think the work there is still quite early stage. It's a very exciting direction.

61
00:10:15,000 --> 00:10:35,000
And so you kind of establish the kind of framework of the MDP and what the various levers are and potential outcomes that you're looking to control what next in your talk.

62
00:10:35,000 --> 00:10:48,000
Oh, that's right. So then we, we actually to start with where we leverage block box existing reinforcement learning techniques, we use policy gradient methods, we use TRPO, we use PPO.

63
00:10:48,000 --> 00:10:51,000
And we just sort of see what happens.

64
00:10:51,000 --> 00:11:13,000
And to our surprise, we, the outcome was quite remarkable. What we found is that a very small fraction of vehicles actually can make a significant difference across these different, these different traffic scenarios, these inter, across intersections, merges, bottlenecks, single multi lane roads.

65
00:11:13,000 --> 00:11:35,000
We found that 5 to 10% of vehicles is sufficient to eliminate traffic congestion in our, in our preliminary studies, as well as to increase average velocities by 50 to 100% in the network for all vehicles, not just for the automated vehicles.

66
00:11:35,000 --> 00:12:00,000
And then in addition, we have these sort of emerging behaviors that of say coordinated vehicles through, through an intersection or through, through these very, these sort of interesting behaviors that actually correspond to techniques that traffic engineers have spent a long time hand designing to improve traffic systems.

67
00:12:00,000 --> 00:12:08,000
And they're interesting to see the very similar behavior sort of pop out without, without the same amount of domain knowledge going on.

68
00:12:08,000 --> 00:12:10,000
What are some examples of this?

69
00:12:10,000 --> 00:12:25,000
Yeah, so one example that I really like is called the traffic break. I don't know if you've experienced that in driving where, if you're sometimes on a highway, a highway patrol officer will actually drive sort of this sinusoidal pattern across multiple lanes.

70
00:12:25,000 --> 00:12:30,000
So it's one single vehicle that slows down multiple lanes of vehicles.

71
00:12:30,000 --> 00:12:42,000
And in some of our experiments, that actually popped out. We have an autonomous vehicle sort of stable sort of sort of bringing multiple lanes of traffic to a, to a higher speed.

72
00:12:42,000 --> 00:13:11,000
Everyone, everyone in the system is benefiting. And just by one vehicle being automated out of 40 or so, where that vehicle is slowing everyone down in a way by driving this sinusoidal pattern blocking all the lanes of traffic in such a way that the, it basically induces the human drivers to not, not resulting traffic jams.

73
00:13:11,000 --> 00:13:33,000
So it's, so is it that it's slowing the traffic down and then itself speeding up and kind of pulling the, the human drivers along, or is it more kind of a fundamental, you know, by causing the, maybe it's causing the human drivers to stop bad behavior or something like that.

74
00:13:33,000 --> 00:13:48,000
Interestingly, it's more the latter. So we, in our work, we, we're, there's also an intersection of our work with control theory. And we can actually use tools from control theory to analyze these same systems.

75
00:13:48,000 --> 00:14:01,000
And like dampening the, something like that are basically can basically techniques from control theory can allow us to determine the sort of the stable points of the system or this unstable points of the system.

76
00:14:01,000 --> 00:14:13,000
And what the analysis tells us is that there is an unstable point of the system where traffic flows very well. All vehicles are going at the same speed and it's all nice.

77
00:14:13,000 --> 00:14:30,000
However, it's unstable. So in the absence of some external control, the state would not stay that way. And what we're seeing is that the reinforcement learning outcome is that the autonomous vehicles actually brings the system to that unstable equilibrium.

78
00:14:30,000 --> 00:14:48,000
And so it is a more fundamental property where the, all, the result is that all vehicles are going at the same speed. The autonomous vehicle essentially in hindsight, we can see the, the outcome of this experiment as the autonomous vehicles figure out what is the right speed that all vehicles need to go at.

79
00:14:48,000 --> 00:14:51,000
And then basically maintains that speed for all vehicles.

80
00:14:51,000 --> 00:15:09,000
And this is in a scenario where the autonomous vehicle has kind of global knowledge or independent of global knowledge. Yeah, I actually independent of global knowledge. So only, only local knowledge of just the vehicles next to it, it can actually figure out the right speed for the system.

81
00:15:09,000 --> 00:15:25,000
Yeah, you know, I mentioned this, this demo scenario that I've seen before may have been your research. It sounds very familiar. It reminds me a little bit of some related perhaps results.

82
00:15:25,000 --> 00:15:39,000
I don't recall the specific reference, but it was something along the lines of an aggressive human driver can actually make traffic flow faster. Have you come across this result before?

83
00:15:39,000 --> 00:15:46,000
As a New York City driver in St. Louis, I often feel like I'm doing my civic duty.

84
00:15:46,000 --> 00:16:15,000
I am not familiar with this. It's our studies show the opposite, which is that if more drivers say five to ten percent of drivers were to be less aggressive and in particular to break less, to accelerate less, just actually to respond a bit less, respond more slowly to the vehicle in front of you.

85
00:16:15,000 --> 00:16:23,000
Then traffic could actually improve for everyone. That's sort of the one of the takeaways from from our early experiments.

86
00:16:23,000 --> 00:16:33,000
Meaning I respond more slowly, you know, the car in front of me breaks and I slam on the brakes and that kind of causes a ripple that's right, right, right, right.

87
00:16:33,000 --> 00:16:44,000
This is all work that's done in simulation, presumably how well do you feel you're actually able to model human drivers?

88
00:16:44,000 --> 00:16:54,000
Yeah, that's a really good question. This is a general limitation for reinforcement learning as we look at more real world context.

89
00:16:54,000 --> 00:17:11,000
On the other hand, I actually, among a lot of real world context, transportation actually has very good simulators. There are decades of researchers in the transportation modeling community who have studied human driving models of actually all sorts of decision making and transportation.

90
00:17:11,000 --> 00:17:31,000
Like how does a human decide which mode of transportation to take or what price point they are at for different subway fares or whether or not they're going to buy a car or in the case of driving, when is it that you're going to hit the break and how hard based on the distance of you to the vehicle in front of you?

91
00:17:31,000 --> 00:17:51,000
All of this has been very, very carefully studied. Of course, there's more work to be done. There's always more work to be done. But in terms of the quality of simulation, the simulators that we use, these types of simulators are actually used to design actual transportation systems and actual.

92
00:17:51,000 --> 00:18:02,000
We've talked about the results for the track. Have you gone as far as modeling some of these other scenarios as well, like the intersections and merges?

93
00:18:02,000 --> 00:18:04,000
Yeah, so we have results for all of those.

94
00:18:04,000 --> 00:18:05,000
Can you share some of those?

95
00:18:05,000 --> 00:18:17,000
Yeah, so the outcomes in terms of the improvements are pretty consistent. 5 to 10% of automated vehicles leads to 50 to 100% improvement in average velocity in those scenarios.

96
00:18:17,000 --> 00:18:21,000
And we get different types of emergent behaviors.

97
00:18:21,000 --> 00:18:29,000
So the emergent behavior on a track is this police car slow down type of thing. What is it at an intersection?

98
00:18:29,000 --> 00:18:40,000
Yeah, what's really interesting in intersection is basically coordinating vehicles to not conflict at an intersection.

99
00:18:40,000 --> 00:18:50,000
So you may have seen a video of a system where all vehicles are automated and there's no need for traffic lights at an intersection.

100
00:18:50,000 --> 00:19:03,000
And so a few years back, I was interested in, well, what if one vehicle is not automated, one human vehicle, then do we not have any benefit of autonomous vehicles when anywhere we have intersections, which is most places?

101
00:19:03,000 --> 00:19:26,000
And what we actually found is that with enough autonomous vehicles, actually with very few autonomous vehicles, the autonomous vehicles can actually coordinate so that at an intersection it can sort of hold back human drivers from reaching the intersection while the other direction of the intersection passes through, if that makes sense.

102
00:19:26,000 --> 00:19:49,000
So what we're calling this mixed autonomy platooning, where most of the time platooning is a very desirable autonomous vehicle behavior where vehicles can sort of platoon together, sort of reduce air drag and be a lot more efficient in driving together, and all of the vehicles in that platoon are autonomous.

103
00:19:49,000 --> 00:20:12,000
And what we're finding here is this sort of emergent mixed autonomy platoon where only the lead vehicle is automated, but we get this benefit where you have a platoon of vehicles that pass through an intersection in one direction, and then you have a platoon of vehicles that pass through the intersection in the other direction, and neither platoon needed to stop at the intersection, which leads to pretty dramatic improvements in average velocity.

104
00:20:12,000 --> 00:20:37,000
And it sounds like you're at least assuming, but maybe you've validated that this is, or probably have validated this is linear with the number of autonomous vehicles, meaning, you know, 5% offers some benefit and that benefit continues with the number of autonomous vehicles, and it's not somehow that, you know, more autonomous vehicles leads to a more chaotic situation.

105
00:20:37,000 --> 00:20:59,000
So surprisingly, you would think we have done that study, but what we actually found is that in many of these cases, we would, we basically work with small scenarios with say 20 total vehicles or 40 total vehicles, and then what we do is we swap out one for an automated one.

106
00:20:59,000 --> 00:21:12,000
So we can swap out fewer than that. We'd have to change the scenario to have a smaller fraction, and in almost all the scenarios that we studied, swapping out one vehicle was actually enough to achieve a very good outcome.

107
00:21:12,000 --> 00:21:17,000
So there was no need to actually explore more, like, more fractions.

108
00:21:17,000 --> 00:21:19,000
The assumption is that it doesn't get worse.

109
00:21:19,000 --> 00:21:30,000
That doesn't get worse. That's right. That's right. Do you think at all about the, you know, what it's like for that single human driver surrounded by autonomous vehicles?

110
00:21:30,000 --> 00:21:42,000
Oh, I see. That's single human. Maybe that single human would get the message to buy two autonomous vehicles at that point.

111
00:21:42,000 --> 00:22:00,000
I actually get a lot of questions about the opposite scenario, where if there were so few autonomous vehicles, then, like, different people respond to, like, I wouldn't want to be in that autonomous vehicle that sort of swirving left and right in traffic, or I wouldn't want to be behind that autonomous vehicle.

112
00:22:00,000 --> 00:22:13,000
That I hear from time to time. And I think an interesting way to think about that is if we start to think about these vehicles not as passenger vehicles, but as almost, like, part of the infrastructure.

113
00:22:13,000 --> 00:22:15,000
Control vehicles in the system.

114
00:22:15,000 --> 00:22:23,000
Control vehicles. Like, think of them as traffic lights, but they're, but instead of these binary signals, they're actually moving traffic lights that can set us speed.

115
00:22:23,000 --> 00:22:31,000
And so we're starting to see some, some projects that are thinking about using these ideas and more near term transportation projects as well.

116
00:22:31,000 --> 00:22:46,000
And there's, I did an interview with Diana Howard, who, I believe out of Georgia Tech, who studies kind of the relationships between humans and robotic systems.

117
00:22:46,000 --> 00:22:53,000
And there seems to be a predisposed willingness to defer to, you know, robotic systems.

118
00:22:53,000 --> 00:22:59,000
So maybe, you know, the humans that are behind that, you know, control car would be totally fine with it.

119
00:22:59,000 --> 00:23:00,000
It could be.

120
00:23:00,000 --> 00:23:03,000
It's an autonomous vehicle that says low down, so that's what I'll do.

121
00:23:03,000 --> 00:23:15,000
There are also concerns about sort of taking advantage of autonomous vehicles, especially as currently autonomous vehicles are designed as sort of very, very passive.

122
00:23:15,000 --> 00:23:17,000
And very safe.

123
00:23:17,000 --> 00:23:25,000
And so there have been evidence and videos of human drivers sort of cutting off an autonomous vehicle at an intersection.

124
00:23:25,000 --> 00:23:30,000
And so it may actually take that autonomous vehicle longer to get to a destination.

125
00:23:30,000 --> 00:23:33,000
This is like the kids beating up the malls.

126
00:23:33,000 --> 00:23:36,000
Exactly. Exactly. Except their adults.

127
00:23:36,000 --> 00:23:39,000
Right. Interesting, interesting.

128
00:23:39,000 --> 00:23:50,000
But the results that you've described were small number of autonomous vehicles leads to these advances in kind of traffic flow.

129
00:23:50,000 --> 00:23:55,000
Your primary metric there is kind of throughput of the system or velocity.

130
00:23:55,000 --> 00:23:58,000
Are there other metrics that you've explored?

131
00:23:58,000 --> 00:24:05,000
We have not explored other metrics explicitly, although there are a lot that we're interested in, such as fairness.

132
00:24:05,000 --> 00:24:12,000
Sometimes different lanes have different throughputs and that may not be fair.

133
00:24:12,000 --> 00:24:16,000
So we may be interested in some fairness metrics.

134
00:24:16,000 --> 00:24:23,000
We're also interested in safety metrics and energy consumption and several others.

135
00:24:23,000 --> 00:24:25,000
There are many, many.

136
00:24:25,000 --> 00:24:31,000
The robotic car here, the autonomous vehicle, is modeled as a reinforcement learning agent.

137
00:24:31,000 --> 00:24:32,000
That's right.

138
00:24:32,000 --> 00:24:38,000
Are there any interesting observations that you've made about the training process itself,

139
00:24:38,000 --> 00:24:44,000
and the learning process, before or until we get to the interesting emergent behaviors?

140
00:24:44,000 --> 00:24:51,000
We have seen other emergent behaviors that are less good for the system, such as tailgating.

141
00:24:51,000 --> 00:24:53,000
We've also learned tailgating.

142
00:24:53,000 --> 00:24:59,000
So there are a number of examples where we do learn some behaviors

143
00:24:59,000 --> 00:25:05,000
that we can describe that everyone can relate to that are not quite what we're looking for.

144
00:25:05,000 --> 00:25:08,000
The presentation is the main result that you're presenting,

145
00:25:08,000 --> 00:25:11,000
these kind of emergent behaviors that you've described,

146
00:25:11,000 --> 00:25:17,000
or are you digging into more details about how you've created the agents,

147
00:25:17,000 --> 00:25:22,000
or what other things should we make sure to touch on in the conversation?

148
00:25:22,000 --> 00:25:30,000
Yeah, so the highlight of the talk is really the empirical results that we found,

149
00:25:30,000 --> 00:25:37,000
as well as the experimental process to get to it,

150
00:25:37,000 --> 00:25:41,000
as part of this because of the vast variety of traffic scenarios,

151
00:25:41,000 --> 00:25:44,000
including the ones that we've discussed today.

152
00:25:44,000 --> 00:25:53,000
We built an open source framework called Flow, which allows us, as well as any other researchers,

153
00:25:53,000 --> 00:25:58,000
to design their own traffic scenario, their own traffic logo block,

154
00:25:58,000 --> 00:26:03,000
their own traffic MDP, and do their own experiments.

155
00:26:03,000 --> 00:26:07,000
What is the kind of Flow user experience?

156
00:26:07,000 --> 00:26:16,000
Is it a visual graphic type of thing, or is it more your setting parameters,

157
00:26:16,000 --> 00:26:21,000
and then running a command line?

158
00:26:21,000 --> 00:26:23,000
Yeah, it's more the latter.

159
00:26:23,000 --> 00:26:28,000
It's more for developers and for researchers at this point.

160
00:26:28,000 --> 00:26:34,000
So you can specify a network, you can specify the different types of vehicles,

161
00:26:34,000 --> 00:26:38,000
human or autonomous, or different types of human drivers,

162
00:26:38,000 --> 00:26:42,000
and you can specify the different fractions of these vehicles,

163
00:26:42,000 --> 00:26:46,000
you can specify the number of lanes in the network, different parts of the network,

164
00:26:46,000 --> 00:26:48,000
and so on and so forth.

165
00:26:48,000 --> 00:26:52,000
And it's also an actively developed tool right now.

166
00:26:52,000 --> 00:27:02,000
You mentioned that your research relies on these established traffic simulation engines,

167
00:27:02,000 --> 00:27:06,000
and does this flow also depend on those?

168
00:27:06,000 --> 00:27:10,000
Yes, so Flow integrates with a few traffic simulators,

169
00:27:10,000 --> 00:27:16,000
one of which is called Sumo, the simulation of urban mobility,

170
00:27:16,000 --> 00:27:21,000
and it's also an open source traffic micro simulation,

171
00:27:21,000 --> 00:27:27,000
and then we also integrate with another commercial simulator called AIMSUN.

172
00:27:27,000 --> 00:27:29,000
AIMSUN, okay.

173
00:27:29,000 --> 00:27:35,000
These are all, so traffic micro simulators are the specific subset of simulators

174
00:27:35,000 --> 00:27:39,000
that are really about simulating vehicle dynamics,

175
00:27:39,000 --> 00:27:44,000
rather than say vehicle routing or land use.

176
00:27:44,000 --> 00:27:45,000
Okay.

177
00:27:45,000 --> 00:27:52,000
And so anyone can download Flow and download Sumo, for example,

178
00:27:52,000 --> 00:27:57,000
and kind of replicate some of the results that you presented?

179
00:27:57,000 --> 00:27:59,000
That's right, everything's open source.

180
00:27:59,000 --> 00:28:01,000
A strong believer in open source.

181
00:28:01,000 --> 00:28:05,000
Awesome, and so do you, can you use these inside of notebooks,

182
00:28:05,000 --> 00:28:11,000
or what's the typical kind of user experience?

183
00:28:11,000 --> 00:28:13,000
I think you could use it inside networks.

184
00:28:13,000 --> 00:28:19,000
We typically don't, because we're typically issuing jobs to some cluster

185
00:28:19,000 --> 00:28:23,000
for the large-scale reinforcement learning runs.

186
00:28:23,000 --> 00:28:24,000
Got it.

187
00:28:24,000 --> 00:28:27,000
But I think you probably can. How long do you run typically?

188
00:28:27,000 --> 00:28:28,000
Take.

189
00:28:28,000 --> 00:28:33,000
They range, actually, in the scale, in terms of reinforcement learning experiments,

190
00:28:33,000 --> 00:28:36,000
we're very, very low.

191
00:28:36,000 --> 00:28:39,000
Low, like low samples needed.

192
00:28:39,000 --> 00:28:46,000
So our experiments actually can run on a standard commodity AWS instance

193
00:28:46,000 --> 00:28:50,000
in between like one and nine hours.

194
00:28:50,000 --> 00:28:52,000
With GPU?

195
00:28:52,000 --> 00:28:54,000
We don't need GPU.

196
00:28:54,000 --> 00:28:55,000
We don't need GPU, okay.

197
00:28:55,000 --> 00:29:01,000
Yeah, so we are not, we basically focus on the state input directly

198
00:29:01,000 --> 00:29:03,000
and we are not doing too much vision.

199
00:29:03,000 --> 00:29:07,000
Any kind of parting thoughts or other things that you want to mention

200
00:29:07,000 --> 00:29:08,000
from your presentation?

201
00:29:08,000 --> 00:29:14,000
Yeah, so I think we talk a lot about automation and AI

202
00:29:14,000 --> 00:29:17,000
and how it's increasing in the world.

203
00:29:17,000 --> 00:29:21,000
I think another dimension of this that I think is really important

204
00:29:21,000 --> 00:29:25,000
is how much connectivity is actually increasing in the world.

205
00:29:25,000 --> 00:29:31,000
We are, we're all more and more, the people and the systems

206
00:29:31,000 --> 00:29:35,000
that we interact with are more and more connected through social media,

207
00:29:35,000 --> 00:29:41,000
through, say, through urban networks, through global supply chains,

208
00:29:41,000 --> 00:29:43,000
the world is sort of more and more connected.

209
00:29:43,000 --> 00:29:47,000
And so a lot of what motivates this research is the realization

210
00:29:47,000 --> 00:29:52,000
that it's not enough to study a single autonomous vehicle

211
00:29:52,000 --> 00:29:54,000
in its own local environment.

212
00:29:54,000 --> 00:29:57,000
We have to study the environment that it affects,

213
00:29:57,000 --> 00:29:59,000
which is, say, the whole city.

214
00:29:59,000 --> 00:30:05,000
And it's, I think because of the increased connectivity in the world,

215
00:30:05,000 --> 00:30:11,000
it's becoming harder and harder to study AI in its own isolated environment

216
00:30:11,000 --> 00:30:16,000
and the broadened scope of the impacts of AI means

217
00:30:16,000 --> 00:30:21,000
that we actually need new techniques that can handle

218
00:30:21,000 --> 00:30:24,000
much larger, much more complex systems.

219
00:30:24,000 --> 00:30:28,000
And that's a lot of what's motivating the next phase of my research.

220
00:30:28,000 --> 00:30:31,000
And so what are some of the specific directions that you're heading in

221
00:30:31,000 --> 00:30:32,000
in the next phase?

222
00:30:32,000 --> 00:30:36,000
Is it kind of taking these LEGO blocks and connecting them to one another?

223
00:30:36,000 --> 00:30:38,000
It is trying to do that.

224
00:30:38,000 --> 00:30:41,000
Current, with current methods, we can't just immediately do that,

225
00:30:41,000 --> 00:30:46,000
so we do need to look at different techniques to enable this.

226
00:30:46,000 --> 00:30:50,000
I'm very excited about directions in representation learning

227
00:30:50,000 --> 00:30:54,000
for large-scale networked dynamical systems,

228
00:30:54,000 --> 00:30:59,000
very interested in how can curriculum learning play a role in all this?

229
00:30:59,000 --> 00:31:03,000
How can we increase the efficiency of our simulators

230
00:31:03,000 --> 00:31:05,000
through the use of machine learning?

231
00:31:05,000 --> 00:31:07,000
Can we compress simulators?

232
00:31:07,000 --> 00:31:13,000
There are a lot of interesting directions to sort of allow us to work

233
00:31:13,000 --> 00:31:18,000
with more and more complex environments.

234
00:31:18,000 --> 00:31:21,000
Yeah, so what you've done as far as you've used reinforcement learning

235
00:31:21,000 --> 00:31:28,000
to identify some emergent behaviors that have utility in mixed autonomy scenarios,

236
00:31:28,000 --> 00:31:34,000
do you see this as now that we've identified these behaviors

237
00:31:34,000 --> 00:31:41,000
we can kind of program the cars some kind of way, independent of how we do that

238
00:31:41,000 --> 00:31:43,000
to exhibit these behaviors?

239
00:31:43,000 --> 00:31:52,000
Or do you see the cars more, do we need to allow the cars to learn things

240
00:31:52,000 --> 00:31:55,000
while they're kind of in real-time use?

241
00:31:55,000 --> 00:31:58,000
How do you see this playing out?

242
00:31:58,000 --> 00:32:03,000
I guess maybe is it a planning scenario that you're really focused on

243
00:32:03,000 --> 00:32:08,000
or you see the impact or is it more about the vehicles themselves?

244
00:32:08,000 --> 00:32:09,000
I think it's both.

245
00:32:09,000 --> 00:32:12,000
That's a really good question and a really good point.

246
00:32:12,000 --> 00:32:14,000
I think it's both.

247
00:32:14,000 --> 00:32:19,000
There are, with real-world problems, there are a number of reasons

248
00:32:19,000 --> 00:32:22,000
that either direction could not work out.

249
00:32:22,000 --> 00:32:24,000
But I think both are very possible.

250
00:32:24,000 --> 00:32:29,000
We could, in the near term, actually see instrumented vehicles

251
00:32:29,000 --> 00:32:32,000
reducing traffic congestion and increasing speeds.

252
00:32:32,000 --> 00:32:36,000
I can see that the technology is there.

253
00:32:36,000 --> 00:32:38,000
We may need to do a few more experiments.

254
00:32:38,000 --> 00:32:42,000
We may need to validate, but it's pretty close to near-term deployable

255
00:32:42,000 --> 00:32:45,000
whether there's a city that wants to do it or whatnot.

256
00:32:45,000 --> 00:32:47,000
That's a different story.

257
00:32:47,000 --> 00:32:52,000
From the planning perspective, I think that that is a very large

258
00:32:52,000 --> 00:32:54,000
potential direction.

259
00:32:54,000 --> 00:33:00,000
Can we help a city sort of map out its 20-year adoption plan

260
00:33:00,000 --> 00:33:02,000
for autonomous vehicles?

261
00:33:02,000 --> 00:33:04,000
It's incentivization plan.

262
00:33:04,000 --> 00:33:08,000
When and where should the system incentivize the adoption

263
00:33:08,000 --> 00:33:11,000
to get to a point where we can see these benefits?

264
00:33:11,000 --> 00:33:16,000
How should the regulation and rules of the game be laid out?

265
00:33:16,000 --> 00:33:20,000
I think from the planning side, I'm very interested in those questions.

266
00:33:20,000 --> 00:33:25,000
I think a lot of the computational and machine learning and large-scale

267
00:33:25,000 --> 00:33:30,000
techniques are very, very critical in the planning context.

268
00:33:30,000 --> 00:33:31,000
Awesome, awesome.

269
00:33:31,000 --> 00:33:34,000
Well, Kathy, thanks so much for taking some time to share with us

270
00:33:34,000 --> 00:33:35,000
what you're up to.

271
00:33:35,000 --> 00:33:36,000
Thank you for having me.

272
00:33:36,000 --> 00:33:38,000
Absolutely.

273
00:33:42,000 --> 00:33:43,000
All right, everyone.

274
00:33:43,000 --> 00:33:45,000
That's our show for today.

275
00:33:45,000 --> 00:33:50,000
For more information on today's show, visit twomolai.com slash shows.

276
00:33:50,000 --> 00:33:54,000
As always, thanks so much for listening and catch you next time.

277
00:33:54,000 --> 00:33:57,000
3

