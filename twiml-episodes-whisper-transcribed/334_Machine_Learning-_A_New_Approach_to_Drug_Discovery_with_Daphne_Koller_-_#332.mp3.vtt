WEBVTT

00:00.000 --> 00:13.400
Welcome to the Twimmel AI Podcast.

00:13.400 --> 00:21.320
I'm your host Sam Charrington.

00:21.320 --> 00:26.960
This week on the podcast, I'm happy to share just a few of the nearly 20 interviews I recorded

00:26.960 --> 00:31.800
earlier this month at the 33rd annual NURRIPS conference.

00:31.800 --> 00:35.920
If you've been waiting for the Twimmel pendulum to swing from workflow and deployment back

00:35.920 --> 00:39.920
over to AI and ML research, this is your time.

00:39.920 --> 00:45.200
We've got some great interviews and store for you over the upcoming weeks.

00:45.200 --> 00:49.280
Before we move on, I want to send a huge thanks to our friends at Shell for their support

00:49.280 --> 00:53.840
of the podcast and their sponsorship of this NURRIPS series.

00:53.840 --> 00:58.600
Shell has been an early adopter of a wide variety of AI technologies to support use cases

00:58.600 --> 01:04.920
across retail, trading, new energies, refineries, exploration, and many more, and is doing

01:04.920 --> 01:08.680
some really interesting things, but don't take it from me.

01:08.680 --> 01:14.720
Microsoft CEO Satya Nadella recently noted that what's happening at Shell is pretty amazing.

01:14.720 --> 01:19.600
They have a very deliberate strategy of using AI right across their operation from the drilling

01:19.600 --> 01:22.800
operations to safety.

01:22.800 --> 01:28.640
Last year, the company established the Shell.ai Residency Program, a two-year full-time program

01:28.640 --> 01:33.400
which allows data scientists and AI engineers to gain experience working on a variety of

01:33.400 --> 01:37.080
AI projects across all Shell businesses.

01:37.080 --> 01:40.960
If you're in a position to take advantage of an opportunity like this, I'd encourage

01:40.960 --> 01:49.400
you to hit pause now and head over to Shell.ai to learn more, once again that Shell.ai.

01:49.400 --> 01:55.760
And now on to the show.

01:55.760 --> 02:01.760
Alright everyone, I am here in not-so-sunny Vancouver, continuing my conversations from the

02:01.760 --> 02:07.120
33rd NURRIPS conference and I've got the pleasure of being seated with Daphne Kohler, founder

02:07.120 --> 02:09.240
and CEO of Ensitro.

02:09.240 --> 02:11.840
Daphne, welcome to the Twomo AI podcast.

02:11.840 --> 02:12.840
Glad to be here.

02:12.840 --> 02:13.840
Thank you.

02:13.840 --> 02:20.640
Well, I historically or typically start these off by having my guests share a little bit

02:20.640 --> 02:26.080
about their backgrounds and I will certainly allow you to do that, but I feel like we could

02:26.080 --> 02:31.320
spend the entire time on your background, you've done so much in this space.

02:31.320 --> 02:37.720
We were talking before we pressed record about your history even with this conference.

02:37.720 --> 02:41.320
But without further ado, please introduce yourself to our audience.

02:41.320 --> 02:42.320
Thank you.

02:42.320 --> 02:46.440
I do feel like an old timer at this point.

02:46.440 --> 02:51.120
I was doing machine learning long, long before it became popular.

02:51.120 --> 02:58.720
So I really got into this field around 93 or 94, maybe even a little earlier than that,

02:58.720 --> 03:05.160
have been a long time participant in this conference.

03:05.160 --> 03:14.320
In fact was the program chair in 2007 and the general chair in 2008 and I very much remember

03:14.320 --> 03:22.320
how in 2007 it was the first time the conference actually hit 1,000 attendees and 1,000 papers

03:22.320 --> 03:26.960
submitted and we all thought that was really, really big and now we have...

03:26.960 --> 03:28.760
12,000, 13 this year.

03:28.760 --> 03:34.360
This is 13,000 attendees plus five on the waiting list who couldn't get in.

03:34.360 --> 03:38.360
But I don't even know how many thousands of papers were submitted.

03:38.360 --> 03:43.800
Well, the graphs I see are exponential, they are ridiculous.

03:43.800 --> 03:48.440
And so I remember the conference and what we old timers feel is the good old days when

03:48.440 --> 03:53.840
you could actually go and run into people that you know and I can't even find them because

03:53.840 --> 03:56.360
there's just such a crowd that you can't even move.

03:56.360 --> 04:01.760
So it's an interesting transition that we've seen in this space in the last three to five

04:01.760 --> 04:09.040
years and in some ways it's been an amazing resurgence for this field and I'm super excited

04:09.040 --> 04:14.320
and proud of what we as a community have accomplished but at the same time you sort of somewhat

04:14.320 --> 04:18.240
miss the intimacy of this of the community as it used to be.

04:18.240 --> 04:25.520
But anyway, coming back to the other parts of my background so I started to work in as

04:25.520 --> 04:32.400
I said machine learning in the early 90s and at that point the data sets that we as machine

04:32.400 --> 04:37.400
learning people had to work with were honestly kind of boring and lame.

04:37.400 --> 04:44.680
So I remember the 20 news group data set which were a bunch of articles from 20 news

04:44.680 --> 04:49.440
groups and one of the quote unquote challenge problems was could you figure out which news

04:49.440 --> 04:58.800
group an article came from and it was rather not super interesting also from an aspirational

04:58.800 --> 05:05.600
perspective not only from a technical perspective because you can't get a lot of enthusiasm

05:05.600 --> 05:10.280
or please I couldn't get a lot of enthusiasm for classifying articles into news groups.

05:10.280 --> 05:17.640
And so in the late 90s I started to look around for data sets that I felt would have more

05:17.640 --> 05:24.880
of an aspirational nature to them and decided to work in the space of biology because at

05:24.880 --> 05:30.800
that point biologists were actually starting to accumulate data sets that seemed more interesting.

05:30.800 --> 05:35.880
Things like the first one I worked on was actually tuberculosis infections so there is

05:35.880 --> 05:41.720
an interesting social network graph of who might have infected who with tuberculosis as

05:41.720 --> 05:44.440
well as some clinical data for each of them.

05:44.440 --> 05:50.200
I worked on some of the earliest data sets where people measured gene expression gene

05:50.200 --> 05:56.440
activity profiles for cancer patients and what could you extract from that about the

05:56.440 --> 06:03.000
types of cancer that might exist worked on some of the earliest human genetics data sets

06:03.000 --> 06:06.400
as the human genome project came about.

06:06.400 --> 06:12.400
So really at that time machine learning on biological data is actually much more interesting

06:12.400 --> 06:16.840
on a lot of other kinds of machine learning both technically and certainly from the perspective

06:16.840 --> 06:20.160
you feel like you're doing something potentially make a difference.

06:20.160 --> 06:27.320
And so that was around the as I said the late 90s early 2000s and I worked in that area

06:27.320 --> 06:29.440
for a long time.

06:29.440 --> 06:30.440
Was it all at Stanford?

06:30.440 --> 06:36.800
Yeah, this was all at Stanford with the exception of a short sabbatical at UC San Francisco

06:36.800 --> 06:40.320
where I actually spent time in a real biology lab which was great.

06:40.320 --> 06:49.760
And I think it was a really exciting trajectory at that point to see how more and more technology

06:49.760 --> 06:54.480
developments were allowing biology to be measured in a quantitative way and not just biology

06:54.480 --> 06:55.480
but also medicine.

06:55.480 --> 07:02.960
So I worked on some really I think inspiring medical problems like one of them was on how

07:02.960 --> 07:11.520
can you take the measurements that are already taken from the premature babies in a NICU?

07:11.520 --> 07:18.360
These are teeny little babies that are sometimes 28 weeks gestational age 1500 grams or about

07:18.360 --> 07:20.840
as big as the palm of your hand.

07:20.840 --> 07:27.040
And by a combination of non-invasive measurements that machine learning could extract from the

07:27.040 --> 07:34.320
bedside monitors that measure their heart rate, respiratory rate and pulse ox.

07:34.320 --> 07:39.080
Can you predict much earlier which babies are going to need more tension and are going

07:39.080 --> 07:43.440
to have more significant medical difficulties than some of the others?

07:43.440 --> 07:50.680
It was actually really exciting to be able to discover new science if you will as a

07:50.680 --> 07:54.000
byproduct of what the machine learning was able to predict.

07:54.000 --> 07:57.440
So that was a lot of fun.

07:57.440 --> 08:02.480
And so that was sort of where I thought my career would continue to evolve.

08:02.480 --> 08:06.360
I fully expected to retire as an academic.

08:06.360 --> 08:14.440
And then sort of this unexpected transition happened that where work that I'd been doing

08:14.440 --> 08:18.840
at Stanford that had really nothing to do with my research.

08:18.840 --> 08:28.640
It was a side interest in technology assisted education by a long process of a couple years

08:28.640 --> 08:34.320
in collaboration with several others of my Stanford colleagues emerged in the launch

08:34.320 --> 08:40.920
of the first three Stanford massive open online courses back in the fall of 2011.

08:40.920 --> 08:47.280
And I don't think any of us had any expectation that this would turn out the way it did, but

08:47.280 --> 08:52.080
when we looked at those courses where each of the three had a hundred thousand people

08:52.080 --> 08:56.280
or more, it was kind of I was among that first batch in Andrew's course.

08:56.280 --> 08:57.280
Okay.

08:57.280 --> 09:00.880
Well, thank you for being our first or second batch.

09:00.880 --> 09:03.600
Well, thank you for being one of our earliest users.

09:03.600 --> 09:06.320
We are grateful.

09:06.320 --> 09:12.440
And it was one of those moments in time when you look at your life and there's a huge

09:12.440 --> 09:14.280
fork in the road.

09:14.280 --> 09:18.680
And you could say, well, I can continue on my current path, which is a great path.

09:18.680 --> 09:25.840
And likely if I do that, then this thing that I accidentally helped create would just

09:25.840 --> 09:31.400
likely die away because no one else was going to like take it up and run with it.

09:31.400 --> 09:37.160
And or I can, what I expected to was put my career and hold temporarily and go through

09:37.160 --> 09:40.280
this other thing for a couple years and really get it off the ground.

09:40.280 --> 09:46.600
And so at that point, Andrew and I both decided to take a leave of absence from Stanford

09:46.600 --> 09:48.760
and go and find a course here together.

09:48.760 --> 09:54.600
And so that was something that we did kind of got started in the fall of 2011 and then

09:54.600 --> 10:00.120
our leave of absence became official in the beginning of 2012.

10:00.120 --> 10:09.000
And then I ended up doing that for about five years from the, as I said, from about the

10:09.000 --> 10:14.320
fall of 2011 to the fall of 2016.

10:14.320 --> 10:18.880
And at some point in the middle of Stanford said, well, you know, your two years leave of

10:18.880 --> 10:22.240
absence are up and so are you coming back?

10:22.240 --> 10:24.680
And I said, well, not quite yet.

10:24.680 --> 10:29.280
And I said, well, if you're not coming back, then you have to resign and I said, okay,

10:29.280 --> 10:30.280
fine.

10:30.280 --> 10:31.280
So I did.

10:31.280 --> 10:33.680
And I don't regret that at all.

10:33.680 --> 10:39.280
I mean, I guess at that point, it wasn't that standard to leave a chaired professorship

10:39.280 --> 10:41.040
at a top university.

10:41.040 --> 10:45.240
I think a lot more people are doing that now.

10:45.240 --> 10:48.920
But I think it was the right thing to do because I don't believe the company would have survived

10:48.920 --> 10:52.840
if I'd gone back to Stanford in 2014.

10:52.840 --> 10:58.800
So I left Stanford in 2014, continue the course Sarah for another couple years.

10:58.800 --> 11:04.880
And then in 2016, the company was on a great trajectory still is, by the way.

11:04.880 --> 11:07.720
But it wasn't still as primarily a content company.

11:07.720 --> 11:13.240
I mean, one can try and sprinkle machine learning here and there and try and make it better.

11:13.240 --> 11:17.080
But it's not where the core of the business really lies.

11:17.080 --> 11:24.400
And I realized that the company would do fine if I left, but whereas around me, when

11:24.400 --> 11:27.800
I looked, machine learning was changing the world.

11:27.800 --> 11:34.040
All of a sudden, all that vague promise that had wrong man to the field in the first place,

11:34.040 --> 11:37.880
we were actually in a position to make that happen.

11:37.880 --> 11:41.560
But one place that it hadn't had much of an impact was on the life sciences.

11:41.560 --> 11:47.640
And that's really what brought me back because I felt like there was an incredible opportunity

11:47.640 --> 11:55.240
to take machine learning and apply it in an area where I was one of the very few people

11:55.240 --> 11:58.120
who could actually bridge those two worlds.

11:58.120 --> 12:03.120
Because I've been doing it for a really long time and I think on one of the few people,

12:03.120 --> 12:08.560
at least at the certain level of seniority, who was truly bilingual at this point.

12:08.560 --> 12:15.000
And I think that's what you critically need in this space is a few people who can really

12:15.000 --> 12:20.080
see both sides of it and bring them together in new ways rather than just kind of, here's

12:20.080 --> 12:25.200
a problem that someone has already kind of cut and dried and defined clearly now, go

12:25.200 --> 12:26.200
solve it.

12:26.200 --> 12:27.200
Yeah.

12:27.200 --> 12:28.200
Yeah.

12:28.200 --> 12:33.840
And so there are a ton of ways that you can apply machine learning in the broad domain

12:33.840 --> 12:37.880
of life sciences, healthcare, medicine.

12:37.880 --> 12:42.640
The particular one that you are involved in is in drug discovery.

12:42.640 --> 12:43.640
Right.

12:43.640 --> 12:48.880
I've seen you talk about, and others talk about some of the context there, some of the

12:48.880 --> 12:54.800
numbers there that kind of define, you know, how drug discovery is working for us.

12:54.800 --> 12:56.640
Maybe you can share some of those.

12:56.640 --> 12:57.640
Yeah.

12:57.640 --> 13:01.720
So I think it's known to pretty much everyone.

13:01.720 --> 13:06.840
You can't open a newspaper without seeing some discussion of drug pricing.

13:06.840 --> 13:07.840
Yeah.

13:07.840 --> 13:08.840
You know it's broken.

13:08.840 --> 13:15.800
We know it's badly broken, but I don't think people fully realize where some of those

13:15.800 --> 13:18.280
difficulties emerge from.

13:18.280 --> 13:24.000
So I think there is a narrative out there that all of it is you because pharma companies

13:24.000 --> 13:29.520
are kind of trying to gouge the consumer and the insurance companies in the government.

13:29.520 --> 13:34.680
And I think it's certainly true that there has been some bad acting out there and it

13:34.680 --> 13:36.600
in ways that are inappropriate.

13:36.600 --> 13:46.920
But I think people also don't fully appreciate just how prone to failure this field is and

13:46.920 --> 13:53.920
how much investment one needs to make in time and money to find even one successful

13:53.920 --> 13:54.920
drug.

13:54.920 --> 14:00.080
So if you look at the number similar to like startup investing, worse, I think.

14:00.080 --> 14:01.080
Okay.

14:01.080 --> 14:08.520
I mean, and because the costs are larger, I mean, the cost of making a single, getting

14:08.520 --> 14:12.400
a single drug approved irrespective of whether it's a blockbuster drug that's going to make

14:12.400 --> 14:19.480
a ton of money or just something for an orphan indication is $2.5 billion and rising.

14:19.480 --> 14:22.240
We don't pump that much money into most startups.

14:22.240 --> 14:24.240
No, we do not.

14:24.240 --> 14:29.440
And now admittedly, this is when you account for the cost of all of the failures for all

14:29.440 --> 14:32.160
of the things that didn't quite make it.

14:32.160 --> 14:37.280
But even so, if you look at, well, how much amortized across the entire industry does

14:37.280 --> 14:42.880
this cost to make one successful startup, it's not nearly $2.5 billion.

14:42.880 --> 14:49.840
So I think there's, my analogy for this is that drug discovery is like a really long road.

14:49.840 --> 14:57.560
It's, you know, 15 years is a not unreasonable estimate that has multiple forks in it.

14:57.560 --> 15:01.320
One of those paths is going to get you to success.

15:01.320 --> 15:03.960
Maybe if you're lucky, 99 will not.

15:03.960 --> 15:07.280
You have no idea which of them is going to be more successful.

15:07.280 --> 15:11.440
So oftentimes it's a bit of a gut instinct or a guess.

15:11.440 --> 15:16.200
And when you take the wrong path, it's not that you find out in a matter of six months.

15:16.200 --> 15:19.800
There's not such thing as a, okay, I'm going to do a product market fit like you do on

15:19.800 --> 15:20.800
a consumer.

15:20.800 --> 15:22.320
You don't fast fail.

15:22.320 --> 15:27.480
It's three years and hundreds of millions of dollars before you slow fail.

15:27.480 --> 15:32.680
And so it makes it very challenging to do this type of process.

15:32.680 --> 15:36.840
And one of the things that we really are hoping to do is to use machine learning to build

15:36.840 --> 15:38.920
where you might think it was a compass.

15:38.920 --> 15:43.400
Something that when you get to these forks in the road, you have a predictive model that

15:43.400 --> 15:48.520
is machine learning trained that says, you know, here's my probability distribution on

15:48.520 --> 15:50.800
the success of each of those paths.

15:50.800 --> 15:54.120
So here's the one that I recommend that you follow.

15:54.120 --> 16:01.720
And that's something that we hope will help avoid a lot of the wrong paths that are currently

16:01.720 --> 16:07.360
being taken and allow us to get to a successful drug much faster because you don't end up

16:07.360 --> 16:12.160
taking all that time to follow the wrong forks and with a much, much lower cost because

16:12.160 --> 16:17.680
if you're not spending all that effort on things that are not going to succeed, then hopefully

16:17.680 --> 16:22.800
that will really help bend that ridiculous cost curve that has come to be called e-rooms

16:22.800 --> 16:25.520
law, which is an interesting e-rooms law.

16:25.520 --> 16:26.520
e-rooms law.

16:26.520 --> 16:30.760
If you think about e-room, e-r-o-o-m, it's the inverse of Moore's law.

16:30.760 --> 16:31.760
Wow.

16:31.760 --> 16:32.760
Okay.

16:32.760 --> 16:37.760
And Moore's law is the exponential increase in productivity on the tech side, e-rooms

16:37.760 --> 16:44.240
laws, the exponential decrease in productivity on drug discovery in that the cost, the number

16:44.240 --> 16:50.520
of drugs approved per billion U.S. dollars has been decreasing exponentially consistently

16:50.520 --> 16:51.840
for the past 70 years.

16:51.840 --> 16:52.840
Wow.

16:52.840 --> 17:00.520
And in thinking about that law, is it, you know, how much of that is friction in the

17:00.520 --> 17:07.600
discovery process regulation, that kind of thing versus some kind of fundamental, you

17:07.600 --> 17:12.760
know, we just running out of things to try or, you know, we losing ground to disease

17:12.760 --> 17:15.760
and generally, like, what's the way to think about all the components of that?

17:15.760 --> 17:17.760
I think that's a really excellent question.

17:17.760 --> 17:23.160
And people have written entire papers trying to tease apart the different factors here.

17:23.160 --> 17:30.080
Partly, I think there's a legitimate case to be made that there's an increased regulatory

17:30.080 --> 17:36.400
burden, some justified trying to be more careful about the lives and health of patients in

17:36.400 --> 17:41.240
clinical trials, some less justified, just lots of bureaucracy and paperwork, doesn't

17:41.240 --> 17:43.320
actually add value, but it'll cost money.

17:43.320 --> 17:45.040
I think that's part of it.

17:45.040 --> 17:53.120
I think another part of it is what Jack's channel was one of the bigger experts in the

17:53.120 --> 17:59.880
space calls the better than the Beatles problem, which is that when you're in the

17:59.880 --> 18:08.120
business of movies or books and you're looking for the next blockbuster, next song, next

18:08.120 --> 18:15.560
movie, the movies from the past, the books from the past, people are looking for new stuff

18:15.560 --> 18:22.120
because they may have already consumed that old stuff and they want a new piece of content.

18:22.120 --> 18:23.120
That's not true for drugs.

18:23.120 --> 18:27.640
I mean, you actually have to be better than all the previously approved drugs for this

18:27.640 --> 18:30.640
to make sense.

18:30.640 --> 18:34.480
Doctors are not looking for the next thing.

18:34.480 --> 18:39.080
If you actually want to be better, if you want to actually have a market, you have to

18:39.080 --> 18:45.280
actually be better than everything that's been come before and has been approved.

18:45.280 --> 18:53.200
The floor keeps rising, if you will, the bar that you have to overcome keeps rising.

18:53.200 --> 18:58.320
I think when you look at it in that light, there's a couple of different, you can think

18:58.320 --> 19:01.240
of it as almost like a dichotomy, if you will.

19:01.240 --> 19:08.280
There's things for which we've already done a pretty decent job of making drugs, cardiovascular

19:08.280 --> 19:12.680
disease, diabetes, infectious disease.

19:12.680 --> 19:16.360
There are some pretty good drugs out there.

19:16.360 --> 19:22.360
The next drug really has to be better and to prove that it's better, you actually, in

19:22.360 --> 19:26.280
many cases, need a very large and very expensive clinical trial.

19:26.280 --> 19:32.560
Then there is the classes of diseases for which we really don't have any good drugs.

19:32.560 --> 19:39.240
I think of those CNS disease of the neural, of the central nervous system is probably

19:39.240 --> 19:42.000
the most obvious category.

19:42.000 --> 19:45.800
That's because we have, it's such a complicated system.

19:45.800 --> 19:50.360
We do not understand it, probably won't for a very long time in the level of mechanistic

19:50.360 --> 19:52.320
understanding.

19:52.320 --> 19:57.200
The model systems that we've been using developed drugs to disease in general, which are typically

19:57.200 --> 20:04.680
animal models, are a very far cry from the human central nervous system.

20:04.680 --> 20:09.400
It turns out that it just doesn't translate in the sense that we find drugs that make

20:09.400 --> 20:19.840
mice smarter, have less, more empathic, have less neuronal death, and it just doesn't

20:19.840 --> 20:24.160
translate into human disease, largely because the mice don't get the disease in the first

20:24.160 --> 20:25.560
place.

20:25.560 --> 20:30.760
Therefore, you are artificially creating a disease in the mouse, and when you cure the artificial

20:30.760 --> 20:34.680
disease, it turns out to have very little to do with curing the real disease.

20:34.680 --> 20:35.680
Interesting.

20:35.680 --> 20:36.680
Interesting.

20:36.680 --> 20:44.400
In Cetra, when you're thinking about this kind of compass analogy of what you do and whoever

20:44.400 --> 20:50.560
the actor is in this case is at the fork in the road, are you using machine learning to

20:50.560 --> 21:00.760
evaluate the efficacy potentially of some compound as a treatment, or are you applying machine

21:00.760 --> 21:06.720
learning to the broader system, like was the probability distribution that you're creating

21:06.720 --> 21:11.640
one that is incorporating market factors, and all these other things, are you really focused

21:11.640 --> 21:13.400
on the biology at this point?

21:13.400 --> 21:19.640
At this point, focus on the biology, and down the line, we might focus on the chemistry,

21:19.640 --> 21:24.120
and then maybe on things like the selection of patients for the clinical trial to identify

21:24.120 --> 21:30.960
the ones that are more likely to be responsive to the drug, and then downstream from that

21:30.960 --> 21:36.760
is, can we use machine learning to have better biomarkers of efficacy so that you can actually

21:36.760 --> 21:42.800
tell whether a patient is responding to your drug in ways other than literally a questionnaire

21:42.800 --> 21:48.080
that's filled out on sheets of paper that a nurse then transcribes into the computer,

21:48.080 --> 21:52.880
which is how this is often done, and even downstream in the manufacturing.

21:52.880 --> 21:57.520
I think there's a lot of opportunities before we get to market factors and things like

21:57.520 --> 21:58.520
that.

21:58.520 --> 22:07.680
Right now, our primary focus is really on the biology and making a prediction on if I make

22:07.680 --> 22:13.520
this intervention in a human, or even in this particular human, how likely is this human

22:13.520 --> 22:14.520
to respond?

22:14.520 --> 22:18.200
What is the clinical outcome going to be of that intervention?

22:18.200 --> 22:21.520
That's a very challenging problem to make a prediction on, but I think there's some

22:21.520 --> 22:26.040
of your tools out there, both on the machine learning and on the biology side, that if you

22:26.040 --> 22:29.000
put them together, give us a chance of making human predictions.

22:29.000 --> 22:35.960
That sounds to me like a personalized medicine type of application, which seems much further

22:35.960 --> 22:39.520
down than the, I'm at a compass trying to develop a drug.

22:39.520 --> 22:45.040
Yeah, no, the personalization is, I think, not really the key focus of what we're doing,

22:45.040 --> 22:51.360
but rather the recognition that a lot of the drugs that people have tried haven't succeeded

22:51.360 --> 22:55.360
because you're treating multiple diseases with one drug.

22:55.360 --> 23:02.680
So if you look at the big success in the field of precision oncology in the last decade

23:02.680 --> 23:08.080
or so, a lot of the successes have come from the realization that breast cancer, for

23:08.080 --> 23:11.160
instance, is not one disease.

23:11.160 --> 23:15.560
The patients who are hurt too positive are very different from the patients who have

23:15.560 --> 23:20.800
a block of one mutation, and you treat them with completely different therapies.

23:20.800 --> 23:25.840
Colleagues of mine who worked at Genenteic at the time that herceptin, which is the drug

23:25.840 --> 23:31.600
that targets her two positive breast cancers, was developed, say that if you had applied,

23:31.600 --> 23:36.840
if you tried out herceptin in an all-comers breast cancer population, you'd need a clinical

23:36.840 --> 23:41.240
trial of about 10,000 women in order to demonstrate even the tiny effect size because you're

23:41.240 --> 23:45.800
averaging out on a whole bunch of people who are not going to respond, but nevertheless

23:45.800 --> 23:47.120
have side effects.

23:47.120 --> 23:51.480
So in your case, it's less about personalization than targeting, really.

23:51.480 --> 23:52.480
Exactly.

23:52.480 --> 23:54.240
Targeting to the right patient population.

23:54.240 --> 24:00.400
You mentioned part of the opportunity here is kind of the application of new machine learning

24:00.400 --> 24:01.920
techniques to this round.

24:01.920 --> 24:06.680
What's kind of the landscape of techniques that you're able to apply?

24:06.680 --> 24:13.960
One of the things that we are doing is relying both on new developments in machine learning,

24:13.960 --> 24:21.280
but at the same time, on new developments in high throughput biology and bioengineering.

24:21.280 --> 24:27.560
That's a space where maybe less familiar to folks who are more expert in the technology

24:27.560 --> 24:31.720
side of things, but there's been as much progress on that side as there's been on machine

24:31.720 --> 24:32.720
learning.

24:32.720 --> 24:39.600
So, for instance, at this point, there is the capability for us to take a small sample

24:39.600 --> 24:47.000
of your skin or a small sample of your blood, then transform that some of those cells into

24:47.000 --> 24:51.680
what are called stem cells, and these are those cells that can then turn into any lineage

24:51.680 --> 24:52.680
in your body.

24:52.680 --> 25:00.000
I can basically create Daphne neurons, or Daphne cardiomyocytes, or Daphne hepatocytes,

25:00.000 --> 25:04.320
and all of them have the genetics that I have.

25:04.320 --> 25:09.840
So, if I have a certain propensity to disease that manifests in that particular cell type,

25:09.840 --> 25:14.400
you could potentially see it there, but it's the right cell lineage.

25:14.400 --> 25:19.080
And so, I have the ability at this point to basically do population diversity, but at

25:19.080 --> 25:21.000
the cellular level.

25:21.000 --> 25:26.240
And I have the further ability to use amazing technologies like CRISPR that allow us to

25:26.240 --> 25:30.920
modify the genome to even create mutations that we know are disease-causing.

25:30.920 --> 25:36.520
So, for instance, if I want to really see what a very high penetrant version of the disease

25:36.520 --> 25:42.680
looks like, I can introduce that mutation into a normal genome and see what the difference

25:42.680 --> 25:45.360
is between the width of mutation without the mutation.

25:45.360 --> 25:51.800
So, think of it as the ability to artificially create training sets on what disease looks

25:51.800 --> 25:53.600
like at the cellular level.

25:53.600 --> 25:54.600
Interesting.

25:54.600 --> 25:59.120
And so, now, you think about, well, that gives me a ton of data because you have potentially

25:59.120 --> 26:05.120
hundreds of genetic backgrounds, maybe even more, with tens of thousands of readouts from

26:05.120 --> 26:11.640
each of those cells, like the kind you might get from super-resolution microscopy, or

26:11.640 --> 26:15.640
transcriptional measurements of all of the genes in the cell.

26:15.640 --> 26:19.520
And now, you ask yourself, okay, with all of those measurements, if this is what healthy

26:19.520 --> 26:27.480
looks like, and this is all the population of unhealthy, what differentiates them?

26:27.480 --> 26:31.320
What does healthy cell look like relative to an unhealthy cell?

26:31.320 --> 26:36.280
And are the unhealthy cells, or are they all one big homogeneous cluster, or are there

26:36.280 --> 26:40.960
subclusters that are very distinctive of the molecular level?

26:40.960 --> 26:47.520
And then, with that, you have an understanding of what the disease looks like at the level

26:47.520 --> 26:50.760
of cellular phenotypes, as they're called.

26:50.760 --> 26:54.200
And because it's an intervenable system, it's not a human.

26:54.200 --> 26:57.200
We're doing an experiment and a human is really hard.

26:57.200 --> 27:04.000
You can ask yourself, if I put this compound into a bunch of cells that are from this cluster,

27:04.000 --> 27:07.760
does that revert the phenotype back to something that looks healthier?

27:07.760 --> 27:11.840
And if it does, maybe that's a drug that will also revert the phenotype at the clinical

27:11.840 --> 27:15.360
outcome level, which is what we ultimately care about, because you want to hear people

27:15.360 --> 27:16.680
not cells.

27:16.680 --> 27:22.360
So basically, you can think about the machine learning as helping us to distinguish between

27:22.360 --> 27:27.600
different cellular phenotypes in a way that aligns with human clinical outcome.

27:27.600 --> 27:28.600
Interesting.

27:28.600 --> 27:34.280
And so, from that perspective, is it primarily kind of unsupervised clustering types of

27:34.280 --> 27:41.200
approaches that you find most useful in your work, or is it a broad set of things?

27:41.200 --> 27:45.360
It's actually a broad set of things, because we do have some supervision signal, not as

27:45.360 --> 27:51.240
much as you would like, because there is, for instance, some understanding that if you

27:51.240 --> 27:54.600
have this mutation, then your chances of disease are really high.

27:54.600 --> 27:58.800
So you can think of it as kind of like a bit of a supervision signal, or you have supervision

27:58.800 --> 28:04.000
signal in the sense of, here is a hundred of these what's called induced pluripotent stem

28:04.000 --> 28:05.000
cells, IPS.

28:05.000 --> 28:08.600
Induced pluripotent stem cells.

28:08.600 --> 28:12.680
So pluripotent means they can go into multiple lineages, and induced means I created them

28:12.680 --> 28:16.480
from a skin sample rather than it's a fetal stem cell.

28:16.480 --> 28:22.040
So you have these IPS cells that you got from patients, that's the positives, and you

28:22.040 --> 28:25.880
have the IPS cells that you got from controls, that's the negatives.

28:25.880 --> 28:30.360
So there is a little bit of supervision signal, but certainly not as much as you want, and

28:30.360 --> 28:34.760
so I think if you had to put a label on it, it falls largely in the category of weekly

28:34.760 --> 28:39.600
supervised learning, not completely unsupervised, not completely supervised, but somewhere in

28:39.600 --> 28:40.600
between.

28:40.600 --> 28:41.600
Got it, got it.

28:41.600 --> 28:47.800
And as you describe this, you can almost envision a kind of closed loop process where you're

28:47.800 --> 28:54.480
able to, you know, I've seen some of the like the bio robots that can, you know, take

28:54.480 --> 28:58.640
an array and do all kinds of experiments at, you know, high throughput.

28:58.640 --> 28:59.640
Are you there yet?

28:59.640 --> 29:00.640
Absolutely.

29:00.640 --> 29:01.640
Okay.

29:01.640 --> 29:02.640
Well, we, sorry.

29:02.640 --> 29:03.640
Let me, let me.

29:03.640 --> 29:06.080
For those who can't see you, she's getting very excited.

29:06.080 --> 29:07.080
Yes.

29:07.080 --> 29:11.520
Now, that's definitely in our roadmap, and it's what we're working towards.

29:11.520 --> 29:13.200
The robots are already there.

29:13.200 --> 29:14.200
Yeah.

29:14.200 --> 29:22.080
They're doing a lot of the high throughput, more menial work automatically at this point.

29:22.080 --> 29:27.120
We don't have the full-blown closed loop system yet, because we only just got the lab

29:27.120 --> 29:28.440
up and running.

29:28.440 --> 29:34.800
But the goal is exactly that we would have the ability to take data off the instruments,

29:34.800 --> 29:42.560
process it automatically, and then use what we see to guide the next round of experiments.

29:42.560 --> 29:48.760
And I think that's going to be incredibly powerful, both at the high level of, you know,

29:48.760 --> 29:54.840
the high, just the experiments in terms of what makes for sick versus healthy cells.

29:54.840 --> 30:00.400
But we actually embed machine learning in every single part of what we do.

30:00.400 --> 30:09.560
So for instance, imaging a plate with imaging plate at 40X resolution across multiple

30:09.560 --> 30:12.920
fluorescent channels can take as long as 30 days.

30:12.920 --> 30:18.240
So very long experiment, because you just have to do tile by tile by tile.

30:18.240 --> 30:26.800
Do you really need to image every well and every tile in every well at 40X resolution,

30:26.800 --> 30:30.600
or can you imagine using machine learning to say, I'm going to do a very quick pass at

30:30.600 --> 30:31.600
10X.

30:31.600 --> 30:32.600
See where they're sitting.

30:32.600 --> 30:34.080
See where the interesting things are.

30:34.080 --> 30:38.800
And then dig down a higher resolution into the cells that are more likely to be interesting.

30:38.800 --> 30:42.760
You can think about machine learning in all sorts of different places, or here's another

30:42.760 --> 30:43.760
example.

30:43.760 --> 30:47.360
Do you really need to image every single one of those fluorescent channels, or can you

30:47.360 --> 30:53.440
infer from some channels what the other ones are going to be, and then image fewer channels?

30:53.440 --> 30:54.440
It sounds easy.

30:54.440 --> 30:58.080
But then I'm envisioning these, you know, you're not building the robots from scratch, you're

30:58.080 --> 31:03.320
getting them from roast or whoever or life sciences, and, you know, they're proprietary

31:03.320 --> 31:05.320
about the way that they control their robots.

31:05.320 --> 31:10.080
Like, can you easily insert your machine learning models into these off-the-shelf tools?

31:10.080 --> 31:11.720
So first of all, is that even an issue?

31:11.720 --> 31:12.720
Am I picking at the right thing?

31:12.720 --> 31:13.720
No, you're here.

31:13.720 --> 31:14.720
You're absolutely right.

31:14.720 --> 31:17.600
It is definitely an issue.

31:17.600 --> 31:24.640
Some manufacturers are more open than others in terms of making their APIs available so

31:24.640 --> 31:32.240
that you can control the robot, you can control the microscope, for instance, from the outside.

31:32.240 --> 31:36.880
And sometimes we have to actually kind of hack into this a little bit, but sometimes

31:36.880 --> 31:39.200
they're being more flexible.

31:39.200 --> 31:44.440
And in some cases, we actually build custom hardware because we have to do that, because

31:44.440 --> 31:48.640
it provides us the flexibility that we need both on the hardware side as well as the software

31:48.640 --> 31:49.640
side.

31:49.640 --> 31:50.640
Yeah.

31:50.640 --> 31:56.640
So we've talked through some examples of the kinds of problems that you're solving this

31:56.640 --> 31:57.640
way.

31:57.640 --> 32:02.560
I think there's still a hole for me in like the where do you start?

32:02.560 --> 32:03.560
What's the first step?

32:03.560 --> 32:06.080
What's the next step like?

32:06.080 --> 32:16.400
So I think the first step is really to build a team that is truly cross-functional and

32:16.400 --> 32:24.440
is able to communicate across what is usually a chasm between these two disciplines.

32:24.440 --> 32:31.760
Most machine learning people took biology, maybe back in high school sometime, and have

32:31.760 --> 32:35.080
a vague recollection of what they learned, but not much beyond that.

32:35.080 --> 32:41.800
I mean, there's so much there in what you're doing is biology, it's chemistry, it's genetics.

32:41.800 --> 32:47.040
And on the other side, most biologists don't really know much about computer science or

32:47.040 --> 32:48.880
machine learning.

32:48.880 --> 32:54.280
They may have done some whatever data analysis and an Excel spreadsheet, but it's really

32:54.280 --> 32:57.560
two communities that don't have a lot of common language.

32:57.560 --> 33:05.360
And one of the things that we're really building is a community of people who really either

33:05.360 --> 33:12.720
have a foot niche camp and we have a bunch of those people who are truly bilingual, or

33:12.720 --> 33:18.040
even if they don't, they have a real willingness to kind of reach out across the chasm and have

33:18.040 --> 33:20.000
a meaningful collaboration.

33:20.000 --> 33:26.440
And I think that's absolutely essential because so much of what we do really requires this

33:26.440 --> 33:28.840
interaction between both sides.

33:28.840 --> 33:35.080
And what we find today is that once you bridge that gap, you actually are in some ways

33:35.080 --> 33:38.960
programming into programming language simultaneously.

33:38.960 --> 33:44.400
There is the programming language of whatever TensorFlow or PyTorch, which we all are used

33:44.400 --> 33:47.120
to when we think about computational modules.

33:47.120 --> 33:53.600
But then there is equally valid experimental modules that you can kind of fit in.

33:53.600 --> 33:59.480
Like here's a set of CRISPR guides, introduce those CRISPR guides into the following set

33:59.480 --> 34:04.200
of cells, differentiate this set of cells into the following lineage.

34:04.200 --> 34:06.960
And I'm not saying each of those steps is easy.

34:06.960 --> 34:10.960
They're actually harder in some ways than the computational steps because it's a little,

34:10.960 --> 34:14.760
I mean, big subologies finicky and these are live cells and they don't always do what

34:14.760 --> 34:19.920
they're told, unlike the bits in the computer, which generally do do what they're told.

34:19.920 --> 34:26.080
But you can still create a level of abstraction on those biological steps that you can incorporate

34:26.080 --> 34:27.960
into your overall procedure.

34:27.960 --> 34:33.280
So your procedure now has blocks that are computational and blocks that are biological.

34:33.280 --> 34:39.040
And it's a single, almost integrated process where these different pieces fit together.

34:39.040 --> 34:44.640
And the whole is considerably larger than the sum of the parts where the typical approach

34:44.640 --> 34:49.120
is, okay, the biologists create some data, throw it over the fence, and then someone does

34:49.120 --> 34:50.120
the analysis.

34:50.120 --> 34:55.600
When you have this sort of real integration of those two steps, the space of what you

34:55.600 --> 34:59.880
can do is obviously exponentially larger.

34:59.880 --> 35:05.120
And therefore, it opens up capabilities to even, to think about problems that you would

35:05.120 --> 35:09.280
never even have thought about far less been able to solve without the integration of those

35:09.280 --> 35:10.280
tools.

35:10.280 --> 35:16.280
I've got to imagine as the CEO of a company that depends so heavily on finding people

35:16.280 --> 35:22.400
with these two independently unique skillsets, not to mention together, you maybe have an

35:22.400 --> 35:30.840
interesting perspective on auto-ML and lowering the barriers to getting to the, at least on

35:30.840 --> 35:34.840
the computational side, any reaction to that?

35:34.840 --> 35:43.000
I think that auto-ML is a great enabler in some ways in that when you get to the point

35:43.000 --> 35:51.440
that you have defined a problem that has well defined input output specifications, you

35:51.440 --> 35:56.760
know, you want to train your algorithm on the following, you want to train whatever predictor

35:56.760 --> 36:00.960
on the following dataset with these inputs and these outputs and the subjective function,

36:00.960 --> 36:06.840
then it allows you to avoid some of the annoying nitty gritty of hyperparameter architecture

36:06.840 --> 36:07.840
search.

36:07.840 --> 36:16.200
It doesn't do at all is tell you what problems to solve and what's the right data to create

36:16.200 --> 36:20.680
because we create our own data, so what data do you even create?

36:20.680 --> 36:23.880
What's the right objective to train the model too?

36:23.880 --> 36:28.520
Because that actually matters if you train your algorithm to regression and might not do

36:28.520 --> 36:33.560
as good a job at classification and vice versa and which is the right one for the problem

36:33.560 --> 36:39.400
that you're trying to solve is not clear and this is the simplest example that one can do.

36:39.400 --> 36:46.280
So I think it's going to help but I don't think it's going to solve the problem for us

36:46.280 --> 36:51.520
and I think also for a lot of other people because the heart of what a really good machine

36:51.520 --> 36:57.840
learning person can do is understand the domain enough that you can identify in your problems

36:57.840 --> 36:59.320
if no one has thought about.

36:59.320 --> 37:04.280
It sounds like that's the stage of the journey that your company is at very much so.

37:04.280 --> 37:09.840
And I think that's hopefully the stage of the journey that we will be at for a long

37:09.840 --> 37:13.840
time, not that we won't be solving some of the problems that we come up with today,

37:13.840 --> 37:20.160
but I think there's so many of those problems that one could imagine making a big impact

37:20.160 --> 37:25.400
on in the drug discovery and development process that even once we nail some of the earlier

37:25.400 --> 37:29.960
problems and maybe move more towards this iterative refinement mode, there's going to

37:29.960 --> 37:31.880
be new problems that we're going to have to tackle.

37:31.880 --> 37:38.080
When you think about the broad landscape of problems that gets us most quickly to a

37:38.080 --> 37:44.560
healthier population, how do you segment those or think about that landscape in terms

37:44.560 --> 37:49.960
of where are the opportunities for folks that are interested in applying machine learning

37:49.960 --> 37:51.480
to make folks healthier?

37:51.480 --> 37:52.480
Oh, I see.

37:52.480 --> 37:57.440
The drug discovery and in particular, you know, you're working on a specific niche within

37:57.440 --> 37:58.440
drug discovery.

37:58.440 --> 38:00.760
What are some other things that you think are interesting?

38:00.760 --> 38:08.360
Well, I think we're working today on a particular phase in the drug discovery process.

38:08.360 --> 38:13.640
It's not by any means the place that will end up because this for us is the beginning

38:13.640 --> 38:22.080
of the journey towards building what I hope will be the, you know, first fully data-enabled,

38:22.080 --> 38:27.240
data-driven drug discovery and development companies so that every step of the process

38:27.240 --> 38:34.080
is now based on data production and machine learning as core technologies.

38:34.080 --> 38:40.120
And I think that you've seen companies like that emerge in other parts of the tech space

38:40.120 --> 38:49.280
where, for instance, Amazon is a fully data-enabled retail company and it's not just in, you

38:49.280 --> 38:56.000
know, the early days of just being a little bit better at recommending items to you and

38:56.000 --> 39:01.360
having the orders be all managed automatically now to every step of the way they're enabled

39:01.360 --> 39:03.120
using data and machine learning and technology.

39:03.120 --> 39:06.560
We hope to be doing that for drug discovery and development.

39:06.560 --> 39:14.160
Before we go to other areas, are the traditional drug discovery companies that far behind?

39:14.160 --> 39:20.800
You know, I think there are islands in some of those companies where they're trying to

39:20.800 --> 39:28.080
bring in machine learning and technology to accelerate things, you know, and it varies.

39:28.080 --> 39:32.880
There was a recent announcement about one company that's using it to accelerate some manufacturing

39:32.880 --> 39:38.880
processes and another one that's using it to enable better design of small molecule binders

39:38.880 --> 39:44.880
to a particular protein. Most of those efforts fall into the category of, here's a problem

39:44.880 --> 39:50.960
I'm already solving anyway. I'm solving it, not maybe not in the perfect way, maybe it's

39:50.960 --> 39:55.280
too slow, maybe I can introduce some additional optimization, so I'm going to use a machine

39:55.280 --> 39:56.280
learning document.

39:56.280 --> 40:07.520
It's probably going to reduce the cost by whatever 20% or something like that. That's great,

40:07.520 --> 40:15.040
it's not transformative. I don't know of any companies that are in the process of saying,

40:15.040 --> 40:18.000
okay, no, we're just going to have to rethink the process from the ground up.

40:19.760 --> 40:26.160
One way of thinking about this, I don't know if it's true, is to ask whether of the big tech

40:26.160 --> 40:33.360
giants that are really fully data enabled from beginning to end, did any of them actually emerge

40:33.360 --> 40:40.640
from the existing incumbents? Amazon did not emerge from Walmart and Netflix didn't emerge

40:40.640 --> 40:47.040
from blockbusters or one of the Hollywood studios and Google didn't emerge from the yellow pages.

40:49.440 --> 40:56.480
These are all kind of the non-peck enabled precursors to those companies and in some cases,

40:56.480 --> 41:01.040
you need to ask yourself, okay, if I was building this from scratch, what would it look like?

41:01.040 --> 41:08.240
So, answer the second part of your earlier question. I think clearly there's opportunities

41:08.240 --> 41:15.440
beyond drug discovery and development. There's some interesting work happening in the device space

41:16.000 --> 41:23.280
in terms of using the mobile phone that we all carry in our pockets to give us both

41:23.280 --> 41:31.520
better tracking of our health state and better nudges to take a healthier lifestyle. Move us

41:31.520 --> 41:38.000
towards the tricorder? Yeah, move us forward to tricorder. I think the challenges here are that the

41:38.560 --> 41:45.360
folks that carry these devices and require those lifestyle changes are not nearly as obedient as

41:45.360 --> 41:52.320
the folks on Star Trek. So compliance is an issue. I think there's some interesting work that's

41:52.320 --> 41:59.200
happening in that space, but it's a road that has its own challenges. It's not maybe as much of

41:59.200 --> 42:05.440
a scientific challenge, but there's a lot of questions about human psychology and affecting

42:05.440 --> 42:12.560
behavior change. I think there's some interesting work that's happening in hospitals as well as

42:12.560 --> 42:22.640
potentially in insurance companies for early warning systems for getting people into care or

42:23.760 --> 42:29.360
warning the physicians and an emergency care ward that sounds a lot to crash or about to have

42:30.080 --> 42:34.800
a sepsis attack or something, and I think that's an interesting space. I think there's a lot of

42:34.800 --> 42:41.360
places where one can ask with the new tools that we have in hand the new ability to collect large

42:41.360 --> 42:46.880
amounts of data. What are problems that we can just solve that almost really ever try to solve

42:46.880 --> 42:52.160
before? Awesome. Awesome. Well, definitely thanks so much for taking some time to share with us

42:52.160 --> 42:56.720
what you're up to. Clearly very exciting stuff and pleasure meeting and chatting with you.

42:57.520 --> 43:00.000
It's been a pleasure for me too. Thank you for having me. Thank you.

43:02.400 --> 43:08.000
All right, everyone. That's our show for today. For more information on today's guest or our

43:08.000 --> 43:16.640
NURPS podcast series, head over to twimlai.com slash NURPS 2019. Thanks once again to Shell for

43:16.640 --> 43:23.680
sponsoring this week's series. Check out the shell.ai Residency program by typing shell.ai

43:23.680 --> 43:38.560
into your browsers address bar. Thanks so much for listening. Happy holidays and catch you next time.

