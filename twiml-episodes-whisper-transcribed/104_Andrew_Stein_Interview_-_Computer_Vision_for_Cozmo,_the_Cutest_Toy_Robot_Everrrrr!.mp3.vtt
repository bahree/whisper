WEBVTT

00:00.000 --> 00:16.120
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

00:16.120 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:29.320
I'm your host Sam Charrington.

00:29.320 --> 00:37.600
This week we have a jam-packed intro including a new contest we're launching, so please

00:37.600 --> 00:41.400
bear with me, you don't want to miss this one.

00:41.400 --> 00:44.720
First, a bit about this week's shows.

00:44.720 --> 00:49.400
As you may know, I spent a few days at CES earlier this month.

00:49.400 --> 00:54.240
While there, I spoke with a bunch of folks applying AI in the consumer electronics industry

00:54.240 --> 00:59.040
and I'm including you in those conversations via this series of shows.

00:59.040 --> 01:03.480
Stay tuned as we explore some of the very cool ways that machine learning and AI are being

01:03.480 --> 01:06.600
used to enhance our everyday lives.

01:06.600 --> 01:11.320
This includes work being done at Anki, who built Cosmo, the cutest little computer vision

01:11.320 --> 01:13.280
powered robot.

01:13.280 --> 01:18.840
Lighthouse, whose smart home security camera combines 3D sensing with deep learning and

01:18.840 --> 01:19.840
NLP.

01:19.840 --> 01:25.760
Intel, who's using the single shot multi-box image detection algorithm to personalize

01:25.760 --> 01:29.680
video fees for the Ferrari Challenge North America.

01:29.680 --> 01:34.480
First beat, a company whose machine learning algorithms analyzed your heartbeat data to

01:34.480 --> 01:40.360
provide personalized insights into stress, exercise, and sleep patterns.

01:40.360 --> 01:45.520
Reality AI and Coeto, who have partnered to bring machine learning based adaptive driving

01:45.520 --> 01:50.240
beams or automatically adjusting high beams to the U.S.

01:50.240 --> 01:57.480
In last but not least, aerial.ai, who applies sophisticated analytics to Wi-Fi signals to

01:57.480 --> 02:03.640
enable some really interesting home automation and healthcare applications.

02:03.640 --> 02:09.320
Now as if six amazing interviews wasn't enough, a few of these companies have been so kind

02:09.320 --> 02:13.520
as to provide us with products for you, the Twimal Community.

02:13.520 --> 02:18.280
In keeping with the theme of this series, our contest will be a little different this time.

02:18.280 --> 02:23.400
To enter, we want to hear from you about the role AI is playing in your home in personal

02:23.400 --> 02:26.640
life and where you see it going.

02:26.640 --> 02:33.240
Just head on over to Twimalai.com slash My AI Contest, fire up your webcam or smartphone

02:33.240 --> 02:37.120
camera and tell us your story in two minutes or less.

02:37.120 --> 02:41.600
We'll post the videos to YouTube and the video with the most likes wins their choice of

02:41.600 --> 02:48.120
great prizes including an Anki Cosmo, a lighthouse smart home camera, and more.

02:48.120 --> 02:53.160
The missions will be taken until February 11th and voting will remain open until February

02:53.160 --> 02:54.480
18th.

02:54.480 --> 03:00.160
Good luck.

03:00.160 --> 03:04.560
Before we dive into today's show, I'd like to thank our friends at Intel AI for their

03:04.560 --> 03:07.560
continued support of this podcast.

03:07.560 --> 03:12.800
Intel was extremely active at this year's CES, with a bunch of AI, autonomous driving

03:12.800 --> 03:15.240
and VR related announcements.

03:15.240 --> 03:18.960
One of the more interesting partnerships they announced was a collaboration with the

03:18.960 --> 03:22.720
Ferrari Challenge North America race series.

03:22.720 --> 03:27.440
Along with the folks at Ferrari Challenge, Intel AI aspires to make the race viewing experience

03:27.440 --> 03:33.720
more personalized by using deep computer vision to detect and monitor individual race cars

03:33.720 --> 03:38.840
via camera feeds and allow viewers to choose the specific cars feeds that they'd like

03:38.840 --> 03:40.880
to watch.

03:40.880 --> 03:45.800
Look for my conversation with Intel's Andy Keller and Emil Chindicki later in this series

03:45.800 --> 03:52.520
for an in-depth discussion about this project and be sure to visit ai.intel.com where you'll

03:52.520 --> 03:56.080
find Andy's technical blog post on the topic.

03:56.080 --> 03:59.360
And now a bit about today's show.

03:59.360 --> 04:04.800
In this episode, I'm joined by Andrew Stein, computer vision engineer at Anki and is partnering

04:04.800 --> 04:09.240
crime Cosmo, a toy robot with tons of personality.

04:09.240 --> 04:13.480
Andrew joined me during the hustle and bustle of CES a few weeks ago to give me some insight

04:13.480 --> 04:18.440
into how Cosmo works, plays and learns, and how he's different from other consumer robots

04:18.440 --> 04:20.680
you may know like the Roomba.

04:20.680 --> 04:25.920
We discussed the different types of algorithms that help power Cosmo, like facial identification,

04:25.920 --> 04:31.120
3D pose recognition, reasoning, and even some simple emotional AI.

04:31.120 --> 04:37.200
We also cover Cosmo's functionality and programmability, including a cool feature called CodeLab.

04:37.200 --> 04:41.640
This was a really fun interview and you should also check out the companion video on YouTube

04:41.640 --> 04:46.200
starring Cosmo himself, which of course will link to in the show notes page.

04:46.200 --> 04:53.200
Alright everyone, I am here at CES and I am with Andrew Stein.

04:53.200 --> 04:59.280
Andrew is a computer vision engineer at Anki and Anki is, well I'll let Andrew tell

04:59.280 --> 05:00.680
you all about Anki.

05:00.680 --> 05:03.280
Andrew, welcome to this weekend machine learning and AI.

05:03.280 --> 05:05.080
Thanks, thanks, it's cool to be here.

05:05.080 --> 05:09.120
Yeah, I can tell you a little bit about Anki's background and then a little bit about

05:09.120 --> 05:13.800
our products and Cosmo specifically.

05:13.800 --> 05:18.400
Anki is a consumer robotics company and we currently have two products that are both

05:18.400 --> 05:20.800
in the entertainment space.

05:20.800 --> 05:23.800
One is Anki Overdrive, which is a car racing game.

05:23.800 --> 05:27.920
It's been out for several years and you can control the cars from your phone and they

05:27.920 --> 05:31.840
can drive themselves and you play against them like you would play in a video game but instead

05:31.840 --> 05:35.040
of looking at a screen you've got actual cars driving around on a real track and you

05:35.040 --> 05:37.040
are living.

05:37.040 --> 05:41.080
And sort of along those same lines which in some sense is bringing a physical product

05:41.080 --> 05:42.080
to life.

05:42.080 --> 05:48.360
Cosmo is a little robot character like you would see on the big screen but brought to life

05:48.360 --> 05:49.360
and real.

05:49.360 --> 05:53.360
So the goal is to really try to take this little robot character, the kinds of things we've

05:53.360 --> 05:55.760
seen in movies but actually make a real one.

05:55.760 --> 06:00.640
And I think it's kind of a core tenant of the company is trying to bring physical products

06:00.640 --> 06:07.320
to life, trying to deliver on this promise of robotics and AI in consumer products.

06:07.320 --> 06:11.600
And specifically Cosmo is very focused on character and personality.

06:11.600 --> 06:14.920
So he can play little games with him, he can recognize your face, he can play little

06:14.920 --> 06:15.920
games.

06:15.920 --> 06:18.600
If you leave him alone he can sort of do his own thing, he has three little cubes that

06:18.600 --> 06:22.320
he can carry around and make stacks out of and they have lights on them, you can play

06:22.320 --> 06:23.320
games with them.

06:23.320 --> 06:25.120
And also he gets a little feisty doesn't he?

06:25.120 --> 06:27.800
Yes he has a lot of personality and that is a big part of it.

06:27.800 --> 06:36.280
So I would say that we're half core robotics company with all the tech that goes with robotics

06:36.280 --> 06:41.480
which is very multi-disciplinary, it brings together a lot of different disciplines.

06:41.480 --> 06:46.640
And we all add to that whole team of animators and character designers who are focused on

06:46.640 --> 06:51.360
the character of Cosmo, who is he and what is his personality and what does he like?

06:51.360 --> 06:55.560
And that's sort of another big part of the company and the experience and I think that's

06:55.560 --> 06:58.400
what's sort of cool about the company is bringing those two sides of things together.

06:58.400 --> 06:59.400
Wow, wow.

06:59.400 --> 07:00.880
And you work on computer vision.

07:00.880 --> 07:05.960
Can you tell us a little bit about your background and how you got involved in CV?

07:05.960 --> 07:06.960
Sure.

07:06.960 --> 07:12.240
So going way back in undergrad, for whatever reason I took a class, I think it was

07:12.240 --> 07:15.080
might have been a graduate level class but it sounded cool on computer vision.

07:15.080 --> 07:16.080
Okay.

07:16.080 --> 07:19.040
Really liked the professor, he ended up working with him as a sort of an undergraduate

07:19.040 --> 07:25.360
researcher and stayed and did a master's degree there at Georgia Tech and had always enjoyed

07:25.360 --> 07:30.440
like working with robotics, I actually had a job in high school doing robotics for sorting

07:30.440 --> 07:34.080
hangard garments actually, both giant industrial robots.

07:34.080 --> 07:39.480
And those two things I think both kind of struck a chord with me and then went to Carnegie

07:39.480 --> 07:43.720
Mellon to pursue my PhD in robotics and focused on computer vision there.

07:43.720 --> 07:44.720
Okay.

07:44.720 --> 07:50.160
And so how does computer vision fit into Cosmo, like Cosmo is so small, I don't even see

07:50.160 --> 07:51.160
a camera anywhere.

07:51.160 --> 07:52.160
Yes, a new one.

07:52.160 --> 07:55.360
It has actually in his face, if you look at him, the little hole there that kind of looks

07:55.360 --> 08:01.160
like a mouth is his camera, so creepily enough he has his eye in his mouth.

08:01.160 --> 08:06.680
But yeah, so it's a pretty core piece of the robot because it's really his main input,

08:06.680 --> 08:09.000
his main source of sensor input.

08:09.000 --> 08:14.840
So cameras are by their nature a very data rich source of information and they're also

08:14.840 --> 08:16.960
very inexpensive, so that's a good combination.

08:16.960 --> 08:21.320
So he is, that's his primary way of sensing the world is through vision.

08:21.320 --> 08:25.640
So that's how he knows where his cubes are, he can see them, he estimates their poses

08:25.640 --> 08:30.120
in three dimensions very accurately so that he can pick them up, stack them.

08:30.120 --> 08:36.840
He can perceive motion and he also sees faces, both human faces and cat and dog faces.

08:36.840 --> 08:40.200
And beyond detecting faces, he can also learn to recognize human faces so you can teach

08:40.200 --> 08:42.000
him your name and he'll remember you.

08:42.000 --> 08:43.320
Oh wow.

08:43.320 --> 08:49.000
What some of the technologies that go into making this happen from a CV and an algorithmic

08:49.000 --> 08:50.000
perspective?

08:50.000 --> 08:51.000
Sure.

08:51.000 --> 08:54.280
And face detection is certainly a big one face detection, face recognition.

08:54.280 --> 08:57.640
There's a lot of sort of proprietary stuff around how we do the 3D pose estimation of

08:57.640 --> 08:59.600
the cubes.

08:59.600 --> 09:06.720
There's intelligent reasoning about, given the geometry we know of the robot and the specifics

09:06.720 --> 09:09.600
of the camera, which we know, the intrinsic parameters of the camera, we can do things

09:09.600 --> 09:12.720
like reason about the ground plane in front of the robot, even though he doesn't have a

09:12.720 --> 09:17.080
depth sensor, we can start reasoning about the ground plane in front of him, which turns

09:17.080 --> 09:19.240
out to be pretty powerful.

09:19.240 --> 09:23.600
And then we'll layer on top of this, right, all these lots of other technologies including

09:23.600 --> 09:27.520
sort of low-level motor controls, path planning.

09:27.520 --> 09:31.880
And has they used the word AI because or the acronym AI, it's still overloaded at this

09:31.880 --> 09:32.880
point.

09:32.880 --> 09:33.880
Yeah.

09:33.880 --> 09:38.840
But sort of the AI behind how Cosmo models his emotional state and how that drives what

09:38.840 --> 09:41.040
behavior he chooses to do at any moment.

09:41.040 --> 09:43.640
Like I said, he is sort of, if you leave him alone, he is sort of on his own.

09:43.640 --> 09:46.200
You're not remote controlling this robot, he's his character.

09:46.200 --> 09:50.440
So what makes him decide to do, you know, A or B at any given moment, and how do we keep

09:50.440 --> 09:51.440
that making sense?

09:51.440 --> 09:56.560
It can't just be random and it can't also can't be scripted, so how to drive that behavior

09:56.560 --> 09:57.560
system?

09:57.560 --> 10:01.520
Well, let's maybe start with the computer vision stuff.

10:01.520 --> 10:05.840
You know, there are lots of ways to do computer vision, traditional stuff and convolution

10:05.840 --> 10:06.840
on neural nets.

10:06.840 --> 10:07.840
They're obviously very popular.

10:07.840 --> 10:13.400
When I look at this thing and think about like the, you know, price point power, stuff

10:13.400 --> 10:16.120
like that, I'm guessing that you're not running.

10:16.120 --> 10:20.320
You know, there's another reason for that, actually, which people tend to forget, given

10:20.320 --> 10:22.200
how popular they are in the news now.

10:22.200 --> 10:26.520
So this product actually started before we even launched Drive, which was back in 2013.

10:26.520 --> 10:30.080
So I was the first person working on the product, there was nobody else doing anything

10:30.080 --> 10:31.080
yet.

10:31.080 --> 10:32.080
There was no code yet.

10:32.080 --> 10:33.080
Okay.

10:33.080 --> 10:36.480
There was also no really no, you know, okay, so I shouldn't say there was no deporting

10:36.480 --> 10:40.280
because neural nets have been around a long time, but there was no, the revolution if

10:40.280 --> 10:41.880
I, if you will, hadn't occurred yet.

10:41.880 --> 10:43.480
We forget that we're still at that level.

10:43.480 --> 10:44.480
It's so early.

10:44.480 --> 10:45.480
Right.

10:45.480 --> 10:46.480
There's a lot of flow that didn't exist yet.

10:46.480 --> 10:47.480
Right.

10:47.480 --> 10:50.880
Like all these things people are, you know, so familiar with now and it wasn't even around

10:50.880 --> 10:51.880
yet.

10:51.880 --> 10:57.680
So yeah, I'm what's known as a classically trained computer vision, which is kind of ridiculous.

10:57.680 --> 11:01.320
So yeah, we certainly, when we started all this and started picking hardware and nailing

11:01.320 --> 11:07.120
down price points and what sort of processing power he was going to have, we actually did

11:07.120 --> 11:11.680
start to do a lot of the vision on board, but again, with more classical techniques, you

11:11.680 --> 11:15.040
know, for face detection, more things more like Vila Joe and space detection.

11:15.040 --> 11:16.040
Like what?

11:16.040 --> 11:17.040
Vila Jones.

11:17.040 --> 11:18.320
It's sort of a classical way of doing face.

11:18.320 --> 11:19.320
What is that?

11:19.320 --> 11:26.000
It's a means of progressively filtering an image with more and more very, very simple,

11:26.000 --> 11:32.160
simply designed filters that are very, very fast in order to Vila cascade sort of rule

11:32.160 --> 11:38.040
things out slowly over time, but be very efficient and eventually learn the pattern in the image,

11:38.040 --> 11:42.720
it's basically looking at local contrast patterns in the image that look like a face, works

11:42.720 --> 11:44.840
very well and it's still often used today.

11:44.840 --> 11:46.760
So that's the kind of thing that we would use.

11:46.760 --> 11:50.280
Face or no face or is it what allows you to identify individual people?

11:50.280 --> 11:51.280
Can you guys?

11:51.280 --> 11:52.280
So yeah, that is face or no face.

11:52.280 --> 11:55.960
So that's what I would call face detection and then I would, I would contrast that with

11:55.960 --> 11:58.760
face recognition, which is given a face who is it?

11:58.760 --> 11:59.760
Okay.

11:59.760 --> 12:00.760
Exactly.

12:00.760 --> 12:04.440
So anyway, we sort of started by doing that in the market detection, trying to do it on

12:04.440 --> 12:05.640
the robot.

12:05.640 --> 12:08.800
We were able to get actually quite far with that, but at some point realized, okay, this

12:08.800 --> 12:10.280
is just, this is just too limiting.

12:10.280 --> 12:13.840
We always knew there would be a companion app the same way that there is overdrive.

12:13.840 --> 12:19.240
And at some point we decided, all right, we're going to take the punch and just put all

12:19.240 --> 12:21.160
of the smarts really in the device.

12:21.160 --> 12:26.000
So the way the product works is that you have an app that connects to, you connect your

12:26.000 --> 12:31.000
device to Cosmos, Wi-Fi, hotspot, and he's actually streaming his images to your device

12:31.000 --> 12:34.880
and all of the computer vision, path planning, et cetera, is actually happening on your

12:34.880 --> 12:35.880
device.

12:35.880 --> 12:36.880
Oh, interesting.

12:36.880 --> 12:40.080
And that's what, again, as you pointed out, that's what allows us to sell it at a price

12:40.080 --> 12:42.320
point and a scale that we're able to.

12:42.320 --> 12:46.960
Otherwise, especially given hardware from three plus years ago, there's just no way we

12:46.960 --> 12:50.400
could have gotten all the capability on the robot.

12:50.400 --> 12:51.400
Right, right.

12:51.400 --> 12:56.720
Is there some limited ability to operate if the, you know, so your iPad runs out of battery

12:56.720 --> 12:57.720
or something like that?

12:57.720 --> 13:00.360
Is it able to go into some kind of autonomous mode?

13:00.360 --> 13:01.360
Very, very little.

13:01.360 --> 13:03.400
So I mean, you sort of like shut himself down.

13:03.400 --> 13:05.760
We try not to just have them die.

13:05.760 --> 13:09.680
But it really is quite tied to the device because so much of it lives there.

13:09.680 --> 13:13.720
All the animation, in fact, so we've been talking a lot about the animation, but the animations

13:13.720 --> 13:19.040
that play on him, the sound, his facial animations are also actually all stored on the device.

13:19.040 --> 13:20.040
Oh, really?

13:20.040 --> 13:22.920
So while those are streaming to him, his images are streaming back to the device, so there's

13:22.920 --> 13:24.240
a lot of data going back and forth.

13:24.240 --> 13:25.240
Oh, wow.

13:25.240 --> 13:27.240
Now I should say it's all within that network.

13:27.240 --> 13:28.640
There's no cloud, anything.

13:28.640 --> 13:29.640
Yeah.

13:29.640 --> 13:30.640
So this is sort of a closed network.

13:30.640 --> 13:31.640
And that's Bluetooth or?

13:31.640 --> 13:32.640
That's pure Wi-Fi.

13:32.640 --> 13:33.640
Pure Wi-Fi.

13:33.640 --> 13:37.360
Yeah, the problem with Bluetooth, which is actually what we use for overdrive, is just bandwidth

13:37.360 --> 13:41.440
to send, we couldn't stream the images at full-frame rate over Bluetooth.

13:41.440 --> 13:45.040
So the rollback controls we could, but the actual image data we couldn't.

13:45.040 --> 13:46.040
Okay.

13:46.040 --> 13:50.880
So you started looking at, for the image detection, the VL and Norbert.

13:50.880 --> 13:51.880
The VL and Jones.

13:51.880 --> 13:52.880
VL and Jones.

13:52.880 --> 13:54.880
Well, I'm more thinking of Norbert.

13:54.880 --> 13:55.880
Oh, man.

13:55.880 --> 13:56.880
Yeah.

13:56.880 --> 14:02.760
Well, we should, that's a new algorithm, we'll have to develop it ourselves.

14:02.760 --> 14:08.000
And so is that what you ended up doing on the device, or now that you have access to

14:08.000 --> 14:11.560
the device, you're able to do more sophisticated things?

14:11.560 --> 14:16.600
That's, I mean, without going into too much detail, that's basically what's running for

14:16.600 --> 14:17.600
the detection.

14:17.600 --> 14:19.440
But cubes is a completely different thing.

14:19.440 --> 14:24.080
Those are detected via a sort of proprietary method that both allows us to detect the

14:24.080 --> 14:28.040
cubes and then estimate their pose in 3D.

14:28.040 --> 14:31.880
And then again, that's super important because his little fingers that he has to get in

14:31.880 --> 14:34.520
the little slots to pick up the cubes, you know, there's only a couple of millimeters

14:34.520 --> 14:35.520
of slot there.

14:35.520 --> 14:39.120
And we've got a robot driving around on treads and treads are really hard to model.

14:39.120 --> 14:43.800
So the way he moves, we really have to be able to get feedback constantly about where

14:43.800 --> 14:47.720
the cube actually is so that we can drive him accurately and pick up the cubes.

14:47.720 --> 14:50.960
That was just a huge part of the project for a very long time, was just how do we make

14:50.960 --> 14:52.360
this thing pick up cubes?

14:52.360 --> 14:53.360
Wow.

14:53.360 --> 14:56.920
Can you understanding that it's a proprietary approach?

14:56.920 --> 15:02.080
Can you give us some analogies that help us understand, you know, what are the technical

15:02.080 --> 15:08.840
challenges beyond, you know, obviously the precision that you just imagined.

15:08.840 --> 15:12.920
You know, what are some of the kind of algorithmic approaches you looked at before you went

15:12.920 --> 15:17.320
down the path of needing to roll your own, you know, what might you consider if you

15:17.320 --> 15:18.320
are starting again?

15:18.320 --> 15:19.320
That kind of thing.

15:19.320 --> 15:24.960
Well, so the obvious thing if you look at these cubes is probably maybe a QR code.

15:24.960 --> 15:29.880
So it's sort of along those lines, there's one big reason we didn't go QR code is the

15:29.880 --> 15:30.880
appearance.

15:30.880 --> 15:34.320
And, you know, we are a tech company, we're building technical products, but there's

15:34.320 --> 15:37.360
a big design component to this, how the robot looks, how he behaves and what we wanted

15:37.360 --> 15:43.360
the cubes to look like and stylistically, nobody liked the QR codes, they just, they

15:43.360 --> 15:45.520
sort of screamed the wrong thing for the product.

15:45.520 --> 15:49.720
So one of the things we wanted to develop was a similar idea that allowed us to encode

15:49.720 --> 15:54.560
information on the sides of the cubes that gave him information, but that gave us aesthetic

15:54.560 --> 15:56.760
control over what they looked like.

15:56.760 --> 16:01.640
And so it's a similar idea to QR codes in some sense, but with the sort of aesthetic

16:01.640 --> 16:02.880
component.

16:02.880 --> 16:09.040
And then as far as estimating the 3D pose, what it effectively comes down to is that we

16:09.040 --> 16:13.280
know points on the cube, points on the marker that are on the side of the cube, and we know

16:13.280 --> 16:18.640
the intrinsic calibration of the camera, basically it's focal length.

16:18.640 --> 16:21.920
And that's a whole other interesting issue, we have to calibrate every robot individually

16:21.920 --> 16:24.320
in the factory to get that.

16:24.320 --> 16:29.160
And given those two things, we can see where those known 3D locations on the cube project

16:29.160 --> 16:30.160
into the image.

16:30.160 --> 16:35.360
So once we find them in the image, and we know the 3D shape they belong to via that correspondence

16:35.360 --> 16:40.920
and some math, you can sort of back out where that 3D object must be in order to have projected

16:40.920 --> 16:42.600
that pattern.

16:42.600 --> 16:45.600
And the 3D points that you're referring to are...

16:45.600 --> 16:50.360
So any of that, sort of anything, no decals, or anything we know, you could use anything

16:50.360 --> 16:54.280
really, but you just want a very accurate notification on the cube.

16:54.280 --> 17:00.320
So you've got these known graphics, we can call them codes, they're not QR codes.

17:00.320 --> 17:06.920
When you look at them, you think that these are just graphical flourishes, but you look

17:06.920 --> 17:10.560
more closely, and you can see that each of the sides is unique, and there can be some

17:10.560 --> 17:11.560
better information.

17:11.560 --> 17:12.560
Well, don't over notice that.

17:12.560 --> 17:15.840
It's one of the challenges of designing them is that we had competing goals.

17:15.840 --> 17:18.880
One was that we wanted all sides of the cube to sort of look the same, so that this cube

17:18.880 --> 17:22.720
had sort of one marker on it, but we also wanted Cosmo to be able to tell the difference

17:22.720 --> 17:26.800
from the different sides, because he can control the lights, and we want to know which

17:26.800 --> 17:28.200
light he's turning on, for example.

17:28.200 --> 17:29.560
Oh, yeah, I didn't even notice that.

17:29.560 --> 17:30.560
So this is your...

17:30.560 --> 17:32.040
So the other is four lights on top.

17:32.040 --> 17:33.040
Okay.

17:33.040 --> 17:36.920
But I was also noticing that this cube in the middle is kind of like your paperclip cube.

17:36.920 --> 17:38.680
Yeah, that's exactly what I see.

17:38.680 --> 17:42.320
That one looks like kind of a stack of things.

17:42.320 --> 17:44.320
Everybody's got their own, what they see in these things.

17:44.320 --> 17:45.320
They were a shark.

17:45.320 --> 17:46.320
Or a shark.

17:46.320 --> 17:47.320
Exactly.

17:47.320 --> 17:51.440
This one looks like a baby and a fetal pose.

17:51.440 --> 17:52.440
Yes.

17:52.440 --> 17:53.440
That's a common one, too.

17:53.440 --> 17:55.680
It is funny when people see these things, yeah.

17:55.680 --> 18:01.640
It was hard because part of the design here was, I guess if we wanted to aesthetic component,

18:01.640 --> 18:06.960
but we also at the time we were walking down, making all the hardware, we didn't necessarily

18:06.960 --> 18:09.440
want to commit ourselves to a particular meaning.

18:09.440 --> 18:13.640
So you know, if you made it the treasure chest cube, it's like, well, it does everything

18:13.640 --> 18:14.640
you do.

18:14.640 --> 18:16.640
It does with the cube, you have to relate some out of it treasure chest.

18:16.640 --> 18:19.840
You didn't want to get too much iconography.

18:19.840 --> 18:23.440
So yeah, these are sort of these general purpose designs.

18:23.440 --> 18:26.720
The challenge that we sort of realized later is that exactly what you just experienced

18:26.720 --> 18:29.560
is how to refer to them is very technical.

18:29.560 --> 18:30.560
Yeah.

18:30.560 --> 18:33.400
Customers carry, you know, when they get a call about a cube or something, they're always

18:33.400 --> 18:36.760
like, right, there's actually a number engraved in there that you can find so you can actually

18:36.760 --> 18:37.760
get one.

18:37.760 --> 18:39.720
Well, obviously, it would have been like make them different colors.

18:39.720 --> 18:42.160
Did that mess up your algorithms or something?

18:42.160 --> 18:43.160
No, no.

18:43.160 --> 18:44.160
Color would have been okay.

18:44.160 --> 18:45.160
I think again, it's just from a design perspective.

18:45.160 --> 18:46.680
I think they wanted them to match more.

18:46.680 --> 18:47.680
Yeah.

18:47.680 --> 18:48.680
Yeah.

18:48.680 --> 18:49.680
Interesting.

18:49.680 --> 18:53.280
And so I understand for the people that are listening that this is a very visual conversation.

18:53.280 --> 18:54.280
Yeah.

18:54.280 --> 18:55.280
So I'm talking about computer vision.

18:55.280 --> 18:56.280
Yeah.

18:56.280 --> 18:57.280
Exactly.

18:57.280 --> 19:03.720
So we'll definitely, I'm going to, at the very minimum, include some pictures of what

19:03.720 --> 19:08.620
we're talking about on the show notes page, but I'm more likely, or as well, going to maybe

19:08.620 --> 19:14.040
shoot some video of this thing in action and post it up on, up on our YouTube channel.

19:14.040 --> 19:17.800
One thing that often, I think, surprises people after hearing it, talked about or referred

19:17.800 --> 19:20.120
to, I don't think they realize how small it is.

19:20.120 --> 19:21.120
I didn't either.

19:21.120 --> 19:22.120
I was really surprised.

19:22.120 --> 19:23.120
So I like to bring one.

19:23.120 --> 19:27.400
Generally people, I think, imagine him much larger, but for the listeners, he's actually

19:27.400 --> 19:32.000
sort of fits in the size of your palm of your hand, so he's quite tiny.

19:32.000 --> 19:34.400
And that's for a couple of reasons.

19:34.400 --> 19:38.640
One is actually maybe non-obvious, which is for him to have the personality he does and

19:38.640 --> 19:43.000
to move around as fast as he does to exhibit that personality and be, you know, sort of cute

19:43.000 --> 19:45.400
and playful, he has to move quickly.

19:45.400 --> 19:49.600
And if you build a heavy big robot, you know, if his little lifter here moved too fast

19:49.600 --> 19:51.920
and you got your finger in there, you would actually hurt yourself.

19:51.920 --> 19:56.000
So in some sense, there's a safety component to it.

19:56.000 --> 19:59.760
But also, it's also just part of his personality.

19:59.760 --> 20:01.240
It makes sense for him to be cute.

20:01.240 --> 20:02.240
It's sort of big.

20:02.240 --> 20:03.240
It's too big.

20:03.240 --> 20:06.520
And we have, I mean, I don't remember if it's 40 or 60 or something, different design

20:06.520 --> 20:08.200
iterations on this thing.

20:08.200 --> 20:12.320
And some of them were much bigger and the smaller ones always went out.

20:12.320 --> 20:14.520
It just feels right for him to be in the palm of your hand.

20:14.520 --> 20:19.520
And then that, in turn, sort of, has impact on the way the sound design is done.

20:19.520 --> 20:21.800
What should he sound like given how big he is?

20:21.800 --> 20:25.480
The difficult side, of course, is really for the manufacturing and mechanical engineers

20:25.480 --> 20:30.480
to squeeze in all the 300 and something parts into this tiny little robot.

20:30.480 --> 20:32.520
There's like no free space inside that thing.

20:32.520 --> 20:33.520
I can imagine.

20:33.520 --> 20:35.360
I can imagine.

20:35.360 --> 20:38.920
So we were talking about the size of the thing of the cubes.

20:38.920 --> 20:43.160
So you've got these, and this kind of algorithm is kind of interesting.

20:43.160 --> 20:47.840
So you've got these, you know, each of the cubes has six sides.

20:47.840 --> 20:54.920
It has kind of a QR code like thing that is a consistent design element for each cube.

20:54.920 --> 20:58.800
And then this thing can look at a cube.

20:58.800 --> 21:03.480
And it is probably relatively easy to identify if a cube is in the frame.

21:03.480 --> 21:09.120
And then it can kind of pick out the, you know, the kind of infer the angle of the different

21:09.120 --> 21:11.520
sides that it's able to see.

21:11.520 --> 21:17.720
And from that kind of figure out, you can create a model, a model like a projection I'm

21:17.720 --> 21:18.720
thinking of that.

21:18.720 --> 21:19.720
Exactly.

21:19.720 --> 21:21.360
This project of geometry is what it all comes down to.

21:21.360 --> 21:22.360
Okay.

21:22.360 --> 21:26.400
The projection of 3D points onto the 2D plane of the image, and given we know what the

21:26.400 --> 21:27.400
3D points are.

21:27.400 --> 21:28.400
And you can back your control.

21:28.400 --> 21:29.400
Figure out, okay.

21:29.400 --> 21:30.400
Exactly.

21:30.400 --> 21:31.400
You can rotate your translation.

21:31.400 --> 21:32.400
Yep.

21:32.400 --> 21:33.400
Okay.

21:33.400 --> 21:38.720
So you would feed that into whatever like like classical control algorithms to make it,

21:38.720 --> 21:40.320
you know, move to the thing, lift it up and get it.

21:40.320 --> 21:41.320
Yeah.

21:41.320 --> 21:43.800
Plan a path into a known location with respect to that cube.

21:43.800 --> 21:47.240
And then yeah, it's sort of a control problem of, as I'm driving forward, make sure I keep

21:47.240 --> 21:51.240
it in the right place until I think my fingers get in there and pick it up.

21:51.240 --> 21:52.240
Yeah.

21:52.240 --> 21:53.840
That's just amazingly sophisticated for this little.

21:53.840 --> 21:54.840
Yeah.

21:54.840 --> 21:55.840
People don't understand how hard that is.

21:55.840 --> 21:58.360
One of the things that I think actually is pretty interesting about this, and it's,

21:58.360 --> 22:02.720
I think more for robotics geeks than, than, the average consumer is that one of the

22:02.720 --> 22:08.640
things that holds robotics back from doing more and more, I think, consumer products is

22:08.640 --> 22:12.200
manipulation, is the ability to change the world around you.

22:12.200 --> 22:16.960
It's still a very, very hard problem both mechanically and from sort of an AI standpoint, from

22:16.960 --> 22:19.160
a software standpoint.

22:19.160 --> 22:24.160
So I would argue this is sort of the first little mobile manipulator, especially at this

22:24.160 --> 22:25.160
scale and this price point.

22:25.160 --> 22:29.800
I mean, Roomba's are effectively a manipulator in that they suck up stuff, so they're doing

22:29.800 --> 22:30.800
some work.

22:30.800 --> 22:36.000
But, you know, Cosmo can actually do this very hard problem of driving up, picking up a,

22:36.000 --> 22:39.680
picking up a cube and then stacking on top of another cube and that's, it's not an easy

22:39.680 --> 22:40.680
thing to do.

22:40.680 --> 22:41.520
It is definitely an easy thing to do.

22:41.520 --> 22:45.280
The other half though that may not be obvious, it's definitely not obvious, about the

22:45.280 --> 22:46.280
cubes.

22:46.280 --> 22:50.120
So not only do they have lights, they also have an accelerometer inside of them.

22:50.120 --> 22:56.400
So Cosmo talks to them over a radio connection, which is kind of like Bluetooth.

22:56.400 --> 23:00.320
And that allows him to know via the accelerometer if the cube has moved.

23:00.320 --> 23:02.640
So if I pick him the cube, he's aware.

23:02.640 --> 23:06.640
And what that means is that if, so if I've seen the cube and I've estimated it's 3D

23:06.640 --> 23:12.040
pose with respect to the robot, and the cube doesn't move, now I can also do the reverse.

23:12.040 --> 23:14.800
If I drive around and Cosmo's, all right, pick up Cosmo and put it in.

23:14.800 --> 23:15.960
You can open a Cosmo based on that.

23:15.960 --> 23:19.320
Once he sees the cube again, if it hasn't moved, he now knows his position with respect

23:19.320 --> 23:22.960
to the cube, which means he now knows his position with respect to the old map he was

23:22.960 --> 23:23.960
building.

23:23.960 --> 23:28.440
So he, it's something that I think people tend to forget is it's not just like pure stimulus

23:28.440 --> 23:29.440
response.

23:29.440 --> 23:32.280
You face, whatever, he's remembering all of this, right?

23:32.280 --> 23:34.720
He's keeping up with the 3D poses of the cubes.

23:34.720 --> 23:37.560
He's keeping up with where you are in space once he sees you.

23:37.560 --> 23:38.800
And there's just big reasons for that.

23:38.800 --> 23:40.360
It makes him look smarter.

23:40.360 --> 23:45.440
It allows him to do behaviors which turn out to be super important.

23:45.440 --> 23:50.080
So for example, if right before he decides he's going to go pick up this cube and he

23:50.080 --> 23:54.320
knows you're, you know, off to his right, he might stop and do the same thing a little

23:54.320 --> 23:57.920
kid does, which is look, look up, look up at you and make sure you're watching him.

23:57.920 --> 24:03.280
And that little moment of eye contact makes it more about this, this sort of interactive

24:03.280 --> 24:06.520
experience where you're drawn in and he, you know, you're very aware that, oh, he knows

24:06.520 --> 24:07.520
I'm here.

24:07.520 --> 24:11.320
As opposed to, I'm just a spectator watching a robot pick up a cube.

24:11.320 --> 24:13.520
It's like, oh, Cosmonose, I'm watching him.

24:13.520 --> 24:18.720
And that little bit of the mixture of sort of that technical component, that technical

24:18.720 --> 24:23.800
capability with the character and personality, I think is a really good example of like,

24:23.800 --> 24:25.640
how this starts to fit together.

24:25.640 --> 24:26.800
Interesting.

24:26.800 --> 24:32.640
So you kind of, you didn't actually literally use air quotes when you said AI with related

24:32.640 --> 24:39.160
with relation to the personality, but, you know, clearly there's a connection between,

24:39.160 --> 24:43.800
you know, the way we think about AI and, you know, the idea of personality.

24:43.800 --> 24:47.880
Like, what are some of the, you know, how are you doing that?

24:47.880 --> 24:52.360
What are some of the approaches to give a personality personality?

24:52.360 --> 24:53.360
Yeah.

24:53.360 --> 24:59.640
But maybe I mentioned there's a, there's this notion of Cosmo having emotion.

24:59.640 --> 25:03.400
So he does, we do internally model his emotional state.

25:03.400 --> 25:10.640
You know, how happy versus sad it is, how calm versus anxious he is, how socialized versus

25:10.640 --> 25:11.640
lonely he is.

25:11.640 --> 25:14.840
I don't remember those are all the same words we actually use in the code, but he effectively

25:14.840 --> 25:20.360
has the set of traits or properties which are changing all the time and different things

25:20.360 --> 25:22.360
that happen to Cosmo affect them.

25:22.360 --> 25:27.040
So another good example involving faces is that, you know, he's sort of designed to be

25:27.040 --> 25:29.080
a social, friendly robot.

25:29.080 --> 25:34.280
And so he, we've sort of, you know, defined his personality to be one that enjoys, you

25:34.280 --> 25:35.800
know, being surrounded by people.

25:35.800 --> 25:38.880
So if he's driving around for a long time, he doesn't see anyone.

25:38.880 --> 25:42.520
At some point his, his loneliness may creep up.

25:42.520 --> 25:46.200
And once it gets high enough, it may trigger him to switch into a behavior which is look

25:46.200 --> 25:48.280
for faces because he's, he's lonely.

25:48.280 --> 25:51.680
So he'll, he'll, that'll, that'll change him to a mode where now he keeps, he's keeping

25:51.680 --> 25:55.680
his head tilted up and he's looking around and he, you know, he's not distracted by

25:55.680 --> 25:56.680
his cubes or whatever.

25:56.680 --> 25:58.400
He wants to find a person.

25:58.400 --> 25:59.560
He's a person.

25:59.560 --> 26:04.240
And now that sort of triggers an emotional change where his, his social, his socialization

26:04.240 --> 26:07.520
goes up and his, his loneliness goes back down.

26:07.520 --> 26:09.760
That allows him to switch out of the behavior and do something else.

26:09.760 --> 26:15.480
So that's sort of an idea of what I was referring to earlier of preventing it from being either

26:15.480 --> 26:20.440
just random behaviors, which, right, over time you can tell his random or being fully scripted

26:20.440 --> 26:21.800
which also doesn't feel natural.

26:21.800 --> 26:26.480
So it is in response to what's been happening and what is currently happening to him.

26:26.480 --> 26:34.080
Is there a notion of like a kind of a long-term personality, meaning the thing that came

26:34.080 --> 26:38.960
to mind is like the Microsoft Tay Chapat, they got trained by, you know, Twitter to be,

26:38.960 --> 26:41.480
you know, a Nazi, right?

26:41.480 --> 26:47.680
Like if you, you know, if you ignore your Cosmo long enough, like will it become like permanently

26:47.680 --> 26:48.680
sad or something like that?

26:48.680 --> 26:49.680
It's a very good example.

26:49.680 --> 26:54.400
You hit exactly, so the answer is no, you hit exactly the reason.

26:54.400 --> 26:59.200
We were concerned, like what happens if you just, your robot ends up like irreparably depressed.

26:59.200 --> 27:00.920
It's not, it's not really what we wanted.

27:00.920 --> 27:06.440
And we felt like what we were trying to create was there is a definition we have of who

27:06.440 --> 27:08.000
Cosmo is and what his personality is.

27:08.000 --> 27:10.200
We have, you know, character designers who that is their job.

27:10.200 --> 27:13.240
They are the owner of what, who is Cosmo?

27:13.240 --> 27:15.080
What are his motivations and these sorts of questions?

27:15.080 --> 27:16.680
And it's not, it's not, it's Cosmo.

27:16.680 --> 27:17.680
It's not my Cosmo.

27:17.680 --> 27:21.320
Like when I take it, take it out of the box, there's not like a random seed that, or, you

27:21.320 --> 27:26.080
know, something that on us, maybe more continuous than a random seed, but that says, you know,

27:26.080 --> 27:30.080
this is, you know, my Cosmo's personality is more Cosmo's personality.

27:30.080 --> 27:33.080
And I think that's something we're interested in exploring, but at this point, right, the,

27:33.080 --> 27:36.000
sort of the, what I would call the personality is more fixed.

27:36.000 --> 27:37.000
Yeah.

27:37.000 --> 27:38.000
We're in more control of that.

27:38.000 --> 27:42.440
The mood, I would call it, which is more transient, is what you're controlling by what you do

27:42.440 --> 27:43.440
with them.

27:43.440 --> 27:46.880
You know, if you keep falling on the floor, or, yeah, if he doesn't see me by for a while,

27:46.880 --> 27:48.800
again, he might get, might get lonely.

27:48.800 --> 27:53.280
Those sorts of things, but they don't, they don't exhibit sort of a long-term effect,

27:53.280 --> 27:56.720
but because it can be very hard to control, like, wait, what, where does that go?

27:56.720 --> 27:59.920
And so, yeah, we sort of, I think, we're a little cautious about that.

27:59.920 --> 28:00.920
Okay.

28:00.920 --> 28:05.880
And so you kind of, you know, on one end, you've got, you know, random on another end,

28:05.880 --> 28:10.560
you've got totally scripted, you know, imagining somewhere in the middle is like a state

28:10.560 --> 28:14.040
machine that's sufficiently complex, that it doesn't seem like either of the two, is

28:14.040 --> 28:15.040
it kind of like that?

28:15.040 --> 28:16.040
Yeah.

28:16.040 --> 28:17.320
I think that's a fair, that's a fair comparison.

28:17.320 --> 28:22.080
There are sort of, there are sort of predefined behaviors, and, and for example, games that

28:22.080 --> 28:25.560
he can play, which themselves are little state machines, which are, which are very much

28:25.560 --> 28:26.560
engineered.

28:26.560 --> 28:31.160
And the look for faces thing, right, like, he didn't sort of, we didn't learn that

28:31.160 --> 28:34.240
behavior of how to look for exactly, okay, what, what it means is you need to look

28:34.240 --> 28:38.800
up and kind of look around in this way, and those things sort of are sort of tuned.

28:38.800 --> 28:44.200
So yeah, I think, looking at it as a state machine, where the transitions between states

28:44.200 --> 28:48.520
are very much driven by not only his sensor input, but also the sort of underlying motion

28:48.520 --> 28:51.640
engine is sort of good to think about it.

28:51.640 --> 28:55.520
You know, I guess one of the questions that jumps out to me as, you know, as a geek, I

28:55.520 --> 28:57.680
guess, is like, is this thing programmable?

28:57.680 --> 29:02.560
Can I like, you know, try to, can I use it as an experimentation platform?

29:02.560 --> 29:03.560
Absolutely.

29:03.560 --> 29:07.160
That's actually one of the, one thing that I'm super excited about that we have done

29:07.160 --> 29:09.720
with the product, and actually we did from day one.

29:09.720 --> 29:12.400
So when we launched it, Cosmo comes with an SDK.

29:12.400 --> 29:13.400
Okay.

29:13.400 --> 29:16.400
So in fact, not everyone realizes it, but in the app that you used to talk to Cosmo, if

29:16.400 --> 29:19.840
you go to settings and you scroll over, there's a button which says enable SDK, everybody

29:19.840 --> 29:21.640
has this out of the box.

29:21.640 --> 29:27.160
So you enable the SDK, you plug your device into your computer over USB, and then you

29:27.160 --> 29:28.560
can program in with Python.

29:28.560 --> 29:33.600
And it is an extremely full-featured and ever-expanding SDK.

29:33.600 --> 29:36.320
It's actually totally incredible all the things you can do.

29:36.320 --> 29:41.320
Having done a PhD in robotics on, you know, sort of research platforms which cost tens

29:41.320 --> 29:47.600
of thousands of dollars, usually broken, the fact that this $179 robot allows you to do,

29:47.600 --> 29:52.320
you know, totally low-level motion control or motor control all the way up to just flip

29:52.320 --> 29:57.000
on face recognition and just use it and path planning is crazy.

29:57.000 --> 30:01.120
And it's designed for, you know, six-year-olds, so it can fall off the table and not break.

30:01.120 --> 30:03.720
So it is an awesome programming platform.

30:03.720 --> 30:10.000
It's actually being used both at Carnegie Mellon and Georgia Tech, I guess, both my alumni.

30:10.000 --> 30:15.240
In their programming classes, both at undergrad and graduate level, we've got some cool, I can't

30:15.240 --> 30:19.400
think of the name right now of programming camps in the summer.

30:19.400 --> 30:22.760
They're starting to adopt Cosmo as their platform.

30:22.760 --> 30:28.840
And so, in concert with all this, so I've mentioned the SDK, you know, that's sort of full-blown,

30:28.840 --> 30:34.840
geek-level robotics program you can do as a sort of an expert, but, you know, someone

30:34.840 --> 30:38.480
at a graduate or undergraduate level or someone who really knows Python.

30:38.480 --> 30:42.200
People, by the way, are also writing, creating movies with him online by scripting him with

30:42.200 --> 30:43.880
the SDK, which is really cute.

30:43.880 --> 30:44.880
Oh, really?

30:44.880 --> 30:46.880
Yeah, there's actually a whole YouTube channel.

30:46.880 --> 30:49.960
Oh, yeah, there's a life with Cosmo is one worth checking out.

30:49.960 --> 30:55.280
It's really, really, really creative videos done with him, super impressive stuff.

30:55.280 --> 30:57.080
And it's all through the SDK.

30:57.080 --> 31:01.040
So it's really cool to see both, it used for research and also for creative outlets like

31:01.040 --> 31:02.040
that.

31:02.040 --> 31:03.040
Yeah.

31:03.040 --> 31:08.600
But so, beyond that, there's a whole bunch of other stuff, which is scratch-based programming.

31:08.600 --> 31:16.040
So scratch is a drag-and-drop block-based visual programming language developed by MIT

31:16.040 --> 31:17.040
and Google.

31:17.040 --> 31:21.400
In the last summer, we actually released an early version of that where you could effectively

31:21.400 --> 31:22.400
sequence the robots.

31:22.400 --> 31:26.440
You had a few very basic blocks and you could sort of, you know, do things like drive

31:26.440 --> 31:32.800
straight, turn right, look up, you could do fun things like wait until you see face smiling.

31:32.800 --> 31:36.480
So you could actually have Cosmo do, you know, drive straight, look up, and then sit there,

31:36.480 --> 31:38.600
and then once you saw face smiling, you would proceed to the next block.

31:38.600 --> 31:40.640
So you could do fun little programs like that.

31:40.640 --> 31:42.680
And that was meant for the other end of the spectrum.

31:42.680 --> 31:45.840
People have never written a line of code, have no idea about it, and it teaches you how

31:45.840 --> 31:49.480
to break a problem down into steps, how to write a sequence of, you know, how to sequence

31:49.480 --> 31:53.760
that, and some of the basics that you can do with a robot.

31:53.760 --> 31:58.400
So now, at that point, we had sort of the very beginning end of the spectrum and the, you

31:58.400 --> 32:02.240
know, the sort of graduate level, programming level, end of the spectrum.

32:02.240 --> 32:07.720
And last fall, we actually released what we call code lab, which took that early version

32:07.720 --> 32:10.720
of scratch and added to another mode, which is more advanced.

32:10.720 --> 32:14.280
So we have what we call now sandbox mode and constructor mode.

32:14.280 --> 32:18.720
And for listeners who know those basically correspond to horizontal and vertical grammar

32:18.720 --> 32:20.040
and scratch.

32:20.040 --> 32:23.280
Horizontal is sort of sequencing and vertical allows you to actually do branching in loops

32:23.280 --> 32:26.280
and more complex structures, but still visually.

32:26.280 --> 32:29.960
So we took code lab constructor and really basically enabled almost anything you could do

32:29.960 --> 32:34.240
in the SDK, but in drag and drop programming with both.

32:34.240 --> 32:38.800
So it's actually, the first time I used it, I was kind of blown away at how easy it was

32:38.800 --> 32:42.200
and how much you could build, how quickly you could do math in there, you can do, you know,

32:42.200 --> 32:45.920
vertical operations, you can really do whatever it's got, you know, trig functions in it,

32:45.920 --> 32:47.120
you can do whatever you want.

32:47.120 --> 32:53.120
So now we sort of have this full spectrum of, you know, very beginner level drag and

32:53.120 --> 32:58.120
drop sequencing to really full blown programming with, but still with drag and drop blocks, so

32:58.120 --> 32:59.520
that you can kind of see how that works.

32:59.520 --> 33:03.040
And then, you know, once you're, once you're sort of comfortable there, you could easily

33:03.040 --> 33:06.560
transition into Python and understand how to, how to write code there.

33:06.560 --> 33:12.800
So it's a really nice transition and to sort of move that along in code lab, we've also

33:12.800 --> 33:18.080
reached, released these featured products or projects and we're continuing to do that.

33:18.080 --> 33:22.920
So it's cool because we can build a little fun activity with code lab, but in the app,

33:22.920 --> 33:25.760
it comes up as a little, you know, icon, you open it up, oh, this sounds fun.

33:25.760 --> 33:29.400
You can play it, it's a little game or a little activity like making Cosmo play different

33:29.400 --> 33:33.920
instruments when you tap on the blocks, for example, all written in code lab.

33:33.920 --> 33:36.800
And the cool thing is there's a button on all of them that says, see inside.

33:36.800 --> 33:42.480
So you click that button and then it actually shows you the full scratch block based program.

33:42.480 --> 33:45.280
And you can sort of see like, oh, now I see how they did that.

33:45.280 --> 33:49.240
And you can customize it or whatever, but it's sort of like the old way we all learned

33:49.240 --> 33:53.400
to write web pages is the source and like, oh, I see how they did that.

33:53.400 --> 33:57.280
And so it's, it's again, a really cool way to kind of dive in and get some ideas for

33:57.280 --> 33:59.280
what's, what's possible.

33:59.280 --> 34:07.960
Now, with the SDK and the scratch piece, you mentioned a little of a motor control.

34:07.960 --> 34:12.600
Can you also get a feed of the images and like try to, you know, say you want to play

34:12.600 --> 34:14.600
with your own facial recognition?

34:14.600 --> 34:15.600
Yeah, absolutely.

34:15.600 --> 34:20.360
And the SDK, yeah, you can get the image feed, a little harder to do that in scratch to

34:20.360 --> 34:21.360
display it.

34:21.360 --> 34:22.920
That's something that I think is worth exploring.

34:22.920 --> 34:27.640
But yes, in the SDK, absolutely, we've had people do that, you know, people who are computer

34:27.640 --> 34:31.180
vision researchers in grad school who want a robot, they don't want to deal with the path

34:31.180 --> 34:32.180
planning part of it, right?

34:32.180 --> 34:33.180
Right.

34:33.180 --> 34:36.600
I found the thing and I know it's an obstacle in 3D and I want to drive a path around it.

34:36.600 --> 34:37.600
I'm focused on the vision.

34:37.600 --> 34:38.600
I don't care about the path planning.

34:38.600 --> 34:41.800
They can use the path planning, but they get the right image feed and they can do their

34:41.800 --> 34:42.800
own detection.

34:42.800 --> 34:47.200
So people have done, there's been interesting work like taking Cosmos image feed and running

34:47.200 --> 34:51.800
it through, you know, some of the popular deep learning networks and learning to recognize

34:51.800 --> 34:52.800
objects and things.

34:52.800 --> 34:55.840
Again, they have the power of a whole laptop to run it on.

34:55.840 --> 34:59.200
But yeah, we've seen people do some really interesting projects and we have a very active

34:59.200 --> 35:01.080
developer form on our website.

35:01.080 --> 35:05.160
People post this kind of stuff all the time and we've had really, really great response.

35:05.160 --> 35:06.160
Huh.

35:06.160 --> 35:07.160
Interesting.

35:07.160 --> 35:13.280
So what's next for the, you know, either this product or the company, like, is it building

35:13.280 --> 35:18.160
on this as a platform or coming out with the next, you know, the next robot or the next

35:18.160 --> 35:19.160
thing?

35:19.160 --> 35:20.160
Yes, yes and yes.

35:20.160 --> 35:24.760
You know, it's not so much I can say about too far down the road, but I will say, yes,

35:24.760 --> 35:28.680
we're adding, we're definitely expanding Cosmos capabilities.

35:28.680 --> 35:32.080
We want to be able to, you know, see and understand more.

35:32.080 --> 35:37.800
And a lot of that, a lot of the user-facing stuff in the near future is focused around

35:37.800 --> 35:38.800
code lab.

35:38.800 --> 35:43.640
One of the benefits of having this code lab universe where we have these projects is that

35:43.640 --> 35:46.960
it also makes it easier for us to release new content.

35:46.960 --> 35:51.400
We don't need a C++ developer who knows all about robotics to write a new little fun

35:51.400 --> 35:52.400
activity.

35:52.400 --> 35:58.200
We're going to have a designer, a game developer who may not be as much of a hardcore coder,

35:58.200 --> 36:02.240
but has a cool idea, right, and they can drag and drop box and make a project and that

36:02.240 --> 36:03.400
can be part of the app.

36:03.400 --> 36:04.840
We can also take user content.

36:04.840 --> 36:09.080
So we can send us your content, you can share your projects and, you know, cool stuff

36:09.080 --> 36:10.600
that actually is neat.

36:10.600 --> 36:13.160
We might actually deploy with the next version of the app.

36:13.160 --> 36:18.600
So there's a lot of stuff around code lab coming and there are new things coming in the

36:18.600 --> 36:23.560
Cosmic Protocol, which I can't say too much about, and then I guess long-term, I would

36:23.560 --> 36:27.680
go back to saying how at the beginning, I said we're a consumer robotics company, I

36:27.680 --> 36:30.360
didn't say we were a toy company.

36:30.360 --> 36:34.920
We're currently focused in entertainment, and that's very deliberate for a couple of

36:34.920 --> 36:35.920
reasons.

36:35.920 --> 36:43.080
One, we felt that, to develop the capabilities we needed both technically and from a manufacturing

36:43.080 --> 36:46.880
scale and price point perspective, this was a good place for us to start building an

36:46.880 --> 36:52.240
actual product that we could sell and market and build a successful company on as opposed

36:52.240 --> 36:55.080
to jumping to the far end of like, we're going to have a humanoid in your home and it's

36:55.080 --> 36:56.280
going to clean your house.

36:56.280 --> 36:57.280
Right.

36:57.280 --> 36:59.040
Yeah, and how are we going to fund that company, right?

36:59.040 --> 37:04.240
So they're trying to keep an eye on building a business at the same time and how to take

37:04.240 --> 37:08.840
steps, you know, sort of build products of stepping stones as we build out core technologies

37:08.840 --> 37:13.720
and core capabilities to get to those big fancy robots everybody wants.

37:13.720 --> 37:18.480
It seems like a lot of the companies in this space take that approach in some way, shape

37:18.480 --> 37:19.480
or form.

37:19.480 --> 37:23.320
Like, I robots got, you know, we know them for the vacuum cleaner, but they've got, you

37:23.320 --> 37:30.080
know, a lot of government robots and defense robots and I'm sure they're kind of eyeing

37:30.080 --> 37:34.160
this, you know, the home robotics market and as that grows and creates opportunities.

37:34.160 --> 37:39.560
Yeah, I think that, and that's, you know, I think it's a necessary, a necessary thing.

37:39.560 --> 37:44.080
People often, you know, that everyone sees what the stuff in movies and TV, right, and

37:44.080 --> 37:45.080
that's where they want.

37:45.080 --> 37:46.080
Right.

37:46.080 --> 37:49.320
But, you know, despite all the headlines about AI and deep learning, et cetera, we're still

37:49.320 --> 37:50.320
a long way off.

37:50.320 --> 37:51.320
Yeah.

37:51.320 --> 37:56.920
And so I think, you know, being careful about building that technology out in a very deliberate

37:56.920 --> 38:02.440
manner and creating products along the way that make good products themselves is important.

38:02.440 --> 38:05.040
Because, you know, to us, a robot is not a product.

38:05.040 --> 38:06.040
It is a technology.

38:06.040 --> 38:07.040
Right.

38:07.040 --> 38:11.080
It's a installation of technologies to gather which make a product, but you still need a

38:11.080 --> 38:12.640
product idea.

38:12.640 --> 38:17.720
And I think to that, to that end, it's not only are we trying to build those technologies,

38:17.720 --> 38:20.760
the other thing that we feel is important, you know, we like to say sort of not only

38:20.760 --> 38:25.720
is the IQ of the robot important, the techie smart AI, but the EQ is also important.

38:25.720 --> 38:28.480
We're going to build these robots and they're going to be living in our homes and that is

38:28.480 --> 38:29.480
our goal.

38:29.480 --> 38:31.000
We want a robot in every home.

38:31.000 --> 38:35.680
Those robots, we don't want them to be weird appliances that sit off in the corner that,

38:35.680 --> 38:36.680
right.

38:36.680 --> 38:39.160
It's this strange thing that you don't interact with.

38:39.160 --> 38:40.920
It's, we've seen this with Cosmo.

38:40.920 --> 38:45.320
It's a really interesting moment when you make eye contact with the robot or you assign

38:45.320 --> 38:49.360
personality to it or, you know, have a bond with it and we definitely see it with this

38:49.360 --> 38:51.640
little robot.

38:51.640 --> 38:52.640
It's a whole different experience.

38:52.640 --> 38:59.440
And so I think that expertise we're building and how to take things we know about movies

38:59.440 --> 39:04.200
and character design and deploy them in hardware and deal with that side of the human robot

39:04.200 --> 39:09.960
interaction piece of the puzzle is also super important and I think will, you know, be important

39:09.960 --> 39:12.160
for all our products in the future.

39:12.160 --> 39:18.880
Are there any kind of learnings that you can kind of encapsulate for us on, I guess,

39:18.880 --> 39:25.640
the intersection of AI and consumer electronics or like, you know, the challenges of putting

39:25.640 --> 39:30.880
AI and consumer electronics in this podcast, we talk a lot about, you know, enterprise-y stuff

39:30.880 --> 39:37.160
and industrial robots and things like that and I'm wondering about, you know, the specifics

39:37.160 --> 39:43.080
of, you know, AI and, you know, games and entertainment and toys and electronics and that kind

39:43.080 --> 39:44.080
of thing.

39:44.080 --> 39:45.080
Yeah.

39:45.080 --> 39:49.240
I think a few things, consumers don't actually care about, I mean, I think your listeners

39:49.240 --> 39:53.920
do and I do, but at large, consumers don't care about the actual tech, right?

39:53.920 --> 39:54.920
Yeah.

39:54.920 --> 39:55.920
Yeah.

39:55.920 --> 39:57.920
They just wanted to work and be cool and we all walk around cell phones and I'm talking

39:57.920 --> 40:00.560
how many people have any idea how that technology works, right?

40:00.560 --> 40:04.320
It's ridiculous what we do every day on our cell phones, but people just want like it

40:04.320 --> 40:09.720
to do all that awesome stuff and I think that is one thing is, you, as engineers working

40:09.720 --> 40:13.240
on their product, I have to remember, computer vision is not the product.

40:13.240 --> 40:18.280
There's a product and it has goals and computer vision is in service of those goals, not

40:18.280 --> 40:19.280
the other way around.

40:19.280 --> 40:26.320
So we often, you know, it don't use sort of the latest and greatest tech or idea because

40:26.320 --> 40:29.200
it's like, well, can the users are going to be able to tell if we're doing that?

40:29.200 --> 40:32.080
Like, what is the actual end result of using that technology?

40:32.080 --> 40:36.320
So I think keeping a mind that, you know, in the consumer space, you're building a consumer

40:36.320 --> 40:40.680
product, you're not necessarily building a technology that's sort of B2B and will be

40:40.680 --> 40:45.520
used in other products and keeping that, that end goal in mind is probably one of the

40:45.520 --> 40:46.520
big ones.

40:46.520 --> 40:50.600
I think another big thing about using AI and particularly, you know, everything over

40:50.600 --> 40:55.400
the last in years is about probabilistic reasoning, effectively, right?

40:55.400 --> 41:01.140
And people want a yes or a no or a guaranteed, it's going to work in these cases and it

41:01.140 --> 41:02.240
won't work in those cases.

41:02.240 --> 41:06.880
And if there's anything we know, it's that you, it's very hard to nail that down.

41:06.880 --> 41:11.200
You can say it's based on our data, it's going to work 95% of the time.

41:11.200 --> 41:14.880
Well, like enumerating the 5% of the cases, you can't do it.

41:14.880 --> 41:18.920
And so a lot of what we spend our time doing is, you know, it's, it's sort of easy to get

41:18.920 --> 41:21.320
the early prototype of the cool behavior.

41:21.320 --> 41:28.760
So what do you do in the weird edge case and 5% of the time that it doesn't work, situations,

41:28.760 --> 41:30.320
all those edge cases are really complicated.

41:30.320 --> 41:34.640
You know, we have kid picks up a robot, right, in the middle of behavior X or animation

41:34.640 --> 41:35.640
Y.

41:35.640 --> 41:36.640
It's like, okay, wait.

41:36.640 --> 41:37.640
So what happens then?

41:37.640 --> 41:40.760
And, you know, just enumerating all possible states in the state machine is not really

41:40.760 --> 41:43.120
a viable solution either.

41:43.120 --> 41:47.720
So I think edge case handling is a big, big deal when you start trying to deploy these

41:47.720 --> 41:51.960
things that you know will have failures or have false positives.

41:51.960 --> 41:55.560
How do you, how do you incorporate that into the product as opposed to pretending it

41:55.560 --> 41:56.560
doesn't exist?

41:56.560 --> 41:57.560
Because it will happen.

41:57.560 --> 42:05.240
And have you developed any methodology for tackling that specific issue or is it, you

42:05.240 --> 42:11.000
know, each behavior, each edge case is different and it's just knowing that you need to think

42:11.000 --> 42:12.000
that through this.

42:12.000 --> 42:14.400
That's a good, that's a good question.

42:14.400 --> 42:19.120
I think we have, particularly our guys that work on more specifically and focused on

42:19.120 --> 42:21.120
that behavior system.

42:21.120 --> 42:26.240
I would say a little bit of both, over time, the way that our behaviors encode or engineered

42:26.240 --> 42:32.440
are designed to sort of handle things better, naturally just by virtue of the way, you

42:32.440 --> 42:34.600
know, the system architecture is set up.

42:34.600 --> 42:38.200
So there are sort of ways to build what we have learned, I think, into the system.

42:38.200 --> 42:41.880
But there is a lot of, you know, that sort of secret sauce, black magic, thing with sort

42:41.880 --> 42:42.880
of like deep-burning.

42:42.880 --> 42:44.960
There's things that I feel like people can't quite explain yet.

42:44.960 --> 42:49.160
It's just sort of like, I've just done this enough, I kind of know what is and isn't going

42:49.160 --> 42:50.160
to happen.

42:50.160 --> 42:56.960
And so some of it, I think, is just at this point, you know, our internal knowledge of how

42:56.960 --> 42:57.960
it works.

42:57.960 --> 43:01.800
But yeah, I think actually over time, as you start to codify what those things are, there

43:01.800 --> 43:05.200
are definitely places in the code where the architecture, again, supports that or makes

43:05.200 --> 43:08.880
it easier or handles things for you that you've sort of realized this always happens.

43:08.880 --> 43:11.800
We need to wait it, just automatically detect and handle that.

43:11.800 --> 43:12.800
Yeah.

43:12.800 --> 43:13.800
Okay.

43:13.800 --> 43:18.880
Anything else on your things to think about from a consumer products perspective?

43:18.880 --> 43:19.880
Hmm.

43:19.880 --> 43:22.320
I think those are probably the big ones.

43:22.320 --> 43:27.240
I guess the other one, given that data is such a huge thing, right, for training all

43:27.240 --> 43:30.480
these models and labeling is such a huge thing.

43:30.480 --> 43:37.720
I think for robots in particular, you know, in images in particular, within that, getting

43:37.720 --> 43:44.200
training data is, I think, even harder on robots because the degree to which the robots

43:44.200 --> 43:48.560
view of the world and images mind from the web differ is huge.

43:48.560 --> 43:53.880
So the statistics of the data that a robot sees, it's all motion blurry or terribly exposed

43:53.880 --> 43:57.360
or like half your arm or what I'm like, nobody has actually pointed the camera at something

43:57.360 --> 43:58.680
and taken a picture.

43:58.680 --> 44:02.480
There's, I think people tend to forget that like, there's already some selection bias

44:02.480 --> 44:07.680
in mining images from the web or images from Facebook, because somebody helped

44:07.680 --> 44:12.120
the camera and took the photo, framed the shot, and decided to upload it.

44:12.120 --> 44:14.200
And decided to upload it, exactly, very true.

44:14.200 --> 44:17.400
And so, you know, Cosmos is driving around, taking images all the time.

44:17.400 --> 44:21.360
And so you just get weird, random garbage all the time and terrible exposures and, you

44:21.360 --> 44:25.600
know, bad white balance and lots of motion blur and a weird perspective, he's looking

44:25.600 --> 44:26.600
up at the world.

44:26.600 --> 44:28.040
Nobody takes pictures from there.

44:28.040 --> 44:34.480
So gathering that data is a big challenge and I think it's not to be underestimated

44:34.480 --> 44:40.680
that it, how much it matters to try to get, to try to get data appropriate for, you

44:40.680 --> 44:44.720
know, your problem when it's robotics and not, you know, something else.

44:44.720 --> 44:45.920
It feels like that'd be easy.

44:45.920 --> 44:50.760
Like you just make, you know, a hundred of these and throw a bunch of blocks around and

44:50.760 --> 44:52.960
like, have them run around and shoot a bunch of video.

44:52.960 --> 44:54.560
I mean, it's the problem you're trying to solve, right?

44:54.560 --> 44:58.440
If it's the block, you can probably sort of design a scenario.

44:58.440 --> 44:59.440
You're right.

44:59.440 --> 45:00.440
Some situations that they care.

45:00.440 --> 45:02.640
If it's the people interaction thing, that's the people very lot of hard work.

45:02.640 --> 45:05.120
That varies a whole lot.

45:05.120 --> 45:07.520
All these things are challenging just different types of rooms.

45:07.520 --> 45:09.480
You know, we're building it in an office, right?

45:09.480 --> 45:10.480
Yeah.

45:10.480 --> 45:12.080
The office environment looks very different from people's homes.

45:12.080 --> 45:13.080
Right.

45:13.080 --> 45:14.080
Right.

45:14.080 --> 45:16.760
So, but we also don't, for privacy reasons, we're not just going to gather people, data from

45:16.760 --> 45:18.160
people's homes and upload it to our servers.

45:18.160 --> 45:19.160
Right.

45:19.160 --> 45:21.960
So, yeah, the data collection problem is a, is a, is a big one.

45:21.960 --> 45:22.960
Mm-hmm.

45:22.960 --> 45:23.960
Yeah.

45:23.960 --> 45:24.960
Makes sense.

45:24.960 --> 45:27.120
Well, Andrew, this has been a great, a great conversation.

45:27.120 --> 45:32.280
What I'm going to do now is I'm going to hit pause and go grab my camera and

45:32.280 --> 45:37.040
we'll kind of let you fire this thing up and see it in action.

45:37.040 --> 45:41.720
So for the folks that are listening on the podcast, they may not catch this part.

45:41.720 --> 45:46.120
But jump over to our YouTube channel and you'll check this out.

45:46.120 --> 45:51.760
But for those who aren't going to do that, or we'll be doing that later once they're

45:51.760 --> 45:56.160
off the train or whatever, thank you so much for taking the time to chat with me.

45:56.160 --> 45:57.160
Sure.

45:57.160 --> 45:58.160
No, it's been fun.

45:58.160 --> 45:59.160
Lots of good questions.

45:59.160 --> 46:00.160
Awesome.

46:00.160 --> 46:05.000
All right, everyone, that's our show for today.

46:05.000 --> 46:09.480
Thanks so much for listening and for your continued feedback and support.

46:09.480 --> 46:16.000
Remember, for your chance to win in our AI at home giveaway, head on over to twimmaleye.com

46:16.000 --> 46:20.440
slash my AI contest for complete details.

46:20.440 --> 46:25.440
For more information on Andrew, Cosmo, or any of the topics covered in this episode,

46:25.440 --> 46:29.760
head on over to twimmaleye.com slash talk slash 102.

46:29.760 --> 46:34.040
Thanks once again to Intel AI for their sponsorship of this series.

46:34.040 --> 46:38.400
To learn more about their partnership with Ferrari North America Challenge and the other things

46:38.400 --> 46:42.640
they've been up to, visit ai.intel.com.

46:42.640 --> 46:47.720
Of course, we'd be delighted to hear from you, either via a comment on the show notes page

46:47.720 --> 46:54.160
or via Twitter directly to me at at Sam Sherrington or to the show at at twimmaleye.

46:54.160 --> 47:01.160
Thanks once again for listening and catch you next time.

