WEBVTT

00:00.000 --> 00:13.400
Welcome to the Tumel AI Podcast.

00:13.400 --> 00:16.400
I'm your host Sam Charrington.

00:16.400 --> 00:24.480
Hey, what's up everyone?

00:24.480 --> 00:29.920
I recently attended the AWS Reinvent Conference in Las Vegas, and I'm excited to share

00:29.920 --> 00:38.720
a few of my many interesting conversations from that event here on the podcast this week.

00:38.720 --> 00:44.160
Before we dive in, I'd like to thank our friends at Capital One for sponsoring our Reinvent

00:44.160 --> 00:45.760
series.

00:45.760 --> 00:50.120
Capital One has been a huge friend and supporter of this podcast for some time now, and

00:50.120 --> 00:54.600
I'm looking forward to sharing my interview with Dave Castillo, Capital One's managing

00:54.600 --> 00:58.640
VP of Machine Learning with you on Thursday.

00:58.640 --> 01:02.400
Dave and I discussed the unique approach being taken at the company's Center for Machine

01:02.400 --> 01:07.480
Learning, as well as some of the interesting AI use cases being developed at the bank,

01:07.480 --> 01:12.080
and the platform they're building to support their ML and AI efforts.

01:12.080 --> 01:17.880
Once again, check back in on Thursday, December 19th for that conversation.

01:17.880 --> 01:23.960
To learn more about Capital One's Machine Learning and AI efforts and research, visit capitalone.com

01:23.960 --> 01:26.960
slash tech slash explore.

01:26.960 --> 01:28.960
And now on to the show.

01:28.960 --> 01:36.760
All right, everyone, I am on the line with Brighton Shang.

01:36.760 --> 01:40.720
Brighton is the founder and CEO at AquaBite.

01:40.720 --> 01:42.760
Brighton, welcome to the Twil AI podcast.

01:42.760 --> 01:43.760
Yeah.

01:43.760 --> 01:44.760
Thank you.

01:44.760 --> 01:45.760
Great to be here.

01:45.760 --> 01:46.760
Awesome.

01:46.760 --> 01:51.440
So you just spoke at the Reinvent Machine Learning Summit earlier this week on a really

01:51.440 --> 01:56.080
interesting topic, and one that we have not covered on the podcast before.

01:56.080 --> 02:01.000
The application of deep learning to fish farming, essentially.

02:01.000 --> 02:06.680
I'm really interested in diving into the topic, but how did you get started working in

02:06.680 --> 02:07.680
this area?

02:07.680 --> 02:10.800
Yeah, it's a bit of an unusual story.

02:10.800 --> 02:17.000
So for context, the company AquaBite, we build software for fish farms.

02:17.000 --> 02:21.480
And it's a camera-based software, so the camera goes in the fish pen.

02:21.480 --> 02:23.680
It takes pictures of the fish.

02:23.680 --> 02:28.520
And then using computer vision and machine learning algorithms, we process those images

02:28.520 --> 02:33.680
to be able to determine things such as the weight of the fish, the health of the fish,

02:33.680 --> 02:39.080
how hungry the fish is, and then ultimately the farming buys us as a subscription service.

02:39.080 --> 02:45.400
And so it's this idea of bringing machine learning and computer vision, which is very

02:45.400 --> 02:48.800
well-understood in other industries and bringing it to fish farming.

02:48.800 --> 02:55.320
Now, the whole idea, I mean, so I grew up in Ithaca, New York, actually right by Cornell,

02:55.320 --> 02:59.080
and one of our family friends was a professor of Occupial through there.

02:59.080 --> 03:01.400
Then I ended up going to Princeton.

03:01.400 --> 03:06.160
I studied operations research and financial engineering, which is basically like data science

03:06.160 --> 03:07.160
and machine learning.

03:07.160 --> 03:12.280
And then after that, pretty much since university, I've been starting various companies.

03:12.280 --> 03:17.240
I started an algorithmic trading firm, also was a CTO of another company that was doing

03:17.240 --> 03:23.520
deep learning for cancer detection, and then 2017, I started Occupial and the idea was

03:23.520 --> 03:29.400
to bring the same machine learning and computer vision technologies to fish farming.

03:29.400 --> 03:34.400
And for those who fish farming, maybe not as well known in the US, but actually is the

03:34.400 --> 03:40.440
main way we get fish, like over half of the fish we consume is farmed.

03:40.440 --> 03:42.280
It's not grown in the ocean.

03:42.280 --> 03:48.160
And so the idea of being these fish, imagine they grow in these massive pens, we don't

03:48.160 --> 03:49.960
really know how they grow.

03:49.960 --> 03:51.640
We don't know how much to feed them.

03:51.640 --> 03:57.280
We don't know a lot of things, and so be able to bring basic insight to the farmers using

03:57.280 --> 04:04.440
computer vision machine learning is really like a game changer for them.

04:04.440 --> 04:08.720
And I can share more about the progression of the company and how we progress.

04:08.720 --> 04:13.520
But now we're selling to these salmon farmers in Norway that are using it to count sea

04:13.520 --> 04:16.560
lice, estimate the weight of their fish.

04:16.560 --> 04:20.880
Most of our engineering teams in San Francisco, but we actually start selling with the salmon

04:20.880 --> 04:25.480
farms in Norway, because 99% of the industries that are national.

04:25.480 --> 04:28.400
Well, how did you identify the opportunity?

04:28.400 --> 04:30.080
Was it serendipity?

04:30.080 --> 04:37.880
You met someone who was interested in or working in aquaculture and you recognized the opportunity

04:37.880 --> 04:45.120
through those conversations, or were you actively searching for places to apply ML and AI,

04:45.120 --> 04:47.800
and you came across this particular opportunity?

04:47.800 --> 04:54.240
Well, generally, I've been working in the space in different companies, and conceptually

04:54.240 --> 05:00.520
I had an idea of, well, to be able to process images and to be able to use that to deliver

05:00.520 --> 05:04.160
some insight, that paradigm, the idea for fish farming.

05:04.160 --> 05:10.120
So I mentioned that I grew by Cornell, but also my old co-founder, one of his classmates

05:10.120 --> 05:14.200
had owned a fish farm, and I had heard about it from him.

05:14.200 --> 05:16.320
And then kind of one thing led to another.

05:16.320 --> 05:22.200
I was reading papers on how they were using camera-sized fish and then ended up at the time

05:22.200 --> 05:25.000
incubating this out of a venture capital firm.

05:25.000 --> 05:29.440
So they had given me some money with the idea of me coming up with a new machine learning

05:29.440 --> 05:34.480
powered startup, and this is one of the ideas I looked into, and then one thing led to

05:34.480 --> 05:38.800
another and then built out a simple prototype and then raised some capital.

05:38.800 --> 05:43.740
So it was a bit of serendipity, but it was also the experience of having worked in these

05:43.740 --> 05:48.520
other industries and seeing the parallels between, I mean, even something as foreign

05:48.520 --> 05:53.800
as like algorithmic trading, it's conceptually similar because you're processing data in

05:53.800 --> 05:58.320
real time that's coming in, and instead of deciding whether to buy or sell stocks, you're

05:58.320 --> 06:01.840
just deciding how much to feed your fish or what action to take.

06:01.840 --> 06:07.320
And so conceptually, these mental models are applicable between different industries.

06:07.320 --> 06:12.880
And so you mentioned talking a little bit more about the evolution of the company.

06:12.880 --> 06:15.640
Where did you start once you identified the problem?

06:15.640 --> 06:17.840
So I started by building a simple prototype.

06:17.840 --> 06:18.840
Okay.

06:18.840 --> 06:24.800
So I actually talked about this at the ML Summit, but I started literally in my apartment

06:24.800 --> 06:29.800
bathtub, so I built a simple rig, filled the bathtub with water, got some robotic fish

06:29.800 --> 06:30.800
off of Amazon.

06:30.800 --> 06:34.800
I was going to say, did you load some salmon into your bathtub?

06:34.800 --> 06:35.800
Yeah, exactly.

06:35.800 --> 06:36.800
Yeah.

06:36.800 --> 06:43.080
I don't know if it would fit, but yeah, certainly like these tiny robotic fish that would swim

06:43.080 --> 06:49.520
around, and it works like the camera could actually determine the length of the robotic

06:49.520 --> 06:54.400
fish, and the proportions of the fish correlate to the weight.

06:54.400 --> 07:00.640
It's just something that biologists know, and so then kind of that the concept was proven,

07:00.640 --> 07:06.200
and then the idea was, okay, now I need to go from my bathtub to the ocean, where it's

07:06.200 --> 07:11.400
rough conditions, where it's limited connectivity, where it's not just these robotic fish, but

07:11.400 --> 07:17.520
you have live fish with behavior, minds of their own, different environmental conditions,

07:17.520 --> 07:24.800
and a lot of practical concerns, and that was really kind of 27, 2018 was building the

07:24.800 --> 07:30.760
first prototypes for the ocean, getting a camera there, actually finding the fish farmers,

07:30.760 --> 07:36.040
so I don't know how many folks in the U.S. know fish farmers, but like again 99% outside

07:36.040 --> 07:41.960
the U.S., and so imagine me and Silicon Valley, but going to Norway to talk to these fish

07:41.960 --> 07:47.440
farmers, find them, convince them that this is like the next idea, and then start working

07:47.440 --> 07:53.400
with them, and so actually ended up living in Norway for a number of months, and certainly

07:53.400 --> 07:55.600
traveling back and forth since then.

07:55.600 --> 07:56.600
Wow, wow.

07:56.600 --> 08:05.720
Yeah, I've seen some fish farms in Asia, and what I remember of them, particularly when

08:05.720 --> 08:14.000
the fish are being fed, and this may be the anomaly, but it was just chaos, it wasn't

08:14.000 --> 08:23.800
like a few robotic fish in a bathtub, the density per square meter of fish or of ocean was

08:23.800 --> 08:31.200
very, very high, it strikes me as a very challenging environment to do computer vision.

08:31.200 --> 08:32.960
I think it is quite challenging.

08:32.960 --> 08:38.720
I think it also depends on what type of fish are going in which environment to take an

08:38.720 --> 08:45.080
example in Norway by law, they cannot have more than two and a half percent of their pen

08:45.080 --> 08:46.080
be fish.

08:46.080 --> 08:47.080
Oh, wow.

08:47.080 --> 08:48.080
Okay.

08:48.080 --> 08:55.000
So actually it's like, it is quite a lot of fish, but it's not super packed, and so it's

08:55.000 --> 09:00.280
not like your fish are blocking your camera, but it is a very chaotic environment.

09:00.280 --> 09:08.680
Going back to the bathtub, you found some success in kind of estimating the weight

09:08.680 --> 09:17.200
of your robotic fish, maybe talk a little bit more about the kind of the process or the

09:17.200 --> 09:24.320
challenges there, for example, even measuring the length of a fish without knowing its distance

09:24.320 --> 09:29.520
from the camera, if you're just using the camera, like how do you overcome those kinds

09:29.520 --> 09:30.520
of issues?

09:30.520 --> 09:31.520
Right.

09:31.520 --> 09:32.520
Right.

09:32.520 --> 09:35.200
So if you look at our website, we have a picture of the camera.

09:35.200 --> 09:41.360
It's a stereo camera, so with stereo, kind of two parallel lenses, we can send depth

09:41.360 --> 09:44.960
using the disparity in the two images.

09:44.960 --> 09:45.960
Oh, okay.

09:45.960 --> 09:53.080
Now, it's a fairly straightforward geometric calculation to figure out.

09:53.080 --> 09:57.520
Kind of if I see the pixel on one image and the pixel on the other image, I can calculate

09:57.520 --> 10:02.000
the disparity and then use that to get the depth and then the three position and therefore

10:02.000 --> 10:05.160
calculate the length and so on and so forth.

10:05.160 --> 10:08.600
Now, conceptually, this makes, it's fairly straightforward.

10:08.600 --> 10:14.000
Now, in practice, you're dealing with a number of challenges, I'll just highlight a couple

10:14.000 --> 10:19.080
for one, optics are slightly different in water.

10:19.080 --> 10:24.680
Water you're dealing with light scattering, turbidity, essentially particles in the water

10:24.680 --> 10:29.360
that your photons, by the time they're hitting your lens, they're a bit distorted or they

10:29.360 --> 10:36.080
got to, they bounce off of different particles and so to be able to get a very precise estimate

10:36.080 --> 10:39.240
is more difficult underwater.

10:39.240 --> 10:46.280
Also fish are shiny, they're reflective, they're very specular and so to be able to get

10:46.280 --> 10:52.600
good detail of that specific scale on one image versus another image and get the distance,

10:52.600 --> 10:58.040
it's actually quite challenging versus something that's more textured or that you can actually

10:58.040 --> 11:00.640
discern a lot of detail.

11:00.640 --> 11:04.640
These fish underwater, I mean the scales look the same, so it's a bit more challenging.

11:04.640 --> 11:10.080
Also for those who've worked with camera-based systems, you need to calibrate them and

11:10.080 --> 11:15.280
the calibration can be a bit sensitive and so there's a number of steps and practical

11:15.280 --> 11:22.440
challenges that you need to work with from resolution to turbidity to calibration to

11:22.440 --> 11:30.040
specularity, the object to lighting and a lot of this was us actually going out to the

11:30.040 --> 11:35.120
field, dropping a camera in the water, doing a lot of experimentation because a lot of

11:35.120 --> 11:41.040
this stuff you can calculate at a theoretical level but until you put the camera in the

11:41.040 --> 11:46.240
water and actually image the fish, you don't know if it's going to work or not and then

11:46.240 --> 11:51.880
compound that with this being at actual fish farm which is in the middle of the ocean,

11:51.880 --> 11:57.720
limited connectivity, literally like you got to take a boat to get out there and so it's

11:57.720 --> 12:03.240
not as easy as taking your autonomous vehicle and driving it around town to get data.

12:03.240 --> 12:10.600
You need to really go through a lot of practical challenges, get on a boat, go to Norway to

12:10.600 --> 12:16.840
actually do this type of research but once you do it then we get the data, we're able

12:16.840 --> 12:21.440
to analyze it and actually deductively come to the best system.

12:21.440 --> 12:27.760
As far as we've talked about deterministic approaches, geometry and optics and things

12:27.760 --> 12:31.840
like that, where do machine learning and deep learning come into play?

12:31.840 --> 12:37.520
It's in the perception so for example, let's just take the example of we want to figure

12:37.520 --> 12:42.360
out the weight of a single fish.

12:42.360 --> 12:47.800
We know from the biologist that if I get the length then I can calculate the weight

12:47.800 --> 12:53.960
because like humans, the fish grow in proportions and so you can get that.

12:53.960 --> 12:58.800
Now the actual detection of these points on the fish, you can imagine if we're doing this

12:58.800 --> 13:04.680
for thousands and thousands of fish a day, we're not going to just want people to identify

13:04.680 --> 13:05.680
the points.

13:05.680 --> 13:10.800
This is where the computer vision comes in where we have algorithms that can automatically

13:10.800 --> 13:17.760
detect key points on the fish and be able to then use that as inputs into the geometry

13:17.760 --> 13:25.160
to get the lengths and the fish weight and that those are essentially deep learning, convolutional

13:25.160 --> 13:31.600
neural net based algorithms that can do detection of different key points and be able to do

13:31.600 --> 13:32.600
other things.

13:32.600 --> 13:37.640
Something we'll talk a bit about later is we determine the health of the fish, it's not

13:37.640 --> 13:42.880
just the weight, it's also the health of the fish, particles in the water, food.

13:42.880 --> 13:46.880
I don't want to spoil too much of the other applications we'll talk about them later but

13:46.880 --> 13:53.440
you can use computer vision as a lot of the perception input to these downstream algorithms

13:53.440 --> 13:59.240
and we are using some supervised algorithms to be able to do things such as determine

13:59.240 --> 14:01.000
the fish weight.

14:01.000 --> 14:07.160
Before we leave the weight, one aspect of this that strikes me as a bit counterintuitive

14:07.160 --> 14:14.240
when I think of a human's length or height and their weight, there's certainly a correlation

14:14.240 --> 14:21.120
but I would think of our height as more correlated to age and our weight can kind of vary around

14:21.120 --> 14:30.200
some midpoint pretty dramatically but that our height obviously doesn't change accordingly.

14:30.200 --> 14:34.600
We don't grow a few inches after Thanksgiving and then take those few inches off, vertical

14:34.600 --> 14:35.600
inches at least.

14:35.600 --> 14:42.400
But what I'm here for you is that you're inferring the weight largely on the length of the

14:42.400 --> 14:43.400
fish.

14:43.400 --> 14:50.200
So to your point, we are detecting a number of different points on the fish so it's not

14:50.200 --> 14:55.480
just the length, it's the width, it's like the eye to the fin to all these different points

14:55.480 --> 15:00.720
on the fish that then end up forming a 3D model of the fish to get the weight.

15:00.720 --> 15:01.720
Got it.

15:01.720 --> 15:07.880
You talked a little bit about the relative density of the fish in the farm.

15:07.880 --> 15:16.280
Are you using your perception models to try to create bounding boxes around multiple

15:16.280 --> 15:20.720
fish in an image or are you throwing out images that have multiple fish?

15:20.720 --> 15:28.400
Most of your images have single fish and how resilient are your models to the orientation

15:28.400 --> 15:29.400
of the fish?

15:29.400 --> 15:33.560
Are you trying to catch the fish at just the right moment?

15:33.560 --> 15:37.960
I would say all of the above.

15:37.960 --> 15:45.000
So if you look at one of the underwater fish image pictures, so I have one in the presentation

15:45.000 --> 15:49.560
I was showing each one of these images has like 50 to 100 fish.

15:49.560 --> 15:50.560
Okay.

15:50.560 --> 15:53.960
So there's like a massive amount of fish and as you pointed out, the fish is in every

15:53.960 --> 15:54.960
which direction.

15:54.960 --> 15:57.920
I mean, the fish generally, they school together.

15:57.920 --> 16:02.960
So if you put it parallel to the school of fish, you can get a nice side view.

16:02.960 --> 16:08.360
But there are some fish that are like facing the camera away from the camera or not in

16:08.360 --> 16:15.480
the right orientation or there's too much light or they're too dark or whatever the water

16:15.480 --> 16:18.560
is too blurry and so the fish is too blurry.

16:18.560 --> 16:27.080
And so there needs to be some type of process by which we can filter the images and make

16:27.080 --> 16:30.400
sure we're getting the best fish to be analyzed.

16:30.400 --> 16:35.960
And that's really more an art than a science where that's where you're tweaking your

16:35.960 --> 16:41.120
hyperparameters to figure out what's the best trade-off between essentially precision

16:41.120 --> 16:45.080
and recall of a fish detector, a clear of a clear fish.

16:45.080 --> 16:49.360
And so whether you want more or less fish and then if you want more fish, then it's

16:49.360 --> 16:52.400
less, the more the fish are less clear.

16:52.400 --> 16:57.840
But then you kind of figure out what's the optimal trade-off to get you the best result.

16:57.840 --> 17:04.400
Then is the idea that if you're capturing kind of the, again, kind of sticking to weight

17:04.400 --> 17:07.880
and maybe this extends to health and some of the other things you're measuring.

17:07.880 --> 17:14.920
But is the idea that you are essentially computing some kind of average weight of all the

17:14.920 --> 17:23.400
fish or is it more trying to identify individual fish and track individual fishes weight or anything

17:23.400 --> 17:24.400
like that?

17:24.400 --> 17:30.480
Yes, so that's actually one of the more cool applications we're working on is fish facial

17:30.480 --> 17:32.080
recognition.

17:32.080 --> 17:37.240
As it turns out, the spots on the fish's face are unique.

17:37.240 --> 17:42.960
And so you can use it like a fingerprint to be able to uniquely identify that fish.

17:42.960 --> 17:46.640
So you can imagine what one of the questions you might ask, okay, how do you know if I

17:46.640 --> 17:50.600
saw the same fish twice, like how do I know if it's swam by the camera twice?

17:50.600 --> 17:54.920
So you can know from this individual fish recognition.

17:54.920 --> 18:00.920
And so we are using that to track individual fish over time and then there's some other

18:00.920 --> 18:07.080
interesting implications where you can use it, for example, in breeding to be able to find

18:07.080 --> 18:11.560
the best male, the best female fish and breathe them together and to be able to do a lot

18:11.560 --> 18:17.520
more detailed analyses if you can know not just at a population level but also at an individual

18:17.520 --> 18:19.240
level how they're growing.

18:19.240 --> 18:24.600
And so we are working along on a lot of these other applications that are improving our

18:24.600 --> 18:27.000
weight estimation model, for example.

18:27.000 --> 18:28.400
Okay, that's awesome.

18:28.400 --> 18:37.760
Yeah, one of our most popular shows from last year was with Jason Holmberg who is the

18:37.760 --> 18:45.520
head of engineering or was at the time at Wildme, which was applying kind of similar types

18:45.520 --> 18:51.280
of approaches to identifying, uniquely identifying humpback whales.

18:51.280 --> 18:57.040
And he's the same kind of fingerprint analogy based on their patterns and markings.

18:57.040 --> 18:59.840
Wow, that's pretty cool.

18:59.840 --> 19:07.880
Yeah, I know that there are, I mean, even WACV 2020, they're holding a specific section

19:07.880 --> 19:10.000
on animal re-identification.

19:10.000 --> 19:15.480
So I know there's, even like specific conferences that are focusing on this.

19:15.480 --> 19:22.960
And so you are, you know, maybe back to kind of the fundamental use case, you describe

19:22.960 --> 19:23.960
this.

19:23.960 --> 19:29.640
I forget what you said, 6,000, I forget if that was like images per day or fish per day

19:29.640 --> 19:30.640
or something like that.

19:30.640 --> 19:36.360
But the picture that you've created for me is that you've got this online real time

19:36.360 --> 19:43.600
application that's constantly taking pictures of fish and, you know, identifying their weight

19:43.600 --> 19:48.560
and health and hunger levels, things like that.

19:48.560 --> 19:53.320
And what I guess one of my fundamental questions is like, do we need to know the real time

19:53.320 --> 19:58.040
health of the fish like with, where does it, you know, I imagine that before that someone

19:58.040 --> 20:02.480
would like to take a boat out to the pen, you know, once a week and sample a few fish

20:02.480 --> 20:07.600
and kind of get a sense for how they were doing, you know, where does that fall short?

20:07.600 --> 20:14.320
Well, so to give you a sense, let's, let's take a typical salmon pen in Norway.

20:14.320 --> 20:19.600
It's about half a football field in Damien or you could submerge an entire 737 in the

20:19.600 --> 20:20.600
pen.

20:20.600 --> 20:22.200
These are like massive pens.

20:22.200 --> 20:27.240
The single pen has anywhere from 100,000 to 200,000 fish.

20:27.240 --> 20:28.240
Okay.

20:28.240 --> 20:33.120
So you're not going to get a representative sample if you just take a sample of even 100

20:33.120 --> 20:38.880
fish, you need to get some representative part of the population.

20:38.880 --> 20:44.960
Now combine that with the other fact that these fish, they're growing one to two percent

20:44.960 --> 20:49.480
every day, just be like of their own body weight at the eats.

20:49.480 --> 20:50.480
Okay.

20:50.480 --> 20:51.480
So they're going pretty quickly.

20:51.480 --> 20:56.880
And so you want to be able to sample enough every day such that you get an accurate weight

20:56.880 --> 21:00.360
and also see a represented enough population.

21:00.360 --> 21:01.360
Okay.

21:01.360 --> 21:06.800
So, I mean, for, and the other thing is for us, again, because these farms were in the

21:06.800 --> 21:12.480
middle of the ocean, it's not like we're sending these images back to the cloud to get

21:12.480 --> 21:13.480
processed.

21:13.480 --> 21:16.080
It's just like too much data.

21:16.080 --> 21:22.440
And so the trade off of processing more images is just computing power and because it

21:22.440 --> 21:26.440
is local at the farm, the computing happens for free.

21:26.440 --> 21:30.400
So we're, we would like to process as many fish as we can.

21:30.400 --> 21:36.560
I'm interested in exploring that the form factor of your computing system a little bit.

21:36.560 --> 21:43.080
Do you have like a floating data center that is doing a floating kind of inference engine?

21:43.080 --> 21:44.600
It's all on camera.

21:44.600 --> 21:53.440
So if you look at our camera, it has the lenses, the camera sensor, there's also a computer

21:53.440 --> 22:00.320
onboard microprocessor that's processing the images on inside the camera and underwater

22:00.320 --> 22:01.320
camera.

22:01.320 --> 22:08.200
So we're doing all of that compute there and then it attaches to whatever switch or power

22:08.200 --> 22:12.320
it has and then, and then they can see all the information coming off the camera.

22:12.320 --> 22:13.320
Got it.

22:13.320 --> 22:17.240
And for one of these typical pens, how many cameras are located there?

22:17.240 --> 22:19.800
It's a single camera that navigates around the pen.

22:19.800 --> 22:20.800
Okay.

22:20.800 --> 22:28.040
And navigates like around the edges or like some kind of autonomous thing or a Roomba fish

22:28.040 --> 22:29.040
counter camera.

22:29.040 --> 22:36.280
So it could be typically, so the cameras and fish pens are not new things.

22:36.280 --> 22:41.440
They actually already have them for monitoring feeding of the fish.

22:41.440 --> 22:45.080
So they typically have cameras on winches.

22:45.080 --> 22:49.720
So they're essentially on rope and police systems that they, they move throughout the pen.

22:49.720 --> 22:50.720
Okay.

22:50.720 --> 22:51.720
So it is moving.

22:51.720 --> 22:56.880
And then how you want to sample that is, is a more complicated question, but could

22:56.880 --> 22:58.880
be autonomous if the farmer wants that.

22:58.880 --> 23:03.160
But a lot of times the farmer doesn't want like autonomous moving thing.

23:03.160 --> 23:09.160
They want to be able to like, because it becomes a liability if it can like move in and

23:09.160 --> 23:11.440
hit things or whatever.

23:11.440 --> 23:18.400
So you mentioned some of the other use cases beyond the weight.

23:18.400 --> 23:20.400
One of them being counting sea lice.

23:20.400 --> 23:22.200
What's that one about?

23:22.200 --> 23:28.680
So sea lice is this parasite, it's a naturally occurring parasite that attaches to the fish.

23:28.680 --> 23:31.920
It weakens in the immune system and eventually kills the fish.

23:31.920 --> 23:36.680
In Norway, for example, it's about 25% of the costs of running the farm.

23:36.680 --> 23:42.680
Now these farms, they need to count sea lice as a part of the legally running a farm.

23:42.680 --> 23:48.560
Because essentially their version of the FDA nor requires them to sample sea lice every

23:48.560 --> 23:51.080
week from all their pens.

23:51.080 --> 23:53.280
So the typical process is fairly tedious.

23:53.280 --> 23:57.600
So you've got to send someone out to the pen, they're netting some fish, then they

23:57.600 --> 24:01.640
anesthetize each fish and then count the sea lice by hand and they have to do this week

24:01.640 --> 24:03.400
over week over week.

24:03.400 --> 24:10.040
Now the idea, we can make this process a lot simpler for farmers with the same camera footage,

24:10.040 --> 24:15.840
be able to identify the sea lice on the fish and then be able to quantify this into a

24:15.840 --> 24:20.560
system that then the farmers could use to manage sea lice infestations.

24:20.560 --> 24:24.520
Now the cool thing is actually in Norway, we are the first company and I think so the

24:24.520 --> 24:30.640
only company where you can apply to have our technology as a replacement for manual counting.

24:30.640 --> 24:35.160
And this is saving the farmers a lot of effort in terms of being able to count the sea lice

24:35.160 --> 24:37.600
and get accurate counts.

24:37.600 --> 24:44.280
You mentioned that 25% of the cost of running the farm is dealing with this sea lice issue.

24:44.280 --> 24:49.320
Is that 25% does that come from the cost of doing the sampling and all that or is that

24:49.320 --> 24:52.360
25% of your fish die will cause of sea lice?

24:52.360 --> 24:55.160
Oh, well, it's a combination of mortality.

24:55.160 --> 25:01.040
So the fish die from the sea lice but also from the treatments to the fish.

25:01.040 --> 25:05.360
They treat the fish for sea lice and it's a very stressful process.

25:05.360 --> 25:11.560
Essentially, it's like a large washing machine that the fish need to go into to get rid

25:11.560 --> 25:13.000
of the sea lice.

25:13.000 --> 25:16.480
So this is a very stressful process, kills the fish.

25:16.480 --> 25:22.640
So the fish, when they're disease, well, they're just like weaker and they eat less and

25:22.640 --> 25:24.320
they're more susceptible.

25:24.320 --> 25:32.040
So it's a really challenging problem and it's mandated by law because if the infestations

25:32.040 --> 25:39.040
get too high, then they start to infect the wild fish and that's that that cannot happen.

25:39.040 --> 25:44.840
And so they need to keep the sea lice levels low and if the infestations increase, then

25:44.840 --> 25:48.840
they need to treat it, which is stressful, kills more fish and the treatments themselves

25:48.840 --> 25:50.320
are quite expensive.

25:50.320 --> 25:54.920
So overall, it's a very, very challenging thing to manage and especially because they

25:54.920 --> 25:58.600
don't actually know the true state of the infestation.

25:58.600 --> 26:02.840
So what the farmers are doing is because they have the more accurate numbers, they can

26:02.840 --> 26:08.920
then forecast infestation levels and then figure out the optimal time to treat the fish

26:08.920 --> 26:14.800
and ultimately reduce the number of treatments and improve the overall welfare of the fish.

26:14.800 --> 26:19.800
And are those models that you're developing and providing for the farmers or the farmers

26:19.800 --> 26:26.400
already have ways to project the intensity of infestations?

26:26.400 --> 26:30.760
They have rudimentary models but we're providing a lot more sophisticated models to them to

26:30.760 --> 26:34.280
be able to forecast the infestation patterns.

26:34.280 --> 26:35.280
Cool.

26:35.280 --> 26:47.440
Going back to the computer vision elements of this, how would you describe the general

26:47.440 --> 26:49.960
approach or models that you're using?

26:49.960 --> 26:56.880
And I'm curious about things like to what degree are you able to take off the shelf computer

26:56.880 --> 27:03.560
vision models, trained on things like image net for example and apply transfer learning

27:03.560 --> 27:10.560
or are you basically starting from scratch with known models or are you kind of inventing

27:10.560 --> 27:19.400
your own things like how complex are the models that you're fielding to solve these problems?

27:19.400 --> 27:26.120
We were able to transfer learn as you mentioned a pre-trained model and train it specifically

27:26.120 --> 27:28.200
to identify fish.

27:28.200 --> 27:35.680
And then you kind of want to go, so previous in the show you had mentioned, well, kind of

27:35.680 --> 27:39.560
what if the fish is in the wrong orientation or if it's super area, it's too dark and

27:39.560 --> 27:43.440
you want to start tuning your model to those nuances.

27:43.440 --> 27:51.040
And that's where when we detect the fish, if the detector has a low confidence, we can

27:51.040 --> 27:56.400
annotate those examples with low confidence to be able to improve the model.

27:56.400 --> 28:02.080
And so we have done annotation to be able to improve the model and the transfer learning

28:02.080 --> 28:07.040
techniques have worked well for us to be able to, for example, fish detection.

28:07.040 --> 28:10.400
Now that's a relatively simple model.

28:10.400 --> 28:13.280
Now let's talk about more complicated models.

28:13.280 --> 28:20.080
So for example, let's just say I want to detect the different points on a fish.

28:20.080 --> 28:27.960
And so first thing you might try is to be able to do a segmentation of the fish.

28:27.960 --> 28:33.160
So like you get an outline of the fish and then figure out a depth mapping of the fish

28:33.160 --> 28:38.440
so every single point what is the distance and then overlay that to get a 3D model.

28:38.440 --> 28:45.920
Now that works, but then you run into like more complicated problem in terms of fish orientation

28:45.920 --> 28:52.280
and you're only maybe seeing like half of the fish and then maybe it's hard to explain,

28:52.280 --> 28:57.080
but sometimes the fish is not clear and you're not getting a good mapping.

28:57.080 --> 29:03.880
And so it's then starting to do some filtering and and tuning of the model to make sure that

29:03.880 --> 29:07.120
it can work in all these different edge cases.

29:07.120 --> 29:18.400
I think another thing that has been an inspiration is let's just say that you want to look at different

29:18.400 --> 29:19.600
poses of the fish.

29:19.600 --> 29:26.040
So maybe the fish is straight, maybe it's curved and you can use those like pose estimation

29:26.040 --> 29:33.760
techniques to be able to determine the orientation of your fish and consequently use that to inform

29:33.760 --> 29:39.680
which type of fish you're accepting and what type of weight model to use.

29:39.680 --> 29:42.600
So it can get like fairly fairly complicated.

29:42.600 --> 29:51.560
I think the computer vision honestly is maybe like 5 to 10% of it.

29:51.560 --> 29:55.800
Like 90 to 95% of it is the type of data you're collecting.

29:55.800 --> 30:03.080
And so we made a massive investment in terms of establishing over half our team in Norway.

30:03.080 --> 30:08.640
And that's because you can't have a team of computer vision engineers, machine learning

30:08.640 --> 30:14.000
engineers in San Francisco just getting a clean data set like to train the model.

30:14.000 --> 30:18.920
A lot of it is like practically going at the farms, collecting the data, getting the

30:18.920 --> 30:26.000
right type of data and getting it annotated and that is just like the devils in the details

30:26.000 --> 30:31.120
about like actually getting and actually physically going out and do the work.

30:31.120 --> 30:34.560
And that is like 90, 95% of it.

30:34.560 --> 30:38.640
Once the data is in a good state, then it's relatively straight forward to train your

30:38.640 --> 30:39.640
model.

30:39.640 --> 30:42.400
And what's been your approach to annotation?

30:42.400 --> 30:48.720
Do you do that in-house or do you do something like a mechanical Turk or something in between

30:48.720 --> 30:54.360
where it's a little bit more curated to your particular use case?

30:54.360 --> 30:56.160
So it depends.

30:56.160 --> 30:58.720
Some of the annotations we do are more general.

30:58.720 --> 31:03.200
So identify the fish, that's not that specialized.

31:03.200 --> 31:08.160
Now when you're identifying a sea-lice and I want you to differentiate it into the eight

31:08.160 --> 31:14.880
different stages of sea-lice, which are millimeters in size, well that requires some special marine

31:14.880 --> 31:16.520
biology background.

31:16.520 --> 31:23.640
And so we work with marine biology, marine biologists in Norway to help us identify the sea

31:23.640 --> 31:31.200
ice, but for the simpler stuff like fish, we're able to outsource those annotations to services

31:31.200 --> 31:32.960
as he mentions.

31:32.960 --> 31:43.320
So you describe the key challenges being the type of data that you're able to produce.

31:43.320 --> 31:48.880
What's the nuance around type, or if there is one, is it, it sounds like it's not just

31:48.880 --> 31:54.560
the volume of data, there's the annotations, of course, and the quality of those annotations.

31:54.560 --> 32:00.560
Are there other aspects, qualitative aspects of the data collection that have been important

32:00.560 --> 32:04.600
to your ability to solve this problem?

32:04.600 --> 32:06.960
Or am I reading too much into that?

32:06.960 --> 32:15.120
I think, and it's like, it's all sorts of things that you wouldn't expect.

32:15.120 --> 32:21.360
It's like, for example, there's a bunch of metadata that's quite interesting.

32:21.360 --> 32:25.880
Like does the breed of the fish matter in terms of your weight model?

32:25.880 --> 32:30.680
Like maybe different breeds have different morphologies, have different weights.

32:30.680 --> 32:38.320
Does the type of environment and environmental conditions affect your model?

32:38.320 --> 32:44.840
There's a bunch of different other types of metadata and confounding factors that could

32:44.840 --> 32:46.800
affect your ultimate model.

32:46.800 --> 32:55.200
And so being able to test it in a wide variety of conditions is also a key part of solving

32:55.200 --> 32:56.720
the problem.

32:56.720 --> 33:03.840
And I think that is really the secret sauce in all of this is that we just like spent

33:03.840 --> 33:09.440
two years banging our heads against the wall in terms of trying out every single condition

33:09.440 --> 33:16.600
and drilling down into even the most minute factors to understand all the different variables

33:16.600 --> 33:22.320
that might affect the problem and investigating it because chances are, it's all, again,

33:22.320 --> 33:23.320
all the above.

33:23.320 --> 33:30.480
Yes, the breed affects the way the fish, the time of year affects the way of the fish,

33:30.480 --> 33:37.520
because well, the time of year affects the runoff to the oceans and the runoff affects

33:37.520 --> 33:43.880
the turbidity under water and the turbidity under water affects what size of the fish you

33:43.880 --> 33:45.880
can see and therefore it affects the weight.

33:45.880 --> 33:50.520
And it's things like that that you would have never imagined the cascading effects and

33:50.520 --> 33:58.040
to be able to investigate all those effects to figure out and again, this is not going

33:58.040 --> 34:02.680
to be figured out by a computer scientist, machine learning scientist in San Francisco.

34:02.680 --> 34:08.280
This is talking to tons of actual fish farmers in Norway and fish biologists who actually

34:08.280 --> 34:13.840
know this stuff and can say, oh, well, that's probably why the reason why the model is

34:13.840 --> 34:14.840
not working.

34:14.840 --> 34:19.640
And so that's the type of qualitative insight that's invaluable.

34:19.640 --> 34:27.120
How readily would you expect or have you seen the models that you've developed for the

34:27.120 --> 34:33.200
Norwegian fish farms to translate to a fish farm in Asia, for example?

34:33.200 --> 34:39.520
I think, well, I would say like, within a species, it's fairly transferable because the

34:39.520 --> 34:41.560
water's the water and the fish are fish.

34:41.560 --> 34:46.440
So actually, we we have our model that estimates for salmon.

34:46.440 --> 34:49.920
It actually just worked out of the box for trout.

34:49.920 --> 34:56.680
Now when you start going to Asia, Asia, they're growing fish and ponds and the ponds are

34:56.680 --> 35:00.040
well, they're muddy and you can't really see the fish that well.

35:00.040 --> 35:04.280
And so they're maybe optics is not the best solution.

35:04.280 --> 35:08.560
Maybe you want some type of acoustic device, but it's really more conditioned.

35:08.560 --> 35:14.160
It's really more dependent on the type of fish and the condition it's grown in.

35:14.160 --> 35:18.760
But if you're going just like from the same species, from one geography to the other,

35:18.760 --> 35:21.240
I don't think there's as much difference.

35:21.240 --> 35:27.920
Of the many different use cases that you've mentioned, you know, weight, health, hunger,

35:27.920 --> 35:30.640
we talked about, you know, sea likes, these are all the ones that we talked about and you

35:30.640 --> 35:32.760
suggested that there are others.

35:32.760 --> 35:38.120
And I'm wondering, you know, before we close out, are there others that are worth mentioning

35:38.120 --> 35:42.520
because they introduce different types of techniques or approaches that you've had to

35:42.520 --> 35:43.520
work with?

35:43.520 --> 35:44.520
Yes.

35:44.520 --> 35:50.040
So the holy grail of fish farming is a fully autonomous fish farm.

35:50.040 --> 35:52.040
I'll explain the reason why.

35:52.040 --> 35:58.520
So right now, the way fish farms are run is that you need people to go there.

35:58.520 --> 36:02.760
So that's why you look at most of the fish farms, they're along the coastline.

36:02.760 --> 36:08.200
They're in places like Norway, in places like Chile, where they have long coastline.

36:08.200 --> 36:14.760
Now just at a macro macro level, like the earth is 70% water, we only produce about 5%

36:14.760 --> 36:16.640
of the world's protein from the oceans.

36:16.640 --> 36:22.440
So there's a massive potential there, but it requires us to have fully autonomous fish

36:22.440 --> 36:27.320
farms that can be in the deep ocean or that can be on land and that requires a lot more

36:27.320 --> 36:28.800
automation.

36:28.800 --> 36:34.160
Now, the weight estimation, for the first time the farmer can understand the growth of

36:34.160 --> 36:37.800
the fish and use that to benchmark the feeding of the fish.

36:37.800 --> 36:41.800
Now feeding is about half of the cost of running a farm.

36:41.800 --> 36:48.680
If you can start to optimize the feeding, essentially by running lots of AB tests to be

36:48.680 --> 36:55.320
able to optimize the feeding and create an optimal feeding policy, that is the real holy

36:55.320 --> 36:57.240
grail of fish farming.

36:57.240 --> 37:02.000
Now the way you do that, there's biological models you can use for feeding.

37:02.000 --> 37:07.920
You can also think of other machine learning based model, for example, reinforcement based

37:07.920 --> 37:13.360
learning model, where you learn the policy that is the best for optimally feeding the

37:13.360 --> 37:14.360
fish.

37:14.360 --> 37:19.560
And I think that, for us, is like a really, really motivating factor and one of the really,

37:19.560 --> 37:23.560
really cool applications that's coming down the pipe line.

37:23.560 --> 37:24.560
Well, right.

37:24.560 --> 37:28.600
And thanks so much for taking the time to share with us what you're up to.

37:28.600 --> 37:29.600
Very cool stuff.

37:29.600 --> 37:30.600
Yeah.

37:30.600 --> 37:31.600
Thanks.

37:31.600 --> 37:34.000
It is great to chat about it as well.

37:34.000 --> 37:39.920
All right, everyone, that's our show for today.

37:39.920 --> 37:47.880
To follow along with our reinvent series, visit twimmelai.com slash reinvent 2019.

37:47.880 --> 37:52.040
Thanks once again to Capital One for their sponsorship of this series.

37:52.040 --> 37:57.840
Be sure to check out capital one dot com slash tech slash explore to learn more about their

37:57.840 --> 38:00.600
ML and AI research.

38:00.600 --> 38:03.520
Thanks so much for listening and catch you next time.

