WEBVTT

00:00.000 --> 00:13.120
Welcome to the Twimal AI Podcast.

00:13.120 --> 00:17.120
I'm your host Sam Charrington.

00:17.120 --> 00:26.600
Hey, what is up, good Twimal people?

00:26.600 --> 00:32.520
As many, if not most of us past the 100 day mark of shelter in place, work from home

00:32.520 --> 00:37.960
and other quarantine measures, I want to both extend to you my best wishes for your health

00:37.960 --> 00:43.160
and happiness and also to remind you to not let your guard down.

00:43.160 --> 00:49.200
COVID-19 is serious business and you don't want to get it or give it.

00:49.200 --> 00:54.400
Be sure to wear that mask when you'll be around other people, avoid indoor crowds and

00:54.400 --> 00:59.280
limit your exposure by minimizing the time and maximizing the distance when you're

00:59.280 --> 01:03.960
in contact with others.

01:03.960 --> 01:10.120
Before we jump into today's show from our CVPR series, I'd like to share a few quick details

01:10.120 --> 01:16.200
about the next great event in our continuing live discussion series.

01:16.200 --> 01:23.440
Join us on Wednesday, July 1st for the great machine learning language undubate as we explore

01:23.440 --> 01:29.480
the strengths, weaknesses and approaches of both popular and emerging programming languages

01:29.480 --> 01:31.400
for machine learning.

01:31.400 --> 01:38.400
We'll have great speakers representing Python, R, Swift, Closure, Scala, Julia and more.

01:38.400 --> 01:43.800
The session kicks off at 11 a.m. Pacific time on the first and you won't want to miss

01:43.800 --> 01:50.640
it, so head over to twimalai.com slash languages to get registered.

01:50.640 --> 01:56.000
At this point, I'd like to send a huge thank you to our friends at Qualcomm for their support

01:56.000 --> 02:01.400
of this podcast and their sponsorship of our CVPR series.

02:01.400 --> 02:07.760
Qualcomm AI research is dedicated to advancing AI to make its core capabilities, perception,

02:07.760 --> 02:11.920
reasoning and action ubiquitous across devices.

02:11.920 --> 02:16.200
Their work makes it possible for billions of users around the world to have AI enhanced

02:16.200 --> 02:20.600
experiences on Qualcomm technology's powered devices.

02:20.600 --> 02:26.440
To learn more about Qualcomm and what they're up to on the AI research front, visit twimalai.com

02:26.440 --> 02:29.160
slash Qualcomm.

02:29.160 --> 02:31.360
And now onto the show.

02:31.360 --> 02:33.200
All right, everyone.

02:33.200 --> 02:35.240
I am here with Pavan Taraga.

02:35.240 --> 02:41.720
Pavan is jointly appointed in the schools of electrical engineering and arts media and

02:41.720 --> 02:45.000
engineering at Arizona State University.

02:45.000 --> 02:47.520
Pavan, welcome to the Twimal AI podcast.

02:47.520 --> 02:48.520
Thank you, Sam.

02:48.520 --> 02:49.520
It's a pleasure and an honor to be here.

02:49.520 --> 02:50.520
Thank you.

02:50.520 --> 02:52.760
It's my pleasure to host you here.

02:52.760 --> 02:58.800
I'm looking forward to digging into your paper that will be presented at CVPR, revisiting

02:58.800 --> 03:02.040
invariance with geometry and deep learning.

03:02.040 --> 03:05.760
But before we do that, I'd love for you to share a little bit about your background and

03:05.760 --> 03:10.840
how you came to work in computer vision and ML sounds great.

03:10.840 --> 03:18.160
So my beginnings in this area started as, you know, as a senior in my undergraduate years.

03:18.160 --> 03:23.320
I was looking at problems like face recognition, face tracking from video, trying to do a senior

03:23.320 --> 03:25.280
design project really.

03:25.280 --> 03:31.040
And as I started digging more, this was in the early or, yeah, early 2000s.

03:31.040 --> 03:36.440
And it was a very exciting time to be in the field of computer vision, because the problem

03:36.440 --> 03:42.680
statement in those days would be presented as giving a computer the ability to see and

03:42.680 --> 03:46.640
that felt like, wow, that's a frontier topic, right?

03:46.640 --> 03:52.240
But I said, you know, looks like I'm sufficiently invested in this, looks like it intersects with

03:52.240 --> 03:57.040
things like neuroscience, perception that is interesting mathematics, that is interesting

03:57.040 --> 04:00.320
computing happening, very highly interdisciplinary.

04:00.320 --> 04:03.360
And it felt like there was much work to be done.

04:03.360 --> 04:09.640
So I decided to go to school in 2000, I mean, grad school in 2004 to the University of

04:09.640 --> 04:16.080
Maryland, studying with Professor Ramachalappa, who is a pioneer in this field and very well

04:16.080 --> 04:21.080
known for face recognition techniques and a lot of interesting things in vision at the

04:21.080 --> 04:22.080
time.

04:22.080 --> 04:28.000
And as I started my work in the lab, I brought in from just face recognition to other things

04:28.000 --> 04:34.240
like understanding video, understanding time series, understanding the role of light,

04:34.240 --> 04:40.000
you know, geometry, elimination, reflectance, all these physics based concepts and how

04:40.000 --> 04:46.160
the interface with pattern recognition methods or machine learning methods and as I went deeper

04:46.160 --> 04:52.280
and deeper into it, I felt like there was a big disconnect between the methods of physics

04:52.280 --> 04:58.520
of image formation and the methods that are used in machine learning, where it's just

04:58.520 --> 05:03.960
purely a driven and statistical techniques and I was trying to find some middle ground

05:03.960 --> 05:08.360
where I could inject physical knowledge into certain structures that could blend well

05:08.360 --> 05:13.080
with machine learning techniques and one thing led to another, I started getting interested

05:13.080 --> 05:19.520
in this area of mathematics called a Romanian geometry and then topology as a means to express

05:19.520 --> 05:23.440
these intuitions and these constraints from physics and interface them with machine learning

05:23.440 --> 05:25.640
in before deep learning.

05:25.640 --> 05:31.120
So that's the theme of my work over the past decade, which is try to understand basic phenomena

05:31.120 --> 05:38.120
whether it's, you know, images or video or human activity and in recent years, we've also

05:38.120 --> 05:43.160
brought in our investigation beyond computer vision to include things like wearable devices

05:43.160 --> 05:49.200
and physiological monitoring where the phenomenon under study is basic human movement and other

05:49.200 --> 05:56.080
things, try to understand it from first principles and try to express that knowledge in a way

05:56.080 --> 06:01.200
that constrains conditions machine learning, so that's the general intersection of topics

06:01.200 --> 06:02.200
I've been looking at.

06:02.200 --> 06:07.320
Okay, and I mentioned in introducing you that one of your appointments is with a school

06:07.320 --> 06:13.320
that has arts in the title, are you, you know, how does that come up in your work and

06:13.320 --> 06:14.320
research?

06:14.320 --> 06:20.280
So, particularly, you know, connected to that particular piece of that school.

06:20.280 --> 06:25.920
So that's a whole story by itself and I can go very organically about how it all began

06:25.920 --> 06:33.920
or I can go in hindsight, this is how it went organically, this is how it began, you

06:33.920 --> 06:40.160
know, our school was founded in 2009 and, you know, I graduated from grad school in 2009,

06:40.160 --> 06:46.000
but then that was 2009, very similar to 2020, Wall Street collapsing and getting loose.

06:46.000 --> 06:51.640
So I stayed back when I posed out for a couple years and when I went interviewing in 2011,

06:51.640 --> 06:56.840
this position opened up in this school under the title of Assistant Professor in Human

06:56.840 --> 07:03.640
Activity Analysis, it was very intriguing and I have been doing human activity analysis

07:03.640 --> 07:08.200
as far as, you know, understanding video-based gate analysis.

07:08.200 --> 07:13.880
Okay, so I'm like fitness trackers and quantified self and all that kind of stuff.

07:13.880 --> 07:18.160
Right, so this was a little before all that stuff happened in particular.

07:18.160 --> 07:23.000
And I came in and I visited and there was, there was a mind-boggling sense of interdisciplinary

07:23.000 --> 07:28.440
that I saw in the school people in music looking at stuff like that, right, accelerometers,

07:28.440 --> 07:31.560
variables, driving, interactive performance with it.

07:31.560 --> 07:36.440
There was a group doing a stroke rehabilitation where you attract human movement through

07:36.440 --> 07:40.560
motion capture and sonify the qualities of your movement.

07:40.560 --> 07:46.800
So smoothness or jerkiness would be converted to sound and you can hear yourself and that

07:46.800 --> 07:49.960
provided additional feedback for you to correct your movements.

07:49.960 --> 07:50.960
Oh wow.

07:50.960 --> 07:56.800
It was, yeah, it was a very mind-boggling experience and even now people find it very

07:56.800 --> 07:59.360
interviewing when I mentioned these things.

07:59.360 --> 08:05.600
So the human activity analysis component was a way for the school to address, you know,

08:05.600 --> 08:09.800
slightly more formal ways to think about human movement, whether it's sense from a camera,

08:09.800 --> 08:13.760
whether it's sense from a variable device, whether it's motion capture, try to come up

08:13.760 --> 08:19.080
with techniques to represent human movement and then do machine learning on it or feed

08:19.080 --> 08:20.360
into these other applications.

08:20.360 --> 08:25.480
And it seemed like I was the right fit at the time and I got a job and I've been here

08:25.480 --> 08:31.040
for eight years and it has led me into very interesting collaborations with media artists

08:31.040 --> 08:37.080
and health scientists who are interested in the intersection of computing, art and things

08:37.080 --> 08:38.280
like health promotion.

08:38.280 --> 08:41.120
So that's the other side.

08:41.120 --> 08:49.600
You mentioned that one of the big themes of your work is been integrating physical, physics

08:49.600 --> 08:53.400
space principles and computer vision.

08:53.400 --> 09:00.160
Can you maybe talk a little bit about that in the broader context of the computer vision

09:00.160 --> 09:01.160
landscape?

09:01.160 --> 09:05.600
We've talked about this quite a bit on the podcast and I kind of describe it as a pendulum

09:05.600 --> 09:09.760
that's kind of swung from physics-based models to statistical and kind of is settling

09:09.760 --> 09:10.760
somewhere in the middle now.

09:10.760 --> 09:14.680
But it sounds like you've been working at this for a while, I'm curious how you think

09:14.680 --> 09:15.680
of it.

09:15.680 --> 09:16.680
Yes.

09:16.680 --> 09:17.680
I mean, you're absolutely right.

09:17.680 --> 09:21.320
It's been a pendulum that keeps swinging and I don't think it settles anywhere.

09:21.320 --> 09:26.000
I mean, that's the interesting problem about computer vision.

09:26.000 --> 09:30.080
Every time someone thinks it settles, right?

09:30.080 --> 09:33.160
Everybody thinks it's settled now and then soon it ships.

09:33.160 --> 09:37.960
So I mean, yes, it's been going on and off this idea about, I mean, I'd like to think

09:37.960 --> 09:45.120
of it as model-based vision versus purely data-driven methods of thinking of vision.

09:45.120 --> 09:50.520
The way the pendulum swings in my opinion is not that the problems are changing.

09:50.520 --> 09:56.360
It's just the language that goes into talking about it and the tools that go into addressing

09:56.360 --> 09:57.360
it.

09:57.360 --> 10:02.240
Those keep shifting, but the problems have remained mostly the same and the problems

10:02.240 --> 10:05.080
are the following in my opinion.

10:05.080 --> 10:11.040
So vision is a very unique, some people think of it as an application of machine learning,

10:11.040 --> 10:13.920
which is a reductionistic way to think about it.

10:13.920 --> 10:18.040
Sure, everything is data and everything is fed into a model and outcomes of decision.

10:18.040 --> 10:25.120
But vision and any perceptual field of inquiry, that can include vision, sound, haptics,

10:25.120 --> 10:29.760
any of these things which have to do with perception, I feel are fundamentally different

10:29.760 --> 10:33.360
than any other application of data analysis.

10:33.360 --> 10:40.320
The way we perceive the world is not the way, let's say, back transactions are processed

10:40.320 --> 10:43.480
by a machine learning computer, machine learning technique.

10:43.480 --> 10:49.520
There is a huge amount of variability is the way I'd call it, that exhibits in the

10:49.520 --> 10:57.720
natural world, which is somehow either discarded or properly passed out by whatever is happening

10:57.720 --> 11:04.000
in our brains and the sources of variability are physics based to a large extent.

11:04.000 --> 11:07.400
The same picture under a different lighting condition looks different, the same picture

11:07.400 --> 11:11.920
under a different slightly changed viewpoint looks different.

11:11.920 --> 11:17.800
So that looking different part is what gives rise to statistical variability.

11:17.800 --> 11:22.160
The statistical ways of thinking are, well, let's just fill up the observation space

11:22.160 --> 11:26.520
with more data points and we'll figure out what the shape of the distribution is from

11:26.520 --> 11:34.120
data, which is okay in, as intense to infinity, I guess that's fine, but when data augmentation

11:34.120 --> 11:38.240
approaches and domain adaptation and that kind of thing, yeah, yeah.

11:38.240 --> 11:43.680
But under and not tend to infinity, if you only have a few data samples, you are better

11:43.680 --> 11:50.360
off trying to understand how the physics around you affects the observed imagery.

11:50.360 --> 11:53.760
And that's where I think the methods have shifted.

11:53.760 --> 11:58.720
So in the keynote that I have at CBPR, you know, at the workshop called differential geometry

11:58.720 --> 12:02.280
and computer vision, I go through some of these historical trends.

12:02.280 --> 12:06.840
And one of the core themes that brings it all together, the word that I use is called

12:06.840 --> 12:12.400
invariance, which is when you look around and try to classify objects, we are able to

12:12.400 --> 12:16.920
do this in a way that is invariant to a lot of nuisance variables.

12:16.920 --> 12:22.400
That is light, you know, shading viewpoint and all sorts of interesting effects that are

12:22.400 --> 12:23.800
hard to describe.

12:23.800 --> 12:28.040
When you say invariance, there's two ways to think about it.

12:28.040 --> 12:33.160
The physics-based ways to think about it are, let's say I am looking at this scene, I

12:33.160 --> 12:37.720
know everything about this scene, including its 3D geometry, including how the paint reflects

12:37.720 --> 12:41.480
off light, including the wavelengths in the incoming radiation.

12:41.480 --> 12:47.360
If I have full knowledge of all of this, then I can re-render a scene, let's say.

12:47.360 --> 12:53.560
I can, just like how it happens in graphics, I can create so many different versions of

12:53.560 --> 12:54.560
the same picture.

12:54.560 --> 12:58.960
If I had full knowledge of everything, simply through a forward rendering process and

12:58.960 --> 13:04.320
construct variability, the data-driven ways of thinking about it say if you don't have

13:04.320 --> 13:08.760
access to everything that you need to understand the phenomena, what is the minimal set, what

13:08.760 --> 13:13.240
is the minimal piece of information that is needed to get a job done.

13:13.240 --> 13:18.360
And that's the dichotomy in the physics-based ways of thinking and the statistical ways

13:18.360 --> 13:19.600
of thinking.

13:19.600 --> 13:27.520
So when you use this term, invariant is the invariant referring to, say we're talking

13:27.520 --> 13:31.120
about a scene with an object in it that might render differently in different lighting

13:31.120 --> 13:32.120
conditions, etc.

13:32.120 --> 13:38.840
Is the invariant that object that is definitively in the scene and then we've got all these

13:38.840 --> 13:44.400
other effects, or does the invariant refer to something else, maybe something more on

13:44.400 --> 13:47.360
the mathematical from a mathematical perspective?

13:47.360 --> 13:51.400
I mean, the word invariant, of course, will depend upon what the end task is.

13:51.400 --> 13:57.640
If it is object recognition, yes, something intrinsic to the object is the invariant.

13:57.640 --> 14:02.880
It is not always as simple as saying the invariant is the color of the object because that changes.

14:02.880 --> 14:08.200
It is often not same as saying the invariant is the edge map of the object or certain corners

14:08.200 --> 14:11.280
of the object because they go in and out of view.

14:11.280 --> 14:16.200
So there's not easy ways of describing what that invariant actually physically means.

14:16.200 --> 14:18.000
So it becomes mathematical at some level.

14:18.000 --> 14:21.520
There is no linguistic equivalent that I can come up with.

14:21.520 --> 14:26.720
But if you look at this rendering ways of thinking, if you can render this object that you

14:26.720 --> 14:30.960
are interested to recognize, in all possible wing conditions, all possible lighting conditions,

14:30.960 --> 14:36.920
and you have this huge set of pictures, that huge set of pictures could be called, you

14:36.920 --> 14:42.840
know, the word sometimes that gets used is equivalent class or sometimes they call it an

14:42.840 --> 14:43.840
orbit.

14:43.840 --> 14:49.720
So this object that you're trying to recognize manifests itself in all this different ways.

14:49.720 --> 14:52.960
If you have a handle on that set, you are in good shape.

14:52.960 --> 14:56.680
If you have a different object, and you place it in the same scene, and you render it in

14:56.680 --> 15:02.120
all these different variations, and you have its own different set, then the invariant

15:02.120 --> 15:09.840
that separates these two is some measure of difference between these two sets of pictures.

15:09.840 --> 15:14.800
And sometimes that set of pictures can have a nice structure, which can allow you to

15:14.800 --> 15:18.280
compute it in closed form, and sometimes not.

15:18.280 --> 15:24.720
So the way we have been trying to express, you know, sometimes illumination is complicated.

15:24.720 --> 15:31.280
And if in the most general case, we don't know how to describe this full set of pictures.

15:31.280 --> 15:36.880
And some simplifying assumptions, which is rooted in some old work from the 90s, Bell

15:36.880 --> 15:41.240
Humor and Krigman wrote a very famous paper, and they said, what is the set of all faces

15:41.240 --> 15:43.920
under any given illumination condition?

15:43.920 --> 15:46.640
And they made some simplifying assumptions of what a face is.

15:46.640 --> 15:51.160
I mean, if I ask you define a face, it's probably defined a face, right?

15:51.160 --> 15:52.160
So how do you even think?

15:52.160 --> 15:57.160
And this is why we've tended towards, you know, deep learning and statistic methods over

15:57.160 --> 16:00.360
the past few years, because we don't know how to define these things.

16:00.360 --> 16:02.320
So exactly.

16:02.320 --> 16:03.640
But here is what they found.

16:03.640 --> 16:08.760
They said, if you define it in some sub linguistic ways, let's say it's a convex object, and

16:08.760 --> 16:13.960
let's say it's an object which has reflectance defined by some lambershine properties, then

16:13.960 --> 16:16.400
you can actually write down what the set looks like.

16:16.400 --> 16:17.880
Now comes deep learning.

16:17.880 --> 16:20.880
It says, I can't define these things, give me data.

16:20.880 --> 16:23.040
And the more data you have, the better it is.

16:23.040 --> 16:24.920
But no one knows how much data is enough, right?

16:24.920 --> 16:30.000
I mean, the more is better is the answer, but how much is enough is never known.

16:30.000 --> 16:33.280
And we have been positioning ourselves at that intersection, where we still look.

16:33.280 --> 16:38.000
If I know that I'm looking at faces, I'm going to weaken the structure a little bit.

16:38.000 --> 16:43.840
I'm going to say that, yeah, these objects that we're looking at have some characterization

16:43.840 --> 16:48.080
under these assumptions of simplicity, but then comes deep learning, which allows me

16:48.080 --> 16:52.320
to fit those other degrees, which I'm not able to specify analytically.

16:52.320 --> 16:57.000
So we're trying to reduce the need for larger and larger training sets by restricting the

16:57.000 --> 17:01.760
deep net layer somehow that are motivated by the knowledge of that physics of image

17:01.760 --> 17:02.760
formation.

17:02.760 --> 17:10.600
Sure, we don't know how much data we need to get the full specification, but we're saying

17:10.600 --> 17:13.880
this will reduce the need for more and more data.

17:13.880 --> 17:18.640
And all things being the same with the same amount of training sets, the same complexity

17:18.640 --> 17:23.760
of the deep architecture, adding these constraints known from the physics of image formation

17:23.760 --> 17:25.720
improves performance.

17:25.720 --> 17:30.680
And it also stabilizes performance against degradation of inputs.

17:30.680 --> 17:34.600
You know, typically if you blur a picture, if you surrender a picture in slightly different

17:34.600 --> 17:38.760
ways, performance drops pretty dramatically, we are able to avoid that.

17:38.760 --> 17:40.320
It's a middle ground, I'd say.

17:40.320 --> 17:47.160
We are not being super specific about defining objects, nor are we saying more data is good.

17:47.160 --> 17:52.160
We are saying something in the middle that is we are trying to come up with some description

17:52.160 --> 17:57.160
of that equivalence class under simplifying assumptions and then let data fill in the

17:57.160 --> 17:58.160
rest.

17:58.160 --> 18:01.240
So that's the way we're trying to marry the two things.

18:01.240 --> 18:08.000
And is the result a mathematical analysis in closed form, or is it experimental results

18:08.000 --> 18:10.000
on data sets?

18:10.000 --> 18:11.000
It both.

18:11.000 --> 18:12.000
Okay.

18:12.000 --> 18:16.920
So, I mean, most of the things we do is we end up having constraints, which are closed

18:16.920 --> 18:19.320
for mathematical equations.

18:19.320 --> 18:23.720
Maybe one layer in the deep net is expected to be orthonormal because the physics of image

18:23.720 --> 18:28.680
formation says that certain variables under certain lighting conditions will have an

18:28.680 --> 18:29.680
orthonormal structure.

18:29.680 --> 18:33.760
Okay, that's the way we impose the constraint that certain layers might have an orthonormal

18:33.760 --> 18:35.640
constraint put in.

18:35.640 --> 18:40.760
But then the network itself has to be learned end to end with data sets.

18:40.760 --> 18:45.400
And the performance has to be validated empirically on data sets.

18:45.400 --> 18:49.920
One of the interesting things we found is this concept of orthonormality, which seems

18:49.920 --> 18:52.200
to have some very special power.

18:52.200 --> 18:55.560
What we're finding is whether, you know, think of it.

18:55.560 --> 19:02.360
So we played with this idea in a paper for BMVC last year, where we took some classic,

19:02.360 --> 19:06.520
you know, disentangling autoencoder kind of networks.

19:06.520 --> 19:13.760
And we had good reason to impose an orthonormality constraint on the latent blocks of these disentangling

19:13.760 --> 19:15.440
autoencoders.

19:15.440 --> 19:16.440
Why orthonormality?

19:16.440 --> 19:22.600
We had to write up a whole, you know, theory around we expect these factors to represent

19:22.600 --> 19:29.840
either movement or lighting conditions or deformations and under appropriate relaxations.

19:29.840 --> 19:34.840
They all become orthogonal to each other and they all have this spherical structures.

19:34.840 --> 19:40.000
So looking at all of this, it looks like orthonormality is a trade-off, which is coming close

19:40.000 --> 19:45.240
to what the physics is telling us to do and but also being sensitive to the idea that

19:45.240 --> 19:46.960
it has to be implemented easily.

19:46.960 --> 19:52.440
We don't want to over complicate things and we want our constraints to be differentiable.

19:52.440 --> 19:54.440
So it's a design process.

19:54.440 --> 19:58.800
So we threw in these orthonormality constraints on disentangling autoencoders and boom, the

19:58.800 --> 20:03.400
numbers of disentangling quality just went up quite significantly.

20:03.400 --> 20:07.000
And so in the case of an autoencoder or in the layer of a deep network, what does it

20:07.000 --> 20:11.280
mean to impose that kind of constraint?

20:11.280 --> 20:19.680
Is it architectural and does it mean that you're diverging from kind of your CNN, resonant

20:19.680 --> 20:24.800
kind of tried-and-true architectures or is it loss function based or something totally

20:24.800 --> 20:25.800
different?

20:25.800 --> 20:27.560
How do you impose those constraints?

20:27.560 --> 20:30.440
There's two or three ways in which it's happened.

20:30.440 --> 20:34.480
One is we stick with architectures as is, don't mess with architectures, but add-and-loss

20:34.480 --> 20:35.480
functions.

20:35.480 --> 20:41.560
That works when the constraints are actually expressable as a closed form equation like

20:41.560 --> 20:47.600
spherical losses or, you know, orthonormality, those can be written on as a closed form equation.

20:47.600 --> 20:51.640
Sometimes the constraints we arrive at do not have an equation, but they have what is

20:51.640 --> 20:54.040
called a manifold structure.

20:54.040 --> 20:59.000
And why manifolds arise is very closely related to invariance.

20:59.000 --> 21:03.960
Here is an example, you know, if I say, so the idea of invariance is this, right, I mean

21:03.960 --> 21:04.960
you have a feature space.

21:04.960 --> 21:07.040
Let's say the feature space is something.

21:07.040 --> 21:11.960
You have this feature space in Rn and it's more specific than something, so it's easier

21:11.960 --> 21:12.960
to follow.

21:12.960 --> 21:19.560
So, let's say it's the latent space of AlexNet, okay, some features from the latent

21:19.560 --> 21:24.760
space of AlexNet, which is embedded in Rn, right, so it's a vector in Rn.

21:24.760 --> 21:29.600
And then we come in and we say, look, I want to impose a slight equivalence here, which

21:29.600 --> 21:33.800
is if I rotate my picture, looks like the features are also changing somehow.

21:33.800 --> 21:38.200
I mean, the features are not always invariant to physical variables like this, right?

21:38.200 --> 21:42.600
But if you're able to say that this feature, this feature, this feature in Rn actually

21:42.600 --> 21:45.760
represent the same picture, just that they're rotated.

21:45.760 --> 21:52.200
We are trying to basically paste the features and thereby the underlying space into something

21:52.200 --> 21:55.840
else to express that concept of equivalence.

21:55.840 --> 22:01.240
And sometimes when that ways of expressing these equivalences is well defined, what happens

22:01.240 --> 22:06.200
is the space gets crumpled, you hope that the neural net learns to crumple the space

22:06.200 --> 22:07.200
all of its own.

22:07.200 --> 22:12.080
That is one of the overarching hopes in deep learning that as you go through the layers

22:12.080 --> 22:17.320
of deep learning, the deep learning is learning to squish and crumple the original feature space

22:17.320 --> 22:20.840
into interesting ways to get a job done.

22:20.840 --> 22:25.440
But what it's doing is it's not always getting the job done the right way because you never

22:25.440 --> 22:26.440
have enough data.

22:26.440 --> 22:30.800
But if I explicitly tell it that here is how rotation affects the features.

22:30.800 --> 22:34.680
And here is how you paste them together through whatever mathematics that's needed.

22:34.680 --> 22:39.360
Then we get some manifold structures, you know, this crumpling can sometimes be expressed

22:39.360 --> 22:41.120
as a manifold.

22:41.120 --> 22:46.680
If you want to say in the concept of, you know, in the paradigm of loss functions, how

22:46.680 --> 22:49.000
do you express a manifold as a loss function?

22:49.000 --> 22:50.960
Sometimes you cannot.

22:50.960 --> 22:58.480
What you can do instead is, you know, manifolds are basically crumpled spaces and they have

22:58.480 --> 23:04.480
ideas associated with them, which are analogous to how we think of maps.

23:04.480 --> 23:09.480
And you know, the earth itself is composed of the earth is a manifold, but then it's also

23:09.480 --> 23:10.480
a sphere approximately.

23:10.480 --> 23:16.320
So if you forget the idea that it's a sphere, but if it were a general weirdly shaped blob,

23:16.320 --> 23:22.320
you would represent it by a series of charts and you would explain how the charts connect.

23:22.320 --> 23:26.080
And that's the way you specify a manifold through things called charts.

23:26.080 --> 23:31.480
And charts are also sometimes, you know, they have a thing, which is similar, called tangent

23:31.480 --> 23:32.480
spaces.

23:32.480 --> 23:37.680
So you sort of flatten the manifold in local coordinate charts and you can express that

23:37.680 --> 23:40.920
tangent space as a vector space.

23:40.920 --> 23:45.760
So once in a while, we have run into these conditions where we have a constraint, which was

23:45.760 --> 23:50.520
expressed as a manifold, which could not be written down as an equation, but whose tangent

23:50.520 --> 23:52.280
space could be written down.

23:52.280 --> 23:58.360
So we were able to enforce conditions of that tangency and said, I want this layer in

23:58.360 --> 24:03.840
my deep net to represent coordinates of a manifold on a specific tangent space.

24:03.840 --> 24:07.120
And the mapping from that back to the manifold could be written down in closed form.

24:07.120 --> 24:08.120
So it depends.

24:08.120 --> 24:16.200
Let me see if I can upload this anywhere close to what you just said.

24:16.200 --> 24:20.360
The way I'm kind of hearing this is that you've got some problem, you know, say you've

24:20.360 --> 24:27.160
got some object and you apply some simple transformation to that object, maybe you rotate

24:27.160 --> 24:28.160
it.

24:28.160 --> 24:35.280
If you've got a deep neural network that is trying to detect that object, for example,

24:35.280 --> 24:42.160
you know, and you've trained it, there may be some feature space or some representation

24:42.160 --> 24:48.760
of that object in, you know, the different layers of the neural net in a oversimplified

24:48.760 --> 24:49.760
world.

24:49.760 --> 24:54.720
You'd kind of want there to be, you know, a relationship between the rotation of the

24:54.720 --> 24:59.280
object itself and the rotation of the features, like maybe you could apply some simple transformation

24:59.280 --> 25:04.160
of the features, but the world isn't, you know, networks aren't that simple.

25:04.160 --> 25:06.880
But it turns out there is a relationship between the features.

25:06.880 --> 25:11.040
It's just more like this crumbly manifold thing.

25:11.040 --> 25:17.360
And you found a way to, you know, express that using the mathematical language of these

25:17.360 --> 25:23.600
manifolds that allow you to detect the actual invariance of the object.

25:23.600 --> 25:25.600
That is very correct.

25:25.600 --> 25:32.560
Thank you for giving me those lines.

25:32.560 --> 25:39.080
The only disclaimer is we have been able to do this for a few common sources of physical

25:39.080 --> 25:40.080
variability.

25:40.080 --> 25:46.560
And that includes things like rotations of objects and deformations of moving parts in

25:46.560 --> 25:52.120
certain cases, lighting conditions under, you know, just to be very clear.

25:52.120 --> 25:55.560
We haven't been able to do this across the board for every possible thing.

25:55.560 --> 25:56.560
Right.

25:56.560 --> 25:57.560
Right.

25:57.560 --> 26:03.600
So simple, like, you know, maybe not three point studio lighting, but a simple, you know,

26:03.600 --> 26:05.800
radio rotation or something like that.

26:05.800 --> 26:10.040
But, you know, clearly there's lots of things you can do in the physical world that aren't

26:10.040 --> 26:12.840
amenable to that representation.

26:12.840 --> 26:13.840
Absolutely.

26:13.840 --> 26:14.840
Yes.

26:14.840 --> 26:15.840
Okay.

26:15.840 --> 26:22.520
And so one of the things that that comes to mind in thinking about this and in your work,

26:22.520 --> 26:30.520
you kind of fall back on or maybe ground yourself in, you know, what you call pragmatic

26:30.520 --> 26:35.160
choices of deep architectures, meaning kind of the popular stuff, the way we're doing

26:35.160 --> 26:37.120
things today.

26:37.120 --> 26:43.560
I think of like Jeff Hinton's capsule networks is trying to come at some of the same ideas

26:43.560 --> 26:49.360
or same problems, are you familiar with that work and you compare contrast?

26:49.360 --> 26:52.360
I mean, we've tracked that body of work also.

26:52.360 --> 26:58.440
Again, you know, he's with all due respect, ACM Turing about, you know, I can't do that

26:58.440 --> 27:03.040
easily, but it's an over complication.

27:03.040 --> 27:11.080
I mean, it's ignoring, it's ignoring so much, it's ignoring the basic laws of, you know,

27:11.080 --> 27:15.560
rotations are not that hard if you understand how to express rotations and we're taking

27:15.560 --> 27:21.080
out that invariances is doable without that level of combination.

27:21.080 --> 27:25.040
So I'm correct that you're trying to come at some of the same problems at least.

27:25.040 --> 27:26.040
Right.

27:26.040 --> 27:27.040
Okay.

27:27.040 --> 27:32.320
In, it may be the case that if that enterprise succeeds, if that capsule network enterprise

27:32.320 --> 27:41.040
succeeds, it may be a more general solution to everything, maybe, but if you want

27:41.040 --> 27:47.120
to be a bit specific about, you know, understood factors of variation, I feel that's an over complication

27:47.120 --> 27:52.120
and there are nicer ways to do that and I think we're able to do that in a better way.

27:52.120 --> 27:53.120
Yeah.

27:53.120 --> 28:00.720
So you've kind of, you've developed this approach and you mentioned that you've got some experimental

28:00.720 --> 28:01.720
results as well.

28:01.720 --> 28:07.200
Can you talk a little bit about how you frame the question experimentally and what you've

28:07.200 --> 28:08.200
seen?

28:08.200 --> 28:09.200
Sure.

28:09.200 --> 28:16.160
I mean, the way we frame it is we want to keep a few things fixed.

28:16.160 --> 28:20.680
And the way we keep a few things fixed is we say pick an architecture first and that

28:20.680 --> 28:21.680
can be allocated.

28:21.680 --> 28:25.960
It can be, you know, we're looking at things like dense net, point net, all those year

28:25.960 --> 28:30.360
architectures, which are known to work well for certain databases, keep the architecture

28:30.360 --> 28:35.800
more or less fixed, keep the training set more or less fixed.

28:35.800 --> 28:41.080
And the only thing that varies is, you know, don't play too much with new fancier data

28:41.080 --> 28:42.080
augmentation methods.

28:42.080 --> 28:48.240
The only thing we are doing is adding in constraints either in some latent variables or we're adding

28:48.240 --> 28:51.080
in certain augmented loss functions.

28:51.080 --> 28:57.040
So most of the additional thing that we're doing is a mathematical expression of some kind.

28:57.040 --> 28:59.720
And keeping in, otherwise there is, it's hard to compare.

28:59.720 --> 29:05.200
I mean, if you say, let me train it for more iterations, but not add a constraint, can

29:05.200 --> 29:06.480
you compare it?

29:06.480 --> 29:13.120
So keeping mostly the computational resources fixed, we're asking if this additional mathematical

29:13.120 --> 29:15.480
knowledge pushes on the low.

29:15.480 --> 29:16.840
And we've been finding that it does.

29:16.840 --> 29:21.520
We have done that for image classification, we've done that for, you know, disentangling

29:21.520 --> 29:25.000
networks, we've done that for time series problems recently.

29:25.000 --> 29:30.280
And some of our compelling results are indeed from time series modeling, where, you know,

29:30.280 --> 29:36.120
we applied this to human activity like ignition data sets with either stick figures or variable

29:36.120 --> 29:38.040
devices.

29:38.040 --> 29:42.560
And the kind of factor that we are trying to factor out in human movement is not light

29:42.560 --> 29:48.480
and shape and geometry, but it's time series variability issues, which is, you know, the

29:48.480 --> 29:53.520
same action when performed by the same person, but at a slightly different time will give

29:53.520 --> 29:57.240
rise to slightly different traces, because people have intrinsic variability and how

29:57.240 --> 29:58.480
they move.

29:58.480 --> 30:03.920
And oftentimes that variability gets expressed through some time warping kinds of relationships.

30:03.920 --> 30:09.680
What we've done is express the time warping property as a constraint, which can be forced

30:09.680 --> 30:14.240
by the network to be factored out in a latent variable, if we just throw in that constraint

30:14.240 --> 30:15.920
in the loss function.

30:15.920 --> 30:21.320
And we found that it improves numbers significantly, just like that without any additional training,

30:21.320 --> 30:24.640
without any additional, you know, data requirements.

30:24.640 --> 30:34.160
So the pictures, or what I think are the pictures of this, if I'm understanding the problem

30:34.160 --> 30:40.920
is along the lines of, you know, start from your seat in the living room, go to the refrigerator,

30:40.920 --> 30:46.080
grab a drink, you know, take off the cover and drop the cover in the trash can, and you've

30:46.080 --> 30:53.840
got this kind of two dimensional plot of the path that the person might take in doing

30:53.840 --> 30:55.440
all that.

30:55.440 --> 31:02.400
And your argument is that the path is an invariant, because the task is the same.

31:02.400 --> 31:08.520
It's, you know, do X and Y, and what you're trying to do is identify, well, what is the

31:08.520 --> 31:09.520
fundamental?

31:09.520 --> 31:16.640
So you said identifying the path, is it somehow in a data set with lots of these, you

31:16.640 --> 31:22.840
know, traces or paths identify which ones correspond to the same actions or.

31:22.840 --> 31:27.000
It's close, I mean, we haven't looked at paths in that way, but we've looked at traces

31:27.000 --> 31:31.520
of stick figures, you know, so you have like 50 joints being tracked and you have the full

31:31.520 --> 31:36.880
time series of 50 joints evolving in space and in three dimensions that comes from motion

31:36.880 --> 31:37.880
capture say.

31:37.880 --> 31:38.880
Okay.

31:38.880 --> 31:42.360
Yes, there are actions, not really unlike what you're saying, actions in a kitchen, actions

31:42.360 --> 31:46.920
in a room, actions in an office, picking up objects, placing them here and there.

31:46.920 --> 31:51.920
And the feature that is invariant, of course, is hard to linguistically describe, but one

31:51.920 --> 31:57.520
of the variables that gives rise to confusion is that people sometimes take longer to do

31:57.520 --> 31:58.520
the same thing.

31:58.520 --> 32:02.400
People sometimes are fast in certain phases of the movement, slow in certain phases of

32:02.400 --> 32:03.400
the movement.

32:03.400 --> 32:04.400
Right.

32:04.400 --> 32:09.400
Or there is asymmetry in the body, you know, the left, the left arm swings more than the

32:09.400 --> 32:10.400
right arm.

32:10.400 --> 32:14.400
You know, there's all these interesting sources of variability which are hard to and the

32:14.400 --> 32:18.960
only way deep learning will be robust to that is if you augmented with all these variables,

32:18.960 --> 32:21.600
all these sources of variation.

32:21.600 --> 32:26.320
The way we think of it is that the variability here is expressible as a warping of the

32:26.320 --> 32:30.720
time axis, whether it's short versus long or speeding up versus slowing down.

32:30.720 --> 32:36.400
Or if it's one side faster than the other side or the swings are smaller than the other,

32:36.400 --> 32:38.760
it's all a time warp.

32:38.760 --> 32:42.960
Sometimes it can be constant, sometimes it can be non-constant and it can be.

32:42.960 --> 32:45.240
So that brings up an interesting question.

32:45.240 --> 32:55.120
Do you assume in your work throughout a single source of invariance or do you also conceive

32:55.120 --> 32:57.320
of multiple sources of invariance?

32:57.320 --> 33:02.840
Like, you know, there's a time invariance, but there's also the left arm swing invariance

33:02.840 --> 33:03.840
factor.

33:03.840 --> 33:04.840
Yeah.

33:04.840 --> 33:06.840
I mean, that is the, I mean, we are headed in that direction.

33:06.840 --> 33:08.840
I mean, right now our investigations have been-

33:08.840 --> 33:09.840
That would be the answer.

33:09.840 --> 33:15.200
The goal is to be able to have almost like a linear combination of known invariance

33:15.200 --> 33:18.560
is that, you know, you can account for, but-

33:18.560 --> 33:19.560
Right.

33:19.560 --> 33:23.560
I mean, at this time we have been playing it very carefully that let's take this one source

33:23.560 --> 33:24.560
of variable.

33:24.560 --> 33:25.560
Let's see if that can be factored out.

33:25.560 --> 33:27.800
Let's see if we can get invaders to that.

33:27.800 --> 33:31.400
And we have had success in many different applications.

33:31.400 --> 33:36.680
It sounds like you're further saying though that in the case of at least this motion capture

33:36.680 --> 33:46.600
type of a data set that the- that maybe time becomes kind of a meta-invariance that can

33:46.600 --> 33:52.480
account for multiple physical characteristics, am I hearing that correctly in there?

33:52.480 --> 33:53.480
It can.

33:53.480 --> 33:57.360
It's- it's hard to write that out clearly, but it does.

33:57.360 --> 34:03.480
Like for instance, if you had like load bearing, you know, if you were carrying a heavy

34:03.480 --> 34:06.640
bag on your bag, it- it will have an interest

34:06.640 --> 34:12.520
ing effect on the time series of your joins, which is not that easy to explain, but it

34:12.520 --> 34:16.360
will sort of stretch out certain phases of your movement and shrink certain phases of

34:16.360 --> 34:17.360
your movement.

34:17.360 --> 34:18.360
It does.

34:18.360 --> 34:24.320
So, yeah, the stretchings and shrinkings of the time axis are the key to finding what that

34:24.320 --> 34:26.800
invariant is for the lack.

34:26.800 --> 34:32.280
And so are there well established benchmark data sets for these types of tasks?

34:32.280 --> 34:36.600
Are you rolling your own to explore these methods?

34:36.600 --> 34:39.560
You know, for motion capture, there are benchmark data sets.

34:39.560 --> 34:43.400
There are, you know, Microsoft has a- it used to have a RGBD data set.

34:43.400 --> 34:48.520
I mean, they go by the RGBD activity, sort of, you know, keywords.

34:48.520 --> 34:49.520
And there's a few out there.

34:49.520 --> 34:51.240
There's a few benchmark data sets out there.

34:51.240 --> 34:54.280
NTU has one, MSR is one.

34:54.280 --> 35:00.600
And sometimes even, you know, the video data sets like HMDB have stick figures available

35:00.600 --> 35:03.360
through other methods like PostNet, for instance.

35:03.360 --> 35:06.880
So yeah, there are well-established data sets that we experiment with.

35:06.880 --> 35:14.880
And is the task that's posed by these data sets one of predicting the action that the-

35:14.880 --> 35:15.880
Right.

35:15.880 --> 35:16.880
Okay.

35:16.880 --> 35:19.640
It's activity classification prediction by and large, right?

35:19.640 --> 35:20.640
Yeah.

35:20.640 --> 35:21.640
Okay.

35:21.640 --> 35:22.640
Okay.

35:22.640 --> 35:27.920
And so what's the kind of state of the art for that kind of activity detection and how

35:27.920 --> 35:30.040
does your method compare to it?

35:30.040 --> 35:35.400
So most of the time series in the deep learning world, most time series things are either a combination

35:35.400 --> 35:39.320
of 1D CNNs or, you know, LSTM models.

35:39.320 --> 35:44.360
So depending upon the data set, the way our process goes is we say, let's find the latest,

35:44.360 --> 35:49.360
you know, benchmarks and we'll improve on those through these mathematical techniques.

35:49.360 --> 35:56.640
So a recent paper we did in CVPR 2019 used LSTMs as the benchmark data, you know, the technique.

35:56.640 --> 36:02.960
And the data sets were NTU 3D data set and a few others like that motion capture.

36:02.960 --> 36:07.840
The tunable parameter in LSTMs is oftentimes the hidden layers, how many hidden units do

36:07.840 --> 36:08.840
you have?

36:08.840 --> 36:12.880
And of course, if you scroll through it, the numbers keep going better and better.

36:12.880 --> 36:15.440
The way we've done it is we kept things the same.

36:15.440 --> 36:21.000
We say, let's say it's 16 hidden units or 32 hidden units, keep that the same.

36:21.000 --> 36:25.400
The only thing we'll change is add in this additional module that either disentangles the

36:25.400 --> 36:29.800
time work function or adds in as a constraint and numbers always go out.

36:29.800 --> 36:36.160
So in the way we thought about it, if my number, if my memory is right, the NTU RGB data set

36:36.160 --> 36:43.280
had like, you know, 80% roughly accuracy with a very fancy LSTM with 200 hidden units

36:43.280 --> 36:44.920
and stuff like that.

36:44.920 --> 36:48.640
And we were able to improve it by four or five percentage points easy without any changes

36:48.640 --> 36:52.520
to anything, but just this additional constraint added in.

36:52.520 --> 36:57.720
So if you find you need more, sure, there's more things to be squeezed out, but we were

36:57.720 --> 37:01.720
able to consistently improve the performance of LSTMs by easy five percentage points

37:01.720 --> 37:06.840
and times six, eight percentage points with no change, but a simple constraint on time

37:06.840 --> 37:07.840
warping.

37:07.840 --> 37:13.560
Yeah, so those are the kinds of results we've been finding, which is if you rethink what

37:13.560 --> 37:19.200
the constraints should be through understanding the phenomena first, the payoffs are actually

37:19.200 --> 37:24.000
quite significant without any additional requirements on data or network, architecture,

37:24.000 --> 37:28.040
complexity or training strategies, they can all be very basic.

37:28.040 --> 37:32.080
And so now we've talked about a couple of, you know, very different types of problems

37:32.080 --> 37:40.040
one, kind of a, you know, computer, a very visual type of task in one of this more time

37:40.040 --> 37:46.440
series to apply this to different settings, how much hand crafting needs to go into the

37:46.440 --> 37:53.000
loss functions and the, you know, the different constraints that you're applying to the network.

37:53.000 --> 37:55.000
That is where the big work is.

37:55.000 --> 38:02.400
So I think the pendulum is swinging to that level of hand crafting, you know, moving away

38:02.400 --> 38:07.200
from features to architectures and loss functions, right, that's where the pendulum is.

38:07.200 --> 38:14.160
And the amount of work that goes into hand crafting is a lot of, I would say, studying

38:14.160 --> 38:21.640
basically, understanding how these variables actually affect the observed data and try

38:21.640 --> 38:25.760
to express it in a way that is emanabled to fusion with the deep net.

38:25.760 --> 38:30.640
The beauty is physics is not one way, you know, light is, there is no single model for

38:30.640 --> 38:35.440
expressing how light and surfaces interact, there's layers and layers and layers to it.

38:35.440 --> 38:40.640
And you have to know all of that or at least as much as you know, as much as you can learn.

38:40.640 --> 38:46.840
And then the hand crafting is where in this spectrum of sophistication do I stop in a way

38:46.840 --> 38:54.080
that I actually have a pragmatic effect on performance without changing anything else.

38:54.080 --> 38:57.680
And that's where a lot of intuition is, you know, you cannot get away from this intuitive

38:57.680 --> 38:58.680
exercise.

38:58.680 --> 39:04.280
Despite all the progress of machine learning and deep learning, the networks are arguably

39:04.280 --> 39:06.040
both intuitive and highly unintuitive.

39:06.040 --> 39:10.480
I mean, some people have an insight about why a network works, but present it to someone

39:10.480 --> 39:12.400
else, it's mysterious.

39:12.400 --> 39:16.640
And the same thing is true of the last functions business.

39:16.640 --> 39:21.280
Sometimes we can motivate it very easily through simple things like, well, yeah, cross entropy

39:21.280 --> 39:25.080
means where it makes sense.

39:25.080 --> 39:29.520
Physics is where some of the unintuitive stuff lies.

39:29.520 --> 39:34.120
It's, that's where a lot of design thinking exists and we are doing that.

39:34.120 --> 39:40.960
So yes, that's where much of the work is understanding that when you approach the N plus 1th problem

39:40.960 --> 39:46.760
that's different from the ones that you've looked at previously that you're starting

39:46.760 --> 39:53.840
from scratch, or are there some principles that give you a foothold when trying to apply

39:53.840 --> 39:56.120
this method to the new area?

39:56.120 --> 39:58.240
And if so, what are those principles?

39:58.240 --> 40:02.160
The details, of course, have to be looked at from scratch, but the principles that we've

40:02.160 --> 40:08.080
bring to the table are ideas of geometry and, you know, this idea that look, whatever it

40:08.080 --> 40:12.640
is that you're observing, whatever it is, the raw space, that is not the space on which

40:12.640 --> 40:14.800
you want your analysis to occur.

40:14.800 --> 40:19.000
You want the analysis to occur in a space that is crumpled.

40:19.000 --> 40:24.480
And the generalizable knowledge that we bring to the table is how do we represent these

40:24.480 --> 40:26.280
crumpled spaces?

40:26.280 --> 40:30.400
And that's the mathematics of humanian geometry and topology, group theory.

40:30.400 --> 40:32.040
Those are all the new mathematics.

40:32.040 --> 40:33.400
It's not new mathematics at all.

40:33.400 --> 40:38.400
It's mathematics of the past two centuries, but in the realm of machine learning, that

40:38.400 --> 40:43.240
mathematics has not made its way in a systematic way.

40:43.240 --> 40:44.720
So that's the generalizable knowledge.

40:44.720 --> 40:48.000
We bring in group theory, geometry, differential geometry, topology.

40:48.000 --> 40:49.560
That's the way we think about it.

40:49.560 --> 40:55.080
But then the specifics, the problem specifics have to be studied from scratch, but then

40:55.080 --> 41:00.200
that knowledge can often be expressed in the constraints of geometry, anthropology, and

41:00.200 --> 41:01.360
group theory.

41:01.360 --> 41:02.520
And that's where we specialize.

41:02.520 --> 41:07.520
How do we take this domain specific knowledge and look at it through the lens of groups and

41:07.520 --> 41:08.520
invariance?

41:08.520 --> 41:12.000
And that's a different kind of generalizable knowledge.

41:12.000 --> 41:18.880
It's really a way of thinking about phenomena rather than thinking about data.

41:18.880 --> 41:28.760
Going back to your keynote, you kind of take a step back and apply this broadly to computer

41:28.760 --> 41:34.120
vision, machine learning, and do you kind of offer any thoughts for where this is all

41:34.120 --> 41:36.120
going?

41:36.120 --> 41:37.120
Not.

41:37.120 --> 41:38.120
Let's make some up.

41:38.120 --> 41:42.920
This is all going, pop in.

41:42.920 --> 41:47.440
So data constraints and scenarios, that's where this is all going.

41:47.440 --> 41:52.200
Machine learning with unconstrained amounts of training data is what the last 10 years

41:52.200 --> 41:53.400
were about.

41:53.400 --> 42:00.160
And we're finding that it's a nice goal, but there are no guarantees to be ever had, even

42:00.160 --> 42:04.320
if you train it forever with as much amount of data that you've got.

42:04.320 --> 42:09.800
If any mission critical deployment requires a guaranteed robustness of some kind, there

42:09.800 --> 42:14.880
is nothing to be given other than, yeah, this is what my numbers are on some data set.

42:14.880 --> 42:15.880
That's all you have.

42:15.880 --> 42:20.160
And now, if I can just hit pause there, you throughout our conversation, you've talked

42:20.160 --> 42:26.920
about constraints, you've talked about constraints on the network and you've talked about constraints

42:26.920 --> 42:33.000
on loss functions, you've talked about constraints on, you know, architectures and not changing

42:33.000 --> 42:34.000
architectures.

42:34.000 --> 42:38.080
And, you know, those have implications on compute constraints and that you haven't really

42:38.080 --> 42:41.240
explicitly talked about constraints on data.

42:41.240 --> 42:44.520
How does that fit into all these other stuff we've talked about?

42:44.520 --> 42:50.560
So I mean, the way I think about it is, if you don't have access to additional data,

42:50.560 --> 42:55.360
you get more bang for your buck by adding these additional constraints that we were talking

42:55.360 --> 42:56.440
about.

42:56.440 --> 43:00.840
If you have access to more data and you can collect as much as you want, you always should,

43:00.840 --> 43:06.840
I mean, that's, I didn't know about, but it's becoming more and more clear that that's

43:06.840 --> 43:09.880
not where the future is headed.

43:09.880 --> 43:14.280
We are not able to keep training bigger and bigger, you know, it's an unsustainable path.

43:14.280 --> 43:18.440
I mean, there is enough energy going in that direction anyway, whether or not we like

43:18.440 --> 43:19.840
it or I like it.

43:19.840 --> 43:22.160
But it's not a sustainable path of progress.

43:22.160 --> 43:27.280
It's smaller and smaller, you know, diminishing returns, but I have an increasing resources.

43:27.280 --> 43:34.560
So that's clear on the margins, but is part of your work trying to get at one shot, few

43:34.560 --> 43:39.440
shot types of problems or no?

43:39.440 --> 43:42.360
We are, I mean, that would be an extreme case.

43:42.360 --> 43:48.600
But yes, I mean, we are thinking more along the lines of, if I had to collect more data,

43:48.600 --> 43:56.600
can I first pause before collecting any more data and robustify what I've got with domain

43:56.600 --> 43:57.600
knowledge?

43:57.600 --> 44:00.080
That's the way I think about it.

44:00.080 --> 44:02.600
One shot and few shot, it's a whole different ball game.

44:02.600 --> 44:08.040
I mean, it's like the wide west of, you know, machine learning and I wouldn't go that

44:08.040 --> 44:09.040
far yet.

44:09.040 --> 44:14.880
Will it be applicable? I mean, sure, I don't see why not, but I wouldn't make big claims

44:14.880 --> 44:21.200
of getting one shot performance, but it should definitely help if not, you know, make it

44:21.200 --> 44:24.080
more amenable to, you know, less training sets.

44:24.080 --> 44:25.080
Yeah.

44:25.080 --> 44:26.080
Okay.

44:26.080 --> 44:30.520
So I interrupt that you were talking about essentially that the data collection is always

44:30.520 --> 44:36.280
going to be expensive and, you know, thinking about the problem space can provide, provide

44:36.280 --> 44:37.280
these benefits.

44:37.280 --> 44:39.960
I mean, unfortunately, human in the loop can't go away.

44:39.960 --> 44:42.800
I mean, there is neural architecture search.

44:42.800 --> 44:44.960
Yes, I mean, again, will this succeed?

44:44.960 --> 44:49.240
They will succeed at developing some representations that get a job done.

44:49.240 --> 44:53.440
And when you layer in questions of interpretation, explanation, which everybody is talking about,

44:53.440 --> 44:58.720
I have a much simpler take on it, which is if you don't have robustness to even simple

44:58.720 --> 45:01.640
physical variables, how will you even explain it?

45:01.640 --> 45:06.280
I mean, if your classification shifts simply because I rotate a picture and you're asking

45:06.280 --> 45:09.640
me to explain it, I think you're asking the wrong question.

45:09.640 --> 45:16.360
If you're at least asking me, can you be first be robust slash invariant to simple things

45:16.360 --> 45:20.880
and then explain it to me, that's a more well-posed question, but these are premature questions

45:20.880 --> 45:22.200
to ask.

45:22.200 --> 45:27.840
And some colleagues of mine have gone so far to say repeatability if your machine learning

45:27.840 --> 45:29.280
technique is not repeatable.

45:29.280 --> 45:33.280
And by that, things like this, yeah, if I click this picture at a slightly different time

45:33.280 --> 45:38.480
of day, nothing's really changed except the time of day and the decision has flipped, the

45:38.480 --> 45:40.280
process is not even repeatable.

45:40.280 --> 45:46.560
So don't even go to the extent of explaining a non-repeatable process or trying to interpret

45:46.560 --> 45:48.040
a non-repeatable process.

45:48.040 --> 45:50.800
Those are all questions that should come later.

45:50.800 --> 45:56.080
So if you think of repeatability, you do an experiment, you get the same result over

45:56.080 --> 46:02.400
and over again, as far as the big things are controlled, machine learning hasn't yet

46:02.400 --> 46:05.560
delivered that even.

46:05.560 --> 46:12.080
So we're trying to bring in that level of robustness, I call it robustness slash invariance.

46:12.080 --> 46:16.840
Some people have called it repeatability, simple and repeatability sounds shinier and

46:16.840 --> 46:22.000
it sounds like the stakes are much higher, but I'm happy to just call it invariance.

46:22.000 --> 46:27.880
Well, Paven, thanks so much for taking the time to share what you're up to and provide

46:27.880 --> 46:32.520
us some context for your CVPR keynote, very cool stuff.

46:32.520 --> 46:37.880
Thank you so much Sam, this has been a pleasure and you've been great, thank you so much.

46:37.880 --> 46:43.960
All right, everyone, that's our show for today.

46:43.960 --> 46:49.760
For more information on today's show, visit twomolai.com slash shows.

46:49.760 --> 47:06.840
As always, thanks so much for listening and catch you next time.

