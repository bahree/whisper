1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:31,040
I'm your host Sam Charrington.

4
00:00:31,040 --> 00:00:35,380
If you're listening to this podcast, you probably have an opinion about AI and where it's

5
00:00:35,380 --> 00:00:36,380
headed.

6
00:00:36,380 --> 00:00:42,200
I personally think AI will make a huge difference in how we approach both our work and personal

7
00:00:42,200 --> 00:00:48,400
lives, but as of today, the biggest impacts for me are in the little things.

8
00:00:48,400 --> 00:00:52,800
But enough of what I think, I want to invite you to join the conversation.

9
00:00:52,800 --> 00:00:58,520
Jump on over to Twimbleai.com slash MyAI to let us know what you think about where personal

10
00:00:58,520 --> 00:01:01,000
and home AI is headed.

11
00:01:01,000 --> 00:01:07,560
Sharing your thoughts takes just two minutes and qualifies you to win some great prizes.

12
00:01:07,560 --> 00:01:13,080
In this episode, I'm joined by Charles Onu, PhD student at McGill University in Montreal

13
00:01:13,080 --> 00:01:19,640
and founder of Benoit, a startup tackling the problem of infant mortality due to asphyxia.

14
00:01:19,640 --> 00:01:24,040
Using SVMs and other techniques from the field of automatic speech recognition, Charles

15
00:01:24,040 --> 00:01:28,960
and his team have built a model that detects asphyxia based on the audible noises a child

16
00:01:28,960 --> 00:01:30,960
makes upon birth.

17
00:01:30,960 --> 00:01:35,600
We go into the process he uses to collect his training data, including the specific methods

18
00:01:35,600 --> 00:01:40,240
they use to record samples and how their samples will be used to maximize accuracy in

19
00:01:40,240 --> 00:01:41,920
the field.

20
00:01:41,920 --> 00:01:47,120
We also take a deep dive into some of the challenges of building and deploying who Ben was platform

21
00:01:47,120 --> 00:01:49,280
and mobile application.

22
00:01:49,280 --> 00:01:53,120
This is a really interesting use case, which I'm sure you'll enjoy.

23
00:01:53,120 --> 00:01:54,120
Let's go.

24
00:01:54,120 --> 00:01:59,960
Alright everyone, I am on the line with Charles Onu.

25
00:01:59,960 --> 00:02:03,400
Charles is a PhD student at McGill University.

26
00:02:03,400 --> 00:02:06,200
Charles, welcome to this weekend machine learning in AI.

27
00:02:06,200 --> 00:02:07,200
Thank you very much, Sam.

28
00:02:07,200 --> 00:02:08,560
I'm happy to be here.

29
00:02:08,560 --> 00:02:14,680
It's great to have you on the show. I had a chance to see your presentation on, I think

30
00:02:14,680 --> 00:02:20,920
the project was called the Benoit at the NIPS Black and AI workshop and it was very well

31
00:02:20,920 --> 00:02:21,920
done.

32
00:02:21,920 --> 00:02:23,920
Thank you.

33
00:02:23,920 --> 00:02:28,960
And I'm sure you'll tell us a lot more about that project, but before we do that, why

34
00:02:28,960 --> 00:02:34,040
don't you tell us how you got involved and interested in machine learning?

35
00:02:34,040 --> 00:02:39,400
Well, that story is very intertwined with the project, the Benoit that you just spoke

36
00:02:39,400 --> 00:02:40,400
about.

37
00:02:40,400 --> 00:02:41,400
All the better.

38
00:02:41,400 --> 00:02:48,440
Yeah, because indeed it was, it was, it might be to pursue that project that I got into

39
00:02:48,440 --> 00:02:54,520
machine learning and took a, I say, side roads from my original path.

40
00:02:54,520 --> 00:02:55,520
Okay.

41
00:02:55,520 --> 00:02:56,520
Yeah.

42
00:02:56,520 --> 00:03:02,960
So, so I had my undergrad education in electrical and computer engineering and when I finished

43
00:03:02,960 --> 00:03:05,880
my undergrad, I worked as a software engineer.

44
00:03:05,880 --> 00:03:13,640
I was doing that time that I was volunteering with an NGO called in Actus and then eventually

45
00:03:13,640 --> 00:03:18,280
co-founded one called Fisher Foundation with some colleagues in Nigeria.

46
00:03:18,280 --> 00:03:24,840
So I studied in Nigeria and that was when we, during our work in the local communities,

47
00:03:24,840 --> 00:03:30,520
we had projects across agriculture, health care and a number of other domains.

48
00:03:30,520 --> 00:03:36,840
And we came across the huge challenge of birth as fixed year, which is essentially when

49
00:03:36,840 --> 00:03:42,400
the baby does not breathe well right after birth and it was such a huge cause of infant

50
00:03:42,400 --> 00:03:49,280
mortality in our communities and but also in many parts of the world and particularly

51
00:03:49,280 --> 00:03:53,680
in developing regions or resource poor settings.

52
00:03:53,680 --> 00:03:59,440
So it was, you know, it was in a bid to see what causes this problem, how could we address

53
00:03:59,440 --> 00:04:00,440
it?

54
00:04:00,440 --> 00:04:06,200
I came across a research that, you know, first of all, detailed that one of the big reasons

55
00:04:06,200 --> 00:04:11,080
why as fixed year is causing such huge casualties in developing countries.

56
00:04:11,080 --> 00:04:16,000
So about one million babies die every year from as fixed year and another one million

57
00:04:16,000 --> 00:04:23,880
suffer severe lifelong disabilities like brain damage, intellectual disability, cerebral

58
00:04:23,880 --> 00:04:26,080
policy and so on.

59
00:04:26,080 --> 00:04:30,520
And one of the reasons why the causality was so high was because in most resource poor

60
00:04:30,520 --> 00:04:38,880
settings, the means for clinical diagnosis was too expensive, too resource intensive and

61
00:04:38,880 --> 00:04:40,640
was just not happening.

62
00:04:40,640 --> 00:04:41,640
Yeah.

63
00:04:41,640 --> 00:04:47,000
And so there was a need for something, a low cost way of being able to screen babies early

64
00:04:47,000 --> 00:04:51,280
enough for whether or not they are breathing well because when it's severe, it's easy

65
00:04:51,280 --> 00:04:55,960
to know, you know, the baby usually would not cry when it's not breathing at birth.

66
00:04:55,960 --> 00:05:01,240
But in many other cases, it's not as severe to cause baby not to cry, but it's there and

67
00:05:01,240 --> 00:05:05,320
it's causing damage to the brain of the oxygen starvation.

68
00:05:05,320 --> 00:05:10,960
And so the work we began to develop was based on clinical research done by doctors in the

69
00:05:10,960 --> 00:05:13,640
70s and 80s way back.

70
00:05:13,640 --> 00:05:18,880
And you know, they had looked at cries of infants suffering several pathologies and in particular

71
00:05:18,880 --> 00:05:23,160
as fixed year, they used their spectograms back in the days and we were able to notice

72
00:05:23,160 --> 00:05:28,760
that several perhaps characteristics of the cries, the fundamental frequencies and melodies

73
00:05:28,760 --> 00:05:34,720
and very important frequency components of the cries were different or in general in

74
00:05:34,720 --> 00:05:39,720
the population of babies that had some of these pathologies from those that, you know,

75
00:05:39,720 --> 00:05:42,520
were okay, but normal.

76
00:05:42,520 --> 00:05:48,120
And in particular, in the case of asphyxia, it's even more pronounced because breathing

77
00:05:48,120 --> 00:05:53,920
and speech are coordinated by the same region of the brain and within our vocal tract as

78
00:05:53,920 --> 00:05:59,920
well, the same set of organs are oscillating when a person is breathing and speaking.

79
00:05:59,920 --> 00:06:04,560
And so the connection is so intertwined that the baby is not breathing well, there is a

80
00:06:04,560 --> 00:06:07,280
manifestation in the frequency patterns in the scribe.

81
00:06:07,280 --> 00:06:11,600
And so it was upon, you know, I'm giving the long-winded story of how I came into a machine

82
00:06:11,600 --> 00:06:12,600
learning.

83
00:06:12,600 --> 00:06:19,440
And it was upon the story of this that I, I first of all, to head about pattern recognition

84
00:06:19,440 --> 00:06:20,960
as a discipline.

85
00:06:20,960 --> 00:06:21,960
Okay.

86
00:06:21,960 --> 00:06:27,000
And I began to study and take courses myself to learn more about it.

87
00:06:27,000 --> 00:06:33,640
And slowly began to, to, you know, to start what has become original as a project now.

88
00:06:33,640 --> 00:06:34,640
Yeah.

89
00:06:34,640 --> 00:06:35,640
Oh, wow.

90
00:06:35,640 --> 00:06:42,280
And you recently published a paper on this that won a Best Paper Award in the Machine

91
00:06:42,280 --> 00:06:45,000
Learning and Healthcare Workshop at Neps, is that right?

92
00:06:45,000 --> 00:06:46,000
Yes.

93
00:06:46,000 --> 00:06:47,000
That's right.

94
00:06:47,000 --> 00:06:48,000
Yes.

95
00:06:48,000 --> 00:06:52,360
Our paper won the Best Paper Award at Nips in 2015 Nips, actually.

96
00:06:52,360 --> 00:06:57,280
And at the last Nips, we published a new one, which was a follow-up to that paper in

97
00:06:57,280 --> 00:07:03,280
which we had moved from algorithm into an actual deployable device in the form of a smartphone

98
00:07:03,280 --> 00:07:04,280
application.

99
00:07:04,280 --> 00:07:05,280
Oh, okay.

100
00:07:05,280 --> 00:07:06,280
Okay.

101
00:07:06,280 --> 00:07:13,880
So maybe we can dive into that project, and you can tell us a little bit about, kind of

102
00:07:13,880 --> 00:07:16,840
a little, in a little bit more detail, how you approach it.

103
00:07:16,840 --> 00:07:24,480
You mentioned that the, the research came out of the 70s and 80s, is this the, the research

104
00:07:24,480 --> 00:07:28,680
that identified these fundamental relationships, or were you somehow able to borrow data from

105
00:07:28,680 --> 00:07:30,080
that research as well?

106
00:07:30,080 --> 00:07:31,080
Yeah.

107
00:07:31,080 --> 00:07:36,680
Well, the, this research, first of all, you know, told us that it was, there was something

108
00:07:36,680 --> 00:07:38,480
to be explored there.

109
00:07:38,480 --> 00:07:42,320
Because at the beginning, the last thing I would have thought of was to consider the infant

110
00:07:42,320 --> 00:07:46,360
cry as a useful signal for diagnostic too.

111
00:07:46,360 --> 00:07:51,960
And, and so it was really serendipitous, I'd say, to have stumbled upon one of these papers

112
00:07:51,960 --> 00:07:59,720
and to see that it was indeed a string of studies between the 70s and 80s, exploring the,

113
00:07:59,720 --> 00:08:03,560
the use of, you know, spectrograms to analyze the infant cries.

114
00:08:03,560 --> 00:08:08,000
And there was this winter afterwards in which nobody seemed to carry it about, you know,

115
00:08:08,000 --> 00:08:09,840
what infant cry could be used for.

116
00:08:09,840 --> 00:08:14,120
And my assumption was that, you know, at the time, there was no, there are no concrete

117
00:08:14,120 --> 00:08:20,040
methods for transferring this knowledge or this hypothesis into useful applications as

118
00:08:20,040 --> 00:08:25,440
we now have today with machine learning being so well developed as a field now.

119
00:08:25,440 --> 00:08:30,880
And several low cost technologies, like mobile phones, that was not conceivably at the time

120
00:08:30,880 --> 00:08:33,040
of the 70s.

121
00:08:33,040 --> 00:08:38,240
So my thoughts was, that was why some of the studies did not scale forward.

122
00:08:38,240 --> 00:08:43,640
You know, when you first came across this paper and got the idea that, you know, this might

123
00:08:43,640 --> 00:08:49,640
be applicable to this problem, you know, you mentioned that you started taking a bunch

124
00:08:49,640 --> 00:08:55,320
of courses, but what was some of the first, like, concrete things that you did to try

125
00:08:55,320 --> 00:08:59,440
to apply this knowledge that you came across?

126
00:08:59,440 --> 00:09:00,440
Yeah.

127
00:09:00,440 --> 00:09:06,480
Well, one of the, one of the first things I did was, you know, I had a doctor friend and

128
00:09:06,480 --> 00:09:08,680
we had long conversations about it.

129
00:09:08,680 --> 00:09:13,800
You know, I tried to understand physiology of the infant, of the infant breeding system

130
00:09:13,800 --> 00:09:14,800
from him.

131
00:09:14,800 --> 00:09:17,880
And, first of all, validated this was something worth pursuing.

132
00:09:17,880 --> 00:09:23,160
And we were together, you know, worked on the early part of the work that we eventually

133
00:09:23,160 --> 00:09:24,160
did.

134
00:09:24,160 --> 00:09:31,000
Well, the next challenge, too, was how do we find data to validate this hypothesis that

135
00:09:31,000 --> 00:09:35,400
infant cry holds information about the presence or not of asphyxia?

136
00:09:35,400 --> 00:09:36,400
Right.

137
00:09:36,400 --> 00:09:41,160
As you know, machine learning is based on the ability to use data and learn from it and

138
00:09:41,160 --> 00:09:44,320
be able to generalize from that going forward.

139
00:09:44,320 --> 00:09:50,520
But as you probably know as well, in medical space acquiring data is can be an extremely

140
00:09:50,520 --> 00:09:56,520
resource intensive process, what intensive time to get approval to interact with actual

141
00:09:56,520 --> 00:10:06,000
patients or time it takes to the amount of cost of funds it would require to conduct

142
00:10:06,000 --> 00:10:09,360
the whole study to acquire this data.

143
00:10:09,360 --> 00:10:13,960
And so one of the first things we thought was to find if someone had, by some chance, been

144
00:10:13,960 --> 00:10:19,880
collecting data of infants in the world, at the time, we only interested in say, we

145
00:10:19,880 --> 00:10:25,520
really thought we would find, you know, cries of babies that were normal.

146
00:10:25,520 --> 00:10:29,360
And if we were able to find that at least, we thought that would be a good point to begin

147
00:10:29,360 --> 00:10:33,720
to start modeling the inherent characteristics of cry.

148
00:10:33,720 --> 00:10:39,160
And to begin to phrase this as maybe an anomaly detection problem, where we have a good model

149
00:10:39,160 --> 00:10:48,480
of what a good cry should be, and we can say that any new example, any new sample,

150
00:10:48,480 --> 00:10:53,720
that doesn't fit this model, is likely an anomaly that has to be checked, you know, has

151
00:10:53,720 --> 00:10:59,360
to go for further verification and, you know, I'm referring to babies here.

152
00:10:59,360 --> 00:11:04,360
And that could be useful screening too that, you know, first responders could use to

153
00:11:04,360 --> 00:11:06,120
transfer babies for tertiary care.

154
00:11:06,120 --> 00:11:07,120
Right.

155
00:11:07,120 --> 00:11:11,120
So we saw we searched and eventually we came across the database that we used for our

156
00:11:11,120 --> 00:11:12,120
work.

157
00:11:12,120 --> 00:11:14,320
It's called the baby shilan to database.

158
00:11:14,320 --> 00:11:20,440
And it's collected across a set of specialist hospitals in Mexico.

159
00:11:20,440 --> 00:11:25,280
And this is a team of doctors who had been tracking several pathologies in babies.

160
00:11:25,280 --> 00:11:30,800
And they had collected the cries of babies in several states, from normal states like,

161
00:11:30,800 --> 00:11:38,160
from normal babies and in different states like hungry states, just a resting state, when

162
00:11:38,160 --> 00:11:44,280
receiving some measure of pain, through maybe blood sampling, and also they collected pathological

163
00:11:44,280 --> 00:11:49,240
states as well as fixier deafness and a number of other conditions.

164
00:11:49,240 --> 00:11:50,240
Okay.

165
00:11:50,240 --> 00:11:54,000
And so we reached out to them, you know, taught them about the work we were trying to

166
00:11:54,000 --> 00:11:55,000
do.

167
00:11:55,000 --> 00:11:58,840
And they gave us access to the subset of their data that had the normal baby's cries

168
00:11:58,840 --> 00:12:01,040
and the XPC database cries.

169
00:12:01,040 --> 00:12:02,040
Yeah.

170
00:12:02,040 --> 00:12:10,160
It was fairly small to set about 69 babies in total, but over a thousand or so recordings.

171
00:12:10,160 --> 00:12:15,600
And that was all we used to develop the, our first, our first work that I really showed

172
00:12:15,600 --> 00:12:21,960
that there was promising, was promising signal in the cry that we could use to develop it

173
00:12:21,960 --> 00:12:24,640
possibly it, it too for the agonies.

174
00:12:24,640 --> 00:12:25,640
Yeah.

175
00:12:25,640 --> 00:12:33,480
How did you use that data to develop a model, what kind of model did you end up pursuing

176
00:12:33,480 --> 00:12:35,640
and what was your general approach there?

177
00:12:35,640 --> 00:12:36,640
Yeah.

178
00:12:36,640 --> 00:12:37,640
Yeah.

179
00:12:37,640 --> 00:12:38,640
That's an interesting one.

180
00:12:38,640 --> 00:12:44,320
The primary subdomain of machine learning that we looked to was that of automatic speech

181
00:12:44,320 --> 00:12:45,320
recognition.

182
00:12:45,320 --> 00:12:53,200
As you can imagine, this is a very similar problem as well, whereas ASR is trying to take

183
00:12:53,200 --> 00:12:58,600
a speech and take a person's speech and understand what the person is saying.

184
00:12:58,600 --> 00:13:02,920
In this case, we're not trying to understand what the baby is saying, what the baby's body

185
00:13:02,920 --> 00:13:04,840
is communicating to us.

186
00:13:04,840 --> 00:13:09,080
And so you can think that the methods developed there will be useful.

187
00:13:09,080 --> 00:13:11,080
And so that was all we did.

188
00:13:11,080 --> 00:13:17,160
We adopted feature extraction methods like the use of male frequency, septal coefficients,

189
00:13:17,160 --> 00:13:18,160
MFCCs.

190
00:13:18,160 --> 00:13:26,560
So MFCCs are an extraction of key frequency components in the speech signal.

191
00:13:26,560 --> 00:13:31,720
And they've been used a lot in ASR because it's been, it's been easy, the methods of discrete

192
00:13:31,720 --> 00:13:37,360
Fourier transforms to extract these key components that really put society things that are not

193
00:13:37,360 --> 00:13:43,400
as relevant, you know, the artifacts of speech that are not as relevant and brings into

194
00:13:43,400 --> 00:13:46,200
the, for the most important component of it.

195
00:13:46,200 --> 00:13:47,200
Okay.

196
00:13:47,200 --> 00:13:53,120
And so MFCCs have used a lot in ASR and we used that for speech recognition and feature

197
00:13:53,120 --> 00:13:56,120
extraction path.

198
00:13:56,120 --> 00:13:59,840
And we use support vector machines at the classification phase and combine these with,

199
00:13:59,840 --> 00:14:04,440
you know, with non-linear kernels like the Gaussian kernels and so on.

200
00:14:04,440 --> 00:14:09,360
So that's made the core of our system in general.

201
00:14:09,360 --> 00:14:16,680
So you had the, you had these thousand recordings, you passed them through some pre-processing

202
00:14:16,680 --> 00:14:22,920
steps that basically broke them down into frequency components and those became your features

203
00:14:22,920 --> 00:14:24,520
for your SVM.

204
00:14:24,520 --> 00:14:28,320
Yes, exactly.

205
00:14:28,320 --> 00:14:34,400
And how, you know, beyond that initial kind of model, like, did you run into any challenges

206
00:14:34,400 --> 00:14:37,080
in, in doing that?

207
00:14:37,080 --> 00:14:41,160
So any challenges in building the classifier, you mean, from building the classifier,

208
00:14:41,160 --> 00:14:42,160
yes.

209
00:14:42,160 --> 00:14:43,160
Yeah.

210
00:14:43,160 --> 00:14:48,320
Well, the good thing was, you know, we've, we've had this data that had been collected.

211
00:14:48,320 --> 00:14:52,920
It had been, you know, someone had someone else had gone through all the work of getting

212
00:14:52,920 --> 00:14:58,600
a clinical approval for it to conduct this study, collected the data, you know, filtered

213
00:14:58,600 --> 00:15:06,120
the data, they had, you know, annotated it by labels, you know, which ones are the pathological

214
00:15:06,120 --> 00:15:08,840
samples and healthy samples and so on.

215
00:15:08,840 --> 00:15:13,920
So, so as you probably know, machine learning is a lot of work that goes into that early part

216
00:15:13,920 --> 00:15:18,800
which we were, fortunately, saved from the engagement.

217
00:15:18,800 --> 00:15:20,960
At least at that time.

218
00:15:20,960 --> 00:15:26,240
So, so we spend most of the time, you know, developing the classifiers and tuning and, you

219
00:15:26,240 --> 00:15:32,400
know, and searching the space of what's the best solution within this range of parameters

220
00:15:32,400 --> 00:15:36,520
between the MFCs extraction and the SVMs and hyperparameters.

221
00:15:36,520 --> 00:15:42,360
But, you know, ultimately, we are, we are now somewhat back to that first stage because

222
00:15:42,360 --> 00:15:48,000
we're able to use that data to show the promise of this approach, to show the, the feasibility

223
00:15:48,000 --> 00:15:49,880
of, of this method.

224
00:15:49,880 --> 00:15:55,920
So now we need to, one, validate it, you know, with data we collect ourselves, we need to,

225
00:15:55,920 --> 00:15:59,600
we need to get a larger data set to improve the performance.

226
00:15:59,600 --> 00:16:05,320
So, the performance of the system we have now is about 90% on specificity and sensitivity

227
00:16:05,320 --> 00:16:06,320
measures.

228
00:16:06,320 --> 00:16:12,640
That's in accuracy in detecting the babies, the expiated babies and that sensitivity

229
00:16:12,640 --> 00:16:16,760
and accuracy in detecting normal babies is our specificity.

230
00:16:16,760 --> 00:16:23,920
And so, you know, the goal is to try to, one, robustly validate this, this, this results

231
00:16:23,920 --> 00:16:29,880
we have using samples acquired from a different geographical location, different population.

232
00:16:29,880 --> 00:16:35,480
And hopefully acquired this more data to use it to improve the performance of the algorithm.

233
00:16:35,480 --> 00:16:41,560
And I'm beginning to develop into, into our software, very practical issues that would

234
00:16:41,560 --> 00:16:47,840
have to face in the real world, like making sure it's robust to noise, and because the samples

235
00:16:47,840 --> 00:16:55,160
were coded in very controlled environment without background noise, and just several optimizations

236
00:16:55,160 --> 00:16:59,880
by, you know, for instance, in the presence of overlapping signals, you know, several of

237
00:16:59,880 --> 00:17:05,920
these crying at one, can we separate them, the five one, can we optimize for the length

238
00:17:05,920 --> 00:17:13,400
of the audio signal that we require to make a useful, a valid diagnosis, and so on,

239
00:17:13,400 --> 00:17:15,840
and more of such things, we're looking at now.

240
00:17:15,840 --> 00:17:16,840
Okay.

241
00:17:16,840 --> 00:17:21,040
And now, one of the tools that will help you do all this is you were able to take the

242
00:17:21,040 --> 00:17:27,080
work that you did initially and then build a mobile app around this.

243
00:17:27,080 --> 00:17:31,440
Mel, tell us a little bit about that process and kind of what stage you are, you're in

244
00:17:31,440 --> 00:17:34,240
with deploying this mobile app.

245
00:17:34,240 --> 00:17:36,240
Yeah.

246
00:17:36,240 --> 00:17:39,720
So, you know, in terms of the development of mobile app, one of the challenges is that

247
00:17:39,720 --> 00:17:47,320
a lot of, a lot of machine learning has, you know, happens on Python and MATLAB, and

248
00:17:47,320 --> 00:17:52,600
what those are not the languages that are used in mobile development, right, in general.

249
00:17:52,600 --> 00:17:58,200
And so, you know, but they really help with experimentation and, and, you know, the fast

250
00:17:58,200 --> 00:18:03,000
tone of our design to take process, but thinking of deployment, you know, we had to start

251
00:18:03,000 --> 00:18:07,360
thinking about, first of all, we had to decide upon what was the best mobile platform

252
00:18:07,360 --> 00:18:12,240
for a place like Nigeria, where I lived when this, when we started this project.

253
00:18:12,240 --> 00:18:18,960
And Nigeria, Android phones are 90% or 95% of what people use.

254
00:18:18,960 --> 00:18:22,080
So that was our go-to platform to start with.

255
00:18:22,080 --> 00:18:27,840
Android at the time, at least, was 2014 and there about the main platform for development

256
00:18:27,840 --> 00:18:31,080
or the main language for Android development was Java.

257
00:18:31,080 --> 00:18:38,200
And now there's been C-shop portals to be done, I think Python, possibly now, yeah, but

258
00:18:38,200 --> 00:18:44,240
also the one of the big challenges too was transferring our code to Java and maintaining

259
00:18:44,240 --> 00:18:51,360
efficiency, maintaining performance as well, accuracy, and, you know, just all of that

260
00:18:51,360 --> 00:18:52,360
thing.

261
00:18:52,360 --> 00:18:53,360
So, it took quite a while.

262
00:18:53,360 --> 00:18:58,360
That was quite a bit of a few weeks or maybe months, we spent on, on just that part

263
00:18:58,360 --> 00:19:04,240
of the work, but we're able to do it ultimately and my colleague, Innocent, who is also a software

264
00:19:04,240 --> 00:19:05,240
engineer.

265
00:19:05,240 --> 00:19:10,560
We're able to completely move our code and maintain performance both in terms of time

266
00:19:10,560 --> 00:19:16,560
to diagnosis, we're able to maintain the original classification performance on the data

267
00:19:16,560 --> 00:19:19,960
set as well when we put it in the mobile application.

268
00:19:19,960 --> 00:19:23,560
So that was one challenge we had to face and it was good.

269
00:19:23,560 --> 00:19:28,920
And we also mentioned that we face this challenge too because we wanted to put the classification

270
00:19:28,920 --> 00:19:31,560
model on the device.

271
00:19:31,560 --> 00:19:36,240
We did not want it to require internet to do classification because if we are trying

272
00:19:36,240 --> 00:19:42,400
to deploy in some of the poorest parts of the world, in Nigeria that's also not so poor,

273
00:19:42,400 --> 00:19:48,280
the internet access is still very, very, very, very scanty in many places.

274
00:19:48,280 --> 00:19:54,000
And so if the device required internet to make it a diagnosis, then the purpose is halfway

275
00:19:54,000 --> 00:19:56,400
defeated already.

276
00:19:56,400 --> 00:20:02,800
And we could go there in the long run, but in the media term it was the most practical

277
00:20:02,800 --> 00:20:04,760
thing for our target groups.

278
00:20:04,760 --> 00:20:09,040
And so we went through that and we got it onto the mobile app.

279
00:20:09,040 --> 00:20:13,600
So where we are now is the questioner, so in terms of validating our mobile application

280
00:20:13,600 --> 00:20:20,240
and that's really love what's taking us, it's what takes out most of our time presently.

281
00:20:20,240 --> 00:20:26,520
So in Montreal, at the Maggi University Health Center, at the Children's Hospital here,

282
00:20:26,520 --> 00:20:32,560
we are doing the validation exercise in one year exercise with the doctors here.

283
00:20:32,560 --> 00:20:39,560
And the goal is to acquire more samples from babies who have experienced in different

284
00:20:39,560 --> 00:20:46,560
levels of species from mild to moderate to severe, acquire control samples of normal babies,

285
00:20:46,560 --> 00:20:53,680
and then to use a binwad to validate against, to classify the samples essentially.

286
00:20:53,680 --> 00:20:58,480
So these samples are going to be, the cry samples of these babies are going to be evaluated

287
00:20:58,480 --> 00:21:01,640
very clinical methods of diagnosis.

288
00:21:01,640 --> 00:21:07,040
So they have blood samples be taken to be analyzed with a blood gas analyzer and a doctor,

289
00:21:07,040 --> 00:21:12,720
especially doctor, would clinically determine what to label these babies as, and then

290
00:21:12,720 --> 00:21:18,840
validate these against the binwad and hopefully further develop the algorithm in that process.

291
00:21:18,840 --> 00:21:24,880
And the next stage after that would be to then take this to Nigeria and do field trials there.

292
00:21:24,880 --> 00:21:31,040
Our regional plan was to do this stage in Nigeria and it's still not a shutdown plan completely

293
00:21:31,040 --> 00:21:37,160
but we faced many challenges with that. Just because, whereas the whole clinical process

294
00:21:37,160 --> 00:21:42,280
I just explained of blood gas analysis and so to confirm the presence of our species,

295
00:21:42,280 --> 00:21:49,560
whereas it's a routine procedure in Montreal, in Canada, in Nigeria it doesn't happen,

296
00:21:49,560 --> 00:21:51,960
which is the root of this problem differently.

297
00:21:51,960 --> 00:21:52,960
Right.

298
00:21:52,960 --> 00:21:56,040
Equipments do not exist in any of the public hospitals there.

299
00:21:56,040 --> 00:22:00,040
There's no power, there's no electricity for the most part, so if we use it if it was

300
00:22:00,040 --> 00:22:08,520
there, there's a whole workflow and process requirements that should be in place or that

301
00:22:08,520 --> 00:22:11,720
would have to put in place if we were to try to do it there.

302
00:22:11,720 --> 00:22:18,160
And a lot of this would cause put time, money, effort and it would be a huge deviation

303
00:22:18,160 --> 00:22:22,720
from the ultimate or the precise focus of the project.

304
00:22:22,720 --> 00:22:26,600
And so after much thought from back, we decided that we'll do the first stage here and then

305
00:22:26,600 --> 00:22:31,680
move to do it, filter out in Nigeria with the doctors who work with there as well.

306
00:22:31,680 --> 00:22:39,160
And now it sounds like the samples you're collecting at McGill are, there's a high level

307
00:22:39,160 --> 00:22:44,280
of care clinically and evaluating the samples.

308
00:22:44,280 --> 00:22:54,760
Are you also collecting them with more professional equipment or are you trying to collect the

309
00:22:54,760 --> 00:22:59,080
samples via the mobile app so that you can kind of match the conditions that you'll be

310
00:22:59,080 --> 00:23:02,200
collecting them with in the field?

311
00:23:02,200 --> 00:23:07,960
Yeah, that was indeed a decision point for us, whether to use the mobile apps, the mobile

312
00:23:07,960 --> 00:23:13,080
phones themselves to apply it there or to use specialized or the recorders.

313
00:23:13,080 --> 00:23:16,240
And ultimately we went for special or the recorders just because of that.

314
00:23:16,240 --> 00:23:17,240
Oh really?

315
00:23:17,240 --> 00:23:18,240
Yeah, we did.

316
00:23:18,240 --> 00:23:24,440
We really want to maintain the one, the recording quality across the subjects, across the samples.

317
00:23:24,440 --> 00:23:33,320
We want to track things like sampling rates and just, you know, exclude some of the immediate

318
00:23:33,320 --> 00:23:39,440
let's say Mr. Lenners' functionalities are coming with a mobile phone.

319
00:23:39,440 --> 00:23:45,000
Also, you know, we've had some slight issues with the ethics before, I don't know if this

320
00:23:45,000 --> 00:23:50,560
probably lands on phone things I should not talk about as well, but yeah, there's also

321
00:23:50,560 --> 00:23:56,880
some ethics issues with using the phone right away for the acquisition and yeah, so we're

322
00:23:56,880 --> 00:24:02,000
going to be using digital audio recorders to pick these signals at this point.

323
00:24:02,000 --> 00:24:03,000
Okay.

324
00:24:03,000 --> 00:24:08,200
Yeah, I'll take your word on it if it's something you can't talk about, but you certainly

325
00:24:08,200 --> 00:24:09,200
pick my curiosity.

326
00:24:09,200 --> 00:24:16,080
I mean, I can imagine in the U.S. we have laws like HIPAA that require a certain level

327
00:24:16,080 --> 00:24:22,640
of standard of care with patient information, I imagine there's that kind of thing going

328
00:24:22,640 --> 00:24:23,640
on.

329
00:24:23,640 --> 00:24:27,280
Yeah, things on that line.

330
00:24:27,280 --> 00:24:28,280
Okay.

331
00:24:28,280 --> 00:24:32,800
Yeah, I mean, it's, it's, it can get complicated.

332
00:24:32,800 --> 00:24:38,680
You've got these samples that you're capturing with specialized audio equipment.

333
00:24:38,680 --> 00:24:44,920
How then do you address the issues that you mentioned previously, you know, kind of

334
00:24:44,920 --> 00:24:50,000
there, the transfer, transferability of those samples to the samples that are collected,

335
00:24:50,000 --> 00:24:53,920
you know, via your mobile device, so your background noises, you're overlapping, like

336
00:24:53,920 --> 00:25:01,880
are you, you recreating these situations after the fact or is that just reserved for a later

337
00:25:01,880 --> 00:25:04,000
stage of developing your model?

338
00:25:04,000 --> 00:25:09,760
Yeah, yeah, at the current stage, we are going to be working on those optimizations more

339
00:25:09,760 --> 00:25:15,200
in the research settings, so we're going to simulate what noise it looked like, okay.

340
00:25:15,200 --> 00:25:19,960
We could go out, you know, the sample, one way which we could do the case of the noises

341
00:25:19,960 --> 00:25:25,400
to record noise in record actual noise signals in the environment, we think the Apple

342
00:25:25,400 --> 00:25:31,000
be used and think that and use that noise to, I wanted to say noisy our samples further

343
00:25:31,000 --> 00:25:36,840
with a bit too much use of noise, but we use that to corrupt our samples essentially.

344
00:25:36,840 --> 00:25:40,080
And then, you know, work more from the research, so our research team is going to be working

345
00:25:40,080 --> 00:25:46,000
more on the research side of how can we improve the algorithm, making more robust noise.

346
00:25:46,000 --> 00:25:50,160
And I guess the more practical test of whatever we develop would happen when we are able

347
00:25:50,160 --> 00:25:56,200
to go through this phase of validation and begin to test on the fields in Nigerian, so

348
00:25:56,200 --> 00:26:01,600
we can put it down on the field and say, and test it in reality.

349
00:26:01,600 --> 00:26:07,040
How many samples are you expecting to collect in the current phase?

350
00:26:07,040 --> 00:26:14,320
Oh, you shouldn't have asked that, now I'm going to, now I'm going to disappoint you

351
00:26:14,320 --> 00:26:21,920
if you've heard about machine learning data, but we are collecting a total of 100 samples.

352
00:26:21,920 --> 00:26:24,640
Oh, wow, okay.

353
00:26:24,640 --> 00:26:30,560
You know, it's interesting because I was, I think perhaps the precursor to that question

354
00:26:30,560 --> 00:26:36,560
was, you know, thinking about, you know, whether this is something you would also evaluate

355
00:26:36,560 --> 00:26:41,520
like a deep learning type of approach, and I figured maybe one of the, you know, the

356
00:26:41,520 --> 00:26:47,000
limitations would be the number of available samples and needing a much more efficient

357
00:26:47,000 --> 00:26:48,000
model.

358
00:26:48,000 --> 00:26:50,000
Yes, yes, that's correct.

359
00:26:50,000 --> 00:26:55,000
I mean, first of all, getting medical data is really hard.

360
00:26:55,000 --> 00:27:02,200
I work on another study at McGill, in which we are also collecting cardio respiratory

361
00:27:02,200 --> 00:27:10,320
signals of newborns, and over a period of since 2014, it's taking us from then to 2017

362
00:27:10,320 --> 00:27:16,080
December to collect a total of 230 newborn data.

363
00:27:16,080 --> 00:27:22,080
So we're tracking, you know, respiratory difficulties in the intensive care unit.

364
00:27:22,080 --> 00:27:26,680
And so the bottom line is, yeah, it's really hard, it takes time to get, you know, quality

365
00:27:26,680 --> 00:27:27,680
medical data.

366
00:27:27,680 --> 00:27:35,520
And, but that's also part of what turns us more towards classical machine learning and

367
00:27:35,520 --> 00:27:42,960
less away from automatic representation methods like deep learning, so that we can really

368
00:27:42,960 --> 00:27:49,520
have control of what features we extract and really make direct connections between,

369
00:27:49,520 --> 00:27:53,960
the features and the cause they have on the system and, you know, and their projectability

370
00:27:53,960 --> 00:27:55,560
as well.

371
00:27:55,560 --> 00:28:02,960
On that note, are there, you know, you started with this understanding from the prior

372
00:28:02,960 --> 00:28:11,800
research that the frequency components would have a big play a big role in identifying

373
00:28:11,800 --> 00:28:19,200
the asphyxia samples in that kind of feature engineering process, feature identification

374
00:28:19,200 --> 00:28:20,200
process.

375
00:28:20,200 --> 00:28:25,320
Did you identify any new features beyond what you found in the existing research, and

376
00:28:25,320 --> 00:28:29,400
in particular, was there anything that you found that surprised you?

377
00:28:29,400 --> 00:28:38,400
I'll say, because there's such a wide range of audio characteristics that I was explored

378
00:28:38,400 --> 00:28:44,600
back then, but one of the features that I really stood out the most was the fundamental

379
00:28:44,600 --> 00:28:51,960
frequency of the cry, because the fundamental frequency is one of the most studied elements

380
00:28:51,960 --> 00:28:56,200
because it's like the very first thing that describes an audio signal even in music

381
00:28:56,200 --> 00:29:02,360
to the fundamental frequency determines the key of a song, and so it more or less determines

382
00:29:02,360 --> 00:29:08,800
what the, at what pace or at what pitch is this child crying at.

383
00:29:08,800 --> 00:29:14,160
And that would say it's been the most significant features consistently across our work.

384
00:29:14,160 --> 00:29:16,880
And across the previous work that was done as well.

385
00:29:16,880 --> 00:29:24,560
Okay, so it's not some, you know, there's not some kind of mysterious thing that's happening,

386
00:29:24,560 --> 00:29:31,080
like some, you know, it's like just the basic, you know, most fundamental thing that you

387
00:29:31,080 --> 00:29:33,760
would get out of this audio signal.

388
00:29:33,760 --> 00:29:40,200
Yeah, but the interesting question comes in in the, in how it varies in the time across

389
00:29:40,200 --> 00:29:41,200
time.

390
00:29:41,200 --> 00:29:42,600
So the time very in nature of this signal.

391
00:29:42,600 --> 00:29:47,960
And that's why it's not a simple problem that you could set it threshold or chord

392
00:29:47,960 --> 00:29:52,480
and say, okay, every value above this, right, right.

393
00:29:52,480 --> 00:29:56,800
So that's really why machine learning was necessitated because it's the complex time

394
00:29:56,800 --> 00:30:03,600
very nature of the signals and of these characteristics that is just impossible to put down a rule

395
00:30:03,600 --> 00:30:08,320
that says, you know, maybe the has this, this and this is going to be normal and otherwise

396
00:30:08,320 --> 00:30:10,880
for, for us fixated.

397
00:30:10,880 --> 00:30:15,200
Now, how do you capture that time very nature with the SVM?

398
00:30:15,200 --> 00:30:21,560
Yeah, so SVMs inherently are not time, time series classifiers.

399
00:30:21,560 --> 00:30:24,960
And so we've used the combination of several methods.

400
00:30:24,960 --> 00:30:29,720
So one of the things we did was use Gaussian kernels for the SVMs, which, which primarily

401
00:30:29,720 --> 00:30:37,240
do with scalar features, or we then segmented the samples into, into several time chunks

402
00:30:37,240 --> 00:30:43,560
and, and use the instances in time, as if they were independent for training.

403
00:30:43,560 --> 00:30:48,880
But at test, I, we test the, we test the instances, again, independently, but combine their

404
00:30:48,880 --> 00:30:53,840
results to determine whether or not we've, the performance has worked, the performance

405
00:30:53,840 --> 00:30:59,360
of the system is doing well at this, at the level of this subject now, at the level

406
00:30:59,360 --> 00:31:01,960
of the independent time instances.

407
00:31:01,960 --> 00:31:07,280
And so that way, by guiding the search, basically through our, our parameters, by guiding the search

408
00:31:07,280 --> 00:31:14,040
with the ultimate performance on the subject, we can go to a better, hyper parameter space

409
00:31:14,040 --> 00:31:18,720
that really optimizes performance at the level of the subject based on the nature of each

410
00:31:18,720 --> 00:31:20,720
of these instances in time.

411
00:31:20,720 --> 00:31:21,720
Hmm.

412
00:31:21,720 --> 00:31:25,960
Yeah, can you give me an example, maybe of how that, how that works?

413
00:31:25,960 --> 00:31:34,280
Like, what, how does the, the relationship between these samples, give you, you know, allow

414
00:31:34,280 --> 00:31:40,520
the algorithm to, to key in on this time-sensitive variation?

415
00:31:40,520 --> 00:31:48,040
Yeah, so, so you could look at it as, imagine we recorded, hypothetically, the, the length

416
00:31:48,040 --> 00:31:51,040
of the samples we have was ten samples.

417
00:31:51,040 --> 00:31:53,520
So that's it was one second at ten hertz.

418
00:31:53,520 --> 00:31:54,520
Okay.

419
00:31:54,520 --> 00:31:57,560
Ten seconds, ten, ten samples per second.

420
00:31:57,560 --> 00:31:58,560
Hmm.

421
00:31:58,560 --> 00:32:00,560
So this is for one subject, for one infant.

422
00:32:00,560 --> 00:32:07,520
So what we do is, you know, we take each of this, the, the feature, the feature vector

423
00:32:07,520 --> 00:32:11,920
at each of these time instances, so to be clear again, at each of these ten time instance,

424
00:32:11,920 --> 00:32:17,160
we have a feature vector of some length, the feature vector is determined by the number

425
00:32:17,160 --> 00:32:23,080
of characteristics we decide to extract from the, from the audio signals, you know, including

426
00:32:23,080 --> 00:32:29,200
the fundamental frequencies and many other characteristics from the MSC features.

427
00:32:29,200 --> 00:32:33,560
And so we take that feature vector of, say, some, some value, let's say it was three.

428
00:32:33,560 --> 00:32:38,400
And we take that feature, those feature vectors, we decore it as, first of all, for training.

429
00:32:38,400 --> 00:32:44,320
And the goal released to find in the, in the high dimensional space, is there a space

430
00:32:44,320 --> 00:32:51,120
on which we can separate the instances from success samples, from the time instances

431
00:32:51,120 --> 00:32:55,960
of failure samples. But when we do that training to try and separate them and find a good

432
00:32:55,960 --> 00:33:01,240
hyperplane, the high dimensional space, then on the evaluation point, we take, of course,

433
00:33:01,240 --> 00:33:05,360
a separate set of samples. So we don't use the same subjects we use in training as the

434
00:33:05,360 --> 00:33:10,560
evaluation phase. In the evaluation phase, we take each of the instances, the ten instances

435
00:33:10,560 --> 00:33:16,520
of a particular subject to evaluate it. We classify them based on the, the model that

436
00:33:16,520 --> 00:33:23,600
we are choosing to evaluate at this point. And, and ultimately, we, we then use another

437
00:33:23,600 --> 00:33:29,040
metric. So in our case, we, we, we explored both the use of just a simple majority count

438
00:33:29,040 --> 00:33:34,280
of the instances, but also we explored using another classifier, another support vector

439
00:33:34,280 --> 00:33:40,760
machine to be able to classify the predictions. So it's like a meta classifier to be able

440
00:33:40,760 --> 00:33:45,200
to classify the predictions of each of the ten instances. So each of the predictions

441
00:33:45,200 --> 00:33:50,600
become their own features to the next classifier. And then we use that to predict, to make

442
00:33:50,600 --> 00:33:59,760
one final prediction for that subject. And is that, yeah, is the meta classifier method

443
00:33:59,760 --> 00:34:05,400
more performant than a majority or some kind of quorum based system?

444
00:34:05,400 --> 00:34:10,640
Yeah, in our case, it performs slightly better than just doing a majority count. And that's

445
00:34:10,640 --> 00:34:17,640
partly because it's able to take into account temporal dynamics now of this, of the, the

446
00:34:17,640 --> 00:34:24,640
original instances in time. It's able to, it's able to find the relationship between,

447
00:34:24,640 --> 00:34:29,240
between these instances over time, pretty much, and connect the ultimate outcome.

448
00:34:29,240 --> 00:34:39,480
And the example that you use was ten data points a second is, is one second, is that the,

449
00:34:39,480 --> 00:34:46,480
was that just a, for illustration or is, it does one second, worth of sample, give you

450
00:34:46,480 --> 00:34:53,920
enough to identify this time varying indicator in the fundamental frequency of aspects.

451
00:34:53,920 --> 00:35:01,840
Yeah, so one of the, one of the things that we've done is, we use longer segments, but

452
00:35:01,840 --> 00:35:06,760
we, first of all, break them down into one second segments. It's also a way of, of dealing

453
00:35:06,760 --> 00:35:12,320
with the fact that we don't have so many subjects. And we want to make sure that whatever we build

454
00:35:12,320 --> 00:35:20,280
is, it leaves room for, for uncertainty. And so what we do is we break down the samples

455
00:35:20,280 --> 00:35:26,280
into one second segments, perform classification on each one second segment, and then average

456
00:35:26,280 --> 00:35:30,680
the results to give a prediction for that subject. So there's several levels of breaking

457
00:35:30,680 --> 00:35:37,520
down, including this. So we, we, we, we, we, we are the very lowest level deal with the

458
00:35:37,520 --> 00:35:42,280
one second segments. And then we, we, we, we, we, we, we, we, we, we average data on

459
00:35:42,280 --> 00:35:46,080
sample data at the higher level to make a prediction for each patient. So in practice

460
00:35:46,080 --> 00:35:49,480
to, in the test, we did with the mobile application. What we do is, we're called lens

461
00:35:49,480 --> 00:35:54,040
of 10 to 20 seconds. And we break it down that way for the classification. So we split

462
00:35:54,040 --> 00:36:01,120
it. That also helps us to do parallel computations if the device supports it. And then we eventually

463
00:36:01,120 --> 00:36:09,600
combine the predictions. And in terms of, you know, where you are currently, what kind

464
00:36:09,600 --> 00:36:16,960
of results are you saying with the, with the method? So, so the, the paper we have published,

465
00:36:16,960 --> 00:36:24,760
we obtained about precisely 86% of sensitivity. So that was the detection rate of infants who

466
00:36:24,760 --> 00:36:32,240
had a sphixia. And it's 9% of a specificity. That was detection rate of infants who did

467
00:36:32,240 --> 00:36:38,680
not have a sphixia who were healthy. And this is the one we published in, in 2015, that's

468
00:36:38,680 --> 00:36:46,080
one the basic part of what that nips. Nips machine learning for health care. Right, right. And

469
00:36:46,080 --> 00:36:53,560
practically speaking, your, your baseline is against, you know, in the field, it's against

470
00:36:53,560 --> 00:37:01,840
an unated doctor trying to identify asphyxia just based on being presented with an infant

471
00:37:01,840 --> 00:37:07,320
that isn't responding normally. Yeah. Yeah. I mean, that's what would, would like to,

472
00:37:07,320 --> 00:37:11,640
to change. And that's, you know, that's not good enough to have the doctor just eyeball

473
00:37:11,640 --> 00:37:16,600
it. Right, right. But it should be clear that there's a very clinical, there's a gold standard,

474
00:37:16,600 --> 00:37:20,040
you know, there's a gold standard, which is used in, in Canada and in many other parts

475
00:37:20,040 --> 00:37:24,240
of the world. That's the blood. And that's a general. Exactly. The blood class analysis.

476
00:37:24,240 --> 00:37:28,920
Okay. Right. So detect this example of the baby's blood through, usually through the

477
00:37:28,920 --> 00:37:34,400
cut on bleak record, the arterial blood sample. And they analyze it for several parameters,

478
00:37:34,400 --> 00:37:40,640
bilirubin, acidosis and electrolytes and so on. And usually they combine this with the

479
00:37:40,640 --> 00:37:46,400
abgas core of the infant. The abgas core is a, is a score assigned to literally, literally

480
00:37:46,400 --> 00:37:52,000
every baby who has been born for the last 40 years. And it's a physical assessment of how

481
00:37:52,000 --> 00:37:57,440
old baby is doing on five measures. So that's combined with this blood gas analysis to make

482
00:37:57,440 --> 00:38:05,760
a confirmatory diagnosis of a fiction. And that is, is the blood gas analysis also something

483
00:38:05,760 --> 00:38:10,720
that is routinely performed or is it performed when there's, you know, a certain level of the,

484
00:38:10,720 --> 00:38:17,840
of the score or some indication of a problem? Well, in Montreal and the rest of Canada,

485
00:38:17,840 --> 00:38:22,880
it's a routine process for every baby that's born. And really that's one of the things that makes

486
00:38:22,880 --> 00:38:28,320
it very convenient for us to do the study here. It's because we would not have to as part of our

487
00:38:28,320 --> 00:38:34,720
study design decide how we collect the gold standard. The gold standard is already a part of

488
00:38:34,720 --> 00:38:39,440
day-to-day clinical operations. We just have to read the charts to get that data. So yeah,

489
00:38:39,440 --> 00:38:47,520
it's routine here. Interesting. And you mentioned that you're working on another project

490
00:38:47,520 --> 00:38:57,280
there as well in addition to Benoit. What's that one? It's called the APEX project. APEX has in

491
00:38:57,280 --> 00:39:06,960
A4APEX, the stands for automated prediction of extubation readiness. It has, I guess, one technical

492
00:39:06,960 --> 00:39:14,000
term, the extubation. And basically that refers to the process of winning a child who is on the

493
00:39:14,000 --> 00:39:21,680
respiratory support. Yeah, so usually infants who are born pre-term, pre-matchell, which is

494
00:39:21,680 --> 00:39:30,000
usually around seven weeks or they're about, is I usually, the lungs are actually not well developed

495
00:39:30,000 --> 00:39:35,360
well-formed to support spontaneous breathing for them. And so they usually require respiratory

496
00:39:35,360 --> 00:39:41,040
support. And this happens in general through the insertion of a tube down the attractor.

497
00:39:41,040 --> 00:39:47,920
Yeah. And the other end of the tube is connected to a ventilator. And this ventilator provides oxygen

498
00:39:47,920 --> 00:39:55,520
to the infant at a certain interval, you know, tunable by the diffusitions. But these positions

499
00:39:55,520 --> 00:40:02,080
have to make a very critical choice under this setting. So they must decide when to remove the

500
00:40:02,080 --> 00:40:08,880
infant from this setup, from mechanical ventilation, as it's called, because the longer you leave the

501
00:40:08,880 --> 00:40:14,000
infant on that, that system, the increased chances of lung disease, because, you know, you've placed

502
00:40:14,000 --> 00:40:21,280
a plastic tube in the trachea. And that causes less interactions with the walls of the trachea

503
00:40:21,280 --> 00:40:27,280
and so on. And so to that degree, it causes something called BP, the bronchopulmonary dysplasia,

504
00:40:27,280 --> 00:40:32,160
which effectively is lung disease. And that's bad because it's going to be a live lung disability

505
00:40:32,160 --> 00:40:36,640
in most cases. So, but also you don't want to remove it too early. So that's the case when you

506
00:40:36,640 --> 00:40:41,760
leave it too much too long. If you remove it too early, the infant may not be ready to breathe on

507
00:40:41,760 --> 00:40:48,480
its own. And what could happen is that the infant would require re-intubation. So intubation is a

508
00:40:48,480 --> 00:40:53,680
process of putting the tube in and extubation is a process of removing the tube. The infant could

509
00:40:53,680 --> 00:41:00,320
require re-intubation. And re-intubation is a technically difficult challenge for infants that have

510
00:41:00,320 --> 00:41:05,360
been integrated already because they're swelling the trachea and so on. And in some cases they never

511
00:41:05,360 --> 00:41:11,440
succeed and the baby ends up having to die. And so there's this trade-off between how one is the

512
00:41:11,440 --> 00:41:19,440
optimal time to extubate an infant on the intubation in the ICU. Can I ask the stupid question,

513
00:41:19,440 --> 00:41:25,520
which is can't they remove the oxygen source without removing the tube and see if it works?

514
00:41:26,560 --> 00:41:29,360
Well, that turns out to not be a stupid question.

515
00:41:29,360 --> 00:41:38,800
Because for our study, that's indeed what we are tracking. Because one of the things the doctors

516
00:41:38,800 --> 00:41:45,840
do as partly a way of evaluating how ready the baby is is to disconnect the ventilator and let the

517
00:41:45,840 --> 00:41:52,000
child breathe through the tube first to just observe how well the infant does. The challenge with

518
00:41:52,000 --> 00:41:57,040
this is that while it's a good process better than nothing, it still has resulted to

519
00:41:57,040 --> 00:42:04,720
to currently North America the failure rate for re-intubation is about 25%. So the doctors get

520
00:42:04,720 --> 00:42:10,160
it wrong about 25% of the time. And really that's the core of the project we're trying to fix. I

521
00:42:10,160 --> 00:42:17,360
was trying to save those 25% of babies who end up either being re-intubated or who end up with

522
00:42:17,360 --> 00:42:25,600
long-term disability. So in a lot of ways similar to the asphyxia problem you have doctors that

523
00:42:25,600 --> 00:42:34,720
don't have an effective way of clinically assessing whether the baby is able to breathe on its own.

524
00:42:34,720 --> 00:42:41,120
And so they do in fact disconnect the ventilator without taking the tube out. But they're just eyeballing

525
00:42:41,120 --> 00:42:46,480
whether the baby looks to be ready. And in 25% of the cases they get it wrong, take the tube out

526
00:42:46,480 --> 00:42:49,360
and only then find out it has to go back in.

527
00:42:49,360 --> 00:42:56,080
Exactly. I say eyeballing, but the doctors have many medical devices connected to the baby,

528
00:42:57,600 --> 00:43:01,920
respiratory monitors and so on. And you know the look at these data, look at the patterns and

529
00:43:01,920 --> 00:43:06,080
make it an informed decision. And you know that explains why they do this too.

530
00:43:06,080 --> 00:43:11,760
Tell you well, 75% is not too bad. It could be better and that's really the goal of the project.

531
00:43:11,760 --> 00:43:18,080
To say how can we take machine learning methods, apply to an automated analysis of the heart rate

532
00:43:18,080 --> 00:43:22,880
signals, respiratory signals that we get from this infant during that spontaneous

533
00:43:22,880 --> 00:43:27,520
bidding trial period. So during that time when the ventilator is turned off, because that's

534
00:43:27,520 --> 00:43:33,360
usually the true measure of how well the infant might do when they don't have that ventilator on.

535
00:43:33,360 --> 00:43:38,080
So we take these signals at that point in time and we are building a primarily

536
00:43:38,880 --> 00:43:43,520
time series methods to analyze them and say how can we make a prediction from this.

537
00:43:43,520 --> 00:43:46,800
Okay. Yeah. And what stage are you in with this project?

538
00:43:46,800 --> 00:43:52,240
We are at the stage where, as I mentioned earlier, you know, in December 2015, we reached

539
00:43:53,360 --> 00:43:56,480
we reached our target of 200 and a set of the... Oh right.

540
00:43:58,240 --> 00:44:04,480
Right. Yeah. Yeah. But that was the target of the project anyways, to get to about,

541
00:44:05,040 --> 00:44:12,560
to get to 200 babies for our training and development and to get another 50 for validation.

542
00:44:12,560 --> 00:44:17,120
So those 50 will be left to the very end of the project, say, five year long project.

543
00:44:17,120 --> 00:44:23,200
We left to the very end before we to evaluate what about methods that we've developed on the other

544
00:44:23,200 --> 00:44:29,360
parts. So we've done quite a bunch of analysis on the data over the last year,

545
00:44:29,360 --> 00:44:34,480
but really much of it has been, much of the detailed work about, say, I've been starting this year

546
00:44:35,120 --> 00:44:41,440
since we now have the many multitasets that we require. Yeah. We've written about a few,

547
00:44:41,440 --> 00:44:47,840
a few works we've done on the data in terms of using Markov chain models to model the respiratory

548
00:44:47,840 --> 00:44:53,680
patterns and how they change over time. Yeah. So we have a paper that we have published about

549
00:44:53,680 --> 00:44:58,640
this work last year at the Engineering and Medicine and Biology Conference.

550
00:44:58,640 --> 00:45:01,920
Okay. And what was the conclusion of that paper?

551
00:45:03,120 --> 00:45:08,160
Yeah. The paper was pretty interesting. At least we find it a bit for people. It was pretty

552
00:45:08,160 --> 00:45:13,600
interesting. So in that case, what we did was we did not look at the raw signals of how the

553
00:45:13,600 --> 00:45:18,880
heart rate is changing, you know, the respiratory rate in particular. We looked more at states. So

554
00:45:18,880 --> 00:45:24,480
so breeding in general goes through a number of states. There's five of them roughly.

555
00:45:24,480 --> 00:45:30,480
There's synchronous breeding, which is when the breeding in the rib cage and abdomen,

556
00:45:30,480 --> 00:45:39,040
in synchrony, it's very creative. So they're happening at the compression and expansion is

557
00:45:39,040 --> 00:45:44,000
happening at the same rate pretty much in both sides. There is a synchronous breeding when they're

558
00:45:44,000 --> 00:45:49,680
out of phase. That's the second pattern. The third pattern is the pause states when the infant

559
00:45:49,680 --> 00:45:56,640
experiences a cessation of breeding at some point. And there's the movement artifact phase,

560
00:45:56,640 --> 00:46:03,120
which is somewhat a phase induced by external factors, either the infant is moving or it's been

561
00:46:03,120 --> 00:46:10,000
found by nurses and so on. And then there's the last phase is called an unknown state.

562
00:46:10,800 --> 00:46:16,080
And that is just the ones that don't fit into any of the four defined patterns. And so the

563
00:46:16,080 --> 00:46:20,160
goal of this project was to see how we could use switching models like the Markov chain,

564
00:46:20,160 --> 00:46:27,360
which models the transitions from one state to another. How we could take that and apply to this

565
00:46:27,360 --> 00:46:35,360
to learn more about what kind of transitions do infants who are ready for excavation go through

566
00:46:35,360 --> 00:46:40,960
and walk on of transitions to infants who are not ready for excavation go through and could this

567
00:46:40,960 --> 00:46:47,680
inform the classifiers will build in the future. And so it was a more of a modeling task using chain

568
00:46:47,680 --> 00:46:54,320
models. And do you think that the Markov chain model will play a big role in the approach you

569
00:46:54,320 --> 00:47:05,360
eventually take to create a diagnostic tool? Yeah. On one hand, it emphasized some of the things

570
00:47:05,360 --> 00:47:12,000
I was known somewhat within the clinical community that for instance pause states are bad.

571
00:47:12,000 --> 00:47:19,200
Session of breeding is not good because that means there's no power to drive the longer activity.

572
00:47:19,840 --> 00:47:23,840
So it's very important for some things like that. But also we observed some interesting trends

573
00:47:23,840 --> 00:47:30,000
in terms of the transitions from some of these phases to the others. That would eventually serve

574
00:47:30,000 --> 00:47:36,720
us features into whatever classifiers we build in the near future. Awesome. Awesome. Well,

575
00:47:36,720 --> 00:47:43,600
you've been very gracious with your time and we're running out of it. So I'd love to dig more

576
00:47:43,600 --> 00:47:47,760
into this. But I think in lieu of that we'll just make sure that we have a link to

577
00:47:49,200 --> 00:47:55,520
to this second paper here. But Charles, thank you so much for taking the time. You're doing

578
00:47:55,520 --> 00:48:01,280
some really interesting work. And I appreciate it having the opportunity to learn about it.

579
00:48:01,280 --> 00:48:06,400
Yeah, thank you very much. Some of us had a nice chat to meet you as well. Awesome. Thanks.

580
00:48:10,640 --> 00:48:16,720
All right, everyone. That's our show for today. For more information on Charles or any of the topics

581
00:48:16,720 --> 00:48:24,560
covered in this episode, head on over to twimlai.com slash talk slash 112. And remember to submit your

582
00:48:24,560 --> 00:48:32,720
thoughts on AI in your life at twimlai.com slash my AI. Thanks so much for listening and catch you

583
00:48:32,720 --> 00:49:02,640
next time.

