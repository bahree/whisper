Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington, a quick update on our deep learning study group.
As you know, we're huge fans of the fast.ai courses and we recently had our second group
of deep learning learners complete the fast.ai deep learning for Kodo's course back in December.
I'm excited to announce that we'll be hosting our third group of students taking the
part one course starting this Saturday morning, February 2nd.
This study group will run seven weeks finishing just in time for participants to jump right
into the deep learning for Kodo's part two course, which is set to start in mid-march.
For details on the study groups or to get registered, visit twimbleai.com slash meetup.
While it nerfs this past December, I had the pleasure of attending the second annual
Black and AI workshop in dinner, which brings in participants from all over the world to
showcase their research, share experiences, and support one another.
I was fortunate enough to spend the day at the workshop and I'm excited to share with
you over the course of this month conversations with just a few of the great members of this
community.
To keep up with the series, visit twimbleai.com slash Black and AI 19.
To get this series kicked off, we're joined by Randy Williams, PhD student at the MIT Media
Lab.
At the Black and AI workshop, Randy presented her research on pop-bots, an early childhood
AI curriculum, which is geared toward teaching preschoolers the fundamentals of artificial intelligence.
In our conversation, we discussed the origins of the project, the three AI concepts that
are taught in the program, and the goals that Randy hopes to accomplish with her work.
This was a fun conversation, it was super thought-provoking.
Enjoy.
All right, everyone, I am on the line with Randy Williams.
Randy is a PhD student at the MIT Media Lab.
Randy, welcome to this week in machine learning and AI.
Hi, thank you Sam for inviting me.
I'm happy to be here to talk to everyone about my work.
Absolutely.
So we had an opportunity to meet at NURBS recently, in fact, you presented at the Black
and AI workshop there, and I was really fascinated by the work you're doing in teaching preschool
children about artificial intelligence.
What sparked your interest in doing that, in teaching, you know, young children about
AI?
Thanks, the workshop that was definitely incredible, and I was happy to share my work with the
people there.
So I am a PhD student at the Media Lab.
I've been working on this project for about three years, and when it started, it wasn't
about AI, and it wasn't necessarily about preschool children either.
It was about computational thinking and how do we help students who might not have access
to fancy robotic toolkits or to teachers?
How do we help them start to learn about these things?
How do we spread the influence of the whole craze about CS to different populations?
So I personally am from, well, Prinshire just County, Maryland, but my family is from
Baltimore, and I went to school in Baltimore, and while I was in undergrad, I spent a lot
of time working with inner-city children and, you know, doing maker spaces or doing
workshops, that kind of thing, and what was really awesome about it was how engaged students
were with, you know, learning these different things, but it also made me a bit sad that,
you know, so many of my classmates in school, they were like, oh, yeah, I've been programming
since I was seven, and, you know, these students, you know, they were like high schoolers,
and they're just getting started with this.
So I just felt really strongly that, you know, there needs to be more done to help everyone
have a chance to learn about these things early on, and it was really difficult in Baltimore
was that there just weren't a lot of teachers, there weren't a lot of people who knew about
the field to come and, you know, teach the kids and share the expertise.
So within the group that I started working in, in the MIT Media Lab, it's called the
Personal Robots Group, and my professor is in Theore Brazil, and she's really passionate
about how AI robotics can help us flourish as human beings, and so a lot of our work
has been about education and how robots play a role in that.
So I started out just building a robot that could help children learn how to program and
sort of, like, be the fun, interactive learning companion to help them, you know, figure things
out and push them to solve new problems and things like that, so the absence of a trained
teacher, how can a robot help children learn about these kinds of things?
And it was really fun.
I started thinking about, you know, like, so what makes the most sense, you know, having
some experience in Baltimore, I was like, well, no one's going to go buy a $200 robot
to do this, so how do we make something less expensive?
So the pop-up project that I'm working on is mostly based around a mobile phone, so
the mobile phone is the intelligent robot that children program, and then I was also thinking,
well, how do we break away from computer sciences, you know, solving mases or doing puzzles
and really open it up to different interests that students might have?
So the robot, you know, can become a character, you can make it look like whatever you want,
it can control the lights around your room and things like that, so it's sort of like
opening doors for, you know, art and theater and music even.
And then somewhere along the way, I was having a conversation with Cynthia one day about
the project in the direction, and she was like, you know, Randy, it work is great, but
you should really think about AI, because AI is the next big thing, and no one's really
doing like AI education, and, you know, as a student, I'm like, okay, well, I've taken
AI classes in college, I don't really know how I'm going to teach children AI, but yeah,
sure, you know, let's go ahead and try it.
So I quickly pivoted and how did I end up with preschool children?
Well, there were a lot of like robot kits for like the seven to ten year old age, and
I just, I guess, enjoy not sleeping and like solving really crazy problems.
So I was like, I'm going to go like right below that.
I'm going to do the five to seven year olds, and that's, it worked out, I guess.
So we have a five to seven year old preschool AI toolkit that I'm working on.
That's awesome.
That's awesome.
So is the Nielab, is that its own department, or are you affiliated with computer science
or robotics department, and kind of what I'm also curious about here is, have you also
received any formal training in education, and how do you kind of think about the interdisciplinary
nature of your project?
Yeah.
So the Nielab is this weird crazy place.
I work in a robotics lab.
The people next to me, they do devices that go underneath your skin to help monitor
your health, and the people on the other side of me do neurobiology.
So it's a department with pretty much anyone who has a crazy idea that doesn't fit into
like normal science or engineering department, you know, that's the place that you go to
do work.
So as a result, I get to do this project, this very interdisciplinary, I get to think
about art, I get to go to schools and do education work, I get to do robots, and you know, I also
have lots of resources around the lab where people do all of these things and can sort
of help contribute to the project and help me grow my ideas.
So I don't actually have formal training and education, however, a lot of the work
that I'm doing is built on this program called Scratch.
So Scratch is this website where children ages seven and up can go and learn about CS,
and it was, I don't want to, so currently the leader of the lab is Mitchell Resnick, but
I believe it started by, like, Seymour Pappert, like, you know, logo turtles.
If you don't know what that is, it's these turtles where, you know, Seymour Pappert
back in the 60s was like, all kids should know how to program, and all kids should, you
know, be able to do this.
And this is when like computers weren't even very popular, so everyone was like, dude, you're
crazy.
But, you know, he's like, yeah, I'm going to do it, and so he started building this
programming language for children, and you know, generations later, there's this online
portal where literally children, millions of children all over the world are learning
how to program.
So even though I didn't have the background, the CS education background to know how to
do it, I got to work with Mitch, and I took his class, and I learned from his students
and can start to pull those things in.
I also didn't necessarily have a background in robotics.
I did computer engineering and undergrad, but mostly, like, building little devices,
not things that were, like, big and interacted with people.
So I learned a lot from my group, and then everyone at the media lab, they're kind of just,
you know, like artists.
So I'm not an artist, I'm an engineer, but I became an artist, and it was able to pull
that in.
So really, what's awesome about interdisciplinary work is that you get to pull in from all
of these different fields, you know, talking to developmental psychologists, can kids
understand AI?
Are they ready to do that yet?
What are the right ways to translate the information so that it makes sense to them?
I've really actually been inspired by all the people I've gotten to work with.
So when you think about teaching AI to preschool kids, obviously, we're not trying to teach
gradient descent algorithm or anything like that, like, how do you, how do you kind of
break down, or maybe take it from the other direction?
What are your goals in trying to teach AI to children at this age level?
Yeah, I would say my primary goal is to give children agency and the world around them.
So before I even, you know, put out this little kid and started, like, actually testing
with children and building things, I did a whole series of studies with other people
in my group around what do children think about AI?
So we would have them interact with toys.
If you look at kids' toys now, they're like amazing, they're really cool.
So they have, like, these little robot things called Cosmo, which, like, they move around
and they can play games against you and they're super cute and you can program them and
stuff too.
But, you know, it's like real AI that is being marketed to children.
Then there's all this controversy about this Barbie doll, hello Barbie, that they talk
to you and every kid in the world, I think, has had a conversation with Siri or Alexa,
you know, not every kid in the world, but quite a few have.
So it's interesting to see how in our time, you know, computers were just kind of, like,
coming to be, and the internet was just coming to be, and children are growing up in a
world now where it's like, yeah, AI is kind of a thing, like, it's normal to see that.
So I was like, okay, so when a child interacts with this thing, that's not a life, not
a human, but can talk to them and seems kind of smart, you know, what are they thinking?
What's going on in their head?
And oftentimes, they're, like, kind of just figuring it out.
They're like, okay, it talks to me.
Like, you know, let's poke it.
We'll see if it can answer questions about dinosaurs or sloths, or does it know what's
in the grocery store down the street, things like that, and then they're like, well, can
I break it?
Hey, do you want this apple, you know, asking these kinds of things to computers, and
just just do what it will say, or, hey, do you have a boyfriend, do you have a girlfriend?
Funny things like that, but even worse, so they kind of didn't really understand how
it worked.
And to me, that's like an opportunity and a challenge for today, because we don't really
want children to have toys that they can't pick apart and understand.
You know, they're like, I like so well, answer my question.
Does she not like me?
And it's like, no, Alexis, you know, NLP algorithm, just isn't programmed for young children's
voices, because it was made by adults who thought only adults would be using it.
So, you know, that's what's going on, but if you say that to a kid, they'll look at
you like, what are you saying?
I have no idea what's going on.
So the goals of the curriculum are really to help children break those kinds of ideas
down.
Like, oh, Alexa isn't working because Alexa was trained a certain way, and if you try
and have Alexa do things outside of the way that she was trained, then she's not going
to get it.
Like, that's kind of the right level that I think any child should have.
It makes me think a little bit of a couple of examples.
One that comes to mind is when children like, you know, who are raised on iPads, see magazines
and start me capping at a magazine like wanting it to do something, or the other example
that comes to mind is knowing how to really effectively search Google, it's a powerful
skill.
But, you know, both of these things, I think, illustrate, you know, like mental models
that are created over time about this thing that you're interacting with, that, you
know, in the case of an iPad, it's just like this piece of glass, but you kind of develop
this model about like how, you know, flat things work, I guess, or, you know, in the case
of a search box, like, you know, how do you can really effectively use, you know, this
world that's behind the search box?
It is part of your work here, trying to shift the mental model that kids have about AI.
I actually really love that framing, and I might have to use that in the future, you know,
like, we're in children's mental models about AI, yeah, so that is literally what I'm
doing.
So, a part of the actual pop-up study that I did, so I have children interact with the AI,
and not just interact with it, I also have them, like, building algorithms from scratch,
not the whole thing.
They're not writing the programming, but pretty much they have a lot of control over the
way the algorithm works.
So, we do that, and at the end of the day, they have this finished AI product that seems
intelligent, and before and after, they're learning about AI, ask them, what do you think
about this thing that's in front of you?
Do you think it's alive?
Is it a person?
Is it a toy?
Is an adult?
Is it a child?
Is it smarter than you?
Are you smarter than that?
And I'm asking all of these questions, because I expect a mental model change to
happen when children are learning about AI, and I'm wondering, you know, how can we make
sure that, you know, there's so many privacy and security, like, safety concerns around
having something that's always recorded you in the house.
So, what are children's mental models, and how does learning about AI impact that?
How does it change the way that they want to interact with these things in the future?
And what were some of the results you saw in these before and after surveys?
Mostly very strange things.
So before, well, the studies that I did, like, two years ago, I interviewed four to ten
year olds about AI, and the older kids, the eight to ten year olds, they were, like,
solid.
They knew exactly what they thought about AI, and, you know, they're like, it's not a
person, it's not quite a toy, it's somewhere in the middle, like, they knew what they were
doing.
But the younger children, they kept telling me, I don't know, I don't know, I don't
know.
And I was getting frustrated, you know, it's a research, you're saying, like, I don't
know, it's not going to get me a paper set into a conference.
And so what I found before was pretty much the same children were like, I'm not really
sure what this thing is, like, you know, we're all over the place.
People saying, yes, people saying, no, people saying, oh, it said my name.
So I guess it's pretty smart, or it didn't say my name, or it doesn't know my favorite
song about the train.
So it's not smart.
You know, just things that were very hard to understand, which is interesting because
these parents are also looking at this, and they're like, I'm not sure, but my child thinks
about it, like, so you know, they keep calling it their best friends.
So, you know, what is this relationship?
But afterwards, there were some interesting differences.
So I split my age grouping into, like, pre-K and kindergarten children.
And so after they had learned about AI, the pre-K children were like, oh, now I understand
it.
So yeah, I would say this thing's pretty smart.
And the kindergarten would children, like, oh, I don't think it's smart.
anymore.
Like, I thought it was smart before.
But now that I get how it works, it's like, nope, like, okay.
And then I also created, like, assessments, like, very simple, multiple choice questions
to ask how much do children really understand about the activities that I've given them,
and how much do they understand about the AI concepts?
So the ones who did the best of the AI concepts were like, you know, not that I played with
this thing.
I'm like, yeah, it's kind of like a person.
Like, it thinks sometimes in ways that I think.
And yeah, it could be smarter than me, too.
It could learn.
It can get better and better.
But interestingly, the children who didn't understand the activities very well were the
opposite.
They're like, nope, not smarter than me.
It's just a toy.
You know, it's fun, but it doesn't seem to be as alive or as human to me.
And so I'm still undecided about what conclusions I want to draw from that.
But I definitely think it's interesting that there is a big difference.
Like, the children who understood AI versus the children who didn't understand AI saw
the technology in very different ways.
So at the very least, it sounds like teaching children about AI does cause something interesting
to happen, something interesting, and hopefully not negative.
So it seems like a good motivator to continue with the work and continue to explore this.
I can't help but think that teaching adults about AI would have the same positive effects.
You know, you think about kind of some of the mass media coverage of AI and some of
the, you know, hysteria is that you read about.
They often kind of belive this, you just lack of understanding.
And have you thought about creating an adult version of your curriculum?
So I haven't thought about it myself, but sort of, you know, even to discuss with you,
we're mentioning about the more that people understand the less scared they might be.
I think that the way that, you know, AI conversations are just playing out in society right
now.
It's kind of like a little bit of both.
So there are some people, I guess, like myself and people in my lab who are like, you
know, look at AI, look at how much good it can do.
We can use it to build, you know, this good thing, that good thing, this good thing.
And I would say that we're experts, but then there are also people who are extremely
wary of AI.
So they're like, they see this technology coming and they see all the negative ways that
it can be used.
And they're like cautious to like, you know, completely repulsed by it, like, no, even
if AI can do good things, we shouldn't build it because in the wrong hands, it can just
be too powerful and too destructive.
And so I think that any adult education, AI, I think would probably have an interesting
time trying to wrestle with that, you know, not trying to push people in any particular
direction, but to let them come up with their own interpretation of how they think the
technology should continue.
Yeah, that's a really interesting point.
I definitely get where you're coming from.
You know, it's almost like the thing that you're afraid of, is it really the thing you
should be afraid of?
That's true.
You know, it's not that there's nothing to be afraid of or not even afraid, but worried
about.
There are, there are genuine concerns, but, you know, it's, it's not necessarily kind of
this terminator scenario in the next five years.
I can tell you, it's a roboticist.
There will be no terminator, because robots love to break, like, they're just not going
to work out.
There could be a, what is the movie, her, like, the thing where it's like all of mine,
like, that's a bit more likely, but I wish you guys no terminators are going to come.
Let's maybe talk about the curriculum that you developed as a part of pop bots.
What are the core AI concepts that you're trying to teach these children?
So the three that I started with were knowledge based expert systems, supervised machine
learning and generative AI.
And I started with these because they seem to be the most relevant to what children
were experiencing.
So a lot of their simple toys were using these, you know, kinds of concepts in them, and
I could easily make connections between, when you toyed as this, this is what's happening
underneath it.
And to me, that seemed like the most important things to teach children at first.
So, you know, knowledge based systems.
Let's go through each of those and maybe you can provide an example of the way a child
might experience that in their kind of everyday toys and how you introduce that in the curriculum.
Knowledge based systems for rule based expert systems or expert systems, they have multiple
names, often come up in natural language processing.
Now a lot of NLP also uses, you know, deep learning, but, you know, in the past, you know,
back in the good old days, it came up a lot in natural language processing as well as
medical diagnosis and even the video game characters that, you know, aren't the main characters
but the ones that, I don't know, if you play a lot of RPG games when you're battling
the random townsmen, like those kinds of characters were all controlled by knowledge based
expert systems or rule based systems, and so it was easy to, you know, talk to children
about, it's like, oh, when you're playing tic-tac-toe against your smart computer or when
you're doing that video game or when you're talking to Alexa, there's probably a bit of
this going on underneath and the way that we did the activity was we played rock paper
scissors.
So, rock paper scissors, you need knowledge, like there are rules, which is, you know,
arts, scissors, paper beads, rock, et cetera, and so children would literally program these
rules into the robot.
All of the interfaces are completely picture-based because I was working with children who were
so young that they couldn't read, so it was an interesting design challenge to say,
okay, powerful AI, absolutely no words whatsoever, and like no math and stuff like that.
So children pretty much put, like, pictures of a paper hand and then an air will like greater
than sign and then a rock, which means paper beads rock.
And so they put in all the rules and now the robot has its knowledge base and it can
use that to make decisions about what to play.
So when the child's actually playing against the robot, then the robot will kind of keep
packing their moves and it'll use that to say, oh, well, I think that you're going
to play paper next and you told me that scissors beats paper, so I'm going to play scissors
and then it's revealed, you know, did the child actually play a paper and a lot of times,
you know, after a couple rounds of the game, yeah, the robot's pretty good at guessing
and they're like, oh my god, the robot got so smart, but what's really cool about that
is it didn't start off smart, it actually starts off losing a lot and as it keeps going,
it gets smarter.
The children start to see how this intelligence didn't disappear, it was learned over time.
Also the children gave the robot the rules to the game, so the children actually played
at part in helping the robot become intelligent, what's even more funny is that the kids
will be like, I'm going to cheat and they'll like switch all the rules around backwards
and the robot will be like, well, I guess that paper beats scissors, so does that mean
that I win and the child's like laughing their head off like, ha, ha, ha, I tricked you.
But that's actually an interesting point because, you know, expert-based rule systems, one
of the ethical issues is what if the rule that you're teaching isn't correct?
So children even get to explore that idea like, okay, if I have a car that's driving by
itself and I teach it the wrong rules, what happens?
And you can see like this look of realization, like, you know, move over the child's face
and they're like, oh my god, that would be so bad.
I'm like, yes, like you're understanding, like, you know, the impact, the real world,
the impact of AI. And then also, children will teach the robot how to react to winning,
losing and getting a tie. So, you know, like, the robot can be a sore winner and like,
every time it wins, it's like, ha, ha, win, you lose. And like, it makes the sparring
sound. So that's like, one iteration that you can have it win humbly. It's like, oh,
that was a good game. So children are also, you know, it's kindergarten, it's free
school. Children also need to have some way that, you know, social interaction, social
learning is coming into this as well. So that's a part of it too.
I'm curious in this first part, the rules-based systems, when you, when the child was programming
the robot, teaching the robot how to respond via these rules, were you also introducing
some notion of probabilistic systems or responses?
So in the sense that the robot was learning over time, what the child was most likely
to do next, yes. It was a little bit tricky, because probability doesn't come up for
a while in, like, early education, but we would make these rule trackers, or these game
trackers, rather, where the children would write down, you know, what moves they put. And
the robot would say, well, I think you're going to put paper next, because you put paper,
like, three times out of the five times that we just played, and the child can look back
at what they did, and they can start to see, oh, yeah, like, one, two, three, like, those
are the times that I picked paper. So yeah, that's the sense in which I envisioned it,
yeah. Yeah, it's like, it's not like super deep, but yeah, that's about how far we can
go. But you kind of raised that as, like, that was made explicit in the curriculum, thinking
about, you know, these, you know, percentages or frequency types of numbers. Yeah, absolutely.
And the entire time the robot is, like, saying these things, it's pointing out what its
knowledge is, and it's explaining why it's making decisions, so that the child can understand
it. And I think my hope is that, you know, when they get older, if they have another AI
class, they can revisit these ideas and actually learn about probability, and it all starts
to make sense. So, like, even reinforcing those ideas later.
And so just a point of clarification, you are referring back to this idea of a robot.
Is this an entirely software based robot just on the smartphone, or is there a hardware
component as well? Ah, yes, I should have explained that. So the robot is a mobile phone with
this social robot technology that we developed in our lab, so it can talk. It has all these
really cute, fun animations. I can listen to you. It has a camera, but around it, I've
built a Lego body. So there's two different bodies that I'm working on now. One uses
Lego We Do, which is like this $200 motor kit, and you can use normal Legos, and then you
could add these motors to it. So now the robot can move and dance, but because it's Lego,
you can change the way that it looks. So sometimes it's a car. Some children really wanted
to play with one that's spun around, so they can sort of have total control over the way
that their robot is. So they're programming it, they're building it, like all of it is
brought down to the child's level. And then the other one, I imagine, is Arduino. So
now I'm thinking about slightly older kids and even more fun things to build, so I'm
building an Arduino platform for it too. So then back to these concepts, we just talked
about the rules-based types of systems. Do you mention supervised machine learning as
well? Yeah. So supervised machine learning comes up in YouTube kids, which surprisingly
a lot of children were interacting with. So I would ask them, how does YouTube know
which movie you want to watch next? And they're like, oh, it just picks whatever is random.
And I'm like, no, it's not random. It usually picks things that are kind of like the video
you just watch. And they're like, oh, yeah, I guess you're right. And so we can talk
about supervised machine learning. So that's when you label some things, for example, as
good and bad. So in the case of YouTube kids, children are labeling things as things
that I want to watch by watching it. And then they can also give extra feedback, thumbs
up, thumbs down, so that the robot, sorry, not the robot. YouTube's algorithm can learn
better. But it's often used for like recommender systems. So it can be YouTube, it can be Netflix.
Children don't have email yet, but sometimes they can kind of get what I mean if I throw
that in there. But for children what we do is we sort foods into healthy and unhealthy
groups. So rock paper scissors is nice because I have street rules. But if you want to
teach a robot about which foods are healthy and unhealthy, you know, I have children think
about like, how many foods are there? Like how many foods would you have to teach the
robot about? And after they kind of like hit the dirty, they backs out and they're like,
oh my god, that's so many foods. So I'm like, okay, there's a better way. We can give
the robot a few examples and it can learn to make guesses on its own. So sort of on the
back end, something I do beforehand, the robot has this database where it has like the
color of foods with food groups and how much sugar it has all of these different features.
And then it's going to use a K-nearest neighbors algorithm to sort of say, well, this food
has this many features similar to this other food. So maybe these two are nearest neighbors
as opposed to this other food. So a good example is like bananas would be more similar to
lemons than chocolate. So what I have children do, they have this like list of 20 foods and
I say we're going to label two of them. So they label, you know, either both of them good
or both of them bad. They take whatever food they want. And then we're say, okay, now let's
ask the robot to guess like whether this food is healthy or not. And so they start to see
like, okay, if I tell the robot that strawberries and tomatoes are healthy and then I ask about
chocolate, it's going to think chocolate's healthy too because I haven't given it any
bad examples. So I have to do better. I'm like, okay, let's teach the robot that chocolate
is not healthy. So now we have strawberries and tomatoes and the good chocolate and the
bad. Let's ask it about ice cream. And the robot can say, well, ice cream is probably
closer to chocolate than it is to the other things because they both, you know, are in
the sweet section. They have a lot of sugar. So it's chocolate unhealthy too. And boom,
like magically the robot seems intelligent, seems like it's learning. It ends up being that
after we teach the robot about like five foods, then it can sort of guess the other 15 foods
that remain. But it all depends on how good the training set is. So I don't use the
words training set with a five year old. But the idea is still the same. It's like, so
we only told it about these five foods and it learned about these 15 foods. Like would
of all the five foods have been good would it do a good job? What if they were all bad?
Would that do a good job? And they can start to seeing how the robot, you know, needs
certain examples of certain quality, like if we only teach it about red foods and we
ask it about blue foods, it's probably going to be a bit confused because like you haven't
given it a good enough training set. That one's usually really fun. And then again, of course
children want to trick the robot. It's like, well, I like chocolate. So I'm putting chocolate
on the good side and like, okay, well, we can do that, of course. How does that impact
the robot? And then we can discuss that as well. And then the last activity is genitive
AI. And this was one that I thought was really important because AI doesn't just follow
rules and it doesn't just classify things and make rules. Sometimes it is creative and
it can be used in art. This particular activity is about music. So first children give the
robot parameters about different emotions and how they would sound as music. So happy
music sounds, you know, kind of fast and upbeat. And it also sort of goes up in core progression.
So like rather than going like during, or it's going to go up. So they teach the robot
that by sliding these two bars, like core progression up and music fast. And then they
do sad. And they're like core progression down music, maybe a little bit slow and then
excited. So core progression up, music fast or scared, core progression down, but music
fast. And they teach the robot about what different emotions should sound like a song.
And then I drive all the teachers in the room crazy. We start playing music with the robots.
So children have this piano where they can play a song. And then the robot will take whatever
song they make and will remix it according to the different emotions. So it's just like
really noisy. But a lot of fun is like children are like, you know, playing songs and hearing
the robot play their song back and sort of like going back and forth with this turn taking.
And then, you know, we ask questions like, so did the robot song sound like your song?
So if you tell it not to change anything, yes, if you tell it to go faster, it'll just
change the progression a little bit. If you tell it to go slower, it'll, you know,
make it a bit slower. Sometimes it'll add new notes. If you tell the core progression
to go up, but you play a down court progression. And then how does that impact the emotions?
It's like, oh, well, it seems like it's kind of picking randomly, but all the happy songs
kind of start to sound the same. So it's really cool to watch children sort of do this
less structured. Like, you know, it's not bright, long answer. It's how does it sound
and they're making music. And then they get up and they play a class orchestra. And then
we turn the tablets off with the rest of the activity after all of that stimulation.
Yeah. So to be clear in this, this third concept, how are you getting at the AI element
of what's happening? So examples of this AI come up. Like, if you look at some of Google's
AI experiments, they have this piano where you can play music along with a computer. But
the question is, how does that computer know what to play? And so in this activity, children
are actually setting parameters for how the computer should change the song to make it
sound a particular way. So if I give you, if they give the robot rather an input with
three notes, C-D-E, and they tell it to make it faster and happier than the robot should
return something according to the parameters faster. And maybe it'll go up C-E-G, like
even higher than the child's output. So they start to see how they can use AI to create
and to create new things. And then you mentioned previously the, some of the surveys you did
before and after, was that before and after children go through this curriculum? Are there
additional observations that you made about their experiences and what they've learned
about having gone through this curriculum beyond what we've already talked about? Yeah. So
there was the before and after about how children feel about AI and about robots. I also did
a before and after about how children feel about engineers. So one of my, I guess, pet
peas as an engineer is that, you know, there's a lot of emphasis on science and mathematics
and STEM, but often technology and engineering is a lot harder to do and so it gets less
attention. So as I went through the curriculum, I was hoping that children would have a better
sense of what engineers do and why engineering is fun. And unfortunately, they did it. And
I think that, you know, a lot of that is because it was a very new concept to them. So to
tell a hilarious story, the first thing that I went in, I was like, okay, who here knows
who an engineer is and, you know, in this classroom of 20, like two children raised their hand.
And I was like, okay, that's not good. We have to do better than that. And so I pointed
to one of the children and I said, okay, you tell me, what is an engineer? Tell us all.
He's like, an engineer is someone who drives a train. And I was like, like, we're really,
really far further than I even thought we were. So, you know, part of doing this research
that I find, you know, like personally enjoyable is that I get to say, well, I'm an engineer.
I'm an engineer because I build things and I build things to help people and starting
to have children, you know, think about that as a different new career path. I kind of
wish going back that I had built more of that into this curriculum that I built. So,
you know, these activities were fun and they were playing games. But at the end of the
day, they didn't get to see how the things they were building could be useful or how they
could help other people or how they could bring joy to other people. And I think that's
why you know at the end when I was like, okay, who wants to be an engineer? I still got
crickets because it's like, all right, we need to do a better job of helping children
sort of like see themselves as this, but also see the value of it in society. And then
also just, like I said, I did a sort of AI assessment. So how much did children learn
about these things? The AI assessment was like 10 questions, all about the different
activities. And some of them are kind of tricky. It was like, I think I mentioned before,
if you only teach the robot about good foods, where will it take you to chocolate goes?
For five-year-old, you're like, of course, everyone knows chocolate's unhealthy, but it's
very difficult for them to see like, okay, wait, but this AI algorithm only knows foods
that I taught it, only foods that I've labeled. So it'll always use those labels to make
its guesses. So it's really cool to see like a lot of children start to get those things
right because it kind of like blew the developments of psychology literature, you know, out of
the water. They were like, I'm not sure if children could do this kind of reasoning yet.
I'm like, no, they did it. It was awesome.
That's fantastic.
Yeah. So yeah, anyways, 10 questions. Some of them a bit tricky. And I think the median
score was like 70%. So I mean, obviously, we shouldn't assess children to have a lead.
That's probably not healthy for them, but they understood a good amount of what was presented
in front of them. And I think that's really encouraging and important. It's, I mean, the
same with like early computer science education. It was very easy to say children can't understand
this is too complex, but the way that something is designed, it can be made accessible to
children. So, you know, right now I'm working on a deep reinforcement learning activity.
So pretty much we're going to build agents that can play snake. So first, we're going
to hand code it. And then we're going to use a simple neural net where we like give
it a bunch of examples. And then we're going to have it do deep learning. And I'm building
very confident that these children can understand it because, you know, if you just are able
to break something down enough, they can get it. So if you're a deep RL person, I'm going
to have some five year olds coming for your job. Pretty. So get ready.
Nice. Nice. This is awesome work. Where do you go from here? So this was really the center
of your master's thesis. Where do you see it going beyond that?
There's so many different things that I want to do and so much work to be done. So some
really things that are going on that there are others in my lab who I was kind of like
the person to go and try this and see if it works or not. So now that it works, other people
in my lab are also trying out their own experiments. One of my lab mates, Athena is doing this work
around, you know, when children are learning with AI, how can that impact their creativity?
So they're not just learning about AI anymore. They're also learning to be more creative
and to be explorative as they're learning, which will have like huge benefits for them,
you know, beyond just learning a particular skill. Another student in my group, Blakely,
not student in my group, like I'm their professor. Another one of my lab mates, Blakely is working
on AI ethics curriculum. So really helping children be able to understand the ethics behind
every AI decision so that they can critically evaluate the things that are on them. But
also when they're building things, you know, why teach children to build something if
they don't know how to build it ethically. Like at the same time, they should be thinking
about both of these things. So I'm really excited about that work. Personally, I've gotten
a lot of feedback from teachers like, this is great. I have no idea about anything
that they had. So can you teach me? So I'm trying to figure out the problem of how can
we actually make this something that teachers can like use and feel empowered to use and
not scared of so that it can really get into classrooms and get into the spaces and
also more that I used to work in. And then I think also just making more cool activities.
In my dream of dreams, this will become like this big online platform and children everywhere
can learn about AI and ways that are meaningful to them. So you know, there has to be a lot
more content behind it beyond these three activities. What other things can children learn
and what are other metaphors that make sense for them, right? So yeah, that's all the
things I'm going to do. Yeah. Awesome. Awesome. Are there things that you have identified
that you need? Meaning if there's, you know, some potential partner out there that,
you know, someone in our listening community might, you know, be connected to anything
come to mind in that regard? I mean, yes. I can plug for things. So I think one thing
that would be really awesome is to have an AI person, somebody feels comfortable with
AI who's really passionate about teaching this, who I can sort of help get started with
their own activities. So I'm doing that with teachers right now and I think the biggest
problem is that they're not comfortable with AI and there's a lot of work that I have
to do to get them there. So I'm wondering how might it be different if I take an AI person
and start to give them tools to be teachers? That would be really cool. Also, if you kind
of just want to chime things out with your kids and experiment and ask questions, some
of the papers that are linked in the website that we have have actual AI resources that
parents can go on and chime right now. I'm just like short activities based on scratch.
So unfortunately, you have to have a kid between the ages of seven or maybe over there.
But there are already things that exist that people can try that I highly recommend them
try and give a feedback on. Well, Randy, thanks so much for taking
the time to share what you're working on with us is really cool stuff and I'm looking
forward to seeing how it evolves. Oh, thank you. I really appreciate the opportunity.
Thanks. All right, everyone. That's our show for today. For more information on Randy
or any of the topics covered in the show, visit twimmelai.com slash talk slash 225.
For more information on the black and AI series, visit twimmelai.com slash black and AI
team. As always, thanks so much for listening and catch you next time.
