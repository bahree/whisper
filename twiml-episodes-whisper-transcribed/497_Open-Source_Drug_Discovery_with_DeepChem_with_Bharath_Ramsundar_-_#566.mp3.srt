1
00:00:00,000 --> 00:00:04,560
you need to find a way to translate, you know, the computational insight into the

2
00:00:04,560 --> 00:00:08,880
language of chemistry or biology, which kind of means you need to know chemistry and biology

3
00:00:08,880 --> 00:00:10,880
and draw discovery in addition to knowing the AI.

4
00:00:16,240 --> 00:00:21,920
All right, everyone. I am here with Barat Rumsunder. Barat is founder and CEO at DeepFar

5
00:00:21,920 --> 00:00:25,280
Sciences. Barat, welcome to the Twomo AI podcast.

6
00:00:25,280 --> 00:00:27,520
Thank you for having me on, Sam. Excited to be here.

7
00:00:27,520 --> 00:00:32,720
It's great to have you on the show and I'm looking forward to digging in and talking a little bit

8
00:00:32,720 --> 00:00:38,640
about your work on deep learning for molecular design to get us started once you share a little

9
00:00:38,640 --> 00:00:42,720
bit about your background and what kind of caught your interest about that field.

10
00:00:42,720 --> 00:00:48,080
Yeah, for sure. So a little bit of background about me, I did my PhD at Stanford a few years ago,

11
00:00:48,080 --> 00:00:53,040
worked with VJ Pandey's group at the time. So my, you know, training before then I had been as

12
00:00:53,040 --> 00:00:59,920
a software engineer and pure math person. So I was really, you know, when I started at Stanford,

13
00:00:59,920 --> 00:01:04,800
I kept passing these posters and all that had all these crazy pictures and molecules on them outside

14
00:01:04,800 --> 00:01:09,360
VJ's lab. So I kind of went in one day and was like, oh, let me just talk to these people and

15
00:01:09,360 --> 00:01:14,480
ended up clicking. So we decided to work together. A lot of the work I did there was in applying to say

16
00:01:14,480 --> 00:01:20,000
my previous background, working with software engineering and mathematics to the problem of

17
00:01:20,000 --> 00:01:26,720
molecular design and drug discovery. So I started an open source framework called DeepKem that has

18
00:01:26,720 --> 00:01:31,520
grown since I think we're now probably one of the most popular open source platforms for drug

19
00:01:31,520 --> 00:01:38,240
discovery out there. I also started a benchmark suite called molecule net which helped establish

20
00:01:38,240 --> 00:01:44,160
standard benchmarks for designing new molecular algorithms. That's been widely used in academia and

21
00:01:44,160 --> 00:01:49,680
in the industry. Since then after leaving Stanford, I co-founded a startup in the crypto space.

22
00:01:49,680 --> 00:01:55,600
I worked on that for a couple years but then decided to come back to working on biotech and medicine

23
00:01:55,600 --> 00:02:00,880
discoveries. So the last few years I've been working with different biotech and pharma companies

24
00:02:00,880 --> 00:02:06,480
on getting AI into their drug discovery process. So that's kind of the the heart of my new company

25
00:02:06,480 --> 00:02:12,240
Deep4 sciences. Awesome. Awesome. What do you see as some of the big challenges that the drug discovery

26
00:02:12,240 --> 00:02:18,320
companies are having as they try to incorporate AI into that process? That's it's a great question.

27
00:02:18,320 --> 00:02:23,840
I think there's a whole range of issues like starting at the very basic. Oftentimes IT setup

28
00:02:23,840 --> 00:02:27,920
is not, you know, unable to handle this. You have to think about, all right, do we get up on

29
00:02:27,920 --> 00:02:33,040
cloud? Many companies are transitioning to cloud so that partly is starting to be taken care of

30
00:02:33,040 --> 00:02:38,400
but it's not a core competency. I think in many of these firms, you often see like external

31
00:02:38,400 --> 00:02:44,800
consultants who are running the IT. So it can be an early situation. Other things I would say,

32
00:02:44,800 --> 00:02:51,280
there's just I think things like pay scale and miscaps between, you'll see very talented senior

33
00:02:51,280 --> 00:02:56,400
biologists getting paid less than a fairly junior developer would make at a tech company,

34
00:02:57,040 --> 00:03:03,280
which it's a it's a hard problem. So I think attracting talent, there's a good sound that you're

35
00:03:03,280 --> 00:03:07,840
working on what you could say are arguably more meaningful challenges trying to find medicine,

36
00:03:07,840 --> 00:03:12,480
but you also have to make that make greater sense for people. So I think a lot of these firms

37
00:03:12,480 --> 00:03:19,200
are still struggling to hire and build out their top tier AI talent. And I think that this will

38
00:03:19,200 --> 00:03:24,720
eventually begin to find a medium ground, but for now I have several friends who are all looking

39
00:03:24,720 --> 00:03:30,320
for basically the same type of candidate and they're also looking as far as I know. So it's

40
00:03:30,320 --> 00:03:34,560
definitely a challenge there, but university programs are starting to pick up the slack. I'd say

41
00:03:34,560 --> 00:03:39,360
other challenges. It's, you know, how do you mesh in these systems in well with human scientists?

42
00:03:39,360 --> 00:03:45,200
So I would say the AI is not a replacement for an expert human team by any means, but you need

43
00:03:45,200 --> 00:03:51,360
to find ways to have the human teams and the scientific teams work together in a complementary

44
00:03:51,360 --> 00:03:58,320
fashion. This can be really hard. Like as I'm sure you've heard from your other data scientist,

45
00:03:58,320 --> 00:04:03,520
a guest like it's a state communication problem, you know, the computational insight into the

46
00:04:03,520 --> 00:04:07,920
language of chemistry or biology, which kind of means you need to know chemistry and biology

47
00:04:07,920 --> 00:04:13,840
and drug discovery in addition to knowing the AI, which makes us a bit of a hard feel to get into.

48
00:04:13,840 --> 00:04:16,240
But I think it's worth it. I think it's been a lot of fun.

49
00:04:16,880 --> 00:04:25,360
At the highest level, the promise of AI for drug discovery is just that that some AI will be

50
00:04:25,360 --> 00:04:32,560
able to spit out drugs for us that are effective at solving medical challenges. Tell us a little bit

51
00:04:32,560 --> 00:04:38,160
about, you know, at a lower level of granularity. Like where is the innovation frontier now? And

52
00:04:39,440 --> 00:04:47,120
if all goes right in efforts like yours, you know, what's the promise for AI in the near term

53
00:04:47,120 --> 00:04:52,240
in this field? It's a great question. And I would say divide this field into two parts.

54
00:04:52,240 --> 00:04:56,240
The first I would say is machine learning for chemistry. And the second is machine learning

55
00:04:56,240 --> 00:05:01,920
for biology. I think machine learning for chemistry has made a lot of strides. Like you see,

56
00:05:01,920 --> 00:05:05,760
like a lot of top-tier conferences, like I clear recently announced they had a

57
00:05:06,320 --> 00:05:11,840
ML for drug discovery and molecules. Track on Europe's has had a standalone workshop for a few years.

58
00:05:12,720 --> 00:05:17,920
I think that there's a lot of open packages like DeepCam. There's DGL Life Sciences from Amazon.

59
00:05:18,560 --> 00:05:24,160
And a few others that really have started to support this field. I would say there's still

60
00:05:24,160 --> 00:05:30,480
challenges in generating molecules effectively, but say predicting properties in molecules,

61
00:05:30,480 --> 00:05:34,880
say analogous to predicting properties of images. Is there all to solve task? But it's an

62
00:05:34,880 --> 00:05:42,880
increasingly straightforward task. The challenge I think is still working at the low data setting.

63
00:05:42,880 --> 00:05:48,960
So unlike other parts of the tech industry, you can't have human annotators create data.

64
00:05:48,960 --> 00:05:53,760
You need to have some type of experimental output actually coming from either a trained lab tech

65
00:05:53,760 --> 00:05:58,400
or robot that's been very properly configured. So we're figuring out how to get

66
00:05:58,400 --> 00:06:04,000
transfer learning working, how to get low data methods, meta-learning. Working I think is

67
00:06:04,000 --> 00:06:08,880
the real frontier. Lots of cool papers like people learning things like contrasts of learning,

68
00:06:08,880 --> 00:06:15,280
looking at the 3D structure, using transformers. There's a whole range of papers that are exploring

69
00:06:15,280 --> 00:06:19,760
this. But I'd say that's the frontier right now. The basics work, but how do we make this work in

70
00:06:19,760 --> 00:06:24,000
like practical settings where there's a lot much data. The secondary machine learning for biology,

71
00:06:24,000 --> 00:06:29,840
I think, is much more mysterious. I would have said that there weren't really any successes until

72
00:06:29,840 --> 00:06:39,600
deep-mind announced alpha-folds too. Alpha-fold 2 is really, I think, made a dramatic difference

73
00:06:39,600 --> 00:06:47,440
in this field where you've taken, I'd say, a fundamental problem of biology, you know,

74
00:06:47,440 --> 00:06:51,760
predicting the structure of proteins. And this has been open for about 50, 60 years now.

75
00:06:51,760 --> 00:06:59,760
And been able to push that into a place where you could argue it's even solved. I think this

76
00:06:59,760 --> 00:07:04,880
just really had a sea change in how scientists and biologists see AI methods. Whereas before,

77
00:07:04,880 --> 00:07:08,640
it was something that was kind of exotic and, well, that doesn't really work. Now it's like,

78
00:07:08,640 --> 00:07:12,480
oh, okay, they just whacked this problem out of the ballpark. We need to pay attention.

79
00:07:13,200 --> 00:07:19,520
But besides that one place, I would say that AI and bios still very early stage. To give an

80
00:07:19,520 --> 00:07:25,920
example of the fundamental challenge, like take a disease like Alzheimer's. The what you hope

81
00:07:25,920 --> 00:07:31,680
the AI would tell you is that, okay, the root cause of Alzheimer's is X. So you just need to

82
00:07:31,680 --> 00:07:37,920
design a molecule that modulates X somehow. Then bam, you'll cure Alzheimer's. We wish we knew that,

83
00:07:37,920 --> 00:07:41,920
but then we see all these failed clinical trials for Alzheimer's because that's an extraordinarily

84
00:07:41,920 --> 00:07:45,840
difficult problem. You're trying to untangle, you know, the history of evolution itself in the human

85
00:07:45,840 --> 00:07:51,920
body. So it's going very deep to the heart of medicine, I would say. And that's beyond today's AI.

86
00:07:51,920 --> 00:07:57,520
I think the best we can hope is to create better tools that make our best doctors and biologists

87
00:07:57,520 --> 00:08:03,040
more capable of handling these problems. So I'd say ML for chemistry much further along,

88
00:08:03,040 --> 00:08:07,440
closer to where, say, things like images are, ML for biology, fundamental science. I think

89
00:08:07,440 --> 00:08:14,240
it's a open field and just beginning to be explored. Got it. Got it. Tell us about the origins of

90
00:08:14,240 --> 00:08:21,120
deep chem. Yeah, absolutely. So back during my PhD, I was fortunate enough to do an internship

91
00:08:21,120 --> 00:08:27,040
with the Google accelerated scientists team at Google. So we use a early version of their

92
00:08:27,040 --> 00:08:32,000
internal AI system called disbelief. This is a pre-tensor flow system. And we built I think a

93
00:08:32,000 --> 00:08:37,840
really cool model and explored, say, large scale training on a bunch of data we gathered to do a

94
00:08:37,840 --> 00:08:44,320
multitask deep learning in the system. And this worked pretty well. And I was really excited. We got

95
00:08:44,320 --> 00:08:50,240
a paper out. We had it written up in the Google blog. A lot of people are excited. But as with all

96
00:08:50,240 --> 00:08:54,400
good things and the internship ended, I came back to grad school and it's like, oh, well, what's I

97
00:08:54,400 --> 00:09:00,080
don't have my core research discovery to work with. So at the time, Kyrsten Tionno just really

98
00:09:00,080 --> 00:09:06,160
started to come online. So I hacked together a few scripts to try to replicate the original paper.

99
00:09:06,160 --> 00:09:11,200
I got most of the way and wanted to share it with some friends. We just put it up on I just put

100
00:09:11,200 --> 00:09:16,160
it up on GitHub. And from there, it's sort of grown organically. So we attracted a few talented

101
00:09:16,160 --> 00:09:23,120
early contributors. We made the licensing permissive MIT rather than a more restrictive license.

102
00:09:23,120 --> 00:09:28,160
So we had some early corporate contributors come in really help out a number of grad students

103
00:09:28,160 --> 00:09:34,240
put projects and papers into there. We're also I think fortunate enough to be able to participate

104
00:09:34,240 --> 00:09:40,480
in Google Summer of Code through the Open Chemistry collaboration. We've been participating

105
00:09:40,480 --> 00:09:44,320
in Google Summer of Code. I think for three years now, had a number of excellent students.

106
00:09:45,040 --> 00:09:49,520
One of the big things that we've done is program allows students to come work on your open source

107
00:09:49,520 --> 00:09:54,720
project. Yes, that's correct. And Google will pay them for their time, which I think is

108
00:09:54,720 --> 00:09:59,440
a tremendous advance. You see all these kids who couldn't otherwise like participating in open

109
00:09:59,440 --> 00:10:05,600
source. One of the nice things we've grown is really a community of, you know, teaching and

110
00:10:05,600 --> 00:10:10,000
documentation. So we have about 30 tutorials really laying out the basics of the science.

111
00:10:11,520 --> 00:10:16,240
Also on the way, we ended up writing a book with O'Reilly deep learning for the life sciences,

112
00:10:16,240 --> 00:10:21,280
which introduces a lot of the techniques in this field and how to use deep Ken with them.

113
00:10:21,280 --> 00:10:25,600
So I think we've tried to put a lot of effort into growing a friendly collaborative open

114
00:10:25,600 --> 00:10:31,680
community. And I think that's really drawn people to work with us. A lot of the people who do AI

115
00:10:31,680 --> 00:10:36,880
in this industry, they often get, I think, their first taste of AI in this field through deep

116
00:10:36,880 --> 00:10:41,280
Ken. So I think that's something we want to do more of. So we continue working on it. We just had

117
00:10:41,280 --> 00:10:46,800
a new release come out last week. We had 29 contributors on this release. So we've got a,

118
00:10:46,800 --> 00:10:51,840
I think a vibrant open source community that's working to really build out better tools.

119
00:10:51,840 --> 00:10:57,360
And what are the specific problems that deep Ken solves for practitioners working in the field?

120
00:10:57,360 --> 00:11:02,080
So I think one of the big things that deep Ken does is we effectively serve as a model

121
00:11:02,720 --> 00:11:07,360
zoo slash repository. So we take a lot of these models that come out in the literature,

122
00:11:08,000 --> 00:11:13,360
you know, academics do great work. They invent a new technique. They put it up on GitHub. It's

123
00:11:13,360 --> 00:11:18,160
pretty clean code. But you're not incentivized really to go further beyond that. That's sort of where

124
00:11:18,160 --> 00:11:22,560
we come in. We say, okay, well, we need unit tests. We need to stabilize this. We need to make

125
00:11:22,560 --> 00:11:28,560
sure that this can be maintained. So we wire it into our CI system. We get test put up. We get

126
00:11:28,560 --> 00:11:34,080
now type checks. We get to everything linted. And at the end, we have a stable implementation of

127
00:11:34,080 --> 00:11:39,760
the model. And we have an extensive CI that tests, you know, Windows, Mac, Linux, there's about

128
00:11:39,760 --> 00:11:46,720
600 700 unit tests, a lot of testing on machine learning. How to stabilize machine learning methods?

129
00:11:46,720 --> 00:11:52,720
So we have a robust production grade implementation that can then be used by downstream industry

130
00:11:52,720 --> 00:11:57,840
and also academic practitioners. So we see ourselves as, you know, picking up from where

131
00:11:58,560 --> 00:12:03,440
academia often leaves off. We do have a number of students also interested in designing new models

132
00:12:03,440 --> 00:12:08,880
of their own. So we do have research collaborations with academics. But I think our mission really is

133
00:12:08,880 --> 00:12:15,840
service a high quality repository of good good models and techniques. What are some of the most

134
00:12:15,840 --> 00:12:22,160
popular models today on DeepCam? I would say the most popular historically has been the Graph

135
00:12:22,160 --> 00:12:27,520
Convolution Network. So we had, I think, one of the first quality implementations of a Graph Convolution

136
00:12:27,520 --> 00:12:32,960
Network for molecules. This was before PyTorch Geometric and DGL. In the last few years,

137
00:12:32,960 --> 00:12:38,320
we've increasingly shifted to using DGL and and PyTorch Geometric to underpin our Graph Convolution.

138
00:12:38,320 --> 00:12:43,120
So we have an extensive collection still, but a lot of them are, say, rappers or extensions

139
00:12:43,120 --> 00:12:50,240
around these other frameworks. More recently, I think we've been expanding into, we have a number

140
00:12:50,240 --> 00:12:54,880
of new models, say, at the frontier and material science. People there are just really beginning to

141
00:12:54,880 --> 00:12:59,600
embrace the deep learning mindset. So some newer models there, as I was talking to students this

142
00:12:59,600 --> 00:13:05,840
morning, who's adding a Graph Convolution variant for predicting material structure this morning.

143
00:13:06,400 --> 00:13:11,840
Another frontier, I think, is actually solving partial differential equations. So the PDEs,

144
00:13:11,840 --> 00:13:16,960
as I recall, they're just critical in many fields of engineering and physics. Let's you solve

145
00:13:16,960 --> 00:13:21,600
these complicated systems. So we had a very talented Google Summer of Code student this summer.

146
00:13:22,160 --> 00:13:27,760
Add in a first deep learning PDE solver. It's called the Physics Inspire Neural Network.

147
00:13:28,400 --> 00:13:32,800
It's still very alpha. I think the API needs a lot of work, but it's a great proof of concept.

148
00:13:33,360 --> 00:13:37,680
And the dream of this entire field is, can you solve these high-dimensional PDEs,

149
00:13:37,680 --> 00:13:43,680
I was talking to some engineers at GM a while back. And it takes them, I think, 18 hours to be

150
00:13:43,680 --> 00:13:49,200
able to solve the fluid flow equations around like a car structure. And they can't really do iterative

151
00:13:49,200 --> 00:13:54,320
design. Whereas if you had a fast approximate solver, you could potentially try out these radical

152
00:13:54,320 --> 00:13:59,760
designs. Click a button and have the model give you approximate answer in 30 seconds and then

153
00:13:59,760 --> 00:14:06,000
just keep designing. When these tools mature, I think they'll enable these types of radical

154
00:14:06,000 --> 00:14:10,880
innovations, but that's probably several years off. There's a lot of fundamental work. So

155
00:14:10,880 --> 00:14:16,000
we see our role as continuing to maintain the core, keep it stable for production use,

156
00:14:16,000 --> 00:14:20,240
but also grow out at the frontiers, adding new scientific models and areas.

157
00:14:20,240 --> 00:14:29,680
What's the relationship between DeepCam as a repository and DeepCam as an API? When describing DeepCam,

158
00:14:29,680 --> 00:14:38,240
you describe primarily this model repository, but those models are built using a DeepCam library.

159
00:14:39,120 --> 00:14:43,920
Can you talk a little bit about the library and the capabilities that enables and

160
00:14:43,920 --> 00:14:47,920
my folks use it as opposed to other lower level libraries?

161
00:14:47,920 --> 00:14:52,400
Oh, yes, that's an excellent question. So the DeepCam library itself is, say,

162
00:14:53,200 --> 00:14:59,440
designed to be one level higher up than, say, the underlying tools like PyTorch or TensorFlow.

163
00:14:59,440 --> 00:15:04,960
So for PyTorch or TensorFlow, you often, say, don't know about scientific file formats.

164
00:15:04,960 --> 00:15:09,280
You don't know about how to featureize scientific data sets in a meaningful fashion.

165
00:15:09,280 --> 00:15:16,000
Molecular data sets come in a hole. The prominent open source package that loads these

166
00:15:16,000 --> 00:15:21,760
file formats is called Bable. That should give you some idea of the diversity of formats that

167
00:15:21,760 --> 00:15:26,320
just kind of rest out there. You need to be able to slurp in all these formats. You need to be able

168
00:15:26,320 --> 00:15:31,520
to transform them into either vectors or graphs that you can use in machine learning.

169
00:15:31,520 --> 00:15:35,520
Oftentimes, there are various scientific transformations. You need to apply maybe

170
00:15:35,520 --> 00:15:40,800
types of normalization. There are metrics that you often use to measure these models that,

171
00:15:40,800 --> 00:15:46,320
again, require you to be scientifically aware rather than using it out of the box metric.

172
00:15:46,320 --> 00:15:51,040
So I think where we see a role is coming in is trying to provide these scientifically aware

173
00:15:51,040 --> 00:15:55,520
layer on top. So our goal really is not to try to reinvent the wheel. If something's in

174
00:15:55,520 --> 00:15:59,280
PyTorch geometric or PyTorch or what have you, we just kind of use that very happily.

175
00:16:00,000 --> 00:16:05,440
And part of our extensive collection of tutorials is walking through how do you use DeepCam

176
00:16:05,440 --> 00:16:10,800
with X other library. But there are just cases where something doesn't make sense for the broader.

177
00:16:10,800 --> 00:16:15,360
There's some, what is relatively niche to the broader world way of processing molecules,

178
00:16:15,360 --> 00:16:19,760
but for us is really interesting. That goes in DeepCam. Because that's part of our core mission

179
00:16:19,760 --> 00:16:24,400
or the same for a material. So it really is like, I think the dividing line is,

180
00:16:24,400 --> 00:16:33,040
this is scientific AI tool. And second, is there, if there is already a high-quality open-source

181
00:16:33,040 --> 00:16:37,680
package and community that maintains this, can we just use them? And if the answer to both of

182
00:16:37,680 --> 00:16:42,160
these questions comes out, then we added to DeepCam. Otherwise, we say, hey, why not add a

183
00:16:42,160 --> 00:16:48,000
tutorial that teaches you how to use DeepCam with this other tool to be able to do this right way?

184
00:16:48,000 --> 00:16:51,600
One of the interesting conversations we've been having on the podcast recently,

185
00:16:51,600 --> 00:17:00,160
primarily in the context of reflections on the past year in different areas within machine learning

186
00:17:00,160 --> 00:17:06,080
is kind of this maturing of the field. For example, in natural language processing,

187
00:17:06,720 --> 00:17:13,760
there are so many models off the shelf that a practitioner can take without having to

188
00:17:13,760 --> 00:17:24,080
create a new architecture, for example. And I'm curious about that the state of the field with

189
00:17:24,080 --> 00:17:30,080
regard to molecular design, it sounds like by virtue of the fact that you are primarily offering

190
00:17:30,080 --> 00:17:37,680
a repository, there's a great opportunity for reuse. But I'm wondering if you can elaborate on

191
00:17:37,680 --> 00:17:47,360
kind of this innovation frontier or the extent to which new problems that people want to solve

192
00:17:47,360 --> 00:17:54,160
are solved best by kind of fundamentally pushing machine learning or taking things off the shelf

193
00:17:54,160 --> 00:18:00,160
and implementing them and applying them to their data. How do you see that evolving now for

194
00:18:00,880 --> 00:18:05,920
DeepCam and the molecular design field? This is a great question and something we've been actively

195
00:18:05,920 --> 00:18:11,840
researching for a few years now. So we have this open source consortium within DeepCam,

196
00:18:11,840 --> 00:18:17,680
like a subgroup that works on a series of models called Converta. So Converta is, as you might

197
00:18:17,680 --> 00:18:26,560
guess, a variant. It is a type of transformer. We trained a model on a number of smile strings,

198
00:18:26,560 --> 00:18:33,360
which is the textual representation of a molecule. And you just kind of use a standard NLP style

199
00:18:33,360 --> 00:18:39,520
technique. So Converta one was intriguing, but not really performant, didn't really match the

200
00:18:39,520 --> 00:18:44,240
standard methods out there. We just very recently at the Alice machine learning from molecules

201
00:18:44,240 --> 00:18:51,520
workshop in December put out Converta 2. Converta 2 is now, I would say comparable with the latest

202
00:18:51,520 --> 00:18:56,560
graph convolutional methods, but it's a lot of work and it gets close to the same results,

203
00:18:56,560 --> 00:19:00,560
so I think we have a ways to go. So all the Converta models, we've actually put them up on the

204
00:19:00,560 --> 00:19:05,680
Hugging Face model hub, so you can download those, I think they've been used by actually a

205
00:19:05,680 --> 00:19:10,560
pretty large community people. This is all in the DeepCam org within Hugging Face.

206
00:19:12,240 --> 00:19:16,880
So we do think this is an area where there's going to be major growth. So far, what I would say is

207
00:19:16,880 --> 00:19:22,480
that we are less mature than, say, for natural language processing, things don't work out at the box.

208
00:19:23,600 --> 00:19:29,280
We hope that when we knock on what get Converta 3 out there, maybe that'll take one more step

209
00:19:29,280 --> 00:19:34,400
towards making this a general purpose technology, but as of now, I think it's a cool research

210
00:19:34,400 --> 00:19:40,720
direction. We spent a lot of time thinking about it. We have a very nice team with kind of researchers

211
00:19:41,840 --> 00:19:46,640
who work with DeepCam and also Revery Labs and UC Berkeley and a couple other places

212
00:19:47,360 --> 00:19:53,920
who've been partnering with us. But for now, we hope to see the Hugging Face style off the shelf

213
00:19:53,920 --> 00:19:59,200
models, but we've not yet gotten that to work, where we were able to recommend that. Whereas the

214
00:19:59,200 --> 00:20:04,080
GraphCon, Lusional Methods are always in this field, the random forest, you know, just sometimes

215
00:20:04,080 --> 00:20:08,800
you pull it off, it just works great. I think we'll get there a few more years.

216
00:20:09,440 --> 00:20:16,160
In addition to DeepCam, you've also worked on a molecule net, which is a data set and a benchmark

217
00:20:16,160 --> 00:20:21,920
suite around molecular design. Can you talk a little bit about that in its origins?

218
00:20:21,920 --> 00:20:26,480
Yep, for sure. So, you know, going back to when we started this DeepCam project,

219
00:20:27,120 --> 00:20:31,920
we put kind of these methods out there, and there are a bunch of new methods starting to come

220
00:20:31,920 --> 00:20:38,160
online. And the question naturally was, you know, how do we compare these methods against each other?

221
00:20:38,160 --> 00:20:44,160
So for a long time, I'd been, you know, inspired really by ImageNet. So I was at Stanford at the time,

222
00:20:44,160 --> 00:20:48,800
I kind of joined, right as the ImageNet paper came out. And I could just see the transformative

223
00:20:48,800 --> 00:20:55,600
impact it had on image processing algorithms. So I'd had this vision of, you know, let's try to

224
00:20:55,600 --> 00:21:00,320
do something similar for molecules. And DeepCam provided a platform. So I partnered with

225
00:21:00,320 --> 00:21:07,360
a kind of very talented other student, Michael. He and I put together the kind of core of molecule

226
00:21:07,360 --> 00:21:13,840
net. So we implemented about, say, 15 algorithms in DeepCam that were prominent in the community

227
00:21:13,840 --> 00:21:20,160
at the time. We added about 15 data sets. We ran that matrix roughly of a lot of experiments

228
00:21:20,160 --> 00:21:25,120
right there. We burned up some of the clusters for a while. And yeah, we tried to put out, I think,

229
00:21:25,120 --> 00:21:30,080
quality benchmarks. And we had recommendations on how do you do a trained valid test split,

230
00:21:30,080 --> 00:21:34,720
and that's chemically aware. And I think it's seen a lot of uptake by the community. I'd say it's

231
00:21:34,720 --> 00:21:38,720
also, you know, it's been a few years, like four years at this point, I think, since we put out

232
00:21:38,720 --> 00:21:42,560
the paper. So starting to show its age a little bit, there's a couple of really cool projects.

233
00:21:42,560 --> 00:21:48,400
There's a therapeutic data commons now that MIT has just put out that extends molecule net with

234
00:21:48,400 --> 00:21:56,000
a number of new new data sets that they've gathered and curated. We are working to extend molecule

235
00:21:56,000 --> 00:22:01,280
net ourselves. We have a successor project that's slowly winding its way out the door and that

236
00:22:01,920 --> 00:22:06,400
knock on wood. Maybe this year we'll get out the door for lucky. But we have integrated

237
00:22:06,400 --> 00:22:12,080
molecule net from the earliest days into DeepCam. So the way a lot of people get access to the

238
00:22:12,080 --> 00:22:18,800
data that they do, you know, input DeepCam and the DeepCam.MoleCulnet.loadX4X is whatever data set.

239
00:22:19,440 --> 00:22:26,320
This is kind of modeled on the psychic learn integrated data sets. So I think that we continue

240
00:22:26,320 --> 00:22:31,040
to support this. We continue to add new data sets. We just added a couple, I think, a couple

241
00:22:31,040 --> 00:22:36,640
months ago. But it's again, it's a long-term effort to try to build out a critical mass of data

242
00:22:36,640 --> 00:22:43,280
that can further the science here. Can you talk a little bit more about developing what you

243
00:22:43,280 --> 00:22:51,440
described as a chemistry-aware validation process? So this is a great question. So oftentimes in

244
00:22:53,120 --> 00:22:57,520
well, at least in the earlier papers on machine learning, you do something like a random split

245
00:22:58,160 --> 00:23:05,360
of your data. And this is mostly fine when you're building kind of toy models. But the downside is

246
00:23:05,360 --> 00:23:10,320
in the real world this often doesn't generalize. To use an example from self-driving car world,

247
00:23:10,320 --> 00:23:16,960
it's really the long tail of a squadron of geese fly across the road. Was that in the training

248
00:23:16,960 --> 00:23:21,760
data? Probably not. But you want to test really on the crazy examples. It's something similar

249
00:23:21,760 --> 00:23:26,880
molecules. You're most interested in predicting the structure of molecules that you haven't seen.

250
00:23:26,880 --> 00:23:32,480
So what you want to do is when doing train valid tests, you often want to do a splitting of the data

251
00:23:32,480 --> 00:23:37,520
where the validation and test sets are drawn from chemical scaffolds, as the term is,

252
00:23:37,520 --> 00:23:41,840
that are far away from the scaffolds that you saw in training. And this gives you a better

253
00:23:41,840 --> 00:23:47,200
estimation of the true generalizability of the model. So one of the things we did in molecules

254
00:23:47,200 --> 00:23:51,040
is probably one of the most used parts of deep chemists. We introduced something called the scaffolds

255
00:23:51,040 --> 00:23:59,120
butter. This wrapped the an existing algorithm by Beemis and Mirko. And that was in the Ardekin

256
00:23:59,120 --> 00:24:05,680
library, put it in a nice usable format for people. So I think this is one of our, you know,

257
00:24:05,680 --> 00:24:10,160
little bit, a little part of the project, but maybe one of the most used pieces actually.

258
00:24:11,520 --> 00:24:14,480
So there was an existing library that allowed you to

259
00:24:15,760 --> 00:24:21,360
compare the scaffolds for different molecules and you were able to use that as part of

260
00:24:21,920 --> 00:24:27,200
creating test transplants. Yep. And I think I would definitely give a shout out to Ardekin,

261
00:24:27,200 --> 00:24:32,080
which I think is probably the foundational open project in chemo and formatics. So they kind

262
00:24:32,080 --> 00:24:37,040
of established the machinery that made it possible for us to build on them. They're

263
00:24:38,480 --> 00:24:42,000
probably one of the most important scientific projects that you may or may not have heard of.

264
00:24:42,640 --> 00:24:45,200
So they're a really cool project. I recommend checking them out.

265
00:24:45,200 --> 00:24:53,360
Nice. Nice. Yeah. As deep learning is maturing, you know, a few years ago,

266
00:24:53,360 --> 00:24:57,680
a lot of scientific papers were, hey, I heard about this machine learning thing. I'm going to

267
00:24:57,680 --> 00:25:03,040
throw it at my problem and see what happens. You know, the field has been maturing quite a bit.

268
00:25:04,400 --> 00:25:10,720
And we've got libraries like yours that are able to aid researchers and practitioners.

269
00:25:11,440 --> 00:25:18,320
I'm wondering if you can talk a little bit about, you know, broadly how you see machine learning

270
00:25:18,320 --> 00:25:23,360
and the traditional sciences and what you see the future is there. How does it evolve?

271
00:25:24,080 --> 00:25:28,720
I would say that, you know, probably the biggest shift is going to be that most scientists will

272
00:25:28,720 --> 00:25:34,480
probably want to do some machine learning coursework as part of their core training.

273
00:25:35,120 --> 00:25:39,840
So I think as these tools become more and more established, it'll be just a core part of the

274
00:25:39,840 --> 00:25:46,960
scientific toolkit that new scientists have to learn. I'd say increasingly, what I see now is that

275
00:25:46,960 --> 00:25:53,280
there's a lot more creativity in terms of like, okay, we've got the basics down. So the paper isn't

276
00:25:53,280 --> 00:25:57,120
just, you know, take off the shelf thing and apply it here and see what happens, which is a lot of fun.

277
00:25:57,120 --> 00:26:02,160
I think you could sometimes get some real surprises that way, but now you know the basics,

278
00:26:02,160 --> 00:26:06,080
people have written about it. So what do you do that's creative? So I think at times you actually

279
00:26:06,080 --> 00:26:14,800
see these very innovative applications. You know, I would say that one of the areas I'm most interested

280
00:26:14,800 --> 00:26:20,000
in right now as a researcher is the application of deep learning to solving partial differential

281
00:26:20,000 --> 00:26:26,080
equations. And these are, you know, foundational mathematical tools, I think from the 1800s or

282
00:26:26,080 --> 00:26:31,280
even earlier, you could argue. And but the challenges have been we've only really been able to solve

283
00:26:31,280 --> 00:26:38,000
them in relatively restricted cases. Like in the 70s, under these class of algorithms called finite

284
00:26:38,000 --> 00:26:43,040
element methods, that this is what really underpins I think a lot of CAD and other modeling tools and

285
00:26:43,040 --> 00:26:48,560
really pushed the field forward. But we might now be seeing the second revolution where through

286
00:26:48,560 --> 00:26:54,480
these deep learning methods. And the big shift I think is that these earlier class of techniques,

287
00:26:54,480 --> 00:26:58,960
you often had to put down what's called a mesh. So let's say I have a complicated car, you need

288
00:26:58,960 --> 00:27:04,160
to basically, you know, drop grid points on your car and your computer model. So you can like model,

289
00:27:04,160 --> 00:27:08,720
you know, the airflow at that point. Whereas with the deep net, you can now do what's called a mesh

290
00:27:08,720 --> 00:27:12,640
free method. You can just say, Oh, well, I'm not going to worry about that. I'll just have my deep net

291
00:27:12,640 --> 00:27:17,360
approximated. I'll give me your data. Now, there's still a lot of caveats here. I think this is a

292
00:27:17,360 --> 00:27:23,520
new technique. But I think that it's one of the more exciting things. And it's because you have to

293
00:27:23,520 --> 00:27:29,040
really understand the math and the physics of these systems in addition to the deep learning.

294
00:27:29,040 --> 00:27:34,960
That's where I think you begin to see real scientific creativity. I think so. I think there's like,

295
00:27:34,960 --> 00:27:39,760
you know, a long tail of like really cool innovations. But you, it requires people to understand

296
00:27:39,760 --> 00:27:44,560
both sides, you know, it's all enough to just be a, you know, numerical analyst or a machine learning

297
00:27:44,560 --> 00:27:49,600
person or, you know, a car designer, you kind of have to have someone in the room who does all,

298
00:27:49,600 --> 00:27:56,080
uh, each of these things are all of these things. So your company deep forest sciences started out as

299
00:27:57,120 --> 00:28:01,680
vehicle for doing some consulting with the drug discovery companies, but you're moving in the

300
00:28:01,680 --> 00:28:07,440
direction of productization. Can you talk a little bit more about your vision for the company

301
00:28:07,440 --> 00:28:13,920
and your offerings? Yeah, for sure. So, uh, basically a few years ago, I started almost my

302
00:28:13,920 --> 00:28:21,520
happenstance consulting for a few friends who were working. I was like, well, there's all these

303
00:28:21,520 --> 00:28:25,040
open tools. You really need me to come in and help you. And they're like, yes, I was like, okay,

304
00:28:25,040 --> 00:28:30,400
sure. Why not? I've just left my previous company. Then over time, I think it's grown into a

305
00:28:30,400 --> 00:28:35,840
realization there are the systematic challenges, I think, in applying AI to these problems.

306
00:28:36,480 --> 00:28:40,880
One of the biggest challenges I think is that in drug discovery at the end of the day, like,

307
00:28:41,680 --> 00:28:46,720
you as a company in response over putting out a medicine. That's what your stockholders are

308
00:28:46,720 --> 00:28:52,720
therefore. That's what the market rewards or punishes you for. So the amount of time you can

309
00:28:52,720 --> 00:28:57,760
afford as an organization to really put into building world quality software, world class

310
00:28:57,760 --> 00:29:04,720
software is limited. And it should be because that's not what your market is. So I think there's

311
00:29:04,720 --> 00:29:10,800
a niche to really build out quality AI software and partner with companies and let them do what they

312
00:29:10,800 --> 00:29:16,480
are the best at, which is trying to find new medicine and, you know, work with us to help solve

313
00:29:16,480 --> 00:29:23,280
the hard AI problems we have. So we have built a system that we call internally Kyron. It builds

314
00:29:23,280 --> 00:29:29,920
on deep chem. And, you know, we continue to support and help grow the deep chem community.

315
00:29:30,720 --> 00:29:35,840
But we've also, I think, made some extensions to it that I think make it more useful for our

316
00:29:35,840 --> 00:29:41,040
partners. And we're able to take this technology and work with a drug discovery company who's

317
00:29:41,040 --> 00:29:47,040
say, got a therapeutic hypothesis to really passionate about. But maybe they don't really have

318
00:29:47,040 --> 00:29:51,600
the expertise in house to really throw the kitchen sink at it and figure out what all these AI

319
00:29:51,600 --> 00:29:55,520
techniques can do. There's just a dizzying area of things you can do these days, especially

320
00:29:55,520 --> 00:30:00,720
to feel this grown. That's where we come in. Like we have kind of the extensive capabilities of

321
00:30:00,720 --> 00:30:05,680
deep chem. We have Kyron built on top of that. We've worked with many different companies at this

322
00:30:05,680 --> 00:30:11,680
point. We bring that expertise. So you can focus on the biology, the hard problems of human medicine,

323
00:30:12,400 --> 00:30:16,880
discovery, and we can focus on the AI and we can help you get where you need to be. So that's

324
00:30:16,880 --> 00:30:21,200
the vision of the company in our shell. Well, I wish you the best of luck with the company and

325
00:30:21,200 --> 00:30:26,240
thanks so much for taking the time to share a little bit about what you've been up to. Any time,

326
00:30:26,240 --> 00:30:54,640
that's my pleasure and I had a lot of fun.

