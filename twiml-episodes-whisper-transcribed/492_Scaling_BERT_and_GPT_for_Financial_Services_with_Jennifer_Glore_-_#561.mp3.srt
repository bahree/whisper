1
00:00:00,000 --> 00:00:05,680
All right, everyone. I am here with Jennifer Glor. Jennifer is the VP of customer engineering at

2
00:00:05,680 --> 00:00:11,040
San Bonova Systems. Jennifer, welcome to the Twoma AI podcast. Thanks for having me.

3
00:00:11,040 --> 00:00:17,200
I'm really looking forward to digging into our conversation. We're going to go deep on GPT-3

4
00:00:17,200 --> 00:00:23,840
and Transformers in the Enterprise in industries like banking and finance. But before we do,

5
00:00:23,840 --> 00:00:28,240
I'd love to have you share a little bit about your background and how you came to work in AI.

6
00:00:28,240 --> 00:00:34,640
Sure. So I've been at San Bonova Systems now for three years. The customer engineering team

7
00:00:34,640 --> 00:00:39,760
is responsible for the technical customer journey here from pre-sales all the way to

8
00:00:39,760 --> 00:00:45,120
post-sales deployment and customer success. Prior to being at San Bonova Systems, I was at Sun

9
00:00:45,120 --> 00:00:50,320
and Oracle, where one of our founders came from. And I had a varied background there where I

10
00:00:50,320 --> 00:00:57,280
worked with products, partners, customers. The last few positions I had involved engineered

11
00:00:57,280 --> 00:01:04,000
systems and cloud deployments for mission critical applications. So AI was up and coming for some

12
00:01:04,000 --> 00:01:08,640
time. It was an interesting technology and I was itching to get involved in that. And when

13
00:01:08,640 --> 00:01:13,760
the opportunity at San Bonova presented itself to combine my technical expertise with customers,

14
00:01:13,760 --> 00:01:19,440
it made perfect sense. That's awesome. That's awesome. I've been following the company for a while now.

15
00:01:19,440 --> 00:01:27,200
And a lot of my early conversations with the folks on the team there, Marshall, Rodrigo,

16
00:01:27,200 --> 00:01:35,040
and others have been around the hardware vision. Creating a new chip architecture to support

17
00:01:36,240 --> 00:01:42,080
machine learning applications. But more recently, the company has been focused on this

18
00:01:42,080 --> 00:01:48,400
GPT-3 thing. Where did that come from? Give us some context for that part of the journey.

19
00:01:48,400 --> 00:01:55,200
Yeah. So obviously San Bonova is an AI accelerator company and part of that is our own chip and our

20
00:01:55,200 --> 00:02:00,880
own system. But in all honesty, the premise for the company is a combination of both hardware

21
00:02:00,880 --> 00:02:06,960
and software. And hardware is only as good as the software that it runs on. And so we are actually

22
00:02:06,960 --> 00:02:12,800
a software-divined hardware platform. And when the company started four years ago, we had the

23
00:02:12,800 --> 00:02:20,960
mission that for AI workloads, deep neural networks, you need to reimagine what that platform,

24
00:02:20,960 --> 00:02:26,160
both software and hardware should look like for the type of workload that are coming, right?

25
00:02:26,160 --> 00:02:32,160
CPUs and GPUs are doing a great job, but they were built for more traditional workloads in mind.

26
00:02:32,160 --> 00:02:37,280
And when you look at these deep neural networks, compute is important, memory is important,

27
00:02:37,280 --> 00:02:43,200
but how the data flows through the system is extremely important. And models are changing and

28
00:02:43,200 --> 00:02:50,000
new research is being done. And so the ability to reconfigure and have flexibility and map your

29
00:02:50,000 --> 00:02:55,520
software to your hardware is extremely important. So from the very early days, well, we have our

30
00:02:55,520 --> 00:03:02,160
own chip and we have our own system. The software stack has been crucial. And so we have two products

31
00:03:02,160 --> 00:03:08,320
at Samba Nova Systems. One is Dataflow as a service, which packages our underlying hardware and

32
00:03:08,320 --> 00:03:15,120
software product and put services and solutions around that or focuses in natural language processing

33
00:03:15,120 --> 00:03:21,520
and computer vision. And then we also sell a data scale product, which is more just the hardware

34
00:03:21,520 --> 00:03:26,720
and the software for folks who want to control the full lifecycle of AI development themselves.

35
00:03:26,720 --> 00:03:33,600
So that's just getting the racks of the Samba Nova servers plus the software layer on top.

36
00:03:33,600 --> 00:03:40,000
Exactly. So we think of them in two ways. Dataflow as a service is more data-centric and data scale

37
00:03:40,000 --> 00:03:46,240
is more model-centric. So if customers are looking to consume solutions and services, they want to

38
00:03:46,240 --> 00:03:52,720
accelerate their AI journey and get there faster, then they're looking for a service and solution

39
00:03:52,720 --> 00:03:58,400
that's optimized and that's what Dataflow is a service. We provide the service, they bring their

40
00:03:58,400 --> 00:04:05,040
data. If you look at data scale, that's a much more model-centric platform where customers are

41
00:04:05,040 --> 00:04:11,040
researching models, doing a lot of work with models, as far as hyper parameter tuning or other

42
00:04:11,040 --> 00:04:16,240
things, making changes to their models, they control the full lifecycle and that would be the platform

43
00:04:16,240 --> 00:04:23,440
for them. Got it. So in the former case, or rather in the latter case, you're expecting

44
00:04:23,440 --> 00:04:28,000
the customers to be a lot more sophisticated. They're spending a lot of their time in training

45
00:04:28,000 --> 00:04:33,200
and development. In the latter case, it's meant to be more of a you bring data and will

46
00:04:34,480 --> 00:04:41,200
figure some stuff out for you. Exactly. And I'll be in EV. Exactly. For customers who are consuming

47
00:04:41,200 --> 00:04:46,400
Dataflow as a service, we're actually seeing two different types of consumers. So certainly,

48
00:04:46,400 --> 00:04:51,440
there's those customers that are early in their AI journey. They may have data scientists,

49
00:04:51,440 --> 00:04:57,280
but the team is not significantly large. They feel like they're maybe behind or haven't

50
00:04:57,280 --> 00:05:02,400
made a lot of progress on their AI journey. So they're looking to accelerate that. And so they bring

51
00:05:02,400 --> 00:05:08,320
in some solutions from us that helps get them part of the way and then they can focus their team

52
00:05:08,320 --> 00:05:15,040
to build workflows around that. There are other users of Dataflow as a service that actually do

53
00:05:15,040 --> 00:05:20,320
have larger AI teams. They're quite skilled, but it's just the decision of where to focus their

54
00:05:20,320 --> 00:05:26,400
effort. And so if they can purchase pre-packaged solutions from us that help take care of some of

55
00:05:26,400 --> 00:05:32,080
the NLP and CV problems, then they can go focus on more business critical parts of their workflow

56
00:05:32,080 --> 00:05:40,080
and AI. And so how did the focus on GPT-3 and transformers come to come to be?

57
00:05:40,080 --> 00:05:45,600
Yeah. So at Samba Nova Systems, as we've been working on our journey and the products that we

58
00:05:45,600 --> 00:05:52,160
have to offer, we're always looking at what are the capabilities that our platform can enable

59
00:05:52,160 --> 00:05:57,440
and bring value to customers. At the end of the day, it's all about the customers and how are they

60
00:05:57,440 --> 00:06:02,560
going to use the product and how are they going to be successful on their AI journey. So for us,

61
00:06:03,120 --> 00:06:09,440
some of the advantages of the underlying platform are tied to our large memory configuration,

62
00:06:09,440 --> 00:06:16,560
the flexibility we have in the platform. And so things like transformer models, both BERT and GPT,

63
00:06:17,520 --> 00:06:22,720
you know, they started a few years ago where you would have a hundred million parameter model,

64
00:06:22,720 --> 00:06:29,680
a 300 million parameter model, GPT-2, a 1.5 billion parameter model. And now we're looking at GPT-3,

65
00:06:29,680 --> 00:06:37,200
which is 175 billion parameter model. That is stressing not only the compute capacity,

66
00:06:37,200 --> 00:06:43,360
but also the memory needs of existing architectures. And because our platform has

67
00:06:44,240 --> 00:06:50,080
those capabilities in really shine in that space, it was just a place for us to get started

68
00:06:50,080 --> 00:06:53,200
and start showing the capabilities that our platform has to offer.

69
00:06:53,840 --> 00:07:02,160
When you're out talking to folks about these kinds of models, I'm curious to learn a bit about

70
00:07:02,160 --> 00:07:09,360
what you're seeing out in the real world, outside of academia, in the industries that I mentioned

71
00:07:09,360 --> 00:07:18,560
earlier, banking, finance, traditional organizations, like how far have they come with trying to use

72
00:07:18,560 --> 00:07:26,640
these models and what ways are they trying to use transformers and what's their experience so far?

73
00:07:26,640 --> 00:07:32,880
Yeah, so I think, I mean, obviously it depends. It depends where you are in the world. Different

74
00:07:32,880 --> 00:07:39,520
countries are potentially further along. Different industries within those countries are further along.

75
00:07:39,520 --> 00:07:44,640
And so you have, you know, if you take a look at, for example, hyperscalers, regardless of where

76
00:07:44,640 --> 00:07:49,680
they are, they are obviously very far in their journey with natural language processing.

77
00:07:49,680 --> 00:07:54,160
Many of them are coming out and pushing the boundaries with new models on a regular basis,

78
00:07:54,160 --> 00:08:00,960
right? And, you know, we used to say that hardware, you know, the hardware has a cycle that's usually

79
00:08:00,960 --> 00:08:06,640
years in gestation period. And these models are making significant improvements like every two to

80
00:08:06,640 --> 00:08:10,640
three months as far as the number of parameters and the compute and memory needs required.

81
00:08:10,640 --> 00:08:18,240
But what we're seeing in enterprise customers, regardless really of where they are in the world,

82
00:08:18,240 --> 00:08:23,680
is that, you know, they realize that they need to do something with AI.

83
00:08:24,560 --> 00:08:30,880
They feel like their competitors are ahead of them. And in some cases, there are actually

84
00:08:31,440 --> 00:08:36,000
examples that we know of or that they know of where investments have been made,

85
00:08:36,000 --> 00:08:42,480
significantly in resources, both people, time, machines to go build solutions, right?

86
00:08:42,480 --> 00:08:46,480
How successful those implementations have been, you know, varying degrees.

87
00:08:47,360 --> 00:08:54,880
But they realize that there is a lot of opportunity here. How they translate that opportunity to

88
00:08:55,840 --> 00:09:01,280
value that they bring to their customers and their business is that's where I think some of

89
00:09:01,280 --> 00:09:06,880
the questions still lie, right? Some people have started to figure it out and are deploying things

90
00:09:07,520 --> 00:09:12,960
slightly. Others are just very early on in their journey. And then you have some in the middle

91
00:09:12,960 --> 00:09:16,880
who have been trying things, but just haven't really figured out how to put it all together.

92
00:09:17,680 --> 00:09:23,920
You know, from a language perspective with natural language processing and our data flow as a service

93
00:09:23,920 --> 00:09:30,240
for language, we see this cutting across all industries. And if you take a look at, say,

94
00:09:30,240 --> 00:09:35,600
financial services, it's going to hit community banking. It will hit corporate banking,

95
00:09:35,600 --> 00:09:41,840
capital markets. There's applicability across all parts of banking and financial services as well

96
00:09:41,840 --> 00:09:48,480
as other industries. And it has the ability to be transformational, both, you know, customer

97
00:09:48,480 --> 00:09:54,800
facing and back office for many industries. And are there specific use cases in those industries

98
00:09:54,800 --> 00:10:02,080
that are coming to the fore as being places to places that organizations are starting or

99
00:10:02,080 --> 00:10:07,200
where they're seeing success? Yeah. So I think if you look at banking and this applies to other

100
00:10:07,200 --> 00:10:13,520
industries as well. The first use case that always jumps to people's minds is call center.

101
00:10:13,520 --> 00:10:20,000
And the reason for that is that is an easy one for people to walk through and understand.

102
00:10:20,000 --> 00:10:25,840
And it does apply in multiple industries. And so when you think about call center interactions,

103
00:10:26,400 --> 00:10:31,760
when they come in, you understand who your customer is. You have some information about them.

104
00:10:32,720 --> 00:10:38,240
Maybe they are speaking with you. They're texting with you. They're chatting with you in other

105
00:10:38,240 --> 00:10:43,040
ways. There's lots of ways that, you know, call centers are running these days, whether it's chat

106
00:10:43,040 --> 00:10:49,840
about with a live person. At the end of the day, despite a lot of technology being applied, you know,

107
00:10:49,840 --> 00:10:55,040
most people when you talk to them about how was your call center experience or support experience

108
00:10:55,040 --> 00:11:00,960
with x, y, and z, right? It's not a positive experience. And then you usually get asked for the

109
00:11:00,960 --> 00:11:06,560
survey at the end. And who fills out the surveys, except for the people who are really irritated

110
00:11:06,560 --> 00:11:11,440
about the process that they've been through. So I think, you know, call center is a very easy

111
00:11:11,440 --> 00:11:16,320
problem to understand. And there's a couple of different ways that we can apply natural language

112
00:11:16,320 --> 00:11:23,440
processing and GPT and obviously combined with other bits to improve that experience and drive

113
00:11:23,440 --> 00:11:29,280
customer value. So, you know, bank banking institutions, certainly when you come in and talk to them,

114
00:11:29,920 --> 00:11:36,160
they understand how to figure out, you know, was a customer happy or not. Some of it's through surveys,

115
00:11:36,160 --> 00:11:41,840
some of it's through other mechanisms. But think about as you're interacting, whether it's via text

116
00:11:42,960 --> 00:11:49,760
or actually talking to a live human being or speaking with the automated system, you know, by tone,

117
00:11:49,760 --> 00:11:55,520
by the word choice, word choice specifically for something like sentiment analysis as a downstream

118
00:11:55,520 --> 00:12:02,640
test of GPT, you can start to get live feedback on what the customer is saying and the word choice

119
00:12:02,640 --> 00:12:07,680
that they're using is this a positive experience, is this a negative experience, or is this a

120
00:12:07,680 --> 00:12:14,000
net neutral experience, right? So that's just one example. As you are talking to a customer or

121
00:12:14,000 --> 00:12:19,680
they're inputting things, you know, you can do extraction of text and apply it to rather than

122
00:12:19,680 --> 00:12:24,560
saying, you know, can you fill out this stuff for me or give me this information, you can grab a

123
00:12:24,560 --> 00:12:31,200
lot of that and get things into the system to improve the overall customer success flow. I mean,

124
00:12:31,200 --> 00:12:37,920
the end, the end state is really to try to get the information from the customer about their problem

125
00:12:37,920 --> 00:12:44,320
as quickly as possible to have the call center automated system or person that eventually gets called

126
00:12:44,320 --> 00:12:50,400
in to have the solution at the hand and ready for the problem that they have and then all of that

127
00:12:50,400 --> 00:12:55,520
be a positive experience. So there's lots of different ways that we can combine all of that to make

128
00:12:55,520 --> 00:13:05,040
that work. I'm not sure if this is a pushback or an opportunity for a liberation, but it just

129
00:13:05,040 --> 00:13:13,840
strikes me that there's so much opportunity to do basic things, like I'm very curious your

130
00:13:13,840 --> 00:13:21,840
experience about the readiness to even do advanced things, you know, to the point you mentioned

131
00:13:21,840 --> 00:13:29,680
earlier, ensuring that the rep that you're talking to has the information about your account

132
00:13:29,680 --> 00:13:34,000
in front of them. So you're not repeating things that you told the last rep or, you know,

133
00:13:34,000 --> 00:13:39,680
telling them what products you have. Like it seems like there are some pretty foundational things

134
00:13:39,680 --> 00:13:45,120
that organizations need to figure out. I don't know if it's just banks or rather, I don't

135
00:13:45,920 --> 00:13:50,640
have an opinion on whether banks are further ahead of that or behind on that, but what's the

136
00:13:50,640 --> 00:13:57,680
readiness of the enterprise to receive this kind of technology given the state of call center?

137
00:13:58,640 --> 00:14:03,360
Yeah, I mean, I think, you know, essentially when you think about a customer,

138
00:14:03,360 --> 00:14:07,840
regardless of industry, they're going to have, you know, they should know about your products,

139
00:14:07,840 --> 00:14:13,520
your previous transactions, your history. That's all structured data, right? So when you think

140
00:14:13,520 --> 00:14:19,360
about that, that is an easier problem to solve. And many people across many industries are doing

141
00:14:19,360 --> 00:14:24,320
better in that once they get some preliminary information from you, right? If you give, say,

142
00:14:25,040 --> 00:14:30,720
a key identifier, they just ask you to verify who you are, right? And they know, oh, here is your

143
00:14:30,720 --> 00:14:34,880
name. Here's the transactions you've had with us. And it can go very smoothly from there.

144
00:14:35,440 --> 00:14:40,720
It's this on other unstructured data, right? Which how do we incorporate that into the workflow,

145
00:14:41,360 --> 00:14:47,600
to bring a better synergy between the customer and the business? And so I think,

146
00:14:47,600 --> 00:14:55,680
you know, we are ready to start doing that. But I think one of the key things is when you start

147
00:14:55,680 --> 00:15:02,320
looking forward to how you do implementations, a lot of people get stuck on what is successful.

148
00:15:02,880 --> 00:15:08,720
And maybe they're thinking really big and really grand. And there are some small things and easy

149
00:15:08,720 --> 00:15:14,160
wins that you can make to show success. And so one of the things we talk about with our customers

150
00:15:14,160 --> 00:15:20,000
is, you know, breaking things down into smaller chunks and milestones where you can actually see

151
00:15:20,720 --> 00:15:28,640
this new technology making impact, you know, testing that it has an impact and then continuing to

152
00:15:28,640 --> 00:15:35,200
make adjustments and add additional things over time. So that you don't get stuck in the cycle of,

153
00:15:35,200 --> 00:15:40,000
I'm testing things and I don't know, is it successful? Is it not? It feels like we're what we call

154
00:15:40,000 --> 00:15:44,800
sort of POC purgatory where you're doing a lot of things, but are you actually driving business

155
00:15:44,800 --> 00:15:53,200
value into your core business? And what's an example of how you might walk back from, hey, I want

156
00:15:53,200 --> 00:16:01,760
to apply this to call center to a specific kind of sequence of of wins and things to test.

157
00:16:01,760 --> 00:16:09,360
If you think about accuracy of being able to translate what a customer is either writing to you

158
00:16:09,360 --> 00:16:17,200
or talking to you, right? That's highly important. And so GPT as an example does a great job

159
00:16:17,200 --> 00:16:24,160
at basic language, right? But if you say are in the financial space or maybe you're an airline,

160
00:16:24,160 --> 00:16:30,080
the vocabulary and types of words that you and your customers will use can be significantly

161
00:16:30,080 --> 00:16:35,360
different. So for different industries and different use cases, there are going to be what we

162
00:16:35,360 --> 00:16:41,520
call sort of custom corpuses or industry specific data sets that are important. So if you're

163
00:16:41,520 --> 00:16:48,160
say working in a call center in a bank and you want to inevitably get some workflows there to help

164
00:16:48,160 --> 00:16:56,800
improve it based on NLP, the first step is let's look at taking the base GPT model and improving

165
00:16:56,800 --> 00:17:03,840
that with custom corpuses that are specific to your industry or specific to your customer install

166
00:17:03,840 --> 00:17:08,960
base, right? So are there standard open source data sets or do you have to curate those data sets

167
00:17:08,960 --> 00:17:16,800
internally? But let's refine the knowledge that the AI model has. So as an example, if you say

168
00:17:16,800 --> 00:17:21,040
end of quarter, does that actually mean the end of a business quarter? Or does that mean the end

169
00:17:21,040 --> 00:17:27,040
of a sporting contest, right? And so those specifics look very different by industry. And so that

170
00:17:27,040 --> 00:17:34,640
would be step one. Let's do some fine tuning on this large NLP model. Then let's gauge accuracy

171
00:17:34,640 --> 00:17:39,840
and how did that improve things? We can do sentiment analysis. We can do text generation. There's

172
00:17:39,840 --> 00:17:45,600
other downstream tasks that we can use to evaluate that and to see, are we making progress?

173
00:17:45,600 --> 00:17:51,520
At some point you get to a, this is a great level of accuracy. I think we can do something with

174
00:17:51,520 --> 00:17:57,440
it. And then you would start to say, okay, let's transition that into adding it into a workflow.

175
00:17:57,440 --> 00:18:02,240
What parts of the workflow can we replace with this? What do we have to enhance as sort of the

176
00:18:02,240 --> 00:18:10,640
next phase? Got it. So it sounds like what I heard there was the first step is kind of transcribing

177
00:18:10,640 --> 00:18:18,720
the conversation and enhancing or enriching the notes that CSR might otherwise take. And then

178
00:18:18,720 --> 00:18:24,640
it's applying kind of these higher level capabilities, sentiment analysis or some predictive thing

179
00:18:25,680 --> 00:18:33,520
to maybe guide them in the conversation or allow you to better assess the success of your

180
00:18:33,520 --> 00:18:42,000
interactions? Exactly, right? So that first step is really to say, is the data that we're using

181
00:18:42,560 --> 00:18:47,840
and trained on capable of giving us the accuracy in our interactions that we want?

182
00:18:47,840 --> 00:18:53,840
And then when you get to a level that says, yeah, it can, you know, this AI model is not just

183
00:18:53,840 --> 00:19:00,160
generic to the English language, but it really understands commercial banking or it really understands

184
00:19:00,160 --> 00:19:06,640
capital markets to very different things, right? Then we can say, how do you apply that in workflows?

185
00:19:07,120 --> 00:19:11,040
And for each of those areas, they're going to have different workflows, right?

186
00:19:11,040 --> 00:19:16,640
Community banking certainly has a call center aspect to it. Capital markets may not. And so

187
00:19:16,640 --> 00:19:21,920
then you would take to the specific use cases and how to apply that. Got it. Got it. So as opposed

188
00:19:21,920 --> 00:19:30,960
to jumping to, you know, something in the workflow, start by, say, start by assessing whether

189
00:19:31,760 --> 00:19:40,640
the model can even be used in the context of your industry, either off the shelf or after fine

190
00:19:40,640 --> 00:19:46,880
tuning with whatever data you can access. Got it. Makes sense. Yeah. And I would say that the model

191
00:19:46,880 --> 00:19:54,000
is wonderful and can be applied across multiple industries. What we do at Samba Nova is pre-trained

192
00:19:54,000 --> 00:20:00,080
and optimize it for the English language on open data sets. And that is a hard chunk of work

193
00:20:00,080 --> 00:20:05,680
that not a lot of people can do across the world, right? So we're able to do that and we're able to

194
00:20:05,680 --> 00:20:12,560
get customers up and running quite quickly. But that stage of industry specification or specific

195
00:20:12,560 --> 00:20:17,440
data is really important so that, especially when you're dealing with customers, you know,

196
00:20:17,440 --> 00:20:21,360
you don't want to get them irritated because it's not giving them the right answer or not

197
00:20:21,360 --> 00:20:28,160
understanding the context. So those differences between industry words or words specific to your

198
00:20:28,160 --> 00:20:34,400
business matter and aren't going to show up in a traditional English language corpus. Or if they

199
00:20:34,400 --> 00:20:38,880
do show up, they're not going to be in the volume that the AI model is going to be able to learn

200
00:20:38,880 --> 00:20:47,520
enough about them. When an organization is trying to use a model like GPT-3 or BERT,

201
00:20:49,520 --> 00:20:55,520
you know, I think that the options that come to mind first are, you know, use GPT-3 as a service

202
00:20:55,520 --> 00:21:03,120
from OpenAI or, you know, pull down a model from hugging face and use that. How does someone know

203
00:21:03,120 --> 00:21:11,040
that they should be calling a seminar? Like, what are the hidden challenges of, you know,

204
00:21:11,040 --> 00:21:17,120
those two approaches or other approaches that maybe you're seeing folks take that folks tend to

205
00:21:17,120 --> 00:21:22,800
run into that impede their progress? The few things that come to mind are, first of all,

206
00:21:23,520 --> 00:21:32,080
finding the resources who can do the type of work at GPT scale. That's a very specific skill set.

207
00:21:32,080 --> 00:21:38,080
Those are hard resources to find, regardless of where you are in the world. And so when we've

208
00:21:38,080 --> 00:21:43,840
talked to customers, I have a customer as an example, in the financial services space, they looked

209
00:21:43,840 --> 00:21:49,360
across at a competitor and said, over the past three years, they've built a team of data scientists

210
00:21:49,360 --> 00:21:55,200
of hundreds, you know, spent millions and millions of dollars investing in hardware and then

211
00:21:55,200 --> 00:22:02,400
spent all that time to work on a solution, we cannot catch up with them, even if we started

212
00:22:02,400 --> 00:22:09,200
investing today. By the time that we get the people, if we can find them, and invest the money,

213
00:22:09,840 --> 00:22:14,400
we will have wasted significant time and they will have leapfrog does even more than today.

214
00:22:15,120 --> 00:22:22,640
So for them, they think about the time it will take to put together what we consider a do-it-yourself

215
00:22:22,640 --> 00:22:28,640
approach on a hardware perspective. There's the money to do that. And then also the people resources

216
00:22:28,640 --> 00:22:33,600
that you need to invest in and that can can do that work both on the hardware side and the software

217
00:22:33,600 --> 00:22:40,560
data science side. And so we are resource constrained to find the right type of people. And so

218
00:22:40,560 --> 00:22:48,080
working with a company like Samba Nova Systems that has the resources and experts who are working

219
00:22:48,080 --> 00:22:55,040
in algorithmic improvements at the cutting edge, at the cusp of research is an advantage that they

220
00:22:55,040 --> 00:23:01,840
can leverage. We have a solution that we bring that we have up and running in a day that customers

221
00:23:01,840 --> 00:23:09,920
can start using a pre-trained GPT model and get going. And so we continue as the life of the service

222
00:23:09,920 --> 00:23:15,440
to optimize that for them and keep abreast of new research and deliver new services and solutions

223
00:23:15,440 --> 00:23:21,280
for them. So by partnering with someone at Samba Nova Systems, they get to leverage our expertise

224
00:23:21,280 --> 00:23:28,080
over a period of time. The do-it-yourself approach is also hard. Even if you have the time to go and

225
00:23:28,080 --> 00:23:35,680
do it, doing something like GPT takes a large scale of equipment because of the constraints of

226
00:23:35,680 --> 00:23:44,240
traditional architectures. And so Samba Nova Systems allows people to basically deploy at a

227
00:23:44,240 --> 00:23:50,160
smaller configuration to start because of some of the enhancements we have in both our hardware

228
00:23:50,160 --> 00:23:56,320
and software and scale up in an optimized way without any change in their environment.

229
00:23:57,040 --> 00:24:02,480
And that's not something that you necessarily get with the off-the-shelf do-it-yourself components.

230
00:24:02,480 --> 00:24:09,680
And so you don't have this option of starting at a reasonable size. You just have to go to this huge

231
00:24:09,680 --> 00:24:17,280
scale. And that's a really big sort of roadblock for a lot of people. Now, to go back to your point,

232
00:24:17,280 --> 00:24:21,680
you say, well, they could go to the cloud and they could go use some of those services.

233
00:24:22,880 --> 00:24:29,280
But at the same time, some of the customers we have have said they've been surprised by some

234
00:24:29,280 --> 00:24:35,280
of the bills that they've received from some of these cloud service providers. Training is not

235
00:24:35,280 --> 00:24:43,280
a cheap endeavor. So compute time is certainly one thing and the network bandwidth of data back

236
00:24:43,280 --> 00:24:51,360
and forth. So while it might be a nice playground to start with, having that as a full-on production

237
00:24:51,360 --> 00:24:56,400
environment becomes a little bit difficult from a financial perspective. And they are starting to

238
00:24:56,400 --> 00:25:03,040
think that maybe some of those workloads should be brought back on-prem. That being said,

239
00:25:03,040 --> 00:25:08,080
we are happy to deploy our solution on-prem with hosting providers or in dedicated cloud

240
00:25:08,080 --> 00:25:15,120
environments for our customers. So we're very flexible. At the same time, we also do have many

241
00:25:15,120 --> 00:25:21,760
customers who have requirements to keep data within their own firewalls, within their own country.

242
00:25:21,760 --> 00:25:28,560
And so there's rules and regulations that play here. So there's lots of reasons I think why

243
00:25:28,560 --> 00:25:36,960
customers may start out looking at things that exist today in the market. But in order to deploy

244
00:25:36,960 --> 00:25:44,000
those in a real environment at production, at scale, I think Sombanova provides a unique advantage

245
00:25:44,000 --> 00:25:53,600
for them. Can you talk a little bit about the process for kind of building the solution

246
00:25:53,600 --> 00:26:05,200
on your end? And I guess to elaborate on that a little bit, the GPT-3 data set, for example,

247
00:26:05,200 --> 00:26:13,280
like OpenAI, Crawl, Reddit, the web, all this stuff, like it's not like a five-remembering

248
00:26:13,280 --> 00:26:17,920
crack. It's not like go to GitHub and download that data set. You have to go crawl that yourself,

249
00:26:17,920 --> 00:26:26,800
right? And there are aspects of the, certainly they publish the paper about the model,

250
00:26:27,760 --> 00:26:32,720
but those papers never really have all of the details about the model. Of course.

251
00:26:32,720 --> 00:26:37,760
Here is what all from a research and development perspective had to go into

252
00:26:38,640 --> 00:26:43,440
essentially replicating what they did and published a lot of, but not all of.

253
00:26:43,440 --> 00:26:52,800
There has been significant time and effort as we've looked at how our transformer models

254
00:26:53,440 --> 00:26:59,120
optimize to run on this new hardware and this new software stack, right? So it's not for us.

255
00:27:00,400 --> 00:27:06,400
It's not only with Dataflow as a service, download an industry standard model and run.

256
00:27:06,400 --> 00:27:12,240
We certainly can do that. Go to HuggingFace, download the model, run it on the platform. That is

257
00:27:12,240 --> 00:27:18,720
a great solution for customers who are interested in our data scale product. But for our Dataflow

258
00:27:18,720 --> 00:27:24,720
is a service product where we are packaging solutions. There's a much larger effort that goes into

259
00:27:24,720 --> 00:27:31,440
play there for the optimizations and enhancements that we put in the stack and for the solution around

260
00:27:31,440 --> 00:27:38,240
it. And I will say whether we're doing work internally or customers are doing work as they look

261
00:27:38,240 --> 00:27:45,280
to additional pre-training and fine-tuning. Data curation is one of the hardest aspects of this.

262
00:27:46,400 --> 00:27:52,160
Data may be available. Is it available in the right format? Do you have access to it? Can you

263
00:27:52,160 --> 00:27:59,840
use it? Different countries have different rules for how it's used. And some countries have more

264
00:27:59,840 --> 00:28:05,520
digitized text content than others. And so the one thing I can say whether it's internal to

265
00:28:05,520 --> 00:28:12,640
Samba Nova or external with our customers. Having the right data set to use is always the first

266
00:28:12,640 --> 00:28:20,240
discussion and always a challenge. As you're out talking to and working with customers, again,

267
00:28:20,240 --> 00:28:29,280
banking finance, but also beyond that, how well do they understand GPT-3 and transformers

268
00:28:29,280 --> 00:28:37,280
and maybe even more interesting, like what's surprising to them about the technology? What is it

269
00:28:37,280 --> 00:28:42,560
that they already kind of get and what is it that? Oh, it just blows their mind. It blows their mind

270
00:28:42,560 --> 00:28:50,160
not necessarily from a performance perspective. But what is it that they find interesting and

271
00:28:50,160 --> 00:28:54,560
counterintuitive, I guess, is what I'm trying to get at? Well, so obviously when you can talk to

272
00:28:54,560 --> 00:28:58,400
customers, there's lots of different personnel that you can be talking to. You can be talking to

273
00:28:58,400 --> 00:29:03,120
the technical people who are data scientists. You can talk to technical people who are more

274
00:29:03,840 --> 00:29:08,240
in the data center and administrators of systems. And you can also talk to business

275
00:29:08,880 --> 00:29:15,280
type users, right? So it all comes down to who you're talking to. If there is an established

276
00:29:15,280 --> 00:29:23,360
team of data scientists and data scientists who work in the area of AI focused on deep neural

277
00:29:23,360 --> 00:29:30,880
networks, I'm doing some clarification here. Then most of those people are abreast and have heard

278
00:29:30,880 --> 00:29:36,400
of Bert and they've heard of GPT. Whether or not they've used it themselves personally or

279
00:29:36,400 --> 00:29:42,800
internally is another question. If you have at customers technical people who are more on the

280
00:29:42,800 --> 00:29:49,200
analytic side and the traditional ML side, it's possible that they don't know much about Bert

281
00:29:49,200 --> 00:29:56,640
or GPT. And this is not a everybody that falls in that category, but there are situations where

282
00:29:56,640 --> 00:30:01,360
just because of the type of data and analytics work that they're doing, they're more focused on

283
00:30:01,920 --> 00:30:06,080
other types of problem solving than deep neural networks with transformers.

284
00:30:07,040 --> 00:30:13,440
The business side users, some of them have certainly same things in the press. I've said

285
00:30:13,440 --> 00:30:19,120
we've gone to talk about GPT and then I saw something about this other model that came out that

286
00:30:19,120 --> 00:30:27,520
's even bigger. The acronym is familiar from a they've heard about it and maybe seen some others

287
00:30:27,520 --> 00:30:33,520
are using it, but maybe the details aren't so well known on the technical side, but they're also

288
00:30:33,520 --> 00:30:39,920
interested in understanding what it can do and how they can take advantage of it. And I think

289
00:30:40,800 --> 00:30:46,560
not everybody has the same understanding of what these large transformer models are capable of

290
00:30:46,560 --> 00:30:52,080
and what they can be applied to, because that information isn't so readily available and shared

291
00:30:52,080 --> 00:30:57,680
at a level that everyone can get a common understanding on. So those are just when I go and talk to

292
00:30:57,680 --> 00:31:04,400
people, the levels of understanding are significantly different based on who we're talking to. A lot

293
00:31:04,400 --> 00:31:14,560
of people don't realize the effort it takes to get to an optimized and running configuration that's

294
00:31:14,560 --> 00:31:25,840
accurate. They underestimate it or they haven't underestimated it from a hardware configuration

295
00:31:25,840 --> 00:31:32,640
side, but having the skill set to be able to implement that is also challenging. So as I think

296
00:31:32,640 --> 00:31:39,280
alluded to earlier, there aren't many people in this world who can actually do an optimized GPT

297
00:31:39,280 --> 00:31:45,360
configuration, right? And so that takes expertise across an entire stack, both hardware and software,

298
00:31:46,000 --> 00:31:52,000
to be able to do that. And so I think that that in and of itself has surprised people when I've

299
00:31:52,000 --> 00:31:58,160
gone and talked to them. The other thing that's surprising, you know, and this is just, it's

300
00:31:58,160 --> 00:32:03,840
back to the value of Samba Nova systems is, you know, they're shocked that we can wheel in a

301
00:32:03,840 --> 00:32:09,120
service that within a day they can be using and it's already pre-trained and optimized for them.

302
00:32:09,120 --> 00:32:14,880
Right? And we can scale it from one rack to many racks. And for us, it doesn't really matter.

303
00:32:14,880 --> 00:32:21,200
And so for them that catches them by surprise because this is a hard problem. And so seeing that,

304
00:32:21,200 --> 00:32:26,880
you know, actually in practice is, you know, we get a lot of, wow, you said it, I don't think we

305
00:32:26,880 --> 00:32:33,200
believed you and you actually delivered and it's amazing. One of the issues that I think we're

306
00:32:33,200 --> 00:32:40,960
still trying to wrap our hands around as an industry with language models is, you know,

307
00:32:40,960 --> 00:32:49,040
predictability, controllability, governance, that kind of thing. Lots of examples of, you know,

308
00:32:49,040 --> 00:32:55,600
language models gone wrong. We don't need to, you know, repeat those. How are the folks that

309
00:32:55,600 --> 00:33:01,040
you're working with addressing those kinds of issues? So certainly they come up, right? As far as

310
00:33:01,040 --> 00:33:05,920
discussion points, right? And what should we be doing that about them? And so this comes back to,

311
00:33:05,920 --> 00:33:11,600
I think, a few things. Certainly it comes back to the data set, right? The information that the AI

312
00:33:11,600 --> 00:33:16,800
model learns is only as good as the data set that it's trained on, right? So what is the right

313
00:33:16,800 --> 00:33:24,000
data set to get you to an accuracy level that makes sense for your business? And so it's not only

314
00:33:24,000 --> 00:33:30,800
about the data set, but then how are you going to measure and test that? You are actually within

315
00:33:30,800 --> 00:33:36,240
the bounds that make sense for you. And that's not something necessarily that Samba Nova system can

316
00:33:36,240 --> 00:33:40,720
guide customers on because it's going to be specific to their business and specific to their

317
00:33:40,720 --> 00:33:45,680
industry, but we're happy to work with them and talk to them about some of these steps that we

318
00:33:45,680 --> 00:33:51,440
think are crucial for them to go through in order to make sure when things are deployed,

319
00:33:51,440 --> 00:33:56,320
it's doing what is expected, right? And if things aren't doing what they're expected, you want to

320
00:33:56,320 --> 00:34:01,920
catch them early before you've gone live and you want to understand how are you going to

321
00:34:01,920 --> 00:34:08,240
remediate that problem and ensure it doesn't happen again, right? So there is a life cycle around this.

322
00:34:08,240 --> 00:34:15,280
You hope to do most of it in the early phases of an implementation and really refine what you're

323
00:34:15,280 --> 00:34:21,120
working on so you know what the answers are going to be and how to address them. And then if you

324
00:34:21,120 --> 00:34:26,160
are in a production environment, if something does happen, how quickly can you respond to it

325
00:34:26,160 --> 00:34:30,160
and remediate things and fix things so they don't continue to happen moving forward?

326
00:34:30,160 --> 00:34:38,800
Can you talk through the data collection aspect of that with maybe some use case examples given

327
00:34:38,800 --> 00:34:44,080
a particular problem, you know, where folks collecting the data, what do they have to do with it

328
00:34:44,080 --> 00:34:53,520
in order to make use of it for fine-tuning? Yeah, so I think, you know, some of it is with data

329
00:34:53,520 --> 00:35:02,720
sanitization. So when you think about GPT models as an example or BERT, trained in pre-trained

330
00:35:02,720 --> 00:35:09,600
in English, we're all using sort of open standard corpses, right? So how sanitized are those,

331
00:35:09,600 --> 00:35:14,880
is there bias in them? You know, all the questions that you would you would think to ask people

332
00:35:14,880 --> 00:35:22,080
should be asking. And so as you start to curate additional data sets to do pre-training and fine-tuning,

333
00:35:22,880 --> 00:35:28,640
making sure, you know, it's you have to trust the source of the data. Is it external data?

334
00:35:28,640 --> 00:35:33,520
Is it internal data? If it's internal data, does it need to be cleansed first of sensitive

335
00:35:33,520 --> 00:35:40,480
information that you shouldn't be putting into an AI model? But then also, you know, you need a

336
00:35:40,480 --> 00:35:48,000
team of data experts who are familiar with how to produce data corpuses. And this is it's

337
00:35:48,000 --> 00:35:53,040
own practice in its own industry, right? And not necessarily my expertise, but it's certainly

338
00:35:53,920 --> 00:35:59,120
a focus where our customers are spending a lot of time. So they get the data set right.

339
00:35:59,120 --> 00:36:05,040
And it's not like you have to do it right in one shot. You can start and continually enhance it

340
00:36:05,040 --> 00:36:11,440
over time by doing additional pre-training and fine-tuning. So that allows you to start the hit

341
00:36:11,440 --> 00:36:18,720
some early milestones and deliver a continually improving solution. You mentioned measurement

342
00:36:18,720 --> 00:36:24,640
and testing with regard to these data sets. What exactly does that mean in this context?

343
00:36:24,640 --> 00:36:30,640
Well, so I think, you know, we have ways of, so take sentiment analysis as an example.

344
00:36:31,440 --> 00:36:38,000
I'm a finance customer. I have a GPT model. We'll go back to my end-of-quarter analysis, right?

345
00:36:39,040 --> 00:36:46,320
Is that a positive or is that a negative statement, right? So let's say, you know, the

346
00:36:46,320 --> 00:36:52,960
Bank of America here in the US ended up ended their quarter, you know, up $10 per share or something.

347
00:36:52,960 --> 00:36:59,200
Okay, so that is a positive statement. So from a sentiment analysis perspective, right? So it

348
00:36:59,200 --> 00:37:04,400
would have pre-trained, it would have done that, and then you would have some sanity. You need to

349
00:37:04,400 --> 00:37:12,080
check, right? Are is the analysis that the AI model doing correct or incorrect? When you start to

350
00:37:12,080 --> 00:37:18,240
do things that are very specific to finance and start talking about, maybe it's talking about

351
00:37:18,240 --> 00:37:24,640
puts or calls or things related to the stock market, it may not be able to discern that. And in

352
00:37:24,640 --> 00:37:29,440
fact, we've seen cases, I don't have one in front of me where, you know, models like Bert large

353
00:37:29,440 --> 00:37:36,080
or maybe GPT will classify something as negative or neutral when it's really positive. And so you

354
00:37:36,080 --> 00:37:44,080
need to be able to flag the incorrect assessments and figure out a way to refine the data that you're

355
00:37:44,080 --> 00:37:50,000
training on to get rid of those so that you're more accurate than not, right? So first of all,

356
00:37:50,000 --> 00:37:55,840
you want to start judging accuracy of your data set, but you also need to come in and actually check

357
00:37:55,840 --> 00:38:00,400
is your accuracy what you think it is or you falsely identifying things, right? And so

358
00:38:01,840 --> 00:38:07,040
two aspects to that. So a lot of what has driven the excitement around

359
00:38:07,040 --> 00:38:18,960
Bert and Transformers generally is that unlike kind of prior models in NLP and you know the way we

360
00:38:18,960 --> 00:38:24,240
think about much of machine learning in general, like you haven't needed these labeled data sets,

361
00:38:24,240 --> 00:38:30,160
like you it's you're kind of letting your training on unlabeled data.

362
00:38:30,160 --> 00:38:37,680
Yeah, it sounds like for these measurement and tests requirements, though, you would need

363
00:38:37,680 --> 00:38:44,320
some kind of labeled data set in order to do benchmarking. Is that the case and does that?

364
00:38:45,840 --> 00:38:50,240
Yeah, I'm not, though, so we're not necessarily using labeled data with our customers. I think

365
00:38:50,240 --> 00:38:57,200
there's just a, you know, when you think about deploying some of these solutions and people question

366
00:38:57,200 --> 00:39:03,600
is AI correct and is it, you know, do you get the same answer every time? There's care that goes

367
00:39:03,600 --> 00:39:09,520
into the creation of the data set, even if it's not labeled, right? So thoughts around that.

368
00:39:10,320 --> 00:39:14,960
And then, you know, I don't necessarily think you need to label everything, but there does need to

369
00:39:14,960 --> 00:39:21,040
be some checking and some test put in place to verify, right? And so maybe that's that spot checking

370
00:39:21,040 --> 00:39:26,480
or other things, right? So I don't think you need to go to the everything must be labeled.

371
00:39:26,480 --> 00:39:31,760
We know that's not going to be a scalable solution, but when you think about, you know,

372
00:39:31,760 --> 00:39:36,560
big name brands deploying these solutions in front of their customers or using it to make

373
00:39:36,560 --> 00:39:42,320
business decisions, you do want to put some ways to at least assess how things are looking.

374
00:39:42,960 --> 00:39:47,440
So you understand, you know, are you accurate or not and doesn't make sense to push forward?

375
00:39:48,480 --> 00:39:53,040
Yeah, yeah, that's that's kind of the question that I had and what I was getting at are folks

376
00:39:53,040 --> 00:40:02,160
spot checking and getting a general feel that this looks about right or are folks setting aside,

377
00:40:02,880 --> 00:40:09,840
you know, some labeled test set or validation set that they then, you know, for sentiment,

378
00:40:09,840 --> 00:40:17,760
let's say, run against their model and, you know, produce numerical reports against.

379
00:40:17,760 --> 00:40:22,960
And then how much of that, how hard is that effort, how well prepared are they to go through those

380
00:40:22,960 --> 00:40:27,440
efforts? Yeah, so I think, you know, in the conversations I've been with customers,

381
00:40:27,440 --> 00:40:32,800
you see sort of a little bit of both and questioning about what is the right way. And I'm not sure

382
00:40:32,800 --> 00:40:38,800
that there is a well, you know, people are still debating the approaches here of what should be

383
00:40:38,800 --> 00:40:43,360
taken. You know, obviously we know there when you create a curated data set and everything needs

384
00:40:43,360 --> 00:40:48,640
to be labeled, there's additional challenges there, right? So, but at the same time, people want

385
00:40:48,640 --> 00:40:54,400
some confidence. And so it's a where that will fall might depend on the customer and the industry,

386
00:40:54,400 --> 00:40:59,200
but I will say it's a discussion point. And I'm not sure that the answer, you know, industry best

387
00:40:59,200 --> 00:41:05,120
practice is well known at this point. Got it. And you also mentioned kind of these guard rails that

388
00:41:05,120 --> 00:41:12,560
folks will put up in place to ensure that when slash if a model has a problem, they can avoid

389
00:41:12,560 --> 00:41:18,000
that problem in the future. Can you talk a little bit about the approaches that you've seen for

390
00:41:18,000 --> 00:41:23,280
doing that? Yeah, so I mean, I think it's mainly about, it goes back to the process I've talked about

391
00:41:23,280 --> 00:41:29,440
where there's some initial training that's done, you do more pre-training or fine-tuning,

392
00:41:29,440 --> 00:41:35,840
you try your downstream tasks. At some point, you know, things are looking good, it's deployed,

393
00:41:35,840 --> 00:41:46,240
you know, but data changes things, things morph over time. And so as you think about deploying

394
00:41:46,240 --> 00:41:51,520
these into environments where they're more in production and less in test, you need to be

395
00:41:51,520 --> 00:41:57,040
constantly staying abreast and looking at are there things that I need to retrain? Do I need to

396
00:41:57,040 --> 00:42:02,320
bring additional data in? Do I need to, does the model need to be changed? That could potentially

397
00:42:02,320 --> 00:42:08,880
happen as well, right? And so how are you monitoring for that and the end-to-end lifecycle of things?

398
00:42:08,880 --> 00:42:14,960
It's not, I don't think it will forever be a, we've trained it and deployed it, you know,

399
00:42:14,960 --> 00:42:21,280
how people speak, what's acceptable or not acceptable, common vernacular, those things change

400
00:42:21,280 --> 00:42:26,400
over time. And so how do you keep up with those changes and incorporate them into a pipeline that

401
00:42:26,400 --> 00:42:33,760
get deployed is critical? We spoke a little bit earlier about what your customers find surprising

402
00:42:33,760 --> 00:42:39,680
as they're working with these models. To close out, I'm curious, what have you found surprising

403
00:42:39,680 --> 00:42:47,760
personally as you started to work more closely with DPT and Burton Transformers? Yeah, so, you know,

404
00:42:47,760 --> 00:42:52,000
I think, well, and maybe this is more of an AI thing in mind. When I, when I first joined

405
00:42:52,000 --> 00:42:57,840
sambanova, I certainly felt that this was a transformational technology. But now that I'm three

406
00:42:57,840 --> 00:43:04,960
years in, I'm looking at use cases with customers, we're exploring a variety of areas. I really

407
00:43:04,960 --> 00:43:15,200
understand that this is going to be a very transformative shift in technology and it's going to

408
00:43:15,200 --> 00:43:21,280
affect all industries, right? You can see it applied in so many different ways. And when I think

409
00:43:21,280 --> 00:43:26,720
about my lifetime, there's been very few of these moments. You think maybe of the internet

410
00:43:26,720 --> 00:43:34,240
boom and sort of the mobile phone. And I really think AI has the ability to be that transformational

411
00:43:34,240 --> 00:43:40,160
shift of this next generation. And so for me, I think that's the exciting part. I knew it was the

412
00:43:40,160 --> 00:43:45,120
new technology and there was lots of things to do. But I don't think when I started my journey

413
00:43:45,120 --> 00:43:52,560
at sambanova, I quite understood how impactful it could be across everybody's lives. Yeah, awesome,

414
00:43:52,560 --> 00:43:58,880
awesome. Well, Jennifer, thanks so much for joining us and sharing a bit of your experiences,

415
00:43:59,520 --> 00:44:07,120
deploying GPT3 and related technology out of customers. Thank you so much. It's been a pleasure.

416
00:44:07,120 --> 00:44:15,120
Thank you for having me.

