Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
You may have listened to one or more of the shows from our AI and consumer electronic series
last week.
There's a ton of interesting work happening in that space, but the reality is that I came
back from CES both excited and also somewhat disillusioned about personal AI.
Don't get me wrong, there's a bunch of cool stuff coming for sure, but it's taking
so long.
In the meantime, the privacy sacrifices we're being asked to make for modest conveniences
seem pretty steep at times.
I want to know what you think about the state of personal AI.
I really want to hear from listeners on their thoughts, experience and desires on the role
AI is playing in your home and personal life, your favorite examples of home or personal
AI.
The home or personal AI that you really want to see in your lifetime, and just where
you see this all going, please check out TwimbleAI.com slash my AI to share your thoughts.
We've got some really great entries so far, and you can check them out on that page,
but we're missing a very important one, yours.
Let me know your thoughts, and you'll be automatically entered into the running for
some great prizes.
For today's show, I'm joined by Nialing Marosi, senior data science researcher at the Council
for Scientific and Industrial Research, or CSIR, in Pretoria, South Africa.
We discuss two major projects that Nialing is a part of at the CSIR, one a predictive
policing use case which focused on understanding and preventing rhino poaching in Kruger National
Park, and the other a healthcare use case which focuses on understanding the effects of
a drug treatment that was causing pancreatic cancer in South Africans.
Along the way, we talk about the challenges of data collection, data pipelines, and overcoming
sparsity.
This was a really interesting conversation that I'm sure you'll enjoy.
Let's do it.
Alright everyone, I am on the line with Nialing Marosi.
Nialing is a senior data science researcher at the Council for Scientific and Industrial
Research, or CSIR, in Pretoria, South Africa, and Nialing, welcome to this weekend machine
learning and AI.
Thank you.
Thank you.
I'm really happy to be on today.
And I'm happy to have you on.
I got a chance to hear your talk at the Black and AI workshop at Nips, and you are doing
some really amazing work.
And I'm looking forward to learning even more about it.
But before we get into what you're up to nowadays, why don't you spend a little bit of time
telling the audience about your background and how you got involved in data science and
machine learning?
Alright, so I am actually originally from Lesutu, but I did most of my university in
the US, so I went to my Calista College for my undergraduate.
I was going to be an econ major because all the cool kids were doing it, but I know
and I've been distracted halfway through.
So yes, in St Paul, Minnesota, I decided during my degree that I ought to know a little
bit more about computing in order to be a really good economist, of course.
But then the bug caught.
I just couldn't stop.
I took an AI class in undergrad, and I was taught by this really brilliant woman, Susan
Fox.
I'm completely plugging her in right now shamelessly.
She was completely brilliant, and I was just wowed by it and the area.
But generally, the whole reason I was into econ to even start with was because I was really
obsessed with trying to understand things.
Like, why do things happen the way they happen?
Why do people do the things they do?
And for what I, as far as I knew, economic theory was one of the best way to describe why
people do the things they did.
But then when I got into AI and the modeling of AI, and then later on, I went to, for my
PhD, which is very unfinished, I went to University of Minnesota and I was doing machine learning.
Then it was also the development of these models that can help you not only observe, which
sometimes in econ, you observe, and then you plan back, but also try to model these things
and try to extract these features that explain to you.
And if you can, you know, in mechanical design, mechanism design, you know, the whole thing
of like, if you can just tweak it a little bit, you can get the output you want, that really
got me very interested.
So overall, I will say I am a true student of liberal arts.
So my machine learning is tainted by econ, is tainted by biology, and it's tainted
by a couple of other things.
So but I've always just wanted to know how things work the way they work, why they work,
the way they work.
And I love Paxons.
I love just discovering what's embedded in a process.
And yeah, that's that.
Yeah, that's amazing.
The more and the deeper I get into, you know, the machine learning AI and the kind
of the opportunities around it, the more I am convinced that, you know, everyone, you
know, we need people from a very broad cross section of backgrounds who understand
this and are working on it and can kind of, you know, both, you know, bring their perspectives
to it, but also apply it to, you know, their disciplines and I'll end doing that.
Can we really advance this to where it needs to be?
No, I agree with you.
I actually think it's in the problem that the worth of these processes is.
I mean, the mathematics can be really beautiful and understand this, the structures under.
But when you sit in an area and you're able to dissect an area and actually apply it,
I've always been drawn to that kind of machine learning, so very applied.
I like seeing the results.
What is CSIR?
Oh, yeah, CSIR, so it's, I think in the US, we call it the government lab.
Okay.
National labs.
We have a national lab, yeah.
Yeah.
Okay.
Yeah.
So it's just this campus and we've got different units.
We've got nano-centile study, nano-particles and the applications, biosciences and these are
the biologies, the wet labs.
Okay.
We've got security.
We've got, so it's a bunch of research lab, national research labs and we serve both the
government and industry.
And academia, actually, sometimes.
And so what are some of the types of projects that you get involved in there?
Yeah, so going back to my all-ever-so-curious, I've been in, I know, but I do try to segment
them, but I've been in a couple of projects and maybe just for today I'll talk about just
the two of them.
One that I'm currently working on and one that I just recently parted with a little bit.
And so some of one of the projects that we worked with was an understanding rhino poaching.
So I have a feeling a lot of people will be aware of this that there is a huge problem
in rhino poaching.
And so we were contracted by the South African park rangers who were the guys that police
the parks in South Africa.
And they contracted us to say, can you guys provide for us some model to understand how
these poaching happens?
And if there is any way that maybe we can have a sort of predictive system that we can
work with, to just cut down on the search space.
So we worked with them.
We were contracted to go work at the Kruger National Park, which is a fairly big national
park.
It's the size of Israel.
Yeah.
Kruger.
Yeah.
It spans all the way into Mozambique.
It's on the border with South Africa and Mozambique.
It's fairly big.
But we work with one of the units in the CSI heart that does security.
And we just, we were building a model to sort of try to narrow down a probability distribution
map over the land.
So to say, you look at the different features there as in things like when was the last
poaching, how far from water, what's the weather like, what's the moonlight like, how far
from the road, and things like those or how dense is the forestry.
And try to put all those features and see how much each one of them contributes to an
area being very high that, you know, a rhino is going to be poached there.
And by doing that, then, you know, maybe the parks can then be allocated there in areas
that we suspect is going to be high poaching.
Obviously, this is, this is a model that can get quite compromised to somebody knows how
it works.
Because then, you know, shifting resources from one area to the other.
And so, you know, maybe that's a lot of time.
But rhinos are fairly territorial.
And so, like, the poachings are going to happen around where they are going to be.
And so we studied those things like how they migrate and all of that kind of stuff.
So that was a project that we did.
It's currently running.
And it ended some early this, this, oh, it's a new year in 2017 and March, 2017.
Okay.
So that was that.
But currently, yes.
You make that one.
That project sounds so easy.
But when you kind of rattle off some of the features of this model, it strikes me that
data is coming from all over the place.
Like lots of different data sources.
Can you talk a little bit about the, you know, the kind of the pipeline.
And the challenges associated with that particular project.
Yeah.
So we actually worked a lot with the experts.
So as one of those models that, like, one was informed by data and the other one was
informed by the experts to start off with, we built this thing where, as the ranges are
patrolling, they can start to input data.
Okay.
So, for example, data about you can see some of the leftover food steps by maybe people
that should not have been in the park.
Okay.
There will be some areas of the parks that are closed off, but also if they had been approaching,
you can see like food steps towards there.
And so like that would information that like a park range would, would, would input.
But also the park does have sensors in there.
And so the sensors would be another, you know, input, data input.
The park we do have knowledge about where the water sources are and generally what, like,
vegetation and what's the word, like, you know, the level, like, how steep it is, how mountain
else it is and stuff like that.
Okay.
And like, how far from the road it is.
So there was already some of that data that was there because obviously this is a very
important area in South Africa.
So that information was there, but that combined with literally the ranges just walking in the
park.
Okay.
So something can be noted as the water source, but then the water is all gone if it hadn't
been raining, things like those, you know, then they would correct it.
So we were seriously learning and we actually have this as a, as it's continuously ingesting
new data.
So every day we get new data from, you know, the last night patrols or things like those.
We also get data from helicopters that will fly over.
Yeah.
So you're right, it came from multiple sources and we just put it together.
Not just, but so some of the problems that we run into here, one of the biggest problems
actually that we ran into was the problem of statistics and the problem is that we would
have a lot of spots.
So we, we had very sparse data, it's a vast land.
And so we will have a lot of areas where we hadn't seen any data points, right?
We don't, we don't have any information on whether there had been a poaching or something
like that.
And we really could only predict based, you know, like everything else that there was
no poaching.
We had to also say whether there was no poaching because there can be a poaching there
or it just hadn't occurred yet.
Okay.
Yeah.
So that was, I think the spacity of the data was one of the things that was quite difficult
when we're trying to generalize over the whole park.
When you, you, you do see it change.
We did see the patterns change over the years.
So, you know, that's why I go back to that thing of saying, you know, just because you haven't
seen a poaching happen in an area doesn't mean that it's not going to be the next area
of interest.
Right.
Right.
Yeah.
How did you deal with attacking that or overcoming that sparsity issue?
Well, we are, I don't know if we, this is cheating or what, but we, we did it.
We did a lot of smoothing.
So, we did a lot of things.
Okay.
It takes things out, but, you know what though, I have to say this.
It turned out that it wasn't even the big problem with our motto.
It seemed, it was pretty good.
So we had cut up the park into Kilometre square grid.
Okay.
It's pretty good, but it turned out that even at the granularity of Kilometre square
grid, it's still too difficult.
Like a poaching can actually happen in this square where we said it would happen.
And they will still not get the poachers.
Ah, okay.
And so it has to make it bigger.
So it has to make it bigger.
That granularity was even too big.
Ah, even that.
And this is, I think, we were working, I think, overall, it's like very square Kilometres
and we broke it down into Kilometres and even that wasn't, wasn't good enough in terms
of truly pinpointing this in order to make it effective enough.
So I, you know, it's one of those where you're like, that's, I mean, sometimes it worked,
but then it was, that part of it was a bit difficult because it's like, oh, you know, you were
so close and our model, certainly, took that into effect because for us, our model punished
a lot more if we missed the poaching, right?
Right.
And if you say there's going to be a poaching and the poaching doesn't happen.
So those are some of the things that we had to take care of.
And like, you know, making sure that the cost truly reflects the outcome that we want.
And was the, you talked about the granularity in terms of the area, but what was the granularity
in terms of time?
Like how did you, did you, were you trying to predict that a poaching might happen in
a given day or week or month?
It was a day.
Okay.
And we were getting updated data every day and so the predictions were daily within
you data.
Yeah.
And did you find that the predictions in terms of area very dramatically day to day or
were they relatively static?
Yeah, the shifts would take a little bit longer.
So the migration pattern in terms of where the poachings would happen would actually shift
a little bit like we take multiple, multiple days to actually move.
But like I said, that's the problem.
And if you say, you know, it's going to happen in this grid and then like next, it's going
to happen in the next grid or, you know, it was still around the same area.
So the policy wasn't as bad.
But once again, it's the limited resources that the park rangers have.
It's the danger of the job.
Right.
You can't just complain side, right?
I mean, just because you are there doesn't mean that they're going to stop poaching.
Right.
Yeah.
And so there were some of those things that actually, you know, really complicated the problem.
But you know what?
I have to say this.
And maybe there's a little bit of a plug.
It was, it was very interesting work.
It was very useful work.
And if there's people, I know there's work like this happening in Kenya.
The groups that are doing the same thing around poaching in Kenya.
And you know, it's one of those things that, you know, it just needs, maybe needs more
men power because it's, it's the only way to truly beat it because it's a social problem
as long as the incentives are there.
Right.
I mean, definitely that gets made by poaching is an offer somebody to risk their life and
go to jail and or what jail, right?
So that's the, that's the thing.
That's why I'm saying like, even when we made it fairly difficult, there would still
be occurrences.
Right.
And and it's mostly because of the geographical space.
So when this model runs in smaller spaces, so there were privately owned firms around
there.
And those are not as big.
And their problem there wasn't as bad because, you know, they're managing a smaller space.
But given how big the space is, given the incentives, given that this is a project that
goes between two countries, you know, it gets very difficult to pull this.
Right.
We lend a lot and the South African park rangers are still using the two.
So they are still getting some value for it.
So I always say sometimes when you're working with Israel world problems, it's just cutting
the search space.
It's not finding the solution.
It's cutting the search space.
Mm hmm.
Yeah.
And in this particular example, we're talking about search space both from a modeling perspective,
but also literally the land perspective.
Yes, the landmass, the little red, yeah, like, yes, in kiloveturn, in by, so no, it's
in kiloveturn.
Right.
Yes.
Right.
But yeah, that project came to, well, our contribution, my contribution in that project
kind of came to an end when we were done developing the model, and that was in March.
And pieces of those are published.
And then of course, like I said, the software was delivered to the park rangers.
And so I moved on from that one, from that project, but it's certainly an interesting one.
And it's been one where we actually have been contacted by other people.
For example, the cash in transit robberies, you know, where they're saying, you know, can
you tell us, spatial, because we've worked with spatial data now, spatially, you know,
what are the chances that this one area is going to be a hotspot for the next, you know,
a hit on a delivery, but yes, you know, they all link up, well, somewhat.
It's different, but you know, at least they have that spatial component.
Right.
Right.
So that one ended about a year ago, just over a year ago.
And so now you're working on what?
So now I actually, it's funny because my life sort of came full circle, and I went back
to biology.
I know I did say that I started off as an economist, but people have to forgive me because
like I say, I am a liberal art student.
So I actually have my undergrad is both computer science and biology, and then, you know, my
PhD work was the science economics and bioinformatics a little bit.
I was just doing a project.
That's also why the PhD never got finished, there was just too much, too much going on.
But so I got contacted by the bio sciences group here at the CSIR.
So these are the white lab biology, so we actually run the experiments and run samples.
And so they had run a project like last year, and that project was on understanding an
effect of one HIV treatment drug, and they found that, you know, there were biomarkers
in African populations that had not been studied and were causing renal failure in the patients
that were taking that specific drug.
And so based on that, it was a signal that no, actually we really have to take this problem
very carefully.
So we know that generally people have the same processes, generally, as human beings.
But also there are some manifestations of diseases that are race or geography dependent.
And so we wanted to, so South Africa is going through a whole thing.
So there's such an increase in cancer incidence in South Africa, as is in the world over.
But there's several research that will show that the rates of these incidence is actually
different in different populations.
So for example, black men will have a higher incidence rate of prostate cancer.
Or for example, it's a lot more difficult to detect breast cancer in black women, and
actually in Latina women, even more, mostly because of how dense the breast tissue is.
So there are some of these things that we know that there are some differential biomarkers
in different populations that make the disease manifest itself differently.
And therefore the therapy ought to be different.
And so we decided to study pancreatic cancer in African population, but specifically South
Africans, which literature will show that they can be quite different, you know, they
can be quite genetically different from maybe let's say West African.
So I want to make that clear.
We're not looking at all people of African descent.
One of the really biggest things I have to say, so besides understanding these biomarkers
is actually just to create the data, make sure the data is out there.
So there may be however much we get to in identifying these biomarkers in pancreatic
cancer, but the most important thing is to create this data so that other researchers
in the rest of the world can study the data because one of the biggest problem with diseases
in African populations is that African populations are not usually included in medical trials.
So there isn't enough information and enough data to go about to see how things affect
people of African origin.
The same happens with the amount of genomic data that's out there, which of course also
the amount of proteomic data.
We are looking at proteomic data.
So this is the data, it's just the proteins and that in actually it's going to be peptides.
But I'm going to stick with proteins just for the sake of just removing it.
It's not really complex, but you know, just for we're having a chip chat, right?
Anyway, the scientists hopefully will not kill me for saying proteins when actually.
So yeah, so you know, we just want to collect like try to find some of these proteins and
see if there are some of them are actually biomarkers in this disease and maybe it might
actually help to say what actually a biomarker is because there's a technical definition
of the biomarker is that a biomarker has to be a protein that is related to a disease.
It is actionable and it is measurable.
So it is measurable enough that you can make a decision.
So there are, so this is why we always talk about biomarkers because if you can truly identify
biomarkers, which means they are actionable, then you can hopefully start to think about
drug development or some kind of corrective thing because you can clearly pinpoint it
and you can take some action.
And some of that action can just be that you can predict and say if I see this biomarker,
I know it is differentiated enough that I can actually predict your susceptibility to
the disease or actually whether the disease or the stage of the disease.
So that's what we wanted to do.
We want to identify these biomarkers and then we want to populate this data set so that
other research has had it.
And for us, we certainly want to find these biomarkers and pass them on to our own, you
know, drug development companies or, you know, we, it's a whole pipeline, this whole system.
So you've got doctors in one end and then you've got academic and research in such it
on the other.
You've got drug companies and then it goes right back to the doctors and we're working
with the local hospitals here.
That's where we're getting the samples.
So in the samples from the local hospitals here, in most of them, I in Johannesburg,
I'm sorry, but it's like 40 kilometers, 50 kilometers away from each other, so practically
close by.
Maybe let's talk a little bit about that, that initial element of collecting the samples
and processing them, and turning them into a data set that you can use.
How, how do you go about that?
Well, you get a sample and you have to prepare this sample.
So I mean, you know, like the doctor goes in and then they diagnose you, oh, that sounds
bad.
I'm sorry, it's always so morbid this whole discussion.
But, you know, like, you know, there's cancer and they, you know, then we ask, you know,
when they are going to do biopsies and stuff like that, right, they'll have like a sample.
And so we get this sample and then it goes into a lab, it gets prepared, it gets run through
mass spec, and the actual process that we use is the SWAT process.
It really is not that important, but it goes through mass spec, and then mass spec is going
to tell us, you know, which proteins are present in this sample.
It's also going to tell us how much of each one of these proteins are present.
And it's in that how much, well, assuming, first of all, you can clearly and neatly say
which proteins are present, because that's the whole science of its own too.
And then you then, after you have defined your, your, your identify them, then you find
out how much of them are present in the sample.
And then you are then, if, if you can find differences between either a protein or a group
of protein between the disease cells and the non-disease cells, then you can say that,
you know, you're starting to get biomarkers for that specific disease.
Now, some of the problems that we run into here is, so I actually had one.
I worked a little bit with data, with genomics data, and anyone that has done like genomics
data and done PCR, I mean, the whole point of PCR is to, what's it called, is to make
more of it.
I can't think of the word.
It's to amplify it.
Expression or amplification?
Yeah.
Yeah.
You know, you can amplify DNA, right?
Unfortunately, for us, you can amplify the protein.
So the amount of sample you have is the amount of sample you have.
Okay.
As always, you have like, so proteomics is one of these things that reproducibility is
a big thing.
And so also, you know, like the whole thing of like confidence in your results.
So this whole statistical packages that are just developed to do this, because the sample
will degrade, but now you can't do anything.
And so you don't get as high a signal.
And so, yeah.
So one of the first thing actually we always do is to standardize our equipment so that
when we do get the sample, we try to get everything run as quickly as possible.
I know I've actually just gone into so many other things, besides where we start the
question.
But hopefully there is a thread that runs through.
Well, you know, one of the things that, you know, one of the things that comes up in
this area is that the data collection itself is often pretty noisy.
And I'm wondering if that's something that you experienced and, you know, how you dealt
with that in your pipeline.
Yeah.
So we are actually just now starting to collect the data.
So you're right.
We get, we get like by like, no, this is a three year project.
And so year one just passed.
And so that was the data collection for the biologists.
And for us, it was to standardize the workflow.
So that then takes care of the technical noise.
So what they call, what is it called, like technical or something?
Anyway, I'm going to call it technical noise because I can't remember.
And I think for people in this audience, it makes sense.
But this is, you know, given the tools that you are using, right?
How much noise do you just get from those tools and try to measure that?
So that's the first thing.
And then yes, we do have sample noise as well.
And the thing, generally, the thing you do in this area is to just try to get as many
samples as possible, which we can't always hide.
And maybe that's a good thing because I mean, it's not as many people have counts are.
But then of course, it has those other implications.
But yeah, I mean, you just, I mean, like I say, it's just like any other statistical exercise.
You just have to have more data in order to be confident in your results.
You have to have more data.
You have to run the samples multiple times.
So for each sample, we run it multiple times and to find out, you know, the noise that's
embedded in just that one sample and the variations that are in that one sample.
And then we run it.
Sometimes we run two samples at the same time and then look at like that, that are supposed
to come from the same cluster.
And then we look at like the variation of the protein there.
And then that will help, you know, at least there we know that they just ran through the
same run.
So at least the technical variation is not exactly there.
And then we can just look at the sample variation.
But this is the place.
This is what biology is.
You're right.
It's always, it's always a variation.
And so the only decisions you really can make is when your data is sufficiently separated.
So one of the first things you do is just look at the means of the two samples.
So you look at mean expression of the disease cell and you look at mean expression of the
non-disease cell.
And then you compare the two means.
And if, if, for example, the standard error, you know, Chris crosses, you really have to
go back and just work through your, your workflow.
So we just start off simple as that.
Because then you can't tell, obviously there you can't draw in conclusions.
But if we can start to see some of those differences, then we get a little bit more confident.
And then we can start to see per sample, where each sample falls.
And then we start to look at, you know, can we predict per sample?
And but yeah, this is something that can be one protein or it can be a combination of
proteins.
Is the process that would happen on the medical side the same as your process?
Meaning you, you got these biopsy samples and you ran them through the mass spec to
separate out all the proteins.
Is that how the absent, your data collection is that how the disease would be diagnosed
or would it be like a radiologist and imaging data and that kind of thing, a different kind
of process?
Oh, I think usually it is still the imaging part.
I have to also say, I don't know as much, I have absolute, everyone's, well, yeah, I have
a lay only a lay on knowledge on how the diseases themselves are diagnosed, like in the hospital
itself.
Because yeah, I get to interact with the data once with the bioscientists and they run
through and all I do is help them standardize the equipment and then later on to do the data
analysis.
Okay.
And so the data that you get is already labeled as to whether the sample is cancerous or
not?
Yes.
Okay.
Yes.
Yes.
The thing is we are getting, yes.
So after a patient has been diagnosed with a certain kind of cancer, then we get a sample.
So if, you know, like you've been diagnosed with pancreatic cancer, then we get the sample
from the pancreas.
We also get a sample from the biofluids, which are like bloods and the lymph something.
Yes.
The biofluids.
So that's the information that we get.
And then yes, that's the one that gets segmented with the mass spec.
Okay.
And so you're, you're kind of in this data collection process now.
Have you started?
And you've also started kind of exploratory work with the data, but you're pretty kind
of the modeling stage.
Yes.
Yes.
Yes, we are definitely before that.
So like I had mentioned that other study with using data.
So we actually are using that data to sort of standardize the workflow.
So all the way, like to see how things shift from, you know, the point of them getting
segmented all the way until they get quantified and start to, you know, to understand that.
And then that way we understand our equipment and we understand what we need to change.
So there are multiple workflows in proteomics, multiple, they spy ex, they is, they is open
swathes, you know, there's trans proteomic pipeline and and all of them really are like
these pipelines.
So, you know, it goes into mass spec and then it gets into another thing that's going to
pick like a peak, like it's going to find all the areas that that are present and then
it gets labeled and then it gets quantified and then, you know, all of this.
And then like we're still at the peptide level and then we go to the good old string alignment.
But what do they call in proteomics?
We do alignment to try to figure out if you see this set of peptide, what's the probability
that it's this protein and then it gets labeled.
So that is always a pipeline.
And so, you know, all these tools in the pipeline are pieces of code and sensors that come
with their own variation and have to be standardized.
So that's what we've been doing.
Once we have that, once we have data that we think is good, that we think we can trust
which will hopefully be at the end of this year.
So the process of actual data analysis is going to be this year.
And then, then we can start really running the biggest thing in this area is to do classification
right, when an extracting those features that put one sample one side over the other.
Because those are the biomarkers, right?
Like they're going to, in this area, be like those features that are seeing your disease
on one disease.
So for us, we're looking at it as a classification problem and to put it on one side over the
other.
We are also very interested in actually just running a clustering problem, even on the
data.
So maybe this goes back to your question of, so it comes labeled to maybe even see if
like, are these expressions, you know, all that different?
Can we, when we cluster them, are there, you know, like some similarities, even between
the disease and non-disease?
So you just cluster the whole data set and hopefully we'll get the separation that these
are the disease cells and they'll cluster together and these are the non-diseased, you know,
and they'll cluster together, the data from both will cluster together.
But you can do that, but that's a lot of the work that you do when you're just exploring
your data.
The same thing, which is, you know, like understanding the differences of the means, you go through
and you just understand your data and then like, you know, like chopping up your data into
blocks so that you're not observing some other phenomena, let's say, maybe you're just
seeing this disease only in like old people or something like that so that you can mix
like, you know, old people and young people and still try to detect these differences.
It ends up being something a process that has a lot of data and I do think one other thing
that makes the problem a little bit complicated is that actually in the whole process of running
your mass spec and everything, though we might run to one to run as many samples as possible.
Remember, I did say that's the sample degrades.
So we always have like a timeline of how much we can take to even run experiments and
that actually is one of the things that limits how much data we can collect.
So ideally we'd collect as much as possible, but you know, we get limited by that.
It's not just that we get too few samples, it's also that the samples we have can degrade
and it can be difficult to rerun them later.
Which actually is why sometimes this process of swath is good because all it does is just
breaks down everything, all it wants.
So without even necessarily needing to label it, you don't need to pick it just segments
everything.
So later on you can actually go back to the old samples and study them when you have
more information of how to actually understand this data, at least it will exist.
One question that occurs for me in thinking about the way you describe your workflow, even
like at the super macro level, right?
The first year is spent on data collection and kind of refining this data workflow and
then you kind of transition to an analysis phase in the second year.
But often these two are like the overall process of getting to a model is very iterative and
you end up tweaking the way you collect data and the kinds of data you collect and building
out features and things like that.
And I'm wondering how, if that's something that you observe as well and how you fit that
into the way you work there on this project?
Yes, definitely.
We definitely do run the problem of getting to some point and then just not having the
results that we wish to have, but or just not having results that are reliable.
But yeah, so it won't mean that we will stop collecting data on yet when year three, that
data will keep coming.
And so while we are running this analysis, we might find that actually we have to check
away some of that data and have to inform the doctors on how to collect the data.
The nice thing is that, like I said, this kind of study is not like we are breaking ground
in the processes, it's not.
We are using processes that have been developed and we're trying to make them better.
There's a lot of work to still like for improvement in this area, like technically.
So yes, we can contribute those kind of technical, you know, like contributions.
But the processes, there are multiple studies, there are multiple universities that are
doing the work and material mix and in cancer.
So you know, we have an idea generally of how to prepare samples of how, you know, we
have a lot of literature that we can lean on to.
So hopefully, you know, fingers crossed, things will work out fine and generally they really
should.
Right.
I don't know what could be so different because we expect the difference is going to be
in the population.
Right.
Because in terms of collections and stuff like those that we are just, it's standardized
methods.
Yeah.
Yeah.
So ultimately, the goal here isn't to, you know, pioneer some new, you know, approach
to collecting the data or modeling, it's rather to apply things that are fairly well understood,
but to a population that has been underrepresented and understudied.
Exactly.
I'm thinking about the, you know, the conversations that I've had with folks in data science
and researchers in, in Africa in particular, I'm forgetting the name of the gentleman
who presented at the black and AI workshop in, from Kenya and, yeah, I think the common
thread through, you know, the things that you presented is this idea of applying these,
actually both of the projects, I think he was working on a similar project with regard
to, to natural resources, as well as kind of applying some of these methods to, to kind
of understudied populations.
And I don't know, I, I guess the question that I'm kind of struggling with is, is, you
know, is a little bit of, is that the fact that you're kind of both working on similar
things is that, to what degree is that kind of representative of the unique, you know,
challenges that are kind of expressing themselves in African countries, you know, versus maybe
a selection bias, that's what the organizers of black and AI thought would be interesting.
Yeah.
So, you know, but I think I actually had a little bit of a difference with the, with a difference
of understanding with the work that I think Shira actually presented.
I, I thought there was a lot of innovation in that, because it's, it's understanding
the resources that you have and having to make these processes work for you.
So, I have to say, and this is actually something I learned about when I moved here, there
is a certain way that you work with these problems when, you know, you are in the US
and you have the resources, you've got all the computing resources and you've got, you
know, other resources, and then you move here and then you don't have as many resources
and the level actually that the innovation comes at that of trying to still do the same
quality of work, but, but at fairly low resources, because the work still has to be done.
So I, I actually really think that is, so we have two areas of opportunity to contribute
I think to, to, you know, the scientific dialogue in the world. Number one is how do you do
science when you don't have as many resources, but how do you do good, usable, useful
science?
And I think for us, that's the most important thing. We don't have the luxury of, you
know, dwelling on the smallest of problems, like, I think it's going to sound bad.
I, my, I, please don't give me on Twitter, but, you know, for goodness, but, you know, like,
if I'm going to be asking for a grant, like, the, the level I am going to get questioned
at, you know, like, it's not just like there's all of this just a line there. So you have
to learn how to work with, with, with those things. And I think that's where innovation
comes from, because in fact, then that sort of thing can be pushed back into the developed
world and say, no, you can actually do it with less resource. And so, you know, there
isn't, you know, that can actually help. And there's been instances where this sort of
thing has happened. And processes have gotten removed because of that. Because, you know,
as they say, what is it called deprivation is the mother of invention. I'm sure I've
just made that up, but I think this is a specific example of interviewing somebody who's
English is a second language, right? We make things like that. But anyway, so, so that's
the first thing. But the second thing is that we have very interesting problems. Like,
we have problems that actually you can make an impact on. Like, just study in this data,
however much we go through, and, you know, can make a difference. And that's the luxury
that we have. That's the thing that really motivates us. So I think, I mean, there's a lot
of basic research that gets done here too. I mean, Amazon has a very, very good lab in
Cape Town. So that's where that's coming out of here. There's a lot of other labs actually
that are running around. There's research institutes. Even here at the CSI, there's a lot
of basic, basic work that gets done. But like I said, I like applied work. So I can't
really say that generally captures the type of work that gets done here. But I do think
we do more of that kind of work here. And I think you'll see maybe that same thing happening
with maybe Latin America also, some of the, you know, the results you see coming out.
And I think it's because we stand to truly make an impact. And it's really attractive
to work in an area where you feel you can actually make an impact to a process to people's
lives. Right. Outstanding. So that's that. That's my walk around. Yeah. And so what are
some of the other things I came across a couple of other things that you've been involved
in? I know last year there was the deep learning in Daba. Were you involved in that?
Yes. Yes. Yes. I was, I was one of the organizers of the deep learning in Daba. I still
am. Okay. So for folks that are familiar with that, what was that? I was, I was cheering
you on from afar. Like, you know, I saw the tweets all the time and I was like, Oh, man,
I need to find a way to go to that and just never was able to make it happen. But it
looked like an awesome event. It was so great. So what happened is just a team of,
our friends, I think actually, these are people that already knew each other from before.
I mean, but overall, we all kind of also met or over Skype and, you know, but we, the
whole purpose of the in Daba is to strengthen machine learning research in Africa. So one of
the big problem actually, it's not the problem of even computing resource. Sometimes the problem
of human resource, you know, like building a team that's big enough to truly, you know,
build that momentum. And so we wanted to find out who else is here doing this work. It can
be really difficult to find out who because we are so sparse, you know, like placed all over.
Find out who's doing it. And for people that are interested, is there where we can
capacity change them? So it was, it was a summer school. I urged people to go check out our
videos on on YouTube. And we managed to get a, you know, a lot of people that actually
this time around have the main planning people were people that have their roots in Africa.
These are Africans. So we managed to all come together. And some of them were in deep
mind and some somewhere in the US and a lot were here in South Africa. And the next year,
so 2018 in Daba is still going to happen in September. And we're looking even for even more
Africans that are practicing in this area because we don't want to have this idea that then no
Africans are doing this work because then it's too wide. Looks unreachable. It looks foreign.
And it's not foreign. It's a technique that can be applied to our problems in our world. So
we have been trying to find more Africans or I'm also trying to find experts, not just, you know,
Afro-African descent, but other experts to come and teach and you know, just be around here.
And it was a fantastic, fantastic event. We had Nando, we had Anima,
who just came, we had George from Brown. We had, and everybody was so, it was a really,
really good contagious. And I can tell you already the type of research and the kind of relationships
collaborations we've formed just from that week. Like it really energized our work.
Oh, that's great. Because even with the guys at Black and AI, I got to meet them because they
saw that we're doing this in Daba. And I really have never worked with it like nicer planning
committee. We generally, I don't know if they'll be mad at me for this, but we fight like crazy
by the nice thing is we are all interested in the same thing. And we work like crazy too. So
anyone that wants to work with us wants to help us see this thing come true, please. Like we are
always open. And that's what we want to do. We just want to strengthen African machine learning.
We have very interesting problems in Africa because the dynamics are different. So if you get
a model in US, it may not work here just because the dynamics are different. So we bring in a whole
new way of turning around some of these theories to get to understand how they may work in our
environments. And we can't do that if we don't have truly fundamental knowledge of how these
things work. We can't expand and stretch them to fit our problems if we don't fully understand
how far they can stretch and expand. So that's why we want to embed like deep, deep, you know,
theoretical knowledge. So people we can really grasp these concepts. And then I think then we
can really do something for ourselves. Well, you're passion for all of this is very palpable,
very tangible. And I appreciate you taking the time to chat with me about it. This is really
fun. Yeah, anything else that you'd like to mention before we close out? I think maybe I'll actually
go back to the whole thing of collaboration partners. If anyone is interested in any of the things
we said or has been interested in a problem that maybe they observed well, they took, you know,
a trip down here to South Africa or anywhere else in Africa. We like collaborators because,
you know, we don't necessarily, it need not be that we are isolated, you know, we get isolated.
So if there are people that are generally interested in working with some of these projects,
one thing I can really tell them is they are rewarding. The findings can be quite rewarding.
And that we're all looking for collaborators because we don't also want to get myopic and how
we understand our own problems. Perhaps looking at them from the outside can be a way to solve them.
So we're open to discussions. Great. And is there any particular best way for folks to connect
with you? Sure. They can get in touch with me. I am on Twitter. Oh, I don't know if I should disclose
who I am on Twitter, given the things I said. I want to tell my, my handle is Ed Nunewska.
That's the name my father gave me and it's stuck. Ed Nunewska. So, Ed Nunewska. So that's that.
And then of course, my email is and more CSI R.C.O.D. Zere. And maybe you can just link that
to the link to the web link. We'll link all of that together in the show notes.
Okay. Great. Yeah. No. If you're just getting in touch with me,
if you want to get in touch with the deep learning Indava to please just link our link over there.
It's deeplearningindava.com. If you want to get in touch with our combatee, please check us out.
Check, you know, maybe there's somebody they've always wanted to work with. Maybe you just like us.
But anyway, yes. I think collaboration is good. Yeah. Great. Well, Nyalin, thank you so much.
And well, yeah, just thank you so much. Thank you so much. It's been interesting.
And please, you know, everybody, I'm always open for discussion. If I said something,
that was not correct. Please, you know, guide me in the right direction. That's what I said,
collaboration, conversation and exploration. That's it. Awesome. Awesome. Thank you.
All right, everyone. That's our show for today. Remember, we want to hear your thoughts on personal
AI head on over to twimlai.com slash my AI to share. For more information on Nyalin or any of the
topics covered in this episode or to share your feedback, head on over to twimlai.com slash talk
slash 109. Thanks so much for listening and catch you next time.
