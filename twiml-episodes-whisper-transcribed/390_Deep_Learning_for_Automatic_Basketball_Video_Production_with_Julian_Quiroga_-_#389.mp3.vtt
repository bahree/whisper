WEBVTT

00:00.000 --> 00:13.400
Welcome to the Twimal AI Podcast.

00:13.400 --> 00:25.680
I'm your host Sam Charrington.

00:25.680 --> 00:29.920
Before we get to today's episode, I'd like to send a huge thank you to our friends

00:29.920 --> 00:36.280
at Qualcomm for their support of the podcast and their sponsorship of this series.

00:36.280 --> 00:42.640
Qualcomm AI research is dedicated to advancing AI to make its core capabilities, perception,

00:42.640 --> 00:47.440
reasoning, and action ubiquitous across devices.

00:47.440 --> 00:52.080
Their work makes it possible for billions of users around the world to have AI enhanced

00:52.080 --> 00:56.680
experiences on Qualcomm technology's powered devices.

00:56.680 --> 01:07.120
To learn more about what Qualcomm is up to on the research front, visit twimalai.com-qualcomm-qulmmm.

01:07.120 --> 01:09.120
And now onto the show.

01:09.120 --> 01:10.120
All right, everyone.

01:10.120 --> 01:12.480
I am here with Julien Carruga.

01:12.480 --> 01:16.800
Julien is computer vision team lead at Genius Sports.

01:16.800 --> 01:19.800
Julien, welcome to the Twimal AI Podcast.

01:19.800 --> 01:20.800
Hi Sam.

01:20.800 --> 01:27.440
Hey, it's great to have you on the show and I'm looking forward to digging into your paper,

01:27.440 --> 01:33.720
which you'll be presenting at CVPR in the computer vision in sports workshop.

01:33.720 --> 01:38.800
But before we do, I would love to have you share a little bit about your background and

01:38.800 --> 01:41.280
how you came to work in computer vision.

01:41.280 --> 01:42.280
Yeah, sure.

01:42.280 --> 01:46.280
Right now I'm the computer vision team lead at Genius Sports.

01:46.280 --> 01:52.800
I'm responsible for leading applied research in video understanding and videography.

01:52.800 --> 01:58.200
I work together with a team of scientists and engineers trying to get the best technologies

01:58.200 --> 01:59.960
for the company.

01:59.960 --> 02:07.840
Before joining Genius Sports, I was an associate professor in a university in Bogota doing

02:07.840 --> 02:12.600
research in signal processing and in-match processing and computer vision.

02:12.600 --> 02:20.520
But I was contacted by the company and they offered me a joint for a very exciting kind

02:20.520 --> 02:23.280
of products with basketball.

02:23.280 --> 02:29.200
And since I played basketball since I was like 10 years old, so I was so excited and

02:29.200 --> 02:31.560
I accepted the offer.

02:31.560 --> 02:38.120
And yeah, I did PhD in informatics and mathematics in France, yeah.

02:38.120 --> 02:44.440
But before that, I was working more in signal processing and all the theoretical aspects.

02:44.440 --> 02:49.920
But then I started to work with images and video and that's when I'm doing right now.

02:49.920 --> 02:51.240
All right, cool.

02:51.240 --> 02:58.800
And tell us a little bit about Genius Sports and some of the things that you do with computer

02:58.800 --> 03:00.800
vision at the company.

03:00.800 --> 03:01.800
Yeah, sure.

03:01.800 --> 03:10.760
So, Genius Sports is a living company in sports data and sports media and all the regulator

03:10.760 --> 03:16.120
sports bearing sectors and it's specialized in the capturing distribution of real time

03:16.120 --> 03:17.120
day.

03:17.120 --> 03:24.320
In particular, in my case, yeah, we are doing more of applied research trying to do like

03:24.320 --> 03:31.240
video understanding and videography to get automatic production and to collect data in

03:31.240 --> 03:32.240
real time.

03:32.240 --> 03:39.320
This data will enrich the kind of data that we provide to our partners and some of the

03:39.320 --> 03:44.160
product that they're working right now, they are related with automatic production with

03:44.160 --> 03:47.320
single and multiple views, yeah.

03:47.320 --> 03:53.560
And also the collection of data in the age really close to the event to the sport event

03:53.560 --> 04:00.360
for instance, basketball and volleyball and a really short period of time.

04:00.360 --> 04:08.080
How much of what the company does is focused on or related to vision data versus other types

04:08.080 --> 04:09.080
of data sources?

04:09.080 --> 04:10.080
Yeah.

04:10.080 --> 04:15.480
So, actually, we start like two years ago, I think when I joined the company, so we are

04:15.480 --> 04:16.480
really new.

04:16.480 --> 04:17.480
Okay.

04:17.480 --> 04:18.480
We're all there.

04:18.480 --> 04:19.480
Yeah.

04:19.480 --> 04:20.480
Yeah.

04:20.480 --> 04:21.480
Yeah.

04:21.480 --> 04:26.800
I guess you mentioned some of the broad things that you're doing there, but you're, I guess

04:26.800 --> 04:31.680
in terms of your, you mentioned that your focus is like applied research.

04:31.680 --> 04:35.280
What are some of the projects that you're focused on?

04:35.280 --> 04:36.280
Yeah.

04:36.280 --> 04:38.640
So, the first one is out of my production.

04:38.640 --> 04:42.280
It can sound like, what is that, but it depends.

04:42.280 --> 04:45.600
And also the complexity it depends.

04:45.600 --> 04:51.960
So, for the case of the paper that we are going to, it's a single camera disabled to observe

04:51.960 --> 04:57.760
the full, the full card or fill, so the idea is just to generate a virtual camera, but

04:57.760 --> 05:03.000
there are other scenarios when you have more than one camera in order to produce a higher

05:03.000 --> 05:08.880
quality production every switching and doing some transition between cameras.

05:08.880 --> 05:15.280
So in this, in the simple scenario, when you only have one camera, it is just to get the

05:15.280 --> 05:21.360
proper frame and to track the main actions, yeah, and in real time, of course.

05:21.360 --> 05:27.440
But when you have more than one camera, you have to bring it to the spectator like a better

05:27.440 --> 05:33.440
experience of the event and trying to select the proper point of view for each action.

05:33.440 --> 05:35.720
So the problem is more shutting it.

05:35.720 --> 05:43.200
And so the paper that you're presenting at CVPR is that single camera only, or does it

05:43.200 --> 05:45.800
include multiple camera scenarios?

05:45.800 --> 05:46.800
Yeah.

05:46.800 --> 05:53.400
And this paper is for basketball and is with a single view, and the main goal is to produce

05:53.400 --> 05:58.000
a high-query production that is really fast.

05:58.000 --> 06:04.120
Because for sports events, the latency of this broadcast is quite important.

06:04.120 --> 06:11.880
So if you want to do any processing of this video, you don't want to add a large latency.

06:11.880 --> 06:20.760
So actually, in our work, we are able to just add like 300 or 400 milliseconds for this

06:20.760 --> 06:22.160
is really important.

06:22.160 --> 06:27.200
But however, there are other components in the streaming processor that are adding more

06:27.200 --> 06:28.200
time.

06:28.200 --> 06:34.880
So the idea of this technology is to be able to produce this high-query production without

06:34.880 --> 06:42.480
adding a large latency to the full pipeline in order to get this broadcast to the spectators.

06:42.480 --> 06:43.480
Okay.

06:43.480 --> 06:49.880
And if folks are listening and would like to take a look at the demonstration of the

06:49.880 --> 06:53.720
project, we've got that, we'll have that in the show notes.

06:53.720 --> 06:55.240
It's up on YouTube.

06:55.240 --> 06:56.240
And it's pretty cool.

06:56.240 --> 07:02.440
You start out with this kind of wide-frame view of a basketball core and you show by adding

07:02.440 --> 07:07.280
additional layers of information that you can localize the ball and localize the players

07:07.280 --> 07:11.760
and know which part of the core the action is going to be on and kind of pan the camera

07:11.760 --> 07:18.240
back and forth and zoom in and zoom out.

07:18.240 --> 07:25.080
So at the end result, as you've described and as the paper's title, kind of an automated

07:25.080 --> 07:29.800
production where presumably you can just kind of point this camera that's connected to

07:29.800 --> 07:35.760
a model at a basketball core and it'll produce something that's kind of watchable and engaging

07:35.760 --> 07:39.320
and interesting as opposed to just the ones zoomed out view.

07:39.320 --> 07:47.360
When we're talking about sports production today, like I would imagine you've got a pretty

07:47.360 --> 07:52.360
broad range of what's actually done, like you've got, you know, maybe at high schools

07:52.360 --> 07:58.360
or maybe even some colleges, you know, a single video that's without an operator that's

07:58.360 --> 08:03.600
just recording and then, you know, certainly in the professional sports, you probably

08:03.600 --> 08:06.400
have teams of people creating a production.

08:06.400 --> 08:13.160
Can you, is the goal here to produce something that is kind of productized and replaces

08:13.160 --> 08:15.200
one or more of those scenarios?

08:15.200 --> 08:24.480
Yeah, so one of the ideas with this project is to enable some people and college and schools

08:24.480 --> 08:30.120
that they are not able to have a like a professional cameraman or something like that, yeah, to

08:30.120 --> 08:36.400
be able to record their games, yeah, but not only to record the games, but also to record

08:36.400 --> 08:40.800
and to stream them to wherever a point, yeah, through the internet.

08:40.800 --> 08:48.840
Yeah, so, you know, parents and family friends, our fans can watch the game of their favorite

08:48.840 --> 08:57.080
team, yeah, without an expensive system of capturing production and streaming, yeah, this

08:57.080 --> 09:04.640
is one, one, one part, the other part is that we are able to do the auto production, yeah,

09:04.640 --> 09:10.720
with the scene, uh, as you mentioned, with the wide view, we have the full information

09:10.720 --> 09:14.280
and at the same time later, we are also working on that.

09:14.280 --> 09:21.800
We can capture at the same time data, more data locations and analytics and also embed

09:21.800 --> 09:28.520
that in the same broadcast, yeah, and also with low data.

09:28.520 --> 09:35.440
And so is the the setup that you've got a single high resolution camera and the panning

09:35.440 --> 09:40.440
and zooming is all done digitally or are you actually controlling the camera?

09:40.440 --> 09:41.440
Exactly.

09:41.440 --> 09:49.520
Actually, it's a fixed camera, it depends on the, on the fill, yeah, and the distance,

09:49.520 --> 09:54.160
it should be a wide angle with a wide angle or a standard camera, now if you have like

09:54.160 --> 10:00.120
a large venue, you can use whatever camera, but if not, you will need like a wide angle

10:00.120 --> 10:04.920
or with a wide angle, yeah, and then all the production is over a virtual camera.

10:04.920 --> 10:10.760
So it's just like a digital crop or digital zoom, yeah, trying to get that.

10:10.760 --> 10:18.200
So there's an important trade of here is that you want to contain the main action inside

10:18.200 --> 10:22.200
this virtual camera, but this really is, I mean, if you are not doing any production,

10:22.200 --> 10:26.120
you are containing the main action, yeah, but you have to crop, yeah, but you have to

10:26.120 --> 10:30.240
crop enough in order to get the attention of the superior to the main action.

10:30.240 --> 10:34.560
So there is a trade up that you don't want to lose any action, yeah, but you want to

10:34.560 --> 10:40.320
contain the action, so it should be like large and small enough to contain properly that

10:40.320 --> 10:44.960
and it depends of the kind of basketball, yeah, I mean, imagine NBA NCAA is something

10:44.960 --> 10:51.360
like that, or college basketball or kids or something that the speed of the game that's

10:51.360 --> 10:56.760
going to be different, so you can incorporate that in order to have like a smooth enough

10:56.760 --> 11:01.120
production, but you don't want to lose any action.

11:01.120 --> 11:05.120
And what resolution cameras have you worked with out of care?

11:05.120 --> 11:06.120
Yeah.

11:06.120 --> 11:15.280
So our standard setup is a 4K camera, yeah, and the resolution of the producer game,

11:15.280 --> 11:16.280
it depends.

11:16.280 --> 11:21.240
If you are doing streaming, perhaps not so high, but it could be like full HD or HD,

11:21.240 --> 11:27.200
you are just recording, yeah, it can be full HD, yeah, it depends of also on the internet

11:27.200 --> 11:31.400
connectivity, or if you only want to record, if you only want to record, it can be like

11:31.400 --> 11:32.400
full HD.

11:32.400 --> 11:40.520
Okay, cool, so I mentioned in the demo, you roll through at the beginning a set of layers

11:40.520 --> 11:46.400
showing, localizing the players and the ball and things like that, you actually show quite

11:46.400 --> 11:53.960
a bit of information overlaid onto the screen in the demo, what are the main contributions

11:53.960 --> 11:55.440
of the paper?

11:55.440 --> 12:02.360
Yeah, so right now we're developing, I think that we are pushing a lot, trying to get

12:02.360 --> 12:10.720
like M2N systems, yeah, instead of that we wanted to have like a more modular system,

12:10.720 --> 12:17.760
yeah, going to the basics of the team sports, I am trying to get like a button up system,

12:17.760 --> 12:22.360
so in basketball you have your ingredients, you have your players, your hoveries, and

12:22.360 --> 12:24.680
you have the ball, and that's it.

12:24.680 --> 12:30.680
So we wanted to custom something based on that, I'm trying to get good solution for localizing

12:30.680 --> 12:37.320
the ball and players and perhaps in time, yeah, and then trying to build really nice roads

12:37.320 --> 12:43.960
of production that can behave well depending on the different kind of basketball, yeah,

12:43.960 --> 12:48.920
and there is a good thing is that in the company we are a lot of people that love basketball

12:48.920 --> 12:54.840
too, actually we use it all these knowledge and all these experience trying to get good

12:54.840 --> 13:01.640
rules of production that perhaps in this M2N approach is quite hard, because you're

13:01.640 --> 13:06.640
going to have a reference, yeah, and you want to have this crap in order to fool this

13:06.640 --> 13:11.400
and that, but depending on the basketball is not so intuitive and not so easy to include

13:11.400 --> 13:18.280
these kind of rules, but in our approach, there is a modular, yeah, you have your ingredients

13:18.280 --> 13:25.800
or your model or the locations of your actors in this case, ball and players, and we take

13:25.800 --> 13:33.640
out the ref and then depending on that, we can at every time select the proper crop or

13:33.640 --> 13:34.880
the action.

13:34.880 --> 13:43.400
So where they make contribution, first of all, is like a full pipeline, yeah, that the

13:43.400 --> 13:49.800
more data you are getting of basketball games, the detector that you have for ball and player,

13:49.800 --> 13:52.360
they work, they will work better.

13:52.360 --> 14:00.600
So you're going to be always in the right position, and also it can easily be implemented

14:00.600 --> 14:05.640
on any field, yeah, and it's not a spend time is working in a real time.

14:05.640 --> 14:11.360
Okay, so I think you packed a lot into that explanation, but one question that jumped out

14:11.360 --> 14:17.480
of me was you mentioned that you start with these ingredients and identifying where the

14:17.480 --> 14:24.800
players are in the ball, and then you mentioned having rules to determine what the optimal

14:24.800 --> 14:31.520
crop and zoom are, do you mean those rules literally meaning that the deep learning is

14:31.520 --> 14:39.320
doing the detection and localizing the ingredients, and then you've got a set of static rules

14:39.320 --> 14:47.040
that are based on that information that do the production or is the production also part

14:47.040 --> 14:48.840
of a learned model.

14:48.840 --> 14:55.800
Yeah, so the learned model is there are two main components that they are learned.

14:55.800 --> 15:00.880
One is the actors, ball and players, and the other one is what is the game state, because

15:00.880 --> 15:05.320
depending on the state of the game, you want to follow one rule or you want to do something,

15:05.320 --> 15:11.640
you want to be more attentive, or you want to be almost still, it depends, yeah, but

15:11.640 --> 15:17.400
we are not trying to learn the proper virtual camera, yeah.

15:17.400 --> 15:23.880
That was a choice that we did, yeah, I remember that when discussing the different approaches

15:23.880 --> 15:30.440
that we could take, there are really similar configuration of players, yeah, and depending

15:30.440 --> 15:36.160
on the ball, you want to frame that I am actually in one way or in another.

15:36.160 --> 15:41.240
So you have to first, you have to be aware of where is the ball, yeah, but not only the

15:41.240 --> 15:47.280
ball is directing where is the proper framing, and you'll have to be aware of the players

15:47.280 --> 15:52.120
and pleasure distribution, yeah, but not only this distribution will tell you what is the

15:52.120 --> 15:57.720
proper frame, and you need a combination of these two depending on the game state.

15:57.720 --> 16:03.440
And sometimes, I mean, in end-to-end approaches, yeah, if you want to state that like an end-to-end,

16:03.440 --> 16:08.120
you have all your ingredients or even your raw video, and then you want like an output

16:08.120 --> 16:13.240
the proper framing, yeah, and it's going to be like a black box, and trying to adjust

16:13.240 --> 16:18.880
that for one kind of basketball or one kind of thing that's going to be quite hard.

16:18.880 --> 16:26.160
This is what we did this choice, and yeah, so it's really, it's quite easy to set one

16:26.160 --> 16:30.640
kind of behavior for what kind of basketball.

16:30.640 --> 16:31.960
Okay, okay.

16:31.960 --> 16:36.960
When you say one kind of basketball, what are examples of the kinds of basketballs that

16:36.960 --> 16:39.560
would change the way you were referring to that?

16:39.560 --> 16:46.000
Yeah, so there are some challenges when you want to produce basketball with a really

16:46.000 --> 16:52.880
nice zoom, yeah, and just for instance, if you see the production that they are doing

16:52.880 --> 16:59.920
for NCAA or for NBA, it's quite different, yeah, NCAA, usually they are just having

16:59.920 --> 17:05.280
like a almost still camera in the hardcore for hardcore possession, and then just they

17:05.280 --> 17:08.680
are just moving for the transition, and that's it.

17:08.680 --> 17:15.040
For the NBA, they really want to track and to do more zoom when they are doing a hardcore.

17:15.040 --> 17:21.360
So this is like a two kind of production, but by kind of basketball, I'm talking about

17:21.360 --> 17:25.400
the maximum speed, so the main challenge when you are trying to do that is someone that

17:25.400 --> 17:29.520
is really fast, like LeBron James or something like that, yeah, and you want to track the

17:29.520 --> 17:35.920
main action, but you don't want to disturb the people that are watching the production,

17:35.920 --> 17:40.080
so you have a trade-off, yeah, so if you already know that your basketball is not going

17:40.080 --> 17:45.400
to be so fast, yeah, you can have like a maximum speed of the virtual camera and things like

17:45.400 --> 17:51.080
that, and be sure that you're going to be able to track the main action, but if your basketball

17:51.080 --> 17:56.440
is quite fast and you don't want to lose the main action, so you have to relax somehow

17:56.440 --> 18:03.680
your roles in order to always be in the right position, okay, okay, so the modular approach,

18:03.680 --> 18:09.600
it sounds like it allows you to, it gives you a little bit more kind of knobs for addressing

18:09.600 --> 18:15.880
these different characteristics of games in terms of faster and slower, and also it sounds

18:15.880 --> 18:21.800
a little bit like it, it will allow maybe in more of a professional setting if this is

18:21.800 --> 18:26.560
deployed, whoever is using it to kind of tune in a personality for the way they want

18:26.560 --> 18:34.080
the video to kind of feel in their NCAA versus NBA for example, yeah, yeah, and even for

18:34.080 --> 18:40.800
the case of NCAA, between men and women is totally different, usually for women, the

18:40.800 --> 18:45.880
point guard is really close to the half-court with the ball, so if you want to take a look

18:45.880 --> 18:50.320
at the point guard and also the action that is taking place under the basket, you need

18:50.320 --> 18:56.440
a wider framing, but for men it's totally different, they are moving different, so they are

18:56.440 --> 19:00.560
something that, I mean, we are not trained to learn that, but it's also possible to learn

19:00.560 --> 19:06.480
that and to avoid feeling that by hand or by the satisfaction of customer that is usually

19:06.480 --> 19:13.880
what we are doing, yeah, sometimes customers prefer this kind of production that other,

19:13.880 --> 19:19.760
but it's quite easy to transfer that, you know, we're models, yeah, that is not so easy

19:19.760 --> 19:26.240
for an end-to-end system that you have to change your last function or your data or whatever

19:26.240 --> 19:27.480
it is, yeah.

19:27.480 --> 19:35.200
And retrained, you also overlay this graph of Gaussian-based actionness in the video,

19:35.200 --> 19:43.040
and it seems to try to capture where the action is or is likely to be on the court.

19:43.040 --> 19:48.960
Can you talk a little bit more about that metric and what goes into it?

19:48.960 --> 19:49.960
Yeah, sure.

19:49.960 --> 19:55.280
So the first thing that we are modeling players, like two-dimensional Gaussian in the court,

19:55.280 --> 19:57.440
that is quite intuitive, yeah.

19:57.440 --> 20:04.680
So since we have like a core model, it's quite easy to have like shapes with the

20:04.680 --> 20:11.680
proper sizing pixels in the image, yeah, and also to map that to a 2D history, so we are

20:11.680 --> 20:15.200
able to model the distribution of players.

20:15.200 --> 20:21.680
And our hypothesis is that if players are more concentrated in a given area of the court,

20:21.680 --> 20:26.000
it's more likely to have like more action there or something interesting that will happen,

20:26.000 --> 20:27.000
yeah.

20:27.000 --> 20:32.400
Imagine that half of players are in one half-court or the other half is in the other half-court,

20:32.400 --> 20:37.320
so sure if they are in the amount or something like that, yeah, it's quite hard to decide

20:37.320 --> 20:43.080
where I should look, or perhaps I should do a sum out, yeah, yeah, something like that.

20:43.080 --> 20:44.080
So this is one thing.

20:44.080 --> 20:48.480
The other thing that you can easily think is, okay, if you have the ball, you only need

20:48.480 --> 20:49.920
the ball, right?

20:49.920 --> 20:53.880
And you can track the ball like in soccer or something similar or in volleyball, I don't

20:53.880 --> 21:00.200
know, yeah, and yeah, but there are a lot of interesting things that you also want to

21:00.200 --> 21:05.960
see, you'll not only want to see someone with the ball like that, and everyone in the

21:05.960 --> 21:12.640
key area taking screens and doing a lot of things and trying to get free for a shot, so

21:12.640 --> 21:13.640
it's quite interesting.

21:13.640 --> 21:17.800
So this function is trying to describe this likelihood, yeah.

21:17.800 --> 21:23.600
But along, it's not so useful because we know that we want to have this ball.

21:23.600 --> 21:28.280
So what we are doing, we are taking each player and modeling this player as a 2D Gaussian,

21:28.280 --> 21:33.480
and then we get this action as function that is a mixture of a Gaussian, yeah.

21:33.480 --> 21:38.920
And depending of the complexity of the production that you want to do, you can take this distribution

21:38.920 --> 21:40.640
and take the optimal framing.

21:40.640 --> 21:48.280
I mean, you can also compute the amount of sum to cover a lot of players or not.

21:48.280 --> 21:55.000
But in the paper and the video that we showed, this simplification, we are just projecting

21:55.000 --> 22:01.920
these to the mixture of Gaussian to 1D, yeah, and we have like a 1D function, and we

22:01.920 --> 22:07.920
just want to take the peak of this function as the center of the action, and then we just

22:07.920 --> 22:11.840
center the virtual camera at this value.

22:11.840 --> 22:16.440
And then with the ball, we take a lot if the ball is inside or not.

22:16.440 --> 22:22.680
However, embassable with a single view is very likely that the ball is going to be

22:22.680 --> 22:28.160
not visible or hard to detect because someone is taking the ball or hiding the ball or doing

22:28.160 --> 22:32.960
something, and you don't want the system to be lost in this situation.

22:32.960 --> 22:37.440
So this action function is more stable, yeah, and the peak is not moving so fast because

22:37.440 --> 22:40.680
it's not possible that one player that is here is going to be here in the next frame,

22:40.680 --> 22:41.680
yeah.

22:41.680 --> 22:47.480
So it's going to be this kind of smoothness, and we want to track this peak to get this

22:47.480 --> 22:50.840
like a good center for the virtual camera.

22:50.840 --> 22:59.440
Okay, cool. So the actor localization that I'm imagining is a supervised learning problem

22:59.440 --> 23:03.920
you've got video, you've got, you know, someone's labeled your players with bounding boxes

23:03.920 --> 23:09.680
and you just train a model to recognize the players, is that correct?

23:09.680 --> 23:15.240
Absolutely, yeah, it's a classical, a classical, a deep learning approach, yeah.

23:15.240 --> 23:20.160
We have some examples of ball, some examples of reveries, and some examples of pleasures.

23:20.160 --> 23:25.560
And the class of reveries is not too easy for an NCAA, the reveries are always dressing

23:25.560 --> 23:28.640
the same, but it depends on the basketball, yeah.

23:28.640 --> 23:38.000
We want to take the players out, yeah, or at least to be aware of, sorry, we, yeah.

23:38.000 --> 23:40.560
And yeah, but it's totally supervised.

23:40.560 --> 23:47.200
And the precision and recall the, the texture, it depends, in our case, we use a JOLO

23:47.200 --> 23:53.160
version 3, yeah, now it's available JOLO version 4, and today's, I go like your JOLO

23:53.160 --> 23:54.160
version 5.

23:54.160 --> 23:58.400
But there's some controversy over whether it's real yellow or something.

23:58.400 --> 23:59.400
Yeah, yeah.

23:59.400 --> 24:05.440
And, yeah, so the nice thing of this approach is that better, when a bird detector and a

24:05.440 --> 24:11.520
faster is available, we can just plug here, yeah, and be more confident on the detection

24:11.520 --> 24:13.800
of our actors, yeah.

24:13.800 --> 24:20.320
And also we are using our core model in order to, do not train over the raw image, but we

24:20.320 --> 24:24.560
transform the image according to the core model.

24:24.560 --> 24:32.640
So we ensure that the network is on the observer, observing the area of the cart, yeah.

24:32.640 --> 24:38.880
And there's some, um, proportion when we are doing this transformation that made the job

24:38.880 --> 24:40.880
easier for the detector.

24:40.880 --> 24:47.000
So this is why even on the large overlap, we are able to detect players with a really

24:47.000 --> 24:48.960
good accuracy.

24:48.960 --> 24:53.680
So elaborate on that a little bit more, it sounds like you're saying you, you have JOLO

24:53.680 --> 25:01.440
as the detector, and that's operating on still frames, correct?

25:01.440 --> 25:08.120
And you're, you've also got this model for the core that, you know, the angle of your

25:08.120 --> 25:12.760
camera, and I'm assuming we're talking about like the 3D model of the core and like, uh,

25:12.760 --> 25:16.400
the 2D 3D projections, and that kind of thing, is that what you're referring to?

25:16.400 --> 25:25.160
Yeah, so, yeah, so since the camera is fixed, uh, we localize the, the cart, or I mean,

25:25.160 --> 25:29.720
we localize the camera, you can see one side or the other, but it's, it's killing.

25:29.720 --> 25:32.480
So we can compute actually a core volume.

25:32.480 --> 25:38.160
So like the projection of a, uh, a, of a volume of interest, it might be like a four meter

25:38.160 --> 25:40.960
high, five meter high volume in the image.

25:40.960 --> 25:46.600
So we can take this region, yeah, and actually to crop and transport that and feed the network

25:46.600 --> 25:52.280
when we are training, yeah, and this will ensure that the variance of the, uh, sizes for

25:52.280 --> 25:57.680
the object that's going to be not so high and can be more specialized in order to detect

25:57.680 --> 26:02.240
the players, because it's not expecting whatever size of players and things like that.

26:02.240 --> 26:03.240
Yeah.

26:03.240 --> 26:08.880
So how tightly cropped around a player is the image that you're feeding to the detector?

26:08.880 --> 26:13.440
Is it, is it very tightly cropped or is it, you know, half-court or, or something like

26:13.440 --> 26:14.440
that?

26:14.440 --> 26:19.480
No, no, it's, is the, is the full court, yeah, but imagine that we are taking out everything

26:19.480 --> 26:26.280
that is not the court and just taking like a crop that exactly contains, uh, all the pixels

26:26.280 --> 26:32.400
of this volume and the players there, uh, they're going to look, uh, similarly in shape,

26:32.400 --> 26:38.760
I mean, it's not likely to have like, uh, better in this transformation that, that's going

26:38.760 --> 26:42.240
to be the double or, you know, three times the size of other.

26:42.240 --> 26:48.840
So the number of, of, of anchors for Jolo, it's going to be, um, um, as well as number,

26:48.840 --> 26:49.840
yeah.

26:49.840 --> 26:50.840
Okay.

26:50.840 --> 26:57.960
I mentioned earlier that part of your, uh, your, the contribution of this paper is, um,

26:57.960 --> 27:05.240
being able to, at least what I took as being able to do this kind of actor detection and

27:05.240 --> 27:12.240
localization in a, in a short time frame, can you elaborate a little bit more on if you've,

27:12.240 --> 27:16.840
you've got the out of the box detector, what pieces are you doing on top of that?

27:16.840 --> 27:23.320
Yeah, so then when, when we have all these, uh, detection of actors, they depended a lot

27:23.320 --> 27:29.560
on Jolo, uh, version three, yeah, and it's going to be faster when a new detector or, or

27:29.560 --> 27:35.320
faster, the, uh, so actually we did like sound changes in Jolo, uh, usually Jolo is not

27:35.320 --> 27:40.440
so good for small objects, but in basketball, there is one small object that is really important

27:40.440 --> 27:49.160
that is the, that is the ball, yeah, so actually, um, um, that is like, um, a map that is, uh,

27:49.160 --> 27:55.480
component in different, uh, layers, we modify one layer in order to take, uh, the later 11,

27:55.480 --> 28:02.680
that is able to get, uh, some interesting feature of small objects, uh, till 14, times 14, uh,

28:03.640 --> 28:10.200
size, yeah, and this enables us to detect the ball in a more consistent, uh, way.

28:10.200 --> 28:16.200
So starting with these detections, then we, we use our core model, again, to localize the

28:16.200 --> 28:23.880
players in this, in the core plane, and to create this action as function, yeah, but then, or also,

28:23.880 --> 28:31.000
we get that to the histograms that is trying to estimate, uh, where is the state of the game?

28:31.000 --> 28:39.000
Yeah, if it is a half-core, uh, timeout, or a transition or something, in order to switch

28:39.000 --> 28:46.680
for the proper role, yeah, or the production. And yeah, is that, is that based solely on player

28:46.680 --> 28:53.160
position, the, yeah, game state? Yeah, yeah, yeah, yeah, so for this paper, yeah, but, uh, of course,

28:53.160 --> 28:59.240
you want to also add the tempo information, yeah, because you can, you can have like a

28:59.240 --> 29:05.000
distribution of players for different situations, yeah, but the story, it's, uh, yeah, I mean,

29:05.000 --> 29:09.880
that would have worked. I would imagine like right after a basket, if you're the balls being

29:09.880 --> 29:13.800
inbounded, you're going to want to, to be zoomed out, because you know the ball is going to end

29:13.800 --> 29:18.440
up on the other side of the core quickly, or something like that. Like, there's incorporating in

29:19.800 --> 29:23.880
knowledge about not just where the, the, the players are, and where the ball is, but like, what's

29:23.880 --> 29:29.640
actually happening from a semantic perspective could be interesting, an interesting signal.

29:29.640 --> 29:34.840
Yeah, so actually right now, we are trying to, uh, move forward with these, uh, we're including

29:34.840 --> 29:42.600
more things. Okay. We really want to have like a live, but I create enough method for production,

29:42.600 --> 29:47.480
without trying to get all these components, uh, and trying to have like something, because we really

29:47.480 --> 29:54.120
want to be really fast, yeah, and trying to build on that. But then depending of the challenge,

29:54.120 --> 30:00.120
and there are some challenges that the system is failing, sometimes you don't want to lose, uh,

30:00.120 --> 30:04.920
small part of it transition, or you are trying to follow someone that is going with the ball,

30:04.920 --> 30:12.680
and you arrive a bit late, yeah. And yeah, sometimes it's, it's, it's happening, yeah, but they're

30:12.680 --> 30:19.640
really, uh, small cases. Yeah. So it's like because it's combining all these ingredients, yeah,

30:19.640 --> 30:25.080
the action, the game estate, and then there is a controller that is really simple, and depending

30:25.080 --> 30:31.400
of the state is deciding something, yeah, I'm producing a really high quality. And however,

30:31.400 --> 30:37.160
there's something that I really like to have, like trying to have more sum and a variety of sums,

30:37.720 --> 30:45.480
premiums, uh, bit, uh, during the health court possession, trying to be more like tracking the

30:45.480 --> 30:53.720
action, yeah, but it needs more, um, awareness. The system really needs to understand more states

30:53.720 --> 30:59.640
inside, uh, the health court state, for instance, like a screen in the key area,

30:59.640 --> 31:06.120
or so what is preparing for taking a three-pointer, or something like that, yeah. So our idea is to

31:06.120 --> 31:11.720
increase the number of states, yeah, because this number of states will increase the number of

31:11.720 --> 31:19.240
rules of production that we can have. Okay. And are the, the rules for your controller,

31:19.240 --> 31:28.440
are those handcrafted, or are those learned as well? Yeah. And so we have this core volume, yeah.

31:28.440 --> 31:33.160
Yep. And so imagine that we do want to have like a sum out, this is where this is you already

31:33.160 --> 31:39.880
know your core volume, and you can find like, uh, the optimal framing that contain this core

31:39.880 --> 31:44.760
volume, the full core volume, and it's well centered. Yeah. But then we also have another

31:44.760 --> 31:51.560
framing. For instance, the left, uh, the left health court framing, yeah. And the right health

31:51.560 --> 31:56.520
health court framing, but also you can have a lot of set of frameings, or you can have a continuous.

31:56.520 --> 32:03.320
Yeah. In our case, we have a discrete, uh, set of frameings inside each health court,

32:03.320 --> 32:09.560
and depending of the peak of the actionist, we are just moving to the proper framing inside the

32:09.560 --> 32:15.640
health court. Yeah. This, this is like a easy solution for the problem, but you can also have

32:15.640 --> 32:22.920
like a continuous, but I will be honest with this, this grid set of, uh, frameings, the quads,

32:23.480 --> 32:31.080
is really good. Yeah. But the solution will be better with a continuous, uh, set of frames,

32:31.080 --> 32:35.480
things like that. Yeah. And to be clear, when you, you, you, you have a discrete set of

32:35.480 --> 32:43.400
frameings, but the, um, the virtual camera is not jumping from one discrete place to another.

32:43.400 --> 32:51.000
It's a smooth transition from one to the next. So, yeah. Yeah. Yeah. Yeah. Yeah. Um, so, yeah. I'm

32:51.000 --> 32:57.640
for doing that is actually quite this is just a proportional, uh, control when, uh, moving from

32:57.640 --> 33:04.680
this framing to the, these started framing and trying to obey a maximum speed of the virtual

33:04.680 --> 33:13.000
camera, because we don't want to talk, uh, use data. Uh, and so still with the, you've got this discrete

33:13.000 --> 33:19.240
set of, uh, views. Did you just write down the rules, you know, the correspondence between the,

33:19.240 --> 33:27.800
the game state and the, the framing or did you try to learn it anyway? No, no. Yeah. So, for the

33:27.800 --> 33:34.120
transition is just, uh, free camera. Yeah. So it's a virtual tradition from one to another. I get

33:34.120 --> 33:40.360
that's just following PID or performance. Yeah. No, no, sorry. So, so imagine that, I think that the two

33:40.360 --> 33:46.440
main, uh, states of the game are transition when we are moving to one hardcore to the other,

33:46.440 --> 33:53.560
and the hardcore position. So we expect that they're going to remain there for a 15 to a 24 second

33:53.560 --> 33:59.960
something of that. Yeah. For doing a transition, the camera is like a free camera. Yeah. Trying to be

33:59.960 --> 34:05.560
smooth, but trying to contain, uh, the main action or the peak of the action is and the ball at the

34:05.560 --> 34:11.080
same time. And there is a trade of there. But the, the ball, if it's, uh, visible, it should be

34:11.080 --> 34:16.760
continued. Yeah. And it's trying to do like a free camera. But in the hardcore, yeah, we know that

34:16.760 --> 34:23.480
we want to be in this hardcore. So we are moving to this set of discrete, uh, views or framing,

34:23.480 --> 34:29.560
yeah. And we are choosing, uh, the framing that is more, or that is closer to the peak of the

34:29.560 --> 34:36.520
action is. And if we were in a different framing, we are just doing a pro, a pro proportional motion

34:36.520 --> 34:44.280
to the next framing. Yeah. And, uh, in the, in the demo, that's a 2D projection. But the peak of

34:44.280 --> 34:52.600
the action is in 3D on your core model, right? Because you also zooming in and out. Yeah. So

34:52.600 --> 34:59.880
actually the peak of the action is, uh, is in 2D. So because the domain of this function is,

34:59.880 --> 35:04.520
is the core plane. So for instance, I don't know, inside the key in the middle of the key in the,

35:05.560 --> 35:11.160
something like that. Yeah. Uh, for a single camera, yeah. And if you don't want to do a lot of

35:11.160 --> 35:16.760
zoom during a hardcore possession and things like that, you can just project to 1D and to select

35:16.760 --> 35:24.840
or like a, like a panning motion of your virtual camera. Yeah. But if you really want to, uh, do like

35:24.840 --> 35:31.000
a full professional with zoom in and, and, and zoom out and everything, you can exploit this

35:31.000 --> 35:37.080
action in 2D and to be aware of the action is, is in the other corner of the hardcore and trying to

35:37.080 --> 35:42.040
be more close to the action and to exploit better the pixel that you want to, uh, to broadcast.

35:42.040 --> 35:49.000
Cool. And so you, you've suggested a few of the next steps here. Can you maybe talk a little

35:49.000 --> 35:53.720
bit more about, you know, where you go based on this or, or have you, are there even other papers

35:53.720 --> 36:01.720
that you've already published beyond, uh, yeah. I, I, I cannot say a lot. Yeah. But, uh, one of our,

36:01.720 --> 36:08.280
I mean, the fourth right now is trying to improve some things. The lighting of the bayonets

36:08.280 --> 36:15.240
sometimes is making things difficult. Yeah. Uh, yeah. So imagine that, uh, that the ball is not

36:15.240 --> 36:21.000
detected for some reason. You have a lot of windows and you have a lot of, uh, change in illumination

36:21.000 --> 36:27.320
and shells and things like that. And the ball is, is, is the ball detector is failing. Yeah. So

36:27.320 --> 36:31.880
you're going to be, I mean, all your production is going to be based in the action expansion. Yeah.

36:31.880 --> 36:37.000
And you don't have all your ingredients and we can fill. So we are trying to get more robust

36:37.000 --> 36:43.160
detector and to get more data, yeah, because the whole detector is totally, uh, data driven. So

36:43.160 --> 36:49.800
we need the more data that we can have in order to teach them the network to detect any

36:49.800 --> 36:55.000
little combustible. Yeah. And if we have the ball, the metal is quite good. The other thing that we

36:55.000 --> 37:01.960
want to do is to optimize some things. Uh, of course, we're going to run JOLO, you need a GPU,

37:01.960 --> 37:10.120
yeah. And this kind of GPU or server that you are using will determine, uh, your inference time.

37:10.120 --> 37:17.640
Yeah. So if you want to be fast enough, you need a good server, but perhaps, uh, you want to do that

37:17.640 --> 37:22.920
locally in the edge. Yeah. And it's not too easy to afford this kind of server for a public

37:22.920 --> 37:29.160
school or for a college or something like that. Yeah. So if we can get a better detector that can run

37:29.160 --> 37:35.880
really fast in CPU or a very cheap GPU or something like that, we are trying to move that and to get

37:35.880 --> 37:43.800
like lighter detector that they are doing a good job. And yeah, but if you have a good server

37:43.800 --> 37:48.360
or a good internet and you can use a string to the cloud and we process in the cloud,

37:48.360 --> 37:54.520
we are getting up. So right now we are trying to get like a multi-mysed version and trying to run.

37:54.520 --> 38:01.720
We are a detector and to try and to correct some errors and some things that they are not so

38:01.720 --> 38:08.440
likely, but even it's happening one time and again or two times. People that are not so happy,

38:08.440 --> 38:14.120
yeah. So it is to be almost perfect. But at the same time, we want to include more cameras,

38:14.120 --> 38:19.800
yeah, and trying to switch also like not expensive cameras, yeah, but trying to switch among these

38:19.800 --> 38:25.160
cameras. And on the other hand, since we are already aware of the location of players,

38:25.160 --> 38:31.160
at the same time without a production, we are collecting or we can collect some statistics that

38:31.160 --> 38:37.160
they are going to be really useful, yeah, for players, for the coach, for fans, for everyone,

38:37.160 --> 38:43.160
yeah, in real time or after the game, it depends because the necessities are different.

38:43.160 --> 38:50.120
And have you already tried using this method with other sports? You've mentioned soccer a

38:50.120 --> 38:57.480
couple of times. How easily generalized is it to, you know, similar but different sports?

38:58.040 --> 39:06.200
Yeah, our abilities should work. I mean, the main, the first modules, I mean, the actors and

39:06.200 --> 39:11.880
something like the core model or field model for soccer and things like that, but the rules of

39:11.880 --> 39:16.840
production, if you're watching soccer or volleyball, they're going to be different. This is the

39:16.840 --> 39:23.640
really nice part, yeah, because you don't have to change all your model, yeah, you have your knowledge

39:23.640 --> 39:29.480
here or the knowledge of the location of the actors, but then you can incorporate other kind of

39:29.480 --> 39:36.840
knowledge in a later stage, like how you should produce soccer or one camera or two or for

39:36.840 --> 39:42.680
20 cameras or volleyball or any other sport, but the main ingredients, yeah, they're going to be

39:42.680 --> 39:49.240
the same. Yeah, but yeah, we, we are trained at the other sports, yeah. So you're already starting to

39:49.240 --> 39:57.480
look at that. Yeah, yeah, sure. Any other thoughts on future directions for this or, you know,

39:57.480 --> 40:02.360
other things that you're excited about it, kind of this intersection of computer vision and sports?

40:02.360 --> 40:08.200
Yeah, yeah, actually, I think that the idea of system, it's going to be, it will be like a system

40:08.200 --> 40:14.040
able to do this over market production, but at the same time providing these statistics and

40:14.040 --> 40:21.000
analytics for any kind of user. So for the players and coaches in real time saying, okay,

40:21.000 --> 40:27.720
these are some statistics and events and analytics, like, yeah, but really, you know, with low

40:27.720 --> 40:32.360
latency and all the same package and with a single camera, something like that, you install and you

40:32.360 --> 40:39.640
get, and you have the full package. Actually, we are aiming that at this part. So you can have that,

40:39.640 --> 40:45.000
you can have your auto production and you can have all the data that you want, yeah, with the same

40:45.640 --> 40:53.080
system, yeah, with low latency. This is the goal. Well, Julian, thank you so much for taking the time

40:53.080 --> 40:59.800
to chat with me about what you're up to. Okay, thank you so much for the invitation and see you later.

40:59.800 --> 41:08.680
Alrighty, thank you. All right, everyone, that's our show for today. For more information on today's

41:08.680 --> 41:25.960
show, visit twomolai.com slash shows. As always, thanks so much for listening and catch you next time.

41:38.680 --> 41:39.320
you

42:08.680 --> 42:11.420
you

