WEBVTT

00:00.000 --> 00:11.600
All right, everyone. Welcome to another episode of the Twemal AI podcast. I am your host,

00:11.600 --> 00:17.680
Sam Charrington. Today, I'm joined by Adam Wood, Director of Data Governance and Data Quality

00:17.680 --> 00:23.600
at MasterCard. Of course, before we get going, be sure to take a moment to hit that subscribe

00:23.600 --> 00:28.560
button wherever you're listening to today's show. I had the pleasure of meeting Adam at a

00:28.560 --> 00:33.360
recent event I hosted with Claudeira, a data leader's round table back in February.

00:34.240 --> 00:39.840
And it is a pleasure to welcome him to the show to talk a little bit about data governance

00:39.840 --> 00:45.040
for machine learning. Adam, welcome to the podcast. Thank you for having me, Sam. It's good to see you

00:45.040 --> 00:52.080
again. It's great to see you and looking forward to digging into our chat. Of course, I love to have

00:52.080 --> 00:57.920
you introduce yourself to our audience and share a bit about how you how you came to work in data.

00:58.880 --> 01:03.840
Yeah, absolutely. So a lot of people don't know this by by education. I've got a doctorate

01:03.840 --> 01:10.720
in biochemistry and through several twists and turns of career moved into IT at Monsanto and

01:10.720 --> 01:16.960
didn't want to do anything else. So I've spent roughly 12 years, the last 12 years of my career

01:16.960 --> 01:23.920
in the data governance and data strategy space and that has spanned Monsanto healthcare companies,

01:23.920 --> 01:30.960
the financial industry and picked up a lot of knowledge. How data science has grown,

01:30.960 --> 01:35.760
how governance has been applied within those different industries, how data is treated

01:35.760 --> 01:40.080
within those different industries and the different sensitive information and regulations that

01:40.080 --> 01:45.200
get applied across the board. So with my current job, I've tried to bring all of that industry

01:45.200 --> 01:49.440
knowledge forward and see how it can help MasterCard progress in their initiatives.

01:50.160 --> 01:58.560
Awesome, awesome. You know, let's maybe start by talking about the various use cases

01:59.360 --> 02:07.040
for the data and data platforms that you're working with at MasterCard. Both machine learning

02:07.040 --> 02:12.880
and beyond. How's data being used there? Yeah, so MasterCard obviously being a global company,

02:12.880 --> 02:18.000
we bring in a lot of information and you can guess what that information is related to. We

02:18.000 --> 02:22.160
process a lot of credit card information for banks in different merchants globally.

02:23.280 --> 02:28.080
The governance needs there have really grown with the volume of data that we process.

02:28.640 --> 02:35.520
And even, you know, the growth of data science as a function is driven more of the need

02:36.320 --> 02:40.720
for governance across the board. So is data privacy regulations have grown?

02:40.720 --> 02:49.280
As the volume of information has grown, the need for us to regulate and do more with it from

02:49.280 --> 02:55.600
a governance standpoint has definitely grown as well. But downside is governance as a classical

02:55.600 --> 03:02.960
initiative tended to get in the way. And so our data needs are for more open use of the information

03:02.960 --> 03:09.200
and putting guardrails on the information rather than being this blocker to data access and use.

03:09.200 --> 03:16.960
So the majority of what we work on right now are ways to automatically detect and catalog sensitive

03:16.960 --> 03:22.080
information across the company and across the borders, the different countries that we do business

03:22.080 --> 03:28.160
in and to make sure every single security and privacy regulation is being followed down to the

03:28.160 --> 03:33.680
letter. And doing so, what we've been able to do is bring solutions forward that enable the

03:33.680 --> 03:40.240
data science community to understand where information lives, what it means, how to access it and

03:40.240 --> 03:46.640
how to do so responsibly using privacy, privacy management and consent management to make sure

03:46.640 --> 03:51.280
anything that we're using the information for is always in line with regulations that we're

03:51.280 --> 03:58.400
facing up to. Now, governance used to be very inflexible. The regulations are changing more and

03:58.400 --> 04:04.000
more. New ones are being added to the table all the time and the data science world has become

04:04.000 --> 04:09.600
incredibly flexible and needs to be moving fast. So everything that we do from a data science

04:09.600 --> 04:15.760
standpoint at MasterCard and actually at several other companies has had two flex with cloud

04:15.760 --> 04:21.920
adoption with machine learning and AI, the scale of data that's needed, the performance needs that

04:21.920 --> 04:27.840
are available. And I would tell you the number one thing that we're focused on right now is heavy

04:27.840 --> 04:33.440
reuse, helping people understand that there is information out there that other data science teams

04:33.440 --> 04:39.200
have curated and put together. And the quality rules that have been applied don't have to be the

04:39.200 --> 04:44.800
spoke. They can be shared across teams. So helping connect data science teams through our governance

04:44.800 --> 04:51.120
platforms and helping them move faster through shared components and reuse has been one of the

04:51.120 --> 04:58.080
largest undertakings that we brought forward. When we think about governance, well, you mentioned

04:58.080 --> 05:03.760
one of the things that is often thought about is this barrier, maybe internal bureaucracy that you

05:03.760 --> 05:09.440
have to overcome to use your data. But more broadly, I guess you can kind of think of it as they're

05:09.440 --> 05:16.880
being like carrots and sticks in terms of why you might invest in data governance and build out

05:16.880 --> 05:24.400
those kinds of processes. And before we started recording, you shared an example of a significant

05:24.400 --> 05:29.600
stick that was passed down by a regulatory body. Can you talk a little bit about this example

05:29.600 --> 05:36.800
that you shared and what it means for folks that are using data on a global scale?

05:36.800 --> 05:43.520
Yeah, absolutely. So the stick that I was referring to has to do with GDPR and the newest

05:43.520 --> 05:50.960
regulations around Shrems. So Amazon was slapped with an $898 million fine. And it was because they

05:50.960 --> 05:57.920
were using data for some of their data science projects that users had consented to them collecting

05:57.920 --> 06:03.360
but they had not consented to the way it was being used. And so privacy regulations have gone

06:03.360 --> 06:08.800
well beyond. I need to know where my data is, how you're tracking it and making sure it's encrypted

06:08.800 --> 06:15.280
and that you're being responsible as you store it. Now, it's if you're going to take my information,

06:15.280 --> 06:21.680
you can only use it in the way that I stated you could. So consent management alongside

06:21.680 --> 06:27.920
the information for people to consume has to be available. People have to have the understanding

06:27.920 --> 06:32.560
that this information that we've collected in this particular place can only be used for these

06:32.560 --> 06:38.800
purposes. And that's where a lot of governance tooling has moved to. So, you know, regulations

06:38.800 --> 06:44.240
and the growth of data science have driven a lot of the governance discipline. You're right,

06:44.240 --> 06:50.560
it used to be a massive blocker. It used to be very prohibitive. Now, it's become much more agile,

06:50.560 --> 06:56.960
a lot more automated and light touch so that we are bringing as many tools forward as possible to

06:56.960 --> 07:04.240
track metadata, policies, consent, and map that side by side with the information on what the

07:04.240 --> 07:09.280
data is and where it's stored. So that is any data science consumer comes forward.

07:10.000 --> 07:16.480
Once to use it, they know the guardrails that they have to to follow. Yeah, I was very surprised to

07:16.480 --> 07:25.200
hear about this, this Amazon fine. For many years, we've kind of operated in this gray area where,

07:25.200 --> 07:31.680
you know, there are all kinds of open questions with regard to, you know, what happens if you take

07:31.680 --> 07:37.520
data and incorporate it into a model, you know, privacy, you know, it wasn't really, you know,

07:37.520 --> 07:42.240
it was indeterminate, you know, there were legal and IP issues that were kind of indeterminate.

07:43.440 --> 07:48.640
Sounds like, you know, some of these things are getting clearer and at least in the case that you

07:48.640 --> 07:56.000
mentioned, the, you know, it's falling back on, you know, if explicit consent wasn't given for

07:56.000 --> 08:02.080
that use, then it can't be used there. And I think, you know, I wonder how many organizations are

08:02.080 --> 08:07.200
operating, you know, with that kind of constraint in place. You know, it has gotten clearer,

08:07.200 --> 08:12.320
but it's also gotten more difficult to manage because the variety of data that people are bringing

08:12.320 --> 08:19.280
in, it gets scattered very quickly. So making sure that you have governance processes highly

08:19.280 --> 08:25.280
automated and scalable processes to make sure that consent and privacy standards are being

08:25.280 --> 08:29.680
adhered to, making sure that data is encrypted at rest and the different types of things that

08:29.680 --> 08:36.000
regulators are asking for. That's all built into these data cataloging tools, which have taken,

08:36.000 --> 08:42.640
taken huge indicators from the data science community as a whole. So the management of privacy

08:42.640 --> 08:49.680
and consent has been incredibly difficult to start because the, the traditional BI, if I go back

08:49.680 --> 08:56.720
10 years, there was no such thing as serving up raw information to an end consumer, right? It

08:56.720 --> 09:01.040
was all going through something that had already been curated, something that had already been

09:01.040 --> 09:09.440
deemed safe. Exactly. It was only exposed through a handful of BI tools. Or there was an army of

09:09.440 --> 09:15.120
data architects and engineers that handled a handful of databases. So they knew what all the

09:15.120 --> 09:22.560
information represented and how to be careful with it. So now data science needs access to the raw.

09:22.560 --> 09:26.880
They don't need the curated layer because they want to be able to build features off of the

09:26.880 --> 09:32.560
raw information and they want to be exposed to all of the variables there to be able to create a

09:32.560 --> 09:37.200
true model of the raw information that they'll encounter instead of trying to build an AI model

09:37.200 --> 09:43.360
on top of a business intelligence layer. It's kind of a no-brainer. So but looking at rather than

09:43.360 --> 09:48.480
going through these highly curated views where, where consent and policy assignment or

09:48.480 --> 09:53.600
everything else would be so much easier, the difficulty has, has become going to all of the

09:53.600 --> 10:00.560
underlying product databases and operational databases and figuring out how to merge consent

10:00.560 --> 10:06.000
and privacy with the underlying data stores. And I'll keep this entire conversation. I'll keep

10:06.000 --> 10:12.400
coming back to data catalogs that are really providing that opportunity. And even you'll see

10:12.400 --> 10:16.960
some of the services being stood up in the public cloud providers right now that are helping

10:16.960 --> 10:21.520
facilitate this. And Amazon just published, I want to say it was a month and half the two months

10:21.520 --> 10:28.080
ago that they've released crawlers for their cloud environments to help identify sensitive

10:28.080 --> 10:32.560
and personal information in all of their cloud environments that can also be fed into their data

10:32.560 --> 10:37.520
catalog. So even the public cloud providers are starting to release these capabilities that

10:37.520 --> 10:42.960
enable governance but do it in a very scalable and automated way. One of the other things that

10:42.960 --> 10:51.280
came up that is just a level of complexity that never really occurred to me. This was something

10:51.280 --> 10:58.240
we discussed that the data leaders roundtable was, you know, you have kind of introduced this

10:58.240 --> 11:09.040
issue of governance and, you know, the requirement to track user consent. But then when you

11:10.240 --> 11:18.720
talk about it at kind of a global scale, you know, that global scale implies not just, you know,

11:18.720 --> 11:30.160
more, more records, more, you know, access. But also this requirement to federate in a sense

11:30.160 --> 11:34.560
because it's not just one regulatory regime. You have all these different regulatory regimes.

11:34.560 --> 11:39.920
You've got requirements that data, you know, stay local to a particular

11:42.160 --> 11:47.280
locale. You know, of course, you can articulate this better than me. You kind of walk through some

11:47.280 --> 11:51.520
of the complexity that you run into there. Yeah. So some of the newest standards that have come

11:51.520 --> 11:57.840
out of, you know, India, China, Germany, South Africa. It's this concept of nationalism.

11:58.800 --> 12:03.200
And each one of these countries brings forth a different set of rules to where

12:03.920 --> 12:09.040
where data is created. And if it carries certain attributes, it can't leave that country.

12:09.840 --> 12:14.960
And when you look at a lot of global companies, their information is processed centrally,

12:14.960 --> 12:21.040
data warehouses are built centrally. And so a lot of AI models and a lot of machine learning

12:21.040 --> 12:28.480
models are grabbing training sets centrally. But what happens now when you can't centralize

12:28.480 --> 12:34.640
that information and everything has to be federated? I know this is certainly, certainly impacted

12:34.640 --> 12:40.640
governance on the data science side as well. I think a lot of companies are struggling with how to

12:40.640 --> 12:47.280
train locally and then build the model centrally. But I can tell you one of the things that's

12:47.280 --> 12:52.400
that's another area of governance that's gaining a lot of momentum and has been for the last three

12:52.400 --> 12:59.520
to four years is the concept of data lineage, which helps us understand where all of the same

12:59.520 --> 13:05.840
data sets are occurring from even in a federated model and how they can be matched and merged and

13:05.840 --> 13:12.240
flow together. This is incredibly beneficial too as we're exchanging information across

13:12.240 --> 13:17.280
different boundaries between different countries to make sure that we stand compliance with

13:17.280 --> 13:25.760
regulations. But at the same time, data scientists as long as I've known any mature data scientists

13:25.760 --> 13:31.120
initiatives, they want to know where their information is sourced from, how it was constructed,

13:31.120 --> 13:38.400
and now is there anything that's limiting its use regionally or consent or privacy related?

13:39.040 --> 13:45.280
The nationalism is bringing in a new area of complexity where you can only use information

13:45.280 --> 13:52.880
or a certain location in that location. So data lineage is really helping us uncover exactly

13:52.880 --> 13:58.480
where that information is being sourced from so that data scientists can make sure that they're

13:58.480 --> 14:03.280
only using it for a specific purpose in that region now. So it's given us a different layer of

14:03.280 --> 14:11.920
granularity to try and protect people from using information in a way it wasn't intended or

14:11.920 --> 14:18.720
moving outside of the boundaries of a country with it. Now I know a kind of fast moving data science

14:18.720 --> 14:23.600
world in which you've got folks, you know, building all kinds of different pipelines and doing

14:23.600 --> 14:29.040
different kinds of transformations, pulling this information into models, sometimes hierarchical,

14:30.800 --> 14:35.520
you know, models, how are folks keeping track of lineage?

14:35.520 --> 14:41.120
Yeah, so some of the newest initiatives that I've been part of, there's some brilliant people

14:41.120 --> 14:44.800
in the data science community of MasterCard that really have a good handle on this.

14:45.440 --> 14:52.320
But as we're building feature stores, we can build in as new feature sets are being created,

14:52.320 --> 14:59.840
we can build in the metadata around how, what types of, how is each feature constructed,

14:59.840 --> 15:06.320
what types of cleansing logic was used, and all of that information is going to be published

15:06.320 --> 15:11.120
back to our data catalog so that the data science community not only understands that these

15:11.120 --> 15:15.680
feature sets are out there and available for use, they understand how they were built.

15:15.680 --> 15:21.520
And so at the intention here, you're right, data science is moving faster and faster.

15:22.000 --> 15:25.840
One of the things that we want to do to enable people is make sure that they have a shared

15:25.840 --> 15:32.160
set of components to use. Rather than 30 or 40 people going after the exact same data set and

15:32.160 --> 15:37.920
taking the time to create their own feature set from it, now we can use data lineage.

15:37.920 --> 15:43.280
We can use the metadata that's been gathered around other curated feature sets that have been

15:43.280 --> 15:48.240
built. Combine that with the information from the feature store to help people locate that

15:48.240 --> 15:54.160
information and move towards it and start using it very quickly. So the agility of data science,

15:55.280 --> 16:00.080
they're going to keep coming up with new use cases, but as people build new feature sets,

16:00.880 --> 16:05.280
we want to make sure that that's immediately understood and available for other people to consume.

16:05.840 --> 16:10.320
As chances are, if there's some new wonderful initiative, a new data science program coming

16:10.320 --> 16:15.680
forward, a lot of people are going to be going after the same data. And whoever reaches the end

16:15.680 --> 16:20.000
goal first and build something that's really valuable, we want other people to start consuming that

16:20.000 --> 16:25.200
right away. With regard to the feature store and metadata management in particular,

16:27.360 --> 16:32.800
talk a little bit more about how you've attacked that problem, what you've built,

16:34.320 --> 16:39.200
and kind of where that's going. So this all started off of the ability to just

16:39.200 --> 16:47.120
curate data. Not even moving towards a feature site yet. It was just how do we build the data sets

16:47.120 --> 16:52.880
from the raw information? How do we aggregate from multiple databases or denormalize something

16:52.880 --> 16:58.160
from multiple data warehouse sources to build something that we could use to train a particular model?

16:59.360 --> 17:05.040
So all of our metadata management, our data catalog was already consuming that information,

17:05.040 --> 17:11.840
meaning we had tracked every single database and every table and every column and every shred of

17:11.840 --> 17:17.280
business metadata that we could get for that information. So that as data scientists were starting

17:17.280 --> 17:23.280
to build curated data sets, they understood what they were bringing in. And then as they built

17:23.280 --> 17:28.880
their data sets, we've got some very, very incredible partners that are publishing back metadata

17:28.880 --> 17:35.280
for what they've done to construct these sets. So we now know that in these tables,

17:35.280 --> 17:40.640
this is information that was sourced from x, y, and z. We're intending to use it for

17:41.200 --> 17:45.040
these additional problems. It's a training set for this set of models.

17:46.480 --> 17:52.800
The discipline that I would love to see going forward is that within any sort of data science

17:52.800 --> 17:59.760
platform, they make sure to relate back to how that particular feature set was constructed to

17:59.760 --> 18:06.240
make sure all of these components are fully understood. We do see gaps here and there. So I look

18:06.240 --> 18:11.280
at it as let's say I cooked a wonderful dinner and I didn't write down any of the recipe.

18:11.920 --> 18:16.080
And now I've got to go do it again. I've got to start from scratch. We don't want people to have

18:16.080 --> 18:22.480
to do that. So what we do with the feature store is very similar to that. So every set that's

18:22.480 --> 18:30.240
being created, you know, it's how was this feature normalized, you know, how was it clandes,

18:30.240 --> 18:36.960
how was any sort of back fills done to make sure that this was a complete feature set for someone

18:36.960 --> 18:43.120
to be able to consume and use and for what purposes were people consuming it. So again, if I'm

18:43.120 --> 18:49.520
working under a particular set of consent assumptions and I'm able to see other data sets or

18:49.520 --> 18:55.200
feature sets that were built from that same set of assumptions and that same consent. I'm off to

18:55.200 --> 19:00.400
the races. I don't have to spend any time trying to construct it myself. I may have some tweaks

19:00.400 --> 19:05.120
that I want to make to it, but I've got a huge leg up. Historically, when we've talked about feature

19:05.120 --> 19:13.600
stores, you know, one aspect of the feature store is kind of making the features available and

19:13.600 --> 19:21.920
kind of ensuring consistency of features and things like that. And another aspect of it is more

19:21.920 --> 19:27.360
kind of the store part of this, not as in storage, but as in a place that you, you know, a marketplace

19:27.360 --> 19:36.880
almost or really focusing on feature reuse and enabling, yeah, teams of void kind of reinventing

19:36.880 --> 19:45.600
the wheel. And there's been this historical kind of, you know, I guess it depends a lot on the

19:45.600 --> 19:49.600
organization. Sometimes you find folks push back on that because they don't want to, you know,

19:49.600 --> 19:54.320
create something that they need for their project and then have to, you know, own and support it,

19:54.320 --> 20:01.200
you know, and have it be used in ways that it wasn't intended. You mentioned reuse earlier.

20:01.200 --> 20:09.360
I'd love for you to share a bit about how you see reuse playing out in org as big as mastercard.

20:09.360 --> 20:14.080
Yeah, so I can tell you some other companies in the way they've addressed it and some of the things

20:14.080 --> 20:20.240
that we're thinking about as well. If you look at some of the companies that have really published a

20:20.240 --> 20:27.840
lot of their governance process and their data catalogs, Lyft, Uber, Spotify, they have all gone and

20:27.840 --> 20:34.640
built their own and they've built their own with data science in mind. So how do you get to reuse?

20:34.640 --> 20:40.720
Whenever you search for particular information, it actually brings back sample queries that have

20:40.720 --> 20:46.640
been run, the people that that have been most frequently accessing that information samples of the

20:46.640 --> 20:53.840
data sets. So, you know, it drives reuse by helping you build a community of people that are

20:53.840 --> 21:00.880
after the exact same information. The way we've approached it is we work with the data science

21:00.880 --> 21:07.120
community who is the larger teams that are building these data sets, bring them into our data

21:07.120 --> 21:15.840
catalog and then there's a way to certify them as top quality assets. And so we also add additional

21:15.840 --> 21:21.760
metadata so that any data science coming in can look for these are the certified assets that are

21:21.760 --> 21:26.880
available for the data science community, see them immediately and then be able to access them.

21:27.920 --> 21:33.840
We do also take some approaches running analytics on our data science environments to look at

21:33.840 --> 21:39.600
query behaviors. Very similar to what these other companies were doing, but looking at behaviors of

21:39.600 --> 21:46.560
individual users within individual teams to see what data they're going after and can we connect

21:46.560 --> 21:52.560
that to a data set that's already been curated and is available to use and then we can actually

21:52.560 --> 22:00.320
drive those users towards those those curated feature sets. So right now we can't guarantee reuse,

22:01.520 --> 22:08.080
but we can do we can strongly promote reusable feature sets that are out there and by including

22:08.080 --> 22:13.600
the logic that was used to build them, we make sure that we can iterate on top of those and

22:13.600 --> 22:18.880
continue to build new ones from a base component rather than trying to, like I said, reinvent the

22:18.880 --> 22:24.160
wheel every single time. In the broader context of ensuring the responsible use of machine learning

22:24.160 --> 22:31.120
and dealing with issues like bias, the ideas of like data cards and data sheets for data sets

22:32.160 --> 22:39.840
have been proposed and are increasingly popular. Are you doing anything like that to kind of

22:39.840 --> 22:46.800
profile the data and the the way it's been sourced and the various biases so that folks

22:47.920 --> 22:54.240
that are trying to use it have more visibility into that? So I would say I'm not as familiar with

22:54.240 --> 23:01.840
any bias that's gone into the data. We do source a lot of external information as many companies do.

23:02.960 --> 23:07.920
We also have several third-party acquisitions that we've made. So whenever we don't have the

23:07.920 --> 23:14.160
information or the capability internally, master card's been making a lot of acquisitions and the

23:14.160 --> 23:21.760
open banking space and fraud detection and identity management. And so we do and every single one of

23:21.760 --> 23:26.960
those instances when we start looking at the information that those companies bring forward, we're

23:26.960 --> 23:33.840
always thinking about new analytics that can be built. And the first the first issue that's always

23:33.840 --> 23:41.280
tackled is what is underrepresented? What do they have that's new to us? What do we have that's

23:41.280 --> 23:46.800
probably new to them? And are there any gaps remaining? Is there anything if we're going to build a

23:46.800 --> 23:53.920
comprehensive model over this information? What type of information do we need to make to or bring

23:53.920 --> 24:00.240
in so that the end result is not skewed? Trying to eliminate as much bias as possible because a lot

24:00.240 --> 24:05.760
of these smaller acquisitions, they cater to one class of user, one class of customer.

24:06.720 --> 24:10.640
So when we're bringing in acquisitions, of course, there's going to be some level of bias,

24:10.640 --> 24:15.360
but master card has the advantage of being a very large global company with an absolutely

24:15.360 --> 24:21.600
massive customer base. And so those types of evaluations help us understand bias pretty quickly.

24:22.320 --> 24:27.680
Now in terms of data profiling, this is also a space that we're spending considerable efforts

24:27.680 --> 24:35.920
and considerable time in going into really understanding across the board, value distributions,

24:36.720 --> 24:41.680
what is the use of the information? Is it reference data? Is it sensitive information?

24:42.240 --> 24:46.880
And we're doing all of this to make sure that we manage encryption. We're making sure that we

24:46.880 --> 24:53.680
manage lineage and flow of sensitive information appropriately. And it's also tied to consent

24:53.680 --> 25:00.400
management. I would say that particular information though, we're still working on ways to really tie

25:00.400 --> 25:05.840
it to the data science community and make it usable. I think the first foray into that is really

25:05.840 --> 25:11.200
going to be around the consent and privacy management, but then figuring out ways to make that give

25:11.200 --> 25:16.080
additional value to data science teams from our data profiling results is something we're exploring

25:16.080 --> 25:22.560
right now. How does data quality plan into all of this? Yeah, so it's always been a really special

25:22.560 --> 25:30.080
relationship between data quality and data science. Mostly because most of the data science teams

25:30.080 --> 25:35.600
that I've worked with, the first words out of their mouth are don't touch the data. Don't try to

25:35.600 --> 25:41.440
sanitize anything before it hits my hands because I want to have influence over the way that it's

25:41.440 --> 25:48.400
cleansed. So some of the things that we really try to do, we know when there is something that's

25:48.400 --> 25:53.120
that's very error prone. For instance, credit card numbers that come in with special characters

25:53.120 --> 25:58.960
and letters in them. Okay, there might be something in that transaction that is valuable to a data

25:58.960 --> 26:04.800
science team, but chances are it's going to have other errors in it and we don't want people to

26:04.800 --> 26:11.680
start to use that type of information. So data quality is really used more from a product development

26:11.680 --> 26:19.680
standpoint. Is it recommended that this data is fit for use or fit for purpose? But in terms of

26:19.680 --> 26:25.040
data quality for data science, a lot of those measures are actually coming from the data science

26:25.040 --> 26:32.160
teams themselves rather than these dedicated data quality organizations that exist and almost every

26:32.160 --> 26:38.560
enterprise organization right now. So data quality for data science has really taken on a life of

26:38.560 --> 26:44.080
its own. It's become a very interesting space in terms of cleansing and future creation.

26:44.880 --> 26:50.960
And so the big level of encouragement that I give to these data science groups is great.

26:50.960 --> 26:56.640
You know, the tools that we have for regular operational data quality, they track what we're

26:56.640 --> 27:01.600
running. We know exactly what we're running it against. If you're building a brand new pipeline,

27:01.600 --> 27:08.880
you have to do the same thing. And you also, my big recommendation is take the data quality

27:08.880 --> 27:15.680
measures and and cleansing measures that you're building and make them some form of reusable component.

27:15.680 --> 27:20.560
If you're going through the effort of doing it, almost like a feature store, there needs to be

27:20.560 --> 27:27.120
some form of feature cleansing store. And that way when you're providing metadata around how you've

27:27.120 --> 27:33.440
created everything, you can cleanly reference the processes that you used to get there or at least

27:33.440 --> 27:39.680
some logic around what's been done from your personal data quality standpoint to let other people

27:39.680 --> 27:45.600
understand how things were created. But data quality is an interesting space in data science.

27:45.600 --> 27:51.760
It's taking shape a lot more than it was. You know, it was sort of go at it alone, cleanse the

27:51.760 --> 27:58.000
information, however you see fit. And you know, the normal data quality measures that organizations

27:58.000 --> 28:03.760
would run don't touch my data. Stay out of it. Let me do what I need to do. Those two are going

28:03.760 --> 28:08.800
to have to meet in the middle somewhere. I think we're on the way to doing that. Just because the

28:08.800 --> 28:15.440
the level of effort it takes to keep reinventing feature sets and features and everyone applying

28:15.440 --> 28:20.560
the same logic over and over with no way to reference it centrally. I think that's about to

28:20.560 --> 28:27.120
change very soon. When we spoke earlier, you also reference data domain discovery. How does that

28:27.120 --> 28:33.840
play into all of this? Yeah. So data domain discovery is a term that's used specifically by

28:33.840 --> 28:41.200
Informatica. Informatica is governance suite. But the domain discovery relates down to what is the

28:41.200 --> 28:48.320
logic that I can run as part of data profiling that lets me understand the type of information that's

28:48.320 --> 28:53.360
in each particular column or what each particular key in a document represents.

28:54.320 --> 29:01.600
And so what companies are starting to do with that information is as you have a series of what are

29:01.600 --> 29:09.600
just loosely called tags or data domains or some form of label for each document, each table,

29:09.600 --> 29:14.880
each column, each key, you can build additional logic on top of that to figure out what governance

29:14.880 --> 29:21.360
policies you have to assign. And so data domains are another one of these ways that can be fully

29:21.360 --> 29:28.000
automated, that can be fully scalable and is one of the newer governance processes that's really

29:28.000 --> 29:35.920
taken hold. There is no manual intervention in these processes. It's something to where you can

29:35.920 --> 29:43.120
scale across as many databases, hybrid cloud environment on premise, fully cloud environment,

29:43.120 --> 29:50.160
and come away with your data sets being labeled with what they contain. And that type of logic

29:50.160 --> 29:55.040
can immediately help you understand if there are different types of security needs, if there are

29:55.040 --> 30:01.040
different types of policy and privacy implications. So is the general idea here that

30:02.320 --> 30:06.880
you know we've got some new database maybe it comes in for being an acquisition or a third party

30:06.880 --> 30:14.640
source and it hasn't been previously curated and this these data discovery data domain discovery

30:14.640 --> 30:23.920
tools can identify columns that represent PII like addresses or phone numbers names. Yeah that's

30:23.920 --> 30:29.360
exactly the point. So the scale of information that every company is bringing in is absolutely

30:29.360 --> 30:35.520
gotten massive logarithmic growth. And not only that data brokers have started to become I mean

30:35.520 --> 30:40.560
those are in the news all the time people selling information whether whether that's appreciated

30:40.560 --> 30:47.360
or not a lot of companies are using information that they didn't generate that someone else did

30:47.360 --> 30:54.000
and now they have to take ownership of it. And so what data domain discovery or data tagging does

30:54.000 --> 30:59.760
is it looks at that information and tries to determine for many patterns in it is it an email address

30:59.760 --> 31:06.560
phone number IP address anything that could be used to reverse engineer your identity or the

31:06.560 --> 31:14.880
identity of your financial information. So obviously fraud has become a very very big deal in

31:14.880 --> 31:21.120
recent years the sophistication of identity theft and people that are stealing credit cards and

31:21.120 --> 31:28.320
making transactions in your name matter of fact two years ago someone filed my my IRS tax return

31:28.320 --> 31:35.280
in my name. So people are getting really creative and so making sure that we understand all

31:35.280 --> 31:41.600
information that we're taking in and processing making sure that any sensitive information around

31:41.600 --> 31:47.360
a customer or bank or any sort of financial transaction is well understood and protected.

31:48.000 --> 31:53.120
This is where the entire governance industry is headed. So these are definitely initiatives

31:53.120 --> 32:01.680
that we've taken on and it also helps us in terms of R&D or POC methods to know which

32:01.680 --> 32:08.240
information needs to be anonymized encrypted we apply that same thing to our operations making

32:08.240 --> 32:13.280
sure that we understand which information needs to be encrypted or even hashed make sure it's

32:13.280 --> 32:19.040
secured at all times. And so this is this is akin to data profiling it's an additional step that

32:19.040 --> 32:24.000
results in labeling of each individual element in a database but that makes sure in an automated

32:24.000 --> 32:30.400
way across the board globally we have the right controls in place to understand what our data

32:30.400 --> 32:37.440
represents and to make sure our customers stay safe. So we've talked a lot about the tooling

32:37.440 --> 32:47.120
around data management data catalog even feature stores a lot of organizations are also investing

32:47.120 --> 32:54.640
in building out platforms for the the data science parts of the workflow is that something that

32:54.640 --> 33:00.160
master card is doing as well. Yeah absolutely so within within our data warehousing environments

33:00.160 --> 33:07.040
we're big users of cladera we have roughly a 20 petabyte Hadoop environment right now very

33:07.040 --> 33:12.560
large contains a ton of information and one of the native components there is the data science

33:12.560 --> 33:20.560
workbench. And so along with that the majority of our data science workflows the data pulls a

33:20.560 --> 33:26.400
lot of the aggregations a lot of the the testing file and training file storage is all happened

33:26.400 --> 33:32.080
with happening within that singular platform. That's also where a lot of our governance activities

33:32.080 --> 33:39.280
have focused to understand we're we're using cladera manager to be able to pull logs how people

33:39.280 --> 33:44.640
are accessing the information how they're interrogating the information and being able to build

33:44.640 --> 33:49.840
different types of analytics to help connect different members of our user community.

33:50.960 --> 33:58.080
So it's it's been a decentralized platform for data science at master cards so far and we're

33:58.080 --> 34:04.480
exploring other ones as well but but Hadoop and cladera have played a very large part for us and

34:04.480 --> 34:11.920
even within the newest releases Apache Atlas as a data catalog component of the cladera platform

34:11.920 --> 34:15.840
has come forward and we're looking forward to building out some additional integrations with

34:15.840 --> 34:22.400
that to strengthen our global governance footprint. Got it and historically one of their pitches

34:22.400 --> 34:30.000
for the data science workbench is kind of this integration between the governance capability

34:30.000 --> 34:36.000
and their like historical data management tooling and the data science workflows and now

34:37.280 --> 34:41.600
you know even emphasizing the ability to deploy on different clad environments which you

34:41.600 --> 34:47.040
mentioned earlier. So even some of the newer things that we've done within data cataloging and

34:47.040 --> 34:52.960
this is happening everywhere it's not a standalone platform. We're building a bunch of API

34:52.960 --> 34:58.480
services that can be accessed and called directly from within data science workbench to be able to

34:58.480 --> 35:05.840
both pull out metadata and push back metadata. So I was referencing you know how to share

35:05.840 --> 35:11.120
how you've built different feature sets or different trainings sets. We want people to be able to

35:11.120 --> 35:15.920
do that natively from within the platform that they're working in so they can search our catalog

35:15.920 --> 35:20.960
natively from within data science workbench and then turn around and at the end of the day when

35:20.960 --> 35:27.120
they when they've built their data set publish that metadata back in so that we'd get a record of

35:27.120 --> 35:32.160
not only how it was built but also where it's stored now so that other people can have access to it.

35:32.160 --> 35:37.360
So Adam a lot of what we've talked about thus far has been you know from your perspective as the

35:37.360 --> 35:42.960
the governance and data management person informed by the work you've done with data scientists

35:42.960 --> 35:50.240
is there a set of things that you wish data scientists knew about the space beyond what we've

35:50.240 --> 35:55.840
talked about or things that you wish that they would do that would make them more effective in

35:55.840 --> 36:02.400
thinking about working with governance. Absolutely so I mentioned I've been in this space for

36:02.400 --> 36:10.720
10 to 12 years right nobody cared about governance when I started it was pure overhead nobody wanted

36:10.720 --> 36:17.920
to do it but then data science became a discipline and it had to get more flexible and now what you'll

36:17.920 --> 36:23.120
find is a lot of these governance platforms take their opportunities from data science.

36:23.120 --> 36:29.120
I think we've all made peace with this is where innovation comes from this is where profitability

36:29.120 --> 36:34.000
is going to come from for a lot of companies and our products have to be able to support that

36:34.960 --> 36:40.240
governance used to get in the way it can't do that anymore when you're chopping at the revenue

36:40.240 --> 36:46.640
stream of your company you've got to make changes so my my biggest advice to data scientists

36:46.640 --> 36:51.840
first and foremost get acquainted with what the platform does get acquainted with how to

36:51.840 --> 36:56.560
contribute information to and consume information from a data catalog because I guarantee your

36:56.560 --> 37:04.720
company has one a lot of people just don't know of its existence in most cases. Beyond that figure

37:04.720 --> 37:10.720
out how you become a contributor and I don't just mean a contributor to the data catalog or your

37:10.720 --> 37:18.480
governance program what I mean is if you're building feature sets figure out what metadata you can

37:18.480 --> 37:25.040
do to improve the work of everyone else around you if you're building data quality logic if you're

37:25.040 --> 37:30.560
building cleansing logic if you're building up feature sets make sure that you're tracking how

37:30.560 --> 37:36.880
that information was constructed and that you're putting it into a central repository so that people

37:36.880 --> 37:43.840
can access it at a later date when you do that when it hits that central repository that's where data

37:43.840 --> 37:50.000
tagging and data profiling is happening so you get the added benefit of letting us do the

37:50.000 --> 37:56.240
automated processes to protect your information for you. We can now let you and everybody else know

37:56.960 --> 38:01.920
if there's sensitive information in it is a data set that's open for use and can be used by anybody

38:01.920 --> 38:10.640
internally. Now a lot of the processes that we run are enablers we try incredibly hard not to

38:10.640 --> 38:16.160
get in the way anymore. What we want to do is make sure data science gets served the information

38:16.160 --> 38:20.960
that they need to be more effective and like you were talking about earlier we are here to promote

38:20.960 --> 38:28.880
reuse and direct people to the right information and how to use it responsibly and so the final

38:28.880 --> 38:36.800
thing that I'll say is I want every data scientist to focus on reuse. Heavy reuse I mean feature

38:36.800 --> 38:41.680
stores came about because the industry was saying we can't keep going at this alone.

38:43.680 --> 38:50.240
Well the data catalog is helping you not have to but in order to do that you have to focus on the

38:50.240 --> 38:55.200
ways that you're constructing data sets and the way that you're tracking that information. You can

38:55.200 --> 39:00.640
contain some of that in your feature store. I'd ask from a governance standpoint that you've pushed

39:00.640 --> 39:07.520
the rest of that metadata into the data catalog so that privacy compliance cyber security everyone

39:07.520 --> 39:13.840
else has the privilege to see your work and make sure that is protected for you. We're not here to

39:13.840 --> 39:19.680
cause roadblocks we're here to be an uplift and help you get to your angle faster but we want to

39:19.680 --> 39:26.320
make sure that we have you set for success through making sure you're adhering to privacy consent

39:26.320 --> 39:32.560
all these other risks that are out there so that you can move very quickly in a de-risked environment.

39:32.560 --> 39:39.200
Awesome awesome well Adam thanks so much for joining us and sharing a bit about your experience

39:39.840 --> 39:45.280
with data governance as great to chat once again. Yeah absolutely thank you so much Sam.

39:45.280 --> 39:55.280
Thanks Adam.

