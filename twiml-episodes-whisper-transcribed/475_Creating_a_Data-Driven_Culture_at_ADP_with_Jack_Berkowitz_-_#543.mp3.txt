All right, everyone. I am here with Jack Berkowitz. Jack is the chief data officer with ADP. Jack,
welcome to the Twimal AI podcast. Thanks. Thanks for having me. I'm looking forward to digging into
our conversation. We'll be talking about some of the ways that ADP is using machine learning,
but to get us started, I'd love to have you share a little bit about your background and a little
bit about your career. Sure. I've got a long career been at this for 30, 31 years now.
Kind of three phases. First phase was largely doing work with DARPA. So early 90s, mid 90s,
doing a lot of work and at that time it was cutting edge, things like ontologies,
distributed reasoning technology. All sorts of stuff that people at DARPA would normally
equate. Then I spent about 12 years doing various startups, some in the semantic web, some in search,
some in analytics. And then for the past 10 years, split between Oracle and now ADP, really running
large scale enterprise level analytics products. And so we build products for other people.
And then my job at ADP is a combination of building products for clients. And then also doing
some things internally that ADP uses. Awesome. Awesome. And when you started at ADP, you started out
in a product-centric role and transitioned over to CDO. I'd love to have you share a little bit
about that transition, how it came about, and how you, it sounds like you still retain some
product ownership there. Yeah, sure do. So the CDO role really has two faces to it.
On the one hand, we build product for clients. We have tens of thousands of clients that use
our analytics for HR, people analytics, compensation analytics, recruiting, things like that.
And then we also have a defensive nature to the CDO organization. So besides having all the data
advantage, what do we do to protect the information? And one of the big messages that I spend a lot
of time on is talking about data governance. So it's pretty funny because as product development,
people as machine learning people, we hear the word data governance and we immediately think,
okay, people are trying to get in our way. We're trying to hold us back. And actually what it means to
us is it enables us to get the data into a nice, clean way so that we can share. And so that,
you know, somebody builds a NML algorithm to do something. I don't know what, you know, but
for job matching, the entire community of developers can then use that algorithm for job matching,
right? So that's all part of that governance that we're putting in place today.
So I'd love to come back to that data governance topic. Before we do, I've jumped right in and
maybe taking it for granted that folks know who ADP is. And it may be the case that most do, but
why don't you give us a quick summary of ADP and the company's focus? Yeah. So ADP is the world's
largest provider of HR payroll benefit solutions. So we have over 920,000 clients in 140 countries.
And, you know, most people know ADP because their W2 or their paycheck has been issued by ADP.
Maybe not today, but maybe at some point in their career. And if it hasn't, it will be, right?
One of the things that we talk a lot about ADP is it's not your grandfather's ADP, but it's
actually my grandfather's ADP. So they've been around for about 70 years. He had a small gas station.
The update is employees and the family through ADP. But, you know, a series of firsts of the
company, really the first companies ever use computers for payroll. First company to build a,
what we now call self-doors of service used to be called something else in the late 90s for doing
HR. First company to do mobile apps for the employees of companies. And so every day, you know,
every week you can check your payroll, you can clock in and out, you can, you know, check your 401K
balance through the through your mobile app. So lots of people, about 58,000 people today,
building products, and then providing great expertise. Because the one thing about HR is that
it's not just about the software. You know, there's, you know, regulations that have to be maintained,
there's problems for, for employees or clients that need to be solved, you know, what if I'm
adopting cross-order? What's the impact on my pay or, or any sort of things like that? And so,
you know, our CEO likes to say, hey, it's about building great products with great expertise.
And that's really what we try to bring to bear. I think one of the consequences of that long history
is, you know, the companies associated with some of those early technologies that maybe weren't
so early when it first got started, you know, to be very clear when I think of kind of poster
trials for the mainframe. ADP is one of those companies who comes to mind and yet we're connected
because you were delivering a keynote at AWS re-invent, talking about some of the things the
companies doing with machine learning as part of the data cloud product. Talk a little bit about
what it means to be building cutting edge data-centric product in a company with that kind of history
and legacy. Yeah, so we still have a little bit of those mainframes running around. And guess what?
So does every bank and every, you know, DMV and everything else. And it's funny, right? As somebody
who's always on the cutting edge, you heard like DARPA and cloud and everything, you know, what do
you mean? Well, the data's got to come from somewhere, right? And if you want reliability,
tell us, it doesn't actually matter where the data comes from. What we're able to do is harness
the semantics of it, the meanings of it, bring it together and make it available in a platform
in something that other people can use, blows and our own teams can use. And that's the essential part
of it. And so, you know, when we were looking, how do we do that in a modern way and how do we
keep up with the pace of business? And, you know, the pace of business is just unbelievable,
particularly now since COVID hit, you know, for us moving it into the cloud made total sense,
right? And so we're sinking information every single minute back and forth between, you know,
those classic on-prem data centers, but their data centers, just the same way as any other data
center. It's not like it's running under my desk or something. And we're sinking information,
and we're extracting value out of it by taking advantage of all the services that we can get
in the AWS cloud. You're coming about platforms, ties back to the the common and about governance,
and what brings them together is this idea of making it easier for your teams to be productive
with that data, to pull meaning out of it, make predictions with that kind of thing. Can you
talk a little bit about the challenges with harnessing the data that the organization has at its
scale? Yeah, let me give you a great example. I'll give you two different examples. Let me start
with one though that it really summarizes not just harnessing the meaning, but also, you know,
the amount of machine learning we're building, right? So in any given month, we pay about 30 million
people in the US. And for those 31 million, 30 million people, we've got about 21 million job
titles. Okay? So, yeah, for about eight or, you know, for about nine million, we don't know what they
do for a living, but for 21 million, we do. We need to crunch that data down into some common
job titles. In fact, we crunch it down to about 9,000 job titles. Now, we don't do that manually.
We don't do that with rules, right? And so we run all that in a data driven machine learning pipeline
using some pretty advanced technology to get that done. All the latest buzzwords you can imagine
plus a few are involved in that pipeline. And you say, well, why do that? Well, if I want to know
what a software engineer makes, you would think that would be easy, but company A calls it software
engineer three company B calls it, I don't know, development specialist company C calls it, you know,
creative machine learning guru juggler, right? And we've got to have a way to bring all that in from
art. Yeah, you can only imagine everybody gets to invent their own title, right? And we've got to
have a way to bring that together. And we do that for our compensation benchmarks. We do that and we
use that same exact thing in sort of our recruiting and sourcing systems. We do the same thing in our
performance review systems. And that's a great example of the challenge. And then we have the same
exact challenge when we try to provide the capabilities for companies to operate in multiple countries.
So things that may be obvious in the US like holiday or vacation are called different things in
different countries. And in fact, the math and the calculation law was different depending on
the country you're in. And so we have the ability by bringing all that information together, having
you know, models on top to combine that information so that our clients benefit through all this
processing. And so when you talk about data governance, are you thinking about it akin to kind
of a traditional enterprise architecture, big committees deciding who can do what and where
data sits and that kind of thing? You know, I'd like to say that there are no committees and we're
we're a reflection of the distributed internet. It's not quite there. But so we do have a central
group, but we really try to operate in more of a hub and spoke or a federated way. And in in
that sense, you know, a lot of people are talking about data mesh these days. We think about
as a semantic mesh or a metrics mesh. So we want the teams that are responsible to operate on and
have the domain knowledge. There's a central group, right, that makes sure that things can attach
because otherwise it's just pandemonium, right? So there's a central group that ensures that either
it's a concept, right, a domain object or a or a new metric that it can attach to some parent
object. But in that case, you know, the central team's very thin and the amount of work they do
is very thin. It's really distributed. We have, you know, tens of not tens, but hundreds and hundreds
of people in development. And we want them to have the independence to be able to create in a way
that they can do best. Now related to that is also then the data lineage. So it doesn't
know good for somebody say, Hey, I've got the data source of data sources for, you know, some problem
benefits. If they don't provide how that data has been brought together and then managed and
then brought up. So we also have artifacts that, you know, if you're going to participate in that
in that world of this federation or this, this combination of information, well, then you also
have the responsibility to say, Hey, this is where my data came from. I'm going to take care of
the data quality of it. And I'm going to advertise to all my other people that collaborate in that
sense. So, you know, I said, Hey, when you were asking me about my career, I started and I did a
lot of work in the semantic web. We actually bring a lot of those concepts to bear. Now whether or
not it's the formal semantics and the language, I don't know, but that idea of distributed data,
self-describing data and then attachment of data is something that we try to bring to bear across
our company. And the ultimate objective is to allow teams to move more quickly. Yeah, I mean,
I think, I think it's three, three key things to us. The first one is about pace, right?
Or client, the world's busy. Clients are demanding and the world's situations are changing all the
time, right? Second thing is, is, is, is about reliability. Because we're messing with people's
paychecks. At the end of the day, that's what we do. And, and, you know, that's the most personal
data there is other than maybe healthcare data, right? If you want to, if you want to see
somebody get excited, make a mistake on their paycheck, right? And so we, we have to have a little
bit of reliability in terms of what we're doing. So the first thing's about pace, second thing's
about reliability. And the third thing is really about clarity and explainability, whether it's
to each other inside the development teams or whether it's to our, and clients, right? This is why,
you know, so there's like an explainability and ethics overlay to all of this as to why we're
so into this, the data governance approach. You gave us a couple of specific examples of
machine learning use cases there. Be curious, have you talked broadly about the various ways
that ML has used? And my guess is that it's used primarily in kind of new products that are built
on top of the data assets that the company has, as opposed to kind of that core payroll processing
or other use cases there as well. You'd be surprised. Yeah, no, you'd be surprised. And so we have
machine learning throughout the entire corporation at this point. And it's come on really fast.
It's come on fast because we've separated the data, but we've also exposed all the machine learning
processes through microservices or through APIs. And then that allows, yes, totally, brand new products,
they're intelligent from the ground up, they're everything everybody could imagine. You know,
there's a chatbot for the screen changes. But we also use it to do things on the older products
as almost overlays into them, right? So the ability to check a payroll before it's submitted and
all the money goes, the ability to check for anomalies, that's all based on new machine learning
capabilities because now we have the data in one place. We can do that and we can provide new
capabilities to existing what we're thought of as legacy applications. And so you can make
something fresh for our clients at the same time as building net new products all at the same time.
And so we're getting great reception on sort of that innovation aspect with our clients because
we've taken some pretty hard steps in terms of building a data platform and building up machine
learning. But it really is to have benefit to them. Let's dig into that platform that you've
built a little bit. Is that the data cloud? Yeah, so the data cloud is really this collection of
capabilities, right? Some people identify as the products we build and some identify as this
platform of data. It's built on top of a set of those capabilities, whether it's Amazon EMR
or Amazon SageMaker and S3s at the bottom of it. We have some partners in as well, some of the
key partners in in the data space because there's certain things dealing with, for example, data
security that still is an emerging area of technology. And so we'll bring in partners as need be.
We don't want to constrain people as well. So if they've built models using, for example,
libraries like BERT or GPT-3, they have access to be able to do and use those models as well.
We want to govern those use of third-party systems because we don't want any hacker to infiltrate
our supply chain of ML, if you will. But all of it's there and all of it's available.
We have a sort of a standard way. Either data scientists or data engineers can enter and interact
with the platform. Security is all managed and so they have access to certain data assets. There
may be other data assets that they need to request and get permission to use. Things that get very
personal about people, for example. And then everything included in there is everything's obfuscated
and encrypted. And so if there are data elements that you don't have a need to know, as a
data scientist, you don't need to know. But we'll obfuscate it, but the engine can still perform
actions against it. And so that's a big aspect of the platform is to make sure that
to reduce the amount of data duplication, but also maintain control of some very personal data
that people have. Did the platform start out as kind of abstracting things that you built for
a specific product into a generalized capability or did it start as a larger effort that pulled in
various internal and external things? What's the history? Yeah, now in my experience boiling the
ocean up front to build a platform just leaves you with a bunch of steam and some salt in the
bottom of a container. And then you're just like, well, where did it go? It's like you got this,
well, you got to, you don't have any wrinkles in your shirt, right? And so we build very specific
application elements and we really, really focus on those. And then as if you got two, three,
four of those together, then you can start to line up the commonalities and then you can drop
things out. So, you know, I like to say, well, we moved to the cloud in 2019, but we actually started
a few years earlier on building machine learning. And that actually taught us enough to be able to
know, hey, we need it to move this to the cloud. And what did we need to do to move to the cloud?
Right? And so we build and we continue to do that, you know, build an application for employment
verification, right? So if people are getting mortgages, they need to make sure their employment is
verified and that their income is verified by the mortgage companies. Once you build that,
hey, wow, you know, there's a new type of machine learning we can do to take care of, you know,
name disambiguation across multiple people named Jack Berkowitz. I have the strangest name in the
world and it turns out there's like six of us on LinkedIn right now. So, you know, that way you
can, you can deal with these types of things. So when you say application elements in the context of
the platform, are those applications or are they kind of platform capabilities?
Um, they're kind of both, kind of both, right? So, so a reasoner is a reason, you know,
a reasoner that decides about, um, uh, matching of a candidate to a job or a job to a candidate.
So you tell me your skills and I'll tell you the jobs that are available. Is that an application
or is that an ML component? It's kind of both, right? It's, it's, it's, it's actually a number of
ML components all put together. But then I can abstract it as a single API so that downstream
applications like our recruiting application or our internal sourcing application can hit that API.
So it's, it's at both levels. What are some of the other components like that?
So, for example, we, we do an awful lot with, um, projections. So we have a lot of different
recommenders and optimizers, right? That'll do, deal with recommendations. So we have a capability,
um, for operational managers, non-HR people to get pushed to them insights about their,
their, their team status, right? How many people are leaving? How many people, um, need raises?
What's the birthday every, everybody? You know, I have a large team inside the company.
You know, I'm an operational manager like anybody else, but I still need that HR data.
Um, that comes to me actually on that mobile app where I can check my pay, my, my, my payroll,
right? Or my 401k. On the same exact app, I get these HR insights, right? So this
recommendations there. Other areas that we, we build machine learning for are, um,
um, you know, again, not just for clients, but for the internal company.
How can we, how can we, you know, answer clients concerns about a regulation in a much more
efficient way? And then we can do that. Have that answer, put it out on a chatbot, put it in the,
in front of our, um, our customer service representatives, um, all sorts of different ways.
And so these are, these are, you know, some knowledge management, some recommendations,
some projections, you know, about, are you ready for the shopping season? That's our,
our favorite one for retailers. So we can actually look at, oh, what's the rate at which you're
hiring people? What's the rate at which people are leaving? How many jobs do you have open?
What's the demand? So we can build this small little workforce planning capability,
quickly by assembling our existing components and then have an advantage, uh, for our clients that
use us as a company that is, you know, fully invested in cloud using cloud services at all
different levels, including the platform services like SageMaker. Um, you know, you mentioned,
uh, kind of these higher level services. I'm curious, how do you think through
uh, what level services to consume from your cloud partner and, or, or conversely, what level,
you know, do you target to build that versus, uh, use external services?
And so I wish I would say that, I wish I could say that there was just like some cookbook out
there, but there's not, right? Um, you know, the best thing for us is that we're, we're
closely closely closely integrated with AWS in terms of engineer to engineer. And so people
like me get the heck out of the way and let the engineers talk, which is the best way to have a
partnership with a, with a, with a, with a tech group. Um, and so we, we'll look at capabilities
and we'll brainstorm them together. Um, and then we'll iterate. So sometimes we've built things
that turns out that that, uh, AWS may have. Sometimes they'll say, hey, we're not building it.
And then, or a third party may say, yeah, it doesn't exist. So we'll have to build. Um,
sometimes we have unique capabilities that we need. Um, so, uh, I try not, we try to be more
as a content team and an application team rather than a core technology developer, you know,
like low level code. But just recently we've built some very low level code to build a reporting
application because the constraints, no matter what databases are out there today,
aren't quite what we need for our clients with, you know, the hundreds of thousands of clients
we have in terms of cost. And so we had to get down and start to build something. Now,
we, the first ones to say we should open source this or, or, yeah, exactly. So whether we open
source it or we find something in the community, um, that can replace it. So, so part of that,
it's a some engineering discipline about, um, making sure that you're, you're extracting your blocks
properly so that you, so because the one thing you know about technology, somebody's going to come
along with a better mouse trap. And so, you know, you need to be ready to re-architect and re-factor.
And so we think about it architecturally. We budget time for that as we go as well. But it's,
it's the reality of the cloud. Mm-hmm. You mentioned the, the, the kind of scope of your
customers just now. You also mentioned some scale, uh, figures during your keynote in terms of
the amount of data that you're dealing, the number of transactions. Talk a little bit about that
and the, the broad impact of scale on the way you deal with data. So I mentioned, right, 920,000
clients, 140 countries. Um, you know, we do like 50 million people apply to jobs by our clients
every year. We do 38 million people in payroll every year. Um, we do 11 million 1099s, right?
That's an incredible amount of people doing contracting, right? So all that information comes
together, the number that I put up on stage and it was, it was kind of fun. Um, we move 2.3 trillion
dollars a year. Um, and the number that, you know, it was hard for me. And, and so we did this kind
of thing where we said, what does 2.3 trillion dollars means? And so if it was a GDP, it would be
somewhere between France and Italy in terms of GDP. Now our payments are not GDP, but it still
gives you a sense of the scale. Now, France and Italy have better food than maybe we do, but,
you know, it gives you, it gives you an idea of the scale. And, and then, you know, the
elasticity to process that becomes, you know, insane, right? Uh, I think we do something, I can't
remember the number that we put on stage, but it's like 300 trillion decisions by our machine learning
every month. You know, and so you've got, well, does that mean 312 trillion queries? No, but it,
it means, you know, the individual decision processes that the algorithms are taking as a process.
Um, you know, to somebody who's been around for a while in the business, that's just mind boggling.
I remember when people were pointing the word petabyte, and now we toss around exabytes, and we,
you know, zettabytes as if they're nothing, right? Um, I remember buying my first hard drive,
and it had 10 megabytes of storage, and I remember a guy telling me, you'll never be able to fill that
up. And we fill it up with single PowerPoint files today, right? So, um, so the scale is kind of
amazing. Um, that $2.3 trillion, and everything that that that entails in terms of payments is,
is the number that just sticks in our head every day. Are there specific ways that you have adapted
the way that you operate or organize to kind of manage that scale? Well, I mean, I think I talked
about a little bit. We, we have a, a real distribute in nature to the development teams. Um, and that's
an important aspect to what we're doing. Um, the other thing is is, is, and I talked a little bit
about this on stage, we really wanted to get to a data-centric culture. So rather than having pillars
of, well, these are the data analysts, and these are the data scientists, and these are the domain
experts, and these are, we got rid of all of that, right? We, you know, they're all together in one
team. So a team, it's, it's modeled after this idea of a two pizza team, but we're not quite selling
the products, right? Um, but it is this notion that we bring everybody together to go solve a specific
problem. So, you know, because we have all these people inside of our company that know HR or
no benefits or no payroll, we can bring people right into the development team to be part of the
development team to go solve a problem. And so that's helped us, uh, create very very tight
development circle, uh, timeframes, right? And then it's just iterating out of it. So those are our
two keys. First of all, lots of federations, second of all, very small teams that are able to
iterate on a very specific problem very quickly. Um, and, and those two, those teams are, are across
domain, right? We, we literally, we want them virtually at least sitting alongside each other.
Hey, what does this mean? Yeah, this does this, right? As opposed to going through, you know,
paperwork exercises and presentations and stuff like that.
The data focused folks on those teams, the data scientists, data engineers, they, are they all
embedded within product organizations or do product folks kind of join, uh, into engineering
efforts or yeah, that's a great question. So we look at it. So a lot of things in, in our company,
uh, a lot of the teams will look at it as triad, engineering, product, and design. I actually
look at it as quads, engineering, product, design, and data science, right? And each one of my teams
has, has all four representatives. And then one point, there may not be a data science problem
to be solved, right? But there's still somebody tracking that project from a data science perspective.
Right? Just the same way as the UX on a certain project may just be the API, not, you know,
not some elaborate UI, right? Uh, or maybe documentation could be the UX. So we have all four
domains represented in this quad, fun idea. And the, how long has the company had data scientists?
Probably since they started doing with it back in 1949, right? To be honest, right?
It's a company of accountants, right? Uh, so it's fun, right? Oh, well, this data science using
machine learning. Well, what's linear regression? Right? Uh, you know, it's fun. I, I interview,
you know, people could just get out of school. Oh, I've been, I've learned this thing about linear
regression. You know, it's been around for, since the 1800s, right? So, so I think it's a hard
question to answer. I think if you want to look specifically at machine learning as a practice,
you know, over the, you know, just like everybody else over the past, you know, six, eight,
10 years has really been the ongoing of that. Um, you know, it's, it's, it's the end of 2021.
Anybody who tells you they've got more than 10 years of machine learning experience,
unless they were doing neural networks in the 90s is lying to you, right? Um, and so I think,
I think, you know, in that, in that six, eight year time ranges, when we start to really add
machine learning, and then by 2016, 2017, we had people really cranking on it. So the company was
very, I think nimble into the new technology, more than I've seen on, uh, on other firms.
And when you think about kind of this model that you have or you have the, the,
the teams kind of embedded together for a lack of a better term, um,
um, and as opposed to having a standalone data science organization or machine learning
organization or something like that, how do you kind of take full advantage of the,
so, so we, yeah, so we look at them as, we look at them as as sort of cohorts or, or however
you want to call it grouping. So we have somebody in charge of data science for sure, right?
But then people are matrixed out, just the same way as we have it with UX, the same way as,
because they need career paths. I think that's the important thing people, right? And there's
a value for them to get together and, and argue out different problems and everything. I try to
visit with each team every week. It drives me nuts because, you know, they all want to meet
exactly the same time. Um, so we, we create this community of practice. Um, so, and, and people
often will say, well, it's a guild and I'm not sure it's a guild as much because there is an order
of product managers. There's an Oregon data scientist, but the projects themselves that are being
executed are executed in this, in this group. And then we have somebody leading that, and that
person could be a data scientist, could be an engineering leader, could be a UX leader, or could be
a product manager, leading that specific project. We just want to get the best person in charge
to execute that, that, that project, if you will. We don't care where they come from.
I was asking about that, but also, you know, where innovation comes from within the organization,
do you, um, is it, you know, kind of tucked into long-standing product road maps, or how do you
leverage opportunities that are created by ML and? Yeah, we, we, we kind of, I hate the top-down
bottom-up thing, but that's in a way. It's happened. So, yeah, we definitely have where we want to be
from a business perspective, but, but our, our job, particularly with senior managers,
is just to give the where or the trajectory, let the engineers and the data scientists say,
hey, I have a way to solve that problem. Maybe a way you hadn't thought about. And so,
we do spend a lot of time on ideation during our development cycles. And we are also always open
to rework as we need to. Now, you don't want to rework forever, but we always give the
opportunity for people to do it. So, we're really, we're, we spend a lot of time talking
why we want to build something. And what we want to build, we let those teams go and decide what
and how they want to build it. Maybe to wrap us up, I'm curious, you're, you know, being in this
being in an organization that's very much focused on kind of HR and talent. I'm most curious
about how the company is dealing with, uh, getting the talent that it needs to innovate on the
data side, very competitive marketplace, often kind of large legacy companies, quote-unquote,
are considered to be less attractive places. Like, how do you deal with all that?
So, the same fears that I think about every day, I wake up thinking about that, I go to sleep,
thinking about that, I nightmare to thinking about that. But actually, I think we're really,
we're really benefiting right now. And we're benefiting for two reasons. One, we took some
steps to get to the cloud. And, you know, at least for what I do, for what you do, people
are attracted to the data. They're attracted to the idea that they can actually work on something
with meaningful data. And they're attracted to the culture around data to build these things,
the quads and everything else. And I'm not saying that we don't have any problems getting talent.
But what I would say is, is that we're really successful in being in great people to the company
because once they get exposed to it, whether through the interview or, you know, through this type
of, you know, discussion we're having now. And they dig into it, they get excited. And I think
that's the best part is you see these sparkles even over, over all the, you know, zooming in
everything else. See, sparkle in people's eyes when they discover something. And that's a spreading
activation. And so, whether you're an older company like ours that's, you know, going through
this transition or whether you're a startup, you know, I've worked at startups where there's
not actually a lot exciting going on. Right? And so you really just have to ask people the question
is, what do you want to spend your days doing? Right? You know, do you actually want to spend your
days putting out on Twitter that you've got a free water bottle this week? Or do you actually
want to go solve a hard problem? Right? You know, I'm an engineer. My favorite movie in the
world is Apollo 13, not because of the astronauts, but because when the guy comes in, he dumps
the stuff on the table and says, you know, folks, we got to put this into this to get these people home.
And the engineers rise to the occasion. And that's the way we feel about, about talent.
You know, we'll give you something hard to do. Let's go do it. And that helps with our creating
and helps with, with keeping people energized. And so we're actually doing great on that.
If anybody wants to come join us and give it a go, we're more than happy to have that discussion.
Awesome. Awesome. Well, Jack, thanks so much for joining us and sharing a bit about what
you're up to there. Great. Thank you. I've really enjoyed the conversation.
