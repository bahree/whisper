All right, everyone, I am on the line with Gary Ren.
Gary is a machine learning engineer at DoorDash.
Gary, welcome to the Twomla AI podcast.
Hey, Sam.
Thanks for having me.
I'm glad to get a chance to speak with you.
Yeah, imagine DoorDash is having a bit of a moment.
Nowadays, you've been pretty, things been pretty crazy there.
Yeah, there's definitely been an unprecedented need for our services lately.
And yeah, we've definitely done, we're definitely doing our best
to make sure that we're available for our consumers, for our merchants and our dashers.
Awesome, awesome.
Well, why don't we start by, as we typically do here on the show,
having you share a little bit about your background
and how you came to work in machine learning?
Cool.
Yeah, so I don't have any kind of super inspirational story
about how I got into machine learning.
But I will say that I first found out about machine learning when I was in college.
I was immediately super interested because it seemed to combine computer science,
which is what I was studying at the time, with math,
which is a subject that I've always enjoyed.
So after college, I joined the Microsoft being search relevance team.
And while I was there, I got some really good hands-on experience
applying machine learning and especially deep learning
to search ranking and different natural language processing type of problems.
And then I joined DoorDouch about two years ago.
And since then, I've worked on a completely different set of problems,
focusing on problems with logistics.
And yeah, even though from my work experience,
I haven't really used that much math for machine learning like I initially expected.
All these different ML packages kind of take care of the math for you.
But it's still been super cool to see how with some lines of code
and some math in the background,
you can create these models that can do everything from predict what users are searching for,
to predict how long it will take for you to be delivered.
So yeah, I'm fortunate enough to work on a range of machine learning problems.
And yeah, I've really enjoyed it.
Cool, cool.
How long were you at Microsoft before DoorDouch?
Yeah, I've brought two and a half years.
It's interesting, I talked to a lot of folks at Microsoft and beyond.
But Microsoft in particular,
there's a ton of talented people that kind of got their start working on Bing.
And I think we like to beat up on Bing's search engine.
But the folks that were working on that team
are doing pretty incredible things all over the place.
Yeah, I definitely learn a lot from my time there at Bing.
And there are tons of smart people working there as well.
So it was a great experience for me.
Awesome, awesome.
And so I think we'll be following along a general kind of general discussion
that you led at the recent Nvidia GTC conference
talking about how machine learning powers on demand logistics at DoorDouch.
But before we dig into the specifics of the logistics applications there,
maybe tell us a little bit about the kind of the general landscape for ML at the company.
Yeah, so I think to better understand how we're using machine learning at DoorDouch,
it's best to start by first understanding our business,
which consists of a three-sided marketplace.
So this includes consumers, merchants and dashers.
And each of these sites, they use DoorDouch for a different reason.
For example, consumers want the convenience of being able to stay at home
while still having access to all their favorite merchants.
Dashers want flexible work opportunities.
And merchants want to increase the reach and revenue of their business.
And dashers are the folks that are delivering the food?
Yep, sorry to clarify.
So dashers are the drivers who deliver the food, correct?
Got it, got it.
OK.
And so, yeah, so this three-sided marketplace leads to many interesting problems
that machine learning is applied to.
So for example, between consumers and merchants,
there's a lot of your traditional e-commerce type of problems.
For example, recommendations, search ranking,
those are some things that are pretty standard in e-commerce.
And those are problems that we have as well.
And then between consumers and dashers,
there's a lot of problems around balancing supply and demand.
How do we make sure that we have enough dashers supply
to meet the consumer demand?
And some of the ways that we do that
is by forecasting demand, forecasting supply.
And there is leverage such as dynamic pricing to try and balance it too.
And then between dashers and merchants,
there's a lot of your traditional dispatch type of problems,
such as the core Simon algorithm, which
is how we find the optimal matching between dashers and deliveries.
And so each of these three sides as well,
they also individually have their own interesting problems
that we can apply machine learning to.
For example, for merchants, one challenge of problem
is how do we predict how long it would take merchants
to prepare the food?
If it's a patai, if it's a pizza, if it's just ice cream,
that's ready to go.
How do we actually predict this as the merchant?
Yeah, so we do ask them.
But merchants, a lot of times, you know,
it's very hectic, very busy in the kitchen.
And they're not able to provide an accurate estimate either.
And so it's super important.
I think about one of my favorite restaurants here in town.
It's a Jamaican restaurant.
And they are particularly notorious for,
oh, it'll take an hour.
You get there.
And you're waiting, you know, another hour, you know,
for the food.
So I need to apply machine learning to that
is what I'm hearing.
Yeah, and that's exactly what we do.
We're definitely taking input from the merchants.
And we also use our own historical data
to try and augment that and come
of the most accurate predictions possible.
Mm-hmm.
Cool.
So the particular application that you presented on
was on-demand logistics.
Is this one that you personally work on,
or is this just one of the many applications at DoorDash?
Yeah, so this is one that I personally work on.
So I work on the logistics team.
And so logistics.
Yeah, the way I'll explain it is,
it's kind of the core engine that powers
the fulfillment of deliveries on DoorDash.
And so logistics includes many of the problems
I mentioned before, such as balancing dashed supply
and consumer demand, as well as the core assignment problem,
which again is how we often find the matching
between dashes and deliveries.
Mm-hmm.
And so kind of walk us through how
to approach those kinds of problems.
Mm-hmm.
Yeah, so I'll say, I'll start by saying
that the high-level goal of the logistics engine
is to make sure that we have fast and efficient deliveries.
And so what this means is that obviously consumers
will hate it if their order takes a long time to be delivered.
And so we want our deliveries to be as fast as possible.
But at the same time, we want our marketplace
to be operating as efficiently as possible, as well.
And so the way that we do that is in a few different stages.
So first is setting up the marketplace
by balancing supply and demand.
So you can imagine that if we have 100 deliveries
but only 10 dashers, then no matter what
else we do in the rest of our logistics system,
we're now going to have fast deliveries.
Because there's 100 deliveries out there
and only 10 dashes available to fulfill them.
And vice versa, if we have 100 dashers,
the only 10 deliveries, then a lot of these dashers
will be sitting around idle.
And it won't be a very efficient use of their time.
So balancing supply and demand and setting up
the marketplace for success is kind of first step
in our logistics system.
The second step would be route planning.
So once you have these dashers and once you have these deliveries,
it's super important for us to plan out
the optimal routes for each of these dashers and deliveries.
And so you can imagine that there's thousands of thousands
routes that we need to account for in real time.
For example, between the dasher and the merchant
and between the merchant and consumer.
And so with the plan for all these routes in real time,
and once these are ready, they all get fed into the final stage,
which is where the optimal matching happens.
So once we have all these deliveries, all these dashers,
and all these data about these deliveries and dashers,
how do we find the optimal matching
between dashers and deliveries in order
to have the fastest deliveries possible
while having an efficient marketplace?
And so yeah, those are good.
I was just going to say a couple of questions jump out of me.
One is you've referred a couple of times
to a logistics engine or a logistics system.
Is this kind of a single piece of technology
or a single literally a single system,
or is it a suite of different applications
that are used to perform all these different tasks?
Yeah, so it's a suite of different applications.
So we have multiple systems that kind of take care
of each of these individual components I mentioned.
So we have one system that takes care of balance
and supply demand, another that takes care of route planning,
and another that takes care of the actual matching itself.
And the way you described it happening in series,
I'm envisioning something that,
or well, the question is are you doing the balancing
and matching and all this in batches, hourly or something?
That doesn't seem like it would work, right?
Or is there a way that you're doing it real time
or what's the granularity that you're making
these kinds of decisions?
Yeah, that's a good question.
So I'll start by talking about how we do the balancing
for supply and demand.
So for this, we actually do it over a pretty wide time range.
So several days out, that's when we first start
to try and balance a pandemic.
So for example, starting today,
we'll try to make predictions for what will happen next week.
And based on that, we'll already start taking actions
to try and balance a pandemic.
For example, if we predict that
we're gonna get a huge spike in demand next week,
then we can take different actions
to make sure that we try and get more dashes on the road.
And the reason that we do it so far in advance
is because for our dashers, it's useful for them
to be able to know when it's gonna be busy in the future
and better plan out their own schedules that way.
And then once we make this initial prediction,
we also continue to update these predictions as we go.
And all the way up to real time.
And so in real time, we continue to monitor
the state of the market.
And so we see that we try to check
if there's an imbalance between dashers and deliveries.
And if so, again, we take different actions
to try and balance it.
So in real time, if we notice that there's not
a dashes on the road, we'll take different actions
to maybe message dashers, telling them
that it's very busy right now, or creating more incentives.
And vice versa, if there's too many deliveries,
then we have lovers such as search pricing,
where we'll increase pricing,
in order to hopefully curb them in.
And we can also do messaging to dashers
to let them know that, hey, it's not that busy right now.
So it might not be the best time to dash.
Yeah, okay.
And so that is that part of the problem is done
kind of over this extended time period.
I'm imagining other parts of it,
like the core matching has to happen kind of on the fly.
Yeah, so core matching is definitely more real time.
So as deliveries come in,
as we predict that they'll be available to pick up,
so kind of going back to the food preparation time
that we were talking about before.
Obviously, we don't want to assign delivery right away
after the order has been submitted,
because a lot of times the food takes an hour
to be prepared, then we will be assigning a dasher
way too early.
And so once we have these raw inputs from the deliveries,
we also make a bunch of different predictions,
one of which is the food preparation time.
And then again, all these raw data along these predictions
get fed into our matching system,
which we'll find the optimal matching.
And yeah, this is all done in real time.
We get inputs from deliveries and dashers in real time,
make the predictions in real time,
and also do the matching real time.
One thing we are moving towards though,
and that we are exploring is you can imagine that,
for example, as we've grown,
we've noticed patterns and where our demand
is comes in throughout the day.
So for example, if there's a really popular merchant,
then it's not that hard to expect
that that merchant will receive some orders
during a Friday dinner, for example.
And so one of the things that we're exploring
is trying to anticipate these orders ahead of time.
And then that way, we can better position our fleet
and better make our assignments to account
for these future deliveries.
Yeah, I was going to ask about that.
I noticed for scheduled ubers, for example,
the impression that I get is not that it actually schedules
the ride, but that it inserts the order for me at the time,
you know, before I need the ride,
but, you know, kind of real time.
There's not really any notion of scheduling.
And I don't know if DoorDash has a notion of scheduling,
like I'd like my dinner at seven o'clock tonight
and so figure out all the kind of working backwards.
And I was curious if that's a,
is that a, you know, based on,
you know, a lot of experimentation on how to do that,
or is it just a simplification
that kind of works in the industry
for these marketplace types of applications?
Yeah, so we do have scheduled deliveries as well.
Okay.
And thanks so much to Wages ascribe.
Yeah, we kind of just treat them as a regular delivery
that happens sometimes in the future.
Okay.
And so for some of the future, predicting future deliveries
work that I was mentioning, basically,
you can think of as scheduled deliveries,
a kind of future deliveries that we know
with pretty much 100% certainty will happen.
Whereas any prediction that we end up making
will have some kind of confidence interval
if that delivery will actually occur or not.
And so we can treat them a pretty similar way.
But yeah, in the end, they are all accounted
for pretty dynamically.
Again, we try to, we ultimately try to predict
when the food will be ready to pick up
and assign the dash of base on that time.
So one of the most interesting aspects of your approach
and you spend quite a bit of time
talking about this in your presentation
is that you are pairing machine learning
with kind of traditional approaches
to logistics optimization.
So you know, let's dive into that a little bit.
Yeah, awesome.
Yeah, so definitely we do make a lot of use
of combining machine learning
and traditional operations research.
And so I'll talk about how we apply this combination
to both supply and demand as well as the optimal matching problem.
So for supply and demand, like I mentioned,
we try and forecast out supply and demand multiple days
and events.
And when we determine that we'll have more deliveries
than dashers, we'll create these incentives
to try and get more dashes on the road.
And again, we do that upfront and in advance
so that dashes have time to plan on their schedules.
And so what this means is that we have to forecast out
what the men will be.
And forecast out what supply will be and determine
what the right incentive is.
And so this gets very challenging
one because of the complexity.
So for example, if you want to determine the optimal incentive
for every single region and every single time of day,
that obviously gets very complicated.
And there's lots of possible combinations
that you can choose.
Another reason it's so challenging
is because forecasting itself is always a challenging problem.
Forecasting, future demand, forecasting, future supply.
There are a lot of factors that go into it.
And especially when you're predicting these things
that are so heavily influenced by the real world,
it makes it even harder.
There's super high variance from things such as weather,
traffic, special events, a pandemic.
So all these things can have huge impact
on our future supply demand.
And so being able to handle all these things
are super challenging.
And so how we try to solve it is
by combining machine learning and operations research.
So with machine learning, we try to build our models
that accurately forecast that demand a supply.
And so once we have these models, what we can do
is feed them into operations research system
in order to find the optimal incentives.
And so the way we do that is by framing it
as a traditional operations research problem,
where we have some objective.
And so in this case, our objective
would be to maximize our delivery quality.
And we also have some constraints.
For example, we can't create $20 incentives.
We want to keep cost low as well.
And so given this objective of maximizing delivery quality
and given this constraint of cost,
we can feed our inputs from our machine learning model
into this system.
And then we can ultimately solve for the optimal incentives
by using integer programming.
And so this basically treats the problem as a math problem,
where you have some objective function,
you have some constraints, and you solve it
through these mathematical methods.
And so yeah, super interesting, because otherwise,
you can imagine that how would you
pick the optimal incentives for every city that DoorDash
operates in for every single time of day?
It gets very challenging.
There's so many combinations.
And if you have human operators do it,
they will have to manually go through every single region.
They will somehow have to try and balance that,
OK, show that at $1 here in San Francisco,
or is it better to spend that extra dollar in San Jose?
And so by feeding into, by using operations research,
we're able to better make these trade-offs
and ultimately come up the optimal set of incentives
that, again, maximize the delivery quality.
And yeah, sorry.
Oh, no.
I was just going to ask, you mentioned integer programming.
Is it also linear, like you're using linear programming
models, or is it nonlinear OR stuff?
Yeah, so we have a mix.
Some's linear, some's nonlinear.
And sometimes we also do mixed-anger programming as well.
OK.
And so essentially, you've got kind of these tried-entry
techniques for solving these systems of equations,
where you have known quantities.
But in your case, some of the quantities you don't actually
know, so you use machine learning
to try to predict what those quantities are.
And then you kind of pump those into the traditional OR
types of tools.
Yep, exactly.
And because of these natural errors in machine learning
models, unfortunately, obviously,
our predictions are not perfect.
So because of that, it's super important for us
to have real-time systems in place to kind of adjust
for these errors.
And so some examples are what I mentioned earlier
where in real-time, we also have monitoring in place
to see if there's imbalance in or supply in demand.
And it will take different actions and response
to essentially try and correct for the mistakes
that are more predictive systems have made.
And so when it's in the case of a monitoring system
identifying an imbalance, does it
is it trying to correct that by, does it just take an action?
You've got some kind of program behavior
that is based on what it observes?
Or does it tweak the inputs and run it
through the same system, hoping that you get a better
output?
Yeah, so currently the way that we do it
is we basically, once we determine that there's an imbalance,
we try to measure how much that imbalance is.
And from there, we have a set of actions
that we have available to us.
And for each of these actions, we try
to understand the impact of each of these actions.
Again, that becomes like a prediction in some ways
where we're predicting what the impact will be of different actions.
For example, if we message dashers,
how many more dashers will we get on the road versus
if we add an extra dollar incentive?
How many more dashers will we get on the road?
And so we have all these different actions,
estimates for the impact of each of these
and based on that.
And again, matching that with how much imbalance
there is currently will pick the action
that tries to fix the imbalance.
Yeah, there's something that we're actively working on
and something that we're building out.
But that's kind of a general framework
where we monitor and we determine how much imbalance there is
and choose the action or the set of actions
that we think will help us fix the imbalance.
And do you incorporate aspects of control systems,
control theory in there?
I'm imagining you're monitoring, observing,
you take some action based on what you think is going to happen.
You kind of overshoot, you might want some dampening in there
or you might need to overcompensate.
Do you just think of systems in that way
or are you just kind of taking a snapshot in time
and if you're oscillating or not,
you're not paying attention to that.
You're just doing making the correction
that needs to happen at a given time.
Yeah, so we definitely, we frequently
check the state of our markets in order
to try and correct for these actions
that maybe we went too far in one direction.
And so yeah, we very frequently check the state of the market.
And if we notice that say we measure dashers
but that result in us having too many dashers on the road
actually, at that point, yeah, we can take additional actions
to try and either reduce the number of dashers on the road
or maybe curb demand at that point.
And so, yeah, and so another approach
that we're exploring as well is framing it
as a reinforcement learning problem.
So you can imagine this problem fits pretty well
into the reinforcement learning framework
where you have some state,
which is essentially the state of our marketplace,
how many dashers there are, how many deliveries there are.
You have a set of actions,
which are these different levers that we have
to try and correct for supply and demand.
And then you have your reward.
In our case, it will be metrics
about delivery quality and efficiency of the marketplace.
And so given these settings,
it fits pretty nicely into reinforcement learning framework
where we can explore and exploit, try out different actions,
see what the reward is, what the impact is of those actions.
And based on that, we can update our models
to one, have better estimates of what the impact
of different actions are,
and two, also allow models to intelligently
take what the best action is at any given state.
And so yeah, this is something we're exploring.
There's other problems with the logistics as well,
that fits pretty nicely into the reinforcement learning framework.
So we think that will be a pretty powerful tool
for us moving forward.
You mentioned that you,
it sounds like you have kind of boiled
all of your customer,
sat metrics into a delivery quality metric.
Is that a metric that you use across the board
in assessing the performance of these kind of systems
or is it specific to the reinforcement learning implementation
that you're looking at?
Yeah, so it's not specific to the reinforcement learning
implementation.
We do have these shared metrics that we commonly look at.
For example, how fast does it take
for a delivery to be delivered?
From time when you place an order
to when it arrives at your doorstep,
we want to minimize that time as much as possible.
And there's other consumer facing metrics
as well that we care about.
For example, cancellations.
We want to reduce cancellations as much as possible,
whether it's because the merchant was actually close
or maybe the consumer got sick of waiting for so long.
And so a lot of these metrics are pretty common
and are shared across the board by different teams,
whenever they work on something that
could impact these metrics.
But again, depending on the project,
there could also be more specific metrics that you look at.
You can think of these delivery times, cancellations,
metrics like that as more of output metrics.
But a lot of times we might want a more granular look
at what the input metrics look like.
And so some examples would be maybe
in self looking at delivery times directly.
Maybe we want to focus on looking at how long it took
to drop off to happen.
So say we're working on a product that
tries to speed up the drop off process.
How long it takes the dash to drop off
the delivery to the consumer.
And so in that case, it will be useful to look
at this more specific metric.
And so tell me a little bit about your experiences
with the reinforcement learning approach.
What have you found there?
Yeah, so it's been still in a more exploratory face
at this point.
And I can maybe talk a bit more about some of the results
that we got when we tried to apply reinforcement learning
to the Simon problem.
So again, here, it was a pretty natural fit
because we have these states, which, again,
is all the existing deliveries and dashers at any given time.
We have these different actions, which
would be all the different possible matching
between dashes and deliveries.
And so what we've actually tried is,
because as you can imagine, if you treat every single combination
of dashed delivery pair as the different actions,
that action space becomes very huge.
So even with 15 deliveries and 15 dashers,
there's actually over one trillion possible combinations.
And so obviously, working with that large of action spaces
is very challenging.
And so what we did was actually, we tried to simplify
and reduce action space by, instead
of using the different combinations of matching as the actions,
we just used different variants of the Simon system,
of the Simon algorithm, as the different actions.
And so those were actions.
And again, our reward in this case was delivery speeds
and marketplace efficiency.
And so once we sell the problem this way,
we tried using pretty standard reinforcement learning methods.
Specifically, we tried using deep reinforcement learning
where our agent was a deep neural network
that took in a bunch of features
and tried to learn for any given state
what was the optimal action to take.
And then again, in this case, the optimal action
is the optimal variant of the Simon algorithm.
So yeah, we've done some exploratory work with this.
We have a blog post about this on our website,
actually, as well with more details.
But we did see pretty problems and results
where we saw some few seconds improvements
and delivery speeds as well as efficiency.
And so a few seconds doesn't sound like much.
But when you scale it up to millions of deliveries.
I want to leave my pizza.
Yeah, definitely.
But yeah, when you scale it up to millions of deliveries,
it definitely adds up.
Interesting.
And so what are the challenges?
What's keeping you from putting that into production?
Yeah, so I think one is we definitely
just need to keep doing more work
to improve each other components within that reinforcement
learning system, improving the deep neural network agent,
improving the different features that we have.
And of course, our system right now,
we don't have a lot of these infrastructure pieces set up.
So it would have to require some restructuring
and we're working on the system, which again, right now
is very much based on using machine learning
plus operations research.
And so yeah, there's definitely a lot of investment
that needs to be made to move away from the current framework
that we have.
But again, yeah, we're always exploring
trying new techniques to do things,
including reinforcement learning.
And as we do more of these explorations,
at some point, if we feel that the improvements
that we'll get is worth this long-term investment,
we'll definitely make this switch then.
Is it possible to, in thinking about kind of the way
you've paired this machine learning system
and the operations research system?
Is it a future direction or of interest
to try to kind of collapse this down
to a single machine learning system?
Is that something that is worth exploration
or if not, why not?
Yeah, I think it is something worth exploring.
I do feel that the challenging part of doing that
would be that there's certain aspects of the problem
that it's just very naturally suited for operations research.
And what I mean by that is whenever you have a problem
where you have a very clear objective function
that you're either trying to maximize or minimize
and use a very clear constraints, it's
much easier to frame as operations research problem
because that's exactly the kind of problems
that they're meant to solve.
Where you have some objective, you have some constraints,
and you basically frame as a math problem
that's much easier to solve.
And so I do think there could be potential
for maybe having some kind of like one shot ML model
that can kind of do everything end to end.
But right now, I haven't found any great ways
of using ML to completely solve these type of problems
where you have objective, but then you also
have these sort of constraints that you must abide by.
And so for us, we found that yeah, combining machine learning
to try and make these predictions, augment the raw data
that we have and feeding it into an optimization system
that can take care of handling these constraints for us,
take care of maximizing and minimizing the objective function.
We found that this approach has worked really well for us.
And the operations research elements of this,
do they, I'm imagining with the, you know,
the kind of the machine learning world,
where, you know, this is all very new.
We're kind of constantly iterating our systems and models
and things like that.
Is your OR system kind of equal in that way?
Are you kind of constantly, you know, tweaking
and iterating, or is it, you know,
because it's a kind of more mature approach,
is it something that once you've identified your constraints
and build this pipeline for your inputs,
it kind of just does this thing
and you don't have to worry about it as much.
Yeah, that's a good question.
So it is definitely a more mature field, like you said.
But our team is definitely always trying new improvements to it.
Some of it could be very small tweaks to the system.
For example, tweaking different settings,
tweaking different parameters, tweaking different ways
of calculating the objective function.
And so we're always trying these things.
And yeah, you'll be surprised sometimes, even the smallest changes
can lead to some of the biggest gains.
Some of the most improvements that we've gotten
over the past year or so have been from very simple changes
on two different systems.
So I can't go into the details, unfortunately,
but some examples are basically just tweaking
a single parameter, say going from like four to five
and that bands up leading to a pretty big result.
And so yeah, so we always do tweaks like that.
And we also, we're always exploring brand new ways
of doing the operations research piece as well.
So actually, the switch to using mixed integer programming
for our dispatch system, that switch was actually made
not too long ago.
So we used to use a simpler algorithm that wasn't as efficient
because it could only do a single matching at a time.
And kind of recently, we transitioned
to this mixed integer programming approach
where we can handle multiple deliveries, multiple dashers
and create multiple matching at a time.
And so yeah, so yeah, so we've always explored new options.
And yeah, I wouldn't be surprised if sometime down the line,
we find some new way of doing this optimization
that nets us some really big gains.
And the mixed and mixed integer programming
does that relate to this idea of multiple inputs
and multiple outputs?
Or I forget what that's specifically,
is that partial some floating point, some integer
or is it related to the inputs outputs?
Yeah, exactly.
So it's related to the variables in the optimization form.
So some of them integers and some of them are floats.
Okay, okay.
And so how does the, how does incorporating floats
into your problem allow you to kind of what I heard
was like optimize multiple variables in parallel?
Yeah, so that component isn't what ultimately
and allows us to make multiple matching in parallel.
So the main change is moving towards this
just general mixed integer slash integer programming approach.
And so before, where again, our system
could only make one pair of matching at a time.
And the reason that this was the case
was because we were using this algorithm
called the Hungarian algorithm.
Okay.
Where one kind of runs pretty slow,
especially when you're running it at scale.
And then yeah, again, it only does one matching at a time.
And so instead by formulating a problem as a mixed-anger program
problem, we're able to not just speed up
how fast variable solve these problems.
But again, also have multiple matching.
And once we frame at this problem,
we can continue to have machine learning
generate predictions to use as different inputs in this system.
For example, we can predict food preparation times.
We can predict how long we'll take the delivery to be delivered.
And based on that, we can create our cost functions,
our objective functions, and optimize that way.
Okay.
Very cool.
Very cool.
Were there other points that you covered
in your presentation that we should make sure to touch on?
Yeah, so I would say one thing that I wanted to stress
as well is kind of just how challenging
a lot of these problems are.
So I think one thing that I've touched on
is the high variance of our systems.
So because we operate in a real world,
lots of factors such as weather, such as traffic,
special events, yeah, one fun example is one game
of throwing things to be on.
Every Sunday evening, we'll see huge spike in demand.
And so even though the last couple of seasons,
maybe one that great, we still had a huge surge in demand.
And people are definitely tuning in.
Yeah, people are still hungry, people are still tuning in.
And I like this one, we have like the Super Bowl.
People definitely tend to order delivery.
And so counting for all these different factors
has been super challenging for us.
That's kind of interesting from the perspective of,
we tend to think about you kind of build this model
and then you put it in a production
and you want to keep an eye on it and make sure
that the data that it sees, you know,
looks like the data that you trained it on.
But it sounds like you've got all these real world factors
that are making the data that the models are seeing
in production, you know, look very different.
Like how do you approach, is there a different way
you need to think about model monitoring
in a high variance environment?
Yeah, I would say you just need to be very careful
and very thorough how you monitor your models.
So I think, yeah, definitely.
Yeah, so I think, so I think one general point
that I want to bring up to is one challenge
I found with machine learning in the industry
is it's not just about finding the right hyper parameters
or finding the right model algorithm to use.
It's also involves a lot of general engineering principles
as well to deploy machine learning
to solve your problems in a reliable and scalable way.
There's a lot of systems that you have to set up in place.
Yeah, one example would be how do you make sure
that you monitor any degradation in your models?
How do you make sure that there's consistency
between the data that you saw during training
and the data that you see during prediction?
How do we manage and run experiments
with different versions of many different models?
How do we periodically retrain these models?
As they degrade, how do we make sure that they get retrained
and updated with the latest data?
And of course, yeah, how do we protect against
incorrect predictions?
In cases such as, yeah, when a pandemic hits,
our models are always going to struggle at predicting that.
So how do we make sure that we account for these
incorrect predictions and adjust accordingly?
And so we've invested a lot of time and effort
into building out engineering systems
that can take care of these things for us.
So setting up monitoring of our model predictions,
monitoring of our model inputs,
making sure that the data that the model sees
is always what it expects.
And if we notice anything wrong, anything that deviates
from what's expected, whether it's the model output
or the input data into the models,
we can take different actions to try and fix that.
So one example is if we see that the model accuracy
is slowly degrade over time, then we can retrain the model.
And we have systems that have been placed as well
so that these models are automatically retrained.
And so when it's time to replace it,
it's a pretty simple switch where we just plug
and play in the new model.
Other cases, it might be more complicated.
So for example, if, yeah, when there's a pandemic again,
our model obviously didn't generate very accurate predictions
in those cases.
And so that might prompt us to look into,
maybe there's some features that we want to add
that will help us better correct for any errors we have.
And maybe, aside from just improving the model itself,
maybe that tells us that we need to build
more real-time systems in place.
And these can be augmented with machine learning
or they could just be using simple heuristics
that try and detect model errors
and then take different actions to account for them.
And so this kind of goes back as well
to how we balance up the time demand.
Where, again, we have all these predictions.
We do all these things ahead of time.
But ultimately, in real-time, we know
that we're not going to have a perfect system.
And there's still going to be imbalance real-time.
And so we spend a lot of time in building
on this real-time monitoring, this real-time system
that can take actions to correct for any issues that we see.
OK.
In the case of the onset of coronavirus did,
I'm imagining you saw your models not working the way
that they otherwise would have was
were your existing model monitoring and retraining
tech and procedures kind of enough?
Or did you find you had to do a lot of manual overrides?
To kind of make it through because it was unprecedented times?
Yeah, so we definitely used a mix of relying
on our existing systems that automates a lot of this
monitoring, retraining, plus some manual actions
on top of it as well.
So a lot of times, like the day of, for example,
when Shelter Place first started,
or when the stimulus checks first went out,
those are things that we're not able to, our systems
are not always able to react as quickly as we would like.
For example, if we were to retrain the model,
we would need new data to come in first
before we can retrain it.
And so in those cases, we definitely
have operators who will, again, help
with monitoring our systems.
And if they notice any drastic changes
that our automated systems are not accounting for
and are not adjusting well enough for,
they will take additional actions on top of that.
And so this is something that we always have in place.
It's not something that we just do because of COVID.
There's always interesting cases here and there
where we have these super drastic events that
requires additional manual intervention.
And so we do still rely on a mix of automated systems,
as well as human intervention.
Got it.
Got it.
Cool.
Well, Gary, thanks so much for taking
the time to share some of that with us.
Yeah.
Thanks, Sam.
Thanks for having me.
Awesome.
Thank you.
Cool.
for your own convenience
to live a happy life,
a happy life with your wife
I'm tired
I need you
I don't want to give you my away
Just listen
or you'll just come
