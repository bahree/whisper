1
00:00:00,000 --> 00:00:16,240
All right, everyone. I am here with my good friend, Dylan Herb. Dylan is the CEO of PaperSpace.

2
00:00:16,240 --> 00:00:22,720
Dylan, welcome back to the Twimal AI podcast. Thanks for having me. Hey, I am really looking

3
00:00:22,720 --> 00:00:29,040
forward to digging into our conversation. It is just about actually just over a year since

4
00:00:29,040 --> 00:00:35,280
the last time we spoke. We had a really good conversation on machine learning as a software

5
00:00:35,280 --> 00:00:41,440
engineering discipline. And maybe we'll reflect a little bit on that. But before we do,

6
00:00:41,440 --> 00:00:49,040
I'd love to have you kind of reintroduce yourself to our audience and maybe share a bit of an

7
00:00:49,040 --> 00:00:54,800
update on PaperSpace and what you've been up to in the past year. Awesome, thanks Sam. Yeah,

8
00:00:54,800 --> 00:01:01,200
so my name is Dylan Herb. I'm the CEO and co-founder of PaperSpace. We are a cloud computing company

9
00:01:02,240 --> 00:01:07,120
that builds a suite of tools for machine learning developers that simplifies the process

10
00:01:07,120 --> 00:01:13,120
of training and deploying machine learning models. We're based in New York and yeah, I guess it's

11
00:01:13,120 --> 00:01:22,240
been a fun year since we last chat in. Yeah, so I mentioned that conversation and it was one

12
00:01:22,240 --> 00:01:31,280
that we got a lot of great feedback on. We talked about this idea of machine learning. I guess

13
00:01:31,280 --> 00:01:41,280
it was a point in time where it was becoming very clear to folks that there was a shift for many

14
00:01:41,280 --> 00:01:48,240
in thinking about machine learning as this experimental process or an exploratory process to one

15
00:01:48,240 --> 00:01:56,080
that required engineering rigor and discipline. We had a really good conversation about that idea,

16
00:01:56,080 --> 00:02:02,880
but I wonder if you would share maybe your big takeaways or recollections from that conversation.

17
00:02:02,880 --> 00:02:09,680
What were the key points for you? Yeah, definitely. I think that it's probably true in any space that's

18
00:02:09,680 --> 00:02:14,960
moving very quickly where the underlying technology is changing seemingly every week.

19
00:02:14,960 --> 00:02:21,200
But as you know, in the machine learning space in particular, there's been a big conversation

20
00:02:21,200 --> 00:02:28,000
about questions such as does machine learning require its own special set of tools or can we reuse

21
00:02:28,000 --> 00:02:36,080
maybe existing tools from the software engineering world? Are there special considerations for

22
00:02:36,080 --> 00:02:41,840
the users of these applications? Is a data scientist a traditional software engineer or something

23
00:02:41,840 --> 00:02:47,360
different? How do we bridge the gap between the kind of more standard machine learning programming

24
00:02:47,360 --> 00:02:53,760
languages like Python or Julia and the more traditional kind of software web tools and programming

25
00:02:53,760 --> 00:03:00,000
languages like Go and JavaScript? I think it's moved very quickly and I would say even today

26
00:03:00,000 --> 00:03:04,960
it's shifting, but I think it's undeniable that machine learning is very quickly making its way

27
00:03:04,960 --> 00:03:11,200
into the software engineering discipline and we're more importantly into a practice of

28
00:03:11,200 --> 00:03:22,320
like delivering machine learning models. So I saw a tweet this morning actually from SRK

29
00:03:23,120 --> 00:03:31,440
and paraphrasing it a little bit here, but the idea was 2015 to 2016 image and vision.

30
00:03:31,440 --> 00:03:46,880
Someone added 2017-2018 Transformers 2019-2020 NLP 2021-2022 MLOPS and the big question was 2023-2024

31
00:03:47,680 --> 00:03:57,440
question mark and you know they were soliciting thoughts on kind of what's next and idea that

32
00:03:57,440 --> 00:04:05,360
we've been talking about that we'll kind of discuss more here you know could be the thing that

33
00:04:05,360 --> 00:04:11,680
fills in that blank and this idea of compositional machine learning. We picked it around a couple

34
00:04:11,680 --> 00:04:19,520
times in prior conversations and you know maybe this is kind of a good entree to have you share a

35
00:04:19,520 --> 00:04:24,000
little bit about you know when you think of this idea of compositional machine learning you know

36
00:04:24,000 --> 00:04:30,080
what is it where did it come from what were some of the inspirations that you've seen recently

37
00:04:30,080 --> 00:04:39,760
that started you thinking down this line. Yeah I really like that that framing and it's funny how

38
00:04:39,760 --> 00:04:44,000
quickly all of those changes happened you know I think there's there's also this whole question

39
00:04:44,000 --> 00:04:50,000
around foundational machine learning or foundational models you know where are we in sort of the

40
00:04:50,000 --> 00:04:54,800
adoption curve I think you know an idea that we've been kicking around I know that you and I

41
00:04:54,800 --> 00:04:59,680
have talked about in the past is this you know or more recently around compositional AI and so for

42
00:04:59,680 --> 00:05:06,320
us you know we've we are we're really at the I would say the beginning of a lot of folks is

43
00:05:06,320 --> 00:05:13,520
journey into machine learning so gradient our machine learning stack is is used by you know at

44
00:05:13,520 --> 00:05:17,840
this point hundreds of thousands of data scientists and machine learning engineers for primarily a

45
00:05:17,840 --> 00:05:23,840
Jupyter notebook product similar to like a Google collab or you know kind of a web based IDE

46
00:05:24,560 --> 00:05:28,800
and so you know we've been really close to seeing folks you know kind of begin their journey

47
00:05:28,800 --> 00:05:34,320
into machine learning and very rapidly we've started to see some some kind of interesting breakout

48
00:05:34,320 --> 00:05:42,160
cases of of how this of how machine learning has become sort of you know composed or or remix in a

49
00:05:42,160 --> 00:05:46,640
way that I think is just fascinating you know a couple that come to mind that have really kind of

50
00:05:46,640 --> 00:05:52,560
sparked a an internal you know kind of dialogue for for us at paper space have been you know one is

51
00:05:52,560 --> 00:05:58,480
is you know this model a first-order motion model came out of NERIPS in 2019 and then earlier

52
00:05:58,480 --> 00:06:05,040
this year we had someone on our platform build a kind of viral funny lip-syncing app that went

53
00:06:05,040 --> 00:06:10,800
from you know sort of academic paper a couple years ago to you know number one app in the app

54
00:06:10,800 --> 00:06:15,440
store you know in lots of countries worldwide and so you know it's kind of interesting where you

55
00:06:15,440 --> 00:06:19,760
see you know maybe an app developer taking a machine learning model and applying to something

56
00:06:19,760 --> 00:06:25,440
you know odd or interesting the other one that I think has been really inspiring is you know we

57
00:06:25,440 --> 00:06:30,080
talk a lot about you know who who's the audience of this and is it software engineers as a data

58
00:06:30,080 --> 00:06:36,080
scientist as a mathematician statisticians and and I think it's actually you know gone expanded

59
00:06:36,080 --> 00:06:40,240
more quickly than we could have imagined so today you know one of the biggest audiences in the

60
00:06:40,240 --> 00:06:45,600
in the Twitter sphere is you know artists and creators you know folks doing generative art and

61
00:06:45,600 --> 00:06:52,880
that's been precipitated largely by open AI's clip model which is contrastive language image

62
00:06:52,880 --> 00:06:58,240
pre-training which basically was a model that was introduced that when you kind of remix it with a

63
00:06:58,240 --> 00:07:03,360
couple of other generative models gives you the ability to kind of you know use a text-based input

64
00:07:03,360 --> 00:07:09,120
and generate you know really fantastical amazing art projects you know and now this is making its

65
00:07:09,120 --> 00:07:15,920
way into NFTs so so I think what's really interesting today is you know whether whether or not some of

66
00:07:15,920 --> 00:07:22,080
these big models are foundational or or essential or or whatever I think what we're seeing is you

67
00:07:22,080 --> 00:07:26,640
know they're getting composed in interesting ways so the API is not necessarily a cloud-based

68
00:07:26,640 --> 00:07:31,680
API that people are consuming but really like you know taking these building blocks and reapplying

69
00:07:32,880 --> 00:07:36,960
so so I think this idea of compositional AI is something that we're you know it's it's kind

70
00:07:36,960 --> 00:07:42,320
of a framework that we're understanding how machine learning is moving past kind of this academic

71
00:07:42,320 --> 00:07:50,240
phase into you know kind of unexpected and interesting real world applications. Do you draw

72
00:07:50,240 --> 00:07:57,520
inspiration for that from kind of the first wave of APIs around the web but certainly you know

73
00:07:57,520 --> 00:08:02,960
especially when you use the term remix that was the term that we like to throw around I was trying

74
00:08:02,960 --> 00:08:13,440
to kind of mentally pin that in time and I don't really have the I don't you know I have to

75
00:08:13,440 --> 00:08:19,920
research that but like there was this transition from kind of this old school way of thinking about

76
00:08:19,920 --> 00:08:27,840
integrating different applications like you know SOA and web sorry XMO web services that no one

77
00:08:27,840 --> 00:08:37,760
thinks about anymore you know to kind of like web 2.0 and rest APIs when the like the essentially

78
00:08:37,760 --> 00:08:46,160
the bar for integration and remixing different services got dramatically lower to the point that

79
00:08:46,880 --> 00:08:53,840
I think you know it's almost not a specific thing anymore because it's just such an integrated part

80
00:08:53,840 --> 00:08:59,200
of the way we think about building new applications and services especially given the rise of cloud.

81
00:09:00,560 --> 00:09:09,200
You know I'm I wonder you know what that experience in that context tells you about the way

82
00:09:09,200 --> 00:09:16,160
composition will evolve on the machine learning side. Yeah I mean I think it's a it's a big question

83
00:09:16,160 --> 00:09:19,920
I think a lot of like you know a lot of smart folks are thinking about sort of what that looks like

84
00:09:19,920 --> 00:09:24,240
you know one of the you know I think the question for us is kind of what's the form factor there

85
00:09:24,960 --> 00:09:30,800
you know if you think about sort of composable portable and encapsulated building blocks of

86
00:09:30,800 --> 00:09:36,720
any kind of software architecture you know immediately the question becomes sort of how big are they

87
00:09:36,720 --> 00:09:42,480
you know what is the kind of interface between them you know machine learning has rapidly gone

88
00:09:42,480 --> 00:09:49,920
through a number of phases and you know we've been around you know for I guess six six years now

89
00:09:49,920 --> 00:09:54,800
and sort of seen a number of these kind of rise and fall so the first was this kind of idea

90
00:09:54,800 --> 00:09:59,200
everyone's going to consume machine learning models through APIs because you know that's how web

91
00:09:59,200 --> 00:10:04,480
developers are used to consuming things like you know clear bits for or something like that you know

92
00:10:04,480 --> 00:10:09,120
a lot of companies kind of rose rose on that model companies like clarify doing really interesting

93
00:10:09,120 --> 00:10:14,640
vision work and making that available as APIs then the big cloud providers followed with vision

94
00:10:14,640 --> 00:10:21,200
APIs and the idea was that we would just kind of layer these into applications I you know I I kind

95
00:10:21,200 --> 00:10:24,880
of what even when that was really sort of the model that people were pushing it was clear that

96
00:10:24,880 --> 00:10:29,600
wasn't going to be sufficient because you know folks want to build their own you know variant of

97
00:10:29,600 --> 00:10:34,080
these and the API model is kind of fundamentally limited so what we're you know another way of saying

98
00:10:34,080 --> 00:10:39,120
that is that the kind of the granularity had to get kind of smaller you know there's been a lot

99
00:10:39,120 --> 00:10:43,920
of consternation earlier which was like hey these things are enormously computationally intense to

100
00:10:43,920 --> 00:10:48,480
to actually create like very few companies can create models the size of GPT-3

101
00:10:49,840 --> 00:10:54,320
arguably you know a number you can count on your hand and so this whole notion of kind of

102
00:10:54,320 --> 00:10:58,560
pre-training or refitting models was really sort of the I would say for the last five years kind of

103
00:10:58,560 --> 00:11:03,920
the the standard like no one's going to retrain the kind of the first few layers of of the image net

104
00:11:03,920 --> 00:11:09,440
they're going to you know train the last one and now we're seeing you know I think even a like a

105
00:11:09,440 --> 00:11:15,680
step beyond that which is you know in the case of these kind of creative you know this creative

106
00:11:15,680 --> 00:11:21,520
artistic community using Clip what they're doing is they're using Clip which is a you know a model

107
00:11:21,520 --> 00:11:25,600
that opening I released that they open I did not release sort of the generator architecture

108
00:11:25,600 --> 00:11:30,720
on top of it so the community has has kind of taken that and applied another generator called

109
00:11:30,720 --> 00:11:36,880
DQGAM and so it's not even just taking one model and changing the data set you're working on it's

110
00:11:36,880 --> 00:11:43,600
taking two models and then recomposing them in a really interesting way so yeah so I don't think

111
00:11:43,600 --> 00:11:48,480
we know exactly what the form factor is but you know when you know I'm I run a company that that

112
00:11:48,480 --> 00:11:54,000
builds tools for this so we have to look for precedence and so you know in our case one of the

113
00:11:54,000 --> 00:11:59,200
the main precedence that we've looked at is is looking at other kind of composable code

114
00:11:59,200 --> 00:12:05,600
architectures you know for example in GitHub there's there's this kind of very large ecosystem

115
00:12:05,600 --> 00:12:10,000
of actions which are these kind of composable encapsulated building blocks that you can apply

116
00:12:10,000 --> 00:12:15,840
into your code repo that can do things like you know do code coverage or deploy your code or test it

117
00:12:16,560 --> 00:12:22,000
or you know add additional functionality and so as we've begun to develop more of our products

118
00:12:22,000 --> 00:12:25,840
and sort of you know build products that that respond to this compositional AI

119
00:12:26,800 --> 00:12:32,320
reality you know we're we're very heavily inspired by you know things that have worked well and

120
00:12:32,320 --> 00:12:37,520
arguably you know we have pretty good precedent for how how to compose you know code that comes

121
00:12:37,520 --> 00:12:43,840
from all sorts of you know different places in the world and different you know different sort

122
00:12:43,840 --> 00:12:48,160
of foundational I guess I don't want to say foundational models but different kind of foundational

123
00:12:48,160 --> 00:12:56,640
pieces I think that's that is an interesting I don't know if it's a point as much as a discussion

124
00:12:56,640 --> 00:13:04,960
around what is the right granularity for delivering machine learning you know as you alluded to

125
00:13:04,960 --> 00:13:09,680
is something that we've been talking about for a long time you and I in particular and the community

126
00:13:09,680 --> 00:13:18,720
at large you know more broadly you know to what degree will you know models as a service be the

127
00:13:18,720 --> 00:13:28,400
primary delivery mechanism for you know your typical developer versus you know them needing the

128
00:13:28,400 --> 00:13:36,080
control that will require them to have access to you know notebooks and infrastructure and

129
00:13:36,080 --> 00:13:43,120
the entire and an experience so that they can customize what they're doing and I think this

130
00:13:43,920 --> 00:13:54,080
the idea that the future is not just single models but kind of multiple models with you know

131
00:13:54,080 --> 00:14:00,720
that are trained in either some end-to-end way or fine-tuned in end-to-end way or in a tightly

132
00:14:00,720 --> 00:14:09,040
coupled way does you know at some point the the permutations of models you know that people might

133
00:14:09,040 --> 00:14:18,080
want to kind of remix you know breaks the industry's ability to you know create wrapper services

134
00:14:18,080 --> 00:14:24,640
for different combinations and people just to operate at a lower level it sounds like that's the

135
00:14:24,640 --> 00:14:31,360
you know what you what you're seeing or what you're you know the vision that is driving

136
00:14:32,480 --> 00:14:39,280
your interest in this compositional idea yeah absolutely you know I think there's there's

137
00:14:39,280 --> 00:14:43,520
you've heard a million times from you know companies and software developers in the space talking

138
00:14:43,520 --> 00:14:48,320
about you know end-to-end pipelines you know you explore some data you train a model you deploy it

139
00:14:48,320 --> 00:14:54,160
um I think that that that paradigm has stuck around I think it's a it's a it's a good one for how

140
00:14:54,160 --> 00:14:59,040
you know data scientists and and data engineers can you know work on a product pipeline that

141
00:14:59,040 --> 00:15:04,640
eventually ships into something interesting um I think that the idea of end-to-end is maybe a

142
00:15:04,640 --> 00:15:10,320
little bit um uh it oversimplifies it a bit because it kind of it sounds like it's sort of there's

143
00:15:10,320 --> 00:15:14,320
an input and then an output whereas you know what what I think we're really seeing is more

144
00:15:14,320 --> 00:15:18,960
combinatorial you know like there are many inputs and many outputs and it's you a fan in architecture

145
00:15:18,960 --> 00:15:24,560
fan out architecture um and very you know practically this has informed how we're building tools um

146
00:15:24,560 --> 00:15:29,200
you know our our main our most popular product is a Jupyter notebook based product and for folks

147
00:15:29,200 --> 00:15:33,760
that are you know there's obviously a large conversation around what what is the role of Jupyter

148
00:15:33,760 --> 00:15:38,080
inside of the machine learning you know development process but you know one of the very fundamental

149
00:15:38,080 --> 00:15:42,720
limitations um and I think there are a lot of benefits but one of the fundamental limitations is that

150
00:15:42,720 --> 00:15:48,000
it is really a you know a linear pipeline it starts at the top and it works its way through cells

151
00:15:48,000 --> 00:15:55,200
down to the bottom um and so fundamentally it's not really recomposable in a way that um you know

152
00:15:55,200 --> 00:16:00,400
that that facilitates or makes possible these more interesting applications um you know they're they're

153
00:16:00,400 --> 00:16:05,360
not as they're not as composable or portable so they're harder to share you know like they um

154
00:16:06,080 --> 00:16:10,880
they're hard to death you know they're they're large JSON objects I think they're extremely useful

155
00:16:10,880 --> 00:16:14,960
in some ways but um you know we've seen there's a there's a reason that folks have really been

156
00:16:15,600 --> 00:16:20,800
embracing sort of these pipelining tools that let you do kind of arbitrarily complex input outputs

157
00:16:21,840 --> 00:16:26,000
you know uh and so that's where a lot of our thinking is today um is around sort of what is

158
00:16:26,000 --> 00:16:32,640
that form factor how do you go from maybe exploring something model or data or um you know just

159
00:16:32,640 --> 00:16:39,040
code repo in a notebook and sort of an interactive REPL uh and then you know how does it get into a

160
00:16:39,040 --> 00:16:43,200
quote-unquote production or you know not even production how does it get into a more interesting

161
00:16:43,200 --> 00:16:48,000
kind of state after you've modified it um and so that's really I think informed a lot of

162
00:16:48,000 --> 00:16:54,080
our thinking uh because you know there's there's you know data code clearly is the main input on one

163
00:16:54,080 --> 00:16:58,480
side you want to create an app or a web service on the other side but but you know there's a lot of

164
00:16:58,480 --> 00:17:03,360
other pieces you pull in and we've been drawing you know a lot on ideas like continuous integration

165
00:17:03,360 --> 00:17:09,680
continuous deployment um composability uh you know pipelining uh uh dags and you know there's

166
00:17:09,680 --> 00:17:14,000
memes now about dags and yamls because I think what we're what the industry is seeing is that we

167
00:17:14,000 --> 00:17:20,560
have to uh you know embrace kind of a more flexible system for building out these new kind of

168
00:17:20,560 --> 00:17:27,760
composed machine learning applications now your your comments on notebooks is calling the mind

169
00:17:27,760 --> 00:17:35,520
another kind of data science internet I don't know if it's a meme or a feud or a drama or whatever

170
00:17:36,880 --> 00:17:45,840
but you know maybe just put it as like you know there are different opinions on the role of notebooks

171
00:17:45,840 --> 00:17:53,920
or the appropriateness of notebooks uh probably best characterized by uh Joe Bruce on one side

172
00:17:53,920 --> 00:17:59,440
you know and his I don't like notebooks talk and then Jeremy Howard on the other side you know

173
00:17:59,440 --> 00:18:09,440
with his I like notebooks talk uh and I think that um you know that that contrast is is

174
00:18:10,800 --> 00:18:19,200
there are folks that have taken you know those positions and tried to operationalize them in

175
00:18:19,200 --> 00:18:24,960
different ways so like you know typically the I don't like notebooks camp well they just don't

176
00:18:24,960 --> 00:18:31,520
use notebooks and they use traditional code and traditional code artifacts uh you know repos

177
00:18:31,520 --> 00:18:39,040
and containers and you know productionalize their projects just not using notebooks on the other

178
00:18:39,040 --> 00:18:47,040
side you know there's folks uh like you know Jeremy and fast AI uh but also you know Netflix I think

179
00:18:47,040 --> 00:18:53,680
is kind of famous for this and some companies which spun out of Netflix uh for and I believe

180
00:18:53,680 --> 00:18:59,520
Airbnb was trying to do this uh for a while I don't know the the more recent status of this but

181
00:19:01,280 --> 00:19:09,440
trying to take the notebook and turn it into a production artifact um you know either through

182
00:19:10,560 --> 00:19:15,600
you know some kind of decorators or annotators or things like that that allow you to to specify

183
00:19:15,600 --> 00:19:22,400
within the notebook hey this is the code that needs to be exposed uh or other mechanisms um

184
00:19:24,640 --> 00:19:30,000
it sounds like you you you started it what's interesting I think in this conversation is you started

185
00:19:30,000 --> 00:19:36,880
with a notebook service that was popular uh but then took this you know traditional engineering

186
00:19:36,880 --> 00:19:43,840
code artifact route as opposed to leaning into the notebook um you know tell yeah here's the thinking

187
00:19:43,840 --> 00:19:48,720
there yeah also um you know for folks that are listening that aren't familiar with paper space

188
00:19:48,720 --> 00:19:53,680
you know we originally started more as an infrastructure as a service company focused on GPUs

189
00:19:54,320 --> 00:19:59,040
and so we are we're interesting in that you know we kind of in many ways grew up with this machine

190
00:19:59,040 --> 00:20:03,200
learning developer audience and kind of washed what they were doing so you know the first very

191
00:20:03,200 --> 00:20:07,440
first offering we provided with something called machine learning in a box which was you know

192
00:20:07,440 --> 00:20:11,600
uh basically a virtual machine template with all sorts of dependencies kind of pre-installed that

193
00:20:11,600 --> 00:20:16,480
we spent countless hours you know fine-tuning to make it work um this was before really containerization

194
00:20:16,480 --> 00:20:21,200
and taken off uh we worked very you know early on we worked very closely with Jeremy at fast

195
00:20:21,200 --> 00:20:26,880
AI um you know we've been very fortunate to I think um I don't know the you know where where

196
00:20:26,880 --> 00:20:30,720
it falls you know from all the numbers but we we've trained a lot of folks in the in the fast

197
00:20:30,720 --> 00:20:35,520
AI universe um or onboarded them into machine learning and deep learning more broadly uh through

198
00:20:35,520 --> 00:20:40,960
the notebook product but you know notebooks we we kind of formalized because it was a pattern we

199
00:20:40,960 --> 00:20:44,800
saw everyone doing they would create a virtual machine and then they would install Jupiter uh

200
00:20:44,800 --> 00:20:50,640
and then they would you know run a web service and put a public IP on it um so you know we we

201
00:20:50,640 --> 00:20:57,520
kind of formalized that pattern um and that became gradient notebooks um it's so for us we with that

202
00:20:57,520 --> 00:21:02,880
background we've kind of had two you know we have sort of this beginners using notebooks at the same

203
00:21:02,880 --> 00:21:07,680
time we are running um you know large GPU infrastructure large clusters we've worked with

204
00:21:07,680 --> 00:21:13,600
um a handful of much much larger kind of very advanced uh um practitioners on on doing kind of

205
00:21:13,600 --> 00:21:20,000
production deployments really uh and so for us it was really you know I think it's the question

206
00:21:20,000 --> 00:21:25,280
of how do you bridge those two worlds I think notebooks are um you know really wonderful

207
00:21:25,280 --> 00:21:33,600
for onboarding people into complex code and data concepts um you know I don't know if it's a

208
00:21:33,600 --> 00:21:37,760
forever thing you know I think it's you know when we describe gradient notebooks today we talk

209
00:21:37,760 --> 00:21:43,280
about it more as it's a it's a web based Jupiter notebook and IDE um so you know you can bring

210
00:21:43,280 --> 00:21:48,960
in uh Python code and Yamel code and um you know other kind of supporting bits as well so it looks

211
00:21:48,960 --> 00:21:55,520
more like maybe a VS code than then uh sort of a standalone Jupiter interface um but fundamentally

212
00:21:55,520 --> 00:22:00,720
you know we've been very interested in in how do you go from a notebook into uh you know like a

213
00:22:00,720 --> 00:22:04,400
notebook is like you're kind of building your your idea or conviction around something and how

214
00:22:04,400 --> 00:22:09,680
do you take that and make something more out of it um and so you know that's that's I think the

215
00:22:09,680 --> 00:22:13,920
area that a lot of folks are thinking about um it's interesting you'd mentioned kind of decorators

216
00:22:13,920 --> 00:22:19,920
and patterns that have kind of been introduced for turning a notebook into a you know runnable Python

217
00:22:19,920 --> 00:22:27,360
file there was a you know paper mill um is a the Netflix project that is very very popular um you

218
00:22:27,360 --> 00:22:31,760
know there are other interesting ones like streamlit which are kind of um I don't even know how to

219
00:22:31,760 --> 00:22:37,840
describe them sort of a combination of a of an interactive notebook and a deployed uh process um

220
00:22:38,800 --> 00:22:44,560
and yeah I mean I think that um that's sort of like right now the question is how do you take

221
00:22:44,560 --> 00:22:48,160
this audience I mean in our case very practically we have a lot of folks that are sort of maybe

222
00:22:48,160 --> 00:22:53,280
growing out of Jupiter notebooks and how do we give them sort of a more composable uh past or

223
00:22:53,280 --> 00:22:59,120
or you know easier path into promoting what they're building or maybe even thinking of like larger

224
00:22:59,120 --> 00:23:04,720
possibilities because they can bring in you know easier more shareable composable building blocks um

225
00:23:05,760 --> 00:23:11,760
so yeah I mean I think uh I don't think notebooks are going anywhere um and I and I think they're

226
00:23:12,480 --> 00:23:18,560
enormously useful um but you know I don't think they're exclusively the form factor and so

227
00:23:18,560 --> 00:23:23,760
you know that's why we're all kind of working hard to find sort of uh uh you know the next step here

228
00:23:24,720 --> 00:23:33,200
and you're uh the the direction that you're betting on is you know the the mean

229
00:23:33,200 --> 00:23:40,560
dag yes the very mean to dag um I mean yeah the machine learning memes have gotten pretty pretty

230
00:23:40,560 --> 00:23:47,120
good in the last year um so I don't know where that puts us on the the hype cycle um but uh but

231
00:23:47,120 --> 00:23:52,160
yeah so you know we uh the one that I shared yesterday on twitter which I thought was really

232
00:23:52,160 --> 00:24:01,840
funny was like a movie poster it was like from the creators of untitled.ipymb and untitled parentheses

233
00:24:01,840 --> 00:24:13,680
one.ipymb is untitled parentheses too.ipymb yep yep yep spot on um you know it's uh yeah I mean

234
00:24:13,680 --> 00:24:18,320
well that's actually you know practically Jupiter notebooks are really hard diversion we actually

235
00:24:18,320 --> 00:24:22,400
had an internal tool that we're you know hopefully we'll release one day but um that we call

236
00:24:22,400 --> 00:24:26,880
MBDIF which is our Diffing Tool for notebooks just because we had to do it um and we ended up running

237
00:24:26,880 --> 00:24:32,000
into a lot of kind of weird issues because um they're you know they're just they're not they're not

238
00:24:32,000 --> 00:24:38,880
really okay uh the format is odd people can annotate it you know colab can add different metadata

239
00:24:38,880 --> 00:24:44,320
annotations the spec changes a bit um you know we can add annotations and it's just it's it's like

240
00:24:44,320 --> 00:24:48,800
hard to diff and and sort of there's different inputs and outputs there you know Jupiter widgets

241
00:24:48,800 --> 00:24:53,440
which are sort of these uh special collaborations between server and client side they're just they're

242
00:24:53,440 --> 00:24:59,120
really weird um for if you from a traditional code perspective um so you know I think we have to

243
00:24:59,120 --> 00:25:04,480
move towards a direction that looks more like um more you know more like traditional software

244
00:25:04,480 --> 00:25:09,440
engineering and that was my you know big pitch a year ago I yeah stand by it we have you know we

245
00:25:09,440 --> 00:25:15,520
we believe really strongly that um Jupiter has a place uh for sure but but you know to to kind of

246
00:25:15,520 --> 00:25:21,680
move the next step we have to um start thinking of you know drawing from known best practices and in

247
00:25:21,680 --> 00:25:28,240
the uh you know uh kind of software engineering world and and one of those is you know uh I wouldn't

248
00:25:28,240 --> 00:25:34,560
even call them DAGs necessarily I mean they certainly you know uh directed aciculate graphs uh but but um

249
00:25:34,560 --> 00:25:40,400
yeah I mean you need to start you know introducing kind of pipelining uh syntax and semantics and

250
00:25:40,400 --> 00:25:45,600
and kind of those primitives you know for us um where uh we're actually just about to my time

251
00:25:45,600 --> 00:25:51,200
this airs we will have rolled out um workflows which is really like our most ambitious project and

252
00:25:51,200 --> 00:25:56,800
also um kind of our most comprehensive which is uh really an automation um and build system for

253
00:25:56,800 --> 00:26:01,520
machine learning applications that allows you to um you know really tightly couple it to source

254
00:26:01,520 --> 00:26:06,160
control so you know to your point on uh kind of untitled one and two um you know that's not

255
00:26:06,160 --> 00:26:13,680
sustainable um uh but you know sort of add a a few lines of code into a repo um uh and begin to

256
00:26:13,680 --> 00:26:18,240
turn that into a kind of a composable building block that could be consumed by other people um and

257
00:26:18,240 --> 00:26:23,440
you know like I mentioned earlier this is heavily inspired by GitHub actions um and and tools like

258
00:26:23,440 --> 00:26:29,680
that um and sort of blended with uh you know kind of the data pipelining tools such as um you know

259
00:26:29,680 --> 00:26:36,560
airflow or you know we're using Argo uh which is kind of a containerized Kubernetes um uh system

260
00:26:36,560 --> 00:26:40,800
but yeah I mean I think this is where it has to go um so you know I don't think we're leaving

261
00:26:40,800 --> 00:26:45,760
notebooks behind but we you know they're insufficient to take us to I think where we want to go

262
00:26:45,760 --> 00:26:59,360
as an industry um so your your infrastructure um use Kubernetes under the covers uh in a lot of

263
00:26:59,360 --> 00:27:05,840
places correct me if I'm wrong but I believe that yeah we're a big Kubernetes yeah uh and you're

264
00:27:05,840 --> 00:27:16,480
you know you selected Argo as the workflow engine which cube flow does one that just like create

265
00:27:16,480 --> 00:27:22,240
cube flow as a service other folks have have gone that route uh why kind of build it from scratch

266
00:27:22,960 --> 00:27:29,920
yeah that's a great question I mean I think um cube flow uh amazing uh project in lots of ways

267
00:27:29,920 --> 00:27:36,240
I think um it's uh this is my opinion in my opinion alone I think it kind of struggles to

268
00:27:36,240 --> 00:27:43,120
to to uh to match sort of the um the audience where it is today um I think it's it's hard to set up

269
00:27:43,120 --> 00:27:51,360
I think um you know the building out sort of the um the the cube flow actions effectively I think

270
00:27:51,360 --> 00:27:55,680
is um still a bit difficult so it requires just more software engineering work so very large

271
00:27:55,680 --> 00:28:01,120
companies um you know I don't spotify uh can can use um cube flow because they can invest in that

272
00:28:01,120 --> 00:28:08,320
ecosystem I think um you know there it's it's not a pattern that um will be as extensible for

273
00:28:08,320 --> 00:28:13,840
the kind of wide adoption that I foresee um and so you know what we've done with workflows which

274
00:28:13,840 --> 00:28:20,480
is our uh kind of newest addition to gradient um is it's kind of take the best of of cube flow

275
00:28:20,480 --> 00:28:27,520
and Argo which is you know containerization um you know sort of uh the ability to create these

276
00:28:27,520 --> 00:28:32,560
you know complex tags with triggers and and sort of the fundamental pieces but expose it in a way

277
00:28:32,560 --> 00:28:37,840
that is much more uh kind of akin to folks that are building you know for example we took a lot

278
00:28:37,840 --> 00:28:42,480
of inspiration from tools like Netlify and Versal which are these web tools that basically let you

279
00:28:42,480 --> 00:28:47,920
come in attach a repo uh to to their service and then it you know basically creates a build system

280
00:28:47,920 --> 00:28:52,400
and gives you a website at the end um with just clicking a few buttons um and I think that's

281
00:28:52,400 --> 00:28:56,800
the form factor we need um and today you know workflows when you when you onboard you basically

282
00:28:56,800 --> 00:29:02,160
it's it's a very similar process give me a repo or pick one of a sample repo um it's going to

283
00:29:02,160 --> 00:29:07,920
give a little bit of code in in a workflow dot yaml file um although that's kind of abstracted

284
00:29:07,920 --> 00:29:12,800
away um and and I think we're gonna move quickly to a point where the yaml is really an implementation

285
00:29:12,800 --> 00:29:18,320
detail uh and folks will be you know I don't know if it's a full low code no code because I don't

286
00:29:18,320 --> 00:29:23,920
know how quickly we get there um but um you know the composability is where we want to focus our

287
00:29:23,920 --> 00:29:29,600
energy um and so you know I think Duplo it has solved a lot of interesting problems and and you

288
00:29:29,600 --> 00:29:33,040
know they're a handful of other folks in the data kind of the data flow space that have worked on

289
00:29:33,040 --> 00:29:39,840
this as well folks coming from the the Jupiter world so there's like uh these tool like plumber

290
00:29:39,840 --> 00:29:43,120
is a really interesting one that I've been looking at recently there's one called kale for Kubernetes

291
00:29:43,120 --> 00:29:48,160
which lets you sort of build out building blocks um um from a notebook and make them deployable

292
00:29:48,160 --> 00:29:51,680
um but we're coming out of any other direction which is like what are what's the you know

293
00:29:51,680 --> 00:29:55,920
what tools are common in the software engineers tool belt and how do we make this machine learning

294
00:29:55,920 --> 00:30:01,040
thing look a lot more like that so for us the inspiration is um it's not starting at Jupiter notebooks

295
00:30:01,040 --> 00:30:07,520
it's starting at um you know uh Jenkins, CircleCI, Versal, Netlify, GitHub actions things that are

296
00:30:07,520 --> 00:30:13,680
like kind of like known known paradigms and known tool stacks or types of tools in uh you know

297
00:30:13,680 --> 00:30:18,240
for folks that are building production applications. Yeah one of the things that I think is

298
00:30:20,000 --> 00:30:28,080
compelling from a user and a face user experience kind of perspective about um you know paper mill

299
00:30:28,080 --> 00:30:38,000
ask type of types of approaches is the idea that they start with the notebook and you know you

300
00:30:38,000 --> 00:30:45,200
because the notebooks is an interesting and useful place for kind of the throwing stuff against

301
00:30:45,200 --> 00:30:52,320
the wall and seeing what sticks and like starting to you know shape it and um you know just kind of

302
00:30:52,320 --> 00:30:59,840
bootstrapping your thinking about the way to attack a problem uh and then you know the traditional

303
00:30:59,840 --> 00:31:05,840
approaches okay you do that you kind of bang stuff into shape and then you like pull it out into

304
00:31:05,840 --> 00:31:11,920
a python module into a text file um but the you know these other approaches allow you to like

305
00:31:13,120 --> 00:31:17,680
it's it's even easier in a sense and if you've already got that infrastructure in place you just

306
00:31:17,680 --> 00:31:25,680
kind of add your decorator or whatever and you know there's your your artifact um I think the

307
00:31:25,680 --> 00:31:31,200
question I'm trying to get to is like you know do you see a bridge between the worlds and what

308
00:31:31,200 --> 00:31:37,120
you've built with workflows where you know you're starting in this you're you're I don't think

309
00:31:37,120 --> 00:31:45,520
you're suggesting folks to not use notebooks to you know get started or to to experiment because

310
00:31:45,520 --> 00:31:53,520
they're useful for that is there a bridge from that to a dag based you know traditional system

311
00:31:53,520 --> 00:31:58,000
other than okay you know rip your stuff out of the notebook and put it into a code module and

312
00:31:58,000 --> 00:32:06,240
take it in to get up yeah uh that's a good one um I I don't know I mean I think that um that

313
00:32:06,240 --> 00:32:10,880
we're we're internally doing a lot of work on on thinking about that form factor like can you

314
00:32:10,880 --> 00:32:16,720
you know turn a cell into an action in our in our pipeline um can you sort of send one over um

315
00:32:18,320 --> 00:32:22,960
the I think that the form factor that we need to get to more quickly and this is actually where

316
00:32:22,960 --> 00:32:29,520
we sent more of our more more of our energy with workflows is um kind of closer what I would call

317
00:32:29,520 --> 00:32:35,840
maybe build packs or sample apps so for example you know I think what versatile and for folks not

318
00:32:35,840 --> 00:32:43,200
familiar it's a it's a web hosting tool for building or a tool for building web applications

319
00:32:43,200 --> 00:32:50,640
very easily and it relies a lot on you know things like for example create react app which is sort

320
00:32:50,640 --> 00:32:54,480
of a starter template that if you're making a website it's a really good place to kind of fork

321
00:32:54,480 --> 00:32:59,920
that one and start somewhere and so I think that you know the pattern we have for notebooks today is

322
00:32:59,920 --> 00:33:05,760
people fork a notebook and build something out um you know clip and vqgan and then they run through

323
00:33:05,760 --> 00:33:13,120
it and they get some images um I guess you know that form factor is is hard to you know directly turn

324
00:33:13,120 --> 00:33:19,440
into something like a create react app or a um uh you know I don't know a starter template of

325
00:33:19,440 --> 00:33:25,120
sorts but I do think is it the nature of notebooks that makes it hard yeah I mean it's it's largely

326
00:33:25,120 --> 00:33:30,880
because the the you know the the large benefit of a notebook is that you get this interactive

327
00:33:30,880 --> 00:33:35,600
repel environment you know you type code you get a response very quickly um but that same you know

328
00:33:35,600 --> 00:33:40,480
the the the fact that it is sort of embedding its outputs and its inputs um cells are not really

329
00:33:40,480 --> 00:33:46,320
ordered um you know they don't have any reference to the dependencies or the or the metadata um

330
00:33:46,320 --> 00:33:50,960
that's required to run the thing it's hard because it's a notebook it's hard because it's a notebook

331
00:33:50,960 --> 00:33:55,840
and so you know what I think well you know one of the things that we're bringing over more into workflows

332
00:33:55,840 --> 00:34:02,640
is the kind of interactive repel you know idea um like for example in circle CI which is our build

333
00:34:02,640 --> 00:34:08,320
tool that we really like um for our web application um you know you can SSH into an instance which is

334
00:34:08,320 --> 00:34:12,560
the equivalent of kind of creating a repel you kind of go in and you can start interacting with the

335
00:34:12,560 --> 00:34:18,080
real thing um it's just you're doing it at a at a you know a higher like a different level of

336
00:34:18,080 --> 00:34:22,800
granularity um you know a notebook is really like tightly connected to a single kernel and you're

337
00:34:22,800 --> 00:34:28,880
kind of you know going through um I think you know I I don't think they're going anywhere I think

338
00:34:28,880 --> 00:34:35,120
they're extremely important components um I think that their importance will be will know more um

339
00:34:35,120 --> 00:34:38,720
I think in a few you know maybe even in the next year when we start seeing sort of how the

340
00:34:38,720 --> 00:34:43,440
the next set of killer applications um you know come to fruition and my guess is it's going to look

341
00:34:43,440 --> 00:34:48,080
more like starter templates like create react app that you're forking um you know more like build

342
00:34:48,080 --> 00:34:53,040
systems and build packs um where you're kind of focusing your energy on picking different you

343
00:34:53,040 --> 00:34:58,320
know um instead of dolly you're picking vqgant um or instead the first order motion model you're

344
00:34:58,320 --> 00:35:04,400
picking uh you know uh the the new enhanced one that that snapchat just came out with um so

345
00:35:04,400 --> 00:35:09,280
so yeah I think that that's it's a big open question um but the good thing is we don't have to

346
00:35:09,280 --> 00:35:14,560
invent it from scratch we can follow um you know a good precedent and I think we should draw that

347
00:35:14,560 --> 00:35:18,160
and this goes back to the sort of the last conversation I think we should draw primarily from

348
00:35:18,160 --> 00:35:22,720
the software engineering world because a lot of this has been resolved over the last say 25 years

349
00:35:22,720 --> 00:35:29,120
or whatever um on how you how do you build scalable you know large production uh applications

350
00:35:30,320 --> 00:35:34,880
one of the things still in that I've heard you say and in this conversation and we we've talked

351
00:35:34,880 --> 00:35:44,240
previously is that this project is you know one of your or your the paper spaces most ambitious

352
00:35:44,240 --> 00:35:52,720
undertaking and um you know I'm curious what why that is like what makes it ambitious it sounds

353
00:35:52,720 --> 00:35:58,560
like you took Argo and like build a web app around it like you know you can make it you can you

354
00:35:58,560 --> 00:36:05,040
can reduce it or simplify it to sounding very simple you know yep what where's the complexity

355
00:36:05,040 --> 00:36:14,080
and the effort yeah uh great question I mean I um you know what I think for us it's we know that

356
00:36:14,080 --> 00:36:20,480
there are certain really well-known best practices so notebooks today whether we think they're

357
00:36:20,480 --> 00:36:25,360
going to exist for 10 years or not they're they're really practical useful um components in the

358
00:36:25,360 --> 00:36:31,440
machine learning you know developers tool belt um deployments on the other end which we also

359
00:36:31,440 --> 00:36:37,120
a deployment service that were were by time this rolls out there will be sort of our next iteration

360
00:36:37,120 --> 00:36:42,160
of that that has been released um but deployments are also relatively well understood at least from a

361
00:36:42,160 --> 00:36:47,680
web perspective I mean we can go into you know edge deployments and quantizing and pruning models

362
00:36:47,680 --> 00:36:52,400
and sort of the you know the complexity there but I think it's there there are less open questions

363
00:36:52,400 --> 00:37:00,240
um really uh you know it's the question about the glue or the fabric that takes these kind of early

364
00:37:00,240 --> 00:37:08,160
you know exploratory prototyping tools and lets them kind of transition into the you know

365
00:37:08,160 --> 00:37:13,280
the the production world you know think that every software company in the MLO space is talking

366
00:37:13,280 --> 00:37:19,440
about end-to-end you know training to deployment R&D to production um and I think that you know

367
00:37:19,440 --> 00:37:23,920
so that that inner fabric I think is really important um and there's no shortage of

368
00:37:23,920 --> 00:37:31,120
DAG based data flow data um you know data tools um and so for us it was very much pick you know

369
00:37:31,120 --> 00:37:35,280
have some principles on what we're picking as the foundational piece you know containerization

370
00:37:35,280 --> 00:37:39,600
we think is it's you know we're making bets we're making bets on technology stacks you know we

371
00:37:40,160 --> 00:37:45,280
invested very heavily into Kubernetes um and you know Kubernetes is an amazing technology has

372
00:37:45,280 --> 00:37:50,080
actually I think been more complicated than some people thought um but I think is a you know

373
00:37:50,080 --> 00:37:55,680
it's a big it's a big bet for us is that that type of container orchestration layer um is one

374
00:37:55,680 --> 00:38:00,160
that we you know shouldn't try to solve differently for machine learning than we should other other

375
00:38:00,160 --> 00:38:06,400
areas um the form factor though for how you compose them is very different um because the

376
00:38:06,400 --> 00:38:12,160
reality is the audience is different you know the folks that are that are I would say um

377
00:38:12,160 --> 00:38:18,720
um that should be using machine learning in their day-to-day work if all things were created equal

378
00:38:18,720 --> 00:38:24,640
and it were very easy to do is massive it includes uh marketing people and statisticians and

379
00:38:24,640 --> 00:38:30,800
folks in the humanities and artists and um you know in addition to software engineers and

380
00:38:30,800 --> 00:38:36,880
BI people and you know analysts and it really is and medical practice you know uh practitioners

381
00:38:36,880 --> 00:38:41,760
so it's pretty it's pretty expansive and so what that means is there's there I don't think there is a

382
00:38:41,760 --> 00:38:47,680
single form factor for everyone um you know I can see a world where uh there it you know

383
00:38:48,720 --> 00:38:54,960
there are zapier like you know connections for um machine learning models to endpoints and there

384
00:38:54,960 --> 00:39:00,960
are APIs that are consumable um just like there are today for web services but I think the question

385
00:39:00,960 --> 00:39:05,600
that you know when we think about it you know our audience is every software developer in the world

386
00:39:05,600 --> 00:39:11,200
building uh you know software applications and delivering those we believe that they are going to

387
00:39:11,200 --> 00:39:17,280
use machine learning as just a part of their toolbell a part of their stack um so you know we have

388
00:39:17,280 --> 00:39:24,080
some guidance on how to how you know workflow should be designed um but it's it's a uh you know it

389
00:39:24,080 --> 00:39:30,800
is not there there's no very obvious precedent for exactly how this should be done um and I think

390
00:39:30,800 --> 00:39:35,920
that when you take on a very large projects like this um getting the form factor wrong especially

391
00:39:35,920 --> 00:39:43,440
for you know uh a software company um can be can be really dangerous um so you know we can get

392
00:39:43,440 --> 00:39:47,440
into sort of how product and development and management is done but I you know it it really is

393
00:39:47,440 --> 00:39:52,400
always I think even at all good companies um some percentage of like seeing where the world is

394
00:39:52,400 --> 00:39:57,360
today uh what are people building you know what are their problems and challenges uh and then the

395
00:39:57,360 --> 00:40:02,160
other 50% is you know what are going to be the challenges a year from now and given how quickly

396
00:40:02,160 --> 00:40:06,880
the space is moving and how many things that I think are just really amazing and unpredictable um

397
00:40:06,880 --> 00:40:14,480
you know it's uh it's it's I think you know ambitious to to try to give a a version of a future

398
00:40:14,480 --> 00:40:26,560
that is um uh you know so so up in the air right now um yeah I think uh uh you reference this idea form

399
00:40:26,560 --> 00:40:31,920
factor you know multiple times throughout this conversation and and you know what you're saying

400
00:40:31,920 --> 00:40:38,560
clearly is that it's not the it's not necessarily the like the engineering challenge of

401
00:40:38,560 --> 00:40:45,520
hooking up a workflow you know engine to uh deployment system to this it's it's all of that

402
00:40:46,160 --> 00:40:51,120
you know there are there is existing software out there that you're taking advantage of you

403
00:40:51,120 --> 00:40:56,000
know not that that's easy right when you have a large distributed system it's always hard but it's

404
00:40:56,640 --> 00:41:03,360
sounds like what you're saying is that the you know the challenge was more getting the user

405
00:41:03,360 --> 00:41:10,720
experience right uh in all that you know compared to you know your previous undertaking which was

406
00:41:11,440 --> 00:41:16,000
there's this well-known user experience a notebook how do we make it so that you know how do

407
00:41:16,000 --> 00:41:21,440
we make it easier to deploy that yeah there's a lot more risk in trying to figure out you know as you

408
00:41:21,440 --> 00:41:27,200
say kind of look into the future in terms of what people will need to you know more easily kind of

409
00:41:27,200 --> 00:41:36,240
compose machine learning uh an AI systems and then build a system that uses just these infrastructure

410
00:41:36,240 --> 00:41:41,520
primitives to make that easier to do yeah absolutely I think that is the challenge I don't think

411
00:41:41,520 --> 00:41:47,280
it's ours alone but I think you know what we're coming at it with is uh I think a you know a somewhat

412
00:41:47,280 --> 00:41:53,520
unique perspective which is that we you know we have a um more of an infrastructure you know deep GPU

413
00:41:53,520 --> 00:41:58,720
and accelerator focused than probably most companies in this space at the same time you know we have

414
00:41:58,720 --> 00:42:04,240
created tool that is used by uh you know probably more folks in this space than almost any other tool

415
00:42:04,240 --> 00:42:09,120
for kind of learning this for the first time and so we have these you know this kind of split

416
00:42:09,120 --> 00:42:13,920
audience of like beginners and advanced people and and I think that that gives us an interesting

417
00:42:13,920 --> 00:42:19,840
perspective on how to how to bridge those but certainly it's not resolved and you know I can see

418
00:42:19,840 --> 00:42:24,000
a scenario where you come back in a year and we say yeah so you know actually you know we the

419
00:42:24,000 --> 00:42:28,720
YAML stuff was too hard to do and the audience didn't need it we you know we really had to make

420
00:42:28,720 --> 00:42:34,720
this say uh you know a wizzy wig a gooey build or something like that or you know more of a safe

421
00:42:34,720 --> 00:42:41,280
year or you know notebooks actually um you know are no longer as useful when people can can clone

422
00:42:41,280 --> 00:42:46,080
starter apps that do basically what they want to do anyway um including the deployment and the

423
00:42:46,080 --> 00:42:52,880
training and the you know inferencing logic um so yeah I think we'll see I mean I think look uh

424
00:42:52,880 --> 00:42:57,440
we're we're in a really exciting time I mean for software developers in particular uh you know

425
00:42:58,080 --> 00:43:03,680
I just listened to the Greg Brockman version of your podcast which I really liked talking about

426
00:43:03,680 --> 00:43:11,280
codex and copilot you know these tools are being used today um in in the real world by you know

427
00:43:11,280 --> 00:43:16,640
like machine learning and assisted technologies are real and they're being used by programmers by

428
00:43:16,640 --> 00:43:22,960
physicians by um you know a lot of folks and so you know it's some level I think it's inevitable

429
00:43:22,960 --> 00:43:28,560
that this technology breaks out of the lab or whatever the analogy is um but um you know I think

430
00:43:28,560 --> 00:43:32,080
there's a race to figure out the form factor and I think the opportunity is massive because I think

431
00:43:32,080 --> 00:43:37,680
we're gonna see you know just like today totally unexpected applications um that are really

432
00:43:37,680 --> 00:43:42,160
inspiring you know I think it's it's amazing that we've been in the space you know uh for it's

433
00:43:42,160 --> 00:43:48,560
relatively um short life life cycle um and just I continue to be amazed at what is being created

434
00:43:48,560 --> 00:43:54,560
and um you know what's possible um and you know we could we could have a whole other our conversation

435
00:43:54,560 --> 00:43:59,600
about you know transformers and uh you know sort of what what what that what that has done for the

436
00:43:59,600 --> 00:44:07,360
space but um and we probably should but uh you you brought up the the interview with Greg and and

437
00:44:07,360 --> 00:44:14,080
codex and um you you talked abstractly about that stuff being used but from our conversations

438
00:44:14,080 --> 00:44:18,560
I know it's not necessarily just abstract for you you actually used it and there's some

439
00:44:18,560 --> 00:44:25,040
codex generated code in in paper base yeah yeah we'll have to uh I mean it's uh still you know

440
00:44:25,040 --> 00:44:29,920
we we were when it first came out we were kind of playing around and you know giving some comments

441
00:44:29,920 --> 00:44:35,360
like generate a function that uh you know does this simple task uh creates an array of of interesting

442
00:44:35,360 --> 00:44:42,320
names or whatever uh for sample projects um and we actually do have a piece today which is um

443
00:44:42,320 --> 00:44:48,080
totally AI generated that is in our production application um it's small it's you know

444
00:44:48,080 --> 00:44:55,680
founded but it opens up the question you know if one whatever 0.001% of our code base is AI generated

445
00:44:55,680 --> 00:45:01,440
generated today um you know I'm curious what percentage that is a year from now or the next time

446
00:45:01,440 --> 00:45:08,720
we talk my guess is it's going to be more um and so uh you know that's an exciting future for sure

447
00:45:08,720 --> 00:45:13,280
like this this stuff is not we're not talking abstractly about the power of machine learning to

448
00:45:13,280 --> 00:45:18,800
change your day-to-day it's actually doing it um you know that's this is also a very complicated

449
00:45:18,800 --> 00:45:23,280
topic I don't think engineer you know software engineers are going to be out of jobs but um you

450
00:45:23,280 --> 00:45:28,880
know I think this this kind of radical AI assisted future uh is really exciting whether you're an

451
00:45:28,880 --> 00:45:34,800
artist a programmer um you know a media producer uh whatever it is like I think that um that's why

452
00:45:34,800 --> 00:45:39,680
this space is so exciting and that's why I think you know um we we care so much about trying to

453
00:45:39,680 --> 00:45:46,160
find the right form factor UX sort of the the the way that we can assist in um you know helping

454
00:45:46,160 --> 00:45:50,560
build more amazing applications like you know kind of breaking out of the the kind of meme culture

455
00:45:50,560 --> 00:45:54,320
and getting into like what what what are you know what are builders building kind of thing

456
00:45:55,760 --> 00:46:03,200
awesome awesome well Dylan always a pleasure to catch up with you thanks so much for the update

457
00:46:03,200 --> 00:46:11,920
and uh looking forward to next time awesome thanks soon take care thank you

