1
00:00:00,000 --> 00:00:13,400
Welcome to the Twomo AI Podcast.

2
00:00:13,400 --> 00:00:18,240
I'm your host Sam Charrington.

3
00:00:18,240 --> 00:00:25,560
Hey, what's up everyone, a few quick updates from Twomo HQ.

4
00:00:25,560 --> 00:00:29,880
As some of you may have noticed, we recently relaunched the Twomo newsletter.

5
00:00:29,880 --> 00:00:32,520
If you've already signed up, awesome.

6
00:00:32,520 --> 00:00:37,440
If not, well, you're missing out on weekly podcast updates, recommendations from the team,

7
00:00:37,440 --> 00:00:38,720
and much more.

8
00:00:38,720 --> 00:00:45,040
Head over to twomoAI.com slash newsletter to get signed up.

9
00:00:45,040 --> 00:00:50,200
After you check out today's podcast, I encourage you to check out our latest demo casts.

10
00:00:50,200 --> 00:00:54,440
This time around, I was joined by Vila Toulos, who you might remember from our conversation

11
00:00:54,440 --> 00:01:00,440
late last year about Netflix's recently open source library, Metaflow, for building

12
00:01:00,440 --> 00:01:03,880
and managing real-life data science projects.

13
00:01:03,880 --> 00:01:08,040
Based on the data we've seen with our previous couple of demo casts, we've decided to no

14
00:01:08,040 --> 00:01:13,240
longer publish the audio-only versions of those here in the main podcast feed.

15
00:01:13,240 --> 00:01:18,960
So you'll need to jump over to twomoAI.com slash Metaflow to check it out.

16
00:01:18,960 --> 00:01:25,120
And now on to the show.

17
00:01:25,120 --> 00:01:26,120
All right, everyone.

18
00:01:26,120 --> 00:01:28,200
I am on the line with David Adybo.

19
00:01:28,200 --> 00:01:35,640
David is co-founder and CTO of Analytical AI, as well as a Kaggle Grandmaster.

20
00:01:35,640 --> 00:01:38,000
David, welcome to the TwomoAI podcast.

21
00:01:38,000 --> 00:01:39,480
Yeah, thank you, Sam.

22
00:01:39,480 --> 00:01:41,040
Happy to be here.

23
00:01:41,040 --> 00:01:42,040
You know what?

24
00:01:42,040 --> 00:01:43,280
I am really looking forward to this chat.

25
00:01:43,280 --> 00:01:48,080
I think this is the first time I've had a sibling on the show.

26
00:01:48,080 --> 00:01:54,680
I interviewed your brother, Steven Adybo, back in July of last year, where we were talking

27
00:01:54,680 --> 00:01:56,640
about retinal image generation.

28
00:01:56,640 --> 00:02:02,040
And he was up on Twitter recently, talking you up and your conquests on Kaggle.

29
00:02:02,040 --> 00:02:04,840
And I thought, man, I've got to get this conversation as well.

30
00:02:04,840 --> 00:02:09,920
So congratulations for being the first sibling, at least to my knowledge on the podcast.

31
00:02:09,920 --> 00:02:13,160
Yeah, thank you.

32
00:02:13,160 --> 00:02:17,320
Why don't we start out by having you share a little bit about your background.

33
00:02:17,320 --> 00:02:20,800
How did you come to work on machine learning?

34
00:02:20,800 --> 00:02:24,680
When I started my PhD, I was interested in machine learning.

35
00:02:24,680 --> 00:02:29,600
I wasn't quite sure where to go back then, so there was a lot of literature review, a

36
00:02:29,600 --> 00:02:32,160
lot of just digging around.

37
00:02:32,160 --> 00:02:37,480
And back then, you know, I read a lot of papers, I kind of tried to get a sense of where

38
00:02:37,480 --> 00:02:40,680
to go to get useful information.

39
00:02:40,680 --> 00:02:45,800
And Kaggle kept creeping up and coming up in various things I read.

40
00:02:45,800 --> 00:02:51,680
And so I finally joined Kaggle, and it kind of put, it gave me an opportunity to put

41
00:02:51,680 --> 00:02:56,440
some of that theoretical background into practice.

42
00:02:56,440 --> 00:02:59,960
And a lot of things made a lot more sense when you actually practice.

43
00:02:59,960 --> 00:03:02,560
So what were you studying for your PhD?

44
00:03:02,560 --> 00:03:09,520
I was looking to investigate deep learning and medical imaging and how the advances in

45
00:03:09,520 --> 00:03:13,000
deep learning at the time could be applied to various medical imaging problems.

46
00:03:13,000 --> 00:03:16,280
And that sounds like an interest that runs in the family.

47
00:03:16,280 --> 00:03:21,000
Yeah, it does.

48
00:03:21,000 --> 00:03:25,080
You know, besides from any kind of genetic contribution, what sparked your interest in

49
00:03:25,080 --> 00:03:26,600
that?

50
00:03:26,600 --> 00:03:31,120
I wanted, actually, the first neural network I ever, I wanted to see if I could build

51
00:03:31,120 --> 00:03:34,280
something to recognize a face in an image.

52
00:03:34,280 --> 00:03:40,520
And this was actually before I started my, I selected my thesis topic.

53
00:03:40,520 --> 00:03:45,400
And so that was really how I got it really interested in machine learning because it

54
00:03:45,400 --> 00:03:48,440
was something I was kind of blindly doing.

55
00:03:48,440 --> 00:03:53,440
And you know, as you're digging around, I wrote my first neural network in C sharp, which

56
00:03:53,440 --> 00:03:55,760
was it worked horribly.

57
00:03:55,760 --> 00:03:58,760
And this was in 2012.

58
00:03:58,760 --> 00:04:04,400
And you know, that kind of made me realize that you read about how neural networks should

59
00:04:04,400 --> 00:04:06,000
work and all these things.

60
00:04:06,000 --> 00:04:11,400
But you never really, I never really knew at the time what, what the appropriate frameworks

61
00:04:11,400 --> 00:04:16,960
to use and, and, and how you go about it, basically.

62
00:04:16,960 --> 00:04:17,960
So.

63
00:04:17,960 --> 00:04:21,320
And so what, why C sharp, were you a Microsoft developer?

64
00:04:21,320 --> 00:04:26,960
Yeah, I was a, I was a Microsoft enterprise developer, I had done all the Microsoft

65
00:04:26,960 --> 00:04:27,960
specifications and stuff.

66
00:04:27,960 --> 00:04:29,720
So I was pretty good at C sharp at the time.

67
00:04:29,720 --> 00:04:32,920
So I said, let me, let me try to do this as C sharp.

68
00:04:32,920 --> 00:04:37,160
And it was just the absolute wrong idea and wrong approach to use at the time.

69
00:04:37,160 --> 00:04:44,400
But, you know, if you, if you have a hammer, you know, you tried to, so if I'm putting

70
00:04:44,400 --> 00:04:50,960
the pieces together correctly, you were the Microsoft enterprise developer before you went

71
00:04:50,960 --> 00:04:54,760
back for your PhD, what prompted you to go back for your PhD?

72
00:04:54,760 --> 00:04:58,840
Well, it's something I always wanted to do, you know, after I got my master's, I worked

73
00:04:58,840 --> 00:05:05,120
in industry a little bit and I always knew I, I needed to kind of pivot back and, and

74
00:05:05,120 --> 00:05:06,320
complete the PhD.

75
00:05:06,320 --> 00:05:11,600
So that was kind of, it was something that was in the plans before I, but I wanted to,

76
00:05:11,600 --> 00:05:14,960
after being in school for so long, you want to work and gain some experience.

77
00:05:14,960 --> 00:05:15,960
So.

78
00:05:15,960 --> 00:05:16,960
Yeah.

79
00:05:16,960 --> 00:05:17,960
Nice.

80
00:05:17,960 --> 00:05:24,240
And so you started working on neural networks in C sharp and kind of, you know, banged

81
00:05:24,240 --> 00:05:27,480
away with that hammer that you, you had.

82
00:05:27,480 --> 00:05:30,840
And it was, it was the absolute wrong, wrong thing to do.

83
00:05:30,840 --> 00:05:34,280
I just need nowhere to go or to start back then.

84
00:05:34,280 --> 00:05:40,120
You kind of were pursuing, you know, this formal, you know, research and education with

85
00:05:40,120 --> 00:05:48,920
the PhD, but then you realized that there was kind of a practical compliment to that in

86
00:05:48,920 --> 00:05:49,920
Kaggle.

87
00:05:49,920 --> 00:05:50,920
Yeah.

88
00:05:50,920 --> 00:05:56,900
Um, how did you start with, you know, once you, you know, created an account and joined

89
00:05:56,900 --> 00:06:02,880
Kaggle, quote unquote, like how did you actually start did you just jump in and do a competition?

90
00:06:02,880 --> 00:06:09,520
So I actually created my account for the first time in, I think it was 2014 or 2015.

91
00:06:09,520 --> 00:06:14,640
And I didn't actually, I looked around, I read the, I didn't actually start competing

92
00:06:14,640 --> 00:06:15,920
until a year later.

93
00:06:15,920 --> 00:06:16,920
Okay.

94
00:06:16,920 --> 00:06:25,120
So I first joined and then I, I just spoke around and then later on, I kept working

95
00:06:25,120 --> 00:06:27,840
on my stuff and I got better at it.

96
00:06:27,840 --> 00:06:31,200
I kind of identified the right frameworks to use.

97
00:06:31,200 --> 00:06:33,880
I got a little bit more comfortable.

98
00:06:33,880 --> 00:06:40,440
And then I think I did my first competition in, in 2016.

99
00:06:40,440 --> 00:06:46,440
And, and that was, I think the data science bowl at the time that one was for trying to

100
00:06:46,440 --> 00:06:57,640
detect the volume of, of, of ejection in, in heart, um, cardio grams or, so that was

101
00:06:57,640 --> 00:06:59,240
my first competition.

102
00:06:59,240 --> 00:07:00,240
Okay.

103
00:07:00,240 --> 00:07:04,600
And that competition, I did okay, you know, but I didn't do really well, but it was good

104
00:07:04,600 --> 00:07:06,640
experience to kind of get my feet wet.

105
00:07:06,640 --> 00:07:07,640
Mm-hmm.

106
00:07:07,640 --> 00:07:08,640
Yeah.

107
00:07:08,640 --> 00:07:12,240
And were you, we had you partnered up with folks for that one or were you working independently?

108
00:07:12,240 --> 00:07:13,240
Yeah.

109
00:07:13,240 --> 00:07:21,280
We have a guy that we're, Jason Zeng, we're both in the same program and we're both doing

110
00:07:21,280 --> 00:07:23,040
kind of deep learning and medically mentioned.

111
00:07:23,040 --> 00:07:25,520
So we both went into that competition together.

112
00:07:25,520 --> 00:07:26,520
Okay.

113
00:07:26,520 --> 00:07:27,520
Yeah.

114
00:07:27,520 --> 00:07:28,520
Cool.

115
00:07:28,520 --> 00:07:37,720
And so that was 2016 fast forward to 2020 and you've seen quite a bit of success and

116
00:07:37,720 --> 00:07:44,440
Kaggle competitions, can you talk about some of the, uh, your more recent results or at

117
00:07:44,440 --> 00:07:47,080
least the results that you're most proud of?

118
00:07:47,080 --> 00:07:48,080
Yeah.

119
00:07:48,080 --> 00:07:53,440
So, um, shortly after that competition, there was another one that was, uh, for also medical

120
00:07:53,440 --> 00:07:54,920
image and related competition.

121
00:07:54,920 --> 00:08:00,000
It was for segmenting ultrasound images in the neck.

122
00:08:00,000 --> 00:08:04,800
And there was, uh, fortunately for me, um, that competition was actually the competition

123
00:08:04,800 --> 00:08:05,800
I did best in.

124
00:08:05,800 --> 00:08:11,960
So there was a, there was a new architecture, a new paper that was written on this, uh,

125
00:08:11,960 --> 00:08:16,840
thing called, it's an encoder, the quarter network is called a unit.

126
00:08:16,840 --> 00:08:21,200
And it hadn't really been used on Kaggle before that architecture.

127
00:08:21,200 --> 00:08:25,240
And I'd read the paper about the architecture.

128
00:08:25,240 --> 00:08:29,640
And when I read the paper, it, because I thought about this too, you know, like how do you segment

129
00:08:29,640 --> 00:08:33,160
things to something I've been thinking about, but when I read that paper, the, the ideas

130
00:08:33,160 --> 00:08:36,200
in the, in the paper made a lot of sense, right?

131
00:08:36,200 --> 00:08:39,840
It was like, and it almost seemed so obvious that what, that was what you were supposed

132
00:08:39,840 --> 00:08:45,960
to do to segment images with convolutional neural networks where you try to preserve, um,

133
00:08:45,960 --> 00:08:51,120
you try to preserve the localization information from the original images and things.

134
00:08:51,120 --> 00:08:53,480
So that paper really sparked my interest.

135
00:08:53,480 --> 00:08:54,480
I read it.

136
00:08:54,480 --> 00:08:56,680
I was, I was a fan of it.

137
00:08:56,680 --> 00:09:00,760
And this competition came up and somebody mentioned it.

138
00:09:00,760 --> 00:09:07,640
And back then, there was a framework called LaZange and, uh, the, and those frameworks

139
00:09:07,640 --> 00:09:13,080
are deprecated now, but back then, that was actually what I did, what I used.

140
00:09:13,080 --> 00:09:16,040
And I, I, I, I said, okay, I'm going to give it a shot.

141
00:09:16,040 --> 00:09:19,840
I'm trying, I'm going to try to implement this unit architecture.

142
00:09:19,840 --> 00:09:20,840
And I did.

143
00:09:20,840 --> 00:09:25,280
And I had no hopes of actually doing well in that competition.

144
00:09:25,280 --> 00:09:26,640
But I said, let me give it a shot.

145
00:09:26,640 --> 00:09:33,600
I implemented it, I trained the network and to my surprise, it worked.

146
00:09:33,600 --> 00:09:37,160
And I was so, I was just so happy that it worked.

147
00:09:37,160 --> 00:09:40,480
I had no idea I was going to finish a second place in the competition.

148
00:09:40,480 --> 00:09:46,400
So, um, so that's probably the one I was most proud of because, um, I had to hack a lot

149
00:09:46,400 --> 00:09:51,880
of things back then, you know, there was, even in 2016, there was, there was not, there

150
00:09:51,880 --> 00:09:57,760
are not a lot of best practices of how you do segmentation, even back then.

151
00:09:57,760 --> 00:10:02,560
So there was this, a lot of the frameworks out there had not specified how you do data

152
00:10:02,560 --> 00:10:09,880
augmentation, you know, for image and masks because when you train, when you train segmentation

153
00:10:09,880 --> 00:10:15,400
networks to avoid overfitting, you have to augment the image and the mask together.

154
00:10:15,400 --> 00:10:19,480
And you have to find the right kind of augmentation strategies and things like that.

155
00:10:19,480 --> 00:10:26,640
So I hacked, there was, I created a good augmentation strategy, a good augmentation framework.

156
00:10:26,640 --> 00:10:30,360
And, you know, I saw a lot of people in the challenge were struggling with this idea,

157
00:10:30,360 --> 00:10:34,880
you know, and they were not probably implementing the right augmentation strategies because,

158
00:10:34,880 --> 00:10:38,920
you know, like I said, this was the first time they used this unit in this competition.

159
00:10:38,920 --> 00:10:42,760
But I was kind of a little bit ahead of the game back then.

160
00:10:42,760 --> 00:10:48,200
And so, yeah, so I finished in second place and it was, it was, it was probably my, the

161
00:10:48,200 --> 00:10:51,080
proudest challenge, I'm, that's awesome.

162
00:10:51,080 --> 00:10:53,400
And that was out of like 950 teams, right?

163
00:10:53,400 --> 00:10:55,720
Yeah, that was out of 950 teams.

164
00:10:55,720 --> 00:11:02,720
Were there other teams that used the unit architecture in that competition?

165
00:11:02,720 --> 00:11:09,440
I think a lot of the teams used the unit, but they were implemented in, they used, they

166
00:11:09,440 --> 00:11:12,160
probably all used the same unit.

167
00:11:12,160 --> 00:11:15,600
And probably that was something that gave me an advantage because I don't think people

168
00:11:15,600 --> 00:11:20,080
had taken the time to learn how to build that unit architecture back then.

169
00:11:20,080 --> 00:11:24,880
So somebody posts that, hey, this is a great implementation of the unit and everybody

170
00:11:24,880 --> 00:11:27,240
just follows the crowd and uses it.

171
00:11:27,240 --> 00:11:31,520
And I think that kind of, if you did something different or you implemented your own and

172
00:11:31,520 --> 00:11:35,480
you kind of improved it a little bit, maybe more than what everybody else was using, you

173
00:11:35,480 --> 00:11:41,480
had a chance of doing a little better than they did if you kind of implemented it.

174
00:11:41,480 --> 00:11:48,320
That's, that's one interesting thing that I find about Kaggle is that it is both at the

175
00:11:48,320 --> 00:11:52,560
same time, you know, kind of inherently this competition, right?

176
00:11:52,560 --> 00:11:58,120
That's what it is, but there's also a lot of collaboration and people sharing kind

177
00:11:58,120 --> 00:12:00,440
of results and kernels and things like that.

178
00:12:00,440 --> 00:12:01,440
Yeah, yeah, yeah.

179
00:12:01,440 --> 00:12:05,760
Yeah, talk a little bit about that dynamic from the perspective of someone who participates

180
00:12:05,760 --> 00:12:06,760
in it.

181
00:12:06,760 --> 00:12:13,200
Yeah, so the kernels are great because it gives, it gives a good starting point like you

182
00:12:13,200 --> 00:12:20,480
can take a kernel and utilize it and kind of quickly get up to speed in what the challenge

183
00:12:20,480 --> 00:12:22,240
is about.

184
00:12:22,240 --> 00:12:27,800
And it gives you, it kind of does a lot of the preliminary hard work you might have

185
00:12:27,800 --> 00:12:32,400
had to do to kind of kind of figure out how to get started.

186
00:12:32,400 --> 00:12:34,560
The next level, yeah, great.

187
00:12:34,560 --> 00:12:37,720
So the kernels are great in that it gets you started.

188
00:12:37,720 --> 00:12:42,960
But being a competition, it's, it's, my approach is generally that if you do what everybody

189
00:12:42,960 --> 00:12:45,280
else does, you're not going to win.

190
00:12:45,280 --> 00:12:50,400
So usually you usually have to take those kernels and try to try to improve them and add

191
00:12:50,400 --> 00:12:55,240
your own unique improvement, optimization just to them because it's a competition after

192
00:12:55,240 --> 00:12:56,240
all.

193
00:12:56,240 --> 00:12:57,240
Yeah.

194
00:12:57,240 --> 00:13:01,600
So the kernels are great and the sharing is great and it gets people up and running

195
00:13:01,600 --> 00:13:02,600
fast.

196
00:13:02,600 --> 00:13:03,600
Yeah.

197
00:13:03,600 --> 00:13:10,240
Like you're, you had the success with the ultrasound nerve segmentation competition

198
00:13:10,240 --> 00:13:12,880
relatively early in your Kaggle journey.

199
00:13:12,880 --> 00:13:16,640
Yeah, it was actually my, my, my second or third competition.

200
00:13:16,640 --> 00:13:19,440
So I was pretty, and that's why I'm also proud of it.

201
00:13:19,440 --> 00:13:20,440
That's pretty encouragement.

202
00:13:20,440 --> 00:13:21,440
Yeah.

203
00:13:21,440 --> 00:13:23,760
It was, I got up there pretty quick.

204
00:13:23,760 --> 00:13:26,360
I think I was, like I said, I was really surprised.

205
00:13:26,360 --> 00:13:27,960
I said, let me implement this.

206
00:13:27,960 --> 00:13:33,120
And it kind of gave me the confidence that, you know, if you just apply your ideas, you

207
00:13:33,120 --> 00:13:36,120
know, you might, you should give it a shot.

208
00:13:36,120 --> 00:13:40,720
Just just give it a shot and, and you never know how it turns out.

209
00:13:40,720 --> 00:13:41,720
Mm-hmm.

210
00:13:41,720 --> 00:13:46,240
You know, it's, it's amazing to think that, you know, just three years ago was kind of

211
00:13:46,240 --> 00:13:50,640
the wild, wild west when it, you know, comes to these kinds of problems.

212
00:13:50,640 --> 00:13:57,400
How was the game evolved over the past three years and not to say that that what your,

213
00:13:57,400 --> 00:14:01,240
your accomplishment was easy, but is it, you know, is it as easy?

214
00:14:01,240 --> 00:14:07,440
Is it still possible to, you know, do the kinds of things that you did in that competition?

215
00:14:07,440 --> 00:14:08,440
Yeah.

216
00:14:08,440 --> 00:14:10,720
You know, talk a little bit about how it has evolved.

217
00:14:10,720 --> 00:14:11,720
Yeah.

218
00:14:11,720 --> 00:14:15,960
So, it's evolved because now, you know, like then it was the wild west.

219
00:14:15,960 --> 00:14:21,440
Now things, a lot of things you could have done in the past again and edge are now standardized

220
00:14:21,440 --> 00:14:23,040
well understood.

221
00:14:23,040 --> 00:14:25,920
So that's good because it moves the field forward.

222
00:14:25,920 --> 00:14:31,120
You know, people have settled on best practices and best strategies.

223
00:14:31,120 --> 00:14:34,160
So it definitely has evolved things that have improved.

224
00:14:34,160 --> 00:14:40,080
It gets harder now to win competitions without really innovating or really looking into

225
00:14:40,080 --> 00:14:45,520
percular things about the data sets or the problem that you can exploit.

226
00:14:45,520 --> 00:14:51,240
So there's definitely, it's not as, it's, I think it's easier to start now than it was

227
00:14:51,240 --> 00:14:57,000
back then because you have a lot of kind of examples and things to go by.

228
00:14:57,000 --> 00:15:02,320
But still being a competition platform, it still requires pushing the limits a little

229
00:15:02,320 --> 00:15:07,920
bit in terms of innovating and finding kind of things that could give you an edge.

230
00:15:07,920 --> 00:15:15,040
So can you give us some examples of, you know, how you've innovated in competitions and,

231
00:15:15,040 --> 00:15:19,280
you know, where you found patterns in the data that you were able to exploit?

232
00:15:19,280 --> 00:15:20,800
How has this played out for you?

233
00:15:20,800 --> 00:15:21,800
Okay.

234
00:15:21,800 --> 00:15:26,960
So the next really good competition I did in was one sponsored by the Department of Homeland

235
00:15:26,960 --> 00:15:34,720
and the TSA for detecting, for detecting threats in the provisioned body scanners.

236
00:15:34,720 --> 00:15:35,720
You seeing the airports?

237
00:15:35,720 --> 00:15:37,120
AKA the newtoscopes.

238
00:15:37,120 --> 00:15:38,120
Yeah.

239
00:15:38,120 --> 00:15:39,120
Yeah.

240
00:15:39,120 --> 00:15:43,920
So, and that was the largest competition on Kegel in terms of price money.

241
00:15:43,920 --> 00:15:47,000
So it was kind of like the highest profile competition.

242
00:15:47,000 --> 00:15:49,720
And we came in, I came in third place in that one.

243
00:15:49,720 --> 00:15:53,720
And that was another one that requires requires money.

244
00:15:53,720 --> 00:15:57,000
The overall purchase was about $1.5 million.

245
00:15:57,000 --> 00:15:58,000
Wow.

246
00:15:58,000 --> 00:16:04,480
So, um, so in that one, we had to innovate because the data set was peculiar.

247
00:16:04,480 --> 00:16:06,000
It was very large.

248
00:16:06,000 --> 00:16:09,400
It was the largest data set ever on Kegel.

249
00:16:09,400 --> 00:16:15,920
And so that required the barriers on that one were required, kind of solving the problem

250
00:16:15,920 --> 00:16:21,960
of dealing with really, really large data and terabytes and, and, you know, you had

251
00:16:21,960 --> 00:16:23,200
to get an edge in that.

252
00:16:23,200 --> 00:16:27,080
And then you had to, the data was also three-dimensional.

253
00:16:27,080 --> 00:16:31,400
And you had to come up with architectures that could deal with three-dimensional data.

254
00:16:31,400 --> 00:16:35,720
So the, so in that, that was another competition where there were no best practices in terms

255
00:16:35,720 --> 00:16:37,920
of how you go about solving this problem.

256
00:16:37,920 --> 00:16:42,200
So if you could, it was one of those, another one of those low-hanging fruits where if you

257
00:16:42,200 --> 00:16:47,560
could quickly come up with an optimal approach, you were more likely to do really well in

258
00:16:47,560 --> 00:16:48,560
it.

259
00:16:48,560 --> 00:16:53,400
So we came up with a very creative architecture that allowed us to perform well.

260
00:16:53,400 --> 00:17:02,120
And so did you join that competition because it looked interesting or did you join that

261
00:17:02,120 --> 00:17:08,240
competition because you saw that there were these issues that would provide kind of a

262
00:17:08,240 --> 00:17:10,000
direction for you to innovate in?

263
00:17:10,000 --> 00:17:11,000
Yeah.

264
00:17:11,000 --> 00:17:15,080
So that competition, like I said, I'll still in my PhD program back then.

265
00:17:15,080 --> 00:17:19,560
My part of my research was dealing with medical imaging data and a lot of the medical imaging

266
00:17:19,560 --> 00:17:24,680
data are three-dimensional CT or MRI.

267
00:17:24,680 --> 00:17:29,120
And I already started thinking about three-dimensional imaging.

268
00:17:29,120 --> 00:17:33,760
So I already started, the architecture that you used was one I already started doing research

269
00:17:33,760 --> 00:17:34,760
in.

270
00:17:34,760 --> 00:17:41,640
I wrote about my thesis for handling the difficulties with the three-dimensional imaging are the

271
00:17:41,640 --> 00:17:47,640
large volumes, and even with the state of the RGPUs we have today, if you want to process

272
00:17:47,640 --> 00:17:54,960
at the original resolution of all these medical images, it's often impossible, right, without

273
00:17:54,960 --> 00:18:01,600
sound sampling or reducing the size of the data to a point where you actually lose useful

274
00:18:01,600 --> 00:18:03,120
information.

275
00:18:03,120 --> 00:18:07,800
So I had started working on some of these problems.

276
00:18:07,800 --> 00:18:13,920
And I'd actually already used the architecture I used on Parkinson's disease data so that

277
00:18:13,920 --> 00:18:22,560
just to see if we could detect or classify Parkinson's disease in brain scans.

278
00:18:22,560 --> 00:18:24,840
So it was something I was working on.

279
00:18:24,840 --> 00:18:29,680
And when that challenge came around, I quickly identified that the data looked very similar

280
00:18:29,680 --> 00:18:34,640
to the medical imaging data I was working with and I already had an approach I'd been investigating

281
00:18:34,640 --> 00:18:40,320
so I said we're just going to crack this method loose on the data and it worked out well.

282
00:18:40,320 --> 00:18:41,320
Nice.

283
00:18:41,320 --> 00:18:44,120
Can you walk us through the method?

284
00:18:44,120 --> 00:18:50,960
Yeah, so it's usually most of the CNNs out there are work with two-dimensional data and

285
00:18:50,960 --> 00:18:57,240
a lot of the methods in deep learning work with two-dimensional imaging and that's well

286
00:18:57,240 --> 00:18:58,240
understood.

287
00:18:58,240 --> 00:19:03,680
But when you come to 3D, the memory requirements, they grow a lot.

288
00:19:03,680 --> 00:19:08,840
So this method I used kind of combined, so you want to learn features in the two-dimensional

289
00:19:08,840 --> 00:19:09,840
space.

290
00:19:09,840 --> 00:19:14,880
But there's also a third dimension which is the third axis where you also can correlate

291
00:19:14,880 --> 00:19:21,120
features across multiple two-dimensional images because the volume is essentially a

292
00:19:21,120 --> 00:19:23,400
step of two-dimensional images.

293
00:19:23,400 --> 00:19:28,400
So what we did was we combined the convolutional neural network, the 2D convolutional neural

294
00:19:28,400 --> 00:19:30,520
network with an LSTM.

295
00:19:30,520 --> 00:19:38,080
And LSTM is a different kind of architecture that kind of models sequences of data.

296
00:19:38,080 --> 00:19:44,560
So and it requires less the input vectors of much smaller than images.

297
00:19:44,560 --> 00:19:48,560
So if you could use the convolutional neural network to kind of learn the two-dimensional

298
00:19:48,560 --> 00:19:54,760
vectors that you need to feed into the LSTM, you could reduce the memory requirements required

299
00:19:54,760 --> 00:19:57,040
to train a three-dimensional volume.

300
00:19:57,040 --> 00:20:03,280
And that was kind of the innovation in the architecture where we were able to.

301
00:20:03,280 --> 00:20:14,680
So it sounds like you're using the, if I get this right, you're using the CNN to do something

302
00:20:14,680 --> 00:20:19,080
along the lines of dimensionality reduction of your two-dimensional images and you're

303
00:20:19,080 --> 00:20:21,080
eating that into an LSTM.

304
00:20:21,080 --> 00:20:22,080
Yes, exactly.

305
00:20:22,080 --> 00:20:23,080
That's what it is.

306
00:20:23,080 --> 00:20:24,080
Interesting.

307
00:20:24,080 --> 00:20:29,000
So by doing that, we didn't have to reduce the resolution of the input images.

308
00:20:29,000 --> 00:20:32,920
So we're able to learn rich two-dimensional futures.

309
00:20:32,920 --> 00:20:38,320
And also, you know, the body scanners, they give you this kind of three-dimensional view

310
00:20:38,320 --> 00:20:40,120
of the person.

311
00:20:40,120 --> 00:20:43,760
And there's kind of a correlation from frame to frame.

312
00:20:43,760 --> 00:20:49,560
If you see something in one frame and you don't see it in another frame, in the next frame,

313
00:20:49,560 --> 00:20:51,040
is it a false positive?

314
00:20:51,040 --> 00:20:51,880
Is it a false negative?

315
00:20:51,880 --> 00:20:58,720
So that kind of temporal effect of kind of going around something, kind of also benefited

316
00:20:58,720 --> 00:21:00,120
that architecture.

317
00:21:00,120 --> 00:21:03,520
So that was one where we could innovate and do well in a challenge.

318
00:21:03,520 --> 00:21:04,520
Nice.

319
00:21:04,520 --> 00:21:12,600
And was your, was the challenge to classify the images or to do segmentation or...

320
00:21:12,600 --> 00:21:14,600
No, it was to classify the image.

321
00:21:14,600 --> 00:21:19,120
So if you had something on your ankles hitting on your clothing, they wanted to know that

322
00:21:19,120 --> 00:21:21,520
there's a threat underneath the left ankle.

323
00:21:21,520 --> 00:21:27,000
There is 17 body zones around the person, the lower legs, backs, and you just have to

324
00:21:27,000 --> 00:21:28,000
tell...

325
00:21:28,000 --> 00:21:32,480
Then you're on that, just have to predict a probability of a threat in a specific body

326
00:21:32,480 --> 00:21:33,480
part.

327
00:21:33,480 --> 00:21:34,480
Okay.

328
00:21:34,480 --> 00:21:35,480
Yeah.

329
00:21:35,480 --> 00:21:36,840
Any other tricks that came to bear there?

330
00:21:36,840 --> 00:21:40,720
You mentioned that part of the challenge had to do with just dealing with the volume of

331
00:21:40,720 --> 00:21:41,720
data.

332
00:21:41,720 --> 00:21:42,720
What did you end up doing there?

333
00:21:42,720 --> 00:21:43,720
Yeah.

334
00:21:43,720 --> 00:21:49,920
So that dealt with just writing a lot of, you know, code to deal with processed data

335
00:21:49,920 --> 00:21:55,520
fast, multi-threaded, find ways to optimize your training so you could load as much data

336
00:21:55,520 --> 00:21:57,920
as possible, as fast as possible.

337
00:21:57,920 --> 00:22:01,160
So that was more like an engineering challenge, you know.

338
00:22:01,160 --> 00:22:03,200
How do you train faster?

339
00:22:03,200 --> 00:22:04,680
How do you load data faster?

340
00:22:04,680 --> 00:22:08,520
How do you get through your training epochs faster?

341
00:22:08,520 --> 00:22:10,280
How do you do your inferencing faster?

342
00:22:10,280 --> 00:22:11,280
So I...

343
00:22:11,280 --> 00:22:12,480
And where did you do all this?

344
00:22:12,480 --> 00:22:18,120
Did you have, did you use university equipment or did you have your own equipment or do

345
00:22:18,120 --> 00:22:19,440
you use cloud?

346
00:22:19,440 --> 00:22:25,760
Because I use AWS Amazon, I write GPU instances on Amazon.

347
00:22:25,760 --> 00:22:26,760
Okay.

348
00:22:26,760 --> 00:22:30,920
And what did you end up spending on the competition?

349
00:22:30,920 --> 00:22:38,760
So this competition we spent probably maybe $2,000 in GPU compute costs over three months.

350
00:22:38,760 --> 00:22:40,440
Would you end up winning?

351
00:22:40,440 --> 00:22:42,000
What is third place?

352
00:22:42,000 --> 00:22:44,000
Third place was worth $200,000.

353
00:22:44,000 --> 00:22:45,000
Nice.

354
00:22:45,000 --> 00:22:46,000
So good profit margin.

355
00:22:46,000 --> 00:22:47,000
Yeah.

356
00:22:47,000 --> 00:22:48,000
That's good.

357
00:22:48,000 --> 00:22:49,560
That was a good profit margin.

358
00:22:49,560 --> 00:22:57,560
I guess I'm curious like the way you thought about the spend on AWS, you know, you know,

359
00:22:57,560 --> 00:23:01,040
obviously before the competition ended, you didn't know if you were winning, but you

360
00:23:01,040 --> 00:23:06,040
had signal that you were doing well, like, did you kind of managing it or did you?

361
00:23:06,040 --> 00:23:07,040
Yeah, yeah.

362
00:23:07,040 --> 00:23:08,320
You definitely manage it.

363
00:23:08,320 --> 00:23:11,320
You definitely manage it.

364
00:23:11,320 --> 00:23:16,760
You have to weigh the cost and the benefit and fortunately, usually what I do is, as

365
00:23:16,760 --> 00:23:22,880
soon as I enter, I want to see myself in the top 30 to give, to know if it's worth,

366
00:23:22,880 --> 00:23:26,600
you know, pushing harder, maybe spending more.

367
00:23:26,600 --> 00:23:30,560
So that's usually how it works, you know, I usually come up with an approach.

368
00:23:30,560 --> 00:23:33,320
I hardly ever pivot in this competition.

369
00:23:33,320 --> 00:23:39,760
I kind of try to come up with a plan that before you even start, yeah, before I start,

370
00:23:39,760 --> 00:23:47,760
but I wanted that plan to show signs of promise right away because oftentimes my strategy

371
00:23:47,760 --> 00:23:49,360
is that I hardly ever pivot.

372
00:23:49,360 --> 00:23:54,720
I hate pivoting because when in this challenge is usually you find out you waste a lot of

373
00:23:54,720 --> 00:24:00,200
time experimenting with approaches that just lead to dead ends.

374
00:24:00,200 --> 00:24:07,120
So I try to think out the problem well ahead of time and then just give it a shot at that

375
00:24:07,120 --> 00:24:11,480
first approach and hope it shows good promise.

376
00:24:11,480 --> 00:24:19,600
It's almost like because of the factors that you describe, like a lot of winning the competition

377
00:24:19,600 --> 00:24:25,920
is being on the winning side of an information asymmetry.

378
00:24:25,920 --> 00:24:35,160
And so the approach is one of, you know, figuring out a strategy.

379
00:24:35,160 --> 00:24:41,080
And if you end up in the top 30, it means you're probably not on the losing side, dramatic,

380
00:24:41,080 --> 00:24:45,960
you know, dramatically on the losing side of some information asymmetry, whereas that's

381
00:24:45,960 --> 00:24:48,360
an interesting way to think about it.

382
00:24:48,360 --> 00:24:53,080
Has that way of thinking about it evolved over the four years you've been doing this,

383
00:24:53,080 --> 00:24:56,640
or did you, did you start pivoting like everybody else does?

384
00:24:56,640 --> 00:25:02,160
Yeah, sometimes, you know, if a lot of time, it depends on the interest in the competition.

385
00:25:02,160 --> 00:25:05,680
And there's a lot of interest, just my personal interest is a lot.

386
00:25:05,680 --> 00:25:10,680
I will pivot if something is not working and I'll, because I don't mind, but if it's

387
00:25:10,680 --> 00:25:17,400
not there, you know, yeah, so it's not like I don't pivot, but it's just, if the cost

388
00:25:17,400 --> 00:25:22,800
of time and commitment you need, you can kind of gauge that from the first time you see

389
00:25:22,800 --> 00:25:26,600
the competition is a lot, you don't want to spend too much time.

390
00:25:26,600 --> 00:25:31,840
And also there's also this diminishing return effect where if you pivot, at least this

391
00:25:31,840 --> 00:25:38,240
is just my approach, is that if you try too many ideas that fail, it's kind of defeating.

392
00:25:38,240 --> 00:25:44,000
So you want to kind of throw your hard punch the first time and try to kind of get a good

393
00:25:44,000 --> 00:25:45,400
result that way.

394
00:25:45,400 --> 00:25:47,760
That's kind of how I approach it.

395
00:25:47,760 --> 00:25:55,000
Is, are there some competitions that you join to play and others that you join to win?

396
00:25:55,000 --> 00:25:59,520
Yeah, most of the competitions I do well in our computer vision.

397
00:25:59,520 --> 00:26:06,840
So I usually try to do computer vision to do well in and win the other machine learning

398
00:26:06,840 --> 00:26:07,840
competitions.

399
00:26:07,840 --> 00:26:11,120
I do them to learn and to figure out things.

400
00:26:11,120 --> 00:26:18,000
What are some other examples of this idea of kind of exploiting unique aspects of the

401
00:26:18,000 --> 00:26:19,000
problem?

402
00:26:19,000 --> 00:26:20,000
Yeah.

403
00:26:20,000 --> 00:26:22,640
So, and these are some of my secrets.

404
00:26:22,640 --> 00:26:29,120
I don't know if I want to give away too much, but I find the discussion forums on

405
00:26:29,120 --> 00:26:35,320
Kaggle very, very useful, like what participants are talking about.

406
00:26:35,320 --> 00:26:42,120
A lot of the times, you know, you reach through those forums and you can kind of, you can kind

407
00:26:42,120 --> 00:26:47,720
of get a sense of an approach or some, you can find kind of connect threads.

408
00:26:47,720 --> 00:26:48,720
So that's another part.

409
00:26:48,720 --> 00:26:52,760
You try to find information you need that maybe people haven't seen.

410
00:26:52,760 --> 00:26:57,600
But there's something they're all trying to say, but I don't know how to explain it.

411
00:26:57,600 --> 00:27:02,120
But there is information in just reading the mindsets or trying to understand what people's

412
00:27:02,120 --> 00:27:03,120
experiences are.

413
00:27:03,120 --> 00:27:08,600
Because oftentimes that aspect of it too, you know, people who are doing well, sometimes

414
00:27:08,600 --> 00:27:10,160
they're usually quiet.

415
00:27:10,160 --> 00:27:15,200
That was one that I noticed in Kaggle too was when I started, the people at the top of

416
00:27:15,200 --> 00:27:20,400
the leaderboard, I always try to look to see what they're talking about.

417
00:27:20,400 --> 00:27:23,320
And they're, you never find anything because they're just quiet.

418
00:27:23,320 --> 00:27:26,800
It's like they know something and they don't want to share.

419
00:27:26,800 --> 00:27:31,800
You know, so there's that aspect of trying to dig in the forums to try to, you know,

420
00:27:31,800 --> 00:27:36,040
try to learn approaches that could help in a challenge.

421
00:27:36,040 --> 00:27:43,120
That makes me think a little bit about research in general and how, you know, often you'll

422
00:27:43,120 --> 00:27:50,120
find that there are a bunch of, you know, more or less kind of parallel introductions

423
00:27:50,120 --> 00:27:56,680
of innovative ideas because, you know, some period of time before, like there was something

424
00:27:56,680 --> 00:27:59,200
in the air and nobody quite knew how to say it.

425
00:27:59,200 --> 00:28:00,200
Exactly.

426
00:28:00,200 --> 00:28:04,880
But there was something in the air and if you can kind of figure that out, that leads you

427
00:28:04,880 --> 00:28:07,320
down the road to some innovation.

428
00:28:07,320 --> 00:28:08,320
Exactly.

429
00:28:08,320 --> 00:28:10,440
That's kind of what I'm trying to say.

430
00:28:10,440 --> 00:28:15,920
So you also participated in a distracted driver competition.

431
00:28:15,920 --> 00:28:18,240
That was what State Farm sponsored?

432
00:28:18,240 --> 00:28:20,240
What was that one all about?

433
00:28:20,240 --> 00:28:27,360
Yeah, that challenge was a challenge to identify distracted drivers.

434
00:28:27,360 --> 00:28:28,360
I think there are different things.

435
00:28:28,360 --> 00:28:35,560
It was the driver playing with the radio, was a driver looking, I forgot in all the categories

436
00:28:35,560 --> 00:28:41,280
in that challenge, but it was kind of to identify distracted drivers.

437
00:28:41,280 --> 00:28:49,280
And that was just they had a dash cam in the car and the task was to kind of indicate

438
00:28:49,280 --> 00:28:54,040
what if the driver was paying attention to driving or was the driver eating or drinking

439
00:28:54,040 --> 00:29:00,640
or using makeup or playing with the radio or doing something else.

440
00:29:00,640 --> 00:29:05,360
So that was another image in competition I did well in.

441
00:29:05,360 --> 00:29:13,080
The trick, one of the things I did in that one that really helped was we used a clever

442
00:29:13,080 --> 00:29:19,920
data augmentation technique that enabled us to convince the data a lot.

443
00:29:19,920 --> 00:29:28,160
We kind of, I don't know if it's relevant, I can explain the technique is we, so if

444
00:29:28,160 --> 00:29:35,000
you, if we had two images of a driver that was playing with the radio, right, two different

445
00:29:35,000 --> 00:29:41,440
drivers, we could take 75% of one image and combine it with the remaining 25% of the

446
00:29:41,440 --> 00:29:44,200
other image and form a new image.

447
00:29:44,200 --> 00:29:47,120
So that creates a kind of an additional image.

448
00:29:47,120 --> 00:29:53,400
So it's, it's more likely some part of the driver, it just that augmentation approach

449
00:29:53,400 --> 00:29:55,520
on how does create a lot more.

450
00:29:55,520 --> 00:30:03,080
You had a picture of one driver playing with the radio and then a picture of the same

451
00:30:03,080 --> 00:30:07,600
driver not playing with the radio, no, no, no, the picture of a different driver that

452
00:30:07,600 --> 00:30:09,360
said was playing with the video.

453
00:30:09,360 --> 00:30:10,360
So with the radio.

454
00:30:10,360 --> 00:30:16,960
Two drivers that are both playing with the radio, you created other images and was this

455
00:30:16,960 --> 00:30:19,000
like a linear interpolation of the two images.

456
00:30:19,000 --> 00:30:23,640
Yeah, yeah, this is just a flat combination, you just combine it and you take some percentage

457
00:30:23,640 --> 00:30:28,440
of this one and some, I mean, you, you join them horizontally or vertically.

458
00:30:28,440 --> 00:30:32,320
And because you're just trying to learn, the neural network has to be able to learn,

459
00:30:32,320 --> 00:30:37,480
you know, if it's a partial image of somebody doing something, there's still enough information

460
00:30:37,480 --> 00:30:43,000
there to, to kind of try to estimate the best prediction.

461
00:30:43,000 --> 00:30:49,320
So you're literally just like 75% of the image horizontally is one picture and 25% is

462
00:30:49,320 --> 00:30:50,320
another picture.

463
00:30:50,320 --> 00:30:51,320
Yeah.

464
00:30:51,320 --> 00:30:52,320
And that worked.

465
00:30:52,320 --> 00:30:53,320
Yeah.

466
00:30:53,320 --> 00:30:54,320
Yeah.

467
00:30:54,320 --> 00:30:55,320
Wow.

468
00:30:55,320 --> 00:30:56,320
Yeah.

469
00:30:56,320 --> 00:31:00,600
And we did that, we were able to, I think I don't know, we had maybe something like that.

470
00:31:00,600 --> 00:31:02,600
What made you try that?

471
00:31:02,600 --> 00:31:05,040
We're trying to deal with overfitting, right?

472
00:31:05,040 --> 00:31:10,640
So the problem with the way the data was collected was that there were a few subjects

473
00:31:10,640 --> 00:31:15,800
in the, in the training set and neural networks tend to overfit, they just memorize, right?

474
00:31:15,800 --> 00:31:20,280
They just memorize the images, right?

475
00:31:20,280 --> 00:31:26,040
Because once they see somewhere, the visor in a certain position or some unique future

476
00:31:26,040 --> 00:31:29,480
in the image, they just latch on to that and they make the correct prediction every time

477
00:31:29,480 --> 00:31:30,720
in training.

478
00:31:30,720 --> 00:31:36,480
But that doesn't generalize to, it doesn't generalize to an unseen validation set, because

479
00:31:36,480 --> 00:31:40,600
they're exploiting, you know, peculiarities of each.

480
00:31:40,600 --> 00:31:45,440
So by doing this administration strategy, you kind of break all those false assumptions

481
00:31:45,440 --> 00:31:49,160
that the neural network might have made to improve.

482
00:31:49,160 --> 00:31:55,000
So it really has to learn the task of maybe identifying when to try and explain what

483
00:31:55,000 --> 00:31:56,000
a radio.

484
00:31:56,000 --> 00:31:57,000
So.

485
00:31:57,000 --> 00:31:58,000
Wow.

486
00:31:58,000 --> 00:32:03,520
Did you also innovate on the model architecture or something off the shelf?

487
00:32:03,520 --> 00:32:06,200
No, we just used off the shelf in that one.

488
00:32:06,200 --> 00:32:10,080
We didn't do anything special with the model architecture.

489
00:32:10,080 --> 00:32:17,080
And a lot of Kaggle competitions are one by like these really kind of monstrosity ensembles

490
00:32:17,080 --> 00:32:18,080
of things.

491
00:32:18,080 --> 00:32:21,880
Is that true generally in vision or less so?

492
00:32:21,880 --> 00:32:22,880
Yeah.

493
00:32:22,880 --> 00:32:28,640
It's true in vision, but it's true in vision when you get to inserting competitions.

494
00:32:28,640 --> 00:32:33,800
In other competitions like the Homeland Security Challenge, we could have kept our position

495
00:32:33,800 --> 00:32:35,400
with one model.

496
00:32:35,400 --> 00:32:37,720
So it's true.

497
00:32:37,720 --> 00:32:44,720
But if one model is, if you really spend time can do, if you focus on one model, you can

498
00:32:44,720 --> 00:32:47,720
almost do it as well as a massive ensemble.

499
00:32:47,720 --> 00:32:51,320
But oftentimes the ensemble is the easy way out.

500
00:32:51,320 --> 00:32:55,160
But the ensembles, there's a cost associated with that, at least for computer vision in

501
00:32:55,160 --> 00:32:56,880
terms of GPU time.

502
00:32:56,880 --> 00:33:02,600
If you have infinite compute resources, you might be able to get away with ensembling.

503
00:33:02,600 --> 00:33:08,560
But oftentimes you have to wait the cost of training many models with focusing on one

504
00:33:08,560 --> 00:33:11,440
and trying to get it as good as possible.

505
00:33:11,440 --> 00:33:19,760
So if you were starting Kaggle today, we actually, we've got a study group, these are folks

506
00:33:19,760 --> 00:33:25,480
that are kind of like an online meetup of folks that are doing Kaggle together.

507
00:33:25,480 --> 00:33:31,600
They've been, I think it's been going for maybe eight weeks now, and they may be about

508
00:33:31,600 --> 00:33:35,480
to start a new session of it.

509
00:33:35,480 --> 00:33:42,400
But the sense is that one of the key things to do is to find other folks to work with.

510
00:33:42,400 --> 00:33:44,840
Is that true in your experience?

511
00:33:44,840 --> 00:33:53,120
Yeah, working with other people usually helps sharing ideas and kind of creating diversity

512
00:33:53,120 --> 00:33:54,760
of approaches.

513
00:33:54,760 --> 00:33:58,360
Most of my competitions have teamed up with somebody.

514
00:33:58,360 --> 00:34:03,920
And everybody brings unique perspectives that help in challenges.

515
00:34:03,920 --> 00:34:11,480
If you were talking to folks that are interested in starting, how would you advise them to kind

516
00:34:11,480 --> 00:34:13,840
of go at it?

517
00:34:13,840 --> 00:34:22,440
Okay, so one part of, at least I see, is that in AI, a lot of people make things a little

518
00:34:22,440 --> 00:34:24,760
more complicated than they need to be.

519
00:34:24,760 --> 00:34:25,760
Really?

520
00:34:25,760 --> 00:34:37,200
I don't know if that's new information, but so the key is actually, the solutions for

521
00:34:37,200 --> 00:34:41,080
problems, at least my approach, is that these solutions are usually simple.

522
00:34:41,080 --> 00:34:44,640
They're not, they're not complicated.

523
00:34:44,640 --> 00:34:51,040
And a barrier to starting Kagel is that there's this idea that it's hard, it's difficult.

524
00:34:51,040 --> 00:34:56,320
If you look at AI, for example, and the progression of deep learning, at least from my experience

525
00:34:56,320 --> 00:35:01,200
and my research, the key contributions have been really simple ideas.

526
00:35:01,200 --> 00:35:12,720
So for example, before 2012, when Alex net won that computer vision challenge, there

527
00:35:12,720 --> 00:35:16,920
was this idea that neural networks were hard to train, there was this vanishing gradient

528
00:35:16,920 --> 00:35:22,440
problem, there was all this stuff going on, you just couldn't train neural networks.

529
00:35:22,440 --> 00:35:27,520
And you should avenge your paper on the difficulties of training neural networks.

530
00:35:27,520 --> 00:35:33,360
And what he found was that the activation function they were using, which was the sigmoid,

531
00:35:33,360 --> 00:35:36,760
was causing, was a problem.

532
00:35:36,760 --> 00:35:42,600
So all, in my opinion, all the breakthroughs we've seen has been a result of the regular

533
00:35:42,600 --> 00:35:49,120
activation function that sort of eliminated that vanishing gradient problem.

534
00:35:49,120 --> 00:35:51,840
So that idea is pretty simple.

535
00:35:51,840 --> 00:35:54,640
It was a simple change in the activation function.

536
00:35:54,640 --> 00:35:59,800
Between then and the other next key contribution, there are a lot of complex things that people

537
00:35:59,800 --> 00:36:06,080
explain and try to cloud the actual real important things that push the ball forward.

538
00:36:06,080 --> 00:36:12,280
And Kegel said of the same way, I kind of feel like a lot of challenges you just have

539
00:36:12,280 --> 00:36:18,120
to kind of look at it with a creative approach and just open your mind that the solution

540
00:36:18,120 --> 00:36:19,120
is simple.

541
00:36:19,120 --> 00:36:27,480
It's just you're just a few ideas away from having kind of like a really good solution.

542
00:36:27,480 --> 00:36:34,840
So I think this is a sort of joining teams is teaming up with people is a good idea.

543
00:36:34,840 --> 00:36:40,200
But generally, you just have to believe that you can do well in a challenge and really

544
00:36:40,200 --> 00:36:42,800
give it a shot.

545
00:36:42,800 --> 00:36:46,440
Because Kegel can be discouraging, you know, it's, you can be discouraging if you go

546
00:36:46,440 --> 00:36:48,080
in and you don't do well.

547
00:36:48,080 --> 00:36:51,720
Fortunately for me, I didn't experience that well, maybe my first challenge, because you

548
00:36:51,720 --> 00:36:55,040
know, my first challenge, I thought, yes, I'm going to blow this thing away.

549
00:36:55,040 --> 00:37:01,200
And you know, you can be, you'll be really surprised, you know, how much you still have

550
00:37:01,200 --> 00:37:02,200
to learn.

551
00:37:02,200 --> 00:37:03,200
Yeah.

552
00:37:03,200 --> 00:37:04,760
So teaming up is a good way.

553
00:37:04,760 --> 00:37:09,960
But I still feel you can do it on your own, just have the motivation to to enter a challenge

554
00:37:09,960 --> 00:37:16,080
and stick at it, don't get discouraged if you don't do well initially.

555
00:37:16,080 --> 00:37:21,080
So teaming up persistence, keeping a simple, what else?

556
00:37:21,080 --> 00:37:23,360
Yeah, that's, that's about it.

557
00:37:23,360 --> 00:37:29,680
And, and reading top solutions, following up at the end of the challenge.

558
00:37:29,680 --> 00:37:35,660
And oftentimes, Kegel, the winners usually share their approaches and follow up and kind

559
00:37:35,660 --> 00:37:40,920
of look and correlate what the winners did with what you did and what you could have done

560
00:37:40,920 --> 00:37:42,640
that or that you missed.

561
00:37:42,640 --> 00:37:46,400
But I think that's it, it's really following up and just being persistent.

562
00:37:46,400 --> 00:37:51,040
So those are the kind of the general tips for folks that want to get started.

563
00:37:51,040 --> 00:37:55,640
What about the expert tips for folks that have been banging their head against it for

564
00:37:55,640 --> 00:37:59,560
a while and haven't gotten to, you know, where they'd like to get?

565
00:37:59,560 --> 00:38:03,200
Do you have any, you know, I think, I think, or ninja habits or anything like that.

566
00:38:03,200 --> 00:38:05,000
I think those tips are universal.

567
00:38:05,000 --> 00:38:06,760
Those tips works for the expert to the experts.

568
00:38:06,760 --> 00:38:12,280
If they stay persistent, they look at the solutions of the top teams, what they did.

569
00:38:12,280 --> 00:38:13,280
That's it.

570
00:38:13,280 --> 00:38:14,440
Okay.

571
00:38:14,440 --> 00:38:16,760
You just kept it simple.

572
00:38:16,760 --> 00:38:17,760
Yeah.

573
00:38:17,760 --> 00:38:18,760
Awesome.

574
00:38:18,760 --> 00:38:25,520
You know, what we didn't talk about yet is analytical AI, which is your, your day job.

575
00:38:25,520 --> 00:38:26,520
What, what is that?

576
00:38:26,520 --> 00:38:27,520
What do you do there?

577
00:38:27,520 --> 00:38:28,520
Yes.

578
00:38:28,520 --> 00:38:33,920
So at Annalclei, we, due to the Homeland Security Challenge, we got a couple of projects.

579
00:38:33,920 --> 00:38:39,760
We're developing various, we're working with various equipment manufacturers to that are

580
00:38:39,760 --> 00:38:48,560
usually in the security space to help identify threats, either on person screening or in

581
00:38:48,560 --> 00:38:51,880
baggage, CTE or X-ray.

582
00:38:51,880 --> 00:38:59,560
And we're also working on various fintech products where we're trying to use AI for things

583
00:38:59,560 --> 00:39:02,800
like technical analysis and things like that.

584
00:39:02,800 --> 00:39:03,800
Interesting.

585
00:39:03,800 --> 00:39:12,480
I did, I, this wasn't a full interview, but I've talked to a group down in Austin, I think.

586
00:39:12,480 --> 00:39:15,360
And I've seen a couple of press releases about this.

587
00:39:15,360 --> 00:39:22,480
I get a couple of year of groups that are using a bunch of sensors, maybe mounted on a police

588
00:39:22,480 --> 00:39:31,640
vehicle or on a drone that are like trying to identify the presence of weapons, you know,

589
00:39:31,640 --> 00:39:38,560
on a person, and the drone mounted ones are the ones that are kind of the most crazy

590
00:39:38,560 --> 00:39:39,560
sounding.

591
00:39:39,560 --> 00:39:40,560
Yeah.

592
00:39:40,560 --> 00:39:41,560
Does that stuff work?

593
00:39:41,560 --> 00:39:43,640
Is that kind of in the domain of stuff that you've been looking at?

594
00:39:43,640 --> 00:39:47,640
That's not necessarily the domain of what we're looking at, like we're, we're looking

595
00:39:47,640 --> 00:39:54,920
at working with teams that make things like passive screening, like tear hurts and, you

596
00:39:54,920 --> 00:40:01,840
know, like, or X-ray for baggage at the airport.

597
00:40:01,840 --> 00:40:08,560
It's not like drone mounted or these are like people screening devices, like the station

598
00:40:08,560 --> 00:40:15,040
at somewhere and they try to make you walk through maybe at events or stadiums and identify

599
00:40:15,040 --> 00:40:17,400
threats under clothing and things like that.

600
00:40:17,400 --> 00:40:18,400
Okay.

601
00:40:18,400 --> 00:40:19,400
Okay.

602
00:40:19,400 --> 00:40:25,680
So opinion on the drone mounted viability.

603
00:40:25,680 --> 00:40:26,680
Awesome.

604
00:40:26,680 --> 00:40:28,720
Well, David, it has been great chatting with you.

605
00:40:28,720 --> 00:40:34,440
Thanks so much for sharing a bit about what you've been up to and all of the great Kaggle

606
00:40:34,440 --> 00:40:35,440
tips.

607
00:40:35,440 --> 00:40:36,440
Yeah.

608
00:40:36,440 --> 00:40:37,440
Thanks.

609
00:40:37,440 --> 00:40:38,440
It was great talking to you too.

610
00:40:38,440 --> 00:40:39,440
Thanks.

611
00:40:39,440 --> 00:40:40,440
Thanks, David.

612
00:40:40,440 --> 00:40:47,400
All right, everyone, that's our show for today to learn more about today's guests or

613
00:40:47,400 --> 00:40:53,080
the topics mentioned in the interview, visit TwomoAI.com slash shows.

614
00:40:53,080 --> 00:40:58,520
Don't forget to check out our demo cast with Vila at TwomoAI.com slash Metaflow.

615
00:40:58,520 --> 00:41:03,080
And of course, be sure to subscribe to our YouTube channel while you're there.

616
00:41:03,080 --> 00:41:07,480
If you like what you hear on the podcast, please subscribe, rate, and review the show on

617
00:41:07,480 --> 00:41:09,520
your favorite pod catcher.

618
00:41:09,520 --> 00:41:20,160
Thanks so much for listening and catch you next time.

