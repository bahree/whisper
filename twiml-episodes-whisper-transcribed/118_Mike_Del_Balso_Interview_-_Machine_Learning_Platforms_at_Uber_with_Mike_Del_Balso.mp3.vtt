WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:32.240
I'm your host Sam Charrington.

00:32.240 --> 00:37.320
In this episode I speak with Mike Delbalso, product manager for machine learning platforms

00:37.320 --> 00:38.920
at Uber.

00:38.920 --> 00:43.520
Mike and I sat down last fall at the Georgian Partners portfolio conference to discuss

00:43.520 --> 00:48.560
his presentation, finding success with machine learning in your company.

00:48.560 --> 00:53.080
In our discussion, Mike shares some great advice for organizations looking to get value

00:53.080 --> 00:54.840
out of machine learning.

00:54.840 --> 00:59.200
He also details some of the pitfalls that companies run into, such as not having the proper

00:59.200 --> 01:04.480
infrastructure in place for maintenance and monitoring, not managing their expectations,

01:04.480 --> 01:09.080
and not putting the right tools in place for data science and development teams.

01:09.080 --> 01:14.560
On this last point, we touch on the Michelangelo platform, which Uber uses internally to build,

01:14.560 --> 01:19.240
deploy and maintain machine learning systems at scale, and the open source distributed

01:19.240 --> 01:22.800
TensorFlow system they've created, Horavod.

01:22.800 --> 01:29.600
This was a very insightful interview, so get your notepad ready.

01:29.600 --> 01:33.760
Before we jump in, over the last few weeks, you've heard me talk quite a bit about our

01:33.760 --> 01:40.000
MyAI contest, which explores the role we see for AI in our personal lives.

01:40.000 --> 01:44.760
We receive some outstanding entries, and now it's your turn to check them out and vote

01:44.760 --> 01:46.280
for a winner.

01:46.280 --> 01:51.880
Do this by visiting our contest page at twimmolai.com slash MyAI.

01:51.880 --> 01:57.640
Voting remains open through Sunday March 4th at 11.59 pm Eastern time.

01:57.640 --> 01:59.520
One more quick announcement.

01:59.520 --> 02:05.720
Join us on Tuesday, March 13th for the next Twimmol Online Meetup, in which our presenter,

02:05.720 --> 02:10.840
Sean Devlin, will be doing an in-depth overview of reinforcement learning and presenting

02:10.840 --> 02:16.360
the Google Deep Mind paper, playing Atari with deep reinforcement learning.

02:16.360 --> 02:21.560
Head on over to twimmolai.com slash Meetup for full details.

02:21.560 --> 02:26.280
And now on to the interview.

02:26.280 --> 02:33.080
Hey everyone, so I am here at the Georgian Partners Conference, and I have the pleasure

02:33.080 --> 02:39.160
of being here with Mike DelBalso, Mike is the product manager for machine learning platforms

02:39.160 --> 02:40.160
at Uber.

02:40.160 --> 02:42.400
Yep, Mike, welcome to this week in machine learning and AI.

02:42.400 --> 02:44.400
Thanks, happy to be here.

02:44.400 --> 02:49.360
It's awesome to have you, and I especially love it when folks tell me that they actually

02:49.360 --> 02:51.880
listen to the show before I'm about to interview them.

02:51.880 --> 02:54.280
Yeah, I listen to almost every episode at the gym.

02:54.280 --> 02:56.240
Oh wow, nice, nice.

02:56.240 --> 02:59.360
Do you like, do you put it on like 1.5x or my guy?

02:59.360 --> 03:00.360
I actually do.

03:00.360 --> 03:05.080
I have some thing where other people can't stand it, like when I play podcasts for my

03:05.080 --> 03:11.320
friends, but it's got some setting to skip spaces and to just go 1.5x, so it just sounds

03:11.320 --> 03:14.120
really weird, but I got you so used to what it doesn't bother me.

03:14.120 --> 03:15.120
That's fun.

03:15.120 --> 03:19.400
I listen to a ton of audio books and podcasts, and I tend to listen to it one and a half

03:19.400 --> 03:24.800
x, and you know, it's still the point where like if I hear the person slow down, they

03:24.800 --> 03:25.800
sound all weird.

03:25.800 --> 03:26.800
Yeah.

03:26.800 --> 03:30.920
I'm like really weird and slow talking, and it's not the point I was expecting.

03:30.920 --> 03:35.920
But yeah, there's actually like little jingles in front of different podcasts that when

03:35.920 --> 03:40.920
I listen to it at 1x, it just sounds weird, like because it's all down pitched or whatever,

03:40.920 --> 03:42.520
I don't know, it's weird.

03:42.520 --> 03:44.560
So I guess this podcast has that too, right?

03:44.560 --> 03:45.560
There's a little jingled.

03:45.560 --> 03:48.200
Yeah, I'm not even going to try to repeat this.

03:48.200 --> 03:49.200
Don't do it.

03:49.200 --> 03:52.200
It's called robot race.

03:52.200 --> 03:53.280
But yeah.

03:53.280 --> 03:58.480
So you know the routine, right, how do you get started in machine learning and AI?

03:58.480 --> 04:05.840
Yeah, so I'm a trained electrical engineer and right on, and so we're in Toronto right

04:05.840 --> 04:12.520
now, and I went to University of Toronto, and when I graduated, I got hired as an associate

04:12.520 --> 04:20.080
product manager at Google, and the associate product management program is the way that

04:20.080 --> 04:24.880
they hire product managers directly out of school, and it's a rotational program.

04:24.880 --> 04:29.120
So they put you on one team for about a year, and then you switch, and they put you on

04:29.120 --> 04:32.120
another team for a year, and then you can switch again if you want.

04:32.120 --> 04:36.200
And so my first role was on maps, and I worked on maps, data, kind of stuff, and then my

04:36.200 --> 04:39.840
second role was on Google's ads auction team.

04:39.840 --> 04:46.600
And I was the product manager for some of the teams that generate a lot of the machine learning

04:46.600 --> 04:50.920
predictions for the ads auction.

04:50.920 --> 04:55.480
And so the kinds of predictions you'd want to make are, you know, how relevant is this

04:55.480 --> 05:00.840
ad to the query that somebody is searching for, or how likely do we think someone is to

05:00.840 --> 05:05.200
click this ad, so just a tangential little product at Google.

05:05.200 --> 05:06.200
It was super important.

05:06.200 --> 05:11.320
It was really interesting because it was super important, and we would make changes that

05:11.320 --> 05:18.960
would have gigantic financial impacts, but you know, it's a lot of really big numbers

05:18.960 --> 05:22.640
and dollars that you work with, and you could be hundreds of millions of dollars change

05:22.640 --> 05:23.840
you'd make.

05:23.840 --> 05:30.440
But at the same time, you work with really small numbers where you are working on a project

05:30.440 --> 05:35.520
that you think is going to improve something or some other metric by 0.01 percent, and

05:35.520 --> 05:39.120
you'll be happy that you squeezed out another 0.1 percent, but really it translates to

05:39.120 --> 05:40.120
a lot of money.

05:40.120 --> 05:41.120
Wow.

05:41.120 --> 05:46.400
It's like really interesting place to work, and there's some pretty unique things about

05:46.400 --> 05:48.960
working on that team.

05:48.960 --> 05:55.920
One, those machine learning models that we ran were, I think, had some of the strictest

05:55.920 --> 05:59.720
requirements for stability in the industry, so, you know, we didn't want any downtime

05:59.720 --> 06:03.840
in the ad system, so we had a whole bunch of infrastructure to support that.

06:03.840 --> 06:04.840
Okay.

06:04.840 --> 06:07.760
Also, super large scale, super real time.

06:07.760 --> 06:13.680
We have to score a whole bunch of ads at query time and return to all these scores and

06:13.680 --> 06:20.120
run a whole crazy auction really quickly, and it's just a complex problem to try to predict

06:20.120 --> 06:25.800
if you're going to click on an ad, and so we tried to do a really good job of it, but

06:25.800 --> 06:27.360
it's always like you can always do more.

06:27.360 --> 06:31.920
So that, I learned a lot about machine learning on those teams, and probably set you up to

06:31.920 --> 06:35.280
learn a ton about the importance of platforms for machine learning.

06:35.280 --> 06:41.360
Yeah, we had our own infrastructure to support us in the machine learning space that helped

06:41.360 --> 06:45.520
us train models and evaluate them in real time and all that kind of stuff.

06:45.520 --> 06:51.720
So I think most importantly though, is I learned a lot about best practices on machine learning,

06:51.720 --> 06:57.760
and I learned that at a time when machine learning was still pretty new for a lot of people,

06:57.760 --> 07:05.480
and I think even today, we're at a point where best practices for machine learning aren't

07:05.480 --> 07:13.400
as widely established as best practices for regular software development, like checking

07:13.400 --> 07:18.200
your code and use Git and run tests before you submit stuff, and et cetera.

07:18.200 --> 07:21.200
And that kind of stuff is just not as well established for machine learning.

07:21.200 --> 07:27.680
So it's part of those best practices are kind of what I learned on those teams.

07:27.680 --> 07:31.560
And so I've been there for a while, and then I joined, about two years ago, I joined

07:31.560 --> 07:37.800
Uber as the product manager for what was pretty much the only machine learning team at the

07:37.800 --> 07:45.160
time, and we began building a machine learning platform, which today is known as Michelangelo,

07:45.160 --> 07:52.160
and we recently wrote a blog post and published it to explain what Michelangelo is all about.

07:52.160 --> 07:58.960
Yeah, basically that's a system to allow internal people within Uber to build machine learning

07:58.960 --> 08:06.560
systems, and deploy them, and monitor them, and maintain them at scale within Uber.

08:06.560 --> 08:14.160
And so our customers are teams like the team who's trying to predict ETAs, like how long

08:14.160 --> 08:18.000
it will take a car to get to you, or the Uber Eats team.

08:18.000 --> 08:20.800
Can you tell them I think they need to work on that a little bit more?

08:20.800 --> 08:25.760
I'm working on it, man, and we've got a whole roadmap to improve this stuff.

08:25.760 --> 08:35.120
But I mean, that really touches on real kind of product implications of using machine

08:35.120 --> 08:42.360
learning, which is like how do you communicate and design for uncertainty, because you know

08:42.360 --> 08:47.480
machine learning, you're inherently, you're making a prediction, and often a lot of use

08:47.480 --> 08:54.440
cases a system will ask for, give me your best prediction, give me one number back.

08:54.440 --> 08:58.040
But often a system will kind of know like a distribution, like I think it's going to

08:58.040 --> 09:06.040
be in this range, and so we try to, when we can, provide like a range of our confidence

09:06.040 --> 09:10.240
intervals for how long we think it will take some process to happen, and I think we do

09:10.240 --> 09:16.840
that well in Uber Eats, but the product requires a single number in ETAs, and it's hard

09:16.840 --> 09:17.840
to, right?

09:17.840 --> 09:22.760
It's funny how much of this ends up being just kind of UX UI, right?

09:22.760 --> 09:28.480
Like if it said, you know, four to eight minutes, it would be, I think a lot more palatable

09:28.480 --> 09:31.560
than four, and then eight the next time you look at it.

09:31.560 --> 09:32.560
Yeah, right.

09:32.560 --> 09:40.120
Yeah, it's also the kind of thing where we have to work with designers a lot to explain

09:40.120 --> 09:46.160
to them the uncertainty that comes with these machine learning systems and help them

09:46.160 --> 09:52.400
understand what level of confidence we actually have with these numbers, so that they can understand

09:52.400 --> 09:58.040
what the user experience will be from, like once they get these values, once they get

09:58.040 --> 10:03.160
the predictions back, but ETAs are inherently a really challenging thing.

10:03.160 --> 10:07.880
Like there will be construction on the street, and then your model has to adapt really

10:07.880 --> 10:10.720
quickly, and it's a tough engineering problem to solve.

10:10.720 --> 10:12.720
Yeah, yeah.

10:12.720 --> 10:17.880
If only users thought about how tough the engineering problems were, when they were waiting

10:17.880 --> 10:18.880
for their Uber.

10:18.880 --> 10:21.560
I think they shouldn't worry about it, and we should just make it a good experience,

10:21.560 --> 10:24.840
and they don't have to even consider anything about implementation.

10:24.840 --> 10:29.920
Should be magical, and that's kind of like what we're trying to do at Uber is make transportation

10:29.920 --> 10:33.880
as reliable as running water, so you don't have to worry about anything, you just open

10:33.880 --> 10:37.400
up the app and call it right, and the ride comes to you.

10:37.400 --> 10:38.400
Right, right.

10:38.400 --> 10:41.520
I want to talk about Michelangelo, I also want to talk about the presentation you did

10:41.520 --> 10:47.080
here, because you spoke here at the George and Partners conference.

10:47.080 --> 10:49.840
Do you talk about Michelangelo in your presentation?

10:49.840 --> 10:55.160
I think I intended to mention it, plug it, but I don't think I actually got to it in the

10:55.160 --> 10:56.160
presentation.

10:56.160 --> 10:57.160
Okay.

10:57.160 --> 11:00.080
I mean, I'm happy to chat about what that's about.

11:00.080 --> 11:07.760
We'll put that on the stack, also HoraVod, you've just announced HoraVod, and that came

11:07.760 --> 11:14.880
up in our last, the Toma Long Island meetup, someone mentioned that they saw the news,

11:14.880 --> 11:19.880
and we discussed that for a little bit, so I'd love to hear kind of you riff on that for

11:19.880 --> 11:24.280
a bit, but let's start with kind of the presentation, and we'll see where that takes us.

11:24.280 --> 11:25.280
Yeah, okay.

11:25.280 --> 11:36.720
So, I gave a 20, 30 minute talk at this conference today, and I tried to get across the

11:36.720 --> 11:43.920
main idea that I tried to get across in this talk, is that to actually get enterprise

11:43.920 --> 11:49.080
value out of using machine learning systems, a building of applying machine learning in

11:49.080 --> 11:56.560
your company, there's a lot more to do, and a lot more to get right than just choosing

11:56.560 --> 12:02.600
the right algorithm, and a lot of people focus on what's the right algorithm to use when

12:02.600 --> 12:09.960
you see most of the news we see about machine learning is, so and so came up with an advancement

12:09.960 --> 12:15.640
in AI that lets us beat this other thing, a new accuracy metric, and stuff like that,

12:15.640 --> 12:21.240
and that's great, and it's totally like a research frontier that's super valuable to

12:21.240 --> 12:27.920
have, but what practically I deal with, and a lot of the basic machine learning problems

12:27.920 --> 12:35.920
that we deal with day to day, in most use cases in a company, are issues that can be adequately

12:35.920 --> 12:42.280
handled with a very few algorithms, we can apply like grading boosted decision trees

12:42.280 --> 12:52.320
or random forests to a large number of classification problems, and receive acceptable results.

12:52.320 --> 12:57.840
And so I forget the stat, but some astounding number of Kaggle competitions are

12:57.840 --> 13:10.520
basically just unsumbles of them, and so if you're trying to extract value practically

13:10.520 --> 13:14.320
in your company and make systems that really use this stuff, the bottlenecks usually

13:14.320 --> 13:19.400
are not there in which algorithm you're choosing, maybe if you're building self-driving

13:19.400 --> 13:24.120
cars and stuff where you're really pushing the limits of what AI can do today, then

13:24.120 --> 13:30.160
you're dealing with not a lot more, but we deal with a lot more challenges related

13:30.160 --> 13:37.560
to infrastructure and data, and things like that that are closer to typical engineering

13:37.560 --> 13:43.360
problems, that people usually have to put a little bit more effort to think about how

13:43.360 --> 13:49.960
to do that correctly in the machine learning paradigm, so in my talk, I was talking about

13:49.960 --> 13:58.560
a few different areas in which there are pitfalls where people typically don't, there could

13:58.560 --> 14:03.040
be things that if you don't have experience, you don't think about this ahead of time

14:03.040 --> 14:09.000
and you're not planning on dedicating time to solving these problems, or it could just

14:09.000 --> 14:13.440
be tricky things to get right even if you know what you're doing, and so one area is

14:13.440 --> 14:18.280
technically just infrastructure, solving the infrastructure that goes around your machine

14:18.280 --> 14:22.280
learning system, so if you're in grad school and you're learning machine learning, you're

14:22.280 --> 14:29.520
a data scientist, as that is, you get really good at training a Python model, or an R model

14:29.520 --> 14:37.000
here, output you're deliverable from that often is a scikit-learn Python object, or maybe

14:37.000 --> 14:44.400
something you can export to, like a PMML format, but that's just one part of the story.

14:44.400 --> 14:49.800
Even if you have a great model, there's a lot more infrastructure around your machine

14:49.800 --> 14:54.080
learning system that you need to integrate well, integrate with wealth.

14:54.080 --> 14:59.280
For example, you need a logging system that is aware of the machine learning use case

14:59.280 --> 15:04.520
that can store historical data in a way that's compatible with what your machine learning

15:04.520 --> 15:08.200
system wants to do with that data, and the future one is training a model on it, or you

15:08.200 --> 15:15.960
need a monitoring system to be able to accurately monitor and evaluate your model's accuracy

15:15.960 --> 15:20.240
over time, so you can determine if your model that you're using in production becomes

15:20.240 --> 15:24.840
stale, and you need to either retrain it, or if you have some other system that's automatically

15:24.840 --> 15:29.080
retraining things, you need a whole bunch of infrastructure to manage that, automatically

15:29.080 --> 15:36.800
train, evaluate, deploy a lot of that stuff, and so my point there is that there's a large

15:36.800 --> 15:41.960
engineering investment to go alongside the basic work on the algorithms, that a lot

15:41.960 --> 15:46.480
of people overlook, and when people think like machine learning is magic, it's really

15:46.480 --> 15:51.800
not magic, you still got to put a lot of work into it, so that's kind of one area, is

15:51.800 --> 16:02.600
that lead you to, like is there for a mature company, or a company who's doing machine learning

16:02.600 --> 16:07.840
a scale, is there like a magic ratio of data scientists to engineers?

16:07.840 --> 16:15.560
That's a good question, well, you know, I'm building Michelangelo, which is, we have

16:15.560 --> 16:23.440
almost exclusively engineers building that, and our customers are a mix of data scientists

16:23.440 --> 16:28.600
and engineers, so the teams that are using our system to actually build these models and

16:28.600 --> 16:34.120
run them in production, it's usually like half and half engineers in data scientists,

16:34.120 --> 16:40.160
and there's a blurry line between engineer and data scientists sometimes, and so there's

16:40.160 --> 16:44.680
often a lot of engineers who just know enough about machine learning that they don't need

16:44.680 --> 16:48.560
to consult data scientists and they can understand enough about these models to be confident

16:48.560 --> 16:54.800
about them, and it doesn't frequently, I don't see it going the other way too much, there's

16:54.800 --> 17:00.320
not often like a data scientist who's running like a production system, but I mean, that

17:00.320 --> 17:05.960
can happen, that wouldn't surprise me if I saw that, so it seems to be that they'll

17:05.960 --> 17:10.360
be paired, so you have data scientists working with kind of this new breed of engineer called

17:10.360 --> 17:15.240
the machine learning engineer that has kind of that base level understanding of models.

17:15.240 --> 17:16.240
Are you?

17:16.240 --> 17:23.480
So what we have at Uber is kind of like the nucleus of a team is an engineer, the team

17:23.480 --> 17:32.080
of engineers, usually one product manager, and a couple of data scientists, and being

17:32.080 --> 17:36.000
an engineer is not just one skill set, and so there are engineers who are very data-focused

17:36.000 --> 17:41.080
engineers or there's UI engineers and the whole spectrum of it, and so usually the folks

17:41.080 --> 17:48.280
that partner most closely with data scientists are the more data-minded engineers, but they're

17:48.280 --> 17:53.400
not necessarily folks with machine learning specialties, and even on my team on a Michelangelo

17:53.400 --> 17:59.320
team, most of the work that you end up doing to run a production machine learning system

17:59.320 --> 18:05.160
is data pipeline, work floor stuff, and so I would say probably even most of our engineers

18:05.160 --> 18:11.760
are just like data engineers, infrastructure engineers, systems engineers, folks that have

18:11.760 --> 18:17.120
picked up a lot of important machine learning concepts, but do not have like PhDs in machine

18:17.120 --> 18:24.240
learning or something like that. And so the idea behind Michelangelo is that you can invest

18:24.240 --> 18:30.360
in building this platform, and then the data scientists can focus on the machine learning

18:30.360 --> 18:34.720
and not have to think about the logging and the monitoring and all of these, you know,

18:34.720 --> 18:37.960
the life cycle of it deploying and managing a model of production.

18:37.960 --> 18:44.720
Yeah, exactly. So, you know, about two years ago when we started Michelangelo, there were

18:44.720 --> 18:50.880
a lot of teams who either were trying to put machine learning systems into production

18:50.880 --> 18:56.760
and building their own production stack for it, and different teams were doing the similar

18:56.760 --> 19:02.840
thing, but they were all these bespoke solutions that we're not, you know, if you're building

19:02.840 --> 19:09.640
something for a specific use case, it's unlikely to be supported with a proper engineering

19:09.640 --> 19:13.120
investment, and it's unlikely to generalize well when you want to expand your use case

19:13.120 --> 19:21.400
and somewhat brittle and stuff like that. So there was a clear, a clear need for a platform

19:21.400 --> 19:27.320
to help these teams put something into production and manage something in production, but, you

19:27.320 --> 19:33.960
know, our goal is to support everything from the exploration side of the data science

19:33.960 --> 19:39.400
workflow all the way to production, managing something, maintaining something in production

19:39.400 --> 19:45.760
and a whole operational side of it. I would say that we, our particular focus is putting

19:45.760 --> 19:53.760
things into production. It's a much harder problem to solve that helping the teams would

19:53.760 --> 19:57.480
like the model exploration stuff. You know, data scientists have their own tools that

19:57.480 --> 20:05.600
they like using, and it's hard to do much better than psychic learn and just letting

20:05.600 --> 20:10.280
a data scientist just iterate really rapidly with the tools that they're used to, but when

20:10.280 --> 20:16.280
it comes time for them to like begin using that system in production, the, and usually

20:16.280 --> 20:20.360
need to rely on an engineering solution, and that's where our platform comes in.

20:20.360 --> 20:24.560
Okay. And so you mentioned logging, you mentioned monitoring, are there other kind of main

20:24.560 --> 20:29.880
features of the platform? Well, I was suggesting that there's, there's actually like all kinds

20:29.880 --> 20:35.840
of infrastructure, whether it's a machine learning platform or not, that you want to have

20:35.840 --> 20:41.280
aware of the machine learning use case. And there's also types of infrastructure that you

20:41.280 --> 20:45.480
would, that is machine learning specific that you might need to build. So there's a thing

20:45.480 --> 20:51.080
that we built, which is a feature store. And so that allows teams to share and discover

20:51.080 --> 20:58.280
features. So if you are building the model that predicts how long a restaurant's going

20:58.280 --> 21:04.960
to take to prepare meal for Uber Eats, maybe the model that I'm building would be able

21:04.960 --> 21:09.200
to benefit from some of the features that you're using in your model. And so it took

21:09.200 --> 21:12.840
way for us to share features. So I don't have to duplicate all the data pipelines to create

21:12.840 --> 21:18.880
those features. And is that, does something like that exist as like a kind of a metadata

21:18.880 --> 21:25.760
catalog that is, you know, mirrors a data store like a HDFS or something like that?

21:25.760 --> 21:31.160
Yeah. So for us, practically, we have, you can do a few things, but basically we manage

21:31.160 --> 21:35.640
metadata, metadata layer to understand where these features are stored. And it is all

21:35.640 --> 21:40.400
in like high HDFS and other people can contribute to it. Or we have this other way where we

21:40.400 --> 21:47.960
manage some core set of features. And, and yeah, we're still figuring out like how we can

21:47.960 --> 21:54.680
make that most usable to other teams. Right. And really nail the, the sharing of this

21:54.680 --> 22:00.760
data use case because there's, it's, it's, I mean, like it's super tricky because if

22:00.760 --> 22:05.840
you're building a production system, you are going to be hesitant to rely on a data

22:05.840 --> 22:10.560
set that you don't own. Right. And you don't know if that person is going to change that

22:10.560 --> 22:14.120
how it's calculated the next day and it messes up your system. So we're trying to like

22:14.120 --> 22:20.240
figure out the right contracts are to guarantee certain data stability and quality and stuff

22:20.240 --> 22:26.120
like that. Like how far along are you on? We have what it even means to have a contract.

22:26.120 --> 22:32.640
Like it's, it's hard enough for services, which have a fairly, you know, small surface

22:32.640 --> 22:40.040
area. Right. Of the, the API, but the, it strikes me that data has a much more kind

22:40.040 --> 22:44.520
of expensive surface area around what you need to try to define a contract. Yeah. I,

22:44.520 --> 22:51.840
like, I, I haven't spent enough time on this area to, to have really figured out where,

22:51.840 --> 22:56.040
where we actually want it to be. So I can't even say if we're 20% there or 50% there,

22:56.040 --> 23:00.040
you know, like, because I really don't know how much you want to do in this space. So

23:00.040 --> 23:03.840
that's, that's tricky. I think it's an area that we probably want to prioritize more.

23:03.840 --> 23:07.920
Yeah. And like another thing that comes along with that is, you know, that's HDFS hive.

23:07.920 --> 23:12.280
That's all offline stuff that's ready for batch processing. Right. But there's a whole

23:12.280 --> 23:18.000
other side to this where if you're running a online prediction model, you want these features

23:18.000 --> 23:24.800
to be generated in real time. And so you might have some real time stream processing

23:24.800 --> 23:29.480
stuff that will calculate those same features. And you want them to be calculated in the

23:29.480 --> 23:35.560
same way as you calculated your offline batch data that you trained your model on. But

23:35.560 --> 23:38.560
you're calculating these features in real time and then making them available to your

23:38.560 --> 23:43.200
model so your model can score. Right. You know, and this could be like understanding how

23:43.200 --> 23:49.360
many, a good example is how many meals has this restaurant? How many orders does this restaurant

23:49.360 --> 23:54.280
gotten in the past 30 minutes? And that might be like a window figure out how you're going

23:54.280 --> 24:00.240
to accumulate. And it's like you, you've got your, this repository that says what your

24:00.240 --> 24:05.040
features are. And then you've got your, you know, you're kind of your meta meta that's

24:05.040 --> 24:12.320
like how you derive the features from the underlying stream of data. Yeah. It's, it's a, it's

24:12.320 --> 24:18.840
and so you can imagine there's a large activation energy to set up a system like that. And so

24:18.840 --> 24:24.440
that's part of the value of having a platform that builds all this infrastructure and plugs

24:24.440 --> 24:28.160
it all together nicely. So you just need to provide a configuration and say, hey, use this

24:28.160 --> 24:33.360
data and give me this real time feature. Right. And that, you know, we found that that

24:33.360 --> 24:38.840
kind of infrastructure has really lowered the activation energy. So we've allowed like

24:38.840 --> 24:42.360
those teams were building these spoke solutions. We built a good system for them and they've

24:42.360 --> 24:47.880
kind of pivoted onto our system and begun using our system. But also there's teams that

24:47.880 --> 24:51.920
before didn't have the resources to even take on a machine learning project, but they've

24:51.920 --> 24:57.920
known that they want to have some kind of predictive solution in their product. And, and the

24:57.920 --> 25:02.640
lower activation energy to get started has kind of helped them unlock that and they've been

25:02.640 --> 25:06.840
able to fund a product because the, or such a project because the cost has come down

25:06.840 --> 25:12.840
so much. Nice. Nice. Now, so we've talked primarily around what I kind of roughly think

25:12.840 --> 25:19.200
of as engineering facing features and infrastructure. But there's a whole set of operational I, you

25:19.200 --> 25:26.160
know, operationalizing features. You may remember me getting into part of this conversation

25:26.160 --> 25:30.400
in an interview with Jennifer, Jennifer Prinky, who is at Walmart Labs at the time, not

25:30.400 --> 25:35.360
too long ago. And kind of the direction that they were heading. And I could see Michelangelo

25:35.360 --> 25:40.080
going in this direction. If it's not already is, you know, you've got a model in production.

25:40.080 --> 25:47.080
Like, are you tracking kind of either statistical drift of the inputs or, you know, model accuracy,

25:47.080 --> 25:52.440
you know, decreasing over time. And then like automatically triggering or at least like

25:52.440 --> 25:57.880
setting a ticket or something like that to reevaluate the model. So the kind of the

25:57.880 --> 26:03.280
full like service level impact of these models. Do you get into that at all? So this is,

26:03.280 --> 26:07.600
we do get kind of into it. And this is an area that we're really trying to focus on over

26:07.600 --> 26:12.920
the next couple of months is build out a lot of, there's a lot of things you would want

26:12.920 --> 26:18.600
to do to operationalize and maintain such a model. So things like tracking the data quality

26:18.600 --> 26:24.560
both in and out of your model. So you might want to do things like track feature distributions

26:24.560 --> 26:29.280
over time and real time. So all the data is coming into your model. Does it look different

26:29.280 --> 26:35.560
in this five minutes than it looked in right past? And you might compare that to the distribution

26:35.560 --> 26:39.760
of data that you saw an hour ago, but also like the historical distribution of like the past

26:39.760 --> 26:44.800
two years of data like that. And right. Has that changed? I mean, you just start

26:44.800 --> 26:50.040
in a rough way. I go ahead. When we were talking about, you know, data and contracts

26:50.040 --> 26:54.960
around data and models like one of my thoughts was, you know, is part of that contract like

26:54.960 --> 26:59.640
a statistical distribution of the data at a point in time so that you can refer back

26:59.640 --> 27:03.720
to, you know, what you thought that data looked like when you built the model. Right. So

27:03.720 --> 27:09.200
you can, so that's not something that we would necessarily want the customer to explicitly

27:09.200 --> 27:14.880
provide, but it would be something that we may be able to extract from the training data.

27:14.880 --> 27:18.640
So we might be able to say like, look, this is the distribution of the data we saw at

27:18.640 --> 27:25.000
training time. Right. It's kind of save a snapshot of the summer summary statistics and then

27:25.000 --> 27:30.240
compare our normal like the data we see in real time to the statistics. And so sometimes

27:30.240 --> 27:35.320
like, you know, your training data, you might rebalance classes and reweight things and stuff

27:35.320 --> 27:40.240
like that. And so there's some complication to take that stuff into account. And so this

27:40.240 --> 27:43.320
is some of the challenges that we're working through right now. Okay. But then there's also

27:43.320 --> 27:48.240
the other side of like doing the same data quality checks on the output of your model.

27:48.240 --> 27:55.040
Like the predictions and, you know, doing the same statistics tracking stuff. And you would

27:55.040 --> 28:02.520
also want to have alerting happen on that kind of thing. And that's all part of this like

28:02.520 --> 28:09.000
larger infrastructure integration story because your company should have a way to, you

28:09.000 --> 28:13.400
know, like set up alerts for production systems. And so you just want to integrate with the

28:13.400 --> 28:21.360
basic stuff that you have. Cool. So we didn't get very far in your presentation. So I was

28:21.360 --> 28:26.560
talking a lot about like infrastructure side, which is the summary is you got to do a lot

28:26.560 --> 28:33.280
of engineering work before you get into to put one of these models into production properly.

28:33.280 --> 28:38.800
There's also another part of it, which is, you know, building tools to help the data

28:38.800 --> 28:45.200
scientists do their job properly, both correctly and productively. And so, you know, there's

28:45.200 --> 28:52.200
many parts of the data science workflow. And, you know, if you leave data scientists,

28:52.200 --> 28:57.480
if you don't support them with the proper tools, then they may be building systems in a

28:57.480 --> 29:01.280
non reproducible way. So there's not a way to like recreate the model. If you need to

29:01.280 --> 29:06.120
retrain it, it may not be all version and like checked in and source control and stuff

29:06.120 --> 29:15.240
like that. And you may not even have standardized ways to evaluate these models. So you may just

29:15.240 --> 29:22.040
waste a lot of cycles comparing data scientists as evaluations to data scientists, bees evaluations.

29:22.040 --> 29:26.040
Because there's not a common set of metrics that everybody's agreed on ahead of time. So

29:26.040 --> 29:31.160
there's some work to provide some infrastructure for them as well. And so the future store is

29:31.160 --> 29:37.480
one example. It gives a kind of like common source of truth. But beyond the technical stuff,

29:38.440 --> 29:46.520
there's a lot of organizational considerations when you're trying to make the most out of

29:46.520 --> 29:53.000
machine learning in your company. So, you know, one thing that's important to understand is that

29:53.720 --> 29:59.720
not everyone's an expert at machine learning. And people come with different levels of

29:59.720 --> 30:06.760
abilities and background knowledge of machine learning. So that leads to a lot of times when

30:07.480 --> 30:11.720
people have false conclusions about how machine learning can be applied to their problem. So

30:11.720 --> 30:15.720
some people will tell me, well, I don't think machine learning can help with my problem at all.

30:15.720 --> 30:20.760
So we don't need to like have a collaboration. And then when we look into it, we realize, oh,

30:20.760 --> 30:25.160
well, actually the main problem you're trying to solve is pretty appropriate for a machine learning

30:25.160 --> 30:31.560
solution. Or there's folks who have told me have kind of conveyed that they believe machine learning

30:31.560 --> 30:35.320
is basically magic. And they think it can solve all of their problems. And that's a kind of thing

30:35.320 --> 30:42.040
where you really want to understand those expectations and adjust those expectations to be

30:42.040 --> 30:48.920
much more realistic. So you don't have a problem down the line of completely missed expectations.

30:48.920 --> 30:55.800
But then there's also people who are almost like overconfident about what they know about

30:55.800 --> 31:01.640
machine learning and they request specific algorithms or specific implementation. And the

31:01.640 --> 31:07.560
example I get in the talk with someone once asked me mentioned that they need unsupervised

31:09.080 --> 31:14.600
online, deep reinforcement warning or something like that. And I was like, okay,

31:14.600 --> 31:19.720
it's like, I don't know if that's a thing, but we should understand where your problem is. So

31:19.720 --> 31:24.120
so like the way to handle most of these situations is to not really focus on the machine learning

31:24.120 --> 31:28.600
part of it, but to really just like talk to these people and understand what the business

31:28.600 --> 31:33.720
problem they're trying to solve is and not involve machine learning vocabulary. And you know,

31:33.720 --> 31:38.600
I'm the product manager of our team. So part of my role is to understand the business problem

31:38.600 --> 31:45.160
and find a way to translate it into a machine learning problem, something that we would be able

31:45.160 --> 31:49.560
to solve and understand also the need to be able to solve or something that you'd be able to support

31:49.560 --> 31:55.720
with both. So we have we also have an applied machine learning team that we that we

31:56.920 --> 32:01.480
is like a tiger team that supports the different engineering groups. Yeah, it's kind of like a

32:01.480 --> 32:09.160
set of machine learning specific data scientists that these folks may be able to like put on loan

32:09.160 --> 32:13.800
to a team to help them solve a machine learning problem if they don't have the resources when it's

32:13.800 --> 32:18.760
a particularly relevant and important machine learning problem. So yeah, so like I hope kind of

32:18.760 --> 32:23.800
coordinate these these types of problems. And yeah, so we figure out like if it's a relevant

32:23.800 --> 32:29.240
problem and how we might be able to solve it. And ultimately I'm trying to understand the

32:29.240 --> 32:35.160
the business metrics that these people are trying to optimize for and understand the mechanisms

32:35.160 --> 32:39.080
that the whole product works. So what do they think actually affects those business metrics?

32:39.080 --> 32:45.240
And then I'm trying to translate that problem into for for our data scientists or for even for

32:45.240 --> 32:50.600
their data scientists who might need help with it. Like a machine learning problem that

32:51.640 --> 32:58.840
where if a data scientist is optimizing for precision recall or all the other kind of data science

32:58.840 --> 33:03.560
metrics that they would be used to that are related to machine learning as they optimize for those

33:03.560 --> 33:09.640
those would likely be an appropriate proxy for optimizing for these end business metrics. And so

33:09.640 --> 33:15.960
it doesn't always work out perfectly. But it's a good way to like start things off. And ultimately

33:15.960 --> 33:21.560
you want to have people who understand the whole problem end to end to really like think things

33:21.560 --> 33:29.160
through think things through. But it's a good way to get started in that kind of area. So like talking

33:29.160 --> 33:38.040
to people in the right at the right level of like vocabulary, you know focusing on the business

33:38.040 --> 33:43.240
problems, expectations making sure they don't think that machine learning's magic setting that

33:43.240 --> 33:52.200
properly. Another thing that I found useful is going out of my way to find a senior person in

33:52.200 --> 33:57.800
the company who really understands machine learning or like taking the time out to educate them

33:57.800 --> 34:03.320
about machine learning. So I can always have them on my side if I really need to ever need to defer

34:03.320 --> 34:09.000
to someone more senior. I know that there's someone there who will will either be sufficiently

34:09.000 --> 34:13.720
technically competent to be able to make the right call or that I've spent enough time with so

34:13.720 --> 34:18.840
that they'll trust me to make the call when it comes to that. So that I found that to be useful.

34:19.560 --> 34:26.040
And then another thing that is also useful for figuring out how to make the most out of machine

34:26.040 --> 34:30.200
learning is realizing that you're not going to have a machine learning, you're not going to have

34:30.200 --> 34:35.080
infinite machine learning experts. And so you have to find a way to make the most out of the limited

34:35.080 --> 34:39.880
number of machine learning experts you have. And what's the answer to that challenge? It's

34:39.880 --> 34:43.560
like how do you set up your org, right? It's like how do you how do you distribute your machine

34:43.560 --> 34:48.760
learning folks across the different teams? And there's different ways you can do it. So I mentioned

34:48.760 --> 34:57.320
that we have this applied group which is kind of like a solutions team in some sense where they

34:57.320 --> 35:04.920
they're a team of a few data scientists who are experts at machine learning and they kind of

35:05.720 --> 35:10.280
are out on loan to different teams that need help that don't have the machine learning expert

35:10.280 --> 35:14.360
keys. And so you can imagine there's these different engineering teams and then there's one

35:14.360 --> 35:19.320
kind of cluster of machine learning people on a separate team that loosely interacted those teams.

35:19.320 --> 35:24.040
But another model is you could just embed one machine learning person or one or two on each

35:24.040 --> 35:29.160
of those teams. And so that model is slightly more difficult to scale because you have a new

35:29.160 --> 35:34.600
team and then you need another machine learning person. And so I think we've experimented with

35:34.600 --> 35:41.320
different models. Different models will work well for different size companies. Often it's not

35:41.320 --> 35:47.240
just a binary thing but there could be like a hybrid where you might lean more to one side or another

35:47.240 --> 35:52.360
and in practice we might have things where our applied team might start off a project but then

35:52.360 --> 35:56.840
hand off a project to a data scientist on a product team at some point. So like thinking those

35:56.840 --> 36:02.520
things through explicitly ahead of time and being realistic about how many resources related to

36:02.520 --> 36:07.880
machine learning that you have that's pretty valuable. And so that kind of covers the organizational

36:08.520 --> 36:12.680
things you want to think about when you're launching machine learning systems. And then

36:13.640 --> 36:21.000
finally just like team focused things which are like how do you when you're running a machine

36:21.000 --> 36:27.080
learning project. What can you do to like organize your machine learning project to be set up for

36:27.080 --> 36:31.960
success. And there's a few things that are kind of just like questions you want to ask yourself

36:31.960 --> 36:37.880
and like rules of thumb you want to apply. So one is about like not artificially encapsulating

36:37.880 --> 36:44.040
the machine learning specific part separately from the non machine learning specific part of your

36:44.040 --> 36:49.080
project. Like you don't want the person who's building the model who's generating these scores

36:49.080 --> 36:53.400
to not know anything about how these scores are being used. And so there's a lot of

36:54.840 --> 36:59.640
like there's a lot of ways that these scores can be misused and a lot of like nuance and how

36:59.640 --> 37:06.280
these scores are generated. And we talked about the the inverse of that which is the designers

37:06.280 --> 37:11.640
and the app teams not really understanding the scores and the probabilistic nature of the scores.

37:11.640 --> 37:20.360
Yeah. So that's that's part of like how you would design a project to to a product rather to

37:20.360 --> 37:26.280
take make actually relevant use of the machine learning scores that you're providing. And then

37:26.280 --> 37:32.680
there's other examples of this which are more like you know your scores can be used in a way

37:32.680 --> 37:39.800
that they they were not intended to be used. And when they can even be used in a way that can

37:39.800 --> 37:43.480
harm your machine learning model. If you have a certain feedback loop where you know if you're

37:43.480 --> 37:50.840
trying to predict churn for example and then someone uses these scores to to provide some

37:50.840 --> 37:55.080
treatment to the people who are most likely to churn. And then they solve the churn problem for

37:55.080 --> 38:01.000
the 10% most likely to churn people. Then those people didn't churn. And then when you go to

38:01.000 --> 38:06.360
retrain your model next month or two months from now or whenever you'll not have those labels

38:06.360 --> 38:11.080
that those people churned. And so your training data is going to be kind of messed up. So that's not

38:11.080 --> 38:16.280
a it's not that's not like a particularly hard problem. But you just have to if you don't think

38:16.280 --> 38:19.960
about that ahead of time if you're not thinking this problem through end to end and you're not aware

38:19.960 --> 38:24.920
of how these scores are being used. Then you may not include that in your design of the whole system.

38:24.920 --> 38:28.360
And so your whole project might be flawed from the beginning. And there's a solution there to

38:28.360 --> 38:33.320
flush your your labels when you make changes like that. There's other things you could do. One could

38:33.320 --> 38:41.320
be just have a holdout set. So you just don't you never apply treatments to some x% of the people

38:41.320 --> 38:46.040
that you're making predictions for. So then you can always reserve them as like the control,

38:46.040 --> 38:52.840
the untouched people that you can train your model on in the future. Or you can even like a more

38:52.840 --> 38:59.240
advanced way is find a way to include that treatment in your modeling in the future. So your model

38:59.240 --> 39:03.880
is aware that maybe these people didn't turn. But it was because they got this treatment. And so

39:04.680 --> 39:08.520
this kind of that has more of a feedback loop. And this is more complicated. You need to think

39:08.520 --> 39:15.960
about it more deeply. But overall like I'm on the team side, it's you really want your folks that

39:15.960 --> 39:22.600
who have who really have an attitude of ownership of these systems to be the most involved here.

39:22.600 --> 39:28.360
You want them to be kind of almost like borderline paranoid about the the operation of these systems

39:28.360 --> 39:34.280
and asking questions like if the world changes, is my model going to be able to react to it?

39:34.280 --> 39:41.320
And how will my model react to it? Or like if how a feature is computed by the logging people

39:42.440 --> 39:47.480
or if it's how it's recorded changes slightly like the user different format to the store int now

39:47.480 --> 39:52.680
instead of a double. Is that going to mess up my number or my predictions? And how can I prevent that

39:52.680 --> 39:58.760
to happen from happening? Or like how will I notice if something's wrong or any number of things

39:58.760 --> 40:04.840
or even even like on these different dimensions like legal and cultural things like based on how

40:04.840 --> 40:11.080
these predictions are being used. Is there any bias that's inherent in this model? And will that have

40:11.080 --> 40:17.880
some impact in how the model is perceived like legally or culturally? And that's always a tricky

40:17.880 --> 40:22.520
problem. And often not just one person can think through all of these problems and you want

40:26.040 --> 40:30.040
like a kind of like a good citizenship attitude because no one's particularly

40:30.040 --> 40:33.960
singularly responsible for these issues. We just want people to really think things through

40:33.960 --> 40:38.840
and really own the system. So they are always feeling like they're doing the right thing here as well.

40:38.840 --> 40:44.040
Okay. So we covered I think the topics in your presentation. I wanted to make sure we hit

40:44.040 --> 40:52.360
on Horavod before we move on. What's that all about? So we have a lot of data over and we've been

40:52.360 --> 41:00.040
trying to get started running distributed TensorFlow. And we ran into a lot of issues. I'm just setting

41:00.040 --> 41:08.040
up the parameter server constellation and connecting everything together in the proper way. And

41:08.040 --> 41:15.320
we've got an engineer, Alex Sergeev, who's awesome. He's a genius. And he found a way to kind of

41:15.320 --> 41:22.360
improve upon the Bidews, a paper that Bidew published where they open source some code to

41:23.080 --> 41:31.400
do a different way to distribute the work in TensorFlow. And basically ripping out the guts of

41:31.400 --> 41:36.760
the distributed stuff and replacing it with open MPI. Exactly. Hearkens back to the great computing

41:36.760 --> 41:44.600
days. Yeah. So it uses like the ring all reduced methods. And you have, you know, you have, if you

41:44.600 --> 41:52.360
have n nodes, each node is only sending data to one other node and receiving from one other node.

41:52.360 --> 41:59.720
And there's no parameter servers. Only all the workers are communicating with other nodes and

41:59.720 --> 42:08.200
are averaging up gradients in that node itself. And so you kind of set up this ring of connections

42:08.200 --> 42:12.920
between like a circle, like an online them all in a circle. And so then if you pass one message

42:12.920 --> 42:20.680
through it will, and you keep iterating your message passing eventually, one signal will get

42:20.680 --> 42:25.000
all the way around and be distributed to all the nodes. It's much easier to understand visually.

42:25.000 --> 42:34.120
We run into that problem. But Alex built this awesome system that is called Horavod. Horavod is

42:34.120 --> 42:40.200
a Russian dance that people link arms in the circle. And so it's kind of like the right imagery

42:40.200 --> 42:48.920
there. And so he's been applying it to a lot of our distributed learning problems. And he's found

42:48.920 --> 42:56.200
that it's much easier to set up a distributed learning job in TensorFlow. So, you know, there's a

42:56.200 --> 43:02.200
lot of boilerplate code that you need to have in a existing parameter server TensorFlow paradigm

43:02.920 --> 43:08.920
to like allow it to all be distributed. And he's figured out a way to have only four lines of code

43:08.920 --> 43:14.840
that you need to add to a TensorFlow script to distribute it. And I've heard not great things about

43:14.840 --> 43:22.280
trying to distribute out of the box TensorFlow. It's pretty challenging. I don't know exactly what

43:22.280 --> 43:28.040
Google does internally. But I think they're probably working on an improvement.

43:28.040 --> 43:33.480
Lewis, from what I've heard, they're trying to, or at least, you know, someone is thinking that at

43:33.480 --> 43:37.880
some point, you know, they've got this Kubernetes thing. It's kind of good at distributed compute.

43:37.880 --> 43:42.120
They've got this TensorFlow thing. Hey, you know, somehow we can kind of get the chocolate and

43:42.120 --> 43:48.440
then the peanut butter together. Yeah, yeah. So I mean, I'm sure there's a whole team working on

43:48.440 --> 43:54.200
that in Google. And so this was just like Alex on our team needed to solve a problem for himself

43:54.200 --> 43:59.560
immediately. And so he built this system. And it's really easy. If you check out the blog posts we

43:59.560 --> 44:06.680
have to search Horavod. And this blog post is open source. And it's open source. You can just

44:06.680 --> 44:11.320
go download it and check out the sample code. And it's literally just add four lines to your TensorFlow

44:11.320 --> 44:18.520
script. And you're good to go. And here you describe it. It goes higher up and ripping out the

44:18.520 --> 44:24.360
guts than I even thought. Like I thought it was just like using kind of MPIs like a low,

44:24.360 --> 44:29.640
low level message passing thing. But it's also kind of changing the way gradients are distributed

44:30.360 --> 44:35.640
across the system. Yeah, it touches various layers there. So Alex has been able to use it too.

44:35.640 --> 44:43.240
Let me see. I think there was some model that took maybe like 10 days to train. And on our cluster

44:44.040 --> 44:48.760
with I don't remember the details. But in some real practical application, he was able to train

44:48.760 --> 44:54.280
this model in seven hours instead. Instead of how many nodes. I don't know how many he used in

44:54.280 --> 44:59.480
this particular thing. But we've trained stuff up to maybe 128 GPUs. That's right. Another that

44:59.480 --> 45:06.120
I mentioned that I remember the the graph that was in the blog post. And you get pretty darn

45:06.120 --> 45:12.200
close to ideal multipliers on the scale. It was pretty impressive. Yeah, it's pretty, I mean,

45:12.200 --> 45:20.520
it's a very large speed up for really big applications. And you know, you can imagine if you take

45:20.520 --> 45:23.880
10 days to train your model and suddenly you can train a model in seven hours, it changes

45:23.880 --> 45:29.080
your whole workflow. It changes like what your job is. Right. And so that team's productivity has

45:29.080 --> 45:35.320
been changed dramatically. And there's not that many use cases that absolutely need like so much

45:35.320 --> 45:42.360
data. So we're still trying to figure out if there's ways that it can be useful to speed up like

45:42.360 --> 45:48.840
smaller work a smaller use cases as well. But it's always something good to have because you know,

45:48.840 --> 45:52.120
people aren't going to begin training on less data. People are always adding more data. And so

45:52.120 --> 45:56.040
that's what's happening to our use cases. And is this an example of something that

45:56.040 --> 46:04.200
would get integrated into the Michelangelo platform or yeah, this is part of the Michelangelo

46:04.200 --> 46:09.000
platform. Yeah. And so I wasn't mentioned in our Michelangelo blog post, but we're working on

46:10.360 --> 46:18.200
kind of like a separate development, X model exploration, deep learning specific IDE kind of

46:18.200 --> 46:25.400
or IDs the wrong word. Like a framework or yeah, kind of like a framework for people to

46:25.400 --> 46:30.680
easily run containers and tends to flow and iterate on TensorFlow models and get a bunch of

46:31.240 --> 46:35.640
machines that they can like GPU machines so they can run these big distributed jobs.

46:35.640 --> 46:39.160
Okay. And then have ultimately have those models appear at Michelangelo so they can push them

46:39.160 --> 46:46.360
to production and evaluate stuff like that. And that's so that's how Horavod fits into Michelangelo.

46:46.360 --> 46:52.040
And I think we're just going to see a tighter and tighter integration in the future.

46:52.040 --> 46:58.200
So now Horavod is open source. Michelangelo is not. Michelangelo is not. I'm still trying to

46:59.080 --> 47:05.240
prioritize that in our roadmap. It's a lot of work to open source something. So don't blame me.

47:06.680 --> 47:12.280
A lot of people have gotten a lot of emails like, hey, so I couldn't find Michelangelo and GitHub.

47:12.280 --> 47:19.400
And I was like, oh, nice medium post. Sorry guys. But yeah, I hope to be able to open source

47:19.400 --> 47:25.320
at sometime. It's just not something we're working on right now. Well, it's I think

47:26.920 --> 47:31.720
as people deploy, you know, as people kind of productionalize machine learning more and more,

47:31.720 --> 47:38.200
like they run into this. They have to run into this. And at every place like, you know, the problem

47:38.200 --> 47:43.400
that you're trying to solve with Michelangelo, preventing data scientists and engineers at Uber

47:43.400 --> 47:47.480
from building this over and over again, we're doing this like on the scale of the industry.

47:47.480 --> 47:54.840
And, you know, there are like a handful of proprietary, you know, kind of all-in-one platforms that

47:54.840 --> 48:00.120
kind of solve some of it. And I forget the name of the company, but I recently came across a

48:00.120 --> 48:07.800
company that is, you know, their focus is trying to solve the kind of model lifecycle and production

48:07.800 --> 48:14.120
thing. But, you know, I think ultimately, you know, it's infrastructure, right? And infrastructure

48:14.120 --> 48:19.560
wants to be open source. Yeah, right. So, you got to shut open source it. I think it would be

48:19.560 --> 48:24.920
cool if we did. What's up with that? I'll bring that to feedback back. I'm arguing for it too.

48:26.280 --> 48:31.080
So, yeah, I think it would be cool if we did. And I would definitely love to see like an industry-wide

48:31.080 --> 48:37.480
adoption of Michelangelo. I feel like we have a lot of high priority stuff. We got to add to it

48:37.480 --> 48:43.000
internally. But there's definitely, I mean, there's a lot of benefits to open sourcing stuff.

48:43.000 --> 48:49.240
And I mean, that's why I think that's why Google open sourced TensorFlow from the beginning.

48:49.240 --> 48:53.320
I mean, they worked on it a lot internally, but then when it was good enough, they open sourced it.

48:53.320 --> 48:58.520
And as far as I understand is because they didn't want to have the same thing happen to them as

48:58.520 --> 49:04.120
what happened with MapReduce, where they didn't open sourced it at first. And then it took,

49:04.120 --> 49:09.240
and then there was a big deviation from the open sourced stuff. Then what happened when they

49:09.240 --> 49:14.440
made someone else open sourced it. Yeah, and they were kind of left out. Yeah. So, awesome.

49:14.440 --> 49:16.680
Yeah, there's a lot of benefits. We'd love to do it sometime.

49:16.680 --> 49:21.720
Right. Oh, Mike, I really enjoyed the conversation. Thanks so much for taking the time to sit down

49:21.720 --> 49:27.480
with us and share a little bit about what you and over up to in the realm of ML platforms.

49:27.480 --> 49:29.160
Awesome. It was a pleasure being here. Thanks a lot.

49:29.160 --> 49:29.720
Right. Thanks.

49:32.840 --> 49:39.000
All right, everyone. That's our show for today. For more information on Mike or any of the topics

49:39.000 --> 49:44.680
covered in this episode, head on over to twimmalai.com slash talk slash 115.

49:45.640 --> 49:52.840
Definitely remember to vote on your favorite MyAI video at twimmalai.com slash MyAI.

49:52.840 --> 50:09.400
And, of course, thanks so much for listening and catch you next time.

