All right, everyone. I am here with Davey Pratik.
Davey is an associate professor in the School of Interactive Computing at
Georgia Tech, as well as a research scientist at Facebook AI Research.
Davey, welcome to the Tomo AI podcast.
Thanks for having me. It's great to get a chance to speak with you and learn a bit about what you're up to.
As is typical, I'd love for us to start by having you introduce yourself a little bit to our audience.
And in particular, share the source of your interest in computer vision and AI and what led you to the field.
Sure. So I think my interest in this field started in I think about the third year of undergrad,
my junior year, where our program had several research projects that students could get involved in.
And especially a funny story, I was interested in computer architecture at the time.
And I thought I had signed up for a computer architecture project, but then when they were
matching students to project, I somehow got assigned to this machine learning project,
which at the time we were calling patent recognition, because I was in the EC department,
and that's what we called it then. But yeah, as I was working with it, that you can accidentally end
up on a bit over two choices. It sounds like a popery kind of class.
Yeah, so this was meant to be like a free form class. It wasn't in class. It was meant to be research
projects, industry projects that students could work on for credit. And so this was through that.
And so that's how I started working in this space. I enjoyed it enough to go to grad school and
pursue this in grad school. And then the transition to computer vision happened about in the first
year of when I started my PhD, where I was working on patent recognition and machine learning
problems for intrusion detection in computer networks. But then I had colleagues around me who were
working on images with computer vision, and they could sort of visually see the output of the
things that they were working on, which to me felt very sort of accessible, intuitive,
and more appealing. And I think that's where the draw came from. And I switched over to that.
And that's what I've been doing for all these years since.
Awesome. And you've been at Georgia Tech for how long?
I think about four years, three and a half four years now.
Okay. Cool. And you're also, as I mentioned, at Facebook,
what are you kind of equally at both, or how do you, how do those go out for you? Yeah.
Yeah. So I split my time between Georgia Tech and Fair. I'm at Georgia Tech in the fall.
So I'm physically in Atlanta from about mid-August to mid-December or so. But I'm teaching classes
and things of that sort. And then I'm on leave from Georgia Tech in the spring. And then that's
when I'm spending time at Fair in the spring and summer. That's a much cleaner, or split
than I imagined. Yeah. And I like that it's this clean. I can't
that our colleagues who have like one day a week and flying back and forth goes to coast,
and that just seems like a lot. So this is a much cleaner and more peaceful split.
Yeah. Yeah. So tell us a little bit about your current research interests. How do you
focus your research at Georgia Tech's last fair? So like we were talking about my background is in
computer vision. In the last several years, five, seven years at this point, I've done a lot of work
at the intersection of vision and language. So things like which were question answering, image
captioning, and things of that sort. So that's been sort of my main research agenda. This whole
time and continues to be. I still spend a lot of time on it. But in the last couple of years,
I've gotten more and more interested in problems at the intersection of AI and creativity.
And so it's still a very early, very exploratory, but I've been thinking about that quite a bit as well.
So I spent my time between vision and language things. Also some body AI work of virtual agents
in virtual environments and things like that. But like I said more recently, I've been thinking a
lot about AI and creativity. And did the work in AI and language or vision and language lead directly
to the AI and creativity or what kind of spurred that interest? Yeah, I think it's hard to kind of
backtrack and figure out exactly what got me interested in this. I think overall I've generally
had an inclination towards AI systems that are interacting with people. And so I think my interest
in vision and language also was the language part of it. My background is in vision, but I think
what drew me to language was the fact that it's sort of a very natural interface for humans for
people to interact with these systems and ask questions or get the descriptions from the machine
and get a sense for what the machine might be seeing and things like that. So I think it is that
human AI interaction collaboration aspect that also interests me is also one of the reasons why
I'm excited about AI and creativity. Cool. And so you're delivering a keynote at the AI
and creativity or AI plus creativity workshop at CVPR. First off, maybe tell us a little bit about
that workshop. What's the focus of the workshop? Is it a new workshop for CVPR? Is this a workshop
that's been going on for a long time? I think it's been around for at least a few years. It's called,
I think the workshop is called Computer Vision for fashion art and design. And I know they've
had at least one iteration of it before this and there may have been others earlier as well.
Neurips also has a workshop on AI and creativity that has been going on for at least a few years
and again may have been longer. Okay, I think the AI and creativity is the title of your presentation
at the computer vision for fashion art and design. And so what's your, tell us a little bit about
your presentation there? Sure. So I guess I start the talk by even talking about why I think AI
and creativity is exciting and could be impactful. And so to do that, I first start by what creativity
even is. And I think it's sometimes hard to forget how general and how powerful just creativity is.
It's essentially sort of any new idea that is of value period. It doesn't have to be in the context
of art specifically or music specifically or poetry specifically. It's all of this but it's also just
even anything of scientific progress and technological progress. All of that stems from new ideas
that are of value in some way. So in that sense, one could even argue maybe a little bit of an
exaggeration, but one could argue that all of progress of any kind of rests and creativity.
And so if we can think of if there are ways in which AI can assist us in this creative endeavor,
I feel like that's that could be that could be very powerful. Is that a is that an accepted
definition of creativity? I'm particularly curious about the value part that seems. And for a lot
of the things that we think of as creative, that seems to be particularly difficult to
nail down. Yeah, yeah. So it is well accepted definition. I mean to the I guess well,
accepted in the sense that that's what Wikipedia says. Wikipedia defines creativity that way as well.
But then a lot of researchers like a lot of computational creativity researchers who do spend
a good amount of time thinking about how we can define creativity. Maybe even attempt to evaluate it.
Those definitions and those ways of thinking also tend to have these two components of novelty
where you want something new. But there are ways of being novel just by being completely random or
sort of sort of if it's a language domain, it's just gibberish and yes, sure, it's new, but
is it really off value in some way? So I think that value component is also often is often thought
about as part of creativity. It doesn't say anything about how to define value. So I think it kind
of still offloads that issue of subjectivity. It just moves it from creativity into that value piece.
And even novelty, if you think about it is not that easy to quantify, even that can be quite
subjective. So I think it's useful to break it down into these components. I found it useful to
think about it that way in the various domains where I've thought about it. But it doesn't really
take the subjectivity away. It doesn't really make it any easier to define each of these spaces.
Just thinking about it in terms of those pieces directly impact some of the things you've done
in the space. I think it does. It's over hasn't directly impacted what kind of problem I look at
in the AI and creativity space. It also hasn't necessarily impacted the kind of approach that I might
use to the problem. But it has very directly impacted how I evaluate the approach.
And the kinds of baselines that I think about when I want to compare the approach. So it's useful
where if there's some approach that we have in mind. And then if we go back and think about where
is the novelty coming from? Where is the value coming from? Then it makes it easier to think about
what baseline would capture just the novelty but wouldn't have the value piece. And what baseline
would capture just the value piece but might not have the novelty. And then those become
national baselines to compare our approach to to see if we are getting a healthier mix of novelty and
value. So I know that's a little abstract, but hopefully that's useful.
When you think about or when you kind of plan out your work in the space, are you
primarily interested in kind of AI augmented creativity where the AI is helping us to be
more creative? You mentioned that earlier. Or do you also look at just kind of creative or
or pseudo creative depending on how rigid you want to define things. Output of AI algorithms.
Even that question, can AI be creative in and of itself? There's a lot of AI-generated art.
You do some of that stuff yourself. Does that qualify as creativity?
I think that's a great question. There's a lot of interesting conversations that are happening
in the community around exactly this. What does it even mean for machines to be creative? Can
machines be creative at all? There are fairly strong opinions on both sides of this and everything
in the middle. I think it's useful to think about that. I don't think that directly impacts
the kind of work I do primarily because like I was saying whether or not machines can be creative
feels like a secondary question in the way I approach it. I'm more interested in knowing whether
machines can help humans be more creative than they would have been on their own. I think if it
has sort of a team setting where if you had the machine alone that was trying to produce something,
if you had a human alone that was where they were trying to produce something and instead if both
work together is the final creative artifact more creative or even if it's not the case but is the
process is the creative process more engaging and more enjoyable for the human than it would have been
if a machine wasn't involved. So that's how I tend to think of it. I do think that there are
multiple stages at which a machine could interact with the human in the creative process. It could be
a very tight engagement where throughout the creative process both are sort of working with
each other to get there as you might with sort of a human collaborator, a human team member.
But I think it can also be something where sort of the seed of inspiration comes from something
the machine did and then the human takes over from there and if we can show that what the human
produces at the end of it or the process that they go through after being inspired by whatever
the machine did is somehow better, more creative, more enjoyable, more satisfying than what would
have happened if if this seed of inspiration didn't wasn't there from the machine. I would still
think of that as success even though the human and the machine are not necessarily closely working
with each other. So in that piece of the machine providing a seed for inspiration, the machine could
be working fairly autonomously where there isn't necessarily human involvement, but I still think of
that as AI assisted creativity for the human. Besides that particular categorization of whether
the two are working together or in series is there like a framework for thinking about
the different directions that people are going in terms of AI and art or even AI and
computer assisted creativity just in terms of laying out a landscape for the different
directions of research and practice. So I don't know if there's a well-established framework for
it and so there's a good chance that I'm missing some frameworks or some ways of thinking about it
that other people have, but if I were to think about it now, I can think of a couple of different
ways of organizing it. One is where the creative task is a very task-driven one and so where
the human might be trying to do something very specific where they're trying to design a bridge
that will work well for a particular scenario. So they're trying to get a particular task done
and to do that task there is a lot of creative thinking that's required and the machine could help
in that in some way and the other is where a human is more just exploring where they are
just sort of like you might like the contrast between sort of drawing versus doodling.
In the former you are very intentionally trying to create something specific whereas if you're
doodling you're just kind of sketching different things. So that kind of thing where you're just sort
of exploring trying to encounter something that is of creative value to you and I think those two
scenarios require different kinds of tools to help you in that. So that's one kind of separation
that we can think of. Another kind of separation could be where the machine tries to mimic humans
in the process of trying to be creative. So for example if you think about trying to get machines
to find a new dance, a new choreography that will go well with music. You could train the machine
using supervised data where you have data of dancers dancing to different forms of music and so
there the machine is trying to mimic humans to be creative whereas you could instead also approach
it as getting the machine to just discover movements that are well-signed with music
where through something like reinforcement learning is just trying to find a series of movements
that is well aligned with the music but is not at all influenced by the kinds of dances that already
exist in the world and those might have pros and cons and different values based on the kind of
application that you're looking at. So these are two ways of organizing the work that I can think of
but there are probably others as well. So in your talk you are going to be reviewing a handful of
projects that you've worked on kind of across this space. I think the first one is the casual
creator or is it causal or casual? It's casual creator and so that actually goes back to the first
point that I was making. So casual creators and this was a term coined in one of the ICCC
papers International Conference and Computational Creativity from a few years ago so it's not
it's not a term that I've come up with but it refers to tools that are meant to aid humans who are
exploring sort of are just exploring and are not trying to build something or create something
for a particular downstream task and so those are called casual creators. And so we've looked at
what we could do in that space to give people tools that might make it a little bit easier
to find something that interests them. And what are some examples of the specific things that you
explored there? Yeah so one is where we have this I've been I guess on the side I've been
dabbling a bit in algorithmic art which which involves it's basically creative coding where
I create these geometric patterns that I think look interesting and so I set the rules of what
these patterns could look like and there's an element of randomness every time you run the code
you're going to see a different pattern. It's going to follow the parameters that I set up so
it's not going to be completely arbitrary but within those parameters you're going to see
different samples. And in that context there are some parameters that I have set but then there
are also some parameters that somebody else could set for example what color palette should these
colors be sampled from and that you as a user could set that to a variety of different
palettes and then see samples from that. So in that context you could think of the tool that I've
built as being a casual creator and that's a tool that you as a user could use to just explore
different patterns try different parameters and see if you find something you like you're not
trying to look for something specific and what we looked at is as you are interacting with this tool
as you're playing with these different parameters can I can we build a model that can predict
what else you might like. So as you're let's say picking one of the different color palettes based
on your choice of the color palette can I make a guess for whether you will like lines with more
curvature or whether you will prefer straight lines and sort of an angular design and if we can
predict that then as you're interacting with these with the stool I can already narrow down the
space of things that you should explore in the future in hopes that you will find something that
you like faster than you would have if you were just exhaustively trying all these parameters out
so that's that's that's one thing that we've looked at in that space. And so the can you talk a
little bit about the kind of the technical contributions or the particular areas of particular
challenge for a work like that it sounds like part of it is the modeling which sounds a little bit
like a recommendation system I'm almost envisioning like you know sometimes I'll pull up an adobe
you know art app or something similar and there are all these palettes of tools and I would just
love for that thing to guess the thing that I need next as opposed to having me having that you know
exactly exactly exactly so yeah it is you can think of it as a smart tool as a recommendation
system I think the the bigger so that the technical approach is fairly straightforward in this
where we sort of collector pairwise preferences from people in terms of what they like better than
something else and we use a subset of those preferences to see if we can reliably predict the
others I think the bigger question here was whether that signal even exists that based on your
choice of a color palette is there would I be able to guess that you might like straight lines over
lines with more curvature or not kind of thing and it's not obvious going in whether that correlation
would exist or not and the answer to this I'm sure depends heavily on the specific domain or
even specific algorithmic art form that you're looking at and so our my main curiosity in doing
this was to see whether this correlation exists or not to begin with and then we have found some
signal that at least in the specific algorithmic art domain that we were looking at that these
correlations do exist we can predict better than chance at least what else you might like based
on some of the preferences that you've given us so far in the algorithmic art the challenge
then remains of how do you plug this into the tool and sort of you would have to look at sequential
decision making whereas you're interacting with this in a sequential fashion we want to be making
these predictions right now everything that we've done is very sort of snapshot at one
instance in time and so the pairwise preferences was that data that you had to collect from
from scratch or were you able to yeah I find that somewhere yeah no we had we had to collect
that from scratch because we were doing this in the context of this particular algorithmic art
tool that I had so we weren't like using preferences on other things that might already exist out there
and so we did this on Amazon Mechanical Turk where we showed people pairs of art pieces and
and and what's nice about these tasks compared to a lot of other things that tend to be on Amazon
Mechanical Turk is these are much more interesting tasks people like looking at pieces of art and
telling you which one they like better and things like that so it's it's quite easy to collect a lot
of data for a bit more about how you set up the task did you show them like two complete pictures
that varied in one particular dimension or did you or or what yeah exactly that exactly that
where we wanted to make sure that the preferences that we are collecting are along specific
dimensions so we tried to keep everything else the same between these two pieces and only change
one variable like just the color palette or just the thickness of lines and things like that
and based on that we collected preferences so that we can then check for correlations across these
okay very cool and is that an example of one of of of portfolio things that you've done in the
this kind of genre of casual creativity or are there others yeah there is there is one other project
that we've looked at in this space which we've been calling neurosymbolic in generative art
okay so it's and it's perhaps an interesting kind of there's a lot of debate in AI right now in
terms of it's sort of neural networks kind of reasoning pattern matching the right kind of
approach to use for many of these challenges challenging tasks or if we need more symbolic reasoning
to do these things and so it's a it's a little bit of a play on that debate in the context of
a generative art or algorithmic art and so what we did there was we look we took these algorithmic
art tools like the ones I told you where the pattern being generated is through these very symbolic
parameters that have been set like the color palettes and shapes and things of that sort
so there's been that line of work in a generative art where in this setting you can
sample different random samples within those parameters and then there's been a huge amount
of work especially with GANS with generative adversarial networks where people have trained
neural networks that allow you to model the distribution of data and then again you can sample
random samples through that and people have found in some domains that to also have artistic value
where some of these generations are very interesting and you can sort of walk through the latent
space and look at interpolations which make for very interesting visualizations and so we were
curious whether there's something that falls at the intersection of these two generative approaches
the sort of the algorithmic and symbolic versus the the neural generative approach and so what we
did was something fairly straightforward again as more of a pilot study where we a generator
many different samples from the algorithmic approach and in theory we can get as much data as we
want because these are just different random samples from the same system and we train a neural
generative modern on it so we trained again on it and we were interested in seeing that if again
trained on these symbolically generated images is is of value to people whether people find it
interesting to look at to play with to look at these interpolations and what they think there
and so what we found is that when we compare these neurosymbolic generations both the final artifact
and the process of interacting with these systems to the symbolic counterpart people prefer the
neurosymbolic approaches fairly frequently compared to the symbolic one and so that seemed like
good validation that there might be something in this direction that is that is worth exploring more
and did your work in the area give you any intuition for why that is?
So I think it maybe goes back to the novelty and value
distinction the trade off that we were talking about earlier I guess not trade off which is
decomposition where I think these patterns looked interesting they looked they look good
to people they seem to be high quality because they are coming from this symbolic generation process
where somebody has thought through and picked these parameters to make sure these patterns look
interesting but then the neural artifacts that tend to be there in these generations
I think probably look intriguing to people and look different than what they are used to
and so I think that combination is our hypothesis for why they may have found it to be interesting
yeah it's hard to know for sure but that's our hypothesis based on the test that we've run
okay very cool and I should have mentioned this earlier but all of the
examples that you know we're talking about we'll be linking to in the show notes
including your CVPR presentation which walks through these as well so that's the
casual creator side the next set of examples were around kind of this idea of machines inspiring
humans talk a little bit about how you you know how you created a project in that area how did you
set that up yeah so one project that we've looked at in that space is on I alluded to this a
little bit earlier is on seeing if machines can discover dance can discover movements that are
in sync with music and so we had what we were the sort of main motivation there or main
goal was there to not train the machine with dances that already exist we wanted to see
what dance sort of emerges if the machine is just trying to produce movement that sings well
with music what does that look like the people find value in that and so so that was that was one
project where we take in as input a snippet of music we have a music representation that essentially
gives us a sense for which to at different points in time when are the pieces of music similar
versus not and then what we try and do is generate a sequence of movements such that when the music
is similar at two points in time the movements are similar at those points in time the similarity
could be in terms of where the agent is on this virtual stage if you will or it could be in terms
of what actions it is taking at those points in time and so we evaluate which one of these
similarities is better and things like that okay now for someone listening to this conversation
who has in senior presentation you might be envisioning like you know open a gym simulation of
humanoid object or something like that or but actually the example that you showed is quite a bit
more simplistic than that absolutely yeah absolutely and it's not even a stick figure if you actually
think about it it's the agent is parametrized in an extremely simple way like you said it can only
take one of K different states at any point in time okay and at any point in time it can go either
one stay once one state up one stay down or stay where it is and it's not allowed to go out of bounds
so it can't go outside of the range and that's it that's all it can do it can just take three actions
at any point in time and it's characterized with just this one ordinal value of states what is nice
about that though is that because it's it's this general you can visualize or instantiate this
agent in many different ways I can make these K states be a sequence of poses that a stick figure
can take and I think that's what you're referring to it can be even simpler where it's just the size
of a dot where it can become bigger or smaller as the music is changing it can be a dot that's
traversing left to right as the music changes and it can even be a fairly complex geometric pattern
that can be set that can be changed based on one parameter so sort of these I don't know if you
have if you saw these videos and I guess the listeners can watch it offline I'm happy to send
your pointers to it but you can have these very leafy visualizations where the sort of the sway
of that of that leafy pattern changes based on this one parameter and so you can have all these
leaves sort of moving and synch with the music and so that is something that I was very excited
about that it's so general that you can have many different visualizations and hopefully
some visualizations are more inspiring in terms of what movements make sense than than others
and I thought that was that was kind of cool I didn't see that the the leafy one if I'm thinking
of the same one and it's really interesting to understand now that those are generated by the
same underlying model because I found the leafy one much more compelling than the stick figure
it's like really interesting visually I think exactly exactly and so there's a lot of yeah
it's exactly that that all of these different visualizations it's the same underlying agent the same
characterization anything a lot of interesting work can be done in figuring out what these
visualizations should look like to make the same underlying movement more or less inspiring more
or less appealing for what a person is trying to do at the end of it and so how do you go about
figuring out what that model should look like as you're starting a project like this so by the
model you mean like what the characterization of the agent should be or right right I think to be
honest in this case it was it was essentially us trying to think about what instantiation captures
the sense of what we're trying to get out so our interest in this was not to figure out how we can
get a humanoid to stay stable and learn the laws of gravity or anything of that sort which sort of
a lot of the reinforcement learning opening I gym like things are meant for so we were not interested
in those things we were interested in this question of if we produce movements that are just in
sync with the music that's that's all the constraint is what does that look like does that look
interesting or not and so we were trying to figure out what is a characterization of the agent
that leaves out all the challenges that we're not interested in but maintains the sense of the
question that we are interested in exploring and this instantiation that that I described was
one that seemed to capture that and so that's what we went with but that could be other starting
points that are equally reasonable and in this particular case where do you go with the
the research does it matter even to try to scale up the you know the model so that it you
know has more stage or is continuous or something like that or is that kind of beyond the point
of what you're trying to show here yeah no I think I think that would be of interest in terms of
because the kinds of movements that we might be able to get might be more interesting if the agent
can take more actions and be in more states than things of that sort so there's probably I'm sure
not probably I'm sure there's a space of movements that cannot be captured with the kind of
instantiation that we have and so I think that would be of interest those could be more inspiring
another thing though is even before that the current approach that we've used to find
this movement that is synced is actually a fairly straightforward just greedy search like approach
there isn't in that sense sort of actual learning that's happening it's more a search process where
we're just optimizing for this movement being synced with music and so what that means is whenever
there's a new piece of input music we're doing the search from scratch it's fairly fast because
it's a greedy approach but it's still every time you give me a piece of music we're just doing
the search from scratch and then finding a dance that goes with it I would be very interested in
doing this in a more machine learning fashion where we've learned mappings of given an input
music what are the characteristics that the output dance needs to have so that at test time we
can now just given an input piece of music just directly predict what the movement should look like
rather than having to run the search process at test time and so starting with a large database of
music of songs and sort of training this model to be able to figure out what pattern makes sense
pattern of movement makes sense and then using that to do the prediction is something that I
think would be would be interesting to do. You mentioned the the search that you're doing on the
music is looking for parts of the music that are similar is that is it analogous to like a beat
detection kind of approach or something different. It is it is related to that like beats would be one
piece of information that affects where the music is repeating but it's it's quite a bit more
fine grained than that that even if the beat so yes if you look at it's I guess it's hard to
describe in words but you can look at this visualization of a matrix that tells you how similar
the music is at different points in time and there's a lot of rich structure there
that is beyond that includes the beats but goes quite a bit beyond that. Okay I'm envisioning
something like a auto correlation where you're kind of shifting the music and trying to protect.
Exactly exactly very much is an autocorrelation in the in an acoustic feature space so where we're
using these rich acoustic features and we're looking for autocorrelation there and in it's the
same thing that we're looking at in the movement that we also have a similar autocorrelation
like matrix for the movement and we're trying to say that the autocorrelation matrix of the movement
should be similar to the autocorrelation matrix of the music and that's the reward if you will
that the agent gets as it decides what actions to take. Okay cool cool you've also got an example
that is illustrating the collaboration that you have spoken about called sketches or focused
on sketches you talk a little bit about that one. Sure yeah so there we've there isn't a machine
there yet this was we studied this in the context of humans with the idea being that if we can
so the the setup is that if you have you're trying to create sketches and if you have a blank canvas
we were trying to look at what collaboration mechanisms lead to sketches that are more interesting
and more creative than others and so the way this collaboration plays out is that you start with
the blank canvas and then one person comes in and draws some strokes on it and then somebody else
comes and draws more strokes on it and and we keep going and we can see how this sketch evolves
and what the final sketch looks like and we were trying to see like I said what collaboration
mechanisms might make sense in that context and so we found a few interesting things here where
what we found is that if just one person draws the whole sketch from start to finish there's
a variance in quality depending on the motivation and skill level off that person
so that's one there's there's large variance in quality and the other is that even when the
quality is high these sketches don't seem surprising or novel to people they kind of like there might
be a sketch of a tree with a bird on it with a sound in the background and sort of things of that
sort that maybe we've seen before and so people don't find them particularly intriguing
the other setup is where you have different people coming and drawing these different strokes
and what we found there is that these sketches look entirely different the qualitative will look
very different from what what happens when one person draws it all out and so people find
them very interesting they're very intriguing but they also find them to be a little too chaotic
where there's just all sorts of things happening on this canvas and it's harder to sort of make
sense of it sometimes it can also look like it's poor quality and so what we found is that a
collaboration setting where at each stage there is some form of a voting mechanism where let's say
I am the person who now has to add strokes to this canvas if I'm shown five versions of the canvas
and I get to pick which one I want to add strokes to then what we found is the evolution of the
canvas through this mechanism leads to pictures that are still quite interesting still very
different from what someone would make if they drew it alone but are not quite as chaotic and noisy
as what happens when there isn't a voting mechanism involved because what happens is the sketches
that are a little bit more coherent are a little bit higher quality are the ones that tend to get
more votes and those are the ones that proceed forward whereas the ones where someone may have
kind of scribbled something or added something to the canvas that didn't that sort of broke its
coherence tend to not get votes and then those don't go forward so it kind of is a good balance
again of novelty and value where you get of these interesting compositions because so many
different people are contributing to it but the voting mechanism keeps sort of the value and the
quality and the coherence high to eventually give you sketches that were rated as more creative
the idea of these sort of other scenarios interesting so does this you know as this plays out does it
produce something that is amazing like is this a mechanism for allowing and you know a crowd of
kind of the unwashed masses you know with no particular art skill to produce like incredible
things that an individual probably couldn't or wouldn't or
is it you know less modest than that and it's in the output so I would say it is less modest than
that I think the way you put it was yeah I think it is it is less modest than that but I think it
is along those lines I think it is taking steps in that direction where as a result of this crowd
of people who may have varying levels of skills in terms of making these sketches we ended up
creating something that no individual would have created it was qualitatively different
whether you like it better or not again a lot of these things are subjective we did find that more
people in our studies liked these collaborative sketches better than they like the ones that
individuals have created yeah there's variance along that but they're certainly qualitatively
very different they're not they're not the same thing so we are getting artifacts that are
different as a consequence of this collaboration yeah the setting sounds really interesting and I've
got to imagine that there have been lots of attempts at you know collaborative art of various forms
and adding in you know some kind of voting mechanism or or something like that or you know
a vetting mechanism of each individual's contribution to this thing or the the prior
or round of contributions to this thing sounds like an interesting way to help the end result evolve
more quickly into something that is appealing yeah exactly exactly and it touches on
much larger questions of what collaboration should look like when people are engaging in a creative
activity I mean we've obviously studied this in a very narrow domain in a very specific setting
but I think the underlying question is quite important in sort of a larger context as well and then
you've got a last category of projects that you've been exploring focused on visual journaling
what's that one about yeah so that one is is a fun project where our our thought was that
if people could see an abstract visualization of their sort of daily journal entry that might
be a way to keep people more engaged that might increase the probability that they will journal
on a regular basis maybe they could also sort of share this entry in a visual way with sort of
family and friends that they're close to or things of that sort and so we're curious to see what
we can do there and if we can create something that is that people do find interesting and so what we
do is we take we asked people with their with their consent to write up a short journal entry of what
the day of what their day looked like and obviously they could decide what they wanted to share in
that journal entry or not and from that we run some sort of natural language processing techniques
to extract what three salient topics were that they were talking about so we had a handful of
categories I think maybe about a dozen or so things like work family friends food sleep
those kinds of things that we can automatically extract figure out which one of these topics
they're talking about and we automatically extract what the associated emotion seems to be I
think we had about 18 different emotions like happy sad frustrated things of that sort that we
can associate with these topics and so with these topics and associated emotions we then create
this abstract visualization where there's a certain shape there is associated with the topic
and there are certain colors that we were associated with these emotions and we have a variety
of visualizations that we produce using these shapes and colors and again we run some evaluation
to see whether people like the fact that the topic is described through a shape whether they like
the fact that the emotion is shown through color do they like having visualizations do they
think they would journal more regularly if their journaling app had this associated visualization
and things like that and we saw a lot of in general positive responses to these things.
Cool. Do you have kind of an overarching message for your workshop audience at the workshop?
I don't know I think the overarching message would just be that I think this intersection of AI
and creativity can be very powerful I think it can be very impactful and it can be a lot of fun to work
on and so I think there's a lot of space for creative ideas no pun intended I guess in terms of what
kinds of things we can look at here what human AI collaboration could look like and things of
that sort I would just sort of encourage people to think about this more and see if they have ideas
in this space and engage if they seem if they feel like they're interested. Awesome awesome well
Davey thanks so much for taking the time to share with you. Thanks for having me this was fun. Thank you.
