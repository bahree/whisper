WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:31.440
I'm your host Sam Charrington.

00:31.440 --> 00:35.880
I'd like to start today's show with a huge shout out for everyone who's taken the time

00:35.880 --> 00:39.280
to vote for us in the People's Choice Podcast Awards.

00:39.280 --> 00:43.000
It's been awesome to hear from those of you who have loved words of encouragement and

00:43.000 --> 00:46.000
we certainly appreciate all the love.

00:46.000 --> 00:50.800
If you're a fan of the pod and you've already voted, we'd also like to encourage you to

00:50.800 --> 00:56.080
head over to your Apple or Google podcast app or wherever you listen to podcasts and

00:56.080 --> 00:58.920
leave us a five star rating or review.

00:58.920 --> 01:05.200
They are super helpful as we push to grow this show and community.

01:05.200 --> 01:11.880
In this episode, I'm joined by Prashant Warrior, CEO and co-founder of cure.ai, a company

01:11.880 --> 01:15.640
building AI-powered software for radiology.

01:15.640 --> 01:19.920
In our conversation, Prashant and I discussed the company's work building products for

01:19.920 --> 01:23.560
interpreting head CT scans and chest X-rays.

01:23.560 --> 01:27.560
Prashant shares with us some great insights into some of the things he and his team have

01:27.560 --> 01:33.560
learned in bringing a commercial product to market in this space, including the gap between

01:33.560 --> 01:38.760
academic research papers and commercially viable software, the challenge of data acquisition

01:38.760 --> 01:44.320
and how to best capitalize on what data you do have access to and much more.

01:44.320 --> 01:48.520
We also touch on the application of transfer learning in this space and the algorithms

01:48.520 --> 01:53.840
and annotation pipelines, Cure has developed to support 3D scans.

01:53.840 --> 01:55.520
Let's get to it.

01:55.520 --> 01:58.760
All right, everyone.

01:58.760 --> 02:01.040
I am on the line with Prashant Warrior.

02:01.040 --> 02:04.000
Prashant is the CEO of cure.ai.

02:04.000 --> 02:06.880
Prashant, welcome to this week in machine learning and AI.

02:06.880 --> 02:08.480
Great to be here, Sam.

02:08.480 --> 02:10.160
Thank you so much for inviting me.

02:10.160 --> 02:11.160
Absolutely.

02:11.160 --> 02:14.400
Let's get started by having you tell the audience a little bit about your background

02:14.400 --> 02:19.000
and how you got involved in working in ML and AI.

02:19.000 --> 02:20.000
Great.

02:20.000 --> 02:25.600
I have been working in the applied math space for a long time.

02:25.600 --> 02:29.240
My undergraduate degree was in operations research.

02:29.240 --> 02:33.640
I got a PhD in operations research and then started working on it.

02:33.640 --> 02:35.640
At that time, this was not part of data science.

02:35.640 --> 02:38.480
There was no field like data science when I did my PhD.

02:38.480 --> 02:44.360
But after my PhD, which was in our research, where we were basically optimizing

02:44.360 --> 02:49.720
truck routes, so figuring out how shipments should be routed from origin to destination,

02:49.720 --> 02:53.560
how we should assign drivers to trucks, and then again, there are lots of rules around

02:53.560 --> 02:57.280
how many hours a driver can drive and the duty time that it has.

02:57.280 --> 03:02.640
So I mean incorporating all those rules to figure out how drivers should be allocated

03:02.640 --> 03:03.640
to trucks.

03:03.640 --> 03:04.640
I mean, assigned to trucks.

03:04.640 --> 03:08.440
So those are the kinds of problems that I was solving during my PhD, which were primarily

03:08.440 --> 03:10.680
integer programming problems.

03:10.680 --> 03:14.920
So I did a lot of work around optimization then.

03:14.920 --> 03:20.920
And then immediately after that, I started working on price optimization and McDonald optimization

03:20.920 --> 03:25.240
demand forecasting for, I started working for SAP.

03:25.240 --> 03:28.480
And so there, I mean, we were working on these problems in the retail space, retail and

03:28.480 --> 03:29.720
fashion retail space.

03:29.720 --> 03:33.120
So this, I mean demand forecasting, some of these problems are very much, I mean, they

03:33.120 --> 03:35.360
are basically your dependent variable as a sales.

03:35.360 --> 03:39.920
And then you have a bunch of independent variables, which are, I mean, which again depend

03:39.920 --> 03:41.640
upon the kind of product that you're selling.

03:41.640 --> 03:45.240
I mean, so a fashion product will have very different independent variables than if you

03:45.240 --> 03:49.600
look at, for example, products which are retail, I mean, typical retail products like a can

03:49.600 --> 03:53.720
of milk, for example, or fruits or vegetables, right?

03:53.720 --> 03:56.600
So we were sort of worked on that for a while.

03:56.600 --> 04:02.520
And then I mean, I was in the US at that time, came back to India and then I was, I set

04:02.520 --> 04:09.160
up a company, which is called Imagna, which was basically using machine learning to understand

04:09.160 --> 04:10.720
customer behavior from cookie data.

04:10.720 --> 04:16.440
So we were basically dropping cookies at, on multiple e-commerce websites and getting

04:16.440 --> 04:20.440
a lot of detailed information about how customers are behaving on those websites.

04:20.440 --> 04:24.440
So you can actually see how they buy clothing, for example, what products they looked at,

04:24.440 --> 04:27.840
what kind of sizes they looked at, what colors they looked at, what styles they looked

04:27.840 --> 04:31.720
at, and all of that, or for example, I mean, integrating, for example, what, what travel

04:31.720 --> 04:35.640
sites they went into, I mean, how they, where they're traveling to, what travel locations

04:35.640 --> 04:38.160
they've looked at, or what kind of movie shows they're watching.

04:38.160 --> 04:45.320
So we had a very consolidated set of data from cookies, which we were then utilized to do

04:45.320 --> 04:48.960
real-time bidding on ads, on basically online ads.

04:48.960 --> 04:51.320
And we had a built a real-time bidding platform.

04:51.320 --> 04:55.560
And that was then, I mean, so that was again, I mean, yeah, even I was, I was heading

04:55.560 --> 04:56.560
that company.

04:56.560 --> 04:59.840
So I was also, I mean, playing more of a commercial role in that.

04:59.840 --> 05:06.600
And then that got acquired by the organization that I currently work for called Tractil Analytics.

05:06.600 --> 05:08.840
I acquired my previous company.

05:08.840 --> 05:11.880
And then I joined Fractil Active Data Scientist.

05:11.880 --> 05:16.720
And in that role, again, I mean, Active Data Scientist, I was working on some problems.

05:16.720 --> 05:21.520
And then we sort of identified there is a large gap in the radiology space where we felt

05:21.520 --> 05:25.440
that deep learning could make a substantial impact by automating interpretation of images.

05:25.440 --> 05:31.160
So that's how I sort of transitioned from the Active Data Scientist role at Fractil

05:31.160 --> 05:33.920
into becoming the CEO of QR.AI.

05:33.920 --> 05:37.400
And I've been working on building this over the last two and a half years.

05:37.400 --> 05:39.640
And so that's, that's, that's my story.

05:39.640 --> 05:46.200
And Cure is currently in the process of rolling out a kind of a packet solution focused on

05:46.200 --> 05:48.960
chest radiology, is that right?

05:48.960 --> 05:53.480
So we have exactly, I mean, so one of our solutions is in chest radiology, which basically

05:53.480 --> 05:57.200
can automatically interpret chest X-rays.

05:57.200 --> 06:01.480
And a second solution is on head CD scans.

06:01.480 --> 06:06.040
So which is basically automatically interpreting head CD scans, those are the two main solutions

06:06.040 --> 06:07.040
we have built.

06:07.040 --> 06:10.240
I mean, there are some more solutions that we've built over the last several years.

06:10.240 --> 06:13.760
But we, I mean, from a commercial perspective, we focus on these two.

06:13.760 --> 06:19.920
And so there's been over the past few years, there've been a ton of work.

06:19.920 --> 06:24.880
You know, in a lot of ways, it feels like a kind of gold rush in the medical field.

06:24.880 --> 06:30.200
When you look at the research journals, it's, hey, we've got this new tool, CNN, let's

06:30.200 --> 06:36.120
apply it to radiological image type A, type B, type C. There's a, you know, a series of

06:36.120 --> 06:37.400
these types of papers.

06:37.400 --> 06:41.760
I'm curious what you've learned about the gap between what you might read in a paper

06:41.760 --> 06:46.120
and actually bringing a product to market.

06:46.120 --> 06:47.840
So that's a, that's a very good question, Sam.

06:47.840 --> 06:51.440
I think I think I have a very strong point of view on that.

06:51.440 --> 06:55.000
I figured you might.

06:55.000 --> 06:57.640
So I mean, there are lots of papers.

06:57.640 --> 07:01.040
I mean, because CNN's, I mean, can read images really well, right?

07:01.040 --> 07:04.560
And so people tell that, okay, I'll just take a CNN and apply it to this medical data

07:04.560 --> 07:06.280
that I have and I'll get good results.

07:06.280 --> 07:08.400
And they do get good results because they're overfitting on the data.

07:08.400 --> 07:09.720
So you have 2000 images.

07:09.720 --> 07:14.760
Let's say you have got 2000 X-rays to train your algorithm on and you sort of label them.

07:14.760 --> 07:16.400
You label each of those images as normal.

07:16.400 --> 07:17.800
Let's say these are X-rays, right?

07:17.800 --> 07:19.680
You label them as normal or abnormal.

07:19.680 --> 07:24.720
And you order on that and you will get some, I mean, you basically put some as validation

07:24.720 --> 07:25.800
testing and so on.

07:25.800 --> 07:29.880
And you get good results, but what happens is that especially with X-rays, right?

07:29.880 --> 07:31.560
There is a huge variety of data.

07:31.560 --> 07:36.320
I mean, if you go from a Philips machine to a GE machine or you go from one set into

07:36.320 --> 07:40.280
another, one center to another, I mean, there are different settings, different in machines.

07:40.280 --> 07:44.480
There is a wide variation and what, what happens typically is you take a data set, you train

07:44.480 --> 07:48.360
on the data set, you validate, you test, I mean, you do all the right things.

07:48.360 --> 07:51.640
But when you take that algorithm and you try to generalize to a new data set, it does

07:51.640 --> 07:53.040
not work well at all.

07:53.040 --> 07:54.040
And we saw this initially.

07:54.040 --> 07:57.600
And when we started working out, working on this problem, on the chest X-ray problem,

07:57.600 --> 08:03.480
we had around 25,000 scans, 25,000 X-rays along with their reports.

08:03.480 --> 08:09.200
So we did what we did is we took the reports, we ran NLP on those reports, some rule-based

08:09.200 --> 08:13.480
NLP, not machine learning base, but rule-based natural language processing, which basically

08:13.480 --> 08:16.600
extracted out the abnormality from the report.

08:16.600 --> 08:20.280
So if, for example, one of the abnormalities is called floral effusion, where it's fluid

08:20.280 --> 08:21.280
in the lungs.

08:21.280 --> 08:25.560
We said we will extract out a bunch of abnormalities, so we trained the algorithms to do that,

08:25.560 --> 08:26.960
to train these NLP algorithms.

08:26.960 --> 08:31.320
So now they've got an X-ray and the corresponding abnormality, the chest X-ray and the corresponding

08:31.320 --> 08:32.320
abnormality.

08:32.320 --> 08:34.640
And we trained our models on that.

08:34.640 --> 08:39.520
And then what we saw is that when we had a new data set, that was trained on 25,000

08:39.520 --> 08:40.520
images.

08:40.520 --> 08:44.160
And when we got a new data set, it did not translate at all, we were getting around

08:44.160 --> 08:49.600
90% accuracy on the first data set, on the second data set that we got from another hospital,

08:49.600 --> 08:52.360
we were somewhere in the 60s, I think.

08:52.360 --> 08:55.040
And so it was, I mean, substantially lower.

08:55.040 --> 09:00.200
And then we figured that I think, I mean, there is a lot of variation in the data, and then

09:00.200 --> 09:01.600
that's also, that's one challenge.

09:01.600 --> 09:05.920
And of course, I mean, over the last 20,500 years, we have increased our X-ray database

09:05.920 --> 09:10.120
from that to 25,000 number to around 1.5 plus million.

09:10.120 --> 09:15.640
So today, we have a huge amount of data, so it sort of has learned a wide variety of data

09:15.640 --> 09:19.920
patterns that it sees, I mean, acquisition data, acquisition patterns, because X-ray acquisition

09:19.920 --> 09:21.720
can occur, I mean, in many different ways.

09:21.720 --> 09:26.040
And so it has learned a lot of these acquisition patterns, learned about a lot of different machines

09:26.040 --> 09:27.400
that are generating those X-rays.

09:27.400 --> 09:29.000
So that makes it a little bit more generalizable.

09:29.000 --> 09:32.080
I mean, I think the more amount of data that you have, it becomes more generalized.

09:32.080 --> 09:38.120
You mentioned using NLP to pull information out of reports or records.

09:38.120 --> 09:43.960
Is this kind of data mining, the electronic medical records to produce labels for your

09:43.960 --> 09:44.960
data set?

09:44.960 --> 09:46.600
Or was there something else happening?

09:46.600 --> 09:48.560
It's not electronic medical records.

09:48.560 --> 09:53.680
So it's basically, I mean, for, I mean, you could think of it as a medical record, but

09:53.680 --> 09:56.640
basically for every radiology image, you will have a radiology report.

09:56.640 --> 09:58.880
It's part of radiology information systems.

09:58.880 --> 10:02.200
So you can, so you are basically just putting that radiology report.

10:02.200 --> 10:03.960
You're not pulling any more medical records.

10:03.960 --> 10:05.800
So ideally, I mean, a patient will have a lot more.

10:05.800 --> 10:09.320
I mean, they will have the history of why they came to the hospital, why they took strain

10:09.320 --> 10:10.320
the first place.

10:10.320 --> 10:14.000
And then maybe there is some microbiological test, which gets done afterwards, where they

10:14.000 --> 10:15.760
are diagnosed with some disease, right?

10:15.760 --> 10:17.840
A radiology report may not contain all of that.

10:17.840 --> 10:21.760
It will basically tell you that I found these patterns on the X-ray.

10:21.760 --> 10:25.040
For example, it might say that I found a fluid effusion, which is basically some fluid

10:25.040 --> 10:28.200
in the lungs, or that could be due to tuberculosis or other disease.

10:28.200 --> 10:30.040
But a radiologist will not report on that.

10:30.040 --> 10:32.520
They will report on what they see in the X-ray.

10:32.520 --> 10:34.840
So it's more visible, visible features.

10:34.840 --> 10:35.840
Okay.

10:35.840 --> 10:41.080
These radiology reports, are they coded or are they, is it just kind of natural text notes

10:41.080 --> 10:43.000
from the radiologists?

10:43.000 --> 10:44.560
They are natural text.

10:44.560 --> 10:48.960
I mean, sometimes, I mean, again, every hospital will have their own format template for reporting.

10:48.960 --> 10:53.720
There are some standard plates recommended by the radiology society of North America.

10:53.720 --> 11:00.920
But again, I mean, I think a lot of people don't use those templates, I mean, but so to

11:00.920 --> 11:05.720
answer your question, I mean, they are very varied, but they have some structure to it.

11:05.720 --> 11:13.800
These questions may be inspired by an image that you have on the Cure website.

11:13.800 --> 11:18.760
You're basically looking at a brain scan on the monitor.

11:18.760 --> 11:25.000
I'm wondering if setting aside machine learning and AI, are we getting to a point where radiologists

11:25.000 --> 11:31.920
are looking at these images digitally and creating bounding boxes and electronically

11:31.920 --> 11:38.360
notating these images in a way that will make it easier for future ML and AI applications

11:38.360 --> 11:42.560
or is it still all manual today?

11:42.560 --> 11:43.560
I mean, absolutely.

11:43.560 --> 11:49.360
I think what we are seeing is that definitely there is, I mean, a lot of work going into

11:49.360 --> 11:51.840
words, creating annotated data sets.

11:51.840 --> 11:53.560
And so a lot of hospitals are working on that.

11:53.560 --> 11:57.160
I mean, I think a lot of the hospitals in the US, I mean, for example, a mass general

11:57.160 --> 12:01.000
hospital, they have their own data science teams.

12:01.000 --> 12:03.120
And those teams are also working on similar problems.

12:03.120 --> 12:07.880
So there is definitely a lot of effort going towards creating these annotated data sets.

12:07.880 --> 12:10.320
So I would not say that, I mean, a lot of radiologists are working on it.

12:10.320 --> 12:15.520
I think focused groups in different parts of the world are working on these kinds of annotations.

12:15.520 --> 12:17.960
And it's not something which is completely standardized yet.

12:17.960 --> 12:18.960
Right.

12:18.960 --> 12:22.920
But it sounds like you're also saying that it's not, you know, we're not necessarily seeing

12:22.920 --> 12:29.840
the radiologists tool change to be more like a data annotation exercise.

12:29.840 --> 12:34.000
It's happening separately and it's some data science team that may be, you know, doing

12:34.000 --> 12:36.200
some of our things to what you were doing.

12:36.200 --> 12:37.200
Exactly.

12:37.200 --> 12:38.680
Because I mean, I'll tell you why.

12:38.680 --> 12:39.680
Right.

12:39.680 --> 12:44.640
So for example, one of the things we had to do was to when we were trying to detect bleeds

12:44.640 --> 12:49.920
from, I mean, bleeds from head CT scans, they had to actually go in or not as, but I

12:49.920 --> 12:55.160
mean, trained specialists had to go in and mark out the bleed on those scans.

12:55.160 --> 12:58.880
And that's a time-taking process because the CT scan of the head will somewhere between

12:58.880 --> 13:00.800
50 to 100 slices.

13:00.800 --> 13:04.240
And for each slice, there'll be either there's some, some of those slices, obviously, will

13:04.240 --> 13:05.240
not have a bleed.

13:05.240 --> 13:09.440
Or maybe all of them don't have a bleed, but some, you have a bleed, you have to actually

13:09.440 --> 13:12.480
mark the boundary of the bleed, which is not a continuous boundary.

13:12.480 --> 13:16.520
I mean, it's sort of a ragged boundary and then you have to mark through, mark all of

13:16.520 --> 13:17.520
that.

13:17.520 --> 13:19.880
That's time-consuming for radiologists.

13:19.880 --> 13:24.240
And so it will not be easy for somebody to sort of incorporate that into the radiology

13:24.240 --> 13:28.120
workflow because they want to see a scan, they want to report on it in a few minutes and

13:28.120 --> 13:29.120
then be done with that.

13:29.120 --> 13:32.160
And marking out the boundaries will take them maybe 20, 30 minutes.

13:32.160 --> 13:36.800
So I don't think some of these are easily incorporated into the workflow, which is why we sort

13:36.800 --> 13:41.040
of started doing this national language processing because we said there is a lot of data already

13:41.040 --> 13:45.480
available in the report because I am saying that, I mean, the radiologist is already writing

13:45.480 --> 13:49.040
that there is this plural effusion in this part of the lung.

13:49.040 --> 13:53.640
So we can extract out all that information from those reports and use that for training.

13:53.640 --> 13:57.560
So rather than getting them to sort of manually mark out these abnormalities.

13:57.560 --> 14:01.160
So you also mentioned these different acquisition patterns.

14:01.160 --> 14:06.920
These are related to the different types of radiology machines.

14:06.920 --> 14:09.000
These are radiology machines.

14:09.000 --> 14:14.600
The amount of exposure, I mean, amount of radiation that you produce.

14:14.600 --> 14:16.800
I mean, so there are, I mean, everybody will have a different setting.

14:16.800 --> 14:18.960
I mean, so these machines also have some settings.

14:18.960 --> 14:23.560
And so there are many different settings and so the, especially for X-rays, I mean, especially

14:23.560 --> 14:27.560
for X-rays, the data from each center is sort of slightly different.

14:27.560 --> 14:30.560
I mean, there is not exactly the same.

14:30.560 --> 14:31.560
Okay.

14:31.560 --> 14:32.560
It's interesting.

14:32.560 --> 14:38.800
I think, you know, there's a tendency to think about the, you know, CNNs or ML and AI

14:38.800 --> 14:44.880
in general as these, you know, maybe give them, give them more credit for being naturally

14:44.880 --> 14:47.680
generalized than they are.

14:47.680 --> 14:52.960
My daughter is doing an internship with the podcast currently where she's taking podcasts

14:52.960 --> 14:58.000
that we've already recorded and running them through automated transcription and looking

14:58.000 --> 15:03.120
at a bunch of different services and kind of rating their performance and, you know,

15:03.120 --> 15:09.200
over time, we've learned that some of the services do better with, you know, phone calls,

15:09.200 --> 15:14.840
some of them do better with podcasts, some of them do better with audio that's recorded

15:14.840 --> 15:20.760
in a room like the, the characteristics, the, you know, very subtle characteristics of

15:20.760 --> 15:27.840
the input data have a, a huge impact on the algorithm's ability to perform all and extract

15:27.840 --> 15:32.520
texts from them, much more so than you might think.

15:32.520 --> 15:37.680
And it sounds like you've, you've had very similar experiences on the, on the input side

15:37.680 --> 15:39.040
with these radiological images.

15:39.040 --> 15:44.160
So I have a very interesting story in this, I mean, so that's, when we started working

15:44.160 --> 15:47.840
on X-rays, this probably around two years back, so we, we were sort of still tying up

15:47.840 --> 15:52.280
with hospitals, we did not have any, any hospital data, any, any real data coming from our

15:52.280 --> 15:53.280
collaborators.

15:53.280 --> 15:55.960
So we were, we said, we will mine the internet for data.

15:55.960 --> 16:00.600
So we looked at some internet sources, we collected some 10,000 images and we said, let's,

16:00.600 --> 16:05.280
let's try to train a model on this and train the model on that and that was very accurate.

16:05.280 --> 16:09.080
I mean, it was super accurate in determining normal from abnormal.

16:09.080 --> 16:11.600
So it was classifying normal versus abnormal.

16:11.600 --> 16:15.080
And then we said, I mean, I mean, this is a very small amount of data, right?

16:15.080 --> 16:18.800
I mean, typically if you're looking at images, you'll look at millions, millions of images

16:18.800 --> 16:19.800
to train algorithms.

16:19.800 --> 16:20.800
Let me say it.

16:20.800 --> 16:21.800
Let's, let's see.

16:21.800 --> 16:23.280
I mean, so we look, we create an attribution algorithm.

16:23.280 --> 16:28.080
So we were attributing the figuring out which, I mean, if you attribute what exactly the

16:28.080 --> 16:30.040
algorithm is learning, you can find out boxes.

16:30.040 --> 16:34.000
So we can basically, for example, there is a something called occlusion, occlusion based,

16:34.000 --> 16:38.640
occlusion based attribution where you can black out one box, one small box within the

16:38.640 --> 16:43.320
whole image and then see what is the attribution of that to the prediction.

16:43.320 --> 16:47.480
So if you, if you black out a box because of which the algorithm is saying that that particular

16:47.480 --> 16:52.960
x-rays abnormal, then suddenly it becomes normal, the prediction changes from normal to abnormal.

16:52.960 --> 16:57.560
And you look at how each box is impacting the probability of being normal or abnormal.

16:57.560 --> 17:01.360
So the boxes which have the highest impact will have the highest difference between the

17:01.360 --> 17:04.000
normal versus abnormal probability when they are blacked out.

17:04.000 --> 17:09.040
So we created these attribution methods and we were trying to attribute the algorithm,

17:09.040 --> 17:10.320
what the algorithm was learning.

17:10.320 --> 17:15.280
And we found that the algorithm actually was learning to distinguish something very simple

17:15.280 --> 17:17.720
because what was there, these were internet images.

17:17.720 --> 17:21.680
So typically, all the abnormal images had a lot of text on them.

17:21.680 --> 17:26.760
So some typing or some written text and the normal images did not have any annotation,

17:26.760 --> 17:29.120
any kind of text or anything like that.

17:29.120 --> 17:32.120
So it was basically any to recognize typewritten letters.

17:32.120 --> 17:33.640
I mean, that's what it's pointing to.

17:33.640 --> 17:36.920
So if it sees typewritten letters, it will assume that it's abnormal.

17:36.920 --> 17:39.040
If it doesn't see typewritten letters, it's normal.

17:39.040 --> 17:40.800
So that is what it was learning.

17:40.800 --> 17:43.000
And so these algorithms are very, very good.

17:43.000 --> 17:46.400
I mean, they're very smart, but also they can learn very different things.

17:46.400 --> 17:49.000
I mean, then what do you expect them to learn?

17:49.000 --> 17:54.600
So you've learned the importance of real data and these different input patterns.

17:54.600 --> 17:59.720
And you've kind of learned some things about the model's ability to generalize across

17:59.720 --> 18:00.720
this.

18:00.720 --> 18:01.720
What else have you learned?

18:01.720 --> 18:06.840
See, other things that we have learned are also that, I mean, if you look at, when we

18:06.840 --> 18:14.440
look at all the research in image and all of them are 224 by 224 images, because that's

18:14.440 --> 18:15.440
the image net size.

18:15.440 --> 18:19.640
And we look at most research is about that size of image.

18:19.640 --> 18:24.240
And if you look at an x ray, I mean, typical chest x ray will be around 4,000 by 4,000 pixels.

18:24.240 --> 18:28.760
So if you are downsizing, so initially, when we started out doing research, we started

18:28.760 --> 18:34.520
with taking that 4,000 by 4,000 or I mean, that size image and downsizing it to, to

18:34.520 --> 18:39.600
2, 2, 2, 2, 2, 3, 4, 24, 24, which basically takes away a lot of the detail that you're looking

18:39.600 --> 18:40.600
at.

18:40.600 --> 18:43.880
I mean, so you cannot, I mean, obviously, if you have a lot of data, it'll, it'll

18:43.880 --> 18:44.880
learn.

18:44.880 --> 18:48.680
Well, I mean, it will be able to detect really large abnormalities, it'll not be able to detect

18:48.680 --> 18:49.920
subtle abnormalities.

18:49.920 --> 18:55.440
And so then we had to devise our own methods to sort of work with higher resolution images.

18:55.440 --> 18:58.000
So today, we are able to work with full resolution images.

18:58.000 --> 19:01.520
So we had to sort of look at patches at a time and do a lot of different techniques.

19:01.520 --> 19:05.760
I mean, some of these are our own IP, so we have not published it yet.

19:05.760 --> 19:09.600
So I cannot reveal it, but there is, there's a lot of work which we have done which sort

19:09.600 --> 19:13.800
of enables us to look at the full size image rather than looking at these down sampled

19:13.800 --> 19:14.800
images.

19:14.800 --> 19:17.640
And that's all the backs of what I see, I mean, out there in terms of literature.

19:17.640 --> 19:24.080
I mean, everybody is taking these standard sort of dense nets or resonates and then applying

19:24.080 --> 19:26.040
them to the down sampled images.

19:26.040 --> 19:30.560
And that also loses a lot of information from that original image.

19:30.560 --> 19:35.120
So that's, if you look at most of the literature, that's what is happening right now.

19:35.120 --> 19:40.960
Is there anything that you can say generally about the approach that you've taken to look

19:40.960 --> 19:42.760
at the large images?

19:42.760 --> 19:49.160
Are you like windowing across the images or any hints you can give us?

19:49.160 --> 19:50.920
So it's a patch based approach.

19:50.920 --> 19:58.360
I mean, we look at patches, we determine some patches and so that's, that's all I can

19:58.360 --> 19:59.360
see.

19:59.360 --> 20:05.080
There is definitely some very, very strong IP in there which sort of, because I don't

20:05.080 --> 20:07.880
think anybody right now is working on large images.

20:07.880 --> 20:11.360
I think everybody else is working on smaller sized images.

20:11.360 --> 20:17.920
And we also tried, I mean, so we also tried training these, I mean, larger sized using the

20:17.920 --> 20:22.360
typical dense nets, and it sort of doesn't perform as well.

20:22.360 --> 20:24.200
I mean, or sometimes it doesn't converge at all.

20:24.200 --> 20:27.720
So we saw lots of convergence problems with larger sized images.

20:27.720 --> 20:31.720
And do you have any intuition for why that is?

20:31.720 --> 20:38.120
I don't actually, I don't, I mean, we have tried that and I really don't have clue why

20:38.120 --> 20:39.400
why that doesn't work typically.

20:39.400 --> 20:42.040
I mean, so not sure.

20:42.040 --> 20:43.040
But there is not much testing.

20:43.040 --> 20:46.400
I mean, honestly, when I look at research, there is not much testing that has been done

20:46.400 --> 20:52.080
on larger images because most of the work, I mean, 224 by 224 is a decent size for your

20:52.080 --> 20:53.080
regular images.

20:53.080 --> 20:56.920
So that's, that's sort of, I don't, I don't see that there is a lot of work done in

20:56.920 --> 20:58.600
that, in that area.

20:58.600 --> 21:05.560
In your approach and or the literature that you've seen, does transfer learning play a lot

21:05.560 --> 21:10.800
or are you looking at pre-trained models or models, you know, that are pre-trained with

21:10.800 --> 21:14.560
image net or some other data set, or are you just training from scratch?

21:14.560 --> 21:21.360
So we have, we found that a pre-training with ImageNet and then using that on our data

21:21.360 --> 21:24.840
set running, I mean, using pre-training on image net did not improve performance on

21:24.840 --> 21:26.760
the on our data sets.

21:26.760 --> 21:30.840
But what we found is that there is opportunity to do transfer learning within the domain.

21:30.840 --> 21:35.800
So I could basically learn from other types of x-rays and use that learning to test x-rays.

21:35.800 --> 21:39.040
So there is some, some of that learning that we have been able to use.

21:39.040 --> 21:43.280
But again, that the transfer learning there, the impact of that is very small.

21:43.280 --> 21:46.880
I mean, I think it also has to do with the amount of data that we have because we have so

21:46.880 --> 21:47.880
much data.

21:47.880 --> 21:50.520
Probably, I mean, the transfer learning is not that impactful.

21:50.520 --> 21:54.720
But if you have a amount of data, then maybe if you transfer knowledge from other other

21:54.720 --> 21:56.720
domains, it might be more useful.

21:56.720 --> 21:57.720
What else have you learned?

21:57.720 --> 22:03.000
I think, I mean, some of the learnings are about the annotations also.

22:03.000 --> 22:09.720
I mean, so what we have learned is that we can do annotations at multiple levels and

22:09.720 --> 22:14.360
bring, I mean, train models which can do multi-level, so basically there are multiple types

22:14.360 --> 22:15.360
of classification.

22:15.360 --> 22:19.160
So one is that, one is to segment out the abnormality.

22:19.160 --> 22:24.080
So you're actually, the annotation will involve actually going into that image or that slice

22:24.080 --> 22:28.040
of a CD scan and then saying that this is the boundary of the abnormality.

22:28.040 --> 22:33.040
So clearly marking that out, a second type of annotation that we have done is looking

22:33.040 --> 22:35.240
at, for example, on a CD scan, slice by slice.

22:35.240 --> 22:39.240
So you can basically look at one slice and say whether that slice is abnormal or not,

22:39.240 --> 22:43.960
which is a much easier task than actually annotating and going out and marking out the

22:43.960 --> 22:45.240
abnormality on that.

22:45.240 --> 22:50.840
So that's a second type of annotation and then the third type of annotation is at a scan

22:50.840 --> 22:55.000
level, either at the whole CD scan level or at the extra level, using the report, we can

22:55.000 --> 22:58.720
extract out the abnormality on that particular scan.

22:58.720 --> 23:01.920
So I mean, we have models which combine all three of these.

23:01.920 --> 23:05.520
So we can, we have losses, I mean, losses which will take the segmentation losses and

23:05.520 --> 23:10.200
add the classification losses at a slice level and the classification losses at the scan

23:10.200 --> 23:11.680
level and combine all of that.

23:11.680 --> 23:16.560
So those are the models where we can actually take all the data that we have because we

23:16.560 --> 23:21.000
have 350,000 HD scans and we cannot expect to label all of them.

23:21.000 --> 23:26.320
I mean, we cannot expect to sort of, 350,000 HD scans each with, let's say, 100 slices.

23:26.320 --> 23:30.880
So you're talking about 35 million slices.

23:30.880 --> 23:34.360
So we cannot expect to sort of mark out all of them.

23:34.360 --> 23:38.520
So you have to mark out a subset of that and so we have marked out a subset of that.

23:38.520 --> 23:43.160
We have labeled at a slice level, a subset of that and then of course, for each of those

23:43.160 --> 23:47.360
350,000 scans, we have got a report so we have, we can extract out the abnormalities

23:47.360 --> 23:49.520
from those as well.

23:49.520 --> 23:53.280
So we have combined all of this and then the models that perform the best on our data

23:53.280 --> 23:57.080
are ones which combine all this knowledge, all the knowledge from all of these types

23:57.080 --> 23:58.080
of annotation.

23:58.080 --> 24:02.800
So just to clarify then, if you're, you know, when I think about a traditional, like

24:02.800 --> 24:09.120
a resonant type of a model, that's a model that is basically looking at a single image.

24:09.120 --> 24:14.640
Is the implication that you've built out an architecture that, you know, is almost,

24:14.640 --> 24:20.080
I'm almost thinking of it like a 3D type of architecture that is, that takes in multiple

24:20.080 --> 24:25.920
slices and kind of understands the relationship between these slices relative to the whole

24:25.920 --> 24:26.920
scan.

24:26.920 --> 24:27.920
Right.

24:27.920 --> 24:28.920
Right.

24:28.920 --> 24:29.920
Exactly.

24:29.920 --> 24:30.920
Exactly.

24:30.920 --> 24:34.720
Tell me a little bit about the process of defining or coming up with this model architecture.

24:34.720 --> 24:39.520
How did you arrive at the final architecture for doing that?

24:39.520 --> 24:42.320
So I think, I mean, it's, I mean, primarily trial and error.

24:42.320 --> 24:48.400
I mean, reading the latest papers and, I mean, we have, I mean, around 10 plus deep learning

24:48.400 --> 24:49.400
scientists now.

24:49.400 --> 24:53.280
I mean, so, I mean, each person focused on their own problem.

24:53.280 --> 24:58.600
And I mean, I think what, what we have basically been doing is, I mean, looking at what is

24:58.600 --> 25:03.000
the latest research in a physics space and trying to implement that.

25:03.000 --> 25:06.400
I mean, so we've implemented many different techniques from many different papers.

25:06.400 --> 25:07.400
Some of them work.

25:07.400 --> 25:08.400
Some of them don't work.

25:08.400 --> 25:09.400
Or a lot of them don't work.

25:09.400 --> 25:10.400
I mean, very few of them work.

25:10.400 --> 25:13.880
But so a lot of them don't translate directly.

25:13.880 --> 25:18.120
I mean, I think what we have seen is that there are lots of new techniques out there, lots

25:18.120 --> 25:22.800
of new, I mean, which show very promising results on the paper itself shows very promising

25:22.800 --> 25:23.800
results.

25:23.800 --> 25:27.600
But then when we apply it to the domain that we are working in, it doesn't really translate

25:27.600 --> 25:28.600
well.

25:28.600 --> 25:29.600
So we have seen that.

25:29.600 --> 25:33.160
But I mean, typically our architectures are very simple. I mean, in fact, what we have

25:33.160 --> 25:37.080
found is that the simpler you make it, the better it is.

25:37.080 --> 25:42.120
Can you give me an example of something that you tried that was more on the complex side

25:42.120 --> 25:47.000
that you thought would add a lot of value, but it ended up doing something simpler, worked

25:47.000 --> 25:48.000
out better?

25:48.000 --> 25:52.000
You were trying GANs at some point of time to see if we could generate abnormal and normal

25:52.000 --> 25:57.520
X-rays using GANs and then use that for training or use that to do a data augmentation.

25:57.520 --> 26:04.680
And we have tried other techniques, I mean, even some of the techniques from video action

26:04.680 --> 26:08.600
recognition and videos we've tried for our head CD scan technology.

26:08.600 --> 26:12.240
And some of these, I mean, again, some of these have not really worked out.

26:12.240 --> 26:17.000
I mean, I think more complex technology, we have not seen that it sort of translates

26:17.000 --> 26:18.000
to real.

26:18.000 --> 26:22.080
I mean, again, I mean, I would not say that some of the technologies that we developed have

26:22.080 --> 26:23.080
not been complex.

26:23.080 --> 26:27.120
But again, I think in general, I mean, I would not, I would say that a lot of things that

26:27.120 --> 26:28.800
we've tried have not worked out.

26:28.800 --> 26:34.600
Yeah, it sounds like you're, you know, you're describing a world in which we might think

26:34.600 --> 26:43.040
of as applied ML and AI, there's still a lot of research involved in your process for

26:43.040 --> 26:46.000
developing this product suite and bringing it to market.

26:46.000 --> 26:47.000
Absolutely.

26:47.000 --> 26:50.920
I mean, I think there is a huge amount of research, there is a huge amount of domain

26:50.920 --> 26:57.160
knowledge, which we have brought in, I mean, which just makes the algorithm much better.

26:57.160 --> 27:00.000
So I mean, simple things actually make it easier.

27:00.000 --> 27:03.600
I mean, so for example, if you're detecting fractures, if you see, I mean, if you just

27:03.600 --> 27:06.440
train a model on fractures, you'll probably see a lower accuracy.

27:06.440 --> 27:10.160
But if you look at what is around the fracture, I mean, if you also detect bleeds and use

27:10.160 --> 27:14.400
that to, I mean, prove your knowledge about the situation, you'll probably get, we actually

27:14.400 --> 27:16.600
get a better accuracy, better probability.

27:16.600 --> 27:20.400
So I mean, if you have a fracture, you most likely have a bleed in the brain also.

27:20.400 --> 27:24.960
So I think bringing in a lot of domain knowledge is critical in some of the areas that we're

27:24.960 --> 27:25.960
working on.

27:25.960 --> 27:29.680
I mean, for example, detecting tuberculosis, you have to look at certain types of features.

27:29.680 --> 27:32.960
So you have looking at certain things, I mean, on the upper lungs, I mean, so it fits

27:32.960 --> 27:35.960
in the lower part of the lungs, that's not going to be very relevant.

27:35.960 --> 27:40.880
So we have, I mean, brought in a huge amount of radiology knowledge into what the algorithms

27:40.880 --> 27:44.080
have developed and those actually add a lot of value.

27:44.080 --> 27:47.520
And of course, I mean, the research also is the, I mean, we also have to do a lot of research

27:47.520 --> 27:52.320
because as I mentioned earlier, most of the material out there is focused on the types of

27:52.320 --> 27:56.120
images that are much smaller and also two-dimensional, right?

27:56.120 --> 27:59.960
I mean, so you're looking at mostly two-dimensional videos, two-dimensional images.

27:59.960 --> 28:02.800
Only in case of videos, you're looking at something which is not too dimensional, but

28:02.800 --> 28:05.200
at least your sequence of images.

28:05.200 --> 28:10.560
And we look at a CD scan or a MRI, I mean, all of these are three-dimensional images.

28:10.560 --> 28:14.040
You have to sort of get knowledge from all of the slides and bring that all together

28:14.040 --> 28:16.440
to infer a classification there.

28:16.440 --> 28:21.080
So we have to, I mean, congest, I mean, sort of ingest knowledge from these sources, which

28:21.080 --> 28:25.040
again, there is not much literature out there on some of these topics.

28:25.040 --> 28:30.120
So though, of course, I mean, there are lots of people now working on this, on technologies

28:30.120 --> 28:31.520
in the medical space.

28:31.520 --> 28:36.200
But when we started, I mean, which we started around two and a half years back, there were

28:36.200 --> 28:42.000
very few people who were working on deep learning in the healthcare space, which is exponentially

28:42.000 --> 28:44.200
increased in the last couple of years.

28:44.200 --> 28:51.800
And out of curiosity, have you directly applied any of the work or models that originated

28:51.800 --> 28:56.480
in looking at videos to this CT scan problem?

28:56.480 --> 28:57.480
We have.

28:57.480 --> 28:58.480
We have.

28:58.480 --> 29:00.440
Did that work out or was that another dead end or?

29:00.440 --> 29:02.920
Well, I think that that's something that has worked out for us.

29:02.920 --> 29:04.760
I mean, some of these techniques have worked out for us.

29:04.760 --> 29:08.120
But I would not be able to go into much detail on that right now because it's still something

29:08.120 --> 29:13.280
that we are working on and we don't have, I mean, I, yeah, so we have not published anything

29:13.280 --> 29:14.280
on that yet.

29:14.280 --> 29:19.560
The company has been active in publishing some of his research findings.

29:19.560 --> 29:25.200
What are some of the recent work that you've published?

29:25.200 --> 29:27.520
So we have published recently.

29:27.520 --> 29:34.200
We published our work on head CT algorithm, which basically detects in multiple kinds

29:34.200 --> 29:39.520
of bleeds, fractures, midland shift, mass effect from head CT scans.

29:39.520 --> 29:45.240
And this, we sort of published some details of the algorithm or, I mean, this is our,

29:45.240 --> 29:48.680
the earlier version of our algorithm, which is probably around nine, I mean, around a year

29:48.680 --> 29:49.680
old.

29:49.680 --> 29:55.440
And we sort of did a validation study of that on on a data set where, so we, we, we had

29:55.440 --> 30:01.840
a data set of 350,000 of which we had basically a training set, a validation set and a testing

30:01.840 --> 30:02.840
set.

30:02.840 --> 30:07.720
But then what we did is we went out and collected an additional 500 scans, which was from

30:07.720 --> 30:09.880
a very different source, completely new source.

30:09.880 --> 30:14.400
And we had those three sort of reported or basically a radiologist had to go in and mild on

30:14.400 --> 30:17.920
a user interface, whether they found an interapparent primal bleed, whether they found a fracture

30:17.920 --> 30:18.920
and so on.

30:18.920 --> 30:20.280
So just a tick box.

30:20.280 --> 30:24.480
And we had sort of three radiologists do that on those 500 scans.

30:24.480 --> 30:27.320
And we also compared our accuracy against that.

30:27.320 --> 30:35.040
And we found that we were 95% at 0.95 plus you see on all of these, all of these detecting

30:35.040 --> 30:36.640
all of these abnormalities.

30:36.640 --> 30:38.200
Now this is, this is slightly older.

30:38.200 --> 30:41.520
I mean, so the technology that we have published there is maybe around a year old.

30:41.520 --> 30:48.600
Now it is currently, I mean, what we are looking at is around 0.97 plus 0.97 plus on abnormalities.

30:48.600 --> 30:53.280
So it's, it's improved a little bit since we published that work.

30:53.280 --> 30:56.120
Has, have you published any data sets in this space?

30:56.120 --> 30:57.120
Yes.

30:57.120 --> 30:59.800
So we also open sourced this data set of 500 scans.

30:59.800 --> 31:05.640
So it's actually for exactly 491, we have published that, we open sourced that data set along

31:05.640 --> 31:09.440
with the ground truth for that, which is basically the reading of the radiologists.

31:09.440 --> 31:13.520
So I mean, one of the challenges that we found is that everybody claims their own accuracy

31:13.520 --> 31:17.240
and there is no common data set on which people can sort of compare their accuracies.

31:17.240 --> 31:20.480
Like, for example, imagine it is there, you can compare accuracy and imagine it.

31:20.480 --> 31:23.360
There is nothing in the, in the, in most of these space.

31:23.360 --> 31:26.320
I mean, so head CT, we said, let's put together this data set.

31:26.320 --> 31:29.120
And then let's, I mean, we, we published our results for that.

31:29.120 --> 31:33.320
I mean, of course, we anticipate that other people can also use that to publish their results

31:33.320 --> 31:34.680
on that particular data set.

31:34.680 --> 31:37.080
And you said, how many scans in the data set?

31:37.080 --> 31:38.080
491.

31:38.080 --> 31:44.800
And is, is that that number of scans enough to really build interesting models against?

31:44.800 --> 31:48.080
It will be hard to get a very accurate model.

31:48.080 --> 31:50.120
You could start and you could build some models on that.

31:50.120 --> 31:52.240
It, it definitely, you could build models.

31:52.240 --> 31:56.480
I mean, maybe the accuracy will suffer a little bit because it's not very large.

31:56.480 --> 32:02.880
I mean, so basically if you, we have 491 of which, I would say around 300 or so, I mean,

32:02.880 --> 32:05.480
I don't remember the exact numbers, but around 300 of them are abnormal.

32:05.480 --> 32:10.160
And of those abnormalities, if you look at a specific kind of bleed, let's say an extra

32:10.160 --> 32:13.880
dual bleed, there are probably around 40, 50 scans which have got extra dual bleeds.

32:13.880 --> 32:18.760
So that itself may not be enough for you to determine and be able to train a model to determine,

32:18.760 --> 32:20.520
to identify an extra dual bleed.

32:20.520 --> 32:25.640
But this data set, the intention was not for people to train more, more for people to validate.

32:25.640 --> 32:29.840
So you can get and measure your algorithm, which you've trained on another data set.

32:29.840 --> 32:33.800
And you can measure your performance on this data set and you can definitely measure that

32:33.800 --> 32:35.200
to a very high level of accuracy.

32:35.200 --> 32:36.200
Okay.

32:36.200 --> 32:37.400
So it's four of more of a testing data set.

32:37.400 --> 32:38.400
Got it.

32:38.400 --> 32:43.880
And are the scans, these full three-dimensional scans with multiple slices each as well?

32:43.880 --> 32:46.360
Or are they static slices?

32:46.360 --> 32:47.360
They are there three-dimensional.

32:47.360 --> 32:51.440
So they have, I would say, anywhere from 5200 slices per scan.

32:51.440 --> 32:55.640
What kind of uptake have you seen on that, has anyone, have you seen other groups doing

32:55.640 --> 32:58.240
validation against it and publishing their results?

32:58.240 --> 33:03.920
I mean, I have not seen, at least, I have not looked at it in the last month or so.

33:03.920 --> 33:07.800
But I mean, before that, I have not seen, we released this data set in March.

33:07.800 --> 33:10.920
So it's not been a long time.

33:10.920 --> 33:14.440
But we have seen, so I don't know if other people have published, I mean, I have not seen

33:14.440 --> 33:17.280
anybody publish against it as far as I know.

33:17.280 --> 33:22.000
But I have seen, we have seen, I mean, hundreds of people download that data.

33:22.000 --> 33:25.640
And so hopefully we'll see some publications out of that soon enough.

33:25.640 --> 33:31.840
When you're building out these models, so you've looked at head CT scans, you've looked

33:31.840 --> 33:41.040
at chest X-rays, you've looked at skull fractures, is your objective to create a single model

33:41.040 --> 33:49.080
that is able to detect abnormalities in each of these different, very different scenarios

33:49.080 --> 33:56.040
or are you building a suite of very specialized tools that is specially trained and focused

33:56.040 --> 33:59.840
on one particular problem space?

33:59.840 --> 34:04.080
I mean, it's much more, I mean, actually, we are building very, very specialized tools.

34:04.080 --> 34:08.280
In fact, if you look at chest X-ray, we detect 15 different types of abnormalities.

34:08.280 --> 34:11.640
And for each abnormality, we have multiple models.

34:11.640 --> 34:13.240
And so it's an ensemble of many models.

34:13.240 --> 34:17.520
So the number of models that go into even detecting these abnormalities from a single

34:17.520 --> 34:22.520
chest X-ray, on a single chest X-ray, we run around 112 models right now to determine

34:22.520 --> 34:25.040
all the different things we can report on that X-ray.

34:25.040 --> 34:27.800
So we are building very, very specialized models.

34:27.800 --> 34:32.680
And I don't think, I mean, there is no, I mean, we will not, definitely, I do not anticipate

34:32.680 --> 34:37.640
that we will be building models, which can detect multiple kinds of abnormalities from

34:37.640 --> 34:39.640
different kinds of images.

34:39.640 --> 34:41.880
So we'll have very specialized algorithms for each.

34:41.880 --> 34:47.480
When you take a step back and you think about bringing these types of tools to market,

34:47.480 --> 34:53.840
what are some of the things that you've done with this and mine to build?

34:53.840 --> 34:56.640
I want to say build scale, but that's not really the right word.

34:56.640 --> 35:05.400
It's almost like manage technical debt to manage all of these models and to allow you to efficiently

35:05.400 --> 35:08.640
manage all of these models, I guess, and bring them to market.

35:08.640 --> 35:14.640
Is there tooling that you build or an approach that you've taken that helps you manage all

35:14.640 --> 35:18.880
of the complexity created by having so many very specific models?

35:18.880 --> 35:23.320
I mean, I would also add, there is one more complexity is that these models are improving

35:23.320 --> 35:25.040
at a very, very fast rate.

35:25.040 --> 35:29.840
I mean, so every month are models improved by a few percentage points.

35:29.840 --> 35:31.040
So that is also there.

35:31.040 --> 35:34.880
I mean, so in terms of a release cycle for our algorithms, we also have to figure that

35:34.880 --> 35:35.880
out.

35:35.880 --> 35:39.800
So there are multiple challenges, but what we are, one of the things that we are doing

35:39.800 --> 35:44.200
is to deploy these models as a cloud-based service.

35:44.200 --> 35:46.360
So that is the preferred model of deployment for us.

35:46.360 --> 35:50.400
So in that cloud-based service, then you can sort of, you are basically, you can host

35:50.400 --> 35:53.320
those models and you have a full ownership of the models.

35:53.320 --> 35:57.760
And if you want to sort of upgrade them, it's not too much of an effort because you are

35:57.760 --> 35:58.760
owning that.

35:58.760 --> 36:03.080
So that's sort of the model that we prefer in terms of deployment.

36:03.080 --> 36:07.480
Of course, I mean, some places we are working towards an on-premise deployment and then

36:07.480 --> 36:10.920
in those scenarios, upgrading the models, I mean, they get a static version, I mean, they

36:10.920 --> 36:13.720
get a current version and then upgrading them will be challenging.

36:13.720 --> 36:18.760
So cloud-based service allows us to, allows us to mitigate some of the problems that you

36:18.760 --> 36:19.760
talk about.

36:19.760 --> 36:22.320
Prashant, thanks so much for taking the time to chat with me.

36:22.320 --> 36:28.720
This has been super interesting and I've enjoyed learning from what you've learned.

36:28.720 --> 36:29.720
Thank you so much, Sam.

36:29.720 --> 36:33.200
Great talking to you as well and thank you for inviting me on this podcast.

36:33.200 --> 36:34.200
Great talking to you.

36:34.200 --> 36:35.200
Fantastic.

36:35.200 --> 36:36.200
Thank you.

36:36.200 --> 36:41.440
All right, everyone, that's our show for today.

36:41.440 --> 36:46.600
For more information on Prashant or any of the topics covered in this episode, head over

36:46.600 --> 36:51.520
to twimmalai.com slash talk slash 165.

36:51.520 --> 36:57.440
Don't forget to visit twimmalai.com slash nominate and cast your vote for us in the People's

36:57.440 --> 36:59.800
Choice Podcast Awards.

36:59.800 --> 37:08.680
As always, thanks so much for listening and catch you next time.

