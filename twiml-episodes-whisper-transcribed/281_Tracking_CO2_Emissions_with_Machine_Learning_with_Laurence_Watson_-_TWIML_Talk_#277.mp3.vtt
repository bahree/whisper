WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:31.920
I'm your host Sam Charrington.

00:31.920 --> 00:36.760
You are invited to join us for the very first Twimblecon conference which will focus on the

00:36.760 --> 00:41.200
tools, technologies and practices necessary to scale the delivery of machine learning

00:41.200 --> 00:43.720
and AI in the enterprise.

00:43.720 --> 00:48.600
The event will be held October 1st and 2nd in San Francisco and early bird registration

00:48.600 --> 00:58.720
is open today at twimblecon.com, again that's twimblecon.com, I can't wait to see you there.

00:58.720 --> 01:01.680
All right everyone, I am on the line with Lawrence Watson.

01:01.680 --> 01:04.960
Lawrence is a data scientist at Carbon Tracker.

01:04.960 --> 01:08.360
Lawrence, welcome to this week in machine learning and AI.

01:08.360 --> 01:10.640
Hi Sam, great to be on the show.

01:10.640 --> 01:13.520
It is great to have you on the show.

01:13.520 --> 01:19.640
Let's get started by exploring a bit of your background, you started out in physics,

01:19.640 --> 01:25.120
made your way over to climate change policy and now you're working in data science in

01:25.120 --> 01:26.280
that field.

01:26.280 --> 01:30.040
Tell us a little bit more about that path for you.

01:30.040 --> 01:34.640
Sure, so when I was small I always wanted to be a physicist.

01:34.640 --> 01:38.960
I just love to ask why and to get down to the root of the question and when you got

01:38.960 --> 01:43.560
to the fundamental laws of the universe, I thought there was far enough.

01:43.560 --> 01:47.920
When I finished my degree, I really wanted to have a positive impact or to address some

01:47.920 --> 01:51.520
of the issues that needed addressing in the world so I decided to try and work on clean

01:51.520 --> 01:53.400
energy and energy policy.

01:53.400 --> 01:58.480
I worked with a think tank that campaigned to reform the European carbon markets and that

01:58.480 --> 02:01.560
was when I got started into programming.

02:01.560 --> 02:06.040
They had a Python and Django stack in fact and I sort of took over looking after their

02:06.040 --> 02:11.040
database, scraping the European Commission's website where they released all of the data

02:11.040 --> 02:17.960
about who was buying and selling these emissions permits and then went from there really and

02:17.960 --> 02:22.480
I've been at carbon tracker almost two years trying to convince the financial markets

02:22.480 --> 02:24.160
about climate risk.

02:24.160 --> 02:27.760
When you say trying to convince the financial markets about climate risk, what is that

02:27.760 --> 02:28.760
intel?

02:28.760 --> 02:29.760
Sure.

02:29.760 --> 02:37.040
So we, carbon tracker popularized this idea of a carbon bubble that if the valuations

02:37.040 --> 02:41.160
of fossil fuel companies that are some extent based on the amount of fossil fuels they're

02:41.160 --> 02:46.000
going to sell in the future, if they're wrong in their predictions and those valuations

02:46.000 --> 02:52.160
are in fact going to be constrained by climate change either by economic factors or by governments

02:52.160 --> 02:57.200
saying you're not going to be allowed to continue in this way that has a financial implication.

02:57.200 --> 03:02.960
So it's all been about quantifying the extent to which they're going to face those risks.

03:02.960 --> 03:04.520
Practically what does that mean?

03:04.520 --> 03:14.640
What is the carbon tracker product or service that works on what this qualification?

03:14.640 --> 03:21.320
So we've done a lot of work on oil and gas and then I've been working on coal power.

03:21.320 --> 03:25.480
For oil and gas we put all the oil projects on a cost curve.

03:25.480 --> 03:30.880
So we say how much does it cost for the company X in this region to produce a barrel of oil?

03:30.880 --> 03:36.600
And then we say how much oil could we burn in a climate compatible scenario?

03:36.600 --> 03:41.120
And the projects that are above the line don't make it in.

03:41.120 --> 03:45.840
And so we say, you know, some companies are better positioned for this energy transition

03:45.840 --> 03:47.800
in the climate compatible way and some aren't.

03:47.800 --> 03:51.360
And then we started doing the same for coal power, saying if there's going to be a coal

03:51.360 --> 03:55.600
power phase out in a given country, how should that be done if it's done on the least cost

03:55.600 --> 03:56.600
basis?

03:56.600 --> 04:02.080
Which company has the highest cost units and should therefore be closed down first?

04:02.080 --> 04:08.240
And that is about the market as well, because I'm saying close down, but it may be that

04:08.240 --> 04:12.960
the market sends a signal such that the coal plant is no longer economically viable and

04:12.960 --> 04:16.080
that phase out would happen in the same way.

04:16.080 --> 04:24.160
And so who are the users of this intelligence, is it the policymaker or the companies themselves?

04:24.160 --> 04:28.440
We think that we have some appeal to a lot of different audiences, definitely policymakers,

04:28.440 --> 04:32.240
because they need to be aware of these forces that are going on in the end to transition

04:32.240 --> 04:35.560
and make sure the policies are there to support it.

04:35.560 --> 04:41.400
But investors certainly, because we think there's a lot of shareholder value at risk for

04:41.400 --> 04:44.800
companies that aren't prepared for the changes that are happening.

04:44.800 --> 04:49.080
We've seen that a lot in Europe in the utility sector, where European utilities lost a lot

04:49.080 --> 04:53.840
of money because they didn't see renewables coming, essentially.

04:53.840 --> 04:57.320
But also to campaigners and journalists as well.

04:57.320 --> 05:00.440
And so where does data science fit into all of this?

05:00.440 --> 05:07.240
So we take a lot of different databases from all sorts of different sources and try and

05:07.240 --> 05:09.760
join them up.

05:09.760 --> 05:14.280
But the project that we've done more recently was really about looking at places where

05:14.280 --> 05:20.560
the databases weren't so good, where it's very hard to get publicly available data about

05:20.560 --> 05:25.040
the kinds of operations that we're trying to find out about.

05:25.040 --> 05:31.200
So trying to find coal production data, trying to find it out about how plants in India

05:31.200 --> 05:36.200
have running their pollution technologies, all of which has impacts on how much they cost

05:36.200 --> 05:38.560
to run and the profitability of the companies.

05:38.560 --> 05:44.000
So it's about joining up different data sources, making them talk to each other and about

05:44.000 --> 05:47.720
filling in the gaps, where we don't have good data.

05:47.720 --> 05:49.400
So walk us through the process.

05:49.400 --> 05:55.440
How did you go about pulling together all of these data sources?

05:55.440 --> 06:02.920
So firstly, I have to give thanks to all of the data providers all around the world doing

06:02.920 --> 06:09.200
a huge amount of good work in terms of making, I mean, we buy a lot of data sets, but

06:09.200 --> 06:14.800
there are also some really good freely available public data sets, including coal swarm, which

06:14.800 --> 06:21.720
have a global database about operating coal plants, which I know is a lot of work and

06:21.720 --> 06:26.960
really a testament as well to open source, because they have a website where a wiki site

06:26.960 --> 06:31.280
where people can upload information, so they aggregate them, do a lot of work themselves

06:31.280 --> 06:33.320
to put it all together.

06:33.320 --> 06:40.760
Of course, there's no uniform naming as often the case, so we have to do a lot of string

06:40.760 --> 06:47.080
matching and patent matching in order to sync up where we think these projects are and

06:47.080 --> 06:51.680
bring together these different qualities that we're looking for basically in terms of capacity

06:51.680 --> 06:56.960
in terms of ownership, and these things are often some organization may be really interested

06:56.960 --> 07:01.040
in what is there, but a different organization may be really interested in who owns it and

07:01.040 --> 07:06.040
how that ownership structure has changed over time, so gluing those things together, and

07:06.040 --> 07:13.080
in terms of how we do it, because carbon track has a lot of X city analysts, so we do a

07:13.080 --> 07:19.240
lot of analysis in Excel, and so my first task in the beginning was to interface with

07:19.240 --> 07:26.200
a lot of existing Excel databases and put them into SQL, which is usually what I would

07:26.200 --> 07:34.520
use, and then just a lot of string matching, they're not terribly exciting at the base layer,

07:34.520 --> 07:36.840
but essential for everything we did on top.

07:36.840 --> 07:41.760
Okay, and are you doing some work with satellite imagery as well, is that right?

07:41.760 --> 07:48.600
Yeah, yeah, so why don't I just jump in and tell you a little bit about that project?

07:48.600 --> 07:54.960
And so what we wanted to find out was the capacity factor of coal plants, and the capacity

07:54.960 --> 08:00.400
factor is simply how much of the time, more proportion of the time they're running compared

08:00.400 --> 08:06.960
to their maximum theoretical maximum output, and that's a key part of the financial evaluation

08:06.960 --> 08:15.280
of any plant, because the profits that they can make are a balance between the revenues

08:15.280 --> 08:19.960
they can earn when they run, and the ongoing costs, and the fixed costs that they have

08:19.960 --> 08:25.640
to pay every year in terms of maintenance costs, in terms of lifetime extensions, and

08:25.640 --> 08:27.360
other fixed costs.

08:27.360 --> 08:33.080
So working out how often these things are running is a really important part of our modeling.

08:33.080 --> 08:38.480
Now for various parts of the world, that data is public, though sometimes it's a few years

08:38.480 --> 08:45.400
out of date, so in the US and in Europe, you can find that data through the EPA and in Europe

08:45.400 --> 08:52.560
through, it's called a NSOE, which is about electricity transparency, but the data is

08:52.560 --> 08:57.280
out there, but for other parts of the world, particularly sort of Southeast Asia and across

08:57.280 --> 09:03.320
Asia, that data was not available, or if it is available it's about four years out of date.

09:03.320 --> 09:09.840
So we wanted to investigate whether we could use remote monitoring that is satellite imagery

09:09.840 --> 09:14.440
to answer that question and work out how often these plants are running, and we thought

09:14.440 --> 09:23.280
we had a good shot at it because at the same time, the proliferation of this, of competitors

09:23.280 --> 09:29.080
in the satellite imagery space, and the availability of the data has just increased hugely in the

09:29.080 --> 09:30.080
last few years.

09:30.080 --> 09:36.160
Partly that's to do with these nano-sats and cube-sats, which are very small, but still

09:36.160 --> 09:43.480
give reasonable quality outputs, and some companies like a planet who we worked with put up

09:43.480 --> 09:48.360
a sort of over a hundred of the, I think 150 now, these cubes-sats, and I know a lot

09:48.360 --> 09:53.360
of other providers, I think you're doing the same or certainly thinking of if they're

09:53.360 --> 09:54.600
not already.

09:54.600 --> 10:04.840
The goal then is to look at areas where you've got known coal production facilities and

10:04.840 --> 10:13.440
try to predict their output, their capacity at any given point in time, and it sounds

10:13.440 --> 10:20.280
like one of the things you're doing is you've got the, you've got some known facilities

10:20.280 --> 10:29.400
and their output via the NSoE and EPN you're using these as labels to then train a model.

10:29.400 --> 10:34.640
Exactly, that was our starting point that we would have all this label data, and thus

10:34.640 --> 10:41.840
we would have a strong base to do some proper supervised learning.

10:41.840 --> 10:47.160
And so without too much further scoping, we then set off to try and do them.

10:47.160 --> 10:51.920
And possibly as with all things, perhaps we should have spent longer scoping out or thinking

10:51.920 --> 11:00.760
about other kinds of solutions, but we just dove straight in and I started writing scripts

11:00.760 --> 11:07.000
to interface with satellite providers, APIs, where you can query for images and things.

11:07.000 --> 11:13.480
So the first step was to create GeoJson objects specifying the areas where it's called areas

11:13.480 --> 11:17.640
of interest or AOIs, what's referred to by these satellite image providers.

11:17.640 --> 11:22.040
So we had to make shape files or GeoJson files for each one of these coal parts that we

11:22.040 --> 11:23.360
wanted to get the data.

11:23.360 --> 11:30.960
Often we just drew a square, a sort of 1.5 kilometer squared size shape file around each

11:30.960 --> 11:38.880
plant and sent that off to the image provider's API and said, give me all the images you

11:38.880 --> 11:45.680
have in the last two years that meet a threshold of cloud cover of, say, less than 10% cloud

11:45.680 --> 11:49.680
cover and let me download it.

11:49.680 --> 11:55.520
And that was amazing in the first instance because that sort of capability, again, is very

11:55.520 --> 12:00.880
new because usually or what has historically been the case was if you want to work with

12:00.880 --> 12:07.560
satellite data, you get image tiles and the tiles are like the photograph, the image

12:07.560 --> 12:13.560
that the satellite sensor takes and it covers a large area and it's a big file.

12:13.560 --> 12:18.080
So if I wanted to do that, historically, I would have had to download sort of terabytes

12:18.080 --> 12:21.400
of data and then sort of click it myself.

12:21.400 --> 12:29.120
Thankfully, I didn't have to do that. I could create a labeled small, well, set of small

12:29.120 --> 12:33.800
images where images were a few hundred kilobytes each or something because they had been pre-clipped

12:33.800 --> 12:34.800
out.

12:34.800 --> 12:39.160
I think a digital globe called these image chips.

12:39.160 --> 12:50.080
And so reasonably quickly, we had a data set of around sort of 80,000 images for the

12:50.080 --> 12:54.280
rest of the labelled.

12:54.280 --> 12:56.680
So we were sort of ready to go relatively quickly though.

12:56.680 --> 13:01.760
There were some challenges there in terms of making sure that the time zones were right

13:01.760 --> 13:06.240
for the labels and the satellite images and sinking that up correctly.

13:06.240 --> 13:11.280
That was a minor headache.

13:11.280 --> 13:17.080
And I mean, another challenge that we saw straight away was that we didn't have any sort

13:17.080 --> 13:20.280
of balance in terms of the training classes.

13:20.280 --> 13:24.920
If we were going to look at whether plants were running very hard or they were running

13:24.920 --> 13:28.960
somewhat or they were off, or if we just, as we ended up just looking at whether plants

13:28.960 --> 13:35.760
were on or off, it was a very imbalanced class and part of that is because satellites

13:35.760 --> 13:43.840
take images in the daytime when it and it plants also happen to run more in the daytime.

13:43.840 --> 13:47.280
So there's no images in the night when plants were running less and more likely to be off.

13:47.280 --> 13:51.840
So we had very imbalanced class, training classes straight away that we had to deal with

13:51.840 --> 13:59.320
them, which we counted just by sampling the imbalanced class multiple times and then

13:59.320 --> 14:04.120
doing lots of manipulations to it.

14:04.120 --> 14:07.600
And that worked out okay, but not fantastic, I would say.

14:07.600 --> 14:10.840
So that was one limitation that we saw straight away.

14:10.840 --> 14:17.680
And were you primarily looking at this binary status, whether the plant was on or off as

14:17.680 --> 14:26.680
opposed to trying to measure the plume area and try to determine the output in some way?

14:26.680 --> 14:31.960
Initially, we absolutely wanted to be hopes, we had high hopes that our model would just

14:31.960 --> 14:37.440
spit out a reasonable output number for each plant and that had to be calibrated on the

14:37.440 --> 14:44.360
actual capacity, the size of each plant, which we had, we had that information.

14:44.360 --> 14:50.400
But unfortunately, we tried to just do a make a regressor, but it didn't turn out terribly

14:50.400 --> 14:51.400
well.

14:51.400 --> 14:57.080
The results it gave didn't seem to reflect reality particularly.

14:57.080 --> 15:05.240
And part of that, we found by doing some manual analysis, was just looking at the classification

15:05.240 --> 15:10.680
that it was doing in terms of the actual pixels that it was counting up.

15:10.680 --> 15:19.440
And this is where perhaps an early weakness that was, I think, I made a decision early

15:19.440 --> 15:29.400
on to take visual images from the API, which is author-rectified sort of our RGB images

15:29.400 --> 15:35.440
because visual images are what's needed, of course, to do an image processing machine

15:35.440 --> 15:37.160
learning technique.

15:37.160 --> 15:45.600
What's also available is 13 band analytic images, which contain a lot, a lot more information.

15:45.600 --> 15:52.720
And we ended up using that to do the counting up rather than doing a visual classifier because

15:52.720 --> 15:59.320
any kind of very light pixels, which could have been to do with a wish-lectivity of metal,

15:59.320 --> 16:04.520
other kinds of sort of smoke plumes and things coming off the ground, that was all getting

16:04.520 --> 16:11.520
counted up and sort of adding to the plants output, which wasn't a good reflection of

16:11.520 --> 16:13.280
what was actually going on.

16:13.280 --> 16:19.800
So fairly quickly, we decided that we weren't going to be able to get the output using this

16:19.800 --> 16:20.800
method.

16:20.800 --> 16:26.640
And so we ended up doing, on Google Earth Engine, we made an algorithm that would count

16:26.640 --> 16:32.120
up the pixels in each image and just say, using the analytical images, because it could

16:32.120 --> 16:39.520
do a spectral linear mixing of the information in those analytic image chips.

16:39.520 --> 16:45.160
And that gave us a better estimate of an instantaneous output.

16:45.160 --> 16:50.920
So our idea then was to combine these two different techniques to say, here's when we think

16:50.920 --> 16:55.080
the plants are often, here's what we think is an average of the plants output over that

16:55.080 --> 16:56.840
given time.

16:56.840 --> 17:01.400
And by combining them, we got to a reasonable results in the end.

17:01.400 --> 17:07.280
You mentioned earlier that a lot of your challenges could be traced back to kind of the way

17:07.280 --> 17:11.200
you scope the problem or problem definition.

17:11.200 --> 17:17.400
And this is one example of where you need it to pivot in the way you approach the problem

17:17.400 --> 17:21.040
or are there others that we can talk for?

17:21.040 --> 17:30.320
Yeah, certainly. I mean, one thing that became clear to us over time as we got more into

17:30.320 --> 17:33.960
the problem was we started out really wanting to understand China and what's happening in

17:33.960 --> 17:34.960
China.

17:34.960 --> 17:41.080
And of course, from a climate change perspective, China is a huge global emitter.

17:41.080 --> 17:44.000
And it has a huge amount of cold capacity.

17:44.000 --> 17:47.360
It has sort of 1100 gigawatts of cold capacity.

17:47.360 --> 17:51.240
So from a climate perspective, it's very important to know what's going on.

17:51.240 --> 17:56.400
And historically, the data has been very poor and China has been criticized for publishing

17:56.400 --> 17:59.360
statistics that perhaps don't really reflect what's going on.

17:59.360 --> 18:03.720
And that sort of thing, or the data is only available years later.

18:03.720 --> 18:08.720
And what we found as we started working more and more closely on this and talking to

18:08.720 --> 18:15.680
more and more people who are closer to the ground was that more in recent times.

18:15.680 --> 18:21.120
In fact, there is a real-time monitoring effort in five Chinese provinces.

18:21.120 --> 18:28.240
So we were actually able to obtain very good high quality granular data for coal emissions

18:28.240 --> 18:32.920
in some of these places, which was brilliant because we could then calibrate the predictions

18:32.920 --> 18:36.160
we'd made for China in those regions.

18:36.160 --> 18:44.640
But then, of course, to some extent reduce the need for the methodology we had developed.

18:44.640 --> 18:49.920
So we were sort of happy pleased and frustrated at the same time with that.

18:49.920 --> 18:51.760
But then, of course, that was only for five regions.

18:51.760 --> 18:55.440
It was only a mandatory in certain places.

18:55.440 --> 19:01.440
So for other places, of course, we can still use our methodology and be even more certain

19:01.440 --> 19:04.000
or confident in the results that it gave us.

19:04.000 --> 19:09.520
Did you find that the models that you created translated well from one region of the world

19:09.520 --> 19:13.720
to another, or did they not?

19:13.720 --> 19:16.200
Yeah, we did.

19:16.200 --> 19:24.440
And I think the interesting variation, in fact, was to do with the ground state of the plants.

19:24.440 --> 19:27.720
Oh, and yeah, here's another good challenge that I'd forgotten about.

19:27.720 --> 19:31.640
Or maybe my mind tried to push it down into my surface.

19:31.640 --> 19:34.440
So annoying.

19:34.440 --> 19:37.000
So just to make it very clear about how we were trying to do this,

19:37.000 --> 19:43.000
we were looking at the visual plumes, the smoke and water vapor that come out of the flu stack

19:43.000 --> 19:47.080
and the cooling towers from a coal plant.

19:47.080 --> 19:54.120
And we were testing and sort of sub-setting on various sort of samples to try and improve

19:54.120 --> 19:54.920
our results.

19:54.920 --> 20:00.760
And I forget how exactly we stumbled upon it, but as soon as we did, it became so obvious

20:00.760 --> 20:05.640
that there are various kinds of cooling technologies that coal plants have.

20:05.640 --> 20:10.680
There's what's called once through, which is if the plant is located in a body of water,

20:10.680 --> 20:18.280
it'll suck in water from, say, a lake or a river, use that to cool its equipment and then

20:18.280 --> 20:23.280
pass it out a slightly warm stream of water.

20:23.280 --> 20:27.720
And there's also active and passive cooling towers, which is draft cooling towers, where

20:27.720 --> 20:31.760
evaporation is used and produces these huge steam plants.

20:31.760 --> 20:37.360
Now those two cooling types produce very different cooling plumes.

20:37.360 --> 20:42.400
And the once through method, in fact, did not behave very well in our models at all.

20:42.400 --> 20:47.920
So once we were able to slice that out and only examine plants with active and natural

20:47.920 --> 20:51.240
draft cooling, we saw much better results.

20:51.240 --> 20:59.760
So that was a real sort of step change that perhaps if we had had a deeper understanding

20:59.760 --> 21:03.960
of the physical characteristics of coal plants at the beginning, we could have seen coming

21:03.960 --> 21:09.680
as it happened, and we were able to infer it by looking at the results as we went along.

21:09.680 --> 21:15.280
It also strikes me that, for example, when would make a big difference if there's no

21:15.280 --> 21:19.400
wind, you're going to have this plume that kind of goes straight up and doesn't spread

21:19.400 --> 21:20.960
horizontally in your image.

21:20.960 --> 21:26.360
But if it's very windy, it'll kind of disperse in one direction, and your model would

21:26.360 --> 21:31.280
need to be able to figure that out to perform more.

21:31.280 --> 21:37.560
Absolutely, we did do a reasonable amount of investigation against environmental data.

21:37.560 --> 21:45.520
And what really enabled us to do this was Google Earth Engine, which had a lot of our environmental

21:45.520 --> 21:49.840
data layers that we could just bring in very easily.

21:49.840 --> 21:52.720
It would have been much more difficult if we weren't using Google Earth Engine, I must

21:52.720 --> 21:53.720
say.

21:53.720 --> 21:57.560
There were other platforms off of similar things, but we were able to, so we were able

21:57.560 --> 22:08.040
to use that to get per image a wind speed, a wind direction, temperature, atmospheric

22:08.040 --> 22:10.040
pressure, and humidity.

22:10.040 --> 22:15.200
And so we did some analysis against all of those variables to see if there was significant

22:15.200 --> 22:20.200
correlation with plume size, and with wind, we did find if the wind isn't blowing the

22:20.200 --> 22:24.560
plume goes straight up and doesn't disperse so much, which when you're looking over vertically.

22:24.560 --> 22:30.000
And some satellites, in fact, do offer an angle offset so that you can try and do volumetric

22:30.000 --> 22:31.480
estimations.

22:31.480 --> 22:36.280
That was something that we'd left on the side and didn't end up trying to investigate.

22:36.280 --> 22:41.760
That was sort of beyond the amount of time we had, but if the wind is very low, you

22:41.760 --> 22:42.760
get the straight up plume.

22:42.760 --> 22:46.160
If the wind is going somewhat, you get more of a dispersal, and if it's a very strong

22:46.160 --> 22:51.080
wind, then you get more of a straight line, so actually the plume area looking from above

22:51.080 --> 22:57.000
isn't as great as sort of medium wind. But overall, we didn't find that it was hugely

22:57.000 --> 23:04.600
significant, saying with the other estimates, because we hoped that by bringing those variables

23:04.600 --> 23:11.280
into the model, we were able to get a really good accuracy, but they didn't actually help

23:11.280 --> 23:14.960
as much as we had hoped, unfortunately.

23:14.960 --> 23:19.320
And I think that was when I talked about the scoping, I mean, we didn't know how hard

23:19.320 --> 23:25.360
this problem was. I think it's the real truth of the matter.

23:25.360 --> 23:36.120
When you just look at the noise and the variation of generation output compared to the plumes

23:36.120 --> 23:42.000
emitted by a plant, you just find that there's a huge variation. It's just very noisy to

23:42.000 --> 23:43.000
start with.

23:43.000 --> 23:49.280
So the accuracy of what we could end up with was always going to be limited by that natural

23:49.280 --> 23:55.160
variation. Whereas if, for example, we were just trying to quantify what kind of equipment

23:55.160 --> 23:58.720
or what kind of cooling technologies, or say we were doing something different and just

23:58.720 --> 24:04.040
looking at whether solar panels are built in a certain area, static stuff that it, rather

24:04.040 --> 24:09.680
than time series data, that's a lot more, I think you can get a much finer degree of

24:09.680 --> 24:13.280
accuracy than trying to get something dynamic like this.

24:13.280 --> 24:14.280
Right.

24:14.280 --> 24:18.160
So we lived and learned.

24:18.160 --> 24:27.800
And so the availability of these image chips helped quite a bit, but did that totally alleviate

24:27.800 --> 24:33.160
the data preparation challenges, or did you have other areas where data prep was really

24:33.160 --> 24:35.640
a big challenge for you?

24:35.640 --> 24:41.840
Doing everything together at the beginning was some challenge.

24:41.840 --> 24:46.400
But beyond that, I mean that just the amount of cloud architecture and cloud solutions

24:46.400 --> 24:50.360
that are being offered really does a lot of the work for you.

24:50.360 --> 24:59.440
And for example, AWS now hosts a lot of archived satellite image data sets that anyone can

24:59.440 --> 25:02.440
access, which we investigated.

25:02.440 --> 25:08.160
We didn't end up using a lot of these satellite image providers now have their own platforms.

25:08.160 --> 25:11.800
And they really try and take as much out of your hands as possible so you can really get

25:11.800 --> 25:14.960
to the implementation phase as quickly as possible.

25:14.960 --> 25:22.280
And it's entirely possible to do extremely rapid prototyping now with new kinds of image

25:22.280 --> 25:27.440
classifiers on satellite data, whether that's through Google Earth Engine, which you can

25:27.440 --> 25:32.480
just pull in all sorts of different sources, or through one of these, mostly I must say,

25:32.480 --> 25:36.640
they're proprietary, but a lot of them have sort of quite low barriers, especially for

25:36.640 --> 25:40.960
academic institutions, and a lot of them have not profit elements as well.

25:40.960 --> 25:45.480
Of course, they have huge fixed costs because they put satellites into the air and they

25:45.480 --> 25:51.360
need to make a return on it, but they are very keen for people to try new things and

25:51.360 --> 25:58.120
to, well, they hope, make commercializable solutions.

25:58.120 --> 26:02.720
For example, Planet has had a Kaggle Challenger while ago about classifying bits of the Amazon

26:02.720 --> 26:08.000
rainforest to try and get people working on these different challenges.

26:08.000 --> 26:12.760
And I know that there's a huge amount being done across this sort of NGO and energy, climate

26:12.760 --> 26:19.000
change space on all sorts of things around water, around coal mining, forest cover, a forest

26:19.000 --> 26:23.480
station, or all those sorts of questions, which can, as I say, I mean, we are a carbon

26:23.480 --> 26:24.480
tracker.

26:24.480 --> 26:29.200
And people that work with this project, it was only sort of maybe three of us.

26:29.200 --> 26:33.480
And the fact that, you know, we could even pull together a sort of machine-learning project

26:33.480 --> 26:38.320
with satellite images, I think, says a lot about how quickly you can get up and running

26:38.320 --> 26:40.160
with modern tooling.

26:40.160 --> 26:47.520
For the classifier that was looking to predict the status of the plants, what model did

26:47.520 --> 26:48.520
you use?

26:48.520 --> 26:50.960
Visual classifier, so it looks like a CNN.

26:50.960 --> 26:51.960
Yeah, exactly.

26:51.960 --> 26:52.960
It was a CNN.

26:52.960 --> 26:56.840
We used Inception V3.

26:56.840 --> 27:05.280
And we just wanted an image-pressing model that knew edges and knew its way around an

27:05.280 --> 27:06.280
image.

27:06.280 --> 27:11.840
We ended up stripping off some of the last final layers.

27:11.840 --> 27:15.520
And I think we added a dense layer.

27:15.520 --> 27:21.360
But, you know, we didn't have to do a huge amount of tweaking.

27:21.360 --> 27:27.760
Maybe we should have done, but that was what we ended up doing, and it worked pretty

27:27.760 --> 27:28.760
well.

27:28.760 --> 27:29.920
Pretty okay, I would say.

27:29.920 --> 27:36.240
You were evaluating your model performance based on, again, this kind of, these known US

27:36.240 --> 27:41.960
and Europe plants, or did you end up with something different?

27:41.960 --> 27:46.120
No, we just used the label data for the US and the EU.

27:46.120 --> 27:50.560
And later, when we found out about this source in China, we were able to do some training

27:50.560 --> 27:53.800
using the label China data as well.

27:53.800 --> 28:00.880
And so we just looked at precision and recoil for the plants that were on and the plants

28:00.880 --> 28:01.880
that were off.

28:01.880 --> 28:05.680
And again, because of this very imbalanced data set, most of the images were of plants

28:05.680 --> 28:09.680
with some sort of smoke vapor bloom.

28:09.680 --> 28:14.480
We had very good accuracy or very good precision for plants that were on.

28:14.480 --> 28:21.040
And then much worse, in fact, for plants that were off, which dragged the accuracy down

28:21.040 --> 28:27.760
overall, which is quite understandable with a very balanced training set.

28:27.760 --> 28:34.320
Head of curiosity, what's the typical kind of cycle time for these plants being on or

28:34.320 --> 28:35.320
off?

28:35.320 --> 28:37.960
Are they cycling several times a day?

28:37.960 --> 28:43.160
Or is it, you know, they're cycling for, you know, days or weeks on end?

28:43.160 --> 28:50.600
So there's a cost if you're a coal plant operator to go down to zero is if you have to start

28:50.600 --> 28:55.680
up against what's called a cold start, and it's much easier to just lower your output.

28:55.680 --> 29:00.920
So plants are sort of ramping their outputs up and down quite a lot.

29:00.920 --> 29:03.840
But then they might turn off for, you know, a period of days.

29:03.840 --> 29:08.960
But most of the time, it's more, more useful for them to try and keep running as much

29:08.960 --> 29:13.880
as possible and to keep some inertia going.

29:13.880 --> 29:17.800
And for the classifies point of view, that isn't very helpful because it's just saying

29:17.800 --> 29:20.720
oh, it's still on, it's still on.

29:20.720 --> 29:27.880
And that was why the results that we got were initially we thought we could do have a

29:27.880 --> 29:32.320
really fine grain time series and be able to see, you know, every day or every time

29:32.320 --> 29:36.640
we got an image whether it's on or off and draw a very nice time series chart.

29:36.640 --> 29:42.720
And what we ended up deciding was that we could get reasonable accuracy over a time period

29:42.720 --> 29:45.920
because we could take these averages.

29:45.920 --> 29:51.400
But we weren't able to get, you know, to say in this week what's happening.

29:51.400 --> 29:54.360
That was just a limitation that we found.

29:54.360 --> 30:00.760
Though as plants in some areas, I know in the UK where the economic conditions are much

30:00.760 --> 30:05.240
more competitive for coal and they're really struggling, they are trying to innovate which

30:05.240 --> 30:10.960
does mean cycling more often because they'll be trying to make sure that they hit the spikes

30:10.960 --> 30:15.760
in our prices and then just sort of lay low the rest of the time.

30:15.760 --> 30:21.600
So I mean, in theory, or I mean, running these models hopefully will be able to identify

30:21.600 --> 30:26.240
some of these changing operating characteristics or I mean certainly spotting plant down times

30:26.240 --> 30:29.880
and things will be something that we would we would love to do in terms of just setting

30:29.880 --> 30:34.120
this running and then automatically flagging when things are changing.

30:34.120 --> 30:38.920
And did you define off with regard to some kind of threshold to account for this, you

30:38.920 --> 30:45.880
know, cycling down very low or was it hard off was the only off that you were considering?

30:45.880 --> 30:50.360
It's a good question because we came up with two things there, whether the pixel count

30:50.360 --> 30:56.200
would give a value at all, but then there was sort of generic noise in the images.

30:56.200 --> 31:01.040
And when you said before about how did the algorithm fare in different regions of the

31:01.040 --> 31:02.040
world?

31:02.040 --> 31:06.560
Of course, the image is a square around the power plant.

31:06.560 --> 31:11.040
So it is getting some of the landscape, of course the landscape is differing all around

31:11.040 --> 31:17.920
the world and we didn't know to what extent the CNN would pick up various bits of this

31:17.920 --> 31:23.800
landscape and other parts of the coal plant and try and include those and including of

31:23.800 --> 31:26.560
course there's some sighted on rivers and on coastal regions and things.

31:26.560 --> 31:30.680
So we really wanted to try and delve into it to ensure that that wasn't happening and

31:30.680 --> 31:34.000
it would be repeatable.

31:34.000 --> 31:41.040
And so even when it was off there was a base level of reflectivity.

31:41.040 --> 31:48.680
So in short, yes, there was some sort of threshold.

31:48.680 --> 31:55.760
And so that's the classifier on the regressor side was that did you use the same sources

31:55.760 --> 32:03.120
and so we and EPA for your training data or for your labels or did that come from someplace

32:03.120 --> 32:04.120
else?

32:04.120 --> 32:11.640
No, we started off with the regress and we did try to use exact same training data, but

32:11.640 --> 32:16.840
we found that it just wouldn't converge, which was very frustrating.

32:16.840 --> 32:22.320
So we switched that pretty quickly and we just thought this isn't going to, this isn't

32:22.320 --> 32:25.040
going to produce good results.

32:25.040 --> 32:30.280
You didn't get anywhere with the regressor at all or you switched to a different approach.

32:30.280 --> 32:37.880
Yeah, we just switched out and and and said let's just do this with a pixel counting method

32:37.880 --> 32:38.880
basically.

32:38.880 --> 32:41.600
Ah, got it, got it.

32:41.600 --> 32:44.720
So this wasn't a machine learning, there was no training data, just counting the pixels

32:44.720 --> 32:51.440
kind of correlating that to an output based on, you know, understanding of the, you

32:51.440 --> 32:55.400
know, the underlying principles precisely, precisely.

32:55.400 --> 32:59.280
And, you know, so of course, you know, we like to use, love to use machine learning

32:59.280 --> 33:03.440
where we can, but in this case, we just thought, okay, we just need to get a, we just need

33:03.440 --> 33:07.520
to get some number outputs here and the simplest way looks to be best.

33:07.520 --> 33:12.880
I mean, of course, a huge challenge in terms of doing the pixel counting is that, you

33:12.880 --> 33:17.680
know, a, a white pixel and a smoke plume for a plant looks indistinguishable from, from

33:17.680 --> 33:23.720
cloud cover, though there is some, some stuff about sort of height and, and some reflectance

33:23.720 --> 33:29.240
and those sorts of things, but essentially for various parts of the world and in Southeast

33:29.240 --> 33:34.560
Asia, certainly very difficult, you're never going to get optical images frequently enough

33:34.560 --> 33:37.840
that aren't obscured by clouds.

33:37.840 --> 33:42.720
The reason why you could set a limit like 10%, that doesn't mean that there's 10% clouds

33:42.720 --> 33:43.720
evenly distributed.

33:43.720 --> 33:48.600
It means in a, in an image, a large image tile, there will be some clouds somewhere.

33:48.600 --> 33:52.280
And so you just hope that that doesn't intersect with the area of interest you're trying to

33:52.280 --> 33:53.280
look at.

33:53.280 --> 33:55.400
And most of the time it didn't, but some of the time it did.

33:55.400 --> 34:00.720
So that was another source of, of error with, with cloud cover.

34:00.720 --> 34:04.920
And there are some senses that are less affected by this.

34:04.920 --> 34:10.440
And there's a whole lot of senses, including from the European Space Agency's Copernicus

34:10.440 --> 34:17.440
platform that, that look at ozone, self-adarkside, nitrogen dioxide, and there's also some radar,

34:17.440 --> 34:21.360
short synthetic aperture radar that will pick up on metals.

34:21.360 --> 34:25.120
And that's very good for looking about where things are being built or if there's industrial

34:25.120 --> 34:26.120
operations happening.

34:26.120 --> 34:30.640
And I know there's some, some very exciting analytics companies that are, that are using

34:30.640 --> 34:39.400
that approach to regularly check on, on industrial applications or economic activity automatically.

34:39.400 --> 34:44.560
So they, their algorithms will just run every day and say, you know, his, his, what we

34:44.560 --> 34:51.400
think, the economic activity in this sector is based on this, this radar data.

34:51.400 --> 34:54.120
How long did you spend on this project?

34:54.120 --> 34:59.400
All told, I think we, we, we got the data at around Christmas last year or that's when

34:59.400 --> 35:03.560
I was writing the, the scripts to get the first training set.

35:03.560 --> 35:07.400
And it took us, I mean, we did other projects in the interim, so it probably took us about

35:07.400 --> 35:13.840
half, half, half two of our time for about nine months, something like that.

35:13.840 --> 35:17.240
Maybe, maybe a little more, actually, you know, I shouldn't, I shouldn't really undersell

35:17.240 --> 35:22.880
the amount of effort it does, but it was, it, you know, it does no one any favours to

35:22.880 --> 35:23.880
do that.

35:23.880 --> 35:28.160
And it was really to fill in the gaps in, in a, in a global coal economics platform that

35:28.160 --> 35:29.560
we have just been developing.

35:29.560 --> 35:35.960
We're going to launch, we're launching just at the start of December, which is going

35:35.960 --> 35:41.000
to showcase the cost and the profitability for every coal plant worldwide, as well as

35:41.000 --> 35:46.520
contrast it when renewables are going to be cheaper, or it'll be cheaper to build new renewables

35:46.520 --> 35:49.400
than to even run existing coal plants.

35:49.400 --> 35:51.560
So that's the, the data we wanted to make available.

35:51.560 --> 35:55.080
And that was why we were doing this project such that we could fill in the gaps of places

35:55.080 --> 35:58.560
that we, we really couldn't find any data at all.

35:58.560 --> 36:03.840
So this project did feed into that portal for China, but over the year, we also tried

36:03.840 --> 36:07.280
to develop a lot of local partners, and so it turned out that they're talking to people

36:07.280 --> 36:11.160
and getting, getting local expertise in all parts of the world was also a very useful

36:11.160 --> 36:12.160
way as well.

36:12.160 --> 36:13.160
That's, is that machine learning?

36:13.160 --> 36:14.160
I don't know.

36:14.160 --> 36:16.000
Review machine at work.

36:16.000 --> 36:19.000
Interesting, interesting.

36:19.000 --> 36:26.200
And so are these models, are they kind of, in an ongoing production, production state feeding

36:26.200 --> 36:34.280
into this portal, or have you, did you kind of do a survey and then collect the data and

36:34.280 --> 36:38.560
then is the portal, was any more static data?

36:38.560 --> 36:44.840
Yeah, it's, our aim is to update it every, every three months, while I had the ambition that

36:44.840 --> 36:49.320
I was sort of productionized everything and just keep all the scripts running.

36:49.320 --> 36:54.320
We didn't, ultimately didn't have the, the need to do that, you know, we're, we're

36:54.320 --> 36:58.240
not from profits, so we're not selling, we don't have customers in that, in that sense.

36:58.240 --> 37:03.600
So it never seemed like it was, it was, it was really necessary to do that.

37:03.600 --> 37:07.760
However, because there is, it is really interesting for a lot of different groups to have this

37:07.760 --> 37:13.440
information, and this is where in the, the not profit sector, you know, it's, it's, it's

37:13.440 --> 37:16.600
very hard to get these sort of partnerships set up where someone builds it and everyone

37:16.600 --> 37:20.960
else uses it, but I have some hopes that, that that will happen.

37:20.960 --> 37:27.360
And there is a lot of very exciting information sharing and technical methodology sharing across

37:27.360 --> 37:31.120
these, these different sort of technologies around the energy transition, and it's, it's

37:31.120 --> 37:32.720
only going to improve over time.

37:32.720 --> 37:37.960
So, so hopefully our work will, we'll be a part of that in some way.

37:37.960 --> 37:46.400
It strikes me that this is, you know, just one really interesting use case around how

37:46.400 --> 37:53.280
machine learning AI data science can be applied in the sphere of climate change, climate

37:53.280 --> 37:54.760
change policy.

37:54.760 --> 37:57.160
Are there others that jump out for you?

37:57.160 --> 37:59.200
Yeah, well, absolutely.

37:59.200 --> 38:04.840
I mean, the, the, the Paris climate agreement and the international agreements, one big

38:04.840 --> 38:10.120
part of that is about countries, inventories, and, and holding every, every signatory to

38:10.120 --> 38:15.880
those agreements to, to account in terms of what they say they're going to be doing.

38:15.880 --> 38:19.920
And, and that means, and that's a whole industry in terms of monitoring compliance, monitoring

38:19.920 --> 38:24.720
CO2 emissions, because what falls out straight away just, just on our coal work is, if you

38:24.720 --> 38:27.520
know how often the plants are running and you know some other characteristics, you can

38:27.520 --> 38:31.800
estimate how much CO2 is, is being emitted.

38:31.800 --> 38:35.280
And there's a lot of satellites now that have, that are just for CO2 monitoring as well

38:35.280 --> 38:36.840
as other air pollutants.

38:36.840 --> 38:45.240
So using, using, using AI, you can, and, and data science, you can run automated algorithms

38:45.240 --> 38:48.160
to just continuously measure these things.

38:48.160 --> 38:53.480
And again, a lot of this data is, is available, it's just a question of gluing and all together.

38:53.480 --> 39:01.320
So I do see a, a future where everyone or civil society is able to, to keep tabs on all

39:01.320 --> 39:06.320
large polluters and, and nation states to say, you know, are you really doing, are you

39:06.320 --> 39:09.720
staying true to the commitments you've made on, on climate?

39:09.720 --> 39:15.840
Is this large polluter staying true to its commitments to, uh, run its air pollution scrubbers

39:15.840 --> 39:20.720
or is it in fact, you know, just, just pumping out pollution into the atmosphere, um, and

39:20.720 --> 39:22.280
thinking it can get away with it.

39:22.280 --> 39:26.880
So I see that really starting to change in, in real time, and the other part of it is

39:26.880 --> 39:31.720
making arguments about the speed of growth of, of the positive side of the, the speed of

39:31.720 --> 39:37.600
uptake of renewables of solar deployment and also smarter, uh, predictive capabilities

39:37.600 --> 39:39.800
in terms of power systems.

39:39.800 --> 39:46.160
So being able to, uh, more accurately predict our solar and wind output, um, shifting

39:46.160 --> 39:52.000
demand, uh, and smart grid, so smoothing out the peaks in NG demand, um, which reduces

39:52.000 --> 39:57.120
the system cost for every on and, and further erodes the case for, for fossil fuels.

39:57.120 --> 40:02.240
Um, so, uh, and across, I, I mainly look at the power sector, but there's, you know, power

40:02.240 --> 40:06.320
also has a water stress and water impacts, which is, which is extremely important, that's

40:06.320 --> 40:10.640
something that can very easily be seen and changes over time can very easily be seen,

40:10.640 --> 40:16.200
um, from space or in automated ways, uh, deforestation can, can now be tracked again in,

40:16.200 --> 40:18.040
sort of, near real time.

40:18.040 --> 40:23.200
Um, so yeah, a huge amount of applications, and I think, um, the, the more, the more people

40:23.200 --> 40:26.600
that, that we in the non-profit sector can sort of mobilise to, to walk in those, the

40:26.600 --> 40:31.120
more data scientists we can, we can attract to, to come and work on those projects, the,

40:31.120 --> 40:33.320
better able will be to, to address them.

40:33.320 --> 40:37.000
Lawrence, thank you so much for taking the time to chat with me.

40:37.000 --> 40:38.000
I really enjoyed it.

40:38.000 --> 40:40.800
Right, Sam, thanks so much for having me on.

40:40.800 --> 40:46.800
All right, everyone, that's our show for today.

40:46.800 --> 40:51.040
For more information about today's show, visit twimmolai.com.

40:51.040 --> 40:57.320
Be sure to visit twimmolcan.com for information or to register for Twimmolcan AI platforms.

40:57.320 --> 41:01.160
Thanks again to C3 for their sponsorship of today's episode.

41:01.160 --> 41:04.840
And to check out what they're up to, visit c3.ai.

41:04.840 --> 41:33.360
As always, thanks so much for listening and catch you next time.

