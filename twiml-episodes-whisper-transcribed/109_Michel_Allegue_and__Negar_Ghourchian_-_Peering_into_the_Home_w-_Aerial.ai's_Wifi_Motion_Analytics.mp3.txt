Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
Contest alert.
This week we have a jam-packed intro, including a new contest we're launching.
So please bear with me, you don't want to miss this one.
First, a bit about this week's shows.
As you may know, I spent a few days at CES earlier this month.
While there, I spoke with a bunch of folks applying AI in the consumer electronics industry,
and I'm including you in those conversations via this series of shows.
Stay tuned as we explore some of the very cool ways that machine learning and AI are being
used to enhance our everyday lives.
This includes work being done at Anki, who built Cosmo, the cutest little computer vision-powered
robot.
Nighthouse, whose smart home security camera combines 3D sensing with deep learning and NLP.
Intel, who's using the single-shot multi-box image detection algorithm to personalize video
fees for the Ferrari Challenge North America.
First beat, a company whose machine learning algorithms analyzed your heartbeat data to
provide personalized insights into stress, exercise, and sleep patterns.
3AI and Koito, who have partnered to bring machine learning-based adaptive driving beams
or automatically adjusting high beams to the U.S.
And last but not least, aerial.ai, who applies sophisticated analytics to Wi-Fi signals to
enable some really interesting home automation and healthcare applications.
Now, as if six amazing interviews wasn't enough, a few of these companies have been so
kind as to provide us with products for you, the Twimmel community.
And keeping with the theme of this series, our contest will be a little different this
time.
To enter, we want to hear from you about the role AI is playing in your home and personal
life, and where you see it going.
Just head on over to Twimmelai.com slash myaicontest, fire up your webcam or smartphone camera,
and tell us your story in two minutes or less.
Go post the videos to YouTube, and the video with the most likes wins their choice of
great prizes, including an Anki Cosmo, a lighthouse smart home camera, and more.
Submissions will be taken until February 11th, and voting will remain open until February
18th.
Good luck.
Before we dive into today's show, I'd like to thank our friends at Intel AI for their
continued support of this podcast.
Intel was extremely active at this year's CES, with a bunch of AI autonomous driving
and VR-related announcements.
One of the more interesting partnerships they announced was a collaboration with the Ferrari
Challenge North America race series.
Along with the folks at Ferrari Challenge, Intel AI aspires to make the race viewing experience
more personalized by using deep computer vision to detect and monitor individual race
cars via camera feeds and allow viewers to choose the specific cars feeds that they'd
like to watch.
Look for my conversation with Intel's Andy Keller and Emil Chindicki earlier in this series
for an in-depth discussion about this project, and be sure to visit ai.intel.com where you'll
find Andy's technical blog post on the topic.
Now about today's show.
In this episode, I'm joined by Michelle Iyege and Negar Gorcian of aerial.ai.
Intel is doing some really interesting things in the home automation space by using Wi-Fi
signal statistics to identify and understand what's happening in our homes and office environments.
Michelle, the CTO, describes some of the capabilities of their platform, including its ability
to detect not only people and pets within the home, but surprising characteristics like
breathing rates and patterns.
He also gives us a look into their data collection process, including the types of data needed,
how they obtain it, and how it's parsed.
Negar, a senior data scientist with aerial, describes the types of models they use, including
semi-supervised, unsupervised, and signal processing-based models, and how they've scaled
their platform, and provides us with some real-world use cases.
And now on to the show.
All right, everyone.
I am on the line with Michelle Iyege and Negar Gorcian.
Michelle is CTO of aerial.ai, and Negar is a senior data scientist there.
Michelle and Negar, welcome to this week in machine learning and AI.
Thank you very much, Sam.
I'm very glad to be here with you.
Thank you very much for having us.
Absolutely.
Why don't we get started by having you tell us a little bit about your backgrounds.
Michelle, why don't you get us started?
Perfect.
Thank you very much, Sam, my background is in the digital scene processing and telecommunications.
I earned master degrees and PhD degrees in Spain in Seville, and then I moved towards to
work with the University College Dublin in Adelaum, and the European Space Agency before
becoming a permanent resident in Canada, which we started an aerial in Montreal in 2015.
Awesome.
And Negar, how about you?
So I started my studies in electrical engineering, and then I moved slightly from my master
towards speech processing, telecommunications, speech recognition.
And that's the first point I got introduced to machine learning field.
And I liked it, I liked working with data and human-centric data specifically.
That's where I decided to start my PhD at McGill University at Montreal in Cambridge Science,
more towards machine learning applications and mining human-centric data.
And then right after that, I joined the aerial as a data scientist.
Awesome.
Awesome.
Why don't you give us a little bit of an overview of what aerial is up to?
It seems like a really interesting application.
Yes.
Well, aerial basically reuse Wi-Fi signals to understand a little bit of context about the environment.
So you have a Wi-Fi signals bouncing all over the places indoors, basically.
And then we'll reuse statistics from the Wi-Fi signal to understand the environment
such as a human presence, a pet's presence, for example, to be applied to a home automation
on health care obligations, basically.
Yeah, I've, I think I've told this story once on the podcast before a few years ago,
I was interested in doing a project around home automation.
And at the time, this was before, before really computer vision with deep learning, you
know, had the advancements, the recent advancements.
And I almost, I pretty much got stuck out of the gate trying to figure out a cost-effective
way to do presence detection.
You know, there were a bunch of different ways to do it, but, you know, we were talking
about things like trying to put NFC receivers by doors and stuff like that, and it was really
messy.
And now there's a bunch of interesting ways to do it, including just put cameras by doors
and do object detection.
But what you're offering seems to be a really interesting way to just piggyback of stuff
that's already there.
Exactly, exactly, that's the main, our main purpose is some, to reuse those water scenes
that, when no one is at home, they behave in a very particular way, when someone just
show up, they behave completely different, and that's, that's when, when the, our work
starts to identify, by identifying those patterns.
Can you tell us a little bit about the science behind it and what makes it work?
I'm imagining, you know, it just has to do with kind of the density and water content of
our bodies, and they change the radio waves bounce around, but I'm sure there's a lot
more detail to it there.
Yes, yes, it's a pleasure to.
So actually, Wi-Fi is a pretty smart system, and it's all the time sensing the environment.
And that's exactly what we use.
We use any statistic from physical layer up to link layer, and by looking at these statistics,
you have, you're basically sensing the environment with any two Wi-Fi devices that are connected
each other, let's say you're routed on your TV, we are already sensing in that, in that
scenario.
And basically, your body, while your body moves through those signals, your body disturbs
those signals in a very particular way, depending on what you're doing, how fast you're going,
and what are the activities you're involved in, basically.
Well, machine learning and AI comes to the, well, we start with the pattern recognition,
but it's more complex, more complex than that, and it's actually machine learning and AI
is the answer to our research questions, and it's providing us with very good results.
That's what we are using machine learning and AI today.
So maybe Nagar, can you tell us a little bit about the pipelines that you use and the types
of data that you're collecting, how you're collecting it, and how you're turning that
into models?
Oh, yeah, sure.
So what we do is that technically, we use Wi-Fi enabled devices in indoor spaces to scan
and record these Wi-Fi statistics that Michelle mentioned.
So technically, we are turning the routers and Wi-Fi enabled devices to some cameras.
Let's say the hidden camera is to scan the environment where these Wi-Fi signal propagates,
and then anything that any event and motion that happens within an indoor space affects
that data statistics, and that's where we, through the routers of each household, we scan
these statistics, we send it to the cloud, and that's where we start processing the data
from.
How granular can you get with the data off of the Wi-Fi routers?
Is it able to tell you, is it able to uniquely identify individuals within a home or just
that maybe that there's someone there, or you mentioned pets, how much detail can you
get out of these signals?
Yes, it's a very fine-grained data sum, and we, as you mentioned before, we are able
to identify different users by the body mass and the way they move on the space.
And these signals could be as sensitive as that we are able to detect a breathing rate,
for example, in the right position, by the action of being breathing, you're moving your
chest, and thus modulating our signals as well, and we are capable of detecting a breathing
rate, for example.
It could be as granular as that.
That is incredible.
I find that really difficult to wrap my head around.
Is this all done without requiring me to change the access points I'm using, or do I
need to use specialized devices?
You don't need to use any specialized devices.
Wi-Fi devices, and we look at statistics within the Wi-Fi standards.
Do you require some of the newer Wi-Fi mesh networking technologies, or I've got
one standard kind of old Wi-Fi router, and I guess are you also looking at, do you also
get statistics reported from the client devices, or is it just the access point?
It could be from both sides, actually, or one of the size involved.
It could be one client, for example, and we collect data in the client and send it up
to the cloud, or we could be on the router looking at multiple clients at the same time.
And we upload the information.
So, as long as you have end devices in your home, IEEE, AOT 2011, and above, we're good
to go.
There's a new one coming out soon, I just read about, is it X?
Yes, yes.
There are new standards coming up.
All of them are improving, actually, and are providing even more fine-grained data to
us, actually.
And the better that Wi-Fi gets, the best for us.
Mesh is also a very interesting topology for us to be in.
We are very excited to work in Mesh, as well.
So I've got my Wi-Fi network and my access point, various clients.
How do you collect data?
Do you have, is there like a mobile client or something like that, or is it another device
type that you're introducing?
Basically, well, if we can upgrade the firmware in your router, that would be the ideal point
to be in, as we're going to be deploying the system very soon with one of our ISPs.
That's the way we're going to use.
So we just need to update your router, for example, your ISPs router.
We could also be in one dumb client that we could provide you with, and the agent that
collects the data and send it to the cloud is in these small devices that we could provide
as well.
But as long as we can update anything where of any of your devices, we are ready to go
from there.
Okay, so is the implication then that the business model, at least as you envision it today,
is less direct to consumer and more, either via an OEM with a router or via an ISP relationship
or something like that, where they can change the firmware for you?
Exactly.
Yes.
We're going through ISPs initially.
That way we feel as well that we could get to a big marker.
But of course, the users is the same, either you go directly consumer or through ISPs,
at the end you have the same users, at the end you have, you want to provide a very cheap
security system, for example, to your customers, where you're going through an ISP or you're
going directly.
We have chosen the ISP because it's a very good business model, it's very clever, that's
the way we're going to start.
So you're collecting this data.
Can you be more specific about the types of data that you require, the specific types
of values?
Yes.
For example, we collect every data available at physical layer, for example, and we all
upload that.
Let's say RSSI, RSSI values, let's say commuting on the RAID on your device, let's say channel
information, we collect all these types of data and all of them are very sensitive to
what's happening in the environment, and we work from there.
We start summarizing, we start doing a feature extraction on top of that, until we reach
to our processing engine with the models and models.
Okay.
So you've got all this data, it's uploaded to the cloud, Nagar, how do you even start
to build models around this, for example, are these supervised models, and how are you
training against this type of data?
Yeah, it's a very tricky and interesting question.
So we receive these variety types and a huge amount of data from each house.
And then depending on the task we have on hand, we decide to choose an algorithm or a learning
method that actually minimizes the requirement for query the user very often.
So we try to go with the setups that we don't really need to get through labels from the
actual users, but we try to like kind of like unsupervised setup or semi supervised learning
setups that be good, a minimum amount of information from the environment, from the
user per se.
And then the rest of is it's on us to actually predict models, build models.
In some applications, we could go fully unsupervised like the security application, but as more
complicated tasks comes in, like activity recognition or healthcare applications, that's
where actually we will need the minimum amount of like label provided by the users, or we
could have extract these raw labels automatically from the rest of the feature space we extract
and use them as reference point.
And over time, as a user, use their application more and more, we get, we correct our models
technically based on the first initial models that we built.
Hmm.
Can you give me an example of how you're able to automatically extract labels from the
data set?
Yeah.
Uh, for example, um, we have some, some specific features that we extract from the
writers directly, uh, gives us a rough estimation or even like sometimes a very good estimation
of a location of a user with respect to the fixed anchors that you have at home, right?
So that will roughly give you an estimation of a location of a person and then using the
time of the day and the pattern of move as part of the amount of motion that each person
has 24 seven, that can kind of roughly give you a good idea of that, like, how was that
user moving and behaving throughout the day?
Hmm.
Okay.
So I'm imagining things like you can figure out how many of the devices, how many of the
clients are cell phones and that gives you a sense of the number of people that are
in the home and then you can like at night, the cell phones are probably not moving and
you kind of know where they are in the home and, uh, you can start to build some labels
from there.
Is that the general idea?
That is, that is like something that we definitely think about and we can, but we're
not limited to those type of getting, yeah, we can use those information about different
users getting connected to a writer, we have access to that, then we sit in a writer.
You have access to those kind of information, but necessarily it's not the only source
of information we extract, but definitely the goal is what you mentioned to actually learn
the pattern of like the behavior of each individual user that lives in a household over time.
You know, we start off with some general models and general assumptions about how people
leave in the house, how do you move, where they to go, when they leave home, when they
come back and then these general assumptions will get edited over time with, with different
models that we have and the models get updated, particularly for each house.
Mm-hmm.
So I kind of get that in the, the general case of kind of presence detection, but when
we're talking about, uh, the, the breathing example that Michelle mentioned, which, uh,
you also mentioned healthcare use cases, I'm assuming that is related to a healthcare
use case.
How do you, how do you begin to build a model around, uh, around that, uh, you mean about
breathing rate?
Right.
Right.
Yeah.
So in those cases, most of the techniques that we would use is like signal processing and
like more of, uh, time series analysis, findings, is an all day finding, uh, the curiosity
in the signal, that's more of those type of, uh, techniques we would use to actually find
the pattern.
The breathing rate is something sick like and then, uh, it's, it's something that you
could actually detect and, uh, information, uh, with regard to presence detection that
you mentioned, uh, no matter like presence detection could be like for us, it has a different
definition.
When you have movements or like very intense movements, that's easier, easier to, to figure
out.
Also, when you sit somewhere or we're, you're trying to space city or when you're asleep,
that presence detection in that level is just, we are looking into finer, like finer
grade, like motion and activities that it just presents off a body with, with have on
the data and then figure out that there is someone there.
And then someone is breathing or someone having very micro movements versus when it houses
empty.
Right.
Right.
Just the presence, when you even think about the, the notion of presence, you're trying
to pull out a rich set of, um, you know, parameters, localization of the people in house
things like that.
It's not just empty or a person in the house.
Nope.
That's, that's improving with the, with the different applications we're developing.
Right.
Right.
When you have applications that require, um, some type of labeling, it sounds like maybe
you're doing that via direct input via mobile device or something.
In some cases, yes, we could get the direct entries from a query user that, uh, to, to
give feedback or label on some particular activity or some particular state of the house.
For example.
But the idea is just to, just to talk to complement a little bit on that, but the idea is to actually
minimize, minimize the query to the user.
Um, for example, in applications such as elderly care, a health care, in particular,
elderly care, uh, we don't see the user interacting too much with our system.
Right.
So we are generating more auto generating our labels, uh, to fit the different type of models
we use, uh, but, but, but for, of course, you, you cannot expect too, too many labels
or, or be interacting too much, uh, for, for this particular application, uh, it's not
difficult to figure out, for example, uh, where the, you know, how people walking, walking
in the bathroom looks like, how people walking in the bathroom looks like, how, you know,
the, uh, brushing teeth looks like it's because you, you could correlate with the time of
the day, um, when they take the actions from, from the moment they, they start walking,
uh, in the morning or at any time.
Wow.
Um, how does the system, uh, how does the system scale in the sense of the, you know,
number of individuals per access point? I guess I'm wondering like what the, you know,
what the, um, I guess I'm wondering if you have multiple people like, if you go from
a house environment to an office environment or something like that, do you start to lose
your ability to get fine-grained information about what's happening within the environment
or deep, does it stay, is it your visibility proportional to the number of access points
and as you increase people, you increase access points and you're, you're still good.
Like, what are the issues there?
Uh, yes, exactly. Uh, definitely the, the fewer number of people that you have in the
sensing area, uh, the better. So let's define a sensing area, such as your access point
on one client connected to it. So your sensing, one specific area, because these two
devices have fixed. Uh, let's say, uh, the more granularity you want with more people
around, you will need to increase the number of independent sensing areas. Uh, that will
give you enough resolution to keep working. But of course, if we are talking about, if
we move from, from residential applications towards more commercial or business settings,
uh, you will lose a solution. Uh, it's not the same to, uh, to track five, six, uh, people
versus a 50 to 100 people. Right. Uh, it's very interesting. Actually, we, we are doing
it today. Uh, we have, uh, deployments in large offices. Uh, the patterns are very,
uh, very interesting over day, overnight, over weekends, over holidays. It's very, very
interesting. Uh, uh, but, but of course, you lose, uh, a little bit of resolution in terms
of, you know, who's walking there within a hundred users, right? Yeah. You mentioned the
sensing area is an access point and a client connection. Uh, it's got to help you that
pretty much everyone is walking around with a client nowadays. And so each individual,
each incremental person, does that create, uh, it's own sensing area if they've got a mobile
device? Yes, for sure. And, and you know that that device is moving, um, and we can use
it. Uh, we, we are, we are doing it and we are planning to, to rely on devices as well.
But let's say like the beauty of our technology and when we are spending more time, it's
in natural doses scenarios where you are not carrying your mobile with you. Okay. And
if you think about it, use, you know, one of the first things that probably you do when
you get home is to get rid of of yourself for a little bit. And we don't, we don't want
to, to lose the, the type of information. You know, you're walking, you want to arrive
home, you want to probably relax. So we want to know that, we want to know that to give
you the, the right tone of your lights. We want to turn on your TV, for example, on your
favorite channel. And we want to prepare this scenario for you, even if you're not wearing
a mobile, but we don't see you controlling the home with your mobile all the time next
to you. Uh, oh, and you everywhere. Uh, this is a really fascinating application. When
can we, as the consumers expect, uh, you know, see this, you know, more broadly available?
Well, this year we are deploying, uh, with one of the largest ISPs in the world. Unfortunately,
I cannot reveal the name yet. But it's huge. We'll be with them in a piece of mine application
for families to know, uh, to know where there are people at home or not, uh, who has arrived
home and prepare, you know, um, kind of a home automation, uh, type of applications, as
well as we are, uh, we're also working very hard for our elderly care applications, because
the, uh, well, the market is huge as well there. And it's so, uh, we are very fascinated
about the elderly care application. We can provide so much information to the caregivers
and even to the doctors of those patients, uh, that is, they don't have it today. There
is no way, uh, without the camera that you can tell how many times a person is going
to the bathroom, how much time he's spending on the bathroom versus taking a shower. So
it is so, the pressure is so high because we can do it, uh, that we will love to go to
the market right away. We would love to extend elderly population, uh, time at home as
much as we can. And even, even after being the child for the hospital, let's say for
something, we would like to track to, to see that everything is, is, is going well at
home. Mm hmm. And is the resolution fine enough such that you can detect, uh, like
fall events, uh, and things like that? Uh, yes, actually, that is one of the most
interesting applications that we started off and many people are asking for. So fall
detection is one of the major actually goals that we're setting for our elderly care
application. And, uh, because it's happening in a, right, in a part, usually mostly it's
happening in some shower areas, map areas, uh, we have very, I hope to get it. And sooner
when we start working, uh, more, more focusedly on our, uh, elderly care application.
And what do you expect the approach to be to detect falls based on this data? Is it, you
know, is it kind of a supervise, you know, finding a bunch of labeled falls and training
against them? How do you, how do you get to that? Yeah. Well, we will definitely starting
off with the following, making a lot of fake falls in the office, probably to get a grasp
of how does this look like? But, uh, but more seriously, we're following to actually, uh,
go and work with elderly care facility, like facilities that they are taking care of
a lot of, a lot of, uh, like people and patients that leave in those centers and actually
fall is something that's very, very often happens there. And they have already studied a lot
of studies. They're getting a lot of data about falling. How does it happen? When does it
happen? Probabilities around that accident, particular accident, which is very, very common
in the, in the population. Um, and then when we learned enough about the patterns and
the stuff that we are trying to features and all the statistics that we're looking for
to distinguish a fall, we will go more towards when we want to apply this, we definitely
will are going to be applying some anomaly detection, algorithm, some abnormal detection,
which you, yeah, predictive analysis based on the based on the pattern of the, the patients
or the elderly person's movement during the day or during past days, because there's
a lot of like medical studies about that. All of these falls, they don't usually happen,
like, and, and, and announce too much. It's not random. Like, there's a lot of symptoms
that happens before that, which is alerting. And then we're going to be using all of those
information. We're going to get people experts in those areas to help us to actually build
up this model. But the regarding the learning procedure probably is going to, we're going
to start off differently with some sort of revised learning algorithm to build up models.
We're going to definitely use some active learning and other segments of our learning techniques
to improve that based on the symptomatic information we will get from the expert experts
in this area. And, and then, yeah, well, we use the pattern of normal versus, versus abnormal
on this, like, particular random things that happens. Then we'll be off without without
involving user. We'll be able to actually predict that first to, to try to avoid and warn
health care caregivers that the, this particular patient with the pattern that you walk to the
part of the amount of activity level that it has. It's very probable that's going to
have a fall in a couple of few days. Or if, if it happens, we will know and will, will
inform the caregivers.
Interesting. How are you approaching the general issue of privacy in deploying systems like
this?
Yes. It's a very interesting question. And, first of all, well, we anonymize our data.
That's the first step when, when they got right, and I start looking at data, those are
non-names already. So, those are numbers and tokens. So, that's the first step we take.
We anonymize the data. You have to understand that before our processing engines arrive,
all the data that is there, no one can understand that, that data. So, it's, it's, it's, it's
meaningless. It's just raw data, going up to the, to the cloud. Even though it's encrypted,
all the links between our agents and the cloud, the cloud itself, from cloud to agents to
go to a, to a, to a, to all, all, all, all is encrypted. Or in the cloud for us are
tokens, especially anonymized data that, that we work with. It's just only at the end when
we present the results to the user that this data might sense. It's only there when, you
know, that path is encrypted. It's only when you present data to the user when you assemble
again, the entire, the whole, the whole set of information, let's say. Do you or the company
have any philosophical perspective on the issue of privacy as it applies to, you know,
this kind of technology with, with, which I think really brings a level of transparency
to, you know, presence and activity in the home that most people probably aren't used
to. Exactly. And, and you, you just have to look at our applications, right? The type of
data we're going to collect, the only goal is to detect, to be very good at detecting with
really high values of through positive and very low false positive values, try to really
aggregate the, the events that we are, that we are interested for only the, the purpose
of our final, the, our final presentation to the user. As you can see in a security system,
well, we just telling the users, you know, someone is at home. Right. And it's, it's not
normal. This time of the day, since the, the, the history we have from, from you, this
is not normal. For elderly care, it's true. We will be looking at the very fine, rain
activities, but the entire goal, the, the outcome of all of that will be, you know, this
patient had a normal day today. So, everything seems normal. Don't worry. Versus, or something
has happened. This is not a normal day for this patient. Or a fall has happened. So, those
type of, those type of the, of outputs are the ones that we'll be providing. And the
only, we will use the data only to provide very accurate outputs.
Yeah. I mean, it strikes me that, you know, we talk a lot about the, the smart home,
but generally speaking, you know, that really is devices in the home, getting smarter.
But this, you know, offers the possibility of having, you know, the home itself via the,
the wireless network really start to know a lot about what's happening inside of it. And
that could potentially create a lot of opportunities for the devices themselves to then take advantage
of this and, and do more interesting things. So, it's really interesting. And I appreciate
you taking the time to, you know, share with us a little bit about what you're up to.
And thanks to you, it's been a, honestly, with this type of technologies, when actually
we are unlocking the, the IoT market, because at the beginning, there was like a chicken
and egg problem. So, I have to put devices inside my home, but for what purposes? So,
what will be the application? And so, this type of technology are unlocking there, because
you already have the sensing system there. So, let's start using it. That's, that's, that's,
that's our main purpose. Yeah. Now, it's, it's really interesting. In fact, I'm, I'm
so close, I picked it up in my hand. Now, I've got a, I recently started playing around
with home automation and smart home stuff. And I have this little Sylvania, like, presence
detector thing that's hooked up to the Samsung Smart Things Hub. And it generally works.
It's a little flaky. But in order to, you know, really automate the home, you have to put
these things all over. And you're telling me that I already have what I need. I just
need to start collecting some data and train some models. Which, of course, it makes
it sound really easy when you say it like that. But, or wait for, for Ariel to, you know,
show up in my router at some point. Thank you very much. Yeah. And then one more thing
I would like to add is that we have to look at when we talk about the philosophy of company,
you could just look back at alternatives that we have right away for doing the same things
that we're trying to do. So, in order to monitor an elderly person, you would need to
make them wear a variable, which is very annoying for them. And it needs a lot of cooperation
for the person. And the other alternative is what using cameras for security, which
is avoiding the privacy way more than our data would ever could, right? Because camera
data images and videos or microphones that right now has been used for, for security
or for home security and home smart homes, they're wearing more transpired data that anyone
could pick up, look at them and see what's going on in your life. Whereas like, our data
is something that's need a huge amount of processing, which you need to have, like, spend
hours and hours to just make sense about like, semantic that's going on. So you also have
to look at the alternatives that we have these days for for doing exactly the same jobs
or like, as you mentioned, also heavily putting a lot of sensors and actually, and putting
a lot of systems, a lot of sensors and a lot of hardwares in your house, we're just replacing
all of them with something that already exists at your place. And that is a bigger help,
I think, we're trying to do. Yeah, I think that's a really, really good
point. I've talked about on the podcast, I think in the context of maybe the same kind
of thing, presence and possibly home automation, this idea that actually for many applications,
the cameras becoming the universal sensor, and certainly you can do this stuff with multiple
cameras at least, depending on the number of entrances and exits and rooms you have
in your house and all that kind of stuff. But, you know, it's much more invasive, I think,
as you're suggesting. And it's much more susceptible to being misused or abused because
the raw data itself, you know, is easily interpretable as opposed to RSSI values and channel
noise and stuff like that, that, you know, you have to run it through some pretty sophisticated
algorithms to make sense of. So I definitely get that and it makes a lot of sense. And I'm
looking forward to kind of keeping an eye on Ariel and, you know, what you guys are up
to.
Yes, we would love to keep you posted, keep you posted with the progress of the company
and the lines of the different lines of products that we will be launching.
Awesome. Well, thank you. Thank you very much for having us and giving the opportunity.
Thanks.
Thank you, Sam. Thank you very much.
All right, everyone. That's our show for today. Thanks so much for listening and for your
continued feedback and support. Remember, for your chance to win in our AI at home giveaway,
head on over to twimmolai.com slash my AI contest for complete details. For more information
on Michelle, Negar, Ariel or any of the topics covered in this episode, head on over to
twimmolai.com slash talk slash 107. Thanks once again to Intel AI for their sponsorship
of this series. To learn more about their partnership with Ferrari North America Challenge and the
other things they've been up to, visit ai.intel.com.
Of course, we'd be delighted to hear from you, either via a comment on the show notes page
or via Twitter directly to me at at Sam Charrington or to the show at at twimmolai. Thanks once
again for listening and catch you next time.
