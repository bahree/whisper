1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:30,720
I'm your host Sam Charrington.

4
00:00:30,720 --> 00:00:36,120
In this episode I'm joined by Ashtotash Saxena, a veteran of Andrew Eng, Stanford Machine

5
00:00:36,120 --> 00:00:40,920
Learning Group, and co-founder and CEO of Casper AI.

6
00:00:40,920 --> 00:00:46,200
Ashtotash and I discuss his Robobrain project, a computational system that creates semantically

7
00:00:46,200 --> 00:00:51,400
meaningful and actionable representations of the objects, actions, and observations

8
00:00:51,400 --> 00:00:56,400
that are robot experiences in its environment, and allows these to be shared and queried

9
00:00:56,400 --> 00:00:59,640
by other robots to learn new actions.

10
00:00:59,640 --> 00:01:04,320
We also discuss his startup Casper, which applies these principles to the challenge of creating

11
00:01:04,320 --> 00:01:05,920
smart homes.

12
00:01:05,920 --> 00:01:06,920
Enjoy.

13
00:01:06,920 --> 00:01:11,000
Alright everyone, I am on the line with Ashtotash Saxena.

14
00:01:11,000 --> 00:01:15,480
Ashtotash is co-founder and CEO of Casper.

15
00:01:15,480 --> 00:01:18,520
Ashtotash, welcome to this week in machine learning and AI.

16
00:01:18,520 --> 00:01:21,360
Yeah, sounds good, looking forward to the chat today.

17
00:01:21,360 --> 00:01:22,360
Absolutely.

18
00:01:22,360 --> 00:01:27,080
Let's get started by having you tell us a little bit about your background and how you got

19
00:01:27,080 --> 00:01:29,960
to get working in ML and AI.

20
00:01:29,960 --> 00:01:36,320
So I joined Stanford University back in 2005 and met Andrew Eng.

21
00:01:36,320 --> 00:01:41,280
Andrew Eng was a professor in machine learning and doing some interesting stuff with flying

22
00:01:41,280 --> 00:01:44,280
helicopters upside down using machine learning.

23
00:01:44,280 --> 00:01:50,360
So that's how I got started into the area of AI and machine learning that my PhD there.

24
00:01:50,360 --> 00:01:55,960
Since then, I've been applying it to robotics, computer vision, natural language processing,

25
00:01:55,960 --> 00:01:58,960
and more recently into the smart home areas.

26
00:01:58,960 --> 00:02:04,200
It turns out AI is a very powerful tool, so it increases the impact and the things that

27
00:02:04,200 --> 00:02:05,440
you can do with it.

28
00:02:05,440 --> 00:02:09,800
Talk a little bit maybe about how, you know, where you see the implications of AI and

29
00:02:09,800 --> 00:02:10,800
smart homes.

30
00:02:10,800 --> 00:02:13,680
It's not a connection that we hear about too frequently.

31
00:02:13,680 --> 00:02:20,840
So it turns out AI is very powerful when the situations and what you're trying to do become

32
00:02:20,840 --> 00:02:23,600
too complex to program manually.

33
00:02:23,600 --> 00:02:30,560
So earlier before joining CASPER, I was a professor at Cornell University for a couple of years

34
00:02:30,560 --> 00:02:33,680
trying to program robots to do things.

35
00:02:33,680 --> 00:02:39,480
And it turns out when you have robots in people's environments, it turns out the home environments

36
00:02:39,480 --> 00:02:41,520
are very complex.

37
00:02:41,520 --> 00:02:46,080
Everyone's home is different, people do activities differently.

38
00:02:46,080 --> 00:02:51,960
There's a lot of variation in the way people speak and the way people do things.

39
00:02:51,960 --> 00:02:55,480
And just the visual information that you get from the cameras.

40
00:02:55,480 --> 00:03:00,040
So for a robot, you're trying to understand what people are doing, how people are speaking,

41
00:03:00,040 --> 00:03:01,960
what the robot can do for them.

42
00:03:01,960 --> 00:03:07,120
Now similarly in the smart home space, if you think about some of the devices such as

43
00:03:07,120 --> 00:03:15,880
the Nest Thermostat built by Google or Amazon Alexa or Google Home built by Amazon and Google

44
00:03:15,880 --> 00:03:20,360
for conversational purposes, they have to, they have a really challenging problem because

45
00:03:20,360 --> 00:03:25,920
you are trying to control the environment in people's house such as climate.

46
00:03:25,920 --> 00:03:30,160
And then what you're dealing with is people who have a lot of variability.

47
00:03:30,160 --> 00:03:34,840
So you have a speaking conversational system which is trying to speak with the person and

48
00:03:34,840 --> 00:03:37,640
every person would speak differently.

49
00:03:37,640 --> 00:03:45,120
Similarly in Casper homes, we control lighting, shades, cameras, microphone for conversations,

50
00:03:45,120 --> 00:03:47,200
sensing for elderly and senior.

51
00:03:47,200 --> 00:03:49,960
So there are a lot of things that we do in the homes.

52
00:03:49,960 --> 00:03:55,960
Such a big variation in the data that it becomes very hard to manually program these rules.

53
00:03:55,960 --> 00:04:02,480
So just to give a very simple example, let us say you talk to a home and say, I am watching

54
00:04:02,480 --> 00:04:03,840
TV too much sun.

55
00:04:03,840 --> 00:04:05,680
So close the curtains.

56
00:04:05,680 --> 00:04:07,040
This is what your intent is.

57
00:04:07,040 --> 00:04:09,240
Now people will say it in a variety of ways.

58
00:04:09,240 --> 00:04:14,520
So you cannot write a computer program saying if person said these words, then do this.

59
00:04:14,520 --> 00:04:17,320
If person said something else, then do this.

60
00:04:17,320 --> 00:04:21,080
And the situation is also a lot of variability.

61
00:04:21,080 --> 00:04:25,360
If you're watching TV and there is too much sun, probably means that the sun is shining

62
00:04:25,360 --> 00:04:26,640
on that particular day.

63
00:04:26,640 --> 00:04:31,400
So you cannot see the TV and the right action is to roll up the shades or close the curtains

64
00:04:31,400 --> 00:04:36,320
and turn on some lights in the background and stop the music which was playing.

65
00:04:36,320 --> 00:04:43,120
So all of this home applications with Alexa, with robots, with Google home and with Casper,

66
00:04:43,120 --> 00:04:49,200
it requires a lot of data processing and understanding of the context to be able to do things.

67
00:04:49,200 --> 00:04:54,240
This is where the AI becomes extremely powerful because it's data driven and one can create

68
00:04:54,240 --> 00:04:59,800
actionable items to improve and do things for the people living in the homes.

69
00:04:59,800 --> 00:05:05,600
We've talked about the challenges presented by smart home environments in terms of the

70
00:05:05,600 --> 00:05:11,160
variability of the different types of data and the way questions are answered and all

71
00:05:11,160 --> 00:05:18,680
the different contextual information that a system needs to keep track of to do what

72
00:05:18,680 --> 00:05:20,320
a user wants.

73
00:05:20,320 --> 00:05:24,480
One of the projects that you've been working on to address all this is something called

74
00:05:24,480 --> 00:05:25,480
Robobrain.

75
00:05:25,480 --> 00:05:26,480
What is that?

76
00:05:26,480 --> 00:05:34,560
Yeah, so it turns out that in some of the areas, it's variety of data and collaboration

77
00:05:34,560 --> 00:05:36,360
through data helps a lot.

78
00:05:36,360 --> 00:05:41,240
So in the area of computer vision, a lot of researchers have been collecting images and

79
00:05:41,240 --> 00:05:46,280
putting image labels like if there is a car in the image, if there is a person in the

80
00:05:46,280 --> 00:05:52,920
image and with this data, it really helps to really help the computer vision algorithms

81
00:05:52,920 --> 00:05:57,360
to train and develop better techniques and use things such as deep learning to build

82
00:05:57,360 --> 00:05:58,520
these classifiers.

83
00:05:58,520 --> 00:06:05,040
Now it turns out in the area of robotics and homes, such progress hasn't been made that

84
00:06:05,040 --> 00:06:06,040
well.

85
00:06:06,040 --> 00:06:11,440
There have been some attempts, but lack of data means that every researcher, every university

86
00:06:11,440 --> 00:06:14,840
was redoing the same things over and over again.

87
00:06:14,840 --> 00:06:20,720
So that's why we started this Robobrain project as a collaboration between Cornell University

88
00:06:20,720 --> 00:06:25,560
where I was, Stanford University where I did my PhD and couple of other places such as

89
00:06:25,560 --> 00:06:27,760
Brown and so on and so forth.

90
00:06:27,760 --> 00:06:34,840
And what we did is we had robots set all these places and the idea was when robot is performing

91
00:06:34,840 --> 00:06:40,000
and learning in these individual environments, for example, a robot at Cornell, maybe trying

92
00:06:40,000 --> 00:06:47,040
to listen to verbal commands and trying to make a simple kitchen recipe like like Afogato

93
00:06:47,040 --> 00:06:49,920
or trying to operate a coffee machine.

94
00:06:49,920 --> 00:06:55,240
A robot at Brown University could be trying to learn how to pick up things and put them

95
00:06:55,240 --> 00:07:01,480
back and a robot at Stanford University may be focusing on image classification tasks

96
00:07:01,480 --> 00:07:04,000
and how to figure out how to see things.

97
00:07:04,000 --> 00:07:09,800
And the idea is if we can pull all this information together in a good learning representation

98
00:07:09,800 --> 00:07:15,720
way, then suddenly this project enables all the robots and not only just the robots at

99
00:07:15,720 --> 00:07:20,440
these three universities, but in many other places more powerful.

100
00:07:20,440 --> 00:07:26,280
Historically, I think ten years back when I was doing my PhD at Stanford, our group was

101
00:07:26,280 --> 00:07:32,880
developing a lot of these robots and one thing that came out of this effort in Enduring's

102
00:07:32,880 --> 00:07:35,400
group was called robot operating system.

103
00:07:35,400 --> 00:07:41,640
So that was an effort of a similar kind where the robot software was open sourced through

104
00:07:41,640 --> 00:07:48,760
Stanford, Velokaraj and many other universities, and it allowed a lot of different groups

105
00:07:48,760 --> 00:07:51,160
to collaborate sharing their software.

106
00:07:51,160 --> 00:07:54,160
And it realized that Ross came out of Enduring's lab.

107
00:07:54,160 --> 00:08:00,400
Well, it was a collaboration that started out from Morgan Quigley who was doing PhD with

108
00:08:00,400 --> 00:08:01,400
Enduring.

109
00:08:01,400 --> 00:08:08,400
And then Velokaraj really helped to expand it with a variety of new people joining at Velokaraj.

110
00:08:08,400 --> 00:08:09,400
Okay.

111
00:08:09,400 --> 00:08:10,400
Cool.

112
00:08:10,400 --> 00:08:15,760
Ross at that time was a very small project where we were just trying to make sure that

113
00:08:15,760 --> 00:08:21,520
a couple of universities could actually connect our software to each other.

114
00:08:21,520 --> 00:08:26,800
And now like ten years later or eight years later, I saw a very similar situation where

115
00:08:26,800 --> 00:08:32,520
people were developing machine learning algorithms individually in different places.

116
00:08:32,520 --> 00:08:38,760
And centralized effort did not exist to bring all these learning skills for robots together

117
00:08:38,760 --> 00:08:39,760
in one place.

118
00:08:39,760 --> 00:08:42,760
And that's why we started this robot brain project.

119
00:08:42,760 --> 00:08:49,400
So if I can maybe paraphrase that what I think I heard is that you've got, you're trying

120
00:08:49,400 --> 00:08:54,080
to train robots on a variety of different tasks.

121
00:08:54,080 --> 00:09:01,640
And you want a robot learning thing B to have some benefit, to be able to learn from

122
00:09:01,640 --> 00:09:07,320
what, another robot learning task A, you know, learned, you know, one way to do that

123
00:09:07,320 --> 00:09:12,720
might be to kind of share the model that it learned.

124
00:09:12,720 --> 00:09:19,520
Like if you're training a deep learning model, you share that from robot A to robot B and

125
00:09:19,520 --> 00:09:20,520
vice versa.

126
00:09:20,520 --> 00:09:24,120
But it sounds like you're proposing something a little different than that.

127
00:09:24,120 --> 00:09:25,120
Is that right?

128
00:09:25,120 --> 00:09:26,120
Right.

129
00:09:26,120 --> 00:09:32,560
So some part of it is one way to share things is you share a learned model from one robot

130
00:09:32,560 --> 00:09:33,560
to another.

131
00:09:33,560 --> 00:09:36,360
So a part of robot brain is to allow to do that.

132
00:09:36,360 --> 00:09:42,600
And a part of that is also to become a platform such that it becomes a good representation

133
00:09:42,600 --> 00:09:46,120
to figure out what model to share to go deeper into one example.

134
00:09:46,120 --> 00:09:51,440
Let us say you are trying to make a kitchen recipe like afogato, which is take the ice cream

135
00:09:51,440 --> 00:09:53,120
out, put some coffee in it.

136
00:09:53,120 --> 00:09:57,760
Now for this, you require machine learning or deep learned models for computer vision where

137
00:09:57,760 --> 00:09:59,400
you are doing classifications.

138
00:09:59,400 --> 00:10:05,840
You need machine learning models for grasping where you are telling how and where to touch

139
00:10:05,840 --> 00:10:11,680
the objects in order to pick it up and then for pouring that recipe and also models that

140
00:10:11,680 --> 00:10:15,480
allow you to parse language into actionable items.

141
00:10:15,480 --> 00:10:17,560
So you need a variety of these models.

142
00:10:17,560 --> 00:10:22,160
So you first need a representation that allows you to compose these different deep learning

143
00:10:22,160 --> 00:10:25,840
models together, which is what robot brain does.

144
00:10:25,840 --> 00:10:33,280
And is it fair to think of it as metadata for describing different situations or is

145
00:10:33,280 --> 00:10:41,240
it representations more in the mathematical sense where there's maybe some vectorized or

146
00:10:41,240 --> 00:10:43,680
semantic representation?

147
00:10:43,680 --> 00:10:49,360
So I think one way to think of that is, let's take a simpler example like a dictionary.

148
00:10:49,360 --> 00:10:54,600
What a dictionary does or a Thessarist does is or even Wikipedia, for example, is that

149
00:10:54,600 --> 00:11:02,960
it has topics or words and it tries to explain the meaning of existing words in relations

150
00:11:02,960 --> 00:11:05,320
to other words through some qualifiers.

151
00:11:05,320 --> 00:11:11,360
So there could be a word called running and the way you would explain running is it's

152
00:11:11,360 --> 00:11:13,880
walking but with a faster speed.

153
00:11:13,880 --> 00:11:20,280
So now running is explainable with two other terms walking and faster in a speed, right?

154
00:11:20,280 --> 00:11:25,720
Similarly, now let us take the example of robot brain.

155
00:11:25,720 --> 00:11:26,720
So you're right.

156
00:11:26,720 --> 00:11:29,200
It is essentially one can think of that as a graph.

157
00:11:29,200 --> 00:11:35,400
In the graph, there are not just words, but also physical situations such as how to move

158
00:11:35,400 --> 00:11:37,400
your arm or robots arm.

159
00:11:37,400 --> 00:11:41,160
How does visually some neurons look like?

160
00:11:41,160 --> 00:11:44,920
What is the spatial relation between two objects?

161
00:11:44,920 --> 00:11:47,920
And these items become nodes in the graph.

162
00:11:47,920 --> 00:11:53,480
And then there are the relations between these edges is an explanation of that concept.

163
00:11:53,480 --> 00:11:57,480
So to give an example, if someone says, oh, I want to pick up a cup.

164
00:11:57,480 --> 00:12:05,280
So the semantic node of the cup would be connected to the table because table is cup is usually

165
00:12:05,280 --> 00:12:11,200
on a table on a countertop, but it would also explain in this case that cup is usually

166
00:12:11,200 --> 00:12:16,840
on top of table and it would include information about x, y coordinates, z coordinates.

167
00:12:16,840 --> 00:12:21,160
That cup is usually two inches away or the bottom of the cup is touching the touching

168
00:12:21,160 --> 00:12:25,880
the table and that helps the robot quite a lot because if it can find the table in the

169
00:12:25,880 --> 00:12:29,360
environment, then it becomes much easier to find the cup.

170
00:12:29,360 --> 00:12:34,520
And then the cup was also be connected to the handle with the information that the handle

171
00:12:34,520 --> 00:12:38,920
is usually used to pick up the cup especially when they're the fluid inside the cup.

172
00:12:38,920 --> 00:12:45,200
So there would be a heat map of sorts on this cup that looks like a neuron, which if

173
00:12:45,200 --> 00:12:48,800
you run that machine learning model, it would find that handle.

174
00:12:48,800 --> 00:12:53,560
So it becomes like a Wikipedia for robots where you're not just linking words.

175
00:12:53,560 --> 00:12:58,800
You're actually linking semantic labels with physical locations through these different

176
00:12:58,800 --> 00:12:59,800
models.

177
00:12:59,800 --> 00:13:00,800
Interesting.

178
00:13:00,800 --> 00:13:08,960
I often hear when we talk about one of the challenges of deep learning or AI more generally

179
00:13:08,960 --> 00:13:17,360
this idea that we can train a model to do things, but there's this whole broader concept

180
00:13:17,360 --> 00:13:25,280
of common sense that helps us as humans navigate within a world and do different things.

181
00:13:25,280 --> 00:13:30,080
It sounds like part of what you're trying to do with robo brain is find a way to encode

182
00:13:30,080 --> 00:13:36,080
all of this common sense, for example, that cups usually sit on top of surfaces, that

183
00:13:36,080 --> 00:13:41,040
when they have liquid in them, that liquid can spill, that you want to hold the handle

184
00:13:41,040 --> 00:13:44,880
in a certain angle so as to not do that.

185
00:13:44,880 --> 00:13:50,240
And then that becomes this robo brain that can be shared between robots doing different

186
00:13:50,240 --> 00:13:51,240
tasks.

187
00:13:51,240 --> 00:13:58,440
It's almost like the Google knowledge graph for textual data, but with, you know, between

188
00:13:58,440 --> 00:14:03,520
not just textual data, but also actions and kind of these semantic relationships.

189
00:14:03,520 --> 00:14:04,520
Exactly.

190
00:14:04,520 --> 00:14:06,120
So this is what it is.

191
00:14:06,120 --> 00:14:11,880
That's why sometimes we call it Wikipedia for robots or knowledge graph for robots because

192
00:14:11,880 --> 00:14:18,680
in addition to symbols and hyperlink documents, it basically contains 3D information about

193
00:14:18,680 --> 00:14:24,560
the real world and appearance models and so on and so forth or actions that are relevant

194
00:14:24,560 --> 00:14:30,440
for robots like how to pick up and move the arms and it's a graph, but the variables here

195
00:14:30,440 --> 00:14:35,240
are semantic spatial and things that are relevant for the real world.

196
00:14:35,240 --> 00:14:41,600
And so when I think of the full power of something like this and even the example or

197
00:14:41,600 --> 00:14:49,360
the analogy to Wikipedia, this thing is most powerful when there's a single instance of

198
00:14:49,360 --> 00:14:53,880
it with lots of people contributing to it.

199
00:14:53,880 --> 00:15:00,520
Does, you know, how well defined are the interfaces to this thing such that, you know, lots of

200
00:15:00,520 --> 00:15:05,120
people can contribute to it and is that, is that happening yet?

201
00:15:05,120 --> 00:15:10,200
So we, it's a university project just like a robot operating system with more than quickly

202
00:15:10,200 --> 00:15:14,040
and enduring was a university project in the very beginning to prove a point.

203
00:15:14,040 --> 00:15:20,120
So at this stage, it is still a collaboration with just two, three groups, a university level

204
00:15:20,120 --> 00:15:27,760
project, Robobrain where we showed that a robot being trained at Cornell with the Robobrain

205
00:15:27,760 --> 00:15:33,560
hosted at Stanford could be used to have a robot at Brown University in a different part

206
00:15:33,560 --> 00:15:36,360
of the country pick up objects and do something.

207
00:15:36,360 --> 00:15:41,440
So we actually showed that loop being completed through these interfaces, the interface here

208
00:15:41,440 --> 00:15:42,440
is the graph.

209
00:15:42,440 --> 00:15:47,520
So you can query the graph, get all the information from different models and make it happen.

210
00:15:47,520 --> 00:15:54,040
So it's not in an industry-ready state, but I think academically it proves a point.

211
00:15:54,040 --> 00:16:00,560
So maybe walk us through before you move on, walk us through that specific proof point.

212
00:16:00,560 --> 00:16:07,040
You know, it strikes me that you can, without the details, that can either be really interesting

213
00:16:07,040 --> 00:16:14,480
or not all that interesting at all, like as is often the case to devils and to details.

214
00:16:14,480 --> 00:16:22,480
What specifically is happening in this scenario and what's the graph that's being transferred?

215
00:16:22,480 --> 00:16:27,560
How is it transferred or all those kind of, those are kind of the questions swirling around.

216
00:16:27,560 --> 00:16:29,080
What's the best place to start with that?

217
00:16:29,080 --> 00:16:35,320
Yeah, so maybe that's a good idea to dig deeper into this particular example that we did

218
00:16:35,320 --> 00:16:39,680
a couple of things, but this is, we can take up one example on how the graph would look

219
00:16:39,680 --> 00:16:43,120
like and go a bit deeper here.

220
00:16:43,120 --> 00:16:44,120
So let us see.

221
00:16:44,120 --> 00:16:48,560
So let's take a very simple example of, well, it's not simple from aerobotics point of

222
00:16:48,560 --> 00:16:54,400
view, it's something that is very simple, just pick up the cup, it's actually very hard

223
00:16:54,400 --> 00:16:58,200
for a robot to execute, but things are getting better.

224
00:16:58,200 --> 00:17:04,760
So the scenario is that there is a robot, two robots actually at Cornell University and

225
00:17:04,760 --> 00:17:12,680
one of them is trying to match the object parts to actionable items.

226
00:17:12,680 --> 00:17:20,000
So this project was done by my PhD student called Jason and the project name is Robobarista.

227
00:17:20,000 --> 00:17:25,840
It essentially goes around in different buildings on campus and uses something in which is known

228
00:17:25,840 --> 00:17:31,160
in computer vision, community as a part-based model, like object part-based model, but more

229
00:17:31,160 --> 00:17:35,560
focused towards robotics control and manipulation.

230
00:17:35,560 --> 00:17:41,280
So just to give some examples, it goes around to a light switch and in 50 buildings and it

231
00:17:41,280 --> 00:17:46,240
operates them now, it has a model that if the light switch looks like this, then it can

232
00:17:46,240 --> 00:17:50,400
touch it from the top or the bottom in this particular way and turn on the light, right?

233
00:17:50,400 --> 00:17:52,280
It learns how to operate the switch.

234
00:17:52,280 --> 00:17:57,560
Then it goes around and finds all the buttons on the campus and it tries to keep pressing

235
00:17:57,560 --> 00:18:04,320
them and then it correlates how the button looks in 3D and visually and tactile and how

236
00:18:04,320 --> 00:18:06,200
do you press them.

237
00:18:06,200 --> 00:18:12,920
And then it goes around and touches all the handles or levers and tries to operate them.

238
00:18:12,920 --> 00:18:18,640
Now it comes back and it does some machine learning and it produces some data in models

239
00:18:18,640 --> 00:18:21,400
and the data looks like the following.

240
00:18:21,400 --> 00:18:29,280
This kind of input data which it represents using a deep learning model correlates to

241
00:18:29,280 --> 00:18:33,280
this action for the symbol buttons.

242
00:18:33,280 --> 00:18:37,600
For the symbol switch, this is how it looks like.

243
00:18:37,600 --> 00:18:39,840
So these become some notes in the graph.

244
00:18:39,840 --> 00:18:44,120
The information is not complete yet because it's not usable at this point in time.

245
00:18:44,120 --> 00:18:49,840
Now another PhD student was focusing on a project called Telmediv called Deepynth Mishra

246
00:18:49,840 --> 00:18:57,680
at Cornell and he's focusing on how to now use this 3D and joint angle information and

247
00:18:57,680 --> 00:19:00,120
link them semantically.

248
00:19:00,120 --> 00:19:04,720
So his focus was on natural language processing and mapping them to symbolic actions.

249
00:19:04,720 --> 00:19:08,280
So his project is, oh, how do I make Fogato?

250
00:19:08,280 --> 00:19:14,640
So Fogato, you go to a coffee container, try to use a lever to pour coffee in the cup

251
00:19:14,640 --> 00:19:20,280
and then you take a cup and try to, it has some ice cream in it, then you try to put

252
00:19:20,280 --> 00:19:22,800
some raspberry syrup in it and coffee.

253
00:19:22,800 --> 00:19:23,800
Now let's think about it.

254
00:19:23,800 --> 00:19:28,400
It is actually reusing similar actions from the other project which is how to operate

255
00:19:28,400 --> 00:19:32,800
the lever, how to hold a container and move it around.

256
00:19:32,800 --> 00:19:39,880
So in this case, the graph gets appended with additional nodes and additional edges.

257
00:19:39,880 --> 00:19:45,560
So the nodes here become cup lever and that if you press the lever, then something comes

258
00:19:45,560 --> 00:19:47,520
out and there is an online recipe.

259
00:19:47,520 --> 00:19:50,600
So now you're basically extending the graph here, right?

260
00:19:50,600 --> 00:19:55,080
So this is what the graph that was created at Cornell and then we went to Stanford.

261
00:19:55,080 --> 00:20:00,520
There was a group with Silvio Severus, a professor in computer vision group and they

262
00:20:00,520 --> 00:20:05,040
focus on computer vision appearance and part-based models and so on.

263
00:20:05,040 --> 00:20:10,920
So there with a couple of other people like in the group, PhD students like Ozan, Sandher

264
00:20:10,920 --> 00:20:16,840
and Ashish Jen, we built this 3D model which is a cup is on the top of a table.

265
00:20:16,840 --> 00:20:22,040
So let's collect a lot of data about cups on the top of the table and from the data you

266
00:20:22,040 --> 00:20:28,200
would learn that a cup when it is found is at a certain pixels or certain inches away

267
00:20:28,200 --> 00:20:32,440
from the table and you would try to pick up this cup many times.

268
00:20:32,440 --> 00:20:34,240
So now this graph has a lot of information.

269
00:20:34,240 --> 00:20:40,600
It has information about that the cup is on the top of a table, how to use levers and

270
00:20:40,600 --> 00:20:42,280
buttons and so on.

271
00:20:42,280 --> 00:20:44,400
Information may not be perfect, that's okay.

272
00:20:44,400 --> 00:20:50,200
Now what happens at Brown University that we have a different robot called Backster in

273
00:20:50,200 --> 00:20:56,280
Stephanie Telex's group and what they are trying to do is really make grasping work very

274
00:20:56,280 --> 00:20:57,280
well.

275
00:20:57,280 --> 00:21:02,200
But it turns out that the grasping the way you grasp as in like pick up an object actually

276
00:21:02,200 --> 00:21:08,040
differs from object to object like a like a whiteboard eraser or a pen lying on a table

277
00:21:08,040 --> 00:21:14,120
you would pick it up from the top and a cup you would try to pick it up from the side

278
00:21:14,120 --> 00:21:17,640
because you don't want to affect the liquid in the cup.

279
00:21:17,640 --> 00:21:22,720
So they are focusing on this robotic action of picking and closing the gripper.

280
00:21:22,720 --> 00:21:27,960
Now what we showed is that if you query the graph with whether it's a cup or a whiteboard

281
00:21:27,960 --> 00:21:32,880
marker or a certain type of object, then you would receive the information that these

282
00:21:32,880 --> 00:21:38,680
are more probabilistically likely areas for doing the grasping.

283
00:21:38,680 --> 00:21:44,760
So that backster robot queried the graph through an API and then we showed that within without

284
00:21:44,760 --> 00:21:48,640
that information, the grasping performs better.

285
00:21:48,640 --> 00:21:55,760
Within that explanation, there are so many little details that individually are difficult

286
00:21:55,760 --> 00:21:58,680
problems in computer vision and robotics.

287
00:21:58,680 --> 00:22:03,000
Navigating around the campus is, you know, there are still lots of interesting problems

288
00:22:03,000 --> 00:22:08,400
around there, even identifying what might be a switch so you can start to poke at it

289
00:22:08,400 --> 00:22:19,000
and determine what might be the actionable surfaces, you know, and then to kind of abstract

290
00:22:19,000 --> 00:22:23,000
away from that to identify that the switch has a top and a bottom.

291
00:22:23,000 --> 00:22:30,400
There are so many individual challenging problems in robotics and AI, what?

292
00:22:30,400 --> 00:22:32,960
Maybe, you know, rewinding that description a little bit.

293
00:22:32,960 --> 00:22:36,840
What are some of the simplifying assumptions that were made in these different kind of

294
00:22:36,840 --> 00:22:38,240
sub-problems?

295
00:22:38,240 --> 00:22:45,680
I think we realized that so within a couple of these groups that we were working with,

296
00:22:45,680 --> 00:22:51,280
that was actually the biggest discussion point because each of these problems like navigation,

297
00:22:51,280 --> 00:22:57,040
manipulation, computer vision, language understanding and so on and so forth, we involved I think

298
00:22:57,040 --> 00:23:04,360
like five different research groups, natural language research group at Stanford, machine

299
00:23:04,360 --> 00:23:08,000
learning group here, computer vision group there and so on and so forth.

300
00:23:08,000 --> 00:23:13,920
The biggest discussion point was what is the representation that became the biggest

301
00:23:13,920 --> 00:23:19,760
question because if, and that actually also highlighted the difference in the different

302
00:23:19,760 --> 00:23:25,200
specific fields, people get a little bit too narrow like language people think about things

303
00:23:25,200 --> 00:23:31,320
in symbolically like a cup and tea and mug and drink and they forget that drink and cup

304
00:23:31,320 --> 00:23:36,360
has a physical meaning it's actually a 3D thing and the people in navigation only think

305
00:23:36,360 --> 00:23:42,320
about 2D, I took the robot from here to there but it's not my job to and the robot was not

306
00:23:42,320 --> 00:23:46,600
close enough to the door and it turns out that if it's not in the right position, you cannot

307
00:23:46,600 --> 00:23:53,360
operate the arm to open the door, it's just kinematically impossible and so on and so forth.

308
00:23:53,360 --> 00:23:59,000
So this was a good exercise in a way to come up with these representations so some good

309
00:23:59,000 --> 00:24:06,640
outcomes came out of it so one good outcome was relation between the natural language symbols

310
00:24:06,640 --> 00:24:09,120
and 3D and spatial information.

311
00:24:09,120 --> 00:24:16,280
So when you start having things like pick up or grasp or on top of like a cup is on top

312
00:24:16,280 --> 00:24:22,760
of table, correlated with the actual 3D or spatial world, it becomes very powerful because

313
00:24:22,760 --> 00:24:27,520
now you can say cup is on top of table, well next time a mobile phone could be on top

314
00:24:27,520 --> 00:24:33,840
of a table but you don't need to observe it with 10,000 images, you can reuse the semantic

315
00:24:33,840 --> 00:24:39,680
notion of on top of to now extend the 3D information that you just learned that cup is on top

316
00:24:39,680 --> 00:24:44,160
of a table which means that the bottom part of the cup is on touching the top part of

317
00:24:44,160 --> 00:24:46,960
the table, it's very powerful 3D information, right?

318
00:24:46,960 --> 00:24:52,080
It goes to the mobile phone now and laptop and so on and so forth and suddenly this transmission

319
00:24:52,080 --> 00:24:58,800
of information happens and then you can start extending the knowledge, I'm not saying

320
00:24:58,800 --> 00:25:03,600
this is complete but that's the idea that we were going towards.

321
00:25:03,600 --> 00:25:09,760
So other than this extension and correlation of different pieces, one other good thing

322
00:25:09,760 --> 00:25:18,520
came out of it is in the area of deep learning, it was a CVPR paper that we wrote in 2014

323
00:25:18,520 --> 00:25:23,520
at computer vision and pattern recognition, it was a best student paper over there and

324
00:25:23,520 --> 00:25:29,480
what we did, what we found in deep learning area is that most of the models are put a

325
00:25:29,480 --> 00:25:34,200
vector in and get something out, they are not interpretable, I mean there are exceptions

326
00:25:34,200 --> 00:25:39,160
but majority of the work in deep learning is not interpretable, you cannot put common

327
00:25:39,160 --> 00:25:45,400
sense or existing knowledge into these models and that was a little bit orthogonal to what

328
00:25:45,400 --> 00:25:49,880
we were trying, many people were trying to do in robotics where there is information which

329
00:25:49,880 --> 00:25:51,160
you want to reuse.

330
00:25:51,160 --> 00:25:57,520
So what we developed was called structural neural networks which essentially what to do

331
00:25:57,520 --> 00:26:03,280
is instead of trying to learn a big giant model which can only take one type of data and

332
00:26:03,280 --> 00:26:09,120
produce one type of output, you start producing these composed, recomposable models.

333
00:26:09,120 --> 00:26:14,440
So each module would focus on specific thing and they would dynamically connect to each

334
00:26:14,440 --> 00:26:21,520
other depending on slightly different situation and that allows it to extend really, really

335
00:26:21,520 --> 00:26:27,280
well to different data sets, different input modalities and different situations.

336
00:26:27,280 --> 00:26:36,520
Your description of the effort around identifying the representation reminds me of, I don't

337
00:26:36,520 --> 00:26:40,560
know if you've come across the term master data management from kind of the enterprise

338
00:26:40,560 --> 00:26:46,480
computing side of things but is basically like a large company will have these different

339
00:26:46,480 --> 00:26:52,080
divisions and they all have customers but they all think of the customer slightly differently.

340
00:26:52,080 --> 00:26:59,200
So they go through this MDM effort to really net out what is a customer, what attributes

341
00:26:59,200 --> 00:27:05,000
does a customer have, how to independent of where they represent a customer whether it's

342
00:27:05,000 --> 00:27:12,680
a CRM system or a ERP system, whatever and they do this for all of the entities that

343
00:27:12,680 --> 00:27:18,400
they have to track in all of these different systems and it sounds like part of what

344
00:27:18,400 --> 00:27:24,120
you're doing here is like creating a master data management system for the objects that

345
00:27:24,120 --> 00:27:26,560
these robots will have to manipulate.

346
00:27:26,560 --> 00:27:34,320
Actually, I did not know about this MDM but looks like we are doing something like that

347
00:27:34,320 --> 00:27:39,840
except that instead of when we think of data we actually mean learnable representation.

348
00:27:39,840 --> 00:27:45,840
So I would call it master representation management for robots or something so that would be

349
00:27:45,840 --> 00:27:52,720
a little bit more apt analogy and so you were careful to say learnable representations,

350
00:27:52,720 --> 00:27:57,280
what are the specific implications of that learnable element?

351
00:27:57,280 --> 00:28:05,720
So this learnable part is actually quite important so what happens in a usual like a dictionary

352
00:28:05,720 --> 00:28:10,160
sort of graph, I mean you can represent a dictionary as a graph right, it links words

353
00:28:10,160 --> 00:28:18,760
to words through some explanations and synonyms and so on that it becomes fixed and the links

354
00:28:18,760 --> 00:28:25,040
do not adapt because the variability in a language dictionary is finite but when you are

355
00:28:25,040 --> 00:28:31,560
working with more complex models such as Google knowledge graph or other elements, the

356
00:28:31,560 --> 00:28:35,800
variability is very large and it has to adapt much faster.

357
00:28:35,800 --> 00:28:43,240
So just a simple example like oh well let us say you are you observed that a switch can

358
00:28:43,240 --> 00:28:48,840
be flipped up to down but a switch can come in three different forms, a up down switch,

359
00:28:48,840 --> 00:28:54,960
a press button switch or this toggle switch and robot may not have observed all the three

360
00:28:54,960 --> 00:28:58,600
switches on the on the first data set collection.

361
00:28:58,600 --> 00:29:05,000
So therefore you need to have a representation that given more data it can add to this information

362
00:29:05,000 --> 00:29:06,000
right.

363
00:29:06,000 --> 00:29:09,680
It learned the model about the switch and the finger that oh whenever a robot finger

364
00:29:09,680 --> 00:29:14,240
goes to the switch you can turn it on and it learns something but it cannot be fixed.

365
00:29:14,240 --> 00:29:18,840
Next time a more data comes in from another place maybe we connect to Japan and they have

366
00:29:18,840 --> 00:29:23,960
slightly different switches there which they do then it should be adaptables.

367
00:29:23,960 --> 00:29:32,520
So that is how I think the representation would improve over time and become with every

368
00:29:32,520 --> 00:29:38,360
action or every learning that any happens anywhere for robots the representation will keep

369
00:29:38,360 --> 00:29:40,200
getting better for everyone.

370
00:29:40,200 --> 00:29:49,400
And I'm curious practically speaking what how is this representation system that is ultimately

371
00:29:49,400 --> 00:29:55,560
queried, how has it been implemented, is it like graph databases or you know a simple

372
00:29:55,560 --> 00:29:58,800
relational database or you know something else.

373
00:29:58,800 --> 00:30:09,480
Oh yeah I think it's basically implemented as a graph and it's a simple it's actually

374
00:30:09,480 --> 00:30:13,760
a sparse graph right because not everything else connected to everything else.

375
00:30:13,760 --> 00:30:20,120
So it is stored as a star sparse graph and one thing we have is what that we call as robot

376
00:30:20,120 --> 00:30:26,960
query language or robot query library and this graph provides a certain types of certain

377
00:30:26,960 --> 00:30:32,160
type of interface so you can query the graph saying that oh give me everything that is

378
00:30:32,160 --> 00:30:38,880
connected to this node or give me everything related to the tactile links related to this.

379
00:30:38,880 --> 00:30:44,560
So I want to operate it up but I only care about tactile information so it allows certain

380
00:30:44,560 --> 00:30:53,000
type of queries it also has other complex queries like give me the most probable answers

381
00:30:53,000 --> 00:30:58,760
because sometimes it has each query may result in a sequence of answers like oh for

382
00:30:58,760 --> 00:31:05,320
grasping a cup there are these five locations usually but some people robots may want to

383
00:31:05,320 --> 00:31:09,400
query all five so that they can optimize according to the situation.

384
00:31:09,400 --> 00:31:14,160
On the other hand some other situation may just want the top one mixed probability query.

385
00:31:14,160 --> 00:31:16,920
So that's how it is implemented.

386
00:31:16,920 --> 00:31:23,640
Do you use this Robobrain system at Casper or have you built a separate set of systems

387
00:31:23,640 --> 00:31:24,640
at Casper?

388
00:31:24,640 --> 00:31:31,920
So I think what happened about two years back this is more of my personal story as compared

389
00:31:31,920 --> 00:31:39,400
to Robobrain or Casper's story is I was looking to see how can I take these ideas and

390
00:31:39,400 --> 00:31:49,800
this opportunity to a bigger impact and I realized that in order to make people's lives better

391
00:31:49,800 --> 00:31:55,880
one can if one starts thinking about people's homes it's a really big impact situation

392
00:31:55,880 --> 00:32:01,200
because a lot of people have homes and not many people have robots.

393
00:32:01,200 --> 00:32:07,720
So I started talking to real estate developers for elderly housing and for normal housing

394
00:32:07,720 --> 00:32:14,560
as well and I wanted to create a similar sensing scenario so it turns out at Casper it's

395
00:32:14,560 --> 00:32:19,120
a robot inside out so it's a robot in which people live inside.

396
00:32:19,120 --> 00:32:23,280
So our home has same level of sensing in fact more than a typical robot.

397
00:32:23,280 --> 00:32:28,120
It has cameras, microphone, motion sensors, thermal sensors so you can see where people

398
00:32:28,120 --> 00:32:36,440
are and what they are doing and locally I respect privacy and then it starts to learn

399
00:32:36,440 --> 00:32:42,480
in a similar way that some elderly person fell down on the bathroom floor what to do about

400
00:32:42,480 --> 00:32:44,360
it and so on and so forth.

401
00:32:44,360 --> 00:32:50,440
So it turns out that the techniques and ideas are similar that you have to learn from

402
00:32:50,440 --> 00:32:57,440
homes and share this information and so on but in technical detail we are doing different

403
00:32:57,440 --> 00:33:00,240
things as compared to Robobrain.

404
00:33:00,240 --> 00:33:09,200
In the Casper scenario you mentioned for example learning that someone's fallen and what

405
00:33:09,200 --> 00:33:16,120
needs to happen how would a robot or a robotic home do that without some specific training

406
00:33:16,120 --> 00:33:17,360
and guidance.

407
00:33:17,360 --> 00:33:23,000
So the ideas are similar to what we talked about the details, algorithm and techniques

408
00:33:23,000 --> 00:33:26,080
are quite different but let me give an example about the falling.

409
00:33:26,080 --> 00:33:33,560
So it turns out that one can start thinking of that as a recomposable deep learning representation.

410
00:33:33,560 --> 00:33:40,080
So there may be a model that can detect objects, there may be a model online that can detect

411
00:33:40,080 --> 00:33:44,760
human poses and track people, there may be a model that knows about geometry.

412
00:33:44,760 --> 00:33:52,400
Now in a home situation you take these recomposable models, put them to detect falling.

413
00:33:52,400 --> 00:33:57,640
So this is how you are reusing information and in some of the houses what happens is after

414
00:33:57,640 --> 00:34:06,120
people fall they ask for help and the expectation is that someone may be available to come there

415
00:34:06,120 --> 00:34:07,120
and help.

416
00:34:07,120 --> 00:34:13,600
So Casper knows that whenever a person fell down in these couple of houses it was an important

417
00:34:13,600 --> 00:34:16,160
scenario that someone may have been called.

418
00:34:16,160 --> 00:34:23,080
So it starts to adapt and now we are building a whole 132 senior home complex near vehicles

419
00:34:23,080 --> 00:34:28,000
and now it has learnt a lot of such things that if people don't get up on time in the

420
00:34:28,000 --> 00:34:32,920
morning then there is something wrong about it that sometimes seniors don't get up in

421
00:34:32,920 --> 00:34:33,920
the morning.

422
00:34:33,920 --> 00:34:38,600
People have a certain pattern for drinking water and it turns out that many elderly people

423
00:34:38,600 --> 00:34:45,440
forget to drink water and that's how it keeps on adapting from these situations by looking

424
00:34:45,440 --> 00:34:49,680
at data from different sources and tries to address those problems.

425
00:34:49,680 --> 00:34:57,080
I'm trying to come to terms with a very high degree of skepticism and it's really I think

426
00:34:57,080 --> 00:35:07,040
around this idea of undirected robotic learning meaning how does the thing know what its objective

427
00:35:07,040 --> 00:35:08,760
function is for example.

428
00:35:08,760 --> 00:35:16,280
What is it trying to optimize without some operator telling it that these are the things

429
00:35:16,280 --> 00:35:22,080
that it's trying to optimize does that make sense as a kind of a half question?

430
00:35:22,080 --> 00:35:23,080
Right.

431
00:35:23,080 --> 00:35:27,120
So let us take an example which is a little bit more concrete toy example.

432
00:35:27,120 --> 00:35:31,880
It may not be as impactful as senior falling for discussion purposes.

433
00:35:31,880 --> 00:35:36,960
So we can discuss some of these important points like objective function and action variables

434
00:35:36,960 --> 00:35:37,960
and so on.

435
00:35:37,960 --> 00:35:44,720
And this example could be let us say Casper robotic home is trying to learn what people

436
00:35:44,720 --> 00:35:48,040
trying to adapt the wake up function in the home.

437
00:35:48,040 --> 00:35:53,640
So usually in alarm clock you just beep the alarm clock and people either wake up or not.

438
00:35:53,640 --> 00:35:59,560
But in Casper home Casper can make a sound to wake you up play music open curtains or

439
00:35:59,560 --> 00:36:02,120
shades for natural lighting in different rooms.

440
00:36:02,120 --> 00:36:03,680
It can turn on the lights.

441
00:36:03,680 --> 00:36:06,240
It can even flash the lights and so on.

442
00:36:06,240 --> 00:36:14,600
And even before you go further down this example there is an assumption that someone a developer

443
00:36:14,600 --> 00:36:21,920
of Casper decided that Casper should be trying to worry about when people wake up.

444
00:36:21,920 --> 00:36:28,280
It's not like it just saw that people tend to wake up and so it's maybe I should optimize

445
00:36:28,280 --> 00:36:29,280
this.

446
00:36:29,280 --> 00:36:31,080
This is a feature of the system that you've built.

447
00:36:31,080 --> 00:36:32,080
Right.

448
00:36:32,080 --> 00:36:33,080
You are right.

449
00:36:33,080 --> 00:36:35,640
So I think there is a little bit of human guidance involved there.

450
00:36:35,640 --> 00:36:38,440
It's not a free AGI.

451
00:36:38,440 --> 00:36:44,480
So certainly I think the level of representation that we manually guide the system is that there

452
00:36:44,480 --> 00:36:48,600
are these things called activities that people do.

453
00:36:48,600 --> 00:36:53,520
And there are these things called these devices that you can operate in a certain way and

454
00:36:53,520 --> 00:36:58,120
you can do crazy things with it like don't open close the curtain five times in 10 seconds

455
00:36:58,120 --> 00:36:59,120
otherwise.

456
00:36:59,120 --> 00:37:03,880
So there are certain limits that and constraint that is given to the system.

457
00:37:03,880 --> 00:37:08,960
So in this particular case what happens there are let us say five variables, music, sound,

458
00:37:08,960 --> 00:37:14,240
curtains, fast curtain, slow and lights, bright lights, dim and so on and so forth.

459
00:37:14,240 --> 00:37:15,480
So these are the actions.

460
00:37:15,480 --> 00:37:20,960
The input variables are how many people in the house, when was the person sleeping last

461
00:37:20,960 --> 00:37:21,960
time?

462
00:37:21,960 --> 00:37:23,720
Did he explicitly set an alarm or not?

463
00:37:23,720 --> 00:37:27,520
Is it weekend versus weekdays, summer, winter, so on and so forth?

464
00:37:27,520 --> 00:37:33,720
And now what happens is you have input variables and output actions which have to be mapped

465
00:37:33,720 --> 00:37:38,880
to each other and let us for the time being assume that they are perfect and they exist.

466
00:37:38,880 --> 00:37:44,880
The part which becomes interesting is how do we take feedback and the objective function.

467
00:37:44,880 --> 00:37:50,840
So here in this case what happens is the feedback is sort of an imitation learning because

468
00:37:50,840 --> 00:37:53,160
Casper doesn't do it the first day.

469
00:37:53,160 --> 00:37:54,200
It kind of observed.

470
00:37:54,200 --> 00:37:57,040
So it sees when people open the curtain.

471
00:37:57,040 --> 00:38:01,120
So it turns out surprisingly that there are there is kind of a clustering of behavior of

472
00:38:01,120 --> 00:38:05,360
two types of people, one set of people like natural lighting and wake up very fast within

473
00:38:05,360 --> 00:38:09,920
a few minutes and they are active like the jump up from the bed and move around.

474
00:38:09,920 --> 00:38:14,560
And the second type of people are kind of just stay in the dark sluggish until they get

475
00:38:14,560 --> 00:38:17,120
them on in coffee and they like it right.

476
00:38:17,120 --> 00:38:20,800
There is spectrum of people but we have found that there are these clusters.

477
00:38:20,800 --> 00:38:25,760
So Casper starts to learn that this person is like this because he took the action of

478
00:38:25,760 --> 00:38:27,320
opening curtains manually.

479
00:38:27,320 --> 00:38:32,040
So so a couple of times he may have opened the curtain manually Casper open curtains Casper

480
00:38:32,040 --> 00:38:35,920
turn on the lights and he may have done it more on the weekdays when he wanted to go to

481
00:38:35,920 --> 00:38:37,560
work versus weekends.

482
00:38:37,560 --> 00:38:42,440
Those become the signals or are supervisory signals.

483
00:38:42,440 --> 00:38:48,160
And that starts to get enough data to map the input to the output which is activity wake

484
00:38:48,160 --> 00:38:53,640
off wake up and the situation of number of people in the house morning time weekend versus

485
00:38:53,640 --> 00:38:58,320
weekday to what to do curtains music, bulbs and so on.

486
00:38:58,320 --> 00:38:59,320
Okay.

487
00:38:59,320 --> 00:39:08,440
So what I heard I might explain as you know part of what you're trying to do is build like

488
00:39:08,440 --> 00:39:15,480
if you think of the nest thermostat right it's got you know a couple of sensors proximity,

489
00:39:15,480 --> 00:39:22,920
temperature and like the controller the dial thing and it's got an effector to that

490
00:39:22,920 --> 00:39:29,520
controls you know the HVAC system and it's trying to you know what differentiates it from

491
00:39:29,520 --> 00:39:36,200
a traditional thermostat is that it's taking this input from this dial but also projecting

492
00:39:36,200 --> 00:39:43,080
that to a number of other features like you know whether it's a weekend or a weekday

493
00:39:43,080 --> 00:39:49,480
or whether someone's home and all this other thing and creating a you know a more rich

494
00:39:49,480 --> 00:39:55,480
or complex relationship between the explicit input and the temperature at any given point

495
00:39:55,480 --> 00:40:00,680
in time and it sounds like what you're aspiring to do with Casper is you know almost create

496
00:40:00,680 --> 00:40:07,560
like a generalized platform for these kinds of relationships between sensors and effectors

497
00:40:07,560 --> 00:40:09,560
that might exist in a smart home.

498
00:40:09,560 --> 00:40:17,480
Yeah precisely so nest is doing is has a very important vision currently they are limited

499
00:40:17,480 --> 00:40:22,680
by that they only have as you said a couple of proximity sensors and one dial or something

500
00:40:22,680 --> 00:40:28,120
like that and possibly as they combine with Google Home a little bit of more supervisory signal.

501
00:40:28,120 --> 00:40:35,160
In Casper homes we partner with builders so we have extremely rich data and just like Robobrain

502
00:40:35,160 --> 00:40:41,000
it all boils down to what data and what level of representation that you can operate at.

503
00:40:41,000 --> 00:40:46,840
So if you operate at oh if there is a motion sensor then I will do this then then this kind

504
00:40:46,840 --> 00:40:52,680
of doesn't represent the real world situation which is quite complex like motion sensing can

505
00:40:52,680 --> 00:40:58,680
happen for many reasons not because someone woke up or someone came home and and there are too

506
00:40:58,680 --> 00:41:04,360
many variables so there's a certain level of representation and data that needs to be

507
00:41:04,360 --> 00:41:07,400
included to enable some of these interesting features.

508
00:41:07,400 --> 00:41:12,520
Okay interesting stuff have you by any chance come across a company called Ariel?

509
00:41:12,520 --> 00:41:16,200
I may have heard of it but not on the top of my mind.

510
00:41:16,200 --> 00:41:23,160
So I did an interview with with them not too long ago and basically what they do that maybe

511
00:41:23,160 --> 00:41:30,280
really interesting in this Casper sense is they turn Wi-Fi signals they get they can pull some

512
00:41:30,280 --> 00:41:37,240
metrics off of your standard Wi-Fi access point and through data science machine learning

513
00:41:37,240 --> 00:41:44,920
uh turn that into very rich representations of you know what's happening within the space like

514
00:41:44,920 --> 00:41:50,760
the speed at which people are moving localizing people the rate at which they're breathing

515
00:41:50,760 --> 00:41:57,240
like really interesting stuff if you haven't already looked at that it may be a rich source of

516
00:41:57,240 --> 00:42:02,520
new data about what's happening in the space that you can you can incorporate.

517
00:42:02,520 --> 00:42:04,920
Oh that's a good pointer I will look it up.

518
00:42:04,920 --> 00:42:11,480
Yeah it's ariel.ai is there A-E-R-I-A-L I think I always misspell it but uh you should be able

519
00:42:11,480 --> 00:42:18,680
to find it Ariel Wi-Fi. Cool well this has been a really interesting conversation I I appreciate

520
00:42:18,680 --> 00:42:24,120
you taking the time Ashutosh is there anything else that you'd like to add to close the circle on

521
00:42:24,120 --> 00:42:31,160
on this? Yeah I think one just last couple of comments on AI and then academia and industry

522
00:42:31,160 --> 00:42:36,360
I think for folks who are in industry and building a product I think this is this is one thing

523
00:42:36,360 --> 00:42:42,360
that I personally found when moving from Stanford Cornell to Casper is there is this

524
00:42:42,360 --> 00:42:48,840
interesting substantial impact that AI is making it possible and it's opening up new challenges

525
00:42:48,840 --> 00:42:54,920
in software engineering product management and so on so it is surprisingly become powerful to

526
00:42:54,920 --> 00:43:01,960
make products that were not possible before because the scale at which these learning models can

527
00:43:01,960 --> 00:43:08,280
operate upon and we haven't even yet tried to yet understand the general principles of software

528
00:43:08,280 --> 00:43:13,560
engineering and product management with AI so the questions that you ask like is it a general

529
00:43:13,560 --> 00:43:19,560
level question or how a designer is limiting it to wake up why are they choosing wake up versus

530
00:43:19,560 --> 00:43:26,040
sensors and then how do you even build a testing framework for AI which operates probabilistically

531
00:43:26,040 --> 00:43:31,960
so these are very interesting challenges that as AI becomes more and more mainstream into products

532
00:43:31,960 --> 00:43:39,320
that we have to address absolutely absolutely in fact just earlier this week I was at an event

533
00:43:39,320 --> 00:43:45,880
I was speaking at an event down in Dallas the capital one hosted and after my talk I was

534
00:43:45,880 --> 00:43:50,360
approached by someone who you know raised a very similar point right he said I'm you know I'm a

535
00:43:50,360 --> 00:43:58,520
product person I don't necessarily need to know all of the details here you know around deep learning

536
00:43:58,520 --> 00:44:03,400
and some of the other things that I was speaking about but there is a whole other set of issues

537
00:44:03,400 --> 00:44:10,280
that I need to be aware of in terms of how we take advantage of data generally and machine learning

538
00:44:10,280 --> 00:44:18,680
in particular to build products that you know meet the needs of some set of some set of users and

539
00:44:18,680 --> 00:44:25,880
so there are definitely huge issues there and I've got on my my short list some conversations

540
00:44:25,880 --> 00:44:32,040
that I want to bring on to the podcast to you know start us thinking about how we approach product

541
00:44:32,040 --> 00:44:37,640
from a ML and AI perspective or ML and AI from a product perspective you know more specifically

542
00:44:37,640 --> 00:44:42,360
sounds like it's something a point that you're starting to see as well uh definitely because

543
00:44:42,360 --> 00:44:48,760
cash per is now deployed in real homes with real customers across the globe and and now now this

544
00:44:48,760 --> 00:44:55,160
AI and real world product it comes up awesome awesome well as you touch thank you yeah thanks a lot

545
00:44:55,160 --> 00:45:03,640
for the interview interesting conversations all right everyone that's our show for today for more

546
00:45:03,640 --> 00:45:09,800
information on Aschitash or any of the topics covered in this episode head over to twimlai.com

547
00:45:09,800 --> 00:45:16,440
slash talk slash 170 if you're a fan of the pod we'd like to encourage you to pop open your apple

548
00:45:16,440 --> 00:45:22,280
or google podcast app and leave us a five star rating and review your reviews go a long way

549
00:45:22,280 --> 00:45:36,920
in helping new listeners find the podcast as always thanks so much for listening and catch you next time

