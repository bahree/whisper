WEBVTT

00:00.000 --> 00:16.240
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

00:16.240 --> 00:21.280
people doing interesting things in machine learning and artificial intelligence.

00:21.280 --> 00:24.400
I'm your host Sam Charrington.

00:24.400 --> 00:29.040
In earlier episodes of the podcast, we've talked about some of the many implications of machine

00:29.040 --> 00:34.400
learning and AI in health care, but we've not yet had an opportunity to dive deeply into

00:34.400 --> 00:36.160
this application area.

00:36.160 --> 00:41.680
Well, that changes now. I'm excited to share with you a really interesting conversation I had

00:41.680 --> 00:46.720
with Brendan Frye, professor of engineering and medicine at the University of Toronto,

00:46.720 --> 00:50.160
and co-founder and CEO of the startup Deep Genomics.

00:50.800 --> 00:53.040
You're going to love this show and learn a ton.

00:53.760 --> 00:58.880
I met Brendan at the rework Deep Learning Summit in San Francisco a few weeks ago,

00:58.880 --> 01:03.920
and I expect to share with you a few other conversations from that conference over the next few weeks.

01:05.040 --> 01:09.840
One of the questions I'm often asked is which AI events are worth going to?

01:10.400 --> 01:14.960
Well, there are a ton of them nowadays, and it can be difficult to separate the good from the

01:14.960 --> 01:21.040
bad. So what I'll be doing regularly here on the podcast is sharing some of the events on my radar.

01:21.680 --> 01:23.920
I'll be sharing them on the Twimble website as well.

01:23.920 --> 01:28.800
For March, I'm planning to be at a bunch of events in the Bay area.

01:28.800 --> 01:35.280
The week of the 6th, I'll be at AI by the Bay, which looks to be a really interesting technical

01:35.280 --> 01:41.680
conference, and next, the Google Cloud Developer Conference. The following week, I'll be at

01:41.680 --> 01:46.320
Strata Hadoop World, which is a great event for machine learning and analytics discussions,

01:46.320 --> 01:49.520
with a particular emphasis on data engineering and infrastructure.

01:49.520 --> 01:55.200
And then, the week of the 20th, I'm attending another couple of events by rework,

01:55.200 --> 01:58.880
this time their machine intelligence and autonomous vehicle summits.

01:59.680 --> 02:04.880
What I'm most excited about, however, and I'll only share this brief teaser now,

02:04.880 --> 02:10.640
is an event I'm organizing called the Future of Data Summit, which will take place in Las Vegas in

02:10.640 --> 02:15.120
May. Stay tuned. I'll share all the details on a future podcast.

02:15.120 --> 02:20.160
Going back to the Strata Hadoop Conference for a sec, you may remember that we partnered with

02:20.160 --> 02:25.680
O'Reilly last year to offer a free ticket to their AI and Strata conferences to lucky Twimble

02:25.680 --> 02:30.800
and AI listeners. Well, we're at it again. We've partnered with the good folks at O'Reilly

02:30.800 --> 02:36.560
to bring you another opportunity to win a free ticket to Strata Hadoop World in San Jose, California.

02:37.280 --> 02:42.560
Join Twimble and thousands of innovators, leaders, and practitioners at Strata Hadoop World to

02:42.560 --> 02:48.080
develop new skills, share best practices, and discover how tools and technologies are evolving

02:48.080 --> 02:55.040
to meet new challenges. One lucky listener will win a pass, but everyone can save 20% on registration

02:55.040 --> 03:00.640
with discount code PC Twimble. That's PC-TW-I-M-L.

03:01.680 --> 03:08.960
To enter, visit our brand new Facebook page at facebook.com slash Twimble AI, where you'll find

03:08.960 --> 03:14.880
full details. Of course, I'll link to the Facebook page in the show notes, which will be posted at

03:14.880 --> 03:21.120
Twimble AI dot com slash talk slash 12. Since the conference is coming up quickly, you'll only have

03:21.120 --> 03:26.400
until March 3rd to enter. Winners will be notified shortly thereafter and announced on the next

03:26.400 --> 03:31.600
podcast. One more quick note before we jump into the interview. Towards the end of my chat with

03:31.600 --> 03:37.280
Brendan, I mentioned a sci-fi series that I like, but I blank on the title. Well, this series is

03:37.280 --> 03:44.160
called the Xenogenesis Trilogy, and it's by Octavia Butler. It's also been re-released as Lilith's

03:44.160 --> 03:50.080
brood, so you may see that as well. In any case, I'll post a link to the books in the show notes,

03:50.640 --> 03:52.480
and now onto the show.

03:59.920 --> 04:06.560
So hello everyone, I've got Brendan Fry on the line with me. Brendan and I met recently at the

04:06.560 --> 04:12.560
Rework Deep Learning Summit in San Francisco, where he delivered a really, really great presentation

04:12.560 --> 04:19.280
called reprogramming the human genome. Why AI is needed? Brendan was kind enough to agree to

04:19.280 --> 04:24.400
discuss his presentation and work in the field here on the podcast. So welcome, Brendan.

04:25.040 --> 04:30.320
Hi Sam, thanks for having me on the show. I'm really excited about this conversation.

04:30.320 --> 04:37.920
You know, we've talked about deep learning and machine learning AI in general,

04:38.800 --> 04:46.800
and healthcare several times on the show. Not in a lot of detail, but just covering the news,

04:46.800 --> 04:52.960
and there's been a lot of advancement in this area. One of the things that we talked about was

04:52.960 --> 04:59.600
Beth Israel Deaconis did the work with applying deep learning to breast cancer detection.

05:00.480 --> 05:08.480
Google Deep Mind is active in applying deep learning to eye disease. And when I think about

05:08.480 --> 05:16.640
examples like the ones that I've tended to see, they are often, they often fit into the pattern of,

05:16.640 --> 05:21.360
hey, we've got a bunch of image data. We know deep learning is great for helping us

05:21.360 --> 05:27.520
kind of find patterns and image data. Let's apply deep learning algorithms to see if we can,

05:27.520 --> 05:33.520
you know, either augment or replace, you know, the medical technicians that are, you know,

05:33.520 --> 05:40.800
finding tumors and things like that. But when I heard and thought about your presentation and the

05:40.800 --> 05:46.720
way you walk through what you guys are doing, it struck me that, and let me know if this is fair,

05:46.720 --> 05:53.840
but it struck me that you guys are applying or trying to apply deep learning at a much

05:53.840 --> 06:00.160
more fundamental level, like looking at the, you know, interactions between proteins and things

06:00.160 --> 06:05.840
like that that create disease. And that strikes me as just super exciting, and that's why I wanted

06:05.840 --> 06:12.800
to really get, have this conversation. So, you know, maybe to get things started, you didn't start

06:12.800 --> 06:17.680
your research career in genomics, how did you find your way into the field?

06:18.240 --> 06:23.840
Yeah, so in the 1990s, I was a machine learning research, right? I did my PhD with Jeff Hinton,

06:23.840 --> 06:30.240
and we were looking at image data and speech and text as well. We published one of the first papers

06:30.240 --> 06:36.480
on deep learning in 1995, which appeared in science. And so really, those are good days,

06:36.480 --> 06:40.000
just discovering new algorithms and trying them out, but we didn't have big data sets,

06:40.000 --> 06:43.840
and we didn't have fast computers, and so, and so that was really a big bottleneck.

06:44.640 --> 06:51.200
Of course, that's completely changed now, but around 2002, by that time I was a professor,

06:51.200 --> 06:57.600
around 2002, my wife and I at the time discovered that the baby shows caring had a genetic problem.

06:58.480 --> 07:05.120
We went and saw a genetic counselor and had to deal with very difficult news. The feedback

07:05.120 --> 07:11.520
was it could be nothing or it could be a really big problem. So that was a really difficult

07:11.520 --> 07:17.760
experience emotionally to go through that and really changed my focus in terms of what I was

07:17.760 --> 07:24.320
doing as a researcher, and it decided to start working on vision and speech recognition and

07:24.320 --> 07:29.360
text analysis and really focus and said on the human genome and figuring out how to connect

07:29.360 --> 07:35.200
what's going on in people's DNA to to their health and also how to how to figure out how to treat

07:35.760 --> 07:44.400
treat disease. And so was my assessment of what you guys are doing relative to some of the examples.

07:44.400 --> 07:48.880
I provided, is that fair? How do you think about the the approach you're taking? Yeah, yeah,

07:48.880 --> 07:54.000
that's that's accurate. So the a lot of other players in this field are essentially leveraging

07:54.000 --> 07:59.840
their previous experience on on image analysis to to then look at medical images. Our approach is

07:59.840 --> 08:04.480
very, very different. We're starting with the genome as the input and the genome is just a long

08:04.480 --> 08:09.680
string of letters, ACG and T three billion of them from your mom and three billion from your dad.

08:10.320 --> 08:17.040
And the challenge there is really to to figure out what the language is. So so first of all the

08:17.040 --> 08:23.680
the language in the genome is not understood and how how words are put together to lead to to life

08:23.680 --> 08:28.640
essentially is not well understood. And so reverse engineering how the genome works is a big

08:28.640 --> 08:33.600
challenge. And then of course, once that's done figuring out how you can manipulate the genome,

08:33.600 --> 08:39.280
what you can do to to fix diseases is the second challenge. So yeah, I've been working on that for

08:39.280 --> 08:44.320
about 13 years and applying machine learning techniques to to crack that problem. And you're talk

08:44.320 --> 08:52.080
you presented some pretty staggering statistics. I think it was that the lifetime risk for

08:52.080 --> 08:59.920
a genetic related disease is something on the order of 65 percent and 8 million births per year

08:59.920 --> 09:08.080
with serious genetic disorders. Yeah, that's right. It's a big problem. And you know, we've

09:08.080 --> 09:12.480
we've been able to sequence the genome and now we can sequence individual genomes for about

09:12.480 --> 09:17.440
a thousand dollars and in a few years it should cost less than a trip to the grocery store to

09:17.440 --> 09:23.360
have your genome sequenced. And so we can read the text of your genome, but the tragic truth is

09:23.360 --> 09:28.640
that we are not currently able to accurately figure out what's wrong with you if you have a

09:28.640 --> 09:33.360
particular mutation, let alone figure out how to fix it. And so there's really a big gap. I call

09:33.360 --> 09:38.720
that the genotype phenotype gap. There's a big gap between our ability to read the text of the

09:38.720 --> 09:43.600
genome and the and make sense of it and then act on it. And so those statistics you gave like 8

09:43.600 --> 09:50.160
million births per year with a serious genetic disorder. That's it's kind of horrendous when

09:50.160 --> 09:53.920
you think we can sequence their genomes. We can find their mutations, but we don't really have

09:53.920 --> 09:58.480
the ability currently to figure out what's going wrong. And that's what we're working on. So both

09:58.480 --> 10:02.400
in my research lab and now with deep genomics, we're figuring out how to how to understand those

10:02.400 --> 10:09.040
mutations and what their implications are. So you know, I'd like to I'd like to understand all

10:09.040 --> 10:15.120
this better. And I'd like the audience to understand all this better. You know, what's the way?

10:15.120 --> 10:21.600
How can you give us kind of a, you know, push us off the deep end perhaps into biology and genomics?

10:21.600 --> 10:27.040
How, you know, how biology works and what are the various issues and implications so that we can

10:27.040 --> 10:33.440
start to have a conversation about this? Yeah, sure. So a common pattern in the field right now is

10:33.440 --> 10:37.040
people get a lot of data and then they kind of say, well, let's just throw it in a big bucket and

10:37.040 --> 10:42.960
give it to machine learning researchers and they'll solve it all. And I think that's a really

10:42.960 --> 10:50.800
bad approach. So our approach is very much a systems approach and that we try to understand biology.

10:51.520 --> 10:58.640
We bring to bear very carefully all biological knowledge that we can ascertain and then we build

10:58.640 --> 11:04.480
our machine learning systems to mimic that biology. And so for example, DNA is replicated when

11:04.480 --> 11:10.560
a cell divides DNA is replicated. So that's an important process. The way DNA is used within

11:10.560 --> 11:17.760
a cell is DNA is transcribed into RNA molecules. RNA molecules are chopped up and put back together

11:17.760 --> 11:24.720
again in a process called splicing. The splice RNA molecules then they are translated into proteins.

11:24.720 --> 11:28.960
And then the proteins go off and do things in the cell. And one of the things the proteins do is they

11:28.960 --> 11:34.880
bind to DNA. So the proteins interact with DNA and they actually interact with DNA in a way that

11:34.880 --> 11:41.600
controls transcription. The proteins also interact with RNA in a way that controls splicing and

11:41.600 --> 11:47.680
similarly processes of translation. And so you can think of biology as these multiple layers

11:47.680 --> 11:54.400
of processing, complex interactions, highly nonlinear, and really the phenotype that we see whether

11:54.400 --> 12:01.280
it's maybe cancer or neurological disorder is something that's gone wrong within one of these

12:01.280 --> 12:07.680
processes. And so that's just a brief summary of what's actually going on in the biology.

12:08.720 --> 12:14.960
So in between the DNA and your phenotype, multiple layers of complex biological processes that

12:14.960 --> 12:20.240
are nonlinear and combinatorial. And so what we do is we build machine learning models for each

12:20.240 --> 12:26.400
of these processes. So right now in the biology community there's just an explosion of data sets

12:26.400 --> 12:31.840
profiling what's going on within cells, essentially allowing scientists to peer right inside of cells

12:31.840 --> 12:37.440
and measure at the single molecule level what's going on. And so there's this rapid growth of data

12:37.440 --> 12:43.280
sets in the last few years and it's growing exponentially. And what we do is we use those massive

12:43.280 --> 12:51.200
data sets to train models to mimic these cellular processes. And like to give you an idea,

12:51.200 --> 12:55.440
the kinds of data sets we're looking at, we have trillions of data points that we use to train

12:55.440 --> 13:04.080
models. Wow. So for any given one of these interactions, you know, before we even start talking

13:04.080 --> 13:11.040
about the computational side of things, just as a community of biologists, how well do we understand

13:11.040 --> 13:16.800
what's really happening in the processes and when we have a data set that we're looking at?

13:18.080 --> 13:22.480
Yeah. Well, that's one of the things that we spent a lot of time on here at Deep Genomics

13:23.200 --> 13:29.280
is basically taking known biology and then figuring out what kinds of data we have that allow us

13:29.280 --> 13:35.040
to better model that known biology and then also try to account for unknown biology as well,

13:35.040 --> 13:40.080
which is one of the nice things that the machine learning offers. People on the past have tried

13:40.080 --> 13:45.280
literally writing down programs, computer programs to try to simulate what's going on in a cell.

13:45.280 --> 13:50.480
And then you might guess those, yeah, you might guess that kind of approach breaks pretty easily.

13:51.200 --> 13:55.280
First of all, we don't know all the rules. Second of all, quantities in the cell are real value.

13:55.280 --> 14:00.080
They're not binary and logical. And so that approach doesn't really work that well.

14:00.080 --> 14:04.320
People have also tried to write down stochastic differential equations describing the

14:04.320 --> 14:10.480
concentrations of molecules in the cell. And that'll work for small sort of very simple,

14:10.480 --> 14:14.160
contained systems where there aren't many molecules that kind of approach can work,

14:14.160 --> 14:18.400
but it won't work for for living cells. There's just too many different molecules

14:18.400 --> 14:22.960
and the processes are too complex. So the approach that we take is the machine learning approach.

14:22.960 --> 14:27.440
We can measure different data sets for these different molecules and then we train machine learning

14:27.440 --> 14:31.840
techniques to mimic the relationships between those data sets that then emerge due to these

14:31.840 --> 14:38.800
biological processes. Is there some characterization for how many relationships there are?

14:38.800 --> 14:43.280
Well, we have a roadmap. We have a technology roadmap, a deep genomics,

14:43.280 --> 14:47.280
which lists all the different modules that we were trying to account for.

14:47.280 --> 14:53.840
And we have a couple dozen described in our roadmap. But the number is much larger than that

14:53.840 --> 15:01.040
and growing every year as well. But having said that, it's just sort of a notion of diminishing

15:01.040 --> 15:06.080
returns. You can get quite a bit out of just modeling one or two processes. For example,

15:06.080 --> 15:11.200
I mentioned splicing where our name molecule is chopped up and then glued back together again.

15:12.160 --> 15:18.320
And that process depends on words essentially in the RNA molecule sequence. So RNA like DNA

15:18.960 --> 15:24.000
is a sequence of letters. And the machinery inside of the cell recognizes little patterns of

15:24.000 --> 15:28.240
letters or words. And those words tell the machinery how to cut up the RNA.

15:28.240 --> 15:36.160
And those letters represent proteins. So the sequence of words is a sequence of proteins in

15:36.160 --> 15:43.760
the RNA or DNA. Is that right? Oh, there's two kinds of words in there. So one kind of

15:43.760 --> 15:49.920
word in the RNA molecule sequence of letters does encode a protein. So it corresponds to amino acids

15:49.920 --> 15:54.880
that make the protein. But there are other words in the RNA that are more like control commands.

15:54.880 --> 15:59.200
So it's kind of like in a computer, you have print statements and then you have control logic.

15:59.200 --> 16:03.600
Right. Right. And the print statements are like proteins. But what's even more important

16:03.600 --> 16:08.160
than the print statements is the control logic itself. That's what creates the system that's

16:08.160 --> 16:12.080
responsive to its environment and that can do different things. Otherwise, we just keep printing

16:12.080 --> 16:19.440
the same thing over and over. Okay. And so the ability of the system to respond to different

16:19.440 --> 16:25.920
circumstances and be dynamic is really crucial. And that's achieved with these control statements,

16:25.920 --> 16:33.440
if you like, that are also embedded within the RNA sequence. So we have a system that was trained

16:33.440 --> 16:40.160
to mimic this process of splicing. And just to give you an example, one of the leading causes

16:40.160 --> 16:47.120
of infant mortality in North America is spinal muscular atrophy. And there's a mutation in the DNA

16:47.120 --> 16:53.840
that leads to this disease. And that mutation is in the RNA molecule as well. And it causes this

16:53.840 --> 17:00.080
process of splicing to go wrong. It leads to so normally a certain chunk of RNA is included in

17:00.080 --> 17:07.680
in the protein that makes up a certain gene called SMN1 or SMN2. And if there's a mutation,

17:07.680 --> 17:13.600
then that chunk is left out and that leads to the disease. Usually those infants die within

17:13.600 --> 17:22.320
the first year of birth. Recently, a therapy was given FDA approval. And what's interesting

17:22.320 --> 17:27.520
about that therapy is that it doesn't target that particular mutation. It actually modifies

17:27.520 --> 17:32.800
another part of the RNA molecule, which goes to show you the importance of commonatorics.

17:32.800 --> 17:37.280
Right? This is not, the biology is not something where there's a correlative effect or there's

17:37.280 --> 17:41.680
a particular mutation. You just need to fix that one mutation quite often. You need to change

17:41.680 --> 17:45.600
something else in order to fix a problem that's occurring in the genome.

17:47.280 --> 17:54.080
And so how I'm just thinking about the scale of this system and the interactions. You mentioned

17:55.280 --> 18:03.600
on the order of a dozen molecules or sorry modules. For a given disease,

18:04.400 --> 18:11.360
is it typically only one direct cause or they're often combinations of things happening

18:11.360 --> 18:18.160
in these different subsystems that is what causes the disease to spring forth?

18:18.160 --> 18:22.640
Yeah, that's a good question. And one thing I've learned about biology is almost anything goes.

18:24.400 --> 18:29.520
And so there's sort of the what's called the central dogmobology, which is very simple. But then

18:29.520 --> 18:34.800
you realize that a lot more complicated things can happen. So yeah, in the context of diseases,

18:34.800 --> 18:40.880
there are diseases called Mendelian disorders, which you can think of them as just a single mutation

18:40.880 --> 18:48.800
if you like, and one gene and a very simple relatively, relatively simple mechanism.

18:48.800 --> 18:53.520
It's still hard to find those, still hard to figure out how to treat those diseases, but

18:53.520 --> 18:57.840
but relatively simple in the sense it's just one mutation or one gene. But at the other end of

18:57.840 --> 19:04.880
the spectrum is the much more complicated situation where you have many different mechanisms or many

19:04.880 --> 19:12.080
different causes that combine together to result in the disorder or the disease. So a couple of

19:12.080 --> 19:17.440
examples there would be diabetes or autism spectrum disorder. And so if you take autism spectrum

19:17.440 --> 19:23.440
disorder as an example, the phenotype isn't even simply described. It's the whole range of phenotypes

19:23.440 --> 19:31.440
really. And also when you look at the heritability of the disorder, you find out that it can't just be

19:31.440 --> 19:35.920
pinned down to a single gene. It's many different genes. And even within those genes,

19:35.920 --> 19:40.960
it's not just a mutation in a particular location. It's a wide range of different genetic variability,

19:40.960 --> 19:46.640
different mutations at different places within that gene. And so the kinds of systems

19:46.640 --> 19:53.360
are building can be used for both situations. So we can pin down the single mutation that's

19:53.360 --> 19:59.040
causing a disease. And we can also use our systems to understand the complex combination of mutations

19:59.040 --> 20:04.400
that that is involved in a disease. Okay. Let me take a maybe a little bit of a tangent.

20:05.280 --> 20:10.560
There were a couple of technologies that you mentioned in your presentation that I wanted to hear

20:10.560 --> 20:16.400
a little bit about. The first is one that I've heard quite a bit about recently, but haven't really

20:16.400 --> 20:23.520
had a chance to dive into it. And that is CRISPR. It sounds like, well, tell us about CRISPR. What is

20:23.520 --> 20:31.280
that and what are the implications of it? Yeah. So CRISPR, Cas9, it's what's commonly referred to

20:31.280 --> 20:38.960
as a gene editing system. And it's a fairly straightforward idea. You basically program if you

20:38.960 --> 20:44.720
like a template into the into the system. So it's a group of proteins effectively and other

20:44.720 --> 20:49.680
molecules. And you essentially program a template into those. And then in living cells,

20:49.680 --> 20:58.320
you insert these molecules of system. And then the template will find its match within the

20:58.320 --> 21:05.200
within the DNA. And then once it's found a match, the system will then edit the DNA according to

21:05.200 --> 21:10.880
your specification. So there's different ways that can happen. It could be as simple as the template

21:10.880 --> 21:15.760
finds the match. And then it sticks there. Or it could be that the template finds a match. And then

21:15.760 --> 21:22.080
and then the DNA is is actually edited. So it's changed. And that's so that's basically an

21:22.080 --> 21:29.680
example of gene editing, which CRISPR Cas9 is one instance. And so how does that play into the

21:29.680 --> 21:36.080
kinds of work that you're doing in your lab and at the company? Yeah. So so there are a couple

21:36.080 --> 21:42.000
problems with with gene editing systems. And one of them is off target effects. And so and so the

21:42.000 --> 21:48.960
template might not be perfectly specific, which means the the system might bind to the DNA in two

21:48.960 --> 21:54.240
different places and edit the DNA in two different places. And so one of the places the correct one,

21:54.240 --> 21:58.880
maybe there's a mutation you're trying to fix to address some sort of a disease. But what happens

21:58.880 --> 22:03.680
is the system will also bind somewhere else to some other region of the DNA and then edit the DNA

22:03.680 --> 22:07.680
there. And that could actually lead to a problem. And so that and that's called an off target effect.

22:07.680 --> 22:13.840
The other one is that suppose the other problem with these kinds of systems as supposed as a

22:13.840 --> 22:20.720
particular mutation that you're trying to correct trying to fix. It may be that the sequence surrounding

22:20.720 --> 22:27.040
that mutation is just not good in terms of designing a template. So you can't actually design a

22:27.040 --> 22:31.840
template in your CRISPR Cas9 system that will that will work properly in terms of finding that

22:31.840 --> 22:36.480
mutation and then correcting the mutation. And so there's a couple different problems with these

22:36.480 --> 22:41.680
gene editing systems. Another problem is delivery. Just has to do with the fact that the the machinery

22:41.680 --> 22:48.080
you need to get inside of the cell involves several different molecules. And each of those molecules

22:48.080 --> 22:52.160
has different properties in terms of in terms of whether or not it can successfully be

22:53.600 --> 22:58.560
be delivered into the cell. And so there's several different issues with gene editing systems.

22:59.040 --> 23:03.040
And there's a few different ways in which our technology that we develop that deep genome is

23:03.040 --> 23:08.880
can be helpful. So one of them is because we we have these machine learning systems that can mimic

23:08.880 --> 23:15.040
biological processes. One biological process is this template matching. So how well the template

23:15.040 --> 23:20.000
matches the DNA that's actually a biochemical process that occurs within the cell. And so our

23:20.000 --> 23:27.280
systems can identify off target effects and predict predict what might happen. The other example

23:27.280 --> 23:32.960
is when you can't actually edit a particular mutation. So there's a mutation that a patient has

23:32.960 --> 23:38.400
and you'd like to fix it. You can't actually edit that mutation because the you can't design

23:38.400 --> 23:45.520
an appropriate template. So then what do you do? Well one idea is maybe you can edit some other

23:45.520 --> 23:51.280
region of the DNA and somehow there will be some sort of compensatory effect. But in order to do

23:51.280 --> 23:56.480
that you actually need a model. You need a system that can mimic how that DNA is going to be

23:56.480 --> 24:01.840
processed because you can't you can't just fix the mutation. You need to introduce a mutation

24:01.840 --> 24:07.440
somewhere else that is going to correct the problem introduced by the first mutation. So for

24:07.440 --> 24:13.360
example the the first mutation the disease mutation may cause a problem with splicing. And what you'd

24:13.360 --> 24:18.000
like to do is introduce a mutation somewhere else that will reverse that problem with splicing.

24:18.000 --> 24:22.480
Right. And again that up and that again that that requires that you have some sort of a model

24:22.480 --> 24:27.040
for how the cell is going to process that piece of DNA to control splicing and that's the kind

24:27.040 --> 24:34.480
of model we build. Okay so you guys the work that you're doing can improve these genome editing

24:34.480 --> 24:42.640
systems and at the same time the the work that you're doing around diseases the genome editing

24:42.640 --> 24:51.280
system is one way that this work would eventually be deployed if you will put it into practice.

24:51.280 --> 24:56.560
That's right at this point in time in deep genomics we have not developed any products to address

24:56.560 --> 25:01.600
that particular therapeutic approach the gene editing system approach but it is a research

25:01.600 --> 25:08.800
endeavor at this point. And so why have I heard so much about CRISPR you know maybe not this year

25:08.800 --> 25:12.800
but towards the tail end of last year is it just that it was you know new or with their new research

25:12.800 --> 25:19.200
results or is it better faster cheaper like what's the what was the big deal with research? Yeah yeah

25:19.200 --> 25:24.400
it's leading to all sorts of breakthroughs in terms of research so the ability of genome biologists

25:24.400 --> 25:30.640
to conduct different experiments different screens fabulous tool for research and in terms of medicine

25:30.640 --> 25:36.080
there's a lot of promise there are some issues that need to be worked out but those are being

25:36.080 --> 25:41.760
looked at and and I think it's very likely that it'll it'll prove to be a useful therapeutic technique

25:41.760 --> 25:48.400
under some circumstances in any case. And so the other question I had in terms of just the

25:48.400 --> 25:53.920
context in which you're you're doing your work is you mentioned and you mentioned this in early

25:53.920 --> 26:02.720
in our conversation now is the increasing drive towards cheaper and cheaper sequencing and at

26:02.720 --> 26:07.200
the deep learning summit you mentioned some new technology that you were expecting to drive the

26:07.200 --> 26:14.320
cost down to as little as $20 within the next year or so what can you give me a kind of a quick

26:14.320 --> 26:21.120
summary of the activity there? Yeah yeah sure there's just as I mentioned before this rapidly

26:21.120 --> 26:25.920
growing diverse array of different biotechnologies that allow us to measure what's going on inside

26:25.920 --> 26:31.200
of cells and genome sequencing is of course an important one it's the one that kind of gives us

26:31.200 --> 26:35.840
the software if you like for the the basic source code of the of the person or the cells

26:36.560 --> 26:42.880
and yeah there's technologies like the Oxford Nanopore technologies and other companies have

26:42.880 --> 26:48.800
similar technologies which will which will allow cheaper sequence much cheaper sequencing genome

26:48.800 --> 26:53.440
sequencing. But that's not the only technology that's helpful there's there's other kinds of

26:53.440 --> 26:58.080
methods that allow you to for example look inside of DNA and see which genes are being transcribed

26:58.080 --> 27:04.800
and measure how quickly they're being transcribed or the transcription rate of the gene techniques

27:04.800 --> 27:08.800
that allow us to measure quantitatively how much protein is being produced and where the protein

27:08.800 --> 27:14.400
is being located within the cell by the by the molecules that that shuttle proteins around.

27:14.400 --> 27:18.720
So there's a lot of different kinds of biotechnologies being developed that allow us to essentially

27:18.720 --> 27:25.920
look inside of cells and measure what's going on. Okay so lots of stuff going on you know maybe

27:25.920 --> 27:30.560
let's yeah I've kind of been just trying to satisfy some curiosity because I've had about

27:30.560 --> 27:35.760
the biological side of this but maybe let's kind of bring the conversation to machine learning

27:35.760 --> 27:42.800
and deep learning and maybe let's start by talking through you know prior to the work that you

27:42.800 --> 27:50.240
and others are doing to apply deep learning it sounds like machine learning a traditional machine

27:50.240 --> 27:55.760
learning linear regression and things like that were applied to these types of problems well how

27:55.760 --> 28:04.800
was talk about the kind of the standard to date approach. Sure yeah you know and I should emphasize

28:04.800 --> 28:10.960
that deep genomics the word deep is is referring not just to deep learning but also these deep layers

28:10.960 --> 28:16.480
of biological processes that get stacked upon one another that relates DNA to the phenotype

28:17.120 --> 28:21.440
and really that's what's most crucial and as you might guess for each one of these modules the

28:21.440 --> 28:26.320
first thing we do is try linear regression and it's the simplest technique quite often the best

28:26.320 --> 28:31.840
technique but when you have a lot of data it does it does help to to look at more sophisticated

28:31.840 --> 28:37.760
methods and so deep learning is a big part of what we do with deep genomics. Okay yeah so really

28:39.520 --> 28:44.560
in in biology two approaches have been taken on supervised learning and supervised learning

28:45.440 --> 28:52.400
and so way way back in the late 1990s people trained hidden markup models on on DNA sequences

28:53.440 --> 28:58.880
and those hidden markup models were able to learn patterns that indicate the starts of genes

28:58.880 --> 29:04.480
and the ends of genes and the locations of axons within the genes the axons are those parts of

29:04.480 --> 29:08.320
the genes that actually they're like the print statements they're the parts of the genes that tell

29:08.320 --> 29:13.680
you what the protein content is. Okay and so yeah that was back in the late 1990s researchers were

29:13.680 --> 29:20.160
training hidden markup models to to model gene structure. And can you give us a 30,000 foot

29:20.160 --> 29:27.920
view into what a hidden markup model is? Oh yeah sure so a hidden markup model is like a machine and

29:27.920 --> 29:33.680
of course simulated inside of the computer that it has several different states and the the model

29:33.680 --> 29:40.240
can switch back and forth between different states. And so for example it might be in the promoter

29:40.240 --> 29:46.240
so so the structure of a gene is there's a promoter there's an axon and then there's an intron and

29:46.240 --> 29:50.400
there's an axon and there's an intron and that just alternates until the end of the gene. There's

29:50.400 --> 29:55.120
a couple other parts of the gene but for simplicity that's just that's just say those are the components

29:55.120 --> 29:59.680
of the gene. So the hidden markup model would start off in the promoter state and then it was

29:59.680 --> 30:05.840
switched to the axon state and then back to the intron state and then back to the back and forth

30:05.840 --> 30:12.240
right. And so that's so that's the hidden markup model has a finite set of states and then there's

30:12.240 --> 30:17.920
a model for how the or probability distribution that describes how the model switches between states.

30:18.560 --> 30:23.840
So for example if you're in the promoter state then there's a high probability that you'll switch

30:23.840 --> 30:27.600
to the axon state. And if you're in the axon state there's a high probability switch to the

30:27.600 --> 30:32.000
intron state. If you're in the intron state there's a high probability switch to the axon state

30:32.000 --> 30:36.640
and so on. Okay. And so it's a probabilistic model that just allows this machine to switch back

30:36.640 --> 30:41.680
and forth between these different states. And then for each of the states part of the hidden

30:41.680 --> 30:46.880
markup model is also a description of what the data will look like in that state. And so for

30:46.880 --> 30:52.880
example when there's a transition from the axon state to the intron state the hidden markup model

30:52.880 --> 30:59.760
also has a component or a probability distribution over what the DNA symbols will look like at that

30:59.760 --> 31:06.480
transition point. And so if you run the hidden markup model just just simulate it which means

31:06.480 --> 31:10.640
let it flip back and forth between these different states and for each state let it generate some

31:10.640 --> 31:15.360
of the DNA sequence. If you run the hidden markup model you'll end up with a synthetic if you like

31:15.360 --> 31:20.560
a synthetic gene sequence. Okay. And the way the hidden markup model is trained is to make the

31:20.560 --> 31:26.160
synthetic gene sequence the output of the hidden markup model match the real data as best as possible.

31:26.160 --> 31:31.920
And so in the late 1990s researchers trained these hidden markup models using actual examples of

31:31.920 --> 31:37.520
DNA sequences and these models were able to automatically learn what the structure of a DNA

31:37.520 --> 31:42.080
sequence looks like. So they were able to learn that there's a promoter, there's an axon and an

31:42.080 --> 31:48.320
intron and that there's alternation between these axons and introns. So that's one example and

31:48.320 --> 31:53.120
that's unsupervised learning and there are lots of other examples of how unsupervised learning has

31:53.120 --> 32:01.840
been used in genome biology ranging from as I said modeling DNA to to actually just visualizations

32:01.840 --> 32:08.000
of dimensionality reduction taking taking for example expression gene expression measurements

32:08.000 --> 32:13.120
which would be say 22,000 gene expression measurements and compressing them down to a three

32:13.120 --> 32:18.720
dimensional or a two dimensional representation for visualization. So the whole wide range of

32:18.720 --> 32:24.000
different uses of unsupervised learning. And then the other the other process has been taken

32:24.000 --> 32:29.040
to supervised learning where you're actually trying to solve a very specific task and probably the

32:29.040 --> 32:35.840
one of the earliest uses of supervised learning in the context of genetic medicine as what was

32:35.840 --> 32:40.800
called the genome wide association study. And in the genome wide association study what you do is

32:40.800 --> 32:50.160
you measure for each patient a what's called the genotype which is just a measure of a variety of

32:50.160 --> 32:55.680
mutations. So those mutations might be measured using a micro array. People might have heard of

32:55.680 --> 33:02.720
the name SNEP array and so SNEP stands for single nucleotide polymorphism and that's just a

33:03.280 --> 33:09.760
location within your DNA which could have a mutation in it. And so these SNEP arrays would measure

33:09.760 --> 33:15.600
say 500,000 different possible mutations in your in your DNA. Another way you might measure

33:15.600 --> 33:20.480
genotype is whole genome sequencing. So you'd literally read out the three billion letters or if you

33:20.480 --> 33:25.200
have if you can do it for both your paternal and maternal DNA you'd have six six billion letters.

33:26.560 --> 33:31.920
And so whatever you however you go measuring this genotype you can essentially think of it as a

33:31.920 --> 33:41.600
vector. So it's going to be a sequence of of of letters ACG and T. So for 500 nucleotide array you

33:41.600 --> 33:48.800
have 500 letters for a 500,000 nucleotide SNEP array you'd have 500,000 letters and then you can

33:48.800 --> 33:57.600
imagine encoding that vector as a binary vector. So the letters ACG and T you can encode it using

33:57.600 --> 34:04.960
one hot encoding. So A is 1, 0, 0, 0, C would be 0, 1, 0, 0. So there's different ways of doing that

34:04.960 --> 34:10.000
or what's often done is what you do is you compare you compare the person's genetics to the reference

34:10.000 --> 34:16.480
genome and so then you represent whether or not they have a mutation there compared to the

34:16.480 --> 34:21.680
the reference genome something like that. So so basically though you represent the person's

34:21.680 --> 34:28.000
genetics as a big long vector of zeros and ones and then what you do is use linear regression to

34:28.000 --> 34:31.600
try to predict the phenotype. So you've got a whole bunch of patients with cancer and a whole

34:31.600 --> 34:37.760
bunch of patients without cancer and and then you just try to predict the whether or not they have

34:37.760 --> 34:42.720
cancer using linear regression. That's what a genome-wide association study is. So it's probably the

34:42.720 --> 34:48.800
simplest and and one of the original uses of machine learning in in genomic medicine. Okay.

34:48.800 --> 34:54.000
Okay. And what are the challenges associated with that approach?

34:55.520 --> 34:59.360
Well if you think about it, what that approach is essentially assuming is that your phenotype is

34:59.360 --> 35:08.800
a linear function of your genetics. Exactly. You mean it's not. And so you know we already talked

35:08.800 --> 35:13.600
about these complex non-linear biological processes that relate your genetics to your phenotype

35:13.600 --> 35:21.040
and we know from experience that this relationship is not linear. And so it's it's a it's an assumption

35:21.040 --> 35:28.080
that has been used successfully to find mutations that are involved in disease but it doesn't

35:28.080 --> 35:33.200
really accurately mimic the biological process. And so there are a few consequences of that

35:33.200 --> 35:39.200
of that limitation and and one of them is that the is that the genome the genome-wide association

35:39.200 --> 35:44.720
study is not guaranteed to find the causal mutation. Okay. And so it may actually find a mutation

35:44.720 --> 35:50.960
that isn't rich, for example, that is common in patients with with cancer but it's not guaranteed

35:50.960 --> 35:55.760
to be the mutation that actually caused the disease. And that's a big problem if you're trying to find

35:55.760 --> 36:01.360
a drug or a therapy to treat the disease because that mutation will be the wrong one. Now they're

36:01.360 --> 36:07.040
their techniques called fine mapping where you you look for nearby mutations and try to try to

36:07.040 --> 36:11.120
couple up those mutations with the one you found in the genome-wide association study

36:11.120 --> 36:17.280
and that that fine mapping approach has been used to to find the the causal mutation the one

36:17.280 --> 36:22.880
that should be treated with the drug but is still limited and doesn't it doesn't solve all of the

36:22.880 --> 36:30.160
problems. And I guess there are a few different other issues and one of them one of them is the

36:30.160 --> 36:36.240
amount of data that's required. And so because of the way the genome-wide association study works

36:36.240 --> 36:41.520
if you think about it there's three billion letters in the genome, three billion possible places

36:41.520 --> 36:46.880
is the commutation. And for each of those locations you're going to try to use that location to

36:46.880 --> 36:50.400
predict whether or not the person has cancer and then compare it against the experimental data.

36:51.120 --> 36:55.760
And so there's really three billion different places you can look. And the problem is if you don't

36:55.760 --> 37:02.880
have much data just by random chance one of those locations is going to match up with the phenotype

37:02.880 --> 37:06.800
that is just even if the DNA is just noise even if you're just generating a whole bunch of noise

37:06.800 --> 37:11.600
patterns you do that for your cases and your controls just by chance one of the locations one of

37:11.600 --> 37:15.920
the positions in the genome you're going to get a good agreement between that mutation and whether

37:15.920 --> 37:22.800
or not the person has a so-called cancer even though it's just noise it's meaningless. And so

37:22.800 --> 37:29.040
and so so many get a lot of false positives. Yeah that's right a large number of false positives.

37:29.040 --> 37:33.360
Okay. And the only way to get rid of that in a genome-wide association study is collect more

37:33.360 --> 37:38.400
and more data and and that's the way you get rid of those false positives. But the problem there is

37:38.400 --> 37:43.200
meaning you're not addressing you're trying to address it through kind of brute force statistics as

37:43.200 --> 37:49.120
opposed to a better technique. That's right that's right you're just trying to get so much data

37:49.120 --> 37:53.200
the overwhelmed the the fact that you have a model of what's really going on well. So the

37:53.200 --> 37:58.480
approach we take which is this deep learning approach allows us to build models that take us from

37:58.480 --> 38:04.400
the DNA to these intermediate molecular phenotypes or cell variables if you like variables representing

38:04.400 --> 38:10.080
things like transcription and splicing. And those intermediate biological processes are really

38:10.080 --> 38:16.160
what's crucial for disease. And so by modeling those explicitly we can take this big sequence of

38:16.160 --> 38:21.280
three billion letters and user machine learning technique to map it down to a much smaller space

38:21.280 --> 38:26.240
that represents what's really going on inside of the cell. And then we can relate that much smaller

38:26.240 --> 38:30.880
and more compact representation with the phenotype whether the person has cancer or not.

38:30.880 --> 38:38.720
Okay so strikes me then that you know basically what you guys are doing is feature engineering

38:38.720 --> 38:42.720
for this particular type of system. Is that a fair way to think about it?

38:43.680 --> 38:51.520
It's a it to some degree yes it's um I would say instead of feature engineering it's biological

38:51.520 --> 38:56.160
engineering in the sense that we're choosing we're choosing because these features that we're

38:56.160 --> 39:03.600
looking at are fairly complex and high level. Right. And and also it certainly doesn't do what you're

39:03.600 --> 39:09.840
doing justice. But if you think about you've got all this raw data that doesn't really express or

39:09.840 --> 39:16.240
kind of model the underlying phenomena and you guys are creating these meta models if you will

39:16.240 --> 39:23.520
that does based on the raw data. It's kind of feature engineering-ish. Yeah well the thing is we

39:23.520 --> 39:28.720
do have data for these intermediate variables. So for example. Got it. Okay. Yeah so one of the

39:28.720 --> 39:33.360
one of the ways you might think of it as feature engineering is we actually model where a protein

39:33.360 --> 39:39.200
will bind to the DNA right. So so protein binding to DNA is a very important biological process

39:39.200 --> 39:43.040
in understanding how a mutation disrupts that is really important for understanding disease.

39:43.040 --> 39:47.680
So you might sort of say well what we've done is we've designed features that describe how the

39:47.680 --> 39:53.840
protein is binding to the DNA. But the way we actually account for that is we obtain training data

39:54.560 --> 39:59.840
for where the protein bound. So we've got a data set of DNA sequences and whether or not the

39:59.840 --> 40:04.960
protein bound to that DNA sequence and then we train a model for that. So if you like each of these

40:04.960 --> 40:09.360
features is actually a machine learning system. And so that's where that's where it's quite

40:09.360 --> 40:13.200
different from traditional feature engineering where you actually hand code the features. So we don't

40:13.200 --> 40:17.760
we don't really hand code the features. We obtain training sets and then we train the models to

40:17.760 --> 40:23.920
extract the features. Okay. Yeah but it is you know it is it does have that you know that sort of

40:23.920 --> 40:29.200
confidential structure to it and we do there is this notion where each of these features is validated.

40:29.200 --> 40:34.800
We do carefully validate each of these we call them a biomodule. So we validate each

40:34.800 --> 40:39.920
biomodule to make sure that it's really counting for that particular biological mechanism.

40:40.880 --> 40:46.400
The other way you can think about this actually is multi-path multi-task training. Okay so deep

40:46.400 --> 40:52.000
neural networks one of the techniques that works really well is it's called multi-task training.

40:52.000 --> 40:57.040
That's where you you train your system to solve multiple tasks at the same time.

40:58.400 --> 41:04.400
So you might have you might have a very simple example might be the input as an image and your

41:04.400 --> 41:11.200
training it to to classify animals and at the same time you're also training it to classify

41:12.720 --> 41:17.760
some other some other kind of object and the ideas that is that the what it learns about those two

41:17.760 --> 41:21.760
for example faces. So maybe you're trying to classify faces and you're also trying to classify

41:21.760 --> 41:26.720
animals and there's some components to those two different problems that are that are of shared

41:26.720 --> 41:34.240
value. For example the detection of body parts or the detection of eyes something like that and

41:34.240 --> 41:39.200
so by training the system to solve these two different tasks at once it can learn sub components

41:39.200 --> 41:43.360
it can learn intermediate variables if you like that are useful for for the two different tasks.

41:44.160 --> 41:48.080
And so you can also think about what we're doing that way we have this these very deep

41:48.080 --> 41:53.840
multi-layer architectures and they're trained to predict phenotype but they're also trained to

41:53.840 --> 41:57.600
predict protein binding they're also trained to predict splicing they're also trained to predict

41:57.600 --> 42:02.720
transcription and these different processes that are going on within the cell. And by training

42:02.720 --> 42:07.520
them jointly to solve these different tasks they get better at solving any one of them and in

42:07.520 --> 42:12.640
particular they can get better at detecting disease and also predicting the effects of therapies.

42:13.200 --> 42:21.440
Are the different modules? How do I ask this question? If you think about this as a if the model

42:21.440 --> 42:26.960
that we're talking about here is a deep neural network are the different modules expressed

42:26.960 --> 42:36.960
explicitly as layers meaning like the the network architecture or does the training process

42:36.960 --> 42:41.680
kind of cause the modules to be expressed in the layers does that question make sense?

42:41.680 --> 42:45.600
Yeah no it does it's a good question you're sort of asking what's the mapping between the

42:46.400 --> 42:49.760
layers of biology and the layers of our machine learning systems.

42:49.760 --> 42:57.360
Yes yeah so so we have two separate maps if you like two separate networks if you like one network

42:57.360 --> 43:04.320
represents the biological processes and for each if you like for each node and each arrow in

43:04.320 --> 43:10.080
that network we train a deep learning system and so and so if the biological network is 10 layers

43:10.080 --> 43:14.720
deep and each layer is modeled by a deep learning system with 10 layers and there's an overall

43:14.720 --> 43:20.320
depth of 100 so that's the one way you can think about it and so because the system is trained

43:20.320 --> 43:24.720
in a modular fashion we can focus in on each component to the biological network and then train

43:26.880 --> 43:31.920
a deep neural network to model that component and sometimes sometimes use a shell

43:31.920 --> 43:37.600
in that work sometimes linear regression is sufficient so the complexity of each of those biological

43:37.600 --> 43:45.120
modules in terms of machine learning is is carefully selected using the traditional machine learning

43:45.120 --> 43:52.160
types of techniques cross validation and perturbation analysis and methods like that and

43:52.160 --> 44:02.160
does it ever make sense to rather than training these models as a stacked neural network to think

44:02.160 --> 44:06.320
of it more as like an ensemble approach where your modules are more separate and you're training

44:06.320 --> 44:12.800
them independently and then you've got some discriminator network you know it's it's sort of the

44:12.800 --> 44:20.160
overall ideas that each of these modules does have a place within the biological system but

44:20.160 --> 44:25.680
having said that we do we do sometimes run into situations where there are fairly different ways

44:25.680 --> 44:31.200
we can conceive of building each module just like in traditional machine learning you might have

44:31.200 --> 44:37.280
different types of you might use a random forest in one case and a neural network and then

44:37.280 --> 44:41.040
you'd like to combine the outputs and see what happens so that sort of thing happens for for

44:41.040 --> 44:44.800
given biological module and might conceive of different ways we can build the machine learning

44:44.800 --> 44:50.400
system to come up with that process and then combine the outputs the the other the other interesting

44:50.400 --> 44:55.440
aspect of this is the sort of end-to-end training that once we put the the system together

44:56.480 --> 45:00.960
then we can fine tune it to make the overall system perform better so even though we

45:00.960 --> 45:06.240
module is initially built using a machine learning system could be a deep neural network

45:07.440 --> 45:11.760
independently of the other modules once we put them together we can adjust all the modules so

45:11.760 --> 45:18.320
they work better together okay in your presentation you had a slide where you were talking about

45:19.120 --> 45:24.560
kind of applying you know what you were doing and applying AI to these types of problems and you

45:25.200 --> 45:30.720
spent quite a bit of time talking about inductive learning versus transductive learning and

45:30.720 --> 45:38.800
how that seems to be you know something that's overlooked in practice can you recap that for us

45:38.800 --> 45:43.680
yeah there's a big focus right now just on collecting data and I think not enough attention is

45:43.680 --> 45:49.520
being paid to analyzing the data when it comes to genomic medicine and so there are a lot of

45:49.520 --> 45:55.600
private and public efforts to just collect data you know the big genome projects the the 100,000

45:55.600 --> 46:00.720
genome project the way the way success is measured is in the number of genomes as opposed to the

46:00.720 --> 46:07.600
information that's being extracted right and and so I think more attention needs to be paid on

46:07.600 --> 46:12.480
analyzing the data now if you look at the genome wide association study where it's this idea of

46:12.480 --> 46:18.000
correlating mutations with the output that's what I would call is more more of a transductive

46:18.000 --> 46:23.040
reasoning approach or basically you're just comparing you're comparing your mutation to the

46:23.040 --> 46:29.840
training data and then trying to make a sort of a winner take all or or taking a voting approach

46:29.840 --> 46:37.440
trying to make a prediction for that mutation now I that's one type of machine learning a different

46:37.440 --> 46:41.440
kind is inductive learning and inductive learning what you do is you you take your training data

46:41.440 --> 46:46.480
and then you build a machine learning model of what's going on and then you apply that model

46:46.480 --> 46:53.440
to the test cases so you apply the model in the future and the advantage of inductive learning

46:53.440 --> 47:02.560
is is generalization so for inductive learning you can learn if in sort of a in one way to view

47:02.560 --> 47:06.560
it is you're learning the rules of what relates the input to the output you're you're learning more

47:06.560 --> 47:11.840
general patterns and this allows you to to take that learning and apply it to completely new

47:11.840 --> 47:16.800
circumstances and so for example if there's a completely new mutation that's never been seen

47:16.800 --> 47:22.480
before if you've used inductive learning you might hope that your machine learning model can still

47:22.480 --> 47:27.680
figure out what's going to happen with that new mutation in contrast to transductive learning

47:27.680 --> 47:32.400
approach if there's a new mutation that's never been seen before that transductive learning

47:32.400 --> 47:36.960
approach can't do anything and so that's true for genome-wide association studies for example if

47:36.960 --> 47:42.480
there's a mutation in a patient that it doesn't exist in the training set then the genome-wide

47:42.480 --> 47:47.680
association study can say nothing about that mutation whereas with the inductive machine learning

47:47.680 --> 47:52.480
approach you might hope that it could take the system could take a look at that mutation and say

47:52.480 --> 47:58.160
ah this mutation is going to cause something to go wrong with splicing and that's going to lead

47:58.160 --> 48:02.480
to the disease and actually that's what we find with our systems so the systems we trained at

48:02.480 --> 48:06.800
deep genomics were able to analyze mutations that have never been seen before that don't exist in

48:06.800 --> 48:17.200
any database okay okay oh that's huge yeah really fighting actually so maybe let's let's dig

48:17.200 --> 48:26.480
into the the data aspect of this a bit in order to do what you're doing I'm imagining you're

48:26.480 --> 48:33.600
benefited you're benefiting pretty significantly by your new data sets coming online all the time like

48:33.600 --> 48:38.960
how is that landscape change and what are some of the types of data that you're looking at

48:39.920 --> 48:44.880
yeah it's one of the most exciting areas right now is biotechnology just the the number of

48:44.880 --> 48:50.800
different kinds of data sets is growing very rapidly in the sizes of those data sets so 10 years

48:50.800 --> 48:57.440
ago we were looking at small data sets consisting of a few thousand examples and now deep genomics

48:57.440 --> 49:02.640
we look at data sets with billions of examples so we're so the amount of data has just grown

49:02.640 --> 49:09.120
very very rapidly and is going to continue to grow there are publicly available data sets so these

49:09.120 --> 49:16.400
are publicly funded research efforts from university labs and so there's plenty of publicly available

49:16.400 --> 49:21.760
data and then there's also different kinds of proprietary data data coming from patient populations

49:22.400 --> 49:28.640
or data that we generate within deep genomics to to study particular aspects of biochemistry and

49:28.640 --> 49:35.120
sort of fine tuner models if you like and then in terms of the in terms of what the data is telling

49:35.120 --> 49:39.360
us as I mentioned before it's these data sets are measuring all sorts of things that are going

49:39.360 --> 49:45.760
on within cells so it's giving us more and more accurate resolution higher and higher resolution

49:45.760 --> 49:50.880
in terms of pinpointing different processes going on within cells and relationships between

49:50.880 --> 49:56.240
those processes so I really do think that in in five to ten years because of this massive growth

49:56.240 --> 50:02.240
in data if we combine machine learning techniques with all these data sets we're going to be able to

50:02.240 --> 50:06.000
produce models of these cellular processes that are quite accurate and reliable.

50:08.480 --> 50:13.200
I took a look at one of your papers the paper that goes into the work that you're doing

50:13.200 --> 50:19.760
about around deep bind and one of the points that you brought up there was the difficulty of

50:19.760 --> 50:28.000
extending results that are seen with in vitro analyses to in vivo analyses and I'm assuming that

50:29.360 --> 50:35.120
or that's that's tied to this issue of the or to what degree is this tied to this issue of the

50:35.120 --> 50:41.600
data sources that you're getting being primarily in vitro and maybe could talk through some of the

50:41.600 --> 50:49.680
issues there yeah yeah so yeah there's different kinds of data and in vitro is data that is

50:49.680 --> 50:54.480
measured under it's in the test tube and it's so this data that's measured in the lab under very

50:54.480 --> 50:59.680
controlled conditions in vivo with the other end of the spectrum is within the living organism

51:00.400 --> 51:05.040
and so it's the idea is that data would reflect more accurately what's actually going to happen

51:05.040 --> 51:12.320
and say a patient and and historically there's been a big disconnect between these data sets but

51:12.320 --> 51:17.520
as as we sort of fill in if you like if we fill in the map of all the different kinds of things

51:17.520 --> 51:22.720
we can measure within the cell and we also fill in the different kinds of conditions under which

51:22.720 --> 51:29.440
we can measure that data and so in vitro in vivo but also different kinds of organisms different

51:29.440 --> 51:35.280
kinds of cell types different tissue types and as we as we measure more and more data for these

51:35.280 --> 51:40.000
different dimensions if you like of different conditions in which we measure the data we get a

51:40.000 --> 51:43.600
more accurate understanding of how all those different kinds of data relate to one another

51:44.720 --> 51:49.040
and so we're also building better and better models that are accounting for confounding factors

51:49.040 --> 51:58.160
or experimental bias or example of a confounding factor might be what oh yeah so there's a different

51:58.160 --> 52:04.320
a wide range of different kinds of confounding factors they'll lump them all together into one group

52:04.320 --> 52:10.160
so experimental bias is a big one and experimental bias just means how your experiment was conducted

52:10.160 --> 52:15.280
you know what what were the very what were some of the technical details that were used to obtain

52:15.280 --> 52:20.320
the data and those things can have a big impact on the on the data itself actually one of the first

52:20.320 --> 52:26.880
projects I worked on in genobiology we we used a particular kind of unsupervised learning method

52:26.880 --> 52:30.800
to analyze the data and we thought we discovered something really interesting and it turned out what

52:30.800 --> 52:40.800
we discovered is who did the experiment on which day and so that's an experimental type of confounding

52:40.800 --> 52:46.320
factor and then there are confounding factors that are biological and so for example if you're

52:46.320 --> 52:50.880
looking at let's take the genome wide association study approach a very very simple machine learning

52:50.880 --> 52:57.120
technique and so if you're looking at a bunch of patients that have a disease and a bunch of

52:57.120 --> 53:01.680
patients that don't have the disease the the problem is that those patients are not really

53:01.680 --> 53:08.400
independent and identically drawn from some simple distribution they're actually related to one

53:08.400 --> 53:15.040
another in some way and so so maybe half of your cases are derived from a single ancestor that

53:15.040 --> 53:21.360
lived 100,000 years ago or something like that so that kind of structure in the population

53:21.360 --> 53:25.440
is going to lead to dependencies of course between these measurements and those dependencies can

53:25.440 --> 53:30.800
lead you astray it's a little bit like you know suppose you're one problem that all machine

53:30.800 --> 53:35.760
learning researchers are familiar with is suppose you have a training data of a hundred examples

53:35.760 --> 53:40.720
and you take one of your examples and just replicate it a million times right you do not have a

53:40.720 --> 53:45.680
training set a bona fide training set of a million a 99 examples because you've biased your

53:45.680 --> 53:50.800
yeah yeah just copied one of the examples a whole bunch of times so that's an example of a

53:50.800 --> 53:55.680
confounding factor that really does arise in human genetics and is really important to to avoid

53:56.320 --> 54:03.280
and is the idea that your approach or deep learning in general is has a higher level of

54:04.480 --> 54:10.000
is more impervious to these types of confounding factors yes yeah that's that's right and so because

54:10.000 --> 54:14.240
we're building a system to model these different biological components we can factor out certain

54:14.240 --> 54:20.160
confounding factors and so as I mentioned for example our system can detect mutations that have

54:20.160 --> 54:27.200
never been seen before which obviously means that it's not sensitive to the to to the structure of

54:27.200 --> 54:32.960
of the human population in terms of the genetics okay but at the same time I you know I should

54:32.960 --> 54:38.400
add that of course our systems are being trained using data that has biases because basically all

54:38.400 --> 54:43.920
the biology is highly biased so and so it's not like the problem is completely gone but yes they're

54:43.920 --> 54:53.920
more impervious yeah awesome awesome well this is this has been fantastic maybe any closing thoughts

54:53.920 --> 55:00.240
on things that you guys are working on are you know what you're excited about yeah I guess the

55:01.600 --> 55:07.680
the the challenges for us are so we have our systems are working well and we're making

55:07.680 --> 55:13.440
good progress in terms of addressing interesting machine learning problems as well as having an

55:13.440 --> 55:19.840
impact in medicine but I think one one area that's interesting to talk about is is the kinds of

55:19.840 --> 55:24.640
problems that we're facing in terms of our machine learning techniques and how those relate to

55:25.840 --> 55:32.160
what generally the field is looking at and and and being challenged with and one of those is

55:32.160 --> 55:38.400
is building systems that can explain themselves and so this has been a people have been talking

55:38.400 --> 55:43.360
about this quite a bit recently is how do you build or train a neural network say or deep learning

55:43.360 --> 55:48.720
system that in such a way that it can actually explain what's going on so it can explain why it makes

55:48.720 --> 55:56.720
a decision right right and you know so that's that's really important for for earning trust and so

55:56.720 --> 56:02.400
if we have a if we have a machine learning system that predicts that you you know woman should

56:03.600 --> 56:08.000
has a has a disease causing mutation in the context of say breast cancer in the system recommends

56:08.000 --> 56:12.800
a double mastectomy then you really do want the system to be reliable and trustworthy and be able

56:12.800 --> 56:17.840
to explain you know why why it made that decision why it made that provided that advice

56:19.280 --> 56:22.240
and so I think that's a really interesting area for machine learning you know I don't have the

56:22.240 --> 56:26.720
answer to to how we how we do that but people are working on that area and a lot more work needs to

56:26.720 --> 56:34.080
be done well so on that point I did do an interview with Carlos Gastrin not too long ago and

56:35.040 --> 56:39.360
our listeners might remember that one if you're interested in this issue of explainability check

56:39.360 --> 56:46.320
out that interview but traditionally if you can use traditionally when talking about deep neural

56:46.320 --> 56:51.440
networks I guess people you know when we're looking at machine learning models people look to

56:51.440 --> 56:58.240
other types of models and not deep neural networks because of this explainability challenge

56:58.800 --> 57:05.280
that is you know particularly acute with neural networks like do you see where do you see

57:05.280 --> 57:10.640
that going do you see light at the end of the tunnel yeah that's a good point and actually think

57:10.640 --> 57:18.000
that that belief is completely wrong-minded so so here's the traditional argument for why you

57:18.000 --> 57:23.760
should look at simple techniques like linear regression or random forests or something like that

57:25.200 --> 57:31.280
so the the argument goes like this to figure out an explanation for why machine learning system

57:31.280 --> 57:35.600
made its prediction what you do is you should look inside of the machine learning system you should

57:35.600 --> 57:41.200
look at the parameters okay so linear regression is really simple because for each input there's

57:41.200 --> 57:46.000
only one parameter connecting it to the output and so you can just look at that parameter and if it's

57:46.000 --> 57:49.680
positive it means that input has a positive impact on the output and if it's negative it has a

57:49.680 --> 57:55.360
negative impact and so that's that's the justification for looking at simple machine learning systems

57:55.360 --> 58:01.360
right okay now this is why I think that's completely wrong-minded if you if you turn to your

58:01.360 --> 58:07.360
friend and ask them why did you make the decision you just made you don't crack open their skull

58:07.360 --> 58:14.480
and look at their synapses to figure out the explanation that's not what you do and yet that's

58:14.480 --> 58:19.520
what the traditional argument is for why you should use simple machine learning systems you're

58:19.520 --> 58:23.840
going to look at the parameters and so therefore you need a simple system no you don't do that

58:23.840 --> 58:27.760
so what you do is you ask your friend to explain themselves well why did you make the decision

58:27.760 --> 58:33.840
you made so I think the future of machine learning is all about using complex deep neural nets

58:33.840 --> 58:37.760
but training them in such a way that they actually produce an explanation at the output

58:38.880 --> 58:43.680
so we don't crack them open and look at the parameters we we actually train the system so that the

58:43.680 --> 58:48.000
output of the neural network is an explanation as well as a decision does that make sense

58:48.720 --> 58:54.080
it does make sense so I'm thinking of the picture I have in my head is yeah we talked

58:54.080 --> 59:00.800
earlier about neural networks that are trained to produce multiple outputs and so in this case

59:00.800 --> 59:05.680
one of the outputs is the explanation and the other output is the you know the thing we're asking

59:05.680 --> 59:09.520
it to make a decision you got it you got it that's exactly right so you can think of this as a

59:09.520 --> 59:14.560
multitask training problem yeah where one output is the decision the other output is the explanation

59:14.560 --> 59:19.200
and so really I think that's that's the future of machine learning in terms of explanations

59:19.200 --> 59:23.440
and there are obviously some really challenging technical issues for for how we get that to work

59:23.440 --> 59:27.680
and it's not really working well yet but I think that is really where things where things will go

59:27.680 --> 59:34.320
in that regard and the other I guess the other observation I can make is is what's what I find really

59:34.320 --> 59:39.600
exciting about this area that deep genomics is working on is the kind of artificial intelligence we

59:39.600 --> 59:46.880
need and so if you look at some recent big successes like deep mines alphago or Google

59:47.520 --> 59:52.160
Google's results or Facebook so if you look at some of the really exciting results that have come

59:52.160 --> 59:59.040
out of those labs therefore things like games which humans invented or image recognition which

59:59.040 --> 01:00:04.320
humans have evolved to be good at or speech recognition which humans invented or evolved and

01:00:04.320 --> 01:00:08.720
or evolved now these are all tests that humans are good at whereas what I think is really

01:00:08.720 --> 01:00:13.840
exciting about genomic medicine is that the AI systems we build need to go beyond what humans

01:00:13.840 --> 01:00:19.120
are capable of so no human is it ever going to be capable of understanding genome or how to

01:00:19.120 --> 01:00:24.080
cure genetic disease or no group of humans will right it's so complex and so common tutorial

01:00:24.080 --> 01:00:32.960
and so really what we need is superhuman AI and so now it's making me think of this is making me

01:00:32.960 --> 01:00:37.920
think of a sci-fi book that I like by Octavia Butler I forget the name of the book but basically

01:00:37.920 --> 01:00:45.840
there are these race of aliens that come down to a north that's been you know kind of ravaged by

01:00:45.840 --> 01:00:54.000
you know disease and this gift that these this alien race has is to effectively repair genetic disorder

01:00:54.000 --> 01:01:00.880
what that has to do with AI who knows but you're also I mean there's some interesting things kind

01:01:00.880 --> 01:01:05.760
of switching the subject here there's also some interesting things happening up in Toronto right

01:01:07.600 --> 01:01:13.920
yeah yeah so you're asking what things happening in Toronto so I can't talk a lot about it right

01:01:13.920 --> 01:01:19.600
now but in the next couple weeks there's going to be an announcement for a new type of artificial

01:01:19.600 --> 01:01:26.320
intelligence institute in Toronto we have over 170 million dollars of funding for it and the

01:01:26.320 --> 01:01:37.920
ideas to build or rebuild the AI research capacity in Toronto and and ensure that we can use that

01:01:37.920 --> 01:01:44.640
capacity to to foster innovation in the startup community and another another bigger businesses

01:01:44.640 --> 01:01:49.280
in the in the area so yeah that should be announced in a few weeks and it should be really big

01:01:49.280 --> 01:01:55.040
big news for Toronto and I think big news for the AI community more broadly that's fantastic

01:01:55.040 --> 01:02:00.560
we'll definitely keep our eyes open for that and so before we go where can people learn more about

01:02:00.560 --> 01:02:07.600
what you're up to and keep tabs on you yeah so you can go to www.deepgenomics.com also just google

01:02:07.600 --> 01:02:13.360
me and we have various papers posted online there where you can for example a tutorial paper that

01:02:13.360 --> 01:02:18.000
describes the approach and and how you can use machine learning not just deep learning but just

01:02:18.000 --> 01:02:23.360
different kinds of machine learning techniques to to approach problems in genomic medicine also

01:02:23.360 --> 01:02:27.920
well Brendan thanks so much this was an amazing conversation I really appreciate you taking the

01:02:27.920 --> 01:02:37.840
time out you best sound it was a pleasure all right everyone that's our show for today a huge

01:02:37.840 --> 01:02:43.040
thanks to all you listeners out there I appreciate all of the notes and comments that you share be

01:02:43.040 --> 01:02:49.440
the mailing list sign up form the show notes pages be a Twitter iTunes and all the other channels

01:02:49.440 --> 01:02:55.040
that you use to share your love for the podcast and don't forget to visit our brand new Facebook

01:02:55.040 --> 01:03:00.640
page at facebook.com slash swimmol ai and give us a like and register for the strata

01:03:00.640 --> 01:03:07.840
Hadoop giveaway while you're there the notes for this show will be up at twimmol ai.com slash talk

01:03:07.840 --> 01:03:13.600
slash 12 and there you'll find links to all of the resources mentioned in the show thanks so

01:03:13.600 --> 01:03:25.360
much for listening and catch you next time

