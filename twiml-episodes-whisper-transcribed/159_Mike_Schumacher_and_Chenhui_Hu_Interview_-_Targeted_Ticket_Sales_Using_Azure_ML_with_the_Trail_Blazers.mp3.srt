1
00:00:00,000 --> 00:00:16,200
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,200 --> 00:00:21,320
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,320 --> 00:00:31,280
I'm your host Sam Charrington.

4
00:00:31,280 --> 00:00:36,080
In today's episode of our AI and sport series, I'm joined by Mike Schumacher, director

5
00:00:36,080 --> 00:00:43,280
of business analytics for the Portland Trailblazers and Chen Hui Hu, a data scientist at Microsoft.

6
00:00:43,280 --> 00:00:48,200
In our conversation, Mike Chen Hui and I discuss how the Blazers are using machine learning

7
00:00:48,200 --> 00:00:54,160
to produce better targeted sales campaigns for both single game and season ticket buyers.

8
00:00:54,160 --> 00:00:58,360
Mike describes some of the early use cases the Trailblazers explored in their drive to

9
00:00:58,360 --> 00:01:03,280
apply analytics and machine learning to the process of increasing ticket sales.

10
00:01:03,280 --> 00:01:08,240
And Chen Hui elaborates on some of the unique challenges of the Trailblazers data set

11
00:01:08,240 --> 00:01:12,000
and the modeling techniques the team apply to solve their problem.

12
00:01:12,000 --> 00:01:13,760
All right, let's do it.

13
00:01:13,760 --> 00:01:19,040
All right, everyone. I am on the line with a couple of guests that I've been looking

14
00:01:19,040 --> 00:01:20,720
forward to speaking with.

15
00:01:20,720 --> 00:01:26,840
I've got Mike Schumacher, who is director of business analytics with Portland Trailblazers,

16
00:01:26,840 --> 00:01:32,480
basketball team and Chen Hui Hu, who is a data scientist at Microsoft.

17
00:01:32,480 --> 00:01:35,920
Mike and Chen Hui, welcome to this weekend machine learning and AI.

18
00:01:35,920 --> 00:01:37,560
Hi, Sam. Thanks for having us.

19
00:01:37,560 --> 00:01:39,080
Yeah, thanks for having me.

20
00:01:39,080 --> 00:01:40,080
Absolutely.

21
00:01:40,080 --> 00:01:45,520
Why don't we, in the tradition of the podcast, get started by having the two of you introduce

22
00:01:45,520 --> 00:01:46,520
yourselves.

23
00:01:46,520 --> 00:01:51,000
Mike, how did you get involved in analytics and machine learning?

24
00:01:51,000 --> 00:01:54,000
Sure. So my career started in software development.

25
00:01:54,000 --> 00:01:58,640
I got my masters in enterprise software architecture and was an application developer

26
00:01:58,640 --> 00:02:01,640
for 12 years before coming to the Blazers.

27
00:02:01,640 --> 00:02:07,080
In those first few years before I made it to the Blazers, a lot of my work shifted from

28
00:02:07,080 --> 00:02:12,200
peer development over to data warehousing, business intelligence, data analysis, data

29
00:02:12,200 --> 00:02:13,560
vis, those types of things.

30
00:02:13,560 --> 00:02:17,760
And my first few years with the Blazers was heavily focused on data management, getting

31
00:02:17,760 --> 00:02:22,760
our data warehouse set up, marketing, automation, CRM.

32
00:02:22,760 --> 00:02:26,880
As our systems and processes became more sophisticated, we started looking into machine

33
00:02:26,880 --> 00:02:30,880
learning and more predictive analytics and that's kind of where we're at today.

34
00:02:30,880 --> 00:02:31,880
Okay, great.

35
00:02:31,880 --> 00:02:32,880
And Chen Hui.

36
00:02:32,880 --> 00:02:37,000
Hi, I'm a data scientist at Microsoft AI and the research in Boston.

37
00:02:37,000 --> 00:02:42,320
I joined Microsoft last year and my current interest is to solve prediction and optimization

38
00:02:42,320 --> 00:02:46,160
problems in retail, marketing, and manufacturing.

39
00:02:46,160 --> 00:02:51,520
Before that, I finished my PhD study, focusing on medical image data mining.

40
00:02:51,520 --> 00:02:53,360
That's pretty much my respect.

41
00:02:53,360 --> 00:02:54,360
Awesome.

42
00:02:54,360 --> 00:02:55,360
Awesome.

43
00:02:55,360 --> 00:03:01,680
So Mike, my producer who stays on top of these things tells me that a good place to start

44
00:03:01,680 --> 00:03:07,640
is to congratulate you for putting quite the smack down on the few suns on an opening night.

45
00:03:07,640 --> 00:03:12,960
Yeah, I did not see that coming, especially with one of our best players sitting in

46
00:03:12,960 --> 00:03:13,960
the game out.

47
00:03:13,960 --> 00:03:18,000
So that was unexpected, but a very pleasant surprise for sure.

48
00:03:18,000 --> 00:03:19,000
Absolutely.

49
00:03:19,000 --> 00:03:20,000
Absolutely.

50
00:03:20,000 --> 00:03:23,360
Why don't we get started by having you tell us a little bit about some of the applications

51
00:03:23,360 --> 00:03:32,280
for analytics at the Blazers and how that has grown to involve machine learning?

52
00:03:32,280 --> 00:03:33,280
Sure.

53
00:03:33,280 --> 00:03:38,680
Yeah, we spend a lot of time working with various departments across the organization.

54
00:03:38,680 --> 00:03:41,800
We're almost like the data police at times.

55
00:03:41,800 --> 00:03:45,120
There's a lot of data warehousing that we do.

56
00:03:45,120 --> 00:03:48,000
We have integrations between different systems.

57
00:03:48,000 --> 00:03:51,400
We help with any type of data analytics project.

58
00:03:51,400 --> 00:03:56,680
The department might need help them help them use data to make better business decisions.

59
00:03:56,680 --> 00:04:00,440
So that's kind of the basis of our group.

60
00:04:00,440 --> 00:04:06,560
We do a lot with CRM, marketing automation, a lot of one-off projects where we're presented

61
00:04:06,560 --> 00:04:11,800
with a problem and we go out and do the analysis to try to help make a decision on something.

62
00:04:11,800 --> 00:04:14,560
And so that's kind of where we started.

63
00:04:14,560 --> 00:04:19,560
And as our foundation has grown and we've been able to build out that foundation with

64
00:04:19,560 --> 00:04:24,120
the data warehouse, we've started to reach out into these other areas like the predictive

65
00:04:24,120 --> 00:04:25,760
analytics and the machine learning.

66
00:04:25,760 --> 00:04:30,000
And that's where we decided to partner with Microsoft who went over and did some use

67
00:04:30,000 --> 00:04:35,880
cases with them and they've turned out pretty successfully and so we've been moving in

68
00:04:35,880 --> 00:04:38,120
that direction.

69
00:04:38,120 --> 00:04:41,320
And how many people on the analytics team there?

70
00:04:41,320 --> 00:04:43,640
We have six on our analytics team right now.

71
00:04:43,640 --> 00:04:44,640
Okay.

72
00:04:44,640 --> 00:04:49,920
We get involved in both front office types of use cases as well as back office player

73
00:04:49,920 --> 00:04:51,800
analytics and that kind of thing.

74
00:04:51,800 --> 00:04:54,360
We have two sides of the business.

75
00:04:54,360 --> 00:04:57,000
Our team in particular focuses on the business side.

76
00:04:57,000 --> 00:05:02,160
There is also some basketball analytics, but our team isn't as involved with those.

77
00:05:02,160 --> 00:05:03,160
Okay.

78
00:05:03,160 --> 00:05:04,160
All right.

79
00:05:04,160 --> 00:05:05,160
Great.

80
00:05:05,160 --> 00:05:10,240
So maybe we can start out by having you walk through one of the early use cases for machine

81
00:05:10,240 --> 00:05:12,120
learning with the team.

82
00:05:12,120 --> 00:05:13,120
Sure.

83
00:05:13,120 --> 00:05:14,120
Yeah.

84
00:05:14,120 --> 00:05:21,080
So when we first talked to Microsoft, we looked at how things came from in the past.

85
00:05:21,080 --> 00:05:26,440
And so we used data in the past to run some of our sales campaigns.

86
00:05:26,440 --> 00:05:31,360
But a lot of times we didn't have all the data we would need to set the campaign up the

87
00:05:31,360 --> 00:05:32,720
way we would like to.

88
00:05:32,720 --> 00:05:38,440
And so what we wanted to do was we wanted to come to Microsoft, give them access to some

89
00:05:38,440 --> 00:05:44,240
of our ticketing data, some of our sales data, and ask them to help us identify patterns

90
00:05:44,240 --> 00:05:48,800
that would allow us to target people in the right way.

91
00:05:48,800 --> 00:05:53,880
So we have over 200,000 people that have purchased tickets in the past.

92
00:05:53,880 --> 00:05:58,200
And we can't reach out to every single one of them and give them a phone call and talk

93
00:05:58,200 --> 00:06:01,120
to them about if they'd be interested in coming out for another game.

94
00:06:01,120 --> 00:06:08,000
And so the idea was as we wanted to use the data to determine who would be best to talk

95
00:06:08,000 --> 00:06:12,760
to, who else might be best just to be reached out to be an email or some sort of marketing

96
00:06:12,760 --> 00:06:14,240
and automation campaign.

97
00:06:14,240 --> 00:06:17,160
And so that's kind of the use case that we went to them with.

98
00:06:17,160 --> 00:06:25,520
So you do have folks that are actively outbound dialing out to pass ticket purchasers to try

99
00:06:25,520 --> 00:06:29,840
to get them to buy tickets for an upcoming game via the phone.

100
00:06:29,840 --> 00:06:30,840
Yes, absolutely.

101
00:06:30,840 --> 00:06:34,320
We have a sales team that's that's working with new customers.

102
00:06:34,320 --> 00:06:39,960
We also have a service team that that nurtures the season ticket holders and helps them maintain

103
00:06:39,960 --> 00:06:42,880
relationship with those pongoing buyers.

104
00:06:42,880 --> 00:06:43,880
Okay.

105
00:06:43,880 --> 00:06:49,080
And so what were some of the first steps in tackling this challenge, which is ultimately,

106
00:06:49,080 --> 00:06:51,960
ultimately it sounds like trying to sell more tickets?

107
00:06:51,960 --> 00:06:52,960
Yeah.

108
00:06:52,960 --> 00:06:58,600
The tactic that we went with was we wanted to make the data points that we had available

109
00:06:58,600 --> 00:07:03,800
that we thought were predictive in understanding who would be interested in buying tickets

110
00:07:03,800 --> 00:07:09,560
again, make that available to Microsoft, try to kind of stay hands off with in terms

111
00:07:09,560 --> 00:07:15,600
of our bias, not necessarily bias, but our history of what we thought was the type of

112
00:07:15,600 --> 00:07:20,120
person we should be targeting and give them that data, allow the machine learning to look

113
00:07:20,120 --> 00:07:25,880
at all the different data points and how they interact and help us essentially score

114
00:07:25,880 --> 00:07:31,120
the customers and identify who would be a potential customer again.

115
00:07:31,120 --> 00:07:38,680
Okay. So Chen, when you, when this project kind of landed on your desk, how did you approach

116
00:07:38,680 --> 00:07:40,840
it from the Microsoft perspective?

117
00:07:40,840 --> 00:07:44,640
So I joined this project, I think in the second phase.

118
00:07:44,640 --> 00:07:50,960
So initially, my colleague has been working with shareholders on two different use cases.

119
00:07:50,960 --> 00:07:55,200
One targeting at predicting the seasonal ticket sales.

120
00:07:55,200 --> 00:08:00,160
The other is targeting the Singletic game ticket sales prediction.

121
00:08:00,160 --> 00:08:06,040
And I imported the first use case to a new environment called Azure Mission Learning

122
00:08:06,040 --> 00:08:11,960
Workbench, which allows data scientists to do a lot of data preparation and divide

123
00:08:11,960 --> 00:08:17,680
up models, experiments and then deploying them at cloud scale very conveniently.

124
00:08:17,680 --> 00:08:22,960
So we kind of like improved our original work in this new environment and then made a

125
00:08:22,960 --> 00:08:27,800
demo in the ignite conference this September.

126
00:08:27,800 --> 00:08:33,320
And so was that primarily for the first use case or the second or did you have the

127
00:08:33,320 --> 00:08:35,760
same couple of steps with both use cases?

128
00:08:35,760 --> 00:08:39,880
For now, we only imported the first use case, but yeah, if time permitted, we can also

129
00:08:39,880 --> 00:08:42,000
do the same thing for the second one.

130
00:08:42,000 --> 00:08:43,000
Oh, okay.

131
00:08:43,000 --> 00:08:48,520
And so what were some of the early findings with that first use case?

132
00:08:48,520 --> 00:08:56,040
Did you find that there are any unique challenges associated with either the problem or the

133
00:08:56,040 --> 00:08:59,200
data set that the blazers brought you?

134
00:08:59,200 --> 00:09:00,200
Of course.

135
00:09:00,200 --> 00:09:05,760
Yeah, I think there are two at least two unique challenges in this project.

136
00:09:05,760 --> 00:09:11,760
First of all, we need to combine different data sources to profile each customer.

137
00:09:11,760 --> 00:09:19,920
For example, we have data from charbracers describing the demographic information, customer

138
00:09:19,920 --> 00:09:27,440
status, customer interest, purchase and patterns, attendance information and even team preferences.

139
00:09:27,440 --> 00:09:33,560
And then on the other side, we have the third party data from axel, which pretty much

140
00:09:33,560 --> 00:09:38,960
tells about the lifestyle interest, broader interest of each customer.

141
00:09:38,960 --> 00:09:45,320
And then we need to also process those data in a Azure data SQL database.

142
00:09:45,320 --> 00:09:51,720
And then we need to combine the data processing step with the model development step in the

143
00:09:51,720 --> 00:09:57,600
new environment and so the so called adrup email workbench environment.

144
00:09:57,600 --> 00:10:04,240
And then the second challenge is the process of develop the machine learning model.

145
00:10:04,240 --> 00:10:09,880
And then to come up the best machine learning model for prediction, essentially, I think

146
00:10:09,880 --> 00:10:15,480
the simplest way is just to share a bunch of models and then tune the hyperparameters,

147
00:10:15,480 --> 00:10:21,800
but it turns out pretty challenging to to log the history of all the experiments.

148
00:10:21,800 --> 00:10:28,000
But thanks to the new environment we have in the Azure Azure machine and workbench, we

149
00:10:28,000 --> 00:10:35,640
are able to log all the hyperparameters performance metrics very easily and then visualize them

150
00:10:35,640 --> 00:10:38,120
easily pick the best model.

151
00:10:38,120 --> 00:10:43,440
Okay, now that's a topic that we've covered on the podcast, quite a bit of late, various

152
00:10:43,440 --> 00:10:46,120
approaches to hyperparameter optimization.

153
00:10:46,120 --> 00:10:53,000
It sounds like what you're describing is some kind of inherent features within the

154
00:10:53,000 --> 00:10:59,240
Azure ML platform that allow you to track kind of different runs with different sets of

155
00:10:59,240 --> 00:11:03,120
hyperparameters, like what exactly are you doing there?

156
00:11:03,120 --> 00:11:11,600
So essentially in the Azure ML workbench, you can write like a Python script, for example,

157
00:11:11,600 --> 00:11:16,520
and then chain the machine learning model with different hyperparameters.

158
00:11:16,520 --> 00:11:25,360
And it allows you to also log the parameters that you are using and the performance metrics

159
00:11:25,360 --> 00:11:29,640
that you end up to have in this model.

160
00:11:29,640 --> 00:11:35,400
And then if you later change another set of hyperparameters, you can easily see how the

161
00:11:35,400 --> 00:11:38,960
hyperparameter is impacting the performance metrics.

162
00:11:38,960 --> 00:11:44,960
It will automatically generate a set of graphs telling you the impact of hyperparameters

163
00:11:44,960 --> 00:11:48,080
on each of your performance metrics.

164
00:11:48,080 --> 00:11:54,680
So does it end up being like a sensitivity analysis or is it more maybe more manual than

165
00:11:54,680 --> 00:11:56,240
that?

166
00:11:56,240 --> 00:12:03,440
So it's the original goal is like to provide you a purely automatic way to select the model.

167
00:12:03,440 --> 00:12:06,840
But of course, this is a pretty challenging.

168
00:12:06,840 --> 00:12:13,080
So now we have, I think it's kind of semi-automatic way because you can write another script

169
00:12:13,080 --> 00:12:18,600
just to do a parameter suite, meaning that you try different combinations of parameters

170
00:12:18,600 --> 00:12:21,160
and then just run a for loop.

171
00:12:21,160 --> 00:12:27,320
And after running this for loop, you end up with the curve that I just described, describe

172
00:12:27,320 --> 00:12:31,320
your like the impact of the hyperparameters.

173
00:12:31,320 --> 00:12:37,720
And then, ideally, you can also write another script to pick the optimal model based on

174
00:12:37,720 --> 00:12:39,200
certain criteria.

175
00:12:39,200 --> 00:12:44,600
OK, so it sounds like it's giving you some kind of facility to implement your own grid

176
00:12:44,600 --> 00:12:47,520
search of the hyperparameter space.

177
00:12:47,520 --> 00:12:53,120
What types of models, like what did you learn about the models themselves for this type

178
00:12:53,120 --> 00:12:55,360
of problem?

179
00:12:55,360 --> 00:12:58,600
And you know, were there any surprising findings there?

180
00:12:58,600 --> 00:13:03,880
And yeah, so we basically tried many standard classification models.

181
00:13:03,880 --> 00:13:09,960
For example, support vector machine logistic regression and boost decision tree random

182
00:13:09,960 --> 00:13:11,440
forest model.

183
00:13:11,440 --> 00:13:20,680
So first of all, almost all the models perform very almost the same in terms of the accuracy.

184
00:13:20,680 --> 00:13:24,880
But the boost decision tree model is slightly better.

185
00:13:24,880 --> 00:13:31,040
And in terms of the accuracy and precision recall, we end up with very high number, something

186
00:13:31,040 --> 00:13:36,440
around like 0.98 in our testing experiments.

187
00:13:36,440 --> 00:13:40,360
So that's pretty amazing to me at the first time.

188
00:13:40,360 --> 00:13:45,760
And then some other findings also are pretty interesting.

189
00:13:45,760 --> 00:13:53,520
For example, if we are targeting the prediction of seasonal ticket purchase, the information

190
00:13:53,520 --> 00:14:00,080
about historical ticket purchase in patent, like whether a customer is a single game ticket

191
00:14:00,080 --> 00:14:03,800
purchaser, it's very important for the prediction.

192
00:14:03,800 --> 00:14:09,000
And I think also the amount of money that the customer has spent in the last season is

193
00:14:09,000 --> 00:14:18,000
also a strong indicator, apart from that, the income or the occupation of the customer

194
00:14:18,000 --> 00:14:24,560
can also tell us a lot because the seasonal ticket is sort of expensive.

195
00:14:24,560 --> 00:14:31,200
Then people who has high income may tend to keep purchasing this seasonal ticket.

196
00:14:31,200 --> 00:14:36,560
Those all strike me as fairly intuitive findings.

197
00:14:36,560 --> 00:14:42,000
Like was there any surprises in the results that you got back from Microsoft?

198
00:14:42,000 --> 00:14:47,160
Yeah, I'd say that there were certainly ones that were intuitive.

199
00:14:47,160 --> 00:14:54,040
There were ones that jumped out to us like specific games or specific sets of numbers of

200
00:14:54,040 --> 00:14:56,640
games that a person has attended in the past.

201
00:14:56,640 --> 00:15:01,160
It was, you know, it's different combinations of those variables that we hadn't looked

202
00:15:01,160 --> 00:15:02,160
at before.

203
00:15:02,160 --> 00:15:06,520
A lot of times we're looking at something very specific like this person purchased,

204
00:15:06,520 --> 00:15:08,440
you know, five games in the past.

205
00:15:08,440 --> 00:15:13,640
So there's someone that's very likely to want to come back to a game the following year.

206
00:15:13,640 --> 00:15:16,640
There was just this combination of all these different data points.

207
00:15:16,640 --> 00:15:21,600
And then in one of the other use cases we looked at the Axiom data, so like the demographic

208
00:15:21,600 --> 00:15:28,200
psychographic lifestyle data that Axiom provided, data points that we'd never had before.

209
00:15:28,200 --> 00:15:32,480
Some of them that are obvious like watching particular sports channels or are those

210
00:15:32,480 --> 00:15:37,640
types of things actually were also predictive in the likelihood of someone purchasing.

211
00:15:37,640 --> 00:15:41,520
And so it was, it was pretty cool to see, you know, all these different data points

212
00:15:41,520 --> 00:15:43,560
at how they interacted.

213
00:15:43,560 --> 00:15:48,720
Can you give an example of the, you know, counterintuitive combination that you saw?

214
00:15:48,720 --> 00:15:55,160
Yeah, for example, there was one like there was a, and I'm not sure why, but anyone that

215
00:15:55,160 --> 00:16:02,480
had been to a Minnesota Timberwolves game and had a credit card, or sorry, a loan that

216
00:16:02,480 --> 00:16:07,560
wasn't a credit card was also, there was a significantly higher likelihood that they

217
00:16:07,560 --> 00:16:09,560
would purchase tickets again.

218
00:16:09,560 --> 00:16:13,200
Something that belonged that wasn't a credit, so there was something totally out of left

219
00:16:13,200 --> 00:16:18,640
field that yeah, I'm not have expected all really interesting, yeah, definitely.

220
00:16:18,640 --> 00:16:23,920
And so how, how have you used the, you know, the results of this work is this kind of

221
00:16:23,920 --> 00:16:30,280
running in production, or how have you integrated into your selling and marketing workflows?

222
00:16:30,280 --> 00:16:34,400
Yeah, for us, it's been kind of, we've been trying to prove out the software, I guess

223
00:16:34,400 --> 00:16:35,400
you could say.

224
00:16:35,400 --> 00:16:39,160
So we've just been getting into the machine learning and predictive analytics.

225
00:16:39,160 --> 00:16:43,080
And so what we wanted to do is run through a couple of use cases that we could actually

226
00:16:43,080 --> 00:16:47,080
measure the results to see if this is the tool we wanted to go with.

227
00:16:47,080 --> 00:16:52,320
And for like the first use case we went through, normally on our sales campaigns will

228
00:16:52,320 --> 00:16:56,400
convert it about 5% of the leads that we contact.

229
00:16:56,400 --> 00:17:01,640
In this particular case, we converted it to 25% and they were purchasing season tickets

230
00:17:01,640 --> 00:17:02,640
in general.

231
00:17:02,640 --> 00:17:05,680
So, you know, very substantial.

232
00:17:05,680 --> 00:17:10,880
We went through and did the second use case and looked at like what's the likelihood

233
00:17:10,880 --> 00:17:14,520
of a single game buyer coming back the following season.

234
00:17:14,520 --> 00:17:19,760
And in general, we get about 16% of our single game buyers back each year for various different

235
00:17:19,760 --> 00:17:24,040
reasons with the models that Microsoft helped us develop.

236
00:17:24,040 --> 00:17:31,600
We were able to identify them at a 30% rate versus a 10% rate of those that weren't coming

237
00:17:31,600 --> 00:17:32,600
back.

238
00:17:32,600 --> 00:17:34,840
And so they were definitely useful.

239
00:17:34,840 --> 00:17:39,320
Can you explain that last point again, like you were taking the model and then using

240
00:17:39,320 --> 00:17:46,600
that to target your outbound calls and you were able to increase the rate, the return

241
00:17:46,600 --> 00:17:51,160
rate for those people that you wouldn't have otherwise or for that group of people?

242
00:17:51,160 --> 00:17:57,320
Well, we weren't able to, we didn't change the rate at which we were converting them.

243
00:17:57,320 --> 00:18:02,080
With our single game buyers, we'll have about 15 to 20,000 people each year that are individual

244
00:18:02,080 --> 00:18:03,600
game buyers.

245
00:18:03,600 --> 00:18:08,920
With the models we wanted to use, we wanted to look at and see who was likely to come

246
00:18:08,920 --> 00:18:09,920
back.

247
00:18:09,920 --> 00:18:13,600
And so Microsoft went through and identified, you know, we identified the top 10%.

248
00:18:13,600 --> 00:18:17,920
We said, these are the people that are going to come back and of that 30% actually came

249
00:18:17,920 --> 00:18:18,920
back.

250
00:18:18,920 --> 00:18:24,240
Whereas the rest of the group that was identified as unlikely to come back, only 10% came

251
00:18:24,240 --> 00:18:25,240
back.

252
00:18:25,240 --> 00:18:30,160
So it was essentially was showing us that the model was able to identify these people, the

253
00:18:30,160 --> 00:18:35,240
people that we were looking for a lot better than our other, the other ways that we were

254
00:18:35,240 --> 00:18:36,240
doing this.

255
00:18:36,240 --> 00:18:40,960
And so in terms of like using that for the future, we, our, our eventual goal is to get

256
00:18:40,960 --> 00:18:45,680
into like a fully automated system where a customer or a fan comes to us, they opt into

257
00:18:45,680 --> 00:18:51,680
us either through a previous purchase, they sign up for some sort of sweepstakes, they

258
00:18:51,680 --> 00:18:54,240
join an email mailing list or something.

259
00:18:54,240 --> 00:18:58,440
And essentially, we'd like to be able to pipe them through the models, have them scored

260
00:18:58,440 --> 00:19:01,200
and then determine, you know, what's the best way to work with them?

261
00:19:01,200 --> 00:19:04,640
Do we want to get them into some sort of email drip campaign where we, you know, send

262
00:19:04,640 --> 00:19:07,480
them newsletters and we near term along that way?

263
00:19:07,480 --> 00:19:11,960
Should we be sending them sales marketing, should we be putting them in a call campaign and

264
00:19:11,960 --> 00:19:13,360
having a sales rep talk to them?

265
00:19:13,360 --> 00:19:18,200
And so essentially, we'd like to have it to a fully automated system, but we're still

266
00:19:18,200 --> 00:19:23,720
in the early stages just trying to, to make sure that the tool works way we wanted to.

267
00:19:23,720 --> 00:19:29,680
And now Azure, Azure ML is kind of a developer tool.

268
00:19:29,680 --> 00:19:35,520
How do you envision using that in the context of your various business processes?

269
00:19:35,520 --> 00:19:40,680
Would you be developing custom applications around it or using some interface where you

270
00:19:40,680 --> 00:19:42,320
can run reports against it?

271
00:19:42,320 --> 00:19:44,160
Have you thought that far about it?

272
00:19:44,160 --> 00:19:45,160
Yep.

273
00:19:45,160 --> 00:19:46,160
Yeah.

274
00:19:46,160 --> 00:19:47,160
So on my team, we have an application developer.

275
00:19:47,160 --> 00:19:49,040
We have a couple of analysts.

276
00:19:49,040 --> 00:19:55,560
We also have people that are focused on CRM and on the marketing and automation side.

277
00:19:55,560 --> 00:19:59,280
And the nice thing is is they play really well with Microsoft.

278
00:19:59,280 --> 00:20:05,400
And so essentially, we have the in house capabilities to be able to load the data into

279
00:20:05,400 --> 00:20:06,400
the models.

280
00:20:06,400 --> 00:20:12,800
And with Azure ML, you essentially get like a web service endpoint with the results.

281
00:20:12,800 --> 00:20:17,720
And so the idea there would be we would hook up some more ETL and then pipe that data

282
00:20:17,720 --> 00:20:21,480
over into our marketing automation system or over into CRM.

283
00:20:21,480 --> 00:20:26,960
And then from there, use the automations within those systems to move forward with the

284
00:20:26,960 --> 00:20:28,520
records.

285
00:20:28,520 --> 00:20:30,480
And then where do you see this going?

286
00:20:30,480 --> 00:20:35,320
What are some of the other use cases that you've got in mind for this?

287
00:20:35,320 --> 00:20:36,320
Yeah.

288
00:20:36,320 --> 00:20:40,960
Aside from like the fully automated scoring system, we're looking at other things.

289
00:20:40,960 --> 00:20:44,640
There's some built-in text analysis that we want to get into.

290
00:20:44,640 --> 00:20:45,960
We get survey data.

291
00:20:45,960 --> 00:20:49,800
We'd like to be able to make that survey data more actionable.

292
00:20:49,800 --> 00:20:56,200
Be able to look at the sentiment of the customer and be able to track that over time.

293
00:20:56,200 --> 00:20:59,880
We'd also like to look at some things like help, help on other projects that we look

294
00:20:59,880 --> 00:21:00,880
at each year.

295
00:21:00,880 --> 00:21:04,320
So one in particular is what we call our drop count model.

296
00:21:04,320 --> 00:21:10,720
And that's essentially how many people come to any given game for various reasons, whether

297
00:21:10,720 --> 00:21:17,320
it's for staffing or for just understanding what the sales might be for that game.

298
00:21:17,320 --> 00:21:22,520
Being able to model that out with this system rather than what we have been using in the

299
00:21:22,520 --> 00:21:23,520
past.

300
00:21:23,520 --> 00:21:26,520
And so there's a variety of different things that we want to get into.

301
00:21:26,520 --> 00:21:31,640
Some automated and some just one-off situations where we want to use the algorithms to be able

302
00:21:31,640 --> 00:21:33,680
to get us more efficient.

303
00:21:33,680 --> 00:21:35,880
And so you ran a couple of use cases.

304
00:21:35,880 --> 00:21:38,280
You got some promising early results.

305
00:21:38,280 --> 00:21:44,880
You're still kind of in advance of having this fully integrated into the way you do business.

306
00:21:44,880 --> 00:21:52,160
What are some of the barriers or impediments that keep you from kind of being all-in already?

307
00:21:52,160 --> 00:21:57,160
Time and workload, I guess, which I'm sure you'll hear from a lot of people.

308
00:21:57,160 --> 00:21:58,160
Uh-huh.

309
00:21:58,160 --> 00:22:03,360
No, we got a lot of great resources, but there's a lot of other responsibilities going

310
00:22:03,360 --> 00:22:04,360
on.

311
00:22:04,360 --> 00:22:07,560
So it's just getting that time to be able to work with it.

312
00:22:07,560 --> 00:22:11,840
System integrations have come a long way over time, but there's still development that

313
00:22:11,840 --> 00:22:14,960
needs to be set up to integrate between systems.

314
00:22:14,960 --> 00:22:18,400
So we're working with a couple of Microsoft products.

315
00:22:18,400 --> 00:22:23,280
We're using Tableau for our data visualization, our marketing automation tools, and other

316
00:22:23,280 --> 00:22:24,280
system as well.

317
00:22:24,280 --> 00:22:28,440
So there's a lot of integrations that need to be set up.

318
00:22:28,440 --> 00:22:33,960
And then, again, just identifying where we can get the most bang for our buck and the

319
00:22:33,960 --> 00:22:38,520
time that we do set up for the development because there's a lot of projects that this

320
00:22:38,520 --> 00:22:45,080
could be worked on or could be used on, but finding the one that would be most useful is

321
00:22:45,080 --> 00:22:47,240
also another challenge.

322
00:22:47,240 --> 00:22:48,240
Right.

323
00:22:48,240 --> 00:22:57,240
For some of the future use cases, do you envision having Microsoft like similarly do some

324
00:22:57,240 --> 00:23:04,920
of the data science pieces of it, the model development, or are you building capacity within

325
00:23:04,920 --> 00:23:07,320
the trouble lasers to do that kind of work?

326
00:23:07,320 --> 00:23:09,600
And where are you on that maturity curve?

327
00:23:09,600 --> 00:23:10,600
Yeah.

328
00:23:10,600 --> 00:23:11,600
Well, both.

329
00:23:11,600 --> 00:23:14,960
We want to continue our partnership with Microsoft because they've been great to work

330
00:23:14,960 --> 00:23:18,240
with, but we are building the capacity internally.

331
00:23:18,240 --> 00:23:20,080
I have some great people on my team.

332
00:23:20,080 --> 00:23:24,160
A couple people in particular are ramping up on this.

333
00:23:24,160 --> 00:23:29,920
We have an application developer that is very well versed in the integrations with different

334
00:23:29,920 --> 00:23:32,200
Microsoft systems.

335
00:23:32,200 --> 00:23:34,760
He manages our CRM system, which is also Microsoft.

336
00:23:34,760 --> 00:23:36,960
And so we have a good set up there.

337
00:23:36,960 --> 00:23:41,680
I have an analyst on my team that she's been spending countless hours just going through

338
00:23:41,680 --> 00:23:44,200
all the training and all the tutorials we've had.

339
00:23:44,200 --> 00:23:47,560
People come out and so just building up that internally.

340
00:23:47,560 --> 00:23:51,200
I'd say we're still in the early phases and that's probably probably why it's taken

341
00:23:51,200 --> 00:23:54,360
us a little bit longer to get there because we don't have a full-blown data scientist on

342
00:23:54,360 --> 00:23:55,360
our team.

343
00:23:55,360 --> 00:23:58,920
But we're certainly working on building that out internally while we continue to work

344
00:23:58,920 --> 00:24:00,440
with Microsoft.

345
00:24:00,440 --> 00:24:06,200
Is there a particular skill set that you can identify that's still lacking?

346
00:24:06,200 --> 00:24:08,000
No, not so much.

347
00:24:08,000 --> 00:24:14,160
I mean, it's essentially just getting used to the tool, getting used to how it works, understanding

348
00:24:14,160 --> 00:24:15,920
the different algorithms.

349
00:24:15,920 --> 00:24:19,320
There's a lot of different ways that things can be done and just gaining that maturity

350
00:24:19,320 --> 00:24:23,080
and experience in the data science type areas.

351
00:24:23,080 --> 00:24:24,080
Right.

352
00:24:24,080 --> 00:24:25,080
All right.

353
00:24:25,080 --> 00:24:26,080
Now, Chen, we have a question for you.

354
00:24:26,080 --> 00:24:35,800
I've looked at Azure ML Studio in the past and it can be, I think of the various cloud-based

355
00:24:35,800 --> 00:24:37,320
approaches to data science.

356
00:24:37,320 --> 00:24:44,000
I think it has an advantage in being pretty approachable because you can do a lot of gooey,

357
00:24:44,000 --> 00:24:45,200
almost whizzy wig.

358
00:24:45,200 --> 00:24:47,840
The type of thing that I think a lot of people expect from Microsoft.

359
00:24:47,840 --> 00:24:53,080
But it's also often developers and data scientists don't really like that kind of thing.

360
00:24:53,080 --> 00:24:59,840
It gets in their way and I'm wondering for you as a data scientist that has deep knowledge

361
00:24:59,840 --> 00:25:04,200
of this tool, how do you approach problems?

362
00:25:04,200 --> 00:25:11,120
Do you approach them within that gooey construct that is the default for Azure ML or are there

363
00:25:11,120 --> 00:25:14,600
other ways that you use the tools?

364
00:25:14,600 --> 00:25:15,880
We're a great question.

365
00:25:15,880 --> 00:25:21,200
So actually I have been using Azure Mission Learning Studio for about a year.

366
00:25:21,200 --> 00:25:25,440
So indeed, we have both pros and cons for this product.

367
00:25:25,440 --> 00:25:30,200
I think it's a great tool for entry-level data scientists because as you mentioned, they

368
00:25:30,200 --> 00:25:37,600
are like gooey and you can jack and jaw on the plan and then you can construct a mission

369
00:25:37,600 --> 00:25:40,200
learning experiment very quickly.

370
00:25:40,200 --> 00:25:44,280
And then also you can deploy it as a web service.

371
00:25:44,280 --> 00:25:50,160
But in the meantime, for senior data scientists, they may want to have more flexibility to

372
00:25:50,160 --> 00:25:57,360
control the machine learning model and also maybe do more complex data preparation steps.

373
00:25:57,360 --> 00:26:02,440
So that's why recently Microsoft launched a new tool called Azure Mission Learning

374
00:26:02,440 --> 00:26:06,680
Workbench, which is primarily for senior data scientists.

375
00:26:06,680 --> 00:26:13,760
Again, to end data science and advanced analytics solution for data scientists to like

376
00:26:13,760 --> 00:26:18,720
prepare data, develop experiments and deploy models at the cloud scale.

377
00:26:18,720 --> 00:26:24,640
But it also allows you to do a lot of things like without using the gooey.

378
00:26:24,640 --> 00:26:32,720
You can write everything basically using a Python script or develop the model, compare

379
00:26:32,720 --> 00:26:38,720
the model within the Azure ML Workbench and then you can also deploy it on different

380
00:26:38,720 --> 00:26:39,720
sources.

381
00:26:39,720 --> 00:26:43,800
And so is the user experience there?

382
00:26:43,800 --> 00:26:48,240
Does it offer kind of the notebook paradigm that's becoming pretty popular for this kind

383
00:26:48,240 --> 00:26:49,240
of thing?

384
00:26:49,240 --> 00:26:54,520
Or is it more at the command line and code level?

385
00:26:54,520 --> 00:26:56,520
Yeah, we have both actually.

386
00:26:56,520 --> 00:27:01,880
So first of all, if you are familiar with I-Python notebook, you can directly jump in to

387
00:27:01,880 --> 00:27:05,280
use that in the Workbench environment.

388
00:27:05,280 --> 00:27:13,040
If you are more familiar with Python script or command line environment, you can develop

389
00:27:13,040 --> 00:27:17,280
a Python script and that script through the command line environment.

390
00:27:17,280 --> 00:27:22,960
And more importantly, you can also deploy a machine learning model either on a local machine

391
00:27:22,960 --> 00:27:29,400
or on a cloud cluster through the command line interface.

392
00:27:29,400 --> 00:27:36,400
And one of the things that the ML Studio does for you is that it's kind of operating

393
00:27:36,400 --> 00:27:39,880
at this higher level of abstraction where you've got these building blocks for different

394
00:27:39,880 --> 00:27:48,280
types of models like you can drag and drop a random forest block model, for example.

395
00:27:48,280 --> 00:27:50,320
And then kind of wire it up with your data.

396
00:27:50,320 --> 00:27:57,120
Are you, do you have access to the same kinds of things in the Workbench?

397
00:27:57,120 --> 00:28:06,000
Or are you rather shifting to kind of your full native Python and scikit-learn and

398
00:28:06,000 --> 00:28:10,000
the kind of traditional Python ecosystem tools?

399
00:28:10,000 --> 00:28:17,960
So at this moment, we are kind of shifting towards the Python, IPython notebook, scikit-learn

400
00:28:17,960 --> 00:28:22,760
or kinds of tools instead of like again providing the GUI.

401
00:28:22,760 --> 00:28:27,280
So we talked about some of the kind of pros and cons of that tool set in general.

402
00:28:27,280 --> 00:28:36,080
Were there any challenges or places where you ran into kind of hit a wall or had to change

403
00:28:36,080 --> 00:28:43,480
your strategy with regard to which tools you used in solving the specific use cases

404
00:28:43,480 --> 00:28:46,640
that you worked on for the trouble users?

405
00:28:46,640 --> 00:28:53,120
So for this use case, I would say because we are not trying to analyze a huge worry

406
00:28:53,120 --> 00:28:58,200
about data and then also deploy it like, for example, Spark as a machine learning model

407
00:28:58,200 --> 00:29:06,400
on Spark, the data size is pretty, so far it's not, it's pretty small.

408
00:29:06,400 --> 00:29:14,760
So we can do the model development work both on EdgeML studio and EdgeML bench.

409
00:29:14,760 --> 00:29:23,760
So the primarily goal of improving our work in the new environment is to try to demonstrate

410
00:29:23,760 --> 00:29:29,320
the new capabilities of this EdgeML work bench.

411
00:29:29,320 --> 00:29:30,320
Okay.

412
00:29:30,320 --> 00:29:36,400
Okay, so you were able to do the things you needed to do with studio work bench is something

413
00:29:36,400 --> 00:29:41,800
that you'd go to if you wanted to scale it up or in terms of the data or wanted to

414
00:29:41,800 --> 00:29:49,120
deploy it out to Spark and you may deploy some use cases there just to kind of show them

415
00:29:49,120 --> 00:29:51,920
this new platform and how it compares to the original.

416
00:29:51,920 --> 00:29:57,360
Yeah, I would say the primary goal is to showcase, but also we want to work with chair

417
00:29:57,360 --> 00:30:05,120
brazers in case they want to move towards the new environment so that we can help them

418
00:30:05,120 --> 00:30:10,000
understand how to land on the new EdgeML work bench.

419
00:30:10,000 --> 00:30:15,160
And this question might be a little bit inside basketball, I guess.

420
00:30:15,160 --> 00:30:21,080
This is for Chen Wei, are you with the data scientist title, are you in a consulting organization

421
00:30:21,080 --> 00:30:27,480
with Microsoft or are you aligned with a product organization and just working with this

422
00:30:27,480 --> 00:30:33,880
particular customer because of their profile or how did you get involved in working on

423
00:30:33,880 --> 00:30:34,880
this project?

424
00:30:34,880 --> 00:30:35,880
Okay.

425
00:30:35,880 --> 00:30:42,560
So for my organization, originally, I think we are more tied to the product team, which

426
00:30:42,560 --> 00:30:46,240
is called Azure Mission Learning as you may know already.

427
00:30:46,240 --> 00:30:53,880
So we are actually the Azure data science team under the Microsoft AI and the research.

428
00:30:53,880 --> 00:31:01,440
So right now, this I think intersection between both the product team and the research team

429
00:31:01,440 --> 00:31:02,440
in Microsoft.

430
00:31:02,440 --> 00:31:09,200
So essentially, we want to bring the advanced research results to the product team so that

431
00:31:09,200 --> 00:31:13,040
we can develop like machine learning products based on those algorithms.

432
00:31:13,040 --> 00:31:16,120
So that's where we came.

433
00:31:16,120 --> 00:31:21,360
So we will try to stand in the middle and then try to understand both the research results

434
00:31:21,360 --> 00:31:25,840
and also the need for the customer about the product.

435
00:31:25,840 --> 00:31:31,520
And are there any research results that you can see playing a role in the types of problems

436
00:31:31,520 --> 00:31:34,560
that the trailblazers are dealing with?

437
00:31:34,560 --> 00:31:42,800
So for me, I'm pretty interested in like reinforcement learning and deep learning as well.

438
00:31:42,800 --> 00:31:47,600
So I was thinking about two different use cases.

439
00:31:47,600 --> 00:31:54,720
For example, if we have like a really large amount data, say like millions of billions

440
00:31:54,720 --> 00:31:59,720
of records, then we may try to build a model with machine with deep learning.

441
00:31:59,720 --> 00:32:05,400
So now because of the the goal original was trying to prove a concept.

442
00:32:05,400 --> 00:32:09,840
So we did not like use, I think a large volume of data.

443
00:32:09,840 --> 00:32:13,800
But later, yeah, if that's the case, we can try deep learning.

444
00:32:13,800 --> 00:32:21,000
And then another use case I was thinking about is to use reinforcement learning to learn

445
00:32:21,000 --> 00:32:28,720
the behavior of the customers and then try to send them offers which may sound more

446
00:32:28,720 --> 00:32:30,160
attractive to them.

447
00:32:30,160 --> 00:32:32,520
Can you walk us through how that might work?

448
00:32:32,520 --> 00:32:38,040
So this is again, so that's based on my intuition.

449
00:32:38,040 --> 00:32:42,560
It's not like a very mature idea being discussed with trailblazers.

450
00:32:42,560 --> 00:32:48,600
But for me, I think if we want to like a sale ticket to our customer, the first step

451
00:32:48,600 --> 00:32:53,160
is to predict whether the customer is willing to buy it or not.

452
00:32:53,160 --> 00:32:57,640
And then the second step maybe is to determine the best price, right?

453
00:32:57,640 --> 00:33:05,040
So in that sense, maybe we need to dynamic change the price according to certain criteria.

454
00:33:05,040 --> 00:33:14,000
For example, if there are other competitors like MBA teams offering the same discount

455
00:33:14,000 --> 00:33:19,680
to your customer, and then you may offer like at least the same discount, right?

456
00:33:19,680 --> 00:33:28,120
So a lot of factors may play a lure in this kind of price optimization use case.

457
00:33:28,120 --> 00:33:35,720
So I think again, machine learning such as reinforcement learning can be a good tool

458
00:33:35,720 --> 00:33:38,360
for solving such complex problem.

459
00:33:38,360 --> 00:33:44,880
So you're thinking that your reinforcement learner would be kind of exploring this

460
00:33:44,880 --> 00:33:51,880
state space of like different types of buyers and different prices and things like that

461
00:33:51,880 --> 00:33:54,800
and trying to find an optimal path through that.

462
00:33:54,800 --> 00:33:55,800
Yeah, yeah.

463
00:33:55,800 --> 00:34:01,560
So essentially what you can control is from I think it's mainly the price or the discount

464
00:34:01,560 --> 00:34:03,920
you offered to your customer, right?

465
00:34:03,920 --> 00:34:08,480
And then the environment that you are sitting in is very complicated.

466
00:34:08,480 --> 00:34:15,600
You have competitors, your customers may have different background.

467
00:34:15,600 --> 00:34:17,600
You cannot control all of this.

468
00:34:17,600 --> 00:34:23,560
So that's why we need to use reinforcement learning to dynamically update your price

469
00:34:23,560 --> 00:34:26,760
and discount to check your customer.

470
00:34:26,760 --> 00:34:31,960
And I'm guessing that Azure ML Studio doesn't do reinforcement learning yet.

471
00:34:31,960 --> 00:34:33,760
Yeah, indeed.

472
00:34:33,760 --> 00:34:41,600
We don't have reinforcement learning as maybe a toolbox, but internally we have another

473
00:34:41,600 --> 00:34:43,800
tool called CNTK.

474
00:34:43,800 --> 00:34:48,960
In CNTK, actually, it has a comprehensive set of functionalities.

475
00:34:48,960 --> 00:34:53,240
So it also offers you the flexibility to develop reinforcement learning.

476
00:34:53,240 --> 00:34:59,000
Actually, I think in the newly released version, it has some tutorial about that.

477
00:34:59,000 --> 00:35:05,880
Right before we close things down, are there, if there were three things that you could

478
00:35:05,880 --> 00:35:11,360
get from Microsoft in there in terms of the way they supported you or their tools, do

479
00:35:11,360 --> 00:35:13,440
you have a wish list for them?

480
00:35:13,440 --> 00:35:15,880
Offhand, I can't think of anything.

481
00:35:15,880 --> 00:35:20,120
We've been very excited about the results.

482
00:35:20,120 --> 00:35:27,440
I guess just being able to ramp up our internal knowledge, which they've been helpful with,

483
00:35:27,440 --> 00:35:31,960
and just getting the ability to spend some more time on these types of projects would

484
00:35:31,960 --> 00:35:34,000
be the two things that we're looking for.

485
00:35:34,000 --> 00:35:36,840
In terms of the tool itself, it's been great.

486
00:35:36,840 --> 00:35:40,720
There is anything at the moment that I can think of that we would add.

487
00:35:40,720 --> 00:35:41,720
Okay.

488
00:35:41,720 --> 00:35:42,720
Awesome.

489
00:35:42,720 --> 00:35:45,280
And can we anything else that you would add or would like to share?

490
00:35:45,280 --> 00:35:51,400
I would say that it's a really great experience to work with shape razors and then to come

491
00:35:51,400 --> 00:35:57,120
up with the solution and trying to improve the existing solution that we have built.

492
00:35:57,120 --> 00:36:02,040
So I really look forward like continuing working with you in the future.

493
00:36:02,040 --> 00:36:03,040
Cool.

494
00:36:03,040 --> 00:36:04,040
Awesome.

495
00:36:04,040 --> 00:36:05,040
Awesome.

496
00:36:05,040 --> 00:36:11,280
Well, I really enjoyed chatting with both of you and appreciate you taking the time.

497
00:36:11,280 --> 00:36:15,880
Mike, I wish you and the Portland Trailblazers a great season.

498
00:36:15,880 --> 00:36:16,880
Thank you.

499
00:36:16,880 --> 00:36:17,880
Appreciate that.

500
00:36:17,880 --> 00:36:18,880
All right.

501
00:36:18,880 --> 00:36:19,880
Thanks, guys.

502
00:36:19,880 --> 00:36:20,880
Thank you.

503
00:36:20,880 --> 00:36:21,880
Thank you.

504
00:36:21,880 --> 00:36:23,880
All right, everyone.

505
00:36:23,880 --> 00:36:30,080
That's our show for today for more information on Mike, Chenhui, or any of the topics covered

506
00:36:30,080 --> 00:36:36,640
in this episode, head on over to twimlai.com slash talk slash 156.

507
00:36:36,640 --> 00:36:43,680
To follow along with the AI and sports series, visit twimlai.com slash AI and sports.

508
00:36:43,680 --> 00:36:47,960
If you're a fan of the pod, we'd like to encourage you to head to iTunes or wherever

509
00:36:47,960 --> 00:36:52,800
you listen to podcasts and leave us your five star rating and review.

510
00:36:52,800 --> 00:36:56,920
We're super helpful as we push to grow the show and the community.

511
00:36:56,920 --> 00:37:25,440
As always, thanks so much for listening and catch you next time.

