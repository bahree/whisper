WEBVTT

00:00.000 --> 00:29.000
All right, everyone, I am here with Vila Tulos Vila is the CEO and co-founder of Outer Bounds and a friend of the show we first spoke back in December of 2019 Vila welcome back to the

00:29.000 --> 00:59.000
2021 AI podcast. Thank you. Thank you. Thanks for having me again, Sam. I'm looking forward to digging into this conversation among other things you've got what you've just got a lot of new stuff going on. New startup last time we spoke you were at Netflix. You've got a book that you're working on. I'll have you tell it, but sounds like you're quite the busy guy. Yeah, well, I mean, not the smartest, smartest idea. So,

00:59.000 --> 01:28.000
maybe, maybe I can start with the book. So, yeah, indeed, I mean, we spoke for the first time, 2019, like when when I was still at Netflix leading the machine learning infrastructure team. Maybe, maybe some of your listeners, like, I don't know if they remember the episode, but we talked about metaflow, which is the opens of open source framework for for machine learning infrastructure that we had started developing and that whenever I spoke about overall, like what how Netflix does machine learning, how Netflix does data science at different conferences.

01:28.000 --> 01:48.000
And so forth, it always felt that there was never enough time to kind of really deep into details. I mean, because of course, I mean, this is a complex field. There are many, many kind of important topics. So I thought that, well, it would be fun to write a book and like, so would have enough enough like pages to cover like all the different topics in detail.

01:48.000 --> 01:58.000
Well, yeah, I think that that's really happening at the same time. It's a crazy amount of work. I should have known that like when I started, but yeah, no, that's going well. And like, hopefully the book will be out like early next year.

01:58.000 --> 02:10.000
Awesome. Just to rewind a bit. So, folks get to know a little bit about your background. It's been a bit since we spoke last time. How'd you get into all of this data science and ML infrastructure stuff?

02:10.000 --> 02:30.000
Yeah, good question. Well, embarrassingly enough, I've been kind of doing this like for a long time. I joined my first neural network startup early 2000s. And ever since then, I've been building infrastructure like for for scientists for researchers, like who want to want to build bleeding edge models and like help their businesses with machine learning and data science.

02:30.000 --> 02:42.000
And now when I joined Netflix, Netflix had this interesting situation that obviously they had been doing recommendations for a long time. Many people know that the recommendation systems that like give you that TV shows and movies when you log into Netflix.com.

02:42.000 --> 02:48.000
But not so many people realize that Netflix actually applies machine learning to too many other use cases as well.

02:48.000 --> 03:01.000
Like all the way, like kind of a study from the production of of these TV shows and movies. And now there are many, many different applications for data science and machine learning and that my team was helping all the scientists were building different applications.

03:01.000 --> 03:14.000
Some like we're using deep learning others were using classical statistics. Other words, we're doing things that are technically not even machine learning like operations research and always the question was that how do we help help scientists? How do we make them productive?

03:14.000 --> 03:20.000
As they are building these applications and how do we help them to actually test these like as close to production as possible.

03:20.000 --> 03:30.000
So that's like what I was doing at Netflix and so it happened that of course many other companies are like trying to figure this out and like have been trying to figure this out like for the past couple of years.

03:30.000 --> 03:36.000
So so we open source open source the package and like now now continuing the journey like with the new startups.

03:36.000 --> 03:49.000
Outer bounds is focused on commercializing metaflow the work you started at Netflix. Yeah, like kind of the big theme overall that like how do we how do we help data scientists machine learning people at different companies and actually like helping their companies how to become productive.

03:49.000 --> 03:53.000
And of course metaflow is a big part of that stories.

03:53.000 --> 04:11.000
But why don't we start with digging into metaflow what's the main problem that metaflow is trying to solve and how does it differ from you know what's now become an explosion of ML ops tools and products.

04:11.000 --> 04:24.000
Yeah, no, it's actually like really interesting that of course now there's indeed this like a game beyond explosion of different startups tools like approaching this this whole industry like from different animals.

04:24.000 --> 04:29.000
Back when we started in 2009 sorry me 2017.

04:29.000 --> 04:45.000
This was before a sage maker. This was before ML flow. This was before Q flow. But the problem space was still the same. So what was the situation at Netflix at the time and I believe that this resonates with many other companies as well that there was plenty of existing infrastructure.

04:45.000 --> 04:51.000
So you had a compute later so you could actually run containers at scale in the cloud you had a data warehouse.

04:51.000 --> 05:01.000
Maybe like it's three or like a cloud-based data lake on the other hand like you may may have had some orchestration systems that allow you to kind of run these bags at scale.

05:01.000 --> 05:05.000
And like maybe you had some kind of a like a worsening systems at least for the code.

05:05.000 --> 05:18.000
But now what we recognize is that stitching these systems together to build the end to an ML applications was really, really hard especially for data scientists who are not software engineers and like maybe not these stupid systems engineers by training.

05:18.000 --> 05:25.000
So the idea of metaflow like since the very beginning is that like can we take all these existing pieces of infrastructure.

05:25.000 --> 05:32.000
And like really like think think about the stack systematically like all the way starting from data compute orchestration versioning and so forth.

05:32.000 --> 05:39.000
And then like wrap it in a kind of very user friendly package like really quite concretely a Python library.

05:39.000 --> 06:00.000
So the people who mainly have been using let's say Jupiter notebooks in the past are actually able to build applications that are more production ready. And of course at Netflix as with many other companies, the old model used to be that you had maybe a data scientist who maybe prototype something in a notebook and maybe a different machine learning engineer who then like to do the model and kind of rewrote the model.

06:00.000 --> 06:14.000
And then the language to make it more production ready. And as even at Netflix as the kind of demands for like a kind of a speeding up the iterations crew, I mean it was obvious that like well, I mean we can't just have that model like where one person like writes one version and then it has to be rewritten for production.

06:14.000 --> 06:22.000
And the idea was that okay, could we have a system that allows these data scientists to build more or less production ready pipelines like from the get go and that.

06:22.000 --> 06:31.000
That's that's kind of like what we have been trying to do and like it was really quite successful at Netflix and and now I mean as open source I mean like other companies have found it useful as well.

06:31.000 --> 06:37.000
So I mean like trying to try to make sure that like it really works for for different different companies outside Netflix now.

06:37.000 --> 06:43.000
What are some of the some examples of some other users that are using it now.

06:43.000 --> 06:53.000
If you if you look at the GitHub repo or like if you come to our Slack channel like you will see many familiar names like the zero real estate company 23 and me.

06:53.000 --> 07:02.000
Of course, like in bioinformatics like we have actually a good number of drone companies who build like a drones to computer really interesting computer vision.

07:02.000 --> 07:12.000
CNN like recently talked about like how they increase the productivity of their data science organization with metaflow so usually the pattern is always the same that there's some.

07:12.000 --> 07:29.000
The engineering team like platform team who have recognized the need that they have to make their platform more usable for data scientists and then they don't want to write everything from scratch and like for the metaflow provides really nice baseline kind of a foundation on which they can then like build their maybe company specific customization so.

07:29.000 --> 07:40.000
I really do believe that machine learning comes in many different shapes and sizes of there is in like one size fits all approach so we don't claim that we have a silver bullet that solves all problems but it's more so than the foundational.

07:40.000 --> 07:50.000
So questions always the same everybody needs data everybody needs compute pretty much everybody needs orchestration versioning so at least like we can help people and is there a particular.

07:50.000 --> 08:04.000
You know feature set or set of functionality or use case that is kind of the the sweet spot or the core value proposition relative to other things that are out there.

08:04.000 --> 08:33.000
Yeah good question and now now of course there are like so many so many different different companies and open source tools that it's actually like even for me it's kind of hard to tell anything apart like everything everybody is like a ML ops company these days and so for what we have been doing since the very beginning is really focused on the on the usability I mean really like the human centric infrastructure knowing that ultimately it is the data scientist who kind of make make operate it and like kind of a can can determine the success of any.

08:33.000 --> 08:50.000
So really focusing on that like human interface so that has been something that like we have been doing and I think like that's what like really gross many people to met a flow in contrast to other solutions that in instead of like really focusing on like the engineering in a degree and like you have to know Kubernetes and docker and YAML and like so for it.

08:50.000 --> 09:01.000
I mean kind of how how easy how easy Python interface can we possibly provide so that like people can actually like kind of a get get kind of things deployed production as easy as possible.

09:01.000 --> 09:14.000
So what's a specific example of an API or something that you find that folks you know struggle to do and met a flow provides it for them in a much easier way.

09:14.000 --> 09:27.000
Yeah yeah I think like you know my my observation is that more so than any any single thing it's actually more like a death by a thousand cuts so this is what I observed at Netflix as well that.

09:27.000 --> 09:42.000
When you have a data scientist and the data scientist is given some business problem but okay so I mean can you build in like a like a predict predict for sure and like can we predict like kind of a how long people are going to stay as Netflix members or something of that sorts.

09:42.000 --> 09:58.000
Well I mean I guess like oftentimes it all starts with data I mean the data scientist wants to kind of get access to data how do you access the data now we for instance Netflix is a big user of spark so and I originally to us so that people have to wait for quite a bit of time to execute some like a sequel queries.

09:58.000 --> 10:13.000
Do you get the data they need and like then as a kind of like way to make that faster like we introduce this idea of of being able to access data directly from the data warehouse so there's a custom is three client now in met up low so you can access data super fast from your data warehouse.

10:13.000 --> 10:37.000
And the next thing is that well you have to think that okay how do you run the compute do you have to write Docker files and with that comes to this like a very mundane question that all these projects use some off to shelf libraries always use tension flow use high torches use extra boost and the kind of the de facto solution these days is of course the right Docker files but I mean that introduces a yet another like a small friction that okay you have to figure out how to do that.

10:37.000 --> 10:47.000
Well as a way of helping with that I mean we have the condo decorator so you like we kind of a baking the dependencies you have to you don't have to write any Docker files by hand the next one is compute how do you run compute the scale.

10:47.000 --> 10:58.000
So I would say that it's really like the fact that like we we have really like we have work with data scientists closely like trying to see that like what are the day to day problems they have and then like addressing them one by one.

10:58.000 --> 11:10.000
And then like packaging everything as a like one cohesive package now like the fact that well we interface with different AWS services that functions AWS batch I mean that is certainly convenient.

11:10.000 --> 11:25.000
But I don't think that that's that's really kind of the kind of the core value prop in a sense that like over time there will be other services that we interface with but it's really kind of a like a going systematically like to all the pain points that people face and then like trying to find solutions for them.

11:25.000 --> 11:39.000
And by the way I mean it's not so that like we always like try to reinvent the wheel oftentimes people use other services in conjunction with metaflow many many of our customers use weights and biases they find it very useful for for model monitoring.

11:39.000 --> 11:54.000
I mean like we had a blog post with determined AI if you want to train large scale deep learning models now actually like we will have a blog post with seldom that how you want to do how you can do model hosting using metaflow and seldom together.

11:54.000 --> 12:04.000
As we know I mean it's a kind of a thick stack of different things and I don't think like anyone can solve all these pieces but the question is that okay so how do you actually like kind of a stitch together something that actually makes sense.

12:04.000 --> 12:06.000
Got it got it got it.

12:06.000 --> 12:13.000
And so the book is the book focused on metaflow and how to use it.

12:13.000 --> 12:29.000
Yeah well I mean the way I think about it is that overall by the way I mean if I may take a step back I mean I ask myself the question that like what's even the point of like writing technical books these days because there's amazing amount of information available online and anyway you can have dating some time and so forth.

12:29.000 --> 12:32.000
And both get out of date so quickly.

12:32.000 --> 12:44.000
I mean that's absolutely true and especially in a field like ML ops I mean it's kind of like crazy I mean I'm sure that what we are seeing today is very different like what the situation will be in five years time.

12:44.000 --> 12:54.000
So instead of like really focusing on like API documentation which is really easily available online anyways I I thought that okay so at least we can systematically go through the stack.

12:54.000 --> 13:08.000
I do think that there are some principles some basic foundation that won't be changing like the fact that you always need data I mean there are like a really fundamental almost like a physical patterns how you access data then like you have the question of compute and you have the question of orchestration.

13:08.000 --> 13:16.000
Now so it happens that of course in my bias point of view I mean doing these things in metaflow is quite easy so I use metaflow as an example.

13:16.000 --> 13:27.000
But now if you wanted to apply the same principles like let's say the flow or like you want to use ML flow or like maybe you have something homegrown I think that like the basic patterns are definitely applicable and.

13:27.000 --> 13:37.000
And I think like when I've been talking to many different people in this field I mean there's still a lot of confusion about like how to think about this large scale compute like using container management systems like opportunities.

13:37.000 --> 13:55.000
Or like how to think about this like a fast data processing in Python how do you kind of combine Apache arrow and non buy and stuff like that so all those things are covered in the book and a while metaflow is used kind of as the reference implementation I mean the idea is that like it should be quite easy to apply them to other frameworks as well if you wish.

13:55.000 --> 14:13.000
And so when you talk about the compute layer to what extent does Kubernetes figure into the picture both in the book and you know practically when you're deploying with metaflow I forget the answer to this question if met I remember metaflow not necessarily.

14:13.000 --> 14:26.000
Yeah, that's being closely coupled with Kubernetes but I could be off on that yeah yeah that's a that's an interesting question so now Kubernetes is a complex beast I guess like everybody.

14:26.000 --> 14:37.000
At the same time it seems that it's here to stay and it does actually solve like many many like very very like a foundational questions for many companies and of course many companies have.

14:37.000 --> 15:05.000
Have found it quite useful in orchestrating microservices so you have nothing to do with machine learning but I mean just like you want to keep your company's product running you have multiple microservices you have to deploy them somewhere Kubernetes provides exactly the right primitives and of course what's even more you have the whole ecosystem of tools available on top of the Kubernetes so you know how to deploy applications using hell like you can monitor stuff so many many good things about that ecosystem overall definitely the big downside is is the complexity.

15:05.000 --> 15:17.000
So now the situation like what I've been seeing at many companies is that you have an engineering team and the engineering team has decided that okay they want to go with Kubernetes because it just makes sense like a technical point of view now you have a data science team.

15:17.000 --> 15:27.000
And the data science teams goes to the engineering team asking that okay so we need to write these applications we need to get stuff running and then the engineering team is that okay we have this Kubernetes thing that like you can use this.

15:27.000 --> 15:40.000
And then the data science starts scratching their head that okay so I mean you go to Kubernetes.io and like you read about pods and you read about stuff and that oh my gosh I mean there's like there's like a hundred miles between my machine learning concerns and Kubernetes.

15:40.000 --> 15:50.000
And that's of course like where things like you flow come in the picture that like you need some kind of a data science layer on top of Kubernetes and I think that that idea makes it makes a ton of sense.

15:50.000 --> 16:11.000
Now the thing about Kubernetes is also that is a very amorphous thing there is in the single Kubernetes there are different ways of running Kubernetes so what we have been trying to do now with metaflow is to is to really like a thing to aspects I mean one is that if you want to run batch jobs at scale and you want to use Kubernetes as the underlying compute layer like how does that work so how does it work with

16:11.000 --> 16:23.000
auto scaling how does it work with the monitoring these workloads and luckily we had experience like with this from Netflix that Netflix actually has another system called fighters.

16:23.000 --> 16:37.000
That's open source as well I mean it predates Kubernetes and now Netflix has been also like starting to look more deeply into Kubernetes but at least when it comes to running really this large fleeks of containers at scale like we had experience of that and like we started making those experiences in.

16:37.000 --> 16:52.000
Into the new Kubernetes decorator that we have been building in metaflow and that will be going out in a few weeks time so that's that's coming soon also I do see that it's kind of a beginning of a journey I don't think there like anything related to Kubernetes is ever done so it's also evolving.

16:52.000 --> 17:11.000
And there are other things like our goal I mean let's say you want to do orchestration on the both Kubernetes something like our goal might be a good solution but at the same time many many many other systems that are really like trying to figure out their Kubernetes story and I'm sure that like over the next couple of years will even see a richer ecosystem of applications.

17:11.000 --> 17:26.000
It sounds like the summary there was when metaflow was at Netflix you didn't need Kubernetes because you had your own thing and now that you're out talking to other non Netflix organizations Kubernetes has become a requirement to some degree.

17:26.000 --> 17:47.000
Yeah I think that that's one way of like putting it also another kind of very practical reason is that we interface directly like with number of AWS services and I honestly think that like for many companies just using AWS patch AWS that functions it's it's the easiest approach and like there's absolutely nothing wrong with that I mean like you don't do anything wrong if you don't use Kubernetes.

17:47.000 --> 18:16.000
But at the same time now companies who already use Kubernetes and maybe use Kubernetes on Azure or like Google I mean then it's of course an interesting question but like how do we easter path into using metaflow and Kubernetes can help there yeah yeah yeah there's an interesting discussion about kind of ways of achieving scale and different layers of cloud services that can be applied towards achieving scale for deployed machine learning models in the book and you talk about.

18:16.000 --> 18:33.000
You know services like batch and step functions and and lamb is like how complete it are you know those services and allowing someone to to you know deliver a production ML system today.

18:33.000 --> 19:02.000
And I think honestly I mean this is the situation already like maybe for the past five years or so that I think that like more or less everything is technically possible but it's really nothing has been easy enough so if you want to if you are really determined to get anything done I mean look I used to work at this at the company and like we were building this massive scale machine learning system that provided low latency predictions like we had less than 100 milliseconds to provide predictions it had to provide like hundreds of thousands requests per second.

19:02.000 --> 19:15.000
And like that system I mean it was like they started building it like 15 years ago something really like crazy time ago so and like of course the same story at Google Yahoo and like all these companies so like it has been possible.

19:15.000 --> 19:26.000
Now the fact is that it has required an inordinate amount of effort and like a big very talented engineers senior engineering teams like building this stuff like a very like a hand built like bespoke system so.

19:26.000 --> 19:43.000
And I think that that's really like what's changing that now with this higher level services like batch and step functions and our go and so forth so like all these things become more accessible to more companies who don't have them don't want to hire like this crazy engineering teams building systems from scratch.

19:43.000 --> 20:08.000
And also of course like the end user data scientists so I don't think that like we are quite yet there I think that there's work to be done I think like let's say I mean good example is server less I think that let's say for machine learning the server less is a great idea that like I just I say that OK so I want to do this like a crazy hyper parameter grid search and I want to run like a thousand models and like just like a submit these things in the cloud and I want to response in two hours just make it happen.

20:08.000 --> 20:20.000
I mean that's that's kind of division and it kind of kind of like kind of we are getting there but I mean there are still like some rough edges and I think that there's stuff that the clouds needs to need to fix I mean also I mean Kubernetes is one component here.

20:20.000 --> 20:25.000
But I mean I think like we are making slow and steady progress towards that vision.

20:25.000 --> 20:45.000
Serverless at least you know as far as land is concerned and a job that takes two hours to run don't seem necessarily compatible like let's say you want to use GPUs not going to happen so yeah I mean you can't use lambda then like you use well I mean you can't really use fargate I mean then you go with AWS batch and it's yet another service so there's a lot of complexity here as well.

20:45.000 --> 21:02.000
And I think it's a lot of it like much of it is actually accidental complexity many of the systems including Kubernetes were originally built of course like not for machine learning not for data science so there's kind of that impenetness mismatch that you are trying to use systems that were not built for machine learning for machine learning workloads.

21:02.000 --> 21:18.000
And I think that like more and more systems start like a treating this compute intense data intense applications as first class citizens so that will help over time but I mean as of today I mean like you kind of see this cracks like between the seams still.

21:18.000 --> 21:31.000
And that's of course like what metaflow is trying to do that like well I mean if you want to kind of access the future already now I mean you can try to use you can try to kind of take a look at metaflow unlike we are trying to kind of a speed up that future like kind of the progress to the future of it's.

21:31.000 --> 21:52.000
And so as metaflow does metaflow use services or depend on services at the level of batch and sub functions and things like that or is it only expecting kind of raw infrastructure at the cloud what layer is it interfacing to the cloud.

21:52.000 --> 22:21.000
Good good question so we like we definitely believe on understanding of the shoulders of giants so I mean we actually we have taken the stance that we want to integrate with the best of the breed solutions that already exist including things like AWS batch and the reason for that is quite simply not because the systems are perfect but I mean there's so much engineering work that goes into building even these lower layers that I mean like I mean it's just a kind of a humble recognition that like if you want to run like a big fleets of context.

22:21.000 --> 22:50.000
Big fleets of containers in the cloud there are many media credit details that you have to figure out and I don't need that like anyone has resources to kind of build everything from scratch so yeah I mean indeed we integrate with batch like directly like we don't go to easy to directly now with Kubernetes well I mean Kubernetes is an interesting story of course because it's kind of a like it's like a slightly different kind of animal but I mean in many other cases the orchestration is a good example that people always wonder about the DAG orchestration and like if metaflow is like airflow or like a prefect or or.

22:50.000 --> 23:18.000
Argo or Dexter or like what have you and and and again like even with orchestrators our point of view I mean this is like again like coming from like a very very many battles cars like when it comes to running hundreds of thousands of workflows that building a robust workflow orchestrator is actually hard to work and like it takes a countless number of engineering hours and instead of us like trying to claim that we are just building a new like a workflow orchestrator like we want to integrate with whoever like kind of builds the best one.

23:18.000 --> 23:32.000
The reason like why for instance like we like AWS that functions is that well AWS just like has a really good track recording keeping these services running so if you just want to like a no hassle system that somebody else takes care of I mean that's sort of like a reasonable solution.

23:32.000 --> 23:47.000
I mean of course there are others like airflow is super popular I mean many good things about airflow again I mean like requires a bit more kind of like hand holding like if you want to run it that scale and that's why there are other companies who provide that as a service but we see that machine learning ultimately.

23:47.000 --> 24:03.000
Machine learning ultimately is kind of like a layer on top of all these like of all this foundational infrastructure and I don't think fundamentally let's say machine learning needs a whole different kind of a compute layer or like whole different kind of a data layer or whole different kind of an orchestration layer.

24:03.000 --> 24:16.000
But then it needs to add layers on top of those things so let's say when it comes to model monitoring model versioning of course like all everything related to feature engineering these are complex topics that then like need to be layered on top of this foundational infrastructure.

24:16.000 --> 24:26.000
Yeah yeah so is the implication then that metaflow kind of is and will remain a AWS specific tool.

24:26.000 --> 24:36.000
No I think like it's pretty like with Kubernetes the idea is that like true Kubernetes you can run it with other clouds as well also that doesn't get you step functions though.

24:36.000 --> 24:51.000
No but I mean for instance like our goal helps there so I mean like if you have our goal running on Kubernetes then you have kind of this like kind of a quote unquote Kubernetes native ecosystem that you can run like using different clouds so that's that's kind of the direction where we are going but ultimately.

24:51.000 --> 25:07.000
Metaflow is not specific to any any I mean there like you know if you actually look at the code base you will find that like there's the plugins directory and under plugins there's AWS I mean like equally well there could be one for GCP or Azure or like whatever whatever else so.

25:07.000 --> 25:13.000
But of course like an Netflix is 100% AWS so it's just happened to have a lot of operational experience with that.

25:13.000 --> 25:27.000
What are the elements of the book that you're most proud of in terms of you know things that you treated better than you know what you've seen out there.

25:27.000 --> 25:42.000
Yeah well I mean I definitely don't claim to know everything that exists out there and I know that like over over the past I don't know like 12 months I have seen that like many new really exciting books have been written about this topic I think that this.

25:42.000 --> 25:56.000
You know I see that what we are now seeing like let's say with ML ops is a big macro trend in the industry so many companies are really trying to figure out what's the right way of doing this and like always when these macro trends happen.

25:56.000 --> 26:17.000
There will be many different approaches especially initially and if you like I always kind of throw the parallels to e commerce and like kind of like the web stack overall and if you think about that the web frameworks 2003 2005 2010 there were like many different directions is it like should you be using PHP should you be using channel should you be using Ruby and Rails.

26:17.000 --> 26:29.000
And I think that's amazing thing that like we have a many like very smart people innovating like a different type of approaches and then like everybody learns from each other and then like kind of over time we converge something that makes sense.

26:29.000 --> 26:38.000
So in that sense what I'm what I'm trying to do with the book is of course like a coming like from from the angle that I have seen working I mean I'm sure that it's not the only way.

26:38.000 --> 26:58.000
And what I really kind of what I'm trying to convey with the book what I really like is is really trying to kind of a touch like all layers of the stacks since that's what I oftentimes see missing that there are like amazing companies amazing talks amazing books about like a specific questions let's say that like a deep learning models or feature engineering or model monitoring.

26:58.000 --> 27:11.000
But then always the question is that okay so like let's say like kind of if I just want to test this model at scale how do I do this or like if I need to version my models how do I do this I think it's useful to kind of a at least like a cover touch like all these spaces one by one.

27:11.000 --> 27:19.000
And then like I think like the book says I mean like it's it's totally up to you like how you decide to solve each one of these layers.

27:19.000 --> 27:48.000
And I'm sure that like there are many many different solutions like to each one of these things and like more will more will appear over time so but it's really like kind of a having that like a systematic like a 3D stuff of the whole stack is something that I personally like find quite valuable because then it allows you to start like thinking the whole thing systematically and not get overly confused about the whole landscape and I know that like you have been of course like doing good work in like trying to map the landscape and trying to kind of a people understand like how all these companies and different pieces of the infrastructure.

27:48.000 --> 27:52.000
Together so I think that there's just a lot of confusion about that in here.

27:52.000 --> 27:58.000
Yeah absolutely thanks for the shout out to our solutions guy will definitely be linking to that in the show notes.

27:58.000 --> 28:09.000
You raise this interesting point about convergence that kind of had my head spinning as you're speaking like what have we converge to on the way I mean.

28:09.000 --> 28:38.000
You could say you could say JavaScript but then that thing you know there is a total divergence in terms of JavaScript frameworks and yeah yeah well you know I mean like I would say that like we have got rid of some things that maybe didn't work so well I mean like I don't know how many people anymore like right CGI beans so how many people install Mod Pearl and I think that like what we are not big difference is the fact that if let's say like if let's say you are not a

28:38.000 --> 28:53.000
C coder like if you don't know like a web web servers HTTP you can go to square space you can go to do to Shopify and I actually like without any coding skills you can actually set up an e-commerce store and I think that that is really the fundamental qualitative change.

28:53.000 --> 29:00.000
But there like now we have probably 10 times more people who can actually start selling coffee or or maybe shoes or whatever online.

29:00.000 --> 29:27.000
And like we are not yet at that point like with machine learning I mean the fact is that you are like a random company you want to start applying machine learning you want to hire a data scientist and now you are thinking that oh my gosh how do we make this person productive how do we actually allow them to study trading I mean you are still at pretty much at loss that like okay so what kind of tooling I mean okay here's a laptop and like maybe you have a Jupiter notebook on the laptop but I mean what else so I think that that's something that's going to take another five years to figure out.

29:27.000 --> 29:56.000
Yeah yeah it's an interesting question I wonder if it's less convergence and more like raising the level of abstraction like the CGI have been with a pretty low level of abstraction and we have all the opportunities is pretty low level I mean look I mean there's still openings who say that like the scientist should learn Kubernetes it's like a data style like a web developers learning CGI being or like kind of Apache config I mean honestly I mean most people don't care anymore so yeah I mean the fact is that like the progress is never linear it's kind of funny that like a fun.

29:56.000 --> 30:25.000
It's kind of funny that like oftentimes we take two steps forward and like occasionally like a three steps backward I remember like for instance like when when MapReduce Hadoop was a big thing I mean people like we're really interested in in in re-implementing all machine learning algorithms on top of the MapReduce paradigm and it's just like a mind-boggling exercise that it doesn't make much sense and everything becomes slower than what they used to be and then like it turned out that that was a bit of a evolutionary dead end and like then people like kind of a came back and now I mean we have a much more sensible approach is.

30:25.000 --> 30:32.000
But I mean yeah I mean it takes a bit of a brownie and walk all the ways to come to the next solutions.

30:32.000 --> 30:54.000
It kind of along those lines of I don't know if it's along those lines but when you think of like the the persona that you're building Metaflow for is it kind of this traditional data scientist that you know wasn't kind of you know they're kind of sweet spot tool

30:54.000 --> 31:03.000
isn't Kubernetes or containers but rather Jupiter notebooks and you know the you know traditional Python tools.

31:03.000 --> 31:12.000
Yeah so the kind of the minimum height for this right that we have always required is that well you kind of need to know some Python.

31:12.000 --> 31:40.000
So let's say if you have been able to like go through scikit-learn tutorial in a Jupiter notebook I mean then I think like you have a like good skill set that you can get going assuming that especially like kind of if there's someone like to maybe help to deploy the system I know that let's say I mean when it comes to getting your AWS account setup I mean requires that you go to the cloud formation console and there are many new concepts there and that's it but I mean once you have the system set up then at least like if you are able to write Python code I mean you should you should get pretty far.

31:40.000 --> 32:05.000
And that's really the idea and like another thing that I really strongly feel about is that you know as we all know experimentation is really key to data science and like the idea that you can like try even like crazy ideas is really really important for all machine learning data science projects and now what I have seen happening in practice is that many data scientists especially those who don't necessarily have like a 10 years of experience.

32:05.000 --> 32:18.000
They are very hesitant to try out crazy things because they are afraid that they will break something there might be and like a engineer yelling at them that look I mean you are allocating too much memory or like kind of you are making your number of filing correctly.

32:18.000 --> 32:29.000
And that kind of a makes them self censor it makes them self limit like what they do and they maybe stick with some some paved path that OK I mean as long as I'm doing exactly this thing I mean then it's fine.

32:29.000 --> 32:38.000
And that is I think that it's quite detrimental like for for data science projects where it's very important that you are like able to try different tools different approaches like this freely and.

32:38.000 --> 32:51.000
And like one really key idea what we have always had is that whatever the infrastructure does it it should work so that like the data scientists can't break anything and there should be a strong isolation let's say between the production pipelines.

32:51.000 --> 33:03.000
And the experimentation that let's say if your company has a production ML pipeline no matter what the data scientists does on their laptop assuming that they are not actively malicious which is usually not the case they can break the production.

33:03.000 --> 33:20.000
And like if you if you ask this question like kind of from yourself at your own company that is it so that you can run any piece of code on your laptop and like no matter what you do like kind of a concrete production unfortunately often I mean the answer is still no that like there are commands there are things that you can run that will break everything.

33:20.000 --> 33:32.000
And it's all those things that now imagine that you hire a new data scientist the new employee at your company you give them a laptop and you say that okay so here are some things you can do but I mean please don't do that and don't do that or otherwise like kind of all.

33:32.000 --> 33:42.000
And then of course I mean people become afraid and that like really limits their productivity and creativity so I think that this is this is really important part like of how we think about the person as well.

33:42.000 --> 33:54.000
That kind of no matter like kind of what kind of background you have like whether you are experiencing experience even for myself I want to have that feeling that okay I can do whatever and like I can't like break things really bad.

33:54.000 --> 34:16.000
And I think that's really important because then no matter like if you are like a 10 year old or like if you are like kind of if you have been doing this for a long time we can just tell that okay stop starting current start trying I mean like Google stuff like copy based stuff from stack overflow it might be totally crazy or like use GitHub co pilot and like what you get out I mean might be totally incorrect but I mean like at least you can't break anything I think that's that's really important.

34:16.000 --> 34:35.000
So one challenge that we see a lot is kind of you know folks scratching their own edge building you know tools and platforms that solve a specific problem you know going out to doing it's at scale as a commercial entity and then realizing there's.

34:35.000 --> 34:54.000
You know not just that core persona the data scientist persona but also there are you know enterprise IT and security and all these other people that you know either need or want to be involved at scale do you you know to what extent are you catering to and this is of course.

34:54.000 --> 35:14.000
You know particularly true in ML ops which has as you know a bona fide part of the name ops you know to what extent are you you know catering to that to that community building tools for them thinking about their requirements and how does that show up and what you're doing yeah yeah good question now.

35:14.000 --> 35:34.000
So the way I think about it is that as long as machine learning and data science was pretty much like a like a research activity so you had R&D and like you had people doing development you had people doing research like as long as it was only research you could have this isolated in environments that had nothing to do with production they could have their own rules their own.

35:34.000 --> 36:01.000
Whatever like a crazy sandboxes and and like in like it wasn't like kind of that important that you actually interface with IT interface security now I think that as companies really want to start employing ML in in production actually like to help the bottom line of the company to actually like right revenue and so forth the ML can't be a research activity anymore it can't be an island it can't be an like isolated sandbox anymore.

36:01.000 --> 36:31.000
And you know this is this is actually like really if you think about the really the long arc that what used to be the situation even 20 years ago that like people were doing machine learning let's say MATLAB or Mathematica or like if you think about the tools like our studio even Excel you know all these tools are actually like quite excellent in in in like quickly trading I mean if you look at if you think about Mathematica that has had notebooks since 1980s or something crazy like that that works fine but the key problem that these tools had is that they were not compatible with production like if you had something like

36:31.000 --> 36:39.000
running in Mathematica and like the company wanted to deploy this on the production infrastructure there was simply no way I mean like you have to re implement the whole thing from scratch.

36:39.000 --> 37:00.000
And now as we want to start using machine learning production like we really have to kind of upgrade these barriers and get out of the sandbox and I think that then it's absolutely inevitable that that like the ML needs to kind of a grow up and it needs to start complying like with this with this governance policies with the security policies with whatever like IT things you have.

37:00.000 --> 37:18.000
And now we are in this interesting kind of a kind of a conflict even that like we want to iterate like we want to experiment like with crazy things and at the same time as things approach production like we want to kind of like play nicely by all the all the kind of the rules of the production so that is that is kind of the kind of the gap that we are trying to breach.

37:18.000 --> 37:29.000
And I think that the important thing is they're also to do it gradually and I think that too many companies still are thinking it as a black and white matter that either you have something that's totally crazy totally not production compatible.

37:29.000 --> 37:36.000
Or then you have something that like 100% like kind of a all I said that an old piece across like that takes a lot of effort.

37:36.000 --> 37:56.000
I think that like Netflix managed to be this really well and thanks to their experimentation culture that let's say you have an A B test and like you have a production model somebody builds a new model now in order to test the new model in kind of actually like to get good read if it works you have to deploy to production and run an A B test now at the same time.

37:56.000 --> 38:04.000
The new experiment doesn't necessarily like have to be kind of as as production ready as the kind of what's already deployed in production.

38:04.000 --> 38:24.000
And like they should be a path they should be a way how you can like run these experiments easily so that they are good enough that like you you dare to run them in production you dare to expose the results due to actual users and at the same time you don't want to impose so many restrictions and so many constraints that it takes six months to kind of get any experiment running.

38:24.000 --> 38:43.000
So I think that that's the kind of the interesting interesting kind of the line that like many many companies have to walk that okay so how do we think about like 100% production how do we think about 10% production how do we think about 50% production and like what are the governance policies that at each kind of a step on this journey.

38:43.000 --> 38:52.000
But yes I mean I guess the kind of a very very short answer is that yes like we should be we should be thinking about all these like operational but it's not black and black and white things.

38:52.000 --> 38:55.000
Yeah awesome awesome.

38:55.000 --> 39:10.000
Vila to kind of wrap up any party thoughts on you know where this is all going both in terms of your work with metaflow and outer bounds as well as ML ops in general.

39:10.000 --> 39:39.000
Yeah well I mean I think we are like living very exciting times like I mean kind of the fact that there is so much activity in this space so many companies I I'm always like a super delighted talk to founders of different companies it's always super fascinating to hear like how different people are approaching this and with that I'm I'm pretty sure that like over over next five years like we will we will learn a lot I think that there might be I just hard to say if there's more fragmentation of convergence I think that like something's converged something probably will diverge a bit so that's that's good.

39:39.000 --> 40:04.000
So that's that's going to be exciting now also like on the on the kind of the user side on the company side what's also super interesting is that I meet people from from all kinds of companies for all kinds of from all kinds of traditional industries that are now starting to apply ML and I think that's really really encouraging and I think you know what's really interesting is that it's the pandemic I think really.

40:04.000 --> 40:29.000
Kind of a leapfrog this development that as there was more pressure for all companies to go digital like for all companies to go online with that game the idea that we have to become smarter about our business the competition is tougher and more and more companies realize that oh I mean like we actually should have a recommendation system on our website or like we should be thinking about all logistics so we maybe we should be analyzing our journey and all that stuff so more and more companies are starting to do this for real.

40:29.000 --> 40:57.000
And and of course I mean still today it's not as easy as it should be and like of course what we are trying to do is it is to try to make it easier so definitely I mean I invite anybody like kind of who has any interesting ideas want to chat I mean like reach out to me so we have an open slack at slack dot out of bounds.co I mean like everybody's welcome to join I mean it's not only about metaflow if you happen to be using metaflow I mean we are happy to help you there but I mean otherwise like just like a happy happy to chat and share notes.

40:57.000 --> 41:07.000
Awesome awesome well the luck thanks so much for taking the time to keep us updated as to what you're up to yeah thank you thanks for having me.

