1
00:00:00,000 --> 00:00:15,920
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

2
00:00:15,920 --> 00:00:20,880
people doing interesting things in machine learning and artificial intelligence.

3
00:00:20,880 --> 00:00:23,560
I'm your host Sam Charrington.

4
00:00:23,560 --> 00:00:28,120
This week on the podcast we're featuring a series of conversations from the AWS re-invent

5
00:00:28,120 --> 00:00:30,200
conference in Las Vegas.

6
00:00:30,200 --> 00:00:34,560
I had a great time at this event, getting caught up on the new machine learning and AI products

7
00:00:34,560 --> 00:00:38,520
and services announced by AWS and its partners.

8
00:00:38,520 --> 00:00:42,720
If you missed the news coming out of re-invent and want to know more about what one of the

9
00:00:42,720 --> 00:00:48,060
biggest AI platform providers is up to, make sure you check out Monday's show, Twimble

10
00:00:48,060 --> 00:00:50,200
Talk number 83.

11
00:00:50,200 --> 00:00:54,040
Around table discussion I held with Dave McCrory and Lawrence Chung.

12
00:00:54,040 --> 00:01:00,400
We cover all of AWS's most important news, including the new SageMaker, DeepLens, Recognition

13
00:01:00,400 --> 00:01:06,440
Video, Transcription, Alexa for Business, Greengrass ML inference and more.

14
00:01:06,440 --> 00:01:11,800
This week we're also running a special listener appreciation contest to celebrate hitting

15
00:01:11,800 --> 00:01:18,400
1 million listens here on the podcast and to thank you all for being so awesome.

16
00:01:18,400 --> 00:01:25,440
Tweet to us using the hashtag Twimble1Mill to enter. Every entry gets a fly Twimble1Mill

17
00:01:25,440 --> 00:01:31,280
sticker plus a chance to win a limited run t-shirt commemorating the occasion.

18
00:01:31,280 --> 00:01:35,400
We'll be digging into the magic Twimble swag bag and giving away some other mystery prizes

19
00:01:35,400 --> 00:01:39,560
as well so you definitely don't want to miss this.

20
00:01:39,560 --> 00:01:47,000
If you're not on Twitter or you want more ways to enter, visit twimbleai.com slash Twimble1Mill

21
00:01:47,000 --> 00:01:49,400
for the full rundown.

22
00:01:49,400 --> 00:01:53,760
Before we dive in, I'd like to thank our good friends over at Intel Nirvana for their

23
00:01:53,760 --> 00:01:57,880
sponsorship of this podcast and our reinvent series.

24
00:01:57,880 --> 00:02:02,640
One of the big announcements at reinvent this year was the release of Amazon DeepLens,

25
00:02:02,640 --> 00:02:08,320
a fully programmable deep learning enabled wireless video camera designed to help developers

26
00:02:08,320 --> 00:02:13,920
learn and experiment with AI both in the cloud and at the edge.

27
00:02:13,920 --> 00:02:19,640
This is powered by an Intel Atom X5 processor, which delivers up to 100 gigaflops of processing

28
00:02:19,640 --> 00:02:22,480
power to onboard applications.

29
00:02:22,480 --> 00:02:26,440
To learn more about DeepLens and the other interesting things Intel's been up to in the

30
00:02:26,440 --> 00:02:30,840
AI space, check out intelnervana.com.

31
00:02:30,840 --> 00:02:36,800
Today we're joined by Aaron Ames, Professor of Mechanical and Civil Engineering at Caltech.

32
00:02:36,800 --> 00:02:42,040
Aaron joined me before his talk at the reinvent deep learning summit on iRobot, Computer

33
00:02:42,040 --> 00:02:45,120
Vision and Autonomous Robotics.

34
00:02:45,120 --> 00:02:49,840
While Aaron considers himself a hardware guy, we got into a great discussion centered

35
00:02:49,840 --> 00:02:53,040
around the intersection of robotics and machine learning.

36
00:02:53,040 --> 00:02:59,000
We cover a range of topics, including Boston Dynamics's Backflipping Robot and how a system

37
00:02:59,000 --> 00:03:01,360
like that actually works.

38
00:03:01,360 --> 00:03:07,120
As well as the various humanoid robots his own lab is created and more broadly, his views

39
00:03:07,120 --> 00:03:10,840
on the role of end-to-end deep learning in robotics.

40
00:03:10,840 --> 00:03:15,040
I had a blast with this interview and I think you will too.

41
00:03:15,040 --> 00:03:17,840
And now on to the show.

42
00:03:17,840 --> 00:03:29,400
Alright everyone, I am here in Las Vegas at Amazon reinvent and I have the pleasure of

43
00:03:29,400 --> 00:03:31,040
being seated with Aaron Ames.

44
00:03:31,040 --> 00:03:36,920
Aaron is a professor of mechanical and civil engineering at Caltech and he's going to

45
00:03:36,920 --> 00:03:41,200
be speaking here at reinvent tomorrow as part of their deep learning summit.

46
00:03:41,200 --> 00:03:46,040
But as you can tell from his department affiliation, he's not a deep learning guy, he is a robotics

47
00:03:46,040 --> 00:03:49,040
guy, a hardware, a self-professed hardware guy.

48
00:03:49,040 --> 00:03:52,040
Aaron, welcome to this week in machine learning and AI.

49
00:03:52,040 --> 00:03:53,040
Pleasure to be here.

50
00:03:53,040 --> 00:03:54,040
Thanks for having me on the interview.

51
00:03:54,040 --> 00:04:00,480
Yeah, I come from actually algorithms and mathematics is sort of my background and putting

52
00:04:00,480 --> 00:04:02,480
it on hardware.

53
00:04:02,480 --> 00:04:06,880
And it's funny because what I do, I'm speaking at the deep learning summit, I think partially

54
00:04:06,880 --> 00:04:12,280
to give this perspective of how learning and AI algorithms will play out on hardware

55
00:04:12,280 --> 00:04:15,320
platforms and what that connection will be.

56
00:04:15,320 --> 00:04:19,760
So I mean, historically in my research and in research like Boston Dynamics and all

57
00:04:19,760 --> 00:04:23,560
these cool things like the backflip video recently appeared, that was incredible.

58
00:04:23,560 --> 00:04:27,080
It was incredible, but guess how much learning is on those platforms?

59
00:04:27,080 --> 00:04:28,720
Yeah, I imagine not much.

60
00:04:28,720 --> 00:04:29,720
No, zero.

61
00:04:29,720 --> 00:04:30,720
Okay.

62
00:04:30,720 --> 00:04:34,920
I mean, the core in doing these things is to take the dynamics of the system, right?

63
00:04:34,920 --> 00:04:39,640
There's physics driving it and then you develop algorithms using something called control

64
00:04:39,640 --> 00:04:44,800
theory to determine how to move the robot, how to make the actuators move in specific

65
00:04:44,800 --> 00:04:47,000
patterns so that you get these dynamic behaviors.

66
00:04:47,000 --> 00:04:48,000
Right.

67
00:04:48,000 --> 00:04:49,480
So it's heavily tied with the physics, right?

68
00:04:49,480 --> 00:04:53,280
You have the physics, you make decisions based on the physics and it's all very deterministic

69
00:04:53,280 --> 00:04:54,280
and pre-programmed.

70
00:04:54,280 --> 00:04:55,280
Yeah.

71
00:04:55,280 --> 00:04:58,240
So AI on the other hand is a totally different animal.

72
00:04:58,240 --> 00:04:59,240
You start with data.

73
00:04:59,240 --> 00:05:00,880
It's all data driven data centric.

74
00:05:00,880 --> 00:05:05,600
You take examples of things that work well, you know, you label images and then you plug

75
00:05:05,600 --> 00:05:07,240
it into a deep neural network.

76
00:05:07,240 --> 00:05:10,520
There's other variants of learning as well that are a little more mathematical and then

77
00:05:10,520 --> 00:05:14,800
the back end is that it sort of learns or identifies these patterns.

78
00:05:14,800 --> 00:05:15,800
Right.

79
00:05:15,800 --> 00:05:19,600
And that's really exciting because it's computers doing things that we don't always expect

80
00:05:19,600 --> 00:05:23,680
they'll do and they can deal with highly unstructured and data driven approaches.

81
00:05:23,680 --> 00:05:24,680
Yeah.

82
00:05:24,680 --> 00:05:29,480
But it sort of runs contrary to this whole hardware and theoretical approach that's

83
00:05:29,480 --> 00:05:33,160
often taken in robotics because, you know, we need to know everything about the robot.

84
00:05:33,160 --> 00:05:37,800
It has to be very pre-programmed and pre-planned in a specific way.

85
00:05:37,800 --> 00:05:41,480
So the question of the deep learning summit that I'm addressing in my talk is, is what

86
00:05:41,480 --> 00:05:45,680
would this integration kind of look like or a view towards this integration of learning

87
00:05:45,680 --> 00:05:49,440
with hardware and robotic systems?

88
00:05:49,440 --> 00:05:55,320
Something that has yet to actually be done in a good way because they're such different

89
00:05:55,320 --> 00:05:56,320
worlds.

90
00:05:56,320 --> 00:05:58,240
And what's missing from the learning community?

91
00:05:58,240 --> 00:05:59,760
What's missing from the robotics community?

92
00:05:59,760 --> 00:06:01,120
How could they benefit each other?

93
00:06:01,120 --> 00:06:02,120
Right.

94
00:06:02,120 --> 00:06:03,120
Right.

95
00:06:03,120 --> 00:06:04,120
Let's dig into that.

96
00:06:04,120 --> 00:06:06,880
But before we do, I want to make sure that the audience gets to know you a little bit.

97
00:06:06,880 --> 00:06:07,880
Absolutely.

98
00:06:07,880 --> 00:06:12,560
So how did you get interested in algorithms, math, hardware and the way you've put them

99
00:06:12,560 --> 00:06:13,560
all together?

100
00:06:13,560 --> 00:06:14,560
Right.

101
00:06:14,560 --> 00:06:15,560
Science fiction in short.

102
00:06:15,560 --> 00:06:16,560
Okay.

103
00:06:16,560 --> 00:06:17,560
That was driven by science fiction.

104
00:06:17,560 --> 00:06:21,040
When I was in undergrad, all I did was read sci-fi all the time.

105
00:06:21,040 --> 00:06:22,280
Any favorites?

106
00:06:22,280 --> 00:06:24,560
Asmob is guy that go to classic, right?

107
00:06:24,560 --> 00:06:25,560
Yeah.

108
00:06:25,560 --> 00:06:28,040
There's some other great ones, you know, high line, you know, these.

109
00:06:28,040 --> 00:06:31,240
Like the classic authors, I think, had a really unique perspective.

110
00:06:31,240 --> 00:06:36,680
Actually, coming from the authors that sort of started in the 50s, 60s, there was such

111
00:06:36,680 --> 00:06:43,160
imagination to where we'd be, unconstrained by the problems that would later be confronted

112
00:06:43,160 --> 00:06:46,600
in robotics and in all these other things that I think it painted a picture of the world

113
00:06:46,600 --> 00:06:50,840
that was really enticing, of how robots can really work amongst us.

114
00:06:50,840 --> 00:06:54,560
And that's driven me for a long time as this sort of internal fascination.

115
00:06:54,560 --> 00:06:58,920
I can't really explain it on my borderline or maybe not even borderline obsessed with

116
00:06:58,920 --> 00:06:59,920
it.

117
00:06:59,920 --> 00:07:02,280
How do we make robots move like us and do things like us?

118
00:07:02,280 --> 00:07:03,280
Yeah.

119
00:07:03,280 --> 00:07:04,800
So that's driven me for a really long time.

120
00:07:04,800 --> 00:07:06,560
And I wanted to delve into that.

121
00:07:06,560 --> 00:07:09,160
So my background is actually highly theoretic.

122
00:07:09,160 --> 00:07:13,240
I didn't touch hardware until actually after my PhD.

123
00:07:13,240 --> 00:07:16,000
I studied walking, but from a theoretic perspective.

124
00:07:16,000 --> 00:07:20,480
So I really wanted to understand the mathematical underpinnings of locomotion.

125
00:07:20,480 --> 00:07:25,200
And as you start by looking at that from a robotics, a hardware perspective or like human

126
00:07:25,200 --> 00:07:26,200
walking.

127
00:07:26,200 --> 00:07:32,480
I started it from a robotics perspective, but not so much hardware as the mathematics

128
00:07:32,480 --> 00:07:35,800
underlying movement, right, underlying dynamics, right?

129
00:07:35,800 --> 00:07:37,040
And how do we understand that?

130
00:07:37,040 --> 00:07:43,400
How do we even model or formulate a mathematical model of walking and running and doing dynamic

131
00:07:43,400 --> 00:07:44,400
things on robots?

132
00:07:44,400 --> 00:07:48,840
So I delved into that, you know, I proved a lot of theorems on what this might look

133
00:07:48,840 --> 00:07:50,800
like, well, how do we quantify what this is?

134
00:07:50,800 --> 00:07:51,880
How do we characterize it?

135
00:07:51,880 --> 00:07:57,320
So really that, you know, that's sort of the basic science of dynamic robotic movement.

136
00:07:57,320 --> 00:07:58,920
How far have we come in that?

137
00:07:58,920 --> 00:08:03,840
Do we have a strong analytical foundation in locomotion, or is it, you know, do we bump

138
00:08:03,840 --> 00:08:08,680
up against, you know, an edge analytically and have to apply computation to it?

139
00:08:08,680 --> 00:08:09,680
That's an interesting question.

140
00:08:09,680 --> 00:08:14,680
And actually, we have a really strong analytic foundation now for locomotion that's been

141
00:08:14,680 --> 00:08:19,320
developed over the last, I mean, I guess 20 years.

142
00:08:19,320 --> 00:08:20,320
Okay.

143
00:08:20,320 --> 00:08:25,000
Starting sort of a little before I was a grad student, it was in its infancy and I started

144
00:08:25,000 --> 00:08:26,000
working with it.

145
00:08:26,000 --> 00:08:29,800
Other people, great people at other universities have developed these frameworks.

146
00:08:29,800 --> 00:08:32,840
Jesse Grizzell at University of Michigan is one example.

147
00:08:32,840 --> 00:08:36,760
There's lots of people, but we've come a long way in our mathematical understanding of

148
00:08:36,760 --> 00:08:37,760
locomotion.

149
00:08:37,760 --> 00:08:38,760
Yeah.

150
00:08:38,760 --> 00:08:39,760
What the models are.

151
00:08:39,760 --> 00:08:40,760
How do we quantify that behavior?

152
00:08:40,760 --> 00:08:43,040
And there's a lot of papers on this too.

153
00:08:43,040 --> 00:08:45,960
You can understand it mathematically, but what's interesting is we have this mathematical

154
00:08:45,960 --> 00:08:52,880
understanding a while ago now, but computationally realizing that math on hardware was a huge

155
00:08:52,880 --> 00:08:53,880
problem.

156
00:08:53,880 --> 00:08:57,840
So that's where the sort of blockade came is we could write a theorem and we could say,

157
00:08:57,840 --> 00:09:00,520
if this thing exists, then we have walking, right?

158
00:09:00,520 --> 00:09:02,600
But how do you find the thing that exists?

159
00:09:02,600 --> 00:09:04,160
And that's a computational question.

160
00:09:04,160 --> 00:09:08,680
In the end, every mathematical thing you do has to be translated to algorithms on the

161
00:09:08,680 --> 00:09:09,680
robot.

162
00:09:09,680 --> 00:09:10,680
And how do you do that?

163
00:09:10,680 --> 00:09:16,120
It turns out that recently there's been a huge surge in this computation area, huge breakthroughs,

164
00:09:16,120 --> 00:09:20,840
mainly due to the computation breakthroughs that have happened.

165
00:09:20,840 --> 00:09:25,120
So the prevalence of cheap and vast computation.

166
00:09:25,120 --> 00:09:29,760
So it turns out that there's a lot of analogies between making a robot move dynamically and

167
00:09:29,760 --> 00:09:30,760
learn.

168
00:09:30,760 --> 00:09:36,200
What I mean is, in essence, it's a large optimization problem, right?

169
00:09:36,200 --> 00:09:38,200
And that's what the math boils down to.

170
00:09:38,200 --> 00:09:42,440
And how do you solve large-scale optimization problems efficiently?

171
00:09:42,440 --> 00:09:46,360
And there's been some great results recently, some of which have come out of my lab, some

172
00:09:46,360 --> 00:09:51,960
of other labs, a bunch of people collaborating where we can now solve these orders of magnitude

173
00:09:51,960 --> 00:09:54,160
faster than we could 10 years ago.

174
00:09:54,160 --> 00:10:00,280
I mean, it used to be it'd take a day plus to generate one walking behavior for a humanoid

175
00:10:00,280 --> 00:10:01,280
robot, right?

176
00:10:01,280 --> 00:10:06,080
Over a day of computation, if it converged, and as a walking behavior, what does that mean

177
00:10:06,080 --> 00:10:07,320
specifically?

178
00:10:07,320 --> 00:10:14,400
So the way you can think about a walking behavior is a periodic motion that's stable.

179
00:10:14,400 --> 00:10:15,400
Okay.

180
00:10:15,400 --> 00:10:21,040
Given a set of parameters that define us, you know, the hardware or what the, you know,

181
00:10:21,040 --> 00:10:23,080
the joints, the angles, the lengths of the legs.

182
00:10:23,080 --> 00:10:25,440
The masses, the inertia, all that stuff.

183
00:10:25,440 --> 00:10:26,440
So what happens?

184
00:10:26,440 --> 00:10:27,440
That's even lower level, then.

185
00:10:27,440 --> 00:10:28,440
Yeah, yeah.

186
00:10:28,440 --> 00:10:31,120
So you pull all those things together to create a mathematical model, right?

187
00:10:31,120 --> 00:10:35,040
And you get a differential equation, if you like, the technical term.

188
00:10:35,040 --> 00:10:39,480
And it's actually a hybrid system too, meaning there's continuous dynamics.

189
00:10:39,480 --> 00:10:41,440
Think about just a bouncing ball, right?

190
00:10:41,440 --> 00:10:44,960
As almost the simplest example of a walking gate, okay?

191
00:10:44,960 --> 00:10:46,840
What I mean is a periodic motion.

192
00:10:46,840 --> 00:10:49,480
So it falls through the air until it hits the ground.

193
00:10:49,480 --> 00:10:52,600
And then there's a discrete impact that pops it back up.

194
00:10:52,600 --> 00:10:56,000
Now imagine you have a little actuation with that ball, like a little spring, and you

195
00:10:56,000 --> 00:11:01,840
can, you know, then the goal of locomotion is to create a stable, periodic motion.

196
00:11:01,840 --> 00:11:04,600
So the ball bounces at the same height all the time, okay?

197
00:11:04,600 --> 00:11:06,520
That's a very low dimensional example.

198
00:11:06,520 --> 00:11:10,880
Now take a humanoid robot, you take all the physics that go into it, right?

199
00:11:10,880 --> 00:11:15,320
So you have something like, you know, let's say 25 degrees of freedom.

200
00:11:15,320 --> 00:11:20,200
What that means is 25 joints that you can actuate, or other joints that you can't actuate.

201
00:11:20,200 --> 00:11:23,200
The point is 25 things they can move, yeah, all right?

202
00:11:23,200 --> 00:11:26,760
And then you have to take that and you get some mathematical representation of it as a

203
00:11:26,760 --> 00:11:30,200
hybrid system, because there's this, you know, when the legs swinging forward, that's

204
00:11:30,200 --> 00:11:31,200
a continuous dynamic.

205
00:11:31,200 --> 00:11:34,120
It's just like when the ball's falling, then the foot strikes the ground and you get these

206
00:11:34,120 --> 00:11:35,120
impacts.

207
00:11:35,120 --> 00:11:40,040
And then you have to create a periodic motion that coordinates all of those, you know, 25

208
00:11:40,040 --> 00:11:42,960
degrees of freedom together in a synchronous way.

209
00:11:42,960 --> 00:11:47,960
And so do these 25 degrees of freedom translate into, you know, some series of hundreds of

210
00:11:47,960 --> 00:11:49,480
differential equations that you're trying to say?

211
00:11:49,480 --> 00:11:53,520
Yeah, so you actually get two times the number of degrees of freedom, because usually we're

212
00:11:53,520 --> 00:11:54,960
dealing with second order systems.

213
00:11:54,960 --> 00:12:01,080
So you end up with, let's say, 50 equations, 50 ordinary differential equations, right?

214
00:12:01,080 --> 00:12:05,400
Or what, technically, an ordinary differential equation that's 50-dimensional, okay?

215
00:12:05,400 --> 00:12:06,400
Okay.

216
00:12:06,400 --> 00:12:09,400
So you're dealing on some 50-dimensional space of evolution.

217
00:12:09,400 --> 00:12:10,400
Yeah.

218
00:12:10,400 --> 00:12:11,400
So it's a very high-dimensional space.

219
00:12:11,400 --> 00:12:12,400
And that's for simple ones.

220
00:12:12,400 --> 00:12:13,400
It gets even higher.

221
00:12:13,400 --> 00:12:14,560
I mean, take a full humanoid with hands and everything.

222
00:12:14,560 --> 00:12:19,960
You could be dealing with a hundred-dimensional system, plus, and this is all very nonlinear.

223
00:12:19,960 --> 00:12:23,680
And more importantly, it's because you're generating these periodic motions, you have to

224
00:12:23,680 --> 00:12:28,200
really utilize these nonlinear dynamics, the inherent dynamics of the system to generate

225
00:12:28,200 --> 00:12:29,200
these behaviors.

226
00:12:29,200 --> 00:12:30,200
Okay.

227
00:12:30,200 --> 00:12:32,080
And is that mean specifically?

228
00:12:32,080 --> 00:12:36,680
What that means is you can't just to provide an example.

229
00:12:36,680 --> 00:12:37,680
You know, it's funny.

230
00:12:37,680 --> 00:12:40,960
We get a lot of comments on YouTube for our videos, right?

231
00:12:40,960 --> 00:12:45,440
And these are, I actually read them sometimes as I enjoy reading them, although I never respond.

232
00:12:45,440 --> 00:12:48,080
I think that's the key is never responding to comments.

233
00:12:48,080 --> 00:12:49,080
But I like reading them.

234
00:12:49,080 --> 00:12:53,880
And a lot of questions revolve around, well, why not just take a human walking trajectory,

235
00:12:53,880 --> 00:12:54,880
right?

236
00:12:54,880 --> 00:12:57,760
Just record a human walking and pop it on the robot, right?

237
00:12:57,760 --> 00:13:01,120
Well, it's because the physics are different from the human and the robot, right?

238
00:13:01,120 --> 00:13:02,120
Right.

239
00:13:02,120 --> 00:13:06,000
So, what I mean by the nonlinear dynamics is there's only certain trajectories that work

240
00:13:06,000 --> 00:13:10,280
for the system, that make sense, that are consistent with its dynamics.

241
00:13:10,280 --> 00:13:12,280
And those are the ones you have to find.

242
00:13:12,280 --> 00:13:15,880
And you can't just put a human trajectory on, you'd have to modify it so it'd be consistent

243
00:13:15,880 --> 00:13:16,880
with the dynamics.

244
00:13:16,880 --> 00:13:19,000
The robot would have to basically have human physical properties.

245
00:13:19,000 --> 00:13:23,560
Yeah, and human actuation and everything else, it'd have to be perfectly human in some

246
00:13:23,560 --> 00:13:25,560
way, and that's not going to happen.

247
00:13:25,560 --> 00:13:26,560
And it shouldn't.

248
00:13:26,560 --> 00:13:29,760
It's like when we have planes that fly, they don't flap their wings.

249
00:13:29,760 --> 00:13:33,240
You have to exploit the, you know, you want to be inspired by flight.

250
00:13:33,240 --> 00:13:34,240
You want to create lift.

251
00:13:34,240 --> 00:13:35,240
Right.

252
00:13:35,240 --> 00:13:37,240
But you want to do it in a way that's consistent with what we can build.

253
00:13:37,240 --> 00:13:38,240
Right.

254
00:13:38,240 --> 00:13:41,360
So you take all these dynamics just not to get too far in the weeds.

255
00:13:41,360 --> 00:13:46,040
And then you have to create these periodic motions, which again, result in these optimization

256
00:13:46,040 --> 00:13:47,040
problems.

257
00:13:47,040 --> 00:13:48,040
Okay.

258
00:13:48,040 --> 00:13:51,840
You know, you could imagine what these might be, you know, in the sense of, even with

259
00:13:51,840 --> 00:13:54,080
the bouncing ball, you want to create a periodic trajectory.

260
00:13:54,080 --> 00:13:56,440
So start at some point and end at some point.

261
00:13:56,440 --> 00:13:58,880
Those are some constraints on the system, right?

262
00:13:58,880 --> 00:14:01,960
Another constraint, it has to satisfy the dynamics of the ball falling.

263
00:14:01,960 --> 00:14:05,480
So you put all those together and you crunch it into this big optimization.

264
00:14:05,480 --> 00:14:09,840
And we, like I mentioned, we've gone from maybe a day plus to solve these, maybe to down

265
00:14:09,840 --> 00:14:15,440
to a couple of minutes, even faster, sub-second, meaning almost real time, which means we

266
00:14:15,440 --> 00:14:18,560
can generate a gate in really fast, right?

267
00:14:18,560 --> 00:14:20,120
And by a gate, I mean a periodic motion.

268
00:14:20,120 --> 00:14:21,120
Yeah.

269
00:14:21,120 --> 00:14:24,040
And then you can start putting all those together and create advanced behaviors, right?

270
00:14:24,040 --> 00:14:28,280
So that's kind of the paradigm for how you create walking gates or any kind of behavior.

271
00:14:28,280 --> 00:14:30,320
You tell, you know, there was the backflip we mentioned earlier.

272
00:14:30,320 --> 00:14:31,320
How would you do that?

273
00:14:31,320 --> 00:14:33,800
Well, you can actually take the dynamics of that system.

274
00:14:33,800 --> 00:14:38,560
You can set that up as an optimization problem where you go through this motion of flippy.

275
00:14:38,560 --> 00:14:42,280
And then you can crunch it into an optimization problem and generate those motions.

276
00:14:42,280 --> 00:14:44,640
And then pop that on the robot.

277
00:14:44,640 --> 00:14:45,640
And that sounds easy.

278
00:14:45,640 --> 00:14:47,520
There's a lot of difficulty in doing that.

279
00:14:47,520 --> 00:14:50,160
It's a non-trivial adventure to actually implement that.

280
00:14:50,160 --> 00:14:52,200
But that's the general trend.

281
00:14:52,200 --> 00:14:53,480
And there's lots of ways that people do this.

282
00:14:53,480 --> 00:14:56,160
I mean, I don't want to go through all the background, but there's lots of ways people

283
00:14:56,160 --> 00:14:57,600
can generate these periodic motions.

284
00:14:57,600 --> 00:15:02,600
They can have reduced dimensional representations of the system that make it a little faster.

285
00:15:02,600 --> 00:15:04,240
There's a lot of tricks and all this stuff.

286
00:15:04,240 --> 00:15:08,600
But in the end, what you're fundamentally doing, the point of this discussion is to kind

287
00:15:08,600 --> 00:15:15,800
of say, this is the way the robotics community by and large approaches the problem of generating

288
00:15:15,800 --> 00:15:16,800
behaviors on robots.

289
00:15:16,800 --> 00:15:18,440
So they start with the physics.

290
00:15:18,440 --> 00:15:23,080
They set up some sort of optimization problem, computation problem, which generates the,

291
00:15:23,080 --> 00:15:26,200
gives you this periodic motion, which you then put on the robot.

292
00:15:26,200 --> 00:15:32,240
Now, when we see a video like the, you know, people will be familiar with the Boston Dynamics

293
00:15:32,240 --> 00:15:34,480
and the Backflip one that came out recently.

294
00:15:34,480 --> 00:15:39,400
And in fact, you showed me a really interesting one on your YouTube of a robot called Doris,

295
00:15:39,400 --> 00:15:41,000
just part of the interview.

296
00:15:41,000 --> 00:15:45,280
When we see videos like that, and let's take the Backfliping one because it was.

297
00:15:45,280 --> 00:15:46,280
I think everyone's seen it.

298
00:15:46,280 --> 00:15:47,280
So that's fine.

299
00:15:47,280 --> 00:15:48,800
It was, I have to say, it was very impressive.

300
00:15:48,800 --> 00:15:51,880
I mean, Boston Dynamics is always raising the bar for our academics.

301
00:15:51,880 --> 00:15:52,880
Yeah.

302
00:15:52,880 --> 00:15:56,960
You think, you know, you mentioned the Doris, you know, if you look at Doris walking on my

303
00:15:56,960 --> 00:16:01,160
YouTube page and then compare it with some of the walking that Boston Dynamics has, they're

304
00:16:01,160 --> 00:16:02,160
in the ballpark, right?

305
00:16:02,160 --> 00:16:03,160
They are.

306
00:16:03,160 --> 00:16:04,680
I mean, which is something I'm very proud of.

307
00:16:04,680 --> 00:16:07,800
But, you know, they had that stuff a couple of years ago and we now we have the mathematics

308
00:16:07,800 --> 00:16:08,800
to understand it.

309
00:16:08,800 --> 00:16:09,800
And then they do the Backflip.

310
00:16:09,800 --> 00:16:10,800
I'm right.

311
00:16:10,800 --> 00:16:14,560
So now we got to do the Backflip or some variants of that that matches it.

312
00:16:14,560 --> 00:16:17,440
So they raise the bar and they push us, which I think is great, but it's a very impressive

313
00:16:17,440 --> 00:16:18,440
behavior.

314
00:16:18,440 --> 00:16:19,440
Yeah.

315
00:16:19,440 --> 00:16:20,440
And so there's no doubt about it.

316
00:16:20,440 --> 00:16:25,720
But when we look at that, are we seeing a robot, you know, basically performing a script

317
00:16:25,720 --> 00:16:30,600
and it can do, you know, just what we see starting from where it started, you know, going

318
00:16:30,600 --> 00:16:33,400
through every point and space that it saw or is there.

319
00:16:33,400 --> 00:16:34,400
That's exactly right.

320
00:16:34,400 --> 00:16:36,800
That's some parametric thing where there's some variability.

321
00:16:36,800 --> 00:16:37,800
It's a script.

322
00:16:37,800 --> 00:16:38,800
It's a script.

323
00:16:38,800 --> 00:16:39,800
Okay.

324
00:16:39,800 --> 00:16:40,800
And you're exactly right.

325
00:16:40,800 --> 00:16:42,800
And here comes the crux of the problem, right?

326
00:16:42,800 --> 00:16:45,560
And the exciting opportunities.

327
00:16:45,560 --> 00:16:50,040
So, you know, when you, let's now talk about the Backflip with Boston Dynamics, when you

328
00:16:50,040 --> 00:16:53,360
look at that video, I mean, everyone's like, oh, SkyNets coming, the robots are taking

329
00:16:53,360 --> 00:16:54,360
over.

330
00:16:54,360 --> 00:16:55,360
Oh, my God.

331
00:16:55,360 --> 00:16:57,920
And again, we mentioned earlier, and now we don't know exactly what's on the robot, just

332
00:16:57,920 --> 00:17:00,560
to be clear, they don't publicly release anything that's on there.

333
00:17:00,560 --> 00:17:01,560
Right.

334
00:17:01,560 --> 00:17:04,600
Although I've, I know Boston Dynamics well enough to make a very educated guess.

335
00:17:04,600 --> 00:17:09,040
And the guess is based on their past stuff, too, is exactly what you said.

336
00:17:09,040 --> 00:17:11,240
It's a pre-plan behavior.

337
00:17:11,240 --> 00:17:15,360
So this robot has no knowledge of its environment in the sense that it's not observing where

338
00:17:15,360 --> 00:17:22,000
those blocks are, and in real time, adjusting its behavior, and learning how to do this behavior.

339
00:17:22,000 --> 00:17:25,160
They put those obstacles in the memory of the computer.

340
00:17:25,160 --> 00:17:26,800
They pre-plan those behaviors.

341
00:17:26,800 --> 00:17:29,640
They do a bunch of experiments till they get the right behavior.

342
00:17:29,640 --> 00:17:30,680
They take a bunch of videos.

343
00:17:30,680 --> 00:17:35,000
What I loved about that, Blackfoot videos, after the Backflip, they showed failure cases.

344
00:17:35,000 --> 00:17:38,080
Which I thought was, which is important to show, because anytime you see a video of something

345
00:17:38,080 --> 00:17:39,080
working, right?

346
00:17:39,080 --> 00:17:40,080
Right.

347
00:17:40,080 --> 00:17:42,600
There's a thousand or 10,000 cases where it didn't work at all.

348
00:17:42,600 --> 00:17:43,600
Right.

349
00:17:43,600 --> 00:17:45,680
And everything tuned in just right?

350
00:17:45,680 --> 00:17:49,840
As hardware is not quite as clean as the math I talked about.

351
00:17:49,840 --> 00:17:50,840
And then it goes.

352
00:17:50,840 --> 00:17:56,120
So it's a pre-plan behavior that robot has no awareness of what it's doing in a broader

353
00:17:56,120 --> 00:17:57,120
sense.

354
00:17:57,120 --> 00:18:04,360
Even beyond the awareness and learning and ability to, the robot's ability to adjust, you

355
00:18:04,360 --> 00:18:08,520
know, I think when it, you know, it's easy to envision something like that where I guess

356
00:18:08,520 --> 00:18:12,240
I'm thinking of it from like a computer, you know, a computer program perspective.

357
00:18:12,240 --> 00:18:17,480
There's no function that says, you know, Backflip, you know, start from X equals whatever.

358
00:18:17,480 --> 00:18:22,160
It is like a vector of points that it is just following, right?

359
00:18:22,160 --> 00:18:23,160
Yeah, yeah.

360
00:18:23,160 --> 00:18:24,160
Effectively, yeah.

361
00:18:24,160 --> 00:18:28,120
I mean, you can represent these behaviors as sort of modules, right?

362
00:18:28,120 --> 00:18:29,720
If you'd like, like Backflip.

363
00:18:29,720 --> 00:18:30,720
It itself.

364
00:18:30,720 --> 00:18:34,480
I mean, so the thing about dynamic Backflip, like with how many, you know, how much freedom,

365
00:18:34,480 --> 00:18:37,560
like Backflip and you can give it a height and it would on the fly.

366
00:18:37,560 --> 00:18:39,400
And that's, and that's a good question.

367
00:18:39,400 --> 00:18:40,400
Exactly.

368
00:18:40,400 --> 00:18:41,400
Right.

369
00:18:41,400 --> 00:18:45,880
So far, you know, before we get to any conversation about awareness and learning, you're absolutely

370
00:18:45,880 --> 00:18:46,880
right.

371
00:18:46,880 --> 00:18:50,320
And I think this is a very astute question and comment is right now.

372
00:18:50,320 --> 00:18:54,000
I mean, I don't know their exact capabilities, but typically it's Backflip from a height

373
00:18:54,000 --> 00:18:57,200
of this high, maybe with some small variations, right?

374
00:18:57,200 --> 00:19:01,520
But if you, if you change the terrain it was on or change the box or change any of those

375
00:19:01,520 --> 00:19:03,640
parameters, it wouldn't do it.

376
00:19:03,640 --> 00:19:04,640
Right.

377
00:19:04,640 --> 00:19:07,560
In fact, if you look at that video, you look at what it's landing on, it's kind of a somewhat

378
00:19:07,560 --> 00:19:12,600
absorbed, you know, a pad that looks like it has, that it's very carefully constructed.

379
00:19:12,600 --> 00:19:14,080
It's not just a random floor.

380
00:19:14,080 --> 00:19:17,640
There was something special about what they were landing on, partially to absorb the shock

381
00:19:17,640 --> 00:19:18,640
of impact.

382
00:19:18,640 --> 00:19:19,640
I'm sure.

383
00:19:19,640 --> 00:19:23,080
But the point is, as you said, yeah, so there's Backflip as a canonical unit, but that

384
00:19:23,080 --> 00:19:26,120
is very constrained in the environments it can work on.

385
00:19:26,120 --> 00:19:27,120
So you're right.

386
00:19:27,120 --> 00:19:30,160
And this is something that's very important for people to understand, I think, from the

387
00:19:30,160 --> 00:19:36,120
learning perspective, is that we're not like one step away from, you know, self-aware

388
00:19:36,120 --> 00:19:37,760
machines in this context.

389
00:19:37,760 --> 00:19:43,280
I mean, we can do pre-programmed behaviors in environments we completely understand and

390
00:19:43,280 --> 00:19:47,720
have characterized within a small window of perturbation.

391
00:19:47,720 --> 00:19:49,480
And that's what we're getting really good at that.

392
00:19:49,480 --> 00:19:52,800
We couldn't do that 10 years ago, 20 years ago, we couldn't even do that, right?

393
00:19:52,800 --> 00:19:54,680
We couldn't, a robot couldn't do a backflip.

394
00:19:54,680 --> 00:19:58,360
You know, I mean, in, or at least not a humanoid, although Raybert has some great stuff from

395
00:19:58,360 --> 00:20:03,040
the 80s where he had two-legged sort of polo-step type robots that could do backflips back then.

396
00:20:03,040 --> 00:20:06,080
You should go check out some of this stuff from when he was a professor at MIT.

397
00:20:06,080 --> 00:20:07,840
I mean, his old, the 1980s.

398
00:20:07,840 --> 00:20:08,840
Mark Raybert.

399
00:20:08,840 --> 00:20:09,840
Mark Raybert.

400
00:20:09,840 --> 00:20:10,840
Yeah.

401
00:20:10,840 --> 00:20:11,840
He's the head of Boston Dynamics.

402
00:20:11,840 --> 00:20:12,840
He's, it's his brainchild.

403
00:20:12,840 --> 00:20:13,840
Got it.

404
00:20:13,840 --> 00:20:15,320
And he went and founded it from MIT.

405
00:20:15,320 --> 00:20:19,560
He actually started out at JPL, which is part of Caltech, and then Carnegie Mellon, then

406
00:20:19,560 --> 00:20:22,320
MIT, then started Boston Dynamics has been doing that forever.

407
00:20:22,320 --> 00:20:25,960
But if you look at it stuff in the 80s, it has the same characteristic.

408
00:20:25,960 --> 00:20:29,840
If you watch those videos, you see how the backflip came to be on Atlas, right?

409
00:20:29,840 --> 00:20:30,840
Yeah.

410
00:20:30,840 --> 00:20:32,000
And, you know, you can really see the trend.

411
00:20:32,000 --> 00:20:35,720
But again, it's all this very structured thing.

412
00:20:35,720 --> 00:20:40,040
And that leads to what do we do about unstructured environments?

413
00:20:40,040 --> 00:20:41,040
Right.

414
00:20:41,040 --> 00:20:43,960
And this is actually the kind of the core of what I'm going to talk about tomorrow, is

415
00:20:43,960 --> 00:20:46,160
I want to set the stage with just like we had this conversation.

416
00:20:46,160 --> 00:20:49,480
I want to explain what it takes to make a robot walk, because I think when you understand

417
00:20:49,480 --> 00:20:55,400
that or make a robot backflip, you realize how much machinery is there, and how first

418
00:20:55,400 --> 00:20:58,200
you're not going to learn how to do that, really.

419
00:20:58,200 --> 00:20:59,200
Right.

420
00:20:59,200 --> 00:21:01,120
I mean, it's too high-dimensional of a problem for learning.

421
00:21:01,120 --> 00:21:06,840
You're not just going to plug in the actuators and whatever into some deep neural network

422
00:21:06,840 --> 00:21:09,320
and expect the outcome to be a backflip.

423
00:21:09,320 --> 00:21:10,320
You need to...

424
00:21:10,320 --> 00:21:12,640
There's some structure in the system that has to be exploited, right?

425
00:21:12,640 --> 00:21:16,760
So there's a place for control and dynamics, but there's a place for learning too, right?

426
00:21:16,760 --> 00:21:20,040
You know, and I think that's the thing is to understand the right context for it.

427
00:21:20,040 --> 00:21:21,040
Right.

428
00:21:21,040 --> 00:21:23,720
You know, learning will not take over the world and learning will not solve all problems.

429
00:21:23,720 --> 00:21:24,720
Right.

430
00:21:24,720 --> 00:21:27,880
But learning can handle unknown and unforeseen things.

431
00:21:27,880 --> 00:21:28,880
Yeah.

432
00:21:28,880 --> 00:21:32,520
So that's the role it can play in the context of like a backflip.

433
00:21:32,520 --> 00:21:34,960
So how do we go about getting to that?

434
00:21:34,960 --> 00:21:41,720
I mean, it seems like it strikes me that there are lots of, you know, umpteen ways of

435
00:21:41,720 --> 00:21:43,120
kind of attacking that problem.

436
00:21:43,120 --> 00:21:46,880
Like I'm thinking that the thought that comes to mind is like, you know, one approach

437
00:21:46,880 --> 00:21:51,560
might be defining levels of abstraction or primitives or something like that, trying

438
00:21:51,560 --> 00:21:57,000
to figure those out and, you know, I'll have the learning, the intelligence kind of select

439
00:21:57,000 --> 00:21:58,000
those on the fly.

440
00:21:58,000 --> 00:22:02,920
Like, what are the, what's the, you need to come, you need to come, you need to come join

441
00:22:02,920 --> 00:22:05,760
the robotics walking community because you nailed it.

442
00:22:05,760 --> 00:22:10,000
No, the current perspective, I, you know, I even have some papers on this from about

443
00:22:10,000 --> 00:22:14,640
five years ago, now, okay, where we call it motion primitives and transitions, right?

444
00:22:14,640 --> 00:22:18,320
And so basically what you do is you create primitives for all these different behaviors.

445
00:22:18,320 --> 00:22:21,040
Because you're going to have to create the behaviors and now the computation has gotten

446
00:22:21,040 --> 00:22:23,920
better, you can imagine, think about a graph, right?

447
00:22:23,920 --> 00:22:27,760
You know, where every node of the graph, so every point is a behavior.

448
00:22:27,760 --> 00:22:28,760
Okay.

449
00:22:28,760 --> 00:22:30,880
And then you have transitions between those behaviors, right?

450
00:22:30,880 --> 00:22:31,880
Which are admissible.

451
00:22:31,880 --> 00:22:36,440
So you might have backflip followed by walking, followed by going up and down stairs.

452
00:22:36,440 --> 00:22:40,120
You might have a bunch of different primitives for different backflips from different heights

453
00:22:40,120 --> 00:22:44,240
and different terrain types and you can build up this entire compendium.

454
00:22:44,240 --> 00:22:50,440
And then you could supervise how you pick an individual behavior with a learning element.

455
00:22:50,440 --> 00:22:53,080
And this has started to be done that I mentioned Jesse Grisel earlier.

456
00:22:53,080 --> 00:22:55,320
I worked closely with him and have for a really long time.

457
00:22:55,320 --> 00:22:58,960
And he started to play with some of these ideas, putting learning on top of that sort

458
00:22:58,960 --> 00:23:04,000
of motion primitive and transition framework where you decide how what gate to do at any

459
00:23:04,000 --> 00:23:07,680
given time based on what the environment is doing and learning algorithm could do that

460
00:23:07,680 --> 00:23:08,680
really well.

461
00:23:08,680 --> 00:23:10,240
And that's a great place for learning.

462
00:23:10,240 --> 00:23:14,080
And that's a great way of thinking about learning in the sense that you've sort of taken

463
00:23:14,080 --> 00:23:15,560
the dynamics into account.

464
00:23:15,560 --> 00:23:23,080
You've taken the mathematical representation of dynamic motions to their sort of extreme.

465
00:23:23,080 --> 00:23:27,000
You've utilized them all the way and then you let learning do what learning does best,

466
00:23:27,000 --> 00:23:31,640
which is based on input data, the environment, decide what to do on an output, but at a

467
00:23:31,640 --> 00:23:34,160
very high level.

468
00:23:34,160 --> 00:23:38,120
And if you look at the way the human brain works, this is very analogous to how the human

469
00:23:38,120 --> 00:23:39,200
brain and body work.

470
00:23:39,200 --> 00:23:43,160
So, you know, there's not thinking about moving my legs and my legs.

471
00:23:43,160 --> 00:23:44,160
Exactly.

472
00:23:44,160 --> 00:23:45,160
Yeah.

473
00:23:45,160 --> 00:23:46,160
So we have motion primitive.

474
00:23:46,160 --> 00:23:47,160
And we transition between them.

475
00:23:47,160 --> 00:23:48,480
More importantly, the architecture of the human body.

476
00:23:48,480 --> 00:23:52,880
Now I'm not an expert here, but I've certainly read a bit about it.

477
00:23:52,880 --> 00:23:55,480
Just with this paradigm, you know, some people say we should just learn everything because

478
00:23:55,480 --> 00:23:56,960
our brain learns everything.

479
00:23:56,960 --> 00:23:58,520
It's not actually true.

480
00:23:58,520 --> 00:24:02,240
Our brain is responsible for some of our motions, but in our spinal cord, we have a separate

481
00:24:02,240 --> 00:24:03,240
brain.

482
00:24:03,240 --> 00:24:06,960
I mean, in essence, we have patterns that are generated.

483
00:24:06,960 --> 00:24:08,440
Those are your locomotion patterns.

484
00:24:08,440 --> 00:24:09,760
Those are your primitives.

485
00:24:09,760 --> 00:24:13,960
So you couldn't walk essentially with very little cognitive load.

486
00:24:13,960 --> 00:24:16,760
I mean, think about walking and texting on your phone.

487
00:24:16,760 --> 00:24:17,880
You don't have to think about it, right?

488
00:24:17,880 --> 00:24:19,240
So that's the motion primitive acting.

489
00:24:19,240 --> 00:24:22,800
And what happens when you get to a stair, you have to look up from your phone.

490
00:24:22,800 --> 00:24:24,080
You have a cognitive load.

491
00:24:24,080 --> 00:24:25,920
For a second, you have to think, what am I going to do next?

492
00:24:25,920 --> 00:24:28,120
You decide, you go in, you're back to your phone.

493
00:24:28,120 --> 00:24:29,120
Yeah.

494
00:24:29,120 --> 00:24:32,760
So think about any time you could be doing something while on your phone.

495
00:24:32,760 --> 00:24:36,720
That's where dynamics control and all those classic approaches would be used.

496
00:24:36,720 --> 00:24:40,000
Any time you have to look up and see something, that's where machine learning would play

497
00:24:40,000 --> 00:24:41,000
role.

498
00:24:41,000 --> 00:24:42,000
Right?

499
00:24:42,000 --> 00:24:44,600
The real point here is it's not one area or the other.

500
00:24:44,600 --> 00:24:45,600
Right.

501
00:24:45,600 --> 00:24:49,440
We really need to understand the intersection of these two domains.

502
00:24:49,440 --> 00:24:53,440
And that's really the challenge problem of the next decade in my opinion.

503
00:24:53,440 --> 00:24:56,040
Because there's a lot of people that do learning, a lot of people that do robotics.

504
00:24:56,040 --> 00:24:59,640
And there's the beginnings of connecting these up a little bit.

505
00:24:59,640 --> 00:25:03,040
But we need to make a concerted effort to really understand this connection point, because

506
00:25:03,040 --> 00:25:05,240
I think that's sort of the key.

507
00:25:05,240 --> 00:25:13,520
So the kind of using a learning system to plan a goal achievement across some set of

508
00:25:13,520 --> 00:25:15,840
primitives is one approach.

509
00:25:15,840 --> 00:25:18,480
We've already talked about the, you know, we've already thrown out the window.

510
00:25:18,480 --> 00:25:22,640
The idea of learning the motion primitives, you know, from the ground up.

511
00:25:22,640 --> 00:25:27,440
But is there a role in learning and making them more robust?

512
00:25:27,440 --> 00:25:28,440
Yes, absolutely.

513
00:25:28,440 --> 00:25:29,440
Right.

514
00:25:29,440 --> 00:25:30,920
That's the second place where learning comes in.

515
00:25:30,920 --> 00:25:31,920
Okay.

516
00:25:31,920 --> 00:25:32,920
You think we'd have a script?

517
00:25:32,920 --> 00:25:37,760
We had a script for this interview, because you're feeding right into my, my talking research.

518
00:25:37,760 --> 00:25:42,040
So the second place, yes, is where learning plays, will play a big role is not at the level

519
00:25:42,040 --> 00:25:48,400
of planning, but at the level of unknown, unforeseen environments and influences.

520
00:25:48,400 --> 00:25:49,400
Right.

521
00:25:49,400 --> 00:25:51,640
So the simplest example is walking on different terrain.

522
00:25:51,640 --> 00:25:52,640
Yeah.

523
00:25:52,640 --> 00:25:55,600
So when you're walking on flat hard ground, we have a perfect model that, remember that everything

524
00:25:55,600 --> 00:26:00,040
we talked about with generating models was built on the premise of having a model.

525
00:26:00,040 --> 00:26:01,040
Right.

526
00:26:01,040 --> 00:26:05,040
So now if you walk on standard dirt, it turns out there are no models of this.

527
00:26:05,040 --> 00:26:06,200
There's no simple models at least.

528
00:26:06,200 --> 00:26:11,320
I mean, there's people make them make their entire careers about modeling and simulating

529
00:26:11,320 --> 00:26:14,200
granular media, deforming and moving around.

530
00:26:14,200 --> 00:26:18,520
So standing dirt, crunching down, it's a really, really hard problem.

531
00:26:18,520 --> 00:26:23,040
So there won't be some computationally as difficult to just render it as a picture.

532
00:26:23,040 --> 00:26:24,040
Exactly.

533
00:26:24,040 --> 00:26:25,040
Let's try to figure out its physics.

534
00:26:25,040 --> 00:26:26,040
Exactly.

535
00:26:26,040 --> 00:26:27,040
Exactly.

536
00:26:27,040 --> 00:26:31,520
So you could imagine days to generate physics simulations of, of sand movie.

537
00:26:31,520 --> 00:26:35,640
Now if it takes a day to generate a physics simulation of, of a robot putting its foot in

538
00:26:35,640 --> 00:26:38,920
sand, you're probably not going to be real time using those things, right?

539
00:26:38,920 --> 00:26:39,920
Yeah.

540
00:26:39,920 --> 00:26:40,920
So how do we bring it together?

541
00:26:40,920 --> 00:26:43,880
Well, so we have some initial work with some colleagues I have at Georgia Tech on

542
00:26:43,880 --> 00:26:48,400
this idea where we learn how to hop in granular terrain.

543
00:26:48,400 --> 00:26:50,080
And so we don't use neural nets there.

544
00:26:50,080 --> 00:26:53,800
We use something called Gaussian processes, which are another way of learning, but it's

545
00:26:53,800 --> 00:26:56,080
not the neural net way.

546
00:26:56,080 --> 00:27:02,000
It's a variant that basically deals with some initial guess on the model and then you update

547
00:27:02,000 --> 00:27:04,880
that model as new data comes in.

548
00:27:04,880 --> 00:27:10,400
And we were able to not know what the tray model was, but have a guess based on some physics.

549
00:27:10,400 --> 00:27:14,880
And then every time the robot would hop in the, in the train, we'd take that data in and

550
00:27:14,880 --> 00:27:18,680
update the model of what the terrain forces look like.

551
00:27:18,680 --> 00:27:21,040
We iterated that through the optimization problem.

552
00:27:21,040 --> 00:27:24,960
So we'd update that every time we, we had a new hop, we'd take this new information,

553
00:27:24,960 --> 00:27:29,880
we generate a new model of the physics interaction with the world, and then we'd run the optimization

554
00:27:29,880 --> 00:27:30,880
with that new model.

555
00:27:30,880 --> 00:27:35,640
And now are we talking about something that's done in simulation as far as learning process

556
00:27:35,640 --> 00:27:36,640
or?

557
00:27:36,640 --> 00:27:38,040
No, we did this on hardware.

558
00:27:38,040 --> 00:27:39,040
Okay.

559
00:27:39,040 --> 00:27:43,520
I mean, we verified in simulation, but really, you, this would have to be on the hardware

560
00:27:43,520 --> 00:27:45,360
because you need the data.

561
00:27:45,360 --> 00:27:46,360
Okay.

562
00:27:46,360 --> 00:27:47,360
Right.

563
00:27:47,360 --> 00:27:48,960
You need to sense what's happening with the environment.

564
00:27:48,960 --> 00:27:49,960
Right.

565
00:27:49,960 --> 00:27:52,000
Because we don't have the models to put in the simulation.

566
00:27:52,000 --> 00:27:54,680
So this is now a data driven modification.

567
00:27:54,680 --> 00:28:01,600
So where we can combine the data with learning that model of the environment with the optimization

568
00:28:01,600 --> 00:28:05,120
framework that I discussed earlier in a feedback loop.

569
00:28:05,120 --> 00:28:08,480
And we did that and we were able to actually, so we wanted to hop, I mean, this is a very

570
00:28:08,480 --> 00:28:09,480
simple robot.

571
00:28:09,480 --> 00:28:12,320
So this is not a walking robot, but it's kind of like, think about the bouncing ball again

572
00:28:12,320 --> 00:28:14,000
where we're going back to the basics.

573
00:28:14,000 --> 00:28:16,880
We wanted to make this thing hop at a specific height.

574
00:28:16,880 --> 00:28:21,640
We'd first tried without having a model of the granular train, and it wouldn't do it.

575
00:28:21,640 --> 00:28:25,560
Is this a, I'm getting hung up on the form factor here.

576
00:28:25,560 --> 00:28:30,720
Is this like a standalone robot that is, you know, what does this thing look like?

577
00:28:30,720 --> 00:28:31,720
All right.

578
00:28:31,720 --> 00:28:32,720
So that's a good question.

579
00:28:32,720 --> 00:28:33,720
Yeah.

580
00:28:33,720 --> 00:28:34,720
And is it suspended?

581
00:28:34,720 --> 00:28:35,720
Yeah.

582
00:28:35,720 --> 00:28:36,720
And some, you know, is it fixed in somewhere?

583
00:28:36,720 --> 00:28:37,720
Yeah.

584
00:28:37,720 --> 00:28:42,760
So this is a very, this was a very simple test bed meant to generate physics of terrain

585
00:28:42,760 --> 00:28:43,760
interaction.

586
00:28:43,760 --> 00:28:47,080
It was actually developed by a colleague of mine, Dan Goldman at Georgia Tech, who is a

587
00:28:47,080 --> 00:28:48,080
physicist.

588
00:28:48,080 --> 00:28:51,280
And this is work with Patricia Vella as well at Georgia Tech, who does machine learning

589
00:28:51,280 --> 00:28:52,280
stuff.

590
00:28:52,280 --> 00:28:53,840
So it's, it's a very simple thing.

591
00:28:53,840 --> 00:28:59,960
It's a motor with a spring between the, basically, the motor and the world.

592
00:28:59,960 --> 00:29:00,960
Okay.

593
00:29:00,960 --> 00:29:01,960
Okay.

594
00:29:01,960 --> 00:29:05,960
So basically it can, it can move a mass up and down to make this thing move on top of

595
00:29:05,960 --> 00:29:06,960
the spring.

596
00:29:06,960 --> 00:29:07,960
And then there's a spring.

597
00:29:07,960 --> 00:29:11,880
And then there's like a foot, right, between the granular terrain.

598
00:29:11,880 --> 00:29:12,880
Right.

599
00:29:12,880 --> 00:29:15,760
So it's, so this thing is only moving one dimension, it's a one dimensional, it's a one

600
00:29:15,760 --> 00:29:16,760
dimensional hopper.

601
00:29:16,760 --> 00:29:17,760
Yeah.

602
00:29:17,760 --> 00:29:18,760
It's one dimensional hopper.

603
00:29:18,760 --> 00:29:19,760
That's right.

604
00:29:19,760 --> 00:29:22,840
So again, any, any, what it does is it sits in a bed of poppy seeds.

605
00:29:22,840 --> 00:29:25,880
His poppy seeds are actually a really good model of different sand and dirt, but they

606
00:29:25,880 --> 00:29:28,720
don't get caught up in the actuator because they're big enough that they don't get into

607
00:29:28,720 --> 00:29:29,720
all the things.

608
00:29:29,720 --> 00:29:30,720
Okay.

609
00:29:30,720 --> 00:29:31,720
And the, and the details.

610
00:29:31,720 --> 00:29:32,720
Exactly.

611
00:29:32,720 --> 00:29:36,640
And what actually you do is is there's this bed of poppy seeds, but you don't want to

612
00:29:36,640 --> 00:29:40,120
have it be changing every time you hop on it because you can compact them.

613
00:29:40,120 --> 00:29:41,520
So it'd be more like hard terrain.

614
00:29:41,520 --> 00:29:44,280
So it actually aerates the bed between every hop.

615
00:29:44,280 --> 00:29:49,240
So you sort of move the poppy seeds, let them settle hop, let them settle hop.

616
00:29:49,240 --> 00:29:54,680
So you, you do a successive experiments where you have the same kind of initial condition

617
00:29:54,680 --> 00:29:58,640
in the poppy seeds just to make sure you have a consistent model you're learning.

618
00:29:58,640 --> 00:29:59,640
So that's a setup.

619
00:29:59,640 --> 00:30:01,480
So it's a very isolated little box.

620
00:30:01,480 --> 00:30:06,120
And then you can use vision or anything else to, to kind of identify what the forces are

621
00:30:06,120 --> 00:30:07,960
between the robot and the terrain.

622
00:30:07,960 --> 00:30:08,960
Okay.

623
00:30:08,960 --> 00:30:09,960
And so, and then we ran this experiment.

624
00:30:09,960 --> 00:30:12,240
Again, this was a proof of concept.

625
00:30:12,240 --> 00:30:15,600
It's probably one of the first examples of putting all these pieces together.

626
00:30:15,600 --> 00:30:18,200
And it kind of shows you, and this is an important point.

627
00:30:18,200 --> 00:30:23,080
It shows you where we're at in, you know, find learning and control and dynamics.

628
00:30:23,080 --> 00:30:27,680
If we have to go back to a 1D hopper and we're, and we publish a paper on it because it's

629
00:30:27,680 --> 00:30:32,440
new and interesting, right, as opposed to a humanoid robot, which is, you know, so you

630
00:30:32,440 --> 00:30:35,360
can imagine that we're just beginning this process and there's some other people working

631
00:30:35,360 --> 00:30:36,360
on this domain as well.

632
00:30:36,360 --> 00:30:41,200
But it's kind of, isn't it scary if you can just watch a beach and just say, yeah, exactly.

633
00:30:41,200 --> 00:30:42,200
Yes.

634
00:30:42,200 --> 00:30:43,680
And that's my advice to anybody.

635
00:30:43,680 --> 00:30:47,480
If a robot has changed and you try to kill it, you just run to a beach and you're going

636
00:30:47,480 --> 00:30:48,800
to be fun.

637
00:30:48,800 --> 00:30:53,720
So, or go on some ice or snow or something, you know, and it'll fall over.

638
00:30:53,720 --> 00:30:54,720
You'll be safe.

639
00:30:54,720 --> 00:30:55,720
Yeah.

640
00:30:55,720 --> 00:30:56,720
That's right.

641
00:30:56,720 --> 00:30:57,720
Huh.

642
00:30:57,720 --> 00:31:01,560
So we, we got those two pieces of learning like what's, what's next?

643
00:31:01,560 --> 00:31:09,480
I think it's, I mean, I think you did a good job exactly parsing the two forefronts is

644
00:31:09,480 --> 00:31:13,360
that we need to push in terms of machine learning on robotic systems.

645
00:31:13,360 --> 00:31:19,000
It's really, this is the key point is there's a lot of work right now on learning as a stand

646
00:31:19,000 --> 00:31:20,600
alone entity, right?

647
00:31:20,600 --> 00:31:21,600
Learn everything.

648
00:31:21,600 --> 00:31:22,600
Right.

649
00:31:22,600 --> 00:31:26,480
And with this, if I can interrupt, as a point of reference for folks that are listening

650
00:31:26,480 --> 00:31:30,320
that want to hear a little bit more about that perspective, a good place to start would

651
00:31:30,320 --> 00:31:35,720
be the interview I did with Peter Abiel, you would be, yes, I know Peter, well, I know.

652
00:31:35,720 --> 00:31:37,680
So Peter is precise, he does fantastic work.

653
00:31:37,680 --> 00:31:43,720
I really respect the work he does, but the idea there is to learn everything.

654
00:31:43,720 --> 00:31:44,720
Right.

655
00:31:44,720 --> 00:31:45,720
And we talked about that.

656
00:31:45,720 --> 00:31:46,720
Yeah.

657
00:31:46,720 --> 00:31:50,520
And I am very strong and adamant is that that is not the right answer.

658
00:31:50,520 --> 00:31:52,720
Now, people will disagree with me and that's okay.

659
00:31:52,720 --> 00:31:54,360
It's okay to disagree in academia.

660
00:31:54,360 --> 00:31:55,960
It shows that the problems aren't solved.

661
00:31:55,960 --> 00:32:00,280
There's no, you know, physical systems, robot arms, even, you know, he does manipulation.

662
00:32:00,280 --> 00:32:01,280
And stuff.

663
00:32:01,280 --> 00:32:03,200
Have this wonderful structure we can exploit.

664
00:32:03,200 --> 00:32:04,200
Yeah.

665
00:32:04,200 --> 00:32:08,000
They might be high dimensional, but they live on manifolds, which are low dimensional

666
00:32:08,000 --> 00:32:10,640
surfaces in this high dimensional space.

667
00:32:10,640 --> 00:32:15,440
Let's use physics and control to push the system to this low dimensional space and then

668
00:32:15,440 --> 00:32:16,840
learn on that space.

669
00:32:16,840 --> 00:32:20,120
It will work orders of magnitude better, I promise, right?

670
00:32:20,120 --> 00:32:25,040
Well, I promise in that, I think I'm right with my opinion, which I may be wrong, and that

671
00:32:25,040 --> 00:32:26,040
would be great.

672
00:32:26,040 --> 00:32:31,160
And at the point when, when a robot does a back flip with no knowledge of his physics

673
00:32:31,160 --> 00:32:36,160
or dynamics, a humanoid robot, then I'll be like, okay, I am ready to listen to the pure

674
00:32:36,160 --> 00:32:37,160
learning approach.

675
00:32:37,160 --> 00:32:41,000
But, you know, then the robotics community, the proof is in the pudding, right?

676
00:32:41,000 --> 00:32:44,000
You know, as they sometimes say, the proof is on the robot.

677
00:32:44,000 --> 00:32:49,760
So, and the reality is we can do so much more with zero learning, model based approaches

678
00:32:49,760 --> 00:32:53,040
on physical hardware than we can with learning.

679
00:32:53,040 --> 00:32:55,960
Now that being said, I'm not trying to advocate that that's the end of the story.

680
00:32:55,960 --> 00:32:59,840
Like I've said through this whole interview, there's limitations to this.

681
00:32:59,840 --> 00:33:02,280
And that's where learning will play a huge role.

682
00:33:02,280 --> 00:33:05,600
So I think the forefront is don't learn everything.

683
00:33:05,600 --> 00:33:09,440
Don't fall into this trap of a big shiny black box that you put in what you want, and it

684
00:33:09,440 --> 00:33:12,040
spits out the right answer.

685
00:33:12,040 --> 00:33:16,280
If only because from a scientific perspective, I find that very unsatisfying too, that's

686
00:33:16,280 --> 00:33:17,960
a separate point.

687
00:33:17,960 --> 00:33:24,120
But I, my opinion is don't fall into that paradigm because you're, you're restricting,

688
00:33:24,120 --> 00:33:29,080
or you're limiting yourself in your worldview instead, unify, unify, unify, unify.

689
00:33:29,080 --> 00:33:33,160
So that's my argument on the forefront of learning is what, what else does unify

690
00:33:33,160 --> 00:33:34,160
mean for you?

691
00:33:34,160 --> 00:33:41,880
I mean, bring the learning, physics, dynamics, computation, control, mechanical design, actuators,

692
00:33:41,880 --> 00:33:42,880
all those pieces.

693
00:33:42,880 --> 00:33:47,680
What's beautiful about robots is they are a microcosm of the universe in some way.

694
00:33:47,680 --> 00:33:52,680
They're completely self-consistent systems that you have complete control and you create.

695
00:33:52,680 --> 00:33:53,680
Yeah.

696
00:33:53,680 --> 00:33:57,240
You have computation, you have actuators, you have all these wonderful things.

697
00:33:57,240 --> 00:34:02,600
So use that, you know, and understand those different pieces at a deep level, and then

698
00:34:02,600 --> 00:34:04,360
you'll really understand how to put them together.

699
00:34:04,360 --> 00:34:10,280
So that's what I mean, unify, unify, all of computation, control, design, and learning.

700
00:34:10,280 --> 00:34:15,680
Understand where they all fit together relative, use the strengths of each, you know, to exploit

701
00:34:15,680 --> 00:34:16,680
them to their maximum.

702
00:34:16,680 --> 00:34:22,200
And that's where I think the really fun stuff is going to come in the next couple years,

703
00:34:22,200 --> 00:34:23,200
in my opinion.

704
00:34:23,200 --> 00:34:27,120
You know, I could be dead wrong in a year from now, if I am, I'm happy to admit it.

705
00:34:27,120 --> 00:34:31,080
But I think that's really where the future is in terms of learning and roboticism.

706
00:34:31,080 --> 00:34:34,360
And do you have any predictions in terms of what that really fun stuff is going to look

707
00:34:34,360 --> 00:34:35,640
like for us?

708
00:34:35,640 --> 00:34:39,480
The forefront is the following, in my opinion, it's getting robots out of the lab into

709
00:34:39,480 --> 00:34:40,480
the lab.

710
00:34:40,480 --> 00:34:42,840
You know, there's been a couple examples of that.

711
00:34:42,840 --> 00:34:45,440
We've taken some of our robots out of the lab in limited context.

712
00:34:45,440 --> 00:34:48,480
Boston and Amick still has some of the best videos where I was walking around kind of

713
00:34:48,480 --> 00:34:49,720
in snow and stuff like that, right?

714
00:34:49,720 --> 00:34:50,720
Yeah.

715
00:34:50,720 --> 00:34:51,720
That was purely a result of that.

716
00:34:51,720 --> 00:34:56,760
Actually, the four, the four-legged ones are the, they had a biped outside in the snow

717
00:34:56,760 --> 00:34:57,760
in one video.

718
00:34:57,760 --> 00:34:59,680
It was about a year or two years ago now.

719
00:34:59,680 --> 00:35:01,640
And again, remember, that's purely reactive.

720
00:35:01,640 --> 00:35:02,640
There was no learning there.

721
00:35:02,640 --> 00:35:06,680
It was walking in snow and on uneven terrain, only through the robustness of the algorithms

722
00:35:06,680 --> 00:35:08,000
that are on there, right?

723
00:35:08,000 --> 00:35:12,960
So, but I think that's really the forefront is, you know, get out of structured environments,

724
00:35:12,960 --> 00:35:17,400
get out of the lab and get on dynamic systems.

725
00:35:17,400 --> 00:35:24,960
So I'm very, very pure, for example, manipulation tasks as they're deceptive in their simplicity.

726
00:35:24,960 --> 00:35:29,200
You know, when a robot can't fall over, you can always correct, right?

727
00:35:29,200 --> 00:35:35,160
And there's a robustness there that when you go to humanoid robots and dynamic robots,

728
00:35:35,160 --> 00:35:36,480
you don't have anymore.

729
00:35:36,480 --> 00:35:41,000
So get a dynamic robotic system, whatever that is, a four-legged robot, a two-legged robot,

730
00:35:41,000 --> 00:35:45,760
a hopping robot, whatever it happens to be out into the real world and make it do cool

731
00:35:45,760 --> 00:35:46,920
stuff.

732
00:35:46,920 --> 00:35:51,560
And that's to me the way of really proving that you understand what's going on, you know,

733
00:35:51,560 --> 00:35:56,400
because that will take all these things we mentioned, especially in an autonomous context.

734
00:35:56,400 --> 00:35:57,840
So this is the second point.

735
00:35:57,840 --> 00:36:01,880
We actually just started a center for autonomy at Caltech called Cast.

736
00:36:01,880 --> 00:36:08,000
And it's really aimed at doing these things is how do we get robots into the wild and not

737
00:36:08,000 --> 00:36:10,080
prescript them all the way, right?

738
00:36:10,080 --> 00:36:14,400
And that's really what I mean by getting into the wild is tell a robot go from A to B outside,

739
00:36:14,400 --> 00:36:15,400
right?

740
00:36:15,400 --> 00:36:19,400
Walking robot or humanoid robot and by A to B it might be over a beach.

741
00:36:19,400 --> 00:36:22,000
It might be, you know, through some ice and snow.

742
00:36:22,000 --> 00:36:23,760
How do we do that?

743
00:36:23,760 --> 00:36:24,760
What's that?

744
00:36:24,760 --> 00:36:29,080
So we actually frame these questions in the context of moonshots for Cast.

745
00:36:29,080 --> 00:36:30,080
Okay.

746
00:36:30,080 --> 00:36:35,920
So just to give us a sense of how hard they are and by moonshot it really a lot of these

747
00:36:35,920 --> 00:36:40,320
are moonshots, meaning we could do it if we had massive amount of resources and people

748
00:36:40,320 --> 00:36:45,760
concerted, but one example of a moonshot is have a robot walk the Pacific Crest Trail.

749
00:36:45,760 --> 00:36:51,360
So this is a trail that goes from Mexico to Canada and have it do it autonomously.

750
00:36:51,360 --> 00:36:56,880
So what would it take to do that, you know, and that exactly would require all the pieces

751
00:36:56,880 --> 00:37:00,520
we've discussed today, plus many more that we don't even know, we don't know yet.

752
00:37:00,520 --> 00:37:05,560
But that's the kind of thing we need to be thinking about I think is pushing these boundaries

753
00:37:05,560 --> 00:37:07,440
of what we can do with robotic systems.

754
00:37:07,440 --> 00:37:11,800
And in an autonomous way, so bringing autonomy in it and bringing them and understanding

755
00:37:11,800 --> 00:37:15,720
how that fits with both the mathematical representation of behaviors and learning and

756
00:37:15,720 --> 00:37:17,640
where those each can play a role.

757
00:37:17,640 --> 00:37:21,360
So to me, that's the direction of push.

758
00:37:21,360 --> 00:37:24,520
It's challenging, but fun, but it's time for the real world.

759
00:37:24,520 --> 00:37:25,520
It's kind of where we're at.

760
00:37:25,520 --> 00:37:28,560
For a long time, we couldn't even get robust to do stuff in our labs that was all that

761
00:37:28,560 --> 00:37:29,560
interesting.

762
00:37:29,560 --> 00:37:33,440
And now we're at the point where we can do some cool stuff in our labs, so leave the lab.

763
00:37:33,440 --> 00:37:36,760
When I'm struggling with a little bit and trying to bridge our early conversation about

764
00:37:36,760 --> 00:37:44,440
these very scripted, rigid tasks, and even some of the stuff that the Boston Dynamics

765
00:37:44,440 --> 00:37:49,560
kind of walking in snow, we have to be incorporating in sensors.

766
00:37:49,560 --> 00:37:55,000
Is even the most primitive stuff is that I'm thinking of that as just kind of the actuators

767
00:37:55,000 --> 00:37:57,840
and not sensors or is that not the way to think about it?

768
00:37:57,840 --> 00:38:01,840
I mean, they all have sensors, the question is, what are the sensors doing and what information

769
00:38:01,840 --> 00:38:02,840
are they taking?

770
00:38:02,840 --> 00:38:03,840
Yeah.

771
00:38:03,840 --> 00:38:06,080
And how are they fit into it?

772
00:38:06,080 --> 00:38:08,200
These sensors are part of all of this.

773
00:38:08,200 --> 00:38:10,960
The question is, what sensors and what are they sensing?

774
00:38:10,960 --> 00:38:15,800
So for all the, from the back flip on, again, I can't speak, I know they're hardware all

775
00:38:15,800 --> 00:38:19,800
the way in, but roughly speaking, you have encoders that look at the angles of all the

776
00:38:19,800 --> 00:38:20,800
joints.

777
00:38:20,800 --> 00:38:24,160
You have an IMU, a inertial measurement unit that tells you the global orientation of the

778
00:38:24,160 --> 00:38:25,160
robot, right?

779
00:38:25,160 --> 00:38:26,160
Some accelerometers.

780
00:38:26,160 --> 00:38:27,160
Some accelerometers in that case.

781
00:38:27,160 --> 00:38:28,160
Exactly.

782
00:38:28,160 --> 00:38:29,160
Exactly.

783
00:38:29,160 --> 00:38:31,760
And then there's sometimes some sort of sensing of the environment, has your flip touched

784
00:38:31,760 --> 00:38:33,400
down, and that's a pretty essential one.

785
00:38:33,400 --> 00:38:35,120
So when we walk with Doris, I can tell you that.

786
00:38:35,120 --> 00:38:37,720
But we need are those three main components.

787
00:38:37,720 --> 00:38:39,400
We need to know when the foot's on the ground.

788
00:38:39,400 --> 00:38:43,480
So since the impact with the ground, we need to know what the angles are on all the joints.

789
00:38:43,480 --> 00:38:49,880
And we need to know, again, an IMU, an accelerometer, we need to know the global orientation of

790
00:38:49,880 --> 00:38:51,840
the robot relative to the robot.

791
00:38:51,840 --> 00:38:58,040
Those three pieces of his information are all you really need to have a robot do a dynamic

792
00:38:58,040 --> 00:39:00,600
thing in a constrained context.

793
00:39:00,600 --> 00:39:01,600
Right?

794
00:39:01,600 --> 00:39:02,920
That means you know the environment, right?

795
00:39:02,920 --> 00:39:07,320
You don't need computer vision if you know how high the blocks are and where they're located

796
00:39:07,320 --> 00:39:08,320
relative to the robot.

797
00:39:08,320 --> 00:39:10,880
And you set the robot up in the same spot every time, right?

798
00:39:10,880 --> 00:39:14,440
So obviously when you start to do more unstructured things, you're going to have to bring in other

799
00:39:14,440 --> 00:39:17,000
sensors, cameras, of course.

800
00:39:17,000 --> 00:39:20,840
And that's one, you know, Pietro Perona's talking, another professor at Caltech is talking

801
00:39:20,840 --> 00:39:24,360
with me at the machine learning summit, and he does computer vision.

802
00:39:24,360 --> 00:39:27,000
And we've started to say, how can we integrate these two pieces together?

803
00:39:27,000 --> 00:39:30,840
So we actually have a robot in our lab called Cassie, where we, he did his algorithms to

804
00:39:30,840 --> 00:39:34,800
parse, you know, where they can determine the pose of people.

805
00:39:34,800 --> 00:39:37,760
And we want to use those pose information to have the robot do something.

806
00:39:37,760 --> 00:39:42,520
So we want the vision of the robot, what the robot's seen, to feed into its behaviors.

807
00:39:42,520 --> 00:39:43,520
Right?

808
00:39:43,520 --> 00:39:45,280
And we're just starting this track, but that gives you an idea.

809
00:39:45,280 --> 00:39:47,200
So in this case, we need a vision system.

810
00:39:47,200 --> 00:39:48,200
You might need four sensors.

811
00:39:48,200 --> 00:39:51,440
If you're going to observe the environment for the hopping behaviors we discussed, you're

812
00:39:51,440 --> 00:39:55,680
going to need to have a really nice notion of what the forces are on the system.

813
00:39:55,680 --> 00:39:58,360
So the more, the more you want to do, the more sensors you need.

814
00:39:58,360 --> 00:39:59,360
Yeah.

815
00:39:59,360 --> 00:40:04,120
And then going back in our conversation, this is very consistent with the perspective

816
00:40:04,120 --> 00:40:05,880
of the human body.

817
00:40:05,880 --> 00:40:10,800
So if you want to walk on flat ground with no obstacles, you can actually, you need very

818
00:40:10,800 --> 00:40:12,280
little sensors, right?

819
00:40:12,280 --> 00:40:16,120
You kind of know when your foot strikes the ground and the rest is pretty, right?

820
00:40:16,120 --> 00:40:20,120
If you've never been on ice before and you take somebody on ice, look at the way they

821
00:40:20,120 --> 00:40:21,120
have sensing.

822
00:40:21,120 --> 00:40:22,120
They're doing a lot of sensing.

823
00:40:22,120 --> 00:40:24,640
They're doing a lot of computation because they're learning, but then watch a couple

824
00:40:24,640 --> 00:40:29,840
minutes on ice and people kind of settle in and they're clearly, they've whittled down.

825
00:40:29,840 --> 00:40:32,880
They've taken all their sensor information and they've decided which sensor information

826
00:40:32,880 --> 00:40:34,120
is important.

827
00:40:34,120 --> 00:40:35,320
And they're using that.

828
00:40:35,320 --> 00:40:37,920
And that's part of the problem, too, is how do you take all this information in with

829
00:40:37,920 --> 00:40:41,280
your environment and whittle out the stuff that's actually relevant to what you're trying

830
00:40:41,280 --> 00:40:43,200
to do and an individual motion permit?

831
00:40:43,200 --> 00:40:47,680
I think that's a great example or a great way of articulating it that really gets at what

832
00:40:47,680 --> 00:40:49,200
what I was struggling with.

833
00:40:49,200 --> 00:40:52,600
It's the, you know, when you think about the human on the ice, there's, you know, there's

834
00:40:52,600 --> 00:40:58,440
that bit of learning and, you know, if you take that to, I'm trying to, trying to reconcile

835
00:40:58,440 --> 00:41:03,480
that with, you know, the Boston, the Boston time I was walking in the snow.

836
00:41:03,480 --> 00:41:08,080
You know, that, you're, we're saying that that robot is not learning like what is it doing

837
00:41:08,080 --> 00:41:12,200
with that sensor data that's allowing it to be more robust than, you know, what we

838
00:41:12,200 --> 00:41:13,200
do.

839
00:41:13,200 --> 00:41:14,200
Well, okay.

840
00:41:14,200 --> 00:41:18,720
So, you notice it was walking in snow and up, you know, small terrain differences, but

841
00:41:18,720 --> 00:41:20,080
not ice.

842
00:41:20,080 --> 00:41:23,320
So the deciding factor here is friction.

843
00:41:23,320 --> 00:41:27,560
So as long as it has sufficient friction when the foot touches down, you can do the same

844
00:41:27,560 --> 00:41:32,680
behavior you do on firm ground on non-firm ground as long as it's reasonably close, right?

845
00:41:32,680 --> 00:41:37,080
As long as the foot doesn't slip as long as, or not too much, or if it slips, you can

846
00:41:37,080 --> 00:41:38,080
catch yourself.

847
00:41:38,080 --> 00:41:42,840
I may be confusing videos in MMI's, but there's one where like it's winning up here.

848
00:41:42,840 --> 00:41:43,840
Oh, it slips on ice.

849
00:41:43,840 --> 00:41:44,840
Yeah.

850
00:41:44,840 --> 00:41:47,080
And there's one where it even slips on icing and catches itself, right?

851
00:41:47,080 --> 00:41:51,720
And again, it slips on a small patch of ice and catches itself and then it's off the

852
00:41:51,720 --> 00:41:52,720
ice.

853
00:41:52,720 --> 00:41:53,720
Yeah.

854
00:41:53,720 --> 00:41:56,720
This is, I think, what your question is and where we can separate is that there's a difference

855
00:41:56,720 --> 00:42:03,360
between reactive behavior that's robust enough to handle terrain differences with learning

856
00:42:03,360 --> 00:42:05,320
a new behavior itself.

857
00:42:05,320 --> 00:42:06,320
Yes.

858
00:42:06,320 --> 00:42:07,320
And that's the difference.

859
00:42:07,320 --> 00:42:12,640
So if you're walking along and you slip on a little puddle, right?

860
00:42:12,640 --> 00:42:16,360
Watch a person when they slip, they go, right, and they catch themselves and then they

861
00:42:16,360 --> 00:42:17,360
keep walking.

862
00:42:17,360 --> 00:42:18,360
That's not a learned behavior.

863
00:42:18,360 --> 00:42:20,320
That's a reactive behavior, right?

864
00:42:20,320 --> 00:42:21,680
Or you miss a step.

865
00:42:21,680 --> 00:42:22,680
That's a great one.

866
00:42:22,680 --> 00:42:25,520
When people don't know a step's coming and there's a step, and then you see them fall,

867
00:42:25,520 --> 00:42:27,600
and then you know this feeling too, right?

868
00:42:27,600 --> 00:42:32,120
You're already falling and catching yourself when you realize, oh, I just fell down a step,

869
00:42:32,120 --> 00:42:33,120
right?

870
00:42:33,120 --> 00:42:36,080
Your body's doing stuff before you even realize what's happened, right?

871
00:42:36,080 --> 00:42:37,080
So that's a great example.

872
00:42:37,080 --> 00:42:41,960
So next time you fall, please, I mean, hopefully I don't fall on purpose, but after you kind

873
00:42:41,960 --> 00:42:45,440
of catch yourself from falling, think back and realize you did all that stuff before

874
00:42:45,440 --> 00:42:47,400
you even thought about what you were doing.

875
00:42:47,400 --> 00:42:48,400
That's reactive.

876
00:42:48,400 --> 00:42:49,920
So that's what Boston Dynamics does.

877
00:42:49,920 --> 00:42:54,120
Their controllers are so robust and they're very impressively robust that they can react

878
00:42:54,120 --> 00:42:56,280
to all these different things and be robust to it.

879
00:42:56,280 --> 00:43:02,040
It's not fair to say that, you know, it's simply kind of actuating, you know, these motors

880
00:43:02,040 --> 00:43:07,200
through a series of pre-plan points and, you know, that's how it's doing, you know, walking

881
00:43:07,200 --> 00:43:11,960
or doing flips or something like, it's more, it's more robust, it's more hierarchical.

882
00:43:11,960 --> 00:43:12,960
It is.

883
00:43:12,960 --> 00:43:13,960
There is more.

884
00:43:13,960 --> 00:43:14,960
Yeah.

885
00:43:14,960 --> 00:43:15,960
And the same with our robots.

886
00:43:15,960 --> 00:43:20,000
My description of moving the robot through a series of pre-plan points or trajectories

887
00:43:20,000 --> 00:43:24,560
as we call it is a simplistic representation of what actually goes on the hard one.

888
00:43:24,560 --> 00:43:25,560
That's part of it.

889
00:43:25,560 --> 00:43:26,720
That's actually mathematically.

890
00:43:26,720 --> 00:43:30,480
That's what we call sort of the feed-forward term or the nominal behavior.

891
00:43:30,480 --> 00:43:33,080
So assuming everything's perfect, that's what it will do.

892
00:43:33,080 --> 00:43:35,200
But we do, we need to stabilize.

893
00:43:35,200 --> 00:43:37,000
We talked about stable periodic motions.

894
00:43:37,000 --> 00:43:38,000
We need to stabilize.

895
00:43:38,000 --> 00:43:39,640
We need to robustify that.

896
00:43:39,640 --> 00:43:40,640
Okay.

897
00:43:40,640 --> 00:43:44,480
And so for that, you add things that bring you back to that orbit if needed.

898
00:43:44,480 --> 00:43:47,760
And that's where this robustness and reactive behavior comes from.

899
00:43:47,760 --> 00:43:49,400
There is a hierarchy.

900
00:43:49,400 --> 00:43:53,280
And so for Boston and Amics, that hierarchy is based on foot placement, typically based

901
00:43:53,280 --> 00:43:57,720
on assuming based on the rubber papers from the 80s and all this, is that they sort of

902
00:43:57,720 --> 00:44:02,360
based on, you know, the orientation of the robot at a high level, it'll place its foot

903
00:44:02,360 --> 00:44:03,520
in different locations.

904
00:44:03,520 --> 00:44:04,520
It still has the nominal.

905
00:44:04,520 --> 00:44:06,120
Listen to a Boston and Amics video.

906
00:44:06,120 --> 00:44:07,120
Yeah.

907
00:44:07,120 --> 00:44:08,720
And you'll notice it's very time-based.

908
00:44:08,720 --> 00:44:10,960
That's because that's the nominal trajectories.

909
00:44:10,960 --> 00:44:11,960
You hear the consistent.

910
00:44:11,960 --> 00:44:12,960
I'm hearing that in my head.

911
00:44:12,960 --> 00:44:15,640
And it doesn't change, right?

912
00:44:15,640 --> 00:44:16,640
So all that's changing.

913
00:44:16,640 --> 00:44:18,040
So that's the trajectory points.

914
00:44:18,040 --> 00:44:19,040
Okay.

915
00:44:19,040 --> 00:44:21,720
But then on top of that, there's a layer where it says, well, if I'm leaning too far

916
00:44:21,720 --> 00:44:25,800
to my left, I mean, this is a simplification, put my foot out here.

917
00:44:25,800 --> 00:44:26,800
Okay.

918
00:44:26,800 --> 00:44:27,800
React to that motion.

919
00:44:27,800 --> 00:44:28,800
Okay.

920
00:44:28,800 --> 00:44:30,080
And so there's that reactive layer as well.

921
00:44:30,080 --> 00:44:31,240
So that's the robustness.

922
00:44:31,240 --> 00:44:35,960
And that's what you see acting when the big dogs on ice, when it's walking in snow.

923
00:44:35,960 --> 00:44:40,080
That's a reactive behavior that's all just a hierarchical algorithm, right?

924
00:44:40,080 --> 00:44:41,720
Mathematical algorithm.

925
00:44:41,720 --> 00:44:42,720
It's not learning.

926
00:44:42,720 --> 00:44:44,280
That's what happens when you go on ice, right?

927
00:44:44,280 --> 00:44:49,080
So just, and so in terms of ice, it's not a single perturbation to your behavior.

928
00:44:49,080 --> 00:44:50,080
Yeah.

929
00:44:50,080 --> 00:44:51,920
It's an entirely new behavior you have to come up with.

930
00:44:51,920 --> 00:44:53,080
So that's a new motion primitive.

931
00:44:53,080 --> 00:44:54,080
Right.

932
00:44:54,080 --> 00:44:55,400
So you have to learn that.

933
00:44:55,400 --> 00:44:58,240
And by learning that, I don't necessarily mean machine learning that primitive.

934
00:44:58,240 --> 00:45:02,200
What I mean is you'd have to learn the fact that on ice, the friction model is different.

935
00:45:02,200 --> 00:45:03,200
Yeah.

936
00:45:03,200 --> 00:45:04,200
Learn that friction model.

937
00:45:04,200 --> 00:45:08,040
Put it back into the mathematical algorithms, modify the nominal behaviors, and then

938
00:45:08,040 --> 00:45:09,760
make yourself robust.

939
00:45:09,760 --> 00:45:11,440
So that's where this feedback loop comes in.

940
00:45:11,440 --> 00:45:13,920
And that's where learning will play a role.

941
00:45:13,920 --> 00:45:14,920
And that's kind of what you do.

942
00:45:14,920 --> 00:45:17,880
I mean, if you look at a human, you go on ice, and basically you're shuffling your feet

943
00:45:17,880 --> 00:45:18,880
around.

944
00:45:18,880 --> 00:45:20,120
You're learning the friction properties of ice.

945
00:45:20,120 --> 00:45:22,680
Once you have a pretty good model of those friction properties, you plug it into your

946
00:45:22,680 --> 00:45:27,560
nominal sort of optimization method, which sits at your spinal cord.

947
00:45:27,560 --> 00:45:31,160
And then once you've got that down, you can walk fairly normally because you've learned

948
00:45:31,160 --> 00:45:32,480
the thing you didn't know.

949
00:45:32,480 --> 00:45:36,120
And then you go back to doing the thing that you always do with a slight modification

950
00:45:36,120 --> 00:45:38,640
based on the different physical model of the world.

951
00:45:38,640 --> 00:45:40,240
So that's kind of the way we work, right?

952
00:45:40,240 --> 00:45:41,240
Right.

953
00:45:41,240 --> 00:45:42,240
It's funny.

954
00:45:42,240 --> 00:45:45,440
The human systems, I think, are great inspiration at every level because it completely mirrors

955
00:45:45,440 --> 00:45:49,200
what we're finding on robotic systems inspirationally.

956
00:45:49,200 --> 00:45:52,960
Again, not in terms of we need to mimic what actually is happening in the human body.

957
00:45:52,960 --> 00:45:57,840
But the higher arcies, where learning plays a role, where dynamics plays a role is really

958
00:45:57,840 --> 00:46:01,800
clear on the human in the human body, I think it's great inspiration for robotic systems.

959
00:46:01,800 --> 00:46:04,320
And the same parallels are happening on the neural network side.

960
00:46:04,320 --> 00:46:07,480
Like we're taking inspiration from these things, bringing them in and try to evolve the

961
00:46:07,480 --> 00:46:09,360
way we think about the learning side.

962
00:46:09,360 --> 00:46:11,440
So definitely inspiration is huge.

963
00:46:11,440 --> 00:46:15,160
But again, a word of caution is stay away from mimicry, right?

964
00:46:15,160 --> 00:46:19,000
Don't just try to create the exact same thing on a robot or an AI, right?

965
00:46:19,000 --> 00:46:23,280
Oh, well, there's, you know, X number of neurons in the human mind.

966
00:46:23,280 --> 00:46:26,080
So if we can hit that neuron, we'll have a smart robot, right?

967
00:46:26,080 --> 00:46:27,080
Right.

968
00:46:27,080 --> 00:46:29,240
No, it's not, that's not the way it's just like if you flap something, it won't necessarily

969
00:46:29,240 --> 00:46:30,240
fly.

970
00:46:30,240 --> 00:46:32,600
But yes, look at the structures.

971
00:46:32,600 --> 00:46:38,400
The really the structures are our key and try to understand what they mean and then realize

972
00:46:38,400 --> 00:46:39,400
them on robotic systems.

973
00:46:39,400 --> 00:46:40,400
Great.

974
00:46:40,400 --> 00:46:41,400
Great.

975
00:46:41,400 --> 00:46:42,400
Well, I really enjoy this conversation.

976
00:46:42,400 --> 00:46:46,600
Any final words for folks or how can folks find you learn more about your work?

977
00:46:46,600 --> 00:46:49,840
The internet is available to find my stuff.

978
00:46:49,840 --> 00:46:54,640
My lab website is bipedorobotics.com, just a simple name.

979
00:46:54,640 --> 00:46:57,960
You can find me on the Caltech website, just Google AirNames and there should be enough

980
00:46:57,960 --> 00:46:58,960
stuff.

981
00:46:58,960 --> 00:46:59,960
My students are on there too.

982
00:46:59,960 --> 00:47:00,960
They do amazing stuff.

983
00:47:00,960 --> 00:47:03,560
A lot of the videos you see are from my grad students.

984
00:47:03,560 --> 00:47:09,720
If you're interested in robotics, please come to grad school somewhere.

985
00:47:09,720 --> 00:47:14,120
If you feel free to ping us, if you're really interested in Caltech.

986
00:47:14,120 --> 00:47:17,080
And in general, keep studying these problems.

987
00:47:17,080 --> 00:47:20,480
This is, we're at a fascinating point right now.

988
00:47:20,480 --> 00:47:22,280
And I think that's amazing.

989
00:47:22,280 --> 00:47:27,120
My couple of final closing statements are, this is massively exciting, but be careful

990
00:47:27,120 --> 00:47:28,600
of the hype.

991
00:47:28,600 --> 00:47:31,840
Instead of just going for the hype, think about these things.

992
00:47:31,840 --> 00:47:36,960
Think about where learning will play a role, look to unification, because we can achieve

993
00:47:36,960 --> 00:47:42,440
these promises that are being made, but we have to be very smart about how we approach

994
00:47:42,440 --> 00:47:43,440
the problem.

995
00:47:43,440 --> 00:47:45,000
And that's what makes it fun right now.

996
00:47:45,000 --> 00:47:46,280
These are not solved problems.

997
00:47:46,280 --> 00:47:50,880
And anybody that says they're solved, I think doesn't know what they're talking about.

998
00:47:50,880 --> 00:47:55,280
We were at this point where we're really trying to understand how learning and, for example,

999
00:47:55,280 --> 00:47:57,880
robotics systems work together.

1000
00:47:57,880 --> 00:48:03,440
And it's an exciting time to be doing this, so I encourage everyone to really dig into

1001
00:48:03,440 --> 00:48:05,840
it and see what they can learn.

1002
00:48:05,840 --> 00:48:06,840
Oh, thanks Aaron.

1003
00:48:06,840 --> 00:48:07,840
Thanks a lot.

1004
00:48:07,840 --> 00:48:15,520
Alright everyone, that's our show for today.

1005
00:48:15,520 --> 00:48:20,440
Thanks so much for listening, and for your continued feedback and support.

1006
00:48:20,440 --> 00:48:24,840
For more information on Aaron, or any of the topics covered in this episode, head on

1007
00:48:24,840 --> 00:48:29,760
over to twimlai.com slash talk slash 87.

1008
00:48:29,760 --> 00:48:36,680
To follow along with the AWS re-invent series, visit twimlai.com slash re-invent.

1009
00:48:36,680 --> 00:48:43,840
To enter our Twimlai 1 mil contest, visit twimlai.com slash twimlai 1 mil.

1010
00:48:43,840 --> 00:48:48,680
Of course, we'd be delighted to hear from you, either via a comment on the show notes

1011
00:48:48,680 --> 00:48:55,040
page or via Twitter to add Twimlai or add Sam Charington.

1012
00:48:55,040 --> 00:48:58,800
Thanks again to Intel Nirvana for their sponsorship of this series.

1013
00:48:58,800 --> 00:49:03,440
To learn more about their role in deep lens and the other things they've been up to, visit

1014
00:49:03,440 --> 00:49:06,040
intelnervana.com.

1015
00:49:06,040 --> 00:49:19,000
And of course, thanks once again to you for listening, and catch you next time.

