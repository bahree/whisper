1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:32,240
I'm your host Sam Charrington.

4
00:00:32,240 --> 00:00:37,000
If you missed our last show and if you did you definitely want to go check it out because

5
00:00:37,000 --> 00:00:39,600
it was a great conversation.

6
00:00:39,600 --> 00:00:44,160
But if you missed that show you missed the first of the many exciting updates we have for

7
00:00:44,160 --> 00:00:45,760
you this summer.

8
00:00:45,760 --> 00:00:50,720
Last time we announced Twimble's third birthday and our 5 millionth download which happened

9
00:00:50,720 --> 00:00:53,040
right around the same time.

10
00:00:53,040 --> 00:00:58,320
To help us celebrate this occasion and to request your commemorative Twimble birthday sticker

11
00:00:58,320 --> 00:01:02,800
visit TwimbleAI.com slash birthday 3.

12
00:01:02,800 --> 00:01:09,240
This week we're continuing the action by kicking off volume 2 of our AI platform series.

13
00:01:09,240 --> 00:01:14,440
You recall that last fall we brought you AI platform's volume 1 featuring conversations

14
00:01:14,440 --> 00:01:21,440
with platform builders from Facebook, Airbnb, LinkedIn, OpenAI, Shell and Comcast.

15
00:01:21,440 --> 00:01:27,640
This series turned out to be one of our most popular series of shows ever and over 1000

16
00:01:27,640 --> 00:01:33,040
of you downloaded our first ebook on machine learning platforms, Kubernetes for machine

17
00:01:33,040 --> 00:01:35,920
learning, deep learning and AI.

18
00:01:35,920 --> 00:01:40,880
Well we'll be back at it over the next few weeks sharing more experiences from teams

19
00:01:40,880 --> 00:01:46,880
working to scale and industrialize data science and machine learning at their companies.

20
00:01:46,880 --> 00:01:51,320
And we've got even more in store on this topic so if it's an area you're interested

21
00:01:51,320 --> 00:01:53,880
in be sure to stay tuned.

22
00:01:53,880 --> 00:02:00,760
You can follow along with the series at twimbleai.com slash AI platforms 2 and by following us on

23
00:02:00,760 --> 00:02:07,720
Twitter at at Sam Charrington and at Twimble AI.

24
00:02:07,720 --> 00:02:12,720
Before we dive in, I'd like to send a giant thanks to our friends over at Sigopt.

25
00:02:12,720 --> 00:02:16,960
They've been huge supporters of my work in this area and I'm really excited to have them

26
00:02:16,960 --> 00:02:21,840
as a sponsor of this series of shows on machine learning and AI platforms.

27
00:02:21,840 --> 00:02:27,640
If you don't know Sigopt, I spoke with their CEO Scott Clark back on show number 50.

28
00:02:27,640 --> 00:02:31,480
Their software is used by enterprise teams to standardize and scale machine learning

29
00:02:31,480 --> 00:02:37,680
experimentation and optimization across any combination of modeling frameworks, libraries,

30
00:02:37,680 --> 00:02:40,560
computing infrastructure and environment.

31
00:02:40,560 --> 00:02:45,680
Teams like 2 Sigma who will hear from later in this series rely on Sigopt software to

32
00:02:45,680 --> 00:02:50,480
realize better modeling results much faster than previously possible.

33
00:02:50,480 --> 00:02:55,960
Of course to fully grasp the potential of a tool like Sigopt is best to try it yourself.

34
00:02:55,960 --> 00:03:01,240
That's why Sigopt is offering you the twimble community an exclusive opportunity to try

35
00:03:01,240 --> 00:03:06,240
their product on some of your toughest modeling problems for free.

36
00:03:06,240 --> 00:03:14,360
To take advantage of this offer, visit twimbleai.com slash Sigopt.

37
00:03:14,360 --> 00:03:16,800
All right everyone, I am here with Adrian Gaden.

38
00:03:16,800 --> 00:03:21,000
Adrian is a machine learning lead at Toyota Research Institute.

39
00:03:21,000 --> 00:03:23,600
Adrian, welcome to this week in machine learning and AI.

40
00:03:23,600 --> 00:03:24,600
I'm super happy to be here.

41
00:03:24,600 --> 00:03:26,080
Thank you for inviting time.

42
00:03:26,080 --> 00:03:33,000
So we are here in Las Vegas at the AWS re-invent conference where you gave a talk and we

43
00:03:33,000 --> 00:03:38,920
will dig into the topic of your talk, which was about advancing autonomous vehicle development

44
00:03:38,920 --> 00:03:40,760
using distributed deep learning.

45
00:03:40,760 --> 00:03:44,840
But before we do that, I'd like to hear a little bit about your background.

46
00:03:44,840 --> 00:03:47,480
How do you get into machine learning?

47
00:03:47,480 --> 00:03:49,240
Yeah, absolutely.

48
00:03:49,240 --> 00:03:55,960
So I've been doing deep learning and machine learning for more than 10 years now.

49
00:03:55,960 --> 00:04:01,320
I was really interested initially in human learning, human psychology, but I also really

50
00:04:01,320 --> 00:04:05,000
like computers and building stuff, so machine learning and AI kind of was like a natural

51
00:04:05,000 --> 00:04:07,040
match made in heaven.

52
00:04:07,040 --> 00:04:12,760
And so I started doing a double major in computer science and math and at the same time looking

53
00:04:12,760 --> 00:04:14,320
into AI more.

54
00:04:14,320 --> 00:04:19,880
And then I did an internship at Inria in the very one on group from a Codidia Schmidt

55
00:04:19,880 --> 00:04:23,720
and Computer Vision, where I participated to some competitions like the ancestors of

56
00:04:23,720 --> 00:04:30,000
ImageNet, so Pascal VOC, Visual Object Challenges, which I won in 2008.

57
00:04:30,000 --> 00:04:35,040
And then I continued the PhD that was with Microsoft Research in Inria, I joined Center in

58
00:04:35,040 --> 00:04:40,440
Paris where I was working on video understanding, more specifically human action recognition.

59
00:04:40,440 --> 00:04:47,400
And after that, I joined XRC, XRC Center Europe, and you actually interviewed a friend of mine

60
00:04:47,400 --> 00:04:53,560
in my former boss, Nile Murray, and computer vision team there, great episode, by the way.

61
00:04:53,560 --> 00:04:59,040
And so I joined them as a research scientist and worked in video analysis in general, so

62
00:04:59,040 --> 00:05:00,920
I started that research effort there.

63
00:05:00,920 --> 00:05:05,360
At the same time, deep learning emerged, so that's when I really transitioned from principled

64
00:05:05,360 --> 00:05:09,960
convex optimization and kernel methods into the alchemy of deep learning and never looked

65
00:05:09,960 --> 00:05:12,080
back since.

66
00:05:12,080 --> 00:05:17,080
And are we saying alchemy just in celebration of the fact that Neurops is next week?

67
00:05:17,080 --> 00:05:20,080
Yeah, that's a good one.

68
00:05:20,080 --> 00:05:26,280
And yeah, and from then on, I did a lot of work on tracking and especially domain adaptation.

69
00:05:26,280 --> 00:05:30,320
And because we didn't have a lot of data, I had to make my own, so I started looking

70
00:05:30,320 --> 00:05:31,840
into simulation a lot.

71
00:05:31,840 --> 00:05:35,640
Game engines to generate data.

72
00:05:35,640 --> 00:05:39,240
And I did a couple of CUPR papers on the topic that were noticed by the industry at large

73
00:05:39,240 --> 00:05:43,480
nut and mistriving, which at the time was like really getting into simulation.

74
00:05:43,480 --> 00:05:47,880
And that's how I joined TRI, because I really dedicated to simulation and very, very large

75
00:05:47,880 --> 00:05:48,880
scale.

76
00:05:48,880 --> 00:05:50,280
These Brahms only happened at a large scale.

77
00:05:50,280 --> 00:05:55,400
If you have just small needs, like Robotaxi, et cetera, you can just label data, but at

78
00:05:55,400 --> 00:05:59,400
a very, very large scale and like Toyota's number one car maker in the world, 100 million

79
00:05:59,400 --> 00:06:02,720
cars on the road today, you need to think about these problems.

80
00:06:02,720 --> 00:06:06,840
And that's what gets me excited as a machinery in person, because it's all about generalization.

81
00:06:06,840 --> 00:06:12,520
And when you think about worldwide, like Japan, Australia, US everywhere, it has to work.

82
00:06:12,520 --> 00:06:16,400
And that's what's really cool, because you both have to invent new things in the research,

83
00:06:16,400 --> 00:06:18,880
but you also have to make it work.

84
00:06:18,880 --> 00:06:20,480
And you get to touch on all these things.

85
00:06:20,480 --> 00:06:21,960
So that's how I got into it.

86
00:06:21,960 --> 00:06:25,320
And I got really hooked into Robotax, based in general, and at the time it was driving in

87
00:06:25,320 --> 00:06:28,120
particular, because it's such a great application for machine learning.

88
00:06:28,120 --> 00:06:30,120
Okay.

89
00:06:30,120 --> 00:06:36,760
Before we get too deep into what you spoke about here, what's the focus that TRI in general,

90
00:06:36,760 --> 00:06:39,000
and then your focus there?

91
00:06:39,000 --> 00:06:40,000
Yeah, absolutely.

92
00:06:40,000 --> 00:06:45,160
So TRI was created almost like three years ago now.

93
00:06:45,160 --> 00:06:51,040
It's basically a separate company that was created by Toyota with $1 billion funding initially,

94
00:06:51,040 --> 00:06:55,240
and we got $2.8 billion more, and it's been up a new company called TRI AD Advanced

95
00:06:55,240 --> 00:06:57,320
Development recently.

96
00:06:57,320 --> 00:06:59,880
Our focus is really, like we're a Robotax company.

97
00:06:59,880 --> 00:07:05,440
And our focus is really about autonomous driving, home robots, and we also do some material

98
00:07:05,440 --> 00:07:10,040
science research for designing better batteries and things like this.

99
00:07:10,040 --> 00:07:12,480
But most of our efforts is really in driving.

100
00:07:12,480 --> 00:07:16,400
And the team I lead in machine learning is really about research for autonomous driving.

101
00:07:16,400 --> 00:07:21,640
We do also things for Robotax a little bit, because from our perspective, a car is a robot.

102
00:07:21,640 --> 00:07:25,680
As a sensory motor loop, essentially, you have perception, prediction, planning, decision

103
00:07:25,680 --> 00:07:29,640
action, and these feedback loops from the real world, which is what exciting is a physical

104
00:07:29,640 --> 00:07:31,320
system.

105
00:07:31,320 --> 00:07:35,520
And TRI really has a mission to improve quality of life in general.

106
00:07:35,520 --> 00:07:39,760
I know it sounds very Silicon Valley, but in that case, it's actually true, because we

107
00:07:39,760 --> 00:07:42,160
have already hundreds of millions of users.

108
00:07:42,160 --> 00:07:46,560
And so the goal is one is the project called Guardian, which is to make a car that can

109
00:07:46,560 --> 00:07:47,560
crash.

110
00:07:47,560 --> 00:07:50,160
So it's the ultimate driver assistance system.

111
00:07:50,160 --> 00:07:54,520
Another one is Schofr, which is the real autonomous car, like not the ones we're talking

112
00:07:54,520 --> 00:07:58,640
about today, but the long-term, the long game, which is real autonomy, like these cars

113
00:07:58,640 --> 00:08:02,320
that can drive themselves completely, autonomously, everywhere, all the time, which obviously is

114
00:08:02,320 --> 00:08:03,320
not going to happen tomorrow.

115
00:08:03,320 --> 00:08:05,000
We talk a lot about that one today.

116
00:08:05,000 --> 00:08:06,920
We talk, yeah.

117
00:08:06,920 --> 00:08:09,960
So this is, but that's, it depends on the product, right?

118
00:08:09,960 --> 00:08:13,920
What people think and hear to your eyes thinking really about the long-term thing.

119
00:08:13,920 --> 00:08:17,800
The cool thing is that these two, Guardian and Schofr, in terms of the machine learning

120
00:08:17,800 --> 00:08:20,040
side of things, they have a huge intersection.

121
00:08:20,040 --> 00:08:24,360
You still need a semantics segmentation, object detection, tracking, a lot of the algorithms

122
00:08:24,360 --> 00:08:28,200
that we're talking about in computer vision are actually completely in common, almost completely

123
00:08:28,200 --> 00:08:29,200
in common.

124
00:08:29,200 --> 00:08:33,640
So from the perspective of my research, I don't make a difference necessarily between

125
00:08:33,640 --> 00:08:37,680
these products, because most of the research I do is very well aligned with those purposes.

126
00:08:37,680 --> 00:08:43,240
And then we also do home robotics, so we have really, really good teams there, XNAS, JPL,

127
00:08:43,240 --> 00:08:48,360
et cetera, where they work on mobile manipulation platforms, so that to assist the elderly for

128
00:08:48,360 --> 00:08:50,360
home care and these kind of things.

129
00:08:50,360 --> 00:08:54,920
And does Toyota have products in market in these, in the home robotics space?

130
00:08:54,920 --> 00:09:00,160
So actually, Toyota manufactures the robot that's called the HSR, the human support robot.

131
00:09:00,160 --> 00:09:04,480
That was, I think, the official platform for the Robocop recently.

132
00:09:04,480 --> 00:09:06,760
So Toyota is really big in robotics.

133
00:09:06,760 --> 00:09:07,760
Robocop.

134
00:09:07,760 --> 00:09:08,760
I was thinking Robocop.

135
00:09:08,760 --> 00:09:13,760
Robocop with a U, pardon my French.

136
00:09:13,760 --> 00:09:14,760
No.

137
00:09:14,760 --> 00:09:20,000
So, yeah, so the goal is basically, how do we transform Toyota into a robotics company?

138
00:09:20,000 --> 00:09:21,000
Yeah.

139
00:09:21,000 --> 00:09:24,800
They have this amazing industrial robotics side, of course, but really, what is the future

140
00:09:24,800 --> 00:09:25,800
of cars?

141
00:09:25,800 --> 00:09:30,080
It's going to be Robocars, but it's also going to be robots beyond cars.

142
00:09:30,080 --> 00:09:34,240
And also how they become a software company and actually a machine learning company.

143
00:09:34,240 --> 00:09:36,120
That's really what's exciting.

144
00:09:36,120 --> 00:09:40,240
Because at this scale of a company that they want to change and see your Toyota, I was

145
00:09:40,240 --> 00:09:44,360
really talking about like, you know, the song that Andy Jassy is talking about is key

146
00:09:44,360 --> 00:09:46,000
notes, the clash song.

147
00:09:46,000 --> 00:09:47,000
We don't do it.

148
00:09:47,000 --> 00:09:48,000
It's not good.

149
00:09:48,000 --> 00:09:50,000
We do it.

150
00:09:50,000 --> 00:09:51,000
We have to do it, right?

151
00:09:51,000 --> 00:09:52,000
Right.

152
00:09:52,000 --> 00:09:53,520
So that's what's really exciting.

153
00:09:53,520 --> 00:09:58,680
Tell me a little bit about the key message of your talk here at MianBet.

154
00:09:58,680 --> 00:09:59,680
Yeah.

155
00:09:59,680 --> 00:10:05,400
So here, what we wanted to talk about was how we, you can do a distributed deep learning

156
00:10:05,400 --> 00:10:10,880
infrastructure in the cloud that actually scales really well and is highly performance.

157
00:10:10,880 --> 00:10:16,680
So when we started this thing, when I took over the team a bit more than a year and a half

158
00:10:16,680 --> 00:10:21,240
ago, I, like, Jerry, we're really well funded, as I mentioned.

159
00:10:21,240 --> 00:10:24,640
So I had dollar signs in my eyes and I was like, all right, I'm going to buy so many GPUs.

160
00:10:24,640 --> 00:10:25,640
I'm going to splurge.

161
00:10:25,640 --> 00:10:28,560
I'm going to, and we had a server room.

162
00:10:28,560 --> 00:10:29,720
We had everything there.

163
00:10:29,720 --> 00:10:33,400
And, and then actually was still, even if you have the money, even if you have the

164
00:10:33,400 --> 00:10:37,520
means that your disposal, it's still fairly slow to ramp up.

165
00:10:37,520 --> 00:10:40,840
And we had Mike Garrison, which was doing a talk with me, which is our lead of infrastructure

166
00:10:40,840 --> 00:10:43,400
engineering, was telling me, hey, what about Amazon?

167
00:10:43,400 --> 00:10:48,840
I was like, they have K80s, you know, they have old GPUs, it's slow, et cetera, but keeping

168
00:10:48,840 --> 00:10:52,200
an open mind, we tried a couple of things.

169
00:10:52,200 --> 00:10:56,160
And we got in touch with the AWS folks and, and we did a lot of infrastructure work to

170
00:10:56,160 --> 00:11:01,480
really, like, make it work, first single node, then multi nodes.

171
00:11:01,480 --> 00:11:05,840
And using PyTorch, we're a PyTorch shop, we used to be in anything shop, and then a

172
00:11:05,840 --> 00:11:06,840
tens of those shop.

173
00:11:06,840 --> 00:11:11,800
And we really like switched to PyTorch full time a year ago or something.

174
00:11:11,800 --> 00:11:17,000
And, and the talk was really about this kind of journey through which we went from like,

175
00:11:17,000 --> 00:11:23,200
yeah, you have a on-prem compute and you can do stuff to really, really large scale distributed

176
00:11:23,200 --> 00:11:25,200
deep learning in the cloud that's efficient.

177
00:11:25,200 --> 00:11:28,120
And efficiencies is really the key here.

178
00:11:28,120 --> 00:11:31,720
And driving in particular, there's one thing that is very different from, let's say,

179
00:11:31,720 --> 00:11:36,920
normal machine learning that you would see at NIPs or CPR, which is we care about small

180
00:11:36,920 --> 00:11:39,080
networks that operate at a high resolution.

181
00:11:39,080 --> 00:11:41,120
And there's two reasons for that.

182
00:11:41,120 --> 00:11:44,480
One is that they need to be small because even if you can compress them, quantize them,

183
00:11:44,480 --> 00:11:47,640
and all these kind of things that we know, we can make them more efficient.

184
00:11:47,640 --> 00:11:53,840
Still, you need a smaller model initially to fit in like computational budget that we

185
00:11:53,840 --> 00:11:57,880
have in the car because safety critical, so you have to have like, really efficient models.

186
00:11:57,880 --> 00:12:02,000
The second thing is you need very high resolution because time is equal space, so I was talking

187
00:12:02,000 --> 00:12:05,960
in my talk about like these weird equations, talking about lean deep learning, so you want

188
00:12:05,960 --> 00:12:07,800
like faster and around time and these kind of stuff.

189
00:12:07,800 --> 00:12:12,360
We want to create some kind of Toyota production system of deep learning and stuff.

190
00:12:12,360 --> 00:12:16,520
So that we can iterate really quickly from idea to model, to validation, and go back

191
00:12:16,520 --> 00:12:19,400
to the drawing board because it's research.

192
00:12:19,400 --> 00:12:25,120
And this idea of very high resolution is part of one of our constraints that we have to

193
00:12:25,120 --> 00:12:29,040
deal with because we want to predict things from far.

194
00:12:29,040 --> 00:12:34,000
And so seeing far is like when you read the California Handbook of Drivers, it tells you

195
00:12:34,000 --> 00:12:37,720
you have to look far in the distance to look far into the future.

196
00:12:37,720 --> 00:12:40,680
And so resolution is kind of a key thing.

197
00:12:40,680 --> 00:12:42,960
It's actually talking literally camera resolution.

198
00:12:42,960 --> 00:12:43,960
Camera resolution.

199
00:12:43,960 --> 00:12:44,960
Camera resolution.

200
00:12:44,960 --> 00:12:48,360
And specifically for the computer vision models that we're using.

201
00:12:48,360 --> 00:12:51,680
And so that means that the compute workload is kind of different because you have small

202
00:12:51,680 --> 00:12:57,600
models and very high resolution. So in terms of data flow operations, time you spend in

203
00:12:57,600 --> 00:13:01,080
this metrics multiplies and all these kind of things, it's very different.

204
00:13:01,080 --> 00:13:03,880
So we had can't down sample or crop everything to 224.

205
00:13:03,880 --> 00:13:04,880
Not.

206
00:13:04,880 --> 00:13:05,880
No.

207
00:13:05,880 --> 00:13:09,720
Or site far resolution doesn't cut it for us, sadly, no, it doesn't.

208
00:13:09,720 --> 00:13:13,360
And so we had to, if you use the standard tools like the data parallel or distributed data

209
00:13:13,360 --> 00:13:16,920
parallel from PyTorch, which are amazing at the image net and these kind of stuff, they

210
00:13:16,920 --> 00:13:18,000
didn't scale for us.

211
00:13:18,000 --> 00:13:21,240
And so we had to rewrite a couple of things and that's what we talked about.

212
00:13:21,240 --> 00:13:22,240
Okay.

213
00:13:22,240 --> 00:13:23,640
So let's walk through that journey.

214
00:13:23,640 --> 00:13:31,440
So you mentioned that one of the first steps was you kind of had to build up the infrastructure

215
00:13:31,440 --> 00:13:35,440
like at a node level from scratch, was that where it started or was there where there's

216
00:13:35,440 --> 00:13:36,440
steps before?

217
00:13:36,440 --> 00:13:37,440
Yeah.

218
00:13:37,440 --> 00:13:38,440
No, no.

219
00:13:38,440 --> 00:13:39,440
So we started.

220
00:13:39,440 --> 00:13:42,320
So that's the cool thing about TRI is that we're fairly young and we're small.

221
00:13:42,320 --> 00:13:47,560
And so there is no, no technical debt because there's nothing when I started, right?

222
00:13:47,560 --> 00:13:52,200
And that was super cool because I'm, as a research scientist, I was mostly, you know, use

223
00:13:52,200 --> 00:13:53,200
this, use that.

224
00:13:53,200 --> 00:13:54,200
All right.

225
00:13:54,200 --> 00:13:55,200
It's there.

226
00:13:55,200 --> 00:13:56,200
You know, use Slurm because it's this way.

227
00:13:56,200 --> 00:13:57,200
I use that file system.

228
00:13:57,200 --> 00:13:58,200
It's there.

229
00:13:58,200 --> 00:13:59,200
Okay.

230
00:13:59,200 --> 00:14:00,400
And here was really just sky's the limit.

231
00:14:00,400 --> 00:14:01,400
What you should do.

232
00:14:01,400 --> 00:14:06,480
And so we really got the opportunity to use the best partner with the best so we worked

233
00:14:06,480 --> 00:14:08,720
directly with a lot of different partners.

234
00:14:08,720 --> 00:14:12,360
And then we really created the thing from scratch and first single node because it was

235
00:14:12,360 --> 00:14:15,480
really easy and ended all kinds of tricks.

236
00:14:15,480 --> 00:14:18,680
Now you have some machines that are monster machines, you know, 700 gigs of RAM.

237
00:14:18,680 --> 00:14:21,280
And so you can scale quite well, but up to a point.

238
00:14:21,280 --> 00:14:24,800
And so that's when we started to switch to using distributed file systems.

239
00:14:24,800 --> 00:14:27,600
So we did a BGFS base, distributed file system.

240
00:14:27,600 --> 00:14:32,640
Before we leave that initial node, I thought I heard you say earlier that it was difficult

241
00:14:32,640 --> 00:14:36,160
and you had to go through a lot of steps to get on that first, they get that first

242
00:14:36,160 --> 00:14:37,160
node up and running.

243
00:14:37,160 --> 00:14:41,320
But you just said it was really easy, assuming that means relative to a full distributed

244
00:14:41,320 --> 00:14:42,320
kind of.

245
00:14:42,320 --> 00:14:50,040
I'm kind of curious about the, you know, the pain points that you had to go through just

246
00:14:50,040 --> 00:14:51,040
to get this up and running.

247
00:14:51,040 --> 00:14:56,880
And also the extent to which there's still pain points are there other things that have

248
00:14:56,880 --> 00:14:58,520
kind of wiped that all the way.

249
00:14:58,520 --> 00:15:02,160
So yeah, okay, the first one is this base, right?

250
00:15:02,160 --> 00:15:06,640
So the first one is because of the scale of the data we have, you cannot.

251
00:15:06,640 --> 00:15:11,080
So for a lot of like, that's a debug experience or research experiments on small data sets,

252
00:15:11,080 --> 00:15:14,280
you can fit them on the RAM and you should do that because that's just like the best

253
00:15:14,280 --> 00:15:15,440
thing for your bug.

254
00:15:15,440 --> 00:15:20,720
But when you have a large data, a large data sets, then that becomes much more complicated.

255
00:15:20,720 --> 00:15:28,080
And so we, we first switch from the RAM disks to EBS volumes or more EFS or we tried everything.

256
00:15:28,080 --> 00:15:32,840
But for like, these kind of like, this high resolution, small networks to not be network

257
00:15:32,840 --> 00:15:33,840
bound, right?

258
00:15:33,840 --> 00:15:38,080
To not have this GPU starvation problem where your average utilization of the GPU is like

259
00:15:38,080 --> 00:15:41,120
15% or something ridiculous.

260
00:15:41,120 --> 00:15:42,120
And these machines are expensive.

261
00:15:42,120 --> 00:15:46,480
So you want to bump that to 90% or above.

262
00:15:46,480 --> 00:15:51,120
That's what we had to actually, even before we started really doing distributed computations,

263
00:15:51,120 --> 00:15:56,360
using a distributed file system enabled us to really download the data once and not every

264
00:15:56,360 --> 00:15:59,960
time you set up a machine because if you auto provision machines and you have to download

265
00:15:59,960 --> 00:16:04,000
data from a three, every time you start a machine, then you're saying like, oh, I have

266
00:16:04,000 --> 00:16:05,000
this idea.

267
00:16:05,000 --> 00:16:08,000
That's way two hours before I can just like press play, right?

268
00:16:08,000 --> 00:16:12,120
So that was a big pain points for research to have this faster and around time.

269
00:16:12,120 --> 00:16:16,680
So the distributed file system was something that was very useful at a single node level

270
00:16:16,680 --> 00:16:18,360
and of course, scaled to the multi node.

271
00:16:18,360 --> 00:16:21,280
So we did it two birds with one stone.

272
00:16:21,280 --> 00:16:23,080
So where did you end up with that?

273
00:16:23,080 --> 00:16:26,120
We used the BGFS as file system.

274
00:16:26,120 --> 00:16:30,520
And we're going to look at Luster, like these announcements that were made recently.

275
00:16:30,520 --> 00:16:31,840
That's very interesting.

276
00:16:31,840 --> 00:16:36,680
Another pain point that we had was the BGFS you're managing yourself.

277
00:16:36,680 --> 00:16:39,920
We just deploying it on the node in your amy or whatever.

278
00:16:39,920 --> 00:16:40,920
Yeah.

279
00:16:40,920 --> 00:16:44,280
So we have like, instead of instances that serve that file system that is then mounted

280
00:16:44,280 --> 00:16:45,760
on these instances.

281
00:16:45,760 --> 00:16:49,040
And we have some infrastructure as code to just like spin this off, like all configured

282
00:16:49,040 --> 00:16:50,560
and ready.

283
00:16:50,560 --> 00:16:52,120
There's something around containers.

284
00:16:52,120 --> 00:16:56,840
So we were baking stuff a lot into the amy, into the machines themselves that were when

285
00:16:56,840 --> 00:17:01,320
they started, you're just there directly because not everybody was familiar with a Docker.

286
00:17:01,320 --> 00:17:05,400
But we picked up Docker too because there's obvious reproducibility benefits.

287
00:17:05,400 --> 00:17:09,440
And when you hack a lot of things quickly at the beginning of a research project, having

288
00:17:09,440 --> 00:17:16,000
this kind of Docker file where people can reproduce your environment and not just, you know,

289
00:17:16,000 --> 00:17:17,000
your experiments.

290
00:17:17,000 --> 00:17:20,280
That's actually extremely helpful for collaboration in the team.

291
00:17:20,280 --> 00:17:23,040
So we used to tie us back to that agility and being able to move quickly.

292
00:17:23,040 --> 00:17:24,040
Exactly.

293
00:17:24,040 --> 00:17:25,040
Close to booting up a whole machine.

294
00:17:25,040 --> 00:17:26,040
Yes.

295
00:17:26,040 --> 00:17:27,040
Yes.

296
00:17:27,040 --> 00:17:28,880
And our IT folks were so happy because it's not like this.

297
00:17:28,880 --> 00:17:29,880
This doesn't work.

298
00:17:29,880 --> 00:17:30,880
Yeah.

299
00:17:30,880 --> 00:17:34,240
But because you happy to get installed something that wrecked the system and that's of course.

300
00:17:34,240 --> 00:17:35,240
So DevOps.

301
00:17:35,240 --> 00:17:39,840
Tracing DevOps, even for researchers actually was quite powerful because you can only do

302
00:17:39,840 --> 00:17:44,440
the research that, you know, the mastery of the tools is really important to empower you

303
00:17:44,440 --> 00:17:48,480
to do research beyond, you know, just pipe Jupyter notebook, let's say.

304
00:17:48,480 --> 00:17:49,480
It's an awesome tool.

305
00:17:49,480 --> 00:17:52,080
But if you want to go beyond, you need to master other tools.

306
00:17:52,080 --> 00:17:54,280
And that's what we've been doing.

307
00:17:54,280 --> 00:17:59,080
It's a journey through engineering, craftsmanship as much as deep learning research.

308
00:17:59,080 --> 00:18:05,400
Is the, you know, when you talk about kind of applying DevOps in this world to what degree

309
00:18:05,400 --> 00:18:11,160
in your experience does it apply directly or are there, you know, gaps or it only takes

310
00:18:11,160 --> 00:18:12,160
you so far.

311
00:18:12,160 --> 00:18:15,480
You have to modify the way you think about it.

312
00:18:15,480 --> 00:18:19,120
And I realized that I'm saying that as if DevOps is this well-defined thing.

313
00:18:19,120 --> 00:18:20,120
Yeah.

314
00:18:20,120 --> 00:18:22,360
But I think it's a good question.

315
00:18:22,360 --> 00:18:27,320
I think there's like two ways to, like let's say there's two extremes, right?

316
00:18:27,320 --> 00:18:29,680
There's the extreme of you do everything yourself.

317
00:18:29,680 --> 00:18:33,600
And there's the extreme of you just use blindly something that someone does for you.

318
00:18:33,600 --> 00:18:37,800
And in that space of, you know, all the grad students in the world in machine learning,

319
00:18:37,800 --> 00:18:41,440
they spend considerable amount of time configuring their environment.

320
00:18:41,440 --> 00:18:44,400
That's a skill we developed during our PhDs.

321
00:18:44,400 --> 00:18:50,040
And Docker and these kind of things, if you don't become an IT guy or DevOps guy, but just

322
00:18:50,040 --> 00:18:52,200
learn from the best there.

323
00:18:52,200 --> 00:18:56,520
And they do some of the things that around security and that's really important for

324
00:18:56,520 --> 00:18:58,840
data that we have that I don't know.

325
00:18:58,840 --> 00:19:03,280
I don't have an inkling, but they expose us to AWS services, they expose us to some

326
00:19:03,280 --> 00:19:04,280
Docker stuff.

327
00:19:04,280 --> 00:19:05,280
So I'm not an AWS expert.

328
00:19:05,280 --> 00:19:06,280
I'm not Docker expert.

329
00:19:06,280 --> 00:19:07,440
I'm not a Kubernetes expert.

330
00:19:07,440 --> 00:19:12,440
But knowing a little bit of that enables empowers you to try more bold research ideas and

331
00:19:12,440 --> 00:19:13,760
actually debug.

332
00:19:13,760 --> 00:19:17,640
And when you care about the performance of your model, not just in terms of its accuracy,

333
00:19:17,640 --> 00:19:24,360
but its speed, having these knowledge enables you to do research much faster actually, which

334
00:19:24,360 --> 00:19:27,000
is counterintuitive a little bit.

335
00:19:27,000 --> 00:19:30,600
But again, when you're beyond MNIST, that's what it takes.

336
00:19:30,600 --> 00:19:31,600
Right, right.

337
00:19:31,600 --> 00:19:37,640
You started out doing a lot of this yourself, yourself, meaning like within, you know, as

338
00:19:37,640 --> 00:19:42,840
research, a community of research scientists, it sounds like you're presenting with an infrastructure

339
00:19:42,840 --> 00:19:43,840
person.

340
00:19:43,840 --> 00:19:46,640
So now you've got kind of, you know, professional support.

341
00:19:46,640 --> 00:19:48,840
Yeah, we do, we do work really tightly with them.

342
00:19:48,840 --> 00:19:52,280
I also, my team is like probably like 30% engineers.

343
00:19:52,280 --> 00:19:53,280
Okay.

344
00:19:53,280 --> 00:19:58,200
And it's really, I think it's really good for research teams to have this mix of really

345
00:19:58,200 --> 00:20:01,200
scientists and engineers.

346
00:20:01,200 --> 00:20:05,560
And because again, as I said, the lines are blurred at large scale research, and you need

347
00:20:05,560 --> 00:20:06,560
these two skills.

348
00:20:06,560 --> 00:20:09,800
And obviously, also like all the DevOps and infrastructure engineering teams.

349
00:20:09,800 --> 00:20:12,400
So the collaborative spirit of terror is really, really good.

350
00:20:12,400 --> 00:20:14,960
Like because we're small, we're very tightly in it.

351
00:20:14,960 --> 00:20:18,760
And because there was no technical debt, we're building everything together.

352
00:20:18,760 --> 00:20:23,560
And really nothing that the infrastructure engineering built was done in isolation without

353
00:20:23,560 --> 00:20:24,560
consulting us.

354
00:20:24,560 --> 00:20:28,680
So that's why we have a system that works really smoothly because all the concerns were

355
00:20:28,680 --> 00:20:32,720
shared and addressed at the same time from all the pieces of the puzzle.

356
00:20:32,720 --> 00:20:39,080
So it's really nice to have that like kick-ass modern infrastructure built around, around

357
00:20:39,080 --> 00:20:40,960
you somehow and with you.

358
00:20:40,960 --> 00:20:41,960
Yeah.

359
00:20:41,960 --> 00:20:47,080
And so did that infrastructure engineering team and support?

360
00:20:47,080 --> 00:20:53,800
Was that always there or did that come at a certain point after you'd built some things?

361
00:20:53,800 --> 00:20:54,800
Yeah.

362
00:20:54,800 --> 00:20:55,800
It's a fairly recent addition.

363
00:20:55,800 --> 00:20:56,800
Okay.

364
00:20:56,800 --> 00:20:59,640
So it started kind of organically and then you had some people that were there.

365
00:20:59,640 --> 00:21:04,720
And it started to be formalized only recently as we scaled up and where that need became

366
00:21:04,720 --> 00:21:05,720
much more obvious.

367
00:21:05,720 --> 00:21:07,200
So yeah.

368
00:21:07,200 --> 00:21:15,080
And is that infrastructure team primarily responsible for like where's kind of the line

369
00:21:15,080 --> 00:21:16,960
that they how far up the stack did they go?

370
00:21:16,960 --> 00:21:23,360
Are they worrying about like tools and frameworks and software platforms or is it primarily infrastructure

371
00:21:23,360 --> 00:21:29,400
and network and disk and file systems and connections to the cloud and all of that stuff?

372
00:21:29,400 --> 00:21:31,440
So I would say the latter.

373
00:21:31,440 --> 00:21:34,640
So I think the lines are blurry.

374
00:21:34,640 --> 00:21:39,240
But you need this single responsibility principle that applies well for software.

375
00:21:39,240 --> 00:21:40,720
It also applies for organization.

376
00:21:40,720 --> 00:21:48,640
There's this conways law that says that software organization writes software that is architected

377
00:21:48,640 --> 00:21:51,040
in a way that reflects the organization.

378
00:21:51,040 --> 00:21:55,920
And so I think it's really good if you have like clear responsibilities but also the lines

379
00:21:55,920 --> 00:22:00,240
are a bit blurred because that means that you get a system that is flexible.

380
00:22:00,240 --> 00:22:02,120
But you need these kind of responsibilities too.

381
00:22:02,120 --> 00:22:03,680
So there's some separation.

382
00:22:03,680 --> 00:22:06,720
And in my team in machine learning research and we are the ones that made the decision

383
00:22:06,720 --> 00:22:11,120
to switch to PyTorch for instance and the way we did that is that for instance I re-implemented

384
00:22:11,120 --> 00:22:16,880
YOLO myself a year and a half ago in all the different deep learning frameworks.

385
00:22:16,880 --> 00:22:20,640
And it was after doing that like object detection is really nice because it's a structured

386
00:22:20,640 --> 00:22:23,800
prediction problem that's shoehorned into a classification one.

387
00:22:23,800 --> 00:22:29,280
And so it breaks the APIs that most frameworks support like from the get go.

388
00:22:29,280 --> 00:22:35,000
And so if you use that you know you're stretching a little bit the capabilities of the network

389
00:22:35,000 --> 00:22:38,760
in terms of the framework in terms of their APIs.

390
00:22:38,760 --> 00:22:44,360
And so re-implementing YOLO in all these different frameworks made it clear that as a research

391
00:22:44,360 --> 00:22:47,520
scientist I value flexibility and PyTorch had the flexibility.

392
00:22:47,520 --> 00:22:48,760
Chainer is also very good.

393
00:22:48,760 --> 00:22:51,600
There is other alternatives but debugging and extra.

394
00:22:51,600 --> 00:22:55,720
So at certain levels like that's why I said like research scientists were making engineering

395
00:22:55,720 --> 00:23:01,520
decisions because choosing PyTorch is something that we wanted to make as a research scientist

396
00:23:01,520 --> 00:23:03,160
group.

397
00:23:03,160 --> 00:23:06,560
And for the reason of also the particular research we're doing.

398
00:23:06,560 --> 00:23:11,400
So for instance one of the things we're doing is with the paper recently called SuperDepth

399
00:23:11,400 --> 00:23:16,920
which is a paper about predicting the depth of a scene from a single image.

400
00:23:16,920 --> 00:23:23,440
And so we self-supervised method where is geometry a supervision instead of using labels

401
00:23:23,440 --> 00:23:26,200
because for that you can't label.

402
00:23:26,200 --> 00:23:30,600
And this is again another example where you super-resolution so this idea of high resolution

403
00:23:30,600 --> 00:23:33,160
is actually important also for accuracy.

404
00:23:33,160 --> 00:23:36,880
If you super-resolve the images this helps you predict better depth maps.

405
00:23:36,880 --> 00:23:40,040
It was one of the key findings that we made in the paper.

406
00:23:40,040 --> 00:23:43,760
And so all that is also enabled because of the choices we made on the software sites

407
00:23:43,760 --> 00:23:45,920
and PyTorch and all these kind of things.

408
00:23:45,920 --> 00:23:48,800
And also around the community that there's around it so that enables us to really move

409
00:23:48,800 --> 00:23:51,560
fast and set on the shoulder of giants.

410
00:23:51,560 --> 00:23:57,320
So I talked to different organizations that have differing opinions on how opinionated

411
00:23:57,320 --> 00:23:59,440
to be for their organizations.

412
00:23:59,440 --> 00:24:08,560
It sounds like you're of the mind to kind of stand it as in this case on PyTorch at TRI

413
00:24:08,560 --> 00:24:12,440
as opposed to other places.

414
00:24:12,440 --> 00:24:17,920
We're going to build a framework of platform and it's going to be able to support whatever

415
00:24:17,920 --> 00:24:22,320
the research scientists or engineer wants to use.

416
00:24:22,320 --> 00:24:25,720
Talk me through a little bit of the way you think about that.

417
00:24:25,720 --> 00:24:26,720
Yeah.

418
00:24:26,720 --> 00:24:28,720
I think about it in almost mathematical terms.

419
00:24:28,720 --> 00:24:32,920
That's the bias of our interest trade-off.

420
00:24:32,920 --> 00:24:40,200
If you have small bias and if you have high variance and you're really favoring exploration

421
00:24:40,200 --> 00:24:44,480
for these kinds of stuff, you need a lot of people that are willing to support you.

422
00:24:44,480 --> 00:24:49,280
So if you say, oh yeah, Slurm and Kubernetes and PyTorch and TensorFlow and everything and

423
00:24:49,280 --> 00:24:53,840
the little framework that that random guy made on his own free time.

424
00:24:53,840 --> 00:24:58,720
So first of all, what is actually your business?

425
00:24:58,720 --> 00:25:02,360
Is it making those that infrastructure and no, for us, it's not for us.

426
00:25:02,360 --> 00:25:04,360
It's making awesome robots, awesome machine learning.

427
00:25:04,360 --> 00:25:11,960
So I clearly err more in the bias area, but it's just a little bit of map-produced exploration

428
00:25:11,960 --> 00:25:12,960
and exploitation trade-off.

429
00:25:12,960 --> 00:25:17,080
When you first have high variance and for a little while, you go wild, you explore and

430
00:25:17,080 --> 00:25:18,560
you're maybe not bound by...

431
00:25:18,560 --> 00:25:20,560
You implement yellow and every framework?

432
00:25:20,560 --> 00:25:21,560
Exactly.

433
00:25:21,560 --> 00:25:22,560
Something like this.

434
00:25:22,560 --> 00:25:26,680
But then, at some point, you need to make a decision, because that's not sustainable.

435
00:25:26,680 --> 00:25:29,360
And you want to move fast in a clearly identified direction.

436
00:25:29,360 --> 00:25:33,280
Once you have identified that direction and you never have enough data to prove that

437
00:25:33,280 --> 00:25:34,280
you're right.

438
00:25:34,280 --> 00:25:38,000
So at some point, you have to have expressed leadership and just go with it.

439
00:25:38,000 --> 00:25:39,000
And then you go for it.

440
00:25:39,000 --> 00:25:42,280
And of course, you keep an open mind because then there's the next phase of exploration

441
00:25:42,280 --> 00:25:47,520
because you're right for only a short amount of time in this field of deep learning.

442
00:25:47,520 --> 00:25:52,760
So we take a diversion on kind of the path that you laid out in the present.

443
00:25:52,760 --> 00:25:53,760
Oh, yeah.

444
00:25:53,760 --> 00:25:55,200
We take a turn at step one.

445
00:25:55,200 --> 00:25:58,960
We got beautifully sidetracked, but in a wonderful direction.

446
00:25:58,960 --> 00:26:05,120
So yeah, so we were single nodes, everything in the RAM, and then moved to try the existing

447
00:26:05,120 --> 00:26:08,880
storage solutions, then moved to more distributed file system.

448
00:26:08,880 --> 00:26:13,840
And once we had this, because it's an in-memory distributed file system, we didn't have GPU

449
00:26:13,840 --> 00:26:14,840
starvation anymore.

450
00:26:14,840 --> 00:26:18,480
But then our training was slow because we were limited to a single machine.

451
00:26:18,480 --> 00:26:23,520
And then, Peter instances happened, so we started to use the 100 GPUs much better that

452
00:26:23,520 --> 00:26:26,760
required also tuning the storage again to avoid GPU starvation.

453
00:26:26,760 --> 00:26:30,080
And then we again, augmented to go into multi-node.

454
00:26:30,080 --> 00:26:34,400
And with the distributed file system, that at least the data was easily accessible from

455
00:26:34,400 --> 00:26:36,200
all the different nodes.

456
00:26:36,200 --> 00:26:39,960
And then that's when we started to hit the limitations of distributed PyTorch, which

457
00:26:39,960 --> 00:26:41,840
was very recent at the time.

458
00:26:41,840 --> 00:26:47,880
Before we jump to distributed, I'm curious about the, you know, you've got some, I guess,

459
00:26:47,880 --> 00:26:52,240
quote unquote hyperparameters like virtual CPUs, or you know, the machine configuration

460
00:26:52,240 --> 00:26:53,240
parameters.

461
00:26:53,240 --> 00:26:56,600
Like, you know, they're kind of universal rules of thumb for that kind of thing that

462
00:26:56,600 --> 00:26:58,840
you figured out, or do you experiment with it a lot?

463
00:26:58,840 --> 00:26:59,840
Is it job-dependent?

464
00:26:59,840 --> 00:27:00,840
A lot?

465
00:27:00,840 --> 00:27:04,520
Are you overly focused on economic optimization?

466
00:27:04,520 --> 00:27:05,800
Like how do you work through all that stuff?

467
00:27:05,800 --> 00:27:07,200
So we optimized for time.

468
00:27:07,200 --> 00:27:09,160
We don't optimize for cost yet.

469
00:27:09,160 --> 00:27:10,160
That one was easy.

470
00:27:10,160 --> 00:27:11,160
Yeah.

471
00:27:11,160 --> 00:27:12,800
That was easy.

472
00:27:12,800 --> 00:27:13,800
We haven't.

473
00:27:13,800 --> 00:27:16,360
So that's more again, the job of the infrastructure engineering people.

474
00:27:16,360 --> 00:27:20,120
So does that mean you just get the biggest one with the best GPU and?

475
00:27:20,120 --> 00:27:21,120
You got it.

476
00:27:21,120 --> 00:27:22,120
Exactly.

477
00:27:22,120 --> 00:27:23,120
That's exactly it.

478
00:27:23,120 --> 00:27:27,160
And also because our workloads, it was obvious that that was the only thing to do.

479
00:27:27,160 --> 00:27:28,720
So go big or go home.

480
00:27:28,720 --> 00:27:29,720
That's basically what we did.

481
00:27:29,720 --> 00:27:30,720
Yeah.

482
00:27:30,720 --> 00:27:31,720
Yeah.

483
00:27:31,720 --> 00:27:33,960
So for a single machine, we just like try to scale as much as possible on a single machine.

484
00:27:33,960 --> 00:27:38,880
And that meant these big, big instances, we're psyched to use soon the new ones that

485
00:27:38,880 --> 00:27:39,880
were announced or even bigger.

486
00:27:39,880 --> 00:27:43,600
So actually, that's feedback that we directly gave AWS.

487
00:27:43,600 --> 00:27:46,400
It's quite cool to see that we give them feedback a year ago.

488
00:27:46,400 --> 00:27:49,040
And then, like, keynotes was, oh, and we heard you.

489
00:27:49,040 --> 00:27:50,040
We did this.

490
00:27:50,040 --> 00:27:51,040
Yeah.

491
00:27:51,040 --> 00:27:54,440
And so the biggest instances that they made, that's something that we had asked for and

492
00:27:54,440 --> 00:27:55,600
a couple of other cool stuff.

493
00:27:55,600 --> 00:27:56,600
So.

494
00:27:56,600 --> 00:27:58,480
But you're still limited on a single machine.

495
00:27:58,480 --> 00:28:03,040
And so when you were kind of topping out at a single machine, how long were your jobs

496
00:28:03,040 --> 00:28:04,880
running for?

497
00:28:04,880 --> 00:28:09,280
So at this stage, it was more in the order of weeks.

498
00:28:09,280 --> 00:28:11,000
But that's what kind of job is this?

499
00:28:11,000 --> 00:28:15,400
So the main one in terms of like computational, the most computational expensive one is

500
00:28:15,400 --> 00:28:16,880
semantics segmentation.

501
00:28:16,880 --> 00:28:17,880
Okay.

502
00:28:17,880 --> 00:28:19,400
Because again, it's like high resolution.

503
00:28:19,400 --> 00:28:20,400
It's very dense.

504
00:28:20,400 --> 00:28:22,080
It's dense prediction.

505
00:28:22,080 --> 00:28:25,520
And so that was the most computational expensive job.

506
00:28:25,520 --> 00:28:32,120
Another type of job that we do that is also very expensive is imitation learning.

507
00:28:32,120 --> 00:28:34,680
So we do a lot of research on end-to-end driving.

508
00:28:34,680 --> 00:28:38,000
The main reason is not so much that we believe that it's all you need to driving, obviously

509
00:28:38,000 --> 00:28:39,000
not.

510
00:28:39,000 --> 00:28:41,920
But we get a lot of data from actual cars.

511
00:28:41,920 --> 00:28:43,320
And so we get a lot of demonstrations.

512
00:28:43,320 --> 00:28:46,280
And so there's this really interesting research question that we're working on, which

513
00:28:46,280 --> 00:28:49,440
is how much value can you derive from these demonstrations?

514
00:28:49,440 --> 00:28:54,320
This is a form of supervision on driving that you want to distill down into your models.

515
00:28:54,320 --> 00:28:55,800
And so we do a lot of research there.

516
00:28:55,800 --> 00:29:00,040
And that's, you know, use all the data is really the question that animates us.

517
00:29:00,040 --> 00:29:01,440
How can we use all the data?

518
00:29:01,440 --> 00:29:04,520
And because we can't label everything, we're not going to active learning routes and

519
00:29:04,520 --> 00:29:07,480
the same thing that everybody else is doing because obviously we're doing that.

520
00:29:07,480 --> 00:29:09,280
And that's not the open research challenge.

521
00:29:09,280 --> 00:29:12,560
Everybody knows active learning is a good thing to do when you labels things.

522
00:29:12,560 --> 00:29:14,520
We're really interested in self-supervised learning.

523
00:29:14,520 --> 00:29:17,520
How can we really use all the data by leveraging geometry?

524
00:29:17,520 --> 00:29:18,520
Right.

525
00:29:18,520 --> 00:29:21,000
For instance, how do we use demonstrations at scale?

526
00:29:21,000 --> 00:29:25,440
And so those are the workflows because motivated by the research direction we're going

527
00:29:25,440 --> 00:29:28,160
in, those were the most intensive ones.

528
00:29:28,160 --> 00:29:32,600
And a single machine, these are things that easily take weeks.

529
00:29:32,600 --> 00:29:33,600
Okay.

530
00:29:33,600 --> 00:29:37,680
So then that necessitated jumping over to distributed training?

531
00:29:37,680 --> 00:29:38,680
Yes, absolutely.

532
00:29:38,680 --> 00:29:46,480
Did you do that after the decision to go with PyTorch or did you have to figure that out

533
00:29:46,480 --> 00:29:47,480
twice?

534
00:29:47,480 --> 00:29:52,640
No, we had made so because also we have a lot of like we're in Silicon Valley.

535
00:29:52,640 --> 00:29:57,560
So it's really nice that there's a lot of dense communication between people are not

536
00:29:57,560 --> 00:29:59,880
afraid to share their plans or are going.

537
00:29:59,880 --> 00:30:03,160
So we know to some extent where things were going.

538
00:30:03,160 --> 00:30:04,320
And we know where we wanted to go.

539
00:30:04,320 --> 00:30:07,440
So we also were open about this with different partners.

540
00:30:07,440 --> 00:30:13,720
And so we knew that when we were going to hit the distributed wall, we would be ready

541
00:30:13,720 --> 00:30:14,720
for it.

542
00:30:14,720 --> 00:30:21,000
So we had all those factors were factored in at the decision time at the first one.

543
00:30:21,000 --> 00:30:22,640
So we didn't have to revisit it later.

544
00:30:22,640 --> 00:30:23,640
Okay.

545
00:30:23,640 --> 00:30:24,640
Thankfully.

546
00:30:24,640 --> 00:30:31,480
But you did have to, it sounds like weighed on some PyTorch features to support doing distributed

547
00:30:31,480 --> 00:30:32,480
the way you wanted.

548
00:30:32,480 --> 00:30:33,480
Absolutely.

549
00:30:33,480 --> 00:30:36,280
So initially we were starting to be a little bit afraid that we would have to either

550
00:30:36,280 --> 00:30:41,480
fork or do some like really big upstream contribution to PyTorch too.

551
00:30:41,480 --> 00:30:45,920
And as again, as I was mentioning, it's kind of like a niche application from the deep learning

552
00:30:45,920 --> 00:30:46,920
era.

553
00:30:46,920 --> 00:30:49,800
Like a high resolution semantic segmentation, for instance, it's not something that a

554
00:30:49,800 --> 00:30:51,840
lot of people are pursuing.

555
00:30:51,840 --> 00:30:59,840
So we were starting to wonder if there was another way than to hit like low in the stack.

556
00:30:59,840 --> 00:31:05,240
And we did like fairly intense debugging performance profiling, which is not easy in the cloud because

557
00:31:05,240 --> 00:31:07,920
everything is like in the ether.

558
00:31:07,920 --> 00:31:12,080
And what we found actually, and that's kind of like was an interesting end of the debugging

559
00:31:12,080 --> 00:31:15,920
journey for the performance optimization, was that in the distributed setting when we

560
00:31:15,920 --> 00:31:22,520
had many machines and a very efficient distributed file system, our epochs, right, our passes

561
00:31:22,520 --> 00:31:28,400
over the entire training data became really fast because we had this huge batch sizes.

562
00:31:28,400 --> 00:31:33,160
And everything was flowing really well to the GPUs, GPUs were crunching really quickly.

563
00:31:33,160 --> 00:31:38,520
And what happened is that there was like huge down times, like wait, like there was a bottleneck

564
00:31:38,520 --> 00:31:39,520
somewhere.

565
00:31:39,520 --> 00:31:44,440
And it turns out that bottleneck, which was hard to find, was in the data loaders when

566
00:31:44,440 --> 00:31:50,960
you do, you know, you how you do multiple workers that pre-fetch the data for you in parallel

567
00:31:50,960 --> 00:31:54,680
to feed the GPUs, like the super hungry GPUs, like really quickly.

568
00:31:54,680 --> 00:31:58,360
And in PyTorch, because you have this global interpreter lock, you have to use processes

569
00:31:58,360 --> 00:32:00,560
and not threads to do that.

570
00:32:00,560 --> 00:32:04,440
And so it's stuck PyTorch data loaders, it starts workers, which starts their multiple

571
00:32:04,440 --> 00:32:06,240
processes.

572
00:32:06,240 --> 00:32:11,640
And forking, like creating a process is much more heavy than creating a thread.

573
00:32:11,640 --> 00:32:17,640
And when you do this very quickly in a distributed setting, that actually became the bottleneck.

574
00:32:17,640 --> 00:32:21,120
So we had to change the data flow and the way we were doing this pre-fetching and those

575
00:32:21,120 --> 00:32:26,080
queues by having some kind of like always warm queues that were kind of like infinitely

576
00:32:26,080 --> 00:32:29,880
producing and then infinitely consuming on the other hand.

577
00:32:29,880 --> 00:32:34,240
And we're playing with fire a little bit there because we're creating racing conditions.

578
00:32:34,240 --> 00:32:36,480
And so that locks can happen.

579
00:32:36,480 --> 00:32:42,760
But because this doesn't sound like a plug-in or something that's like a funnel plug-in.

580
00:32:42,760 --> 00:32:44,240
So this was on top, right?

581
00:32:44,240 --> 00:32:49,240
This was something that we were using in stock PyTorch except for the data loaders.

582
00:32:49,240 --> 00:32:54,080
Except for the data loaders, where we changed the data loaders to something else.

583
00:32:54,080 --> 00:32:58,720
And that's what I mentioned by this, warm producers, infinite and this racing conditions.

584
00:32:58,720 --> 00:33:00,720
And recently we've been playing more and more with Horovod.

585
00:33:00,720 --> 00:33:03,880
This is also an open-source library made by Uber.

586
00:33:03,880 --> 00:33:04,880
And it's with PyTorch?

587
00:33:04,880 --> 00:33:05,880
It works with PyTorch.

588
00:33:05,880 --> 00:33:06,880
I didn't realize that.

589
00:33:06,880 --> 00:33:07,880
It's TensorFlow and PyTorch.

590
00:33:07,880 --> 00:33:10,040
It's starting with TensorFlow and now it's PyTorch.

591
00:33:10,040 --> 00:33:14,000
And actually, this provides this great MPI interface.

592
00:33:14,000 --> 00:33:17,400
And that enables, so it's a little bit less efficient for our niche application.

593
00:33:17,400 --> 00:33:19,080
But we have other applications.

594
00:33:19,080 --> 00:33:22,800
And so the flexibility that you get with Horovod might be worth the price in performance.

595
00:33:22,800 --> 00:33:26,320
So we're considering moving more and more stuff to Horovod.

596
00:33:26,320 --> 00:33:31,640
It sounds like you were able to, you invested a little bit in kind of tweaking PyTorch to make

597
00:33:31,640 --> 00:33:32,640
it work.

598
00:33:32,640 --> 00:33:33,640
But it kind of caught up.

599
00:33:33,640 --> 00:33:36,800
And now you've got some solutions that work for you.

600
00:33:36,800 --> 00:33:45,440
And so you are able to do distributed training like were you done, like pop the champagne.

601
00:33:45,440 --> 00:33:47,240
So it's interesting.

602
00:33:47,240 --> 00:33:51,280
And one way, yes, because there was a lot of internal questions.

603
00:33:51,280 --> 00:33:53,800
So like I said, TRIRI is a robotics company.

604
00:33:53,800 --> 00:33:58,400
And one thing you have to understand is that in autonomous driving, roboticists, they do

605
00:33:58,400 --> 00:34:03,800
very things very differently than the really hardcore deep learning crowd, which is they

606
00:34:03,800 --> 00:34:07,600
used to light our sensors, clustering methods, like DARPA challenge stuff.

607
00:34:07,600 --> 00:34:11,800
They work awesomely well and have like much stronger safety guarantees than what we

608
00:34:11,800 --> 00:34:12,960
do in deep learning.

609
00:34:12,960 --> 00:34:19,720
And so they're not necessarily very experienced in the deep learning way.

610
00:34:19,720 --> 00:34:23,840
And so doing these kind of things also means that like training for weeks to develop an

611
00:34:23,840 --> 00:34:26,080
algorithm, that sounds insane.

612
00:34:26,080 --> 00:34:30,280
And so here doing this distributed training and showing them internally that, hey, you can

613
00:34:30,280 --> 00:34:33,080
do things really quickly in the cloud at scale.

614
00:34:33,080 --> 00:34:37,040
And you can tweak your models and do your develop your algorithms almost as quickly as if

615
00:34:37,040 --> 00:34:38,680
you were not doing deep learning.

616
00:34:38,680 --> 00:34:43,000
That was kind of like a champagne popping bottle popping moments.

617
00:34:43,000 --> 00:34:44,000
Where is it?

618
00:34:44,000 --> 00:34:45,000
Oh, that's super cool.

619
00:34:45,000 --> 00:34:47,280
Now we actually are going to run with it.

620
00:34:47,280 --> 00:34:49,840
Of course, we're not done on the research side.

621
00:34:49,840 --> 00:34:55,000
Now we can basically study what happens when you do self-supervised learning on a lot

622
00:34:55,000 --> 00:34:59,680
of videos, what happens if you do imitation learning on really a lot of demonstrations.

623
00:34:59,680 --> 00:35:04,840
And actually we have a paper that we're going to push on archive soon, where we really

624
00:35:04,840 --> 00:35:10,040
push the boundaries of imitation learning and show that you can go quite far with like

625
00:35:10,040 --> 00:35:11,240
deeper models and more data.

626
00:35:11,240 --> 00:35:15,160
It's kind of like a prototypical deep learning story, more data, deeper models, that works

627
00:35:15,160 --> 00:35:16,160
really well.

628
00:35:16,160 --> 00:35:20,960
That's only thanks to the infrastructure that we had that we had an awesome intern, Felipe,

629
00:35:20,960 --> 00:35:23,080
that could do these experiments, thanks to that.

630
00:35:23,080 --> 00:35:27,240
So we're not there, but we're definitely enjoying the fruit of our labor.

631
00:35:27,240 --> 00:35:28,240
Nice.

632
00:35:28,240 --> 00:35:33,280
So there's a semantic segmentation that before you made it over to distributed was taking

633
00:35:33,280 --> 00:35:36,320
weeks, what does it take now typically?

634
00:35:36,320 --> 00:35:38,720
So we can do things in like under two hours now.

635
00:35:38,720 --> 00:35:39,720
Oh, wow.

636
00:35:39,720 --> 00:35:40,720
Wow.

637
00:35:40,720 --> 00:35:42,480
That's really fast, yeah.

638
00:35:42,480 --> 00:35:45,000
What does that require in terms of a cluster size?

639
00:35:45,000 --> 00:35:54,960
So we typically run jobs at, I think right now, beyond eight machines, so beyond 64 GPUs

640
00:35:54,960 --> 00:35:57,240
for single network, right?

641
00:35:57,240 --> 00:36:02,040
We find that we don't need to go beyond that at this stage, so we don't do like a single

642
00:36:02,040 --> 00:36:07,320
network on 256 GPUs or something like this, which is the most people that do that at least

643
00:36:07,320 --> 00:36:14,000
publicly do that is just to beat speed records on ImageNet, which you know, it's nice.

644
00:36:14,000 --> 00:36:15,640
That's not really what we're going for.

645
00:36:15,640 --> 00:36:22,280
So for the jobs we do, let's say between four and eight machines, so 32 and 64 GPUs,

646
00:36:22,280 --> 00:36:27,320
provides us with like a small turnaround time and good deterioration speed for our research.

647
00:36:27,320 --> 00:36:32,600
Is it that, you know, the complexity involved in going from eight to, you know, some multiple

648
00:36:32,600 --> 00:36:38,320
of eight isn't, you know, is overburdened some?

649
00:36:38,320 --> 00:36:45,680
Is it that the value of going from two hours to, you know, 30 minutes isn't there?

650
00:36:45,680 --> 00:36:50,920
So there's, there's some like more infrastructure problems around like limitation of supply,

651
00:36:50,920 --> 00:36:56,440
you know, like we often joke at TRI, we have infinite GPUs because we're in the cloud.

652
00:36:56,440 --> 00:37:00,320
But in reality, it's not necessarily there because availability zones, et cetera, so some

653
00:37:00,320 --> 00:37:02,520
things that I don't fully understand.

654
00:37:02,520 --> 00:37:09,080
The other thing is also at some point, you start to hit algorithmic difficulties.

655
00:37:09,080 --> 00:37:14,560
So like for instance a year ago, people were convinced you couldn't do large batch SGD

656
00:37:14,560 --> 00:37:17,440
because you would have generalization performance issues.

657
00:37:17,440 --> 00:37:21,600
And that's when Facebook made their, you know, oh, actually no, it's just a numerical optimization

658
00:37:21,600 --> 00:37:22,600
problem.

659
00:37:22,600 --> 00:37:26,880
You just got to do the linear scaling rule, this warm up, you have to twit a little bit.

660
00:37:26,880 --> 00:37:28,720
And then yes, it generalizes the same way.

661
00:37:28,720 --> 00:37:34,440
And that's when you have this explosion of large batch training methods, but still there's

662
00:37:34,440 --> 00:37:35,760
a limit to that, right?

663
00:37:35,760 --> 00:37:39,960
And depending on your data sets, depending on your learning algorithm, depending on also

664
00:37:39,960 --> 00:37:41,200
the data at hand, right?

665
00:37:41,200 --> 00:37:48,000
So the particular generalization gap that you have to overcome large, like there's a good

666
00:37:48,000 --> 00:37:49,880
size of batch size.

667
00:37:49,880 --> 00:37:54,080
So beyond like very, like there's a limit to how big your batch can be.

668
00:37:54,080 --> 00:37:55,080
Okay.

669
00:37:55,080 --> 00:38:00,720
So if you have a single cluster running at a time, or do you, you know, spin up multiple

670
00:38:00,720 --> 00:38:05,480
clusters and run multiple training jobs kind of constantly all the time, and does that,

671
00:38:05,480 --> 00:38:12,680
you know, if that's the case, or even if not really, does that level of change drive

672
00:38:12,680 --> 00:38:17,440
you to use something like Kubernetes or some kind of infrastructure, may you've mentioned

673
00:38:17,440 --> 00:38:19,960
Kubernetes and Slurm and some other things.

674
00:38:19,960 --> 00:38:20,960
Yeah.

675
00:38:20,960 --> 00:38:25,240
So the way we do it is we provision clusters on demand by the researchers.

676
00:38:25,240 --> 00:38:32,160
So we tend to have a couple of like clusters per researcher, per project.

677
00:38:32,160 --> 00:38:36,520
So that's really nice also because it helps a lot with experimental management, you know,

678
00:38:36,520 --> 00:38:37,520
like babysitting experiments.

679
00:38:37,520 --> 00:38:44,480
It's this full time job when you get closer to the deadline and having like these separate

680
00:38:44,480 --> 00:38:48,400
clusters for the separate workflows for the separate people.

681
00:38:48,400 --> 00:38:53,840
That helps with just the cognitive load of where you were, et cetera.

682
00:38:53,840 --> 00:38:58,040
And so we didn't feel like, and again, my team is like fairly small, we're like 12, 13

683
00:38:58,040 --> 00:38:59,040
people.

684
00:38:59,040 --> 00:39:00,040
Okay.

685
00:39:00,040 --> 00:39:04,160
So we don't need necessarily, we do very large experiments, but we don't necessarily

686
00:39:04,160 --> 00:39:08,200
do many, many different experiments, we like probably have four or five projects at the

687
00:39:08,200 --> 00:39:09,200
same time.

688
00:39:09,200 --> 00:39:10,200
Okay.

689
00:39:10,200 --> 00:39:14,120
So no need for like complex scheduling or monitoring or queuing or these kind of things.

690
00:39:14,120 --> 00:39:15,640
It's going to get there and we know it.

691
00:39:15,640 --> 00:39:19,000
So that's why we're preparing for that.

692
00:39:19,000 --> 00:39:21,640
And I have like more than HPC experience.

693
00:39:21,640 --> 00:39:26,320
So that's why I favor a bit Slurm also because when we started having this discussion,

694
00:39:26,320 --> 00:39:29,480
Kubernetes was not supporting GPUs now they do.

695
00:39:29,480 --> 00:39:34,400
And the only thing I'm a little bit afraid of is adding interaction levels because again,

696
00:39:34,400 --> 00:39:35,920
we care about speed and performance.

697
00:39:35,920 --> 00:39:40,760
So the story, the stock that I was talking mentioning before, we could do that because

698
00:39:40,760 --> 00:39:45,440
we were a working tightly with the infrastructure engineering team or AWS or Nvidia.

699
00:39:45,440 --> 00:39:50,480
We were actually talking to them directly and we actually knew what was going on under

700
00:39:50,480 --> 00:39:51,480
the hood.

701
00:39:51,480 --> 00:39:56,760
So we could pop up the look under the hood and say, oh, yeah, this is wrong or this is

702
00:39:56,760 --> 00:39:58,680
wrong or this smells funny.

703
00:39:58,680 --> 00:40:00,000
Can you check this?

704
00:40:00,000 --> 00:40:05,440
And so if we do too much, add too many layers of interaction like Kubernetes might be

705
00:40:05,440 --> 00:40:06,440
that.

706
00:40:06,440 --> 00:40:07,440
I don't know.

707
00:40:07,440 --> 00:40:08,440
I'm not sure.

708
00:40:08,440 --> 00:40:11,960
I'm a little bit afraid that we lose control and we lose interpretability in a sense.

709
00:40:11,960 --> 00:40:16,320
And our models are already hard to interpret.

710
00:40:16,320 --> 00:40:21,400
You mentioned in passing the managing experiments, experiment management.

711
00:40:21,400 --> 00:40:27,280
Have you built any higher level tooling or infrastructure to help research scientists

712
00:40:27,280 --> 00:40:28,280
do that?

713
00:40:28,280 --> 00:40:31,520
Or is there something that you're using off the shelf or is it, you know, post-it notes

714
00:40:31,520 --> 00:40:33,320
and Excel spreadsheet something?

715
00:40:33,320 --> 00:40:34,320
Yeah.

716
00:40:34,320 --> 00:40:36,640
So we did our fair share of Excel scheduling.

717
00:40:36,640 --> 00:40:39,280
Of course, do that a little bit.

718
00:40:39,280 --> 00:40:43,720
But we had an interesting journey where we initially used TensorBoard, but then TensorBoard

719
00:40:43,720 --> 00:40:46,520
didn't scale for us because that's on disk.

720
00:40:46,520 --> 00:40:48,760
And so it just didn't work.

721
00:40:48,760 --> 00:40:52,320
We switched to VISDOM, but VISDOM is a little bit too bare bones.

722
00:40:52,320 --> 00:40:56,880
It's very flexible, but there was also other issues there.

723
00:40:56,880 --> 00:40:58,800
So we're really starting to think about this.

724
00:40:58,800 --> 00:41:07,760
And at the same time, we got in touch with a company startup called WNB, WNB, WNB, WNB.

725
00:41:07,760 --> 00:41:12,840
And they basically, because we're just creating this company and basically talk to us and

726
00:41:12,840 --> 00:41:17,000
open AI and looking for like, what do you guys need?

727
00:41:17,000 --> 00:41:19,880
And we really worked really tightly with them.

728
00:41:19,880 --> 00:41:22,120
We have the customers now.

729
00:41:22,120 --> 00:41:26,560
And we have this really cool, like, experiment dashboard, experiment management system, where

730
00:41:26,560 --> 00:41:30,600
we can do a lot of visualization of experiments, multi-user, multi-project.

731
00:41:30,600 --> 00:41:32,840
It scales really well.

732
00:41:32,840 --> 00:41:34,840
And yeah, so that's what we used today.

733
00:41:34,840 --> 00:41:37,600
And so we're really, again, not optimizing for cost.

734
00:41:37,600 --> 00:41:39,400
We're optimizing for time.

735
00:41:39,400 --> 00:41:43,280
And because there's a lot of excitement around machine learning, there's a lot of opportunities

736
00:41:43,280 --> 00:41:44,640
to work with great partners.

737
00:41:44,640 --> 00:41:46,440
So that's our approach.

738
00:41:46,440 --> 00:41:50,400
When you first mentioned scale there, you were talking about on disk performance of

739
00:41:50,400 --> 00:41:58,400
TensorBoard, but then later when you're talking about its scaling, like, how is it doing

740
00:41:58,400 --> 00:42:02,120
in terms of, I mean, you're not a huge organization, but is it scaling in terms of the number

741
00:42:02,120 --> 00:42:05,040
or experiments that you do?

742
00:42:05,040 --> 00:42:09,440
So right now, we're, like, probably less than 20 users, so that's service.

743
00:42:09,440 --> 00:42:14,600
So I can't say about the scaling in the user, but we do a lot of experiments.

744
00:42:14,600 --> 00:42:19,760
Like, I mean, as you know, researchers, we, we, a lot of research is the speculative

745
00:42:19,760 --> 00:42:22,840
late strategy, which is you throw it at the wall and you see what sticks.

746
00:42:22,840 --> 00:42:27,000
So you have in a high-merch optimization, all these kind of things means that the single

747
00:42:27,000 --> 00:42:31,000
researcher, especially when you have this nice infrastructure in terms of machines and

748
00:42:31,000 --> 00:42:35,600
experiments you can run, you're going to, like, have a fire hose of metrics you want

749
00:42:35,600 --> 00:42:37,080
to visualize.

750
00:42:37,080 --> 00:42:39,600
And so that scales really well for that.

751
00:42:39,600 --> 00:42:42,920
And again, we're not in the business of making dashboards or these things, so we're really

752
00:42:42,920 --> 00:42:47,560
happy to partner or buy whatever is not our core business, which is really about this deep

753
00:42:47,560 --> 00:42:49,760
learning models for driving.

754
00:42:49,760 --> 00:42:54,280
And does WNB do the hyper-performer optimization for you?

755
00:42:54,280 --> 00:42:55,280
Or do you do service?

756
00:42:55,280 --> 00:42:57,680
Yeah, so we do our own stuff there.

757
00:42:57,680 --> 00:43:03,000
They have some services there, which we don't use, but we, I think hyper-optimization

758
00:43:03,000 --> 00:43:06,200
is, like, I'm still on the fence whether this is something internal or something that

759
00:43:06,200 --> 00:43:11,320
we can partner with, because there is, like, typical patterns and typical, like, algorithms

760
00:43:11,320 --> 00:43:15,880
and I've been a big user of hyper-opt, so you can do biogen hyper-optimization and these

761
00:43:15,880 --> 00:43:18,040
kind of things.

762
00:43:18,040 --> 00:43:21,360
And sure, this is, like, almost standardized, so you could imagine having a service for

763
00:43:21,360 --> 00:43:22,560
that instead.

764
00:43:22,560 --> 00:43:26,800
But some of these things actually have to hook up really deep into, so it depends on the

765
00:43:26,800 --> 00:43:29,440
model and the research project you're doing.

766
00:43:29,440 --> 00:43:34,240
So there's a blurred line there, and there's awesome, like, general purpose algorithms,

767
00:43:34,240 --> 00:43:35,240
I think.

768
00:43:35,240 --> 00:43:39,000
The one that I use the most recently that I really like is hyper-band, which is kind

769
00:43:39,000 --> 00:43:43,920
of, like, a band-it approach that's using the fact that it's our optimization is sequential,

770
00:43:43,920 --> 00:43:47,760
so you can restart from a checkpoint and continue any of these kind of things.

771
00:43:47,760 --> 00:43:52,760
So yeah, on the fence, some of the things in-house, some of the things, black box, it's

772
00:43:52,760 --> 00:43:55,000
not, I'm on the fence for this.

773
00:43:55,000 --> 00:44:00,720
And so I'm making an assumption that you don't have to worry about, besides from the kind

774
00:44:00,720 --> 00:44:05,960
of distributive file system issues that we've talked about, a lot of the kind of traditional

775
00:44:05,960 --> 00:44:11,240
enterprise data management, you know, data lakes, data warehouse, hooking into data stores,

776
00:44:11,240 --> 00:44:12,240
that stuff.

777
00:44:12,240 --> 00:44:13,600
You just need big, dist store stuff.

778
00:44:13,600 --> 00:44:14,600
Yeah.

779
00:44:14,600 --> 00:44:19,960
So we have, like, we use S3 a lot, and we use to use S3 directly.

780
00:44:19,960 --> 00:44:23,320
And so basically, what we've been doing is just, like, what happened with processors.

781
00:44:23,320 --> 00:44:27,640
We add layers of cache, you know, and hotter and hotter caches, which are getting smaller

782
00:44:27,640 --> 00:44:30,080
as they are getting hotter.

783
00:44:30,080 --> 00:44:34,240
And we have to, like, asynchronously, preemptively fill those caches and these kind of things.

784
00:44:34,240 --> 00:44:35,240
So it's always the same thing.

785
00:44:35,240 --> 00:44:40,440
Is that these caches, like, the, you know, the various S3 features, like, glacier and all

786
00:44:40,440 --> 00:44:41,440
these?

787
00:44:41,440 --> 00:44:44,440
Yeah, so you can see basically all these different types of storages, right, as these

788
00:44:44,440 --> 00:44:49,040
cache, like, like, these are, I call them caches, but it's a metaphorical cache, right?

789
00:44:49,040 --> 00:44:50,040
Right.

790
00:44:50,040 --> 00:44:57,640
S3, we used to use S3 directly as, like, S3 to GPUs, and that obviously didn't scale.

791
00:44:57,640 --> 00:45:02,880
And so we added this, like, you know, different storages and distributed files, yeah, EBS,

792
00:45:02,880 --> 00:45:03,880
etc.

793
00:45:03,880 --> 00:45:04,880
Yeah.

794
00:45:04,880 --> 00:45:05,880
Yeah.

795
00:45:05,880 --> 00:45:09,520
And then you have these prefetch and queues that are, literally, feeling the RAM with,

796
00:45:09,520 --> 00:45:13,320
next to your GPUs, and so you have this ultimate layer of cache, right?

797
00:45:13,320 --> 00:45:14,320
Okay.

798
00:45:14,320 --> 00:45:19,600
And then on the back end, are you, do you have to worry about inference and model serving?

799
00:45:19,600 --> 00:45:25,440
So at this moment, the inference is the models we serve are in our robots, right?

800
00:45:25,440 --> 00:45:27,040
So that's a big thing, right?

801
00:45:27,040 --> 00:45:28,040
Right.

802
00:45:28,040 --> 00:45:31,520
Is that the models we serve are the ones that are going to be in the path to actuation

803
00:45:31,520 --> 00:45:32,520
of the car.

804
00:45:32,520 --> 00:45:37,520
So there we have, like, amazing driving technology teams, like, that own parts of the

805
00:45:37,520 --> 00:45:41,600
stack, like, we have an object perception team, we have a slam team, we have a planning

806
00:45:41,600 --> 00:45:43,000
and controls team.

807
00:45:43,000 --> 00:45:48,160
And these guys, they basically take our models or make their own.

808
00:45:48,160 --> 00:45:54,200
And they make them more efficient, fit them in the computational budget that they have.

809
00:45:54,200 --> 00:45:55,720
And that's how we serve models.

810
00:45:55,720 --> 00:46:00,920
So that's a fairly different model than, let's say, web-based application.

811
00:46:00,920 --> 00:46:01,920
Yeah.

812
00:46:01,920 --> 00:46:10,480
Is that the process of getting the models to fit compression or pruning or what have

813
00:46:10,480 --> 00:46:14,480
you, is that there's still a manual process to large degrees, right?

814
00:46:14,480 --> 00:46:21,520
So to some extent, it's kind of a little bit weird because there are some ways that are

815
00:46:21,520 --> 00:46:24,440
productized, a little bit like there's sensor RT and these kind of things.

816
00:46:24,440 --> 00:46:27,920
But it's still more an art than a science, so it doesn't always work.

817
00:46:27,920 --> 00:46:33,040
It works for certain types of networks like out of the box with some it doesn't.

818
00:46:33,040 --> 00:46:37,800
And so there you have some tools or bag of tricks that are general purpose that you can

819
00:46:37,800 --> 00:46:42,400
throw at this and that you should throw at this, definitely, and that our teams are doing.

820
00:46:42,400 --> 00:46:46,320
So upstream or upstream on the research side and my team what we're doing, you can learn

821
00:46:46,320 --> 00:46:52,560
models that are compressible or that are amenable to compression by having some compressibility

822
00:46:52,560 --> 00:46:53,960
factor built in.

823
00:46:53,960 --> 00:46:57,680
You can have also small models, like as I mentioned, right?

824
00:46:57,680 --> 00:47:02,040
And there's more and more research results that show that small models can generalize as

825
00:47:02,040 --> 00:47:03,200
well as big models.

826
00:47:03,200 --> 00:47:07,400
They just have to train for longer or you have to change the learning algorithm.

827
00:47:07,400 --> 00:47:13,960
And another thing is one of the big things we're trying to do is how far can we do multi-test

828
00:47:13,960 --> 00:47:15,360
learning, right?

829
00:47:15,360 --> 00:47:20,320
Because if you can have a shared backbone and squeeze many different things, that's awesome.

830
00:47:20,320 --> 00:47:24,960
And the one recent project that we did around panoptic segmentation is basically this.

831
00:47:24,960 --> 00:47:30,200
It basically takes a mental segmentation and takes instant segmentation, so mask our

832
00:47:30,200 --> 00:47:36,320
CNN and these kind of things and that works really well, but that's extremely slow.

833
00:47:36,320 --> 00:47:43,280
I think like mask rescinds me like 150 milliseconds per image or something and you have to basically

834
00:47:43,280 --> 00:47:49,000
reduce those models and merge them together with maybe different heads to make it efficient.

835
00:47:49,000 --> 00:47:53,520
And we made a recent paper, it's going to be an archive soon called tasknet for things

836
00:47:53,520 --> 00:47:59,120
and stuff consistency network where we basically merge them together and have a task consistency,

837
00:47:59,120 --> 00:48:02,160
a cross task consistency because the main problem with multi-test learning is if you just

838
00:48:02,160 --> 00:48:05,880
sum the losses, it doesn't necessarily, they maybe contradict each other.

839
00:48:05,880 --> 00:48:09,720
So when you're arriving at an intersection, it says turn left or turn right, you don't

840
00:48:09,720 --> 00:48:12,840
know you go in the middle, there's a lot of work, not a good idea.

841
00:48:12,840 --> 00:48:17,120
So like imagine the gradients might be pushing in orthogonal directions.

842
00:48:17,120 --> 00:48:22,360
So one of the key things we did is we actually augmented the objective to have a consistency

843
00:48:22,360 --> 00:48:28,560
encouraging objective and between the stuff classes, like so road, sky, et cetera, on

844
00:48:28,560 --> 00:48:34,000
the semantic segmentation side and the thing classes on the instant segmentation side.

845
00:48:34,000 --> 00:48:39,000
So merging these networks is one way to be more efficient and that's some of the very

846
00:48:39,000 --> 00:48:40,720
recent work that we've been doing.

847
00:48:40,720 --> 00:48:45,000
How have we done in terms of kind of getting a lay of the land of your presentation?

848
00:48:45,000 --> 00:48:47,000
We went way beyond.

849
00:48:47,000 --> 00:48:52,280
Yes, so excellent, nice, awesome.

850
00:48:52,280 --> 00:48:55,560
Any kind of parting thoughts or words?

851
00:48:55,560 --> 00:49:02,080
No, I think we're really excited to continue this direction of large-scale deep learning

852
00:49:02,080 --> 00:49:08,560
in the cloud and tackling this really, really challenging open research questions, yeah.

853
00:49:08,560 --> 00:49:12,520
So we're continuing to grow very, very fast and excited to be in that space of self-driving

854
00:49:12,520 --> 00:49:14,320
robots and with deep learning.

855
00:49:14,320 --> 00:49:16,720
So very happy to have been able to talk about it.

856
00:49:16,720 --> 00:49:17,720
Awesome.

857
00:49:17,720 --> 00:49:18,720
Well, thanks so much, Adrian.

858
00:49:18,720 --> 00:49:19,720
It was awesome to have you on the show.

859
00:49:19,720 --> 00:49:20,720
It was a pleasure.

860
00:49:20,720 --> 00:49:26,080
All right, everyone, that's our show for today.

861
00:49:26,080 --> 00:49:30,960
For more information about today's guests or to follow along with our AI platform's volume

862
00:49:30,960 --> 00:49:36,960
2 series, visit twimmelai.com slash AI Platforms 2.

863
00:49:36,960 --> 00:49:42,280
Thanks once again to Sigop for their sponsorship of this series and support of the show.

864
00:49:42,280 --> 00:49:47,560
To check out what they're up to and take advantage of their exclusive offer for Twimmel listeners,

865
00:49:47,560 --> 00:49:51,280
visit twimmelai.com slash Sigop.

866
00:49:51,280 --> 00:50:01,280
As always, thanks so much for listening and catch you next time.

