1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:34,860
I'm your host Sam Charrington. A couple of weeks ago, I had the pleasure of attending

4
00:00:34,860 --> 00:00:40,200
the NURPS conference in Montreal. I had a wonderful time there and of course, the highlight

5
00:00:40,200 --> 00:00:45,880
was the chance to meet a ton of Tummel listeners. I held two fun meetups at the conference. The

6
00:00:45,880 --> 00:00:51,400
first was focused on AI and production and AI platforms and infrastructure and it attracted

7
00:00:51,400 --> 00:00:57,400
a pretty nice crowd. We basically took over a dumpling restaurant in Chinatown right by the

8
00:00:57,400 --> 00:01:02,440
convention center. I also held a listener meetup one evening and got to hang out with listeners

9
00:01:02,440 --> 00:01:08,200
from all over the country and world. Of course, I took advantage of the opportunity to sit down

10
00:01:08,200 --> 00:01:13,240
with a few of the many great researchers attending and presenting the conference and this week on

11
00:01:13,240 --> 00:01:21,960
the show, we're excited to share our 2018 NURPS series. In this, the first episode of the series,

12
00:01:21,960 --> 00:01:27,320
we're joined by Coonlay Olucatune, professor in the department of electrical and computer science

13
00:01:27,320 --> 00:01:33,800
at Stanford University and chief technologist at San Bonova Systems. Coonlay was an invited speaker

14
00:01:33,800 --> 00:01:38,840
at the conference this year, presenting on designing computer systems for software 2.0.

15
00:01:38,840 --> 00:01:44,840
In our conversation, we discussed various aspects of designing hardware systems for machine and

16
00:01:44,840 --> 00:01:51,240
deep learning, touching on multi-core processor design, domain specific languages, and graph-based

17
00:01:51,240 --> 00:01:55,480
hardware. We covered the limitations of the current crop of machine learning hardware,

18
00:01:56,040 --> 00:02:02,440
such as GPUs, and peer a bit into the future as well. This was a fun one that I know you'll enjoy.

19
00:02:02,440 --> 00:02:11,960
And now on to the show. All right, everyone. I am here with Coonlay Olucatune. Coonlay is a

20
00:02:11,960 --> 00:02:17,160
professor of electrical engineering and computer science at Stanford University as well as the

21
00:02:17,160 --> 00:02:22,600
chief technologist at San Bonova Systems. Coonlay, welcome to this week in machine learning and AI.

22
00:02:22,600 --> 00:02:31,960
Thank you. So you just came from giving a talk on designing computer systems for software 2.0.

23
00:02:31,960 --> 00:02:41,080
Here at NURPS in Montreal, and I am really excited about digging into the topic of your talk. But

24
00:02:41,080 --> 00:02:45,480
before we do that, I'd love to learn a little bit more about your background. How did you get

25
00:02:46,120 --> 00:02:52,280
started in kind of this intersection of computer systems, architecture, and machine learning?

26
00:02:52,280 --> 00:02:59,000
Yeah, so I've been in computer architecture for a long time. I've been at Stanford for almost

27
00:02:59,000 --> 00:03:07,880
27 years. And I had done a lot of work in computer hardware. In fact, many of the ideas that

28
00:03:07,880 --> 00:03:14,040
underlie multi-core microprocessors were developed in my lab in the mid-90s before they became

29
00:03:14,040 --> 00:03:22,680
mainstream. And I did a company that started up. It was called a Farrow Web Systems. And we did some

30
00:03:22,680 --> 00:03:30,440
high-throughput processes for the data center. And it got acquired by a Sun Microsystems.

31
00:03:31,640 --> 00:03:38,760
Subsequently, Sun was acquired by Oracle. And all the big spark servers were basically based

32
00:03:38,760 --> 00:03:46,120
on the technology that was acquired back in 2002. So I have a long history of kind of doing

33
00:03:46,120 --> 00:03:56,760
hardware. About 10 years ago, after I came back from doing the first startup, I realized that the

34
00:03:56,760 --> 00:04:04,280
issue going forward wasn't so much building new hardware. It was actually getting programs to run

35
00:04:04,280 --> 00:04:11,960
efficiently on that hardware and getting programs at all. And so we've gone into the right ones

36
00:04:11,960 --> 00:04:19,000
run anywhere at Sun, right? Big cloud emission there. Yeah, of course the joke was right once

37
00:04:19,000 --> 00:04:26,600
debug everywhere. But yeah, I mean, I think Java didn't help the cause really.

38
00:04:29,560 --> 00:04:36,760
Many things worse from an efficiency point of view, right? So certainly, you could imagine that

39
00:04:36,760 --> 00:04:43,960
maybe it may develop as more productive, but that's arguable too. We're still garbage collecting

40
00:04:43,960 --> 00:04:51,720
to this day, right? Exactly. So anyway, about 12 years ago now, we started thinking about,

41
00:04:51,720 --> 00:04:57,800
how could we kind of make a difference to the application developer? How could we make their

42
00:04:57,800 --> 00:05:08,440
life easier? And you know, even go you go back to sort of 2006, 2007. And it was clear that

43
00:05:08,440 --> 00:05:15,160
the world of high performance hardware, which is the world that I have spent most of my life in,

44
00:05:15,160 --> 00:05:23,640
wasn't just parallel cores, right? It wasn't just multiple CPUs. It was also these new

45
00:05:23,640 --> 00:05:33,240
up and coming things called GPUs. And then, of course, it wasn't just shared memory, it was also

46
00:05:33,240 --> 00:05:39,560
clusters, right? And people wanted to program these things. And yet every programming,

47
00:05:39,560 --> 00:05:46,120
everything, everything, every program you needed to write needed to be different for the

48
00:05:46,120 --> 00:05:54,520
particular platform that you wanted to run on, right? And that, to me, seemed like a real problem

49
00:05:54,520 --> 00:05:59,800
from the point of view of the software developers. And so what we decided the right approach

50
00:06:00,680 --> 00:06:07,880
was to look at using domain-specific languages, right? So domain-specific languages had been around,

51
00:06:07,880 --> 00:06:15,800
and then you're probably familiar with them, but let me just define them, just to make sure that

52
00:06:15,800 --> 00:06:20,760
everybody understands what they are. So they, the domain-specific languages, as the name suggests,

53
00:06:21,720 --> 00:06:26,520
are designed for a particular domain, right? That was a particular problem domain that you

54
00:06:26,520 --> 00:06:33,880
want to solve. And so if you can give the programmer both the operators and the data types that

55
00:06:33,880 --> 00:06:37,720
match that domain, then they can, you make their life a lot easier, right? Really good example

56
00:06:38,440 --> 00:06:43,000
since we're talking about machine learning would be MATLAB, right? So matrix and linear algebra,

57
00:06:43,000 --> 00:06:48,520
you give yourself a bunch of matrix and linear algebra operators and data types, matrices,

58
00:06:48,520 --> 00:06:54,200
and vectors, and so on. And then now you can write your algorithms with linear algebra much

59
00:06:54,200 --> 00:06:59,800
more easily. So, you know, so it sounds like if I can interrupt, it sounds like you consider MATLAB

60
00:06:59,800 --> 00:07:08,840
to be a DSL, which suggests to me that there's a spectrum of domain specificity in the DSL world.

61
00:07:08,840 --> 00:07:14,200
Right, right, right, right. Yes, they're absolutely. So, I mean, there are other examples that are

62
00:07:14,200 --> 00:07:18,280
you know, different domains, sequels, and other examples, right? Different domain, but again,

63
00:07:18,840 --> 00:07:23,800
MATLAB may be a bad example since you could probably use it to program one more than anything,

64
00:07:23,800 --> 00:07:28,120
but the question is how efficient would, if you wanted to write an operating system using MATLAB?

65
00:07:31,960 --> 00:07:37,400
A good thing to do. So there's this notion that yeah, it really should fit the problem that you're

66
00:07:37,400 --> 00:07:45,240
trying to solve. But you know, the thing about MATLAB that is a good example of the kind of initial

67
00:07:45,240 --> 00:07:49,240
approach of domains with the languages is that they weren't really focused on performance,

68
00:07:49,240 --> 00:07:55,960
right? They focused on productivity and not performance, right? And it was almost a sense that hey,

69
00:07:55,960 --> 00:08:02,280
you couldn't, you had to give up one to get the other. And so the research approach that we

70
00:08:02,280 --> 00:08:09,400
took was to say, look, there's some real value by using the abstractions provided by the domain

71
00:08:09,400 --> 00:08:14,120
specific languages. They're higher level. They're more declarative. You're saying what you want

72
00:08:14,120 --> 00:08:19,160
rather than, you know, you know, how to get it, right? So that the example would be, you know,

73
00:08:19,160 --> 00:08:24,520
MATLAB says, hey, this is matrix multiply. If you do that and see you write a bunch of loops,

74
00:08:24,520 --> 00:08:28,760
right? I don't know what to do with a bunch of loops, right? But I do know what to do if you tell

75
00:08:28,760 --> 00:08:35,320
me it's matrix multiply. So that raising of the abstraction level was something that could be a

76
00:08:35,320 --> 00:08:40,520
driver for high performance if you knew what, if you had the right sort of compiler technology.

77
00:08:41,320 --> 00:08:44,760
So I don't want to rat hole on the compiler technology that we developed, but it was really

78
00:08:44,760 --> 00:08:51,480
cool and it did all sorts of things, including enable you to take a high level MATLAB like program

79
00:08:51,480 --> 00:08:57,880
and run it without modification on the whole range of computing devices you might see in the data

80
00:08:57,880 --> 00:09:05,480
center. So multi-core GPU cluster or any combination of the like. The running on them isn't usually the

81
00:09:05,480 --> 00:09:09,400
problem. The problem is taking advantage of them. Presumably it's taking, yeah, yeah, it's taking

82
00:09:09,400 --> 00:09:12,920
cool, but yeah, no, no, no, no, no, no, no, no, no, no, yeah, running, yeah, yeah, right, you can

83
00:09:12,920 --> 00:09:18,360
get that one good thread and it would be much good. Yeah, no, yeah, I'm just taking on, you know,

84
00:09:18,360 --> 00:09:23,160
all the apps that are running on my laptop and I just see one of the core, the core is, you know,

85
00:09:23,160 --> 00:09:29,560
no, no, by running. Yes, actually getting good performance, yeah. And hopefully close to what

86
00:09:29,560 --> 00:09:35,240
you would have gotten if you had written in this low-level thing. So, you know, if the low-level

87
00:09:35,240 --> 00:09:40,120
programming languages were CUDA for a GPU, could you take this high level representation and get to

88
00:09:40,120 --> 00:09:44,920
the performance level that you would have gotten had you written the CUDA, right? So that's what we're

89
00:09:44,920 --> 00:09:46,120
that we're talking about, right?

90
00:09:46,120 --> 00:09:46,960
Yeah.

91
00:09:46,960 --> 00:09:48,280
Has book, thank you for clarifying.

92
00:09:48,280 --> 00:09:49,120
Right.

93
00:09:49,120 --> 00:09:50,440
Right.

94
00:09:50,440 --> 00:09:51,440
Right.

95
00:09:51,440 --> 00:09:54,440
And then, but what that got us into

96
00:09:54,440 --> 00:09:57,600
was this whole realm of data analytics.

97
00:09:57,600 --> 00:10:02,000
And so we started looking at how to do SQL and Spark

98
00:10:02,000 --> 00:10:04,120
and machine learning.

99
00:10:04,120 --> 00:10:08,960
And we fact defined a new DSL for the machine learning

100
00:10:08,960 --> 00:10:11,600
well that we called optimal, you know,

101
00:10:11,600 --> 00:10:19,840
this is a play on, but it was spelled O-N-O-P-T-I-M-L, right?

102
00:10:19,840 --> 00:10:22,640
Of course, of course.

103
00:10:22,640 --> 00:10:25,680
And it was, you know, it was 2008 when we kind of defined it.

104
00:10:25,680 --> 00:10:28,040
It was so M-L hadn't really taken off then.

105
00:10:28,040 --> 00:10:31,280
But it was, it was so we like to think

106
00:10:31,280 --> 00:10:33,360
we were ahead of the curve, absolutely.

107
00:10:33,360 --> 00:10:34,040
It sounds like it.

108
00:10:34,040 --> 00:10:35,880
Yeah.

109
00:10:35,880 --> 00:10:39,240
So that was kind of the impetus for kind of our playing

110
00:10:39,240 --> 00:10:41,280
in this whole machine learning space, right?

111
00:10:41,280 --> 00:10:41,780
OK.

112
00:10:41,780 --> 00:10:45,880
There's an ocean that, hey, this, we can define DSLs.

113
00:10:45,880 --> 00:10:51,400
We can do machine learning algorithms.

114
00:10:51,400 --> 00:10:52,520
We can write them easily.

115
00:10:52,520 --> 00:10:58,840
We could run them efficiently on a whole range of architectures.

116
00:10:58,840 --> 00:11:01,720
I should note that the other piece of technology

117
00:11:01,720 --> 00:11:06,160
that we kind of relied on was all these DSLs

118
00:11:06,160 --> 00:11:09,240
were not what are called standalone DSLs.

119
00:11:09,240 --> 00:11:11,640
So an example of a standalone DSL

120
00:11:11,640 --> 00:11:15,240
would be the examples I gave before, map lab,

121
00:11:15,240 --> 00:11:17,680
SQL, they're standalone, right?

122
00:11:17,680 --> 00:11:21,640
An example of an embedded DSL would be something like TensorFlow.

123
00:11:21,640 --> 00:11:26,280
And so all our DSLs were embedded in Scala.

124
00:11:26,280 --> 00:11:32,280
And one thing that I mentioned in the talk and, you know,

125
00:11:32,280 --> 00:11:34,120
part, you know, I'm an academic.

126
00:11:34,120 --> 00:11:37,760
So it's all about sort of putting your stake in the ground

127
00:11:37,760 --> 00:11:42,320
for a few of an idea and then seeing, you know,

128
00:11:42,320 --> 00:11:45,360
what, what, you know, who came after, right?

129
00:11:45,360 --> 00:11:46,960
And did they cite you?

130
00:11:46,960 --> 00:11:54,320
So we did optimize this in 2008 and TensorFlow's later.

131
00:11:54,320 --> 00:11:57,600
But TensorFlow, you know, if you look

132
00:11:57,600 --> 00:12:00,840
at all of these data allocation machine learning,

133
00:12:00,840 --> 00:12:03,160
you'll see that, of course, essentially,

134
00:12:03,160 --> 00:12:05,480
you can describe them at some level of abstraction,

135
00:12:05,480 --> 00:12:07,920
as a set of operators with data flow

136
00:12:07,920 --> 00:12:09,520
ox between them, right?

137
00:12:09,520 --> 00:12:10,760
They all look like that way.

138
00:12:10,760 --> 00:12:14,320
And you define that the operators may look different,

139
00:12:14,320 --> 00:12:16,440
but they fundamentally all look that way.

140
00:12:16,440 --> 00:12:18,960
And so yeah, what we wanted at the end of the day

141
00:12:18,960 --> 00:12:20,840
was a data flow graph.

142
00:12:20,840 --> 00:12:24,160
And the question is how you get it and how you describe it.

143
00:12:24,160 --> 00:12:28,480
TensorFlow takes a very explicit way of describing

144
00:12:28,480 --> 00:12:30,200
your flow graph, right?

145
00:12:30,200 --> 00:12:32,200
But that's not the most natural thing to do.

146
00:12:32,200 --> 00:12:35,600
The most natural thing is just describe your program

147
00:12:35,600 --> 00:12:38,480
and then have the underlying infrastructure extract

148
00:12:38,480 --> 00:12:39,560
that graph.

149
00:12:39,560 --> 00:12:41,080
And so that's what we did, right?

150
00:12:41,080 --> 00:12:43,440
And so one of the slides in the talk, I said, you know,

151
00:12:43,440 --> 00:12:46,280
I say, here's Kving's clustering, right?

152
00:12:46,280 --> 00:12:49,440
Here's the four lines of code it takes in my DSL.

153
00:12:49,440 --> 00:12:52,360
And here's TensorFlow.

154
00:12:52,360 --> 00:12:55,480
It takes 20 because it's one of the four

155
00:12:55,480 --> 00:12:57,720
and optimal.

156
00:12:57,720 --> 00:13:00,000
What are the kinds of trying to get at the level?

157
00:13:00,000 --> 00:13:07,440
So you have a group by group, you know, group the samples

158
00:13:07,440 --> 00:13:09,000
by their distance to the means.

159
00:13:09,000 --> 00:13:09,720
OK.

160
00:13:09,720 --> 00:13:10,240
Great.

161
00:13:10,240 --> 00:13:11,040
You've done it.

162
00:13:11,040 --> 00:13:12,520
All of a sudden you've got clusters.

163
00:13:15,920 --> 00:13:16,920
Nice.

164
00:13:16,920 --> 00:13:22,120
And then the other one is OK, now go find the centroid

165
00:13:22,120 --> 00:13:24,480
of the clusters and you've got your new means.

166
00:13:24,480 --> 00:13:26,920
So I could describe it now.

167
00:13:26,920 --> 00:13:29,200
And anybody who kind of knows the group by operator,

168
00:13:29,200 --> 00:13:32,360
like you do, can drop it instantly, right?

169
00:13:32,360 --> 00:13:35,680
As opposed to constructing some graph.

170
00:13:35,680 --> 00:13:36,480
Right.

171
00:13:36,480 --> 00:13:38,520
So that's the difference in the extract.

172
00:13:38,520 --> 00:13:38,880
Yeah.

173
00:13:38,880 --> 00:13:42,880
And I think that's the idea that I was getting at with these,

174
00:13:42,880 --> 00:13:46,760
like the variations of domain specificity.

175
00:13:46,760 --> 00:13:49,800
Like you're operating at a way higher level of abstraction.

176
00:13:49,800 --> 00:13:50,400
Yeah.

177
00:13:50,400 --> 00:13:57,760
And so this DSL, you said, 2008, has this continued

178
00:13:57,760 --> 00:14:01,600
to be kind of central to some of the things

179
00:14:01,600 --> 00:14:03,200
you've been working on since?

180
00:14:03,200 --> 00:14:04,240
Or yeah.

181
00:14:04,240 --> 00:14:08,280
So I mean, I think it was an early, so let me kind of just

182
00:14:08,280 --> 00:14:12,560
trace the arc of what we did.

183
00:14:12,560 --> 00:14:15,640
And then I'll become clear where it sits.

184
00:14:15,640 --> 00:14:19,360
So yeah, that was kind of OK.

185
00:14:19,360 --> 00:14:24,200
We had these DSL's embedded in Scarlet.

186
00:14:24,200 --> 00:14:28,280
But our thesis was, if you want to develop a new application,

187
00:14:28,280 --> 00:14:30,960
one DSL wasn't going to do the job with the reason

188
00:14:30,960 --> 00:14:33,560
that you just described is they were specific to you know.

189
00:14:33,560 --> 00:14:36,560
So you say, OK, now I want a SQL piece.

190
00:14:36,560 --> 00:14:38,600
That means I need a SQL DSL.

191
00:14:38,600 --> 00:14:39,800
I want a machine learning piece.

192
00:14:39,800 --> 00:14:41,680
That means I need a machine learning DSL.

193
00:14:41,680 --> 00:14:43,920
I want to graph an analog piece.

194
00:14:43,920 --> 00:14:45,880
It means I need a graph DSL.

195
00:14:45,880 --> 00:14:48,560
And maybe I come up with something else, right?

196
00:14:48,560 --> 00:14:50,400
That you might need.

197
00:14:50,400 --> 00:14:52,520
And then you say, well, I've got this application

198
00:14:52,520 --> 00:14:54,800
that is going to use all of them in some way.

199
00:14:54,800 --> 00:14:56,280
We're going to argue whether they're

200
00:14:56,280 --> 00:14:58,200
going to use them sequentially.

201
00:14:58,200 --> 00:15:00,880
And the data's going to pass between whether the things

202
00:15:00,880 --> 00:15:02,360
are going to be more intertwined.

203
00:15:02,360 --> 00:15:06,800
But let's suppose that you have multiple DSL's.

204
00:15:06,800 --> 00:15:10,720
What you'd like to do is to be able to take

205
00:15:10,720 --> 00:15:13,920
a single application, compose the multiple DSL's,

206
00:15:13,920 --> 00:15:16,440
and do global optimization, right?

207
00:15:16,440 --> 00:15:17,320
That was, yeah.

208
00:15:17,320 --> 00:15:18,080
Yeah, OK.

209
00:15:18,080 --> 00:15:20,160
So that's what you want to do.

210
00:15:20,160 --> 00:15:26,080
And so in order to do that, the solution that comes to mind

211
00:15:26,080 --> 00:15:31,920
is to say, OK, why don't we capture the,

212
00:15:31,920 --> 00:15:35,080
since we said they're all up like graphs anyway, right?

213
00:15:35,080 --> 00:15:38,520
Could we figure out some underlying representation

214
00:15:38,520 --> 00:15:40,880
that's graph thankful like that?

215
00:15:40,880 --> 00:15:43,400
All of these DSL's could happen, right?

216
00:15:43,400 --> 00:15:46,480
So then you have dependencies, and you can parallelize.

217
00:15:46,480 --> 00:15:49,080
And then you could confuse across the boundaries

218
00:15:49,080 --> 00:15:53,400
of the DSL and get rid of intermediate data and data

219
00:15:53,400 --> 00:15:56,920
movement, which is the scourge of any high-performance

220
00:15:56,920 --> 00:15:58,400
implementation, right?

221
00:15:58,400 --> 00:16:00,080
And so that was the goal, right?

222
00:16:00,080 --> 00:16:03,120
To say, can we create, that was one of the goals.

223
00:16:03,120 --> 00:16:08,320
The other goal was this notion that, hey,

224
00:16:08,320 --> 00:16:11,200
you come up with a new domain area,

225
00:16:11,200 --> 00:16:14,040
but actually developing a high-performance DSL

226
00:16:14,040 --> 00:16:15,160
is a difficult problem.

227
00:16:15,160 --> 00:16:21,000
So what if we could kind of remove the burden

228
00:16:21,000 --> 00:16:24,520
of the high-performance apart from you

229
00:16:24,520 --> 00:16:26,560
by creating a framework that allows you

230
00:16:26,560 --> 00:16:28,720
to develop new DSL's?

231
00:16:28,720 --> 00:16:32,800
And then leverage all of this high-performance compiler

232
00:16:32,800 --> 00:16:35,720
optimization infrastructure on top of that.

233
00:16:35,720 --> 00:16:36,680
So that was the goal.

234
00:16:36,680 --> 00:16:40,840
And so our view was, so we developed this infrastructure.

235
00:16:40,840 --> 00:16:42,680
We developed the framework.

236
00:16:42,680 --> 00:16:46,400
The DSL optimal was kind of the poster child DSL wasn't

237
00:16:46,400 --> 00:16:48,320
the most work into.

238
00:16:48,320 --> 00:16:51,960
And at the end of the day, we figured the real value was

239
00:16:51,960 --> 00:16:56,600
in the optimization framework, not in the DSL itself.

240
00:16:56,600 --> 00:17:03,920
And so going forward, we said, so Scala has its issue.

241
00:17:03,920 --> 00:17:09,520
I think it has peaked and gone down in terms of popularity.

242
00:17:09,520 --> 00:17:13,560
It has all sorts of issues associated with the complexity

243
00:17:13,560 --> 00:17:15,600
of the language and the number of developers

244
00:17:15,600 --> 00:17:18,040
who are conversant with it.

245
00:17:18,040 --> 00:17:22,120
And so our view was it was too difficult

246
00:17:22,120 --> 00:17:25,560
to push a Scala-based DSL.

247
00:17:25,560 --> 00:17:30,320
But we could imagine pushing a Scala-based compilation

248
00:17:30,320 --> 00:17:36,960
infrastructure if the DSLs that you created came from someone

249
00:17:36,960 --> 00:17:37,960
else.

250
00:17:37,960 --> 00:17:41,280
So you can imagine to kind of fast forward to today

251
00:17:41,280 --> 00:17:43,600
and you want to optimize TensorFlow, right?

252
00:17:43,600 --> 00:17:46,360
So TensorFlow will give you a graph.

253
00:17:46,360 --> 00:17:47,200
You take that graph.

254
00:17:47,200 --> 00:17:49,080
You give it to our framework.

255
00:17:49,080 --> 00:17:51,720
And then we can optimize it.

256
00:17:51,720 --> 00:17:54,000
And is that theoretical idea?

257
00:17:54,000 --> 00:17:55,360
Is that actually what you're doing?

258
00:17:55,360 --> 00:17:59,200
That's actually what we're doing, yeah.

259
00:17:59,200 --> 00:18:03,120
OK, which is a whole huge part of the system

260
00:18:03,120 --> 00:18:04,600
that you don't have to worry about anymore.

261
00:18:04,600 --> 00:18:07,520
You just need to take these graphs and figure out how to do it.

262
00:18:07,520 --> 00:18:11,960
Right, so again, it's all about actually

263
00:18:11,960 --> 00:18:15,680
getting application developers to use any particular language

264
00:18:15,680 --> 00:18:20,880
as its own set of issues associated with it.

265
00:18:20,880 --> 00:18:26,000
And Google's a much bigger entity than we could ever be

266
00:18:26,000 --> 00:18:27,360
in pushing that sort of thing.

267
00:18:27,360 --> 00:18:30,560
So we're going to wind up right on top of that

268
00:18:30,560 --> 00:18:33,440
and provide the added advantage that, hey,

269
00:18:33,440 --> 00:18:35,480
not only can you take TensorFlow, but you

270
00:18:35,480 --> 00:18:39,880
can take PyTorch and you can take SQL and you can take whatever.

271
00:18:39,880 --> 00:18:42,120
And you can change it to this representation.

272
00:18:42,120 --> 00:18:44,120
I should say a little bit about the representation just

273
00:18:44,120 --> 00:18:47,200
because before you do that, a quick question.

274
00:18:47,200 --> 00:18:52,760
So the part of the vision here that was these very targeted

275
00:18:52,760 --> 00:18:57,440
domain-specific languages, TensorFlow doesn't really get you

276
00:18:57,440 --> 00:18:58,200
there.

277
00:18:58,200 --> 00:18:59,840
There are some things in some areas that

278
00:18:59,840 --> 00:19:01,480
might be built on top of TensorFlow that

279
00:19:01,480 --> 00:19:03,000
will kind of get you there.

280
00:19:03,000 --> 00:19:05,120
Or do you think it does?

281
00:19:05,120 --> 00:19:09,280
So I would view TensorFlow as a domain-specific language,

282
00:19:09,280 --> 00:19:14,520
where the domain again is matrix and then

283
00:19:14,520 --> 00:19:18,600
around it, but it's one of the DSLs

284
00:19:18,600 --> 00:19:23,200
that you might want to have a full system.

285
00:19:23,200 --> 00:19:26,920
Have you kind of moved away from the idea

286
00:19:26,920 --> 00:19:31,840
that folks will develop very specific DSLs for specific problem

287
00:19:31,840 --> 00:19:33,840
domains or do you think that that will happen

288
00:19:33,840 --> 00:19:34,840
on top of TensorFlow?

289
00:19:34,840 --> 00:19:36,680
It might happen on top of TensorFlow.

290
00:19:36,680 --> 00:19:41,760
It might be other languages to get developed.

291
00:19:41,760 --> 00:19:46,320
You ask sort of what the arc of the research is.

292
00:19:46,320 --> 00:19:53,520
I mean, when we decided that issue of what kinds of DSLs

293
00:19:53,520 --> 00:19:59,440
people want to develop, that is a very domain-specific

294
00:19:59,440 --> 00:20:00,480
question, right?

295
00:20:00,480 --> 00:20:03,920
And the question wrapped up in what languages people want

296
00:20:03,920 --> 00:20:06,920
to use and what abstractions really make sense.

297
00:20:06,920 --> 00:20:16,920
And we wanted to not have to develop new languages

298
00:20:16,920 --> 00:20:20,640
ourselves and get traction on those languages.

299
00:20:20,640 --> 00:20:22,880
And so rather, we thought, OK, if there

300
00:20:22,880 --> 00:20:27,240
is existing languages, how can we accelerate them?

301
00:20:27,240 --> 00:20:29,360
And how can we provide a platform that

302
00:20:29,360 --> 00:20:32,960
might cut across a bunch of existing languages?

303
00:20:32,960 --> 00:20:34,680
OK.

304
00:20:34,680 --> 00:20:39,200
So then, guessing that this platform serves

305
00:20:39,200 --> 00:20:45,200
as both a center point for your research group at Stanford,

306
00:20:45,200 --> 00:20:48,360
but also ties to what you're doing at Sambanova?

307
00:20:48,360 --> 00:20:51,200
Yeah, to some of the ideas.

308
00:20:51,200 --> 00:20:54,880
Definitely, Sambanova has their own platform, which

309
00:20:54,880 --> 00:20:56,960
is different from other things.

310
00:20:56,960 --> 00:21:00,680
But certainly, some of the core ideas.

311
00:21:00,680 --> 00:21:00,880
OK.

312
00:21:00,880 --> 00:21:04,240
So then we can maybe come back to more

313
00:21:04,240 --> 00:21:05,720
on what Sambanova is doing.

314
00:21:05,720 --> 00:21:11,160
So please continue the thread on the system.

315
00:21:11,160 --> 00:21:13,880
We started talking about the connection

316
00:21:13,880 --> 00:21:16,480
between the software and hardware.

317
00:21:16,480 --> 00:21:20,880
And we kind of left off at optimizing the software.

318
00:21:20,880 --> 00:21:25,040
So let me fast forward to more recently at about ML.

319
00:21:25,040 --> 00:21:26,480
And let's talk about.

320
00:21:26,480 --> 00:21:33,600
So about six years ago, Chris Ray showed up at Stanford.

321
00:21:33,600 --> 00:21:40,040
And he is a database machine learning expert.

322
00:21:40,040 --> 00:21:42,560
And we got chatting.

323
00:21:42,560 --> 00:21:45,960
And we started working together with a bunch of joint students.

324
00:21:45,960 --> 00:21:48,800
And he is a math whiz.

325
00:21:48,800 --> 00:21:55,000
And he knows all about theory, which I don't do.

326
00:21:55,000 --> 00:22:00,280
I was more of a hands-on builder kind of guy.

327
00:22:00,280 --> 00:22:03,280
And we started working together.

328
00:22:03,280 --> 00:22:06,280
And we started thinking about what one could do

329
00:22:06,280 --> 00:22:09,520
with machine learning algorithms to optimize them

330
00:22:09,520 --> 00:22:11,720
for modern hardware.

331
00:22:11,720 --> 00:22:15,680
And he came from Wisconsin.

332
00:22:15,680 --> 00:22:19,680
And one of the things he did was an idea

333
00:22:19,680 --> 00:22:22,240
for training machine learning algorithms

334
00:22:22,240 --> 00:22:28,040
using Tocastic Grand Accent SGD that allows them

335
00:22:28,040 --> 00:22:30,440
to be paralyzed much more efficiently.

336
00:22:30,440 --> 00:22:33,600
But the interesting thing about his innovation

337
00:22:33,600 --> 00:22:38,000
is an innovation that nobody who didn't know anything

338
00:22:38,000 --> 00:22:40,120
about the algorithm would make.

339
00:22:40,120 --> 00:22:43,480
Because they would look to that and said,

340
00:22:43,480 --> 00:22:46,720
if I do this, the algorithm's going to be incorrect.

341
00:22:46,720 --> 00:22:53,120
Not something we want, right?

342
00:22:53,120 --> 00:22:56,960
So I think to tell a little story.

343
00:22:56,960 --> 00:23:02,600
So I teach at course in parallel software at Stanford.

344
00:23:02,600 --> 00:23:06,800
And there's one rule that I tell the students about parallel

345
00:23:06,800 --> 00:23:11,160
programming in a what's called shared memory.

346
00:23:11,160 --> 00:23:13,640
Is this something your listeners would understand?

347
00:23:13,640 --> 00:23:14,240
Some of them.

348
00:23:14,240 --> 00:23:14,840
OK.

349
00:23:14,840 --> 00:23:15,600
All right.

350
00:23:15,600 --> 00:23:16,360
All right.

351
00:23:16,360 --> 00:23:20,200
So programming with shared memory, first rule.

352
00:23:20,200 --> 00:23:23,960
If you touch shared data, you should put synchronization

353
00:23:23,960 --> 00:23:24,520
around.

354
00:23:24,520 --> 00:23:26,800
You should put locks around it, right?

355
00:23:26,800 --> 00:23:28,760
There's a whole set of concurrency issues.

356
00:23:28,760 --> 00:23:29,760
You do, yeah.

357
00:23:29,760 --> 00:23:32,320
But basically locks me.

358
00:23:32,320 --> 00:23:36,520
It's like going to slow mode, right?

359
00:23:36,520 --> 00:23:39,640
Essentially, that means that when you've got a lock,

360
00:23:39,640 --> 00:23:41,920
there's only one problem.

361
00:23:41,920 --> 00:23:44,600
What you'd like is as much parallelism as possible.

362
00:23:44,600 --> 00:23:46,800
Whenever you take a lock on a piece of data,

363
00:23:46,800 --> 00:23:51,200
only one processor can actually be touching the data at the time.

364
00:23:51,200 --> 00:23:52,960
So a multiple processes want to touch it,

365
00:23:52,960 --> 00:23:54,640
the others have to wait, right?

366
00:23:54,640 --> 00:23:58,920
And that means you're slowing things down.

367
00:23:58,920 --> 00:24:02,840
And just a bit of size, if we talk about locking,

368
00:24:02,840 --> 00:24:08,720
what you would like to do is not use too much locking.

369
00:24:08,720 --> 00:24:10,280
Because if you do too much locking,

370
00:24:10,280 --> 00:24:12,880
you'll create too much overhead.

371
00:24:12,880 --> 00:24:14,520
But if you don't do enough locking,

372
00:24:14,520 --> 00:24:16,960
you'll create what are called data races, right?

373
00:24:16,960 --> 00:24:19,600
Where you touch the data without locking.

374
00:24:19,600 --> 00:24:23,200
Well, so the general conventional wisdom

375
00:24:23,200 --> 00:24:26,720
is, if you touch shared data, you should take locks.

376
00:24:26,720 --> 00:24:32,800
But if you actually parallelize SGD by using locking,

377
00:24:32,800 --> 00:24:38,760
you do so little work based on when you take a lock

378
00:24:38,760 --> 00:24:41,640
that your turn, find out the all your time

379
00:24:41,640 --> 00:24:43,120
will be spent locking.

380
00:24:43,120 --> 00:24:44,760
That's all you'll ever do all day long.

381
00:24:44,760 --> 00:24:47,680
And that will just basically mean your program

382
00:24:47,680 --> 00:24:50,480
won't run very fast in power.

383
00:24:50,480 --> 00:24:53,200
So Chris Ray and his student came up

384
00:24:53,200 --> 00:25:00,200
with an idea they called hog wild with an exclamation mark.

385
00:25:00,480 --> 00:25:03,280
And the idea is pretty simple.

386
00:25:03,280 --> 00:25:08,280
It says, throw out the locks, okay?

387
00:25:08,280 --> 00:25:11,040
And you say, that can't be correct.

388
00:25:11,040 --> 00:25:13,160
What you mean, I'm just going to touch the data,

389
00:25:13,160 --> 00:25:15,320
willy nilly, I don't know.

390
00:25:15,320 --> 00:25:16,440
So sequentially, right?

391
00:25:16,440 --> 00:25:20,400
You're going to touch the data one iteration

392
00:25:20,400 --> 00:25:22,240
after the next to your SGD.

393
00:25:22,240 --> 00:25:24,400
Everything looks very reasonable.

394
00:25:24,400 --> 00:25:26,880
Now you've got a bunch of parallel processes

395
00:25:26,880 --> 00:25:32,200
which are updating the model in any fashion whatsoever.

396
00:25:32,200 --> 00:25:34,960
They're getting stale data, right?

397
00:25:34,960 --> 00:25:40,440
There is no sequential order to the updates that you could match.

398
00:25:40,440 --> 00:25:43,920
Maybe there is, but it certainly isn't the case

399
00:25:43,920 --> 00:25:47,120
that I read something in the previous iteration,

400
00:25:47,120 --> 00:25:49,840
and I'm updating it that, this iteration could be,

401
00:25:49,840 --> 00:25:53,200
I read it, and iterations before.

402
00:25:53,200 --> 00:25:55,080
The day is already be updated,

403
00:25:55,080 --> 00:25:59,720
and now I'm going to change the model based on this, right?

404
00:25:59,720 --> 00:26:01,440
So all kinds of mayhem.

405
00:26:01,440 --> 00:26:03,880
In other words, an idea that goes against the fiber

406
00:26:03,880 --> 00:26:06,840
of any distributed computing parallel program.

407
00:26:06,840 --> 00:26:09,560
Exactly, exactly, exactly, you got it.

408
00:26:09,560 --> 00:26:15,480
It's anathema to anybody who knows about programming.

409
00:26:15,480 --> 00:26:16,800
And you're saying, what the hell?

410
00:26:16,800 --> 00:26:18,760
What is this?

411
00:26:18,760 --> 00:26:19,840
But it works.

412
00:26:19,840 --> 00:26:20,840
And why does it work?

413
00:26:20,840 --> 00:26:24,040
You can prove it works as long as you don't delay updates too much,

414
00:26:24,040 --> 00:26:27,280
and it's back to this noise argument that we were having before.

415
00:26:27,280 --> 00:26:30,240
Fundamentally, Stochastic Green descent

416
00:26:30,240 --> 00:26:32,640
is a stochastic algorithm, and it has a bunch of noise

417
00:26:32,640 --> 00:26:38,240
associated with things, but the model's solution bounces around.

418
00:26:38,240 --> 00:26:39,920
So this is just a quick note.

419
00:26:39,920 --> 00:26:42,440
We were having that talk before we started recording,

420
00:26:42,440 --> 00:26:43,920
so you should walk us through that again,

421
00:26:43,920 --> 00:26:45,800
because it comes up, not just here,

422
00:26:45,800 --> 00:26:47,960
but also when we talk about quantization.

423
00:26:47,960 --> 00:26:49,920
Yeah, okay, all right, all right.

424
00:26:49,920 --> 00:26:53,640
So there's no notion about these algorithms.

425
00:26:53,640 --> 00:26:55,800
Stochastic Green is sent in, in particular,

426
00:26:55,800 --> 00:27:00,200
which is the workhorse of machine learning training.

427
00:27:00,200 --> 00:27:04,680
And, you know, the basic idea, as you all know,

428
00:27:04,680 --> 00:27:10,760
is maybe some of you know, is you've got a big data set.

429
00:27:10,760 --> 00:27:12,320
You take one of the elements of data set,

430
00:27:12,320 --> 00:27:15,720
you estimate the gradient and you move in the opposite direction,

431
00:27:15,720 --> 00:27:18,680
and you update the model based on that.

432
00:27:18,680 --> 00:27:22,760
Now, if you have lots of processes,

433
00:27:22,760 --> 00:27:24,440
lots of threads that are doing this,

434
00:27:24,440 --> 00:27:29,840
then what you'd like to do is you'd like to lock each piece

435
00:27:29,840 --> 00:27:31,600
of the model as you update it,

436
00:27:31,600 --> 00:27:34,000
so you make sure that only one processor,

437
00:27:34,000 --> 00:27:38,080
the processes all see a consistent view of the model.

438
00:27:38,080 --> 00:27:41,640
So, as I said, fundamentally, this update product,

439
00:27:41,640 --> 00:27:43,520
sometimes you compute a gradient,

440
00:27:43,520 --> 00:27:45,080
because you're only estimating the gradient,

441
00:27:45,080 --> 00:27:47,520
and the gradient sends you in the wrong direction, right?

442
00:27:47,520 --> 00:27:49,760
So you don't actually get, you know,

443
00:27:49,760 --> 00:27:52,920
if you were doing, if you weren't doing stochastic gradient descent,

444
00:27:52,920 --> 00:27:57,920
then you would always go down until you get got to the optimum,

445
00:27:57,920 --> 00:28:03,840
the optimum, which would be a global optimal function with convex.

446
00:28:03,840 --> 00:28:05,920
But if you're doing stochastic gradient descent,

447
00:28:05,920 --> 00:28:08,560
you can sometimes go uphill and you bounce around.

448
00:28:08,560 --> 00:28:14,120
So there's fundamentally noise associated with stochastic gradient descent,

449
00:28:14,120 --> 00:28:17,440
and you can prove, if you are so inclined,

450
00:28:17,440 --> 00:28:23,920
about how much noise you will see in a convex optimization problem,

451
00:28:23,920 --> 00:28:26,920
not deep learning, deep learning's non-convex.

452
00:28:26,920 --> 00:28:29,720
So the question then is,

453
00:28:29,720 --> 00:28:37,720
if you do anything to perturb the process of getting to the optimum,

454
00:28:37,720 --> 00:28:39,680
you will add noise.

455
00:28:39,680 --> 00:28:42,720
And the question is, how much noise do you add,

456
00:28:42,720 --> 00:28:46,600
and can you bound that noise to be below the inherent noise

457
00:28:46,600 --> 00:28:49,200
associated with stochastic gradient descent?

458
00:28:49,200 --> 00:28:54,720
If you can prove that the noise you add is less than the noise

459
00:28:54,720 --> 00:28:58,720
that is already there, then you'll say you're not affecting the solution.

460
00:28:58,720 --> 00:29:00,720
So that's the nature of the proof,

461
00:29:00,720 --> 00:29:03,320
all about reasoning about noise.

462
00:29:03,320 --> 00:29:05,520
Okay, so with that proof,

463
00:29:05,520 --> 00:29:11,320
you can think about how much noise you add based on how stale the updates are,

464
00:29:11,320 --> 00:29:15,520
and then you can prove that things will converge to the right answer

465
00:29:15,520 --> 00:29:18,720
at roughly the same rate as it would be if you had the locks in.

466
00:29:18,720 --> 00:29:20,720
Even if you go hog-wise.

467
00:29:20,720 --> 00:29:23,720
Even if you go hog-wise.

468
00:29:23,720 --> 00:29:25,720
So interesting.

469
00:29:25,720 --> 00:29:29,720
So that's, and everybody uses it these days.

470
00:29:29,720 --> 00:29:32,720
Google uses it, Microsoft uses it.

471
00:29:32,720 --> 00:29:41,720
Everybody goes hog-wise because doing anything else will slow you down dramatically.

472
00:29:41,720 --> 00:29:43,720
Okay, where were we?

473
00:29:43,720 --> 00:29:45,720
We were getting to hardware, I think.

474
00:29:45,720 --> 00:29:46,720
Oh, getting to hardware.

475
00:29:46,720 --> 00:29:48,720
Okay, that's right.

476
00:29:48,720 --> 00:29:51,720
So again, so we were talking about,

477
00:29:51,720 --> 00:29:57,720
so that was the nature of a bunch of work we did together with Chris Ray,

478
00:29:57,720 --> 00:30:03,720
this notion of, sort of, what can you do with stochastic-grang descent

479
00:30:03,720 --> 00:30:09,720
to improve its behavior on modern hardware?

480
00:30:09,720 --> 00:30:13,720
Okay, so modern hardware likes to be very parallel.

481
00:30:13,720 --> 00:30:20,720
It likes to not have to idea you'd like to not use too much memory.

482
00:30:20,720 --> 00:30:29,720
Modern hardware likes to do things on small data types,

483
00:30:29,720 --> 00:30:35,720
think eight-bit integers, rather than 64-bit floating point, right?

484
00:30:35,720 --> 00:30:41,720
So that is the key thing about modern hardware.

485
00:30:41,720 --> 00:30:49,720
The other thing that was interesting about the work with Chris Ray was

486
00:30:49,720 --> 00:30:58,720
related to the things that I talked about at designing my talk,

487
00:30:58,720 --> 00:31:01,720
designing computer systems for software talk 2.0.

488
00:31:01,720 --> 00:31:06,720
I was just in this notion that there are two big trends in computing today.

489
00:31:06,720 --> 00:31:12,720
One is exemplified by the thousands of people at NURPS, right?

490
00:31:12,720 --> 00:31:16,720
Which is the interest in machine learning and the broad applicability

491
00:31:16,720 --> 00:31:23,720
of the approaches and the dramatic improvements in applications,

492
00:31:23,720 --> 00:31:26,720
especially kind of high-end applications that have to do with doing things

493
00:31:26,720 --> 00:31:28,720
that humans traditionally have been good at.

494
00:31:28,720 --> 00:31:32,720
And that, of course, is causing everybody to get excited.

495
00:31:32,720 --> 00:31:39,720
And one of the things that is true of building complex machine learning models

496
00:31:39,720 --> 00:31:42,720
is that they take lots of computation.

497
00:31:42,720 --> 00:31:46,720
And if you look at why machine learning has been successful,

498
00:31:46,720 --> 00:31:49,720
it's because the computation has been available, right,

499
00:31:49,720 --> 00:31:52,720
to actually train these large networks, right?

500
00:31:52,720 --> 00:31:56,720
So if you, the ideas are all, maybe the data wasn't there,

501
00:31:56,720 --> 00:32:01,720
but even if the data was there, the computing computation certainly wasn't there, right?

502
00:32:01,720 --> 00:32:06,720
So you've got this situation where machine learning

503
00:32:06,720 --> 00:32:12,720
needs lots of computation. At the same time, Moore's Law is basically slowing down, right?

504
00:32:12,720 --> 00:32:20,720
So Moore's Law, as most people know, talks about the doubling of transistors

505
00:32:20,720 --> 00:32:23,720
every 18 to two months to two years.

506
00:32:23,720 --> 00:32:27,720
But what people don't know is that Moore's Law may be slowing down,

507
00:32:27,720 --> 00:32:29,720
but that's not the real problem.

508
00:32:29,720 --> 00:32:39,720
The real problem is this other related law or scaling factor called denod scaling.

509
00:32:39,720 --> 00:32:42,720
So denod scaling basically says,

510
00:32:42,720 --> 00:32:46,720
if I double the number of transistors on a chip,

511
00:32:46,720 --> 00:32:51,720
if I scale things the right way, I can keep the power the same.

512
00:32:51,720 --> 00:32:55,720
So I can double the number of transistors and keep the power the same.

513
00:32:55,720 --> 00:33:00,720
Now, if I take denod scaling away, I double the number of transistors

514
00:33:00,720 --> 00:33:02,720
and my power doubles too.

515
00:33:02,720 --> 00:33:07,720
That's, that was screwed, right?

516
00:33:07,720 --> 00:33:09,720
And that's the position we've been in, right?

517
00:33:09,720 --> 00:33:12,720
Which is why processes haven't been getting faster,

518
00:33:12,720 --> 00:33:16,720
because they're not the ways that you speed up conventional processes

519
00:33:16,720 --> 00:33:18,720
and not power efficient.

520
00:33:18,720 --> 00:33:23,720
And we're already at the limit of our power dissipation, right?

521
00:33:23,720 --> 00:33:27,720
Especially, you know, in almost anything you talk about, right?

522
00:33:27,720 --> 00:33:32,720
Whether it be your desktop or your laptop or your mobile device.

523
00:33:32,720 --> 00:33:38,720
And so we're tapped out in terms of sort of what we can do with general purpose processes,

524
00:33:38,720 --> 00:33:40,720
given that we're power limited.

525
00:33:40,720 --> 00:33:44,720
So the question then becomes, what do you do instead, right?

526
00:33:44,720 --> 00:33:48,720
And I think that is why it's such an interesting time in computer systems,

527
00:33:48,720 --> 00:33:54,720
because we've got this convergence of these two big trends,

528
00:33:54,720 --> 00:33:59,720
this need for insatiable amounts of computation to build machine learning models

529
00:33:59,720 --> 00:34:05,720
at the same time, the conventional ideas for improvement performance are basically stored.

530
00:34:05,720 --> 00:34:13,720
And so this is kind of motivating all kinds of exploration into alternatives

531
00:34:13,720 --> 00:34:18,720
for general purpose processes. GPUs was an early-entrant,

532
00:34:18,720 --> 00:34:23,720
but there are lots of companies investing, or lots of investment going in.

533
00:34:23,720 --> 00:34:31,720
So one of the questions after the talk was, how much investment do I think has gone into new hardware for AI?

534
00:34:31,720 --> 00:34:34,720
And I estimate billions.

535
00:34:34,720 --> 00:34:35,720
I can say that.

536
00:34:35,720 --> 00:34:36,720
Yeah.

537
00:34:36,720 --> 00:34:42,720
I mean, hardware companies typically take in much larger amounts than software

538
00:34:42,720 --> 00:34:45,720
and I can think of it doesn't easily.

539
00:34:45,720 --> 00:34:46,720
Yeah.

540
00:34:46,720 --> 00:34:47,720
Yeah, exactly.

541
00:34:47,720 --> 00:34:48,720
Right.

542
00:34:48,720 --> 00:34:49,720
You know.

543
00:34:49,720 --> 00:34:50,720
So, yeah.

544
00:34:50,720 --> 00:34:52,720
Sabanova was well-funded too.

545
00:34:52,720 --> 00:34:57,720
So I just need to follow that.

546
00:34:57,720 --> 00:35:02,720
You quickly get to building this.

547
00:35:02,720 --> 00:35:08,720
So I'm working with Chris Ray has been all about playing these games,

548
00:35:08,720 --> 00:35:15,720
with efficiency and noise and so on, to get higher.

549
00:35:15,720 --> 00:35:22,720
So when doing SGD, it's all about how many iterations does it take to a certain level of accuracy?

550
00:35:22,720 --> 00:35:26,720
And then what you really care about is not just how many iterations,

551
00:35:26,720 --> 00:35:30,720
but how long does each of those iterations take?

552
00:35:30,720 --> 00:35:37,720
So the definition of the number of iterations is what we call statistical efficiency.

553
00:35:37,720 --> 00:35:43,720
And then the amount of time each iteration takes, we call hardware efficiency.

554
00:35:43,720 --> 00:35:50,720
So no kinds of games about as you play with the noise, you affect statistical efficiency.

555
00:35:50,720 --> 00:35:53,720
But you're also potentially improving hardware efficiency.

556
00:35:53,720 --> 00:35:58,720
If you make hardware efficiency worse and statistical efficiency worse, then of course you screwed up.

557
00:35:58,720 --> 00:36:05,720
But what typically you can do is make hardware efficiency much better without affecting statistical efficiency too much.

558
00:36:05,720 --> 00:36:07,720
So hog wild would be an example, right?

559
00:36:07,720 --> 00:36:13,720
You threw away the locks and iterations got faster.

560
00:36:13,720 --> 00:36:18,720
And now you didn't have to do too many extra and you got to the same accurate result.

561
00:36:18,720 --> 00:36:25,720
It strikes me that there's also economic efficiency in there that is not always perfectly correlated with either of those other two.

562
00:36:25,720 --> 00:36:28,720
What efficiency would that be?

563
00:36:28,720 --> 00:36:32,720
In terms of meaning, the cost of getting the result that you ultimately want.

564
00:36:32,720 --> 00:36:40,720
Right. Right. Right. Right. Right. Right. Right. Right. Right. Yeah. Yeah. Yeah.

565
00:36:40,720 --> 00:36:45,720
So that kind of led you down to, you know, into the hardware and kind of designing.

566
00:36:45,720 --> 00:36:51,720
Yeah. So yeah, instead of always been an hardware guy, but it's always been about.

567
00:36:51,720 --> 00:36:58,720
So I just have set up this problem that, hey, CPUs are kind of not going to improve anymore.

568
00:36:58,720 --> 00:37:03,720
CPUs are better, but they still fundamentally have issues.

569
00:37:03,720 --> 00:37:15,720
You know, the question is, you know, how can you design something that is both very efficient, especially in terms of power efficient.

570
00:37:15,720 --> 00:37:18,720
And also very flexible. Right.

571
00:37:18,720 --> 00:37:22,720
Because the most power efficient thing you could design would be exactly what you want. Right.

572
00:37:22,720 --> 00:37:30,720
So you say, oh, here's my algorithm. I'm going to cost it directly into hardware. And I'm going to go fab a chip based on that.

573
00:37:30,720 --> 00:37:39,720
As long as that algorithm never changes. Now that's the problem. Right. Right. Right.

574
00:37:39,720 --> 00:37:56,720
You know, there's a chart that I showed. So Moore's Law says a number of transistors doubles every every year. And if you look at the machine learning papers on archive, that's exceeding Moore's Law.

575
00:37:56,720 --> 00:38:10,720
So how many of those ideas are any good? Who knows? Right. But this is probably some good ideas in that. How many of those make that way to software let alone hardware.

576
00:38:10,720 --> 00:38:14,720
Exactly. Exactly. Good point.

577
00:38:14,720 --> 00:38:29,720
So what you really do need is a way to get both high efficiency and flexibility at the same time, because hey, you need to be able to come up with new ideas and be able to implement them quickly.

578
00:38:29,720 --> 00:38:36,720
You know, implement them both quickly in terms of performance and quickly in terms of how much time it took you to implement.

579
00:38:36,720 --> 00:38:48,720
You mentioned that the GPUs aren't perfect. And I happened to be overhearing a conversation here at NURPS yesterday the day before.

580
00:38:48,720 --> 00:38:59,720
It was kind of like, well, you know, CPUs didn't work so well for this. But then we have GPUs and they solve all the problems. And it was kind of this always well.

581
00:38:59,720 --> 00:39:10,720
So maybe it's worth talking about what are some of the challenges of GPUs? Well, GPUs, of course, were designed for graphics.

582
00:39:10,720 --> 00:39:22,720
And they still, of course, have some of the baggage associated with graphics, but GPUs, such as, well, they've got extra hardware for doing graphics that you care less about.

583
00:39:22,720 --> 00:39:32,720
So you think about Silicon areas as finite resource that you want to use. And you care about machine learning if I use 20% of it to make graphics go fast.

584
00:39:32,720 --> 00:39:36,720
You say, hey, why are you taking my resources to do things I don't care about, right?

585
00:39:36,720 --> 00:39:58,720
So they still have those specific things, but more fundamentally, they are these architecture is designed to execute matrix multiply very efficiently.

586
00:39:58,720 --> 00:40:20,720
Okay, so it sounds like a good thing. We need to do that. We need to do that. So the question then becomes is matrix multiply what you want ultimately ultimately what you might want is some variant of matrix multiply that isn't quite what GPUs are good at.

587
00:40:20,720 --> 00:40:29,720
You might also want something that does sparse computation, right? They're doing dense matrix multiply very efficiently. Maybe you want something that does sparse.

588
00:40:29,720 --> 00:40:35,720
Maybe you want to be able to fuse lots of operators together to create this very weird function.

589
00:40:35,720 --> 00:40:40,720
And you would like to be able to do that without having to write some custom code of action function.

590
00:40:40,720 --> 00:40:57,720
If I can delve into some of the intricacies, I mean, so when talking about efficiency, you know, it has to do with how much of the silicon area actually goes into doing real look, right?

591
00:40:57,720 --> 00:41:13,720
So how much of the silicon area actually does multiply add? How much of the silicon area provides the memory resources for those those multiply add units? And how much of the silicon area goes into what we call overhead, right?

592
00:41:13,720 --> 00:41:34,720
Managing threads, managing register, register contacts, doing things that are not really required to move the computation forward, but are necessary to support the programming model that came with GPUs, right?

593
00:41:34,720 --> 00:41:49,720
And then, you know, what are some of the things that GPUs are lacking, right? So going back to this model of data analytics is being a set of data flow operators, right?

594
00:41:49,720 --> 00:41:58,720
So ideally, what you'd like to be able to do is cast that data flow graph directly into hardware.

595
00:41:58,720 --> 00:42:16,720
GPUs actually make that difficult because of the way that the memory is organized. So but if you could do that efficiently, then there's all sorts of things that you could do that to make your computation be faster and more importantly to make it be much more efficient, right?

596
00:42:16,720 --> 00:42:31,720
Everybody talks about peterroflops, but that's not the story really. It really is about how optimally you can map any particular application to your hardware and what efficiency do you get?

597
00:42:31,720 --> 00:42:48,720
On a bunch of applications, the efficiencies of which GPUs gets are maybe, you know, less than 10%, right? So that means less than 10% of the time you're actually kind of using the full capabilities of the GPU.

598
00:42:48,720 --> 00:43:03,720
So what that means is I could potentially build a machine that has a quarter of the capability, but if I could use it 90% of the time, I might be better off. I'm not saying I said, well, I will build that with that kind of machine.

599
00:43:03,720 --> 00:43:23,720
So, you know, what you say, what's the matter with GPUs? It's a fairly technical argument, but one that has real ramifications about what performance you get out of the end of the day. So you kind of combine these issues of sort of, you know, overhead for doing things that are not machine learning.

600
00:43:23,720 --> 00:43:39,720
So, overhead for supporting a threading mix, a thread of three graphics, overhead for kind of supporting this programming model associated with CUDA, not very efficient mapping of a bunch of these different networks.

601
00:43:39,720 --> 00:43:44,720
And then you see why there's room for other players to come in.

602
00:43:44,720 --> 00:43:58,720
So I think I pulled you down to depression. It's what I'm glad to talk about, but it's one that requires some level of understanding of what GPUs are.

603
00:43:58,720 --> 00:44:05,720
Presumably, a big part of what you're working on are things that fix all of the above.

604
00:44:05,720 --> 00:44:22,720
Yes, exactly. How do you give them? Yeah. And so it sounds like then one of the maybe interesting bits here is what it means to build a computing architecture that's kind of more natively graph aware.

605
00:44:22,720 --> 00:44:25,720
Yeah, yeah, yeah. Can you talk a little bit about that?

606
00:44:25,720 --> 00:44:37,720
Yeah, yes. So I think some of the things that we found out was that it is about graphs, but it's about hierarchical graphs.

607
00:44:37,720 --> 00:44:48,720
So what you typically see when you kind of look below the colors of these graphs is that what you see is these operators.

608
00:44:48,720 --> 00:44:58,720
And the operators that you're probably familiar with from maybe the distributed execution world is map and reduce, right?

609
00:44:58,720 --> 00:45:07,720
So these are pretty basic operators and depending on what functions you are operating over, they can be made fairly general.

610
00:45:07,720 --> 00:45:25,720
And so we take operators like that, producing a few others and we nest them and that gives you a lot more capability. And then once you have that graph, right, then you can think about how could you optimize that graph so that uses memory very efficiently.

611
00:45:25,720 --> 00:45:37,720
So the communication is string lines so you can pipeline operations very efficiently. And then you think about how can I make that graph work very efficiently in hardware? What do I need to do?

612
00:45:37,720 --> 00:45:46,720
So that's what what it's about. And we at Stanford, we worked on an architecture that we call plasticine.

613
00:45:46,720 --> 00:45:58,720
It's named after a children's modeling clay that is popular in Europe. I grew up in London and so I played with it as a little boy.

614
00:45:58,720 --> 00:46:02,720
We're in Canada now. I'm sure they've got it in Canada.

615
00:46:02,720 --> 00:46:20,720
The closest thing to it in the States is called Play-Doh. Everybody played with Play-Doh. The key difference, and I think it's an important one from the naming point of view, is that if you leave Play-Doh out, it becomes a rock.

616
00:46:20,720 --> 00:46:34,720
Well, it turns out the plasticine's oil base, so it never, and it's like a puddy stuff. It's like a puddy eggs and stuff. It's never hard. But it's not silly. It doesn't maintain your shape.

617
00:46:34,720 --> 00:46:52,720
No, it's about gradations. It's not a new one. It's not a new one. So if you're going to see the movie Wilson and Grovitt, or the Clay Nation sort of thing, gummy. Yeah, gummy is probably plasticine.

618
00:46:52,720 --> 00:47:04,720
Keep it in shape. Take a picture of it. Yeah, exactly. So yeah, so plasticine is before the record. Gumby was before my time, but SNL...

619
00:47:04,720 --> 00:47:06,720
Oh, what a cracker!

620
00:47:06,720 --> 00:47:12,720
It wasn't before mine. I can't say.

621
00:47:12,720 --> 00:47:26,720
So yeah, so plasticine's an architecture that was designed to execute these hierarchical data flow graphs, very efficiently. So it's kind of native execution mode. It's a hierarchical data flow graph.

622
00:47:26,720 --> 00:47:36,720
But there are a whole bunch of things that you want to do to do efficient machine learning execution. You want to do data flow graphs. You want to deal with sposity, right?

623
00:47:36,720 --> 00:47:44,720
It's a quick way to like rattle off what it means to do graphs and hardware. Like are there kind of key principles?

624
00:47:44,720 --> 00:47:58,720
So I mean, I think you can think of execution units as these nodes, right? And the ways of communicating between them so that you can map these graphs directly onto these execution units, right?

625
00:47:58,720 --> 00:48:10,720
And then the way that you think about moving data through these is in terms of a pipeline of data moves through it, right? So if you're only going to do things once, then you'd be wasting your time, right?

626
00:48:10,720 --> 00:48:20,720
But think of it as a multi-part intersecting assembly line, right? That's the way to think about how to set things up.

627
00:48:20,720 --> 00:48:29,720
Really all kind of thinking about the cause being the data and the kind of moves through this assembly line and kind of at the end, the cause is complete, right?

628
00:48:29,720 --> 00:48:42,720
But maybe they're doing, you know, is there some notion of like having if you've got some large graph and you're kind of mapping it to this more static substrate that you're kind of swapping in parts of the graph?

629
00:48:42,720 --> 00:48:53,720
Yeah, yeah. So that's a very good question, right? So, you know, there's some machine that your TensorFlow initially had no way. I mean, you've got a static graph right? You've done.

630
00:48:53,720 --> 00:49:02,720
And from a hardware point of view, you say, array, that's what I want. I can optimize the hell out of it. I map it to my substrate and I'm not going to change it.

631
00:49:02,720 --> 00:49:13,720
But then you come along and say, ah, I don't sometimes I want to do this part of graph. Sometimes I want to do that part of the graph. So you have to have some way of reprogramming things, right?

632
00:49:13,720 --> 00:49:20,720
And so a critical element of any architecture like this is how long does it take you to reprogram it, right?

633
00:49:20,720 --> 00:49:33,720
So that is a consideration, right? Because you're talking about a reprogrammable thing as opposed to a general purpose. Yeah, yeah. So think of it, you know, as like, you know, the assembly line metaphor is pretty good, right?

634
00:49:33,720 --> 00:49:40,720
On the factory floor, you set up the assembly line and you're going to make the set of cars and it's going to be this way for months, right?

635
00:49:40,720 --> 00:49:53,720
So you set it up and then you let it go, right? But if every of you, you know, well, back when I used to be a graduate student at Michigan, people were talking about these flexible manufacturing lines, right?

636
00:49:53,720 --> 00:50:10,720
Because, you know, Michigan's course Michigan, right? So, and so then maybe, maybe you're doing different things where we come, right? So now you have to have some way of adding some flexibility, having some reprogrammability.

637
00:50:10,720 --> 00:50:23,720
And so yes, now it's more flexible. But there's a truism in hardware design and I get goes back to something I said before about the fact that, you know, you could be more efficient if you only had to do one thing.

638
00:50:23,720 --> 00:50:36,720
And anytime you add flexibility, you are losing efficiency, right? And so as always, this game was okay. How much extra flexibility am I going to add and how what's it going to do to my efficiency?

639
00:50:36,720 --> 00:50:46,720
Yeah, at some point you go too far, you say, you know, screw it. And CPUs, of course, are at the extreme of that of that spectrum, right?

640
00:50:46,720 --> 00:50:49,720
Very flexible on the flexibility side with huge amounts of overhead.

641
00:50:49,720 --> 00:50:54,720
And the other side would be, oh, this is the model that I want to bake in the silicon.

642
00:50:54,720 --> 00:51:10,720
And silicon, I can't change it. Yeah, probably efficient, but then. So you get the spectrum. And you're saying, you're saying, you know, what, you know, what's the ingenuity about what I do about what I, what, what, what things I can change and what things are fixed, right?

643
00:51:10,720 --> 00:51:16,720
And so that's the game. And then what, what's my compiler tool chain to target that, right?

644
00:51:16,720 --> 00:51:26,720
Right. Compile tool chains for CPUs are very well established, right? There's, you know, C, L of the M, you know, what have you?

645
00:51:26,720 --> 00:51:38,720
You can, CUDA is pretty, pretty well established too. And some of these other architectures that you could imagine, if you didn't have, you know, A, they have many more degrees of freedom.

646
00:51:38,720 --> 00:51:49,720
So actually coming up with, with the right thing is, is more difficult and B, they're just weird, you know, in fact, we're in a good way in that.

647
00:51:49,720 --> 00:51:56,720
And then one of the things that they don't have is explicit instructions, right?

648
00:51:56,720 --> 00:52:08,720
So I mean, well, it means that, so an instruction would say, like explicit instruction that, you know, shift and move and allow level stuff.

649
00:52:08,720 --> 00:52:21,720
Right. Well, they have them, but they're done spatially, right? So you say, you say, okay, I'm going to, instead of this, this particular clock cycle, I'm going to do an ad.

650
00:52:21,720 --> 00:52:29,720
And I'm going to do a shift and then I've got an executing instruction. Then you say, no, you send it up. You're always going to do a shift at the end of time.

651
00:52:29,720 --> 00:52:33,720
It's more like configuration. That's what you're going to do. And I'm just just what I put in.

652
00:52:33,720 --> 00:52:38,720
Yeah, I'm going to feed you data and you're going to do what you do, right?

653
00:52:38,720 --> 00:52:43,720
And you're not going to change. And then the next step is going to do something else, right?

654
00:52:43,720 --> 00:52:55,720
And so, and so this is how you get these things. So why, how do you make the data flow so that everything gets to the right place so that the things that do their thing, you need a network.

655
00:52:55,720 --> 00:53:05,720
Right. Right. So now you understand how you're building your building up kind of hardware, which has some flexibility, but, but, but, but, but not too much, right?

656
00:53:05,720 --> 00:53:20,720
The key thing is, is where you put the flexibility and how you actually generate code. Okay. Interesting. Interesting. And so, but I should say it's all driven by the relatively static nature of at least the early machine learning.

657
00:53:20,720 --> 00:53:31,720
Right. Right. It's become more flexible, but it's still relatively static compared to say, pick your favorite software in space. Right. Right. Right. Yeah.

658
00:53:31,720 --> 00:53:44,720
And so, how does this tie into what you're doing at some an over? So at seven over, we are doing a bunch of things. We are figuring out how to create a new platform for AI. Right.

659
00:53:44,720 --> 00:53:49,720
And what is platform can mean a lot of things. So, so how low do you go? How high do you go?

660
00:53:49,720 --> 00:54:04,720
Well, let me do low those easy because we're going all the way to silicon. Exactly. Hi. You know, we're going to come up all the way to to the frameworks.

661
00:54:04,720 --> 00:54:12,720
Okay. Yeah. Okay. And be very broad. My understanding is still early. So I can't say what we're actually doing.

662
00:54:12,720 --> 00:54:22,720
But, you know, if I can, I can talk about the founding team and sort of what capable is they bring in that kind of, but we don't need to go into the team.

663
00:54:22,720 --> 00:54:34,720
Yeah. Well, I think it's kind of interesting about this interview is that I'm not sure we ever transition from your like background to, you know, to your, to your talk.

664
00:54:34,720 --> 00:54:45,720
We kind of at all wove together and chronologically in time. We end up it ended up at what you're doing now. Yeah. And so I, I have covered what I, what I talked in my.

665
00:54:45,720 --> 00:54:57,720
I did it. Yeah. We, we, we, we, we, we, we, we, we covered the whole space. And so, and, and maybe I should recap. And then there'll be clear. So the recap is, okay.

666
00:54:57,720 --> 00:55:06,720
I started out by saying, hey, we're in it. We're in this, this era where machine learning is ascended and more is Laura's.

667
00:55:06,720 --> 00:55:20,720
Yeah, it's gone. Right. We need to do things differently. We need new algorithms based around these ideas of, of, of, of trading off this is called efficiency for hardware efficiency.

668
00:55:20,720 --> 00:55:37,720
We need to make specific languages for encoding them. We need optimizing compilers for generating code for a variety of different architectures, including new hardware accelerators, which are defined on top of these data flow operators.

669
00:55:37,720 --> 00:55:57,720
And then plastic seat being an example. So we're gonna go build that. Yeah. Yeah. Yeah. Yeah. Nice. Nice. Also, well, cool. Thank you so much for taking the time to chat with me and we'll thank you for reaching out to speed of pleasure. Fantastic. Yeah.

670
00:55:57,720 --> 00:56:11,720
All right, everyone. That's our show for today. For more information on Kuhnle or any of the topics covering in this episode, visit twimmelai.com slash talk slash 211.

671
00:56:11,720 --> 00:56:29,720
You can also follow along with our NURP series at twimmelai.com slash NURP's 2018. As always, thanks so much for listening and catch you next time.

