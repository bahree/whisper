1
00:00:00,000 --> 00:00:16,680
Hello and welcome to another episode of Tumultalk, the podcast where I interview interesting

2
00:00:16,680 --> 00:00:21,520
people doing interesting things in machine learning and artificial intelligence.

3
00:00:21,520 --> 00:00:24,000
I'm your host, Sam Charrington.

4
00:00:24,000 --> 00:00:28,720
I apologize in advance for a longer than usual intro, but we've got a bunch of news and

5
00:00:28,720 --> 00:00:31,420
announcements that we wanted to share this week.

6
00:00:31,420 --> 00:00:35,920
Thanks to everyone that listened to, shared, and commented on last week's show.

7
00:00:35,920 --> 00:00:39,960
Based on your feedback so far, it's pretty clear you're enjoying both the Industrial

8
00:00:39,960 --> 00:00:44,440
AI series as well as our more technical Nerd Alert shows.

9
00:00:44,440 --> 00:00:48,200
I am too, so you'll definitely see more of both.

10
00:00:48,200 --> 00:00:52,600
This week though, we're starting a two week break from the Industrial AI series.

11
00:00:52,600 --> 00:00:57,040
I've got a great show for you today and then next week the week of July 3rd will

12
00:00:57,040 --> 00:01:02,600
be foregoing our usual Friday release and experimenting with a shift to a Monday release

13
00:01:02,600 --> 00:01:05,640
schedule for at least the rest of the summer.

14
00:01:05,640 --> 00:01:09,800
When this podcast drops, I'll be in New York City for the O'Reilly AI conference where

15
00:01:09,800 --> 00:01:14,720
I'll be interviewing speakers like Douglas Eck from Google Brain, Rana Alcaloubi from

16
00:01:14,720 --> 00:01:21,080
Effectiva, Ben Vigota from Gamalon, and Naveen Rao of Intel Nirvana.

17
00:01:21,080 --> 00:01:27,000
Our O'Reilly AI series will be posted on Monday July 10th for your binge listening pleasure.

18
00:01:27,000 --> 00:01:32,040
The following week I'm in Germany, in Hamburg, Berlin, and possibly Munich.

19
00:01:32,040 --> 00:01:35,880
If you're in or near one of those cities and you'd like to connect, definitely give me

20
00:01:35,880 --> 00:01:37,360
a shout out.

21
00:01:37,360 --> 00:01:42,080
As we've mentioned over the past few weeks, we've been planning and now have finalized

22
00:01:42,080 --> 00:01:44,760
our very first Twimmel Happy Hour.

23
00:01:44,760 --> 00:01:48,720
We've partnered with our friends from the NYAI meetup group and we'd love for you to

24
00:01:48,720 --> 00:01:54,280
meet us at Amesworth Midtown and New York City on Thursday, June 29th, starting at 6pm

25
00:01:54,280 --> 00:01:59,920
right after the O'Reilly conference for a few hours of drinks, conversations, and networking.

26
00:01:59,920 --> 00:02:03,800
I'm looking forward to being back in my hometown and sharing a drink with those of you who

27
00:02:03,800 --> 00:02:05,160
can make it.

28
00:02:05,160 --> 00:02:11,560
Make sure to RSVP at twimmelai.com slash NY meetup to let us know you're coming.

29
00:02:11,560 --> 00:02:13,400
And now about today's show.

30
00:02:13,400 --> 00:02:18,600
Our guest this week is Zornizza Kozarva, Manager of Machine Learning with Amazon Web

31
00:02:18,600 --> 00:02:23,120
Services Deep Learning, where she leads a group focused on natural language processing

32
00:02:23,120 --> 00:02:28,680
and dialogue systems for products like Alexa and Lex, the latter of which we discussed

33
00:02:28,680 --> 00:02:30,360
in the podcast.

34
00:02:30,360 --> 00:02:34,160
We spend most of our time talking through the architecture of modern natural language

35
00:02:34,160 --> 00:02:38,800
understanding systems, including the role of deep learning, and some of the various ways

36
00:02:38,800 --> 00:02:43,720
folks are working to overcome the challenges in the field, such as understanding human

37
00:02:43,720 --> 00:02:45,120
intent.

38
00:02:45,120 --> 00:02:49,600
If you're interested in this field, she mentions the AWS chatbot challenge, which you've

39
00:02:49,600 --> 00:02:55,080
still got a couple more weeks to participate in, of course, a link will be in the show notes,

40
00:02:55,080 --> 00:02:59,560
which will be posted at twimmelai.com slash talk slash 30.

41
00:02:59,560 --> 00:03:03,600
I had a ton of fun chatting with Zornizza and learned a bunch, and we couldn't wait

42
00:03:03,600 --> 00:03:05,800
to share this conversation with you.

43
00:03:05,800 --> 00:03:06,800
Enjoy.

44
00:03:06,800 --> 00:03:19,520
All right, everyone, I am on the line with Zornizza Kozarva, Zornizza is a manager with

45
00:03:19,520 --> 00:03:25,440
AWS deep learning, and we are going to be talking about deep learning and natural language

46
00:03:25,440 --> 00:03:26,440
understanding.

47
00:03:26,440 --> 00:03:29,240
And I'm super excited to have her on the line.

48
00:03:29,240 --> 00:03:30,240
How are you Zornizza?

49
00:03:30,240 --> 00:03:35,800
Likewise, thank you Sam, it's a great pleasure to be here and to be part of the show.

50
00:03:35,800 --> 00:03:38,040
I'm doing really well.

51
00:03:38,040 --> 00:03:39,040
Awesome, awesome.

52
00:03:39,040 --> 00:03:42,440
Well, why don't we get started by having you tell us a little bit about your background

53
00:03:42,440 --> 00:03:45,680
and how you got to where you are?

54
00:03:45,680 --> 00:03:52,680
Yes, so currently I'm a manager of the AWS deep learning group at Amazon that focuses

55
00:03:52,680 --> 00:03:56,360
on natural language processing and dialogue systems.

56
00:03:56,360 --> 00:04:02,000
My background and PhDs are in the field of natural language processing, which focuses

57
00:04:02,000 --> 00:04:06,320
on doing systems that understand what humans mean.

58
00:04:06,320 --> 00:04:11,360
For a couple of years, I wore an academic hat at the University of South and California.

59
00:04:11,360 --> 00:04:15,640
I was an assistant professor there for the computer science department, and I focused

60
00:04:15,640 --> 00:04:20,120
on different types of research funded by DARPA and IRPA.

61
00:04:20,120 --> 00:04:25,160
And after that, I moved to industry where I decided to tackle the same challenges, but

62
00:04:25,160 --> 00:04:30,800
at a much larger scale and with a bigger impact to humans and society.

63
00:04:30,800 --> 00:04:37,360
Hmm, do you currently do research or are you primarily focused on product oriented work?

64
00:04:37,360 --> 00:04:42,760
I'm focused on both, like we do a lot of product development inside the Amazon, but

65
00:04:42,760 --> 00:04:48,040
at the same time, I'm making sure that I continue participating and serving the scientific

66
00:04:48,040 --> 00:04:49,040
community.

67
00:04:49,040 --> 00:04:54,400
We do have scientific work as well as I regularly serve on the program committees and

68
00:04:54,400 --> 00:04:55,400
I'm an area chair.

69
00:04:55,400 --> 00:05:00,840
So I'm trying to do both, but at work, definitely the focus is on building products.

70
00:05:00,840 --> 00:05:01,840
Got it.

71
00:05:01,840 --> 00:05:02,840
Got it.

72
00:05:02,840 --> 00:05:06,640
You're currently working on the deep learning and natural language understanding systems

73
00:05:06,640 --> 00:05:10,840
that power Amazon Alexa and Amazon Lex.

74
00:05:10,840 --> 00:05:13,440
I'm pretty sure everyone knows what Amazon Alexa is.

75
00:05:13,440 --> 00:05:18,200
We've talked about it a bunch of times here on the show, and in fact, I demonstrated a

76
00:05:18,200 --> 00:05:21,480
few times how to access the show on Alexa.

77
00:05:21,480 --> 00:05:26,240
So folks are familiar with that, but I'm not sure everyone knows what Amazon Lex is.

78
00:05:26,240 --> 00:05:29,800
So can you maybe give us a high level overview of that service?

79
00:05:29,800 --> 00:05:32,480
It was just announced last year at ReInvent, right?

80
00:05:32,480 --> 00:05:34,120
That is absolutely right.

81
00:05:34,120 --> 00:05:38,800
Well, let me walk you through like how we ended up with Amazon Lex.

82
00:05:38,800 --> 00:05:44,280
So if you think about it, we live in the artificial intelligence era, and we see the development

83
00:05:44,280 --> 00:05:48,320
of very smart systems from self-driving cars to Internet of things.

84
00:05:48,320 --> 00:05:53,360
But at the core, since this conversation was system, that enabled the communications

85
00:05:53,360 --> 00:05:55,920
between machines and humans.

86
00:05:55,920 --> 00:06:00,840
And it has been a dream for developers and for sciences in general to be able to build

87
00:06:00,840 --> 00:06:02,320
such assistance.

88
00:06:02,320 --> 00:06:07,480
But if you take any developer and they have to build such kind of a system, it requires

89
00:06:07,480 --> 00:06:12,440
them to know a lot about natural language understanding and speech recognition, which

90
00:06:12,440 --> 00:06:13,440
are very tough.

91
00:06:13,440 --> 00:06:17,400
And you either should have like a PhD or should have spent significant amount in these

92
00:06:17,400 --> 00:06:18,400
areas.

93
00:06:18,400 --> 00:06:23,360
Developer had to worry about how do I build systems that are really scalable, how do I

94
00:06:23,360 --> 00:06:29,480
enable testing and make sure that my bots are going to be working what the users need,

95
00:06:29,480 --> 00:06:34,400
how to do authentication, how to integrate the business logic, and all of these challenges

96
00:06:34,400 --> 00:06:40,880
were kind of blocking the development at a faster space of all these applications.

97
00:06:40,880 --> 00:06:47,040
So we introduce Amazon Lex, which is a new service for building conversation interfaces

98
00:06:47,040 --> 00:06:50,680
for your apps using voice and text.

99
00:06:50,680 --> 00:06:53,600
And there are multiple benefits to that.

100
00:06:53,600 --> 00:06:56,400
One is like Amazon Lex is very easy to use.

101
00:06:56,400 --> 00:06:58,200
It's built for developers.

102
00:06:58,200 --> 00:07:02,600
And we at Amazon do all the heavy lifting in terms of the infrastructure we take care

103
00:07:02,600 --> 00:07:03,840
of the models.

104
00:07:03,840 --> 00:07:08,680
And the developer just has to focus on what is their customer use case and how they want

105
00:07:08,680 --> 00:07:10,560
these applications to look.

106
00:07:10,560 --> 00:07:15,600
The best part is like we have very high quality text and speech language understanding.

107
00:07:15,600 --> 00:07:20,160
And they are powered by the same deep learning technology as Alexa.

108
00:07:20,160 --> 00:07:24,360
So that's why we have the short legs, it's short for Alexa.

109
00:07:24,360 --> 00:07:30,040
The good part is also that any developer can seamlessly deploy and scale.

110
00:07:30,040 --> 00:07:35,560
If you build your application, for example, for specific platform, like let's say, Facebook

111
00:07:35,560 --> 00:07:40,240
Messenger, you can very easily port it to many other platforms and you don't have to worry

112
00:07:40,240 --> 00:07:41,480
about that.

113
00:07:41,480 --> 00:07:46,000
And at the same time, we have like AWS mobile hub integration that allows you to do many

114
00:07:46,000 --> 00:07:51,680
things like simple, nice data, analyze user behavior, track retention, integrate your

115
00:07:51,680 --> 00:07:53,840
bot and so many, many things.

116
00:07:53,840 --> 00:08:00,000
So this new service Amazon Lex allows people to focus on what matters to them and literally

117
00:08:00,000 --> 00:08:06,160
like so of a particular user need, whether it's booking a hotel or it's opening a bank

118
00:08:06,160 --> 00:08:07,160
account.

119
00:08:07,160 --> 00:08:11,800
And the most exciting part is like we're organizing a challenge right now.

120
00:08:11,800 --> 00:08:14,640
We started in April and it will end in July.

121
00:08:14,640 --> 00:08:18,800
So those folks that are really passionate and want to build their bots, I encourage them

122
00:08:18,800 --> 00:08:22,920
to have a look at our web page and just register for the challenge.

123
00:08:22,920 --> 00:08:29,320
Oh, is that some kind of is it like a prize for the best Amazon Lex app or something?

124
00:08:29,320 --> 00:08:33,720
Yeah, there are different rewards, there's the monetary rewards, there's the AWS credits

125
00:08:33,720 --> 00:08:38,000
and also folks can come to reinvent 2017, there will be ticket.

126
00:08:38,000 --> 00:08:44,120
And as I say, the focus is like build a chatbot that engages users and at the same time fulfills

127
00:08:44,120 --> 00:08:49,280
a specific need that you have like booking a hotel or any other thing that you might

128
00:08:49,280 --> 00:08:50,280
have in mind.

129
00:08:50,280 --> 00:08:51,280
Okay.

130
00:08:51,280 --> 00:08:52,280
Nice.

131
00:08:52,280 --> 00:08:57,520
So with that in mind, let's maybe talk about what are some of the biggest challenges

132
00:08:57,520 --> 00:09:01,600
in working on systems like this, like what are you currently researching?

133
00:09:01,600 --> 00:09:08,080
Well, my focus is in natural language processing and the most hard part is to build systems

134
00:09:08,080 --> 00:09:11,840
that actually understand what the humans mean.

135
00:09:11,840 --> 00:09:18,160
This involves like can we understand what intense people have in mind, can we identify the

136
00:09:18,160 --> 00:09:22,680
slots that enable us and understand how these intense should be fulfilled.

137
00:09:22,680 --> 00:09:26,320
And for most people that haven't worked in this area, it sounds like oh, that's pretty

138
00:09:26,320 --> 00:09:32,080
straightforward, but actually language is very ambiguous and very, very hard to understand.

139
00:09:32,080 --> 00:09:37,480
If we deal with very explicit intents, let's say cancel travel to Miami, I just literally

140
00:09:37,480 --> 00:09:44,360
said every single thing that I'm planning to do, cancel with my intent and Miami is my destination.

141
00:09:44,360 --> 00:09:48,200
But imagine I'm chatting with someone and they're asking me, are you coming to the board

142
00:09:48,200 --> 00:09:49,200
a party?

143
00:09:49,200 --> 00:09:51,960
And I suddenly say, I'm on my way.

144
00:09:51,960 --> 00:09:56,480
If the conversational system pops in and says, hey, Zornica, should I send an Uber your

145
00:09:56,480 --> 00:09:57,480
way?

146
00:09:57,480 --> 00:09:58,480
That's amazing.

147
00:09:58,480 --> 00:10:00,880
So, building such applications is really hard.

148
00:10:00,880 --> 00:10:07,040
It requires a system to understand implicit intents, which are very hard to detect.

149
00:10:07,040 --> 00:10:11,200
It requires the system to know what your user preferences are.

150
00:10:11,200 --> 00:10:14,320
Maybe I'm using specific means of transportation.

151
00:10:14,320 --> 00:10:16,440
The system has learned it over time.

152
00:10:16,440 --> 00:10:19,440
And it's making automatically the recommendation.

153
00:10:19,440 --> 00:10:25,240
And the ability to generate such kind of replies automatically instead of using templates

154
00:10:25,240 --> 00:10:30,080
that are already pre-specified, these are all very, very complex problems that are open

155
00:10:30,080 --> 00:10:31,080
ended.

156
00:10:31,080 --> 00:10:35,880
And we are continuing to invest both in terms of sciences as well as in industry.

157
00:10:35,880 --> 00:10:40,880
How do you solve and make systems being able to handle all this complexity?

158
00:10:40,880 --> 00:10:41,880
Hmm.

159
00:10:41,880 --> 00:10:49,360
So maybe what's a specific area that you've been focusing on there in terms of your research?

160
00:10:49,360 --> 00:10:54,920
My research focuses on building this natural language understanding capability.

161
00:10:54,920 --> 00:11:00,680
Anyone, anytime an utterance that comes in, we focus on extracting those slots to fill

162
00:11:00,680 --> 00:11:06,240
in that template as well as understanding what these intents are, such that when you pass

163
00:11:06,240 --> 00:11:12,240
that information to a dialogue manager or a component that communicates with the backends,

164
00:11:12,240 --> 00:11:18,680
we understand like what the human meant and the more correctly you extract such information

165
00:11:18,680 --> 00:11:24,280
and the most accurately you populate it in these specific templates, then the better your

166
00:11:24,280 --> 00:11:25,600
system will be.

167
00:11:25,600 --> 00:11:30,040
And humans don't have to repeat the same question over and over again.

168
00:11:30,040 --> 00:11:31,600
You mentioned a dialogue manager.

169
00:11:31,600 --> 00:11:38,200
Did these systems have standard components, independent of the implementation to all of

170
00:11:38,200 --> 00:11:43,120
these systems have dialogue managers and what is the general architecture of these types

171
00:11:43,120 --> 00:11:44,120
of systems?

172
00:11:44,120 --> 00:11:46,520
Yeah, that's an excellent question.

173
00:11:46,520 --> 00:11:50,840
While a conversational assistant can live in different shapes and forms like either on

174
00:11:50,840 --> 00:11:56,920
your phone or in your home device, even in your car, the common part is like they have

175
00:11:56,920 --> 00:12:03,320
very standard, like processing blocks, input is like either speech or text.

176
00:12:03,320 --> 00:12:08,360
And the first component that gets hit is the so-called natural language understanding component.

177
00:12:08,360 --> 00:12:13,960
That is the piece that focuses on understanding the intents and the slots of the users.

178
00:12:13,960 --> 00:12:19,200
Once that information is extracted, it gets passed to the dialogue manager.

179
00:12:19,200 --> 00:12:24,520
The task is to take these pieces of information, send them to the backends and a backend

180
00:12:24,520 --> 00:12:25,520
think about it.

181
00:12:25,520 --> 00:12:28,080
If you want to book, let's say, a flight.

182
00:12:28,080 --> 00:12:30,800
Maybe I just say book me a flight to Miami.

183
00:12:30,800 --> 00:12:34,960
Once extracted the Miami term and you pass it to the dialogue manager, it communicates

184
00:12:34,960 --> 00:12:37,440
to the backend, let's say your favorite travel website.

185
00:12:37,440 --> 00:12:41,720
And it says, well, now I need to know what date you will be traveling, do you have any

186
00:12:41,720 --> 00:12:45,920
price restrictions, do you want it to be like a direct flight or not?

187
00:12:45,920 --> 00:12:50,160
It sends back all this information to the dialogue manager says, hey, I need to have all

188
00:12:50,160 --> 00:12:52,040
this information filled.

189
00:12:52,040 --> 00:12:56,640
The dialogue manager passes the slots and then they hit a natural language generation

190
00:12:56,640 --> 00:13:01,800
component that says back to the user, hey, can you tell me like, do you want a direct flight

191
00:13:01,800 --> 00:13:04,720
and do you have any price constraints?

192
00:13:04,720 --> 00:13:08,000
That output could be both text or it could be speech.

193
00:13:08,000 --> 00:13:11,600
It gets sends back to the user and then the user says, well, actually, I don't have

194
00:13:11,600 --> 00:13:12,600
any constraints.

195
00:13:12,600 --> 00:13:15,080
Find me, let's say, the cheapest flight.

196
00:13:15,080 --> 00:13:19,560
So this loop, constant loop between these three components, natural language understanding,

197
00:13:19,560 --> 00:13:24,120
dialogue manager, natural language generation is what drives the whole conversation between

198
00:13:24,120 --> 00:13:26,120
a system and a human.

199
00:13:26,120 --> 00:13:30,800
How you implement them, it depends on you as a policy developer.

200
00:13:30,800 --> 00:13:33,760
How you decide what models to include.

201
00:13:33,760 --> 00:13:37,920
But on the high level, these are kind of like the three building blocks that act like

202
00:13:37,920 --> 00:13:40,600
everyone has to focus us on building.

203
00:13:40,600 --> 00:13:41,600
Okay.

204
00:13:41,600 --> 00:13:42,600
Okay.

205
00:13:42,600 --> 00:13:49,000
And then even within the NLU component there, we can even break that down further.

206
00:13:49,000 --> 00:13:57,000
I know or I recall that the Google a while ago, I guess, around a year ago announced like

207
00:13:57,000 --> 00:14:00,840
an open source parser, their parsing MacPars face rule.

208
00:14:00,840 --> 00:14:05,720
And that's just one of the different pieces of the NLU component itself.

209
00:14:05,720 --> 00:14:08,080
Like what does that part look like?

210
00:14:08,080 --> 00:14:13,520
Well, think about it that the natural language understanding components there, as I said,

211
00:14:13,520 --> 00:14:16,040
they're different and depends what your need is.

212
00:14:16,040 --> 00:14:17,040
Okay.

213
00:14:17,040 --> 00:14:21,200
And the tools that you quoted, they're kind of like a high level dependency parser or

214
00:14:21,200 --> 00:14:22,440
just a parser.

215
00:14:22,440 --> 00:14:27,640
You can use that information to facilitate how to build this kind of natural language understanding

216
00:14:27,640 --> 00:14:28,960
components.

217
00:14:28,960 --> 00:14:34,520
But at the core, it's like you have to think about how to define your slots or how do

218
00:14:34,520 --> 00:14:39,040
you define your semantics, how do you define the space over which your system will operate

219
00:14:39,040 --> 00:14:42,280
and would semantically understand what a human means.

220
00:14:42,280 --> 00:14:47,520
And these things typically are called slots, they're the entities and semantic bits of information.

221
00:14:47,520 --> 00:14:50,400
That capture what our request is.

222
00:14:50,400 --> 00:14:52,160
You can build them from scratch.

223
00:14:52,160 --> 00:14:56,560
You just need to know like what are the right machine learning models for that.

224
00:14:56,560 --> 00:15:01,800
Or if you want, as I say in Amazon Lex, we have like pre-built capabilities such that

225
00:15:01,800 --> 00:15:04,880
people can just choose from a drop-down menu.

226
00:15:04,880 --> 00:15:09,920
So that enables like a person who knows nothing about machine learning to be able to build

227
00:15:09,920 --> 00:15:10,920
them.

228
00:15:10,920 --> 00:15:16,120
For anyone that is from natural language crossing field and has dealt and worked in semantics

229
00:15:16,120 --> 00:15:21,920
and information extraction, it is much easier for people with such kind of skill set to

230
00:15:21,920 --> 00:15:26,800
be able to build their component from scratch and to know how to define these semantics

231
00:15:26,800 --> 00:15:33,920
or how to define the space that the machine learning system should operate over and make predictions.

232
00:15:33,920 --> 00:15:36,520
And how do you characterize that space?

233
00:15:36,520 --> 00:15:41,760
You know, you're starting with typically some audio waveform, like what's the process

234
00:15:41,760 --> 00:15:48,480
for getting that into some parsed set of slots that you can then operate on further

235
00:15:48,480 --> 00:15:50,000
back in the system.

236
00:15:50,000 --> 00:15:51,000
Uh-huh, yeah.

237
00:15:51,000 --> 00:15:56,720
Once you have the speech, as I said, the input could be both speech that you transfer from

238
00:15:56,720 --> 00:15:59,840
speech to text or it could be the text itself.

239
00:15:59,840 --> 00:16:02,000
Think about it like a text messaging.

240
00:16:02,000 --> 00:16:07,000
Once you have that text in, what you do is like you have to make the design of what the

241
00:16:07,000 --> 00:16:08,680
intents and the slots are.

242
00:16:08,680 --> 00:16:12,840
And I know sometimes people come and ask me, well, where do these intents and slots come

243
00:16:12,840 --> 00:16:13,840
from?

244
00:16:13,840 --> 00:16:16,280
And the answer is they're the designer's choice.

245
00:16:16,280 --> 00:16:20,280
You can take them from an existing large ontology, just pick the pieces that you care

246
00:16:20,280 --> 00:16:21,280
about.

247
00:16:21,280 --> 00:16:24,720
Let's say in travel, you might care about cities and countries and so on.

248
00:16:24,720 --> 00:16:29,560
You can automatically learn them from a lot of unlabeled text or you can even manually

249
00:16:29,560 --> 00:16:30,560
create them.

250
00:16:30,560 --> 00:16:33,600
So how do these slots look like?

251
00:16:33,600 --> 00:16:35,720
Let's say we're building a shopping bot.

252
00:16:35,720 --> 00:16:40,640
Then we can decide that our slots are the things that are most important, products and vendors

253
00:16:40,640 --> 00:16:44,000
and brands and models and product families.

254
00:16:44,000 --> 00:16:48,960
And the intents or which are the actions on top of which we can do operations are buying

255
00:16:48,960 --> 00:16:52,600
them, selling them, recommending them, tracking them.

256
00:16:52,600 --> 00:16:57,840
What we do is like we formulate this type of problems as a sequence prediction.

257
00:16:57,840 --> 00:17:02,240
Like if I give you these categories, the products and the brands and I give you some text of

258
00:17:02,240 --> 00:17:09,040
length M, like can you find segments inside the text that can be labeled with these specific

259
00:17:09,040 --> 00:17:10,520
categories?

260
00:17:10,520 --> 00:17:15,880
And the moment you do that and you're having this rich representation that you're caring

261
00:17:15,880 --> 00:17:20,840
about and that your dialogue system can ingest and actually build on top of.

262
00:17:20,840 --> 00:17:26,000
So you have to annotate your data in the correct way, meaning if I say purchase added

263
00:17:26,000 --> 00:17:33,840
as rules, quick to and Nike Pegasus, each word or how's it segments of words, they get

264
00:17:33,840 --> 00:17:36,520
tacked with this specific information.

265
00:17:36,520 --> 00:17:41,160
And then the machines just ingest it such that they can build prediction models on top

266
00:17:41,160 --> 00:17:42,240
of that.

267
00:17:42,240 --> 00:17:45,000
And that's one way you can do it.

268
00:17:45,000 --> 00:17:46,000
Yeah.

269
00:17:46,000 --> 00:17:47,000
Okay.

270
00:17:47,000 --> 00:17:54,880
So one thing I'm inferring from your description is that you consider or it's generally

271
00:17:54,880 --> 00:18:03,440
considered that the speech recognition component of, you know, a broader system like Lex and

272
00:18:03,440 --> 00:18:08,840
the NLU component of a broader system like, you know, system are like two different things.

273
00:18:08,840 --> 00:18:10,640
Is that the way you tend to think of it?

274
00:18:10,640 --> 00:18:18,200
Like this, you're getting speech that's already, you know, turned from audio signals to some

275
00:18:18,200 --> 00:18:21,240
set of symbols, whether that's, you know, language or something else.

276
00:18:21,240 --> 00:18:24,040
And then that's what you're working to understand.

277
00:18:24,040 --> 00:18:25,040
Is that right?

278
00:18:25,040 --> 00:18:26,040
That is correct.

279
00:18:26,040 --> 00:18:27,040
Yes.

280
00:18:27,040 --> 00:18:31,120
You think of them like different building blocks that you need to piece together in the

281
00:18:31,120 --> 00:18:35,840
right way, such that you can do the complex system that is going to be able to drive

282
00:18:35,840 --> 00:18:36,840
this dialogue.

283
00:18:36,840 --> 00:18:41,720
So in my case, I just focus on the natural language processing component.

284
00:18:41,720 --> 00:18:44,080
And we have amazing colleagues that do the same thing.

285
00:18:44,080 --> 00:18:50,520
They focus on speech or they focus on generating from speech to text, yes.

286
00:18:50,520 --> 00:18:56,880
So when you were talking about the intense and the slots and looking at that problem as

287
00:18:56,880 --> 00:19:03,880
predicting a sequence that makes me think of deep learning models like LSTMs, do those

288
00:19:03,880 --> 00:19:10,240
would come into play there, talk about the impact of deep learning on all this.

289
00:19:10,240 --> 00:19:11,240
Yes.

290
00:19:11,240 --> 00:19:12,240
Absolutely.

291
00:19:12,240 --> 00:19:18,240
You have very good intuition and LSTMs are very useful in solving such type of a problem.

292
00:19:18,240 --> 00:19:20,840
It's a structure prediction problem.

293
00:19:20,840 --> 00:19:26,800
And as I say, until recently, people used to employ a lot of the traditional supervised

294
00:19:26,800 --> 00:19:27,800
learning.

295
00:19:27,800 --> 00:19:33,920
They picked their favorite algorithm being a CRF dagger or being like learning to search

296
00:19:33,920 --> 00:19:34,920
algorithm.

297
00:19:34,920 --> 00:19:40,640
And most of the focus was on how to do feature engineering and find what are the right

298
00:19:40,640 --> 00:19:44,280
features and how do we iterate over those features.

299
00:19:44,280 --> 00:19:51,040
But now with the big wave of deep learning, we see that one can build such kind of systems.

300
00:19:51,040 --> 00:19:55,120
If you're an expert in the field, one can do them much faster in terms of like picking

301
00:19:55,120 --> 00:20:00,760
the right algorithm, you can train your word embeddings on a much larger, unlabeled data

302
00:20:00,760 --> 00:20:05,040
and also get much more powerful results.

303
00:20:05,040 --> 00:20:09,360
So LSTM is great for solving this kind of structure prediction problem.

304
00:20:09,360 --> 00:20:14,120
And typically we see very good results if you have the last layer with conditional random

305
00:20:14,120 --> 00:20:15,720
fields.

306
00:20:15,720 --> 00:20:16,800
Can you elaborate on that?

307
00:20:16,800 --> 00:20:18,960
What are conditional random fields?

308
00:20:18,960 --> 00:20:21,080
Yes, it's very, very standard.

309
00:20:21,080 --> 00:20:23,560
They're like discriminative classifiers.

310
00:20:23,560 --> 00:20:28,600
It's very, very standard built for many decades and using this kind of task.

311
00:20:28,600 --> 00:20:33,360
Their use, as I say, for sequence prediction, can encode relationships between the observed

312
00:20:33,360 --> 00:20:40,120
data, like typically the current and the previous word, does not model long-range dependencies.

313
00:20:40,120 --> 00:20:45,600
While in the LSTM, you have these deep learning models, which are more powerful, as I said,

314
00:20:45,600 --> 00:20:49,240
they can learn powerful representation given enough data.

315
00:20:49,240 --> 00:20:53,360
They can capture the long-term dependencies, not only in a sentence, but even they can

316
00:20:53,360 --> 00:20:56,160
span between sentences and paragraphs.

317
00:20:56,160 --> 00:21:00,480
And as I said, the best part is like you don't have to focus on feature engineering.

318
00:21:00,480 --> 00:21:04,840
You can just pass the raw data as input.

319
00:21:04,840 --> 00:21:13,760
So if you're looking to build a system like this, what are the primary considerations that

320
00:21:13,760 --> 00:21:20,600
you need to think about to architect it correctly and to build a system that meets a specific

321
00:21:20,600 --> 00:21:22,360
set of needs?

322
00:21:22,360 --> 00:21:28,680
I would say if you are familiar with machine learning, if you use these sets of methods or

323
00:21:28,680 --> 00:21:34,160
methods that are appropriate for structure prediction, your problem will be kind of solved.

324
00:21:34,160 --> 00:21:38,200
But the part that one really needs to focus on is the data.

325
00:21:38,200 --> 00:21:44,240
Because the data is going to drive the quality of how your system performs and behaves.

326
00:21:44,240 --> 00:21:48,400
And the semantic representation, this means as like how are these labeled spaces going

327
00:21:48,400 --> 00:21:50,120
to look like?

328
00:21:50,120 --> 00:21:54,760
In terms of like the machine learning algorithm themselves, there's like plenty of open-source

329
00:21:54,760 --> 00:22:01,200
platforms that people can use at Amazon, we have the MXNet platform, which is an open-source

330
00:22:01,200 --> 00:22:03,800
machine learning platform, we have TensorFlow.

331
00:22:03,800 --> 00:22:08,960
People have a wide variety of choosing which machine learning toolbox they can use.

332
00:22:08,960 --> 00:22:11,520
And as I said, that's pretty easy to pick up.

333
00:22:11,520 --> 00:22:15,320
But the hardest part is like if you don't know how to get your data, if you don't know

334
00:22:15,320 --> 00:22:20,840
how to represent it right, then even if you have the best toolbox on earth, you're

335
00:22:20,840 --> 00:22:24,400
only able to build your applications in the right way.

336
00:22:24,400 --> 00:22:29,160
So I encourage people to look at both things, not only at the machine learning side, but

337
00:22:29,160 --> 00:22:33,560
also on the side of like, how do I design my system?

338
00:22:33,560 --> 00:22:34,760
How do I collect the data?

339
00:22:34,760 --> 00:22:38,840
How do I drive all of these processes together?

340
00:22:38,840 --> 00:22:43,360
And you said making sure you represent your data right is one of the big challenges.

341
00:22:43,360 --> 00:22:46,400
What exactly does that mean and what are the considerations there?

342
00:22:46,400 --> 00:22:51,440
Yes, well, as I said, the biggest problem is like semantic understanding of like what

343
00:22:51,440 --> 00:22:56,440
humans mean and how should the computer in cold and understand that.

344
00:22:56,440 --> 00:22:57,440
And that's a challenge.

345
00:22:57,440 --> 00:23:00,040
And it's been a challenge for many years.

346
00:23:00,040 --> 00:23:04,440
There are theories, but yet building such a system that understands us humans is very

347
00:23:04,440 --> 00:23:05,440
challenging.

348
00:23:05,440 --> 00:23:10,920
So we have these basic representations that can, to some extent, work, but that doesn't

349
00:23:10,920 --> 00:23:13,520
mean that really understand what a human means.

350
00:23:13,520 --> 00:23:17,360
It's very hard for the systems to pick up like sarcasm.

351
00:23:17,360 --> 00:23:20,720
How do you take it, represent it and even like model it?

352
00:23:20,720 --> 00:23:24,480
These are much, much harder things we have to account for.

353
00:23:24,480 --> 00:23:29,480
Right now we have these basic, more flatter or slightly more structured representations,

354
00:23:29,480 --> 00:23:32,400
but that's definitely not the way to go forward.

355
00:23:32,400 --> 00:23:35,360
And I'm trying to put that into context.

356
00:23:35,360 --> 00:23:43,120
If I'm thinking through building out a system to understand language and you're advising

357
00:23:43,120 --> 00:23:50,720
me to start with the data collection and representation, I get collection, obviously it's going

358
00:23:50,720 --> 00:23:56,080
to be, or depending on the situation, it may be difficult to collect the data, but assume

359
00:23:56,080 --> 00:24:03,840
that I can collect a bunch of data, say, it's assumed it's in text form from bot requests

360
00:24:03,840 --> 00:24:05,680
or something like that.

361
00:24:05,680 --> 00:24:09,120
The next step you're saying is the representation.

362
00:24:09,120 --> 00:24:15,680
Where does representation come in before I start throwing my data at the machine learning

363
00:24:15,680 --> 00:24:20,960
algorithms and put another way, like part of what I'm expecting or hoping the machine

364
00:24:20,960 --> 00:24:26,760
learning algorithms to do is to kind of parse the data and help me figure out how to represent

365
00:24:26,760 --> 00:24:27,760
it.

366
00:24:27,760 --> 00:24:28,760
Is that right?

367
00:24:28,760 --> 00:24:31,600
Well, there are different ways one can do it.

368
00:24:31,600 --> 00:24:37,200
I'm also hearing a good thought from your side, which is like, can you even build the machines

369
00:24:37,200 --> 00:24:41,880
or can you build a machine, machine learning algorithms that can, given just some chat,

370
00:24:41,880 --> 00:24:46,920
but can automatically infer what the slots should be, what the intent should be.

371
00:24:46,920 --> 00:24:49,640
And definitely that's possible.

372
00:24:49,640 --> 00:24:53,760
It's not going to be very accurate because it's almost like when you do clustering over

373
00:24:53,760 --> 00:24:57,720
documents, right, you can end up with these different representations.

374
00:24:57,720 --> 00:25:00,160
And the same thing is going to happen here.

375
00:25:00,160 --> 00:25:05,920
So that's why typically you start with the notions of you defining your, your slots

376
00:25:05,920 --> 00:25:06,920
and intents.

377
00:25:06,920 --> 00:25:11,760
So when you build the machine learning applications, typically you have the classes, right, that

378
00:25:11,760 --> 00:25:16,240
you want to output, meaning if I give you a large document collection and I say, well,

379
00:25:16,240 --> 00:25:18,920
I just want to know is this low, is this medicine and so on.

380
00:25:18,920 --> 00:25:19,920
Okay.

381
00:25:19,920 --> 00:25:20,920
You already have these categories.

382
00:25:20,920 --> 00:25:24,560
So it's the same thing for building these natural language understanding components.

383
00:25:24,560 --> 00:25:29,520
You need to know what categories or what is your space over which you're going to operate.

384
00:25:29,520 --> 00:25:33,160
If you try to learn that automatically, as I say, you're going to end up with these

385
00:25:33,160 --> 00:25:38,560
coarse green, very high level, you'll define like meanings and they won't be sufficient

386
00:25:38,560 --> 00:25:46,240
for you to build a meaningful application, but if you sit down and actually write it yourself,

387
00:25:46,240 --> 00:25:51,120
you have much higher chance because think about it just to build a flight booking system.

388
00:25:51,120 --> 00:25:55,200
If you open the different travel website and you see like what are the minimum sets of

389
00:25:55,200 --> 00:26:00,400
inputs they require you from the destination to destination, time, location, and so on.

390
00:26:00,400 --> 00:26:04,680
And you just define literally that to be your space or the slots over which the system

391
00:26:04,680 --> 00:26:05,680
would operate.

392
00:26:05,680 --> 00:26:08,840
You're going to be able to build much, much better system.

393
00:26:08,840 --> 00:26:15,120
And to be honest, yes, one of the of the pushes in science, both in terms of industries,

394
00:26:15,120 --> 00:26:21,520
like can you build systems or conversational assistance that can learn from human interactions

395
00:26:21,520 --> 00:26:23,760
and that you can teach right now.

396
00:26:23,760 --> 00:26:27,880
If you ask something to a system to tell you, I'm sorry, I'm not quite sure about that

397
00:26:27,880 --> 00:26:29,720
or like I'm still learning.

398
00:26:29,720 --> 00:26:34,000
In reality, it will be really awesome if you make those system learn such that anything

399
00:26:34,000 --> 00:26:39,720
you say and based on how people have replied, plus like request for new, let's say for

400
00:26:39,720 --> 00:26:43,960
new information that you haven't seen before, if the system can learn it and start asking

401
00:26:43,960 --> 00:26:49,000
about it or see many people are talking about it, then this is the place where we want

402
00:26:49,000 --> 00:26:53,000
to go because humans cannot encode all the knowledge in the world.

403
00:26:53,000 --> 00:26:58,400
And where I'm headed at is like, if you look at how all of these applications are built,

404
00:26:58,400 --> 00:27:02,800
they are operated over different domains, which means you have a movie domain, you have

405
00:27:02,800 --> 00:27:06,200
like music domain, shopping domain and so on.

406
00:27:06,200 --> 00:27:11,320
And each of these domains have their semantic representations or so called slots and templates

407
00:27:11,320 --> 00:27:13,920
that you can call and you can fill in.

408
00:27:13,920 --> 00:27:18,920
But a human cannot sit down and represents the whole world in these frames, right?

409
00:27:18,920 --> 00:27:19,920
It's right.

410
00:27:19,920 --> 00:27:22,240
I'm consuming its labor intensive.

411
00:27:22,240 --> 00:27:23,880
It doesn't scale.

412
00:27:23,880 --> 00:27:28,120
And most importantly, it's like we humans don't operate for domains, right?

413
00:27:28,120 --> 00:27:31,640
I can say order my pizza and book a flight, right?

414
00:27:31,640 --> 00:27:35,960
I just request two different domains and express multiple intents.

415
00:27:35,960 --> 00:27:41,280
And that's the main reasons why it's, as I say, like the current technology is great

416
00:27:41,280 --> 00:27:43,160
and it's all real use cases.

417
00:27:43,160 --> 00:27:48,440
But there's like many, many more things that have to be done and we have to focus on figuring

418
00:27:48,440 --> 00:27:53,800
out how do you build an end-to-end system that can operate for any domain that can operate

419
00:27:53,800 --> 00:27:59,000
for different languages and that can continue to help assist in us.

420
00:27:59,000 --> 00:28:05,680
And so what's the state of the art there are people building a bunch of individual domain

421
00:28:05,680 --> 00:28:12,320
knowledge and then using some deep neural network to kind of identify which domain is

422
00:28:12,320 --> 00:28:20,040
being asked about in a particular utterance or are they building kind of bigger, flatter

423
00:28:20,040 --> 00:28:21,040
models?

424
00:28:21,040 --> 00:28:23,280
Is there any particular direction now?

425
00:28:23,280 --> 00:28:29,280
I think we have one of the most common trends that I have been seeing over time in this

426
00:28:29,280 --> 00:28:34,600
field is for people to try to focus on the different domains and for each domain focus

427
00:28:34,600 --> 00:28:35,600
on the slots.

428
00:28:35,600 --> 00:28:40,320
And sometimes I've seen people trying to transfer knowledge from similar domains, let's

429
00:28:40,320 --> 00:28:46,360
say I know everything about reserving restaurants and I have a little bit of data for hotels.

430
00:28:46,360 --> 00:28:51,320
Now can I learn how to reserve hotels by knowing how to reserve restaurants?

431
00:28:51,320 --> 00:28:53,240
So that's the most common approach.

432
00:28:53,240 --> 00:28:58,400
And as I said, it's a challenge because it doesn't scale, it just doesn't work.

433
00:28:58,400 --> 00:29:02,880
The ideal scenario is like, can you build a system that doesn't have these boundaries

434
00:29:02,880 --> 00:29:07,400
and can just like operate over anything that we have in mind?

435
00:29:07,400 --> 00:29:13,120
Yes, in terms of like what algorithms, there's a lot of people do use deep learning as

436
00:29:13,120 --> 00:29:15,920
I say, different parts of the components.

437
00:29:15,920 --> 00:29:16,920
Yeah.

438
00:29:16,920 --> 00:29:23,680
Yeah, and I guess deep learning isn't really fundamental to my question as much as is

439
00:29:23,680 --> 00:29:28,320
the best practice to or you know, is the research frontier.

440
00:29:28,320 --> 00:29:35,440
If I'm trying to build a system that can handle hotel reservations and pizza orders and

441
00:29:35,440 --> 00:29:41,760
buying cars and you know, multiple things, am I likely to be better off getting a bunch

442
00:29:41,760 --> 00:29:47,320
of data for each of those building out specialized representations for each of those and training

443
00:29:47,320 --> 00:29:52,800
models that perform well for each and then use some kind of discriminator that can figure

444
00:29:52,800 --> 00:30:00,800
out which model to use or is there some other kind of technique that at that metal level,

445
00:30:00,800 --> 00:30:02,520
you know, to pull it all together?

446
00:30:02,520 --> 00:30:09,520
Yeah, if you're building a production system that has to work and satisfy user and customer

447
00:30:09,520 --> 00:30:12,480
needs, then that's the right way to go.

448
00:30:12,480 --> 00:30:17,240
It will guarantee you one that your system is going to be doing the right things and

449
00:30:17,240 --> 00:30:22,240
it will have higher precision, which is what's very important for users.

450
00:30:22,240 --> 00:30:25,840
Nobody likes to hear the same question twice like, what did you mean?

451
00:30:25,840 --> 00:30:28,640
I didn't get your question.

452
00:30:28,640 --> 00:30:33,640
In terms of research, I think people can have much more flexibility and they can use

453
00:30:33,640 --> 00:30:34,640
all kinds of techniques.

454
00:30:34,640 --> 00:30:39,840
They can use like transfer learning to see like, how do I transfer my bot that I built?

455
00:30:39,840 --> 00:30:44,160
Let's say for restaurants into flights or into something else and I think these kind of

456
00:30:44,160 --> 00:30:49,280
transfers are more successful for things that are closer to each other.

457
00:30:49,280 --> 00:30:54,280
There are some people that I have just seen on general like entity recognition and sentiment

458
00:30:54,280 --> 00:30:59,560
analysis, but the thing is like they've been evaluated on much smaller data.

459
00:30:59,560 --> 00:31:04,160
So ideally what I really would like to see is like people doing it on a larger scale with

460
00:31:04,160 --> 00:31:09,400
lots of data and having many of these domains and actually showing like how possible it is

461
00:31:09,400 --> 00:31:13,440
and where are going to be like the biggest challenges.

462
00:31:13,440 --> 00:31:17,120
Also you can build the system in a different way like if you want, you can do these individual

463
00:31:17,120 --> 00:31:21,240
components and then you have something on the top that actually ranks your results and

464
00:31:21,240 --> 00:31:26,440
tells you what's the most likely domain sets of intents and also slots or you can build

465
00:31:26,440 --> 00:31:31,520
one big giant neural network architecture that you can incorporate.

466
00:31:31,520 --> 00:31:35,520
Let's say if you have your LSTM, you can make it learn both your slots.

467
00:31:35,520 --> 00:31:39,800
It can learn your intent as well as the domain and over time with a lot of data, you can

468
00:31:39,800 --> 00:31:44,680
learn these constraints that in certain domain, let's say like movies, it's very less likely

469
00:31:44,680 --> 00:31:48,560
that I do an action that is let's say possible for a different.

470
00:31:48,560 --> 00:31:53,840
I would say that if you are building a real application, then stick to what works.

471
00:31:53,840 --> 00:32:00,000
If you are passionate about exploring and pushing the frontiers and doing like a lot of research,

472
00:32:00,000 --> 00:32:04,920
then definitely there are many more like open doors in terms of like trying to see like

473
00:32:04,920 --> 00:32:08,040
where is the boundaries and how far can we get.

474
00:32:08,040 --> 00:32:10,040
Hmm, great, great.

475
00:32:10,040 --> 00:32:11,920
Let's talk about the data a little bit.

476
00:32:11,920 --> 00:32:18,040
Are there standard data sets that folks are using for these kinds of problems like there

477
00:32:18,040 --> 00:32:21,880
are in the image recognition side of things?

478
00:32:21,880 --> 00:32:27,640
I've seen like there is some challenges that are called the dialog state tracking challenge.

479
00:32:27,640 --> 00:32:34,440
They do focus a lot on the dialog manager component and there are also these attempts

480
00:32:34,440 --> 00:32:40,080
with these different same data challenge that people can do the knowledge transfer that

481
00:32:40,080 --> 00:32:41,480
I was talking about.

482
00:32:41,480 --> 00:32:46,600
I've seen people use different types like Ubuntu chats and that's like if you just want

483
00:32:46,600 --> 00:32:52,000
to build like a high level chatbot system that doesn't, it's not go oriented.

484
00:32:52,000 --> 00:32:57,480
And then I've seen a lot of work from Facebook AI that drives in that area and they have

485
00:32:57,480 --> 00:32:59,480
a data set that's called BABY.

486
00:32:59,480 --> 00:33:00,480
It's called what?

487
00:33:00,480 --> 00:33:01,480
I think BABY.

488
00:33:01,480 --> 00:33:02,480
Okay.

489
00:33:02,480 --> 00:33:08,960
I'm not sure how the right pronunciation is BABY, but it has like different tasks like

490
00:33:08,960 --> 00:33:15,240
20 tasks and it's annotated and people do use it for conducting research.

491
00:33:15,240 --> 00:33:20,480
So if somebody wants to like start in that area and wants to play around, maybe these

492
00:33:20,480 --> 00:33:21,480
are good places.

493
00:33:21,480 --> 00:33:26,520
As I said, it depends like you just want to build like a chatbot that doesn't have any

494
00:33:26,520 --> 00:33:31,480
goal for a few months or do you want to focus on building a real working system that is

495
00:33:31,480 --> 00:33:34,840
going to fulfill your goals for you as a human.

496
00:33:34,840 --> 00:33:35,840
Hmm.

497
00:33:35,840 --> 00:33:40,960
And now if you're building a system like this and none of these data sets work for you,

498
00:33:40,960 --> 00:33:45,480
you've got to figure out some place to find that data.

499
00:33:45,480 --> 00:33:50,600
And I noted that you've got some research experience into large scale knowledge extraction

500
00:33:50,600 --> 00:33:51,600
from the web.

501
00:33:51,600 --> 00:33:57,200
Are there any techniques there that you might use to help you collect the data set?

502
00:33:57,200 --> 00:33:59,640
Well, you can do different things.

503
00:33:59,640 --> 00:34:04,480
People have invested a lot of effort in building this wizard of all systems.

504
00:34:04,480 --> 00:34:09,120
It means like you can build very quick application that simulates a scenario.

505
00:34:09,120 --> 00:34:13,760
Let's say one person will pretend he is the booking expert and the other one will be

506
00:34:13,760 --> 00:34:19,440
the customer and they can drive the conversation on their own and the booking agent will just

507
00:34:19,440 --> 00:34:21,320
try to fulfill that intent.

508
00:34:21,320 --> 00:34:27,760
So if you create such scenarios and record all the data with different people interacting,

509
00:34:27,760 --> 00:34:32,880
that could be one easy quick way to start building your application.

510
00:34:32,880 --> 00:34:34,360
Another way could be that you can do that.

511
00:34:34,360 --> 00:34:37,760
And just to drill into that, what you're suggesting there is that you define out these

512
00:34:37,760 --> 00:34:42,360
scenarios and then are you thinking like go to some place like a mechanical Turk and

513
00:34:42,360 --> 00:34:47,600
say, hey, you know, you play the booking agent and you play the customer and you get kind

514
00:34:47,600 --> 00:34:52,080
of random people to explore these scenarios or do you mean something else by that?

515
00:34:52,080 --> 00:34:54,200
Yeah, it's perfectly feasible.

516
00:34:54,200 --> 00:34:56,920
Yes, you can exactly do that.

517
00:34:56,920 --> 00:35:01,000
Like kind of decide what you what the application you want to build.

518
00:35:01,000 --> 00:35:05,520
You can set up everything being on Amazon Turk or being even let's say you're a startup

519
00:35:05,520 --> 00:35:08,600
and you don't want this information to be leaking.

520
00:35:08,600 --> 00:35:09,600
Then you can set it up.

521
00:35:09,600 --> 00:35:14,880
Even build your own very quick in-house application that just can record these conversations.

522
00:35:14,880 --> 00:35:18,920
And once you have that data, then you can start building, let's say, a first prototype.

523
00:35:18,920 --> 00:35:22,360
You can even launch it and then test it on real users.

524
00:35:22,360 --> 00:35:25,360
When the data comes back, you can start iterating.

525
00:35:25,360 --> 00:35:29,400
And once you have this kind of nice loop, you can keep iterating and improving what you

526
00:35:29,400 --> 00:35:30,400
have done.

527
00:35:30,400 --> 00:35:31,400
That's one way.

528
00:35:31,400 --> 00:35:35,760
Like completely even focus on, let's say, like just Amazon Mechanical Turk.

529
00:35:35,760 --> 00:35:40,120
You can either have predefined questions, but then the conversation will become very artificial

530
00:35:40,120 --> 00:35:43,480
or you can play the game that you have just explained.

531
00:35:43,480 --> 00:35:48,600
And then the on your questions, like, can we do something if I give you the whole web?

532
00:35:48,600 --> 00:35:51,880
What can I do to facilitate the building of such systems?

533
00:35:51,880 --> 00:35:54,960
Like at the core of these systems is like a knowledge component.

534
00:35:54,960 --> 00:35:59,680
You have to have knowledge bases that help you extract this information much more accurately

535
00:35:59,680 --> 00:36:01,920
that help you get world knowledge.

536
00:36:01,920 --> 00:36:05,800
And one way is that you can get that world knowledge if you don't have your own knowledge

537
00:36:05,800 --> 00:36:06,800
graph.

538
00:36:06,800 --> 00:36:11,280
You can get that world knowledge by literally extracting all of that information from tons

539
00:36:11,280 --> 00:36:13,600
of web pages on different topics.

540
00:36:13,600 --> 00:36:16,240
And you can integrate it inside your models, right?

541
00:36:16,240 --> 00:36:21,360
Either as additional features or additional signal and the help drive these applications

542
00:36:21,360 --> 00:36:24,480
to be more precise and more accurate.

543
00:36:24,480 --> 00:36:28,200
Interesting, interesting.

544
00:36:28,200 --> 00:36:33,480
If you did a talk on dialogue systems, actually that's coming up.

545
00:36:33,480 --> 00:36:38,280
It looks like is that in the same kind of domain of the things that we've been talking about

546
00:36:38,280 --> 00:36:41,160
as far or there are different aspects to that?

547
00:36:41,160 --> 00:36:47,760
Yes, that was like, have the core component of like, if people know machine learning and

548
00:36:47,760 --> 00:36:52,360
they want to build everything from scratch, their cells is like, what components should

549
00:36:52,360 --> 00:36:53,520
they focus on?

550
00:36:53,520 --> 00:36:57,840
What machine learning algorithm they should work like pick up and then how to get the

551
00:36:57,840 --> 00:36:58,840
data?

552
00:36:58,840 --> 00:37:01,400
And at the same time, it's like, what's the expectation?

553
00:37:01,400 --> 00:37:07,200
Some people have the expectations that this system should be like 99% accurate.

554
00:37:07,200 --> 00:37:12,560
And I was like, oh, not really, we're doing these baby steps in the field for some very

555
00:37:12,560 --> 00:37:14,040
specific basic things.

556
00:37:14,040 --> 00:37:18,240
You have high accuracy, but that doesn't mean that you have solved the problem.

557
00:37:18,240 --> 00:37:23,760
It just shows that the solution of such task is possible, but doesn't mean that it's a

558
00:37:23,760 --> 00:37:24,760
solve problem.

559
00:37:24,760 --> 00:37:29,080
So, you bring up accuracy and that raises some interesting questions, I think, on the

560
00:37:29,080 --> 00:37:34,960
speech recognition side, you know, there are some standardized measures of accuracy and

561
00:37:34,960 --> 00:37:40,240
you have folks like, you know, Microsoft and others reporting there, their accuracy

562
00:37:40,240 --> 00:37:45,080
and, in fact, Microsoft recently reported, or they're, I think, a number of organizations

563
00:37:45,080 --> 00:37:49,800
have recently reported human parity and recognition.

564
00:37:49,800 --> 00:37:57,800
It seems like it's maybe not quite as straightforward to report accuracy on the NLU side of things.

565
00:37:57,800 --> 00:37:59,000
Is that true or no?

566
00:37:59,000 --> 00:38:06,000
Well, actually, no, think about it like when we annotate the data, you typically have

567
00:38:06,000 --> 00:38:09,600
your training set, your development set, and you have your test set.

568
00:38:09,600 --> 00:38:14,440
And for each of those, we always measure what is your precision, what is your recall,

569
00:38:14,440 --> 00:38:15,440
what's your F score?

570
00:38:15,440 --> 00:38:21,400
We go on the level of each of these slots, and we also record other things like, how hard

571
00:38:21,400 --> 00:38:23,200
is the task for a human?

572
00:38:23,200 --> 00:38:28,040
We measure the cap agreement, the Krippendorf Alpha, and the idea is that if you see how hard

573
00:38:28,040 --> 00:38:33,480
the task is for a human, then expect your system to be 10% less than that, right?

574
00:38:33,480 --> 00:38:38,760
So if two humans have really hard time annotating your data with your representations, this

575
00:38:38,760 --> 00:38:44,080
means that it will be extremely hard also for that system to learn about it.

576
00:38:44,080 --> 00:38:49,200
My point was that building the natural language understanding systems is much harder than

577
00:38:49,200 --> 00:38:52,720
building a, let's say, image understanding system.

578
00:38:52,720 --> 00:38:55,480
And the challenge is like language is very ambiguous.

579
00:38:55,480 --> 00:39:01,120
We have to deal with a lot of slang that people might be using, or specific like metaphors

580
00:39:01,120 --> 00:39:02,920
that people have in mind.

581
00:39:02,920 --> 00:39:07,840
And so the building of a system that can understand and operate on top of that, right?

582
00:39:07,840 --> 00:39:08,840
It's very hard.

583
00:39:08,840 --> 00:39:12,440
That's why I was saying that it's important to have your knowledge basis hooked up so

584
00:39:12,440 --> 00:39:18,640
that the system can get, think about like a cheat sheet and some extra information that

585
00:39:18,640 --> 00:39:22,360
can help it facilitate, understand better, like what we mean.

586
00:39:22,360 --> 00:39:23,360
Right.

587
00:39:23,360 --> 00:39:24,360
Yeah.

588
00:39:24,360 --> 00:39:26,560
I think that's what I was getting at with the accuracy question.

589
00:39:26,560 --> 00:39:32,760
I can think of many occasions often happening right here at home where I definitely understand

590
00:39:32,760 --> 00:39:36,160
the words, but I'm not sure I totally understand the meaning.

591
00:39:36,160 --> 00:39:46,040
And while I can certainly grade my system's accuracy relative to some label set, it's

592
00:39:46,040 --> 00:39:50,960
harder to capture even the right metrics in terms of, you mentioned this earlier in

593
00:39:50,960 --> 00:39:59,800
the conversation, like, do we even have representation for nuance and sarcasm and things

594
00:39:59,800 --> 00:40:05,880
like that, that, you know, if I had some uber metric of, hey, does, you know, does the system

595
00:40:05,880 --> 00:40:13,080
understand what was being said, it just seems way more difficult to really capture what

596
00:40:13,080 --> 00:40:14,440
that even means.

597
00:40:14,440 --> 00:40:15,440
Yes.

598
00:40:15,440 --> 00:40:20,200
And, you know, like back in the day when I was like with my academic head, my head that

599
00:40:20,200 --> 00:40:25,640
grant from my ARPA, that focused on, can you build systems that understand metaphors

600
00:40:25,640 --> 00:40:30,640
for four different languages, it was Arabic, Russian, Spanish and English, and what

601
00:40:30,640 --> 00:40:31,640
I mean, metaphors.

602
00:40:31,640 --> 00:40:32,640
Metaphors.

603
00:40:32,640 --> 00:40:33,640
Metaphors, got it.

604
00:40:33,640 --> 00:40:34,640
Yes.

605
00:40:34,640 --> 00:40:40,640
And you have these four different languages like Spanish and Russian and Arabic and English.

606
00:40:40,640 --> 00:40:46,200
And the idea is like, we just pass any text, could be news, can you find those metaphors,

607
00:40:46,200 --> 00:40:51,880
can you interpret them and also assign the sentiment that the person had when he said that

608
00:40:51,880 --> 00:40:52,880
metaphor, right?

609
00:40:52,880 --> 00:40:59,880
So, if I say my lawyer is a shark, so you know that, yeah, sharks are vicious, but it's

610
00:40:59,880 --> 00:41:04,040
really good for me to have a lawyer like that because it means that that the lawyer is

611
00:41:04,040 --> 00:41:07,280
going to do the right thing and they're going to protect you.

612
00:41:07,280 --> 00:41:11,840
But if I'm saying this to you, then for you, that is going to have a negative connotation,

613
00:41:11,840 --> 00:41:12,840
right?

614
00:41:12,840 --> 00:41:17,320
So, it was really hard to build systems that just given any three texts in these languages,

615
00:41:17,320 --> 00:41:21,760
it can identify the metaphoric expression interpret what they mean.

616
00:41:21,760 --> 00:41:26,600
And yeah, we've focused like two years on just building and trying to solve it.

617
00:41:26,600 --> 00:41:31,640
And unlike other tasks in each language processing that have matured over time and that have

618
00:41:31,640 --> 00:41:37,600
like significantly higher performance, building such kind of system that understand metaphors

619
00:41:37,600 --> 00:41:38,600
was very hard.

620
00:41:38,600 --> 00:41:42,240
It's like in the 50 percent, it's really challenging.

621
00:41:42,240 --> 00:41:47,960
Yeah, again, going back to my previous point, it's even hard to, before we get to building

622
00:41:47,960 --> 00:41:53,640
the system to think about what performance even means in this context, right?

623
00:41:53,640 --> 00:41:59,280
I think even that statement about my lawyer as a shark can be, you know, can probably have

624
00:41:59,280 --> 00:42:03,360
either positive or negative sentiment depending on the circumstance.

625
00:42:03,360 --> 00:42:05,160
That is correct, exactly.

626
00:42:05,160 --> 00:42:09,960
But you know, the best part is like, as I say, language is very hard and there are a lot

627
00:42:09,960 --> 00:42:13,960
of people trying to solve these challenging tasks for some of them, we've made tremendous

628
00:42:13,960 --> 00:42:18,400
progress, others are open-ended and we're still working on them.

629
00:42:18,400 --> 00:42:22,320
And that's what excites me because it means that we have a lot of work to do, a lot of

630
00:42:22,320 --> 00:42:25,680
efforts to put into building their systems.

631
00:42:25,680 --> 00:42:27,080
Absolutely, absolutely.

632
00:42:27,080 --> 00:42:31,160
What are some of the other areas that you're tracking that you're seeing exciting work

633
00:42:31,160 --> 00:42:32,160
happening?

634
00:42:32,160 --> 00:42:37,760
In natural language processing, there is like a lot of focus on question answering.

635
00:42:37,760 --> 00:42:41,920
And the building, both type of systems, like if I give you a knowledge base, can you

636
00:42:41,920 --> 00:42:46,720
do question answering over this knowledge base and do inferences on top of that?

637
00:42:46,720 --> 00:42:50,360
And we have seen open-ended question answering where you have a document and just somebody

638
00:42:50,360 --> 00:42:55,280
comes in and types the question like this on the spur of the moment, then can we find

639
00:42:55,280 --> 00:42:58,720
the corresponding answer in that document?

640
00:42:58,720 --> 00:43:01,240
They're both very challenging and exciting.

641
00:43:01,240 --> 00:43:06,000
So this year I will area chair for ACA, which is association of computational linguistics

642
00:43:06,000 --> 00:43:10,840
conference, our top tier one conference and like the biggest natural language processing

643
00:43:10,840 --> 00:43:15,920
conferences and the areas that we're training a lot for information extraction and question

644
00:43:15,920 --> 00:43:17,080
answering.

645
00:43:17,080 --> 00:43:22,840
And there's like a lot of effort, some challenges that are coming up and people have just

646
00:43:22,840 --> 00:43:28,880
been given the data and given the ability to think about how to innovate and how to solve

647
00:43:28,880 --> 00:43:29,880
them.

648
00:43:29,880 --> 00:43:36,760
I know Kora is among the folks that have data sets for question answering and there's

649
00:43:36,760 --> 00:43:41,440
another popular one, at least another popular one that I'm forgetting the name of right

650
00:43:41,440 --> 00:43:42,440
now.

651
00:43:42,440 --> 00:43:43,840
Yes, that's absolutely correct.

652
00:43:43,840 --> 00:43:46,520
Like Kora has a nice data set.

653
00:43:46,520 --> 00:43:51,600
You have squat, who is coming, does a data set developed by University of Stanford,

654
00:43:51,600 --> 00:43:53,000
Percy Liang's group?

655
00:43:53,000 --> 00:43:55,400
And that's one of the, it's a very good data set.

656
00:43:55,400 --> 00:44:00,680
It has a lot of training data, magnitude's larger than previous data set.

657
00:44:00,680 --> 00:44:03,360
And it has different types of categories of questions.

658
00:44:03,360 --> 00:44:07,520
So that kind of mostly simulates or approximate real case scenario.

659
00:44:07,520 --> 00:44:12,040
And that data set focuses on the second question answering type that I was talking about.

660
00:44:12,040 --> 00:44:16,280
You have like documents and then you have a question like can you find the answer in

661
00:44:16,280 --> 00:44:17,280
the document?

662
00:44:17,280 --> 00:44:21,200
And it's much challenging because people can ask the question in any form using different

663
00:44:21,200 --> 00:44:22,600
part of phrases.

664
00:44:22,600 --> 00:44:27,280
And then finding these pants with the correct answer is way harder than traversing a

665
00:44:27,280 --> 00:44:29,080
real knowledge base.

666
00:44:29,080 --> 00:44:35,680
And so are the core techniques that are used for these two different types of question

667
00:44:35,680 --> 00:44:39,280
answering tasks the same or are they dramatically different?

668
00:44:39,280 --> 00:44:45,160
Well, I've seen people that use, let's say, knowledge graphs to answer questions to

669
00:44:45,160 --> 00:44:48,040
use more graph based algorithms.

670
00:44:48,040 --> 00:44:52,040
And I'm seeing a lot of trends with the deep learning for the second kind of problem

671
00:44:52,040 --> 00:44:56,960
with this squat data set, which is more like machine comprehension from text.

672
00:44:56,960 --> 00:45:00,600
And there are people have different architectures of how they solve it.

673
00:45:00,600 --> 00:45:05,120
But let's say for the machine comprehension one, I've seen very common is like people

674
00:45:05,120 --> 00:45:09,640
try to represent the question into some kind of an embedding or vector space.

675
00:45:09,640 --> 00:45:14,360
And then they have the document they try to use like attention mechanism on top to pick

676
00:45:14,360 --> 00:45:18,520
up entities or pick up spans that could be good match for the answer.

677
00:45:18,520 --> 00:45:23,600
And then they kind of try to have some similarity between the question and the answer.

678
00:45:23,600 --> 00:45:28,760
So yes, both of those different types of question answering have wide variety of methods

679
00:45:28,760 --> 00:45:29,760
have been employed.

680
00:45:29,760 --> 00:45:34,440
But these are two things that I'm noticing are kind of trending when people publish their

681
00:45:34,440 --> 00:45:35,600
work.

682
00:45:35,600 --> 00:45:36,600
Hmm.

683
00:45:36,600 --> 00:45:42,800
So for the knowledge graphs, I'm imagining there that you're using some kind of technique

684
00:45:42,800 --> 00:45:50,320
to identify, well, maybe a precursor to that is what types of representations are using

685
00:45:50,320 --> 00:45:56,400
typically on your documents that you're trying to do this question answering for.

686
00:45:56,400 --> 00:46:04,640
Are you doing things like trying to do semantics and identify nouns and verbs and that kind

687
00:46:04,640 --> 00:46:05,640
of structure?

688
00:46:05,640 --> 00:46:09,840
Or are you operating on a lower level than that?

689
00:46:09,840 --> 00:46:15,680
Oh, actually, yeah, that's what I was saying that this data set, I like it because one,

690
00:46:15,680 --> 00:46:22,280
the magnitude is much larger than any previous data set and two, you have to focus on extracting

691
00:46:22,280 --> 00:46:25,000
different types of bits and pieces.

692
00:46:25,000 --> 00:46:28,040
And sometimes they could be just a word of phrase.

693
00:46:28,040 --> 00:46:32,280
They could be combinations of like just like a non phrase or much harder.

694
00:46:32,280 --> 00:46:37,160
It's not like a single answer like when was Barack Obama born and you just say the year,

695
00:46:37,160 --> 00:46:38,160
right?

696
00:46:38,160 --> 00:46:41,200
That's what a knowledge like a question answering over knowledge base does.

697
00:46:41,200 --> 00:46:46,400
This one is more open and that if I say like, hey, what were the symptoms for people who

698
00:46:46,400 --> 00:46:50,840
have cardiac arrest, maybe the answers were contained in different paragraphs and you

699
00:46:50,840 --> 00:46:55,520
have to find those different paragraphs and the exact spans with the answer.

700
00:46:55,520 --> 00:46:59,680
And that's what makes it much more challenging, but at the same time, much more useful because

701
00:46:59,680 --> 00:47:04,720
most of the information that we need and the questions that we have, they lay in this unlabeled

702
00:47:04,720 --> 00:47:10,720
documents that are being on the web or that you as a corporation might have and you might

703
00:47:10,720 --> 00:47:12,880
want to just search for the information.

704
00:47:12,880 --> 00:47:17,480
So I personally prefer this type of question answering work because it's, as I say, more

705
00:47:17,480 --> 00:47:19,000
real case scenario.

706
00:47:19,000 --> 00:47:23,600
And second, it's like more useful to us.

707
00:47:23,600 --> 00:47:24,960
And so just to take a step back.

708
00:47:24,960 --> 00:47:31,160
So with these question answering data sets in particular, the Stanford one, the data set

709
00:47:31,160 --> 00:47:37,400
includes the base document and then a set of questions and answers from that document

710
00:47:37,400 --> 00:47:44,520
and are there multiple answers for each question and to what degree to the questions overlap?

711
00:47:44,520 --> 00:47:48,120
Yes, that's a great question.

712
00:47:48,120 --> 00:47:53,600
So typically you have something like one question like, I'm just reading from the official

713
00:47:53,600 --> 00:47:58,240
paper that was published, which governing bodies have veto power and then you have a whole

714
00:47:58,240 --> 00:48:03,200
document that, let's say, is talking about something, right?

715
00:48:03,200 --> 00:48:08,120
There is one specific sentence that can have this answer, for example, the European Parliament

716
00:48:08,120 --> 00:48:12,800
and the Council of the European Union have powers over the month and veto and so on.

717
00:48:12,800 --> 00:48:18,160
So given that question, then the idea and this document idea is like, can you find the

718
00:48:18,160 --> 00:48:26,000
paragraph and more specifically the sentence that contains this specific type of an answer?

719
00:48:26,000 --> 00:48:31,760
And I haven't like the deeper in terms of like understanding like how many of the question

720
00:48:31,760 --> 00:48:37,400
the exact, let's say, question could be found with the exact answer inside.

721
00:48:37,400 --> 00:48:42,160
But I do know that the creators made sure that when that data was annotated, that they

722
00:48:42,160 --> 00:48:46,800
asked people is like, if you read this article, can you ask a question using paraphrases,

723
00:48:46,800 --> 00:48:50,760
which means like different words or different ways that you can ask about it.

724
00:48:50,760 --> 00:48:54,600
So it doesn't have to be the exact same, how to say exact same phrasing.

725
00:48:54,600 --> 00:48:58,680
If you had the exact same phrasing, then the problem is much more simple, right?

726
00:48:58,680 --> 00:49:03,280
But definitely that's how to say much more challenging dataset, the way it was created

727
00:49:03,280 --> 00:49:04,640
and the way it's annotated.

728
00:49:04,640 --> 00:49:09,440
So I think they did a good job on making sure it's created the right way.

729
00:49:09,440 --> 00:49:13,240
It has different complexity, yeah.

730
00:49:13,240 --> 00:49:19,280
So that helps me, that helps clarify for me like what you're fundamentally trying to

731
00:49:19,280 --> 00:49:26,360
do is you're given a question and you're trying to essentially index into this document,

732
00:49:26,360 --> 00:49:31,400
the sentence, the particular sentence that answers it, which is a totally different

733
00:49:31,400 --> 00:49:39,280
problem than, or at least it is a more narrow problem than synthesizing an answer based

734
00:49:39,280 --> 00:49:46,880
on multiple sentences in the document or a summary type of problem or trying to pull

735
00:49:46,880 --> 00:49:53,440
pieces from two different sentences that are required to formulate an answer.

736
00:49:53,440 --> 00:49:58,040
Yes, that's more like a summarization what you are describing.

737
00:49:58,040 --> 00:50:02,920
And there the goal is a little bit different if I give you one or multiple news articles

738
00:50:02,920 --> 00:50:08,120
about the same topic is like can you find sentences such that you can summarize the text

739
00:50:08,120 --> 00:50:10,480
in a much more compact fashion.

740
00:50:10,480 --> 00:50:15,120
And for a human, the moment they read it, they get the gist of the facts and at the same

741
00:50:15,120 --> 00:50:20,400
time the whole summary is coherent and has natural reading flow.

742
00:50:20,400 --> 00:50:27,200
There are dataset that has been created on that area is just the problem is called more

743
00:50:27,200 --> 00:50:28,960
like summarization, right?

744
00:50:28,960 --> 00:50:31,320
Right, but there's some overlap, right?

745
00:50:31,320 --> 00:50:37,040
So if you just to construct a simple example, if I've got a document that says somewhere

746
00:50:37,040 --> 00:50:42,040
in it, you know, my favorite color is red, you know, and then the next sentence is, you

747
00:50:42,040 --> 00:50:45,280
know, but I also like blue and yellow, right?

748
00:50:45,280 --> 00:50:48,840
And if you ask a question, what colors do I like?

749
00:50:48,840 --> 00:50:54,640
There's got to be some synthesis or summarization in there somewhere and, you know, A, is that,

750
00:50:54,640 --> 00:51:00,360
you know, typically part of the question answering, is there a, you know, a set of work in question

751
00:51:00,360 --> 00:51:06,520
answering that's looking at those kind of more complex scenarios or are there folks that

752
00:51:06,520 --> 00:51:11,240
are trying to combine the question answering and summarization pieces to, you know, answer

753
00:51:11,240 --> 00:51:12,840
these more complex questions.

754
00:51:12,840 --> 00:51:17,440
Yeah, if I'm not mistaken, there are people who are trying to do both.

755
00:51:17,440 --> 00:51:24,160
I've seen this a mostly like focusing on one, but noted the two, but I'm sure that there

756
00:51:24,160 --> 00:51:25,440
are people who work on that.

757
00:51:25,440 --> 00:51:30,040
I'm just not aware at the moment of, of, or I don't have them on top of my head for such

758
00:51:30,040 --> 00:51:36,200
paper, but like, there's a researcher called Sasha Rush, like he has a paper on like,

759
00:51:36,200 --> 00:51:40,600
how do you do this summarization that you were describing with attention mechanisms?

760
00:51:40,600 --> 00:51:45,400
So I'm sure that they're likely there could be a work combining both of the things that

761
00:51:45,400 --> 00:51:48,560
you're describing.

762
00:51:48,560 --> 00:51:53,680
So if someone wants to dig into this more, do you have any go-to resources for getting

763
00:51:53,680 --> 00:51:54,680
started?

764
00:51:54,680 --> 00:51:55,680
Yes.

765
00:51:55,680 --> 00:51:58,280
For example, depends on what your aim is.

766
00:51:58,280 --> 00:52:03,960
If your aim is to stay on top of the Neatronic Processing field, a great place is just to

767
00:52:03,960 --> 00:52:08,960
go to the ACO ontology and all the different NLP conferences, their index there.

768
00:52:08,960 --> 00:52:13,920
You can see the latest papers organized by yours and by tracks.

769
00:52:13,920 --> 00:52:18,040
So you can pick your favorite track, being question answering, being parsing, being

770
00:52:18,040 --> 00:52:20,280
machine translation, whatever excites you.

771
00:52:20,280 --> 00:52:24,760
And it's great to just sit down and like read through these papers and search that you

772
00:52:24,760 --> 00:52:26,360
can get on a high level.

773
00:52:26,360 --> 00:52:30,440
What is it that people are working on and how far they have advanced?

774
00:52:30,440 --> 00:52:35,240
If somebody's just a beginner and they're trying to learn about the field, I encourage

775
00:52:35,240 --> 00:52:36,240
you.

776
00:52:36,240 --> 00:52:39,840
You can look at the Stanford's class on deep learning, like Neatronic's first thing

777
00:52:39,840 --> 00:52:40,840
with deep learning.

778
00:52:40,840 --> 00:52:45,800
It's taught by Chris Manning and Richard Zohar, both of them are like leaders in the field.

779
00:52:45,800 --> 00:52:51,000
And it's a good place to start and just kind of learn both about what are the problems

780
00:52:51,000 --> 00:52:56,280
in NLP, like the basic ones, and then how do you solve them using deep learning?

781
00:52:56,280 --> 00:53:01,080
And there are a lot of books people can just take and read specific chapters.

782
00:53:01,080 --> 00:53:07,320
So it really depends on what is your end goal, is it learning or is it just download and

783
00:53:07,320 --> 00:53:08,320
build?

784
00:53:08,320 --> 00:53:13,720
And you have open source code that people can use as well, just to run something basic

785
00:53:13,720 --> 00:53:17,320
and understand what's happening.

786
00:53:17,320 --> 00:53:22,800
And to bring us full circle, if all you want to do is build systems that use this stuff,

787
00:53:22,800 --> 00:53:26,200
you can use services like the stuff you're working on at Amazon.

788
00:53:26,200 --> 00:53:27,840
Yes, you can do that.

789
00:53:27,840 --> 00:53:33,160
And as I say, one is if you know nothing about machine learning, but yet you want to build

790
00:53:33,160 --> 00:53:37,160
such systems, you can use a lot of the pre-built things and we've done the heavy lifting

791
00:53:37,160 --> 00:53:38,160
for you.

792
00:53:38,160 --> 00:53:42,440
If you are passionate about machine learning, you know the algorithms and you love implementing

793
00:53:42,440 --> 00:53:43,440
from scratch.

794
00:53:43,440 --> 00:53:47,600
You can use like open source like MXNet, which we are supporting.

795
00:53:47,600 --> 00:53:48,600
You can use TensorFlow.

796
00:53:48,600 --> 00:53:50,720
You can use any of those tools.

797
00:53:50,720 --> 00:53:56,240
It's just depending on like what's your level and also like are you on a deadline or are

798
00:53:56,240 --> 00:53:59,360
you in this like learning exploration mode?

799
00:53:59,360 --> 00:54:09,680
And do you foresee a future that allows folks to combine elements of both and in particular

800
00:54:09,680 --> 00:54:14,560
what I'm getting at is, you know, now your choice has seemed to be, you know, I can use

801
00:54:14,560 --> 00:54:23,360
a service like Lex that's, you know, pre-trained or I can, you know, roll my own and, you know,

802
00:54:23,360 --> 00:54:27,840
train using my own data and, you know, the presumption being I'm trying to get more accuracy

803
00:54:27,840 --> 00:54:33,320
by, you know, training on a more limited, you know, the more limited corpus that I'm concerned

804
00:54:33,320 --> 00:54:34,320
about.

805
00:54:34,320 --> 00:54:40,360
Do you see over time the kind of AI as a service offerings allowing you to upload your

806
00:54:40,360 --> 00:54:45,480
own data and train on it and somehow augment, you know, their pre-trained models?

807
00:54:45,480 --> 00:54:49,640
Yeah, I think that's exactly where like future is headed.

808
00:54:49,640 --> 00:54:53,080
Definitely people have their own data sets, their own requirements.

809
00:54:53,080 --> 00:54:59,320
If they have the data scientists also like available, doing exactly what you describe is

810
00:54:59,320 --> 00:55:00,320
possible.

811
00:55:00,320 --> 00:55:06,560
And I think that's fantastic way to take advantage of your in-house data, take advantage

812
00:55:06,560 --> 00:55:12,000
of your engineers and put them on a mission or put them on a task, which is like, okay,

813
00:55:12,000 --> 00:55:14,680
improve these services, augment them, make them better.

814
00:55:14,680 --> 00:55:20,160
So definitely I think that's a great place to be and in a great area to invest and focus

815
00:55:20,160 --> 00:55:21,160
on.

816
00:55:21,160 --> 00:55:22,160
Great.

817
00:55:22,160 --> 00:55:27,720
Well, I really appreciated all the time you spent with us today and I really enjoyed

818
00:55:27,720 --> 00:55:28,720
the conversation.

819
00:55:28,720 --> 00:55:29,720
Thanks so much.

820
00:55:29,720 --> 00:55:30,720
Zora Nitsa.

821
00:55:30,720 --> 00:55:32,720
Likewise, thank you very much Sam.

822
00:55:32,720 --> 00:55:33,720
Bye.

823
00:55:33,720 --> 00:55:34,720
Bye.

824
00:55:34,720 --> 00:55:35,720
Bye.

825
00:55:35,720 --> 00:55:42,480
All right, everyone, that's our show for today.

826
00:55:42,480 --> 00:55:47,480
Thanks so much for listening and for your continued support, comments and feedback.

827
00:55:47,480 --> 00:55:48,960
This is your last reminder.

828
00:55:48,960 --> 00:55:55,200
If you are in New York today, June 29th, Thursday, join me this evening at the happy hour.

829
00:55:55,200 --> 00:55:57,880
I'm hosting with the NYAI Meetup.

830
00:55:57,880 --> 00:56:05,080
If you'd like more details, please sign up using the form at twimlai.com slash NY Meetup.

831
00:56:05,080 --> 00:56:10,680
The notes for this episode can be found at twimlai.com slash talk slash 30.

832
00:56:10,680 --> 00:56:16,360
For more information on industrial AI, my report on the topic or the industrial AI podcast

833
00:56:16,360 --> 00:56:21,360
series, visit twimlai.com slash industrial AI.

834
00:56:21,360 --> 00:56:26,000
As always, remember to post your favorite quote or takeaway from this episode and we'll

835
00:56:26,000 --> 00:56:27,840
send you a laptop sticker.

836
00:56:27,840 --> 00:56:33,760
You can post them as comments to the show notes page via Twitter mentioning at twimlai or via

837
00:56:33,760 --> 00:56:35,360
our Facebook page.

838
00:56:35,360 --> 00:56:46,760
Thanks so much for listening and catch you next time.

