1
00:00:00,000 --> 00:00:15,920
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

2
00:00:15,920 --> 00:00:20,880
people doing interesting things in machine learning and artificial intelligence.

3
00:00:20,880 --> 00:00:23,240
I'm your host Sam Charrington.

4
00:00:23,240 --> 00:00:27,480
This show you are about to hear as part of a series of shows recorded in San Francisco

5
00:00:27,480 --> 00:00:32,000
at the Artificial Intelligence Conference, which was hosted by our friends at O'Reilly

6
00:00:32,000 --> 00:00:33,800
in Intel Nirvana.

7
00:00:33,800 --> 00:00:39,000
In addition to their support for the event itself, Intel Nirvana is also our sponsor for this

8
00:00:39,000 --> 00:00:41,560
series of podcasts from the event.

9
00:00:41,560 --> 00:00:45,920
A huge thanks to them for their continued support of this show.

10
00:00:45,920 --> 00:00:50,960
Make sure you check out my interview with Navine Rao, VP and GM of Intel's AI products

11
00:00:50,960 --> 00:00:56,280
group, and Scott Appland, director of Intel's developer network, which you can find at

12
00:00:56,280 --> 00:01:00,880
Twimbleai.com slash talk slash 51.

13
00:01:00,880 --> 00:01:06,800
At the AI conference, Intel Nirvana announced DevCloud, a cloud hosted hardware and software

14
00:01:06,800 --> 00:01:13,680
platform for learning, sandboxing and accelerating the development of AI solutions.

15
00:01:13,680 --> 00:01:19,920
The DevCloud will be available to 200,000 developers, researchers, academics and startups

16
00:01:19,920 --> 00:01:23,760
via the Intel Nirvana AI Academy this month.

17
00:01:23,760 --> 00:01:30,400
For more information on the DevCloud or the AI Academy, visit intelnervana.com slash

18
00:01:30,400 --> 00:01:32,480
DevCloud.

19
00:01:32,480 --> 00:01:35,360
Our first multi-person interview.

20
00:01:35,360 --> 00:01:41,120
I speak with Mo Patel, practice director of AI and deep learning and Laura Forelich,

21
00:01:41,120 --> 00:01:44,840
data scientist of Think Big Analytics.

22
00:01:44,840 --> 00:01:50,120
Mo and Laura joined me at the AI conference after their session on training vision models

23
00:01:50,120 --> 00:01:53,440
with public transportation data sets.

24
00:01:53,440 --> 00:01:57,320
We talked about this and a bunch of other interesting use cases they worked on involving

25
00:01:57,320 --> 00:02:02,440
image analysis and deep learning, including an assisted driving system.

26
00:02:02,440 --> 00:02:07,040
We also talked through the practical challenges faced when working on real machine learning

27
00:02:07,040 --> 00:02:11,480
problems by feature detection, data augmentation and training data.

28
00:02:11,480 --> 00:02:12,960
All right, everyone.

29
00:02:12,960 --> 00:02:18,520
I am here at the AI conference, and I am with a couple of guests this time.

30
00:02:18,520 --> 00:02:23,080
I am with Laura Forelich and Mo Patel with Think Big Analytics.

31
00:02:23,080 --> 00:02:28,440
In fact, Mo and I, we had an opportunity to meet at a conference a while back, and you

32
00:02:28,440 --> 00:02:32,960
kind of came up to me and introduced yourself as a listener of the podcast, which I think

33
00:02:32,960 --> 00:02:36,800
that was maybe the first time that ever happened to me, and I was like, excited out of my

34
00:02:36,800 --> 00:02:37,800
mind.

35
00:02:37,800 --> 00:02:44,200
Yeah, I remember you were actually talking to the people that chain the deep learning

36
00:02:44,200 --> 00:02:51,680
framework, and I was like, I recognize that voice, you know, it's a very recognizable

37
00:02:51,680 --> 00:02:52,680
voice.

38
00:02:52,680 --> 00:02:56,520
And we had an interesting conversation about the industrial AI stuff that I was working

39
00:02:56,520 --> 00:02:59,280
on at the time, and some of the work that you were doing there.

40
00:02:59,280 --> 00:03:04,960
So then when we saw that you and Laura were doing a presentation here at this conference

41
00:03:04,960 --> 00:03:07,520
in San Francisco, I thought, oh, we got to get you on the show.

42
00:03:07,520 --> 00:03:08,520
So welcome.

43
00:03:08,520 --> 00:03:09,520
Thank you.

44
00:03:09,520 --> 00:03:10,520
Thank you.

45
00:03:10,520 --> 00:03:15,520
This is actually the first time I'm doing an interview with two guests, so to be interesting

46
00:03:15,520 --> 00:03:18,960
to just how the kind of traffic management works.

47
00:03:18,960 --> 00:03:23,280
But why don't we start by having Laura introduce yourself?

48
00:03:23,280 --> 00:03:30,400
OK, so currently I'm a data scientist working with Think Big Analytics, as you just mentioned.

49
00:03:30,400 --> 00:03:33,120
So I work on all types of projects.

50
00:03:33,120 --> 00:03:37,360
Whenever a customer or company has a lot of data that they want to gain insight from

51
00:03:37,360 --> 00:03:41,840
to solve some use case, I can help them out.

52
00:03:41,840 --> 00:03:47,320
It doesn't have to be deep learning, like any sort of method that tries to reveal relevant

53
00:03:47,320 --> 00:03:52,960
patterns using some method that makes sense, given the use case and the data at hand,

54
00:03:52,960 --> 00:03:54,520
we'll go with that.

55
00:03:54,520 --> 00:04:01,480
Before joining Think Big, I spent half a year in a research group where they investigated

56
00:04:01,480 --> 00:04:05,160
something called non-specific effects of vaccines, which is basically vaccines turn

57
00:04:05,160 --> 00:04:09,680
out to affect the immune system in a general way, not just protecting against the targeted

58
00:04:09,680 --> 00:04:10,680
disease.

59
00:04:10,680 --> 00:04:12,880
So very interesting research.

60
00:04:12,880 --> 00:04:19,280
That I did a PhD at the Technical University of Denmark using various machine learning techniques

61
00:04:19,280 --> 00:04:21,880
to analyze brain activity data.

62
00:04:21,880 --> 00:04:22,880
Oh, wow.

63
00:04:22,880 --> 00:04:23,880
Yeah.

64
00:04:23,880 --> 00:04:25,320
So that's sort of my background.

65
00:04:25,320 --> 00:04:26,320
OK.

66
00:04:26,320 --> 00:04:27,320
Enemote?

67
00:04:27,320 --> 00:04:32,560
Yeah, I am currently the practice director for AI with Think Big Analytics, mostly looking

68
00:04:32,560 --> 00:04:34,600
at America's customers.

69
00:04:34,600 --> 00:04:41,520
And part of that is probably not as working on projects as much, but doing more of the

70
00:04:41,520 --> 00:04:45,560
proof-of-concept type work, so taking some of the most advanced things that are going

71
00:04:45,560 --> 00:04:50,000
out there and see if we can apply them to our clients' problems, so part of that.

72
00:04:50,000 --> 00:04:54,240
So there's a hands-on portion of it, but then there's also the dreaded power-pointing

73
00:04:54,240 --> 00:04:59,480
of things, character-version of that highly technical stuff, into things that people don't

74
00:04:59,480 --> 00:05:03,840
understand, which is a kind of a fascinating part of it, because I really love that trying

75
00:05:03,840 --> 00:05:07,400
to lower the barriers, because there's a lot of hyperion, I try to lower the barriers

76
00:05:07,400 --> 00:05:11,720
so that people can understand that this is not terminated or it's actually just math,

77
00:05:11,720 --> 00:05:12,720
right?

78
00:05:12,720 --> 00:05:18,000
So that's kind of my day-to-day, I really like doing that, and my background is I come

79
00:05:18,000 --> 00:05:23,720
from, if you look at data science, machine learning type things, I come from more of

80
00:05:23,720 --> 00:05:28,000
the computer science side, compared to people who come from statistics or maybe from some

81
00:05:28,000 --> 00:05:34,040
sciences, the hard sciences, or the years software engineering, into transitioning into more

82
00:05:34,040 --> 00:05:40,080
math type software engineering, and then into analytics, and yeah, oh, nice, nice.

83
00:05:40,080 --> 00:05:46,880
And so the two of you did a talk yesterday, it was actually a tutorial, yeah, what was

84
00:05:46,880 --> 00:05:48,520
the tutorial about?

85
00:05:48,520 --> 00:05:54,160
The tutorial yesterday was on image analysis using deep learning methods, in brief.

86
00:05:54,160 --> 00:06:00,560
So we had both the general introduction, making sure that everyone was on the same level,

87
00:06:00,560 --> 00:06:06,120
agreed on what is an image, what are pixels, what sorts of values are we dealing with,

88
00:06:06,120 --> 00:06:15,040
and so on and so forth like, and also going into what sorts of problems can we talk about

89
00:06:15,040 --> 00:06:20,400
in the image analysis, and then we went into more detail on one particular topic, object

90
00:06:20,400 --> 00:06:25,480
detection, and zoomed back out a bit in the end.

91
00:06:25,480 --> 00:06:29,920
So that's how I sort of see the whole framing of the talk, I don't know if you have anything

92
00:06:29,920 --> 00:06:30,920
to them.

93
00:06:30,920 --> 00:06:36,240
Yeah, absolutely, I think, but just kind of making sure that people are aware of the computer

94
00:06:36,240 --> 00:06:43,440
vision basics, and then diving into something that is fairly cutting edge, object detection,

95
00:06:43,440 --> 00:06:50,000
and a lot of applications out there, and not only the theoretical part, but also in a notebook

96
00:06:50,000 --> 00:06:54,400
style kind of layout saying, hey, this is how you can actually do it yourself as well,

97
00:06:54,400 --> 00:06:55,400
right?

98
00:06:55,400 --> 00:06:58,400
I felt that was very compelling, and then towards the end, talked about some of the challenges

99
00:06:58,400 --> 00:07:03,680
around training models, you know, it's like, we make it sound so easy, but to do it for

100
00:07:03,680 --> 00:07:08,280
real data, there are many challenges, and so we talked about that and we can go into

101
00:07:08,280 --> 00:07:09,280
that detail if you want.

102
00:07:09,280 --> 00:07:11,280
Yeah, what are some of the challenges?

103
00:07:11,280 --> 00:07:16,920
Yeah, absolutely, you know, for example, there was a paper that came out or the weekend,

104
00:07:16,920 --> 00:07:22,920
how this team trained image net data set in 24 minutes, right, and, and, I mean, you

105
00:07:22,920 --> 00:07:23,920
look a bit of a controversy.

106
00:07:23,920 --> 00:07:28,320
Yeah, yeah, it was, of course, yeah, because, you know, it's like, well, they used that

107
00:07:28,320 --> 00:07:32,920
headline was Alex Net, not ResNet, which is like more of the current state of the art,

108
00:07:32,920 --> 00:07:36,880
and, and what kind of hardware you use, and all sorts of different things, but that is

109
00:07:36,880 --> 00:07:40,960
exactly the type of thing, right, is that what are all the different parameters, like

110
00:07:40,960 --> 00:07:47,440
batch sizes and, and different processors and, and multi GPU, multi server, because most

111
00:07:47,440 --> 00:07:52,840
of the things you see the examples of tutorials, it's like, just run this code, right?

112
00:07:52,840 --> 00:07:57,360
But if you in production, even you have like a million images, and you need to make sure

113
00:07:57,360 --> 00:08:01,920
that this will train over like days and not weeks, you know, you may have to scale it,

114
00:08:01,920 --> 00:08:05,920
and how do you do the scaling, and those are all the challenges that's kind of like more

115
00:08:05,920 --> 00:08:10,600
engineering style challenges, but then there's also challenges around annotation, right?

116
00:08:10,600 --> 00:08:15,720
It's like, well, this is supervised learning, you have to annotate the data, and that could

117
00:08:15,720 --> 00:08:20,720
mean anything from, it's like, you know, simple classification, kind of easy, so to speak,

118
00:08:20,720 --> 00:08:21,720
right?

119
00:08:21,720 --> 00:08:23,520
But there's a picture, and there's a label, right?

120
00:08:23,520 --> 00:08:28,280
Now you, for object detection, there could be bounding boxes, so you draw squares around

121
00:08:28,280 --> 00:08:32,440
the objects like our balls, and, and, you know, like umbrella, and, and things like that,

122
00:08:32,440 --> 00:08:36,760
to make sure, and then label it that this is what the object is, and then the, even something

123
00:08:36,760 --> 00:08:40,680
more advanced, which is kind of drawing the polygons around the objects itself, which

124
00:08:40,680 --> 00:08:45,080
is the segmentation, kind of like the holy grail of, of, toward getting towards being able

125
00:08:45,080 --> 00:08:46,960
to do object detection.

126
00:08:46,960 --> 00:08:50,640
Many challenges in, and of course, you can try to do it internally or externally, we

127
00:08:50,640 --> 00:08:55,480
actually, for a project, we actually built a segmentation tool that allowed people to

128
00:08:55,480 --> 00:09:00,200
go ahead and draw boxes around cars, and pedestrians, and things like that.

129
00:09:00,200 --> 00:09:04,760
So, you know, as much as we talk about the deep learning parts, right, there's all sorts

130
00:09:04,760 --> 00:09:09,920
of many data engineering, data prep, data cleaning, things that were, have been around,

131
00:09:09,920 --> 00:09:12,560
and also the traditional data science for a while, right?

132
00:09:12,560 --> 00:09:15,280
So very much of, of, of, challenge.

133
00:09:15,280 --> 00:09:19,600
And so that's that a bit with the annotation tool that we built internally.

134
00:09:19,600 --> 00:09:24,880
We have that tool, and we were using it internally, but our team was just not large enough to

135
00:09:24,880 --> 00:09:30,320
annotate enough images quickly enough, so we had to both use that and go to an external

136
00:09:30,320 --> 00:09:35,600
company to help, get help from them to annotate all the images, and that was a lot of back and

137
00:09:35,600 --> 00:09:38,960
forth with them just defining their requirements.

138
00:09:38,960 --> 00:09:41,000
What sorts of things do we want labeled?

139
00:09:41,000 --> 00:09:46,080
How do we want them labeled, like, what's the smallest size of object that we require

140
00:09:46,080 --> 00:09:47,400
labels on?

141
00:09:47,400 --> 00:09:51,720
What do we do if it's partially obscured, like, if there's a car blocking another car?

142
00:09:51,720 --> 00:09:56,120
Those sorts of things, because you may have difficulties if you have a really small object,

143
00:09:56,120 --> 00:10:00,960
and you label it, then during the training phase, you'll be punished.

144
00:10:00,960 --> 00:10:04,560
The model will be punished if you don't detect that object, but it may actually not be

145
00:10:04,560 --> 00:10:09,480
very interesting to detect that object at test time, because small image, small objects

146
00:10:09,480 --> 00:10:14,160
are far away, so you may want to focus on objects that are closer.

147
00:10:14,160 --> 00:10:19,120
One way to handle that would be to put an extra label and small objects, saying, difficult,

148
00:10:19,120 --> 00:10:24,640
in that way you might handle such objects differently from normally labeled objects by not punishing

149
00:10:24,640 --> 00:10:28,720
the model if it doesn't detect them, but also not punishing the model if it does detect

150
00:10:28,720 --> 00:10:29,720
them.

151
00:10:29,720 --> 00:10:36,400
Yeah, I've had some interesting conversations with folks that specialize in labeling data

152
00:10:36,400 --> 00:10:42,040
for folks, and it really opened my eyes to just this process that you're describing.

153
00:10:42,040 --> 00:10:46,120
If you think of, hey, just label my data, but if you're talking about images, all different

154
00:10:46,120 --> 00:10:51,480
kinds of ways that you can do it, and they have direct impact on the types of, you know,

155
00:10:51,480 --> 00:10:54,560
not just the types of models that you're creating in their performance, but the cost of the

156
00:10:54,560 --> 00:10:55,560
labeling process.

157
00:10:55,560 --> 00:10:56,560
Yeah, exactly.

158
00:10:56,560 --> 00:11:01,640
So, this company that we worked with had this quite elaborate pricing scheme, I never

159
00:11:01,640 --> 00:11:05,440
really looked at the details of it, but if you increase the number of classes, you would

160
00:11:05,440 --> 00:11:08,600
sort of get an extra cost to the first classes as well.

161
00:11:08,600 --> 00:11:12,760
So you really had to consider, like, more maybe can we sort of have this external company

162
00:11:12,760 --> 00:11:17,680
to part of the labeling and then do some further post processing in our own tool, like

163
00:11:17,680 --> 00:11:18,680
a way.

164
00:11:18,680 --> 00:11:22,440
We needed a machine learning model to optimize the processing for vendor tool.

165
00:11:22,440 --> 00:11:23,440
Yeah, exactly.

166
00:11:23,440 --> 00:11:27,200
And, you know, there are some interesting projects around that, you know, there's that

167
00:11:27,200 --> 00:11:32,160
snorkel project from the Don Lab at Stanford, they're trying to do some stuff around kind

168
00:11:32,160 --> 00:11:37,240
of, you know, around the training data and building, building more training data, which

169
00:11:37,240 --> 00:11:42,000
just reminded me, another big one is a data augmentation, which is another thing that,

170
00:11:42,000 --> 00:11:47,360
you know, if your data doesn't have, I example, I gave, is that having the road data for when

171
00:11:47,360 --> 00:11:49,800
it's foggy versus when it's not, right?

172
00:11:49,800 --> 00:11:53,680
And what if we never capture the fog based, which is, it should be hard to do in San Francisco,

173
00:11:53,680 --> 00:11:58,520
but, you know, what it's so, so those are all the type of things that, so luckily, you

174
00:11:58,520 --> 00:12:02,960
know, at least what's great is that a lot of money, much of this knowledge has been encoded

175
00:12:02,960 --> 00:12:07,840
now where they're just in chaos, there's just a function for data augmentation, sure,

176
00:12:07,840 --> 00:12:11,440
maybe you could add your own, but there is that state of the art, like might as well just

177
00:12:11,440 --> 00:12:15,000
use that when you're training process, but these are all the things and it's like when

178
00:12:15,000 --> 00:12:17,960
you think about simply, it's like, yeah, just take the images, run it through a deep learning

179
00:12:17,960 --> 00:12:23,360
model and outcomes your, your trained model after you do all the deep learning things,

180
00:12:23,360 --> 00:12:27,840
like generalization and, and, and loss optimization, all those things, but then there's all these

181
00:12:27,840 --> 00:12:31,960
other things that you have to kind of worry about, yeah.

182
00:12:31,960 --> 00:12:35,800
And regarding data augmentation, even though people have made tools that you can sort of

183
00:12:35,800 --> 00:12:40,560
just use, you of course have to think about all of the data augmentation steps, do they

184
00:12:40,560 --> 00:12:41,560
make sense?

185
00:12:41,560 --> 00:12:46,680
For traffic scenes, do you really want to flip your images horizontally to teach the

186
00:12:46,680 --> 00:12:49,200
model that an upside down car is also a car?

187
00:12:49,200 --> 00:12:51,960
Well, maybe you do, but it depends on your use case, right?

188
00:12:51,960 --> 00:12:52,960
Right.

189
00:12:52,960 --> 00:12:53,960
That would depend on your use case.

190
00:12:53,960 --> 00:12:54,960
Yeah.

191
00:12:54,960 --> 00:12:55,960
I mentioned action movies, you know?

192
00:12:55,960 --> 00:12:56,960
Yeah.

193
00:12:56,960 --> 00:13:00,440
I'm going to get those upside down cars, yeah.

194
00:13:00,440 --> 00:13:06,480
And so these are, these are just some of the issues that you run into in the training phase

195
00:13:06,480 --> 00:13:08,880
of building and deploying a deep learning model.

196
00:13:08,880 --> 00:13:12,640
And then there's the whole, you know, how do you actually get this out into the wall to

197
00:13:12,640 --> 00:13:13,800
do inference?

198
00:13:13,800 --> 00:13:19,000
Like, are there, you know, best practices, tips, tools of the trade or, you know, tricks

199
00:13:19,000 --> 00:13:20,320
that you've come across for that?

200
00:13:20,320 --> 00:13:21,320
Yeah.

201
00:13:21,320 --> 00:13:26,520
I mean, actually, as much as, as much knowledge there's out there about the training aspects

202
00:13:26,520 --> 00:13:29,280
of it, there's actually not as much.

203
00:13:29,280 --> 00:13:33,920
And something that like even even traditional machine learning in production, I think we

204
00:13:33,920 --> 00:13:37,840
always, we heard this thing about data science and like, there's not a, you know, there's

205
00:13:37,840 --> 00:13:42,320
a lot of talk about it, but the in production is still not, you know, you could do a survey

206
00:13:42,320 --> 00:13:46,680
and you probably find that only maybe off all the people who actually say they do data science

207
00:13:46,680 --> 00:13:50,360
only 25 to 30% maybe actually put it into production.

208
00:13:50,360 --> 00:13:53,760
And then once you get to deep learning, that could, that number could start even going

209
00:13:53,760 --> 00:13:54,760
lower.

210
00:13:54,760 --> 00:13:58,520
And I think that's just because as you were saying that there are, there is a whole different

211
00:13:58,520 --> 00:14:02,040
set of challenges when you're trying to put models into production, right?

212
00:14:02,040 --> 00:14:03,960
So number one, where are you going to put it?

213
00:14:03,960 --> 00:14:07,240
Are you going to put it on some beefy servers in a data center?

214
00:14:07,240 --> 00:14:11,160
Then maybe you have lesser problems because you could take those big, gigabyte size models

215
00:14:11,160 --> 00:14:16,640
and, and stupid, Democrats, containers and kind of a lot of the traditional way of apps

216
00:14:16,640 --> 00:14:17,640
are served.

217
00:14:17,640 --> 00:14:20,120
But then you start talking about, well, we're going to do mobile.

218
00:14:20,120 --> 00:14:22,600
Well, that's, you know, that becomes another challenge.

219
00:14:22,600 --> 00:14:27,400
How do you compress the models, maybe quantization, you know, lowering the floating point and

220
00:14:27,400 --> 00:14:28,400
things like that?

221
00:14:28,400 --> 00:14:31,600
So, you know, that's another, and somebody actually asked this question, they're like,

222
00:14:31,600 --> 00:14:35,440
I was like, can I take this and put it into a card to, you know, do this?

223
00:14:35,440 --> 00:14:39,600
And we're like, there is a lot more that would go into it before you be able to do that.

224
00:14:39,600 --> 00:14:42,000
So the training is definitely challenging.

225
00:14:42,000 --> 00:14:46,600
But being able to serve the models at scale, brings in kind of all your traditional DevOps

226
00:14:46,600 --> 00:14:51,600
and data ops, kind of bringing it all in, model management, version control of the models

227
00:14:51,600 --> 00:14:55,960
and data lineage, traceability, everything that we've been discussing for any other data

228
00:14:55,960 --> 00:14:57,160
science type things.

229
00:14:57,160 --> 00:14:59,640
Those are all bring, they're back on the table, right?

230
00:14:59,640 --> 00:15:01,880
And how complex those can be.

231
00:15:01,880 --> 00:15:06,800
Are there emerging or accepted tools or open source projects for doing that kind of thing?

232
00:15:06,800 --> 00:15:11,640
I know that, you know, some of the folks, some of the vendors that focus on, you know,

233
00:15:11,640 --> 00:15:15,920
machine learning platforms, they've got some of that stuff built in or integrated into

234
00:15:15,920 --> 00:15:16,920
their tool set.

235
00:15:16,920 --> 00:15:22,520
But it's all like, you know, within that tool set, are there, you know, is there a kind

236
00:15:22,520 --> 00:15:27,480
of open source model management framework, for example, that's kind of emerging as a

237
00:15:27,480 --> 00:15:32,240
standard or does it have to be kind of custom cut for an individual use case?

238
00:15:32,240 --> 00:15:34,240
At least I haven't come across.

239
00:15:34,240 --> 00:15:39,280
I know we built one internally, yeah, from just a lot of our projects, right?

240
00:15:39,280 --> 00:15:43,560
Because we saw this need of model management and, you know, it's internally called Tink

241
00:15:43,560 --> 00:15:48,480
Deep, you know, for managing models, you know, it's maybe, maybe we'll become a

242
00:15:48,480 --> 00:15:52,280
open source, you know, you know, how these things go, you know, I think big we have tried

243
00:15:52,280 --> 00:15:56,080
to make things open source, for example, the Kylo Framework for data lakes, you know,

244
00:15:56,080 --> 00:16:00,240
so this could be another path on that roadmap, but, you know, there's a lot of polishing

245
00:16:00,240 --> 00:16:01,760
that needs to be done before it gets.

246
00:16:01,760 --> 00:16:05,360
So folks should reach out to you if they want to get their hands on this open source.

247
00:16:05,360 --> 00:16:10,560
Yeah, possibly, possibly, I'm not the operator, so I can definitely put in touch.

248
00:16:10,560 --> 00:16:14,200
But I have not come across, there are definitely some projects.

249
00:16:14,200 --> 00:16:19,080
Once again, the formally amp lab, the UCB rise now, right, and then, and then Stanford

250
00:16:19,080 --> 00:16:20,080
Don, right?

251
00:16:20,080 --> 00:16:25,440
They, they have, I can't remember the names of the projects of my top of my head, but

252
00:16:25,440 --> 00:16:31,160
I've seen that in, that's in their program agenda for being able to serve large scale machine

253
00:16:31,160 --> 00:16:34,960
learning models and you can consider deep learning into that, into that.

254
00:16:34,960 --> 00:16:39,360
And I will, you know, I'm not, not do a commercial plug, but that's actually one of the things

255
00:16:39,360 --> 00:16:43,400
that we are also focused on because when we look at things, it's like, yeah, training

256
00:16:43,400 --> 00:16:48,360
is, is there, but we work with traditional customers, enterprise customers who want to

257
00:16:48,360 --> 00:16:52,600
put all that stuff into production because all the investment, investment they make on

258
00:16:52,600 --> 00:16:57,320
AI or deep learning, data science is useless unless they actually put the models into production,

259
00:16:57,320 --> 00:16:58,320
right?

260
00:16:58,320 --> 00:17:02,920
So building the tooling around that, monitoring the models and all of those things are

261
00:17:02,920 --> 00:17:03,920
interpreglability.

262
00:17:03,920 --> 00:17:05,160
It's a huge part.

263
00:17:05,160 --> 00:17:10,240
All of those being able to kind of have one stop shop for that is very attractive.

264
00:17:10,240 --> 00:17:13,880
So there's commercial aspects to it.

265
00:17:13,880 --> 00:17:14,880
Interesting, interesting.

266
00:17:14,880 --> 00:17:20,360
So we, before we got started, we mentioned a few use cases that you would be able to

267
00:17:20,360 --> 00:17:24,840
kind of talk to us about and walk us through and the first one is one that you worked on

268
00:17:24,840 --> 00:17:29,120
Laura as a traffic project that you worked on with an automotive parts manufacturer and

269
00:17:29,120 --> 00:17:33,720
it sounds like this was in some ways an inspiration for the session, the tutorial that you did

270
00:17:33,720 --> 00:17:34,720
here.

271
00:17:34,720 --> 00:17:35,720
Can you tell us about them?

272
00:17:35,720 --> 00:17:41,480
So this project was for an assisted driving system.

273
00:17:41,480 --> 00:17:47,880
So that self-driving at all, we didn't want to go there, but just to help each other

274
00:17:47,880 --> 00:17:48,880
essentially.

275
00:17:48,880 --> 00:17:54,520
So the idea was that you have a car that's connected to the system and it's driving along

276
00:17:54,520 --> 00:17:59,920
like doing whatever it's doing, going where it's going and it has a camera recording whatever

277
00:17:59,920 --> 00:18:01,400
it passes.

278
00:18:01,400 --> 00:18:06,880
If it happens to pass a stop car that's on the road, it might be a good thing to be able

279
00:18:06,880 --> 00:18:10,840
to detect that, to tell other cars, hey, look out.

280
00:18:10,840 --> 00:18:15,160
If you're in this lane, you might want to change lanes already now, so you don't sort of

281
00:18:15,160 --> 00:18:18,200
get a surprise when you get to that stop car.

282
00:18:18,200 --> 00:18:24,240
You could even have that indicate this an accident or just congestion.

283
00:18:24,240 --> 00:18:30,600
So stop cars on the road is definitely something that you might want to tell other cars about.

284
00:18:30,600 --> 00:18:35,000
So the project was about trying to detect this and there are a lot of steps to this.

285
00:18:35,000 --> 00:18:40,000
First, a video is of course a lot of images that come in one at a time.

286
00:18:40,000 --> 00:18:45,800
So the first step was trying to look at, okay, so how well can we detect the objects

287
00:18:45,800 --> 00:18:51,400
and trying to compare the various object detection methods that were out there, see how fast

288
00:18:51,400 --> 00:18:57,200
are they, how accurate are they, all of these things and also try to get an idea of how

289
00:18:57,200 --> 00:18:59,440
might we be able to improve them.

290
00:18:59,440 --> 00:19:05,680
Then subsequently you have to be able to tell is this part of the picture part of the

291
00:19:05,680 --> 00:19:06,680
road?

292
00:19:06,680 --> 00:19:07,960
Or is it not part of the road?

293
00:19:07,960 --> 00:19:12,960
Because if it's not part of the road, if it's parking, you don't care so much whether

294
00:19:12,960 --> 00:19:16,640
there are stopped cars in that car's in there, so that's another thing.

295
00:19:16,640 --> 00:19:19,360
Thirdly, you'll want to be able to tell is the car moving.

296
00:19:19,360 --> 00:19:22,600
So one thing is detecting the cars in each image.

297
00:19:22,600 --> 00:19:28,040
Another thing is seeing, so this is the same car that I just saw in the previous image.

298
00:19:28,040 --> 00:19:33,880
And then estimating the distance, the difference in distance from when you saw it last, trying

299
00:19:33,880 --> 00:19:36,040
to estimate its speed.

300
00:19:36,040 --> 00:19:43,360
So this comes into object tracking, which is synced to from the research that we were

301
00:19:43,360 --> 00:19:49,720
able to do to be still quite immature compared to object detection.

302
00:19:49,720 --> 00:19:54,120
So far, the detection there are already a lot of methods, a lot of research out there.

303
00:19:54,120 --> 00:19:58,840
For object tracking, it seemed to be less solved.

304
00:19:58,840 --> 00:20:01,040
So we spent some time looking into that.

305
00:20:01,040 --> 00:20:08,000
And so in the end, we had a demo that was able to detect most cars and sort of give an

306
00:20:08,000 --> 00:20:11,960
estimate of is it moving, how fast is it moving?

307
00:20:11,960 --> 00:20:14,200
And that was basically where we stopped.

308
00:20:14,200 --> 00:20:15,200
Okay.

309
00:20:15,200 --> 00:20:20,240
And were you exclusively trying to detect cars or other obstacles in the road?

310
00:20:20,240 --> 00:20:25,040
So we did want to detect other objects in the start of the practice as well, turned out

311
00:20:25,040 --> 00:20:29,120
that there were some difficulties with that because in traffic data sets, you tend to have

312
00:20:29,120 --> 00:20:30,120
a lot of cars.

313
00:20:30,120 --> 00:20:31,120
Right?

314
00:20:31,120 --> 00:20:33,040
You don't have as many people.

315
00:20:33,040 --> 00:20:34,160
You don't have as many bikes.

316
00:20:34,160 --> 00:20:36,120
You don't have as many buses.

317
00:20:36,120 --> 00:20:39,760
So your training data has a high imbalance.

318
00:20:39,760 --> 00:20:45,320
And that just makes it more difficult to learn those other classes that are not cars.

319
00:20:45,320 --> 00:20:52,080
So in the end, we ended up focusing more just the car part of it and not so much on detecting

320
00:20:52,080 --> 00:20:55,120
all the other classes that we were initially interested in.

321
00:20:55,120 --> 00:20:56,120
Okay.

322
00:20:56,120 --> 00:20:57,120
Interesting.

323
00:20:57,120 --> 00:21:02,400
So you mentioned the object detection methods that you came across.

324
00:21:02,400 --> 00:21:09,160
Can you kind of summarize the state of object detection and what are the main methods and

325
00:21:09,160 --> 00:21:12,240
what you found as you compared them one to the other?

326
00:21:12,240 --> 00:21:17,880
So the methods that we looked into most were the ones that were quite recent at the time

327
00:21:17,880 --> 00:21:22,160
of the project, which was taking the beginning of this year.

328
00:21:22,160 --> 00:21:26,640
So at that time, there were a lot of what's referred to as single shot methods.

329
00:21:26,640 --> 00:21:31,600
So you have two versions of one called YoLiLook1s, YoLo.

330
00:21:31,600 --> 00:21:35,160
There's one called single shot multi-box detector.

331
00:21:35,160 --> 00:21:41,160
And what these methods have in common is that they just look at the image once.

332
00:21:41,160 --> 00:21:44,280
So you'll take the image that you're trying to analyze and pass it through the model

333
00:21:44,280 --> 00:21:46,400
once to extract features.

334
00:21:46,400 --> 00:21:50,120
And then based on those features, you'll predict the coordinates of the bounding box as

335
00:21:50,120 --> 00:21:53,680
well as the class of the object within the bounding box.

336
00:21:53,680 --> 00:21:58,360
And you'll do that for a bunch of predefined boxes on the image.

337
00:21:58,360 --> 00:22:04,280
So before like seeing the image, you'll already have to find a large number of what's called

338
00:22:04,280 --> 00:22:08,160
prior boxes or default boxes, their various names.

339
00:22:08,160 --> 00:22:13,920
So for one particular method, it's around 7,300 prior boxes.

340
00:22:13,920 --> 00:22:20,000
For each of these boxes, you give a prediction of the class that it might contain and a

341
00:22:20,000 --> 00:22:24,480
correction to the predefined coordinates to match the object better.

342
00:22:24,480 --> 00:22:29,080
And that's sort of the general theme for these for these single shot methods.

343
00:22:29,080 --> 00:22:30,080
Okay.

344
00:22:30,080 --> 00:22:36,240
Is that they generally they'll predefined some large set of boxes and then detect objects

345
00:22:36,240 --> 00:22:37,720
relative to those boxes?

346
00:22:37,720 --> 00:22:38,720
Yeah.

347
00:22:38,720 --> 00:22:39,720
Exactly.

348
00:22:39,720 --> 00:22:40,720
Okay.

349
00:22:40,720 --> 00:22:41,720
Interesting.

350
00:22:41,720 --> 00:22:47,360
And then on the object tracking side, what was the method that you found and how did you,

351
00:22:47,360 --> 00:22:49,880
what was your experience with it, how did it perform?

352
00:22:49,880 --> 00:22:52,320
So we ended up using a heuristic approach.

353
00:22:52,320 --> 00:22:57,800
So basically looking at the detected objects and a number of frames, I think we ended up

354
00:22:57,800 --> 00:23:01,760
with Iran looking back at the past 20 frames.

355
00:23:01,760 --> 00:23:07,480
Basically trying to match the current car that we're looking at to the car in the previous

356
00:23:07,480 --> 00:23:13,800
images that matches the color of the best and has the closest Euclidean distance and those

357
00:23:13,800 --> 00:23:17,760
sorts of heuristics that turned out to work pretty well.

358
00:23:17,760 --> 00:23:18,760
Okay.

359
00:23:18,760 --> 00:23:22,960
And you mentioned kind of doing a scan of the literature.

360
00:23:22,960 --> 00:23:27,720
Was that one of the methods that you found and the researcher, were you not able to get

361
00:23:27,720 --> 00:23:29,320
any of that stuff to work while?

362
00:23:29,320 --> 00:23:30,320
Yeah, exactly.

363
00:23:30,320 --> 00:23:35,320
So the methods that we found and tried out, we spent quite a while trying to get them

364
00:23:35,320 --> 00:23:37,480
to work and didn't really work out.

365
00:23:37,480 --> 00:23:42,280
So in the end, we just thought, okay, let's try heuristically see how it works.

366
00:23:42,280 --> 00:23:43,960
And it ended up working pretty well.

367
00:23:43,960 --> 00:23:48,040
So then in the interest of time, we went with that.

368
00:23:48,040 --> 00:23:52,560
And of course, we're hoping to get some of the more advanced methods to work in the future.

369
00:23:52,560 --> 00:23:58,440
But the heuristic approach turned out to really give quite good results.

370
00:23:58,440 --> 00:24:02,160
Which is also an important lesson for folks that actually have problems to solve.

371
00:24:02,160 --> 00:24:03,160
Yeah.

372
00:24:03,160 --> 00:24:04,160
Yeah.

373
00:24:04,160 --> 00:24:10,760
So I was observing that project mostly and of course, as you were just saying, for

374
00:24:10,760 --> 00:24:16,720
an outsider, I was like, oh, this is clearly, you need to use the Eurusing Conventional

375
00:24:16,720 --> 00:24:22,360
Networks, but then use recurrent on top of that because you're trying to track something

376
00:24:22,360 --> 00:24:26,720
and then maybe do the predictions for future frames and things of that sort.

377
00:24:26,720 --> 00:24:31,880
And that was the kind of the common, and actually, of course, that's what I searched for.

378
00:24:31,880 --> 00:24:35,000
There is somebody who was working on a recurrent yolo, right?

379
00:24:35,000 --> 00:24:36,000
We did try that, actually.

380
00:24:36,000 --> 00:24:40,040
That was what it means we tried, and yeah, it didn't work, and that's what we mean.

381
00:24:40,040 --> 00:24:44,720
That maybe, you know, this is something that will, as more people, experiment and it will

382
00:24:44,720 --> 00:24:45,720
start evolving.

383
00:24:45,720 --> 00:24:49,400
And because object tracking is another great area for computer vision.

384
00:24:49,400 --> 00:24:55,680
That's a big challenge for folks that are implementing this stuff like in real use cases

385
00:24:55,680 --> 00:25:00,600
is that, you know, I've heard it described and repeated it as kind of overfitting on

386
00:25:00,600 --> 00:25:01,600
a data set, right?

387
00:25:01,600 --> 00:25:04,240
Like, hey, this works great for MSNet, right?

388
00:25:04,240 --> 00:25:06,800
But, you know, for another data set, it doesn't.

389
00:25:06,800 --> 00:25:09,400
It's hard to reproduce the results.

390
00:25:09,400 --> 00:25:11,360
And that's actually another issue that we ran into.

391
00:25:11,360 --> 00:25:16,600
So we took this pre-trained model that someone had under GitHub repo just to see how it worked

392
00:25:16,600 --> 00:25:17,920
and it didn't detect anything.

393
00:25:17,920 --> 00:25:22,840
So this was a sanitation model, and we wanted it to detect roads, and it just didn't detect

394
00:25:22,840 --> 00:25:23,840
anything.

395
00:25:23,840 --> 00:25:27,280
And, of course, in our images, we had a lot of roads because this was a traffic data

396
00:25:27,280 --> 00:25:28,280
set.

397
00:25:28,280 --> 00:25:32,200
And we were like, why is this, and one of the team members wrote the author, and he was

398
00:25:32,200 --> 00:25:37,360
like, oh, well, that's because it didn't do data augmentation, because I wanted to improve

399
00:25:37,360 --> 00:25:42,840
the performance as much as possible to the data set that I'm submitting this entry to.

400
00:25:42,840 --> 00:25:48,440
So this was a competition, and he was just optimizing to these lighting conditions and so

401
00:25:48,440 --> 00:25:50,760
on that the data set had.

402
00:25:50,760 --> 00:25:57,720
So when we retrained the model with data augmentation, it was actually able to detect

403
00:25:57,720 --> 00:26:02,160
a lot more road, even we didn't add any data, we just used data augmentation.

404
00:26:02,160 --> 00:26:04,840
And what is data augmentation doing in this process?

405
00:26:04,840 --> 00:26:09,520
So I think some of the parameters that we tuned in this case was suggesting the brightness

406
00:26:09,520 --> 00:26:11,200
of the training images.

407
00:26:11,200 --> 00:26:17,760
So like we had the original training images that this guy had trained on, but then we added

408
00:26:17,760 --> 00:26:22,760
the same images, but with different levels of brightness and other things to the training

409
00:26:22,760 --> 00:26:23,760
set.

410
00:26:23,760 --> 00:26:30,600
So essentially to deal with things like glare, nighttime, twilight, and all sorts of other

411
00:26:30,600 --> 00:26:32,720
lighting type situations, right?

412
00:26:32,720 --> 00:26:38,400
So just do a bunch of different transformations on the image to adjust the brightness by

413
00:26:38,400 --> 00:26:42,600
a few plus minus a few stops, or maybe apply some cool Instagram filters.

414
00:26:42,600 --> 00:26:43,600
There you go.

415
00:26:43,600 --> 00:26:48,760
Actually, so what's great, once again, I love this field and everything people are doing

416
00:26:48,760 --> 00:26:54,560
because there is a paper around this topic of data augmentation and best practices.

417
00:26:54,560 --> 00:26:59,240
And much of has been codified in Keras and some of the other computer vision libraries.

418
00:26:59,240 --> 00:27:02,000
So you don't have to do imagination.

419
00:27:02,000 --> 00:27:08,560
It's like, let's just apply this best-in-class data augmentation and then we'll just see

420
00:27:08,560 --> 00:27:09,560
if it works.

421
00:27:09,560 --> 00:27:13,040
Of course, if it doesn't, then you may have to go inside and tweak some things.

422
00:27:13,040 --> 00:27:14,040
Yeah.

423
00:27:14,040 --> 00:27:15,040
Okay.

424
00:27:15,040 --> 00:27:16,040
Awesome.

425
00:27:16,040 --> 00:27:17,040
Anything else on that project?

426
00:27:17,040 --> 00:27:19,640
I can think of right now.

427
00:27:19,640 --> 00:27:20,640
Yeah.

428
00:27:20,640 --> 00:27:31,040
I think another thing from just my observations was that, you know, everybody has their local

429
00:27:31,040 --> 00:27:32,040
perspective, right?

430
00:27:32,040 --> 00:27:39,280
And we have a kind of a U.S.-based, U.S. centric viewpoint on traffic and driving.

431
00:27:39,280 --> 00:27:43,840
And I think there's just a different set of things in countries, right?

432
00:27:43,840 --> 00:27:47,360
And one actually, one good example of that is traffic science, right?

433
00:27:47,360 --> 00:27:51,920
You know, like a stop sign is, you know, the concept is somewhat universal, but it is

434
00:27:51,920 --> 00:27:53,320
different in other countries.

435
00:27:53,320 --> 00:27:56,680
So these are the type of things that you heard or account for if you're trying to do more

436
00:27:56,680 --> 00:27:59,920
like sign detection or other types of things.

437
00:27:59,920 --> 00:28:00,920
Yeah.

438
00:28:00,920 --> 00:28:01,920
Excellent.

439
00:28:01,920 --> 00:28:02,920
Excellent.

440
00:28:02,920 --> 00:28:07,400
So you mentioned a project called Lost and Found that was for a logistics company?

441
00:28:07,400 --> 00:28:08,400
Yeah.

442
00:28:08,400 --> 00:28:09,400
Yeah.

443
00:28:09,400 --> 00:28:13,080
And that one, you know, as much as this kind of object detection type things, that one

444
00:28:13,080 --> 00:28:15,520
had a little bit of a different type of challenge.

445
00:28:15,520 --> 00:28:19,240
And that is that it's the type of thing that you were trying to find, right?

446
00:28:19,240 --> 00:28:24,320
So it's like, imagine your shipping packages and then, you know, somehow the package loses

447
00:28:24,320 --> 00:28:27,160
it's tracking label drips off or box break.

448
00:28:27,160 --> 00:28:30,480
And then so this company finds the item and that's like, okay, what is this?

449
00:28:30,480 --> 00:28:32,760
Because a lot of times it's not really clearly.

450
00:28:32,760 --> 00:28:37,840
Or you as a customer will call and say, I'm missing like, you know, a brown pair of shoes,

451
00:28:37,840 --> 00:28:41,040
you know, but this isn't this, you know, and somebody's manually going through all the

452
00:28:41,040 --> 00:28:42,640
stuff to find it, right?

453
00:28:42,640 --> 00:28:44,400
And just, yeah, it's a very tedious process.

454
00:28:44,400 --> 00:28:49,920
And so how do you build a system that could give you like, you know, based on some description?

455
00:28:49,920 --> 00:28:53,040
And I know Google image search is this great, but, you know, we don't have, you know,

456
00:28:53,040 --> 00:28:54,040
it's not available.

457
00:28:54,040 --> 00:28:58,200
It's not available as API even, you know, Google is not giving it to everybody.

458
00:28:58,200 --> 00:29:02,800
And so there's some cloud APIs, but still not this, the point I'm trying to make is that

459
00:29:02,800 --> 00:29:06,960
the universe of items you could lose is infinite, right?

460
00:29:06,960 --> 00:29:09,800
It's not like a 10 class, 90 class, 9000 class.

461
00:29:09,800 --> 00:29:10,800
It's like infinite.

462
00:29:10,800 --> 00:29:15,600
So doing object detection model that will say, oh, we'll just be, we'll just detect the

463
00:29:15,600 --> 00:29:19,080
label of the item and we'll just be able to find it.

464
00:29:19,080 --> 00:29:25,760
So the approach was a little bit of a combination of transfer learning and feature matching as

465
00:29:25,760 --> 00:29:28,760
opposed to like feature detection, feature engineering, feature learning.

466
00:29:28,760 --> 00:29:33,360
So you know, one thing that customers do when they ask the question is they actually

467
00:29:33,360 --> 00:29:37,640
could provide a photo from the internet or they may actually have the item.

468
00:29:37,640 --> 00:29:42,240
And you know, this all sounds like probably somewhat easy for commercial items, right?

469
00:29:42,240 --> 00:29:46,960
But if you think about industrial items or niche things or collectibles and stuff like

470
00:29:46,960 --> 00:29:51,600
that, that's where you really start getting into the problems finding these items.

471
00:29:51,600 --> 00:29:55,080
Certainly, you're not going to have them just sitting around in your training data.

472
00:29:55,080 --> 00:29:56,080
Yeah, yeah.

473
00:29:56,080 --> 00:30:00,040
The way to kind of tackle this problem, it's like an image search problem, right?

474
00:30:00,040 --> 00:30:05,080
And previously, previous generation techniques were doing, you know, a lot of the handcrafted

475
00:30:05,080 --> 00:30:12,040
features, there are algorithms like SIFT, Surf and Orb and some of these previous generation

476
00:30:12,040 --> 00:30:19,640
feature detection algorithms, I believe if you open SIFT, yeah, SIFT, SURF and ORB, these

477
00:30:19,640 --> 00:30:25,480
are all acronyms for feature detection in previous generation computer vision.

478
00:30:25,480 --> 00:30:29,320
Matter of fact, I think, and you know, of course, I don't know the details, but when I look

479
00:30:29,320 --> 00:30:34,160
at it, the Amazon app, when you open up the visual search, I think they're not using

480
00:30:34,160 --> 00:30:35,160
deep learning.

481
00:30:35,160 --> 00:30:38,840
They're using that previous generation because of the dots it's showing.

482
00:30:38,840 --> 00:30:42,920
And based on just my knowledge, that's exactly how it works.

483
00:30:42,920 --> 00:30:47,600
So I don't know if somebody, maybe somebody from Amazon can verify or maybe not, they probably

484
00:30:47,600 --> 00:30:48,600
don't want to.

485
00:30:48,600 --> 00:30:52,440
But yeah, so we were like, well, we don't, those, one of them I forget which one is actually

486
00:30:52,440 --> 00:30:56,840
proprietary, so we can't use it, you know, without getting a license and all sorts of challenges

487
00:30:56,840 --> 00:30:57,840
like that.

488
00:30:57,840 --> 00:30:58,840
And we have deep learning now.

489
00:30:58,840 --> 00:31:03,240
So being able to extract using some of the straight up state of the art models such

490
00:31:03,240 --> 00:31:07,640
as ResNet or Inception, and you know, it's really thinking about this problem.

491
00:31:07,640 --> 00:31:10,640
It's like, well, what are those models doing, right?

492
00:31:10,640 --> 00:31:15,320
You have high level, high dimensional data images.

493
00:31:15,320 --> 00:31:19,880
And the point of generalization is to come up with low level features that you can generalize

494
00:31:19,880 --> 00:31:25,240
so that it will work on not just that data on much wider data.

495
00:31:25,240 --> 00:31:31,280
So well, why don't we just try to take our target and the source and essentially extract

496
00:31:31,280 --> 00:31:34,880
those low level features and create a feature store, right?

497
00:31:34,880 --> 00:31:39,120
So the next time you have a search for something, you say, okay, let me, it's like, it's almost

498
00:31:39,120 --> 00:31:42,080
like fingerprint matching type, if that's one way to think about it, right?

499
00:31:42,080 --> 00:31:45,160
It's like creating the fingerprint of the search.

500
00:31:45,160 --> 00:31:49,400
And then we have the entire database of fingerprints and you just say, okay, find the one that's

501
00:31:49,400 --> 00:31:50,400
the closest match.

502
00:31:50,400 --> 00:31:54,320
And we didn't have to get it 100% right because there was a human in the loop that somebody

503
00:31:54,320 --> 00:31:57,800
would say, okay, all right, I can tell between these five images that this is the one,

504
00:31:57,800 --> 00:31:58,800
right?

505
00:31:58,800 --> 00:32:04,000
Find your features a priori or where the, the training process.

506
00:32:04,000 --> 00:32:06,200
Yeah, we just use, we didn't do any training.

507
00:32:06,200 --> 00:32:10,280
We just use the pre-trained model, for example, ResNet or, or inception.

508
00:32:10,280 --> 00:32:13,800
We removed some of the, some of the classification layers because we weren't interested in the

509
00:32:13,800 --> 00:32:14,800
classification, right?

510
00:32:14,800 --> 00:32:18,640
Because if you look at the learning model, that's what the lower layers are doing.

511
00:32:18,640 --> 00:32:22,600
It's eventually, after the features are, you get to the low level, you then do a, you

512
00:32:22,600 --> 00:32:24,560
do your classic classification.

513
00:32:24,560 --> 00:32:26,520
And then, so we said, we're not interested in that.

514
00:32:26,520 --> 00:32:30,840
Let's freeze the model at certain level and then then see what the features are coming

515
00:32:30,840 --> 00:32:32,240
out of that.

516
00:32:32,240 --> 00:32:35,960
Store those and then let's do the same thing for the search candidate.

517
00:32:35,960 --> 00:32:40,280
And then the object tracking, there's a lot of similarities as far as the Euclidean distance

518
00:32:40,280 --> 00:32:44,080
type thing where you're trying to make sure that it's the same car from the previous image

519
00:32:44,080 --> 00:32:45,240
to this image.

520
00:32:45,240 --> 00:32:49,400
And then, so once you extract the features, you try to do a distance and see how close,

521
00:32:49,400 --> 00:32:50,600
closely they match.

522
00:32:50,600 --> 00:32:53,960
And that's essentially what you're trying to do is that you, in this case, we were doing

523
00:32:53,960 --> 00:33:00,320
a cosine distance between both of the features, feature vectors, or the kind of the customers

524
00:33:00,320 --> 00:33:04,840
feature vector and then the entire database of images, objects that we have to find the

525
00:33:04,840 --> 00:33:05,840
closest ones.

526
00:33:05,840 --> 00:33:10,320
So that's kind of like, you know, in that cell, that's how that problem was solved.

527
00:33:10,320 --> 00:33:16,720
On that one, did you determine where you were going to freeze your network based on experimentation

528
00:33:16,720 --> 00:33:21,080
or was it more kind of intuitive, you know, this is where the classification starts, so

529
00:33:21,080 --> 00:33:22,440
we're just going to stop here.

530
00:33:22,440 --> 00:33:27,040
Yeah, so yeah, if you ever kind of dissect one of these models, it's all, you can read

531
00:33:27,040 --> 00:33:28,040
all the layers.

532
00:33:28,040 --> 00:33:32,560
And yeah, you can tell which layers is when the kind of the feature extraction stops and

533
00:33:32,560 --> 00:33:38,040
the classification starts typically around kind of densely connecting and softmax classifier.

534
00:33:38,040 --> 00:33:40,320
Those are the kind of the later, later stages.

535
00:33:40,320 --> 00:33:44,400
So once you start kind of stop your convolution layers, you know, that's when you can, that's

536
00:33:44,400 --> 00:33:45,400
when you can stop.

537
00:33:45,400 --> 00:33:50,400
And yeah, we, you know, we, so we try to experiment with like, like till the very end or somewhere

538
00:33:50,400 --> 00:33:54,480
in the middle, you know, because these models are also, the state of the art have 50 layers,

539
00:33:54,480 --> 00:33:55,720
you know, like many layers.

540
00:33:55,720 --> 00:33:59,640
So it's like, you know, because we were not really interested in doing the classification.

541
00:33:59,640 --> 00:34:05,920
So at what level of feature, raw features that, that our, our search works in a good performance,

542
00:34:05,920 --> 00:34:07,000
yeah, right?

543
00:34:07,000 --> 00:34:10,720
Because once again, like if you get to like, really low level, then our search results

544
00:34:10,720 --> 00:34:12,880
will be like all over the place, right?

545
00:34:12,880 --> 00:34:15,640
So we want to capture at some, some good level.

546
00:34:15,640 --> 00:34:21,800
So they're not a, not scientific way, it's very much was a trial and error to come up with

547
00:34:21,800 --> 00:34:23,960
where, where it was giving us the best results.

548
00:34:23,960 --> 00:34:28,640
So I was actually wondering just now, did you use the features from many layers at one,

549
00:34:28,640 --> 00:34:31,680
so did you pick just one layer and take the features from, from that?

550
00:34:31,680 --> 00:34:35,920
Yeah, after, after several layers, so like 25 or 30 layers, we said, okay, now let's see

551
00:34:35,920 --> 00:34:40,800
what the output of the images, you know, the feature vector and said, now this is the

552
00:34:40,800 --> 00:34:41,800
one we want to use.

553
00:34:41,800 --> 00:34:46,320
Yeah, I'm, I'm thinking inspired by these object detection methods that sense to use features

554
00:34:46,320 --> 00:34:51,120
from different layers to capture both large and small objects in the amic.

555
00:34:51,120 --> 00:34:55,920
But I guess it's not so important if you know that you have one object in the amic, and

556
00:34:55,920 --> 00:34:58,120
you're just trying to find that one object, right?

557
00:34:58,120 --> 00:35:03,120
Yeah, typically the, so, so what I didn't mention is that this company, when they get the

558
00:35:03,120 --> 00:35:06,840
item, they take photos of it, right, multiple angles and everything.

559
00:35:06,840 --> 00:35:12,240
So typically that's the only thing that's in there, once again, all classic problems still

560
00:35:12,240 --> 00:35:18,800
are there, like data cleaning and, and background removal and all sorts of things like that, yeah.

561
00:35:18,800 --> 00:35:21,520
Yeah, yeah, interesting, interesting.

562
00:35:21,520 --> 00:35:26,480
And you mentioned one more, which was a fraud detection app for a bank.

563
00:35:26,480 --> 00:35:30,360
Yeah, yeah, and, and did you want to talk about, I can also talk about it, you know, if

564
00:35:30,360 --> 00:35:34,360
you could start to talk, yeah, so I, I wasn't on the topic, I, I know about the project,

565
00:35:34,360 --> 00:35:38,680
yeah, I, I just felt like, because you, it's in Denmark, right?

566
00:35:38,680 --> 00:35:44,760
And, and, yeah, is this, I think more details can be found, because it's the video off

567
00:35:44,760 --> 00:35:49,400
this project, there was a talk at the O'Reilly conference in New York in June, and it's available

568
00:35:49,400 --> 00:35:53,280
online, so those who are interested into this technique, I think what's really neat about

569
00:35:53,280 --> 00:35:56,960
this is that in the previous two cases, we talked about computer vision, right, which

570
00:35:56,960 --> 00:36:01,480
is kind of the, the cool factor, right, because everybody is excited about being, being able

571
00:36:01,480 --> 00:36:05,680
to do things with images, right? But now this is, here comes like fraud detection, which

572
00:36:05,680 --> 00:36:08,880
is, you know, through the common person, it's like, who cares, right?

573
00:36:08,880 --> 00:36:13,080
As long as my career card works, and nobody, you know, anybody who defros me, but banks,

574
00:36:13,080 --> 00:36:16,080
of course, are very much concerned with that, right?

575
00:36:16,080 --> 00:36:20,760
So, so in this case, you're like, well, I mean, so of course, fraud detection is not new,

576
00:36:20,760 --> 00:36:21,760
right?

577
00:36:21,760 --> 00:36:26,200
People have been doing this for decades, all sorts of things like human created, curated

578
00:36:26,200 --> 00:36:32,080
rules, right? It's like you swipe a card in San Francisco, and then you swipe it in, you

579
00:36:32,080 --> 00:36:34,840
know, Bombay, right? It's like, obviously, there is a problem, right? And so, you know,

580
00:36:34,840 --> 00:36:38,680
it's, you know, things like that, you can always have those handcrafted rules, but, you

581
00:36:38,680 --> 00:36:43,240
know, those can become like, you have 20,000 rules, and it's like, you know, it becomes

582
00:36:43,240 --> 00:36:47,040
a real cumbersome process, you start applying some traditional machine learning aspects to

583
00:36:47,040 --> 00:36:50,680
it, so you do a lot of feature engineering on the data to say, okay, these are the, these

584
00:36:50,680 --> 00:36:55,520
are the features that contribute to fraud, and we should flag for that, right? And then

585
00:36:55,520 --> 00:37:00,520
we're like, well, what are the ways you can improve upon this? Now, we have deep learning,

586
00:37:00,520 --> 00:37:06,240
feature learning, are there ways to actually improve upon the model? And so, you know, we

587
00:37:06,240 --> 00:37:10,160
said, well, let's try a couple of things. So, one of the things, and this is a classic

588
00:37:10,160 --> 00:37:14,200
by the object tracking example as well, like, so it's like, well, what is the first thing

589
00:37:14,200 --> 00:37:20,000
I would do? And most people with transactional data or sequential data, the go to technique

590
00:37:20,000 --> 00:37:25,000
is using some kind of a curl model, right? Where LSTM or something like that, right? So,

591
00:37:25,000 --> 00:37:28,440
that you have that recent history, and then you can be, you should be able to tell, oh,

592
00:37:28,440 --> 00:37:34,040
this is fraudulent, or it's about to be fraudulent. So, we tried that, and actually, there's the

593
00:37:34,040 --> 00:37:38,440
model result, if I recall correctly, there's a chart in that talk, which shows you all the

594
00:37:38,440 --> 00:37:42,840
different approaches. I think it was on par with the traditional machine learning, so not

595
00:37:42,840 --> 00:37:47,240
really, not promising, but then, like, well, creative way of, like, well, what if we could

596
00:37:47,240 --> 00:37:52,440
apply some of the vision-based techniques? So, it's, you know, vision, there are certain

597
00:37:52,440 --> 00:37:57,720
properties that are necessary for a conditional model to work, shift very invariant statistics

598
00:37:57,720 --> 00:38:02,040
and locally curated values. Those are the two things that famously, Yamakun tweeted

599
00:38:02,040 --> 00:38:07,240
out a few months ago, which I remember very well, right? I'm not coming from research, right?

600
00:38:07,240 --> 00:38:10,200
And those things really made a lot of sense to me, it's like, okay, all right, so those are

601
00:38:10,200 --> 00:38:14,640
the properties you need, because traditionally, the type of data we have, even in credit

602
00:38:14,640 --> 00:38:18,600
credit transaction, it's just some kind of a time series, you know, you have, you have

603
00:38:18,600 --> 00:38:24,200
amount and location and all sorts of things like that, but not like a picture, right? And,

604
00:38:24,200 --> 00:38:28,520
you know, this technique is detailed in, if you, you know, even five minutes of that talk,

605
00:38:28,520 --> 00:38:32,600
there is a couple of slides on it, which will, this, like, visually, it's very intuitive,

606
00:38:32,600 --> 00:38:38,840
is to come up with a feature map of the transactions, using some history. So, then idea is to create,

607
00:38:38,840 --> 00:38:44,840
like, a visual image of the recent transactions, and then feed it through the convolutional

608
00:38:44,840 --> 00:38:49,880
neural network to see if you could detect fraud. When you think about this, and this is something

609
00:38:49,880 --> 00:38:54,440
that I would, I would ponder others to think about, right, is that think about this as,

610
00:38:54,440 --> 00:38:59,480
as how we would do something like that, right? And one example I always talk about is that

611
00:38:59,480 --> 00:39:03,880
people who sit in, like, operations controls, right? And they're looking at those 50 screens,

612
00:39:03,880 --> 00:39:08,200
right? Or even traders when they look at, like, all these charts and all these things, right?

613
00:39:08,200 --> 00:39:12,520
You know, they're visually also trying to look for some changes in signals that will allow,

614
00:39:12,520 --> 00:39:17,960
say, oh, you know, I need to take some action. And the idea is very similar here, right? Is that

615
00:39:17,960 --> 00:39:22,280
if we could convert, I mean, there's data behind those charts, right? If we could somehow create

616
00:39:22,280 --> 00:39:26,840
the, and we just, like, we'll create charts out of the data, and then feed it through the,

617
00:39:26,840 --> 00:39:31,480
through the convolutional neural network, and then tell it what abnormal looks like, right?

618
00:39:31,480 --> 00:39:36,040
And then now I'll ask it to flag it. So, it's super interesting. I think those traders would be

619
00:39:36,040 --> 00:39:40,040
a lot less effective if they were looking at a spreadsheet. Yeah, well, and we know, we know that,

620
00:39:40,040 --> 00:39:44,680
right? It's like, yeah, it's like, I imagine if I gave you, like, a trend chart versus, like,

621
00:39:44,680 --> 00:39:48,920
all the data in a table, right? How quickly could you make a decision, right? Yeah, so

622
00:39:48,920 --> 00:39:54,440
put like that, it's super intuitive that a neural net would, you know, vision-focused

623
00:39:54,440 --> 00:39:58,200
neural net would be effective in solving these kinds of problems. Yeah, yeah. And, you know,

624
00:39:58,200 --> 00:40:02,920
it's a, it's a, it's a great, I love talking about this because it's a great example of,

625
00:40:02,920 --> 00:40:06,840
of applying some of these kind of what the research there and the progress that we are making

626
00:40:06,840 --> 00:40:11,560
in computer vision towards the problem that you were to think is in that realm, right? And you

627
00:40:11,560 --> 00:40:15,400
can talk about, I mean, you know, and when you start thinking about this way, there are many more

628
00:40:15,400 --> 00:40:20,040
things that open up, like, you know, anomaly detection and anything that you can, essentially,

629
00:40:20,040 --> 00:40:24,280
you can visualize, like, if you had like a heat map, right? So, yeah, we go up shore, we can generate

630
00:40:24,280 --> 00:40:29,320
a heat map of a lot of data, right? I think the big trick over there is that you have to be consistent

631
00:40:29,320 --> 00:40:34,280
in the way you feed the data because remember the properties of the common neural networks

632
00:40:34,280 --> 00:40:40,200
require that it's like, think of it, it's, it is an image. If you start shifting around the bits,

633
00:40:40,760 --> 00:40:44,760
the image will stop making sense, right? And that's what we are really banking on, that it is

634
00:40:44,760 --> 00:40:49,240
the image that could, that makes sense to us and we are trying to find those patterns. So,

635
00:40:49,240 --> 00:40:54,360
it is very important that you don't use another technique the next time around. You keep the feature

636
00:40:54,360 --> 00:41:00,200
map same for the, even throughout the production cycle, right? Not, not change it around, not change

637
00:41:00,200 --> 00:41:06,280
the sequence of transactions and things like that. Okay. Yeah, it's detailed much more in that talk

638
00:41:06,280 --> 00:41:12,440
if anybody's interested. We'll try to track down the line. Yeah. Yeah. Awesome. Well, these are all

639
00:41:12,440 --> 00:41:18,440
really, really interesting use cases. Thank you both for taking the time to kind of talk through

640
00:41:18,440 --> 00:41:24,360
them. Is there anything else that you wanted to mention? Either of you. Nothing comes to mind right

641
00:41:24,360 --> 00:41:29,080
now. Probably something built in like half an hour? Yeah, of course, of course. I'll take Sam's

642
00:41:29,080 --> 00:41:35,080
role and I'll ask you, what has your impression been in this, I guess, day or half or so far at the

643
00:41:35,080 --> 00:41:41,000
conference? Well, I have enjoyed it personally. I think there are a lot of really interesting

644
00:41:41,000 --> 00:41:45,880
talks and some that I would have liked to go to but that were just filled up by the time I got there.

645
00:41:45,880 --> 00:41:51,400
There was one on what to do if you don't have a lot of data because there are some ways around

646
00:41:51,400 --> 00:41:55,880
that I gather and something that a lot of people are starting to talk about as well as the use of

647
00:41:55,880 --> 00:42:01,080
unsupervised learning. I don't remember the details but I ran into this really interesting

648
00:42:01,080 --> 00:42:07,720
paper where they started so they wanted to train some kind of image analysis, object detection,

649
00:42:07,720 --> 00:42:13,320
something method. I don't recall the details. The insight that they had was that well, how do

650
00:42:13,320 --> 00:42:19,640
children learn to associate shapes that sort of belong together? So if a child sees a cat the first

651
00:42:19,640 --> 00:42:26,520
time, it may not know that the legs and the head and sort of everything goes together into being a cat.

652
00:42:26,520 --> 00:42:32,040
But then when the child sees the cat move a lot, it sort of realizes, okay, so this is the cat

653
00:42:32,040 --> 00:42:36,280
and these parts belong together. So this is one object. So this is essentially learning how to

654
00:42:36,280 --> 00:42:43,800
detect a whole object. And there is some research that shows that this is indeed how children learn

655
00:42:43,800 --> 00:42:50,520
to recognize shapes or people who regain sight. Like there is actually some research showing that

656
00:42:50,520 --> 00:42:57,560
this is how it might work for humans. So based on that insight, what these authors did was just

657
00:42:57,560 --> 00:43:06,360
show videos to a deep learning model and it did learn to recognize objects in this way.

658
00:43:06,360 --> 00:43:11,880
And then once, of course, once it learned how to recognize objects, then it's easier for it to

659
00:43:11,880 --> 00:43:18,760
learn that, okay, so this object is a cat. This object is a house. So that was a really cool

660
00:43:18,760 --> 00:43:24,600
application of using unsupervised learning to gain momentum. Yeah, like a little bit of a roundabout

661
00:43:24,600 --> 00:43:30,120
way of going around labeling aspect. Yeah, it's pretty neat. And I think that's a, it's great,

662
00:43:30,120 --> 00:43:35,080
you know, some of these research moving forward around, you know, because we've been talking about

663
00:43:35,080 --> 00:43:41,560
big data related, you know, machine learning, right, deep learning. But there is a lot of data

664
00:43:41,560 --> 00:43:46,040
class and balance is a huge, huge thing, right, just that there's some places where there's

665
00:43:46,040 --> 00:43:50,600
just not enough things to detect, you know, how do you handle those things? Yeah, so it's very

666
00:43:50,600 --> 00:43:55,960
fascinating. And I'll say that for me today, it was really fascinating, the keynote for Andrew

667
00:43:55,960 --> 00:44:01,640
Ing, right, kind of very non-traditional, right? You know, he wrote out the white words and I would

668
00:44:01,640 --> 00:44:06,040
recommend a lot of people to check out that because I really felt that, of course, you know, he's

669
00:44:06,040 --> 00:44:10,920
well-informed, suspected, and things like that. But the things that he highlighted, I really felt

670
00:44:10,920 --> 00:44:15,400
they really hit home because, you know, you know, you know, of course, people give great

671
00:44:15,400 --> 00:44:19,880
keynotes and I think they're good. But I think he really said, these are the real things that you

672
00:44:19,880 --> 00:44:26,040
need to do, you need to worry about or look at that are very relevant versus let's just try to

673
00:44:26,040 --> 00:44:30,040
write, you know, increase the hype curve further and further, right? I thought that was very,

674
00:44:30,040 --> 00:44:34,760
you know, that's something that I know I will kind of reference several times watching the video

675
00:44:34,760 --> 00:44:39,480
because he really brought some of the key points out there. Awesome. Awesome. Great. Well,

676
00:44:39,480 --> 00:44:43,960
thanks both of you. Thank you for having us come. Yeah, thank you. You know, long time listener

677
00:44:43,960 --> 00:44:49,320
and finally hearing my voice, you know, it's going to be weird. Thank you so much for having us.

678
00:44:49,320 --> 00:44:51,480
Awesome. Enjoy the rest of the conference. Thank you.

679
00:44:55,320 --> 00:45:01,560
All right, everyone. That's our show for today. Thanks so much for listening and of course,

680
00:45:01,560 --> 00:45:07,480
for your ongoing feedback and support. For more information on Mo and Laura or any of the other

681
00:45:07,480 --> 00:45:13,560
topics covered in this episode, head on over to twimlai.com slash talk slash 54.

682
00:45:14,280 --> 00:45:23,000
For the rest of this series, head over to twimlai.com slash AI SF 2017. And please, please, please,

683
00:45:23,000 --> 00:45:28,200
send us any questions or comments that you may have for us or our guests, be a Twitter,

684
00:45:28,200 --> 00:45:36,200
at twimlai or at Sam Charington or leave a comment on the show notes page. There are a ton of great

685
00:45:36,200 --> 00:45:41,640
conferences coming up through the end of the year to stay up to date on which events will be attending

686
00:45:41,640 --> 00:45:49,160
and hopefully to meet us there, check out our new events page at twimlai.com slash events

687
00:45:49,160 --> 00:46:03,800
twimlai.com slash events. Thanks again for listening and catch you next time.

