Hello and welcome to another episode of Tumel Talk, the podcast where I interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
This time around, we're doing something special here on the show and I'm really excited
to share it with you.
My producer and I spent some time in New York City this week, guests of the fine folks
from the future labs at NYU Tandon and FF Venture Capital, who are sponsors of this
week's show and the organizations behind the NYU FF VC AI Nexus Lab startup accelerator
program.
You might recall that I mentioned the future labs AI Summit last week, an event hosted
by the AI Nexus Lab to showcase the startups in their first batch, as well as the impressive
AI talent in the New York City ecosystem.
We attended this event on Wednesday afternoon and had an amazing time.
We got to give out a bunch of Twimmel stickers, meet some fans of the show, and check out
a great set of speakers.
I particularly enjoyed watching AI luminaries Gary Marcus and Jan LeCoon, both NYU faculty
and longtime friends, taking swipes at one another from the stage.
It was great.
I tweeted some of the highlights, which you can check out by looking me up on Twitter at
at Sam Charrington.
We had our mobile studio set up in a backstage dressing room and over the next few weeks we'll
be sharing some great discussions we had with some of the speakers at the event.
But first, we've got a monster of a show for you this week.
Backed from the future labs incubator space, we spoke with founders from the five companies
in the inaugural batch of the AI Nexus Lab program.
Hello Vera, Clustera, behold.ai, Cambrian intelligence, and Alpha Vertex.
These companies are doing some really interesting things and I think you'll enjoy hearing their
stories.
We also spent some time chatting with Steve Cuyin, the managing director of future labs,
but what makes the AI Nexus Lab program so special?
We're releasing all six of these interviews simultaneously for your binge listening
pleasure as Twilmultalk number 18, parts one through five.
Before we get started though, if you like what you hear, you might be interested to know
that applications are now open for the next AI Nexus Lab cohort.
The program gives companies $100,000 in investment capital, four months of customized programming
plus three additional months of free space, along with curated mentorship from leading
NYU academics and New York City investors, pro bono services from partners like lawyers
and designers, plus a paid four student fellow for the duration of the program.
Additionally, each company is partnered with an AI Nexus Lab corporate pilot partner,
which in the last cohort included Daimler, Quantopia, and Tough Mudder.
The application deadline for the program is coming up quickly.
It's May 3rd, and the cohort starts on July 10th.
For more details and to apply, visit nexuslab.ai or email hello at futurelabs.nyc with any
questions.
And now, on Tourship.
Hello everyone, this is Sam Charrington from this week in Machine Learning and AI, and
I am live here at the NYU Future Labs Accelerator Space, and I'll be talking to several of the
companies from the NYU AI Nexus Accelerator.
And the first up here is Hello Vera.
And I'm here with James Fan and Liang Liang Zhao.
Guys, why don't you say hi?
So tell us a little bit about Hello Vera.
Yes, Hello Vera.
We are applying artificial intelligence technology to the problem of customer service.
As you know, customer service is a major pain point for a lot of enterprises.
It requires a lot of human agents.
It's a very costly operation, often it costs $2 for a human agent to send you an email
and the $5 to answer a phone call.
With all the money spent, customer satisfaction actually is all the time low.
So last year, I went to talk to Liang Liang and they said, you know what, this is a problem
that artificial intelligence can help a lot.
You know what makes human hate to do this job is this is very repetitive.
If you look at the top customer service issues, they're almost always the same issues repeating
over and over.
So that's a perfect fit for AI because the repetitive nature makes it easy for AI to
learn to recognize the patterns in it.
And then there's also a lot of data in this domain.
Every company keeps track of the previously solved tickets and how human agents have solved
the tickets.
You know, data is the lifeline of artificial intelligence, right?
So this data, we can use machine learning technology to learn how to resolve it just
like a human would.
And what's better is, when you once you deploy, you have additional new data coming in.
So the AI technology for customer service will get better and better after it gets deployed.
So you're part of this accelerator now, how long have you been doing this?
We started last year, so we just about a year.
Okay.
And there have been a number of companies going after the customer support, the customer
support market, and trying to apply machine learning and AI, everything from startups to
you know, big companies in a space like Zendesk and others, what is unique about your
approach?
Right.
So if you look at the space in this, there are three type of companies.
There's one type that's doing essentially a frequently asked question search type of
things.
You know, that has a limited capabilities.
A second type is what we call agent assist, basically they provide tools to make human
agents to do their job more efficiently.
That's nice, but your human agent's still the bottleneck.
If your human agent go home, your customers won't get their questions answered until they
come back again.
The third type is these chat platforms that if your company have enough technology, techies
available, you can tell them to use the chat platform builders to build a chatbot.
One thing is very important to know is most of these chatbots are very script based.
So if you have scripts, then one thing you find out very quickly is once you deploy, customers
will never behave the way you imagine they were, they don't follow the script.
And then your chatbot just falls apart.
So our approach is where you're taking machine learning data driven approach.
So it's a lot more robust and as we have more and more data, it actually gets better
and better.
And our bot actually is autonomous.
It gives answers in real time, instantaneously.
Okay.
Can you tell me a little bit more about that?
I think most people who are doing AI and machine learning would characterize it as data
driven.
What specifically are you doing to collect and process this data to make your bot smarter?
Yes.
We have come up with a proprietary machine learning algorithm based on deep learning.
It's able to be a number of deep learning based approach, state or deep learning approaches,
a number of natural language processing tasks, as well as a number of benchmark data sets.
Our deep learning program is able to take advantage of all the data in customer service
domain, even starting with a small number of data, but its performance continues to improve
as the data gets more and more available.
How much data does a customer typically need to have to start off with?
We can start off with a very little data.
We can start off with just a dozen, two dozen instances with a dozen or two dozen question
answer pairs.
Okay.
And then we are able to start with running and produce answers.
When you're, so you start with your couple dozen question answer pairs, as you increase
the amount of data, do you also have to increase, are you also increasing labeled data or do
you have a way to do kind of online labeling?
Right.
We are actually taking advantage of users response by observing user response to infer the
label automatically and then we can able to take advantage of that.
Okay.
I mentioned a bunch of technologies, deep learning and LP and others, how does that all fit
together to allow you to do all this?
So this is actually, I guess it's fairly obvious to us because we've been working in this
space for a long time.
My background is in question answering.
Okay.
Not enough background is machine learning.
We made IBM several years ago as researchers where you used to be at IBM research in New York
or in Yorktown right here outside of New York.
So when I was at IBM, one of the things is, I was one of the main leads for this IBM Watson
question answering system that you may have seen on TV that we can change at jeopardy.
So I've been working in this question answering domain for a long time.
So one of the things for us, in order to solve customer service issues, you need to figure
out what customer wants, understand what customer wants and the delivered answer they were
looking for.
So in order to do that, you need to use a variety of natural language processing techniques
as well as using machine learning techniques to recognize, understand what customers needs
are and the figure of the right answer.
And so let's take one of those deep learning, for example, how exactly are you, does deep
learning play into what you do?
Yes, so deep learning is very nice in terms of what can take full advantage of all the
available data to deliver high performance.
And as I mentioned, you know, in customer service, you can actually get quite a bit data
compared to a lot of other natural language processing tasks.
Often you can have supervised data based on the prior approach and we are taking full
advantage using deep learning to deliver a better performance.
And so did you, did you base your deep learning models based on, you know, some of the contemporary
industry research, or did you develop them all from scratch?
What helped you get to where you are now?
We are researchers, so we are very familiar with the latest trends in the research community,
latest works.
The specific deep learning approach is what we have come up on our own.
Yeah, there are a lot of things we can see about deep learning, probably the time is not
limited.
Let's get started.
Yeah, just self-promoting.
I have a class teaching, I'm teaching a class at Columbia University on deep learning.
All the slides online, so welcome to our chat.
Okay.
Columbia class, what's the name of the class?
The deep learning for language, speech, and innovation.
And innovation?
Yeah, and I'm probing a little bit into how you guys are using deep learning because I
find that the listeners want, like, stuff that they can go and apply.
What would you tell folks that want to apply deep learning to building their own, you
know, speech models, and maybe even applying it to customer service?
What have you learned that someone else could go use?
Right, so I don't know about speech in particular, but for natural language processing, the key
issue is sparsity.
You tend to have a very high-dimensional sparse space you are working in.
And you want to use deep learning.
You want to reduce this dimension, high-dimension, often you have million dimension, highly-sparse
features.
You want to reduce it into a lower-dimension, dense feature space that can take advantage
of other aspects of deep learning easily.
And what are the features in the space that you guys are working in?
We use a variety of those features.
We actually tend to get extremely sparse, high-dimension features.
Typically, it's word, phrase, other linguistic features, etc., etc.
In any particular technique that you're using for the dimensionality reduction?
We are using our own proprietary projection technique.
Okay, for dimension reduction.
Okay.
And so how about on the NLP side of things?
Anything interesting you can share about your approach with NLP?
One thing I can mention is, in order to, a lot of time you have, you want to start, you
want to have a co-start, a co-start is very important.
What it means co-start is, if you have limited amount of data, you still want to use a deep
learning approach, a co-start can give you high performance even with limited amount
of data.
And so to achieve the ability to do a cold start, are you using transfer learning or are
there other techniques that you're taking advantage of?
Yeah, we, that's one of the core technology we have.
It's the proprietary machine learning technique that actually can do co-start very well.
Okay.
Okay.
Tell me where you are as a company and where the product is as a company, are you generally
available?
So our customers are large enterprises, usually we talk to customer service directors in
large enterprises, we apparently have two pilot partners we work with, and then we
previously licensed our technology to a Fortune 500 company for their in-house intelligent
agent development.
And what can you, what can you say about the kind of the process for going into a new
customer, when you, you know, they say, hey, this sounds great, we want to deploy this.
What does that look like?
What do they have to do?
Usually we make this process really simple, we, we go give them a demo, we, by the time
we talk to them, we already have a demo, using their data, they're publicly available data
up and running, so they can interact with an agent bot for their domain by the time we
walk in the door.
What does that mean?
They're publicly available data, most companies don't have like their support.
Oh, they do.
So think about it.
So for example, think about their tweets.
Oh, okay, they, they, a lot of companies provide customer service to the point, and that
data is public.
Okay.
And we can show how an agent behave on tweets based on their existing human agent tweets.
Okay.
So then we already have something by the time we walk in the door.
And of course, that's just a start, right?
We have, if we have more data from them, do deeper integration, our AI technology can
do a lot more.
Okay.
And then the AI will become smarter, smarter, when he learned to interact with customer
and agents.
How well does, are there any issues associated with transferring or, you know, build training
a model on social data and then sending it off to, to go after emails?
Does it transfer very well or other tricks that you need to do?
So, so there is a little bit, the language usage, if you will, right?
If you look at the way people write tweets, the English is slightly different from the way
they write emails.
And you can even say, if people are on the mobile platform, then they tend to use short
hands for words that you otherwise wouldn't say in, if you're typing out on a full-size
keyboard.
But other than that, yes, we will be able to handle this.
So you go in, you are able to demonstrate some value to them up front based on the social
interactions.
And then they say, let's do this and they want to pull in, you know, more of their proprietary
data.
Are they, are you able to hook up to their existing systems and what systems are those,
are those email, or are they something like a Zendesk or a support system, or...
Right.
So you have this seamless integration with existing ticketing systems they have, whether
that's Zendesk, Salesforce, or Oracle, or any other ticketing system.
So that means it's very easy for them to integrate with our system.
And then do they have to, do you have some kind of console that they use to label and tag
different interactions, or does the system do it all for them?
So we provide a dashboard which gives them a 30,000 feet overview of how things are going.
They can look at how many tickets are coming in, how many tickets are resolved, where the
tickets are coming from, et cetera, et cetera, and they can learn about what are the tickets
that stop being resolved, et cetera, et cetera.
And do you, I imagine that I'm thinking of like a, kind of, you have all these tickets
right, you have some that are being resolved, and are you showing them, is the system
able to figure out and display confidence levels, like, you know, we're pretty sure we
nail these, these, and not so sure.
How does that, is that just displayed on the dashboard?
Yeah.
So we, they can store by the confidence, they can store by the time, they can store
by a number of these criteria, they can do the filtering to, to run report, look at
the tickets.
There are a number of ways for them to, to, to check to run analytics on, on their system.
And then I would imagine, if you're doing this a scale, another thing that would be important
is, for the, the things that you don't, that you haven't been able to resolve correlating
them so that, you know, we've got, you know, a thousand things here that we had no ability
to help out with, but we think that, you know, these two hundred are all kind of about the
same thing.
Is, is that something that you guys, yeah, that, that's a great idea.
That's exactly the direction we are heading as well.
Okay.
Yeah.
Maybe you should work with that.
Can you give it to the other, what are the other things that, that, you know, on that
topic, what are the things that are, you know, either on your roadmap or more generally,
things that you think this space needs to evolve to be able to do in order to fully realize
the vision for customers?
Yeah.
So I think, I think we are in, in the right space.
Our claim is, we think this space that will see more and more issues automatically resolved
by AI.
Imagine 10 years from now, I will say, overwhelming majority of customer service requests will
be automatically responded immediately, only when you have rare cases that requires human
attention and you'll take a little bit longer from human to come back.
And that's, that's across multiple channels.
It's not just email, but also chat, social media, texting, etc., etc.
How did you, of all the things that you could have applied your backgrounds to, you know,
deep learning, NLP, all that stuff is super hot.
How did you come up with customer service?
So here's a story, how I thought it was a story, yes, that's always story, right?
I bought this CPU from New Egg and the New Egg has this price matching policy, right?
So the price dropped, so I called them, I was on hold and then I talked to the agent.
But that wasn't the first time I do this, I've done this before, this price matching
on New Egg before.
So I know exactly the set of questions they ask and exactly how this process works.
Okay.
So as I was going through this, I was, I was, I'll hold and I realized, you know, as annoying
as it is for me, that aging on the other side, he probably even more annoyed because every
day he's going through the same process over and over.
And that's something AI must be able to do.
So that's where I thought, hey, maybe I wanted to talk about, hey, maybe that's something
we should use AI to, to resolve, address this pain point.
Nice, nice.
Tell me a little bit about one of the things that companies that are, you know, marketing
AI technologies to lines of business like support, you know, have to grapple with this
issue of, are we, you know, replacing people, you know, augmenting people, you know, what
are the kinds of questions that your customers are asking and how do you help them think
through, you know, what the role of AI within, you know, with automation and these kinds
of environments?
Yeah.
So clients, their number one concern is customer satisfaction and our goals are aligned.
Our goal is to improve customer satisfaction.
If you look at the customer service, if you can get a 24 hour response time for email,
that's considered good.
And only less than half the company can achieve that goal.
By having AI there, we can reduce the response time significantly and improving the customer
satisfaction.
And from the agent point of view, what we're doing is actually making their jobs more interesting
instead of doing the same thing over and over, they get to do things different and more
difficult, more challenging customer service issues, making a meaningful job for those,
so can deliver customer satisfaction and customers.
Okay.
So the reason why the response times are so slow because they don't have enough and they
can't afford enough customer support people.
So if you can help them use those people more effectively, then it's a win-win for everybody.
Yeah.
Exactly.
Right.
Anything else you'd like to add or how can folks, you know, find you and learn more?
Well, check out our website, hellobearer.ai.
And if you're available, come to our demo date tomorrow Wednesday Wednesday.
Okay.
Awesome.
Well, thanks James.
Thanks, Dan Lam.
Great.
All right, everyone.
That's our show for today.
Once again, thanks so much for listening and for your continued support.
A huge, huge thanks to our sponsors this week.
Future Labs at NYU Tandon and FF Venture Capital.
Don't forget that the application deadline for the next batch of AI Nexus Lab companies
is coming up quickly.
Visit nexuslab.ai to learn more or apply or email hello at futurelabs.nyc with any questions.
And of course, don't forget to share your favorite quotes from this week's interviews to receive
a twimmel sticker.
We're starting to get pictures back from folks who are proudly displaying them on their
laptops and they look amazing.
You can get yours by sharing your favorite quote via the show notes page, via Twitter,
via our Facebook page, or via a comment on YouTube or SoundCloud.
The notes for this show will be up on twimmelai.com slash Nexus Lab where you'll find a playlist
with all of the individual interviews and links to all of the people, companies and resources
mentioned in the show.
Once again, thanks so much and catch you next time.
