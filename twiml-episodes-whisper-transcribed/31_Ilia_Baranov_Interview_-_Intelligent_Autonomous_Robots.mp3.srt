1
00:00:00,000 --> 00:00:16,400
Hello and welcome to another episode of Twimo Talk, the podcast why interview interesting

2
00:00:16,400 --> 00:00:21,560
people, doing interesting things and machine learning and artificial intelligence.

3
00:00:21,560 --> 00:00:25,200
I'm your host Sam Charrington.

4
00:00:25,200 --> 00:00:29,960
I've mentioned here on the podcast a couple of times that I'm keenly interested in industrial

5
00:00:29,960 --> 00:00:33,040
applications of machine learning and AI.

6
00:00:33,040 --> 00:00:37,360
I've come a long way in my research in this area and I'm very close to publishing a special

7
00:00:37,360 --> 00:00:38,960
report on the topic.

8
00:00:38,960 --> 00:00:42,280
If you're interested in learning more about this work when it's completed, I've put up

9
00:00:42,280 --> 00:00:46,560
a form at twimolayi.com slash industrial AI.

10
00:00:46,560 --> 00:00:51,080
Fill out that form and I'll let you know when the report is available.

11
00:00:51,080 --> 00:00:56,560
In conjunction with this work, we've got something really special to debut here on the podcast.

12
00:00:56,560 --> 00:01:01,520
For the next several weeks, I'll be interviewing some very interesting guests working on topics

13
00:01:01,520 --> 00:01:04,440
connected to industrial AI.

14
00:01:04,440 --> 00:01:08,720
We'll be discussing different application areas like manufacturing, warehouse automation

15
00:01:08,720 --> 00:01:14,480
and logistics and practice areas like robotics, reinforcement learning and simulation.

16
00:01:14,480 --> 00:01:18,360
We've been planning this for quite some time and we're very excited for you to hear what

17
00:01:18,360 --> 00:01:19,920
we've cooked up.

18
00:01:19,920 --> 00:01:25,200
Of course, as always, we love your comments, feedback and suggestions, which you can leave

19
00:01:25,200 --> 00:01:31,280
on the series page at twimolayi.com slash industrial AI.

20
00:01:31,280 --> 00:01:37,000
Our first guest in the industrial AI series is Ilya Baranov, engineering manager at Clear

21
00:01:37,000 --> 00:01:38,920
Path Robotics.

22
00:01:38,920 --> 00:01:43,000
Ilya is responsible for setting the engineering direction for all of Clear Path's research

23
00:01:43,000 --> 00:01:44,400
platforms.

24
00:01:44,400 --> 00:01:49,160
He likes to describe his role at the company as both enabling and preventing the robot

25
00:01:49,160 --> 00:01:50,160
revolution.

26
00:01:50,160 --> 00:01:55,960
He's a longtime contributor to the open source robotics community and RAS and open source

27
00:01:55,960 --> 00:01:58,400
robotic operating system.

28
00:01:58,400 --> 00:02:02,960
In our conversation, we cover a lot of ground, including what it really means to field autonomous

29
00:02:02,960 --> 00:02:08,280
robots, the use of autonomous robots and research and industrial environments, the different

30
00:02:08,280 --> 00:02:12,160
approaches and challenges to achieving autonomy and much more.

31
00:02:12,160 --> 00:02:16,000
This was a really fun interview and I'm excited to share it with you.

32
00:02:16,000 --> 00:02:21,000
Before we get started, I'd like to give a huge thank you to the team over at Banzai.

33
00:02:21,000 --> 00:02:26,440
Banzai, who is supporting this podcast series, as well as my forthcoming report, has been

34
00:02:26,440 --> 00:02:29,680
a big supporter of my research in this area.

35
00:02:29,680 --> 00:02:34,440
Banzai offers an AI platform that empowers enterprises to build and deploy intelligent

36
00:02:34,440 --> 00:02:35,440
systems.

37
00:02:35,440 --> 00:02:39,480
I've been following them since their initial launch just over a year ago when I'm at

38
00:02:39,480 --> 00:02:44,160
the founders at a conference and I've been very impressed with both the team and technology.

39
00:02:44,160 --> 00:02:49,440
If you're trying to build AI-powered applications, focus on optimizing and controlling the systems

40
00:02:49,440 --> 00:02:53,080
in your enterprise, you should take a look at what they're up to.

41
00:02:53,080 --> 00:02:57,600
They've got a really unique approach to building AI models that lets you use high-level code

42
00:02:57,600 --> 00:03:02,880
to model the real world concepts in your application, automatically generate train and evaluate

43
00:03:02,880 --> 00:03:07,400
low-level models for your projects, using technologies like deep learning and reinforcement

44
00:03:07,400 --> 00:03:13,560
learning, and easily integrate the models into your applications and systems using APIs.

45
00:03:13,560 --> 00:03:19,200
You can check them out at bions.ai and definitely tell them that you appreciate their support

46
00:03:19,200 --> 00:03:21,160
of the podcast.

47
00:03:21,160 --> 00:03:29,480
And now on to the show.

48
00:03:29,480 --> 00:03:36,000
All right, everyone, I am on the line with Ilya Baranov, who is an engineering manager

49
00:03:36,000 --> 00:03:41,800
with Clear Path Robotics, and I'm excited to have Ilya on to talk about the intersection

50
00:03:41,800 --> 00:03:45,920
between robotics and machine learning and AI.

51
00:03:45,920 --> 00:03:46,920
How are you doing?

52
00:03:46,920 --> 00:03:48,320
Oh, I'm doing great today.

53
00:03:48,320 --> 00:03:49,320
Thank you.

54
00:03:49,320 --> 00:03:50,320
Awesome, awesome.

55
00:03:50,320 --> 00:03:52,080
Why don't we start with a little bit of your background?

56
00:03:52,080 --> 00:03:56,360
Can you tell us a little bit about how you got to Clear Path?

57
00:03:56,360 --> 00:03:57,360
For sure.

58
00:03:57,360 --> 00:04:00,920
So I've always really liked robotics ever since a young age.

59
00:04:00,920 --> 00:04:08,440
I probably started out with Lego, as I'm sure most of us started it this way.

60
00:04:08,440 --> 00:04:13,880
And I really wanted to go to school at University of Waterloo due to their co-op program.

61
00:04:13,880 --> 00:04:18,320
So when I joined them in the first year, I joined their robotics team.

62
00:04:18,320 --> 00:04:23,560
And at the time, we had a pretty broad robotics team where the first years would do sort

63
00:04:23,560 --> 00:04:26,960
of small competitions with sumo robots and line following.

64
00:04:26,960 --> 00:04:30,880
And then the upper years would usually work towards their capstone project or final

65
00:04:30,880 --> 00:04:32,480
year design project.

66
00:04:32,480 --> 00:04:33,480
Okay.

67
00:04:33,480 --> 00:04:37,400
And so I really liked this one group that was doing a capstone project that was doing

68
00:04:37,400 --> 00:04:39,720
autonomous mind-sweeping.

69
00:04:39,720 --> 00:04:42,840
And so I asked to help them out instead of doing the first year stuff.

70
00:04:42,840 --> 00:04:48,120
Because by that point, I had gotten beyond the line following stuff.

71
00:04:48,120 --> 00:04:54,480
And so I ended up helping them out with their GPS solution to position their robot.

72
00:04:54,480 --> 00:04:57,480
And that team turned into Clear Path, essentially.

73
00:04:57,480 --> 00:04:58,480
Oh, wow.

74
00:04:58,480 --> 00:04:59,480
Okay.

75
00:04:59,480 --> 00:05:00,480
Yeah.

76
00:05:00,480 --> 00:05:01,480
So it's quite interesting.

77
00:05:01,480 --> 00:05:04,600
There's a lot of learning to do, even especially in the first year.

78
00:05:04,600 --> 00:05:08,040
One of the funny things that ended up happening is a little bit of the code and firmware

79
00:05:08,040 --> 00:05:14,200
that I wrote and Ryan Garry wrote made our robot go in circles whenever it'd get to its

80
00:05:14,200 --> 00:05:18,000
actual weight point that it was designated to go to.

81
00:05:18,000 --> 00:05:21,600
We didn't really have any good tolerance on our GPS goal.

82
00:05:21,600 --> 00:05:22,600
So it'd get there.

83
00:05:22,600 --> 00:05:26,240
And then GPS would drift a little bit and so chase it and GPS would drift a little more

84
00:05:26,240 --> 00:05:27,920
and it would chase it back.

85
00:05:27,920 --> 00:05:28,920
And so.

86
00:05:28,920 --> 00:05:30,680
Oh, wow.

87
00:05:30,680 --> 00:05:34,040
So yeah, that's a kind of funny thing that happens when you're trying to do this stuff

88
00:05:34,040 --> 00:05:35,040
in university.

89
00:05:35,040 --> 00:05:36,040
Uh-huh.

90
00:05:36,040 --> 00:05:42,160
Well, I think it would help folks understand a little bit more of the context of what we're

91
00:05:42,160 --> 00:05:43,160
talking about.

92
00:05:43,160 --> 00:05:47,800
If we go into a little bit of Clear Path, what is the company focused on?

93
00:05:47,800 --> 00:05:48,800
Yeah, for sure.

94
00:05:48,800 --> 00:05:53,600
So out of those kind of routes, the four founders decided that they would try to have

95
00:05:53,600 --> 00:05:56,800
a go at it and create robotics for research.

96
00:05:56,800 --> 00:06:01,720
But they actually started on the idea of can we take this mind-sweeping robot idea and

97
00:06:01,720 --> 00:06:03,360
actually apply it to the real world?

98
00:06:03,360 --> 00:06:09,040
And they were fairly surprised to find out that large defense industries didn't want

99
00:06:09,040 --> 00:06:14,720
to buy from four guys in a garage.

100
00:06:14,720 --> 00:06:18,840
So they had to kind of switch their idea and so they went with what they knew.

101
00:06:18,840 --> 00:06:23,040
They knew that they understood the kind of university level research application of

102
00:06:23,040 --> 00:06:24,040
robotics.

103
00:06:24,040 --> 00:06:28,240
They had talked to a lot of professors and so they decided to create platforms.

104
00:06:28,240 --> 00:06:32,800
So Clear Path really got started creating robotics platforms for research.

105
00:06:32,800 --> 00:06:33,800
Okay.

106
00:06:33,800 --> 00:06:38,360
So the idea being that if you're a researcher and you're trying to do some work outdoors

107
00:06:38,360 --> 00:06:44,320
or indoors, any kind of development for robotics, for positioning, or movement, or interaction,

108
00:06:44,320 --> 00:06:48,960
instead of spending the term, you and your grad student creating this robot, you would

109
00:06:48,960 --> 00:06:53,000
purchase one from us already integrated with the sensors that you wanted to use.

110
00:06:53,000 --> 00:06:54,000
Okay.

111
00:06:54,000 --> 00:06:55,000
Got it.

112
00:06:55,000 --> 00:06:56,000
Yeah.

113
00:06:56,000 --> 00:06:58,800
So this kind of platformed approach to research robots and especially our kind of niche

114
00:06:58,800 --> 00:07:03,760
that we found was the outdoor rugged market because there had been a lot of indoor ones

115
00:07:03,760 --> 00:07:08,640
like the pioneer from, sorry, I'm forgetting their name right now, but yeah, there

116
00:07:08,640 --> 00:07:13,720
been a few kind of indoor robots before but nobody had really done an outdoor robot platform

117
00:07:13,720 --> 00:07:14,720
at the time.

118
00:07:14,720 --> 00:07:15,720
Okay.

119
00:07:15,720 --> 00:07:22,400
When I look on the Clear Path site, there are, it's not just one or a couple of different

120
00:07:22,400 --> 00:07:23,400
types of robots.

121
00:07:23,400 --> 00:07:29,120
There are a bunch of different platforms, both kind of these rugged, ruggedized outdoor

122
00:07:29,120 --> 00:07:32,760
ones as well as some indoor ones.

123
00:07:32,760 --> 00:07:44,520
There's UAVs, there are ones for the, you know, sea, it's called USV, so sea vehicle.

124
00:07:44,520 --> 00:07:50,080
And there's even a video of one towing a plane, is that a real application of one of these

125
00:07:50,080 --> 00:07:51,080
robots?

126
00:07:51,080 --> 00:07:54,960
Not quite, actually, it's funny you should mention that.

127
00:07:54,960 --> 00:07:59,920
That was actually a fun shoot we did for the Discovery Channel, where we tried to find

128
00:07:59,920 --> 00:08:03,400
the limits of the towing capability of our grizzly platform.

129
00:08:03,400 --> 00:08:04,400
Okay.

130
00:08:04,400 --> 00:08:09,320
And by the time we had towed a fully fueled jet, pretty much up a little incline, you can't

131
00:08:09,320 --> 00:08:14,080
really see it in the video, but the actual tarmac there sloped.

132
00:08:14,080 --> 00:08:17,680
We couldn't really figure out what was the next big thing we could tell, so we got to

133
00:08:17,680 --> 00:08:18,680
stop there.

134
00:08:18,680 --> 00:08:19,680
Nice.

135
00:08:19,680 --> 00:08:20,680
Nice.

136
00:08:20,680 --> 00:08:21,680
I mean, it looks awesome.

137
00:08:21,680 --> 00:08:22,680
It's very impressive.

138
00:08:22,680 --> 00:08:23,680
Yeah.

139
00:08:23,680 --> 00:08:24,680
Yeah.

140
00:08:24,680 --> 00:08:25,680
It's a lot of fun.

141
00:08:25,680 --> 00:08:26,680
Definitely.

142
00:08:26,680 --> 00:08:27,680
Yeah.

143
00:08:27,680 --> 00:08:32,000
So the grizzly and the more modern version, the Wardhog is meant for outdoor heavy work.

144
00:08:32,000 --> 00:08:36,240
So agriculture and mining is really two of the places where we've seen a lot of interest

145
00:08:36,240 --> 00:08:37,240
there.

146
00:08:37,240 --> 00:08:38,240
Okay.

147
00:08:38,240 --> 00:08:41,680
So one, you know, it's funny, you could find these trivial sounding applications for

148
00:08:41,680 --> 00:08:42,680
these things.

149
00:08:42,680 --> 00:08:43,680
I have a real need.

150
00:08:43,680 --> 00:08:47,120
For example, we worked with a vineyard where they had a problem where they'd have birds

151
00:08:47,120 --> 00:08:49,200
come and eat the grapes constantly.

152
00:08:49,200 --> 00:08:51,400
And so there's two real solutions to this.

153
00:08:51,400 --> 00:08:54,880
One is you put a bird netting, which is crazy expensive because you have to cover vast

154
00:08:54,880 --> 00:08:58,040
fields with this fairly expensive mesh.

155
00:08:58,040 --> 00:09:01,960
You're not about to tell us about autonomous scarecrow, are you?

156
00:09:01,960 --> 00:09:02,960
Pretty much.

157
00:09:02,960 --> 00:09:03,960
Pretty much.

158
00:09:03,960 --> 00:09:04,960
Yeah.

159
00:09:04,960 --> 00:09:05,960
Yeah.

160
00:09:05,960 --> 00:09:08,160
So the other solution they went with is they made birdbangers.

161
00:09:08,160 --> 00:09:11,720
So they're basically this big propane air cannon that goes off every once in a while, makes

162
00:09:11,720 --> 00:09:13,200
a loud sound and scares them off.

163
00:09:13,200 --> 00:09:14,200
Oh, wow.

164
00:09:14,200 --> 00:09:15,200
Yeah.

165
00:09:15,200 --> 00:09:18,400
But the crow's in particular got clever and they figured out that the birdbanger was always

166
00:09:18,400 --> 00:09:21,080
in one place and didn't really scare them anymore.

167
00:09:21,080 --> 00:09:23,880
And whenever people would move around the birdbanger, the crow's would notice that people

168
00:09:23,880 --> 00:09:27,200
were carrying it around and they just move away from that area, but still eat the grapes

169
00:09:27,200 --> 00:09:28,200
elsewhere.

170
00:09:28,200 --> 00:09:29,200
Oh, wow.

171
00:09:29,200 --> 00:09:33,520
And so what we ended up doing is mounting one of these birdbangers on the grizzly and

172
00:09:33,520 --> 00:09:39,320
have it autonomously drive up and down the rows very quietly and then let it off and

173
00:09:39,320 --> 00:09:41,520
then go to the next spot quietly and let it off.

174
00:09:41,520 --> 00:09:46,240
And because it's electric and it's so slow, you know, or it could be made to go slowly,

175
00:09:46,240 --> 00:09:47,240
it worked.

176
00:09:47,240 --> 00:09:48,240
It scared them off.

177
00:09:48,240 --> 00:09:49,240
Awesome.

178
00:09:49,240 --> 00:09:53,240
So, you know, it sounds like a completely ridiculous use case, but it actually, you know,

179
00:09:53,240 --> 00:09:54,800
it was worth the time, it was worth the money.

180
00:09:54,800 --> 00:09:58,120
The complexity was low enough that we could actually assemble this application pretty much

181
00:09:58,120 --> 00:10:00,000
from building blocks.

182
00:10:00,000 --> 00:10:06,520
And now was this a research application or is this one of, does the company also do commercial,

183
00:10:06,520 --> 00:10:08,520
slash industrial solutions?

184
00:10:08,520 --> 00:10:09,520
Yeah, absolutely.

185
00:10:09,520 --> 00:10:14,200
So that one was research, but in the last few years, what we've done is we've created

186
00:10:14,200 --> 00:10:18,760
this new division inside of clear path called automotors and so what automotors does is

187
00:10:18,760 --> 00:10:25,080
we create these indoor platforms, the auto 1500 and the auto 100 to move around payload

188
00:10:25,080 --> 00:10:26,080
indoors.

189
00:10:26,080 --> 00:10:29,440
So in a factory or warehouse setting is kind of our target market right now.

190
00:10:29,440 --> 00:10:30,440
Okay.

191
00:10:30,440 --> 00:10:32,120
So we took up a big chunk of our team.

192
00:10:32,120 --> 00:10:37,240
We grew from roughly 20 people when I joined and now we're about 187 and most of that

193
00:10:37,240 --> 00:10:39,280
growth has come from the automotor side.

194
00:10:39,280 --> 00:10:40,280
Okay.

195
00:10:40,280 --> 00:10:47,720
I'll mention this because it was initially confusing to me, the clear path automotors

196
00:10:47,720 --> 00:10:52,640
has nothing to do with the auto autonomous truck company that Uber bought.

197
00:10:52,640 --> 00:10:54,400
No, but they were spelled the same.

198
00:10:54,400 --> 00:10:55,400
Yeah.

199
00:10:55,400 --> 00:10:56,400
Yeah.

200
00:10:56,400 --> 00:11:03,720
It kind of sort of happened that we filed that auto motor or auto trademark and branding

201
00:11:03,720 --> 00:11:05,360
a little bit before that.

202
00:11:05,360 --> 00:11:09,560
And yes, the two companies are totally unrelated, just a total coincidence.

203
00:11:09,560 --> 00:11:18,120
And the auto motor's platform is somewhat reminiscent of the Keeva style of autonomous

204
00:11:18,120 --> 00:11:21,200
warehouse materials handling robots.

205
00:11:21,200 --> 00:11:26,560
Do you, you know, the Keeva is kind of deployed as this entire system.

206
00:11:26,560 --> 00:11:32,320
Are you guys focusing just on the robots or are you also developing this entire warehouse

207
00:11:32,320 --> 00:11:34,640
automation system to go with them?

208
00:11:34,640 --> 00:11:35,640
Absolutely.

209
00:11:35,640 --> 00:11:37,520
We're doing the entire system all at once.

210
00:11:37,520 --> 00:11:42,440
And one thing I'd like to kind of point out is that Keeva in my mind is a little bit more

211
00:11:42,440 --> 00:11:48,040
of the old school style of robots wherein every single robot individually is actually fairly

212
00:11:48,040 --> 00:11:49,040
dumb.

213
00:11:49,040 --> 00:11:53,520
No, they'll follow QR codes on the floor and they get commands from the control system

214
00:11:53,520 --> 00:11:57,240
to go from point A to point B in a straight line and that's it, right?

215
00:11:57,240 --> 00:12:01,360
And when they do their pickup operation, it's essentially a blind pickup operation.

216
00:12:01,360 --> 00:12:07,400
And so the entire system is only applicable when you have a kind of lights out where

217
00:12:07,400 --> 00:12:12,760
there's no humans beyond a certain point, whereas the systems that we make are actually

218
00:12:12,760 --> 00:12:15,080
intended to work with humans.

219
00:12:15,080 --> 00:12:18,640
And so they're intended to take the same walkways that you'd see forklifts drive down,

220
00:12:18,640 --> 00:12:20,960
the same walkways that you'd see people walk around.

221
00:12:20,960 --> 00:12:25,600
So we think our system is a lot more flexible because you don't have to structure the entire

222
00:12:25,600 --> 00:12:27,520
warehouse around the robots.

223
00:12:27,520 --> 00:12:32,320
In fact, ideally, really nothing changes because it's infrastructure free.

224
00:12:32,320 --> 00:12:36,760
You could have any factory could drop in a few autos and they could get to work on day

225
00:12:36,760 --> 00:12:37,760
one pretty much.

226
00:12:37,760 --> 00:12:38,760
Oh, that's awesome.

227
00:12:38,760 --> 00:12:40,840
That's a great distinction to make.

228
00:12:40,840 --> 00:12:46,360
And it's also a good segue into one of the big questions that I've had or really a distinction

229
00:12:46,360 --> 00:12:51,440
that I think is worth exploring at least is, you know, I think in the robotics field we

230
00:12:51,440 --> 00:12:57,040
throw around the term autonomous quite a bit or I've seen it thrown around quite a bit.

231
00:12:57,040 --> 00:13:01,080
And I'm wondering, you know, I'd like to explore what exactly that means, right?

232
00:13:01,080 --> 00:13:06,640
I think, you know, just given the example you just provided in terms of the way the

233
00:13:06,640 --> 00:13:11,720
design principles of auto relative to Kiva, you know, Kiva will call their robots autonomous

234
00:13:11,720 --> 00:13:17,800
as well, but they're, you know, being controlled and directed by some central machine.

235
00:13:17,800 --> 00:13:24,640
So autonomous doesn't necessarily imply intelligent, let's say, you know, how do you guys think

236
00:13:24,640 --> 00:13:27,200
of, you know, what autonomous means?

237
00:13:27,200 --> 00:13:31,680
And is there any standardization around that term in the robotics industry like there

238
00:13:31,680 --> 00:13:36,240
are levels of standardization of, you know, what it means to be self-driving or autonomous

239
00:13:36,240 --> 00:13:37,760
in the automobile industry?

240
00:13:37,760 --> 00:13:41,960
They're starting to be and they're mostly focused around the concept of safety.

241
00:13:41,960 --> 00:13:42,960
Okay.

242
00:13:42,960 --> 00:13:47,040
So what level of safety is it to work with these robots in human areas?

243
00:13:47,040 --> 00:13:48,040
Okay.

244
00:13:48,040 --> 00:13:52,720
And so, and this goes back really to the older, well, still still current welding style robots

245
00:13:52,720 --> 00:13:57,480
for car plants, for example, where the arm will come down and weld the specific point

246
00:13:57,480 --> 00:13:59,440
completely blindly, right?

247
00:13:59,440 --> 00:14:03,960
It has no concept of what it's doing realistically and has no concept of what's in the way.

248
00:14:03,960 --> 00:14:08,640
And so it will gladly, yeah, it will gladly smash right through somebody, right?

249
00:14:08,640 --> 00:14:15,000
And so that I would call, now I'm unsure if there is a kind of a growing term, but around

250
00:14:15,000 --> 00:14:20,000
here what we say is that systems like that are automated, but they're not necessarily

251
00:14:20,000 --> 00:14:21,000
autonomous.

252
00:14:21,000 --> 00:14:22,000
Okay.

253
00:14:22,000 --> 00:14:26,320
So that the system is doing a thing automatically, it is repeating the same motion, but it

254
00:14:26,320 --> 00:14:30,840
is not actually planning its own path, it's not making its own decisions.

255
00:14:30,840 --> 00:14:33,240
And so that's the case here as well.

256
00:14:33,240 --> 00:14:37,600
And we've had, you know, there have been mobile robots inside of factories for quite a

257
00:14:37,600 --> 00:14:38,600
while.

258
00:14:38,600 --> 00:14:41,000
I mean, Toyota has been making them probably since the 80s.

259
00:14:41,000 --> 00:14:46,480
And yeah, and these systems will follow magnetic tape on the floor or buried markers.

260
00:14:46,480 --> 00:14:49,240
And they'll go from station to station, they'll pick up a load, they'll go somewhere else

261
00:14:49,240 --> 00:14:50,240
and drop it off.

262
00:14:50,240 --> 00:14:55,000
And again, I consider that system automated, but it's not really autonomous, it's only

263
00:14:55,000 --> 00:15:01,560
follows a very specific set of instructions and can't deviate, it can't replan.

264
00:15:01,560 --> 00:15:06,120
And if anybody trips its safety laser, it will just stop, it has no other option.

265
00:15:06,120 --> 00:15:13,200
So then going back to our mobile scarecrow, if you will, when you say that it's autonomously

266
00:15:13,200 --> 00:15:17,840
navigating the vineyard, to what degree is it actually doing that autonomously?

267
00:15:17,840 --> 00:15:18,840
Yeah, absolutely.

268
00:15:18,840 --> 00:15:24,880
Well, I mean, that specific one was kind of more of a test case here in Niagara region.

269
00:15:24,880 --> 00:15:29,560
So that one was actually just using GPS waypoints going from point to point.

270
00:15:29,560 --> 00:15:35,320
And if it saw something in front of it using a stereo camera, it would just stop.

271
00:15:35,320 --> 00:15:36,320
Okay.

272
00:15:36,320 --> 00:15:39,080
So that was one of those cases where it's kind of automated, but not autonomous.

273
00:15:39,080 --> 00:15:40,080
Okay.

274
00:15:40,080 --> 00:15:45,880
However, in the auto cases, what they're doing is they actually use laser scanners to build

275
00:15:45,880 --> 00:15:49,440
up a map of the environment and find their own path through the environment.

276
00:15:49,440 --> 00:15:50,440
Okay.

277
00:15:50,440 --> 00:15:54,800
And so they're actively each unit is making its own decisions, even though we have this

278
00:15:54,800 --> 00:15:59,680
overarching dispatching system that will command each unit to do certain tasks.

279
00:15:59,680 --> 00:16:03,120
The actual execution of that task is usually up to the robot itself.

280
00:16:03,120 --> 00:16:04,120
Okay.

281
00:16:04,120 --> 00:16:05,120
Interesting.

282
00:16:05,120 --> 00:16:11,880
And to what degree at auto are you getting into notions of the robots collaborating

283
00:16:11,880 --> 00:16:14,360
with one another or with humans?

284
00:16:14,360 --> 00:16:15,360
Yeah.

285
00:16:15,360 --> 00:16:16,360
Absolutely.

286
00:16:16,360 --> 00:16:19,560
So with one another, the one kind of interesting story I can tell is there's a client

287
00:16:19,560 --> 00:16:25,480
we have where we're working towards replacing the standard assembly line, essentially.

288
00:16:25,480 --> 00:16:29,520
So you can imagine vehicles or machines going by on an assembly line.

289
00:16:29,520 --> 00:16:34,640
And if you have a different range of products, you could have three different assembly lines

290
00:16:34,640 --> 00:16:37,840
for a simple, a medium and a very complex product, for example.

291
00:16:37,840 --> 00:16:41,720
So instead of that, what we're doing is the robot actually carries the product and then

292
00:16:41,720 --> 00:16:43,320
there's only one assembly line.

293
00:16:43,320 --> 00:16:48,200
And so as the large auto 1500 is carrying the product, smaller robots are driving up and

294
00:16:48,200 --> 00:16:52,760
delivering, here's a simple part for the cheap model, here's a much more complex part

295
00:16:52,760 --> 00:16:54,640
for the expensive model.

296
00:16:54,640 --> 00:16:58,280
And oh, by the way, the more complex model needs more time for assembly.

297
00:16:58,280 --> 00:17:02,560
And so the robot will drive slower and it'll have bigger buffers between it and the next

298
00:17:02,560 --> 00:17:03,560
auto 1500.

299
00:17:03,560 --> 00:17:08,200
So if you can imagine it, it's this totally mobile assembly line using robots as the actual

300
00:17:08,200 --> 00:17:09,200
carriers.

301
00:17:09,200 --> 00:17:10,200
Right.

302
00:17:10,200 --> 00:17:11,200
Oh, that's interesting.

303
00:17:11,200 --> 00:17:12,200
Yeah.

304
00:17:12,200 --> 00:17:13,200
Absolutely.

305
00:17:13,200 --> 00:17:15,800
And so that's a case where not only are robots collaborating with each other because you

306
00:17:15,800 --> 00:17:20,520
have smaller deliveries to larger deliveries and this kind of dynamic spacing.

307
00:17:20,520 --> 00:17:24,440
But you also have humans collaborating directly with the robots where they know that their

308
00:17:24,440 --> 00:17:27,440
parts are arriving just in time for them to use.

309
00:17:27,440 --> 00:17:33,120
And yeah, and you can imagine there's hundreds of different ways that this is more optimal

310
00:17:33,120 --> 00:17:34,720
than a assembly line.

311
00:17:34,720 --> 00:17:39,120
If something is too slow or something gets broken or something's not quite right, that can

312
00:17:39,120 --> 00:17:43,120
be pulled out of the assembly line without the rest of the assembly line even noticing.

313
00:17:43,120 --> 00:17:47,400
And since the dispatcher system is keeping track, it will automatically adjust the distance

314
00:17:47,400 --> 00:17:48,560
between robots.

315
00:17:48,560 --> 00:17:54,960
In general, when you're deploying a system like this, what's the kind of level of abstraction

316
00:17:54,960 --> 00:17:57,600
if you will that the customer needs to deal with?

317
00:17:57,600 --> 00:17:58,960
Yeah, that's a great question.

318
00:17:58,960 --> 00:18:02,280
So we have this entire mapping system.

319
00:18:02,280 --> 00:18:07,160
And if you could kind of imagine, let's take a case of a small manufacturer.

320
00:18:07,160 --> 00:18:11,200
So they want to use the auto 100 to move parts around the facility.

321
00:18:11,200 --> 00:18:15,120
So on day one, an auto 100 arrives at their facility and they drive it around.

322
00:18:15,120 --> 00:18:18,840
So this first step, they're physically driving it with a little joystick.

323
00:18:18,840 --> 00:18:23,800
The idea being that humans are especially people who work at the facility, much better

324
00:18:23,800 --> 00:18:27,680
know what is a dangerous area and what's a safe area than a machine could.

325
00:18:27,680 --> 00:18:30,600
So for the initial step, we really don't want them driving autonomously.

326
00:18:30,600 --> 00:18:33,280
We want somebody to kind of shepherd them around.

327
00:18:33,280 --> 00:18:37,240
As it does that first pass, it builds up this map of the environment that is then uploaded

328
00:18:37,240 --> 00:18:39,840
to the control system or the dispatcher.

329
00:18:39,840 --> 00:18:46,240
And after that, all the robots now know this map and the user from an abstraction perspective,

330
00:18:46,240 --> 00:18:50,360
they get this two dimensional floor plan that they can then draw on with just a mouse

331
00:18:50,360 --> 00:18:51,360
click.

332
00:18:51,360 --> 00:18:52,360
This is cell one.

333
00:18:52,360 --> 00:18:53,360
This is cell two.

334
00:18:53,360 --> 00:18:54,360
Don't go here.

335
00:18:54,360 --> 00:18:55,680
This is a one way zone.

336
00:18:55,680 --> 00:18:58,200
This is a slow speed zone, so on and so on.

337
00:18:58,200 --> 00:19:02,000
And so they're essentially painting in the map in what style that they want the robots

338
00:19:02,000 --> 00:19:03,000
to work in.

339
00:19:03,000 --> 00:19:04,000
Okay.

340
00:19:04,000 --> 00:19:08,520
And lastly, the robots are also able to detect what is a charging station, what is a docking

341
00:19:08,520 --> 00:19:11,280
station if they need higher precision.

342
00:19:11,280 --> 00:19:14,680
And those are automatically, those are features automatically added to the map.

343
00:19:14,680 --> 00:19:18,760
So at the end of this, you know, first day, the user has a map of their plant.

344
00:19:18,760 --> 00:19:22,400
They know where all the cells are, where the charging stations are, and where all the robots

345
00:19:22,400 --> 00:19:23,400
are positioned.

346
00:19:23,400 --> 00:19:29,000
After that, they can either do individual commands and tasks or fleet white commands.

347
00:19:29,000 --> 00:19:33,520
So they can tell a robot, I need you to go from here to here right now, and that's kind

348
00:19:33,520 --> 00:19:35,160
of a one time command.

349
00:19:35,160 --> 00:19:39,560
Or you could set up a chain saying, I need robots from this dock to this dock every 30

350
00:19:39,560 --> 00:19:41,080
seconds.

351
00:19:41,080 --> 00:19:42,920
And then it takes off.

352
00:19:42,920 --> 00:19:43,920
Okay.

353
00:19:43,920 --> 00:19:49,160
And then a next level would be integrating that in with some type of plant management system

354
00:19:49,160 --> 00:19:54,720
that is, you know, based on kind of flow of, you know, machines and materials or integrating

355
00:19:54,720 --> 00:20:00,360
into a CNC or something like that to, I, what is that, you know, integrating into the

356
00:20:00,360 --> 00:20:04,360
broader production pipeline, what is that fit in?

357
00:20:04,360 --> 00:20:05,360
Yeah.

358
00:20:05,360 --> 00:20:08,080
So that's not something we've started out quite yet.

359
00:20:08,080 --> 00:20:09,320
That's definitely on our roadmap.

360
00:20:09,320 --> 00:20:10,320
Okay.

361
00:20:10,320 --> 00:20:13,200
However, we have a lot of integration partners that have started doing that.

362
00:20:13,200 --> 00:20:20,520
So we have seen quite a few different full robotic arms and dual manipulator systems mounted

363
00:20:20,520 --> 00:20:22,000
on top of auto units.

364
00:20:22,000 --> 00:20:23,000
Oh, wow.

365
00:20:23,000 --> 00:20:24,000
Okay.

366
00:20:24,000 --> 00:20:30,360
And actually, at this year's ICRA 2017, we're going to have a UR5 arm on top of a rich

367
00:20:30,360 --> 00:20:32,640
back, which is a research robot.

368
00:20:32,640 --> 00:20:39,160
But the research robots are also now deploying this autonomy research kit for use by researchers.

369
00:20:39,160 --> 00:20:42,880
And one of the demonstrations we'll have there is trivially scripting the arm to pick up

370
00:20:42,880 --> 00:20:47,840
an object, drive somewhere and put it down in about, you know, five, ten lines of code.

371
00:20:47,840 --> 00:20:48,840
Okay.

372
00:20:48,840 --> 00:20:50,360
Oh, wow.

373
00:20:50,360 --> 00:20:57,040
One of the things that you mentioned that has come up in, and my research is being really

374
00:20:57,040 --> 00:20:58,040
important.

375
00:20:58,040 --> 00:21:05,640
And a lot of ways distinct from the treatment of AI and robotics in kind of the academic

376
00:21:05,640 --> 00:21:12,440
literature is this idea of learning from the subject matter expertise that is inherent

377
00:21:12,440 --> 00:21:18,320
in the customer environment or the ultimate deployment environment of the robot.

378
00:21:18,320 --> 00:21:23,040
So for example, you talked about, hey, let's let humans drive the robot around.

379
00:21:23,040 --> 00:21:29,200
So we don't have to let the robot bang around the warehouse for a week to try to figure

380
00:21:29,200 --> 00:21:32,040
out what's what.

381
00:21:32,040 --> 00:21:41,400
And then letting humans then come in and put markings on the map to identify areas that

382
00:21:41,400 --> 00:21:46,080
robots shouldn't go or should go or directions, things like that.

383
00:21:46,080 --> 00:21:55,880
I'm curious your perspective on that notion generally of capturing human expertise in

384
00:21:55,880 --> 00:22:05,040
the programming of the robot with AI and any challenges that it represents, other areas

385
00:22:05,040 --> 00:22:08,400
that you might see it come up, things like that.

386
00:22:08,400 --> 00:22:09,400
Yeah, for sure.

387
00:22:09,400 --> 00:22:15,920
So one of the early problems we had was when we were looking into getting these robots

388
00:22:15,920 --> 00:22:19,120
into factories, we had two different responses.

389
00:22:19,120 --> 00:22:21,160
One of them was, this is fantastic.

390
00:22:21,160 --> 00:22:22,400
The robot can go anywhere.

391
00:22:22,400 --> 00:22:23,800
I don't have to do any planning.

392
00:22:23,800 --> 00:22:28,280
It'll just figure everything out, which isn't quite right because really to get to that

393
00:22:28,280 --> 00:22:32,480
kind of level of information, you're talking about a general purpose AI, which we're not

394
00:22:32,480 --> 00:22:33,960
close to.

395
00:22:33,960 --> 00:22:34,960
Right.

396
00:22:34,960 --> 00:22:39,240
And then the other end of the spectrum, which we also got was, well, how can I depend

397
00:22:39,240 --> 00:22:45,720
on this thing if it's not exactly following this path that I laid on the floor for it?

398
00:22:45,720 --> 00:22:51,400
And so some of our early efforts involved putting virtual tape into the map.

399
00:22:51,400 --> 00:22:57,080
So behaviors to tell the robot that I need you to follow this exact path and don't

400
00:22:57,080 --> 00:22:58,080
deviate from it.

401
00:22:58,080 --> 00:23:01,520
If anything gets in your way, stop, otherwise keep going.

402
00:23:01,520 --> 00:23:06,520
And that kind of behavior really comes from the learning that a lot of the times in the

403
00:23:06,520 --> 00:23:11,800
academic community, getting the thing to work and work well and not crash into things is

404
00:23:11,800 --> 00:23:12,800
quite an achievement.

405
00:23:12,800 --> 00:23:13,800
It's quite difficult.

406
00:23:13,800 --> 00:23:15,440
That's what we spend a lot of time on.

407
00:23:15,440 --> 00:23:19,640
But especially when you're talking about industrial use cases, the customer is looking at it as

408
00:23:19,640 --> 00:23:20,640
equipment.

409
00:23:20,640 --> 00:23:24,120
They're not really looking at it as this self-driving vehicle.

410
00:23:24,120 --> 00:23:30,960
And so they don't care that it's doing these magic, creating maps and navigating.

411
00:23:30,960 --> 00:23:36,480
They care about what is the tag time, how efficient is it, and what is its downtime.

412
00:23:36,480 --> 00:23:41,800
And a lot of the time, you will find that through these people working there for years and

413
00:23:41,800 --> 00:23:44,160
years, they know what the most efficient route is.

414
00:23:44,160 --> 00:23:50,600
They know that even though this route is longer in terms of footpath or absolute distance,

415
00:23:50,600 --> 00:23:54,960
it will take a shorter time because it tends to be less congested, for example.

416
00:23:54,960 --> 00:24:01,280
So adding in that human layer knowledge of a here's an area that is more clear usually

417
00:24:01,280 --> 00:24:06,040
is kind of an interesting trick that we've had to fuse the best of human knowledge of

418
00:24:06,040 --> 00:24:11,560
the environment with this kind of superhuman level planning and optimization that computers

419
00:24:11,560 --> 00:24:12,560
can do.

420
00:24:12,560 --> 00:24:13,560
Great.

421
00:24:13,560 --> 00:24:14,560
Great.

422
00:24:14,560 --> 00:24:20,160
Can you talk a little bit about all of the various ways, maybe catalog the various ways that

423
00:24:20,160 --> 00:24:25,120
you guys use machine learning in AI with the auto systems?

424
00:24:25,120 --> 00:24:26,120
Yeah.

425
00:24:26,120 --> 00:24:32,600
So some of the things we're really looking into, one of them, it's sort of on the border

426
00:24:32,600 --> 00:24:38,840
machine learning, but one of the main kind of problems of creating these systems is getting

427
00:24:38,840 --> 00:24:40,840
an accurate map.

428
00:24:40,840 --> 00:24:47,200
And so there's a standard way to use laser data and turn it into a map just by basically

429
00:24:47,200 --> 00:24:48,680
it's called graph slam.

430
00:24:48,680 --> 00:24:55,080
And that method works well on its own, but it does have inherent problems of kind of distortions

431
00:24:55,080 --> 00:24:56,080
and things like that.

432
00:24:56,080 --> 00:25:01,480
So you do have to apply a little bit of intelligence to the way that you're creating these maps and

433
00:25:01,480 --> 00:25:06,320
that you know that on a factory floor, for example, it would be very unlikely for the outer

434
00:25:06,320 --> 00:25:07,320
wall to curve.

435
00:25:07,320 --> 00:25:08,320
Right.

436
00:25:08,320 --> 00:25:09,320
Right.

437
00:25:09,320 --> 00:25:13,040
So that just doesn't look right to a human and so it shouldn't look right to our algorithms

438
00:25:13,040 --> 00:25:14,040
either.

439
00:25:14,040 --> 00:25:18,920
And I mean, too, you're doing things like maybe classifying points and curve fitting and

440
00:25:18,920 --> 00:25:22,160
that kind of thing to try to generate the ultimate map.

441
00:25:22,160 --> 00:25:23,160
Generate much better maps.

442
00:25:23,160 --> 00:25:24,160
Yeah.

443
00:25:24,160 --> 00:25:28,000
And the kind of the step further than that is after we have a decent map, we can also

444
00:25:28,000 --> 00:25:31,440
think about can we classify obstacles in that space?

445
00:25:31,440 --> 00:25:37,760
So just using laser data or perhaps camera data or ultrasonic data, can we classify that

446
00:25:37,760 --> 00:25:40,440
I'm fairly confident this is a forklift.

447
00:25:40,440 --> 00:25:43,880
If this is a forklift, that means that it has these large times.

448
00:25:43,880 --> 00:25:48,440
If I can't see the times, then either they're out of my laser scanning range or something

449
00:25:48,440 --> 00:25:49,440
else is going wrong.

450
00:25:49,440 --> 00:25:54,800
So I'm going to give this an extra wide birth because I can't tell where the hazard is.

451
00:25:54,800 --> 00:25:56,440
Or otherwise, oh, I do see the times.

452
00:25:56,440 --> 00:25:57,440
I know exactly where it is.

453
00:25:57,440 --> 00:26:01,680
So I'm going to shrink my approach distance and I can be more efficient in my pathening.

454
00:26:01,680 --> 00:26:02,680
Okay.

455
00:26:02,680 --> 00:26:06,960
So obstacle recognition and being able to predict what an obstacle is going to do in terms

456
00:26:06,960 --> 00:26:12,240
of movement or speed or direction is definitely something that makes planning more efficient.

457
00:26:12,240 --> 00:26:17,640
And how about in terms of the robot, the navigation?

458
00:26:17,640 --> 00:26:25,080
I mean, we've talked about a little bit of the the pathing is all of the the pathing more

459
00:26:25,080 --> 00:26:30,200
or less deterministic, you know, outside of the fact that it has to detect objects and,

460
00:26:30,200 --> 00:26:39,600
you know, react to them or the is the general path that takes more or less set or will one

461
00:26:39,600 --> 00:26:45,480
of these robots ever deviate if it, you know, knows of an alternate path and find some obstacle

462
00:26:45,480 --> 00:26:48,880
that, you know, isn't moving or not moving quickly enough.

463
00:26:48,880 --> 00:26:49,880
Yeah.

464
00:26:49,880 --> 00:26:50,880
Absolutely.

465
00:26:50,880 --> 00:26:55,160
It's, it's making a constant projection of how long it's going to take to arrive to its

466
00:26:55,160 --> 00:26:56,160
end goal.

467
00:26:56,160 --> 00:26:57,160
Okay.

468
00:26:57,160 --> 00:26:58,160
And it's updating the system.

469
00:26:58,160 --> 00:27:02,760
So the system knows this robot needs a 30 second time from point A to point B and it's

470
00:27:02,760 --> 00:27:05,760
only going to make it in in 32 seconds.

471
00:27:05,760 --> 00:27:07,080
So something's not quite right.

472
00:27:07,080 --> 00:27:14,760
So this path is either not possible to do in this time or there's more detourists or obstacles

473
00:27:14,760 --> 00:27:18,080
in the way than there should be at this time.

474
00:27:18,080 --> 00:27:22,440
And so the robot's constantly making this projection of what is the fastest way to get

475
00:27:22,440 --> 00:27:23,440
there?

476
00:27:23,440 --> 00:27:24,440
What is the most efficient way to get there?

477
00:27:24,440 --> 00:27:29,920
And if it's on a path and it sees obstacles or even if other robots in the space have detected

478
00:27:29,920 --> 00:27:35,720
those obstacles and uploaded them to the supervising system, then that robot will know,

479
00:27:35,720 --> 00:27:40,760
okay, this is likely a less ideal path, so I'm going to take this alternative path.

480
00:27:40,760 --> 00:27:46,200
Can you talk a little bit about the, maybe the difference between machine learning and

481
00:27:46,200 --> 00:27:52,640
AI that is running on the robots versus running on the supervising system?

482
00:27:52,640 --> 00:27:55,040
What functions maybe sit where?

483
00:27:55,040 --> 00:27:58,480
Yeah, I can talk a little bit about that.

484
00:27:58,480 --> 00:28:04,000
Ideally speaking, we don't want to have our individual robots constantly trying to adjust

485
00:28:04,000 --> 00:28:07,200
all the time or constantly trying to learn all the time.

486
00:28:07,200 --> 00:28:11,760
Because this runs into one of the fundamental problems you have, especially applying AI

487
00:28:11,760 --> 00:28:17,800
and industry, is that you have to be probably safe, right, especially with these machines

488
00:28:17,800 --> 00:28:20,760
being very large and fast.

489
00:28:20,760 --> 00:28:25,640
You have to be sure that even though there's a hardware safety system on board, triggering

490
00:28:25,640 --> 00:28:31,000
a hardware emergency stop is not a desirable effect because you just, at the very best

491
00:28:31,000 --> 00:28:36,440
case, you've messed up your, your tack time, right, you've messed up your delivery window.

492
00:28:36,440 --> 00:28:40,200
But in the worst case, you can't stop fast enough and you actually hit something.

493
00:28:40,200 --> 00:28:47,320
So, we need to ensure that the robots on the robot level have as predictable behavior as

494
00:28:47,320 --> 00:28:48,480
possible.

495
00:28:48,480 --> 00:28:53,080
And this even goes up to the level of, if you'll notice, the auto 1500s and the 100s

496
00:28:53,080 --> 00:28:55,720
have a LED strip around the edge.

497
00:28:55,720 --> 00:29:00,600
And so what we do is because, especially the auto 1500, it's fundamentally, doesn't really

498
00:29:00,600 --> 00:29:02,840
have a front in a rear.

499
00:29:02,840 --> 00:29:05,400
They're almost a mirror image of each other.

500
00:29:05,400 --> 00:29:07,920
And so the robot doesn't care if it's going forwards or backwards.

501
00:29:07,920 --> 00:29:11,480
And so that leads to a lot of confusion for people because they couldn't tell what the

502
00:29:11,480 --> 00:29:13,200
robot was planning to do, right.

503
00:29:13,200 --> 00:29:17,440
And then people will naturally, you know, if you can imagine you see this machine behaving

504
00:29:17,440 --> 00:29:22,920
in a predictable way, you'll naturally start to stop and be wary and kind of clog up

505
00:29:22,920 --> 00:29:24,960
the root, right.

506
00:29:24,960 --> 00:29:29,280
So, having people comfortably know where the robot's planning to go means though naturally

507
00:29:29,280 --> 00:29:30,960
clear out of that space.

508
00:29:30,960 --> 00:29:35,080
And then it's kind of a reinforcement effect in that the robot will move better.

509
00:29:35,080 --> 00:29:38,760
And so that LED strip, what it actually does is it actually puts headlights at the front

510
00:29:38,760 --> 00:29:41,200
and tail lights at the back like a car.

511
00:29:41,200 --> 00:29:45,040
And it will actually blink yellow blinking turning signals when it's turning in one direction

512
00:29:45,040 --> 00:29:46,200
of the other.

513
00:29:46,200 --> 00:29:50,040
And people really respond naturally to that because we have this kind of built in language

514
00:29:50,040 --> 00:29:51,040
for roads.

515
00:29:51,040 --> 00:29:52,040
Right.

516
00:29:52,040 --> 00:29:53,640
What does it look like when cars coming to stop?

517
00:29:53,640 --> 00:29:56,680
Well, the back red tail lights will flare brighter.

518
00:29:56,680 --> 00:29:57,680
Right.

519
00:29:57,680 --> 00:29:58,680
What does it look like when it's trying to pass?

520
00:29:58,680 --> 00:30:03,680
Well, it might blink the white front lights telling you, go ahead, you know, you go first.

521
00:30:03,680 --> 00:30:08,000
And so all these kind of behaviors really make it much more predictable in its movement.

522
00:30:08,000 --> 00:30:11,520
And as a side effect, they make it more safe.

523
00:30:11,520 --> 00:30:22,080
What else goes into, I mean, the so you've talked about safety systems, but do customers,

524
00:30:22,080 --> 00:30:24,480
you mentioned provably safe.

525
00:30:24,480 --> 00:30:30,680
What goes into the proving of the safety and to what degree do you have to do that are

526
00:30:30,680 --> 00:30:37,320
they're a specific regulatory requirements that you run into that have standards for proving

527
00:30:37,320 --> 00:30:38,320
safety.

528
00:30:38,320 --> 00:30:40,800
And, you know, what are those and how do you address them?

529
00:30:40,800 --> 00:30:41,800
Yeah.

530
00:30:41,800 --> 00:30:42,800
Absolutely.

531
00:30:42,800 --> 00:30:47,440
So there's one of the the fields where we're seeing here is that a lot of the standards

532
00:30:47,440 --> 00:30:52,040
in industry for so called collaborative robots are really designed around collaborative

533
00:30:52,040 --> 00:30:53,040
arms.

534
00:30:53,040 --> 00:30:56,760
So universal robot or the backster from rethink, right?

535
00:30:56,760 --> 00:31:00,600
These are robots that are intended to work with humans.

536
00:31:00,600 --> 00:31:05,000
And so they're very, very clearly defined on maximum inertia's pinch points and things

537
00:31:05,000 --> 00:31:06,000
like that.

538
00:31:06,000 --> 00:31:11,320
But actually proving that a system that is mobile on the ground, that's a much more tricky

539
00:31:11,320 --> 00:31:12,320
story.

540
00:31:12,320 --> 00:31:13,320
Okay.

541
00:31:13,320 --> 00:31:14,480
So there's a large set.

542
00:31:14,480 --> 00:31:22,920
I think we currently follow 12 or 13 different standards for safe systems working with people.

543
00:31:22,920 --> 00:31:23,920
Okay.

544
00:31:23,920 --> 00:31:28,720
And so from the very basic level, things like the emergency stop system has to be dual

545
00:31:28,720 --> 00:31:29,720
redundant.

546
00:31:29,720 --> 00:31:35,680
So at any given time, if any one system fails, the system can still stop safely.

547
00:31:35,680 --> 00:31:36,680
Mm-hmm.

548
00:31:36,680 --> 00:31:41,920
Other things going all the way up to our planner on the robot itself should never plan

549
00:31:41,920 --> 00:31:45,040
into a space that it can become unsafe.

550
00:31:45,040 --> 00:31:50,760
So even in the worst case scenario, some horrible bug freezes the entire computer, the robot

551
00:31:50,760 --> 00:31:54,400
should still be able to stop itself safely.

552
00:31:54,400 --> 00:31:55,400
Mm-hmm.

553
00:31:55,400 --> 00:31:56,400
Right?

554
00:31:56,400 --> 00:32:02,280
Well, you have the highest level, which is the supervisory system, commanding robots and

555
00:32:02,280 --> 00:32:05,160
kind of hinting them a most reasonably safe path.

556
00:32:05,160 --> 00:32:06,160
Mm-hmm.

557
00:32:06,160 --> 00:32:10,280
Then you have the actual autonomy on board the robot, ensuring that it's going at a safe

558
00:32:10,280 --> 00:32:15,360
speed with a safe clearing distance in front of it and planning into a safe space.

559
00:32:15,360 --> 00:32:19,600
Then a lower level down, you have the microcontroller that's doing the low level command and real

560
00:32:19,600 --> 00:32:24,600
time control of brakes, motor and coder values and those kind of thing.

561
00:32:24,600 --> 00:32:28,480
And then even outside of all that, you have this completely separate hardware safety system

562
00:32:28,480 --> 00:32:31,200
that's tied into the safety lasers.

563
00:32:31,200 --> 00:32:35,440
So that when the lasers are set to mode, that it's expecting the robot to travel at one

564
00:32:35,440 --> 00:32:41,000
meter per second, we know that the robot will stop at this speed in one meter seconds.

565
00:32:41,000 --> 00:32:45,040
So the laser, you know, safety trip range has to be at least this far.

566
00:32:45,040 --> 00:32:46,040
Okay.

567
00:32:46,040 --> 00:32:51,400
And so a lot of the challenge to build this safe system was, can we prove and can we test

568
00:32:51,400 --> 00:32:56,800
out that the robot will actually stop at this speed under all of these conditions?

569
00:32:56,800 --> 00:32:57,800
Right.

570
00:32:57,800 --> 00:32:58,800
Right.

571
00:32:58,800 --> 00:33:02,200
And so how we did that is we actually have a motion tracking system similar to what's

572
00:33:02,200 --> 00:33:04,360
used in the film industry.

573
00:33:04,360 --> 00:33:08,400
And we put tracker dots all over our robots and we would run them at carburet obstacles

574
00:33:08,400 --> 00:33:13,440
over and over again for hours from different directions, different speeds, different payloads,

575
00:33:13,440 --> 00:33:19,000
everything and figure out exactly how long it takes to stop in all of these conditions.

576
00:33:19,000 --> 00:33:20,000
Okay.

577
00:33:20,000 --> 00:33:24,840
So the interesting things we found out is there's actually a slight omission in some of

578
00:33:24,840 --> 00:33:33,040
the safety standards in that the safety standard assumes if you're going around an arc or curve,

579
00:33:33,040 --> 00:33:37,160
if you stop the motors, so you remove power from them, the robot will naturally go in a

580
00:33:37,160 --> 00:33:38,160
straight line.

581
00:33:38,160 --> 00:33:39,160
Mm-hmm.

582
00:33:39,160 --> 00:33:41,040
So you can imagine, you know, you're swinging away it on a string.

583
00:33:41,040 --> 00:33:43,000
If you let go, it should travel in a straight line.

584
00:33:43,000 --> 00:33:44,000
Right.

585
00:33:44,000 --> 00:33:48,560
But that's not the case because you actually do have rotational momentum on your robot.

586
00:33:48,560 --> 00:33:52,680
So you will actually go in a, you will continue to go in a curve, not as much of a curve

587
00:33:52,680 --> 00:33:55,040
as you are going, but more than you would expect.

588
00:33:55,040 --> 00:33:56,040
Right.

589
00:33:56,040 --> 00:33:59,320
And so these kind of things are really hard to see unless you do these thousands of hours

590
00:33:59,320 --> 00:34:02,480
of testing and you track it down to the millimeter.

591
00:34:02,480 --> 00:34:03,480
Mm-hmm.

592
00:34:03,480 --> 00:34:06,840
But that really shapes the way that our laser safety field sets work.

593
00:34:06,840 --> 00:34:07,840
Mm-hmm.

594
00:34:07,840 --> 00:34:13,080
And it seems like that doesn't even take into account the, you know, the physics of whatever

595
00:34:13,080 --> 00:34:14,080
your payload is.

596
00:34:14,080 --> 00:34:19,160
You know, if you've got a bunch of palatized things stacked up, you know, 10 feet tall,

597
00:34:19,160 --> 00:34:24,480
you're going to have kind of a dispersion radius of things all over the, the warehouse

598
00:34:24,480 --> 00:34:30,160
floor that you need to kind of keep track of if you're trying to figure out, you know,

599
00:34:30,160 --> 00:34:34,520
what the dangerous radius around this, this robot is.

600
00:34:34,520 --> 00:34:35,520
Absolutely.

601
00:34:35,520 --> 00:34:36,520
Yeah.

602
00:34:36,520 --> 00:34:41,200
And so the kind of next steps that we're really looking into is, can we use our load sensors

603
00:34:41,200 --> 00:34:45,480
to ensure that we never tip anything over even if somebody puts something improperly on

604
00:34:45,480 --> 00:34:47,480
top of the robot?

605
00:34:47,480 --> 00:34:52,600
Can we, can we use camera systems to ensure that we have looking around corners that the

606
00:34:52,600 --> 00:34:54,000
robot can't see?

607
00:34:54,000 --> 00:34:58,320
And so to start breaking ahead of time, can we project light ahead of the robot so that

608
00:34:58,320 --> 00:35:01,920
people know that the robot's coming around the corner?

609
00:35:01,920 --> 00:35:02,920
Those kind of systems.

610
00:35:02,920 --> 00:35:03,920
Yeah.

611
00:35:03,920 --> 00:35:05,760
There's definitely, there's, there's lots and lots of different directions to go, but

612
00:35:05,760 --> 00:35:10,320
at the most fundamental level, it's ensuring that your systems are dual redundant and you

613
00:35:10,320 --> 00:35:13,920
have a completely hardware-based safety stop system.

614
00:35:13,920 --> 00:35:20,880
It sounds like in a lot of ways, there's a convergence between industrial robotics and

615
00:35:20,880 --> 00:35:29,520
consumer autonomous vehicles and the technologies that are perhaps accelerating due to the interest

616
00:35:29,520 --> 00:35:35,520
in self-driving cars are going to kind of find their way into the industrial realm.

617
00:35:35,520 --> 00:35:37,400
Are you guys seeing that?

618
00:35:37,400 --> 00:35:38,400
Yeah.

619
00:35:38,400 --> 00:35:39,400
Yeah.

620
00:35:39,400 --> 00:35:46,040
And undoubtedly, you know, the consumer autonomous vehicle market is a very large market, but

621
00:35:46,040 --> 00:35:49,280
in my opinion, it's a much more difficult market to capture.

622
00:35:49,280 --> 00:35:50,280
Right.

623
00:35:50,280 --> 00:35:55,400
The nice thing about the inside of a factory is it never rains.

624
00:35:55,400 --> 00:35:57,880
So you're never going to have the fire sprinklers off, right?

625
00:35:57,880 --> 00:35:58,880
Yeah, exactly.

626
00:35:58,880 --> 00:36:03,760
So you're never going to have rain, you're never going to fog, you're never going to ice.

627
00:36:03,760 --> 00:36:06,240
And so those, these are all things that we don't have to worry about.

628
00:36:06,240 --> 00:36:09,040
And so we have much more predictable systems.

629
00:36:09,040 --> 00:36:14,560
And so a lot of the times, it's actually kind of nice that the autonomous vehicle market

630
00:36:14,560 --> 00:36:18,400
is thinking about all these problems to make their lasers and cameras more robust against

631
00:36:18,400 --> 00:36:21,040
these effects that we don't even have to worry about.

632
00:36:21,040 --> 00:36:24,600
So we get this additional robustness, essentially, for free.

633
00:36:24,600 --> 00:36:30,400
Do you guys, to what degree do you guys use reinforcement learning?

634
00:36:30,400 --> 00:36:36,040
That's technology that has come up quite a bit in my research into these systems.

635
00:36:36,040 --> 00:36:39,360
Is that something that you guys are looking at or using?

636
00:36:39,360 --> 00:36:44,560
We're definitely looking at it, especially as I mentioned, with the idea of, can we classify

637
00:36:44,560 --> 00:36:47,960
obstacles that we see in our space?

638
00:36:47,960 --> 00:36:51,960
But that isn't yet released into our actual industrial offerings at the moment.

639
00:36:51,960 --> 00:36:52,960
Okay.

640
00:36:52,960 --> 00:37:00,040
And so over time, you're adding more capability in terms of like computer vision and things

641
00:37:00,040 --> 00:37:07,080
like that, generally, to be able to detect and differentiate between various obstacles.

642
00:37:07,080 --> 00:37:13,760
So that is that primarily for the safety use case or there are other things that you

643
00:37:13,760 --> 00:37:20,240
envision the robots doing with the ability to make those kinds of distinctions?

644
00:37:20,240 --> 00:37:21,240
Yeah.

645
00:37:21,240 --> 00:37:25,920
So the real three things are safety, efficiency, and accuracy.

646
00:37:25,920 --> 00:37:26,920
Okay.

647
00:37:26,920 --> 00:37:34,440
So with safety, having a stereoscopic camera system, such as on the auto 100, it allows

648
00:37:34,440 --> 00:37:38,480
you to see obstacles outside of the field of range of the lighter.

649
00:37:38,480 --> 00:37:39,480
Okay.

650
00:37:39,480 --> 00:37:43,680
So especially the auto 100, we expect it to be used more in colored environments and smaller

651
00:37:43,680 --> 00:37:44,680
environments.

652
00:37:44,680 --> 00:37:49,240
So it really needs to see that there's a desk that's up above where the lighter can see.

653
00:37:49,240 --> 00:37:51,240
To ensure that doesn't crash into it.

654
00:37:51,240 --> 00:37:52,240
Right.

655
00:37:52,240 --> 00:37:53,240
Right.

656
00:37:53,240 --> 00:37:56,720
The second idea in terms of efficiency is if we can classify obstacles, we can figure out

657
00:37:56,720 --> 00:37:58,960
what their behavior movement is.

658
00:37:58,960 --> 00:38:02,800
And so naturally as a person, if you're walking down the street and you see somebody walking

659
00:38:02,800 --> 00:38:06,360
towards you, I mean, and sometimes humans will make this mistake, but you'll go to the

660
00:38:06,360 --> 00:38:08,960
left, they'll go to the left, you'll go to the right, they'll go to the right.

661
00:38:08,960 --> 00:38:10,560
You know, you could do that little dance.

662
00:38:10,560 --> 00:38:11,560
Right.

663
00:38:11,560 --> 00:38:12,560
Right.

664
00:38:12,560 --> 00:38:16,200
So the idea here is can we kind of heuristically figure out a way to ensure that robots

665
00:38:16,200 --> 00:38:22,520
don't do that kind of behavior, that they actually have a almost a personality, they'll tend

666
00:38:22,520 --> 00:38:28,640
to stick to the wall when they see a person very visibly get out of your way or vice versa,

667
00:38:28,640 --> 00:38:31,920
you know, they're carrying something very heavy and very quickly, they'll, they'll, you

668
00:38:31,920 --> 00:38:35,200
know, sound a little alarm, even though you're not in the range, you're not in the way yet,

669
00:38:35,200 --> 00:38:38,080
they'll warn you ahead of time because they know you might get in the way.

670
00:38:38,080 --> 00:38:39,080
Right.

671
00:38:39,080 --> 00:38:40,080
Right.

672
00:38:40,080 --> 00:38:41,080
And so those kind of things.

673
00:38:41,080 --> 00:38:42,080
So that would be kind of the efficiency state.

674
00:38:42,080 --> 00:38:45,040
Well, I mean, and safety again as well, but also ensuring that the robot doesn't have

675
00:38:45,040 --> 00:38:47,880
to be out of the way or can plan ahead of time.

676
00:38:47,880 --> 00:38:48,880
Yeah.

677
00:38:48,880 --> 00:38:54,600
So basically in terms of actual localization, camera gives you several orders of magnitude

678
00:38:54,600 --> 00:38:57,760
more rich data than just a laser.

679
00:38:57,760 --> 00:39:04,280
And so you can start positioning yourself based on paint or markings or you name it light

680
00:39:04,280 --> 00:39:05,280
fixtures.

681
00:39:05,280 --> 00:39:09,480
And so that gives you this added level robustness and accuracy in terms of positioning yourself

682
00:39:09,480 --> 00:39:11,280
in three dimensional space.

683
00:39:11,280 --> 00:39:12,280
Okay.

684
00:39:12,280 --> 00:39:16,120
And all those things actually require machine learning quite to a large extent.

685
00:39:16,120 --> 00:39:21,480
You have to understand that even if this obstacle doesn't look like it's in the way, if

686
00:39:21,480 --> 00:39:25,280
you recognize it as a table, you can make certain assumptions like, okay, well, tables

687
00:39:25,280 --> 00:39:27,080
usually touch the floor.

688
00:39:27,080 --> 00:39:30,840
And so even if I can't see the legs on the other side, I know there's something on the

689
00:39:30,840 --> 00:39:31,840
other side.

690
00:39:31,840 --> 00:39:35,760
And if I know roughly the dimensions, I know roughly how big I have to avoid this obstacle

691
00:39:35,760 --> 00:39:38,160
by even if I can't see the other end of it.

692
00:39:38,160 --> 00:39:39,160
Right.

693
00:39:39,160 --> 00:39:40,160
Right.

694
00:39:40,160 --> 00:39:47,160
And the challenge is that I think you're trying to overcome with the computer vision applications

695
00:39:47,160 --> 00:39:53,360
is the, the lidar is generally only giving you a two-dimensional kind of lay of the land.

696
00:39:53,360 --> 00:39:54,360
Right.

697
00:39:54,360 --> 00:39:56,160
And it's typically they're mounted pretty low.

698
00:39:56,160 --> 00:40:02,200
So like anything that's around knee level, it sees and anything below or above that,

699
00:40:02,200 --> 00:40:05,640
it's kind of oblivious to is that the way yours work as well.

700
00:40:05,640 --> 00:40:06,640
Yeah.

701
00:40:06,640 --> 00:40:07,640
That's close.

702
00:40:07,640 --> 00:40:09,320
I mean, we try to mount ours right about ankle level.

703
00:40:09,320 --> 00:40:10,320
Okay.

704
00:40:10,320 --> 00:40:11,800
Or as low as we possibly can.

705
00:40:11,800 --> 00:40:12,800
Okay.

706
00:40:12,800 --> 00:40:19,280
Because you really want to see people's ankles or feet, ideally, when you know exactly what

707
00:40:19,280 --> 00:40:20,800
their contact point to the floor is.

708
00:40:20,800 --> 00:40:21,800
Okay.

709
00:40:21,800 --> 00:40:27,440
But yeah, as I mentioned earlier, kind of one of our early issues we had a lot was forklifts.

710
00:40:27,440 --> 00:40:30,560
So a forklift driver who didn't put his tines down.

711
00:40:30,560 --> 00:40:31,560
Yeah.

712
00:40:31,560 --> 00:40:37,080
So the two kind of big forks at the front, they would be sticking up in the air right about

713
00:40:37,080 --> 00:40:38,080
knee level.

714
00:40:38,080 --> 00:40:39,080
Okay.

715
00:40:39,080 --> 00:40:42,560
And it's kind of a deadly area, if you think about it, because it's just out of range

716
00:40:42,560 --> 00:40:43,560
of the LiDAR.

717
00:40:43,560 --> 00:40:44,560
Yeah.

718
00:40:44,560 --> 00:40:45,560
Yeah.

719
00:40:45,560 --> 00:40:46,560
And so that was quite tricky.

720
00:40:46,560 --> 00:40:49,960
And you're really playing this bouncing game, you theoretically you want to be right at

721
00:40:49,960 --> 00:40:51,880
ground level.

722
00:40:51,880 --> 00:40:56,720
But the problem with that is a, you can't really mount a laser that low because you'll

723
00:40:56,720 --> 00:40:59,200
just start to scrape it on the floor.

724
00:40:59,200 --> 00:41:02,720
And the other problem is is that floors aren't actually that flat.

725
00:41:02,720 --> 00:41:03,720
Right.

726
00:41:03,720 --> 00:41:09,720
So you do actually, there's another aspect there of kind of human guided machine learning

727
00:41:09,720 --> 00:41:15,000
where you want the robots to understand that this is not an obstacle, nor is it a hill.

728
00:41:15,000 --> 00:41:19,600
It's just the floors slightly uneven.

729
00:41:19,600 --> 00:41:24,320
I would have thought that, you know, the poor concrete floors would be a lot more flat

730
00:41:24,320 --> 00:41:28,880
and reliable than anything in my old wood floor house.

731
00:41:28,880 --> 00:41:30,360
You would be amazed.

732
00:41:30,360 --> 00:41:32,920
It's really a factor of distance, right?

733
00:41:32,920 --> 00:41:37,920
Your factory floor is so massive that's a 0.1 degree difference turns into, you know,

734
00:41:37,920 --> 00:41:38,920
a few feet.

735
00:41:38,920 --> 00:41:39,920
Yeah.

736
00:41:39,920 --> 00:41:41,520
So it's quite surprising.

737
00:41:41,520 --> 00:41:46,520
So tell me this, are there any particular, you know, beyond the things we've talked about

738
00:41:46,520 --> 00:41:54,480
in the computer vision domain, are there any trends or research or technologies that

739
00:41:54,480 --> 00:42:02,120
you're tracking in the machine learning, deep learning AI domain that kind of have

740
00:42:02,120 --> 00:42:05,840
you excited for the implications to robotics?

741
00:42:05,840 --> 00:42:06,840
Yeah.

742
00:42:06,840 --> 00:42:14,080
So what we're taking a close look at is understanding maps and understanding the behavior of mapping

743
00:42:14,080 --> 00:42:15,440
and positioning.

744
00:42:15,440 --> 00:42:20,480
So can we, for example, understand that here's a factory floor and just off the factory

745
00:42:20,480 --> 00:42:22,920
floor, there's a lunchroom, for example.

746
00:42:22,920 --> 00:42:23,920
Okay.

747
00:42:23,920 --> 00:42:27,600
And as a human, you would assume that somewhere between 11 o'clock in the morning and

748
00:42:27,600 --> 00:42:28,600
1 p.m.

749
00:42:28,600 --> 00:42:31,280
in the afternoon, the lunchroom is going to be very busy.

750
00:42:31,280 --> 00:42:35,120
So don't bother to walk through there because you know it's going to be busy.

751
00:42:35,120 --> 00:42:38,960
And so can we apply that kind of concept to our understanding of maps to the robots

752
00:42:38,960 --> 00:42:39,960
understanding maps?

753
00:42:39,960 --> 00:42:44,240
So as they're driving around, they collect this data, they send it up, and then our processes

754
00:42:44,240 --> 00:42:49,520
to system can understand that this area is very busy at this time.

755
00:42:49,520 --> 00:42:53,280
Even though I have no vision of it, I know from last week and the week before that this

756
00:42:53,280 --> 00:42:55,520
area is probably too busy for me to plan through.

757
00:42:55,520 --> 00:42:58,000
So I'm just going to avoid it without even trying.

758
00:42:58,000 --> 00:43:02,040
So that's definitely an area that we're looking into is understanding maps and kind of gaining

759
00:43:02,040 --> 00:43:07,920
a more fundamental level understanding of how space is changing throughout the day.

760
00:43:07,920 --> 00:43:08,920
Okay.

761
00:43:08,920 --> 00:43:11,840
And that example that I give is kind of most easy to understand.

762
00:43:11,840 --> 00:43:17,600
But there's also, especially small factories and small kind of cell-based manufacturing.

763
00:43:17,600 --> 00:43:19,080
Things change every day.

764
00:43:19,080 --> 00:43:21,160
This day you're making cases for a cell phone.

765
00:43:21,160 --> 00:43:27,480
The next day you're making, I don't know, car dashboard accessories, that kind of stuff.

766
00:43:27,480 --> 00:43:33,200
So people, but also their equipment is moving around on the factory floor and having the

767
00:43:33,200 --> 00:43:38,520
robot understand that this drill press that was here yesterday is now over here, but it's

768
00:43:38,520 --> 00:43:39,680
the same object.

769
00:43:39,680 --> 00:43:42,680
So when I ask you to go to the drill press, you don't go to the old location, you go to

770
00:43:42,680 --> 00:43:45,000
the new location.

771
00:43:45,000 --> 00:43:49,000
So again, those are things that mapping and understanding of the space is something that

772
00:43:49,000 --> 00:43:50,600
we're really looking into.

773
00:43:50,600 --> 00:43:57,640
So you're about to head off to ICRA, which is in Singapore this year.

774
00:43:57,640 --> 00:44:00,880
That's the International Conference on Robotics and Automation.

775
00:44:00,880 --> 00:44:01,880
Is that right?

776
00:44:01,880 --> 00:44:02,880
That's correct.

777
00:44:02,880 --> 00:44:04,720
What are you excited to see there?

778
00:44:04,720 --> 00:44:05,720
Oh.

779
00:44:05,720 --> 00:44:10,520
Well, all of it pretty much.

780
00:44:10,520 --> 00:44:14,640
We've seen quite a large growth in these two kind of fields.

781
00:44:14,640 --> 00:44:17,680
One is mobile manipulation.

782
00:44:17,680 --> 00:44:23,200
So not only having these human safe arms working in their cell, but actually moving from

783
00:44:23,200 --> 00:44:24,800
cell to cell.

784
00:44:24,800 --> 00:44:31,280
And so one of our industrial partners, what they did is they're working on very high precision,

785
00:44:31,280 --> 00:44:35,160
very trackable manufacturing.

786
00:44:35,160 --> 00:44:40,360
So they're making jet engine parts or nuclear reactor parts.

787
00:44:40,360 --> 00:44:46,120
And so every single part needs to have a history and needs to be checked every single step.

788
00:44:46,120 --> 00:44:48,920
So one of our autos is carrying around a manipulator.

789
00:44:48,920 --> 00:44:53,120
The manipulator will come up to a station, take a block of aluminum, put it in a CNC and

790
00:44:53,120 --> 00:44:58,920
see, start it, wait for it to finish, take it out, bring it to the measuring station, measure

791
00:44:58,920 --> 00:45:01,640
it, label it, track it in their database.

792
00:45:01,640 --> 00:45:04,840
And so we've been working on that for a little while, but now we're starting to see a lot

793
00:45:04,840 --> 00:45:07,760
of different companies take a crack at that same problem.

794
00:45:07,760 --> 00:45:12,680
Is can we make multi kind of flexible manipulation?

795
00:45:12,680 --> 00:45:15,880
And the other big trend we're seeing is survey robotics.

796
00:45:15,880 --> 00:45:22,000
So remote inspection of pipelines and power lines and power stations and places where it's

797
00:45:22,000 --> 00:45:26,360
just very far to get to and you don't really want a human there all the time.

798
00:45:26,360 --> 00:45:30,080
But you do want to have high quality data come back from it.

799
00:45:30,080 --> 00:45:35,720
And so those are two fields that we see, even large industrial partners, or just large

800
00:45:35,720 --> 00:45:37,840
companies in general.

801
00:45:37,840 --> 00:45:42,560
For example, DJI got started in the kind of consumer space, but they're really making

802
00:45:42,560 --> 00:45:47,480
inroads in the, can they do remote survey of data with their drones?

803
00:45:47,480 --> 00:45:49,400
So that should be pretty interesting as well.

804
00:45:49,400 --> 00:45:54,160
And I'm starting to see, there are a number of companies that are trying to tackle the

805
00:45:54,160 --> 00:46:00,880
indoor industrial drone problem or space.

806
00:46:00,880 --> 00:46:07,560
For example, flying around warehouses or supermarkets to, you know, hopefully overnight

807
00:46:07,560 --> 00:46:16,000
where no one's in there to take inventory, which is a super expensive process for companies.

808
00:46:16,000 --> 00:46:17,000
Yeah.

809
00:46:17,000 --> 00:46:24,160
And you guys have, are you, are you less far, I presume, I should say, that given that

810
00:46:24,160 --> 00:46:29,960
you have, you know, auto motors, which is kind of the commercialization and kind of industrial

811
00:46:29,960 --> 00:46:40,640
facing company focused on the, you know, indoor materials handling platforms, are you kind

812
00:46:40,640 --> 00:46:46,760
of moving in a commercial direction with the UAV and the USB, the aerial and the seaborne

813
00:46:46,760 --> 00:46:53,800
vehicles as well, or are those more research oriented for, you know, the foreseeable future?

814
00:46:53,800 --> 00:46:59,120
So definitely the unmanned aerial vehicles tend to be a little bit more research focused

815
00:46:59,120 --> 00:47:04,320
for now, at least on our side, simply the reason being that the main preventor from them

816
00:47:04,320 --> 00:47:08,360
being used for most tasks is just battery life.

817
00:47:08,360 --> 00:47:09,360
Yeah.

818
00:47:09,360 --> 00:47:12,800
So if you're doing aerial surveys and you're doing aerial surveys of data, that's great.

819
00:47:12,800 --> 00:47:16,400
15, 20 minutes, that's all pretty much you need to collect the data you need.

820
00:47:16,400 --> 00:47:17,400
Yeah.

821
00:47:17,400 --> 00:47:21,680
But if you're doing something like store inventory, you need to do an hour or two hours.

822
00:47:21,680 --> 00:47:22,680
Right.

823
00:47:22,680 --> 00:47:24,480
And it's just not really feasible.

824
00:47:24,480 --> 00:47:29,280
On the other hand, though, the unmanned surface vehicle are heron.

825
00:47:29,280 --> 00:47:35,120
That's an interesting case because we had actually done some work there, becoming a data

826
00:47:35,120 --> 00:47:43,360
provider to provide data for municipalities and companies about tailings ponds and overflow

827
00:47:43,360 --> 00:47:47,520
ponds in those kind of places where you need to know the depth and water quality of a small

828
00:47:47,520 --> 00:47:48,520
body of water.

829
00:47:48,520 --> 00:47:49,520
Okay.

830
00:47:49,520 --> 00:47:53,880
And so the idea would be that different companies would take this heron out to a site, do

831
00:47:53,880 --> 00:47:59,600
an automated survey, a GPS guided automated survey of the depth and quality of a pond.

832
00:47:59,600 --> 00:48:03,480
And then that data is uploaded to us and we provide this data as a service.

833
00:48:03,480 --> 00:48:05,720
Oh, super interesting.

834
00:48:05,720 --> 00:48:08,880
So that's something that we're looking into as well.

835
00:48:08,880 --> 00:48:13,920
So that's actually quite a lot closer to a real direct commercial application where the

836
00:48:13,920 --> 00:48:17,360
user is using it just as another piece of equipment and not really worrying about it

837
00:48:17,360 --> 00:48:18,360
being a robot.

838
00:48:18,360 --> 00:48:19,360
Oh nice.

839
00:48:19,360 --> 00:48:25,680
And maybe switching gears a little bit, you are kind of active in the open source robotics

840
00:48:25,680 --> 00:48:26,680
community.

841
00:48:26,680 --> 00:48:32,560
There's a robot, ROS is robotics operating system or robot operating system that you've done

842
00:48:32,560 --> 00:48:33,920
quite a bit of work with.

843
00:48:33,920 --> 00:48:39,600
And is that what's the intersection with with ClearPath is through the ClearPath platforms

844
00:48:39,600 --> 00:48:42,920
run some version of ROS?

845
00:48:42,920 --> 00:48:43,920
Yeah.

846
00:48:43,920 --> 00:48:44,920
Yeah.

847
00:48:44,920 --> 00:48:52,160
So ROS is this idea of can we apply the Linux ideal where Linux is free and open source

848
00:48:52,160 --> 00:48:56,680
and you can run it on anything, can we apply that to robots as well?

849
00:48:56,680 --> 00:49:01,760
So the idea behind ROS is it runs predominantly on top of Ubuntu, but it can run on a few

850
00:49:01,760 --> 00:49:03,360
other platforms.

851
00:49:03,360 --> 00:49:09,200
And it will talk the same language from microcontrollers all the way up to servers.

852
00:49:09,200 --> 00:49:10,440
Okay.

853
00:49:10,440 --> 00:49:15,240
And so that makes assembling a robot very, very easy because you can add on an arbitrary

854
00:49:15,240 --> 00:49:19,840
microcontroller, an almost an arbitrary sensor because most of them now have supported

855
00:49:19,840 --> 00:49:26,960
ROS drivers and assemble your robot almost as Lego bricks, which is what we do.

856
00:49:26,960 --> 00:49:31,680
And so we became a very early supporter of ROS and we continue to be one of the kind of

857
00:49:31,680 --> 00:49:36,680
the largest companies that provide all of our platforms are ROS compatible, all of our

858
00:49:36,680 --> 00:49:37,680
research platforms.

859
00:49:37,680 --> 00:49:39,440
Oh nice.

860
00:49:39,440 --> 00:49:48,560
And is there a standard interface between ROS and kind of higher level machine learning

861
00:49:48,560 --> 00:49:53,680
AI stuff or are those kind of two separate things at this point?

862
00:49:53,680 --> 00:49:57,920
At this point they're a little bit separate, but they're starting to get there.

863
00:49:57,920 --> 00:50:04,160
So one example is everybody should be familiar with the OpenCV framework for image processing.

864
00:50:04,160 --> 00:50:08,320
And OpenCV actually came out of Willa Garage, which also started ROS.

865
00:50:08,320 --> 00:50:09,320
Okay.

866
00:50:09,320 --> 00:50:13,800
So at the same time, Willa Garage created the kind of open source robotics movement and

867
00:50:13,800 --> 00:50:18,040
a lot of these early fundamental libraries for image processing, a little bit of the machine

868
00:50:18,040 --> 00:50:20,840
learning work and those kind of tasks.

869
00:50:20,840 --> 00:50:21,840
Hmm.

870
00:50:21,840 --> 00:50:22,840
Interesting.

871
00:50:22,840 --> 00:50:23,840
Interesting.

872
00:50:23,840 --> 00:50:24,840
Yeah.

873
00:50:24,840 --> 00:50:30,760
And I guess this is also an aside, but I did a, I got in on a Kickstarter for this little

874
00:50:30,760 --> 00:50:33,720
miniature LiDAR system called Scance.

875
00:50:33,720 --> 00:50:35,040
Have you ever come across that?

876
00:50:35,040 --> 00:50:36,040
I believe so.

877
00:50:36,040 --> 00:50:37,040
Yeah.

878
00:50:37,040 --> 00:50:41,360
I haven't done anything with it, which is the case with most of my electronic Kickstarter

879
00:50:41,360 --> 00:50:51,400
projects, but it looks like it's pretty cool that you can make all of the components in

880
00:50:51,400 --> 00:51:01,720
this ecosystem from the platforms to the UAVs to the sensors, including LiDAR, they've

881
00:51:01,720 --> 00:51:12,320
just become so affordable and miniature as it's become very accessible, which I think contributes

882
00:51:12,320 --> 00:51:18,320
to people being able to do lots of things and play with different ideas, including kind

883
00:51:18,320 --> 00:51:20,320
of the ML and AI angle.

884
00:51:20,320 --> 00:51:21,320
Yeah.

885
00:51:21,320 --> 00:51:22,320
Absolutely.

886
00:51:22,320 --> 00:51:25,600
The cost of LiDAR is coming down quite significantly.

887
00:51:25,600 --> 00:51:33,400
But more than that, really, the real enabler in my mind is the rapid growth of processing

888
00:51:33,400 --> 00:51:35,400
power for images.

889
00:51:35,400 --> 00:51:39,840
So not only the libraries are designed to run on CPUs, but also GPU-based processing

890
00:51:39,840 --> 00:51:46,040
of images, because as nice as LiDARs are, and we use them almost everywhere, fundamentally,

891
00:51:46,040 --> 00:51:52,040
we build the world around humans and humans mostly use vision for their navigation.

892
00:51:52,040 --> 00:51:55,440
And so almost everything we've structured, we've structured around this idea of you

893
00:51:55,440 --> 00:52:01,200
have a roughly human sized object that can see roughly human distances, and that's how

894
00:52:01,200 --> 00:52:04,000
we get around it.

895
00:52:04,000 --> 00:52:10,600
So fundamentally, I believe that in the long run, in the next 50 to 100 years, most of

896
00:52:10,600 --> 00:52:14,680
our systems will start to use cameras as their predominant source.

897
00:52:14,680 --> 00:52:22,160
And that's beneficial even today, because a relatively decent camera is maybe $20.

898
00:52:22,160 --> 00:52:26,880
And it's more than good enough to do cutting edge research.

899
00:52:26,880 --> 00:52:31,800
And you know, you can start with two cameras that are the same model.

900
00:52:31,800 --> 00:52:35,600
You put them on a ruler, so they're a measured distance apart.

901
00:52:35,600 --> 00:52:38,320
You calibrate out their small imperfections.

902
00:52:38,320 --> 00:52:43,440
And then you attach it to a consumer grade laptop, and you have a cutting edge stereoscopic

903
00:52:43,440 --> 00:52:46,160
vision platform that you can start doing research on.

904
00:52:46,160 --> 00:52:47,160
That's awesome.

905
00:52:47,160 --> 00:52:53,320
Any particular, you know, for folks that are interested in the hobbyist angle here, any

906
00:52:53,320 --> 00:52:59,600
particular links or pointers or places that you find are helpful for folks getting started?

907
00:52:59,600 --> 00:53:00,600
Yeah.

908
00:53:00,600 --> 00:53:06,880
Well, I'll kind of suggest that people visit the Clear Path Robotics Ross 101 series of

909
00:53:06,880 --> 00:53:10,800
tutorials, where we can help people get started on Ross.

910
00:53:10,800 --> 00:53:14,840
We have a little virtual machine, so you don't have to install Ubuntu on your home computer.

911
00:53:14,840 --> 00:53:17,480
You can kind of just run it virtually.

912
00:53:17,480 --> 00:53:21,600
And all of our robots are simulated there, along with sensors.

913
00:53:21,600 --> 00:53:26,520
So you could actually simulate, for example, Husky with a stereo camera, with a LiDAR,

914
00:53:26,520 --> 00:53:31,080
with an IMU, and move around a virtual map and start doing mapping, navigation, path

915
00:53:31,080 --> 00:53:34,840
planning, all of that for free on any laptop.

916
00:53:34,840 --> 00:53:36,560
Oh, that's amazing.

917
00:53:36,560 --> 00:53:38,640
I'm definitely going to have to do that.

918
00:53:38,640 --> 00:53:40,760
Well, you brought up simulation.

919
00:53:40,760 --> 00:53:44,800
That's a topic that I want to dig into also, but I fear we are bumping up against

920
00:53:44,800 --> 00:53:51,080
a time constraint here, so I'm going to save that for another conversation.

921
00:53:51,080 --> 00:53:56,560
But thank you so much for taking the time to speak with me about your work.

922
00:53:56,560 --> 00:54:03,200
It is really fascinating stuff that kind of speaks to the, you know, the kid geek playing

923
00:54:03,200 --> 00:54:06,360
with Legos and trying to make stuff automated.

924
00:54:06,360 --> 00:54:08,480
I really appreciate you taking the time out.

925
00:54:08,480 --> 00:54:09,480
Absolutely.

926
00:54:09,480 --> 00:54:10,480
Thank you very much.

927
00:54:10,480 --> 00:54:11,480
All right.

928
00:54:11,480 --> 00:54:19,360
All right, everyone, that's our show for today.

929
00:54:19,360 --> 00:54:24,520
Thanks so much for listening and for your continued support, comments, and feedback.

930
00:54:24,520 --> 00:54:29,000
We're excited to hear what you think about this show and the industrial AI series we've

931
00:54:29,000 --> 00:54:30,960
just kicked off.

932
00:54:30,960 --> 00:54:35,560
I'd also like to thank our sponsor, Banzai, once again, be sure to check out what they're

933
00:54:35,560 --> 00:54:39,120
up to at vons.ai.

934
00:54:39,120 --> 00:54:43,720
Speaking of Banzai, they'll also be at the O'Reilly AI conference in New York City later

935
00:54:43,720 --> 00:54:45,080
this month.

936
00:54:45,080 --> 00:54:51,880
If you'd like to attend, you can save 20% on registration by using our special code PC

937
00:54:51,880 --> 00:54:55,480
Twimble, PC-TW-I-M-L.

938
00:54:55,480 --> 00:54:59,880
We'll include the code and a link to the registration page in the show notes.

939
00:54:59,880 --> 00:55:02,440
I'd love to meet up with listeners at the conference.

940
00:55:02,440 --> 00:55:07,600
In fact, I'm planning a community meetup during the event and I'll share details as soon

941
00:55:07,600 --> 00:55:09,840
as they've been ironed out.

942
00:55:09,840 --> 00:55:16,280
As usual, the notes for this episode can be found at twimbleai.com slash talk slash

943
00:55:16,280 --> 00:55:18,400
27.

944
00:55:18,400 --> 00:55:23,440
For information on industrial AI, my report on the topic or the industrial AI podcast

945
00:55:23,440 --> 00:55:28,360
series, visit twimbleai.com slash industrial AI.

946
00:55:28,360 --> 00:55:32,560
As always, remember to post your favorite quote or takeaway from this episode and we'll

947
00:55:32,560 --> 00:55:34,840
send you a laptop sticker.

948
00:55:34,840 --> 00:55:38,920
You can post them as comments to the show notes page via Twitter, you are following us

949
00:55:38,920 --> 00:55:42,960
at at Twimbleai, aren't you, or via our Facebook page.

950
00:55:42,960 --> 00:56:10,200
Thanks again for listening and catch you next time.

