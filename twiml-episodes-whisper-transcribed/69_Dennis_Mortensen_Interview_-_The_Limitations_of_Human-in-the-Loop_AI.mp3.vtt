WEBVTT

00:00.000 --> 00:15.920
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

00:15.920 --> 00:20.880
people doing interesting things in machine learning and artificial intelligence.

00:20.880 --> 00:23.320
I'm your host Sam Charrington.

00:23.320 --> 00:28.320
Once again, let's start the show by sending some love out to you, the listeners for your

00:28.320 --> 00:32.440
continued support over the last few weeks and months.

00:32.440 --> 00:38.480
This community continues to amaze us, continues to grow and to engage with us, which we love

00:38.480 --> 00:39.480
to see.

00:39.480 --> 00:44.360
We've said it before, but please don't hesitate to reach out to us with any questions,

00:44.360 --> 00:50.320
comments, guest or topic requests or just a friendly hello via any of our various channels.

00:50.320 --> 00:54.360
You can reach us on our Facebook page or Twitter at Twimble AI.

00:54.360 --> 01:02.240
You can reach me directly at Sam Charrington on Twitter or you can email us at teamattwimbleia.com.

01:02.240 --> 01:07.920
Speaking of community, please take note, the next Twimble online meetup is coming up soon.

01:07.920 --> 01:15.360
On Tuesday, November 14, at 3pm Pacific time, we'll be joined by Kevin T, who will be presenting

01:15.360 --> 01:20.920
his paper active preference learning for personalized portfolio construction.

01:20.920 --> 01:24.920
If you've already registered for the meetup, you should have received an invitation with

01:24.920 --> 01:26.560
all the details.

01:26.560 --> 01:32.520
If you still need to sign up, just head on over to twimbleia.com slash meetup to do so.

01:32.520 --> 01:34.040
We hope to see you there.

01:34.040 --> 01:39.280
Now, as you may know, a few weeks ago we spent some time in New York City hosted by our

01:39.280 --> 01:42.400
friends at NYU Future Labs.

01:42.400 --> 01:47.000
About six months ago, we covered their inaugural AI Summit, an event they hosted to showcase

01:47.000 --> 01:52.360
the startups in their first batch of their AI Nexus Lab accelerator program, as well as

01:52.360 --> 01:55.840
the impressive AI talent in the New York City ecosystem.

01:55.840 --> 02:00.520
Well, this time we had the pleasure of interviewing the four startups from the second AI Nexus

02:00.520 --> 02:07.040
Lab batch, Mount Cleverist, Bite AI, Second Mind, and Bowtie Labs.

02:07.040 --> 02:11.000
We also interviewed some of the great speakers from the event, and we're presenting a couple

02:11.000 --> 02:14.000
of those interviews to you this week.

02:14.000 --> 02:20.360
If you missed any of the shows in the series, visit twimbleia.com slash AI Nexus Lab 2 to

02:20.360 --> 02:21.760
get caught up.

02:21.760 --> 02:29.000
My guess this time is Dennis Mortensen, founder and CEO of x.ai, a company whose AI-based

02:29.000 --> 02:33.480
personal assistant Amy helps users with scheduling meetings.

02:33.480 --> 02:38.160
I caught up with Dennis backstage at the Future Labs event a few weeks ago, right before

02:38.160 --> 02:43.280
he went on stage to talk about investing in AI from the startup point of view.

02:43.280 --> 02:48.480
Dennis shares some great insight into building an AI first company, not to mention his vision

02:48.480 --> 02:53.040
for the future of scheduling, something no one actually enjoys doing, and his thoughts

02:53.040 --> 02:55.960
on the future of human AI interaction.

02:55.960 --> 02:59.720
This was a really fun interview, which I'm sure you'll enjoy.

02:59.720 --> 03:05.040
A quick warning though, this might not be the show to listen to in the car with the kiddos,

03:05.040 --> 03:08.440
as this episode does contain a few expletives.

03:08.440 --> 03:17.560
And now on to the show.

03:17.560 --> 03:21.920
Alright everyone, I'm here at the NYU Scurple Center, where the Future Labs group is having

03:21.920 --> 03:26.720
their AI Summit, and I've got the pleasure of being backstage with Dennis Mortensen,

03:26.720 --> 03:31.440
the founder and CEO of x.ai, Dennis, welcome to the podcast.

03:31.440 --> 03:32.440
Thanks much for having me.

03:32.440 --> 03:34.080
It's great to have you on the show.

03:34.080 --> 03:38.240
Why don't we get started by having you tell us a little bit about your background and

03:38.240 --> 03:39.800
what the company's up to?

03:39.800 --> 03:40.800
Sure.

03:40.800 --> 03:41.800
Background.

03:41.800 --> 03:43.320
So that's the four hour version, right?

03:43.320 --> 03:44.320
Exactly.

03:44.320 --> 03:47.840
How do you find your way into AI?

03:47.840 --> 03:55.160
So we've, sadly, because we are getting older, been at it for about twenty-three years.

03:55.160 --> 04:02.040
This is our fifth venture, and they've all had really a backdrop in data, and I think

04:02.040 --> 04:07.120
we've been able to massage data from the mid-90s all the way up to this point for

04:07.120 --> 04:08.120
way.

04:08.120 --> 04:12.680
If you really want to massage data in the year 2017, AI is probably the right moniker to

04:12.680 --> 04:14.040
apply to that.

04:14.040 --> 04:19.160
So in our prior venture, we did predictive analytics for media, trying to predict which

04:19.160 --> 04:23.960
stories to carry where, say, on the home page of CNN, and for how long, and when you kill

04:23.960 --> 04:26.880
it, what other story do we put in its place?

04:26.880 --> 04:30.920
And before that, we did an enterprise web analytics company.

04:30.920 --> 04:35.480
So go to four seasons, how do you make sure they sell as many rooms as possible, and you

04:35.480 --> 04:37.200
try to analyze that data?

04:37.200 --> 04:42.000
So certainly, just a lifetime around data, and we're very fond of that.

04:42.000 --> 04:44.880
And you're saying, we, so this is a team of people that have kind of stuck together

04:44.880 --> 04:46.400
across these five companies or so.

04:46.400 --> 04:52.440
So we've certainly carried over team members from one venture to the next, and there's

04:52.440 --> 04:57.840
suddenly some comfort in knowing that when I'm up here with you, the house is not at

04:57.840 --> 04:59.480
fire at home, right?

04:59.480 --> 05:04.000
Because, hey, I've talked to these guys for the last ten years, at least.

05:04.000 --> 05:09.200
And for this particular venture of x.ai, it's not so much that we're an AI company.

05:09.200 --> 05:15.720
I think we are, but it's more that we've latched on to this, I think, very obvious pain

05:15.720 --> 05:16.920
of setting up meetings.

05:16.920 --> 05:19.120
So it's not that we kind of invented that pain.

05:19.120 --> 05:24.200
I think both you and I figured out exactly two hours out of college that if you go to work,

05:24.200 --> 05:25.200
you set up meetings.

05:25.200 --> 05:28.160
And when you set up meetings, you're not going to get a personal assistant.

05:28.160 --> 05:29.160
It's you.

05:29.160 --> 05:30.160
Are you?

05:30.160 --> 05:31.160
You're going to fucking hate it.

05:31.160 --> 05:33.960
And then you do it for 20 years straight.

05:33.960 --> 05:42.000
And that just doesn't ring true to me, as in, do I do that task for the next 20 years?

05:42.000 --> 05:46.200
So I think that was perhaps the catalyst to say, hey, there might be this opening for

05:46.200 --> 05:52.480
where some intelligent agent can come along and just remove this one particular chore.

05:52.480 --> 05:56.560
And we then spent the last four years trying to engineer that intelligent agent, a me at

05:56.560 --> 05:57.560
x.ai.

05:57.560 --> 06:01.080
So then when you email me saying, hey, Dennis, I'm downtown.

06:01.080 --> 06:04.960
You've got time to meet up for a Diet Coke, I can reply back and say, yeah, I'm up for

06:04.960 --> 06:05.960
that.

06:05.960 --> 06:06.960
I have C.C.

06:06.960 --> 06:07.960
didn't.

06:07.960 --> 06:08.960
Amy.

06:08.960 --> 06:09.960
And she can help put something on my calendar.

06:09.960 --> 06:14.520
It is now her job to remove me from the conversation, reach out to you.

06:14.520 --> 06:19.880
Have this very human-like negotiation, really, drive it towards conclusion and upon conclusion

06:19.880 --> 06:20.880
send us an invite.

06:20.880 --> 06:23.120
And it's not that you haven't seen it before.

06:23.120 --> 06:24.520
You can buy it today if you want to.

06:24.520 --> 06:26.440
It's just cost you $60,000 a year.

06:26.440 --> 06:27.440
And it's called Tom.

06:27.440 --> 06:32.120
You should have come to the office on Monday, but if you want to pay $17 instead, you should

06:32.120 --> 06:33.120
hire you.

06:33.120 --> 06:34.120
Yeah.

06:34.120 --> 06:35.120
Nice.

06:35.120 --> 06:36.120
Nice.

06:36.120 --> 06:37.120
And you've been at it for four years.

06:37.120 --> 06:38.120
Can people sign up for it publicly for a while?

06:38.120 --> 06:41.560
It was like in by the only or something along those lines, right?

06:41.560 --> 06:42.560
Very much so.

06:42.560 --> 06:49.800
So we spent perhaps short of the first three years doing core R&D, but this is one of those

06:49.800 --> 06:50.800
products for way.

06:50.800 --> 06:54.280
If there's no pre-existing data set, you're going to have that chicken and egg challenge,

06:54.280 --> 06:55.280
right?

06:55.280 --> 06:58.320
I need the product out there to collect some data, but I can't have the product out there

06:58.320 --> 07:00.000
because I don't have any data.

07:00.000 --> 07:08.400
So we had this suddenly very early, early, early data that we ran with for years that became

07:08.400 --> 07:09.800
more and more robust.

07:09.800 --> 07:14.560
And the whole thing was based on a free wait list and we were so fortunate that people

07:14.560 --> 07:16.880
immediately kind of recognized the pain and signed up for it.

07:16.880 --> 07:19.960
We had a very long wait list and that's always nice.

07:19.960 --> 07:26.560
But early this year, we commercialized that R&D and put it to market and now I've been

07:26.560 --> 07:33.600
in market for short of three quarters and I just about to kind of tune our product tiers

07:33.600 --> 07:39.520
and pricing just ever so slightly, but suddenly, off to the races, trying to pay back our

07:39.520 --> 07:40.520
investors.

07:40.520 --> 07:41.520
Nice.

07:41.520 --> 07:42.520
Very nice.

07:42.520 --> 07:48.160
You know, one of the dirty secrets, if you will, of AI is that at least people outside

07:48.160 --> 07:50.840
of the industry think it's just the computer is doing the work.

07:50.840 --> 07:54.880
I'm imagining there's a significant human and a loop component to what you're doing.

07:54.880 --> 07:57.720
Can you tell me, you know, how much of a row, a row that plays?

07:57.720 --> 07:58.720
Sure.

07:58.720 --> 08:05.400
I think there's a difference between what you're trying to achieve and there's nothing wrong

08:05.400 --> 08:10.560
with a human and loop and there's not even anything wrong with a human and loop forever.

08:10.560 --> 08:15.720
That's called automation or augmenting the humans that they can do a job slightly faster,

08:15.720 --> 08:18.120
slightly more accurate and so on and so forth.

08:18.120 --> 08:20.280
I think you need to decide what you want to be.

08:20.280 --> 08:27.040
Do I want to be a, if you're in the self-driving car space, a BMW with slightly better lane

08:27.040 --> 08:33.280
control or do I want to be way more with a fully autonomous vehicle in place, perhaps,

08:33.280 --> 08:34.280
in a decade from now?

08:34.280 --> 08:39.040
But I don't think you can work on both at the same time though, because they're somewhat

08:39.040 --> 08:47.240
in conflict and we set out to create the fully autonomous agent from day one or die-trying.

08:47.240 --> 08:52.040
Investors fucking hate it when I say that out loud, that's in, there is no plan B here.

08:52.040 --> 08:56.520
And I think the difference is between one of you having a fallback for where there's

08:56.520 --> 09:01.080
something here which you didn't understand or didn't predict at a level of accuracy

09:01.080 --> 09:03.880
for where you're willing to move forward in a fully autonomous way.

09:03.880 --> 09:08.360
So you now send it back to a human, we need to kind of resolve that.

09:08.360 --> 09:15.400
Or you have not a fallback, but a willingness to make errors and simply just label the

09:15.400 --> 09:19.200
data and then upon those errors figure out how can I make that prediction slightly more

09:19.200 --> 09:20.840
accurate tomorrow?

09:20.840 --> 09:24.640
So we're not a self-driving car, that means self-driving cars probably don't have much room

09:24.640 --> 09:26.240
for errors.

09:26.240 --> 09:32.400
Perhaps some versions of an error which is that you stop or go to the side or anything

09:32.400 --> 09:33.400
that rhymes with that.

09:33.400 --> 09:35.480
What are you going to do as mess up my lunch tomorrow?

09:35.480 --> 09:36.480
Yeah, exactly.

09:36.480 --> 09:41.560
And I might even churn you as a customer and I would hate for that to kind of happen,

09:41.560 --> 09:44.800
but I'm allowed to make mistakes here.

09:44.800 --> 09:48.680
So we've always hunted the idea of the fully autonomous agent.

09:48.680 --> 09:54.640
And that means of that 150 people we have in place for the team right now, about a hundred

09:54.640 --> 09:55.640
to answer your question.

09:55.640 --> 09:57.360
So I'm not trying to avoid it.

09:57.360 --> 10:02.640
About a hundred of that 150 does nothing but label data.

10:02.640 --> 10:04.120
But I think there's a distinction here between-

10:04.120 --> 10:07.880
But they're not labeling exceptions in the loop of the customer query.

10:07.880 --> 10:12.040
It's something that happens later and Amy does what she can to figure out.

10:12.040 --> 10:18.280
It's certainly happening in real time as well and it's happening as double annotation

10:18.280 --> 10:22.040
and it's happening with golden data sets where they label things that aren't even part

10:22.040 --> 10:23.880
of a real customer query.

10:23.880 --> 10:30.000
But all of this for this purpose of being able to come out tomorrow with a slightly more

10:30.000 --> 10:31.520
accurate set of predictions.

10:31.520 --> 10:32.520
Sure.

10:32.520 --> 10:33.520
Sure.

10:33.520 --> 10:38.640
And that's going to be going from zero data to millions of emails annotated over the

10:38.640 --> 10:45.600
last three years and that becomes that corpus for where we can wake up one day and essentially

10:45.600 --> 10:50.640
have this all margin type of software which we can then be in market with.

10:50.640 --> 10:51.640
Yeah.

10:51.640 --> 10:56.280
So what's the- I mean if you do have two thirds of your team doing annotation and some

10:56.280 --> 11:01.200
of that is real time just like a company that might describe that as human in the loop,

11:01.200 --> 11:06.760
what are the key distinctions between you know building a company kind of with the idea

11:06.760 --> 11:11.160
that you're going to do that and building a company that you know does that but at

11:11.160 --> 11:13.640
horse every minute of it?

11:13.640 --> 11:20.160
I think certainly the difference is that if you have kind of this split setting for

11:20.160 --> 11:22.000
where you have a human in the loop.

11:22.000 --> 11:27.200
The human then many times is tasked to make a perfect outcome.

11:27.200 --> 11:29.720
Whatever the implication might be on your data set.

11:29.720 --> 11:30.880
Just make the perfect outcome.

11:30.880 --> 11:33.920
I said right now just swing the card to the left.

11:33.920 --> 11:35.840
I don't really care what that means to our data set.

11:35.840 --> 11:38.120
Just swing the card to the left.

11:38.120 --> 11:43.080
When we label data there'll be a set of intents, there'll be some entities that we try to

11:43.080 --> 11:49.520
extract but even as they see those entities either not being there or being labeled

11:49.520 --> 11:52.440
so that the outcome is wrong they still move forward.

11:52.440 --> 11:56.920
I said now I'll drive that car into a wall and I'm putting this in the air force and

11:56.920 --> 12:00.600
nobody can see this but their job is not to swing the car to the left.

12:00.600 --> 12:05.440
That is to drive it into the wall and say I labeled it as we've agreed.

12:05.440 --> 12:09.520
And the machinery still took a decision which was not optimal but the only way we can

12:09.520 --> 12:14.080
kind of learn from that is if I label it per the guidelines.

12:14.080 --> 12:20.000
So that's the difference between going all McKinsey style on automating a workforce to

12:20.000 --> 12:26.280
do a job much faster and that of trying to train or create a corpus of data where you

12:26.280 --> 12:29.680
can have this autonomous agent kind of operate.

12:29.680 --> 12:35.320
So I'm hearing that as there's a difference between labeling and having a CSR jump in

12:35.320 --> 12:37.280
and fix a situation and get it right.

12:37.280 --> 12:42.280
And labeling is kind of you know you're positioning it as the longer term approach but certainly

12:42.280 --> 12:50.280
is one that contributes more towards generating a bigger you know better data set whereas

12:50.280 --> 12:55.440
having the CSR jump in and you know provide the right answer when the AI gets stuck might

12:55.440 --> 12:59.080
not necessarily contribute to the long term solution.

12:59.080 --> 13:02.800
Couldn't agree more and it's not that there's anything wrong with that.

13:02.800 --> 13:06.960
I said you can create a formidable business on humans in the loop I said that exists

13:06.960 --> 13:11.920
everywhere in the world call a taxi and there's a human in that car right so that exists

13:11.920 --> 13:14.000
today all over the place.

13:14.000 --> 13:18.080
My point from very early on was just that I think you have to make up your mind whether

13:18.080 --> 13:23.120
you want to be one or the other the day you start because they are in conflict and it's

13:23.120 --> 13:30.120
very easy to fall in love with the perfect outcome because it hurts less on the way there

13:30.120 --> 13:35.800
so I've suddenly had emails in my inbox that have disappointment included into them.

13:35.800 --> 13:40.000
That's the most polite way I can put it where Amy made a mistake she shouldn't have made

13:40.000 --> 13:43.960
and the funny thing about machine mistakes and you know this obviously is that machine

13:43.960 --> 13:48.200
mistakes don't look like human mistakes so if you email me and you and I have a dialogue

13:48.200 --> 13:52.720
back and forth and there's a little bit of ambiguity in the way you put it you can empathize

13:52.720 --> 13:57.560
with my decision I said oh right I see where Dennis came from on that decision but machines

13:57.560 --> 14:03.080
make different type of mistakes for where it is much harder to empathize that's it that

14:03.080 --> 14:07.480
is just so obvious I said why didn't you get that right because there's a difference

14:07.480 --> 14:13.000
in the machine and you trying to kind of resolve what's being said here and that means

14:13.000 --> 14:19.560
little things for where tonight at 1 a.m. you send me an email saying hey Dennis I got something

14:19.560 --> 14:25.080
super important which you meet up tomorrow and talk it through the machine might just really

14:25.080 --> 14:30.600
do that tomorrow but that's not what you're trying to do you wanted today you're just so excited

14:30.600 --> 14:34.840
that you stayed up late and then you want to meet Dennis in eight hours from now right and that

14:34.840 --> 14:39.800
seems like a silly machine mistake I said you saw the importance couldn't you feel the importance

14:39.800 --> 14:46.120
in that email and then I wanted to meet with you in eight hours yeah so that is kind of the

14:46.120 --> 14:50.920
interesting dilemma the way but we've been taking those punches to the face for three years

14:50.920 --> 14:56.280
and we stick into it yeah and so I am imagining your response to this but based on the

14:56.280 --> 15:02.120
the previous conversation around human and loop but for that particular type of error and those

15:02.120 --> 15:08.840
like it is the answer labeling more data or is the answer developing some kind of front-end

15:08.840 --> 15:15.960
set of human heuristics that can help guide the AI down the right path so that's a really good

15:15.960 --> 15:21.960
question so I think people see this as a single problem but it's probably kind of a set-up

15:21.960 --> 15:28.520
problem and I think if you were to simplify it perhaps there's the initial natural language

15:28.520 --> 15:34.600
understanding challenge which is not kind of a solved science and the only hope we have is that we

15:34.600 --> 15:39.640
picked a space so narrow that we might be able to understand everything which is being talked about

15:39.640 --> 15:45.160
when we talk about meetings right but even as you saw that that is certainly a place for where

15:45.160 --> 15:53.880
many times what we just need is more data as in there's things in our little universe here that

15:53.880 --> 15:59.400
happens so rare that the data set is still so sparse and give you an example so a new meeting

15:59.400 --> 16:04.440
intent for the very definition that a meeting is about to happen that happens in every single

16:04.440 --> 16:09.480
meeting that we set up so that means we have a ton of new meeting intent data as in you can say

16:09.480 --> 16:14.680
pretty much what you want hedonist let's do the hoki boki calm early next week we understand that

16:14.680 --> 16:19.160
being you wanting to set up a new meeting but you're trying to change the pin code to the conference

16:19.160 --> 16:24.600
call happens one out of 10,000 meetings so do a hundred thousand meetings and I have 10 data points

16:25.240 --> 16:31.400
as in that is so sparse it's not about any type of model which I might put in place as in there's

16:31.400 --> 16:35.720
just not enough data really to take any good decisions here so that is something for we can certainly

16:35.720 --> 16:41.320
see we just need to keep turning through more meetings and we can see that kind of the level of

16:41.320 --> 16:46.280
accuracy continues to increase so that's the one challenge and then if you do understand what's

16:46.280 --> 16:52.440
being said I said that NLU engine you put in place is robust and backed by a very large data set

16:52.440 --> 16:58.760
you need to have some sort of reasoning engine in place for where you email Amy at x3a and say hey

16:58.760 --> 17:03.640
I'm going to be running five minutes late if I understand it that doesn't mean I know what to do

17:03.640 --> 17:09.400
with it do I do nothing do I do something if I do something what is that something what does that

17:09.400 --> 17:16.200
look like that is where as you alluded to there's a lot of design where I can help

17:17.080 --> 17:23.080
take you down a dialogue path which is more likely to end up in a successful outcome versus

17:23.080 --> 17:28.280
another dialogue path for where it is less likely to end up in a successful outcome and we can

17:28.280 --> 17:35.480
certainly see and this sounds devious and it's not that if we help direct people down one avenue

17:35.480 --> 17:39.560
we're both going to end up slightly happier certainly more likely to end up slightly happier

17:40.280 --> 17:45.720
and then in the end if you take some action in your reasoning engine that is some sort of

17:45.720 --> 17:51.480
computational outcome then you need some NLG engine that can take that computational outcome

17:51.480 --> 17:57.080
and turn it into language so we can communicate clearly to all the constituents that is also a

17:57.080 --> 18:03.320
place where we found that we thought it was clear what we just communicated but given that the

18:03.320 --> 18:09.960
conversational UI is somewhat of a new UI perhaps not to you and I who started on the command line

18:09.960 --> 18:14.040
but certainly to many people in the middle of a way they grew up in the graphical use interface

18:14.040 --> 18:24.200
they don't have some inner connection to the conversation UI and that have been just a long

18:24.200 --> 18:29.800
optimization path trying to figure out exactly how to put it and you describe that last step as

18:29.800 --> 18:36.200
NLG to what extent is it real kind of NLG versus picking from a list of predefined things

18:37.080 --> 18:43.560
we don't think there's a decision tree of sorts for where if I just do every single branch

18:43.560 --> 18:49.960
and have enough templates in place I can find that template the matches that particular setting

18:49.960 --> 18:55.560
that I ended up on so we've tried to create and I'm certainly not saying that we solved it

18:55.560 --> 19:00.520
but the only way that we can be so ambitious is again we picked a single vertical

19:00.520 --> 19:04.680
meaning that you can talk all you want about Chelsea Football Club winning the premiership

19:04.680 --> 19:10.120
next year we don't have any idea but if you talk about meetings we can generate

19:10.120 --> 19:15.560
tricky fluid responses that are created on the fly and the reason that we need that is that

19:16.280 --> 19:22.200
even though meeting sounds sounds almost simple they're just not because you talk about

19:22.200 --> 19:29.160
multiple times in multiple ways well multiple participants some mandatory some optional some assistance

19:29.720 --> 19:35.480
sure and not to get it even get into all the rescheduling and the moving locations and all of that

19:35.480 --> 19:39.560
and you don't follow the path that we sit forth and that means sometimes we need to talk about

19:39.560 --> 19:44.840
fewer things sometimes I need to talk about multiple things at the same time so we assemble those

19:44.840 --> 19:52.280
on the fly and I've been kind of forced to build this kind of design setting so if you want

19:52.280 --> 19:57.880
some sort of visual output you know you and me will go install Photoshop and for other tools

19:57.880 --> 20:03.720
and we'll end up with some pallet of little sprites that we can use for that kind of output

20:04.280 --> 20:12.040
where do you design conversational UIs I said not in word but where right now you're building

20:12.040 --> 20:16.360
your own thing to do it right you're building your own thing and the same as he goes for the

20:16.360 --> 20:21.960
front of it here on the labeling and where do you label your data I said hopefully not in Excel

20:21.960 --> 20:26.520
so you're going to label it somewhere else so you build your own kind of labeling piece of software

20:27.000 --> 20:35.160
so those NLG scripts and scripting that we've invented was some sort of amalgamation of raw text

20:35.160 --> 20:40.600
and JavaScript and our own little version of JavaScript is how we can generate these responses

20:40.600 --> 20:48.680
hmm interesting but even they can given that they are programmatic end up sometimes not sound obvious

20:48.680 --> 20:54.520
I said why does he say that I said that's not even a proper sentence I know I'm also sorry

20:54.520 --> 20:57.960
but it's because we're trying to generate on the fly we actually don't know what it looks like

20:57.960 --> 21:04.360
until she starts talking and you English only currently or multiple languages English only okay

21:04.360 --> 21:12.440
okay we are you're you're kind of sighing back in the chair so no that is a big problem it sounds

21:12.440 --> 21:17.240
like so we have really three dimensions for where we're going to go expand and the reason I do the

21:17.240 --> 21:26.120
kind of slight sign because it was so visual is that whenever we raised another $2 in capital we

21:26.120 --> 21:32.040
immediately get the hey when are you going to do more languages we could talk about the challenge

21:32.040 --> 21:37.000
in that to when are you going to do more communication channels and we can talk about the challenge

21:37.000 --> 21:41.880
in that we will most certainly do both of them we want the agent to be multilingual

21:42.680 --> 21:47.480
not just so we can attack other markets but so that we can better serve the guest

21:48.200 --> 21:52.920
so we set up meetings at about 190 countries today but we really only have customers

21:53.640 --> 21:59.080
in English speaking nations but they meet up with people all over the world so for me up with

21:59.080 --> 22:05.560
somebody in Germany I could actually remove some of the ambiguity for spoken in his own language

22:06.360 --> 22:11.720
so we most certainly will do that and then the last one is that we want to make those obvious

22:11.720 --> 22:18.200
integrations into things that revolve around the event itself say whenever you meet up with

22:18.200 --> 22:24.440
somebody in midtown you use Uber one she set up the meeting two she know where is that three

22:24.440 --> 22:29.480
do you know why you office is that why do I have to kind of click for the Uber you can just make

22:29.480 --> 22:33.240
it happen or even better why do I have to spend an hour and yelp trying to figure out where we're

22:33.240 --> 22:38.360
going to meet those little things where hey you know I eat at Harasushi whenever I meet up with

22:38.360 --> 22:43.080
people just book the table it's not rocket science right right so those are certainly three

22:43.080 --> 22:50.520
dimensions but to say it's all email all English very few integrations okay and you mentioned

22:50.520 --> 22:56.440
some of the challenges on the language side is it all like doing it all over again certainly

22:56.440 --> 23:02.280
there are some economies of scale and you have to see the face that associates this question in

23:02.280 --> 23:08.840
particular this not you but certainly other people are from the outside if they haven't thought

23:08.840 --> 23:13.480
about it for more than a few minutes immediately just let's on to oh so it's just about kind of

23:13.480 --> 23:21.000
translating your templates first of all search and replace yeah yes sorry you did not respond to

23:22.600 --> 23:30.760
Google translation yeah so I think there's two parts to it that's certainly the fact that we might

23:31.960 --> 23:41.560
have to train on a local data set I said the way you set up meetings in northern Europe versus

23:41.560 --> 23:49.000
southern Europe or the Caribbean or Asia might actually just be slightly different it could just

23:49.000 --> 23:55.240
be that northern Europe we are super direct we press slightly more casual and I'm saying that as

23:55.240 --> 24:01.080
an insults if we go to southern Europe we might just have little cues in Asia that we don't have

24:01.080 --> 24:09.000
in the US and if I don't pick up on that I might not have the intelligent agent I had hope for

24:09.000 --> 24:15.000
in a different language so that's certainly should yes we might have to train on a local

24:15.000 --> 24:20.520
data set I'm imagining a country where you know the level of politeness maybe Japan might be an

24:20.520 --> 24:26.040
example this is so high that you know someone says okay that means they don't really want that time

24:26.040 --> 24:30.680
that's just their way of not so not to offend the Japanese we might even cut this whole segment

24:32.360 --> 24:36.520
so now I'll give you something where both you and I are involved so it's only you and I we are

24:36.520 --> 24:42.760
insulting now yeah so I'm Danish I assume you're American yeah and here's the thing we don't do

24:42.760 --> 24:50.200
in northern Europe so you and me can set up a meeting for May 17th next year at my office and you'll

24:50.200 --> 24:56.200
never hear from me I will just assume you turn up at my office and it's all good here's what most

24:56.200 --> 25:03.560
Americans do confirm triple confer so you knew it already three weeks prior to the meeting hey Dennis

25:03.560 --> 25:08.120
just checking in I'll see you in about three weeks the day before Dennis see you tomorrow one

25:08.120 --> 25:14.280
o'clock the first time I'll do the yeah I know it's on my calendar the third time I have yeah

25:15.000 --> 25:20.040
I fucking know which I'm on this like four times now and the funny thing is that we've actually had

25:20.040 --> 25:27.960
to engineer for that in our solution because as you double confirm there's many things which you

25:27.960 --> 25:33.800
say in that that rhyme with the reschedule so we need to be very good at picking up on the fact that

25:33.800 --> 25:38.920
all you're doing here it's just giving me a thumbs up one of the signs that we've done to kind of

25:38.920 --> 25:44.440
protect against that is that Amy learned this skill as well which is that she will reach out knowing

25:44.440 --> 25:49.560
that we set up the meeting a long time ago and you are American so prior to the meeting happening

25:49.560 --> 25:54.600
she'll reach out and say hey just give me your thumbs up the meetings for tomorrow at one o'clock

25:54.600 --> 25:58.920
if there's no changes I'll assume you're both all good and set she'll have a better language than

25:58.920 --> 26:04.200
that so that is one of those interesting things for me just do that for the American and

26:04.200 --> 26:10.520
seems that the Northern European is good so right now she does it for everybody and we haven't

26:10.520 --> 26:16.920
had any complaint for where hey don't be so overly anal they're just taking it you know that's

26:16.920 --> 26:21.400
that but I can totally imagine and that brings me to the second part of the language challenge

26:21.400 --> 26:25.720
outside of being able to train a new data set which is what I alluded to here is that there's

26:25.720 --> 26:31.560
probably some product design choices that you need to make for the particular market that you're in

26:31.560 --> 26:38.280
example take our reminder logic so I see see an Amy to set up a meeting between you and I say

26:38.280 --> 26:44.040
for Friday you are slightly tidy or busy you're here today right doing all sorts of things

26:44.040 --> 26:50.920
how quick can Amy not you so we can certainly see East Coast US you can be reasonably aggressive

26:51.880 --> 26:57.000
we can certainly also see that's even just within the US there's other places for where

26:57.000 --> 27:02.440
people are not as comfortable in her reasoning out as quick as she's doing I said she's a little

27:02.440 --> 27:10.680
bit too bossy for them yeah and certainly people in New York sure still let's do this but there's

27:10.680 --> 27:15.400
certainly other places where that is not the case do you find it all that people that people try to

27:15.400 --> 27:21.000
give Amy the kind of advice that they might give an actual assistant like hey Amy you need to tone

27:21.000 --> 27:27.400
it down a little bit or that kind of thing or to what extent does Amy blur the lines between a

27:27.400 --> 27:34.280
virtual assistant like virtual assistants overloaded but yeah an AI and a human that's a very

27:34.280 --> 27:41.560
interesting question now I'm not sure you me or anybody really got the answer just yet what I

27:41.560 --> 27:47.480
don't think you should do and certainly not something which we're trying to do is to play a game

27:47.480 --> 27:53.560
of daily twining tests for where you try to fool people into believing that this is a human

27:53.560 --> 27:58.840
I'm finding it hard to figure out what you win on each one of those tests sure you can have a

27:58.840 --> 28:04.200
little bit of a ha ha moment and a little bit of social fun and that's that really probably just make

28:04.200 --> 28:10.120
your make the job harder for yourself the next time that is exactly what is happening so we try

28:10.120 --> 28:15.640
very hard to be upfront and honest about the fact that this is machinery but do the job so well

28:16.280 --> 28:23.160
that you kind of forget or don't care now let's give you one stat here that we did early on

28:23.160 --> 28:30.120
so in 11% of all the meetings which we do at least one of the emails in that dialogue will have

28:30.120 --> 28:36.680
one intent only gratitude as in somebody emailed Amy back saying thank you or appreciate you setting

28:36.680 --> 28:43.800
this up for Friday so sorry for not getting back to you earlier even people like me I bloody work

28:43.800 --> 28:51.720
there will start out my kind of handovers with Amy would you be so kind and it's not that I don't

28:51.720 --> 28:58.280
know what's going on here but that is interesting and we're still so early that that's probably

28:58.280 --> 29:04.440
going to be a half decade for we fumble a little bit until we figure out what is the right design

29:04.440 --> 29:10.840
for this new setting for we have kind of mixed agents some human some machine have you ever thought

29:10.840 --> 29:16.280
about whether in that particular example you're doing that for Amy or for the human that's on the

29:16.280 --> 29:24.680
other side of the email so there's some research that suggests in any master slave relationship

29:24.680 --> 29:31.400
if the master is acting in a aggressively demeaning way towards the slave it's actually not the

29:31.400 --> 29:36.840
slave who's losing it's the master and that's plenty of traditional research on that for where

29:36.840 --> 29:44.600
the more rude you turn over time the Saturday things really become for you and that's also why we

29:44.600 --> 29:49.800
have these early suggestions for where you should probably be kind to the Alexis and the series

29:49.800 --> 29:55.960
and the katanas of the world especially if you have kids around the house because you are in one

29:55.960 --> 30:01.160
way certainly asking a question but you're also teaching some other human being about how to behave

30:01.160 --> 30:07.160
in the world and there's certainly a thing missing right now for where they will not learn it otherwise

30:07.800 --> 30:12.760
if they don't learn it from you because there's no real penalties built into these systems yet

30:12.760 --> 30:18.840
which I think we need to have penalties for where like Amy talking back I don't think that's the

30:18.840 --> 30:24.600
right design but yes so I don't know who you think you're talking to Buster but I'm not

30:24.600 --> 30:29.720
scheduling anything for you if you talk to me like that well I couldn't get the point across

30:30.280 --> 30:35.400
that would get the point across I think if you walked into the team of AI interaction designers

30:35.400 --> 30:40.760
we have they would kind of say I hear you let's massage that a little bit and kind of see what we

30:40.760 --> 30:47.080
can do here but my point is certainly what aligns with what you said here for where say we pick a

30:47.080 --> 30:54.360
slightly more refined example for where you are really a super kind person but you kind of late

30:54.360 --> 31:00.680
all the time you're a little bit tardy still nice though that means as Amy is about to suggest

31:00.680 --> 31:06.280
you and me meeting up tomorrow if she knows that you're probably not gonna really be there for the

31:06.280 --> 31:13.160
8 a.m. like a third of the meetings you do you reschedule it's just who you are nice but tardy

31:13.160 --> 31:17.320
perhaps you should really just start out by suggesting how about we meet up at one worst case

31:17.320 --> 31:20.600
then you can just continue to work as inbox you didn't have to kind of get up early and be

31:20.600 --> 31:25.640
at the office for only to kind of sit there alone because you didn't get there and that is us

31:25.640 --> 31:33.080
taking into consideration that people are different here and what I want is even if you kind of

31:33.080 --> 31:40.520
perhaps even turn into an asshole perhaps the response speed just slows down as in she's super

31:40.520 --> 31:46.040
speedy you know machine speedy right but perhaps we'll put this on the cool a little bit

31:46.040 --> 31:49.880
I'll respond to you in half an hour and I'm not sure what those designs look like but I actually

31:49.880 --> 31:57.080
do think they eventually will have to emerge in these systems interesting interesting before

31:57.080 --> 32:01.880
we wrap up I want to go back to a comment that you made earlier about just about the different

32:01.880 --> 32:06.520
machinery the different tools that you've had to build on your own I've talked to several

32:07.080 --> 32:12.040
companies in the conversational space over the past few days and everyone's building the same

32:12.040 --> 32:19.960
things right everyone has you know they started off they tried wit.ai api.ai you know the kind of

32:19.960 --> 32:25.800
the black box nature of those platforms didn't work out for them you know you're saying similar

32:25.800 --> 32:31.000
things you know the platform itself plus all of the tooling that goes around you know labeling

32:31.000 --> 32:37.400
annotation is this all stuff that you think that everyone is doomed to reinvent for themselves

32:37.400 --> 32:43.000
or you know or is it the nature of the problem says that you know folks will want to create these

32:43.000 --> 32:50.120
things over and over or do you think the problem will eventually lend itself to a more of a platform

32:50.120 --> 32:58.920
type of an approach it depends on how loaded the word platform is I suddenly believe that

32:58.920 --> 33:09.160
the tooling will disappear as a task for the individual companies that doesn't ring true to me and

33:10.360 --> 33:18.680
I've been around long enough to see how the first mover were forced to make all sorts of choices

33:18.680 --> 33:23.240
for where they would go and implement things for where had they been a tool out there I wouldn't

33:23.240 --> 33:30.760
have been implementing that but there was no tool out there so that goes from any type of labeling

33:30.760 --> 33:38.520
or even any kind of NLG type design you would have to do I expect that type of tooling to arrive

33:38.520 --> 33:44.200
I'm actually even surprised that more people are not trying to attack the kind of AI space

33:45.160 --> 33:50.440
from that angle yeah and I haven't really seen anybody do anything but just do it for themselves

33:50.440 --> 33:55.560
for where well we might even want to when they spin that out and say hey here's a tool

33:56.280 --> 34:03.400
for where somebody else might be able to take advantage of that and go back say 30 years pretty

34:03.400 --> 34:11.160
much any Fortune 2000 would pretty much implement their own ERP system if you did that in 2017

34:11.160 --> 34:18.760
you'll be crazy you would install you know some Oracle people solve whatever type ERP and

34:18.760 --> 34:24.040
hopefully be happier with that so tooling I agree should and will be commercialized

34:24.760 --> 34:31.800
now on the generalized ability to kind of make predictions I think there's a difference

34:31.800 --> 34:38.840
between whether you being in a high accuracy or low accuracy space higher accuracy meaning that

34:38.840 --> 34:46.840
your product can't exist without a very high degree of accuracy in its predictions so a self-driving

34:46.840 --> 34:52.520
car cannot live with a footnote that suggests for every one thousand miles we hit a pedestrian

34:52.520 --> 34:57.320
even though that is a fantastic piece of software it just can't exist in market but there's

34:57.320 --> 35:03.960
only plenty of software for where hey I pick up 80% of the faces in all of the photos that you

35:03.960 --> 35:09.560
upload nice I said that's not too shabby I said that's really just you helping me out for where I

35:09.560 --> 35:14.520
don't need to kind of attack those faces in most of the images which I upload that's good and for

35:14.520 --> 35:20.600
that you should probably just go use clarify and that becomes I think a good platform play but I

35:20.600 --> 35:28.840
think right now if you cannot live with a kind of degree of error you probably have to forget

35:28.840 --> 35:34.680
how do I then go engineer my own high accuracy backdrop and the only way you can beat those

35:34.680 --> 35:40.280
platforms is by being super focused on some vertical way I'm just the guy who scheduled meetings

35:40.280 --> 35:45.800
right as we've optimized everything for that particular use case and there's not that we're

35:45.800 --> 35:52.120
necessarily smarter than the next guys just hyper focused so yes I do think that will arrive

35:52.920 --> 35:58.680
what I don't think will arrive is that you want to build something on Facebook messenger the tools

35:58.680 --> 36:08.360
which they provide will be all you need sure for some nifty few basic things but not for anything

36:08.360 --> 36:15.000
serious okay great well I really enjoy this conversation Dennis thanks so much for joining us

36:15.000 --> 36:18.200
this was fun we should do it again awesome thank you see you

36:23.080 --> 36:29.160
all right everyone that's our show for today thanks so much for listening and for your

36:29.160 --> 36:37.320
continued feedback and support for more information on Dennis x.ai or any of the topics covered in

36:37.320 --> 36:44.920
this episode head on over to twimmolai.com slash talk slash 67 we hope you've enjoyed our NYU

36:44.920 --> 36:51.880
future labs ai summit series if you need to catch up on any of the episodes visit twimmolai.com

36:51.880 --> 37:00.040
slash ai nexus lab 2 of course you can send along your feedback or questions via twitter to act

37:00.040 --> 37:07.400
twimmolai or at sam charrington or leave a comment or write on the show notes or series pages thanks

37:07.400 --> 37:12.680
again to future labs for their sponsorship of this series for more information on the program

37:12.680 --> 37:29.480
visit futurelabs.nyc and of course thank you once again for listening and catch you next time

