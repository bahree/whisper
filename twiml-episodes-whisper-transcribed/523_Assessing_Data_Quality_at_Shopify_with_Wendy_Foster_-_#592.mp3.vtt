WEBVTT

00:00.000 --> 00:11.320
All right, everyone. Welcome to another episode of the Twomble AI podcast. I'm your host,

00:11.320 --> 00:17.280
Sam Charrington. And today I'm joined by Wendy Foster, director of engineering and data

00:17.280 --> 00:22.680
science at Shopify. Before we get into today's conversation, be sure to take a moment to

00:22.680 --> 00:28.120
head over to Apple Podcasts or your listening platform of choice. And if you enjoy the show,

00:28.120 --> 00:33.400
please leave us a five star rating and review. Wendy, welcome to the podcast.

00:33.400 --> 00:38.680
Thanks, Sam. I'm so excited to be here. Long time fan, first time participant.

00:38.680 --> 00:42.760
Awesome. I'm so excited to hear that. And looking forward to our conversation,

00:43.880 --> 00:50.680
we'll be talking a bit about your group at Shopify and what you do. And digging into your

00:50.680 --> 00:55.880
perspective on data centric AI and how you make that real at Shopify. I'd love to have you get

00:55.880 --> 00:59.800
us started by sharing a bit about your background and how you came to work in the field.

00:59.800 --> 01:07.960
Yeah, for sure. It's definitely been a long and twisty journey. So I'll try and be fairly concise

01:07.960 --> 01:13.000
about it. But I don't think I'm actually like unique, especially in the data science or machine

01:13.000 --> 01:20.280
learning field, which is highly cross-disciplinary by nature. But I started out training in the

01:20.280 --> 01:26.840
humanities of a doctorate in literature and cultural studies. But while doing that work,

01:27.800 --> 01:35.320
I was oriented always toward technology studies in particular, which meant I was always hacking

01:35.320 --> 01:42.600
and kind of stretching outside of the traditional boundaries of the humanities. And when I finished

01:42.600 --> 01:48.120
that doctorate, I think like many folks, I wanted to work in the real world. I did want to stay

01:48.120 --> 01:54.600
in academia. And I wanted to work in technology. So I was really fortunate to find, which was at

01:54.600 --> 02:01.720
the time, a very new integrated program. So was at Simon Frazier University, was a master's in

02:01.720 --> 02:09.160
interactive arts and technology, which combined humanities and sociology with computer science and

02:09.160 --> 02:15.720
art. And it was a big incubator actually for a lot of incredible design thinking talent that

02:15.720 --> 02:21.880
was aiming at the game industry, which was a big passion point for me. So those are kind of the

02:21.880 --> 02:30.200
two big steps that I took that I would say like brought me to where I am today. Like I was fascinated

02:30.200 --> 02:38.200
by how data could be visualized and turned into experiences for end users. That was probably the

02:38.200 --> 02:47.320
first step I took into data science. And I was fortunate enough after I graduated to move to Toronto

02:47.320 --> 02:55.400
from Vancouver at the time and get a job at Copo Books. And I think I was there first the time

02:55.400 --> 03:01.640
they were calling it insights and visualization analytics. Awesome. And so what do you do at Shopify?

03:01.640 --> 03:06.440
Yeah, I do a lot of interesting things. I'll say I talk a little bit about my group, we're called

03:06.440 --> 03:12.600
Core Optimize, we're part of our core platform group. And there's two big investment areas within

03:12.600 --> 03:21.560
Core Optimize. We have a product development capacity. And if I reduce it to its most foundational

03:21.560 --> 03:29.240
like product instantiations, it's the reporting and analytic surfaces that we provide to merchants

03:29.240 --> 03:33.800
to help them understand their business better and make better decisions for their business.

03:33.800 --> 03:39.960
We have embedded within that capacity and algorithms group. So they look for opportunities for what

03:39.960 --> 03:46.600
we call horizontal leverage. And what horizontal leverage like means for us is that any algorithm

03:46.600 --> 03:52.840
development we do doesn't just serve our primary group unoptimized but can be utilized and extended

03:52.840 --> 03:59.240
by other groups across Shopify for their product. So a key product for us in that space or key

03:59.240 --> 04:05.560
algorithmic product for us in that space is product categorization. So product categorization

04:05.560 --> 04:11.800
is useful for an incredibly wide array of domains. It can help reduce toil and merchant workflow,

04:11.800 --> 04:17.480
but it's also incredibly useful as a facet for search and discovery. It helps other teams

04:17.480 --> 04:23.240
make better decisions about merchant bucketing just as some very very small examples there.

04:23.240 --> 04:30.440
And we wanted to talk a little bit about data centric AI and categorization is an area that

04:30.440 --> 04:37.960
that comes in the play for you. Maybe take a step back. This idea of data centric AI, how

04:37.960 --> 04:45.880
familiar are you with that? And how is that concept landed for you in thinking about the work

04:45.880 --> 04:53.720
that you do at Shopify? Yeah, absolutely. Actually, I've been thinking about it for probably like

04:53.720 --> 05:00.200
several years and I don't know if the framing for that existed many many years ago, but

05:01.720 --> 05:07.080
I think when I think about differentials between data centric and model centric like AI,

05:07.080 --> 05:13.080
I think back to several companies ago when we're building recommendation projects very small

05:13.080 --> 05:20.760
like startup and with a very enthusiastic group of engineers and machine learning experts where we

05:20.760 --> 05:28.120
were very very excited about all the parameter tuning we could do and very very excited about 0.002

05:28.120 --> 05:34.440
percent improvement in our model performance. And we were fortunate enough that like startup to

05:34.440 --> 05:42.200
have a very rich like wide and deep data set. So our data quality just from a from a coverage

05:42.200 --> 05:48.840
perspective was exceptional. And so like the data was always a rich source for us and we really

05:48.840 --> 05:55.000
put like less attention on it than we should have and spent a lot of time playing with micro

05:55.000 --> 06:00.680
optimizations. I don't know that if I framed it in terms of those like kind of concepts that we're

06:00.680 --> 06:07.480
talking about now at that point, but as like I moved through my career and went into different

06:07.480 --> 06:13.560
organizations and I'll say organizations of different scale in different access to data like

06:13.560 --> 06:20.200
those concepts started becoming more separated for me. And also in organizations of different

06:20.200 --> 06:26.200
scale, they'll say Shopify in particular, we orient all of our decision making whether it's

06:26.200 --> 06:33.320
technical or product around the merchant problem. So if I talk about merchant centricity is being

06:33.320 --> 06:40.680
highly linked to a direction for teams to be data centric versus model centric, they're like

06:41.480 --> 06:47.720
they're incapable of being extricated from each other in my mind. If I care about what's doing

06:47.720 --> 06:53.880
best for the merchant and improving merchant success, I want us to care way more in our approach

06:53.880 --> 07:01.640
about data quality and data coverage than I want people to care about like the I think the micro

07:01.640 --> 07:07.960
details of parameter tuning. And I'm going to be incredibly poor and say I know someone's

07:08.600 --> 07:16.120
said it better. And I'm pretty sure it was like Andrew in, but it's like I think when he talks

07:16.120 --> 07:22.040
about it, he talks about it as like the difference between being able to make an impact in like

07:22.040 --> 07:27.400
not making an impact at all, but satisfying our engineering needs to engineer things.

07:27.400 --> 07:37.400
When you talk about data quality in the context of Shopify, how would you kind of assess data quality

07:37.400 --> 07:47.560
at Shopify and what are some of the things that you think about to address, maintain, and improve data

07:47.560 --> 07:54.120
quality there? Yeah, I mean, in some senses, it's linked to data governance for us. So a big part

07:54.120 --> 08:00.760
of data quality for me is trustworthiness across our different data sets. Are we

08:00.760 --> 08:06.120
cleaning and transforming when the transformation is necessary in like appropriate ways?

08:06.120 --> 08:11.240
And when we transform it in one place is it consistent with how we've transformed it in another?

08:12.840 --> 08:18.680
Is it reliable? Do we have good SLAs on like those data sets? And especially this is

08:18.680 --> 08:23.320
clearly particularly important for our data pipelines and our model pipelines, like ensuring

08:23.320 --> 08:28.200
we have proper service level understandings of that, both for our customers, but as well as for

08:28.200 --> 08:35.480
internal teams who are building off of it. Are we like, I mean, we clearly part of like data

08:35.480 --> 08:42.840
governance is ensuring that our merchants data is well protected. So having like structures that

08:42.840 --> 08:49.800
keep us attentive to that. And for like the modeling side specifically, a piece that like I care

08:49.800 --> 08:56.280
about is coverage and freshness. So with something to use the example of the product categorization

08:56.280 --> 09:04.600
piece, our merchants are incredibly unique. So in Shopify, we understand them as like entrepreneurs

09:04.600 --> 09:10.840
because their behavior is very robust to change in dynamic, right? So it means that like,

09:10.840 --> 09:15.640
is they see the world changing around them? They're constantly updating their products or

09:15.640 --> 09:22.200
their inventories that allow them to be able to like sell better and have higher, clearly higher

09:22.200 --> 09:28.440
success for themselves. But for us, what this means is that ensuring that we're always bringing

09:28.440 --> 09:35.800
fresh data into our modeling like approaches is not just important, but it's critical. Like it's

09:35.800 --> 09:41.000
more critical than worrying about the model architecture itself. It's not to say we don't do model

09:41.000 --> 09:46.760
improvements because also like things like you have to update your model. You can rely on like the

09:46.760 --> 09:51.000
architectures that you kind of get for free with the incredible work that people have already done.

09:51.880 --> 09:57.240
But for product categorization, like an evolution where we did care about updating the model was

09:57.240 --> 10:03.960
bringing image data into our consideration versus just relying on textual data. So like we do

10:03.960 --> 10:10.040
care about ensuring our model is like robust, but like attentiveness to like how the data is changing

10:10.040 --> 10:15.400
underneath us. Sometimes on a daily basis is the most interesting and exciting thing for us,

10:15.400 --> 10:20.040
I think. So that's the data centricity part. Like we need to care about it because it's an

10:20.040 --> 10:25.400
integral part of how merchants behave on our platform. Interesting. It sounds like in a

10:25.400 --> 10:33.960
center saying that the kind of the time scale of innovation around the data versus the model is

10:33.960 --> 10:38.920
very different with the data. It's something you're thinking about constantly. Whereas with the

10:38.920 --> 10:45.960
model, you know, there are kind of bigger boulders that you might take on like integrating the image

10:45.960 --> 10:53.400
information, but changes to the model that come from changes to the data that those that changes

10:53.400 --> 10:59.880
are fewer and further between. Yeah, you nailed it. Absolutely. It's the dynamism of the data that

10:59.880 --> 11:05.160
I think is most important to us. And as I said, like produces better model results. The more

11:05.160 --> 11:13.640
attentive to it, we are the more we foreground coverage versus keeping tweaking accuracy of

11:13.640 --> 11:18.840
existing things we're already pretty good at. And because like helped us be more successful

11:18.840 --> 11:24.440
with this particular investment anyway. Elaborate on that a bit. What does foreground and coverage

11:24.440 --> 11:30.600
mean to you? Yeah. So if I think about like merchant products because we have a high degree of

11:30.600 --> 11:36.760
diversity in the types of merchants who are using like the platform, but also in the types of

11:36.760 --> 11:43.080
products they sell. And not just between merchants, but the the rapidity of which merchants

11:43.720 --> 11:49.240
change in pivot their own merchandising base as well. So it's just a highly dynamic like product

11:49.240 --> 11:55.720
environment has to be like foregrounded so that we can understand if like what we're even inferring

11:55.720 --> 12:00.680
from them is going to be like useful for it. So the expansion of coverage piece to me is like you

12:00.680 --> 12:05.560
can get really good at it like a category of it like we're inferring product type from our product

12:05.560 --> 12:11.160
data, which was like the first step we took with this product categorization model and get really

12:11.160 --> 12:19.720
good at it because to a large extent like merchandising and inventory around clothing is relatively

12:19.720 --> 12:26.520
like stable or we can we can make like the gap jumps like much easier there. But our merchants who

12:26.520 --> 12:32.360
made cell clothing today might pivot and sell power tools tomorrow or like our long film merchants

12:32.360 --> 12:38.760
right. So it requires us to like not just be good at one very large category of product type,

12:38.760 --> 12:44.760
but to be very very good at starting to like build out understanding of some of like those dynamic

12:44.760 --> 12:50.120
changes that are happening with transformations in industry for merchants. So we want to be

12:50.120 --> 12:55.720
equally good at inferring product type for clothing as we want to be for like home goods as we

12:55.720 --> 13:03.320
want to be for bicycles and power tools. Yeah, it's it's a it's a pretty rich tail of product types

13:03.320 --> 13:11.480
for sure. Yeah, I'm thinking as an example of this thinking back to my conversation the last

13:11.480 --> 13:19.000
conversation I had with Salma's former head of data at Shopify and we spoke quite a bit about the

13:19.000 --> 13:25.800
impact of COVID on the company and I'm imagining as you're describing you know these merchants that

13:25.800 --> 13:30.840
are selling clothes one day on all of a sudden you know you have masks pop up on the platform and

13:30.840 --> 13:35.480
you know no one was selling masks before. Is that the kind of thing that you're referring to?

13:35.480 --> 13:40.680
Yeah, I think it was probably like more acute or you saw those changes happen more frequently

13:40.680 --> 13:50.120
during the most impactful early stages of of COVID but I would also say that like that dynamism

13:50.120 --> 13:56.040
and like adjusting your business to meet market needs even if it's not as rapid a transformation.

13:56.840 --> 14:02.920
We see as typical behavior for entrepreneurs like figuring out like their business models

14:02.920 --> 14:08.680
especially in very very early stage anyway. So it's not just something you need to look at when we're

14:08.680 --> 14:12.600
going through a pandemic it's just constant. Yeah, it's always yeah for sure.

14:13.640 --> 14:19.160
And is the impact on categorization when you when you have wholly new products that are

14:19.160 --> 14:27.400
introduced to the platform or is it different products offered by different vendors or what are

14:27.400 --> 14:33.080
the conditions that that most impact the categorization effort and impact coverage?

14:33.080 --> 14:41.000
Yeah, it's probably like a bit of both but I would say the the higher interest at least

14:41.000 --> 14:48.440
for me right now is on merchants updating their products. I mean like one of the ways we've

14:48.440 --> 14:56.040
productized this at Shopify is so merchants have what's called an administrative space when they

14:56.040 --> 15:02.520
log into the Shopify platform and in that administrative place they have multiple operational

15:02.520 --> 15:08.280
pages where they can do things like update their products and like shift inventory between

15:09.160 --> 15:14.200
stores if they have multiple stores but for for product type or we're really focused is on

15:14.200 --> 15:19.720
their product page and that's where they do their their product updates at new products change

15:19.720 --> 15:25.960
existing products and where we surface our inference there is in a category for them which is

15:25.960 --> 15:31.560
called product type so merchants have a bit of a choice here they can choose to set their own

15:31.560 --> 15:36.600
product type where they can use our inference so in some ways it's like a nice virtuous circle

15:36.600 --> 15:42.120
because if they don't like our inference they can use a custom type and then we can learn from

15:42.120 --> 15:48.200
what they didn't like about our label but it's it's actually like a key function for them to get

15:48.200 --> 15:54.520
that right because the idea of a product type is connected to a product category taxonomy

15:54.520 --> 16:00.440
that isn't just useful for us in other parts of Shopify to help merchants merchandise better or

16:00.440 --> 16:06.120
market their service is better or for merchants to be able to do that themselves using themselves

16:06.120 --> 16:11.480
are third party apps but they typically are because they're entrepreneurs sell across multiple

16:11.480 --> 16:18.040
channels so that product type like the taxonomic product reference is actually a thing now ideas

16:18.040 --> 16:24.120
of taxonomies are like not interesting to like merchants in general this wanted to be right and

16:24.120 --> 16:30.120
exportable to like Facebook marketplaces or like Google marketplaces right wherever else they like

16:30.120 --> 16:38.040
sell their products and so like when I think of like us being able to like get this thing like

16:38.840 --> 16:44.360
right and have the highest coverage for them I think about how they can actually use it to like

16:44.360 --> 16:49.720
amplify their success across all of the channels they care about and if they're updating products

16:49.720 --> 16:54.680
like very very quickly we have to like have a real-time inference and we have to make sure that

16:54.680 --> 17:00.440
that inference is correct enough so that it doesn't become a frustrating aspect of a workflow

17:00.440 --> 17:06.760
that changes often for them if there if there are a merchant who is involved in dynamic product

17:06.760 --> 17:13.640
updates and quite frankly most of them are because if you're like a one or two person like organization

17:13.640 --> 17:19.480
you're going to be constantly in those pages updating how you describe like your your products like

17:19.480 --> 17:23.720
how you even like even images around them right because you're always trying to like tweak and

17:23.720 --> 17:30.120
optimize that experience to find your audience in your fit so like they're highly experimental they

17:30.120 --> 17:37.640
change things all the time thinking about that taxonomy how much of that or what's the relationship

17:37.640 --> 17:47.240
between human curators taxonomists and machine machine learning in creating that taxonomy

17:47.880 --> 17:53.480
yeah so for the initial stages of our product categorization we kind of did a couple of things

17:54.280 --> 17:59.400
we leveraged like the Google product taxonomy to have a reference point for what that what that

17:59.400 --> 18:05.240
tree structure should look like for merchants and we also employed subject matter experts

18:05.240 --> 18:11.320
to help us like label those initial efforts both within house and as like a third party service

18:11.320 --> 18:18.760
so once you reach a certain critical mass of like I mean we focused on um a clothing or a peril

18:18.760 --> 18:25.480
um to start with to get right really well because you don't need um a lot of uh like high domain

18:25.480 --> 18:31.080
expertise to to label pants effectively or a pair of socks so we got a lot of leverage from that

18:31.080 --> 18:35.960
and it's also one of our biggest categories um merchant categories that Shopify so

18:35.960 --> 18:42.040
it was a great like scaffolded place for us to start so once we got enough um good accurate

18:42.040 --> 18:47.160
like labels to be able to have confidence in our inferences on the product type we were able to

18:47.160 --> 18:53.400
build this experience um to surface the inference um into that operational page that merchants use

18:53.400 --> 18:59.240
to manage their products and once we had that space in then we could start expanding our

18:59.240 --> 19:05.800
understanding right because of the the fields that like surround that operation so our inference

19:06.440 --> 19:11.800
if they want to accept it or reject it the custom types that they would add product titles product

19:11.800 --> 19:17.960
descriptions are also in that operational page as well as tags so additional metadata are all um

19:17.960 --> 19:23.560
merchant generated um so we've been able to like kind of bootstrap the model with like subject matter

19:23.560 --> 19:28.520
expertise labeling a really well-known domain and then start trying to stretch it into unfamiliar

19:28.520 --> 19:35.320
domains what's an example of domain in this case is it clothing to power tools or is it more

19:36.280 --> 19:42.200
um you know within clothing one to the next yeah yeah I guess like actually all of it if I'm

19:42.200 --> 19:48.200
being honest so it's like like clothing will have like your clearly your top level um uh

19:49.240 --> 19:56.040
I guess like product types that are like most recognizable to us so like pants shirts um socks um

19:56.040 --> 20:03.320
but like so you want like the the ability to be able to navigate down and number of like leaves

20:03.320 --> 20:08.840
in a sock category for sure and it gets harder clearly as you get more granular because then it

20:08.840 --> 20:16.280
becomes for for merchants and I think for buyers as well um uh more that maybe that becomes more

20:16.280 --> 20:23.000
the domain knowledge how you define a very particular pair of pants like as chinos versus like

20:23.000 --> 20:30.840
um blue jeans it starts becoming um uh just more refined but like I think really like the the

20:30.840 --> 20:39.160
parent part of like that taxonomy node is the most important one to get right um so a pair

20:39.160 --> 20:43.960
of clothing would be like the large categories but yeah to your point also extending it to like

20:43.960 --> 20:51.400
other um sellable domains and I mean like those could be power tools it could be home decor

20:51.400 --> 20:56.760
and living when you think of the broad like areas we would want to like um search for useful things

20:56.760 --> 21:01.960
under but it can also be incredibly niche like there's going to be um massive amounts of like

21:02.520 --> 21:07.240
edge cases where there's one product that someone's selling and it's a very particular type of like

21:07.240 --> 21:13.720
let's say like iron on badge or something right yeah so it's a really complicated like area like

21:13.720 --> 21:18.920
well-known domains are clearly easier to like access and learn than um your edge cases

21:18.920 --> 21:23.800
and when did you first introduce images to the categorization?

21:23.800 --> 21:28.760
oh it would have been last year like the the work on this is probably

21:30.600 --> 21:38.360
only about a year and a half old now so it started out um modeling just using the textual

21:38.360 --> 21:45.480
descriptions um attached to um products so the title description um product description

21:45.480 --> 21:50.760
I think was also vendor and some of the metadata we also collect from it so like tags that they

21:50.760 --> 21:58.360
would that merchants would add um to those product like uploads um and then it was like later on

21:58.360 --> 22:03.400
in that year maybe maybe it was like a handful of months later where the model was extended

22:03.400 --> 22:09.080
to incorporate images. the images were already in place part of this data set so you didn't have

22:09.080 --> 22:16.760
to collect any additional information um how did you vectorize the images and did you

22:16.760 --> 22:23.560
did you already have kind of an embedding space for product images or there had been experiments

22:23.560 --> 22:28.520
done on done on it before so if I'm recalling correctly I actually think it was done during a

22:28.520 --> 22:33.720
hack days um someone who I actually like I think was actually one person who ended up bringing

22:33.720 --> 22:40.600
um over to the the team had done a hack days on um creating vector space for like the images so

22:41.320 --> 22:45.320
the images product images are stored separately from the textual

22:46.040 --> 22:51.480
descriptions for um uh the product type because they're like media assets are

22:52.200 --> 22:59.400
a different like data store right so um merging like the pipelines was like non-trivial like um

22:59.400 --> 23:06.120
um absolutely but absolutely necessary improvement to the model for us to I think be able to

23:06.600 --> 23:12.040
aren't I mean my feeling is is that it was necessary in order for us to be able to start extending

23:12.040 --> 23:18.760
into um subsequent domains and also build I think like real future thinking around

23:18.760 --> 23:23.880
how we want to extend the model and our understanding of products in the future because

23:23.880 --> 23:30.120
you look at like um how merchants as I said they're highly experimental and one of the things

23:30.120 --> 23:35.240
it's like really important to them or I think images like comes into play arrest understanding

23:35.240 --> 23:41.320
the images piece better um we're not doing this today but I'm kind of want the team to be thinking

23:41.320 --> 23:47.720
about its day is like what happens when that converts to 3D right so I think it's like a table

23:47.720 --> 23:53.320
stakes like activity now for when you go browsing you want um not necessarily the whole augmented

23:53.320 --> 23:58.520
reality experience that's still available in very limited spaces but you want to be able to like

23:58.520 --> 24:05.160
touch that image on your screen rotate it see its dimensions um and I think like for me the

24:05.800 --> 24:11.240
the the image that's typically uploaded with a product is just a stepping stone for us to be

24:11.240 --> 24:18.840
able to do um inference from um 3D models that merchants might want to um might want to engage to

24:18.840 --> 24:26.040
we supported in like parts of the Shopify platform so it's a it's a necessary addition meaning

24:26.040 --> 24:34.600
it currently merchants can upload 3D uh or multiple perspective images yeah there's aspects

24:34.600 --> 24:41.000
through like their experience where they can like uh be able to like create 3D experiences for

24:41.000 --> 24:48.040
buyers to be able to like do the image like manipulation um which is uh I think like I consider

24:48.040 --> 24:54.840
it table stakes in terms of like by your experience now um not all merchants do that um but I think

24:54.840 --> 25:02.280
it's like a growing expectation that there's that affordances like I mean to to an extent it's like

25:02.280 --> 25:07.400
for a merchant to be able to provide like that image they have to have probably a certain amount

25:07.400 --> 25:13.720
of like resources but those are getting more and more accessible um and I do think it's a space

25:13.720 --> 25:19.720
we need to be thinking about in terms of building into um anything around product understanding

25:19.720 --> 25:27.560
we do going forward curious about maybe other other challenges involved in uh in this particular

25:27.560 --> 25:35.480
aspect of the projects so there's there's challenges in I don't know I want to frame it um I

25:35.480 --> 25:40.280
mean there's technical challenges that coming work that come with like working and productionizing

25:40.280 --> 25:49.080
with like large scale models so this particular like work really like I think um it was a primary

25:49.080 --> 25:53.400
use case I'll say this way a primary use case for the evolution of our internal machine learning

25:53.400 --> 26:01.880
platform so it was definitely pushing on technical boundaries um from a product um perspective um

26:01.880 --> 26:08.280
we had to open ourselves up to like new spaces where this would be leverageable and like as I said

26:08.280 --> 26:12.600
we orient like all of our decisions and what we decide to put our time against

26:12.600 --> 26:18.280
unlike the highest merchant problem so this requires like the team maybe this is true of a lot of

26:18.280 --> 26:24.920
like teams that um are building um algorithms they want to have like impact on the world outside

26:24.920 --> 26:32.040
of like um their lab or like their team space but um it can't be a built it and they will come

26:32.040 --> 26:37.560
kind of like venture right it's like the decision to work on product categorization and the team

26:37.560 --> 26:44.680
had to do a lot of like outreach to teams across Shopify to be able to identify um the very best

26:44.680 --> 26:50.680
opportunities um for like product fit right we can build our own products around it and

26:50.680 --> 26:55.480
they said that creates a bit of a virtuous circle for us because we get better and enriched data

26:55.480 --> 27:02.920
from um having um especially like that surface to our admin but we also want that like that

27:02.920 --> 27:09.320
inference to be important for the company outside of our team so creating those relationships

27:09.320 --> 27:14.440
and intersecting road maps is incredibly challenging and I actually think it's like probably one of

27:14.440 --> 27:21.320
the biggest like challenges for um uh industry like level machine learning it's like it's probably

27:21.320 --> 27:27.880
very very rare that one team can support like both building like the algorithm and the constellation

27:27.880 --> 27:32.760
of products around it without making those relationships with other teams so your company also has

27:32.760 --> 27:38.680
to be at scale it's like what we actually saw is that like working on like the algorithm and trying

27:38.680 --> 27:45.800
to like build against it almost in parallel was like an impossibility right so yeah a building ahead

27:45.800 --> 27:51.160
you have to have like strategic foresight to understand whether the right things to like build um

27:51.160 --> 27:55.960
and then like making those like connections to product spaces that would benefit from it

27:55.960 --> 28:04.280
becomes so much easier the hardest part about it is like really just getting teams to understand

28:04.280 --> 28:10.520
the runway right so if you're doing like especially if you're like building in um a new space

28:10.520 --> 28:16.520
you have like an MVP model um but you may need like like the decisions you make around how to

28:16.520 --> 28:21.960
improve and even if it's just from a data coverage like perspective have to be with an i about

28:21.960 --> 28:27.160
where that like um output of like that model is going to find a home is it for an internal

28:27.160 --> 28:33.000
application then you probably like build your roadmap instead of like optimization priorities

28:33.000 --> 28:37.960
around a completely different space then if you know merchant facing teams are going to leverage it

28:37.960 --> 28:45.480
right you mentioned that it you found it really difficult to both build the model and build the

28:45.480 --> 28:53.400
products around the model and i'm curious that that's a little bit counterintuitive um in the sense of

28:54.360 --> 29:04.600
um you know if you've assuming you've got the the products uh domain expertise on the same team

29:05.480 --> 29:11.240
um you know minimizing communication barriers just having everything in one place you think you

29:11.240 --> 29:17.960
can move quicker but it sounds like there were some inherent challenges uh with that and i'm

29:17.960 --> 29:24.200
curious about those yeah it's mostly a timing thing right and this is true of like um where you

29:24.200 --> 29:30.440
want um uh that model like output to be useful for teams outside of yourself where you have even

29:30.440 --> 29:36.520
less control about the staging of the product building against the algorithm development right so

29:36.520 --> 29:43.560
when the model development like cycle and this is actually true of like any machine learning work

29:43.560 --> 29:50.600
or data science work probably generally um the cycle of how you build that is very very different

29:50.600 --> 29:56.200
from the software development cycle or the product development cycle more generally so um the

29:56.200 --> 30:03.320
model has to be like built with some and we have to have some degree of confidence in it um before

30:03.320 --> 30:11.320
like product opportunities can be software developed against it right so i think like the it's

30:11.320 --> 30:17.000
not that like the challenges is like can we think of products to build around like the output of

30:17.000 --> 30:23.000
a product categorization model the challenges how do you time that for internal team like if we

30:23.000 --> 30:28.920
own all of the teams um product teams and the other teams that are building against it like the

30:28.920 --> 30:35.720
staging is probably easier right um well it was easier for us but um we don't want to just be the

30:35.720 --> 30:41.320
only team like leveraging this output so if we want another team across Shopify let's say our

30:41.320 --> 30:46.200
search and discovery team to be able to use the output of a product categorization model

30:46.200 --> 30:52.120
for a search facet we have to understand where on their roadmap that work might be located

30:52.120 --> 30:57.560
if at all and if it's not be able to influence them to put it on their roadmap and then ensure

30:57.560 --> 31:03.640
the way we're having to like um optimize if that's required um to be a you to make the output as

31:03.640 --> 31:09.000
useful as possible for that other team like this artwork gonna be able to time out in a line with

31:09.720 --> 31:14.200
how they've scheduled their work like it's complicated enough to do all of those like

31:14.840 --> 31:22.520
roadmap alignments within one team clearly far more possible um much much more difficult to do it

31:22.520 --> 31:28.280
with um external teams even within your own organization especially when you're hoping as we are

31:28.280 --> 31:35.560
that this horizontal like asset can like help not just one team or two teams but a dozen teams right

31:36.200 --> 31:42.760
so it's it's mostly just about managing timelines and getting like um other teams who don't support

31:42.760 --> 31:48.680
this kind of work like the algorithm development work on their own teams explicitly understand like

31:48.680 --> 31:55.160
the actual like length of time it takes um it takes to build these kind of products because that's

31:55.160 --> 32:03.160
also an unknown too uh Shopify recently published a blog post about Merlin uh a new ML platform

32:03.800 --> 32:09.080
at the company can you talk a little bit about the relationship between your team and

32:09.080 --> 32:16.040
that platform and and even the categorization product and that platform um how do they fit

32:16.040 --> 32:23.160
it together yeah um they fit together very closely actually so um the machine learning platform

32:23.800 --> 32:29.160
is a relatively like new investment for Shopify as well like i'm probably going to be a mistake

32:29.160 --> 32:35.960
in here but i think it's less than like two years old so the teams that are working in Shopify

32:35.960 --> 32:42.840
on building um machine learning applications were the initial use cases for Merlin so the the team

32:42.840 --> 32:49.320
that um uh i support who is building these horizontal like algorithms were one of like the first

32:49.320 --> 32:56.440
use cases for Merlin but again like i say this is from like a product against a like data platform

32:56.440 --> 33:02.440
is a product and so building and evolving something as complicated as a machine learning platform

33:03.320 --> 33:10.920
in parallel with a team who's building um large-scale like multi-model models is um a challenge

33:10.920 --> 33:17.320
so uh we feed in like requirements and we we fall along the road map and as we're able to take

33:17.320 --> 33:22.520
advantage of more and more of the capabilities that the machine learning platform makes available

33:22.520 --> 33:30.280
we migrate to them right so i think we started out um uh with the algorithms team um building

33:30.280 --> 33:37.720
stand-alone like pipelines that um we're built in a way that when Merlin was able to support those

33:37.720 --> 33:43.160
like on-platform like it was a fairly simple like migration effort um and same with taking

33:43.160 --> 33:48.760
advantage of like the feature store that's being built out too it's like we're moving into like

33:48.760 --> 33:54.280
near real-time um inference production and that's on their road maps so when they're able to support

33:54.280 --> 34:00.680
that we'll be able to to merge there but um it's an exceptional team doing incredibly hard work

34:00.680 --> 34:07.160
with an enormous amount of stakeholders across the organization so um i'm super happy with like

34:07.160 --> 34:12.760
their progress and their level of like partnership with us like um we bait they basically are

34:12.760 --> 34:19.400
filters for like um the pain the team is experiencing and um uh that gets like road mapped into

34:19.400 --> 34:24.840
feature sets that are prioritized by them we've talked quite a bit about the categorization

34:24.840 --> 34:32.840
use case um what are some other use cases that your team has been working on so i think like

34:32.840 --> 34:37.880
for us the product space is not completely exhaustible if i'm talking to just about like the

34:37.880 --> 34:44.280
algorithms work um but that doesn't mean the domain space of like merchant value is exhausted

34:44.280 --> 34:49.800
that we can do in much smaller efforts so i think when we think about the large um large scale like

34:49.800 --> 34:56.120
data work to me it's like a lot of its exploratory array like what large data sets do we have

34:56.120 --> 35:01.880
that we think can provide merchant value um i think we still have a lot of like um mining that

35:01.880 --> 35:09.160
we need to do on the product data set um specifically um but smaller areas that i think are useful

35:09.160 --> 35:14.360
for merchants that can help them understand their business better is to really help them like

35:15.080 --> 35:19.880
benchmark against themselves like be able to have like actually sensitive instead of out of the

35:19.880 --> 35:27.320
box forecast for their businesses um it sounds like simple work but like the the models for like

35:27.320 --> 35:33.880
supply and demand on each individual merchant um use case can look incredibly like different

35:33.880 --> 35:41.880
right um uh some merchants even have i think one merchant like described it to me is um they have

35:41.880 --> 35:49.960
like a model where they loan things out and then get them back and so how something like for forecasting

35:49.960 --> 35:54.680
them if you're doing like inventory forecasting for them would look very different than inventory

35:54.680 --> 35:59.880
forecasting for a merchant that sells something and once you sell it it's gone they're like

35:59.880 --> 36:07.320
well we get stuff in from distributor a and then we lend it out um to a whole bunch of customers

36:07.320 --> 36:11.880
and then we wait to get that back and then we're also getting like new products from like different

36:11.880 --> 36:16.200
domains into the like how do i understand my business better i'm like that is a really hard

36:16.200 --> 36:21.400
challenge probably not super unique especially like merchants are very creative about how they

36:21.400 --> 36:26.840
manage their businesses now but it's enough of an edge case that it wouldn't fit into a generalizable

36:26.840 --> 36:33.640
like forecast model we might be want to be able to provide to merchants um as a tool um to use in

36:34.840 --> 36:39.400
their admin in our analytics home as an example so i think that that one's really hard

36:39.400 --> 36:46.440
i think imagine that Shopify supported that at all the the lending use case you know let alone

36:46.440 --> 36:52.360
forecasting it but even the inventory management parts of it and some of the more basic

36:53.320 --> 36:59.960
mechanics of that that business yeah the the inventory like management support i am

37:01.320 --> 37:08.760
pretty sure doesn't like uh doesn't like account like fully for that kind of like model so

37:08.760 --> 37:15.960
it positive it's not part of like our tooling but um merchants like create are incredibly creative so

37:18.040 --> 37:24.840
they find ways to like like use the platform for work for their immediate needs and then

37:24.840 --> 37:30.760
creative ways often like sometimes they contract out like new services or find third party

37:31.400 --> 37:36.440
apps that can support them um to be able to extend parts of their business so they're being

37:36.440 --> 37:41.640
creative about how they support that too and for like one person like merchant businesses um maybe

37:41.640 --> 37:48.360
they can like uh maybe they can kick love that uh to a large extent for themselves too but yeah

37:48.360 --> 37:54.680
for for them it's like like really understanding how to like build that kind of business like

37:54.680 --> 38:00.440
effectively is um not just a tooling challenge from any e-commerce solution they might use Shopify

38:00.440 --> 38:05.720
in this case but also from an understanding perspective so the analytics products we provide

38:05.720 --> 38:11.080
need to like i don't know if we'd be able to like handle the specificities of that use case but

38:11.080 --> 38:16.600
i know how flexible we can be on like building that kind of like forecasting model that allows

38:16.600 --> 38:22.360
merchants to have some autonomy over controlling aspects of how you define how that model should work

38:23.000 --> 38:28.280
um i think it's probably very similar with pricing to like the thing they're also interested in

38:28.280 --> 38:33.640
is like tools that help them experiment with pricing more effectively returning back to this idea

38:33.640 --> 38:40.920
of data-centric AI versus model-centric and and the way that you've incorporated that into the

38:40.920 --> 38:48.200
categorization use case you talked about incorporating in the user-provided labels

38:48.200 --> 38:54.760
into the into the loop how do you operationalize that yeah so we have that product like pretty

38:54.760 --> 39:01.000
well-instrumented um really like you can you can always like we always want to improve on that

39:01.000 --> 39:06.840
because we learn more but we know if like if we provide an inference when you think of the field

39:06.840 --> 39:12.920
it's like a light suggestion in it so when they have the product type in their admin it's like a

39:12.920 --> 39:17.800
great out so they can say hey we're recommending this product type for you to use and if they click

39:17.800 --> 39:23.320
in the text field then it populates that text field and then they can attach it to like their

39:23.320 --> 39:28.760
inventory but they can also choose to ignore that field and there's an opportunity for them to enter

39:28.760 --> 39:35.160
a custom type and also what they'll do regardless of whether they select a product type or not is

39:35.160 --> 39:42.280
usually include um tags um descriptive tags for their product which is um like helps to make

39:42.280 --> 39:48.280
them more discoverable it's a really rich source of um metadata for them to like leverage so

39:48.280 --> 39:53.320
we know if they accept our suggestion if they click on that field and then apply it um to their

39:53.320 --> 40:00.040
product so that's all part of like our product um dataset model awesome well Wendy thanks so

40:00.040 --> 40:06.680
much for taking the time to chat and share a bit about what you and your team are up to very cool

40:06.680 --> 40:31.960
stuff thank you Sam it's been a pleasure

