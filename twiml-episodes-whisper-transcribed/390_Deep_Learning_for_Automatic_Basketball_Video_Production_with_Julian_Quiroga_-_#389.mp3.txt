Welcome to the Twimal AI Podcast.
I'm your host Sam Charrington.
Before we get to today's episode, I'd like to send a huge thank you to our friends
at Qualcomm for their support of the podcast and their sponsorship of this series.
Qualcomm AI research is dedicated to advancing AI to make its core capabilities, perception,
reasoning, and action ubiquitous across devices.
Their work makes it possible for billions of users around the world to have AI enhanced
experiences on Qualcomm technology's powered devices.
To learn more about what Qualcomm is up to on the research front, visit twimalai.com-qualcomm-qulmmm.
And now onto the show.
All right, everyone.
I am here with Julien Carruga.
Julien is computer vision team lead at Genius Sports.
Julien, welcome to the Twimal AI Podcast.
Hi Sam.
Hey, it's great to have you on the show and I'm looking forward to digging into your paper,
which you'll be presenting at CVPR in the computer vision in sports workshop.
But before we do, I would love to have you share a little bit about your background and
how you came to work in computer vision.
Yeah, sure.
Right now I'm the computer vision team lead at Genius Sports.
I'm responsible for leading applied research in video understanding and videography.
I work together with a team of scientists and engineers trying to get the best technologies
for the company.
Before joining Genius Sports, I was an associate professor in a university in Bogota doing
research in signal processing and in-match processing and computer vision.
But I was contacted by the company and they offered me a joint for a very exciting kind
of products with basketball.
And since I played basketball since I was like 10 years old, so I was so excited and
I accepted the offer.
And yeah, I did PhD in informatics and mathematics in France, yeah.
But before that, I was working more in signal processing and all the theoretical aspects.
But then I started to work with images and video and that's when I'm doing right now.
All right, cool.
And tell us a little bit about Genius Sports and some of the things that you do with computer
vision at the company.
Yeah, sure.
So, Genius Sports is a living company in sports data and sports media and all the regulator
sports bearing sectors and it's specialized in the capturing distribution of real time
day.
In particular, in my case, yeah, we are doing more of applied research trying to do like
video understanding and videography to get automatic production and to collect data in
real time.
This data will enrich the kind of data that we provide to our partners and some of the
product that they're working right now, they are related with automatic production with
single and multiple views, yeah.
And also the collection of data in the age really close to the event to the sport event
for instance, basketball and volleyball and a really short period of time.
How much of what the company does is focused on or related to vision data versus other types
of data sources?
Yeah.
So, actually, we start like two years ago, I think when I joined the company, so we are
really new.
Okay.
We're all there.
Yeah.
Yeah.
Yeah.
I guess you mentioned some of the broad things that you're doing there, but you're, I guess
in terms of your, you mentioned that your focus is like applied research.
What are some of the projects that you're focused on?
Yeah.
So, the first one is out of my production.
It can sound like, what is that, but it depends.
And also the complexity it depends.
So, for the case of the paper that we are going to, it's a single camera disabled to observe
the full, the full card or fill, so the idea is just to generate a virtual camera, but
there are other scenarios when you have more than one camera in order to produce a higher
quality production every switching and doing some transition between cameras.
So in this, in the simple scenario, when you only have one camera, it is just to get the
proper frame and to track the main actions, yeah, and in real time, of course.
But when you have more than one camera, you have to bring it to the spectator like a better
experience of the event and trying to select the proper point of view for each action.
So the problem is more shutting it.
And so the paper that you're presenting at CVPR is that single camera only, or does it
include multiple camera scenarios?
Yeah.
And this paper is for basketball and is with a single view, and the main goal is to produce
a high-query production that is really fast.
Because for sports events, the latency of this broadcast is quite important.
So if you want to do any processing of this video, you don't want to add a large latency.
So actually, in our work, we are able to just add like 300 or 400 milliseconds for this
is really important.
But however, there are other components in the streaming processor that are adding more
time.
So the idea of this technology is to be able to produce this high-query production without
adding a large latency to the full pipeline in order to get this broadcast to the spectators.
Okay.
And if folks are listening and would like to take a look at the demonstration of the
project, we've got that, we'll have that in the show notes.
It's up on YouTube.
And it's pretty cool.
You start out with this kind of wide-frame view of a basketball core and you show by adding
additional layers of information that you can localize the ball and localize the players
and know which part of the core the action is going to be on and kind of pan the camera
back and forth and zoom in and zoom out.
So at the end result, as you've described and as the paper's title, kind of an automated
production where presumably you can just kind of point this camera that's connected to
a model at a basketball core and it'll produce something that's kind of watchable and engaging
and interesting as opposed to just the ones zoomed out view.
When we're talking about sports production today, like I would imagine you've got a pretty
broad range of what's actually done, like you've got, you know, maybe at high schools
or maybe even some colleges, you know, a single video that's without an operator that's
just recording and then, you know, certainly in the professional sports, you probably
have teams of people creating a production.
Can you, is the goal here to produce something that is kind of productized and replaces
one or more of those scenarios?
Yeah, so one of the ideas with this project is to enable some people and college and schools
that they are not able to have a like a professional cameraman or something like that, yeah, to
be able to record their games, yeah, but not only to record the games, but also to record
and to stream them to wherever a point, yeah, through the internet.
Yeah, so, you know, parents and family friends, our fans can watch the game of their favorite
team, yeah, without an expensive system of capturing production and streaming, yeah, this
is one, one, one part, the other part is that we are able to do the auto production, yeah,
with the scene, uh, as you mentioned, with the wide view, we have the full information
and at the same time later, we are also working on that.
We can capture at the same time data, more data locations and analytics and also embed
that in the same broadcast, yeah, and also with low data.
And so is the the setup that you've got a single high resolution camera and the panning
and zooming is all done digitally or are you actually controlling the camera?
Exactly.
Actually, it's a fixed camera, it depends on the, on the fill, yeah, and the distance,
it should be a wide angle with a wide angle or a standard camera, now if you have like
a large venue, you can use whatever camera, but if not, you will need like a wide angle
or with a wide angle, yeah, and then all the production is over a virtual camera.
So it's just like a digital crop or digital zoom, yeah, trying to get that.
So there's an important trade of here is that you want to contain the main action inside
this virtual camera, but this really is, I mean, if you are not doing any production,
you are containing the main action, yeah, but you have to crop, yeah, but you have to
crop enough in order to get the attention of the superior to the main action.
So there is a trade up that you don't want to lose any action, yeah, but you want to
contain the action, so it should be like large and small enough to contain properly that
and it depends of the kind of basketball, yeah, I mean, imagine NBA NCAA is something
like that, or college basketball or kids or something that the speed of the game that's
going to be different, so you can incorporate that in order to have like a smooth enough
production, but you don't want to lose any action.
And what resolution cameras have you worked with out of care?
Yeah.
So our standard setup is a 4K camera, yeah, and the resolution of the producer game,
it depends.
If you are doing streaming, perhaps not so high, but it could be like full HD or HD,
you are just recording, yeah, it can be full HD, yeah, it depends of also on the internet
connectivity, or if you only want to record, if you only want to record, it can be like
full HD.
Okay, cool, so I mentioned in the demo, you roll through at the beginning a set of layers
showing, localizing the players and the ball and things like that, you actually show quite
a bit of information overlaid onto the screen in the demo, what are the main contributions
of the paper?
Yeah, so right now we're developing, I think that we are pushing a lot, trying to get
like M2N systems, yeah, instead of that we wanted to have like a more modular system,
yeah, going to the basics of the team sports, I am trying to get like a button up system,
so in basketball you have your ingredients, you have your players, your hoveries, and
you have the ball, and that's it.
So we wanted to custom something based on that, I'm trying to get good solution for localizing
the ball and players and perhaps in time, yeah, and then trying to build really nice roads
of production that can behave well depending on the different kind of basketball, yeah,
and there is a good thing is that in the company we are a lot of people that love basketball
too, actually we use it all these knowledge and all these experience trying to get good
rules of production that perhaps in this M2N approach is quite hard, because you're
going to have a reference, yeah, and you want to have this crap in order to fool this
and that, but depending on the basketball is not so intuitive and not so easy to include
these kind of rules, but in our approach, there is a modular, yeah, you have your ingredients
or your model or the locations of your actors in this case, ball and players, and we take
out the ref and then depending on that, we can at every time select the proper crop or
the action.
So where they make contribution, first of all, is like a full pipeline, yeah, that the
more data you are getting of basketball games, the detector that you have for ball and player,
they work, they will work better.
So you're going to be always in the right position, and also it can easily be implemented
on any field, yeah, and it's not a spend time is working in a real time.
Okay, so I think you packed a lot into that explanation, but one question that jumped out
of me was you mentioned that you start with these ingredients and identifying where the
players are in the ball, and then you mentioned having rules to determine what the optimal
crop and zoom are, do you mean those rules literally meaning that the deep learning is
doing the detection and localizing the ingredients, and then you've got a set of static rules
that are based on that information that do the production or is the production also part
of a learned model.
Yeah, so the learned model is there are two main components that they are learned.
One is the actors, ball and players, and the other one is what is the game state, because
depending on the state of the game, you want to follow one rule or you want to do something,
you want to be more attentive, or you want to be almost still, it depends, yeah, but
we are not trying to learn the proper virtual camera, yeah.
That was a choice that we did, yeah, I remember that when discussing the different approaches
that we could take, there are really similar configuration of players, yeah, and depending
on the ball, you want to frame that I am actually in one way or in another.
So you have to first, you have to be aware of where is the ball, yeah, but not only the
ball is directing where is the proper framing, and you'll have to be aware of the players
and pleasure distribution, yeah, but not only this distribution will tell you what is the
proper frame, and you need a combination of these two depending on the game state.
And sometimes, I mean, in end-to-end approaches, yeah, if you want to state that like an end-to-end,
you have all your ingredients or even your raw video, and then you want like an output
the proper framing, yeah, and it's going to be like a black box, and trying to adjust
that for one kind of basketball or one kind of thing that's going to be quite hard.
This is what we did this choice, and yeah, so it's really, it's quite easy to set one
kind of behavior for what kind of basketball.
Okay, okay.
When you say one kind of basketball, what are examples of the kinds of basketballs that
would change the way you were referring to that?
Yeah, so there are some challenges when you want to produce basketball with a really
nice zoom, yeah, and just for instance, if you see the production that they are doing
for NCAA or for NBA, it's quite different, yeah, NCAA, usually they are just having
like a almost still camera in the hardcore for hardcore possession, and then just they
are just moving for the transition, and that's it.
For the NBA, they really want to track and to do more zoom when they are doing a hardcore.
So this is like a two kind of production, but by kind of basketball, I'm talking about
the maximum speed, so the main challenge when you are trying to do that is someone that
is really fast, like LeBron James or something like that, yeah, and you want to track the
main action, but you don't want to disturb the people that are watching the production,
so you have a trade-off, yeah, so if you already know that your basketball is not going
to be so fast, yeah, you can have like a maximum speed of the virtual camera and things like
that, and be sure that you're going to be able to track the main action, but if your basketball
is quite fast and you don't want to lose the main action, so you have to relax somehow
your roles in order to always be in the right position, okay, okay, so the modular approach,
it sounds like it allows you to, it gives you a little bit more kind of knobs for addressing
these different characteristics of games in terms of faster and slower, and also it sounds
a little bit like it, it will allow maybe in more of a professional setting if this is
deployed, whoever is using it to kind of tune in a personality for the way they want
the video to kind of feel in their NCAA versus NBA for example, yeah, yeah, and even for
the case of NCAA, between men and women is totally different, usually for women, the
point guard is really close to the half-court with the ball, so if you want to take a look
at the point guard and also the action that is taking place under the basket, you need
a wider framing, but for men it's totally different, they are moving different, so they are
something that, I mean, we are not trained to learn that, but it's also possible to learn
that and to avoid feeling that by hand or by the satisfaction of customer that is usually
what we are doing, yeah, sometimes customers prefer this kind of production that other,
but it's quite easy to transfer that, you know, we're models, yeah, that is not so easy
for an end-to-end system that you have to change your last function or your data or whatever
it is, yeah.
And retrained, you also overlay this graph of Gaussian-based actionness in the video,
and it seems to try to capture where the action is or is likely to be on the court.
Can you talk a little bit more about that metric and what goes into it?
Yeah, sure.
So the first thing that we are modeling players, like two-dimensional Gaussian in the court,
that is quite intuitive, yeah.
So since we have like a core model, it's quite easy to have like shapes with the
proper sizing pixels in the image, yeah, and also to map that to a 2D history, so we are
able to model the distribution of players.
And our hypothesis is that if players are more concentrated in a given area of the court,
it's more likely to have like more action there or something interesting that will happen,
yeah.
Imagine that half of players are in one half-court or the other half is in the other half-court,
so sure if they are in the amount or something like that, yeah, it's quite hard to decide
where I should look, or perhaps I should do a sum out, yeah, yeah, something like that.
So this is one thing.
The other thing that you can easily think is, okay, if you have the ball, you only need
the ball, right?
And you can track the ball like in soccer or something similar or in volleyball, I don't
know, yeah, and yeah, but there are a lot of interesting things that you also want to
see, you'll not only want to see someone with the ball like that, and everyone in the
key area taking screens and doing a lot of things and trying to get free for a shot, so
it's quite interesting.
So this function is trying to describe this likelihood, yeah.
But along, it's not so useful because we know that we want to have this ball.
So what we are doing, we are taking each player and modeling this player as a 2D Gaussian,
and then we get this action as function that is a mixture of a Gaussian, yeah.
And depending of the complexity of the production that you want to do, you can take this distribution
and take the optimal framing.
I mean, you can also compute the amount of sum to cover a lot of players or not.
But in the paper and the video that we showed, this simplification, we are just projecting
these to the mixture of Gaussian to 1D, yeah, and we have like a 1D function, and we
just want to take the peak of this function as the center of the action, and then we just
center the virtual camera at this value.
And then with the ball, we take a lot if the ball is inside or not.
However, embassable with a single view is very likely that the ball is going to be
not visible or hard to detect because someone is taking the ball or hiding the ball or doing
something, and you don't want the system to be lost in this situation.
So this action function is more stable, yeah, and the peak is not moving so fast because
it's not possible that one player that is here is going to be here in the next frame,
yeah.
So it's going to be this kind of smoothness, and we want to track this peak to get this
like a good center for the virtual camera.
Okay, cool. So the actor localization that I'm imagining is a supervised learning problem
you've got video, you've got, you know, someone's labeled your players with bounding boxes
and you just train a model to recognize the players, is that correct?
Absolutely, yeah, it's a classical, a classical, a deep learning approach, yeah.
We have some examples of ball, some examples of reveries, and some examples of pleasures.
And the class of reveries is not too easy for an NCAA, the reveries are always dressing
the same, but it depends on the basketball, yeah.
We want to take the players out, yeah, or at least to be aware of, sorry, we, yeah.
And yeah, but it's totally supervised.
And the precision and recall the, the texture, it depends, in our case, we use a JOLO
version 3, yeah, now it's available JOLO version 4, and today's, I go like your JOLO
version 5.
But there's some controversy over whether it's real yellow or something.
Yeah, yeah.
And, yeah, so the nice thing of this approach is that better, when a bird detector and a
faster is available, we can just plug here, yeah, and be more confident on the detection
of our actors, yeah.
And also we are using our core model in order to, do not train over the raw image, but we
transform the image according to the core model.
So we ensure that the network is on the observer, observing the area of the cart, yeah.
And there's some, um, proportion when we are doing this transformation that made the job
easier for the detector.
So this is why even on the large overlap, we are able to detect players with a really
good accuracy.
So elaborate on that a little bit more, it sounds like you're saying you, you have JOLO
as the detector, and that's operating on still frames, correct?
And you're, you've also got this model for the core that, you know, the angle of your
camera, and I'm assuming we're talking about like the 3D model of the core and like, uh,
the 2D 3D projections, and that kind of thing, is that what you're referring to?
Yeah, so, yeah, so since the camera is fixed, uh, we localize the, the cart, or I mean,
we localize the camera, you can see one side or the other, but it's, it's killing.
So we can compute actually a core volume.
So like the projection of a, uh, a, of a volume of interest, it might be like a four meter
high, five meter high volume in the image.
So we can take this region, yeah, and actually to crop and transport that and feed the network
when we are training, yeah, and this will ensure that the variance of the, uh, sizes for
the object that's going to be not so high and can be more specialized in order to detect
the players, because it's not expecting whatever size of players and things like that.
Yeah.
So how tightly cropped around a player is the image that you're feeding to the detector?
Is it, is it very tightly cropped or is it, you know, half-court or, or something like
that?
No, no, it's, is the, is the full court, yeah, but imagine that we are taking out everything
that is not the court and just taking like a crop that exactly contains, uh, all the pixels
of this volume and the players there, uh, they're going to look, uh, similarly in shape,
I mean, it's not likely to have like, uh, better in this transformation that, that's going
to be the double or, you know, three times the size of other.
So the number of, of, of anchors for Jolo, it's going to be, um, um, as well as number,
yeah.
Okay.
I mentioned earlier that part of your, uh, your, the contribution of this paper is, um,
being able to, at least what I took as being able to do this kind of actor detection and
localization in a, in a short time frame, can you elaborate a little bit more on if you've,
you've got the out of the box detector, what pieces are you doing on top of that?
Yeah, so then when, when we have all these, uh, detection of actors, they depended a lot
on Jolo, uh, version three, yeah, and it's going to be faster when a new detector or, or
faster, the, uh, so actually we did like sound changes in Jolo, uh, usually Jolo is not
so good for small objects, but in basketball, there is one small object that is really important
that is the, that is the ball, yeah, so actually, um, um, that is like, um, a map that is, uh,
component in different, uh, layers, we modify one layer in order to take, uh, the later 11,
that is able to get, uh, some interesting feature of small objects, uh, till 14, times 14, uh,
size, yeah, and this enables us to detect the ball in a more consistent, uh, way.
So starting with these detections, then we, we use our core model, again, to localize the
players in this, in the core plane, and to create this action as function, yeah, but then, or also,
we get that to the histograms that is trying to estimate, uh, where is the state of the game?
Yeah, if it is a half-core, uh, timeout, or a transition or something, in order to switch
for the proper role, yeah, or the production. And yeah, is that, is that based solely on player
position, the, yeah, game state? Yeah, yeah, yeah, yeah, so for this paper, yeah, but, uh, of course,
you want to also add the tempo information, yeah, because you can, you can have like a
distribution of players for different situations, yeah, but the story, it's, uh, yeah, I mean,
that would have worked. I would imagine like right after a basket, if you're the balls being
inbounded, you're going to want to, to be zoomed out, because you know the ball is going to end
up on the other side of the core quickly, or something like that. Like, there's incorporating in
knowledge about not just where the, the, the players are, and where the ball is, but like, what's
actually happening from a semantic perspective could be interesting, an interesting signal.
Yeah, so actually right now, we are trying to, uh, move forward with these, uh, we're including
more things. Okay. We really want to have like a live, but I create enough method for production,
without trying to get all these components, uh, and trying to have like something, because we really
want to be really fast, yeah, and trying to build on that. But then depending of the challenge,
and there are some challenges that the system is failing, sometimes you don't want to lose, uh,
small part of it transition, or you are trying to follow someone that is going with the ball,
and you arrive a bit late, yeah. And yeah, sometimes it's, it's, it's happening, yeah, but they're
really, uh, small cases. Yeah. So it's like because it's combining all these ingredients, yeah,
the action, the game estate, and then there is a controller that is really simple, and depending
of the state is deciding something, yeah, I'm producing a really high quality. And however,
there's something that I really like to have, like trying to have more sum and a variety of sums,
premiums, uh, bit, uh, during the health court possession, trying to be more like tracking the
action, yeah, but it needs more, um, awareness. The system really needs to understand more states
inside, uh, the health court state, for instance, like a screen in the key area,
or so what is preparing for taking a three-pointer, or something like that, yeah. So our idea is to
increase the number of states, yeah, because this number of states will increase the number of
rules of production that we can have. Okay. And are the, the rules for your controller,
are those handcrafted, or are those learned as well? Yeah. And so we have this core volume, yeah.
Yep. And so imagine that we do want to have like a sum out, this is where this is you already
know your core volume, and you can find like, uh, the optimal framing that contain this core
volume, the full core volume, and it's well centered. Yeah. But then we also have another
framing. For instance, the left, uh, the left health court framing, yeah. And the right health
health court framing, but also you can have a lot of set of frameings, or you can have a continuous.
Yeah. In our case, we have a discrete, uh, set of frameings inside each health court,
and depending of the peak of the actionist, we are just moving to the proper framing inside the
health court. Yeah. This, this is like a easy solution for the problem, but you can also have
like a continuous, but I will be honest with this, this grid set of, uh, frameings, the quads,
is really good. Yeah. But the solution will be better with a continuous, uh, set of frames,
things like that. Yeah. And to be clear, when you, you, you, you have a discrete set of
frameings, but the, um, the virtual camera is not jumping from one discrete place to another.
It's a smooth transition from one to the next. So, yeah. Yeah. Yeah. Yeah. Yeah. Um, so, yeah. I'm
for doing that is actually quite this is just a proportional, uh, control when, uh, moving from
this framing to the, these started framing and trying to obey a maximum speed of the virtual
camera, because we don't want to talk, uh, use data. Uh, and so still with the, you've got this discrete
set of, uh, views. Did you just write down the rules, you know, the correspondence between the,
the game state and the, the framing or did you try to learn it anyway? No, no. Yeah. So, for the
transition is just, uh, free camera. Yeah. So it's a virtual tradition from one to another. I get
that's just following PID or performance. Yeah. No, no, sorry. So, so imagine that, I think that the two
main, uh, states of the game are transition when we are moving to one hardcore to the other,
and the hardcore position. So we expect that they're going to remain there for a 15 to a 24 second
something of that. Yeah. For doing a transition, the camera is like a free camera. Yeah. Trying to be
smooth, but trying to contain, uh, the main action or the peak of the action is and the ball at the
same time. And there is a trade of there. But the, the ball, if it's, uh, visible, it should be
continued. Yeah. And it's trying to do like a free camera. But in the hardcore, yeah, we know that
we want to be in this hardcore. So we are moving to this set of discrete, uh, views or framing,
yeah. And we are choosing, uh, the framing that is more, or that is closer to the peak of the
action is. And if we were in a different framing, we are just doing a pro, a pro proportional motion
to the next framing. Yeah. And, uh, in the, in the demo, that's a 2D projection. But the peak of
the action is in 3D on your core model, right? Because you also zooming in and out. Yeah. So
actually the peak of the action is, uh, is in 2D. So because the domain of this function is,
is the core plane. So for instance, I don't know, inside the key in the middle of the key in the,
something like that. Yeah. Uh, for a single camera, yeah. And if you don't want to do a lot of
zoom during a hardcore possession and things like that, you can just project to 1D and to select
or like a, like a panning motion of your virtual camera. Yeah. But if you really want to, uh, do like
a full professional with zoom in and, and, and zoom out and everything, you can exploit this
action in 2D and to be aware of the action is, is in the other corner of the hardcore and trying to
be more close to the action and to exploit better the pixel that you want to, uh, to broadcast.
Cool. And so you, you've suggested a few of the next steps here. Can you maybe talk a little
bit more about, you know, where you go based on this or, or have you, are there even other papers
that you've already published beyond, uh, yeah. I, I, I cannot say a lot. Yeah. But, uh, one of our,
I mean, the fourth right now is trying to improve some things. The lighting of the bayonets
sometimes is making things difficult. Yeah. Uh, yeah. So imagine that, uh, that the ball is not
detected for some reason. You have a lot of windows and you have a lot of, uh, change in illumination
and shells and things like that. And the ball is, is, is the ball detector is failing. Yeah. So
you're going to be, I mean, all your production is going to be based in the action expansion. Yeah.
And you don't have all your ingredients and we can fill. So we are trying to get more robust
detector and to get more data, yeah, because the whole detector is totally, uh, data driven. So
we need the more data that we can have in order to teach them the network to detect any
little combustible. Yeah. And if we have the ball, the metal is quite good. The other thing that we
want to do is to optimize some things. Uh, of course, we're going to run JOLO, you need a GPU,
yeah. And this kind of GPU or server that you are using will determine, uh, your inference time.
Yeah. So if you want to be fast enough, you need a good server, but perhaps, uh, you want to do that
locally in the edge. Yeah. And it's not too easy to afford this kind of server for a public
school or for a college or something like that. Yeah. So if we can get a better detector that can run
really fast in CPU or a very cheap GPU or something like that, we are trying to move that and to get
like lighter detector that they are doing a good job. And yeah, but if you have a good server
or a good internet and you can use a string to the cloud and we process in the cloud,
we are getting up. So right now we are trying to get like a multi-mysed version and trying to run.
We are a detector and to try and to correct some errors and some things that they are not so
likely, but even it's happening one time and again or two times. People that are not so happy,
yeah. So it is to be almost perfect. But at the same time, we want to include more cameras,
yeah, and trying to switch also like not expensive cameras, yeah, but trying to switch among these
cameras. And on the other hand, since we are already aware of the location of players,
at the same time without a production, we are collecting or we can collect some statistics that
they are going to be really useful, yeah, for players, for the coach, for fans, for everyone,
yeah, in real time or after the game, it depends because the necessities are different.
And have you already tried using this method with other sports? You've mentioned soccer a
couple of times. How easily generalized is it to, you know, similar but different sports?
Yeah, our abilities should work. I mean, the main, the first modules, I mean, the actors and
something like the core model or field model for soccer and things like that, but the rules of
production, if you're watching soccer or volleyball, they're going to be different. This is the
really nice part, yeah, because you don't have to change all your model, yeah, you have your knowledge
here or the knowledge of the location of the actors, but then you can incorporate other kind of
knowledge in a later stage, like how you should produce soccer or one camera or two or for
20 cameras or volleyball or any other sport, but the main ingredients, yeah, they're going to be
the same. Yeah, but yeah, we, we are trained at the other sports, yeah. So you're already starting to
look at that. Yeah, yeah, sure. Any other thoughts on future directions for this or, you know,
other things that you're excited about it, kind of this intersection of computer vision and sports?
Yeah, yeah, actually, I think that the idea of system, it's going to be, it will be like a system
able to do this over market production, but at the same time providing these statistics and
analytics for any kind of user. So for the players and coaches in real time saying, okay,
these are some statistics and events and analytics, like, yeah, but really, you know, with low
latency and all the same package and with a single camera, something like that, you install and you
get, and you have the full package. Actually, we are aiming that at this part. So you can have that,
you can have your auto production and you can have all the data that you want, yeah, with the same
system, yeah, with low latency. This is the goal. Well, Julian, thank you so much for taking the time
to chat with me about what you're up to. Okay, thank you so much for the invitation and see you later.
Alrighty, thank you. All right, everyone, that's our show for today. For more information on today's
show, visit twomolai.com slash shows. As always, thanks so much for listening and catch you next time.
you
you
