WEBVTT

00:00.000 --> 00:13.380
Welcome to the Twomo AI Podcast.

00:13.380 --> 00:15.740
I'm your host, Sam Charrington.

00:15.740 --> 00:23.720
Hey, what's up everyone?

00:23.720 --> 00:28.880
It's been nearly three years since we launched the Twomo Online Meetup, initially as a way

00:28.880 --> 00:34.040
for listeners to connect with one another and study academic research papers together.

00:34.040 --> 00:39.440
The group really took off in mid-2018 though when I mentioned off-handedly in my interview

00:39.440 --> 00:44.820
with fast.ai's Rachel Thomas that I'd be taking their course and I invited the Twomo

00:44.820 --> 00:47.480
listener community to join me.

00:47.480 --> 00:52.200
That led to the very first Twomo study group and the folks who came together for that group

00:52.200 --> 00:57.960
have become the backbone of a community that's now over 3,000 members strong.

00:57.960 --> 01:02.600
Fast forward 18 months and we've supported each other on our personal learning journeys

01:02.600 --> 01:10.640
and a wide variety of courses from stanfordfast.ai, deeplearning.ai, on Kaggle projects and much

01:10.640 --> 01:11.880
more.

01:11.880 --> 01:16.040
I say all that to say that I am humbled by the role that we've been able to play in helping

01:16.040 --> 01:21.400
folks learn machine learning and I am excited about the new educational programs that we're

01:21.400 --> 01:24.320
bringing to the Twomo community this year.

01:24.320 --> 01:28.440
We recently launched a collaboration to bring you the causal modeling and machine learning

01:28.440 --> 01:32.880
course and study group which I've mentioned here before and today I'd like to share some

01:32.880 --> 01:37.600
new details on the AI enterprise workflow study group that we're launching in just a

01:37.600 --> 01:39.200
few weeks.

01:39.200 --> 01:42.600
If you've been listening for a while you know that I am very excited about the work going

01:42.600 --> 01:47.360
on in ML and AI communities to make developing and deploying machine learning and deep learning

01:47.360 --> 01:51.640
models in the enterprise more accessible and efficient.

01:51.640 --> 01:59.320
In fact we hosted an entire conference TwomoCon AI platforms on this topic just last fall.

01:59.320 --> 02:03.720
Until now there have been very few formal resources that folks could turn to to learn

02:03.720 --> 02:08.360
real world machine learning workflows and deployment strategies.

02:08.360 --> 02:13.760
Our folks at IBM are working to change this though with the AI enterprise workflow specialization

02:13.760 --> 02:17.760
that they recently made available on Coursera.

02:17.760 --> 02:21.920
And I am super excited to share that we've partnered with them to host a study group for

02:21.920 --> 02:27.720
this six course specialization program which I will personally be hosting.

02:27.720 --> 02:31.880
The courses in the sequence teach real world machine learning and an enterprise environment

02:31.880 --> 02:37.320
including applying the scientific process to understanding business use cases and structuring

02:37.320 --> 02:45.160
data collection visualizing and analyzing data and hypothesis testing feature engineering

02:45.160 --> 02:51.320
and identifying and addressing data biases selecting the best models for machine learning

02:51.320 --> 02:59.640
vision and NLP use cases and using ensembles deploying models using microservices and containers

02:59.640 --> 03:06.720
Kubernetes and Apache spark and applying unit testing to ML models and monitoring model

03:06.720 --> 03:09.400
performance in production.

03:09.400 --> 03:13.440
I am really looking forward to working through these courses and I would love for anyone

03:13.440 --> 03:15.920
interested in these topics to join me.

03:15.920 --> 03:20.200
If this sounds interesting and you'd like to learn more, I invite you to join a webinar

03:20.200 --> 03:26.880
that I'm hosting with Ray Lopez, the courses instructor on Saturday, February 15th at 9.30

03:26.880 --> 03:29.160
a.m. Pacific time.

03:29.160 --> 03:34.360
To register, visit twimmelai.com slash AI workflow.

03:34.360 --> 03:43.680
And now on to the show, all right, everyone, I am on the line with Nemo, Nemo is the CTO

03:43.680 --> 03:44.680
at Grow Intelligence.

03:44.680 --> 03:47.120
Nemo, welcome to the twimmelai podcast.

03:47.120 --> 03:48.120
Thanks.

03:48.120 --> 03:49.120
Happy to be here.

03:49.120 --> 03:50.120
Awesome.

03:50.120 --> 03:55.640
Let's jump right in and have you share with us a bit of your background and how you came

03:55.640 --> 04:02.800
to work and the intersection of machine learning, AI and global food security.

04:02.800 --> 04:04.800
Great.

04:04.800 --> 04:10.720
So I've been at Grow Intelligence for about four years now, four and a half years.

04:10.720 --> 04:15.840
And before that, for many years, I was an engineer and tech lead at Google.

04:15.840 --> 04:20.360
And obviously working on a lot of things that are technically similar in terms of machine

04:20.360 --> 04:27.080
learning, using data, mathematical algorithms, what brought me to Grow Intelligence, well,

04:27.080 --> 04:33.400
first I met, it was the founder, Sarah Manker had a really compelling vision for why this

04:33.400 --> 04:36.480
is an important area to be working on today.

04:36.480 --> 04:41.040
And what brought me here was that AI were solving some really important problems, some

04:41.040 --> 04:44.640
of the biggest problems affecting the world.

04:44.640 --> 04:51.200
And secondly, I think that the timing of the problems that we're trying to tackle is

04:51.200 --> 04:55.920
really appropriate, meaning maybe 10 years ago, what we're trying to do today would

04:55.920 --> 04:59.160
not have been realistic or would not have made sense.

04:59.160 --> 05:04.720
And 10 years of the future would probably be not so interesting anymore because it hopefully

05:04.720 --> 05:05.720
will have been done.

05:05.720 --> 05:09.480
So I think we'll kind of have a sweet spot for this industry.

05:09.480 --> 05:16.760
And then thirdly, I think what makes it technically interesting is that from various perspectives,

05:16.760 --> 05:24.160
whether it's computer science, satellite hardware, data storage and infrastructure, a lot

05:24.160 --> 05:29.720
of different enabling technologies are available to us today.

05:29.720 --> 05:37.000
And so make this problem not just important, but also feasible, I mean, addressable today.

05:37.000 --> 05:42.960
You mentioned Sarah, I had the opportunity to hear her speak at the Black and AI workshop

05:42.960 --> 05:46.080
at last year's Neurip's conference.

05:46.080 --> 05:50.400
And so had a chance to learn a little bit about what Grow is up to.

05:50.400 --> 05:56.520
And so all she seems like an amazing person to work with, but also she does a very good

05:56.520 --> 06:03.280
job at articulating the motivation behind what you're doing and the importance of the

06:03.280 --> 06:04.280
work you're doing.

06:04.280 --> 06:06.520
Can you share a bit of that with us?

06:06.520 --> 06:12.600
Yeah, I guess the one way of putting it is what we do for getting the technical aspects

06:12.600 --> 06:17.800
is basically we help people make better decisions in the world of food and agriculture.

06:17.800 --> 06:25.400
So motivations, I think, are that the data-driven decision making hasn't quite taken hold in

06:25.400 --> 06:26.400
this industry.

06:26.400 --> 06:30.000
And obviously it's one of the largest industries in the world.

06:30.000 --> 06:36.000
Think about two billion people in the world are involved in the whole industry of food

06:36.000 --> 06:41.760
and agriculture from production all the way through its redistribution and so on.

06:41.760 --> 06:50.280
And this world is a number one, changing pretty rapidly as economies develop and culture

06:50.280 --> 06:54.720
has changed, people's diets and what type of food they eat change.

06:54.720 --> 07:02.200
So people need to make better decisions about what's going on in the world of food.

07:02.200 --> 07:08.280
Besides this, social and cultural changes and economic changes, another aspect is obviously

07:08.280 --> 07:15.080
global warming has thrown a lot of uncertainty in many different food related scenarios.

07:15.080 --> 07:20.480
And then maybe even more short-term, you know, you have trade wars and tariffs and deforestation

07:20.480 --> 07:22.480
and things like that.

07:22.480 --> 07:26.240
So a lot of locusts, is that something you're involved in?

07:26.240 --> 07:32.440
There's apparently a massive locust swarm currently in Eastern Africa and it's expected

07:32.440 --> 07:34.520
to make its way all the way to India.

07:34.520 --> 07:35.680
Yeah, absolutely.

07:35.680 --> 07:40.440
This is a huge topic in the last couple of weeks and that's exactly the type of problem

07:40.440 --> 07:42.800
where we would help people make better decisions on.

07:42.800 --> 07:49.520
So if suddenly this infestation shows up, you know, if you are trying to decide, well,

07:49.520 --> 07:56.560
what does it really mean in terms of food supply or not just in total but like how it affects?

07:56.560 --> 08:00.600
This region, that region, this type of crop, other types of crops, what will they do to

08:00.600 --> 08:03.480
prices, imports, exports.

08:03.480 --> 08:09.520
So yeah, connecting all those dots together and trying to make more informed decisions

08:09.520 --> 08:15.360
regardless of whether you're a supplier or a consumer or a processor is basically the

08:15.360 --> 08:19.480
type of problem we help to solve.

08:19.480 --> 08:21.520
But yeah, I think that's a great example.

08:21.520 --> 08:28.080
You know, a few months ago maybe you would have chosen to mention the US China trade wars

08:28.080 --> 08:37.480
as an example or the swine flu that's affecting pigs in Asia or the forest fires in Brazil

08:37.480 --> 08:38.480
and the Amazon.

08:38.480 --> 08:44.440
All of those are really great examples of the type of really huge events that affect our

08:44.440 --> 08:47.760
users and that we try to help them deal with.

08:47.760 --> 08:53.720
And so who are the typical users and maybe a bit more concretely, what are the specific

08:53.720 --> 08:57.080
types of problems that they're trying to solve?

08:57.080 --> 08:58.080
Okay, great.

08:58.080 --> 09:03.000
So yeah, I think one thing that's important, there's quite a lot of buzz in this world

09:03.000 --> 09:07.000
of agriculture these days, ag tech.

09:07.000 --> 09:13.960
So one distinction that I want to make is sort of this ecosystem is can roughly be split

09:13.960 --> 09:15.960
into two categories.

09:15.960 --> 09:19.800
There's one that you hear a lot about which is precision ag.

09:19.800 --> 09:23.960
So this is the type of, this is what we don't do, I'll start with that.

09:23.960 --> 09:30.480
And so there's a lot of really cool tech related to helping farmers make very, very local

09:30.480 --> 09:36.040
decisions, even every square foot of your field, you could say, well, should I put more water

09:36.040 --> 09:37.040
here?

09:37.040 --> 09:38.360
Should I put more fertilizer there?

09:38.360 --> 09:44.880
And so you'd have instruments and measurements on the field level and down to subfield level

09:44.880 --> 09:45.880
decision making.

09:45.880 --> 09:46.880
Exactly.

09:46.880 --> 09:51.440
Here might be like Blue River, which was acquired by John Deere.

09:51.440 --> 09:57.080
And they had a technology that you put on the back of a vehicle that would like, they

09:57.080 --> 10:01.080
would identify weeds and spray fertilizer on the weeds to make them burn out or something

10:01.080 --> 10:02.080
like that.

10:02.080 --> 10:03.080
Exactly.

10:03.080 --> 10:07.320
So it's a different, but then so that's what we call precision ag or what the world in

10:07.320 --> 10:12.880
general calls precision eggs is really advising things maybe on a few feet at a time.

10:12.880 --> 10:17.920
We're dealing with a different class of problems, which we, which we don't think there are any

10:17.920 --> 10:20.320
great solutions for right now, but it's more macro.

10:20.320 --> 10:25.760
So maybe you're not trying to decide what to do on every square foot, but if you have

10:25.760 --> 10:31.760
a chunk of land and you're trying to decide what is the best use of this land, or then

10:31.760 --> 10:38.680
in terms of what types of crops are suitable in this place, what other parts of the world

10:38.680 --> 10:41.560
have had success with this type of crop.

10:41.560 --> 10:46.120
What are the environmental conditions that make one type of crop versus another?

10:46.120 --> 10:51.200
So basically, one example is, what should I do with this land?

10:51.200 --> 10:52.680
Six months, one year.

10:52.680 --> 10:57.960
Another example is, well, if you've been producing a certain type of crop and you're concerned

10:57.960 --> 11:04.560
about the trends in production of that crop in other parts of the world, let's say you're

11:04.560 --> 11:10.600
a coffee producer from Vietnam, which is a very large coffee producer, and you're worried

11:10.600 --> 11:16.720
about oversupply or shortages, well, you should be able to quickly analyze what's going

11:16.720 --> 11:21.560
on in Brazil, even though you're in Vietnam, because you're essentially working on the

11:21.560 --> 11:24.000
same commodity.

11:24.000 --> 11:28.320
So that type of decision, you know, you say, well, will the production this year be greater

11:28.320 --> 11:30.640
than expected, less than expected?

11:30.640 --> 11:33.160
What's the weather like in the different producing countries?

11:33.160 --> 11:35.200
What are the expected yields?

11:35.200 --> 11:41.560
So those types of decisions in terms of what crops to plant, how much to expect in terms

11:41.560 --> 11:47.840
of supply and demand are another category, and then going on down the line, you know,

11:47.840 --> 11:53.480
you could be, let's say, a food processor and you're buying a wholesale wheat, let's say

11:53.480 --> 11:58.640
from corn, and you want to know where to buy it from, and maybe you're importing it from

11:58.640 --> 12:03.040
different places, so you want to predict which countries or which parts of the world

12:03.040 --> 12:12.000
will have shortages or excess supply, that's another example, or, you know, in continuing

12:12.000 --> 12:15.960
in other domains, you could have a financial application where you're, let's say, lending

12:15.960 --> 12:22.280
money to farmers, so if you want to know the probability that these loans will become

12:22.280 --> 12:27.440
delinquent, and that means you need to understand, you know, the environment and what the climate

12:27.440 --> 12:32.360
is doing to the farmers, and the probability that their crops will fail, for example,

12:32.360 --> 12:36.200
or that they will be a drought, or things like that, or that they're on the contrary,

12:36.200 --> 12:40.000
that there will be a huge production, and then the prices will be low.

12:40.000 --> 12:44.080
So all these things obviously affect the livelihood of the farmer, and therefore, as a lender,

12:44.080 --> 12:48.280
you would want to know the probability of those things, whether you're, or even if you're

12:48.280 --> 12:53.440
providing insurance, crop insurance, and you could be a bank, you could be a government,

12:53.440 --> 12:57.440
you could be all kinds of different entities that deal with that.

12:57.440 --> 13:02.440
So, yeah, there's a long list and another macro type of decision that we enable is, you

13:02.440 --> 13:07.600
know, impacts of diseases, you know, that I mentioned swine flu, this was a big topic

13:07.600 --> 13:12.560
in the world of agriculture last year, there is aflatoxins, there's like all kinds of

13:12.560 --> 13:18.080
different pests and diseases and things that affect crops that are affected by weather

13:18.080 --> 13:23.560
and climate, so, or the locust that you mentioned is also, you know, it's a typical phenomenon,

13:23.560 --> 13:28.800
but the intensity depends on weather, so if you wanted to know that it was going to be

13:28.800 --> 13:33.760
more severe or less severe than usual, those are the types of decisions that we would

13:33.760 --> 13:34.760
help you make.

13:34.760 --> 13:41.080
And now you started with talking about kind of macro level land use and how that's different

13:41.080 --> 13:43.160
from the precision egg.

13:43.160 --> 13:50.960
Are you, does that, is implication in part that you're less worried about the actual

13:50.960 --> 13:56.000
land itself, like it's clear that a big part of what you do is like market analytics,

13:56.000 --> 14:01.800
if you will, and like thing entire like supply chain of agriculture and different forces

14:01.800 --> 14:07.200
that play there, but are you also looking at the nutrients in a kind of macro plot of

14:07.200 --> 14:10.000
land, or is that all left to like the precision egg piece?

14:10.000 --> 14:15.080
No, no, that's really important actually, yeah, even on, so for example, let's say you're

14:15.080 --> 14:21.920
trying to understand if there's a shortage of one crop, how much will people substitute,

14:21.920 --> 14:25.560
how much substitution would there be in another crop, right?

14:25.560 --> 14:30.120
And a big part of that equation is understanding the content of it.

14:30.120 --> 14:37.920
So for example, we don't just try to predict the how much wheat will be produced, but

14:37.920 --> 14:42.240
we try to predict how much certain types of wheat would be produced because they have

14:42.240 --> 14:48.280
different protein content, and that affects a lot of things, everything from how much

14:48.280 --> 14:54.600
will be consumed for different uses, and as well as what the prices will be for different

14:54.600 --> 14:56.200
categories of things.

14:56.200 --> 15:02.640
So yeah, protein content or calorie content of different crops are, is a huge part of it.

15:02.640 --> 15:08.920
Also things like, you know, if what's the trade off between, I'll give you an example,

15:08.920 --> 15:16.520
I mentioned the swine flu, so that's a disease that's been affecting the pigs in China,

15:16.520 --> 15:22.520
and it's a huge deal because that's the main type of meat that's consumed there.

15:22.520 --> 15:26.960
Well you might want to know, well, okay, if there's suddenly a shortage of pork, would

15:26.960 --> 15:31.480
that translate into an increase in chicken demand, right?

15:31.480 --> 15:36.520
Because people, if pork becomes very expensive, maybe people will start eating more chicken.

15:36.520 --> 15:41.320
Now there's obviously many variables there, culture, and so on, but one of the key components

15:41.320 --> 15:43.480
is, well, how much nutrition do you get?

15:43.480 --> 15:48.800
Like what's the equivalent amount in terms of grams of protein between these two things?

15:48.800 --> 15:59.080
So the biology of plants and understanding the content is critical, even at the macro level.

15:59.080 --> 16:04.880
Now when I think about all of the problems that you just described, and then think about

16:04.880 --> 16:10.600
data that I might want to have access to in order to begin to try to solve these problems

16:10.600 --> 16:16.360
or, you know, provide some insights about them, you know, that seems huge, almost, you

16:16.360 --> 16:21.760
know, I don't want to be hyperbolic, but like infinite, like there's so much data that

16:21.760 --> 16:27.200
you could plug into or might want to plug into, you know, a system that solves these

16:27.200 --> 16:28.200
kind of problems.

16:28.200 --> 16:31.000
Like, what are your typical data sources?

16:31.000 --> 16:35.440
How do you approach data acquisition?

16:35.440 --> 16:36.440
That's a great question.

16:36.440 --> 16:39.600
So I think that, you know, just to cover the types of data.

16:39.600 --> 16:46.120
So the first thing people think of and, you know, that jumps to mind because it's visually

16:46.120 --> 16:50.360
important and quantity wise, it's important is satellite data.

16:50.360 --> 16:55.480
We have, you know, in terms of just sheer volume of data, that's the majority of our data,

16:55.480 --> 16:56.480
obviously.

16:56.480 --> 17:02.680
There's incredible amounts of information about every pixel on Earth, and it's not just

17:02.680 --> 17:08.760
images in terms of, you know, visual photography that as you, most people would imagine when

17:08.760 --> 17:15.040
you think of a satellite picture, some of it is infrared and ultraviolet and, you know,

17:15.040 --> 17:22.120
so different, all the entire frequency range of the electromagnetic spectrum has information

17:22.120 --> 17:24.520
about what's going on.

17:24.520 --> 17:30.960
So what happens is that you have different satellite hardware, which is, which is able to

17:30.960 --> 17:36.680
capture different bands of this electromagnetic signal is bouncing off the Earth.

17:36.680 --> 17:42.560
And from that, some of it is visible, so, you know, so, and some of it is not visible,

17:42.560 --> 17:47.520
but from that you can derive really complicated and very useful things.

17:47.520 --> 17:52.200
For example, you know, obviously you can derive temperature, which, well, maybe it's not

17:52.200 --> 17:56.520
so obvious, like how can a satellite that's way up in orbit know what's the temperature

17:56.520 --> 18:03.160
on the ground, but it looks at various signals bouncing off the Earth, and, you know, there's

18:03.160 --> 18:07.520
a well-established science that says, okay, but, you know, we fit a mathematical model

18:07.520 --> 18:13.320
around that, and we can determine based on the electromagnetic signature, what is the

18:13.320 --> 18:16.320
temperature at this, on each point on Earth.

18:16.320 --> 18:21.840
Similar to how, you know, you can look at a planet or a star and figure out its chemical

18:21.840 --> 18:27.840
composition just by looking at the electromagnetic signals that come out of it, we can do the

18:27.840 --> 18:29.480
same thing with the Earth.

18:29.480 --> 18:36.000
So it's temperature, rainfall, you know, including microwave signals, so you can get an idea

18:36.000 --> 18:40.440
of what kind of clouds there, how much rain is there, and how much humidity is coming out

18:40.440 --> 18:42.000
of the ground and so on.

18:42.000 --> 18:46.960
So you can estimate temperature, rainfall are more complicated things like evapotranspiration,

18:46.960 --> 18:49.640
which is an extremely important signal.

18:49.640 --> 18:56.600
It tells us how much, as the name implies, how much water is being released into the atmosphere

18:56.600 --> 19:01.120
from the transpiration or like sweating of plants.

19:01.120 --> 19:07.920
That's a really important indicator of plant health, and similarly, there's another signal

19:07.920 --> 19:13.360
called vegetation index, so again, looking at just the colors and the infrared signals,

19:13.360 --> 19:20.400
the red and green and infrared, you can determine how much biomass there is, like how much

19:20.400 --> 19:24.160
living matter there is in the flesh of these plants.

19:24.160 --> 19:28.520
That's also an extremely important signal, and you can get this information from satellites

19:28.520 --> 19:33.120
at an individual pixel level and covering almost the entire world.

19:33.120 --> 19:37.880
So there's enormous amounts of data that's from satellites, and that's, yeah.

19:37.880 --> 19:46.640
That's rapidly changing, and probably the biggest part in terms of volume, not probably.

19:46.640 --> 19:52.920
It's way more than half of our data, but in terms of importance, and this is a key point

19:52.920 --> 19:59.760
for us, is that, well, the economic data and social data is all equally important.

19:59.760 --> 20:08.360
So prices, for example, or commodity prices, or retail prices, or production, quantity,

20:08.360 --> 20:14.520
or yield, historical yields, or how much fertilizer has been used in one place or another.

20:14.520 --> 20:18.440
What is the cost of transportation from one place to another?

20:18.440 --> 20:25.000
All of these things fit together to enable people to answer these complex questions, typically

20:25.000 --> 20:30.680
involve climate, weather, economics, and that society.

20:30.680 --> 20:37.200
Even within economic and social, you've got wildly disparate data types.

20:37.200 --> 20:42.640
You've got an imagining time series data that you need to deal with, as well as documents

20:42.640 --> 20:47.440
that are best considered from an NLP type of perspective.

20:47.440 --> 20:56.680
One of the challenges is just as a baseline, many countries, governments, and non-governmental

20:56.680 --> 21:01.840
organizations and companies have been collecting enormous amounts of just basic agricultural

21:01.840 --> 21:09.000
data, in some cases for a really long time, like the US Department of Agriculture, for example,

21:09.000 --> 21:16.520
has over 150 years of data on everything from the yields of every single crop in every

21:16.520 --> 21:24.320
single county in the United States, to the production, and how much area was planted,

21:24.320 --> 21:32.960
and the crop conditions, where they're healthy, unhealthy, what percentage of the corn in

21:32.960 --> 21:38.440
this particular county was considered good as of July 3rd of this year, for every year

21:38.440 --> 21:39.440
going back.

21:39.440 --> 21:44.680
So there's incredibly granular data that we're tapping into.

21:44.680 --> 21:49.400
And same thing, from the United Nations, from the World Bank, from all kinds of different

21:49.400 --> 21:53.040
organizations, academia.

21:53.040 --> 21:58.840
So besides the obvious satellite data, there's enormous, enormously amounts of ground-based

21:58.840 --> 22:00.520
data that have been collected.

22:00.520 --> 22:09.000
And as you mentioned, some of it is really organized nicely and has modern APIs, let's

22:09.000 --> 22:12.920
say for exchange rates, we have excellent APIs, and we're not reinventing the wheel, you

22:12.920 --> 22:16.840
can figure out, you can get currency exchange rates in a really good way.

22:16.840 --> 22:23.120
But in some cases, it's obscure data sets that were typed up 75 years ago, and now exist

22:23.120 --> 22:29.080
as some text that's been scanned into an image, and then the image has been put into a PDF,

22:29.080 --> 22:37.120
and maybe it's in a different language, so you would have to do a combination of OCR, optical

22:37.120 --> 22:43.480
character recognition to extract the text from the images, and then do MLT to interpret that

22:43.480 --> 22:48.480
text and then extract structured data at the end of the day from that, which could be

22:48.480 --> 22:51.360
yields, for example.

22:51.360 --> 22:56.280
So the data itself is often a big part of the challenge.

22:56.280 --> 23:01.800
We probably could spend a whole hour talking about the data, but let's maybe take a step

23:01.800 --> 23:06.880
back and contextualize this by looking at the types of problems you solve.

23:06.880 --> 23:14.000
So we've talked about this from an end user perspective, but are there, do you approach

23:14.000 --> 23:20.960
each of the problems that your customers are looking to solve as kind of one-offs,

23:20.960 --> 23:27.920
like do you do consulting, or do you have specific categories of products that you offer,

23:27.920 --> 23:30.680
and most of the work you do kind of falls into different types?

23:30.680 --> 23:32.680
Yeah, and on a great question.

23:32.680 --> 23:39.200
So the first point, I think, is that we're offering a platform, so everything we do,

23:39.200 --> 23:46.280
as much as possible, except for some rare exceptions, everything we do, we attempt to really

23:46.280 --> 23:52.560
productize it and make it scalable and make it available to all our users, and we're

23:52.560 --> 23:56.720
going to talk a lot about machine learning and AI, but I think one important point is

23:56.720 --> 24:04.120
that we offer a platform where people can access all of this data in a highly organized

24:04.120 --> 24:11.360
way, and then they can access it visually through a web application or through an API,

24:11.360 --> 24:14.720
and we expect our customers to also build their models.

24:14.720 --> 24:19.760
So in a way, we're providing sort of this platform that gives you access to a normal wealth

24:19.760 --> 24:27.520
of data, enormous wealth of data, creating value by deriving data on top of these existing

24:27.520 --> 24:33.640
data sets, but also making you able to access it in a really organized way.

24:33.640 --> 24:43.880
So one of the applications that we have for AI is we've structured this information into

24:43.880 --> 24:49.120
a knowledge graph, so we have what some people call an ontology.

24:49.120 --> 24:54.720
So we have the grow ontology, which organizes data from hundreds and hundreds of different

24:54.720 --> 25:01.400
sources into a common language, so if we're talking about wheat, and there's many dozens

25:01.400 --> 25:07.640
of varieties of wheat, you know that a bit of data from one source that tells you maybe

25:07.640 --> 25:12.040
the protein content of wheat, and then another source that tells you the price of wheat,

25:12.040 --> 25:16.040
well, we have to make sure that the specific type of wheat that these two things are talking

25:16.040 --> 25:18.360
about is the same item.

25:18.360 --> 25:27.360
So also organizing all of that information into a structured knowledge base or in the form

25:27.360 --> 25:34.280
of a knowledge graph that relates all of these entities is a key part, and then our users

25:34.280 --> 25:44.440
can use that through an API or a web app to find insights in the data, and in some cases

25:44.440 --> 25:53.120
we will do the extra work for them in terms of like building forecasting models, predicting

25:53.120 --> 25:58.400
things that the world is interested in and making that part of the platform as well.

25:58.400 --> 26:04.280
And so for the different types of modeling tasks and the machine learning applications,

26:04.280 --> 26:09.080
what are the types of problems that you're typically attacking?

26:09.080 --> 26:12.480
So roughly, I think there's four classes of problems.

26:12.480 --> 26:18.160
One that the first one is yields, agricultural yields, which is a hugely important.

26:18.160 --> 26:27.680
We've been now doing that for about a live in production for a little over three years.

26:27.680 --> 26:33.640
And so this is things like for the first example was, can you predict the yield of corn

26:33.640 --> 26:37.200
in the US in three years?

26:37.200 --> 26:47.800
So in February 2020, we already have a prediction of what the final yield of the US corn production

26:47.800 --> 26:53.200
will be, meaning how many bushels or how many tons of corn will be produced per acre

26:53.200 --> 26:58.760
on average across the United States, as well as down to every single county.

26:58.760 --> 27:04.800
Now we're in February, so nothing has been planted yet, so we have a model that's based

27:04.800 --> 27:10.880
on historical trends, but as the season progresses and we get into March and April and things

27:10.880 --> 27:18.520
are getting planted and they're starting to grow and we see the weather, our prediction

27:18.520 --> 27:20.880
gets constantly refined.

27:20.880 --> 27:25.200
So when we say yield models, basically telling you what everybody will, the conclusion

27:25.200 --> 27:31.720
that we will reach a year from now, meaning how good was the corn yield in the US in 2020,

27:31.720 --> 27:35.280
we're constantly estimating that through a yield model.

27:35.280 --> 27:40.440
So if you log into our product every day, whatever little bit of information comes from the

27:40.440 --> 27:46.880
world that would help us better forecast the US corn yield will be incorporated and this

27:46.880 --> 27:53.680
is fully productized so that there is an answer updating itself every day.

27:53.680 --> 27:58.800
So while this is interesting, obviously people have been concerned with US corn yields for

27:58.800 --> 28:05.360
a really long time, but traditionally it's been done through very slow processes where

28:05.360 --> 28:12.800
there's a lot of human and subjective elements and maybe you'll have official updates on

28:12.800 --> 28:17.480
this year's forecast will be updated maybe once and once throughout the course of the year.

28:17.480 --> 28:22.360
So we're saying that we'll make that completely objective, automate it and do it every day.

28:22.360 --> 28:28.360
So we did that for corn in the US and started out putting our predictions in real time

28:28.360 --> 28:36.800
and it proved to be enormously successful in 2017, 18, 19, then those seasons are we correctly

28:36.800 --> 28:45.040
anticipated the final result or in several instances before the market or any other forecast

28:45.040 --> 28:51.480
or the traditional forecast had detected them and when the truth finally came out in terms

28:51.480 --> 28:58.240
of when at the end of the season when the full crop was realized in each time we'd sort

28:58.240 --> 29:03.520
of been out on a limb and predicting something unusual, it turns out we were right ahead of

29:03.520 --> 29:04.520
the curve.

29:04.520 --> 29:09.880
So that was an enormous success so that's yields and then we've done that now 10 times.

29:09.880 --> 29:19.640
We did it for corn in the US, soybeans in the US, in Argentina and in Brazil, wheat in

29:19.640 --> 29:25.480
India, in Russia, in Ukraine and corn in China as well.

29:25.480 --> 29:30.680
So again, a number of different cases where we've managed to build really good yield models

29:30.680 --> 29:37.280
that are sort of the state of the art and have been able to predict real world events before

29:37.280 --> 29:38.840
anybody else was.

29:38.840 --> 29:45.720
So that's been one area of huge success yields and in each case, like I said, our customers

29:45.720 --> 29:50.440
would also look at maybe they'll look at, you know, bananas and Ecuador tomorrow and

29:50.440 --> 29:55.440
we may not have already built a model for that particular case but we've shown a general

29:55.440 --> 30:00.480
framework that applies to many crops across the whole world and more importantly we're

30:00.480 --> 30:06.640
providing you all of the data so that you can use our models and use our outputs or you

30:06.640 --> 30:14.920
can also use the data and produce predictions of your own if it happens to be a series

30:14.920 --> 30:17.840
that we are not explicitly forecasting.

30:17.840 --> 30:21.720
So that's yield and well, before I move on to the second area, one thing I want to say

30:21.720 --> 30:25.760
is we were very strategic about what we choose to model.

30:25.760 --> 30:31.160
So as in, for example, in the yield case, you know, I gave you a bunch of examples.

30:31.160 --> 30:35.160
Each one sort of pushes the envelope in a new interesting way.

30:35.160 --> 30:46.920
So for example, compared to the US, let's say one of the key pieces when we started modeling

30:46.920 --> 30:52.760
wheat in India as well, a big difference is in the US, you know, most of the heartland,

30:52.760 --> 30:58.240
the corn belt or the wheat belt and so on, especially corn is concentrated in the Midwest.

30:58.240 --> 31:04.480
So even though it's a huge area, the climate in the major producing areas doesn't change

31:04.480 --> 31:05.960
that much.

31:05.960 --> 31:12.240
So, but then you go to India and you say, okay, India produces a lot of wheat, but it's

31:12.240 --> 31:15.960
planted all over the country from the north to the south.

31:15.960 --> 31:22.640
So it's actually a key technical challenge that this new example introduced is that, well,

31:22.640 --> 31:29.720
how do you do accurate crop masks, you know, how do you model the effect, you know, when

31:29.720 --> 31:35.560
it's a wide range of latitudes from north to south and the climate is very different.

31:35.560 --> 31:39.800
And then the second piece there is, unlike the US, you know, the farms tend to be really

31:39.800 --> 31:41.120
small.

31:41.120 --> 31:49.400
So figuring out, you know, which points have wheat versus rice versus corn and so on or

31:49.400 --> 31:53.880
just forest and, you know, other things is much more difficult in India.

31:53.880 --> 31:58.960
So just all that to say that each of these examples is sort of pushes the technical envelope

31:58.960 --> 31:59.960
in a different way.

31:59.960 --> 32:06.400
And so that was, and so yield is that that's one big area where we've done a lot of work

32:06.400 --> 32:12.840
and if you go to our website, we've published a bunch of papers on that and in our products

32:12.840 --> 32:19.760
where, like I said, you know, these forecasts are there on a daily basis fully automated.

32:19.760 --> 32:29.440
The second area, fairly closely related is crop masking, so that is a key piece of yields,

32:29.440 --> 32:32.960
but it's yield forecasting, but it's its own problems.

32:32.960 --> 32:40.080
It's basically looking at satellite imagery as I described before, not just visible, but

32:40.080 --> 32:43.920
all the whole spectrum across time.

32:43.920 --> 32:52.640
We try to predict what is or ought to figure out what is going on in each pixel in terms

32:52.640 --> 32:59.680
of is there wheat being planted, is there sugar, is it bananas, is it coffee, is it what

32:59.680 --> 33:00.680
the crop is.

33:00.680 --> 33:05.600
And this is extremely important and we do that by looking and that's called crop masking.

33:05.600 --> 33:10.960
So it's an important point because by itself, it's a really useful bit of information

33:10.960 --> 33:11.960
to have.

33:11.960 --> 33:15.640
You're essentially trying to label each pixel with a crop?

33:15.640 --> 33:16.640
Yeah.

33:16.640 --> 33:23.480
And what makes it complicated is that, well, first of all, a lot of crops look the same

33:23.480 --> 33:29.720
in terms of, so you use things of how they evolve over time, you know, if it peaks in,

33:29.720 --> 33:34.520
you know, if a certain signal peaks in July versus it peaks in August, then it tells you

33:34.520 --> 33:40.520
whether it's this crop or that plant, this other crop.

33:40.520 --> 33:46.360
But yeah, so we're trying to map the figure and then secondly, is that if you could assume

33:46.360 --> 33:52.600
it's all constant, then it's a fairly well solved problem, you know, you could, but the problem

33:52.600 --> 33:54.560
is, you know, the world is dynamic.

33:54.560 --> 33:59.160
So even in the same form, there's such a, there's a thing called crop rotation where

33:59.160 --> 34:03.840
people, for various reasons, will plant different things every year and sometimes it will be

34:03.840 --> 34:09.240
a predictable cycle or sometimes it's driven by the weather and sometimes it's driven by

34:09.240 --> 34:10.520
market conditions.

34:10.520 --> 34:15.560
So that happens a lot in the US with corn and soy, for example, the same farmer could

34:15.560 --> 34:19.040
choose to use this land for corn or use it for soybeans.

34:19.040 --> 34:25.360
So if you're trying to predict the corn yield of this year, 2020, knowing which pixels are

34:25.360 --> 34:31.640
corn and which pixels are soybeans, obviously has a huge impact because when you then apply

34:31.640 --> 34:35.640
the other signals, let's say the temperature, you know, you need to know, am I looking at

34:35.640 --> 34:39.800
a temperature in a spot where there's corn or am I looking at a temperature in a spot

34:39.800 --> 34:43.640
where there is soy beans because we will have a different effect.

34:43.640 --> 34:49.200
So crop masking is its own problem, even though it's an important input to yield, it's its

34:49.200 --> 34:55.480
own huge problem and so that's a big area where we're doing a lot of work in and that's

34:55.480 --> 34:57.480
a different type of machine learning.

34:57.480 --> 35:05.040
So yields that I mentioned before is you often using regression methods, whereas crop masking

35:05.040 --> 35:15.960
is heavy on image processing and in season crop masking is a combination of, you know,

35:15.960 --> 35:22.640
these image cubes of the same place over time, you apply with neural network techniques

35:22.640 --> 35:29.120
applied to it, help you make a much better guess than otherwise in terms of what each pixel

35:29.120 --> 35:30.120
is.

35:30.120 --> 35:36.080
So that's so crop masking is another example and that one is uses a lot of image processing.

35:36.080 --> 35:41.760
A third example of a class of problems we work on is droughts.

35:41.760 --> 35:49.040
That's very similar to yields, but for different applications that predicting droughts, there

35:49.040 --> 35:56.320
are standard international classifications of, and these are discrete classifications.

35:56.320 --> 36:02.120
This is a drought of level one or level two, level three, you know, these are the correspond

36:02.120 --> 36:06.880
to severities kind of like you have hurricanes, severities and so on.

36:06.880 --> 36:14.240
So unfortunately, the world doesn't have a single, automated, fully objective way to

36:14.240 --> 36:19.280
classify the entire world and say, okay, is there a drought, yes or no, how intense is

36:19.280 --> 36:20.280
it?

36:20.280 --> 36:26.280
Is it a one, two, three, four, five, or zero, or, you know, meaning it's totally normal.

36:26.280 --> 36:30.760
So what we're trying to do, but there is some manual processes that have been developed

36:30.760 --> 36:37.000
over time, historically, for example, governments like the US government will pay or many governments

36:37.000 --> 36:41.880
will pay farmers if there is a drought, it's a, you know, drought insurance.

36:41.880 --> 36:48.320
So that type of stuff, you know, is very inefficient because there isn't a single benchmark.

36:48.320 --> 36:54.840
So we're trying to create a completely objective drought index that the entire world can agree

36:54.840 --> 37:03.800
on and it applies for every place in the world, takes into account all the weather and environmental

37:03.800 --> 37:10.720
signals and produces a consistent labeling, you know, drought severity.

37:10.720 --> 37:17.520
And so that's an interesting class of problems that we're working on.

37:17.520 --> 37:23.720
And the fourth category that I haven't mentioned yet is a completely different type of problem,

37:23.720 --> 37:28.560
which is the knowledge graph automation.

37:28.560 --> 37:34.960
So as I mentioned, you know, we bring in data from, you know, dozens and dozens of sources

37:34.960 --> 37:41.520
all the time and we want to organize that into a common ontology so that if we have some

37:41.520 --> 37:45.480
data, like I mentioned about corn, we know it's about corn.

37:45.480 --> 37:50.360
If it's yellow corn, we know it's about yellow corn, et cetera, or we know if it's temperature

37:50.360 --> 37:56.240
on the ground versus temperature, you know, on the land surface versus temperature, you

37:56.240 --> 38:01.400
know, in a weather station, a couple of meters above ground, it's a totally different concept

38:01.400 --> 38:04.120
like the temperature of the ground and the temperature of the air.

38:04.120 --> 38:09.160
So we, you know, our system has to know what exactly you mean by temperature.

38:09.160 --> 38:13.280
So this means it's highly, highly structured.

38:13.280 --> 38:18.760
That means all these data that come from outside sources have to be mapped and transformed

38:18.760 --> 38:24.920
into this common structure so that we're referring to the same entities.

38:24.920 --> 38:32.160
And that, as, you know, we're growing exponentially, we currently have about 55 million data series

38:32.160 --> 38:37.480
a little over that in our platform and it's doubling every six to nine months.

38:37.480 --> 38:44.280
So one of the key pieces is that, you know, we want to be really accurate but also efficient

38:44.280 --> 38:50.480
about mapping, you know, outside knowledge into our internal knowledge graph.

38:50.480 --> 38:56.640
So that means we have a whole class of problems related to knowledge graph automation.

38:56.640 --> 39:07.680
So that involves graph algorithms and NLP and, you know, slightly less structured neural

39:07.680 --> 39:09.400
network approaches and so on.

39:09.400 --> 39:16.400
That will help us, you say, when we have a source that says, you know, if some of it is just

39:16.400 --> 39:22.760
plain language translation as well, but it's really understanding that, hey, if we have

39:22.760 --> 39:30.560
a Vietnamese data series that talks about, you know, the yields of rice and there's three

39:30.560 --> 39:36.120
varieties of rice, it's really important that, you know, we map that correctly into the

39:36.120 --> 39:41.200
items that we call these three or 10 varieties of rice and making sure that, you know, the

39:41.200 --> 39:45.640
Vietnamese word and the English word, you know, are referring to the same thing.

39:45.640 --> 39:46.640
Right.

39:46.640 --> 39:51.080
So in addition to any models that you're using to kind of extract the data, for example,

39:51.080 --> 39:59.440
you talked about pulling tab your data from PDFs, you're also using models to kind of

39:59.440 --> 40:06.880
dynamically update the way data is kind of ingested into this knowledge graph and how it's

40:06.880 --> 40:08.960
labeled and things like that.

40:08.960 --> 40:09.960
Exactly.

40:09.960 --> 40:10.960
Exactly.

40:10.960 --> 40:15.880
So the knowledge graph, you can think of it as the knowledge graph is sort of the foundation

40:15.880 --> 40:19.240
and then using that knowledge graph, we map stuff.

40:19.240 --> 40:25.400
So and we automatically try to learn what the description of things that come from outside

40:25.400 --> 40:31.600
and map that into our into our ontology so that, but this part, by the way, I think is

40:31.600 --> 40:37.840
an important thing to note is we, you know, AI will help us get 80, 90% of the way there,

40:37.840 --> 40:44.680
but we still have human beings really review and understand these things so that if our

40:44.680 --> 40:50.640
knowledge graph automation says that, oh, a maze is the same thing as corn, well, there's

40:50.640 --> 40:57.200
still going to be, you know, unless it's like 99.99% confidence, there will still be a

40:57.200 --> 41:01.440
human who says, is really is a maze really the same thing as corn, yes, it makes sense

41:01.440 --> 41:02.440
and proves that.

41:02.440 --> 41:07.560
Well, it's a lot easier to fix those problems before you pollute the pool, so to speak,

41:07.560 --> 41:11.920
when you have, was it say, 55 million data series that you're mapping?

41:11.920 --> 41:12.920
Yeah, exactly.

41:12.920 --> 41:13.920
Exactly.

41:13.920 --> 41:20.000
So I think the, sometimes, and those, the way the data comes in from outside, sometimes

41:20.000 --> 41:26.600
it's not clear if, or, you know, the, the, the, not every source has a cleanly organized

41:26.600 --> 41:32.880
way of representing how, what something is versus how it's measured and things like that.

41:32.880 --> 41:38.560
So yeah, so yeah, that's, that's, we're creating the, the transformation instruction set,

41:38.560 --> 41:41.760
if you will, through AI.

41:41.760 --> 41:48.120
Speaking about kind of that quality of that data set that you're working with, how do

41:48.120 --> 41:54.520
you try to account for noise or missing values in the data that you collect?

41:54.520 --> 41:55.520
Do you try?

41:55.520 --> 41:59.400
Do you kind of have a principle that says, we're just going to record what we're given?

41:59.400 --> 42:02.280
Or do you try to correct it on ingest?

42:02.280 --> 42:03.440
What's your approach there?

42:03.440 --> 42:05.000
Yeah, no, great question.

42:05.000 --> 42:12.440
So I think that, for us, reproducibility and attribution is really, really important.

42:12.440 --> 42:16.880
So at the bottom layer, you know, or I should say that the first layer in our platform

42:16.880 --> 42:24.440
after the data has been transformed, the values that we, we have are can be directly traced

42:24.440 --> 42:27.760
to, to where it came from.

42:27.760 --> 42:34.320
So if we say, you know, the MDVI of, you know, the meaning of the amount of vegetation in

42:34.320 --> 42:41.360
this particular pixel is, you know, 0.5 or whatever, like then, then, then, we'll have

42:41.360 --> 42:43.480
that value where it came from.

42:43.480 --> 42:48.240
If the source revised it, we'll also annotate that and say, okay, this was the yesterday

42:48.240 --> 42:52.080
they said it was this much and then today they revised it to this much and this applies

42:52.080 --> 42:58.960
to, you know, economic data as well as satellite data, you know, hardware or changes or algorithm

42:58.960 --> 42:59.960
changes.

42:59.960 --> 43:06.600
So, and so even after transformation, we always have the original value and we annotate it

43:06.600 --> 43:10.640
with things like when it was reported, when it was revised, etc.

43:10.640 --> 43:16.800
So all our data series are actually three-dimensional in the sense that there's the value, there's

43:16.800 --> 43:21.560
the time and then there's also the potential revisions that could have occurred in the past

43:21.560 --> 43:25.200
on that particular point.

43:25.200 --> 43:28.600
And that, that's really, really important when, especially when you're dealing with things

43:28.600 --> 43:32.360
like estimates or forecasts and so on.

43:32.360 --> 43:37.760
And then, like, and of course, it's very important because we don't know in advance every single

43:37.760 --> 43:42.240
use case that people will be using it. So if you've, if you've done some analysis and

43:42.240 --> 43:47.000
then the data changes because the source made some corrections, it's really important

43:47.000 --> 43:52.280
that you can, as a user, you can totally see why that happened and where it came from.

43:52.280 --> 43:58.760
That said, on top of that, we add, so we do a bunch of things.

43:58.760 --> 44:04.760
One is that, as I mentioned, you know, we build models, so we create brand new data that

44:04.760 --> 44:10.360
are forecasts and predictions and so on from the existing data and those are available in

44:10.360 --> 44:13.880
the data in the platform, just like other things.

44:13.880 --> 44:18.040
So as I mentioned, the yield and the drought index and all these things that I mentioned.

44:18.040 --> 44:26.840
We also do a lot of grow derived, which is grow derived data series, which are like basic

44:26.840 --> 44:33.520
operations that combine data from multiple sources.

44:33.520 --> 44:41.280
So for example, you know, you may have a trivial example would be, you know, we have population

44:41.280 --> 44:45.440
data from, let's say, the World Bank about every country in the world and how it's growing

44:45.440 --> 44:48.560
and including projecting it into the future.

44:48.560 --> 44:53.800
And then you have consumption data, let's say, from some other organization or then, you

44:53.800 --> 44:58.480
know, and well, if you join those two, you can get per capita consumption, which, you

44:58.480 --> 45:01.960
know, so you get some data from one source, some data from another source.

45:01.960 --> 45:06.400
You combine them and you create a new data series that's of independent interest.

45:06.400 --> 45:10.880
So that's, so we do a lot of those types of things as well.

45:10.880 --> 45:14.960
And then finally, I think the most basic answer to your question, though, is that, you

45:14.960 --> 45:21.480
know, we try, if something is fundamentally difficult data, we often try to get multiple

45:21.480 --> 45:22.480
sources.

45:22.480 --> 45:28.840
So if you go into our product and you say, how much sugar was produced in Brazil last

45:28.840 --> 45:33.920
year or even, you know, last month, you use probably five different sources that will

45:33.920 --> 45:38.320
tell you that we have that, give you that number and, you know, they might differ by a few

45:38.320 --> 45:41.840
percent because we use different methodologies and so on.

45:41.840 --> 45:48.760
And you can, you can take them each individually or we can give you the average of them or we

45:48.760 --> 45:54.080
can give you what we've selected as sort of the best combination of things.

45:54.080 --> 46:01.360
So yeah, the answer is, you know, often you triangulate the truth from multiple sources.

46:01.360 --> 46:04.480
And that's often the big part of the value, right?

46:04.480 --> 46:10.840
You know, if you look at, especially these hugely important economic, hugely economically important

46:10.840 --> 46:15.160
commodities, you know, there's a lot of speculation and hidden information and so on.

46:15.160 --> 46:21.560
So a lot of the use cases are about getting the same information from multiple sources

46:21.560 --> 46:26.480
to get a better version of the truth and then building decisions on top of that.

46:26.480 --> 46:34.320
And with that, you know, the speculation and competition, even on a kind of nation state

46:34.320 --> 46:41.080
stage, do you worry about adversarial use cases or data poisoning or anything like that?

46:41.080 --> 46:47.840
Yeah, I mean, I think, I mean, we don't have any specific concerns, but it is the type

46:47.840 --> 46:52.240
of thing that each customer would have their own concerns. So we try to make sure that

46:52.240 --> 46:59.960
if there's, if there are multiple versions of the truth, we try to get all of them or

46:59.960 --> 47:08.640
all the relevant ones. So, but at the end, so I think at the end of the day, also satellites

47:08.640 --> 47:17.040
are, it's hard to lie to a satellite. Although it's possible, it's possible, you'd be amazed

47:17.040 --> 47:22.560
that are the adversarial things that can be done. But yeah, I think the, there is, there

47:22.560 --> 47:27.400
is no magic answer. It's trying to get the best possible information, the most objective

47:27.400 --> 47:36.280
possible sources and then make sure that it's interpreted and mapped and organized correctly.

47:36.280 --> 47:44.480
And then obviously, then when we do modeling, we spend an enormous amount of time backtesting,

47:44.480 --> 47:51.560
looking at historical data, looking at different algorithms. And I think this touches on another

47:51.560 --> 47:56.560
point, which is really important that we haven't discussed yet, is that we try to avoid black

47:56.560 --> 48:03.040
box models. If it's possible to predict something or forecast something with a model that

48:03.040 --> 48:11.760
has, you know, more explanatory power, slightly transparent model, we will, versus a black box

48:11.760 --> 48:17.600
model, we will prefer the former, all else being equal. So, for example, you know, we talked

48:17.600 --> 48:22.880
a lot about yield. If we say, well, the yield, we think the yield is going to be higher than

48:22.880 --> 48:27.840
expected this year, you know, all of a sudden, then we want to be able to say, well, the reason

48:27.840 --> 48:33.800
why our forecast is optimistic or whatever, or just change yesterday relative to today

48:33.800 --> 48:41.080
is because this signal moved, right? And that's a hugely important thing in terms of building

48:41.080 --> 48:46.120
confidence in the models, and also letting people use them in the real world. So, if you

48:46.120 --> 48:53.560
have a model that says, for example, the yield of soybeans in the US was dramatically

48:53.560 --> 48:59.720
affected by the temperature in November, and that doesn't make sense, like physically,

48:59.720 --> 49:03.840
because by November, all the soybeans have finished growing, and they should be, you

49:03.840 --> 49:08.120
know, harvested by that point, so that why would the temperature affect it physically

49:08.120 --> 49:12.200
biologically? So, our model is kind of, are not just black boxes where you just throw

49:12.200 --> 49:18.080
tons of data and see what comes out. It's really saying, like, well, we want the model

49:18.080 --> 49:23.800
to model reality and understand the signals that go in or signals that make sense from

49:23.800 --> 49:29.160
a process, physical point of view, and then we can also open the box and see what it's

49:29.160 --> 49:34.880
doing and understand it, and it makes sense from a biological and economic point of view.

49:34.880 --> 49:40.080
It certainly makes sense that all things being equal, you'd prefer the more explainable

49:40.080 --> 49:48.080
things, but often, all things aren't equal to find that you have specific use cases where

49:48.080 --> 49:54.200
the advantages, performance, or otherwise, lead you to use black box models.

49:54.200 --> 50:04.680
Yeah, so I think, yes. And, you know, then it's a trade-off, but, you know, we'll do whatever

50:04.680 --> 50:09.720
is the best trade-off. So, there are cases where it's a little bit black boxy and neural

50:09.720 --> 50:17.400
networky, but, like I mentioned, for example, the image processing and crop masking over

50:17.400 --> 50:27.280
time, you know, it could be, if it's sometimes you would be able to explain it, because let's

50:27.280 --> 50:31.480
say, you know, like I mentioned, there's rotation between crops, sometimes it's a very

50:31.480 --> 50:36.360
regular thing, you know, let's say, one year, you plan, sorry, one year, you plan corn

50:36.360 --> 50:41.360
and you add her. And so, if it's a very predictable pattern and that comes out of it, then you're

50:41.360 --> 50:48.200
like, oh, okay, that pattern was picked up. But, if it's much more, but sometimes in this

50:48.200 --> 50:54.800
case, this is an example of, we've tried both approaches, and there are cases where,

50:54.800 --> 51:00.280
I shouldn't say both, both classes of approaches, and there are some cases where, so we reach

51:00.280 --> 51:05.480
the limit. So, we went through a classical approach where it's not black box and we're

51:05.480 --> 51:11.640
explicitly modeling every single signal and looking at its temporal signature and saying,

51:11.640 --> 51:15.960
you know, when did it turn on, when did it turn off and try and to fit it into very specific

51:15.960 --> 51:21.880
models of behavior. So, we've done a really, we've gotten, we've gotten really great results,

51:21.880 --> 51:27.000
but sort of we got to the point where we want to go even further and get higher accuracy.

51:27.000 --> 51:35.080
And in that case, you have to take models with, you know, many thousands of, there are

51:35.080 --> 51:39.560
tens of thousands of signals, so you're not necessarily going to be able to interpret

51:39.560 --> 51:47.480
it every time. And do your models tend to be, you know, wide or monolithic types of models,

51:47.480 --> 51:53.400
or do you rely heavily on hierarchy and assembling and things like that?

51:53.400 --> 52:01.560
More of the latter. So, for example, when we work, so hierarchy, time scale hierarchy is

52:01.560 --> 52:07.880
really important because the nature of the, for example, let's go back to the yield example.

52:07.880 --> 52:13.560
If you look at the, and yield, by the way, is super important because that's the hard variable.

52:13.560 --> 52:20.200
If you ultimately care about how much food will be produced, but the amount produced is yield

52:20.200 --> 52:27.480
multiplied by area, right? So, the area is relatively easy to estimate. Again, there's parts of

52:27.480 --> 52:32.760
the world where that's hard too, but if the, but so the yield is the sort of the magic variable

52:32.760 --> 52:37.400
that everybody is paying attention to a lot because that's the one that changes year to year if it's

52:37.400 --> 52:43.000
too cold, too hot, et cetera. And so yields that are driven by two very different time scales.

52:43.640 --> 52:49.800
One is if you look at the yield over a hundred years, you'll see just dramatic improvements,

52:49.800 --> 52:55.080
you know, and depending on the crop, that curve will look like an exponential or a straight line

52:55.080 --> 52:59.800
or a sigmoid shape. It's kind of like how you have more's law in electronics. There's like,

53:00.360 --> 53:06.360
there's similar things happening in crops because people get better at breeding the right seeds and

53:06.360 --> 53:15.160
figuring out what seeds work where and things like irrigation comes in or pesticides or fertilizers.

53:15.160 --> 53:21.320
So, there's just long-term trends that are very important. So, that's the long-term trend model,

53:21.320 --> 53:27.560
and that's one time scale, but that will only give you the, that won't tell you what changed

53:27.560 --> 53:35.400
unexpectedly in 2020 or in 2019. So, so we do construct yield models explicitly as two levels.

53:35.400 --> 53:39.880
One is a long-term trend model that's saying even even on, you know, the first day of the year

53:39.880 --> 53:44.920
before a single seed has been planted, we already have an idea of where long-term

53:44.920 --> 53:49.640
progress should be, and it's different for every country and every crop. And then off of that

53:49.640 --> 53:54.200
baseline, so that, you know, that that by itself is valuable, right? Like you could just have long-term

53:54.200 --> 53:58.680
forecasts, I can say, okay, this is what it's going to be like, you know, in Germany in 2021,

53:58.680 --> 54:06.120
and in India or Pakistan in 2022, etc., you can have forecasts. But then the short, the intra-year

54:06.120 --> 54:10.920
part is saying, okay, what's going on this year? How much has been planted? What's what was the

54:10.920 --> 54:16.920
temperature, the time, you know, at different point, reason and so on? So the in-season model is

54:16.920 --> 54:22.760
taking a whole bunch of other daily and weekly and so on signals, whereas the long-term model is

54:22.760 --> 54:29.960
taking, you know, annual and historical trends. So, so yeah, for yield is an example where

54:29.960 --> 54:35.720
decoupling those two, and you could try to model just the, just model it as a time series without

54:35.720 --> 54:43.800
doing that. But then you're just, the problem becomes way, way noisier and harder and you just

54:43.800 --> 54:52.920
don't get good results. And so, so it's very much, yeah, so that's that's one example. Another

54:52.920 --> 54:59.400
example is demand, on the demand side, which we haven't talked too much about, but, you know,

54:59.400 --> 55:04.040
if you are trying to forecast consumption of different things, similarly again, there is some

55:04.040 --> 55:12.920
long-term trends that are driven by like economics, you know, and and culture. So, for example,

55:12.920 --> 55:19.640
you know, the many countries throughout the world, you know, as the GDP, as the income per capita

55:19.640 --> 55:26.920
increases, and people rise out of poverty, the amount of meat that they eat is going to increase

55:26.920 --> 55:34.440
because when very poor people generally can't afford to eat meat or any kind. So, as countries develop,

55:34.440 --> 55:39.400
the first thing, one of the things you see is the, the diets start to change. So, those types of

55:39.400 --> 55:44.680
things are macro long-term trends, so you definitely need a long-term model for that. But then on

55:44.680 --> 55:49.800
top of that, you know, on any given year, prices could be high, and so the demand for one thing

55:49.800 --> 55:55.400
could be high or lower, or things, you know, trends can change. So, similarly on the demand side,

55:55.400 --> 56:00.760
there is also these short and long-term timescales, and modeling them explicitly makes the

56:01.480 --> 56:07.880
the problem much more solvable. And then I think more generally, you know, if we're trying to,

56:07.880 --> 56:14.920
we feature engineering and hierarchical modeling is really important. Again, it goes back to the

56:14.920 --> 56:22.040
point about black boxes, you know, we could, we have, as I mentioned, 50s or 56 million data

56:22.040 --> 56:27.240
series, and if you translate that into different values, it's in the hundreds of trillions

56:27.240 --> 56:33.560
of data points. So, one approach would be, hey, for every problem we have, just throw every data

56:33.560 --> 56:39.160
point that exists in our country to it and say, yeah, sure, let the machine learn it, right?

56:40.360 --> 56:44.760
But the problem is you can't give a machine like 600 trillion data points and say, okay,

56:44.760 --> 56:50.360
predict one value, it needs a lot of help. So, we have enormous amounts of expertise in the

56:50.360 --> 56:58.680
company in terms of, you know, remote sensing experts, agronomists, hydrologists, some people

56:58.680 --> 57:03.960
like that who are saying, okay, well, don't just throw a million features, these are the 100

57:03.960 --> 57:09.640
features that really should matter, right? And then when we see impact of different features,

57:09.640 --> 57:15.640
we can say, oh, yes, that makes sense. But this feature, this phenomenon, this cause, you know,

57:15.640 --> 57:21.640
this cause has this effect because we understand how these, whether it's biology or economics

57:21.640 --> 57:26.840
or transportation or what have you. There is some domain knowledge that that says, yes,

57:26.840 --> 57:32.280
this makes sense. Well, I know we're running a bit long here. If you've got time for one more

57:32.280 --> 57:38.040
question, I'd be curious to have you, you know, just give us a sense for your overall modeling

57:38.040 --> 57:45.080
process. And in particular, if there are any unique aspects to the way you approach models

57:45.080 --> 57:50.120
beyond the things that we've talked about as far systematically. Yeah, I think, I guess,

57:50.120 --> 57:54.920
the one of the key things is what we choose to model. As I mentioned, you know, we have a platform

57:54.920 --> 58:00.680
where you could really be modeling a million different things every day because we're giving

58:01.560 --> 58:05.960
this highly organized platform that allows you to answer all kinds of questions.

58:06.520 --> 58:14.040
There's a few things we do before we decide to model something. One is, is it an important problem

58:14.040 --> 58:19.880
to model, right? Like all the examples that I gave, they're not just, they're economically

58:19.880 --> 58:25.720
really interesting for our user base. So, you know, I'm like, for example, I mentioned a couple of

58:25.720 --> 58:30.520
times wheat in India. Well, you know, there, of course, there's really cool scientific and technical

58:30.520 --> 58:36.920
challenges, but the first question is, does anybody care? And in that case, the answer is, yes,

58:36.920 --> 58:42.840
it's a huge question because historically, you know, India obviously is one of, you know,

58:42.840 --> 58:48.920
one of the largest countries in the world in terms of population and the second largest.

58:50.440 --> 59:00.360
Historically, and wheat is a big staple there, you know, for the people of India. And historically,

59:00.360 --> 59:07.880
though, for the last 50 years, India has been self-sufficient mostly. So, they produce a lot of wheat,

59:07.880 --> 59:11.960
and they consume a lot of wheat, but it doesn't quite interact too much with the rest of the

59:11.960 --> 59:19.560
world's wheat. But now, you know, because India's continues to develop economically,

59:21.080 --> 59:27.480
and as well as, you know, there are some theories that their green revolution of the last 50 years

59:27.480 --> 59:33.800
is sort of leveling off, and they're kind of, some people are concerned that their production

59:33.800 --> 59:40.040
will not continue to rise as it has, but the demand will continue to rise. So, if that happens,

59:40.040 --> 59:47.400
and suddenly a small percentage change in the supply and demand of wheat in India

59:47.400 --> 59:52.200
could translate into enormous amounts of imports, right? Because it's sort of like, you know,

59:52.200 --> 59:56.680
you have this huge number of production and a huge number of consumption that are kind of

59:56.680 --> 01:00:02.920
well balanced, but if there's a small change, even a 5% or 10% difference shortage, and then they

01:00:02.920 --> 01:00:08.120
need to import that much, then that means, you know, a huge new source of demand in the world,

01:00:08.120 --> 01:00:15.000
and maybe Australians will start producing a lot more wheat to export to India or Canada and other

01:00:15.000 --> 01:00:20.840
countries who are importing will have to import from other places. So, it has, it's sort of like

01:00:20.840 --> 01:00:26.840
this big iceberg that's hiding under the water that could have a big impact. So, all that to say

01:00:26.840 --> 01:00:32.040
is that the first part of modeling process is, is it an interesting thing to model from a business

01:00:32.040 --> 01:00:40.440
point of view, and is it fundamentally? And so, you know, and that, and there's a lot of them,

01:00:40.440 --> 01:00:46.360
but it's important that we work on the right ones. And secondly, is then we, like I said,

01:00:46.360 --> 01:00:53.480
we don't come at a problem with a solution, which I think distinguishes us from many companies

01:00:53.480 --> 01:00:59.800
where we didn't start out as an AI company saying, well, you know, let's just find the

01:00:59.800 --> 01:01:07.000
problem and say to work on and stumble into agriculture, it was more a joint thing of figuring out

01:01:07.000 --> 01:01:13.560
that, you know, this particular domain needs these answers and needs better decisions, but we don't

01:01:13.560 --> 01:01:21.640
care if we end up using neural networks or gradient descent algorithm xg boosts our random forest

01:01:21.640 --> 01:01:28.440
algorithms and components, but we're agnostic to technology, but we want to solve the problem.

01:01:28.440 --> 01:01:34.600
So, I think that the second part of our approach is where every single new problem were prepared

01:01:34.600 --> 01:01:41.960
to use different approaches. But third, third piece is that when we build a particular model,

01:01:41.960 --> 01:01:50.280
we do try to build a framework that helps us experiment and reuse things in different situations.

01:01:50.920 --> 01:01:57.720
And so, for example, even though each country and crop is different for a yield modeling,

01:01:57.720 --> 01:02:04.680
we do have a basic framework that applies across the board and some, you know, the input signals

01:02:04.680 --> 01:02:13.320
will change, but there's two or three key algorithms that we will always use and then the specific

01:02:13.320 --> 01:02:19.960
inputs will be different, but the back testing and how we evaluate our results and so on

01:02:19.960 --> 01:02:28.920
will be following that process. And yeah, we try to look at, finally, when we're getting close to

01:02:30.520 --> 01:02:38.680
having something that we like and that we're ready to launch, we look at performance in very

01:02:38.680 --> 01:02:46.200
unique ways. So, for example, you know, we don't look at just the average value of our error or

01:02:46.200 --> 01:02:51.000
just the signal. But, you know, even when we're predicting a single number, let's say the wheat

01:02:51.000 --> 01:02:58.840
yield of Russia or the Black Sea region, it might be a single number at the end, but underneath it,

01:02:58.840 --> 01:03:03.240
we're actually making that same prediction in a much more granular way. So, we look at,

01:03:03.240 --> 01:03:08.840
oh, how is the error distributed spatially? Does that make sense? How's the error distributed in

01:03:08.840 --> 01:03:14.760
the back testing? Like, when we run it, when we back test historically, does it, you know, what are

01:03:14.760 --> 01:03:19.720
the years where our model would have performed better or worse? And why is that? And does that,

01:03:19.720 --> 01:03:25.080
does it just random noise? Or is it like, does it give us features that we should model?

01:03:25.080 --> 01:03:30.920
So, we have a very iterative process where we look at spatial temporal distribution

01:03:30.920 --> 01:03:37.000
performance and bring in a lot of domain expertise to sort of figure out the feature engineering

01:03:37.000 --> 01:03:46.120
and tweaks that we need to do to have a good model. Is it hard in your case to know when to stop?

01:03:46.120 --> 01:03:52.760
When it's good enough? No, I think we're lucky because, again, from the first point I started with,

01:03:52.760 --> 01:03:59.320
we usually have a very clear idea of why this is interesting. And together with that comes an idea

01:03:59.320 --> 01:04:06.360
of what's reasonable to move the needle, right? So, in terms of to add value to the world.

01:04:06.360 --> 01:04:11.880
So, you know, like, let's say if you're trying to model something in the United States, then,

01:04:12.520 --> 01:04:18.600
you know, there's typically going to be a lot of really good inputs, a lot of historical data,

01:04:18.600 --> 01:04:24.600
and better than most other places in the world. So, we will, our expectation will be like,

01:04:24.600 --> 01:04:28.280
well, okay, to make a difference in this case, we really make, we've got to make sure that our

01:04:28.280 --> 01:04:36.440
errors less than 0.5 percent, right? Because anybody can get to within 2 percent or whatever, right? Like,

01:04:36.440 --> 01:04:43.080
the data is so good. Yeah, exactly. And conversely, you go to a country where, or part of the world,

01:04:43.080 --> 01:04:49.080
where there's very little data and there's no, or maybe, maybe no ground truth at all,

01:04:49.720 --> 01:04:55.800
so on. And then you're like, well, okay, everybody's the best anybody in the world can do is 10 percent.

01:04:55.800 --> 01:05:01.320
So, or 20 percent, or they have, or maybe 50 percent, because they have absolutely no idea what's

01:05:01.320 --> 01:05:06.920
going on. And then in that case, we're like, well, okay, can we consistently robustly make a

01:05:06.920 --> 01:05:11.720
forecast that has an error of 10 percent? And that's, maybe that's awesome. That would be terrible

01:05:11.720 --> 01:05:17.320
for for something that, you know, that everybody else has a 1 percent error on, but if it's

01:05:17.320 --> 01:05:22.120
everywhere else has a 20 percent error, then we'll put it and we'll be confident that we're adding

01:05:22.120 --> 01:05:29.000
value. So, so we always know when when we're adding value and when we're not adding value. And so

01:05:29.000 --> 01:05:32.760
that gives us an easy way to say, okay, let's launch this. Even though there's a million things

01:05:32.760 --> 01:05:37.480
that we could do to improve, we're already ahead of the, you know, we're adding value.

01:05:38.200 --> 01:05:45.640
Well, Nemo, thanks so much for being so generous with your time and sharing with us what you're

01:05:45.640 --> 01:05:51.560
up to there at Grow. Very much appreciated. Yeah, thanks, Sam. And yeah, I enjoyed it. I hope

01:05:51.560 --> 01:05:55.400
it was informative and inspiring. Absolutely. Thanks so much. Thank you.

01:05:59.400 --> 01:06:05.080
All right, everyone. That's our show for today. For more information about today's guest or

01:06:05.080 --> 01:06:10.120
any of the topics mentioned in the interview, visit twomelai.com slash shows.

01:06:11.400 --> 01:06:15.880
To learn more about the IBM AI Enterprise workflow study group, I'll be leading.

01:06:15.880 --> 01:06:22.920
Visit twomelai.com slash AI workflow. Of course, if you like what you hear on the podcast,

01:06:22.920 --> 01:06:27.080
please subscribe, rate, and review the show on your favorite pod catcher.

01:06:27.080 --> 01:06:45.880
Thanks so much for listening and catch you next time.

