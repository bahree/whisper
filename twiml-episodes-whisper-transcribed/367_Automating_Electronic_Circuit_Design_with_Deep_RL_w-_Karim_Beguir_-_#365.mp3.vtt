WEBVTT

00:00.000 --> 00:13.400
Welcome to the Twimal AI Podcast.

00:13.400 --> 00:15.920
I'm your host Sam Charrington.

00:15.920 --> 00:24.080
Hey, what's going on everyone?

00:24.080 --> 00:28.220
I was just checking my calendar and noticed that by this time last year, I had already

00:28.220 --> 00:32.060
been to about half a dozen conferences in three different cities.

00:32.060 --> 00:38.460
While I don't miss planes, airports or hotels at all, I really do miss the opportunities

00:38.460 --> 00:43.260
that conference visits created for me to really connect one-on-one with listeners and guests

00:43.260 --> 00:45.260
of the podcast.

00:45.260 --> 00:49.280
Of course, what we're all learning now is that physical separation does not need to

00:49.280 --> 00:51.340
mean that we're disconnected.

00:51.340 --> 00:55.500
So let's you and I use this as an opportunity to connect virtually.

00:55.500 --> 01:00.220
I'd love to hear from you, yes, you, about how things are going for you and these unique

01:00.220 --> 01:03.180
times we've found ourselves in.

01:03.180 --> 01:04.300
What are you working on?

01:04.300 --> 01:06.740
What new routines are you establishing?

01:06.740 --> 01:10.620
What new breakthroughs or realizations might you be finding in your work or personal

01:10.620 --> 01:11.940
life?

01:11.940 --> 01:19.820
Please reach out and let me know what you're up to via text or voicemail to 314-582-5935.

01:19.820 --> 01:25.940
via email to sam at twomolei.com or via message on our website or your favorite social media

01:25.940 --> 01:26.940
platform.

01:26.940 --> 01:31.860
I hope you're staying safe and healthy and helping others stay healthy by observing social

01:31.860 --> 01:33.580
distancing.

01:33.580 --> 01:35.820
And now on to the show.

01:35.820 --> 01:37.340
Alright, everyone.

01:37.340 --> 01:39.900
I am on the line with Karim Begear.

01:39.900 --> 01:44.100
Karim is co-founder and CEO at InstaDeep.

01:44.100 --> 01:46.580
Karim, welcome back to the Twomolei podcast.

01:46.580 --> 01:47.580
Hi, Sam.

01:47.580 --> 01:49.300
It's a pleasure to speak again.

01:49.300 --> 01:50.300
Absolutely.

01:50.300 --> 01:55.860
So if Karim's name sounds familiar, that's because we spoke, we were trying to figure

01:55.860 --> 01:56.860
this out.

01:56.860 --> 01:59.260
It was between a year and a half and a year ago.

01:59.260 --> 02:01.940
The show actually was published in September.

02:01.940 --> 02:10.780
It was number 302 and you should definitely check it out for Karim's full background.

02:10.780 --> 02:17.780
But Karim, why don't you give us a brief overview of what you're up to as well as an update

02:17.780 --> 02:19.700
from what we last spoke?

02:19.700 --> 02:20.700
Absolutely.

02:20.700 --> 02:24.740
So first, it's a pleasure to be back and continue our conversation.

02:24.740 --> 02:27.340
On our side, it's been pretty inventful.

02:27.340 --> 02:29.380
The lot has happened.

02:29.380 --> 02:33.780
As you know, InstaDeep is a decision-making AI startup.

02:33.780 --> 02:38.860
So we focus on problems related to making complex decisions.

02:38.860 --> 02:45.420
We also do our own innovation in AI and try to be helpful to the community.

02:45.420 --> 02:49.580
And we've made progress, basically, on these three areas.

02:49.580 --> 02:53.860
We've been able to release innovative products in decision-making AI.

02:53.860 --> 03:01.460
We've also been able to publish and innovate in research, publishing original pieces that

03:01.460 --> 03:06.180
were actually welcome, that no ribs were we got as spotlight presentation, for example,

03:06.180 --> 03:07.940
with Google DeepMind.

03:07.940 --> 03:14.420
And we've also been very active on the community side, organizing major events in Africa

03:14.420 --> 03:22.180
and helping basically lots of young talents find and save the opportunities in AI.

03:22.180 --> 03:23.180
That's right.

03:23.180 --> 03:29.780
And we most recently saw one another at Nurebs and had a chance to catch up briefly

03:29.780 --> 03:36.780
at the Black and AI dinner, where you really pick my interest around one of the company's

03:36.780 --> 03:42.980
new initiatives or products, which is called DeepPCB.

03:42.980 --> 03:45.140
Tell us about what DeepPCB is.

03:45.140 --> 03:46.140
Absolutely.

03:46.140 --> 03:50.500
So DeepPCB actually started with a conversation.

03:50.500 --> 03:57.820
Two years ago, I had a dinner with a good friend of mine, who is actually an expert in hardware

03:57.820 --> 04:03.980
design, worked on chips for well-known phones, et cetera.

04:03.980 --> 04:09.020
And we were speaking about what is AI doing in this particular sector.

04:09.020 --> 04:15.700
And he was like, not that much, like in particular, like PCBs stand for printed circuit boards.

04:15.700 --> 04:20.140
So basically, those are the chips that you will find with all sorts of consumer electronics

04:20.140 --> 04:25.060
products, iPhones, speakers, Bluetooth, et cetera.

04:25.060 --> 04:30.580
And you know, the situation in that market was that, you know, auto-rooters basically

04:30.580 --> 04:35.860
automated systems to connect the different components, like build basically the electrical

04:35.860 --> 04:40.740
circuitry have been going on for many years, but they were not that great.

04:40.740 --> 04:45.260
And we were like, hey, that sounds like an interesting problem to look at.

04:45.260 --> 04:51.020
We started looking to it, eventually, this good friend, Nabil Truba, who is now leading

04:51.020 --> 04:53.580
our hardware team, joined in steady.

04:53.580 --> 04:58.860
And we've worked very hard on this project, and we're very proud, you know, to have been

04:58.860 --> 05:00.580
able to achieve our goals.

05:00.580 --> 05:05.620
And in November last year, we've released it in beta form, and it is a world first.

05:05.620 --> 05:10.860
For the first time, we have an AI system that is end-to-end, fully deployable and scalable

05:10.860 --> 05:16.500
on the cloud, capable of understanding how to root chips, essentially.

05:16.500 --> 05:20.820
And now last time we spoke, our conversation was focused on the work your company was

05:20.820 --> 05:28.420
doing, applying deep reinforcement learning to logistics, is DPCB also based on deep reinforcement

05:28.420 --> 05:29.420
learning?

05:29.420 --> 05:30.420
Absolutely.

05:30.420 --> 05:37.140
And there is a very strong commonality and like design philosophy between our products.

05:37.140 --> 05:40.660
So in a sense, let me give you an example.

05:40.660 --> 05:46.300
We've continued to do great work in logistics, and recently last September, we've won a major

05:46.300 --> 05:51.180
contract, for example, with Dutchaban, the German railway company.

05:51.180 --> 05:57.220
And to give you an idea, this is about routing trains on a large scale, talking about 10,000

05:57.220 --> 06:03.700
trains a day, you know, and something on some 33,000 kilometers of railway.

06:03.700 --> 06:10.100
But turns out, there are commonalities between routing trains and routing chips on a board.

06:10.100 --> 06:14.980
And so we've realized that, you know, the projects and the type of research that InstaDep

06:14.980 --> 06:18.980
is doing, is actually applicable to multiple fields.

06:18.980 --> 06:23.260
And when it comes to in particular printed circuit boards, the opportunity was compelling.

06:23.260 --> 06:28.460
So we went full speed ahead and this turned out to be our first product.

06:28.460 --> 06:29.460
Alrighty.

06:29.460 --> 06:34.460
So when you initially met with your friend, your friend mentioned that they're, you

06:34.460 --> 06:40.860
know, while these auto routers have been in place or have been in use for many years,

06:40.860 --> 06:43.500
they were not without their challenges and problems.

06:43.500 --> 06:49.340
What were some of those challenges and problems and what was the opportunity to introduce AI?

06:49.340 --> 06:54.780
I think auto routers have been, you know, they've been, there's been a lot of great work done

06:54.780 --> 07:01.660
on auto routers, but in terms of like design philosophy, the design philosophy is all about

07:01.660 --> 07:04.940
essentially using heuristics to solve problems.

07:04.940 --> 07:09.100
And we spoke a little bit about this in our past conversation.

07:09.100 --> 07:15.500
So it's very similar to, let's say, what was the status of software for chess before Alpha

07:15.500 --> 07:20.900
Zero came out, those systems, which worked very well actually, but still are built on

07:20.900 --> 07:26.500
heuristics for the hardest problems, you know, heuristics have limits.

07:26.500 --> 07:31.660
And a system that can essentially mobilize learning and learning at scale can get better

07:31.660 --> 07:32.980
results.

07:32.980 --> 07:37.780
When it comes in particular for in the status of printed circuit boards, it is actually

07:37.780 --> 07:38.780
incredible.

07:38.780 --> 07:45.100
And we are in 2020 that actually complex circuits are still designed manually.

07:45.100 --> 07:50.500
And the reason why people design those manually is because auto routers essentially fail

07:50.500 --> 07:56.900
to deliver the goods to the degree of quality, which is expected by high quality customers.

07:56.900 --> 08:03.140
So as a consequence, we see a really compelling opportunity with modern AI built on the latest

08:03.140 --> 08:04.140
innovation.

08:04.140 --> 08:06.060
Some of it actually developed in house.

08:06.060 --> 08:09.460
We actually have patents on the work we've done for the PCB.

08:09.460 --> 08:15.340
There is an opportunity to like accelerate the design cycle of products, because it's

08:15.340 --> 08:17.420
not just about quality.

08:17.420 --> 08:21.820
Human engineers do absolutely amazing work and have amazing intuition.

08:21.820 --> 08:23.300
That's about the speed.

08:23.300 --> 08:28.580
A human engineer could take in certain cases multiple weeks if not months to completely

08:28.580 --> 08:32.060
route a complex board with modern AI.

08:32.060 --> 08:37.300
We do believe that instead of that, this timing can be brought to 24 hours.

08:37.300 --> 08:42.140
This, if done at scale, would be tremendous for the industry and it would accelerate the

08:42.140 --> 08:43.140
product cycle.

08:43.140 --> 08:48.540
We are very used in consumer electronics to have a cycle every six months or a year, there

08:48.540 --> 08:50.260
is a new version coming.

08:50.260 --> 08:55.820
We believe that AI could actually accelerate that cycle.

08:55.820 --> 09:00.980
And as a consequence, also make it easier to design new products and experiment and ultimately

09:00.980 --> 09:05.460
unleash more human creativity mobilizing AI.

09:05.460 --> 09:09.580
You mentioned complexity of the boards as being one of the challenges.

09:09.580 --> 09:12.540
What are we talking about when we talk about complexity?

09:12.540 --> 09:17.100
I'm assuming we're measuring that in, for example, a number of components, but having

09:17.100 --> 09:21.540
work with circuit boards before there are also issues like the number of layers and things

09:21.540 --> 09:22.540
like that.

09:22.540 --> 09:26.700
When you talk about a complex board, what exactly are you talking about?

09:26.700 --> 09:34.460
So a board really consists in basically an AI is that we need to connect and as a consequence,

09:34.460 --> 09:37.900
like those, they can be what needs to be connected.

09:37.900 --> 09:43.180
So you have pairs of components essentially that need to be connected and there could

09:43.180 --> 09:44.820
be thousands of those.

09:44.820 --> 09:48.820
And as you mentioned rightly, they could be multiple layers.

09:48.820 --> 09:53.940
Simple designs start with two or four layers, but you could have a lot more.

09:53.940 --> 09:59.820
And the more you have layers, the more components you have to connect, the harder the problem.

09:59.820 --> 10:01.460
It is an NP-hard problem.

10:01.460 --> 10:07.220
And so this is where AI can help, particularly when you're looking at the most difficult

10:07.220 --> 10:11.700
designs that we take human engineers' significant amount of time to solve.

10:11.700 --> 10:18.980
So how do you frame this problem as one that reinforcement learning can be applied to solving?

10:18.980 --> 10:24.260
So this is another case of needle and a haystack style problem.

10:24.260 --> 10:28.460
So you have an extremely large solution space to give you an idea.

10:28.460 --> 10:32.580
The game, of course, was 10 to the power 170, roughly.

10:32.580 --> 10:38.260
We are talking here at significantly more, like this can be very, very large.

10:38.260 --> 10:43.580
And so the question is, how can I build a system that's going to figure out what is a good

10:43.580 --> 10:45.460
solution to this problem?

10:45.460 --> 10:50.580
And of course, you have lots of rules that you need to abide by.

10:50.580 --> 10:59.500
We call those DRCs, like basically design rules checks that need to be absolutely verified

10:59.500 --> 11:04.300
for the circuit board to be valid and to be deployable in production.

11:04.300 --> 11:08.900
So the question is, you have this massive optimization under constraints where essentially

11:08.900 --> 11:11.020
you need to find a good solution.

11:11.020 --> 11:16.900
And we know from recent progress and from also our own experimentation that AI systems

11:16.900 --> 11:21.660
can be built using deeper reinforcement learning to build up intuition.

11:21.660 --> 11:25.700
And so it's a little bit like humans will do it, except that you have the benefits of

11:25.700 --> 11:29.700
doing it very consistently and importantly at a very large scale.

11:29.700 --> 11:36.820
We're talking about potentially like hundreds of CPUs, if not thousands working together

11:36.820 --> 11:43.420
with GPUs to accumulate experience and sort of build up the right knowledge base to crack

11:43.420 --> 11:44.420
the problem.

11:44.420 --> 11:49.900
And so when you talk about this knowledge base, can you go into a little bit more detail

11:49.900 --> 11:57.220
into how you're building the agent and the learner and how you're kind of representing

11:57.220 --> 11:59.740
this knowledge that's being accumulated?

11:59.740 --> 12:05.700
Yeah, so this is very similar to, for example, what has been done by DeepMind for the

12:05.700 --> 12:07.340
game of chess and Go.

12:07.340 --> 12:11.740
You're going to have a learner that's essentially going to play games.

12:11.740 --> 12:17.300
And based on the outcome of these games is going to start to learn what works and what

12:17.300 --> 12:18.300
doesn't.

12:18.300 --> 12:23.660
So you can see this problem as basically having a reward function, which is completing

12:23.660 --> 12:24.660
the design.

12:24.660 --> 12:31.700
If you've completed the design and it is DRC clean, so it satisfies to all the design rules,

12:31.700 --> 12:33.780
then that's a good outcome.

12:33.780 --> 12:39.220
And so you are effectively starting, let's say from a random point, but learning as you

12:39.220 --> 12:46.820
go and sort of putting more probability on the paths that are yielding a good solution.

12:46.820 --> 12:49.660
And of course, devil is in the detail on those systems.

12:49.660 --> 12:55.340
But if you do this diligently enough, you're going to get a system that's going to start

12:55.340 --> 13:01.620
to figure out what it should do, first on small boards and then on bigger ones, and ultimately

13:01.620 --> 13:03.900
get you to competitive results.

13:03.900 --> 13:09.660
Now, I would imagine when a human engineer is working on these kinds of problems, there

13:09.660 --> 13:17.460
are certainly completion of the board is a primary goal, but I'm imagining they're also

13:17.460 --> 13:25.460
worried about the total length of their traces, which probably corresponds to noise on the

13:25.460 --> 13:29.660
board or latency between components, that kind of thing.

13:29.660 --> 13:37.260
In other words, a lot more kind of nuance characteristics than just whether all of the

13:37.260 --> 13:39.300
components are connected.

13:39.300 --> 13:42.820
Are you able to take these kinds of things into account?

13:42.820 --> 13:43.820
Absolutely.

13:43.820 --> 13:48.980
So those actually participate into the design of the reward function.

13:48.980 --> 13:51.420
So this is the way to look at it.

13:51.420 --> 13:57.700
Of course, exactly like you said, it is desirable to have a secret length as small as possible.

13:57.700 --> 14:03.460
It is desirable also to have as little as possible changes from one layer to another through

14:03.460 --> 14:05.180
what we call VS.

14:05.180 --> 14:11.860
So those can actually be expressed in the design of the reward function, such that you sort

14:11.860 --> 14:16.020
of have everything you need and that the system has everything it needs to learn.

14:16.020 --> 14:23.780
But absolutely, and one of the areas where we spent a lot of time was how can we incorporate

14:23.780 --> 14:28.340
those into like a functional mechanism that triggers learning.

14:28.340 --> 14:33.300
And we're very happy to say that actually this is positive, like this is possible.

14:33.300 --> 14:39.820
And when we look at the first announcement we made in November last year, when we announced

14:39.820 --> 14:45.620
the beta release, actually many engineers came to us and they just couldn't believe that

14:45.620 --> 14:51.140
an AI system would go end-to-end and crack this problem.

14:51.140 --> 14:57.220
But this is another proof of how powerful AI can be in 2020.

14:57.220 --> 15:01.700
And in particular, deep reinforcement learning applied to decision-making problem is truly

15:01.700 --> 15:02.700
disruptive.

15:02.700 --> 15:08.980
So at InstaDip, we are focusing on those type of problems and we believe there is tremendous

15:08.980 --> 15:14.700
value to be unlocked for customers in terms of improving efficiency, accelerating design

15:14.700 --> 15:16.700
cycles and the like.

15:16.700 --> 15:23.500
If you describe the process as one of starting with simple boards and working your way up

15:23.500 --> 15:29.700
to more complex boards, can you elaborate that on that?

15:29.700 --> 15:37.300
If you've got a particular problem with a particular set of circuits that need to be

15:37.300 --> 15:46.380
connected to one another, is the learner that you're trying to create to route this particular

15:46.380 --> 15:47.380
board?

15:47.380 --> 15:51.100
Is it starting with the subset of components and then gradually increasing the complexity

15:51.100 --> 15:56.940
of what it's doing or is it are you talking, are you referring to kind of building up a

15:56.940 --> 16:03.140
knowledge base across multiple, maybe even theoretical, you know, board layouts that

16:03.140 --> 16:08.300
you have created just to train the learner and then you can take this pre-trained learner

16:08.300 --> 16:10.180
and apply it to new boards?

16:10.180 --> 16:15.780
It's not necessarily the final algorithm that we designed, but it's more like the approach

16:15.780 --> 16:21.700
we took, like to crank them problem like this that actually many people have tried and

16:21.700 --> 16:27.620
failed is in and this is a good generic principle in different foster learning.

16:27.620 --> 16:32.900
Start with a small problem that is almost too stupid, right?

16:32.900 --> 16:39.100
But make sure that it is working, make sure that what you expect to see is indeed what

16:39.100 --> 16:40.100
you see.

16:40.100 --> 16:45.540
Devil is in the detail in those systems and deep aerial systems in particular are not

16:45.540 --> 16:51.540
too usually tricky to train because, you know, a problem could come from multiple sources.

16:51.540 --> 16:57.660
It could come from this like straight out bug into your system or it could be that you

16:57.660 --> 17:02.780
have the wrong initialization parameters from an applied math point of view and so you're

17:02.780 --> 17:06.860
doing everything right, the code is right, but the system still won't learn because

17:06.860 --> 17:12.340
the parameters have been badly initialized, so I'm describing more philosophy.

17:12.340 --> 17:19.300
We really start with baby cases and build up our skills, expertise and train progressively

17:19.300 --> 17:21.860
the better agents, realize what work what doesn't.

17:21.860 --> 17:28.580
So there is a lot of like in-depth analysis and details that you need to do to be able

17:28.580 --> 17:34.820
to have systems that actually are ready for the real world and I think that's an interesting

17:34.820 --> 17:39.780
problem like, you know, when we look at the work that the Institute teams do, I think

17:39.780 --> 17:46.580
what is really excited about is how can we take those algorithms that have been tested

17:46.580 --> 17:52.860
mostly on games and very well-defined environments if you want and sort of translate them into

17:52.860 --> 17:57.940
the real world, you know, whether it's routine boards or trains or anything else.

17:57.940 --> 18:02.260
And you know, there are lots of challenges that come with that, but also at the same time,

18:02.260 --> 18:07.860
if you manage to overcome the challenges, it is truly an exciting time and you can see

18:07.860 --> 18:11.060
actually customers come back and give you great feedback.

18:11.060 --> 18:15.260
Customers say, please keep me in the loop for your next release and we've been constantly

18:15.260 --> 18:19.620
improving our product and answering recently releases, for example, supporting Altram,

18:19.620 --> 18:22.700
which is a key standard and so on and so forth.

18:22.700 --> 18:26.940
So I think there is a true excitement in doing things in the real world, even though of course

18:26.940 --> 18:27.940
it's much harder.

18:27.940 --> 18:36.220
So can you maybe compare and contrast the RL applied to games in this particular scenario?

18:36.220 --> 18:42.380
You know, I'm just thinking through some of the differences in the game scenario, you've

18:42.380 --> 18:50.500
often got, you know, other agents or things in the game, in the environment kind of respond,

18:50.500 --> 18:56.300
you know, randomly or probabilistically to the things you do or at least via some,

18:56.300 --> 18:58.700
you know, some complex function.

18:58.700 --> 19:05.740
In this world, you've got your set of components and unless you're doing kind of deep physics

19:05.740 --> 19:10.540
based, you know, simulations of the interactions between the components, you maybe you're not

19:10.540 --> 19:16.700
getting into kind of random responses to things like follow down that thread for me.

19:16.700 --> 19:22.340
So one of the key differences is when it comes to gaming, the reward system is very clear.

19:22.340 --> 19:26.580
You know, there is a score to maximize, there is an opponent to defeat.

19:26.580 --> 19:32.780
So there is full visibility in a sense on what the reward is, which is quite important.

19:32.780 --> 19:34.980
So you're already saving a lot of time.

19:34.980 --> 19:36.940
You know what's the objective.

19:36.940 --> 19:41.380
When it comes to the real world, if I tell you, for example, like, okay, I have this,

19:41.380 --> 19:42.900
you know, and this is what we were talking about.

19:42.900 --> 19:48.340
I have this complex board with, you know, you know, eight layers and a thousand pairs

19:48.340 --> 19:49.340
to connect.

19:49.340 --> 19:53.540
Well, what is the reward function is actually a very good question.

19:53.540 --> 19:57.620
You could probably work for years on what is the best reward function you could come up

19:57.620 --> 19:58.620
with.

19:58.620 --> 20:01.780
So that is one first real challenge.

20:01.780 --> 20:08.060
The second challenge is when you design the environment, making sure you incorporate all

20:08.060 --> 20:16.140
the elements that are important in actually design, like coding and modeling the environment.

20:16.140 --> 20:22.540
If I take the example in logistics that we did and the work we do with railway companies,

20:22.540 --> 20:26.500
that is actually not a trivial thing to do in games.

20:26.500 --> 20:32.100
The environment by construction is already given to you and is very clear, not just the reward,

20:32.100 --> 20:33.740
but the environment itself.

20:33.740 --> 20:39.660
If you're talking about, for example, a complex train network with dozens of thousands

20:39.660 --> 20:46.900
of trains operating every day, you know, there could be problems on one railway.

20:46.900 --> 20:48.620
What's the consequence of that problem?

20:48.620 --> 20:52.580
Just modeling the environment is a challenge in itself.

20:52.580 --> 20:55.820
Once in a good scenario, you've modeled the environment.

20:55.820 --> 20:58.860
The next challenge is speed in games.

20:58.860 --> 21:04.180
By construction, most games are quite fast because there are, for example, designed for

21:04.180 --> 21:08.660
massively online multiplayer games, for example, things of that nature.

21:08.660 --> 21:15.140
So the latencies are, in the order of milliseconds, sometimes, building a real-world environment

21:15.140 --> 21:20.780
that represents properly the problem that you're looking at, and at the same time, ensuring

21:20.780 --> 21:26.260
that it's quick enough so that you deploy deeper out is actually a non-trivial thing.

21:26.260 --> 21:32.220
So as you can see, every step of, you know, this challenge, which is kind of already pre-built

21:32.220 --> 21:37.540
in for games, becomes very tricky in the real world, but also very interesting.

21:37.540 --> 21:43.500
This is also why it's not a surprise that all the deeper out breakthroughs tend to happen

21:43.500 --> 21:48.060
on games, because that is sort of the ideal framework to get results.

21:48.060 --> 21:54.540
And so going back to my earlier question, is what you've done here that you've trained

21:54.540 --> 22:01.620
a model using reinforcement learning that you can then apply to kind of an arbitrary

22:01.620 --> 22:07.060
new board that you're presented with, or is there an element of training that has to

22:07.060 --> 22:13.260
happen when you see a new board, or fine-tuning, or something like that?

22:13.260 --> 22:15.020
It's a bit of both.

22:15.020 --> 22:22.660
So the right analogy is what would qualify a human expert, too, and he comes with a set

22:22.660 --> 22:27.780
of knowledge, a knowledge base, an intuition about how to tackle those problems, but of course

22:27.780 --> 22:32.900
he's going to spend time sort of fine-tuning his approach to the problem at hand.

22:32.900 --> 22:35.780
So our design philosophy is pretty much the same.

22:35.780 --> 22:41.340
There is pre-built-in experience and knowledge that comes when we tackle a new board, but

22:41.340 --> 22:45.500
there is also an amount of fine-tuning, basically essentially.

22:45.500 --> 22:50.540
This system will learn an experiment on every new board and get something out of it.

22:50.540 --> 22:55.220
And when you think about it and you compound those effects, this is how you build a learning

22:55.220 --> 23:00.980
system that can progressively tackle harder and harder problems, and together with compute,

23:00.980 --> 23:07.980
with more customer-served, sort of potentially redefine the standards in the industry.

23:07.980 --> 23:09.740
This is our goal with DPCB.

23:09.740 --> 23:16.980
Today DPCB is in beta format, so it's sort of still learning every day and learning quickly,

23:16.980 --> 23:18.420
but still learning a lot.

23:18.420 --> 23:24.020
We would like to bring it to a point where the tool is so useful that it is widely adopted

23:24.020 --> 23:29.340
by in the industry and helps the industry achieve its goals faster and more efficiently.

23:29.340 --> 23:35.140
If we manage to crack boards at scale in less than 24 hours, this would change the life

23:35.140 --> 23:41.340
of many companies operating in consumer electronics and for the better, because they could be able

23:41.340 --> 23:46.780
to experiment with different designs faster, maybe bring products to market that would

23:46.780 --> 23:54.260
have been impossible otherwise, because the cost of having a design team work for it for

23:54.260 --> 23:57.300
two or three months is just an affordable.

23:57.300 --> 24:01.860
How do you characterize where you are relative to that goal?

24:01.860 --> 24:07.180
How complex are you able to get now and how long does it take to do a board?

24:07.180 --> 24:11.140
I think it's pretty remarkable what we have achieved already, especially that we are

24:11.140 --> 24:16.620
a small startup and do not have access to large compute.

24:16.620 --> 24:21.740
The key thing for us now, if you want to take DPCB to its full potential, is really

24:21.740 --> 24:27.460
unleash tremendous amount of compute and train on much larger boards, so our goal for this

24:27.460 --> 24:34.980
year is really move from free beta, where we are effectively trying to help customers all

24:34.980 --> 24:40.300
over the world and getting feedback in the process, getting them to a point where we can

24:40.300 --> 24:46.740
compete with professional product offerings, and ultimately, if we do everything well,

24:46.740 --> 24:50.380
we design the state of the art in the industry.

24:50.380 --> 24:55.660
So I would say we are well on our way, probably more than 50 percent done, but still a lot

24:55.660 --> 24:56.660
of work.

24:56.660 --> 25:01.220
You are not going to answer my question.

25:01.220 --> 25:03.620
We are in beta, we didn't tell you that.

25:03.620 --> 25:14.260
I am trying to get a sense for how far along this is relative to both how you measure

25:14.260 --> 25:15.260
it.

25:15.260 --> 25:19.260
You talked about the number of components and layers and all that stuff, but also how

25:19.260 --> 25:25.220
far along you are relative to that for solving real world problems, is this something that

25:25.220 --> 25:31.700
is currently useful to someone that wants to route a PCB or not and how do you know

25:31.700 --> 25:37.740
or how would they know if their problem is practical for what you've done so far?

25:37.740 --> 25:43.540
Yes, so the great news is we are actually already solving real PCB boards for real customers

25:43.540 --> 25:45.500
and we're very proud of that.

25:45.500 --> 25:52.740
Those boards are still small, we're currently limiting in beta to 150 pairs and two layers

25:52.740 --> 25:54.860
and we're going to progressively expand that.

25:54.860 --> 26:00.460
So this is where we are at the moment, but the good news is that actually we've already

26:00.460 --> 26:06.020
received very good feedback from customers from literally everywhere at the US Asia and

26:06.020 --> 26:08.900
that the system works, so we're pretty excited about it.

26:08.900 --> 26:18.940
We made a comment that one of the limitations is access to compute or at least you gave

26:18.940 --> 26:25.900
the impression that this is constantly running and constantly improving, talk a little bit

26:25.900 --> 26:31.300
about the relationship with compute and the compute requirement and how you're addressing

26:31.300 --> 26:32.300
that.

26:32.300 --> 26:38.020
Absolutely, so if you look at how the parallel systems work, there is always this concept

26:38.020 --> 26:45.460
of accumulating experience through multiple simulations, gathering this experience to improve

26:45.460 --> 26:49.300
your model through gradient descent and iterating again.

26:49.300 --> 26:55.620
And if you look at the kind of amount, the kinds of amount of compute that you need to really

26:55.620 --> 26:59.580
have, for example, a breakthrough in DPRL, it's quite significant.

26:59.580 --> 27:04.900
If you look at StarCraft, for example, like DeepMind actually did spend millions of

27:04.900 --> 27:10.620
dollars to crack that problem, today, instead, it cannot spend millions of dollars to define

27:10.620 --> 27:11.620
the StarCraft.

27:11.620 --> 27:17.180
So what we're doing actually, we're raising funds and one of the reasons we're raising

27:17.180 --> 27:23.300
a series B, essentially, one of the reasons actually to have enough compute capabilities

27:23.300 --> 27:27.660
to push our systems to redefine the state of the art.

27:27.660 --> 27:32.900
So there is a real opportunity out there, but a compute is a necessary equation when it

27:32.900 --> 27:37.580
comes to DPRL, of course, you can focus on sample efficiency and the like, but you will

27:37.580 --> 27:42.500
not be able to crack those problems with, let's say, a limited amount of GPUs and CPUs

27:42.500 --> 27:43.500
available.

27:43.500 --> 27:48.900
You will need to have essentially a cloud partner to be able to progress this to the next

27:48.900 --> 27:49.900
level.

27:49.900 --> 27:54.260
And we actually don't more than that, we actually design DPCB to be fully on the cloud

27:54.260 --> 27:55.260
from day one.

27:55.260 --> 28:01.180
So every time a customer actually uploads a board, it is solved in real time on the cloud.

28:01.180 --> 28:08.660
And so scalability and scalability of learning is essential if you want to have systems that

28:08.660 --> 28:12.700
build up new state of the art per like results.

28:12.700 --> 28:15.340
And we're pretty excited about that.

28:15.340 --> 28:20.500
And we think this is actually achievable in the near term for instead, meaning something

28:20.500 --> 28:22.100
like a year or less.

28:22.100 --> 28:28.500
We talked a little bit about this kind of notion of transfer learning to use that term

28:28.500 --> 28:36.820
very broadly, that you're training a model and agent and you can, when you're faced with

28:36.820 --> 28:41.580
a new board, you can leverage the experience that you've, you know, you slash this agent

28:41.580 --> 28:46.380
has experienced this models experience with previous boards.

28:46.380 --> 28:51.300
We've also talked about, you know, in the real world, like different designs have different

28:51.300 --> 28:57.700
requirements, maybe, you know, one board has specific requirements around noise or, you

28:57.700 --> 29:02.660
know, the number of layers relative to others, you know, maybe, I guess what I'm, I'm wondering

29:02.660 --> 29:10.100
is if, you know, as you evolve your reward function when you're faced with new scenarios,

29:10.100 --> 29:15.620
does that interfere with transferability or, you know, can you transfer from one reward

29:15.620 --> 29:18.020
function to another?

29:18.020 --> 29:22.980
It really depends of like how far other reward functions are from respective to each other.

29:22.980 --> 29:26.300
But in general, transfer learning is pretty robust.

29:26.300 --> 29:31.140
So, you know, there is a remarkable ability to transfer knowledge from one problem to

29:31.140 --> 29:32.140
another.

29:32.140 --> 29:37.060
And this is something we see across the board, across the board in AI and it's the same

29:37.060 --> 29:38.860
in printed circuit boards.

29:38.860 --> 29:45.340
So if your reward function is not very dissimilar, you will be able to transfer knowledge.

29:45.340 --> 29:51.660
If your board is relatively similar to previously seen and solved boards, transfer learning

29:51.660 --> 29:53.180
will apply as well.

29:53.180 --> 29:59.180
And this is actually a key point, Sam, because this is what makes those systems so interesting.

29:59.180 --> 30:04.460
The fact that they learn, but then when faced with a very complex problem, you know, they

30:04.460 --> 30:10.220
won't have to necessarily burn all that compute to redo everything again.

30:10.220 --> 30:16.660
If you look at how optimization works in many cases today, there is no learning, no

30:16.660 --> 30:18.580
memory of what happened.

30:18.580 --> 30:23.220
And so, you know, if you have, for example, people, you know, doing optimization on boards

30:23.220 --> 30:28.300
or on root problem, or no matter which routing problems these are, well, essentially, you're

30:28.300 --> 30:31.540
burning compute overnight to solve something.

30:31.540 --> 30:36.780
And maybe you kind of come in the next night and do the same thing all over again.

30:36.780 --> 30:39.780
So the transfer learning part is actually critical.

30:39.780 --> 30:45.540
And this is what allows you to keep progressing, you know, as you deploy compute, sort of

30:45.540 --> 30:51.860
this compute is actually more wisely used, if you get two results that can improve what

30:51.860 --> 30:53.380
you're going to do tomorrow.

30:53.380 --> 30:57.900
You mentioned that you had a spotlight presentation at NURBS.

30:57.900 --> 31:02.260
Was that related to this work or is that something separate?

31:02.260 --> 31:09.980
So yeah, we were very surprised this year, actually, to have a spotlight paper at NURBS.

31:09.980 --> 31:15.940
And this was work done with DeepMind, with Nando Freitas and his team.

31:15.940 --> 31:21.940
And interestingly, we looked at, you know, deeper questions, but around compositionality.

31:21.940 --> 31:27.980
How can I, in a bit in the same spirit, but how can I look at certain problems?

31:27.980 --> 31:35.300
And while I saw simple tasks, use those as sort of like, you know, basic tasks to compose,

31:35.300 --> 31:37.340
more complex tasks and so on.

31:37.340 --> 31:43.660
So I think that we're very proud, despite our humble origins, to be able to partner with

31:43.660 --> 31:47.300
the world's best in AI when it comes to research and innovation.

31:47.300 --> 31:52.900
And one of the things, which is unusual about the company, is our ability to, on one side,

31:52.900 --> 31:59.140
innovate in pure research and in particular, deeper, but then productize and experiment

31:59.140 --> 32:02.260
with this innovation in the real world.

32:02.260 --> 32:08.860
And I think that's kind of something pretty exciting, because you get exposed to things

32:08.860 --> 32:13.060
that are both intellectually challenging, but also you have a chance to crack real world

32:13.060 --> 32:14.060
problems.

32:14.060 --> 32:18.820
And so this, you know, it was a big surprise for us, you know, first collaboration with

32:18.820 --> 32:25.460
DeepMind, for us in itself was a milestone, to get that distinction, which roughly is

32:25.460 --> 32:31.940
equivalent to being ranked in the top 2% of all worldwide papers submitted at NURBS.

32:31.940 --> 32:35.660
So that was one of the milestones of our, of our year.

32:35.660 --> 32:40.780
So can you share a little bit more detail about the, the paper and the results?

32:40.780 --> 32:47.220
Yeah, so the paper is called Alphine PI, you can find it on our website, and study.com.

32:47.220 --> 32:51.540
And what we did is we looked at, in this particular case, toy problems.

32:51.540 --> 32:56.900
If you remember, we were speaking about starting with relatively simple things and building

32:56.900 --> 33:01.060
up from there, we looked at, for example, the Hanoi Towers problem.

33:01.060 --> 33:05.380
So Hanoi Towers is classically, you have those disks, you need to move them from one port

33:05.380 --> 33:09.660
to another, and you need to respect a certain order in which you do this.

33:09.660 --> 33:14.460
You know, this is very difficult to solve the Hanoi Towers problem, let's say, a classic

33:14.460 --> 33:17.900
D-barrel album, like the DQN of PPO.

33:17.900 --> 33:25.900
So Alphine PI was able to crack that problem using recursion and also using planning.

33:25.900 --> 33:32.580
So if you look at, for example, the insights from Alphago and Alphazero planning is key.

33:32.580 --> 33:38.860
So the ability to look ahead and sort of build the tree of possibilities and then decide

33:38.860 --> 33:43.860
I'm going to act according to, you know, this path, because I really thought about it

33:43.860 --> 33:50.740
or another way to, to say it is like system one and system two in Daniel Kahneman's classification.

33:50.740 --> 33:53.580
Well, we've actually applied this.

33:53.580 --> 34:00.540
But rather than have just a simple planning algo, like a tree, that is, like a Monte Carlo

34:00.540 --> 34:05.340
tree search that is guiding the neural net, we've done multiple layers of trees.

34:05.340 --> 34:13.380
So as we have compositionality across multiple levels, we actually are calling trees and

34:13.380 --> 34:18.660
doing planning and search across multiple levels, which had never been done before.

34:18.660 --> 34:22.860
So if you're interested, feel free to have a look at the website, the paper is there,

34:22.860 --> 34:27.820
and also the code is available, we try to be very open even though we're a small startup.

34:27.820 --> 34:32.260
So everything is out there available on GitHub and accessible through our website.

34:32.260 --> 34:36.180
Well, Karim, thanks so much for taking some time to catch up.

34:36.180 --> 34:41.460
It's been great chatting with you as always and super excited about what you're up to.

34:41.460 --> 34:43.820
Thanks a lot Sam and talk to you soon.

34:43.820 --> 34:45.580
All right, thank you.

34:45.580 --> 34:51.460
All right everyone, that's our show for today.

34:51.460 --> 34:57.260
For more information on today's show, visit twomolai.com slash shows.

34:57.260 --> 35:24.020
As always, thanks so much for listening and catch you next time.

