Welcome to the Twimal AI Podcast. I'm your host, Sam Charrington.
All right, everyone. I am here in Vancouver at Neurips and I am with Kathy Wu. Kathy is the Gilbert W. Winslow Assistant Professor of Civil and Environmental Engineering at MIT.
Kathy, welcome to the Twimal AI Podcast. Thank you so much, having to be here.
It's great to chat with you. We're going to talk about your upcoming presentation on mixed autonomy traffic and reinforcement learning.
But before we do that, you've recently moved over to the Civil Engineering Department at MIT from more of an EECS background.
Tell us a little bit about your interests and your journey.
Thanks, yeah. So I studied EECS as an undergraduate master's student, PhD, and I also, in my postdoc, and I recently joined Civil like you said.
During undergrad, I actually had the end of undergrad. I started becoming interested in transportation in part, actually because of self-driving cars.
And so I started shifting my work and my thinking and my research, studying still robotics oriented, machine learning oriented perspectives on the problem, but really incorporating a lot of the domain specific challenges and problems.
And my work has gradually become a really nice integration of both sides.
I think coming from RPI, like I think of civil engineering as like broke building bridges and things like that.
And so it's awesome to see the kind of interdisciplinary approaches being brought to bear and thinking about autonomous vehicles at Northwestern.
There was a really strong transportation department or planning department and thinking about how cities need to be constructed, for example, to accommodate autonomous vehicles.
What's the focus of your particular research?
Yeah, transportation is really right for disruption, I would say, with AI.
What I study in particular is how can we understand the potential impact of autonomous vehicles on the rest of the system.
I would say that most of the work done in autonomous vehicles is either studying a single vehicle and how a single vehicle should drive and recognize stop signs and stop signs and navigating in its local environment.
Or it's about how all vehicles are already autonomous and how can we coordinate them so that we can have intersections without stoplights.
So very little is studied and known about that intermediate region regime of partial adoption or different levels of automation.
And so that's what we call mixed autonomy and that's what my talk will be about.
Which I think folks are starting to come to a consensus that that's going to be the rule for quite some time.
That's right. At least a few decades.
I think you even see this in kind of mainstream media, going back five years, I'd ask people when they thought autonomous vehicles would be here and they thought they would dominate the streets in five years.
That's right.
And now folks are much more guarded.
There's a bit more of a sobering perspective on autonomous vehicles now that's right.
So also the autonomous vehicles interacting with human driven vehicles is going to be the role, particularly in cities and on highways, maybe in some controlled environments like airports or something like that.
There may be lanes for AVs, but we're going to have to figure out how these two interact with each other and that's what you're focused on.
Yeah, that's right. And actually what you're pointing out is a really good point. There are a lot of different types of scenarios.
There are airports, there are potential changes to the urban environment where there can be dedicated lanes just for vehicles, just for autonomous vehicles.
There can be maybe enclosed regions like campuses.
And so one of the really nice parts and challenging parts about this particular research area is that there are just so many different varieties of traffic scenarios.
And so we need advancements and machine learning techniques to sort of support the vast variety.
And so your talk is particularly focused on the application of reinforcement learning models to mix autonomy?
That's right. So what we study is how can reinforcement learning methods today help us gain insights into what could our traffic systems look like if we could control a fraction of vehicles, so a fraction of autonomous vehicles.
We want to characterize at what point of the transition do we see benefits for traffic congestion, for travel times, for energy consumption, for safety, and things like that. Do we need 100% or is it 99%? That's really different.
This is very important for potentially city planners, policy makers, and traffic operations, engineers.
If that number is, if we see benefits at 5% versus 10% versus 50%, and so that's what we look at with by studying this in reinforcement learning paradigm.
And you've focused on any particular type of environment, cities, highways. I remember seeing a demo of some research kind of along these lines that looked at like a track like environment.
And if you've got some say 90% of cars that are modeled as human driven and then you introduce a few autonomous vehicles, they actually help with traffic circulation.
And so the assumption there was a track like, does your talk focus on a particular scenario?
Yeah, so we always have to start with the simplest environment that we can. So we do look at the track, we look at a variety of different scenarios as well, and we call them traffic logo blocks.
So we'll take the full city network and we'll sort of decompose them into a simple intersection network, a simple sort of multi lane scenario, or a simple merging scenario, or a simple traffic bottleneck.
And then the idea is that we can study each of these environments where we control a fraction of the vehicles with reinforcement learning, and we can sort of start taking insights in these smaller environments.
And then as we were also working on developing methods that can help us scale these experiments to networks that have multiple of these components and then eventually working our way up to a city. The goal is a city.
We got it, got it. So walk us through your presentation. What's the, how do you set up the scenario?
Yeah, so I think a sort of hidden part of reinforcement learning is how much energy and effort goes into designing the task itself, designing the environment.
So reinforcement learning is often formulated in this Markov decision process framework, and so we really go through and we specify each of those components of a Markov decision process. What is the state, what is the action, what is the reward, and so on and so forth.
What does count makes sense? What horizon makes sense? What does the, what should the network look like? What should, how should we model the individual humans? And so we are, we jointly study the entire setup of the, of the Markov decision process, the MDP, as well as the choice of algorithm.
And so we might consider, for instance, here in this scenario, let's keep, let's keep things simple, let's care, let's, let's optimize for say the average velocity of all vehicles in the system.
In the future, we can study this, trade it off with energy consumption and human stress levels and, and whatnot.
And so what we'll do for a lot of the effort actually goes into designing the state of the MDP. What is, what can the autonomous vehicles actually observe about the system?
And here we do a variety of trade offs. We could give the system, we could give the autonomous vehicles full observation of the environment, but this may be less practical for deployment purposes.
And so we may want to limit the observations to say local information around the vehicles and maybe some aggregate statistics of the system.
And all of this needs to be, needs to be carefully thought through.
Those assumptions are kind of models of an evolving, you know, future real world scenario right there are the automakers are dabbling in like connected car scenarios where the autonomous vehicle will have information about, you know, from the other vehicles on the road.
Yeah.
Is that those some of the things that you're trying to model in?
So it's a really interesting point. One of the potentials for this work is actually to help automotive or the public sector actually understand what parts of the system actually need to be communicated to the autonomous vehicles to achieve some outcome.
So I think the work there is still quite early stage. It's a very exciting direction.
And so you kind of establish the kind of framework of the MDP and what the various levers are and potential outcomes that you're looking to control what next in your talk.
Oh, that's right. So then we, we actually to start with where we leverage block box existing reinforcement learning techniques, we use policy gradient methods, we use TRPO, we use PPO.
And we just sort of see what happens.
And to our surprise, we, the outcome was quite remarkable. What we found is that a very small fraction of vehicles actually can make a significant difference across these different, these different traffic scenarios, these inter, across intersections, merges, bottlenecks, single multi lane roads.
We found that 5 to 10% of vehicles is sufficient to eliminate traffic congestion in our, in our preliminary studies, as well as to increase average velocities by 50 to 100% in the network for all vehicles, not just for the automated vehicles.
And then in addition, we have these sort of emerging behaviors that of say coordinated vehicles through, through an intersection or through, through these very, these sort of interesting behaviors that actually correspond to techniques that traffic engineers have spent a long time hand designing to improve traffic systems.
And they're interesting to see the very similar behavior sort of pop out without, without the same amount of domain knowledge going on.
What are some examples of this?
Yeah, so one example that I really like is called the traffic break. I don't know if you've experienced that in driving where, if you're sometimes on a highway, a highway patrol officer will actually drive sort of this sinusoidal pattern across multiple lanes.
So it's one single vehicle that slows down multiple lanes of vehicles.
And in some of our experiments, that actually popped out. We have an autonomous vehicle sort of stable sort of sort of bringing multiple lanes of traffic to a, to a higher speed.
Everyone, everyone in the system is benefiting. And just by one vehicle being automated out of 40 or so, where that vehicle is slowing everyone down in a way by driving this sinusoidal pattern blocking all the lanes of traffic in such a way that the, it basically induces the human drivers to not, not resulting traffic jams.
So it's, so is it that it's slowing the traffic down and then itself speeding up and kind of pulling the, the human drivers along, or is it more kind of a fundamental, you know, by causing the, maybe it's causing the human drivers to stop bad behavior or something like that.
Interestingly, it's more the latter. So we, in our work, we, we're, there's also an intersection of our work with control theory. And we can actually use tools from control theory to analyze these same systems.
And like dampening the, something like that are basically can basically techniques from control theory can allow us to determine the sort of the stable points of the system or this unstable points of the system.
And what the analysis tells us is that there is an unstable point of the system where traffic flows very well. All vehicles are going at the same speed and it's all nice.
However, it's unstable. So in the absence of some external control, the state would not stay that way. And what we're seeing is that the reinforcement learning outcome is that the autonomous vehicles actually brings the system to that unstable equilibrium.
And so it is a more fundamental property where the, all, the result is that all vehicles are going at the same speed. The autonomous vehicle essentially in hindsight, we can see the, the outcome of this experiment as the autonomous vehicles figure out what is the right speed that all vehicles need to go at.
And then basically maintains that speed for all vehicles.
And this is in a scenario where the autonomous vehicle has kind of global knowledge or independent of global knowledge. Yeah, I actually independent of global knowledge. So only, only local knowledge of just the vehicles next to it, it can actually figure out the right speed for the system.
Yeah, you know, I mentioned this, this demo scenario that I've seen before may have been your research. It sounds very familiar. It reminds me a little bit of some related perhaps results.
I don't recall the specific reference, but it was something along the lines of an aggressive human driver can actually make traffic flow faster. Have you come across this result before?
As a New York City driver in St. Louis, I often feel like I'm doing my civic duty.
I am not familiar with this. It's our studies show the opposite, which is that if more drivers say five to ten percent of drivers were to be less aggressive and in particular to break less, to accelerate less, just actually to respond a bit less, respond more slowly to the vehicle in front of you.
Then traffic could actually improve for everyone. That's sort of the one of the takeaways from from our early experiments.
Meaning I respond more slowly, you know, the car in front of me breaks and I slam on the brakes and that kind of causes a ripple that's right, right, right, right.
This is all work that's done in simulation, presumably how well do you feel you're actually able to model human drivers?
Yeah, that's a really good question. This is a general limitation for reinforcement learning as we look at more real world context.
On the other hand, I actually, among a lot of real world context, transportation actually has very good simulators. There are decades of researchers in the transportation modeling community who have studied human driving models of actually all sorts of decision making and transportation.
Like how does a human decide which mode of transportation to take or what price point they are at for different subway fares or whether or not they're going to buy a car or in the case of driving, when is it that you're going to hit the break and how hard based on the distance of you to the vehicle in front of you?
All of this has been very, very carefully studied. Of course, there's more work to be done. There's always more work to be done. But in terms of the quality of simulation, the simulators that we use, these types of simulators are actually used to design actual transportation systems and actual.
We've talked about the results for the track. Have you gone as far as modeling some of these other scenarios as well, like the intersections and merges?
Yeah, so we have results for all of those.
Can you share some of those?
Yeah, so the outcomes in terms of the improvements are pretty consistent. 5 to 10% of automated vehicles leads to 50 to 100% improvement in average velocity in those scenarios.
And we get different types of emergent behaviors.
So the emergent behavior on a track is this police car slow down type of thing. What is it at an intersection?
Yeah, what's really interesting in intersection is basically coordinating vehicles to not conflict at an intersection.
So you may have seen a video of a system where all vehicles are automated and there's no need for traffic lights at an intersection.
And so a few years back, I was interested in, well, what if one vehicle is not automated, one human vehicle, then do we not have any benefit of autonomous vehicles when anywhere we have intersections, which is most places?
And what we actually found is that with enough autonomous vehicles, actually with very few autonomous vehicles, the autonomous vehicles can actually coordinate so that at an intersection it can sort of hold back human drivers from reaching the intersection while the other direction of the intersection passes through, if that makes sense.
So what we're calling this mixed autonomy platooning, where most of the time platooning is a very desirable autonomous vehicle behavior where vehicles can sort of platoon together, sort of reduce air drag and be a lot more efficient in driving together, and all of the vehicles in that platoon are autonomous.
And what we're finding here is this sort of emergent mixed autonomy platoon where only the lead vehicle is automated, but we get this benefit where you have a platoon of vehicles that pass through an intersection in one direction, and then you have a platoon of vehicles that pass through the intersection in the other direction, and neither platoon needed to stop at the intersection, which leads to pretty dramatic improvements in average velocity.
And it sounds like you're at least assuming, but maybe you've validated that this is, or probably have validated this is linear with the number of autonomous vehicles, meaning, you know, 5% offers some benefit and that benefit continues with the number of autonomous vehicles, and it's not somehow that, you know, more autonomous vehicles leads to a more chaotic situation.
So surprisingly, you would think we have done that study, but what we actually found is that in many of these cases, we would, we basically work with small scenarios with say 20 total vehicles or 40 total vehicles, and then what we do is we swap out one for an automated one.
So we can swap out fewer than that. We'd have to change the scenario to have a smaller fraction, and in almost all the scenarios that we studied, swapping out one vehicle was actually enough to achieve a very good outcome.
So there was no need to actually explore more, like, more fractions.
The assumption is that it doesn't get worse.
That doesn't get worse. That's right. That's right. Do you think at all about the, you know, what it's like for that single human driver surrounded by autonomous vehicles?
Oh, I see. That's single human. Maybe that single human would get the message to buy two autonomous vehicles at that point.
I actually get a lot of questions about the opposite scenario, where if there were so few autonomous vehicles, then, like, different people respond to, like, I wouldn't want to be in that autonomous vehicle that sort of swirving left and right in traffic, or I wouldn't want to be behind that autonomous vehicle.
That I hear from time to time. And I think an interesting way to think about that is if we start to think about these vehicles not as passenger vehicles, but as almost, like, part of the infrastructure.
Control vehicles in the system.
Control vehicles. Like, think of them as traffic lights, but they're, but instead of these binary signals, they're actually moving traffic lights that can set us speed.
And so we're starting to see some, some projects that are thinking about using these ideas and more near term transportation projects as well.
And there's, I did an interview with Diana Howard, who, I believe out of Georgia Tech, who studies kind of the relationships between humans and robotic systems.
And there seems to be a predisposed willingness to defer to, you know, robotic systems.
So maybe, you know, the humans that are behind that, you know, control car would be totally fine with it.
It could be.
It's an autonomous vehicle that says low down, so that's what I'll do.
There are also concerns about sort of taking advantage of autonomous vehicles, especially as currently autonomous vehicles are designed as sort of very, very passive.
And very safe.
And so there have been evidence and videos of human drivers sort of cutting off an autonomous vehicle at an intersection.
And so it may actually take that autonomous vehicle longer to get to a destination.
This is like the kids beating up the malls.
Exactly. Exactly. Except their adults.
Right. Interesting, interesting.
But the results that you've described were small number of autonomous vehicles leads to these advances in kind of traffic flow.
Your primary metric there is kind of throughput of the system or velocity.
Are there other metrics that you've explored?
We have not explored other metrics explicitly, although there are a lot that we're interested in, such as fairness.
Sometimes different lanes have different throughputs and that may not be fair.
So we may be interested in some fairness metrics.
We're also interested in safety metrics and energy consumption and several others.
There are many, many.
The robotic car here, the autonomous vehicle, is modeled as a reinforcement learning agent.
That's right.
Are there any interesting observations that you've made about the training process itself,
and the learning process, before or until we get to the interesting emergent behaviors?
We have seen other emergent behaviors that are less good for the system, such as tailgating.
We've also learned tailgating.
So there are a number of examples where we do learn some behaviors
that we can describe that everyone can relate to that are not quite what we're looking for.
The presentation is the main result that you're presenting,
these kind of emergent behaviors that you've described,
or are you digging into more details about how you've created the agents,
or what other things should we make sure to touch on in the conversation?
Yeah, so the highlight of the talk is really the empirical results that we found,
as well as the experimental process to get to it,
as part of this because of the vast variety of traffic scenarios,
including the ones that we've discussed today.
We built an open source framework called Flow, which allows us, as well as any other researchers,
to design their own traffic scenario, their own traffic logo block,
their own traffic MDP, and do their own experiments.
What is the kind of Flow user experience?
Is it a visual graphic type of thing, or is it more your setting parameters,
and then running a command line?
Yeah, it's more the latter.
It's more for developers and for researchers at this point.
So you can specify a network, you can specify the different types of vehicles,
human or autonomous, or different types of human drivers,
and you can specify the different fractions of these vehicles,
you can specify the number of lanes in the network, different parts of the network,
and so on and so forth.
And it's also an actively developed tool right now.
You mentioned that your research relies on these established traffic simulation engines,
and does this flow also depend on those?
Yes, so Flow integrates with a few traffic simulators,
one of which is called Sumo, the simulation of urban mobility,
and it's also an open source traffic micro simulation,
and then we also integrate with another commercial simulator called AIMSUN.
AIMSUN, okay.
These are all, so traffic micro simulators are the specific subset of simulators
that are really about simulating vehicle dynamics,
rather than say vehicle routing or land use.
Okay.
And so anyone can download Flow and download Sumo, for example,
and kind of replicate some of the results that you presented?
That's right, everything's open source.
A strong believer in open source.
Awesome, and so do you, can you use these inside of notebooks,
or what's the typical kind of user experience?
I think you could use it inside networks.
We typically don't, because we're typically issuing jobs to some cluster
for the large-scale reinforcement learning runs.
Got it.
But I think you probably can. How long do you run typically?
Take.
They range, actually, in the scale, in terms of reinforcement learning experiments,
we're very, very low.
Low, like low samples needed.
So our experiments actually can run on a standard commodity AWS instance
in between like one and nine hours.
With GPU?
We don't need GPU.
We don't need GPU, okay.
Yeah, so we are not, we basically focus on the state input directly
and we are not doing too much vision.
Any kind of parting thoughts or other things that you want to mention
from your presentation?
Yeah, so I think we talk a lot about automation and AI
and how it's increasing in the world.
I think another dimension of this that I think is really important
is how much connectivity is actually increasing in the world.
We are, we're all more and more, the people and the systems
that we interact with are more and more connected through social media,
through, say, through urban networks, through global supply chains,
the world is sort of more and more connected.
And so a lot of what motivates this research is the realization
that it's not enough to study a single autonomous vehicle
in its own local environment.
We have to study the environment that it affects,
which is, say, the whole city.
And it's, I think because of the increased connectivity in the world,
it's becoming harder and harder to study AI in its own isolated environment
and the broadened scope of the impacts of AI means
that we actually need new techniques that can handle
much larger, much more complex systems.
And that's a lot of what's motivating the next phase of my research.
And so what are some of the specific directions that you're heading in
in the next phase?
Is it kind of taking these LEGO blocks and connecting them to one another?
It is trying to do that.
Current, with current methods, we can't just immediately do that,
so we do need to look at different techniques to enable this.
I'm very excited about directions in representation learning
for large-scale networked dynamical systems,
very interested in how can curriculum learning play a role in all this?
How can we increase the efficiency of our simulators
through the use of machine learning?
Can we compress simulators?
There are a lot of interesting directions to sort of allow us to work
with more and more complex environments.
Yeah, so what you've done as far as you've used reinforcement learning
to identify some emergent behaviors that have utility in mixed autonomy scenarios,
do you see this as now that we've identified these behaviors
we can kind of program the cars some kind of way, independent of how we do that
to exhibit these behaviors?
Or do you see the cars more, do we need to allow the cars to learn things
while they're kind of in real-time use?
How do you see this playing out?
I guess maybe is it a planning scenario that you're really focused on
or you see the impact or is it more about the vehicles themselves?
I think it's both.
That's a really good question and a really good point.
I think it's both.
There are, with real-world problems, there are a number of reasons
that either direction could not work out.
But I think both are very possible.
We could, in the near term, actually see instrumented vehicles
reducing traffic congestion and increasing speeds.
I can see that the technology is there.
We may need to do a few more experiments.
We may need to validate, but it's pretty close to near-term deployable
whether there's a city that wants to do it or whatnot.
That's a different story.
From the planning perspective, I think that that is a very large
potential direction.
Can we help a city sort of map out its 20-year adoption plan
for autonomous vehicles?
It's incentivization plan.
When and where should the system incentivize the adoption
to get to a point where we can see these benefits?
How should the regulation and rules of the game be laid out?
I think from the planning side, I'm very interested in those questions.
I think a lot of the computational and machine learning and large-scale
techniques are very, very critical in the planning context.
Awesome, awesome.
Well, Kathy, thanks so much for taking some time to share with us
what you're up to.
Thank you for having me.
Absolutely.
All right, everyone.
That's our show for today.
For more information on today's show, visit twomolai.com slash shows.
As always, thanks so much for listening and catch you next time.
3
