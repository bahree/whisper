1
00:00:00,000 --> 00:00:16,460
All right, everyone. I am here with Noam Sloanam. Noam is principal investigator of project

2
00:00:16,460 --> 00:00:21,440
debater at IBM Research. Noam, welcome to the Twomal AI podcast.

3
00:00:21,440 --> 00:00:24,340
Hello, Sam. Thank you for having me.

4
00:00:24,340 --> 00:00:43,340
Hey, I'm really looking forward to digging into our conversation. We're going to focus, of course, on project debater and what's new, everything about that project, but before we dive in deep there, I'd love to have you share a little bit about your background and how you came to work in AI.

5
00:00:43,340 --> 00:00:56,340
So, I did my PhD at the Hibby University in Jerusalem at the machine learning lab. This was the late 90s, more or less. I graduated in 2002.

6
00:00:56,340 --> 00:01:12,340
And I worked mainly on information theoretic methods for cluster analysis and related algorithms and the main data that I was considering back then was textual data.

7
00:01:12,340 --> 00:01:31,340
And in 2002, I moved to Princeton, New Jersey to do my postdoc. And in 2007, I joined IBM Research. And I worked on various projects. And in 2011, I suggested to work on project debater.

8
00:01:31,340 --> 00:01:35,340
And this is what I'm doing in the last 10 years or so.

9
00:01:35,340 --> 00:01:42,340
Nice. Nice. And was debater and existing project at that time? How far along was it?

10
00:01:42,340 --> 00:01:52,340
So it has an interesting history because, as I assume, you know, we have this tradition in IBM Research of grand challenges in artificial intelligence.

11
00:01:52,340 --> 00:02:07,340
So back in the 90s, IBM introduced the blue that was able to defeat the Garry Kasparov in chess. And in 2011, IBM introduced Watson that defeated the all-time winners of the TV trivia game, jeopardy.

12
00:02:07,340 --> 00:02:20,340
And just a few days after this event, an email was sent to all the thousands of researchers of IBM across the globe asking us what should be the next grand challenge for IBM Research.

13
00:02:20,340 --> 00:02:26,340
And I was intrigued by that. So I offered my office mate at the time to brainstorm together.

14
00:02:26,340 --> 00:02:37,340
And this is what we did. We sat in the office in Tel Aviv and we raised many different ideas that I cannot share at this point.

15
00:02:37,340 --> 00:02:53,340
But these were mainly strange thoughts, but at some point towards the end of the hour, I don't recall the exact trigger I suggested this notion of developing a machine that will be able to debate humans.

16
00:02:53,340 --> 00:03:02,340
And that this is how we would demonstrate the technology through a full-life debate between this envisioned system and an expert human debater.

17
00:03:02,340 --> 00:03:15,340
And this sounded better than all the other thoughts that we had at that time. So we decided to submit that. And we submitted the proposal in February 2011.

18
00:03:15,340 --> 00:03:27,340
So a little more than 10 years now. And it was a single slide. So basically the guidance, well, you know, submit a single slide. Don't swamp us with, you know, with all the glory details.

19
00:03:27,340 --> 00:03:37,340
And this is what we did. And this started a fairly long and thorough review process because obviously there were many, many submissions.

20
00:03:37,340 --> 00:03:52,340
And this took about a year and eventually in February 2012, this proposal to my surprise was selected as the next grand challenge for IBM Research.

21
00:03:52,340 --> 00:04:09,340
And we started to work just a few months later with a small team that that gradually expanded. And we worked for nearly seven years only on that just on this mission of developing a machine that will be able to debate humans.

22
00:04:09,340 --> 00:04:23,340
And eventually we demonstrated the system for the first time in about two years ago in February 2019. So this is in a nutshell. This is the history of how this project came to life.

23
00:04:23,340 --> 00:04:40,340
And you describe it as kind of working on this one project over the past, you know, seven years or so. But the project is resulted in a bunch of different research papers and individual research kind of components.

24
00:04:40,340 --> 00:04:47,340
How do you think of the evolution of the project since its inception?

25
00:04:47,340 --> 00:05:00,340
So this is an interesting aspect, I think, of this project because when we started, we, we had this, we did what computer scientists often do.

26
00:05:00,340 --> 00:05:18,340
This big problem and we just decided to break it down into more tangible and more focused and more modular problems. And apparently to participate in a live debate, you need a lot of capabilities.

27
00:05:18,340 --> 00:05:39,340
And this resulted with many, I would say some project that we needed to run them in synchrony over the years. And the outcome of that was actually a sequence of papers that we started to publish in 2014.

28
00:05:39,340 --> 00:05:56,340
We made, we published, I believe, more than 50 papers in the, you know, the immediate suspect conferences like ACL and EMLP and associated workshops, of course, triple AI as well.

29
00:05:56,340 --> 00:06:12,340
But only recently, we really published a paper that describes the system in its entirety. It took us a while and we actually started to work on that only after the demonstration of the system in San Francisco two years ago.

30
00:06:12,340 --> 00:06:32,340
So I would say I would divide that into two. We have these individual papers, typically highlighting a particular aspect of the system, which, which I think are interesting by themselves. Some of them actually touch on problems that were not clearly defined before we even published the paper.

31
00:06:32,340 --> 00:06:46,340
And then we have this more recent paper that is very concise and describes the system in its entirety for the first time. And this was published in nature two months ago.

32
00:06:46,340 --> 00:07:02,340
We'll dig into those before we do. I'm curious, you know, to what degree do you think about what you're building with the beta and the context of the, the touring tests and how does the evolution of the system reflect that?

33
00:07:02,340 --> 00:07:22,340
This is an excellent point because I think we deliberately stay. I mean, we explicitly stated that we do not want to pass the touring test in this project because I think the test by itself deserves a separate discussion.

34
00:07:22,340 --> 00:07:40,340
And I think there are some criticism about whether or not indeed with AI researchers should focus on this on this test. But from our perspective, it was fairly clear that we, this is not what we are trying to do on the contrary.

35
00:07:40,340 --> 00:07:58,340
Actually, it was important to us that the system will present itself as an automatic system. And so it will not be mistaken at any point that that this is a human being participating in the debate.

36
00:07:58,340 --> 00:08:14,340
And regardless, I think it is at least in terms of the technical approach that we took, the debating style of the system that we developed versus the debating style of a human are pretty distinct.

37
00:08:14,340 --> 00:08:26,340
So even if we were trying to pretend as humans, I think it would have been pretty hard in the world of a competitive debate.

38
00:08:26,340 --> 00:08:32,340
Can you elaborate on that last point in terms of the debating style?

39
00:08:32,340 --> 00:08:44,340
Perhaps I should explain a little bit what do we mean by a competitive debate and what were the rules of the competition.

40
00:08:44,340 --> 00:08:56,340
So first of all, the debate starts with a motion that defines what we are debating. And in the San Francisco event, it was whether or not the government should subsidize preschool.

41
00:08:56,340 --> 00:09:09,340
And there are many considerations around how this motion is being selected. But, you know, to be concise, I will just mention that obviously it was never included in the training data of the system nor in the development data of the system.

42
00:09:09,340 --> 00:09:19,340
So this was taken from a kind of a hidden list of topics. And we are on site government. So we project debaters support the motion.

43
00:09:19,340 --> 00:09:27,340
And we were debating one of the legendary debaters in the history of university debate competitions, Mr. Harish Natharajam.

44
00:09:27,340 --> 00:09:33,340
I would say he can be seen as, you know, as the Gary Kasparov of the world of debate.

45
00:09:33,340 --> 00:09:46,340
So he was on the on the opposition side. And we have four minutes opening speeches for each side, four minutes, rebuttal speeches for each side and two minutes closing statements.

46
00:09:46,340 --> 00:09:57,340
So all in all, including the poses, this is close to 25 minutes of a discussion between between man and machine in front of a live audience, mainly journalists from all over the world.

47
00:09:57,340 --> 00:10:08,340
It was also broadcast live in the internet. And the system has two major sources of information in order to perform its goal.

48
00:10:08,340 --> 00:10:23,340
One of them is a massive collection of newspaper articles, the Lexis nexus corpus. So this is around 400 million articles at the order close to 10 billion sentences.

49
00:10:23,340 --> 00:10:37,340
And when the debate starts, the system is is try using different capabilities. We can talk about these capabilities to to pinpoint short pieces of text that satisfy three criteria.

50
00:10:37,340 --> 00:10:46,340
They should be relevant to the topic. They should be argumentative in nature. They should argue something about the topic, not just be relevant.

51
00:10:46,340 --> 00:11:08,340
And they should support our side of the debate. And this is a formidable challenge that we can talk about. But once these short pieces are found, the system is using other capabilities, mainly cluster analysis and some rule based procedures in order to glue them together into a compelling narrative.

52
00:11:08,340 --> 00:11:20,340
So this is one major source of information of the system. The other very important source of information of the system is a unique collection, kind of a knowledge graph.

53
00:11:20,340 --> 00:11:38,340
Well, we have thousands of of nodes that represent, I would say, more principled argumentative elements. And these are written by hand by humans, by experts. We generated these data over the years.

54
00:11:38,340 --> 00:11:49,340
And when the debate starts, the system is navigating in this knowledge graph, so to speak, searching for the most relevant principle arguments, trying to use them in the right timing.

55
00:11:49,340 --> 00:12:04,340
The current principle arguments in the knowledge graph. Is there a subset of the graph that just so happens to be specific to this particular argument, or is it more abstract about argumentation in general.

56
00:12:04,340 --> 00:12:22,340
So these are more these arguments reflect principles that people can use during the debate. So let me give you a concrete example. Let's say that we are debating whether or not to ban the sale of alcohol or whether or not to ban organ trade.

57
00:12:22,340 --> 00:12:33,340
In both cases, the opposition may say, well, if you ban that you are at the risk of the emergence of a black market, which by itself has a lot of negative implications.

58
00:12:33,340 --> 00:12:41,340
And so the black market argument is a principled one. You can use precisely the same argument in many different debates.

59
00:12:41,340 --> 00:12:56,340
One may kind of assume, well, this is not that difficult, right? So it's kind of a keyword matching thing. If the debate is about banning something, then we shouldn't anticipate the black market argument to a merge.

60
00:12:56,340 --> 00:13:12,340
Of course, this is not the case because think of a debate about I like the example of banning internet cookies. We're not going to see people standing in street corners selling internet cookies or something like that.

61
00:13:12,340 --> 00:13:33,340
The system really needs to develop. I would say a more subtle understanding of the nuances of the human language in order to perform well in this task. Then there is rebuttal that that we can talk later on, but but now coming back to your point, what are the differences in style between this machine and a human.

62
00:13:33,340 --> 00:13:51,340
So first of all, the debate has a very good memory, right? It recalls these 400 million articles. And when it's the pinpoint this specific piece of evidence, it can quote it precisely.

63
00:13:51,340 --> 00:14:08,340
I can say, you know, this research published in this year with these numbers and so on and so forth. It will not get confused in the middle. It will not forget what it was planning to say. So it is kind of strong in this aspect.

64
00:14:08,340 --> 00:14:23,340
You can also plan ahead in terms of the available time and make sure that it will keep up with time. So so it has all these properties that are that I would say are important for the debate.

65
00:14:23,340 --> 00:14:43,340
And on the other hand, it is much weaker on other aspects of the debate. So first of all, in terms of logic, the logic that we can integrate into the speeches that the system is conveying is fairly limited.

66
00:14:43,340 --> 00:14:55,340
So we can identify the general themes that emerge from all the arguments and arrange the arguments accordingly and try to have a compelling flow or something of that sort.

67
00:14:55,340 --> 00:15:04,340
But often you see human debaters, they take a point and they can develop the logic of this point throughout the entire speech.

68
00:15:04,340 --> 00:15:14,340
And to some extent, they do that because they don't have this this body of knowledge that we can rely upon. They have their memory and they have their expertise.

69
00:15:14,340 --> 00:15:22,340
So so I think this is one important distinction.

70
00:15:22,340 --> 00:15:40,340
The place where it starts to be a little bit more similar is when we are starting to use the principal arguments. Actually, in fact, we realize that we need this part of the system after observing how human debaters debate.

71
00:15:40,340 --> 00:16:00,340
Because often this is what they do. They have this vast experience of many previous debates. And perhaps I'm simplifying it a little bit, but to my understanding, an important aspect of their skill is really to have this arsenal of principal arguments that they have in their memory.

72
00:16:00,340 --> 00:16:15,340
And then they can quickly understand which arguments are relevant to the debate. And then they build a logic around it and start to look for fallacies in the in the arguments presented by the opposite, by the opponent.

73
00:16:15,340 --> 00:16:25,340
So this is these are very different styles. And when you listen to the debate, you immediately recognize that this is one style and this is the other style.

74
00:16:25,340 --> 00:16:44,340
But regardless, as I said, it was important to us. So even we were kind of integrating a little pieces of humor in the debate. And it was also the subtext was always project debater, conveying the message, I'm a machine, I'm not, I'm not human.

75
00:16:44,340 --> 00:16:56,340
The project debater perspective, it's fully hands off once a debate starts for such from input output. It's not trying to interpret spoken speech.

76
00:16:56,340 --> 00:17:06,340
So so so so it so first of all, the system is fully automatic and it's, you know, basically on its own, once the debate starts.

77
00:17:06,340 --> 00:17:17,340
There's no human intervention that's it. So it's exactly as you mentioned, there is this short input phrase. We should subsidize preschool. That's it.

78
00:17:17,340 --> 00:17:27,340
So so I think there is, you know, it is important to notice the gap between the conciseness of the input.

79
00:17:27,340 --> 00:17:44,340
And I would say the length and the depth of the output that the system should should present. So this is one aspect. Now, when the human debate is is presenting when Harish is presenting his speeches, the system is listening.

80
00:17:44,340 --> 00:17:59,340
In order to to respond accordingly. And this really starts by understanding the words articulated by the human debate. And for that, we use the Watson speech recognition capabilities out of the box.

81
00:17:59,340 --> 00:18:17,340
There was a little thing about the British accent of of Harish that that we needed to handle in kind of just in the last minute more, more or less, when we realized that this is a problem. But again, we had capabilities from Watson also to adjust the system to his accent.

82
00:18:17,340 --> 00:18:33,340
So the performance in terms of speech recognition were pretty high. But then you need to go beyond the words. You need really to understand the gist of the speech, the claims being stated by by Harish.

83
00:18:33,340 --> 00:18:54,340
And to that, we used a few techniques that usually rely on the same principle of trying to anticipate in advance, what kind of arguments, the opposition might use and then listen to determine whether indeed the opposition were making this argument and then respond accordingly.

84
00:18:54,340 --> 00:19:15,340
Yeah, when I think about the elements you've described so far, this is overly simplistic, but it sounds like there's a set of kind of general capabilities, an example of that might be when you describe the first part of the system is sounded a lot like extractive summarization.

85
00:19:15,340 --> 00:19:35,340
In some ways, and then you've got this knowledge graph that is maybe more domain specific or specific to debater. And one way is that one way that you think about the components of the system, kind of general versus specific or how blurry those lines are.

86
00:19:35,340 --> 00:19:48,340
Not blurry to some extent, but I think it is a fair way to try and grasp what the system is doing. So first of all, it is extractive. It is not abstractive.

87
00:19:48,340 --> 00:20:12,340
It will not start to say things that, you know, by itself, it will take pieces of texts on various places. And the rationale behind that was that if you're going to present this system in a live event in front of the entire world, you need some, you need to be careful about what the system might say.

88
00:20:12,340 --> 00:20:30,340
We know an abstractive summarization technique or a generative network or something like that, it can say anything. So we wanted to avoid this, I would say, southern situations.

89
00:20:30,340 --> 00:20:52,340
By the way, even in extractive approach, you may reach points that are kind of risky. The issue is that sometimes in a very credible resource, they will quote a ridiculous claim by someone else just to counter this claim.

90
00:20:52,340 --> 00:21:13,340
And the system needs somehow to figure this out because these claims could be outrageous. So you, if you are completely naive and the system is looking for these short pieces of text that I mentioned earlier, it may find a sentence, the sentence is relevant argumentative, then it can cut a short piece out of this sentence that represents the claim.

91
00:21:13,340 --> 00:21:32,340
And if it is not careful enough, the claim could be ridiculous. And we needed to add some safety mechanisms in order to at least simple safety mechanisms in order to avoid the situation like that, but going back to your point, the system is extractive in nature.

92
00:21:32,340 --> 00:21:49,340
But when we compare that to extractive summarization, let's think about the summarization challenge that we have. Essentially, we get this query and we need to summarize all the arguments out of 10 billion sentences.

93
00:21:49,340 --> 00:22:03,340
This is not summarizing one document or 50 documents. This is kind of summarizing the entire corpus. And another distinction is that the system has a stance.

94
00:22:03,340 --> 00:22:17,340
So we need to automatically identify each argument if it supports our opinion or not, which usually is not considered in I would say in standard summarization algorithms.

95
00:22:17,340 --> 00:22:42,340
And is the system during its training phase is it attempting to parse out the argument of a or the stance of a given piece of input data or is it more just ingesting the text and then later during a debate identifying arguments that may support its points.

96
00:22:42,340 --> 00:22:53,340
So the system is preparing things in advance. So the entire material it is going to use during the debate, the system is preparing that in advance.

97
00:22:53,340 --> 00:23:11,340
And it actually prepares more material than it is going then what will be used eventually in the debate and then during the debate, the system can decide in a dynamic manner to say, OK, so the opening speech is kind of written in advance because we are opening the debate and we haven't heard anything yet.

98
00:23:11,340 --> 00:23:26,340
But once the human debate is starting to provide her or his input, then the system can dynamically decide, you know, whether to skip some arguments and give more room for a battle or things like that.

99
00:23:26,340 --> 00:23:41,340
And just to elaborate on this point quickly, can you discuss the relationship between the systems preparation and training.

100
00:23:41,340 --> 00:24:00,340
So this was I think another interesting aspect of this project because we had all these different components. So just as an example, we had a component and these are actually available today freely available for research purposes.

101
00:24:00,340 --> 00:24:22,340
We can touch on that later on, but just to give you two examples, one component was really a component that the focus of that was to detect pieces of evidence in the massive corbos and and this component has its own training data development data and test data.

102
00:24:22,340 --> 00:24:34,340
So training data for this component could be in the form of eventually became very very large. We invested a lot in in how to annotate data in an efficient manner by the crowd.

103
00:24:34,340 --> 00:24:54,340
But eventually we annotated I would say around 200,000 sentences in Lexis nexus corbos as either containing evidence, which is relevant to a particular debate topic. So this was done with respect to, I don't know, 100 200 different debate topics.

104
00:24:54,340 --> 00:25:08,340
And all the sentence seems to be relevant, but it is not representing evidence that you can use during the debate. And the distinctions could be quite subtle.

105
00:25:08,340 --> 00:25:20,340
So imagine that one example that we give you have a debate about whether or not Valentine's Day, we should keep it or not.

106
00:25:20,340 --> 00:25:34,340
And then the system is fighting these two sentences. One of them is saying, well, you know, there was a survey running in Canada and people said that basically this is a waste of time and money and we should forget about it. That's fine. You can say that.

107
00:25:34,340 --> 00:25:53,340
Then there is another sentence saying, well, we had a survey in the US and people said that if they're going to break up with the partner, they will do it just before Valentine's Day. So they will spell the money on buying a present for Valentine's Day.

108
00:25:53,340 --> 00:26:04,340
So this is kind of perhaps a useful piece of information to know, but it is you're not going to use that during the debate now both sentences are very similar in structure.

109
00:26:04,340 --> 00:26:14,340
They mentioned the word survey, they mentioned numbers, they mentioned statistics. So making a distinction between these two is fairly challenging.

110
00:26:14,340 --> 00:26:35,340
And we needed to reach very high accuracy in order to perform well. So this is one module. Then there is another module saying, can we automatically identify whether this piece of evidence support our position or support the position of.

111
00:26:35,340 --> 00:26:57,340
So we refer to that as pro-con analysis and this is also a service which today we make available freely available for research purposes. And again, this has its own training data and development data and test data because the target function is different.

112
00:26:57,340 --> 00:27:13,340
And now these need to be somehow synchronized because this was a little bit challenging because at some point we have this capability of evidence detection and it can find pieces of evidence of a particular characteristic.

113
00:27:13,340 --> 00:27:22,340
And then the team walking on pro-con analysis are considering these data and they make progress and three months later they have very good results.

114
00:27:22,340 --> 00:27:30,340
But during these three months the other team also made progress. And now the evidence that they generally is actually quite different.

115
00:27:30,340 --> 00:27:36,340
So this was a little bit tricky to keep everybody in synchrony.

116
00:27:36,340 --> 00:27:44,340
It sounds a bit like a ML ops type of a problem where you've got different versions of components floating around and you need to.

117
00:27:44,340 --> 00:27:59,340
Exactly. And sometimes the component was in this kind of project we were very focused on the goal on what we need to accomplish.

118
00:27:59,340 --> 00:28:14,340
And this was in my opinion this was very useful because it was I sometimes think of that as a lighthouse in the dark. You are on this ship in the ocean and the waves are coming and this is night but you have this light house far away.

119
00:28:14,340 --> 00:28:20,340
And you know exactly where you need to go and this is very helpful in terms of taking decisions.

120
00:28:20,340 --> 00:28:33,340
And for example at some point we realized that we should develop the capability of entity linking or more specifically wikification.

121
00:28:33,340 --> 00:28:41,340
That is to identify in each sentence what are the wikipedia concepts being mentioned in this sentence.

122
00:28:41,340 --> 00:28:53,340
And the reason was that we realized that this could be very useful for example if we are debating whether autonomous cars will bring more harm than good.

123
00:28:53,340 --> 00:28:58,340
There are many ways to refer to the concept of autonomous cars.

124
00:28:58,340 --> 00:29:07,340
You can say autonomous cars and you can say driverless automobiles and there are like dozens of ways by which you refer to the same concept.

125
00:29:07,340 --> 00:29:16,340
So if you have this utility that can automatically identify that this wikipedia concept was mentioned in the sentence.

126
00:29:16,340 --> 00:29:24,340
You are basically vastly expanding the amount of data that you are going to consider for the debate.

127
00:29:24,340 --> 00:29:38,340
But the challenge was how do you wikify 10 billion sentences? It's not about wikify and you know you want to do that several times because perhaps you are improving the algorithm and so on.

128
00:29:38,340 --> 00:29:46,340
And the algorithms that were out there were simply too heavy for us to one.

129
00:29:46,340 --> 00:30:01,340
So we developed to make sure I'm on the same page when you say wikification are you talking about cross linking entities within the phrases in your corpus to actual wikipedia pages or kind of linking.

130
00:30:01,340 --> 00:30:14,340
Okay, the former just saying you know in this sentence these are the wikipedia pay concept that is we were just you can think of that as sending pointers from the sentence to the relevant wikipedia pages.

131
00:30:14,340 --> 00:30:29,340
But we needed an algorithm that you know even with heavy computational resources if we were using algorithms out there it took us like two months to complete just a single run.

132
00:30:29,340 --> 00:30:52,340
And this was too much so so we needed actually now to develop this capability and this means that we needed to develop our own evaluation data and this mean meant that actually we needed to go into the annotation process of you know how do you train crowd workers to identify wikipedia concepts in a sentence.

133
00:30:52,340 --> 00:31:10,340
This is a story by itself, but we generated very nice benchmark data sets for you know for training and for development and for and for testing and and converge to a very simple and highly efficient algorithm that was performing very well.

134
00:31:10,340 --> 00:31:23,340
And and obviously we share these results in in in a couple of papers and also this is an example of I would say I'm more basic NLP capability which is available today.

135
00:31:23,340 --> 00:31:47,340
So if you want to week so if you are a researcher with interesting in this field of entity linking and you have your own data and you would like to try it you can just go ahead and use this service which which is available and and it runs extremely fast so we were able to weakify 10 billion sentences in like less than 48 hours.

136
00:31:47,340 --> 00:32:13,340
And and actually the performance of this algorithm in spite of its simplicity are very good and and this was interesting so in some cases we needed actually to resort to solving relatively basic NLP problems and simply because we needed the capability and nothing of that satisfy the requirements was was available.

137
00:32:13,340 --> 00:32:37,340
You talked a little bit about performance in kind of relative performance of this this vocabication module I'm curious how you think about performance and evaluation and metrics and baselines across the various components and the broader collective devater system.

138
00:32:37,340 --> 00:33:03,340
Yeah so so when we evaluated in individual components we use the standard paradigm of of supervised learning with this was kind of follow the protocol you have a training data development data you have test data do devaluations see that you improve over time we needed to reach the extremely high precision so the system as a whole was very much precision oriented.

139
00:33:03,340 --> 00:33:21,340
But the evaluation we didn't need to invent anything new we needed just to in terms of evaluation we need to be very rigorous in terms of benchmark data sets development and things like that but when you talk about evaluating the system as a whole.

140
00:33:21,340 --> 00:33:45,340
Yeah this is this is a different story and this is actually one of the main points that we made in this recent paper that describes the entire system because it is completely unclear how to first of all even if you even when you consider a single debate it's not that clear how to score the system.

141
00:33:45,340 --> 00:34:14,340
It debate is can last for you know in our format can last for 25 minutes and and also you know the way it works in in a live event is that people vote before the debate starts on their position and then they vote again after the debate ends and then the winning side is declared as a side who was able to pull more votes to to his position.

142
00:34:14,340 --> 00:34:29,340
But this is a very complicated production because you know you need audience and you need a human debater and the audience need to be unbiased and and sometimes the vote before the debate start is is is extremely biased so.

143
00:34:29,340 --> 00:34:41,340
So this was really challenging and eventually what and and also another requirement when you want to publish a paper is to compare your system to other systems right.

144
00:34:41,340 --> 00:35:02,340
But the point was there was no other system capable of doing a debate so so how do you kind of get a point of reference even if you succeed to score the system so what we did in in this recent paper was to approach that in two stages first of all we said look to participate in a debate.

145
00:35:02,340 --> 00:35:15,340
You must have an opening speech okay this is our if you cannot articulate a good opening speech don't go to debate right and an opening speech is something that other systems can do.

146
00:35:15,340 --> 00:35:28,340
So you can take a summarization technique and use some queries in order to bring relevant documents and and the summarization technique will summarize and generate an opening speech and you can use.

147
00:35:28,340 --> 00:35:57,340
So we really wanted to compare to GPT three unfortunately we didn't get access so we resorted to compare to GPT two okay and and this and again GPT two fine tuned for this particular task fine tuned to articulate arguments that are relevant to the topic or to articulate a whole speech and so on so this was a very challenging comparison and and we didn't know what would be the outcome.

148
00:35:57,340 --> 00:36:25,340
Because when we started a project GP we started in 2012 okay so deep learning in NLP was not really there okay GPT two I think it came out in 2019 or something like that or 2020 and and and we started this comparison in 2020 with this you know major and and very prominent technique that just came out and we will

149
00:36:25,340 --> 00:36:43,340
see what will happen and and we also fine tuned it over thousands tens of thousands of arguments I mean to give it a best shot and then you send the speeches to to the cloud and ask them to give it a score between you know one to five you can ask them you know how well.

150
00:36:43,340 --> 00:36:55,340
The speaker is performing in in this opening speech and you can say you know the speaker is performing well and you can answer between one to five strongly disagree or strongly agree.

151
00:36:55,340 --> 00:37:09,340
And then you average over 80 topics because a live debate is one debate we wanted the results you know to be statistically meaningful and and also we compared that to expert human debaters which was an upper bound.

152
00:37:09,340 --> 00:37:36,340
On on the same topics and the scores were pretty interesting so so debate of system came very close to expert human debaters I think the other score of the weather was around four and human debaters were on 4.2 and and and GPT two I think made it to 3.4 or something like that and it was the best amongst several other techniques that that we tried for the opening speech.

153
00:37:36,340 --> 00:38:01,340
Then we did another thing you know to evaluate the the the whole debate and this was by sending a human evaluators three speeches the opening speech by our system a response speech by a human and then the response speech by our system and again asking them to give us a score between one to five and again we saw that the scores are pretty good at the order of four to the question of you know whether.

154
00:38:01,340 --> 00:38:22,340
The system is performing well in the debate so so we were very I would say this was kind of a tense point because we really didn't know it was past the demonstration in San Francisco you know we started to do this systematic evaluation really didn't know what we're going to get in the results but the results were pretty good.

155
00:38:22,340 --> 00:38:32,340
How many end to end kind of fall on debate says the system performed. Oh this is an interesting question.

156
00:38:32,340 --> 00:38:45,340
I would say it's probably close to 100 okay but but publicly debates out of IBM I would say it's around five.

157
00:38:45,340 --> 00:38:55,340
Okay so most of the debates were were internally and and we started the first live debates in 2016.

158
00:38:55,340 --> 00:39:06,340
After more or less four years of work we felt that that's it we we must jump into the water and and we started the first live debates and this was.

159
00:39:06,340 --> 00:39:16,340
The system was completely clueless you know I I remember many many team members vividly remember this one of the first debates we had it was whether or not.

160
00:39:16,340 --> 00:39:28,340
Physical education should be compulsory and and the system started to talk about sex education and and the human debate was trying to bring it back to the topic and the system was just drifting away.

161
00:39:28,340 --> 00:39:46,340
And this was very amusing for some people in the audience and very disturbing for some other people in the audience depending on on your perspective I guess but I would say what was interesting to to see was that you know in 2016 it was at the level of a toddler.

162
00:39:46,340 --> 00:40:06,340
It was not making a lot of sense it was making arguments in favor of the opposition drifting away and so on three years later it was at the level of a strong university debate so the way I like to see it we made it from kindergarten to university in three years which is pretty good.

163
00:40:06,340 --> 00:40:32,340
So you've got this you know set of 100 debates the debates are evaluated by having human evaluators or audience members rate their perspective on the topic before and after the debate does that then become a source of training data that you can use to have the machine learn from its own performance or do you would you need a lot more debates in order for that.

164
00:40:32,340 --> 00:40:59,340
That's more a lot more we only use that for evaluation and to keep track of where we are in terms of the performance of the system over time and so we will have some kind of a quantitative assessment before we go out and presented to the board but but again we were discussing within the team is it possible to do something like that using an end to end system.

165
00:40:59,340 --> 00:41:19,340
Because obviously this is not an end to end system right we we have these components we have this orchestrator that that is we we actually in the paper we use this term of composite artificial intelligence because we think of it is like in composition in music.

166
00:41:19,340 --> 00:41:30,340
So basically you need to orchestrate all these different capabilities into a single cognitive activity which which is debating and the question emerge.

167
00:41:30,340 --> 00:41:44,340
Can you do that using an end to end system and how much data you will need for that and and to be fair from from my perspective I don't see how this can be done in an end to end panel.

168
00:41:44,340 --> 00:42:04,340
If you have many many debates I maybe this will show up you know in come in upcoming years but I think this is this is one of these tasks that actually should be handled by by decomposing the problem into more tangible problems.

169
00:42:04,340 --> 00:42:23,340
So I alluded to the fact that you know when you first started this project deep learning was at its infancy and certainly we've seen natural language processing evolve pretty dramatically over the past several years with the emergence of language models.

170
00:42:23,340 --> 00:42:38,340
Now both from a technology perspective as well as from a kind of managing a recent project perspective how do you deal with that change that's happening parallel for such a big problem.

171
00:42:38,340 --> 00:42:51,340
This actually has an interesting history in in the project because when we started deep learning was not really dominant in the NLP.

172
00:42:51,340 --> 00:43:00,340
It was a feature engineering and logistical gradients for claim detection and evidence detection and so on.

173
00:43:00,340 --> 00:43:18,340
And then in in I admit I was you know I was I was very suspicious about this deep learning trend and and not to say annoyed by it when when it started to show up and said look I don't like that and

174
00:43:18,340 --> 00:43:32,340
but it became larger and larger and more and more team members said look we cannot ignore that yeah and and I said fine I'm that's okay but you need to show me numbers.

175
00:43:32,340 --> 00:43:36,340
We're not going to do that just because everybody else are doing that.

176
00:43:36,340 --> 00:43:54,340
If you can show me on the on the benchmark data sets that that we have that this is performing better or and or even comparable to what we already have that that's fine now willing to switch but the burden of proof is on you.

177
00:43:54,340 --> 00:44:13,340
And we have this team of researchers that started to look into that more and more and and I was starting to be unpatient to be felt because it took time and the result were not that good we had actually better results but in a couple of months.

178
00:44:13,340 --> 00:44:32,340
At some point they told me look we need two more weeks and I said I said fine okay if you think that you can really improve in two weeks fine go ahead and and and they did it and and they showed very nice result actually slightly better than what we had by then.

179
00:44:32,340 --> 00:44:57,340
It was on claim detection it was detecting claims and and and this was I think sometime doing 2015 okay and and this was very interesting to see because you know the profile is in the numbers you you you can have your own criticism about whether this is good or bad for science but but if this team.

180
00:44:57,340 --> 00:45:15,340
In just a couple of months outperforms the on walk that they did for you know for two or more years you cannot ignore that and then we started the shift so so we started to use declining more and more and and and in 2016.

181
00:45:15,340 --> 00:45:40,340
I would say three things happened we started to move to declining and we started to consider much larger data the Lexis nexus corpus up to that point we were considering only Wikipedia and we started to annotate data with the count and and the boost in terms of the result was was remarkable so at the end of 2015.

182
00:45:40,340 --> 00:46:01,340
This was the numbers that we had for claim detection and for evidence detection you know the precision in the top 40 predictions was you know 25% 30% it was a it's a very tough problem and this was very disturbing by the end of 2016 we were above 70%.

183
00:46:01,340 --> 00:46:17,340
And and today actually if you consider the evidence detection module that that we have with you know these APIs that that we release where we use belt fine tuned over large data and and so on.

184
00:46:17,340 --> 00:46:30,340
We get more than 95% accuracy over the top 40 predictions averaged over 100 topics which is really remarkably in my opinion.

185
00:46:30,340 --> 00:46:46,340
Can you speak a little bit to the kind of methodologies that you evolved around annotation and taking advantage of crowd workers to deliver that annotation.

186
00:46:46,340 --> 00:47:11,340
Yes, this was another dominant issue that we needed to address because we had many problems and we needed to collect annotate data of many for many different challenges and we started with an in house team of annotators that we trained very carefully so we had this team and they and they did tremendous work but eventually it doesn't scale.

187
00:47:11,340 --> 00:47:37,340
So we needed to move to the crowd we use that was called crowd flower at the time then it was called figure eight today it is called up and but we developed a lot of expertise in working with the crowd annotators and and one interesting transition was that when we walked with the in house and it annotators at the beginning we were very pedantic very very careful about how to define evidence how to define claim.

188
00:47:37,340 --> 00:47:48,340
We had this book that we wrote with all the guidelines and all the examples and all that so the first data that we developed was very precise but also very small.

189
00:47:48,340 --> 00:48:05,340
It contained a few I would say 500 Wikipedia pages completely annotated by these annotators which was a tremendous effort but this was too small and when you move to the crowd you cannot show them such elaborated guidelines.

190
00:48:05,340 --> 00:48:23,340
They're not going to do that they're not going to read that so so the focus was really how do you articulate in you know just a couple of paragraphs maybe three paragraphs what you mean by evidence and what you mean by claim if them two or three clear examples and they should be good to go.

191
00:48:23,340 --> 00:48:47,340
And then you need to add a lot of layers of I would say monitoring the quality of the work of each annotator and removing those that are doing poor job and and rewarding those that are doing good job and this is how we eventually were able to to annotate large large enough data.

192
00:48:47,340 --> 00:49:10,340
And are you using are you currently using a quorum type of approach to annotation where you get the multiple and of course each each sentence when I said that we annotated 2000 sentences I meant each sentence was considered by between 10 to 15 people.

193
00:49:10,340 --> 00:49:22,340
So so this was we invested a lot in that and and many of the data sets that that we developed we we shared with the community.

194
00:49:22,340 --> 00:49:41,340
So access nexus we don't have the you know the terms of the data is that we cannot share that but Wikipedia data and other data sets we are sharing and some of the data sets are very interesting we for example over the years we recorded I think close to 3000

195
00:49:41,340 --> 00:49:52,340
debate speeches by human debaters they were debating kind of it was very interesting it's like you play chess by by mail.

196
00:49:52,340 --> 00:50:01,340
I send you an envelope with my move and then you hope this was you know back in the days and then you open the letter and you read the move and then you do you move and you send me a letter.

197
00:50:01,340 --> 00:50:16,340
So we had debates in this format basically we we we had a team of of debaters and they were receiving a topic and the guidance well you know you need to prepare for 10 minutes and then you need to record yourself with the opening speech.

198
00:50:16,340 --> 00:50:34,340
And then this speech is being sent to another debater you never meet him okay this is being sent to someone else and his guidance is really to listen to the speech and and then prepare a rebuttal and then the rebuttal is going to perhaps to a third debater was listening to the first two speeches and responding so.

199
00:50:34,340 --> 00:50:52,340
So in this way we we collected around 3000 debates speeches and we also shared that in a recent paper last year with the community where we did some analysis over these data so so I really encourage all the listeners.

200
00:50:52,340 --> 00:51:10,340
I would say to do two things first of all to visit the project debater website and and you know consider all the data sets that we released over the years and and more over to twice many of the capabilities that we developed they're available for free for for academic research.

201
00:51:10,340 --> 00:51:39,340
So it could be weakification that I mentioned it could be claim detection evidence detection procon analysis argument quality that we didn't have time to touch and even more advanced capabilities that we are developing over the last two years like key point analysis and narrative generation so all these are also text clustering all these are freely available so I assume you will put the link on on.

202
00:51:39,340 --> 00:51:57,340
On the podcast and everybody can go there and if you are a researcher in the field during academic research I and college people to give it a shot and these are there about a dozen of these APIs that are accessible for some problems.

203
00:51:57,340 --> 00:52:22,340
Yes, we have about a dozen we're going to give a tutorial in ACL on that and also on each guy and and we are we are excited to see what people will do with that awesome will definitely link to provide the link to that in the show notes page so check that out if you're listening to this and interested in learning more to kind of wrap us up.

204
00:52:22,340 --> 00:52:43,340
I'm wondering you know this 10 years of experience from initial idea to today what your experience with this project has kind of taught you or left you with in thinking about the broader development of AI.

205
00:52:43,340 --> 00:53:09,340
I would say the first answer is actually not about AI it's about people I think it's really about the people that you work with and I feel truly fortunate to be able to work with an amazing team of researchers that are not only top researchers dedicated to their mission but but they're simply people that are fun to work with.

206
00:53:09,340 --> 00:53:33,340
So I think this is the most important aspect to spend your time with people that you like and that you have fun to work with and in terms of AI I think you know we started this conversation by mentioning earlier grand challenges in artificial intelligence and.

207
00:53:33,340 --> 00:54:02,340
Grand Challenges in AI are really there from from day one so so back in the fifties out of some oils who was in IBM actually the person who coined the term machine learning he was working on developing a software that can play checkers and he spent decades on that today looks kind of trivial but he spent decades on that and when he succeeded when it was performing very well.

208
00:54:02,340 --> 00:54:31,340
And this was a sensation people were amazed by that and then Geritas are one of the founders of reinforcement learning also still working in in IBM research worked on backgammon and developed fantastic software this was in the late 80s early 90s that was able to play backgammon and and using I would say at least conceptually techniques that are not very different from what you see in recent years.

209
00:54:31,340 --> 00:54:55,340
In in alpha go and in the 90s that there was chess and more recently alpha go but deep mind but but I think all these board games while they were extremely instrumental in in pushing the boundaries of AI they still lie in what I refer to as the comfort zone of artificial intelligence.

210
00:54:55,340 --> 00:55:20,340
And there are several reasons to that I will touch on one when a board game is done we know who won the game and this has very important implications because this means that we can have many versions of the system we can get the signal from each game so you can hold millions that ends of the system they play against each other after each game is done you know who won the game you can improve by that.

211
00:55:20,340 --> 00:55:49,340
But when a debate is done we do not necessarily know who won the debate it's not even clear how to define that so you don't have this pass and you need to follow and use other power times so I would say debate is certainly out of the comfort zone of artificial intelligence it's it's in a different territory where humans are actually still better and and from my perspective I think this is good news because this means that we still have many open questions to answer.

212
00:55:49,340 --> 00:56:09,340
Awesome awesome well now I'm thanks so much for taking the time to share a bit about what you're working on and IBM debater very very interesting project with a very broad scope and it's been nice for me to have the opportunity to follow it over the years.

213
00:56:09,340 --> 00:56:12,340
Thank you very much Sam was a real pleasure.

214
00:56:12,340 --> 00:56:22,340
Thank you.

