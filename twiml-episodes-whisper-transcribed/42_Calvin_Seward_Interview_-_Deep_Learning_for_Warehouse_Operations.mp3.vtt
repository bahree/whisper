WEBVTT

00:00.000 --> 00:16.000
Hello and welcome to another episode of Twimmel Talk, the podcast where I interview

00:16.000 --> 00:21.400
interesting people, doing interesting things in machine learning and artificial intelligence.

00:21.400 --> 00:24.200
I'm your host Sam Charrington.

00:24.200 --> 00:29.200
This week, I'm happy to bring you my interview with Calvin Seward, a research scientist with

00:29.200 --> 00:31.800
Berlin-Germany-Based Zalando.

00:31.800 --> 00:36.360
Now, our American listeners might not know the name Zalando, but they're one of the largest

00:36.360 --> 00:41.080
e-commerce companies in Europe with a focus on fashion and shoes.

00:41.080 --> 00:46.060
Calvin is a research scientist there, while also pursuing his doctorate studies at Johannes

00:46.060 --> 00:49.400
Kepler University in Linz, Austria.

00:49.400 --> 00:54.080
Our discussion continues the Industrial AI series here on the podcast, and focuses on

00:54.080 --> 01:00.240
how Calvin's team tackled an interesting warehouse optimization problem using deep learning.

01:00.240 --> 01:02.560
Before we dive into the show, take note.

01:02.560 --> 01:08.400
This is the last podcast before we give away not one, but two tickets to the AI conference

01:08.400 --> 01:13.080
in San Francisco, brought to you by O'Reilly and Intel Nirvana.

01:13.080 --> 01:17.360
If you've listened to the podcast for a while, you already know that this is one of my favorite

01:17.360 --> 01:21.960
events, and you've already heard some of the great speakers that it attracts.

01:21.960 --> 01:26.000
If you'd like to attend, now is the time to enter our giveaway.

01:26.000 --> 01:31.080
Folks really seem to like our new Streamline contest app that makes it super quick to make

01:31.080 --> 01:33.640
up to 10 contest entries.

01:33.640 --> 01:40.920
To get your entries in, just hop on over to twimmelai.com slash AISF, and stay tuned for

01:40.920 --> 01:44.400
our announcement of the winners on next week's show.

01:44.400 --> 01:51.120
And now, a quick shout out to our sponsors, bonsai, and wise.io at GE Digital.

01:51.120 --> 01:55.960
If you've heard me mention bonsai before, bonsai offers an AI platform that lets enterprises

01:55.960 --> 02:01.280
build and deploy intelligent systems for industrial applications and more.

02:01.280 --> 02:06.280
Banzai's platform lets enterprises develop robust machine learning models that improve

02:06.280 --> 02:11.000
system control and enhance real-time decision support.

02:11.000 --> 02:16.120
Their platform also automates the management of deployed machine learning applications,

02:16.120 --> 02:20.960
allowing businesses to use them to increase automation and improve operational efficiency

02:20.960 --> 02:26.800
of industrial systems, including robotics, manufacturing, supply chain, logistics, energy

02:26.800 --> 02:28.520
and utilities.

02:28.520 --> 02:34.640
You can find more information about bonsai and their early access program at bonds.ai slash

02:34.640 --> 02:36.440
twimmelai.

02:36.440 --> 02:42.200
And undoubtedly you know GE, but did you know that GE was a software company too?

02:42.200 --> 02:47.240
GE Digital is a leading software company focused on solutions for the industrial internet

02:47.240 --> 02:52.440
of things, and is reimagining industry's infrastructure for connecting software, apps

02:52.440 --> 02:55.840
and analytics to industrial businesses.

02:55.840 --> 03:00.880
GE Digital creates software powered by their predix platform to design, build, operate

03:00.880 --> 03:06.480
and manage the entire life cycle of physical assets, enabling industrial businesses to

03:06.480 --> 03:09.840
operate faster, smarter, and more efficiently.

03:09.840 --> 03:15.760
The wise.io team, now part of GE Digital, is building industrial machine learning applications

03:15.760 --> 03:17.960
for GE and its customers.

03:17.960 --> 03:23.720
For more information about GE Digital, visit GE.com slash digital.

03:23.720 --> 03:25.760
And now on to the show.

03:25.760 --> 03:37.120
All right, everyone, I am on the line with Calvin Seward.

03:37.120 --> 03:43.160
Calvin is a Berlin Germany-based research scientist at Zalando, and he's also pursuing

03:43.160 --> 03:47.360
his doctorate at Johannes Kepler University in Lens Austria.

03:47.360 --> 03:49.320
Calvin, welcome to the show.

03:49.320 --> 03:50.320
Welcome.

03:50.320 --> 03:55.720
Folks, who are listening to the show know that I was recently in Berlin, and I am in fact

03:55.720 --> 04:00.560
connected with you while I was in Berlin, but unfortunately we weren't able to connect

04:00.560 --> 04:03.000
locally, but we're connected now.

04:03.000 --> 04:08.800
So I'm really looking forward to diving into our topic today, which is some work that

04:08.800 --> 04:13.680
you did not too long ago on warehouse optimization.

04:13.680 --> 04:18.720
But before we dive into that, why don't we spend a little bit of time having you introduce

04:18.720 --> 04:20.720
yourself to the audience?

04:20.720 --> 04:21.720
Yeah, thanks.

04:21.720 --> 04:24.600
See, as I said, I'm Calvin Seward.

04:24.600 --> 04:31.080
Originally, I studied mathematics at the Humboldt University here in Berlin.

04:31.080 --> 04:36.440
And since then, I've been working at Zalando, and so Zalando is the tech company that nobody's

04:36.440 --> 04:37.440
heard of.

04:37.440 --> 04:41.040
It's a very large online retailer based in Germany.

04:41.040 --> 04:45.840
And so it's more centered on fashion retail in the European market.

04:45.840 --> 04:51.480
So it's well known in Europe, but very not so well known in the rest of the world.

04:51.480 --> 04:57.520
And in addition to working at Zalando, I also am pursuing my doctorate.

04:57.520 --> 05:02.920
So the doctorate's program is cooperation between the Johannes Kepler University in Lens

05:02.920 --> 05:05.400
in Austria and Zalando.

05:05.400 --> 05:11.960
And so it's really nice, it's really fun, because I get to do research, but I also get to

05:11.960 --> 05:14.920
use Zalando's resources and Zalando's data.

05:14.920 --> 05:16.360
And so it's a really cool thing.

05:16.360 --> 05:18.840
Oh, that sounds like a great opportunity.

05:18.840 --> 05:20.320
It really is.

05:20.320 --> 05:24.720
How did you initially get interested in artificial intelligence?

05:24.720 --> 05:29.240
Somehow my career, it's always just been like, you know, whatever the next thing is, just

05:29.240 --> 05:30.240
do it.

05:30.240 --> 05:35.360
So I studied statistics, and so then when I started Zalando, I was

05:35.360 --> 05:39.000
one of the first people doing data science.

05:39.000 --> 05:42.000
And I don't even think my title was data scientist.

05:42.000 --> 05:44.640
It was like data analyst or something like this.

05:44.640 --> 05:49.840
And so at the beginning, we just did ad hoc reporting for for management, trying to answer

05:49.840 --> 05:56.920
questions like, oh, should the article breadth be broader or so should we have more articles,

05:56.920 --> 05:59.480
more different articles or should it be deeper?

05:59.480 --> 06:04.920
So each article have more time so that so that it doesn't get sold out so quickly.

06:04.920 --> 06:06.760
Different questions like that.

06:06.760 --> 06:12.680
And then slowly but surely, the low-hanging fruit got dealt with, and it became apparent

06:12.680 --> 06:16.560
that they didn't order to keep up with the competition.

06:16.560 --> 06:19.000
You know, we had to step up our game.

06:19.000 --> 06:24.960
And so that's how we got interested in artificial intelligence because, you know, it was definitely

06:24.960 --> 06:30.920
the next big thing and is something that can can drive a lot of customer value.

06:30.920 --> 06:35.480
Maybe you can tell us a little bit about the warehouse optimization problem that you've

06:35.480 --> 06:36.480
worked on.

06:36.480 --> 06:37.480
Yeah.

06:37.480 --> 06:43.880
What we did was we first had one project called the O'Coffee Projects, where you can

06:43.880 --> 06:49.240
imagine the inside of warehouse, it looks like an offline retailer actually.

06:49.240 --> 06:54.640
It looks like targets or a safe way or Tesco or Kaufland or, you know, I don't know which

06:54.640 --> 06:59.640
country my listeners are going to be sitting in, but just one of these large or Walmart,

06:59.640 --> 07:04.320
one of these large stores with a bunch of aisles with items and cross aisles.

07:04.320 --> 07:08.600
And people walk through these store with shopping carts and they put items in the shopping

07:08.600 --> 07:12.280
cart and then they go to check out and leave.

07:12.280 --> 07:17.520
And so it's the same way in the offline or in the online warehouse.

07:17.520 --> 07:24.360
So what happens is our workers, they start off at this thing that we call the train station

07:24.360 --> 07:27.200
and they pick up this cart that's empty.

07:27.200 --> 07:31.000
And then they walk through the aisles and the cross aisles and they put items into their

07:31.000 --> 07:32.000
cart.

07:32.000 --> 07:37.320
And then when they've sort of completed their shopping list, they bring the cart back

07:37.320 --> 07:42.440
to the train station and it's sent on to be processed and for the items to be sent

07:42.440 --> 07:44.080
to the customers.

07:44.080 --> 07:48.760
So then everybody knows when they're shopping that there's an efficient way and there's

07:48.760 --> 07:50.960
an inefficient way to walk through the store.

07:50.960 --> 07:56.400
And so you first, you first buy your butter and your milk because those are close to one

07:56.400 --> 07:58.600
another and then you go off and buy the bread.

07:58.600 --> 08:01.440
You don't do the butter than the bread and then the milk.

08:01.440 --> 08:07.160
And so it's the same way in the online warehouse that we want to, we want to know how to order

08:07.160 --> 08:11.920
the shopping list so that the worker can walk through the warehouse and not to move away.

08:11.920 --> 08:16.120
So this is sort of a traveling salesman problem where you have a bunch of different locations

08:16.120 --> 08:20.840
that the worker has to visit and then you want to be able to tell the worker how to

08:20.840 --> 08:23.960
visit the locations in the most efficient way.

08:23.960 --> 08:30.640
And so there was some research that was done about how to walk through the warehouse.

08:30.640 --> 08:36.000
If the warehouse has a specific layout and it's this so-called rope ladder layout.

08:36.000 --> 08:42.040
And so it's like, it's the same layout that you have in most large offline retail stores.

08:42.040 --> 08:47.240
And the rope ladder layout is, well, tell us specifically what that means.

08:47.240 --> 08:54.720
You have aisles and cross aisles and each cross aisle or each aisle is the same length

08:54.720 --> 08:59.240
and they have and they're aligned with one another.

08:59.240 --> 09:03.520
So it's not like you have this weird jog that you have to make.

09:03.520 --> 09:04.520
Okay.

09:04.520 --> 09:09.600
So it's kind of a simplification and I guess now that I'm visualizing it rope ladder is

09:09.600 --> 09:14.560
just simply trying to create that visual of two long rows with a bunch of cross aisles,

09:14.560 --> 09:15.560
that kind of thing.

09:15.560 --> 09:17.720
Exactly, it looks like a rope ladder.

09:17.720 --> 09:18.720
Got it.

09:18.720 --> 09:19.720
Yeah.

09:19.720 --> 09:25.040
And so there was some work that was already done on optimizing for this setup.

09:25.040 --> 09:32.760
But what was missing was the people who work in the warehouse say they have these big

09:32.760 --> 09:37.800
carts they push around and they're actually quite large because they can carry a lot of

09:37.800 --> 09:38.800
items.

09:38.800 --> 09:39.800
Okay.

09:39.800 --> 09:43.800
But they're sort of difficult to handle and so it's the same way if you're shopping

09:43.800 --> 09:48.640
offline, if you if your cart is fairly full, then you generally leave it in the cross

09:48.640 --> 09:54.000
aisle and you walk into the aisle without the cart and collect your, collect your items

09:54.000 --> 09:56.000
and then return to the cart.

09:56.000 --> 10:00.640
And so we wanted to be able to tell the workers, okay, how best to, to handle the cart.

10:00.640 --> 10:04.920
So we extended this algorithm and we come up with this, this algorithm we call the copy

10:04.920 --> 10:05.920
algorithm.

10:05.920 --> 10:10.080
And so this is called optimal cart pick algorithm that's able to tell the warehouse

10:10.080 --> 10:16.080
workers how best to walk through the warehouse and where to leave the cart.

10:16.080 --> 10:19.680
So that the warehouse worker knows he can always just leave his cart where the algorithm

10:19.680 --> 10:25.160
suggests it and then I think walk to the different locations and get the items and he

10:25.160 --> 10:29.560
knows that the, that the algorithm will always bring him back to the cart before he gets

10:29.560 --> 10:34.000
too much stuff that he can carry, you know, too many things to carry.

10:34.000 --> 10:37.240
And so this is, this has absolutely nothing to do with machine learning.

10:37.240 --> 10:38.720
Let me just say that.

10:38.720 --> 10:41.240
So if people think, oh, where's the machine learning?

10:41.240 --> 10:43.080
It's still not here yet.

10:43.080 --> 10:49.120
This is a fairly straightforward discrete optimization problem where you just have to, you

10:49.120 --> 10:53.760
have this list of items, you have to decide how to order the items, you have these list

10:53.760 --> 10:57.240
of cart locations that you can put the cart and you've got to insert the cart locations

10:57.240 --> 10:58.880
in there somehow.

10:58.880 --> 11:02.440
And then you've got to optimize the sky with a dynamic programming algorithm.

11:02.440 --> 11:06.840
So it, the optimization works is linear in the number of, number of aisles.

11:06.840 --> 11:10.160
So it's, it's got a reasonable enough complexity.

11:10.160 --> 11:16.680
Okay, before we move on, you mentioned traveling salesman problem and, you know, folks that

11:16.680 --> 11:22.560
have done any work in computer science would, you know, probably be familiar with that.

11:22.560 --> 11:27.720
But in case there are folks that aren't familiar with the implications of, you know, something

11:27.720 --> 11:33.200
being essentially a TSP, what does that mean in terms of, you know, how we know how to,

11:33.200 --> 11:34.600
to solve that problem?

11:34.600 --> 11:40.800
Oh, there's, there's lots of literature on, on solving traveling salesman problems.

11:40.800 --> 11:43.520
But at the end of the day, it's an MP hard problem.

11:43.520 --> 11:50.480
So MP hard means, means that it's something that's in the most general case is exponentially

11:50.480 --> 11:51.480
complex.

11:51.480 --> 11:55.320
And so there's lots of other risks about how to solve it.

11:55.320 --> 11:58.560
But you can imagine that, that there's traveling salesman problems.

11:58.560 --> 12:02.760
So, so the idea is that the way, the place that the name comes from is you have a bunch

12:02.760 --> 12:09.480
of different locations, and you have some salesman, and he starts at his house, and he wants

12:09.480 --> 12:15.200
to then go visit all the locations, and he wants to do it in a way to where, to where

12:15.200 --> 12:17.960
the distance that he travels is minimal.

12:17.960 --> 12:20.160
And so there's lots of other risks on it.

12:20.160 --> 12:26.320
And obviously if the locations are organized in a nice way, then how best to do it is

12:26.320 --> 12:27.320
fairly clear.

12:27.320 --> 12:33.000
For example, if all the dimensions lie on all the locations lie on a one-dimensional line,

12:33.000 --> 12:36.160
then it's fairly clear how best to travel.

12:36.160 --> 12:40.000
But already in two dimensions, it becomes difficult.

12:40.000 --> 12:43.360
So this rope ladder warehouse layout is one of these special cases.

12:43.360 --> 12:47.640
You can think of it like the, the single dimensions case where you just have a line.

12:47.640 --> 12:52.440
It's a special case to where you can efficiently solve the traveling salesman problem.

12:52.440 --> 12:59.680
Okay, and then you mentioned your cart handling strategy component of this, where you're trying

12:59.680 --> 13:03.480
to figure out where to, where the worker can park their cart.

13:03.480 --> 13:10.720
Do you also need to consider anything along the lines of been packing or cart capacity

13:10.720 --> 13:12.720
or anything like that?

13:12.720 --> 13:18.040
Yeah, I mean, it's something you can't consider, but at the end of the day, it's not a huge

13:18.040 --> 13:24.760
deal because basically just try and try and make the pick list as large as possible.

13:24.760 --> 13:30.000
And then if the cart gets too full, then there's a button for the, for the warehouse worker

13:30.000 --> 13:33.520
where he just says, my cart is full and then he goes back to the train station and gets

13:33.520 --> 13:35.960
a new cart and the system deals with that.

13:35.960 --> 13:40.280
So, okay, so that's not, that's not really a big problem.

13:40.280 --> 13:41.280
Okay.

13:41.280 --> 13:48.280
So you mentioned that the formulation of this problem, this okapi algorithm is, you know,

13:48.280 --> 13:49.920
we're at discrete optimization.

13:49.920 --> 13:52.000
It's not yet machine learning.

13:52.000 --> 13:55.960
How is the discrete optimization problem solves in practice?

13:55.960 --> 13:59.160
So for us, it's a dynamic programming algorithm.

13:59.160 --> 14:01.160
That's what it, that's what it's called.

14:01.160 --> 14:04.480
And so, so I mean, there's a couple of articles online.

14:04.480 --> 14:07.880
You can, you can Google it where I explain this.

14:07.880 --> 14:13.680
So let me, let me try and remember how best to explain it, but the idea of dynamic programming

14:13.680 --> 14:20.400
is that you, you know that there's a lot of different combinations, but each combination

14:20.400 --> 14:26.560
will, there's these transitions between combinations and they can only take on a certain finite

14:26.560 --> 14:28.400
number of states.

14:28.400 --> 14:32.360
And so you just look for the best combination for each transition.

14:32.360 --> 14:38.960
And so the way this looks in, in practice is, is imagine we have a rope ladder way, lay

14:38.960 --> 14:41.520
out with only two cross aisles, okay?

14:41.520 --> 14:42.520
Okay.

14:42.520 --> 14:48.800
And then, then imagine we, we sort of split it, split it in half, right?

14:48.800 --> 14:51.040
So then there's these two cross aisles.

14:51.040 --> 14:53.200
And so, and we're not, don't think about the cart.

14:53.200 --> 14:54.200
We're not thinking about the cart.

14:54.200 --> 14:56.200
We're just thinking about the optimal way to walk.

14:56.200 --> 14:57.200
Okay.

14:57.200 --> 15:00.120
Then there's a couple of different things that they can happen.

15:00.120 --> 15:03.320
Either the worker, he, he doesn't walk.

15:03.320 --> 15:04.840
So these, these two cross aisles.

15:04.840 --> 15:09.440
So the, these two little cross aisle sections, they're in the middle, okay?

15:09.440 --> 15:12.160
So either the worker doesn't walk on those.

15:12.160 --> 15:16.680
So that means that his entire pick route was either the left or the right.

15:16.680 --> 15:19.880
Or it can happen that he only walks.

15:19.880 --> 15:21.760
So he's got a return to where he started, yeah.

15:21.760 --> 15:26.600
So that means that he walks once on both of them.

15:26.600 --> 15:29.480
So he walks on the, on the top cross aisle.

15:29.480 --> 15:34.080
He walks once on the bottom cross aisle, he walks once, okay?

15:34.080 --> 15:38.080
Or it's possible that he walks twice at the top.

15:38.080 --> 15:41.040
Or it's possible that he walks twice at the bottom.

15:41.040 --> 15:46.040
Or it's possible that he walks twice at both the top and bottom.

15:46.040 --> 15:48.920
So these are all the different states that are possible.

15:48.920 --> 15:56.360
And so what you can do then is no matter what your optimal solution is on the left and

15:56.360 --> 15:59.040
no matter what your optimal solution is on the right.

15:59.040 --> 16:03.760
They're going to have to communicate with each other via these, these seven different states.

16:03.760 --> 16:09.200
So if you can sort of recursively find the optimal solution for the left.

16:09.200 --> 16:13.520
What you can do is then you can recursively find seven different optimal solutions for

16:13.520 --> 16:15.160
these seven different transitions.

16:15.160 --> 16:19.560
I don't remember if it was exactly seven, but these seven different transitions, you

16:19.560 --> 16:22.520
can know, okay, what's the optimal solution going to be.

16:22.520 --> 16:28.360
And then you just calculate, okay, what's the, what's the optimal route for the next cross

16:28.360 --> 16:34.560
aisle, or the next aisle section, and for these seven different transitions.

16:34.560 --> 16:39.360
And then you do that recursively until you get to the end.

16:39.360 --> 16:43.040
And so then instead of having to think about every single different combination, you're

16:43.040 --> 16:48.800
always just trying to figure out, okay, what's the best one for these seven different states?

16:48.800 --> 16:54.400
Okay, if I could try to paraphrase that you, again, we're looking at this warehouse with

16:54.400 --> 17:02.080
this rope ladder configuration, and you can basically chunk it down into sections of the

17:02.080 --> 17:08.680
rope ladder with two cross aisles and then solve the optimization problem locally.

17:08.680 --> 17:14.400
And then that's all kind of strung together recursively to give you an overall optimal

17:14.400 --> 17:15.400
strategy.

17:15.400 --> 17:16.400
Exactly.

17:16.400 --> 17:17.400
Exactly.

17:17.400 --> 17:18.400
Okay.

17:18.400 --> 17:19.400
It's hard to explain.

17:19.400 --> 17:24.880
The first time I read the paper, I was also like, what's going on here?

17:24.880 --> 17:29.680
I also saw you mentioned in some of your writing simulated annealing, is that this process

17:29.680 --> 17:31.840
that we just described, or is that something different?

17:31.840 --> 17:34.240
Okay, so that's definitely the next step.

17:34.240 --> 17:37.760
So now what we got was we got this copy algorithm.

17:37.760 --> 17:41.000
So a copy is short for optimal cart pick.

17:41.000 --> 17:42.000
Okay.

17:42.000 --> 17:47.800
And it works well, but since we have larger warehouses that are more than just two cross

17:47.800 --> 17:55.720
aisles, and since we have this cart business going on, it takes like a second or so to calculate

17:55.720 --> 17:59.600
calculate what the optimal route will end up being, right?

17:59.600 --> 18:00.600
Okay.

18:00.600 --> 18:04.720
So if you're just trying to figure out the route for the warehouse worker, you already

18:04.720 --> 18:07.720
have your pick list together, then it's fine.

18:07.720 --> 18:14.240
But the next step is, of course, to optimize the pick list, because every day the warehouse

18:14.240 --> 18:18.280
worker is a pick, you know, hundreds of thousands of pick lists.

18:18.280 --> 18:22.920
And if you can optimize these to where each pick list has items that are fairly close

18:22.920 --> 18:30.200
to one another, and optimize it to where the pick lists are fairly large, and batches

18:30.200 --> 18:35.080
don't have to be picked from very many zones of the warehouse, then this is a real good

18:35.080 --> 18:36.280
thing.

18:36.280 --> 18:44.200
But in order to do this, you have to sort of know how long a hypothetical pick list will

18:44.200 --> 18:45.880
end up being.

18:45.880 --> 18:52.720
And this one second thing is really a big constraint, because then you can't try out, you know, thousands

18:52.720 --> 18:58.560
and thousands of different combinations without racking up a huge Amazon web services bill

18:58.560 --> 19:00.560
that's prohibited.

19:00.560 --> 19:06.120
So what we did is we just just to make sure I'm understanding there you.

19:06.120 --> 19:14.120
With this Ocopy algorithm, that'll give you basically the routing for an individual,

19:14.120 --> 19:16.160
you know, pick list and picker.

19:16.160 --> 19:24.400
And then in order to figure out the best way to organize the pick list and like the orders,

19:24.400 --> 19:26.520
you have to just brute force that.

19:26.520 --> 19:31.880
So you go through and run this Ocopy algorithm a bunch of times with a bunch of pick lists.

19:31.880 --> 19:32.880
Is that the idea?

19:32.880 --> 19:38.440
Yeah, well, I mean, even if you're using simulated kneeling, you still have to, I mean, so

19:38.440 --> 19:42.240
yeah, there's, there's methods better than brute force like simulated kneeling, but even

19:42.240 --> 19:45.360
there you have to try out a bunch of different combinations.

19:45.360 --> 19:46.360
Okay.

19:46.360 --> 19:52.240
You're, you're never going to, you're never going to get around having to try out, try out

19:52.240 --> 19:56.960
a bunch of different combinations of a pick list to see which ones end up being super

19:56.960 --> 20:01.520
long and which ones end up being quite reasonable.

20:01.520 --> 20:08.480
And so your problem comes in when you've got, when it takes one second to try out one

20:08.480 --> 20:13.640
of these combinations to do that at scale, takes a really long time.

20:13.640 --> 20:14.640
Exactly.

20:14.640 --> 20:15.640
Exactly.

20:15.640 --> 20:22.400
I think you had an example of, I don't know if this map to the kind of a real life Zolando

20:22.400 --> 20:26.000
configuration, but like 2000 years to.

20:26.000 --> 20:27.000
Yeah, exactly.

20:27.000 --> 20:28.000
Exactly.

20:28.000 --> 20:34.320
Jesus, Jesus would order his shoes and he still wouldn't have them now.

20:34.320 --> 20:40.880
So you've got the two problems and your focus was on trying to reduce the time it takes

20:40.880 --> 20:46.960
to calculate, is it to calculate an optimal route or to calculate the length of a route

20:46.960 --> 20:48.560
given a pick list?

20:48.560 --> 20:53.800
Yeah, to calculate the length of the optimal route given the pick list.

20:53.800 --> 20:54.800
Got it.

20:54.800 --> 20:58.320
Basically calculating for this stuff where we're trying to figure out which order goes

20:58.320 --> 21:03.120
with which pick list or which order should be in which pick list.

21:03.120 --> 21:06.400
We don't actually have to know what the route should be.

21:06.400 --> 21:11.280
We just need to know how long the optimal route would end up being.

21:11.280 --> 21:12.360
Okay.

21:12.360 --> 21:19.240
And so we want to decrease that time because whether we're using brute force or simulated

21:19.240 --> 21:23.920
annealing or some other kind of heuristic, it's still going to be dependent on the amount

21:23.920 --> 21:28.920
of time it takes us to figure out the length of the optimal route for a given pick list.

21:28.920 --> 21:29.920
Exactly.

21:29.920 --> 21:30.920
Exactly.

21:30.920 --> 21:34.800
So there's two different levers we can pull to speed things up.

21:34.800 --> 21:43.040
One is better simulated annealing, heuristics, and the other one is just make this bottleneck

21:43.040 --> 21:47.640
which is calculating the length of a pick list faster.

21:47.640 --> 21:48.640
Mm-hmm.

21:48.640 --> 21:49.640
All right.

21:49.640 --> 21:51.600
And that's where machine learning comes in.

21:51.600 --> 21:52.600
Exactly.

21:52.600 --> 21:54.840
Now we're finally going to get to machine learning.

21:54.840 --> 21:59.240
I hope the audience is still with us right now.

21:59.240 --> 22:01.880
I'm sure they are because this is their time.

22:01.880 --> 22:02.880
Okay.

22:02.880 --> 22:03.880
Okay.

22:03.880 --> 22:07.280
If you've been tuning out now is your time to tune back in.

22:07.280 --> 22:14.920
So what we did then is we used this copy algorithm to generate data that we learn on.

22:14.920 --> 22:21.040
So we just generate millions and millions of random pick lists.

22:21.040 --> 22:24.560
And we put these through the copy algorithm.

22:24.560 --> 22:31.080
So we had a bunch of different CPU cores just running at the same time, taking a random

22:31.080 --> 22:38.760
pick list, calculating how long that would take, and then spitting out the answer.

22:38.760 --> 22:44.040
And so these computers, they generated our training data.

22:44.040 --> 22:49.840
And then with this training data, where we've got a pick list, so we know where the articles

22:49.840 --> 22:53.400
are that need to be picked and how many there are.

22:53.400 --> 22:57.480
And how long it would take for the optimal route to get picked.

22:57.480 --> 23:05.160
So given these two guys, we can then feed this information into a neural network and train

23:05.160 --> 23:09.160
that neural network and get some sort of a good result.

23:09.160 --> 23:12.920
And so there's lots of stuff you can simulate, yeah.

23:12.920 --> 23:18.080
And some of it will be good for neural networks and some of it probably won't.

23:18.080 --> 23:23.240
For example, if you think of some sort of a fancy hashing algorithm that tries to avoid

23:23.240 --> 23:27.480
hash collisions, you can obviously simulate this, but you wouldn't be able to get a neural

23:27.480 --> 23:32.640
network to to give you the same output because the whole idea of hashing algorithms is that

23:32.640 --> 23:37.320
it's, you know, as non-continuous as possible.

23:37.320 --> 23:43.600
But for this copy thing, it works very nicely because you can imagine if you just have one

23:43.600 --> 23:46.640
pick and you move it around in the warehouse.

23:46.640 --> 23:51.280
If you just move it a little bit, it won't change, change the pick routes very much.

23:51.280 --> 23:55.200
So if you move it a little bit in the cross aisle or in the aisle, it won't change the

23:55.200 --> 24:00.360
pick route very much because the worst thing that can happen is if you move it, you know,

24:00.360 --> 24:05.720
a foot, the worst thing that can happen is the warehouse worker has to walk an extra foot

24:05.720 --> 24:06.720
to get there.

24:06.720 --> 24:08.960
It's not so linear in the cross aisle.

24:08.960 --> 24:12.960
So if you have a pick that's in the middle of the aisle and you move it the next aisle

24:12.960 --> 24:16.560
over, it could be that it creates a big jump.

24:16.560 --> 24:21.640
Because then the warehouse worker, he may have been going to that aisle already.

24:21.640 --> 24:24.240
And then this new aisle, he wasn't planning on going there.

24:24.240 --> 24:28.280
And so then the distance is quite a lot larger.

24:28.280 --> 24:31.840
But still it's, you know, it's not these huge jumps.

24:31.840 --> 24:37.800
So that's one reason why it's a nice thing to model with neural networks.

24:37.800 --> 24:44.280
And then the dependencies between the articles are also nice because obviously it's not

24:44.280 --> 24:48.960
just some linear sum, you know, if this article is here and this article is here, the distance

24:48.960 --> 24:51.720
for the guy has to walk is the sum of the two distances.

24:51.720 --> 24:55.520
But it's this complex dependency between all the different articles.

24:55.520 --> 24:59.080
But this is this sort of more locally dependent.

24:59.080 --> 25:05.040
So it's less of one of these situations where the butterflies, wings in Japan cause an

25:05.040 --> 25:08.720
earthquake and an LA situations.

25:08.720 --> 25:15.240
But it's more that as you shift articles around, it really only has, generally, I mean,

25:15.240 --> 25:19.040
sometimes there's exceptions, but generally it really just has an effect on how the warehouse

25:19.040 --> 25:24.040
worker walks in that area and it doesn't have too much of an effect on, on far flowing

25:24.040 --> 25:26.440
corners of the warehouse.

25:26.440 --> 25:31.800
And so because of this, because we don't have too many jumps and the function is somewhat

25:31.800 --> 25:35.760
continuous, makes it through it's good for neural networks.

25:35.760 --> 25:42.680
Because, because local structures are more important than global structures, we can use

25:42.680 --> 25:47.600
convolutional neural networks because the convolutional filters, they only focus on local

25:47.600 --> 25:49.000
features.

25:49.000 --> 25:54.120
And then they combine these local features together as they move up through the hidden layers.

25:54.120 --> 25:55.120
Hmm.

25:55.120 --> 26:03.560
So then let me take a second to kind of recap basically, we want to get the time to figure

26:03.560 --> 26:10.720
out the optimal path length for this, you know, for picking an order down.

26:10.720 --> 26:15.280
Neural networks is probably a great way to do that.

26:15.280 --> 26:21.640
And essentially what we're trying to do is we're trying to train a neural network to approximate

26:21.640 --> 26:24.120
this Ocopi algorithm.

26:24.120 --> 26:30.160
And we do that by generating a bunch of random pick lists and throwing them through the

26:30.160 --> 26:35.080
Ocopi algorithm to generate the path length.

26:35.080 --> 26:39.680
So basically generating our training data through by throwing random data through this Ocopi

26:39.680 --> 26:40.920
algorithm.

26:40.920 --> 26:46.160
And then using that to train our neural network, exactly, exactly.

26:46.160 --> 26:51.000
And so I guess one question that I've got is it, you know, you found that it, you know,

26:51.000 --> 26:56.120
at one second per route to run things through this, or it takes a second to run a route

26:56.120 --> 27:02.280
through this Ocopi algorithm. And in order to, you know, fully explore the state space

27:02.280 --> 27:08.320
for like a real warehouse, it would take 2,000 something years if you did all of those,

27:08.320 --> 27:14.040
you know, what, how much coverage do you need in order to, you know, accurately train

27:14.040 --> 27:16.400
a neural network to do this?

27:16.400 --> 27:22.200
What, you know, what percent of that state space or how many training samples do you need?

27:22.200 --> 27:27.120
Well, we didn't really say, oh, we have to have exactly this accuracy.

27:27.120 --> 27:30.880
But we just said, oh, you know, we've got this machine here.

27:30.880 --> 27:34.920
Let's create enough pick lists where the machine runs for a week or so.

27:34.920 --> 27:38.800
And then, and then because we've got other things to do this week, and then next week we'll

27:38.800 --> 27:41.000
come back and look at the results.

27:41.000 --> 27:44.920
So that's the way it works a lot of times, you know, and then we look to the results.

27:44.920 --> 27:47.040
And we're like, it's good enough.

27:47.040 --> 27:50.080
And then, and then that was, and that's how it happened.

27:50.080 --> 27:54.160
So it wasn't like we explored, oh, how many, how many pick lists do we have to create

27:54.160 --> 27:55.160
to get this accuracy?

27:55.160 --> 28:01.960
But it was just sort of these practical considerations that were more at the, at the forefront.

28:01.960 --> 28:07.920
And then, you know, I typically associate convolutional neural nets with image processing

28:07.920 --> 28:15.960
types of tasks, but yet it worked in this case based on the, you know, this locality aspect

28:15.960 --> 28:16.960
of the problem.

28:16.960 --> 28:23.320
Because it was the, did you have to jump through any intermediate steps to kind of format the

28:23.320 --> 28:27.480
process so that it, or format the input data so that it looked like an image, or you're

28:27.480 --> 28:31.600
just kind of feeding it, you know, data that, you know, was natural to the problem.

28:31.600 --> 28:35.720
And, you know, without any kind of intermediate steps.

28:35.720 --> 28:39.840
I think that it didn't a day, we used cafe for this.

28:39.840 --> 28:44.760
So this was a, this was back in the dark days before TensorFlow.

28:44.760 --> 28:48.520
And so there you had different, different input layers.

28:48.520 --> 28:53.880
And I think we figured out that the, the TTIF, it's an image format.

28:53.880 --> 28:58.680
I think that we figured out that that was the most convenient, convenient layer to use.

28:58.680 --> 29:05.280
So yeah, the pick list, we, we transformed them into a TTIF image and we had these images

29:05.280 --> 29:06.280
in there.

29:06.280 --> 29:07.280
Okay.

29:07.280 --> 29:08.600
Interesting.

29:08.600 --> 29:14.800
But, I mean, this is really just a stupid technical detail, it was just, it was just because

29:14.800 --> 29:17.680
of the, the different input layers and cafe.

29:17.680 --> 29:22.080
And so if we had done it with TensorFlow now, it would have been a, a whole different

29:22.080 --> 29:23.080
story.

29:23.080 --> 29:24.080
Okay.

29:24.080 --> 29:31.040
And so the, you used a convolutional network to model this.

29:31.040 --> 29:36.040
How did you arrive at the ultimate architecture of that network and the, you know, the number

29:36.040 --> 29:39.360
of layers and the configuration of those layers and all that stuff?

29:39.360 --> 29:45.520
Oh, we tried out a couple of different things and then one of them worked and we were happy.

29:45.520 --> 29:46.520
But, okay.

29:46.520 --> 29:50.600
I mean, there's a little bit of dark, dark arts, this sort of thing.

29:50.600 --> 29:56.240
And we, we knew, we knew sort of like what the interactions are between different articles.

29:56.240 --> 30:00.880
And so we said, okay, you know, because of these interactions, maybe the filter size

30:00.880 --> 30:05.520
should be about this, this large and we knew how complex interactions could be.

30:05.520 --> 30:09.680
So the depth of the network should be around here and then tried out a couple of different

30:09.680 --> 30:11.600
combinations.

30:11.600 --> 30:16.960
And then today, I mean, these, these TTIF images were, we're not, not particularly large

30:16.960 --> 30:23.840
because each, each aisle is then one, one pixel in each, each cross aisle or, and then,

30:23.840 --> 30:28.400
and then the depth, the depth of the cross aisle, that's, that's the, or the depth of an

30:28.400 --> 30:33.440
aisle is sort of a prox, and prox mission because obviously these articles are, are located

30:33.440 --> 30:37.760
some discrete spots or some continuous spot, though you have to make it into a discrete

30:37.760 --> 30:38.760
pixel.

30:38.760 --> 30:42.640
So it's a little bit of an approximation, but who cares?

30:42.640 --> 30:46.920
And so, and so the images were not particularly large, we were feeding through and so you

30:46.920 --> 30:52.520
could train it very quickly and within, within the course of, of a day and just try out a

30:52.520 --> 30:56.040
bunch of different things and just see what works best be done with it.

30:56.040 --> 30:57.040
Okay.

30:57.040 --> 30:58.040
All right.

30:58.040 --> 30:59.040
Awesome.

30:59.040 --> 31:05.680
And what were you able to accomplish in terms of getting your, your time down that you

31:05.680 --> 31:07.320
were trying to accomplish?

31:07.320 --> 31:08.320
Oh, yeah.

31:08.320 --> 31:10.240
No, that was, that was really good.

31:10.240 --> 31:15.360
So I don't remember these act numbers, but it's definitely under, under a millisecond.

31:15.360 --> 31:20.680
So so I did, I did a benchmark and that's, that's in one of the blog articles where, where

31:20.680 --> 31:25.720
we just then, they ran it and we, we had different configurations because obviously with a,

31:25.720 --> 31:28.680
with this sort of thing, it's, it's a whole lot more efficient if you don't just calculate

31:28.680 --> 31:31.560
one pick list, but calculate a batch of pick lists together.

31:31.560 --> 31:32.560
Mm-hmm.

31:32.560 --> 31:36.720
And so you're able to take your pick lists and put them in a big batch and calculate that

31:36.720 --> 31:38.400
whole batch.

31:38.400 --> 31:43.720
And if you had a large enough batch, maybe 30 or 40 pick lists, then you were, you were

31:43.720 --> 31:45.400
well under a millisecond.

31:45.400 --> 31:47.240
And so this was a huge improvement.

31:47.240 --> 31:48.240
Okay.

31:48.240 --> 31:49.240
Awesome.

31:49.240 --> 31:50.240
Awesome.

31:50.240 --> 31:51.240
Yeah.

31:51.240 --> 31:54.640
And also, also just, I mean, you didn't even have to use fancy hardware, a millisecond

31:54.640 --> 32:02.440
on the CPU, yeah, so if we had used the GPU, sure, it would have been even faster, but.

32:02.440 --> 32:09.280
And the millisecond corresponds to inference against the trained network as opposed to,

32:09.280 --> 32:10.640
and then that's why it's so fast.

32:10.640 --> 32:11.640
Yeah.

32:11.640 --> 32:12.640
Yeah.

32:12.640 --> 32:15.280
Learning is obviously a little bit slower because there you have the forward pass, the

32:15.280 --> 32:19.200
backwards pass, the weight updating and all this other business going on.

32:19.200 --> 32:20.200
Mm-hmm.

32:20.200 --> 32:22.280
And so that, that you really want to do on the GPU.

32:22.280 --> 32:26.160
But when you're just inferring afterwards, it's a small network.

32:26.160 --> 32:29.480
So you can, you can just infer a small picture of a small network.

32:29.480 --> 32:31.760
So you can just infer on the CPU.

32:31.760 --> 32:34.840
And you're already, you're already very fast.

32:34.840 --> 32:41.120
And obviously for, for when you're deploying it to a live system, people always like it

32:41.120 --> 32:46.080
when you can deploy it to a large number of different hardware setups and you don't

32:46.080 --> 32:48.480
have to have one specific GPU.

32:48.480 --> 32:51.080
So that's always a big advantage.

32:51.080 --> 32:52.080
Awesome.

32:52.080 --> 32:54.800
So you solved this problem.

32:54.800 --> 32:56.880
Where did you go next?

32:56.880 --> 33:01.280
That was one of the last warehouse problems that we actually dealt with because at the end

33:01.280 --> 33:04.680
of the day, you can think, think of it this way, you know.

33:04.680 --> 33:09.120
If you solve these warehouse problems, it's really great because it makes it to where fulfillment

33:09.120 --> 33:12.400
costs are lower, the item gets there faster.

33:12.400 --> 33:13.640
So everybody wins.

33:13.640 --> 33:19.240
The customers, they're happier because they don't have to pay as much for fulfillment costs.

33:19.240 --> 33:23.320
We win because we don't have to have such large warehouses because everything works more

33:23.320 --> 33:24.320
efficiently.

33:24.320 --> 33:29.800
But at the end of the day, the maximum, you know, win you can make is whatever your fulfillment

33:29.800 --> 33:30.800
costs are.

33:30.800 --> 33:35.240
If you can manage to be so efficient, the fulfillment is for free, then that's the maximum

33:35.240 --> 33:37.400
you can get.

33:37.400 --> 33:44.880
Whereas if you develop new products that really excites customers and make it to where you

33:44.880 --> 33:51.200
can engage with customers who weren't engaging with you beforehand, the potential winnings

33:51.200 --> 33:53.560
are, you know, just through the roof.

33:53.560 --> 33:55.720
There's no limit to that.

33:55.720 --> 34:00.640
And so we said, okay, we want to try and get away from just incrementally eking out

34:00.640 --> 34:08.200
a little bit of efficiency here and there and we want to get into things that really create

34:08.200 --> 34:15.120
new ways of interacting with, with fashion and interacting with e-commerce.

34:15.120 --> 34:19.640
And so, and so I think you see this a lot, I go to a lot of, you know, industry conferences

34:19.640 --> 34:24.680
and I really see this a lot that there's this progression in companies.

34:24.680 --> 34:28.920
And the first thing that they do is they, they have all this data sitting around and the

34:28.920 --> 34:35.320
first thing they do is they realize, oh, we can use this data to drive efficiency.

34:35.320 --> 34:42.320
And that was one of the first projects that I helped contribute to was this forecast

34:42.320 --> 34:46.880
where we, you know, tried to predict which articles would be returned so that we could

34:46.880 --> 34:52.880
have enough workers at the warehouse on the day that these articles would be coming back

34:52.880 --> 34:55.800
because we didn't, you know, the customers, they just put them in the mail when they

34:55.800 --> 34:56.800
want to return them.

34:56.800 --> 35:01.800
So we don't really know how many articles are going to come to us on a given day.

35:01.800 --> 35:06.800
Yeah, but we were able to use data and fairly accurately predict which articles were going

35:06.800 --> 35:11.000
to be returned when and make it to where the right number of workers were there.

35:11.000 --> 35:14.280
So this was, it was a driver of efficiency is very nice.

35:14.280 --> 35:18.240
So a lot of companies, that's the first thing that they do is they take some sort of

35:18.240 --> 35:24.160
existing process and they make it a little bit more efficient with, with data science

35:24.160 --> 35:26.640
and with machine learning.

35:26.640 --> 35:31.780
And then you can go to the next thing, which is this project that I've talked about now,

35:31.780 --> 35:38.080
which is you create new processes that drive efficiency through, through data science.

35:38.080 --> 35:44.760
So any sort of, any sort of consideration of how to split the pick list or split the

35:44.760 --> 35:50.480
orders between pick list to optimize, to optimize the actual walking distance.

35:50.480 --> 35:53.120
This was completely impossible without a copy.

35:53.120 --> 35:58.160
So no one even thought about trying to do it, but by having a copy, you were able to

35:58.160 --> 36:02.840
come up with new processes, and by having data science, you were able to come up with

36:02.840 --> 36:05.880
new processes that drive efficiency.

36:05.880 --> 36:08.360
But for the customer, nothing has changed.

36:08.360 --> 36:12.160
There's absolutely no new products for him.

36:12.160 --> 36:15.800
It could have been, you know, just a bunch of business people sitting around, you know,

36:15.800 --> 36:17.400
coming up with business rules.

36:17.400 --> 36:22.480
He doesn't notice the difference, but what's really great is when you can then come up

36:22.480 --> 36:28.600
with new products like you're really great, recommend their really great search.

36:28.600 --> 36:32.960
All these self-driving cars is obviously also an example, we don't have that, we're not

36:32.960 --> 36:33.960
working with that.

36:33.960 --> 36:39.760
But these are products that are genuinely new and wouldn't have been possible and are

36:39.760 --> 36:41.800
new for the customer too.

36:41.800 --> 36:46.600
And this is where the big future is at.

36:46.600 --> 36:51.160
It's interesting that your examples are recommenders and searches.

36:51.160 --> 36:58.000
But think of those as kind of these existing things that we do, much like the warehouse,

36:58.000 --> 37:03.520
we do them, you know, using either brute force or, you know, brute force things that

37:03.520 --> 37:07.520
feel like brute force in their sophistication.

37:07.520 --> 37:12.600
And not necessarily like, you know, wholly new kind of user experiences.

37:12.600 --> 37:17.280
Do you have some examples of the way that you're thinking about recommendations and search

37:17.280 --> 37:23.280
that illustrate, you know, where the new opportunities come in for you?

37:23.280 --> 37:24.280
Yeah.

37:24.280 --> 37:29.440
So it's a great question because, yeah, obviously, for example, for documents search,

37:29.440 --> 37:35.160
you can always have some strange business rules that come up with documents.

37:35.160 --> 37:40.840
But I guess you're old enough to remember, you know, what searching the internet was like

37:40.840 --> 37:42.560
before Google came around.

37:42.560 --> 37:44.960
It was completely different animal.

37:44.960 --> 37:48.280
Yes, there was search, but it was so frustrating.

37:48.280 --> 37:51.800
And it's the same way with like old speech recognition systems.

37:51.800 --> 37:57.120
Yes, it was so there were systems, but they were so frustrating that it's as if, you

37:57.120 --> 38:02.600
know, if something's unusable, then it's pointless, you know?

38:02.600 --> 38:06.600
So I'm saying, sure, you can always come up with something that does something.

38:06.600 --> 38:10.840
But if it's so frustrating, then it's pointless and it's the same with self-driving cars.

38:10.840 --> 38:17.440
I mean, even back in the day, they had these cars that somehow were able to tell where

38:17.440 --> 38:22.680
the line was and stay between it, but they were in no way shape or form safe.

38:22.680 --> 38:27.720
And so, you know, what's the point if it is this Russian roulette?

38:27.720 --> 38:35.920
But by using data science, you can cross this threshold between something that's unusable

38:35.920 --> 38:40.920
and something that's usable, and that's what I mean by enabling a new product, enabling

38:40.920 --> 38:45.400
a product that's usable, that's what I guess I mean.

38:45.400 --> 38:55.880
Okay, and so to extend this, there are different ways of searching, you know, the classic search

38:55.880 --> 38:59.880
is just you have, it's this is a document-based search.

38:59.880 --> 39:05.640
You have your text field, you type something in, blue dress or whatever, and then you get

39:05.640 --> 39:08.600
a list of blue dresses.

39:08.600 --> 39:13.080
And I think that there's definitely ways that we can improve this.

39:13.080 --> 39:17.200
So we came up, we came up, for example, with a little tinder, a tinder for fashion

39:17.200 --> 39:23.400
articles, ones where you swipe left, swipe right, and you get shown different stuff.

39:23.400 --> 39:27.800
And so it wasn't like, it wasn't all that usable, but it was a fun thing and it was like

39:27.800 --> 39:34.880
just a way of showing that search can be different than box at the top and then display

39:34.880 --> 39:36.720
results at the bottom.

39:36.720 --> 39:37.720
Right.

39:37.720 --> 39:44.480
I've also seen companies in this space experimenting with image-based search, you know,

39:44.480 --> 39:49.520
similarity, things like that, is that the general direction that you guys are headed

39:49.520 --> 39:51.000
with this kind of stuff?

39:51.000 --> 39:58.720
Oh yes, definitely, definitely, we, I mean, fashion, it's so, so I mean, if you're like

39:58.720 --> 40:03.080
searching, you know, Amazon, they start off with books, and then when you search for

40:03.080 --> 40:07.400
a book, it's fairly simple, because you don't, you don't judge a book by its cover, you

40:07.400 --> 40:09.520
search for the author and the title.

40:09.520 --> 40:14.640
But in fashion, you do judge a dress by, by its picture.

40:14.640 --> 40:21.760
And it's very difficult to, even for experts, to describe, address, use words to describe

40:21.760 --> 40:24.240
exactly what it's going to look like.

40:24.240 --> 40:28.440
And so, and then if you have a layperson and they're, they're trying to wait for our

40:28.440 --> 40:33.560
huge assortment and trying to find something fairly specific and, and this assortment

40:33.560 --> 40:38.000
with over 100,000 articles, then it's going to be very difficult for them to find the

40:38.000 --> 40:39.000
right article.

40:39.000 --> 40:45.320
And thus, we have more clever search, search things than just using metadata, just using

40:45.320 --> 40:51.720
some, some description that some, that some people have hand annotated, which obviously

40:51.720 --> 40:56.400
it works for books, it works for computers, you just sort of say, what sort of, what's

40:56.400 --> 40:59.760
a RAM you want, what sort of processor you want, and bam, you've got your results, but

40:59.760 --> 41:04.040
you can't do that with dresses and fashion articles.

41:04.040 --> 41:10.320
I guess when I think of how that process is done today, not necessarily for fashion,

41:10.320 --> 41:16.960
but, you know, with other e-commerce search experiences, it seems like the, you know,

41:16.960 --> 41:26.120
that search and research experience is largely driven by, as you said, metadata in the

41:26.120 --> 41:32.000
fashion space to the extent that it's currently, you know, still driven by metadata, where

41:32.000 --> 41:33.000
does that come from?

41:33.000 --> 41:38.200
Is that, I guess you already said, it's basically hand, it's all handcrafted, right?

41:38.200 --> 41:45.320
Yeah, yeah, it's handcrafted and it's just been, it's been a very open question as to how

41:45.320 --> 41:53.200
to extract data from unstructured, or how to extract insights, useful insights from unstructured

41:53.200 --> 41:59.400
data, and pictures are very much unstructured data, but like one thing that you can do that's

41:59.400 --> 42:05.280
fairly easy, even with today's understanding is it's fairly easy to come up with, with

42:05.280 --> 42:11.240
neural networks, they're able to say if fashion articles are similar or dissimilar based

42:11.240 --> 42:18.000
on the picture, and then you can, you can use this similarity measure to help improve

42:18.000 --> 42:22.720
your recommendation system, so then at the bottom it's always like, oh, customers who

42:22.720 --> 42:28.200
like this also clicked on this, you know, and then, then you can improve the recommendation

42:28.200 --> 42:34.480
experience that way, that's definitely an easy, low-hanging fruit, even with today's

42:34.480 --> 42:36.560
image recognition stuff.

42:36.560 --> 42:37.560
Okay.

42:37.560 --> 42:44.480
Well, let me ask you this, when you're working on a problem like the warehouse optimization

42:44.480 --> 42:52.480
problem, where there are existing processes, or if not existing processes, existing costs

42:52.480 --> 42:58.440
associated with that, and you're comparing that to something that is more or less wholly

42:58.440 --> 43:09.520
new like a new user experience for discovery or for searching for items, it strikes me

43:09.520 --> 43:13.680
that you have to take a very different approach and building out the business case for these

43:13.680 --> 43:21.000
two types of things, and that depending on the culture of an organization, the management

43:21.000 --> 43:25.880
team, et cetera, it may be more difficult to do one than the other.

43:25.880 --> 43:30.000
Do you have any insights on navigating that process based on your experience working

43:30.000 --> 43:36.520
across these different types of problems, and as you described it, kind of the maturity

43:36.520 --> 43:42.240
of starting from one type of problem and moving to the next and then moving to the next?

43:42.240 --> 43:48.160
Yeah, that's a really great question, and I would say that the most important thing

43:48.160 --> 43:56.520
is that you have management that's for thinking enough to know that these sort of things

43:56.520 --> 44:02.440
is not an easy win, and it's not a win that happens immediately, but it's something

44:02.440 --> 44:07.480
where you have to invest for a while before you get something good, and you really don't

44:07.480 --> 44:11.120
know exactly how long that's going to take.

44:11.120 --> 44:17.400
So management is really important, and then these managers, they then have to say, okay,

44:17.400 --> 44:23.480
we're going to not try and devote all of our resources just to the next release cycle,

44:23.480 --> 44:29.120
but we're also going to devote some resources to things that are not going to pay off immediately.

44:29.120 --> 44:32.920
And so I work in Salando Research, and that's what we do.

44:32.920 --> 44:38.240
That's what we try and focus on, is things that are more of long-term benefit and less

44:38.240 --> 44:39.240
short-term.

44:39.240 --> 44:44.160
And so it's really great that the Salando management team has decided that this is a really

44:44.160 --> 44:50.960
important thing, and this is really something that I find hard to find in a lot of companies,

44:50.960 --> 44:53.160
and so I'm really happy about this.

44:53.160 --> 45:00.000
And then from our perspective, it's helpful to not put all your eggs in one basket.

45:00.000 --> 45:07.320
So don't just focus on one deliverable, but focus on portfolio of deliverables.

45:07.320 --> 45:11.120
So we try and focus on four main things.

45:11.120 --> 45:18.120
We focus on prestige as one, so things like what I'm doing right now, with talks and podcasts

45:18.120 --> 45:23.120
and generating excitement for Salando and the great research we're doing.

45:23.120 --> 45:29.760
We focus on products, new products, we focus on papers, so academic publications to really

45:29.760 --> 45:35.880
sell the great research we're doing within the academic community, and we focus on patents,

45:35.880 --> 45:40.120
patenting, whenever we come up with new ideas, we patent them, because the patent portfolio

45:40.120 --> 45:43.120
is also very valuable.

45:43.120 --> 45:45.680
Interesting.

45:45.680 --> 45:50.920
So you mentioned prestige, patents, publications, and some other things.

45:50.920 --> 45:58.200
It sounds like from that that you guys are very active out in the machine learning community,

45:58.200 --> 46:02.960
as well as e-commerce communities, how can folks in the listening audience who want

46:02.960 --> 46:08.560
to learn more about the kinds of things you're doing, how can folks find you and find all

46:08.560 --> 46:10.560
that good stuff?

46:10.560 --> 46:11.560
That's a great question.

46:11.560 --> 46:16.840
We have a tech blog, so the Salando tech blog, and it's not just us that they're right

46:16.840 --> 46:21.360
to this blog, but there's lots of different techies at Salando who write to this.

46:21.360 --> 46:25.720
And so, and there's also Salando research page where we're different projects are detailed

46:25.720 --> 46:27.200
that we're working on.

46:27.200 --> 46:29.120
There's two great ways to get started.

46:29.120 --> 46:33.000
If you like what you see, you can always send us a job application.

46:33.000 --> 46:37.680
We're always looking for new, excited data scientists and researchers.

46:37.680 --> 46:41.200
So those are two great ways to get into what we're doing.

46:41.200 --> 46:42.200
Awesome.

46:42.200 --> 46:45.200
And I'll include links to those in the show notes.

46:45.200 --> 46:46.200
Yes.

46:46.200 --> 46:48.000
Calvin, I really enjoyed this conversation.

46:48.000 --> 46:49.000
Thank you so much.

46:49.000 --> 46:50.000
Yes.

46:50.000 --> 46:51.000
Yes.

46:51.000 --> 46:53.000
Thanks for taking the time.

46:53.000 --> 46:56.480
All right, everyone.

46:56.480 --> 46:58.320
That's our show for today.

46:58.320 --> 47:03.240
Thanks so much for listening and for your continued feedback and support.

47:03.240 --> 47:07.960
For the notes for this episode, to ask any questions or to let us know how you like the

47:07.960 --> 47:13.960
show, please, please, please leave a comment on the show notes page at twimolei.com slash

47:13.960 --> 47:16.800
talk slash 38.

47:16.800 --> 47:22.040
Thanks again to our sponsors, bonsai and wise.io at GE Digital.

47:22.040 --> 47:27.640
For more information about bonsai, visit bons.ai slash twimolei.

47:27.640 --> 47:33.320
And for more on GE Digital, visit GE.com slash digital.

47:33.320 --> 47:40.760
Once you're done with this show, take 30 seconds to head over to twimolei.com slash AISF to enter

47:40.760 --> 47:45.400
our giveaway for a free ticket to the AI conference in San Francisco.

47:45.400 --> 47:48.440
You could be one of two lucky winners.

47:48.440 --> 47:54.200
For more information on industrial AI, my report on the topic or the industrial AI podcast

47:54.200 --> 47:59.560
series, visit twimolei.com slash industrial AI.

47:59.560 --> 48:26.320
Thanks again for listening and catch you next time.

