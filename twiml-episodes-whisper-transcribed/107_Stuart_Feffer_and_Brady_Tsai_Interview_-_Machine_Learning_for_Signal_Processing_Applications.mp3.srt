1
00:00:00,000 --> 00:00:16,120
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

2
00:00:16,120 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:32,440
I'm your host Sam Charrington.

4
00:00:32,440 --> 00:00:33,840
Contest alert.

5
00:00:33,840 --> 00:00:38,960
This week we have a jam-packed intro, including a new contest we're launching.

6
00:00:38,960 --> 00:00:43,040
So please bear with me, you don't want to miss this one.

7
00:00:43,040 --> 00:00:46,720
First, a bit about this week's shows.

8
00:00:46,720 --> 00:00:51,440
As you may know, I spent a few days at CES earlier this month.

9
00:00:51,440 --> 00:00:56,400
While there, I spoke with a bunch of folks applying AI in the consumer electronics industry,

10
00:00:56,400 --> 00:01:01,040
and I'm including you in those conversations via this series of shows.

11
00:01:01,040 --> 00:01:05,440
Stay tuned as we explore some of the very cool ways that machine learning and AI are being

12
00:01:05,440 --> 00:01:08,600
used to enhance our everyday lives.

13
00:01:08,600 --> 00:01:13,680
This includes work being done at Anki, who built Cosmo, the cutest little computer vision-powered

14
00:01:13,680 --> 00:01:15,280
robot.

15
00:01:15,280 --> 00:01:22,120
Nighthouse, whose smart home security camera combines 3D sensing with deep learning and NLP.

16
00:01:22,120 --> 00:01:28,120
Intel, who's using the single-shot multi-box image detection algorithm to personalize video

17
00:01:28,120 --> 00:01:31,680
fees for the Ferrari Challenge North America.

18
00:01:31,680 --> 00:01:36,440
First beat, a company whose machine learning algorithms analyzed your heartbeat data to

19
00:01:36,440 --> 00:01:42,360
provide personalized insights into stress, exercise, and sleep patterns.

20
00:01:42,360 --> 00:01:48,400
3AI and Koito, who have partnered to bring machine learning-based adaptive driving beams

21
00:01:48,400 --> 00:01:52,280
or automatically adjusting high beams to the U.S.

22
00:01:52,280 --> 00:01:59,480
And last but not least, aerial.ai, who applies sophisticated analytics to Wi-Fi signals to

23
00:01:59,480 --> 00:02:05,640
enable some really interesting home automation and healthcare applications.

24
00:02:05,640 --> 00:02:11,000
Now as if six amazing interviews wasn't enough, a few of these companies have been so

25
00:02:11,000 --> 00:02:15,520
kind as to provide us with products for you, the Twimmel community.

26
00:02:15,520 --> 00:02:19,360
And keeping with the theme of this series, our contest will be a little different this

27
00:02:19,360 --> 00:02:20,360
time.

28
00:02:20,360 --> 00:02:25,400
To enter, we want to hear from you about the role AI is playing in your home and personal

29
00:02:25,400 --> 00:02:28,640
life, and where you see it going.

30
00:02:28,640 --> 00:02:36,200
Just head on over to twimmelai.com slash myaicontest, fire up your webcam or smartphone camera,

31
00:02:36,200 --> 00:02:39,120
and tell us your story in two minutes or less.

32
00:02:39,120 --> 00:02:43,600
Go post the videos to YouTube, and the video with the most likes wins their choice of

33
00:02:43,600 --> 00:02:50,480
great prizes, including an Anki Cosmo, a lighthouse smart home camera, and more.

34
00:02:50,480 --> 00:02:55,040
Submissions will be taken until February 11th, and voting will remain open until February

35
00:02:55,040 --> 00:02:56,040
18th.

36
00:02:56,040 --> 00:03:02,360
Good luck.

37
00:03:02,360 --> 00:03:06,560
Before we dive into today's show, I'd like to thank our friends at Intel AI for their

38
00:03:06,560 --> 00:03:09,520
continued support of this podcast.

39
00:03:09,520 --> 00:03:14,760
Intel was extremely active at this year's CES, with a bunch of AI autonomous driving

40
00:03:14,760 --> 00:03:17,200
and VR related announcements.

41
00:03:17,200 --> 00:03:21,440
One of the more interesting partnerships they announced was a collaboration with the Ferrari

42
00:03:21,440 --> 00:03:24,720
Challenge North America race series.

43
00:03:24,720 --> 00:03:29,440
Along with the folks at Ferrari Challenge, Intel AI aspires to make the race viewing experience

44
00:03:29,440 --> 00:03:35,360
more personalized by using deep computer vision to detect and monitor individual race

45
00:03:35,360 --> 00:03:40,640
cars via camera feeds and allow viewers to choose the specific cars feeds that they'd

46
00:03:40,640 --> 00:03:42,200
like to watch.

47
00:03:42,200 --> 00:03:46,960
Look for my conversation with Intel's Andy Keller and Emil Chindicki earlier in this series

48
00:03:46,960 --> 00:03:52,920
for an in-depth discussion about this project, and be sure to visit ai.intel.com where you'll

49
00:03:52,920 --> 00:03:56,200
find Andy's technical blog post on the topic.

50
00:03:56,200 --> 00:03:58,880
Now about today's show.

51
00:03:58,880 --> 00:04:05,440
In this episode, I'm joined by Stuart Feffer, co-founder and CEO of Reality AI, which provides

52
00:04:05,440 --> 00:04:11,240
tools and services for engineers working with sensors and signals, and Brady Tsai, business

53
00:04:11,240 --> 00:04:17,680
development manager at Kui Tu, which develops automotive lighting solutions for car manufacturers.

54
00:04:17,680 --> 00:04:22,360
Stuart and Brady joined me at CES a few weeks ago after they announced a partnership to bring

55
00:04:22,360 --> 00:04:27,760
the adaptive driving beam or ADB headlights to North America.

56
00:04:27,760 --> 00:04:33,000
Brady explains what exactly ADB technology is and how it works, while Stuart walks me

57
00:04:33,000 --> 00:04:38,400
through the technical aspects not only of this partnership, but of the reality AI platform

58
00:04:38,400 --> 00:04:40,040
as a whole.

59
00:04:40,040 --> 00:04:44,400
And now on to the show.

60
00:04:44,400 --> 00:04:53,160
Hey everyone, we are here at CES and I am with Stuart Feffer of Reality AI and Brady

61
00:04:53,160 --> 00:04:56,080
Tsai of Kui Tu.

62
00:04:56,080 --> 00:04:59,200
Stuart and Brady, welcome to this week in machine learning and AI.

63
00:04:59,200 --> 00:05:00,200
Hi.

64
00:05:00,200 --> 00:05:01,200
Hi.

65
00:05:01,200 --> 00:05:06,720
It's great to have you guys here, and thanks for braving the driving rain and horrendous

66
00:05:06,720 --> 00:05:09,640
traffic at CES to make it here.

67
00:05:09,640 --> 00:05:11,280
It is a phenomenon, that's for sure.

68
00:05:11,280 --> 00:05:14,360
It is definitely a spectacle.

69
00:05:14,360 --> 00:05:19,800
Why don't we get started by having the two of you guys introduce yourselves and tell

70
00:05:19,800 --> 00:05:24,640
us a little bit about your background and kind of how you got to what you're up to nowadays.

71
00:05:24,640 --> 00:05:25,880
Yeah, sure.

72
00:05:25,880 --> 00:05:30,040
So yeah, I'm Stuart Feffer and I'm a co-founder and CEO of Reality AI.

73
00:05:30,040 --> 00:05:35,160
And we're an AI startup, I'm sure you have a lot of them on these past podcasts.

74
00:05:35,160 --> 00:05:38,720
And our focus is a little different than most I think.

75
00:05:38,720 --> 00:05:45,120
We are very much focused on problems related to sensors and signals.

76
00:05:45,120 --> 00:05:51,360
And we're not deep learning, we are, we use a different set of approaches that are very

77
00:05:51,360 --> 00:05:56,360
much grounded in signal processing math, and I'm sure we'll talk about that.

78
00:05:56,360 --> 00:06:01,840
We're here at CES with one of our customers, Coeto, also known in the United States as

79
00:06:01,840 --> 00:06:06,280
North American lighting, and they're making a product announcement that features our

80
00:06:06,280 --> 00:06:07,280
technology.

81
00:06:07,280 --> 00:06:08,280
Nice.

82
00:06:08,280 --> 00:06:09,280
Brady?

83
00:06:09,280 --> 00:06:10,280
Hi, I'm Brady.

84
00:06:10,280 --> 00:06:15,440
I'm business development manager with NL and Coeto.

85
00:06:15,440 --> 00:06:22,360
I work in a Silicon Valley lab, which is based in San Jose, just to give you a brief introduction

86
00:06:22,360 --> 00:06:23,360
of Coeto.

87
00:06:23,360 --> 00:06:26,720
Coeto is a tier one supplier for automotive lighting.

88
00:06:26,720 --> 00:06:35,600
And we are the supplier for major OEMs, such as Honda, Toyota, and Ford.

89
00:06:35,600 --> 00:06:38,840
There is a product called ADP.

90
00:06:38,840 --> 00:06:45,400
That's where we work with Stuart Reality AI, try to bring the AI into automotive lightings.

91
00:06:45,400 --> 00:06:46,400
It's called ADP?

92
00:06:46,400 --> 00:06:47,400
ADP.

93
00:06:47,400 --> 00:06:48,400
Okay.

94
00:06:48,400 --> 00:06:49,800
Adaptive driving beam.

95
00:06:49,800 --> 00:06:52,480
Adaptive driving beam.

96
00:06:52,480 --> 00:06:57,400
And tell me a little bit about what's the main idea there.

97
00:06:57,400 --> 00:06:58,400
Yeah, go ahead, Brady.

98
00:06:58,400 --> 00:07:04,320
Yeah, so adaptive driving beam, it's a vehicle lighting mechanism where it allows user to

99
00:07:04,320 --> 00:07:07,320
have high beam always on.

100
00:07:07,320 --> 00:07:08,320
Okay.

101
00:07:08,320 --> 00:07:13,760
But in order to do that, we don't want to blind the income in traffic or the traffic

102
00:07:13,760 --> 00:07:15,160
in front of you.

103
00:07:15,160 --> 00:07:27,000
So now that all the headlights and tail lights are based on LEDs, that allows us to turn

104
00:07:27,000 --> 00:07:32,320
on and off a section of our headlights.

105
00:07:32,320 --> 00:07:40,720
And in order to know which section to shut off, we have to first be able to detect the

106
00:07:40,720 --> 00:07:42,720
vehicle in front of us.

107
00:07:42,720 --> 00:07:43,720
Oh, interesting.

108
00:07:43,720 --> 00:07:46,320
And that's where AI technology comes in.

109
00:07:46,320 --> 00:07:53,280
What sensors do you assume or require on the vehicle in order to be able to do that?

110
00:07:53,280 --> 00:07:58,280
I'm imagining if we're talking about technology that's going to be available in the near-term,

111
00:07:58,280 --> 00:08:01,320
we're not expecting every car to have a light hour on it.

112
00:08:01,320 --> 00:08:02,320
Right.

113
00:08:02,320 --> 00:08:05,920
So for ADB purpose, we only need cameras.

114
00:08:05,920 --> 00:08:06,920
Okay.

115
00:08:06,920 --> 00:08:07,920
Yeah.

116
00:08:07,920 --> 00:08:08,920
All right, cool.

117
00:08:08,920 --> 00:08:10,920
And ADB, by the way, it's available today, right, Brady?

118
00:08:10,920 --> 00:08:14,480
This is a live product.

119
00:08:14,480 --> 00:08:15,440
It's on the road in Japan and...

120
00:08:15,440 --> 00:08:16,440
Yes, yes.

121
00:08:16,440 --> 00:08:20,560
It's been widely used in Japan, also in Europe.

122
00:08:20,560 --> 00:08:24,080
And it's come into North America in a very short period of time.

123
00:08:24,080 --> 00:08:25,080
Yeah.

124
00:08:25,080 --> 00:08:26,080
Okay.

125
00:08:26,080 --> 00:08:30,640
So what we've been doing, what we've been showing today, starting today at CES, is the

126
00:08:30,640 --> 00:08:32,360
next generation of ADB.

127
00:08:32,360 --> 00:08:33,360
Okay.

128
00:08:33,360 --> 00:08:39,200
The existing iteration is based more on traditional machine vision techniques.

129
00:08:39,200 --> 00:08:43,480
And which is great, it works pretty well.

130
00:08:43,480 --> 00:08:46,000
But it is prone to some false positives.

131
00:08:46,000 --> 00:08:57,040
And the idea here is to use AI to reduce the false positive rate so that you've got to

132
00:08:57,040 --> 00:09:02,560
be able to tell the difference between a headlight and a stoplight or a bright vending machine

133
00:09:02,560 --> 00:09:05,280
that's not a truck, that type of thing.

134
00:09:05,280 --> 00:09:10,400
So the idea is to refine the prediction and deliver a more accurate prediction.

135
00:09:10,400 --> 00:09:11,400
Okay.

136
00:09:11,400 --> 00:09:13,160
I'm using a machine learning.

137
00:09:13,160 --> 00:09:19,040
What is it about the traditional techniques that lends itself to the false positives?

138
00:09:19,040 --> 00:09:22,920
Well, you know, traditional machine vision techniques without getting into the specifics

139
00:09:22,920 --> 00:09:27,000
of what COETO's current product does because we can't really do that.

140
00:09:27,000 --> 00:09:32,080
But you know, these traditional machine vision like template matching, you know, they're

141
00:09:32,080 --> 00:09:38,840
very good in constrained environments where you don't have a great deal of variation in

142
00:09:38,840 --> 00:09:40,320
target and background.

143
00:09:40,320 --> 00:09:41,800
That's when they tend to perform best.

144
00:09:41,800 --> 00:09:42,800
Okay.

145
00:09:42,800 --> 00:09:43,800
Right.

146
00:09:43,800 --> 00:09:47,160
So pattern matching machine vision techniques are great, say, on an assembly line where

147
00:09:47,160 --> 00:09:49,560
you're doing quality control.

148
00:09:49,560 --> 00:09:56,120
But out in that dynamic real world where you have a lot more variation, both in your target

149
00:09:56,120 --> 00:10:00,080
and in the background against what you're trying to separate that target.

150
00:10:00,080 --> 00:10:04,520
Well, you know, you start to come up against the limitations of the technique.

151
00:10:04,520 --> 00:10:09,960
Now one of the main constraints here though is, you know, we're not talking about an autonomous

152
00:10:09,960 --> 00:10:11,720
vehicle necessarily.

153
00:10:11,720 --> 00:10:17,920
This is a product that's going to go on regular cars starting in, you know, they're available

154
00:10:17,920 --> 00:10:18,920
as I said.

155
00:10:18,920 --> 00:10:21,320
It was pretty, we're saying they're available in Japan and Europe today.

156
00:10:21,320 --> 00:10:22,320
Right.

157
00:10:22,320 --> 00:10:25,560
And in the United States in 2019 or 2020, something like that.

158
00:10:25,560 --> 00:10:26,560
Okay.

159
00:10:26,560 --> 00:10:29,360
So it's got to fit within a certain price point.

160
00:10:29,360 --> 00:10:30,360
Right.

161
00:10:30,360 --> 00:10:31,360
Right.

162
00:10:31,360 --> 00:10:32,360
Right.

163
00:10:32,360 --> 00:10:33,360
Right.

164
00:10:33,360 --> 00:10:35,240
You can't have an expensive processing brick just turning the high beams on them off.

165
00:10:35,240 --> 00:10:37,000
It doesn't work as a product.

166
00:10:37,000 --> 00:10:38,000
Right.

167
00:10:38,000 --> 00:10:45,000
So the challenging bit here is not just accomplishing the detection using machine learning and suppressing

168
00:10:45,000 --> 00:10:47,920
false positives where you need false positive suppress.

169
00:10:47,920 --> 00:10:55,920
The real challenge is doing that and then delivering that prediction in a form that can

170
00:10:55,920 --> 00:11:00,720
run on cheap hardware that meets the price point requirements of the product.

171
00:11:00,720 --> 00:11:05,400
And this is cheap hardware that is presumably mounted, you know, within the lens, within

172
00:11:05,400 --> 00:11:08,080
the light headlight assembly, right?

173
00:11:08,080 --> 00:11:09,080
Yeah.

174
00:11:09,080 --> 00:11:10,080
Inside the headlight assembly.

175
00:11:10,080 --> 00:11:11,080
That's exactly right.

176
00:11:11,080 --> 00:11:16,760
So it's got to, you know, and it's got to, you can't make the car too much more expensive.

177
00:11:16,760 --> 00:11:17,760
Right.

178
00:11:17,760 --> 00:11:21,400
You can make it only as more expensive as people perceive value in being able to turn their

179
00:11:21,400 --> 00:11:22,920
high beams on it off automatically.

180
00:11:22,920 --> 00:11:23,920
Yeah.

181
00:11:23,920 --> 00:11:24,920
Right.

182
00:11:24,920 --> 00:11:25,920
Right.

183
00:11:25,920 --> 00:11:33,480
He was saying we're actually tracking vehicles leaving the high beams always on and tracking

184
00:11:33,480 --> 00:11:39,200
that vehicle that's in front of you or that's on coming as it moves across the field

185
00:11:39,200 --> 00:11:43,360
division so that he's selectively blocked out.

186
00:11:43,360 --> 00:11:47,560
But you can still see animals, pedestrians or other things that are peripheral to that

187
00:11:47,560 --> 00:11:48,560
car.

188
00:11:48,560 --> 00:11:50,080
Yes.

189
00:11:50,080 --> 00:11:54,200
So this is resonating really strongly with me because I, you know, while I'm, you know,

190
00:11:54,200 --> 00:11:58,680
normally live in a city environment over the holidays, I was in a more rural environment

191
00:11:58,680 --> 00:12:01,960
and made frequent use of the high beams.

192
00:12:01,960 --> 00:12:02,960
Yeah.

193
00:12:02,960 --> 00:12:06,720
And when you depend on the high beams and then you turn them off because there's an

194
00:12:06,720 --> 00:12:07,720
upcoming traffic light.

195
00:12:07,720 --> 00:12:08,720
It's like, where am I?

196
00:12:08,720 --> 00:12:10,080
It's like it's totally dark.

197
00:12:10,080 --> 00:12:15,640
And so I can relate to, you know, wanting to just, you know, a, you know, as cars get more

198
00:12:15,640 --> 00:12:19,600
complex, they're going to have more knobs and stuff and, you know, one less thing to worry

199
00:12:19,600 --> 00:12:20,800
about would be great.

200
00:12:20,800 --> 00:12:26,880
But, you know, there's, you know, if you can have, you can offer me, you know, visibility

201
00:12:26,880 --> 00:12:35,360
into kind of my field of view, even while oncoming cars are approaching, that sounds like a great

202
00:12:35,360 --> 00:12:38,480
proposition and one that will increase safety.

203
00:12:38,480 --> 00:12:41,800
You know, tell me a little bit about some of the technology that goes into making this

204
00:12:41,800 --> 00:12:42,800
happen.

205
00:12:42,800 --> 00:12:43,800
Yeah.

206
00:12:43,800 --> 00:12:44,800
Sure.

207
00:12:44,800 --> 00:12:47,800
So the, you know, on the sensing side, which is our contribution, right?

208
00:12:47,800 --> 00:12:51,120
Coeto, North American lighting, they're the headlight experts.

209
00:12:51,120 --> 00:12:57,280
And in terms of controlling the beam and shaping the beam and figuring out exactly how to adapt

210
00:12:57,280 --> 00:13:01,480
the beam to the driving patterns, that's their area of expertise for sure.

211
00:13:01,480 --> 00:13:08,920
Our area of expertise is sensing the car in front, so that in delivering that location

212
00:13:08,920 --> 00:13:14,760
of the car to their control mechanism so that it can appropriately adapt.

213
00:13:14,760 --> 00:13:18,280
So it knows where the car is, it can do the calculations, it needs to do to figure out

214
00:13:18,280 --> 00:13:19,840
what to do with those LEDs.

215
00:13:19,840 --> 00:13:24,080
So you give them like a vector of angles and distances, for example?

216
00:13:24,080 --> 00:13:28,440
Yeah, basically, you know, we're delivered, it's very similar to what you would see in

217
00:13:28,440 --> 00:13:33,120
an ADAS system, the sort of collision avoidance system for autonomous vehicles.

218
00:13:33,120 --> 00:13:36,560
Where, you know, you see bounding boxes on cars and pedestrians, that kind of thing.

219
00:13:36,560 --> 00:13:37,920
It's a very similar sort of output.

220
00:13:37,920 --> 00:13:38,920
Okay.

221
00:13:38,920 --> 00:13:44,720
So that's what, that's our contribution to this is the sensing piece.

222
00:13:44,720 --> 00:13:49,800
And I think, you know, I mentioned in the introduction, reality AI, our approach to machine

223
00:13:49,800 --> 00:13:51,840
learning is a little different, right?

224
00:13:51,840 --> 00:13:54,160
We're not using deep learning.

225
00:13:54,160 --> 00:13:59,280
Deep learning, unfortunately, would probably require more compute power than we can afford

226
00:13:59,280 --> 00:14:03,640
on that, you know, on that control unit.

227
00:14:03,640 --> 00:14:05,400
Even on the inference side alone?

228
00:14:05,400 --> 00:14:06,400
Yeah.

229
00:14:06,400 --> 00:14:07,400
Yeah.

230
00:14:07,400 --> 00:14:14,680
So our approach in general to machine learning is we spend a lot of energy on

231
00:14:14,680 --> 00:14:18,440
the feature engineering.

232
00:14:18,440 --> 00:14:24,200
And we take a signal processing based approach.

233
00:14:24,200 --> 00:14:30,120
And we have a process that will, you know, looks through to 300 different feature types

234
00:14:30,120 --> 00:14:34,160
and compute each of them, test them and predicts which one's going to be best for any given

235
00:14:34,160 --> 00:14:35,160
situation.

236
00:14:35,160 --> 00:14:41,360
And what are the sensors that you have available on assuming you don't have access to vehicle

237
00:14:41,360 --> 00:14:42,360
sensors?

238
00:14:42,360 --> 00:14:46,720
The sensor is in the headlight assembly and this is maybe a camera or there are other

239
00:14:46,720 --> 00:14:47,720
sensors.

240
00:14:47,720 --> 00:14:48,720
Well, in this case, we're working with a camera.

241
00:14:48,720 --> 00:14:49,720
Okay.

242
00:14:49,720 --> 00:14:52,440
I mean, it's certainly conceivable that in the future, other sensors might be in play.

243
00:14:52,440 --> 00:14:53,440
Okay.

244
00:14:53,440 --> 00:14:55,080
But at the moment, it's purely camera based.

245
00:14:55,080 --> 00:14:56,080
Okay.

246
00:14:56,080 --> 00:14:59,880
And our technology is not camera specific.

247
00:14:59,880 --> 00:15:03,920
I would, you know, if I'm going to be candid, I would actually say image based things is

248
00:15:03,920 --> 00:15:11,320
probably our weakest, our weakest area in image based things where we tend to be strongest

249
00:15:11,320 --> 00:15:17,200
is in problems that could be reduced to a question of texture.

250
00:15:17,200 --> 00:15:22,680
So if you're doing object recognition, right, you want to know, that thing over there

251
00:15:22,680 --> 00:15:28,960
is that a pedestrian or a person on a bicycle, right, that's a good deep learning problem,

252
00:15:28,960 --> 00:15:31,200
object recognition, deep learning is good at that.

253
00:15:31,200 --> 00:15:32,200
Yeah.

254
00:15:32,200 --> 00:15:34,400
And it requires compute, but it can do it.

255
00:15:34,400 --> 00:15:38,240
Our stuff tends to work much better on texture based problems.

256
00:15:38,240 --> 00:15:39,240
Okay.

257
00:15:39,240 --> 00:15:44,800
In fact, that's the way in which we approach this with the headlight detection and the

258
00:15:44,800 --> 00:15:52,080
false positive suppression, is looking at spatial relationships between pixels of different

259
00:15:52,080 --> 00:15:54,480
colors inside of a decision window.

260
00:15:54,480 --> 00:15:55,480
Okay.

261
00:15:55,480 --> 00:15:56,480
Right.

262
00:15:56,480 --> 00:15:58,120
It's just a different way of going about it.

263
00:15:58,120 --> 00:16:02,440
Now the fact is our stuff is much more widely used, I mean, we do, we do some things with

264
00:16:02,440 --> 00:16:09,120
images that are texture based, but sound, vibration, accelerometry, electrical signals.

265
00:16:09,120 --> 00:16:14,120
Those are really a sweeter spot for us most of the time.

266
00:16:14,120 --> 00:16:19,360
And we are getting ready to launch a couple of things with coeto that will involve other

267
00:16:19,360 --> 00:16:24,440
types of sensors beyond cameras as well, different kind of product, different kind of use.

268
00:16:24,440 --> 00:16:31,400
And when you say your stuff, what are we talking about here, is it, you know, some hardware

269
00:16:31,400 --> 00:16:36,160
that goes in the headlight assembly, is it some algorithms, is it IP, is it services?

270
00:16:36,160 --> 00:16:37,160
Sure.

271
00:16:37,160 --> 00:16:39,640
But the headlight is coeto's product.

272
00:16:39,640 --> 00:16:40,640
Yep.

273
00:16:40,640 --> 00:16:47,720
What reality AI offers is a tool for the R&D engineer to create that product.

274
00:16:47,720 --> 00:16:48,720
Okay.

275
00:16:48,720 --> 00:16:54,720
So by our stuff, what I mean is the algorithms and the application that allows an engineer

276
00:16:54,720 --> 00:17:02,080
to use those algorithms to expose the algorithms to data and generate detection code, which can

277
00:17:02,080 --> 00:17:10,600
then be either hung in the cloud, if it's a cloud-based application or pulled out of that

278
00:17:10,600 --> 00:17:17,640
cloud-based environment, pulled into the IDE for an embedded environment, and then run

279
00:17:17,640 --> 00:17:24,280
in the embedded target, which is, oh, we have plans to use this.

280
00:17:24,280 --> 00:17:25,280
Right.

281
00:17:25,280 --> 00:17:26,280
Right.

282
00:17:26,280 --> 00:17:30,000
Maybe tell me a little bit about the, what can you tell me about kind of the experience

283
00:17:30,000 --> 00:17:35,680
of your engineers working with this technology, do you?

284
00:17:35,680 --> 00:17:41,760
I'm imagining that your engineers don't typically have machine learning and AI expertise, or am

285
00:17:41,760 --> 00:17:43,760
I wrong about that?

286
00:17:43,760 --> 00:17:44,760
Right.

287
00:17:44,760 --> 00:17:52,600
So as a lighting company, most of our effort is optics and mechanical and how to control

288
00:17:52,600 --> 00:17:54,520
the heat in the headlight.

289
00:17:54,520 --> 00:18:04,920
So we're not experienced in putting sensors or more computing embedded system into our

290
00:18:04,920 --> 00:18:05,920
headlamps.

291
00:18:05,920 --> 00:18:12,080
So we're quite excited to be able to work with reality AI and try to find possibility

292
00:18:12,080 --> 00:18:21,200
to put sensors into headlamps and try to make it a smarter headlights and rear lights.

293
00:18:21,200 --> 00:18:26,200
And so the platform, do you refer to it as a platform, or a toolkit, or?

294
00:18:26,200 --> 00:18:29,280
Yeah, we call it a toolkit or an application, even.

295
00:18:29,280 --> 00:18:32,160
This is kind of like an SDK that's got some built-in.

296
00:18:32,160 --> 00:18:38,240
Like how is the, think of it as a code generation application, right?

297
00:18:38,240 --> 00:18:42,720
So there's, this is a podcast, so I can't pull up a demonstration here, right?

298
00:18:42,720 --> 00:18:48,880
But think of this as a tool set where you can provide examples of what you're looking

299
00:18:48,880 --> 00:18:55,640
for in the case of what we're doing with Coeto, what those are, you know, here are images

300
00:18:55,640 --> 00:19:02,200
where this is, this over here is a, the, the tail light of a car that we're following

301
00:19:02,200 --> 00:19:06,760
and we want to block out, we don't want to, we don't want to blind over, right next to

302
00:19:06,760 --> 00:19:10,360
it over there, that's a, that's a reflection of, of a stop sign.

303
00:19:10,360 --> 00:19:14,200
So that's a counter example, right, don't count that as a headlight.

304
00:19:14,200 --> 00:19:18,480
That red light off in the distance, that's a stop light, don't count that either, right?

305
00:19:18,480 --> 00:19:19,480
So that, that's our input.

306
00:19:19,480 --> 00:19:27,560
We have snippets of images taken by the camera and with some labels on them, the tell us, tell

307
00:19:27,560 --> 00:19:29,040
us what they are.

308
00:19:29,040 --> 00:19:37,200
In our application, we can load it with these examples and run first a process we call AI

309
00:19:37,200 --> 00:19:42,120
Explorer, what AI, and AI Explorer does the feature engineering.

310
00:19:42,120 --> 00:19:47,520
It's a machine learning driven process, sort of, you could almost think of it as an expert

311
00:19:47,520 --> 00:19:53,680
system, but it isn't really, but it, what it will do is go through and try to identify

312
00:19:53,680 --> 00:20:01,280
an optimized feature set, which can then be exposed to a machine learning algorithm,

313
00:20:01,280 --> 00:20:06,320
which is, you know, could be an SVM, could be a neural network.

314
00:20:06,320 --> 00:20:12,320
We pick, we can pick, we can pick that based on what's the most appropriate form of

315
00:20:12,320 --> 00:20:17,760
output forward with the customer, what we will need for their technical requirements for

316
00:20:17,760 --> 00:20:18,960
the product.

317
00:20:18,960 --> 00:20:23,720
But you know, I mean, your audience is all about machine learning and AI, so I'm sure

318
00:20:23,720 --> 00:20:28,120
you're, you know, you and they know that when you have the right feature set, your choice

319
00:20:28,120 --> 00:20:30,560
of algorithm becomes much less important.

320
00:20:30,560 --> 00:20:37,000
And if you have good, really solid features that separate, that give you a good separation

321
00:20:37,000 --> 00:20:41,040
between classes, well, heck, almost any algorithm will find what you're looking for,

322
00:20:41,040 --> 00:20:42,040
right?

323
00:20:42,040 --> 00:20:47,360
So, you know, that's really what the point of our application is, is to do that feature

324
00:20:47,360 --> 00:20:57,520
engineering and identify the most optimized features possible, such that we can then use

325
00:20:57,520 --> 00:21:04,120
the latest touch machine learning possible, and therefore delivered prediction code that

326
00:21:04,120 --> 00:21:08,040
is as compact and computationally efficient as possible.

327
00:21:08,040 --> 00:21:14,920
So what extent do the features that, that this tool spits out, you know, that, do they

328
00:21:14,920 --> 00:21:20,880
tend to be kind of intuitive features versus, you know, kind of artificial features, kind

329
00:21:20,880 --> 00:21:26,960
of mathematical combinations of the inputs that don't really have any intuitive interpretation?

330
00:21:26,960 --> 00:21:28,120
Most of the time it's the latter.

331
00:21:28,120 --> 00:21:29,120
The latter?

332
00:21:29,120 --> 00:21:30,120
Yeah.

333
00:21:30,120 --> 00:21:31,120
Okay.

334
00:21:31,120 --> 00:21:33,360
So, you know, look, by the time someone gets to us, if it's a sound problem, for example,

335
00:21:33,360 --> 00:21:39,120
a vibration problem, by the time a customer gets to us, their engineers have already tried

336
00:21:39,120 --> 00:21:43,600
an FFT, put that into a neural net to see what would happen, right?

337
00:21:43,600 --> 00:21:47,120
So, you know, if it was a problem, was that easy to solve, they wouldn't be calling us

338
00:21:47,120 --> 00:21:48,880
in the first place.

339
00:21:48,880 --> 00:21:53,480
So, you know, look, our algorithm will check an FFT just to be, you know, a couple of

340
00:21:53,480 --> 00:21:56,800
different flavors and a couple of different varieties to it, just to make, just for

341
00:21:56,800 --> 00:21:58,480
completeness sake.

342
00:21:58,480 --> 00:22:02,920
But generally speaking, we're going to need to carve, we're going to need to carve up that

343
00:22:02,920 --> 00:22:05,000
feature space in a very different way.

344
00:22:05,000 --> 00:22:06,600
And how do you, how do you do that?

345
00:22:06,600 --> 00:22:10,600
Well, you know, we use, we use mathematics, you'd find in the literature under sparse

346
00:22:10,600 --> 00:22:13,800
coding, compressive sensing, that type of thing.

347
00:22:13,800 --> 00:22:15,960
And what, what is, what are those things?

348
00:22:15,960 --> 00:22:16,960
What's sparse coding?

349
00:22:16,960 --> 00:22:17,960
What's compressive sensing?

350
00:22:17,960 --> 00:22:22,320
Well, you know, you, I guess what, what we're doing is you could think of us as carving

351
00:22:22,320 --> 00:22:31,080
up time, frequency in a much more complex way than an FFT, which is just using bands.

352
00:22:31,080 --> 00:22:38,960
And so it can be very responsive to things like transients and phase and, you know, those

353
00:22:38,960 --> 00:22:40,200
kinds of phenomenon.

354
00:22:40,200 --> 00:22:44,880
Now, in the image kinds of problems like, like we're dealing with here with ADB, that stuff

355
00:22:44,880 --> 00:22:46,400
isn't relevant.

356
00:22:46,400 --> 00:22:53,200
But it turns out when we use these same mathematics on images, what that basically translates to

357
00:22:53,200 --> 00:22:56,760
is a texture kind of relationship.

358
00:22:56,760 --> 00:23:01,480
And we, we tend to be good at finding textures and discontinuities and textures.

359
00:23:01,480 --> 00:23:06,120
But that's sort of a side, it's, it's a side usage, which turns out to be very useful

360
00:23:06,120 --> 00:23:08,880
in certain cases like with ADB.

361
00:23:08,880 --> 00:23:19,880
But our primary focus is more in the vibration, electrical signal, sound, light are even.

362
00:23:19,880 --> 00:23:26,880
And so in the past, when I've talked to folks who have, are taking similar approaches to

363
00:23:26,880 --> 00:23:33,880
kind of automating feature engineering, there's, you know, there's often a lot of like Monte

364
00:23:33,880 --> 00:23:36,360
Carlo type simulations and that kind of thing.

365
00:23:36,360 --> 00:23:37,760
Do you do that kind of stuff as well?

366
00:23:37,760 --> 00:23:38,760
Yeah, not so much.

367
00:23:38,760 --> 00:23:43,160
I mean, we'll basically judge which one, which feature set is the best on the basis.

368
00:23:43,160 --> 00:23:47,840
I will take, well, basically with, with want with feature sets that look promising according

369
00:23:47,840 --> 00:23:49,600
to their to our algorithm.

370
00:23:49,600 --> 00:23:54,160
We train a quick machine learning model on a subset of the, on a subset of the training

371
00:23:54,160 --> 00:23:59,240
data, do a quick k-fold analysis and we rank them on the basis of their performance under

372
00:23:59,240 --> 00:24:00,240
that k-fold.

373
00:24:00,240 --> 00:24:04,280
So it's a pretty straightforward accuracy based ranking.

374
00:24:04,280 --> 00:24:09,680
The other thing we do is we do generate a relative measure of the complexity of the

375
00:24:09,680 --> 00:24:11,840
feature computation.

376
00:24:11,840 --> 00:24:18,080
Because again, our customers are, by and large, coming to us because they intend to deploy

377
00:24:18,080 --> 00:24:24,160
to an embedded target where compute is going to be a limited resource, either cycles or

378
00:24:24,160 --> 00:24:25,960
memory.

379
00:24:25,960 --> 00:24:31,680
And so we'll give them a relative ranking of, you know, if it's green and the bar is

380
00:24:31,680 --> 00:24:37,600
hardly filled in, well, you can probably fit it on a cortex M3, M4, right?

381
00:24:37,600 --> 00:24:41,880
But if it's, if it's almost, the bar is almost filled up and it's turned red, well, you're

382
00:24:41,880 --> 00:24:45,160
probably going to need server grade hardware to execute that particular model.

383
00:24:45,160 --> 00:24:47,360
And we basically make that an engineering choice.

384
00:24:47,360 --> 00:24:56,800
Now the engineer who's using this stuff can trade off computational complexity for accuracy

385
00:24:56,800 --> 00:24:58,320
in some cases.

386
00:24:58,320 --> 00:25:04,920
I think something trying to wrap my head around like the, so we get the problem.

387
00:25:04,920 --> 00:25:10,920
The problem is you've got limited computational capacity and a lot of these environments.

388
00:25:10,920 --> 00:25:17,320
And as exciting as deep learning is, it requires a significant compute capability, even

389
00:25:17,320 --> 00:25:20,640
for the inference.

390
00:25:20,640 --> 00:25:24,240
But deep learning is exciting because you don't have to do feature engineering.

391
00:25:24,240 --> 00:25:25,240
Right.

392
00:25:25,240 --> 00:25:26,240
You want to go the other way.

393
00:25:26,240 --> 00:25:30,040
You got to do some feature engineering, which is difficult manually.

394
00:25:30,040 --> 00:25:32,040
You guys automate it.

395
00:25:32,040 --> 00:25:36,240
I'm trying to wrap my head around kind of the next level of detail, which is like if I

396
00:25:36,240 --> 00:25:42,880
wanted to, you know, if I wanted to build something like this, like, you know, what are the things

397
00:25:42,880 --> 00:25:47,880
that I should be thinking of as a, you know, data scientist or engineer, you know, if

398
00:25:47,880 --> 00:25:52,800
I wanted to, you know, if I needed to build my own kind of automated feature engineering

399
00:25:52,800 --> 00:25:57,520
pipeline, like understanding that there's proprietary IP and, yeah, yeah, yeah, yeah, sure,

400
00:25:57,520 --> 00:25:58,520
and all that.

401
00:25:58,520 --> 00:26:00,280
Like, what are the, the things that I should be thinking about?

402
00:26:00,280 --> 00:26:01,280
Okay.

403
00:26:01,280 --> 00:26:07,600
Well, so the first case and the first thing I would say is that, you know, features are domain

404
00:26:07,600 --> 00:26:09,200
specific isn't quite the right word.

405
00:26:09,200 --> 00:26:10,400
That's not what I'm going for.

406
00:26:10,400 --> 00:26:13,760
But the, the, the, the, the differences of them or something like that.

407
00:26:13,760 --> 00:26:14,760
Yeah.

408
00:26:14,760 --> 00:26:18,920
So, you know, our approach, the kinds of features where you, we're going to try from

409
00:26:18,920 --> 00:26:23,400
suit to nuts are going to be the kinds of features that are relevant when you're talking

410
00:26:23,400 --> 00:26:28,280
about an, an input you could think of as a wave form in some way.

411
00:26:28,280 --> 00:26:29,280
Yep.

412
00:26:29,280 --> 00:26:30,280
Right.

413
00:26:30,280 --> 00:26:35,600
And those kinds of features are going to be completely different than the kinds of features

414
00:26:35,600 --> 00:26:41,800
you would use if, you know, you're looking at business records of some sort, right?

415
00:26:41,800 --> 00:26:42,800
Obviously.

416
00:26:42,800 --> 00:26:47,960
But even with sound, the kinds of features we're looking at are not going to be the same

417
00:26:47,960 --> 00:26:52,360
kinds of features you're going to want to use if you're building a competitor to Amazon

418
00:26:52,360 --> 00:26:58,400
Echo or Siri or OK Google, right, where the problem is natural language recognition.

419
00:26:58,400 --> 00:27:03,040
Our stuff isn't actually the kinds of features we employ aren't actually very good at language

420
00:27:03,040 --> 00:27:04,680
recognition at all.

421
00:27:04,680 --> 00:27:07,000
But it's really good at machine hums.

422
00:27:07,000 --> 00:27:08,000
Ah, OK.

423
00:27:08,000 --> 00:27:09,000
OK.

424
00:27:09,000 --> 00:27:15,440
So, you're doing, you probably have like, you're kind of doing different types of FFTs,

425
00:27:15,440 --> 00:27:17,920
different types of windows, different kind of release.

426
00:27:17,920 --> 00:27:18,920
Yeah.

427
00:27:18,920 --> 00:27:21,640
We don't, we, we check FFTs for completeness, right, right, we're more likely to be using

428
00:27:21,640 --> 00:27:25,400
sparse coding, compressive sensing and other kinds of more complex features sets.

429
00:27:25,400 --> 00:27:26,400
Got it.

430
00:27:26,400 --> 00:27:27,400
OK.

431
00:27:27,400 --> 00:27:28,400
I think that's good.

432
00:27:28,400 --> 00:27:33,880
So, you've got, so there's some set of algorithms that are particularly good at identifying,

433
00:27:33,880 --> 00:27:38,000
you know, either frequency components or something like that, you know, in this type of

434
00:27:38,000 --> 00:27:39,000
signal.

435
00:27:39,000 --> 00:27:40,000
Transient phase frequency.

436
00:27:40,000 --> 00:27:41,000
Yeah.

437
00:27:41,000 --> 00:27:42,000
OK.

438
00:27:42,000 --> 00:27:43,000
OK.

439
00:27:43,000 --> 00:27:46,440
And so you, you're just kind of sweeping across those with different parameters and, you

440
00:27:46,440 --> 00:27:49,840
know, maybe there's some kind of grid searching or something like that that you're doing

441
00:27:49,840 --> 00:27:53,280
or randomized searching or something like that or something like that in there.

442
00:27:53,280 --> 00:27:54,280
Yeah.

443
00:27:54,280 --> 00:27:59,120
Something that, you know, it's guided, but there's still a fair amount of, we're going to

444
00:27:59,120 --> 00:28:00,320
try a spectrum of things.

445
00:28:00,320 --> 00:28:01,320
Yeah.

446
00:28:01,320 --> 00:28:05,640
And, you know, we try a spectrum of things and we find a family of features that's promising

447
00:28:05,640 --> 00:28:11,560
the algorithm will dive in and do more exploration within that promising family, right?

448
00:28:11,560 --> 00:28:13,640
But yeah, you kind of have the idea.

449
00:28:13,640 --> 00:28:18,240
And what's the, by what's the origin of the kind of the company and the product?

450
00:28:18,240 --> 00:28:19,240
Yeah.

451
00:28:19,240 --> 00:28:20,240
Yeah.

452
00:28:20,240 --> 00:28:21,240
Great question.

453
00:28:21,240 --> 00:28:23,920
So, you know, where this stuff really came from is really the other co-founder, truthfully.

454
00:28:23,920 --> 00:28:24,920
OK.

455
00:28:24,920 --> 00:28:26,320
So I'm the, I'm the business guy.

456
00:28:26,320 --> 00:28:27,920
My background's Wall Street.

457
00:28:27,920 --> 00:28:32,040
I've spent just enough time in, you know, math and physics and that type of thing to be

458
00:28:32,040 --> 00:28:34,080
able to follow along.

459
00:28:34,080 --> 00:28:39,640
But the real genesis of this came from our other co-founder, Jeff Strackey, and Jeff's

460
00:28:39,640 --> 00:28:40,640
our CTO.

461
00:28:40,640 --> 00:28:41,640
OK.

462
00:28:41,640 --> 00:28:44,440
Turns out he's been my best friend since we were 13 years old.

463
00:28:44,440 --> 00:28:45,440
Oh, wow.

464
00:28:45,440 --> 00:28:46,440
Yeah.

465
00:28:46,440 --> 00:28:55,000
But for the last, I guess, 10, 12 years or so before we started Reality AI, Jeff was

466
00:28:55,000 --> 00:29:03,520
doing contract R&D for US federal government customers in military and intelligence community.

467
00:29:03,520 --> 00:29:09,960
So, you know, always in this area of applying this new field of machine learning to complex

468
00:29:09,960 --> 00:29:17,120
signal processing, signal recognition problems, surveillance, target acquisition, that kind

469
00:29:17,120 --> 00:29:18,920
of thing.

470
00:29:18,920 --> 00:29:24,960
And you know, during that developed a fairly comprehensive body of IP, we have 10

471
00:29:24,960 --> 00:29:29,400
patents awarded, six patents pending, most of which come from that period.

472
00:29:29,400 --> 00:29:30,400
OK.

473
00:29:30,400 --> 00:29:34,120
And but that's really where the expertise for this came from.

474
00:29:34,120 --> 00:29:40,040
And a couple of years ago when we decided to create Reality AI, we took all of that

475
00:29:40,040 --> 00:29:46,080
IP out of the contracting entity used for the, those federal government customers.

476
00:29:46,080 --> 00:29:49,720
Everything that wasn't classified wasn't subject to export control because we don't want

477
00:29:49,720 --> 00:29:50,720
that headache.

478
00:29:50,720 --> 00:29:56,520
But anything that could be freely used commercially, we moved that intellectual property into a new

479
00:29:56,520 --> 00:29:57,520
company.

480
00:29:57,520 --> 00:30:01,120
We sunsetted the old thing that had been used for the defense contracting.

481
00:30:01,120 --> 00:30:09,880
And we created Reality Analytics Inc reality AI to apply this technology commercially.

482
00:30:09,880 --> 00:30:17,400
We turned that into an application usable by an R&D engineer version 1.0 of that came

483
00:30:17,400 --> 00:30:19,400
out in June of 2016.

484
00:30:19,400 --> 00:30:20,400
OK.

485
00:30:20,400 --> 00:30:23,640
2.0 is coming out in just a couple of weeks.

486
00:30:23,640 --> 00:30:24,640
OK.

487
00:30:24,640 --> 00:30:25,640
Nice.

488
00:30:25,640 --> 00:30:26,640
Yeah.

489
00:30:26,640 --> 00:30:33,880
And we've been, you know, adding customers and automotive, probably our number one area

490
00:30:33,880 --> 00:30:37,000
right now, followed very closely by industrial.

491
00:30:37,000 --> 00:30:41,240
And we also have a couple of consumer product customers that are doing interesting things.

492
00:30:41,240 --> 00:30:48,720
And so for industrial, this might be an industrial machinery supplier who wants to be able to

493
00:30:48,720 --> 00:30:50,640
do predictive maintenance.

494
00:30:50,640 --> 00:30:57,520
You just drop in the algorithms and at home is home in kind of those kind of, you know,

495
00:30:57,520 --> 00:31:02,360
frequency based vibration vibration and occasionally sound.

496
00:31:02,360 --> 00:31:03,360
Yeah.

497
00:31:03,360 --> 00:31:06,360
And even some of the automotive customers, by the way, are doing that same kind of thing

498
00:31:06,360 --> 00:31:08,680
but on the vehicle.

499
00:31:08,680 --> 00:31:13,440
But the industrial customers are always, you know, one former and other of, you know,

500
00:31:13,440 --> 00:31:16,200
figuring out when the wing of a jigger needs to think of a barber place.

501
00:31:16,200 --> 00:31:17,200
Right.

502
00:31:17,200 --> 00:31:18,200
Right.

503
00:31:18,200 --> 00:31:22,560
I'm trying to make it, you know, it's come up called the machine whisperer.

504
00:31:22,560 --> 00:31:26,400
There's always like the machine whisperer that knows when it sounds like this, you need

505
00:31:26,400 --> 00:31:29,160
to whack it here with a hammer four times or whatever.

506
00:31:29,160 --> 00:31:30,160
You got it.

507
00:31:30,160 --> 00:31:31,160
You got it.

508
00:31:31,160 --> 00:31:34,400
So, you know, our approach commercially there is that we are generally working with the

509
00:31:34,400 --> 00:31:35,400
equipment makers.

510
00:31:35,400 --> 00:31:36,400
OK.

511
00:31:36,400 --> 00:31:40,400
So that, you know, much like Kuido is trying to, who's building the smarts into the headlight,

512
00:31:40,400 --> 00:31:44,320
we're working with the, you know, industrial equipment makers, the pump makers would have

513
00:31:44,320 --> 00:31:49,400
you to build the smarts into their equipment, as opposed to some kind of aftermarket

514
00:31:49,400 --> 00:31:50,400
add-on.

515
00:31:50,400 --> 00:31:51,400
It's interesting.

516
00:31:51,400 --> 00:31:58,920
I've asked several of the folks that I've talked to today, you know, what kind of things

517
00:31:58,920 --> 00:32:06,120
have they learned trying to introduce artificial intelligence to consumer products?

518
00:32:06,120 --> 00:32:12,800
And, you know, universally, the answer has to do with the user experience and, you know,

519
00:32:12,800 --> 00:32:16,960
from the perspective of the consumer, like, they don't really care about AI.

520
00:32:16,960 --> 00:32:21,840
And like, this is like, at the far end of that spectrum, nobody, no one who's driving

521
00:32:21,840 --> 00:32:26,000
a car is even going to, even if they know that, you know, hey, I don't have to turn

522
00:32:26,000 --> 00:32:29,880
on my headlights, I think my high beams anymore, you know, this is something that you just

523
00:32:29,880 --> 00:32:32,840
want to be invisible to them and just work.

524
00:32:32,840 --> 00:32:40,200
That being said, have you, as a company kind of learned anything about applying AI in

525
00:32:40,200 --> 00:32:43,600
these kind of situations?

526
00:32:43,600 --> 00:32:45,760
Well, it's still early days.

527
00:32:45,760 --> 00:32:46,760
Yeah.

528
00:32:46,760 --> 00:32:47,760
Yeah.

529
00:32:47,760 --> 00:32:53,080
So, we're actually looking into possibility of embedding more sensors into headlights from

530
00:32:53,080 --> 00:32:57,240
those driving as well, like, such as light hour and radars.

531
00:32:57,240 --> 00:33:03,960
And after we, they, right now, the full factor of light are just too big to put into the

532
00:33:03,960 --> 00:33:04,960
lightings.

533
00:33:04,960 --> 00:33:09,680
But we're waiting for that size to shrink into a reasonable size so that we can put

534
00:33:09,680 --> 00:33:10,680
into the headlights.

535
00:33:10,680 --> 00:33:19,000
And is the idea there that, you know, just that Quido would be, would become a sensor

536
00:33:19,000 --> 00:33:27,080
provider to the OEM in addition to a lighting provider or is it somehow tied to lighting

537
00:33:27,080 --> 00:33:30,240
in the delivery of lighting?

538
00:33:30,240 --> 00:33:36,920
That, I can't disclose that part yet, but we are looking into that kind of a possibility

539
00:33:36,920 --> 00:33:45,160
and also a possibility of doing some kind of an edge computing in headlights for autonomous

540
00:33:45,160 --> 00:33:46,160
driving.

541
00:33:46,160 --> 00:33:47,160
Interesting.

542
00:33:47,160 --> 00:33:52,400
You know, the cool thing about what Quido is doing here, right, is that because they're

543
00:33:52,400 --> 00:33:57,760
providing the headlights, the tail lights, the turn signals, right, that's their market,

544
00:33:57,760 --> 00:34:01,680
they own strategic real estate on the car.

545
00:34:01,680 --> 00:34:09,360
They have, they have the, the placement on all of the corners, right, and if you want

546
00:34:09,360 --> 00:34:14,960
to place sensors to get them the best possible field of view around the vehicle, where you

547
00:34:14,960 --> 00:34:19,880
got to put them, right, plus these guys have, I mean, I've had, since I've been standing

548
00:34:19,880 --> 00:34:23,560
next to them all day at CES and the booth, I've had a chance to hear them, hear them

549
00:34:23,560 --> 00:34:30,400
pitch and, you know, putting, being able to put these sensors in a form factor where it

550
00:34:30,400 --> 00:34:38,480
can stand up to a car wash and weather, you know, these guys are expert in creating electronics

551
00:34:38,480 --> 00:34:44,480
that are protected from the elements and still can be, you know, can still see through.

552
00:34:44,480 --> 00:34:50,880
So you know, that's actually, it turns out that as you sensor up a car, the real estate

553
00:34:50,880 --> 00:34:57,360
that their stuff owns and their ability to deliver it in a form factor that fits with

554
00:34:57,360 --> 00:35:03,120
a car's design that is protected from the elements that could stand up to a power washing

555
00:35:03,120 --> 00:35:08,880
or whatever Mother Nature is going to throw at it, that's actually very, very important.

556
00:35:08,880 --> 00:35:13,400
And something that, you know, the automotive industry looks to be only just beginning to

557
00:35:13,400 --> 00:35:18,200
grapple with as they start to think about the reality of making cars that are instrumented

558
00:35:18,200 --> 00:35:19,200
in this way.

559
00:35:19,200 --> 00:35:20,200
Right, right.

560
00:35:20,200 --> 00:35:26,560
Yeah, I can imagine the modularity being, you know, a lighting assembly is pretty plug

561
00:35:26,560 --> 00:35:33,960
and play relative to, you know, changing out something that's kind of built into the

562
00:35:33,960 --> 00:35:36,800
frame of the car or the sheet metal or something like that.

563
00:35:36,800 --> 00:35:41,920
It seems like a, I can see how it would be a strategic place to be.

564
00:35:41,920 --> 00:35:46,920
Is this something that you envision becoming available like as an aftermarket type of thing

565
00:35:46,920 --> 00:35:54,040
or is it, you know, primarily you're going to market through the OEMs, the manufacturers?

566
00:35:54,040 --> 00:35:56,760
Oh, you mean ADV?

567
00:35:56,760 --> 00:36:03,040
So I think right now in North America, we're just waiting for the regulation to go through.

568
00:36:03,040 --> 00:36:12,800
I think sometime in 2018 or 2019, the regulation will go through and we can see vehicles on

569
00:36:12,800 --> 00:36:16,800
the street with ADV within two years.

570
00:36:16,800 --> 00:36:21,480
And what's the nature of the regulation that is over this?

571
00:36:21,480 --> 00:36:26,080
Like the transportation from the FTC, they have to approve everything.

572
00:36:26,080 --> 00:36:30,600
Say that the ID, right, for, yeah, okay.

573
00:36:30,600 --> 00:36:34,920
And apparently they have this kind of regulation in Japan already.

574
00:36:34,920 --> 00:36:42,320
So that's why they, if you see vehicle in Japan, they already have ADV embedded in, this

575
00:36:42,320 --> 00:36:43,320
is already on the street.

576
00:36:43,320 --> 00:36:44,320
Oh, wow.

577
00:36:44,320 --> 00:36:45,320
Yeah, wow.

578
00:36:45,320 --> 00:36:48,720
The first versions of ADV are on the street in Japan and Europe today.

579
00:36:48,720 --> 00:36:49,720
Huh.

580
00:36:49,720 --> 00:36:54,880
Yeah, it's interesting how much of this stuff, you know, there's a lot of the stuff in

581
00:36:54,880 --> 00:37:01,720
this space, AI in general, that is, you know, behind regulation and then there's still

582
00:37:01,720 --> 00:37:06,480
even more of it that's like a head of regulation, we're never quite just right, right?

583
00:37:06,480 --> 00:37:07,480
Yeah, yeah.

584
00:37:07,480 --> 00:37:08,480
Yeah.

585
00:37:08,480 --> 00:37:09,480
Yeah.

586
00:37:09,480 --> 00:37:10,480
It's been a great conversation.

587
00:37:10,480 --> 00:37:11,480
Yeah.

588
00:37:11,480 --> 00:37:12,480
Awesome.

589
00:37:12,480 --> 00:37:14,160
Any final parting words?

590
00:37:14,160 --> 00:37:19,520
You know, I always like to say, because this is a machine learning audience, right?

591
00:37:19,520 --> 00:37:20,520
Yep.

592
00:37:20,520 --> 00:37:26,480
And, you know, there's so much focus on deep learning for a lot of good reasons, right?

593
00:37:26,480 --> 00:37:33,760
I mean, deep learning is an incredibly powerful approach that has made progress on problems

594
00:37:33,760 --> 00:37:37,360
where very little progress has been made in a long time before it.

595
00:37:37,360 --> 00:37:42,000
So I'm certainly not knocking deep learning in any way, shape, or forms relevant to a very

596
00:37:42,000 --> 00:37:45,400
wide class of issues.

597
00:37:45,400 --> 00:37:48,720
But it's not the only, it's not the only tool at toolbox.

598
00:37:48,720 --> 00:37:56,000
And there are cases in, as I said, in particular, with edge cases where you need real-time prediction

599
00:37:56,000 --> 00:38:02,760
at the edge in a product with a price point, that, you know, it may not be the best tool.

600
00:38:02,760 --> 00:38:06,440
So, think broadly about your options as you're trying to solve real problems.

601
00:38:06,440 --> 00:38:07,440
That's it.

602
00:38:07,440 --> 00:38:11,160
And, you know, we are, for certain kinds of problems, we are one of those kinds of options.

603
00:38:11,160 --> 00:38:15,000
But I think the, I think the statement is true generally.

604
00:38:15,000 --> 00:38:16,000
Cool.

605
00:38:16,000 --> 00:38:20,800
And we'll, we'll make sure to link to, uh, to both your websites.

606
00:38:20,800 --> 00:38:26,680
I'm anxiously awaiting the automated high beams as well as the other aspects of the, uh,

607
00:38:26,680 --> 00:38:28,080
the smarter car.

608
00:38:28,080 --> 00:38:30,560
Uh, thank you both for taking the time to chat.

609
00:38:30,560 --> 00:38:31,560
Thank you.

610
00:38:31,560 --> 00:38:32,560
Thank you.

611
00:38:32,560 --> 00:38:33,560
Thank you.

612
00:38:33,560 --> 00:38:38,600
All right, everyone, that's our show for today.

613
00:38:38,600 --> 00:38:43,160
Thanks so much for listening and for your continued feedback and support.

614
00:38:43,160 --> 00:38:49,640
Remember, for your chance to win in our AI at home giveaway, head on over to Twimlai.com

615
00:38:49,640 --> 00:38:54,280
slash my AI contest for complete details.

616
00:38:54,280 --> 00:38:59,000
For more information on Stuart, Brady, or any of the topics covered in this episode, head

617
00:38:59,000 --> 00:39:03,520
on over to twimlai.com slash talk slash 105.

618
00:39:03,520 --> 00:39:07,520
Thanks once again to Intel AI for their sponsorship of this series.

619
00:39:07,520 --> 00:39:11,520
To learn more about their partnership with Ferrari North America Challenge and the other

620
00:39:11,520 --> 00:39:16,120
things they've been up to, visit ai.intel.com.

621
00:39:16,120 --> 00:39:21,160
Of course, we'd be delighted to hear from you, either via a comment on the show notes page

622
00:39:21,160 --> 00:39:27,720
or via Twitter directly to me at at Sam Sharrington or to the show at at Twimlai.

623
00:39:27,720 --> 00:39:42,720
Thanks once again for listening and catch you next time.

