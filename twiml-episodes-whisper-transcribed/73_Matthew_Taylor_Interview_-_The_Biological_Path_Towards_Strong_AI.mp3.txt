Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting
people doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
A big thanks to everyone who participated in last week's Twimble Online Meetup and
to Kevin T from SIGUP for presenting.
You can find the slides for his presentation in the Meetup Slack channel as well as in
this week's show notes.
Our final Meetup of the Year will be held on Wednesday, December 13th.
Make sure to bring your thoughts on the top machine learning and AI stories for 2017
for our discussion segment.
For the main presentation, prior Twimble Talk guest Bruno Gonzalez will be discussing
the paper understanding deep learning requires rethinking generalization by Shi Huang Zhang
from MIT and Google Brain and others.
You can find more details and register at twimbleia.com slash Meetup.
If you receive my newsletter, you already know this, but Twimble is growing and we're
looking for an energetic and passionate community manager to help expand our programs.
This position can be remote, but if you happen to be in St. Louis, all the better.
If you're interested, please reach out to me for additional details.
I should mention that if you don't already get my newsletter, you are really missing
out and should visit twimbleia.com slash newsletter to sign up.
Now the show you are about to hear is part of our Strange Loop 2017 series brought to you
by our friends at Nexusos.
Nexusos is a company focused on making machine learning more easily accessible to enterprise
developers.
Their machine learning API meets developers where they're at, regardless of their mastery
of data science, so they can start cutting up predictive applications immediately and
in their preferred programming language.
It's as simple as loading your data and selecting the type of problem you want to solve.
Their automated platform trains and selects the best model fit for your data and then outputs
predictions.
To learn more about Nexusos, be sure to check out the first episode in this series at
twimbleia.com slash talk slash 69 where I speak with co-founders Ryan Sevy and Jason Montgomery.
Be sure to also get your free Nexusos API key and discover how to start leveraging machine
learning in your next project at nexosos.com slash twimble.
In this episode, I speak with Matthew Taylor, open source manager at Numenta.
You might remember hearing a bit about Numenta from an interview I did with Francisco Weber
of cortical.io on twimble talk number 10, a show which remains the most popular show of
the podcast to date.
Numenta is basically trying to reverse engineer the neocortex and use what they learn to
develop a neocortical theory for biological and machine intelligence that they call hierarchical
temporal memory.
Met joined me at the conference to discuss his talk, the biological path towards strong
AI.
In our conversation, we discussed the basics of htm, its biological inspiration and how
it differs from traditional neural networks, including deep learning.
This is a nerd alert show and after you listen, I would also encourage you to check out the
conversation with Francisco, which we'll link to in the show notes.
And now on to the show.
Hi everyone, I am here at the strange loop conference in St. Louis.
And I am joined by Matt Taylor, who is an open source community manager at Numenta.
And I am super excited to have you here with me, Matt.
You just delivered a talk here at the conference and I'm looking forward to us diving into that.
But before we go anywhere else, welcome.
Thank you.
It's a pleasure to be here.
Pleasure to have you on the show.
So why don't we get started by having you tell us a little bit about your background and
how you got into machine learning and AI?
Yeah, I don't know how far back to go.
But I mean, in computers, I got interested in computers when I was enlisted in Air Force.
I was an intelligence analyst in the Air Force.
And then that turned into a department of defense job in the same place and I was doing a lot
of simulation, like air defense simulations in like Fortran and Shell scripts.
It was kind of our cake, but it was a very powerful simulation.
So that's sort of what got me into programming.
I didn't really think much about artificial intelligence until I read on intelligence,
which is a book that our founder Jeff Hawkins wrote, I think in 2005.
And I was working in the software industry at that point.
I got away from, you know, old defense industry and moved here to St. Louis to work in software
after I got my software degree.
Oh, wow.
And so I would just consult it around St. Louis, worked at a bunch of different places and
did a bunch of different jobs.
And I read that book.
I remember reading it on intelligence and another book called The Singularity is Near by
Ray Kurzweil.
Sure.
And reading those two books at the same time really like flipped the script for me.
And I was like, it made me start wondering all these big questions like, what is consciousness?
What is intelligence?
How do we even define these things?
Is it really possible that we could build intelligence systems out of non-biological materials?
But at the time, you know, I was just working here doing mundane software programming and
stuff.
But I don't have a math degree, I didn't have an experience in deep learning or artificial
neural networks.
Even at that point deep learning wasn't even a big deal.
So I just gave it up as a pipe dream.
But at some point, I got a job at Yahoo as a front-end engineer, which is odd because
I'd never done front-end engineers before, but I got a job at Yahoo and moved out to the
Bay Area.
Worked there for a couple years and out of the blue, I got a call from a recruiter for
a front-end physician at Nementa.
And I was like, wow, what?
OK, sure.
Wow.
So I jumped on board at that point and just started doing web stuff.
Eventually moved up to do web services.
It was the manager web services.
And when my boss, Jeff, decided he wanted to take all of their algorithms, open source,
I was like, I want to help with that.
Because I like open source.
I've always been an advocate of open source and been a part of different communities.
And I was like, sign me up, so I did.
That's fantastic.
So maybe for folks that aren't familiar with Nementa, you can kind of walk us through
the company and its position in the machine learning space.
I think the company has kind of a unique approach to machine learning.
And folks that have been around with the podcast for a while and listened to Francisco
Weber's podcast might recall Nementa and Jeff Hawkins' work coming up in that context
because the work that cortical is doing is related to what Nementa is doing.
Yeah, that podcast, I think, was a great primer for us for Nementa.
It was a partner of ours, and Francisco is a brilliant guy, you know, is exactly what
he's talking about.
So our mission at Nementa is different than I think most companies, and it's always been
this ever since that I've been at the company.
It's two things.
Understand how intelligence works in the Neo Cortex, and the second thing is implement
those things outside of biological systems, like try and build it, because basically
reverse engineer the Neo Cortex as our mission.
And hopefully, you know, we'll make money out of that at some point.
But honestly, we're like really kind of R&D focused right now.
Yeah.
Very small company, very focused on the research.
And is it primarily just funded by Jeff?
Yeah, it's privately funded by Jeff Donah.
Yeah, yeah.
A group of contributors that have been long time associates of Jeff and Donah, you know,
they built Palm and Handspring, and so there's a crew of board members that I think help
with the funding, but I don't know the details of all that.
And is the implication of that mission, though, that the company is not under your traditional
kind of venture commercialization pressures?
Is it better to think of Nementa as like an open AI than like a, you know, machine learning
company X?
I guess.
I've never thought of it in comparison to open AI, but I guess it would be similar in
that we're not building products.
You know, we're not selling services.
What we're doing is we're trying to make discoveries.
So all of our discoveries are based on neuroscience research, you know, our research engineers are
always reading the most recent neuroscience papers that come out there, they're interacting
with different neuroscientists in the community, trying to answer questions that are relevant
to how we understand intelligence in the context.
And what we do is as we make these discoveries and we test them out, you know, we'll prototype
them and software and think, oh, this is how it works.
It actually does, our theory seems to work in software the way we thought.
Then we will create patents around those discoveries.
So there, you know, specific ones about things that we've discovered about how the brain
is working and how we've implemented it and currently in software, but it could be implemented
in hardware too.
Okay.
The idea being, you know, the monetization strategy is in the value of the IP itself.
So we don't want to be distracted by consulting, by providing services or by creating applications
at this point.
We really want to focus on the discovery, on the brain, trying to figure out how it works
and we think that good things will come of that.
Okay.
So for your talk, one of the big things that I think you talked about at least from the
perspective, from what I got out of the abstract was you kind of premised it on, you know,
hey, there's a lot of excitement out there about neural nets and deep learning and things
like that, but these are all based on a model of a neuron that is, you know, rather
dated.
Right.
And I presume you then walk through some of the new things that we've learned since then.
Yeah.
You kind of walk us through your talk and the ideas that you wanted to share with folks.
Sure.
So I'd like to say, first off, that I don't have anything bad to say about artificial
neural networks or deep learning.
I sure that's necessary technology that we needed to build in.
But one of my main points is that it's not going to naturally evolve into what people
call strong AI.
And the first thing I say in my talk is weak AI is not intelligent and won't become intelligent.
There's not going to be some, this like exponential growth and suddenly, you know, sentience.
There's some core things about the an end point neuron models specifically that don't have
the capacity for intelligence as we understand those are what are some of those core things.
Let's just dive right in there's there's there's two main things.
One is that the neuron needs to have three states and current neurons have two states active
or not.
And we add the idea of a predictive state.
So the neuron goes into a predictive state to indicate that it thinks based upon the
context of its input that it's going to be active soon.
And that prediction is core to everything about our theory that and we, you know, we take
that from understanding how the brain works.
Your brain is constantly making predictions about what it's going to see next when it's
going to feel next all the time.
And you can see that by investigating these depolarized pyramidal neurons in the neuroscience
they call these cells a depolarized, which means that they're primed to fire.
And we're missing that in the an end neuron model.
There's no, there's no concept of that.
So there's that.
And the other thing is pyramidal neurons have different integration zones.
It's not, they don't just have one group of connections to other neurons.
They've got apical dendrites that kind of provide feedback from layers that are either
above it or different parts of the cortex.
There is distal, a distal zone that's kind of, that's lateral.
So that's getting connections from, it could be from another layer, it could be from within
a layer itself, but that provides context.
And these both provide context for the proximal input.
The proximal input is really the driver input.
That's typically coming from the direction of the senses.
And so that's, that's like the sensory input that we need to understand, we need to process.
And the pyramidal neurons do that in the context of these other zones and the context of distal
input and apical input.
So those are the two things I think we're really missing from that point neuron model.
So I get that the neuroscience research has identified these things in human biology,
but it's not clear to me how we've demonstrated that those are required for intelligence, or
even that those things can't be approximated with artificial neural networks as we currently
know that like the last thing, the different zones, you know, maybe think of well, you
know, we just have different inputs and different weights, right?
And then as far as predictions are concerned, if we're able to predict at a network level,
you know, who's to say that the neuron itself has to have that predictive state in order
to create intelligence?
Well, it's, it's true that current artificial neural networks in deep learning could potentially
put together models that replicate the parts of the things about the neuron that we're
saying are required for intelligence.
I think we use it all.
It's for prediction all the time.
Yeah.
But I don't know that that's, it doesn't feel natural to me.
And think about this recently, there's been this big discussion in the deep learning community
about back propagation because Jeff Hinton has recently said, let's give up on back propagation,
go back to the drawing board and try and figure out what's really going on.
We did that 12 years ago.
So we never tried back propagation.
We've always tried to do this because we don't see back propagation happening in the brain.
And for the, for the longest time, you know, Hinton and, and Ben Gio were insisting that back
propagation is happening in the brain, we just don't see it.
So I think, so that's kind of a move in, in our direction.
And even from like the deep mind crew, they recently had this blog post about how important
neuroscience is to contributing to artificial intelligence.
It feels to me like the community started to move in our direction.
And maybe they will be able to hack these properties that we're saying we need in, in
the neuron model into deep learning systems that, that could happen.
But I don't think that it will happen without them doing something to incorporate those
ideas.
And Ben Gio, just this week published a paper that talked about, I forget the exact
title.
Something about consciousness.
I don't know if you saw that.
I did not see that.
And it was controversial might be strong, but it raised a lot of questions because he,
you know, proposed that somehow we need to take into account some notion of consciousness
in our models.
But the paper didn't present any experimental results or whatever it was just like a prod
to the community.
Anything about consciousness is going to be controversial because what is consciousness
Sam?
Right.
What is intelligence?
Exactly.
I was asking people in the audience who believes humans are intelligent and they all raise their
hands.
Who believes chimpanzees are intelligent?
And they just go down the evolutionary ladder and see hands going down.
By the end of it, I'm asking who thinks plants are intelligent and there's still one or
two people that think plants are intelligent and they may be right.
You know, I don't, we don't know.
Yeah.
Permissium, whatever.
So there's a lot of disagreement.
The thing is everybody believes humans are intelligent.
So at least we can start with that.
So we have been, and I think by association, we can include most primates and not two because
they have the same neocortical structure that we have.
So we've focused that on that neuroscience and what we think, what we all know is intelligent
and that's the neocortex of the mammalian brain.
So you started off talking about like level setting on intelligence and just how open
and that is and then talked about kind of the evolution of the neuron.
Like how do you get from there to systems?
Oh, okay.
So you think about the pyramidal neuron, like I said, and it has these integration zones.
It's hard to visualize without a picture, but Francisco said the same thing.
I know.
I know.
But my talk will be online at some point.
So if you could find Matt Taylor talking strangely, but I've got a bunch of drawings and
stuff.
But if you look at a pyramidal neuron and it's got, we'll link to it if you should
us a link.
Okay.
It has these integration zones, distal, which is lateral to the side, proximal, which comes
from below apocode, which comes from on top.
The cortex has this homogenous structure.
If you took your neocortex and you unwrinkled it and unfolded it and flattened it all out,
it's a sheet of cells.
It's about the size of a dinner napkin, it's about the thickness of a dinner napkin.
And it's homogenous throughout.
It has the same structure and what that, there's sort of like this computational unit in
the cortex called a cortical column.
This is something that is more recent of a neuroscience discovery.
We've known for like a hundred years that the cortex had layers, like there is these
distinct little layers in the sheet and that their structure was different enough that
we thought, well, they're doing different things, but we're not exactly sure what they're
doing.
Now that we know they're not just layers, there's also columns.
And we can take that, each column and say, okay, each one of these is some individual
computational unit, right?
And maybe they can share their computation or the output of their computations with their
neighbors and stuff.
So this idea that a column can have layers within it and every layer is full of these
primal neurons, okay?
So imagine a column that's cut up into layers and this is sort of a cylindrical column,
cut up in layers.
Each one of those layers is full of primal neurons that have these integration zones,
apical up and down to the north sort of and proximal to the south and distal to the side.
So each layer itself has the same integration zone properties as an individual neuron
because they're all oriented in exactly the same way.
So you can treat that layer as a computational unit.
So a layer gets proximal input, a bunch of proximal input that all gets piped into its
neurons in different ways.
From some space that's representing generally some spatial sensory features changing over
time or something like that.
So you can think of the layer itself as a computational unit.
Depending on where it gets its proximal input, where it gets its distal input and its
able to input, it does different things.
And also there's a bunch of different layers in the cortex, somewhere between six and
ten, depending on which neuroscience you talk to.
But each one of those layers is structured a little bit differently too.
So there's some minor deviation in the organization of those primal neurons within layers that
also give them a little bit of different computational aspects, organization in what sense.
For example, we have these algorithms that we're saying are happening in these layers.
One is called a spatial pooling algorithm that takes some input and kind of spreads it,
normalizes it while retaining the semantics of the input.
And these create these mini column structures of neurons.
And some layers have this.
And typically the distal connections from each one of those neurons as it's perceiving
proximal input, they start connecting to each other over time.
When you take that distal input to a layer and you say, okay, we're not going to get that
distal input from somewhere else, we're going to have all of the primal neurons within
the layer give each other distal input.
What you're doing is just naturally creating a temporal context.
Because when your only context is some input is what state you've been in in the past,
then that's the temporal context.
If you're getting that input from somewhere else, who knows, that context could mean any
number of things.
But if you're just giving yourself context, that's you're looking at your own past.
That layer has context of its own history when you loop them back to itself.
So that's one of the core things that we discovered.
We call this a temporal memory algorithm.
And it relies on these little mini column structures that takes the input, the bits of input
that are coming in from some sensory organ or perhaps from another part of the cortex,
normalizes it into these column activations and then activates cells within each column
based upon the distal context that it's getting.
So what you get is it's starting to tie sequences together.
When you see a pattern repeating over and over, over and over, you get these distal connections
that are being reinforced.
Because they see the pattern and the distal connection will create a connection to the active
cells that it just saw that represented the previous spatial input.
And then we get another input and there may be a prediction.
So I saw that last time I'm going to be next.
So it makes a prediction and if it's right and the next input activates a column that
that that cells in, then if it comes active, it was a correct prediction.
Well, the context you're creating for me is how I felt when Francisco was explaining
something.
It's like, whoa.
It's a lot easier with visuals.
And hence, that's why I created this bunch of videos on our YouTube channel to try and
explain it all visually.
So you explain kind of the microstructure than the macrostructure and then like what's
next?
So Strange Loop is a developer conference, like how do you get from there to, okay, how do
I build something?
Well, there's two questions there, I guess.
Strange Loop is a developer conference, however, it's also like a weird conference, you
know, it's all granted.
It is.
And so you can like, yes, it's very eclectic.
So you can get in, if you have something that's like on the fringe, but very interesting,
you can get in and talk to them.
So I think that's why I got this talk.
But there's, as far as from a, but still, I mean, in addition to developing IP and all
of that, as I understand it, Numenta's company offers tools that allow people to actually
use this stuff.
Is that correct or no?
All open source tools.
So all of our code is open source and anybody can try and use it if they want to.
I've created a lot of tutorials and code samples and I try and make it as approachable as possible
for our community.
We've got a very active forum, lots of discussions about the theory and about code and stuff.
So as a user of these open source tools and things like, am I, do I need to think about
columns and dendrites and all of that stuff or am I thinking about other representations?
So it can go either way.
It depends on what you're trying to do.
So we have a pretty diverse and eclectic community that are interested in this, typically
people who are really interested in how the brain works or, you know, let's say they
can be a little off.
But I mean, they're always very smart and inquisitive and curious and it, it amazes me the types
of things that people try and do with, with our stuff and I always encourage it and I
was like, yeah, try it.
Give it a try.
Who knows?
We don't know what it's going to have.
It's a software that we open source is called the new pick, the Numenta platform for intelligent
computing.
And we just released 1.0 of that a few months ago and that includes up to what I just talked
about, the temporal memory part of it, and a few years back after we, you know, went
through this research cycle and made the temporal memory discovery, that was a big discovery
for us to see how sequences were memorized in the brain or in the cortex.
We kind of just dumped it all open source and we started like building these potential
sample, you know, which is brainstormed about what could we make with this that people
might want to use.
And we made all these sample applications, there's one that was like rogue human behavior
detection, which is something you can install on a computer and it monitors the different
metrics that are coming out of the computer over days and weeks and given indication
about a user's behavior.
Are they behaving oddly or differently based on the time of day and the thing that they're
doing and the metrics that are coming out of the computer?
So that's a sort of thing that you can do.
We also had a IT analytics program that hooked up to AWS and we actually licensed that to
another company called crock.
And so they are actively selling that to IT companies that have a bunch of servers on Amazon
and it will automatically like through CloudWatch connect to all the different metrics coming
out of your servers and it will create models for all of them and it'll just start streaming
the data into them and you don't really have to do anything, they're all sort of pre-configured.
And then it'll give you anomaly indications over time.
So after it's seen that server data for a while, it gets an idea of what's normal and
what's not normal, then it notifies you that something's wrong with the server.
It doesn't know what's wrong with the server, but it can tell you that something abnormal
is happening and even with this server and this server and the combination of those.
So there's anywhere that there's streaming analytics that you need anomaly detection,
I think that there's a potential application for what we have right now with new pick 1.0.
There's also this really interesting thing that I think is still a big opportunity for
people who want to try and build something novel with this.
We figured out a way to encode geospatial location into a format.
Remember when Francisco and you talked a lot about SDRs about sparse distributed representations.
So corticals, I was all about that, they call them semantic fingerprints.
We found a way to encode location information like latitude,
longitude, altitude, into an SDR.
So we can take something that moves through time and space and give the algorithms,
the intelligence algorithms a way to understand the patterns in the movement of that object.
So for an example that I always do is I go walk my dogs on the same dog walking around every day.
And if I take a tracker with me and then I go put all my points back through the algorithm,
the first time it sees the walk, it's like all anonymous.
It doesn't think, none of it's familiar because it's brand new.
The second time I do it, it's a little bit less familiar.
The third time I do it, it's like no big deal.
This is normal, right?
As soon as I deviate from the path that I've taken,
and even if I just go walk on the other side of the street,
or if my dogs decide they don't want to stop at that tree,
they want to stop at some other tree,
I get anomaly indications coming from my path.
So I think this has big applications in fields like logistics,
air traffic control, human tracking, pet tracking,
stuff like that, where you've got normal routes of things that normally happen.
And you don't necessarily, to the T, want to say,
oh, if they deviate right now, or if they're not at this point at this time,
there's something wrong, you just want to get an idea of their general movement,
whether it's strange or not, or whether it's,
have been seen or not, then it can do that sort of thing. That's really interesting.
Certainly for the network and server anomaly detection,
and the example you gave before that,
there are things that you can do with a variety of different techniques.
Are there things that you've found that either the approach you take,
because of the approach you take, it's just kind of besting class,
or if you need to do X, Y, Z, this is the best way to do it,
or either from a complexity of creating the solution,
or computational costs, or some other metric.
Well, we wondered the same thing,
but the problem we had several years ago is that there are no standard benchmarks
for streaming temporal anomaly detection,
or just for temporal anomaly detection.
Most of the benchmarks are on spatial data,
and most of the machine learning techniques work on spatial data online.
We didn't find anything so we could compare what we did with what,
like LSTM, for example, has some abilities to do temporal analysis on things,
it'd be sort of in batches that move along.
So we created a benchmark we called the anomaly,
the numente anomaly benchmark, and we've set up R as one of them in the running,
and we set up an LSTM one, and we set up, there's one from Twitter,
there's one from Etsy, that does streaming anomaly detection,
like they've got open source projects that do that sort of thing.
And we created these input data sets, things like how many taxi calls
where they're in New York City over an entire period of time or something.
And you can look at that data, and you can say something weird happened there,
for sure, and you go look it up and you're like, oh, there was a big game in town,
or there's stuff like that, you can find that data.
So we'd find data sets like that that had a good amount of data,
and had obvious anomalies that were labeled and marked,
and we've run all of these algorithms against them,
and score them based on how well they detected the anomaly.
And waiting it, I think we waited it pretty heavily on,
not providing false positives, I can't remember exactly,
but it's open source, it's on GitHub, it's a nimenta-slash-nab for nimenta-anomaly-finchmark.
Okay, we have that at least, and of course we're the winner,
because we always mean, but we had like this contest,
we're like, if anybody beat us at this and somebody came and beat us at it,
we're like, okay, we're gonna fix it, so we fixed it,
we're like, we're beating again, but there's always some tweaking that you can do,
you know, to try and get that last few percent.
Ah, okay, it kind of leads me with an impression that, like, this is a tool that,
you know, we've, or a set of tools, that you have a strong feeling that,
you know, closely models the inner workings of the brain as we understand it,
and that over time, that will lead to, you know, I'm assuming you're banking on,
like, order of magnitude, you know, capabilities over current approaches.
Like, the things you can do using nimenta and the things you can do,
using other things will diverge over time, but today,
it doesn't sound like there's a, you know, a bang on the table, like,
if you need to do x, y, z, these tools will get you there,
you know, a hundred times faster and a hundred times cheaper,
or even 10, or, you know, it sounds like, you know,
it's an interesting approach and something that's worthwhile for people to learn,
and take a look at and understand and thinking around.
But it's, we don't have a killer.
There's no killer.
I guess that's what I'm, what I'm getting.
Yeah, there's no killer app, but we're patient, too.
There's a lot of things about the brain that we don't, we still don't understand.
Right.
And what we have currently in nimenta 1.0 is just, you know, temporal memory stuff.
All of our other work that we're doing is in research repository,
is that kind of attach on top of that.
So we're taking those core algorithms, which aren't going to change,
and we're building new and different things with them,
because the core algorithms in your brain don't change,
but we discover that it can do lots of different things with those core algorithms.
Right.
So we're building structures now, because we think we understand how
sensory motor integration happens with sensory input and movement.
But it is the integration of two layers in one of those columns.
Remember I told you about the layers having these integrations.
Yeah.
So we could have one layer that is running the same temporal memory algorithm that I described
earlier, with the mini columns and everything.
But we don't send it its own distal input.
We don't give it a temporal context.
Okay.
We can pipe in the context, the distal connection,
comes from somewhere else in the brain.
It comes from a different layer down.
And if we assume that the output of that layer is providing us with
location information associated with a sensory input
that's proximal coming up to the layer from the bottom.
So that's the driver signal as this sensory input.
The distal signal is going to represent the object being touched
and what location on the object that sensory feature was sensed.
Then we can have a layer that can represent every object we've ever
touched and what sensory input we've felt where on it.
And so that layer now provides that information to another layer,
which we call an output layer.
This output layer has a little bit of a different structure,
because it doesn't have the mini columns like the one underneath it.
But it represents, over time, a library of every object we've ever learned.
So we can train this thing and say, okay, this is a coffee cup.
Touch it all over the place.
Right, right?
Okay.
Here's a banana.
Touch it all over the place.
And we can build a library of objects that that top layer represents.
So the bottom layer is basically just going to represent all the sensory input
you've felt on every location on every object that you've touched.
And this is the temporal memory concept.
It's the temporal memory concept, but it's not doing temporal memory anymore.
It's doing sensory feature and location association,
just because we've changed the distal input.
So it's no longer giving itself distal input.
It's getting it from somewhere else.
And it does something entirely different.
And so it sounds like the idea there is,
like if you think about using deep learning,
object recognition, like our best guess at the way the different layers work now.
So you've got layers that kind of figure out edges and layers that figure out colors.
And so, you know, when the inputs, the banana,
you know, we'll get kind of the curvy layer firing and the yellow layer.
So that's kind of the deep learnings couldn't do.
No, but I'm saying what you're describing sounds like,
you know, maybe in the, kind of in the internals,
is capturing a richer representation of these various things.
That's clear what the big difference is.
Is our model incorporates movement?
And that's the big difference.
So can you name anything that is intelligent that cannot move?
Nothing comes.
I've never, nobody ever does.
Because there's nothing intelligent that can't move.
Yeah.
So we believe that's a core feature of intelligence.
The ability to interact with your environment has to be baked in
to the architecture of the intelligent system.
It's not something that you can just add.
You can't just add behavior to a system that you're building.
It has to be baked into the flow of information.
So like I said, when, when you move your finger to touch an object,
you know where your finger is going to move.
Because you just commanded it to move there.
So that information is available to your brain.
That loop has to be baked in.
So that every time you touch something,
you know where it's going and you know what you expect to feel.
If you don't feel that, something's wrong.
Okay.
And so Matt is demonstrating all this with a glass of water.
And we've been experimenting with a video camera set up here.
So we may be able to show the visual aids
of with motion.
It helps with the visual aids.
But like I said, if you want visuals, go to nemento.org.
Yeah.
I got lots of stuff.
Nice.
Nice.
Awesome.
Well, anything else that you covered in your talk
or last kind of final thoughts that you want to leave us with?
I guess I just want to emphasize that we have a really nice
community.
And like I'm the community manager.
So of course, we're going to say that.
But honestly, there's some really bright people that have even shown up
just in the past year that are doing some really interesting things with HTML.
All of our papers are open access.
So all this theory is everything that we theorize about.
We write papers about and we put it out there.
And we do it with code.
So we're like, here's a paper.
Here's a simulation.
Here's the code.
You can run it yourself if you want to try to run it yourself.
So if you don't believe us, you can try it yourself.
And there's lots of people in our community that have decided they're going to
write their own HTML system and their own favorite language of their own environment.
So there's a lot of people doing new and interesting things.
They're creating their own visualizations.
Last one was thesis from this guy in Turkey.
He did this amazing sensory motor sort of simulation in a 3D game environment where he's
got a player trying to find a point and he wrote his whole thesis on his brain.
But he used our theory and then attached some stuff on top.
He theorized further and he's like, well, what have I got this and this and this?
And trying to create a more complete idea of the brain, not just the cortex.
Because we're really just working on cortex right now.
And he's trying to incorporate some other things like some like real behaviors or real
drivers of what is the motivation for that agent that is running the intelligence.
And we're not quite there, but we're focusing our research right now on location,
like that location signal I'm telling you about.
We've got a really good idea of how that location signal is generated.
And it's super interesting.
Like the way that your brain rocks location of things is amazing.
You probably don't, I don't have knowledge to explain it.
But it's about grid cells, location cells and place cells and stuff like that.
If anybody wants to go research that, there's some really interesting neuroscience papers
coming out about grid cells.
Okay, for example, I'll give you a little example.
If you put a mouse in a box and you let it run around the box and you're monitoring its neurons,
you'll see as it runs around the box and you trace where it goes,
certain neurons will fire when it's in certain places.
And those fire, and you can identify those cells that are greening whenever it's in place.
Yeah, X, Y.
Yeah, the specific neurons going to fire?
Yes.
Wow.
And if you look at it, it forms this hexagonal grid.
So there's this hexagonal pattern of neurons that are firing as you move through space,
representing where you're at in the space that you're occupying.
And we think that that interplay of neurons and that idea of neurons representing locations
in space plays out at a bigger level to even represent objects in space too.
Okay.
Like you have an allocentric representation of any object that you can imagine.
Allocentric meaning not related to where you are, not egocentric,
but just like imagine a cup.
I mean, that's an object that you have.
And if you like used its center of gravity for whatever, as its center,
you could define it entirely based upon all the sensory input that you've ever received
about those objects that you've felt or seen or whatever.
And we think that that has something to do with grid cells.
That how those objects are stored, like the plate that how in 3D space they're defined
is linked to the sensory input that we receive about them.
And what cells are firing in space as we're imagining where we're touching on the object.
Okay.
Wow.
Super, super interesting stuff.
I will definitely make a note for folks to listen to the conversation with
Francisco a couple of times before this one.
Or maybe this one should be the prerequisite for that one, I don't know.
Well, it's hopefully it's standalone, hopefully it's standalone.
Awesome.
Well, thanks so much, Matt.
You're welcome.
I appreciate the opportunity.
Absolutely.
All right, everyone.
That's our show for today.
Thanks so much for listening and for your continued feedback and support.
For more information on Matt or any of the topics covered in this episode,
head on over to twimlai.com slash talk slash 71.
To follow along with our Strange Loop 2017 series,
visit twimlai.com slash ST loop.
Of course, you can send along your feedback or question via Twitter
to at Twimlai or at Sam Charrington or leave a comment right on the show notes page.
Thanks again to Nexosis for their sponsorship of the show.
Check out twimlai.com slash talk slash 69 to hear my interview with the company founders.
And visit nexosis.com slash twimble for more information and to try their API for free.
Thanks again for listening and catch you next time.
