Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
In this episode we're joined by Sebastian Rooter.
Sebastian is a PhD student studying natural language processing at the National University
of Ireland and a research scientist at Text Analysis Startup, Alien.
In our conversation, Sebastian and I discussed recent milestones in neural NLP, including
multi-task learning and pre-trained language models.
We also discussed the use of attention-based models, tree RNNs and LSTMs and memory-based
networks.
Finally, Sebastian walks us through his recent UML fit paper, short for universal language
model fine-tuning for text classification, which he co-authored with Jeremy Howard
afast.ai, who I interviewed in episode 186.
Before we dive into the conversation, I'd like to send a huge thanks to our friends at
IBM for their sponsorship of this show.
Interested in exploring code patterns leveraging multiple technologies, including ML and AI,
then check out IBM Developer.
With more than 100 open source programs, a library of knowledge resources, developer advocates
ready to help, and a global community of developers, what in the world will you create?
Live in at IBM.biz slash ML AI podcast, and be sure to let them know that Twimmel sent
you.
And now onto the show.
All right, everyone.
I am on the line with Sebastian Rooter.
Sebastian is a PhD student studying natural language processing at the National University
of Ireland, as well as a research scientist at Alien.
Sebastian, welcome to this week in Machine Learning and AI.
Hey, Sam.
Thanks for having me.
Yeah, I'm really excited about having you on the show.
We've been trying to coordinate this for a while.
And so thank you once again, that you've been doing some really interesting work at kind
of the intersection of deep learning and natural language processing that I'm looking forward
to diving into.
But before we do that, I'd love to learn a bit about your background.
You've been studying natural language processing and computational linguistics in particular
since undergrad days.
How did you get interested in into this field of study?
Yeah, so yes, I said I did my undergrad in computational linguistics at the University
of Highlandberg in Germany.
And computational linguistics really is still quite a small field, or at least when I was
studying that, there wasn't that much interest in it.
And so how I initially got into that was that I was kind of doing high school, really interested
in both mathematics and languages as well.
So I really liked kind of learning different languages, but at the same time kind of the
analytical side of math really appealed to me.
And so I really was looking for something that like for some fields that were I could manage
to combine both of those maybe quite different areas.
And then in doing research, I really found that computational linguistics was really the
field which is really at the intersection of yeah, like computer science and linguistics.
And so for me, I tried that out and really seemed to be the perfect fit for me personally.
And a lot of the kind of my classmates at that time, what I really liked about computational
linguistics was that it seemed to because you kind of need such a like a peculiar
set of interests.
So there were a lot of people in that subject with like a variety of different interests,
people who were interested in kind of other things, social sciences, practical linguistics
as well.
So really had kind of a very wide variety broad set of backgrounds.
And I think that made studying and working in the field particularly interesting for
me as well.
Tell us a little bit about your graduate work.
And yeah, so I did kind of the undergraduate in that there.
And then afterwards I was really looking for, I really wanted to stay in the field as
well, but I was looking for to get some industry experience first.
But then in kind of researching for a job, I came across a program kind of an industrial
PhD program where it could combine research and kind of industry work as well.
And that really appealed to me.
And yeah, I decided to go in that direction, consequently.
And then doing my graduate work, I was really been looking for something initially I started
working on kind of a lot of the applications of NLP.
So as it's often used in the industry setting, like working on different applications of
text classification, like sentiment analysis, or different forms of information extraction.
And then kind of working on those very downstream tasks, I realized that actually the most kind
of the challenge that permitted those or what was really at the heart of solving them was
really because we had to create text classification applications for a lot of different domains,
different languages, different data from different customers as well.
So I really realized that actually we in order to solve those challenges better, we actually
need to have better methods and better algorithms to learn from limited amounts of label data.
So really having either models that analyze better or better ways to learn from either
distant or distant supervision or from unlabeled data to.
So this kind of idea of how can we more efficiently use label data or how can we learn from additional
sources of supervision has really driven a lot of my interest and really a lot of my graduate
work.
And you're you're finishing up your PhD kind of any day now, right, you're on your last
year?
Yeah, I'm in my last year some currently in the process of just writing up my thesis and
putting those different projects on which I worked on it together essentially.
And I guess the last background question you are also working as a research scientist
at Alien, which it sounds like is through this industrial PhD program?
Yeah, exactly.
And what does Alien do?
So Alien is focused on the natural language for us in startup, which is mainly focused
on analyzing and providing services around news.
So we have some kind of a different number of products, one which aims at aggregating
news and enriching news with different forms of kind of semantic information like entities,
but also relations and so and sentiment to doing things like named entry recognition and
to linking sentiment analysis around those.
And then there's kind of a separate set of services which are which developers can integrate
into their own applications to kind of use NLP in their own services.
And then finally, we also do a fair amount of consulting to developing kind of specialized
applications for particular customers.
Okay, very cool.
And so maybe to kind of dive into some of your work in NLP, you recently wrote I think
on your blog post about kind of the history of natural language processing from your perspective.
Maybe kind of walk us through the, maybe not the full history, but kind of the interesting
recent historical developments in the field.
Sure, yeah.
So that blog post kind of arose in conjunction or as a byproduct of a session of natural
language processing that we organized at the deep learning level, which is kind of a
big initiative kind of a summer school like event in South Africa that kind of sought
to bring together and strengthen the African machine learning community.
And for a session of natural language processing, we essentially wanted to give kind of both
beginners as well as maybe people who've already worked with NLP and overview of maybe
some of the most important milestones that are still relevant today or that they can
still like knowing them would still kind of help them tackle ongoing challenges.
And in compiling this kind of this overview, Herman Camper, who co-organized the session
with me, we essentially started out because we really wanted to have to get something
that not only reflects our opinion, but also some opinions of a larger set of experts.
So we started out just sending emails to a number of experts, NLP, just to get a bit
more, more suggestions and more ideas.
And then essentially we compiled kind of the eight milestones that were mentioned.
And then we found relevant into a list here.
And yeah, and so just because the main kind of category of methods are currently being
used in NLP at this point, are really mostly using neural network-based approaches.
So because of that, we mainly focused on kind of approaches or milestones that have relevance
to that, although in the post there's also a lot of other kind of more traditional milestones
that led up to that research in which kind of a lot of research later on is building on.
Yeah, so to think so, essentially the milestones we arrived at were kind of the
first neural language models that were proposed in 2001, kind of as a something that has been
in many different ways kind of built upon and or co-opted by subsequent approaches because
a lot of different tasks like sequence-to-sequence learning or even learning word embeddings can
be expressed as some sort of variation of just doing language modeling.
And something that is becoming more prevalent these days is multi-task learning, which
was first proposed for NLP in 2008, as kind of a very milestone, very seminal paper of
Colourbird and Destiny.
And that paper also got a test of time award at ICNL this year.
And then probably what was that paper called?
Yeah, so it's like a unified architecture of four-netual language processing, I think.
Yeah, deep neural networks with multi-task learning, I think that's the full title.
Yeah, so that's definitely, if you haven't got that paper yet, that's really worth reading.
And I'm surprised to hear that one was 10 years ago, multi-task learning seems to be just
getting popular.
Well, I should say I'm reading a lot more about it over the past, maybe six to nine months.
So in that paper in particular, that introduced kind of a lot of different techniques like
using CNNs for text, for instance, or even using something like unsuverse learning of
word embeddings.
That was in 2008.
And only about five years later, people were really starting to use word embeddings.
And even nowadays, yeah, so now like 10 years later, people are actually really starting
to pick up multi-task learning.
So in many ways, that particular paper was kind of a bit ahead of its time and not really
widely kind of regarded or not a lot of people kind of took inspiration from that paper
at that time.
And then kind of probably what most of the experts we were talking to mentioned really
as one of the biggest recent milestones was the use of word embeddings that were pre-trained
and learned in unsuverse way on a large corpus so that really started out with word-to-vec.
And kind of a whole separate branch of research that I've kicked off of really trying to
better understand what these word embeddings capture.
And word embeddings really are still very widely used, even word-to-vec is still often
used in papers these days.
And then kind of the last milestones you mentioned were essentially just the more prevalent use
of using neural networks for NLP.
And mainly then kind of in three different types, so essentially the main types people
are using these days are recurrent neural networks and mainly these long short-term memory
networks which are kind of a modification on this classic recurrent neural network.
Then convolutional neural networks have been proposed for NLP and also used in particular
for some text classification tasks like sentiment analysis.
They have been used quite often and now more recently also for different tasks like machine
translation for instance because people have realized that using these conclusions you
can actually capture more efficiently long term dependencies in your data by using kind
of wider receptive fields with daily latest convolutions in your models.
So there's been some recent scene end-based models for machine translation.
And then one particular category that I find quite interesting in NLP is that you have
because linguistically if you look at a sentence it really, its sentence can be kind of split
up hierarchically.
So you have words or even like going on the sub word level you have different more themes
that compose into a word and then you have words that form different clauses or chunks
in a sentence.
So instead of processing a sentence sequentially you can have models that take its input
or act upon this tree structure as well.
And these have been kind of called historically like recursive neural networks because they
kind of recursively from the bottom up starting from the individual words builds the representation
of the entire sentence using some sort of composition function.
And more recently they're also called tree RNNs or tree LSTMs.
So you can have an LSTM that doesn't act on a sequence but on entire tree.
How much are those used and how well do they work?
Yeah, so it really depends on the kind of tasks you use so they can be kind of useful if
you want to, for instance, incorporate so for machine translation some of these some
modifications using these kind of three-based methods have been proposed essentially to
incorporate a bit more syntactic structure into the model.
So just to make it a bit easier for the model to model this type of structure which helps
when translating into certain languages or maybe if you translate from one language
where, for instance, the verb comes, so with the object comes first to an language where
this, where the position of object is reversed, for instance.
So in some sense this can help you model yeah, some syntactic relations and or yeah another
task like for sentiment, there's been some datasets where you can have kind of supervision
at the word level where these for which task these have been originally proposed.
So there's been a few things in general still if you have like an arbitrary NP task, probably
like a bidirectional LSTM will still get you further probably but I would guess or I really
hope to see, I personally would hope to see more of these models that can actually incorporate
some linguistic information in kind of feel as a future direction.
So I think this maybe while it's maybe not the most performant model yet, I think it's
really a kind of useful way or useful kind of method or kind of class of methods to
think about.
And more recently you can have people have started using kind of graph convolution networks
which basically apply like a scene in the convolution operation on on this tree as well.
And they've shown some good results for yeah, for tasks we have some dependencies like
semantic role labeling for instance, like semantic what like semantic role labeling,
which is yeah, which is kind of a classic LP task and basically a form of so it's also
people also refer to it as shallow semantic parsing and it essentially comes kind of from
a and has like an underlying theory in that you have different frames of sentences.
So depending what works, you use each verb put a vocal different frame and then you would
essentially try to label the arguments of that verb that coca with that frame.
So it's kind of a more linguistically informed or a classic linguistic task that people
have been evaluating on.
The next milestone that you pick up is sequence sequence models, right?
Yes, exactly.
Those have been popping up all over the place, not just NLP.
Yeah, so it's really kind of like, yeah, like in doing that review, I looked back at
the paper again and they in their paper, I think mainly evaluated on machine translation,
which is I think really the kind of the biggest application these kinds of models have been
applied to.
But then, yeah, so for context sequence, the sequence models are essentially just a general
kind of framework that tries to map an input sequence so it can be words, but can also
be any other type of symbols to an output sequence using an encoder neural network that encodes
this input sequence into a fixed access vector and then output sequence that's given that
vector generates the target sequence.
And yeah, and this has already been proposed in 2015 for machine translation, but since
then basically a lot of applications in NLP, like as soon as you try to generate a sentence,
most of these models would try to use kind of a sequence, a sequence model under the hood.
So these have been very popular for things like chatbots or even in settings where you
don't have an input sequence as an input, but just kind of another representation.
Like for image captioning, for instance, you can imagine that you have a CNN model that
generates a representation of an image and then based on that, you would use that as
initialization for your LSTM and you would then try to generate the caption of that image.
So this kind of framework has really turned out to be very versatile and really applicable
in a lot of scenarios.
You also mentioned attention-based methods.
How do those fit into NLP?
Yeah, so attention, probably like everyone who's kind of aware of sequence sequence model
probably has also heard of attention.
So attention was kind of the probably the main improvement that has really allowed machine
translation models to exceed and overcome or outperform classic phrase-based or statistical
machine translation models.
And attention really, so as I mentioned before, in classic sequence to sequence learning,
you would try to have a model that compresses the input sequence into a fixed size vector.
But that, if you can imagine for machine translation, if you have a very long sentence or
even entire paragraph that you might want to translate to, it can be very challenging
or it can place a lot of computation burden on the model to try to compress the entire
meaning of this paragraph into a fixed size vector.
And attention essentially allows the model to kind of overcome this bottleneck.
So in addition to having this fixed size vector, at every step of generating an output
symbol, the model can also look back at kind of the input sequence and at the different
hidden states of the input sequence.
And essentially, it allows the model to, instead of having to compress everything into
one state, essentially remember kind of the most similar past states, which then makes
it easier for the model to generate the relevant output.
And yeah, and attention also is really something that has turned out to be quite flexible.
So that is really now used, I think in most sequences to sequence learning tasks as well,
that has also been used in, for instance, in image captioning, so you could imagine that
instead of kind of paying attention to different parts of your input sequence, when you just
try to generate a caption or individual words with some image, you can also pay particular
attention to certain parts of that image that might be relevant for generating that next
word.
Or yeah, generally so I think that now this is really common, the attention because this
idea of just computing kind of a weight or kind of a weighted average of your input sequence
or of certain states based on the similarity.
So the doctorate to your current state really has allowed kind of models that can access
memory based on similarity to kind of current state, or also these recent, basically kind
of state of the app models for machine translation, which is a transformer, which essentially
uses self attention, so is the attention not applied to previous sequence, but to the sequence
itself to essentially allow the model to kind of look at and consider the surrounding
words and the surrounding context to improve the representation of the current word.
And by using multiple layers, this can be done multiple times so that you can have a kind
of a more contextually sensitive and a hopefully more expressive or better representation of
each word in your sentence.
Is this related at all to the representations of networks like wavenet where you've got
like these hierarchical layers that are folding upwards, and does that kind of relate to
wavenet, for example?
Yeah, so basically in kind of these conditional sequence models, you get, you can model like
the kind of longer dependencies between different words, but essentially stacking these conditional
layers on top of each other.
So as you go higher, each word will be able to kind of access or consider kind of words
that have become more, that have become, come earlier in the sentence.
Yeah.
So with just a few layers, if you use stylish convolutions, you can have more, you can,
you're able to incorporate almost the entire sequence length.
And with attention, essentially you can do that instead, you don't need to stack layers
at all because the attention mask or this attention operation allows you to directly look
at all of the words in the sentence.
So essentially you kind of have this, you have like a global context, essentially every
layer, whereas in this conditional one, you have a local context, which can very quickly
scale to a global context.
So it's an attention layer intuitively kind of makes it easier to model this global context,
but on the other hand, you miss out on some of this local information again, because
your mask or your attention operation is kind of irrespective of the position of the words.
So because of that, people typically use kind of an embedding of the position or some
function that indicates where the word in the sentence is situated to be able to kind
of model this local context again.
When you describe attention, you're talking about this attention mask, which essentially
kind of weights where you're looking at in the input vectors, is that the right way to
think about it?
Exactly.
So you generally have some, some attention weights that you, that you compute, and then
you do softmax over that.
So in the end, you get some, you essentially get kind of a probability distribution that
tells you how relevant each of the words is or how similar they are to your current input.
And then, and then in attention, the way these attention weights are computed that can
differ a bit, and that usually includes some number of learned parameters so that model
can kind of learn to pay attention or with regard to different aspects potentially.
And so that the next milestone on your list are memory-based networks, and that's not
a term that I've heard used.
What is that referring to?
Yeah.
So we use that to refer to basically kind of a variety of different methods that essentially
have some sort of memory mechanism, yeah.
So essentially these methods are kind of very similar to attention in a way in that you
can kind of see attention as essentially using the past instance of your model essentially
as a memory or like a lookup table.
So by using attention in a model essentially has like a memory that is the size of the
input sequence.
And these other methods are similar in a way, but some of them have kind of in addition
a kind of a not only that you're able to read from this memory, but you can also write
back at the memory.
So probably I think deep-mind, they have, you know, researchers from deep-mind probably
have produced most of these models that fall under this category with some coming from
fair as well.
And yeah, probably one of the most common ones is kind of this neural touring machine,
which essentially which essentially tries to mimic kind of the classic touring machine,
which has like this tape where you can read and write to and which essentially tries to
use this concept and implement that in a neural network by having a memory where you
can basically read and write to as well, but with a mechanism that is very similar to kind
of attention that you can basically access content based on this on similarity, but you
can also have some location based addressing in that you kind of know, okay, you've stored
this information in a certain part of your memory, so you can add access that based
on location as well.
And these types of models really are kind of, I've found it kind of useful to include
this, this particular category of models, because I think this, so firstly because this
concept of memory is kind of closely tied to attention, but also because I think going
forward having some sort of memory or some sort of kind of additional capacity of the
model to access additional information in some form or another, so for instance having
access in some way to a knowledge base that you can, that you can kind of query from
or write to as well, or having some kind of more expressive way of storing, remembering
like reading, storing facts that you've read about and then recalling them.
I think going forward and really to really think we can probably talk about that later
in more depth as well, but really to kind of have models that can kind of reason and
have better reason abilities, we need some sort of memory of something, some mechanism
that comes at least close to that.
It does seem a bit like the previous milestones that you've mentioned, the impacts of those
are fairly clear with these memory-based networks, it's a bit more speculative, do you
feel that way?
Yeah, I definitely agree with that, so most of these methods have either been evaluated
on either kind of synthetic tasks, like counting, sorting, things like that, or on, so kind
of the baby dataset from Facebook AI research, which is essentially a synthetically
generated dataset for reading comprehension, so essentially they generate kind of stories
which consist of different sentences, which involve multiple actors and kind of objects
as people moving a ball or bringing a ball to different rooms in the end, the question
would be, okay, where's the ball?
And so most of these methods have been incorporated on this dataset, which is quite synthetic
in the way it was created, so in practice people haven't really seen them scale too well
to kind of more realistic datasets, yeah, so I think it's really safe to say that so far
kind of the impact was probably limited, but I think kind of this, yeah, this mechanism
I think is promising for the future.
And so that brings us to 2018, the last milestone on your list, which is pre-trained language
models, and more generally the idea of being able to apply transfer learning, which we've
seen a ton of success with, and the image domain to NLP.
And you've done quite a bit in that space, you know, tell us about what you've seen in
that space that kind of inspired you to start working in that area.
Yeah, so for me personally, so maybe I came on that from two directions.
So first in my personal research, as I've worked on different tasks and kind of developing
different, like domain annotation, multi-tasking methods for different tasks, that were like
usually task specific and try to incorporate some features of the target task, kind of
the logical or kind of the natural progression in that was really trying to work on kind of
this more general inductive transfer learning setting, essentially, where you try to use some
sort of pre-trained knowledge and generalize or use that to do better on an arbitrary target
task, essentially.
So in that context, you really want to have some pre-training task or some existing information
that is as general as possible, so that it will be likely useful for kind of any number
of target task, essentially.
And then in the second direction, I've also been really following a lot of the progress
made in computer vision.
And just really been fascinated or I found it really cool to see that how transfer learning
was really kind of commonplace there and we used a lot in practice by practitioners in
computer vision that was really very easy to build models or to just collect a few hundred
images for different classes that you care about, use a pre-trained model, find you those
on those images and you could really already get reasonable performance.
And I found that really kind of a factor that I think made it easy for a lot of people
to just have an experiment or develop their own computer vision models.
And I really wanted to have something or I really found thought it would be very useful
to have something similar for a natural language as well, where you can similarly create
collective view, 100 label examples and train your own models for your own task that
you care about.
And kind of in thinking about that, essentially I started kind of talking with Jeremy
Howard from FASDI as well, which been thinking along similar directions.
And concurrently there's been some related work coming out from the Institute for Artificial
Intelligence as well.
And so it really started to crystallize that kind of a like the ideal or useful pre-trained
task for that would really be language modeling because that's already been used as a kind
of a successful variant with Goetheveg, because all Goetheveg does essentially kind of
a variation of language modeling, but instead of using that just to initialize the first
layer of our models with Goetheveg meetings, why don't we just pre-trained a language
model and use that to initialize the remaining parameters of our models.
And that really kind of was, yeah, like this overall direction wasn't really like, wasn't
completely new, so in 2015 there was like the first paper which actually used language
models and then fine-tuned those on the target task.
And we essentially kind of took that a step further, added like a step where we pre-trained
that on a general domain purpose and then proposed some other techniques to improve the fine-tuning
performance or to kind of to retain as much information as possible doing this fine-tuning
process.
I guess when we're talking about transfer learning, there's two pieces, one is being
able to use models that are created by third parties, presumably on other data sets and
the other element is disability to kind of fine-tune it to meet your specific needs.
With kind of that in mind, like do you consider word embeddings to be transfer learning,
you know, certainly we share like glove vectors and things like that, they definitely meet
that first criteria, but maybe not the second, is that the key distinction that you make?
So I definitely think which using like pre-trained vulnerabilities is one form of transfer learning.
So it's one way or kind of a very simple way to use existing pre-trained knowledge.
And kind of using pre-trained language models in the asset is really kind of an additional
step or you basically use kind of that knowledge and for additional input in your model either
to influence more and more layers or you use kind of these richer, these embeddings from
language models which just capture richer relations than you could capture with word embeddings.
So both are kind of forms of transfer learning, but I think using language models scores kind
of a step further than just using word embeddings.
When you say language models, what specifically are you referring to?
When I think of language models, I think of things like LDA, is that what you're referring
to or are you speaking about them more broadly?
So LDA, so latent, usually allocation is an example of topic modeling, so topic modeling
is typically just used for like the expiration where you have like a corpus and you want
to find out what people are talking about in there, so that generally gives you like
a list of topics.
And so language modeling when people talk about language modeling is really, so language
modeling really is the task of you have a sequence of words like a sentence and you want
to predict the next word in that sequence.
So it's a very clearly defined task because you only need kind of the raw text data essentially.
So given the text you can always see, you always know what the next word is that you want
to predict, so you can very easily train this kind of model on a large amount of data.
The typical approach to solving this kind of task would be like an LSTM.
Yeah, so the typical model really this days, so the more traditional model, so stepping
back a bit, the more traditional model would be kind of using basically using Ngrams,
so using kind of different windows of words and then computing the next word or predicting
the next word based on how what words you've seen co-cur with your existing Ngrams essentially.
And then these days, yeah, you have kind of a typical language model would be in LSTM,
maybe with multiple layers.
And yeah, so that would kind of be the most typical one, people have used other models as
well using memory or kind of other variations on this classic LSTM, but recently actually
people showed that if you're just a bit more careful about tuning the hyper parameters
of your LSTM, you can actually get very good performance just using a very classic LSTM
for language modeling.
And so the method that you came up with with Jeremy is called ULM Fit, tell us a little
bit about how it works and the approach you took there.
Sure, so yeah, so our intuition was really with that method that instead of initializing
only the first layer of the model with word embeddings, we really want to have something
with which we can initialize our entire model so that we in the end can take our pre-tuned
language model and we just need to put a new layer, like a new layer for the classification
task on top.
And essentially our kind of method repose here consists of three steps, so we first just
train kind of a classic LSTM language model on a large general domain copus, so we really
want to have a kind of a copus that can capture very general domain knowledge.
And for that, we just use kind of a copus subset of Wikipedia that is quite commonly used
for language model evaluation and training as well.
And then in the second step, you want to get this language model to kind of learn about
some of the characteristics of the data or of the copus you actually care about.
So in the second step, we then find you in this language model, so still the same language
model, only we can just continue training it on data of our new classification task.
So for instance, if you want to do a movie review classification based on positive or negative
reviews, we would just fine tune that and continue training it on movie reviews of that domain.
And for that step, essentially, we realize that we don't really want to train the model,
like use too high of learning rate or you want to kind of be careful in how you train
the model so that you don't actually accidentally override the information that your general
language model has already captured before.
So we essentially proposed kind of two different techniques, certain learning rate schedule
and using different learning rates for different layers, essentially for the model to allow to
retain as much of the general information from the general language model as possible.
And kind of only adapt the higher layers of the model for the current, the new domain.
Because our intuition was with that, that from computer vision, people have shown that
essentially the low layers of the model really capture the most general information.
So in the lowest layers, you really have information about the edges and kind of very general
features.
And as you go higher, the information gets more specific to the task for image net you
would have the higher layers really responding to particular parts of dogs or dog noses
even so the information as you go higher in the model gets more task specific.
And in a P people actually now recently have started to show that there's like a similar
hierarchy of information in your model that was trained in text.
So because of that, our intuition was really that we want to retain as much of the information
in the lower layers as possible and then use higher learning rates for the higher layers
to adapt them to a large extent.
And then in the final step, we essentially remove the softmax layer that was used for the
language modeling objective and replace that with layer, so just softmax cross entropy
layer that just tries to predict the target classes for our task.
And we just train that new layer on top of together with the remaining language model.
And here in addition to the two previous techniques, we also propose to make it a bit easier
for the model to adapt the top layer to the, which is randomly initialized to the other
parameters which have already been trained.
So we initially only train the top layer and freeze the remaining layers.
And then at the second epoch, I'm freeze another layer from the top down to make it kind
of easier for the model to adapt the new parameters to the existing ones that have already been
trained.
There's a lot there. So first, let's maybe start by noting that the method is specifically
kind of targeting this classification type of a task as opposed to predicting the next
word or a generation type of task.
Where do you see those classification tasks come up?
Yes.
So we decided to initially focus on classification because we thought that was kind of the most
or those had like the most real world applications.
So yeah.
So from, yeah, kind of a lot of applications from, yeah, classifying chat logs, customer
requests, requests in different categories routing those to different relevant entities
in legal classifying different legal documents, depending on different, yeah, different fields.
Yeah. So I think classification is really something as soon as you have some sort of text
that is generated and you want to have some information that you want to filter out that
can be expressed as a classification task if you just are able just to define certain
number of categories that you want to express.
Or similarly, a lot of other tasks like even doing sequence labeling or so can also be
expressed as classification. So we found that by focusing on classification first, we
can really cover a lot of, a lot of the real world applications of NLP.
And then you mentioned that recent research has shown that in neural networks that are
kind of language models, there's a similar phenomenon to what we've seen in computer
vision where the lower layers are more general.
On the computer vision side, we've got some intuitive ways of explaining that and talking
about low level features like edges and textures and things like that as being found in these
lower layers. Is there a similar clean way to explain what we're seeing in the NLP side?
Yeah. So there's not, so it's a bit, so in computer vision, it's always nice that
you can actually get some sort of like intuitive feeling by visualizing that in NLP, it's not
exactly as straightforward. But it's still somewhat intuitive. So so far, I think there's
been kind of two ways in which people have shown that there's some hierarchy first when
you do multi-task loading with different little p-task. So multi-task loading is when you
share, when you have one model that performs multiple tasks at the same time. And then
if you have your model, if you train a model with some kind of higher level or more semantic
tasks, like named entry recognition, and if you train that together with another task,
it's more syntactic. So kind of a more lower level linguistically, like a part of speech
tagging, then people have shown that actually information that is relevant for the part
of speech tagging tasks, so information that kind of maximizes the performance in that
task is actually captured at lower level lower layers of model, whereas for named entry
recognition, the information would be contained on a higher level layer. And then more recently
in this kind of in some papers from AI2, where they had so in their L-mold paper and then
in the follow-up paper as well, they showed that in having these embeddings that were
pre-trained or trained in a language model, if you use just, if you use lower layer lower
level layers of your model, then those actually give you the best performance for lower level
tasks, like part of speech tagging, whereas for higher level tasks, the most, the best information
is contained in higher layers of model. So, so far, yeah, so really the best way to look
at kind of a downstream task that encodes some sort of some level of hierarchy, and then
basically generalize from that. So, yeah, so, so far, we haven't really, but there has
not been kind of more intuitive or like a more easily accessible way by just defining
a task that kind of encodes some assumption or something that you want to measure and
then measure the performance of different layers of the model on that task.
And then you mentioned that the ULMFIT method includes some specific guidance around like
setting your learning rates and learning rate scheduling and things like this. On the
computer vision side, these types of things are often done very iteratively via experimentation
to determine, you know, what the right learning rates are and how to schedule your learning
rates or apply learning rates to different layers is what you're saying here that you can
be more prescriptive about it because of some characteristic of the problem or just that
you should take that kind of an approach when training these models.
Um, yeah, so we try to come up with a, so I mean, the way we arrived at these methods,
also, and there's some explanation and trial and error on kind of our validation data as well,
um, but recently or kind of the parameters we arrived at, we found them to perform well on
different or kind of a variety of text classification problems. So it's really kind of more of
the guidance of these are like good rules of thumb or like a good range of parameters that
give, um, that give good results in general, but then obviously for, for particular domains or
particular tasks, it might still be useful to do some, um, some fine-tuning of these parameters or
to slightly change them and see, um, particularly playing around with like the learning rate,
and, um, kind of the number of epochs you train your model, um, can still give you boost in
performance. And so what kind of results have you seen with this approach? Um, so, so with this,
um, so with our approach that we proposed, we essentially were able to outperform the state of
the art on, um, kind of the number of YT studied text classification datasets. And that was, um,
particularly kind of exciting encouraging for us, um, because on a lot of these datasets, um,
some of the architectures were really had either a lot of feature or architecture engineering,
whereas we, um, really used a very simple, um, uh, LSM with just different numbers of dropout,
and, um, only this, um, kind of pre-training step, um, essentially. Um, so it was really encouraging
that, um, yeah, this very simple model was really able to outperform the state of the art on,
on a variety of benchmarks. Um, and then I think to me personally, uh, very exciting was just to see
that this type of approach, um, even trained on, um, limited number of examples. So we basically did
some inflation studies, so we trained it on, um, smaller training exercises, going from 100 to, um,
yeah, two in different steps to 1,000, 10,000, uh, number of examples. And we really saw that just
by virtue of using this pre-trained, um, information and pre-training language model,
we were actually really able to, um, outperform, kind of, training a model from scratch on the same
number of examples by an order of magnitudes, um, or we were able to reach the same performance as a
model that was trained from scratch on kind of an order of magnitude more data. And I think this,
this particular finding that's something that, um, not only we, but, um, kind of other researchers
working in one of a similar direction of using language modeling have found. And, uh, yeah, for,
for me personally, I think that's very encouraging, um, because I think this will really help to unlock,
um, a lot of the kind of potential for NLP and just make it easier for people to use it on, on their
own data sets and just should make it easier for people to, to just collect a small number of
examples and then train and apply these kind of models to their data. Are there any qualitative
comparisons you can make between transfer learning and computer vision and transfer learning
in NLP based on this approach? So, um, so I think maybe one, one comparison is that what we
initially tried and what is, um, kind of commonly done computer vision is that you only train,
kind of, freeze your, um, internet work and you only train like the, the top mostly in front
scratch or you're only on trees, like a couple of the, the top layers of the model, um, but really for
us in, um, at least at the moment, because the models people are using right now are still
quite a bit more shallow than, um, kind of typical models like resonant or dense net that you
would use for transfer learning computer vision. Um, so we really still found it useful to kind of
train, um, the entire model or to fine tune the entire model. At the same time, we've seen or in the
community, um, kind of one of the most promising approaches is, um, this Elmo approach from AI2
and they actually use our, take kind of an orthogonal approach where they don't fine tune the
model, but use the embeddings from the language model, um, kind of as fixed features in a,
in a, um, kind of in a separate model that is still trained from scratch. So you kind of have your
existing, um, architecture and you just add the embedding that you get from your language model
for each word as an additional feature, um, as input, um, and they, they, um, yeah, we're able to
achieve kind of very good and serial fair performance on, um, a large variety of tasks as well.
And, um, kind of reasonably comparing, so in some ongoing work comparing against the
approach, we actually find that, um, they're very kind of those, so our fine tuning approach versus
just using the fixed features like an Elmo is quite, uh, actually is about like a similar performance.
Um, whereas in computer vision, really the, um, kind of the prevalent or the, uh, current paradigm
really seems that people are just, um, fine tuning these models, instead of using them as fixed features.
So I think it's still, um, yeah, so I think we'll still, um, so that's an ongoing research direction
essentially, um, to see what is kind of the best way going forward really to do this sort of fine
tuning in LP. Do we want to use, uh, do we want to use fine tuning or do we want to use fixed features
or maybe a combination of the two and what are actually, yeah, what are like the pros and cons of
that? And in your work, did you train from scratch, your pre-trained language model that you then
use later on to apply to different test code? Did you, uh, was that already available for you?
Um, so we, we trained on language model from scratch. So we trained, uh, yeah, we, we tried
or experimented with different ways to train the initial language model as well, um, yeah,
just because we want to observe the effect of the data, um, on the language model.
Um, but, yeah, there's like different types of, um, tasks like, um, so we trained on the
subset of Wikipedia, but Elmo, for instance, was trained on kind of a larger, uh, news corpus.
Um, and, um, they use, I think like a pre-trained language model that was available online,
and more recently, there's been some work from, uh, OpenAI, where they also trained a language model
that was based on this transformer architecture from machine translation on an even, uh, larger corpus.
Um, so, and it's still not entirely clear how those different, what the actual impact or
how much of a benefit it gives you when training on like a larger corpus. Um, I think one hypothesis
might be that training on training a more expressive model on more data, as we've kind of seen all
the history of deep learning that might work better in the long term, um, but we still need to kind
of figure out what actually the, uh, the best ways to do that. And out of curiosity, what, uh, kind
of order of magnitude were you experiencing in terms of training time for these models?
Um, so in terms of training the initial, so training the first, uh, uh, language model on the
large corpus, or fine tuning the language model, or, uh, well, both. Um, so yeah, so it kind of
depends on your, um, like on the approach. So when we trained our language model, um, because the
initial, like, the spring training set, because you have, um, a very, like, a lot of tokens,
a large corpus that you train on, that's usually the most extensive step. So for us,
in our early experiments, we trained that out for, like, 24 hours on one, uh, GPU, essentially,
and then usually the fine tuning, um, and the final training set would be a lot faster, so maybe
it would be like, uh, one hour, depending on the training set size, um, in the open AI paper,
because they trained an even larger model on even more data, they trained for about a month.
So it can really, if you scale that up, um, that can take a lot longer, but then fine tuning would
probably, um, take similar long, maybe a bit longer, because, because model is steeper, um,
and recently, kind of in the fast AI library, um, with some ongoing experience from computer vision,
they've kind of integrated some methods where you can train, um, which are kind of, um,
this, like, one technique called, uh, super convergence, that has shown, um, some good results for
computer vision, where you essentially have a, uh, particular learning rate schedule, and you
train a model with a very high learning rate, um, and in doing that, and if you're kind of careful
about how you use the schedule, you can get to very high performance, uh, very fast, um, so using,
like a technique like that might also, um, for language modeling, might also allow you to train your
language models, um, yeah, significantly faster. With word embeddings, we've kind of, you know,
those of matured and we've gotten to the point that there are, you know, multiple options for
word embedding vectors that you can more or less use interchangeably. Is that the case for
these pre-trained language models? Like, can you use either the open AI language models or what
you've published kind of interchangeably in building out models and just experiment to see what
works best for you? Or are they, are the, the language models more, you know, intertwined to
how they are intended to be used? Um, yeah, so in a sense, you can still, um, you can basically kind
of use them interchangeably at this point, um, although so we've recently seen, or there's been
a recent paper which showed, okay, there's maybe some, um, differences in the representation that
these models learn so that on, on some tasks, actually having, um, using, like an LSTM in contrast
with a transformer as language model might actually give you better performance, but then you have
the transformer which might be maybe more efficient than the LSTM because it doesn't require this
temporal dependency, but this is again, like still very preliminary work, um, so I don't think, yeah,
so I don't think at this point we really have a great understanding yet for which type of tasks,
these particular models work, um, work really well, um, but I think what you want, so as long as you
have a model, like a language model that is very expressive, that achieves kind of a good, um,
performance on your data, then I think generally you would probably expect to get similar
performance, and then probably going forward, there might be some particular guidance on maybe
if you have a sort of, like, reasoning class or, um, something which requires maybe more
long term, um, dependencies, maybe you won't rather want to use a transformer, um, but that's
still a bit early stage to give kind of these more, um, more concrete rules of them.
If we cover it all, there is a cover on ULM fit, uh, and, you know, and or, you know, what's next in
kind of that research direction? Um, yeah, so, so I think in that, in that research direction,
I think there's, like, a lot of interesting directions, so first I don't think we've yet,
kind of come to the ceiling of what we can achieve, um, using language models in NLP,
so I think, so I personally think that, um, because of the results I've seen so far are really
encouraging and really significant improvements of what we've seen before. Um, people are going to,
um, start using more and more instead of using pre-treatment meetings, using, um,
pre-treatment language models in their own applications. So I think these will really kind of
become a, uh, a mainstay in NLP going forward, at least for the foreseeable future. Um,
and in, in that, I think there's still a lot of questions on how you actually, um, how you can,
kind of compress and capture as much information in your language model as before,
as possible, what are like the best language models to use, how you can incorporate these in that.
So just, um, kind of, uh, maximizing the benefit from using this language modeling task,
I think is kind of a need to, like, need a direction that will still or should still give us some
boost in some tasks. Um, and then probably in the, in the more long term, um, and, and then kind
of maybe tied to the former, um, just understanding what actually, um, this or how far we can actually
go using these language models, um, because language modeling might, um, while it's still, while it
gives us a boost on some tasks, it's still a similar objective to what we've been doing with,
where to back. And just kind of this idea of language modeling of just, um, predicting the next word
based on its previous words, um, is while it should give you kind of some, um, to capture some
relations in text, there's still a lot of things that it can't capture. So it's, um, yeah, for
instance, it's really hard to capture, um, kind of more like real world knowledge, actually about
how the, how the world works or how different, um, kind of entities or things in the, in the real
world, um, kind of relate to each other. It's really hard, it's often not mentioned in text, and then
only like, uh, very rarely. So it's really hard to capture something like that, which would be
useful for us like quest answering or reading comprehension with just using language model. So I
think one really interesting direction going forward is really how we can, um, incorporate, um,
information that allows us to do better sort of reasoning and natural language understanding,
either in order to augment our language model, or, um, as additional forms of pre-training maybe,
or maybe additional forms of knowledge has, um, like in the memory from a knowledge base,
or through some other module that we can then, um, use or leverage in our, uh, downstream tasks.
Well, Sebastian, thanks so much for taking the time to chat about this. Uh, it's really interesting
work you're doing, and I'm looking forward to kind of keeping up with how it evolves.
Uh, cool and congrats. Yeah, thanks for having me. Thank you.
All right, everyone, that's our show for today. For more information on Sebastian or any of the
topics covered in this episode, visit twimmelai.com slash talk slash 195.
If you're a fan of the show, and you haven't already done so, or you're a new listener, and you
like what you hear, please head over to your Apple or Google podcast app, and leave us a five-star
rating and review. Your reviews help inspire us to create more and better content, and they help
new listeners find the show. Thanks again to our friends at IBM for their sponsorship of this
episode. Be sure to check out IBM developer at IBM.biz slash MLAI podcast. As always,
thanks so much for listening, and catch you next time.
