WEBVTT

00:00.000 --> 00:15.240
Hello and welcome to another episode of Twomble Talk, the podcast where I interview interesting

00:15.240 --> 00:19.960
people, doing interesting things in machine learning and artificial intelligence.

00:19.960 --> 00:30.800
I'm your host, Sam Charrington.

00:30.800 --> 00:34.720
For today's show, we'll be taking a break from our strategy data conference series coverage

00:34.720 --> 00:40.520
and presenting a special conversation recorded yesterday with Jeremy Howard, founder and researcher

00:40.520 --> 00:46.000
at fast.ai, accompanying many of our listeners are quite familiar with due to their popular

00:46.000 --> 00:48.240
deep learning course.

00:48.240 --> 00:51.900
The podcast is being released today in conjunction with the company's announcement of version

00:51.900 --> 00:59.040
1 of their fast AI library at the inaugural PyTorch DevCon in San Francisco.

00:59.040 --> 01:02.080
Jeremy and I cover a ton of ground in this conversation.

01:02.080 --> 01:05.920
Of course, we dive into the new version of the library and explore why it's important

01:05.920 --> 01:07.480
and what's changed.

01:07.480 --> 01:12.160
We also explore the unique way in which it was developed and what it means for the future

01:12.160 --> 01:14.520
of the fast.ai courses.

01:14.520 --> 01:19.480
What's more, Jeremy shares a ton of great insights and lessons learned in this conversation,

01:19.480 --> 01:22.960
not to mention a bunch of really interesting sounding papers.

01:22.960 --> 01:24.880
I know you'll enjoy this one.

01:24.880 --> 01:29.360
Alright, let's do it.

01:29.360 --> 01:34.360
Alright everyone, I am on the line with Jeremy Howard.

01:34.360 --> 01:38.600
Jeremy is founder and researcher with fast AI.

01:38.600 --> 01:41.840
Jeremy, welcome to this week in machine learning and AI.

01:41.840 --> 01:43.560
Thank you very much.

01:43.560 --> 01:46.400
It is great to finally get you on the show.

01:46.400 --> 01:55.880
As you know, the tool more community in particular, our meet up has really been enjoying the

01:55.880 --> 01:57.600
deep learning for coders course.

01:57.600 --> 02:05.520
We brought a group of folks through that course earlier this summer and spun up a second

02:05.520 --> 02:08.640
group to work on that course.

02:08.640 --> 02:12.240
And then you've recently announced the machine learning course and we've got a group starting

02:12.240 --> 02:16.320
soon that will be working on that course together.

02:16.320 --> 02:20.160
So we are big fans of fast AI.

02:20.160 --> 02:25.280
The interview I did with Rachel, that was Twomble Talk 138 back in May, remains one of

02:25.280 --> 02:28.720
the most popular ones shows to date.

02:28.720 --> 02:30.400
So I am super excited.

02:30.400 --> 02:35.400
So I'm the pleasure of all mine and let me just say thank you so much for everything

02:35.400 --> 02:42.200
that you're doing for the machine learning and AI community and thanks so much for spending

02:42.200 --> 02:44.080
time looking at our little course.

02:44.080 --> 02:47.000
I'm really grateful.

02:47.000 --> 02:52.640
It is a great course and we'll jump into all the reasons why I am sure.

02:52.640 --> 02:57.480
But before we do that, I want to talk a little bit about your background.

02:57.480 --> 03:02.520
So you've been former president and chief scientist at Kaggle.

03:02.520 --> 03:08.000
You founded several startups in this space, your published researcher as well as on the

03:08.000 --> 03:12.000
faculty at U.S.F. and you're unabashedly Ph.D.

03:12.000 --> 03:13.000
Less.

03:13.000 --> 03:14.000
That's true.

03:14.000 --> 03:19.960
Unlike Rachel, who is facetly Ph.D. or something.

03:19.960 --> 03:26.280
So I want to start out by talking about, I want to give you a chance to more fully walk

03:26.280 --> 03:35.040
folks through your background, but also maybe end up at the Ph.D. I think has come to,

03:35.040 --> 03:43.840
this is a space where the Ph.D. carries a lot of weight and I'm curious your thoughts

03:43.840 --> 03:48.400
on kind of navigating the space and doing all that you've done without one and what it

03:48.400 --> 03:52.000
says to other folks that want to participate in the space.

03:52.000 --> 03:57.000
Yeah, I mean, I understand where the question is coming from Sam because it's definitely

03:57.000 --> 04:03.400
always been intimidating and terrifying for me doing what I'm doing without an academic

04:03.400 --> 04:04.920
background.

04:04.920 --> 04:11.040
And I can't begin to tell you how deeply surprised I was when I discovered I was actually pretty

04:11.040 --> 04:15.640
good at machine learning because I had, no, literally I had no idea, like you have to

04:15.640 --> 04:17.640
realize I, I mean, sort of answer your question.

04:17.640 --> 04:25.640
I started my career when I was 18 at a, at a strategy corporate strategy company called

04:25.640 --> 04:34.160
McKinsey and Company, I got a degree in a Bachelor of Arts in Philosophy, but I didn't

04:34.160 --> 04:38.840
turn up to any lectures because I was working full time, so I just turned up to exams.

04:38.840 --> 04:43.920
So I really, even though in theory I have a degree, I haven't really studied anything

04:43.920 --> 04:47.240
much in a formal way.

04:47.240 --> 04:53.240
So I'm kind of very unfamiliar with the university system and the academic system overall.

04:53.240 --> 04:59.200
And so I spent, you know, eight years in corporate strategy and then 10 years running a couple

04:59.200 --> 05:06.160
of companies, which were somewhat related to machine learning, but one of them was an

05:06.160 --> 05:09.440
email provider called FastMail, which is still pretty popular.

05:09.440 --> 05:15.520
And you know, the machine learning I did there was like, you know, try to improve the spam

05:15.520 --> 05:17.440
detector mainly.

05:17.440 --> 05:22.840
And then the other one was an insurance pricing company called Optimal Sisions, which

05:22.840 --> 05:28.960
was more about operations research and optimization and simulation than it was about predictive

05:28.960 --> 05:29.960
modeling.

05:29.960 --> 05:36.880
So at the end of all that, when I entered my first Kaggle competition, because I wanted

05:36.880 --> 05:43.880
to like finally learn to do machine learning properly, and I won it, I was just like, that

05:43.880 --> 05:48.640
can't be right, because I knew that it was an econometrics competition and there was

05:48.640 --> 05:54.120
a lot of PhDs and professors and econometrics in the competition and I just thought, that's

05:54.120 --> 06:02.760
really weird that some kind of self-taught hack, you know, business guy could possibly

06:02.760 --> 06:06.280
beat these guys at predicting time series.

06:06.280 --> 06:11.920
I just thought that was, yeah, deeply weird and surprising and very pleasing.

06:11.920 --> 06:15.720
I mean, it was the start of a new career for me because when you find out you're good

06:15.720 --> 06:20.680
at something, you kind of, you know, at least in my case, I went all in on trying to be as

06:20.680 --> 06:22.680
good as I could be.

06:22.680 --> 06:28.760
I didn't realize that your career at Kaggle began with competing in a competition.

06:28.760 --> 06:29.760
Yeah.

06:29.760 --> 06:37.440
So at that point, it was just Anthony Goldblum and he had, you know, hired a contractor

06:37.440 --> 06:46.000
to kind of hack together a site based on his idea of creating a competition platform.

06:46.000 --> 06:54.640
And yeah, I came across it because I went to the R meetup in Melbourne thinking that would

06:54.640 --> 07:00.480
be a good way to learn to do machine learning properly and somebody there told me, oh, there's

07:00.480 --> 07:05.560
a good way to learn machine learning would be to try one of these Kaggle competitions.

07:05.560 --> 07:11.320
And so, yeah, so I did much to my surprise, you know, I won my first one and I think I also

07:11.320 --> 07:15.600
won my second one and I got to the top of the leaderboard and so by the time the next

07:15.600 --> 07:20.960
meetup came along, Anthony was actually at the meetup and somebody introduced me and

07:20.960 --> 07:27.360
by that stage, he knew who I was because I was the highest ranked Kaggleer and I ended

07:27.360 --> 07:30.400
up becoming the first investor in the company.

07:30.400 --> 07:38.120
And then I rewrote the whole platform from scratch as a volunteer because it turned out

07:38.120 --> 07:41.160
it wasn't really going to be scalable enough to do what was needed to be done.

07:41.160 --> 07:46.000
And yeah, I ended up becoming an equal partner in the company.

07:46.000 --> 07:48.920
So that was, yeah, that was a cool way to get involved.

07:48.920 --> 07:51.120
Yeah, that's that's pretty amazing.

07:51.120 --> 07:57.520
And people often kind of poo poo Kaggle competitions and they do with comments like, oh, it's

07:57.520 --> 08:01.520
not really the real world, all the hard stuff is done for you.

08:01.520 --> 08:04.640
I imagine you have a slightly different to the Kaggle competition.

08:04.640 --> 08:09.840
So these are people who, these are people who have heard third hand and it's, yeah, what's

08:09.840 --> 08:10.840
your take on that?

08:10.840 --> 08:17.440
A lot of the exercises and the deep learning for coders course are, hey, just go find

08:17.440 --> 08:19.960
a data set on Kaggle and do some stuff with it.

08:19.960 --> 08:27.880
So you obviously believe pretty strongly in that as a way to learn.

08:27.880 --> 08:28.960
Yeah, I do.

08:28.960 --> 08:34.560
You know, that's a great question, actually, because you know, like with many of these

08:34.560 --> 08:39.320
troubling myths, there's just enough of an element of truth in it to make it sound

08:39.320 --> 08:45.800
believable, you know, which is like, obviously, there is a lot to building a data product

08:45.800 --> 08:52.880
or solving a data-oriented problem that is not about creating a more predictive, predictive

08:52.880 --> 08:53.880
model.

08:53.880 --> 08:55.760
So yes, that's true.

08:55.760 --> 09:01.040
But then, you know, taking that premise that the, therefore, competing in Kaggle competitions

09:01.040 --> 09:06.400
as a waste of time is a totally ridiculous leap.

09:06.400 --> 09:13.240
It's actually, if you want to do a good job of your data product, having a predictive

09:13.240 --> 09:17.880
model that's good at predicting things is actually a pretty good, pretty important part

09:17.880 --> 09:19.200
of that.

09:19.200 --> 09:26.880
Furthermore, Bryman, who developed the Random Forest amongst other things, had this

09:26.880 --> 09:33.640
fantastic two cultures of statistics paper in which he talked about how incredibly

09:33.640 --> 09:40.480
powerful a good predictive model is is providing a platform for data interpretation for understanding

09:40.480 --> 09:41.480
your data.

09:41.480 --> 09:45.280
And that's one of the things that I spend a lot of time on on the new machine learning

09:45.280 --> 09:46.480
course.

09:46.480 --> 09:51.720
So if you're going to kick us on a Kaggle competition, you need to understand the data

09:51.720 --> 09:54.480
really, really well.

09:54.480 --> 09:59.040
And so if you're good at understanding data really, really well and building models that

09:59.040 --> 10:03.600
are very predictive, and you also have to be really good at software engineering,

10:03.600 --> 10:06.960
in a very practical way, because every idea you come up with, you have to be able to

10:06.960 --> 10:12.160
code it in a way that actually works correctly and that's tested.

10:12.160 --> 10:15.680
And then you need to make sure it's maintainable because you've got to patch lots and things

10:15.680 --> 10:19.000
on top of each other over the three months of the competition.

10:19.000 --> 10:26.280
So realistically, if you can get a good result on a Kaggle competition, you have exercised

10:26.280 --> 10:31.840
many of the pieces necessary for machine learning in the real world.

10:31.840 --> 10:37.800
The other pieces like productionising that model, that's a whole different skill, which

10:37.800 --> 10:43.480
you can practice elsewhere, or skills like figuring out what problem to solve and what

10:43.480 --> 10:45.680
constraints there are to solve that problem.

10:45.680 --> 10:49.680
I mean, that's kind of more of a management consulting corporate strategy kind of issue,

10:49.680 --> 10:52.000
which again, there are resources for that.

10:52.000 --> 10:56.800
But yeah, for the part that is really about machine learning, Kaggle competitions are

10:56.800 --> 10:58.720
a great exercise.

10:58.720 --> 11:05.180
You made an interesting comment in there that winning a Kaggle competition and building

11:05.180 --> 11:13.400
models in general is very much about really understanding the data.

11:13.400 --> 11:20.600
And in the deep learning for coders, part one course, you kind of, my personal experience,

11:20.600 --> 11:28.600
we kind of sail through the first three lessons that were focused on building object detectors

11:28.600 --> 11:30.080
and things like that.

11:30.080 --> 11:39.120
And then we got to this really interesting set of lessons around building, using machine

11:39.120 --> 11:43.480
learning for more tabular data.

11:43.480 --> 11:49.000
And the promise of that is that actually kind of the opposite of what you said, that

11:49.000 --> 11:59.120
previously, in order to really work with traditional enterprise data, a data scientist really

11:59.120 --> 12:05.360
had to be a domain expert and understand those domains and the data sources very deeply.

12:05.360 --> 12:11.440
The impression a lot of us took from what we learned in applying deep learning to tabular

12:11.440 --> 12:18.680
data is that we didn't have to be as deeply ingrained in that particular field because the

12:18.680 --> 12:22.800
network would learn a lot of the patterns for us.

12:22.800 --> 12:26.280
How do you reconcile those two perspectives?

12:26.280 --> 12:32.080
Well, the first thing to note is there's a difference between getting a pretty good model

12:32.080 --> 12:34.280
and winning a Kaggle competition.

12:34.280 --> 12:38.760
So winning a Kaggle competition, you actually have to do everything better than everybody

12:38.760 --> 12:42.600
else because if you don't, somebody else will do that thing better than you and will

12:42.600 --> 12:43.600
beat you.

12:43.600 --> 12:48.880
So you know, Kaggle, it's definitely true that Kaggle solutions, like the top 10 Kaggle

12:48.880 --> 12:54.280
solutions are going to be very over engineered for practical purposes.

12:54.280 --> 13:01.800
But what they show you is kind of the full menu of things which can improve your model

13:01.800 --> 13:05.880
and you can kind of pull each one out one at a time to figure out how important each

13:05.880 --> 13:07.080
piece is.

13:07.080 --> 13:14.680
So doing some amount of feature engineering is almost always helpful and doing a lot is

13:14.680 --> 13:17.600
going to be necessary to actually winning a competition.

13:17.600 --> 13:26.880
Having said that, it's definitely true that deep learning allows us to do less feature

13:26.880 --> 13:33.560
engineering and still get as good results as we might of with a GBM or a random forest

13:33.560 --> 13:34.560
or something.

13:34.560 --> 13:41.560
And there's been some interesting papers and talks from folks like Instacart and Pinterest

13:41.560 --> 13:45.800
who have switched from GBM based methods in their companies.

13:45.800 --> 13:52.920
So Pinterest switched from GBM to deep learning, for example, for their home page, you know,

13:52.920 --> 13:55.760
kind of main home page recommendation feed.

13:55.760 --> 14:01.720
And they've talked about how doing that made their engineering process less complex because

14:01.720 --> 14:07.520
they didn't need to do as much feature engineering as they did before, the architecture kind

14:07.520 --> 14:10.080
of did more for them.

14:10.080 --> 14:14.960
So you generally, you know, with deep learning, you don't have to bucketize your continuous

14:14.960 --> 14:18.080
variables, which some kinds of model require.

14:18.080 --> 14:22.800
You don't have to create interactions, which some kinds of model require.

14:22.800 --> 14:28.240
You don't have to do special tricks to allow it to extrapolate further, which you certainly

14:28.240 --> 14:31.200
need for any tree based method.

14:31.200 --> 14:34.440
So yeah, I think both of those things are true at the same time.

14:34.440 --> 14:43.480
Yeah, certainly the course in our group created a number of fans of the whole technique of

14:43.480 --> 14:44.480
entity embeddings.

14:44.480 --> 14:45.480
Oh, yeah.

14:45.480 --> 14:46.480
Yeah.

14:46.480 --> 14:47.480
Yeah.

14:47.480 --> 14:48.480
Very underappreciated.

14:48.480 --> 14:55.120
I mean, the idea that you can use a mixture of categorical and continuous variables kind

14:55.120 --> 14:58.800
of without thinking about it is great.

14:58.800 --> 15:02.880
And you can use them for time series, you can use them for tabular, you can use them

15:02.880 --> 15:06.280
for collaborative filtering, you can use them for text.

15:06.280 --> 15:08.520
I mean, they pop up everywhere.

15:08.520 --> 15:14.640
And actually, I'll be interested to see your feedback when you try it.

15:14.640 --> 15:22.280
But the new Fast AI version one library makes that ridiculously easy.

15:22.280 --> 15:28.240
Like now you can basically create a model with a mixture of categorical and continuous variables

15:28.240 --> 15:34.240
in, you know, and train it in three or four lines of code, because we're really trying

15:34.240 --> 15:40.400
to, yeah, make that that idea of entity embeddings be as natural to use as possible.

15:40.400 --> 15:47.680
Well, I appreciate you helping us get to talking about the new library, which you're going

15:47.680 --> 15:53.600
to be announcing tomorrow today for those who listen to the podcast the day it's released

15:53.600 --> 15:56.400
because we're going to try and get this out tomorrow.

15:56.400 --> 15:58.440
Let's talk about the library.

15:58.440 --> 16:04.600
So Fast AI as a company is focused on research, it's focused on software, it's focused

16:04.600 --> 16:05.600
on courses.

16:05.600 --> 16:09.960
We talked a little bit about all of that with Rachel.

16:09.960 --> 16:13.440
This is really about the software.

16:13.440 --> 16:14.440
Yeah.

16:14.440 --> 16:19.720
And this is the long term vision of what Fast.ai is doing.

16:19.720 --> 16:25.880
And I'm a bit sloppy about this myself, but our company is Fast.ai and the software is

16:25.880 --> 16:28.720
just Fast.ai.

16:28.720 --> 16:35.600
So Fast.ai, you know, it's all about getting to a point where people can use deep lining

16:35.600 --> 16:40.360
to help them do whatever it is they're doing really easily.

16:40.360 --> 16:43.560
And to allow anybody to do that, we actually have to get to a point where you don't have

16:43.560 --> 16:49.360
to use code at all because only something like 0.1% of the global population knows how

16:49.360 --> 16:50.680
to code.

16:50.680 --> 16:56.240
So kind of the Fast.ai library is step one along that path to kind of require less and less

16:56.240 --> 17:01.720
code to be able to do more and more things, more and more reliably, more and more quickly.

17:01.720 --> 17:08.480
Since you grounded us out on terminology, another area that's somewhat confusing is that

17:08.480 --> 17:19.440
you're announcing what you call the V1 version one of the Fast.ai library, but it supersedes

17:19.440 --> 17:26.880
a previous version of the library that was also written in PyTorch, which itself supersedes

17:26.880 --> 17:33.240
a previous version of the library that was written in TensorFlow.

17:33.240 --> 17:38.680
So when we talk about the V1 library, we're talking about the new thing.

17:38.680 --> 17:39.680
Yeah.

17:39.680 --> 17:45.480
So just to go back through that, so the previous thing was version 0.7.

17:45.480 --> 17:52.000
And that never got a version one tag because I wrote it knowing that it was not going

17:52.000 --> 17:56.160
to be that particularly close to the final form of what we wanted.

17:56.160 --> 18:01.000
It was kind of something that I hacked together that was good enough for the needs of the

18:01.000 --> 18:08.920
initial PyTorch-based courses, because as you won't know, PyTorch is really not suitable

18:08.920 --> 18:13.200
on its own as a first library for deep learning because you have to write your own training

18:13.200 --> 18:18.440
loop and you have to do a lot of things yourself, and it's an amazingly great library,

18:18.440 --> 18:22.720
but it's kind of missing that carous style layer on top.

18:22.720 --> 18:31.720
So we kind of built the amount we needed to get people going, but it was certainly not

18:31.720 --> 18:38.920
a really carefully integrated, fully thought through library.

18:38.920 --> 18:47.080
So here we are, 18 months later, we've rewritten the entire thing from scratch in a way which

18:47.080 --> 18:51.280
is explicitly designed to provide a long-term foundation for all the software we built

18:51.280 --> 18:52.440
for now on.

18:52.440 --> 18:57.960
And then before that was something that was, yeah, a sad on top of carous and TensorFlow,

18:57.960 --> 19:00.960
and I don't think we ever even called that a library or gave it a name.

19:00.960 --> 19:07.920
It was only a kind of bunch of little utilities that's sad on top of carous, to smooth over

19:07.920 --> 19:10.520
some of the slightly rough edges.

19:10.520 --> 19:13.600
So yeah, that's been kind of the progression.

19:13.600 --> 19:18.920
And so it's really the first time where we're saying, okay, you know what, this software

19:18.920 --> 19:24.880
is actually now, we think pretty damn good, we're pretty damn proud of it, we think people

19:24.880 --> 19:31.200
should start using it for, you know, basically anybody who's trying to train neural nets, we

19:31.200 --> 19:35.360
think this is the best software out there for doing that.

19:35.360 --> 19:43.120
And specifically for kind of production use as opposed to education or rapid prototyping?

19:43.120 --> 19:50.720
Yeah, and I know there are certainly Fortune 500 companies using FastAI 0.7, but you know,

19:50.720 --> 19:55.880
they're nearly entirely Fortune 500 companies where they have a lot of their technical

19:55.880 --> 20:00.480
staff who have done the courses and got introduced to it that way and are kind of happy to dig

20:00.480 --> 20:04.440
into the source code as necessary to make it work the way they wanted to.

20:04.440 --> 20:12.080
So yeah, now this is, you know, we think this is totally ready for everybody to use.

20:12.080 --> 20:18.760
It's also like a good time for it because it's aligned with the PyTorch version 1 release.

20:18.760 --> 20:22.720
I mean, we're a little bit ahead of them, so we're actually using the PyTorch version

20:22.720 --> 20:32.040
1 pre-release now and when the final release comes out, we'll be obviously supporting that.

20:32.040 --> 20:38.240
But PyTorch version 1 has done a lot of work on the productionization story with the

20:38.240 --> 20:43.360
integration of Cafe 2 and, you know, the kind of full support of Owen and X and stuff

20:43.360 --> 20:44.360
like that.

20:44.360 --> 20:50.760
So because any FastAI model is also a PyTorch model, you can use all of that new functionality

20:50.760 --> 20:54.960
to serve your FastAI models directly.

20:54.960 --> 21:01.920
You made an interesting post about the methodology behind developing the new library that was

21:01.920 --> 21:07.920
actually somewhat controversial on the twimmel slack.

21:07.920 --> 21:14.760
If I remember the gist of it, it was that the library was built, just kind of built from

21:14.760 --> 21:23.360
the ground up relative to 0.7 and specifically built kind of using or around the Jupyter

21:23.360 --> 21:28.560
notebooks that will eventually become part of the course or maybe the part 2 version

21:28.560 --> 21:29.560
of the course.

21:29.560 --> 21:32.000
Yeah, talk a little bit about that process.

21:32.000 --> 21:34.960
Yeah, okay, so this is actually pretty fascinating.

21:34.960 --> 21:39.880
I'm glad you boarded up because it's not something I've had a chance to write about yet.

21:39.880 --> 21:43.120
So this will be the first kind of proper description of this.

21:43.120 --> 21:45.160
Here's what happened.

21:45.160 --> 21:49.280
The first thing is I just love working in Jupyter notebooks.

21:49.280 --> 21:55.800
I am, you know, I've been coding for gosh, you know, well over 30 years.

21:55.800 --> 22:02.160
I just, in many different languages, but I just write better code faster when I'm in

22:02.160 --> 22:04.560
a notebook.

22:04.560 --> 22:09.320
And so I like that, but it's, you know, writing stuff in a notebook is not something that's

22:09.320 --> 22:14.920
really been well suited to creating, you know, reusable modules in the past.

22:14.920 --> 22:17.360
So kind of that was issue number one.

22:17.360 --> 22:23.280
Issue number two is that we've got this kind of unique thing we do when there's an in-person

22:23.280 --> 22:28.320
course on where I make a big room available every day during the course.

22:28.320 --> 22:31.920
And I tell everybody all the students, I'm going to be working in this room.

22:31.920 --> 22:37.000
If anybody else wants to work with me, you are most welcome to do so.

22:37.000 --> 22:41.760
And so during the course, we have a whole bunch of fast AI students, you know, hanging out

22:41.760 --> 22:43.160
working together.

22:43.160 --> 22:49.000
And generally I've got my work being projected onto a big screen so people can kind of watch.

22:49.000 --> 22:53.840
And one of the most common things I hear from the students is, gosh, I learned so much

22:53.840 --> 23:00.640
watching you test and refactor and build, which I can't, I don't get out of the course,

23:00.640 --> 23:04.040
you know, like in the course, everything kind of just appears all done.

23:04.040 --> 23:08.960
And I think one of the things people surprised me is how much I screw things up, you know,

23:08.960 --> 23:11.880
I'm just constantly making mistakes and fixing them.

23:11.880 --> 23:17.440
And, you know, everything is a lot harder than people perhaps realize based on what they

23:17.440 --> 23:18.680
see in the course.

23:18.680 --> 23:24.800
So the question I often get is like, how can we learn to kind of develop software, you

23:24.800 --> 23:28.440
know, machine learning software, the way you're developing it?

23:28.440 --> 23:34.800
So what I did was I decided the next version of the software version, one of fast AI,

23:34.800 --> 23:40.040
which we're releasing today, I am going to build in notebooks where each stage, I'm

23:40.040 --> 23:42.320
going to like, I'm going to leave all the cells in there.

23:42.320 --> 23:45.360
So you can see every stage of that progression.

23:45.360 --> 23:49.400
So you can see what I built first and then how I refactored it and then what I checked

23:49.400 --> 23:51.480
it against and so forth.

23:51.480 --> 23:57.840
So as a result, there's this series of, I don't know, something like 14 or 15 notebooks,

23:57.840 --> 24:02.360
which if you go through the whole thing, you end up writing the entire fast AI library

24:02.360 --> 24:03.360
yourself.

24:03.360 --> 24:04.520
Wow.

24:04.520 --> 24:13.600
And so that 14 notebooks, and that'll eventually be the part two course, which the current

24:13.600 --> 24:17.680
part two course is kind of taking you into the internals of the old library.

24:17.680 --> 24:21.160
So this is a new approach to doing that for the new library.

24:21.160 --> 24:22.160
Yeah.

24:22.160 --> 24:27.200
And in the process, you're going to have to learn about a lot of recent research results

24:27.200 --> 24:33.600
because as you're aware, the, you know, even the 0.7 and particularly 1.0 integrates

24:33.600 --> 24:38.520
a lot of recent research results to kind of make them directly available.

24:38.520 --> 24:44.200
So as you go through part two, you're going to be like learning about, you know, what

24:44.200 --> 24:49.400
paper is this particular line of code based on and why has it done that way and so forth.

24:49.400 --> 24:55.360
So yeah, you're, you're both learned a lot about modern kind of cutting edge deep learning

24:55.360 --> 25:00.920
research, but also about the process of building machine learning software.

25:00.920 --> 25:05.440
And so what we did is like really simple, but it worked really well is from time to time

25:05.440 --> 25:09.840
as I was kind of building a notebook and I could create a function that I kind of think,

25:09.840 --> 25:13.320
okay, that's probably going to be useful to use again.

25:13.320 --> 25:17.680
So I just put a little comment at the top and my comment was always a hash export.

25:17.680 --> 25:21.520
And anytime I had a little thing running in the background that anytime it saw a cell that

25:21.520 --> 25:26.880
said hash export, it would chuck it into a Python module.

25:26.880 --> 25:31.400
And so I could then build the next notebook on top of the previous notebook by simply importing

25:31.400 --> 25:34.760
the previous notebooks, auto generated module.

25:34.760 --> 25:38.960
And so then at the end of all that, we then went through a manual process of kind of

25:38.960 --> 25:42.520
figuring out like, okay, well, what have we ended up with here and we kind of structured

25:42.520 --> 25:49.520
things into a carefully decoupled set of independent modules, which ended up being

25:49.520 --> 25:53.880
fast AI and wrote all the documentation and so on and so forth.

25:53.880 --> 26:00.600
But you know, it really, you can really see the final result is close to identical to

26:00.600 --> 26:03.000
what you'll see in those notebooks.

26:03.000 --> 26:08.600
One of the issues that was raised, and I think I raised questions along this line, well,

26:08.600 --> 26:12.880
I'm sure I raised questions along this line as well and our slack is, you know, that sounds

26:12.880 --> 26:20.440
like a very kind of organic way of coming up with the library that may not lend itself

26:20.440 --> 26:28.320
well to kind of the door ability and, you know, well architected APIs that you would want

26:28.320 --> 26:30.840
if you're going to be using this for a general purpose.

26:30.840 --> 26:31.840
Like how do you?

26:31.840 --> 26:33.160
That's a great question.

26:33.160 --> 26:36.920
So that's how I used to think too.

26:36.920 --> 26:47.080
And about 20 years ago, I got maybe a bit less, I got super interested in test driven development.

26:47.080 --> 26:51.040
And for those that aren't familiar with it, the kind of basic idea of test driven development

26:51.040 --> 26:55.720
is you kind of write a bunch of tests, you make each one pass one at a time.

26:55.720 --> 27:01.680
Every time you find you've got some duplicate code, you refactor it into a class or a function

27:01.680 --> 27:06.000
and you try to figure out what it is that class or functions doing based on that duplicate

27:06.000 --> 27:08.240
code and give it a name.

27:08.240 --> 27:11.320
And you keep on repeating this again and again and again.

27:11.320 --> 27:15.120
And I kind of just played around with it because a few people I respected thought it was

27:15.120 --> 27:16.120
great.

27:16.120 --> 27:18.040
I thought it was really weird.

27:18.040 --> 27:21.640
And one of my key issues was what you just said, which is, well, what point do you actually

27:21.640 --> 27:26.480
design a durable thought for API?

27:26.480 --> 27:33.080
Much to my surprise, I discovered that this process of testing and refactoring naturally

27:33.080 --> 27:37.960
ended up just through having to refactor out these abstractions and then abstractions

27:37.960 --> 27:42.400
on top of those and then abstractions on top of those and carefully naming things.

27:42.400 --> 27:49.160
Yeah, like I ended up with better APIs than I'd ever written when I'd carefully designed

27:49.160 --> 27:50.160
them.

27:50.160 --> 27:53.480
And you know, I should mention I've spent a lot of time designing APIs.

27:53.480 --> 27:56.440
I wrote a number of MVC modules.

27:56.440 --> 28:00.680
I was the Pell 6 chair for all the data functionality in Pell 6.

28:00.680 --> 28:07.560
So I like explicitly was writing RFCs for that API, you know, I've written a lot of

28:07.560 --> 28:14.040
APIs in my time and I've discovered that this organic approach, I end up with better APIs.

28:14.040 --> 28:19.120
I end up with, I end up with no stuff in them which actually doesn't need to be there.

28:19.120 --> 28:23.040
So unnecessary complexity is entirely avoided because you only build what you need.

28:23.040 --> 28:30.880
So I end up with less kind of unnecessary and over complex abstractions.

28:30.880 --> 28:36.400
So I kind of end up with something that's concise and neat and I don't know, like when

28:36.400 --> 28:37.640
you try it out, see what you think.

28:37.640 --> 28:44.160
I'm really, really proud of this API, like I found that we have almost identical four

28:44.160 --> 28:50.080
lines of code to build a NLP model versus a computer vision model versus a tabular model

28:50.080 --> 28:53.400
versus a collaborative filtering model.

28:53.400 --> 28:59.200
You know, it's, it's been a, I found it a real pleasure to work in frankly.

28:59.200 --> 29:01.400
Definitely looking, looking forward to that.

29:01.400 --> 29:07.960
Yes, since you mentioned your work with Pearl, I will admit that in working with the 0.7

29:07.960 --> 29:13.760
version of the API, at some point I grumbled in our slide channel that, you know, some

29:13.760 --> 29:19.400
of the, you know, the attribute and function names were seemed unnecessarily terraced.

29:19.400 --> 29:23.000
And, you know, Jeremy must have been a Pearl developer in a former life.

29:23.000 --> 29:26.400
And someone said, oh, yeah, he was actually a Pearl committer.

29:26.400 --> 29:27.400
Yeah.

29:27.400 --> 29:34.640
And I mean, I think it's fair to say also that some of them were unnecessarily terraced.

29:34.640 --> 29:41.080
So we've actually changed from a rule of thumb of symbol parts should try to be three

29:41.080 --> 29:44.880
letters or less to kind of symbol parts should try to be five letters or less.

29:44.880 --> 29:48.320
And that's actually made a big difference to be able to say train rather than TRN and

29:48.320 --> 29:50.360
valid rather than VAL.

29:50.360 --> 29:56.000
Um, it's actually worse than that though, I'm not just a, a keen Pearl programmer, I'm also

29:56.000 --> 30:01.560
a keen kind of J and APL programmer where everything is one symbol.

30:01.560 --> 30:07.400
So we should expect like, uh, deltas and upside down deltas and Greek letters, creeping

30:07.400 --> 30:08.400
it.

30:08.400 --> 30:09.400
Not quite, right?

30:09.400 --> 30:14.240
Because, um, I mean, I could talk about this for hours, but I'm, I'm just fascinated

30:14.240 --> 30:21.120
in notation and my kind of hero here is Kenneth Iverson, the cheering award winner who wrote

30:21.120 --> 30:26.880
the classic cheering award lecture notation as a tool for thought.

30:26.880 --> 30:33.960
And in it, he describes how good notation helps you, you know, do good work, do good

30:33.960 --> 30:38.960
research, come up with new ideas, implement things more quickly and easily.

30:38.960 --> 30:46.640
And good notation as he defines it is very, very different to what kind of pairpate Python

30:46.640 --> 30:47.640
looks like.

30:47.640 --> 30:53.880
Good notation is something where you, you know, you're kind of I, um, can quickly look

30:53.880 --> 30:59.960
at one part of the screen and capture the gist of gist of what's going on.

30:59.960 --> 31:03.760
So it's about using vertical space really carefully.

31:03.760 --> 31:10.480
It's about kind of having common idioms be easily recognizable.

31:10.480 --> 31:16.160
And so I would say to get to that point where you've got notation as a tool for thought,

31:16.160 --> 31:24.440
you kind of have to slightly give up on Python's goal of being immensely friendly, even to

31:24.440 --> 31:30.120
the most new programmers and say, okay, now I actually want people to invest a little

31:30.120 --> 31:36.800
bit of time learning this, but the promise will be that if you do so, you will be immensely

31:36.800 --> 31:39.440
more productive as a result.

31:39.440 --> 31:45.600
So you know, we definitely don't go anywhere near to the APL and J level of that kind of

31:45.600 --> 31:46.600
premise.

31:46.600 --> 31:49.200
I don't know less it is, it is the premise.

31:49.200 --> 31:55.520
I don't know of J, but APL was a language that I studied for a few weeks and my first

31:55.520 --> 32:02.080
like computer languages survey classes at school, and I remember that those weird keyboards

32:02.080 --> 32:03.080
very well.

32:03.080 --> 32:09.840
So J is kind of an ASCII version of that largely written by Kenneth Iverson's son, actually,

32:09.840 --> 32:13.520
because Kenneth Iverson wrote the original APL, but you've got to realize like APL goes

32:13.520 --> 32:19.400
back to, I mean, it was originally written as a mathematical notation, not as a programming

32:19.400 --> 32:20.920
language.

32:20.920 --> 32:25.520
So, you know, it came out, that came out in the late 50s, the implementations came out

32:25.520 --> 32:33.720
in the early 60s, still today many big and successful companies choose to use APL for their

32:33.720 --> 32:38.200
most important stuff, particularly, you know, big hedge funds.

32:38.200 --> 32:43.280
So the fact that this is a notation that has survived many, many decades longer than any

32:43.280 --> 32:48.040
other widely in use language today, I think it tells you a lot about how extraordinarily

32:48.040 --> 32:49.360
it was designed.

32:49.360 --> 32:53.840
And it's something everybody should study it at some point, because it's, you know,

32:53.840 --> 33:01.080
you just learned so much from seeing this totally independent language evolution path.

33:01.080 --> 33:05.480
I did not realize it was still in wide use.

33:05.480 --> 33:07.880
Oh, yeah, absolutely.

33:07.880 --> 33:16.280
So you know, maybe to digress a little bit from the library, you know, you've already

33:16.280 --> 33:23.280
mentioned a few papers, and one of the hallmarks of the library is, you know, that you have

33:23.280 --> 33:30.320
identified these, in some cases, relatively obscure papers that have outsized results in

33:30.320 --> 33:32.400
terms of training efficiency.

33:32.400 --> 33:33.920
I love doing that.

33:33.920 --> 33:36.760
And clearly, clearly you do.

33:36.760 --> 33:43.000
The question, and maybe why it's a digression is, you know, how do you keep up with all of

33:43.000 --> 33:47.160
the stuff that's happening in the space and, you know, to the extent that you're able

33:47.160 --> 33:52.200
to drop in these obscure references in both code and conversation?

33:52.200 --> 33:53.200
Hmm.

33:53.200 --> 34:01.960
Twitter, basically, you know, the Twitter machine learning community is really terrific.

34:01.960 --> 34:06.120
And you can quickly get, you know, become a part of it.

34:06.120 --> 34:12.280
If you go to my Twitter page, so I am Jeremy P Howard, if you go to my profile, you can

34:12.280 --> 34:18.000
click on my likes, and you can immediately see, you know, what, who am I liking things

34:18.000 --> 34:19.000
from?

34:19.000 --> 34:22.720
And you'll see that there's just a long list of people posting about, basically, mainly

34:22.720 --> 34:24.680
about deep learning.

34:24.680 --> 34:27.960
So you can start following the people you find interesting.

34:27.960 --> 34:32.240
And it's just a really rich, highly technical community.

34:32.240 --> 34:39.280
And so the other thing I do is I explicitly look out for the stuff that other people are

34:39.280 --> 34:40.280
missing.

34:40.280 --> 34:45.000
Or rather than kind of trying to say, oh, here's a really popular paper everybody's talking

34:45.000 --> 34:46.000
about.

34:46.000 --> 34:52.520
Instead, I kind of look out for like, oh, here's a extremely good model somebody's built,

34:52.520 --> 34:56.480
but nobody's talking about this paper, because that's where I get to do something that other

34:56.480 --> 34:57.480
people aren't doing.

34:57.480 --> 34:59.560
So I get to kind of contribute more.

34:59.560 --> 35:04.760
And so I particularly interested in looking at, you know, I always read the winning blog posts

35:04.760 --> 35:11.400
from Kaggle competitions, I look at the, if you go to any machine learning or deep learning

35:11.400 --> 35:18.200
workshop website, you'll generally find posted papers from the people that won that competition.

35:18.200 --> 35:24.640
They are at a astonishing source of tricks, but those things never generally get published

35:24.640 --> 35:26.240
anywhere else.

35:26.240 --> 35:30.000
So and they're never kind of, they don't appear in search results.

35:30.000 --> 35:31.600
You have to go and find them.

35:31.600 --> 35:35.280
But in like these workshops where people say, here's how I won, you know, this academic

35:35.280 --> 35:38.320
competition's object detection path.

35:38.320 --> 35:41.360
They'll generally say, you know, these are all the other papers we looked at.

35:41.360 --> 35:42.560
These are the things we tried.

35:42.560 --> 35:43.560
These are the things we worked.

35:43.560 --> 35:46.000
These are the things that didn't work.

35:46.000 --> 35:47.600
So that's, that's a really great trick.

35:47.600 --> 35:53.560
Oh, that's an interesting hack to, to focus your efforts on papers where there's a competition

35:53.560 --> 35:54.560
involved somewhere.

35:54.560 --> 35:56.720
Yeah, focus on stuff that works.

35:56.720 --> 36:00.920
And you know, even that's much more controversial than it should be, because this is kind of

36:00.920 --> 36:08.520
a view in the academic community that researchers don't really need to worry about, you know,

36:08.520 --> 36:13.760
the latest and greatest tweaks, you know, and techniques.

36:13.760 --> 36:16.880
But the truth is, you know, people building deep learning models are doing it because

36:16.880 --> 36:20.840
they're trying to make something that's more accurate than somebody else's model or trains

36:20.840 --> 36:25.600
faster than somebody else's model, you know, we're not just doing it because of the mathematical

36:25.600 --> 36:27.000
purity of it or something.

36:27.000 --> 36:33.600
So, you know, furthermore, if you're claiming that your model, you know, your architecture,

36:33.600 --> 36:37.440
your training method, your optimizer is better than some other thing, you know, you have

36:37.440 --> 36:39.600
to compare it to that other thing.

36:39.600 --> 36:45.120
And if you don't know how to actually train a good modern model, then your experiments

36:45.120 --> 36:46.800
are pretty much meaningless anyway.

36:46.800 --> 36:52.920
So, you know, I think it's really important for practitioners to be familiar with, you

36:52.920 --> 36:58.040
know, in practice, how are people actually training these most accurate and fastest

36:58.040 --> 37:00.040
models?

37:00.040 --> 37:06.000
At the recent deep learning in Daba event in South Africa, Jeff Dean made a comment

37:06.000 --> 37:11.920
about how, you know, one of his secrets to success, if you will, is as opposed to going

37:11.920 --> 37:21.240
deep on fewer papers, going shallower on, you know, many more papers, he thinks is

37:21.240 --> 37:26.840
a preferred approach, you know, do you ascribe to something similar or do you have other

37:26.840 --> 37:29.760
kind of, you know, hacks for learning and keeping up?

37:29.760 --> 37:30.760
Yeah.

37:30.760 --> 37:31.760
I think that's basically right.

37:31.760 --> 37:37.080
I mean, like when you think about it, if you don't use that approach, then, you know,

37:37.080 --> 37:41.120
you know, think of like your knowledge is a weighted average of the kind of the inputs

37:41.120 --> 37:42.480
you're putting into it, right?

37:42.480 --> 37:46.720
And so, anything that you don't read or look at gets away to zero.

37:46.720 --> 37:50.000
So you can't like, you know, it's kind of easy to pretend like, oh, I didn't look at

37:50.000 --> 37:55.520
it so it doesn't count, but no, you know, you're supposed to put 98% there and 2% there

37:55.520 --> 37:58.240
and 0% on these other thousand things.

37:58.240 --> 38:03.160
So yeah, I think it's definitely worth going broad, but I'd also say like, I look out

38:03.160 --> 38:08.240
for the themes, you know, and so for me, one of the most important theme at the moment

38:08.240 --> 38:14.360
is transfer learning beats everything all the time.

38:14.360 --> 38:18.640
And almost nobody's really doing, you know, not totally nobody, but almost nobody's

38:18.640 --> 38:21.960
actually doing research about transfer learning.

38:21.960 --> 38:26.360
Most papers don't actually apply their techniques to transfer learning.

38:26.360 --> 38:28.240
So you know, here for me, here's a theme, right?

38:28.240 --> 38:33.960
So every time I see anything that I think, oh, that, you know, what if you added transfer

38:33.960 --> 38:38.400
learning to that or, you know, what if I use that transfer learning technique in this

38:38.400 --> 38:41.200
different field that doesn't currently use transfer learning?

38:41.200 --> 38:47.960
So like our ULM fit model, which is the state of the art for text classification, pretty

38:47.960 --> 38:53.200
much everywhere it's been looked at now in multiple languages.

38:53.200 --> 38:57.760
That was just me saying, how come people never use transfer learning properly in NLP?

38:57.760 --> 38:59.160
You know, I should try it.

38:59.160 --> 39:03.560
And yeah, it's kind of like following that, that, that theme.

39:03.560 --> 39:08.680
And I won't go deeper on that because I do have a conversation with Sebastian scheduled

39:08.680 --> 39:11.160
to dig into that sometime soon.

39:11.160 --> 39:12.160
Oh, good.

39:12.160 --> 39:18.880
Maybe back to the, the library and the course, I've heard some, I don't know if they're

39:18.880 --> 39:19.880
rumors.

39:19.880 --> 39:24.520
You know, there's something that you wrote gave folks the impression that the new part

39:24.520 --> 39:30.960
one course is kind of turning away from this top down approach and taking more of a bottom

39:30.960 --> 39:32.800
up approach.

39:32.800 --> 39:33.800
Is that true?

39:33.800 --> 39:38.240
And before you answer that, I will say that, you know, so we did these weekly study

39:38.240 --> 39:45.080
group sessions, kind of like virtual sessions where we all got online and talked about, you

39:45.080 --> 39:46.840
know, what we were learning in the course.

39:46.840 --> 39:52.240
And we spent a ton of time almost every week talking about top down and just getting

39:52.240 --> 39:53.240
used to it.

39:53.240 --> 39:59.920
It's very different from the way folks learn, but very effective at kind of getting you

39:59.920 --> 40:00.920
pulled in quickly.

40:00.920 --> 40:01.920
Yeah.

40:01.920 --> 40:03.880
I mean, it depends a lot on your background, right?

40:03.880 --> 40:11.400
I mean, you know, in a lot of kind of more MBA style stuff, it's often, it is often a

40:11.400 --> 40:16.920
lot more top down, a lot of kind of executive education is a lot more top down.

40:16.920 --> 40:21.360
You know, but most people who are kind of coding have come from more of a, yeah, maybe

40:21.360 --> 40:27.000
come from more of a computer science, academic background, which is very bottom up.

40:27.000 --> 40:34.680
So no, we're not stepping away from the top down approach at all because it's, you know,

40:34.680 --> 40:42.200
all of the educational research I've studied, which is a lot, shows that most, by far the

40:42.200 --> 40:49.240
majority of people learn better with the top down approach, even though it requires to

40:49.240 --> 40:54.160
some extent unlearning how to learn based on the bottom up approach that we kind of get

40:54.160 --> 41:00.160
used to from school and university, I will say the machine learning course, the introduction

41:00.160 --> 41:05.960
to machine learning course is it's still pretty top down like lesson one, you know, the

41:05.960 --> 41:10.600
first cell is here's a random forest, we've trained it and here's the result.

41:10.600 --> 41:14.720
And then we kind of gradually dig into like how do we interpret that result and how to

41:14.720 --> 41:18.520
be actually build that tree and by kind of lesson seven, we write our own random forest

41:18.520 --> 41:25.800
from scratch in pure Python, but I don't know, yeah, I think because the people I was originally

41:25.800 --> 41:36.120
doing that course for were master's students, I possibly was a little more, I don't know,

41:36.120 --> 41:40.560
go a little bit deeper a little bit earlier so that they didn't get too uncomfortable

41:40.560 --> 41:43.280
with the kind of change of style.

41:43.280 --> 41:49.200
I'm looking for the details here since you mentioned that machine learning course, of course

41:49.200 --> 41:55.480
has been kind of, you know, it's been around in a pre-release state, I guess for quite

41:55.480 --> 42:02.840
some time, but since it's been formally released, we've got a study group that some folks

42:02.840 --> 42:07.040
in the community are organizing that will be starting very soon.

42:07.040 --> 42:14.640
In fact, lesson one is going to be on Sunday, October 7th at three o'clock GMT and they're

42:14.640 --> 42:18.880
going to continue that for, you know, 12 weeks on Sundays at that time.

42:18.880 --> 42:24.760
Well, let me encourage people to get into that even if, even for folks who haven't done

42:24.760 --> 42:30.120
the deep learning course yet, like you can do the two in either order, they both are designed

42:30.120 --> 42:36.960
to work well together, but it's definitely true that people who study with a group on

42:36.960 --> 42:41.200
average have more effective learning outcomes and more importantly tend to stick with it

42:41.200 --> 42:44.840
for longer than people who study independently.

42:44.840 --> 42:50.440
So yeah, I think that sounds like a fantastic initiative and I hope people listening join

42:50.440 --> 42:51.440
in.

42:51.440 --> 42:58.640
Well, we had a great group that did the deep learning part one course together this summer

42:58.640 --> 43:08.320
and in fact, most of the, you know, this course and we've got another session of the deep

43:08.320 --> 43:13.440
learning course that's going now, I'll elaborate on that in a second, but these are all kind

43:13.440 --> 43:17.280
of being run by folks that came together to do this deep learning course together.

43:17.280 --> 43:22.320
So it's been awesome for us on that deep learning course.

43:22.320 --> 43:29.720
So we had a group that started three, three weeks ago, I think they've had three sessions,

43:29.720 --> 43:36.160
a second group on the deep learning for coders part one course.

43:36.160 --> 43:38.160
We made some tweaks to how we did it.

43:38.160 --> 43:43.160
The first time we did it, we did, we were planning for a weekly pace.

43:43.160 --> 43:47.320
We held that through about the fourth lesson and then we went to buy weekly because it

43:47.320 --> 43:49.400
gets a lot harder.

43:49.400 --> 43:50.400
Yeah.

43:50.400 --> 43:51.400
Yeah.

43:51.400 --> 43:56.040
This time they started doing a bi-weekly pace all the way through, but one of the things

43:56.040 --> 44:02.120
that through a little bit of a wrench in our plan, a good wrench, is that you announced

44:02.120 --> 44:09.200
that for the new course, which is going to be starting towards the end of October, although

44:09.200 --> 44:17.320
we noted that the notebooks haven't been written yet, yeah, I should probably do that.

44:17.320 --> 44:24.440
For this new course, previously the options for taking this course were you could take

44:24.440 --> 44:30.360
it in person and you offered a bunch of different types of scholarships or apply to take

44:30.360 --> 44:40.640
it remotely during the live course time or wait a few months and catch it via video.

44:40.640 --> 44:47.560
But you just announced with some pretty interesting kind of background commentary that you've

44:47.560 --> 44:53.560
decided to make the remote course available to anyone who wants to sign up for it.

44:53.560 --> 44:54.560
Yeah.

44:54.560 --> 44:58.480
As long as, you know, the only thing I ask is that you follow a long live, which means

44:58.480 --> 45:05.840
if you're in a annoying time zone for our evening US time classes that you get up and

45:05.840 --> 45:06.840
do it anyway.

45:06.840 --> 45:13.760
I want people involved to be contributing to the real-time chat during the course.

45:13.760 --> 45:20.520
But other than that request, yeah, it's open to anybody who has at least a year of coding

45:20.520 --> 45:26.560
experience and definitely looking forward to seeing how this little experiment works out.

45:26.560 --> 45:27.760
I think it's going to be really cool.

45:27.760 --> 45:32.680
Yeah, that was one of the questions that folks had was whether the folks that are in kind

45:32.680 --> 45:37.520
of off-time zones, whether the videos would be made available any sooner so that they

45:37.520 --> 45:43.320
could, you know, participate via forums and groups like ours, but watch the videos at

45:43.320 --> 45:46.120
a slightly more convenient time.

45:46.120 --> 45:51.400
I mean, it's, I mean, I can't technically stop anybody from doing that, I guess, because

45:51.400 --> 45:56.640
I mean, it's on YouTube live and the videos appear on YouTube live, but I would certainly

45:56.640 --> 46:02.560
much prefer people to actually be there during the class because that's where we're having

46:02.560 --> 46:04.440
the discussion.

46:04.440 --> 46:10.240
You can ask me questions, you know, while the lesson's going on, you know, I think that's

46:10.240 --> 46:14.000
what makes it a really rich and interesting experience.

46:14.000 --> 46:23.760
We started this course, a second session of the part one course through this really

46:23.760 --> 46:25.800
a great wrench in our plan.

46:25.800 --> 46:31.360
And so what we've decided to do is we'll kind of continue for the part one course, the

46:31.360 --> 46:39.680
first couple of lessons, but as soon as that, the new course starts, which I think you

46:39.680 --> 46:46.400
said was the 22nd of October, if that date holds, we will be kind of switching gears and

46:46.400 --> 46:50.920
working on the new course, the new library, et cetera, and everyone's really excited

46:50.920 --> 46:51.920
about that.

46:51.920 --> 46:56.600
And people do need to sign up to participate in fast AI live, so I'm sure you can provide

46:56.600 --> 46:58.880
the link there that they can do that with.

46:58.880 --> 47:04.400
All right, so we'll include that in the show notes and then the sign up for the meetup

47:04.400 --> 47:09.800
and for our study groups, that'll be at twimmalei.com slash meetup.

47:09.800 --> 47:18.240
So maybe kind of jumping back to the library, one of the things that you are kind of

47:18.240 --> 47:23.320
including in your announcement about the new library is some benchmarking that you did

47:23.320 --> 47:26.560
relative to the Kieres library.

47:26.560 --> 47:29.920
Can you talk a little bit about that and what you showed?

47:29.920 --> 47:36.440
Yeah, so I mean, I'd love for people to help do more benchmarking, I only had time to

47:36.440 --> 47:38.040
quickly throw something together.

47:38.040 --> 47:43.160
And I will say it's been a while since I really used Kieres, so I tried to find documentation

47:43.160 --> 47:49.000
on best practices, but there actually is, I couldn't find anything post 2016 in terms

47:49.000 --> 47:54.200
of official, here's how to do transfer learning in Kieres, so it's possible that my Kieres

47:54.200 --> 47:59.760
approach is not as optimal as it could be, but basically, yeah, I tried to use the classic

47:59.760 --> 48:10.040
Kaggle Dog's versus Cats data set to transfer and learn a ResNet 34 and just to attract how

48:10.040 --> 48:13.880
many lines of code it took, and I tried to optimize my Kieres lines of code as best as

48:13.880 --> 48:19.960
I could, how long it took to train and what accuracy I could get.

48:19.960 --> 48:25.600
And yeah, I was very pleased to find that the first AI library code was something like

48:25.600 --> 48:33.040
a fifth as many lines and I was quite a bit faster and quite a bit more accurate, which

48:33.040 --> 48:38.400
is, yeah, it's really all about the little, you know, all the stuff we curate both in terms

48:38.400 --> 48:44.440
of papers that we incorporate into the defaults and also some unpublished research, which

48:44.440 --> 48:51.000
we hope to publish later this year around ways to do this kind of training better.

48:51.000 --> 48:59.080
One of the things that I did notice about the new library is the code to do fine-tuning

48:59.080 --> 49:07.200
got very compact to the 0.7, can you maybe, you know, talk a little bit about that and

49:07.200 --> 49:12.320
more broadly, like the big, the differences that folks, you know, should expect to see

49:12.320 --> 49:14.560
when they start working with the new library.

49:14.560 --> 49:19.400
So, you know, Perl, since we've talked about Perl has Larry Wall who wrote it has this

49:19.400 --> 49:24.720
motto, which is, make the easy things easy and make the hard things possible.

49:24.720 --> 49:30.000
And so, to me, it's not just about making the easy things easy, but make the important

49:30.000 --> 49:34.520
things easy and there's nothing more important than transfer learning.

49:34.520 --> 49:41.200
So yeah, we tried very, very hard to make it, you know, basically transfer learning is

49:41.200 --> 49:44.960
kind of the thing you get automatically and for free.

49:44.960 --> 49:49.840
So if you create a model by default, you'll get some pre-trained weights and by default,

49:49.840 --> 49:57.280
you'll get something that is set up for discriminative fine-tuning and set up for, you know, layer

49:57.280 --> 50:01.080
freezing and, you know, all the stuff you need that you'll know from the course if you've

50:01.080 --> 50:02.080
done it.

50:02.080 --> 50:08.440
Yeah, but then, you know, the nice thing is that all of the power of PyTorch, we very

50:08.440 --> 50:12.440
intentionally make as close to the surface as possible.

50:12.440 --> 50:17.400
So for example, you know, we integrate very closely with PyTorch and we use a lot of

50:17.400 --> 50:19.680
PyTorch APIs directly.

50:19.680 --> 50:24.880
So for example, a fast AI data set is a PyTorch data set.

50:24.880 --> 50:30.880
The fast AI data loader is a wrapper for the PyTorch data loader and in our docs, which

50:30.880 --> 50:33.760
actually we should talk about our docs a bit because it's one of the things I'm most

50:33.760 --> 50:39.560
proud of, but in our docs, everywhere that we are using a PyTorch object, you'll see

50:39.560 --> 50:44.680
that there is actually a hyperlink directly to the PyTorch documentation for that class

50:44.680 --> 50:45.680
or function.

50:45.680 --> 50:50.040
So, you know, the two libraries are really nicely integrated.

50:50.040 --> 50:51.280
Oh, that's awesome.

50:51.280 --> 50:58.320
I'd love to hear you talk a little bit about the docs with the 0.7 library for the most

50:58.320 --> 51:00.200
part, the code was the docs.

51:00.200 --> 51:01.720
Yeah, there was no docs.

51:01.720 --> 51:09.000
And in fact, someone from our, from the tumble community, Kai contributed some docs and

51:09.000 --> 51:12.200
was told, well, you know, hold off on this because we're going to do better.

51:12.200 --> 51:14.800
So what have you done with the version 1 library?

51:14.800 --> 51:18.480
Well, you won't be shocked to hear this, but the entire set of documentation is written

51:18.480 --> 51:19.760
as Jupyter notebooks.

51:19.760 --> 51:21.520
Oh, nice.

51:21.520 --> 51:29.000
And so that means that every page in the documentation, you can actually run it in your own Jupyter

51:29.000 --> 51:32.000
notebook and see the experiments.

51:32.000 --> 51:37.700
So that all of the documentation is designed to be a very, you know, every, every module

51:37.700 --> 51:43.760
starts with an overview of like, hey, here's some code you can run right now to, you know,

51:43.760 --> 51:48.240
build this kind of model or to do this kind of data orientation.

51:48.240 --> 51:54.200
We wrote our entire, a kind of computer vision library from scratch in PyTorch, full

51:54.200 --> 51:58.680
new set of transformations, every transformation, therefore, is documented as, you know, a line

51:58.680 --> 52:04.080
of code in the, in the docs that actually, you know, prints out examples of that data

52:04.080 --> 52:06.520
orientation shows you the pictures.

52:06.520 --> 52:12.680
So then what we've written is we've written a whole new documentation framework, which

52:12.680 --> 52:18.520
takes those docs and turns them into a, into a website.

52:18.520 --> 52:22.520
And that website, for example, it does things like any, any, any place you've used back

52:22.520 --> 52:26.080
to text to kind of, you know, say, hey, this is, this is code.

52:26.080 --> 52:31.920
This is a symbol, it will automatically try and find anything in that code that represents

52:31.920 --> 52:39.720
a PyTorch or, first AI class or function or object automatically generate a hyperlink

52:39.720 --> 52:40.720
to that.

52:40.720 --> 52:46.360
So you can basically write, you know, standard mark down cells, you can standard code

52:46.360 --> 52:54.560
cells, inputs, outputs, pictures, everything will then automatically generate this fully

52:54.560 --> 53:02.920
hyperlinked table of contents, searchable documentation with, you know, embedded pictures

53:02.920 --> 53:04.680
and all that kind of thing.

53:04.680 --> 53:10.000
And then, yeah, you can go and try it out yourself by actually loading up that, that notebook

53:10.000 --> 53:11.760
locally and trying it out.

53:11.760 --> 53:15.440
So I think it's, as far as I know, it's the first time anything like this has been done

53:15.440 --> 53:20.240
and I think it's going to be super helpful for this kind of thing we say to people, which

53:20.240 --> 53:23.480
is how you should be experimenting, you should be running code, you should be trying things

53:23.480 --> 53:24.480
out.

53:24.480 --> 53:28.920
So the documentation, you know, is stuff that you can try out as experiments.

53:28.920 --> 53:32.320
That sounds, that sounds tremendous.

53:32.320 --> 53:39.520
The, I'm not aware of any, I've never seen code distributed as Jupyter notebooks.

53:39.520 --> 53:42.240
That does sound very cool.

53:42.240 --> 53:49.200
Someone mentioned that you tweeted something about some extensions to Jupyter that you

53:49.200 --> 53:52.800
were creating, is that what that's referring to?

53:52.800 --> 53:57.640
Yeah, they're not actually extensions, it's a, it's a, it's a framework of, it's a bit

53:57.640 --> 54:02.600
like a, if you've ever used things, it's kind of syncs on steroids, you know, about

54:02.600 --> 54:03.600
for notebooks.

54:03.600 --> 54:08.640
So basically something where you feed in Jupyter notebooks and it spits out a nice document

54:08.640 --> 54:10.640
documentation website for you.

54:10.640 --> 54:11.640
Hmm.

54:11.640 --> 54:16.800
And one of the things that comes up occasionally is, yeah, folks that want to develop in Jupyter

54:16.800 --> 54:25.200
notebooks and then productize, productionalize that code are, are you using techniques in, in

54:25.200 --> 54:32.720
this process that could be, also used to take a Jupyter notebook and, you know, maybe

54:32.720 --> 54:38.080
identify parts that are annotated as being, you know, that kind of the export thing that

54:38.080 --> 54:39.280
you're referring to.

54:39.280 --> 54:41.480
And then put those into a production module.

54:41.480 --> 54:43.200
Yeah, absolutely.

54:43.200 --> 54:47.600
So, you know, as we go through part two, which I guess will be kind of first and second

54:47.600 --> 54:51.760
quarters of 2019, that's kind of what we'll be doing is we'll be seeing how to, how to

54:51.760 --> 54:53.640
go through that process.

54:53.640 --> 54:59.120
You know, for me, I like automating things, the right amount, which is like not too much

54:59.120 --> 55:00.920
and not too little.

55:00.920 --> 55:07.920
So for me, this kind of exporting cells is a great way to kind of gradually build up much

55:07.920 --> 55:11.240
of the API that you want, but then the piece where it's like, okay, let's create a really

55:11.240 --> 55:17.080
nicely designed decoupled set of modules with clear dependency paths and all that kind

55:17.080 --> 55:18.080
of stuff.

55:18.080 --> 55:25.200
That's something I did, actually Sylvan and I did together, you know, manually and carefully.

55:25.200 --> 55:30.360
So I'm not really into kind of necessarily directly turning that Jupyter notebook into

55:30.360 --> 55:36.520
a module, but we certainly got some, yeah, use some simple tools to help us semi automate

55:36.520 --> 55:37.520
that process.

55:37.520 --> 55:38.720
Okay.

55:38.720 --> 55:45.600
What are some other highlights that folks that are familiar with the.7 library should

55:45.600 --> 55:49.800
expect to see or should be on a lookout for with version one?

55:49.800 --> 55:50.800
Yeah.

55:50.800 --> 55:56.800
So this new data augmentation slash computer vision library is something which you should

55:56.800 --> 56:05.600
definitely check out because it's, it's actually something which the, the PyTorch team helped

56:05.600 --> 56:11.800
make sure that PyTorch was explicitly performance accelerated for exactly the things we needed

56:11.800 --> 56:12.800
for it.

56:12.800 --> 56:21.840
So it's very fast and it actually ends up with much higher quality outputs than any existing

56:21.840 --> 56:27.480
data augmentation library because normally if you do like a rotate and then a zoom, for

56:27.480 --> 56:31.560
example, it basically interpolates on top of interpolation and you end up with these kind

56:31.560 --> 56:37.520
of fuzzier and fuzzier images where else we use an approach which actually keeps all of

56:37.520 --> 56:41.720
the sharpness of the image throughout the process.

56:41.720 --> 56:49.040
We also have some, this allows us to actually incorporate as default some kinds of transformation

56:49.040 --> 56:55.880
which pretty much nobody else is using, particularly perspective warping, which is a really important

56:55.880 --> 57:01.960
transformation in practice but it really requires this special kind of library to make it work

57:01.960 --> 57:02.960
effectively.

57:02.960 --> 57:08.640
So I'd say definitely check out the computer vision transformation library we've built.

57:08.640 --> 57:17.540
I'd also say have a look at the really good support for NLP transfer learning.

57:17.540 --> 57:25.720
Quite a few of the community on the fuzzier forums have been trained out the ULM fit techniques

57:25.720 --> 57:29.960
of basically transfer learning for NLP in non-English languages.

57:29.960 --> 57:37.600
In the last week or two, I've heard from two Polish students that they just won the

57:37.600 --> 57:42.000
Polish main Polish academic competition.

57:42.000 --> 57:46.680
Somebody else has just got the state of the art of a German and then a few months ago,

57:46.680 --> 57:48.840
somebody got the state of the art of a tie.

57:48.840 --> 57:55.280
Like in the German example, the chap on the forum basically said, hey, I tried it.

57:55.280 --> 57:56.480
I trained it for 20 minutes.

57:56.480 --> 57:59.880
The first thing that popped out was the immediate state of the art of a German.

57:59.880 --> 58:06.560
So for NLP, you can basically do stuff with this library that you will get better results

58:06.560 --> 58:10.520
than anybody's published before, kind of trivially.

58:10.520 --> 58:15.000
And we actually include, if you look in the examples directory of the repo, just click

58:15.000 --> 58:20.280
on the text example that'll actually show you how to do it end to end.

58:20.280 --> 58:27.360
And certainly, very much easier support for tabular data sets that's there is definitely

58:27.360 --> 58:28.960
worth checking out.

58:28.960 --> 58:33.560
It's not that it's doing anything that you couldn't do with 0.7, but it's now super, super

58:33.560 --> 58:34.560
easy.

58:34.560 --> 58:35.560
Yeah.

58:35.560 --> 58:39.720
And I think also, just check out the documentation framework because we do plan to extract

58:39.720 --> 58:46.640
that out into a separate independent project at some time soon-ish and I'd love to see

58:46.640 --> 58:53.600
more people trying to build Jupyter-based documentation systems because I think it's

58:53.600 --> 58:58.560
really helpful to your users to be able to say, hey, all of the documentation is code

58:58.560 --> 59:01.440
that you can run yourself right now and try it out.

59:01.440 --> 59:09.560
So the current library is very much focused on supervised learning and as we've discussed

59:09.560 --> 59:12.120
transfer learning.

59:12.120 --> 59:20.200
Do you see the library moving into models like reinforcement learning or unsupervised

59:20.200 --> 59:22.240
learning?

59:22.240 --> 59:27.440
Reinforcement learning, no, at least not in the short to medium term.

59:27.440 --> 59:32.880
I'm still unconvinced that we really know what we're doing as a community when it comes

59:32.880 --> 59:34.680
to reinforcement learning.

59:34.680 --> 59:40.520
The good results we're seeing are largely because of hacks that basically involve throwing

59:40.520 --> 59:44.120
ridiculous amounts of hardware at a problem.

59:44.120 --> 59:50.360
So I still want to spend some time doing some deep research into reinforcement learning

59:50.360 --> 59:55.280
to try and find ways to make it work better on smaller amounts of resources and on kind

59:55.280 --> 01:00:02.640
of more practical problems, you know, not many people need to win Dota or go.

01:00:02.640 --> 01:00:08.520
Unsupervised learning definitely kind of, I don't really believe that there's such a thing

01:00:08.520 --> 01:00:14.640
as unsupervised learning, but I do believe very much in what Jan LaCouden calls self-supervised

01:00:14.640 --> 01:00:21.480
learning, which is coming up with a supervised learning model which doesn't require explicit

01:00:21.480 --> 01:00:22.760
labels.

01:00:22.760 --> 01:00:29.720
And so for example, ULM fit is entirely based on something called a language model.

01:00:29.720 --> 01:00:34.560
A language model is just a model which predicts the next word in a piece of text.

01:00:34.560 --> 01:00:38.160
So you don't need any labels, you just need some text and you can build a model that

01:00:38.160 --> 01:00:42.240
tries to predict the next word after every sequence.

01:00:42.240 --> 01:00:47.760
So that's a self-supervised model because it uses the input data itself to generate labels.

01:00:47.760 --> 01:00:55.840
So I'm very keen to continue to provide richer and richer and more and more varied self-supervised

01:00:55.840 --> 01:01:01.480
learning support because that allows you to do transfer learning even in situations where

01:01:01.480 --> 01:01:04.720
you may not have explicit labels.

01:01:04.720 --> 01:01:10.200
The idea of self-supervised learning as you described it is related to another recurring

01:01:10.200 --> 01:01:16.680
theme that comes up from time to time on the podcast and that is incorporating model-based

01:01:16.680 --> 01:01:22.600
approaches into deep learning models, like physics-based approaches or other depending on

01:01:22.600 --> 01:01:23.600
the domain.

01:01:23.600 --> 01:01:28.160
Is that something that you are interested in, you're seeing and do you see it?

01:01:28.160 --> 01:01:31.040
How do you see it working with the library?

01:01:31.040 --> 01:01:33.480
Oh yeah, so very much so.

01:01:33.480 --> 01:01:35.320
It's something I really enthusiastic about.

01:01:35.320 --> 01:01:40.920
I mean, a great example of a model-based approach is the convolutional neural network.

01:01:40.920 --> 01:01:47.320
So if you start out with the observation that your data is auto-currelated along some

01:01:47.320 --> 01:01:52.320
dimensions, so for example, in an image, one pixel tends to be similar to the pixel above

01:01:52.320 --> 01:01:55.400
it and to the left of it and to the right of it and below it.

01:01:55.400 --> 01:02:01.800
So you've got two-dimensional autocorrelation and so a convolution is an operation explicitly

01:02:01.800 --> 01:02:08.800
architected to allow it to be easier to identify those kind of autocorrelated patterns.

01:02:08.800 --> 01:02:14.640
So like I see, it is a great example of a model-based or model inspired architecture.

01:02:14.640 --> 01:02:19.480
Then there's more recently, there's been a lot of, maybe not a lot, quite a few good

01:02:19.480 --> 01:02:26.480
examples of places where domain experts have come up with tweaks to an architecture which

01:02:26.480 --> 01:02:32.040
allow it to, you know, more easily represent the kinds of things that are most common

01:02:32.040 --> 01:02:33.280
in that domain.

01:02:33.280 --> 01:02:38.480
So for example, there was a couple of papers, one of which was by Saunderdeeleman talking

01:02:38.480 --> 01:02:44.680
about group convolutions, which is basically saying, hey, if you're doing something like

01:02:44.680 --> 01:02:52.040
pathology images or satellite images, which are rotation invariant, here is an architecture

01:02:52.040 --> 01:02:57.720
that is explicitly designed so that rotation invariance is built into the variant architecture.

01:02:57.720 --> 01:03:03.960
I've seen similar things in models for physics, where the kind of basic invariances or constraints

01:03:03.960 --> 01:03:09.000
of what would be required in those physics modules are, models are built into the architecture.

01:03:09.000 --> 01:03:14.600
So with fast AI, we've tried to make that kind of thing pretty easy to add because there's

01:03:14.600 --> 01:03:20.800
this idea of a custom head, you can very easily create a custom head for your architecture

01:03:20.800 --> 01:03:27.800
which might contain some of those ideas, or you can create a custom module, a custom

01:03:27.800 --> 01:03:34.680
NN module, you know, a PyTorch model, and pass that directly to a fast AI learner, and

01:03:34.680 --> 01:03:38.680
we've kind of provided lots of hooks for you to make it easy to add all the additional

01:03:38.680 --> 01:03:42.520
fast AI features into your model.

01:03:42.520 --> 01:03:47.960
So yeah, I think we've, you know, tried to support what we can there and maybe people who

01:03:47.960 --> 01:03:54.240
are interested in specific domains that already have some kind of model inspired architectures,

01:03:54.240 --> 01:03:58.440
hopefully we'll be able to start contributing some of their approaches.

01:03:58.440 --> 01:04:03.240
Maybe to start to wrap things up, I hear you're writing a book on machine learning, what's

01:04:03.240 --> 01:04:04.240
that going to cover?

01:04:04.240 --> 01:04:06.880
Okay, so we've got two books coming up.

01:04:06.880 --> 01:04:10.800
Why does a book with Professor Terence Pa about machine learning?

01:04:10.800 --> 01:04:17.040
The first few chapters are available in an early draft form online, and it's basically

01:04:17.040 --> 01:04:18.920
inspired by the course.

01:04:18.920 --> 01:04:24.120
So Terence Pa, if your listeners may recognize the name, he's a pretty famous computer scientist

01:04:24.120 --> 01:04:28.840
who built the antler parser generator, which I guess is kind of the most widely used parser

01:04:28.840 --> 01:04:35.120
generator around, and he spent decades becoming, say, the world's leading expert, or certainly

01:04:35.120 --> 01:04:40.600
one of them in parser generators, and he's now turning his attention to machine learning,

01:04:40.600 --> 01:04:44.200
and he's a colleague here at the University of San Francisco.

01:04:44.200 --> 01:04:49.440
He actually sat in on my machine learning course when I taught it, and said, oh, I like

01:04:49.440 --> 01:04:50.440
that so much.

01:04:50.440 --> 01:04:52.760
I think we should write a book based on it.

01:04:52.760 --> 01:04:59.520
So yeah, so we're doing that, and everything Terence does, he does exceptionally deeply and

01:04:59.520 --> 01:05:00.920
exceptionally well.

01:05:00.920 --> 01:05:04.880
So if you check out some of the early material, you will see there's a lot of beautiful

01:05:04.880 --> 01:05:08.960
visualizations and really nice descriptions.

01:05:08.960 --> 01:05:16.720
The second book is with Sylvia Guga, Sylvia, some of your listeners may recognize as being

01:05:16.720 --> 01:05:22.840
an exceptional student from an earlier course who repeatedly wrote brilliant material that

01:05:22.840 --> 01:05:28.400
I featured in the course, and since then he's gone on to do some really cool research

01:05:28.400 --> 01:05:35.080
around transfer learning, and AWS were kind enough to actually sponsor him as the first

01:05:35.080 --> 01:05:42.360
FastAI scholar in residence, so he's been working full-time with us for most of this year,

01:05:42.360 --> 01:05:50.480
and he's going to help me write a book about the FastAI Deep Learning Library, and learning

01:05:50.480 --> 01:05:55.520
Deep Learning using the Fast.AI top-down approach.

01:05:55.520 --> 01:05:59.760
So that one's going to be coming out published by O'Reilly sometime in 2019.

01:05:59.760 --> 01:06:00.760
Awesome.

01:06:00.760 --> 01:06:07.920
Related to your own evolution in the space and what you've seen from Sylvia, I'm sure

01:06:07.920 --> 01:06:13.760
you've been asked for folks that are interested in this field, don't want to get a PhD but

01:06:13.760 --> 01:06:16.560
want to contribute to research.

01:06:16.560 --> 01:06:22.000
Do you have kind of a path that you point folks down?

01:06:22.000 --> 01:06:23.000
Yeah.

01:06:23.000 --> 01:06:28.680
I mean, Sylvia would be a great example of that.

01:06:28.680 --> 01:06:33.800
His background is pure math, so minimal computer science.

01:06:33.800 --> 01:06:37.400
He's actually visiting us in San Francisco this week, so I've just been chatting to him

01:06:37.400 --> 01:06:42.000
about this, and he was telling me, yeah, he's been doing Deep Learning for less than a

01:06:42.000 --> 01:06:48.520
year, and he thinks his story of kind of going from a pure math, minimal computer science

01:06:48.520 --> 01:06:57.640
background to contributing to the FastAI library and doing well-regarded research is kind

01:06:57.640 --> 01:07:03.040
of a good example of how people, yeah, it doesn't have to take a long time.

01:07:03.040 --> 01:07:07.200
You don't have to have some kind of formal background.

01:07:07.200 --> 01:07:12.160
I think all it needs is tenacity.

01:07:12.160 --> 01:07:17.080
I think it requires strong coding shops, and so Sylvia has been working very hard to

01:07:17.080 --> 01:07:23.800
become a better coder, because then you can run lots of experiments every time you come

01:07:23.800 --> 01:07:26.800
up with an idea, you can try it out.

01:07:26.800 --> 01:07:28.560
And then just start writing.

01:07:28.560 --> 01:07:33.440
Start writing simple little blog posts, like just pick something that you've seen come

01:07:33.440 --> 01:07:42.040
out where somebody maybe, give me a simple example, ULMFIC came out showing good results

01:07:42.040 --> 01:07:44.320
on English classification.

01:07:44.320 --> 01:07:49.160
So if you're a big French, why not try it on French classification, and that's a simple

01:07:49.160 --> 01:07:53.040
piece of research, and you can write a blog post, or you can write a PDF, or put it on

01:07:53.040 --> 01:07:55.920
archive, showing your results on French.

01:07:55.920 --> 01:08:00.080
And then maybe you could say, oh, well, now that I've done French classification, let's

01:08:00.080 --> 01:08:04.720
also try sequence to sequence, or let's try sequence labeling, you know, just little

01:08:04.720 --> 01:08:10.520
extensions, and you'll be pretty surprised that you kind of keep publishing little extensions

01:08:10.520 --> 01:08:18.600
to something that you like pretty quickly, you'll find that you've somehow become more

01:08:18.600 --> 01:08:23.280
of an expert on that particular area than anybody else, and people start coming to you

01:08:23.280 --> 01:08:29.000
for advice, and you can start suddenly realizing, oh, you know, when Jeremy and Sebastian did

01:08:29.000 --> 01:08:32.240
that paper, they never tried this other technique.

01:08:32.240 --> 01:08:35.800
So maybe they'd be like, oh, they didn't try using a transformer model, maybe I should

01:08:35.800 --> 01:08:39.240
try a transformer model instead of an LSTM, let's try that.

01:08:39.240 --> 01:08:45.800
And so, you know, just keep digging, keep trying things, I'd say try to be as practical and

01:08:45.800 --> 01:08:50.600
useful as possible, don't get too lost in the math.

01:08:50.600 --> 01:08:56.200
And then, yeah, if you start coming up with some things that start showing good results,

01:08:56.200 --> 01:09:00.640
you can reach out to other people who have been doing work in that field and say, you

01:09:00.640 --> 01:09:04.880
know, here's my results, here's my code, what do you think?

01:09:04.880 --> 01:09:09.960
And if they think it's good, you know, maybe you can start doing some collaborative research

01:09:09.960 --> 01:09:16.320
with other people, which is exactly how Sebastian and I ended up doing some work together,

01:09:16.320 --> 01:09:21.960
and now it is Leslie Smith and I, you know, talking about collaborating, you know, yeah,

01:09:21.960 --> 01:09:27.440
it's all about doing useful work in a field and getting to know some of the other folks

01:09:27.440 --> 01:09:29.480
that are doing that kind of work too.

01:09:29.480 --> 01:09:35.480
Leslie, we know from the work on cyclical learning rates that was featured in the library,

01:09:35.480 --> 01:09:36.480
right?

01:09:36.480 --> 01:09:40.200
Yeah, and the learning rate finder, and more recently, the one cycle schedule that's going

01:09:40.200 --> 01:09:47.000
to be kind of the main featured training method in fast AI version one, and perhaps most importantly,

01:09:47.000 --> 01:09:50.960
the super convergence phenomenon that we're finding we can train things five to ten times

01:09:50.960 --> 01:09:55.040
faster than we were before he discovered that.

01:09:55.040 --> 01:10:01.040
Well, that sounds like another conversation, maybe one that I'll need to have with him.

01:10:01.040 --> 01:10:02.040
Yeah.

01:10:02.040 --> 01:10:04.120
But for now, Jeremy, thank you so much.

01:10:04.120 --> 01:10:08.320
Once again, for taking the time to chat with me, it was really great having you on the

01:10:08.320 --> 01:10:09.320
show.

01:10:09.320 --> 01:10:13.400
That's my pleasure, and I hope folks, you know, if people interested in the fast AI library,

01:10:13.400 --> 01:10:17.800
if you just go to docs.fast.ai, you'll find all the information to get started there

01:10:17.800 --> 01:10:22.480
and come to our forums and tell us how you go.

01:10:22.480 --> 01:10:23.480
Fantastic.

01:10:23.480 --> 01:10:24.480
Thanks so much.

01:10:24.480 --> 01:10:25.480
Thanks, Sam.

01:10:25.480 --> 01:10:26.480
Bye-bye.

01:10:26.480 --> 01:10:31.680
All right, everyone, that's our show for today.

01:10:31.680 --> 01:10:37.360
For more information on Jeremy or any of the topics covered in this show, visit twimmelai.com

01:10:37.360 --> 01:10:40.480
slash talk slash 186.

01:10:40.480 --> 01:10:46.320
You'll find there a link to the fast AI library and the new fast.ai courses as well.

01:10:46.320 --> 01:10:52.360
To join our community of machine learning enthusiasts, including our study groups for the fast.ai courses,

01:10:52.360 --> 01:10:56.040
visit twimmelai.com slash meetup.

01:10:56.040 --> 01:11:00.120
If you're a fan of the podcast and you haven't already done so or you're a new listener

01:11:00.120 --> 01:11:05.280
and you like what you hear, head to your Apple or Google podcast app and leave us a five-star

01:11:05.280 --> 01:11:06.800
rating and review.

01:11:06.800 --> 01:11:10.840
The reviews help inspire us to create more and better content and they help new listeners

01:11:10.840 --> 01:11:12.440
find the show.

01:11:12.440 --> 01:11:39.560
As always, thanks so much for listening and catch you next time.

