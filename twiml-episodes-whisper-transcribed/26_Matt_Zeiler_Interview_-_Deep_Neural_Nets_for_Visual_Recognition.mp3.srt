1
00:00:00,000 --> 00:00:15,480
Hello and welcome to another episode of TwimoTalk, the podcast where I interview interesting

2
00:00:15,480 --> 00:00:20,720
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:20,720 --> 00:00:25,120
I'm your host Sam Charrington.

4
00:00:25,120 --> 00:00:28,160
First and foremost, I'd like to start off by thanking you.

5
00:00:28,160 --> 00:00:33,680
It's your dedication and support of this show that keeps us pumping week after week.

6
00:00:33,680 --> 00:00:38,800
All your downloads, listens, reviews, comments, and general love for the show give us the

7
00:00:38,800 --> 00:00:43,160
ability to grow and to continue to bring you great content.

8
00:00:43,160 --> 00:00:48,280
As always, thank you to everyone who's sending quotes this past week.

9
00:00:48,280 --> 00:00:52,360
And to all those who've received stickers in the mail, be sure to take pictures and show

10
00:00:52,360 --> 00:00:56,400
them off by tweeting them to at TwimoAI.

11
00:00:56,400 --> 00:01:03,120
For you new listeners to receive your TwimoSticker, just send us a tweet, Facebook comment, or comment

12
00:01:03,120 --> 00:01:08,720
right on the show notes page with your favorite quote from today or any episode of the show.

13
00:01:08,720 --> 00:01:12,240
The next couple weeks will be super busy and exciting for me.

14
00:01:12,240 --> 00:01:16,480
Next week, I'm in Silicon Valley for the NVIDIA GTC conference.

15
00:01:16,480 --> 00:01:20,640
If any Twimo listeners are planning to attend and would like to get together, I am totally

16
00:01:20,640 --> 00:01:26,880
game to host a listener meetup, just let me know if you're interested and will make something happen.

17
00:01:26,880 --> 00:01:30,880
And of course, the week after next will be the future of data summit that I'm hosting

18
00:01:30,880 --> 00:01:32,480
in Las Vegas.

19
00:01:32,480 --> 00:01:36,320
If you haven't already made plans to attend, it's not too late.

20
00:01:36,320 --> 00:01:42,080
For more information about the summit, visit TwimoAI.com slash future of data.

21
00:01:42,080 --> 00:01:46,400
And if you have any questions at all about the event, feel free to reach out to me via

22
00:01:46,400 --> 00:01:49,800
the contact page at TwimoAI.com.

23
00:01:49,800 --> 00:01:51,680
Now let's get to this week's show.

24
00:01:51,680 --> 00:01:58,280
Today, we bring you our final interview from backstage at the NYU Future Labs AI Summit.

25
00:01:58,280 --> 00:02:00,840
Our guest this week is Matt Zeeler.

26
00:02:00,840 --> 00:02:05,600
Matt graduated from the University of Toronto, where he worked with deep learning researcher

27
00:02:05,600 --> 00:02:11,320
Jeffrey Hinton, and he went on to earn his PhD in machine learning at NYU, home of

28
00:02:11,320 --> 00:02:13,000
Jan LeCoon.

29
00:02:13,000 --> 00:02:20,720
In 2013, Matt founded Clarify, a startup whose cloud-based visual recognition system gives

30
00:02:20,720 --> 00:02:27,560
developers a way to integrate visual identification into their own products and whose initial image

31
00:02:27,560 --> 00:02:34,920
classification algorithm achieved top five results in that year's ImageNet competition.

32
00:02:34,920 --> 00:02:40,760
I caught up with Matt after his talk, which was titled, From Research to the Real World.

33
00:02:40,760 --> 00:02:45,400
Our conversation focused on the birth and growth of Clarify, as well as the underlying

34
00:02:45,400 --> 00:02:48,640
deep neural network architectures that enable it.

35
00:02:48,640 --> 00:02:52,760
If you've been listening to the show for a while, you've heard me ask several guests

36
00:02:52,760 --> 00:02:58,200
how they go about evolving the architectures of their deep neural networks to enhance performance.

37
00:02:58,200 --> 00:03:03,520
Well, in this podcast, Matt gives the most satisfying answer I've received to date by

38
00:03:03,520 --> 00:03:04,920
far.

39
00:03:04,920 --> 00:03:05,920
Check it out.

40
00:03:05,920 --> 00:03:07,720
I really think you'll enjoy this one.

41
00:03:07,720 --> 00:03:17,160
And now on to the show.

42
00:03:17,160 --> 00:03:18,160
All right, everyone.

43
00:03:18,160 --> 00:03:24,200
I am here with Matt Zealer, CEO and founder of Clarify.

44
00:03:24,200 --> 00:03:28,240
And we are live at the Future Labs AI Summit.

45
00:03:28,240 --> 00:03:29,840
Matt, how are you doing?

46
00:03:29,840 --> 00:03:30,840
Good.

47
00:03:30,840 --> 00:03:31,840
Thanks for having me, Ellen.

48
00:03:31,840 --> 00:03:32,840
Absolutely.

49
00:03:32,840 --> 00:03:33,840
Thanks for being on.

50
00:03:33,840 --> 00:03:40,120
We just left the stage where you were talking about, from research to the real world.

51
00:03:40,120 --> 00:03:42,720
And we'll take a second to get into your talk in a moment.

52
00:03:42,720 --> 00:03:47,520
But why don't you tell us a little bit about your background and about Clarify?

53
00:03:47,520 --> 00:03:48,520
Sounds good.

54
00:03:48,520 --> 00:03:54,680
So, I, way back, I grew up in Canada and in a small farm town, so I was never exposed

55
00:03:54,680 --> 00:03:55,680
to big tech stuff.

56
00:03:55,680 --> 00:04:01,560
And that always got me excited seeing it on TV and gave me excitement about starting

57
00:04:01,560 --> 00:04:08,760
a company someday and for engineering at University of Toronto is what I did in my undergrad.

58
00:04:08,760 --> 00:04:12,000
It was a pretty cool program called Engineering Science where you take every discipline of

59
00:04:12,000 --> 00:04:16,560
engineering and then for the first two years and then the last two you specialize.

60
00:04:16,560 --> 00:04:22,920
And when I was deciding which option to specialize in, I talked to one of Jeff Hinton's PhD students.

61
00:04:22,920 --> 00:04:28,360
So Jeff is very famous in this field of AI and he was a U of T professor at the time.

62
00:04:28,360 --> 00:04:32,720
And his student showed me this video of a flame flickering and he said it was completely

63
00:04:32,720 --> 00:04:35,400
created by artificial intelligence.

64
00:04:35,400 --> 00:04:39,360
And that's when I knew this was something completely different than anything else I've

65
00:04:39,360 --> 00:04:43,880
seen before and anything else I could program, which I knew I had to do at the time.

66
00:04:43,880 --> 00:04:48,280
And so I had to learn more and I took a computer option and Jeff Hinton's course in third

67
00:04:48,280 --> 00:04:50,680
year and then did my undergrad thesis with Jeff.

68
00:04:50,680 --> 00:04:54,000
So that was quite the opportunity.

69
00:04:54,000 --> 00:04:55,000
Absolutely.

70
00:04:55,000 --> 00:05:00,200
And I didn't know enough having just taken undergrad to start a company in this field.

71
00:05:00,200 --> 00:05:05,880
So I decided to do my PhD and that's what brought me to New York to go to NYU.

72
00:05:05,880 --> 00:05:11,480
And I focused over four years on neural networks applied to understanding images and that's

73
00:05:11,480 --> 00:05:14,440
exactly what we do today at Clarify.

74
00:05:14,440 --> 00:05:20,440
And the last year was particularly exciting where there was this event called ImageNet that

75
00:05:20,440 --> 00:05:26,760
held every year and in 2012 Jeff Hinton again and two of his PhD students had some really

76
00:05:26,760 --> 00:05:32,480
groundbreaking results applying neural networks to this competition compared to other algorithms

77
00:05:32,480 --> 00:05:36,280
like edge detection, color detection, simple stuff.

78
00:05:36,280 --> 00:05:42,080
And they blew out everybody and by a huge margin it was really a step function improvement

79
00:05:42,080 --> 00:05:44,200
and accuracy of these things.

80
00:05:44,200 --> 00:05:48,160
And so everybody who didn't believe in neural nets all of a sudden started believing in

81
00:05:48,160 --> 00:05:49,160
them.

82
00:05:49,160 --> 00:05:53,000
So what really triggered this explosion we're seeing in the AI world.

83
00:05:53,000 --> 00:05:57,200
And so being at NYU where I was already working on this stuff I could get up and running

84
00:05:57,200 --> 00:06:04,960
pretty quickly with that result and at the start of 2013 and continue to improve it throughout

85
00:06:04,960 --> 00:06:05,960
the year.

86
00:06:05,960 --> 00:06:11,360
And I realized that after interning at Google Brain, which is their neural net team, the

87
00:06:11,360 --> 00:06:16,360
tech I had working back in New York was actually working better than what they had internally.

88
00:06:16,360 --> 00:06:21,120
And so I saw that as a big opportunity to start a business because Google is well known

89
00:06:21,120 --> 00:06:24,960
in the AI space and they were already ahead of many other companies out there.

90
00:06:24,960 --> 00:06:30,600
And so that's what triggered it in the fall of 2013 incorporating Clarify.

91
00:06:30,600 --> 00:06:34,600
And we ended up winning right off the start of this ImageNet competition.

92
00:06:34,600 --> 00:06:39,800
So that was a great way to kick off the company and triggered a lot of inbound press and

93
00:06:39,800 --> 00:06:41,560
invested from there.

94
00:06:41,560 --> 00:06:46,640
And we've been offering this technology up as APIs and continuing to grow the business

95
00:06:46,640 --> 00:06:47,640
through that.

96
00:06:47,640 --> 00:06:49,040
That's pretty amazing.

97
00:06:49,040 --> 00:06:53,360
We talk about ImageNet from time to time on the podcast.

98
00:06:53,360 --> 00:07:00,360
Anything you can share about the experience building up to competing in ImageNet and successfully

99
00:07:00,360 --> 00:07:01,360
winning it?

100
00:07:01,360 --> 00:07:03,320
Yeah, it was a lot of fun.

101
00:07:03,320 --> 00:07:06,400
It was back in the very early days of Clarify.

102
00:07:06,400 --> 00:07:12,920
I really started programming our library and everything back in August of 2013.

103
00:07:12,920 --> 00:07:15,320
And the submission deadline was in November.

104
00:07:15,320 --> 00:07:20,640
And so I just had in my apartment one desktop with a couple of graphics cards in it because

105
00:07:20,640 --> 00:07:24,200
they use GPUs for all this type of neural net stuff.

106
00:07:24,200 --> 00:07:27,400
And it was just training away constantly.

107
00:07:27,400 --> 00:07:32,040
And I submitted five results to the competition and they ended up winning the top five places.

108
00:07:32,040 --> 00:07:37,680
So it was really exciting to have those early days of Clarify where it was just me and

109
00:07:37,680 --> 00:07:39,200
the one machine.

110
00:07:39,200 --> 00:07:42,520
And now we just surpassed 50 people in the company.

111
00:07:42,520 --> 00:07:46,960
So it's also exciting now that it's been created to grow the company.

112
00:07:46,960 --> 00:07:47,960
That's awesome.

113
00:07:47,960 --> 00:07:52,960
Well, one of the questions that I ask frequently and haven't really, I think, to date got a

114
00:07:52,960 --> 00:07:59,640
very satisfying response is, you know, when you're trying to, you know, starting from what

115
00:07:59,640 --> 00:08:06,440
Hinton Steamed did in 2012 and you're trying to evolve a neural net architecture to take

116
00:08:06,440 --> 00:08:11,560
on a problem, or if you're starting from scratch, like how do you approach the problem

117
00:08:11,560 --> 00:08:14,520
of neural network architecture?

118
00:08:14,520 --> 00:08:19,760
What's the thinking and the primitives that go into that that get you to winning image

119
00:08:19,760 --> 00:08:20,760
net?

120
00:08:20,760 --> 00:08:21,760
Yeah.

121
00:08:21,760 --> 00:08:28,120
I had the very last paper on my PhD was actually focused on understanding these neural networks.

122
00:08:28,120 --> 00:08:32,560
And people have understood what the very first layer of these networks do.

123
00:08:32,560 --> 00:08:37,720
So neural nets are composed of many layers of processing that are learned from the data,

124
00:08:37,720 --> 00:08:40,120
which is what makes them really powerful.

125
00:08:40,120 --> 00:08:45,120
And the first layer, you can just visualize if you look at a neural net applied to images,

126
00:08:45,120 --> 00:08:49,560
it ends up learning different edges and different colors very simply in the first layer.

127
00:08:49,560 --> 00:08:51,640
But nobody really knew what was happening beyond that.

128
00:08:51,640 --> 00:08:55,520
In the second layer, third layer, all the web to however many layers you have.

129
00:08:55,520 --> 00:09:00,840
So the last paper of my PhD was focused on visualizing and understanding convolutional

130
00:09:00,840 --> 00:09:02,200
neural networks.

131
00:09:02,200 --> 00:09:08,280
And we saw that these edges form into things like corners and circles and T junctions and

132
00:09:08,280 --> 00:09:12,120
parallel lines kind of mid-level things by the second layer.

133
00:09:12,120 --> 00:09:17,920
The third layer starts extracting things like eyeballs and noses and ears.

134
00:09:17,920 --> 00:09:22,200
And then the fourth and fifth layers might start learning faces and then the final layers

135
00:09:22,200 --> 00:09:24,200
will output person.

136
00:09:24,200 --> 00:09:29,120
So it actually builds up these levels of abstraction in a very sensible way.

137
00:09:29,120 --> 00:09:36,200
And so in visualizing these things, we actually robbed Fergus and I at NYU, realized some deficiencies

138
00:09:36,200 --> 00:09:42,520
of a neural net architecture that Jeff Hinton used with his team in ImageNet 2012.

139
00:09:42,520 --> 00:09:47,240
And so we could actually improve the architecture kind of systematically by looking at these

140
00:09:47,240 --> 00:09:48,240
visualizations.

141
00:09:48,240 --> 00:09:52,160
And that gave a multiple percentage points improvement.

142
00:09:52,160 --> 00:09:56,360
And then other things are more of an art than a science.

143
00:09:56,360 --> 00:10:00,480
There's not a lot of theory around these neural networks.

144
00:10:00,480 --> 00:10:06,680
It's more from experience when you see this kind of behavior change these types of parameters.

145
00:10:06,680 --> 00:10:13,600
And so that's why there's very few experienced people in this field and that's why they're so

146
00:10:13,600 --> 00:10:14,600
valuable.

147
00:10:14,600 --> 00:10:17,680
It's that kind of experience that they bring to the table.

148
00:10:17,680 --> 00:10:21,480
What's an example of if you see this change that?

149
00:10:21,480 --> 00:10:27,560
So one example is if there's something called a learning rate, which tells you how big

150
00:10:27,560 --> 00:10:32,800
of a step to update your model every time you see a new image in the case of our stuff.

151
00:10:32,800 --> 00:10:38,240
And so if you have a really high learning rate, you'll see the accuracy just explode and

152
00:10:38,240 --> 00:10:41,800
you'll see the parameters of the model just explode into really high values.

153
00:10:41,800 --> 00:10:44,040
It becomes an unstable system.

154
00:10:44,040 --> 00:10:49,000
And so you know you can actually decrease the learning rate to make that more stable.

155
00:10:49,000 --> 00:10:53,720
And that's something that we see with non-neural network machine learning models as well.

156
00:10:53,720 --> 00:10:58,560
Are there things that, is there an example specifically related to neural network architecture?

157
00:10:58,560 --> 00:11:04,200
Like if you're seeing your neural network do X or not do X, maybe you need to add this

158
00:11:04,200 --> 00:11:05,760
kind of layer or that kind of layer?

159
00:11:05,760 --> 00:11:06,760
Yeah.

160
00:11:06,760 --> 00:11:12,400
So the visualizations that we notice that looked incorrect in some sense were when we looked

161
00:11:12,400 --> 00:11:16,000
at higher layers, there was a lot of blocking artifacts.

162
00:11:16,000 --> 00:11:20,600
So it didn't look like a very sharp visualization.

163
00:11:20,600 --> 00:11:26,640
And so that was a result of the first layer being really large filters and not being applied

164
00:11:26,640 --> 00:11:32,040
at every pixel, one pixel stride, but every four pixels it was taking big jumps.

165
00:11:32,040 --> 00:11:36,840
And so when you visualize it also plops down in big jumps.

166
00:11:36,840 --> 00:11:41,440
And so that has to be throwing away information, it's skipping over too much.

167
00:11:41,440 --> 00:11:46,720
And so by reducing the stride, reducing the filter size, it actually increased the accuracy.

168
00:11:46,720 --> 00:11:53,440
So it sounds like the lesson then is or lessons are that as you said it's you know there's

169
00:11:53,440 --> 00:12:00,120
art as well as science involves it's highly iterative.

170
00:12:00,120 --> 00:12:04,760
But also I think what I learned in this discussion is that what really gave you the edge was being

171
00:12:04,760 --> 00:12:10,000
able to kind of introspect if you will what was happening at the different layers of the

172
00:12:10,000 --> 00:12:15,600
architecture and using the knowledge that you gain there to evolve the architecture.

173
00:12:15,600 --> 00:12:17,280
Yeah, exactly.

174
00:12:17,280 --> 00:12:20,720
Is the do you remember the name of the paper that you referred to?

175
00:12:20,720 --> 00:12:25,880
It's called visualizing and understanding convolutional neural networks.

176
00:12:25,880 --> 00:12:30,320
And is that paper related to the deep dream work?

177
00:12:30,320 --> 00:12:31,720
So it's funny.

178
00:12:31,720 --> 00:12:32,720
It's smiling here.

179
00:12:32,720 --> 00:12:33,720
It's funny.

180
00:12:33,720 --> 00:12:34,720
You mentioned that.

181
00:12:34,720 --> 00:12:36,600
Yeah, I think it's a very similar technique.

182
00:12:36,600 --> 00:12:44,320
So the purpose of my paper was to just go through a network, you input an image, it goes

183
00:12:44,320 --> 00:12:48,320
feed forward through a network as if it was about to predict the categories.

184
00:12:48,320 --> 00:12:54,440
And then you reconstruct back down to generate a pixel and deep dream basically did that

185
00:12:54,440 --> 00:12:59,840
process in multiple loops so they would reconstruct a visualization, add it back to the original

186
00:12:59,840 --> 00:13:02,720
image and then continue that in a cycle.

187
00:13:02,720 --> 00:13:10,440
And that's where the system essentially gets locked into what it's dreaming about and

188
00:13:10,440 --> 00:13:16,400
it starts visualizing kind of crisper objects that it can think about.

189
00:13:16,400 --> 00:13:17,400
Okay.

190
00:13:17,400 --> 00:13:24,040
So clarify is a bit of a success story in the NYU ecosystem, kind of where is the company

191
00:13:24,040 --> 00:13:29,600
at now in terms of, you know, however you describe it size scale, you know, the problems

192
00:13:29,600 --> 00:13:31,280
that you're going after, things like that.

193
00:13:31,280 --> 00:13:36,880
Yeah, so it's been really exciting starting it in my apartment and then the very first

194
00:13:36,880 --> 00:13:41,080
office was at NYU's incubator on Verix Street.

195
00:13:41,080 --> 00:13:46,120
And then once we had about 10 people, we got our own office and that was around when we

196
00:13:46,120 --> 00:13:50,280
raised our series B, which was a pretty big round, 10 million dollars.

197
00:13:50,280 --> 00:13:57,440
And then just last fall in October of 2016, we raised our series B, which was a 30 million

198
00:13:57,440 --> 00:14:01,880
dollar round, so lots of funding for growth in the future.

199
00:14:01,880 --> 00:14:07,240
And we just surpassed 50 people, so growing really quick and we were only about 30 people

200
00:14:07,240 --> 00:14:08,440
at the start of the year.

201
00:14:08,440 --> 00:14:09,440
Wow.

202
00:14:09,440 --> 00:14:10,440
Yeah.

203
00:14:10,440 --> 00:14:11,440
That's amazing.

204
00:14:11,440 --> 00:14:12,440
Yeah.

205
00:14:12,440 --> 00:14:21,200
And so the, as I understand, the solution that you guys are offering is, and you can,

206
00:14:21,200 --> 00:14:26,840
you know, correct and iterate on this, but it is kind of a visual understanding API if

207
00:14:26,840 --> 00:14:32,600
you will, where you feed it images and it will tag those images for you and give you

208
00:14:32,600 --> 00:14:37,360
probabilities of the likelihood of those tags.

209
00:14:37,360 --> 00:14:41,720
And you know, that's something that we see, you know, there are numerous versions of this

210
00:14:41,720 --> 00:14:46,680
available in a marketplace, you know, including by, you know, big players like Google and Microsoft

211
00:14:46,680 --> 00:14:47,680
and Amazon.

212
00:14:47,680 --> 00:14:51,680
Like what makes clarified different and how do you compete in a crowded field?

213
00:14:51,680 --> 00:14:58,640
Yeah, so that's a good summary of what we offer and have been offering for over three years.

214
00:14:58,640 --> 00:15:03,520
Now, so one big advantage for us is that we've been out at least three times longer than

215
00:15:03,520 --> 00:15:08,560
most other people in this space, which means we've, and because of winning ImageNet, early

216
00:15:08,560 --> 00:15:11,160
it means we've had a lot of conversations with customers.

217
00:15:11,160 --> 00:15:15,480
We really understand lots of different industries and the problems that each of these customers

218
00:15:15,480 --> 00:15:16,640
have in them.

219
00:15:16,640 --> 00:15:19,640
And so we try and build those features into our platform.

220
00:15:19,640 --> 00:15:23,560
And so some examples of that were just launched in the fall.

221
00:15:23,560 --> 00:15:26,120
One is a search product and one is a training product.

222
00:15:26,120 --> 00:15:30,720
So search very simply lets you throw in your images to our system and we take care of

223
00:15:30,720 --> 00:15:31,720
the rest.

224
00:15:31,720 --> 00:15:35,280
We understand them from the pixels up to recognize all these different concepts.

225
00:15:35,280 --> 00:15:40,480
And then we let you search by the concepts that we can recognize, but also by image.

226
00:15:40,480 --> 00:15:45,280
So if you take a picture out in the world, you can find visually similar pictures automatically

227
00:15:45,280 --> 00:15:46,640
without even saying a word.

228
00:15:46,640 --> 00:15:50,720
So that's really powerful as a discovery tool, and that applies across every industry.

229
00:15:50,720 --> 00:15:53,560
Like retail, you can use it for shopping, gardening.

230
00:15:53,560 --> 00:15:58,880
You can use it for gardening ideas or travel for planning your next vacation.

231
00:15:58,880 --> 00:16:02,080
It's a universally useful feature in our platform.

232
00:16:02,080 --> 00:16:07,600
And likewise, training is another universally useful feature.

233
00:16:07,600 --> 00:16:11,480
We started off with this one size fits all model we call the general model.

234
00:16:11,480 --> 00:16:17,560
We started building what we like to call domain models for food, travel, wedding, real estate,

235
00:16:17,560 --> 00:16:18,560
nudity and so forth.

236
00:16:18,560 --> 00:16:21,240
So there are more focus on different industries.

237
00:16:21,240 --> 00:16:24,480
And then with custom training, we've gone one step further.

238
00:16:24,480 --> 00:16:28,640
Now you can teach the platform to recognize whatever you care about.

239
00:16:28,640 --> 00:16:33,800
And this is a huge step ahead of a lot of the other people out there.

240
00:16:33,800 --> 00:16:38,200
And it's really important for our customers because now if you take a retail setting, they

241
00:16:38,200 --> 00:16:43,640
have a way of categorizing their products, or e-commerce marketplaces.

242
00:16:43,640 --> 00:16:49,200
People are used to manually tag in this content, so they already implicitly have a categorization.

243
00:16:49,200 --> 00:16:55,120
Or for filtering out unwanted content, they already have a terms of use that includes nudity

244
00:16:55,120 --> 00:17:01,080
and drugs and weapons, and even non-offensive stuff like, you know, they just don't want

245
00:17:01,080 --> 00:17:05,760
advertisements on their site or stock photos on their site or money or people.

246
00:17:05,760 --> 00:17:10,400
And so now with custom training, you can customize it to recognize exactly what you care about

247
00:17:10,400 --> 00:17:13,520
in your business, which is very exciting.

248
00:17:13,520 --> 00:17:19,640
What kind of accuracy lift do you see customers obtaining with custom training relative to

249
00:17:19,640 --> 00:17:21,600
standard or domain models?

250
00:17:21,600 --> 00:17:27,400
Yeah, it's a big lift because it's usually trained on their specific data.

251
00:17:27,400 --> 00:17:34,400
So in terms of accuracy, numbers, I think it's not fair to compare because the general

252
00:17:34,400 --> 00:17:38,480
model is meant for if you take your phone out of your pocket and take a picture and tell

253
00:17:38,480 --> 00:17:40,240
you something meaningful.

254
00:17:40,240 --> 00:17:44,680
We at Clarify have collected massive data sets to make that really accurate.

255
00:17:44,680 --> 00:17:51,000
But when you focus on the 10 or 100 or 1000 categories that you care about only, then you

256
00:17:51,000 --> 00:17:56,560
can end a strain on data that you have access to, then you can really drive the accuracy

257
00:17:56,560 --> 00:17:59,800
because it's really solving your specific problem.

258
00:17:59,800 --> 00:18:07,520
So as Clarify does Clarify offer both a consumer solution, take a, you know, an app that I take

259
00:18:07,520 --> 00:18:11,800
a picture and it will recognize things as well as a business offering.

260
00:18:11,800 --> 00:18:17,640
Yeah, we do have a consumer app called Forever, which lets you apply our general model and

261
00:18:17,640 --> 00:18:21,240
our facial recognition to understand your personal photos.

262
00:18:21,240 --> 00:18:24,520
And it's available on iOS right now.

263
00:18:24,520 --> 00:18:28,440
That's spelled forever with a Y at the end, it's for every one of your photos.

264
00:18:28,440 --> 00:18:30,400
And it even lets you teach things.

265
00:18:30,400 --> 00:18:35,000
So this custom training that we just launched in our API, we actually launched it first

266
00:18:35,000 --> 00:18:36,160
in forever.

267
00:18:36,160 --> 00:18:40,400
So you can teach it like the name of your pet or your favorite sports car and all that

268
00:18:40,400 --> 00:18:44,960
becomes searchable over your personal pictures as well as, you know, your mom's name and

269
00:18:44,960 --> 00:18:47,400
your sister's name, it actually recognizes people.

270
00:18:47,400 --> 00:18:51,040
So whenever you take a new picture of them, it'll automatically tag them and index them

271
00:18:51,040 --> 00:18:52,040
for search.

272
00:18:52,040 --> 00:19:00,200
Okay, and to what degree does having that is the main reason why or one of the main reasons

273
00:19:00,200 --> 00:19:04,880
why you offer that because it allows you to expand the data set for which you're able

274
00:19:04,880 --> 00:19:06,040
to train over.

275
00:19:06,040 --> 00:19:07,040
Yeah.

276
00:19:07,040 --> 00:19:08,880
How does that play into the model?

277
00:19:08,880 --> 00:19:09,880
Yeah, exactly.

278
00:19:09,880 --> 00:19:14,280
That was the initial, well, there was two initial incentives at the data collection and

279
00:19:14,280 --> 00:19:16,480
it was always really a passion of mine.

280
00:19:16,480 --> 00:19:22,920
Even before starting Clareify, before deciding on the API as building a platform, I was always

281
00:19:22,920 --> 00:19:27,320
passionate about applying this technology to my own personal pictures and that's when

282
00:19:27,320 --> 00:19:29,880
I knew it was actually ready to start a business around.

283
00:19:29,880 --> 00:19:34,600
I built a very simple demo and just dragged and dropped my pictures into it and it gave

284
00:19:34,600 --> 00:19:36,400
meaningful results.

285
00:19:36,400 --> 00:19:42,600
And so it's always been a passion plus it's a great way for us to crowdsource data collection.

286
00:19:42,600 --> 00:19:44,880
That's awesome.

287
00:19:44,880 --> 00:19:50,920
What are some of the most popular business use cases that you're seeing?

288
00:19:50,920 --> 00:19:55,120
Yeah, I like to bucket them into two big buckets.

289
00:19:55,120 --> 00:19:59,680
One is organization and one is moderation and these apply across all different industries.

290
00:19:59,680 --> 00:20:05,720
So organization, we have companies like Travago, for example, that are in the travel space.

291
00:20:05,720 --> 00:20:11,800
They want to take all the user uploaded and hotel uploaded photos and tag them with our

292
00:20:11,800 --> 00:20:16,920
travel model so that people may be the next time you're planning your vacation, you can

293
00:20:16,920 --> 00:20:21,200
search for the best pool in Jamaica and it shows you the pictures to compare and make

294
00:20:21,200 --> 00:20:22,920
your decision easier.

295
00:20:22,920 --> 00:20:25,960
Same story applies in the wedding space with Stanley Pretty.

296
00:20:25,960 --> 00:20:30,560
They have users upload their entire wedding album and they use our wedding model to categorize

297
00:20:30,560 --> 00:20:36,200
them and that helps new users come to Stanley Pretty and find inspirations for their wedding.

298
00:20:36,200 --> 00:20:40,400
The more new users and the more content, the more ad revenue that they can drive from

299
00:20:40,400 --> 00:20:46,280
Stanley Pretty and on the moderation side, whenever there's an upload button on the internet

300
00:20:46,280 --> 00:20:51,400
or in a mobile app, there's a chance that you're going to get offensive content and that

301
00:20:51,400 --> 00:20:57,440
could be nudity, drugs, weapons, violence, lots of different stuff that you don't want

302
00:20:57,440 --> 00:21:03,200
on your marketplace and advertisers don't want to be associated with this content either.

303
00:21:03,200 --> 00:21:10,800
So now with our moderation models, you can build a brand safe section of your site and for

304
00:21:10,800 --> 00:21:15,600
your community or to drive ad revenue and do that automatically.

305
00:21:15,600 --> 00:21:21,760
And this is traditionally done with a manual work and it just doesn't scale both in terms

306
00:21:21,760 --> 00:21:28,360
of how fast a human can respond to new uploads and to how much new content is being created

307
00:21:28,360 --> 00:21:35,400
by cell phones all over the world. So we solve both of those by automating the process.

308
00:21:35,400 --> 00:21:42,040
So I'm curious what your thoughts are on where you see opportunities in this space.

309
00:21:42,040 --> 00:21:49,440
We're here at the Future Lab Summit. In addition to many of the New York AI community, there

310
00:21:49,440 --> 00:21:55,960
are lots of NYU students. The next AI entrepreneur might be in the audience there.

311
00:21:55,960 --> 00:22:01,560
Where do you think the opportunities lie for folks that are looking to do something?

312
00:22:01,560 --> 00:22:07,320
Yeah, I think there's a huge amount of opportunity leveraging artificial intelligence and we're

313
00:22:07,320 --> 00:22:13,280
starting to see that by the sheer number of startups that are being formed around AI.

314
00:22:13,280 --> 00:22:18,280
I think one thing that excites me a lot is this personalization capability I mentioned

315
00:22:18,280 --> 00:22:25,240
in talking about training your pets, training your mom's name and your photos. But that

316
00:22:25,240 --> 00:22:30,040
could be anywhere. It could be in your Alexa learning about you. It could be in all your

317
00:22:30,040 --> 00:22:36,800
devices. And the more we see that, the more AI is going to fit to each individual and I

318
00:22:36,800 --> 00:22:39,720
think that's going to be the next wave of AI.

319
00:22:39,720 --> 00:22:42,960
It's awesome. It's awesome. Any parting thoughts?

320
00:22:42,960 --> 00:22:48,480
I would urge that any person interested in starting an AI company is not doing it to

321
00:22:48,480 --> 00:22:54,200
ride the wave, I think. And not doing it just because you have cool technology, I think

322
00:22:54,200 --> 00:22:59,440
you really want to have a passion for starting a company because as the company gets bigger

323
00:22:59,440 --> 00:23:03,920
and bigger, you'll be doing, if you're the CEO, you'll be doing less and less of the

324
00:23:03,920 --> 00:23:08,880
technology yourself. So just keep that in mind when you're thinking about building a business.

325
00:23:08,880 --> 00:23:12,680
You mentioned that on stage. Does that sound like hard one, hard learn lessons?

326
00:23:12,680 --> 00:23:21,640
Yeah, it's always itch that I want to scratch to get into the code and work on new stuff.

327
00:23:21,640 --> 00:23:26,560
But there's a lot of things that only a CEO can do. And so that's my priority.

328
00:23:26,560 --> 00:23:31,040
Right. Well, Matt, thank you so much for taking the time and being on the show is very

329
00:23:31,040 --> 00:23:32,040
chatting with you.

330
00:23:32,040 --> 00:23:33,640
Thanks for having me.

331
00:23:37,640 --> 00:23:42,960
All right, everyone. That's our show for today. Once again, thanks so much for listening

332
00:23:42,960 --> 00:23:48,360
and for your continued support. Please don't forget to share your favorite quote from this

333
00:23:48,360 --> 00:23:54,680
show via the show notes page via Twitter or via our Facebook page. If you do, we'll be

334
00:23:54,680 --> 00:24:01,000
happy to send you one of our laptop stickers. The notes for this show will be up on twomolei.com

335
00:24:01,000 --> 00:24:07,040
slash talk slash 22 where you'll find links to Matt and clarify in the various resources

336
00:24:07,040 --> 00:24:20,560
we've mentioned in the show. Thanks so much for listening and catch you next time.

