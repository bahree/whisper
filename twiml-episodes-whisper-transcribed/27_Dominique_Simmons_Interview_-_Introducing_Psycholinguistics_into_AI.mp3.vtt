WEBVTT

00:00.000 --> 00:16.200
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

00:16.200 --> 00:21.360
people doing interesting things in machine learning and artificial intelligence.

00:21.360 --> 00:25.240
I'm your host Sam Charrington.

00:25.240 --> 00:28.560
I think you're really going to enjoy today's show.

00:28.560 --> 00:35.160
Our guest this week is Dominique Simmons, applied research scientist at AI tools vendor

00:35.160 --> 00:37.840
dimensional mechanics.

00:37.840 --> 00:43.200
Dominique brings a really interesting background in cognitive psychology and psycho linguistics

00:43.200 --> 00:47.760
to her work in research in AI and well to this podcast.

00:47.760 --> 00:52.120
In our conversation, we cover the implications of cognitive psychology for neural networks

00:52.120 --> 00:57.800
in AI systems and in particular, how an understanding of human cognition impacts the

00:57.800 --> 01:03.360
development of AI models for applications such as media processing.

01:03.360 --> 01:08.400
We also discuss our research into multi modal training of AI models and how our understanding

01:08.400 --> 01:11.400
of the human brain has influenced this work.

01:11.400 --> 01:16.200
In addition, we explore the debate around the biological plausibility of machine learning

01:16.200 --> 01:17.720
and AI models.

01:17.720 --> 01:20.880
Really, this was a great discussion.

01:20.880 --> 01:24.280
Before we jump in though, I've got a question for you.

01:24.280 --> 01:31.000
How would you like one of our beautiful this week in machine learning and AI laptop stickers?

01:31.000 --> 01:32.880
I know you want one.

01:32.880 --> 01:38.120
We've already sent stickers all around the world and we'd love to send you one as well.

01:38.120 --> 01:43.800
All you need to do is pull up the show notes page, which in this case will be at twimmolai.com

01:43.800 --> 01:50.600
slash talk slash 2323 and drop us a note with your favorite quote from the show.

01:50.600 --> 01:56.160
You can also post a quote via Twitter, just mention at twimmolai or on our Facebook page.

01:56.160 --> 02:00.560
Links to all of these will be available in the show notes.

02:00.560 --> 02:04.120
I can't believe it's mid may already.

02:04.120 --> 02:09.320
Next week, I'll be hosting my future of data summit in Las Vegas as part of the interop

02:09.320 --> 02:10.560
ITX conference.

02:10.560 --> 02:16.680
I've got a ton of great speakers lined up for the event, including folks from Intel,

02:16.680 --> 02:23.560
Microsoft, GE, Capital One, level three communications and Walmart, as well as leading industry analysts

02:23.560 --> 02:26.800
and startup executives.

02:26.800 --> 02:32.440
Topics will span IOT and edge computing, data management, and of course machine learning

02:32.440 --> 02:36.200
in AI, blockchain, and much more.

02:36.200 --> 02:40.120
If you're planning to attend interop, I hope you join us at the summit.

02:40.120 --> 02:45.120
And if you've been meaning to attend the summit, but held out until the very last minute,

02:45.120 --> 02:47.040
it is not too late to register.

02:47.040 --> 02:55.280
In fact, you can do so using my 20% off discount code by visiting twimmolai.com slash interop.

02:55.280 --> 03:00.040
Of course, if you have any questions about the summit, please feel free to reach out to

03:00.040 --> 03:02.440
me via the contact page.

03:02.440 --> 03:10.840
And now on to the show.

03:10.840 --> 03:17.640
All right, hey, everyone, I am excited to have Dominique Simmons on the line.

03:17.640 --> 03:23.200
Dominique is an applied research scientist with dimensional mechanics.

03:23.200 --> 03:24.680
How are you, Dominique?

03:24.680 --> 03:26.080
I'm doing great.

03:26.080 --> 03:27.080
Thank you.

03:27.080 --> 03:28.080
How about yourself?

03:28.080 --> 03:29.080
Doing very well.

03:29.080 --> 03:30.080
Very well.

03:30.080 --> 03:33.720
I wanted to start this conversation by talking a little bit about your background.

03:33.720 --> 03:41.680
You have a master's degree in cognitive psychology and psycho linguistics, and you have ended

03:41.680 --> 03:45.680
up doing work in artificial intelligence.

03:45.680 --> 03:51.640
Tell us a little bit about your background and kind of your path to working in AI.

03:51.640 --> 03:58.280
So I'll start from the very beginning.

03:58.280 --> 04:02.480
As a child, I was always fascinated by the brain.

04:02.480 --> 04:06.240
I grew up as an only child, and I found myself journaling.

04:06.240 --> 04:12.320
When I wasn't with my other friends, I'd journal and make observations about what people

04:12.320 --> 04:20.720
are doing, what was going on in my environment, and what I was fascinated by what made them

04:20.720 --> 04:23.040
do the things that they did.

04:23.040 --> 04:29.320
And that carried on throughout school, and eventually in college, I had a great mentor

04:29.320 --> 04:37.480
who brought neuroscience into our curriculum, and I started, you know, tabling for brain

04:37.480 --> 04:38.480
awareness week.

04:38.480 --> 04:44.920
I started, you know, learning about the brain and the circuits and, you know, just how

04:44.920 --> 04:47.080
these processes come about.

04:47.080 --> 04:50.920
And so, again, that carried me through.

04:50.920 --> 04:54.400
I knew that I wanted to do that in graduate school.

04:54.400 --> 05:04.960
And after becoming a lab manager, University of Illinois, Urbana Champaign, being a post-back

05:04.960 --> 05:15.120
intern at UMass Amherst, I got a lot of exposure to different types of psychology, anything

05:15.120 --> 05:24.280
from, you know, infant psychology, cognitive psychology, psycho linguistics, music cognition,

05:24.280 --> 05:25.280
you name it.

05:25.280 --> 05:30.400
I was just very fascinated with all these aspects, and you could see these parallels coming

05:30.400 --> 05:33.640
together as well.

05:33.640 --> 05:41.960
So in graduate school, I studied specifically multi-sensory perception, which is the influence

05:41.960 --> 05:47.520
of one sense over another, and how senses interact.

05:47.520 --> 05:56.120
So I come from a school of thought where the brain is agnostic, if you will, to input.

05:56.120 --> 06:05.120
And once the input, you know, is processed, then, you know, it becomes sound or it becomes

06:05.120 --> 06:08.720
hearing or, you know, any one of these senses.

06:08.720 --> 06:16.000
But the actual input is just information.

06:16.000 --> 06:23.200
The brain likes getting information and, you know, learning and processing.

06:23.200 --> 06:32.280
And then at the, the later stages, that's when it becomes what we know as, as, as senses,

06:32.280 --> 06:33.600
sensory input.

06:33.600 --> 06:34.600
Okay.

06:34.600 --> 06:38.880
So with that, that gave me a unique background.

06:38.880 --> 06:44.400
So I will say that in graduate school, I got a little bit tired of the theory.

06:44.400 --> 06:52.160
You know, of course, it's, you know, critical, it's a critical foundation for a lot of work.

06:52.160 --> 06:58.000
But I started to get, you know, to itch for applications of these ideas.

06:58.000 --> 06:59.000
Right.

06:59.000 --> 07:00.760
You know, this idea of integrating senses.

07:00.760 --> 07:04.240
How can we, how can we make this into a device?

07:04.240 --> 07:09.600
You know, what, how can it help, you know, non-hearing populations or populations that

07:09.600 --> 07:13.640
have sensory deficits?

07:13.640 --> 07:22.360
And so I worked on a project, a brain training project on hearing, veterans with hearing

07:22.360 --> 07:23.360
loss.

07:23.360 --> 07:32.320
And essentially it was a, a program, like an auditory game, auditory video game, where they

07:32.320 --> 07:38.640
had to, to learn complex sounds in order to navigate through the game.

07:38.640 --> 07:42.760
When the sound goes up, they had to jump, but the sound goes down, they had to, you know,

07:42.760 --> 07:43.760
back under something.

07:43.760 --> 07:44.760
Oh, interesting.

07:44.760 --> 07:45.760
And so, yeah.

07:45.760 --> 07:53.480
And so that was my first taste of the applied aspect, you know, of things of the applied

07:53.480 --> 07:54.480
world.

07:54.480 --> 08:01.800
And the goal of that was assessment or trying to rebuild new neural pathways to improve

08:01.800 --> 08:04.600
their hearing or something else.

08:04.600 --> 08:07.560
So it was a little bit of both, but really the latter.

08:07.560 --> 08:16.000
Really trying to re-strengthen those connections, those auditory connections through training

08:16.000 --> 08:17.800
them with, with complex sounds.

08:17.800 --> 08:23.040
And so we build the complex sounds in MATLAB and other tools.

08:23.040 --> 08:27.640
And you know, at that point, we were doing some initial testing, but it's gotten, gotten

08:27.640 --> 08:28.640
pretty far.

08:28.640 --> 08:30.640
It's gotten to the point where it's in, in, in app.

08:30.640 --> 08:31.640
Oh, wow.

08:31.640 --> 08:32.640
Yeah.

08:32.640 --> 08:40.720
So that was part of my graduate work, and then I ended up, so it's funny how I got into

08:40.720 --> 08:41.720
AI.

08:41.720 --> 08:42.720
It's a bit of a jump.

08:42.720 --> 08:50.800
So, still on that applied path, I ended up here at Dimensional Mechanics as a user experience

08:50.800 --> 08:53.520
researcher in VR.

08:53.520 --> 09:00.960
That was the initial space that we were in, creating VR content.

09:00.960 --> 09:02.960
And optimizing it.

09:02.960 --> 09:03.960
Oh, interesting.

09:03.960 --> 09:04.960
Yeah.

09:04.960 --> 09:15.640
And so that's, that's why, so I was trying to work on things like immersion, enriching the

09:15.640 --> 09:20.680
user experience of someone in VR environments.

09:20.680 --> 09:29.560
What are the perceptual aspects that come into it, and how to build a better immersive environment

09:29.560 --> 09:40.760
for users, and also, you know, avoiding things like uncanny valley and nausea and all the,

09:40.760 --> 09:43.320
the not so good stuff that goes with VR.

09:43.320 --> 09:45.920
But eventually, and uncanny valley is what?

09:45.920 --> 09:46.920
Oh, yes.

09:46.920 --> 09:47.920
Uncanny valley.

09:47.920 --> 09:50.800
That's what I forget what, what the phenomena is.

09:50.800 --> 09:51.800
Yeah.

09:51.800 --> 09:59.120
So it's, when you see a character that is human-like, but not quite there.

09:59.120 --> 10:00.120
Okay.

10:00.120 --> 10:06.120
And usually, you can tell in the eyes that's usually a giveaway, and you start to get this

10:06.120 --> 10:14.040
uneasy feeling, because, you know, you see the human-like quality that could be there,

10:14.040 --> 10:16.080
but it's not quite human-like.

10:16.080 --> 10:18.080
Okay.

10:18.080 --> 10:27.080
And that's a big issue with characters in VR and virtual environments, so.

10:27.080 --> 10:31.520
But eventually, we pivoted into the AI space.

10:31.520 --> 10:39.400
And so, I've been using my background to build, help build in the cognitive components

10:39.400 --> 10:50.200
into our system, things like decision-making and perception, and memory as well.

10:50.200 --> 10:57.800
Inside of curiosity, what drove the pivot from VR to AI?

10:57.800 --> 11:08.280
I, it was, you know, business decision, but I believe that we saw a bigger opportunity

11:08.280 --> 11:13.920
if you will in AI, especially a general AI platform that we're working on.

11:13.920 --> 11:20.840
VR, that is, is, you know, is vast as well, and there are a lot of areas that you can

11:20.840 --> 11:24.040
go into that people don't necessarily recognize.

11:24.040 --> 11:33.880
It's way more than the entertainment space, but AI can, it affects almost every single field

11:33.880 --> 11:37.920
there is, almost every single area of business.

11:37.920 --> 11:45.360
I was on a panel a few months ago and someone asked, you know, is there, is there any area

11:45.360 --> 11:48.880
that you can think of that hasn't been touched by AI?

11:48.880 --> 11:55.320
And they're, you know, that we tried to come up with one example, but if it's not already,

11:55.320 --> 11:59.000
it is going to be affected, yeah.

11:59.000 --> 12:06.920
And so just for context, and I really want to dig into your, you know, how your background

12:06.920 --> 12:13.080
ties into your current work, but for context, you said that at dimensional mechanics, you're

12:13.080 --> 12:20.240
working on a platform for, did you say a general platform for AI or a platform for general

12:20.240 --> 12:21.240
AI?

12:21.240 --> 12:26.000
I thought I saw the ladder on the website or something or someplace.

12:26.000 --> 12:27.000
Yeah.

12:27.000 --> 12:35.200
So it's a general AI platform, essentially a set of development tools for companies so

12:35.200 --> 12:42.400
that they can reduce their costs in engineering costs and AI and machine learning.

12:42.400 --> 12:51.280
It's, AI is very expensive to produce and you need quite a bit of manpower and especially,

12:51.280 --> 12:57.040
you know, you have to have essentially, you know, experts currently, but we are trying

12:57.040 --> 13:05.120
to do away with that so that someone who is interested in AI or, you know, a company

13:05.120 --> 13:11.880
that maybe doesn't necessarily have AI and ML experts, they can still build models to

13:11.880 --> 13:13.880
solve their problems.

13:13.880 --> 13:14.880
Okay.

13:14.880 --> 13:15.880
Got it.

13:15.880 --> 13:22.680
I thought I read that you guys were going after the, the AGI problem, artificial general

13:22.680 --> 13:31.480
intelligence, but it sounds like, it sounds more narrowly constrained than that a little

13:31.480 --> 13:32.480
bit.

13:32.480 --> 13:33.480
Yeah.

13:33.480 --> 13:38.360
I mean, we're, we're definitely adding to that conversation and adding to those efforts.

13:38.360 --> 13:46.280
We want to build general AI, but it actually should mention that we are currently in the

13:46.280 --> 13:47.880
media space.

13:47.880 --> 13:52.560
So, you know, you have to narrow it down somewhat.

13:52.560 --> 14:00.800
So we're currently working with companies to build AI models for images, video, and text.

14:00.800 --> 14:02.400
Okay.

14:02.400 --> 14:10.080
And I imagine that the media applications lend themselves particularly well to your

14:10.080 --> 14:16.120
background and a cognitive approach to, you know, there are clear cognitive elements

14:16.120 --> 14:19.720
to AI with regards to media.

14:19.720 --> 14:23.240
Can you talk a little bit about how those intersect?

14:23.240 --> 14:24.240
Right.

14:24.240 --> 14:33.760
So, with, let's say, you know, images and video, for example, I come from it actually as

14:33.760 --> 14:39.800
a matter of fact, I'm working on a computer vision project with a local university.

14:39.800 --> 14:49.760
And we try to find parallels between, you know, how humans ingest or process, I guess,

14:49.760 --> 14:50.760
perceive media.

14:50.760 --> 14:56.840
That's the best way to put it and how a system would do the same thing.

14:56.840 --> 15:04.000
And it's, you know, obviously there's going to be vast differences between how a machine

15:04.000 --> 15:10.600
does and how a human does and we're not trying to make a one-to-one mapping, but there's

15:10.600 --> 15:12.240
a lot to be said.

15:12.240 --> 15:19.720
There's a lot of information and there's a lot of inspiration in how a human perceives

15:19.720 --> 15:28.120
media and that we can apply to how a machine perceives media.

15:28.120 --> 15:38.520
So, for example, and, you know, in computer vision, you can think of it as like a multi-disciplinary

15:38.520 --> 15:45.840
field because you're drawing from vision science, you're drawing from computer science,

15:45.840 --> 15:49.960
psychology, you know, cognitive science.

15:49.960 --> 15:57.080
And so, you know, and part of that is looking at, you know, exactly.

15:57.080 --> 16:07.480
So, part of the way that researchers create ground truth for computer vision experiments

16:07.480 --> 16:10.680
is they look at human ratings.

16:10.680 --> 16:19.000
They'll have, you know, humans view a set of videos, do eye tracking and whatnot and

16:19.000 --> 16:25.800
then try to apply that, you know, that eye gaze data to the system at hand.

16:25.800 --> 16:27.800
So that can be built in.

16:27.800 --> 16:37.000
So, you know, in by using those human ratings, you can build smarter systems.

16:37.000 --> 16:42.400
Just to make sure I'm understanding all of what you're saying.

16:42.400 --> 16:51.280
So we can envision a system where a labeling system where you've got some humans that

16:51.280 --> 16:56.680
are trying to label a set of images.

16:56.680 --> 17:02.920
And you're saying that in addition to just the label that they're, you know, that they

17:02.920 --> 17:07.960
may type in to, you know, or a set of labels that they may type in, you're also doing

17:07.960 --> 17:13.560
something like, you know, eye tracking with the camera or something like that to see where

17:13.560 --> 17:20.160
they're looking on the images and that helps you to refine the training process.

17:20.160 --> 17:21.160
Right.

17:21.160 --> 17:25.960
There's a lot of, there's a lot of rich information.

17:25.960 --> 17:34.960
There can be from eye tracking studies and, you know, how humans, what is the eye gaze

17:34.960 --> 17:36.040
data look like?

17:36.040 --> 17:43.160
What do, you know, one of my focuses is no pun intended but an intention, user attention

17:43.160 --> 17:48.960
in that when we take in an environment, when we're looking around, there's tons and tons

17:48.960 --> 17:49.960
of stimuli.

17:49.960 --> 17:52.880
The way that we can process it all of once.

17:52.880 --> 17:58.760
And so with humans, the whole scene is not relevant at the same time.

17:58.760 --> 17:59.760
Right.

17:59.760 --> 18:04.080
It's going to be relevant in basically spotlights.

18:04.080 --> 18:09.720
So you can apply that with a system as well.

18:09.720 --> 18:17.840
If you may want to enhance certain parts of images or video, but you may want to do it

18:17.840 --> 18:24.640
in a fashion where it's focusing on the most relevant information in that scene.

18:24.640 --> 18:31.800
And so back to your grad school research on multimodal and kind of this model of the

18:31.800 --> 18:37.640
brain where, you know, you have just a bunch of inputs and you're processing them, you

18:37.640 --> 18:38.680
know, kind of as equals.

18:38.680 --> 18:44.720
Are there other examples of inputs or other examples of this, of the multiple modes

18:44.720 --> 18:49.800
that you're incorporating into your work today?

18:49.800 --> 18:56.520
Not particularly currently, but I would like to see, and this is something that I'd like

18:56.520 --> 19:05.840
to implement later and it's the, I guess, intersection or combination of audio and

19:05.840 --> 19:06.840
visual.

19:06.840 --> 19:07.840
Okay.

19:07.840 --> 19:15.040
I have seen some early work in this, but, you know, if, let's say, let's say you're watching

19:15.040 --> 19:21.800
a video and there's likely going to be audio as well.

19:21.800 --> 19:29.960
And where you're focusing your attention is going to be not only influenced by the visuals,

19:29.960 --> 19:39.520
but also, and also by the audio, but the, what's critical is the combination of the, you

19:39.520 --> 19:44.160
know, space spatial temporal information.

19:44.160 --> 19:50.680
That's, that's something that's going to heavily influence where your attention is guided

19:50.680 --> 19:52.000
in the scene.

19:52.000 --> 20:00.560
And so I think there needs to be a lot more research in that space, you know, previously,

20:00.560 --> 20:06.080
there's been a lot of studies on this, but, you know, there's been a lot of focus on

20:06.080 --> 20:12.600
the visual, obviously, and there's been a lot, there's been some focus on the audio,

20:12.600 --> 20:21.480
but really where you're going to find fascinating insights is the, the combination, what's

20:21.480 --> 20:27.520
going on spatially, what's going on temporarily, and that, that intersection.

20:27.520 --> 20:34.000
And practically speaking, how might you expect that to impact an AI project?

20:34.000 --> 20:46.240
So let's say you build a model to detect the tone of a commercial, well, that's going

20:46.240 --> 20:55.560
to use both video, the visuals and the, and throughout the commercial, and then also,

20:55.560 --> 21:07.280
you know, advertisers put a lot of focus on the audit, auditory aspect as well, the, you

21:07.280 --> 21:15.320
know, the, the mood of the, the mood of the music, going with, you know, what's going

21:15.320 --> 21:16.720
on in the scene.

21:16.720 --> 21:30.600
So with an AI system, if you're able to train it on the video, and then train it on the,

21:30.600 --> 21:36.400
the audio, and then, yeah, I can think of like a kind of a thought experiment right now.

21:36.400 --> 21:43.000
So you can see if it can recognize the, the tone of the video just solely through the

21:43.000 --> 21:50.640
visual, and then see if how well it does with just the audio, but I bet you that when

21:50.640 --> 21:57.440
you combine both of them, you have both types of information that will allow it to best

21:57.440 --> 22:03.360
categorize the, the tone of the video.

22:03.360 --> 22:04.360
Got it.

22:04.360 --> 22:08.040
I mean, it sounds like the basic idea is just try to use all the information that you have

22:08.040 --> 22:15.120
to, to make more accurate models, and often it turns out that the information that you

22:15.120 --> 22:18.800
have comes in, you know, multiple modes.

22:18.800 --> 22:25.960
Some of it is, some of it is audio, some of it is video, you know, and there may be others

22:25.960 --> 22:27.280
as well.

22:27.280 --> 22:28.280
Right.

22:28.280 --> 22:31.920
That's, yeah, exactly.

22:31.920 --> 22:36.720
If we, you know, the more information that we have available, the more information we

22:36.720 --> 22:44.440
can train our systems with, and that's how we, as humans learn as well.

22:44.440 --> 22:51.640
For example, in the education room, you know, you have a video of a lecture, you have an

22:51.640 --> 23:00.320
audio of a lecture, but if you are not only, you know, you're using both, and you know,

23:00.320 --> 23:07.040
the best is if you're actually in the classroom and immersed and you have both, both sensory

23:07.040 --> 23:12.600
streams coming in, the visuals and the auditory, you're going to have a better chance of, you

23:12.600 --> 23:17.320
know, remembering the content and, and being able to build off of that as well.

23:17.320 --> 23:18.320
Right.

23:18.320 --> 23:19.320
Right.

23:19.320 --> 23:27.560
Now a lot of your work calls into question the whole notion of, you know, biological

23:27.560 --> 23:34.920
plausibility for neural nets and the extent to which we should be trying to model neural

23:34.920 --> 23:38.080
nets and AI systems after human systems.

23:38.080 --> 23:43.680
And in fact, you wrote about this in a blog post last year.

23:43.680 --> 23:50.200
What are your thoughts on, you know, this whole question?

23:50.200 --> 23:58.160
It's, it's debatable, definitely, and depending on, you know, what your background is, I've

23:58.160 --> 24:04.960
seen some hardcore computer scientists where they're like, you don't need this plausibility.

24:04.960 --> 24:12.840
But since my, my background is very brain heavy, I definitely want to include that in the

24:12.840 --> 24:20.280
conversations, hey, okay, well, to what extent do we need to model these systems after the

24:20.280 --> 24:22.480
human brain?

24:22.480 --> 24:27.440
It does not need to be a one-on-one mapping.

24:27.440 --> 24:36.600
I do believe that because with the brain, the human brain and, you know, a computer, the

24:36.600 --> 24:41.440
lower level bits are very different.

24:41.440 --> 24:52.600
There's some similarity there with neurons firing and the binary bits for computers, but

24:52.600 --> 24:54.360
it wouldn't be in our best interest.

24:54.360 --> 24:56.920
There are so many other things that we need to tackle right now.

24:56.920 --> 25:02.640
It wouldn't be in our best interest to try to make a one-on-one mapping.

25:02.640 --> 25:10.480
But these systems, in my opinion, should be biologically inspired.

25:10.480 --> 25:20.240
So we can take concepts like modularity or integrated systems, localization.

25:20.240 --> 25:28.720
We can take all of these aspects from neuroscience and cognitive science and apply them to building

25:28.720 --> 25:30.440
these models.

25:30.440 --> 25:39.240
And I personally try to keep that in mind when I'm building various AI models.

25:39.240 --> 25:49.040
And I think of modularity and locality as computer science things, as technical things.

25:49.040 --> 25:56.480
Can you talk about how those concepts express themselves biologically and how they've influenced

25:56.480 --> 25:58.800
the types of models you build?

25:58.800 --> 25:59.800
Sure.

25:59.800 --> 26:11.200
So modularity, it's the idea that the brain processes, there are different areas for different

26:11.200 --> 26:12.200
processes.

26:12.200 --> 26:20.720
There's an area for language, there's an area for motor, there's an area for other types

26:20.720 --> 26:23.840
of processes and systems.

26:23.840 --> 26:32.840
So and they're believed to be all encompassing, if you will, or self-contained.

26:32.840 --> 26:35.080
I'm not particularly from that school of thought.

26:35.080 --> 26:39.880
I think there's relevance in that school of thought.

26:39.880 --> 26:48.000
But there's also a lot of ton of interconnectivity.

26:48.000 --> 26:55.560
And that's really, it's literally all connected, and even if there's some localization, a particular

26:55.560 --> 27:03.920
area for language, that's going to influence the visual processes that's going to influence

27:03.920 --> 27:06.040
the auditory processing.

27:06.040 --> 27:15.560
So in my opinion, it's really all about interconnectivity, but as far as building AI models, so this is

27:15.560 --> 27:21.840
kind of going back to the thought experiment that I brought up.

27:21.840 --> 27:27.160
But you can think of it as when you're training these models.

27:27.160 --> 27:33.320
You can think about what kind of, I guess, you can think of it as terms of sensory input

27:33.320 --> 27:37.200
and separate streams or combined streams.

27:37.200 --> 27:42.800
So you can feed an audio, you can feed in video, and then you can feed in the combination

27:42.800 --> 27:43.800
of that.

27:43.800 --> 27:52.680
And you can think of that as the interconnectivity equivalent, if you will.

27:52.680 --> 27:58.880
So this reminds me of some conversations I've had recently about folks working on deep

27:58.880 --> 28:07.840
neural nets, and this question comes up when they're trying to develop these complex,

28:07.840 --> 28:12.520
deep neural networks, whether they, you know, whether they're ultimately developing

28:12.520 --> 28:21.200
this kind of the single model that takes in all the input and produces all of the outputs,

28:21.200 --> 28:26.960
and it's kind of monolithic, or whether they develop, you know, what looks more like

28:26.960 --> 28:35.200
an ensemble, in a sense of, you know, or a hierarchical neural network model where

28:35.200 --> 28:41.360
they've, you know, they're taking in, you know, inputs and training the model to be able

28:41.360 --> 28:46.200
to determine, you know, some kind of higher level feature.

28:46.200 --> 28:50.440
And then they have, you know, many of these in parallel that they feed into kind of a higher

28:50.440 --> 28:55.360
level neural network to, you know, make the ultimate decision.

28:55.360 --> 28:59.000
And this may happen in several layers.

28:59.000 --> 29:06.920
It sounds like what you're saying is that that is ultimately more, you know, that's closer

29:06.920 --> 29:11.600
to what the brain is doing, than the, you know, we think of the brain, I guess, and I

29:11.600 --> 29:17.320
guess as laypeople is kind of this monolithic thing, but you're saying that the, you know,

29:17.320 --> 29:19.120
in many ways is kind of hierarchical.

29:19.120 --> 29:21.120
Is that, is that accurate?

29:21.120 --> 29:27.600
Yeah, I mean, and you can take a particular system, the visual system, for example.

29:27.600 --> 29:34.560
So, you know, you get the early visual sensory input, you know, it's really globs and

29:34.560 --> 29:36.600
shapes and shadows.

29:36.600 --> 29:46.520
And then as the input gets further up the streaming to V3 and V4, then you start to actually

29:46.520 --> 29:53.320
make out a particular image, you know, a scene of a park or a beach or whatever it is.

29:53.320 --> 30:01.880
So yeah, it goes from sort of like a lower level abstract to the more.

30:01.880 --> 30:08.680
And yeah, I mean, I agree with the idea that, you know, we have these lower level processes

30:08.680 --> 30:15.640
that are done first and then as they are being carried out and further processed, then

30:15.640 --> 30:23.360
you get things that are more fine, fine tuned, fine grain, if you will.

30:23.360 --> 30:28.200
You can also apply that to the motor system as well.

30:28.200 --> 30:34.640
But first, when your motor system is still developing, you know, you're going to have

30:34.640 --> 30:43.040
clunky, non-coordinated movements, but then as you go further along and you can fine tune

30:43.040 --> 30:48.920
them and fine train them, then you're able to write, you're able to type, you're able

30:48.920 --> 30:52.280
to do more fine tune movements.

30:52.280 --> 31:00.760
Are there a set of principles? Do you think that, you know, anyone working in this field

31:00.760 --> 31:09.200
should be thinking about as they're approaching, you know, developing AI systems with regard

31:09.200 --> 31:16.600
to, you know, this whole issue of biological reference or plausibility?

31:16.600 --> 31:24.480
I would say, I think in terms of, you know, being interdisciplinary, there are a lot of

31:24.480 --> 31:33.080
areas that come together in AI and I think in order to be, to develop successfully, you

31:33.080 --> 31:36.400
need to borrow from each of those.

31:36.400 --> 31:44.000
Like I said, you know, computer science, cognitive science, psychology, all of these, these

31:44.000 --> 31:51.400
different areas are going to get you, are going to help you build a better foundation,

31:51.400 --> 32:00.800
as opposed to, you know, just focusing on the computer science theories or the, you know,

32:00.800 --> 32:06.040
cognitive science theories, you really need a combination of all of them.

32:06.040 --> 32:12.960
Are there a set of canonical references that folks should take a look at to dig into

32:12.960 --> 32:16.360
this area more?

32:16.360 --> 32:23.240
It wouldn't hurt to read up on the history of AI, I think it's a little known fact for

32:23.240 --> 32:27.920
some that it's actually been around since the fifties.

32:27.920 --> 32:35.360
A man named Marvin Minsky was, you know, he's considered to be the father of AI.

32:35.360 --> 32:41.880
I would, I would read up on, on him, his work, I'd read up on Alan Turing.

32:41.880 --> 32:48.960
He laid some of the foundational, you know, thinking in AI, yeah, it's start there.

32:48.960 --> 32:49.960
Yeah.

32:49.960 --> 32:50.960
Awesome.

32:50.960 --> 32:52.120
Awesome.

32:52.120 --> 33:01.920
So maybe let's, let's try to dig into, you know, some, some more concrete things are there.

33:01.920 --> 33:07.440
Specific applications of what you guys are doing at dimensional mechanics that we can

33:07.440 --> 33:14.600
maybe talk about or what, you know, ways that you're helping customers develop AI applications

33:14.600 --> 33:15.960
with your platform.

33:15.960 --> 33:16.960
Yeah.

33:16.960 --> 33:24.840
So we have a demo on our site, actually, I wish I could go into a lot more detail.

33:24.840 --> 33:32.360
But for now, I'll just mention the demo and the site and that's an image-rinking demo where

33:32.360 --> 33:38.880
you can upload a photo and it will give it a score.

33:38.880 --> 33:39.880
Okay.

33:39.880 --> 33:46.400
And relative to the other, the existing photos on there, and you can see them, you can

33:46.400 --> 33:47.920
scroll through them.

33:47.920 --> 33:49.880
There's a top, top 10 list.

33:49.880 --> 33:50.880
Okay.

33:50.880 --> 33:53.960
And it's scoring it from what perspective?

33:53.960 --> 33:58.040
The, so it's trying to give it the best ranking.

33:58.040 --> 34:07.160
So it's, it's using a lot of different metrics, can't really go into the particulars, but

34:07.160 --> 34:13.600
is it, is it trying to label the image or trying to rate its aesthetic quality or?

34:13.600 --> 34:17.600
It's, yeah, it's trying to rate its aesthetic quality.

34:17.600 --> 34:18.600
Okay.

34:18.600 --> 34:19.920
Got it.

34:19.920 --> 34:24.720
So it's kind of, I don't know if anybody remembers the hot or not app, it's kind of the hot or

34:24.720 --> 34:28.040
not app for, for images.

34:28.040 --> 34:29.040
Right.

34:29.040 --> 34:33.000
We, that's brought up and, that's been brought up at our discussions.

34:33.000 --> 34:34.000
Okay.

34:34.000 --> 34:41.120
But yeah, it's, like I said, it's rating the more aesthetic qualities of, of an image.

34:41.120 --> 34:42.120
Okay.

34:42.120 --> 34:51.640
And in what ways has the, your work around the cognitive psychology influenced how a

34:51.640 --> 34:54.480
system like that works?

34:54.480 --> 35:01.880
So part of this is going, is going to go back to, you know, how, how a person perceives

35:01.880 --> 35:02.880
an image.

35:02.880 --> 35:05.680
And I'll just give, you know, very general example.

35:05.680 --> 35:14.040
So, you know, when we see an image, we're taking in a lot of aspects, the shadows involve

35:14.040 --> 35:20.320
the lighting, the angle of object, the, you know, the, the, the, sort of the busyness

35:20.320 --> 35:24.960
or the, you know, the, the contrast involved.

35:24.960 --> 35:31.600
So we're assessing all of those things when we're an image.

35:31.600 --> 35:36.400
And you could say that the system is doing something similar.

35:36.400 --> 35:37.400
Okay.

35:37.400 --> 35:41.760
Uh, this is, this is kind of getting me into another space.

35:41.760 --> 35:44.400
So one thing, it's interesting.

35:44.400 --> 35:48.400
So have you heard of the black box problem?

35:48.400 --> 35:52.160
Generally, yes, generally, I've heard of a black box problem.

35:52.160 --> 35:56.160
I don't know if it's the same one that you're, when I think of the black box problem,

35:56.160 --> 36:00.040
I think of that, uh, from, uh, an AI explainability perspective.

36:00.040 --> 36:01.040
Right.

36:01.040 --> 36:02.040
Right.

36:02.040 --> 36:03.840
And that's, that's what I was going to get into.

36:03.840 --> 36:04.840
Okay.

36:04.840 --> 36:07.800
So for, and then there's a parallel with humans as well.

36:07.800 --> 36:15.640
So, you know, we, as researchers, we present a set of stimuli and then, you know, a person

36:15.640 --> 36:24.800
responds to those given stimuli, but what's exactly is going on in between is, uh, you

36:24.800 --> 36:30.160
know, it's debatable sometimes more, more times than not.

36:30.160 --> 36:37.280
And with AI, uh, that's one of the things that we're trying to work on as well, not necessarily

36:37.280 --> 36:45.160
dimensional mechanics, but as a, as a field, um, trying to demystify what's going on

36:45.160 --> 36:52.680
in between, um, and they're, they're, I, I think that taking a good, hard look at the,

36:52.680 --> 36:58.400
the training sets that you and, and manipulating those in a way where, you know, you're feeding

36:58.400 --> 37:04.600
in sections at a time and, you know, these have, this section has particular features.

37:04.600 --> 37:09.840
This one doesn't, that can possibly get at, at that question, but it's going to take

37:09.840 --> 37:12.080
a lot more, more work.

37:12.080 --> 37:13.080
Mm-hmm.

37:13.080 --> 37:18.680
And I think once we do that, it'll, we'll be able to, AI models will be that much more

37:18.680 --> 37:24.160
valuable because we'll be able to tweak as, as necessary.

37:24.160 --> 37:25.160
Right.

37:25.160 --> 37:26.160
Right.

37:26.160 --> 37:33.000
Uh, so going back to this demo application, you know, presumably you've trained, you

37:33.000 --> 37:43.080
developed some AI model, uh, to rank these images and you've trained it on lots of input

37:43.080 --> 37:44.080
data.

37:44.080 --> 37:50.600
Uh, did the multi-modal training come into play in, in this case?

37:50.600 --> 37:57.120
Not in the current iteration, but that is something we would definitely want to explore

37:57.120 --> 38:01.320
on how to make it smarter, if you will.

38:01.320 --> 38:03.320
Right.

38:03.320 --> 38:04.320
Yeah.

38:04.320 --> 38:11.840
Yeah, I can imagine, um, you know, if someone is, if someone is rating images on a, uh,

38:11.840 --> 38:20.320
numeric scale, but you also had a camera looking at them, observing them, then you, there's

38:20.320 --> 38:26.240
a ton of additional information like, you know, the creases in their eyes when they smile,

38:26.240 --> 38:33.840
you know, the smile, the eyes, you know, they could, that could perhaps, uh, lend some

38:33.840 --> 38:39.040
additional insight as to whether this is a visually appealing image.

38:39.040 --> 38:40.040
Right.

38:40.040 --> 38:44.640
There's so many factors that, that come into play, you know, like I said, whether you

38:44.640 --> 38:50.440
have the right lighting, whether the, the expression on someone's face, um, what that's

38:50.440 --> 38:52.600
conveying, there, there's so many things.

38:52.600 --> 38:56.120
So, uh, it would be great to further explore it.

38:56.120 --> 39:02.160
We've built it on a, you know, particular set of features, but, um, we would definitely

39:02.160 --> 39:05.400
like to expand that in the, in the future.

39:05.400 --> 39:06.400
Mm-hmm.

39:06.400 --> 39:11.720
Are there any other, uh, kind of applications or use cases that, um, might be interesting

39:11.720 --> 39:13.040
to explore?

39:13.040 --> 39:15.040
Oh, there are tons.

39:15.040 --> 39:18.280
It's really about having time to explore them.

39:18.280 --> 39:19.280
Yeah.

39:19.280 --> 39:20.280
Yeah.

39:20.280 --> 39:25.680
It would be great to get a sense for, you know, I think we, you've given us a sense thus

39:25.680 --> 39:35.880
far that having a cognitive psychology background can really lend insight into, you know, ways

39:35.880 --> 39:41.080
to think about, you know, your modeling and your training, uh, and it would be great

39:41.080 --> 39:48.360
to, you know, then talk through some examples of, you know, how, how that's kind of played

39:48.360 --> 39:57.160
out in kind of a customer scenario or a, you know, just a practical scenario so that folks

39:57.160 --> 40:02.920
can kind of see the line kind of go from beginning to end, if that makes sense.

40:02.920 --> 40:03.920
Okay.

40:03.920 --> 40:08.960
And I've taught, yeah, and I've touched on this a little bit earlier, but, you know, we're

40:08.960 --> 40:20.120
looking at what, what we're looking at, user interest and engagement, um, essentially,

40:20.120 --> 40:25.360
you know, when you see a scene, what is, what's relevant to you, what, what catches your

40:25.360 --> 40:26.360
attention?

40:26.360 --> 40:27.360
Right.

40:27.360 --> 40:28.360
Right.

40:28.360 --> 40:34.840
And once various factors of that can, can be identified and what, by the way, we're,

40:34.840 --> 40:41.800
you know, looking at both lower, lower level features, things like, uh, line orientation

40:41.800 --> 40:48.520
and color, you know, very low level features that would grab your attention automatically,

40:48.520 --> 40:49.760
if you will.

40:49.760 --> 40:56.680
And then also higher level things like, uh, emotion, things that, uh, more, I guess there's

40:56.680 --> 41:05.880
a term top down, um, attention, which is, is intentional based, you're, you're, um,

41:05.880 --> 41:11.680
looking at something intentionally, okay, um, or, you know, goal or oriented.

41:11.680 --> 41:16.440
So the possible applications of that, that research.

41:16.440 --> 41:21.160
So I've, you know, talked about, uh, the advertising space, right.

41:21.160 --> 41:29.000
So, you know, for example, if advertisers can take this research and realize, okay, at

41:29.000 --> 41:35.600
the 32nd mark, this is where this particular, you know, location in the, the scene, this

41:35.600 --> 41:40.640
is where people are going to be most engaged, uh, most, they feel like there's something

41:40.640 --> 41:44.080
most relevant in that, in that, uh, particular area.

41:44.080 --> 41:51.120
Well, that could be a great placement for product ad, you know, or product logo.

41:51.120 --> 41:57.560
You can also get a sense of how long you're going to be able to sustain someone's, how,

41:57.560 --> 42:01.960
how much, how much time someone's attention is going to be sustained, you know, in a world

42:01.960 --> 42:07.840
where we're on our phones all the time, um, that, that gap is shrinking.

42:07.840 --> 42:14.680
So, you know, with advertisers, it's that much more critical to find what's relevant

42:14.680 --> 42:20.280
and, and get in there before, uh, the user's, uh, attention is lost.

42:20.280 --> 42:21.280
Okay.

42:21.280 --> 42:27.440
So, then you're through this research, you're developing models that can, that can look

42:27.440 --> 42:34.040
at, uh, is it only static images or is it, uh, video as well in this project?

42:34.040 --> 42:35.040
It's video as well.

42:35.040 --> 42:36.040
Okay.

42:36.040 --> 42:37.520
Actually, in this particular project, it's video.

42:37.520 --> 42:38.520
Oh, okay.

42:38.520 --> 42:45.640
So, you're, you're looking at, you're basically training models to, to model human attention

42:45.640 --> 42:53.480
and interest, uh, on these videos, and then you can use that to help advertisers assess

42:53.480 --> 42:56.400
their work, for example.

42:56.400 --> 43:03.480
So as opposed to convening a panel or a focus group to try to get a sense for whether an

43:03.480 --> 43:10.200
advertisement is effective, uh, you know, which is probably expensive in time consuming

43:10.200 --> 43:18.480
and maybe not even all that accurate, you can use these models to screen the, the advertisements

43:18.480 --> 43:22.400
to, you know, for screen the advertisements for effectiveness.

43:22.400 --> 43:24.400
Is that the general idea?

43:24.400 --> 43:25.400
Right.

43:25.400 --> 43:27.240
And going off the accuracy point.

43:27.240 --> 43:33.920
So, you know, a lot of times in focus groups and whatnot, there, there's a, uh, uh, verbal

43:33.920 --> 43:42.560
or written response, but a lot of times what we say is not necessarily reflecting what's

43:42.560 --> 43:44.040
going on internally.

43:44.040 --> 43:45.040
Right.

43:45.040 --> 43:46.040
Right.

43:46.040 --> 43:47.040
Right.

43:47.040 --> 43:53.040
And we try to get at that as well, um, we currently use tools like, um, eye tracking and

43:53.040 --> 43:54.440
biometric sensors.

43:54.440 --> 44:01.440
So to get at the physiological responses to, to the input, to the video input.

44:01.440 --> 44:02.440
Okay.

44:02.440 --> 44:10.200
Uh, and, uh, I forget if we cover this, but what do you call that that phenomenon?

44:10.200 --> 44:17.800
Like I know a related idea is, I guess I, you call it attribution error or, uh, you

44:17.800 --> 44:22.000
know, issues around attribution, meaning if you, if I look at an image, I can tell you

44:22.000 --> 44:25.480
I like it, but I can't tell you necessarily why I like it.

44:25.480 --> 44:32.320
Is there a specific, is there specific terminology for, um, you know, the, um, you know, the,

44:32.320 --> 44:37.560
uh, other side of this, which is, you know, I might not even, I might say I like it,

44:37.560 --> 44:41.160
but I might not really like it or vice versa.

44:41.160 --> 44:42.160
Right.

44:42.160 --> 44:46.000
Well, there, there are a lot of things that come to play, especially in an experimental

44:46.000 --> 44:47.080
setting.

44:47.080 --> 44:49.600
So there is experiment or bias.

44:49.600 --> 44:53.960
If, you know, the, there might be some influence of the experiment or you have to be careful

44:53.960 --> 44:57.480
in the way that it's asked if you are going to ask.

44:57.480 --> 45:03.440
Because the question itself can be loaded and, and, and bias the response.

45:03.440 --> 45:10.360
This is getting into another area, but, uh, with eyewitness experiments, the way that

45:10.360 --> 45:17.400
you pose a question can definitely influence how the person will, will respond.

45:17.400 --> 45:24.920
You can, you know, let's say there is, um, an accident and, you know, you, you throw

45:24.920 --> 45:30.600
in an object in the question, like, uh, at the stop sign, blah, blah.

45:30.600 --> 45:37.560
Well, the fact that you mentioned the stop sign, you know, even if there wasn't one there,

45:37.560 --> 45:41.680
the person may still agree, I say, yeah, okay, I remember the stop sign.

45:41.680 --> 45:46.080
It's like, no, there wasn't even a stop sign there at that particular scene.

45:46.080 --> 45:52.880
So, so there's experiment or bias, there's, so you mentioned attribution, but there, you

45:52.880 --> 45:57.920
also want to be seen in a particular way as well when you respond.

45:57.920 --> 46:02.800
Um, so you have to keep that in mind, and we may not even be conscious of that.

46:02.800 --> 46:07.960
We just, we, we want to have, we want to produce positive responses.

46:07.960 --> 46:08.960
Mm-hmm.

46:08.960 --> 46:13.400
So, you know, to get away with all, get away at all that, I think a great measure is,

46:13.400 --> 46:19.080
is more something physiological that, you know, it doesn't get a chance to reach our

46:19.080 --> 46:20.080
thoughts.

46:20.080 --> 46:23.480
Mm-hmm, interesting, interesting.

46:23.480 --> 46:31.640
So, beyond just this attribution issue and my ability to articulate, there is a whole

46:31.640 --> 46:40.520
host of cognitive biases that can, um, that can distance someone's real perception of,

46:40.520 --> 46:46.080
an image or video from what they ultimately say and some kind of panel or focus group

46:46.080 --> 46:56.520
and thus being able to develop machine models that can, you know, not just rate the, the

46:56.520 --> 47:03.120
image or model, the, you know, the human reception of an image, but also maybe tell us a little

47:03.120 --> 47:08.940
bit, you know, as we kind of get further along with the black box issue, tell us what the

47:08.940 --> 47:15.280
issues are, you know, this one may be too dark here or too contrasty there, that kind

47:15.280 --> 47:16.280
of thing.

47:16.280 --> 47:17.280
Right.

47:17.280 --> 47:18.280
Right.

47:18.280 --> 47:22.760
To give, you know, possibly a more objective measure, if you will.

47:22.760 --> 47:23.760
Mm-hmm.

47:23.760 --> 47:29.800
It sounded like you were wrapping up this research project, um, what's on the horizon for

47:29.800 --> 47:30.800
you?

47:30.800 --> 47:34.480
Are there any areas that you're, any particular areas that you're looking forward

47:34.480 --> 47:37.360
to exploring further?

47:37.360 --> 47:44.320
Right now, I am working on a, learning more about the natural language processing space,

47:44.320 --> 47:50.240
which I find really fascinating, especially with my psycho linguistics background.

47:50.240 --> 47:57.480
So for those who don't know, natural language processing, um, is the ability for systems

47:57.480 --> 48:06.960
to take natural text, you know, anything as short as words, phrases, and to documents,

48:06.960 --> 48:15.600
full documents, novels, even, and, uh, be able to get insights out of that input data.

48:15.600 --> 48:21.520
Things like, I mean, you can get more technical things like frequency counts and, and whatnot,

48:21.520 --> 48:28.600
but you can figure out the, the sentiment of a particular, uh, text.

48:28.600 --> 48:37.200
You can figure out all kinds of things that, you know, it would take a person hundreds

48:37.200 --> 48:39.400
and hundreds of hours to do.

48:39.400 --> 48:45.560
You can just load in all of these, uh, documents and, you know, get a score for sentiment.

48:45.560 --> 48:53.160
Is it particularly positive or negative or all kinds of, uh, different insights?

48:53.160 --> 49:02.240
And what, uh, what is peaking your curiosity around, uh, NLP and, uh, the application of

49:02.240 --> 49:05.880
psycho linguistics to, to that field?

49:05.880 --> 49:10.760
Maybe we can start with, uh, what is psycho linguistics relative to, you know, traditional

49:10.760 --> 49:13.520
linguistics or other aspects of linguistics?

49:13.520 --> 49:14.520
Sure.

49:14.520 --> 49:23.840
So linguistics is, you know, the study of language, the parts of language, the structures

49:23.840 --> 49:32.320
and whatnot, and psycho linguistics, it's bringing in psychology into that.

49:32.320 --> 49:37.800
You know, you're, you're looking at things like the way in which people say things, um,

49:37.800 --> 49:44.560
that term is prosody, the inflection and someone's invoice to convey certain messages.

49:44.560 --> 49:45.560
Okay.

49:45.560 --> 49:46.560
It's, you know, it's fascinating.

49:46.560 --> 49:51.320
You take one sentence, the man went to the park.

49:51.320 --> 49:53.360
The man went to the park.

49:53.360 --> 49:59.680
The man went to the park, you know, if the, you can say the exact same thing, but put different

49:59.680 --> 50:02.640
inflection on it and has a completely different meaning.

50:02.640 --> 50:03.640
Okay.

50:03.640 --> 50:10.000
There's, you know, the way, uh, the way in which we produce sentences and the, you know,

50:10.000 --> 50:20.160
syntactic structure and how that affects both the producer of the speech and then also

50:20.160 --> 50:23.760
the, you know, listener as well.

50:23.760 --> 50:33.120
Um, it also gets into, you know, co-articulation and these other mechanics of speech that's

50:33.120 --> 50:35.200
what's co-articulation?

50:35.200 --> 50:43.240
Coarticulation is when it's the, it, it's so it has to do with the flow of words.

50:43.240 --> 50:49.640
When, when we're speaking, all the words seem discreet, but if you look at an audio form,

50:49.640 --> 50:59.200
uh, waveform, you'll notice that the sounds actually overlap and so that's the coarticulation.

50:59.200 --> 51:06.320
And you also get into the social aspects of speech, so when, uh, two people are conversing

51:06.320 --> 51:15.040
and there's a, uh, phenomena that occurs called common ground and that's when, um, you

51:15.040 --> 51:20.840
know, you start out using different terms, but over the course of the conversation, you

51:20.840 --> 51:26.160
start to use similar terms to each other, not the same ones, um, because you've built

51:26.160 --> 51:31.920
up, built up a report, uh, gosh, I mean, there's, there's so much, there's, there's also the

51:31.920 --> 51:37.560
phenomena where, um, you know, you're building up that common ground, but then you also take

51:37.560 --> 51:44.720
on a similar speaking style to that person, um, and that can also convey that you, you

51:44.720 --> 51:46.080
like that person.

51:46.080 --> 51:48.480
You can also, and that's called convergence.

51:48.480 --> 51:49.480
Okay.

51:49.480 --> 51:55.560
There's also divergence where maybe, um, you're, you're not a big fan of that person.

51:55.560 --> 52:04.160
You start, uh, changing your speaking style, maybe, you know, unconsciously, but, um, changing

52:04.160 --> 52:06.880
your speaking style, nevertheless.

52:06.880 --> 52:07.880
Hmm.

52:07.880 --> 52:08.880
Interesting.

52:08.880 --> 52:18.920
So when I think of natural language processing, I tend to think of applications that are,

52:18.920 --> 52:27.680
you know, either primarily textual or, um, you know, translation types of applications,

52:27.680 --> 52:33.520
uh, but you're, you know, just your little explanation of cycle linguistics and some,

52:33.520 --> 52:38.480
given some of the background we've talked about, you know, it, it strikes me that there's

52:38.480 --> 52:45.960
a ton of interesting work and exploration to go into, uh, what's, how to articulate

52:45.960 --> 52:46.960
this.

52:46.960 --> 52:54.360
Well, maybe to articulate it by example, like when you create a neural network to recognize

52:54.360 --> 52:59.320
images, right, when, you know, we know a little bit about how those neural network structure

52:59.320 --> 53:05.680
themselves and you've got kind of your edge detectors and your, you know, shading detectors

53:05.680 --> 53:12.800
and all those things that emerge, I wonder the extent to which, uh, the concepts like

53:12.800 --> 53:17.720
prosody and other things, if you're training a neural network on speech samples, you

53:17.720 --> 53:22.760
know, if there are regions in the neural network that emerge, that somehow reflect, you

53:22.760 --> 53:29.080
know, prosody, for example, or if that's a, if that's, you know, is that kind of the

53:29.080 --> 53:31.360
current frontier of research?

53:31.360 --> 53:38.400
Yeah, that's definitely a frontier of this research in this particular space, um, especially

53:38.400 --> 53:46.600
audio, you know, visual inputs have been fairly well studied in the AI space, but audio

53:46.600 --> 53:53.080
less much part of the issue is the shortage of data in that space there.

53:53.080 --> 53:58.800
There are, there are quite a few open source video and image data sets, but not so much

53:58.800 --> 54:04.680
on the audio side, but going back to your point, yeah, I believe that what you would do

54:04.680 --> 54:10.320
is you would set, you know, prosody, up as a feature, you'd set, I don't know, co-articulation

54:10.320 --> 54:16.560
or these other, you know, syntax, you'd, you'd start to set these up as individual features

54:16.560 --> 54:20.960
to train the models.

54:20.960 --> 54:26.960
Meaning that you would, you would have humans identify them somehow and label them or

54:26.960 --> 54:32.360
you would have, how would you set up prosody, for example, as a feature?

54:32.360 --> 54:41.160
It's a good question, so initially it would likely have to be partially, at least partially

54:41.160 --> 54:49.200
supervised and you'd want to use some sort of existing ratings, so probably human ratings

54:49.200 --> 54:56.600
and I can imagine, you know, you have a waveform and they, you know, listen to the speech

54:56.600 --> 55:04.080
snippet and mark places where, you know, goes high or goes low.

55:04.080 --> 55:11.720
This is also evident in the physical waveform as well, so I could see that even being done

55:11.720 --> 55:19.000
without human ratings, but, you know, the system, you know, you feed it various waveforms

55:19.000 --> 55:27.480
and you feed at the sounds to go with it, it should be able to learn the parts where the

55:27.480 --> 55:33.840
wave, the audio goes up and then, you know, the times where the inflection goes down.

55:33.840 --> 55:39.560
But the tricky part would be associating that with a particular meaning and that's where

55:39.560 --> 55:45.800
you'd probably need humans to come in, so, you know, humans would tag the particular

55:45.800 --> 55:51.160
sentence as, oh, the emphasis was on this, so the emphasis was on that.

55:51.160 --> 55:59.440
And then, once you have those lists of different emphasis, you could train the model on that.

55:59.440 --> 56:07.040
And so, ideally, it would know when the inflection goes up, that's where the, the emphasized

56:07.040 --> 56:09.040
meaning is.

56:09.040 --> 56:20.680
I would imagine that traditional linguistics has a lot to offer in terms of, you know,

56:20.680 --> 56:22.560
just how to represent all of this stuff.

56:22.560 --> 56:26.600
Like, it strikes me that, you know, just there's a representational challenge and, you

56:26.600 --> 56:30.240
know, if someone were to try to take this approach to, you know, building and training

56:30.240 --> 56:36.600
models, but, you know, certainly linguists have been, you know, representing prosody

56:36.600 --> 56:42.200
and some kind of way and developing ways to map that to specific meanings.

56:42.200 --> 56:44.040
Is that correct?

56:44.040 --> 56:48.360
Yes, that is, that is correct.

56:48.360 --> 56:57.560
And so, it's definitely, definitely worth a look if someone is trying to train on audio

56:57.560 --> 57:01.600
models to, you know, take a look at that space.

57:01.600 --> 57:10.360
That's why, going back to what I said about being, you know, thinking multidisciplinary,

57:10.360 --> 57:16.920
wouldn't maybe, you know, wouldn't maybe be obvious to go to the cycle linguistics area.

57:16.920 --> 57:23.720
But it, like we've been, we've been saying, it can give you some great insight into how

57:23.720 --> 57:26.880
to train an audio model.

57:26.880 --> 57:37.120
And it'll give you more than just the surface characteristics of a waveform or the audio.

57:37.120 --> 57:43.680
It'll, you'll be able to, you know, train it on meaningful insights as well.

57:43.680 --> 57:50.400
His prosody is not something that you can necessarily, you can see the inflections, but you

57:50.400 --> 57:54.240
can't necessarily see the meaning on the physical waveform.

57:54.240 --> 57:58.920
You need, you need to add that insight, right, in addition.

57:58.920 --> 57:59.920
Right.

57:59.920 --> 58:00.920
Hmm.

58:00.920 --> 58:05.800
Oh, this is a really, really interesting space.

58:05.800 --> 58:10.200
Any, any other thoughts before we wrap up?

58:10.200 --> 58:16.360
No, I, I think this is a great space as well.

58:16.360 --> 58:22.040
What I, I particularly appreciate about it is, like I said, the multidisciplinary aspect

58:22.040 --> 58:23.040
of it.

58:23.040 --> 58:26.480
We're building these very complex systems.

58:26.480 --> 58:31.240
And I just mean that as a, as a field, right, in addition to my company.

58:31.240 --> 58:39.080
But, you know, we're, yeah, we're building these complex models that, you know, in some

58:39.080 --> 58:43.120
respect, reflect what's going on in a human brain.

58:43.120 --> 58:49.040
But we need to keep in mind that, you know, the more complex they get, the more information

58:49.040 --> 58:54.000
that we're going to need to seek out, and it's going to come from different places.

58:54.000 --> 58:57.960
Yeah, I, I can definitely see that.

58:57.960 --> 59:06.240
Yeah, I don't, I, I think I've commented here on the podcast or, um, certainly on Twitter

59:06.240 --> 59:13.120
that if I wasn't so busy trying to figure out this machine learning and I think linguistics

59:13.120 --> 59:16.240
would be high on my list of things to figure out.

59:16.240 --> 59:22.560
Uh, it's a fascinating field and it's great that you get to, uh, combine the two.

59:22.560 --> 59:24.280
Yeah, it is great.

59:24.280 --> 59:29.320
And one thing I did want to mention is that ideally, you know, the system would be language

59:29.320 --> 59:30.320
agnostic.

59:30.320 --> 59:37.200
Um, so, you know, we're really teaching it about human language, whatever, uh, it could

59:37.200 --> 59:44.240
be French, Spanish, you know, English, whatever it is, um, which is very helpful.

59:44.240 --> 59:49.160
And it can be used in, like you alluded to, um, translation tools.

59:49.160 --> 59:50.160
Mm-hmm.

59:50.160 --> 59:56.680
Yeah, my favorite example of this, in fact, is from a conversation I did with, uh, recently

59:56.680 --> 01:00:02.640
with Shubos and Gupta from Baidu Labs, and he talked about how, uh, they were able

01:00:02.640 --> 01:00:07.680
to build a, uh, English to Mandarin translator.

01:00:07.680 --> 01:00:12.600
I believe it was English to Mandarin translator before they even had any, you know, without

01:00:12.600 --> 01:00:17.680
having any Mandarin speakers, you know, on their staff, you know, just based on, you

01:00:17.680 --> 01:00:23.720
know, this, this property that you're describing, the, the, the fact that a lot of the application

01:00:23.720 --> 01:00:26.680
of this is, uh, language agnostic.

01:00:26.680 --> 01:00:27.680
Exactly.

01:00:27.680 --> 01:00:35.280
Because that's, yeah, it, it's not working on those particular nuances, if you will.

01:00:35.280 --> 01:00:39.920
It's, it's looking at it with a more agnostic view.

01:00:39.920 --> 01:00:42.760
Mm-hmm.

01:00:42.760 --> 01:00:43.760
Awesome.

01:00:43.760 --> 01:00:47.880
Uh, well, before we go, what's the best way, uh, folks want to connect with you or get

01:00:47.880 --> 01:00:48.880
in touch?

01:00:48.880 --> 01:00:52.560
Uh, what's the best way to do that?

01:00:52.560 --> 01:01:01.280
You can connect with Dimensional Mechanics on Twitter at DM, INC, underscore AI, and, uh,

01:01:01.280 --> 01:01:03.560
we're also on Facebook and LinkedIn.

01:01:03.560 --> 01:01:13.360
You can connect with me personally at ArtSci, ART, SCI, uh, two, with two zeroes, um, at Twitter.

01:01:13.360 --> 01:01:14.360
Okay.

01:01:14.360 --> 01:01:16.480
So at ArtSci, zero, zero.

01:01:16.480 --> 01:01:17.480
Yeah.

01:01:17.480 --> 01:01:18.480
Awesome.

01:01:18.480 --> 01:01:19.480
Awesome.

01:01:19.480 --> 01:01:21.480
Well, Dominic, thanks so much for being on the show.

01:01:21.480 --> 01:01:26.320
It was great chatting with you and looking forward to reconnecting soon.

01:01:26.320 --> 01:01:27.320
Thank you, Sam.

01:01:27.320 --> 01:01:28.320
I really appreciate it.

01:01:28.320 --> 01:01:29.320
Thanks for having me on.

01:01:29.320 --> 01:01:30.320
Absolutely.

01:01:30.320 --> 01:01:31.320
Take care.

01:01:31.320 --> 01:01:32.320
Bye.

01:01:32.320 --> 01:01:38.320
All right, everyone, that's our show for today.

01:01:38.320 --> 01:01:43.400
Once again, thanks so much for listening and for your continued support.

01:01:43.400 --> 01:01:47.360
Don't forget to share your favorite quote from this show via the show notes page, Twitter

01:01:47.360 --> 01:01:53.840
or our Facebook page, and if you do, we'll be happy to send you one of our laptop stickers.

01:01:53.840 --> 01:01:57.640
If you're planning to attend the future of data summit next week, please reach out

01:01:57.640 --> 01:01:59.880
and let me know to look out for you.

01:01:59.880 --> 01:02:06.120
The notes for this show will be up on twimmelai.com slash talks slash 23, where you'll find

01:02:06.120 --> 01:02:10.440
links to Dominic and the various resources we mentioned in the show.

01:02:10.440 --> 01:02:38.960
Once again, thanks so much for listening and catch you next time.

