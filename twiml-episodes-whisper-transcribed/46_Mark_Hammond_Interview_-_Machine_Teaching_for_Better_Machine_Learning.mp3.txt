Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting
people doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
It's been another exciting week here at Twimble Headquarters.
Just a few days after hitting the 500,000 listens mark, thanks to you once again, we learned
that at least a few of those listens came from a certain Mark Cuban.
And yes, I mean that Mark Cuban.
Speaking at a conference in New York City, Mark mentioned that he turns to this very
podcast to learn about and keep up to date on advances in artificial intelligence.
Mark, if you're listening, we love you man.
Thanks for the shout out.
The CNBC article that covered Mark's talk and mentioned this podcast focused on his fear
of AI and what it might bring in the future.
As you might imagine, this is a topic I've got some opinions on and I respond to the
article and Mark's fears in this week's newsletter.
If you're not already receiving it, head to twimbleai.com slash newsletter to sign up and I'll
make sure you get the current issue.
Last week we announced the first of two winners for our artificial intelligence conference ticket
giveaway.
Winners received a bronze pass to the conference which grants access to all keynotes and sessions.
Our second winner is Richard S. from Brooklyn, New York.
Thanks again to everyone who entered the contest.
If you didn't win this go round but would like to join us at the conference, use the discount
code PC Twimble for 20% off of registration.
We'll link to the conference in the show notes which you can find at twimbleai.com slash talk slash 43.
The first twimble online meetup was last week and was wonderful.
The focus of the meetup was the CVPR best paper award winner learning from simulated and
unsupervised images through adversarial training by researchers from Apple.
The idea behind this paper is this, consider a problem like IGaze detection.
You've got a picture from, for example, a cell phone camera and you want to determine
which way the user is looking.
Generating labeled IGaze training data is hard and expensive.
Generating simulated IGaze training data sets is much easier and cheaper though and can
be done for example by using something like a video game engine.
The problem is that the simulated IGaze images don't look close enough to real images
to train a model to work effectively on real data.
This paper proposes using a generative adversarial network to train a refiner model that can
make simulated IGaze images look like real IGaze images while preserving the gaze direction.
Thanks again to community members Josh Manella who did a great job presenting this paper
and to Kevin Maider for walking us through a TensorFlow implementation of the model.
You guys are just awesome.
We're working on getting the recording posted for those who weren't able to join us live.
If you're signed up for the meetup or the newsletter you'll be notified when it's
available.
If you'd like to join the meetup, head over to twimlai.com slash meetup to register.
Next month's meetup will be held on Wednesday September 13th at 11 a.m. Pacific time and
we'll post the details of the program shortly.
Before we get to the show, I'd like to give a shout out to our friends at wise.io at GE Digital
for their sponsorship of this industrial AI podcast series.
Hopefully you caught last week's show featuring Josh Bloom, Vice President of Data and Analytics
at GE Digital.
We had a great discussion about how to incorporate physics-based information into machine learning
models among other things.
For more information, you'll find that show at twimlai.com slash talk slash 42.
And for more information on wise.io at GE Digital, visit wise.io.
And now for today's show.
If you've listened to any of the shows in the industrial AI series, you've undoubtedly
heard me mention our friends over at bonsai.
I'm super grateful to bonsai for taking the lead in sponsoring both the industrial AI
podcast series as well as my paper on that topic.
Well today's show, which concludes this first season of the industrial AI series, features
my interview with bonsai co-founder and CEO Mark Hammond.
Our conversation centers on the role of what he calls machine teaching and delivering practical
machine learning solutions, particularly for enterprise or industrial AI use cases.
I really enjoyed this conversation with Mark and I know you will too.
And now on to the show.
All right, everyone.
I am here at the offices of bonsai with Mark Hammond, the co-founder and CEO of the company.
Mark, welcome to this week in machine learning and AI.
Thank you for having me.
Happy to be here.
Yeah, I'm super excited to have you on the show.
Folks who are regular listeners will know the name bonsai without a doubt, because you
guys have very graciously sponsored my research into industrial AI and the podcast series.
And I'm really looking forward to digging into with you what industrial AI means for bonsai.
But before we dive into that, why don't we, why don't you spend a few minutes telling
us a little bit about your background?
Sure.
So my background is actually originally very technical.
I started programming very young and ended up working at Microsoft while I was still in
high school on Windows itself, Windows 95, and the first many versions of Internet Explorer.
So definitely hands-on coding on the products themselves.
My passion that was always been artificial intelligence.
So even while I was there, I knew that was what I wanted to do.
And I decided to pursue a course of studies in computation and neural systems at Caltech.
So I was working at Microsoft attending Caltech, and it was great in all regards other than
that it happened in the late 90s, which was a fantastic time to work at Microsoft.
And not the best time in the world to be in the field of AI.
It's like part of one of the AI winters.
And so I found myself when I was completing those studies faced with, how do we use all
this stuff in the real world?
And at that point in time, it was really, well, do you pursue a course in academia, right?
Is that do you go to the academic route or what else do you do?
Because it's hard of the AI winters.
And so I kind of decided at that point that because I have this strong impetus towards
applying this technology in real world scenarios, if I wanted to do that, I was going to need
to get some of the not purely technical skills.
And so I decided, okay, I got to go try product management, developer sales and marketing,
et cetera, et cetera.
And so I pursued that course.
I did find myself at one point back at Microsoft this time in sales and marketing.
I was one of the developer evangelists who was outpitching.net when.net was brand new
and getting everyone on the C-sharp bandwagon, so that was a lot of fun.
And fast forward to today.
And the market is now in a great place where the technology is very capable.
It's the right time to start looking at applying these technologies to our real world
industrial and commercial enterprises and looking at those use cases.
And I had come to the insight which led to bonsai.
And it was born through, having gone through the academic track, having gone through the
pure business track, having looked at trying to apply AI in lots of different contexts.
And ultimately coming on one very simple realization.
It's one of these, one of these things where you look back and you say, well, that seems
obvious in hindsight, but until you think about it, it's not apparent.
And that's that no matter how good we make these algorithms, they could be as good or better
than humans at learning.
We will always have to teach them.
You have to teach them something.
It's a learning algorithm.
It's kind of by design it has to be taught.
And there wasn't a huge focus on how you actually teach something.
We spend so much time in this field focused on the machine learning algorithms themselves
that teaching is often afterthought.
That was the spark that said, look, if we're going to be able to solve these real world
industrial AI applications, the subject matter expertise, the ability for people to define
what they want to teach and how to teach it, that is an area that is ripe for enabling
the technology to be used.
And that's what led to Founding Bones.
I am sitting here today.
Awesome.
Awesome.
It's interesting that you came across that realization.
I tend to find the same thing that the emphasis is on kind of the machine learning.
And maybe you put another way, the way people tend to think about this teaching process
is throwing a bunch of data at an algorithm.
I guess it's kind of analogous to like throwing a bunch of books at a kid and expecting them
to learn on their own.
Yeah, absolutely.
Absolutely.
The one that I often use is with my son.
He's learning how to play baseball.
And I tell people I don't take him out to the backyard.
He's five, right?
So I tell people he's five.
I don't take him out to the backyard and throw fastballs at him because that would just be,
that's just cruel.
Why would you do that?
And yet, no one even pauses for a moment when we're like, well, we're just going to throw
giant data sets at these machine learning algorithms.
And I bet if I threw a million fastballs at my son, he'd figure out out eventually, too.
But it's just not a very efficient or effective mechanism for teaching.
Yeah.
And probably be pretty painful for your son.
True.
True.
Not very responsible for me as a parent.
So maybe we can, I guess, let's just dig into this.
So when you talk about machine training, what does that mean or machine teaching, what
does that mean to you?
So machine teaching really boils down to actually looking at the art and science about
how we teach things, distilling out the abstractions that are there, and then providing the appropriate
platform, tooling, et cetera, that developers, we've come to expect in order to be able
to properly construct the solution to a problem in that context.
So that's at a very high level, but at a concrete level, what it means for us is we need to
give you a very formal way, because it's still a computer program at the end of the day.
We need to give you a very formal way to specify what it is you're actually trying to teach,
and how you can go about phasing that teaching in a way that follows, again, using examples
we're just talking about, you don't want to have it be just throw massive throws of
data at the system or how you teach it can be broken up in ways that facilitate acquisition
and mastery of these concepts you're trying to teach.
So really at the end of the day, it's about empowering developers to work as teachers
and giving them the ability to do that in a very formal, structured way.
You can think about it if we're doing this in very humanistic terms, you talked about textbooks,
right?
So a textbook has a curriculum that's set out in it.
Here's the table of contents, all the concepts we want you to master.
We're going to go through it in this order.
Here's phased problem sets that ramp in difficulty level.
You go through all of these different ways of structuring the textbook in order to try
to help guide students as they learn things.
We do the same thing.
We just do it in a very formal, structured way.
We give you an actual programming language where there's no ambiguity about what you're
trying to do.
It's less freeform textbook and much more program that you're creating.
Maybe you can make that more clear by walking us through an example, you know, pick a use
case and maybe talk about how you would apply this to the use case.
Yeah, absolutely.
So, if we look at a robotic system as an example, so you have an industrial robot, perhaps
it's a robotic armature being used in a manufacturing setting or a warehouse setting.
And you want that armature to be able to create conduct various pick and place operations.
Maybe it's doing a palatizing operation, something of that nature.
Now, when you want to have the piece of equipment learn to accomplish this task, you can break
it up into the constituent concepts that matter.
It's not about, I want you to perform the entire task, let me demonstrate it for you.
It's about, okay, you need to understand the concepts of moving between points.
Here is where you're currently at in space.
Here is the target you need to get to.
How would you drive the motors to get to that target?
That would be an example of a concept.
Now, for a concept like that, if you're looking at a commercially available industrial robot,
there are very good controllers for that kind of thing already, right?
They've got the inverse kinematics all worked out, and they know how to do it not just
efficiently and effectively, but in a way that's going to maximize the lifetime of that
equipment.
You don't want to unnecessarily drive it too quickly, so you're going to cause it to
fail faster than you'd want.
Real world concerns when you're using these kinds of robots.
But then when you get to a grasping concept, so now we need to actually grasp the item
that we're going to be picking as part of this action.
That is much more complex, right?
And you have to deal with rigid bodies and soft bodies and different packaging materials
and all these different kinds of aspects that come to play, teaching the nuances that go
along with that.
That's where you can start to take your subject matter expertise and really bring it to
bear.
There are people within all of our organizations who already know a lot about these facets
of things, and they're not programmers per se.
They might be a mechanical engineer, they might be a chemical engineer, it depends what
kind of problem you're tackling.
But they know a lot about that area, and so if you asked them, if I asked you to teach
a human to do this, what would you do?
What would you actually, what are the concepts you want them to learn?
How would you show them those things?
How would you test whether they got it right or not?
They usually can tell you actually, because that's their field.
They know that pretty well, and so we just give them a mechanism to capture that.
So in the context of grasping, for example, since we're just walking through one of these
use cases, you might say, well, actually, if I'm teaching a human to grasp something,
I got to rewind a lot until back when they're toddlers, right?
But what do you do?
You use large-scale, gross motor scale objects.
You get them really close to their hands.
You have set their hands on it mostly, and then you let them go through the motions.
It's hard to think back in many of these cases for these very simplistic motions, because
to us, it's simple, but if you watch children doing it, they have to learn, too.
But you break it down.
And you literally break it down into those kinds of things where I'm going to teach you
gross motor skills.
I'm going to teach you in these simulation environments so that you can experiment frequently.
And you learn these concepts related to grasping.
So you learn the concepts related to grasping.
You're leveraging the pre-existing concepts related to moving between points.
You want to teach concepts related to stacking or placing orientation valid grasps so that
you can orient parts in appropriate ways for fastening them, et cetera, et cetera.
All these kinds of things that happen when you're doing real-world industrial robotics,
you can break the problem down.
You break it down into these constituent concepts.
You design a plan for how you want to teach it.
Typically, that will involve some simulation environment in conjunction with some real-world
physical environment.
And then you define what that curriculum looks like to teach it.
And then because you've done it in that way, the system can proceed to try all the various
areas that it can explore to teach how that works.
And mathematically, if we're looking at the low levels on the math, all that's really
happening is you're constraining the state space the system needs to explore.
That's what, in practice, that's what's actually happening.
But it's happening in this more naturally-expressed way that a subject matter expert can readily latch
on to and work well with.
So that's an example in a robotics context.
If you look at examples...
Well, that's not going too far because there's so much...
Yeah.
Sure.
...to unpack.
The first thing that jumped out at me was you kind of describe these two different types
of concepts one that you know a lot about.
And you can help me refine this language.
And another that you need to teach more abstractly.
So for example, in moving, you know, in kind of the macro movement of the robot arm from
point A to point B, you know, it's a well-understood problem, you've got the inverse kinematics
you mentioned.
Yeah, I get the impression that, you know, we've talked a lot in this series about kind
of reinforcement learning from a research and academic perspective and one of the, you
know, the problems are, I think, in that domain not decomposed in this way.
And so I think what I heard you say was, it'd be kind of crazy to, like, throw a bunch
of data and, like, have the robot try to figure out on its own the best way to move from
point A to point B.
And hey, we've already done that years and years and years, and we spent a bunch of
time perfecting the way to do that.
So, you know, part of what I hear you talking about is kind of, is an idea of modularity.
Yes.
I agree.
And these approaches that I'm trying to, like, get at a whole lot of stuff at one point.
Sure.
You know, one thing that I want us to dig into is like, you know, compare contrast, you
know, what you're doing with, you know, the way some of the things we've talked about
on the podcast, kind of, academic approaches to reinforcement learning.
And so one is this idea of modularity.
Another is, you know, maybe kind of elaborating on this idea of constraining the state space
in a way that is easily expressed by humans, like I think constraining the space, the
state space is a huge part of, you know, this process even from an academic perspective,
but my impression, not being an academic and at the start of this field, but my approaches
or my sense is that their approach is constrained in the state space mathematically, right?
As opposed to conceptually.
Is that fair?
That's fair.
At the end of the day, it all does boil down to a mathematical constraint.
It's just how you enable people to express that.
And by virtue of building a system where you're expressing it in this more natural way for
a subject matter expert who's actually working on these problems, you can get at the underlying
math by allowing people to express it in these more natural terms.
Perhaps an analogy here would be, would be useful.
If we look back at old programming systems, right?
So in the, in the late 90s when I was at Microsoft Visual Basic for building desktop apps
was everywhere.
People used that all over the place.
And it was very popular because it enabled people who had subject matter expertise, you
know, I'm running my veterinary clinic, I'm doing whatever it happens to be, to build
the applications they can, they cared about because they didn't worry about comm interop
capabilities and all these, you know, low-level stuff.
They worried about, can I build a form and can I put the right components onto the form
that I care about and tie that back to a database in a way that doesn't require me to go become
an expert in assembly language and low-level binary interface technologies.
This is the same kind of thing.
It's about building the right abstraction at the end of the day.
And so even if what our technology is going to do are the bonsai platform itself is going
to take all this code that you've provided and it's going to compile it.
And yes, at the end of the day, it's a big mathematical constraint.
It's not that fundamentally the technology is different somehow.
It's the same.
It's just that we're allowing people to express it at an appropriate level of abstraction
where it's now framed in the context of the subject matter.
It's framed in the context of the business problem you're trying to solve.
And that's very powerful because it takes it so that your data scientists can still play
the role that's appropriate for them to play.
Your programmers can play the role that's appropriate for them to play and the subject
matter experts can participate and actually teach it the intelligence that you actually
want the system to exhibit.
Typically, what we find in a lot of these environments is if you have true, deep expertise
in machine learning and data science, that is its whole own field.
And the people who have that, if you look at the intersection with the people who have
the expertise in building manufacturing equipment or optimizing supply chain facets rare, right?
It's very rare that they overlap.
So we have to provide, as an industry, we have to provide a way to enable all of these
disparate skill sets to work together.
Then we have to focus on the skill sets that are already within these organizations or
we're never going to solve the real world problems.
And so that's, that ultimately is where we're getting at with this technique.
Yes, it's about decomposing the problems and it's about decomposing the problems in a
way that allows these subject matter experts who know about all the different facets of
the use case they care about to really come in and say, I need to teach you about this.
So if I look at real world examples, we're doing a lot of work with Siemens at the moment
as a, as they're one of our customers.
And if we look at their manufacturing equipment that they come to us and they want to talk
about adding intelligence to, I'm an expert at platforms and artificial intelligence and
all this stuff.
I'm not an expert at CNC milling, right?
That's not my, that's not my area.
When they come to us and they say, well, here are the real world problems we face when
we have these gigantic pieces of manufacturing equipment and they can have an expert get
on the line and they can, that expert once say, well, you're going to need to understand
this facet of friction compensation and so on and so on.
And you know, areas that I know that, nothing about, frankly, as I don't know, personal
level, but they can tell us all sorts of things about that and we can work with them to
say, all right, well, how do you go about this now?
How would we break that down into something we can measure, into a set of concepts the
system can learn?
And it's not about how do we craft a, you know, a pit controller to solve this problem
which would be a traditional way to solve this problem in enterprise context.
It's about how can we tell whether it was correct or not?
So this is where the reinforcement learning part comes in.
You don't have to be able to specify the controller at a mathematical level.
You have to be able to assess whether the behavior was what you wanted and the ability
to break down that behavior into components so that you can assess for each of those
constituent components whether or not that was what you actually wanted.
So elaborate on that.
Do you, I mean, ultimately in these use cases you're trying to, are you trying to create
the controller or are you saying the controller already exists and you're trying to identify
the right parameters for the controller or are you trying to say the controller and the
parameters exist and you're just trying to do some kind of validation?
So all of the above actually, we run it, unfortunately the answer is that we see all of these
scenarios.
So there are cases where what you have is that you have an existing controller and what
you're looking to do is to identify deviations, right?
So you're really trying to figure out when you've deviated and you have some condition
that was not anticipated and you want to be able to deal with it appropriately.
So that's something you definitely run into.
There are areas you run into where you have existing controllers and you want to enhance
the capabilities of those controllers beyond the already well-defined characteristics.
So you run into that as well.
And then there are areas where you people are still operating things by hand.
So it is not uncommon.
We can look at CNC machines, right?
And we were just talking about them to have expert human operators manning these machines
because the value to the business that is using them and creating the part, let's say you're
making a large-scale aircraft part.
That part might be a couple hundred thousand dollars just for that one part.
And it might be a week-long operation to mill that part, right?
You're not going to just turn it over to your G code script and let it run.
And you're going to have someone there to make sure everything's going as you expect.
If there's a mistake on day two, you want to stop it on day two.
So that you're not wasting tons of time and money as you're going through that.
And at the same time, one of the things that I hear over and over again is that they're
from the perspective of trying to apply kind of modern, sane business and engineering
practices to some of these industrial environments, a lot of what this subject matter expertise
is, hey, when I hear this machine kind of sounding an octave or two higher and pitch or something
like that, I know that we're probably going to lose a bit or we're going to probably
damage the part or something like that.
There's a lot of art in addition to the science.
How do you begin to capture all that?
So that's actually an excellent point.
So the beauty of the modern machine learning technology is its ability to detect nuances
there where the human expert, the subject matter expert, can say, yes, I hear it.
And when it sounds off, then I know this is about to happen and you can say, well, what
are you listening for?
And they're not experts in acoustics, they're not going to sit there and tell you, well,
it's exactly this is the kind of sound.
It's more like, I just know what I'm listening for, I've heard it before.
And so the traditional mechanism would be go through label, data set, et cetera.
And you can still do that.
There are techniques you can use in simulation as well to model those environments.
But in practice, the benefit you get from modern machine learning technology versus expert
systems, saying if we go back to the 80s, is this flexibility.
So if I can use another analogy, which might be intuitive to a lot of people, if you play
a sport and you really enjoy playing that sport and you practice and practice and practice
and you get good at it and someone comes to you and they're like, wow, you're really
good.
What is it that you're doing?
I'm missing so that I want to be good at this sport too.
Oftentimes, as an amateur, you don't know.
I just practiced a lot.
I got good at it.
And if you go to a professional coach or a professional athlete, they can tease it apart.
They can say, well, actually, when you're doing this motion, you'll note that you arch
in this way and they can get into all the subtleties and the new ones.
That's why they're a coach or a pro.
And so humans as a learning system, if we look at ourselves as learning systems, we have
this remarkable ability to be able to exhibit intelligent behavior, regardless of our ability
to explain all of it, right?
And modern machine learning systems are like this.
So if you take a deep reinforcement learning neural network kind of approach and you apply
it to a problem and you say, here's the correct behavior.
Let's look at it over and over and over again, whether that's because it's getting acoustic
data and it's listening and you're telling it whether or not the part was about to break
or you observe that the part broke and now it's learning what the subtleties and the acoustics
are so that it can have that same sense that the expert operator did.
It can do that, right?
That's one of the benefits of the technology.
But the more you know about the problem itself, it enables you to decompose it into
those bits.
And so you're not forced, you can always use the technology and get it to the point where
again, you're the amateur athlete and you're just learned because you practice so much.
Or in the industrial case, I have my system and it's actually monitoring the acoustics
off of the equipment and it's learning to detect what it sounds like when a part is about
to break.
It can do that.
That's fantastic.
But then if you have that subject matter expertise and you can really decompose the
problem, you can get a lot of benefits because you can teach faster.
You can now have the predictions that are made explained so that the system can make
more nuanced and more accurate behavioral decisions.
And really getting that subtlety and nuance allows us to build and capture more knowledge
and build more sophisticated systems.
It's kind of like with expert systems, you are totally rigid.
Here are the rules.
Right.
It's all this behavior and powerful in that sense, but very constrained.
It was not very flexible.
And now the pendulum has swung the entire opposite way or all the way at the other end.
And you have your machine learning systems and it's throw lots of data at it and it's
going to learn to predict something and great.
It makes great predictions but no one knows why.
Right.
So before totally explainable, completely inflexible.
Now totally flexible, not explainable and by virtue of using a machine teaching approach
like the one that we've outlined, it's no longer black or white.
You get this nice continuous gray area.
If you don't have a lot of that, that you can provide, the system can still learn and
that's okay.
The more of it you provide, the more explainability you get, the faster it can learn, the more nuanced
you can add to the decisions you're making.
And it just opens that up.
And so it really allows us to tackle these problems at whatever level of subject matter
expertise, explainability is appropriate for what you're trying to do.
Okay.
So what?
I think what I just heard was, well you talked about explicitly the spectrum, but when
a company is using your tools and building a solution based on it, they've got the
ability to, you know, you can start by at the highest level by throwing lots of data at
the problem and not building, you know, building constraints into the system or, you know,
conversely, you know, articulating the concepts, you know, breaking down the concepts that
compose the system, you know, or you can do that to some varying degree of detail.
So it sounds like that's probably one of the kind of architectural design decisions
of someone that's implementing this, like how much decomposition do we need to go to?
And is that what are the factors there, is it primarily performance, is it actually
it tends to be very iterative.
So typically, typically what ends up happening in a real life engagement is they will first
start with the simplest possible model, which is there's only one concept and I just having,
I'm doing the classic reinforcement learning thing.
Here's the environment for you to go explore, go explore it.
And that might be a robotics environment, it might be a supply chain simulation, it
could be any number of things, but just explore and see what you can figure out.
Typically that will learn something, not as much as one would hope, but something.
And then you say, okay, well, let's see what would happen if I taught it about this.
And so you add some conceptual block into the system and you break it down into teaching
that.
And it may or may not help, it's not always a given that it helps.
Often times we'll get feedback from people who are more on the academic mindset.
The whole point of deep learning was to get away from specifying these things, right?
That was the whole point, why are you doing this?
What happens if the person specifies this model and they're wrong, right?
That one of the benefits of deep learning is that it's not reliant on our presupposed
conception of what the model should be.
How do you cope with that?
And for us, it's like, well, that's beautiful, actually, because when you start to break
it down and you decompose the problem and you do it in this iterative way and you see
whether that supports a faster learning, whether it supports better explanations, better
reuse, better generalization, all these different factors you might want to optimize for
and care about, you learn about your own model.
And so if your conceptual model is that friction compensation is super important for this
manufacturing process and you go through the motions and you see that, well, the system's
learning to make predictions and it's compensating just fine.
But all the things I taught it that I thought I knew aren't being used.
And the system can come back and tell you this, it's, well, you taught me this concept
and in fact, I never use what I learned.
I'm always doing something else.
That's instructive.
That tells you, hey, this model I thought made sense, there's something better because
the system has learned the correct behavior and it's not using what I do.
And this happens at all levels of granularity.
So in practice, it's this iterative process.
People start at the very simplistic model.
They start to add more and more of the model that they believe is correct.
It's very rarely a, here is the 120 concept model that I think maps to the problem I'm trying
to solve and I'm going to go build the whole thing in one go and go from there.
It's much more of an iterative refinements and expansion of the model so that you can
have more nuance covered and more subtlety covered and learn about your model in the process
of doing that.
Okay.
And one of the things that you guys talk a lot about is the notion of explainability.
Yes.
You just went into that.
Very important for customers in this space, for a variety of reasons.
I don't think I previously understood that it's this granularity of defining the concepts
that really gets you the explainability.
Yeah.
Absolutely.
Can you elaborate on that?
Yeah, absolutely.
So there are a lot of techniques that have been published about how you start to peer
into the neural networks and try to tease out what is actually going on.
You got lime and a lime and all.
There's tons of these things.
Our approach is different.
As you said, because it's not magic in our system, it's not like we're going to have
some amazing new way to peer into the neural network and tell you what these group of neurons
meant.
Right.
That's not what we do.
What we do is we say, we're going to let you break it up in this way.
And it's always easiest to frame these things in real world scenarios.
So let's say you are building a supply chain logistics system.
You have got your real world data.
So you have all the telemetry coming from that.
You have simulation models that you've built in some discrete event simulator or something
like that.
So you've got all these different facets you can pull on.
And the model that you use takes into account very coarse things like the weather and seasonality
of goods and perishability of goods and not all these kinds of things that you might care
about.
And you might have more fine grain concepts that you're teaching at about the composition
of your fleet and the land routes that are viable for you to follow and so like all these
kinds of things.
So you know, you can teach all of this stuff.
What's important to emphasize here is that it is very rare for a company that we work
with to come back and say, and now we're turning it all over to this automated system we
trained.
Go.
That doesn't like me.
Yeah.
That's still there's not a level of comfort there yet.
What happens is there's still a human and the human analyst is sitting there and making
the ultimate decision and they're using the system to provide decision support.
Yeah.
And in that context, if you've built, I don't care how sophisticated it is.
If you've built a very elaborate neural network or maybe you used some other machine learning
or AI technique to build a system and it comes back and it says, I think you should have
truck 17, which is currently in Hoboken, depart now.
Go.
I thought what I think you should do, the analyst is going to sit there and look at it
and say, why?
Okay, that's nice that you tell me that.
And I understand that you have this visibility on massive parametric space that I'm not
perhaps aware of as a human, but I'm still not comfortable with the fact that I have
no context into why you're telling me to do this.
That truck is only two thirds full and the next truck that can hit that location is
not available for two days.
Okay, I don't think that's a good call.
Whereas if the decision support system comes back and says, I think you should have this
truck leave now.
And I think you should have it leave now because.
And then it frames that prediction in the context, again, not magic, but in the context
of all these concepts you've defined, that was your own model.
So you as that analyst who is sitting there and presumably is either very familiar with
that model or part of defining it, are going to look at that and have some rich context
to say, oh, right.
So we taught it about these overland routes and it sees that there is a storm coming and
those routes are going to be cut off.
And that's why it's telling me to do it now, even though there's not another truck for
two days, whatever it happens to be, but it can frame it in that context.
That gives you much more power as an analyst to make that decision in confidence in the
results.
You get your audit trail.
This is why.
This is why this happened.
So even if those models are not ground truth, this is not exactly the state of the world,
but it is the model that you use to run your business.
It is the model you use to drive your robotic systems or whatever it happens to be.
You want to have that level of explainability and that's what you currently use to frame it.
And so we're taking a lot of the magic out of the AI, but giving you the flexibility
that you could have a note in there where the system comes back and it says, I think
you should have the truck to part now.
And everything in the model, I'm not using any of that.
If you just use that model, the model would not say, make the truck to part now, but I've
also learned by virtue of looking at all the real world telemetry and that I believe
making that prediction now is a good prediction.
Then the analyst is going to look at it and say, well, I'm not really comfortable doing
that, but let's look at what happens.
Let's see if that was, in fact, a good prediction that comes out and that tells me I need to
go back and enhance my model.
My model is now deficient in some way and then you can iterate and you can keep working
on the system.
Specifically deficient in its expression of these concepts, right?
It has a blind spot.
Actually, blind spot isn't really the right way to say because the model doesn't have the
blind spot.
It's the lack of decomposition.
Yeah, you can't explain it.
It's like going to the human expert and saying, why?
Having them say, I don't know, this is the way I do it and it works, right?
Humans have this interesting, I'm a student of human nature as well, and humans have this
interesting facet where we conflate the ability to explain something with the ability to justify
something.
It's important as you look at these systems and say, well, are you actually explaining
why you chose to make this decision and that's really what happened or are you just looking
at what happened and now you're justifying it?
A lot of times it's the latter.
It's not the former.
That's human nature and that's just the way we are.
But when it comes to industrial AI and really applying this technology, you really want it
to be the former.
In certain circumstances, you want to go back later and leverage the human strength, which
is to say, system predicted I should do something that was out of the bounds of my model.
There's a gap, assuming that it was the correct behavior.
Then there's a gap, how do I try to fill that gap and then your ability to justify and
come up with creative explanations for what that might be.
Their ability to have your data scientists dive in and really tease apart what happened
and try to refine that model becomes very powerful.
It is a very fluid process.
It is not a right once run forever proposition.
It is a right many times, continually refine and learn as you go along and get a greater
and greater and greater ability to explain what is actually happening as you go through
that process.
That's the nature of the beast.
One of the things I found in my research and articulated in the industrial AI paper
was an emerging maturity model in the way people are looking at deploying AI and in the enterprise
generally, I think, but particularly in these industrial types of situations where it's
just as you describe, there's this fundamental issue of trust.
That trust is, I think, multifaceted part of it is repeatability part of it is explainability.
There are a bunch of other factors.
As people are gaining this trust, the first thing that they want to do is point these systems
at some process and some system and just help them monitor it and tell them new things
about it and surface new insights.
As they gain some trust that, hey, it's actually providing me interesting information, maybe
it should tell me what to do.
Then they flip the switch or allow it to optimize and it becomes a decision support system
in the way you described it.
There's this further stage which is actually the next switch which is just do it.
Think it so.
I'm wondering if you see that same progression among your customers and what are some of
the other factors that compose, what are some of the most important factors that compose
trust beyond explainability?
We definitely are starting to see some of that, but I would emphasize the starting two
part.
You yourself described there's an emerging capability maturity model that people are using as a factor
here.
I would wholeheartedly agree with that.
The state of the market right now really is, it's like it's 1995 all over again.
Hey, there's this cool visual basic thing.
Let's go try it out.
In this case, it's like there's this internet thing and everyone's like, wow, I really
need to do something about this internet thing, but a lot of people, the maturity of people's
ability to do that is all over the map, right?
People don't even know where to start, they know it's important and you have true, deep
experts who are doing it and so we see all of that and as you engage with customers and
they're looking at the maturity of their trust in these systems and trust in their own models
and own systems, they built so that they feel more comfortable turning it over.
We definitely see that.
You can look at, as an example, autonomous vehicles, so we talked to, of course, lots of people
about autonomous vehicles.
It's a hot area and there was a period of time not long ago where no trust whatsoever
in having the systems make control decisions, using the technology for perception and identifying
whether there's a bicycle on the road or a cow or something like that, okay, we're comfortable
at that level right now, not steering the vehicle, like no, that's not yet.
And you see some of those organizations now getting more and more comfortable with them.
But really, it boils down to how well-baked is the systems that you've built.
They can be at the point where it is just, you still want a human in the loop, it will
get to the point where you want a human to validate what's coming out.
And then yes, you will get to the point where frankly, you will have the system make decisions
in an automated way and you do that because there's now sufficient trust and confidence
in the system that it's going to do the right thing that doing the wrong thing is now
an exceptional activity and they'll still make some mistakes, but it's rare and when
it does make a mistake, you can capture that and you can use that to further refine the
system.
So yeah, I think that's a natural progression.
We are starting to see that, but frankly, at this point in time, the market is really
all over the map.
And so tons of experts in a room, we will run into that with some frequency and you get
into the occasion where people are just dipping their toes in the water and everywhere
in between.
So it kind of depends on the particulars of the customer and how forward-looking they
are and how much resource they have to allocate towards exploring various facets of what
they can do.
But by and for the large part right now, there's a lot of desire to have explainability to
have that audit trail, if you will, so that people can go back and test things.
The more you get to automation towards the automation end of the spectrum, the more people
want to be able to look not purely at the audit trail, but in generalization.
So if you look at control systems for robotics, which we're talking about at the beginning,
am I teaching the right concepts such that it will generalize the behavior in many scenarios,
not just the one I'm teaching it about.
So there tend to be more towards that end of the spectrum of trust and automation.
So that's how they can perform their tests.
I didn't just learn how to grasp in a way that is appropriate for this one task I'm trying
to do.
So did I learn grasping in a generalized way such that if I present a variety of objects
and a variety of scenarios, it will still do the right thing.
And consequently, you see everything, you see, you see everything on the spectrum at this
point in time.
Just to follow up on that last comment you made about the generalization, I imagine that's
got to be driven by a business driver.
You don't want to have an overly generalized system because that's going to be more expensive
than what you need to solve your problem.
100% agree.
Yes.
Yes.
Do you find, I don't know what the question is.
No, you're totally accurate though.
If you have, let's just keep it in the same vein.
It's easy to continue with that example.
So robotics, okay.
So I have my robotic system.
What I have it doing, it's been retooled.
We are part of a chain of this manufacturing chain.
We just recently retooled for this chain.
I really care about this one operation.
I need to attach these two parts of whatever we're building.
That means that the grasp has to be in a certain orientation because it's only viable to
connect the two things.
If it's I'm not covering up the part that needs to be combined and so on, all these kinds
of things.
And that's what they care about.
They're really focused on that because that's what they're manufacturing right now and
that's what's economically effective and efficient and capable.
And if you look instead for the person who manufactures that piece of robotics equipment.
So I have, I may be B or I'm, you know, you pick your robotic manufacturer of choice.
I make robotic armatures.
I care a lot about the generalization because for me, having it work with my customers,
I have a variety of contexts helps them go faster.
And so that's kind of the breakdown we tend to see now.
And then I think I imagine it also goes back to this idea of customer and market maturity,
right?
So, you know, my first few projects are going to be like proofs of concept and things
like that.
And I'm trying to solve this thing quickly and see if this is a viable technology.
But at some point, you know, project three or four or something like that, I want it.
I really want to understand that, you know, if I'm going to invest in an approach or a
platform that it can solve a broad swath of problems because there's real cost to that
investment.
Totally.
And that's exactly what we see.
So it is a typical engagement for us at the moment would be to have a, we have an early
access program that we're actively working right now.
And customers coming into that almost always want to run a proof of concept, as you said.
As a first stab, we want to try to make it as aligned with the ultimate production
use case as appropriate, but also appropriate duration and so on so that it's a, the spend
of resource and people's time and money is aligned with pinning down exactly what you
said.
Is this technology something that makes sense for what we're trying to do?
And as people get that level of comfort, then yes, then you get more into the, okay,
now let's expand the scope and we're doing a much broader use of this technology and
the production environment and so on.
That is a progression that we see time and time again.
And I think that's true.
That's not just true about us.
I think that's true about this technology in these industrial contexts in general.
We talked a little bit about reinforcement learning and, you know, in some of the examples
you gave, you start high level problem, you decompose it into concepts, you know, you
know, if the concept is like a leaf node, you know, somewhere under there, you're doing
reinforcement learning to kind of figure out that leaf node.
If you don't already have a well understood model like inverse kinematics, help us understand
the relationship between what you guys are doing and the underlying reinforcement learning
stuff.
Like are you, how are you, how are you architecting the, sure, the networks?
How are you, you know, training them?
Are there, you know, any particularly interesting things that you're doing to, you know, ensure
that they're quickly trainable, is there any academic research that you have based your
approaches on?
Like what are the things that you think about in that interface?
Sure, sure.
That's a, that's a, there's a lot of depth that we can get into there.
So let me, let me start at a high level so we can frame everything and then we'll, I'm
happy to push down.
So at a high level, the, for bonsai's platform in particular, the best way to think about
it is in relationship to a database.
So when you're building industrial or commercial enterprise application X for your company,
whatever happens to be, and it's going to work with data, you're going to use a database
almost certainly.
That's a very common thing to do.
And what is the database providing for you?
It's providing that level of abstraction so that you are not focusing on how this data
is split across disks in the cluster.
And when you rebalance tree structures for searching and all this kind of like that, all
that stuff's the database deals with for you.
And it gives you this nice abstraction so you specify the structure of your data and
the kinds of questions you want to be able to ask of it and it can take care of the rest.
Our platform is very analogous to that, very similar.
Now, of course, our abstraction is around this machine teaching stuff and so on.
But in principle, when you're working with these simulation environments, when you're
working with real world equipment and telemetry, you are nonetheless interfacing with all
of those systems and you have to manage them.
So if you're building a system and you're going to go through the actual training motions
and let's say it's a supply chain logistics system and you have a discrete event simulation
model of that system and you want to train primarily on that before you bridge to the
real world telemetry data just so you get quicker learning and more repeatable learning.
Then you have to manage those simulations.
Those simulations, depending on what you're doing, those can run very quickly.
In some cases, if you're doing a computational fluid dynamics simulation, that can run for
hours or days and so managing all of that becomes something that matters.
And so in the same way that you don't worry about data spanning different disks in your
cluster on your database, we don't want you to worry about am I running 10 copies of my
simulation environment and where am I running them?
How do I reconfigure them between runs so that I'm maximizing the efficiency of the learning?
All of that is the kind of stuff that our platform manages for you.
And so in that sense, there's a lot of low-level plumbing infrastructure stuff that is really
valuable because you don't have to worry about it and it manages that for you.
But then when you dig down, okay, so that's the high level, now drill down a level.
Great.
I've provided this.
But that's interesting stuff because at some point, someone's got to set up models and
actually train them and have that stuff all automated out of the box is a lot of work
that someone doesn't have to figure out how to do.
Yeah, and in fact, that's kind of the state of the art for a lot of this work.
If you look at the academic literature and you look at deep reinforcement learning algorithms
in particular, you'll find DDPG networks and TRPO networks and questions around whether
you should have learner memories or not.
And is it on policy or off-policy method because if it, depending on which way it is, you
might have to throw out historical data you've cashed, given what you're learning next.
And this level of detail is great if you are focused on the mechanics of the learning.
And from our perspective, it's the kind of thing you shouldn't have to worry about if
you want to focus on what you're teaching and how the system should be intelligent at
the end of the day, what the subject matter expertise is.
I would rather abstract all that and manage it for you.
And so by, you know, abstracting and managing it for you, you know, when you kind of punch
into the details, can mean a bunch of things, it can mean, you know, actually we know about
all this stuff and we know how to figure out which is the best thing, you know, and we
do that.
But what we really only do this one thing and you only have one choice and thus we've
managed it for you.
Sure.
Sure.
Yes.
So it's more the former than the latter.
Of course.
As you'd expect.
As you'd expect.
You never know.
No, it's a totally fair question.
So what does that mean in practice?
And let's use analogies again because it makes it easier to recognize.
Let's say you're teaching the system something silly.
I want it to learn how to play tic-tac-toe.
I picked tic-tac-toe in particular because everyone's played it and everyone understands
if you're past a certain age that it's a pointless game because you'll never win, etc.
Right.
The state space is not huge for tic-tac-toe.
There's a funny xkcd comic actually where he literally maps out the entire state space
in the comic.
Like here is every position you can possibly enter and what the correct move is once you're
in that.
Like you can never, right?
And you just do it.
It's small enough of a state space.
You can do that.
We'll link to it in the show notes.
Yeah.
Awesome.
Perfect.
I can give you that link.
That's easy.
If you were teaching that and you did it in our system, part of what the system does when
it's compiling and it's generating the appropriate underlying networks on your behalf is it will
just run the simulation for a while.
And it will collect statistics on what it sees.
And if it's running tic-tac-toe, after it runs it a little bit, and this is not a take
a lot of wall clock time, it's just got to run a lot of iterations of the, in this case,
it's a game, but it runs a lot of iterations of it.
It will see very quickly the state space isn't large.
And consequently, maybe using a q-table is a perfectly reasonable algorithmic approach
to solving this problem.
Q-table being.
Q-table being a specific approach for building a reinforcement learning network where it's
appropriate if you don't have a lot of options to the state space is not huge.
If you can enumerate enough of it, just a table is a perfectly reasonable thing to use.
And I mean, that's an oversimplification of a q-table, but that's the general, that's
the general gist, and fine, why not use that?
That's an efficient system to use in this context.
Whereas if I give it chess, and you say, go run some sample iterations of chess, and
just see what's going on, it will very quickly learn that the state space is gigantic.
It's huge.
And using a q-table is not an appropriate choice in that context.
You need to use a different type of network, and in fact, depending on how deep that network
is and how well you've decomposed it, we might have to have some pretty deep layers,
layer stacks in that network to be appropriate.
So that's one level of how it decides which algorithmic approach is to use.
It also looks at the kind of data that are flowing through.
So if you're looking at chess, you can hand me the data as a array.
If I'm looking at a robotic armature, you might hand me sensory data, which is just a collection
of floating point values for motor torques and sensor detections and so on.
And if I'm looking at autonomous vehicle, you might be handing me visual camera data.
I could be handing the system any of these things.
The appropriate network to utilize is completely dependent on that data.
So if you hand me a visual data, I should be probably constructing an appropriately sized
convolutional network, right?
Exactly.
It has spatial locality.
If you hand me audio data, it has spatial locality in a sense, but it also has temporal locality.
So I should be using different kinds of networks for that and all these kinds of heuristics
and ways of looking at the environment and exploring and looking at how you deconstructed
the problem, they're all taken into account.
And so when the compiler outputs at the end of the day, okay, this is the network topology
we're going to use.
This is the algorithmic structure we're going to use, et cetera, et cetera.
That's what's informing it all.
And on top of that, we ourselves are a machine learning system.
So it learns by virtue of having explored how to solve similar kinds of problems it's
seen before, how to tune hyperparameters and all these other kinds of things.
Again, levels of detail that the compiler should deal with for you, the platform should
deal with for you.
I want to, if we've done our job properly, it's much again going back to the database
analogy.
It's just like that.
You don't have to tune any of those things.
You don't even have to know what those things are or what they mean.
You just have to be able to tell me what you want to teach and how to teach it and
we'll build something for you.
Is it the most efficient thing that you could possibly have hand tuned if you were an expert
and knew how to do it yourself?
Probably not.
And that's why you still have database administrators and database experts who can go in and tweak
all the, I'm going to look at the slow log and go modify the queries and I'm going to, all
the things you do with databases.
Same thing for us.
If you want to go in and you want to provide a node in the system where you tell us, this
is the structure.
This is literally the topology it should be for this component.
Okay.
We're not going to stop you.
That's fine.
But if we give you the flexibility to decide where at what level you want to do that, that's
better because it now lets you focus on the right people on the right levels.
Your subject matter expertise can be focused on what to teach and how to teach it.
Your machine learning experts and data scientists can be focused at that level and teasing
apart when the networks are making predictions that weren't, didn't fit in your model and
you need to now refine it.
Great.
That's where I want them to play.
Your programmers have their role to play.
I need to integrate with all these simulation environments and I need to have the telemetry
data being tied into the system and so on.
Every participant in this process has a role to play and our job as a platform company
is to make sure that they all have the right tooling that's appropriate for what they're
trying to do and they're part in the process and that we can have the discussion at the
appropriate level.
Is it at the level of the use case?
Is it at the level of breaking that down?
Is it at the level of the subject matter expertise or are we, do we need to get down to the
level of convolutional neural network architecture?
Is there a spec sheet or is there an enumerated list of like these are the networks that we support
and how quickly does that evolve are there limitations or-
So it's continuously evolving as you can imagine as a platform company we're always adding
more.
We have documentation up on our website so if you hit our main website-
And so that's all there.
Yeah just link to the docs section.
There's documentation down to the protocol level so I have my own bespoke custom simulator
which we do run into with some frequency and I need to be able to tie this simulator
to the platform.
How do I do that?
So there's documentation on that and so it just kind of, it depends on what level you
want to get to but yes there's documentation all up online publicly available.
Do you get asked by customers like how many different network topologies or architectures
do you support and-
Yeah that happens sometimes it does.
It depends on the-
It depends on the-
It's how technical they are.
Machine learning, depth that they've gotten to.
So yes we've had people ask that and so we can talk about TRPO networks and DDPG networks
and or DQN networks and all the different, we don't have to numerate them all right now
but yes you can start to enumerate all the different ones that the platform has baked
in and have that conversation.
You'll also run into people who have been rolling their own.
So a lot of times that we'll get asked the question beyond which networks do you support.
I was just going to ask this question.
We'll get asked okay we have been, we'll get we'll get asked the question well who else
in the space should we be looking at and really there's two answers.
When it comes to deep reinforcement learning and applying that to solve these real problems
the first is rolling your own right that is actually we run into that very commonly.
And the second is very, very vertically specific company focused areas right.
So there are players in the space who only focus on deep reinforcement learning,
force applying, only deep reinforcement learning for robotics etc.
So those are the kinds of things you run into.
In the case of the latter if the solution they have fits your bill then that's great right.
They have a very specific focus.
We are a platform company so we're looking to allow you more flexibility in custom modeling
and how you expand all that out.
So that it's just kind of a judgment call internally for where you fall on what you want
to do.
And the former where you're rolling your own which we run into all the time.
That's actually a perfectly fine situation for us because the conversation quickly becomes
well how much time have you invested in that and have you run into this set of problems.
So you'll run into customers who they've decided reinforcement learning is the correct path
to solve their problem.
They've been going down that path and building out the solutions.
They're spending a ton of time managing their simulations, their tonning and all these
different assets of what we had just been talking about.
And we say well you know we can we're not going to magically make the problem that you're
facing about crafting a good reward function go away right that's part of that's still
part of the development process you're going to have to do that.
So we can take all the pain of managing those simulations off of your shoulders right
like the platform can help you do that.
And so you run into those companies that are a little bit further down the roll your
own and they're like oh wow I don't have to do this anymore.
That's that sounds great.
Let me let's let's talk about doing it.
And then you run into ones that are just dipping their toes in the water.
They kind of say well I could just build your built on top of TensorFlow.
Why wouldn't I just build it using TensorFlow and we can start to enumerate all the reasons
why but but generally we can say and these are the problems you will run into.
And some percentage of them will say I don't want to I don't want to deal with that.
Let's talk.
And some percentage of them will say I got to experience that myself and that's fine with
us because we know that you'll you'll come back totally totally yes exactly you got
to learn how to find the balance of where where it makes sense to roll your own and
where it doesn't.
Yeah and actually I was going to I was going to ask the question more aligned with kind
of that last way you expressed it and in particular you know TensorFlow is obviously a popular
platform for this stuff like is it an either or no it doesn't have to be at all in fact
we have a feature that we added the product recently called gears and for the developers
in the audience this is an interrupt feature and for people who aren't developers per
say it's what allows you to bridge the gap right it allows you to bring your current
investments that you've built whether it's in TensorFlow or you built a perception model
using OpenCV or whatever you happen to have done and add that to the system.
Facet of building any of a modern machine learning system which is not just building the
model but also deploying it in a production environment those there's actually completely
separate problems are going to face in those two arenas and so you might have built these
models but and want them to participate in the broader prediction pipeline and you can
do that very easily in our system using the gears feature it'll we allow you to add
that in so it's again going back to the the database analogy you don't have to if you
have the that expertise and you want to do it or you've already baked a bunch of things
and you want to leverage them we're not going to make you redo that work and we're not
going to stop you from tinkering with the lower level pieces if that's what you want
to do it just becomes an option as any good platform should it's we're going to give you
the ability to say I don't want to deal with any of that do it for me or I've done some
of this and I want to add it or now I want to tinker with the low level bits because I
I feel like I've learned enough and I'm an expert and I want to do that now so you can you
can play at any of these levels but it's not an either or in fact if you bring a TensorFlow
model to the system it integrates really well our systems built on TensorFlow a TensorFlow
based gear we can chain everything in all the appropriate ways if you have a Python function
that you've written you want to call out to maybe you want to invoke a cloud API because
you've made an investment in Watson or some other technology none of these are barriers
and in fact this is part of the way the system was designed if we go back to the very very
beginning and I talked about you have existing controllers that know how to do the inverse
kinematics and all you need to do is move your robotic armature between point A and point
B you should not be teaching that that is but and this goes to the academics right so
you look at the academic papers they're going to talk about how you teach all these things
and that's great because it's it's talking to how we further enhance the technology and
I love that work that's great but if we're talking about practical real world application
why you have tons of work spent on building that and you should just use it and that's
a very simple simple example but if you look at autonomous vehicles the automobile companies
have spent a lot of resource on building capabilities around assistive parallel parking
and all these other things do we really want to go reinvent all of that it it seems kind
of silly we should just integrate that with the rest of everything else and that
idea extends to your cloud based API is your TensorFlow module totally totally that's right
that's right it can't be a homogenous this is the only way or you know that's not that's
not practical that doesn't work so this has been super interesting anything that you'd
like to leave folks with well I would encourage the audience to take a look at our platform
if they're interested in the early access program of course we would love to hear from
you if you have a use case that you think is suitable we'd love to hear from you but
just in general I would encourage everyone to start thinking about machine teaching whether
it's with us or not with us the path forward for industrial AI in general is going to
rely very heavily on the marriage of human expertise and machine intelligence you need
both it's not enough to have one or the other you need both and so starting to explore
in more depth how you're teaching the system don't just throw data at it blindly don't
that that's that's level one right you need to move several levels beyond that and so I
would encourage everyone listening start to think about that start to think about strategies
for doing that whether you're rolling your own or whether you're using a tool like ours
that matters a whole lot and as practitioners using this technology a lot of our job is
going to be teaching it's not going to be over time the tools will get better tensor flow
will add more capabilities platforms like ours will become more prominent all of these
things will happen just as a natural evolution of the industry and the part that will remain
in all circumstances no matter what is how do I teach what I want the system to actually
be intelligent about and that's going to be with us forever and that's very particular
and idiosyncratic to our businesses and what we're trying to accomplish so really start
to think about that that would be what I would encourage the audience to do great great
and we'll make sure we point folks to your website and the eap and some of the other stuff
we talked about sounds great awesome thank you so much yeah thank you as well I really
appreciate it all right everyone that's our show for today thanks so much for listening and for
your continued feedback and support for the notes for this episode including links to mark
and the various resources mentioned on the show head on over to the show notes at twemolei.com
slash top slash 43 please be sure to comment there with your feedback or questions
thanks again to our sponsors for this series bonsai and wise.io at ge digital I'm so so grateful
for their support if you enjoyed this series it would mean a ton to me if you took a second
to reach out to them on twitter to thank them for their support at at wise.io and at bonsai AI
don't forget to register for my newsletter at twemolei.com slash newsletter and for next months
online meetup at twemolei.com slash meetup thanks again for listening and catch you next time
