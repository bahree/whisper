Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host, Sam Charrington, alright everyone, I am on the line with Ahmed El Gamal.
Ahmed is a professor in the Department of Computer Science at Rutgers University, as well
as director of the Art and Artificial Intelligence Lab there.
Ahmed, welcome to this week in machine learning and AI.
Thank you for inviting me.
Absolutely, I'd like to get started by having you share a little bit about your background
and what brought you to an interest in kind of the space of digital humanities and this
confluence of art and AI and more broadly your interests in computer vision.
Yes, so my career has been around artificial intelligence for a long time in particular
computer vision, I'm a computer vision person, but also I have a long version for art, for
long time.
And as a computer vision person, I always find it interesting that we, the vision look
at images and can you recognize cars and dogs and cats and men and women, he's like that.
But obviously, if you look at an artwork, that's not what we're looking for, it's much
deeper.
There are layers and layer of understanding of artworks that we do as human when you look
at artworks and also not only the understanding, but artwork effect us at the emotional level.
So it's much deeper than just what we do with the science and the vision.
That always intrigues me and that as an AI person, I also find it very, very interesting
and very fascinating because I believe that AI is not only about driving a car or
they just, in order to have a machine that is intelligent at the level of human intelligence,
the machine has to be able to understand these creative products like art and music and
literature and jokes and not only understand them, but be able to create them as well.
And this is not something new actually since the beginning of AI and the tone of AI scientists
has been trying to do that, I've been trying to create art and create music and understand
art and music, but it has been very challenging.
And I believe this is one of the important aspects to prove that AI is actually intelligent.
One of your recent projects is a tool called ICANN which is focused on generating art.
Can you talk a little bit about the genesis of that project and ultimately the capabilities
of that tool?
Yes.
So in the last few years, GANN came around, which is an amazing tool to generate images
in particular, given some training sets.
So GANN by design is supposed to generate new samples of some distribution, if you give
it images of pets, it will try to generate more and more images of pets, and some people
have tried to use GANNs before to make art books like you give it portraits, Renaissance
portraits, for example, and try to generate these portraits.
However, our understanding of art is very different.
I believe that art is about innovation and making something novel.
So if you just generate samples from the same distribution of art that you give it, it's
not going to be art, it's not going to be called art, that's imitation of art.
So you have to be creative, you have to boost the machine to be creative.
There's a whole field of stuff in the AI called computational creativity, where scientists
in that GANN has been for a long time studying how to make the machine creative, how to make
a creative process, whether you are creating music or art or visual art or literature,
or drugs or anything like that.
So my goal is really was how can you change GANN to make it creative, not just simulating
the solution, but pushing the envelope of art to make something new, and then our long
study of these issues in the lab helped us into completing this problem.
So first we have to come up with a theory about how art evolved to start with, how artists
make new art, obviously these are theories or several theories about that.
The theory we use is coming from psychology by a scientist, his name is Colin Martin
Dale.
So here's the question, look at history of art, what happened, why artists keep evolving
the styles as they go, why Baroque happened after Renaissance, and why impression is
not happening in 19th century, and why Cubism came after that, and it is just random or
there's something fundamental in how these styles illusion and evolve.
So basically, artists always has to generate new ideas in their art to push against what
is called habituation, because if we keep looking at the same art for a long time, it's
not interesting anymore as an artist, as a viewer, so artists has to always innovate.
However, this innovation has to come with what's called list effort, because if you innovate
too much in your art, unlikely that people will accept that, will be shocking for people.
So artists has to innovate to a certain degree, but with a limited amount of innovation, somehow
push against habituation, according to the list effort principle.
So that's exactly what we're trying to implement to make GANs creative.
So we develop what's called creative adversarial network, it's a variant of GAN that's really
designed to be implementing this concept.
So how can we make it innovative, or push the novelty, there are different ways to do
that.
In particular, we look at what's called style ambiguity, which is a process that relates
how artists break out style, so suppose, for example, you are an impressionist artist
living in the 19th century, making a lot of impressionist work.
After a while, you have exerted all possible things you can do within that style.
You have painted all possible facades, all these possible length games, all possible scenes
in that style, and at some time you already exerted all these possibilities, if you are a
new artist, even if you like that style, and you innovate, there is no room for innovation
anymore within that style.
So that's basically the reason why most artists at certain points break out style and create
something new.
Coming up was something new, like, for example, Tzan at the time, or Van Gogh at the time
trying to break out of ambitionism and do what's called after that was the ambitionism.
So that's exactly what we're trying to do here.
How can we digest what having artistry to certain points, to some certain points, and break
out of style to create something new?
Can I jump into it with a question, and this may lead you into what you actually did.
But when I think about what you're proposing that we develop a model of the way artists
generated, and in this case, the model kind of supposes that the artist lives within some
style, but there are maybe kind of random pushes of the envelope, if you will, or maybe
they're not random, but an individual artist innovates, but not too much.
I kind of get that as a simplistic model for the evolution of art.
But it does seem like coming up with some kind of representation for that and how that happens
would be very complex computationally.
Yes, definitely.
You have to simplify it.
And that's what we managed to do at least to certain degree.
We suppose we give the machine lots and lots of images of art.
What we did was we give it art from the last 500 years of Western canon of art history.
And we only give the machine the artworks and the style of each artwork according to
styles from art and history and like Renaissance Baroque, imperialism, all these art movements
that happened.
So this is the only thing that the machine gives the machine, the images of the art and
these labels.
So the formulation here is that we want the generator, we want to put the generator under two opposing
courses in one hand, like a chemical gun, if we need to learn the distribution of art,
right?
We need something from that distribution.
But that would be only imitation, right?
So how can you push it to be innovative?
So we added what we call style ambiguity.
We want to basically, the generator generates something that follows the distribution but
doesn't follow the existing styles at all.
So in order to do that, the discriminator here has to be equipped with a stylist's fire.
So the estimator has to be able to tell for any new artwork what style is it, is it
Renaissance, is Baroque, is it Ubism, is it abstract.
So the generator job here is to find out a solution that generate images, follow the
general aesthetics of art, follow the same distribution of art.
But in the same time, doesn't follow any existing styles because if it generated another
ambitionist art or another, a cubism art, you're going to get been allowed.
So you see the dilemma here, so it has to generate something that fits the aesthetics in
general, but doesn't fit existing style.
And that what needed to innovate in style, but follow the aesthetics doesn't really make
something shockingly random that people won't accept.
And we see that right away in the generation, what it generates is always following the
style, following the aesthetics so you can see a good choice of colors, a good choice
of composition rules, variety of texture, but in the same time, you can not easily put
what it generates into any existing style.
It doesn't repeat what happened before, we don't see anything that looked like Renaissance
or a cubism art or a cubism art, we can always see that it innovates and try to make something
new out of that.
So these two forces actually kind of boost the innovation, but limit the innovation at
the same time because we bullet back to the distribution of art, so it doesn't go straight
and start generating random things that's going to be too innovative.
How do you kind of enforce this rule to maintain the aesthetic, but not the style within the
GAN?
Basically, the loss function of the GAN, we change the loss function of the GAN such that
it has these two opposing losses.
In one hand, it has a typical GAN loss, which is try to generate images from the distribution
of the real fake loss as usually in a GAN setting, so it is, that's incentive to be within
the aesthetics, but in the same time, we have the style ambiguity loss, which is basically
based on the style classifier of that denominator, we compute some sort of entropy score out
of that style classifier, and we basically try to maximize this style ambiguity.
So in one hand, when I minimize the divergent from the distribution of art, but in the same
time when I maximize the ambiguity of the style, so this implemented the two opposing forces.
Okay, and now is the loss function, when it's evaluated, is that a scalar, and I guess
what I'm asking you is, do you have this issue where you have these two opposing components
of your loss function that just average out and kind of you lose all of the information
and the nuance in the two different components, or is that not an issue here?
That is exactly what it's trying to do.
I mean, it tries to find out both in the surface of the optimization that you are doing that
in between the two.
You want to minimize one, maximize the other, so it has to find some sweet spot between
the two.
I'm curious about the training process you've got.
How many images did you train the Gannon?
Yeah, the first version we did, it was about 80,000 images from last 500 years of Western
art, about 20 different styles that we used at starting from my sons to all the way
to contemporary art, almost tiny form among all the styles, make sure that we don't have
any bias in the data, so roughly all the styles are in uniform number.
So the interesting thing was that under distance trains, we find that the machine tends to generate
more and more abstract works, less figurative artworks, and more abstract works for
that, which is very interesting.
Why is that?
I mean, why they would generate abstract artworks and not figurative artwork?
We kept thinking about that for a long time, so why is that?
But when we look at the progression of history of art, one thing we find interesting in the
results is that the machine under distance trains that we put in generate more and more
abstract artworks and less and less figurative, we hardly see any portraits or any landscape
generated.
It's more about more abstract and more, it's a little bit surrealist nature.
So we were wondering why is that, why the machine generates more abstract?
However, if you look at art history and look at the progression art history, at least
some other research we have done also, we actually find that it's clear that art history moves
into a trajectory from a figurative art through the history in the last five centuries until
we reached the 20th century, where artists move into abstraction and very beautiful abstraction,
then later into a color field painting and abstract exhibitionism and contemporary art.
So there is a clear trajectory of art moving away from figurative art into abstraction,
which basically seems that the machine here figured out that there is this trajectory
and in order to create novel art, it has to be more into the abstract realm of art.
So under this constraint that we put into the formulation, it seemed that finding a good
solution, abstract art provides more good solution that fits these two constraints.
Because if it's a figurative art, it probably gonna generate things that looks like Renaissance
or Baroque or other classical styles, so it didn't analyze why for abstract art, I think
there's a lot of room for experiment for the machine or results that machine can generate
that doesn't really fit into existing styles that easy.
So it's seen that's why the machine is getting more and more of these abstract works.
The website is aicanicand.io and we'll put a link in the show notes.
I definitely, you know, the abstract nature of the results are very apparent.
But I think about kind of the, you know, art that might be generated by again, what comes
to mind is more like the, if you remember back in 2012, this woman tried to do a hand
restoration of this Spanish fresco echihomo and basically made it look really, really
bad.
And that's kind of what I think of when you kind of think of ganger-erated images, at
least, you know, the gans are getting a lot better now, but these are decidedly abstract.
And in fact, you have a gallery on the site that's kind of the 2017 version of the, of
Ican and then a 27, 8, 2018 version of Ican and just kind of comparing the two visually.
And I'd like you to comment on, you know, the, whether, you know, this could be kind of
selection bias, you handpicked, you know, the images kind of differently or something.
But the, the art is much better in the gallery that you're displaying for 2018.
Is that characteristic of the, the second version of the model's results or did you just
pick better art for the website?
And no, just physically we change more and more data for longer time and it gets, it
is affecting the, the process, so that's why it's getting better.
And that's, that's maybe not, you know, not intuitive that, you know, I would almost expect
maybe that a counterintuitive result or the opposite result, you train it, you know, with
more, if you're training it with more historical art that it would tend more towards kind of
reproducing what it sees then to get further out into abstraction, if that makes any sense.
That's absolutely not, that's a whole idea that, that, again, we'll do that.
Again, we'll definitely try, if you get more data and more training it will emulate the
data better.
But, exactly, but what we doing here is the variant that we drive, which is creative at
the cellular network, which is, by definition, it doesn't try to generate anything that existed
before, because if you generate things that stimulate what existed before that get, get,
get been alive because of the style ambiguity, but of the loss, so it has to generate something
that doesn't fit existing style at all, but follows the aesthetics, that's why it's always
has tried to generate things that are not holding into existing styles, and that's why
bush, bush, bush the creativity of the, of the result.
So having more data will, will, will, will not make it emulate the results by definition,
because we, it still have to innovate according to the loss.
And actually, let me discuss this, according to your question, why this is different from
GANs, GINID images, of course.
Exactly, if you, if you look at most of our GINID by using GANs, especially maybe a year
or two years old, now GANs getting better, if you give it a board trace, for example,
as training sets, it will generate what's, what's looks like the form of board trace, right?
So you can see kind of, Francis Bacon, the form of style of board trace in the generation,
specifically, GAN images that you see in several artists, the genetic art using GANs
are having this characteristic.
So what happens in that case is actually, the GANs are not successful in generating good
board trace.
So the GAN actually fails in generating the board trace correctly, and, and because of
the deformation, that's why you will find it interesting.
So it surprised you because of the deformation, and that surprise is why you might like it,
or might not like it as a viewer.
That's why, that's, I mean aesthetics in GANs, genetic images, the element of deformation
or failure to imitate the training data.
So, and that's exactly what we've pointed out in our academic paper, when we derived
the PICAN, is that we, we thought, we think of this failure to imitate the solution as
a failure case, not a creative process.
The machine here is not intentionally deforming the image.
The machine is just failing to imitate the poetry.
For us as a viewer, it's interesting thing to look at.
But the process here is not creative.
The process here is a, a, a emulative process that just failed, right?
And that's totally what, not what we are trying to do, we're trying to really make it
be constructive in being creative, meaning that the machine in our case in, in, when we
We do a hand, but the machine from the beginning
trying to generate something that have these two constraints
both into place follows the aesthetic,
but doesn't follow existing style.
So with these two constraints,
the machine has to find a solution
that satisfies these two constraints.
Art history, if you look at the way art history progress
over time, there is a quote from an art historian,
his name is Henry Walbren, who say that style
has to evolve in a smooth way, like a rock rolling down a hill.
Meaning that first, a style doesn't jump.
We cannot have renaissance moving into ambitionism
and moving that to Baroque and then moving to realism.
No, it doesn't happen this way.
Style moves in a very slowly over time
from renaissance to Baroque to in a very ordered way.
So if you boost the machine to generate something that
doesn't fit existing styles, but keep the aesthetic
it cannot find a solution by mixing out, for example,
renaissance and Baroque or mixing out Baroque and
ambitionism or try to find something in between.
There is no way to find something in between a solution.
So the only way for the machine to solve this problem
is really to extrapolate on that trajectory,
figure out that is a trajectory of how art progressed
and then generate something on top of that.
And that's why Jeanette Moore and more abstract works.
So by construction here, as the machine has a creative
process in terms of generating the art,
it doesn't emulate, it has to always innovate.
And the source of aesthetics of what you see
is this creative process is not the failure
through which you need something from the data set.
It's not the failure to generate a board tree.
It's not a failure to generate a landscape.
The real aesthetics here coming from the fact
it's followed the aesthetics rules, learning the ethics rules,
but try to constructively be constructively
generating something new.
Yeah, I'm not sure I fully understand that.
So what I hear you saying is you've got this,
the history of art is this progression or sequence of styles.
And what your can kind of creative adversarial network
is creating is something that is art
that doesn't exist kind of between two styles,
but kind of by definition projects out
from kind of the last element of that sequence.
And maybe you're just speaking figuratively,
and I'm trying to be too literal or rigorous about this.
But why is that necessarily the case?
Why is it that the things that we're seeing
are not kind of orthogonal to the sequence of styles
that we've seen?
Yeah, it's a good question.
Yes, it can.
It can be.
Because at the end, I mean, we, the machine-strike solution
giving the constraint we give it.
But let me bring you out to another piece of research
that we have done.
In another research, we looked at what representation
the machine learns if we teach it to classify styles.
So we give the machine lots of images and style labels
and train lots of new networks to classify styles,
such as to try and classify whether the art is very
sounds borrowed, ambition is man, and so on.
Just like classification.
But then what we looked at, we looked at what representation
the machine learned.
So we look at the activation of the fully committed layers
and in this network and look at things
like the principal component analysis of these activitions
and the manifold of activation and things like that.
And to our surprise, when you look at this,
we find that the machine arranged the data
in a chronological order by itself.
Interesting.
Yeah, we never give the machine anything
about the date of the artwork or that any sounds
happened before Baroque or Baroque happened before Cubism
or Embritionism.
We found that when you look at two-dimension plots
of the data, Renaissance comes first, followed by Baroque,
followed by 17th century art.
And then comes 19th century art realism and Embritionism
and then move to Cezanne and move to Cubism and abstract.
By itself.
Amazing. I mean, you can find that the machine actually,
the art has evolved into a full circle
going from Renaissance all the way to 20th century
in a very smooth way.
And the machine discovered that by itself.
Interesting.
I was going to ask what happens if you tell the network
kind of the sequence by feeding in dates,
but it sounds like you don't have to it, figures it out.
Exactly, exactly.
And that exactly explains why the machine actually generated
art that is more figurative and more abstract at the end.
Can you elaborate a little bit on how you got
to this two-dimensional or kind of time representation
or sequential representation from the activations?
Yeah, so basically we look at the activation space
and look at the modes of variation,
the principal component analysis of this activation space.
And what we find that first, you can explain
almost 95% of the variance of the data
using very few number of components
in the activation space, usually five, six components
in all the networks that you have seen.
And actually the first two dimensions,
the first two modes of variation captured
about 70% of the variance.
And if you plot the data against these two modes of variation,
you can always clearly see this chronological progression
from 14th century till now,
where if you go radially across clockwise, across that
to the emission plot, it has about 70% correlation
with time.
So the machine figured out this smooth transition by itself,
which basically tells us that one thing we already know
from art history is that style progress in a very smooth way,
it doesn't progress in random ways,
it progressed in a very smooth way.
And that's what the machine was figured out by itself.
If I were to create a model for the evolution of art,
being someone who's probably as far as you can get
from someone who knows anything about this,
but I would kind of evolve the model that you've described
where you've got these kind of styles
and then these perturbations in aesthetic
or perturbations in, how did you describe that earlier?
That kind of the simple model for the way art evolves?
You wanna boost innovation
and there are multiple ways to boost innovation,
but you wanna boost innovation in a least amount
or least with least effort.
Right, right, right.
So you've got this style that has evolved
and you kind of innovate in these small incremental ways.
And I guess what's missing for that for me is,
it strikes me that you have a lot of that
and then you have these kind of big step function innovations
that are much more dramatic than the small random innovations.
Is that just not true from the kind of research
into the evolution of art or is that possible
further extension of work like this
to incorporate that type of model?
Actually, what you're saying is true.
There are different ways artists innovate in their work.
They can innovate within the style
and they can break out of style.
And this is something that Martin Delecchi pointed out.
Most artists work within a style,
meaning that there is a predominant style
at any time in history.
And most artists just work within that style.
Like if you are in 17th century,
probably you're gonna do Baroque.
That's what's happening and everybody is doing
within the rules of Baroque style.
But what happened is at certain points,
artists really are a good board of these schools
that they are working with
because they tried all possible subject matter
within that style and there's no room for innovation anymore.
When you're working within the style,
the only way you innovate is to look
at different subject matter within the style.
You can try the different story,
different scene, different things,
but everything within the style rules.
But at certain points, you exerted all these possibilities.
And then that's where really important artists
come up with new break out of the style.
That's what happened, for example,
when Picasso broke out of what's happened
and painted ladies of Avignon, for example, in 1907.
And that was too innovative at that time.
And it led to the beginning of Cubism
or earlier when Monk bended the scream
and early works of exhibitionism.
So there are always certain artists who break out of style
and other artists are to copy these new styles
and follow their direction.
And that's the kind of innovation we plugged in
into the formulation of Can,
which is the style ambiguity.
We don't want an machine to generate something
that fits existing style.
Because if it generates something that fits existing style,
it's the entropy, there would be no surprise.
The entropy would be very low for that bottle of the loss
and we're trying to maximize that more.
But the machine has to always generate something
that the classifier, the discriminator,
cannot classify, be almost uniform in terms of classifying
that style according to the styles that you give the machine.
So that's where the style ambiguity gets maximized.
Okay, interesting.
So I'm curious, this working creativity
is kind of one area of interest of yours.
Were there any principles or observations
that you made in working on this project
that kind of informed your broader work in computer vision?
I have been focused more and more into that area
for the last maybe six, seven years
to really understand more how to make the machine understand art.
And so the generation of art is something that came
actually out of long progress into understanding this concept.
So the earlier works that we have done in that area
those things like how to classify styles,
how to classify the genre of art, how to classify artists,
how to look at artistic influences
and even you have worked earlier
on how to quantify creativity in artwork.
Like can you tell, can you look at art history
and look at images only and their time stamps
and find out artworks that were creative in their time.
And actually we find that the machine by some formulation
really what's called network centrality
could figure out important piece of art
to art history just by looking at images of art
and their dates without knowing anything else about styles
or about artists or anything like that.
So the machine figure out for example things like
Picasso's ladies have been known
or a monk's theme or Monet's tag
has fundamental important pieces of artwork in history.
And that lead us, that lead us actually
to formulating the creative adversarial network
as a variant of GAN that has this built in process
of style ambiguity as a constraint
that help pushing the machine to be creative
and innovative.
Interesting.
So really, really interesting work.
How do you see this work evolving?
What's next?
What's next is you are focused now on our focus now
and how to, what we've proved is basically that the machine
can, we can give the machine all this art history
without any curation just to give it all art history
and it can generate almost autonomously new artworks
that what we achieved.
So that's a proof concept that machine
can reduce things autonomously to some degree.
But what we really want to do is to give artists
a control over the process.
How can artists control this generation
to achieve something that they want to do,
not just make it autonomous?
And that's really what we try to do now,
how to make it more collaborative and more controllable.
Fantastic, fantastic.
Well, Ahmed, thank you so much for taking the time
to chat with us about your work.
Thank you very much.
All right, everyone, that's our show for today.
If you like what you've heard here,
please do us a huge favor and tell your friends about the show.
And if you haven't already hit that subscribe button yourself,
make sure you do so you don't miss any of the great episodes
we've got in store for you.
As always, thanks so much for listening
and catch you next time.
