WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:31.960
I'm your host Sam Charrington.

00:31.960 --> 00:37.160
Earlier this week I had a chance to speak with Chris Shaloo, senior software engineer at

00:37.160 --> 00:44.360
Google AI, about his project and paper on exploring exoplanets with deep learning.

00:44.360 --> 00:46.680
This is a great story.

00:46.680 --> 00:52.040
Chris, inspired by a book he was reading, reached out on a whim to a Harvard astrophysics

00:52.040 --> 00:57.400
researcher kicking off a collaboration and side project eventually leading to the discovery

00:57.400 --> 01:02.160
of two new planets outside of our solar system.

01:02.160 --> 01:07.720
In our conversation, Chris and I walked through the entire process he used to find these two

01:07.720 --> 01:13.360
exoplanets, including how he researched the domain as an outsider, how he sourced and

01:13.360 --> 01:18.080
processed his dataset and how he built and evolved his models.

01:18.080 --> 01:26.440
Finally, we discussed the results of his project and his plans for future work in this area.

01:26.440 --> 01:30.720
This podcast is being released in parallel with Google's release of the source code and

01:30.720 --> 01:35.840
data that Chris developed and used, which will link to in the show notes.

01:35.840 --> 01:40.480
If what you hear inspires you to dig into this area more deeply, you've got a nice head

01:40.480 --> 01:42.000
start.

01:42.000 --> 01:47.560
Chris was a really interesting conversation and I'm excited to share it with you.

01:47.560 --> 01:52.520
Before we jump into the interview, a reminder that the next Twimmel Online Meetup is quickly

01:52.520 --> 01:54.000
approaching.

01:54.000 --> 02:00.040
Be sure to join us next Tuesday, March 13th, for an in-depth review of reinforcement

02:00.040 --> 02:05.520
learning and the Google DeepMind paper, playing Atari with deep reinforcement learning, presented

02:05.520 --> 02:08.080
by Meetup member Sean Devlin.

02:08.080 --> 02:13.760
Get on over to twimmelai.com slash Meetup to learn more or register.

02:13.760 --> 02:18.080
Okay, let's get to it.

02:18.080 --> 02:25.800
Hey everyone, I am on the line with Chris Jaloo.

02:25.800 --> 02:28.600
Chris, welcome to this Weekend Machine Learning and AI.

02:28.600 --> 02:30.840
Thanks Sam, happy to be here.

02:30.840 --> 02:31.840
Awesome.

02:31.840 --> 02:35.640
Why don't we get started by having you tell the audience a little bit about your background

02:35.640 --> 02:38.960
and how you got interested in machine learning?

02:38.960 --> 02:39.960
Sure.

02:39.960 --> 02:44.880
So, I started out studying mathematics actually.

02:44.880 --> 02:51.920
In my undergraduate degree, I did a double major in pure and applied mathematics.

02:51.920 --> 02:57.400
And once I graduated, I then did a year of research in pure mathematics, studying certain

02:57.400 --> 02:59.920
classes of polynomials in fact.

02:59.920 --> 03:00.920
Oh man.

03:00.920 --> 03:07.640
I'm starting to break out and like sweat here, I think in grad school, the real analysis

03:07.640 --> 03:10.160
class I took was like the hardest class.

03:10.160 --> 03:11.160
Right.

03:11.160 --> 03:14.520
Well, I was actually studying these polynomials over finite fields.

03:14.520 --> 03:18.400
So it was more in the abstract algebra space.

03:18.400 --> 03:25.480
But to your point exactly, after I did this, I decided I wanted to do something with more

03:25.480 --> 03:29.280
of a concrete application in the real world.

03:29.280 --> 03:32.360
And so I knew I wanted to do a PhD.

03:32.360 --> 03:37.640
And so I looked at some other options and eventually I decided to pursue a PhD in biomechanical

03:37.640 --> 03:38.640
engineering.

03:38.640 --> 03:39.640
Oh wow.

03:39.640 --> 03:46.880
So I started that PhD, but after about a year I decided that perhaps a career in biomechanical

03:46.880 --> 03:49.760
engineering research wasn't for me.

03:49.760 --> 03:53.160
So I started to look for other opportunities at that point.

03:53.160 --> 03:57.960
So briefly, I went back to mathematics for a little while by teaching classes at a

03:57.960 --> 04:03.920
university, but I decided to apply for a job at Google mainly because I was excited

04:03.920 --> 04:08.960
by some of the really high impact world changing projects that I was hearing about coming

04:08.960 --> 04:11.360
out of Google in particular.

04:11.360 --> 04:14.200
I remember being excited by Project Loon.

04:14.200 --> 04:19.200
So for those who don't know that was a project, it's actually still going that tries to use

04:19.200 --> 04:25.960
networks of flying balloons to bring the internet to users in rural and remote areas.

04:25.960 --> 04:30.720
So I applied to Google and I was hired as a software engineer, but unfortunately I didn't

04:30.720 --> 04:33.640
get to work on Project Loon straight away.

04:33.640 --> 04:38.080
I was actually placed in the Google Display Ads team and I was working on ads for Google

04:38.080 --> 04:40.360
Maps and Gmail.

04:40.360 --> 04:42.960
And this is where I got my first taste of machine learning.

04:42.960 --> 04:47.840
I was actually working on models to try and show the most relevant ads to each user.

04:47.840 --> 04:52.000
And I learned a lot about machine learning in that role.

04:52.000 --> 04:57.840
And then early on in my career at Google, I saw a presentation here at Google by some

04:57.840 --> 05:01.720
researches in the Google Brain team where I currently work.

05:01.720 --> 05:07.760
And they had created a neural network that would automatically generate image captions.

05:07.760 --> 05:09.480
And I thought this was really exciting.

05:09.480 --> 05:15.440
This model that they created could accept raw pixels from photographs and output fully

05:15.440 --> 05:19.960
formed English sentences that would describe the photo.

05:19.960 --> 05:24.320
And so this model was actually trained using only images and captions as input.

05:24.320 --> 05:29.880
So quite amazingly, the model was not actually given any details about the English language

05:29.880 --> 05:32.200
except the captions.

05:32.200 --> 05:38.600
And it actually managed to learn not only how to caption images, but also how to write sentences

05:38.600 --> 05:42.680
with good English grammar, which I thought was pretty amazing as well, just from reading

05:42.680 --> 05:44.320
captions.

05:44.320 --> 05:49.080
And so at that point I decided I wanted to work on the Google Brain team.

05:49.080 --> 05:54.360
And luckily I got the chance to transfer to the brain team after two years in ads.

05:54.360 --> 06:00.160
And since then I've been working on machine learning research here in the brain team.

06:00.160 --> 06:03.940
And I've been lucky enough to work on many different areas of machine learning research

06:03.940 --> 06:05.440
since I joined the team.

06:05.440 --> 06:06.440
Awesome.

06:06.440 --> 06:11.560
And one of the areas that you did get to work on, you got a little bit of publicity on.

06:11.560 --> 06:17.120
This grew out of really a side project or a hobby project, is that right?

06:17.120 --> 06:24.680
Yeah, that's right, actually this project that I've been working on to discover planets

06:24.680 --> 06:31.640
with machine learning really grew out of a random sort of chance idea I had while I was

06:31.640 --> 06:35.480
reading an unrelated book.

06:35.480 --> 06:41.800
There's a book called Human Universe by Brian Cox, which is mainly about exploring our

06:41.800 --> 06:47.960
evolution as a species, but it also digs into the question of whether we are unique in

06:47.960 --> 06:49.840
the universe.

06:49.840 --> 06:59.240
And one of the fundamental pieces to that question is whether there are other planets like Earth

06:59.240 --> 07:02.440
out there and how many there are.

07:02.440 --> 07:08.440
And then one of the things he mentioned in this book was that it's actually quite difficult

07:08.440 --> 07:16.840
to detect these planets in sort of around far away stars.

07:16.840 --> 07:23.200
And one of the difficulties is actually digging through this huge amount of data that

07:23.200 --> 07:26.000
is collected by modern satellites.

07:26.000 --> 07:32.160
And so when I read that, I instantly connected that back to my work at Google where we train

07:32.160 --> 07:35.560
models to dig through large data sets all the time.

07:35.560 --> 07:40.240
And so I wondered if perhaps we could apply some of those same techniques to dig through

07:40.240 --> 07:43.520
these large astronomy data sets and look for exoplanets.

07:43.520 --> 07:44.520
Nice.

07:44.520 --> 07:47.160
And this is interesting to me.

07:47.160 --> 07:54.480
I've interviewed several people who have come from physics, including at least one astronomer

07:54.480 --> 08:02.640
Josh Bloom, who's at GE Digital now, who have started from this kind of deep domain

08:02.640 --> 08:09.240
knowledge and learned machine learning and applied it to what they're doing.

08:09.240 --> 08:13.480
But you're coming at it from almost the complete opposite approach, like you have some machine

08:13.480 --> 08:15.440
learning tools.

08:15.440 --> 08:22.120
And then you hear about this really interesting problem in astrophysics and you get involved

08:22.120 --> 08:25.120
and you actually do something really interesting with them.

08:25.120 --> 08:26.720
How did you get started?

08:26.720 --> 08:33.280
Well, you're right, that I actually don't have very much background or knowledge in astronomy

08:33.280 --> 08:34.280
at all.

08:34.280 --> 08:37.400
In fact, I still don't.

08:37.400 --> 08:45.960
And so the first thing I did was I jumped on Google and started looking for what these

08:45.960 --> 08:49.560
data sets actually looks like and who worked with them.

08:49.560 --> 08:55.760
And I was lucky enough to stumble across the name of an astrophysicist who was at the

08:55.760 --> 08:58.960
time working at Harvard, his name is Andrew van der Berg.

08:58.960 --> 09:07.360
And he seemed to be someone who had dealt with these data sets in which we looked for planets.

09:07.360 --> 09:15.080
And so I literally just sent him an email and said, hi, I work at Google in machine learning.

09:15.080 --> 09:19.480
Would you be interested in collaborating on a project together?

09:19.480 --> 09:21.720
And he actually was interested.

09:21.720 --> 09:26.520
And so this whole project has really been a partnership between Andrew and I where I

09:26.520 --> 09:32.760
have taken care of the machine learning side and the coding side.

09:32.760 --> 09:35.640
And he has taken care of the astronomy side.

09:35.640 --> 09:38.960
Tell me a little bit about the timeline of the project.

09:38.960 --> 09:42.200
How long did you spend, have you been working on this?

09:42.200 --> 09:48.480
So I believe I started working on this project in late 2016.

09:48.480 --> 09:54.040
So around September or October, I believe I first emailed Andrew.

09:54.040 --> 09:59.240
And initially I was working on this as you mentioned at the start as a side project.

09:59.240 --> 10:05.000
I was really just devoting 10 or 20% of my time to this for a few months.

10:05.000 --> 10:10.440
But it was around March or April in 2017.

10:10.440 --> 10:16.880
So perhaps six months later that we had managed to train a model that we thought we might

10:16.880 --> 10:21.200
be able to use to search for new exoplanets.

10:21.200 --> 10:29.800
And when we ran this model on a very small sample of stars, we actually found that we were

10:29.800 --> 10:34.120
able to discover some new signals that probably were exoplanets.

10:34.120 --> 10:39.360
And that's when we started taking this project a lot more seriously.

10:39.360 --> 10:45.840
And then I started working on it probably more towards 100% of my time.

10:45.840 --> 10:57.520
And so then for most of last year, for the rest of 2017, we really went back and carefully

10:57.520 --> 11:02.680
trained our model again and used it to actually carefully search these stars.

11:02.680 --> 11:08.360
Andrew did the validation of our new planets that we discovered and then we wrote the paper

11:08.360 --> 11:11.480
and that was published in January of this year.

11:11.480 --> 11:16.800
We'll dig into kind of how things shifted when you started working on this full time.

11:16.800 --> 11:24.040
But I suspect that there are a lot of folks out there who know some machine learning maybe

11:24.040 --> 11:30.680
have taken a deep learning course or working it and would love to apply it on a project

11:30.680 --> 11:32.240
like this.

11:32.240 --> 11:37.720
And so I'm really curious if you can dig into those first six months or even those first

11:37.720 --> 11:38.720
six weeks.

11:38.720 --> 11:44.320
When you're spending just 10, 20% of your time equivalent to what folks might have to

11:44.320 --> 11:48.440
work on a project like this in their nights and weekends.

11:48.440 --> 11:50.920
How did you approach it and what were some of the things you did?

11:50.920 --> 11:58.440
What did the data set look like and how did you set priorities for making progress with

11:58.440 --> 11:59.440
this?

11:59.440 --> 12:00.440
Sure.

12:00.440 --> 12:05.800
So actually when I started, I had this vague notion that we would use machine learning

12:05.800 --> 12:10.280
to search for planets but I didn't even know what the data looked like.

12:10.280 --> 12:17.960
I thought that what we might be doing is taking a model to input photographs from the

12:17.960 --> 12:26.520
sky and actually look for the actual planets in images on the sky.

12:26.520 --> 12:32.600
But it turns out that's not in fact the way that most exoplanets are discovered.

12:32.600 --> 12:38.680
So the format of the data in this case, it's actually not images of the sky.

12:38.680 --> 12:44.680
But rather we look at how the brightness of a star changes over time.

12:44.680 --> 12:50.280
And so if you're monitoring the brightness of a particular star in the sky and if a

12:50.280 --> 12:56.640
planet happens to pass in front of that star relative to the telescope that's recording

12:56.640 --> 13:02.440
the brightness, you'll actually see the brightness of that star dip down while the planet

13:02.440 --> 13:10.360
is blocking some of the star light and then the brightness will then increase again once

13:10.360 --> 13:15.120
the planet is no longer blocking any of the light from the star.

13:15.120 --> 13:20.960
So the data that we're looking at is actually a time series of brightness and what we're

13:20.960 --> 13:27.240
looking for is certain patterns in that brightness time series that would correspond to a planet

13:27.240 --> 13:29.440
passing in front of the star.

13:29.440 --> 13:36.400
Do you get it as a time series of brightness because it's been pre-processed from the

13:36.400 --> 13:43.280
state that you previously expected it to be, meaning there have some telescopes of captured

13:43.280 --> 13:49.200
images and within those images, individual stars are identified and some brightness value

13:49.200 --> 13:54.880
is calculated and kind of logged off into some time series data set or is there something

13:54.880 --> 13:56.440
else happening to produce that data?

13:56.440 --> 13:58.000
Do you have a sense for that?

13:58.000 --> 13:59.880
Yes, no, you're exactly right.

13:59.880 --> 14:08.560
So what happens is this data set has actually been pre-processed by a team at NASA.

14:08.560 --> 14:14.760
So the data originally comes from the Kepler Space Telescope which was in operation for

14:14.760 --> 14:22.640
the main part of its mission for eight years, beginning in 2009, I believe.

14:22.640 --> 14:29.280
Yeah, the main part of its mission was in operation for eight years, beginning in 2009, but there

14:29.280 --> 14:33.000
was looking at this specific section of the sky that we've been searching for the first

14:33.000 --> 14:34.720
four years.

14:34.720 --> 14:41.440
So there's this four-year data set from the Kepler Telescope and a team at NASA has already

14:41.440 --> 14:51.640
taken that data, has localized the stars in that data and converted that data into these

14:51.640 --> 14:56.720
time series and has actually posted that for free on the internet.

14:56.720 --> 14:59.360
You can actually download it.

14:59.360 --> 15:05.560
It takes up several terabytes and in fact, it takes several weeks to download because

15:05.560 --> 15:07.960
you don't get great download speeds.

15:07.960 --> 15:09.520
Even if you're on Google LAN?

15:09.520 --> 15:16.840
Yeah, even if you're on Google LAN, it's millions of files and we literally just had this

15:16.840 --> 15:21.720
big WGet script that would just download all these individual files and it took about

15:21.720 --> 15:24.080
two weeks to download.

15:24.080 --> 15:28.120
But that was going back to your original question here.

15:28.120 --> 15:34.440
That was one of the ways in which we were very lucky in this project.

15:34.440 --> 15:41.560
A lot of the data pre-processing was already taken care of by NASA.

15:41.560 --> 15:49.680
And so not only that, but we were also lucky in that we had a large training set of labelled

15:49.680 --> 15:56.960
examples from astronomers at NASA and at other universities.

15:56.960 --> 16:05.240
So I mentioned that this telescope was launched in 2009, so over eight years ago.

16:05.240 --> 16:13.160
And in that time, a lot of human astronomers have looked at certain patterns in this data

16:13.160 --> 16:20.040
set and have labelled them essentially as being, this is a signal that is a planet and

16:20.040 --> 16:22.680
this other signal is not a planet.

16:22.680 --> 16:25.800
So that was one of the other ways in which we were lucky.

16:25.800 --> 16:28.840
We didn't have to start from scratch with no training set.

16:28.840 --> 16:34.680
We actually had the data and we had a training set there that was already made for us.

16:34.680 --> 16:41.840
And those two reasons are probably key for us being able to make such rapid progress.

16:41.840 --> 16:46.120
And within about six months having all the pieces together and being able to find some

16:46.120 --> 16:48.400
new planet candidates.

16:48.400 --> 16:54.840
So I know that there are many other problems in, for example, astronomy that do have large

16:54.840 --> 17:03.120
amounts of data available, but perhaps that data is not in a form that is easily ingestable

17:03.120 --> 17:10.240
by a machine learning model and also perhaps there is not a training set of labelled examples

17:10.240 --> 17:13.360
that you can use to train a machine learning model.

17:13.360 --> 17:16.840
So I think those considerations are very important.

17:16.840 --> 17:24.800
If somebody is trying to, in their spare time, train a machine learning model to accomplish

17:24.800 --> 17:31.040
any task, the two things you want to ask yourself is, one, does this data exist in a format

17:31.040 --> 17:37.040
that I can, you know, obtain easily and process myself?

17:37.040 --> 17:41.960
And two, is there a training set that I can use to train my model?

17:41.960 --> 17:46.240
And can you tell us a little bit about the model development process?

17:46.240 --> 17:48.160
How did you approach that?

17:48.160 --> 17:49.480
Sure.

17:49.480 --> 17:57.880
So my process when I develop a model is to start simple and then try and build that up

17:57.880 --> 18:01.320
into something more complicated.

18:01.320 --> 18:09.440
And so the simplest thing that I thought I could try with this model was simply a linear

18:09.440 --> 18:17.160
logistic regression model, which is a very common and well understood type of machine learning

18:17.160 --> 18:22.360
model that has been used for decades successfully in a lot of tasks.

18:22.360 --> 18:33.840
And so I had this data from NASA, this time series of brightness values.

18:33.840 --> 18:43.200
And so the first consideration there was how am I going to feed this data into my model

18:43.200 --> 18:46.840
and we can perhaps get into that a little bit more.

18:46.840 --> 18:52.600
But once I had figured that out, I thought, well, let's just try the simplest model I

18:52.600 --> 18:56.240
can possibly think of.

18:56.240 --> 19:01.040
And you know, I think as a general rule of thumb, you know, your simple model should at

19:01.040 --> 19:05.920
least get you part of the way there, perhaps even most of the way there.

19:05.920 --> 19:11.680
And so we were actually able to train this simple model to actually have relatively good

19:11.680 --> 19:18.200
accuracy, the simple model that we ended up training first actually ended up having an

19:18.200 --> 19:21.240
accuracy of about 92%.

19:21.240 --> 19:28.920
And then several months later when we trained our big complicated neural network model,

19:28.920 --> 19:32.040
that model ended up having about 96% accuracy.

19:32.040 --> 19:39.360
So I think the lesson here is that you can certainly start simple and you'll probably

19:39.360 --> 19:44.520
get most of the way there before you start trying these, you know, really complicated

19:44.520 --> 19:45.520
models.

19:45.520 --> 19:51.160
You talked a bit about the data set, but what did the labels look like?

19:51.160 --> 19:57.960
I'm envisioning, I mean, so you've got these, you've got stars and you're trying to

19:57.960 --> 20:06.680
identify whether the stars have planets, are the labels, you know, yes planets, no planets

20:06.680 --> 20:12.200
or they, you know, numbers of planets, because you, part of what you were able to do with

20:12.200 --> 20:21.840
this research is identify new planets in known solar systems, meaning stars that already

20:21.840 --> 20:25.040
had existing planets, right?

20:25.040 --> 20:26.040
Right.

20:26.040 --> 20:27.040
Right.

20:27.040 --> 20:31.800
So I'm imagining the labels have to be more, somewhat more nuance than binary.

20:31.800 --> 20:36.800
Right.

20:36.800 --> 20:42.200
So, yeah, so if we imagine that the data for a single star is a very, very, very long time

20:42.200 --> 20:47.760
series of brightness measurements, actually the individual inputs to the model are not

20:47.760 --> 20:55.480
that entire time series, but their individual events on that time series that some other,

20:55.480 --> 20:59.800
you know, separate computer algorithm, a very basic algorithm that's not machine learning

20:59.800 --> 21:07.680
at all has gone through and has identified certain events on that time series where the brightness

21:07.680 --> 21:09.080
decreases.

21:09.080 --> 21:18.560
So as you said, certain stars can have many events where the brightness decreases, you know,

21:18.560 --> 21:24.680
it may have many planets, but it may also have something called star spots, which is like

21:24.680 --> 21:31.000
a dark spot on the star, and because the star itself is rotating, those dark spots when

21:31.000 --> 21:36.760
that, when the dark spot rotates into the, into the view of the telescope, that's also

21:36.760 --> 21:39.240
going to cause the brightness of the star to decrease.

21:39.240 --> 21:40.240
Right.

21:40.240 --> 21:45.040
So, so there are, there are many different types of events, some of which are astronomical,

21:45.040 --> 21:50.920
some of which are actually instrumental, there can cause the brightness of the star measured

21:50.920 --> 21:54.000
by the telescope to decrease.

21:54.000 --> 21:59.480
And so when we actually, when I'm actually talking about labels, I'm talking about a label

21:59.480 --> 22:05.120
for a particular event on the, on the star where we've actually observed the brightness

22:05.120 --> 22:06.200
decreasing.

22:06.200 --> 22:15.520
So that label is just brightness decreasing, or is it brightness decrease because of a

22:15.520 --> 22:16.520
planet?

22:16.520 --> 22:17.520
Yeah.

22:17.520 --> 22:21.800
So the label is is the, the second option you provided.

22:21.800 --> 22:26.560
So one of the possible labels is brightness decreased because of a planet.

22:26.560 --> 22:32.640
And the other possible labels are brightness decreased because of some astronomical event,

22:32.640 --> 22:34.680
for example, a star spot.

22:34.680 --> 22:42.240
And then the, the third possible label in, in the data set is that the brightness decreased

22:42.240 --> 22:50.040
for some sort of instrumental reason, perhaps there was some noise, instrumental noise,

22:50.040 --> 22:52.800
or, you know, something like that.

22:52.800 --> 22:56.800
And so when we trained the model, so those were really the only three labels in the data

22:56.800 --> 23:00.080
set that, that we were, that we were given that we started with.

23:00.080 --> 23:01.080
Okay.

23:01.080 --> 23:05.840
But when I train, when I train the model, I actually just, I, I binarized this.

23:05.840 --> 23:09.440
So one label was this event is a planet.

23:09.440 --> 23:12.440
And the other event is this event is not a planet.

23:12.440 --> 23:18.400
Can you give me a sense for, you know, how long did you spend kind of start, you know,

23:18.400 --> 23:24.240
familiarizing yourself with the data set and maybe learning a little bit about the background

23:24.240 --> 23:34.560
of the problem and the domain knowledge you might need to, to solve it versus modeling,

23:34.560 --> 23:39.960
versus applying your model to, to unlabeled data.

23:39.960 --> 23:40.960
That kind of thing.

23:40.960 --> 23:41.960
Sure.

23:41.960 --> 23:42.960
Yeah.

23:42.960 --> 23:49.560
And I think that it was about six months before we'd actually train the model and start

23:49.560 --> 23:51.080
a discovering planets.

23:51.080 --> 23:58.480
And certainly I would say that at least four to five of those months were me trying to

23:58.480 --> 24:05.320
understand this data to actually, you know, not only download it, but being able to open

24:05.320 --> 24:12.240
this file format, right, like, what, what, you know, what, what format does a, there's

24:12.240 --> 24:16.960
a, you know, brightness plot of a star come in from NASA.

24:16.960 --> 24:20.840
It ends up coming in a file with a dot FIT S extension.

24:20.840 --> 24:26.240
And so you need to be able to figure out how to open that extension and how to extract

24:26.240 --> 24:31.680
the data that you want and then actually how to pre-process that.

24:31.680 --> 24:40.240
Luckily, I had Andrew, you know, on the other end of the phone who would, who already

24:40.240 --> 24:45.080
had a lot of experience with this, which, which really helped, which really helped me.

24:45.080 --> 24:51.880
But nonetheless, I spent a lot of time just learning how to actually, you know, use this

24:51.880 --> 24:53.560
data and what it meant.

24:53.560 --> 24:56.480
I spent a lot of that time reading papers as well.

24:56.480 --> 25:01.960
There, there have been other people who have applied machine learning to similar problems.

25:01.960 --> 25:09.520
And so I need to understand what they did, you know, I don't want to reinvent the wheel.

25:09.520 --> 25:16.840
You know, I can try and learn from their mistakes and also the things they did that worked well.

25:16.840 --> 25:22.600
And so, you know, once it actually got to coding the model and training the model and testing

25:22.600 --> 25:27.880
the model, that was really only probably one of one out of the first six months.

25:27.880 --> 25:28.880
Wow.

25:28.880 --> 25:29.880
Wow.

25:29.880 --> 25:35.160
What were some of those things that you learn from other attempts that you applied to your

25:35.160 --> 25:37.280
own modeling process?

25:37.280 --> 25:45.160
Sure, yeah, so there are, there are several, there are several steps that are fairly

25:45.160 --> 25:52.080
standard in astronomy for processing these brightness time series.

25:52.080 --> 25:54.640
The brightness time series are typically called light curves.

25:54.640 --> 25:57.840
So I'll just start using the word light curves for them now.

25:57.840 --> 26:03.840
So the first thing you actually need to do with the light curve is actually, you need to flatten

26:03.840 --> 26:07.040
away what's called the stellar variability.

26:07.040 --> 26:12.920
So it turns out that the variability or the light from a star is not actually going to

26:12.920 --> 26:15.560
be constant over time.

26:15.560 --> 26:20.960
For various reasons, the brightness that you'll measure from a star is actually changing

26:20.960 --> 26:23.200
over time quite naturally.

26:23.200 --> 26:27.240
Meaning independent of an event, the star is getting further or whatever?

26:27.240 --> 26:33.280
Well, yeah, there's so there's several reasons, the star, the star is itself rotating.

26:33.280 --> 26:38.600
So different, perhaps different areas of the star's surface are brighter than other areas.

26:38.600 --> 26:47.000
And so when the star rotates, the brightness that you see actually actually changes.

26:47.000 --> 26:53.240
Also there's instrumental effects here that can also cause the sort of the baseline brightness

26:53.240 --> 26:55.200
to kind of drift over time.

26:55.200 --> 27:01.760
That's actually characteristic of the instrument on the Kepler telescope.

27:01.760 --> 27:08.200
So you need to fit away this kind of variability that you see in the brightness of the star.

27:08.200 --> 27:13.360
But you want to do this in such a way that you don't actually, you know, fit away the

27:13.360 --> 27:18.280
events that we're trying to classify, which is when the brightness decreases kind of more

27:18.280 --> 27:20.280
sharply.

27:20.280 --> 27:21.280
Okay.

27:21.280 --> 27:23.280
And suddenly.

27:23.280 --> 27:25.200
So there are various techniques to do that.

27:25.200 --> 27:33.520
And so we were able to use some of those techniques in order to sort of normalize the brightness

27:33.520 --> 27:40.400
of the star so that outside these events we're looking at, the brightness was totally flat.

27:40.400 --> 27:45.400
So that was certainly one of the key starting points for us.

27:45.400 --> 27:51.360
Were these other techniques machine learning types of techniques or more, you know, simpler

27:51.360 --> 27:55.160
data massaging types of approaches?

27:55.160 --> 27:56.160
Right.

27:56.160 --> 28:05.480
So the current, I guess state-of-the-art system for classifying these events as being

28:05.480 --> 28:13.160
planets or not planets is actually, it's called the RoboVetto, it was developed at NASA.

28:13.160 --> 28:18.960
And this is actually mainly not a machine learning technique.

28:18.960 --> 28:24.800
There is one component inside this RoboVetto that uses a machine learning technique.

28:24.800 --> 28:30.880
But for the most part, it's actually a decision tree that has been sort of crafted and honed

28:30.880 --> 28:32.440
by humans.

28:32.440 --> 28:41.200
So this piece of software, which was developed over a few years, actually runs hundreds

28:41.200 --> 28:44.280
of different heuristics on these events.

28:44.280 --> 28:50.360
And it has all these different thresholds and branches to determine whether this event

28:50.360 --> 28:53.360
should be classified as a planet or not.

28:53.360 --> 28:59.480
So that's the main technique that is actually used at the moment.

28:59.480 --> 29:06.840
There have been some other techniques that took on the problem that we were focused on.

29:06.840 --> 29:10.680
One of those used a random forest model.

29:10.680 --> 29:16.000
And another one used a sort of unsupervised clustering type model.

29:16.000 --> 29:24.120
And so we were sort of one of the first to decide to use neural networks for this problem.

29:24.120 --> 29:29.760
Coming back to the thinking about your labeled data, which you mentioned, you kind of

29:29.760 --> 29:39.480
binarized, you turned into, is this event on the light curve due to an orbiting planet

29:39.480 --> 29:41.880
or not?

29:41.880 --> 29:52.360
How do you get from that to being able to detect new orbiting planets on a known star that

29:52.360 --> 29:56.480
has, on a star that already has known orbiting planets?

29:56.480 --> 30:06.160
Or was that a consequence not necessarily related or produced by your algorithm?

30:06.160 --> 30:07.160
Sure.

30:07.160 --> 30:12.680
So I think I mentioned that these events that we detect on the light curve where the brightness

30:12.680 --> 30:19.560
dips are actually produced by a completely separate algorithm.

30:19.560 --> 30:27.920
And traditionally, what would happen was that, well, the astronomers would run some algorithm

30:27.920 --> 30:38.760
and would take a whole large set of these events that were detected and manually examine

30:38.760 --> 30:42.760
each of them by eye and decide which of those were caused by planets and which of those

30:42.760 --> 30:46.600
were caused by various other events.

30:46.600 --> 30:53.920
And so because this process was, you know, the time required was really dominated by the

30:53.920 --> 31:00.400
fact that the humans had to go in and examine these things, it wasn't possible to examine

31:00.400 --> 31:03.080
every possible signal.

31:03.080 --> 31:11.360
So what they did was they set some threshold and said, okay, we're only going to examine

31:11.360 --> 31:17.960
events detected above some certain signal to noise thresholds.

31:17.960 --> 31:23.760
And so now even with the signal to noise threshold, they still actually had to go through

31:23.760 --> 31:29.960
and examine over 30,000 events from the four-year capital emission.

31:29.960 --> 31:36.200
So it wasn't like they chose a really, really aggressive threshold.

31:36.200 --> 31:43.000
But the possibility still remained that if the threshold was lowered just a little bit

31:43.000 --> 31:50.600
and some of these, you know, lower signal to noise events, you know, could be considered

31:50.600 --> 31:55.800
that there may be some planets that were missed by the previous searches.

31:55.800 --> 31:58.840
And so that's what we looked at in this project.

31:58.840 --> 32:06.920
We took our train model and we used that model to go and look at these events that had not

32:06.920 --> 32:13.320
previously been classified because the signal to noise was below the traditional thresholds.

32:13.320 --> 32:18.920
And so that was how we were able to discover new planets around stars that had already

32:18.920 --> 32:21.920
been searched, you know, multiple times before.

32:21.920 --> 32:29.520
Did you run the algorithm against kind of all of the remaining data and thus you have,

32:29.520 --> 32:35.720
you know, we collectively now have a fairly high confidence that we found all of the possible

32:35.720 --> 32:44.160
exoplanets or was, you know, because of the data volume or whatever, you know, you also

32:44.160 --> 32:50.280
had some threshold or some slice of the data and there's still an opportunity to apply

32:50.280 --> 32:51.880
them or broadly.

32:51.880 --> 32:58.160
So out of the 200,000 stars in this data set, we've actually only run our model over 600

32:58.160 --> 32:59.160
meters.

32:59.160 --> 33:00.160
Wow.

33:00.160 --> 33:01.160
Okay.

33:01.160 --> 33:11.200
So we chose, we chose those 670 because those stars have already had already had multiple

33:11.200 --> 33:14.080
orbiting planets discovered around them.

33:14.080 --> 33:21.320
And it's a lot more likely that you're going to discover more planets around stars that

33:21.320 --> 33:27.080
we've already discovered planets around than if you just chose some random star.

33:27.080 --> 33:32.080
So we really chose these 670 because we just wanted to, you know, have the quickest test

33:32.080 --> 33:34.280
of our model possible.

33:34.280 --> 33:40.520
And so we restricted ourselves to this tiny sample and actually, you know, discovered

33:40.520 --> 33:45.600
two new planets and we were very excited about this and, you know, we decided to stop and

33:45.600 --> 33:46.600
write our paper.

33:46.600 --> 33:53.520
But certainly what we're currently doing right now is working on ramping up our current

33:53.520 --> 33:56.960
pipeline to actually search all 200,000 stars.

33:56.960 --> 34:00.960
And, you know, who knows what we're going to find when we do that.

34:00.960 --> 34:07.400
Talk a little bit about the process and approach you took once you switch gears from the more

34:07.400 --> 34:09.880
traditional approach to applying a neural net.

34:09.880 --> 34:13.520
I think you said you were using a logistic regression originally?

34:13.520 --> 34:14.520
Right.

34:14.520 --> 34:15.520
That's right.

34:15.520 --> 34:16.520
Yes.

34:16.520 --> 34:22.440
So the logistic regression model really just took in, say, one of these light curves, one

34:22.440 --> 34:27.960
of these time series and simply use those as features.

34:27.960 --> 34:34.880
Each independent point on the light curve was an independent feature to the model.

34:34.880 --> 34:42.440
And so the model could learn, for example, if this particular pixel, we fed our model,

34:42.440 --> 34:48.440
we fed the events into the model such that, you know, we'd normalized where we thought

34:48.440 --> 34:56.160
the light, the light was decreasing, we actually sort of like centered the event in the input.

34:56.160 --> 34:59.920
So the model knew where the event was supposed to be.

34:59.920 --> 35:05.760
And so the model could learn things like if this particular pixel has a brightness below

35:05.760 --> 35:12.720
average, you know, that might contribute to a classification of, you know, it being a

35:12.720 --> 35:18.280
planet, or it not being a planet, but essentially in the logistic regression model, each of those

35:18.280 --> 35:25.760
individual pixels was going to be considered independently of all the other pixels, essentially

35:25.760 --> 35:33.200
they were all going to be used as independent indicators of whether this time series,

35:33.200 --> 35:35.000
this light curve was a planet model.

35:35.000 --> 35:45.000
So your input vector to the logistic regression model was a vector of kind of the four years

35:45.000 --> 35:52.240
worth of these brightness values for a particular pixel at whatever time increment, they were

35:52.240 --> 35:53.880
captured at.

35:53.880 --> 36:00.160
So we didn't actually feed in all four years of data in one very, very long vector.

36:00.160 --> 36:06.080
What we did was we actually fed in just one of the events basically that we were looking

36:06.080 --> 36:07.080
at.

36:07.080 --> 36:14.040
So we, we really kind of like zoomed in on the light curve of the particular event that

36:14.040 --> 36:18.680
we wanted to know the classification for.

36:18.680 --> 36:27.320
So our, the dimensionality of our input vector was something like like 1000, 1000 time series

36:27.320 --> 36:30.920
points as opposed to all the time series points over four years.

36:30.920 --> 36:37.000
And did you presumably, like you, you knew where the event was so you bracket it around

36:37.000 --> 36:38.000
it?

36:38.000 --> 36:39.000
Exactly.

36:39.000 --> 36:44.400
We made sure that in our input, the event that we were considering was, was centered.

36:44.400 --> 36:45.400
Got it.

36:45.400 --> 36:46.400
Okay.

36:46.400 --> 36:53.160
So moving from sort of the, the simple model, the logistic regression model, you know,

36:53.160 --> 37:01.920
so, so one, one parallel we, we noticed with this problem was is, is to the problem of

37:01.920 --> 37:05.200
classifying objects and images.

37:05.200 --> 37:10.640
So with an image, your input is actually a two dimensional grid.

37:10.640 --> 37:14.920
But what you're doing is looking for, essentially looking for local patterns within that grid,

37:14.920 --> 37:24.520
you know, local groups of pixels will together form, you know, edges and shapes and images.

37:24.520 --> 37:29.440
And so what we had, we had it, a one dimensional grid or a vector.

37:29.440 --> 37:34.280
But we were also looking for local patterns, you know, in the grid.

37:34.280 --> 37:40.480
We were looking for shapes in which the light would gradually decrease as the planet sort

37:40.480 --> 37:46.680
of passes in front of the star and then gradually increase again, sort of like a U shape.

37:46.680 --> 37:54.080
And so with that parallel to image classification, we decided to use a convolutional neural network,

37:54.080 --> 37:59.480
which has been very successful for image classification in the past.

37:59.480 --> 38:03.840
And the, the only real difference here is that our inputs are one dimensional, rather

38:03.840 --> 38:11.480
than two or three dimensional. And so we, we used one-day convolutions and, and other

38:11.480 --> 38:17.520
than that, our model is very similar to sort of a classic convolutional neural network.

38:17.520 --> 38:23.560
And did you start with a, did you build it up from kind of scratch, or did you start

38:23.560 --> 38:29.320
with a, a deep kind of existing, deep network architecture?

38:29.320 --> 38:37.960
No, it's, it's actually a pretty simple classic architecture that I built up from scratch.

38:37.960 --> 38:46.040
So essentially, it's just convolutional layers, followed by max pooling layers for say 10

38:46.040 --> 38:51.360
or 12, 12 layers deep. I don't remember exactly how many layers we used, followed by some

38:51.360 --> 38:57.680
fully connected layers, followed by the output, which is the probability that this particular

38:57.680 --> 38:58.680
input is applied.

38:58.680 --> 39:04.640
And did the model evolve much at all as you began working with the data, or did that initial

39:04.640 --> 39:10.960
model that you, that you kind of settled on kind of hold throughout the project?

39:10.960 --> 39:16.560
Probably the, the biggest change that we made over the project was actually to feed in

39:16.560 --> 39:22.000
two separate representations of the light curve that we were looking at, of the event.

39:22.000 --> 39:25.560
I should say the event in the light curve that we were looking at.

39:25.560 --> 39:29.800
So this one of these was a, was a wide view of the event.

39:29.800 --> 39:35.000
And the other view was a, a very zoomed in narrow view of the event.

39:35.000 --> 39:43.440
And so what we, what we learned was that the model sometimes needed some information that

39:43.440 --> 39:51.640
was very, very far away from the, the event we were looking at in order to make its classification

39:51.640 --> 39:53.320
decision.

39:53.320 --> 40:00.080
And so that, that was sort of facilitated by feeding in a very, a wide view of the

40:00.080 --> 40:01.920
light curve.

40:01.920 --> 40:08.920
But also the model needs a fairly fine grained look at the, the shape of the light curve

40:08.920 --> 40:11.160
is, of the event as well.

40:11.160 --> 40:16.080
Sorry, as I mentioned, we were looking for U shaped patterns, but there are various,

40:16.080 --> 40:20.760
other astronomical events that can cause, for example, a V shaped pattern.

40:20.760 --> 40:26.560
And so what we did was we, we ultimately ended up feeding in two separate representations

40:26.560 --> 40:29.080
of the event into the model.

40:29.080 --> 40:35.720
And so each representation is treated by sort of individual, convolutional layers that

40:35.720 --> 40:36.720
are totally separate.

40:36.720 --> 40:42.360
And then they're, they're joined up towards the, the end and combined together to, to give

40:42.360 --> 40:44.360
the final output prediction.

40:44.360 --> 40:45.360
Okay.

40:45.360 --> 40:50.120
And maybe tell us a little bit about like how the time has been allocated like since

40:50.120 --> 40:55.120
that six month mark when you started applying the neural network.

40:55.120 --> 40:56.120
Right.

40:56.120 --> 41:02.920
So we spent a lot of time last year writing the paper.

41:02.920 --> 41:12.560
So some of the things that we, we did for that was come up with various ways to visualize

41:12.560 --> 41:15.760
the sort of things that the model had learned.

41:15.760 --> 41:22.560
You know, especially as this paper was going to be published in an astronomy journal rather

41:22.560 --> 41:28.800
than a machine learning journal, where people are perhaps not quite as familiar as, as,

41:28.800 --> 41:33.040
you know, the machine learning community in what exactly a convolutional neural network

41:33.040 --> 41:35.720
is and what it's doing.

41:35.720 --> 41:42.520
So we used some techniques, for example, to visualize the features of the input that

41:42.520 --> 41:45.720
the model had learned.

41:45.720 --> 41:50.360
And that was also a good sanity check for us to make sure the model was, was sort of

41:50.360 --> 41:55.920
looking at the right features in order to make its decision.

41:55.920 --> 42:03.120
So the, the technique we applied there, which is, which is quite a simple one is if, if

42:03.120 --> 42:08.720
you block out part of the input and then fear the input into the model and then you look

42:08.720 --> 42:13.520
at the model's prediction, if the, if the part of the input that you blocked out was really

42:13.520 --> 42:18.960
important for the model's decision, then, then the decision is going to change a lot.

42:18.960 --> 42:24.160
But if you block out sort of an unimportant region of the input, then the model's decision

42:24.160 --> 42:28.920
is, is not going to change, you know, at all perhaps.

42:28.920 --> 42:34.560
And what we found, and what we found was, was when we blocked out the regions that were,

42:34.560 --> 42:39.960
that, that, you know, certainly we thought, indicated that a planet had passed in front

42:39.960 --> 42:45.960
of the star, the model's prediction changed from predicting this was a planet to predicting

42:45.960 --> 42:48.920
it wasn't a planet, which was exactly what we had hoped.

42:48.920 --> 42:54.880
It means that we, we weren't sort of fitting to other aspects of the, of the like curve.

42:54.880 --> 43:00.760
We were really fitting our model was learning the features that we, we expected.

43:00.760 --> 43:06.160
So we spent, we spent quite a bit of time really digging into the model and, and producing

43:06.160 --> 43:13.160
sort of visualizations and explanations of its, of its predictions to, to put in the

43:13.160 --> 43:14.160
paper.

43:14.160 --> 43:15.160
Awesome.

43:15.160 --> 43:20.160
And you're going to be publishing some additional information about that this week is

43:20.160 --> 43:24.160
that to remember correctly, you're going to be publishing some of the code that you

43:24.160 --> 43:25.160
used as well.

43:25.160 --> 43:26.360
Yeah, that's right.

43:26.360 --> 43:32.480
So we published our paper this January, which outlines everything that we did.

43:32.480 --> 43:40.640
But this week, we're actually releasing all of the code that we used to train our model,

43:40.640 --> 43:44.720
which also includes actually the, you know, all the code you need to download the data

43:44.720 --> 43:51.360
from NASA's servers to process the data in the exact way that we did in the paper.

43:51.360 --> 43:56.720
I mentioned like fitting away the, the low frequency variability in the stars brightness,

43:56.720 --> 43:59.360
that's included as well.

43:59.360 --> 44:05.120
You know, all of this, the specifications for our model are included and the hyper parameters

44:05.120 --> 44:07.600
that we use to train the model.

44:07.600 --> 44:13.320
And so anyone will be able to download this data, we'll be able to, to train a model.

44:13.320 --> 44:18.600
And, you know, potentially they'll be able to use this to go searching.

44:18.600 --> 44:19.600
That's awesome.

44:19.600 --> 44:23.600
I hope being, if anything, to see out of this.

44:23.600 --> 44:25.440
Well, a few things.

44:25.440 --> 44:32.520
I'm hoping that some people are able to, perhaps, build on the work that we did.

44:32.520 --> 44:40.680
So as I mentioned, our project has been focused on data from NASA's Kepler telescope, which

44:40.680 --> 44:43.120
has been in operation for eight years now.

44:43.120 --> 44:49.600
But there's another telescope launching this year, or it's at least scheduled to launch

44:49.600 --> 44:55.920
this year by NASA, which is called the, the test, T-E-WS satellite.

44:55.920 --> 45:03.640
And that is going to use sort of a very similar approach to the Kepler satellite for recording

45:03.640 --> 45:09.440
this brightness data for many, many, many more stars even than Kepler did.

45:09.440 --> 45:15.960
And so I'm hoping that, you know, others in the astronomy community will perhaps build

45:15.960 --> 45:23.240
on this, this, this code that I'm releasing, and perhaps even apply it to, to other missions

45:23.240 --> 45:30.240
and, and use it to, to discover planets in, in data collected by the tests.

45:30.240 --> 45:31.240
That's awesome.

45:31.240 --> 45:32.240
Awesome.

45:32.240 --> 45:36.160
Well, that, that is some really amazing work.

45:36.160 --> 45:40.320
I appreciate you taking the time to share it with us.

45:40.320 --> 45:41.320
Great.

45:41.320 --> 45:42.320
Yeah.

45:42.320 --> 45:44.560
Thanks a lot for having me on.

45:44.560 --> 45:47.800
All right, everyone, that's our show for today.

45:47.800 --> 45:53.160
For more information on Chris, or any of the topics covered in this episode, you'll find

45:53.160 --> 45:59.280
the show notes at twimmaleye.com slash talk slash 117.

45:59.280 --> 46:04.000
If you have any questions for Chris, please post them there, and we'll make sure to bring

46:04.000 --> 46:06.440
them to his attention.

46:06.440 --> 46:11.000
If you're new to the pod and like what you hear, or you're a veteran listener and haven't

46:11.000 --> 46:16.560
already done so, head on over to your favorite podcast app and leave us your most gracious

46:16.560 --> 46:18.400
review and rating.

46:18.400 --> 46:22.160
It helps new listeners find us, which helps us grow.

46:22.160 --> 46:23.680
Thanks in advance.

46:23.680 --> 46:35.760
And of course, thanks so much for listening, and catch you next time.

