1
00:00:00,000 --> 00:00:15,280
Welcome to the Tumel AI Podcast. I'm your host, Sam Charrington.

2
00:00:21,440 --> 00:00:27,760
All right, everyone. I am on the line with Elias Diaco Nicolos. Elias is on the faculty

3
00:00:27,760 --> 00:00:33,680
at the University of Wisconsin-Madison. Elias, welcome to the Tumel AI Podcast.

4
00:00:33,680 --> 00:00:39,680
Great to be here, Sam. I'm really looking forward to diving into our discussion. Before we do,

5
00:00:40,400 --> 00:00:46,320
I'd love to hear a little bit about your background. Your primary research interests are

6
00:00:46,320 --> 00:00:54,160
in algorithms and machine learning. And if the paper that we're going to discuss this time around,

7
00:00:54,160 --> 00:01:00,000
distribution independent pack learning of half spaces with Moss Art Noise, which one

8
00:01:00,000 --> 00:01:05,600
the Outstanding Paper Award at NURBS. If it's any indication, your work is quite theoretical

9
00:01:05,600 --> 00:01:11,440
in nature. Tell us a little about your background and how you came to working on this type of work.

10
00:01:11,440 --> 00:01:18,160
All right, so I grew up in Greece, and this is what I did in my undergrad. I moved to Columbia

11
00:01:18,160 --> 00:01:24,800
University for grad school. My grad school was in a topic called the theoretical computer science,

12
00:01:24,800 --> 00:01:30,400
so I'm an algorithms person. And somehow in the process, I realized that the best way to have

13
00:01:30,400 --> 00:01:37,120
an impact in the world if you're doing theoretical algorithmic research is to actually work on algorithm

14
00:01:37,120 --> 00:01:42,960
questions that come from machine learning and statistics. Why is that? Why is that the best place?

15
00:01:43,520 --> 00:01:46,960
I mean, maybe, yeah, maybe the phrasing is not accurate. I think it's really a good place because

16
00:01:46,960 --> 00:01:52,880
this is a setting where I think our listeners would all agree, but I'm curious your thought.

17
00:01:52,880 --> 00:02:00,000
So I actually started doing this before it was popular, because I could really see that maybe not

18
00:02:00,000 --> 00:02:05,520
all of the theoretical algorithm that one develops, but maybe some of them could be used in practice

19
00:02:05,520 --> 00:02:14,480
and you could see the practical improvements in data analysis tasks. So in particular, I used to

20
00:02:14,480 --> 00:02:20,960
like doing theoretical algorithmic research just for the sake of doing it, but sort of later,

21
00:02:20,960 --> 00:02:27,120
like after my finish at my PhD, I started gravitating towards theoretical questions that if solved,

22
00:02:27,120 --> 00:02:34,880
would actually have a practical impact. Describe for us broadly your research interests and focus,

23
00:02:34,880 --> 00:02:38,960
so that we have a little bit of the context out of which this paper comes.

24
00:02:38,960 --> 00:02:43,840
So I mean, I have broad interests within algorithms and machine learning. So this particular

25
00:02:43,840 --> 00:02:50,720
narrative paper belongs at the high level in an area which is called the high-dimensional robust

26
00:02:50,720 --> 00:02:59,360
learning. The idea here is that historically, every machine learning algorithm needs to make

27
00:02:59,360 --> 00:03:05,360
some assumptions. Assumptions about the model where the data comes from. So in some sense,

28
00:03:05,360 --> 00:03:13,600
very roughly speaking, every algorithm could be viewed as a data fitting method. You're trying

29
00:03:13,600 --> 00:03:20,560
to fit the data to a model. Now, the issue is that this assumption about the data coming from

30
00:03:20,560 --> 00:03:26,960
a model of a given type is very crucial. So and typically, you do not want your algorithm

31
00:03:26,960 --> 00:03:32,320
to overfeed to this assumption. In the sense that if this assumption is not exactly true,

32
00:03:32,320 --> 00:03:37,680
but if it's approximately true, you want your algorithm to still work. And unfortunately,

33
00:03:37,680 --> 00:03:43,280
in high-dimensional settings, we realized about five years ago that this is actually not the case.

34
00:03:43,920 --> 00:03:50,720
Even a very tiny deviation from the assume model could make the machine learning algorithm

35
00:03:50,720 --> 00:03:55,920
very, very fragile. So we started and decided that, okay, we need to rectify this and develop

36
00:03:55,920 --> 00:04:01,120
methodology to have robust learning algorithms for high-dimensional problems. And so when you talk

37
00:04:01,120 --> 00:04:10,640
about high-dimensional problems and perturbations, are you thinking about things like the adversarial

38
00:04:10,640 --> 00:04:15,840
examples, types of problems that we are familiar with, where you've got an image,

39
00:04:15,840 --> 00:04:23,600
high-dimensional, and you apply some noise to it? So that's a great question. I was expecting

40
00:04:23,600 --> 00:04:29,120
this question exactly to draw a difference. So these types of adversarial examples,

41
00:04:29,120 --> 00:04:34,000
they're also some type of robustness, they're quite some type of robustness, but it's somewhat

42
00:04:34,000 --> 00:04:39,680
different than the one I'd like to discuss. In particular, in the sort of adversarial robust

43
00:04:39,680 --> 00:04:44,000
setting, what you have is that you train a bunch, so you train your neural network on some images.

44
00:04:45,440 --> 00:04:50,960
And then you perturb those images in a way that's imperceptible to humans and see how the

45
00:04:51,680 --> 00:04:56,000
how the model you learned performs. We have learned that it's actually non-robust and we need to do

46
00:04:56,000 --> 00:05:02,480
something to make it robust. So the perturbations in the adversarial robust setting take place

47
00:05:02,480 --> 00:05:08,080
at test time. So you train with a bunch of clean data and then you want to test on a set of

48
00:05:08,080 --> 00:05:14,640
corrupted data. So the setting of robustness that I care about, at least with respect to this line

49
00:05:14,640 --> 00:05:20,400
of work, is something that's called test time attacks, where you actually train on corrupted data.

50
00:05:20,400 --> 00:05:27,920
So these two are related, so these two notions of robustness are related, but they're also quite

51
00:05:27,920 --> 00:05:34,400
a bit different. And you said they're called test time attacks, but the data is perturbed in

52
00:05:34,400 --> 00:05:41,920
training. So the side examples are called test time attacks. What I'm going to talk about is

53
00:05:41,920 --> 00:05:48,320
called training time attacks. Got it. Okay. So let me give you an example. Like the most basic

54
00:05:48,320 --> 00:05:53,920
example that I expect anyone could could understand with just a little bit of background. So if I give

55
00:05:53,920 --> 00:06:02,080
you samples like IID samples from a probability distribution, like a Gaussian, and I ask you to find

56
00:06:02,080 --> 00:06:09,760
the expectation, the mean value of the distribution where the samples come from. Let's say in one

57
00:06:09,760 --> 00:06:17,360
dimension, then what would you do? To find the mean value. Yeah. You'd sum them and divide by the

58
00:06:17,360 --> 00:06:23,440
number of samples you have. Yeah, that's fantastic. That's called sort of empirical mean. And we know

59
00:06:23,440 --> 00:06:29,360
that it works, right? Unfortunately, though, if one of the samples that I give you is not drawn

60
00:06:29,360 --> 00:06:34,960
from the distribution that you assumed it was, it's an outlier, then the average doesn't work anymore.

61
00:06:35,920 --> 00:06:39,760
Because the average could be arbitrarily far from the true mean. It's not going to convert

62
00:06:39,760 --> 00:06:44,880
to the true mean. If anything, you take infinitely many samples. So what do we do in this case?

63
00:06:44,880 --> 00:06:49,600
So for the one-dimensional setting, the solution is known for like, I don't know, a centurion

64
00:06:49,600 --> 00:06:54,000
statistics. So instead of taking the average, you're taking something which is called the median.

65
00:06:55,200 --> 00:07:01,040
Okay, so we know that the median is robust to outliers, and it's optimally robust for one-dimensional

66
00:07:01,040 --> 00:07:07,440
problems, right? Now imagine a generalization of this problem to hide dimensions. So now instead of

67
00:07:07,440 --> 00:07:13,680
observing one-dimensional points, you're observing high-dimensional points. Every observation that you

68
00:07:13,680 --> 00:07:18,080
have is a high-dimensional vector, let's say in a million dimensions. And you want to do the same

69
00:07:18,080 --> 00:07:23,280
thing. You want to actually compute the expected value of the corresponding distribution.

70
00:07:24,000 --> 00:07:29,760
Now in the case of clean data, you would do exactly the same thing that you did in the one-dimensional

71
00:07:29,760 --> 00:07:34,960
case. You would sum all the samples and divide by the number of the samples. So this is the empirical

72
00:07:34,960 --> 00:07:40,960
meaning high dimensions. And in the case of clean data, it works. Now the difficulty is actually

73
00:07:40,960 --> 00:07:48,240
generalizing this high-dimensional empirical mean when you actually have, let's say, 10% of your

74
00:07:48,240 --> 00:07:53,280
of your samples being arbitrary outliers. In this case, unfortunately, there's not such an easy

75
00:07:53,280 --> 00:08:00,480
solution as taking the median. Meaning because the median and a high-dimensional scenario isn't well

76
00:08:00,480 --> 00:08:07,040
defined or because of the number of outliers you have. That's, these are great questions. So

77
00:08:07,040 --> 00:08:13,760
there are many ways to define a notion of a median and high dimensions. For example, one thing that

78
00:08:13,760 --> 00:08:20,000
you could do is look at every coordinate individually and calculating the median of every coordinate and

79
00:08:20,000 --> 00:08:25,440
giving that answer. Unfortunately, this is not going to work. The reason is they're going to work

80
00:08:25,440 --> 00:08:30,480
is because you have many dimensions and in some sense the noise can accumulate across the

81
00:08:30,480 --> 00:08:36,240
dimensions. So if you have, let's say, even a 1% of outliers, then the error you're going to get

82
00:08:36,240 --> 00:08:42,240
at the end is going to be very large in the worst case. It would actually depend on, it would actually

83
00:08:42,240 --> 00:08:48,160
scale with the number of dimensions. And this is something that you can avoid. We know that you can

84
00:08:48,160 --> 00:08:53,760
avoid that if you look at like information theoretic bounds, but we didn't know how to avoid it with

85
00:08:53,760 --> 00:08:59,360
a computationally efficient algorithm with a method that you can actually run. So what we did

86
00:08:59,360 --> 00:09:05,200
four years ago with a number of great authors is we developed the first methods that is actually

87
00:09:05,200 --> 00:09:11,200
robust for estimating the mean of a high dimension distribution to a constant number of outliers.

88
00:09:11,200 --> 00:09:16,880
So even if you have, let's say, 20% of outliers and no matter how high the dimension is,

89
00:09:16,880 --> 00:09:22,160
the algorithm runs efficiently and gives you an accurate approximation of the mean.

90
00:09:22,720 --> 00:09:27,920
What's the general flavor or shape of this algorithm? I see. So there are many versions.

91
00:09:27,920 --> 00:09:38,000
Maybe the easiest one is about detecting and removing the consequential outliers.

92
00:09:38,880 --> 00:09:44,720
So we are in a high dimensional setting. So the most sort of naive thing to try to do is detect

93
00:09:44,720 --> 00:09:53,440
the outliers and remove them. And after you do that, then you just output the mean of the rest.

94
00:09:53,440 --> 00:09:58,880
It will be the ideal methodology to solve the problem. The issue is that this is impossible.

95
00:09:59,440 --> 00:10:04,880
We can prove that it is impossible to actually detect the outliers in high dimension setting.

96
00:10:05,440 --> 00:10:11,600
So what do we do? So the next thing to try to is, okay, maybe I cannot detect and remove all the

97
00:10:11,600 --> 00:10:18,640
outliers. Maybe I can detect and remove the ones that if I kept in the data sets, then they

98
00:10:18,640 --> 00:10:23,760
would actually skew the appear can mean by a lot. And it turns out that this is something that you

99
00:10:23,760 --> 00:10:29,200
can do by using spectral memory. So I guess I do not have like a picture to show you, but the idea

100
00:10:29,200 --> 00:10:35,200
is this that let's say you have your data set is some kind of clouds in high dimension. You might

101
00:10:35,200 --> 00:10:40,640
get like a sphere, right? Even outliers very far from that sphere, then you can eyeball it.

102
00:10:41,200 --> 00:10:46,800
You can eyeball it and you can remove it. These are outliers that are very easy to remove.

103
00:10:46,800 --> 00:10:52,720
Unfortunately, in high dimensional settings, these are not the outliers that can kill you.

104
00:10:52,720 --> 00:10:57,280
These are not the only outliers that can kill you. They can be outliers that are within

105
00:10:57,280 --> 00:11:02,480
the initial cloud of points. Each one of them individually looks like a fine point.

106
00:11:02,480 --> 00:11:09,200
You cannot say that this on its own is an outlier, but somehow the outliers have the ability

107
00:11:09,200 --> 00:11:16,320
to collude with each other to skew your estimates. So what you need to do is somehow

108
00:11:16,320 --> 00:11:23,600
detect outliers in a high dimensional setting in a more global scale. So it's like a local versus

109
00:11:23,600 --> 00:11:27,120
global type of phenomenon that appears here. And this is because of the high dimensional setting.

110
00:11:28,080 --> 00:11:35,840
Now does your problem presume single prior distribution? I'm thinking about the one-dimensional

111
00:11:35,840 --> 00:11:44,960
example where as opposed to trying to identify and discard outliers, you might have multiple prior

112
00:11:44,960 --> 00:11:51,760
distributions and you're trying to determine which of your samples belongs to which distribution

113
00:11:51,760 --> 00:11:56,240
as a way to formulate the problem. Right, right. So the formulation that we're using this

114
00:11:56,240 --> 00:12:01,280
setting is a frequentist formulation. It is not the Bayesian formulation. So there is not

115
00:12:01,280 --> 00:12:06,320
something as a prior. So what we really assume is that we have a family of distributions,

116
00:12:06,320 --> 00:12:11,840
let's say a family of models, where we assume the clean data comes from. Let's say for example,

117
00:12:11,840 --> 00:12:17,200
the clean data could come from a mixture of high dimensional gougins. So that's an assumption.

118
00:12:18,000 --> 00:12:22,640
Okay, so you do assume a mixture of gougins as opposed to a single gougin.

119
00:12:22,640 --> 00:12:28,240
Yeah, we can do that. And in fact, there are many different assumptions that we can handle algorithmically.

120
00:12:28,240 --> 00:12:34,560
These are related, I mean, this is a technical problem. So these are related to the rate of increase

121
00:12:34,560 --> 00:12:39,600
of the moments of the distribution of the good error. So if the moments of the good distribution

122
00:12:39,600 --> 00:12:44,960
behave well in the technical, in the technical sense, we can actually solve the problem.

123
00:12:45,760 --> 00:12:50,560
But what I want to emphasize is that some types of assumptions of this form are actually necessary.

124
00:12:51,360 --> 00:12:56,640
In the sense that if you make no assumptions about your good data in this unsupervised learning,

125
00:12:56,640 --> 00:13:01,440
where you have unlabeled data, the problem is not solvable even information theoretically,

126
00:13:01,440 --> 00:13:07,040
even like with infinitely many samples. And the reason is that the outliers, they have the ability

127
00:13:07,040 --> 00:13:11,520
to actually completely mask the information that's contained in the good data.

128
00:13:12,320 --> 00:13:17,200
So some type of assumption like the one that you are literally doing is actually

129
00:13:17,200 --> 00:13:20,320
information theoretically necessary. Got it.

130
00:13:20,320 --> 00:13:24,800
Right, so this is so basically where sort of thing started and this is an unsupervised

131
00:13:24,800 --> 00:13:29,840
setting. Unsupervised machine learning means that the data set that you observe is an unlabeled

132
00:13:29,840 --> 00:13:33,200
data set. You have a bunch of points in high dimension without labels.

133
00:13:33,200 --> 00:13:37,520
So maybe it's time for me to move to the Norrips paper.

134
00:13:37,520 --> 00:13:40,960
Yeah, yes. How does that paper come in?

135
00:13:40,960 --> 00:13:46,560
Right. So this is a supervised learning setting. This is a setting where you observe labeled data.

136
00:13:46,560 --> 00:13:52,080
And what you're trying to do is you're trying to fit a linear model. This is like the most basic

137
00:13:52,080 --> 00:13:59,680
family of concepts that you could try to fit to the data. Like literally a linear separator.

138
00:13:59,680 --> 00:14:06,640
You're trying to find a linear separator that separates the point into two classes,

139
00:14:06,640 --> 00:14:12,800
the positive points and the negative points. This seems like almost like a too simplistic problem.

140
00:14:12,800 --> 00:14:18,880
And indeed, in the case of of clean data, it is. Now the question is what happens

141
00:14:19,520 --> 00:14:24,960
when the labels that you observe are actually not clean. They have, let's say, some kind of random

142
00:14:24,960 --> 00:14:31,040
noise attached to them. Can you still recover the true linear model efficiently in the presence

143
00:14:31,040 --> 00:14:36,240
of these types of corruptions? And what we show in this paper is that, in fact, in a very

144
00:14:36,240 --> 00:14:41,920
reasonable model over random label perturbations, this is something that can be done. It can be done

145
00:14:41,920 --> 00:14:48,080
with a computational efficient algorithm. If I understand what you're saying, it's that the linear

146
00:14:48,080 --> 00:14:57,440
model is insufficient in the case of clean data. But when noise is added, that a linear model,

147
00:14:57,440 --> 00:15:05,760
a simple model becomes sufficient. Let me rephrase. So the reason that we consider

148
00:15:05,760 --> 00:15:11,680
settings where the labels are noisy is because these settings are more realistic in practice.

149
00:15:11,680 --> 00:15:16,480
We cannot really assume that we observe label data and our labels are perfectly clean.

150
00:15:16,480 --> 00:15:23,040
So what I was trying to say is that if you make the unrealistic assumption that the data

151
00:15:23,040 --> 00:15:30,480
is clean, then we knew how to fit linear models since the 60s. What we did is we gave an algorithm

152
00:15:31,040 --> 00:15:36,640
to fit linear models under the more realistic assumption that the labels are actually randomly

153
00:15:36,640 --> 00:15:42,080
perturbed. So this is the contribution of this work compared to prior works. We can actually

154
00:15:42,080 --> 00:15:49,840
learn linear separators efficiently in the presence of noise. And so the paper is called

155
00:15:49,840 --> 00:15:55,040
distribution independent pack learning of half spaces with mass art noise. There's a bunch of

156
00:15:55,040 --> 00:16:01,040
terminology in there. Walk us through that terminology pack learning half spaces mass art noise.

157
00:16:01,040 --> 00:16:05,680
Where do they come into play? Okay, that's great. So pack learning. So pack is an acronym. It means

158
00:16:05,680 --> 00:16:13,520
probably approximately correct is a standard model of binary classification introduced by

159
00:16:13,520 --> 00:16:18,320
Leslie Valiant in the 80s and even before that similar models existed by WAPNIC.

160
00:16:19,680 --> 00:16:26,400
So basically the model is essentially for someone who has seen statistics and machine learning.

161
00:16:26,400 --> 00:16:33,680
The most natural thing you could imagine that you observe a bunch of IID labeled examples

162
00:16:33,680 --> 00:16:39,520
that come from a distribution on points with corresponding labels and then you're trying to find

163
00:16:39,520 --> 00:16:47,120
a classifier that generalizes over unseen data. So that's the definition of the pack model.

164
00:16:47,120 --> 00:16:54,640
Now the term distribution independent which in fact maybe is in some sense unnecessary because

165
00:16:54,640 --> 00:17:00,080
the original definition of the pack model was distribution independent is that I'm going to observe

166
00:17:00,080 --> 00:17:05,760
a bunch of labeled examples x and y. Okay, x is going to be my point in high dimensions and y is

167
00:17:05,760 --> 00:17:12,400
going to be a binary label 0 or 1. So what I do not want to do is I do not want to make any

168
00:17:12,400 --> 00:17:18,640
assumptions about the distribution of the x's. Right? I do not want to assume that the x's are

169
00:17:18,640 --> 00:17:23,200
drawn let's say from a Gaussian distribution. So the only thing I'm going to assume is that the

170
00:17:23,200 --> 00:17:29,120
x's are IID samples from some distribution which is fixed but it's unknown to me and it can be

171
00:17:29,120 --> 00:17:36,240
arbitrary and the motivation for all that is on the real data of this type there are settings

172
00:17:36,240 --> 00:17:42,560
where we don't know anything about the distribution of the data and ideally we would like to be

173
00:17:42,560 --> 00:17:48,160
able to handle noise even in those settings. So this is what distribution independent means.

174
00:17:48,800 --> 00:17:54,720
Now the third and last term of the title is massar noise. So let me explain what this means.

175
00:17:54,720 --> 00:18:02,080
So you observe your labeled examples x, y. If y was sort of in the case of clean data why would

176
00:18:02,080 --> 00:18:08,960
actually be the correct label of x. Right? So now what would be a reasonable model of noise?

177
00:18:08,960 --> 00:18:14,880
A reasonable model of noise would be that's okay. I take every y independently and I perturb it.

178
00:18:14,880 --> 00:18:20,560
I flip it. I make it 0 from 0 to 1 not from 1 to 0 with some small probability. Let's say

179
00:18:20,560 --> 00:18:26,560
1 tenth. So this is what massar noise is but it's a little bit more subtle. What it tells you is

180
00:18:26,560 --> 00:18:33,840
that I take every label and with probability at most 1 tenth I perturb it. But you don't know what

181
00:18:33,840 --> 00:18:38,480
is the probability that I use to perturb it. It's a number that's less than 1 tenth but it could

182
00:18:38,480 --> 00:18:44,000
be anything between 0 and 10. Okay. That's the definition of the massar noise model. It means

183
00:18:44,000 --> 00:18:48,960
that under perturbation and the probability of perturbing every label is going to be bounded

184
00:18:48,960 --> 00:18:53,680
from above by some constant. Certainly the constant should be less than half otherwise I lose

185
00:18:53,680 --> 00:19:00,880
all information. And the feature of the model is that you don't know what the flipping probability is.

186
00:19:00,880 --> 00:19:06,800
It can be different across the examples you observe. Got it. And does that massar noise

187
00:19:07,520 --> 00:19:15,440
particularly model well some natural phenomena that we see? Right. So it's reasonable to assume

188
00:19:15,440 --> 00:19:22,640
that the noise added to the examples is independent or almost independence. But in general we don't

189
00:19:22,640 --> 00:19:28,080
know and certainly we should be assuming some boundedness. Otherwise we get no information.

190
00:19:28,080 --> 00:19:33,040
But what we really don't know is we don't know if the same noise is going to be added to different

191
00:19:33,040 --> 00:19:38,880
examples. So in terms of practical applications there are many the people who define this model

192
00:19:38,880 --> 00:19:44,480
like in the 80s and 90s have set out many settings where this is actually reasonable.

193
00:19:44,480 --> 00:19:49,680
So as a theorist I just took the model and tried to analyze it. Got it. Got it.

194
00:19:50,560 --> 00:19:55,600
So let me tell you one thing that I think is surprising especially if you haven't thought about

195
00:19:55,600 --> 00:20:03,920
this problem. Let's consider the case where you know a priori that every label is going to be

196
00:20:03,920 --> 00:20:10,560
perturbed probability exactly one time. So is this model easier or harder than the one I mentioned

197
00:20:10,560 --> 00:20:15,840
already. So what would you think? I would think easier. I think you would say harder.

198
00:20:17,120 --> 00:20:23,600
Actually it's the opposite. So I would think that you would say that it's harder but in fact it's

199
00:20:23,600 --> 00:20:32,400
easier. Oh I was speaking it's easier from I guess an information theoretic perspective we have

200
00:20:32,400 --> 00:20:36,560
more information about the problem. From an information theoretical perspective when you have more

201
00:20:36,560 --> 00:20:43,520
noise you can predict less accurately. But you are right in the sense that algorithmically

202
00:20:43,520 --> 00:20:51,680
it was known how to solve. Just to see that. So basically when you know exactly what is the

203
00:20:51,680 --> 00:20:56,240
amount of noise you're going to add to every example then in some sense you have the ability to

204
00:20:56,240 --> 00:21:04,640
invert the noise. So in fact go from let's say the any statistic that is defined on the

205
00:21:04,640 --> 00:21:10,480
noisy data there is a mathematical way to transform it efficiently to the same statistic on the

206
00:21:10,480 --> 00:21:16,720
clean data. So this has been studied a lot since the 90s it has a name it's called statistical

207
00:21:16,720 --> 00:21:22,000
query model. There are some genetic transformations that tell you that any algorithm that works in

208
00:21:22,000 --> 00:21:28,000
this statistical query model is actually tolerant to this type of noise. The type of noise where

209
00:21:28,000 --> 00:21:33,680
everything is going to be perturbed with the same probability. But the massar noise model

210
00:21:33,680 --> 00:21:37,920
where you know that the probability of flipping is going to be bounded from above on every example

211
00:21:37,920 --> 00:21:42,960
at most one tenth. But you don't know what it is even though the accuracy you can get is higher

212
00:21:42,960 --> 00:21:48,800
information theoretically the problem is easier algorithmically is much more challenging because now

213
00:21:48,800 --> 00:21:56,640
if you see a given example with its label you have no way of knowing if this label is 100% correct

214
00:21:56,640 --> 00:22:06,080
or 90% correct or anything between 90% and 100%. This makes it really hard to actually to actually

215
00:22:06,080 --> 00:22:12,880
invert. In particular this genetic transformation I mentioned that relates this statistical query

216
00:22:12,880 --> 00:22:19,440
model with tolerance to noise fails to hold in the massar noise model. So we need to do we need

217
00:22:19,440 --> 00:22:25,360
to do something new. One more terminology or one more bit of terminology from the titles half

218
00:22:25,360 --> 00:22:31,520
spaces. Right. Half space is just a linear separator. Oh got it. Just a linear model. You have

219
00:22:31,520 --> 00:22:37,440
a bunch of points. You draw a hyperplane in Euclidean space. What's above the hyperplane is

220
00:22:37,440 --> 00:22:43,840
positive? What's below is negative. All right. So in order to analyze this what kind of

221
00:22:43,840 --> 00:22:51,760
machinery did you call in the play? Right. So what we wanted to do is use SGD. Okay. It makes

222
00:22:51,760 --> 00:22:58,240
sense. SGD is the most natural algorithm to use to solve an ML problem. So you need to formulate

223
00:22:58,240 --> 00:23:04,640
the problem in a mathematical way as an optimization problem and hopefully SGD is going to solve

224
00:23:04,640 --> 00:23:09,600
this optimization problem. What we ended up showing as a first step is that this is impossible.

225
00:23:10,400 --> 00:23:17,040
Okay. Fundamentally SGD can't be applied here in other words. Yes. So this is like 50% of the

226
00:23:17,040 --> 00:23:22,400
truth. So if you try to write some kind of complex relaxation of the problem,

227
00:23:22,400 --> 00:23:27,760
try to solve it by SGD. This is going to be this going to fail completely. We can prove that.

228
00:23:27,760 --> 00:23:33,120
And the proof is not particularly difficult. Right. But during sort of the process of developing

229
00:23:33,120 --> 00:23:38,880
this proof, we actually realized that even though SGD does not suffice to solve the problem of

230
00:23:38,880 --> 00:23:44,000
the entire space, it actually suffices to solve the problem on a non-trivial fraction of the space.

231
00:23:44,000 --> 00:23:50,720
Okay. Okay. So basically, I mean, this is of course, it's a technical thing. But we showed that

232
00:23:51,200 --> 00:23:58,640
there exists a non-trivial fraction of a domain where SGD works. So what we, this is an unknown

233
00:23:58,640 --> 00:24:04,000
subset that there is an efficient algorithm to actually detect. So we can find the subset of the

234
00:24:04,000 --> 00:24:09,280
domain where SGD works. We can solve the problem on that fraction of the domain and then iterate on

235
00:24:09,280 --> 00:24:16,960
the rest. Basically, the algorithm turns out to be an application of many codes to an SGD routine.

236
00:24:16,960 --> 00:24:24,080
Are you able to either determine the importance of the subset of the space that you are able to

237
00:24:24,800 --> 00:24:31,280
apply SGD or are you able to kind of keep track of how much of the space you've covered by iteratively

238
00:24:31,280 --> 00:24:36,240
searching with SGD? Right. So to show that this algorithm is actually efficient,

239
00:24:36,240 --> 00:24:41,680
this process that I describe this iterative process needs to happen a small number of times.

240
00:24:41,680 --> 00:24:46,320
Right. If it happens a exponential number of times, you haven't solved the problem efficiently.

241
00:24:46,320 --> 00:24:51,200
And this is part of the structural understanding that we obtained by solving the problem. But in

242
00:24:51,200 --> 00:24:57,760
every iteration, we actually cover a non-trivial and inverse polynomial fraction of the space.

243
00:24:57,760 --> 00:25:02,400
After at most the polynomial number of iterations, we have covered the entire space.

244
00:25:02,400 --> 00:25:08,240
Right. Okay. Let's say in every iteration, we solve one percent of the problem. So we need

245
00:25:08,240 --> 00:25:16,080
the hundred iterations solve the problem. Maybe this is a sidebar, but are there specific details

246
00:25:16,080 --> 00:25:25,680
of the implementation or the proofs that you or what you covered in a paper that are accessible

247
00:25:25,680 --> 00:25:31,920
without going into, without getting too pulled into the theory? I think the answer to that is

248
00:25:31,920 --> 00:25:40,560
probably no, but I'll be honest here. So it's not a terribly complicated paper. I think it's

249
00:25:40,560 --> 00:25:46,480
actually quite simple from a theory perspective. It has something original that people didn't come

250
00:25:46,480 --> 00:25:54,640
up with before. So what I maybe should say that this, even though it answers an open problem

251
00:25:54,640 --> 00:26:00,160
from a long time ago. So this was posed in the 80s in learning theory. It's not over here.

252
00:26:00,160 --> 00:26:05,520
So this is in some sense the first paper in this sort of line of work of doing distribution

253
00:26:05,520 --> 00:26:10,400
independent learning with noise. And I believe it's going to lead to many developments.

254
00:26:11,040 --> 00:26:18,960
In particular, like something that we have been able to answer very recently with one of the

255
00:26:18,960 --> 00:26:23,920
authors of the same paper, my colleague, Christos Zamos, and two of our PhD students here at

256
00:26:23,920 --> 00:26:31,760
Madison is that in fact, if we make some very weak, but still reasonable assumptions about

257
00:26:31,760 --> 00:26:36,960
the distribution. So if we look at the distribution specific sharing, but still reasonable,

258
00:26:36,960 --> 00:26:42,480
we have a way of showing that SGD actually works as is. So we relax the problem a little bit,

259
00:26:43,120 --> 00:26:47,920
but still in a way that it remains reasonable and we can now solve it by SGD.

260
00:26:47,920 --> 00:26:53,920
And you're a bit cagey about the assumptions that you're making. Are they,

261
00:26:54,800 --> 00:27:01,600
are you fixing to a limited subset of known distributions or is there some other

262
00:27:02,960 --> 00:27:06,800
distributions that's important? Right, right. So the paper is going to be online in a week,

263
00:27:06,800 --> 00:27:14,720
so I'm happy to share this. So I mean, the terms are going to be sort of a little

264
00:27:14,720 --> 00:27:19,840
potentially, potentially a little bit technical, but really what we need is that the distribution

265
00:27:19,840 --> 00:27:26,320
of the inputs is reasonable in the sense that it's not too concentrated or too sort of like,

266
00:27:26,320 --> 00:27:32,800
let's say, not too dense or not too empty and where. Okay. And so there are these technical terms

267
00:27:32,800 --> 00:27:38,080
that are called concentration, anti-cursentration. So as long as we have weak properties of that

268
00:27:38,080 --> 00:27:44,720
for, this probably suffice to solve the problem. Okay. Interesting. Interesting. And so what is it

269
00:27:44,720 --> 00:27:54,400
about this paper that you think kind of caught the interest of the NIPs reviewers and landed it

270
00:27:54,400 --> 00:28:00,080
the outstanding paper award? Right. That's difficult for me to answer. I mean, this is,

271
00:28:00,080 --> 00:28:06,320
I'm not happy that the paper got recognition and I really believed in it before we submitted it.

272
00:28:06,320 --> 00:28:11,440
So I believe it was a significant advance. I think the reason is because it solves,

273
00:28:11,440 --> 00:28:16,240
like, that's my guess, that it solves an old open problem and recognized open problem

274
00:28:17,280 --> 00:28:24,000
in machine learning theory. And really, essentially, no progress had been made on distribution

275
00:28:24,000 --> 00:28:28,560
independent learning in the presence of noise for a long time. And also at the same time,

276
00:28:28,560 --> 00:28:33,520
the solution turns out to be quite clear, at least compared to other theory papers.

277
00:28:33,520 --> 00:28:40,800
And were you surprised by how clean it ended up being? Yes, I was very surprised. In fact,

278
00:28:41,840 --> 00:28:47,440
we solved this problem in a month and then we spent like 10 months to improve it,

279
00:28:47,440 --> 00:28:55,040
and we couldn't. So it somehow gives me the belief that this turns out to be, this is

280
00:28:55,040 --> 00:29:00,320
probably the best possible solution to the problem. But yet, you remain convinced that

281
00:29:00,320 --> 00:29:06,000
there's more to come and you'll be able to build on it or improve on it. Yes, I mean,

282
00:29:06,000 --> 00:29:12,000
there are some other things that we have recently done and I am indeed cage about them because

283
00:29:12,000 --> 00:29:17,360
they're not sort of written yet. But yeah, I believe that this line of work is going to lead to

284
00:29:17,360 --> 00:29:23,040
a lot of progress in the next couple of years. And so for folks that are interested in digging in

285
00:29:23,040 --> 00:29:26,640
a little bit deeper, there's obviously this paper, but you've also recently

286
00:29:26,640 --> 00:29:35,520
co-authored a survey on this broader space. Can you talk a little bit about that in the focus there?

287
00:29:35,520 --> 00:29:41,200
Right, right. So since this initial 2016 paper on robustly learning high-dimensional

288
00:29:41,200 --> 00:29:45,520
distributions, so we're back in the unsupervised setting. So once we wrote this paper,

289
00:29:45,520 --> 00:29:50,800
a number of people found this interesting. And at this point, there is a long literature

290
00:29:50,800 --> 00:29:55,680
on algorithmic high-dimensional robust statistics. So what I did with my long-time

291
00:29:55,680 --> 00:30:00,720
collaborator, Daniel King, we decided, okay, there's so much work in the past four years and it's

292
00:30:00,720 --> 00:30:06,800
unclear if people understand other people's work. So let's try the survey, giving an overview of

293
00:30:06,800 --> 00:30:12,480
all the techniques that people have developed in this space. What are the problems that have been

294
00:30:12,480 --> 00:30:18,880
solved? What are the problems that are open? Somehow giving some kind of, you know, pose, like I

295
00:30:18,880 --> 00:30:24,960
point where, you know, the community needs to say, okay, this is what it has achieved so far.

296
00:30:24,960 --> 00:30:31,200
What are the next directions to look at? So this is available on the archive and it's also going to be

297
00:30:31,200 --> 00:30:36,720
sort of at least a short version of it's going to be part of a book chapter on the young worst

298
00:30:36,720 --> 00:30:41,920
case analysis that's going to be published by Cambridge University Press soon. Okay, and this is

299
00:30:41,920 --> 00:30:47,920
the recent advances in algorithmic high-dimensional robust statistics that was published on archive

300
00:30:47,920 --> 00:30:53,120
back in November of last year. That's right. That's right. And how many papers does it cover?

301
00:30:53,120 --> 00:31:00,400
I mean, in true detail, probably around 15, but we give an overview of about a hundred.

302
00:31:00,400 --> 00:31:06,160
Oh, wow. Wow. There has been a lot of work in this space in the past few years and really

303
00:31:06,160 --> 00:31:15,360
the reason for that are these theoretical questions have the potential of practical impact and

304
00:31:16,320 --> 00:31:20,640
already we have seen some steps in that direction. For example,

305
00:31:20,640 --> 00:31:27,520
one of the prototypical applications of robust statistics is in something that's called data

306
00:31:27,520 --> 00:31:32,320
poisoning. So this is a phenomenon where you have a machine learning system. So the input

307
00:31:32,320 --> 00:31:36,880
coming from the outside let's say you have many users, but then you have a small number of

308
00:31:36,880 --> 00:31:42,400
malicious users that are trying to insert fake data in the system and completely destroy the

309
00:31:42,400 --> 00:31:46,720
behavior of the system. So robust algorithm would actually be able to prevent that.

310
00:31:46,720 --> 00:31:52,560
Okay, so we have had the number of papers and I've got all of the couple where we actually do that.

311
00:31:52,560 --> 00:31:57,760
We actually show that some of these theoretical algorithms developed in these initial works

312
00:31:58,240 --> 00:32:04,080
can give you provable and practically useful defenses against these types of data

313
00:32:04,080 --> 00:32:09,840
poisoning attacks in machine learning systems. Okay. And are you aware of any actual implementations of

314
00:32:10,640 --> 00:32:15,120
the work in the space? Implementation is what sense. I mean, I'm afraid

315
00:32:15,120 --> 00:32:22,880
there. In a sense of a company using it. I see. Okay. So yeah, we're not there yet. So I'm

316
00:32:22,880 --> 00:32:28,880
very eager to sort of, you know, to collaborate with people to do that. At this point,

317
00:32:28,880 --> 00:32:34,560
we're at the stage where we have sort of proof of principle experiments published in like

318
00:32:34,560 --> 00:32:40,480
ICML and Newrips. So we're not yet at the stage where this sort of line of work has reached

319
00:32:40,480 --> 00:32:46,720
the industry. But it's a goal. It's a goal for the immediate future. And do you think that that

320
00:32:46,720 --> 00:32:53,200
is because the, it sounds like folks are aware of the problem are the solutions sufficiently

321
00:32:53,200 --> 00:32:59,840
generalizable at this point that they are easily applied in industry? So I think the reason is

322
00:32:59,840 --> 00:33:06,160
that it hasn't propagated enough. Right. So in some sense, another reason might be that some of

323
00:33:06,160 --> 00:33:12,000
the algorithms are not just creating the sense. Okay. There are a little bit more sophisticated

324
00:33:12,000 --> 00:33:18,080
algorithms using spectral methods. They're not as automatic as machine learning people who'd like

325
00:33:18,080 --> 00:33:23,120
them to be. So basically, a next step, which is currently something I'm currently working on,

326
00:33:23,120 --> 00:33:28,400
is actually completely eliminate the algorithms from these problems. Right. So we formulate them in

327
00:33:28,400 --> 00:33:34,080
a certain way so that we can just use it in solving. And somehow the insights obtained from these

328
00:33:34,080 --> 00:33:41,760
initial papers are useful. Let's see that. So let me point out that these problems are inherently

329
00:33:41,760 --> 00:33:47,600
non-convex. And this is why they're so hard. Okay. But even for non-convex problems,

330
00:33:47,600 --> 00:33:52,960
when they have some additional structure, it is quite possible that if you formulate them the

331
00:33:52,960 --> 00:34:00,000
right way, some version of SGD actually solves them. And this is something that I believe is true

332
00:34:00,000 --> 00:34:05,200
and we're working towards proving it. Well, Alias, thanks so much for taking the time to share what

333
00:34:05,200 --> 00:34:09,520
you're working on. Something you very much for the opportunity that you gave me. Thank you.

334
00:34:13,360 --> 00:34:18,400
All right, everyone. That's our show for today. For more information on today's show,

335
00:34:18,400 --> 00:34:33,200
visit twomolai.com slash shows. As always, thanks so much for listening and catch you next time.

