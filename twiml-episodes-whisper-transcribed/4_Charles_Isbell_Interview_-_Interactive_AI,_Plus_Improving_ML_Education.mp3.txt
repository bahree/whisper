Hello everyone and welcome to Twimble Talk, the podcast where I interview interesting people
doing interesting things and machine learning and artificial intelligence.
I'm your host Sam Charrington.
We've got another great interview for you this time around but first a quick update
on the drawing we've been running in conjunction with O'Reilly Media.
As you know if you've listened previously O'Reilly Media is holding their first ever AI conference
on Monday and Tuesday, September 26th and 27th in New York City. The conference will span both
low-level talks on implementing AI and high-level talks on the impact of AI in society
and I'm personally looking forward to speeches by AI luminaries such as
Google's Peter Norvig, Facebook's Jan LeCoon, and Intel's Slash Nervana's Navine Row.
And we're giving away a ticket to one lucky winner here two day.
In addition, right after the AI conference on Wednesday and Thursday, the 28th and 29th
is the O'Reilly Stratta Plus Hadoot World Big Data Conference which is one that I've been attending
for years now. You may have heard me mention this one before. Stratta is a much bigger event
and while it's not strictly focused on AI, there are tons of really interesting AI machine learning
talks at Stratta as well. Along with talks focusing on what I consider to be the core topics of that
event, data infrastructure and data engineering. And O'Reilly has been kind enough to offer us
a ticket to Stratta as well, which we'll be giving away today. So about that giveaway.
If you went ahead and entered into the contest via either Twitter or the Twimlai.com website
before the cutoff date, your name or Twitter ID went into a spreadsheet and you actually
had a pretty good chance of winning as far as giveaways go. I chose winners using a random
number generator to pick four numbers in the range of my spreadsheet rows. The first winner
who was lucky number 17 is Lance Pool who entered via Twitter. Lance gets to choose either conference
ticket for his prize. The second prize winner is Yinka also from Twitter and he gets the ticket
remaining after Lance's choice. I've also chosen two runner-ups who may be called upon to
fulfill the duties of one of our winners if either of them can attend the event. Our first runner-up
is Samuel W and our second runner-up is Dennis A who both happened to have entered via the Twimlai.com
site. If you hear this any of you please reach out to me to claim your prize. Now if you didn't
win it's not too late to save 20% on your registration for either conference. You can do that by using
the registration code PCTWIML when registering and I'll include a link to the registration page
in the show notes. On behalf of the podcast and our partner O'Reilly thank you to everyone who
entered and now on to the show. All right folks I am super excited to bring you this interview.
My guess this time is Charles Isbel Jr., Professor and Senior Associate Dean in the College of
Computing at Georgia Institute of Technology. Charles and I go back a bit and in fact he's the first
AI researcher I ever met. His research focus is what he calls interactive artificial intelligence,
a discipline of AI specifically focused on the interactions between AI's and humans.
Charles and I spent a good chunk of time in our interview exploring what this means and some of
the interesting research results in this field. One part of the discussion I found particularly
interesting was the intersection between his AI research and the related fields of marketing
and behavioral economics. Beyond his research Charles is well known in the ML and AI worlds for his
popular machine learning course on Udacity which he teaches with Brown University Professor Michael
Littman. In addition Charles helped launch the online masters of computer science program at
Georgia Tech. We spend quite a bit of time talking about what's really missing in machine learning
education and how to make it more accessible. Of course I'll be linking to Charles and the
resources we mentioned in the show notes which you'll be able to find at twomolei.com slash talk
slash four and now on to the interview. All right everyone so I'm here with Charles Isbell. Charles
is senior associate dean and professor at Georgia Tech and actually Charles and I go way back.
So this has been a weird conversation because we're already like 20 minutes in and just getting
started with the interview. Charles say what's up to everyone and we'll get started.
What's up everyone how are you doing? I'm happy to be here. I'm happy to be having this conversation.
Awesome well thank you so much for joining us for this interview now. I think we figured out that
that it's been like 20 something years since we met and that was pretty interesting in that
we were roommates during a I guess summer internships at Bell Labs and that was when you were at
MIT and studying AI. Tell us a little about your experience at MIT and what you said you're in the
famous AI lab there right? I was although the AI lab no longer exists it merged with the laboratory
for computer sciences now known as CSAIL. So I love my time at MIT and I love my time at Bell Labs
and eventually AT&T labs. Sort of my journey through AI is a I don't know it's a bit of a
wandering one so here I'll just give you my entire history up to now in like 15 seconds and we'll
see how that goes. So as you can tell by my accent I was born in Chattanooga Tennessee but my
earliest memory is arriving in a moving truck at the age of three and a half in Atlanta so I think
of myself as being from Atlanta. But very very early on I cared a lot about computers and computer
science and I knew when I was eight years old that I was going to do computer science although I
didn't know what it was. I knew I was going to be a professor although I didn't know what it was
and I knew I was going to do AI even though I had no idea what that was. Something about building
robots and yeah eight years old. You know it took me a very long time to realize that not everybody
thought they knew what they wanted to do and they were eight years old. I think I was probably a
senior in college before I realized this but I had always sort of wanted to to build intelligent
things although I couldn't have articulated that way when I was eight years old but I always wanted
to build smart things I always thought I thought the computers were great at least what I thought
computers were and I basically just wanted to build you know an intelligent friend that's
basically what I was into at the time and so everything I kind of did from at that point on was
about that. My actual first encounter with Bell Labs long before we met I was things the summer
before ninth grade so I was 13 years old or so and I built a computer at Bell Labs as a part of
this the summer science program. What I say I built a computer I mean there was a kit and another
engineer did all of the work while I stood there and watched it but it felt like I was building
the thing. It was a time X and Claire T 1000 and I remember. Yeah it was a little chicklet thing
and it didn't have an on-off switch so when you turned it off you had to unplug it. It was great
and the first program I ever wrote was a piece of code that would fill up the screen with inverse
spaces and it ran out of memory before it could finish doing it and that was my introduction to
real computer so you know that that's what I figured I needed to fix that and so that whole summer
we spent well the two or so weeks that I was there for that program I spent a lot of time trying
to figure out how how to make computer smart and how to make them do what you wanted to do and it
just verified for me that that's what I wanted to do for all of my life so I kind of dove in from
there and I kept getting you know bigger and better computers and convincing my mom that you know
an Apple 2GS was the right thing and it was the best thing she could do for my education she kind
of nodded politely eventually gave me the things that I wanted and I sort of moved through and one
of the advantages of knowing what you want to do with your life is that you sort of moved towards it
there's some disadvantages we can talk about those but really admit that you know I knew I wanted
to go to Georgia Tech because I wanted to stay in Atlanta and I thought that it was the best place
for me to be so I went to Georgia Tech as an undergrad I completely dove into AI didn't do a lot
of research at the time because that you know in the the 1980s it was a little there weren't as many
places where you could do the kind of research that you can do now as an undergrad that no matter
sort of what you're into and then decided well there was basically one place for me to go to grad
school and I applied to MIT and I went to MIT and I wrote this long essay about building robots and
trying to make them smart and and trying to make certain that they wouldn't run out of memory and
it was a it was a lot of fun so I ended up going to MIT immediately started diving into machine
learning which at the time was sort of new for me I knew about AI and I knew I wanted to build robots
but it didn't occur to me that you needed to do something separate to make machines learn and
I decided almost immediately once I was exposed to it that this was the central question you couldn't
be smart unless you could learn right and our machines were never going to be able to do the
interesting things that I wanted them to do when I was eight nine years old unless they were smart
enough to learn how to do them on their own and so I dove into that became a part of the AI lab
went through a couple of advisors I'm still good friends with with all of them and eventually
ended up where I was the side story where we met is I at the same time that I was going through grad
school I got to go to bill labs every summer so part of this this fellowship program you know
all about this of course and there I did a lot of really interesting things in AI that had
absolutely nothing to do with what I was doing in grad school but it was so interesting what they
were doing they're trying to build these knowledge representations and kind of really understand
how it is you could think and you could represent thought that I just you know at the time it felt
okay that I wasn't making progress in grad school because I was still getting to do these cool
things and so by the time we met I was doing six months out of the year at Bell Labs and six
months out of the year at MIT more or less oh wow I don't think I realized that at the time
yeah because I take four and a half months over the summer I'd start before everyone else and I
would end after everyone else and I would go back during the winter breaks okay okay uh so
the I think the time that you kind of came up in AI was during the quote unquote AI winter
is that right more or less yeah I was just sort of at the tail end of the AI winter nobody told
me that I didn't figure that out until much later so how was that impacted your and your
contemporaries perspective on AI and and the work you've done and how do you like what do you
think about the current popularity of AI and where it's all going so I think basically
what it's mainly done is it the people who are about my age and a little bit older who
live through the AI winter I think basically spend a lot of their time wondering when the next
AI winter is going to come so a lot of us are very very sort of naturally and reflexively worried
that we're overhyping what's going on right it was it wasn't that it was difficult to get funding
it wasn't that it wasn't it was difficult to do work it wasn't that there weren't people
interested in the problem that we're interested in it's that any minute now the federal government
would take away all of the funding and we would you know we would go from having 10 graduate
students to having two graduate students and I kind of think that little fear is always there
in the in the back of our heads and we find ourselves thinking please stop overhyping deep
neural networks or you know getting people convinced that we're gonna uh we're gonna build
the next data or the you know the next android and self-driving cars and any minute it can all kind
of go wrong so I think it's probably made us somewhat more cautious at least it's made me
somewhat more cautious and trying to think a little bit about the hype that's sort where
where it's kind of driven me uh but you know the other advantage of being a part of you a part
of sort of AI when it was during the AI winter is that you knew that you and the people you were
talking to were in it because you were truly passionate and motivated about solving the problem
as opposed to starting a company that would make you really rich or you know this is the hot thing
you were doing it because you you actually cared about it and and I think that you know that's
important right certainly when you're when you're doing research you have to be passionate about the
the things that you you're doing and really believe that somehow it's gonna get you someplace
interesting. And so do you think the fear notwithstanding do you feel like the is the industry
structured in the same way such that the risk is the same or is it different and in particular
I'm thinking about is there you know the funding sources more distributed now is the level of
industrial activity you know more greater now or is it all you know from a research perspective
all still fundamentally the government funding everything and you know when he decided to change
there when the winds changed there at all collapses. Well I think structurally two things have
happened one is computers computing and that sort of way of of crunching things and data are now
ubiquitous they're everywhere so industry is deeply into this it's not going away
Google exists right and everything is driven by data and it turns out that the parts of AI the
parts of computer vision the all the sort of pieces of of building intelligent things they're
driven by data now and since we everyone has access to data and everyone has access to
computing everyone has access to really fast machines I'm not worried about sort of it structurally
going away in fact the problem is sort of the opposite it's that everyone has a piece of it now
it's it's driven as much by commercial interest as it is by sort of pure research and so really the
difficult thing in some ways is that there's so many opportunities to do the what I would have
thought of as AI what we would talk about is machine learning and those kinds of related things
that it's easy for things to become diffuse in a way that wasn't true 25 years ago I don't think
this is a bad thing I mean the the fact that Facebook exists the fact that Google exists the
fact that everything is about your about data and about you know sort of modeling what people are
doing and what things are happening is definitely a good thing and it does mean that there's always
going to be funding for some piece of it even if it's not being called AI or it's not being
called machine learning the kind of ideas metastasized so I'm not really worried about it going away
the only thing that worries me is that people are concerned that bad things will happen because
of what we're doing and for good reasons right they're concerned about their privacy we now have
all these ability it's ability to track everything that you do I guarantee you Google is well aware
that you and I are having this conversation right now they probably know what we're going to say
before we say it you know they've got more data on us than you can possibly imagine and truthfully
we I'm not entirely sure that we mind Facebook knows everything about us their companies out there
neither was it heard of who know kind of everything about us as a people worried about privacy they're
also worried about cars running off the road and killing other people they're worried about robots
you know rising up in terminator style killing us all so the the kind of fears is the hype has
actually gotten to the point of not what you haven't given us what we promised it's that you've given
us more than what we asked for I think that's where the danger is coming from now but in terms of
funding in terms of people being interested in these problems now that's driving everything even
things you don't think of as being AI or being machine learning. It's interesting that in some
ways it's in some ways the industry's given more in some ways like we're still waiting like
you know if you if you survey sci-fi and you know even the Jetsons you know where where sci-fi thought
we would be in you know 2016 and a lot of ways where we're not there yet right like a lot of
movies would have had the self-driving cars all over the street but some of this stuff it takes
longer it takes longer to develop than you think and some of the stuff is happening quicker than
you think. No I think well some of the things are happening that nobody ever thought about I mean
you go back and you start thinking about sci-fi it wasn't self-driving cars or self-driving jetpacks
right it's still haven't got my jetpack yet I'm still waiting for that and it's true we we haven't
gotten the flying machines we haven't gotten the really the smart butlers that are that are
taking us everywhere another thing we've gotten a lot of other things right we've got access to
information that we've never had access to before we can ask questions and we'll get the answers
back we can look up anything we want to we can teach ourselves we've gotten a lot more things we
never thought about than we thought we would and we've gotten less of the kind of obvious things
that that I think people sort of hoped that we would one day get so you know it's a mix I'm okay
with that I mean I I people ask me all the time you know when are the computers going to achieve
sentience and and and take over the world and I think the answer is probably never or at least
probably not for a very very long time not in the way that people think about it but we're going
to have very smart machines and we already do doing a whole lot of things for us that we never
sort of expected them to do and the interesting thing is we won't even notice and it won't seem
like that big of a deal I mean for example with the Tesla and the autonomous cars Uber and all
the things that they're doing that's amazing have you ever been in one of these cars
if you ever to it led to this that's amazing that you can sit in that car and it can drive you
through traffic on a highway at 65 miles an hour that's it's amazing if you would ask me how
you would do something like that 25 years ago I mean I can barely forget how human beings do it
and in fact being on the road it's pretty clear to me lots of human beings don't do a very good
job of it but that's a miracle and we barely notice right every time you get an airplane right the
pilot's not flying the airplanes flying itself right and we just take this everyday miracle is just
a another little thing in fact you know one of the big complaints if you're into AI right is that
you never actually get credit for the cool things that you do right AI is kind of the the science
and the engineering of making computers act the way they do in the movies right but one of the
things that sort of tied into that is if it's got to be intelligent then it's got to be like humans
and if it's got to be like humans it has to be mysterious and something we can't understand so
the problem is every time we do something even if it's amazing once we know how to do it and we
understand it well that can't be real intelligence and so we don't give the credit to AI so AI sort
of has this problem where you you can't ever win because anything interesting you do well
we understand that and that's not real intelligence so it's no longer AI yeah or it's just it's
just computers right it's never this thing where you succeed it it's just oh that's not the real
part the real intelligent part is this thing and then when you can suddenly do be you know people
at jeopardy well that's that's not really intelligence the real intelligence is other things so you
you basically just keep you know innovating your way out of out of business and so AI gets sort
of smaller and smaller and smaller and what it's allowed to to call itself because the mystery gets
smaller and smaller is it smaller smaller or further further well it's always sort of infinitely
far away right all right it's it's it's something that we can always look for but we can never
quite get to sort of Zeno's paradox of AI but there's not like a you know there's not some finite
set of things that we need to do to figure out AI and we're chipping away at it and it's getting
smaller and smaller it's like the goalpost is moving yeah well so I think both of those things are
true I think there are a finite number of things we need to do we're definitely chipping away at it
and so the stuff we need to do sort of gets smaller and smaller though it's still really big but the
goalpost keep moving right we've got cars that can drive themselves more or less and now that's
no longer amazing so it's got to be something else but that's that's amazing and by the way
it's not just amazing it has an amazing impact on the world have you seen this I know you're on
Facebook see you remember this map that was going around for a while that showed the the most
common jobs in every state you remember this yeah and do you remember what the most common
job is in almost every state in the US truck driver right yeah truck driver delivery person taxi
driver right that's something like 42 or 44 this item the right number but it's over 40 for some
reason in other states it's elementary school teacher I don't know why but but mostly it's truck
driver well you know we're five years away from all the cars delivering driving themselves right
Uber is it's not going to have people involved anymore my old advisor my one of my PhD advisors
you know is heading the work at primary right so things are going to be delivered to as by drones
and people are going to be involved anymore well that's the most common job in the country
and it's going away right so the the goalpost removing the the things we have to do or getting
smaller or not and people have this sort of feeling what AI is but whether or not you want to call
it AI or not it's going to have a massive impact on our day-to-day lives and it's going to have
a massive impact on the economy it's going to have a massive impact on sort of how we see ourselves
and how we interact with one another and whether you decide that it's AI or not or it's intelligent
or not whether you move the goalposts or not it's changing everything around us in deep and
profound ways yeah absolutely absolutely so I want to talk about a couple of of really specific
things with you and we'll take these in in turn the first is in the the realm of education
and the second is in the realm of your research focus area and reinforcement learning but let's
start with the first of those we got we got through your grad school experience in MIT then you
went back to Georgia Tech and most recently you've been doing a lot of work in online education
around machine learning maybe walk us through what you're doing there and in particular I'm curious
and maybe as a bit of background here I didn't go through your entire course but I took a look at
the the course that you did with Michael Litman and it was I really enjoyed the presentation
having gone through a number of ML MOOCs and it made me wonder like what you know what unique
views do you bring to you know teaching and or learning machine learning in AI that you surfaced
in the the coursework as well as you know which of the you know are there any views you have that
you think kind of go against the grain of the way people other people are approaching it
yeah so so I'm glad you enjoyed the the the classes Michael and I had a ball just a total blast
doing it and if you haven't you should watch the the Michael Jackson parody video we did about
machine learning you get to see get this you Michael dressed up as Michael Jackson and dancing
which is well worth the price of admission which is free so the you talk about this kind of
interaction we have one of the things that Michael and I I tried to do is we decided that we've
been wanting to do things for a long together for a long time but you know he's on one part of the
country having another part of the country we wanted to do this this machine learning MOOC and
and this gave us the the opportunity to do it and the way we decided to come at it was it's
much like we're doing this now we said you know what education like this should be more like a
podcast you should have a conversation so every time we did one of these these lectures one of us
would be the professor who would try to present the material and the other person would try to be
the student so the professor would do all the preparation and come up with the sort of lesson
and get everything together and the student would do no preparation at all and come in cold so you
know in that way it's just like regular school and we would just talk and of course he's an expert
I'm an expert and this is what we do all day so it's not like we didn't really kind of understand
what was going on but it turned out and I think this really does come out in the conversations that
we had that we actually have very different views of what's important right so Michael is much more
of a theoretician if you asked him what AI and machine learning is he might say something like
computational statistics I'm much more interested in thinking about it and it's kind of practical
applications and you know sort of what you can do as a practitioner to to to use these tools
to to make them work and get synthesis I want people to see that this thing over here is just like
that thing over there which is just like this thing over there and they're all tied together
and I'm much less interested in proving in the abstract what it is that that you actually
can learn in what you actually can't learn it's not that these things are important I just you
know I'm just less interested in them than than Michael is and so we would spend all of these
times kind of arguing some of that sometimes obviously sometimes not about what's going on
and what I hope came out of that and you can tell me if you if you think it's true or not
is that the student was drawn into this conversation and at least got the feeling that not only
were they learning some equation or getting ready for some test or doing some assignment but that
there really is a deep conversation going on about AI and machine learning and there's lots of
different ways to think about it and and really that kind of gets to my larger philosophy about
the way education works and why I'm so excited about the online education that's that we've
been able to do to me what's really missing in education is access right the ability for people
to really to participate in the in the commons that is education that is research that that is
learning and one thing that I think's important for people to understand is that when you say
access some people turn that into affordability you know is it cheap enough you know
tuition is too high you know and that is a part of access but access is actually very different
access is just the ability to be able to participate in the conversation and that if you're
capable of getting through it being able to have the real opportunity to get through it
affordability is only a small part of that so one of the things that we've been doing and
and I'm actually quite proud of this over the last three years is we decided that we
wanted to push on this idea of access and affordability and that online education in MOOCs
were one way of doing it and while we're working on this this machine learning class we wanted
to make it a part of something bigger and so Georgia Tech when when I was there in my senior
social dean role I guess I still am and in my professor role we wanted to build an entire degree
a graduate level degree that anyone who could get access to the internet and then who had the
time and had the desire would be able to get through an actual full-fledged course
a full-fledged and not just a course a full-fledged degree a real program and so we created this
online MS program it's exactly the same as our on-campus program same requirements same degree
you get through this you get a you get a master of science computer science from a top 10
department and it's indistinguishable from the one that you get on campus and here's the thing
that we we did two things to sort of push on this notion of access one is we decided to make it
as inexpensive as possible so the entire the cost of the entire degree is something around $6600
wow depending on how fast you you get through the program so somewhere between $6,000
and $8,000 sort of depending upon what you do you get an entire degree that's pretty inexpensive
if you came on campus and you were out of state student it cost you more like $46,000
so that was the first thing that we did make it affordable but the other thing that we decided
to do is we decided to admit every single student we believed who could succeed
this is a pretty big deal right if you if if we think about our on-campus degree we accept about
10% of our applicants why do we accept 10% of our applicants because it's all the space we have
right I'd estimate somewhere between 60 and 70% of the students who applied our graduate program
are above bar but we only got a room for 10% of them so only 10% of them get in and by the way
it's it's it's basically a lottery right I mean you know when when you've got your place like
Stanford and you're accepting four or five percent of the people coming into your undergraduate
program there's no way that that four or five percent really better than the next four or five
percent the four or five percent after that you're you're almost closing your eyes and just picking
people right yeah and this is but what we were doing at the graduate level we don't like that
for our online degree which again is the same degree as our on-campus degree at this point we're
accepting about 60% of applicants okay we've gone from zero students three years ago to 4,000
students this term 4,000 currently enrolled students or is that a cumulative 4,000 currently
enrolled students okay wow wow that's pretty good how many on campus about two or three hundred
okay in fact right by the way it's not just that we've got 4,000 students they're performing
as well as the on-campus students oh by the way it's not just that we have 4,000 students
who are behaving who are performing as well as the on-campus students they look very different
so if you look at our on-campus degree about 85% of the applicants are far national
faster majority of whom are from India following behind China so about 15% are US citizens
for our online degree it's the compliment about 85 80 to 85% of the applicants are US citizens
or permanent residents okay right they're in their early 30s early in mid 30s not in their
earlier mid 20s most of them are working full-time they've got you know jobs mostly in IT they're
not all of them they've got mortgages they've got kids and they're trying to sort of get through
their day but they can't take the time to get further education or to do that thing they want to
do because again they've got mortgages and kids they've got responsibilities right so what's
interesting is we've done studies of this we partnered with Harvard and looked at it we think that
of the people who are coming through our program almost none of them would have pursued an advanced
degree otherwise they weren't they because they just simply didn't have the option they couldn't
take two years off from their lives to go and pursue a degree because they had too many other
responsibilities and things that they had to do but this gives them the option of doing that and so in
fact the overlap between them and the people who normally we get education is almost zero
current estimate is that we'll add between eight and 10% every year to the number of graduate
IT workers in the United States then we otherwise would have seen and have you looked at what what
they're doing afterwards how long has the program been in place and how long have you been tracking
that into what degree so it's been about three years in fact I think we're beginning our we'll be
we're just ending our third year now and we'll be starting our fourth year so people have just
begun to graduate we had 20 people graduate two terms ago and this semester we're expecting
to see closer to about 250 and we're expecting to see a steady state of closer to a thousand people
graduating a year most of them already had jobs so you know usually the way you measure success you
say okay the people get jobs when they graduate well most of these people already had jobs so they
didn't lose their jobs I guess that's a good thing but it's hard it's hard to know what that
what that impact is because the usual measures don't really make sense but they're all they all
seem to be happy 97% of them said that they would you know recommend this to other people many of
them do get jobs while they're in the middle of the program a lot of them get promotions and they
move through you'll have to ask me in five years what the what the real impact is but right now it appears
that people are happy they're getting a lot out of it some of them are able to change careers get
promotions and to do things they wouldn't otherwise be able to do because they just couldn't take
the time off to do it so I'm very happy with that and happy with the sort of impact it appears to
be having on students let me ask you this a lot of people who listen to the podcaster somewhere along
the progression of learning and and entering machine learning as a field as a profession and
I'm wondering what what do you think the right set of uh set of educational tools to take advantage of
right MOOCs are a piece of that um but there's obviously other pieces that go into making a full
kind of a well-rounded student of machine learning in AI how do you recommend that students
approach that or do you have a philosophy around that well so I sort of do and I do think it comes
out in my in my class if you actually take the class as opposed to watch the lectures you get my
assignments and I'll just describe my first assignment to you because I think it actually captures
a lot of at least what I believe matters in becoming a either a machine learning researcher or
a machine learning practitioner or even AI or more broadly speaking so here's my first assignment
first assignment is go find two datasets I don't care what they are so long as they're interesting
they have to be interesting by themselves and they have to be interesting together and you have
to convince me that they're interesting um then I want you to implement these five or six algorithms
and when I say implement I mean steal the code I don't really care you'll get any credit
whatsoever for implementing and running the code you steal libraries you know go get your
your favorite implementation of K&N or boosting from somewhere else I don't really care
and I want you to run all of those algorithms on those two datasets and I want you to do analysis
and explain to me why you got the behavior that you did why did some of those algorithms which
should all work why did some of them behave better on some data on one of the datasets than the other
what sort of things did you learn by applying those algorithms and doing the data analysis convince
me that you thought about it convince me what experiments you would need to run in order to really
get the answers to the questions and then run those experiments do all of that and then write it
up in 12 pages not 13 pages not 14 pages 12 pages why do I have an assignment like that I haven't
assignment like that because I think much about machine learning much about the field that we're in
is really about the practice of doing it you know theoretically all of these algorithms is
particularly in supervised learning they're all very similar they all can learn the same kinds of
things you know but there's no free lunch right so there has to be built into what you're doing
deep assumptions about your data what is you're trying to accomplish and you have to be able to
surface those things so if somebody want to ask me if I wanted to really do machine learning what
do I need to learn I give them two answers one you need to learn the foundations and the fundamentals
yes you need to know the math you understand information theory you need to understand you know
what linear algebra is you need to not flinch or somebody mentions an eigenvector an eigenproblem
to you you need to get the math yes and you need to get the computing because it's a fundamentally
I'm computing pace discipline and computing is not math computing is not engineering computing is
not science you need to internalize the computing part of machine learning but just as important
and in many ways more important I believe is you have to really dive deeply into the empirical side
of it you have to get dirty with data you have to understand what the difficulties are in and
answering the questions you want to answer and you have to really realize that the questions you're
asking aren't necessarily the right ones most of what traps us in machine learning and in lots of
other things we do are the unspoken assumptions you have to surface what those things are and I
think that the best way of doing that is by getting your hands and your feet dirty so my classes
are designed to do that to force you to get into a messy ill-defined situation and to work your
way out of it so if you want to do data analysis if you want to do machine learning that's great it's
wonderful I can think of nothing more interesting to do but you have to get out of the textbooks you
have to play through the data and understand why it works the way that it does why the algorithms
have the effect that they do why you can learn some things you can't seem to learn other things
and that I think is actually really missing I think people either dive down the empirical side
and just try to get stuff working but with no understanding of the fundamentals they don't even
know how to ask the questions or they get so caught up in the fundamentals they don't worry
about whether it actually works in practice or how you would actually apply your ideas
and you have to do both especially in a field like machine learning they use all the
the social media tools that are out there to build community to talk to each other to talk to
the faculty to talk to the advisors they really build an entire community around what they're doing
and really the people who are in that community do well and the people who are not a part of that
community do poorly so one of the things that's important about the trips that I've been taking in
the traveling around the world I've been doing is making certain that we provide the tools so that
people can build local community that makes sense to them because that's how the learning happens
you guys you guys might be single-handedly propping up Google Plus I'm about helping Google Plus
I think people haven't been nice enough to Google Plus I've never heard of anyone else saying they're
using it well there's no lag because no one else is using it so you got that nice nice nice
so let's switch gears a little bit and talk about your research your research is your research focus
as I understand it anyways primarily around reinforcement learning or maybe you tell me tell us
what your research focus is nowadays and how you think of that area yeah so I I you know I
like I said earlier I really have been into AI machine learning for a very long time and it
took me a while to figure out what it was about it that I I really cared about and it was I was
easier to see when I was reflecting back on it what it is that you know I found interesting what
I didn't the kind of machine learning that I care about the name that we kind of give it in the
field is interactive machine learning and interactive AI I sometimes refer to as interactive AI
because I care about the AI problem as much as I do the the machine learning problem and what it
really is is about what happens when you instead of just saying oh look here's some data and I'm
going to look at that data and then I'm going to build a function and now I can do some prediction
you know that you're going to have a fundamentally incremental and interactive process so I want to
model human beings because I actually care about messy data and there's nothing messier than people
so I want human beings to be a part of the story of how I learned and when I say that I think
that people learn only through social communities or they learn best their social communities
I think that's actually true for our machines as well so that ends up looking a lot like and I
spend most of my time worrying about reinforcement learning so you're right about that and the
reason I care about reinforcement learning is that reinforcement learning is really I think trying
to do something big and hairy which is actually model what it means to be an autonomous agent so
when people ask me for the one sentence description of what it is that I what it is that I do I said
I care about interactive machine learning I care about building intelligent agents that have to
interact with other intelligent agents perhaps hundreds of thousands of them at a time and some of
those intelligent agents might be human they don't all have to be human but some of them will be
and since some of them are human you can't just go around sending XML packets back and forth you have
to actually engage in conversation you have to worry about the fact that human beings change over time
they're inconsistent they're errone they're highly non-marcovian there's all kinds of interesting
things about people and you need to be partners with people and you need to be long lived in order for
you to make progress in the area so that's what I really care about I care about building a system
that doesn't just predict whether you know a car is going to run into the side of the road or not
but actually deals with the fact that there are several million other people on the road at the
same time and you have to interact with those other people and you have to learn by talking to
them and interacting with them and so reinforcement learning is a subset of that yes that's right I
spend a lot of my time worrying about game theory I spend a lot of my time worrying about
marketing believe it or not about social behavior and how people tend to interact and
and work with one another and how you can convince them to to work with you or how you can deal
with them if they're trying to work against you so it's the whole gamut of what it means to interact
with other intelligent beings that have their own set of goals and and interest that might not be
the same as yours so tell me you mentioned marketing tell me more about how that plays into your
research or or maybe even give us an example of some of the research topics you've been looking
into recently so I like the marketing question so so I spend a lot of time with a friend of my
with one of my students is now a professor in North Carolina on something called drama management
so the short version of drama management is well you know you've played video games right
uh yep and you know the thing about video games is the interesting ones are ones where you're
you know involved an entire world and an entire story so what's actually going on is that you're
the person building the system for you is trying to build a story but most stories you just read
and you're a passive participant of and things like games you're actually an active participant
which means there's this tradeoff between your sense of autonomy and agency on the one hand
and me making certain that you have a good experience or a good story so you can actually think of
lots and lots of things like this you can think about conversations that you have in the interviews
and a podcast is like a story where you're negotiating back and forth and trying to
trying to figure out how to tell the the story that you want to tell while still allowing people
to say the things that they that they need to say or that they want to say you can think about
all kinds of examples like those can kind of go on for a while but the the the thing that the
thing there is that it turns out that because your player or the person who's participating
in building the story with you has their own ideas they might take your ideas off track they
might turn your murder mystery into a horror story they might turn your interview where you're
supposed to be going back and forth and having a conversation into a series of you ask me a
questions and I say yes or no and it's not much of an interview for you right so you have to
influence what the player is doing what the human participant is doing or otherwise
you don't end up with a good story that you want to have so there are two ways of doing that one
and I think you know you and most your listeners if you ever heard the expression a game that's on
rails sure so you know that's where well I'm sorry I'm just not going to let you go through this door
because if you do it breaks the video game it breaks the story and so you're on rails and the
thing about being on rails it takes you out of the story takes you out of the experience and that's
what a lot of people do and a lot of the drama management stuff is about that as well but there's
another way of doing and in fact the right way of doing it if you can make it work is you get the
other person the person you're interacting with you're trying to learn with the story you're trying
to get to participate in the story to actually accept your goals as his or her own and it turns out
marketing is very good at this so we build this kind of system where you get people to do the things
that you want them to do by putting them in situations where it's just natural for them to do those
things so rather than lock every door except one door in a room so you go through it I make something
happen maybe some noise or something interesting that makes you want to go through that door right
so um those kind of like themes of behavior like economics and incentives and things like that
coming into play here right yeah oh that's exactly right so in fact the example of this that
everyone's familiar with is one called scarcity uh-huh so that's where it turns out that people
if they believe that something is going away they suddenly find it more valuable right so anybody
with kids knows certainly anyone with kids ten years ago know that Disney has his habit of saying oh
we're going to release on DVD beauty in the beast and then we're never going to release it again uh-huh
and so everybody buys it right because it's about to go away or I mean black fridays like this right
you're gonna every year at the day after Thanksgiving you go to the store to buy a bunch of stuff
it doesn't make any sense whatsoever there are not even things you want to have but they're going
away you're gonna get a price right now it's on sale and so people react to that they can't help
themselves uh it's a scarcity is just one of one of the particular they very easy to understand
there's tons of others of these there's something called liking which is it turns out people will
do things for you if they if they like you uh people react to authority actually my favorite
example is something called consistency where if you can get someone to say something out loud
that they believe something they haven't almost pathological need to be consistent with it over time
so uh you know do you have anybody in your neighborhood who won't mold their lawn
um here's the way you get them to mold the lawn you wait till it's winter right and so all the
grass is you know kind of dead and it's all the the same height and you start up a conversation
and you say man you know it really looks great around here when it's like this you know everything's
the same color everything's the same height if you get the person to agree with that yeah it looks
really nice and it's like this the next summer they'll mold the lawn because they basically believe
that's the way it's supposed to be and you know it's really nice about it it's not that you got
them to mold the lawn it's that they believe that they are in complete control of the idea that
they're the ones who made the decision are in charge so that's a long story but the the short
version is we built systems like this uh that basically convinced people uh to do the things that
we wanted them to do we influenced them so i'm not using machine learning just to predict your
behavior i'm using machine learning to figure out how to intervene to get you to do something and
what i really want to happen is for you to believe it's your own idea so we built this little story
just a quick example we built this little story uh where the whole goal was to get you to buy a fish
at a market it's not the most exciting story in the world and there are lots of ways we can
influence you to do this with scarcity and various other things and and and so we had people
play this game and uh the people we tried to influence were much more likely than the people we
didn't um in buying the fish and doing the things that we tried to get done sure now that's
interesting but what's more interesting is that when you ask the people whether they felt manipulated
or not the people who were not manipulated were much more likely to say they felt they were being
manipulated than the people who actually were manipulated that's interesting why is that
because the whole the whole way this works the whole way the kind of psychology works is you
feel as if you have agency that you're making the decision when something goes on sale and you
decide you're gonna buy it you don't feel that you've been tricked into buying it you made the
decision to do it right and so what's really interesting this is why it's not just running the
data and doing machine learning it's actually understanding about human behavior it's understanding
behavioral economics it's understanding the way marketing tricks work it's it's all about getting
the person to make the decision you know themselves that they want to do this thing and then they have
agency they have control and they're much more likely to see it through the fact that you kind of
trick them into doing it is neither here nor there so quick note uh for listeners anyone that's
interested in digging deeper into some of these ideas uh there's a great book called Influence by
Robert Chaldeini that is super accessible and is covers all the things that you you talked about
consistency and scarcity things like that um but this brings up a uh question for me and that is
a lot of the a lot of the work we read about reinforcement learning nowadays is you're training
these agents to uh navigate a world right and then the work you're describing is you've got this
world that's essentially training the human to navigate it and there's an interesting complementariness
to it and I'm wondering if if that complementariness has been explored at all like the things that I'm
thinking around like adversarial networks like can you have the one training the other thinking
it's training the other does that make any sense is anything happening there oh yeah that's
actually very commonly doing it so the way so the thing that really got me into reinforcement learning
when I was a young graduate student a couple hundred years ago uh was actually playing games so
there was this guy named Saro who had built something called TD Gammon which was a particular way
of doing a reinforcement learning to to learn how to play backgammon and the way it learned to play
backgammon was through self-play so it it played both sides of the game uh and it learned by playing
itself how to get better uh and this is a well I think I'm pretty well understood sort of technique
for learning right you it's difficult to it if it's too hard you can't learn if it's too easy you
can't learn you need to be just about a little beyond your current level of understanding and so
yeah this kind of thing happens all the time now it is true that a lot of people who worry about
machine learning do not think about the kind of complementary nature that rather than there being an
agent that's training in an environment the environment could be in fact training the agent and people
don't always see that um in fact my biggest complaint or complaints not the right word but my
biggest um I don't know let's say complaint my biggest complaint about the way machine learning
is portrayed is that it's portrayed as a supervised learning problem you know I'm going to give you
a bunch of input output examples and you're going to learn the function that maps input output
and that's interesting but I think reinforcement learning is more interesting because it's this
bigger problem you don't have inputs and outputs all you've got is actions you can take and feedback
you get from the world and then from that you have to figure out how to behave that feels richer to
me even though in some sense they're equivalent the unsupervised learning is a very different way
of thinking about the world even though again sort of mathematically they're they're all kind of
equivalent and that kind of breadth of what machine learning and AI is is something that I don't
think we spend enough time really thinking about I think people tend to focus on the supervised
learning part instead of the reinforcement learning in the unsupervised learning part at least in
the kind of popular press okay so maybe taking a step back how do you think about the
current state of reinforcement learning like can you characterize the the major research
efforts or even is it possible to characterize the major research efforts into a handful of
directions and kind of who's doing what so I think there's kind well so the answers no it's
way too broad but there's a couple of things that I think are really interesting one is all this
work on deep networks and deep neural networks which you know is the the current thing that everybody's
really into and by the way it's really good work you know I know the people who've been pushing on
that for years and years and years and and they've really been able to to do a lot of interesting
things they they've got the kind of fundamentals right with the math and they're taking advantage of
the fact that we have insane amounts of data so that we can actually sort of take advantage of those
algorithms and do cool things a lot of what's going on at least in my world that people are paying
a lot of attention to is figuring out how to use the stuff that we know from deep networks and
deep learning and applying it to reinforcement learning okay and and rather than doing the
supervised learning take where you said well okay here's a state of the world tell me what to do
you're actually treating it the way you treat a reinforcement learning problem you're talking about
building value functions over what the states are in the world and what things are better and then
using that to figure out how to make a decision and use what you learn from making the decision
to affect your view of what's valuable in the world and kind of having each one feed into one
another and so recognizing that there's at least two parts of that problem instead of one part of
that problem is a really big deal and being able to marry the kind of math that's come out of
supervised learning has been I think really important that I think has has been really interesting
is push forward a lot of a lot of of what we've been able to to learn in the last couple of years
for sure the second thing which I think is interesting in part because it's it's my own work and
and place where I lived is very related to what we just got through talking about and it's this
interactive machine learning it turns out you know I mentioned earlier that there's no free lunch
right so for those of you don't know the no free lunch there and basically just says that
all algorithms are equally good and in fact not only are all algorithms equally good but none of
them are any better than behaving randomly and the reason that's true is because over all the
infinite number of problems that one could encounter you know any algorithm has just as good a
chance of doing well as that as any other algorithm but it turns out in practice we don't care
about every possible problem in the universe we care about a small set of problems in the universe
and what allows us to get leverage over that small set are built in assumptions about that
about that world so the problem of learning is difficult and in some ways impossible
but it turns out people are really good at solving the problems that people are really good at
what they're really bad about is explaining to you how they do what they do but they're really
good at solving these problems so a lot of what's been going on in the reinforcement learning world
in particular is taking advantage of people learning from getting people to tell you something
or to demonstrate something to you about how to do something so that you can learn much much faster
than you ever would and really what you're getting out of it is you're getting human beings the
human beings assumptions about the way the world works and you're taking advantage of those
assumptions to narrow down the to narrow down the search base so I'll give you really I'll give
you a really quick example so it turns out that people do not think about things and
atomic actions they tend to think about them in these big temporarily extended views of the world
so that takes something like Pac-Man right if you asked if I asked you to explain Pac-Man to me
you would be describing in terms of up down left right or what you would say things like oh well
look you need to get the power pellet you need to avoid the ghosts you need to you know you need to
do these four or five things and we run experiments on this where we ask people to to create buttons
that they would use if to to make Pac-Man go faster and they come up with these interesting
buttons these sort of long term things but dividing the world up like that not from up down left
right but into get the power pellet avoid the ghost is something that is very difficult to learn
from scratch but people have already figured this out so you build systems where people are able
to express to you those tricks those shortcuts those assumptions about the world and then you can
learn so much faster than you would ever be able to do on your own and that's kind of where we're
getting a lot basically taking assumptions from the world and getting them automatically from
humans I think that's incredibly important and one of the reasons I think it's important by the way
is because so many of the problems that we actually care about involve people right they involve
other people they involve interacting with people and so you have to understand the fundamental
assumptions that people are living and and you have to take advantage of them if you're ever going
to learn so those are two areas that I happen to think are are really cool in the reinforcement
learning space right now are we also learning how to enable the machines to make the assumption the
assumptions themselves like what's happening there yeah but the way they do it is they kind of do it
they do it by dint of observing the world right there's a Michael Lippman always says a couple of
things that I really like him and one is that you know if the person who's doing the programming
is doing all the learning and writing down the data structures then you're stuck right you need
the machine itself to be able to learn its own data structures through observation it needs to be
able to to build its own assumptions and its own models if you're always giving it the model then
it's always depending upon you to give it the model it has to be able to to build its its own model
so fundamental to that is this idea that that you're going to learn these you're going to build in
your own assumptions you're going to learn new assumptions and you're going to build models that
you're you're willing to adapt and so yes yes that that's definitely built into it it's definitely
a part of what's going on but the problem is absent nothing number absent anything you you can't
know where to start and so this gets his back full circle to this idea that learning is a
social exercise right as human beings we interact with other human beings that have a bunch of
assumptions they built the world together and they kind of know how it works and a lot of your
job is to figure out what it is they've built into the world as assumptions so that you can begin
to learn and our machines have to be able to do the same thing or otherwise they're not actually
living in the same world that we're living in. Interesting interesting one of the one of the
papers that I pulled up of yours on archive is a paper perceptual reward functions which is
pretty recently published and that goes into I think the the former of these two areas that you
mentioned where you're trying to map kind of the deep learning to you know a broader set of
problems. Can you describe that the paper? That is relatively new stuff there's a bunch of new
things that are coming coming out about about that at the student mine actually Edwards is really
buying into the fundamental idea there is that you know people have people's reward functions so
if you're a machine learning guy right you're particularly reinforcement learning guy you start
talking about rewards and you start talking about states and you divide the world up into the abstract
space and you go that's how you solve problems but we spend most of our time never actually worrying
about where these things come from they're just given to us and this paper is a part of actually a
larger body of work that that I've been I've been paying a little bit of attention to the last
couple of years of trying to figure out where those things come from are there principles about
where reward functions come from are there principles about where state comes from at least with
respect to the way human beings deal with it so that you can actually solve these problems in
general and be more robust to small changes in the environment one of the things that that's true
about reinforcement learning is you know there's a nice little math equation that you need in order
to figure out how to learn and determine value and it's very nice and it's very elegant but it's
actually quite fragile so if I were to build a system let's say a robot and I wanted this robot
to get from one end of a hallway to another and along the way it might do some other interesting
things I can construct all my little alphas and my my learning rates and I can put everything together
so that eventually it will learn and that it will do exactly what you want it to do and it won't get
so scared that something battle happened that it won't move and it won't get so distracted by
some interesting thing over here to the left that it'll never get to the end of the hallway I can
actually do that pretty well but then if I take that robot and all that it's learned and then I
make the hallway five inches longer it will stop working right because the math is very brittle
everything is set up just right so that everything kind of touches one another and what you
want to do is you want to build systems that are robust to that you want to build systems that
adapt to that and it turns out that human beings are very good I mean in fact optimized in some
ways for dealing with you know it's still a niche environment right we we do pretty well on earth
we don't we won't do pretty well on Mars right we don't do pretty well in space but but you know
it's still a rich environment that we're in and you want to build systems that can do that and so
the perceptual reinforcement learning stuff is about using what we get from our perceptions
directly as the as the notion of state and as our notion of reward that we try to get things to
look like what we see we try to imitate the things that we see through through our perceptions
rather than you know build simple or actually complex optimization functions that tell us you
know whether this thing actually is like that thing no you just think about what it is that you see
what it is that you're what it is you're receiving and there's this sort of larger philosophy
around that I'm actually quite excited about the work I think what it allows us to do is to stop
thinking about reinforcement learning as five you know a five tuple where you have to set the values
and start thinking about it as a larger programming problem where the whole thing is it's reinforcement
learning is not the thing that you start with it's the mechanism by which you happen to solve the
problem it is itself a programming language is itself a wave of viewing the world and you've got
a step back to the level of task and problem instead of thinking about solving this particular
equation interesting yeah I thought the example that was provided in the introduction to the paper
was a good one that was tip training robot to to fold origami like what you know what's the state
of an origami and how do you how would you represent that traditionally you know whereas the
what's natural for us as humans is to see a picture of the final result and you know how do
you define a you know a score metric or a distance metric from you know a given current origami
to this target yeah it's and it's a rich problem too because as soon as if I asked you to explain
me how to do origami which by the way I have absolutely no idea how to do something magic with
your hands paper you do a flurry of things and then suddenly there's a dragon I don't really
know what happens but you know you start saying oh well you start thinking about folding and you
start talking at this very high level just like with with Pac-Man right and the way of dividing up
that world is actually important because if you don't divide up the world in the right way you will
never in a million years a billion year in the lifetime of the universe actually solve the problem
because there's just too many possibilities right this goes all the way back to to language learning
and you know it turns out that people do not actually correct their children right so you don't
get any negative examples hardly at all when you're a kid and yet somehow children learn to speak
their particular language even though nobody's telling them when they're you think you are but you
don't actually correct your children and we can prove to you mathematically that you can't learn
under those circumstances so the only way it can be happening is if the world has been divided
up in the nice little ways and there's only a few possibilities and you're searching over those
few possibilities because the world's already been divided up for you if you have to go to the trouble
of dividing up the world yourself then you're just there is enough time there aren't enough examples
there isn't enough time yeah yeah yeah so now at the risk oh go ahead no I'm just gonna say so to
me if you pop up to the AI level instead of the machine learning level right uh that's really the
interesting thing right but what's really exciting about AI right now what's really exciting about
machine learning right now is that we finally have enough computing power we finally have enough
mathematical sophistication and we finally have enough data that we can actually start solving
really hard problems where we're going to be forced to move beyond you know the equation
that we wrote down in 1965 that hasn't changed to thinking about bringing in all of these other
things whether it's marketing and behavioral economics whether whether it's game theory whether
it's well engineering whether it's control you know we actually going to have to bring in tons of
other things in order to solve the problems we're now at the point where we can actually do that
so we're actually meeting in the middle so that so this is why this is an exciting time for me
nice nice so at the risk of asking a question that we've kind of touched on in a couple different
ways already for someone who wants to dig deeper into the kind of stuff we were just talking about
interactive machine learning and AI and reinforcement learning are there any places that you would
point them to get started well I would start with just a basic machine learning class particularly
one that covers reinforcement learning if you really are interested in reinforcement learning
as a topic I mean you know rich sudden's book is freely available online it's a great place
to start to kind of understand what's going on the class that I teach with Michael Litman is
freely online there's lots and lots and lots and lots and lots of examples out there I would
actually start with that and get the basics there's survey papers I mean Google is your friend in
this case but if you're the if you're the kind of person who wants to have someone give you a
nice brief overview of what's going on then you know hey start with my class just pick Michael
Litman you can go to your desk you can get it for free just sort of skim through it and watch through
it and you'll you'll figure out from there where to go and I would really I would really encourage
people to pick a problem that they find interesting if you games are the things for you then start
looking up the deep learn the deep reinforcement learning work on games there's a there's a bunch
of work done recently on solving most of the Atari games using deep learning that's really
interesting stuff the problem with starting there though is that oh now you have to know what
convolution nets are and you know you're you're going to find yourself distracted for nine
months while you learn enough math to figure out what's going on I would actually start top down I
would start thinking about the problems what the issues are before I get so deep into the to the
math that I get lost you don't want to lose the forest for the trees here and it is very easy
to lose the forest for the trees because there's so much kind of interesting and very difficult
math that's underneath all of this but really you want to keep sight of the goal right which is
to build something that can learn over time can adapt over a year it can live for 20 years
and continually learn and adapt and think about what that would mean think about what it would
mean to you as a person and then start asking what kind of background you would need to have in
order to build a system that does that that's great and I'll include links to a bunch of the things
that you mentioned in the show notes um oh so I would let me add one thing to show notes
you mentioned the book influence I would also recommend the media equation
to media equation that is a fantastic book it's one of these it's a short book about how human
beings actually behave and how it turns out that people will treat machines as if they're humans
even though they know better because they'll treat anything that acts like it has intention
as if it has intention and I think that fact alone should influence everyone who's thinking
about building systems that have to interact with humans interesting we're not even all that good
at describing intention other people the thought of applying it to machines is uh and we're going
to have to work on that I actually think it's the other way around I think the problem is we're
incredibly good at describing intentions to other people it's just not always the right intentions
ah yeah yeah yeah um great so I think we uh this has been a great discussion um I appreciate you
getting together with me for it especially on a Saturday morning and don't want to monopolize
your Saturday so we'll wrap things up here anything else you'd like to uh toss out
no just I really enjoy this and we should have this conversation again
absolutely absolutely um and then for folks that want to get in touch with you
they find you on google plus well if you go to google plus I'm the one guy who's still there
so just send me an email it may take me a while to respond that I'm more than happy to respond
just google in bell c.katek.edu okay and are you on twitter or any of the the the lesser use
social networks I have a I have a twitter account uh and occasionally I even use it uh but really
emails the only way to really get to me I'm unless you have my cell number and I'm not giving
you my cell number nice nice all right great uh well thanks so much Charles really appreciate it um
and uh next time look absolutely awesome
all right everyone that's our show for today thanks so much for listening
if you're one of our lucky winners or runners up please reach out to me
at sam at twimlai.com a bunch of you have asked hey what's up with the newsletter
no you haven't missed anything I've just been crazy busy and haven't had a chance to get one out
I'm so sorry about that I'm still working on it and I'll keep you posted thank you so much for
your support and catch you next time
