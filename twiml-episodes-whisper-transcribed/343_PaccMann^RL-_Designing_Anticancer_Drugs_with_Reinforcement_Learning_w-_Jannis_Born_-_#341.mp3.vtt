WEBVTT

00:00.000 --> 00:13.400
Welcome to the Twimal AI Podcast.

00:13.400 --> 00:22.120
I'm your host Sam Charrington.

00:22.120 --> 00:24.080
Hey what's up everyone?

00:24.080 --> 00:26.620
Happy New Year and Happy New Decade.

00:26.620 --> 00:31.980
I am pumped to get 2020 kicked off by announcing a couple of new educational collaborations

00:31.980 --> 00:37.420
to add to our current array of Twimal community programs.

00:37.420 --> 00:39.580
The first of these starts next week.

00:39.580 --> 00:43.780
We are super excited to be collaborating with research scientist and instructor Robert

00:43.780 --> 00:50.620
Ness to bring his core sequence, causal modeling and machine learning to the Twimal community.

00:50.620 --> 00:55.460
Cosality has become a very hot topic in the ML&A eye space, but there are relatively few

00:55.460 --> 01:00.540
instructional resources geared towards data scientists and ML developers.

01:00.540 --> 01:04.780
Furthermore, this is the first time we'll have the opportunity to host a course instructor

01:04.780 --> 01:10.020
leading a study group on our platform so this group should be a ton of fun.

01:10.020 --> 01:14.740
The study group will meet at 8 a.m. U.S. Pacific time on Saturdays and to get things kicked

01:14.740 --> 01:22.380
off, Robert and I are hosting an overview session next Saturday, February 1st at that time.

01:22.380 --> 01:27.740
Know how topic in our community is ML&A eye platforms and more broadly, strategies for

01:27.740 --> 01:32.020
efficiently developing and deploying machine learning and deep learning models inside

01:32.020 --> 01:33.180
the enterprise.

01:33.180 --> 01:38.380
I've hinted at this next study group before and I'm mentioning it again now since we're

01:38.380 --> 01:39.380
getting close.

01:39.380 --> 01:45.220
I've partnered with IBM to bring the new IBM AI enterprise workflow specialization,

01:45.220 --> 01:51.060
a six course certificate granting sequence recently published on Coursera to you, our

01:51.060 --> 01:52.060
community.

01:52.060 --> 01:56.340
I'll personally be taking this course sequence and hosting a study group for those of you

01:56.340 --> 01:58.020
who'd like to join me.

01:58.020 --> 02:03.620
If you're doing interested in or would like to learn more about data science, ML or AI

02:03.620 --> 02:08.500
in a real world enterprise context, I'd encourage you to check this one out.

02:08.500 --> 02:12.820
I'll be hosting an informational session on the course in early February.

02:12.820 --> 02:18.820
For more information on or to join either of these programs, visit twimmelai.com slash

02:18.820 --> 02:20.940
learn 2020.

02:20.940 --> 02:22.860
And now on to the show.

02:22.860 --> 02:34.100
Hey everyone, I am here in Vancouver for NERPs continuing our conversations with some

02:34.100 --> 02:40.820
of the researchers that are at and participating in this amazing conference.

02:40.820 --> 02:43.500
And I've got the pleasure of being seated with Janis Bourne.

02:43.500 --> 02:50.100
Janis is a PhD student at ETH in Zurich and the IBM research in Zurich.

02:50.100 --> 02:52.780
Janis, welcome to the twimmelai podcast.

02:52.780 --> 02:54.780
Thank you so much Sam for having me.

02:54.780 --> 02:57.900
Why don't we start out by having you share a little bit about your background.

02:57.900 --> 03:03.300
You're coming at things from a cognitive science perspective, but your poster here is

03:03.300 --> 03:05.140
on reinforcement learning.

03:05.140 --> 03:09.620
How did you get interested in this field and how do all those threads come together?

03:09.620 --> 03:10.620
Right.

03:10.620 --> 03:11.620
Yes.

03:11.620 --> 03:12.620
So you're right.

03:12.620 --> 03:16.660
I'm having a background in cognitive science and in computation in your science.

03:16.660 --> 03:24.860
And so I've been like focusing on brain research for my past five years of education.

03:24.860 --> 03:32.540
And now recently I've been doing more work on computational systems biology and specifically

03:32.540 --> 03:38.260
on cancer and cancer trying to understand mechanisms of how cancer work and how we can

03:38.260 --> 03:41.180
find new treatments against cancer specifically.

03:41.180 --> 03:47.140
And in this work, I've been using mostly deep learning techniques and this will be part

03:47.140 --> 03:51.460
of like my presentation here at this conference also.

03:51.460 --> 03:54.660
And so yeah, so how do those things go together?

03:54.660 --> 04:00.420
So I think like many people think it's in a way weird if you come from brain sciences and

04:00.420 --> 04:03.900
then you're going to machine learning, right?

04:03.900 --> 04:07.660
And this is something where I would say it's like it's a very obvious thing to do in

04:07.660 --> 04:12.300
a way because if you look back into the history of machine learning, where it all came from,

04:12.300 --> 04:18.140
like mecaloch and pits, the first artificial neuron and then a few years later, Frank

04:18.140 --> 04:20.700
Rosen, Bella, the perceptron.

04:20.700 --> 04:26.460
And so these were all computational neuroscientists and they were in the end really trying to understand

04:26.460 --> 04:28.020
how the brain works.

04:28.020 --> 04:33.500
And they basically developed the the the fundament of the field of machine learning.

04:33.500 --> 04:38.420
And so at some point this community then in a way, it split up into two groups.

04:38.420 --> 04:43.340
And one group was more trying to actually understanding how the brain works.

04:43.340 --> 04:48.180
And the other group was more interested in solving the problems, right?

04:48.180 --> 04:53.340
And from this from this community, the machine learning community evolved into, but where

04:53.340 --> 04:57.580
is computation neuroscience right now, it's still a field, it's still out there.

04:57.580 --> 05:02.180
It's has been it's separating more and more from the machine learning community.

05:02.180 --> 05:06.580
I'm still out there and originally it has been one big community.

05:06.580 --> 05:10.980
And so therefore, I think it's quite natural to have this process.

05:10.980 --> 05:11.980
Yeah.

05:11.980 --> 05:18.500
Yeah, I think particularly here at NURBS, I have the opportunity to speak with many folks

05:18.500 --> 05:25.260
that are kind of working on that edge of cognitive sciences, brain sciences, and both using

05:25.260 --> 05:29.860
that to inform the way we think about machine learning, using machine learning to validate

05:29.860 --> 05:32.780
some of the biological theories.

05:32.780 --> 05:40.220
It was maybe more novel is coming from cognitive science and brain science and applying machine

05:40.220 --> 05:45.260
learning to developing cancer pharmaceuticals, how did that come about?

05:45.260 --> 05:46.260
Yeah.

05:46.260 --> 05:47.260
How did that come about?

05:47.260 --> 05:48.220
It's a good question.

05:48.220 --> 05:55.580
So like if you look at brain sciences, there's really this problem of seeing the brain,

05:55.580 --> 06:02.100
which is arguably the most complex thing we have in the universe, and seeing like observing

06:02.100 --> 06:08.100
this brain and trying to understand this brain from a different like scales, a different

06:08.100 --> 06:09.540
spatial scale, so to speak.

06:09.540 --> 06:14.940
So you can think about the brain in a very abstract and cognitive ways, thinking about

06:14.940 --> 06:18.500
cognitive phenomena like language and memory and those things.

06:18.500 --> 06:23.620
And you can think about it more from a neural perspective, like how do actually like what

06:23.620 --> 06:26.500
is the most fundamental unit of information processing?

06:26.500 --> 06:28.620
How do these units interact?

06:28.620 --> 06:30.660
How does information arise?

06:30.660 --> 06:34.420
And so like these are two fundamentally different approaches.

06:34.420 --> 06:38.660
And so I like in the first three years of my studies, I focused on cognitive science,

06:38.660 --> 06:42.980
which has more this top down approach, like thinking from the big concepts and then down

06:42.980 --> 06:45.060
towards the implementation level.

06:45.060 --> 06:49.860
Whereas computational neuroscience, they have more like this bottom up perspective.

06:49.860 --> 06:54.820
In the end, they're trying to solve the same problems, but they start first with the basic

06:54.820 --> 07:01.540
building blocks, like having a biologically plausible neural network model that imitates

07:01.540 --> 07:05.020
basic behavior of neurons and then they try to scale it up in order to understand more

07:05.020 --> 07:07.860
complex cognitive phenomena.

07:07.860 --> 07:12.740
And so like these two fields, they really, they help each other and they need to work

07:12.740 --> 07:15.500
together in order to understand how the brain works.

07:15.500 --> 07:20.980
And so after my undergrad studies, I really had the feeling, okay, I need something more

07:20.980 --> 07:22.060
solid.

07:22.060 --> 07:25.220
And I really wanted to have this bottom up perspective from a computer competition in

07:25.220 --> 07:29.260
your science, which then I got in my masters.

07:29.260 --> 07:35.580
And so afterwards, I mean, I had to say that I was keen to explore applications of machine

07:35.580 --> 07:40.620
learning, because while I mean while studying the brain, I got really interested more and

07:40.620 --> 07:45.380
more into the whole field of data science and machine learning, and I wanted to apply

07:45.380 --> 07:51.300
those techniques, but at the same time, I wanted to, I wanted to still somehow work with

07:51.300 --> 07:54.180
a human body and with humans in general.

07:54.180 --> 08:01.740
So this is how, yeah, how I came about doing cancer, cancer drug modeling.

08:01.740 --> 08:10.900
And so the, the poster is titled Pac-Man, yeah, tell us about Pac-Man, yeah.

08:10.900 --> 08:14.140
So Pac-Man is a frame, I mean, it's an acronym.

08:14.140 --> 08:18.820
So spelled with a double C and double N. So it's an acronym.

08:18.820 --> 08:25.020
We came up during my, like about a year ago, during my master thesis, for a prediction

08:25.020 --> 08:30.180
of anti-cancer compound sensitivity with multimodal attention-based neural networks.

08:30.180 --> 08:35.660
And so like when my supervisor came about with this acronym at one of the very long nights,

08:35.660 --> 08:38.540
we spent in the lab, we like, okay, there's no discussion.

08:38.540 --> 08:41.380
This is going to be the name for the project.

08:41.380 --> 08:45.220
So quite funny how, how this came about.

08:45.220 --> 08:51.540
So, and we, what we're doing in this work, that was the first step of, of the project

08:51.540 --> 08:59.300
I'm presenting here at the conference, we were trying to basically forecast the effect,

08:59.300 --> 09:05.340
the inhibitory effect of a molecule against a specific type of cancer.

09:05.340 --> 09:11.060
And so we are treating this problem of predicting cancer drug sensitivity really as the

09:11.060 --> 09:13.740
property of a pair.

09:13.740 --> 09:19.100
And the pair is like composed of the molecule itself, the chemical, the drug that you give

09:19.100 --> 09:20.420
to the patient.

09:20.420 --> 09:24.900
And then the particular tumor cell that you want to target.

09:24.900 --> 09:28.980
Because cancer is really like, I mean, it's a family of diseases.

09:28.980 --> 09:29.980
And it is so diverse.

09:29.980 --> 09:35.180
I mean, there has probably never been two types of cancer that have been exactly alike.

09:35.180 --> 09:42.100
Because the cascades of mutations you have, they vary like heavily in between of every

09:42.100 --> 09:43.540
individual patients.

09:43.540 --> 09:51.260
So it's really unfeasible to try to investigate whether a molecule has some anti-cancer effect

09:51.260 --> 09:52.340
in general.

09:52.340 --> 09:58.460
So you really need to treat this problem as the property of a pair.

09:58.460 --> 10:05.300
So is this drug like has it inhibitory effect against the specific type of cancer in the

10:05.300 --> 10:07.620
patient individually?

10:07.620 --> 10:11.620
One of the questions that comes up first for me is one of the techniques you're applying

10:11.620 --> 10:13.140
here is reinforcement learning.

10:13.140 --> 10:17.700
How does that play into achieving that goal?

10:17.700 --> 10:19.460
So it comes about in the second step.

10:19.460 --> 10:25.220
So the first step was really just trying to predict the sensitivity.

10:25.220 --> 10:28.540
So the efficacy of this of a drug.

10:28.540 --> 10:37.060
And so what we did in a consecutive step after we had built this model, what we asked ourselves

10:37.060 --> 10:42.500
was like, wow, wouldn't it be amazing to have a model that can generate new drugs?

10:42.500 --> 10:46.940
And that can come up and propose new anti-cancer candidate drugs.

10:46.940 --> 10:51.980
Because in the whole pharmaceutical industry, there's a huge productivity decline in the

10:51.980 --> 10:59.380
last few decades and the estimated costs that you have per new drug, they're estimated to

10:59.380 --> 11:01.500
be 2 to 3 billion USD.

11:01.500 --> 11:05.820
And most of these drugs that are then FDA approved and approved on the market, so they're

11:05.820 --> 11:12.380
really specific only for very few types of diseases or even one disease only.

11:12.380 --> 11:20.460
So the cost in R&D that go our, like, spend in this business, it's just huge.

11:20.460 --> 11:26.300
And so we, I mean, we came up with this framework where reinforcement learning is really

11:26.300 --> 11:33.140
core and component, where we're trying to design anti-cancer drugs specifically for individual

11:33.140 --> 11:35.380
patients or groups of patients.

11:35.380 --> 11:42.340
So we're trying to envision a precision medicine perspective here, where we're not trying

11:42.340 --> 11:46.540
to generically come up with new anti-cancer candidate drugs.

11:46.540 --> 11:53.740
But we try to, like, in the design process itself, we try to tailor the molecule, the

11:53.740 --> 11:58.340
drug specifically, to the need of the patient himself or herself.

11:58.340 --> 12:02.420
And so for this framework, we use a reinforcement learning machine.

12:02.420 --> 12:03.420
Okay.

12:03.420 --> 12:08.900
You also mentioned in the title of the poster transcriptomic data.

12:08.900 --> 12:10.460
What is transcriptomic data?

12:10.460 --> 12:11.460
Right.

12:11.460 --> 12:17.780
So you can think about transcriptomic data as basically the expression of every single

12:17.780 --> 12:21.820
gene that you have in your body, like you know about the human genome.

12:21.820 --> 12:26.500
And so part of the human genome encode for specific proteins.

12:26.500 --> 12:30.020
And these expression of these proteins, you can measure in the cell, there's different

12:30.020 --> 12:31.500
techniques to do that.

12:31.500 --> 12:38.020
So the most commonly used technique and the technique that was used to measure the data

12:38.020 --> 12:44.340
we work with is called RNA sequencing data, where you measure basically the mRNA snippets

12:44.340 --> 12:45.540
in the cell.

12:45.540 --> 12:50.140
And so from this, you can infer basically which genes were expressed to what extent.

12:50.140 --> 12:56.300
So you end up, if you do the sequencing step, you end up with a vector of about 20,000

12:56.300 --> 12:57.980
genes.

12:57.980 --> 13:00.420
And for each gene, you would have an expression value.

13:00.420 --> 13:07.060
This is usually just an integer, like how many times did you find this as the snippet

13:07.060 --> 13:08.060
in the sample?

13:08.060 --> 13:13.460
And then so this vector, you can really think of it as a fingerprint of the cell.

13:13.460 --> 13:17.180
So it's a proper characterization of the cell.

13:17.180 --> 13:21.220
There's a different types of omics data.

13:21.220 --> 13:23.660
So this is transcriptomic data, right?

13:23.660 --> 13:29.820
There's also genomics data, which directly measuring gene data.

13:29.820 --> 13:35.940
And there's also a proteomics data where you actively measuring the proteins.

13:35.940 --> 13:42.700
So the, you know, starting from that first step, you're kind of starting with trying to

13:42.700 --> 13:46.940
predict the effect of a drug on the cell.

13:46.940 --> 13:53.180
Is it, is this a supervised learning type of a problem that you, is that the way you've

13:53.180 --> 13:54.180
framed it?

13:54.180 --> 13:55.180
Yes, yes.

13:55.180 --> 13:56.180
This is supervised learning.

13:56.180 --> 13:59.140
So it's a regression problem in the end.

13:59.140 --> 14:04.020
It's quite simple in the fact that we're really trying to predict a single property.

14:04.020 --> 14:06.180
And this is the IC50 value.

14:06.180 --> 14:12.260
So this is the micro molar concentration of a drug that you need in order to kill 50%

14:12.260 --> 14:13.460
of the cells.

14:13.460 --> 14:18.180
So, and this is the thing you're trying to minimize.

14:18.180 --> 14:23.300
So if you have a smaller concentration of the drug, then this drug is more effective,

14:23.300 --> 14:24.300
right?

14:24.300 --> 14:32.100
So your training data comes from measurements that have been done applying drug, you know,

14:32.100 --> 14:34.500
different types of drugs to different types of cells.

14:34.500 --> 14:35.500
Exactly.

14:35.500 --> 14:39.700
So there's huge databases for, for this problem.

14:39.700 --> 14:44.980
So the two we are working with are GDSC and CCLE.

14:44.980 --> 14:49.380
There's a standard database in the field and they, they usually don't work with patients

14:49.380 --> 14:54.940
directly because you can't try like several hundred drugs on, on the same patient, right?

14:54.940 --> 14:57.980
But they work with them, so called cancer cell lines.

14:57.980 --> 14:59.740
So these are abstractions.

14:59.740 --> 15:03.700
These are cell lines that have been growing in the lab in petri dishes for quite some

15:03.700 --> 15:04.700
time.

15:04.700 --> 15:08.260
And you apply these drugs, I mean, to, to these cancer cell lines.

15:08.260 --> 15:11.900
So these cells have been taken originally at some point from humans, but they have been

15:11.900 --> 15:14.100
growing in the lab for a long time.

15:14.100 --> 15:16.860
And they have been mutations induced downstream.

15:16.860 --> 15:23.620
So they are proxies of real cancer, but it's, I mean, it's an active field of research

15:23.620 --> 15:29.060
to whether or not on to what extent they have problem proxies.

15:29.060 --> 15:35.700
And so in the creation of this data set, somebody carefully administered small quantities of

15:35.700 --> 15:40.900
these drugs and noted the point at which half of the cells were, or just over half of

15:40.900 --> 15:46.500
the cells have died off, and that's the proxy for the efficacy of the drug.

15:46.500 --> 15:47.500
Absolutely, right?

15:47.500 --> 15:48.500
Okay.

15:48.500 --> 15:57.260
And so you, you built a model to predict the performance of new, new arbitrary drugs.

15:57.260 --> 16:00.820
And how do you kind of featureize the drugs?

16:00.820 --> 16:01.820
Right.

16:01.820 --> 16:05.420
So that's a good, it's a good question, because in the end, the drug is immolical, so this

16:05.420 --> 16:13.300
is a graph and graphs are rather difficult to represent in a deep learning regime.

16:13.300 --> 16:21.460
So what traditionally has been done by chemoinformaticians about a few decades ago is they would derive molecular

16:21.460 --> 16:22.460
fingerprints.

16:22.460 --> 16:29.260
These are binary vectors, and in these binary vectors, every item would basically specify

16:29.260 --> 16:31.380
the presence of a certain feature.

16:31.380 --> 16:33.100
And this was completely handcrafted.

16:33.100 --> 16:39.260
So one feature could be like, do I have ax aromatic rings in this molecule or not something

16:39.260 --> 16:40.260
in this?

16:40.260 --> 16:44.260
So, but this is a very arbitrary and handcrafted representation of a molecule.

16:44.260 --> 16:47.260
And the field of deep learning has been moving forward.

16:47.260 --> 16:54.380
So what, I mean, one great thing that deep learning really brought to us is like advances

16:54.380 --> 16:56.860
in natural language processing, right?

16:56.860 --> 17:02.060
So, and a different representation of a molecule can just be a text representation.

17:02.060 --> 17:07.460
So there's certain languages that most commonly use languages called smiles, and smiles

17:07.460 --> 17:13.540
as an in-line notation of molecule, of molecules where you would basically write down and list

17:13.540 --> 17:14.940
of atoms and bonds.

17:14.940 --> 17:20.620
So you basically, you think about the molecule as a graph, and then you do it traverse through

17:20.620 --> 17:24.740
the graph, and you denote step by step the atoms and bonds.

17:24.740 --> 17:30.260
Kind of like a much more rigorous approach to saying H2O for water.

17:30.260 --> 17:31.260
Yes, absolutely.

17:31.260 --> 17:32.260
Okay.

17:32.260 --> 17:34.460
And this is the type of representation we're working with at the moment.

17:34.460 --> 17:35.460
Oh, interesting.

17:35.460 --> 17:42.180
So you've totally skipped the accepted formalism and are primarily working with this natural

17:42.180 --> 17:43.940
language approach.

17:43.940 --> 17:49.700
What's the thinking behind that is that is it that the natural language has more expressiveness

17:49.700 --> 17:55.140
somehow than the binary representation, or is it something else?

17:55.140 --> 18:01.620
So I mean, one thing that's great is that it is much more like it is closer to the actual

18:01.620 --> 18:03.380
representation of the molecule.

18:03.380 --> 18:05.780
It is much easier to understand for any chemist.

18:05.780 --> 18:11.420
Any chemist can look at the smiles notation and can understand the molecule, can draw the

18:11.420 --> 18:14.940
molecule where this does not hold for a fingerprint.

18:14.940 --> 18:19.660
Another advantage of smiles is that it enables data augmentation.

18:19.660 --> 18:24.460
So data augmentation is commonly used everywhere in deep learning, like images, you make rotations

18:24.460 --> 18:26.700
or whatever.

18:26.700 --> 18:31.580
So what you can do is, apparently, if you think of a molecule as a graph, there's not

18:31.580 --> 18:33.340
a single graph traverse, right?

18:33.340 --> 18:34.860
But you can start at different points.

18:34.860 --> 18:35.860
Start at different points.

18:35.860 --> 18:36.860
Exactly.

18:36.860 --> 18:41.300
And then you would get a completely different, not completely different, the atoms and

18:41.300 --> 18:44.740
bonds would be the same, but the ordering would be different and you would get a different

18:44.740 --> 18:45.740
text representation.

18:45.740 --> 18:46.740
Right?

18:46.740 --> 18:50.420
Whereas on the fingerprint, theoretically, they should all resolve to the same fingerprint.

18:50.420 --> 18:51.420
Absolutely.

18:51.420 --> 18:52.420
They do.

18:52.420 --> 18:53.420
They all resolve to the same.

18:53.420 --> 18:57.700
So you have a unique representation for the molecule, in the case of a fingerprint, whereas

18:57.700 --> 19:06.540
in case of a smiles, you can really exploit this smiles augmentation, basically, by exploring

19:06.540 --> 19:11.580
different graph traverse in order to augment the performance of you.

19:11.580 --> 19:12.580
Better generalize.

19:12.580 --> 19:15.700
Yes, it would generalize much better.

19:15.700 --> 19:21.580
And so the advantage of working with text really is also that you can more or less directly

19:21.580 --> 19:29.100
transfer all of the advances of natural language processing, like attention-based models, which

19:29.100 --> 19:33.060
by the way, are absolutely great because they leverage interpretability methods.

19:33.060 --> 19:40.140
So attention, this super commonly used technique in NLP, right, where the model really highlights

19:40.140 --> 19:46.500
only specific parts of the input sequence in order to produce the next output token.

19:46.500 --> 19:51.180
For example, a language translation task, right, or in order to produce a prediction.

19:51.180 --> 19:54.820
And so we can also leverage these techniques into our model.

19:54.820 --> 20:02.100
And this is great because you can understand the reasoning of the model post-talk, basically.

20:02.100 --> 20:08.900
So what we can do with this model is we can understand that the model came to a specific

20:08.900 --> 20:14.380
prediction because it was focusing on a specific substructure of the molecule, right.

20:14.380 --> 20:18.620
And then we can check in the literature, this like a known substructures, it known to have

20:18.620 --> 20:20.820
certain chemical properties.

20:20.820 --> 20:23.900
And in this way, we can validate the performance of the model.

20:23.900 --> 20:24.900
Okay.

20:24.900 --> 20:31.060
Now, others doing similar types of applications have taken, you know, whatever their input

20:31.060 --> 20:38.060
domain is and kind of projected it to like an embedding space and finding related molecules

20:38.060 --> 20:43.940
in that embedding space and then using that to identify candidate, you know, materials,

20:43.940 --> 20:46.420
I think is the example that I'm thinking of.

20:46.420 --> 20:48.500
Is that something that you've looked at as well?

20:48.500 --> 20:49.500
Yes.

20:49.500 --> 20:54.860
So this comes about in the in the drug generation part, which is the second part of the project

20:54.860 --> 20:58.780
that we're trying to design new cancer drugs.

20:58.780 --> 21:04.540
And so what we're doing there is we use a deep generative model, specifically variational

21:04.540 --> 21:06.260
auto encoders.

21:06.260 --> 21:12.820
And what is really awesome, if you're working with variational auto encoders is this property

21:12.820 --> 21:19.940
of the latent space and the fact that like similarity in this latent space, which is

21:19.940 --> 21:26.540
in a way the embedding that you generate for a specific input in our case, a molecule,

21:26.540 --> 21:36.340
that similarity in this in this in this latent space will correspond to a structural similarity

21:36.340 --> 21:40.580
of the molecule, if you decode the points in the latent space.

21:40.580 --> 21:45.060
So this is like the drug molecule in this case, yes, yes.

21:45.060 --> 21:47.620
So I mean, it seems like a supernatural property, right?

21:47.620 --> 21:51.700
You would expect this that similarity in this latent space, although it is hidden somewhere

21:51.700 --> 21:54.380
in the network, it will resemble something meaningful.

21:54.380 --> 21:56.740
But apparently this is not necessarily the case.

21:56.740 --> 22:01.300
So you have to specifically enforce this with a specific constraints that you have to apply

22:01.300 --> 22:05.500
during training this model, but they, and this is like the core property of variational

22:05.500 --> 22:08.660
auto encoders, but this doesn't come along naturally, basically.

22:08.660 --> 22:09.660
It's not for free.

22:09.660 --> 22:14.340
You have to figure out what the relationship is between two drugs that causes them to

22:14.340 --> 22:19.500
have a similar effect on the target molecule, yes, in a way, or the target cell.

22:19.500 --> 22:20.500
Yeah.

22:20.500 --> 22:26.260
So I mean, what you can do, and this would be a pure chemistry model, this doesn't necessarily

22:26.260 --> 22:30.260
need to have anything to do with cancer or with drugs.

22:30.260 --> 22:34.340
It can be the same way for materials, like all kinds of chemicals, basically.

22:34.340 --> 22:39.260
So what you can do, for example, is you have a certain point in the latent space, you decode

22:39.260 --> 22:40.260
a molecule from it.

22:40.260 --> 22:42.300
It is some kind of molecule.

22:42.300 --> 22:43.820
Let's say it's aspirinous, right?

22:43.820 --> 22:44.820
It could be.

22:44.820 --> 22:48.660
So and then you take a different point and you decode from there, and let's say you take

22:48.660 --> 22:50.660
it, you get paracetamol, right?

22:50.660 --> 22:55.300
And then what you can do is you can in the latent space, you can traverse, you can basically

22:55.300 --> 23:02.740
make a walk, like a walk from this point of paracetamol to the point of aspirin.

23:02.740 --> 23:09.100
And you can decode intermediate positions, and you will end up with molecules that are

23:09.100 --> 23:15.620
in a way intermediate mixtures in between of aspirin and paracetamol.

23:15.620 --> 23:22.740
So and this is a super nice property for everybody working in drug discovery, because you can

23:22.740 --> 23:26.500
much better explore the chemical space.

23:26.500 --> 23:30.540
And so this is something that, I mean, it's not obvious, but it is extremely important

23:30.540 --> 23:34.900
to have better models and techniques to explore the chemical space.

23:34.900 --> 23:38.900
The size of the chemical space, it is about 10 to the, it's estimated to be around 10

23:38.900 --> 23:40.740
to the 60 molecules.

23:40.740 --> 23:42.300
So this is massive.

23:42.300 --> 23:45.860
The amount of atoms in the universe, I'm not sure it's like a few orders of magnitude

23:45.860 --> 23:47.660
higher, but it's not crazy.

23:47.660 --> 23:52.180
I don't, I think it's below 10 to the 100, I'm not, I would need to look it up.

23:52.180 --> 23:59.420
But so, and you need to have techniques to navigate this space meanfully, specifically

23:59.420 --> 24:07.700
at a time where, where we have generated and synthesized already so many compounds,

24:07.700 --> 24:11.700
like I think it's in the order of 10 to the nine or 10 to the 10 that have ever been

24:11.700 --> 24:18.700
synthesized and tested, but it is completely unfeasible to just continue like a random sampling

24:18.700 --> 24:19.700
process.

24:19.700 --> 24:20.700
Right.

24:20.700 --> 24:26.260
And therefore, you really need to have this guided, guided sampling and guided navigation.

24:26.260 --> 24:34.540
Kind of going back to that phase two of your project, you are applying, you mentioned

24:34.540 --> 24:41.060
a generational or a generative rather model as kind of an intro to where the reinforcement

24:41.060 --> 24:42.060
learning comes in.

24:42.060 --> 24:43.460
What's the connection between those two?

24:43.460 --> 24:44.460
Yeah, absolutely.

24:44.460 --> 24:49.140
So, this is the part of the project where I'm really most excited about, is about generating

24:49.140 --> 24:51.340
new drugs.

24:51.340 --> 24:56.140
And so not so much the old prediction model that I've been talking about before.

24:56.140 --> 25:02.780
So what we're really trying to do there is that given the transcriptomics profile of

25:02.780 --> 25:07.260
cancer patients, so this kind of theory work in the following way, that you have a medical

25:07.260 --> 25:14.700
doctor making a biopsy from a tumor cell, this biopsy is then sequenced.

25:14.700 --> 25:17.620
You get the gene expression, this is the transcriptomics data.

25:17.620 --> 25:19.500
You put it into the model.

25:19.500 --> 25:25.820
You have a variational autoencoder for this cell profile, so only for the transcriptomics

25:25.820 --> 25:26.820
data.

25:26.820 --> 25:33.620
You encode this transcriptomics data into some latent representation.

25:33.620 --> 25:40.580
And they are in this latent space, you fuse together the chemical, like another variational

25:40.580 --> 25:41.580
autoencoder.

25:41.580 --> 25:44.100
So it's really like a combination of two variational autoencoders.

25:44.100 --> 25:46.820
One is for chemistry, it's just for pure chemistry and molecules.

25:46.820 --> 25:52.420
And the other one is for cell profiles, specifically cancer cell profiles in transcriptomics

25:52.420 --> 25:53.420
data.

25:53.420 --> 25:57.460
You fuse together the latent embeddings of these two models.

25:57.460 --> 26:01.220
And then you decode from there a molecule.

26:01.220 --> 26:06.580
And how you can use this model is really by, you can feed it, a cancer cell profile from

26:06.580 --> 26:11.100
a patient, and it will propose you an anti-cancer drug.

26:11.100 --> 26:16.820
So originally, like in the first place, this will be like a random molecule, but now the

26:16.820 --> 26:21.660
reinforcement learning comes into play, what we can do with this molecule is we can plug

26:21.660 --> 26:25.220
it into the prediction model that we developed in the first step, right?

26:25.220 --> 26:30.420
So in the first step, I said we have this prediction model that takes as two inputs, namely

26:30.420 --> 26:35.220
a molecule, and a cancer cell profile, and it tries to predict the efficacy of a drug,

26:35.220 --> 26:36.220
right?

26:36.220 --> 26:39.780
So it's kind of providing our scoring function for the RL learner.

26:39.780 --> 26:40.780
Absolutely, absolutely.

26:40.780 --> 26:41.780
Okay.

26:41.780 --> 26:45.660
So we use this prediction model to get a reward, and then this reward is used in turn in

26:45.660 --> 26:47.580
order to update the generator.

26:47.580 --> 26:52.020
And then we have a closed loop system, which we can train with a policy gradient and reinforcement

26:52.020 --> 26:53.020
learning techniques.

26:53.020 --> 27:00.020
And then on the long run, we can, and this we've shown quite, quite consistently, we can

27:00.020 --> 27:05.500
like propose molecules that have an higher predicted efficacy, according to our prediction

27:05.500 --> 27:06.500
model.

27:06.500 --> 27:12.220
The two various auto encoders, are those trained independently, or are they trained in

27:12.220 --> 27:13.220
the end somehow?

27:13.220 --> 27:14.220
Yeah.

27:14.220 --> 27:18.060
So they are initially pre-trained completely independently, so you can really thinking

27:18.060 --> 27:24.260
about these auto encoders as learning completely disentangled representation.

27:24.260 --> 27:31.100
So one is really for molecules, just to understand like this smiles language notation, to understand

27:31.100 --> 27:33.860
how chemistry works in a way.

27:33.860 --> 27:40.140
And so the other auto encoder for the transcriptomics data, you can, yeah, so this is just trying

27:40.140 --> 27:44.700
to approximate and learn the space of possible cancer cells, so to speak.

27:44.700 --> 27:48.860
So these are pre-trained independently, and then what we do is really, we, we, like we

27:48.860 --> 27:54.660
think is that second one is it, it's, yeah, so it's creating the representation of the

27:54.660 --> 28:01.460
cancer cells, and then the, there's a decoder step that's taking these two and coming up

28:01.460 --> 28:04.860
with a prediction of the, of a, of a drug molecule.

28:04.860 --> 28:05.860
Yes.

28:05.860 --> 28:13.460
So there's decoder that basically combines the two latent representation of the cell profile

28:13.460 --> 28:19.100
of interest and a drug, and then comes up with a new cancer drug.

28:19.100 --> 28:20.700
So how is this one trained?

28:20.700 --> 28:23.380
So this is trained jointly in this reinforcement learning.

28:23.380 --> 28:24.380
Okay.

28:24.380 --> 28:27.220
So it's part of that reinforcement learning circle, got it?

28:27.220 --> 28:28.220
Yeah.

28:28.220 --> 28:29.220
Absolutely.

28:29.220 --> 28:33.900
So what's important to note here is that it's highly non-trivial, how you combine these

28:33.900 --> 28:40.340
different data modalities, because it, it, it seems extremely arbitrary in a way to,

28:40.340 --> 28:45.100
to fuse latent representations of a molecule with the latent representation of a cancer

28:45.100 --> 28:46.180
cell profile.

28:46.180 --> 28:52.220
What we're doing there, it is, I mean, in a way, it is just the first thing that came to

28:52.220 --> 28:56.140
our mind is we're summing up the latent representations.

28:56.140 --> 29:02.100
But because we're doing this consistently, while we're being in this reinforcement learning

29:02.100 --> 29:10.540
regime, we, we think that we can basically warp this latent space representation from

29:10.540 --> 29:14.140
originally, according structural similarity between molecules, right?

29:14.140 --> 29:19.380
I was talking before in between, like, about morphing aspirin into paracetamol, right?

29:19.380 --> 29:26.140
So we can, like, morph this latent space into encoding functional similarity.

29:26.140 --> 29:29.940
And functional, by functional similarity, I mean different functional pro, like similar

29:29.940 --> 29:32.020
functional properties of the molecule.

29:32.020 --> 29:36.460
So that you have a certain subset of the space, and in this subset of the space, you will

29:36.460 --> 29:43.620
find molecules more frequently that have high predicted anti-cancer effects, basically,

29:43.620 --> 29:45.300
according to our prediction model.

29:45.300 --> 29:54.620
Do you or, have you come across research that looks into the algebraic combinations of

29:54.620 --> 30:00.660
latent spaces and, and how that, you know, what, the, how, what the right intuition is there?

30:00.660 --> 30:03.060
People, you know, how, how much has that been studied?

30:03.060 --> 30:04.060
Have you come across stuff?

30:04.060 --> 30:09.660
I mean, to the best of my knowledge is something that is not very, very actively studied.

30:09.660 --> 30:15.380
So there is a paper from, actually, from Europe's from two years ago called deep sets.

30:15.380 --> 30:20.340
And they are talking about how, how to, how to deal with sets data.

30:20.340 --> 30:25.060
And what they're proposing is, I mean, it's important because this is my second conversation

30:25.060 --> 30:28.780
today where someone said, oh, we just sum up these two latent spaces, and that's what

30:28.780 --> 30:29.780
we use to.

30:29.780 --> 30:34.540
I mean, I was, yes, actually, I was today at a poster session, and I talked to somebody

30:34.540 --> 30:36.860
who was doing exactly the same thing.

30:36.860 --> 30:42.060
And like, I mean, I told them, honestly, this is kind of an arbitrary choice.

30:42.060 --> 30:43.820
I'm doing the very same thing in my work.

30:43.820 --> 30:44.820
I'm just interested.

30:44.820 --> 30:48.940
I do have a better justification for it than I do, right?

30:48.940 --> 30:55.420
So, so, I mean, in a way, what they proposed on this deep sets paper from two years ago,

30:55.420 --> 30:59.260
where they're talking about how to deal with sets and in a deep learning framework is

30:59.260 --> 31:04.300
that you need to have a permutation in variant operation in order to combine sets, because

31:04.300 --> 31:08.300
the thing is with sets, for me, that was the justification that was given to me in the

31:08.300 --> 31:09.300
previous conversation.

31:09.300 --> 31:10.300
Right.

31:10.300 --> 31:16.100
So, it kind of eliminates the role of order in, yeah, the order doesn't play a role.

31:16.100 --> 31:17.100
Right.

31:17.100 --> 31:19.580
So, this holds for many operations, right?

31:19.580 --> 31:24.660
It like, it holds for the, for an averaging for some, for many others.

31:24.660 --> 31:30.500
But so, like, the sum is something that we came up with, and it is an obvious choice.

31:30.500 --> 31:36.300
But, to be honest, I, to me, in a way, it still feels like we're mixing apples and oranges

31:36.300 --> 31:40.580
in bit, and I'm not super satisfied with how we're solving this part of the framework.

31:40.580 --> 31:42.620
Also, losing information in the process.

31:42.620 --> 31:47.020
Just like if you were to do an average, there's, you know, unique information that you're,

31:47.020 --> 31:48.980
that you're just kind of throwing away.

31:48.980 --> 31:49.980
Yeah.

31:49.980 --> 31:54.300
There's information being lost, and there's a, actually, there's a paper also, like, I

31:54.300 --> 31:59.380
saw another paper where they've been at this conference just yesterday, where they've been

31:59.380 --> 32:05.220
looking into different ways of combining latent spaces, and so they, they proposed, I

32:05.220 --> 32:06.620
think, three ways.

32:06.620 --> 32:11.020
One was just like a uniform sampling, so you would basically have a mixture of both.

32:11.020 --> 32:15.420
So you would sample, like, from a uniform distribution between zero and one, and then

32:15.420 --> 32:20.180
you would say, okay, I wait the one representation with 80% the other one with 20, and so I just

32:20.180 --> 32:22.100
have a weighted average, basically.

32:22.100 --> 32:28.020
So another thing they proposed was a Bernoulli distribution, where you would basically pick,

32:28.020 --> 32:33.260
like, the latent representation is it's an embedding of a certain amount of dimension,

32:33.260 --> 32:34.260
right?

32:34.260 --> 32:37.860
It's a vector of a certain length, and then you can say for every dimension, you pick

32:37.860 --> 32:41.740
either one or the other, and you do this important distribution, and then you have a mixed

32:41.740 --> 32:43.060
representation.

32:43.060 --> 32:47.580
Or the third thing they were suggesting is like a learned embedding, basically, where

32:47.580 --> 32:54.620
you have a specific, like, a few deep, a few dense layers of a neural net to learn this

32:54.620 --> 32:55.620
embedding.

32:55.620 --> 33:01.260
So, but still all of these, they didn't seem specifically instructive to me, but rather,

33:01.260 --> 33:04.820
like, okay, you can do it this way or this way, and we can check what works best, and we

33:04.820 --> 33:09.620
see empirically this works best, but it wasn't super, yeah, they didn't provide a, like,

33:09.620 --> 33:11.100
a great justification for it.

33:11.100 --> 33:17.020
But still, I'm curious and to try it out, and this, I will definitely try it out.

33:17.020 --> 33:24.300
Very particularly interesting observations in training the DRL learner to solve this

33:24.300 --> 33:30.260
problem, is it kind of similar, you know, to other use cases, or were there specific things

33:30.260 --> 33:32.940
that you had to do here to get it to converge?

33:32.940 --> 33:39.740
So, it's an actor and critique framework, so to speak, where you have the actor is this

33:39.740 --> 33:44.300
conditional drug generator that comes up with a new compound, and the critique is the

33:44.300 --> 33:47.300
separately pre-trained, this prediction thing.

33:47.300 --> 33:48.620
Running it through this prediction thing.

33:48.620 --> 33:49.620
Exactly.

33:49.620 --> 33:52.980
So, and you can assess other properties of the molecules as well, right?

33:52.980 --> 33:58.980
So, because this, like, predicted property, this ICFIT, it's not the only property qualifying

33:58.980 --> 34:03.260
or disqualifying a molecule for being a drug, so there's also other things, like, water

34:03.260 --> 34:06.100
solubility is something that's extremely important, or...

34:06.100 --> 34:07.100
Will it kill you?

34:07.100 --> 34:08.100
Yeah, yeah.

34:08.100 --> 34:14.260
Or, like, cytotoxicity is a common thing that just, like, you have a drug that is generally

34:14.260 --> 34:19.060
so psychotoxicity will just kill everything, right, and then it doesn't have either, right?

34:19.060 --> 34:24.420
So, and there's many of those things that you really need to incorporate, and then this

34:24.420 --> 34:29.260
reward function for the generator can become very complex, right, because you need to trade

34:29.260 --> 34:35.220
off what is more important, do I wait solubility higher than, like, at, uh, cytotoxicity, or

34:35.220 --> 34:39.820
how about, like, uh, synthesize ability of the molecule, some structures are just extremely

34:39.820 --> 34:44.060
difficult to synthesize, and although you can, like, draw them on the paper, you cannot

34:44.060 --> 34:46.220
really make them chemically in the lab, right?

34:46.220 --> 34:47.220
Yeah.

34:47.220 --> 34:49.020
So, this is another thing, and so...

34:49.020 --> 34:52.780
Presumably, that's all future work, and right now you're focused on performance relative

34:52.780 --> 34:53.780
to this predictor.

34:53.780 --> 34:58.740
Right, so, this has been the first step, just, uh, performance relative to the predictor.

34:58.740 --> 35:03.260
We have the framework now there with all these, like, a panel of critiques, so to speak, to

35:03.260 --> 35:05.300
evaluate other chemical properties.

35:05.300 --> 35:10.300
This is something that is commonly studied, um, or has been commonly studied to, to train

35:10.300 --> 35:17.700
generative models to, um, to come up with a molecule that's full, full specific chemical

35:17.700 --> 35:23.940
criteria, what's really novel about our work is this bridging drug design and systems

35:23.940 --> 35:29.540
biology, basically, where you leverage, um, biomolecular information, in this case of the

35:29.540 --> 35:34.300
cancer cell, into the design process directly, and this is something that, like, has never

35:34.300 --> 35:41.100
been done in any way, and this is what, what distinguishes our work from, from, like,

35:41.100 --> 35:44.900
a lot of what is happening in, in, in, in, in, in, in, in the computational chemistry domain,

35:44.900 --> 35:47.860
and the drug, um, drug discovery domain.

35:47.860 --> 35:51.700
With respect to your previous question about reinforcement learning, so one thing that

35:51.700 --> 35:57.380
happens commonly in generative models is this, this mode collapse, where, um, basically,

35:57.380 --> 36:04.900
you are generating only a single, um, element that can, in a gun setting, for example, can

36:04.900 --> 36:09.860
really fool the discriminator very well, but you lose the variety of the samples that

36:09.860 --> 36:10.860
you're generating.

36:10.860 --> 36:12.540
But this is kind of a form of overfitting.

36:12.540 --> 36:16.220
In a way, absolutely, exactly, because the model in a way it learns, okay, I have this

36:16.220 --> 36:19.940
specific instance and it works super well, so I just always go for this one, right?

36:19.940 --> 36:21.380
Why should I explore something else, right?

36:21.380 --> 36:23.500
And it makes a lot of sense to behave in this way.

36:23.500 --> 36:24.500
Yeah.

36:24.500 --> 36:29.460
And this is something we, we also observed, um, in the fact that, um, the model we had,

36:29.460 --> 36:32.980
it tend to, um, like, produce non-carbon chains.

36:32.980 --> 36:37.420
And for some reason, these carbon chains, they, under some circumstances, had the, the

36:37.420 --> 36:41.540
property of that being having a high predicted efficacy, according to our prediction model,

36:41.540 --> 36:46.980
but still we know that they, they, they can't, they don't really qualify as actual drugs.

36:46.980 --> 36:49.740
And so this was one of the challenges we were facing.

36:49.740 --> 36:55.300
So with respect to the results, what I'm most impressed by when I, when I look at this

36:55.300 --> 37:00.380
and what really surprised me, what I didn't expect when I started working on this is that

37:00.380 --> 37:06.420
the drug, the drugs, the molecule, the model comes up with, they really resemble closest

37:06.420 --> 37:11.500
with the known anti-cancer drugs that are known to work for this type of disease.

37:11.500 --> 37:17.580
So what this means is that we train that generative model to design a new lung cancer drug.

37:17.580 --> 37:23.020
We eventually arrive at a new compound and we check the chemical properties of these compounds

37:23.020 --> 37:28.740
and we see, okay, from all known cancer drugs, we can measure the similarity and we see

37:28.740 --> 37:34.940
it's not most similar to any kind of cancer drug, but it's most similar to known approved

37:34.940 --> 37:36.620
lung cancer drugs.

37:36.620 --> 37:41.300
And we, we have the same result for breast, we generate a new drug against breast cancer,

37:41.300 --> 37:46.380
we, uh, check the database of known cancer drugs, we check which molecules are more similar

37:46.380 --> 37:52.580
by like a nearest neighbor search and we find the nearest neighbors of this new drug cancer,

37:52.580 --> 37:58.980
uh, sorry, new breast cancer drug, uh, actually proved breast cancer drugs and not, and this

37:58.980 --> 38:04.380
is nearest neighbor search in your, uh, latent space or this nearest neighbor's, uh, search

38:04.380 --> 38:07.220
of the fingerprints of these molecules.

38:07.220 --> 38:08.220
Okay.

38:08.220 --> 38:12.340
So because on a, like again, if you take the smiles notation, you cannot really compute

38:12.340 --> 38:16.500
a nearest neighbor in between our packs, right, doesn't make sense. So we compute the

38:16.500 --> 38:17.500
fingerprint first.

38:17.500 --> 38:18.500
Okay.

38:18.500 --> 38:21.260
And then we make a nearest neighbor search there by tiny motor similarity.

38:21.260 --> 38:23.940
This is like the standard metric to use in this case.

38:23.940 --> 38:30.580
Um, and they are, yeah, again, what we find is that the molecules we generate, they seem

38:30.580 --> 38:35.780
to be closest to known cancer drug, cancer drugs that are approved for this specific site

38:35.780 --> 38:38.220
of cancer and not anything else.

38:38.220 --> 38:43.180
And this, in a way, it shows us that we are on the right track and that in a way the

38:43.180 --> 38:47.420
model understands that a lung cancer drug should have different properties to breast cancer

38:47.420 --> 38:48.420
drug.

38:48.420 --> 38:49.420
Nice.

38:49.420 --> 38:55.420
And so in terms of your qualitative results and metrics, how are you approaching that?

38:55.420 --> 39:00.580
This is extremely difficult in the sense that the actual validation for such a framework

39:00.580 --> 39:06.660
is to test it in the way that you synthesize the drugs that the model comes up with.

39:06.660 --> 39:07.660
Right.

39:07.660 --> 39:15.180
You run, you run, you run screening tests and you try to basically start the entire pipeline

39:15.180 --> 39:17.420
of clinical trials.

39:17.420 --> 39:19.380
And this is something we're working on at the moment.

39:19.380 --> 39:27.060
So at IBM, we do have options to synthesize molecules.

39:27.060 --> 39:29.580
And this is something we're starting to do.

39:29.580 --> 39:34.300
But at the moment, we are looking for collaborators when it comes to the experimental validation.

39:34.300 --> 39:39.020
This is a skill and expertise that we do not have in-house.

39:39.020 --> 39:42.900
Also, we don't have the equipment in-house to run these essays.

39:42.900 --> 39:47.300
But therefore, we are, at the moment, we are actively seeking for collaborators to work

39:47.300 --> 39:53.100
with us together to run these drug screening essays to basically, like, in a petri dish

39:53.100 --> 39:56.420
measure, how, what's the efficacy of this drug?

39:56.420 --> 40:04.180
Taking a step back to the evaluation criteria we were discussing earlier, is that something

40:04.180 --> 40:13.060
that is automatable, maybe the better way to ask the question is, in your training loop,

40:13.060 --> 40:16.180
what do you use as, like, a loss function?

40:16.180 --> 40:20.540
So the loss function is, because it's the real problem of the machine.

40:20.540 --> 40:21.540
Right.

40:21.540 --> 40:22.540
Right.

40:22.540 --> 40:25.220
Like, the reward is coming from the prediction model that we have.

40:25.220 --> 40:26.220
Right.

40:26.220 --> 40:31.300
I mean, what Pac-Man really tries to do is, it tries to run this drug screening essay for

40:31.300 --> 40:32.300
you.

40:32.300 --> 40:33.300
Right.

40:33.300 --> 40:35.740
I mean, as opposed to, you have to double do it by hand, right?

40:35.740 --> 40:36.740
Right.

40:36.740 --> 40:41.020
So it's spitting out these candidate drugs that pass its test of, you know, being able

40:41.020 --> 40:45.420
to fool, you know, the, the critic or, you know, pass your predictor model.

40:45.420 --> 40:53.060
And then you're manually kind of comparing these to other known drugs for similar types

40:53.060 --> 40:57.740
of tissue for kind of a qualitative sanity check.

40:57.740 --> 41:00.620
Or has that, have you integrated that into the training process somehow?

41:00.620 --> 41:01.620
Mm-hmm.

41:01.620 --> 41:09.740
In a way that, if you train long enough, you see that the model, like, with a high probability

41:09.740 --> 41:14.660
comes up with a drug that has a high predicted efficacy, which means it passes this drug screening

41:14.660 --> 41:18.900
essay, this virtual drug screening, it performs very well.

41:18.900 --> 41:23.260
And it has chemical properties that are desired, basically.

41:23.260 --> 41:26.660
So it is more or less easy to synthesize it.

41:26.660 --> 41:30.020
It has the right amount of water solubility, all of these properties.

41:30.020 --> 41:36.020
And so, but then what we do is, like, we store those molecules that have basically passed

41:36.020 --> 41:37.700
all of these tests.

41:37.700 --> 41:42.940
And then post-talk what we can do is we can then look at these molecules together with

41:42.940 --> 41:47.700
a chemist and then check whether it is feasible to synthesize them.

41:47.700 --> 41:52.420
And because this is like, I mean, it's another set of problems, like, how do you synthesize

41:52.420 --> 41:53.420
a molecule?

41:53.420 --> 41:54.420
Right.

41:54.420 --> 41:56.700
So there's a whole active field of research on retro synthesis, right?

41:56.700 --> 42:04.700
Just trying to basically decompose the target molecule that you want to have into the reactants

42:04.700 --> 42:09.060
and reagents you need in order to get and arrive at this molecule, right?

42:09.060 --> 42:12.180
And this is like, I mean, it's a huge problem by itself.

42:12.180 --> 42:17.900
So you really need to have this, like, recipe of basic ingredients that you can purchase anywhere

42:17.900 --> 42:21.620
in order to arrive at this new compound that probably has never been synthesized in the

42:21.620 --> 42:22.620
world before.

42:22.620 --> 42:27.220
Awesome, well, Yannis, thanks so much for chatting with me about what you're out to.

42:27.220 --> 42:28.220
Very cool stuff.

42:28.220 --> 42:29.220
Thank you so much.

42:29.220 --> 42:30.220
Appreciate it.

42:30.220 --> 42:35.860
All right, everyone, that's our show for today.

42:35.860 --> 42:41.300
To learn more about today's guests or the topics mentioned in the interview, visit twomelai.com

42:41.300 --> 42:43.380
slash shows.

42:43.380 --> 42:47.900
For more information on either of our new study group offerings, causal modeling and machine

42:47.900 --> 42:56.220
learning or the IBM Enterprise AI workflow, visit twomelai.com slash learn 2020.

42:56.220 --> 43:00.700
Of course, if you like what you hear on the podcast, be sure to subscribe, rate, and

43:00.700 --> 43:03.740
review the show on your favorite pod catcher.

43:03.740 --> 43:20.900
Thanks so much for listening and catch you next time.

