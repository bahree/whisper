1
00:00:00,000 --> 00:00:16,520
All right, everyone. I am here with Jose Miguel Hernandez-Lobato, who is a university lecturer

2
00:00:16,520 --> 00:00:22,960
in machine learning at the University of Cambridge. Miguel, welcome to the Tumbo AI podcast.

3
00:00:22,960 --> 00:00:30,400
Thanks. Thanks a lot for inviting me. Hey, I'm looking forward to digging in, learning a bit

4
00:00:30,400 --> 00:00:36,480
about what you're working on, but I'd love to have you start by sharing a bit about your background

5
00:00:36,480 --> 00:00:43,920
with our audience. How did you come to work in machine learning? So good. That's a good question.

6
00:00:43,920 --> 00:00:49,920
So I was, as an undergrad, always interested in artificial intelligence, and obviously the

7
00:00:49,920 --> 00:00:55,760
exposure that I had to artificial intelligence was more the traditional AI. For example,

8
00:00:55,760 --> 00:01:03,360
as an undergrad, I started coding my own test programs, and so on. And then when I finished my

9
00:01:03,360 --> 00:01:09,600
undergrad, I was deciding what to do, and there was this opportunity of doing a PhD, and at the time,

10
00:01:10,320 --> 00:01:17,360
the most similar thing to a PhD in AI was focused on this topic of machine learning, and I just

11
00:01:17,360 --> 00:01:24,320
started working in machine learning, and actually I think I was quite lucky, because I started

12
00:01:24,320 --> 00:01:29,120
at a time where machine learning was not so popular and so hot, and now recently it has

13
00:01:29,680 --> 00:01:36,640
exploded in interest and opportunities. So I think I was quite lucky to get just

14
00:01:37,440 --> 00:01:43,680
when it was not so popular, and I'm in an actually very good position to take advantage of that.

15
00:01:43,680 --> 00:01:48,560
That's awesome. Tell us a little bit about your research interests.

16
00:01:50,080 --> 00:01:59,040
Good, so yeah, so I'm faculty in Cambridge at the moment, and Cambridge is well known for having

17
00:01:59,040 --> 00:02:09,360
a strong focus on Bayesian methods. My interest is at the intersection of Bayesian methods and

18
00:02:09,360 --> 00:02:16,480
deep learning, and I think Bayesian methods, they bring a lot of opportunities to quantify uncertainty,

19
00:02:17,120 --> 00:02:23,120
and this will help us a lot to solve many problems, where uncertainty is very important,

20
00:02:23,120 --> 00:02:29,120
especially in decision-making problems. For example, in active learning, if we want to know

21
00:02:29,120 --> 00:02:36,640
what data to collect next, so that we learn fast about a particular problem, how to, for example,

22
00:02:36,640 --> 00:02:44,720
find the new molecules with improved properties fast, we can also make use of this uncertainty,

23
00:02:44,720 --> 00:02:50,160
and even if we want to, for example, compress the parameters of neural networks,

24
00:02:51,040 --> 00:02:56,560
so that they have reduced the size, for example, if we want to transfer a neural network

25
00:02:57,840 --> 00:03:02,960
to a smartphone or download it, for example, or we want to implement the neural network in

26
00:03:02,960 --> 00:03:11,280
hardware, and we want to store the neural network in a low memory device, you can use these

27
00:03:11,280 --> 00:03:20,240
techniques, and in general, I'm very excited about the challenges of obtaining uncertainty

28
00:03:20,240 --> 00:03:24,000
as to much with deep learning. It's not a straightforward, but there are many opportunities for

29
00:03:24,000 --> 00:03:33,440
having a big impact by doing this. If you were to taxonomize the different approaches,

30
00:03:33,440 --> 00:03:38,640
the folks are taking kind of at this intersection of Bayesian and deep learning,

31
00:03:39,360 --> 00:03:46,080
where is the activity happening right now? Good, so what happens at the moment is that as I said,

32
00:03:46,080 --> 00:03:51,360
it's not really easy to obtain the accurate estimates of uncertainty, and in practice,

33
00:03:51,360 --> 00:03:56,160
the problem is interactable and you have to do approximations. So there are many different ways

34
00:03:56,160 --> 00:04:02,480
of doing these approximations. You could use, for example, sampling based methods that

35
00:04:02,480 --> 00:04:09,360
draw approximate samples of posterior distribution. You could also think of the

36
00:04:09,360 --> 00:04:14,000
instead of drawing samples to come up with a deterministic approximation that

37
00:04:14,000 --> 00:04:20,000
quantifies your uncertainty. This will be, for example, Gaussian distribution. We will try to

38
00:04:20,000 --> 00:04:25,760
obtain a Gaussian distribution that quantifies your uncertainty about the weights of your new

39
00:04:25,760 --> 00:04:35,280
network. This is a different approach, and another alternative is to have something even kind

40
00:04:35,280 --> 00:04:41,200
of in between of the two, something more flexible than a Gaussian, but not as complicated as drawing

41
00:04:41,200 --> 00:04:50,160
samples. And this could be, for example, implicit models that work with very flexible distributions.

42
00:04:50,160 --> 00:04:57,520
So people work a bit on these different techniques to obtain uncertainty estimates.

43
00:04:57,520 --> 00:05:05,840
And at present, there is not really like a very well, like one method that is really known to be

44
00:05:05,840 --> 00:05:10,960
better than the others, and this sort of activity of trying to come up with methods that have

45
00:05:10,960 --> 00:05:17,360
good trade-offs in terms of the computational cost that it takes to obtain these uncertainty

46
00:05:17,360 --> 00:05:26,880
estimates and the quality of the uncertainty estimates. And one of the areas that you've

47
00:05:26,880 --> 00:05:34,160
been applying this kind of work is around in some recent papers around molecular design.

48
00:05:34,160 --> 00:05:42,160
Yeah, that's right. So that's an idea that I'm really excited about. Finding new molecules

49
00:05:42,160 --> 00:05:48,880
with improved properties is really challenging. So usually you have to propose a new molecule

50
00:05:48,880 --> 00:05:54,320
and maybe you have to collect data to see how good that molecule is. And based on that data,

51
00:05:54,320 --> 00:06:01,920
you may update your models and propose another molecule and the whole process repeats.

52
00:06:01,920 --> 00:06:09,840
And the idea is how to achieve this in a way that you find faster some molecule with good properties.

53
00:06:10,640 --> 00:06:19,360
So in this, yeah. Is there a particular aspect of this problem that lends itself to

54
00:06:19,360 --> 00:06:23,200
a Bayesian approach, or where these uncertainty estimates are particularly useful,

55
00:06:23,200 --> 00:06:31,920
or are those kind of separate areas of research for you? So there are some

56
00:06:31,920 --> 00:06:37,040
the estimates in this case are very useful because you will use your uncertainty to guide

57
00:06:37,040 --> 00:06:42,640
the search for better molecules. So typically, you will want to

58
00:06:44,080 --> 00:06:50,240
collect data on those molecules for which you have a chance of getting good results.

59
00:06:50,240 --> 00:06:56,560
And this means that there should be some uncertainty or some probability that the value

60
00:06:56,560 --> 00:07:00,560
or the properties of the molecule are actually maybe better than what you found before.

61
00:07:00,560 --> 00:07:06,720
So you will use this uncertainty and actually the quality of your predictions for the properties

62
00:07:06,720 --> 00:07:12,480
of the molecules to decide what molecules to find next. And the molecules that we choose are

63
00:07:12,480 --> 00:07:20,240
those that have some trade-off between the, if you think about it, the point estimate of how good

64
00:07:20,240 --> 00:07:27,360
the molecule is, but also some high uncertainty. And when you are able to balance these two things,

65
00:07:27,360 --> 00:07:31,520
like molecules where you have uncertainty and there is the probability that you will obtain

66
00:07:31,520 --> 00:07:37,200
actually something better than what you have found before, then you will be

67
00:07:37,200 --> 00:07:43,520
interested in collecting data for those molecules. Got it. And now you've taken a couple of different

68
00:07:43,520 --> 00:07:52,560
approaches to this problem. One paper was focused on kind of searching over the possible chemical

69
00:07:52,560 --> 00:08:02,560
reactions. And then more recently, you're doing this via 3D and in 3D space. And this was a

70
00:08:02,560 --> 00:08:10,880
paper that was featured or that you presented at ICLR recently. That's right. So yeah. So the whole

71
00:08:10,880 --> 00:08:17,360
thing of finding the molecules is actually quite challenging because you, molecules have discrete

72
00:08:17,360 --> 00:08:22,720
objects and they have a lot of structure. And it's not really a straightforward how to come up

73
00:08:22,720 --> 00:08:27,280
with something that looks like a realistic molecule like the ones that you find in the real world.

74
00:08:27,280 --> 00:08:32,080
So the approach that we follow to do this is to use deep generative models. And these are going

75
00:08:32,080 --> 00:08:39,040
to be deep unit networks that are trained on large amounts of existing molecules. For example,

76
00:08:39,040 --> 00:08:44,240
and they will be able to generate new molecules. And the question is how do you want to represent

77
00:08:44,240 --> 00:08:50,880
the molecules and how do you want to train these models to generate new molecules? So obviously,

78
00:08:50,880 --> 00:08:56,480
you may want to synthesize those molecules in practice. So what you could do is to have a deep

79
00:08:56,480 --> 00:09:04,000
generative model that is trained on existing data about chemical reactions, how how

80
00:09:04,000 --> 00:09:09,680
existing molecules are synthesized using chemical reactions. And then you will be able to generate

81
00:09:10,320 --> 00:09:16,160
molecules via chemical reactions. So the model will tell you how to synthesize the generated

82
00:09:16,160 --> 00:09:23,120
molecules. The other approach that is also actually quite important is based on

83
00:09:23,120 --> 00:09:32,560
the actual location of the atoms. So most generative models of molecules they work using molecular graphs.

84
00:09:33,360 --> 00:09:40,560
And we just generate a graph with the atoms that form the molecule and the connections

85
00:09:40,560 --> 00:09:47,040
between those. But there is a lot of important structure in the 3D configuration of the atoms

86
00:09:47,040 --> 00:09:53,760
that is missed by these models. And another approach is to actually generate molecules in 3D

87
00:09:53,760 --> 00:09:59,200
space instead of generating these molecular graphs. That is what the approach based on chemical

88
00:09:59,200 --> 00:10:05,760
reactions does. You can generate the molecules in 3D space placing one atom and then connecting

89
00:10:05,760 --> 00:10:11,200
that atom with previous ones and so on. And the advantage of this is that you have actually more

90
00:10:11,200 --> 00:10:15,520
information about the structure of the molecule and this can be very important for determining

91
00:10:15,520 --> 00:10:21,440
the properties of the molecule. As an example you have that the molecule of water actually

92
00:10:21,440 --> 00:10:26,480
is not the way the hydrogen atoms are connected to the oxygen atom is not the

93
00:10:28,400 --> 00:10:33,840
for example flat. You have like a small angle between the bonds and this gives the the

94
00:10:33,840 --> 00:10:41,120
molecule of water specific properties. And if you just work with graphs without taking into account

95
00:10:41,120 --> 00:10:45,600
for example this angle between the bonds then you won't be able to capture those properties.

96
00:10:45,600 --> 00:10:52,160
So that's why I think capturing these properties and being able to generate molecules in 3D

97
00:10:52,160 --> 00:11:00,880
spaces is quite interesting. So I just want to say that just to motivate this at the moment

98
00:11:00,880 --> 00:11:05,920
there is a huge interest in the application of deep learning methods to this problem because

99
00:11:05,920 --> 00:11:12,080
there are many many opportunities to in particular accelerate the design of new

100
00:11:12,080 --> 00:11:18,240
tracks for example this is something that is very very expensive companies are spending a huge

101
00:11:18,240 --> 00:11:23,920
amounts of money into designing new tracks and deep learning now is offering a lot of possibilities

102
00:11:23,920 --> 00:11:35,360
to accelerate this process. I can see how having worked with this data in kind of the two-dimensional

103
00:11:35,360 --> 00:11:43,760
kind of the flat graph realm would leave you wanting to try a 3D approach. Did your

104
00:11:45,920 --> 00:11:53,200
specific approach or architecture for approaching the 3D problem? Did you start over? Was that kind

105
00:11:53,200 --> 00:12:00,880
of built on what you did for the 2D problem? Yeah so actually the work on 3D is one of the

106
00:12:00,880 --> 00:12:06,400
first works in this area so we really were starting almost from scratch because the approach is at

107
00:12:06,400 --> 00:12:13,760
the moment not as sophisticated as previous models but we are able to successfully generate

108
00:12:13,760 --> 00:12:18,160
these molecules in 3D space. So some of the molecules that we are generating in 3D space they

109
00:12:18,160 --> 00:12:24,640
are relatively simple much simpler than the ones generated with previous models but it's really

110
00:12:24,640 --> 00:12:31,040
exciting. Just to clarify how we do this the idea is to have our reinforcement learning agent

111
00:12:31,040 --> 00:12:38,720
that is going to learn how to place these atoms in a space. The agent is given an initial back

112
00:12:38,720 --> 00:12:45,840
of atoms and the agent has to choose what atoms to place in a space and how to arrange those

113
00:12:45,840 --> 00:12:51,920
and the only feedback that the agent gets is the final energy or the configuration the energy of

114
00:12:51,920 --> 00:12:56,800
the configuration of the atoms. So the agent has to learn by trial and error how to find 3D

115
00:12:56,800 --> 00:13:02,320
configurations of atoms that have the energy and they are physically possible in their work.

116
00:13:04,320 --> 00:13:12,080
And so some of the traditional challenges with reinforcement learning are the sample

117
00:13:12,080 --> 00:13:22,800
inefficiency and the challenges of creating the objective function. How did issues like that manifest

118
00:13:22,800 --> 00:13:30,640
themselves in this paper? That's right so typically reinforcement learning methods are data hungry

119
00:13:30,640 --> 00:13:39,520
and the way we address this is to use some fast numerical methods that approximate the energy

120
00:13:39,520 --> 00:13:45,120
of the atoms in a space. So we are actually able to collect a relatively large amount of data

121
00:13:45,920 --> 00:13:53,200
to find this. The problem with this is that obviously you may want to find molecules that are

122
00:13:53,200 --> 00:13:58,400
stable and that have like this 3D configuration that is physically possible but you may also want

123
00:13:58,400 --> 00:14:03,360
to find molecules with interesting properties. And the question is that then you have to combine

124
00:14:03,360 --> 00:14:09,920
these two different objectives. One is the energy of the molecule that might be cheap

125
00:14:09,920 --> 00:14:16,240
to obtain and then you may also have another property of the molecule that could be actually

126
00:14:16,240 --> 00:14:21,840
quite expensive to obtain. You may have to do experiments in a laboratory to finally test the

127
00:14:21,840 --> 00:14:25,200
properties of that molecule in the real world that are the ones that you would expect.

128
00:14:26,320 --> 00:14:32,240
So in practice you would have to find a balance between how to combine the two approaches

129
00:14:32,240 --> 00:14:38,560
and the one way to do this is to use for example sub-agat models. The idea is how to solve

130
00:14:38,560 --> 00:14:44,480
sub-agat models. These models will, for example, make predictions about the expensive properties

131
00:14:44,480 --> 00:14:49,280
based on some existing data. And that reinforcement learning agent will try to

132
00:14:49,280 --> 00:14:53,120
will be working with the predictions of these sub-agat models that will be that will be

133
00:14:53,120 --> 00:15:05,520
very fast to a lot of weight. And to what degree have you integrated in kind of the Bayesian

134
00:15:05,520 --> 00:15:11,440
approach into this reinforcement learning oriented formulation of the problem?

135
00:15:12,320 --> 00:15:17,680
In the reinforcement learning approach we haven't really done that yet but we have done that

136
00:15:17,680 --> 00:15:24,800
in the case of the, for example, the models with chemical reactions. And the idea here is to do

137
00:15:24,800 --> 00:15:29,600
something called the Bayesian optimization methods. Bayesian optimization methods are actually

138
00:15:31,040 --> 00:15:37,520
in the world, correct? Yeah, that's in the in the 2D graph setting. The idea is that

139
00:15:39,520 --> 00:15:45,520
Bayesian optimization methods work also by using these sub-agat models and the idea is that you will

140
00:15:45,520 --> 00:15:52,640
you will fit, for example, a predictor of the properties of the molecule that gives you estimates

141
00:15:52,640 --> 00:15:57,360
of uncertainty. And this could be, for example, a Gaussian process. These are very good models

142
00:15:57,360 --> 00:16:05,360
that work quite well to provide the estimates of uncertainty. And then you can use these

143
00:16:05,360 --> 00:16:12,640
uncertainties to decide what data to collect next. What is super interesting is that we are using

144
00:16:12,640 --> 00:16:20,800
deep generative models to generate the molecules, but to connect these models with a Bayesian optimization

145
00:16:21,920 --> 00:16:27,360
approach, what we do is that we work with the latent representation of molecules given by the

146
00:16:27,360 --> 00:16:34,400
deep generative models. These deep generative models, like variation algorithm colors, they learn

147
00:16:34,400 --> 00:16:41,360
a compressed representation of the data. They have some latent variables. And by using these

148
00:16:41,360 --> 00:16:46,880
models, we are actually able to map molecules to a low dimensional latent space that is

149
00:16:46,880 --> 00:16:53,520
actually continuous. And then we can map points from this latent space back to the original space

150
00:16:53,520 --> 00:16:59,920
of molecules. So what we do is then use Bayesian optimization techniques to do molecule optimization

151
00:16:59,920 --> 00:17:07,920
in this latent space. So this is like a super interesting idea. And the advantage of this is that

152
00:17:07,920 --> 00:17:13,440
you have now an approach that is going to do efficient optimization because you are using this

153
00:17:13,440 --> 00:17:18,400
Bayesian optimization methods that work very well in continuous spaces and relatively low dimensional.

154
00:17:19,120 --> 00:17:24,800
And we are combining these methods with a deep generative model that will generate molecules

155
00:17:24,800 --> 00:17:30,400
that are similar to those found in the real world. And this is going to be done in a way without

156
00:17:30,400 --> 00:17:35,760
having any expertise on how the molecules are constructed. You just have a data set of molecules.

157
00:17:35,760 --> 00:17:41,920
You fit your deep generative model to this data. You obtain this latent space that represents

158
00:17:43,360 --> 00:17:49,040
the molecules in a continuous representation. And then you can do molecule optimization in that

159
00:17:49,040 --> 00:17:57,280
space. So this is some areas where I'm currently working quite a lot with members of my group.

160
00:17:57,280 --> 00:18:07,760
Got it. And does the surrogate model extension to the 3D setting allow you to do some more things?

161
00:18:08,720 --> 00:18:12,240
Yeah. In principle, you could do similar things. This is something that we haven't really

162
00:18:12,240 --> 00:18:18,160
explored yet. But you could have your reinforcement learning agent optimizing some combined

163
00:18:18,160 --> 00:18:24,160
objective between the energy of the molecule that you are constructing and the prediction of

164
00:18:24,160 --> 00:18:29,520
the property of the molecule according to the surrogate model. This is obviously something

165
00:18:29,520 --> 00:18:35,040
that we haven't done yet. But it's a very exciting direction for future work.

166
00:18:36,320 --> 00:18:40,560
Awesome. Awesome. So you also do some work in compression. Tell us about that.

167
00:18:41,040 --> 00:18:47,920
That's right. So this is something that I'm really excited about. And this is some work that

168
00:18:47,920 --> 00:18:54,480
has been done by some of my PhD students in particular, Martin Harasi and Greg Flamick.

169
00:18:54,480 --> 00:19:01,360
And this is a completely radical new way of doing compression. So most compression methods,

170
00:19:01,360 --> 00:19:10,640
they actually work by mapping, for example, a sequence of characters to another representation

171
00:19:10,640 --> 00:19:16,800
of that sequence that has a size that is proportional to the log probability of the original

172
00:19:16,800 --> 00:19:22,080
sequence. This is what typically you do in compression. And it's well known. Not that the

173
00:19:22,080 --> 00:19:27,840
information that a particular value of a random variable has is determined by the log probability

174
00:19:27,840 --> 00:19:34,720
of this of this random variable. So typical methods for compression, they just compress

175
00:19:35,920 --> 00:19:40,800
a specific value of a random variable. They find a new representation that is more efficient.

176
00:19:40,800 --> 00:19:45,600
And there are many methods for doing this like arithmetic coding is an example.

177
00:19:45,600 --> 00:19:50,240
Well, this is really cool of the methods that we are working with, which we call them

178
00:19:50,240 --> 00:19:56,160
relative entropy coding methods. The idea is that we are not really compressing one value of a

179
00:19:56,160 --> 00:20:03,680
random variable. We are compressing random samples. So we just have distributions. We could have

180
00:20:03,680 --> 00:20:10,800
like a base distribution that is shared by the center and the receiver. And what we want to

181
00:20:10,800 --> 00:20:16,880
compress is a random sample from a target distribution. And we don't really care exactly

182
00:20:16,880 --> 00:20:24,000
about the particular sample that we get. We just want to be able to transmit a random sample

183
00:20:24,000 --> 00:20:30,000
from this target distribution to the receiver without actually telling the receiver what the

184
00:20:30,000 --> 00:20:34,400
distribution we are sampling from. The receiver only has this base distribution that is shared

185
00:20:34,400 --> 00:20:39,200
between the center and the receiver. And yeah, we call this method the relative entropy coding.

186
00:20:39,200 --> 00:20:46,000
And what is interesting is that this technique is able to find the compressed representations

187
00:20:46,000 --> 00:20:52,720
of the weights of neural networks that are currently state of the, these methods are really

188
00:20:52,720 --> 00:21:00,080
state of the ad for compressing neural networks. And so how does compressing the distribution

189
00:21:01,040 --> 00:21:06,640
lend itself to compress communication from the center to the receiver?

190
00:21:06,640 --> 00:21:13,680
Yeah, so what you actually do is you don't really send the distribution. So you just send some

191
00:21:13,680 --> 00:21:21,120
bits that will allow the receiver to reconstruct a random sample. And this random sample in general,

192
00:21:21,120 --> 00:21:29,280
the center doesn't really control what sample you send. You just are able to choose randomly one

193
00:21:29,280 --> 00:21:35,840
and then send some bits to the receiver. And the receiver will take those bits, use the shared

194
00:21:35,840 --> 00:21:40,160
distribution, the base distribution that is shared between the center and the receiver,

195
00:21:40,160 --> 00:21:45,120
and use that the base distribution to recover the sample. So in general, you don't really send

196
00:21:46,640 --> 00:21:52,720
the distribution itself, but you are able to send samples from the distribution.

197
00:21:53,360 --> 00:21:59,040
And that's because the distribution, the compressed distribution is, you consider as pre-shared,

198
00:21:59,040 --> 00:22:01,200
it's known to both center and receiver.

199
00:22:01,200 --> 00:22:05,360
Yes, that's right. So that's some information that is

200
00:22:06,960 --> 00:22:10,960
agreed between center and receiver. And typically this could be a very simple distribution that

201
00:22:10,960 --> 00:22:18,800
is easy to sample from, for example, a standard Gaussian distribution. And what is interesting

202
00:22:18,800 --> 00:22:24,880
of these method is that you are really just sending random values of random variables without

203
00:22:24,880 --> 00:22:30,320
caring much about the value of those. And this is extremely useful for compressing the weights

204
00:22:30,320 --> 00:22:35,600
of neural networks. Because neural networks are very, very tolerant to perturbation of the weights.

205
00:22:35,600 --> 00:22:40,800
So it might be fine if you just send some randomly corrected version of your weights,

206
00:22:40,800 --> 00:22:46,000
your neural network might still be able to make accurate predictions using that corrected

207
00:22:46,000 --> 00:22:52,640
version of the weights. So by doing that, by sending some small perturbation of the weights,

208
00:22:52,640 --> 00:22:57,840
and not exactly caring about sending a specific value of the weights, we are able to achieve

209
00:22:57,840 --> 00:23:05,760
the best existing compression rates for neural networks. Got it. But you might not want to apply

210
00:23:05,760 --> 00:23:11,840
this to traditional communication. That's right. So the question is, what type of communication

211
00:23:11,840 --> 00:23:16,240
you can apply these to? Yeah. You think some of that you can actually apply these to many other

212
00:23:16,240 --> 00:23:21,760
types of data, not only the weights of your networks. For example, images, you may say,

213
00:23:21,760 --> 00:23:29,200
I want to send some image. You may also tolerate some error in your image. And it turns out

214
00:23:29,200 --> 00:23:34,960
that it might be fine if you send just some version of your image that is slightly corrected.

215
00:23:35,840 --> 00:23:40,880
This is usually called the lossy compression. So you won't be able to send the original image,

216
00:23:40,880 --> 00:23:46,480
but the reconstruction quality of the image could be still quite good. And obviously,

217
00:23:46,480 --> 00:23:52,480
all this depends on the tradeoff that you have between how much you want to compress the image,

218
00:23:52,480 --> 00:23:58,080
and you would have a potential loss, and maybe you don't want to compress the image so much,

219
00:23:58,080 --> 00:24:08,000
and the loss is not so high. And then you've also been applying deep generative models to robust

220
00:24:08,000 --> 00:24:13,360
prediction. Tell us about that work. That's right. So this is something that we have been really

221
00:24:13,360 --> 00:24:19,520
working on very recently, and there is a lot of interest in this area. So it turns out, I mean,

222
00:24:19,520 --> 00:24:25,920
this is widely known. Deep learning methods, they are not very robust, especially to

223
00:24:25,920 --> 00:24:34,880
experience features, for example, that could be looking as useful to make predictions in your

224
00:24:34,880 --> 00:24:41,760
data, but they're actually not like this. And the typical example of this is this problem where you

225
00:24:41,760 --> 00:24:49,840
have to classify images of camels and images of cows. And you could imagine that the cows appear

226
00:24:49,840 --> 00:24:56,640
typically with a background of a green field, and the camels could appear with a background of a

227
00:24:56,640 --> 00:25:02,320
desert. And if you try to see that deep learning methods to classify these images, the deep learning

228
00:25:02,320 --> 00:25:09,120
method is very likely to fix on the background pixels, which are not really representative of what

229
00:25:09,120 --> 00:25:15,280
you want to learn. It's not really differentiating between the shape of the cow and the camel. And when

230
00:25:15,280 --> 00:25:20,960
you try to make predictions, then for example, for a cow that is standing in a beach and not in a

231
00:25:20,960 --> 00:25:27,440
green field, then it's going to make a horrible mistakes. So the idea is then how can you make

232
00:25:27,440 --> 00:25:34,080
deep learning methods more robust so that they don't fix on these patterns in the data that are

233
00:25:34,080 --> 00:25:40,560
just spurious and they are not really representative of the prediction problem that you want to solve.

234
00:25:40,560 --> 00:25:46,640
So there has been a lot of interesting work in this area, especially with some methods

235
00:25:46,640 --> 00:25:52,080
called the invariance risk minimization. And they actually come up with solutions to this problem,

236
00:25:52,080 --> 00:25:57,680
but they are based on using linear models. And obviously linear models, they are not really going to

237
00:25:57,680 --> 00:26:04,960
be very accurate in many different settings where actually the patterns in the data are not linear.

238
00:26:04,960 --> 00:26:08,240
So what do we propose with invariant risk minimization?

239
00:26:08,240 --> 00:26:12,080
Yeah, that's right. So this is the work around, yeah, that's what I didn't know about this work.

240
00:26:12,080 --> 00:26:15,840
It's very widely known and it's having, it's had like a lot of impact.

241
00:26:15,840 --> 00:26:22,400
Well, I was going to ask that you explain that as a broad concept, independent of linear versus

242
00:26:22,400 --> 00:26:30,000
non-linear. Yeah, so the idea is that you want to find some, the idea here to solve this problem

243
00:26:30,000 --> 00:26:36,880
is to find some predictor that is going to be invariant across different representations of the

244
00:26:36,880 --> 00:26:43,280
data or environments so that, for example, you could imagine that you have these images of

245
00:26:43,920 --> 00:26:50,880
cameras and cows and the type of background maybe changes slightly in across two different

246
00:26:50,880 --> 00:26:56,480
versions of your dataset. And then what happens is that this correlations between the background

247
00:26:56,480 --> 00:27:03,040
pixels and the target label is going to change from one version of the data and the other. Maybe in

248
00:27:03,040 --> 00:27:08,640
one version of the data, the fraction of the cows with green fields is slightly higher than

249
00:27:10,160 --> 00:27:15,680
in another version of the data. So if you have a predictor that focuses on these pixels,

250
00:27:15,680 --> 00:27:21,600
then it's going to be changing across this environment. So in some environments,

251
00:27:21,600 --> 00:27:26,160
the predictor could be more reliable and in other environment it might be less reliable.

252
00:27:26,160 --> 00:27:32,080
And this allows you to identify that the patterns that the predictor is capturing are probably

253
00:27:32,080 --> 00:27:38,160
not realistic and curious. So there is to find some predictor that will be invariant

254
00:27:38,880 --> 00:27:42,880
and it's going to work well across different environments. And for example, this predictor that

255
00:27:42,880 --> 00:27:49,040
focuses on the shape of the cow or the camel will be invariant. And the idea is to have a predictor

256
00:27:49,040 --> 00:27:56,800
that, for example, could work in the non-linear case. So I can say briefly how we solve this problem

257
00:27:56,800 --> 00:28:01,920
and the idea is that we use deep generative models also to solve this problem and we use something

258
00:28:01,920 --> 00:28:07,360
really cool and that is really exciting at the moment. And it's a family of deep generative models

259
00:28:07,360 --> 00:28:14,400
operational to encoders that are identifiable. This is well known that the existing variational

260
00:28:14,400 --> 00:28:18,960
to encoder models, if you flip them to the data, the latent variables that you will be obtaining

261
00:28:19,680 --> 00:28:26,880
could be different if you train different times your methods. So there are many different

262
00:28:26,880 --> 00:28:34,960
transformations of your latent variables and the model could just run to achieve those transformations.

263
00:28:34,960 --> 00:28:40,400
So in general, every time you learn your model, the latent variables that you could obtain and

264
00:28:40,400 --> 00:28:44,480
calling the data could be different. And this makes these methods not very reliable if you want

265
00:28:44,480 --> 00:28:51,360
to use the latent variables for predictions. What has been very recently developed is a family

266
00:28:51,360 --> 00:28:56,720
of deep generative models for variational to encoder models that are identifiable. And this

267
00:28:56,720 --> 00:29:02,960
means that every time you train these models on the data using, for example, different initializations

268
00:29:02,960 --> 00:29:09,040
of your neural networks, you will always obtain the same latent variables. And actually,

269
00:29:09,040 --> 00:29:16,320
this can be useful for solving this invariant risk immunization problem. The idea is that you

270
00:29:16,320 --> 00:29:24,800
will find latent variables that represent the data and then you can use causal identification

271
00:29:24,800 --> 00:29:31,920
methods to choose those latent variables that are actually predictive of the target property.

272
00:29:31,920 --> 00:29:38,080
So in the case of the images and the of camels and cows, you could think of fitting an

273
00:29:38,080 --> 00:29:43,360
identifiable variational to encoder model to this data. And then finding some latent variables

274
00:29:43,360 --> 00:29:49,760
that some will be describing the grass and other variables will be describing the shape of the

275
00:29:49,760 --> 00:29:58,000
cows and the camels. And using the causal identification methods, you can choose those latent

276
00:29:58,000 --> 00:30:04,240
variables that are actually connected with the shape of the cows and the camels with the final

277
00:30:04,240 --> 00:30:11,520
label. And the other latent variables like the green fields and that determine the green field

278
00:30:11,520 --> 00:30:18,560
or the desert, they won't be captured and they won't be identified as cows are related to the

279
00:30:18,560 --> 00:30:24,080
target label. Can you give us an overview of how the causal identification part of that works?

280
00:30:24,080 --> 00:30:33,920
That's right. So what happens is that you have an underlying cows and models. So you have

281
00:30:33,920 --> 00:30:39,040
these latent variables that you have learned with the identifiable variational to encoder model,

282
00:30:39,040 --> 00:30:45,360
and you have now data for the values of the latent variables and data for the target property.

283
00:30:45,360 --> 00:30:48,880
And obviously you also have data for the different environments that I mentioned before. All

284
00:30:48,880 --> 00:30:55,200
these works only if you have these different environments where things change. So once you

285
00:30:55,200 --> 00:30:59,680
have observations from these latent variables, you can try to identify what's the actual

286
00:30:59,680 --> 00:31:05,920
causal direction in the generation of the data. For example, the latent variable points

287
00:31:06,800 --> 00:31:12,480
towards the label. And that means that the label is actually generated by the latent variable

288
00:31:12,480 --> 00:31:19,680
or actually the label for the image points towards the latent variable. And that means that

289
00:31:19,680 --> 00:31:24,640
the actually the latent variable is caused by the label. So the causal identification methods,

290
00:31:24,640 --> 00:31:33,440
they will apply either independence tests to identify what is this right direction for the

291
00:31:33,440 --> 00:31:42,560
other roles that connect the different variables. For they are based on other underlying assumptions.

292
00:31:42,560 --> 00:31:50,320
Like, for example, something that is used in practice is to assume that the label is obtained

293
00:31:50,320 --> 00:31:58,640
as a nonlinear transformation of the latent variable plus some additiveness.

294
00:31:58,640 --> 00:32:04,000
And if you have a model that works in that way, you have that the label is actually generated

295
00:32:05,040 --> 00:32:09,200
as a nonlinear transformation of the latent variable plus some noise. You can actually

296
00:32:10,400 --> 00:32:16,400
identify the right direction by just fitting the nonlinear model in both directions. You can try to

297
00:32:18,080 --> 00:32:23,040
use a nonlinear model to predict the label from the latent variable or a nonlinear model to

298
00:32:23,040 --> 00:32:29,760
predict the latent variable from the label. And you can then look at the statistical patterns

299
00:32:29,760 --> 00:32:37,760
in the noise. And the right direction will actually have a specific properties that allows you

300
00:32:37,760 --> 00:32:45,600
to identify that. This is some work on Cups and inference that has been really exciting.

301
00:32:46,560 --> 00:32:52,480
This was done in the Bernhard circles that and this work actually that we are, I mean, we're

302
00:32:52,480 --> 00:32:56,560
working on this and we plan to submit it to new ribs. This is done also in collaboration with

303
00:32:56,560 --> 00:33:07,600
Bernhard circles and one of my PhD students. Got it, got it. And so how in the case of this last

304
00:33:08,560 --> 00:33:13,520
work that we've been discussing, how do you evaluate the results and how well is it working?

305
00:33:14,720 --> 00:33:19,840
Good. So yeah, so right now evaluating the performance of these methods is challenging.

306
00:33:19,840 --> 00:33:25,360
And right now there is a benchmark problem that people are considering for the evaluation of

307
00:33:25,360 --> 00:33:31,360
these methods and this is called the colored M-nist. It's a, I mean, M-nist, everyone is familiar with

308
00:33:31,360 --> 00:33:36,800
M-nist, everyone that works in the planning. So you have the M-nist, this data set with digits,

309
00:33:37,680 --> 00:33:43,760
and you will have that some digits are half different colors. So you color the digits with

310
00:33:43,760 --> 00:33:50,160
the colors that are red or green and you will choose these colors in a way that they are

311
00:33:51,840 --> 00:33:55,760
spiritually correlated with the target label. So you would have some of these fake

312
00:33:55,760 --> 00:34:01,600
correlations between the colors and the target label. And obviously, for example, you could say,

313
00:34:02,720 --> 00:34:08,320
I mean, you typically classify the digits in two categories, I think, from 0 to 4 is

314
00:34:08,320 --> 00:34:16,880
category one and from 5 to 9 is category two. So you will say the color of the digit, most of the

315
00:34:16,880 --> 00:34:23,520
times, agrees with the actual category. So you have these colors that are correlated with the

316
00:34:23,520 --> 00:34:31,040
label. And what happens is that you have two different versions of your data where this

317
00:34:31,040 --> 00:34:36,800
probability of agreement of the color with the label changes slightly. And this is related to

318
00:34:36,800 --> 00:34:44,080
this thing that I mentioned before that you need some variation in the spurious correlations

319
00:34:44,080 --> 00:34:52,480
to be able to identify them as spurious. So you can then train a deep learning methods on this

320
00:34:52,480 --> 00:35:00,080
data. And what happens is that the test data, actually, the color has no association at all

321
00:35:00,080 --> 00:35:06,320
with the label. So actually if you train a deep learning method on this data and then you evaluate

322
00:35:06,320 --> 00:35:11,600
the predictive performance on the test data, a normal deep learning method is going to perform

323
00:35:12,240 --> 00:35:17,920
extremely poorly because the colors are actually the opposite. The combination of the colors

324
00:35:17,920 --> 00:35:26,880
is the opposite at test time. So you could use this benchmark to see how well you are doing.

325
00:35:26,880 --> 00:35:33,360
And actually, we have extremely good results in this benchmark because we are able to both

326
00:35:33,360 --> 00:35:41,200
find nonlinear representations of the data and also nonlinear predictions. We are able to do

327
00:35:41,200 --> 00:35:46,240
nonlinear predictions with the methods that we have developed. We achieve some of the best

328
00:35:46,240 --> 00:35:58,720
existing results in this particular benchmark. Awesome. And talk a little bit about how your

329
00:35:58,720 --> 00:36:07,440
broader work around applying Bayesian methods and uncertainty estimation applies in this particular

330
00:36:07,440 --> 00:36:13,520
problem. And that's right. So in this case, the idea is the variation out on color model.

331
00:36:13,520 --> 00:36:21,040
So we have this latent variable model that explains how the data is generated. And obviously,

332
00:36:21,040 --> 00:36:26,640
you have latent variables. So these are variables that are not really observed. So the deep

333
00:36:26,640 --> 00:36:32,320
genetic model uses these latent variables to generate the data but do not observe those.

334
00:36:32,320 --> 00:36:38,400
So you really need to infer those latent variables from the data. And you need to use Bayesian

335
00:36:38,400 --> 00:36:45,120
methods for this. For example, you have to do something called the typical evaluation

336
00:36:45,120 --> 00:36:50,480
and inference where you feed a simple approximate distribution to the posterior distribution

337
00:36:50,480 --> 00:36:54,560
over the latent variables. So you could use a variation and inference to solve this problem.

338
00:36:54,560 --> 00:37:02,080
However, it's much better if you use other techniques. And this is what I mentioned before

339
00:37:02,080 --> 00:37:06,400
about the different trade-offs that you have in Bayesian methods. That you could have simple

340
00:37:06,400 --> 00:37:12,560
methods that are maybe computationally cheap and they work relatively well. But you could have

341
00:37:12,560 --> 00:37:17,760
more advanced methods that are maybe more expensive. But they can be much more accurate.

342
00:37:17,760 --> 00:37:22,480
And an example in this case could be sampling based methods. You could think of instead of

343
00:37:22,480 --> 00:37:26,640
using variational inference, which is what most people use when they train

344
00:37:29,520 --> 00:37:35,440
every variation out on colors, you could use some sampling based method to do something

345
00:37:35,440 --> 00:37:45,200
more efficient and more accurate in this case. Awesome. You've got a few other papers at

346
00:37:45,200 --> 00:37:54,000
this latest iClear conference. Yeah. Why don't we quickly kind of talk through those? One of them is

347
00:37:57,200 --> 00:38:02,480
Yeah, so I can talk a bit about some of those papers as well. There is also another paper,

348
00:38:02,480 --> 00:38:10,080
which I'm also really excited about. And it got an oral presentation that I clear. And it's

349
00:38:10,080 --> 00:38:16,240
called the clue. And it's a method for interpretability in machine learning. Right now there is a lot of

350
00:38:16,240 --> 00:38:21,760
interest in trying to open the black box of deep learning methods. No, you train these methods and

351
00:38:21,760 --> 00:38:28,080
you don't really know why they make some predictions. So a lot of people have been focusing on

352
00:38:28,080 --> 00:38:34,320
interpretability methods for normal deep learning techniques. And they will say, oh, my deep learning

353
00:38:34,320 --> 00:38:41,440
method now says that my loan should be rejected, for example. And the joint interest is knowing why

354
00:38:41,440 --> 00:38:48,720
that happens. However, as I mentioned before, uncertainty is very important in many decision

355
00:38:48,720 --> 00:38:55,440
making problems and in many prediction tasks. And if you care about uncertainty, you may have

356
00:38:55,440 --> 00:39:02,560
that your base and deep learning method just tells you, I don't really know what's the prediction,

357
00:39:02,560 --> 00:39:07,920
what's the prediction in this particular setting. For this particular data point, maybe I don't

358
00:39:07,920 --> 00:39:15,520
really know if you should be given your loan or not. So I'm very uncertain about what the right

359
00:39:15,520 --> 00:39:21,280
predictions should be. And the question is then, why is your base and deep learning method

360
00:39:21,280 --> 00:39:30,480
and certain? You may want to actually try to understand what's maybe making the data your deep learning

361
00:39:30,480 --> 00:39:36,960
method and certain. So can the general explainability is focused on the prediction and in this

362
00:39:36,960 --> 00:39:41,760
clue paper, you're focused on the uncertainty estimate? That's right. We are actually focusing on

363
00:39:41,760 --> 00:39:48,960
interpreting uncertainty estimates and trying to come up with interpretability of why deep learning

364
00:39:48,960 --> 00:39:55,440
methods might be uncertain. And what is interesting is that we also use deep generative models and

365
00:39:55,440 --> 00:40:04,000
variation and color models for this. So the idea is that it's similar techniques and obviously

366
00:40:04,000 --> 00:40:10,240
there are many applications of these methods. So what we do is we say, okay, we have this

367
00:40:10,240 --> 00:40:16,480
base and deep learning method and it's saying that this particular data point is highly uncertain.

368
00:40:17,520 --> 00:40:22,320
So what we do is we train a deep generative model, a variation and color model on the data.

369
00:40:22,320 --> 00:40:28,880
And this will map the data into some low dimensional late in the space. And now what you can do

370
00:40:28,880 --> 00:40:35,680
is try to find new points in this latent space that are close to the original data point.

371
00:40:36,720 --> 00:40:44,720
But where the uncertainty of the neural network when you decode those latent points back and

372
00:40:44,720 --> 00:40:51,360
you make predictions, the neural network becomes more confident. So by doing this, we are now

373
00:40:51,360 --> 00:40:56,560
able to say, you have this data point for which your neural network is very uncertain.

374
00:40:57,280 --> 00:41:01,920
Now I have this other data point that is very close to the original one, but the neural network

375
00:41:01,920 --> 00:41:06,800
is much more confident and it's much more certain. And now you can look at the two data points,

376
00:41:06,800 --> 00:41:10,320
the one for which the neural network is uncertain and the one for which the neural network now is

377
00:41:10,320 --> 00:41:17,360
confident. And this will give you a lot of information telling you why the neural network is uncertain.

378
00:41:17,360 --> 00:41:21,360
And you can look at the differences between the two data points and you will be able to understand

379
00:41:21,360 --> 00:41:27,520
why this is the case. And we have tested this on obviously N-next. We have this N-next digit

380
00:41:27,520 --> 00:41:33,920
and we get some of these digits. We have for example, a four looks like a nine, but you

381
00:41:33,920 --> 00:41:39,120
wouldn't really be able to say this is a four, this is a nine. And then this method precisely tells you

382
00:41:39,120 --> 00:41:45,680
the pixels in the image that are actually creating the confusion in the Bayesian deep learning method.

383
00:41:45,680 --> 00:41:51,120
This highlighting, for example, those pixels that make the four look like a nine or not.

384
00:41:52,400 --> 00:41:57,360
And I'm really excited about this because I think it's opening now a new area for research

385
00:41:57,360 --> 00:42:02,320
into interpretability because people will now think, okay, now we can apply interpretability

386
00:42:02,320 --> 00:42:08,880
methods to answer this and we can try to understand better why our methods don't know what they should know.

387
00:42:08,880 --> 00:42:24,880
So you're, help me understand how the approach gives helps you interpret what's happening.

388
00:42:24,880 --> 00:42:35,200
So you are finding close points in the latent space and we understand kind of some geometric

389
00:42:35,200 --> 00:42:39,520
properties about the relationships between points and the latent space. But we don't necessarily

390
00:42:39,520 --> 00:42:49,760
understand the latent space itself and kind of what the dimensions in that space mean.

391
00:42:49,760 --> 00:43:03,280
So how does knowing, how do you get from knowing the two close points, share similar values?

392
00:43:03,280 --> 00:43:07,600
How do you get from there to understanding the causes or being able to interpret?

393
00:43:08,960 --> 00:43:14,000
Yeah, so that's that's I would question. So why does this whole thing works? No, and how

394
00:43:14,000 --> 00:43:19,120
how just operating in this latent space makes makes any sense. So the idea is that the latent space,

395
00:43:19,120 --> 00:43:26,560
the way you train these models is that the latent space has some structure and it captures some

396
00:43:26,560 --> 00:43:33,040
similarity between the different data points. So because the latent space has low

397
00:43:33,040 --> 00:43:40,320
dimension, you will have to find some compressive representation of data points in this latent

398
00:43:40,320 --> 00:43:43,760
space. And whenever two data points are close to each other in the latent space,

399
00:43:43,760 --> 00:43:48,880
this should still exhibit some similar patterns or regularities. Otherwise, you wouldn't be able to

400
00:43:48,880 --> 00:43:54,960
compress the data. So we know that now data points in latent space that are close to each other should

401
00:43:54,960 --> 00:44:05,760
be relatively similar. So our goal is to find these different versions of the original data point

402
00:44:06,480 --> 00:44:11,840
for which the neural network is more confident, the answer is less. So what we can do is now

403
00:44:12,720 --> 00:44:19,920
map these points from latent space into the predictions of our model by just decoding from the latent

404
00:44:19,920 --> 00:44:26,160
space, feeling that as an input to the base and neural network and then getting the value of the

405
00:44:26,160 --> 00:44:30,880
uncertainty. And then you could just do gradient based optimization in the latent space

406
00:44:32,560 --> 00:44:38,560
to find some new points in the latent space that decodes into something that the

407
00:44:38,560 --> 00:44:46,160
neural network is highly like much more confident. And obviously, you want to stay close to the

408
00:44:46,160 --> 00:44:51,040
original point because otherwise what you could get could be very different and that would be

409
00:44:51,040 --> 00:44:55,440
not very informative. No, if you just say, oh, this is a data point where you are very confident

410
00:44:55,440 --> 00:44:59,120
and the other one where you are very uncertain and they are completely different, you don't really

411
00:44:59,120 --> 00:45:07,440
find anything, any pattern that you could explain why things happen. So this technique is actually

412
00:45:07,440 --> 00:45:15,200
called counterfactual, it's a counterfactual method for interpretability. And what typically

413
00:45:15,200 --> 00:45:23,440
means is that you say, I have this data point and actually my predictions are very uncertain.

414
00:45:23,440 --> 00:45:30,640
And by using this counterfactual approach, you say how my data point should have been so that my

415
00:45:30,640 --> 00:45:36,960
network is very confident in your predictions. That's what we are trying to do our counterfactual

416
00:45:36,960 --> 00:45:42,080
by saying, okay, this is the data point that I got and I imagine that things would have been

417
00:45:42,080 --> 00:45:47,520
otherwise and I got another version of this data point for which my neural network is much more

418
00:45:49,200 --> 00:45:53,760
confident. And then by just sticking to something that is close in late in the space,

419
00:45:53,760 --> 00:45:58,480
but we are the uncertainty actually decreases quite quickly, then we are able to

420
00:45:59,120 --> 00:46:04,960
obtain this informative data points. Got it, got it. Awesome.

421
00:46:04,960 --> 00:46:11,600
Well Miguel, thanks so much for joining us and sharing a bit about what you're up to. Thanks

422
00:46:11,600 --> 00:46:41,440
thanks a lot. Yeah, thanks a lot for inviting me. Awesome. Thank you.

