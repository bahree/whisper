WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:33.200
I'm your host Sam Charrington. A couple of weeks ago I spent some time at the Pegaworld

00:33.200 --> 00:39.040
conference in Las Vegas. The theme of the conference was automation, particularly in service

00:39.040 --> 00:43.720
of the customer experience, and I had a great time seeing all the advancements coming

00:43.720 --> 00:48.280
into this field by way of machine learning and AI.

00:48.280 --> 00:53.760
In this the final episode of our Pegaworld series, I'm joined by Vince Jeffs, senior director

00:53.760 --> 00:59.880
of product strategy for AI and decisioning at Pegasystems. Vince and I had a great talk

00:59.880 --> 01:06.440
about the role AI and advance analytics will play in defining future customer experiences.

01:06.440 --> 01:10.480
We do this in the context provided by one of his presentations from the conference, which

01:10.480 --> 01:16.400
explores four technology scenarios from Pegasystems innovation lives. These look at a connected

01:16.400 --> 01:22.420
car experience, the use of deep learning for diagnostics, dynamic notifications and

01:22.420 --> 01:27.480
continuously optimized marketing. We also get into an interesting discussion about how

01:27.480 --> 01:33.080
much is too much when it comes to hyper personalized experiences and how businesses can manage

01:33.080 --> 01:35.880
this challenge.

01:35.880 --> 01:41.160
Before we jump into the interview, a huge thanks one more time to Pegasystems for sponsoring

01:41.160 --> 01:46.360
this series. Amidst the discussion of automation and enhanced customer experience

01:46.360 --> 01:51.920
as a Pegaworld, the company announced several new AI powered capabilities as part of its

01:51.920 --> 01:55.960
new Pegat Infinity process automation platform.

01:55.960 --> 02:02.360
For more info on Pegat Infinity, head on over to pegat.com slash infinity.

02:02.360 --> 02:06.800
Alright, let's go.

02:06.800 --> 02:12.240
Alright everyone, I am here at Pegaworld in Las Vegas and I have the pleasure of being

02:12.240 --> 02:19.080
seated with Vince Jeffs. Vince is the senior director of product strategy for AI and

02:19.080 --> 02:22.960
decisioning. Vince, welcome to this week in machine learning and AI.

02:22.960 --> 02:24.600
Thanks Sam, great to be here.

02:24.600 --> 02:29.400
It's great to have you here. Let's get started by talking a little bit about your journey

02:29.400 --> 02:33.800
to AI. How did you get into this space? What's your background?

02:33.800 --> 02:39.440
Yeah, I've got a surturicus background to coming to where I am, but it's been a fun

02:39.440 --> 02:47.280
journey. I actually studied applied statistics at Georgetown in the University of Maryland

02:47.280 --> 02:54.440
long time ago and I think that's kind of what AI has become. We called it applied statistics

02:54.440 --> 03:00.280
back then. Now it's fancy term AI, but it's all good. From there I worked on the client

03:00.280 --> 03:07.480
side with UPS, working, building, decisioning and marketing technology systems. I worked

03:07.480 --> 03:13.040
with an agency, Rapp Collins. I worked with SAS, the business intelligence and analytics

03:13.040 --> 03:20.920
vendor and did that for about four years. Then I joined a company called Unica. Unica

03:20.920 --> 03:28.000
was actually doing predictive modeling with their first solution. Then they got into the

03:28.000 --> 03:32.440
marketing technology space and I spent ten years with Unica before they were bought

03:32.440 --> 03:41.320
by IBM. I spent a few years with IBM. I like to say, sort of, kiddingly, that my career

03:41.320 --> 03:48.560
took me from Big Brown to Big Blue. Then I ended up with PEGA. I spent the last four years

03:48.560 --> 03:56.240
with PEGA in that product strategy role. So did you know John Hogan? Yes, absolutely.

03:56.240 --> 04:04.480
We worked together in a past life. John's a great guy. He headed up engineering at Unica

04:04.480 --> 04:13.120
for years. Awesome. Tell us a little bit about your role at PEGA. What's your focus at

04:13.120 --> 04:17.680
PEGA systems? It's a lot of fun at this point in my career because I do get to think

04:17.680 --> 04:24.680
about the strategic factors that a software vendor needs to consider as they build product

04:24.680 --> 04:30.840
as they decide whether or not they need to maybe buy something or partner. That's really

04:30.840 --> 04:35.080
the kind of, when I tell people, there's three things I do. I worry about building buy-in

04:35.080 --> 04:42.000
and partnering and the right mix of that and when to do that. That's a fairly broad set

04:42.000 --> 04:48.680
of items there. I really do work closely with our product team. We have a product team

04:48.680 --> 04:57.240
in Amsterdam and a product team in Cambridge. We think a lot about facets of the way

04:57.240 --> 05:02.720
we would prioritize what we would build into our product. We want to be market driven.

05:02.720 --> 05:06.880
We want to do things that are innovative. We want to balance that with what our customers

05:06.880 --> 05:13.400
need and what they demand to make the software successful. Then we also have a lot of people

05:13.400 --> 05:19.800
call it technical debt that you have to always be paying back and fixing the underlying

05:19.800 --> 05:24.640
technology, being able to do things faster and more efficiently. We try to balance those

05:24.640 --> 05:28.440
three things and we've come up with a way of doing that. That's a big part of my job

05:28.440 --> 05:35.200
is working with everyone that's involved in that process. Then also I do work very much

05:35.200 --> 05:41.960
with our partner team. You're here at PEGA World with us. We announced this morning

05:41.960 --> 05:48.480
our launch of an ISV partner program. I've had a big hand in that and some of the partners

05:48.480 --> 05:52.320
that were mentioned that are going to be in that program, such as movable link and

05:52.320 --> 05:58.040
celebrous. In Prasado, I've worked very closely and helped bring those partners along and

05:58.040 --> 06:03.640
nurture them in their journey with us. Fantastic. Fantastic. You gave a couple of presentations

06:03.640 --> 06:09.600
here at the conference yesterday. What were those on? I did. I did. It was a fast, fun,

06:09.600 --> 06:16.680
furious day for me. I did a couple of presentations yesterday. One was a really cool thing that I'm

06:16.680 --> 06:22.520
very passionate about and that is driving new innovations into our product by having

06:22.520 --> 06:27.280
the idea of an innovation lab. It's not so much research. I like to think as research

06:27.280 --> 06:31.760
is more academic. It's more thinking about really applied ways that we can do cool new

06:31.760 --> 06:36.600
things in ways that we can actually affect customer journeys and customer experience

06:36.600 --> 06:43.760
with AI and machine learning. We did what we called for sneak peeks where we wove that

06:43.760 --> 06:49.280
into a story about a gal named Danielle who has a connected car and we're trying to

06:49.280 --> 06:53.760
predict things that might go wrong with her car. We're trying to help her experience

06:53.760 --> 06:59.400
by diagnosing things quicker. We're also trying to be more personalized when we communicate

06:59.400 --> 07:05.120
with her. Then ultimately we're trying to manage any of the communications we're doing

07:05.120 --> 07:10.840
to make sure we're always doing something intelligent, relevant and smart. What was the

07:10.840 --> 07:16.120
other presentation? The other presentation was a panel discussion. I was very thrilled

07:16.120 --> 07:25.440
to be able to host three of our great customers, British gas, GM and HSBC. As I kidded when

07:25.440 --> 07:31.920
I opened it up, we had gas, we had a car and we had financing. We had a nice mixture

07:31.920 --> 07:36.520
of use cases so you could go somewhere. We could go somewhere with that. That's exactly

07:36.520 --> 07:43.920
right. It was fun. They have great stories. I let them do most of the talking. I think

07:43.920 --> 07:49.600
we ended up with a nice blend of where they are today with AI and their use of it in a

07:49.600 --> 07:55.240
practical way and where they're on their journey to what we like to call Omni Channel

07:55.240 --> 07:59.560
experiences with customers and then where they're taking that, how they're expanding

07:59.560 --> 08:07.000
that out in their organizations to try to continue to drive more customer-centric value.

08:07.000 --> 08:13.000
Awesome. Maybe let's go back to that first presentation and talk through these four scenarios

08:13.000 --> 08:19.200
with an emphasis, of course, on the AI and machine learning bits that you were showing.

08:19.200 --> 08:25.800
Yeah, absolutely. As I said, we had four sneak peeks and the first one was really about

08:25.800 --> 08:33.040
Danielle having some car problems. There's connected cars today. GM tells a great story

08:33.040 --> 08:37.800
and they were on my panel and telling that story. Travis Bradburn tells that he's been

08:37.800 --> 08:43.040
10 years working with Pega and the connected car with GM. They really pioneered some of

08:43.040 --> 08:47.520
this. I based on Star in particular. On Star, exactly. Customers of GM that have the

08:47.520 --> 08:52.920
on-star package are familiar with the whole connected car experience. We based that

08:52.920 --> 08:58.480
on that sort of use case a little bit, but where we were taking it was into the deep learning

08:58.480 --> 09:04.720
area. We've been very big about applying what we call practical AI. There's plenty of

09:04.720 --> 09:12.600
models today that are very useful, supervised machine learning models such as logistic regression

09:12.600 --> 09:16.960
and Bayesian and lots of things that we use today, but what we are really experimenting with

09:16.960 --> 09:21.920
is the ability for deep learning to listen to a lot of different data sources and there's

09:21.920 --> 09:27.240
a lot of different data sources coming off both the connected car and Danielle herself

09:27.240 --> 09:33.320
using her mobile app and going on the website and engaging with the brand. We were learning

09:33.320 --> 09:40.400
sort of what might be going wrong with both Danielle's experiences and her car and basically

09:40.400 --> 09:46.880
that was about using deep learning to trigger off a early warning that there may be something

09:46.880 --> 09:53.640
trending bad with her car before we have to actually wait, which is the typical car

09:53.640 --> 09:58.120
users experience today. Suddenly, they get a check engine light and usually when they

09:58.120 --> 10:02.600
get that, there's already something wrong with their car. Sometimes it's something simple

10:02.600 --> 10:06.880
like maybe a gas caps loose, but more often than not, it's something where there's actually

10:06.880 --> 10:11.640
a part that's already failing. What we were trying to use is deep learning to preempt

10:11.640 --> 10:16.920
that to actually listen to all those different sensors and be able to give an early warning

10:16.920 --> 10:21.840
and maybe get that car into the shop to have a look at it before something actually breaks

10:21.840 --> 10:22.840
down.

10:22.840 --> 10:29.840
Can you take us inside the process of building out this demo in the lab? Where did the

10:29.840 --> 10:33.360
data come from, for example, and what were some of the specific data sources that you

10:33.360 --> 10:34.360
used?

10:34.360 --> 10:38.720
Right. The data sources were pretty much the device sensors that are on the connected

10:38.720 --> 10:51.640
car. We were listening to things like breaking gas mileage, oil pressure, and then any

10:51.640 --> 10:58.360
sensors themselves, like sensors that might be able to tell us that the oxygen levels

10:58.360 --> 11:04.040
in the system are trending in a bad direction. That could actually be an indication that

11:04.040 --> 11:10.680
some underlying part is about to fail in the near future. As we're in remember, this

11:10.680 --> 11:16.040
is a connected car. We're getting this data constantly. Every time they call it key

11:16.040 --> 11:24.360
turns, every time there's a key turn, the decision hub is being fed new data. We're able to

11:24.360 --> 11:30.360
learn, again, every time there's a key turn and she takes that car out on her commute,

11:30.360 --> 11:33.600
we're able to learn more about the performance of that vehicle.

11:33.600 --> 11:38.120
What we were doing is we were using deep learning to actually look into the future and say,

11:38.120 --> 11:42.320
we predict that the performance, not necessarily there's going to be a breakdown. It wasn't

11:42.320 --> 11:48.280
so much about actually a bad breakdown, but it was more about gas mileage performance

11:48.280 --> 11:55.640
going down. We want to be able to prevent her from just losing money on paying for unnecessary

11:55.640 --> 12:02.440
gas. That's the alert that we gave her. We said, nothing urgent. Your performance is degrading.

12:02.440 --> 12:08.320
If you come in, she was still under warranty. We'll have a look at this and then that led

12:08.320 --> 12:10.560
to the second sneak peak.

12:10.560 --> 12:16.400
You mentioned that the scenarios incorporated both data from the vehicle as well as data

12:16.400 --> 12:21.920
from Danielle herself did. Any of this Danielle originated data come into play in this

12:21.920 --> 12:29.680
first scenario? It did not in the first sneak peak. It did later on. We'll make sure

12:29.680 --> 12:34.000
to hit on that. You're leading us into the second sneak peak.

12:34.000 --> 12:40.760
What we had done is we had provided her with, again, a friendly alert when it's convenient

12:40.760 --> 12:45.760
and we could also automate the process of helping her schedule an appointment and using

12:45.760 --> 12:50.760
some AI technologies. Those aren't real fancy AI technologies, but they're good customer

12:50.760 --> 12:56.520
experiences to get her into a dealership maybe that she's used in the past and she's comfortable

12:56.520 --> 13:04.840
with and at a time that's comfortable for her. We can maybe not so much predict but give

13:04.840 --> 13:10.400
her convenience associated with her past behaviors.

13:10.400 --> 13:16.640
Then once we got her into the shop, really what we had, the second sneak peak was all about

13:16.640 --> 13:24.000
helping that technician through the diagnostic process. We're using some rules which Pega

13:24.000 --> 13:32.680
has a great rules engine along with some models to help that technician get quicker to

13:32.680 --> 13:40.200
a solution. As the technician was already given a next best set of service actions that

13:40.200 --> 13:46.560
they might look at and they were inspecting the car and saying, well, no, this is probably

13:46.560 --> 13:53.800
not the problem even though you're saying it's a 60% model saying it's a 60% propensity

13:53.800 --> 13:59.560
as soon as the agent gives the feedback to the model that that particular item wasn't

13:59.560 --> 14:05.520
the problem, then the model can recalculate and hone in on what is the likely problem. We

14:05.520 --> 14:11.240
had six or seven different things that were teed up as potential problems in this situation

14:11.240 --> 14:16.280
and we were able to help that technician quickly narrow down to the problem probably faster

14:16.280 --> 14:21.640
than they would have just buy somewhat trial and error which happens in the shop sometimes.

14:21.640 --> 14:29.720
It's interesting that example where we are with machine learning and AI today is kind

14:29.720 --> 14:36.600
of easy to think of that as passe, what's the right way to come at this. What's interesting

14:36.600 --> 14:42.760
to me about that specific example that you give as well, it doesn't strike us as kind

14:42.760 --> 14:49.640
of the way we think of machine learning and AI today. AI in the 70s and 80s was all about

14:49.640 --> 14:56.760
these expert systems that were trying to guide maintenance people through processes to help

14:56.760 --> 15:05.240
them move, help them resolve issues more quickly. It's interesting that we're kind of combining

15:05.240 --> 15:11.400
kind of in this rule system you're describing traditionally or older approaches or thinking

15:11.400 --> 15:16.280
around AI with more modern deep learning and other types of technologies.

15:16.280 --> 15:21.480
Absolutely and I think that's you've hit on what we feel is like you know sometimes innovation

15:21.480 --> 15:28.840
and I'll try to pull out a quote is rediscovering things from the past and then and then putting

15:28.840 --> 15:35.400
a new twist on them right or combining multiple innovations from the past and I think expert systems

15:35.400 --> 15:40.920
still have you know a very good role to serve in the right use cases it's just like when I'm

15:40.920 --> 15:45.880
sure you would agree with me with machine learning it's not about one algorithm it's not about

15:45.880 --> 15:51.400
this new deep learning which is you know really cool new ways to do neural networks which have

15:51.400 --> 15:57.240
been around for you know 20 years or more right but and there's some great advances there don't get

15:57.240 --> 16:01.960
me wrong but it's about picking the right algorithm for the right problems and then sometimes

16:01.960 --> 16:08.600
combining those together into a real solution for somebody like a technician or a car owner to

16:08.600 --> 16:15.400
benefit from the application of multiple sets of analytics together so yes there there wasn't one

16:15.400 --> 16:21.960
piece of analytics I could point to in that second sneak peak that's terribly new or innovative

16:21.960 --> 16:28.520
but it is the combination of these things in practical ways of application that really do drive

16:28.520 --> 16:34.680
value for consumers and organizations and so what was the third sneak peak then so the third

16:34.680 --> 16:41.720
sneak peak is a little cooler okay so so that's good because we don't want to get you know on an AI

16:41.720 --> 16:46.680
podcast and not have a few things that are cool to talk about so deep learning is cool and also

16:46.680 --> 16:52.520
this one is which is this one was about what we really called dynamic email notifications but

16:52.520 --> 16:57.240
we really believe this is going to any kind of dynamic treatments the customers might get and

16:57.240 --> 17:01.960
when I say treatments I mean you know whether you get something that is presented to you on a

17:01.960 --> 17:06.520
website or whether you get it in your mobile app or whether you get it in an email I would think

17:06.520 --> 17:12.680
of all those is sort of consumer treatments it's a brand having a conversation with you and this

17:12.680 --> 17:18.280
sneak peak was about making that email much more dynamic and when you think about it emails kind

17:18.280 --> 17:22.840
of an older channel now almost getting like direct mail right where you think yeah you know that's

17:22.840 --> 17:29.480
a lot of people have have you know predicted the death of email like they did cobalt right but

17:29.480 --> 17:36.120
as we heard on stage it at at Peggy yesterday from Affleck I think there's still cobalt running

17:37.080 --> 17:42.360
so so there's going to be email I believe for a while and it's still a very viable channel

17:42.360 --> 17:48.440
but what we're doing is making it dynamic so that it is essentially like a web page and so really

17:48.440 --> 17:54.200
a lot of people think about emails outbound treatment outbound marketing we really like to think

17:54.200 --> 18:00.040
of it now with this new sneak peak as inbound and that might sound crazy but what I mean by that

18:00.040 --> 18:05.720
is when that email goes out it's nothing more than a template there's containers in it that will

18:05.720 --> 18:11.400
be pre-populated that aren't pre-populated excuse me with content that's the way most emails

18:11.400 --> 18:17.160
are done today organizations have to back up weeks and get approval and decide exactly what's

18:17.160 --> 18:21.720
going to go into that email and then they send it out and then maybe you don't open it for another

18:21.720 --> 18:26.200
two or three days because you're behind on your email right or that's a personal email account

18:26.200 --> 18:30.520
you don't check it that often but maybe you go in there because you do a search for a brand

18:30.520 --> 18:35.800
you're interested in something and pop up that email now suddenly that content is three or four

18:35.800 --> 18:41.720
weeks stale that's not going to make for a great experience very often in the contextual world

18:41.720 --> 18:47.560
we live in so what we did in this sneak peak is we showed how working with a natural language

18:47.560 --> 18:55.560
generation partner that we're now partnered with Pursado and a dynamic email content provider

18:55.560 --> 19:02.360
movable link and Pega we could dynamically populate that email with content at open time

19:02.360 --> 19:08.120
so at open time when you open that email now it calls back to Pega it gets the next best

19:08.120 --> 19:13.880
content to put into that email in this case it was thanking Dan Yale for coming into the

19:13.880 --> 19:21.160
you know get her car service quickly and actually encouraging her to sign up to a new loyalty

19:21.160 --> 19:26.520
program that we had and even encouraging her with some you know points that were specific to her

19:26.520 --> 19:32.760
value and then the language that was used in there which is the Pursado piece was generated

19:33.640 --> 19:40.440
for Dan Yale so knowing what emotional language she responds to and you can do that if you have

19:40.440 --> 19:46.040
enough interactions you need a lot you need maybe 75 interactions with Dan Yale but if you do that

19:46.040 --> 19:52.040
and you test and learn you can learn that she might respond to appreciative language or

19:52.040 --> 19:56.920
urgent language and there's a set of emotions that Pursado sort of keeps track of and they tune

19:56.920 --> 20:02.840
the language and to you know what resonates with her and when you think about it that's great

20:02.840 --> 20:08.680
that's more like a brand having a conversation with a customer rather than having some one-size-fits-all

20:08.680 --> 20:15.800
treatment so there's AI happening at the Pursado level around this natural language generation

20:15.800 --> 20:22.680
and customization is there a lot of what I've seen at at the conference here and in the key notes

20:22.680 --> 20:29.160
is around optimizing the presentation of all offers kind of referring back to the the podcast I

20:29.160 --> 20:34.840
did with Rob Walker and the next best action and next best offer is there talk a little bit about

20:34.840 --> 20:42.680
the AI that's you know that is involved in that piece in this third sneak peak right right so

20:43.400 --> 20:52.200
when when Dan Yale opens that email Pursado has already sort of figured out probably a number of

20:52.200 --> 20:58.120
variations that they're going to test with Dan Yale they've maybe been again if you you know

20:58.120 --> 21:04.520
walk with my scenario and assume that yes we have interacted with Dan Yale before we've had a

21:04.520 --> 21:08.920
number of chances to test and learn with that with that language that we're going to use so they've

21:08.920 --> 21:14.520
got some other variations maybe call it 16 or 20 variations sitting out there that now they're

21:14.520 --> 21:18.760
continuing to test so that loop is going on each time we have an interaction with Dan Yale

21:19.400 --> 21:26.840
what we're doing is we're actually providing the the the actual piece of content that we want to

21:26.840 --> 21:31.240
so the image that we want to put in there maybe we want to put a you know an image of Dan Yale

21:31.240 --> 21:37.400
in her you know not her Dan Yale herself but somebody that you know Dan Yale might resonate with

21:37.400 --> 21:44.120
and the type of car she has and and then we're also putting in very specific copy that we might

21:44.120 --> 21:50.440
be controlling like the fact that she had just been in to the shop yesterday we can actually

21:51.320 --> 21:57.400
tune that to the fact that we put that language in that says thanks for coming in yesterday

21:57.400 --> 22:02.840
as opposed to you know just thanks for coming in so just little things like that that might sound

22:02.840 --> 22:08.920
a little trivial but they add up what we've what we've been able to prove is that as that email

22:08.920 --> 22:14.760
becomes more and more relevant and then we're populating in some very specific content again like

22:15.400 --> 22:22.200
and please sign up for our new rewards program that we just launched you know two days ago again we

22:22.200 --> 22:29.160
can be very specific about the context of that we would love to reward you with 100 value points

22:29.160 --> 22:36.680
for signing up and those value points again we can at real time recalculate and decide how many

22:36.680 --> 22:42.840
points we want to give to Dan Yale based on a model we have about her lifetime value and her

22:42.840 --> 22:48.280
loyalty and this sort of thing so we can be discriminative about how much points we give her versus

22:48.280 --> 22:55.240
somebody else based on her loyalty and we can do that again at open time if we can maybe

22:55.880 --> 23:01.960
digress from the sneak peeks for a second sure one question that is jumping out at me and

23:01.960 --> 23:07.960
this relates to a conversation I had with someone here at the event yesterday I think you know we've

23:07.960 --> 23:15.960
established that consumers appreciate personalized experiences we all know that you know we've

23:15.960 --> 23:20.360
all had the experience the the opposite of that where you you call into a call center to get

23:20.360 --> 23:24.760
something done you get bounced around four times and each time you have to tell them who you are

23:24.760 --> 23:28.920
and what the problem is right that's you know the antithesis of a personalized experience and now

23:28.920 --> 23:35.320
what we're talking about are these hyper personalized experiences where you're drawing on this vast

23:36.280 --> 23:43.000
you know database of knowledge you know based on interactions and I guess that the observation

23:43.000 --> 23:47.880
is that you know sometimes it comes across as creepy yeah right even for me I'm like very

23:47.880 --> 23:53.320
technology for I thought that's where you were going right very technology for like I love the

23:53.320 --> 23:58.920
technology that's enabling all this but you know I hear it and sometimes like and I'm wondering

23:59.560 --> 24:05.240
yeah you can talk about your general perspective on this but I'm wondering specifically

24:05.240 --> 24:10.840
if you've done research into you know from the perspective of innovation labs or if you've

24:10.840 --> 24:20.920
you know seen research elsewhere that tries to you know explore this personalization versus you

24:20.920 --> 24:27.160
know creepiness and and you know the way consumers you know do we have data that says that consumers

24:27.160 --> 24:32.440
really want that beyond the fact that they do actually click more yeah yeah it's it's it's a

24:32.440 --> 24:37.880
really interesting area and I'd say we don't have a lot of data on that and it is a good

24:37.880 --> 24:44.120
area for us as an industry to really dig into more especially with you know more of these you

24:44.120 --> 24:51.400
know regulations that are becoming more prominent right with like everybody knows about GDPR

24:51.400 --> 24:57.400
which just launched May 25th but I think that's just a that's really a swell that's going on

24:57.400 --> 25:02.840
it's not just in Europe I think it's happening everywhere quite frankly where consumers are waking

25:02.840 --> 25:07.480
up a little bit to the fact that there's been a lot of data collected about them and it's being

25:07.480 --> 25:13.000
collected and they need to sort of seize a little bit control of that you know let's face it

25:13.000 --> 25:20.520
consumers are empowered but they're also sometimes naive about what's going on in the background

25:20.520 --> 25:26.280
but then once they become less naive about that then they become more empowered and I think brands

25:26.280 --> 25:34.680
want to you know buy in large most trusted big name brands smart companies want to be responsible

25:34.680 --> 25:41.560
about that but they don't know where that line is exactly and they need to they need to be very

25:41.560 --> 25:47.240
careful about how they test that they don't want to test that in actual practice if they don't

25:47.240 --> 25:52.520
know what they're doing so that makes them a lot more conservative and that's not always good so

25:52.520 --> 25:58.280
what we believe is that they can test some of that using simulations and using other means to

25:58.280 --> 26:06.280
push the envelope a little bit in a lab if you will and then sort of slowly roll out and test

26:06.280 --> 26:15.080
that you know that line how do you test consumer attitudes and consumer reactions to you know

26:15.080 --> 26:21.240
a campaign and a set of interactions and via simulation yeah well I think first of all you need

26:21.240 --> 26:27.160
to do some of those tests with voice of the customer you know with panels and actually you know

26:27.160 --> 26:32.200
ask your customers right you don't have to ask all of them you can use statistics to figure out

26:32.200 --> 26:36.920
you know approximately whether your customer base is happy or not with this kind of a thing that

26:36.920 --> 26:43.560
you're doing but then what you can do is you can use simulations to kind of like run the scenarios

26:43.560 --> 26:51.160
that might play out in terms of things like say opt out it's not always a catastrophic event that

26:51.160 --> 26:57.400
happens when you cross the creepy line but it can be a bad marketing event right like if somebody

26:57.400 --> 27:04.120
opts out and now there's better ways to be a little bit more granular as a customer as a company

27:04.120 --> 27:10.680
about how you set permissions and allow consumers to set those permissions and so they you know

27:10.680 --> 27:16.120
you can get smart about them being able opt out of certain things but then you know entice them

27:16.120 --> 27:20.680
still to want to engage with your brand and other areas even if they're going to opt out of these

27:20.680 --> 27:26.280
these channels or these communications so I think you need to you know be smart about how you test

27:26.280 --> 27:34.760
that I think where you're going which is kind of interesting and it goes back to the the scenario the

27:34.760 --> 27:40.840
the sneak peak of you know using the data that you have and kind of additudinal

27:42.920 --> 27:48.120
learnings about a particular customer maybe there's a way to determine customers that will

27:48.120 --> 27:55.080
be creeped out and then send them more generic if you will emails or less kind of edgy

27:55.720 --> 28:00.760
types of emails I don't it's not clear to me like how you would learn that but it's a really

28:00.760 --> 28:07.000
interesting area and I guess to your to your other point you know maybe just ask right yeah yeah

28:07.000 --> 28:14.120
maybe ask in sample and use you know some traditional methods of statistics to extrapolate right

28:14.120 --> 28:20.440
but I think you know you're on to what you know we're kind of digging into a little bit which is

28:20.440 --> 28:25.880
you know you really have to you know you have to kind of blend that together and

28:25.880 --> 28:35.800
and and then you know be careful about how you roll it out and and and monitor it very closely

28:35.800 --> 28:40.920
right monitor what's going on is you're testing because you don't have to roll these things out

28:40.920 --> 28:47.400
in mass right you roll them out in very small increments when you put it into production and then

28:47.400 --> 28:52.520
you watch what's happening and you compare that with what you thought was going to happen in the

28:52.520 --> 29:00.040
simulations you did and and you adjust right that's one of the hallmarks we think of what Pega

29:00.040 --> 29:06.440
helps do is it really helps customers be able to be more agile about once they do do things in

29:06.440 --> 29:11.960
production about being able to quickly rotate and change you know directions if they need to

29:11.960 --> 29:17.720
or pull something back out if it's not working commonwealth bank of australia and the keynote

29:17.720 --> 29:23.160
this morning talked about how they were able to do those things you know in five hours now to make

29:23.160 --> 29:29.320
changes as opposed to something that took eight weeks to do so that's I think a key you know part of

29:29.320 --> 29:34.680
it is hey you know when you're using AI and when you when you're affecting customer experience

29:34.680 --> 29:40.280
it's going to be a test and learn process you're not going to your lab is not going to have it

29:40.280 --> 29:46.680
completely right right but if you have the ability to at least make an educated guess going in

29:47.320 --> 29:54.520
and then and ask your customers right so we touched on that and then you know pivot fairly

29:54.520 --> 30:00.680
rapidly when you see that it's not exactly going as we drew it up on the drawing board that's key

30:00.680 --> 30:05.720
and I think you can you know get smart then about how you treat those customers in which ones like

30:05.720 --> 30:14.200
you said which ones your modeling which ones you feel are you know going to be more sensitive versus

30:14.200 --> 30:18.840
not and and then your models can learn and get smarter about that is you get more and more

30:18.840 --> 30:23.960
customers that you're learning you know you're getting more granular about the sensitivity almost

30:23.960 --> 30:29.000
like prosados getting more and more granular about the language that you respond to you get more

30:29.000 --> 30:33.880
granular about your ability to decide whether Sam's going to be creeped out or Vince is going to

30:33.880 --> 30:41.320
be creeped out interesting interesting so popping back over to this fourth sneak peak yep yep so

30:41.320 --> 30:49.640
the fourth sneak peak the the story kind of culminated with with Danielle being happy being

30:49.640 --> 30:55.800
in a back in a happy place right she had her car fix she got this you know offered a sign up for

30:55.800 --> 31:01.960
this loyalty program and get points so she accepted that everything was looking great until the

31:01.960 --> 31:08.280
next morning she gets in an accident okay so we had to add a little drama to the to the scenario

31:08.280 --> 31:14.680
and that and of course she has a connected car so we have some we have some intelligence about

31:14.680 --> 31:21.400
maybe how bad that accident was now we don't want to cross the creepy line you know so we don't

31:21.400 --> 31:28.680
like reach out to her or anything but what we do do is and and the scenario continued with her

31:28.680 --> 31:34.280
then get it wasn't a major accident so the airbag didn't go off but she got on right after that

31:34.280 --> 31:40.600
happened she got on her mobile and she was looking on our service pages right maybe she was looking

31:40.600 --> 31:46.200
up to see if you know it's cosmetic damage you know sort of whatever whatever she needed to kind

31:46.200 --> 31:52.200
of you know do a little investigation on and that were those were cues that we were picking up

31:52.200 --> 31:57.400
so we're picking up the fact that suddenly Danielle's like looking at service pages and looking

31:57.400 --> 32:04.200
at these pages that nothing to do with maybe buying a new car or you know how to use her mobile app

32:04.200 --> 32:10.760
so we decided that and we call it next best moment that we had some marketing we had a marketing

32:10.760 --> 32:16.680
treatment teed up to go out to her in two days after sneak peak number three had concluded and

32:16.680 --> 32:21.160
that was going to be we were going to make her this big great offer on a new car because she had

32:21.160 --> 32:28.680
a older connected car well we decided that the next best action and the next best moment for that

32:28.680 --> 32:33.960
was going to be you know that night because she checks emails that night and we kind of learn

32:33.960 --> 32:39.960
that that's the time she's most likely to engage with emails what we did is we actually took that

32:39.960 --> 32:46.200
communication out of the queue because we recognize that there's something going on we don't know exactly

32:46.200 --> 32:53.400
what it is but we predict that she's probably going to be calling us you know for some more service

32:53.400 --> 32:59.640
and so therefore it's not time to be marketing to her so we actually pause that you know maybe

32:59.640 --> 33:05.240
we'll resume it later on again when you know when the time's right but the time wasn't right so we

33:05.240 --> 33:12.680
pause that and we really manage that next touch point proactively interesting interesting and

33:12.680 --> 33:21.400
so across the maybe talk a little bit about what what goes into that from is there MLAI

33:22.840 --> 33:29.160
involved in that fourth scenario and and how is it expressed yeah yeah good question we like

33:29.160 --> 33:34.680
to categorize decision management and the arbitration of decisions as AI we think it's fair

33:34.680 --> 33:39.880
actually there's there's been you know other third parties like Forster that have agreed with

33:39.880 --> 33:45.800
that that decision management is a form of AI I guess those things can be argued by the AI

33:45.800 --> 33:51.480
purists right and and you know to some extent I understand their arguments that you know let's say

33:51.480 --> 33:57.240
basic rules or even some of the basic robotics that's just pure automation right there isn't anything

33:57.800 --> 34:04.200
you know terribly sophisticated algorithmically going on let's just for the sake of this

34:04.200 --> 34:10.680
conversation say that that's part of AI decision management so we can we can decide the you know

34:10.680 --> 34:16.600
the the decisions that we're going to make either today when Danielle comes in channel in the

34:16.600 --> 34:21.720
mobile app we decide what we want to actually present in a container there or on the website

34:22.440 --> 34:28.120
but we also can look at the decisions that we've teed up right that our marketing organization

34:28.120 --> 34:34.680
has teed up and they're in a queue ready to go out and and we can arbitrate all that we can capture

34:35.000 --> 34:40.040
you know things we can sort of you know capture and kill things if we need to or capture and pause

34:40.040 --> 34:46.680
things so that was really more about again not fancy AI technology so to speak but the orchestration

34:46.680 --> 34:52.040
of decisions across channels which again what we've seen is that that that just has tremendous

34:52.040 --> 35:00.040
benefits for organizations yeah and that's been a core theme across the keynotes that I've seen here

35:00.040 --> 35:06.440
and and one of the things that I've observed is that a lot of emphasis has been placed on

35:07.080 --> 35:15.320
the distinction between this traditional approach to marketing that is characterized by

35:15.320 --> 35:23.960
set segments that are determined say on the on the period of you know weeks you know versus a

35:23.960 --> 35:30.440
continually optimized marketing loop that's in a real time putting the other offers for

35:31.800 --> 35:37.720
for customers and you know this model extends beyond marketing but marketing is an example that's

35:37.720 --> 35:42.520
been frequently used can you allow rate on that distinction and how you see that playing out

35:42.520 --> 35:48.600
absolutely I think that's a really important distinction and it actually is a you know we sometimes

35:48.600 --> 35:53.720
call it like a hundred and eighty degrees shift in in the way you think about how you approach

35:54.760 --> 35:59.400
understanding a customer and then taking action on that customer so when you use the more

35:59.400 --> 36:04.760
traditional approach as you called it which by the way is has you know still has applications

36:04.760 --> 36:10.040
today in some cases where you just simply don't don't have any customer data right if you have

36:10.040 --> 36:14.600
to go out and do advertising and you really don't have customers that are aware of you you might

36:14.600 --> 36:19.640
have to use segmented approach to reach those customers but once you have some customer data

36:19.640 --> 36:24.600
and that doesn't take very long as an organization right once you or on board a customer

36:24.600 --> 36:30.120
and they've transacted with you a little bit you've got a wealth of information about that individual

36:30.120 --> 36:37.240
customer why not use that in the moment for any conversation or treatment that you're going to

36:37.240 --> 36:44.920
have with that customer as opposed to putting them into buckets where they're going to be you know

36:44.920 --> 36:52.760
batch treated um sometimes uh in in a way that lots of other customers will be treated and maybe

36:52.760 --> 36:57.800
a few of those it's very relevant too but maybe a lot of them it doesn't resonate very well

36:57.800 --> 37:05.320
so it really is a more always on transactional approach to say that what we're going to do is we're

37:05.320 --> 37:12.040
really going to let this engine wake up and get the data that it's got about this customer

37:12.040 --> 37:19.480
as of right now and make a decision of what to put into something and do that populate it

37:19.480 --> 37:24.600
in real time literally in hundreds of milliseconds doesn't matter if it's a web container

37:24.600 --> 37:29.480
doesn't matter if it's a mobile app that's calling to get some next best action doesn't matter

37:29.480 --> 37:36.440
if it's a you know call center rep that that needs more information or wants something recalculated

37:36.440 --> 37:42.680
but you do that in real time as opposed to as you said sort of pre-calculating it sometimes weeks

37:43.480 --> 37:48.840
you know ago which things can lose their relevance very rapidly maybe that customer you know

37:48.840 --> 37:54.120
bought something that you're now you know you're you're marketing to them something they already

37:54.120 --> 37:59.960
you know purchased or or they're now interested in something else and you're not factoring that

37:59.960 --> 38:05.560
in to your conversation you need to sell this to Amazon because they do that all the time they do

38:06.920 --> 38:11.560
you were just shopping for shoes yes I bought this shoes why are you still telling me about this

38:11.560 --> 38:16.520
shoes and you know that's because that's a you probably know that's an algorithm that you know

38:16.520 --> 38:21.960
collaborative filtering and wisdom of the crowd algorithm again it has its applications

38:21.960 --> 38:27.960
especially when you've got tight product affinities it can matter you know this tie goes with this

38:27.960 --> 38:33.160
shirt sort of thing but then there's other times when that algorithm isn't working so well

38:33.160 --> 38:38.360
right and where you know something about that customer you need to use that intelligence rather

38:38.360 --> 38:45.080
than just the fact that other people buy these things together yeah yeah um and so maybe to to wrap

38:45.080 --> 38:54.120
up the session that you did with HSBC it was GM GM British gas British gas what were the highlights

38:54.120 --> 39:01.480
of that session yeah the highlights were really we spent about half the time talking about

39:01.480 --> 39:07.000
how they got to where they are and the fact that they're not there yet right they're getting

39:07.000 --> 39:12.520
great value but it's it's a job in these big these are all big companies right huge companies

39:12.520 --> 39:21.160
and so it's a long journey to to get a big company to really change its mindset about how it

39:21.160 --> 39:26.680
approaches these things and and to do that across all the channels that they're interacting with

39:26.680 --> 39:33.000
uh in in case of GM they started with on star that's great on star customers are getting a more

39:33.000 --> 39:39.400
dynamic and you know personalized and you know they're using more data to help improve the experience

39:39.400 --> 39:45.320
of the on star customer but what about the all the other GM customers that don't use on star right

39:45.320 --> 39:50.840
and so Travis talked about how they're starting to roll that out into more of their you know

39:50.840 --> 39:58.360
programs beyond just the on star program British gas uh Joe Allen told a similar story about where

39:58.360 --> 40:03.320
they really did tackle a lot in their first couple of years of putting peg in they really felt like

40:03.320 --> 40:08.280
you know if you're a gas or electricity customer you don't interact with those brands too often

40:08.280 --> 40:13.400
right but when you do it's really important right it might just be before your contract

40:13.400 --> 40:17.720
is up or so there's these really important moments of truth where you've got to get

40:17.720 --> 40:22.600
things well with synchronized so she talked about how they they couldn't start in just one

40:22.600 --> 40:29.000
channel they really went in you know in and she calls it we did inbound outbound and we ended up

40:29.000 --> 40:35.320
with unbound um which was I I love the tagline because the idea there is it's more channelless

40:35.320 --> 40:41.880
it's really not about channels it's about making decisions for the customer and being coordinated

40:41.880 --> 40:48.280
across omnichandals um but then she talked about how they're taking that to paid media um and

40:48.280 --> 40:53.640
you know outside of their own media which is really interesting and then she also talked about

40:53.640 --> 40:57.800
how they're using it now in their loyalty program and they're expanding the use of it in their

40:57.800 --> 41:05.080
loyalty program so um and then HSBC also talked along similar lines Fabian uh was great

41:05.080 --> 41:11.480
about explaining how the bank is really interested in getting those experiences right when customers

41:11.480 --> 41:17.240
are doing things on the website you know when they're when they're using a mortgage loan calculator

41:17.240 --> 41:23.720
that's incredible information you know if they stop using it suddenly you know there's opportunities

41:23.720 --> 41:28.680
to again reach out and try to help the customer maybe they were struggling with something you know

41:28.680 --> 41:33.720
maybe there's questions that you've got to answer for them and so they he told you know great

41:33.720 --> 41:40.200
examples of where brands need to continue to think about AI and the ability for it to drive

41:40.200 --> 41:45.800
you know self-service but also how the human comes into the loop in those it's really important

41:45.800 --> 41:52.920
that the agents be well equipped and they can get AI help to be better equipped to have great

41:52.920 --> 41:59.480
conversations with customers and be more you know be more convenient and more helpful with them right

41:59.480 --> 42:04.040
so we don't have those experiences that we started out with that you talked about with somebody

42:04.040 --> 42:09.480
bouncing around an IVR you know getting a rep that transfers you to another rep that asks you

42:09.480 --> 42:14.760
the same questions over and over and you're just about to pull your hair out um so it is really

42:14.760 --> 42:21.480
important to get the human well you know integrated into that loop with AI and you know um Fabian told

42:21.480 --> 42:27.480
great examples of how they're doing that fantastic Vince it's been great catching up on what you're

42:27.480 --> 42:33.240
up to anything you'd like to add to close us up no it's been great to talk here with you Sam it's

42:33.240 --> 42:40.680
it's an exciting topic I love your program and um I'm passionate about it as you can tell I know

42:40.680 --> 42:49.880
you are too so thanks for having me on absolutely thank you all right everyone that's our show for

42:49.880 --> 42:56.520
today for more information on Vince or any of the topics covered in this episode head over to

42:56.520 --> 43:06.120
twimmelai.com slash talk slash 154 to follow along with the pegaworld series visit twimmelai.com slash

43:06.120 --> 43:15.960
pegaworld 2018 for more information on pegassystems for their new pegat infinity offering visit pegat.com

43:15.960 --> 43:35.400
slash infinity as always thanks so much for listening and catch you next time

