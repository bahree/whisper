Hello and welcome to another episode of Twomo Talk, the podcast where I interview interesting
people, doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
As I mentioned last week, the reborn Twomo newsletter is live, be on the lookout for
it weekly and if you haven't signed up yet, head over to TwomoAI.com slash newsletter
to do so.
And if you've already received it, please do forward it along to a friend to let them
know about the podcast.
I want to send out a huge thanks to everyone who's checked out our O'Reilly AI New York
series.
We had a great time pulling this all together.
We're super excited to share it with you and glad that you've enjoyed it.
Keep on sending your thoughts, comments and feedback to us via the series page at TwomoAI.com slash
O'Reilly AI NY.
Make sure you enter our latest ticket giveaway to win a free ticket for the AI conference,
September 17 through 20 in San Francisco.
How you ask?
Simple.
Just let us know what you think about any of the podcasts in the O'Reilly AI New York
series or post your favorite quote from any of them on the series or show pages on Twitter
or via any of our other social media channels mentioning at TwomoAI, at Intel Nirvana and
the hashtag TwomoAISF so that we know you want to enter.
The contest ends on August 2nd and the winner will be announced on the next show.
Full details can be found on our website at twomoAI.com slash the AISF.
And now about today's show.
After a brief hiatus, the industrial AI series is making its triumphant return.
Our guest this week is Yodet Stanton, a self-described data nerd and the founder and CEO of OpenSensors.io.
Open sensors is a real-time data exchange for IoT, the Internet of Things, that enables
anyone to publish and subscribe to real-time open data in order to build higher order
smart systems and better understand the world around them.
Our discussion focuses on smart buildings and how they're enabled by IoT and machine
learning techniques.
Before we jump into the interview, a brief word from our sponsors.
You've heard me mention Bonsai before.
Bonsai offers an AI platform that lets enterprises build and deploy intelligent systems.
If you're trying to build AI-powered applications focused on optimizing and controlling the industrial
systems in your enterprise, you should take a look at what they're up to.
They've got a unique approach to building AI models that lets you use high-level code
to model the real-world concepts in your application, automatically generate train and evaluate
low-level models for your project using techniques like reinforcement learning, and easily integrate
those models into your applications and systems using APIs.
You can check them out at bonds.ai and definitely let them know.
You appreciate their support of the podcast.
I'm excited to announce a new sponsor this week, and that is wise.io and GE Digital.
Wise.io was among the very first companies I began following in what I called the machine-learning
platform space back in 2012 and 2013.
I've since interviewed co-founder Josh Bloom here on the show and many of you have been
in the company's subsequent acquisition by GE Digital.
At GE Digital, the Wise.io team is focused on creating technology and solutions to enable
advanced capabilities for the industrial internet of things, making infrastructure more intelligent
and advancing the industry's critical to the world we live in.
I want to give a hearty thanks and shout out to the team at Wise.io and GE Digital for
supporting my industrial AI research and this podcast series.
Of course, you can check them out at Wise.io.
All right, on to the show.
All right, everyone, I am on the line with Yodet Stanton. Yodet is a self-described data
nerd, founder and chief unicorn of OpenCensors.io.
Yodet, welcome to this week in machine-learning and AI.
Thank you, Sam.
I'm really excited to be here and thank you for inviting me.
I am super excited for this conversation.
Now, the listeners don't know, but we've known each other for a little bit having first met
in London and then I think the next time we saw each other was in Barcelona.
And so I've been following the progress of your company, OpenCensors, and I'm super excited
about what you're doing there.
And I think I'm particularly excited about having you on to share some of what folks need to know about
the intersection between machine-learning and AI and the Internet of Things.
So why don't we get started by having you tell folks a little bit about your background.
You have done a number of things in a variety of different industries and I think folks
will find that context interesting.
Okay, thank you.
So I've been, I guess, officially a programmer probably for about, gosh, for about 17 years now.
My background is computer science. I did a degree in computer science.
I also liked quite a lot of math.
So I ended up working in what was the only available kind of computer science plus math kind of industry,
which was in finance and investment banking.
And most of my early career were sitting on trading floors with either kind of equity traders
and algorithm traders and writing a lot of the exchange connectivity, supporting the exchanges,
and also some of the kind of massive machine learning for quant trading.
So that's really where my love of data came out of and was born.
And in weird ways, what I do now is actually very similar because if you think of IoT,
there's lots of small messages moving around really, really fast.
You're adding some level of intelligence to plus moving data, which on its own,
you know, one IoT data point isn't that interesting, but on aggregate, it's hugely interesting.
So I haven't moved that far even though, you know, when I describe it,
it seems like worlds apart, but technically it's not.
Wow.
Tell us a little bit about the company Open Sensors.
What are you up to there?
So Open Sensors has been a company that started as very much as a side project.
So we've been around for about three years, just maybe three and a half years.
The initial thing was I was working as a consultant and people probably about five, four or five years ago
will say, oh, I have all the streaming data.
We were working in the kind of the early days of Hadoop and kind of this big data world at the time.
And I saw more and more requests for help me do something on streaming data.
So initially it was just like experimenting with storm.
What would happen when you start kind of streaming a lot of data sets?
Okay.
Adding some kind of, you know, doing stuff on data flows and so forth.
At the same time, I also started thinking, well, a lot of this hardware is going to be deployed
and people are going to want to reuse a lot of this data.
So what would happen if I started publishing, you know, data from my environment?
I had a particular interest in air quality data because my daughter had asthma and I thought,
well, let's kind of look at the correlations between her attacks and air quality levels.
So that was, that was very much like not, it was not a job that I was trying to create.
It was just intellectual challenges.
I don't think I heard that part of the story.
Was it originally open sensors.org?
It was always.io.
It was just, we were just having so much fun.
And then over time, I could see, you know, IoT was going to be a thing.
And then obviously once, once we started, we started saying, hey, we're doing this at meetups and stuff
and then people started using it.
And then we got like some customers and thought, oh, I guess this is a company now.
So started hiring people.
There was no, there was no method to this madness.
So when you say people started using it, what exactly was it at the time and how has it evolved?
So it at the time was anyone can use it to publish data.
So we have real-time data exchange is the kind of the initial, the initial concept
where any community member can just make a project around something that they cared about.
Usually it was around air quality because I guess maybe I was in that world.
I eventually started becoming around water quality.
Nowadays, the sensors have got quite sophisticated, I have to say, the initial prototypes are now industrial.
And then what we started seeing was that a lot of our customers were coming from the building space.
The actual customers, the way that works is that they don't publish their data.
It's open, it's private, and they pay us some hosting charges.
And we started kind of going in and saying, well, why is this?
And we understood actually there's some fundamental problems in managing real estate.
And it also combines a lot of air quality data because people care about how good is this space.
And people spend a lot of time indoors.
So there's a lot of impact to productivity and health and so forth within inside the building.
And the interesting thing that's coming out is nowadays because we carry so much outside air quality data,
what some of the larger landlords are starting to think about is how do I understand the performance of my HVAC systems
by comparing the indoor air quality to the outdoor air quality and so forth.
Interesting.
So it's all very organic, but we try to follow the pains versus the IoT hype.
So who knows where this is all going to go.
And I remember I think the last time we spoke, you were doing a lot with agricultural data as well.
Yeah, I think so agriculture is that so we have a couple of customers that are an architect.
And again, I think the theme is that what people tend to do is they tend to combine multiple data sets.
So IoT is actually like the individual data sets are really not interesting like knowing a humidity of a soil.
Okay, it's one data point, but it's one.
I think this is this is late no random moment, but it's when you combine a lot of data that you get very interesting outputs.
So when you start combining like the water kind of humidity with with weather data with kind of water quality data and so forth,
you get some really, really, really interesting out.
But I'm still I still don't know.
I don't think we kind of defined what IoT data analytics looks like.
I think it's still, you know, kind of version one, both from our perspective and the industry perspective.
So yeah, it's work in progress.
Can you give us examples of the kinds of insights or the types of results that really characterize that observation for you that when you combine lots of different types of data that that's where the real value is.
Yeah, so I mean, so the industry that we're working mostly in is within within buildings.
So smart buildings is the general term. I don't really like that term, but anyway, let's kind of go with it.
And so for a lot of building owners, I mean, they spend so buildings are the second largest cost that they have for most kind of organizations, you know, your people,
people, cost is, I think JLL have her square foot. They say you spend generally $300 per square foot for people 30 for your rent and maybe three for utilities and so forth.
And a lot of people are saying, well, how much real estate do I actually need and how like what's my footprint?
What does it need today? And at the same time, how do I make it so that it's a nice place to work because you don't want to have, you don't want to pack too many people in a space because you it becomes really noisy.
And you know, the CO2 level go really high and so forth. So how do I create that balance between efficient use of space, but also kind of not necessarily hitting the productivity of people and just making it a crappy place to be.
And that's a really hard line. And that's when you need to measure obviously you need to know, you know, the noise levels, the light level CO2 levels high CO2 makes people sleepy.
But you also need to measure the footfall and the trends of both in order to actually kind of weave the best path and kind of think through what how much real estate you need.
It seems like it's a weird one, but it seems to be the thing that most people care about.
You said the footfall, what's that?
Footfall is basically the number of people coming in and out of the space, which parts of the space are busy versus under use.
Okay, it's really interesting to hear you describe all of that. You know, when I think of the times that I've worked in a real office, quote unquote, you know, I just come in and kind of do my work.
And you know, they were certainly times when, you know, I thought about the space like when it was too hot or too cold or when I had to walk really far to get to something.
But to think about all of the various factors that I was not even thinking of that go into my comfort and productivity in the space.
It's pretty astounding actually, you know, all the various variables that you just mentioned.
So I can certainly understand why someone would want to take an analytics approach to optimizing these various factors.
Yeah, and why do a lot of people have like legacy real estate as well?
Because they just kind of grow without much of a plan, but they most people actually only realize they don't like a space when they when something goes wrong.
Like the amount of work it takes to actually kind of efficiently allocate teams and so forth is is very interesting.
One of the things that I have learned in the context of the industrial AI research that I've been doing is, you know, when I initially went into that, you know, I was thinking, you know, manufacturing and robots and, you know, those kinds of things.
But this whole notion of managing and optimizing the physical plant is a huge opportunity for the application of machine learning in AI.
And that's everything from, you know, data centers as well as, you know, the smart buildings stuff that we're talking about here.
In addition to optimizing a building from the perspective of the comfort of its inhabitants, there are also pretty significant cost implications for managing all these systems for your customers.
Is that right?
Yes, for sure. And just like even in manufacturing and so forth, there are also a lot of assets that you have to, there's a lot of expensive assets, especially in high rises.
I mean, simple things like a lot of the high rises have these window cleaning equipment built into them.
So actually, like, again, it's kind of monitoring the use of this, monitoring like if it's windy, we shouldn't be using, you know, window cleaners remotely debugging it and so forth.
I mean, it's like the least sexy bit of IoT, but it's the most impactful, in my opinion, because you're not necessarily, you're kind of, my colleague Sean said, you know, you're putting, like, it's like putting a set of, you know, a thousand or a million set of eyes.
You could be monitoring it manually, but obviously that's, that's crazy. Why would you do that? That's what IoT is good for. It's good for counting.
It's good for kind of fairly dumb measurements, but at aggregate and at scale, that obviously kind of, you know, it's, it's a very different way to run stuff.
That most people are starting to just, I suppose, in the first card of getting their heads around what it means for various industries.
Super interesting. So, what have you learned about applying machine learning and AI to IoT in general and smart buildings in particular?
Maybe we can start by talking about what are some of the challenges in this use case area?
Well, I mean, I think what I'm learning, so just, I'm going to start this by, I don't know, did you see the recent Cisco, recently Cisco published maybe about two or three weeks ago, that 75% of IoT projects fail?
Did you see that?
Oh, I vaguely remember seeing the Twitter headline, but that's about it.
Right. So, the biggest challenge is actually, I mean, most of, I think data science generally is, is a kind of, you know, once you get data out, it's, you know,
you can get some, some people to analyze it and so forth. I think the biggest challenge is actually deployment management and operational management of networks.
What I mean by that is, once you have a significant amount of IoT devices in the wild, you, there is a significant network management problem that you're going to face, and most people don't know they need until they come across it.
You have usually fairly cheap sensors with some batteries, monitoring your battery status, when does stuff need to be changed?
When does the battery need to be changed? Where is all these assets? Like, where are they?
So, tagging, making sure that you know, the kind of, making the deployment easy is another thing.
So, there's a, I think before you even get like a shred of data, that's the biggest challenge is deployment and management, which has been a surprise to me, because I, I come from the data world, and I thought, well, you know, I get these streams.
Obviously, I'm going to get the streams and I'm going to do some really cool things.
So, yeah, it's been, it's been a very painful learning exercise, but it's one that I guess we're kind of grappling with.
So, most of the data stuff that I do these days is actually, how do I get the, how do I get the kind of deployment times down and how do I, meaningfully and intelligently, alert people when their kind of various sensors are down or when they lose signal and so forth?
So, the, this, the sensor challenges that you describe sound like, you know, very low level, low level things, you know, battery, network connectivity, things like that.
But it sounds like this task of management may also involve some machine learning. Is that the case?
So, the machine learning bit of kind of the network management or least kind of, it's more around the predictive maintenance of not just the assets that they monitor, but the sensors themselves.
So, what you don't want to do is say, hey, you know, sensor A in this corner of the world has run out of battery.
What you want to say is, like, the set of sensors in this corner of the world are likely to need updating, let's update them together.
And because we know the patterns, let's, let's kind of change all the batteries while we're there, because the human cost of sending engineers and a truck in various places, changing one battery at a time is, it's crazy, right?
And that's the kind of pattern pattern kind of finding that we're most concerned with at the moment.
Okay. So, there's a prediction problem as well as kind of a fleet management slash traveling salesman type of optimization problem involved here.
Exactly. Yeah. So, yeah, everyone talks about predictive maintenance of the stuff that they're monitoring.
But actually, there's a predictive maintenance of the sensors, which is quite meta, I guess.
And do you also do, you know, in the IT world, you might have, you know, some subset of systems that ultimately support some higher level service and one of the big applications of machine learning is to like correlate the, you know, various systems so that you can surface, you know, alerts and predictive.
Insights about the systems themselves, do you do a similar thing in IOT where you are trying to understand what sensors are required to, you know, support a system or an application and give visibility to it.
Yes. And this is, this is hard because we didn't actually set up to be a hardware company, but we are getting more and more into that world because most people come to us and say, oh, yeah, I want to do this thing.
It's quite, it's usually quite vague. They're the thing. And then they say, you know, what sensor should I use? And we're like, Jesus, like, this is not what we set up to do.
But it's just like a startup. But yeah, so, so, you know, we've now had to build about, I think we have about 30 relationships with various hardware vendors.
And we've really had to get down to the very low level kind of both in terms of testing because if the sensor itself doesn't work, we obviously kind of the software side looks bad.
So really we're kind of deeply tied into that world and, and, you know, visiting factories and how do you actually kind of test that stuff that's coming out of the factory lines is is correct.
And then it's just kind of the cycle going down lower and lower into the into that world, which has been actually super interesting.
You're visiting factories of the center. Yes. Manufacturer. Oh, wow. I thought you were talking about customer factories are initially really interesting.
Yes. So there's a whole because a lot of these deployments, a lot of these sensor deployments involve on average, I think we're seeing about five different sensors being deployed on particular kind of sites.
And they can range from the as a monitoring to football to environmental monitoring. And all of these sensors usually come from different places.
And so we have to do this whole kind of weird logistic management and the gateways come from a different place of, yeah, weirdly we're kind of going more and more into that world.
We now have like an embedded systems engineer on the team and he's basically dedicated to testing verifying a lot of the sensors.
And obviously the data quality is really, really important.
So somebody says, oh, I have a CO2 sensor. Can you confirm how you tested that because if you if the data quality is crap, no amount of analytics is going to help you. Right. Right.
Interesting. Interesting. So can you talk a little bit about the algorithmic implications of all this.
I'm still I have to say I'm still kind of grappling of what they've been. So so I think there's a lot of first principles that are still we're in such an early market that a lot of first principles are still to be to be figured out.
So people talk a lot about all this IOT standards and all this kind of stuff. And that's actually that's not a problem.
So matching kind of data sheets versus reality is a massive problem because you know, like I've done some crazy things like put humidity sensors in my as I'm running the shower to actually see to tech checking for data quality.
Some of our customers have put like 10 air quality sensors next to each other to try to see what the output is. Right.
Loading smoke on it. Just all sorts of crazy stuff because tests don't really exist for a lot of the stuff like standard tests.
So what I like to say is more kind of testing kits because in calibration chambers because again for like we process.
I think at the moment we process something like seven or eight million data points just from air quality a day right.
But they're like they're all different manufacturers have their own kind of obviously kind of the analog sensors.
So some are measuring like parts per billion versus parts of a million. So you can't really kind of correlate a manufacturer sensor that has that's measuring kind of parts per billion to million.
You just can't do that. So how do we like having kind of the data.
It's not a data quality problem, but some sort of data.
I don't know how one is a word I'm looking for, but you know, some sort of like matching.
I was just wondering if you were doing something like on the fly transformation or normalization of these different data values.
Is that part of the solution you're offering we're not at the moment, but we're trying to figure out so we talk to a lot of environmental scientists and saying like how how would this.
Well, how would you do a standard transformation between these different types of sensors from there isn't there isn't an answer yet.
I'm afraid to say I mean elevation matters as well like if a sensor is at ground level near near the kind of exhaustive a car should we say versus at the top of the building.
There are two different readings for the same spot right like so what we're trying to do is actually kind of include a lot of environmental scientists into these conversations who don't necessarily know anything about electronics.
Yeah, a lot of these kind of standard ways of doing these transformations don't exist.
That's been a consistent thing that I've been hearing in the conversations I've had with folks about trying to do things with AI in the industrial sphere and that is the importance of being able to incorporate subject matter expertise into the conversation into the way systems and algorithms are being developed.
Sounds like you're seeing much of the same. Yes, yes, we are. I think there is a industry policy that if we get enough data, we can just figure it out because we'll just throw some algorithm at it.
But there is fairly big nuances between the different types of yeah, the kind of how do we interpret this and how do we make this easy for other people to understand is a huge.
It's a huge not issue, but it is something that is not going to take one domain or a bunch of computer scientists to figure out.
I mean, we did a project about a year and a half ago where people deployed air quality sensors and then back gardens near Heathrow, which is a major airport in the UK.
And, you know, there was nothing kind of surprising about that data COT level, sorry, noise levels are high, the kind of the particulates are really, really high.
But people are asking us, you know, I have a kid, I live here, what is going to be the impact on my kids health? And I'm like, wow, I, this is way beyond my expertise.
I can tell you what the trends are, you know, and that's not, that's not particularly helpful, right?
So, I think generally IOT is going to need many, many domains. You have the electronics people that need to make, obviously kind of not just high quality sensors, but, you know, kind of make the variables the easy to understand or at least kind of kind of standardized the way these things are published.
And then you have the domain experts that need to kind of make the data itself easy to understand is not necessarily algorithmic issues, but what does this mean? Like, does this actually for air quality, for example, like, how does low levels of particular exposure impact mile?
And yes, it's super interesting, but very, very early.
On the topic of the various algorithms and the approach to machine learning generally, are there specific other specific approaches or algorithms or ideas that apply best to IOT types of data?
I don't think so. I mean, not that I've seen so far, I think.
I guess that was maybe a, you know, to general a question. I guess what I'm trying to get a sense of is, you know, what's the, what are the standard approaches that you're taking for doing some of the things that we've talked about, like, you know, correlation.
What degree does machine learning come into the play? Are you come into play? Are you, you know, doing, you know, fairly basic things? Are you doing things like neural networks? And then, you know, over time, where do you see things going?
I say it's pretty basic. So the approach we're taking is we try to do phase approach, because when you think about IOT at scale is actually very expensive. You need lots of sensors to, to do kind of the more advanced stuff.
So what we try to say is like, what is the thing that you need to know today with a minimal amount of data? And then how do we make it more and more sophisticated?
I mean, versus kind of, you know, because there isn't most customers, especially nowadays when they get started, they don't have like tons of data. They're just, they're starting with a few sensors.
The, actually the interesting, so there's two things that are kind of all, I'll hit on both, but remind me if I don't hit the second point.
One is you, you start with, obviously you always start with the exploratory side list, let's deploy some sensors and let's just see what the kind of the general patterns are.
And then let's kind of make it more and more sophisticated as you gather more data. And then let's, for space, especially for space design, it's a lot of the architects are saying, okay, once I have some, some data, I'm going to change the space.
You see what impact that brings to, to the way people are using the space. And a lot of the times it's actually kind of, it looks like AB testing nowadays with physical space, which is super interesting.
So, you know, you have what they say is pre-occupancies, what they call it is like, okay, let's just deploy some sensors before we've changed the space. And let's just understand, because previously architects would, especially would send a guy with like a clipboard to count or interview people, but what they said was actually a lot of the answers that they were getting were kind of either subjective or not incorrect, but you know, subjective.
And so, initially it's just like, let's just give you some data so you can actually think about the use of this space and how you allocate teams in a different way.
And then they, they redesign it and then they actually test against their, should we think kind of initial, initial kind of KPIs, like, you know, you know, and this is super new.
So, this is like, you know, for architects, this is, this is never been done. So, yeah, I think it's kind of, to me, I like a lot of this stuff is more looking like what people are doing with, with AB testing of websites and so forth.
So, I think the same kinds of ways of analyzing data apply.
The second thing is around obviously kind of finding faults. And again, people talk about predictive maintenance quite a bit, but, you know, kind of in some of the arguments, especially is, is, can we order stuff for you before you need to order it yourself.
So, order parts, I think there's one startup that I've seen that's, you know, you subscribe to their service and you get fertilizer, you know, kind of automatically based on kind of not just usage, but also kind of the soil conditions.
And that changes for the times of the year and so forth. So, that's kind of we will enable you to automate a lot of these processes by kind of understanding the patterns that came before.
It's a huge, again, I don't see it enough, but I think it's going to happen more and more, especially, especially at these kind of large industrial scales.
Interesting. Have you, in terms of the analytics, you mentioned in some of the early, I think it was early days of open sensors, you were using things like storm.
Can you talk a little bit about the technologies that you use?
Yeah, I think so we have, we've actually re-architected pretty massive way, especially in the last six months. So, we, I mean, like in the early days, a lot of the kind of the real time systems were things like storm, we had to build our own kind of MQTT brokers and so forth.
And now there's really sophisticated, you know, kind of middleware and so forth. So, we're kind of leveraging that. I guess we're, I hate the term again, but, you know, kind of going into this more kind of lightweights, serverless kind of architecture, where a lot of the kind of models are just lambdas based on, you know, they can learn.
We deploy very lightweight functions or models without necessarily kind of managing this really, really complex model. So that makes sense.
It does. So, the models themselves, what, what stack do you use for model development?
So, various, so I come from obviously the closure world, so I still write a lot of, a lot of kind of closure. Now the rest of the team are actually kind of kind of moving away from that.
So, I'm trying, it's fine, but I'm still the only one that's kind of more of the functional person. So, there is, there's a lot of work being done and especially in Python and the kind of scientific libraries in Python.
I've gone through my five stages of grief about that already.
You guys can't handle closure. Fine. Use this inferior programming language or paradigm for that matter.
It's not here, but I think I've had to, my role has definitely evolved to being the pointy-haired boss that's more like I had to give up the cool stuff that I would do.
But it's, I think the point I'm making is more that in terms of a lot of the work we did actually, especially for the early kind of alerting predictive maintenance and so forth, you don't need, I mean, you don't need really, really complicated algorithms.
And, and for mostly by think what I see with IoT especially is like the kind of upfront over-engineering of we'll do this really, really, really interesting stuff before they've got any data.
That's the kind of culture that we're trying to break is like let's solve the really easy problems first and one day we'll start using some crazy deep learning for, for something.
That's what people do. Right. Right. Interesting. So the, I guess I have a question about the specifics of doing any kind of machine learning in an environment that's primarily focused on time series data.
Are you applying machine learning on streaming data kind of as it's, you know, in-flight streaming data or are you primarily doing it after it's been landed in some data source or some, you know, some data structure.
Yeah, I guess that's the place to start the question.
Yeah, so I mean, you build, so you build your models on whatever historical data you have. So let's, let's kind of take specifically around, I don't know, like let's take a simple thing like, is a sensor going to break and that pattern is obviously kind of the models built on, you know, six months or a year's worth of data.
And then yes, because the alerts that you need for, especially the predictive maintenance side, the data sets are running through the models on real time and you're trying to kind of get alerts in real time.
There is a third, there's a kind of an interesting development that I'm seeing and, and how many, not that something we're doing, but some, some kind of other companies are, which is actually came like based on, based on space, based on certain characteristics and even might be some physical data that we have that somebody's counted or parking meters, for example, how many sensors do we actually need.
And that's very, I think that's very interesting to me. There's a company that we worked with about two years ago that took a lot of like historical parking data and from that, try to create a model around how many sensors to deploy.
And I think efficient kind of deployment is especially at scale is, is kind of another aspect. I'm not describing this properly.
So what I'm hearing is using models to actually this is something that came up in this industrial AI research that I mentioned.
There are actually a number of use cases where folks are using models to optimize resource placement.
So, you know, this can be everything from at the macro level, you know, things like where do we put, you know, fire hydrants and fire stations in a city?
And where do we put the roads to a semiconductor? How do we route the, you know, the various paths in the semiconductor?
And it sounds like in your world, these same techniques are being used to determine, you know, where and what the optimal placement is for sensors.
Yes, exactly. And how many, do we need 100% coverage, like do you need 100% coverage of parking sensors, for example, or can you get away with just enough data if you covered 60% of the base with parking sensors?
Because, again, once you're able to be more efficient, I mean, it's the cost of not just the kind of the hardware, but it's also the maintenance cost that people are really trying to optimize.
So, the idea being that if you, if you have less than full coverage of the parking sensors, then you can do like some kind of statistical model. And I'm assuming the parking sensors are used to drive the signs to tell you how many slots are left.
If you have 60% coverage, you can try to use some statistical model, as opposed to showing an exact number. Is that the main use case or are there others?
If you know, if you know the patterns of how people park generally, you can make some kind of best guess rooting software over kind of enough data.
So, so the kind of the question that especially as IOT mature is that we'll come up over and over again is how much data is is enough.
Because the tradeoff between kind of full deployment and like not enough data and not enough sensors is still a thing to be figured out.
One of the things that I've heard come up quite a bit in the context of IOT is folks starting to look at doing inference at the edge. So, you know, building your model centrally and then deploying them out on some edge device and doing inference closer to where decisions need to be made.
Is that something that comes up in your use case?
Yeah, for sure. So, most of the sensors that we deploy tend to be neural networks. So, they use, so the kind of the stack is a sensor talks to a gateway or multiple gateways and the gateway talks to something and internet.
Now, a lot of the times the gateways are, you know, fairly robust. They can run kind of a minimal computation and a lot of the deployments that we do, you have one gateway covering probably a whole building.
So, pushing more and more, especially as a lot of this, the kind of the work we do becomes starts to touch kind of critical infrastructure such as lighting, for example, what you don't want is a situation where, you know, your AWS kind of infrastructure has gone down and you can't turn on the lights or change the lights.
So, I think the edge, the edge is going to be more and more important, but again, there's, for my observation, at least, there doesn't seem to be a clear, a clear separation of concerns, like what lives where is still a thing to be figured out by the industry.
So, it sounds like for this particular use case, the pushing the machine learning to the edge, you're not quite there yet, but it's something where you can, you can see it coming down the line.
I can see it coming down the line, but yeah, not yet, because the gateways is still, I mean, it's still early days of a lot of these gateways, but it's only, it's only a matter of time before there.
The memory is going to be kind of much better and the kind of DevOps of the gateways is going to be against standard, because you need to be able to easily update them and remotely kind of orchestrate them.
And what I'm excited about is things like AWS Greengrass, for example, I think they bring this potential over the next few years, and I'm kind of playing around with it, but I haven't deployed in production yet.
And what's Greengrass for those that don't know, and why are you excited about it?
Oh, goodness, so I'm going to start AWS services now.
So, the Greengrass is advertising local compute, so lambda style compute at big gateway level.
Or, I mean, it says for devices, but, you know, kind of, you know, I wouldn't necessarily run it in a very small cheap dumb device, but if you have a gateway,
you can run lambda functions, and you can obviously do everything that most things that lambda functions can do.
So it's starting to push more and more compute down to the edge level, but it's not something that I've seen anyone at least run in production.
I think there's a lot of, there's a lot of excitement. There's a lot of kind of interest in it, but ask me this time next year.
Okay, okay. So the sensors that you've talked about thus far are, you know, I'd say simple sensors, although you've described in detail, their complexity and the challenges they create.
Are you doing anything with computer vision with photographic sensors?
Yeah, there's a couple of companies that we work with, there are partners of ours. One company is called ModCAM, so they have, so a lot of people are using them for for counting within retail contracts and within even kind of even the buildings context.
So I don't know much about the tech they use, but they're, they're vision sensors that are, but they're doing all the processing on the device level, which I think is super interesting.
So they're not sending back kind of video, but they're, they give you accounts, they give you some heat maps and so forth.
Oh, wow.
Yeah, I think it's, it's, it's one of the most kind of probably more exciting hardware companies that I've come across over the last few years.
So you're able to, you know, what, where your system may not be designed for ingesting video data, you're able to integrate, you know, this video sensor in because it's providing aggregate metrics to you that you can just suck right in.
So they have like a grid system, so they send you an array of data back, and that could be the counts in real time of people kind of as they move through these groups.
And that's, that's good enough for you to understand how many people are kind of the flows of people and so forth.
So I think, yeah, I mean, I think those kind of developments are really quite cool because, you know, as an industry, we don't, we haven't been constrained for a long time on the chip.
And how much processing we can do. So this is skill that not many people have, but I think it's developing.
Did you, when we spoke earlier, you mentioned that in your experience, generic machine learning doesn't really work in this use case.
Have you fully articulated kind of the thoughts behind that, or was there more that that you wanted to say there?
I guess, well, I mean, it wouldn't be fair to say generic machine learning wouldn't work.
Maybe I've been too harsh.
I'm rolling back now. I'm just going to, you can see me.
But it, well, you know, maybe we can start by saying when you, when you think that, or when you say that, what do you mean by generic machine learning and what do you mean by, you know, doesn't work or isn't ideal?
I guess, I guess what I mean is I'm pushing back probably being hugely contrary and against IOT is a data and data out problem kind of it really kind of.
Yeah, it's, it's an annoying vision that people have that they could just, they could just do something on streaming data.
And then I see advertisements for generic kind of IOT. Oh, we do IOT analytics and I think what does that even mean?
There is no such thing like so what I'd like to say, I think the industry is going to form around verticals or use cases and all of the machine learning knowledge we have can get applied.
And I think that's the most interesting. I mean, IOT is like saying we're like, it's like saying the web. It means nothing.
So, just like we have, you know, CRM systems, e-commerce systems and so forth, I think IOT will get those kind of blends of systems of that are kind of applicable to do one or two things really, really well.
And the intelligence layer will apply to the, to the thing that is, you know, kind of trying to do.
So, and that's, that's what I'd like to see more of is is, you know, kind of let's say, whether it's machine learning or not, the kind of what we need for a wearable type, you know, device is very different to industrial IOT, to buildings, to, you know, everything else to consume our goods and all that kind of stuff.
So, you know, I think they're still a long way to go and define in this and what are the variables that are necessary to that kind of put the end outcomes first and then designs the algorithms, if that makes sense.
That makes a ton of sense. What I hear you saying really resonate strongly with with something that I tell people and that is start with the business problem first start with the problem that you're trying to solve and if you don't know that figure that out, but once you do start there.
And also earlier, you made another point that I tend to tell people and that is, you know, do the simplest thing that solves your business problem and, you know, don't get too caught up in trying to be too fancy.
Yes, yeah. And it's the temptation, if you're very technical, especially today is to go for it be kind of, I'm going to build the coolest thing in the world and so forth. And that is, yeah, that is, especially in IOT, he doesn't work because you, you don't have, it's not just like software or you have this luxury of being able to do kind of quick iterations once you've deployed something, you're kind of stuck with it.
So being very conservative where you start is trust me is going to save you a lot of heartache and money.
Any other advice you'd give to someone who is trying to get smarter about their physical facilities, whether, you know, be smart buildings or data centers or, you know, any of the other things that you work with.
Gosh, that is, I think, well, I'm not going to advertise my services, but I'm going to say that.
But I think it's, I'm going to give the same advice that I give most people that I've got to start a variety.
Get something like five centers in a lab environment working before, before you kind of scale up, get it working, get it kind of, get it solving something, even if it's just, it's just kind of go outside of the building and outside of the kind of theoretical world as it were.
Because I see a lot of ambition in the industry, I see a lot of, we want to run before we can kind of give them crawl stage, I think, where people are possibly kind of specking out quite cool stuff because they want to be part of this future or whatever.
But the reality is that when you started that place, you kind of forget about the first principles, you forget about the first principles of security and security doesn't have to be anything basic security and so forth.
So I would say just to start small usually on everything on both the IoT side and on the data side, it's the least glamorous kind of advice, but it's really true for this case.
What I'm hearing there is keeping it real.
And there's definitely, well, you're at, you're at the nexus of two over hype spaces.
So it probably serves you very well to try to keep it real to, you know, as much as possible.
Yeah, I think a lot of people are disappointed because I don't kind of, I'm like the most cynical person probably in the industry now all these years.
That's awesome. Well, I have really enjoyed this conversation and learned a lot about the intersection between between IoT and machine learning and how that's all applied to smart sensors and smart buildings, anything else you'd like to leave our audience with.
I think I've talked it up, but I really appreciate them. If they've listened this far, I really appreciate it. Thank you very much.
Well, if they've listened this far and still have questions, how can they find you?
You can find me. I'm at your stand on Twitter or at open sensors, we are at open sensors IO so far away.
I would like to see more people engaged in this industry and they're kind of getting their hands dirty away versus the kind of the marketing way.
So always, always happy to help on questions and getting people started and resources and so forth.
Awesome. Awesome. Well, thanks so much, you did. I really appreciate it. And thank you.
Thank you so much.
All right, everyone. That's our show for today. Thanks so much for listening and for your continued support.
Let us know how you like this show by leaving your comment on the show notes page at twonlai.com slash talk slash 36.
That's also where you'll find the notes for this episode. For more information on industrial AI, my report on the topic or the industrial AI podcast series, visit twonlai.com slash industrial AI.
The report is complete and it's beautiful. And I'll be notifying folks who sign up at that page, how they can receive a copy of it shortly.
Once you're done with this show, if you haven't already, head over to twonlai.com slash O'Reilly AI and why to check out our series from the last O'Reilly AI conference in New York City.
Make sure you leave a comment there or mention at twonlai at Intel Nirvana and the hashtag twonlai.sf on Twitter to enter our giveaway for a free ticket to the San Francisco AI conference.
Thanks again for listening and catch you next time.
