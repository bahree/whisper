All right, everyone. I am here with your Donnus,
Katanidis. Your Donnus is research director at CNRS in Paris.
That's the National Center for Scientific Research,
as well as the head of quantum algorithms with QCWARE.
Your Donnus, welcome to the Twelma AI podcast.
Thanks for having me. I'm looking forward to this talk.
It's been a while about a year, a little over a year,
since we talked about quantum machine learning on the show here.
And I imagine that the field has advanced quite a bit.
So I'm looking forward to an update as well as your take.
You recently delivered a main conference keynote at ICML on the top.
So can we say that quantum machine learning is going big time now or blowing up?
I always say that quantum machine learning is the most overhyped
and underestimated area of quantum computing.
And it can be both in superposition, right?
So I think we have many exciting new results.
This is true. And to me, it was very important to give this talk at ICML,
because I really believe in the fact that we need to work together
the quantum and the classical ML community,
because you have the problems.
You know what are the bottlenecks on the computational side?
You've been looking at these problems and the specifics for many years.
We are coming from quantum algorithms.
We understand what quantum computing can offer.
And if we put these things together, I think we can do great things together.
So tell us a little bit about your background.
How did you come to work on quantum machine learning?
So I started working on quantum algorithms more general 20 years ago.
So I started my PhD in 2000 in Berkeley.
So I was in California for a few years.
And there I worked on different things, mostly quantum algorithms for communication
networks, and for cryptography, and some quantum algorithms, not so much on machine learning.
And the only machine learning I did was a classical result on
classical recommendation systems through an interest you that I did with
Pravagkar Lagavan at some point in the beginning of 2000.
And after that, I went to MIT.
I worked with Peter Schor for a couple of years.
And then I moved to Paris in 2006 as a research director for CNRS.
Okay. And so you've been working on quantum algorithms for 20 years.
How long is quantum algorithms even been a thing?
Not much more than that.
21 years.
So I think the first breakthrough result that people
cite on quantum algorithms is Peter Schor's algorithm for factoring large numbers.
And this was in 93, so it's like 27 years ago.
And this was kind of the result that made people very interested in looking at this new model of
computation and try to figure out what does it have to offer when we look at trying to
compute and code information using quantum mechanics and not classical physics.
So to me, it's a very exciting thing because it kind of tries to understand in some sense also
what are the computational limits of nature, because nature is a quantum mechanical system.
So this is what we try to understand.
And maybe it's important to say in the beginning that quantum computing is not
a faster processor, right? So it is not that everything that you run nowadays on a classical
computer, you can just put it on a quantum computer and it will run faster.
This is really not how it works.
It's a completely different paradigm.
It's a different way of computing.
And we need to design new algorithms and different algorithms in order to harness the power of
quantum mechanics. And we can do it for certain tasks and we can provide algorithms that run
much faster, even exponentially faster sometimes compared to classical computers.
But this is not always the case.
For many tasks, a classical computer will be as good as a quantum computer.
So we need to figure out exactly for what applications a quantum computer can offer
something more, whether it is about speed up, speed or speed or performance.
And to do that, we need to look at the algorithms and design algorithms.
In what ways has the way that we think about the computing itself,
a quantum computing change over these 27, you know, both years?
As it just been advancing, you know, getting more qubits or has the fundamental architecture
or approaches of quantum computing change?
Yeah. So I guess in the beginning, there were two quite disjoint communities that were working
on quantum information. I come from the theoretical computer science part.
And there, quantum computing was something which it was completely theoretical.
It was part of like the theoretical computer science groups as in Berkeley or in other places.
And it was just a model of computation that we were trying to understand what we can do with it.
It was something completely mathematical and abstract.
We had no idea if it would ever, you know, realize exactly.
But in some sense, we were almost mathematicians so we didn't care about these things, right?
It was a great thing to do math and we were proving theorems, right?
At the same time, physicists were trying to actually implement and figure out ways to control
these very, very small quantum systems that could be one electron or one photon or one atom, right?
And in order to be able to control these type of systems, you need the very, very precise ways
of doing it. So, and physicists in the beginning were doing this because they wanted to study physics,
right? And understand the laws of physics. And little by little, you know, the two communities
started coming together because on our side, we were saying, look, if we had the quantum
computer, there are all these amazing things that you can do. And I think the physicists realized
that maybe there is more to do than study physics. And they started getting into doing circuits
and gates and cubits. And and little by little, we started seeing the first very small quantum
machines. We are quite far still from having a universal fault tolerant quantum computer.
But we have seen many strides when it comes to the hardware development.
We've seen Google's announcement a few months ago about the supremacy experiment.
Many other technologies are, you know, they are not only for superconducting cubits,
but with trapped ions and other technologies. And we also, I think, have many advances when
it comes to thinking algorithmically about this model of computing. There will be many new algorithms.
And quantum machine learning is something that started quite later. So, I think that the result
that kind of initiated this, the subfield was the quantum algorithm for solving linear systems.
And that was sometime in 2009. So, I could say that quantum machine learning started maybe very,
you know, sporadically from 2009. And then we had kind of the first end-to-end application or
quantum recommendation system in a theoretical paper sometime in 2016. So, between five and ten
years of quantum machine learning. And it was at the quantum recommendation algorithm that
that Ewan Tang did that research about. We did a show with Ewan just about a year ago April
of last year. Some of that research. Yeah. So, yes, it was exactly this quantum recommendation
system. It's a very interesting story, the sense that, you know, I was getting to know this new
quantum techniques that had to do with linear algebra. And because I had worked on classical
recommendation systems back in 2001, I kind of figured out that maybe this is the right problem
to actually look into and try to find the quantum algorithm. So, we started working with
Michael Thor and Pamprakash. And we came up with this quantum application. And in the beginning,
we, you know, we benchmarked our result compared to the best classical results that existed out
there. And we could say that there was an exponential gap between our quantum algorithm and the
classical algorithm. And then probably Ewan, you know, said more about this, she started working
on this problem in the beginning in order to prove that classical algorithm is cannot do better
than the ones we already had. But little by little, she realized that maybe there are some different
techniques inspired by our quantum algorithm that could give you a new classical algorithm,
right? And this is what happened. She came up with a very nice classical result that showed that
at least in theory that the gap, the speed, the speed up that we can expect between the quantum
and the classical algorithm is not any more exponential, but it's polynomial. And of course,
the polynomial in the absolute is less than an exponential gap. But somehow this is not the end
of the story in the sense that this polynomial is actually a very, very large polynomial,
meaning that if you look at instances where you would want to do recommendation systems,
like looking at Amazon or Netflix or, you know, online purchase systems like that,
then actually this polynomial gap is even bigger than the one we had before, which was an exponential
one. But somehow, from a theoretical point of view, it says that the gap that we have cannot be
exponential is only polynomial. But from a practical point of view, it's to be more interesting
when it comes to machine learning because we really need to solve real problems. The gap is even
bigger than it was before. So, so we still have to see how to take this gap and actually
implemented in a quantum computer that we don't have yet. And there will be, you know, slowdowns
because the clock speed of a quantum computer is not as fast as a classical computer and things
like that. But we still have a very decent theoretical gap of something like a million or a
billion times faster, right? And hopefully out of this billion times faster, we can keep something
that makes sense. Even if you say it's a thousand times faster in practice, this would be a really,
really great thing to do. Also speaks to the idea that even if we don't ever get quantum computers
that can run these algorithms, perhaps we learn, you know, from the approaches we're developing
and exploring quantum algorithms and kind of bring some of what we learn back to classical algorithms.
This is absolutely true. And this was a great example on the work of you and on the
recommendation systems. In machine learning, there are more examples like that. For example,
when it comes to neural networks, which is something that we know that it works very well,
but we don't necessarily understand why and why this one doesn't, the other one doesn't somehow.
Like we've been trying to figure out what is the right architectures for defining some quantum
neural networks. And the difference there, for example, I have to do with things that it's not
easy to apply an own linearity because it quantum is a reversible and linear evolution.
So then you have these extra constraints that make you think of different ways of defining
neural networks. And this can also go back to classical neural networks and define new ways
of doing classical neural networks that could use the intuition of the quantum to provide
classical neural networks that can be more accurate or more efficient. So there is a lot of
back and forth between classical and quantum information. And this is why we need to work more
closely with the classical ML community as well. Maybe we can take a step back and have you
ground us on quantum computing and what are the fundamental ideas there? I'll be honest,
I've heard it numerous times. It's still difficult to wrap my head around, supervisition and
similar concepts. And so maybe you can start by talking about what you think are the key ideas
for folks that are coming from classical approaches. So yeah, it's not an easy task to do to explain
quantum in a live, but I will do my best. I guess the first comment is to say that one does not need
to really understand quantum mechanics and all the postulates of physics and quantum mechanics
in order to start playing around with quantum algorithms and quantum information.
So for us, it's mostly a mathematical model that we need to understand, which is a little
different than the one that we use for classical computing. And once you have this mathematical
model in place, then in some sense the physics part stops and then the algorithmic and the
computer science part starts. So the main difference between classical and quantum computing,
people probably have heard this many times, is that the carrier of information is not a bit,
which is a zero or a one, but it's a quantum bit, which can be a zero and one at the same time.
It's not very different than saying that I have a random bit, that sometimes it's zero,
sometimes it's one. So you can define the space of this random bit with two probabilities,
the probability of getting zero and the probability of getting one. So you can associate in a random
bit a two-dimensional vector. It's the same thing that quantum, you can associate in a quantum bit
a two-dimensional vector, but now this vector doesn't have positive probabilities that sum up to one.
It has complex numbers whose squares sum up to one. In other words, if you have a quantum
system, you can think of a quantum system as a vector in some very high-dimensional
Euclidean space. The same way that if you have a random variable, which is more than one bit,
you can think of a distribution, which is in an exponential space and you have positive
probabilities that sum up to one. Here, the quantum system is defined by, again, an exponential
size vector with positive or negative numbers, actually even complex numbers whose squares sum up
to one. So this is the basic difference, right, of how do you encode information and what is the
carrier of information in quantum? And once you have this, then you want to understand how can
they evolve the system? So I have a quantum system. What kind of operations can they apply to
this quantum system to evolve it? And it's very simple in some sense because you want to evolve
a quantum system in a way that the quantum system remains a quantum system. So since the quantum
system was this vector in Hilbert space with some fixed norm, let's say norm one, then the only
kind of operations that you can apply to it is some unitary operation because this is the
operation that keeps the norm of the vector the same, right? The same way that we're saying,
if I have a probability distribution, how can I evolve it? I can apply a stochastic matrix
because it keeps probability distribution, it will give you probability distribution.
Here you have a quantum state, you apply a unitary matrix, you're going to get a different quantum
state, that's still a quantum state, right? So this is easily the way of applying operations on
quantum systems. The quantum system is a vector, you apply a unitary matrix, you get a different vector,
right? And the second thing, and this is also very important that you can do to this quantum
system is that you can try to observe it, right? But kind of what we know from the postulate
of quantum mechanics is that when you observe something, this is not just the passive observation
that doesn't change anything, but the moment you try to observe the system, the state of the
system changes itself, right? So the quantum measurement just specifies what will be the outcomes
that you're going to get, the possible outcomes that you're going to get out of this observation,
and with what probability each outcome will come up, right? So when you measure something,
then you'll have a distribution over possible classical outcomes that come from this quantum
state that you had before. So I know it's a mouthful, but basically if we understand this,
this the notion of a tube bit, and the fact that I can apply a unitary operation to it,
or I can measure it and observe some classical information out of it, then we basically have
the basics that we need in order to start talking about quantum algorithms.
And maybe the one simple quantum procedure that I can discuss and it's quite interesting for
machine learning is the one that has to do with estimating the distance between quantum states,
right? So you can think of two quantum states as encodings of two data points, right? And one
of the things that we need to do many times in machine learning is figure out the similarity
between these two points, right? So you want to estimate something like the inner product
between these two points. As long as these data points are now encoded into this quantum state,
it's fairly efficient to compute the distance or the inner product between these data points.
And this is one of the things that we use in order to do, for example, classification or
clustering based on similarity learning. I can talk maybe about one more, a little more elaborate
thing that we can do without getting into many of the details, which is linear algebra procedures.
And again, I'm talking about this because machine learning is a lot of, you know, linear algebra,
whether you want to train neural networks, but also when you want to do more traditional machine
learning like principal component analysis or support vector machines, they're always these
matrices that you have to handle. You need to figure out, you know, top eigen spaces,
eigenvectors and things like that. So quantum is particularly powerful in performing this type
of computations that have to do with eigenvalues and eigenvectors in a more efficient way.
These tools are very powerful, but they're also very subtle. And this is where a lot of the hype
comes also when it comes to quantum machine learning. These procedures are not always faster,
but they can be faster if we really pay attention and we apply them to the right
applications and do the right use cases. And when we do that, this is how we can get very fast
to accommodation systems faster both than the classical or the quantumly inspired classical
still but much faster when we applied to things like spectral clustering or expectation
maximization, things where this linear algebra part is really the bottleneck of the computation.
So you alluded to this earlier and I think it's really coming out in this conversation around the
algorithms, the speed up that we're talking about here doesn't come from just running it on
a super fast hardware that actually doesn't really exist. It's because there's something fundamental
about the way we can work with qubits that we can't do bits. And I'm thinking of it as a non-linearity
that's probably not the right way to think about it, but you can do the different things.
Can you help us get to the essence of what these different things are that we can do that make
better? Sure. I will do my best. Again, you know, quantum mechanics is not the easiest thing
to get into issue about and there are many things that we don't really understand.
But I think the main idea of why you would expect a quantum algorithm to be faster, for example,
than a classical algorithm, is because we can utilize this notion of superposition. When I talk
about superposition, it means that for example, imagine you want to estimate the distance between
one point and many different points. It could be the centroids that you have calculated from
different classes or some other data points. What we can do is things like, instead of estimating
the distance of the point with each one of the data points one after the other, so we have to
spend a lot of time if the number of these points is great, right? We can kind of go into a super
position of the data points and kind of start estimating fast things that have to do with the
average distance or things like that. So I would maybe say that it's some sort of parallelism
that is happening at some point, but we should not think of it as a parallel computer either.
So it's not a nonlinear computer and it's not a parallel computer.
And it's certainly not just a faster processor, right? So I usually get this question,
shouldn't be just simpler if we just get a compiler that will take my classical algorithm,
make it into a quantum algorithm and then I don't have to learn anything new and I will be done.
It's not that easy. It's not that easy because you really have to understand mentally. It's just not
that easy. It's fundamentally different. You can use this parallelism, the super position.
At the same time, as we said, every time you try to extract information out of these things,
you end up destroying your states and you get only a small part of the information. So there's
this interplay between using this big Hilbert space to encode information, but figuring out very
clever ways of extracting the information that you need and not care about the rest.
So I guess this is the best way I could explain it in a couple of minutes.
What I'm hearing is something, the picture that's forming, that's probably inaccurate, is
something along the lines of classical computing. We do a lot of iterative types of computation
and there is an element of these properties of quantum super position and observation that
allows us to look at a quantum data structure and get a lot of what we might otherwise have to
iterate in classical computing. Is there any of that that is true?
Yes, I know. No, no, it's true that I think a different way of looking at it could be that
what the quantum computer enables you to do is kind of search many different computational paths
at the same time, but this is not enough because then if you just say, let me search all of them in
super position and then let me measure, then what you get is just a random path, which you could
have done it also by a randomized classical algorithm, right? So what you need to do is first of all
go into a super position of these paths, but then figure out clever ways of just
getting rid of the paths that you don't like so that at the end, only the good paths that you
that will lead to a solution remain as possibilities of the quantum algorithm.
So there is this inherent stochasticity in quantum, which is also in randomized algorithm.
The next thing is that because as I said, we don't deal only with probabilities, but also with
this positive, negative, complex amplitudes, there is a lot of interference between these paths,
and if you are clever enough, you will interfere the back paths and you will make them disappear,
and you will only get good paths that lead to solutions at the end of your algorithm.
Okay. And so you've got these kind of principles like being able to do distances and linear algebra,
how does that get us to quantum machine learning algorithms and kind of what's
different, you know, state and landscape of quantum ML? Yeah, it's a very nice question.
So I can start maybe from the simplest thing, so we can start with supervised learning and,
you know, the first thing that one might want to do would be some sort of classification, right? So
again, there are two different ways of, okay, there are many different ways of trying to do
classification. One of them is based on similarity learning, right? So you somehow map your data
points into some points in space, and then you try to figure out which points are close to each
other so that you can give them one label and which other points are far and close so you can
give them a different label, right? So this is things that kind of everyone knows in classical
machine learning, we are, you know, getting to understand more and more what's happening.
And again, there one thing, the simplest thing you can do is to say that, okay, every time you want
to estimate the distance, why don't you use a quantum computer to estimate the distance, right?
But you can go a little bit more in the more quantum versions of these things, where you say,
okay, but maybe not only do I want to estimate each distance separately, but imagine that I
want to, I have a point, I have a bunch of different centroids, I want to soft classify my point,
depending on which centroid is closer to me, right? So different things you can do is not do it one
by one sequentially, but again, go to the superposition of the centroid, and this will allow you to sample
the right centroid with the correct probabilities, for example. So these are kind of the things that
you can do in the simplest problems, like you already have your point and you want to classify them
in the space that you are, right? If you want to go to a next level, we can say that many times
before being able to classify your points, you need to pre-process your data and map them from
one space to a different space, for example, through some dimensionality reduction techniques. We can
think of principle component analysis or feature analysis, linear discriminant and all this type of
very powerful classical techniques. And the reason they are very powerful is also because they
are computationally hard to do, right? Because you need to figure out the eigenvectors and the
eigenvalues of your of your data matrices. And there we can use more powerful and elaborate
quantum procedures that have to do with inverted matrices, finding eigenvectors. So this mapping
from a higher dimensional space of your data points to a smaller dimensional space where you
believe that the classification will be good. For example, by looking at your top eigenspace,
then this mapping can also be done in a quantum way. And this is usually most of the times the
bottleneck of the classification, how to find the right space to put your points.
We can also try to define quantum deep learning and quantum neural networks.
Before we go. So you started talking about quantum with quantum supervised learning.
You know, we've you've got this the way you described it was used quantum computing for
the distance part of that task as opposed to the entire task. Is that typical of a quantum
approach that you kind of cherry pick a particular part that's hard classically and apply
quantum to it as opposed to end and quantum. Both both cases are possible, right? For example,
if you have an algorithm like I give you a number and you need to factor the number into two prime
factors, then the entire algorithm is equal to algorithm. And because the entire algorithm is
a quantum algorithm, this is why we need like millions and millions of tubes to actually implement
this algorithm, right? There are more hybrid algorithms where there is a classical outer algorithm
and then at the specific points, one can do a specific part of the computation on on a quantum
computer, get back a result and continue with the classical program, the classical algorithm,
right? For example, you already get ready to say that when I was discussing about something like
near a central classification, many parts will still happen classically because quantum cannot
offer something to that, right? Figuring out the centroids of a labeled set of data, it's pretty
simple, it's never the bottleneck classically, so let's do it classically, right? Then at some
points, when you have to find distances or you have to start projecting data points to different
spaces, then for the specific task, we can use a quantum computer and then we can, you know,
continue within our classical algorithm. So for the way we do it, that you see where, for example,
when we say we have a quantum nearest centroid algorithm, what it looks to someone who wants to
use it is basically the same that using psychic learn to do classical nearest centroids,
there is a Python environment, you have a notebook and you run it, so this is exactly what
the quantum thing feels like, you just say instead of run your classical nearest centroid and
fit your data and predict it, you say fit and predict your data with the quantum nearest
centroid. And what happens at the back is that there is a classical program that at some point
says send this data to your quantum computer, measure your quantum computer, get some classical
data out and continue with your classical computation. Another question that this raises for me is,
I think of, you know, when you've got these quantum algorithms operating in the
context of classical approaches and classic problems and kind of regular data,
I guess there was a part of the way I was thinking about this that wanted the classical algorithms
to be operating on classical data, like really complex data with these, you know, weird states
and, you know, crazy tensions and things like that. You know, what's the relationship between
the data and the quantum algorithms and do you have to do something to data to make it
operable in a quantum environment? It doesn't have to be more complex.
It's a very good question. You're really pinpointing on one of the very important
subtle points for quantum machine learning. And this is what do we do with classical data
and how do we load classical data into a quantum format, which is the one that we need in order
to run our quantum algorithms, right? So let me try to explain a little bit what this is.
So you have some classical data, you have some classical description of a point in some
end-dimensional space, right? What we would need in order to apply some fast, for example,
quantum linear algebra techniques or estimating the distances and things like that,
we need some quantum state that in some sense encodes this classical data point into this quantum
state, okay? And this is not a priori trivial thing to do. We are asking to create a quantum state
out of a classical description of classical data. So there are many different ways of approaching
this task. One is to say that we will need to develop some special type hardware,
like your classical RAM that you have on your computer, that you can say, okay, just load the
data that exists in position 35, then your RAM goes to position 35 and brings back this data.
You don't have, you know, as it used to be with tapes and this starts from the beginning and,
go all the way to the point that you want. So you have this fast access to the data, right?
What we would need for a quantum computer is also to have some sort of fast quantum access
to this data, right? So there were a few proposals that had to do with some kind of more exotic
technological things to do it on hardware, right? What we try to do with QCware and I've been working
on this for quite some time now is to figure out can we efficiently load classical data with
current quantum technology? Like I don't want to use anything that doesn't exist. I want to use
machines that Google or IBM is coming up with, right? And can I use these types of machines to load
classical data on quantum states? And what we found is kind of the optimal ways of doing it.
So the optimal way says that the circuit that you need in order to load a data point that has
and features must have size n otherwise you're missing your data, right? But you can have it
in a very, very shallow way. So the depth of the circuit that kind of corresponds to the time
that it will take for the quantum circuit to actually apply this operation is only logarithmic
on the dimension of the data. Which means that I need these two bits which have optimal size
and I can make them very, very shallow, which means very, very fast. Okay? And this is one of the
ways, one of the bottlenecks that we managed to get over with. And this is why if someone told me
maybe three years ago how far is real quantum machine learning applications? I would have predicted
something which would have been further down the road than I could say now.
It sounds like the the process of applying quantum algorithms then if it assumes that you are
accessing quantum data and that quantum data was originally real world data points say some
time series data points or something. Does the process of using quantum algorithms inject some
noise, you know, noise in a sense of, you know, these kind of, you know, static data points are
projected into some probabilistic quantum space. And, you know, is that a disadvantage that
quantum has to overcome in order to be useful on? I don't know, what is not, is there a set of,
I guess you could apply quantum to physics problems and you've got this inherently quantum
source, but for everything else. Yeah, very good question. So we will have to deal with noise
in the quantum setting. And we do have to deal with noise first because the computers that we have
now that we will have in a few years will be noisy, meaning that when I have a qubit and I tell my
qubit just go to the state, the qubit doesn't really go to this state but to a state close to the state.
And this is because it's extremely difficult to really control quantum systems at that level
of precision. So there will be noise and this is why we call the error that we are now and we
will be in the next few years, the NISC error for noise intermediate scale quantum machines.
And now it's so fresky who coined the term, it wasn't me. So
and the question is, is this noise going to kill the quantum machine learning applications or not?
Right. I'm quite optimistic and I will tell you why I'm quite optimistic because
the data that we have even for classical machine learning are already very noisy.
Right. The whole point of machine learning is try to extract the signals out of very noisy data.
Right. So if I tell you that you have a bunch of data and then I perturb a little bit the data
all of them. Right. If I have you know cats here and dogs there and I perturb all the cats and the dogs
you expect your machine learning algorithm to still be able to discern the cat from a dog.
Right. Because already the data that you learned on, for example, were very noisy and very
fuzzy images of cats and dogs. Right. So somehow there is already noise on the data.
Okay. So for the quantum case, there will be noise on the data in the sense that if you give me a quantum
a classical data point, the quantum state that I will construct will be close to the correct point,
but not exactly. And then quantum will add even more noise when I try to estimate, for example,
the inner product or the distance between two points, that computation will also have a little bit
of noise there. But again, this is something that we even do in classical machine learning.
For example, when we are training neural networks, many times we inject artificial noise
on the computation because we want a neural network to be robust. Right. We wanted to be robust.
We want to to be robust against both adversarial adversaries, but also as a way to increase the
privacy of the data. So this is also something very interesting that I'm quite interested recently,
is that one, the main way maybe to deal with privacy in machine learning is again to make your
data a little bit more noisy or the computation a little bit more noisy. In the sense that
it's enough noise to hide specifics of the data. Right. But still you can extract the useful
information that you need in order to solve your problem. So somehow this is how the quantum
thing will do, not because you want it to do it, but because it will do it by itself. Right. So
privacy or something like that. Yes, it's inherently private.
And so is the idea of understanding the way that noise
is injected from kind of classical round to quantum round. Is this
kind of a pedestrian thing that is assumed and no one cares about? Or is this like a research
topic that people are working towards an information theory of quantum or something like that?
Yeah. No, it's very important. It's very important. For example, I will just give you a small
example. Right. And we were, we started working on unsupervised learning and we started from,
you know, clustering 101. So we wanted to find a quantum analog of k-means.
Right. And we figured out what the algorithm should look like. But as I said, every time we will
be doing a quantum procedure, we were adding noise to the computation. Right. So what we had to do
is to go back to the classical algorithm and say, okay, even classically, if I start adding noise
now and we know what type of noise we were adding, would the clustering still be good or not?
Right. What we did is that we did extensive simulations on real data sets like M-list and
Iris and many different, you know, canonical. Let's call them data set where people actually
not for clustering. There were more, you know, synthetic data in other runs. But we looked at what
happens when your classical k-means algorithm has noise in it. Right. We defined a new
classical clustering algorithm. And what we found out is that, obviously, as long as your noise is
not enormous where everything becomes noise. Right. Your clustering doesn't lose anything from
from the accuracy for decent amounts of noise. Right. Even for decent amount of noise,
you still have very good clustering. Okay. Of course, you can find data that will destroy your
algorithm. Right. But when you test it on the data that you expect to run your clustering algorithm
on, you can handle a lot of noise. And this is what also enabled us. And this is some results that
we published last year at Newribs to figure out both what we expect from the quantum algorithm to
give as accuracy. And also how much faster it will actually be because the runtime of the quantum
algorithm depends on how precise or how noisy you can, you want your computation. Right. The more
precise you need the computation the more time you have to spend. But the fact that even having
quite big noise, the accuracy did not suffer. We could say that the running time of the quantum
algorithm when you have a bigger computer would be much faster than the classical k-means algorithm.
And so with those results that were only accessible to you via simulation in comparison or is there
some theoretical framework that says under set of conditions, we know that the noise will be decent
in converting this over to quantum. Yeah. So yeah, I come from a computer science background.
So obviously we have to prove the theorems. Right. And we proved exactly the trade-off between
how much error you can have in the computation. How much running time, how long you have to run.
And then by simulations, we figured out the errors that you can handle and still have good
accuracy. And for that error, we went back and we said, okay, so what is the running time
and how fast will the algorithm be? And this we took from asymptotic theoretical analysis of how
the k-means algorithm, the quantum k-means algorithm works. Okay. Yeah. Cool. So you're about to
speak about quantum neural networks. Yes, quantum neural networks is a very intriguing to me
because we are in a very bizarre situation. And I think maybe in classical machine learning,
people were in a similar situation maybe 20 or 30 years ago where we kind of think we have ideas
on what the architectures of quantum neural networks should be, right, to do things like classification.
But we only have like 10 or 20 qubits to try things out and see how they work.
So it's the same as telling you propose to me a neural network that you think can classify
well, but you cannot simulate it. So then you're kind of stuck because you cannot prove many things
for neural networks. The main thing that you do is that you run it and you see that it works.
And if it doesn't work, then you see how to tweak it to make it work, right? So for us, it's very
difficult because we don't have the ability to actually simulate this quantum neural networks
because every time you try to simulate it on a classical computer, there is this exponential
blow-up on the time. So if I have a neural network of 100 qubits, then I need two to the 100
dimension for my classical computer to simulate it. And I don't have 100 qubits to run it on either.
So it's very difficult to find ways of really giving evidence if not proofs of why we would expect
this quantum neural networks to work. So what we did on our side, it's two things. The first
thing we said, okay, let's not define quantum neural networks. Let's go back to classical neural
networks. We know that they work very well. Can I speed up the training on them if I have a quantum
computer on the side? So I'm not going to use a quantum circuit as a quantum neural network,
but I'm going to use the algorithms on a quantum computer to train my classical neural network
faster, right? And again, because there is a lot of linear algebra there, we can also prove that
in some cases there are speed ups that you can get from from quantum training, okay? And the second
case was that we are trying to use the intuition that we have from quantum algorithms
to at least come up with quantum architecture is where we can prove something very simple
that they're not going to be words that the classical ones. Even that is not very clear, right?
So I'm trying to get kind of guarantees that say that if you run this quantum neural network,
at least you have the guarantee that it will run at least as well as an equivalent classical one
and hopefully it will run better, but you know, what can we do?
And so is that second part? Have you developed the quantum neural networks or
so we have some for now there's some internal work with QCWARE where we develop some new
architectures based on the intuition that we got from from how to load quantum data because
as I said, this is also something fairly new, but what are the optimal ways of
floating data because for a neural network this is kind of, you know, half of the thing that you
have to do is load the data and then pass it through the neural network. So the fact that we
figure out the optimal ways of loading the data and doing inner products with different data,
this is what kind of gave us the intuition of how we should be defining this quantum architectures
and hopefully we will be able to get some more theoretical guarantees. We are working on it,
we are not there yet, but we are quite hopeful that we will be able to at least propose some
architecture with some provable guarantees now. Is there a way to characterize where we are with
quantum neural networks and the kind of the language that we use for classical neural networks
like, you know, we're at the single hidden layer feed for network stage or, you know,
so I think we're orthogonal to the kind of complexity that we see in classical.
So if you're asking about what type of experiments we can do, right, on a real quantum computer,
I think some of the most impressive experiments is to say that let me look at the M-nist
data set of 100 in digits. I will only pick two digits set of 10 because I cannot handle 10,
I can handle two of them and instead of 700 pixels, we used four pixels and I do
figure out if you have three versus one by looking at four pixels, you know,
blurry images of three's and ones. So when it comes to real hardware, you know,
real data, we're very far from figuring out whether quantum neural networks will work or not,
right? And the implementation of the number of qubits that we have to work with kind of the
the web bar compute bar. At the same time, we have many different proposals for architecture,
so how this quantum neural networks should look like. It's very difficult to prove anything
and you cannot test them. So that's why what we're trying to do is come up with an architecture where
you can at least have some guarantees, some provable guarantees. And it's not easy, it's not easy,
but we're making progress, everyone, many people are working on this, we're making progress,
the progress I think will be much faster when we get our hands on better hardware because this
is kind of a deep letting is empirical to some extent, right? You need to try it out.
And so our people doing, you know, anything approximating kind of, you know,
the, you know, very sophisticated networks, you know, quantum CNNs or quantum deep reinforcement
learning or, you know, on paper at least. So we had, we had the paper that last year's ICLR,
where we discussed quantum convolutional neural networks. Okay.
On our side, that paper was very theoretical in the sense that we used classical CNNs
and quantum ways of training the CNNs. Okay. They have been some proposals on quantum CNNs as well.
You have to find quantum ways to do the different layers, like the pooling, the, you know,
applying the nonlinearity and this type of things. Again, ideas are out there. We need to
find better ideas. We'll be getting better ideas when we find ways of, of trying out things and
figuring out why they work or why they not work. For example, a quantum circuit is a reversible
computation. It's a linear of this unit that is a linear operations. So the first thing is how do
you apply a nonlinearity if you, if you have a linear operator, right? So even that is not
obvious what is the correct way of injecting nonlinearity in a quantum neural network.
The many different things. Maybe I will measure and then I get a sample and this induces
a nonlinear element. Maybe I need to get rid of some of the cubits and look at the subset of
cubits. This also includes some nonlinear element. So even that is not trivial in the many different
ways. And anything on the reinforcement learning side? Reinforcement learning. I think it's probably
the least advanced area. It's also not the easiest one. That's fine. So we started with supervised
learning a few years ago. I'm supervised learning last year. And there have been very few
papers on quantum reinforcement learning. And what we did with the student of mine is to look at
policy iteration before we go to deep reinforcement learning even through, you know,
iterative methods as you said and solving linear systems one after the other to update your policy
and improve your policy and things like that. There are things we can do. And I think reinforcement
learning is quite interesting for quantum for different reasons. One of the reasons is that you
don't have this problem that we discussed earlier of loading data because it's not like you have
images which you have no idea about and you need to really look at all the data and load it.
Your data and the reinforcement learning is basically what you have learned of your game by
taking some moves and figuring out where you're going. So you can kind of produce the data
as you are exploring your state space, right? And this is easier data in the sense that we can
construct data and it's not just data that we have to store and load from memory, right?
So this is one of the reasons why I do think that reinforcement learning is a very interesting
thing for quantum algorithms. And then adding deep RL into the mixture. Yes, it's a great thing to do
and not much has been done. But as I told you, we have a very young field. We have pretty much five
good years of doing things and we have a very small community. So hopefully after the ICML talk
and the interview with you, more people from the classical ML community will start getting
interesting about what is this thing out there. And I'm very happy to talk to people and figure
out how to work together. What are the limitations of, we do this kind of distinction
early on between classical algorithms, I'm sorry, between quantum algorithms and quantum computing.
And a lot of the things we're looking for, a lot of the interesting work is in the algorithms
and independent of being able to run them. To what degree is simulation viable for quantum
algorithms? Can we simulate quantum algorithms in a classical machine? So if you want to simulate a
general quantum computation, a quantum algorithm on hundred qubits, then the equivalent classical
problem that you need to solve has dimension two to the hundred. Precisely because there's a state
of a quantum system of a hundred qubits is a two to the hundred dimensional vector.
So this is why the maximum quantum system that we can simulate classically is something between
30 and 40. I think for now there's something like 32, 34, 36 and this is the limit because you get
to things like two to the 32 when you're touching the limits of what you can do.
And we're depending on what kind of qubits or how you count or which vendor we're kind of at
that point with quantum machines now. So we're beyond the point where it makes sense to simulate
because we have access to the actual machines that are beyond the capacity of what we can simulate.
You're right that for example both Google and IBM have a 53 qubit machine.
So we will never be able to simulate a general computation on 53 qubits because you would have
this two to the 53 object that you have to handle. At the same time this would be the case if you
had perfect qubits somehow that you know what they do. Because if you have 50 qubits that are so
noisy then it's very easy to simulate what will happen at the end it would be just garbage.
And it was exactly the point where what Google managed to do with the supremacy experiment is to
have these 53 qubits good enough that at the end you don't get total garbage but with very small
probability you get something that has to do with what you were trying to compute.
And this is exactly the point where where the reason we call this you know and I think it's a
very important experiment right the experiment said that you have nowadays a machine that can do
something completely useless but something that you cannot simulate classically right now the
holy grail is to go from something completely useless to something very useful that also you cannot
do with a classical computer. And this is what we are trying to reach this point with quantum
machine learning with quantum chemistry with quantum optimization we are not there yet but we are
doing good progress and I think you know the only thing we can do and I think this is my responsibility
there's a scientist as well is to try to accelerate this process so that we can get to real world
applications as fast as possible because at the end we do want to have an impact and to make
this well the better place so we're trying our best. Awesome awesome well you're done is thanks so
much for taking the time to share with us a bit about your recent keynote and your research
fascinating topic and conversation and I appreciate it. Thank you very much for the invitation.
