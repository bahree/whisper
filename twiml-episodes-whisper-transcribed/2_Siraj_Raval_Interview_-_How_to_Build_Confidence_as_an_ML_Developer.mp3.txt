Hello everyone and welcome to the podcast.
If you're a regular listener of the show, I want to start out by saying thank you so much
for your support.
It's been really great to get your notes and feedback about the show.
I won't go into the backstory here, but going forward, I'm going to pivot a bit in my approach
to the show and focus on interviews with interesting folks in machine learning and AI.
And to accompany the podcast, I'm still going to bring you the news, but now via the email
newsletter.
If you'd like to know more about these changes, hop over to the show notes after listening,
which can be found at twimlai.com slash talk, T-A-L-K slash two, the number two.
Okay, so about the interview you're about to hear.
If you've listened to a few of my previous shows, you've probably heard me mention the name
Siraj Ravel.
Siraj is a machine learning hacker and educator whose machine learning for hackers and fresh
machine learning YouTube series are fun, informative, high energy and practical ways to learn
about a ton of machine learning and AI topics.
I had a chance to catch up with Siraj in San Francisco recently and we had a great discussion.
Siraj has great advice on how to learn machine learning and build confidence as a machine
learning developer, how to research and formulate projects, who to follow on machine learning
Twitter and much more.
I'll include links to Siraj's shows and some of the things we discuss in the show notes.
A quick note before the interview.
If you're new to the show, you should know that I've partnered with O'Reilly to give
away a ticket to their upcoming AI conference.
I'll talk about how to enter after the interview and end the show notes and now onto the interview.
Alright, so I'm here with Siraj Ravel.
Siraj, it's great to meet you in person.
I've been talking about your YouTube videos on the podcast for I've talked about a couple
of them and like I wanted to talk about you like every week because there's so many
great videos but I've held back a lot, you know, I got to spread the love.
So it's great to get a chance to meet you in person and I just wanted to spend a few
minutes kind of talking about what you're up to and how you got here.
Sounds good, yeah.
I'm totally down.
Appreciate you coming over.
Nice.
So, you know, let's start there like how did you get into machine learning?
I mean, ever since I was in college, I was looking for something to really put all my
energy into and what it was for me was a robotics lab at my school at Columbia and the robotics
lab was my first for ray into machine learning and I found that there were all these problems
that I wanted to solve that at the time deep learning wasn't really a thing that deep learning
would then solve later like in two years and so I was looking into like the initial types
of machine learning like support vector machines and things like that and just gradually
over time I realized like, hey, neural nets, deep learning, this stuff is like going to
solve so many problems.
So yeah, I've just always been into intelligence and solving intelligence.
That's pretty much my main driver in life like I want to help humanity solve intelligence
because I think it's the most important thing we can do.
So Columbia is, you know, not San Francisco and we're sitting here in San Francisco like
what was the path?
How did you get?
How did you end up here and what are you up to?
Yeah, so yeah, was that Columbia and honestly I didn't feel like I really fit into Columbia.
I was, you know, I fit in really well here in San Francisco in like Silicon Valley culture.
I think because I'm, you know, I'm not so much into like going to classes in person and
just like studying subjects that I don't care a lot about.
Like I just wanted to just study robotics and AI.
So once I was at the robotics lab, I felt like, okay, this is, this is like my thing.
I'm going to keep doing this.
But that only lasted like a year and then I had a startup called Lucid Robotics where
I was trying to create a robot for your home like a platform where each app would be a physical
task.
So you'd have an app for like cleaning the dishes and stuff.
Clearly, this was way out of scope at the time, but at the time you couldn't tell me that.
I had to see the computer science problems myself.
What actually ended the startup, I mean, we raised funding from Sabir Bhattia, the founder
of Hotmail, we had a team.
What ended the startup was we couldn't get the robot to pick up a simple novel object
they had never seen before.
Deep learning now solves this.
So then, so then after the startup failed, I dropped out.
I dropped out of Columbia.
I just was so disenchanted with so many things.
And I felt like San Francisco was the place where I could go to rediscover myself.
And it's been a, it's been a, you know, quite a journey.
And there's been a lot of uncertainty in my life about what I should be doing, the path
I should be moving towards.
But I'm lucky enough to have come to the conclusions that I have that intelligence is the most
important thing for us to solve in our lifetime.
Because if we don't solve it, then some other catastrophe could wipe out our species, whether
it's biochemical terrorism or some natural disaster or, you know, something like that.
We have to solve intelligence.
Yeah.
So how did you, how did that bring you to doing a YouTube channel?
Yeah.
So, so I, you know, I had a few jobs here as an engineer at CBS Interactive and at Twilio
and they were, they were incredible.
I love these positions, but engineering itself just, I don't know, I felt like I could,
I could be having more impact at Twilio.
I mean, Twilio was a great place.
They, I was doing company, it was a great company.
I was doing developer education and like, that was my full time role.
So I was doing technical writing.
It was the first time I hadn't just been doing code.
And I felt like, okay, this is, this is my thing, like technical writing.
This is awesome.
I get to, I get to combine my writing ability and my coding ability.
Yeah.
The thing for me, like the reason that I left was that I wanted to do video documentation.
I believe in the future of video documentation.
And I, I feel like Twilio was going on a different path.
So I decided, okay, you know what, I'm just going to do this full time.
And so I started the YouTube channel on the side while I was at Twilio.
Okay.
So I was making one video a week, but the quality wasn't at the level that I wanted it
to be.
I didn't have enough, like the production equipment wasn't good enough.
Yeah.
I wasn't giving enough time to the technical writing.
So the only option I had was to quit and do this full time.
Okay.
And so then I was just like, all right, here we go.
And how many have you done?
Video so far.
Yeah.
I think it's like, it's at least, at least like 28 videos now.
Wow.
Almost 30.
It's one video a week every week since like January 1st.
Wow.
Nice.
Nice.
And you've, the original show was called Machine Learning for Hackers.
Is that right?
Yeah.
Machine Learning for Hackers.
And you, you've just launched a new one?
Yeah.
And does that one replace Machine Learning for Hackers?
Or are they like two parallel tracks that continue ongoing?
You know, it's interesting because the idea with Machine Learning for Hackers is that
it's meant for developers.
And Fresh Machine Learning was also meant for developers, but it was like a different
topic subset.
It was like newer things.
But what I've noticed is that I have, so my subscribers, I have three different types
of people who are watching me.
I have the research scientists, the cool kids who are like developing the novel algorithms.
Then there's the developers who are, honestly, they're also the cool kids.
And those are the people I really want to, you know, they were my main motivation from
the start.
I want to make things for developers.
And then there's actually the third subset which I'm learning about, which are people
who are not really technical, but they really want to be.
So it's like, I have to make videos that catering to each of them.
So I'm still kind of trying to figure out like, you know, because sometimes my video is
catered to the research scientists, sometimes the developers, sometimes the, you know, people
who are not very technical.
So I think for now, I'm making videos that kind of cater to all three, but eventually I
want to get to the point where I have channels, dedicated channels for each of these subsets.
Yeah.
And for that, I have to grow a little bit more.
Okay.
It sounds like, in a lot of ways, a parallel path to mine with this podcast, I, you know,
my initial vision was, you know, I just couldn't get enough machine learning information.
Like I, I, you know, spend the week like opening up web browser tabs of articles that I wanted
to read or papers that I wanted to take a look at.
And I'd end up in a given week with like 80 to 100 of these tabs open.
And I'm like, this is ridiculous, not, and then you spend some time going through it and
half of it is crap.
And like if everyone's doing the same thing, then, you know, people would appreciate, you
know, something that tries to figure out what's good and what's not and just spend some
time talking about what's good.
So hey, I don't have to spend my week collecting this bag of tabs.
And you know, it's been super rewarding, but it's like a ton of work.
It's a ton of work.
And then I look at your stuff and like, I can't imagine what goes into, you know, your
videos because you're like going deep into a topic and then, you know, you're writing
code, you're like, you know, publishing code up on GitHub.
What's the process?
Is it, is it the same every, every week, or are you like still experimenting?
Yeah.
So I've developed a methodology for this over time.
Like I'm building the process.
So what it is is like the first part of research, like what is the topic I want to talk about
and let me just learn about it.
The second part is the code, like programming it.
Like I'm going to program some very, very simple, what I like to call the quick start
of X.
So the quick start of auto encoders, the quick start of support vector machines.
Yep.
Then it's the technical writing.
So research, code, technical writing, then it's the production.
So the actual video, like shooting it, and then it's editing.
And then there's marketing and release.
So yeah, it's like five or six things in sequential order.
And I can, I managed to fit, I'm able to fit all these things into a single week and
it takes around 40 to 60 hours for a single video.
Generally, it's closer to 60 hours.
Now I have clients, so I'm increasing the output from one video a week to two.
So that's like 120 hours a week.
That's a lot.
This is actually the first week where I have to make two videos in one week.
So I'm hiring, yeah, I'm hiring a video editor, a technical video editor, which is like
a new role because they have to be a video editor who also knows kind of like how to code.
Because I have code and I have to, you know, they have to point those red arrows at what
I'm talking about.
They have to be at least.
They need to know what's important.
They need to know what's important, right?
And they have to know the cards, you know, the cards where I'm talking, like what I'm
saying, like, oh, this is a relevant what he's talking about, like support documentaries
or whatever.
Yeah.
So I'm looking for unicorns, basically.
Yeah.
Yeah.
Aren't we all?
Well, so you're doing it all in one week, you're not like, you know, researching one week
and producing the, you know, researching in next week's video one week and then producing
it's all self-contained in that week.
It's all self-contained in that week, yeah.
And how do you determine what's, you know, what you're going to talk about next?
That's a good question.
I, so, yeah, so I browsed the machine learning subreddit, looking at what's hot, what
it, whatever interests me, I look at hacker news, I look at Twitter, like Twitter is actually
a great learning tool for me.
I just follow people who I think are really smart and, you know, young lacunes and stuff
like that.
And I think my, the other data source is Facebook groups, I mean, a lot of machine learning
Facebook groups.
So yeah, whatever is like new and hot and the intersection of what's new and hot and
like what I'm into, generally, I can figure that out in like one day, but it takes all
day.
Yeah.
Yeah.
The curation part is, yeah, it's hard.
I mean, there's just, there's a lot of stuff out there, you know, like I said before and
there's a lot of stuff that, you know, looks really, there's a lot of clickbait, right?
It looks really interesting.
And then you get, you dig deep and it's just nothing there.
Totally.
Yeah.
Or it's like just way, way too technical and you didn't even think it would be.
It's like a lot of math.
It's like, ah, here we go.
Is there an example of, you know, something that you thought you wanted to take on?
And then you just, you know, found out that it was just, that the math was just too ridiculous.
I think, ah, well, I can't, well, I, if I've decided I'm going to do it, I'm just like,
I literally don't have time to like, not do it because I've, you know what I mean?
Because I just have to keep going.
But I can tell you that the closest I was to like, not being able to finish a video
was generative adversarial networks.
That was a very video.
That was a very video.
Thank you.
That was the hardest video I've ever had to make because make, because that stuff, yeah,
that stuff was pretty hard.
Was that the video where you're like, well, this really should be two or three videos,
but I'm just going to, you know, cram it down to one and see how it goes.
It was one of those where you said something like that, I thought.
Um, yeah, no, no, I could definitely have more than one on, uh, Gans.
Yeah.
Uh, so what, um, you know, that's the topic that's come up on my podcast quite a bit.
Why don't you talk a little bit about, um, you know, talk a little bit about Gans, what
you learn there in, in doing that project.
Yeah.
So yeah, Ian Goodfellow, who's now a research scientist at OpenAI, he's, he's the guy who
authored the paper, but it's a, it's a generative model that can create, uh, so if you give it
some input data, it's going to, it's going to have some output data that's similar to the
input data, but different.
So if you feed it like a collection of faces, it's going to generate faces that look similar
but are different.
And at first, I was like, well, how is this going to be useful?
But it's a tool for any kind of engineer to design, uh, so if you feed it like, you
know, uh, collection of living rooms, it's going to be able to generate novel living
rooms that look photorealistic, which is super cool.
So it's a tool to help engineers like envision their ideas better.
And yeah, yeah, I, um, I like the idea of two dueling entities, you know, uh, uh,
how the discriminator is always trying to, uh, fool, um, fool, fool, fool its counterpart,
or the, the counterpart is always trying to fool the discriminator, which is always trying
to detect like, oh, is this, is this false or real?
Right.
And just keeps doing that until eventually, you know, it just gets better and better.
It's a brilliant idea.
And like, you know, deep mind has done this stuff with like AlphaGo when they trained
two dual neural neural nets against each other to play Go, so it just got better and
better.
So this idea of, you know, of having this adversarial nature can be applied to a lot of other
things in machine learning.
Have you seen examples of that?
I've been looking for that, uh, as well, I've come across, uh, or at least ideas of, uh,
of, you know, where, hey, if we can pit one machine learning algorithm or one AI against
another, you know, and let them train each other.
Have you seen, uh, besides from the, the generous stuff that was covered in the papers,
other examples of that?
Yeah, um, I think, uh, there's a lot of a potential for like game AI.
So if you have, you know, a bot versus a human, or just two bots first thing each other.
Um, I think so, so deep mind is like really into games, which is cool.
Uh-huh.
And I think there's a lot of potential for combining, uh, adversarial work with what
they're doing in 3D games.
Um, just as like a, I mean, it was, it's kind of like a suggestion on my part.
I'm sure they've already thought about this, but if you, um, apply gans, if you were to
apply gans to games, I think that would be really cool.
I haven't seen a paper.
No, we're talking about like first person shooters type games or the types of games that
they're playing, you know, in deep mind, the Atari game.
No, no, no, yeah.
Okay.
So, okay.
So like, what I think is really cool, um, so open AI just yesterday.
I think released this call for, um, research scientist on four problems.
There was number four was, what was it?
It was like create a simulation that where all the entities get better and better over
time.
Like you create an entity in the simulated world and then it learns to like what kind of
food it needs, what kind of nutrition it needs to survive better and better.
Like I think there's a lot of potential for adversarial, uh, algorithms there, um,
two entities versus each other in this, in this simulated world.
So maybe not necessarily just a game, but any kind of simulated environment where you
have a set of constraints and you want, you want it, you want some kind of AI to get
better over time.
I think we're going to see a lot of, um, a lot of adversarial algorithms in the future.
And a lot of one shot learning, mm-hmm.
I'd like to see more of that because right now, you know, all this machine learning stuff
is, is kind of siphoned off to these big companies like Facebook and Google and Apple.
But with, you know, if, with advances in one shot learning, anybody who is going to be
able to, uh, create these models and, and learning algorithms from sparse data, startups,
for example, that only have like, you know, a hundred users, but they want to imply machine
learning to that.
Right.
Right.
Uh, so you dig into a topic like this, you know, Gans, there's, you know, research papers.
Like how do you, how do you take, how do you make the leap from that to code to getting
code up?
Um, you know, a lot of the folks that listen to my podcast, I've, you know, heard from,
you know, are in the process of learning and they're trying to figure out projects to work
on and, you know, getting from some of the things that they're reading about to, you
know, some working example, like, and you've got that down to a science, right?
So at this point, yeah, uh, from repetition, how do you approach it?
Yeah, so I think, um, for me, it's, it's, it's, it's, a lot of it is what I learned
from Tulio, like the idea of having a quick start, like a bare bone skeleton that a developer
can then build off of.
What is the minimum viable product for, for demoing this, this idea that you have?
However simple you can make it, do it.
So if I read something like, you know, um, a paper on, like, for example, ah, there's
so much, uh, auto encoders, what's the simplest thing I can do with an auto encoder?
An auto encoder takes them input, compresses it and then, uh, reconstructs it.
It's only a, it's a three layer, it's a very simple neural network.
What's the simple, simple demo I can make with this?
And I just think about it and I'm like, okay, compression, oh, compression, just compression
alone.
So just use it as a compression algorithm.
So like a zip, you know, zipping, yeah, zipping and unzipping.
So then I was like, okay, so then I'm like, okay, so how do I code this?
So what I first do is I search GitHub.
So it's happened like very, you know, auto encoder and I look under Python because Python
is awesome.
And I see what's been done before, usually, usually something has been done before.
So I'll take that and I'll like kind of like strip away the unnecessary things and add
documentation.
And that's going to be the demo.
Okay.
And the rare case, it's not, then I have to code it myself.
Okay.
Yeah.
How often does that happen?
That code to get yourself, like entirely, um, I'd say like off the top of my head, probably
like 15% of the time.
Okay.
Yeah.
So one of the, you know, the two lessons I got from that are, you know, simplify, simplify,
simplify, like, you know, you know, whether it's, uh, the actual coding or the, uh,
you know, trying to parse the research, it's like, figure out what this thing is at its
bare essence and focus on that, uh, and then like reuse, like, figure out what's been
done and try to use that.
Is there anything else?
And like any other pieces of advice that you'd give to folks that are trying to work this
process?
Um, yeah, just like, don't be intimidated by papers, like, there is a lot of math and
papers.
Really, like when I'm reading a paper, um, it's the abstract and the background, the process
and the conclusion, which matter the most to me.
And there's really not a lot of math.
It's, it's, it's when they start describing, you know, certain aspects of the process that
it can get really, really confusing if you don't know math notation.
But math notation itself is in serious need of an upgrade.
Mm-hmm, so it's more human readable.
Mm-hmm.
Right now, it's kind of siphoned off to just these research scientists who look at this
stuff every day.
So I think, you know, we're going to start to see, um, innovations in, in how we publish
scientific research so that anybody can read it.
What that's going to look like, I'm not sure.
But they're just, they're just too much coming out right now and it's too important, uh,
for a few people, for only a few people to be able to read it.
So, so I would say, if you just read the abstract of a paper and you feel like you get the
gist, that's fine.
You can go start searching GitHub with just that.
Don't feel like, um, you know, guilty or, or something.
And definitely look at videos and, and what I try to do when I'm trying to learn something
is I try to get as many different types of data sources that can into my brain.
That always helps.
Videos, articles, conversations with people, you know, there's, there's a lot of content
out there.
And it's just going to increase exponentially.
Mm-hmm.
Yeah.
I find the same thing and find also that, um, sometimes it doesn't work out like you expect
like the, I did a review of the Google research wide and deep learning paper.
And you know, they've got this cool YouTube video that, you know, simplifies everything.
But I watched that and I didn't, I didn't get it.
But then I went through the paper and, uh, it made sense.
And then I went back to the video and was like, oh, yeah, I don't know why I didn't get
that before.
Yeah.
I think that, you know, having lots of different types of input can make a big difference.
So what's, like, what's your roadmap for, for upcoming topics and research?
Yeah.
Um, so in terms of like the topics themselves, I kind of decide them week to week.
But the, for the larger vision is to just focus on machine learning, kind of be like
Khan Academy for machine learning.
And I'm going to start needing help and from other people.
So I'm hiring and, uh, yeah, just try to get, I'm just optimizing for subscribers.
I want to get, you know, I want to get every developer on the planet to at least do a little
bit of machine learning.
I think it's super important.
Uh, there are about 10 million developers on the planet right now.
And not nearly, there's not nearly enough that are even aware of how important machine
learning is, um, architecture engineering is a new, uh, feature engineering.
And if you want to win, if you have a startup, if you, if you have, uh, an idea, if you
want to win, you, at this point, you have to implement some sort of AI because if you
don't, someone else will, right.
So I want to make machine learning as, you know, democratizing, making it as accessible
and understandable as possible to as many people as possible.
So I'm just going to keep going down that path and do whatever it takes to, to make that
happen.
And that's going to be lots and lots of videos in the future.
You've got a new project that you're working on.
Is that something that you can talk about?
That's going to be public as well.
That's going to be public.
Yeah.
And it's not going to be on my channel.
It's going to be on theirs.
But a big ML, like I'm partnered with, I've, I've now, you know, I've signed a deal
with big ML.
So I'm going to be making a video series for them, um, about their product and it's going
to be, it's, it's called cloud machine learning.
And it's using big ML to do a bunch of, uh, pragmatic, real world applications.
So the first one, uh, is going to be, uh, about climate change and how we can use machine
learning to prevent climate change.
Okay.
So I'm super excited about that one.
And then so like, because video content takes up so much of my time, I don't really have
time to do things like client acquisition and, yeah, you know, all this, all this stuff.
So the, the clients that I do have are the people who have come to me and right now have
like seven or eight and they're kind of in a queue, uh, and yeah, I'm just taking on
as much as I can handle at a time.
And as I grow, I'm going to start, start looking at more, you know, ideally, you know, my
goal is to one day partner with deep mind.
I want to make videos for deep mind, um, but they're like, I consider them like the Navy
Seals machine learning, so I've got to get, I've got to get to that level.
You know, the Apollo program for intelligence, uh-huh.
You know, if we solve intelligence, we can apply it to anything like just think of it as
an objective function or X any problem you can ever think of it.
If you have the right learning algorithm and you say solve for X, it could solve it, scientific
research problems or even existential problems, the questions that have plagued us in
stay one.
Who are we?
Why are we here?
What's the point of the universe?
You might not be capable of figuring this stuff out ourselves, but a highly intelligent
AI could.
Mm-hmm.
We might not like the answers.
We might, we might not like the answers.
We might not like the answers, but where, so where do you fall on the whole singularity
thing?
All right.
That's what, wake, wake, that's why I wake up in the morning.
I want to make it a benevolent singularity happen as soon as possible, uh-huh, as soon
as possible.
What do you think about the, uh, the open AI research stuff that they put out a few
weeks ago on Safe Machine Learning, have you been following that stuff?
Mm-hmm.
So, so specifically like, uh, ways to, they published this framework for like four or
five different areas of research that need to be kind of dug into so that we can ensure
the safety and, you know, benevolence as you put it of, of AI like, you know, if we've
got a AI powered robot, um, you know, how do we, how do we ensure that, you know, it
doesn't learn how to game the system and, um, and, you know, for example, if it's being
programmed to clean, right?
How do, how do we know that, how do we program it so that it doesn't sweep stuff onto the
carpet?
Right.
Yeah.
I think, um, yeah, and then Google had like the kill switch paper, which I thought was
super cool.
Uh, I like that open AI is thinking about this.
I love open AI in general, the, the concept behind it.
I think, um, yeah, it's like preventing AI from doing bad things is going to be really
important.
I mean, technology has always been a double-edged sword, you know, with the, starting with
the natural fire.
And I think that, you know, with security, I think that's going to be one of the first,
uh, where we're going to see, uh, we're going to see the power of AI, uh, when it comes
to protecting humans, if you have an AI and you train it to get really good at breaking
into systems, the only thing that's going to be able to stop that is an AI that's good
at detecting an AI that can break into systems.
So, uh, I think it's a great thing what they're doing.
I think it's really important.
I think it's really important.
And what Mary is doing as well, and, uh, you know, the ethics committee that DeepMind
has at Google to prevent, uh, you know, malevolent types of AI, all this stuff is super,
super important.
Mary's the machine intelligence research institute.
Yeah.
Yeah.
Yeah.
Yeah.
And, you know, there's always a question like, can we stop it, um, you know, who knows?
But it's, it's, it's good to try.
And honestly, uh, if a malevolent AI, uh, doesn't kill us, then something else likely
will.
So this is something that, um, just something that's really important.
Hmm.
So what's your maybe taking a step back like for folks that are trying, uh, do you have
a quick like, if someone, you know, a friend comes up to you and says, okay, I really,
you know, I really want to learn this stuff now.
Like what's your curriculum?
What's your, you know, one, two, three, uh, list of stuff to do is it?
Do you think are you trying to build your videos so that someone could just follow those
and get everything that they need or, uh, are there some set of resources that you think
are kind of canonical?
Yeah.
So I think that, um, my videos are good if you know some basic Python.
If you know Python, then my good, my videos are a great starting point.
But I think that my videos alone are not enough, um, you know, it's, it's one of the things
of like combining different data sources.
So I think my videos, in addition to some long form content, I think, uh, so for me, uh,
big ML has some great long form content, um, there's, uh, so, you know, I actually don't
think I think that, uh, there's a deep learning course on Udacity, uh, by a Google engineer
who works at Google Brain, I forgot what it's called, but if you, if you Google just
like Udacity deep learning, uh, that, that course is really good.
That to me is even the TensorFlow course or not the TensorFlow course.
That's a great one.
Um, but there's one specifically on deep learning in general, um, um, there's just
just so much.
I think it's, it's one of those things where it's like, you, okay, so if you're saying like,
I want to learn machine learning, I would say like, okay, first learn Python, um, uh, by
reading the book, uh, learn Python the hard way, um, uh, and then once you, once you,
once you feel like you're comfortable with Python, just start building things, just start
building things and, and my videos are good because it's application specific and I make
it really easy for you to, you know, just, when you hit compile and you see your model
train, train and then you can apply to other things, that is like super useful for, for
your confidence as a machine learner and also just as a developer.
So and also just go to GitHub and search for machine learning projects like search for
like machine learning demo or machine learning simple and just look at those readmeas, download
them, compile them, open it in a text editor and just like go through them one by one and
like really try to understand what's happening, you know, and, and I would say start off
at a high level because, you know, some people would say the other way, like start off at
a low level, like learn exactly how to implement these models from scratch.
No, no, no, I would say start off at a high level and once you get it at a high level,
then you can start like trying to rebuild, you know, uh, you know, you know, you know,
neural net from scratch.
Yeah, like custom and implement from ground up or implement some research or something
like that.
Yeah.
Yeah.
Yeah.
Keras, torch, lots of great libraries these days.
Mm hmm.
Nice.
Um, what, uh, Quora is well, sorry, Quora is awesome.
I've learned so much from Quora, just like, you know, cause I'll find one question on
Quora on deep learning and on the side bar, it's like, oh my god, all these questions
are amazing.
And then you have people like Jan LeCoon answering them and like Monica Anderson and like,
all these like really famous research scientists.
Yeah.
So I've learned a lot from them.
Are there people that you, is it primarily like search, uh, based that where you find
stuff or are you following particular people and just kind of keeping up with them there?
It's search based.
Search based.
Yeah, search based.
How about on Twitter?
Are there, you mentioned Yana, there are other folks that you, uh, yeah, find our good
signal to noise, uh, machine learning folks on Twitter?
For sure.
I think, uh, for me, uh, I think Chris Dixon, he's a partner in Andreessen Horowitz.
He, he's, he's good for like knowing, uh, you know, what's up and coming and machine
learning.
I think he has a good eye for that.
One person in general that I really respect about technology is Bology Srinivasan, who's
also a partner in Andreessen Horowitz.
That guy knows he lives in the future.
And, um, yeah, board, Jan LaCoon is also like a great Twitter handle.
I don't think I've come across that one yet, but it sounds funny.
I really like it.
Yeah.
Yeah.
Nice.
And, yeah.
And then, and, and, and following these big companies like Amazon and Google is really
important because you, you can see like, oh, they just released, you know, DSST&E,
their new machine learning library, which needed to be renamed, but, yeah, destiny.
It's great.
I don't think so, I'm not a fan, but, I mean, in general, I think machine learning needs
better marketing, like a lot, a lot, you know, not, I'm not going to diss anybody, so nice.
So for folks that aren't familiar with your, your videos, are there, you know, two or
three that like, oh, man, these were my favorite or these were my best are, yeah, um, I think
so the, the one that ended up being most popular was AI composer.
That was the second video I made for machine learning for hackers.
So AI composer, so the top three would be like AI composer.
The one I'm most proud of is generative adversarial networks because it was the hardest.
And the one that I thought was the dopest was a build an AI artist because I just thought
that application was really cool, like applying some style to some novel, you know, picture.
This like the thing that Prism is doing now.
That Prism is doing.
Yeah.
Nice.
And so what is the, what's composer?
Composer is generating machine, like machine generated music.
Do you feed it to music, like a data set of like, you know, 500 songs, it'll learn the
style of that song and then it can generate new music in that same style.
Okay.
And I trained it in the video over British folk music, but you could apply anything to
it.
One idea I thought would be really cool that someone should do is take Hans Zimmer music
and generate music in the style of Hans Zimmer.
So Prism for music.
And that's kind of what the magenta magenta is trying, well, I'm, they're not trying
to do specifically that, but did you use magenta, any of their code in your, in this project?
I didn't.
No, no, no, no.
This was for that, it was not that, yeah, it was, I found it on GitHub and I modified it.
Okay.
Yeah.
Nice.
Interesting.
What was I going to ask you?
Oh, you've done a, you've done a couple of videos on chatbots and chatbot platforms.
That was a good one.
What do you think about that space and like, what would you learn and, you know, over a few
attempts at playing around with that stuff?
Yeah.
I think, you know, I, with the marketing effort, I expected, I expected with AI, like Facebook's
acquisition, that, that chatbot building technology to be way better than it was.
But what ended up happening is I found that API.ai had a much better, it was much easier
for me to build a chatbot with API.ai.
Yeah.
I think that chatbots in general are going to get really popular and we're going to replace
all of our apps with chatbots.
This is already happening in Asia.
So like with WeChat, like, a lot of people don't even use apps anymore, you know, in China
and stuff because it's so easy to just say like, you know, you can even combine different
apps together, like book me an Uber in 30 minutes at this location and take me to my favorite
restaurant.
And that's querying.
Like, Yelp, your Google or whatever, you know, your preferences locally and the Uber
app or if it was in China, quality.
So there's a lot of potential for chatbots.
And if you are like right now thinking about, you know, building a startup, like if it
was me, if it was me, I would be doing some kind of chatbot, chatbot for X where there
is no chatbot because this is just going to get more and more popular.
Like I already used chatbots in Messenger for like, you know, like detecting like scores
and stuff like that.
Scores of like sports and stuff.
Yeah.
Okay.
No, I mean, not that I watch sports, but like I just play around with them.
Yeah.
Yeah.
Yeah.
But I haven't found anything that's particularly useful like the thing that I haven't played
around with a bunch of them, but you know, they're all kind of, uh, yeah, which is the
doesn't feel like we're there yet.
Yeah, we're not there yet.
We're not there yet.
But we will be in like a year.
That's how fast the space is moving.
Yeah.
Yeah.
It's just going to it's just yeah.
Right now there's a lot of people who are like really need deep in this stuff and
they're building, but we're going to see a lot of releases.
And like, you know, because the bigger players haven't caught on yet, that, you know, that's
one of the reasons.
But deaf, I promise you Uber has a team dedicated to this Airbnb has a team dedicated, right?
Absolutely.
And then Facebook's releasing M, which they're training right now full time with like humans
and machines and just getting better and better and people internally at Facebook are
using this.
And I talked to, you know, some of these people and they really like it.
Um, and I was like, please give me an invite to M like, wouldn't you like to have an invite?
I'm like, oh my God.
If anyone at Facebook is listening, we both want invites to ask.
Yes.
Please.
Please.
Nice.
Nice.
Well, that's been great.
It's been great.
Channel with you.
Anything that you'd want to leave folks with or point them to or, you know, help them
to check out.
Yeah.
Um, yeah, I would say definitely subscribe to my channel because I'm just getting started.
And that's where I'm putting all of my effort into right now.
And, uh, what else, I would say, if you're a unicorn video producer, if you're a
universe machine learning, yeah, if you're, if you're a video editor who happens to know
how to program as well, definitely, uh, you know, message me on Twitter, uh, because
I'm looking for you because I need you.
And, uh, yeah, just don't, don't give up if, if, you know, machine learning is, you
know, it's, it's kind of hard, but it's a worthwhile endeavor and you can make a lot of money
for it from it.
And you can learn a lot and it's going to, and if you, if you get good at learning about
machine learning, which is one of the, it can be one of the hardest things on the planet
to learn, like solving intelligence, like the human brain, like how do we work is equivalent
to asking like, what is the universe?
If you can get good at that, it's just going to train your brain to be good at so many
different things.
So, yeah, don't give up.
Awesome.
Awesome.
Well, thanks.
Yeah.
Thanks.
All right, everyone, that's it for today's interview.
Before we go, a reminder that this week in machine learning and AI and O'Reilly have
partnered to offer one lucky listener a free pass to the inaugural O'Reilly AI conference,
which will be held at the end of September in New York City.
You can enter via Twitter or the twimmalei.com website by doing one of the following three things.
The preferred way of entering is via Twitter.
Just follow at twimmalei, T-W-I-M-L-A-I and retweet the contest tweet that I'll pin to the
account and post in the show notes.
Do those two things and you'll be entered.
If you're not on Twitter, you can sign up for my newsletter at twimmalei.com slash newsletter
and add a note, please enter me in the additional comments field.
Finally, if you're not on Twitter and you aren't interested in the newsletter, no problem.
Just go to the contact form on twimmalei.com and send me a message with that form using
AI contest as the subject.
The drawing will be open to entries through September 1st and I'll announce the winner
on the September 2nd show.
Good luck and hope to see you in New York.
Thanks again for listening.
