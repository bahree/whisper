1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:34,320
I'm your host Sam Charrington. For those challenged with promoting the use of machine learning

4
00:00:34,320 --> 00:00:40,760
in an organization and making it more accessible, a key to success is to support data scientists

5
00:00:40,760 --> 00:00:46,320
and machine learning engineers with modern processes, tools and platforms.

6
00:00:46,320 --> 00:00:51,480
This is a topic we're excited to address here on the podcast with the AI Platforms podcast

7
00:00:51,480 --> 00:00:56,080
series that you're currently listening to, as well as a series of e-books that will be

8
00:00:56,080 --> 00:00:58,080
publishing on the topic.

9
00:00:58,080 --> 00:01:02,760
The first of these e-books takes a bottoms up look at AI platforms and is focused on the

10
00:01:02,760 --> 00:01:08,120
open source Kubernetes project, which is used to deliver scalable machine learning infrastructure

11
00:01:08,120 --> 00:01:12,840
at places like Airbnb, booking.com and open AI.

12
00:01:12,840 --> 00:01:17,640
The second book in the series looks at scaling data science and ML engineering from the top

13
00:01:17,640 --> 00:01:23,000
down, exploring the internal platforms, companies like Airbnb, Facebook and Uber have

14
00:01:23,000 --> 00:01:26,600
built and what enterprises can learn from them.

15
00:01:26,600 --> 00:01:31,280
If these are topics that you're interested in and especially if part of your job involves

16
00:01:31,280 --> 00:01:36,880
making machine learning more accessible, I'd encourage you to visit Twimbleai.com slash

17
00:01:36,880 --> 00:01:45,320
AI platforms and sign up to be notified as soon as these books are published.

18
00:01:45,320 --> 00:01:51,360
In this episode of our AI platform series, we're joined by Daniel Jevins, General Manager

19
00:01:51,360 --> 00:01:54,080
of Data Science at Shell.

20
00:01:54,080 --> 00:01:58,400
In our conversation, Daniel and I explore the evolution of analytics and data science

21
00:01:58,400 --> 00:02:04,040
at Shell and cover a ton of interesting machine learning use cases that the company is pursuing,

22
00:02:04,040 --> 00:02:07,360
like well drilling and charging smart cars.

23
00:02:07,360 --> 00:02:11,840
A good bit of our conversation centers around IoT related applications and issues, such

24
00:02:11,840 --> 00:02:17,560
as inference at the edge, federated machine learning and digital twins, all key considerations

25
00:02:17,560 --> 00:02:20,280
for the way they apply machine learning.

26
00:02:20,280 --> 00:02:25,000
We also talk about the data science process at Shell and the importance of platform technologies

27
00:02:25,000 --> 00:02:28,280
to Daniel's organization and the company as a whole.

28
00:02:28,280 --> 00:02:32,120
And we discuss some of the technologies that he and his team are excited about introducing

29
00:02:32,120 --> 00:02:34,000
to the company.

30
00:02:34,000 --> 00:02:35,640
And now on to the show.

31
00:02:35,640 --> 00:02:44,360
All right, everyone, I am on the line with Daniel Jevins.

32
00:02:44,360 --> 00:02:48,280
Daniel is the General Manager for Data Science at Shell.

33
00:02:48,280 --> 00:02:51,680
Daniel, welcome to this weekend machine learning and AI.

34
00:02:51,680 --> 00:02:53,280
Thanks so much for having me.

35
00:02:53,280 --> 00:02:59,320
Before we jump in, I'd love to hear a little bit about your background and how you got

36
00:02:59,320 --> 00:03:02,840
to working in data science at Shell.

37
00:03:02,840 --> 00:03:08,000
I know previously you were the General Manager for Advanced Analytics at the company and

38
00:03:08,000 --> 00:03:10,640
you've worked in that capacity for a while.

39
00:03:10,640 --> 00:03:13,080
Tell us a little bit about your background.

40
00:03:13,080 --> 00:03:17,480
Yeah, so it's not a straightforward story.

41
00:03:17,480 --> 00:03:23,440
When I left university, I joined Accenture as many of us did in that era and spent a

42
00:03:23,440 --> 00:03:26,520
bunch of time developing big systems.

43
00:03:26,520 --> 00:03:31,400
And I guess the Eastward described what I was doing was data engineering without any of

44
00:03:31,400 --> 00:03:32,400
the tools.

45
00:03:32,400 --> 00:03:33,400
We used a lot of SQL.

46
00:03:33,400 --> 00:03:36,480
That sounds fun.

47
00:03:36,480 --> 00:03:38,000
It was tough back then.

48
00:03:38,000 --> 00:03:43,720
We hacked a lot of stuff together in Excel and made some crazy business insight for executives

49
00:03:43,720 --> 00:03:49,040
based on core business processes and taking raw data out of SAP.

50
00:03:49,040 --> 00:03:50,040
It was a fun time.

51
00:03:50,040 --> 00:03:54,600
We spent most of the evenings extracting data and then run it overnight and come back and

52
00:03:54,600 --> 00:03:57,320
hope the results worked in the morning.

53
00:03:57,320 --> 00:04:02,320
And that worked pretty well, but it was a fun start and I learned a lot from that.

54
00:04:02,320 --> 00:04:05,800
So I also got really interested in the interface between data and process.

55
00:04:05,800 --> 00:04:11,720
And I guess the easiest way to describe my career is that I've always been in that interface.

56
00:04:11,720 --> 00:04:16,920
And so then I then spent a lot of time learning about things like Six Sigma and Lean and trying

57
00:04:16,920 --> 00:04:21,360
to apply some of those techniques into the business processes that I was extracting

58
00:04:21,360 --> 00:04:26,320
data for and trying to improve the way that our business ran.

59
00:04:26,320 --> 00:04:31,840
And I went through a whole series of roles in that sort of area from data architecture

60
00:04:31,840 --> 00:04:36,680
to process architecture in the CI office in a more strategic role.

61
00:04:36,680 --> 00:04:42,960
And then eventually got to the point where I saw back in about 2012 that increasingly

62
00:04:42,960 --> 00:04:48,960
there are a whole series of new tools coming out that were starting to apply data science

63
00:04:48,960 --> 00:04:52,440
in really interesting ways to improve the way that the business ran.

64
00:04:52,440 --> 00:04:55,480
And what I saw was that this was going to be a big thing and it was going to change

65
00:04:55,480 --> 00:04:57,640
the way in which industry did business.

66
00:04:57,640 --> 00:05:02,640
And so I went to my manager who was at the time Shell's lead architect and I said to him,

67
00:05:02,640 --> 00:05:05,800
look, I see a big opportunity in this space.

68
00:05:05,800 --> 00:05:09,360
Would you let me go and start something?

69
00:05:09,360 --> 00:05:11,640
And he said, actually, we've just created a new role.

70
00:05:11,640 --> 00:05:15,080
The IT executive wants to do something as well.

71
00:05:15,080 --> 00:05:16,080
Why don't you apply?

72
00:05:16,080 --> 00:05:20,360
And so I applied for what we then called the predictive analytics center of excellence

73
00:05:20,360 --> 00:05:22,680
lead position.

74
00:05:22,680 --> 00:05:25,560
And I think they didn't really know what it was or what it was supposed to be.

75
00:05:25,560 --> 00:05:28,960
So they appointed me.

76
00:05:28,960 --> 00:05:33,080
And I sort of went back to my roots and I said, well, what do I need to make this successful?

77
00:05:33,080 --> 00:05:38,760
Well, I need some good data engineers and I need some people who understand stats.

78
00:05:38,760 --> 00:05:43,760
And so I hired a statistician and I went back to some of my old colleagues and brought

79
00:05:43,760 --> 00:05:46,640
in a data engineer and we got started.

80
00:05:46,640 --> 00:05:49,280
And we didn't really know what we were doing back then.

81
00:05:49,280 --> 00:05:51,040
We were sort of making it up as we were going along.

82
00:05:51,040 --> 00:05:54,800
We got a lot of input from others and talked to a lot of different companies.

83
00:05:54,800 --> 00:05:59,000
So what was really interesting was we figured out pretty early on that the way this works

84
00:05:59,000 --> 00:06:04,480
is you focus on the value and actually getting good at articulating where the value is from

85
00:06:04,480 --> 00:06:09,320
a business use case is really fundamental.

86
00:06:09,320 --> 00:06:14,280
And what we did was we effectively built out some cases around the customer space.

87
00:06:14,280 --> 00:06:20,480
We also focused on some work in our finance space and some work in the asset space.

88
00:06:20,480 --> 00:06:25,240
And all three of those paid pretty modest dividends pretty quickly.

89
00:06:25,240 --> 00:06:30,560
And that gave us a bit of a mandate and a bit of a momentum to start to grow.

90
00:06:30,560 --> 00:06:34,080
And I think maybe skipping forward a little bit, we went through a couple of years of sort

91
00:06:34,080 --> 00:06:35,160
of modest growth.

92
00:06:35,160 --> 00:06:40,840
But what were really changed was we hit on something that really resonated and we ran

93
00:06:40,840 --> 00:06:46,320
our first big project, which was focused on spare part inventory optimization.

94
00:06:46,320 --> 00:06:49,720
And we were able to deploy that quite quickly as a minimum viable product and it suddenly

95
00:06:49,720 --> 00:06:52,120
started to make millions of dollars.

96
00:06:52,120 --> 00:06:57,320
And it was at that point that the game shifted and suddenly this became a big thing and it

97
00:06:57,320 --> 00:07:01,520
became very much on the agenda of the executives and they got very interested in what we could

98
00:07:01,520 --> 00:07:03,320
do.

99
00:07:03,320 --> 00:07:06,440
And from there, really the team has been growing very, very rapidly.

100
00:07:06,440 --> 00:07:11,760
And I've been through various incarnations of positions, as you mentioned, to my current

101
00:07:11,760 --> 00:07:17,280
position where I'm now running about a team of about 130 people worldwide based in four

102
00:07:17,280 --> 00:07:22,240
global locations, combination of data scientists and data engineers.

103
00:07:22,240 --> 00:07:25,520
And we're running use cases right across the business.

104
00:07:25,520 --> 00:07:26,520
Interesting.

105
00:07:26,520 --> 00:07:29,040
I'm really looking forward to digging into some of those use cases.

106
00:07:29,040 --> 00:07:35,320
I didn't want to ask though, seeing this transition from advanced analytics, COE to data

107
00:07:35,320 --> 00:07:42,080
science, COE, tell me about the kind of background behind that change.

108
00:07:42,080 --> 00:07:50,160
Is it more significant than rebranding the role and the mission or does it have a significant

109
00:07:50,160 --> 00:07:52,200
meaning to the way you do business?

110
00:07:52,200 --> 00:07:57,880
Well, I think if you go back to the beginning, we had the idea really of putting statistical

111
00:07:57,880 --> 00:08:02,880
methods into software applications and deploying them to end users.

112
00:08:02,880 --> 00:08:06,400
That was if you like the initial mission that we came up with.

113
00:08:06,400 --> 00:08:11,440
But I think we always saw how this could evolve because even back in, we're talking back

114
00:08:11,440 --> 00:08:16,200
in 2013 now, we could see the early writing on the wall around the development of machine

115
00:08:16,200 --> 00:08:22,400
learning and also things like natural language processing and AI and the way in which this

116
00:08:22,400 --> 00:08:23,400
could evolve.

117
00:08:23,400 --> 00:08:27,800
And so we had that in mind, but we have focused very much on the simpler things and trying

118
00:08:27,800 --> 00:08:31,120
to deliver value with what we're building out then.

119
00:08:31,120 --> 00:08:35,000
I think it's been a pretty natural evolution, but of course, as you evolve, you need to

120
00:08:35,000 --> 00:08:37,080
describe what you do a bit better.

121
00:08:37,080 --> 00:08:41,040
And where it started off with, as I said, deploying those statistical methods, we're now

122
00:08:41,040 --> 00:08:43,520
deploying advanced machine learning at scale.

123
00:08:43,520 --> 00:08:45,840
And so we need a title that reflects that.

124
00:08:45,840 --> 00:08:50,000
So I think it's not that the mission or the vision has changed, but just we've managed

125
00:08:50,000 --> 00:08:52,920
to follow the roadmap and hence needed to rebound.

126
00:08:52,920 --> 00:08:56,360
One of the things that you mentioned in your background is this.

127
00:08:56,360 --> 00:09:00,280
Actually, there are a couple of things that I wanted to probe into.

128
00:09:00,280 --> 00:09:08,320
One is around this idea of kind of the interface between process and data and analytics and

129
00:09:08,320 --> 00:09:12,400
how you apply these techniques at that interface.

130
00:09:12,400 --> 00:09:22,640
But you also mentioned really needing to understand the value that these types of projects can

131
00:09:22,640 --> 00:09:25,080
bring to the table.

132
00:09:25,080 --> 00:09:30,560
Starting with that, what have you learned about kind of capturing the essence of the value

133
00:09:30,560 --> 00:09:33,840
proposition of these kinds of projects?

134
00:09:33,840 --> 00:09:36,000
So I think there's a couple of things I would say.

135
00:09:36,000 --> 00:09:37,920
So just linking to that process and data point.

136
00:09:37,920 --> 00:09:42,120
I find that people tend to look at the world through one or other lens.

137
00:09:42,120 --> 00:09:45,960
So business folks often tend to look at it through the lens of the process and forget

138
00:09:45,960 --> 00:09:47,800
about the data.

139
00:09:47,800 --> 00:09:52,240
And data practitioners often come at it from the data side and forget about the process.

140
00:09:52,240 --> 00:09:56,720
And the answer is you've got to understand both to really be successful.

141
00:09:56,720 --> 00:10:02,400
If I talk about that inventory use case, which I talked about as our big launching case,

142
00:10:02,400 --> 00:10:05,520
the key there was that interface of process and data.

143
00:10:05,520 --> 00:10:10,480
So what we understood was the data allowed us to develop certain recommendations around

144
00:10:10,480 --> 00:10:14,600
the stock levels that we were operating.

145
00:10:14,600 --> 00:10:17,960
And off the back of that, we could improve statistically the recommendations we were

146
00:10:17,960 --> 00:10:19,640
giving to the industry analyst.

147
00:10:19,640 --> 00:10:21,840
And that was relatively straightforward.

148
00:10:21,840 --> 00:10:28,640
But what we then had to do was work really closely with the experts in the business through,

149
00:10:28,640 --> 00:10:31,640
in this case, the materials management center of excellence internally.

150
00:10:31,640 --> 00:10:36,720
So the team that looked after materials management as a discipline and try and work with them

151
00:10:36,720 --> 00:10:39,400
to say, how are we going to fit a tool into your business process?

152
00:10:39,400 --> 00:10:43,760
And the reason it was successful was because we made a tool which made it really, really

153
00:10:43,760 --> 00:10:47,320
easy for the inventory analyst to do their job.

154
00:10:47,320 --> 00:10:49,480
And ultimately, that's why it was so successful.

155
00:10:49,480 --> 00:10:52,040
So I think that's one element of how you get the value.

156
00:10:52,040 --> 00:10:56,600
I think the other elements of getting to the value is understanding the friction.

157
00:10:56,600 --> 00:11:00,720
So again, if I use this as an example, what we understood was the inventory analyst could

158
00:11:00,720 --> 00:11:05,800
probably get to the same recommendations that the algorithm was making or close to, but

159
00:11:05,800 --> 00:11:07,920
it would take them several weeks.

160
00:11:07,920 --> 00:11:11,640
And that's not scalable, and it's not even doable because what that means is it doesn't

161
00:11:11,640 --> 00:11:13,120
get done.

162
00:11:13,120 --> 00:11:17,320
So what we quickly figured out was that actually understanding that friction point, which

163
00:11:17,320 --> 00:11:22,880
was this saves the inventory analyst time, was key to getting the value of which also leads

164
00:11:22,880 --> 00:11:27,440
to better decision making and off the back of that bottom line impact.

165
00:11:27,440 --> 00:11:30,720
So it's that friction understanding that's been really key to our journey.

166
00:11:30,720 --> 00:11:35,240
I think the other thing is, and maybe one of the other big learnings and learn from some

167
00:11:35,240 --> 00:11:41,840
of my failures here as well, often the business will ask questions which are thinly veiled.

168
00:11:41,840 --> 00:11:45,840
I have lots of data looking for a problem problems.

169
00:11:45,840 --> 00:11:51,920
And that's the worst type of definition because ultimately more data is not better.

170
00:11:51,920 --> 00:11:56,520
What's better is to have better insight, and that typically means small data.

171
00:11:56,520 --> 00:12:01,600
And so the challenge of any analytics project is taking big data into small insights, which

172
00:12:01,600 --> 00:12:04,200
allows someone to make a better decision.

173
00:12:04,200 --> 00:12:08,360
You mentioned that better insights typically mean small data.

174
00:12:08,360 --> 00:12:09,360
Can you elaborate on that?

175
00:12:09,360 --> 00:12:15,840
I think that is counterintuitive to the way we think about a lot of these problems nowadays.

176
00:12:15,840 --> 00:12:16,840
Yeah, I think so.

177
00:12:16,840 --> 00:12:20,560
I mean, it's not saying that you don't use a lot of data in coming to the insights,

178
00:12:20,560 --> 00:12:26,320
but ultimately, if you look at, let's take an operator in the North Sea, for example,

179
00:12:26,320 --> 00:12:33,200
we're currently asking them to deal with probably 10,000 data points on any given day.

180
00:12:33,200 --> 00:12:38,880
So they should be looking at the incoming variables from 10,000 different sensor feeds about

181
00:12:38,880 --> 00:12:40,480
their plans.

182
00:12:40,480 --> 00:12:42,920
No one can process that amount of data.

183
00:12:42,920 --> 00:12:47,560
And ultimately, you end up with just information overload, which means you shut down or you switch

184
00:12:47,560 --> 00:12:51,600
off or you manage on intuition or gut feel.

185
00:12:51,600 --> 00:12:56,600
And the challenge of data science is, can I take all of that incoming data that I have

186
00:12:56,600 --> 00:13:00,920
and turn it into the three things that that operator needs to look at and make sure that

187
00:13:00,920 --> 00:13:04,760
they really pay attention to those three things because that's what we're comfortable

188
00:13:04,760 --> 00:13:07,080
with dealing with as human beings.

189
00:13:07,080 --> 00:13:12,360
So a lot of my team and the thinking that we try to instill in people is, look, you've

190
00:13:12,360 --> 00:13:14,680
got to make it easy for your user.

191
00:13:14,680 --> 00:13:19,720
We like our iPhones because the app is typically only giving you one or two or three pieces of

192
00:13:19,720 --> 00:13:22,960
information, that's what a well designed app does.

193
00:13:22,960 --> 00:13:26,080
And you might deal with a lot of apps in a day, but actually each one is pretty targeted

194
00:13:26,080 --> 00:13:28,960
in the way that it surfaces information to you.

195
00:13:28,960 --> 00:13:32,560
And that's really the same sort of thinking we try and bring into the design of the things

196
00:13:32,560 --> 00:13:35,240
that we build for our business users.

197
00:13:35,240 --> 00:13:40,800
So I recently had an opportunity to hear one of your colleagues talk a little bit about

198
00:13:40,800 --> 00:13:47,560
the various use cases of machine learning at Shell at a conference.

199
00:13:47,560 --> 00:13:52,440
And I'd love for you to kind of run through that list.

200
00:13:52,440 --> 00:13:57,480
I mean, there were, you've got a ton of things going on in this space.

201
00:13:57,480 --> 00:13:59,000
Can you give us a taste?

202
00:13:59,000 --> 00:14:00,320
Yeah, of course.

203
00:14:00,320 --> 00:14:07,600
So we're looking at the application of machine learning into areas in the subsurface,

204
00:14:07,600 --> 00:14:13,160
for example, like well drilling where we're trying to automate the way in which we do

205
00:14:13,160 --> 00:14:18,920
geo-steering using machine learning, we're also doing work in production looking at predictive

206
00:14:18,920 --> 00:14:19,920
maintenance.

207
00:14:19,920 --> 00:14:23,320
So in other words, how can we predict failure on piece of equipment?

208
00:14:23,320 --> 00:14:27,680
That's everything from valves to compressors to heat exchangers.

209
00:14:27,680 --> 00:14:31,000
And going back to the example I gave on the operator, trying to give our operators really

210
00:14:31,000 --> 00:14:33,840
meaningful insight around the areas they need to focus on.

211
00:14:33,840 --> 00:14:36,520
We're also looking at optimization of those assets.

212
00:14:36,520 --> 00:14:41,680
So how can we use machine learning and other techniques to optimize the throughput of our

213
00:14:41,680 --> 00:14:45,600
manufacturing equipment, our production equipment?

214
00:14:45,600 --> 00:14:51,880
We're working with trading in a number of areas, trying to improve the way in which we manage

215
00:14:51,880 --> 00:14:57,640
our trading portfolios, the way we manage risk, the way in which we also make bets and take

216
00:14:57,640 --> 00:15:00,360
positions in the market.

217
00:15:00,360 --> 00:15:07,320
We are looking at optimizing our lubricants in the way that we blend our lubricants, effectively

218
00:15:07,320 --> 00:15:13,120
trying to leverage larger data sets to understand how we can make our products more effectively

219
00:15:13,120 --> 00:15:14,840
or more efficiently.

220
00:15:14,840 --> 00:15:20,600
We're working in retail, trying to develop new insights for our customers, but also trying

221
00:15:20,600 --> 00:15:23,920
to make our sites safer by using things like machine vision.

222
00:15:23,920 --> 00:15:29,520
And actually machine vision is an area that we're looking at far more broadly because leveraging

223
00:15:29,520 --> 00:15:34,680
video footage across our very physical value chain is a huge opportunity.

224
00:15:34,680 --> 00:15:39,680
And then we're also working in the new energy space where we're starting to try to develop

225
00:15:39,680 --> 00:15:48,040
algorithms to charge cars more smartly and also save our customers money in the process.

226
00:15:48,040 --> 00:15:53,080
So that's just a few examples that I could go on for a long time.

227
00:15:53,080 --> 00:16:01,000
How does your organization support such a broad portfolio of application areas?

228
00:16:01,000 --> 00:16:10,640
Are you kind of embedded into the different business units or business processes or do

229
00:16:10,640 --> 00:16:13,560
you operate in a more centralized way?

230
00:16:13,560 --> 00:16:15,720
So I think it's a combination.

231
00:16:15,720 --> 00:16:20,320
So the way I describe my team is we try and provide a technical backbone to these projects

232
00:16:20,320 --> 00:16:22,720
to make sure that we do them consistently.

233
00:16:22,720 --> 00:16:30,040
We operate with common standards and we deploy them to a high level of delivery.

234
00:16:30,040 --> 00:16:34,840
So we're trying to act as a true center of excellence if you will.

235
00:16:34,840 --> 00:16:38,600
We're often bringing in resources, I would say almost always bringing in resources from

236
00:16:38,600 --> 00:16:40,720
other parts of the organization.

237
00:16:40,720 --> 00:16:44,520
We partner very closely with our business service centers because they have some great

238
00:16:44,520 --> 00:16:46,360
data scientists there.

239
00:16:46,360 --> 00:16:51,560
We also partner closely with our IT colleagues because we need them to help us operationalize

240
00:16:51,560 --> 00:16:53,240
the things that we're building.

241
00:16:53,240 --> 00:16:57,440
And of course we want business people embedded in these projects because a lot of this

242
00:16:57,440 --> 00:17:01,400
doesn't work unless you're very close to the user and the person with the problem who

243
00:17:01,400 --> 00:17:04,000
really understands the case that you're trying to develop.

244
00:17:04,000 --> 00:17:09,440
So our most successful stories are those where all of those ingredients are there.

245
00:17:09,440 --> 00:17:13,760
So I think it's the best way to describe it is we're involved in a lot of these projects.

246
00:17:13,760 --> 00:17:19,920
We're providing technical assurance, expertise, we're often hands-on in terms of delivery,

247
00:17:19,920 --> 00:17:21,320
but we're not doing it on our own.

248
00:17:21,320 --> 00:17:26,000
We bring together cross disciplinary working teams to deploy the outcome.

249
00:17:26,000 --> 00:17:32,840
You mentioned operationalization as well as technical standards to what degree have you

250
00:17:32,840 --> 00:17:42,040
established a standard set of tools, practices or a concrete platform upon which you build

251
00:17:42,040 --> 00:17:43,680
these types of projects?

252
00:17:43,680 --> 00:17:45,400
That's a great question.

253
00:17:45,400 --> 00:17:47,880
So I think I'll answer that in two ways.

254
00:17:47,880 --> 00:17:51,040
We certainly have established tools and best practices.

255
00:17:51,040 --> 00:17:55,920
So I talk about my center of excellence having three core functions.

256
00:17:55,920 --> 00:17:58,680
Number one, we develop the underlying platform.

257
00:17:58,680 --> 00:18:00,920
We work with our IT colleagues to do that.

258
00:18:00,920 --> 00:18:07,640
The second thing is that we develop a series of use cases on top of that platform to demonstrate

259
00:18:07,640 --> 00:18:12,720
the value of it, but we also democratize that platform to allow others to use the platform

260
00:18:12,720 --> 00:18:13,720
as well.

261
00:18:13,720 --> 00:18:18,840
And we run a network to share best practice with about 2,000 people across Shell around

262
00:18:18,840 --> 00:18:19,840
how we do this.

263
00:18:19,840 --> 00:18:23,320
So that's the operating model, if you will.

264
00:18:23,320 --> 00:18:27,120
If you talk about the platform specifically, it's always evolving.

265
00:18:27,120 --> 00:18:34,240
So we built the first platform in about 2014, early 2015, I guess.

266
00:18:34,240 --> 00:18:38,120
And of course, the technology now has moved on significantly since then.

267
00:18:38,120 --> 00:18:42,600
And so we're in the process of working through some of that and refreshing some of our tools

268
00:18:42,600 --> 00:18:44,200
and our ways of working.

269
00:18:44,200 --> 00:18:47,120
But we've had a number of core components that have been very successful and will be with

270
00:18:47,120 --> 00:18:48,520
us for a long time to come.

271
00:18:48,520 --> 00:18:55,480
Things like Altrix and Databricks have been the standards as well as R and Python.

272
00:18:55,480 --> 00:18:58,840
And we've done a lot of work in those tools.

273
00:18:58,840 --> 00:19:03,120
Increasing though, we're also looking at others, things like C3 IoT.

274
00:19:03,120 --> 00:19:05,360
We do a lot of work with math works as well.

275
00:19:05,360 --> 00:19:09,880
So it's very much, we've brought together a best of breed toolset.

276
00:19:09,880 --> 00:19:15,200
And of course, we're really excited as you may have heard around Microsoft and working

277
00:19:15,200 --> 00:19:19,640
very closely with Microsoft now to move things into more of a paths set up in the public

278
00:19:19,640 --> 00:19:20,640
cloud.

279
00:19:20,640 --> 00:19:23,520
And so that's very much the direction that we're heading in.

280
00:19:23,520 --> 00:19:30,280
And a lot of the use cases that you support are, you know, what we've come to start calling

281
00:19:30,280 --> 00:19:32,280
edge applications.

282
00:19:32,280 --> 00:19:40,960
So can you talk a little bit about how the IoT and edge use cases impact the requirements

283
00:19:40,960 --> 00:19:43,920
that you have on the underlying platform?

284
00:19:43,920 --> 00:19:44,920
Yeah, of course.

285
00:19:44,920 --> 00:19:47,480
So I think a couple of things.

286
00:19:47,480 --> 00:19:52,600
I think in the strictest sense, Shell has been an IoT player for a very, very long time.

287
00:19:52,600 --> 00:19:57,720
And we've had a consolidated sensor infrastructure for many years.

288
00:19:57,720 --> 00:20:02,440
It's based on a technological OSI, so PIE and we effectively aggregate all of our sensor

289
00:20:02,440 --> 00:20:04,840
data into centralized repositories.

290
00:20:04,840 --> 00:20:08,320
And that's been a huge enabler for us because of course, that means you don't have to deploy

291
00:20:08,320 --> 00:20:11,480
all the sensors and you don't have to deal with some of the IoT problems.

292
00:20:11,480 --> 00:20:14,960
We just pick up the brilliant work that others have done to aggregate all that data for

293
00:20:14,960 --> 00:20:15,960
us.

294
00:20:15,960 --> 00:20:19,800
So that's been a big play and the challenge there has been making that available in the

295
00:20:19,800 --> 00:20:23,240
cloud and starting to leverage machine learning on top of that.

296
00:20:23,240 --> 00:20:26,200
And that's been a really exciting journey.

297
00:20:26,200 --> 00:20:32,000
But increasing needs as we deploy new solutions, we also need to deploy things to the edge.

298
00:20:32,000 --> 00:20:33,960
And in particular, deploying machine learning.

299
00:20:33,960 --> 00:20:38,960
So the best example is some of the work we've been doing in retail recently, where we're

300
00:20:38,960 --> 00:20:44,520
now deploying cameras into retail sites in Singapore and in Thailand.

301
00:20:44,520 --> 00:20:49,040
And into those cameras, we actually, because we've got six cameras generating about 200

302
00:20:49,040 --> 00:20:53,680
megabytes per second in data volumes, we need to be able to filter that before we pass

303
00:20:53,680 --> 00:20:57,040
it into the cloud, because otherwise it just becomes unmanageable.

304
00:20:57,040 --> 00:21:00,960
So what we're doing is we're using effectively edge deployment.

305
00:21:00,960 --> 00:21:07,040
And we're allowing the containerized cloud based environment to push machine learning

306
00:21:07,040 --> 00:21:12,560
into the edge to act as a filter to allow us to only retrieve the elements that we need

307
00:21:12,560 --> 00:21:16,920
into the cloud for type processing in a scaled environment like Spark.

308
00:21:16,920 --> 00:21:19,920
So that's pretty, that's pretty cutting edge and that's pretty exciting.

309
00:21:19,920 --> 00:21:23,080
And that's one of the areas that I'm really enjoying working in.

310
00:21:23,080 --> 00:21:26,280
The other example, of course, is some of the new devices that are coming online, so things

311
00:21:26,280 --> 00:21:27,280
like charge posts.

312
00:21:27,280 --> 00:21:32,200
So we're doing a lot of work around how can we deploy algorithms, which have full connectivity

313
00:21:32,200 --> 00:21:37,920
into charging posts, so we can optimize the way in which we provide electricity to electric

314
00:21:37,920 --> 00:21:39,400
vehicles.

315
00:21:39,400 --> 00:21:45,960
The retail application you mentioned was one that was highlighted at the Ignite conference.

316
00:21:45,960 --> 00:21:48,200
Can you talk about that in more detail?

317
00:21:48,200 --> 00:21:49,200
What are its goals?

318
00:21:49,200 --> 00:21:50,200
Of course.

319
00:21:50,200 --> 00:21:53,640
So I mean, our retail businesses is huge.

320
00:21:53,640 --> 00:21:57,440
We're the largest single branded retailer in the world.

321
00:21:57,440 --> 00:22:04,080
We operate in about 70 different markets, we have about 44,000 sites and we deal with

322
00:22:04,080 --> 00:22:07,080
about 30 million customers every day.

323
00:22:07,080 --> 00:22:08,800
That's an incredible scale.

324
00:22:08,800 --> 00:22:13,320
And of course, in that business, we want to make sure that our customers are safe and

325
00:22:13,320 --> 00:22:16,360
secure and that we protect them from risks.

326
00:22:16,360 --> 00:22:20,600
And as you will know, I mean, having hydrocarbons there has an elements of risk to it.

327
00:22:20,600 --> 00:22:26,040
And so we need to make sure that we're able to intervene in situations like smoking,

328
00:22:26,040 --> 00:22:29,160
which is remarkably still an occurrence on some of these sites.

329
00:22:29,160 --> 00:22:33,720
As well as looking at other risks like people speeding or going in the wrong direction,

330
00:22:33,720 --> 00:22:38,520
which may have an impact on pedestrians going into the store or situations where we may

331
00:22:38,520 --> 00:22:44,560
have robberies having a bid, we want to be able to make sure we can detect and ideally detect

332
00:22:44,560 --> 00:22:49,320
the symptoms of those things about to happen so we can make an intervention.

333
00:22:49,320 --> 00:22:53,600
And so what we've done is we've developed a machine learning system that's looking for

334
00:22:53,600 --> 00:22:58,640
some of those well-known symptoms that are about to cause issues.

335
00:22:58,640 --> 00:23:03,200
And then providing those as alerts back to the service champion.

336
00:23:03,200 --> 00:23:07,920
So that's the person who looks after the customer in the store.

337
00:23:07,920 --> 00:23:10,000
And we're currently in a pilot phase with that.

338
00:23:10,000 --> 00:23:14,640
We're testing it out in Singapore and in Thailand, as I mentioned.

339
00:23:14,640 --> 00:23:15,640
It's going pretty well.

340
00:23:15,640 --> 00:23:20,440
It's early days, but it's a really exciting area for us because there's so many use cases

341
00:23:20,440 --> 00:23:24,960
we can think of that can help improve our retail business, but way beyond that into our

342
00:23:24,960 --> 00:23:29,240
production business and into our refining business and elsewhere.

343
00:23:29,240 --> 00:23:33,840
Because at the end of the day, what we've built is a standard platform that runs in the

344
00:23:33,840 --> 00:23:40,600
public cloud that allows us to operate all of these cases at scale on a common infrastructure.

345
00:23:40,600 --> 00:23:47,080
And so this particular application, as you mentioned, is based on capturing video.

346
00:23:47,080 --> 00:23:54,120
You mentioned that the video that's being pushed to the centralized processing in the cloud

347
00:23:54,120 --> 00:23:56,440
is reduced bandwidth.

348
00:23:56,440 --> 00:24:02,440
Are you also doing inference at the edge or are you, tell us a little bit more about how

349
00:24:02,440 --> 00:24:04,240
that's what's happening there?

350
00:24:04,240 --> 00:24:05,240
Yeah, of course.

351
00:24:05,240 --> 00:24:08,400
So I mean, if you think about it, what we have is about six different cameras that are

352
00:24:08,400 --> 00:24:13,200
all pushing footage into an edge device.

353
00:24:13,200 --> 00:24:19,640
We've then deployed a thin machine learning model, so a thin, deep neural network, if

354
00:24:19,640 --> 00:24:25,480
you will, to that edge device based on TensorFlow, but it's kind of a yolo type model.

355
00:24:25,480 --> 00:24:30,440
What it's doing is fast and loose inference, pulling out frames of interest and passing

356
00:24:30,440 --> 00:24:35,640
those frames into the cloud, we're then loading them into a blob store environment, but

357
00:24:35,640 --> 00:24:39,240
then automatically bringing them up into the memory of the spark cluster and the spark

358
00:24:39,240 --> 00:24:45,840
cluster is then using effectively a Kafka stream, passing those through and identifying

359
00:24:45,840 --> 00:24:51,720
potentially interesting events that we want to notify the service champion about.

360
00:24:51,720 --> 00:24:58,040
Those events are then pushed into a database which provides an alert back then into the

361
00:24:58,040 --> 00:25:01,200
service champion in a dashboard which runs on an iPad.

362
00:25:01,200 --> 00:25:05,600
So that's a very brief overview of the architecture, but the core elements are inference at

363
00:25:05,600 --> 00:25:10,400
the edge and tighter inference in the cloud to reduce false positives.

364
00:25:10,400 --> 00:25:16,680
And then Kafka acting as the bus to pass those alerts through into the service champion

365
00:25:16,680 --> 00:25:18,520
in the form of a mobile device.

366
00:25:18,520 --> 00:25:26,920
And so the inference that's happening in the cloud is based on a more robust model presumably.

367
00:25:26,920 --> 00:25:31,120
Yeah, it's deeper, of course, because what we've got is a smaller data volume and you

368
00:25:31,120 --> 00:25:37,640
can do tighter inference, so you're using effectively deeper neural nets to make more

369
00:25:37,640 --> 00:25:40,880
robust recommendations back to the service champion.

370
00:25:40,880 --> 00:25:49,960
And are you in any way federating the training or the models, you know, pushing the knowledge

371
00:25:49,960 --> 00:25:55,880
in the centralized models out to the edge, because periodically or training them in concert

372
00:25:55,880 --> 00:25:58,680
with one another, are you doing anything in that space?

373
00:25:58,680 --> 00:26:04,440
So we're continually retraining based on new data and feedback from the service champion

374
00:26:04,440 --> 00:26:07,520
because both of those two things are important in refining the models.

375
00:26:07,520 --> 00:26:12,160
We're also working with offline training data to also try new things to try and improve

376
00:26:12,160 --> 00:26:17,040
the models as well and new ideas based on the new footage that we now have.

377
00:26:17,040 --> 00:26:20,920
I think the, I mean, I'm sure you'll hear this from a lot of people, but training machine

378
00:26:20,920 --> 00:26:23,640
learning is obviously it's a bit of trial and error.

379
00:26:23,640 --> 00:26:28,120
You've got to try a bunch of things and iterate quickly and that's very much the phase that

380
00:26:28,120 --> 00:26:31,040
we're in now to try and make our models more robust.

381
00:26:31,040 --> 00:26:34,840
The beauty is that we have these things fully containerized though, and as they improve,

382
00:26:34,840 --> 00:26:40,560
we can pass those down to the edge to improve the way in which they perform.

383
00:26:40,560 --> 00:26:45,080
On that note, how do you do experiment management?

384
00:26:45,080 --> 00:26:49,040
Well, it's a great question.

385
00:26:49,040 --> 00:26:50,440
It's a tough one.

386
00:26:50,440 --> 00:26:54,120
Maybe the best way to describe it is what we're trying to do across the department.

387
00:26:54,120 --> 00:26:58,640
I mean, of course, we have design of experiments training that we roll out for a lot of our

388
00:26:58,640 --> 00:27:00,720
data scientists.

389
00:27:00,720 --> 00:27:05,840
I think the other thing is that we have a set up around quality where we put in place

390
00:27:05,840 --> 00:27:13,200
a bunch of peer reviews to try to make sure that we're doing things in a sensible way across

391
00:27:13,200 --> 00:27:15,080
the team.

392
00:27:15,080 --> 00:27:20,520
I think though as well, and this is maybe a bit of a non-answer that the challenge with

393
00:27:20,520 --> 00:27:23,360
this is, some of this is quite new for us.

394
00:27:23,360 --> 00:27:28,560
And so in some ways, as I said, it's a bit of trial and error as to what works, particularly

395
00:27:28,560 --> 00:27:31,720
given the architecture that we're using is quite new.

396
00:27:31,720 --> 00:27:34,840
So we're trying to learn a lot from the way that others are handling this.

397
00:27:34,840 --> 00:27:38,920
We're learning a lot from other organizations who have perhaps ahead of us, some of the

398
00:27:38,920 --> 00:27:44,040
tech giants, for example, but I think it would be unfair to say we've got this right.

399
00:27:44,040 --> 00:27:46,240
We're still very much learning.

400
00:27:46,240 --> 00:27:53,920
One other thing I'm curious about is the degree to which you've instilled formalized processes

401
00:27:53,920 --> 00:28:03,040
around screening for a bias in data sets or results in, for example, in this application

402
00:28:03,040 --> 00:28:11,240
that's very much consumer facing and based on video, which is we've seen recent examples

403
00:28:11,240 --> 00:28:18,680
of bias creeping into the use of object detection, image detection, facial recognition, things

404
00:28:18,680 --> 00:28:20,160
like that.

405
00:28:20,160 --> 00:28:29,200
How mature would you say your data science practices are in terms of understanding and

406
00:28:29,200 --> 00:28:33,440
building processes in place to protect against that kind of bias, and where do you see that

407
00:28:33,440 --> 00:28:34,440
going?

408
00:28:34,440 --> 00:28:37,560
Yeah, it's a really good question.

409
00:28:37,560 --> 00:28:45,320
I'll answer that in two ways, I think we've merged in my group, the statistics group and

410
00:28:45,320 --> 00:28:50,680
the data science group, and I think that has really helped in the way we think about

411
00:28:50,680 --> 00:28:56,120
quality of models, because as you can probably appreciate, the statistics group have a much

412
00:28:56,120 --> 00:29:02,280
deeper understanding, if you will, of the potential for bias to cause issues.

413
00:29:02,280 --> 00:29:06,840
So we've had a stats group since the 1970s, it's a very mature group, and I think they've

414
00:29:06,840 --> 00:29:12,800
really helped in terms of bringing the challenge into some of the data scientists who are perhaps

415
00:29:12,800 --> 00:29:17,240
more focused on some of the more emerging technologies and have a deeper knowledge there.

416
00:29:17,240 --> 00:29:20,480
So I think it's that cross-pollination between different disciplines that's helping us

417
00:29:20,480 --> 00:29:22,960
in the way that we develop these models.

418
00:29:22,960 --> 00:29:26,480
And we're trying to encourage that across the team, and in particular, I mentioned the

419
00:29:26,480 --> 00:29:29,200
quality initiative that we're starting to roll out.

420
00:29:29,200 --> 00:29:33,720
We're trying to make sure that we have peer reviews to look at this and look at things

421
00:29:33,720 --> 00:29:37,000
like systematic bias in the way that we're developing our models.

422
00:29:37,000 --> 00:29:40,800
I think the other thing that's really important that we're talking a lot about at the moment

423
00:29:40,800 --> 00:29:45,960
is estimating uncertainty and distribution at the source of the data sets that are coming

424
00:29:45,960 --> 00:29:51,440
in, and really trying to understand that so you're not building in systematic bias through

425
00:29:51,440 --> 00:29:55,520
basing your models on a small set of observations.

426
00:29:55,520 --> 00:30:00,560
And I think in particular, one area that I think has a lot of promise here is using synthetic

427
00:30:00,560 --> 00:30:02,920
data to train the algorithms.

428
00:30:02,920 --> 00:30:06,760
We're not there yet with that, but I think that's an area that we're really interested

429
00:30:06,760 --> 00:30:10,840
in because we think it has strong potential to remove some of those biases.

430
00:30:10,840 --> 00:30:17,080
Is there a particular use case for which you see that as being most promising?

431
00:30:17,080 --> 00:30:21,080
Well, I think it's more of a... I mean, it's very early days with this, right?

432
00:30:21,080 --> 00:30:26,120
And we really don't know if this is going to work, by the way.

433
00:30:26,120 --> 00:30:32,440
Because the question is, can you accurately generate enough realistic data to be

434
00:30:32,440 --> 00:30:34,440
representative?

435
00:30:34,440 --> 00:30:39,960
I think what we're excited about is, if you look at the occasional event from a machine

436
00:30:39,960 --> 00:30:45,600
vision perspective, it's very hard to get a representative set of footage around that,

437
00:30:45,600 --> 00:30:46,600
right?

438
00:30:46,600 --> 00:30:52,840
So you end up very easily overfitting, whereas I think what's quite interesting is, if you

439
00:30:52,840 --> 00:31:01,440
think about synthetic data, you can potentially generate a vast quantity of data in a VR world

440
00:31:01,440 --> 00:31:07,120
that gives a real indication of potentially all the scenarios in which this could be

441
00:31:07,120 --> 00:31:11,520
observed and creates a much more representative data set to do a first-pass training on your

442
00:31:11,520 --> 00:31:12,520
model.

443
00:31:12,520 --> 00:31:16,000
Now, we still don't think that synthetic data will take us to real world in one step.

444
00:31:16,000 --> 00:31:19,760
It's going to be a two-step process, but if we can build that into the way we think

445
00:31:19,760 --> 00:31:22,440
about machine vision, it could be a real game changer.

446
00:31:22,440 --> 00:31:23,440
We think.

447
00:31:23,440 --> 00:31:25,440
But like I said, I can be wrong on this one.

448
00:31:25,440 --> 00:31:33,560
I think you're right, I agree. I wonder what the timeframe is for all of the pieces to

449
00:31:33,560 --> 00:31:34,560
come together.

450
00:31:34,560 --> 00:31:41,840
There's been some interesting results in combining synthetic data with real world data and

451
00:31:41,840 --> 00:31:47,120
applying techniques like domain transfer, but a lot of that stuff is really bleeding

452
00:31:47,120 --> 00:31:48,120
it.

453
00:31:48,120 --> 00:31:54,280
And I'd love to hear if there are any tools or papers or things like that that are top

454
00:31:54,280 --> 00:31:58,040
of mind for you in having looked at this.

455
00:31:58,040 --> 00:32:04,120
Yeah, I mean, we're like I said, we're really early stages, and we're kind of going

456
00:32:04,120 --> 00:32:10,240
in alone because we haven't found anything that's bang on point yet for not the use cases

457
00:32:10,240 --> 00:32:12,160
that we are interested in.

458
00:32:12,160 --> 00:32:15,120
And so I think this is actually an area where we think we might be able to publish some

459
00:32:15,120 --> 00:32:20,960
useful material that's going to drive some of the discussion in this space.

460
00:32:20,960 --> 00:32:22,960
So watch this space is what I would say.

461
00:32:22,960 --> 00:32:29,080
So we talked a little bit about the experiment management side of things.

462
00:32:29,080 --> 00:32:37,480
How do you approach model management and deploying models out to production and managing their

463
00:32:37,480 --> 00:32:40,040
performance over time?

464
00:32:40,040 --> 00:32:43,640
What kind of tooling have you built up around that and processes?

465
00:32:43,640 --> 00:32:46,280
That is a great question as well.

466
00:32:46,280 --> 00:32:48,440
So this is a real headache.

467
00:32:48,440 --> 00:32:51,280
So let me just be completely honest with you.

468
00:32:51,280 --> 00:32:56,560
Look, I can answer it with a simple answer, which is, you know, we containerize our models,

469
00:32:56,560 --> 00:33:01,480
we use things like Azure Container Services and Kubernetes to deploy them.

470
00:33:01,480 --> 00:33:04,400
We have, we embed metrics so we can manage it.

471
00:33:04,400 --> 00:33:09,560
We're doing some work looking at things like ML flow in Spark to help with some of this.

472
00:33:09,560 --> 00:33:13,880
However, I'll be completely honest and say, we're actually looking at, we're working

473
00:33:13,880 --> 00:33:16,240
with C3 IoT to try and crack this problem.

474
00:33:16,240 --> 00:33:22,560
And I'll explain in the scenario that we're working through, we have thousands of valves

475
00:33:22,560 --> 00:33:28,240
across our business, literally thousands of them, and we want to be able to run machine

476
00:33:28,240 --> 00:33:30,120
learning models for every single valve.

477
00:33:30,120 --> 00:33:31,800
Now every single valve is slightly different.

478
00:33:31,800 --> 00:33:32,800
The flow is different.

479
00:33:32,800 --> 00:33:34,840
The temperature, the pressure is different, right?

480
00:33:34,840 --> 00:33:38,640
So you basically need a model per valve, but you don't want to manually manage that because

481
00:33:38,640 --> 00:33:40,640
it's just unmanageable.

482
00:33:40,640 --> 00:33:48,560
So you need drift management, you need the ability to automatically transfer between different

483
00:33:48,560 --> 00:33:49,880
types of models.

484
00:33:49,880 --> 00:33:54,560
You need human override on those valves to actually replace the model with one that you think

485
00:33:54,560 --> 00:33:56,600
is going to perform better.

486
00:33:56,600 --> 00:34:01,240
You need to be able to retrain those models on a regular basis based on new incoming data

487
00:34:01,240 --> 00:34:02,240
sets.

488
00:34:02,240 --> 00:34:07,040
And you need methods to actually manage the overall performance of the system in a simple

489
00:34:07,040 --> 00:34:11,920
way that gives an end user the ability to look across the entire set of valves.

490
00:34:11,920 --> 00:34:16,160
So if you're giving an idea on a refinery, you might have 10,000 of these things.

491
00:34:16,160 --> 00:34:22,000
So that is a real world problem, it's a great real world problem, it's a really exciting

492
00:34:22,000 --> 00:34:23,000
one.

493
00:34:23,000 --> 00:34:24,080
But it's also a real challenge.

494
00:34:24,080 --> 00:34:31,000
And so like I said, we've gone and we've worked with C3 IoT to look at, can we leverage

495
00:34:31,000 --> 00:34:37,000
their platform and their type system to help us to manage that level of machine learning

496
00:34:37,000 --> 00:34:42,440
deployed into an asset where we have to be able to support a user interacting with that

497
00:34:42,440 --> 00:34:43,440
every day?

498
00:34:43,440 --> 00:34:44,440
Right.

499
00:34:44,440 --> 00:34:53,280
Adding the edge components to the model management challenge makes it a lot more complex.

500
00:34:53,280 --> 00:34:57,480
And you're relative to serving up models to some centralized website or via centralized

501
00:34:57,480 --> 00:34:58,480
website.

502
00:34:58,480 --> 00:35:01,960
I can definitely see where the complexity comes in there.

503
00:35:01,960 --> 00:35:09,160
We mentioned the valves and building individual models for these valves.

504
00:35:09,160 --> 00:35:13,800
I'm assuming that's kind of this digital twin type of use case.

505
00:35:13,800 --> 00:35:16,520
How do you end up using those digital twins?

506
00:35:16,520 --> 00:35:18,000
And do you like that terminology?

507
00:35:18,000 --> 00:35:21,520
Do you use that internally or not really?

508
00:35:21,520 --> 00:35:22,600
Yeah, we do.

509
00:35:22,600 --> 00:35:26,600
I think the problem with the terminology is that everyone means something different by

510
00:35:26,600 --> 00:35:27,600
it.

511
00:35:27,600 --> 00:35:34,600
And it's everything from a simulated set of the physics of the operations of the system

512
00:35:34,600 --> 00:35:41,240
through to a 3D model based on CAD drawings and all the variations in between.

513
00:35:41,240 --> 00:35:42,960
So you have to be a bit careful with it.

514
00:35:42,960 --> 00:35:47,040
And we're trying to standardize on a definition internally so that we can say this is what

515
00:35:47,040 --> 00:35:48,040
we mean.

516
00:35:48,040 --> 00:35:49,960
And then it has these attributes.

517
00:35:49,960 --> 00:35:53,200
That's the current discussion that we're going through.

518
00:35:53,200 --> 00:35:56,160
So interested if anyone else has had a similar problem.

519
00:35:56,160 --> 00:36:00,800
But what we're trying to do really here is it is kind of a digital twin setup.

520
00:36:00,800 --> 00:36:05,120
We're taking a hierarchy of the equipment that we have on the site and then we're effectively

521
00:36:05,120 --> 00:36:09,760
tagging the things we want to monitor with a model against that hierarchy.

522
00:36:09,760 --> 00:36:15,200
And then we're able to manage that basis the way in which the asset is set up.

523
00:36:15,200 --> 00:36:18,320
But it tends to be specific pieces of equipment.

524
00:36:18,320 --> 00:36:22,280
And of course, within the context of that, we're taking the historic data feeds about that

525
00:36:22,280 --> 00:36:23,800
piece of the asset.

526
00:36:23,800 --> 00:36:28,960
And then we're running an algorithm, typically a machine learning model, not always a deep

527
00:36:28,960 --> 00:36:34,440
learning model, by the way, against that particular piece of equipment in order to provide

528
00:36:34,440 --> 00:36:36,400
results back to the user.

529
00:36:36,400 --> 00:36:43,920
Do you ultimately end up with for a complex piece of equipment as you're trying to make

530
00:36:43,920 --> 00:36:48,640
predictions against the performance of that complex piece of equipment and ensemble

531
00:36:48,640 --> 00:36:55,800
of thousands or tens of thousands of submodels representing the individual parts?

532
00:36:55,800 --> 00:37:01,200
And have you built a framework that allows you to do that kind of thing repeatedly or

533
00:37:01,200 --> 00:37:02,600
are we not there yet?

534
00:37:02,600 --> 00:37:05,960
Well, so you know what's really interesting is actually we're going the other way right

535
00:37:05,960 --> 00:37:06,960
now.

536
00:37:06,960 --> 00:37:07,960
Really?

537
00:37:07,960 --> 00:37:14,440
So one of the things that we found is the difference in performance between the submodels that

538
00:37:14,440 --> 00:37:20,160
we're building out in the complex system versus basically having a master model that cuts

539
00:37:20,160 --> 00:37:23,360
across all the pieces of equipment is not differentiating.

540
00:37:23,360 --> 00:37:28,760
And of course, having the master model is much, much easier.

541
00:37:28,760 --> 00:37:32,920
We're currently playing around with that, but we actually think that more and more will

542
00:37:32,920 --> 00:37:35,640
be moving towards master models for certain things.

543
00:37:35,640 --> 00:37:40,400
But to be honest, it depends because it's not a one-size-fits-all for certain pieces

544
00:37:40,400 --> 00:37:45,920
of equipment we found having one model monitoring a whole sort of train, if you will, works

545
00:37:45,920 --> 00:37:46,920
really well.

546
00:37:46,920 --> 00:37:50,120
And for other things, you've really got a monitor that piece of equipment using a very

547
00:37:50,120 --> 00:37:51,120
specific model.

548
00:37:51,120 --> 00:37:56,440
So I think I would say we're learning all the time with this because we're sort of looking

549
00:37:56,440 --> 00:37:57,440
at it.

550
00:37:57,440 --> 00:37:58,440
We're learning as we go.

551
00:37:58,440 --> 00:38:02,200
And it's something we believe quite passionately in, right, which is you go through a process

552
00:38:02,200 --> 00:38:05,680
and you iterate on that and you don't overthink it.

553
00:38:05,680 --> 00:38:09,400
And you may try three, four different approaches, even within the same team.

554
00:38:09,400 --> 00:38:13,400
And that's OK, because I don't think anyone's done this, not at the scale that we're trying

555
00:38:13,400 --> 00:38:14,400
to do it now.

556
00:38:14,400 --> 00:38:18,760
So it was actually featured pretty prominently at this conference we keep referring to, the

557
00:38:18,760 --> 00:38:23,400
Microsoft Ignite conference in the Satya's key notes.

558
00:38:23,400 --> 00:38:30,840
And one of the examples was the use of not just the work with C3 IoT, but their recent

559
00:38:30,840 --> 00:38:36,080
acquisition of bonsai and some of the work you're doing around reinforcement learning

560
00:38:36,080 --> 00:38:40,760
and the application of that, that's also, you know, like all of the things we've talked

561
00:38:40,760 --> 00:38:47,720
about very new, but can you talk a little bit about that work and what you've seen there?

562
00:38:47,720 --> 00:38:49,520
Well, yeah, absolutely.

563
00:38:49,520 --> 00:38:54,720
I mean, what this came out of was basically the idea of the self-driving car.

564
00:38:54,720 --> 00:38:58,320
And the idea was basically, well, if they're making self-driving cars, why can't we have

565
00:38:58,320 --> 00:39:01,680
self-driving wells, basically?

566
00:39:01,680 --> 00:39:05,200
Because if you think about it, in some ways it's a simpler problem to solve.

567
00:39:05,200 --> 00:39:09,640
There's less dimensionality to it, there's less uncertainty to it in some ways, there's

568
00:39:09,640 --> 00:39:12,920
less unexpected events that you still have them.

569
00:39:12,920 --> 00:39:18,000
And so effectively, what we've been trying to do is develop based on a three-dimensional

570
00:39:18,000 --> 00:39:24,840
model of the subsurface, a set of automated geosteering algorithms that allow us to move

571
00:39:24,840 --> 00:39:29,000
the drill bit through the subsurface in line with the well plan, and that's the simplest

572
00:39:29,000 --> 00:39:30,000
way to describe it.

573
00:39:30,000 --> 00:39:34,000
Now, if you think about that, it's actually a very, very suitable problem for reinforcement

574
00:39:34,000 --> 00:39:39,400
learning, because it's got a very simple penalty function, right?

575
00:39:39,400 --> 00:39:44,360
Out of well plan, you assign a penalty and off the back of that, you can very, very quickly

576
00:39:44,360 --> 00:39:49,680
start to bring the well back into line as you train the algorithm over time.

577
00:39:49,680 --> 00:39:56,760
And what we found was that the bonsai solution effectively gave us the opportunity to do

578
00:39:56,760 --> 00:40:00,440
that very easily at scale.

579
00:40:00,440 --> 00:40:04,080
And it's one of those things, you can do this yourself, but actually, if someone's built

580
00:40:04,080 --> 00:40:08,880
a framework for doing this at scale, it's going to be much easier for us to do that as

581
00:40:08,880 --> 00:40:12,360
we go forward, rather than having to maintain our own software.

582
00:40:12,360 --> 00:40:15,280
And that was something that was very appealing about bonsai, that's why we started working

583
00:40:15,280 --> 00:40:16,440
with them.

584
00:40:16,440 --> 00:40:21,760
And so we're now looking at them to help us to scale this as we look at applying it into

585
00:40:21,760 --> 00:40:24,080
different scenarios across our business.

586
00:40:24,080 --> 00:40:32,000
So in formulating this self-driving well problem, what are the different control variables?

587
00:40:32,000 --> 00:40:34,960
I imagine there are tons, but what are the kinds of things that we're talking about,

588
00:40:34,960 --> 00:40:40,000
like rotational speed of the drill bits, and that kind of thing?

589
00:40:40,000 --> 00:40:46,360
Yeah, exactly, and sort of the geospatial positioning, the azimuth, et cetera, right?

590
00:40:46,360 --> 00:40:51,880
You've got a whole series of different measurements that you're taking all the time, and the best

591
00:40:51,880 --> 00:40:59,280
way to describe it, is it's like driving forward, but you're only getting the data in retrospect.

592
00:40:59,280 --> 00:41:03,280
And that's the challenge with it, because what happens, of course, is the data comes

593
00:41:03,280 --> 00:41:07,800
off the bit, and you get it kind of a foot behind where you are if you see what I'm saying.

594
00:41:07,800 --> 00:41:12,920
And so that's quite an interesting dilemma in the whole process.

595
00:41:12,920 --> 00:41:17,840
But certainly, it's looking at a multi-dimensional, three-dimensional problem set based on your

596
00:41:17,840 --> 00:41:22,280
understanding of the subsurface continually, and constantly iterating and adjusting, as

597
00:41:22,280 --> 00:41:29,280
well as trying to really look at the optimum way of doing it, because it's not always

598
00:41:29,280 --> 00:41:35,360
intuitive, because obviously you'll go, this is directional drilling, it's not only sort

599
00:41:35,360 --> 00:41:37,080
of linear drilling.

600
00:41:37,080 --> 00:41:42,960
So your speed also changes depending on the way in which you're drilling, and obviously

601
00:41:42,960 --> 00:41:47,360
that has knock-on effect from an optimization perspective.

602
00:41:47,360 --> 00:41:51,960
And so with reinforcement learning in general, bonds are in particular, the notion of

603
00:41:51,960 --> 00:41:56,000
using simulation is key.

604
00:41:56,000 --> 00:42:02,240
Did you already have a simulation of this in place, and were you able to easily use that

605
00:42:02,240 --> 00:42:03,960
with reinforcement learning?

606
00:42:03,960 --> 00:42:10,240
So I think the beauty of this is we have a lot of internal simulations set up for this

607
00:42:10,240 --> 00:42:15,080
of course, because more or less everything that we do here has been looked at and has

608
00:42:15,080 --> 00:42:18,080
been simulated in the past for optimization purposes.

609
00:42:18,080 --> 00:42:21,920
So if you take something like rate of penetration, we have endless simulations of the way in

610
00:42:21,920 --> 00:42:23,960
which that can be optimized.

611
00:42:23,960 --> 00:42:28,280
And so we can bring some of those things into something like bonsai by having that very

612
00:42:28,280 --> 00:42:32,280
good understanding of the first principles, simulators that we've developed over many

613
00:42:32,280 --> 00:42:36,200
years, as well as of course, simulators of the subsurface, which is another element

614
00:42:36,200 --> 00:42:37,640
of the simulation.

615
00:42:37,640 --> 00:42:41,720
So I think that's been the real benefit, and it's the bringing together our existing

616
00:42:41,720 --> 00:42:46,800
scientific knowledge with the new technology of reinforcement learning that's really driving

617
00:42:46,800 --> 00:42:48,800
this change.

618
00:42:48,800 --> 00:42:53,200
Well, Dan, we covered a ton of ground here.

619
00:42:53,200 --> 00:42:59,040
I appreciate you taking the time to chat with us any kind of final thoughts or words of

620
00:42:59,040 --> 00:43:05,520
wisdom to folks that are maybe at an enterprise that doesn't quite have as much experience

621
00:43:05,520 --> 00:43:12,160
with this intersection of data and process as you and Shell.

622
00:43:12,160 --> 00:43:14,120
What should they be thinking about?

623
00:43:14,120 --> 00:43:17,920
I think it always comes back to really understanding your business problem.

624
00:43:17,920 --> 00:43:21,200
I mean, I know I talked about that earlier on in the call, but the thing I'd encourage

625
00:43:21,200 --> 00:43:24,280
you is that I talked about a lot of sophisticated techniques.

626
00:43:24,280 --> 00:43:28,200
I talked about machine vision, I talked about reinforcement learning, a lot of the biggest

627
00:43:28,200 --> 00:43:31,720
value things we've done are actually the simplest things.

628
00:43:31,720 --> 00:43:36,480
And so if you're feeling like you're just getting started with this, and I know a number

629
00:43:36,480 --> 00:43:41,520
of companies are actually the biggest thing is understanding where the big value is for

630
00:43:41,520 --> 00:43:45,320
your business, and trying to solve the problem in the simplest way you possibly can.

631
00:43:45,320 --> 00:43:50,160
I've got a lot of time for deep science, I absolutely love it, as you can probably tell,

632
00:43:50,160 --> 00:43:54,200
I love some of the things we're doing, but I do think there's so much low hanging

633
00:43:54,200 --> 00:43:56,400
fruit in this space that getting started.

634
00:43:56,400 --> 00:44:00,680
And also, I would say there's some great tools out there that make it very accessible

635
00:44:00,680 --> 00:44:02,440
to get stuck in very, very quickly.

636
00:44:02,440 --> 00:44:06,480
So we've had a great relationship with Ultrix over many years, and we've had huge value

637
00:44:06,480 --> 00:44:10,920
from them, just because it makes it so easy for citizen data scientists in the business

638
00:44:10,920 --> 00:44:13,280
to get stuck in and start to add value.

639
00:44:13,280 --> 00:44:17,480
And I think a lot of this is about a cultural change, trying to drive cultural change across

640
00:44:17,480 --> 00:44:22,640
an organization where data and data science is central to the way that we do business.

641
00:44:22,640 --> 00:44:27,160
That's something which is exciting, it's essential for any company I believe, but it's

642
00:44:27,160 --> 00:44:31,480
also more and more accessible with the latest advances in technology.

643
00:44:31,480 --> 00:44:37,480
Yeah, we didn't get into the cultural side of this, but your colleague Yuri spent a

644
00:44:37,480 --> 00:44:44,200
lot of time talking about that in a session that I had with him at Ignite, clearly something

645
00:44:44,200 --> 00:44:50,280
that's very central to the way you think about scaling data science and machine learning

646
00:44:50,280 --> 00:44:51,280
at Shell.

647
00:44:51,280 --> 00:44:52,280
Yeah, it's massive.

648
00:44:52,280 --> 00:44:57,560
I mean, I think the biggest problem of this is adoption and belief and adoption in the

649
00:44:57,560 --> 00:45:03,240
sense that how do you persuade people to use the output of a data science project?

650
00:45:03,240 --> 00:45:06,720
And the second is do you believe that this is going to improve the way in which you do

651
00:45:06,720 --> 00:45:09,320
your work and make your life easier?

652
00:45:09,320 --> 00:45:14,680
And I think it also comes down to, we've got to learn as an organization to work in a way

653
00:45:14,680 --> 00:45:17,480
that's for more familiar to software houses.

654
00:45:17,480 --> 00:45:23,000
So things like developing minimum viable products, having strong product ownership, iterating

655
00:45:23,000 --> 00:45:29,360
quickly, failing fast, being able to pivot, having the setup in which you are willing

656
00:45:29,360 --> 00:45:33,040
to work with a minimum viable product, not tell the people that are developed it that

657
00:45:33,040 --> 00:45:38,560
is rubbish, those sorts of things are not commonplace and not comfortable for an organization

658
00:45:38,560 --> 00:45:39,560
like ours.

659
00:45:39,560 --> 00:45:43,520
And so it's as much a challenge of building and understanding on both sides, building

660
00:45:43,520 --> 00:45:47,160
and understanding on the business side of the way in which we need to work and building

661
00:45:47,160 --> 00:45:51,040
and understanding from the way that we're working with the challenges that the business

662
00:45:51,040 --> 00:45:54,320
people have every day and bringing those two worlds more closely together.

663
00:45:54,320 --> 00:45:58,840
And it's an exciting challenge, but it's one that's going to take time and it's core

664
00:45:58,840 --> 00:46:01,680
to how we're trying to get the value out of what we're doing.

665
00:46:01,680 --> 00:46:02,680
Fantastic.

666
00:46:02,680 --> 00:46:04,440
Well, Daniel, thank you so much.

667
00:46:04,440 --> 00:46:05,440
Thank you.

668
00:46:05,440 --> 00:46:12,120
All right, everyone, that's our show for today.

669
00:46:12,120 --> 00:46:17,040
For more information on Daniel or any of the topics covered in today's show, visit

670
00:46:17,040 --> 00:46:22,040
twimmelai.com slash talk slash 202.

671
00:46:22,040 --> 00:46:28,360
To learn more about our AI platform series or to download our eBooks, visit twimmelai.com

672
00:46:28,360 --> 00:46:31,240
slash AI platforms.

673
00:46:31,240 --> 00:46:49,440
As always, thanks so much for listening and catch you next time.

