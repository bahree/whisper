1
00:00:00,000 --> 00:00:04,880
The conversation you're about to hear was recorded live at Twomokon AI

2
00:00:04,880 --> 00:00:11,680
platforms. For more coverage of Twomokon, visit Twomokon.com-news or follow us

3
00:00:11,680 --> 00:00:18,400
on Twitter at Twomokon AI. But first, a word from our sponsor.

4
00:00:18,400 --> 00:00:23,840
Thanks to our friends at Dot Science for being a founding sponsor of Twomokon AI

5
00:00:23,840 --> 00:00:28,960
platforms. Dot Science is excited to have met so many amazing attendees at this

6
00:00:28,960 --> 00:00:33,360
year's conference and looks forward to continuing those conversations. If you

7
00:00:33,360 --> 00:00:35,680
weren't able to connect with their team at the conference

8
00:00:35,680 --> 00:00:39,040
or aren't interested in what you heard on stage or at their exhibit in the

9
00:00:39,040 --> 00:00:43,760
community hall, head over to dot science dot com slash deploy

10
00:00:43,760 --> 00:00:48,800
for a free demo and see just how easy it is to get your models into production

11
00:00:48,800 --> 00:00:57,440
and keep them performing. So please take the opportunity to

12
00:00:57,440 --> 00:01:03,520
join me in welcoming our first guest Hussein Mahana is the head of artificial

13
00:01:03,520 --> 00:01:09,360
intelligence and machine learning at cruise and Hussein has a very unique

14
00:01:09,360 --> 00:01:14,800
set of experiences that I'm excited to dig into

15
00:01:14,800 --> 00:01:20,160
in this interview. He was founding engineering leads on the Facebook's FB

16
00:01:20,160 --> 00:01:26,560
learner platform went on to Google to work on Google Cloud and now is

17
00:01:26,560 --> 00:01:31,440
running ML and AI at cruise. Hussein, welcome to Twomokon.

18
00:01:31,440 --> 00:01:36,320
As I mentioned in the interview, you have had a very unique set of experiences

19
00:01:36,320 --> 00:01:42,160
in this space, starting with joining Facebook at a really pivotal

20
00:01:42,160 --> 00:01:45,600
time I think for the company clearly before there was a machine learning

21
00:01:45,600 --> 00:01:51,280
platform in helping get that effort launched. Tell us a little bit about those

22
00:01:51,280 --> 00:01:56,720
you know that time period that you were there. I imagine it was a crazy

23
00:01:56,720 --> 00:02:03,520
period and you've got some more stories. Yeah, it was 2012 and I think it was

24
00:02:03,520 --> 00:02:08,400
the really best time to work on machine learning at Facebook at the time because

25
00:02:08,400 --> 00:02:13,440
the product was mature enough to support machine learning.

26
00:02:13,440 --> 00:02:16,960
Before you can do machine learning you also need good data infrastructure

27
00:02:16,960 --> 00:02:21,600
but the machine learning platform and capabilities themselves were very little.

28
00:02:21,600 --> 00:02:26,000
So at the time there was probably maybe two algorithms at most,

29
00:02:26,000 --> 00:02:32,800
probably maybe two people using machine learning at Facebook and maybe

30
00:02:32,800 --> 00:02:39,120
over the you know an entire year maybe 20 models were trained. By the time I left

31
00:02:39,120 --> 00:02:42,800
we had 25% of engineering using machine learning so we were in the

32
00:02:42,800 --> 00:02:48,080
thousands and we were training maybe two to three million models a month and

33
00:02:48,080 --> 00:02:51,920
a big portion of those were automatically trained and triggered just like

34
00:02:51,920 --> 00:02:57,520
whenever new data comes they just got launched. And most important metric of

35
00:02:57,520 --> 00:03:03,920
all is the time it takes to ship a model from idea to production.

36
00:03:03,920 --> 00:03:07,440
A relatively simple model would take three months, four months in those days.

37
00:03:07,440 --> 00:03:10,800
When I started. When I started and then we got to a point where

38
00:03:10,800 --> 00:03:15,520
multiple models a day could be launched. Wow, that's incredible. So the early

39
00:03:15,520 --> 00:03:20,960
models were that I'm imagining ads and feed? I mean yes, I mean ads and news

40
00:03:20,960 --> 00:03:27,520
feed and search at Facebook are the biggest consumers of machine learning

41
00:03:27,520 --> 00:03:31,760
and they continued but the earliest models were very very simple,

42
00:03:31,760 --> 00:03:35,760
very rudimentary but at the time I left we've supported sort of all sorts of

43
00:03:35,760 --> 00:03:40,720
algorithms and models you can think of. I can imagine. So when you got started was

44
00:03:40,720 --> 00:03:47,200
how big was that effort? Was there a minimum viable product for the platform or

45
00:03:47,200 --> 00:03:52,240
there was no Facebook wide platform. There were like sort of pockets of people

46
00:03:52,240 --> 00:03:56,560
who decided that they had to work on a platform for their team because they

47
00:03:56,560 --> 00:04:00,400
just couldn't ship anything and I became one of those. There was there was a

48
00:04:00,400 --> 00:04:05,840
small tool that we had and I went to my manager after several months working in

49
00:04:05,840 --> 00:04:09,440
the ads team and I said you know what I'm just going to focus on the platform.

50
00:04:09,440 --> 00:04:14,000
It is our biggest bottleneck and so I started working and I remember the

51
00:04:14,000 --> 00:04:18,000
first thing I shipped I locked myself for three weeks. We were training a simple

52
00:04:18,000 --> 00:04:23,600
boosted decision tree that took three days and when I got it down to 21 hours I

53
00:04:23,600 --> 00:04:29,120
could just see the tears of joy because my fears were like you're seeing I could

54
00:04:29,120 --> 00:04:32,560
I could train a model in a day and get the results in a day you know in the

55
00:04:32,560 --> 00:04:36,480
morning and then and then just be done like they were extremely happy and we

56
00:04:36,480 --> 00:04:42,480
eventually got that down to two hours and so and you can see a correlation

57
00:04:42,480 --> 00:04:47,600
between sort of the innovation we had and the productivity that machine learning

58
00:04:47,600 --> 00:04:51,920
engineers had so I decided to focus on that and then as the journey of the

59
00:04:51,920 --> 00:04:57,120
platform evolved we realized that there's an opportunity to support applied

60
00:04:57,120 --> 00:05:01,200
research because now when you have a platform that unifies the company if you

61
00:05:01,200 --> 00:05:07,440
drop in a advanced algorithm everyone else can use it and so the

62
00:05:07,440 --> 00:05:12,320
platform supported applied research in a in a great way and so the work you did

63
00:05:12,320 --> 00:05:16,240
with the boosted decision trees how did you achieve that speed?

64
00:05:16,240 --> 00:05:21,360
Was it just working on the algorithm itself or was it scaling it some way

65
00:05:21,360 --> 00:05:27,360
distributing a combination of everything so the first early wins were mostly

66
00:05:27,360 --> 00:05:34,080
about just avoiding some inefficiencies often machine learning data

67
00:05:34,080 --> 00:05:38,400
scientists or or machine learning scientists are not the best infrastructure

68
00:05:38,400 --> 00:05:45,200
builders and so there was just very common mistakes and those were the early

69
00:05:45,200 --> 00:05:49,040
or low hanging fruit but eventually we got to a point where it was all about

70
00:05:49,040 --> 00:05:54,160
making the algorithm itself faster there's a paper that Facebook one

71
00:05:54,160 --> 00:05:58,240
published about image net in an hour that's an example of how such

72
00:05:58,240 --> 00:06:01,680
scaling efforts eventually evolved where it wasn't just about the

73
00:06:01,680 --> 00:06:05,600
infrastructure but it's also about exploring different algorithms learning

74
00:06:05,600 --> 00:06:08,240
algorithms that can speed up the training

75
00:06:08,240 --> 00:06:14,160
training overall. Did the speed for training a model versus

76
00:06:14,160 --> 00:06:17,520
cycle time what like what ended up being your driving metric what was the thing

77
00:06:17,520 --> 00:06:22,240
you were focused on? That's a fantastic question it's the end-to-end

78
00:06:22,240 --> 00:06:27,200
machine learning cycle all the way from the moment you prepare your data

79
00:06:27,200 --> 00:06:32,160
to generate your features to training your models to

80
00:06:32,160 --> 00:06:37,440
deploying and then back again that cycle was essentially our entire focus

81
00:06:37,440 --> 00:06:42,160
and moving through that cycle faster and faster meant that we're essentially

82
00:06:42,160 --> 00:06:47,200
building models that are learning faster because that cycle itself is one

83
00:06:47,200 --> 00:06:52,160
cycle of learning and reality so we focused on the entire end-to-end.

84
00:06:52,160 --> 00:06:56,960
We talked about the MVP can you talk about the evolution of the platform there?

85
00:06:56,960 --> 00:07:02,720
Yeah we went through three phases in 2012 I focused on what was at the time

86
00:07:02,720 --> 00:07:07,520
called ab learner that was just for ads and it became really successful that

87
00:07:07,520 --> 00:07:11,360
other teams started coming to us and saying hey you know we want to give up our

88
00:07:11,360 --> 00:07:14,400
platform start using your things so that's when we moved it to FB

89
00:07:14,400 --> 00:07:18,560
learner and we had like two other groups at Facebook

90
00:07:18,560 --> 00:07:23,440
but then we realized that so we were scaling on the dimension of teams or

91
00:07:23,440 --> 00:07:27,680
scenarios but we're not scaling on the dimension of algorithms and techniques so

92
00:07:27,680 --> 00:07:32,800
it was a platform basically basically based around the couple of algorithms so

93
00:07:32,800 --> 00:07:37,120
we then moved to the third generation which is FB learner flow and that's when

94
00:07:37,120 --> 00:07:41,520
we scaled the number of scenarios significantly and the number of algorithms

95
00:07:41,520 --> 00:07:47,040
that we support and we built that platform with extensibility

96
00:07:47,040 --> 00:07:51,120
from the get go and not necessarily extensibility by the core FB learner team

97
00:07:51,120 --> 00:07:56,640
but the entire company and that's when the adoption rate in Facebook picked up

98
00:07:56,640 --> 00:08:01,040
one of the things I'm really proud of is that we balance flexibility with

99
00:08:01,040 --> 00:08:04,560
ease of use that we had about maybe a hundred to two hundred users from

100
00:08:04,560 --> 00:08:08,400
Cheryl Sandberg's org and their finance and business and so we're really proud

101
00:08:08,400 --> 00:08:11,840
about democratizing machine learning within Facebook to that extent

102
00:08:11,840 --> 00:08:16,560
at the same time we had the latest convolutional nets we had deep learning for NLP

103
00:08:16,560 --> 00:08:22,480
so we successfully I think we successfully built a a good multi-layered

104
00:08:22,480 --> 00:08:28,000
platform that scaled for different use cases. So you just mentioned use cases you

105
00:08:28,000 --> 00:08:33,440
started with a teams dimension and an algorithms dimension do those two get you

106
00:08:33,440 --> 00:08:38,480
use cases or is there another abstraction that you thought of where you're

107
00:08:38,480 --> 00:08:43,040
trying to generalize a use case beyond the specific team and an algorithm?

108
00:08:43,040 --> 00:08:50,000
Yes so if we talk about abstraction layer FB learners flows

109
00:08:50,000 --> 00:08:54,480
contribution I would say and we talked about this on on Facebook log is

110
00:08:54,480 --> 00:08:58,480
I think we nailed the right upstraction it's a workflow and a workflow consists

111
00:08:58,480 --> 00:09:02,080
of an operator that takes generic data whatever data types you want

112
00:09:02,080 --> 00:09:07,040
and gives generic outputs. The nice thing is that once you have an operator you

113
00:09:07,040 --> 00:09:10,720
can create any workflow you want but what's even more powerful is the entire

114
00:09:10,720 --> 00:09:15,520
workflow can become an operator and yet another workflow and this composition

115
00:09:15,520 --> 00:09:20,480
allowed us to build multi-layered platform. Let me give you a concrete example so

116
00:09:20,480 --> 00:09:24,800
let's say you build a convolutional net that takes in an image and produces a

117
00:09:24,800 --> 00:09:29,920
model that classifies based on the data and the labels we offer that in itself is

118
00:09:29,920 --> 00:09:34,320
extremely powerful requires someone who's deep in in convolutional nets and deep

119
00:09:34,320 --> 00:09:38,880
learning but at the same time it's still hard for a lot of other machine learning

120
00:09:38,880 --> 00:09:43,760
users even data scientists to use so what you can do is you can wrap that in

121
00:09:43,760 --> 00:09:48,480
another workflow that simplifies it by saying just give us the data and we'll

122
00:09:48,480 --> 00:09:52,160
do hyper parameter tuning on your behalf and then you can wrap that with another

123
00:09:52,160 --> 00:09:56,480
workflow that makes it more useful from a business case so

124
00:09:56,480 --> 00:10:00,800
filtering images and in different scenarios like if you're filtering them to

125
00:10:00,800 --> 00:10:06,320
remove explicit content is different than if you're filtering them to

126
00:10:06,320 --> 00:10:11,120
propose an image for you to share later so these are all different use cases so

127
00:10:11,120 --> 00:10:16,960
essentially that multi-layering allowed us to scale and the most important part is

128
00:10:16,960 --> 00:10:22,000
making everything shareable and reusable so whenever some team builds

129
00:10:22,000 --> 00:10:26,320
something every other team at Facebook has the opportunity of reusing it

130
00:10:26,320 --> 00:10:31,040
and to make it reusable we had to make it discoverable so we created search

131
00:10:31,040 --> 00:10:36,320
we would rank these workflows by how many times they've been used how many times

132
00:10:36,320 --> 00:10:40,320
they've been successful so that the rest of Facebook which started growing

133
00:10:40,320 --> 00:10:44,160
into the thousands would know like oh this is the most popular convolutional

134
00:10:44,160 --> 00:10:49,200
network workflow or this is the most popular text classification workflow

135
00:10:49,200 --> 00:10:53,760
and so on so that was very useful at Facebook and it helped spread adoption

136
00:10:53,760 --> 00:10:59,040
Facebook in a lot of ways has demonstrated a huge commitment to

137
00:10:59,040 --> 00:11:02,160
open source and open is generally if you look at

138
00:11:02,160 --> 00:11:05,680
the kind of the bottom of the stack they do open compute at the top of the

139
00:11:05,680 --> 00:11:09,920
stack they're doing things like PyTorch and Onyx but they haven't

140
00:11:09,920 --> 00:11:13,840
you know open source the platform and I've had conversations on the

141
00:11:13,840 --> 00:11:18,880
podcast with folks on the T man while I didn't ask this my sense was that

142
00:11:18,880 --> 00:11:23,440
a lot of the way things are done or work are very Facebook specific like

143
00:11:23,440 --> 00:11:26,560
yep there was no Kubernetes when we started this so we're doing our own

144
00:11:26,560 --> 00:11:31,600
distributed compute the connections to data is that kind of yeah no that's

145
00:11:31,600 --> 00:11:34,800
absolutely right once you start going into end-to-end machine learning

146
00:11:34,800 --> 00:11:40,400
unlike PyTorch which is heavily contained the integration into whatever

147
00:11:40,400 --> 00:11:44,960
infrastructure system you have is a much bigger component and so when we were

148
00:11:44,960 --> 00:11:48,560
looking at open sourcing of the learner flow we had to open source the rest of

149
00:11:48,560 --> 00:11:53,280
Facebook with it now the beauty of Kubernetes is that it gives you this

150
00:11:53,280 --> 00:11:58,560
abstraction layer and through my time at Google we invested in

151
00:11:58,560 --> 00:12:05,920
Qflow pipelines which is you can think of it as a moving workflow engine that

152
00:12:05,920 --> 00:12:10,480
you can take with you wherever Kubernetes exists yeah yeah speaking of

153
00:12:10,480 --> 00:12:14,720
Google after Facebook you went to Google can you talk a little bit about yeah

154
00:12:14,720 --> 00:12:19,760
absolutely so I was very passionate about you know building machine learning

155
00:12:19,760 --> 00:12:24,080
and helping tools or platforms and helping others adopt machine learning and

156
00:12:24,080 --> 00:12:27,920
frankly there's no better place to do this than being at Google because of

157
00:12:27,920 --> 00:12:31,440
its amazing machine learning brand amazing machine learning research

158
00:12:31,440 --> 00:12:36,400
capabilities and Google Cloud and so that trifecta was extremely

159
00:12:36,400 --> 00:12:42,640
exciting for me and I joined Google and you know I just like my time at

160
00:12:42,640 --> 00:12:47,040
Facebook was extremely amazing but then seeing the platter of machine learning

161
00:12:47,040 --> 00:12:52,480
use cases from healthcare to autonomous vehicles to

162
00:12:52,480 --> 00:12:58,160
finance and so on just was fabulous and amazing like there's a lot of

163
00:12:58,160 --> 00:13:02,480
diversity in machine learning so you joined Facebook at

164
00:13:02,480 --> 00:13:07,760
in 2012 and Google in 2017 they had this amazing machine learning brand

165
00:13:07,760 --> 00:13:10,880
the work was all done they were much further along

166
00:13:10,880 --> 00:13:17,920
Google you mean Google so not necessarily actually Google and Facebook their

167
00:13:17,920 --> 00:13:21,680
investments in machine learning follow their strategies so let me explain

168
00:13:21,680 --> 00:13:27,280
what I mean by that Google has a very broad set of products like documents

169
00:13:27,280 --> 00:13:33,200
doorbells cameras all you name it Facebook is far more focused okay right and

170
00:13:33,200 --> 00:13:36,240
so when you look at machine learning investments Google has a broad

171
00:13:36,240 --> 00:13:41,680
portfolio Facebook is far more focused there are places where Facebook is more

172
00:13:41,680 --> 00:13:45,120
is better or advanced and vice versa the nice thing is that the two are

173
00:13:45,120 --> 00:13:49,040
complimentary so I'll give you an example I think PyTorch demonstrates

174
00:13:49,040 --> 00:13:55,600
Facebook's focus on usability and ease of use but then you look at Facebook

175
00:13:55,600 --> 00:13:59,600
Google's broad portfolio of research it demonstrates

176
00:13:59,600 --> 00:14:04,560
its breadth so I won't say one is better than the other they just have two

177
00:14:04,560 --> 00:14:09,440
different styles that they've inherited from how they invest in technology in

178
00:14:09,440 --> 00:14:12,880
general one of the themes that's

179
00:14:12,880 --> 00:14:21,760
recurred in my interviews here and beyond this conference is the idea that

180
00:14:21,760 --> 00:14:28,480
right now productivity and machine learning is primarily a usability

181
00:14:28,480 --> 00:14:33,360
challenge as opposed to a you know a modeling challenge for example would you

182
00:14:33,360 --> 00:14:37,520
agree with that or I agree to a very large extent to that that that's

183
00:14:37,520 --> 00:14:41,520
absolutely right and that's one of my you know pieces of advice that I give

184
00:14:41,520 --> 00:14:45,360
to people who are trying to build a new platform it's not necessarily about

185
00:14:45,360 --> 00:14:51,360
sophistication because your end customer may not need it yet right your end

186
00:14:51,360 --> 00:14:55,440
customer might have a usability problem and and through Google Cloud we found

187
00:14:55,440 --> 00:14:59,840
that different customer types had different usability issues even the very

188
00:14:59,840 --> 00:15:05,200
sophisticated customers who would come to us and say just give me GPUs even the

189
00:15:05,200 --> 00:15:10,960
usability of giving them a GPU easily and clearly meant a big difference to them

190
00:15:10,960 --> 00:15:16,160
so I think my advice is do not ignore usability

191
00:15:16,160 --> 00:15:21,600
machine learning is obviously a very deep technical area but approach it with a

192
00:15:21,600 --> 00:15:28,480
product sense and that's why at Google and at times that Facebook designers and

193
00:15:28,480 --> 00:15:34,480
user-experient experts were my friends because I would ask them to help me

194
00:15:34,480 --> 00:15:38,560
figure out where the usability bottlenecks that users are suffering from and

195
00:15:38,560 --> 00:15:42,240
then if we solve them you see massive increase in productivity are there

196
00:15:42,240 --> 00:15:46,560
examples of where designers have kind of come in oh yeah

197
00:15:46,560 --> 00:15:51,520
what you thought about a problem absolutely so one example is at Google we had a

198
00:15:51,520 --> 00:15:56,960
fantastic user experience team and we were building a lot of great machine

199
00:15:56,960 --> 00:16:01,840
learning tools for text and image and and so on and then what we noticed is

200
00:16:01,840 --> 00:16:05,280
that our users wanted to combine all these together

201
00:16:05,280 --> 00:16:11,600
right and so our our we deployed our UX team and they would sit

202
00:16:11,600 --> 00:16:15,440
with our users to go through an end-to-end machine learning workflow

203
00:16:15,440 --> 00:16:19,360
and those users are other companies and then when we showed them these end-to-end

204
00:16:19,360 --> 00:16:23,840
workflows you could see how it just thinks click in the eyes of our users are

205
00:16:23,840 --> 00:16:28,240
like oh I understand why it takes so long because I would spend so much time in

206
00:16:28,240 --> 00:16:32,240
this part like preparing data when I thought that the hardest part was using

207
00:16:32,240 --> 00:16:37,840
TensorFlow but I actually need to invest in improving this so that was one of

208
00:16:37,840 --> 00:16:40,960
the examples and it just happened again and again and became our most

209
00:16:40,960 --> 00:16:45,200
favorite topic with customers that customers would come to us and say

210
00:16:45,200 --> 00:16:49,040
where's your UX team so it was really interesting

211
00:16:49,040 --> 00:16:54,480
awesome so you've been at cruise for about six months now yes

212
00:16:54,480 --> 00:16:59,360
what's your why cruise and what's your role yeah absolutely I

213
00:16:59,360 --> 00:17:04,320
so I started in machine learning in 2012 when things were just ramping up and

214
00:17:04,320 --> 00:17:06,960
not a lot of people thought that machine learning is the

215
00:17:06,960 --> 00:17:13,600
sexiest thing I actually see another trend that is about to happen and that's

216
00:17:13,600 --> 00:17:18,640
the domain of autonomous vehicles I think that's going to push AI to a whole

217
00:17:18,640 --> 00:17:22,320
new level in terms of the depth of the problem

218
00:17:22,320 --> 00:17:28,160
and in terms of scale so let me give you concrete examples

219
00:17:28,160 --> 00:17:31,600
most of the machine learning applications that are dominant in the industry

220
00:17:31,600 --> 00:17:36,480
today are either advertisement or recommendations for movies or

221
00:17:36,480 --> 00:17:41,200
products and these are very decent and extremely impactful

222
00:17:41,200 --> 00:17:45,440
applications but if you compare them to what a car needs to do

223
00:17:45,440 --> 00:17:51,600
navigate the roads of San Francisco safely the decision making is

224
00:17:51,600 --> 00:17:55,520
maybe an order of magnitude less so the car has to

225
00:17:55,520 --> 00:17:59,440
track so many objects including pedestrians

226
00:17:59,440 --> 00:18:03,440
funny pedestrians who might be wearing a palm tree costume the car needs to have

227
00:18:03,440 --> 00:18:07,600
common sense that happens here in San Francisco

228
00:18:07,600 --> 00:18:13,600
I've seen a gentleman who had a bike with a four trolley system behind them

229
00:18:13,600 --> 00:18:17,200
so you see a lot of these interesting things and then the car needs to

230
00:18:17,200 --> 00:18:20,880
predict what these different agents are going to do

231
00:18:20,880 --> 00:18:24,960
and so the decision-making is very complex and you need to do that in a hundred

232
00:18:24,960 --> 00:18:30,640
milliseconds so the problem is far deeper and that just pushes

233
00:18:30,640 --> 00:18:34,080
AI to new limits the other thing that is really important is

234
00:18:34,080 --> 00:18:39,200
the accuracy required is very high in order to drive a car safely

235
00:18:39,200 --> 00:18:42,720
no one gets hurt if you show them a bad ad or a bad recommendation

236
00:18:42,720 --> 00:18:46,080
right and what's interesting is that you can learn from that but

237
00:18:46,080 --> 00:18:51,680
in autonomous vehicles we have to push our accuracy limits and then finally

238
00:18:51,680 --> 00:18:56,080
every car moving in the street has multiple sensors

239
00:18:56,080 --> 00:19:00,240
so they have multiple cameras multiple lidars that are generating gigabytes of

240
00:19:00,240 --> 00:19:04,800
data a second and when you have multiple cars of these roaming around

241
00:19:04,800 --> 00:19:08,800
the data scale is actually gigonomous

242
00:19:08,800 --> 00:19:13,520
so scale is an interesting point we had a really interesting exchange

243
00:19:13,520 --> 00:19:17,680
early on when we were talking about the you participating in the conference

244
00:19:17,680 --> 00:19:22,240
and I kind of approach you with hey you are at these huge scale places

245
00:19:22,240 --> 00:19:25,440
Google and Facebook that you know nothing's bigger than that right and you're

246
00:19:25,440 --> 00:19:29,840
like hold on autonomous vehicles is way bigger scale

247
00:19:29,840 --> 00:19:34,160
elaborate on that you know how do you think about the two relative to one

248
00:19:34,160 --> 00:19:40,000
oh absolutely here's a way to analyze scale if you look at your training data

249
00:19:40,000 --> 00:19:44,400
right don't just look at the number of rows but look at the size of a record

250
00:19:44,400 --> 00:19:51,200
one record most of the time when you leverage when you leverage recommendations

251
00:19:51,200 --> 00:19:54,640
it's tabular data the record size is not huge

252
00:19:54,640 --> 00:19:57,920
but if you look at the record size for an autonomous vehicle

253
00:19:57,920 --> 00:20:00,960
it could be thousands of lidar points

254
00:20:00,960 --> 00:20:05,040
multiple you know tens of thousands of pixels

255
00:20:05,040 --> 00:20:09,120
even audio matters because the car needs to listen if an

256
00:20:09,120 --> 00:20:13,280
emergency vehicle is coming around we actually need to figure out if

257
00:20:13,280 --> 00:20:18,000
if a pedestrian is waving to us or looking at the car or looking at the phone

258
00:20:18,000 --> 00:20:22,880
so the record is just far bigger so that's one example of scale

259
00:20:22,880 --> 00:20:27,680
there's another thing that is interesting machine learning is just part of

260
00:20:27,680 --> 00:20:33,200
the application it's it's it's among so in web development or web-based

261
00:20:33,200 --> 00:20:37,360
applications like recommendations the tool chain is well developed

262
00:20:37,360 --> 00:20:41,040
in autonomous vehicles we're still innovating that we're still building it

263
00:20:41,040 --> 00:20:45,600
um and we're still trying to scale to the amount of data

264
00:20:45,600 --> 00:20:50,640
and um that's one other example of how scale matters in autonomous vehicles

265
00:20:50,640 --> 00:20:55,600
because the tool chain doesn't yet exist um we're in we're inventing that

266
00:20:55,600 --> 00:20:58,720
as we're inventing the cars themselves

267
00:20:58,720 --> 00:21:03,760
are scale and the need to build out the tools or those that the only challenges

268
00:21:03,760 --> 00:21:07,600
that you face or are the problems themselves in early

269
00:21:07,600 --> 00:21:11,920
challenging all of them but they are in what ways yeah i mean the

270
00:21:11,920 --> 00:21:16,720
you get into a cycle of like i can solve this problem if i could just scale

271
00:21:16,720 --> 00:21:21,120
then after you scale okay i solve this problem now i i discover a new problem

272
00:21:21,120 --> 00:21:25,520
and i need to scale further so one of the things that attracted me to

273
00:21:25,520 --> 00:21:29,680
the company is this understanding the interplay between the applied research

274
00:21:29,680 --> 00:21:35,360
problem and the underlying tooling and that's why um our co-founder Kyle says

275
00:21:35,360 --> 00:21:39,280
he's building two things he's building the car and he's building the tools

276
00:21:39,280 --> 00:21:43,040
that are going to build the car because no one has no one has built that before

277
00:21:43,040 --> 00:21:47,680
if you compare this to the web world the tools the tool chain is far more mature

278
00:21:47,680 --> 00:21:50,960
we've been building web applications and mobile applications for

279
00:21:50,960 --> 00:21:54,720
for a couple of decades now and so the tool chain is far more mature but

280
00:21:54,720 --> 00:21:59,120
you look at autonomous vehicles that's just not there it cruises your approach is

281
00:21:59,120 --> 00:22:03,840
multimodal in terms of the types of information that you're taking in off the

282
00:22:03,840 --> 00:22:06,640
vehicle you've mentioned LiDAR you've mentioned imagery you've mentioned

283
00:22:06,640 --> 00:22:13,840
sound even uh within all of those are there specific categories of problems

284
00:22:13,840 --> 00:22:21,600
that are uh key or oh yeah yeah i can list so many i mean the basic is just

285
00:22:21,600 --> 00:22:27,040
detecting um objects in the scene understanding that this is a car

286
00:22:27,040 --> 00:22:31,280
and that the scar is heading this way um understanding whether the scar is moving

287
00:22:31,280 --> 00:22:36,880
or not um you have the same problem for pedestrians bicycles and now scooters

288
00:22:36,880 --> 00:22:41,520
and all of these agents have different behaviors and it's not just

289
00:22:41,520 --> 00:22:45,920
enough to say this is where they at now you also need to predict what are they

290
00:22:45,920 --> 00:22:51,040
going to do in the future and so behavioral prediction is also another problem

291
00:22:51,040 --> 00:22:55,040
one of the other interesting areas to apply machine learning which i don't think

292
00:22:55,040 --> 00:23:01,280
people know uh a lot about uh autonomous vehicles the style of driving how fast you

293
00:23:01,280 --> 00:23:05,600
break and how fast you accelerate uh may not

294
00:23:05,600 --> 00:23:09,840
necessarily affect safety but affects your experience as a writer

295
00:23:09,840 --> 00:23:14,400
not so because if you break hard um the writers may get nauseous

296
00:23:14,400 --> 00:23:20,320
right and so the driving style so my wife tells me

297
00:23:20,320 --> 00:23:23,920
exactly and so the driving style itself is a machine learning problem i mean i

298
00:23:23,920 --> 00:23:28,480
think it's it's a Pandora box like frankly um i went there because the the

299
00:23:28,480 --> 00:23:32,240
number of machine learning problems is just endless and i think it will

300
00:23:32,240 --> 00:23:35,600
it will it will be an exciting place for anyone excited about

301
00:23:35,600 --> 00:23:39,040
machine learning uh problems or machine learning tools

302
00:23:39,040 --> 00:23:44,720
and one of the ways you were introduced to cruises that they were doing some

303
00:23:44,720 --> 00:23:48,800
of their work on the google platform can you talk a little bit about

304
00:23:48,800 --> 00:23:54,560
yeah how you're platforming uh the you know machine learning i cruise today

305
00:23:54,560 --> 00:23:59,840
so google cloud we offer multiple sort of suites of products to our AI

306
00:23:59,840 --> 00:24:04,160
customers cruises obviously an AI company so they were mostly

307
00:24:04,160 --> 00:24:09,200
focused on the lower level infrastructure like GPUs and some tooling around it

308
00:24:09,200 --> 00:24:13,280
um i remember my first meeting with cruise and i was like okay well you know i'm

309
00:24:13,280 --> 00:24:16,320
getting introduced to these people they seem really enthusiastic

310
00:24:16,320 --> 00:24:19,680
and then i look at our numbers and i start seeing the GPU usage

311
00:24:19,680 --> 00:24:23,920
you know uh rocketing up to the extent that we have to go and

312
00:24:23,920 --> 00:24:28,640
you know um scrambled to get them more GPUs and i was like something is happening there

313
00:24:28,640 --> 00:24:35,440
um and for me you know you know a company's uh focus on machine learning

314
00:24:35,440 --> 00:24:40,080
by how much they spend on the infrastructure and how much they use it and so

315
00:24:40,080 --> 00:24:42,720
it's very clear to me that something big is happening there

316
00:24:42,720 --> 00:24:46,480
and then i visited them a few months later and the progress rate

317
00:24:46,480 --> 00:24:53,840
was phenomenal um so i joined uh there um a few months ago and it was

318
00:24:53,840 --> 00:24:58,080
eight months into building their own machine learning uh dedicated platform

319
00:24:58,080 --> 00:25:02,480
and it just advanced uh really quickly and just in the five months that i've

320
00:25:02,480 --> 00:25:06,320
been there it even advanced further um so i'm really glad

321
00:25:06,320 --> 00:25:09,360
them there because the problem is deep the

322
00:25:09,360 --> 00:25:13,760
pace is really fast uh and that's something i enjoy and i think it's very

323
00:25:13,760 --> 00:25:19,680
important for machine learning um and i get to again redefine what

324
00:25:19,680 --> 00:25:22,560
the future of machine learning i believe is going to look like because i

325
00:25:22,560 --> 00:25:26,640
believe in uh just like ads and and and recommendations

326
00:25:26,640 --> 00:25:29,520
propelled the application of machine learning in the industry the last three

327
00:25:29,520 --> 00:25:33,840
to five years i think in the next five years it's going to be robotics

328
00:25:33,840 --> 00:25:37,120
and autonomous vehicles and it's going to push machine learning to levels we

329
00:25:37,120 --> 00:25:40,880
haven't seen and i'm really excited about that period i think machine learning

330
00:25:40,880 --> 00:25:46,800
and AI will fulfill their promise uh through the vehicle of robotics

331
00:25:46,800 --> 00:25:51,520
uh so you you you're bringing a whole an incredible wealth of

332
00:25:51,520 --> 00:25:56,160
platform building experiences to a new problem one that has unique

333
00:25:56,160 --> 00:26:00,800
challenges how do you customize you know what you've

334
00:26:00,800 --> 00:26:04,240
done before what you've learned or what you believe about you know

335
00:26:04,240 --> 00:26:08,800
delivering platforms to that specific problem you know both

336
00:26:08,800 --> 00:26:13,920
generally philosophically but also you know concretely what does the cruise

337
00:26:13,920 --> 00:26:18,640
platform look like sure so i think for cruise particularly and this is

338
00:26:18,640 --> 00:26:22,400
something i did super well at facebook it's the interplay between applied

339
00:26:22,400 --> 00:26:27,360
research and platforms how can you scale applied research

340
00:26:27,360 --> 00:26:30,720
by shipping it through a platform because applied research and machine

341
00:26:30,720 --> 00:26:35,040
learning is costly and you don't want every team every sub team to do their

342
00:26:35,040 --> 00:26:38,560
own applied research what you'd rather do is if one team innovates you want

343
00:26:38,560 --> 00:26:42,720
everyone else to use it and so that interplay is important is that is is applied

344
00:26:42,720 --> 00:26:47,360
research the print your primary user at cruise as opposed to data

345
00:26:47,360 --> 00:26:50,800
scientists machine learning engineers that are both other function all of

346
00:26:50,800 --> 00:26:54,800
these are all in in by org so the applied uh research

347
00:26:54,800 --> 00:26:59,280
part of the autonomous vehicle the data scientists and the machine learning

348
00:26:59,280 --> 00:27:02,240
platform are all one community that's essentially cruise the eye and that's

349
00:27:02,240 --> 00:27:06,080
one of the things that i think is unique about cruise often if you see

350
00:27:06,080 --> 00:27:09,200
companies who split the two in the early days at

351
00:27:09,200 --> 00:27:14,800
facebook these were combined google also the machine

352
00:27:14,800 --> 00:27:19,760
intelligence group is also a combined group and i think that approach is

353
00:27:19,760 --> 00:27:24,640
really important because the platform evolves through the demands of the

354
00:27:24,640 --> 00:27:28,160
research scientists and and the the data scientists

355
00:27:28,160 --> 00:27:32,080
but also the platform has an ability to influence them and

356
00:27:32,080 --> 00:27:36,160
improve their research so that sort of yang and yang is very important

357
00:27:36,160 --> 00:27:40,880
in terms of um general advice about a platform i would say

358
00:27:40,880 --> 00:27:44,000
first thing is what i mentioned bring your scientists and your platform

359
00:27:44,000 --> 00:27:48,400
builders together uh the second thing is uh be extremely

360
00:27:48,400 --> 00:27:54,000
customer driven uh sometimes it's enticing to chase a very sophisticated

361
00:27:54,000 --> 00:27:57,040
scenario but that may not be what you needed the moment

362
00:27:57,040 --> 00:28:01,360
so be customer driven the the third thing is be careful bringing

363
00:28:01,360 --> 00:28:07,440
biases of other experiences so i often seen that big data techniques

364
00:28:07,440 --> 00:28:11,920
failed for machine learning um so as an example if you use map

365
00:28:11,920 --> 00:28:16,240
produce um it's just it doesn't scale as well as one

366
00:28:16,240 --> 00:28:20,320
gpu machine and i had this example at facebook where there's a sophisticated

367
00:28:20,320 --> 00:28:24,320
graph processing system it ran on 500 machines

368
00:28:24,320 --> 00:28:29,760
and it ran slower than one single machine um and ran even

369
00:28:29,760 --> 00:28:36,000
much much slower compared to one gpu so um bringing some of these biases

370
00:28:36,000 --> 00:28:40,560
is dangerous and then finally i believe a proper platform is an algorithm

371
00:28:40,560 --> 00:28:44,800
agnostic platform um that's the basic minimum level of

372
00:28:44,800 --> 00:28:48,560
extensibility uh that a platform has if you build it around an algorithm

373
00:28:48,560 --> 00:28:52,640
machine learning changes so much what is hot today is

374
00:28:52,640 --> 00:28:57,280
tomorrow's um is is tomorrow's deprecated algorithm

375
00:28:57,280 --> 00:29:00,560
and so if your entire platform is basically based on a bunch of them

376
00:29:00,560 --> 00:29:04,080
then you're going to be wasting a lot of work and effort

377
00:29:04,080 --> 00:29:09,600
a lot of teams struggle with uh this generalizability

378
00:29:09,600 --> 00:29:13,840
aspect that you're mentioning you know do we support a specific

379
00:29:13,840 --> 00:29:17,600
framework do we support a bunch of frameworks we support specific algorithms

380
00:29:17,600 --> 00:29:22,080
versus a bunch of algorithms do you think there's a certain scale that

381
00:29:22,080 --> 00:29:26,720
you have to be at before you can afford to do to be general

382
00:29:26,720 --> 00:29:29,840
or is that something that you need to commit to

383
00:29:29,840 --> 00:29:34,720
independent of the size that you're at well it depends on the company i

384
00:29:34,720 --> 00:29:40,000
think we made an early decision in 2014 at facebook

385
00:29:40,000 --> 00:29:45,360
that we are going to generalize because it was very clear that the company

386
00:29:45,360 --> 00:29:48,800
is going to require different algorithms different use cases and we don't

387
00:29:48,800 --> 00:29:52,480
want to reinvent the wheel um but maybe a different

388
00:29:52,480 --> 00:29:56,320
different companies have different uh circumstances so just work it

389
00:29:56,320 --> 00:30:00,000
backwards from where you think the customer will be not today

390
00:30:00,000 --> 00:30:03,680
but in three years um i believe companies like facebook,

391
00:30:03,680 --> 00:30:07,600
cruise, google and so on will benefit from a general platform

392
00:30:07,600 --> 00:30:13,040
um smaller companies may benefit from more specialized platforms like if you're

393
00:30:13,040 --> 00:30:16,000
a fintech company and you know you're not going to be dealing with

394
00:30:16,000 --> 00:30:20,320
images at all and there's no value for you then focus on tabular data

395
00:30:20,320 --> 00:30:24,240
and build your platform that way um but if you're a company that has mixed

396
00:30:24,240 --> 00:30:27,840
sources of data very likely you need to generalize

397
00:30:27,840 --> 00:30:32,160
um curious about how you how you approach the organizational side of things

398
00:30:32,160 --> 00:30:36,320
you mentioned that you've got uh all of the kind of key

399
00:30:36,320 --> 00:30:41,360
customer groups uh in the same org as the platform and that's key are there

400
00:30:41,360 --> 00:30:47,040
other things that you've uh learned or believe organizationally that

401
00:30:47,040 --> 00:30:50,720
require then are required to make this successful. Yeah you know over my time at

402
00:30:50,720 --> 00:30:55,200
facebook and google and in cruise i've ran organizations for AI

403
00:30:55,200 --> 00:30:59,120
that consisted of different uh functions

404
00:30:59,120 --> 00:31:04,480
not just machine learning experts um and my advice is treat all of them

405
00:31:04,480 --> 00:31:08,960
equally you need them all to deliver a good machine learning

406
00:31:08,960 --> 00:31:13,040
product and so as an example at facebook one of the very early decisions

407
00:31:13,040 --> 00:31:17,280
we realized that machine learning has a usability problem so we need to hire

408
00:31:17,280 --> 00:31:22,560
user uh interface ui people and we elevated them to the same level as our

409
00:31:22,560 --> 00:31:25,760
researchers because they didn't want to join a team where they felt they're

410
00:31:25,760 --> 00:31:30,800
going to be second class so um a big believer in this cross functional uh

411
00:31:30,800 --> 00:31:34,640
mixture of talent and actually what's interesting is they

412
00:31:34,640 --> 00:31:39,760
each function brings its diverse uh perspective and that aggregation of

413
00:31:39,760 --> 00:31:42,480
perspectives creates really fantastic machine learning

414
00:31:42,480 --> 00:31:46,560
product. So where do you see platforms going

415
00:31:46,560 --> 00:31:51,600
overall or machine learning in kind of the enterprise context?

416
00:31:51,600 --> 00:31:56,240
Well i'm going to be biased because i've made my bet through google cloud i

417
00:31:56,240 --> 00:32:01,440
think um there's going to be a lot in kubernetes um and that's the reason why

418
00:32:01,440 --> 00:32:08,320
we invested in q-flow i think um uh notebooks um interacting well with machine

419
00:32:08,320 --> 00:32:12,480
learning workflows that's why q-flow has a notebook solution and has q-flow

420
00:32:12,480 --> 00:32:17,280
pipelines and then i'm very excited about the ability to share

421
00:32:17,280 --> 00:32:20,880
so if someone builds a interesting machine learning component or an interesting

422
00:32:20,880 --> 00:32:24,320
machine learning workflow how can they share this with the rest of their

423
00:32:24,320 --> 00:32:29,280
company or the rest of the community? So i think these um pillars are

424
00:32:29,280 --> 00:32:31,840
necessary for successful machine learning platforms

425
00:32:31,840 --> 00:32:37,040
and i believe cloud providers are going to play a very big role

426
00:32:37,040 --> 00:32:40,080
in that aspect but i think it's going to be on kubernetes.

427
00:32:40,080 --> 00:32:43,760
Nice i should mention that i have not seen them yet but uh

428
00:32:43,760 --> 00:32:48,480
david aronchick one of the founding team members of q-flow is here somewhere

429
00:32:48,480 --> 00:32:52,400
and uh there's quite a bit of interest in a

430
00:32:52,400 --> 00:32:56,320
q-flow session in the unconference if that's of interest uh definitely check

431
00:32:56,320 --> 00:33:00,960
that out uh who's saying thanks so much for joining us here at twomelcon AI

432
00:33:00,960 --> 00:33:09,520
platforms. Thank you very much. Appreciate it.

433
00:33:09,520 --> 00:33:13,360
All right everyone i hope you enjoyed our show straight from the main

434
00:33:13,360 --> 00:33:18,800
stage at twomelcon AI platforms. For more information about today's show

435
00:33:18,800 --> 00:33:23,440
visit twomelai.com and for more twomelcon coverage

436
00:33:23,440 --> 00:33:28,640
visit twomelcon.com slash news. Thanks so much for listening

437
00:33:28,640 --> 00:33:55,360
and catch you next time.

