1
00:00:00,000 --> 00:00:11,200
All right, everyone. Welcome to another episode of the Twomo AI podcast. I'm, of course,

2
00:00:11,200 --> 00:00:17,000
your host, Sam Charington. And today I'm joined by Audrey Smith, the Chief Operating Officer

3
00:00:17,000 --> 00:00:22,160
at ML Twist. Before we get into today's conversation, be sure to take a moment to head over

4
00:00:22,160 --> 00:00:27,440
to Apple Podcasts or your listening platform of choice. And if you enjoy the show, please

5
00:00:27,440 --> 00:00:34,160
leave us a five-star rating and review. Audrey, welcome to the podcast. Thank you, Sam.

6
00:00:34,160 --> 00:00:40,000
Thanks for having me. Absolutely. I am really looking forward to our conversation. For those

7
00:00:40,000 --> 00:00:44,400
listening in with us, if you've been listening to the show recently, you know that we've been

8
00:00:44,400 --> 00:00:52,240
digging deep into data-centric AI. And this conversation will continue in this theme. And I'm

9
00:00:52,240 --> 00:00:58,720
super excited to have Audrey on. She's got a ton of experience with labeling, label ops,

10
00:00:58,720 --> 00:01:05,200
and so much more in this space. So Audrey, once again, welcome. Thanks, Sam.

11
00:01:07,360 --> 00:01:12,560
Let's start with a little bit about your background and how you came to work in machine learning.

12
00:01:12,560 --> 00:01:22,640
Sure. So I actually studied law. I am a lawyer. I studied in France. You can hear my accent, of

13
00:01:22,640 --> 00:01:28,240
course. And I was a lawyer in France for three years before I decided that I wanted to have an

14
00:01:28,240 --> 00:01:36,080
international experience. So I went to the UK, worked there for five years. And then when I moved

15
00:01:36,080 --> 00:01:44,400
to the US in 2014, I was really looking forward to finding my place into the tech industry.

16
00:01:46,720 --> 00:01:50,720
Until then, I had no technical background. I didn't know anything about machine learning.

17
00:01:50,720 --> 00:01:58,400
So I didn't know exactly how I would start. But I applied for jobs basically where you needed to

18
00:01:58,400 --> 00:02:07,120
have French speaking skills. And my first job was to listen to Siri and listen, especially to

19
00:02:07,120 --> 00:02:13,040
French speakers, talking to Siri. And that's the start of my data labeling journey. Really,

20
00:02:13,040 --> 00:02:18,400
that's when I learn about machine learning and how data labeling is so important to it.

21
00:02:19,200 --> 00:02:25,760
And I wanted to dig into it a little bit more, went to Google, worked on way more projects,

22
00:02:25,760 --> 00:02:35,600
linked to GPR compliance, user experience, ads policy, and all around data labeling. And I got

23
00:02:35,600 --> 00:02:42,560
hooked. So I went to Amazon, stayed there for four years, working data labeling operation as well,

24
00:02:42,560 --> 00:02:48,640
helping Amazonian team with their machine learning projects. Got lucky to work on a lot of

25
00:02:48,640 --> 00:02:57,440
different projects, pertaining to different formats like video image, text. And then after four years,

26
00:02:57,440 --> 00:03:04,480
went to label box, when they were still Series A. And I was the director of labeling operation

27
00:03:04,480 --> 00:03:11,120
over there for a couple of years. And then joined ML Twist a few months ago as their chief operating

28
00:03:11,120 --> 00:03:16,560
officer. Awesome, awesome. Why don't you give us a quick summary of ML twist? Sure.

29
00:03:16,560 --> 00:03:26,320
So really, ML Twist is coming from GID that they are the space in the data labeling space for

30
00:03:26,320 --> 00:03:32,080
machine learning is very crowded at the moment. There are so many different players on the market.

31
00:03:33,360 --> 00:03:39,520
And they're all offering different solutions. And they're like even newcomers on the market.

32
00:03:39,520 --> 00:03:45,520
So if you think about it, there are over 80 data labeling platforms out there. And so much more

33
00:03:45,520 --> 00:03:51,760
when it comes to workforce labeling companies. And now you have the newcomers that are the

34
00:03:51,760 --> 00:03:58,960
synthetic data platforms, the augmented data platform and so on and so on. And this is all great,

35
00:03:58,960 --> 00:04:04,320
all this technology is great, but they don't connect to each other in a very easy way. And they

36
00:04:04,320 --> 00:04:09,920
are like, it's pretty siloed. And a lot of them are even specializing certain verticals or

37
00:04:09,920 --> 00:04:18,160
in certain formats. And so GID behind ML Twist is to connect all this ecosystem and give companies

38
00:04:18,160 --> 00:04:27,360
the choice to use the right tool for the right use case. It's a kind of like middleware for

39
00:04:27,360 --> 00:04:36,240
your labeling software and systems. Yeah, we were called middleware. I think that's okay,

40
00:04:36,240 --> 00:04:42,320
that's okay to call us middleware. And really like the idea is to, you know, be the glue

41
00:04:42,880 --> 00:04:48,720
and connect all the different tooling so that like data science team doesn't spend time looking

42
00:04:48,720 --> 00:04:54,720
for the right tool, the right workforce, the right everything and just easily connect all the

43
00:04:54,720 --> 00:05:02,000
pieces of the puzzle together to get their machine learning model trained and performing at the

44
00:05:02,000 --> 00:05:09,360
right level. So let's maybe start by talking about some of the commonalities you've experienced

45
00:05:09,360 --> 00:05:18,080
as you've tackled labeling across many different companies and customers. What's the typical

46
00:05:18,080 --> 00:05:24,720
journey for an organization getting started with labeling? Yeah, that's a great question. So

47
00:05:25,600 --> 00:05:31,920
whether it's a small startup starting the ML journey or a big company who wants to enter the AI

48
00:05:31,920 --> 00:05:40,480
world, the journey is very similar. As I mentioned earlier, the space is very crowded with a lot of

49
00:05:40,480 --> 00:05:46,160
very great tools on the market. And the idea for these companies that just start their journey

50
00:05:46,160 --> 00:05:51,120
is that they don't have a data labeling operation person in house. Usually data scientists,

51
00:05:51,120 --> 00:05:56,720
machine learning engineers or product managers are the ones like who are really trying to get

52
00:05:56,720 --> 00:06:03,360
all the right pieces in place. And without any knowledge, without any background, it's quite

53
00:06:03,360 --> 00:06:11,840
overwhelming to go after it and you have to find your right data labeling tool. And as I said,

54
00:06:11,840 --> 00:06:16,320
there are many on the market which one is the best one for your use case and then the right

55
00:06:16,320 --> 00:06:21,600
workforce and depending on what you want to label, each workforce is going to have their own

56
00:06:21,600 --> 00:06:28,960
strengths and their own weaknesses. So like you have to find, assess them and then make your

57
00:06:28,960 --> 00:06:34,000
own choice and selection. And that's just it takes time. It takes like probably a few months to

58
00:06:34,000 --> 00:06:39,200
get there. And once you get that in place, there is also the formatting issue, right? Because you

59
00:06:39,200 --> 00:06:45,280
have your data in house with a certain format and you need to connect that to the data labeling

60
00:06:45,280 --> 00:06:49,920
platform that you're going to be using. So data scientists are going to have constantly to change

61
00:06:49,920 --> 00:06:55,120
the format to be able to plug into the data labeling tool. And that's also another issue that

62
00:06:55,120 --> 00:07:00,960
needs to be tackled. So yeah, definitely you need to think about all the species and once you find

63
00:07:00,960 --> 00:07:07,200
the species and you connect them, you have to train, you have to create your task, put them on

64
00:07:07,200 --> 00:07:13,360
the platform, train the workforce on the task and go quality control, look at the quality because

65
00:07:13,360 --> 00:07:19,120
it's not only about maintaining, like sorry, it's not about just reaching the high quality of

66
00:07:19,120 --> 00:07:24,640
your data, it's also maintaining it as you go through all your rounds of data labeling. And

67
00:07:24,640 --> 00:07:31,440
that can be very challenging. In the early days of labeling when folks would use, you know,

68
00:07:31,440 --> 00:07:39,440
crowdsource, like commoditized crowdsource platforms, like mechanical Turk, you know, data quality

69
00:07:40,080 --> 00:07:46,560
was and continues to be a huge issue. And you know, folks would do like, have multiple lablers and

70
00:07:46,560 --> 00:07:57,040
try to kind of abstract away from the individual labeler to achieve levels of quality. You know,

71
00:07:57,040 --> 00:08:01,040
when you're using one of these labeling services, is that done for you? Or are you still

72
00:08:01,840 --> 00:08:08,080
having to kind of manually implement these kinds of tricks in order to achieve high quality labels?

73
00:08:08,080 --> 00:08:12,160
So you still have to do that, unfortunately, like the idea is that, you know,

74
00:08:12,160 --> 00:08:17,520
the mist that you can just like create a task and then set it up on the platform and have

75
00:08:18,880 --> 00:08:25,600
lablers in another part of the world, being able to nail it from the first pass is like,

76
00:08:25,600 --> 00:08:31,760
it's not gonna work. It can work. So crowdsourcing is a great option. Definitely when it comes to

77
00:08:31,760 --> 00:08:37,520
easy task, to task where you think that the knowledge is universal, right? Like is there a dog or

78
00:08:37,520 --> 00:08:43,040
is there a cat on the picture? You can trust anyone to know the difference. When it comes to complex

79
00:08:43,040 --> 00:08:48,160
tasks, then you need guidelines. You need rules in place that you're gonna train people on so that

80
00:08:48,160 --> 00:08:55,600
they can again annotate with high quality, but also consistently. And that's part of the challenge.

81
00:08:55,600 --> 00:09:01,120
And that means that companies going through that journey have to accept that feedback is

82
00:09:01,120 --> 00:09:06,640
very important on the top of quality control. They need to train the people. It's like going to

83
00:09:06,640 --> 00:09:12,880
school. You can't know like first you train and then you get tested and then you can you can

84
00:09:12,880 --> 00:09:20,160
deliver high quality data. And that's exactly the mindset that companies should use when they

85
00:09:20,160 --> 00:09:26,720
start working with outsourced labelling workforces. I had a really interesting conversation recently

86
00:09:26,720 --> 00:09:35,280
as part of this series with Cheyne Mahanti at Watchful. And we were talking about this same

87
00:09:35,280 --> 00:09:46,160
journey. And in particular, when companies do labelling inside in-house versus one to outsource

88
00:09:46,160 --> 00:09:54,080
it. And the key idea that he raised was this idea of context. Like you can outsource when

89
00:09:55,680 --> 00:10:02,800
there's no context required to correctly label. Like you said, you know, anyone can know a dog

90
00:10:02,800 --> 00:10:10,400
from a cat or even, you know, a stop sign on a road. But if, you know, some deep business

91
00:10:10,400 --> 00:10:15,760
context is required, you know, that is going to have to be done in-house. Is that your experience

92
00:10:15,760 --> 00:10:24,480
as well? Not exactly. So I had a chance over the years to test some of those ideas. And we were

93
00:10:24,480 --> 00:10:30,480
even able to test. So companies were coming to us and asking us, look, I really need doctors

94
00:10:30,480 --> 00:10:37,520
to annotate my data because that requires medical knowledge. And on the side, we were testing

95
00:10:37,520 --> 00:10:41,680
something else. We were saying, okay, let's do it with doctors. But let's do it also with

96
00:10:41,680 --> 00:10:47,680
regular laborers. And maybe a doctor comes in and train the people on what to do and what to

97
00:10:47,680 --> 00:10:56,960
recognize. And actually, we got pretty similar quality from boss ranges. So it doesn't have to be

98
00:10:56,960 --> 00:11:04,880
all, you know, done internally because these people have the right knowledge. It can be that we

99
00:11:04,880 --> 00:11:11,360
are able to transfer the knowledge. It might take longer, but we can get to very similar quality

100
00:11:11,360 --> 00:11:19,040
over time. That's going to be tremendously less expensive because of that. So that there are

101
00:11:19,040 --> 00:11:25,200
pros and cons, but it's not entirely true for my experience. But it sounds like you have to be

102
00:11:25,200 --> 00:11:33,520
committed to that training and knowledge transfer and feedback loop in order to achieve the

103
00:11:33,520 --> 00:11:40,960
level of quality you'd want with non-subject matter expert laborers. Exactly. And then that's

104
00:11:40,960 --> 00:11:46,400
where every company is going to make a choice. If they have to get a very fast turnaround time

105
00:11:46,400 --> 00:11:51,840
with high quality, obviously, you have to go with an internal team that's going to be very

106
00:11:51,840 --> 00:11:58,800
knowledgeable on the topic they are labeling. But if you have a bit of time and if your cost

107
00:11:58,800 --> 00:12:04,480
sensitive, then you might go the other route, take a bit longer, but get to the same quality

108
00:12:04,480 --> 00:12:12,240
after a while. Yes, maybe continue on this training, this training angle are there. Things that

109
00:12:12,240 --> 00:12:20,000
you've learned about how to effectively train and support laborers in the process.

110
00:12:20,000 --> 00:12:26,880
Yes, absolutely. I think that as a data labeling operation, people really like one of the

111
00:12:26,880 --> 00:12:33,760
skills that you have to master is being able to translate technical requirements into simple

112
00:12:33,760 --> 00:12:38,880
task. And that's really like what it is about. When you get to talk to machine learning engineers

113
00:12:38,880 --> 00:12:44,400
or data scientists about what they want, what the image in that the task should be about and

114
00:12:44,400 --> 00:12:50,880
how to handle it and so on. It can be very confusing and it can go like in a different places

115
00:12:50,880 --> 00:12:58,560
at the same time. So Jager is to get all these requirements and put them on paper and get Jager,

116
00:12:58,560 --> 00:13:04,400
okay, what do they really want and make it as simple as possible when you translate that into

117
00:13:04,400 --> 00:13:12,480
guidelines that's going to be helping the team getting trained on the task. So really,

118
00:13:12,480 --> 00:13:19,760
that's actually something I learned doing over the years is that you have to translate,

119
00:13:19,760 --> 00:13:26,960
you have to think as a labeler that has no technical background and tell them what they need to do.

120
00:13:26,960 --> 00:13:34,640
And one thing I really like doing with the labelers is once they have worked on a product for months,

121
00:13:35,680 --> 00:13:41,120
giving them more context about why they are doing that is very important because that give them

122
00:13:41,120 --> 00:13:46,640
the purpose of why they are doing this task on a daily basis. Once the product has been released

123
00:13:46,640 --> 00:13:53,040
publicly and there is like press release or a website talking about it, I love sending that

124
00:13:53,040 --> 00:13:58,000
to the laboring team that worked on it so that they really understand and they can really see

125
00:13:58,000 --> 00:14:04,960
and share like the success of the product. To help them be part of the team. Exactly.

126
00:14:04,960 --> 00:14:12,080
Can you maybe give us an example of, you know, when you think of kind of the most complex

127
00:14:12,080 --> 00:14:18,400
labeling tasks that you've tackled, give us an example of one of those and some of the things

128
00:14:18,400 --> 00:14:26,320
that you did from a training and support perspective to help that team be successful.

129
00:14:26,320 --> 00:14:36,480
One of the most complex use cases I worked on was like touching to augmented reality. I worked on like

130
00:14:38,160 --> 00:14:44,400
J.J. about having an item that would be you would be able to see in your living room with like

131
00:14:44,400 --> 00:14:50,400
the real size to see if you would like to buy this couch or this lamp or this kettle and that

132
00:14:50,400 --> 00:14:58,640
was actually a very complex workflow. The task in itself was not super complex but on my end,

133
00:14:58,640 --> 00:15:03,920
you know, like on the labeling operation side of things that was very complicated because

134
00:15:03,920 --> 00:15:10,000
of the technology that we were using, we were not able to use any item that we had. We couldn't

135
00:15:10,000 --> 00:15:18,480
like for instance have some sort of spiky item going through that technology that would render

136
00:15:18,480 --> 00:15:25,840
this like a vision of the of this item. So there was like this like all selection of the items

137
00:15:25,840 --> 00:15:31,680
that could go through that technology that we were using and then you would have to after that

138
00:15:33,120 --> 00:15:39,040
talk with the product management team that had like all these like dates to release all these

139
00:15:39,040 --> 00:15:44,960
products so that they could be available on the marketplace and so we had to juggle all of

140
00:15:44,960 --> 00:15:50,800
this like huge volume and at the same time quality issues that were happening. On the top of that

141
00:15:50,800 --> 00:15:57,680
once there was the ear reproduction of the item like some of them were not good at all and that

142
00:15:57,680 --> 00:16:02,560
couldn't be publicly released on the website so we had to go through some quality control.

143
00:16:02,560 --> 00:16:11,920
Anyway, the entire workflow was very complex and was handled by a lot of different stakeholders,

144
00:16:11,920 --> 00:16:20,720
a lot of different teams inside and outside of the company and that was pretty stressful to handle

145
00:16:20,720 --> 00:16:29,040
but that worked really well in gym. It sounds like one of the takeaways there is that

146
00:16:30,240 --> 00:16:38,720
just the place of labeling in the overall kind of process of delivering a product it's

147
00:16:38,720 --> 00:16:44,720
you know maybe easy to think of hey you know before you start this project you've got this big

148
00:16:44,720 --> 00:16:50,560
data set you send it off to some labelers you know you get back you know a label data set and then

149
00:16:50,560 --> 00:16:57,120
you kind of start with the product of productizing or building whatever you want but it sounds like

150
00:16:57,120 --> 00:17:02,800
at least in the case of this workflow that you're describing you were kind of in the loop of

151
00:17:02,800 --> 00:17:11,200
productizing this ARVR experience and you know the the things that you were the challenges that you

152
00:17:11,200 --> 00:17:17,280
were experiencing just related to the complexity of delivering the product overall.

153
00:17:17,280 --> 00:17:23,280
Yeah that's that's very true and I think that's like really the the core of the data labeling

154
00:17:23,280 --> 00:17:29,360
operation team is that is that we are in the middle we are not we can be at the start of it but

155
00:17:29,360 --> 00:17:34,160
there is always this idea that there is a product that's going to be released at the end and

156
00:17:34,160 --> 00:17:39,680
what does that mean is that as a data labeling operation person you are dealing with humans you are

157
00:17:39,680 --> 00:17:44,880
dealing with like you know a labeling team you are dealing with the product managers you are

158
00:17:44,880 --> 00:17:51,200
dealing like with so many people having their own requirements but also their own limitations

159
00:17:51,200 --> 00:17:55,840
and you have to juggle all of that to make sure that the product is going to be released on time

160
00:17:55,840 --> 00:18:04,320
and that's true whether or not you are data labeling operation team internally or you are just

161
00:18:04,320 --> 00:18:10,320
you know like these companies outsourcing all of that piece this is this is very central to the

162
00:18:10,320 --> 00:18:16,160
success of a product release for sure. You've mentioned data labeling operations a few times

163
00:18:16,160 --> 00:18:26,000
you know how how kind of ubiquitous and mature is that as a role a job title a function

164
00:18:26,000 --> 00:18:34,400
the most large organizations that are you know have a significant investment in ML and labeling

165
00:18:34,400 --> 00:18:42,640
you know have that team in place. That's a really good question I think that I was really at the

166
00:18:42,640 --> 00:18:49,840
early stage of that that journey like data labeling operation when I started I mean I got lucky

167
00:18:49,840 --> 00:18:57,360
right because basically there was no knowledge or degree in data labeling operation and so they

168
00:18:57,360 --> 00:19:05,520
were opening the doors to anyone who wanted to give it a try and so as the years go by now you get

169
00:19:05,520 --> 00:19:10,880
people who have been in the space for a few years like I've been in the space for the past seven years

170
00:19:10,880 --> 00:19:16,800
and that's the type of people that you want to have if you want to lead data labeling operation

171
00:19:16,800 --> 00:19:26,720
team at the big company and additionally like the complexity of the data labeling space not only

172
00:19:26,720 --> 00:19:31,920
in the ecosystem as I mentioned earlier there are so many players on the market right now but also

173
00:19:31,920 --> 00:19:39,920
the complexity of the labeling tasks themselves all of that have grown exponentially over the years

174
00:19:39,920 --> 00:19:47,040
and that's just like you you need people who are specialized in the domain to make the right

175
00:19:47,040 --> 00:19:54,960
decision but also to make decision very fast and that's still not completely I think understood

176
00:19:56,800 --> 00:20:01,600
but we're coming we're getting there I see more and more people with like you know a lot of

177
00:20:01,600 --> 00:20:06,800
experience getting hired to other places so there is this idea now that you're looking for people

178
00:20:06,800 --> 00:20:14,080
with experience in the data labeling but now you know when you start up or when you only start

179
00:20:14,080 --> 00:20:19,840
your journey you don't have that in house you I think it takes a little bit of time to to to

180
00:20:19,840 --> 00:20:26,000
realize that this is a nation and it's a short wall in the in the entire AI loop you mentioned that

181
00:20:26,000 --> 00:20:30,960
when you started there was no degree program is there now or have you seen like certifications or

182
00:20:30,960 --> 00:20:38,640
that kind of I know not yet but I think I think it's going to happen in the in the next few years

183
00:20:38,640 --> 00:20:45,840
I think it has to happen that has become its own specialty and and I really truly believe that

184
00:20:45,840 --> 00:20:53,520
it's going to happen soon so if you're in this role if you're the the data labeling ops team

185
00:20:53,520 --> 00:20:59,280
and you know you're at a larger company that has multiple projects and you're approached with a

186
00:20:59,280 --> 00:21:08,000
new project you know walk us through kind of the steps of onboarding a new a new project or initiative

187
00:21:08,000 --> 00:21:12,080
or customer however you would think about it what are the things you're thinking of what are the

188
00:21:12,080 --> 00:21:18,400
things you're asking them for and just kind of how do you think about kind of spinning up a new

189
00:21:18,400 --> 00:21:22,480
effort basically you need to talk to the machine learning engineers you need to talk to the

190
00:21:22,480 --> 00:21:28,720
scientists and understand their needs what are they looking to accomplish with that labeling task what

191
00:21:28,720 --> 00:21:36,480
is their model about what do they want to recognize or predict with that model that they are they

192
00:21:36,480 --> 00:21:42,480
want to get the data for that's really what's going to help make sure that you're going to get the

193
00:21:42,480 --> 00:21:48,320
right task to the laborer so that you can get the right data labored and then you're going to be

194
00:21:48,320 --> 00:21:53,280
able to feed your model and train it so really there is this discussion on like where they want to go

195
00:21:53,280 --> 00:21:58,960
and then once you frame it you talk about the task and either they have already an idea about the

196
00:21:58,960 --> 00:22:05,440
task or they don't they can just tell you you know I have 50,000 images of dresses and I want to

197
00:22:05,440 --> 00:22:11,520
recognize all the attributes on the dress do it good luck I need that for like in three months time

198
00:22:11,520 --> 00:22:18,080
and then you go about it and then so the idea is to show them the task that you're going to be

199
00:22:18,080 --> 00:22:24,880
creating the guidelines that will go with it but also like the examples that you're going to give

200
00:22:24,880 --> 00:22:31,200
because the the best way to train labeling team on a task is to show them example about how to

201
00:22:31,200 --> 00:22:39,440
train so about how to label a specific task so what I used to do for instance even at amazon is

202
00:22:39,440 --> 00:22:46,000
create my own task and then work on it myself label a few images myself to see if that was making

203
00:22:46,000 --> 00:22:51,280
sense if I was covering all the different use cases and once it was done I was submitting it to the

204
00:22:51,280 --> 00:22:56,160
machine learning team they were telling me if they like it or not if that works for them and then

205
00:22:56,160 --> 00:23:02,640
from there I would train the team and that goes back to what I was talking about which is feedback

206
00:23:02,640 --> 00:23:07,760
loop tell the machine learning engineers hey you're going to have to do some quality control

207
00:23:07,760 --> 00:23:15,040
after the first pass to see if what you're getting is what you want or not give feedback and so on

208
00:23:15,040 --> 00:23:22,560
and so on so JJ is to have like a great relationship with the technical team and just like you know

209
00:23:22,560 --> 00:23:29,360
give them in advance the knowledge get them used to the fact that it's not going to be one one

210
00:23:29,360 --> 00:23:36,240
of thing that's going to be a project that's going to be on and on that's going to be very repetitive

211
00:23:36,240 --> 00:23:42,320
but that we will be there to help them get there with high quality annotations and a lot of

212
00:23:42,320 --> 00:23:47,600
ways it sounds like a product management type of role like you're the labeling product manager

213
00:23:47,600 --> 00:23:54,160
yeah yeah I like that idea a lot of a lot of people doing labeling operations some like they end

214
00:23:54,160 --> 00:24:02,320
up also being product managers for machine learning products that's correct so you've you've developed

215
00:24:02,320 --> 00:24:11,680
this task and you've got this feedback loop you know it sounds like the task will often evolve

216
00:24:11,680 --> 00:24:17,680
quite a bit from what you originally thought it should be to you know what you what you do at scale

217
00:24:17,680 --> 00:24:22,480
can you talk a little bit about that evolution yeah I think it's very important to keep in mind that

218
00:24:22,480 --> 00:24:28,800
there will be a feedback loop and and that's what I was trying to to say earlier is that you know

219
00:24:28,800 --> 00:24:32,320
like you're you're going to have two types of feedback loops basically you're going to have the one

220
00:24:32,320 --> 00:24:36,960
that's going to be about training the laborers making sure they understand your requirements

221
00:24:36,960 --> 00:24:43,200
making sure that they are reaching the the right quality and once you get there you're going to get

222
00:24:43,200 --> 00:24:48,000
your data back and then what happens is that you're going to feed your model with that with that

223
00:24:48,000 --> 00:24:54,400
data and that's why you're going to realize that that your model is responding well to everything

224
00:24:54,400 --> 00:25:00,080
that's supposed to be doing or sometimes it's responding well to some areas but not to others

225
00:25:00,080 --> 00:25:04,720
and then in that case that's actually a feedback loop that's sent to the data science team

226
00:25:04,720 --> 00:25:09,520
so that they know that they need to be framed and reworked that task to cover those areas that

227
00:25:09,520 --> 00:25:15,120
were not working well when they tested their model and so again you get into another task that

228
00:25:15,120 --> 00:25:19,760
you're going to train the laborers on and you're going to give them another feedback loop and so on

229
00:25:19,760 --> 00:25:26,800
and so on so are there some common ways that tasks evolve I imagine you know if you've

230
00:25:27,520 --> 00:25:32,880
if you've done similar types of use cases you know an engineering team may you know

231
00:25:32,880 --> 00:25:37,120
habitually come to you and say I want this and you say no you really don't want that because

232
00:25:37,120 --> 00:25:42,800
you're going to end up changing it to to something else because you've just seen over and over

233
00:25:42,800 --> 00:25:47,760
it doesn't work the way that that they think but I'm wondering if there are examples of

234
00:25:47,760 --> 00:25:56,480
you know those kinds of evolutions or transitions where you know that a task starts out as

235
00:25:56,480 --> 00:26:03,440
as X and ends up evolving to Y for whatever reasons I would say yes I'm trying to think about an

236
00:26:03,440 --> 00:26:10,560
example but that's not coming to my mind right now but I I would say what what really blew my

237
00:26:10,560 --> 00:26:16,160
mind over the years is that I've seen a lot of different companies going after the same

238
00:26:16,160 --> 00:26:23,360
problem trying to solve it and they were doing it in a very different way which was also like very

239
00:26:24,160 --> 00:26:31,600
very intriguing for me because I was like I saw that okay you want to recognize that and

240
00:26:33,600 --> 00:26:37,760
the machine learning teams are going to be convinced that the way they are going about it is

241
00:26:37,760 --> 00:26:46,320
the right way and and and actually that's where like it creates like even more like complexity

242
00:26:46,320 --> 00:26:52,240
into that space is that there are like a lot of different ways to tackle a problem exactly the

243
00:26:52,240 --> 00:26:57,200
same problem so that I've seen a lot for sure so we've talked about setting up these tasks

244
00:26:59,120 --> 00:27:05,200
we've talked about the the training part is there an element of workforce selection

245
00:27:05,200 --> 00:27:13,360
that comes to bear when you're spinning up a new effort yes absolutely so as you like it depends

246
00:27:13,360 --> 00:27:20,080
on the task if you have a task that requires specific knowledge you want to find a workforce

247
00:27:20,080 --> 00:27:27,280
that's going to be able to get that type of special specialized people to work on the task whether

248
00:27:27,280 --> 00:27:31,840
or not it's to become labor laws or to be training the labor laws on the task

249
00:27:31,840 --> 00:27:40,400
that that's one now you can have also task that requires language skills and if you want to

250
00:27:40,400 --> 00:27:47,280
understand the context let's let's take the example of you know content moderation on on social

251
00:27:47,280 --> 00:27:53,360
major you can you you you want to do it on a lot of different languages not only in English so

252
00:27:53,360 --> 00:27:57,120
you're going to have to find a workforce that's going to be able to understand Spanish and

253
00:27:57,120 --> 00:28:05,200
Brazilian Portuguese and so on and because it's social major there is a cultural context to it

254
00:28:05,200 --> 00:28:11,920
it's not only knowing or understanding Spanish it's also understanding the context of the country

255
00:28:11,920 --> 00:28:18,560
right like why would they talk about this politician and and so on and so on and and so that's

256
00:28:18,560 --> 00:28:25,520
where like it becomes very tricky to have only one workforce to do all your needs if you have a

257
00:28:25,520 --> 00:28:30,640
lot of different needs you're going to have to have a portfolio of workforces that you're going to

258
00:28:30,640 --> 00:28:37,440
be obviously testing before partnering with them but that will be helping you with all your

259
00:28:37,440 --> 00:28:43,120
different data labeling needs and sometimes it's even like better to have workforces from

260
00:28:43,120 --> 00:28:47,920
different parts of the world because they're going to be able to see things with a different angle

261
00:28:47,920 --> 00:28:52,160
now when you look at the various labeling company websites they all

262
00:28:52,160 --> 00:29:00,080
you know portray themselves as solving all the problems you know with equal level of excellence

263
00:29:00,080 --> 00:29:06,400
and they all want to kind of be the one stop shop but it sounds like your experience is that

264
00:29:06,400 --> 00:29:13,440
that's not really the case and it does it shouldn't necessarily be the case I think that it was

265
00:29:13,440 --> 00:29:20,800
probably true a few years back when you were mentioning mechanical talk or like maybe there was

266
00:29:20,800 --> 00:29:27,120
like crowd flower at the time like it was just like the space was like very new there were

267
00:29:27,120 --> 00:29:32,640
very few players and and you had to go to one of them to make it work somehow or even you have

268
00:29:32,640 --> 00:29:38,080
the idea about having companies that were bridging their own in-house labeling tool because they

269
00:29:38,080 --> 00:29:44,080
couldn't find anything that was working for them on the market I mean even Elon Musk just said

270
00:29:44,080 --> 00:29:48,480
that on the podcast recently that they had to build their own data labeling platform so

271
00:29:48,480 --> 00:29:55,840
it's it's I in my experience I don't think it's true anymore because what happens is that

272
00:29:55,840 --> 00:30:02,960
companies are going with one data labeling tool and one workforce and they try and and we know

273
00:30:02,960 --> 00:30:07,920
why because it's so difficult to get all the species together it's so time consuming and

274
00:30:08,560 --> 00:30:12,800
like as I said earlier these people are data scientists they should be working on models they

275
00:30:12,800 --> 00:30:20,160
shouldn't be working on finding the right partners but they do that and then and then all of a sudden

276
00:30:20,160 --> 00:30:27,680
the quality drops all of a sudden the cost gets higher or the turnaround time is not good enough

277
00:30:27,680 --> 00:30:32,400
and then everything it's kind of like falling apart but you know you don't want to go through that

278
00:30:32,400 --> 00:30:40,800
process all over again it's it's so time consuming to find another another partner so I believe yes

279
00:30:40,800 --> 00:30:47,840
the JECO system is is is great right now it's crowded but in a good way meaning that there are

280
00:30:47,840 --> 00:30:54,240
so many options on the market that a company doesn't need to choose one option they can just play

281
00:30:54,240 --> 00:30:58,560
with them depending on what they need at the moment they need it depending on the model they're

282
00:30:58,560 --> 00:31:05,600
working on I think that we need to keep in mind that nowadays companies have not not one model in

283
00:31:05,600 --> 00:31:11,360
house they have hundreds of models that they need to work on with different formats and and and

284
00:31:11,360 --> 00:31:18,560
thinking that there will be one stop shop I think is is something that's going to be hard to to

285
00:31:18,560 --> 00:31:27,680
believe moving forward you mentioned that you've seen kind of this recurring pattern of when you're

286
00:31:27,680 --> 00:31:35,600
working with a vendor at some point the quality drops off and the turnaround time gets extended

287
00:31:35,600 --> 00:31:41,200
and that kind of thing is that is there something inherent about labeling the causes that to happen

288
00:31:41,200 --> 00:31:47,120
or is it more kind of just working with a vendor and they're really focused on the new customer and

289
00:31:47,120 --> 00:31:53,360
they kind of let the the older customers languish a little bit I think yeah part of it is working

290
00:31:53,360 --> 00:31:58,080
with human beings like it's you know like you're not like working with tech you're working with

291
00:31:58,080 --> 00:32:04,640
people and they have lives and they have issues and they get sick and you know so we have to take

292
00:32:04,640 --> 00:32:13,200
that into account again like the idea about having like this like data labeled very fast with very

293
00:32:13,200 --> 00:32:19,280
good quality it's going to be hard to maintain that over weeks and weeks just because

294
00:32:19,280 --> 00:32:27,200
you are dealing with human people and and human beings and most of the time this this like

295
00:32:27,200 --> 00:32:32,640
workforce labeling partners they are doing the best they can and they they want to do a good job

296
00:32:32,640 --> 00:32:37,600
and and that's just that sometimes it's very hard that's the nature of the business and I think

297
00:32:37,600 --> 00:32:45,440
we need to keep that in mind when we are using one of those partners is that I think you're you've kind

298
00:32:45,440 --> 00:32:54,480
of your your answer kind of suggests this but it is a big part of your experience in this label

299
00:32:54,480 --> 00:33:01,440
ops role helping you know engineers understand that there are humans on the other side of this

300
00:33:01,440 --> 00:33:07,200
API that you know the labeling companies kind of position themselves as like this API that

301
00:33:07,200 --> 00:33:12,400
abstracts the messiness of labeling do you think that that also abstracts away from the humans on

302
00:33:12,400 --> 00:33:17,120
the other side of those APIs and that's a big part of the role is helping them understand that

303
00:33:17,120 --> 00:33:24,800
I think it's trying to juggle like what's going on on like every side of the you know the workflow

304
00:33:24,800 --> 00:33:30,480
so yes it's like talking to machine learning engineers and and educating them on how it works and

305
00:33:30,480 --> 00:33:35,360
how quality is going to be rich and how quality is going to be maintained that it takes time

306
00:33:35,360 --> 00:33:40,960
but in the end they're going to gain from it so Jager that like you know they understand a

307
00:33:40,960 --> 00:33:47,440
bit more what's going on in this entire loop that's not only tech but are so human beings involved

308
00:33:47,440 --> 00:33:54,000
in the process and on the other end like trying also to juggle you know what's happening with

309
00:33:54,000 --> 00:34:00,160
the data labeling companies and and see how I can help them and that happens a lot that we have

310
00:34:00,160 --> 00:34:04,960
discussions with them about how they can have a better workflow how they can have a better

311
00:34:04,960 --> 00:34:11,520
QA process in place so that there is not a need for too many feedback loops so it's kind of like

312
00:34:11,520 --> 00:34:19,360
understanding what's happening you know in the entire workflow and find a way to make it work

313
00:34:19,360 --> 00:34:25,920
at the best the best the best you can if we haven't talked much about tooling uh obviously

314
00:34:25,920 --> 00:34:31,600
important part of the overall workflow how have you seen that evolve over the years

315
00:34:31,600 --> 00:34:37,440
when when I started a lot of the tasks were bound in boxes so really like you didn't have to have

316
00:34:37,440 --> 00:34:44,800
very high tech tooling to make it work into the machine learning world but over the years I've

317
00:34:44,800 --> 00:34:52,480
seen so many data labeling platform trying to become more sophisticated trying to respond to

318
00:34:52,480 --> 00:34:58,960
special needs from certain machine learning companies they have like very great features they

319
00:34:58,960 --> 00:35:05,200
can do segmentation they can do relationship between worlds like in a text it has become very

320
00:35:05,200 --> 00:35:13,040
sophisticated and all these companies are tacking in a different way I would say which is very

321
00:35:13,040 --> 00:35:22,080
interesting to see and they they are like pretty some of them are even like really good for certain

322
00:35:22,080 --> 00:35:30,480
verticals but not for others or certain format but not for others so definitely data labeling

323
00:35:30,480 --> 00:35:35,520
as become more and more complex and if you add on the top the new comments as I mentioned earlier

324
00:35:35,520 --> 00:35:42,400
about synthetic data or augmented data then it becomes even more complex so really there is a lot

325
00:35:43,120 --> 00:35:48,640
to play with and it's just a connection of being able to select the right one and to connect

326
00:35:48,640 --> 00:35:57,440
them with each other when you need it talk a little bit about measuring quality for labeling

327
00:35:57,440 --> 00:36:07,040
efforts so I mean you know quality everyone wants to reach 100% I I talk to people who are saying

328
00:36:07,040 --> 00:36:16,160
well I don't want anything else than 99 or 100% that's that's a that's a bit complicated to reach

329
00:36:16,160 --> 00:36:24,720
but the idea is to be able to check the quality and you have to do it regularly once once you

330
00:36:24,720 --> 00:36:28,880
able to check the quality of the work that has been done by the laborers what does that mean is

331
00:36:28,880 --> 00:36:34,160
that you're going to have a sample of your data that you're going to look at and you're going to

332
00:36:34,160 --> 00:36:39,920
look let's say you look at 100 images and you know 95 of them have been labeled correctly

333
00:36:39,920 --> 00:36:46,080
so you have a 99 95% accuracy rate you're happy with that right like how you're going to maintain

334
00:36:46,080 --> 00:36:52,080
that accuracy level weeks after weeks and I think again it goes back to what I was talking about

335
00:36:52,080 --> 00:36:57,440
which is the feedback loop you want to make sure that you keep an eye on the quality again you're

336
00:36:57,440 --> 00:37:03,440
working with people who are labeling even though they are using like performant tooling in the end

337
00:37:03,440 --> 00:37:08,960
if you don't have a good labeling workforce doing the labeling correctly the quality is going

338
00:37:08,960 --> 00:37:17,440
is not going to be good so so really like the idea is to being able to do the quality control

339
00:37:17,440 --> 00:37:22,560
regularly and make sure that if you see that something is dropping you are able to address it

340
00:37:22,560 --> 00:37:29,440
as soon as possible so that the laborers can retrain and can perform well moving forward and

341
00:37:29,440 --> 00:37:36,400
even correct the laborers that were done incorrectly in the past so yeah it goes back to this idea about

342
00:37:36,400 --> 00:37:48,000
this cycle of quality control and is that is that quality control being measured against

343
00:37:50,160 --> 00:37:56,160
you know kind of what's that process is it you know having internal folks spot check or

344
00:37:57,040 --> 00:38:04,560
you know where does that that come from yeah so everyone is going to get it in a different way but

345
00:38:04,560 --> 00:38:12,320
ideally I think as you mentioned earlier the internal you know laborers in a company are going to

346
00:38:12,320 --> 00:38:18,880
be the one with most of the knowledge and ideally you would use those people for QA you would use

347
00:38:18,880 --> 00:38:25,040
those people to check the quality of the work that has been outsourced to make sure that it's

348
00:38:25,040 --> 00:38:30,080
maintained but also to give some feedback and retrain more than anything else because

349
00:38:30,080 --> 00:38:36,800
cost wise it probably makes more sense to do it that way than to have like an army of people in

350
00:38:36,800 --> 00:38:44,240
house that would do the the whole labeling and the whole QA and are there established kind of norms

351
00:38:44,240 --> 00:38:48,640
about you know what percentage of labels you want a spot check or that kind of thing

352
00:38:49,600 --> 00:38:59,200
there are a lot of opinions on that what I've been taught over the years is that if you look at

353
00:38:59,200 --> 00:39:05,840
a hundred every every other day you're going to be able to have a good idea about what's going on

354
00:39:05,840 --> 00:39:11,680
even if it's like 10,000 images that have been labeled that's still going to give you a good idea

355
00:39:11,680 --> 00:39:16,800
about what's going on in your data sets okay so it sounds you know in some ways it's less about

356
00:39:17,520 --> 00:39:24,080
um you know establishing kind of statistical significance of sampling or anything like that

357
00:39:24,080 --> 00:39:32,640
more about just having a feel for how it's going yeah and it has to be done regularly so um

358
00:39:32,640 --> 00:39:37,600
obviously if you do that you know once a month you're not going to get a good idea about it but

359
00:39:37,600 --> 00:39:41,680
if you do it like every other day you're going to have a really good idea about what's going on

360
00:39:41,680 --> 00:39:51,840
definitely mm-hmm and I asked this question earlier I want to re-ask it you know when you see a drop

361
00:39:51,840 --> 00:40:00,640
in quality you know it sounds like one of the tools uh in your toolbox is training and feedback

362
00:40:00,640 --> 00:40:07,760
and and that kind of thing you know how often are you implementing strategies like you know

363
00:40:07,760 --> 00:40:14,800
aggregating labelers uh and taking a quorum that kind of thing versus you know training and

364
00:40:14,800 --> 00:40:20,640
what's the thought process around you know these kinds of strategies yeah absolutely that's a really

365
00:40:20,640 --> 00:40:26,720
good question uh definitely they're like different ways to go about um you know making sure that

366
00:40:26,720 --> 00:40:32,560
quality is going to be high so on one of the projects I worked on in the past the idea is to have

367
00:40:33,280 --> 00:40:39,840
we were like having uh several people on the same image at the same time and uh you know like

368
00:40:39,840 --> 00:40:44,160
if we had like three agreements on the way they were labeling if the three people were

369
00:40:44,160 --> 00:40:50,640
labeling the same way then we were considering it as correct even if you were not eyeballing the data

370
00:40:50,640 --> 00:40:58,480
that was delivered um and we were doing that as long as the quality was not great and was not

371
00:40:58,480 --> 00:41:04,560
maintained and once it was done we were dropping from like three people to two people and then from

372
00:41:04,560 --> 00:41:11,280
two people two people to one person and why we had to do that it's a question of budget right so

373
00:41:11,280 --> 00:41:19,760
you have to be able to balance um you're like search for like quality and and the money you have

374
00:41:19,760 --> 00:41:24,400
to spend on it right if you get three people per image obviously it's going to cost way more

375
00:41:24,400 --> 00:41:31,600
but that's also a good way about doing crowdsourcing right if you go into uh use mechanical

376
00:41:31,600 --> 00:41:37,440
torque or happen and you have three people on the same image even though you feel that the

377
00:41:37,440 --> 00:41:42,800
knowledge is probably you know you don't you're not sure if people know about what they are labeling

378
00:41:42,800 --> 00:41:50,400
you can have like certain degree of um certainty that this is correct if three people out of three

379
00:41:50,400 --> 00:41:55,040
are responding the same way so you're right they're like a lot of different ways to go about

380
00:41:55,040 --> 00:42:01,280
quality again depending on the complexity of the task the budget the turnaround time you're

381
00:42:01,280 --> 00:42:07,520
going to have to juggle all these options and find the best one for your your case how often is it

382
00:42:08,320 --> 00:42:17,840
you as the kind of data label ops on the customer side that is thinking about that and having

383
00:42:17,840 --> 00:42:24,880
to come up with the solution versus um you know the vendor that is you know promising to kind

384
00:42:24,880 --> 00:42:29,440
of manage the quality for you like how hands-on does quality management need to be

385
00:42:29,440 --> 00:42:36,240
I mean I'm pretty hands-on I would say I think I think that's where also it's one of the strengths of

386
00:42:36,240 --> 00:42:44,480
the data labeling oppression people is that they are um they can be like very objective in the way

387
00:42:44,480 --> 00:42:53,680
of doing things um so ideally like I mean I was the one proposing and there is this idea about

388
00:42:53,680 --> 00:42:58,960
also rejecting right like understand how much it's going to cost and how long it's going to take

389
00:42:58,960 --> 00:43:04,400
and they're like those three matrix that are really important that help you measure if your

390
00:43:04,400 --> 00:43:09,120
data labeling project have been successful or not uh it's obviously the quality of the data

391
00:43:10,240 --> 00:43:16,080
the turnaround time how fast they can deliver uh I have customers asking for a five minute turnaround

392
00:43:16,080 --> 00:43:21,440
time how do you get high quality with a five minute turnaround time when you have people who are trained

393
00:43:21,440 --> 00:43:26,720
and that are like on the other side of the world with like the time difference and so on um and

394
00:43:26,720 --> 00:43:33,920
then you have the budget how much money are you able to spend on data labeling and so um you have

395
00:43:33,920 --> 00:43:39,680
to take the three matrix into consideration each time that you are you know starting a data

396
00:43:39,680 --> 00:43:44,960
labeling project that's that's the only way you can understand fully what you want to do about it

397
00:43:44,960 --> 00:43:53,760
and in other areas of of tech and I guess life you have this classic like uh time cost quality

398
00:43:53,760 --> 00:44:02,160
pick any two does that idea recur in uh in labeling well I believe you can you you can reach three of

399
00:44:02,160 --> 00:44:07,440
them but obviously you're right like depending on the solution yes you're going to have to to

400
00:44:07,440 --> 00:44:13,600
privilege which of those two are the most important ones to you and then you you might be able to

401
00:44:13,600 --> 00:44:18,960
reach the third one as well but you need to be more flexible on the third one so for instance

402
00:44:18,960 --> 00:44:24,560
I'm going to give you an example if you use crowdsourcing uh for your labeling it's going to be

403
00:44:24,560 --> 00:44:32,160
super cheap uh you're going to have a fast turnaround time and quality hmm you're not 100% sure

404
00:44:32,160 --> 00:44:40,960
about it uh if you have an internal team doing the labeling super high quality but also super expensive

405
00:44:40,960 --> 00:44:46,800
and uh and the fast turnaround time it depends on the size of your team if you have five people

406
00:44:46,800 --> 00:44:51,760
they can do only what they can do you know during that day so they might not have a big volume

407
00:44:51,760 --> 00:44:58,720
done within 24 hours or week or so um so yes you're right each time there is like there are like

408
00:44:58,720 --> 00:45:04,400
several options and you have to write to think about what matters to you the most I love to get

409
00:45:04,400 --> 00:45:11,200
your take on the various ethical considerations with regards to labeling particularly with

410
00:45:11,200 --> 00:45:22,800
uh many of the the labeling workforces being uh remote and with um you know workforces that are

411
00:45:22,800 --> 00:45:31,680
used so much uh lower kind of income than you know in the in western countries um there have been

412
00:45:31,680 --> 00:45:38,080
some recent articles uh there's a wired article uh not wired it actually MIT tech review article by

413
00:45:38,080 --> 00:45:43,840
Karen how talking about how uh one of the label labeling companies was kind of taking about

414
00:45:43,840 --> 00:45:52,960
taking advantage of economic turmoil and Venezuela um and uh uh his Facebook is was getting sued

415
00:45:52,960 --> 00:46:00,160
by a labeling company in Kenya I think I watch how you kind of thought about and managed the various

416
00:46:00,160 --> 00:46:05,200
ethical considerations before answering your question I think I would like to ask two questions

417
00:46:05,200 --> 00:46:12,560
the first one is is like how does it work for outsourcing in general not only for data labeling but

418
00:46:12,560 --> 00:46:18,560
if you think about recycling we are doing that already in other domain in other verticals

419
00:46:19,120 --> 00:46:24,160
are we comfortable with it do we need to revisit but that's that's the bigger discussion that's

420
00:46:24,160 --> 00:46:30,880
broader discussion that we should probably have as well the second one is you're probably mentioning

421
00:46:30,880 --> 00:46:35,280
so data labeling in general but I think that the article was also mentioning content moderation

422
00:46:35,280 --> 00:46:40,000
because you can have like some disturbing content and that might affect you know psychologically

423
00:46:40,000 --> 00:46:49,200
some people um is it needed do we need content moderation I think as a parent myself I I want to

424
00:46:49,200 --> 00:46:54,640
feel that the internet is a bit safer for my kids uh and I want to have a choice to you know

425
00:46:54,640 --> 00:47:01,600
protect them if I can so in my view it's very important that we keep doing content moderation

426
00:47:02,320 --> 00:47:08,320
uh not not to answer and and one thing I would like to add is that I yes content moderation has

427
00:47:08,320 --> 00:47:14,400
been outsourced but it's not entirely outsourced I know for a fact that content moderation is

428
00:47:14,400 --> 00:47:23,120
currently done uh in the United States and also in Europe um so um the question and I've done

429
00:47:23,120 --> 00:47:29,360
I mean I when I work my first job I was not doing content moderation but I had some pretty

430
00:47:29,360 --> 00:47:35,840
disturbing things when I was doing the job and so you know it's it's unfortunately it's part of

431
00:47:35,840 --> 00:47:41,440
like the low income jobs in the data labeling space to jump in I think you know you're already

432
00:47:41,440 --> 00:47:50,000
raising uh uh several important issues one I think is that um you know there are

433
00:47:50,000 --> 00:47:58,000
multitude of potential issues it's not just one issue that and it's not you know solely

434
00:47:58,720 --> 00:48:03,600
you know outsourced versus insourced there's a lot of complexity to it uh but I also thought the

435
00:48:03,600 --> 00:48:12,640
first point you made around you know the questions in labeling and and label an outsourced labeling

436
00:48:12,640 --> 00:48:18,560
in particular are the same as other kinds of outsourcing and even more broadly

437
00:48:18,560 --> 00:48:25,920
um other types of commerce like the first thing I thought of was like in in coffee we've got fair

438
00:48:25,920 --> 00:48:33,040
trade right you know uh and so you know maybe the future is like fair trade labeling or something

439
00:48:33,040 --> 00:48:38,640
like that. Absolutely absolutely I think that's uh that's a great comment that you're making right

440
00:48:38,640 --> 00:48:43,680
now I think that that's the future and that's what I was going to talk about is that I

441
00:48:43,680 --> 00:48:50,800
think that jays that yes content moderation is needed but how do you do it is what needs to be

442
00:48:50,800 --> 00:48:57,760
improved and definitely um uh throughout like the years I've seen companies taking action in that

443
00:48:57,760 --> 00:49:03,920
in that field so for instance um they're going to be having like a therapist on site so that

444
00:49:03,920 --> 00:49:08,320
people who feel like they need to talk to someone they can straight away go and talk to that person

445
00:49:08,320 --> 00:49:14,800
uh they can also uh do content moderation only on a voluntary basis it's not something you're not

446
00:49:14,800 --> 00:49:20,480
going to lose your job if you don't want to do it you have the choice um and these people also

447
00:49:20,480 --> 00:49:26,160
work less hours than other regular laborers working on regular labeling tasks just because it's a

448
00:49:26,160 --> 00:49:32,720
way to work on my stack okay you're doing a very very difficult job and you don't need to work you

449
00:49:32,720 --> 00:49:38,640
know as many hours as as the other people are doing uh other tasks I think it's the beginning and

450
00:49:38,640 --> 00:49:45,120
every company has their own vision on what it should look like but I've seen a lot of companies

451
00:49:45,600 --> 00:49:52,080
especially feng um making decisions to work only with companies that have made that type of

452
00:49:52,080 --> 00:49:57,600
efforts for their own workers and you're right you're right that I I believe that the future is going

453
00:49:57,600 --> 00:50:03,760
to be that there will be some sort of committee uh that would like you know um

454
00:50:04,560 --> 00:50:11,200
eject the rules in terms of fair data labeling uh how does that work how you protect the workers

455
00:50:11,200 --> 00:50:15,280
and so on and and that's definitely something that I would like to see happening

456
00:50:16,080 --> 00:50:22,080
if anything the unifying thread between you know the various aspects of this conversation

457
00:50:22,080 --> 00:50:27,840
is recognizing the humanity of the folks that are doing the labeling and the implications of that

458
00:50:27,840 --> 00:50:32,480
both from your process as well as the you know now the ethical considerations we're discussing

459
00:50:33,120 --> 00:50:40,720
yeah definitely I one thing I would like to add to that is that um you know all these people like

460
00:50:40,720 --> 00:50:46,720
a lot of them are not you know educated they don't have like degrees and and that's their way

461
00:50:46,720 --> 00:50:53,840
also to go and start having like an education uh around IT how to use a computer how to label

462
00:50:53,840 --> 00:51:00,400
and a lot of the companies I've been working with us for the years have you know promoted

463
00:51:00,400 --> 00:51:06,080
internally all these people from doing the labeling to doing quality control to being teamly

464
00:51:06,080 --> 00:51:12,080
to being program manager so there is like all this like new industry that's going to generate

465
00:51:12,080 --> 00:51:21,120
you know educated people that we'll be able to get like um you know good salaries and and and

466
00:51:21,120 --> 00:51:29,680
grow into their career so I I want I was one of them even if uh if uh I was uh I was doing the same

467
00:51:29,680 --> 00:51:35,680
thing but in the United States but I started you know at at that level and then I went up so I

468
00:51:35,680 --> 00:51:44,240
think that's very important also to to talk about that uh what do you see as the future of data

469
00:51:44,240 --> 00:51:51,360
label operations I think that the ecosystem needs to get unified I think that it's it's very

470
00:51:53,120 --> 00:52:00,400
there are like so many players that it's just like it's going to be hard to moving forward for

471
00:52:00,400 --> 00:52:06,800
company going into machine learning to find their way uh even though they're incredible um

472
00:52:06,800 --> 00:52:12,960
tools on the on the market right now so that's one so unifying the ecosystem is is a very important

473
00:52:12,960 --> 00:52:18,960
one and uh for the role in itself the data labeling operation I think that we're going to see more

474
00:52:18,960 --> 00:52:27,040
and more of data labeling operation people uh hired uh even in smaller companies or new companies

475
00:52:27,040 --> 00:52:33,120
going into the the journey instead of you know having uh only machine learning engineers and and

476
00:52:33,120 --> 00:52:39,520
think okay we're good we can start our journey there will be this idea that um other non-technical

477
00:52:39,520 --> 00:52:45,840
people are really um important to the journey well Audrey thanks so much for joining us and sharing

478
00:52:45,840 --> 00:52:51,920
a bit of your wealth of experience and labeling well thank you I was very honoured to be on your

479
00:52:51,920 --> 00:52:59,840
podcast thank you Sam thank you

480
00:53:21,920 --> 00:53:28,800
you

