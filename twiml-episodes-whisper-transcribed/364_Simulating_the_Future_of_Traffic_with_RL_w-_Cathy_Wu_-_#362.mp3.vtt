WEBVTT

00:00.000 --> 00:16.000
Welcome to the Twimal AI Podcast. I'm your host, Sam Charrington.

00:16.000 --> 00:36.000
All right, everyone. I am here in Vancouver at Neurips and I am with Kathy Wu. Kathy is the Gilbert W. Winslow Assistant Professor of Civil and Environmental Engineering at MIT.

00:36.000 --> 00:40.000
Kathy, welcome to the Twimal AI Podcast. Thank you so much, having to be here.

00:40.000 --> 00:51.000
It's great to chat with you. We're going to talk about your upcoming presentation on mixed autonomy traffic and reinforcement learning.

00:51.000 --> 01:02.000
But before we do that, you've recently moved over to the Civil Engineering Department at MIT from more of an EECS background.

01:02.000 --> 01:06.000
Tell us a little bit about your interests and your journey.

01:06.000 --> 01:18.000
Thanks, yeah. So I studied EECS as an undergraduate master's student, PhD, and I also, in my postdoc, and I recently joined Civil like you said.

01:18.000 --> 01:26.000
During undergrad, I actually had the end of undergrad. I started becoming interested in transportation in part, actually because of self-driving cars.

01:26.000 --> 01:44.000
And so I started shifting my work and my thinking and my research, studying still robotics oriented, machine learning oriented perspectives on the problem, but really incorporating a lot of the domain specific challenges and problems.

01:44.000 --> 01:51.000
And my work has gradually become a really nice integration of both sides.

01:51.000 --> 01:57.000
I think coming from RPI, like I think of civil engineering as like broke building bridges and things like that.

01:57.000 --> 02:06.000
And so it's awesome to see the kind of interdisciplinary approaches being brought to bear and thinking about autonomous vehicles at Northwestern.

02:06.000 --> 02:19.000
There was a really strong transportation department or planning department and thinking about how cities need to be constructed, for example, to accommodate autonomous vehicles.

02:19.000 --> 02:23.000
What's the focus of your particular research?

02:23.000 --> 02:29.000
Yeah, transportation is really right for disruption, I would say, with AI.

02:29.000 --> 02:38.000
What I study in particular is how can we understand the potential impact of autonomous vehicles on the rest of the system.

02:38.000 --> 02:55.000
I would say that most of the work done in autonomous vehicles is either studying a single vehicle and how a single vehicle should drive and recognize stop signs and stop signs and navigating in its local environment.

02:55.000 --> 03:05.000
Or it's about how all vehicles are already autonomous and how can we coordinate them so that we can have intersections without stoplights.

03:05.000 --> 03:14.000
So very little is studied and known about that intermediate region regime of partial adoption or different levels of automation.

03:14.000 --> 03:18.000
And so that's what we call mixed autonomy and that's what my talk will be about.

03:18.000 --> 03:27.000
Which I think folks are starting to come to a consensus that that's going to be the rule for quite some time.

03:27.000 --> 03:30.000
That's right. At least a few decades.

03:30.000 --> 03:42.000
I think you even see this in kind of mainstream media, going back five years, I'd ask people when they thought autonomous vehicles would be here and they thought they would dominate the streets in five years.

03:42.000 --> 03:43.000
That's right.

03:43.000 --> 03:46.000
And now folks are much more guarded.

03:46.000 --> 03:51.000
There's a bit more of a sobering perspective on autonomous vehicles now that's right.

03:51.000 --> 04:08.000
So also the autonomous vehicles interacting with human driven vehicles is going to be the role, particularly in cities and on highways, maybe in some controlled environments like airports or something like that.

04:08.000 --> 04:17.000
There may be lanes for AVs, but we're going to have to figure out how these two interact with each other and that's what you're focused on.

04:17.000 --> 04:24.000
Yeah, that's right. And actually what you're pointing out is a really good point. There are a lot of different types of scenarios.

04:24.000 --> 04:33.000
There are airports, there are potential changes to the urban environment where there can be dedicated lanes just for vehicles, just for autonomous vehicles.

04:33.000 --> 04:38.000
There can be maybe enclosed regions like campuses.

04:38.000 --> 04:50.000
And so one of the really nice parts and challenging parts about this particular research area is that there are just so many different varieties of traffic scenarios.

04:50.000 --> 04:58.000
And so we need advancements and machine learning techniques to sort of support the vast variety.

04:58.000 --> 05:05.000
And so your talk is particularly focused on the application of reinforcement learning models to mix autonomy?

05:05.000 --> 05:21.000
That's right. So what we study is how can reinforcement learning methods today help us gain insights into what could our traffic systems look like if we could control a fraction of vehicles, so a fraction of autonomous vehicles.

05:21.000 --> 05:36.000
We want to characterize at what point of the transition do we see benefits for traffic congestion, for travel times, for energy consumption, for safety, and things like that. Do we need 100% or is it 99%? That's really different.

05:36.000 --> 05:44.000
This is very important for potentially city planners, policy makers, and traffic operations, engineers.

05:44.000 --> 05:55.000
If that number is, if we see benefits at 5% versus 10% versus 50%, and so that's what we look at with by studying this in reinforcement learning paradigm.

05:55.000 --> 06:14.000
And you've focused on any particular type of environment, cities, highways. I remember seeing a demo of some research kind of along these lines that looked at like a track like environment.

06:14.000 --> 06:27.000
And if you've got some say 90% of cars that are modeled as human driven and then you introduce a few autonomous vehicles, they actually help with traffic circulation.

06:27.000 --> 06:37.000
And so the assumption there was a track like, does your talk focus on a particular scenario?

06:37.000 --> 06:51.000
Yeah, so we always have to start with the simplest environment that we can. So we do look at the track, we look at a variety of different scenarios as well, and we call them traffic logo blocks.

06:51.000 --> 07:06.000
So we'll take the full city network and we'll sort of decompose them into a simple intersection network, a simple sort of multi lane scenario, or a simple merging scenario, or a simple traffic bottleneck.

07:06.000 --> 07:18.000
And then the idea is that we can study each of these environments where we control a fraction of the vehicles with reinforcement learning, and we can sort of start taking insights in these smaller environments.

07:18.000 --> 07:34.000
And then as we were also working on developing methods that can help us scale these experiments to networks that have multiple of these components and then eventually working our way up to a city. The goal is a city.

07:34.000 --> 07:42.000
We got it, got it. So walk us through your presentation. What's the, how do you set up the scenario?

07:42.000 --> 07:52.000
Yeah, so I think a sort of hidden part of reinforcement learning is how much energy and effort goes into designing the task itself, designing the environment.

07:52.000 --> 08:08.000
So reinforcement learning is often formulated in this Markov decision process framework, and so we really go through and we specify each of those components of a Markov decision process. What is the state, what is the action, what is the reward, and so on and so forth.

08:08.000 --> 08:27.000
What does count makes sense? What horizon makes sense? What does the, what should the network look like? What should, how should we model the individual humans? And so we are, we jointly study the entire setup of the, of the Markov decision process, the MDP, as well as the choice of algorithm.

08:27.000 --> 08:39.000
And so we might consider, for instance, here in this scenario, let's keep, let's keep things simple, let's care, let's, let's optimize for say the average velocity of all vehicles in the system.

08:39.000 --> 08:47.000
In the future, we can study this, trade it off with energy consumption and human stress levels and, and whatnot.

08:47.000 --> 09:00.000
And so what we'll do for a lot of the effort actually goes into designing the state of the MDP. What is, what can the autonomous vehicles actually observe about the system?

09:00.000 --> 09:13.000
And here we do a variety of trade offs. We could give the system, we could give the autonomous vehicles full observation of the environment, but this may be less practical for deployment purposes.

09:13.000 --> 09:22.000
And so we may want to limit the observations to say local information around the vehicles and maybe some aggregate statistics of the system.

09:22.000 --> 09:26.000
And all of this needs to be, needs to be carefully thought through.

09:26.000 --> 09:45.000
Those assumptions are kind of models of an evolving, you know, future real world scenario right there are the automakers are dabbling in like connected car scenarios where the autonomous vehicle will have information about, you know, from the other vehicles on the road.

09:45.000 --> 09:46.000
Yeah.

09:46.000 --> 09:49.000
Is that those some of the things that you're trying to model in?

09:49.000 --> 10:09.000
So it's a really interesting point. One of the potentials for this work is actually to help automotive or the public sector actually understand what parts of the system actually need to be communicated to the autonomous vehicles to achieve some outcome.

10:09.000 --> 10:15.000
So I think the work there is still quite early stage. It's a very exciting direction.

10:15.000 --> 10:35.000
And so you kind of establish the kind of framework of the MDP and what the various levers are and potential outcomes that you're looking to control what next in your talk.

10:35.000 --> 10:48.000
Oh, that's right. So then we, we actually to start with where we leverage block box existing reinforcement learning techniques, we use policy gradient methods, we use TRPO, we use PPO.

10:48.000 --> 10:51.000
And we just sort of see what happens.

10:51.000 --> 11:13.000
And to our surprise, we, the outcome was quite remarkable. What we found is that a very small fraction of vehicles actually can make a significant difference across these different, these different traffic scenarios, these inter, across intersections, merges, bottlenecks, single multi lane roads.

11:13.000 --> 11:35.000
We found that 5 to 10% of vehicles is sufficient to eliminate traffic congestion in our, in our preliminary studies, as well as to increase average velocities by 50 to 100% in the network for all vehicles, not just for the automated vehicles.

11:35.000 --> 12:00.000
And then in addition, we have these sort of emerging behaviors that of say coordinated vehicles through, through an intersection or through, through these very, these sort of interesting behaviors that actually correspond to techniques that traffic engineers have spent a long time hand designing to improve traffic systems.

12:00.000 --> 12:08.000
And they're interesting to see the very similar behavior sort of pop out without, without the same amount of domain knowledge going on.

12:08.000 --> 12:10.000
What are some examples of this?

12:10.000 --> 12:25.000
Yeah, so one example that I really like is called the traffic break. I don't know if you've experienced that in driving where, if you're sometimes on a highway, a highway patrol officer will actually drive sort of this sinusoidal pattern across multiple lanes.

12:25.000 --> 12:30.000
So it's one single vehicle that slows down multiple lanes of vehicles.

12:30.000 --> 12:42.000
And in some of our experiments, that actually popped out. We have an autonomous vehicle sort of stable sort of sort of bringing multiple lanes of traffic to a, to a higher speed.

12:42.000 --> 13:11.000
Everyone, everyone in the system is benefiting. And just by one vehicle being automated out of 40 or so, where that vehicle is slowing everyone down in a way by driving this sinusoidal pattern blocking all the lanes of traffic in such a way that the, it basically induces the human drivers to not, not resulting traffic jams.

13:11.000 --> 13:33.000
So it's, so is it that it's slowing the traffic down and then itself speeding up and kind of pulling the, the human drivers along, or is it more kind of a fundamental, you know, by causing the, maybe it's causing the human drivers to stop bad behavior or something like that.

13:33.000 --> 13:48.000
Interestingly, it's more the latter. So we, in our work, we, we're, there's also an intersection of our work with control theory. And we can actually use tools from control theory to analyze these same systems.

13:48.000 --> 14:01.000
And like dampening the, something like that are basically can basically techniques from control theory can allow us to determine the sort of the stable points of the system or this unstable points of the system.

14:01.000 --> 14:13.000
And what the analysis tells us is that there is an unstable point of the system where traffic flows very well. All vehicles are going at the same speed and it's all nice.

14:13.000 --> 14:30.000
However, it's unstable. So in the absence of some external control, the state would not stay that way. And what we're seeing is that the reinforcement learning outcome is that the autonomous vehicles actually brings the system to that unstable equilibrium.

14:30.000 --> 14:48.000
And so it is a more fundamental property where the, all, the result is that all vehicles are going at the same speed. The autonomous vehicle essentially in hindsight, we can see the, the outcome of this experiment as the autonomous vehicles figure out what is the right speed that all vehicles need to go at.

14:48.000 --> 14:51.000
And then basically maintains that speed for all vehicles.

14:51.000 --> 15:09.000
And this is in a scenario where the autonomous vehicle has kind of global knowledge or independent of global knowledge. Yeah, I actually independent of global knowledge. So only, only local knowledge of just the vehicles next to it, it can actually figure out the right speed for the system.

15:09.000 --> 15:25.000
Yeah, you know, I mentioned this, this demo scenario that I've seen before may have been your research. It sounds very familiar. It reminds me a little bit of some related perhaps results.

15:25.000 --> 15:39.000
I don't recall the specific reference, but it was something along the lines of an aggressive human driver can actually make traffic flow faster. Have you come across this result before?

15:39.000 --> 15:46.000
As a New York City driver in St. Louis, I often feel like I'm doing my civic duty.

15:46.000 --> 16:15.000
I am not familiar with this. It's our studies show the opposite, which is that if more drivers say five to ten percent of drivers were to be less aggressive and in particular to break less, to accelerate less, just actually to respond a bit less, respond more slowly to the vehicle in front of you.

16:15.000 --> 16:23.000
Then traffic could actually improve for everyone. That's sort of the one of the takeaways from from our early experiments.

16:23.000 --> 16:33.000
Meaning I respond more slowly, you know, the car in front of me breaks and I slam on the brakes and that kind of causes a ripple that's right, right, right, right.

16:33.000 --> 16:44.000
This is all work that's done in simulation, presumably how well do you feel you're actually able to model human drivers?

16:44.000 --> 16:54.000
Yeah, that's a really good question. This is a general limitation for reinforcement learning as we look at more real world context.

16:54.000 --> 17:11.000
On the other hand, I actually, among a lot of real world context, transportation actually has very good simulators. There are decades of researchers in the transportation modeling community who have studied human driving models of actually all sorts of decision making and transportation.

17:11.000 --> 17:31.000
Like how does a human decide which mode of transportation to take or what price point they are at for different subway fares or whether or not they're going to buy a car or in the case of driving, when is it that you're going to hit the break and how hard based on the distance of you to the vehicle in front of you?

17:31.000 --> 17:51.000
All of this has been very, very carefully studied. Of course, there's more work to be done. There's always more work to be done. But in terms of the quality of simulation, the simulators that we use, these types of simulators are actually used to design actual transportation systems and actual.

17:51.000 --> 18:02.000
We've talked about the results for the track. Have you gone as far as modeling some of these other scenarios as well, like the intersections and merges?

18:02.000 --> 18:04.000
Yeah, so we have results for all of those.

18:04.000 --> 18:05.000
Can you share some of those?

18:05.000 --> 18:17.000
Yeah, so the outcomes in terms of the improvements are pretty consistent. 5 to 10% of automated vehicles leads to 50 to 100% improvement in average velocity in those scenarios.

18:17.000 --> 18:21.000
And we get different types of emergent behaviors.

18:21.000 --> 18:29.000
So the emergent behavior on a track is this police car slow down type of thing. What is it at an intersection?

18:29.000 --> 18:40.000
Yeah, what's really interesting in intersection is basically coordinating vehicles to not conflict at an intersection.

18:40.000 --> 18:50.000
So you may have seen a video of a system where all vehicles are automated and there's no need for traffic lights at an intersection.

18:50.000 --> 19:03.000
And so a few years back, I was interested in, well, what if one vehicle is not automated, one human vehicle, then do we not have any benefit of autonomous vehicles when anywhere we have intersections, which is most places?

19:03.000 --> 19:26.000
And what we actually found is that with enough autonomous vehicles, actually with very few autonomous vehicles, the autonomous vehicles can actually coordinate so that at an intersection it can sort of hold back human drivers from reaching the intersection while the other direction of the intersection passes through, if that makes sense.

19:26.000 --> 19:49.000
So what we're calling this mixed autonomy platooning, where most of the time platooning is a very desirable autonomous vehicle behavior where vehicles can sort of platoon together, sort of reduce air drag and be a lot more efficient in driving together, and all of the vehicles in that platoon are autonomous.

19:49.000 --> 20:12.000
And what we're finding here is this sort of emergent mixed autonomy platoon where only the lead vehicle is automated, but we get this benefit where you have a platoon of vehicles that pass through an intersection in one direction, and then you have a platoon of vehicles that pass through the intersection in the other direction, and neither platoon needed to stop at the intersection, which leads to pretty dramatic improvements in average velocity.

20:12.000 --> 20:37.000
And it sounds like you're at least assuming, but maybe you've validated that this is, or probably have validated this is linear with the number of autonomous vehicles, meaning, you know, 5% offers some benefit and that benefit continues with the number of autonomous vehicles, and it's not somehow that, you know, more autonomous vehicles leads to a more chaotic situation.

20:37.000 --> 20:59.000
So surprisingly, you would think we have done that study, but what we actually found is that in many of these cases, we would, we basically work with small scenarios with say 20 total vehicles or 40 total vehicles, and then what we do is we swap out one for an automated one.

20:59.000 --> 21:12.000
So we can swap out fewer than that. We'd have to change the scenario to have a smaller fraction, and in almost all the scenarios that we studied, swapping out one vehicle was actually enough to achieve a very good outcome.

21:12.000 --> 21:17.000
So there was no need to actually explore more, like, more fractions.

21:17.000 --> 21:19.000
The assumption is that it doesn't get worse.

21:19.000 --> 21:30.000
That doesn't get worse. That's right. That's right. Do you think at all about the, you know, what it's like for that single human driver surrounded by autonomous vehicles?

21:30.000 --> 21:42.000
Oh, I see. That's single human. Maybe that single human would get the message to buy two autonomous vehicles at that point.

21:42.000 --> 22:00.000
I actually get a lot of questions about the opposite scenario, where if there were so few autonomous vehicles, then, like, different people respond to, like, I wouldn't want to be in that autonomous vehicle that sort of swirving left and right in traffic, or I wouldn't want to be behind that autonomous vehicle.

22:00.000 --> 22:13.000
That I hear from time to time. And I think an interesting way to think about that is if we start to think about these vehicles not as passenger vehicles, but as almost, like, part of the infrastructure.

22:13.000 --> 22:15.000
Control vehicles in the system.

22:15.000 --> 22:23.000
Control vehicles. Like, think of them as traffic lights, but they're, but instead of these binary signals, they're actually moving traffic lights that can set us speed.

22:23.000 --> 22:31.000
And so we're starting to see some, some projects that are thinking about using these ideas and more near term transportation projects as well.

22:31.000 --> 22:46.000
And there's, I did an interview with Diana Howard, who, I believe out of Georgia Tech, who studies kind of the relationships between humans and robotic systems.

22:46.000 --> 22:53.000
And there seems to be a predisposed willingness to defer to, you know, robotic systems.

22:53.000 --> 22:59.000
So maybe, you know, the humans that are behind that, you know, control car would be totally fine with it.

22:59.000 --> 23:00.000
It could be.

23:00.000 --> 23:03.000
It's an autonomous vehicle that says low down, so that's what I'll do.

23:03.000 --> 23:15.000
There are also concerns about sort of taking advantage of autonomous vehicles, especially as currently autonomous vehicles are designed as sort of very, very passive.

23:15.000 --> 23:17.000
And very safe.

23:17.000 --> 23:25.000
And so there have been evidence and videos of human drivers sort of cutting off an autonomous vehicle at an intersection.

23:25.000 --> 23:30.000
And so it may actually take that autonomous vehicle longer to get to a destination.

23:30.000 --> 23:33.000
This is like the kids beating up the malls.

23:33.000 --> 23:36.000
Exactly. Exactly. Except their adults.

23:36.000 --> 23:39.000
Right. Interesting, interesting.

23:39.000 --> 23:50.000
But the results that you've described were small number of autonomous vehicles leads to these advances in kind of traffic flow.

23:50.000 --> 23:55.000
Your primary metric there is kind of throughput of the system or velocity.

23:55.000 --> 23:58.000
Are there other metrics that you've explored?

23:58.000 --> 24:05.000
We have not explored other metrics explicitly, although there are a lot that we're interested in, such as fairness.

24:05.000 --> 24:12.000
Sometimes different lanes have different throughputs and that may not be fair.

24:12.000 --> 24:16.000
So we may be interested in some fairness metrics.

24:16.000 --> 24:23.000
We're also interested in safety metrics and energy consumption and several others.

24:23.000 --> 24:25.000
There are many, many.

24:25.000 --> 24:31.000
The robotic car here, the autonomous vehicle, is modeled as a reinforcement learning agent.

24:31.000 --> 24:32.000
That's right.

24:32.000 --> 24:38.000
Are there any interesting observations that you've made about the training process itself,

24:38.000 --> 24:44.000
and the learning process, before or until we get to the interesting emergent behaviors?

24:44.000 --> 24:51.000
We have seen other emergent behaviors that are less good for the system, such as tailgating.

24:51.000 --> 24:53.000
We've also learned tailgating.

24:53.000 --> 24:59.000
So there are a number of examples where we do learn some behaviors

24:59.000 --> 25:05.000
that we can describe that everyone can relate to that are not quite what we're looking for.

25:05.000 --> 25:08.000
The presentation is the main result that you're presenting,

25:08.000 --> 25:11.000
these kind of emergent behaviors that you've described,

25:11.000 --> 25:17.000
or are you digging into more details about how you've created the agents,

25:17.000 --> 25:22.000
or what other things should we make sure to touch on in the conversation?

25:22.000 --> 25:30.000
Yeah, so the highlight of the talk is really the empirical results that we found,

25:30.000 --> 25:37.000
as well as the experimental process to get to it,

25:37.000 --> 25:41.000
as part of this because of the vast variety of traffic scenarios,

25:41.000 --> 25:44.000
including the ones that we've discussed today.

25:44.000 --> 25:53.000
We built an open source framework called Flow, which allows us, as well as any other researchers,

25:53.000 --> 25:58.000
to design their own traffic scenario, their own traffic logo block,

25:58.000 --> 26:03.000
their own traffic MDP, and do their own experiments.

26:03.000 --> 26:07.000
What is the kind of Flow user experience?

26:07.000 --> 26:16.000
Is it a visual graphic type of thing, or is it more your setting parameters,

26:16.000 --> 26:21.000
and then running a command line?

26:21.000 --> 26:23.000
Yeah, it's more the latter.

26:23.000 --> 26:28.000
It's more for developers and for researchers at this point.

26:28.000 --> 26:34.000
So you can specify a network, you can specify the different types of vehicles,

26:34.000 --> 26:38.000
human or autonomous, or different types of human drivers,

26:38.000 --> 26:42.000
and you can specify the different fractions of these vehicles,

26:42.000 --> 26:46.000
you can specify the number of lanes in the network, different parts of the network,

26:46.000 --> 26:48.000
and so on and so forth.

26:48.000 --> 26:52.000
And it's also an actively developed tool right now.

26:52.000 --> 27:02.000
You mentioned that your research relies on these established traffic simulation engines,

27:02.000 --> 27:06.000
and does this flow also depend on those?

27:06.000 --> 27:10.000
Yes, so Flow integrates with a few traffic simulators,

27:10.000 --> 27:16.000
one of which is called Sumo, the simulation of urban mobility,

27:16.000 --> 27:21.000
and it's also an open source traffic micro simulation,

27:21.000 --> 27:27.000
and then we also integrate with another commercial simulator called AIMSUN.

27:27.000 --> 27:29.000
AIMSUN, okay.

27:29.000 --> 27:35.000
These are all, so traffic micro simulators are the specific subset of simulators

27:35.000 --> 27:39.000
that are really about simulating vehicle dynamics,

27:39.000 --> 27:44.000
rather than say vehicle routing or land use.

27:44.000 --> 27:45.000
Okay.

27:45.000 --> 27:52.000
And so anyone can download Flow and download Sumo, for example,

27:52.000 --> 27:57.000
and kind of replicate some of the results that you presented?

27:57.000 --> 27:59.000
That's right, everything's open source.

27:59.000 --> 28:01.000
A strong believer in open source.

28:01.000 --> 28:05.000
Awesome, and so do you, can you use these inside of notebooks,

28:05.000 --> 28:11.000
or what's the typical kind of user experience?

28:11.000 --> 28:13.000
I think you could use it inside networks.

28:13.000 --> 28:19.000
We typically don't, because we're typically issuing jobs to some cluster

28:19.000 --> 28:23.000
for the large-scale reinforcement learning runs.

28:23.000 --> 28:24.000
Got it.

28:24.000 --> 28:27.000
But I think you probably can. How long do you run typically?

28:27.000 --> 28:28.000
Take.

28:28.000 --> 28:33.000
They range, actually, in the scale, in terms of reinforcement learning experiments,

28:33.000 --> 28:36.000
we're very, very low.

28:36.000 --> 28:39.000
Low, like low samples needed.

28:39.000 --> 28:46.000
So our experiments actually can run on a standard commodity AWS instance

28:46.000 --> 28:50.000
in between like one and nine hours.

28:50.000 --> 28:52.000
With GPU?

28:52.000 --> 28:54.000
We don't need GPU.

28:54.000 --> 28:55.000
We don't need GPU, okay.

28:55.000 --> 29:01.000
Yeah, so we are not, we basically focus on the state input directly

29:01.000 --> 29:03.000
and we are not doing too much vision.

29:03.000 --> 29:07.000
Any kind of parting thoughts or other things that you want to mention

29:07.000 --> 29:08.000
from your presentation?

29:08.000 --> 29:14.000
Yeah, so I think we talk a lot about automation and AI

29:14.000 --> 29:17.000
and how it's increasing in the world.

29:17.000 --> 29:21.000
I think another dimension of this that I think is really important

29:21.000 --> 29:25.000
is how much connectivity is actually increasing in the world.

29:25.000 --> 29:31.000
We are, we're all more and more, the people and the systems

29:31.000 --> 29:35.000
that we interact with are more and more connected through social media,

29:35.000 --> 29:41.000
through, say, through urban networks, through global supply chains,

29:41.000 --> 29:43.000
the world is sort of more and more connected.

29:43.000 --> 29:47.000
And so a lot of what motivates this research is the realization

29:47.000 --> 29:52.000
that it's not enough to study a single autonomous vehicle

29:52.000 --> 29:54.000
in its own local environment.

29:54.000 --> 29:57.000
We have to study the environment that it affects,

29:57.000 --> 29:59.000
which is, say, the whole city.

29:59.000 --> 30:05.000
And it's, I think because of the increased connectivity in the world,

30:05.000 --> 30:11.000
it's becoming harder and harder to study AI in its own isolated environment

30:11.000 --> 30:16.000
and the broadened scope of the impacts of AI means

30:16.000 --> 30:21.000
that we actually need new techniques that can handle

30:21.000 --> 30:24.000
much larger, much more complex systems.

30:24.000 --> 30:28.000
And that's a lot of what's motivating the next phase of my research.

30:28.000 --> 30:31.000
And so what are some of the specific directions that you're heading in

30:31.000 --> 30:32.000
in the next phase?

30:32.000 --> 30:36.000
Is it kind of taking these LEGO blocks and connecting them to one another?

30:36.000 --> 30:38.000
It is trying to do that.

30:38.000 --> 30:41.000
Current, with current methods, we can't just immediately do that,

30:41.000 --> 30:46.000
so we do need to look at different techniques to enable this.

30:46.000 --> 30:50.000
I'm very excited about directions in representation learning

30:50.000 --> 30:54.000
for large-scale networked dynamical systems,

30:54.000 --> 30:59.000
very interested in how can curriculum learning play a role in all this?

30:59.000 --> 31:03.000
How can we increase the efficiency of our simulators

31:03.000 --> 31:05.000
through the use of machine learning?

31:05.000 --> 31:07.000
Can we compress simulators?

31:07.000 --> 31:13.000
There are a lot of interesting directions to sort of allow us to work

31:13.000 --> 31:18.000
with more and more complex environments.

31:18.000 --> 31:21.000
Yeah, so what you've done as far as you've used reinforcement learning

31:21.000 --> 31:28.000
to identify some emergent behaviors that have utility in mixed autonomy scenarios,

31:28.000 --> 31:34.000
do you see this as now that we've identified these behaviors

31:34.000 --> 31:41.000
we can kind of program the cars some kind of way, independent of how we do that

31:41.000 --> 31:43.000
to exhibit these behaviors?

31:43.000 --> 31:52.000
Or do you see the cars more, do we need to allow the cars to learn things

31:52.000 --> 31:55.000
while they're kind of in real-time use?

31:55.000 --> 31:58.000
How do you see this playing out?

31:58.000 --> 32:03.000
I guess maybe is it a planning scenario that you're really focused on

32:03.000 --> 32:08.000
or you see the impact or is it more about the vehicles themselves?

32:08.000 --> 32:09.000
I think it's both.

32:09.000 --> 32:12.000
That's a really good question and a really good point.

32:12.000 --> 32:14.000
I think it's both.

32:14.000 --> 32:19.000
There are, with real-world problems, there are a number of reasons

32:19.000 --> 32:22.000
that either direction could not work out.

32:22.000 --> 32:24.000
But I think both are very possible.

32:24.000 --> 32:29.000
We could, in the near term, actually see instrumented vehicles

32:29.000 --> 32:32.000
reducing traffic congestion and increasing speeds.

32:32.000 --> 32:36.000
I can see that the technology is there.

32:36.000 --> 32:38.000
We may need to do a few more experiments.

32:38.000 --> 32:42.000
We may need to validate, but it's pretty close to near-term deployable

32:42.000 --> 32:45.000
whether there's a city that wants to do it or whatnot.

32:45.000 --> 32:47.000
That's a different story.

32:47.000 --> 32:52.000
From the planning perspective, I think that that is a very large

32:52.000 --> 32:54.000
potential direction.

32:54.000 --> 33:00.000
Can we help a city sort of map out its 20-year adoption plan

33:00.000 --> 33:02.000
for autonomous vehicles?

33:02.000 --> 33:04.000
It's incentivization plan.

33:04.000 --> 33:08.000
When and where should the system incentivize the adoption

33:08.000 --> 33:11.000
to get to a point where we can see these benefits?

33:11.000 --> 33:16.000
How should the regulation and rules of the game be laid out?

33:16.000 --> 33:20.000
I think from the planning side, I'm very interested in those questions.

33:20.000 --> 33:25.000
I think a lot of the computational and machine learning and large-scale

33:25.000 --> 33:30.000
techniques are very, very critical in the planning context.

33:30.000 --> 33:31.000
Awesome, awesome.

33:31.000 --> 33:34.000
Well, Kathy, thanks so much for taking some time to share with us

33:34.000 --> 33:35.000
what you're up to.

33:35.000 --> 33:36.000
Thank you for having me.

33:36.000 --> 33:38.000
Absolutely.

33:42.000 --> 33:43.000
All right, everyone.

33:43.000 --> 33:45.000
That's our show for today.

33:45.000 --> 33:50.000
For more information on today's show, visit twomolai.com slash shows.

33:50.000 --> 33:54.000
As always, thanks so much for listening and catch you next time.

33:54.000 --> 33:57.000
3

