1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:32,040
I'm your host Sam Charrington.

4
00:00:32,040 --> 00:00:37,280
In this episode of our Strata Data Conference series, we're joined by Justin Norman, director

5
00:00:37,280 --> 00:00:42,520
of research and data science services at Cloud RF Fast Forward Labs.

6
00:00:42,520 --> 00:00:46,880
Fast Forward Labs was an applied AI research firm and consultancy founded by Hillary

7
00:00:46,880 --> 00:00:52,880
Mason, whose Twimble Talk episode remains an all-time fan favorite.

8
00:00:52,880 --> 00:00:57,600
My chat with Justin took place on the one-year anniversary of Fast Forward Labs' acquisition

9
00:00:57,600 --> 00:00:59,200
by Cloudera.

10
00:00:59,200 --> 00:01:03,240
So we start with a bit of an update before diving into a look at some of their recent

11
00:01:03,240 --> 00:01:05,480
and upcoming research projects.

12
00:01:05,480 --> 00:01:10,880
Specifically, we discussed their recent report on multitask learning and their upcoming

13
00:01:10,880 --> 00:01:13,760
research into federated machine learning.

14
00:01:13,760 --> 00:01:19,600
To learn more about Cloudera and CFFL, visit Cloudera's machine learning resource center

15
00:01:19,600 --> 00:01:22,520
at cladera.com slash ML.

16
00:01:22,520 --> 00:01:26,560
A huge thanks to them for sponsoring this series.

17
00:01:26,560 --> 00:01:29,520
Thanks also to our second sponsor, Capital One.

18
00:01:29,520 --> 00:01:34,320
At the Nip's conference in Montreal this December, they'll be co-hosting a workshop focused

19
00:01:34,320 --> 00:01:39,880
on challenges and opportunities for AI and financial services and the impact of fairness,

20
00:01:39,880 --> 00:01:43,040
explainability, accuracy and privacy.

21
00:01:43,040 --> 00:01:47,040
The call for papers is open now through October 25th.

22
00:01:47,040 --> 00:01:54,400
For more information or submissions, visit twimlai.com slash C1 Nips.

23
00:01:54,400 --> 00:01:58,880
If you love this show, you've got to love our sponsors because they help make it possible.

24
00:01:58,880 --> 00:02:03,160
So please take a look at what they're up to and tell them Twimble sent you.

25
00:02:03,160 --> 00:02:08,880
And now on to the show.

26
00:02:08,880 --> 00:02:13,720
All right, everyone, I am here in New York City at the Stratoc conference and I'm seated

27
00:02:13,720 --> 00:02:15,400
with Justin Norman.

28
00:02:15,400 --> 00:02:19,960
Justin is the director of research and data science services at cladera fast forward

29
00:02:19,960 --> 00:02:20,960
labs.

30
00:02:20,960 --> 00:02:23,280
Justin, welcome to this weekend machine learning and AI.

31
00:02:23,280 --> 00:02:24,280
Thank you very much.

32
00:02:24,280 --> 00:02:25,280
Glad to be here.

33
00:02:25,280 --> 00:02:26,280
Awesome.

34
00:02:26,280 --> 00:02:32,040
So Justin, you started your career in data as an officer with the US Marine Corps.

35
00:02:32,040 --> 00:02:33,560
Tell us a little bit about your background.

36
00:02:33,560 --> 00:02:35,000
Yeah, that's absolutely right.

37
00:02:35,000 --> 00:02:39,360
So I actually got a chance to study computer science and focus on mathematical optimization

38
00:02:39,360 --> 00:02:41,000
at the Naval Academy.

39
00:02:41,000 --> 00:02:45,680
So naturally, when I made the decision to join the Marine Corps, I was asked to go into

40
00:02:45,680 --> 00:02:50,240
a technical role, I'm pretty much straight off the bat, which was just fine by me.

41
00:02:50,240 --> 00:02:56,160
But over the course of about seven years, I got a chance to both locally and also overseas

42
00:02:56,160 --> 00:03:01,560
participate in a lot of large scale network enterprises, which had massive data challenges.

43
00:03:01,560 --> 00:03:06,760
Not the least of which were that time for over 30,000 connected devices under management.

44
00:03:06,760 --> 00:03:11,160
And just understanding what traffic flows looked like normal, what traffic looks like that

45
00:03:11,160 --> 00:03:12,160
were anomalous.

46
00:03:12,160 --> 00:03:16,200
And being able to react dynamically to that was a large portion of my job.

47
00:03:16,200 --> 00:03:22,440
So machine learning was embedded quite frankly in the sort of a soul of what we were doing.

48
00:03:22,440 --> 00:03:25,880
But at the time, we didn't really have terminology for data science and machine learning.

49
00:03:25,880 --> 00:03:28,160
We just sort of did what we needed to do.

50
00:03:28,160 --> 00:03:32,960
But naturally that would help me to sort of progress into industry as the field emerged

51
00:03:32,960 --> 00:03:36,600
a bit further later in my lifetime.

52
00:03:36,600 --> 00:03:39,960
You went on to found a startup in machine learning, is that right?

53
00:03:39,960 --> 00:03:40,960
I did.

54
00:03:40,960 --> 00:03:48,160
So I worked with a few people that I knew quite well to try to work on the problem of business,

55
00:03:48,160 --> 00:03:50,400
predictive analytics within sports.

56
00:03:50,400 --> 00:03:55,480
And so we weren't so focused on the saber matrix that you see from the sort of traditional

57
00:03:55,480 --> 00:04:00,120
sports analytics, but we're a lot more interested in trying to find ways to solve some of the

58
00:04:00,120 --> 00:04:04,840
corporate challenges that we saw in a lot of other industries, but applying them to industries

59
00:04:04,840 --> 00:04:09,920
which really didn't have that kind of background in skill set and helping them to accelerate

60
00:04:09,920 --> 00:04:11,240
from a financial perspective.

61
00:04:11,240 --> 00:04:19,400
So a lot of our focus was actually in the beautiful game in football, but the right football.

62
00:04:19,400 --> 00:04:23,040
And we did a lot of work in Central and South America to help some of those smaller clubs

63
00:04:23,040 --> 00:04:28,080
actually be able to take advantage of the business value of their players.

64
00:04:28,080 --> 00:04:33,240
For example, transferring or trading a player that had a higher social media impact than

65
00:04:33,240 --> 00:04:38,040
perhaps another player that was equally skilled to try to impact things like ticket sales

66
00:04:38,040 --> 00:04:41,360
and retention of a season ticket holders, things like that.

67
00:04:41,360 --> 00:04:42,360
Interesting.

68
00:04:42,360 --> 00:04:50,000
I did an interview with a guy named Minoa gift that was doing some very similar things

69
00:04:50,000 --> 00:04:55,760
in terms of looking at how to score player, social media impact and the ultimate impact

70
00:04:55,760 --> 00:04:58,440
on the game.

71
00:04:58,440 --> 00:05:06,920
So you went on to, among other things, do data science at Cisco and now at Cloud or a

72
00:05:06,920 --> 00:05:11,480
Fast Forward Labs, tell us a little bit about your role and your focus at CFFL.

73
00:05:11,480 --> 00:05:12,480
Great.

74
00:05:12,480 --> 00:05:13,480
Yeah.

75
00:05:13,480 --> 00:05:18,560
So as people may or may not be aware, we're actually exactly at one year of the acquisition

76
00:05:18,560 --> 00:05:20,360
of Fast Forward Labs at Cloud Air.

77
00:05:20,360 --> 00:05:25,560
So in a nutshell, my role is to take Fast Forward Labs kind of from where it is, which

78
00:05:25,560 --> 00:05:32,040
is actually very well integrated and quite successful with its existing clients and some additional

79
00:05:32,040 --> 00:05:34,200
quite our clients and really scale that globally.

80
00:05:34,200 --> 00:05:36,680
And I mean that from not just a physical standpoint.

81
00:05:36,680 --> 00:05:42,080
So yes, we want to expand to media and into Asia, but actually also from a data perspective.

82
00:05:42,080 --> 00:05:46,400
So can we take the research that we've done, the products that we've developed and start

83
00:05:46,400 --> 00:05:52,160
to do those at scale and the enterprise and be really known as not just leaders in the

84
00:05:52,160 --> 00:05:56,960
research field, but leaders in how to apply that research across both corporate organizational

85
00:05:56,960 --> 00:05:59,280
governmental entities.

86
00:05:59,280 --> 00:06:04,600
And that is from a technical perspective, a challenge, but also from a human and strategic

87
00:06:04,600 --> 00:06:09,200
perspective, a challenge, which is why I think Fast Forward Labs is really uniquely positioned.

88
00:06:09,200 --> 00:06:13,400
Because as you know, our research not just doesn't just focus on the technical and technique

89
00:06:13,400 --> 00:06:17,760
aspect of things that we have quite a bit of research in that area, but also in how to

90
00:06:17,760 --> 00:06:24,840
layer the people in process and skills, conversations into the application of that technology so that

91
00:06:24,840 --> 00:06:28,440
you can get the outcome when you actually expect to have it.

92
00:06:28,440 --> 00:06:36,200
And so for those that don't know, the research that you're referring to is a series of reports,

93
00:06:36,200 --> 00:06:40,640
can you talk a little bit about some of the topics that you've covered in the report

94
00:06:40,640 --> 00:06:41,640
just as context?

95
00:06:41,640 --> 00:06:42,640
Sure.

96
00:06:42,640 --> 00:06:46,600
The best way I think to talk about the reports is to start with a process that we go through

97
00:06:46,600 --> 00:06:49,600
to actually decide what we're going to do.

98
00:06:49,600 --> 00:06:51,480
And I think it's really powerful.

99
00:06:51,480 --> 00:06:58,640
So the entire team gets together and really calls out, I'd say, with the intent to find

100
00:06:58,640 --> 00:07:07,360
some bad ideas of types of topics that might be relevant within the next 12 to 24 months

101
00:07:07,360 --> 00:07:08,360
within machine learning.

102
00:07:08,360 --> 00:07:13,520
And the intent is that we're going to look at topics that are not just papers or research

103
00:07:13,520 --> 00:07:17,800
that is out there in scholarly journals, but actually something that is starting to be

104
00:07:17,800 --> 00:07:22,480
applied in industry, or maybe we have the ability to bring that last step.

105
00:07:22,480 --> 00:07:27,080
And so topics in the past, like natural language generation, symmetric recommendations,

106
00:07:27,080 --> 00:07:32,520
image analysis with deep learning, and then most recently multi-task learning, have sort

107
00:07:32,520 --> 00:07:36,720
of become of the topic that has gone that we've narrowed down in that process and really

108
00:07:36,720 --> 00:07:43,720
have felt that is most relevant to the widest group of consumers that exist within industry,

109
00:07:43,720 --> 00:07:45,840
academia, and beyond.

110
00:07:45,840 --> 00:07:51,800
So we've actually just launched a report as I just referred to called multi-task learning,

111
00:07:51,800 --> 00:07:56,760
which focuses on actually executing multiple machine learning tasks at the same time.

112
00:07:56,760 --> 00:07:59,160
And so we're really excited about that.

113
00:07:59,160 --> 00:08:02,200
And there's actually a number of people this week at Strata who are going to be speaking

114
00:08:02,200 --> 00:08:03,680
about that in greater depth.

115
00:08:03,680 --> 00:08:07,120
And so very excited to hear what they have to say about that.

116
00:08:07,120 --> 00:08:10,640
But we're not stopping and actually have two more reports in the queue.

117
00:08:10,640 --> 00:08:13,560
One of them we actually know the research, but the research is going to be focused on

118
00:08:13,560 --> 00:08:15,640
and that's on federated learning as well.

119
00:08:15,640 --> 00:08:21,600
So we're really excited to be able to share this because we think that now we're beginning

120
00:08:21,600 --> 00:08:25,920
to come in influence not just by the community that we had through Fast Forward Labs, which

121
00:08:25,920 --> 00:08:31,600
was extensive, but also because we're at Clavera, we now have a focus along the enterprise

122
00:08:31,600 --> 00:08:33,640
with a much, much larger scale.

123
00:08:33,640 --> 00:08:37,600
It's helping us to understand what's relevant to that community as well.

124
00:08:37,600 --> 00:08:42,800
And that definitely has directly influenced what we've been able to perform in the research

125
00:08:42,800 --> 00:08:44,920
space as well.

126
00:08:44,920 --> 00:08:49,200
On that multi-task learning paper, I haven't had a chance to take a look at that one,

127
00:08:49,200 --> 00:08:55,160
but around the time it was being that initiative was being kicked off someone at CFFL reached

128
00:08:55,160 --> 00:08:59,320
out to me to CFI knew anyone who was working in that space.

129
00:08:59,320 --> 00:09:02,920
And I had recently done an interview with Ryan Poplin at Google.

130
00:09:02,920 --> 00:09:09,600
I'm pretty sure that's who it was who had made an interesting comment that they were looking

131
00:09:09,600 --> 00:09:16,720
at these retinal, fundus images and using those to determine a variety of demographic

132
00:09:16,720 --> 00:09:20,480
information about the people who the images came from.

133
00:09:20,480 --> 00:09:27,240
And they noticed that when they asked their model to do to determine a single thing and

134
00:09:27,240 --> 00:09:32,120
compare the performance relative to asking the model to do multiple things, the model

135
00:09:32,120 --> 00:09:35,240
performed better when it had multiple things to do.

136
00:09:35,240 --> 00:09:45,520
And his theory was that that kind of forced the model to generalize better.

137
00:09:45,520 --> 00:09:46,760
And so I kind of made the connection.

138
00:09:46,760 --> 00:09:48,160
I hope that connections are good connection.

139
00:09:48,160 --> 00:09:50,160
That's a very good connection.

140
00:09:50,160 --> 00:09:54,680
And I think you'll see that in the report even that we recreated results on that specific

141
00:09:54,680 --> 00:09:57,480
use case, but on other use cases that was very similar.

142
00:09:57,480 --> 00:10:01,360
And in some areas, it's very well explainable to your point why that happens.

143
00:10:01,360 --> 00:10:02,680
And in some areas, it's not.

144
00:10:02,680 --> 00:10:06,080
And I think that's one of the most powerful parts of the research component of what that

145
00:10:06,080 --> 00:10:08,160
report covers.

146
00:10:08,160 --> 00:10:12,920
So you certainly can recreate that experience where you do have model performance that's

147
00:10:12,920 --> 00:10:18,360
a bit better on one or multiple, excuse me, multiple or even three or four or even

148
00:10:18,360 --> 00:10:20,920
more learning tasks at the same time.

149
00:10:20,920 --> 00:10:24,480
But the type of data is highly relevant to whether or not you're going to see that performance.

150
00:10:24,480 --> 00:10:27,080
And I'm one of the things that we spend a lot of time talking about.

151
00:10:27,080 --> 00:10:34,200
And so is the, what's the kind of core thesis of that, of that paper?

152
00:10:34,200 --> 00:10:39,960
Well, so that for, like I said, for certain types of data sets and for certain learning

153
00:10:39,960 --> 00:10:43,480
tasks, you should definitely do it.

154
00:10:43,480 --> 00:10:44,880
So it is the core thesis.

155
00:10:44,880 --> 00:10:49,440
But I think the most important part is that it is possible to actually execute these

156
00:10:49,440 --> 00:10:56,360
multiple learning tasks and actually get them at scale, utilizing some of the more now

157
00:10:56,360 --> 00:10:58,680
commoditizable learning functions.

158
00:10:58,680 --> 00:11:02,360
So things like deep learning models are highly relevant to this as well.

159
00:11:02,360 --> 00:11:07,480
So the focus is on really making sure that people understand which techniques exist and

160
00:11:07,480 --> 00:11:08,920
then when to apply them.

161
00:11:08,920 --> 00:11:13,760
And are there a specific set of techniques for multitask learning or is it just the same

162
00:11:13,760 --> 00:11:18,720
stuff but with multiple objectives there, but a little bit of both.

163
00:11:18,720 --> 00:11:21,880
So there are definitely certain sets of techniques, but it depends on the objective.

164
00:11:21,880 --> 00:11:25,000
Can you give me an overview of the specific types of techniques that were you would need

165
00:11:25,000 --> 00:11:26,000
Frederica for?

166
00:11:26,000 --> 00:11:27,000
Okay.

167
00:11:27,000 --> 00:11:30,920
That was the report that recently came out going forward.

168
00:11:30,920 --> 00:11:36,480
You are looking at, you mentioned that the next one is going to be on federated learning.

169
00:11:36,480 --> 00:11:37,480
That's right.

170
00:11:37,480 --> 00:11:39,240
What's the, what's the thinking around that?

171
00:11:39,240 --> 00:11:43,520
So one of the things that was always a theme at fast-forward labs.

172
00:11:43,520 --> 00:11:47,880
And I think again, back to my earlier point is something that's coming in front of mine

173
00:11:47,880 --> 00:11:51,920
because of the types of customers that we've been working with at Clara is the idea of

174
00:11:51,920 --> 00:11:55,600
really trying to execute and scale machine learning at the edge.

175
00:11:55,600 --> 00:12:00,800
So by the edge, I mean, at devices that are, you know, the last device before a human

176
00:12:00,800 --> 00:12:07,840
or last device before a sensor, you know, executes its function to read data from an environment.

177
00:12:07,840 --> 00:12:11,280
And there's a number of reasons to want to you machine learning at the edge.

178
00:12:11,280 --> 00:12:16,880
I think one of the biggest ones is if the device, and now they do, have enough computational

179
00:12:16,880 --> 00:12:20,960
power to execute that, you get returns that results back that you can, you know, influence

180
00:12:20,960 --> 00:12:24,560
outcomes with directly without having to report back to some kind of central model or

181
00:12:24,560 --> 00:12:27,000
sometimes central computing store.

182
00:12:27,000 --> 00:12:29,640
So this is most relevant in IoT applications.

183
00:12:29,640 --> 00:12:34,800
I think you can even think of it as a human with your cell phone.

184
00:12:34,800 --> 00:12:38,240
There's obviously multiple machine learning models that are powering very important functions

185
00:12:38,240 --> 00:12:39,760
on your phone.

186
00:12:39,760 --> 00:12:46,600
But one of the challenges that comes into play right away with that is that ultimately,

187
00:12:46,600 --> 00:12:49,800
there's a lot of people who want to have the power of machine learning and AI enabled

188
00:12:49,800 --> 00:12:54,440
capabilities, but without necessarily exposing the underlying data structure.

189
00:12:54,440 --> 00:12:59,040
And the data that, that data structure that might be influenced by a person's personal

190
00:12:59,040 --> 00:13:05,280
choices, by, for example, on a commercial application, competitive IP applications that

191
00:13:05,280 --> 00:13:08,960
don't want to be shared with the industry, but you still want the benefit of being able

192
00:13:08,960 --> 00:13:16,400
to train and to share, for example, parameters, hyperparameters that settings that are relevant

193
00:13:16,400 --> 00:13:21,640
across the scope of problems without necessarily exposing how you got there.

194
00:13:21,640 --> 00:13:27,880
And so federated learning is a set of techniques for an approach to be able to do just that,

195
00:13:27,880 --> 00:13:33,720
where you potentially have a centralized model or a model that serves as a baseline for

196
00:13:33,720 --> 00:13:37,520
one of multiple devices that are deployed and over multiple workflows.

197
00:13:37,520 --> 00:13:42,160
But you still get a chance to benefit from that without exposing each one of the individual

198
00:13:42,160 --> 00:13:46,120
data underlying data structures that are there.

199
00:13:46,120 --> 00:13:49,760
And that's very important from an ethical perspective, very important from a commercial

200
00:13:49,760 --> 00:13:51,160
perspective.

201
00:13:51,160 --> 00:13:56,720
And also it does have a performance impact, a positive performance impact, as you might

202
00:13:56,720 --> 00:14:00,360
know from starting from, you're essentially starting from, you know, a little bit farther

203
00:14:00,360 --> 00:14:03,720
down the races that are that that's starting line.

204
00:14:03,720 --> 00:14:13,440
So is the issue that you're kind of framing around not wanting to disclose model parameters

205
00:14:13,440 --> 00:14:18,960
is the issue that you're looking to address the idea that if you push a model out to

206
00:14:18,960 --> 00:14:25,880
the edge, you're exposing, you know, that model, the parameters of that model are IP and

207
00:14:25,880 --> 00:14:26,880
you're exposing that IP.

208
00:14:26,880 --> 00:14:27,880
Kind of the other way around.

209
00:14:27,880 --> 00:14:30,040
It's the data we don't want to expose.

210
00:14:30,040 --> 00:14:36,680
So, for example, if you're using a phone, the types of text messages or images that

211
00:14:36,680 --> 00:14:40,000
you have on your phone are very private, you don't want that to be shared.

212
00:14:40,000 --> 00:14:46,080
But being able to do natural language processing or analysis of your text messages in order

213
00:14:46,080 --> 00:14:50,120
to respond better, provide applications on top of that is something of course you want

214
00:14:50,120 --> 00:14:51,120
to have that.

215
00:14:51,120 --> 00:14:56,560
So if you are a provider of software, you want to be able to train models on the widest

216
00:14:56,560 --> 00:15:01,360
set of information you possibly can, but you may not have the benefit of reading everybody's

217
00:15:01,360 --> 00:15:03,360
text messages nor should you.

218
00:15:03,360 --> 00:15:08,240
So is there a way that potentially you can get the benefit of a more precise model that

219
00:15:08,240 --> 00:15:13,240
fits better to a larger set of data, generalizes to a larger set of data without actually having

220
00:15:13,240 --> 00:15:14,600
access to that data?

221
00:15:14,600 --> 00:15:20,840
And so being able to perform these multiple learning functions over time and a very broad

222
00:15:20,840 --> 00:15:27,040
set of workers or workflows that are existing in near real time and then giving that information

223
00:15:27,040 --> 00:15:33,560
back the potential parameter settings of a model or the sort of things that shape a fit

224
00:15:33,560 --> 00:15:39,440
to have a model be more generalizable without exposing the underlying data is what we're

225
00:15:39,440 --> 00:15:40,440
looking for.

226
00:15:40,440 --> 00:15:45,680
And so the idea is that I've got access to some set of data at the edge.

227
00:15:45,680 --> 00:15:50,800
I don't want to transcend, send all of that data back to some central location, for privacy

228
00:15:50,800 --> 00:15:54,120
reasons, bandwidth reasons, whatever, all of the above.

229
00:15:54,120 --> 00:16:00,560
So what can I do on the edge to presumably, we talk a lot about the edge for inference,

230
00:16:00,560 --> 00:16:06,760
but what we're talking about here is to train or partially train on the edge and then use

231
00:16:06,760 --> 00:16:12,720
that to, it sounds like the idea of federated is use that to enhance a centralized model

232
00:16:12,720 --> 00:16:17,560
that can maybe even be like distributed or some aspect of that model or what that model

233
00:16:17,560 --> 00:16:20,040
is learned, distribute out to the other edge devices.

234
00:16:20,040 --> 00:16:22,400
How do you do that?

235
00:16:22,400 --> 00:16:26,240
Well, I mean, you'll have to wait for the report.

236
00:16:26,240 --> 00:16:32,920
But the longest short of it is, it's now possible from a computational perspective to execute

237
00:16:32,920 --> 00:16:38,000
these multiple workers when you're actually looking at thinking about a model that's

238
00:16:38,000 --> 00:16:40,080
being deployed anywhere.

239
00:16:40,080 --> 00:16:45,280
It's being done by some automation workflow, just like any other software engineering component.

240
00:16:45,280 --> 00:16:51,080
And so now that we can do this, not just like with one or two on a laptop, but with 1,000

241
00:16:51,080 --> 00:16:56,760
or 1,000, 100,000, and actually have not just a bit like, we don't have been going straight

242
00:16:56,760 --> 00:17:00,080
but also about computational constraints.

243
00:17:00,080 --> 00:17:05,200
That's a large part of what we'll be exposing is how to actually execute this.

244
00:17:05,200 --> 00:17:08,360
And then what are some of the constraints of that from a technology perspective?

245
00:17:08,360 --> 00:17:09,800
That's one aspect of it.

246
00:17:09,800 --> 00:17:19,000
And then from a sharing of model parameter information or model fit information, how actually

247
00:17:19,000 --> 00:17:25,760
to bring that back to a centralized location, to average and generalize that across the

248
00:17:25,760 --> 00:17:30,120
full schemes that it's useful to be to your point, distribute it back into that matrix

249
00:17:30,120 --> 00:17:32,840
of learners is also focused on.

250
00:17:32,840 --> 00:17:36,960
So there are a couple of techniques that we've developed and a few that we've adopted

251
00:17:36,960 --> 00:17:40,120
and written about that you'll hear about very soon.

252
00:17:40,120 --> 00:17:48,320
And the past, my impression of the reports has been that the focus is on kind of going

253
00:17:48,320 --> 00:17:53,600
out, exploring what's out there in important areas and writing about those.

254
00:17:53,600 --> 00:18:01,080
One of my favorites was the natural language summarization, and it did kind of a survey

255
00:18:01,080 --> 00:18:06,360
of all the different techniques that have been used to do summarization, LDA, lots of

256
00:18:06,360 --> 00:18:08,280
other things.

257
00:18:08,280 --> 00:18:14,640
It sounds like here you're starting a tiptoe into developing some technology or algorithms.

258
00:18:14,640 --> 00:18:20,080
Yeah, and I think that happened largely because we recognize that this is a real and really

259
00:18:20,080 --> 00:18:23,400
important need for industry and for government.

260
00:18:23,400 --> 00:18:28,280
But the techniques that we did research on weren't as mature as they might have again

261
00:18:28,280 --> 00:18:30,680
for other areas of research that we've explored.

262
00:18:30,680 --> 00:18:33,960
So if they were out there, we'd certainly tell you that these are the ones you should

263
00:18:33,960 --> 00:18:34,960
use.

264
00:18:34,960 --> 00:18:39,160
I think we've taken a good survey of what we've found for the multi, for excuse me, for

265
00:18:39,160 --> 00:18:40,400
a federated learning.

266
00:18:40,400 --> 00:18:44,400
But this time around, it became necessary for us to bridge the gap a little bit.

267
00:18:44,400 --> 00:18:47,720
And so, of course, the team has that capability and it's more than happy to do that when we

268
00:18:47,720 --> 00:18:48,960
think it's relevant.

269
00:18:48,960 --> 00:18:56,920
I mean, in a lot of ways that is, it kind of pokes at the thesis of the research, which

270
00:18:56,920 --> 00:19:03,480
is, I've always interpreted it as, this is stuff that's right at the edge and hate this

271
00:19:03,480 --> 00:19:08,280
cool thing happens someplace which kind of flipped it and people don't really know yet.

272
00:19:08,280 --> 00:19:09,280
Right.

273
00:19:09,280 --> 00:19:15,040
I'm trying to remember what the thing was in the summarization paper, but there was, there

274
00:19:15,040 --> 00:19:18,120
was some new, I think it was, it was word vectors.

275
00:19:18,120 --> 00:19:19,120
Right.

276
00:19:19,120 --> 00:19:24,520
So there was a bunch of LDA stuff and language modeling that people were using for this and

277
00:19:24,520 --> 00:19:27,720
it was kind of worked a little bit, but it wasn't great.

278
00:19:27,720 --> 00:19:32,640
But hey, word vectors came around and now we can really do interesting summarization stuff.

279
00:19:32,640 --> 00:19:38,680
The thesis was, hey, we're kind of scanning the world looking for these opportunities

280
00:19:38,680 --> 00:19:45,440
where external change has enabled some new way of some new capability.

281
00:19:45,440 --> 00:19:50,160
You know, here, you're kind of more being that external change.

282
00:19:50,160 --> 00:19:51,160
Yeah.

283
00:19:51,160 --> 00:19:53,480
It's a pretty, it strikes me as a pretty significant shift.

284
00:19:53,480 --> 00:19:58,120
It is a significant shift and I think it goes back to, you know, how we started the

285
00:19:58,120 --> 00:20:04,440
podcast, which is, you know, Cladera gives us a platform now to have, I think, a perspective

286
00:20:04,440 --> 00:20:07,480
on what's happening in industry from the top layer, right?

287
00:20:07,480 --> 00:20:11,080
So I think one of the things that's very powerful that we've maintained about fast forward

288
00:20:11,080 --> 00:20:15,760
lab is that we're talking to academia, we're talking to startups, we're talking to, you

289
00:20:15,760 --> 00:20:19,120
know, organizations which are focused on machine learning and AI.

290
00:20:19,120 --> 00:20:22,720
And that's a particularly powerful perspective that we've always had, but we didn't have

291
00:20:22,720 --> 00:20:29,400
as much exposure to the, you know, industry players, but the people who are doing machine

292
00:20:29,400 --> 00:20:34,280
learning and AI at scale in the edge and the petabyte scale, right?

293
00:20:34,280 --> 00:20:39,920
So I think what we're finding now is we're being asked by that community to solve a different

294
00:20:39,920 --> 00:20:44,320
set of problems and those problems may not have been commoditized yet.

295
00:20:44,320 --> 00:20:49,440
So we have the ability to connect what they're looking at strategically and from a business

296
00:20:49,440 --> 00:20:55,160
or a mission relevance perspective and then apply that cutting edge research, which was

297
00:20:55,160 --> 00:21:02,160
always sort of there with a layer of, you know, of interface to use it to use a word.

298
00:21:02,160 --> 00:21:06,440
So I think that's what what's occurring as a result of that one year being at the company.

299
00:21:06,440 --> 00:21:07,440
Okay.

300
00:21:07,440 --> 00:21:08,440
Okay.

301
00:21:08,440 --> 00:21:09,440
Interesting.

302
00:21:09,440 --> 00:21:15,840
And now this whole area of devices and the edge is not new to you.

303
00:21:15,840 --> 00:21:16,840
No.

304
00:21:16,840 --> 00:21:19,960
And we didn't talk about it in your background, but you spent some time at Fitbit.

305
00:21:19,960 --> 00:21:20,960
I did.

306
00:21:20,960 --> 00:21:24,040
How has that informed your thinking about this whole space?

307
00:21:24,040 --> 00:21:29,040
It definitely has been shaped by thinking about this space and made it quite frankly

308
00:21:29,040 --> 00:21:35,760
top of mind for me anytime that I recommend building a model factory, AI system.

309
00:21:35,760 --> 00:21:40,840
And so just to get a little bit deeper about that at companies that have an edge device

310
00:21:40,840 --> 00:21:46,000
that's being delivered to consumer or is being used to gather information from the environment

311
00:21:46,000 --> 00:21:51,040
like a sensor, you end up having this really poignant real time challenge.

312
00:21:51,040 --> 00:21:55,240
And so you need to and you want to do machine learning right at that device or near that

313
00:21:55,240 --> 00:22:01,400
device because it's important to be able to serve back either to your human or to the

314
00:22:01,400 --> 00:22:02,400
environment.

315
00:22:02,400 --> 00:22:08,520
The results of a model or the score of a model in some very, some very poignant way.

316
00:22:08,520 --> 00:22:13,600
And you know, the example that you get on a device like a fitness tracker is that a person

317
00:22:13,600 --> 00:22:17,960
might go through some fitness activity and want to see, you know, projections of where

318
00:22:17,960 --> 00:22:22,480
they might be, had certain variables changed, had they run faster, you know, what their

319
00:22:22,480 --> 00:22:28,280
heart rate might be, if they were to continue the next set of their exercise.

320
00:22:28,280 --> 00:22:31,800
And for example, you know, something very famously, you know, the number of steps that

321
00:22:31,800 --> 00:22:37,080
you're doing, that's not a static number for any human being and their performance upwards

322
00:22:37,080 --> 00:22:40,560
or downwards on that, you know, depends on a variety of factors, a variety of features

323
00:22:40,560 --> 00:22:42,840
to use that machine learning language.

324
00:22:42,840 --> 00:22:47,680
So of course, you want to be able to provide that back as quickly as possible and you know,

325
00:22:47,680 --> 00:22:53,160
latency and incurred by going back to a more robust off-mind data store.

326
00:22:53,160 --> 00:22:57,000
Sometimes it's just not, it's just not for a moment enough to provide that.

327
00:22:57,000 --> 00:23:03,960
And so you end up wanting to do this sort of challenging activity, which is to do, you

328
00:23:03,960 --> 00:23:09,040
know, training of a model and batch scoring of a model within your data store, where all

329
00:23:09,040 --> 00:23:13,240
the data actually lives on a larger, on a larger platform, like, for example, the

330
00:23:13,240 --> 00:23:20,120
chip, and you want to be able to somehow take the results of that train model and put it

331
00:23:20,120 --> 00:23:24,960
somewhere that's much closer to the user itself, which is probably connected near to some

332
00:23:24,960 --> 00:23:26,840
connected device at the edge.

333
00:23:26,840 --> 00:23:32,160
And it actually means that you need a couple of different environments to be able to do

334
00:23:32,160 --> 00:23:36,200
a scoring of machine learning models or AI models.

335
00:23:36,200 --> 00:23:41,000
And then your production environment doesn't become something that's running, you know,

336
00:23:41,000 --> 00:23:44,680
within a 24 hours of latency, but something that may be running several times a minute

337
00:23:44,680 --> 00:23:45,680
or even a second.

338
00:23:45,680 --> 00:23:49,080
And if you say a couple of different environments, what do you mean?

339
00:23:49,080 --> 00:23:52,160
I mean, I mean, deployment environments from machine learning models.

340
00:23:52,160 --> 00:23:57,840
So for example, historically deployment might look something like, I have a machine learning

341
00:23:57,840 --> 00:24:02,920
model that's written in Python and I'm going to use a cron job or something like that to

342
00:24:02,920 --> 00:24:04,920
schedule a run of the model.

343
00:24:04,920 --> 00:24:09,680
It'll just pull a representative sample from, you know, from some interface layer on top

344
00:24:09,680 --> 00:24:13,760
of the doop and then I'll return the results of that and dump it in a table somewhere

345
00:24:13,760 --> 00:24:14,760
else also to do.

346
00:24:14,760 --> 00:24:19,320
And then people can query that with whatever they want, you know, let's say SQL, right?

347
00:24:19,320 --> 00:24:22,880
So that's a, that's a, that's a, a point of workflow.

348
00:24:22,880 --> 00:24:28,400
And then if you want from an application perspective to return results, you could put some kind

349
00:24:28,400 --> 00:24:32,240
of restful API layer on top of that and then you listen to that endpoint or hit that endpoint

350
00:24:32,240 --> 00:24:35,400
whenever you, you have a request, that's, that's an idea.

351
00:24:35,400 --> 00:24:37,000
Not super performant, right?

352
00:24:37,000 --> 00:24:38,000
Yeah.

353
00:24:38,000 --> 00:24:42,560
So if I was a, you know, a cell phone or a fitness tracker and there were 17 million

354
00:24:42,560 --> 00:24:43,560
of me, right?

355
00:24:43,560 --> 00:24:48,000
And I wanted to do that, that, that same function that I was querying that API directly

356
00:24:48,000 --> 00:24:49,000
from there.

357
00:24:49,000 --> 00:24:50,640
It's pretty challenging, right?

358
00:24:50,640 --> 00:24:54,600
So you actually end up needing a different environment, actually completely different

359
00:24:54,600 --> 00:24:59,120
soft software engineering workloads to deliver that come from performance, but you still

360
00:24:59,120 --> 00:25:03,600
want access to the underlying data because it's still saving the doop and that's how

361
00:25:03,600 --> 00:25:04,600
you train, right?

362
00:25:04,600 --> 00:25:08,920
So this is, you know, sort of an extension of the problem that we were talking about

363
00:25:08,920 --> 00:25:13,920
before, where you actually do, you know, want to have access to the data.

364
00:25:13,920 --> 00:25:19,240
And so having a separate environment that's closer to the closer to the consumer, whether

365
00:25:19,240 --> 00:25:24,440
that be a device or a person, allows you to actually do some pre-processing and treat

366
00:25:24,440 --> 00:25:28,320
pre-printing of features actually at the edge or near the edge.

367
00:25:28,320 --> 00:25:32,800
And so for that, you know, common set of information that are features that I like power these

368
00:25:32,800 --> 00:25:33,800
models.

369
00:25:33,800 --> 00:25:40,160
And wanting to, you know, to do that pre-processing almost as the data streamed itself, right?

370
00:25:40,160 --> 00:25:44,920
And then allow the model that's sitting on that device to pull from that source of data

371
00:25:44,920 --> 00:25:48,520
where it needs to, and then return results much more quickly.

372
00:25:48,520 --> 00:25:53,680
So that's one of the things that I learned while working at a device company is that sometimes

373
00:25:53,680 --> 00:25:58,000
the machine learning challenges are not necessarily from a technical algorithm perspective, but

374
00:25:58,000 --> 00:26:02,480
actually how you apply it and how you apply it to get the outcome that you're looking

375
00:26:02,480 --> 00:26:08,520
for from, you know, from a consumer perspective and sometimes near real time or step second

376
00:26:08,520 --> 00:26:09,520
time.

377
00:26:09,520 --> 00:26:15,800
It sounds like when you describe this architecture, it's in the different environments, you

378
00:26:15,800 --> 00:26:19,560
know, we've talked about kind of the central capability we've talked about the edge, but

379
00:26:19,560 --> 00:26:22,960
it almost sounds like you're laying out a hierarchical environment where you've got,

380
00:26:22,960 --> 00:26:27,080
you know, maybe you've got regions and something that's, you know, immediately behind the

381
00:26:27,080 --> 00:26:33,200
edge, like this is talks about often in an IoT environment, you've got your edge devices

382
00:26:33,200 --> 00:26:37,560
and then you've got your plant device that's kind of a, you know, it's, I don't think

383
00:26:37,560 --> 00:26:40,920
it, I don't know that it's clear what the exact function of that is today.

384
00:26:40,920 --> 00:26:46,520
It's kind of doing some training and intermediate model development or at least that's the people

385
00:26:46,520 --> 00:26:47,520
aspire to that.

386
00:26:47,520 --> 00:26:48,520
Sure.

387
00:26:48,520 --> 00:26:53,640
Today, it's more doing data collection and centralizing the data transfer to, you know,

388
00:26:53,640 --> 00:26:57,800
some mothership or some kind of intermediate mothership.

389
00:26:57,800 --> 00:26:59,080
How do you see all that evolving?

390
00:26:59,080 --> 00:27:00,080
Yeah.

391
00:27:00,080 --> 00:27:05,040
So what I think is starting to happen is because there's a much clearer definition of what

392
00:27:05,040 --> 00:27:09,000
actually you're going to need from a, especially for commoditized models.

393
00:27:09,000 --> 00:27:12,720
So if we're talking about like ensemble models, like random forests are actually boost.

394
00:27:12,720 --> 00:27:16,000
We know it's, you know, we're very, very good at understanding what these models are

395
00:27:16,000 --> 00:27:19,080
going to need from an input layer perspective to be successful, right?

396
00:27:19,080 --> 00:27:24,360
So when you begin to pre-process or pre-trained features or pre-trained data and put that

397
00:27:24,360 --> 00:27:28,520
post to the edge, the interviewer that you're talking about actually can be responsible

398
00:27:28,520 --> 00:27:35,120
for promoting these feature sets and, you know, accomplishing this migration of data with

399
00:27:35,120 --> 00:27:41,520
the very precise scale as opposed to just dumping or translating everything when we think

400
00:27:41,520 --> 00:27:42,520
we might need it.

401
00:27:42,520 --> 00:27:48,440
And I think that's where MLOPS, AIOPS is actually going to start to take a bigger role.

402
00:27:48,440 --> 00:27:54,040
And, you know, really even applying machine learning to, you know, the workflow itself

403
00:27:54,040 --> 00:27:57,760
and what necessarily needs to be accomplished during that phase.

404
00:27:57,760 --> 00:28:03,920
And you start to see the, you know, technologies like airflow and Jenkins, you know, be the control

405
00:28:03,920 --> 00:28:08,720
layer for it, but underlying it, there's actually a machine learning functions that are

406
00:28:08,720 --> 00:28:13,960
powering what we translate into the, you know, the online feature store.

407
00:28:13,960 --> 00:28:16,440
Which I think is something that's really exciting.

408
00:28:16,440 --> 00:28:23,400
Now, airflow is kind of a data workflow open-source project developed by Airbnb.

409
00:28:23,400 --> 00:28:24,400
Airbnb?

410
00:28:24,400 --> 00:28:28,600
I think the original developer came from Facebook and then worked at Airbnb, but yeah,

411
00:28:28,600 --> 00:28:33,800
so airflow is an example of what I'd call an AIOPS or AIOPS tool.

412
00:28:33,800 --> 00:28:39,840
It definitely does scheduling and more flamaticant, just like any other tool like in that category

413
00:28:39,840 --> 00:28:40,840
would do.

414
00:28:40,840 --> 00:28:44,840
But I think what makes it specific is that it's really tuned for the types of techniques

415
00:28:44,840 --> 00:28:48,960
that you'll need to perform in a machine learning workflow specifically.

416
00:28:48,960 --> 00:28:55,360
And so I think that category of, you know, tools is starting to become not just needed,

417
00:28:55,360 --> 00:29:01,920
but also up here in multiple, you know, software options, which shows that it's validated

418
00:29:01,920 --> 00:29:02,920
in the market.

419
00:29:02,920 --> 00:29:05,720
Airflow is an open-source approach to it, but there are certainly a lot of others who

420
00:29:05,720 --> 00:29:07,760
are taking a more commercial approach to it.

421
00:29:07,760 --> 00:29:12,240
And I think it's going to be necessary and is a lot of these companies and, you know,

422
00:29:12,240 --> 00:29:13,240
project scale.

423
00:29:13,240 --> 00:29:17,680
And you've mentioned Jenkins, which, you know, has been around forever, kind of in the

424
00:29:17,680 --> 00:29:19,680
Java community for those bills and stuff.

425
00:29:19,680 --> 00:29:20,680
Right.

426
00:29:20,680 --> 00:29:21,680
How does that fit into this whole?

427
00:29:21,680 --> 00:29:26,280
Well, I think we're, so now we're, like, getting into the idea of how we're going to,

428
00:29:26,280 --> 00:29:28,480
or what is a model, or what is a deployed model.

429
00:29:28,480 --> 00:29:29,480
Yeah.

430
00:29:29,480 --> 00:29:35,320
And so, you know, a deployed model, as we mentioned before, could be simply a table somewhere

431
00:29:35,320 --> 00:29:41,120
that we've scored or we use a function to score, you know, some fitted, some model to

432
00:29:41,120 --> 00:29:42,120
score.

433
00:29:42,120 --> 00:29:44,120
So, you know, the data, the results of data, and put it into a table.

434
00:29:44,120 --> 00:29:46,200
That could be, you know, what we consider deployed.

435
00:29:46,200 --> 00:29:51,240
But I think more and more we're starting to see deployed, meaning it is the model, the

436
00:29:51,240 --> 00:29:56,760
model architecture itself, and the ability to query that, that model architecture for

437
00:29:56,760 --> 00:30:01,280
the result that we're looking for in some kind of performant or way that we can fit into

438
00:30:01,280 --> 00:30:02,280
an SLI.

439
00:30:02,280 --> 00:30:03,440
I think that's what we're starting to see.

440
00:30:03,440 --> 00:30:08,960
And so, when containerization and microservices, you know, are layered together to try to

441
00:30:08,960 --> 00:30:12,640
produce this result holistically, so, like, you know, a model, you know, becomes the

442
00:30:12,640 --> 00:30:17,720
container itself, and the services that it takes to be able to interface with it, tools

443
00:30:17,720 --> 00:30:21,320
like that, you know, automation, workflow management, tools become critical.

444
00:30:21,320 --> 00:30:26,080
Because when you're actually interfacing with a model, you actually might be spending

445
00:30:26,080 --> 00:30:33,200
the whole workflow of a machine, the data, workflow that the machine needs to interact

446
00:30:33,200 --> 00:30:36,880
with, and then performing the scoring, and then actually returning that result all

447
00:30:36,880 --> 00:30:37,880
of us.

448
00:30:37,880 --> 00:30:44,660
And so, it's no longer about just having the skill set to be able to produce a nicely

449
00:30:44,660 --> 00:30:47,240
fitted model against some set of data.

450
00:30:47,240 --> 00:30:51,800
It's actually being able to put, to return that result, and the way that it needs to

451
00:30:51,800 --> 00:30:56,120
be consumed, either by an API or directly to an application.

452
00:30:56,120 --> 00:30:59,480
And so, now we're in this space where we're thinking about things a bit more holistically

453
00:30:59,480 --> 00:31:00,480
than we have to.

454
00:31:00,480 --> 00:31:06,440
Maybe going back a little bit to this kind of federated model, federated idea, and

455
00:31:06,440 --> 00:31:09,960
just kind of in the back of my head thinking through like how this might work.

456
00:31:09,960 --> 00:31:17,240
And at, you know, one thought is at a low level, you know, people are doing things around

457
00:31:17,240 --> 00:31:22,600
distributed training, and that's all centered, or frequently centered around this idea of

458
00:31:22,600 --> 00:31:28,760
like exchanging gradient updates from one machine to another, or, you know, having something

459
00:31:28,760 --> 00:31:35,520
that's tracking all of these gradient updates that the distributed workers involved in training

460
00:31:35,520 --> 00:31:36,680
can access.

461
00:31:36,680 --> 00:31:40,720
Like is that involved in, is that part of what we're talking about, or what we're talking

462
00:31:40,720 --> 00:31:45,960
about, you know, when you talk about federated training and federated ML, is it something

463
00:31:45,960 --> 00:31:47,120
at a higher level?

464
00:31:47,120 --> 00:31:51,080
Well, so I think it's certainly a component of what we're talking about, but I think

465
00:31:51,080 --> 00:31:57,080
we have to be really careful there not to slip into the space of, of training the model

466
00:31:57,080 --> 00:31:59,440
of leaking, essentially, across.

467
00:31:59,440 --> 00:32:02,840
And that's exactly what we don't want to accomplish with federated.

468
00:32:02,840 --> 00:32:05,480
So I think the, and a library on what you mean by that.

469
00:32:05,480 --> 00:32:11,800
So the idea of, you know, even though individual workers or individual models that are, that

470
00:32:11,800 --> 00:32:16,800
are being deployed by workers, don't have access directly to other, to other data stores.

471
00:32:16,800 --> 00:32:19,960
The fact that they could learn the underlying patterns or structures and perhaps in for

472
00:32:19,960 --> 00:32:23,200
what's there, we really have to be careful about that.

473
00:32:23,200 --> 00:32:28,800
And so the idea of a federated sort of abstracts, I think a little bit more, you know, how

474
00:32:28,800 --> 00:32:33,880
to accomplish that, though we're sharing, you know, not just graded information, but really

475
00:32:33,880 --> 00:32:37,600
a larger set of parameters that are, that are, you know, available depending on the

476
00:32:37,600 --> 00:32:38,600
type of model.

477
00:32:38,600 --> 00:32:43,040
And actually, because it's a, it's much more oriented around the techniques, the specific

478
00:32:43,040 --> 00:32:46,080
algorithms that we're using underneath that shouldn't matter as much.

479
00:32:46,080 --> 00:32:50,440
But rather, you know, it is the mechanism for which these distributed workers are able

480
00:32:50,440 --> 00:32:56,320
to share two centralized repository and then that centralized repository performs better,

481
00:32:56,320 --> 00:33:00,640
you know, then in each individual one could do that we're really focused on.

482
00:33:00,640 --> 00:33:06,240
So then it sounds like it is, it is operating at a higher level and the, the goal is less

483
00:33:06,240 --> 00:33:12,640
about, you know, sharing these gradient updates or whatever is a low level kind of information

484
00:33:12,640 --> 00:33:18,920
sharing for the model in question to allow this distributed model to converge and more

485
00:33:18,920 --> 00:33:25,240
like training a model individually at different places and sending key information about that

486
00:33:25,240 --> 00:33:30,440
model, sharing key information about that model to make everyone's models better.

487
00:33:30,440 --> 00:33:31,440
Right.

488
00:33:31,440 --> 00:33:37,560
And so, again, the sort of central idea, if you were asked to summarize that would be

489
00:33:37,560 --> 00:33:42,080
that, you know, if you have, you know, the ability to take a random of these techniques,

490
00:33:42,080 --> 00:33:47,000
which might be, you know, ultimately computationally expensive, it's in to do across such a large

491
00:33:47,000 --> 00:33:52,800
set of independent workers, you would achieve an outcome which would be impossible without

492
00:33:52,800 --> 00:33:57,280
that centralized sharing information, without that federated sharing information.

493
00:33:57,280 --> 00:34:05,240
So the other thing that this makes me think a little bit about is differential privacy.

494
00:34:05,240 --> 00:34:11,320
Is that something that you've looked at previously in other roles or that you are looking

495
00:34:11,320 --> 00:34:16,320
at in the context of, of this federated learning?

496
00:34:16,320 --> 00:34:17,320
Yeah, definitely.

497
00:34:17,320 --> 00:34:21,000
I think it's going to, we're going to definitely try to write about that, but the research

498
00:34:21,000 --> 00:34:22,000
is ongoing.

499
00:34:22,000 --> 00:34:25,440
So I wouldn't be able to tell you what we've uncovered yet because we're literally looking

500
00:34:25,440 --> 00:34:27,440
at some of these things right now.

501
00:34:27,440 --> 00:34:28,440
Okay.

502
00:34:28,440 --> 00:34:34,400
You talked a little bit about online versus offline learning often when the whole online

503
00:34:34,400 --> 00:34:40,520
learning comes up, it comes up in the context of spark and streaming and pipelines.

504
00:34:40,520 --> 00:34:42,720
How do you see that fitting into this?

505
00:34:42,720 --> 00:34:43,720
Yeah.

506
00:34:43,720 --> 00:34:50,520
So when I was describing this area earlier where, you know, where you might want to respond

507
00:34:50,520 --> 00:34:55,880
to, you know, to an activity or something that has occurred, like, for example, with

508
00:34:55,880 --> 00:35:02,080
a fitness tracker, those exchanges of data are happening with real-time streams.

509
00:35:02,080 --> 00:35:06,640
So, you know, I don't think it's a secret to anyone that's, you know, that's spark streaming

510
00:35:06,640 --> 00:35:14,400
and really, you know, things like Kafka, you know, interfaces between these devices and

511
00:35:14,400 --> 00:35:17,120
our key component of how this works.

512
00:35:17,120 --> 00:35:21,200
So what I would say is that's the piping behind this process is that we've been talking

513
00:35:21,200 --> 00:35:23,200
about.

514
00:35:23,200 --> 00:35:29,840
What makes it a little bit more challenging is the sort of potentially asynchronous nature

515
00:35:29,840 --> 00:35:35,200
of how data works in that area, and this is back to the sort of Cisco days, and the, you

516
00:35:35,200 --> 00:35:40,440
know, for lack of a better term, the UDPness of it, where you may receive some or all the

517
00:35:40,440 --> 00:35:46,960
data, some of it may be at order, probably will be, and, you know, you still have to find

518
00:35:46,960 --> 00:35:49,560
a way to coherently respond to that.

519
00:35:49,560 --> 00:35:53,400
And I think that component of it becomes a data engineering challenge, which is at the

520
00:35:53,400 --> 00:35:57,000
edge, combined with a machine learning challenge, which is at the edge, combined with a software

521
00:35:57,000 --> 00:35:58,360
engineering challenge at that the edge.

522
00:35:58,360 --> 00:36:01,680
And so we have to solve all these problems very, very quickly.

523
00:36:01,680 --> 00:36:06,160
And so what I've seen in industry so far is I've worked on it is that everyone's architecting

524
00:36:06,160 --> 00:36:12,360
slightly different workflows are on this, and it's probably time that we and others begin

525
00:36:12,360 --> 00:36:16,800
to standardize that a bit to make it more accessible for the community.

526
00:36:16,800 --> 00:36:19,920
And so we're specifically talking about workflows.

527
00:36:19,920 --> 00:36:26,480
Are you talking about the whole, the federated concepts specifically, or we're not, we're

528
00:36:26,480 --> 00:36:31,640
talking about the workforce for managing these edge devices and software engineering for

529
00:36:31,640 --> 00:36:32,640
edge devices.

530
00:36:32,640 --> 00:36:33,640
Yeah.

531
00:36:33,640 --> 00:36:38,000
I mean, you asked about the, about, you know, how a premium instrument plays into it.

532
00:36:38,000 --> 00:36:41,800
And I think it, like I said before, it's the piping that regardless of what application

533
00:36:41,800 --> 00:36:45,480
you're trying, whether it's a federated learning mechanism, or simply you're just trying

534
00:36:45,480 --> 00:36:49,800
to deliver online services, machine learning services, you're going to have to interact

535
00:36:49,800 --> 00:36:51,040
with that environment.

536
00:36:51,040 --> 00:36:53,280
And the ecosystem right now is pretty complex.

537
00:36:53,280 --> 00:36:56,960
And I think we've got to do some work to, you know, to at least abstract some of it so

538
00:36:56,960 --> 00:37:00,800
that we're more focused on solving the problem than dealing with engineering workflows, which

539
00:37:00,800 --> 00:37:02,760
is where we currently are.

540
00:37:02,760 --> 00:37:06,160
And how close do you think we are to being able to do that?

541
00:37:06,160 --> 00:37:11,400
We've advanced engineering practices, you know, with DevOps, for example, significantly

542
00:37:11,400 --> 00:37:18,640
over the past few years, and we've got a growing base of experience with mobile.

543
00:37:18,640 --> 00:37:26,400
Although for, you know, from the device perspective, the rate of change of, you know, what's

544
00:37:26,400 --> 00:37:32,640
happening in the device tends to be a lot slower than what we'd want in a kind of an IoT

545
00:37:32,640 --> 00:37:35,160
enterprise, more agile environment.

546
00:37:35,160 --> 00:37:41,320
But with, you know, with those as kind of background, you know, then we've got these two, you

547
00:37:41,320 --> 00:37:44,920
know, IoT, which is changing quickly, and we're just kind of wrapping our heads around

548
00:37:44,920 --> 00:37:49,720
and trying to figure out men to layer onto that, the machine learning and AI stuff.

549
00:37:49,720 --> 00:37:54,120
Like how do you think we as an industry like put together?

550
00:37:54,120 --> 00:37:55,120
You mentioned standards.

551
00:37:55,120 --> 00:38:00,280
It seems like we're so far from standards, you know, just a way that works that consistently

552
00:38:00,280 --> 00:38:01,600
to manage all of this stuff.

553
00:38:01,600 --> 00:38:02,600
Yeah.

554
00:38:02,600 --> 00:38:11,440
I don't think that would be a smart thing to do, but I will say that it might be useful

555
00:38:11,440 --> 00:38:18,000
for us to maybe go a little bit away from segregating ourselves by community.

556
00:38:18,000 --> 00:38:23,520
There are really well, very well understood, very powerful practices and networks that

557
00:38:23,520 --> 00:38:26,640
have existed for years that might be really helpful for us as some of these challenges.

558
00:38:26,640 --> 00:38:31,560
They've been dealing with real-time streaming since the beginning of computers sharing

559
00:38:31,560 --> 00:38:33,120
information with each other, right?

560
00:38:33,120 --> 00:38:36,280
I mean, I spent a lot of time at Cisco, and let me tell you, there's some people there

561
00:38:36,280 --> 00:38:40,080
who have gotten down to the algorithm level and digester shortest path and can tell you

562
00:38:40,080 --> 00:38:43,960
exactly how messages respond to that, you know, from device to device when you're talking

563
00:38:43,960 --> 00:38:45,800
about the context of a router.

564
00:38:45,800 --> 00:38:47,040
And those standards exist.

565
00:38:47,040 --> 00:38:51,160
They're actually really, they're very well documented, they're published, they're public.

566
00:38:51,160 --> 00:38:56,640
So I think that we have examples of how to accomplish this, you know, sort of standards-based

567
00:38:56,640 --> 00:39:01,320
practice out there, but it may not come from the community we're familiar with, right?

568
00:39:01,320 --> 00:39:05,600
So as a machine learning practitioner or a data scientist, you're probably a lot more

569
00:39:05,600 --> 00:39:08,920
familiar with the software engineering community, and you're probably a lot more familiar with

570
00:39:08,920 --> 00:39:14,680
people who are publishing standards by way of, you know, GitHub or standards by way, you

571
00:39:14,680 --> 00:39:21,840
know, of library, but we may not have access to or may not have thought about, you know,

572
00:39:21,840 --> 00:39:26,920
applications for handling messaging or handling workflows, you know, even a lower layer

573
00:39:26,920 --> 00:39:31,440
of the stack and the computing and computing, and I think it's going to be this interface

574
00:39:31,440 --> 00:39:36,000
of communities that are happening that helps us to build out these standards and practices

575
00:39:36,000 --> 00:39:41,000
that make sense because we are not talking about one community, we're actually talking,

576
00:39:41,000 --> 00:39:45,360
we just talked in this conversation about multiple different architectures converging.

577
00:39:45,360 --> 00:39:49,560
So I think we need to expand our view a little bit and start to look for places and people

578
00:39:49,560 --> 00:39:53,960
that have experiences, you know, potentially a different part of the stack that can help

579
00:39:53,960 --> 00:39:59,080
us be successful where we are here in the real time of online and mental conversation.

580
00:39:59,080 --> 00:40:03,600
You know, you talked about Spark as being core to this streaming environment.

581
00:40:03,600 --> 00:40:11,000
Is there an analogous environment or platform on the Python side that's gained any traction?

582
00:40:11,000 --> 00:40:18,280
Yeah, not that I'm aware of, and I think largely that's happening because of the way that

583
00:40:18,280 --> 00:40:21,040
Python tends to interact with data in general.

584
00:40:21,040 --> 00:40:24,520
I think data scientists, data scientists, we've tended, and this might just be a community

585
00:40:24,520 --> 00:40:25,520
issue.

586
00:40:25,520 --> 00:40:29,800
We've tended to use it on the, you know, the research and dev side.

587
00:40:29,800 --> 00:40:33,040
And so interacting with data, you know, that the more abstracted, I mean, the less abstracted

588
00:40:33,040 --> 00:40:37,800
layer really at that point has not been something I've seen a lot of research poured into,

589
00:40:37,800 --> 00:40:38,800
but I could be wrong about that.

590
00:40:38,800 --> 00:40:42,280
So, you know, I think I haven't seen it, but, you know, that's not to say it doesn't

591
00:40:42,280 --> 00:40:43,280
exist.

592
00:40:43,280 --> 00:40:44,280
All right.

593
00:40:44,280 --> 00:40:50,520
So you, you mentioned a term AI ops, or you may have said ML ops a couple of times I've

594
00:40:50,520 --> 00:41:00,400
done some writing about that term, but as applied to AI enabled IT operations, so like managing

595
00:41:00,400 --> 00:41:07,320
the data center with AI, are you starting to see, or are you starting to evangelize the

596
00:41:07,320 --> 00:41:16,720
use of that term to specifically refer to ops as it relates to AI, meaning managing the

597
00:41:16,720 --> 00:41:19,320
AI infrastructure of an organization?

598
00:41:19,320 --> 00:41:20,320
Yeah.

599
00:41:20,320 --> 00:41:23,160
So, I think that's where I would hope we would go.

600
00:41:23,160 --> 00:41:27,160
I mean, you know, who knows what these terminologies are going to end up, but I mean, we're

601
00:41:27,160 --> 00:41:31,480
talking about AI when, you know, 10 years ago we've been talking about, you know, applied

602
00:41:31,480 --> 00:41:32,480
statistics.

603
00:41:32,480 --> 00:41:36,800
So, you could go anywhere, but I do think that that's a really powerful way to use that

604
00:41:36,800 --> 00:41:42,360
term, because I think in a lot of ways, I actually saw a tweet the other day that was really

605
00:41:42,360 --> 00:41:43,360
great.

606
00:41:43,360 --> 00:41:47,800
You know, that was talking about, you know, asking, you know, software engineers and IT

607
00:41:47,800 --> 00:41:54,800
people to deploy models, being just like, you know, trying to have, see world, take care

608
00:41:54,800 --> 00:41:58,560
of your drafts, just because they take care of other large scale mammals, right?

609
00:41:58,560 --> 00:42:02,480
Like, it's really completely different set of skills, yeah.

610
00:42:02,480 --> 00:42:07,520
And so, when we think about software engineering, we have a term, we have a terminology, we

611
00:42:07,520 --> 00:42:12,760
have a framework, we actually have tools and entire category of software that's devoted

612
00:42:12,760 --> 00:42:16,920
to taking care of the operations necessary to manage the software infrastructure that runs

613
00:42:16,920 --> 00:42:17,920
the company, right?

614
00:42:17,920 --> 00:42:20,960
It's very, it's a huge business and it's actually really important.

615
00:42:20,960 --> 00:42:25,400
But from an AI perspective, historically, and I've experienced this personally, you're

616
00:42:25,400 --> 00:42:32,520
usually either asked to do it yourself or you're, you're translating or giving, you know,

617
00:42:32,520 --> 00:42:37,600
your baby, so to speak, to IT or engineering organization and telling them to scale that.

618
00:42:37,600 --> 00:42:42,880
And what almost universally happens, they have no idea why you made those decisions.

619
00:42:42,880 --> 00:42:47,280
They disagree with them, sometimes for really good reason, about the way that you approach

620
00:42:47,280 --> 00:42:48,680
it from a software engineering perspective.

621
00:42:48,680 --> 00:42:52,280
And so, they bring engineer the whole thing and miss a lot of the core components of

622
00:42:52,280 --> 00:42:53,280
what you were trying to accomplish.

623
00:42:53,280 --> 00:42:55,040
Do you have a specific example of that?

624
00:42:55,040 --> 00:42:59,880
Yeah, so I can tell you that one of the first models that I actually developed myself

625
00:42:59,880 --> 00:43:07,680
in industry, you know, was written in NAR, I think like a lot of us were doing it.

626
00:43:07,680 --> 00:43:14,320
It was a simple logistic progression, or turned a binary result and I felt like it was quite

627
00:43:14,320 --> 00:43:18,680
generalizable for the problems that we're looking at, so I delivered it to my IT organization

628
00:43:18,680 --> 00:43:23,080
to be applied back into one of the products that was actually already online for one of our

629
00:43:23,080 --> 00:43:27,680
internal tools and they wrote the entire thing in Java.

630
00:43:27,680 --> 00:43:36,080
And so the challenge with that was, you know, Java has a lot of, it's very verbose.

631
00:43:36,080 --> 00:43:44,600
And so the performance that I had sort of expected out of my small, like, you know, seven-line

632
00:43:44,600 --> 00:43:48,960
Python code, now had a whole bunch of other dependencies that I'd never planned for.

633
00:43:48,960 --> 00:43:55,960
And so the application, the AI application, so to speak, that returned, you know, sub-second

634
00:43:55,960 --> 00:44:00,440
or very close to second results for the data set size I was looking at now took, you

635
00:44:00,440 --> 00:44:02,280
know, five to ten minutes to run.

636
00:44:02,280 --> 00:44:08,440
Probably we think of going from, you know, our Python to Java is a step forward in performance,

637
00:44:08,440 --> 00:44:09,440
right?

638
00:44:09,440 --> 00:44:10,440
Totally.

639
00:44:10,440 --> 00:44:13,960
If only that's all you're doing, but in the context of it being run in a much more robust

640
00:44:13,960 --> 00:44:19,480
application, which had not quite a few other dependencies that I never cared about, you

641
00:44:19,480 --> 00:44:21,480
know, that that's isn't necessarily the case.

642
00:44:21,480 --> 00:44:27,800
And so, you know, I think if we'd had a much more robust AI workflow in place, I would

643
00:44:27,800 --> 00:44:35,680
be deploying my model, so to speak, you know, and the workflow or even the AI tool kit

644
00:44:35,680 --> 00:44:40,440
itself would decide the best way to implement that or to return that rather than, you know,

645
00:44:40,440 --> 00:44:44,800
the IT organization myself hadn't had the negotiation for every single product that we

646
00:44:44,800 --> 00:44:46,120
developed, right?

647
00:44:46,120 --> 00:44:51,600
And so that, you see that all the time when someone checks in code, you know, to, you

648
00:44:51,600 --> 00:44:57,040
know, to a DevOps workflow, they have no idea how it might be integrated at the end.

649
00:44:57,040 --> 00:44:58,040
It doesn't matter.

650
00:44:58,040 --> 00:45:02,800
It's that the core component of what the application that they've developed gets integrated

651
00:45:02,800 --> 00:45:03,800
into the overall.

652
00:45:03,800 --> 00:45:06,960
And so we just got to get there from an AI perspective.

653
00:45:06,960 --> 00:45:10,760
And I think we're starting to make a lot of progress on that.

654
00:45:10,760 --> 00:45:16,920
Years ago, maybe five years ago, let's say, you know, we would talk about data scientists

655
00:45:16,920 --> 00:45:20,440
as this unicorn, you know, did everything, right?

656
00:45:20,440 --> 00:45:28,680
And now more often than not, we're starting to see, you know, specifically in internet

657
00:45:28,680 --> 00:45:29,680
companies, right?

658
00:45:29,680 --> 00:45:35,160
You've got this very well-defined role now of machine learning engineer that works, you

659
00:45:35,160 --> 00:45:37,800
know, tends to work hand in hand with data science.

660
00:45:37,800 --> 00:45:38,800
Sure.

661
00:45:38,800 --> 00:45:42,280
People are even changing, you know, data scientists is becoming a bit passe and there's

662
00:45:42,280 --> 00:45:46,080
like applied research scientists and these other roles, but they're, it's much more

663
00:45:46,080 --> 00:45:54,200
of a teaming kind of relationship between these two and the ML engineer than inherits, you

664
00:45:54,200 --> 00:45:58,440
know, because they are an engineer, they kind of inherit everything that's been developed,

665
00:45:58,440 --> 00:46:00,840
you know, in terms of DevOps processes.

666
00:46:00,840 --> 00:46:01,840
Yep.

667
00:46:01,840 --> 00:46:07,760
And it seems to be that a lot of that is as much smoother, you know, for organizations

668
00:46:07,760 --> 00:46:09,280
that kind of have that worked out.

669
00:46:09,280 --> 00:46:10,280
Sure.

670
00:46:10,280 --> 00:46:13,640
This tends to be internet companies, not enterprises, there's still a lot of work that

671
00:46:13,640 --> 00:46:16,800
needs to be done, I think, to kind of translate these practices.

672
00:46:16,800 --> 00:46:17,800
I think that's right.

673
00:46:17,800 --> 00:46:18,800
But we're getting there.

674
00:46:18,800 --> 00:46:20,000
And I think you're right about that.

675
00:46:20,000 --> 00:46:21,000
This is a good story.

676
00:46:21,000 --> 00:46:24,920
I'm not, you hear that, like, to sell, you know, doom and gloom, I think we're absolutely

677
00:46:24,920 --> 00:46:25,920
getting there.

678
00:46:25,920 --> 00:46:28,320
I would expand your list to data first companies.

679
00:46:28,320 --> 00:46:33,120
Companies then, like, use, you know, information that they either generate or derive from their

680
00:46:33,120 --> 00:46:37,520
customers as the main product that they then, you know, present back to their customers.

681
00:46:37,520 --> 00:46:39,280
That's a great distinction, yeah.

682
00:46:39,280 --> 00:46:43,840
And so, you know, there are many there in that category, but the ride sharing, you know,

683
00:46:43,840 --> 00:46:49,680
companies, you know, anyone that's doing consumer pricing, you know, like hotel companies,

684
00:46:49,680 --> 00:46:52,680
come to mind is the ones that are really innovating in this area.

685
00:46:52,680 --> 00:46:55,720
It's a little slower for utility companies.

686
00:46:55,720 --> 00:46:59,840
It's a little slower for telecoms and it's a little bit slower, you know, for governments.

687
00:46:59,840 --> 00:47:03,520
And I think these are some of the organizations which actually have the data scale that we

688
00:47:03,520 --> 00:47:05,680
really want to interact with.

689
00:47:05,680 --> 00:47:08,520
And I haven't seen as much of that there, but we're on the way.

690
00:47:08,520 --> 00:47:14,480
And to your point, if we can get the tooling, you know, ready or closer to being, you know,

691
00:47:14,480 --> 00:47:18,920
being mature, as we build those roles in those organizations, I think that's a really

692
00:47:18,920 --> 00:47:19,920
good marriage.

693
00:47:19,920 --> 00:47:20,920
Yeah.

694
00:47:20,920 --> 00:47:21,920
Yeah.

695
00:47:21,920 --> 00:47:22,920
Awesome.

696
00:47:22,920 --> 00:47:24,920
Well, Justin, thanks so much for taking the time to chat with us.

697
00:47:24,920 --> 00:47:27,920
It's been great to meet you.

698
00:47:27,920 --> 00:47:30,920
Welcome to CFFL here to like 90 days.

699
00:47:30,920 --> 00:47:32,920
This is day 90.

700
00:47:32,920 --> 00:47:33,920
Awesome.

701
00:47:33,920 --> 00:47:34,920
Awesome.

702
00:47:34,920 --> 00:47:37,920
Well, I enjoyed the rest of the conference and thank you.

703
00:47:37,920 --> 00:47:45,240
All right, everyone, that's our show for today.

704
00:47:45,240 --> 00:47:49,920
For more information on Justin or any of the topics we covered in this show, visit

705
00:47:49,920 --> 00:47:54,640
twomolei.com slash talk slash 185.

706
00:47:54,640 --> 00:48:00,680
For more information on the entire strata data series, visit twomolei.com slash strata

707
00:48:00,680 --> 00:48:03,520
and why 2018.

708
00:48:03,520 --> 00:48:07,480
Once again, a big thanks to our sponsors, Cladera and Capital One for their sponsorship

709
00:48:07,480 --> 00:48:09,080
of this series.

710
00:48:09,080 --> 00:48:37,600
As always, thanks so much for listening and catch you next time.

