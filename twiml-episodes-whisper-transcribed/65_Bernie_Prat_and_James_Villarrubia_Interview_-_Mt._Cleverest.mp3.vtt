WEBVTT

00:00.000 --> 00:15.920
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

00:15.920 --> 00:20.880
people doing interesting things in machine learning and artificial intelligence.

00:20.880 --> 00:23.360
I'm your host Sam Charrington.

00:23.360 --> 00:28.800
Let me start this show by sending a huge thank you to everyone out there listening.

00:28.800 --> 00:33.680
We've dropped a ton of great interviews over the past few weeks, but through your dedication,

00:33.680 --> 00:40.480
we continue to see a growing outpouring of feedback, comments and shares with each release.

00:40.480 --> 00:44.920
If you're a regular listener, but don't normally send in feedback, we would absolutely

00:44.920 --> 00:46.520
love to hear from you.

00:46.520 --> 00:52.160
So please head on over to Apple Podcasts or wherever you listen and leave us a review.

00:52.160 --> 00:57.480
Of course, a 5 star review is appreciated, but what's most important is that your voice

00:57.480 --> 00:58.480
is heard.

00:58.480 --> 01:03.160
It lets us know what you like or what you feel we could improve on, and it lets those

01:03.160 --> 01:08.000
looking for a new machine learning and AI podcast know that they should join the Twimble

01:08.000 --> 01:09.400
community.

01:09.400 --> 01:15.440
Speaking of community, the details of our next Twimble online meetup have been posted.

01:15.440 --> 01:22.080
On Tuesday, November 14th, a 3pm Pacific time will be joined by Kevin T, who will be presenting

01:22.080 --> 01:27.800
his paper, active preference learning for personalized portfolio construction.

01:27.800 --> 01:31.800
If you're already registered for the meetup, you should have received an invitation with

01:31.800 --> 01:33.680
all the details.

01:33.680 --> 01:39.520
If you've yet to join the meetup, head on over to twimbleai.com slash meetup to do so.

01:39.520 --> 01:41.080
We hope to see you there.

01:41.080 --> 01:46.160
Now, as some of you may know, we spent a few days last week in New York City, hosted

01:46.160 --> 01:49.520
by our great friends at NYU Future Labs.

01:49.520 --> 01:54.000
About 6 months ago, we covered their inaugural AI Summit, which is an event they hosted

01:54.000 --> 01:58.800
to showcase the startups in the first batch of their AI Nexus Lab program, as well as

01:58.800 --> 02:02.360
the impressive AI talent in the New York City ecosystem.

02:02.360 --> 02:07.200
Well, we were more than excited when we found out they would be having a second summit

02:07.200 --> 02:08.680
so soon.

02:08.680 --> 02:13.760
This time, we had the pleasure of interviewing the four startups of the second AI Nexus

02:13.760 --> 02:20.840
Lab batch, Mount Cleverist, Bite.ai, Second Mind, and Bowtie Labs.

02:20.840 --> 02:25.080
We also interviewed a bunch of the speakers from the event and will be sharing those discussions

02:25.080 --> 02:27.040
over the upcoming weeks.

02:27.040 --> 02:32.480
In this first episode of the series, you'll hear from Mount Cleverist, a startup started

02:32.480 --> 02:37.480
by childhood friends, James Villarubia, and Bernie Pratt.

02:37.480 --> 02:42.480
Mount Cleverist is an online service for teachers and students that can take any text via

02:42.480 --> 02:48.160
the web and generate a quiz along with answers based on the content supplied.

02:48.160 --> 02:52.800
To do this, they employ a pretty sophisticated natural language understanding pipeline,

02:52.800 --> 02:54.920
which we discuss in this interview.

02:54.920 --> 02:59.760
We also touch on the challenges they face in generating correct question answers, how

02:59.760 --> 03:05.240
they fine tune their machine learning models to improve those answers over time and more.

03:05.240 --> 03:07.600
And now on to the show.

03:07.600 --> 03:18.000
Alright everyone, I am here at NYU Future Labs, meeting with

03:18.000 --> 03:21.240
some of the AI Nexus Lab companies.

03:21.240 --> 03:27.000
And the first company into the interrogation room is Mount Cleverist.

03:27.000 --> 03:33.560
And I'm here with the CEO, James Villarubia, and the COO, Bernie Pratt.

03:33.560 --> 03:36.280
Welcome to this week in machine learning and AI.

03:36.280 --> 03:38.280
Thanks for having us, yeah.

03:38.280 --> 03:43.560
So why don't we get started with an introduction to the two of you, your backgrounds, as well

03:43.560 --> 03:46.280
as the company and what the company is up to?

03:46.280 --> 03:47.280
Sure.

03:47.280 --> 03:51.480
So my background is really as an engineering statistician.

03:51.480 --> 03:56.360
I got an engineering degree from UVA, then a master's in public policy, mostly focused

03:56.360 --> 03:57.680
on tech policy.

03:57.680 --> 04:02.320
And what I found was the coolest, most interesting problems out there to solve were just engineering

04:02.320 --> 04:03.320
ones.

04:03.320 --> 04:04.320
They were political ones.

04:04.320 --> 04:05.800
They're big picture policy stuff.

04:05.800 --> 04:10.400
So I jumped into the Pentagon as a statistician and then briefly went to the White House and

04:10.400 --> 04:12.040
then find the DOJ.

04:12.040 --> 04:16.800
And then I got kind of tired of DC and got the startup bug and came up to here to New

04:16.800 --> 04:20.760
York and helped run a cybersecurity company for a couple of years, until eventually this

04:20.760 --> 04:25.280
idea that we had about Mount Cloverist finally kind of peaked the right person's interest.

04:25.280 --> 04:26.960
And they said, go do that.

04:26.960 --> 04:30.800
And we said, great, we've been trying to get it going for a long time, so we're really

04:30.800 --> 04:31.800
excited.

04:31.800 --> 04:32.800
Thanks, James.

04:32.800 --> 04:33.800
And Bernie, how about you?

04:33.800 --> 04:34.800
Sure.

04:34.800 --> 04:39.080
So I moved up to New York right after college and we did some work in a startup in finance

04:39.080 --> 04:43.840
where we were pulling data out of press releases to send to programmatic traders.

04:43.840 --> 04:48.840
And this allowed us to get into machine learning and natural language processing early on in

04:48.840 --> 04:49.840
my career.

04:49.840 --> 04:53.720
Not as an engineer, but as a manager of engineers doing product work primarily.

04:53.720 --> 04:57.680
From there, I bounced around into a few different places, again, in product positions, but

04:57.680 --> 05:00.560
very, very data heavy, API heavy.

05:00.560 --> 05:03.200
And James and I, we've actually been friends for about 25 years.

05:03.200 --> 05:04.200
We met in kindergarten.

05:04.200 --> 05:05.200
Oh, wow.

05:05.200 --> 05:06.200
Yeah.

05:06.200 --> 05:07.200
And so.

05:07.200 --> 05:08.200
It's the first time I've heard that.

05:08.200 --> 05:09.200
Photo evidence, too.

05:09.200 --> 05:11.200
It used to be part of our pitch.

05:11.200 --> 05:12.200
Nice.

05:12.200 --> 05:16.280
We were friends for a very long time and had always wanted to work together after doing.

05:16.280 --> 05:19.960
So we went to high school together as well and did some good work in a few number of

05:19.960 --> 05:20.960
different areas.

05:20.960 --> 05:22.960
But this was the chance for a school.

05:22.960 --> 05:23.960
Yeah.

05:23.960 --> 05:24.960
We were in ROTC together.

05:24.960 --> 05:30.560
James was doing the band and the newspaper and I was a member of that and we were just

05:30.560 --> 05:31.560
all over the place.

05:31.560 --> 05:36.040
We had ones in Bangkok.

05:36.040 --> 05:39.040
Bernie never went, but I don't, I don't, we don't talk about that.

05:39.040 --> 05:40.040
I know.

05:40.040 --> 05:41.040
Yeah.

05:41.040 --> 05:42.040
Nice.

05:42.040 --> 05:43.640
This is an opportunity for us to work together.

05:43.640 --> 05:44.640
Yeah.

05:44.640 --> 05:45.640
Finally.

05:45.640 --> 05:46.640
Awesome.

05:46.640 --> 05:47.640
Awesome.

05:47.640 --> 05:48.640
And so Mt.

05:48.640 --> 05:49.640
Cleverist.

05:49.640 --> 05:50.640
I love the name.

05:50.640 --> 05:52.240
It's actually rather clever.

05:52.240 --> 05:53.800
What does the company do?

05:53.800 --> 05:56.280
So we actually started the company kind of based off an idea.

05:56.280 --> 05:59.560
We had seven, some seven years ago.

05:59.560 --> 06:00.680
My parents are both teachers.

06:00.680 --> 06:04.320
I actually still teach at UVA part-time, cybersecurity.

06:04.320 --> 06:09.200
And what we realized is that growing up, I see my parents deal with kind of bad textbooks,

06:09.200 --> 06:13.000
that kind of handed down to them from the administration that they had to kind of bend

06:13.000 --> 06:15.000
to meet the needs of the classroom.

06:15.000 --> 06:18.440
And we were iterating through ideas and that was the one that I said, no, like if we could

06:18.440 --> 06:21.960
figure out a way to solve this, like this would be really valuable because my parents

06:21.960 --> 06:24.160
just always were complaining about it.

06:24.160 --> 06:27.960
So we didn't really quite know the approach yet and we didn't have necessarily the NLP

06:27.960 --> 06:30.480
and machine learning skills to really tackle it yet.

06:30.480 --> 06:34.080
But as the industry has grown and kind of our skills have grown, we said, okay, this is

06:34.080 --> 06:35.680
something we can apply.

06:35.680 --> 06:39.520
NLP, machine learning, neural nets, and solve this kind of selection problem.

06:39.520 --> 06:45.680
So what Mount Clevrist does is we can take any content on the web, URL, piece of text,

06:45.680 --> 06:49.640
and then generate quiz questions on the fly on that text in a matter of seconds.

06:49.640 --> 06:53.240
And then the kind of the real advantage, though, is not just creating the questions.

06:53.240 --> 06:55.840
But after that, we track every interaction with that quiz.

06:55.840 --> 06:59.840
What students get wrong, what they get right, how long they take with each question.

06:59.840 --> 07:03.480
What questions and answers teachers like and don't like, what they want to use, feed

07:03.480 --> 07:08.200
that into a neural net that then improves the system, improves the quiz for the next person.

07:08.200 --> 07:12.120
So it's actually really at the end of the day, it ends up being one big online textbook

07:12.120 --> 07:16.000
that actually improves itself the more you use it.

07:16.000 --> 07:17.000
Interesting.

07:17.000 --> 07:18.000
Interesting.

07:18.000 --> 07:24.520
And so I'm familiar with the, there's a ton of research happening around question answering,

07:24.520 --> 07:28.360
which is, you know, you have a body of text, you kind of start with some questions and

07:28.360 --> 07:32.120
then you use AI machine learning to try to answer those questions.

07:32.120 --> 07:37.240
You've kind of inverted that and you're using AI to generate the questions, as well as

07:37.240 --> 07:42.040
the answers and track the kind of track and adjust over time.

07:42.040 --> 07:47.160
Is that as established a research area, the question asking piece?

07:47.160 --> 07:49.160
Not so much.

07:49.160 --> 07:54.560
I mean, a few years ago, there were very few papers, at least now there are some interesting

07:54.560 --> 07:58.240
work being done, but again, nothing substantial because a lot of it has been driven by kind

07:58.240 --> 08:04.000
of the question answering Alexa, kind of Siri approach to machine learning.

08:04.000 --> 08:09.160
What the question that has, or that what has been tackled in machine learning is this idea

08:09.160 --> 08:12.760
of taking a mass amount of text and figuring out a good question, come around it, kind

08:12.760 --> 08:13.760
of the Watson model.

08:13.760 --> 08:14.760
Okay, Jeopardy.

08:14.760 --> 08:18.360
So being able to parse mass amounts of text and generate one question, maybe a very well-formed

08:18.360 --> 08:20.720
question, but it's one question.

08:20.720 --> 08:25.360
Our problem and the really kind of the heart of our tech is that we take a very limited

08:25.360 --> 08:31.040
amount of text and be able to generate 100, 120 questions off of one piece of text, each

08:31.040 --> 08:32.920
asking about something different.

08:32.920 --> 08:36.600
Then the kind of extra level of difficulty is then great, you've got a question, you've

08:36.600 --> 08:38.520
got an answer that you've drawn out.

08:38.520 --> 08:40.440
How do I generate good, wrong answers?

08:40.440 --> 08:45.160
How do I find a question or an answer that is a good distractor from the correct answer?

08:45.160 --> 08:47.960
So I put a multiple choice question in front of a kid.

08:47.960 --> 08:51.640
If it's so close to the right answer that it's confusing, that's bad.

08:51.640 --> 08:55.320
If it's so far away that they would never guess it anyway, it's also bad.

08:55.320 --> 08:59.840
So you've got to find the kind of that Goldilocks middle ground on kind of good distractors.

08:59.840 --> 09:02.960
And that was really probably the heart of the NLP problem.

09:02.960 --> 09:08.320
I'm imagining like a dial where you can kind of tune the question for difficulty or I

09:08.320 --> 09:12.720
guess a big part of the neural net piece that you described is about kind of normalizing

09:12.720 --> 09:18.920
the question answer set so that your kind of average ends up where you want it to be.

09:18.920 --> 09:20.480
Is that a good way to think about it?

09:20.480 --> 09:25.120
Yeah, so we can actually look at kind of the readability of the text or kind of industry

09:25.120 --> 09:29.400
standard scoring mechanism to take a chunk of text and figure out what grade levels this

09:29.400 --> 09:30.400
would be appropriate for.

09:30.400 --> 09:34.560
So the origin text, we can actually kind of guess at what good, what these questions are

09:34.560 --> 09:37.960
going to come out kind of referring to in terms of like is this a fifth grade text or

09:37.960 --> 09:39.040
is this a seventh grade text.

09:39.040 --> 09:43.040
We're actually working on some tech to be able to convert something that is maybe written

09:43.040 --> 09:46.960
at a 12th grade level down to a ninth grade level and then kind of use questions that are

09:46.960 --> 09:48.240
more appropriate for that.

09:48.240 --> 09:50.240
That's kind of in a coming release.

09:50.240 --> 09:55.520
But yeah, it's being able to correctly pick questions that are appropriate for grade

09:55.520 --> 10:00.480
level and answers that are appropriate for a grade level is a whole layer of complexity

10:00.480 --> 10:04.040
that a lot of other, you know, tech solutions don't really think about, but it's unique

10:04.040 --> 10:05.520
to the education space.

10:05.520 --> 10:06.520
Okay.

10:06.520 --> 10:13.200
I think of educators as folks that kind of want to have a lot of control over their source

10:13.200 --> 10:14.200
materials.

10:14.200 --> 10:19.640
Like how does this approach land for them relative to what they're used to?

10:19.640 --> 10:22.360
So we're kind of taking this problem in two different ways.

10:22.360 --> 10:27.200
The first is the initial product allows a teacher to bring in whatever content they would

10:27.200 --> 10:28.200
like.

10:28.200 --> 10:32.280
So if they found a news article that is exciting and relates to their class or if they

10:32.280 --> 10:37.000
have a page that they've been using and sending students to for years instead of having

10:37.000 --> 10:42.400
that all based on paper in terms of the grading, we're actually pulling that in and tracking

10:42.400 --> 10:43.640
that information.

10:43.640 --> 10:47.840
On the other side, there's a search component that you kind of brought into it and we're

10:47.840 --> 10:52.960
working towards it, that is the broader vision of having a collection, a universe of content

10:52.960 --> 10:54.760
and then being able to rank and sort that.

10:54.760 --> 10:57.760
So there's the create problem and then there's the ranking and sorting.

10:57.760 --> 10:59.800
So we kind of split those intentionally.

10:59.800 --> 11:02.880
The control issue, it's something we want to get into.

11:02.880 --> 11:07.600
We know that it's a political battle in the lightest of terms because it's not true

11:07.600 --> 11:10.280
politics, but yes, that is something that we see often.

11:10.280 --> 11:15.440
So we're coming up with ways to either encourage behavior in a certain way to kind of let

11:15.440 --> 11:20.120
go of that, including automatic randomization of questions or adding in questions from

11:20.120 --> 11:23.600
a different source that are applicable to the source that was provided.

11:23.600 --> 11:28.840
So we're actually swapping in new information and using that as part of the quiz for students.

11:28.840 --> 11:34.560
So it's not a standardization, but it's instead a way for us to help determine the quality

11:34.560 --> 11:37.200
of content as well as the students understand.

11:37.200 --> 11:39.720
And so there's kind of a couple of different problems there.

11:39.720 --> 11:45.400
There's also a distinction in education between formative assessment and somewhat of assessment.

11:45.400 --> 11:50.200
And this idea that teachers get really kind of close hold on exams because they want to

11:50.200 --> 11:54.480
be able to kind of assign really clear grades and hold those students accountable and make

11:54.480 --> 11:57.560
sure they can kind of deal with parents that disagree with those grades.

11:57.560 --> 11:59.520
They have to have kind of a clear, clear chain.

11:59.520 --> 12:04.160
But what has been kind of lost is this idea of this formative assessment that I want

12:04.160 --> 12:08.400
to have homework that a kid can try over and over again until they get it right because

12:08.400 --> 12:12.280
I'm actually interested in them learning it, not just grading on their first guess.

12:12.280 --> 12:16.400
So what Mount Clevver says really focuses on is kind of trying to get the teacher to

12:16.400 --> 12:21.120
not think about the quiz that we are providing as summative, as yet you're going to get grades

12:21.120 --> 12:22.880
and this is going to account to the report card.

12:22.880 --> 12:27.560
But more of a, get good questions in front of the kid to make sure that they understand

12:27.560 --> 12:31.560
the content and they can take that quiz as many times as possible until they really grasp

12:31.560 --> 12:32.560
it or master it.

12:32.560 --> 12:33.560
Okay.

12:33.560 --> 12:37.280
Can you talk a little bit about the pipeline that you used to deliver this from a machine

12:37.280 --> 12:38.600
learning perspective?

12:38.600 --> 12:39.600
Yeah.

12:39.600 --> 12:44.720
It's, it's funny because we get a lot of, we get a lot of questions about like, oh,

12:44.720 --> 12:49.360
we can't, like, can't, can't just be done by a machine learning model off the shelf.

12:49.360 --> 12:55.080
And yes and no, in the sense that, in the sense that we are using some kind of, you know,

12:55.080 --> 13:00.520
some basic, you know, basic kind of industry tried and true NLP models and neural nets.

13:00.520 --> 13:01.520
What are some of those?

13:01.520 --> 13:06.080
I mean, we are leveraging a lot of NER for a name that's a recognition using some kind

13:06.080 --> 13:10.280
of interesting, interesting math around word vectors, what do I call like the donut model

13:10.280 --> 13:13.320
saying, okay, I want to find similar words, but then, like, go up and then remove the

13:13.320 --> 13:17.360
word that are really similar to find those kind of, again, the Goldilocks distractors.

13:17.360 --> 13:19.840
So those are kind of the approaches that we're doing in the neural nets.

13:19.840 --> 13:23.560
We're trying lots of different things because that part of the product is still kind

13:23.560 --> 13:27.840
of not nascent, but we're getting there, so we're still kind of refining that.

13:27.840 --> 13:31.520
But the pipeline itself, actually, what's interesting about Mount Cleverist is that it's not

13:31.520 --> 13:37.400
just one huge big model with a model, is that we have to build, you know, an NLP that

13:37.400 --> 13:41.240
can generate, you know, dozens of types of questions, so each one has its own kind of

13:41.240 --> 13:42.240
pipeline.

13:42.240 --> 13:46.320
She's that into a unified data structure, but then we have to normalize questions against

13:46.320 --> 13:49.360
questions, answers against answers, formats against formats.

13:49.360 --> 13:53.440
So even within the ranking system, within one lesson, within one subject, we might have

13:53.440 --> 13:58.680
a whole series of models, each, again, not necessarily huge, robust, crazy big models,

13:58.680 --> 14:01.680
but each doing is a unique specific thing.

14:01.680 --> 14:02.680
Live right on that.

14:02.680 --> 14:06.280
What do you mean by normalizing questions against questions, and are we talking about in terms

14:06.280 --> 14:08.320
of their difficulty and things like that?

14:08.320 --> 14:09.320
Right.

14:09.320 --> 14:14.240
So in terms of their difficulty, so imagine you're a teacher and you've created a lesson,

14:14.240 --> 14:18.000
and you want to, like, we've generated, let's say, a hundred quiz questions.

14:18.000 --> 14:20.960
Now some of those are not going to be great because the NLP isn't perfect.

14:20.960 --> 14:23.280
No, we don't know many products that are perfect.

14:23.280 --> 14:25.560
So we want that kind of human and the loop feedback.

14:25.560 --> 14:28.840
So we are capturing, kind of, what, you know, the upvotes and downvotes similar to kind

14:28.840 --> 14:33.280
of Reddit of what teachers like and don't like, but at the question at the answer level.

14:33.280 --> 14:36.720
So we get that, just that base level, kind of, like, how many people have upvoted, how

14:36.720 --> 14:39.720
many people have liked or disliked this particular piece.

14:39.720 --> 14:42.040
But then we've got this kind of student performance data on the back end.

14:42.040 --> 14:46.600
So okay, well, when I showed this question in this format, in this context, like, this

14:46.600 --> 14:48.920
is how well a student did, given how long they took.

14:48.920 --> 14:52.920
So normalizing that data means that I have to take every interaction with every question

14:52.920 --> 14:56.840
or format or answer, and then trying to figure out, okay, even though this question has

14:56.840 --> 15:01.200
been shown to, you know, 10 different students in 10 different ways, how do I judge its effectiveness?

15:01.200 --> 15:04.800
Is this a good measure of learning on this particular topic?

15:04.800 --> 15:07.120
So like, that's the normalization that we're talking about.

15:07.120 --> 15:12.960
And is that, like, some big batch job that runs every X day or week or something, or

15:12.960 --> 15:16.960
is it something that you just kind of trigger it's erratically?

15:16.960 --> 15:22.520
So we've actually made kind of a goal of the product to not do things in batch.

15:22.520 --> 15:26.120
Which was, it was a bold goal, it may slow this down a little bit.

15:26.120 --> 15:30.120
But we actually wanted, we set the goal from the user experience levels that we wanted

15:30.120 --> 15:33.320
the quiz to improve on a, like, per interaction basis.

15:33.320 --> 15:39.920
So like, every time a kid answers a question, exactly, it re-jiggers the entire, re-, does

15:39.920 --> 15:40.920
that mean-

15:40.920 --> 15:45.040
So by the time the second student sees the quiz, it's actually improved and changed and

15:45.040 --> 15:47.520
learned from the results of the first student.

15:47.520 --> 15:53.840
And is that learning, does that mean that you are, like, retraining models in that whole

15:53.840 --> 15:54.840
pipeline?

15:54.840 --> 15:55.840
Or does it mean that-

15:55.840 --> 15:59.200
Are there some set of heuristics that you're using to kind of massage weights or things

15:59.200 --> 16:01.360
like that without having to retrain all your models?

16:01.360 --> 16:02.360
A bit of both.

16:02.360 --> 16:06.080
So we don't retrain the model every run through, though we do have some kind of tail-trained

16:06.080 --> 16:07.200
models kind of worked in.

16:07.200 --> 16:11.280
But most of it is capturing kind of the heuristics of the performance with those questions in

16:11.280 --> 16:12.600
this format.

16:12.600 --> 16:16.680
And capturing that and then feeding that back in as additional information into the model

16:16.680 --> 16:19.960
as we then kind of randomize and select what we want to do and what we want to show to

16:19.960 --> 16:21.400
the second student.

16:21.400 --> 16:25.440
So it's the heuristics of the first student fed back into the same model, tail-trained

16:25.440 --> 16:29.200
a couple pieces, and then kind of what you get, we're like, oh, tried this version of

16:29.200 --> 16:32.880
this content, or this version of this question with these answers in this format instead

16:32.880 --> 16:36.840
of the old one because that old version, it wasn't a great test, but this one might

16:36.840 --> 16:37.840
be.

16:37.840 --> 16:40.920
So it's a little bit of randomization, a little bit of kind of design of experiments,

16:40.920 --> 16:44.520
constantly trying to say, okay, how, you know, reduce how many experiments or variations

16:44.520 --> 16:47.200
do we need to run before we figure out what the best stuff is?

16:47.200 --> 16:48.200
Okay.

16:48.200 --> 16:54.760
And in terms of identifying the target content in the first place, is that are the educators,

16:54.760 --> 17:00.240
you know, feeding URLs into the system to direct you, or are you doing some ML, German,

17:00.240 --> 17:04.480
crawling, or something like that to figure out the interesting content out there?

17:04.480 --> 17:08.680
At the moment, we're relying on the, what we consider the expert networks of teachers.

17:08.680 --> 17:12.960
So we want the educators to be the one providing content that they have used in the past, and

17:12.960 --> 17:17.000
then we'll be doing that ranking in order to help them either bubble up what is better,

17:17.000 --> 17:20.240
or take advantage of the stuff that they've tried in true sources.

17:20.240 --> 17:24.880
So a lot of the open educational resources movement from the Obama administration has been

17:24.880 --> 17:25.880
very helpful in that.

17:25.880 --> 17:31.200
And a lot of institutions, as well as a lot of individuals, are now providing content

17:31.200 --> 17:36.200
openly available under Creative Commons license, or MIT license, whatever it might be, is

17:36.200 --> 17:40.880
now available to us and not behind the paywall, not under the umbrella of one of the large

17:40.880 --> 17:42.640
publishers or anything like that.

17:42.640 --> 17:45.480
So it's taking advantage of that recent trend.

17:45.480 --> 17:46.480
Okay.

17:46.480 --> 17:47.480
Interesting.

17:47.480 --> 17:51.480
What have been kind of the biggest challenges in pulling this all together?

17:51.480 --> 17:55.040
Well, I think that the biggest challenge was designing that data structure.

17:55.040 --> 17:59.920
So again, we have all of these different models, all looking at essentially the same data,

17:59.920 --> 18:03.800
and how you store that, and how you store that in a way that can be kind of lightweight,

18:03.800 --> 18:07.200
pulled in the moment, you know, in between quiz questions.

18:07.200 --> 18:10.440
That was something that I think both of us had to kind of take a step back and say,

18:10.440 --> 18:17.680
how do we store this data at scale, but as we're small, but also at scale, kind of building

18:17.680 --> 18:22.200
towards this bigger architecture, being able to track what I like to call kind of the context

18:22.200 --> 18:26.440
mapping, that it was this version of the question with these answers shown, like maybe there

18:26.440 --> 18:30.520
are 10 wrong answers, but we only showed four, and it was a true false or a multiple choice

18:30.520 --> 18:32.400
with the none of the above, not this.

18:32.400 --> 18:37.920
So being able to capture all that context, and store that, and then correctly tease it

18:37.920 --> 18:40.320
out, and then build a model against it.

18:40.320 --> 18:44.600
Turning out what that included, and how to put all the pieces of data together.

18:44.600 --> 18:45.600
That was interesting.

18:45.600 --> 18:52.680
We have a model in the tool called a quinstance, which is a quiz instance, because we've got

18:52.680 --> 18:57.080
to generate a quiz, and it might have teacher preferences at one given moment, but then

18:57.080 --> 19:01.640
within that quiz, within the context, we need to have an individualized version for each

19:01.640 --> 19:04.600
student that they experience at that moment in time.

19:04.600 --> 19:06.400
It's like, how do we further that?

19:06.400 --> 19:08.080
It's a quiz, but that's also a quiz.

19:08.080 --> 19:12.360
So it's quinstance became our term, and it's been great.

19:12.360 --> 19:15.560
But we have a lot of those little things that we have to figure out on the way that we

19:15.560 --> 19:20.400
have to structure this and store this in a unique way that I think gives us an advantage

19:20.400 --> 19:23.800
in the market that I think other people have really thought about data for education this

19:23.800 --> 19:24.800
way yet.

19:24.800 --> 19:28.160
And so for folks that are like, how did you approach that problem?

19:28.160 --> 19:32.000
Did you just stumble upon the answer, or did you just try out everything that was out

19:32.000 --> 19:35.800
there and see what worked, and like, what did you end up doing?

19:35.800 --> 19:36.800
These are so-or-subject.

19:36.800 --> 19:41.880
Oh man, flashbacks.

19:41.880 --> 19:47.520
I actually, when we first started trying to build this, I was just like a, you know, a budding

19:47.520 --> 19:48.520
web developer.

19:48.520 --> 19:53.600
I actually built the whole tool without a lot of the neural nets I hadn't quite gotten

19:53.600 --> 19:54.600
there yet.

19:54.600 --> 19:58.120
But I built my own kind of parsing engine and NLP engine out of PHP, because it was the

19:58.120 --> 19:59.360
only language I knew.

19:59.360 --> 20:01.920
Right, so I had a lot of lessons learned.

20:01.920 --> 20:05.520
Right, so it was a terrible, terrible idea.

20:05.520 --> 20:08.120
I think, on the front end, it was like a Drupal 6.

20:08.120 --> 20:09.120
It was.

20:09.120 --> 20:10.120
Right, exactly.

20:10.120 --> 20:13.800
Not out of these moments, but like, it was a learning experience.

20:13.800 --> 20:14.800
But exactly.

20:14.800 --> 20:18.200
And like, I got 10 times better as a developer, and it's like, it jumps under, I think,

20:18.200 --> 20:20.360
a lot of my career just being, having to suffer through that.

20:20.360 --> 20:24.080
So having a really good problem to chew on for a long time.

20:24.080 --> 20:26.560
And then I eventually said, OK, well, no, Python is better for this.

20:26.560 --> 20:28.560
There's Java libraries that I can incorporate.

20:28.560 --> 20:30.480
I need to stand up microservices architectures.

20:30.480 --> 20:34.160
Right now, we have, I think, 14 different microservices, each running even different parts

20:34.160 --> 20:37.640
of the models, all talking to each other, leveraging the same data set, caching some parts

20:37.640 --> 20:38.640
here and there.

20:38.640 --> 20:42.640
So I mean, but I had to learn that kind of all on my own, starting with that poor, poor

20:42.640 --> 20:43.640
Drupal site.

20:43.640 --> 20:47.000
But yeah, that's, that's, is, is trial and error could have been more press.

20:47.000 --> 20:54.040
It, it, it, it, it almost was, I thought it was a band when I found Lyravelle.

20:54.040 --> 20:57.920
I was like, oh man, it's not Drupal, but, yeah.

20:57.920 --> 21:02.280
And in terms of the data store, did you like, is it like some kind of document oriented

21:02.280 --> 21:07.520
MongoDB type of thing or like a Cassandra or what direction did you go?

21:07.520 --> 21:11.440
We actually, because we didn't really know what we were doing, and I think that's actually

21:11.440 --> 21:15.600
a great use case for Mongo is that it's a kind of a turnkey solution and you can kind

21:15.600 --> 21:17.240
of drop in whatever you want.

21:17.240 --> 21:19.960
And then there are a lot of kind of lightweight ORMs on top of it.

21:19.960 --> 21:22.320
So you can change the model and it doesn't break everything.

21:22.320 --> 21:24.560
You just have to go back and kind of clean some stuff later.

21:24.560 --> 21:28.920
So we've been doing Mongo for probably the last year as we kind of moved to a more production

21:28.920 --> 21:33.280
level product, but we've now hit the wall or think, okay, the type, you know, the model

21:33.280 --> 21:34.520
types have kind of settled.

21:34.520 --> 21:35.880
We kind of know what our structure is.

21:35.880 --> 21:37.520
We know what it needs to be.

21:37.520 --> 21:38.520
We've thought it out.

21:38.520 --> 21:41.000
We've been in the wild and see what happened.

21:41.000 --> 21:43.680
So now we're actually moving to kind of a combination of things.

21:43.680 --> 21:48.200
Probably some kind of Mongo or other, you know, no SQL database for a lot of the document

21:48.200 --> 21:49.200
structure.

21:49.200 --> 21:53.680
And then probably Cassandra for a lot of the, like the interactions, the, in the moment

21:53.680 --> 21:57.440
interactions because it's ability to scale kind of linearly where everyone else kind

21:57.440 --> 22:00.360
of stops at a certain certain point.

22:00.360 --> 22:01.360
So yeah.

22:01.360 --> 22:03.960
So we were, I'm really excited to move to Cassandra, but Cassandra, you know, also has some,

22:03.960 --> 22:06.800
you know, issues around search, you got to, you got to figure out how to get searched

22:06.800 --> 22:07.800
on.

22:07.800 --> 22:10.120
So there's a lot of other, you know, different ways looking at, you know, postgres for

22:10.120 --> 22:12.520
other certain features because you can index and search there.

22:12.520 --> 22:14.960
So we're actually moving to a more complex model.

22:14.960 --> 22:19.200
But again, each database has to fit a different part of the system.

22:19.200 --> 22:23.040
And we now know how that system really needs to, like, be set up to, you know, run at

22:23.040 --> 22:24.040
light speed.

22:24.040 --> 22:25.040
Okay.

22:25.040 --> 22:30.000
So given that you're doing kind of the interactive updating and all that kind of stuff, I'm assuming

22:30.000 --> 22:35.560
that's not so PHP, is that like so far or it is almost like there's a little bit of

22:35.560 --> 22:39.960
Python on the back end, some Java libraries that haven't like written, but kind of leveraging

22:39.960 --> 22:41.120
some open source stuff.

22:41.120 --> 22:45.760
But primarily the entire stack has written in JavaScript, leveraging Amazon Lambda and

22:45.760 --> 22:47.040
then react to the front end.

22:47.040 --> 22:53.200
So we have made this is a if, you know, the heavens opened up and, and to God said, yes,

22:53.200 --> 22:57.760
please like go use this product and we had massive scale that we are set up to, you know,

22:57.760 --> 22:58.760
I assume handle it.

22:58.760 --> 22:59.760
Scale breaks everything.

22:59.760 --> 23:02.920
But we knew that there was going to be so much compute that we wanted to make sure we

23:02.920 --> 23:05.000
could kind of turn every little lever.

23:05.000 --> 23:09.040
So all those microservices are, most of them are speaking, you know, Lambda to each other.

23:09.040 --> 23:13.440
And it also means that the models are lightweight enough in some respects that we can offload

23:13.440 --> 23:16.080
some of that model computation to the browser.

23:16.080 --> 23:18.360
So we have this JavaScript written neural nets.

23:18.360 --> 23:23.800
So I can actually load some of the early computation onto the computer for the teacher or the user

23:23.800 --> 23:27.800
or the phone and then do the computation and just pass back the results and kind of offload

23:27.800 --> 23:30.800
a good 20 to 30% of our load back onto the user.

23:30.800 --> 23:33.680
So we're not doing it now, but we are set up to do that eventually.

23:33.680 --> 23:34.680
Oh, wow.

23:34.680 --> 23:40.080
And are you using any particular open source library to do the front end inference?

23:40.080 --> 23:42.360
Oh, I want to do right that yourself.

23:42.360 --> 23:47.560
No, that's a combination of synaptic, I think synaptic.js was the one reason right now.

23:47.560 --> 23:49.480
And that is, there have been many variations.

23:49.480 --> 23:51.960
I think the first one we used was called brain.

23:51.960 --> 23:56.080
There's a lot of JavaScript libraries that are just coming out where they said, I want

23:56.080 --> 23:58.360
to write JavaScript and I want to do neural nets.

23:58.360 --> 24:00.480
And they can do some pretty cool things on the browser.

24:00.480 --> 24:04.320
Not necessarily the big scale stuff that we want to do on some of our calculations, but

24:04.320 --> 24:07.880
a lot of the smaller, like within a document, within a document, you could have known

24:07.880 --> 24:11.200
document space, we can do that on the browser side and we're, you know, going to shift

24:11.200 --> 24:12.600
to that model later.

24:12.600 --> 24:13.600
Hmm.

24:13.600 --> 24:14.600
Interesting.

24:14.600 --> 24:18.960
I'm trying to think through the way I've envisioned your process.

24:18.960 --> 24:23.560
You get these documents, you're doing a bunch of what I think of as backend processing

24:23.560 --> 24:28.320
to come up with questions and answers and normalize them and all that kind of stuff.

24:28.320 --> 24:32.680
What would you want to do on the front end that would require, you know, running the inference

24:32.680 --> 24:36.040
locally or would take advantage of that if not required?

24:36.040 --> 24:39.840
So the first thing you do kind of as a user is you drop in the URL, eventually it'll

24:39.840 --> 24:43.440
be search term or URL, but right now we're focused on kind of new content capture.

24:43.440 --> 24:48.600
You drop into URL and then immediately we go scrape that content from that URL and then

24:48.600 --> 24:49.600
start parsing it.

24:49.600 --> 24:52.440
And a lot of that parsing work right now we're handling the backend, but it can be handled

24:52.440 --> 24:53.440
by the browser.

24:53.440 --> 24:54.440
Oh, got it.

24:54.440 --> 24:55.440
Right.

24:55.440 --> 24:58.000
So that is actually a big portion of the compute because it's a lot of parsing.

24:58.000 --> 25:02.320
But if that can be off offload instead of 10 people doing it all on one of our machines

25:02.320 --> 25:06.440
or a series of Lambda functions, but pushing that to the browser, because that's kind of,

25:06.440 --> 25:09.800
it's not proprietary stuff, it's not crazy, you know, complicated, but it just needs to

25:09.800 --> 25:10.800
get done.

25:10.800 --> 25:13.800
Someone needs to pull out, you know, named entities, someone needs to, you know, to

25:13.800 --> 25:16.960
break, do sentence barrier detection, all that stuff can be handled, then we just want

25:16.960 --> 25:17.960
the results.

25:17.960 --> 25:21.840
And then we get to kind of the nitty gritty of the data on the backend.

25:21.840 --> 25:26.200
It strikes me that if a lot of folks aren't doing that now, that's going to be kind of

25:26.200 --> 25:30.400
a popular way to do cooperative compute.

25:30.400 --> 25:34.120
It's almost like, you know, having your users, you know, mine Bitcoin for you before the

25:34.120 --> 25:41.120
legitimate link.

25:41.120 --> 25:42.120
Right.

25:42.120 --> 25:43.120
The only other industry that I know is really doing that is Bitcoin and not, you know, like,

25:43.120 --> 25:49.560
oh, like, my advertising window is mining Bitcoin for someone in the Ukraine, so, yeah.

25:49.560 --> 25:52.560
But I was like, okay, well, how, like, when I read that, I was like, that's a really cool

25:52.560 --> 25:53.560
architecture.

25:53.560 --> 25:56.480
And like, we'd already been kind of thinking about this as like, oh, so like someone's

25:56.480 --> 25:58.000
proving that this is doable.

25:58.000 --> 26:01.760
So it was kind of a check in the box with, yes, this is maybe where architecture should

26:01.760 --> 26:02.760
go.

26:02.760 --> 26:06.600
And it strikes me that that could be a startup in and of itself, right?

26:06.600 --> 26:10.680
So there's an architecture because there's all kinds of problems that you can run into

26:10.680 --> 26:15.240
of like, you know, the process is stealing all the compute and usability issues and stuff

26:15.240 --> 26:16.240
like that.

26:16.240 --> 26:17.240
Yeah.

26:17.240 --> 26:19.200
If we figure that out, then we can shift to maybe that'll be our second business once we

26:19.200 --> 26:20.200
sell this.

26:20.200 --> 26:21.200
Yeah.

26:21.200 --> 26:22.200
Nice.

26:22.200 --> 26:27.080
You know, given all that, all that technology, like, there's tons of folks, particularly

26:27.080 --> 26:31.640
here in New York City, right, doing ed tech, what makes you different.

26:31.640 --> 26:34.600
So we've been, you know, been doing this project for a long time.

26:34.600 --> 26:38.080
So we've been watching the ed tech market when the booms and busts thing were on the third

26:38.080 --> 26:40.800
boom right now that we've been paying attention to.

26:40.800 --> 26:44.120
And we keep seeing investors getting burned and mostly because they keep investing kind

26:44.120 --> 26:47.240
of this, what seems like a really cool new thing.

26:47.240 --> 26:50.880
But in reality, it falls into kind of like two standard business models.

26:50.880 --> 26:54.520
One we call it kind of a warehouse model, which is just collect as much information as possible

26:54.520 --> 26:56.040
and then make it searchable.

26:56.040 --> 27:00.440
But if you look at some of the products out there, you find that those, the search algorithms

27:00.440 --> 27:02.080
are poor at best.

27:02.080 --> 27:04.760
And they're not searching on like real performance data, just keywords.

27:04.760 --> 27:08.200
So you end up getting like a big warehouse and you'll search for the War of 1812, for

27:08.200 --> 27:10.680
example, you get 342 results.

27:10.680 --> 27:14.280
I'm not speaking about any product, particularly.

27:14.280 --> 27:18.240
And all of them are ranked 3.9 or four stars out of four stars.

27:18.240 --> 27:22.000
So as a teacher, like, I tried to use that, I was like, this is useless for me.

27:22.000 --> 27:23.000
Great.

27:23.000 --> 27:26.800
So I'm like, am I going to open 342 PDFs and then read them and say, oh, I think this

27:26.800 --> 27:27.800
want to work.

27:27.800 --> 27:30.400
And even if I learned, oh, this one actually was effective.

27:30.400 --> 27:33.840
I have no way to really transfer that knowledge back in and share that with my community.

27:33.840 --> 27:36.480
So that was like one thing, okay, we can solve that part.

27:36.480 --> 27:39.920
And the other business model is we call kind of the wall of the garden model, which is

27:39.920 --> 27:44.440
more like the, you know, 1920s newspaper business model, right?

27:44.440 --> 27:47.680
Whereas, you know, like EdTech companies are essentially taking investor money, paying

27:47.680 --> 27:51.360
authors to write content and then putting it behind a paywall, just like a newspaper,

27:51.360 --> 27:52.680
traditional media.

27:52.680 --> 27:54.000
And they're saying, oh, no, no, no, you can't read it.

27:54.000 --> 27:55.000
But I promise you.

27:55.000 --> 27:56.000
It's the best.

27:56.000 --> 27:57.000
Right.

27:57.000 --> 28:01.560
So I was going to say it.

28:01.560 --> 28:06.920
So you have this model where the kind of the incentives are misaligned, or is that it's

28:06.920 --> 28:10.680
not in their interest to share what pieces of content they like and don't like, because

28:10.680 --> 28:14.360
you kind of get like, oh, you buy this whole suite of stuff.

28:14.360 --> 28:17.440
So yeah, they want to improve it, but they're not necessarily helping the teacher do that

28:17.440 --> 28:21.080
and really enlisting the teacher's help, being honest about what is and is not working.

28:21.080 --> 28:24.080
And if I ask, you know, if someone at the New York Times, if I think they're, their

28:24.080 --> 28:27.880
company, or the newspapers better than the Washington Post, I know who they're going to say,

28:27.880 --> 28:28.880
right?

28:28.880 --> 28:29.880
I know what that answer is.

28:29.880 --> 28:33.880
So getting real data and performance out of kind of this traditional model is just

28:33.880 --> 28:34.880
hard.

28:34.880 --> 28:39.080
So you've got this kind of high quality, you know, hard to produce, expensive to produce

28:39.080 --> 28:43.600
new content, model wall garden, and they got warehouse, you know, high quantity and very

28:43.600 --> 28:44.760
low quality.

28:44.760 --> 28:48.480
And the more, you know, more stuff you get, the worse the user experience gets.

28:48.480 --> 28:52.520
So we said, can we tie quality and quantity together?

28:52.520 --> 28:54.640
Can we make it kind of a positive feedback loop?

28:54.640 --> 28:57.960
And that's really where the AI and the machine learning, you know, kind of cuts in is that

28:57.960 --> 29:03.360
we are capturing at scale enough information to kind of keep floating the best stuff up

29:03.360 --> 29:08.520
to the top, but searching through it and capturing it in a way is not just traditional search.

29:08.520 --> 29:12.560
That means we can kind of cut through the top and get quantity and quality at scale.

29:12.560 --> 29:20.960
Have you found that a better way to rank and rank the way you present content is by kind

29:20.960 --> 29:26.160
of bubbling up what you've seen with the interactions as opposed to asking for an explicit

29:26.160 --> 29:27.680
star rating or things like that?

29:27.680 --> 29:29.920
Is that the direction you're going with this?

29:29.920 --> 29:35.360
What I would say is that we know that star rankings are not working.

29:35.360 --> 29:36.360
So it's been tried.

29:36.360 --> 29:40.720
We are capturing that data, but instead of just having someone vote on like, oh, like

29:40.720 --> 29:42.040
I like this piece of content.

29:42.040 --> 29:46.280
Instead, we can capture more interesting data, but like, I've got this piece of content

29:46.280 --> 29:47.920
and there's a hundred questions in it.

29:47.920 --> 29:51.840
I've seen tons of people who have strong opinions about the top 20.

29:51.840 --> 29:57.320
So it's kind of the ranking and sorting algorithm is a bit more off of the Reddit idea

29:57.320 --> 30:01.560
of how do you have these kind of layered nested pieces of information, how do you float all

30:01.560 --> 30:06.320
of that and some kind of recursive loop of like, oh, now I know that this piece of content

30:06.320 --> 30:07.800
is better than this one.

30:07.800 --> 30:12.040
And I'm not just using the uploads and downloads on those top level pieces, but everything

30:12.040 --> 30:13.040
inside.

30:13.040 --> 30:16.280
And that's really what's enabled us to kind of take the next level in terms of ranking.

30:16.280 --> 30:20.080
And then you combine that with performance data and now you've got something that, you

30:20.080 --> 30:24.400
know, no one else is going to be like, all right, all right, that's a very cool story.

30:24.400 --> 30:25.400
What's next?

30:25.400 --> 30:34.040
So if you take what we're doing right now and you really tease out that there's teachers

30:34.040 --> 30:36.920
using up the system, what we can do is we can then take the data that the teachers and

30:36.920 --> 30:41.840
students have produced and bring that to institutions themselves and say, here's a view

30:41.840 --> 30:47.480
of your school that you've never seen before, one that would benefit you in terms of looking

30:47.480 --> 30:51.880
at how your students are actually learning as opposed to just the output grades like

30:51.880 --> 30:55.480
where we're looking at are the students digging deeper into the content?

30:55.480 --> 30:59.920
Are they actually mastering something as opposed to did they just memorize it and move on?

30:59.920 --> 31:06.280
So looking at the next phase is using aggregated data of students and teachers at the school

31:06.280 --> 31:10.320
level, at the district level, the local government level and that type of thing.

31:10.320 --> 31:14.960
If you remember, we were talking about earlier about the being able to come normalize and

31:14.960 --> 31:18.200
standardize questions against questions, answers against answers.

31:18.200 --> 31:22.160
Well, there's nothing preventing us from using very similar models to rank students

31:22.160 --> 31:25.520
against students and not to students against their classmates or against themselves, but

31:25.520 --> 31:28.720
against every other student who's ever touched the system.

31:28.720 --> 31:33.080
So what I think is really unique about the way that we're doing this is that even if students

31:33.080 --> 31:37.840
see different pieces of content and take different quizzes, we can, you know, compare

31:37.840 --> 31:41.480
them and say, okay, which student actually learned more is doing better?

31:41.480 --> 31:45.520
And if you look at the way we are standardizing students for results today, kind of standardize

31:45.520 --> 31:49.640
tests, it's shove a student in a room on a Saturday and put 300 questions in front of

31:49.640 --> 31:50.640
an prey.

31:50.640 --> 31:53.640
And you hope you get good data.

31:53.640 --> 31:58.400
But with Mt. Cleveris, though, instead of that 300 questions, you can get 30,000 data

31:58.400 --> 32:00.720
points per student per year over the course of a year.

32:00.720 --> 32:04.520
And you can finally get to this as Bernie alluded to, the second order metrics of success

32:04.520 --> 32:09.600
that are kind of the holy grails of the education policy of questions like, did the student become

32:09.600 --> 32:12.040
more curious about what did they become more curious?

32:12.040 --> 32:16.320
Did the student get, you know, did they learn how to learn over time?

32:16.320 --> 32:20.160
And figuring out kind of where and what was, you know, what the most successful at?

32:20.160 --> 32:24.040
That's the stuff that a lot of kind of this typical standardized test models can't get

32:24.040 --> 32:25.040
to.

32:25.040 --> 32:28.560
So we know that at scale, that's where we think kind of a lot of this data will be valuable

32:28.560 --> 32:33.680
is that we can actually provide real, you know, real standardized testing data to schools

32:33.680 --> 32:36.160
without them having to actually do any standardized testing.

32:36.160 --> 32:37.760
It's just part of the product.

32:37.760 --> 32:38.760
Awesome.

32:38.760 --> 32:42.720
But James and Bernie, it was great getting to learn a little bit about Mt. Cleveris and

32:42.720 --> 32:44.760
kind of explore how you pulled it all together.

32:44.760 --> 32:45.760
Fascinating story.

32:45.760 --> 32:47.600
I really appreciate you taking the time.

32:47.600 --> 32:48.600
Thank you.

32:48.600 --> 32:49.600
Yeah.

32:49.600 --> 32:57.160
All right, everyone, that's our show for today.

32:57.160 --> 33:02.160
Thanks so much for listening and for your continued feedback and support.

33:02.160 --> 33:07.520
For more information on Bernie, James, Mt. Cleveris, or any of the topics covered in

33:07.520 --> 33:13.600
this episode, head on over to twimlai.com slash talk slash 63.

33:13.600 --> 33:18.680
To follow along with the NYU Future Labs AI Summit series, which will be piping to your

33:18.680 --> 33:25.200
favorite pod catcher all week, visit twimlai slash nexus labs too.

33:25.200 --> 33:30.680
Of course, you can send along your feedback or questions via Twitter to at twimlai or

33:30.680 --> 33:36.160
at sam charrington or leave a comment right on the show notes page.

33:36.160 --> 33:40.720
Thanks again to NYU Future Labs for their sponsorship of the show and the series.

33:40.720 --> 34:09.240
And of course, thank you once again for listening and catch you next time.

