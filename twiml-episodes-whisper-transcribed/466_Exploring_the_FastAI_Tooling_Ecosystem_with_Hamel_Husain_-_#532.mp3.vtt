WEBVTT

00:00.000 --> 00:12.960
All right, everyone, I am here with Hamil Hussein.

00:12.960 --> 00:17.360
Hamil is a staff machine learning engineer at GitHub.

00:17.360 --> 00:20.880
Hamil, welcome to the Twimal AI podcast.

00:20.880 --> 00:23.440
Thank you for having me. I'm excited to be here.

00:23.440 --> 00:25.680
I'm excited for this conversation and in

00:25.680 --> 00:29.680
particularly because we've had a couple of reschedules due to

00:29.680 --> 00:33.920
technical issues. So this is a hotly anticipated

00:33.920 --> 00:39.680
conversation on my part. It was anticipated prior to all that, but

00:39.680 --> 00:45.600
really looking forward to digging into the chat. Let's jump right in and

00:45.600 --> 00:49.280
have you share a little bit about what you do at GitHub.

00:49.280 --> 00:54.320
Yeah, yeah, thanks for asking. So I get up, I've been doing a

00:54.320 --> 00:57.360
couple of different things. So I spent a long time at GitHub doing

00:57.360 --> 01:02.640
open-source work. So I've worked a lot on fast AI, so

01:02.640 --> 01:07.280
GitHub sponsored me to work on fast AI for a large period of time.

01:07.280 --> 01:10.480
And then I also did a lot of work with GitHub actions, integrating those with

01:10.480 --> 01:14.320
different data science, open-source projects, like

01:14.320 --> 01:20.720
great expectations, Jupyter, Kubeflow, so on and so forth.

01:20.720 --> 01:25.600
Now that I've been working a lot internally on our ML infrastructure,

01:25.600 --> 01:28.160
so those are kind of like different flavors of things. Currently I'm on

01:28.160 --> 01:31.280
paternity leave, so I had a new born two months ago.

01:31.280 --> 01:34.800
So I technically have not been doing anything

01:34.800 --> 01:39.120
work related for a couple of months. I won't get

01:39.120 --> 01:42.160
I was going to go down to Rathole and ask you how your sleep was, but

01:42.160 --> 01:47.520
well, that's actually despisely not so bad compared to

01:47.520 --> 01:53.440
my first child, so. Oh, that's awesome. That's awesome.

01:53.440 --> 02:00.240
I guess I wanted to, I want to kind of start out with the fast AI

02:00.240 --> 02:05.200
work that you've been doing and how that came about, but

02:05.200 --> 02:08.880
it may be useful context for you to share a little bit about your

02:08.880 --> 02:12.800
background and kind of how you came to work on the infrastructure side of

02:12.800 --> 02:19.600
machine learning. Yeah, so I started in data science

02:19.600 --> 02:25.040
a long time ago, around 2003 or so when I graduated from

02:25.040 --> 02:30.000
undergrad, and back then I was working as a

02:30.000 --> 02:35.520
as a statistician predicting a loan defaults for a large bank.

02:35.520 --> 02:39.440
After that, I went on to work on work and management consulting,

02:39.440 --> 02:45.360
doing like a data science flavor of things. I had a brief hiatus where I

02:45.360 --> 02:49.600
tried out a different career, which we don't have to get into right now.

02:49.600 --> 02:55.200
And then we're back to the technical consulting and then I decided

02:55.200 --> 02:58.240
after doing so many data science projects at different companies and

02:58.240 --> 03:04.240
different industries, I knew that tooling was like really far behind because

03:04.240 --> 03:09.360
people always struggled with deploying models,

03:09.360 --> 03:14.240
monitoring them, doing things in a systematic way.

03:14.240 --> 03:18.000
There was a lot of open source tools, but not really good systems.

03:18.000 --> 03:24.560
And so at that time, in 2014 or so, I was happy to be living in

03:24.560 --> 03:29.440
Boston at that time and at that time, and there was a startup called data robot

03:29.440 --> 03:35.520
which was building ML tooling, specifically is auto ML tooling.

03:35.520 --> 03:40.000
So they got a bunch of people that are really good at Kaggle,

03:40.000 --> 03:45.600
three or four different grandmasters, all of who which were like number one at some

03:45.600 --> 03:49.280
point, decided to bake in a lot of their best practices with regards to

03:49.280 --> 03:52.800
modeling to a product. And I thought that was really interesting.

03:52.800 --> 03:57.680
So I joined them. I learned a lot there about how to create software for data

03:57.680 --> 04:04.000
science. It's spent a lot of time talking to

04:04.000 --> 04:09.040
kind of implementing these systems at different companies that are trying to

04:09.040 --> 04:13.280
use it, trying to automate some of their machine learning processes.

04:13.280 --> 04:18.400
And then I ended up moving to the Bay Area because of my wife.

04:18.400 --> 04:23.680
She was doing medicine and she's in a fellowship program so we had to move to the Bay Area.

04:23.680 --> 04:28.560
Then I decided, I would like to experience one of these

04:28.560 --> 04:33.760
Bay Area companies that keep hearing about, like it's some kind of like a

04:33.760 --> 04:38.880
different, you know, from the outside Silicon Valley looks like a

04:38.880 --> 04:43.440
really different and kind of amazing experience.

04:43.440 --> 04:46.240
You know, when you hear about it, like at least like when you're

04:46.240 --> 04:48.640
yeah, when you're living somewhere else or you're not part of that.

04:48.640 --> 04:54.400
So I thought I have to like experience this. So I joined Airbnb as a data

04:54.400 --> 04:58.560
scientist shortly after coming to the Bay Area.

04:58.560 --> 05:02.400
And that was a really interesting experience.

05:02.400 --> 05:07.440
When I found the Airbnb, like, so when I first got to Airbnb, I thought

05:07.440 --> 05:12.800
it would be really advanced in terms of like ML tooling, ML infrastructure.

05:12.800 --> 05:16.560
I thought how won't need any tools and infrastructure.

05:16.560 --> 05:23.040
You know, they already have those because it's you know, it's Silicon Valley.

05:23.040 --> 05:29.200
And so when I got there, you know, I just, the first project

05:29.200 --> 05:35.200
there it gave to me was this model that forecast LTV.

05:35.200 --> 05:39.120
And they said like, hey, can you just review this model? Yeah, lifetime value.

05:39.120 --> 05:41.520
Yeah, for marketing, for growth marketing.

05:41.520 --> 05:45.840
And they asked me to kind of take a look at it, you know, see if

05:45.840 --> 05:49.280
you can make any improvements on the model, kind of like your first, you know,

05:49.280 --> 05:52.560
getting your feet wet into the place.

05:52.560 --> 05:56.880
And so actually this particular model was a guy who ran an R

05:56.880 --> 06:00.480
script on his laptop, it's about coefficients,

06:00.480 --> 06:04.400
any copy and paste coefficients into an Excel spreadsheet,

06:04.400 --> 06:09.120
which had like formulas that would like materialize these coefficients into

06:09.120 --> 06:12.800
a SQL query that didn't copy and paste it into airflow.

06:12.800 --> 06:17.520
And it like really blew my mind and I thought, wow, like there's

06:17.520 --> 06:22.080
made it to Silicon Valley. Yeah, I thought I made Silicon Valley.

06:22.080 --> 06:25.840
And you know, working at a very celebrated tech company

06:25.840 --> 06:29.760
and it's like, wow, okay, like there's no ML tooling at all whatsoever.

06:29.760 --> 06:34.080
Like it's the most bit, you know, it's kind of,

06:34.080 --> 06:37.520
you can't really imagine anything more basic than that.

06:37.520 --> 06:42.400
And so then I started to build tooling at Airbnb.

06:42.400 --> 06:46.720
And then, you know, kind of got back into tooling.

06:46.720 --> 06:50.640
And then eventually, and then I created a lot of things,

06:50.640 --> 06:55.840
a lot of like artifacts that ended up being used for big head.

06:55.840 --> 07:01.120
And then after that, I ended up going to GitHub,

07:01.120 --> 07:05.440
which is where I'm at now. And then I started working on infrastructure

07:05.440 --> 07:09.200
there and tooling there, ended up working on a lot of open-source stuff

07:09.200 --> 07:14.880
through regards to tooling. And so at this point, I'm pretty much

07:14.880 --> 07:18.800
sold myself or convinced myself that I will be tooling,

07:18.800 --> 07:22.640
doing ML tooling for the foreseeable feature.

07:22.640 --> 07:26.720
Because I keep somehow floating back into that no matter how hard I try to do

07:26.720 --> 07:29.600
anything else.

07:29.600 --> 07:36.160
At GitHub, what are the main kind of use cases that

07:36.160 --> 07:41.280
ML is being used for nowadays? I mean, there's stuff that we hear about like

07:41.280 --> 07:49.120
co-pilot. But I imagine that probably most of the use cases that,

07:49.120 --> 07:53.840
you know, GitHub, ML engineers and data scientists are working on are kind of,

07:53.840 --> 07:59.840
you know, internal types of use cases. And then maybe not dissimilar from the kind of thing you did at

07:59.840 --> 08:04.400
Airbnb, supporting growth and kind of platform

08:04.400 --> 08:07.760
health and that kind of thing. Yeah, so there's a bunch of different use cases

08:07.760 --> 08:12.720
that GitHub, some of them you touched on. So a lot of forecasting of various things

08:12.720 --> 08:19.840
in terms of like infrastructure usage. Also, there's a lot of platform health

08:19.840 --> 08:25.760
stuff like detecting spam, detecting bots of various kinds.

08:25.760 --> 08:29.920
Apparently, people like to buy stars, things like that, you know, like,

08:29.920 --> 08:32.720
you know, catching things like that or catching abuse of the platform.

08:32.720 --> 08:36.160
That was a thing. Yeah, I didn't know that was a thing either.

08:36.160 --> 08:41.840
Seems like a pretty low point in your life if you had to go buy stars.

08:44.320 --> 08:48.480
But and then there's some there's actually some user-facing stuff

08:48.480 --> 08:56.080
that are not known so widely. So if you go to github.com slash explore,

08:56.080 --> 09:00.800
you'll see kind of a recommendation of different repositories you might be

09:00.800 --> 09:06.160
interested in based upon your activity on GitHub. And then also,

09:06.160 --> 09:09.920
like another example is if you create a new repository,

09:09.920 --> 09:15.280
you can attach topics to it like different tags. And so there's a small

09:15.280 --> 09:18.800
recommendation system that will recommend other tags you should apply.

09:18.800 --> 09:22.160
So there's some things like that. So these are the kind of things that data

09:22.160 --> 09:27.120
scientists work on inside GitHub. And there still is pretty a

09:27.120 --> 09:32.320
pretty new thing for GitHub. Yeah. It's not really,

09:32.320 --> 09:35.680
it's something they're actually building up right now. It's in this most

09:35.680 --> 09:41.360
nascent stages, I would say. And so with that in mind,

09:41.360 --> 09:47.760
what does the platform look like at GitHub? Yeah, so it's been

09:47.760 --> 09:53.360
changing quite a bit. So we were on AWS before. And then we had kind of

09:53.360 --> 10:00.320
our own homegrown infrastructure that was composed of using a bunch of

10:00.320 --> 10:04.800
different things like cooflow, in some other stuff.

10:04.800 --> 10:09.280
And then we got Bob on Microsoft. And then we started transitioning

10:09.280 --> 10:16.160
everything over to Azure and using Azure ML. And so

10:16.160 --> 10:20.480
Azure ML is kind of like is the managed service with the Azure

10:20.480 --> 10:25.680
provides. And it kind of is white labels a lot of ML flow stuff as

10:25.680 --> 10:29.520
well. So with regards to the experiment tracking and the model

10:29.520 --> 10:35.120
registry and things like that, it has your ML more or less adopts

10:35.120 --> 10:40.480
that behind the scenes. And so that's what that's what they're

10:40.480 --> 10:46.400
using. And so how did your work with the fast AI

10:46.400 --> 10:51.840
team and the fast AI tools generally come about? Yeah, it was

10:51.840 --> 10:56.880
really organic. So the way that happened was when I first got to

10:56.880 --> 11:00.320
GitHub, you know, I think GitHub was still trying to find that

11:00.320 --> 11:05.040
like kind of get a sense for what it wanted to do with ML.

11:05.040 --> 11:09.920
There was definitely a lot of prototyping and sort of exploration of

11:09.920 --> 11:14.640
the space of like different ML projects, but it wasn't quite

11:14.640 --> 11:20.400
solidified yet. And so in the meantime, what I did was kind of do

11:20.400 --> 11:28.000
work in open source to kind of, you know, just for fun or just kind of

11:28.000 --> 11:32.400
see, you know, what, you know, and also look for opportunities for things that

11:32.400 --> 11:37.360
might integrate with GitHub. So at some point, it's always been

11:37.360 --> 11:41.840
like a student of Jeremy's like from a long time ago.

11:41.840 --> 11:46.400
And so one of the things that we, one of the things I ended up

11:46.400 --> 11:49.440
learning like a long time ago and one of his classes was

11:49.440 --> 11:55.040
about how to do semantic search. So he showed something in one of his classes

11:55.040 --> 12:00.640
where he had like photos of different objects and you could search those

12:00.640 --> 12:05.680
photos semantically using natural language, but also like, you know,

12:05.680 --> 12:10.640
even if the photo, you know, if you construct a shared web vector space,

12:10.640 --> 12:15.040
you know, you can create a semantic search. And so this is back in, I don't know,

12:15.040 --> 12:20.080
like 2017 or something. It was a little bit of a newer concept.

12:20.080 --> 12:23.920
And so I decided to try that out with code. So I thought that was be really

12:23.920 --> 12:28.400
interesting. And at that time, like, no one has really used GitHub's public

12:28.400 --> 12:33.440
data set before. It wasn't really, for whatever reason, like, I don't know,

12:33.440 --> 12:38.400
ML people have like ignored GitHub data set. Maybe it just wasn't obvious

12:38.400 --> 12:41.440
that you could get it and do something interesting with it.

12:41.440 --> 12:44.480
So the thing that's really interesting about GitHub's data says you can,

12:44.480 --> 12:48.240
you can actually construct a really interesting parallel corpus out of it

12:48.240 --> 12:53.920
with regards to, so you can get a bunch of you code. So like, for example, Python code,

12:53.920 --> 12:58.240
you can get pairs of doc strings and code. It takes some work. You have to like,

12:58.240 --> 13:02.240
get the code, clean it, you have to parse it out, you have to parse the doc

13:02.240 --> 13:06.800
strings out from the code and like, you know, and then remove the,

13:06.800 --> 13:10.160
you get a lot of duplicates and do all that stuff. So I mean, that's a

13:10.160 --> 13:12.400
tremendous amount of work, but you can actually get a very interesting

13:12.400 --> 13:16.400
parallel corpus. And then you can do a lot of representation learning on that

13:16.400 --> 13:20.880
code. And then you can produce some things that are

13:20.880 --> 13:23.840
really interesting. So then I started to work on that

13:23.840 --> 13:29.040
in open source. And then what eventually happened is we got bought by Microsoft

13:29.040 --> 13:31.920
and then there were some people on Microsoft research that are interested in

13:31.920 --> 13:36.960
that. We're going to be using like, fast AI in that. And that was one of the things

13:36.960 --> 13:40.640
that I think Jeremy was really excited about, like, one of the things that,

13:41.840 --> 13:49.280
you know, like an example of a use of this library in the, you know, kind of in the wild.

13:50.720 --> 13:55.280
So first, this is my first involvement. And then at some point, get up, release,

13:55.280 --> 14:03.040
GitHub actions. And so then I started going around to all these open source projects, like Jupiter,

14:03.040 --> 14:07.840
Great Expectations, Scoop Flows, so on and so forth. And started making integrations between

14:07.840 --> 14:13.360
GitHub actions in these various data science projects. So like, for example, there's a,

14:14.160 --> 14:19.360
there's a project called Great Expectations that is like, testing for data quality.

14:20.000 --> 14:24.960
So I thought, okay, it would be really interesting to do like CICD for data quality,

14:24.960 --> 14:27.760
like, let's say if you're like updating a SQL query or something like that,

14:27.760 --> 14:32.480
like it wouldn't be cool if you had a test that could run, you know, if you're changing,

14:32.480 --> 14:36.320
you know, changing SQL code in a PR, you know, when you could trigger that test,

14:36.320 --> 14:41.120
things like that. So like, and then I started helping Jeremy out with his CICD.

14:42.240 --> 14:46.400
And then one thing led to another and then start working on more and more things.

14:46.400 --> 14:49.600
Like, once you start working on someone's CICD, you have to like, understand like,

14:49.600 --> 14:55.120
whole their code, how it runs, like, you know, how the tests are run, what they mean,

14:55.120 --> 14:59.360
what's breaking, you know, and then I started helping with this documentation.

15:00.240 --> 15:06.880
Even going back quite a few years, they've been doing pretty interesting things like

15:06.880 --> 15:13.760
integrating in documentation and code and doing that all in notebooks as opposed to kind of

15:13.760 --> 15:20.000
traditional code files. So I imagine you'd have, you got sucked into that and that led to,

15:20.720 --> 15:24.240
you know, some of the things like MBDev and FastPages.

15:24.240 --> 15:28.960
Yeah, yeah, yeah. No, that's a good, yeah. So fast forwarding, that stuck, you know,

15:28.960 --> 15:31.760
went into a big rabbit hole on all these things that you described.

15:32.480 --> 15:35.200
Because then I started wondering like, well, how is all this stuff created?

15:35.200 --> 15:40.240
Like, it's not that clear to me because actually, you know, like, they're doing a lot of interesting

15:40.240 --> 15:48.320
things using a very unique tech stack. And so then I went and learned that tech stack and then

15:48.320 --> 15:54.560
I got really involved in things like MBDev and FastCore and started working on that.

15:56.240 --> 16:01.760
And then subsequently, I work on a bunch of other projects. So yeah, it was just very organic.

16:04.240 --> 16:08.400
Kind of went into, you know, you see one thing, interesting, another thing,

16:08.400 --> 16:14.560
and at least some things pull in threads. Yes, yeah. Yeah. So what is MBDev?

16:15.600 --> 16:24.640
Yeah, MBDev is a development environment that all of FastAI is built in. And it's a

16:24.640 --> 16:30.960
literate programming environment. So the idea is you should be able to write your code in

16:30.960 --> 16:40.000
your documentation and test all in a single context. And not have to write, you know, your code in

16:40.000 --> 16:45.120
a different place, your test in a different place in your documentation in yet a different place.

16:45.760 --> 16:50.560
And keep those all in sync yourself. But like, that should be more natural. Like, hey, write some

16:50.560 --> 16:57.760
code, explain it to yourself, into your users, and then have like inside the documentation,

16:57.760 --> 17:03.840
have some runnable code that explains like how this code runs, like by example.

17:05.840 --> 17:11.680
And then, you know, also make those tests, if you can as well, but make it very natural,

17:11.680 --> 17:17.440
like a conversation with your users. And have that be run every single time your code,

17:18.720 --> 17:24.560
you want to, you know, update your library and have those tests always run. And so,

17:24.560 --> 17:34.800
so basically what MBDev is is built on some of the things that Jupiter for the interactive aspect

17:34.800 --> 17:41.040
of like writing code, but also being able to write prose alongside your code. So it integrates

17:41.040 --> 17:49.200
that with a static site generator that renders documentation, and then also some other things that

17:49.200 --> 17:55.440
export notebook code to plain, you know, like modules like to Python modules, like that you would

17:55.440 --> 18:02.000
write in the ID like VS code. So it's a system that like glues together these things to create a new

18:02.000 --> 18:06.800
development environment, that is this literate programming environment. And it's kind of hard to

18:06.800 --> 18:12.480
explain like in this abstract sense, like I would definitely say something to experience.

18:13.280 --> 18:16.640
Because when someone explained it to me, I was really skeptical. It's like, well,

18:16.640 --> 18:21.200
it sounds like Jupiter. Yeah, you're like, well, what do you mean like MBDev? You just write

18:21.200 --> 18:26.080
everything in notebook. And that's not really what it is. It's, it's, it's happens to be using a

18:26.080 --> 18:32.000
notebook, but that's not the central point of it. The central point of it is like it's an experience

18:32.000 --> 18:38.400
where you write, yes, you are, in this specific case, you're writing in a notebook, but you're writing

18:38.400 --> 18:45.680
your tests and documentation in the notebook with some special sugar in syntax that's available to you

18:45.680 --> 18:53.200
with for various options. And then that all gets that automatically like gets create like documentation

18:53.200 --> 19:00.560
gets created and tests will get run NCI for you automatically. And the result of that is like

19:00.560 --> 19:05.520
much higher quality software and also like much lower iteration cycles. Because what happens is

19:06.240 --> 19:11.040
okay, it's like most people don't write documentation and most people don't write tests. And why is that?

19:11.040 --> 19:16.160
Because like writing documentation sucks. Like you write your code. And then now you're asking

19:16.160 --> 19:20.400
the developer to like, well, just go write this other documentation somewhere else and then

19:20.400 --> 19:25.760
keep that in sync yourself. And like, that's a pain. Like, you know, no one does that properly.

19:25.760 --> 19:32.240
Like very few people do that properly. And same thing with tests. So like, it's really like a new,

19:32.240 --> 19:37.680
it's a new development workflow. And it's like one of the secrets behind how fast the eye,

19:37.680 --> 19:42.400
like you might be wondering, like, how does Jeremy and like maybe one other person,

19:43.200 --> 19:46.800
depending on who's on it and fast the eye at the time, develop all of the software.

19:47.520 --> 19:52.240
And one of the secrets behind that is MBDEF because it helps make you a lot more productive.

19:52.240 --> 19:59.360
Yeah, like I mentioned, it does sound quite a lot like Jupiter or maybe Jupiter with some,

19:59.360 --> 20:07.200
you know, annotation types of things that let you say, hey, this is doc, this is code,

20:07.200 --> 20:16.160
this is test. But it sounds like it's more of a system than that. You mentioned literate programming

20:16.160 --> 20:21.280
a couple of times. You know, what is that and how does that play into what they're really trying

20:21.280 --> 20:29.360
to do with MBDEF? Yeah, literate programming is this like big concept. I don't know who invented it.

20:29.360 --> 20:37.280
You know, I have to look that up, but it's this concept where like your programming environment

20:37.280 --> 20:43.840
should not be dead. Like it shouldn't be completely static. You should be able to see the result of

20:43.840 --> 20:52.160
your code and how that changes, you know, inputs and outputs in real time as you're as you're programming

20:52.160 --> 20:59.840
and not have it be, yeah, like and be able to experiment on the fly. Then also like pros and

20:59.840 --> 21:07.680
code should be able to be intermingled naturally because you want to be able to like talk to

21:07.680 --> 21:15.200
your users and talk to yourself and document your code. Beyond, let's just say like comments

21:15.200 --> 21:22.720
necessarily like and you want to be able to kind of have this expository like form of programming

21:22.720 --> 21:29.840
where you can kind of show your code in the same context as like writing code. And yes,

21:29.840 --> 21:36.080
that sounds a lot like Jupiter, but like it's Jupiter like with some other things to allow it to

21:36.080 --> 21:43.280
go the whole way because like Jupiter in it by itself is not necessarily like taking it doesn't

21:43.280 --> 21:48.880
doesn't allow you to software engineering completely the way you might want to do it. Like it's

21:48.880 --> 21:54.080
not necessarily the best suited ID just to create like Python modules and you have to export that

21:54.080 --> 21:58.640
somehow out of a Jupiter notebook if you're just using Jupiter. And then it's not necessarily

21:58.640 --> 22:02.800
straightforward like how would you write tests in Jupiter? And it's not necessarily straightforward

22:02.800 --> 22:06.960
like how would you how would you create like yes it looks like when you if you write a really

22:06.960 --> 22:12.320
polished Jupiter notebook it can look a lot like documentation within like how do you actually like

22:12.320 --> 22:17.760
create documentation out of that in a systematic way in a reliable way and then give users a lot

22:17.760 --> 22:20.880
of different options like how to control that documentation because like you said like

22:21.680 --> 22:25.360
might not want to show all the code in the documentation or might want to show certain things

22:25.360 --> 22:33.200
like how do you do that. So it's kind of like you know that friction you feel like and everyone

22:33.200 --> 22:38.880
that may have may feel this like you're in the notebook you're developing some code and then

22:38.880 --> 22:43.200
at certain point you're like oh my god goodness I need to take this code and make it into plain

22:43.200 --> 22:48.960
text and you refactor it and you're going back and forth a lot. And I think everybody's like

22:48.960 --> 22:55.200
a little bit frustrated in that process. You know intuitively like can there be a better way

22:56.320 --> 23:01.920
but we have all learned to ignore that and just like say well that's just part of life. So MB

23:01.920 --> 23:06.960
Dev is kind of this answer to no like we shouldn't ignore that like let's try to find a way.

23:06.960 --> 23:14.000
So my no means MB Dev perfect. It's kind of like the best kind of thing that we can have

23:14.800 --> 23:21.040
with gluing together existing technologies. But I think you know someone could definitely take

23:21.040 --> 23:28.880
the concept of MB Dev and build something from first principles that may work even better.

23:30.080 --> 23:35.040
But yeah MB Dev is kind of like the thing that just can work with just like kind of hacking

23:35.040 --> 23:41.680
some stuff together right now. From the description it sounds like yes it's this tool that

23:41.680 --> 23:51.040
the fast AI team built to allow them to build the fast AI library but it can be used more broadly

23:51.040 --> 23:57.280
you know by anyone for anything. Is that yeah absolutely yeah. Yeah I mean it's not just for data

23:57.280 --> 24:02.160
science at all. In fact I feel like it's been used for more regular software projects than it has

24:02.160 --> 24:10.800
been for anything related to data science. So there's been a lot of like API clients written

24:10.800 --> 24:17.920
with MB Dev. There's been all kinds of other software that's been written with MB Dev.

24:17.920 --> 24:22.240
And so yeah I really think like it's a window you know of course it only works with Python

24:23.280 --> 24:31.040
at the moment. But I think it's general software development. It's a way it's a development

24:31.040 --> 24:38.560
environment for general software development. When I think about some of the activity in the space

24:38.560 --> 24:46.080
you know I think of things like Netflix's and Compass like these and in fact

24:48.320 --> 24:54.960
this was probably after your time at Airbnb but at some point they were kind of going down the

24:54.960 --> 25:02.880
path of trying to like production eyes notebooks. A lot of people have made attempts at that.

25:02.880 --> 25:14.400
This would you say that MB Dev is in the same vein. You know in some ways it's more like what

25:14.400 --> 25:20.960
fast AI was actually trying to do was like write books and courses and you know things like that

25:20.960 --> 25:31.040
more so than production software. Even the the the framework the library you know they weren't

25:31.040 --> 25:35.280
necessarily they were authoring it they weren't necessarily trying to productionalize it

25:35.280 --> 25:43.360
in the traditional sense of the word. Is there a productionalization or operationalization

25:43.360 --> 25:51.600
aspect to MB Dev at all? As far as MB Dev is concerned it is it's all it is definitely about

25:51.600 --> 25:58.480
you know making proper Python modules and allowing you to I mean it is definitely all very much

25:58.480 --> 26:07.440
about productionizing software in terms of making Python modules and packages pushing them to

26:07.440 --> 26:14.080
pypy making sure you have good documentation and good CI because like when you start an MB Dev

26:14.080 --> 26:22.080
project it automatically stubs out like CI for you so that it's kind of already there and so

26:22.800 --> 26:27.680
it's very much geared towards nudging you towards productionization. Now as far as fast AI is

26:27.680 --> 26:33.760
concerned I think one of your observations is definitely correct like I don't know that fast

26:33.760 --> 26:42.720
AI has been overly concerned about productionization of of applications with fast AI like like you

26:42.720 --> 26:50.880
know there's relative to other tools that you might see so for example you know like TensorFlow has

26:50.880 --> 26:56.240
like TFX and TensorFlow serving and stuff like that so definitely desktop does not there's not

26:56.240 --> 27:03.280
that those kind of things don't are not there for a fast AI and you're right like one of the things

27:03.280 --> 27:08.160
that was like really important in a fast AI is to be able to have really good documentation

27:10.960 --> 27:18.000
and also like good tests because especially like with the service area and then like only being like

27:18.000 --> 27:27.040
one or two contributors full time and so one of the goals is like okay like the the docs have to be

27:27.040 --> 27:32.800
really good because after all it is a you know this is used for education and the docs are not good

27:32.800 --> 27:38.320
you know people are going to get lost very quickly but then you know the the problem is with docs

27:38.320 --> 27:45.040
is like how do you keep those in sync with the code with in the code is changing so rapidly

27:45.040 --> 27:50.080
because the fast AI changes quite rapidly you know it's they're always keeping up with state of the

27:50.080 --> 27:57.680
art things and making their own state of the art things and so the kind of the answer to that was

27:57.680 --> 28:01.840
like hey let's make documentation of first class citizen like you should be doing it while you're

28:01.840 --> 28:06.960
writing software like you should be really natural there should be no friction in introducing

28:06.960 --> 28:16.080
documentation and so that's kind of exactly what yeah that's why MBDev allowed yeah is a what

28:16.080 --> 28:27.600
are how to fast core on fast pages relate to MBDev yeah so so one background of Jeremy is he has

28:27.600 --> 28:34.560
programmed a lot of different languages prior to Python well he he I think he says like and you

28:34.560 --> 28:39.840
know he says it sometimes that he's been programming every day since he was I don't know what it is

28:39.840 --> 28:46.800
yeah I was laughing because it's probably been a couple of years now but in our in the

28:46.800 --> 28:54.560
tumult community we you know very early on kind of recognize the you know the importance of what

28:54.560 --> 29:05.680
he was doing with the library and hosted a study group around the course and I remember kind of

29:05.680 --> 29:12.240
vividly you know my early experience with the library and and other people's and I remember

29:13.520 --> 29:21.120
making a comment on our slack like why does he name these parameter names like this why does he name

29:21.120 --> 29:27.520
stuff like and someone was like yeah he was a pro contributor back in the day and I'm pretty

29:27.520 --> 29:35.360
far at some about this in a in in one of the past interviews with with him um but uh yeah

29:35.360 --> 29:43.040
he's been programming for for quite a long time and and and he's um you know he draws a lot of

29:43.040 --> 29:52.880
inspiration from uh kind of classical computer science like the um the literate programming is done

29:52.880 --> 30:00.640
new thin um there are a bunch of other folks that like he's a big fan of APL yeah is you know

30:01.520 --> 30:08.240
took a half a semester or a quarter of a semester and like a survey course in school and it's like

30:08.240 --> 30:13.360
the only thing I remember about APL is that it had the weirdest keyboard you had all these symbols

30:14.240 --> 30:21.840
uh you basically you know programming and you know Greek symbols uh with APL and like Jeremy

30:21.840 --> 30:32.800
Supern of that um so uh yes yeah no and this shows up and so like you know um and he's not exaggerating

30:32.800 --> 30:38.160
when he says that because I've spent a lot of time per program per program with him and you know he

30:38.160 --> 30:43.920
actually spends a lot of time hacking in different languages even right now and so he's

30:44.640 --> 30:50.720
what that ends up when it's happening is he whenever he uses a new language he always like creates

30:50.720 --> 30:58.720
like a very he tries to hack the language deeply and create a bunch of utilities that bring in

30:58.720 --> 31:04.800
like other aspects of different like paradigms so like you know the one thing he misses about

31:05.440 --> 31:10.720
Python is like he well you know he wants more functional programming tools or he wants more

31:10.720 --> 31:18.720
like macro like meta programming abilities and things like that um and so you know that's what

31:18.720 --> 31:28.400
Fastcore is it's like hacking Python you know deeply to give you like some more functionality or

31:28.400 --> 31:33.920
some different types of functionality that you know you you might want and then he ends up using

31:33.920 --> 31:40.080
in the using everywhere but um this is pretty like so if you just read fast AI code

31:41.280 --> 31:47.200
you know a lot of it may look pretty foreign uh not only in syntax but in style

31:47.200 --> 31:53.040
uh you know like you said like you know so there's like some things like succinctness which you

31:53.040 --> 31:59.680
know he really values he really likes to keep likes to keep uh lines of code like make things

31:59.680 --> 32:07.280
on one line and the idea is like you could see all the code in like one page or it's close to one

32:07.280 --> 32:12.400
page as possible or something like this and so um that's where fastcore comes from it's a very

32:12.400 --> 32:18.480
interesting so like to understand it was a deep rabbit hole like to understand fast AI deeply

32:18.480 --> 32:23.280
I had to understand development environment which is then be dead of then all of a sudden

32:23.280 --> 32:26.400
but then when you start to look at the source code you have to understand like this fastcore

32:27.120 --> 32:31.360
uh to understand like the source code and then like yeah it just goes from there so like

32:31.360 --> 32:35.280
it's pretty interesting if you're if you're trying to like understand more about the Python

32:35.280 --> 32:40.400
programming language like a little bit deeper level it's pretty interesting to look at fastcore to

32:40.400 --> 32:44.480
see like all the things you can do and then try to you can like get some insight and like how some

32:44.480 --> 32:49.760
of these things are done it is pretty interesting uh it's a way to definitely learn more Python even if

32:49.760 --> 32:59.360
you're like using it every day yeah yeah I remember having that experience going through uh through

32:59.360 --> 33:08.160
the course like you know hacked a little bit with Python or you know it kind of your typical Python

33:08.160 --> 33:15.120
stuff right um you know as far as maybe calling a name function or whatever to get a list of

33:15.120 --> 33:19.680
methods or something like that but you listen to Jeremy kind of talk about Python and work

33:19.680 --> 33:25.280
with it in these you know using all kinds of exotic dunder functions and stuff like that that

33:26.160 --> 33:32.720
it's like okay yeah yeah no that existed it's really interesting like and then you might wonder

33:32.720 --> 33:40.000
okay like well why is this even a good idea like well why why does this like does this this is

33:40.000 --> 33:44.000
actually make this person more productive the cost and benefits of these things and so one thing

33:44.000 --> 33:50.560
I will say is like a lot of this like actually like isn't like isn't service of some kind of learning

33:50.560 --> 33:58.480
as well like doing this whole thing like is a journey of like also continuously learning the Python

33:58.480 --> 34:07.280
programming language at a deep level and uh he engages he does that like really soon like anytime

34:07.280 --> 34:12.560
he's frustrated with anything in Python he'll stop say okay can I like change it whereas like

34:12.560 --> 34:17.920
someone like me would be like okay like well just let's just let's just move on let's just do it

34:17.920 --> 34:22.640
but then like the thing is like it adds up really fast like then he ends up becoming really like he

34:22.640 --> 34:29.760
ends up knowing a lot about Python like really fast um even like very esoteric things out because

34:29.760 --> 34:35.280
they're esoteric like he'll know it like and so you know I think that adds to the productivity

34:35.280 --> 34:41.280
productivity component um but you know it does have the cost of like other new covers okay like if

34:41.280 --> 34:45.760
you want to contribute to a fast AI library you kind of learn this other thing and you know so

34:45.760 --> 34:52.560
the rabbit hole is deep it sounds like yes yeah very deep yes yeah so that's fast core fast pages

34:52.560 --> 34:58.320
you know one thing that is really important is I find as a data scientist writing blocks like

34:58.320 --> 35:05.840
it's it's really useful to like share your knowledge and so you know whenever written blogs before

35:06.320 --> 35:12.960
um you know I used to use medium and like you always want to you know a lot of times you want

35:12.960 --> 35:18.720
to put code in your blocks but then you know the process of writing is not linear like you start

35:18.720 --> 35:22.880
writing it down you're like oh you know actually this code like I don't like it anymore like maybe

35:22.880 --> 35:26.960
I'm this doesn't really make the point that I was thinking or whatever and you change your code then

35:26.960 --> 35:32.560
you get like copy and paste all your code again into this thing and then like update your words

35:32.560 --> 35:36.400
around it and like update the output and you're like this is a big mess you're like copying

35:36.400 --> 35:41.520
and pasting constantly and then you're like you you realize like why am I doing this like

35:42.400 --> 35:48.320
like I'm a programmer why am I copying and pasting like charts and graphs and things into this

35:48.320 --> 35:52.960
things I can like write a blog post like doesn't make any sense like if I'm changing can I just like

35:52.960 --> 35:59.280
change all of this stuff with code and then you also realize like hey there's like Jupiter like I can

35:59.280 --> 36:04.080
write work I can just run a Jupiter no it like isn't a Jupiter notebook like a block like I can't

36:04.080 --> 36:09.200
why can't a Jupiter notebook be like a block like it's pretty obvious like and then I start looking

36:09.200 --> 36:16.160
around like how do I turn a Jupiter notebook into a block and actually there was not good answer

36:16.160 --> 36:22.880
for that it's like well you know like it was like very hacky like nothing really works very well

36:22.880 --> 36:27.440
there's some like here and there are different things as I look I just want something that just like

36:27.440 --> 36:33.520
I save a notebook somewhere and it just becomes a blog and then I have some ability to like hide

36:33.520 --> 36:40.320
cells and show cells and do some things like that and then so I took some of the ideas from

36:40.320 --> 36:46.080
MBDev with regards to how it renders docs and I said well why can't I just be a blogging platform

36:48.160 --> 36:52.640
and then all the conversion process and all that you know can you just automate that with

36:52.640 --> 36:58.080
GitHub actions can we have like triggers to say okay when you update something in your repo it

36:58.080 --> 37:03.120
just re-renders the notebook and re-processes it and makes it into a page and so that was the

37:03.120 --> 37:10.480
general idea of that it was just like making it easier for you to write your blog as a notebook I've

37:10.480 --> 37:15.920
always appreciated how weights and biases does that they have a nice implementation of being able

37:15.920 --> 37:23.520
to kind of blog your experiments and things like that is it in a similar vein yeah yeah I really

37:23.520 --> 37:28.800
like weights and biases too one of my favorite tools it's it's similar to that I'll say weights

37:28.800 --> 37:34.240
and biases more of a you don't really have to even you don't really have to write any code really

37:34.240 --> 37:40.240
if you don't want to you can just start typing like a Google doc and you know plus a plus stuff in

37:40.240 --> 37:45.120
there so I think that's really good at a lower level yeah I said lower level it's like you make

37:45.120 --> 37:50.640
it proper duper a notebook and you save it um weights and biases the visualization layer is a

37:50.640 --> 37:59.280
bit different um they're not really just like using like Python in there it's like some other syntax uh

37:59.280 --> 38:03.920
you know and you can use Vega and something like that to create custom visualizations and you know

38:03.920 --> 38:10.400
it's kind of this middle ground yeah so yeah it's it's a bit different but similar kind of a

38:10.400 --> 38:19.280
similar genre I guess and then you mentioned uh GitHub actions in oh you've mentioned it a few

38:19.280 --> 38:26.320
times but you know most recently kind of as a um part of the the fast pages process you know

38:26.320 --> 38:30.800
talk through GitHub actions and some of the ways you've used them to support data science

38:31.600 --> 38:38.080
yeah um so the idea is like can we use like can we have CICD in various like

38:38.800 --> 38:44.400
data science workflows like doesn't make sense so for example so while we're talking about weights

38:44.400 --> 38:54.560
and biases um so one integration that I've made is something that will uh you know ping weights

38:54.560 --> 39:00.480
and biases for experiment tracking results and bring those into the PR and render them in the PR

39:00.480 --> 39:06.800
uh so that you can view them and then have a discussion so the idea is like uh the example that I

39:06.800 --> 39:12.720
showed was you know you bake a PR against a modeling code I don't know if you've seen PRs like this

39:12.720 --> 39:19.920
but I've seen a lot of different PRs that for someone makes change to a model and then you know

39:19.920 --> 39:25.760
what the the review is like hey like what happened is make the model better and their response is

39:25.760 --> 39:31.600
yeah it makes it better and you just emerge it but like you know that is broken like we know

39:31.600 --> 39:37.040
that's broken like we can't do that we can't do have this like you know this like uh you know

39:37.040 --> 39:43.040
hearsay conversation about code like it should be something that's very objective like more objective

39:43.040 --> 39:47.120
and so the idea is like okay like can you bring your experiment tracking results into the PR

39:47.840 --> 39:54.400
to you know accomplish to like bring more visibility into the results of workflow and there's a lot

39:54.400 --> 39:58.640
and there's a lot of different um nuances there like I don't want to just give you the impression

39:58.640 --> 40:03.280
it's just like something is triggered on every push or something like that just like normal code

40:03.280 --> 40:08.080
like machine learning is a little bit different so the idea is like can we deserve an integration

40:08.080 --> 40:12.640
that makes sense and those those are the kind of things that worked on uh for example

40:13.920 --> 40:21.520
um there's another like there's another thing where um this is a project called repo to docker

40:21.520 --> 40:29.760
that takes like that takes uh any repository like data science repository and dockerize it

40:29.760 --> 40:36.000
and this is for the purpose like this is what binder uses like if you try to go to binder and like

40:36.000 --> 40:42.080
give it uh get up url it what we'll do is like it'll give you a jupiter notebook but it'll try

40:42.080 --> 40:47.360
it's best to like build the dependencies by introspecting your repo so you don't need docker file

40:47.360 --> 40:54.800
there you're just you know giving it a typical python repo maybe it has a requirements txt file

40:54.800 --> 41:00.640
and it's gonna figure it all out yeah it'll try to guess like it'll you know as a hierarchy like

41:00.640 --> 41:05.200
it'll encourage requirements txt file if it doesn't find that it'll like look for a condo file

41:05.200 --> 41:08.320
it doesn't find that it'll like look for something else and look for like these things

41:09.440 --> 41:14.960
and like you know it also supports docker files or you know if you have that it'll look for that

41:14.960 --> 41:19.520
or do whatever but you know a lot of people don't have that stuff like my that data scientist

41:19.520 --> 41:24.480
just have requirements txt or something and you want to reproducible environment so it's like okay

41:24.480 --> 41:30.640
can you have get up actions automatically build that for you and deploy it somewhere um so that's

41:30.640 --> 41:36.800
being used uh get up actions you know and so the get up action is interesting because like you can

41:38.000 --> 41:43.440
pre-package them and like make them modular so like this weights and biases thing like you don't

41:43.440 --> 41:51.600
have to like you can just call the weights and biases action and like say okay like you give it like

41:51.600 --> 41:57.360
some like three or four parameters to get it working you don't have to like use all the code that

41:57.360 --> 42:02.880
I created for to to ping the weights and biases API similarly like for this is duper example

42:03.840 --> 42:08.560
you know you just just give it like whatever parameters like let's say you're trying to push

42:08.560 --> 42:13.520
this thing to a docker repo this image that you automatically build you just give it like your

42:13.520 --> 42:19.600
docker credentials and off you go you don't have to like so like that's that's the kind of power

42:19.600 --> 42:23.280
of get up actions is like you don't have to worry about the complexity of these things you can just

42:23.280 --> 42:32.000
use them in your work about it so high level you've got uh various life cycle triggers on the

42:32.000 --> 42:38.560
get hub side whether that's you know code being pushed to something or a new comment in an issue

42:39.360 --> 42:46.080
and then the action itself kind of encapsulates integrations with other things and so you can

42:46.080 --> 42:51.840
basically hook all your other things into various stages of your of interacting with get hub

42:52.480 --> 42:58.960
yeah absolutely yeah that's a good explanation and then um so some of the ones you mentioned

42:58.960 --> 43:06.640
and did you mention actions for great expectations yeah yeah yeah yeah yeah so you can say you can

43:06.640 --> 43:12.800
let's say you have like a SQL file in your repo you can set up an action to trigger like if you

43:12.800 --> 43:20.080
change this equal file uh you know let's say and then you know you want to validate the data that

43:20.080 --> 43:24.160
is like emitted by this equal file or maybe it's even a table definition that you have in your get

43:24.160 --> 43:31.280
a repo um you can have that validated by great expectations and then you can have the action

43:31.920 --> 43:37.680
like tell you whether a pastor failed the expectations check if it fails you can actually have it

43:37.680 --> 43:44.480
place a link to the the dashboard that great expectations produces um and you know

43:44.480 --> 43:48.880
things like that so just make it a little bit easier for you as a data scientist like when you're

43:48.880 --> 43:54.400
doing something to have it more integrated uh you know where it makes sense yeah maybe kind of

43:54.400 --> 44:01.680
wrap things up do you have visibility into kind of the direction that Jeremy and the the team are

44:01.680 --> 44:08.560
headed with fast API I'm wondering like you know what you're excited about there or um you know

44:08.560 --> 44:14.400
what you're looking for to taking on once you're back from paternity oh yeah that's a good question

44:14.400 --> 44:21.040
I haven't you know I've tried to stay true to my paternity leave and try to not pay too much

44:21.040 --> 44:26.960
attention to the outside world it's been hard um but actually don't know to be honest with you like

44:26.960 --> 44:31.920
what necessarily they're gonna focus on the most I would actually have talked to Jeremy

44:31.920 --> 44:43.280
yeah to ask him about that to be honest um what uh what what was on your list of things that you

44:43.280 --> 44:48.640
were kind of looking forward to and excited about before you left do you remember yeah so I was

44:48.640 --> 44:55.120
actually looking so one thing I've been really like interested in is like the explosion of different

44:55.120 --> 45:04.080
ML tooling out there mm-hmm and how this space is going to evolve yeah uh and you know um and then

45:04.080 --> 45:10.560
also like I was looking into like because like uh you know I haven't mentioned like GitHub is

45:10.560 --> 45:16.640
moved on to Azure using Azure ML I was actually looking at all these different alternative workflow

45:16.640 --> 45:23.680
tools for ML mm-hmm it's I was exploring a lot of them and one of the one that was most excited

45:23.680 --> 45:31.360
about so far is Metaflow mm-hmm from Netflix team so uh yeah that's one of the things we've been

45:31.360 --> 45:37.600
playing with most recently nice so we'll see maybe I will do something in that with that project

45:37.600 --> 45:44.320
in the future nice I had I interviewed recently Vela Toulouse who is the the founder that he's

45:44.320 --> 45:52.000
no longer in Netflix now he's kind of doing a startup based on Metaflow so um you know I'm sure

45:52.000 --> 45:57.360
there'll be lots of opportunity to dig into what they're up to there yeah yeah there definitely is

45:57.360 --> 46:03.280
and uh yeah I've been uh talking to Vela as well with the great interests and so yeah I think

46:03.280 --> 46:08.480
that's a really you know I'm really excited about their project and what in particular uh out of

46:08.480 --> 46:13.840
curiosity uh you mentioned all of the projects that are out there there are a ton of projects out

46:13.840 --> 46:20.480
there what in particular about that one uh catches your interest yeah so a lot of projects uh they're

46:20.480 --> 46:29.200
out there so like before this I was actually involved in Coopflow um and and so and then I've also

46:29.200 --> 46:35.520
used MLflow uh because of Azure and things like that and so one of the things that really impresses

46:35.520 --> 46:43.280
me about Metaflow is where how they meet the user where they are and so what I mean by that is

46:44.160 --> 46:48.160
for example Coopflow kind of tells the data scientists hey you should learn

46:48.960 --> 46:54.480
Kubernetes yeah um you know they may not say that explicitly but that is

46:54.480 --> 47:01.200
that is definitely like lurking in the room right and the ultimately like that makes it

47:01.200 --> 47:06.320
difficult can make it very difficult for adoption it's kind of like saying hey like I want to drive

47:06.320 --> 47:11.360
this car but I need to have a mechanic sitting in the passenger seat next to me the whole time

47:11.360 --> 47:16.400
mm-hmm and like no I don't want to drive a car like I cannot drive a car like that like can I just

47:16.400 --> 47:26.560
drive a car and so um you know I think with a lot of the Netflix info uh like that that you see

47:26.560 --> 47:32.960
you know it's kind of different like in terms of you know they try to meet the user where they are

47:33.520 --> 47:37.360
some might argue they made to try to meet the user too much where they are maybe like with this

47:37.360 --> 47:43.040
notebook info I think that's really cool like maybe some of those things are like experiments to

47:43.040 --> 47:49.440
try to see how far they can push the envelope either way I really like the the whole uh notion

47:49.440 --> 47:54.640
of meeting the user where they are and thinking about what like the user experience looks like

47:54.640 --> 48:02.800
and so like at their APIs and their workflow the design of the API uh is very intuitive and it

48:03.360 --> 48:10.720
doesn't require the user to really learn some like galaxy brain thing like Kubernetes

48:10.720 --> 48:19.680
um and I think that sounds really simple but I don't see that really any other that many tools do

48:19.680 --> 48:31.760
that um now MLflow is is there too um but I feel that MLflow is behind in a lot of their features

48:31.760 --> 48:39.360
versus metal flow in this regard um and I'm not a big you know the API something that I don't find

48:39.360 --> 48:46.880
as intuitive and so yeah that's it I mean this is like you know it's a good it's an open source

48:46.880 --> 48:52.800
project that seems like has a good traction I really like their API I like their philosophy of

48:52.800 --> 49:01.120
meeting the user where they are um yeah and so that's that's them apart uh so yeah I'm excited

49:01.120 --> 49:08.960
about it awesome awesome uh well Hamel it's been great catching up with you um excited we finally

49:08.960 --> 49:15.920
got to record this conversation and uh you know thanks for joining the show all right thank you for

49:15.920 --> 49:41.600
having me thank you

