1
00:00:00,000 --> 00:00:16,120
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

2
00:00:16,120 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:32,440
I'm your host Sam Charrington.

4
00:00:32,440 --> 00:00:33,840
Contest alert.

5
00:00:33,840 --> 00:00:38,960
This week we have a jam-packed intro, including a new contest we're launching.

6
00:00:38,960 --> 00:00:43,040
So please bear with me, you don't want to miss this one.

7
00:00:43,040 --> 00:00:46,720
First, a bit about this week's shows.

8
00:00:46,720 --> 00:00:51,440
As you may know, I spent a few days at CES earlier this month.

9
00:00:51,440 --> 00:00:56,400
While there, I spoke with a bunch of folks applying AI in the consumer electronics industry,

10
00:00:56,400 --> 00:01:01,040
and I'm including you in those conversations via this series of shows.

11
00:01:01,040 --> 00:01:05,440
Stay tuned as we explore some of the very cool ways that machine learning and AI are being

12
00:01:05,440 --> 00:01:08,600
used to enhance our everyday lives.

13
00:01:08,600 --> 00:01:13,680
This includes work being done at Anki, who built Cosmo, the cutest little computer vision-powered

14
00:01:13,680 --> 00:01:15,280
robot.

15
00:01:15,280 --> 00:01:22,120
Nighthouse, whose smart home security camera combines 3D sensing with deep learning and NLP.

16
00:01:22,120 --> 00:01:28,120
Intel, who's using the single-shot multi-box image detection algorithm to personalize video

17
00:01:28,120 --> 00:01:31,680
fees for the Ferrari Challenge North America.

18
00:01:31,680 --> 00:01:36,480
First beat, a company whose machine learning algorithms analyzed your heartbeat data to

19
00:01:36,480 --> 00:01:42,360
provide personalized insights into stress, exercise, and sleep patterns.

20
00:01:42,360 --> 00:01:48,400
3AI and Koito, who have partnered to bring machine learning-based adaptive driving beams

21
00:01:48,400 --> 00:01:52,280
or automatically adjusting high beams to the U.S.

22
00:01:52,280 --> 00:01:59,480
And last but not least, aerial.ai, who applies sophisticated analytics to Wi-Fi signals to

23
00:01:59,480 --> 00:02:05,640
enable some really interesting home automation and healthcare applications.

24
00:02:05,640 --> 00:02:11,000
Now, as if six amazing interviews wasn't enough, a few of these companies have been so

25
00:02:11,000 --> 00:02:15,520
kind as to provide us with products for you, the Twimmel community.

26
00:02:15,520 --> 00:02:19,360
And keeping with the theme of this series, our contest will be a little different this

27
00:02:19,360 --> 00:02:20,360
time.

28
00:02:20,360 --> 00:02:25,400
To enter, we want to hear from you about the role AI is playing in your home and personal

29
00:02:25,400 --> 00:02:28,640
life, and where you see it going.

30
00:02:28,640 --> 00:02:36,200
Just head on over to Twimmelai.com slash myaicontest, fire up your webcam or smartphone camera,

31
00:02:36,200 --> 00:02:39,120
and tell us your story in two minutes or less.

32
00:02:39,120 --> 00:02:43,600
Go post the videos to YouTube, and the video with the most likes wins their choice of

33
00:02:43,600 --> 00:02:50,480
great prizes, including an Anki Cosmo, a lighthouse smart home camera, and more.

34
00:02:50,480 --> 00:02:55,040
Submissions will be taken until February 11th, and voting will remain open until February

35
00:02:55,040 --> 00:02:56,040
18th.

36
00:02:56,040 --> 00:03:02,360
Good luck.

37
00:03:02,360 --> 00:03:06,560
Before we dive into today's show, I'd like to thank our friends at Intel AI for their

38
00:03:06,560 --> 00:03:09,520
continued support of this podcast.

39
00:03:09,520 --> 00:03:14,760
Intel was extremely active at this year's CES, with a bunch of AI autonomous driving

40
00:03:14,760 --> 00:03:17,200
and VR-related announcements.

41
00:03:17,200 --> 00:03:21,440
One of the more interesting partnerships they announced was a collaboration with the Ferrari

42
00:03:21,440 --> 00:03:24,720
Challenge North America race series.

43
00:03:24,720 --> 00:03:29,440
Along with the folks at Ferrari Challenge, Intel AI aspires to make the race viewing experience

44
00:03:29,440 --> 00:03:35,360
more personalized by using deep computer vision to detect and monitor individual race

45
00:03:35,360 --> 00:03:40,640
cars via camera feeds and allow viewers to choose the specific cars feeds that they'd

46
00:03:40,640 --> 00:03:42,200
like to watch.

47
00:03:42,200 --> 00:03:46,960
Look for my conversation with Intel's Andy Keller and Emil Chindicki earlier in this series

48
00:03:46,960 --> 00:03:52,920
for an in-depth discussion about this project, and be sure to visit ai.intel.com where you'll

49
00:03:52,920 --> 00:03:56,200
find Andy's technical blog post on the topic.

50
00:03:56,200 --> 00:03:58,160
Now about today's show.

51
00:03:58,160 --> 00:04:04,920
In this episode, I'm joined by Michelle Iyege and Negar Gorcian of aerial.ai.

52
00:04:04,920 --> 00:04:09,880
Intel is doing some really interesting things in the home automation space by using Wi-Fi

53
00:04:09,880 --> 00:04:16,440
signal statistics to identify and understand what's happening in our homes and office environments.

54
00:04:16,440 --> 00:04:21,440
Michelle, the CTO, describes some of the capabilities of their platform, including its ability

55
00:04:21,440 --> 00:04:26,040
to detect not only people and pets within the home, but surprising characteristics like

56
00:04:26,040 --> 00:04:28,200
breathing rates and patterns.

57
00:04:28,200 --> 00:04:32,960
He also gives us a look into their data collection process, including the types of data needed,

58
00:04:32,960 --> 00:04:36,200
how they obtain it, and how it's parsed.

59
00:04:36,200 --> 00:04:41,200
Negar, a senior data scientist with aerial, describes the types of models they use, including

60
00:04:41,200 --> 00:04:46,160
semi-supervised, unsupervised, and signal processing-based models, and how they've scaled

61
00:04:46,160 --> 00:04:50,720
their platform, and provides us with some real-world use cases.

62
00:04:50,720 --> 00:04:53,320
And now on to the show.

63
00:04:53,320 --> 00:04:54,960
All right, everyone.

64
00:04:54,960 --> 00:04:59,800
I am on the line with Michelle Iyege and Negar Gorcian.

65
00:04:59,800 --> 00:05:06,280
Michelle is CTO of aerial.ai, and Negar is a senior data scientist there.

66
00:05:06,280 --> 00:05:11,160
Michelle and Negar, welcome to this week in machine learning and AI.

67
00:05:11,160 --> 00:05:12,160
Thank you very much, Sam.

68
00:05:12,160 --> 00:05:14,760
I'm very glad to be here with you.

69
00:05:14,760 --> 00:05:16,760
Thank you very much for having us.

70
00:05:16,760 --> 00:05:17,760
Absolutely.

71
00:05:17,760 --> 00:05:21,560
Why don't we get started by having you tell us a little bit about your backgrounds.

72
00:05:21,560 --> 00:05:23,760
Michelle, why don't you get us started?

73
00:05:23,760 --> 00:05:24,760
Perfect.

74
00:05:24,760 --> 00:05:32,280
Thank you very much, Sam, my background is in the digital scene processing and telecommunications.

75
00:05:32,280 --> 00:05:44,920
I earned master degrees and PhD degrees in Spain in Seville, and then I moved towards to

76
00:05:44,920 --> 00:05:53,280
work with the University College Dublin in Adelaum, and the European Space Agency before

77
00:05:53,280 --> 00:06:01,200
becoming a permanent resident in Canada, which we started an aerial in Montreal in 2015.

78
00:06:01,200 --> 00:06:02,200
Awesome.

79
00:06:02,200 --> 00:06:04,200
And Negar, how about you?

80
00:06:04,200 --> 00:06:10,240
So I started my studies in electrical engineering, and then I moved slightly from my master

81
00:06:10,240 --> 00:06:14,960
towards speech processing, telecommunications, speech recognition.

82
00:06:14,960 --> 00:06:19,800
And that's the first point I got introduced to machine learning field.

83
00:06:19,800 --> 00:06:25,120
And I liked it, I liked working with data and human-centric data specifically.

84
00:06:25,120 --> 00:06:32,560
That's where I decided to start my PhD at McGill University at Montreal in Cambridge Science,

85
00:06:32,560 --> 00:06:38,080
more towards machine learning applications and mining human-centric data.

86
00:06:38,080 --> 00:06:42,000
And then right after that, I joined the aerial as a data scientist.

87
00:06:42,000 --> 00:06:43,000
Awesome.

88
00:06:43,000 --> 00:06:44,000
Awesome.

89
00:06:44,000 --> 00:06:47,000
Why don't you give us a little bit of an overview of what aerial is up to?

90
00:06:47,000 --> 00:06:50,000
It seems like a really interesting application.

91
00:06:50,000 --> 00:06:51,000
Yes.

92
00:06:51,000 --> 00:07:01,800
Well, aerial basically reuse Wi-Fi signals to understand a little bit of context about the environment.

93
00:07:01,800 --> 00:07:09,080
So you have a Wi-Fi signals bouncing all over the places indoors, basically.

94
00:07:09,080 --> 00:07:15,440
And then we'll reuse statistics from the Wi-Fi signal to understand the environment

95
00:07:15,440 --> 00:07:26,160
such as a human presence, a pet's presence, for example, to be applied to a home automation

96
00:07:26,160 --> 00:07:29,400
on health care obligations, basically.

97
00:07:29,400 --> 00:07:35,680
Yeah, I've, I think I've told this story once on the podcast before a few years ago,

98
00:07:35,680 --> 00:07:41,840
I was interested in doing a project around home automation.

99
00:07:41,840 --> 00:07:51,440
And at the time, this was before, before really computer vision with deep learning, you

100
00:07:51,440 --> 00:07:54,720
know, had the advancements, the recent advancements.

101
00:07:54,720 --> 00:08:00,080
And I almost, I pretty much got stuck out of the gate trying to figure out a cost-effective

102
00:08:00,080 --> 00:08:03,360
way to do presence detection.

103
00:08:03,360 --> 00:08:08,160
You know, there were a bunch of different ways to do it, but, you know, we were talking

104
00:08:08,160 --> 00:08:15,720
about things like trying to put NFC receivers by doors and stuff like that, and it was really

105
00:08:15,720 --> 00:08:16,720
messy.

106
00:08:16,720 --> 00:08:23,480
And now there's a bunch of interesting ways to do it, including just put cameras by doors

107
00:08:23,480 --> 00:08:26,680
and do object detection.

108
00:08:26,680 --> 00:08:32,440
But what you're offering seems to be a really interesting way to just piggyback of stuff

109
00:08:32,440 --> 00:08:34,120
that's already there.

110
00:08:34,120 --> 00:08:41,120
Exactly, exactly, that's the main, our main purpose is some, to reuse those water scenes

111
00:08:41,120 --> 00:08:47,480
that, when no one is at home, they behave in a very particular way, when someone just

112
00:08:47,480 --> 00:08:54,120
show up, they behave completely different, and that's, that's when, when the, our work

113
00:08:54,120 --> 00:08:59,320
starts to identify, by identifying those patterns.

114
00:08:59,320 --> 00:09:04,320
Can you tell us a little bit about the science behind it and what makes it work?

115
00:09:04,320 --> 00:09:12,040
I'm imagining, you know, it just has to do with kind of the density and water content of

116
00:09:12,040 --> 00:09:18,600
our bodies, and they change the radio waves bounce around, but I'm sure there's a lot

117
00:09:18,600 --> 00:09:20,400
more detail to it there.

118
00:09:20,400 --> 00:09:23,040
Yes, yes, it's a pleasure to.

119
00:09:23,040 --> 00:09:31,800
So actually, Wi-Fi is a pretty smart system, and it's all the time sensing the environment.

120
00:09:31,800 --> 00:09:33,960
And that's exactly what we use.

121
00:09:33,960 --> 00:09:42,640
We use any statistic from physical layer up to link layer, and by looking at these statistics,

122
00:09:42,640 --> 00:09:51,000
you have, you're basically sensing the environment with any two Wi-Fi devices that are connected

123
00:09:51,000 --> 00:09:57,480
each other, let's say you're routed on your TV, we are already sensing in that, in that

124
00:09:57,480 --> 00:09:58,480
scenario.

125
00:09:58,480 --> 00:10:05,080
And basically, your body, while your body moves through those signals, your body disturbs

126
00:10:05,080 --> 00:10:12,720
those signals in a very particular way, depending on what you're doing, how fast you're going,

127
00:10:12,720 --> 00:10:16,720
and what are the activities you're involved in, basically.

128
00:10:16,720 --> 00:10:24,320
Well, machine learning and AI comes to the, well, we start with the pattern recognition,

129
00:10:24,320 --> 00:10:30,880
but it's more complex, more complex than that, and it's actually machine learning and AI

130
00:10:30,880 --> 00:10:40,240
is the answer to our research questions, and it's providing us with very good results.

131
00:10:40,240 --> 00:10:46,040
That's what we are using machine learning and AI today.

132
00:10:46,040 --> 00:10:52,320
So maybe Nagar, can you tell us a little bit about the pipelines that you use and the types

133
00:10:52,320 --> 00:10:56,920
of data that you're collecting, how you're collecting it, and how you're turning that

134
00:10:56,920 --> 00:10:58,120
into models?

135
00:10:58,120 --> 00:11:00,400
Oh, yeah, sure.

136
00:11:00,400 --> 00:11:08,600
So what we do is that technically, we use Wi-Fi enabled devices in indoor spaces to scan

137
00:11:08,600 --> 00:11:13,760
and record these Wi-Fi statistics that Michelle mentioned.

138
00:11:13,760 --> 00:11:20,760
So technically, we are turning the routers and Wi-Fi enabled devices to some cameras.

139
00:11:20,760 --> 00:11:27,600
Let's say the hidden camera is to scan the environment where these Wi-Fi signal propagates,

140
00:11:27,600 --> 00:11:35,000
and then anything that any event and motion that happens within an indoor space affects

141
00:11:35,000 --> 00:11:43,080
that data statistics, and that's where we, through the routers of each household, we scan

142
00:11:43,080 --> 00:11:48,080
these statistics, we send it to the cloud, and that's where we start processing the data

143
00:11:48,080 --> 00:11:49,080
from.

144
00:11:49,080 --> 00:11:55,920
How granular can you get with the data off of the Wi-Fi routers?

145
00:11:55,920 --> 00:12:01,080
Is it able to tell you, is it able to uniquely identify individuals within a home or just

146
00:12:01,080 --> 00:12:07,840
that maybe that there's someone there, or you mentioned pets, how much detail can you

147
00:12:07,840 --> 00:12:09,560
get out of these signals?

148
00:12:09,560 --> 00:12:16,360
Yes, it's a very fine-grained data sum, and we, as you mentioned before, we are able

149
00:12:16,360 --> 00:12:22,760
to identify different users by the body mass and the way they move on the space.

150
00:12:22,760 --> 00:12:30,120
And these signals could be as sensitive as that we are able to detect a breathing rate,

151
00:12:30,120 --> 00:12:40,720
for example, in the right position, by the action of being breathing, you're moving your

152
00:12:40,720 --> 00:12:48,160
chest, and thus modulating our signals as well, and we are capable of detecting a breathing

153
00:12:48,160 --> 00:12:49,480
rate, for example.

154
00:12:49,480 --> 00:12:52,280
It could be as granular as that.

155
00:12:52,280 --> 00:12:53,280
That is incredible.

156
00:12:53,280 --> 00:12:59,880
I find that really difficult to wrap my head around.

157
00:12:59,880 --> 00:13:08,640
Is this all done without requiring me to change the access points I'm using, or do I

158
00:13:08,640 --> 00:13:13,160
need to use specialized devices?

159
00:13:13,160 --> 00:13:16,320
You don't need to use any specialized devices.

160
00:13:16,320 --> 00:13:22,720
Wi-Fi devices, and we look at statistics within the Wi-Fi standards.

161
00:13:22,720 --> 00:13:29,440
Do you require some of the newer Wi-Fi mesh networking technologies, or I've got

162
00:13:29,440 --> 00:13:36,760
one standard kind of old Wi-Fi router, and I guess are you also looking at, do you also

163
00:13:36,760 --> 00:13:42,000
get statistics reported from the client devices, or is it just the access point?

164
00:13:42,000 --> 00:13:48,520
It could be from both sides, actually, or one of the size involved.

165
00:13:48,520 --> 00:13:53,680
It could be one client, for example, and we collect data in the client and send it up

166
00:13:53,680 --> 00:13:59,400
to the cloud, or we could be on the router looking at multiple clients at the same time.

167
00:13:59,400 --> 00:14:03,120
And we upload the information.

168
00:14:03,120 --> 00:14:13,240
So, as long as you have end devices in your home, IEEE, AOT 2011, and above, we're good

169
00:14:13,240 --> 00:14:14,240
to go.

170
00:14:14,240 --> 00:14:17,440
There's a new one coming out soon, I just read about, is it X?

171
00:14:17,440 --> 00:14:18,440
Yes, yes.

172
00:14:18,440 --> 00:14:20,640
There are new standards coming up.

173
00:14:20,640 --> 00:14:26,320
All of them are improving, actually, and are providing even more fine-grained data to

174
00:14:26,320 --> 00:14:27,920
us, actually.

175
00:14:27,920 --> 00:14:35,640
And the better that Wi-Fi gets, the best for us.

176
00:14:35,640 --> 00:14:39,920
Mesh is also a very interesting topology for us to be in.

177
00:14:39,920 --> 00:14:44,120
We are very excited to work in Mesh, as well.

178
00:14:44,120 --> 00:14:49,960
So I've got my Wi-Fi network and my access point, various clients.

179
00:14:49,960 --> 00:14:50,960
How do you collect data?

180
00:14:50,960 --> 00:14:57,440
Do you have, is there like a mobile client or something like that, or is it another device

181
00:14:57,440 --> 00:14:59,520
type that you're introducing?

182
00:14:59,520 --> 00:15:06,920
Basically, well, if we can upgrade the firmware in your router, that would be the ideal point

183
00:15:06,920 --> 00:15:16,560
to be in, as we're going to be deploying the system very soon with one of our ISPs.

184
00:15:16,560 --> 00:15:17,800
That's the way we're going to use.

185
00:15:17,800 --> 00:15:23,880
So we just need to update your router, for example, your ISPs router.

186
00:15:23,880 --> 00:15:31,440
We could also be in one dumb client that we could provide you with, and the agent that

187
00:15:31,440 --> 00:15:39,160
collects the data and send it to the cloud is in these small devices that we could provide

188
00:15:39,160 --> 00:15:40,400
as well.

189
00:15:40,400 --> 00:15:46,440
But as long as we can update anything where of any of your devices, we are ready to go

190
00:15:46,440 --> 00:15:47,440
from there.

191
00:15:47,440 --> 00:15:54,040
Okay, so is the implication then that the business model, at least as you envision it today,

192
00:15:54,040 --> 00:16:03,760
is less direct to consumer and more, either via an OEM with a router or via an ISP relationship

193
00:16:03,760 --> 00:16:07,240
or something like that, where they can change the firmware for you?

194
00:16:07,240 --> 00:16:08,240
Exactly.

195
00:16:08,240 --> 00:16:09,240
Yes.

196
00:16:09,240 --> 00:16:12,080
We're going through ISPs initially.

197
00:16:12,080 --> 00:16:19,200
That way we feel as well that we could get to a big marker.

198
00:16:19,200 --> 00:16:26,400
But of course, the users is the same, either you go directly consumer or through ISPs,

199
00:16:26,400 --> 00:16:31,760
at the end you have the same users, at the end you have, you want to provide a very cheap

200
00:16:31,760 --> 00:16:36,880
security system, for example, to your customers, where you're going through an ISP or you're

201
00:16:36,880 --> 00:16:38,400
going directly.

202
00:16:38,400 --> 00:16:46,520
We have chosen the ISP because it's a very good business model, it's very clever, that's

203
00:16:46,520 --> 00:16:48,240
the way we're going to start.

204
00:16:48,240 --> 00:16:51,640
So you're collecting this data.

205
00:16:51,640 --> 00:17:02,680
Can you be more specific about the types of data that you require, the specific types

206
00:17:02,680 --> 00:17:03,680
of values?

207
00:17:03,680 --> 00:17:04,680
Yes.

208
00:17:04,680 --> 00:17:11,200
For example, we collect every data available at physical layer, for example, and we all

209
00:17:11,200 --> 00:17:12,200
upload that.

210
00:17:12,200 --> 00:17:23,200
Let's say RSSI, RSSI values, let's say commuting on the RAID on your device, let's say channel

211
00:17:23,200 --> 00:17:32,000
information, we collect all these types of data and all of them are very sensitive to

212
00:17:32,000 --> 00:17:36,000
what's happening in the environment, and we work from there.

213
00:17:36,000 --> 00:17:42,520
We start summarizing, we start doing a feature extraction on top of that, until we reach

214
00:17:42,520 --> 00:17:46,840
to our processing engine with the models and models.

215
00:17:46,840 --> 00:17:47,840
Okay.

216
00:17:47,840 --> 00:17:55,040
So you've got all this data, it's uploaded to the cloud, Nagar, how do you even start

217
00:17:55,040 --> 00:18:03,600
to build models around this, for example, are these supervised models, and how are you

218
00:18:03,600 --> 00:18:06,840
training against this type of data?

219
00:18:06,840 --> 00:18:12,280
Yeah, it's a very tricky and interesting question.

220
00:18:12,280 --> 00:18:19,960
So we receive these variety types and a huge amount of data from each house.

221
00:18:19,960 --> 00:18:26,920
And then depending on the task we have on hand, we decide to choose an algorithm or a learning

222
00:18:26,920 --> 00:18:32,280
method that actually minimizes the requirement for query the user very often.

223
00:18:32,280 --> 00:18:37,720
So we try to go with the setups that we don't really need to get through labels from the

224
00:18:37,720 --> 00:18:45,560
actual users, but we try to like kind of like unsupervised setup or semi supervised learning

225
00:18:45,560 --> 00:18:49,920
setups that be good, a minimum amount of information from the environment, from the

226
00:18:49,920 --> 00:18:50,920
user per se.

227
00:18:50,920 --> 00:18:56,680
And then the rest of is it's on us to actually predict models, build models.

228
00:18:56,680 --> 00:19:05,480
In some applications, we could go fully unsupervised like the security application, but as more

229
00:19:05,480 --> 00:19:10,800
complicated tasks comes in, like activity recognition or healthcare applications, that's

230
00:19:10,800 --> 00:19:17,560
where actually we will need the minimum amount of like label provided by the users, or we

231
00:19:17,560 --> 00:19:25,520
could have extract these raw labels automatically from the rest of the feature space we extract

232
00:19:25,520 --> 00:19:27,440
and use them as reference point.

233
00:19:27,440 --> 00:19:35,360
And over time, as a user, use their application more and more, we get, we correct our models

234
00:19:35,360 --> 00:19:39,280
technically based on the first initial models that we built.

235
00:19:39,280 --> 00:19:40,280
Hmm.

236
00:19:40,280 --> 00:19:45,720
Can you give me an example of how you're able to automatically extract labels from the

237
00:19:45,720 --> 00:19:46,720
data set?

238
00:19:46,720 --> 00:19:47,720
Yeah.

239
00:19:47,720 --> 00:19:55,280
Uh, for example, um, we have some, some specific features that we extract from the

240
00:19:55,280 --> 00:20:01,280
writers directly, uh, gives us a rough estimation or even like sometimes a very good estimation

241
00:20:01,280 --> 00:20:07,080
of a location of a user with respect to the fixed anchors that you have at home, right?

242
00:20:07,080 --> 00:20:12,720
So that will roughly give you an estimation of a location of a person and then using the

243
00:20:12,720 --> 00:20:18,360
time of the day and the pattern of move as part of the amount of motion that each person

244
00:20:18,360 --> 00:20:24,680
has 24 seven, that can kind of roughly give you a good idea of that, like, how was that

245
00:20:24,680 --> 00:20:28,440
user moving and behaving throughout the day?

246
00:20:28,440 --> 00:20:29,440
Hmm.

247
00:20:29,440 --> 00:20:30,440
Okay.

248
00:20:30,440 --> 00:20:34,760
So I'm imagining things like you can figure out how many of the devices, how many of the

249
00:20:34,760 --> 00:20:39,000
clients are cell phones and that gives you a sense of the number of people that are

250
00:20:39,000 --> 00:20:44,440
in the home and then you can like at night, the cell phones are probably not moving and

251
00:20:44,440 --> 00:20:49,800
you kind of know where they are in the home and, uh, you can start to build some labels

252
00:20:49,800 --> 00:20:50,800
from there.

253
00:20:50,800 --> 00:20:52,640
Is that the general idea?

254
00:20:52,640 --> 00:20:56,440
That is, that is like something that we definitely think about and we can, but we're

255
00:20:56,440 --> 00:21:00,600
not limited to those type of getting, yeah, we can use those information about different

256
00:21:00,600 --> 00:21:04,840
users getting connected to a writer, we have access to that, then we sit in a writer.

257
00:21:04,840 --> 00:21:09,360
You have access to those kind of information, but necessarily it's not the only source

258
00:21:09,360 --> 00:21:13,800
of information we extract, but definitely the goal is what you mentioned to actually learn

259
00:21:13,800 --> 00:21:19,640
the pattern of like the behavior of each individual user that lives in a household over time.

260
00:21:19,640 --> 00:21:24,000
You know, we start off with some general models and general assumptions about how people

261
00:21:24,000 --> 00:21:27,680
leave in the house, how do you move, where they to go, when they leave home, when they

262
00:21:27,680 --> 00:21:35,400
come back and then these general assumptions will get edited over time with, with different

263
00:21:35,400 --> 00:21:40,360
models that we have and the models get updated, particularly for each house.

264
00:21:40,360 --> 00:21:41,360
Mm-hmm.

265
00:21:41,360 --> 00:21:48,240
So I kind of get that in the, the general case of kind of presence detection, but when

266
00:21:48,240 --> 00:21:55,680
we're talking about, uh, the, the breathing example that Michelle mentioned, which, uh,

267
00:21:55,680 --> 00:21:59,240
you also mentioned healthcare use cases, I'm assuming that is related to a healthcare

268
00:21:59,240 --> 00:22:00,880
use case.

269
00:22:00,880 --> 00:22:07,040
How do you, how do you begin to build a model around, uh, around that, uh, you mean about

270
00:22:07,040 --> 00:22:08,040
breathing rate?

271
00:22:08,040 --> 00:22:09,040
Right.

272
00:22:09,040 --> 00:22:10,040
Right.

273
00:22:10,040 --> 00:22:11,040
Yeah.

274
00:22:11,040 --> 00:22:15,760
So in those cases, most of the techniques that we would use is like signal processing and

275
00:22:15,760 --> 00:22:22,440
like more of, uh, time series analysis, findings, is an all day finding, uh, the curiosity

276
00:22:22,440 --> 00:22:27,960
in the signal, that's more of those type of, uh, techniques we would use to actually find

277
00:22:27,960 --> 00:22:28,960
the pattern.

278
00:22:28,960 --> 00:22:32,700
The breathing rate is something sick like and then, uh, it's, it's something that you

279
00:22:32,700 --> 00:22:37,800
could actually detect and, uh, information, uh, with regard to presence detection that

280
00:22:37,800 --> 00:22:43,040
you mentioned, uh, no matter like presence detection could be like for us, it has a different

281
00:22:43,040 --> 00:22:44,040
definition.

282
00:22:44,040 --> 00:22:49,400
When you have movements or like very intense movements, that's easier, easier to, to figure

283
00:22:49,400 --> 00:22:50,400
out.

284
00:22:50,400 --> 00:22:56,160
Also, when you sit somewhere or we're, you're trying to space city or when you're asleep,

285
00:22:56,160 --> 00:23:01,640
that presence detection in that level is just, we are looking into finer, like finer

286
00:23:01,640 --> 00:23:08,320
grade, like motion and activities that it just presents off a body with, with have on

287
00:23:08,320 --> 00:23:11,840
the data and then figure out that there is someone there.

288
00:23:11,840 --> 00:23:16,560
And then someone is breathing or someone having very micro movements versus when it houses

289
00:23:16,560 --> 00:23:17,560
empty.

290
00:23:17,560 --> 00:23:18,560
Right.

291
00:23:18,560 --> 00:23:19,560
Right.

292
00:23:19,560 --> 00:23:27,120
Just the presence, when you even think about the, the notion of presence, you're trying

293
00:23:27,120 --> 00:23:34,720
to pull out a rich set of, um, you know, parameters, localization of the people in house

294
00:23:34,720 --> 00:23:35,720
things like that.

295
00:23:35,720 --> 00:23:38,080
It's not just empty or a person in the house.

296
00:23:38,080 --> 00:23:39,080
Nope.

297
00:23:39,080 --> 00:23:42,880
That's, that's improving with the, with the different applications we're developing.

298
00:23:42,880 --> 00:23:43,880
Right.

299
00:23:43,880 --> 00:23:44,880
Right.

300
00:23:44,880 --> 00:23:52,840
When you have applications that require, um, some type of labeling, it sounds like maybe

301
00:23:52,840 --> 00:23:58,880
you're doing that via direct input via mobile device or something.

302
00:23:58,880 --> 00:24:05,400
In some cases, yes, we could get the direct entries from a query user that, uh, to, to

303
00:24:05,400 --> 00:24:10,800
give feedback or label on some particular activity or some particular state of the house.

304
00:24:10,800 --> 00:24:11,800
For example.

305
00:24:11,800 --> 00:24:16,960
But the idea is just to, just to talk to complement a little bit on that, but the idea is to actually

306
00:24:16,960 --> 00:24:20,920
minimize, minimize the query to the user.

307
00:24:20,920 --> 00:24:26,800
Um, for example, in applications such as elderly care, a health care, in particular,

308
00:24:26,800 --> 00:24:32,640
elderly care, uh, we don't see the user interacting too much with our system.

309
00:24:32,640 --> 00:24:33,640
Right.

310
00:24:33,640 --> 00:24:39,560
So we are generating more auto generating our labels, uh, to fit the different type of models

311
00:24:39,560 --> 00:24:45,800
we use, uh, but, but, but for, of course, you, you cannot expect too, too many labels

312
00:24:45,800 --> 00:24:52,560
or, or be interacting too much, uh, for, for this particular application, uh, it's not

313
00:24:52,560 --> 00:24:59,840
difficult to figure out, for example, uh, where the, you know, how people walking, walking

314
00:24:59,840 --> 00:25:07,120
in the bathroom looks like, how people walking in the bathroom looks like, how, you know,

315
00:25:07,120 --> 00:25:11,920
the, uh, brushing teeth looks like it's because you, you could correlate with the time of

316
00:25:11,920 --> 00:25:17,280
the day, um, when they take the actions from, from the moment they, they start walking,

317
00:25:17,280 --> 00:25:20,320
uh, in the morning or at any time.

318
00:25:20,320 --> 00:25:21,320
Wow.

319
00:25:21,320 --> 00:25:31,520
Um, how does the system, uh, how does the system scale in the sense of the, you know,

320
00:25:31,520 --> 00:25:39,280
number of individuals per access point? I guess I'm wondering like what the, you know,

321
00:25:39,280 --> 00:25:46,200
what the, um, I guess I'm wondering if you have multiple people like, if you go from

322
00:25:46,200 --> 00:25:50,320
a house environment to an office environment or something like that, do you start to lose

323
00:25:50,320 --> 00:25:55,720
your ability to get fine-grained information about what's happening within the environment

324
00:25:55,720 --> 00:26:02,800
or deep, does it stay, is it your visibility proportional to the number of access points

325
00:26:02,800 --> 00:26:06,440
and as you increase people, you increase access points and you're, you're still good.

326
00:26:06,440 --> 00:26:07,800
Like, what are the issues there?

327
00:26:07,800 --> 00:26:13,200
Uh, yes, exactly. Uh, definitely the, the fewer number of people that you have in the

328
00:26:13,200 --> 00:26:19,920
sensing area, uh, the better. So let's define a sensing area, such as your access point

329
00:26:19,920 --> 00:26:25,440
on one client connected to it. So your sensing, one specific area, because these two

330
00:26:25,440 --> 00:26:31,480
devices have fixed. Uh, let's say, uh, the more granularity you want with more people

331
00:26:31,480 --> 00:26:38,160
around, you will need to increase the number of independent sensing areas. Uh, that will

332
00:26:38,160 --> 00:26:43,760
give you enough resolution to keep working. But of course, if we are talking about, if

333
00:26:43,760 --> 00:26:50,760
we move from, from residential applications towards more commercial or business settings,

334
00:26:50,760 --> 00:27:01,080
uh, you will lose a solution. Uh, it's not the same to, uh, to track five, six, uh, people

335
00:27:01,080 --> 00:27:07,440
versus a 50 to 100 people. Right. Uh, it's very interesting. Actually, we, we are doing

336
00:27:07,440 --> 00:27:14,400
it today. Uh, we have, uh, deployments in large offices. Uh, the patterns are very,

337
00:27:14,400 --> 00:27:20,840
uh, very interesting over day, overnight, over weekends, over holidays. It's very, very

338
00:27:20,840 --> 00:27:25,760
interesting. Uh, uh, but, but of course, you lose, uh, a little bit of resolution in terms

339
00:27:25,760 --> 00:27:31,760
of, you know, who's walking there within a hundred users, right? Yeah. You mentioned the

340
00:27:31,760 --> 00:27:38,160
sensing area is an access point and a client connection. Uh, it's got to help you that

341
00:27:38,160 --> 00:27:44,360
pretty much everyone is walking around with a client nowadays. And so each individual,

342
00:27:44,360 --> 00:27:52,640
each incremental person, does that create, uh, it's own sensing area if they've got a mobile

343
00:27:52,640 --> 00:28:01,400
device? Yes, for sure. And, and you know that that device is moving, um, and we can use

344
00:28:01,400 --> 00:28:08,600
it. Uh, we, we are, we are doing it and we are planning to, to rely on devices as well.

345
00:28:08,600 --> 00:28:14,480
But let's say like the beauty of our technology and when we are spending more time, it's

346
00:28:14,480 --> 00:28:20,760
in natural doses scenarios where you are not carrying your mobile with you. Okay. And

347
00:28:20,760 --> 00:28:24,200
if you think about it, use, you know, one of the first things that probably you do when

348
00:28:24,200 --> 00:28:32,000
you get home is to get rid of of yourself for a little bit. And we don't, we don't want

349
00:28:32,000 --> 00:28:36,960
to, to lose the, the type of information. You know, you're walking, you want to arrive

350
00:28:36,960 --> 00:28:42,560
home, you want to probably relax. So we want to know that, we want to know that to give

351
00:28:42,560 --> 00:28:48,360
you the, the right tone of your lights. We want to turn on your TV, for example, on your

352
00:28:48,360 --> 00:28:54,160
favorite channel. And we want to prepare this scenario for you, even if you're not wearing

353
00:28:54,160 --> 00:28:59,960
a mobile, but we don't see you controlling the home with your mobile all the time next

354
00:28:59,960 --> 00:29:05,600
to you. Uh, oh, and you everywhere. Uh, this is a really fascinating application. When

355
00:29:05,600 --> 00:29:13,040
can we, as the consumers expect, uh, you know, see this, you know, more broadly available?

356
00:29:13,040 --> 00:29:22,160
Well, this year we are deploying, uh, with one of the largest ISPs in the world. Unfortunately,

357
00:29:22,160 --> 00:29:31,560
I cannot reveal the name yet. But it's huge. We'll be with them in a piece of mine application

358
00:29:31,560 --> 00:29:38,640
for families to know, uh, to know where there are people at home or not, uh, who has arrived

359
00:29:38,640 --> 00:29:47,280
home and prepare, you know, um, kind of a home automation, uh, type of applications, as

360
00:29:47,280 --> 00:29:55,840
well as we are, uh, we're also working very hard for our elderly care applications, because

361
00:29:55,840 --> 00:30:03,040
the, uh, well, the market is huge as well there. And it's so, uh, we are very fascinated

362
00:30:03,040 --> 00:30:08,200
about the elderly care application. We can provide so much information to the caregivers

363
00:30:08,200 --> 00:30:14,560
and even to the doctors of those patients, uh, that is, they don't have it today. There

364
00:30:14,560 --> 00:30:20,520
is no way, uh, without the camera that you can tell how many times a person is going

365
00:30:20,520 --> 00:30:26,120
to the bathroom, how much time he's spending on the bathroom versus taking a shower. So

366
00:30:26,120 --> 00:30:32,120
it is so, the pressure is so high because we can do it, uh, that we will love to go to

367
00:30:32,120 --> 00:30:38,600
the market right away. We would love to extend elderly population, uh, time at home as

368
00:30:38,600 --> 00:30:43,400
much as we can. And even, even after being the child for the hospital, let's say for

369
00:30:43,400 --> 00:30:48,000
something, we would like to track to, to see that everything is, is, is going well at

370
00:30:48,000 --> 00:30:55,800
home. Mm hmm. And is the resolution fine enough such that you can detect, uh, like

371
00:30:55,800 --> 00:31:02,480
fall events, uh, and things like that? Uh, yes, actually, that is one of the most

372
00:31:02,480 --> 00:31:07,240
interesting applications that we started off and many people are asking for. So fall

373
00:31:07,240 --> 00:31:11,840
detection is one of the major actually goals that we're setting for our elderly care

374
00:31:11,840 --> 00:31:18,360
application. And, uh, because it's happening in a, right, in a part, usually mostly it's

375
00:31:18,360 --> 00:31:23,920
happening in some shower areas, map areas, uh, we have very, I hope to get it. And sooner

376
00:31:23,920 --> 00:31:30,000
when we start working, uh, more, more focusedly on our, uh, elderly care application.

377
00:31:30,000 --> 00:31:37,800
And what do you expect the approach to be to detect falls based on this data? Is it, you

378
00:31:37,800 --> 00:31:43,880
know, is it kind of a supervise, you know, finding a bunch of labeled falls and training

379
00:31:43,880 --> 00:31:49,320
against them? How do you, how do you get to that? Yeah. Well, we will definitely starting

380
00:31:49,320 --> 00:31:55,520
off with the following, making a lot of fake falls in the office, probably to get a grasp

381
00:31:55,520 --> 00:32:01,880
of how does this look like? But, uh, but more seriously, we're following to actually, uh,

382
00:32:01,880 --> 00:32:07,320
go and work with elderly care facility, like facilities that they are taking care of

383
00:32:07,320 --> 00:32:14,040
a lot of, a lot of, uh, like people and patients that leave in those centers and actually

384
00:32:14,040 --> 00:32:19,160
fall is something that's very, very often happens there. And they have already studied a lot

385
00:32:19,160 --> 00:32:24,400
of studies. They're getting a lot of data about falling. How does it happen? When does it

386
00:32:24,400 --> 00:32:29,680
happen? Probabilities around that accident, particular accident, which is very, very common

387
00:32:29,680 --> 00:32:36,240
in the, in the population. Um, and then when we learned enough about the patterns and

388
00:32:36,240 --> 00:32:41,600
the stuff that we are trying to features and all the statistics that we're looking for

389
00:32:41,600 --> 00:32:46,400
to distinguish a fall, we will go more towards when we want to apply this, we definitely

390
00:32:46,400 --> 00:32:53,400
will are going to be applying some anomaly detection, algorithm, some abnormal detection,

391
00:32:53,400 --> 00:33:00,400
which you, yeah, predictive analysis based on the based on the pattern of the, the patients

392
00:33:00,400 --> 00:33:04,960
or the elderly person's movement during the day or during past days, because there's

393
00:33:04,960 --> 00:33:11,000
a lot of like medical studies about that. All of these falls, they don't usually happen,

394
00:33:11,000 --> 00:33:15,600
like, and, and, and announce too much. It's not random. Like, there's a lot of symptoms

395
00:33:15,600 --> 00:33:20,080
that happens before that, which is alerting. And then we're going to be using all of those

396
00:33:20,080 --> 00:33:25,760
information. We're going to get people experts in those areas to help us to actually build

397
00:33:25,760 --> 00:33:30,200
up this model. But the regarding the learning procedure probably is going to, we're going

398
00:33:30,200 --> 00:33:34,560
to start off differently with some sort of revised learning algorithm to build up models.

399
00:33:34,560 --> 00:33:38,840
We're going to definitely use some active learning and other segments of our learning techniques

400
00:33:38,840 --> 00:33:45,040
to improve that based on the symptomatic information we will get from the expert experts

401
00:33:45,040 --> 00:33:52,760
in this area. And, and then, yeah, well, we use the pattern of normal versus, versus abnormal

402
00:33:52,760 --> 00:33:58,320
on this, like, particular random things that happens. Then we'll be off without without

403
00:33:58,320 --> 00:34:04,680
involving user. We'll be able to actually predict that first to, to try to avoid and warn

404
00:34:04,680 --> 00:34:10,840
health care caregivers that the, this particular patient with the pattern that you walk to the

405
00:34:10,840 --> 00:34:14,840
part of the amount of activity level that it has. It's very probable that's going to

406
00:34:14,840 --> 00:34:22,360
have a fall in a couple of few days. Or if, if it happens, we will know and will, will

407
00:34:22,360 --> 00:34:24,480
inform the caregivers.

408
00:34:24,480 --> 00:34:34,040
Interesting. How are you approaching the general issue of privacy in deploying systems like

409
00:34:34,040 --> 00:34:35,040
this?

410
00:34:35,040 --> 00:34:41,840
Yes. It's a very interesting question. And, first of all, well, we anonymize our data.

411
00:34:41,840 --> 00:34:47,800
That's the first step when, when they got right, and I start looking at data, those are

412
00:34:47,800 --> 00:34:55,880
non-names already. So, those are numbers and tokens. So, that's the first step we take.

413
00:34:55,880 --> 00:35:03,920
We anonymize the data. You have to understand that before our processing engines arrive,

414
00:35:03,920 --> 00:35:09,560
all the data that is there, no one can understand that, that data. So, it's, it's, it's, it's

415
00:35:09,560 --> 00:35:18,320
meaningless. It's just raw data, going up to the, to the cloud. Even though it's encrypted,

416
00:35:18,320 --> 00:35:27,040
all the links between our agents and the cloud, the cloud itself, from cloud to agents to

417
00:35:27,040 --> 00:35:33,440
go to a, to a, to a, to all, all, all, all is encrypted. Or in the cloud for us are

418
00:35:33,440 --> 00:35:40,760
tokens, especially anonymized data that, that we work with. It's just only at the end when

419
00:35:40,760 --> 00:35:48,520
we present the results to the user that this data might sense. It's only there when, you

420
00:35:48,520 --> 00:35:55,400
know, that path is encrypted. It's only when you present data to the user when you assemble

421
00:35:55,400 --> 00:36:02,800
again, the entire, the whole, the whole set of information, let's say. Do you or the company

422
00:36:02,800 --> 00:36:10,680
have any philosophical perspective on the issue of privacy as it applies to, you know,

423
00:36:10,680 --> 00:36:16,560
this kind of technology with, with, which I think really brings a level of transparency

424
00:36:16,560 --> 00:36:22,800
to, you know, presence and activity in the home that most people probably aren't used

425
00:36:22,800 --> 00:36:29,880
to. Exactly. And, and you, you just have to look at our applications, right? The type of

426
00:36:29,880 --> 00:36:37,320
data we're going to collect, the only goal is to detect, to be very good at detecting with

427
00:36:37,320 --> 00:36:43,240
really high values of through positive and very low false positive values, try to really

428
00:36:43,240 --> 00:36:49,120
aggregate the, the events that we are, that we are interested for only the, the purpose

429
00:36:49,120 --> 00:36:56,640
of our final, the, our final presentation to the user. As you can see in a security system,

430
00:36:56,640 --> 00:37:02,440
well, we just telling the users, you know, someone is at home. Right. And it's, it's not

431
00:37:02,440 --> 00:37:08,480
normal. This time of the day, since the, the, the history we have from, from you, this

432
00:37:08,480 --> 00:37:14,040
is not normal. For elderly care, it's true. We will be looking at the very fine, rain

433
00:37:14,040 --> 00:37:19,880
activities, but the entire goal, the, the outcome of all of that will be, you know, this

434
00:37:19,880 --> 00:37:29,280
patient had a normal day today. So, everything seems normal. Don't worry. Versus, or something

435
00:37:29,280 --> 00:37:35,960
has happened. This is not a normal day for this patient. Or a fall has happened. So, those

436
00:37:35,960 --> 00:37:41,520
type of, those type of the, of outputs are the ones that we'll be providing. And the

437
00:37:41,520 --> 00:37:46,320
only, we will use the data only to provide very accurate outputs.

438
00:37:46,320 --> 00:37:52,680
Yeah. I mean, it strikes me that, you know, we talk a lot about the, the smart home,

439
00:37:52,680 --> 00:38:00,440
but generally speaking, you know, that really is devices in the home, getting smarter.

440
00:38:00,440 --> 00:38:07,320
But this, you know, offers the possibility of having, you know, the home itself via the,

441
00:38:07,320 --> 00:38:13,680
the wireless network really start to know a lot about what's happening inside of it. And

442
00:38:13,680 --> 00:38:19,840
that could potentially create a lot of opportunities for the devices themselves to then take advantage

443
00:38:19,840 --> 00:38:25,120
of this and, and do more interesting things. So, it's really interesting. And I appreciate

444
00:38:25,120 --> 00:38:30,880
you taking the time to, you know, share with us a little bit about what you're up to.

445
00:38:30,880 --> 00:38:37,240
And thanks to you, it's been a, honestly, with this type of technologies, when actually

446
00:38:37,240 --> 00:38:42,520
we are unlocking the, the IoT market, because at the beginning, there was like a chicken

447
00:38:42,520 --> 00:38:49,960
and egg problem. So, I have to put devices inside my home, but for what purposes? So,

448
00:38:49,960 --> 00:38:54,840
what will be the application? And so, this type of technology are unlocking there, because

449
00:38:54,840 --> 00:39:01,120
you already have the sensing system there. So, let's start using it. That's, that's, that's,

450
00:39:01,120 --> 00:39:07,480
that's our main purpose. Yeah. Now, it's, it's really interesting. In fact, I'm, I'm

451
00:39:07,480 --> 00:39:12,200
so close, I picked it up in my hand. Now, I've got a, I recently started playing around

452
00:39:12,200 --> 00:39:19,920
with home automation and smart home stuff. And I have this little Sylvania, like, presence

453
00:39:19,920 --> 00:39:28,680
detector thing that's hooked up to the Samsung Smart Things Hub. And it generally works.

454
00:39:28,680 --> 00:39:35,320
It's a little flaky. But in order to, you know, really automate the home, you have to put

455
00:39:35,320 --> 00:39:39,600
these things all over. And you're telling me that I already have what I need. I just

456
00:39:39,600 --> 00:39:46,520
need to start collecting some data and train some models. Which, of course, it makes

457
00:39:46,520 --> 00:39:53,280
it sound really easy when you say it like that. But, or wait for, for Ariel to, you know,

458
00:39:53,280 --> 00:39:58,760
show up in my router at some point. Thank you very much. Yeah. And then one more thing

459
00:39:58,760 --> 00:40:03,080
I would like to add is that we have to look at when we talk about the philosophy of company,

460
00:40:03,080 --> 00:40:07,600
you could just look back at alternatives that we have right away for doing the same things

461
00:40:07,600 --> 00:40:12,400
that we're trying to do. So, in order to monitor an elderly person, you would need to

462
00:40:12,400 --> 00:40:17,800
make them wear a variable, which is very annoying for them. And it needs a lot of cooperation

463
00:40:17,800 --> 00:40:23,560
for the person. And the other alternative is what using cameras for security, which

464
00:40:23,560 --> 00:40:30,000
is avoiding the privacy way more than our data would ever could, right? Because camera

465
00:40:30,000 --> 00:40:36,080
data images and videos or microphones that right now has been used for, for security

466
00:40:36,080 --> 00:40:42,880
or for home security and home smart homes, they're wearing more transpired data that anyone

467
00:40:42,880 --> 00:40:47,960
could pick up, look at them and see what's going on in your life. Whereas like, our data

468
00:40:47,960 --> 00:40:52,840
is something that's need a huge amount of processing, which you need to have, like, spend

469
00:40:52,840 --> 00:40:58,000
hours and hours to just make sense about like, semantic that's going on. So you also have

470
00:40:58,000 --> 00:41:03,640
to look at the alternatives that we have these days for for doing exactly the same jobs

471
00:41:03,640 --> 00:41:11,680
or like, as you mentioned, also heavily putting a lot of sensors and actually, and putting

472
00:41:11,680 --> 00:41:17,040
a lot of systems, a lot of sensors and a lot of hardwares in your house, we're just replacing

473
00:41:17,040 --> 00:41:24,240
all of them with something that already exists at your place. And that is a bigger help,

474
00:41:24,240 --> 00:41:29,560
I think, we're trying to do. Yeah, I think that's a really, really good

475
00:41:29,560 --> 00:41:36,440
point. I've talked about on the podcast, I think in the context of maybe the same kind

476
00:41:36,440 --> 00:41:45,160
of thing, presence and possibly home automation, this idea that actually for many applications,

477
00:41:45,160 --> 00:41:52,560
the cameras becoming the universal sensor, and certainly you can do this stuff with multiple

478
00:41:52,560 --> 00:41:57,680
cameras at least, depending on the number of entrances and exits and rooms you have

479
00:41:57,680 --> 00:42:03,080
in your house and all that kind of stuff. But, you know, it's much more invasive, I think,

480
00:42:03,080 --> 00:42:15,000
as you're suggesting. And it's much more susceptible to being misused or abused because

481
00:42:15,000 --> 00:42:24,080
the raw data itself, you know, is easily interpretable as opposed to RSSI values and channel

482
00:42:24,080 --> 00:42:29,160
noise and stuff like that, that, you know, you have to run it through some pretty sophisticated

483
00:42:29,160 --> 00:42:34,960
algorithms to make sense of. So I definitely get that and it makes a lot of sense. And I'm

484
00:42:34,960 --> 00:42:41,000
looking forward to kind of keeping an eye on Ariel and, you know, what you guys are up

485
00:42:41,000 --> 00:42:42,000
to.

486
00:42:42,000 --> 00:42:46,840
Yes, we would love to keep you posted, keep you posted with the progress of the company

487
00:42:46,840 --> 00:42:53,040
and the lines of the different lines of products that we will be launching.

488
00:42:53,040 --> 00:42:57,840
Awesome. Well, thank you. Thank you very much for having us and giving the opportunity.

489
00:42:57,840 --> 00:42:58,840
Thanks.

490
00:42:58,840 --> 00:43:01,080
Thank you, Sam. Thank you very much.

491
00:43:01,080 --> 00:43:08,880
All right, everyone. That's our show for today. Thanks so much for listening and for your

492
00:43:08,880 --> 00:43:15,880
continued feedback and support. Remember, for your chance to win in our AI at home giveaway,

493
00:43:15,880 --> 00:43:23,000
head on over to twimmolai.com slash my AI contest for complete details. For more information

494
00:43:23,000 --> 00:43:28,440
on Michelle, Negar, Ariel or any of the topics covered in this episode, head on over to

495
00:43:28,440 --> 00:43:35,040
twimmolai.com slash talk slash 107. Thanks once again to Intel AI for their sponsorship

496
00:43:35,040 --> 00:43:40,240
of this series. To learn more about their partnership with Ferrari North America Challenge and the

497
00:43:40,240 --> 00:43:45,080
other things they've been up to, visit ai.intel.com.

498
00:43:45,080 --> 00:43:50,160
Of course, we'd be delighted to hear from you, either via a comment on the show notes page

499
00:43:50,160 --> 00:43:56,960
or via Twitter directly to me at at Sam Charrington or to the show at at twimmolai. Thanks once

500
00:43:56,960 --> 00:44:22,440
again for listening and catch you next time.

