Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting
people doing interesting things in machine learning and artificial intelligence.
I'm your host Sam Charrington.
The show you're about to hear is part of a series recorded at the Georgian Partners
Portfolio Conference last week in Toronto.
My guess for this interview is Kenneth Conroy, VP of Data Science at VancouverBased
Fin.AI, a company building a chatbot system for banks.
Kenneth and I spoke about how Fin.AI built its core conversational platform.
We spoke in depth about the requirements and challenges of conversational applications
and how and why they transitioned off of a commercial chatbot platform, in their case,
API.AI, and built their own custom platform based on deep learning, word-to-vec, and other
natural language understanding technologies.
Georgian Partners is a venture capital firm whose investment thesis is that certain tech
trends change every aspect of a software business over time, including business goals, product
plans, people in skills, technology platforms, pricing and packaging.
Georgian invests in those companies best positioned to take advantage of these trends and then works
closely with those companies to develop and execute the strategies necessary to make
it happen.
Applied AI is one of the trends they're investing in as our conversational business and security
first.
Georgian sponsored this series and we thank them for their support.
To learn more about Georgian, visit twimmolai.com slash Georgian, where you'll also be able to
download white papers on their principles of applied AI and conversational business.
Before we jump in, if you're in New York City on October 30th and 31st, we hope you'll
join us at the NYU Future Labs AI Summit and Happy Hour.
As you may remember, we attended the inaugural summit back in April.
The fall event features more great speakers, including Karina Cortez, head of research at
Google New York, David Venturelli, science operations manager at NASA Ames Quantum
AI Lab, and Dennis Mortensen, CEO and founder of startup x.ai.
For the event homepage, visit AISummit2017.futurelabs.nyc, and for 25% off tickets, use the
code twimmol25.
For details on the Happy Hour, visit our events page at twimmolai.com slash events.
And now on to the show.
All right, everyone.
I am here at the Georgian Partners Portfolio Conference in Toronto, Canada, where I'll
be doing a few interviews, and I am excited to be here with Kenneth Conroy.
Kenneth is the VP of Data Science at fin.ai.
Kenneth, welcome to this week in Machine Learning and AI.
Thanks for having me.
Awesome.
And so you're in from Vancouver.
Yeah.
So stand from Vancouver from last night, so still filling out a bit, but happy to be here.
Hi.
Why don't we get started by having you tell us a little bit about your background and
how you got involved in data science and machine learning?
Sure.
Well, I'm from Ireland, and I did my PhD in Dublin City University in the area of heterogeneous
sensor data.
So I was in a research lab called the Clarity Center for Sensor Web Technologies.
And I was involved with coming up with a way of aggregating sensor content from multiple
different devices that were not in any way connected.
And doing that, I ended up coming up with machine learning strategies for close string
and have one of the supervised learnings for finding out things that researchers wanted
to detect.
The researchers in this case would be domain experts in sports science.
And from there, when I finished my PhD, I continued working in the same university, but for
the inside center for data analytics.
And that's where I moved way into the NLP machine learning, sends with analysis, projects.
It was a commercialization wing of the university essentially.
And I ended up moving to Vancouver maybe three years ago, now I'm at FinAI and leading the
data science team as we create conversational assistance for banks.
Nice.
Is there a lot of machine learning and AI activity in Ireland?
Yes.
This is a very big hub actually in Dublin.
OK.
I'm hoping that we set up a Dublin branch for our Amia headquarters in the future.
I know a lot of people in the field and the universities very qualified people there.
So yeah, it's a bit of a hope right now for machine learning.
Nice.
So tell us a little bit more about what Fin is up to.
So we're creating conversational assistance for banks, so think of a Siri for your bank.
We provide things like day to day banking, your basic banking needs, like checking your
balance online or paying bills or transferring money from friends to friends, as well as
more kind of day to day kind of Q&A type stuff you would ask a bank, what your fees are
for your credit cards, product information, stuff like that.
We integrate with the bank's APIs for security, logging in, if we have any interactions
with your bank accounts.
And essentially, yeah, we're just kind of expanding our product base beyond the initial
NLU side of things for detecting intents.
So having recommendation engines in the future as well as credit score coach, moving
more into voice platforms.
So right now we're NLP based text interface mostly.
We have experimented with some voice interfaces, but our primary platform is Facebook for
which we launched a production bot for ATB financial as of yesterday, so we're in production
as of yesterday.
Nice.
Nice.
So you're here at the conference as a portfolio company of George and Partners, but
you're also speaking at the conference later on today.
What's the topic of your talk?
The talk topic title went through some iterations.
So I think it's a how we built a virtual banking assistant or virtual financial assistant
for banks.
Okay.
So it sounds like that's the story, the fin story.
Essentially, yeah.
So one of our co-founders, Natalie Cartwright, she'll be introducing the talk and giving
a lot of the business insight into why we went down the path we went down and then I'll
talk more to the data sign side of things and how the technical challenges arose along
the way and how we make the decisions we made and how we're kind of continually improving
on that process.
Okay.
Well, let's dig into that.
What were some of the major goals and challenges on the data sign side?
So I think we kind of reduced the problem to its core issue, which was how do you design
a taxonomy of intense for which you want to get answers?
It's a bit of a complex task because you've got to, for us, we were a closed domain.
We wanted to stay a closed domain and stay in retrieval-based systems.
So it was banking only and the responses are pre-written, no generative responses at
all.
Okay.
So when we have that as our canvas and we want to create a taxonomy to kind of drill
down into individual branches of what the conversational tree might be, there were a lot
of challenges involved in that, where you draw the boundaries between things.
At what stage or at what extent do you want to make it conversational with one-to-one responses?
So the bulk of our functionality in terms of intense would be one level.
You would say question and you get an answer.
But some of them will have flows.
So if you want to make a bill payment, you can say something like, I want to pay my BC
hydro bill $50 and it will pre-fill those things using the entity recognition and ask you
to confirm.
Or if you don't give enough details, we'll ask you for more input and that kind of two
and throw conversational side of things comes into it.
So in that case, it's almost like walking through a wizard in a traditional, you always
got a set of questions that represent information that's needed to fulfill the transaction
and you just go one to the next to the next.
Exactly.
And based on conversations we have with customer service agents, so a lot of our functionality
is to kind of help the CSAs answer questions in doing that.
And we got a list of questions that they get on a daily basis and we could waste them
based on how frequent they came in and from that was kind of like the seed of how we
would build this taxonomy that wants one communication with banks.
And as we speak to more and more people in different banks, we're seeing the commonality
between the banks is very strong.
There's maybe 85, 90% commonality in what they want, what they want to achieve.
So that's the good side about having this taxonomy in place.
You can bootstrap a bot fairly quickly and get it up to a reasonable level of performance
very quickly.
It's then when you want to build out those more kind of fully featured functions and those
conversational side of things.
That's when the complexities come into it and where really kind of future is for the business.
A bunch of questions.
I guess one question is not necessarily related to the data science side of things, but
are you integrating one-to-one with the banks or are you using some kind of intermediary
like a yodulee or something like that?
I think so.
I don't know too much about the what goes on behind the scenes and the engineering side
of things.
So the engineering team will do a lot of the interactions with the banks themselves.
A lot of our bots are completely done by us, hosted by us and accessible by anybody because
they're not personally, no personally identifiable information in there.
So for banks that require API integrations with the banks themselves, we provide an
interface for the banks to give the security credential requirements and login functionality.
So all that stuff is done by them.
We do not take the responsibility of authenticating the users and that's up to the banks to
do if they want to have integrations with their systems.
What does it mean to have a banking bot that doesn't deal with any personally identifiable
information?
You're saying that you're just passing requests to the bank and they're answering them or
are you talking about bots that just don't deal with account information that are like
telling you where to find branches and ATMs and that kind of thing?
Yeah, so some of our functionality will be finding ATMs or just basic questions about
the products and services they offer.
And that stuff is not confidential in any way.
It's open information that may exist on an FAQ in a different format on their site.
So it's still a conversational way of talking to your bank or a bank doesn't necessarily
have to be your bank if you're not authenticated with it.
But yeah, that's what I mean.
Okay.
What percentage of the banks you're working with are taking this approach where it's just
that surface level interaction versus account level detail?
Typically, when we do POCs, so for banks, the first version will not have banking integrations.
Banks move a lot slower than startups, for instance.
So if they want to integrate their systems with us, we have to have a lot of trust between
us.
So we've had a relationship with ATB financial for over a year now and based on that level
of trust and that level of working collaboratively together, we've been able to create a production
bot that uses all of that API integration.
Okay.
Yeah, building up that trust and building up that system for them and allowing them to test
it and kind of iterate on it before it goes to production is kind of key.
Okay.
So we started talking about the data science side of things in terms of identifying the
intents.
In what way can you characterize the breadth of the intents or the interactions that you
have for a typical customer?
How many of these intents are there in a realm like banking?
So this question comes up a lot.
What is an intent?
So we use a lot of entity recognition to reduce the amount of intents.
We do not want a lot of intents in our system.
We want to break down the problem into kind of smaller subsets, more consumable subsets.
So the amount of intents is actually quite low compared to what you would think based
the amount of responses we can give, we give thousands of responses.
But there might only be a few hundred intents and it depends on the agent to functionality
that we have.
It depends on how many kind of FAQ type questions they want in there and what subset of
all functionality that we can offer they want to make use of.
So yeah, the amount of intents is kind of a wishy-washy number.
The amount of responses is a solid number that we can give per agent basis.
But the amount of potential intents is kind of set at a certain value for our core basic
banking needs.
So the taxonomy tree has an empty list of responses.
So anywhere you could put a response in any of those leaves, that's another response.
And that's what the banks decide what they want to support.
And the banks come to us with their call logs information, analytics on what the subject
matter is for their chat logs, for instance.
And then they can see the subset of the taxonomy that would best meet their needs.
What level of abstraction is an intent?
Is it something like, you know, I want to ask a question about an FAQ or is it like
individual questions, you know, does it map more closely to individual FAQ questions
or responses?
So it depends.
Things like if you want to find an ATM would have like a find ATM intent, it's fairly
well defined.
If you want to find out your fees for your master card, for instance, the intent might
be fees.
Okay.
The anti-recognition would find what the master card is or means and provide a different
response based on master card rather than visa.
Okay.
Maybe we break it down into smaller bite size chunks.
Okay.
Interesting.
So you've got this tree structure, you've got these entities, well, I guess a kind of basic
question.
Are you using any of the commercial platforms to do any of this stuff like the API data
AI is of the world and others?
Not anymore.
So we did.
Interesting.
Initially we used API AI way back when.
So they're great for what they're built to do.
They allow you to create bots fairly quickly, not much data involved, accuracy isn't too
bad, fairly customizable, but they weren't the way that we could continue.
They were too limited in terms of what we wanted to achieve.
We had no idea what was in their model, for instance.
We had no secondary match for what their primary intent match would be.
You said no idea what was in their model, meaning, you know, they identified intents using
NLP, whatever, but it was all a black box to you.
They just gave you an API and told you, hey, bot user initiated this intent and we found
these entities and figured out, but you couldn't tweak or tune that at all.
Exactly, yeah.
There was limitations on where we could go with it.
Okay.
If you wanted to have multi-layer models, for instance, or focus on or upweight specific
types of intents, the functionality was wasn't there to be in a scalable enterprise
product within our domain, and because we were in our domain, we wanted to have a system
where we could reuse as much of what we were providing for each bank across banks.
API is quite complex when it comes to sharing data for one agent to another, and you need
individual agents for that.
Okay.
There's also a limitation on the amount of data you can upload to it, and the rate limitation
on how often you can request, model matches and so on.
So they're the reason why we moved away, and that was the move to our production system
was 100%.
It's our own now.
Okay.
You mentioned in there, multi-layer models, what would that entail, or what does that represent?
So in place of our entity recognition, we are building up data sets to find how the
user kind of goes down a certain tree.
Okay.
Right now, we're using a deregnation to do that, but we could use a model to do that.
It's like a subset of all available intents, but narrowed down to those individual entities.
Once the data set is a bit more richer and a bit more well defined and developed and
we have more user data, we can use that as an additional layer in the model.
So there'd be the existing model, which is the top layer intent match, and then within
each conversational flow, there are kind of submodels that have all available actions
there as well as a few escape actions.
So rather than having to cancel out of that flow to query something else, you get a focused
way of finding what the user's next input is.
I'm still trying to wrap my head around what the idea of multi-layer, meaning you've
got your entities that you're kind of extracting out traditionally, but then you're applying
other probabilistic models to try to identify where the entities are, is that the idea of
a multi-layer?
The multi-layer model isn't in production, but this is a replacement for part of that
entity recognition modules.
So given enough data and enough information on what the synonyms and ABSs are for different
entities in our system, we can further define and automate that process rather than using
the existing one, because you got to update things like synonyms over time, and you might
miss certain things.
You might not always find MasterCard if it's miss belts, for instance.
But that said, both that approach and the existing approach, if you miss Bell MasterCard,
because we're using the intent level at a higher level, we're still finding what the
intent of the user is, which is safe ease, and we can just guide the user via UX to the
specific response they're actually looking for.
And as part of that shift to the multi-layer, is there kind of an underlying shift in
an approach from something analogous to NLTK on Python to something that's more like
a homegrown deep learning entity recognizer?
Yeah, so we have two tracks for right now.
We have our production track, which is kind of a SPARK Python pipeline, using word embeddings
and using word-to-vec for other algorithms like that.
And then we have our research or in deep learning track.
In that track, we're working on deep learning stuff.
We're working on MXNet and TensorFlow in parallel.
We're experimenting on where we're going to get the best accuracy over time and where
this can fit into our multi-layer approach.
And why MXNet and TensorFlow?
So TensorFlow is very popular, and MXNet is very good.
So we are...
Now, I've heard MXNet is very fast.
I don't know that I've heard very good, necessarily, not that it's not, but...
I can't speak with too much confidence on the subject.
Maybe define good.
I can't.
Okay.
Got it.
Interesting.
Yeah, I mean, there are tons of lots of framework choices out there.
There are a lot there.
Yeah, it's kind of early days for our deep learning path.
But the goal was to get this into production in a usable state and have our stakeholders
happy with the performance of it, which is there, which is great.
But this is the exciting kind of future side.
It's getting everyone on the team very excited.
Looking on the deep learning side of things.
Nice.
Nice.
Are you able to characterize, in some way, the benefit that you, you know, besides from
kind of the flexibility and visibility, agility, all that,ility kind of things?
Like in going from api.ai, where you didn't kind of control the model to, you know, that
first pipeline that you just mentioned where you're using Word2vec and stuff like that.
Are there quantitative, was there specific quantitative advantages that you saw?
Yeah.
So when we're evaluating, we couldn't evaluate api.ai in the same way that we didn't have
the ability to see, exploit the training test data on their side and find out what the
cross validation score would be for instance.
We can do that.
An objective, the evaluate our own models against our own models, which is great.
But we do analyze logs and we take a snapshot of everything that's gone through our system
as it exists in api.ai and then put it into our new model as well and then compare the
results of that in real world terms.
We take a snapshot of a week's worth of data that goes into an agent, see how accurate
it is based on that.
That's what the banks are interested to see to, they're interested to see the real world
accuracy of something without kind of adjusting for duplication in the data or however
cross-fold validation kind of, it's hard for them to visualize how that's working.
So real world, they need to see what those values are.
So in doing that, we can see that our models are outperforming what was existing for api.ai.
Okay.
So we started down the path of challenges.
Are there other things that come to mind in terms of challenges that you've come across?
I guess.
We haven't seen it too much, but it can happen and we're quite wary of it and we're kind
of getting ahead of the curve by cautioning against it is intent drift.
So when the banks themselves have the ability to map odorances to intense, we are at risk
of having our taxonomy start to diverge based on how they write the response and how they
think that should be the answer for that specific intent.
If you've got a bunch of data in there that's labeled for an intent and all those pieces
are answered by that response and then part of that response gets taken away then doesn't
make sense for those things that were in there initially to still map to the same place.
And it'll look like it's doing the right thing, but the response isn't given to the user.
So to kind of counteract that we are building tools for the banks to be able to do this
themselves.
So the CSAs with our human and loop infrastructure will be able to correct errors made and
map things to the correct intent and then feed that back into our system.
And we also have methods of coming up with approximations about those things that are
kind of prompting the user to pick from some subset of those things.
But we want to have a two or three level deep kind of verification on anything they map
to make sure that is appropriate response to what the user's odorance was.
So can you give me an example of where they might change something that disrupts that
relationship?
Sure.
We have things like tell me about you and who are you and sometimes the response to that
gives us the same thing, but they're separate intents.
Tell me about you and who are you.
So tell me about you and be like, what can you do?
Okay.
Whereas who are you is just an introduction to the bot itself.
But sometimes who are you means who are you, the bank, right?
So how, what training that goes in for that is important depending on the context of
what that response is.
And so you mentioned that the CSAs, it sounds like to some extent the customer service teams
at the bank have some role in kind of defining out the hierarchy and the responses.
Is that correct or are you doing this all as a service for them?
So earlier collaborations, very heavily involved with meeting with the bank's CSAs, talking
through their issues, how their data forms, their opinions on what should be in there
or whatnot, but we do have a base taxonomy based on those consultations with multiple
banks at that point.
Okay.
And we can see about 85, 90% of commonality across all the banks.
Okay.
So that's kind of our core taxonomy.
And if if banks want to extend beyond that, they just know that they'll have, we'll
have fewer data entries for those things, fewer utterances to train, it would be a little
less accurate at first.
But if it makes sense, we can build that in as part of our core offering.
In other cases, it might be locale based or it might just be for that one bank.
Okay.
And in those cases, they're just one-offs kind of customizations.
Okay.
And so this case where you get kind of drift in the intent, is that because of changes
that the customer service people are able to make in the underlying system or is it the
training data that they feed to you, that you are putting through your pipeline?
So the customer, which is the bank, has the ability to change the responses, if they want
to change the responses.
We kind of monitor that to make sure it doesn't go too far away from the meaning of what
that intent is.
Okay.
But they're also able to use our systems to manually answer questions.
So if a query comes in and we do not have the high enough confidence to give the answer,
it gets handed off to our human and the loop system.
Okay.
And then at that point, they can answer the question and then recommend an intent or utterance
to map to that.
For time as well, they can also monitor their own logs.
And if they have people who are qualified to do so, you can educate them to do so.
They can mark those logs for us, for themselves, and then that can be fed back into their model.
So this happens a lot in pre-production when we have user acceptance testing with our
banks.
They kind of pre-train the bot by interacting with it time and time again.
Typically, we annotate that, but we want to hand over some of that to the banks to give
them an insight into the type of things that are being asked and how we best answer those
questions.
Okay.
And so is there a, you know, it sounds like the intent drift challenges, you know, almost
like a, you know, skill slash cultural slash focus kind of thing?
How much of that is addressed by, you know, educating the customer service folks, you
know, versus a technology solution?
It's a bit of both, and it's not just the customer service folks, too.
It's anybody in the organization.
Okay.
They might say they want a thousand questions answered, but that isn't one thousand distinct
intents in any way, or even sometimes they're exact same intent and the exact same subset
of intents.
Okay.
So I think part of it is to frame the problem differently.
People still kind of tend to think of things like FAQs in a chat box if it's an FAQ
in a web page, but those type of questions don't get asked in the same way as they would
be listed on a web page.
You got to structure things differently.
It's not conversational.
It's not intuitive.
And the user doesn't just doesn't do it.
So part of it is managing the expectations from the start, training the users, the customer
is on how we best organize this information and why we do that, as well as because we
have to got the taxonomy that's kind of shared across banks, we can reuse the data across
banks.
And that's mutually beneficial for everyone involved because that means the accuracy of
all of those intents improve as data from each of those banks come in.
Interesting.
In your presentation, will you be outlining, do you have any kind of prescriptive, you
know, if you're looking at doing chatbots or maybe even ML or AI generally like to, you
know, things one through end?
Kind of, yeah.
It's obviously heavily weighted in the way we actually did it and how we tried it and
how it didn't work and then how we did it and seemed to be working pretty well.
So yeah, I'll talk about exactly how we did it as well as how we're best seeing rolling
this out works to customers.
So seeing this in the real world, seeing how customers interact with it and help you
get to where you need to go and where themselves need to go, it's really cool to see.
So what are your top three, you know, make sure you do this or don't make this mistake,
kind of advice to startups that are trying to get systems like this up and running.
Don't rush into it.
So make sure the taxonomy is well defined.
You will spend a lot of time researching this at the start.
The two is you got to get some good data in there.
We looked at lots of sources of information including previous chat logs or transcripts
from calls.
They're not great, even as C did it, they're not very good and they're often unstructured
and difficult to even annotate in any way.
We found for the cold star problem, crowdsourcing is key.
Getting a list of different ways of saying different things can get you very far, very
quickly.
And then, did you crowdsource among the customer service agents that customers are like
Amazon Turk or something like that?
Yeah, both.
Okay.
So interesting.
For kind of things that customers weren't helping build, maybe their features for our
core platform that have not been released yet.
And then often customers would have their own ideas and they would submit those ideas.
We would build on those by submitting mechanical jobs to get more data.
Okay.
I guess then the third thing would be to consider where you draw the line between intense
and entities, how you reduce the problem space and increase the accuracy by customizing
to a certain extent to the domain you're working in.
So get that taxonomy up and running, get that dictionary of terms for banking up and
running if you're in banking.
Obviously, I don't like to do a banking buff.
But you said a bunch of stuff in there.
So the first thing was the line between the entities and the intents.
And we haven't talked about that yet.
Is there like a trade-off dial in there somewhere that you have to kind of find the
right place?
It's not a straightforward task to find out where to do that or what the top intent should
be.
Like, do you focus on a product and then have a bunch of sub entities that have from features
of that product or you talk about the features and products that correspond to that feature
or things like fees, whatever.
So the way you segment that stuff, you've got to be able to kind of keep track of what
you've done as well.
And if you ever want to go back again and change things, you don't want to be doing that
when you've got a few million data entries in there to an entity.
It's just going to be an impossible task.
So that's an issue with a lot of the kind of first-time bot builder.
You just build a bot in it works and you're like, okay, cool, it works.
Then you want to add another 10 or 20 questions.
Then you get a lot of conflicts because there's lots of similarity between those questions
and existing questions.
And that's the downside to doing that approach and the upside to having a vertical and a
well-defined taxonomy to take into account everything that could be asked in that vertical.
And is there a right or a wrong way to approach building out that taxonomy in terms of this
line between the intents and the entities or is it more, you just have to do something
and stick to it and be absolutely consistent as you expand out your vocabulary?
Yeah, I mean, there's no right answer to this.
It's a very difficult problem to solve.
It's not that you can't change it afterwards, but you want to change it a little bit.
You want to tweak it.
You might split some intents or combine other intents.
But you don't want to completely rebuild the system every few weeks or months.
Sure.
It's a bit of both.
But there was another question that I wanted to ask that's maybe going a little bit back
to, you know, so you kind of, you scrapped API.ai and built your own system for doing
this.
And you said it was, you said it was spark and Python.
Did you also invest in building like, you know, almost like a user interface or kind
of a higher level platform tools for both your internal people and the banks or your, you
know, how sophisticated it does that layer need to be in order to have a usable system?
Yeah, it's a very complex system.
And it's, I guess, 70% built right now.
Okay.
And mostly the internal functionality.
We don't have the external bank facing side of things for running it.
Okay.
But it's essentially our interface to our database.
Where we define what intents belong to each customer, what the taxonomy is for that, for
instance, what entities are in there, where they apply, what the response content is, and
the ability to map from utterance to those intents and support the user in making those
decisions too.
So to make sure that you got the context is what that intent means.
If there are a few hundred intents, it might be difficult to know exactly what an utterance
should go into if you're not, you know, fluent in the system.
So we have some supporting information, metadata associated with that, or examples that
already exist to help you make that decision.
So yeah, that's called the Atlas project.
That's kind of our, I guess, the heart behind everything.
Hmm.
Interesting.
Interesting.
And then in terms of, we were speaking upstairs earlier, and you mentioned that you, as
part of, you know, getting to this initial production customer, you kind of replatformed
everything.
How did you have things deployed before and how are they deployed now?
So before we had APII for doing a lot of our functionality for entity recognition, for
instance, as well as the model itself, but now we have that entirely ours.
It's a rebuild.
Okay.
Yeah, I guess I was wondering in terms of, I guess, now that you've kind of built your own
platform for a place, APII.AI, what processes and automation have you built up around deploying
models up into production?
Yeah.
The offline stuff, so the training of the model, we don't have kind of well-defined release
processes for that side of things.
But any model we build and we release, we have a strict release process that's done
with engineering and DevOps, and we ensure that we have a record of what models deployed
in which environment, what was trained on, what the results of evaluation were over time,
and it's controlled.
We don't just release models whenever we feel like it.
We also have test suites that we must run through before we ever release anything to
production to make sure we've not broken anything.
If any intent has reduced in accuracy in the effects, something else down the line in
terms of maybe a flow, a conversational flow, or some keyword isn't working at some point
in the flow, we've got to make sure that's caught and not deployed.
Though I think we're maturing as a company, and that we're a lot more strict on our deployment
environments and how we're actually doing things, but yeah, everything is hosted up on the
cloud and got a serialized model to produce the intent recognition side of things.
Yeah, it's working pretty well.
You mentioned that you're also able to catch when intense change meaning and things like
that, and testing, but are you also able to, do you have machinery in place that is able
to identify, I guess I'm thinking of it like kind of the long tail of intense or entities
that aren't being caught by the system, like how automated does that need to be?
Is that something where you're running a weekly or monthly report and just look at what
isn't being caught correctly or is there an automated process in place that is always
up to date and you're always trying to catch up to build out that long tail?
Yeah, I think to some extent some of the long tail, we're never going to go down to.
It's a long tail.
It's a long tail, for sure.
When we do have the human and loop functionality, it works really well for our use case.
When it comes to finding the things that we probably should support, oftentimes we will
have that ability to run it through our actual model, our kind of model trained on everything
that we have, rather than the model of things that we support for that agent.
Then we can find out if there are things that we're accurately catching, but they just
don't have a response for.
So it looks like we just don't support it, that catches some of those things.
We can also use unsupervised kind of clustering to find groups of things or questions that
converge around a new topic or a new kind of question type that we may want to suggest
as a customer to include or for us to include in our taxonomy if it does not already.
We do also do manual log analysis.
For the time being, we're keeping an eye on the data.
A lot of the data is, especially now we've got a production data coming in, it's interesting
to see.
Just hand, help you make decisions on how we further the product from a customer point
of view.
Interesting.
Interesting.
It sounds like you guys are doing some really interesting things, and in particular it's
interesting to hear some of the background behind kind of the platform shift and what
that's enabled you to do, so thanks so much for sharing that and I'm looking forward to
catching your talk.
Awesome.
It's a pleasure.
Awesome.
All right everyone, that's our show for today.
Thanks so much for listening and for your continued feedback and support.
For more information on Kenneth or any of the topics covered in this episode, head on
over to twimlai.com slash talk slash 61.
To follow along with the Georgian partner series, visit twimlai.com slash gppc 2017.
Of course, you can send along feedback or questions via Twitter, at twimlai, or at Sam
Charrington, or leave a comment on the show notes page.
Thanks once again to Georgian partners for their sponsorship of the show.
Be sure to check out their white papers, which you can find by visiting twimlai.com slash
Georgian.
Thanks again for listening and catch you next time.
