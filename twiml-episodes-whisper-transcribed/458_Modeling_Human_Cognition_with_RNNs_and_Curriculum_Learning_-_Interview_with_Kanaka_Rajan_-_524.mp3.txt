All right, everyone. I am here with Kanaka Rajan. Kanaka is an assistant professor at the
Icon School of Medicine at Mount Sinai. Kanaka, welcome to the Twimal AI podcast.
Thank you so much for having me. I'm really looking forward to jumping into our conversation. We'll
be talking about your work in the field of computational neuroscience. But to get us started,
I'd love to have you share a little bit about your background and how you've come to bridge
the worlds of biology and artificial intelligence. Thank you. I sort of took a circuitous route
to getting into neuroscience and specifically computational neuroscience. I was trained in
engineering and physics. And then, you know, I sort of collected fields along the way.
I thought I was going to be an experimental neuroscientist when I first got to graduate school.
And then I was very quickly dissuaded of that particular delusion of mine. And I thought,
okay, I should stick to at least the tools that I have acquired in my various
dabblings across fields. And so computational neuroscience seemed like the perfect melding
sphere for such a thing. So, essentially, how I've gotten here.
And what was it about the experimental approach that you didn't find appealing?
So, I do find it incredibly exciting and challenging. So, that wasn't the issue. The issue
resident hands either, right? Once somebody showed me how to do experiments, I could do them.
Yeah. And the reason I know this is because, you know, we do rotations. In graduate school,
you show up and you spend eight weeks or 10 weeks in somebody's lab. So, I did, like,
four experimental rotations at Brandeis University with, you know, world-class experimentalists.
My issue was the complete inability to design experiments. So, you know, I would show up
the next day and it would still be completely blank slate. I'd be like, okay, now tell me what to do.
I didn't have the same sorts of issues with computational stuff. So, you know,
it was really a fork. I did decide should I spend the next 10 years trying to get better at designing
this whole other complicated, incredibly rich field. Or should I just take my tools and attack
a slightly different sliver of the same problem? Nice, nice. Tell us a little bit about your research
writ large. What are the broad questions and issues that interest you?
So, I work exactly at the interface between, you know, AI, artificial intelligence, ML,
and experimental neuroscience. So, the field that I work in straddles both. What I do for
living can be described as building LEGO models of the brain. So, what I want to do is to build,
essentially, you know, a model that, you know, makes like the Death Star and looks like a Death Star,
but it's actually engineered by me as an artificial system. I have built it to mimic something
the biological brain does. My goal is then to reverse engineer this LEGO Death Star and see what
makes it tick. And then, of course, the rest is a little bit of hope and prayer and a little
bit of hard science to say, well, is this the same operating principles that the biological brain
uses. So, I build essentially artificial models that make like the biological brain, but are
much more simplified and engineered. And it sounds like the, you're referring to the brain as a
whole, meaning you're trying to build what I might call like end-to-end models of the brain or
comprehensive models of the brain as opposed to simplified models of particular subsystems within
the brain or the idea. I would say both. So, there are models of the brain that I build which are
more like behavior level models, right? I could take an artificial, you know, I build neural
network models within this class of essentially computational modeling. And I can train these
neural network models to capture a behavior of the whole organism. Like, for example, you know,
if you're standing in front of an elevator bank and, you know, both doors open, which one do you
pick, that kind of decision making, or counting while you're walking, estimating time, learning,
remembering, deciding, those types of behaviors. So, that would be in the category that you just
mentioned of brain rich large, because they're capturing behavior of the whole organism. But within
it, I also build multi-region neural network models, which would capture the interactions between
interconnected brain areas. And so, that is a much more granular, more biologically grounded,
sort of system. And that may or may not capture behavior, but what this model does is capture
the dynamics or the neural activity over time from all of these brain regions. So, we can certainly
build whole brain models at both the behavior and the neural level. And I think I build both kinds of
models and any combination of the two. Got it, got it. One of the things I found fascinating about
your work is particular to this, well, I don't even know if it's limited to behavior or dynamics,
you know, one versus the other, but this idea of looking at cognitive processes that, you know,
may manifest as kind of a split second decision about an elevator and then drilling into how they
play out all kinds of different timescales. Can you elaborate a little bit on that idea and how you
how you dig into that? Sure. So, there's a tension in neuroscience in general, right? When you
want to understand something about the biological brain, there's a tension. The building blocks the
Lego that I just mentioned, the building blocks are much, much faster, right? The neurons are at,
you know, working at millisecond timescales. They're connected with synapses and those dynamics are
at most hundreds of milliseconds. And yet, you know, I have to show a my niece or nephew or
godchild how to solve this elevator problem, which elevator button press and how to go to. But this
kid is going to remember this for the duration of their lifetimes. So, there's essentially a
tension between the timescales of the building blocks and the timescales of behaviors and learning
of behaviors over lifetimes essentially. So, that somehow the biological system bridges seamlessly.
Artificial systems are less good at this, but both feels like AIML and neuroscience are both
kind of geared towards this fundamental tension. And so, one of the things that, you know, my work has
been able to do is to exploit a certain feature of a type of neural network models, which are called
recurrent neural network models, sometimes RNNs for short. And those are characterized by, you know,
connections between active neuron-like units going forwards and backwards. So, they have feed-forward
and feedback connections. This lets them have long-range dynamics. So, what that means is that they
can have ongoing patterns of neural-like activity, essentially in perpetuity. However, I can
engineer this RNN to have model elements that are still fast, like the neural timescale.
So, there's a fundamental feature of these types of models that has a convenient feature.
So, one of the things that me and several people who work on RNNs are working on is to say,
well, can we use this natural feature of this type of neural network model as a substrate?
On which to build this LEGO model that has other functionality? Like, can I get this recurrent
neural network model to solve the elevator problem? But, you know, the brain doesn't just do the
elevator problem, right? Like this kid recognizes, you know, elevators from a picture book, even if it
isn't their real elevator, it can solve escalators and it can, you know, there's a lot of flexibility.
That is a harder problem. So, yes, I can exploit the mathematics of recurrent neural network models
and their ability to produce long-time scales, but I still have to engineer them. So, they have
the flexibility to do many different things all over many, all over long-time scales, using the same
machinery that only biology has access to, which, inconveniently for us, biology is annoying.
You know, in talking about the human side of this equation, one of the things that comes to mind
is memory. And, you know, certainly RNNs have a form of memory, but then you also talk about
kind of dynamics. You know, we think of memory in a lot of ways as kind of the static snapshot of,
you know, either, you know, some rules or a view of the world or something like that. Dynamics
sounds, well, sounds more dynamic, right? It's like the evolving state of the system, and I'm wondering,
you know, can you kind of put some color on that, like the relationship between memory and
dynamically evolving system states? So, that's an outstanding question, and you've really hit the
nail right on the head. So, this is a fundamental thing, like what you're asking about is a fundamental
feature, right? We have to reconcile the ongoing nature of this, you know, neural activity, right?
Even if my eyes are closed, there's patterns of activity swirling in my brain, with the fact
that I still remember the elevator problem from when I was like five years old, but that has to
be the static piece. And that's kind of how people thought memory used to work. So, in fact,
the earlier model, earliest models of memory were, you know, like the hubfield model, all involved
this idea of what are known in my field as fixed points. But that just involves saying, let's say
I want to remember two things, right? What I would do is take a group of neurons over here, elevate
their firing rate to a certain static value, and that's a memory. If I want to remember another
thing, I take another group of neurons over here, I elevate their firing rate to some other number,
and I leave it there. So, that number doesn't change, and for however long it does not change,
I have remembered object A and object B. That's how people used to think memory used to work.
And so, then experiments were designed to test this model. So, they would have animals that were,
you know, making movements based on remembering a number or making decisions and so forth,
in very, because experimental technologies like Way Back When were still, you know, pretty,
um, pretty simple compared to what they're able to do now, and they observed such activity
anyway in the brain. Then came this revolution in neuroscience where people were able to record
electrical activity from the brain while animals were doing much more complicated versions of the
same problem. So, there's a version of this elevator problem where you've taken this kid,
strap them down and only force them to make a choice with their eyeballs, which elevator to get
into, or you have this version of the problem where this child is walking towards the elevator and
making a decision while all this ongoing activity is occurring, all this dynamics of the movement
are occurring, and then, you know, the door opens, there's a pause, and the the kid can get into
the elevator. So, there is dynamics, but the kid hasn't forgotten the elevator problem. How might
this work? So, one of my postdoc papers involved proposing this idea of what if it's not fixed
points? What if it is waves of activity? Or in other words, sequences? So, this is, you know,
individual neurons only fire for a short duration, but if you look at the whole population,
there's like a wave that goes through, where each neuron has a temporarily kind of sparse bump,
but if you tile all of the bumps together, you get the same duration, but now it's essentially
doing what the fixed point used to be doing, but it's a much more robust way that has both features.
It has steady representation during the period for which you want the memory to be represented,
but you also have dynamics because this activity is actually moving. And so, now we're proposing
more advanced versions of this hypothesis, and we're saying, what if it's not even sequences?
In our kinds of tasks, right, like I'm talking to you, but I also remember, I've got to keep an
eye on the time, because how long I've ever ambled about sequences. So, so now I'm thinking,
if you were to record electrical activity in my brain, it's unlikely to be just sequences.
Maybe it's some other high-dimensional repeating pattern. So, we have advanced these types of
theories to incorporate both features, the stability of the memory that you asked about,
along with the ongoing dynamics that is true of biological brains.
So, you proposed as an example, this very simple model of memory, where you're trying to,
your subject is remembering two quantities, and those kind of map one-to-one to firing rates of
neurons. You know, that's compelling from an experimentation perspective, but then you think about,
okay, these abstract concepts like elevators and dog and cat and all these things that we're
amazing at remembering. What do we know about how memory works at that level? Like, it's starting
to come to call to mind, you know, ideas like theory of mind and stuff like that that are
kind of abstract. How close are we to understanding how all that machinery works?
Great question, to which I only have a waffly answer. Not a whole lot.
So, unfortunately, the state of the field, well, and I shouldn't be so super pessimistic about it.
So, let me try that answer. So, we're all trained in the physical sciences to some degree,
and so our instinct is to clear the deck first. So, you present me with the problem like this,
what I, my instinct is to clear the deck and produce the most simple form of this question that I
can handle with some nice mathematical formulation. And that's what, you know, I attempted to do with,
with talking about working memory and so forth. And I think experimentalists have a version of
the exact same issue, right? They do, they take this very complicated animal with all of its
inner richness and theories of mind. And then they essentially kind of strap it down and force it
to make one little movement or another, right? So, there's a version of this that's true of both
sides of the aisle. Right. So, there's that instinct. That instinct has the benefit that I can say
something general now about memory, right? I can talk to you about the same or similar problem being
solved in multiple different nervous systems. So, I can say, well, this is how a larval zebra fish
would do this, how mouse would do this, rat would do this, macaque would do this, humans would do this.
And then I can, as a theorist, I have the privilege to sit back and say, is there something fundamental
that unifies all of these different models that I have built into something that starts to look
like a theory? Is there a conserved or unified theory of memory that is true of nervous system
independent of this details of it? That's the advantage. The disadvantage is I lose all of the
other details that make biology interesting. So, for example, I'm not talking about any kind
of synaptic dynamics, right? I'm not talking about neuro-modulators. I'm not talking about evolution
even, right? The models we build start from this kind of random soupy thing and then are overtrained
to solve this elevator problem to perfection. But that's clearly not how biology works at all.
So, yes, it's got the pros and the cons to it. But I'm saying, like, in order to span all of those
levels, sort of vertical and horizontal integration to produce a satisfactory answer,
we're not even close to those big questions. You mentioned that your research kind of led to this
idea of RNNs as the substrate for building more complex models of memory and I think maybe
more importantly behavior. When I hear substrate, I think of, you know, platform building blocks,
you're combining them in different ways, elaborate on that idea a bit more.
So, when I said, so I find RNNs to be a convenient substrate to capture several different features
of the biological brain or neural circuits that I'm interested in, right? So, one convenient
piece of this is the fact that they have forward going and backward going connections, which are
true of biological brains, independent of species and granularity and so forth. They are also
mathematically simple, which helps me. But then also with reference to the previous question, I have
let go of a lot of details. RNNs have this ongoing dynamics. They can be coarsed and trained to do
many different behaviors. So, there's those conveniences. But I can also expand a single module
into multiple regions, right? I can pretend. So, you know, when you look at, you know,
the complex nervous systems like mammalian nervous systems, mouse and humans and macoxins
so forth. There are anatomical partitions and there are functional partitions of neural circuits
into sometimes brain areas, right? But how those brain areas are defined, you can abstract that idea
into each area as an RNN. You can say I have an RNN that makes like, you know, a region that
senses stress. I have another RNN is a region that says, okay, I've had this much stress and I'm
going to shut down the system now. And those two in conjunction, we'll start to get at questions
in the brain like how do two regions interact, sometimes compete and sometimes cooperate. So,
you've suddenly gone from a circuit level model of one RNN as the brain to multi region RNNs,
which have now gone to a multi circuit level. Now, you train that multi circuit RNN to do a behavior
and pretty soon you've spanned three different levels. You've got the individual circuits,
multi area circuits to the whole organism. Now, expecting this model to also capture details
of the molecular machinery, maybe beyond us at the moment. It's a little bit of a kitchen sink
flavor of modeling, but you know, this is what you can do with them. You can treat the RNN as its
own module and explore its features, or you can treat it as a building block on which to build
other functionality. Like, you can take the RNN and train it to do many different tasks.
You can take the RNN and hook more of them together to build multi region RNNs.
And so, that's the sense in which it's a versatile and convenient substrate.
I got it. And when you talk about training RNNs to do different tasks in this context,
what are some of the types of tasks that you're training these RNNs to do, these networks to do,
and what are, well, what's the training procedure look like? Are you,
what's the data look like? Are you training them into N versus subsystem? Tell us a little bit more
about how you're using the RNNs. So, let me do this question sort of more specifically,
right? So, one of the things that we're working on in the lab is this project called curriculum
learning. And so, this came about because we were frustrated by the limitations of current
training algorithms. And, you know, we didn't invent this machine learning and AI engineers
innovated this amazing concept. It was originally even inspired by psychophysics where, you know,
when you train an experimental animal or watch a child learn by imitation or something,
there's a shaping to this behavior. The behavior is shaped by means of reinforcement.
And that then led to the idea of using curriculum learning, like different syllabi,
where the task you want a system to learn increases in complexity slowly. And so,
you can find that you can train networks to do things better. Now, in the work that I had done
before we came upon this, we used to use standard training algorithms, which didn't resemble biology
and didn't do that well anyway. So, there's two flavors of the types of things.
One, involved training networks to do tasks using something like that propagation.
So, you can, you know, turns out that if you scale up network sizes, you can get these networks
to do a lot of things. However, when tasks get complicated or over long periods of time,
back propagation wasn't doing so hot. So, then we do the other flavor of work where we train
the individual units inside the RNN to match experimental data collected from individual neurons
in the biological system. That target sort of a different problem, but they're both wildly
unrealistic. They don't even smell like something the biological system may have,
may have used to get the animal into the state where it can perform these things.
Meaning, we know that we don't learn on a module by module basis and we learn more holistically.
Right. Exactly. Right. So, we learn by doing a simple version of the task first.
Then we stack on a slightly more complicated thing if the first thing paid off.
If the, if the escalation step in task complexity is kind of, you know, very mini-school,
then you have the option of testing out. So, we thought what we would do is to train RNNs using
curricula. So, you know, my team and I are designing different curricula. So, for example,
one of the tasks, let's go back to our famous elevator problem, right? Our elevator problem has
features of navigation because you have to walk from your apartment or your office to the elevator.
It has, it has indications of working memory because you want, you know, when the doors open,
you want to be able to estimate which side has more people or fewer people. And then you want to
hold that in memory while you make a decision to make a turn and go into the elevator that has,
let's say, few people. So, it's almost like a two alternative choice feeling, but it also has
evidence accumulation. So, what we're trying to do is instead of taking a network and saying,
okay, here's the full blown elevator problem, solve it. What we're doing is training the network,
as though it were a person being trained. So, we can have multiple different curricula, right? One
in which, you know, first both elevators are blank, right? Which elevator bank you choose,
you get a reward. So, that's the first step. The second one is you put one person in the elevator.
Once, let's say the network has mastered this, then you put one person in the elevator.
Then if the, if the, if the network goes to the side that has no people, you give it a reward.
Then you escalate the slowly and slowly and then it starts to get at things like, let's say there
were a thousand people in one elevator and a hundred in the other. Thus, this network really need to
count one through thousand in one elevator and one through hundred in the other.
Brookforce will suggest yes. But what turned, what, what we found is that if you train networks
using a curriculum, not only can it do much more complicated tasks than the network,
than the naive version of the training, it can also do many more of these elevators simultaneously.
So, network starts to intuit something like, feels like. If you're standing in front of the elevator
and one has a thousand people and one has a hundred, you'll kind of feel like the one that has a
hundred is easier to get to. We don't know what feels like looks like in the brain.
But I can tell you because we now can build these networks that have gone through the same
or at least qualitatively similar shaping. So, I can say you've got a record from region X
where the signal should look like this particular signal to indicate what feels like, feels like.
So, these are, you know, this powerful class of models that now be now building
and using for all kinds of biological mechanisms.
Now, when I hear you describe this particular task and how the network approaches it
under this curriculum learning regime, like I think about the, you know, that ultimate task of,
you know, counting or deciding based on the number of people in the elevator, which one to choose
as being, I'm imagining it to be very different from the penultimate step, right? It's not like
that, I'm imagining that that step immediately before was not, you know, about the same problem,
the number of, the number of inhabitants or people in the elevator, which is
suggesting to me that the, you know, the, this feel like is maybe akin to like the, you know,
the deep levels in a, you know, CNN where you're like training structure in some way and that
structure is useful to the ultimate problem solving task. I'm trying to think through and want to
talk through the relationship between that kind of low level structure and, you know, feels and
like how those things connect to one another. So, you've again, like, it's an incredible question
to ask. So, really, you're right, like the penultimate step before this problem is solved is not
999 people and 199. So, really what you're asking is what makes a good curriculum and what makes
a bad curriculum. So, given that I want to teach this, you know, animal that I've just adopted to
get into the elevator unassisted, for example, then what, what would make a good curriculum?
The argument we're making is just by watching two completely trained, let's say dogs,
because you know, dog person, two completely trained dogs getting into the elevator will not be
able to tell you the roots that they took to get there. So, we don't have all of the answers to
this problem, but we know that by testing different curricula all of which end in the dog being
able to solve the elevator problem, we are able to discern how the biological circuitry's inside
structure would have been shaped in this case, fun and tender. But it's the analogy that you set
up with the structure of the weights or the weight space within a CNN passing through a training
protocol is exactly what we're looking at. So, we're looking at, you know, in epoch by epoch or
asked the task complexity increases, what happens to this weight matrix? Are you learning something
that looks, are you solving the navigation problem first, the working memory problem next,
and then the counting problem last? Right. In fact, the structure you see evolving,
or do you see the counting emerging first? Because counting is kind of like a lookup table,
and then, you know, doing the navigation, then doing the working memory piece, and the answer I'm
going to give you is there isn't a one step. The simpler a task is, one might argue that this
counting task is simple compared to the kinds of tasks that humans and macaques can do,
the number of roots by which you can learn, and therefore the number of curricula that can still
approach the final state are big, are many. So, the more complex something is, the smaller the
solution space appears to be. Therefore, if there are multiple curricula or multiple different
learning trajectories that can approach that solution space, then, you know, then they will,
then the solutions will also look kind of similar. So, it kind of depends on the task that you wanted
to solve, the roots that the structure will take to approach it. But without putting networks
through something like this, you wouldn't have the foggiest idea, right? Like if two dogs walked
into a bar and say we can both juggle, our current go-to involves recording from their brains and
looking at squiggles in state space. But you won't be able to tell if the first dog learned and
Boston, the second dog learned in New York and how. They were successful. But by following their
trajectories, learning trajectories, or even mimicking their learning trajectories in
network models, we might be able to make progress. And so in this work are the curricula that you're
presenting these networks with are those explicitly designed by you or are the the curricula
themselves learned? Or, you know, can you look, do you look at like a curricula, like a hyper
parameter, and you're, you know, maybe doing some automated search across them?
Oh, see, that's a very good, so I feel like now I'm going to open my notebook and take notes.
Right now we're limited by sadly my imagination. So we're hand designing this curriculum.
Okay. Because our first goal, so what we discovered when we first did this was, yes, we can tell
those two dogs apart that walked into a bar and can juggle identical. So that was the big win.
Then we said, let's look in literature. We have this vast network of experiments.
And by just to put a point on that, by telling these two dogs apart, what you mean more
concretely is you've built these models, you've trained them using these different curricula to be
successful at the same end task. And you can distinguish between kind of the things that they've
learned. That strategies that they would use, yeah, did one learn by means of reward and the other by
means of imitation. Those would be sort of two different types of learning that these animals can
experience and still get to mastery. Right. Okay. But doing curriculum learning, I'll be able to
distinguish those two because different learning rules will benefit to different degrees to different
curricula. Yeah. So the first observation was this different learning principles will benefit to
different degrees to the choice of the curriculum. So you can use that curriculum learning as a tool
to disambiguate learning principles in the biological brain. So then we went to look in literature
to say, well, have people looked at this type of, you know, have people systematically put their
animals through shaping protocols and can they share these types of data with us? We found that
people rarely system systematically collect curate or publish curriculum learning type data.
Right. Because different labs have different shaping protocols that they put their experimental
animals through. A lot of it is trial and error like the senior post dog designed the shaping
protocol that happened to work for the mouse. So we're all going to do it. There's also tricky
features because as I had mentioned, biology is gnarly. So a lot of the actual shaping involves
just getting the animal to behave while being handled. So there's all these complications that
were not interested in modeling with our models. What we wanted to do with the first paper
is to say, well, we're just going to say curriculum learning as a tool to disambiguate learning
principles. Inspire experiment lists to much more carefully collect curate and then hopefully share
with us details of these experiments, collect, you know, what syllabus worked, what syllabus did
not work. I mean, just because 75% of the animals learned and 25 failed to learn the task you were
trying to get them to learn, the start mean that they've, you know, failed. That means that the
curriculum could have been tweaked in a better way. So that's the first goal. The next goal is
certainly to go in the directions that you have suggested, which is to say, well, can we say something
more general about which types of tasks will respond to which types of curriculum? And then can we
auto engineer those? Can we train networks to follow some kind of low energy path through the
space of possible curriculum? That would be a home run. Yeah, I'm not sure if there's a question
at the end of this, but it strikes me that the way you're approaching the problem starts to
poke at issues of like nature versus nurture and like, how can we capture what nurture really means
and that kind of thing? Is that something that you think about? I do, but not in a terribly coherent
way. Me neither. Yeah, no, you know, this is not really my real house at all. I mean, my knee
jerk has to say, yes, of course, they're both important. Yeah. I think for me personally, the key
is not to take my, my tools and my models so seriously that I conflate them with reality. Yeah.
So, you know, for me, the win is not that I can write the, even though I was trained in that
school of thought, is to write down the most elegant, simple mathematical solution and so forth.
Yes, there's a, there's a little kick to it. The better kick is if I make this prediction about
the juggling dogs and one of my experimental collaborators said, oh, yeah, now this really worked,
or this really didn't work. That's the win. If is, if it is validated or falsified by biological data,
because that's where reality is, is the, is the biological system. Yeah. Now, if I were an engineer
still, or a male practitioner or died in the world, I would be like, well, what is the smallest
network I can build that can do the most things? I'm not. So, I'm interested in with all the
works and wrinkles of biology. How can, how, what in the brain is tracking, you know, which
task is currently happening and when it's time to switch, right? I'm having this conversation
with you. I'm watching the time, you know, you're doing the same thing. And so, we're like,
somebody in the brain is tracking this in the biological brain. And we're not terribly good at
either, right? As you can see from some of my rambly answers, the time keeping and answering
coherently. So, with all these wrinkles, I want to understand the functioning of the biological brain.
I am aware that the tools aren't perfect. They weren't evolved. And this gets to your question.
They didn't go through a process of evolution. They're missing a whole lot of biological
details. So, you know, the, I call them units. I don't even call them neurons within the network.
And so, I think it's another one of those questions where we have to say, well, can I tackle a
sliver of this problem? And a sliver of that problem is now we're able to train these networks
over very long periods of time. As I explained with the curriculum learning, it takes weeks to train
an experimental animal to do one of these tasks that they do in the lab. So, can I play that game
further over a developmental trajectory? I don't have terribly clever ideas for that because
the hardware and the software are changing constantly in such a problem, but it's one that I'm excited
to dive into in the next phase of my career. Yeah, yeah. I particularly appreciate the,
you calling out the distinction between developing a tool that may have some predictive value,
you know, versus kind of getting caught up in, you know, your tool and taking it to be
representative of the actual thing itself, you know, you mentioned closed form kind of equations
around this, you know, simplified model that you make. I find it, you know, in conversations
around the biology in particular, I often, like, I want to go there. It's like, I need to like,
really reign myself in and make the distinction between the model and the thing being modeled.
Yeah, no, I appreciate you saying that you put it extremely eloquently. I think anyone that's
trained in the physical sciences has that tension. Because you want to write me, you want to write
down the formula and be done with it. But I think to understand, I mean, I remember this,
like feeling of shock as I walked into an experiment lab as a postdoc, as a legitimate
theorist, right? And I go, oh my god, nothing is as I thought it would be at all. I mean,
what even is going on? Yeah. And you realize, okay, you're in a whole other game now, biology is
not. It's going to, it, I, my prediction is we're not going to have anything that looks like a
grand unified theory of name of brain function. I think we're going to have a pile of models
and then a holistic understanding will emerge from such a thing. That's so disappointing. I've
spoken and written about how I'm a sucker for grand unified theories. I want to kind of go back
to a point that you made earlier. The relationship or distinction between,
I, there's a lot of ways we could come at it. But, you know, training these kind of complex
hierarchical systems of RNNs module, you know, modular, module by module or unit by unit versus
kind of end to end. And I asked about that unit by unit versus end to end or in isolation versus
end to end. And you responded with, you train them in curricula. But I don't, to me, those don't
come as like orthogonal things. You could train, you could use curricula, you know, the idea of
curricula learning, but unit by unit as opposed to end to end. Is that tell us a little bit more about,
you know, which of those or do you experiment with all of those or like,
I think it depends on the problem. So the answer is closer to experiment with
So one of the key distinctions I need to draw here is that the word learning is used
by multiple different communities to mean different things, right? When, when experimental
neuroscientists, biologists talk about, talk about learning, they're talking about the process,
the animal has experience, it's all experiential state. When you and I talk about learning,
we're talking about a training algorithm really. So in some sense, it's kind of the details of
the problem. And the answer is, I'm getting these networks into a state where once I stop
training them, they can autonomously produce the relevant dynamics that manifest in the time
varying behavior consistent with biology. And so it kind of depends. Sometimes I do them
unit by unit, sometimes you would have to train the units activations along with the behavior,
or sometimes you want to abandon all of them and put them through a curriculum.
But within the curriculum, you can again play with both of those. So it sort of depends on the
problem that one is tackling. And in my case, the problem isn't sort of cooked up in vacuum.
It is also inspired by something weird in experiments. So, you know, an experimental observation
that I've read about or one of my collaborators tells me about, that's how usually a problem gets
sparked. And I'm like, oh, I wonder if I can get networks to do something like that.
And what's an example of that? So an example of that would be something that looks like sequences,
right? This was one of my earliest, I would say, you know, discoveries if I may be so bold
as to use that term. People were seeing sequences everywhere. They see sequences. By sequences,
I mean, you know, time varying patterns of activity every neuron is only firing a small-ish bump.
But over the population, it looks like a wave going through. People see that in the hippocampus.
They see that in the prefrontal cortex. They see that in the striate. And they see this
in anatomically wildly different areas. And they see them all over the place. They see them during
working memory. They see them during, you know, place fields and place cells. They see them during
navigation, learning, remembering any function. There's a ubiquitous nest to this, the fact that
people see sequences. And that led me to wonder, well, what if it's an accident? Like we can't stop
sorting things. Is that why we're seeing sequences? That's how the problem first started.
Then we came up with this theory of they're doing a fundamental function, which is remembering
how long a task is occurring and when it's time to switch. So I'm having this conversation with
you. I'm also thinking about time, let's say, right? Something in the brain has to have steady
representation during the performance of this answer. It has to switch when it's time to ask the
next question or answer the next question. Something that has that feature, independent of the underlying
anatomy, is sequences. Because they're steady. They're the way it goes through, but it has a start
time and an end time. Now, of course, if I zorch the neurons that are making the sequence,
I'm not able to do this task properly, right? I keep sipping my cup of coffee and put it down
repeatedly. But why am failing? Maybe different from what we think, right? Maybe we're failing because
the state tracker is broken. And so we're now trying to get this into a framework we're starting
to talk about things like addictions and obsessive problems that what if we're looking at the problem
sort of much more narrowly than we need to? What if these disorders share the feature that,
you know, if I take a sip of a glass of wine and put it down, I know the action is finished.
Because once I put the glass down, well, what if I didn't? Or there's something that is tracking
that I've taken a sip and put it down is broken? Then I keep doing it obsessively for length of time.
And so that's an example of of a weird biological feature, repetitive action until something is
finished or inability to stop performing an action that could be cast as a as a fundamental
property of neural circuits and therefore neural circuit dysfunction. And that was this observation
that we're seeing sequences everywhere. GA wonder why? Yeah, and I was going to ask about the
kind of the end goal of the research you identify this, you know, quirk, let's say, an experimental
result. You try to create a model for it. So now you have this tool and it sounds like at least one
of the objectives here is that the tool can then be a launching point for deeper inquiry.
Is that how you see the work playing out? That's right. So one we can better leverage existing data,
right? I mean, we can say like people should share data with us because they're collecting it
anyway by process of training these animals. You better leverage existing data. You can use
these models as essentially a bottomless pit of hypotheses. So you can do experiments on them
that you wouldn't be able to either ethically or technologically or financially do in the real
system. So you can in some sense fail faster if you tried all those ideas on these substrate models.
Yeah. And so yes, they are essentially tools for deeper inquiry. At the very, very least, they
generate predictions for the next experiment, which can then, you know, validate or falsify.
And then I go back to the drawing board, refine the model. So all of the collaborations that I have
involved is kind of, you know, intimate recursive back and forth. And is that is the use of the tool
necessary necessarily? I'm envisioning like a simulation type of an approach to use the tools.
Is that the way it tends to work or is it something else? That's right. That's exactly right.
So these models are mathematical models that are then simulated in essentially computer programs,
right? And so we can do the manipulations in the program that you wouldn't be able to
necessarily do. Use them to extract features from data that are inaccessible from just measurements
alone. Yeah. So that kind of inquiry these models lend themselves to.
Great. Great. Well, Connaca, thank you so much for sharing a bit about what you're working on with
us. Very fascinating. And looking forward to keeping in touch and learning more.
Thank you so much for having me.
