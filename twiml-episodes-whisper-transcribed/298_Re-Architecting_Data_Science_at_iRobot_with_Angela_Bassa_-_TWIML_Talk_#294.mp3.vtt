WEBVTT

00:00.000 --> 00:16.320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

00:16.320 --> 00:21.480
people, doing interesting things in machine learning and artificial intelligence.

00:21.480 --> 00:34.040
I'm your host, Sam Charrington, Hey Twimble listeners, if you're a fan of our AI

00:34.040 --> 00:39.680
platforms coverage and especially if you download our first AI platforms ebook, Kubernetes

00:39.680 --> 00:44.800
for machine learning, deep learning and AI, then today is your day.

00:44.800 --> 00:49.440
While we've been working tirelessly on Twimblecom, I have also been working on Book 2 in the

00:49.440 --> 00:53.440
series, the definitive guide to machine learning platforms.

00:53.440 --> 01:00.080
And I am happy to say that it is finally available to download now.

01:00.080 --> 01:04.880
We created the book as a resource for ML, AI and data science leaders and innovators

01:04.880 --> 01:09.120
to help guide their efforts in scaling and industrializing machine learning and deep learning

01:09.120 --> 01:11.320
in their organizations.

01:11.320 --> 01:16.440
In this book, we address questions such as why invest in increasing your organization's

01:16.440 --> 01:20.160
capacity to deliver machine learning and deep learning models.

01:20.160 --> 01:23.720
What are the key barriers to delivering ML and DL models?

01:23.720 --> 01:28.560
How of organizations like Facebook, Airbnb and LinkedIn overcome these challenges and

01:28.560 --> 01:32.240
how can their learning be applied to your organization?

01:32.240 --> 01:35.840
What are the state of the art, machine learning platforms and tools and how can you put

01:35.840 --> 01:37.480
them to use?

01:37.480 --> 01:42.280
How can you develop an AI platform strategy to support your organization's goals?

01:42.280 --> 01:48.000
To access the definitive guide to machine learning platforms, visit TwimbleAI.com slash

01:48.000 --> 01:50.200
AI platforms.

01:50.200 --> 01:54.760
And now on to the show.

01:54.760 --> 01:57.400
All right, everyone.

01:57.400 --> 01:59.560
I am on the line with Angela Bassa.

01:59.560 --> 02:03.160
Angela is the director of data science at IROBOT.

02:03.160 --> 02:06.080
Angela, welcome to this weekend machine learning and AI.

02:06.080 --> 02:07.080
Thanks so much, Salem.

02:07.080 --> 02:08.520
I'm happy to be here.

02:08.520 --> 02:14.880
I am super excited to have you on the show and to get into a little bit of what you're

02:14.880 --> 02:17.720
up to there at IROBOT.

02:17.720 --> 02:24.040
To kind of get us started, I'd love to hear a bit about your background and how you came

02:24.040 --> 02:28.960
to be working at the intersection of robotics and data science.

02:28.960 --> 02:37.920
Yeah, so my background is mathematics and I came to the intersection of robotics and

02:37.920 --> 02:43.240
data science through an enormous amount of luck.

02:43.240 --> 02:49.440
Most people who come into data scientific practice either come from sort of the analytical,

02:49.440 --> 02:53.560
mathematical, physics sort of background or they come from computer science and software

02:53.560 --> 02:56.560
development and software engineering.

02:56.560 --> 03:01.440
And I am very much on the first camp and I am trying to learn as much as possible from

03:01.440 --> 03:04.680
the second camp's firehose.

03:04.680 --> 03:08.760
My academic training is in applied math.

03:08.760 --> 03:10.400
This was back at MIT.

03:10.400 --> 03:15.840
Since then I left, my sort of journey into data science was always through a heavy use

03:15.840 --> 03:21.800
of data, but under many different disciplines, so I worked in investment banking, in strategy

03:21.800 --> 03:27.080
consulting and agricultural technologies, and marketing and energy trading.

03:27.080 --> 03:33.680
I noticed that you had an incredibly broad background set of experiences before you found

03:33.680 --> 03:37.040
your way into data science.

03:37.040 --> 03:44.160
Yeah, I think it's sort of reflective of my personal and family history as well, so I'm

03:44.160 --> 03:49.840
a third generation immigrant and my family is sort of very transient and almost nomadic

03:49.840 --> 03:55.240
and I think that has translated into my career as well.

03:55.240 --> 03:59.120
And it's also, I mean, all jokes aside, it's actually something that I find comes quite

03:59.120 --> 04:05.720
easily to make so growing up, we spoke several languages at home and I find it very easy

04:05.720 --> 04:10.560
now in a professional capacity to understand that some people are speaking HREs, whereas

04:10.560 --> 04:15.560
some people are speaking engineers or some people are speaking analytics ease and to be

04:15.560 --> 04:22.160
able to provide a translational step has a huge amount of value, especially in a discipline

04:22.160 --> 04:28.880
like data science, where there's sort of this division between the tools and the mechanics

04:28.880 --> 04:35.160
of how you solve problems and the domain expertise of knowing which questions to ask and which

04:35.160 --> 04:37.800
problems are worthy of being solved first.

04:37.800 --> 04:38.800
Right.

04:38.800 --> 04:45.840
And so playing that midfield there has proven incredibly valuable and transferable, thank

04:45.840 --> 04:46.840
goodness.

04:46.840 --> 04:49.240
Nice, nice.

04:49.240 --> 04:55.440
You mentioned that your academic background was in applied math, what any particular focus

04:55.440 --> 04:56.440
or flavor?

04:56.440 --> 04:59.880
I liked graph theory quite a bit.

04:59.880 --> 05:07.960
I spent a lot of time in that domain and also logic and first sort of logic, sort of

05:07.960 --> 05:14.520
model theory, but I learned very early on that academia wasn't going to be my thing.

05:14.520 --> 05:22.480
I just don't have the personality fit for that actually more than a personality fit,

05:22.480 --> 05:27.000
I actually don't have the diligence to focus that long on a single problem.

05:27.000 --> 05:28.000
Yeah.

05:28.000 --> 05:34.680
So I ended up going into industry where my particular flavor of ADHD is actually quite valuable.

05:34.680 --> 05:39.200
I mentioned that you are at iRobot as did you.

05:39.200 --> 05:44.040
I imagine folks are familiar with iRobot, but maybe you should share a little bit

05:44.040 --> 05:52.360
about the company and the focus of the company just to levels it.

05:52.360 --> 05:53.680
Yeah, happy to.

05:53.680 --> 05:59.160
So iRobot is, a lot of folks actually don't know, but iRobot is almost 30 years old.

05:59.160 --> 06:01.680
So we've been around for quite a while.

06:01.680 --> 06:07.360
I've been here for about two and a half years now and I started the data science practice

06:07.360 --> 06:08.360
here.

06:08.360 --> 06:12.640
We've been growing quite a bit over the last two and a half years.

06:12.640 --> 06:20.800
But obviously iRobot builds robots and so we have lots of fantastic algorithms and machine

06:20.800 --> 06:26.120
learning engineers, many of whom predate my tenure here.

06:26.120 --> 06:35.160
But now we have sort of a focused competency whose mandate it is to look at fleet data

06:35.160 --> 06:41.360
and to make sure that we are using that information and feeding that back into the development

06:41.360 --> 06:46.840
of products into the customer experience and into the strategy.

06:46.840 --> 06:54.280
So at iRobot, we're well known for our flagship product, which is the Robotic Vacuum Cleaner.

06:54.280 --> 06:57.040
And we have a whole line of robotic vacuums.

06:57.040 --> 07:01.800
There's not just one, so depending on what specifically a customer might be looking

07:01.800 --> 07:08.960
for, we have different offerings with different levels of data driven features and autonomy.

07:08.960 --> 07:13.360
And we also have the Brava line, which is a robotic mobs and we just announced earlier

07:13.360 --> 07:16.560
this year the ptereline of robotic lawn mowers.

07:16.560 --> 07:22.040
So more and more we have this portfolio of autonomous products that can take care of your

07:22.040 --> 07:23.760
home so you can do other stuff.

07:23.760 --> 07:26.640
If you're like me, you can be a nerd.

07:26.640 --> 07:31.080
I'm one would call an endorsement so I don't use my free time to go outside but if you

07:31.080 --> 07:35.320
like that then you can do that while your robots are back home making sure that everything

07:35.320 --> 07:37.000
is sparkly clean.

07:37.000 --> 07:42.000
You mentioned that you started the data science group there at iRobot.

07:42.000 --> 07:47.840
Did you do that from internally where you already at iRobot or did you join the company

07:47.840 --> 07:50.640
to start the group?

07:50.640 --> 07:51.640
The latter.

07:51.640 --> 07:58.440
So I was at a company called Annernock before and I was also brought in to run their

07:58.440 --> 08:02.320
data science team, although they already had the team in place when I joined.

08:02.320 --> 08:11.680
They had two or three people working in data science there at the time and here at iRobot

08:11.680 --> 08:15.080
I was the first data science hire that they had.

08:15.080 --> 08:22.520
There's always pros and cons as to whenever you're starting a team especially in established

08:22.520 --> 08:23.520
organizations.

08:23.520 --> 08:26.480
So it's very different if your product is data scientific at that point you probably

08:26.480 --> 08:32.240
have data science challenge that's built in from either the founding team or at least very

08:32.240 --> 08:33.240
close to inception.

08:33.240 --> 08:38.440
Whereas when you're coming into an organization that is established and that has a product

08:38.440 --> 08:45.680
or an industry that they work within and you're starting to infuse that organization with

08:45.680 --> 08:49.080
data and data informed decision making.

08:49.080 --> 08:52.520
There are certain times where it makes sense to start with merging your talent and just

08:52.520 --> 08:56.840
flunking and figuring out what value you can extract from that data or you can start

08:56.840 --> 09:04.440
very top heavy and have more of a strategic or even a structural approach to it.

09:04.440 --> 09:09.320
And iRobot chose the latter looking for me and I've been very diligently making sure

09:09.320 --> 09:14.680
that they never think that that was a bad decision on their part.

09:14.680 --> 09:21.080
I had the company even come to know that it needed data science, what precipitated creating

09:21.080 --> 09:26.600
the opening and opportunity for you to join the company.

09:26.600 --> 09:31.400
So I like to believe that it's because some people with a lot of foresight who were

09:31.400 --> 09:38.400
here before me saw that as part of the vision as a compelling part of the story of what

09:38.400 --> 09:39.400
we're trying to do.

09:39.400 --> 09:44.920
So when you read about what iRobot is doing right now we're talking very openly about

09:44.920 --> 09:49.880
this this bet that we're making on the smart home and what we think that smart home ecosystem

09:49.880 --> 09:52.600
is going to mean going forward.

09:52.600 --> 09:58.440
But it all started with a small step towards connecting our products to the cloud and allowing

09:58.440 --> 10:04.400
those products to leave artifacts for us to be able to inspect.

10:04.400 --> 10:11.080
And one of the things that has always been at the forefront here has been the utmost

10:11.080 --> 10:13.800
stewardship that we have of that data.

10:13.800 --> 10:20.480
This data is not being generated from pings that your mobile phone is making to the cloud

10:20.480 --> 10:21.480
that you carry on you.

10:21.480 --> 10:23.080
This is coming from inside your home.

10:23.080 --> 10:30.960
This is one of your most precious havens and to allow somebody to allow a company to come

10:30.960 --> 10:39.400
in and autonomously, a proof that environment and report back is something that has to

10:39.400 --> 10:41.320
be done with a lot of trust.

10:41.320 --> 10:48.720
So I think part of the strategy internally was to make sure that all of that was in place

10:48.720 --> 10:54.600
before letting a whole bunch of nerds loose for linking all that data.

10:54.600 --> 10:55.600
So we had good.

10:55.600 --> 11:01.000
I was just going to ask you to elaborate a bit on what that data is and where it comes

11:01.000 --> 11:02.000
from.

11:02.000 --> 11:03.000
Yeah.

11:03.000 --> 11:11.000
So in late 2015 we had our first connected product and we started aggregating that information.

11:11.000 --> 11:16.560
So the information that we get always with the permission of our customers has to do with

11:16.560 --> 11:18.080
the functioning of the robot.

11:18.080 --> 11:24.800
So we're interested in identifying bugs before our customers are bothered by them before

11:24.800 --> 11:29.440
they impact the functioning of the functionality of the robot.

11:29.440 --> 11:34.280
We're interested in understanding how our customers use their robots.

11:34.280 --> 11:39.440
So one thing that's always important to keep in mind is that I'm not the person who should

11:39.440 --> 11:45.520
be asking the questions because I am a very specific type of nerd who has very nerdy questions

11:45.520 --> 11:49.160
and there's only one of me and millions and millions of all of us.

11:49.160 --> 11:55.120
So we as a company want to make sure that we're answering the questions of all of our customers.

11:55.120 --> 12:00.160
And so the data that we're collecting helps inform what our customers want from our products

12:00.160 --> 12:04.720
that maybe we haven't ideated yet and then it helps us develop that.

12:04.720 --> 12:10.360
But one thing to keep in mind is that we never sell that data, that data is not the thing

12:10.360 --> 12:16.320
that we make money off of the data is essentially the thing that allows us to do what our customers

12:16.320 --> 12:19.360
want from their product better than anybody else.

12:19.360 --> 12:20.360
Yeah.

12:20.360 --> 12:27.440
One of the things that I found, so I was at the AWS Remar's conference a few weeks ago.

12:27.440 --> 12:32.440
And I robot had a big presence at that event as well.

12:32.440 --> 12:38.320
And one of the things that I realized was that I just had a very dated view of the company

12:38.320 --> 12:39.320
and the products.

12:39.320 --> 12:47.160
Like, I remember when the Rumba first came out, and you can correct me if I'm wrong, but

12:47.160 --> 12:48.760
I think it was pretty dumb.

12:48.760 --> 12:53.440
Like, you know, you turn this thing on and it would like bounce in a wall and kind of randomly

12:53.440 --> 12:54.440
change direction.

12:54.440 --> 12:59.680
And the idea was that like, if you kept this thing charged up enough and let it do it

12:59.680 --> 13:04.000
enough, it would eventually clean up, you know, a room, right?

13:04.000 --> 13:10.280
As opposed to, you know, what I saw today was, you know, there were some visualizations

13:10.280 --> 13:18.120
that were like a total, like a slam type of, you know, process where these robots have

13:18.120 --> 13:23.360
all kinds of sensors and they're like mapping out their environments dynamically and, you

13:23.360 --> 13:30.320
know, employing some sophisticated, relatively sophisticated, certainly relative to, you

13:30.320 --> 13:34.880
know, what I recall, algorithms to make sure that they're cleaning up all the parts of

13:34.880 --> 13:35.880
your house.

13:35.880 --> 13:42.640
And then you're getting into this notion of like collaborative cleaning with either multiple,

13:42.640 --> 13:47.840
like the, you know, how does the broom robot work with the mop robot to clean a house?

13:47.840 --> 13:53.160
Like, it's, it's a lot more as like, it's not your, you know, not your father's room

13:53.160 --> 13:57.760
but anymore or something like that is a lot more sophisticated than I remembered.

13:57.760 --> 14:05.760
Well, I think 15, 20 years ago, a lot of things in hindsight look dumber, I certainly

14:05.760 --> 14:09.560
looked umber when I think of myself 15, 20 years ago.

14:09.560 --> 14:13.960
But yeah, I think, I think that's, that's apt.

14:13.960 --> 14:20.920
So the, the robots today, I mean, the thing that happens with a company that has been

14:20.920 --> 14:26.840
around for almost 30 years is you have all of these co-bases with a lot of institutional

14:26.840 --> 14:30.160
knowledge and a lot of love and passion embedded in there.

14:30.160 --> 14:35.040
And so it's hard to just say, yeah, we're going to start over, yeah, no problem.

14:35.040 --> 14:39.240
All the people who came before, what could have, what could they have possibly known?

14:39.240 --> 14:40.240
And it's hard to do that.

14:40.240 --> 14:42.800
But that's sort of a little bit of what it takes.

14:42.800 --> 14:47.720
It takes discharging a lot of technical debt and, and starting fresh to be able to do all

14:47.720 --> 14:53.600
of these things and today, you know, the, the Roomba's and the Bravas, they can, some

14:53.600 --> 14:55.120
of the models, they can work together.

14:55.120 --> 15:03.040
So you can tell your Roomba and your Brava to, to tackle, to tag team on, on a task.

15:03.040 --> 15:07.920
And so your Roomba might know exactly where it is.

15:07.920 --> 15:12.760
And so if you want the kitchen and the dining room to get cleaned and mopped, then the Roomba

15:12.760 --> 15:17.480
can dispatch and go to the kitchen, finish as it's moving to the dining room and communicates

15:17.480 --> 15:21.960
with the Brava mop, that the kitchen is all done, that the, the, the mobbing can start

15:21.960 --> 15:24.080
there and it moves into the dining room.

15:24.080 --> 15:27.400
And then when it's finished with a dining room, it lets the Brava know that it can follow

15:27.400 --> 15:28.400
along.

15:28.400 --> 15:34.280
And so then both of those rooms get, uh, vacuumed and mopped and you don't have to lift

15:34.280 --> 15:35.600
a finger.

15:35.600 --> 15:41.040
And with the Roombas, those, um, also have the clean base now, so the, the, the top models

15:41.040 --> 15:42.280
have the clean base.

15:42.280 --> 15:49.280
So the Roomba can dock itself and the base vacuums, the bin of the robotic vacuum and stores

15:49.280 --> 15:50.280
that.

15:50.280 --> 15:53.080
So you don't have to touch it for sometimes weeks or months at a time until you have

15:53.080 --> 15:55.240
to empty the clean base.

15:55.240 --> 16:01.400
So this, this idea of autonomy is something that, uh, at least our modern product line,

16:01.400 --> 16:06.440
uh, is already delivering on and, uh, the whole product line is always evolving towards.

16:06.440 --> 16:10.520
But what we're going towards really, uh, is beyond autonomy, which is something that

16:10.520 --> 16:16.800
Colin, uh, Angle or CEO talked about are remars as well, which is intelligence is an autonomy,

16:16.800 --> 16:17.800
right?

16:17.800 --> 16:20.400
Um, if you autonomously can do something, that's great.

16:20.400 --> 16:25.480
That's better than, than not doing it and, and to require, uh, active direction.

16:25.480 --> 16:31.840
But, um, if you can coordinate and, um, if you can be responsive and collaborative and

16:31.840 --> 16:36.800
if you can be part of a system that enables, uh, all of that collaborative response of

16:36.800 --> 16:41.960
autonomy to take place, uh, then, then you're really talking about the, the transformative

16:41.960 --> 16:47.560
power of data, which is sort of what we're building our platform to be able to leverage.

16:47.560 --> 16:54.560
Is there an example of that in the context of, uh, Roomba in particular, or robotics

16:54.560 --> 17:00.600
or I robot in general, like, how intelligence is, you know, greater than autonomy, however.

17:00.600 --> 17:07.880
Yeah, I think the, the one example would be, um, if you can send, uh, a robot to, to

17:07.880 --> 17:11.520
perform a mission, right in the parlance, if you can send a robot to go and clean the

17:11.520 --> 17:13.560
room, um, that's great.

17:13.560 --> 17:21.000
But if you can tell that robot where in that room to, uh, spend more of its time, uh, either

17:21.000 --> 17:25.560
because, um, you know that there's a particular stain or you know that there is a particular

17:25.560 --> 17:35.160
area that needs to be, um, focused on or if you, um, know that the, uh, that another robot

17:35.160 --> 17:37.360
in the family should follow along.

17:37.360 --> 17:41.480
And so if you can report back that you've identified, there's something, uh, amiss in this

17:41.480 --> 17:42.480
region or that region.

17:42.480 --> 17:46.320
So the way that Colin sort of articulated it, which was really clever, uh, not just because

17:46.320 --> 17:53.280
he's my CEO actually thought this was very clever, um, is, um, if you think of, of the example

17:53.280 --> 17:54.520
of astronauts, right?

17:54.520 --> 17:58.120
If you have somebody who is able to make it to the moon and back, that's great.

17:58.120 --> 18:02.800
But if they're, or make it to Mars and back, but if, if they're there and they have gone

18:02.800 --> 18:06.840
through a battery of, of training to make sure that they can withstand the journey, they

18:06.840 --> 18:10.440
don't have infinite RAM so they can't know all of the things.

18:10.440 --> 18:14.400
So if you have somebody back in Houston who can tell them, hey, that rock over there that

18:14.400 --> 18:18.880
you're not paying any attention to because you're not a geologist, but I am, pick it up

18:18.880 --> 18:22.440
and bring it home, bring a sample because I want to know what that is, right?

18:22.440 --> 18:28.200
So if, if that relationship goes beyond just a relationship of autonomy, but a relationship

18:28.200 --> 18:33.280
of responsiveness so that you can act on that information while it is relevant rather

18:33.280 --> 18:39.440
than only after the payload has been delivered, um, that's really where, where we're driving

18:39.440 --> 18:40.440
towards.

18:40.440 --> 18:48.400
And so when you think about applying data science in this context, how do you break

18:48.400 --> 18:55.360
down the different roles and, and places that you're applying data science?

18:55.360 --> 19:00.200
Um, and I guess I'm, you know, I'm thinking of it kind of crudely in terms of use cases

19:00.200 --> 19:08.640
maybe like, you know, I'm imagining you could apply this to, you know, certainly the autonomy

19:08.640 --> 19:16.680
of the robots within the home, there are like predictive maintenance types of use cases,

19:16.680 --> 19:21.480
there are like business things like how many of the people that buy these things actually

19:21.480 --> 19:27.600
use them and how many of the people, you know, um, that, you know, buy them and use them

19:27.600 --> 19:28.600
a lot.

19:28.600 --> 19:33.160
Probably want to see like the next bigger version because, you know, their current

19:33.160 --> 19:38.040
one, you know, isn't doing something as good as it could be or like what are all the,

19:38.040 --> 19:42.800
like how do you think about not what are all of them, but how do you taxonomize the different

19:42.800 --> 19:47.840
ways that data science plays at, at I robot?

19:47.840 --> 19:55.120
I think the, the way that I like to think about it is in terms of the, the utility of each

19:55.120 --> 20:03.640
of the different projects and, um, and their priority within the, the greater, greater strategy

20:03.640 --> 20:08.040
that we have both in R&D and, uh, in I robot as a whole.

20:08.040 --> 20:13.720
So, um, especially as I was saying before, when, when you have a company that has a product

20:13.720 --> 20:18.840
that is data scientific, right, the thing that you are selling is the knowledge that you

20:18.840 --> 20:21.320
have about the data that you collect.

20:21.320 --> 20:26.320
It's a completely different ball game, but, uh, in the sense of I robot where our product,

20:26.320 --> 20:33.040
uh, is this physical, uh, robot and the data really plays a supporting role to that.

20:33.040 --> 20:38.520
I think the, the thing that you want to, uh, focus on is the fact that data science is

20:38.520 --> 20:42.320
not a, uh, a cheap investment.

20:42.320 --> 20:46.200
And so as, as I stood up to practice here, the first thing that was top of mind is making

20:46.200 --> 20:50.800
sure that we demonstrate or return on that investment because, uh, the thing that I have

20:50.800 --> 20:58.200
seen happen, uh, in, in similar cases is that there's this, this image of the potential

20:58.200 --> 21:05.040
of what, uh, what this practice could deliver and then, um, that potential isn't realized

21:05.040 --> 21:09.960
in the very near term and everybody gets disenchanted and it becomes the self-fulfilling

21:09.960 --> 21:12.240
prophecy that it was never going to work.

21:12.240 --> 21:17.720
Uh, and that happens over and over, uh, when you're talking outside of sort of the, the,

21:17.720 --> 21:22.560
the Silicon Valley data driven, uh, startup ecosystem.

21:22.560 --> 21:27.600
And that's the thing that I was most cognizant of is what are the things that we can deliver

21:27.600 --> 21:31.080
in the very short term with the information that we already have.

21:31.080 --> 21:32.840
I don't want to re-architect anything yet.

21:32.840 --> 21:39.840
I don't want to change how our software gets, uh, developed or how, uh, data gets, uh,

21:39.840 --> 21:45.640
encoded and, and ingested and transformed process stored all of that, uh, based on the

21:45.640 --> 21:50.760
things that we've inherited, what, what exists of value that we can deliver in the very

21:50.760 --> 21:52.080
short term.

21:52.080 --> 21:58.160
And then based on, uh, the, the moment that you can generate there, um, you can start recruiting

21:58.160 --> 22:04.200
champions and you can start recruiting stakeholders that can help you make the more foundational,

22:04.200 --> 22:08.560
uh, changes that enable really big bets.

22:08.560 --> 22:13.640
So here at IROBOT, you know, one of the big bets that we're making is, um, on the smart

22:13.640 --> 22:20.520
home and what that will mean and, uh, who will win in that space and, and our bet is that,

22:20.520 --> 22:26.840
uh, we will win because of, uh, both our, our capability and our expertise and, uh, our

22:26.840 --> 22:30.480
commitment to customer privacy and all of these things rolled into one.

22:30.480 --> 22:34.680
But that's not something that could have been accomplished in the first six months, right?

22:34.680 --> 22:39.720
And so I really try to think, uh, in terms of sort of your near term horizon and your long

22:39.720 --> 22:40.720
term horizon.

22:40.720 --> 22:43.760
So your near term horizon are the things that your data is already bringing to you that

22:43.760 --> 22:46.680
if only somebody were to pay attention to it, right?

22:46.680 --> 22:50.520
You could, um, you could make smarter decisions.

22:50.520 --> 22:51.520
And so those are easy.

22:51.520 --> 22:59.360
You just need to dedicate the time and effort to look at the tactical to, to, to chat across

22:59.360 --> 23:03.800
the organization to figure out who could do, who could make better decisions if only,

23:03.800 --> 23:07.760
uh, somebody could help them understand how things are getting used.

23:07.760 --> 23:11.360
And that's all already, uh, instrumented.

23:11.360 --> 23:17.520
But, uh, that's really sort of quote unquote bootstrapping, the really big, uh, play, which

23:17.520 --> 23:24.400
then requires, uh, you know, improved data architecture and, um, all of the things that

23:24.400 --> 23:30.280
come, that, that, that, that come downstream from that in terms of, uh, data quality, lineage,

23:30.280 --> 23:35.320
governance, um, all of those other, other things that, that are important.

23:35.320 --> 23:41.960
Yeah, I find this, this conversation really interesting and it's one that I, when I talk

23:41.960 --> 23:47.040
to folks that are, you know, running data science organizations or, you know, machine learning

23:47.040 --> 23:54.280
AI, organization centers of excellence, things like this, this, the whole concept of how

23:54.280 --> 23:58.320
they manage and balance their portfolios.

23:58.320 --> 24:06.280
Also as to kind of demonstrate short-term value, you know, enough short-term value, um,

24:06.280 --> 24:13.440
while also kind of keeping their eye on, you know, a broader vision and, you know, selling

24:13.440 --> 24:19.320
that or making progress to that, like it's a very delicate balance in a lot of places

24:19.320 --> 24:23.320
and one that, you know, a lot of energy is put towards.

24:23.320 --> 24:27.840
Yeah, and it's really easy to sort of hire a team.

24:27.840 --> 24:35.160
I mean, it's not easy, but it's quite possible to hire a team of a hundred people, uh, all,

24:35.160 --> 24:42.320
you know, experts and, and, and really fantastic professionals and throw them at a problem.

24:42.320 --> 24:47.160
And then they will, you know, come up with all of these, I mean, they really are fantastic

24:47.160 --> 24:53.880
ideas that will require two years of additional instrumentation and, um, further investment.

24:53.880 --> 24:59.480
And, um, I like to joke that if we were to do the things that I want to do, we go bankrupt

24:59.480 --> 25:04.480
because I'm not, uh, the target audience for this, right?

25:04.480 --> 25:12.320
There, there are lots of, uh, robotics companies that find it very difficult to, to stay, uh,

25:12.320 --> 25:18.320
in the market for as long as I robot has, uh, to, to do, uh, these things in a cost effective

25:18.320 --> 25:19.320
way.

25:19.320 --> 25:26.080
Uh, and, and that's the game for us is how can we, uh, deliver on the promise of consumer

25:26.080 --> 25:32.320
robotics in a way that isn't going to extinguish itself because, you know, we've, we've been

25:32.320 --> 25:33.880
not more than we can chew.

25:33.880 --> 25:40.760
So this very measured approach, um, can be quite frustrating at times because it, it can

25:40.760 --> 25:47.480
feel like you're, you're funding the, uh, the least interesting parts of the journey.

25:47.480 --> 25:52.000
And in fact, it's quite the opposite, um, what, what I feel like I'm doing is I'm clearing

25:52.000 --> 26:00.880
the midfield so that, uh, my, my key players can then be able to take amazing shots, uh,

26:00.880 --> 26:06.760
without having this, this constant oversight and this demanding voice that, uh, why haven't

26:06.760 --> 26:09.160
we, uh, paid for ourselves yet?

26:09.160 --> 26:10.160
Mm-hmm.

26:10.160 --> 26:11.760
Sounds like you're a football fan.

26:11.760 --> 26:17.800
I am, and I call it football, for me, it's soccer.

26:17.800 --> 26:21.240
So for, for folks who might be listening in, who don't know, I was actually born and raised

26:21.240 --> 26:27.680
in Brazil, and I have just started to learn, uh, American football rules.

26:27.680 --> 26:31.040
So, um, now it gets really confusing.

26:31.040 --> 26:32.040
Nice.

26:32.040 --> 26:37.560
Uh, so, how, how big is the data science team there now?

26:37.560 --> 26:41.360
Um, so we have, uh, a blended team.

26:41.360 --> 26:47.080
So we don't have, uh, just data scientists in our data organization, which is also something

26:47.080 --> 26:51.240
that I think is, is, uh, fundamental to our success so far.

26:51.240 --> 27:00.280
Uh, we started with, uh, data scientists, uh, but as we've, um, grown, uh, the, the, the,

27:00.280 --> 27:05.520
the portfolio of, of solutions that we offer internally and in our production environment,

27:05.520 --> 27:08.920
we've, we've been, um, adding specializations.

27:08.920 --> 27:15.400
So we have a blended team of, uh, data architects, data stewards, data engineers, data analysts

27:15.400 --> 27:20.520
and data scientists that, that help us cover all of the different things that we have in

27:20.520 --> 27:21.800
our road now.

27:21.800 --> 27:24.600
How many on the data team there?

27:24.600 --> 27:29.920
So on the data team per se, I think we have 12 people right now.

27:29.920 --> 27:38.880
One of the things that I wanted to dig into a little bit is how you have built out processes

27:38.880 --> 27:47.120
and platforms to support delivering models in the production and, and, you know, doing

27:47.120 --> 27:50.240
the work of the, the team.

27:50.240 --> 27:55.800
Can you talk a little bit about the, you know, both the philosophy there, but you also like

27:55.800 --> 28:01.520
try to get us to kind of concrete details around, you know, some of the things you're doing.

28:01.520 --> 28:06.520
So for a company like I robot, one of the things that we had to do was we had to discharge

28:06.520 --> 28:08.080
a lot of technical debt.

28:08.080 --> 28:15.160
So, um, a lot of our products, uh, originally were, uh, each one independent platform.

28:15.160 --> 28:20.320
And so they had, uh, a code base, uh, and all of the ancillary things that go with that

28:20.320 --> 28:22.520
that were independent of each other.

28:22.520 --> 28:27.400
And that made it so that each platform was robust and, and there are lots of benefits

28:27.400 --> 28:29.440
with that in terms of manufacturing.

28:29.440 --> 28:34.480
But one thing that, uh, proved, uh, less than helpful was the fact that there was very

28:34.480 --> 28:40.800
little modularization, so it was hard to be able to reutilize learnings, uh, and to shift

28:40.800 --> 28:44.280
priorities, uh, as they needed to, to happen.

28:44.280 --> 28:50.200
So one of the things that, uh, we've recently underwent was, was a reorganization where, um,

28:50.200 --> 28:57.040
we brought data science specifically, uh, closer to engineering and closer to product management.

28:57.040 --> 29:03.920
And we've also, um, created a new design language and a shared code base that's modularized

29:03.920 --> 29:12.000
so that, uh, the different pieces of the software can be interoperable.

29:12.000 --> 29:17.520
And so things like navigation and mapping, things like Wi-Fi connectivity and all of those

29:17.520 --> 29:26.440
parts of, of the, the, the platform can now, um, be, uh, plot, be almost plug and play

29:26.440 --> 29:29.960
with the different products that, that we develop.

29:29.960 --> 29:39.320
And what that does is it, it really allows us to, to be much faster in our ability to,

29:39.320 --> 29:41.000
to write software.

29:41.000 --> 29:47.840
And so what we're, uh, moving towards are these robots that become smarter over time.

29:47.840 --> 29:50.560
So, um, hardware is very different than software.

29:50.560 --> 29:55.880
You can't just release an OTA and get new hardware and new injection molded plastic in,

29:55.880 --> 29:58.600
in people's hands, but you can do that with software.

29:58.600 --> 30:04.800
And so if we can have a smart platform, um, that, uh, is part of the hardware that can

30:04.800 --> 30:13.880
receive improved, uh, direction over time, then that allows us to be able to, to solve

30:13.880 --> 30:17.840
the problems that our customers have, uh, in more intelligent ways.

30:17.840 --> 30:18.840
Mm-hmm.

30:18.840 --> 30:25.200
And so we, uh, we essentially embarked on that, uh, not too long ago and we've been operating

30:25.200 --> 30:32.440
under that model for the, for all of 2019, essentially, where, um, we have now a, uh,

30:32.440 --> 30:38.560
data, uh, a DevOps culture and we have a cloud, uh, culture and we have a data-driven

30:38.560 --> 30:44.480
culture that, uh, is imbued into all of the different teams so that they can leverage

30:44.480 --> 30:50.680
the power, uh, of this new design language that, that is shared across all of our products.

30:50.680 --> 30:59.360
Mm-hmm. And so when you say design language, what is that, what does that really mean?

30:59.360 --> 31:04.360
So, um, it means a lot of things, one of the things, for instance, is we used to have

31:04.360 --> 31:11.680
a, um, homegrown, uh, coding language for some of our robots because of the restricted

31:11.680 --> 31:17.800
nature of the compute that was available to them, to them, which is perhaps what might

31:17.800 --> 31:23.920
have made them feel less than intelligent 15, 20 years ago, um, moving forward into, into

31:23.920 --> 31:28.840
the present and the future, uh, that just wasn't going to cut. And so a lot of our code

31:28.840 --> 31:34.200
base right now is in Python and, uh, that helps both in terms of attracting talent, but

31:34.200 --> 31:38.000
also in terms of shifting talent around and shifting learnings around.

31:38.000 --> 31:42.640
And I was talking about code on the robot or code somewhere else.

31:42.640 --> 31:51.800
Yes, and so, um, uh, not all of the parts are in, uh, the, the new paradigm yet because

31:51.800 --> 31:56.760
this is, this is a transition, but a lot of it, uh, both on robot and off. And also in

31:56.760 --> 32:02.960
terms of the, uh, the types of things that can happen on the robot, um, you know, there's

32:02.960 --> 32:07.960
a lot more, uh, power that the robots have, uh, you know, for, for the things that, that

32:07.960 --> 32:12.600
they're capable of doing right now. So if you're going to have teaming, take place, um,

32:12.600 --> 32:16.880
all of that needs to happen. And it needs to happen on the edge so that that information

32:16.880 --> 32:22.600
doesn't necessarily need to get, uh, sent back home for things to work. Sorry that they

32:22.600 --> 32:23.600
should.

32:23.600 --> 32:28.280
Sure. Yeah, it strikes me that there's, you know, platform and, and this conversation

32:28.280 --> 32:35.960
is going to be a little overloaded in the sense of the robot itself is a platform. It's

32:35.960 --> 32:40.400
a hardware platform. And then you've got a software platform sitting on that hardware

32:40.400 --> 32:48.480
platform. And then you've got, that's presumably connected to the cloud, right? AWS, that's

32:48.480 --> 32:57.080
a platform. And so, you know, in that kind of environment, where does DevOps come in

32:57.080 --> 33:04.200
the play and how, how is that used presumably to help tie all these things together?

33:04.200 --> 33:12.000
So the way that it comes into play is twofold. I think one is just as a, uh, mentality

33:12.000 --> 33:18.080
that all of the software developers, uh, need to have in terms of, of the level of ownership

33:18.080 --> 33:23.560
of code. But on top of that, I think, uh, the, the, the, as you describe the different

33:23.560 --> 33:31.360
layering, um, so we want to have, um, folks work on the things that they're good at, the

33:31.360 --> 33:36.120
things that they're passionate at and not on the things that are unnecessary. So the

33:36.120 --> 33:39.280
same kind of mentality applies to data science. And I'm going to speak to data science because

33:39.280 --> 33:43.400
that just comes more easily to me. But in both data science and machine learning, you,

33:43.400 --> 33:48.400
you want to have that same DevOps culture where you don't want to spend 80% of your time

33:48.400 --> 33:52.880
cleaning data. You want to spend 80% of your time figuring out how your data is dirty.

33:52.880 --> 33:57.160
And then writing code that solves it. So the next person doesn't have to do that as well.

33:57.160 --> 34:03.960
So, um, that has to come individually from each member of our team. But we also have, uh,

34:03.960 --> 34:09.600
a team dedicated to maintaining, uh, all of those different layers, uh, both on the, the

34:09.600 --> 34:13.280
hardware platform, the software platform and the cloud platform. I don't know if that

34:13.280 --> 34:17.560
answers your question. Uh, kind of, it starts to get us there. What is that team called?

34:17.560 --> 34:26.560
So, um, that team is the cloud ops team. I guess one, one question that I've got is,

34:26.560 --> 34:33.120
you know, as, as a company that kind of ships these products that are inherently platforms,

34:33.120 --> 34:43.120
uh, I'm wondering if you also have like horizontal, you know, platforms or tools or processes

34:43.120 --> 34:53.400
that are, you know, just how you develop models at Irobat or how you, you know, do experimentation

34:53.400 --> 35:00.440
or how you do deployments that are kind of independent of the individual, uh, robotics

35:00.440 --> 35:07.320
platforms or, you know, because you're developing these like highly integrated things, you

35:07.320 --> 35:15.000
know, is everything very specific to one product. Well, that's the crux of it. So we were handicapped

35:15.000 --> 35:20.760
by the fact that, um, we were faced with with exactly what you're describing where we had

35:20.760 --> 35:28.200
all of these different, uh, distinct platforms. And so, um, as you well know, and as your audience

35:28.200 --> 35:35.800
knows, machine learning requires a lot of training data. Uh-huh. And so how can we train, uh, these

35:35.800 --> 35:43.560
models, uh, with, with the, the, the ultimate objective of having them be as robust as possible.

35:43.560 --> 35:50.840
And so there's a lot of, of information that, um, that these different, uh, formerly distinct

35:50.840 --> 35:55.720
platforms were collecting that weren't distinct at all. So that information should be able to

35:55.720 --> 36:02.680
all be used, but it couldn't because they were coming in through disparate, uh, mechanisms

36:02.680 --> 36:08.440
using different schemas, using, uh, different co-basis. And so part of this rearchitecture has really

36:08.440 --> 36:15.960
been to have a unified, uh, and we call it a design language because it applies both to the,

36:15.960 --> 36:24.520
the industrial design of the hardware, but also the, uh, code plasticity underlying all of that.

36:24.520 --> 36:32.120
And so now that we have this, this unified, uh, shared, uh, platform, all of the information

36:32.120 --> 36:39.400
that comes in, uh, is much more, uh, readily available for, for utilization in different models.

36:39.400 --> 36:46.760
And so part of what we're doing, um, is increasing the personalization of our products. And to do that,

36:46.760 --> 36:51.800
you know, if I, if you're interested in ever increasing autonomy, you don't want to have to worry

36:51.800 --> 36:57.240
about actually sending your robot out, uh, to clean your home. You want that to just automatically

36:57.240 --> 37:03.240
happen, and you don't want to have to worry about it. And so one of the things that, uh, we imagined

37:03.240 --> 37:11.400
we should do, and now we do, is as you are, um, using your robot over time, we learn how you like

37:11.400 --> 37:15.240
to clean your home. When you like to clean your home, are there specific rooms that you like to clean,

37:15.720 --> 37:22.600
um, with different rates? And so we can make recommendations for you on when you should run your

37:22.600 --> 37:28.760
robot or during what times in what rooms so that you can just say, yes, please do this for me

37:28.760 --> 37:33.400
and subplugging me. And then the robot will take over. And if you have one with a clean base,

37:33.400 --> 37:40.200
then the robot will take over and it will, um, run its, its cleaning missions, uh, on the frequency

37:40.200 --> 37:45.800
that you've specified. And you only touch it when the clean base is full. And so one of the things

37:45.800 --> 37:50.200
that's important to keep in mind with something like that is you're actively telling your customer

37:50.200 --> 37:54.680
to not engage with your product. So you have to make sure that you've covered all your bases

37:54.680 --> 38:01.160
so that your, your product is working as intended, uh, in an unsupervised way for as long as it does.

38:01.800 --> 38:09.800
So what's the experience from the data scientist perspective? Like they,

38:09.800 --> 38:19.480
they, there's not now post this rearchitecture. They, do they, is there a centralized place like a

38:19.480 --> 38:26.600
data warehouse or something where they access all of this data and then, um, are there specific tools

38:26.600 --> 38:32.760
that they are able to use now to build models that are independent of, you know, where those models

38:32.760 --> 38:41.240
are ultimately going to run from a robot perspective. Like how, what is that? What services

38:42.200 --> 38:47.880
or experiences does that layer provide for the data scientists that need to work on these

38:48.680 --> 38:54.200
different models for these different robots? It really depends on the use case, right? So if you

38:54.200 --> 39:01.000
have a robot and your robot, uh, has sent you a message for whatever reason. And so it's blinking

39:01.000 --> 39:05.400
and you go when you look in your app and if your app is not reflecting exactly what your robot

39:05.400 --> 39:10.280
is saying, you're going to think that we don't know what we're doing. So that's one use case where it's,

39:10.280 --> 39:17.160
you know, it has to be extremely low latency and fairly high concurrency. So that, uh, use case for

39:17.160 --> 39:23.640
how, for our data management is very specific. Um, whereas for the data scientists, as you ask, we

39:23.640 --> 39:28.760
don't really have a need for, for extremely low latency because it's a, it's sort of our research

39:28.760 --> 39:34.520
environment that as we discover things that we would like to do, um, we can then go into our data

39:34.520 --> 39:41.320
lake and swim in it. So there are these different architectures that serve different purposes as

39:41.320 --> 39:47.000
what they should. So in our data lake, uh, environment where our data scientists are doing a lot of

39:47.000 --> 39:55.720
their, their researching, that's now a centralized place, um, that has, um, reduced a lot of the overhead

39:55.720 --> 40:02.120
that our data scientists need. So a lot of the processing is taking place centrally and, um,

40:02.120 --> 40:08.200
and we've abstracted a lot of the, the complexity of, of aggregating and transforming all of that

40:09.000 --> 40:17.240
in our lake so that the data scientists are, are, um, essentially dealing with, with derived data sets

40:17.240 --> 40:22.680
that already are in the format that is shared across all of our different products and all of our

40:22.680 --> 40:30.520
different, uh, platforms, so to speak. That data lake, um, is that, what is that, is that S3

40:30.520 --> 40:38.840
or Redshift or something else or some combination of, you know, other things? It's a combination

40:38.840 --> 40:46.200
because of the, the different requirements of how that, uh, uh, those different data stores are

40:46.200 --> 40:52.280
traversed. So, um, for the data scientific case in particular, we rely quite a lot on Athena.

40:52.280 --> 41:01.560
Okay. Um, for, for the, the queering and, and the, the creation of, of, uh, extracts, uh, for,

41:01.560 --> 41:07.000
for research, uh, one important thing to note as well is that there are, uh, significant access

41:07.000 --> 41:12.920
controls to all of these different parts of the environment and, um, there are also the, the,

41:12.920 --> 41:20.040
the different parts of the, the data lake that can be, uh, hashed or tokenized, um, so I don't

41:20.040 --> 41:25.640
necessarily need to know what you call a particular room. I just need to know that you care enough

41:25.640 --> 41:30.680
that you've named things, right? Like I don't need to know what you call your robot, um, but I would

41:30.680 --> 41:38.680
like to know that you love it enough that you've named it. Um, so, uh, those types of, of data, uh,

41:39.720 --> 41:45.320
care and, and maintenance are the things that, that we've centralized so that you don't have to

41:45.320 --> 41:49.720
worry whether the data scientist knows enough to not go spolunking whether or not supposed to,

41:49.720 --> 41:52.200
and we're really trying to protect our data scientists from themselves.

41:53.080 --> 42:02.520
And so you've got the, this data lake environment that is, uh, Athena and other things,

42:02.520 --> 42:10.200
depending on the use case, what are the types of tools that data scientists are typically using

42:10.200 --> 42:15.320
there? Are you doing a lot of deep learning types of things with, uh,

42:15.320 --> 42:22.760
uh, tension flow and that kind of stuff or, uh, psychic learn or what does the modeling experience

42:22.760 --> 42:29.800
look like from a data scientist's perspective at a robot? I tried not to be too dogmatic, uh,

42:29.800 --> 42:35.080
just because different tools, uh, are appropriate for different use cases. So when we are still in

42:35.080 --> 42:44.280
the, uh, ideating and, and researching phase, uh, we've used things, uh, that run the gamut, um,

42:44.280 --> 42:48.920
and one of the things that I mentioned is once these processes are actually, uh, running,

42:49.720 --> 42:54.600
on the robot, they're running in, in a resource constrained environment. So when we're learning

42:54.600 --> 43:01.880
things about the information that we, uh, have access to, those are running on our own, uh, hardware,

43:02.760 --> 43:07.240
our own compute, uh, not necessarily our own hardware, sometimes the Amazon owns the hardware.

43:07.240 --> 43:13.000
But still, those are, uh, we have a lot more flexibility with what we use and how it will be

43:13.000 --> 43:19.400
appropriate. And then it's on us, uh, for whatever algorithms need to run on board, the, the robot,

43:20.120 --> 43:24.760
to make sure that they're, uh, optimized so that they can run in the restricted compute environment.

43:24.760 --> 43:31.400
So as far as what we're using, I mean, yes, we do use sensor flow. We use, um, uh, different

43:31.400 --> 43:38.280
libraries. We certainly use psychic learn as well. Um, and in terms of, uh, what kind of, uh,

43:38.280 --> 43:43.320
methodologies we're using internally. I mean, you mentioned slam, uh, you know, iRobot has,

43:44.040 --> 43:50.600
a pretty strong, uh, published presence, uh, in the development of eSlam, um, but there are, uh,

43:50.600 --> 43:56.760
myriad other, um, algorithms that, that we use as well. Um, and we have teams that focus on deep

43:56.760 --> 44:01.480
learning. We have a team that focuses on reinforcement learning, um, for all sorts of different

44:01.480 --> 44:08.040
use cases that I can't actually describe yet until we launch, uh, but they're imminent. So, um,

44:08.040 --> 44:12.920
yeah, we have a, a pretty strong bench, uh, in terms of, of the different methodologies that

44:12.920 --> 44:18.520
we make use of. And I, I mentioned, we both mentioned slam at this point and I did not define it

44:18.520 --> 44:23.640
earlier. It's simultaneous. Simultaneous is that position in mapping, local addition in mapping.

44:23.640 --> 44:28.360
Yeah. So how the robots able to go out into the world and kind of figure out where it is and

44:28.360 --> 44:33.880
map it, it's environment. And if you've never seen it, uh, it's pretty remarkable. It's a pretty

44:33.880 --> 44:42.760
long demo. Yeah. It is. And I have, uh, I mean, I have a million robots. Um, it's, uh, it's one of the

44:42.760 --> 44:48.840
perks of the job having to test all of these things. But, um, I actually have, uh, I also have a

44:48.840 --> 44:54.920
young son. And so we have, uh, child gates, sort of baby gates all over the house. And it is

44:54.920 --> 45:00.760
remarkable to see the robots sort of figure out, oh, nope, I can't go this way. And it goes all

45:00.760 --> 45:05.000
the way around the floor map to find another point of entry to the room that I wanted to clean.

45:05.560 --> 45:11.400
So it's actually quite smart. And it's, you know, we forget to we who, who, who, who do this

45:11.400 --> 45:17.080
professionally. Um, you live in the zeros and ones and the code and to actually see a piece of

45:17.080 --> 45:23.000
hardware, uh, take that knowledge and apply it, it is actually really, really cool, which is

45:23.000 --> 45:28.680
something that in previous, in previous roles, I didn't necessarily have. But, but to see that

45:28.680 --> 45:35.320
mobile sensor platform take direction and utilize it and, and tangibly move around its, its environment

45:35.320 --> 45:41.000
and understand its, its spatial components. Right. It's actually really fun.

45:41.720 --> 45:47.800
So we've talked a little bit about data access. We've talked a little bit about modeling. I guess

45:47.800 --> 45:57.720
kind of last question in this vein, uh, deployment. How are you deploying models, uh, so that they're

45:57.720 --> 46:04.600
kind of accessible for inference? Like I'm thinking about AWS has like this greengrass thing where

46:04.600 --> 46:11.880
you can like deploy models out to the edge or I'm assuming that your, the, the I robot platforms

46:11.880 --> 46:18.120
aren't like greengrass endpoints or that you're running. I don't know. You tell me are you running

46:18.120 --> 46:23.960
like serverless model deployment on the robots and that kind of thing or how funky does it get?

46:23.960 --> 46:32.440
Yeah. So we, um, we're pretty bought into the serverless architecture paradigm. And so, uh, that

46:32.440 --> 46:42.520
is essentially how most of the, the platforms run on our side. But in terms of deployment, um, for,

46:43.400 --> 46:51.080
for the algorithms that run on the edge, we actually have, um, an OTA pipe that, um, because,

46:51.080 --> 46:59.160
because the OTA, like how you, thank you. Yes. Right. Exactly. Um, I forget my TLAs aren't everybody's

46:59.160 --> 47:06.920
TLAs, three-letter acronym. So thank you. Um, yeah. So, um, we, because these things are running,

47:07.800 --> 47:14.200
on a autonomous vehicle. I mean, these aren't, you know, on the streets. They're in your homes

47:14.200 --> 47:22.520
always. And so once, uh, once we, we introduce those models into the, the, the platform software

47:22.520 --> 47:26.280
and we compile it and we ship it, that there's a, there's an extensive amount of testing that needs to

47:26.280 --> 47:31.800
happen. So that, you know, if, if you're a customer and we're sending you these really cool new

47:31.800 --> 47:37.720
features, the thing you want this robot to do is vacuum your home. That's what you went and,

47:37.720 --> 47:43.240
and got this robot for. So that's the thing that we never want to compromise. And we make sure that

47:43.240 --> 47:49.400
the, the, any new features that, that we introduce, be them, uh, data scientific or not,

47:49.400 --> 47:53.720
is we have to go through this extensive, uh, battery of testing to make sure that the robot

47:53.720 --> 47:57.800
still functions and it's not going to, you know, act all crazy because it's hardware.

47:57.800 --> 48:01.880
It's not just that the zeros and ones are going to fly through the screen. No, the robot, uh,

48:01.880 --> 48:06.520
is, is a thing that can hit your puppy. So don't we definitely don't want that to happen ever?

48:06.520 --> 48:16.120
So, um, we don't have an over the air pipe that delivers just new model, uh, features. But what we do

48:16.120 --> 48:23.000
is we have this robust system for delivery both to factories and to customers. And that's all

48:23.000 --> 48:27.880
delivered through AWS, but it's not, uh, greengrass because that would be specifically just for model

48:27.880 --> 48:33.960
deployment. Well, Angela, thanks so much for taking the time to chat with me about, uh, just a little

48:33.960 --> 48:38.360
bit of what you've got going on there. It sounds like really interesting stuff and, and probably

48:38.360 --> 48:44.280
that we need to like follow up at some point to go into more detail. Yeah, that would be great.

48:44.280 --> 48:48.360
I love that. And thank you so much for the opportunity to turn around. Absolutely. Thanks Angela.

48:52.760 --> 48:57.160
All right, everyone. That's our show for today. If you like what you've heard,

48:57.160 --> 49:01.400
please do us a favor and tell your friends about the show. And if you haven't already

49:01.400 --> 49:06.280
hit that subscribe button yourself, make sure you do so you don't miss any of the great episodes

49:06.280 --> 49:36.120
we've got in store for you. As always, thanks so much for listening and catch you next time.

