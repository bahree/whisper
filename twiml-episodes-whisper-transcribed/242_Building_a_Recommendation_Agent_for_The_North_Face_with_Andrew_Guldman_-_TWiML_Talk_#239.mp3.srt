1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:31,640
I'm your host Sam Charrington.

4
00:00:31,640 --> 00:00:35,840
Today we're joined by Andrew Goldman, vice president of product engineering and research

5
00:00:35,840 --> 00:00:38,120
and development at Fluid.

6
00:00:38,120 --> 00:00:43,080
Andrew and I caught up a while back to discuss Fluid XPS, a user experience built to help

7
00:00:43,080 --> 00:00:49,080
the casual shopper decide on the best product choices during online retail interactions.

8
00:00:49,080 --> 00:00:53,960
The XPS has expanded since we recorded this interview, we specifically discuss its origins

9
00:00:53,960 --> 00:00:58,040
as a product to assist out-of-wear retailer the North Face.

10
00:00:58,040 --> 00:01:03,280
In our conversation, we discussed their use of heat sink algorithms and graph databases,

11
00:01:03,280 --> 00:01:07,720
their use of chat and other interfaces, and the challenges associated with staying on

12
00:01:07,720 --> 00:01:11,040
top of a constantly changing technology landscape.

13
00:01:11,040 --> 00:01:14,880
This was a fun interview.

14
00:01:14,880 --> 00:01:18,960
Before we jump into the episode, I'd like to join Pegasystems, this episode's sponsor

15
00:01:18,960 --> 00:01:24,520
and inviting you to meet me this June at Pegasworld, the company's annual digital transformation

16
00:01:24,520 --> 00:01:31,840
conference, so that it optimizes every customer touchpoint on every channel in real time.

17
00:01:31,840 --> 00:01:36,600
That way each interaction is relevant and timely to each individual customer, no matter

18
00:01:36,600 --> 00:01:41,520
if it's a sales call, a digital marketing campaign, or a customer service chat, either

19
00:01:41,520 --> 00:01:47,880
online or in-store, and the system is always learning in real time to make the next interaction

20
00:01:47,880 --> 00:01:49,520
better.

21
00:01:49,520 --> 00:01:52,120
Pegas Customers are the real stars at Pegasworld.

22
00:01:52,120 --> 00:01:57,400
There, you'll hear great stories of AI applied to the customer experience at real Pegas

23
00:01:57,400 --> 00:01:58,400
Customers.

24
00:01:58,400 --> 00:02:03,600
The event is a great way to learn from a who's who of the Fortune 500, and of course, I'll

25
00:02:03,600 --> 00:02:06,480
be there and speaking as well.

26
00:02:06,480 --> 00:02:13,120
To register, visit Pegasworld.com and enter the promo code Twimble19 when you sign up.

27
00:02:13,120 --> 00:02:16,320
Again, that's Twimble19, it's as easy as that.

28
00:02:16,320 --> 00:02:20,240
Hope to see you there, and now on to the show.

29
00:02:20,240 --> 00:02:23,640
All right, everyone.

30
00:02:23,640 --> 00:02:25,880
I am on the line with Andrew Goldman.

31
00:02:25,880 --> 00:02:30,160
Andrew is VP of Product Engineering and R&D at Fluid.

32
00:02:30,160 --> 00:02:33,240
Andrew, welcome to this weekend machine learning and AI.

33
00:02:33,240 --> 00:02:34,240
Thank you very much.

34
00:02:34,240 --> 00:02:35,240
Great to be here.

35
00:02:35,240 --> 00:02:42,320
So you've been at Fluid for about 18 years, not counting a brief hiatus that you can

36
00:02:42,320 --> 00:02:47,560
describe, but why don't you tell us about Fluid and the kind of work that you've done

37
00:02:47,560 --> 00:02:49,560
there over the past 18 years?

38
00:02:49,560 --> 00:02:50,560
Great.

39
00:02:50,560 --> 00:02:51,560
Thank you.

40
00:02:51,560 --> 00:03:00,120
So in general, Fluid focuses on providing excellent user experience for online retail,

41
00:03:00,120 --> 00:03:08,160
and Fluid has agency and software as a service divisions, and within both of those addressed

42
00:03:08,160 --> 00:03:13,880
engineering design, user experience and strategy, Fluid's clients include the North Face,

43
00:03:13,880 --> 00:03:21,360
and we'll be talking about shortly, Puma, Vans, Benefit, Cosmetics, and many, many others

44
00:03:21,360 --> 00:03:24,360
with offices in New York and in Oakland.

45
00:03:24,360 --> 00:03:26,960
So that's Fluid as a whole.

46
00:03:26,960 --> 00:03:33,440
My particular role at Fluid has been focused on engineering leadership, so I've worked

47
00:03:33,440 --> 00:03:37,480
in both the agency and software as a service side of the business.

48
00:03:37,480 --> 00:03:43,120
For the last several years, I've worked primarily on two big projects.

49
00:03:43,120 --> 00:03:49,680
One of them, Fluid Configure, online product configuration platform, and the other XPS,

50
00:03:49,680 --> 00:03:51,720
which we'll talk about in more detail.

51
00:03:51,720 --> 00:03:58,160
XPS stands for Expert Personal Shopper, applying AI technology to online retail.

52
00:03:58,160 --> 00:04:07,400
And XPS was a product or XPS was a project that Fluid created for and with the North Face.

53
00:04:07,400 --> 00:04:08,400
Is that right?

54
00:04:08,400 --> 00:04:11,960
Initially, yeah, they were our first customer with XPS.

55
00:04:11,960 --> 00:04:15,880
It's expanded a little beyond that, but they were the initial focus, yeah.

56
00:04:15,880 --> 00:04:17,440
Let's jump into that.

57
00:04:17,440 --> 00:04:22,160
Tell us about the general problem that you're trying to help these retailers solve.

58
00:04:22,160 --> 00:04:23,160
Sure, sure.

59
00:04:23,160 --> 00:04:24,160
Absolutely.

60
00:04:24,160 --> 00:04:29,560
We'll first just really brief encapsulation of the North Face in case people are unfamiliar

61
00:04:29,560 --> 00:04:31,240
with them.

62
00:04:31,240 --> 00:04:37,640
They provide top quality gear that's really designed and targeted towards climbers, runners

63
00:04:37,640 --> 00:04:39,640
and skiers.

64
00:04:39,640 --> 00:04:44,880
And of course, a good jacket for runners is also great for hikers and is also good for

65
00:04:44,880 --> 00:04:51,040
lifestyle and so on, but they're really targeted towards technical high quality gear.

66
00:04:51,040 --> 00:04:58,840
So what we were trying to do for the North Face, the genesis of XPS, was to help the more

67
00:04:58,840 --> 00:05:06,440
casual users figure out what to get from the North Face, you know, the really technical

68
00:05:06,440 --> 00:05:10,920
like the expert climber would probably know what they need in a jacket.

69
00:05:10,920 --> 00:05:15,440
But somebody who's going back backing for the first time might not really know quite

70
00:05:15,440 --> 00:05:16,440
what to get.

71
00:05:16,440 --> 00:05:21,320
And so we wanted to help them sort of help them sort of emulate the experience of working

72
00:05:21,320 --> 00:05:27,480
with a knowledgeable sales associate in a scalable online venue.

73
00:05:27,480 --> 00:05:32,320
I can relate very personally to that need right now.

74
00:05:32,320 --> 00:05:39,640
I am in the process of planning my first bike packing trip, which is basically camping,

75
00:05:39,640 --> 00:05:45,120
but kind of carrying your gear on a bike that's going to be later this month.

76
00:05:45,120 --> 00:05:52,800
And the array of stuff that the lists say that I need is immense and then kind of sorting

77
00:05:52,800 --> 00:06:00,160
through all of the different options for each of the various components is just, there's

78
00:06:00,160 --> 00:06:06,720
a lot of work that one needs to do to at least if you're like me and you want to kind of

79
00:06:06,720 --> 00:06:09,640
get the right thing, it's a lot of work.

80
00:06:09,640 --> 00:06:16,320
So I can definitely see why an online tool in particular one that's powered by some

81
00:06:16,320 --> 00:06:20,480
element of AI would be super helpful to folks.

82
00:06:20,480 --> 00:06:27,360
But exactly, so you're trying to build this tool, what is the, what is XPS provide?

83
00:06:27,360 --> 00:06:30,720
How does it kind of emulate this assistant?

84
00:06:30,720 --> 00:06:34,680
How does it emulate like a sales person at a store?

85
00:06:34,680 --> 00:06:40,600
In format, we adhere fairly closely to what would happen with the sales associate.

86
00:06:40,600 --> 00:06:45,880
You have a conversation, you know, there's questions and answers going back and forth.

87
00:06:45,880 --> 00:06:53,960
And through that conversation, the sales associate is accumulating important information, you

88
00:06:53,960 --> 00:06:55,480
know.

89
00:06:55,480 --> 00:07:01,920
And then as that information accumulates, that sales person's recommendation gets better

90
00:07:01,920 --> 00:07:02,920
and better.

91
00:07:02,920 --> 00:07:11,240
So what that means in the more technical world of XPS is that we have, we actually used

92
00:07:11,240 --> 00:07:20,040
graph database technology to represent the, we called them facts, just to be a fairly generic

93
00:07:20,040 --> 00:07:24,640
term that could be used across, to me, in different things at different times, you know,

94
00:07:24,640 --> 00:07:33,080
but like, you'd have this directed acyclic graph of facts that could be hierarchical that

95
00:07:33,080 --> 00:07:40,000
eventually connected to products and the edges in the graph had weight associated with

96
00:07:40,000 --> 00:07:41,000
them.

97
00:07:41,000 --> 00:07:50,520
So as a session with XPS proceeds, you're parsing XPS would parse the responses from the user

98
00:07:50,520 --> 00:07:56,680
if they came in via free text, or it could also work with button clicks if the answers

99
00:07:56,680 --> 00:07:59,360
were a little more directed.

100
00:07:59,360 --> 00:08:04,920
But either however they came in, it would result in weight being placed on nodes in the

101
00:08:04,920 --> 00:08:15,280
graph and then the directed graph, we used a heat sink algorithm to accumulate weight

102
00:08:15,280 --> 00:08:19,520
on the products and thereby derive the recommendations.

103
00:08:19,520 --> 00:08:22,320
What specifically is a heat sink algorithm?

104
00:08:22,320 --> 00:08:27,480
So a heat sink algorithm, if you have, you know, a directional graph where things, an

105
00:08:27,480 --> 00:08:34,800
acyclic graph where things point in a direction, just to look at a simple example without getting

106
00:08:34,800 --> 00:08:38,560
into hierarchy, you can consider product characteristics.

107
00:08:38,560 --> 00:08:45,520
So we're looking at North Face Jackets and you could say, okay, this jacket has color,

108
00:08:45,520 --> 00:08:46,520
right?

109
00:08:46,520 --> 00:08:49,600
So it can be red or it can be blue or it can be green or whatever.

110
00:08:49,600 --> 00:08:54,360
So you'd have an association sometimes people would have color preferences so you'd have

111
00:08:54,360 --> 00:09:01,920
an association, directed association from green to this particular jacket.

112
00:09:01,920 --> 00:09:07,440
So then if it comes out that I'm looking for a green jacket, I'd put weight on the green

113
00:09:07,440 --> 00:09:14,880
node in my session specifically and then that weight traverses the edge of the graph and

114
00:09:14,880 --> 00:09:18,800
ends up on, well, the multiple jackets that could be green, right?

115
00:09:18,800 --> 00:09:23,960
So green would be associated with an array of different jackets, all of which would receive

116
00:09:23,960 --> 00:09:26,760
weight from green.

117
00:09:26,760 --> 00:09:31,760
Then simultaneously, I'm looking for a waterproof jacket.

118
00:09:31,760 --> 00:09:34,240
So I put weight on waterproof.

119
00:09:34,240 --> 00:09:38,000
Waterproof is similarly associated with a collection of jackets.

120
00:09:38,000 --> 00:09:45,360
The weight derives from, or it travels from waterproof to all of those waterproof jackets.

121
00:09:45,360 --> 00:09:52,160
So we have some jackets that have accumulated heat or weight from green and others that

122
00:09:52,160 --> 00:09:56,120
have accumulated heat from waterproof.

123
00:09:56,120 --> 00:09:58,640
And so some jackets are hotter than others.

124
00:09:58,640 --> 00:10:02,280
The jackets that are both green and waterproof are the hottest ones.

125
00:10:02,280 --> 00:10:08,440
And so you have like multiple sources of heat, you know, the nodes that have been activated

126
00:10:08,440 --> 00:10:11,680
and then that heat accumulates on products.

127
00:10:11,680 --> 00:10:13,920
Where does AI come in in this project?

128
00:10:13,920 --> 00:10:20,200
What requirements did you have for artificial intelligence as you were building us out?

129
00:10:20,200 --> 00:10:25,040
Well, the artificial intelligence requirements were pretty high level.

130
00:10:25,040 --> 00:10:33,400
The initial genesis of the product was a partnership between IBM and Fluid for the benefit of

131
00:10:33,400 --> 00:10:35,120
the North Face.

132
00:10:35,120 --> 00:10:40,680
So the original idea was to use Watson to create this technology.

133
00:10:40,680 --> 00:10:46,640
But that's pretty broad, right?

134
00:10:46,640 --> 00:10:54,560
So as we dug in to implementing what I was describing there, the first attempt was just

135
00:10:54,560 --> 00:10:58,360
to use Watson as is.

136
00:10:58,360 --> 00:11:02,240
At the time though, this is way back at the beginning of Watson.

137
00:11:02,240 --> 00:11:07,760
This was, you know, a little bit after Watson had been used in the Jeopardy game show.

138
00:11:07,760 --> 00:11:08,760
Okay.

139
00:11:08,760 --> 00:11:10,160
And we have a lot of notoriety there.

140
00:11:10,160 --> 00:11:11,160
Right.

141
00:11:11,160 --> 00:11:16,520
But at the time it was a single API, it was this question and answer API that was really

142
00:11:16,520 --> 00:11:22,360
targeted towards the Jeopardy use case where it didn't, it didn't have the idea of context

143
00:11:22,360 --> 00:11:26,920
like I was describing where you accumulate knowledge through a conversation that really

144
00:11:26,920 --> 00:11:29,160
wasn't part of the game.

145
00:11:29,160 --> 00:11:34,920
And it also was designed to come back with a single answer, you know, because in Jeopardy,

146
00:11:34,920 --> 00:11:39,360
you don't say, oh, well, it could be this or that or that or that, it's just one answer.

147
00:11:39,360 --> 00:11:40,360
Right.

148
00:11:40,360 --> 00:11:41,360
Right.

149
00:11:41,360 --> 00:11:46,400
So the question answer API didn't really fit our use case.

150
00:11:46,400 --> 00:11:51,440
So that was when we started getting into this graph database business.

151
00:11:51,440 --> 00:12:00,080
So in the context of the solution I was describing, we initially used AI technology for natural

152
00:12:00,080 --> 00:12:07,040
language processing to try to make sense out of the utterances that users would provide

153
00:12:07,040 --> 00:12:08,680
to us.

154
00:12:08,680 --> 00:12:11,280
That was the initial piece.

155
00:12:11,280 --> 00:12:15,640
You know, what I was describing with the graph and everything was basically a content

156
00:12:15,640 --> 00:12:22,760
based recommendation engine that really doesn't use a lot of sophisticated AI techniques.

157
00:12:22,760 --> 00:12:29,960
We'd always had in mind to get to machine learning sort of collaborative filtering type

158
00:12:29,960 --> 00:12:32,680
techniques to improve the recommendations.

159
00:12:32,680 --> 00:12:37,160
But you know, as of now we're still, we're still waiting to get there.

160
00:12:37,160 --> 00:12:42,920
So it's been a little more focused on content based recommendations.

161
00:12:42,920 --> 00:12:50,400
The interface for XPS, is it a chat, I'm assuming it's a chatbot type of interface?

162
00:12:50,400 --> 00:12:59,720
And if so, are you using a platform technology to manage the chat interactions, you know,

163
00:12:59,720 --> 00:13:05,240
parse out the intents and all that kind of stuff, are you doing that manually?

164
00:13:05,240 --> 00:13:12,880
So at the highest level it is a chat interface and it's super compatible with things like

165
00:13:12,880 --> 00:13:17,240
Facebook Messenger and we have implemented it on Facebook Messenger, but it doesn't

166
00:13:17,240 --> 00:13:20,680
require a dedicated chat platform like that.

167
00:13:20,680 --> 00:13:25,320
It runs just fine in a standard browser as well.

168
00:13:25,320 --> 00:13:29,280
So it's pretty flexible in how it can be deployed.

169
00:13:29,280 --> 00:13:36,000
We initially, when we were building this out, the supporting technology to manage the

170
00:13:36,000 --> 00:13:40,840
conversation for us was not super satisfactory.

171
00:13:40,840 --> 00:13:42,920
So we sort of built our own deal.

172
00:13:42,920 --> 00:13:52,280
In the meantime, since then, we've evaluated other technologies like IDM Assistant, which

173
00:13:52,280 --> 00:13:59,120
do a lot of the same things that we've been doing and have a lot of advantages, just

174
00:13:59,120 --> 00:14:07,400
the training capabilities they have, the ability to understand intents as well as entities,

175
00:14:07,400 --> 00:14:13,560
the ability to impact the behavior of the conversation, you know, to change the flow,

176
00:14:13,560 --> 00:14:19,680
the conversation, have it work better without having to do any coding, it was really attractive.

177
00:14:19,680 --> 00:14:28,360
So what we're sort of in the process now of incorporating watts and Assistant into

178
00:14:28,360 --> 00:14:35,400
XPS, sort of as complimentary pieces, if you want to go into a little more detail about

179
00:14:35,400 --> 00:14:42,400
how XPS guides a conversation relative to how watts and Assistant does, they have fundamentally

180
00:14:42,400 --> 00:14:45,600
different approaches, which can work well together.

181
00:14:45,600 --> 00:14:46,600
Sure.

182
00:14:46,600 --> 00:14:47,600
Had that direction?

183
00:14:47,600 --> 00:14:48,600
All right.

184
00:14:48,600 --> 00:14:54,160
No, that's interesting, because you mentioned using them in conjunction with one another

185
00:14:54,160 --> 00:15:03,360
and I was starting to form a question around how that's going to work, so to start with

186
00:15:03,360 --> 00:15:08,120
watts and Assistant, I mean, that's fairly, there's a whole sort of family of technologies

187
00:15:08,120 --> 00:15:11,920
that operate in fairly similar ways.

188
00:15:11,920 --> 00:15:20,120
And they parse intents based on the intent that's been identified, can parse out entities,

189
00:15:20,120 --> 00:15:25,880
and so you can do things, you know, a customer service, it can understand that you're trying

190
00:15:25,880 --> 00:15:32,160
to track and order to be your intent, for example, and then it can know that in order

191
00:15:32,160 --> 00:15:36,080
to track and order, it needs to have an order number, right?

192
00:15:36,080 --> 00:15:40,720
And so it can try to parse the order number from what you've said, or if it doesn't get

193
00:15:40,720 --> 00:15:45,640
it, it can solicit the order number, once it has that, then it can move forward.

194
00:15:45,640 --> 00:15:53,240
And so you've got this sort of structure of intents with related entities, and it can

195
00:15:53,240 --> 00:15:59,160
guide a conversation that way, it can solicit what it needs based on what the intent is.

196
00:15:59,160 --> 00:16:02,920
So that's kind of the watts and Assistant approach.

197
00:16:02,920 --> 00:16:09,960
XPS, on the other hand, is much more, is intended to be much more sort of directive and focused

198
00:16:09,960 --> 00:16:18,320
and purposeful and flexible in what it's doing, like its sole purpose is to recommend products.

199
00:16:18,320 --> 00:16:23,400
So you've got a potentially confusing collection of products, you know, like all these jackets,

200
00:16:23,400 --> 00:16:26,800
so many jackets, there's like 20 kinds of ski jackets, what the hell, you know, right?

201
00:16:26,800 --> 00:16:32,160
So there's all these products with the intention of recommending the right ones.

202
00:16:32,160 --> 00:16:40,440
And the watts and Assistant approach tends to lead the order in which information is solicited,

203
00:16:40,440 --> 00:16:42,160
is somewhat fixed.

204
00:16:42,160 --> 00:16:45,560
You know, if you're looking for an order, you get the order number.

205
00:16:45,560 --> 00:16:50,800
Whereas within the jacket recommendation world, there's a lot of different things that

206
00:16:50,800 --> 00:16:52,360
you could be soliciting.

207
00:16:52,360 --> 00:16:56,920
You know, there's how it behaves in certain types of weather, you know, how it does relative

208
00:16:56,920 --> 00:17:03,080
to wind and rain and temperature, there's color, there's breathability, you know, on and

209
00:17:03,080 --> 00:17:09,200
on and on, like the number of questions that could potentially be asked is big.

210
00:17:09,200 --> 00:17:15,080
And if you ask them in the wrong order, it doesn't appear very intelligent.

211
00:17:15,080 --> 00:17:23,800
So our one of probably our core challenges of XPS was guiding the dialogue in a way that

212
00:17:23,800 --> 00:17:28,200
would allow it to make the best recommendations the quickest.

213
00:17:28,200 --> 00:17:34,080
So we incorporated kind of a taking that heat sink idea that I was talking about earlier

214
00:17:34,080 --> 00:17:39,520
where you figure out what price recommend based on the information, you know, we kind

215
00:17:39,520 --> 00:17:47,120
of flip that on its head and use like a complementary idea of hypothetically saying, well, if we

216
00:17:47,120 --> 00:17:49,760
knew this, how helpful would it be?

217
00:17:49,760 --> 00:17:53,120
If we knew that, how helpful would it be?

218
00:17:53,120 --> 00:18:00,280
Combining that with the natural collections, you know, natural groupings of these facts,

219
00:18:00,280 --> 00:18:06,880
you know, like if you're saying like, is it, is it good in mild wind or high wind or calm

220
00:18:06,880 --> 00:18:13,320
or whatever, if you're looking at the wind speed collection of facts, well, that condenses

221
00:18:13,320 --> 00:18:15,880
nicely to a single question.

222
00:18:15,880 --> 00:18:19,200
You don't have to ask three separate questions, you know, it's like, how windy is it going

223
00:18:19,200 --> 00:18:20,200
to be?

224
00:18:20,200 --> 00:18:23,560
And perhaps your answers are buttons if you want or it could be free text, whatever, whatever

225
00:18:23,560 --> 00:18:24,560
you want, right?

226
00:18:24,560 --> 00:18:30,440
But if we've decided based on analyzing all of these different facts and running them

227
00:18:30,440 --> 00:18:36,360
through these scenarios, we decide we care about wind is the most important thing to

228
00:18:36,360 --> 00:18:38,680
influence our recommendation.

229
00:18:38,680 --> 00:18:43,760
And we ask about wind, you know, if we get to another point in a different conversation

230
00:18:43,760 --> 00:18:48,760
with a different user, maybe based on what they've told us, it's more important to ask

231
00:18:48,760 --> 00:18:53,040
about color to differentiate the candidate product set.

232
00:18:53,040 --> 00:18:59,000
The way I would describe the algorithm that you're describing is along the lines of it's

233
00:18:59,000 --> 00:19:05,760
trying to maximize information gain per question asked or something like that.

234
00:19:05,760 --> 00:19:11,640
Basically, I mean, the way that we phrase it is differentiating the candidate product

235
00:19:11,640 --> 00:19:16,360
set, you know, like we have based on what we currently know, we know that there's a set

236
00:19:16,360 --> 00:19:19,440
of products that are suitable.

237
00:19:19,440 --> 00:19:28,040
And what we really want to do with the next question is chop that set in half and be more

238
00:19:28,040 --> 00:19:30,800
confident about half of it.

239
00:19:30,800 --> 00:19:31,800
You know what I mean?

240
00:19:31,800 --> 00:19:37,400
We kind of simplified the challenge to try to make it more consistent.

241
00:19:37,400 --> 00:19:40,280
We found that taking that approach worked pretty well.

242
00:19:40,280 --> 00:19:46,800
So that's how we scored each one of these potential questions to ask, did how much does

243
00:19:46,800 --> 00:19:50,680
it split the results set in half and how much does it increase the confidence of one

244
00:19:50,680 --> 00:19:51,920
of those halves?

245
00:19:51,920 --> 00:19:58,480
How complex is the algorithm excited that is there a pre-existing algorithm that's known

246
00:19:58,480 --> 00:20:03,840
to solve that kind of problem or did you have to kind of invent something from scratch?

247
00:20:03,840 --> 00:20:06,720
We invented stuff.

248
00:20:06,720 --> 00:20:07,720
We invented stuff.

249
00:20:07,720 --> 00:20:10,000
We were working.

250
00:20:10,000 --> 00:20:14,120
This was logic that ran in the graph database.

251
00:20:14,120 --> 00:20:17,840
We were using TinkerPop APIs.

252
00:20:17,840 --> 00:20:19,160
It's TinkerPop APIs.

253
00:20:19,160 --> 00:20:20,160
Yes.

254
00:20:20,160 --> 00:20:22,040
Yeah, I don't know where they came up with that name.

255
00:20:22,040 --> 00:20:26,960
It's standardizing the way that you can interact with graph databases.

256
00:20:26,960 --> 00:20:32,080
It's sort of like JDBC is to relational databases.

257
00:20:32,080 --> 00:20:35,240
TinkerPop is to graph databases.

258
00:20:35,240 --> 00:20:37,080
So it's a set of standardized APIs.

259
00:20:37,080 --> 00:20:42,680
We were initially working with Neo4j and we moved over to Titan.

260
00:20:42,680 --> 00:20:46,800
The graph database space is quite volatile.

261
00:20:46,800 --> 00:20:52,400
It was nice to have this sort of standard API to work with.

262
00:20:52,400 --> 00:20:59,120
We were writing Java code that used TinkerPop APIs to interact with the graph.

263
00:20:59,120 --> 00:21:01,320
It was sort of like streaming APIs.

264
00:21:01,320 --> 00:21:06,720
If you work with Java collections and you start streaming them and then you do one thing

265
00:21:06,720 --> 00:21:10,040
to them and then you get a stream back and you do another thing to them and you kind

266
00:21:10,040 --> 00:21:11,800
of chain these calls together.

267
00:21:11,800 --> 00:21:19,200
It's just sort of typical sort of a Lambda type flow within Java.

268
00:21:19,200 --> 00:21:25,360
So you do things like you get your set of facts and then you filter it based on the ones

269
00:21:25,360 --> 00:21:29,920
that have weight and then you see where they point and what the edge weights are and you

270
00:21:29,920 --> 00:21:33,760
calculate the accumulated weight and you filter again.

271
00:21:33,760 --> 00:21:40,600
Anyway, all these sort of traversals and streaming stuff in Java.

272
00:21:40,600 --> 00:21:43,040
So yeah, we had to write this code.

273
00:21:43,040 --> 00:21:49,160
We basically would look at the, you take the original set of recommended products, then

274
00:21:49,160 --> 00:21:56,200
you'd apply hypothetical weight to a single fact and then you'd see what the result of

275
00:21:56,200 --> 00:22:03,160
that was in this new result set and then you'd just repeat that process for any of the facts

276
00:22:03,160 --> 00:22:09,840
that you could consider asking about and then you'd just compare the sort of the weighting

277
00:22:09,840 --> 00:22:15,760
of the results, the recommended products and see which one had the profile that most

278
00:22:15,760 --> 00:22:22,080
closely matched, chopping the original set in half and increasing its confidence.

279
00:22:22,080 --> 00:22:27,760
And so was your product catalog space or there are the intersection of your product catalog

280
00:22:27,760 --> 00:22:37,360
space and the characteristic space such that you could do that calculation all in real time

281
00:22:37,360 --> 00:22:41,680
or did you have to pre-compute some of it or could you pre-compute some of it?

282
00:22:41,680 --> 00:22:50,080
It was all real time, yeah, the graph database ran quickly, I mean that was one of the reasons

283
00:22:50,080 --> 00:22:52,080
we chose that technology.

284
00:22:52,080 --> 00:22:59,480
The traversals are really, really fast and the accumulation of calculations as you navigate

285
00:22:59,480 --> 00:23:03,680
as you traverse through the graph could happen really, really quickly too.

286
00:23:03,680 --> 00:23:11,400
You build this algorithm that allows you to direct questioning in a way that helps a

287
00:23:11,400 --> 00:23:19,440
user kind of iterate as quickly as possible to a single product or a small set of products

288
00:23:19,440 --> 00:23:27,840
that they're interested in but you still see their opportunities to use that in parallel

289
00:23:27,840 --> 00:23:32,000
with the Watson platform, how would those work together?

290
00:23:32,000 --> 00:23:37,600
Yeah, yeah, good, yeah, that was what I was supposed to be describing before, right?

291
00:23:37,600 --> 00:23:48,600
I was describing these different mechanisms for driving a conversation with Watson Assistant

292
00:23:48,600 --> 00:23:55,640
having this intent and entities approach versus what I was describing with XPS and so

293
00:23:55,640 --> 00:24:03,640
the way they fit together nicely is that if you have, if the utterance can be, if Watson

294
00:24:03,640 --> 00:24:10,080
Assistant can get some traction with the user's utterance, then you let it do its thing.

295
00:24:10,080 --> 00:24:16,120
So if it says, oh, this is customer service, I got this, then XPS isn't going to be able

296
00:24:16,120 --> 00:24:19,600
to handle that, no, that's not what XPS does.

297
00:24:19,600 --> 00:24:24,680
And so if Watson Assistant was able to figure out that it could do some with it, then it

298
00:24:24,680 --> 00:24:25,880
does some with it.

299
00:24:25,880 --> 00:24:32,440
So Watson Assistant is kind of the initial recipient of the request.

300
00:24:32,440 --> 00:24:39,320
And then if Watson Assistant either identifies that it's not an XPS could deal with or it

301
00:24:39,320 --> 00:24:44,040
just doesn't know what the heck is going on, then XPS takes a cut at it.

302
00:24:44,040 --> 00:24:50,400
Yeah, it sounds like if you walk into a store, there's a greeter there that greeter is

303
00:24:50,400 --> 00:24:51,400
Watson Assistant.

304
00:24:51,400 --> 00:24:55,240
If you have a customer service question, they'll walk you over to the CS desk and kind of figure

305
00:24:55,240 --> 00:24:56,240
that out.

306
00:24:56,240 --> 00:24:59,840
But if you want to buy something, they'll kind of direct you to a salesperson and that's

307
00:24:59,840 --> 00:25:00,840
XPS.

308
00:25:00,840 --> 00:25:01,840
Exactly, exactly.

309
00:25:01,840 --> 00:25:06,600
Because what we found, I mean, this is pretty obvious if you think about it really, but

310
00:25:06,600 --> 00:25:10,720
you know, when people come into like a chatbot experience, they don't all want to do

311
00:25:10,720 --> 00:25:15,240
what you want them to do, you know, they're like, they're checking it out.

312
00:25:15,240 --> 00:25:16,960
They're like, oh, what is this thing?

313
00:25:16,960 --> 00:25:22,520
And XPS was really not very good at handling this broad array of things that were coming

314
00:25:22,520 --> 00:25:23,520
up.

315
00:25:23,520 --> 00:25:24,520
People just chatting.

316
00:25:24,520 --> 00:25:30,360
People were like, hi, you know, an XPS didn't really know what to do with hi, you know.

317
00:25:30,360 --> 00:25:31,360
Right.

318
00:25:31,360 --> 00:25:32,360
Right.

319
00:25:32,360 --> 00:25:33,360
Right.

320
00:25:33,360 --> 00:25:42,160
I'm curious about the software development process and specifically the idea of incorporating

321
00:25:42,160 --> 00:25:51,160
in these, you know, external AI-centric APIs and any ways that maybe you had to think differently

322
00:25:51,160 --> 00:25:58,160
about the development process, you know, relative to other kinds of projects.

323
00:25:58,160 --> 00:26:04,280
Well, I think the big difference is that the, you know, the AI technologies we were using

324
00:26:04,280 --> 00:26:09,880
like Watson Assistant and to a lesser extent some of the NLP stuff we were using, it's

325
00:26:09,880 --> 00:26:14,240
not like, you know, talking to weather underground and getting back the weather, you know what

326
00:26:14,240 --> 00:26:15,240
I mean?

327
00:26:15,240 --> 00:26:18,760
You have to train them, you have to prep them up, you know.

328
00:26:18,760 --> 00:26:30,640
So there was this body of work that typically is best handled by experts to get the corpus,

329
00:26:30,640 --> 00:26:34,880
get the service ready to do what we needed it to do.

330
00:26:34,880 --> 00:26:39,480
And just needing that different skill set definitely presented challenges for us.

331
00:26:39,480 --> 00:26:48,160
You know, our team was really a team of software engineers and the idea of using APIs at runtime

332
00:26:48,160 --> 00:26:54,400
was super comfortable, but the idea of needing to train a service so that it would recognize

333
00:26:54,400 --> 00:26:57,680
certain intents was pretty foreign.

334
00:26:57,680 --> 00:27:03,480
And just because of staffing challenges, the engineers typically had to kind of step into

335
00:27:03,480 --> 00:27:08,240
that role of training these systems.

336
00:27:08,240 --> 00:27:16,720
And so did you have to build out specific processes and tooling to enable that to be done

337
00:27:16,720 --> 00:27:17,720
successfully?

338
00:27:17,720 --> 00:27:24,360
Um, I mean, I don't know if it was really that formal, it was basically like people were

339
00:27:24,360 --> 00:27:28,400
obligated to do it and so they did it and as they did it, they got better at it.

340
00:27:28,400 --> 00:27:33,960
You know, the tooling was already present, you know, like there's Watson Knowledge Studio

341
00:27:33,960 --> 00:27:40,480
comes as part of the package, which is, you know, great tooling sophisticated at this

342
00:27:40,480 --> 00:27:41,480
point.

343
00:27:41,480 --> 00:27:43,360
It's mature works really well.

344
00:27:43,360 --> 00:27:46,920
So we fortunately didn't didn't have to address that part of a puzzle.

345
00:27:46,920 --> 00:27:54,240
I mean, we were looking, we played around at different times with just manually using

346
00:27:54,240 --> 00:27:59,760
Watson Knowledge Studio to do the training versus trying to do it via APIs.

347
00:27:59,760 --> 00:28:03,320
You know, and we hit our heads on walls every once in a while when we would try to do our

348
00:28:03,320 --> 00:28:08,960
own automation is generally work better to like do it the way they sort of want you to

349
00:28:08,960 --> 00:28:15,680
do it, which is more manually or less or yeah, exactly a little bit more manually.

350
00:28:15,680 --> 00:28:23,120
In the case of WKS Watson Knowledge Studio, it was easier to just go into their UI, do

351
00:28:23,120 --> 00:28:24,120
their thing.

352
00:28:24,120 --> 00:28:30,560
I mean, that's continually progressing, which actually I think is another way that this

353
00:28:30,560 --> 00:28:34,880
type of work was a little different than the work that we were accustomed to doing.

354
00:28:34,880 --> 00:28:36,280
What's that?

355
00:28:36,280 --> 00:28:41,240
Well, like just this exact thing you were talking about, like trying to script, trying to

356
00:28:41,240 --> 00:28:47,160
interact programmatically with some of these services would change, it would change way

357
00:28:47,160 --> 00:28:49,320
more quickly than we were accustomed to.

358
00:28:49,320 --> 00:28:53,680
There'd be new vendors offering things that were better from one week to the next, you

359
00:28:53,680 --> 00:28:57,760
know, WKS would have a big iteration and things would change around and things that weren't

360
00:28:57,760 --> 00:29:01,080
possible previously were now possible.

361
00:29:01,080 --> 00:29:07,040
There'd be discontinued practice like, like Watson Assistant went from being Watson dialogue

362
00:29:07,040 --> 00:29:13,000
to Watson conversation to Watson Assistant and if through each step of that, there were

363
00:29:13,000 --> 00:29:14,600
major changes.

364
00:29:14,600 --> 00:29:22,520
So it's just such a like booming in a live field, sometimes it's just like ground is constantly

365
00:29:22,520 --> 00:29:24,760
shifting under us.

366
00:29:24,760 --> 00:29:31,000
And so we had to incorporate into our normal development process.

367
00:29:31,000 --> 00:29:36,640
This idea of sort of continually having spikes where we were doing research about things

368
00:29:36,640 --> 00:29:42,600
that we had already researched, you know, there had to be kind of a lot more time and energy

369
00:29:42,600 --> 00:29:48,160
put into staying abreast with the current technologies.

370
00:29:48,160 --> 00:29:52,040
And we also incorporated short, really short sprints.

371
00:29:52,040 --> 00:29:58,760
We're on a weekly sprint cycle on this project throughout throughout its whole life cycle.

372
00:29:58,760 --> 00:30:02,800
At the beginning, we thought it was going to be a temporarily short sprint cycle, but

373
00:30:02,800 --> 00:30:07,240
we found that we continuously were needing to like adjust course, you know, we'd learn

374
00:30:07,240 --> 00:30:11,680
something new, we get some new feedbacks, there'd be some new technology and we're continually

375
00:30:11,680 --> 00:30:16,720
just kind of let's say zigzagging because we were generally playing in the same direction

376
00:30:16,720 --> 00:30:24,480
of the significant, you know, adjustments to the approach on a almost on a weekly basis.

377
00:30:24,480 --> 00:30:32,840
Yeah, but at the same time, it sounds like you were able to successfully get this done

378
00:30:32,840 --> 00:30:40,280
with a traditional engineering team, whereas if you were, you know, needing to build all

379
00:30:40,280 --> 00:30:47,880
of the AI and LP conversational bits from scratch, it may have been a bit harder.

380
00:30:47,880 --> 00:30:50,480
Yeah, absolutely, absolutely.

381
00:30:50,480 --> 00:30:51,480
Yeah.

382
00:30:51,480 --> 00:30:56,880
And the degree of maturation in the space that we saw in the, you know, couple of years

383
00:30:56,880 --> 00:31:02,760
we spent building it was just amazing, you know, it would have been awesome if it could

384
00:31:02,760 --> 00:31:07,520
have been at the place it is now two years ago, it made our lives a lot easier, but we

385
00:31:07,520 --> 00:31:11,600
you know, perhaps gained a deeper appreciation of the advances.

386
00:31:11,600 --> 00:31:20,080
How did you address like the testing part of the development cycle and understanding, you

387
00:31:20,080 --> 00:31:26,280
know, did you try to create some kind of regression testing for the training process?

388
00:31:26,280 --> 00:31:32,000
So you knew if you kind of broke something in training, that kind of thing.

389
00:31:32,000 --> 00:31:33,000
Right.

390
00:31:33,000 --> 00:31:34,000
Great question.

391
00:31:34,000 --> 00:31:41,000
Kind of mapping this, you know, traditional dev process to this, you know, AI enhanced,

392
00:31:41,000 --> 00:31:43,000
let's say, dev process.

393
00:31:43,000 --> 00:31:44,000
Yeah.

394
00:31:44,000 --> 00:31:45,000
Yeah.

395
00:31:45,000 --> 00:31:46,000
Yeah.

396
00:31:46,000 --> 00:31:49,200
You know, I'm afraid my answer is going to be a little bit of a cop out here.

397
00:31:49,200 --> 00:31:54,160
We were looking at this, finding the right balance between delivering stuff quickly for

398
00:31:54,160 --> 00:32:02,040
a small number of customers in this constantly shifting space versus having a solution that

399
00:32:02,040 --> 00:32:06,680
was really solid and scalable and we'd be able to use for 50 customers, you know, there

400
00:32:06,680 --> 00:32:09,760
was this real tension between that.

401
00:32:09,760 --> 00:32:16,880
And as you say, it's directly attributable to applying sort of traditional web software

402
00:32:16,880 --> 00:32:23,720
development, multi tenant software as a service practices to this AI space.

403
00:32:23,720 --> 00:32:34,000
So, you know, we, we just kind of did the best we could, we had thorough regression tests

404
00:32:34,000 --> 00:32:37,920
around the more traditional parts of our code base.

405
00:32:37,920 --> 00:32:43,600
You know, we had thorough unit tests, test coverage metrics and all that kind of stuff

406
00:32:43,600 --> 00:32:51,280
around the express application and around our react front ends and stuff like that.

407
00:32:51,280 --> 00:33:01,600
And it came to the Watson assistant pieces and the NLP training, it was a little softer.

408
00:33:01,600 --> 00:33:03,640
It was a little softer.

409
00:33:03,640 --> 00:33:09,520
We were intending to button that up a little better as we move forward.

410
00:33:09,520 --> 00:33:14,400
And we're expecting, you know, given the pace of evolution of the tools, we're expecting

411
00:33:14,400 --> 00:33:17,640
that it's going to be easier to do that going forward.

412
00:33:17,640 --> 00:33:22,680
You know, it was like Watson knowledge studio advance, we're expecting to be able to script

413
00:33:22,680 --> 00:33:29,960
the training more thoroughly and tie that scripted training to testing the results of it

414
00:33:29,960 --> 00:33:31,960
more thoroughly.

415
00:33:31,960 --> 00:33:37,640
But it's really tricky because not only is potentially our training set changing, but

416
00:33:37,640 --> 00:33:42,040
also, you know, like Watson assistant is a service we're relying on that's constantly

417
00:33:42,040 --> 00:33:43,040
evolving.

418
00:33:43,040 --> 00:33:45,280
So it could be that our training data stays the same.

419
00:33:45,280 --> 00:33:49,240
But the results change, even though we can't change anything.

420
00:33:49,240 --> 00:33:56,000
And so we didn't get too obsessed with buttoning that up at this point in the process.

421
00:33:56,000 --> 00:33:57,000
Right.

422
00:33:57,000 --> 00:34:01,320
Embrace the chaos to a certain extent.

423
00:34:01,320 --> 00:34:06,920
You know, and I think an important sort of corollary to that is that, you know, we're

424
00:34:06,920 --> 00:34:09,080
not sending rockets into space, right?

425
00:34:09,080 --> 00:34:12,600
And we're not automating million dollars trading, right?

426
00:34:12,600 --> 00:34:13,920
We're recommending jackets.

427
00:34:13,920 --> 00:34:20,960
And so we, we kind of leveled the appropriate appetite for risk with the domain.

428
00:34:20,960 --> 00:34:26,480
You know, if something goes awry with the training of Watson assistant and it's not quite

429
00:34:26,480 --> 00:34:31,320
right, well, you know, we can tolerate that.

430
00:34:31,320 --> 00:34:38,520
So, you know, we, we do our best.

431
00:34:38,520 --> 00:34:40,920
Where did the training data come from?

432
00:34:40,920 --> 00:34:49,480
We have thorough analytics built into XPS so that we keep track of every step of every user's

433
00:34:49,480 --> 00:34:52,480
interaction with the service.

434
00:34:52,480 --> 00:34:59,560
And we're able to use the utterances that we captured from users throughout the process.

435
00:34:59,560 --> 00:35:06,160
So there's, there's a manual step to it in that the taking the data from our analytics

436
00:35:06,160 --> 00:35:10,400
system and feeding it in to Watson knowledge studio.

437
00:35:10,400 --> 00:35:16,560
There were some manual processing involved with it, especially around the ground truth.

438
00:35:16,560 --> 00:35:21,160
You know, like we could have automated feeding in all the utterances, but it would have

439
00:35:21,160 --> 00:35:26,200
been a little trickier to say what the correct responses should have been.

440
00:35:26,200 --> 00:35:33,760
But we did have the advantage of accumulating a large amount of real data and being able

441
00:35:33,760 --> 00:35:38,400
to use that throughout the process.

442
00:35:38,400 --> 00:35:47,000
And from the perspective of the engineers that were working on this, what was their experience

443
00:35:47,000 --> 00:35:52,840
like did they feel like they had to become data scientists in order to be successful

444
00:35:52,840 --> 00:35:53,840
with this project?

445
00:35:53,840 --> 00:36:00,840
Or, you know, was there a good balance between the APIs taking care of, you know, the deep

446
00:36:00,840 --> 00:36:07,760
algorithmic bits in them, you know, doing the higher level training stuff, the integration

447
00:36:07,760 --> 00:36:09,760
and the traditional engineering tasks?

448
00:36:09,760 --> 00:36:11,760
Yeah, a good question.

449
00:36:11,760 --> 00:36:19,800
You know, there was a, on the one hand, the engineering team were, were somewhat generalists

450
00:36:19,800 --> 00:36:25,640
who really enjoyed being exposed to new ideas and new technologies.

451
00:36:25,640 --> 00:36:29,880
You know, so like in the course of this project, some of the people on the team were learning

452
00:36:29,880 --> 00:36:33,120
react and redux for the first time, for example.

453
00:36:33,120 --> 00:36:34,120
Okay.

454
00:36:34,120 --> 00:36:38,360
But the entire team was learning about the Watts and APIs for the first time.

455
00:36:38,360 --> 00:36:42,600
And so being exposed to new technologies like that was awesome.

456
00:36:42,600 --> 00:36:47,800
And I think there's just the idea of understanding and being exposed to the role of a data scientist

457
00:36:47,800 --> 00:36:53,080
and how that compares to software engineering and being in a situation where they were forced

458
00:36:53,080 --> 00:36:57,080
to kind of be a little bit more immersed in that data science role than they ordinarily

459
00:36:57,080 --> 00:36:58,080
would have been.

460
00:36:58,080 --> 00:37:03,440
I think that was, that broadened horizons and was welcomed.

461
00:37:03,440 --> 00:37:10,040
At the same time, I think there were kind of, you know, they reached kind of a saturation

462
00:37:10,040 --> 00:37:16,840
point where like having to deal with the fact that it wasn't, you know, recognizing,

463
00:37:16,840 --> 00:37:20,920
you know, the difference between, you know, there are some examples of these things, you

464
00:37:20,920 --> 00:37:27,080
know, there are certain utterances that just cause problems like, yeah, just like negation

465
00:37:27,080 --> 00:37:28,080
is a simple one.

466
00:37:28,080 --> 00:37:34,960
You know, I want a jacket that's not green or you could say that anything but green,

467
00:37:34,960 --> 00:37:42,160
you know, and recognizing these negations correctly can involve some extensive training.

468
00:37:42,160 --> 00:37:49,800
Some of the language around that is fairly ambiguous to the untrained NLP system.

469
00:37:49,800 --> 00:37:56,880
And so like having to go back in and like, oh, anything but green, why isn't that working?

470
00:37:56,880 --> 00:37:57,880
How are we going to train that?

471
00:37:57,880 --> 00:38:04,320
Like that wasn't generally the developer's favorite part of the job, you know, yeah, so

472
00:38:04,320 --> 00:38:09,160
I think at the abstract level, the idea of understanding data science and how that fits

473
00:38:09,160 --> 00:38:14,200
into the process and how these AI technologies really work was awesome and they loved it,

474
00:38:14,200 --> 00:38:19,440
but they kind of had enough after a while.

475
00:38:19,440 --> 00:38:26,280
And kind of end of the day, how was the project received from the North Face's perspective,

476
00:38:26,280 --> 00:38:28,440
customer perspective?

477
00:38:28,440 --> 00:38:34,600
Well, it was certainly understood from the get go that this was kind of bleeding edge

478
00:38:34,600 --> 00:38:41,360
stuff, you know, that we were figuring this out on the fly and giving it a go.

479
00:38:41,360 --> 00:38:48,000
So the like the format and the vision of it, I think, was awesome, you know, they really

480
00:38:48,000 --> 00:38:49,000
like that.

481
00:38:49,000 --> 00:38:55,200
One of the challenges that we met with the North Face that honestly surprised me was

482
00:38:55,200 --> 00:39:01,280
the product attribution turned out to be surprisingly challenging.

483
00:39:01,280 --> 00:39:09,720
I had assumed that the North Face would have really thorough, like facets, faceted characteristics

484
00:39:09,720 --> 00:39:13,480
of their jackets that would provide us with all the raw material that we would need

485
00:39:13,480 --> 00:39:18,960
in order to differentiate them through a conversation, but we found two challenges in

486
00:39:18,960 --> 00:39:19,960
that.

487
00:39:19,960 --> 00:39:26,040
One is that the the existing faceted search capability that you see, you know, basically

488
00:39:26,040 --> 00:39:30,800
across the commerce landscape is really good, you know, like if, if you want to just sort

489
00:39:30,800 --> 00:39:35,240
of check boxes and say, I need a jacket that's waterproof, I need a jacket that's green,

490
00:39:35,240 --> 00:39:38,560
like you don't need this conversational interface to do that.

491
00:39:38,560 --> 00:39:44,640
You can just click, click, see it, you know, that's like, so that is so surprised you said

492
00:39:44,640 --> 00:39:49,760
is really good because in my head, as you were saying that I was thinking is really horrible

493
00:39:49,760 --> 00:39:56,920
I guess in some places it's implemented better than others is probably the best way to

494
00:39:56,920 --> 00:39:57,920
say that.

495
00:39:57,920 --> 00:40:02,320
I mean, I think of like kayak.com, you know, when you're searching for flights or

496
00:40:02,320 --> 00:40:06,040
hotels or something, you know, I'm like, to me, that's awesome, you know, just it's

497
00:40:06,040 --> 00:40:09,200
really nice, like, but you're absolutely, of course, you're right.

498
00:40:09,200 --> 00:40:14,840
I mean, it's not implemented well across the board, but the idea has been articulated

499
00:40:14,840 --> 00:40:18,640
successfully in certain cases.

500
00:40:18,640 --> 00:40:27,880
So we deliberately did not want this conversational experience to be perceived as like a watered

501
00:40:27,880 --> 00:40:30,840
down version of a faceted search.

502
00:40:30,840 --> 00:40:31,840
Right.

503
00:40:31,840 --> 00:40:38,960
And so part of that sort of necessitated that we have facets, you know, we have product

504
00:40:38,960 --> 00:40:44,960
attributes that are different, you know, there's kind of qualitatively different.

505
00:40:44,960 --> 00:40:49,440
And so we started looking, you know, experimented around with different things, you know, like

506
00:40:49,440 --> 00:40:55,880
more emotional type attributes where you'd say, like, I want an adventurous jacket.

507
00:40:55,880 --> 00:41:01,760
Well, like, what does that even mean on one, you know, but if you could, if you could

508
00:41:01,760 --> 00:41:07,120
somehow capture that and kind of represent that or, you know, like, like the personality

509
00:41:07,120 --> 00:41:14,160
of the shopper can translate into like finding jackets that match that personality, whether

510
00:41:14,160 --> 00:41:21,000
it's adventurous or studious or whatever it may be, you know, so we spent some time kind

511
00:41:21,000 --> 00:41:28,280
of exploring that in order to really maximize the conversational benefits.

512
00:41:28,280 --> 00:41:29,920
And that proved to be difficult.

513
00:41:29,920 --> 00:41:34,880
I can't say we hit, hit it out of a park with that piece.

514
00:41:34,880 --> 00:41:42,000
So there's, there's clearly room for more progress, like identifying what, how to make

515
00:41:42,000 --> 00:41:50,120
this more satisfyingly conversational and how to obtain the product attribution necessary

516
00:41:50,120 --> 00:41:51,120
to do that.

517
00:41:51,120 --> 00:41:52,120
All right.

518
00:41:52,120 --> 00:41:59,520
The challenges that you had with regard to the product attributes specific to these more

519
00:41:59,520 --> 00:42:05,480
emotional attributes that you were looking for or even some of the traditional attributes

520
00:42:05,480 --> 00:42:12,000
as well, like the kind of the, did you deal with challenges and just having the basic kinds

521
00:42:12,000 --> 00:42:16,080
of information you'd want to help customers make decisions?

522
00:42:16,080 --> 00:42:19,240
Yes, for sure, for sure.

523
00:42:19,240 --> 00:42:24,720
Take, take waterproofness, for example, like if you don't think about it too much, it seems

524
00:42:24,720 --> 00:42:26,120
really straightforward.

525
00:42:26,120 --> 00:42:28,400
The jacket's waterproof, it's not, right?

526
00:42:28,400 --> 00:42:31,480
But it's, no, it's not that simple.

527
00:42:31,480 --> 00:42:39,240
And there are some barely formally defined standards of waterproofness.

528
00:42:39,240 --> 00:42:44,040
You have water resistance versus waterproofness.

529
00:42:44,040 --> 00:42:50,800
And so you have the one challenge of like the interface with the human being, you know,

530
00:42:50,800 --> 00:42:53,080
with the person who's by this thing, right?

531
00:42:53,080 --> 00:42:59,920
And like trying to avoid jargon, but it was surprisingly difficult to avoid jargon.

532
00:42:59,920 --> 00:43:03,200
Same thing with windproofness, wind resistance and all that.

533
00:43:03,200 --> 00:43:07,240
So you've got kind of this sort of impedance mismatch between the technical characteristics

534
00:43:07,240 --> 00:43:13,400
of the jackets and the way a user might perceive them.

535
00:43:13,400 --> 00:43:19,160
And then sometimes too, there were just missing data, you know, you just, you would think

536
00:43:19,160 --> 00:43:23,680
that they would just all be there, but it's not, you know, like the systems that they

537
00:43:23,680 --> 00:43:29,720
use, sometimes all the dots don't connect all the way up to where we got the data.

538
00:43:29,720 --> 00:43:37,840
So it got to be sometimes a bit of a bottleneck, just getting data that they just must have,

539
00:43:37,840 --> 00:43:40,880
but it wasn't flowing to us.

540
00:43:40,880 --> 00:43:44,560
And how did you address that?

541
00:43:44,560 --> 00:43:50,800
Well, the scale that we were looking at with, that we were looking at with the North Face

542
00:43:50,800 --> 00:43:55,400
is relatively small, you know, we got a few hundred jackets.

543
00:43:55,400 --> 00:44:01,240
So we would just work, we were just working with the North Face product team and just working

544
00:44:01,240 --> 00:44:05,200
with people there and they help us resolve things that are missing.

545
00:44:05,200 --> 00:44:06,600
That's sort of a simple part.

546
00:44:06,600 --> 00:44:11,240
It's cumbersome, you know, it's not super ideal.

547
00:44:11,240 --> 00:44:16,040
And it raises questions around scalability, you know, like it's working okay, because

548
00:44:16,040 --> 00:44:23,240
we got, you know, 300 some jackets, but if we were to expand, that would be more problematic.

549
00:44:23,240 --> 00:44:27,520
With other customers, we've worked with, we've had larger numbers of products, which has

550
00:44:27,520 --> 00:44:33,400
made those problems more, more real, and we've had to resort to, well, not resort to,

551
00:44:33,400 --> 00:44:37,920
we've leveraged, there's actually another place where machine learning has come in, where

552
00:44:37,920 --> 00:44:42,760
you get information, the information that you have about a product, you know, things

553
00:44:42,760 --> 00:44:50,160
like its description and so on, can be used via machine learning to perform classifications

554
00:44:50,160 --> 00:44:57,600
and determine some of its attributes, limited, you know, it depends on what kind of description

555
00:44:57,600 --> 00:45:03,520
you have for that product, as to how well that will work, or if you're able to tap into

556
00:45:03,520 --> 00:45:10,920
supplementary sources like product reviews, but it's really helpful, but it doesn't

557
00:45:10,920 --> 00:45:12,600
truly solve the problem.

558
00:45:12,600 --> 00:45:19,080
We've also looked at crowd sourcing to help with it too, but it's just definitely a

559
00:45:19,080 --> 00:45:20,080
challenge.

560
00:45:20,080 --> 00:45:23,200
It really kind of opened my eyes to like a whole industry.

561
00:45:23,200 --> 00:45:30,080
I didn't really quite realize that there's like a whole industry around product attribution

562
00:45:30,080 --> 00:45:32,240
and it's tricky.

563
00:45:32,240 --> 00:45:36,080
Yeah, it's amazing.

564
00:45:36,080 --> 00:45:41,440
So you've some years back or some, at some point someone used some attributes to come

565
00:45:41,440 --> 00:45:45,200
up with a description, but you've lost connection to the attributes themselves and have to

566
00:45:45,200 --> 00:45:50,720
like infer them using ML from the descriptions that they wrote, basically, that's sort of

567
00:45:50,720 --> 00:45:55,120
what it seemed like, yeah, yeah, wow, wow, yep.

568
00:45:55,120 --> 00:46:03,160
And so this, the system is like, it's up on the northface.com slash XPS.

569
00:46:03,160 --> 00:46:04,760
How do you see it evolving over time?

570
00:46:04,760 --> 00:46:09,240
You've talked a little bit about, you know, some, some areas, but where does it go from

571
00:46:09,240 --> 00:46:10,240
here?

572
00:46:10,240 --> 00:46:16,120
What's the budget?

573
00:46:16,120 --> 00:46:22,800
I think that probably the most interesting place for it to go is machine learning.

574
00:46:22,800 --> 00:46:27,520
So we've got that whole heatsink business I was talking about to provide content based

575
00:46:27,520 --> 00:46:35,160
recommendations, but providing using machine, I see using machine learning in two ways

576
00:46:35,160 --> 00:46:40,800
to benefit system one is to help figure out which question to ask next.

577
00:46:40,800 --> 00:46:48,400
So you could be seeing based on the characteristics of a session in XPS, you could see which questions

578
00:46:48,400 --> 00:46:53,640
not based on this predictive stuff we've been doing, but you could just see based on like

579
00:46:53,640 --> 00:46:59,440
actual results of prior sessions, which questions delivered the most value.

580
00:46:59,440 --> 00:47:01,240
Right, right.

581
00:47:01,240 --> 00:47:05,920
And then, of course, you could also be using it to actually provide product recommendations.

582
00:47:05,920 --> 00:47:11,120
You could see, okay, based on how this session is progressing, you know, what products

583
00:47:11,120 --> 00:47:18,640
received positive feedback from similar sessions in the past and then bump those recommendations

584
00:47:18,640 --> 00:47:19,640
up.

585
00:47:19,640 --> 00:47:24,880
And like I had mentioned, the analytics tracking that we've been doing, you know, came up when

586
00:47:24,880 --> 00:47:30,480
we were talking about like, training the NLP system, well, that NLX system also will

587
00:47:30,480 --> 00:47:36,400
provide us with training data for both of those applications of machine learning.

588
00:47:36,400 --> 00:47:41,960
So we're positioned to make that happen, but all you have to do is listen to a couple

589
00:47:41,960 --> 00:47:48,560
of episodes of Twimmel to understand that it's a piece of work, you know, that's, you

590
00:47:48,560 --> 00:47:52,720
know, that, but I think that would be a great place for XPS to expand.

591
00:47:52,720 --> 00:47:56,520
Andrew, thanks so much for taking the time to chat with us about this project.

592
00:47:56,520 --> 00:48:01,320
It sounds like a ton of fun, and I'm looking forward to playing around with it and maybe

593
00:48:01,320 --> 00:48:02,920
seeing if I can find a jacket.

594
00:48:02,920 --> 00:48:03,920
Yeah.

595
00:48:03,920 --> 00:48:04,920
Yeah.

596
00:48:04,920 --> 00:48:11,080
Hopefully we can expand to give you advice about bike paniers and tents and stuff.

597
00:48:11,080 --> 00:48:14,560
Thanks a lot, Jim.

598
00:48:14,560 --> 00:48:15,560
Thanks, Andrew.

599
00:48:15,560 --> 00:48:23,240
All right, everyone, that's our show for today for more information on Andrew or any of

600
00:48:23,240 --> 00:48:29,400
the topics covered in this show, visit twimmelai.com slash talk slash 239.

601
00:48:29,400 --> 00:48:56,160
As always, thanks so much for listening and catch you next time.

