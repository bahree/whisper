1
00:00:00,000 --> 00:00:15,920
Hello and welcome to another episode of Twimble Talk, the podcast where I interview interesting

2
00:00:15,920 --> 00:00:20,880
people doing interesting things in machine learning and artificial intelligence.

3
00:00:20,880 --> 00:00:23,600
I'm your host Sam Charrington.

4
00:00:23,600 --> 00:00:27,560
The details are set for the next Twimble Online Meetup.

5
00:00:27,560 --> 00:00:28,840
Mark your calendars.

6
00:00:28,840 --> 00:00:35,200
The September Meetup will be held on Tuesday the 12th from 3 to 4 p.m. Pacific time.

7
00:00:35,200 --> 00:00:40,120
The discussion will be led by Nikola Kuchereva, who will be presenting learning long-term

8
00:00:40,120 --> 00:00:45,800
dependencies with gradient descent is difficult by Joshua Benjiro in company.

9
00:00:45,800 --> 00:00:50,320
This is one of the classic papers on recurrent neural networks so you won't want to miss

10
00:00:50,320 --> 00:00:51,560
it.

11
00:00:51,560 --> 00:00:58,120
For additional details or to join the meetup, head over to twimbleai.com slash meetup.

12
00:00:58,120 --> 00:01:02,160
If you missed the first meetup, the recording is available on that page as well.

13
00:01:02,160 --> 00:01:05,040
My guess this week is Jennifer Prinky.

14
00:01:05,040 --> 00:01:09,320
That name might sound familiar as she was one of the great speakers for my future of

15
00:01:09,320 --> 00:01:11,960
data summit back in May.

16
00:01:11,960 --> 00:01:17,560
At the time, Jennifer was a senior data science manager and principal data scientist at Walmart

17
00:01:17,560 --> 00:01:22,880
Labs, but she's since moved on to become head of data science at Atlassian.

18
00:01:22,880 --> 00:01:27,240
Back at the summit, Jennifer gave an awesome talk on what she calls data mixology.

19
00:01:27,240 --> 00:01:32,240
The slides for which can be found on the show notes page at twimbleai.com slash talk slash

20
00:01:32,240 --> 00:01:33,560
46.

21
00:01:33,560 --> 00:01:37,760
Our conversation this time begins with a recap of that talk, after which we shift our

22
00:01:37,760 --> 00:01:42,040
focus to some of the practices she helped develop and implement at Walmart around the

23
00:01:42,040 --> 00:01:45,800
measurement and management of machine learning models and production.

24
00:01:45,800 --> 00:01:50,760
And more generally, building agile processes and teams for machine learning.

25
00:01:50,760 --> 00:01:55,400
Before we jump in, I want to give a big thank you to our friends at cloud error for sponsoring

26
00:01:55,400 --> 00:01:56,680
this show.

27
00:01:56,680 --> 00:02:00,640
You probably think of cloud error primarily as the Hadoop company, and you're not wrong

28
00:02:00,640 --> 00:02:01,640
for that.

29
00:02:01,640 --> 00:02:05,400
But did you know they also offer software for data science and deep learning?

30
00:02:05,400 --> 00:02:07,000
Yep, they do.

31
00:02:07,000 --> 00:02:08,800
The idea is pretty simple.

32
00:02:08,800 --> 00:02:13,440
If you work for a large enterprise, you probably already have Hadoop in place, and your Hadoop

33
00:02:13,440 --> 00:02:18,400
cluster is filled with lots of data that you want to use in building your models.

34
00:02:18,400 --> 00:02:24,200
But you still need to easily access that data, process it using the latest open source tools

35
00:02:24,200 --> 00:02:28,280
and harness bursts of compute power to train your models.

36
00:02:28,280 --> 00:02:32,480
This is where cloud error's data science workbench comes in.

37
00:02:32,480 --> 00:02:36,440
With the data science workbench, cloud error can help you get up and running with deep

38
00:02:36,440 --> 00:02:41,960
learning without massive new investments by implementing an on demand self service deep

39
00:02:41,960 --> 00:02:45,720
learning platform on existing CDH clusters.

40
00:02:45,720 --> 00:02:49,520
From a tech perspective, data science workbench is pretty neat.

41
00:02:49,520 --> 00:02:54,480
It uses Kubernetes to transparently schedule workloads across the cluster, supporting our

42
00:02:54,480 --> 00:03:00,480
Python and Scala and deep learning frameworks like TensorFlow, Keras, Cafe, and Theano.

43
00:03:00,480 --> 00:03:06,920
And as of last month's 1.1 release, GPUs on the Hadoop cluster are fully supported.

44
00:03:06,920 --> 00:03:11,200
The folks at cloud error are so confident that you're going to like what you see that for

45
00:03:11,200 --> 00:03:16,040
a limited time, they're offering a drone to qualified participants who register for

46
00:03:16,040 --> 00:03:19,240
a demo of the data science workbench.

47
00:03:19,240 --> 00:03:24,520
For your demo and drone, visit twimmaleye.com slash cloud error.

48
00:03:24,520 --> 00:03:29,040
And now on to the show.

49
00:03:29,040 --> 00:03:37,400
All right, everyone, I am on the line with Jennifer Prinky.

50
00:03:37,400 --> 00:03:43,880
Jennifer is a senior data science manager at Wal-Mart Labs, specializing in machine

51
00:03:43,880 --> 00:03:44,880
learning.

52
00:03:44,880 --> 00:03:49,360
And I am super excited to have her on the line with me, Jennifer, welcome to the show.

53
00:03:49,360 --> 00:03:50,360
Hi, Sam.

54
00:03:50,360 --> 00:03:51,360
Nice to be here.

55
00:03:51,360 --> 00:03:52,840
Yeah, nice to have you here.

56
00:03:52,840 --> 00:03:55,200
And it is so nice to speak with you again.

57
00:03:55,200 --> 00:03:57,200
Folks recognize Jennifer's name.

58
00:03:57,200 --> 00:04:02,000
It's because Jennifer was one of the speakers at the future of data summit.

59
00:04:02,000 --> 00:04:07,320
And she so graciously offered to spend some time with us to talk a little bit about what

60
00:04:07,320 --> 00:04:10,200
she's doing at Wal-Mart Labs.

61
00:04:10,200 --> 00:04:14,600
Before we jump into that, Jennifer, why don't we have you spend a little bit of time talking

62
00:04:14,600 --> 00:04:20,040
about your background and how you ended up working in machine learning at Wal-Mart?

63
00:04:20,040 --> 00:04:21,040
Sure.

64
00:04:21,040 --> 00:04:25,640
So actually, when I tell people what my background is, they're a little bit surprise because

65
00:04:25,640 --> 00:04:28,640
I'm actually a particle physicist originally.

66
00:04:28,640 --> 00:04:33,920
And so the reason why it's not as crazy as you might think at first is that I was doing

67
00:04:33,920 --> 00:04:38,000
the type of particle physics where you have lots of data to treat.

68
00:04:38,000 --> 00:04:43,120
And so I was actually working with a huge amounts of data even before the word data science

69
00:04:43,120 --> 00:04:45,840
become as trendy as it is today.

70
00:04:45,840 --> 00:04:51,600
So I mean, the reason why I eventually switched to pure data science and specifically retail

71
00:04:51,600 --> 00:04:57,240
data science is that I was looking for like lots of data, interesting data to work with.

72
00:04:57,240 --> 00:05:02,080
And so it actually turns out that retail has lots of very interesting challenges for somewhat

73
00:05:02,080 --> 00:05:03,920
passionate with data to work with.

74
00:05:03,920 --> 00:05:06,320
So here I am, right?

75
00:05:06,320 --> 00:05:07,320
Fantastic.

76
00:05:07,320 --> 00:05:08,320
Fantastic.

77
00:05:08,320 --> 00:05:13,120
Can you tell us a little bit about the talk that you gave at the summit?

78
00:05:13,120 --> 00:05:15,920
What were your goals for that presentation?

79
00:05:15,920 --> 00:05:16,920
Yes.

80
00:05:16,920 --> 00:05:20,520
So my topic for the summit was something I call data mixology, right?

81
00:05:20,520 --> 00:05:26,800
I mean, so my goal was to try to set society people to the fact that the real challenge with

82
00:05:26,800 --> 00:05:31,360
big data today is not necessarily velocity or volume as people think.

83
00:05:31,360 --> 00:05:33,640
It's really about viability, right?

84
00:05:33,640 --> 00:05:38,040
Because when you start plugging in several data sources, sometimes you have to rethink

85
00:05:38,040 --> 00:05:44,960
your model entirely and you have to deal with all challenges related to data silos and

86
00:05:44,960 --> 00:05:48,600
understanding the quality of the data coming from different sources.

87
00:05:48,600 --> 00:05:53,680
And so, yeah, I mean, I really thought that this was a topic that was not necessarily covered

88
00:05:53,680 --> 00:05:57,640
enough in the different conferences that I had been around recently.

89
00:05:57,640 --> 00:06:00,880
So I thought it was an interesting topic to cover.

90
00:06:00,880 --> 00:06:06,080
It was definitely an interesting topic and it was clear as you were delivering it that

91
00:06:06,080 --> 00:06:08,480
it came from your experience.

92
00:06:08,480 --> 00:06:13,680
How did these issues of silos manifest themselves in your world?

93
00:06:13,680 --> 00:06:21,920
Now, so the way it comes around on my experience is that I recently started a new team where

94
00:06:21,920 --> 00:06:27,960
essentially the goal is to try to use both stores data from Walmart and online data from

95
00:06:27,960 --> 00:06:29,440
Walmart and bring them together.

96
00:06:29,440 --> 00:06:30,440
Okay.

97
00:06:30,440 --> 00:06:35,680
So in the Walmart world, truth is, I mean, the Walmart e-commerce business and the Walmart

98
00:06:35,680 --> 00:06:38,800
stores business are essentially separated.

99
00:06:38,800 --> 00:06:42,320
It's not the same people and even the data lives in separate places.

100
00:06:42,320 --> 00:06:48,280
It's not necessarily trivial for an e-commerce data scientist at Walmart to access the store

101
00:06:48,280 --> 00:06:49,960
sales data, for example.

102
00:06:49,960 --> 00:06:55,240
And so as we were trying to bring these two worlds together, I actually came to discover

103
00:06:55,240 --> 00:07:00,120
first-hands all the different challenges you have from bringing different data sources

104
00:07:00,120 --> 00:07:02,640
together, even when it comes from the same company.

105
00:07:02,640 --> 00:07:05,160
So this is exactly how I came up.

106
00:07:05,160 --> 00:07:08,920
You like to come to speak about this topic.

107
00:07:08,920 --> 00:07:17,720
And a lot of companies are pursuing ideas like data lakes or that idea by various different

108
00:07:17,720 --> 00:07:18,720
names.

109
00:07:18,720 --> 00:07:22,960
Is that something that you guys ended up doing or did you take a different approach to

110
00:07:22,960 --> 00:07:24,600
integrating all this data?

111
00:07:24,600 --> 00:07:27,640
Now, we're absolutely taking that direction, right?

112
00:07:27,640 --> 00:07:33,440
But as you can imagine, right, I mean, the challenge for Walmart is really that you have a Walmart

113
00:07:33,440 --> 00:07:39,240
e-commerce, which is a tech company that there's more recent and really like a typical Silicon

114
00:07:39,240 --> 00:07:40,560
Valley company.

115
00:07:40,560 --> 00:07:46,440
And on the other hand, this huge Walmart company, legacy company that has lots of data.

116
00:07:46,440 --> 00:07:49,240
They actually been gathering data for a long time now.

117
00:07:49,240 --> 00:07:53,320
I think they were one of the first companies actually realized that data was so important.

118
00:07:53,320 --> 00:07:57,880
And so you really have to deal with different types of systems altogether.

119
00:07:57,880 --> 00:08:00,200
We're not necessarily using the same technology.

120
00:08:00,200 --> 00:08:05,640
So we're definitely after the creation of a data lake where all data scientists across

121
00:08:05,640 --> 00:08:10,080
the company would be able to come and look at their, the same data.

122
00:08:10,080 --> 00:08:11,880
But it's a long road, right?

123
00:08:11,880 --> 00:08:16,400
I think every company that is trying to tackle this challenge knows that it is a long road.

124
00:08:16,400 --> 00:08:20,800
And it requires a lot of different skillset and lots of different people and expertise

125
00:08:20,800 --> 00:08:22,960
to actually achieve the goal.

126
00:08:22,960 --> 00:08:27,160
It's funny, I think the way that some of the vendors in the space talk about it is that

127
00:08:27,160 --> 00:08:32,840
you just set up, you know, set up a Hadoop cluster and run some ETL jobs and you'll have

128
00:08:32,840 --> 00:08:33,840
a data lake.

129
00:08:33,840 --> 00:08:38,240
What are some of the challenges that you ran into and what makes it, what makes the road

130
00:08:38,240 --> 00:08:39,240
long?

131
00:08:39,240 --> 00:08:42,840
Now, I mean, so I mean, I'll give you a specific example.

132
00:08:42,840 --> 00:08:48,760
So one of the very interesting data sets that everybody across the company wants to work

133
00:08:48,760 --> 00:08:51,600
with is the online engagement data, right?

134
00:08:51,600 --> 00:08:57,000
I mean, essentially, which items does the customer actually click on and what do they eventually

135
00:08:57,000 --> 00:08:58,000
buy, right?

136
00:08:58,000 --> 00:09:01,800
And so this is a data set that, for example, stores doesn't have access to because they

137
00:09:01,800 --> 00:09:04,880
don't have engagement, they just have their final purchases.

138
00:09:04,880 --> 00:09:09,560
So they don't have any way to measure properly the interest of the customer as long as they

139
00:09:09,560 --> 00:09:11,280
don't purchase something.

140
00:09:11,280 --> 00:09:16,040
And so people have to keep like actually getting this data from us and they actually get

141
00:09:16,040 --> 00:09:21,840
data dump, right, and they don't necessarily create like a exhaustive signal pipelines

142
00:09:21,840 --> 00:09:23,160
to get this real time.

143
00:09:23,160 --> 00:09:27,520
And so there are lots of different versions of these data that live across the company.

144
00:09:27,520 --> 00:09:32,960
And so whenever we Walmart e-commerce make a change to this data, it's not easy to

145
00:09:32,960 --> 00:09:34,960
communicate these changes to other teams.

146
00:09:34,960 --> 00:09:40,880
And so one of the challenges is you don't necessarily know any more which is the original

147
00:09:40,880 --> 00:09:42,520
source of truth.

148
00:09:42,520 --> 00:09:46,840
So in that specific case, it might be easier because you know who the owner is, but in some

149
00:09:46,840 --> 00:09:50,400
other cases, we don't necessarily even know where the data is coming from.

150
00:09:50,400 --> 00:09:55,800
And so everybody's interested in the same data, but this data exists in multiple versions.

151
00:09:55,800 --> 00:10:00,600
And it's actually very hard to come up with a procedure to actually figure out which one

152
00:10:00,600 --> 00:10:05,120
is the best one and which one is the accurate source of truth.

153
00:10:05,120 --> 00:10:09,440
That actually gives us a really interesting segue to one of the main topics that I wanted

154
00:10:09,440 --> 00:10:12,640
to dig in with you here on the podcast.

155
00:10:12,640 --> 00:10:18,880
And that is one of the interesting aspects of your role is leading a team that's focused

156
00:10:18,880 --> 00:10:26,440
on measuring and auditing for the various machine learning models at Walmart.

157
00:10:26,440 --> 00:10:33,200
And you mentioned this source of truth and data providence is kind of one small aspect

158
00:10:33,200 --> 00:10:34,200
of that.

159
00:10:34,200 --> 00:10:39,840
And tell us a little bit about your role and some of the type of work that you're focused

160
00:10:39,840 --> 00:10:40,840
on in that role.

161
00:10:40,840 --> 00:10:41,840
Right.

162
00:10:41,840 --> 00:10:42,840
Definitely.

163
00:10:42,840 --> 00:10:48,320
So I'm actually a part of a group called the search algorithms team.

164
00:10:48,320 --> 00:10:52,600
So we're essentially the group of data scientists and machine learning experts that take care

165
00:10:52,600 --> 00:10:58,800
of all machine learning algorithms that you would see at work on the walmart.com page,

166
00:10:58,800 --> 00:10:59,800
right?

167
00:10:59,800 --> 00:11:05,360
That includes learning to rank algorithms and involves everything related to the understanding

168
00:11:05,360 --> 00:11:06,360
of the customer.

169
00:11:06,360 --> 00:11:11,240
So we actually split down the responsibilities on my team into three different portions.

170
00:11:11,240 --> 00:11:15,760
So there is something called the perceived team, which is essentially in charge of trying

171
00:11:15,760 --> 00:11:17,560
to understand what the customer wants.

172
00:11:17,560 --> 00:11:18,560
Right.

173
00:11:18,560 --> 00:11:24,000
I mean, so query understanding it involves a lot of natural language processing algorithms,

174
00:11:24,000 --> 00:11:28,600
auto completion algorithms, spell checking algorithms would be their responsibilities.

175
00:11:28,600 --> 00:11:29,600
Okay.

176
00:11:29,600 --> 00:11:30,600
Here's the guide team.

177
00:11:30,600 --> 00:11:35,520
So the guide team is about learning to rank and showing the right items once you think

178
00:11:35,520 --> 00:11:37,720
you understand what the customer is looking for.

179
00:11:37,720 --> 00:11:43,360
And then we have this measure team, which is my team that essentially takes care of helping

180
00:11:43,360 --> 00:11:49,040
the others understand their weaknesses, suggest new data sets that they can use, suggest

181
00:11:49,040 --> 00:11:55,080
best practices, make sure that these other algorithms are retrained properly at the proper

182
00:11:55,080 --> 00:12:00,640
frequency, catch problems early on, so we're essentially creating models to take care

183
00:12:00,640 --> 00:12:01,640
of other models, right?

184
00:12:01,640 --> 00:12:06,800
I mean, so we create specific measurement scoring systems that range from data quality

185
00:12:06,800 --> 00:12:08,920
to customer satisfaction.

186
00:12:08,920 --> 00:12:13,680
So we're trying to bring like a essentially what the team that gets a real profound understanding

187
00:12:13,680 --> 00:12:18,200
of the other algorithms in order to help the others understand what they need to do to

188
00:12:18,200 --> 00:12:20,080
make it even better.

189
00:12:20,080 --> 00:12:26,680
And are you primarily focused on helping the search teams or are you, do you also work

190
00:12:26,680 --> 00:12:32,040
with teams outside of search that are doing data science and machine learning?

191
00:12:32,040 --> 00:12:36,080
So that's an interesting question, because my original mission was definitely to help

192
00:12:36,080 --> 00:12:37,400
the search team.

193
00:12:37,400 --> 00:12:41,320
But we actually, it turns out that we are the only measured team within the company.

194
00:12:41,320 --> 00:12:45,440
And so once people started understanding what we're doing, we actually get lots of

195
00:12:45,440 --> 00:12:50,560
requests from other teams to actually help them as well, right?

196
00:12:50,560 --> 00:12:54,680
Search is obviously an area where you have lots of different teams that are involved

197
00:12:54,680 --> 00:12:55,680
with us, right?

198
00:12:55,680 --> 00:13:00,280
And so we're really focusing on search, but you can imagine that the team in charge of

199
00:13:00,280 --> 00:13:05,440
the inventory and the catalog is also a team, teams that we are very close, closely working

200
00:13:05,440 --> 00:13:06,440
with.

201
00:13:06,440 --> 00:13:09,520
So it's pretty natural that we also bring measurements for them.

202
00:13:09,520 --> 00:13:15,200
And so another area where we're also partnering with other teams is that we actually created

203
00:13:15,200 --> 00:13:21,400
an entire process called machine learning lifecycle management, which is essentially a checklist

204
00:13:21,400 --> 00:13:27,400
of things that we believe all machine learning models should, I mean, people who work on machine

205
00:13:27,400 --> 00:13:30,400
learning models should do before pushing something to production.

206
00:13:30,400 --> 00:13:33,720
And so it actually turns out that we have a pretty efficient system now.

207
00:13:33,720 --> 00:13:39,000
So I mean, we are essentially requiring data scientists to provide, you know, like a very

208
00:13:39,000 --> 00:13:43,840
clear view of what the accuracy is, but also what the performance of the algorithm is

209
00:13:43,840 --> 00:13:48,560
in terms of the amount of CPU that their model consume when they're retraining and so

210
00:13:48,560 --> 00:13:50,120
for sets, so on and so on.

211
00:13:50,120 --> 00:13:56,640
We are not trying to expand this process to the entire e-commerce section of Walmart.

212
00:13:56,640 --> 00:14:00,560
And it actually turns out that lots of people are interested by that because the challenging

213
00:14:00,560 --> 00:14:04,240
data science is oftentimes in a company like ours.

214
00:14:04,240 --> 00:14:08,520
You have machine learning engineers who are really like engineering people who don't necessarily

215
00:14:08,520 --> 00:14:13,080
understand the limitation of data science properly speaking, right?

216
00:14:13,080 --> 00:14:17,440
And so they are not necessarily trained to think in terms of evaluating the accuracy

217
00:14:17,440 --> 00:14:21,080
and making the proper checks before sending something to production.

218
00:14:21,080 --> 00:14:25,160
They are the type of people who are really looking forward to see their model in action

219
00:14:25,160 --> 00:14:29,840
and they don't necessarily take the time to evaluate the statistical performance of the

220
00:14:29,840 --> 00:14:30,840
models.

221
00:14:30,840 --> 00:14:34,840
And so creating this, you know, like this process is really making sure that everybody's

222
00:14:34,840 --> 00:14:37,760
on the same page that things are running properly in production.

223
00:14:37,760 --> 00:14:44,360
It's interesting, it makes me think of a few years ago when the software development community

224
00:14:44,360 --> 00:14:50,400
went through this process of like industrializing the delivery of software and that resulted

225
00:14:50,400 --> 00:14:57,840
in ideas like lean and agile methodologies and DevOps and things like that.

226
00:14:57,840 --> 00:15:05,160
And it sounds like you guys are kind of on the, you know, the cutting edge of an industrialization

227
00:15:05,160 --> 00:15:14,200
wave of machine learning, not to be confused at all with the industrial AI line of inquiry

228
00:15:14,200 --> 00:15:17,120
that we've talked about here in the podcast recently.

229
00:15:17,120 --> 00:15:22,880
But I love this idea of a machine learning lifecycle model.

230
00:15:22,880 --> 00:15:27,840
What can you tell us about that model and the, you know, the various steps and stages

231
00:15:27,840 --> 00:15:31,440
and requirements that you've put in place for the teams there?

232
00:15:31,440 --> 00:15:32,440
Right.

233
00:15:32,440 --> 00:15:37,240
So I mean, you definitely write about, you know, like that being like a new wave of agile,

234
00:15:37,240 --> 00:15:38,240
right?

235
00:15:38,240 --> 00:15:42,160
I mean, agile for data science or machine learning, this is exactly what we're after.

236
00:15:42,160 --> 00:15:47,720
So I mean, as we were putting the like the first steps together, I actually came to realize

237
00:15:47,720 --> 00:15:49,920
that it is really a cultural problem, right?

238
00:15:49,920 --> 00:15:53,960
I mean, because if you want to reach a stage where things are done properly, you're really

239
00:15:53,960 --> 00:15:58,960
about trying to fix tech debt, but people usually think of tech debt as code debt, right?

240
00:15:58,960 --> 00:16:04,240
I mean, this is the way that people came to know code debt and truth is tech debt is much

241
00:16:04,240 --> 00:16:05,240
more than this, right?

242
00:16:05,240 --> 00:16:08,640
I mean, there's a, there are actually more pieces to tech debt than just code debt.

243
00:16:08,640 --> 00:16:13,440
There is a definitely data that related to like the quality of your data, but also the

244
00:16:13,440 --> 00:16:17,280
data sets that you may not be using, but your competitors are using, right?

245
00:16:17,280 --> 00:16:21,760
I mean, so if you're actually in a situation where, for example, we know, for example,

246
00:16:21,760 --> 00:16:26,280
that Amazon is using a specific data set that we have, but we are not using, you're actually

247
00:16:26,280 --> 00:16:29,360
aware in the data debt situation, right?

248
00:16:29,360 --> 00:16:31,320
Then there is the notion of system debt.

249
00:16:31,320 --> 00:16:38,120
So the case where you're using legacy systems and you're not improving and getting to use

250
00:16:38,120 --> 00:16:45,600
the latest versions of a specific software or not like a newest cutting-edge software that

251
00:16:45,600 --> 00:16:47,560
is intended into three.

252
00:16:47,560 --> 00:16:51,360
And then you have machine learning that so machine learning that is really when you're using

253
00:16:51,360 --> 00:16:54,600
a machine learning model, not to the best of its ability, right?

254
00:16:54,600 --> 00:16:58,600
I mean, so, for example, if you don't understand at which frequency you should be retraining

255
00:16:58,600 --> 00:17:02,600
a model, you don't understand, you don't monitor the inputs and outputs.

256
00:17:02,600 --> 00:17:06,240
It's definitely also a situation that you have to take care of.

257
00:17:06,240 --> 00:17:10,360
So I mean, the steps that, you know, when somebody asked me, how, what should I do to

258
00:17:10,360 --> 00:17:15,920
actually get started with, you know, like a automation and I'll try to, like, basically

259
00:17:15,920 --> 00:17:17,560
audit my models, what should I do?

260
00:17:17,560 --> 00:17:21,840
So my answer to that is, it's not necessary, something that's very complicated.

261
00:17:21,840 --> 00:17:25,920
It's really about a process and also creating a culture in your company where everybody

262
00:17:25,920 --> 00:17:29,800
understands that making things right is important.

263
00:17:29,800 --> 00:17:34,120
And so it really depends on the kind of model you're dealing with, but like usually one thing

264
00:17:34,120 --> 00:17:38,880
I suggest everybody should do is make sure that you document everything that you're doing,

265
00:17:38,880 --> 00:17:39,880
right?

266
00:17:39,880 --> 00:17:44,280
I mean, so it may sound like a cheesy answer, you know, but it's definitely super important.

267
00:17:44,280 --> 00:17:48,960
We actually turned out that most of the times when we didn't have a model performing well

268
00:17:48,960 --> 00:17:51,920
enough, it wasn't necessary because of the model itself.

269
00:17:51,920 --> 00:17:56,400
It was because we didn't have a clear understanding of what the model was doing, right?

270
00:17:56,400 --> 00:18:00,880
And so we were not able to reproduce the same model.

271
00:18:00,880 --> 00:18:02,560
There was a lack of transparency.

272
00:18:02,560 --> 00:18:07,040
And so for example, you would have a new engineer coming over and trying to take over the

273
00:18:07,040 --> 00:18:11,840
project and they wouldn't even know how the model was built.

274
00:18:11,840 --> 00:18:16,360
So the other thing is you're, it's extremely important that you have a clear understanding

275
00:18:16,360 --> 00:18:21,240
of what your failures and weaknesses were, so that I mean, people tend to forget that

276
00:18:21,240 --> 00:18:25,960
you're like in the concept of machine learning, life cycle management, there is the worst

277
00:18:25,960 --> 00:18:26,960
cycle, right?

278
00:18:26,960 --> 00:18:30,680
I mean, so there is an opportunity for everybody to learn about their weaknesses in order

279
00:18:30,680 --> 00:18:35,120
to make sure that the next iteration of your model is better.

280
00:18:35,120 --> 00:18:36,120
Right.

281
00:18:36,120 --> 00:18:40,520
And you're like, so definitely think about the culture that you have to bring in your

282
00:18:40,520 --> 00:18:44,920
company and make sure that you keep in track of everything you're doing, that it is

283
00:18:44,920 --> 00:18:49,680
very clear the data you're using, it is very clear that you understand the quality of

284
00:18:49,680 --> 00:18:52,640
your data and you understand your challenges.

285
00:18:52,640 --> 00:18:57,640
On the various teams there, can you tell me a little bit about the relationship between

286
00:18:57,640 --> 00:19:04,880
data scientists and people with a statistical orientation and developers and engineers?

287
00:19:04,880 --> 00:19:08,640
Yeah, I can absolutely tell you about that.

288
00:19:08,640 --> 00:19:14,200
So actually my team has a statistical analyst, data scientist and machine learning engineers.

289
00:19:14,200 --> 00:19:17,800
So people sometimes struggle to understand what the difference is.

290
00:19:17,800 --> 00:19:23,520
So really our, in our view, a statistical analyst are people who know how to play with

291
00:19:23,520 --> 00:19:25,600
the data really, really well.

292
00:19:25,600 --> 00:19:31,200
So they essentially like can get you, you know, like a very clear understanding of whether

293
00:19:31,200 --> 00:19:36,200
your data is sufficient entropy and sufficient variance for you to build a model and then

294
00:19:36,200 --> 00:19:40,120
can give you answers very quickly to get started.

295
00:19:40,120 --> 00:19:44,400
The data scientist is actually the person that would, I would say like prototype a model,

296
00:19:44,400 --> 00:19:45,400
right?

297
00:19:45,400 --> 00:19:48,640
And so once you have an understanding that your data is good enough for you to solve a

298
00:19:48,640 --> 00:19:53,680
specific problem, the data scientist will come up with a solution and essentially try

299
00:19:53,680 --> 00:19:58,960
to assess which is the best type of machine learning model for you to solve that problem.

300
00:19:58,960 --> 00:20:02,720
So we don't necessarily expect like the statistical analyst to be someone who's an expert

301
00:20:02,720 --> 00:20:03,720
in machine learning.

302
00:20:03,720 --> 00:20:07,160
I mean, of course, they have some understanding that they are not the persons that be in

303
00:20:07,160 --> 00:20:09,560
charge of creating a model.

304
00:20:09,560 --> 00:20:14,400
And then the machine learning engineer is someone that knows how to optimize this machine

305
00:20:14,400 --> 00:20:17,400
learning model and make it work at scale.

306
00:20:17,400 --> 00:20:22,440
So they're really like focusing on making everything efficient and I mean, they really have

307
00:20:22,440 --> 00:20:24,200
the ability to push that to production.

308
00:20:24,200 --> 00:20:29,080
So having all this skill set together in one team has been really helpful for us because

309
00:20:29,080 --> 00:20:32,360
it really helps us move things to production really quickly.

310
00:20:32,360 --> 00:20:37,240
One of the things I've seen in the past with organizations that have a model similar to

311
00:20:37,240 --> 00:20:42,400
yours, although I think less sophisticated in the way you are managing it and the machine

312
00:20:42,400 --> 00:20:49,360
learning life cycle processes that you've introduced is a little bit of friction in kind

313
00:20:49,360 --> 00:20:56,520
of the interface between the data scientists and the machine learning engineers where you

314
00:20:56,520 --> 00:21:02,760
would have a data scientist, you know, create a model kind of coded up using, you know, maybe

315
00:21:02,760 --> 00:21:07,280
even a set of tools that the are not the set of tools that the ML engineers are working

316
00:21:07,280 --> 00:21:14,200
with kind of throw it over the wall and then have this machine learning engineer who,

317
00:21:14,200 --> 00:21:20,240
you know, maybe less sophisticated in understanding the model, you know, try to implement it often

318
00:21:20,240 --> 00:21:26,200
in, you know, going from, you know, Python, for example, to Java or something like that.

319
00:21:26,200 --> 00:21:32,120
And that both resulting in, you know, creating an opportunity for the introduction of errors

320
00:21:32,120 --> 00:21:39,400
as well as slowing cycle time and iteration time, just because of the back and forth over

321
00:21:39,400 --> 00:21:45,960
this barrier, how have you guys seen that at all and how have you addressed it?

322
00:21:45,960 --> 00:21:50,920
Now, so I definitely saw see how that problem can arise, right?

323
00:21:50,920 --> 00:21:55,240
I mean, so I think like at the very beginning, when this team was still very decent, I mean,

324
00:21:55,240 --> 00:21:57,200
we definitely had that problem.

325
00:21:57,200 --> 00:22:02,880
The way we kind of sold it is that there is actually a very decent overlap between the

326
00:22:02,880 --> 00:22:05,280
data scientists and the machine learning engineer.

327
00:22:05,280 --> 00:22:10,240
So usually the data scientists would actually code something, which is pretty close to what

328
00:22:10,240 --> 00:22:14,720
would end up being in production except that it is not necessarily functioning as scale,

329
00:22:14,720 --> 00:22:15,720
right?

330
00:22:15,720 --> 00:22:17,360
I mean, so usually they use the same language.

331
00:22:17,360 --> 00:22:19,000
So that's for sure.

332
00:22:19,000 --> 00:22:23,560
The other thing is we make sure that I actually like I have my machine learning engineers

333
00:22:23,560 --> 00:22:25,720
and my data scientists working pairs.

334
00:22:25,720 --> 00:22:26,720
Okay.

335
00:22:26,720 --> 00:22:30,720
So the machine learning engineer is actually involved in the early stages as well, but he's

336
00:22:30,720 --> 00:22:32,480
not the tech lead for that portion, right?

337
00:22:32,480 --> 00:22:38,080
I mean, so he actually gets to be involved and immersed with the model like very early

338
00:22:38,080 --> 00:22:42,880
on, which gives him some more sophisticated understanding of the model that makes it easier

339
00:22:42,880 --> 00:22:47,440
for him to him or her to actually push it to production later.

340
00:22:47,440 --> 00:22:51,600
So we don't really have like this French association faces really like the entire pair

341
00:22:51,600 --> 00:22:56,160
is working throughout the process except that the first phase is the phase where the data

342
00:22:56,160 --> 00:23:00,120
scientists is in charge and the last phase is the phase where the machine learning person

343
00:23:00,120 --> 00:23:01,120
is in charge.

344
00:23:01,120 --> 00:23:02,120
Okay.

345
00:23:02,120 --> 00:23:07,040
That's another really adaptation of the agile idea or at least the pair programming notion

346
00:23:07,040 --> 00:23:11,960
of agile to this machine learning lifecycle.

347
00:23:11,960 --> 00:23:12,960
Interesting.

348
00:23:12,960 --> 00:23:13,960
Interesting.

349
00:23:13,960 --> 00:23:21,520
So you develop these models, you get them in production and then you are tasked with

350
00:23:21,520 --> 00:23:26,960
tracking and measuring and auditing their performance, not just when you're putting them

351
00:23:26,960 --> 00:23:30,360
in the production, but over time, tell us a little bit about that cycle.

352
00:23:30,360 --> 00:23:31,800
Yeah, sure, sure.

353
00:23:31,800 --> 00:23:37,080
So I mean, the interesting thing was, you know, like at first when we came up with this

354
00:23:37,080 --> 00:23:42,080
new model of having like an external team kind of measuring things was pretty interesting,

355
00:23:42,080 --> 00:23:43,080
right?

356
00:23:43,080 --> 00:23:47,320
Because our other teams up to that point in time they were actually used to essentially

357
00:23:47,320 --> 00:23:52,560
come up with a success metric that they would use for essentially build a model and they

358
00:23:52,560 --> 00:23:57,360
would actually use the same success metric for measuring and auditing this model themselves,

359
00:23:57,360 --> 00:23:58,360
right?

360
00:23:58,360 --> 00:24:02,360
And so the value proposition was that you're kind of in the situation where you have a

361
00:24:02,360 --> 00:24:03,360
conflict of interest, right?

362
00:24:03,360 --> 00:24:04,360
Right.

363
00:24:04,360 --> 00:24:05,360
Right.

364
00:24:05,360 --> 00:24:10,360
And even if you want to be like a really truthful, I mean, if the same person is actually coming

365
00:24:10,360 --> 00:24:14,680
up with measurements and actually assessing their own models, they don't necessarily see

366
00:24:14,680 --> 00:24:16,320
things in a different light, right?

367
00:24:16,320 --> 00:24:21,520
I mean, so the value proposition here is that you have a different person that doesn't

368
00:24:21,520 --> 00:24:25,800
know or knows very little about the model auditing things and actually come up with their

369
00:24:25,800 --> 00:24:29,560
own definition of what success means for that model, right?

370
00:24:29,560 --> 00:24:32,880
So we had a little bit of tension at the beginning, as you can imagine, right?

371
00:24:32,880 --> 00:24:35,960
Because it's almost like you use the word auditing, right?

372
00:24:35,960 --> 00:24:37,480
And that's definitely what we do, right?

373
00:24:37,480 --> 00:24:42,360
I mean, so you're in a situation where everybody's wondering like, well, what is the status

374
00:24:42,360 --> 00:24:43,360
of my model?

375
00:24:43,360 --> 00:24:46,680
Well, these guys are going to find anything wrong with my model.

376
00:24:46,680 --> 00:24:51,800
So it took some time for us to actually make it very clear that we are not here to actually

377
00:24:51,800 --> 00:24:52,800
judge your work.

378
00:24:52,800 --> 00:24:55,560
We're actually here to help you improve it, right?

379
00:24:55,560 --> 00:24:56,560
Right.

380
00:24:56,560 --> 00:24:57,560
Right.

381
00:24:57,560 --> 00:24:58,560
Right.

382
00:24:58,560 --> 00:25:00,880
But I mean, I think everybody's very comfortable right now that we're actually in charge

383
00:25:00,880 --> 00:25:03,920
of making sure of the quality of the model.

384
00:25:03,920 --> 00:25:06,960
So we have a very good dynamic with the other teams right now.

385
00:25:06,960 --> 00:25:13,480
And it comes to measuring the performance of the models that you guys are using.

386
00:25:13,480 --> 00:25:20,560
Are you focusing on business metrics or technical model performance metrics or a combination

387
00:25:20,560 --> 00:25:21,560
of both?

388
00:25:21,560 --> 00:25:24,120
It's definitely a combination of both.

389
00:25:24,120 --> 00:25:28,120
I mean, so the reason why we believe that there should be an entire team focused on this

390
00:25:28,120 --> 00:25:32,520
is as you can imagine, there is not one single metric per model, right?

391
00:25:32,520 --> 00:25:33,520
Sure.

392
00:25:33,520 --> 00:25:37,560
We actually have like some models actually use like several metrics or several tens of

393
00:25:37,560 --> 00:25:42,040
metrics to actually make sure that we have a comprehensive view of how the model is

394
00:25:42,040 --> 00:25:43,040
performing.

395
00:25:43,040 --> 00:25:48,880
And so it ranges from like a how accurate is the model to how efficient is the model in

396
00:25:48,880 --> 00:25:52,920
terms of your like is it using too much CPU as I mentioned earlier?

397
00:25:52,920 --> 00:25:56,480
And is it is it impacting the customer in a proper way, right?

398
00:25:56,480 --> 00:26:02,640
So our belief is that you should have a specific metric for every single model separately.

399
00:26:02,640 --> 00:26:08,240
So in retail, it is pretty traditional to use typically like the number of add to cards

400
00:26:08,240 --> 00:26:13,840
or the number of clicks or even the revenue as a measurement of your like success when

401
00:26:13,840 --> 00:26:16,800
you, for example, run a bit tests, right?

402
00:26:16,800 --> 00:26:21,080
So our belief is that because you have these two steps, right, understanding the customer

403
00:26:21,080 --> 00:26:26,040
through perceive and guiding the customer through guide, we believe that you should have

404
00:26:26,040 --> 00:26:30,800
metrics specific to each one of these portions, specifically because otherwise you're looking

405
00:26:30,800 --> 00:26:34,760
at all models in terms of add to cards, it doesn't really make sense, right?

406
00:26:34,760 --> 00:26:39,600
Because the perception phase is really about understanding the customer not necessarily.

407
00:26:39,600 --> 00:26:45,960
So for example, if I ever drop in add to cards, it is possible that my new perceived algorithm

408
00:26:45,960 --> 00:26:51,080
is really working well, but because there is a bottleneck with the guide phase, I won't

409
00:26:51,080 --> 00:26:53,160
see that this model is performing well, right?

410
00:26:53,160 --> 00:26:58,280
I mean, so really making sure that you have very narrow and very specific metrics, even

411
00:26:58,280 --> 00:27:02,840
if it means having many of them is definitely working very well for us.

412
00:27:02,840 --> 00:27:05,160
I guess I have mixed feelings about that hearing it.

413
00:27:05,160 --> 00:27:11,840
I wonder about local minima, local maxima, or I guess probably a better way to put it

414
00:27:11,840 --> 00:27:19,120
is unit test versus integration test or system tests, like what if you're creating, you

415
00:27:19,120 --> 00:27:25,720
have a measure that the perceived team is able to maximize, but it doesn't maximize

416
00:27:25,720 --> 00:27:31,640
the overall metric of something like revenue or an add to card.

417
00:27:31,640 --> 00:27:33,640
How do you manage that?

418
00:27:33,640 --> 00:27:35,120
That's a very good question, actually.

419
00:27:35,120 --> 00:27:40,080
We see that problem very often, so basically, you would have a new perceived algorithm

420
00:27:40,080 --> 00:27:46,160
that performs really well, but you'd actually see that it actually causes the guide performance

421
00:27:46,160 --> 00:27:47,160
to drop, right?

422
00:27:47,160 --> 00:27:50,800
I mean, so you definitely have this kind of cannibalization problems.

423
00:27:50,800 --> 00:27:52,400
Let me give you an example, right?

424
00:27:52,400 --> 00:27:57,400
I mean, so we actually figured at some point that when you're actually improving the accuracy

425
00:27:57,400 --> 00:28:05,920
or the efficiency of your autocompletion algorithms, it essentially drops the performance of the

426
00:28:05,920 --> 00:28:07,520
spell check algorithm.

427
00:28:07,520 --> 00:28:08,520
Why?

428
00:28:08,520 --> 00:28:12,400
Because if people can use the autocompletion algorithm, they're not going to finish entering

429
00:28:12,400 --> 00:28:17,480
the queries by end, which means that the spell checking algorithm is not called that

430
00:28:17,480 --> 00:28:18,480
offer, right?

431
00:28:18,480 --> 00:28:21,400
I mean, it's pretty logical, if you think about it.

432
00:28:21,400 --> 00:28:25,000
So I mean, this is exactly the kind of thing you want to observe, because in that specific

433
00:28:25,000 --> 00:28:29,480
scenario that essentially allows us to say, you know what, it's worth investing more

434
00:28:29,480 --> 00:28:36,720
time, making a perfect autocompletion algorithm rather than making a perfect spell check algorithm.

435
00:28:36,720 --> 00:28:41,680
So you actually use these inefficiencies to determine which algorithms you should focus

436
00:28:41,680 --> 00:28:42,680
on.

437
00:28:42,680 --> 00:28:43,680
Interesting.

438
00:28:43,680 --> 00:28:51,360
So a related question that I've had for folks in the retail space is around short

439
00:28:51,360 --> 00:28:58,280
sighted versus long sighted models, and this, an example here might be, you know, as

440
00:28:58,280 --> 00:29:05,680
we talked about, it's pretty common to optimize your models around add to carts or even, you

441
00:29:05,680 --> 00:29:12,520
know, short term, you know, even immediate revenue creation or even something like profitability

442
00:29:12,520 --> 00:29:19,080
to be kind of one level higher in business impact.

443
00:29:19,080 --> 00:29:27,720
But I wonder if, when you're doing that, if it's possible that you are sub optimizing the

444
00:29:27,720 --> 00:29:33,360
broader metric like customer lifetime value or something along those lines, is that something

445
00:29:33,360 --> 00:29:35,520
that you think about there at all?

446
00:29:35,520 --> 00:29:38,320
Now, we definitely have that as a metric.

447
00:29:38,320 --> 00:29:40,800
So you suggested like a customer lifetime value.

448
00:29:40,800 --> 00:29:45,360
This is one of the metric you would monitor against the entire process, which is why I

449
00:29:45,360 --> 00:29:49,080
say that you need to have several metrics for every model, right?

450
00:29:49,080 --> 00:29:54,080
I mean, so we make sure that we keep track of all different aspects and dimensions of

451
00:29:54,080 --> 00:29:55,080
the problem.

452
00:29:55,080 --> 00:30:00,040
But as in always in business, at the end of the day, you have to follow a business decision

453
00:30:00,040 --> 00:30:01,040
as well, right?

454
00:30:01,040 --> 00:30:05,840
And so if the goal of the company is to increase revenue drastically over the next quarter,

455
00:30:05,840 --> 00:30:10,080
I mean, you, at the end of the day, you, you align your decision based on this as well,

456
00:30:10,080 --> 00:30:11,080
right?

457
00:30:11,080 --> 00:30:14,320
I mean, at the end of the day, the final choice of what you're like, which algorithm

458
00:30:14,320 --> 00:30:17,680
you should improve comes down to a business decisions.

459
00:30:17,680 --> 00:30:22,560
Our goal is really to make sure that they have all information in hand and handy to actually

460
00:30:22,560 --> 00:30:24,320
make a decision based on that, right?

461
00:30:24,320 --> 00:30:29,000
I mean, so whatever they decide to do, we make sure that they are aware that if they choose

462
00:30:29,000 --> 00:30:34,960
to do a specific or take a specific decision, it may impact customer lifetime value out

463
00:30:34,960 --> 00:30:36,600
these kind of things.

464
00:30:36,600 --> 00:30:45,280
Are there other instances where you are, where you're working to balance short-term versus

465
00:30:45,280 --> 00:30:47,920
long-term optimization targets?

466
00:30:47,920 --> 00:30:53,800
Well, I mean, obviously for as far as I've seen things that were more so far as really

467
00:30:53,800 --> 00:30:56,800
like this kind of optimization would come down to a business decision, right?

468
00:30:56,800 --> 00:31:02,000
I mean, so I don't think we're already reached a level where we can forecast our predict

469
00:31:02,000 --> 00:31:09,480
the future well enough to actually get to this side to comprehensive knowledge that brings

470
00:31:09,480 --> 00:31:13,080
everybody on the same page, for sure.

471
00:31:13,080 --> 00:31:14,080
Right.

472
00:31:14,080 --> 00:31:19,240
Are you in the process of auditing these various teams?

473
00:31:19,240 --> 00:31:28,800
Do you have a list, either formal or in your head of these are the top end things that

474
00:31:28,800 --> 00:31:35,720
people tend to do wrong or put another way, what's your advice for folks that want to

475
00:31:35,720 --> 00:31:42,600
learn from what you've learned from your teams on how they should approach modeling?

476
00:31:42,600 --> 00:31:43,600
Right.

477
00:31:43,600 --> 00:31:44,600
Definitely.

478
00:31:44,600 --> 00:31:50,040
So I would see three things that I believe are good take-up is for everybody who's trying

479
00:31:50,040 --> 00:31:51,320
to tackle this problem.

480
00:31:51,320 --> 00:31:56,840
So the first one is definitely what I would say before making sure you document everything,

481
00:31:56,840 --> 00:32:01,480
especially in large organizations where the turnover of your employees is really high,

482
00:32:01,480 --> 00:32:02,480
right?

483
00:32:02,480 --> 00:32:06,160
I mean, you want to make sure that if something went wrong with the past model, at least

484
00:32:06,160 --> 00:32:10,880
you know what went wrong and you're at the ability of fixing this in the next situation.

485
00:32:10,880 --> 00:32:16,920
And so make sure that anyone can actually grab that model and reproduce the same results.

486
00:32:16,920 --> 00:32:17,920
That's one thing.

487
00:32:17,920 --> 00:32:23,720
The other thing is I actually noticed that many times when our models are unsuccessful,

488
00:32:23,720 --> 00:32:28,360
it is essentially not due to a performance issue from the model side, it's actually a problem

489
00:32:28,360 --> 00:32:30,040
with the inputs.

490
00:32:30,040 --> 00:32:35,280
So a failure in one of the systems or like typically it retains something you could see happening

491
00:32:35,280 --> 00:32:37,560
is a seasonality pattern, right?

492
00:32:37,560 --> 00:32:43,920
I mean, so basically your model was meant to function well for your inputs to be in a

493
00:32:43,920 --> 00:32:48,640
specific range and you have to make sure that it is still the same range, right?

494
00:32:48,640 --> 00:32:53,160
I mean, so actually monitoring the inputs and the outputs goes a very long way.

495
00:32:53,160 --> 00:32:57,960
It doesn't necessarily mean that you have to monitor things very closely, but you're

496
00:32:57,960 --> 00:33:03,240
essentially get a sense that the number of average number of add to cards you see on

497
00:33:03,240 --> 00:33:08,360
a specific day is still pretty close to what you would expect them and what it was when

498
00:33:08,360 --> 00:33:10,840
you actually trained your model.

499
00:33:10,840 --> 00:33:11,840
Right, right.

500
00:33:11,840 --> 00:33:16,200
The last thing is, I would say that one issue I've seen as well is not necessarily an

501
00:33:16,200 --> 00:33:22,560
issue, but data scientists tend to, I would say that not necessarily overfitting the

502
00:33:22,560 --> 00:33:26,520
way you would think about it, but like use too much data for the models.

503
00:33:26,520 --> 00:33:32,320
So something that we're actually requiring from all our data scientists now is that when

504
00:33:32,320 --> 00:33:40,440
they suggest a specific amount of data for retrain the models, we actually ask them to train

505
00:33:40,440 --> 00:33:45,160
the same model, exact same model with the lesser amount of data and they actually do that

506
00:33:45,160 --> 00:33:47,280
for several data points.

507
00:33:47,280 --> 00:33:54,240
And we actually build this curve of essentially CPU consumption versus accuracy of the model.

508
00:33:54,240 --> 00:33:58,960
And I actually turned out that in our case, many people were using, I would say four times

509
00:33:58,960 --> 00:34:02,120
too much data compared to what was actually needed.

510
00:34:02,120 --> 00:34:03,120
Oh wow.

511
00:34:03,120 --> 00:34:06,400
So essentially that means that you're using four times too much CPU, right?

512
00:34:06,400 --> 00:34:11,280
I mean, so you're sticking you to four times longer to train these models.

513
00:34:11,280 --> 00:34:15,840
So essentially, of course, it's better to use more data, but if you're going to increase

514
00:34:15,840 --> 00:34:20,640
your accuracy by just one percent by throwing four times as much data, it doesn't really

515
00:34:20,640 --> 00:34:21,640
make sense, right?

516
00:34:21,640 --> 00:34:22,640
That means four.

517
00:34:22,640 --> 00:34:27,600
So I'm definitely, I think that data scientists are not trained to think in terms of money

518
00:34:27,600 --> 00:34:28,600
optimization, right?

519
00:34:28,600 --> 00:34:29,600
That means four.

520
00:34:29,600 --> 00:34:35,480
So this is something that we've made sure now that everybody is actually aware of conscious

521
00:34:35,480 --> 00:34:39,600
of the amount of CPU they're using when they're training the models.

522
00:34:39,600 --> 00:34:43,880
And have you developed a set of rules of thumb?

523
00:34:43,880 --> 00:34:50,800
Is there a way to generalize that or is the right way for them to, do they always need

524
00:34:50,800 --> 00:34:57,160
to run the models with four different data points and understand where the kind of that

525
00:34:57,160 --> 00:35:01,760
utility curve and pick the right point on it?

526
00:35:01,760 --> 00:35:03,760
This is the way we're functioning right now, right?

527
00:35:03,760 --> 00:35:07,960
I mean, of course, for the future, I have some hope of coming up with a, I mean, it's

528
00:35:07,960 --> 00:35:09,960
a very iterative process, right?

529
00:35:09,960 --> 00:35:13,840
I mean, so the way we've been thinking about this data, I mean, as we ask people,

530
00:35:13,840 --> 00:35:18,760
to do things, people actually start creating their own scripts and their own tools to actually

531
00:35:18,760 --> 00:35:20,120
perform these tasks.

532
00:35:20,120 --> 00:35:25,560
So when something comes across as being easy to generalize, we try to make sure that this

533
00:35:25,560 --> 00:35:28,160
is also accessible to other team members.

534
00:35:28,160 --> 00:35:33,040
And so over time, we're actually building this data base of tools that everybody can use

535
00:35:33,040 --> 00:35:34,440
for their specific problems.

536
00:35:34,440 --> 00:35:38,800
And so we're moving towards automations, just like it's a very slow process because as

537
00:35:38,800 --> 00:35:43,000
you may guess, like we have very different types of models and not everything can be

538
00:35:43,000 --> 00:35:46,160
used for the models as well.

539
00:35:46,160 --> 00:35:54,320
Do you have some kind of tool or platform in place for deploying and managing the various

540
00:35:54,320 --> 00:36:00,880
models or the individual teams do that themselves for their own services?

541
00:36:00,880 --> 00:36:04,560
I guess, you know, part of the question is thinking about it, like what's happening

542
00:36:04,560 --> 00:36:10,920
on the dev side of things, folks are forming, you know, dev ops teams around microservices

543
00:36:10,920 --> 00:36:16,360
that, you know, have full lifecycle responsibilities for those services, are you doing similar things

544
00:36:16,360 --> 00:36:17,360
around models?

545
00:36:17,360 --> 00:36:20,000
Yes, so we're moving in that direction.

546
00:36:20,000 --> 00:36:25,400
So we're actually developing our own compute platform where essentially all models will

547
00:36:25,400 --> 00:36:26,400
be trained.

548
00:36:26,400 --> 00:36:30,440
And so that platform would actually be talking to the data like DRK, right?

549
00:36:30,440 --> 00:36:35,480
I mean, but again, it's a very slow process because you have to train people to use that

550
00:36:35,480 --> 00:36:41,200
new platform, there are some paradigms that are not necessarily very obvious to everybody.

551
00:36:41,200 --> 00:36:44,840
We try to make sure that, you know, like everybody gets to use their favorite language

552
00:36:44,840 --> 00:36:49,640
in that platform, but essentially we're also loading that compute platform with the tools

553
00:36:49,640 --> 00:36:50,880
that was mentioned before.

554
00:36:50,880 --> 00:36:53,560
So that everything is in one place.

555
00:36:53,560 --> 00:36:57,960
Everybody's aware of, you know, like what tools exist to make your life easier as a data

556
00:36:57,960 --> 00:37:00,840
scientist or a machine learning engineer?

557
00:37:00,840 --> 00:37:03,640
And is this a home-run platform or something that you're...

558
00:37:03,640 --> 00:37:04,640
Yes.

559
00:37:04,640 --> 00:37:12,160
I'm imagine when you talked about the monitoring, the inputs and outputs of the models that

560
00:37:12,160 --> 00:37:16,440
struck me as really interesting, and I imagine some platform that, you know, you would tie

561
00:37:16,440 --> 00:37:21,480
into a monitoring system that when you're, you know, as part of your documentation phase,

562
00:37:21,480 --> 00:37:27,840
you're able to describe the expected bounds of a given model.

563
00:37:27,840 --> 00:37:30,000
And then this thing is monitoring the inputs.

564
00:37:30,000 --> 00:37:34,600
And if it starts, if you start seeing inputs outside of the bound, this thing would shoot

565
00:37:34,600 --> 00:37:40,000
off, you know, red flags and start paging people, have you gotten there yet or is that part

566
00:37:40,000 --> 00:37:41,000
of what you're working for?

567
00:37:41,000 --> 00:37:42,000
Yes.

568
00:37:42,000 --> 00:37:43,000
Yes, absolutely.

569
00:37:43,000 --> 00:37:44,000
Absolutely.

570
00:37:44,000 --> 00:37:46,000
This is exactly what we're trying to do right now, right?

571
00:37:46,000 --> 00:37:47,000
I mean, so it's...

572
00:37:47,000 --> 00:37:52,080
For, I mean, the challenge with this specific is that when you have, like, you're like

573
00:37:52,080 --> 00:37:56,800
supervised models and like a numerical data, it's fairly easy to monitor the inputs, right?

574
00:37:56,800 --> 00:37:57,800
I mean, so...

575
00:37:57,800 --> 00:37:58,800
Right.

576
00:37:58,800 --> 00:38:02,800
I mean, so for some of the models, it's actually already in place, where essentially,

577
00:38:02,800 --> 00:38:03,800
we...

578
00:38:03,800 --> 00:38:25,800
Whenever an input goes outside of, like, minus two sigma plus two sigma boundaries, it's actually

579
00:38:25,800 --> 00:38:30,800
shooting an email to the person in charge of monitoring the bottle and they would actually

580
00:38:30,800 --> 00:38:34,040
know that, you know, something is potentially about to happen, right?

581
00:38:34,040 --> 00:38:38,320
I mean, so we're definitely geared towards this, like, I mean, one thing we definitely

582
00:38:38,320 --> 00:38:42,400
want to achieve in the near future is a model that allows you to understand that your model

583
00:38:42,400 --> 00:38:43,560
is expiring before...

584
00:38:43,560 --> 00:38:44,560
Before it's time, right?

585
00:38:44,560 --> 00:38:49,600
I mean, so right now, I think most companies are thinking of retraining models in terms

586
00:38:49,600 --> 00:38:51,400
of a regular sequence, right?

587
00:38:51,400 --> 00:38:54,600
I mean, basically, I retrain my model every other week.

588
00:38:54,600 --> 00:38:55,600
Right.

589
00:38:55,600 --> 00:39:00,200
So when you're in retail, there may be lots of happenings, there may be, like, holidays

590
00:39:00,200 --> 00:39:04,560
and sometimes you have to retrain things faster, unless you have something in place to let

591
00:39:04,560 --> 00:39:09,120
you know that the bottle is about to change or needs to be updated, you would actually

592
00:39:09,120 --> 00:39:12,960
learn that by your customer complaining about getting the wrong results or something that's

593
00:39:12,960 --> 00:39:15,080
not accurate or relevant to our searches, right?

594
00:39:15,080 --> 00:39:19,600
And so you don't want that to happen because it essentially involves that the customer needs

595
00:39:19,600 --> 00:39:24,040
to have a bad experience for you to be aware that something's wrong with your model.

596
00:39:24,040 --> 00:39:25,040
Right.

597
00:39:25,040 --> 00:39:29,760
So make sure that we can catch these problems early in the process before it actually impacts

598
00:39:29,760 --> 00:39:31,000
the customer.

599
00:39:31,000 --> 00:39:32,000
Mm-hmm.

600
00:39:32,000 --> 00:39:38,240
And so what are some of the methodologies that you use to identify these expiring models?

601
00:39:38,240 --> 00:39:44,520
Well, again, it's about like finding the right metric to actually assess the satisfaction

602
00:39:44,520 --> 00:39:45,520
of the customer, right?

603
00:39:45,520 --> 00:39:50,240
I mean, but I don't think there's like a one-true, only metric that works for all cases,

604
00:39:50,240 --> 00:39:53,680
but I mean, again, it's the mission of the measure team, right?

605
00:39:53,680 --> 00:39:54,680
Right.

606
00:39:54,680 --> 00:39:55,680
And measuring things as well.

607
00:39:55,680 --> 00:39:56,680
So another word with a model.

608
00:39:56,680 --> 00:39:57,680
Capturing the dissatisfaction.

609
00:39:57,680 --> 00:40:00,200
Sorry, sorry for cutting you off with just a paraphrase.

610
00:40:00,200 --> 00:40:04,240
In other words, the model is expiring when it stops performing if there's not some other

611
00:40:04,240 --> 00:40:05,480
dimensions to it.

612
00:40:05,480 --> 00:40:06,480
Yeah.

613
00:40:06,480 --> 00:40:07,480
Right.

614
00:40:07,480 --> 00:40:08,480
Right.

615
00:40:08,480 --> 00:40:09,480
Okay.

616
00:40:09,480 --> 00:40:10,480
Interesting.

617
00:40:10,480 --> 00:40:16,120
As part of this measure team, you also are chartered with specifically looking for weaknesses

618
00:40:16,120 --> 00:40:18,560
in other people's models.

619
00:40:18,560 --> 00:40:21,200
What does that look like and how do you approach that?

620
00:40:21,200 --> 00:40:29,960
And I guess I'm thinking of looking for corner cases or cases in the data that these teams

621
00:40:29,960 --> 00:40:35,760
might not have thought about that based on your experience, you could foresee causing

622
00:40:35,760 --> 00:40:37,840
poor model performance.

623
00:40:37,840 --> 00:40:40,640
How do you approach that part of the role?

624
00:40:40,640 --> 00:40:43,760
Now, there are definitely two components to it, right?

625
00:40:43,760 --> 00:40:47,040
I mean, so there's definitely weaknesses that you would see.

626
00:40:47,040 --> 00:40:53,800
And like a specific model that requires like a free-contrading or is extremely sensitive

627
00:40:53,800 --> 00:40:57,760
to seasonality would be something that we would like to look at and try to figure out

628
00:40:57,760 --> 00:40:59,520
like what is causing this, right?

629
00:40:59,520 --> 00:41:05,600
I mean, so the way we do that is essentially, we essentially keep track of, for example,

630
00:41:05,600 --> 00:41:09,480
the assume that your model is something like a logistic regression model because it's

631
00:41:09,480 --> 00:41:11,760
a easy to explain.

632
00:41:11,760 --> 00:41:17,720
So you would be able to see like what parameters are extremely stable over time and essentially

633
00:41:17,720 --> 00:41:19,840
don't change even when you will train the model.

634
00:41:19,840 --> 00:41:24,680
And which one of these parameters are actually extremely volatile and have a very big error

635
00:41:24,680 --> 00:41:25,680
to it, right?

636
00:41:25,680 --> 00:41:30,040
And so we would actually understand very with precision, but parameters are causing the

637
00:41:30,040 --> 00:41:31,640
model to underperform.

638
00:41:31,640 --> 00:41:36,720
So that's kind of like a reverse engineer, other people's model in order to understand

639
00:41:36,720 --> 00:41:37,880
what the weaknesses are.

640
00:41:37,880 --> 00:41:42,400
So that's one thing we do when we're trying to kind of automate.

641
00:41:42,400 --> 00:41:47,920
The other piece is something which is like something you have an inkling that requires

642
00:41:47,920 --> 00:41:48,920
to be updated, right?

643
00:41:48,920 --> 00:41:53,440
I mean, so an example of something we have tried to do recently is that we were trying

644
00:41:53,440 --> 00:41:57,680
to add the notion of geolocation to which he personalized the results depending on

645
00:41:57,680 --> 00:42:00,080
your location in the country, right?

646
00:42:00,080 --> 00:42:06,800
And so I mean, you know that this needs to be taken into account and you know that you're

647
00:42:06,800 --> 00:42:11,000
going to add that feature in the model, but the question is like, what is your base data

648
00:42:11,000 --> 00:42:13,760
set and your best bet to actually add that to the model, right?

649
00:42:13,760 --> 00:42:19,960
I mean, so this is why we have statistical analyst trying to assess the quality of the

650
00:42:19,960 --> 00:42:22,880
different data sets that we have available.

651
00:42:22,880 --> 00:42:27,320
So this is where our job actually gets interesting because we get to touch to lots of different

652
00:42:27,320 --> 00:42:29,080
data sets across the company, right?

653
00:42:29,080 --> 00:42:34,080
And try to understand what is the data source that we could use to actually improve these

654
00:42:34,080 --> 00:42:37,560
signals and make our search engine better.

655
00:42:37,560 --> 00:42:45,520
So do you have, is this maybe goes back to our platform discussion a moment ago, but

656
00:42:45,520 --> 00:42:54,360
is there a place that has a dashboard of all the models that are running in Walmart?

657
00:42:54,360 --> 00:42:58,920
I guess I'm wondering at the granularity at which you track this like, do you have a

658
00:42:58,920 --> 00:43:04,480
master view of all deployed models and their performance and you can do trend analysis

659
00:43:04,480 --> 00:43:11,000
across this and see, you know, where logistic regression, you know, types of models work

660
00:43:11,000 --> 00:43:17,080
versus other things or are these things managed more on a product by product basis?

661
00:43:17,080 --> 00:43:22,320
No, no, we're definitely geared towards like at least for search, I mean, we're definitely

662
00:43:22,320 --> 00:43:28,880
moving forward to a phase where we get to see a holistic view of all models in product

663
00:43:28,880 --> 00:43:29,880
model.

664
00:43:29,880 --> 00:43:30,880
At one time, right?

665
00:43:30,880 --> 00:43:35,760
I mean, so basically if lots of your models are using the same base model, like it's

666
00:43:35,760 --> 00:43:39,840
fairly easy to do, it gets more complicated if you have many different types of machine

667
00:43:39,840 --> 00:43:44,200
learning models in production, but we definitely believe that you should have a comprehensive

668
00:43:44,200 --> 00:43:45,840
view of everything.

669
00:43:45,840 --> 00:43:50,360
For the reason we mentioned earlier that you have some crosstalk happening across models,

670
00:43:50,360 --> 00:43:51,360
right?

671
00:43:51,360 --> 00:43:54,520
I mean, it's possible that the fact that one model is underperforming is caused by another

672
00:43:54,520 --> 00:43:59,880
one overperforming and so we believe that you cannot keep things segmented and just keep

673
00:43:59,880 --> 00:44:01,680
track of one product at a time.

674
00:44:01,680 --> 00:44:06,320
I mean, I really strongly believe that having a comprehensive view as much as possible

675
00:44:06,320 --> 00:44:08,360
is really important.

676
00:44:08,360 --> 00:44:12,960
Getting to the level where we have a comprehensive view of all the models across the company is

677
00:44:12,960 --> 00:44:21,080
going to be very challenging as you can imagine, but to what extent do you use machine learning

678
00:44:21,080 --> 00:44:23,680
models to manage these models?

679
00:44:23,680 --> 00:44:25,880
And then how do you do that?

680
00:44:25,880 --> 00:44:27,800
That's definitely what we want to do, right?

681
00:44:27,800 --> 00:44:33,600
I mean, I sometimes call my team like the team that creates machine learning models of

682
00:44:33,600 --> 00:44:34,760
machine learning models, right?

683
00:44:34,760 --> 00:44:40,800
And so essentially the way you would do that is essentially using the parameters of the

684
00:44:40,800 --> 00:44:43,960
other models as a feature for another model, right?

685
00:44:43,960 --> 00:44:47,320
I mean, so basically you're kind of, as you mentioned earlier, right?

686
00:44:47,320 --> 00:44:49,080
I mean, you want to manage your things over time.

687
00:44:49,080 --> 00:44:53,240
So essentially like a trend analysis would be something that could, you know, you could

688
00:44:53,240 --> 00:44:57,600
definitely use machine learning for this type of management.

689
00:44:57,600 --> 00:45:01,600
And are you doing this at all today or is it more directional?

690
00:45:01,600 --> 00:45:02,800
Getting started.

691
00:45:02,800 --> 00:45:03,800
Okay.

692
00:45:03,800 --> 00:45:04,800
Interesting.

693
00:45:04,800 --> 00:45:05,800
Interesting.

694
00:45:05,800 --> 00:45:10,480
Yeah, I can imagine if you have all of your model data, all of your parameter data,

695
00:45:10,480 --> 00:45:15,520
all of your performance data, you know, then part of what your measure team is able to

696
00:45:15,520 --> 00:45:20,920
do is someone brings you a model and some data and you can just run your meta model against

697
00:45:20,920 --> 00:45:23,640
it and predict whether their model is going to work or not.

698
00:45:23,640 --> 00:45:25,240
It sounds like a great application.

699
00:45:25,240 --> 00:45:26,240
Yeah.

700
00:45:26,240 --> 00:45:27,240
Awesome.

701
00:45:27,240 --> 00:45:30,640
Is there anything else that your team is focused on that we haven't talked about so far?

702
00:45:30,640 --> 00:45:33,200
Well, I mean, I've covered most of it.

703
00:45:33,200 --> 00:45:37,840
I mean, the one thing is like I mentioned this effort to actually bring the stores data

704
00:45:37,840 --> 00:45:39,720
together with the online data.

705
00:45:39,720 --> 00:45:42,400
So this is an effort we started pretty recently.

706
00:45:42,400 --> 00:45:45,000
One of the challenges we're trying to tackle is the following.

707
00:45:45,000 --> 00:45:49,640
So, uh, the search is actually an interesting problem because where, as you can imagine, we're

708
00:45:49,640 --> 00:45:53,960
using like lots of different data sources to rank the items we're showing to the customer,

709
00:45:53,960 --> 00:45:54,960
right?

710
00:45:54,960 --> 00:45:59,560
And so essentially we're using data related to the content of the items.

711
00:45:59,560 --> 00:46:04,040
So if somebody searches for TV Samsung, you want to show that you're like the right

712
00:46:04,040 --> 00:46:06,160
brand and the right product for sure.

713
00:46:06,160 --> 00:46:10,560
But then the question is among Samsung TVs, which one do you want to show first, right?

714
00:46:10,560 --> 00:46:14,960
And so the answer to that is you're showing the one that is the most popular.

715
00:46:14,960 --> 00:46:20,920
So we sometimes run into a problem because I think, for example, of like a smaller type

716
00:46:20,920 --> 00:46:23,080
of item that you would usually buy in the store, right?

717
00:46:23,080 --> 00:46:26,720
I mean, so sometimes people connect to walmart.com website.

718
00:46:26,720 --> 00:46:31,440
They enter a search and they actually decide to go buy that item in store.

719
00:46:31,440 --> 00:46:36,680
So the reason why they actually search for that item was to check the inventory in their

720
00:46:36,680 --> 00:46:38,800
local, local Walmart store, right?

721
00:46:38,800 --> 00:46:44,280
I mean, so for us as the search team, this is really a problem because if you see someone

722
00:46:44,280 --> 00:46:47,360
click on the item, but they eventually they don't purchase it.

723
00:46:47,360 --> 00:46:51,200
We take that as a bad sign that we didn't show the right item, right?

724
00:46:51,200 --> 00:46:55,680
And so essentially that would cause us to demote that item over time.

725
00:46:55,680 --> 00:47:00,560
And it's very possible that the item that we showed was actually the one that the customer

726
00:47:00,560 --> 00:47:01,560
meant to see, right?

727
00:47:01,560 --> 00:47:05,360
I mean, and so it is very possible that eventually they bought that.

728
00:47:05,360 --> 00:47:10,880
So closing the loop with that and actually like attributing a specific store purchase

729
00:47:10,880 --> 00:47:15,720
to a specific online search is something that we're trying to do now, right?

730
00:47:15,720 --> 00:47:18,960
I mean, so I think people have heard of the new Google attribution, right?

731
00:47:18,960 --> 00:47:23,400
And they actually get to track you when you shop in store as well as online.

732
00:47:23,400 --> 00:47:29,200
I mean, we're essentially trying to do that for essentially mapping the, like essentially

733
00:47:29,200 --> 00:47:33,440
mapping the gap between the stories and the online experience.

734
00:47:33,440 --> 00:47:34,440
Mm-hmm.

735
00:47:34,440 --> 00:47:39,320
And that that's what the data lake enables you to do by pulling all that information into

736
00:47:39,320 --> 00:47:42,120
the one place and allowing folks to build models across it.

737
00:47:42,120 --> 00:47:44,120
Yeah, definitely.

738
00:47:44,120 --> 00:47:45,120
Interesting.

739
00:47:45,120 --> 00:47:50,960
Anna, are you, to what extent are you using external data sources and building your search

740
00:47:50,960 --> 00:47:52,960
models?

741
00:47:52,960 --> 00:47:57,360
So we're, I mean, we do, you know, like I don't know that we're using like a lot of

742
00:47:57,360 --> 00:47:58,360
data sources.

743
00:47:58,360 --> 00:48:03,840
I mean, the external data sources we essentially use is to, I would say for monitoring purposes,

744
00:48:03,840 --> 00:48:04,840
right?

745
00:48:04,840 --> 00:48:08,680
I mean, so for example, we're trying to catch instances where we have a cold stock

746
00:48:08,680 --> 00:48:09,680
problem, right?

747
00:48:09,680 --> 00:48:13,440
I mean, so if something doesn't sell really well at Walmart, when you actually know this

748
00:48:13,440 --> 00:48:17,400
is a very popular item on the marketplace, you would try to do something about it.

749
00:48:17,400 --> 00:48:22,520
But we don't necessarily use that to create and build new models or essentially focusing

750
00:48:22,520 --> 00:48:24,480
on our own data at this point.

751
00:48:24,480 --> 00:48:25,480
Got it.

752
00:48:25,480 --> 00:48:26,480
Got it.

753
00:48:26,480 --> 00:48:27,480
All right.

754
00:48:27,480 --> 00:48:30,760
Well, this has been a really, really interesting conversation and I appreciate you taking

755
00:48:30,760 --> 00:48:33,720
the time out to chat with us about what you're up to.

756
00:48:33,720 --> 00:48:39,680
But I think folks can learn a ton about the machine learning lifecycle management challenge

757
00:48:39,680 --> 00:48:44,920
and, and, and learn a ton from the way you guys have taken it on at, at Walmart.

758
00:48:44,920 --> 00:48:47,560
I really appreciate you taking the time to join us.

759
00:48:47,560 --> 00:48:48,560
No worries.

760
00:48:48,560 --> 00:48:50,360
I mean, I always love talking about this topic.

761
00:48:50,360 --> 00:48:51,360
So my pleasure.

762
00:48:51,360 --> 00:48:52,360
Awesome.

763
00:48:52,360 --> 00:48:55,360
Thanks so much, Jennifer.

764
00:48:55,360 --> 00:48:59,320
All right, everyone.

765
00:48:59,320 --> 00:49:05,680
What's our show for today for the notes for this episode head on over to twimmaleye.com

766
00:49:05,680 --> 00:49:13,160
slash talk slash 46, whether this is your first or 50th show, I want to thank you so much

767
00:49:13,160 --> 00:49:14,560
for listening.

768
00:49:14,560 --> 00:49:16,120
I really want to hear from you.

769
00:49:16,120 --> 00:49:21,040
So please take a moment to comment on the show notes page or on Twitter with your feedback

770
00:49:21,040 --> 00:49:26,440
or questions or just what you found most interesting and useful about this episode.

771
00:49:26,440 --> 00:49:31,320
Also, if you share your favorite quote via a comment or social media, we'll send you

772
00:49:31,320 --> 00:49:34,360
one of our fab laptop stickers.

773
00:49:34,360 --> 00:49:39,200
Another thanks to this week's sponsor, Claudeira, for more information on their data science

774
00:49:39,200 --> 00:49:47,000
workbench or to schedule your demo and get a free drone, visit twimmaleye.com slash Claudeira.

775
00:49:47,000 --> 00:49:51,160
If you subscribe to my newsletter, you already know that I've got a busy month ahead as

776
00:49:51,160 --> 00:49:53,280
far as events go.

777
00:49:53,280 --> 00:49:58,840
The week of September 18th, I'll be in San Francisco for the O'Reilly Artificial Intelligence

778
00:49:58,840 --> 00:49:59,840
Conference.

779
00:49:59,840 --> 00:50:04,360
There's also a chance that on Saturday the 16th, I'll make it to the Scaling Deep Learning

780
00:50:04,360 --> 00:50:08,720
Conference NSF, which looks to be an interesting one.

781
00:50:08,720 --> 00:50:13,120
The following week, I'll be at Strange Loop, a great technical conference held each year

782
00:50:13,120 --> 00:50:15,440
right here in St. Louis.

783
00:50:15,440 --> 00:50:21,200
Now I love meeting up with listeners, so if you're planning to be at any of these events,

784
00:50:21,200 --> 00:50:26,240
please drop me a note via a comment, the contact form, or Twitter.

785
00:50:26,240 --> 00:50:29,920
For more info on any of these events, check out the show notes.

786
00:50:29,920 --> 00:50:59,880
Thanks again for listening and catch you next time.

