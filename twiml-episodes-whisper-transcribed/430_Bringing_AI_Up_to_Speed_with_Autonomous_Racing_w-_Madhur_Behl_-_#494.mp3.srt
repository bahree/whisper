1
00:00:00,000 --> 00:00:15,680
All right, everyone. I'm here with Mador Behehl. Mador is an assistant professor in the

2
00:00:15,680 --> 00:00:21,280
Department of Computer Science at the University of Virginia. Mador, welcome to this one, my AI

3
00:00:21,280 --> 00:00:26,640
podcast. Yeah, thank you for inviting me, Sam. I'm very happy to be here and excited to share

4
00:00:26,640 --> 00:00:32,240
a thing or two about autonomous racing today. We are going to have a really interesting conversation.

5
00:00:33,120 --> 00:00:39,120
As you mentioned, we're talking about autonomous racing, but before we dig in or race off into

6
00:00:39,120 --> 00:00:43,840
that direction, I'd love to hear you share a little bit about your background and tell us how you

7
00:00:43,840 --> 00:00:52,160
came to work in autonomous vehicles and autonomous racing. Sure, so I think for me, the trajectory

8
00:00:52,160 --> 00:00:59,040
into AI and autonomous racing, it really started because of my love and affinity for robotics and

9
00:00:59,040 --> 00:01:05,040
autonomous systems. So as far as I can remember, I've always been interested in robotics and that

10
00:01:05,040 --> 00:01:11,520
that interest really took shape in my undergraduate back in India, where I even got the chance to sort

11
00:01:11,520 --> 00:01:18,240
of lead the robotics club of my university. I must say, though, back then, you know, I was miles

12
00:01:18,240 --> 00:01:24,720
away from doing anything principal than scientific and what would be an AI. It was mostly about

13
00:01:24,720 --> 00:01:30,400
hacking your way through just getting this set of motor and arms to work and climbing staircase

14
00:01:30,400 --> 00:01:37,680
or navigate some obstacle avoidance course. So I have no shame in admitting early on that I think

15
00:01:37,680 --> 00:01:43,760
I probably have built five or half a dozen robots without ever having written a single piece of

16
00:01:43,760 --> 00:01:51,280
mathematical equation or even drawing on matrix. So really, I think the the journey for me solidified

17
00:01:51,280 --> 00:01:56,880
when I started attending grad school at the University of Pennsylvania and that's really where I

18
00:01:56,880 --> 00:02:01,760
started, you know, learning about the theoretical underpinnings of the field and developing the

19
00:02:01,760 --> 00:02:07,600
background in in control systems and embedded systems and optimization and eventually in machine

20
00:02:07,600 --> 00:02:13,920
learning and autonomous systems and deep learning, which we all know are somewhat like the ingredients of

21
00:02:13,920 --> 00:02:21,440
this, you know, AI field. And so for me, I think the the tipping point or what I realized was that

22
00:02:21,440 --> 00:02:28,000
I had affinity to apply novel theoretical methods but to physical system, right? So that that

23
00:02:28,000 --> 00:02:33,360
aspect of having to control something in the real world, whether that's a robot or it could be

24
00:02:33,360 --> 00:02:38,880
even a building automation system, but something physical, something even safety critical or life

25
00:02:38,880 --> 00:02:44,880
critical. That's something which is canonical to most of my research even today. And so when I

26
00:02:44,880 --> 00:02:50,480
joined the University of Virginia a little over three and a half years ago, you know, I got very

27
00:02:50,480 --> 00:02:57,600
excited and interested in safety aspects of AI for robotics for autonomous systems and self-driving

28
00:02:57,600 --> 00:03:04,320
cars are a very good example for this sort of a problem and someone would consider self-driving cars

29
00:03:04,320 --> 00:03:09,120
to be one of the biggest challenges in the field right now and one which has the potential to

30
00:03:09,120 --> 00:03:15,200
transform mobility. So it got my attention and I was very fortunate to work with some super shop

31
00:03:15,200 --> 00:03:21,200
students and very, you know, great colleagues and have the freedom to pursue some crazy ideas

32
00:03:21,200 --> 00:03:26,480
including one that I would love to talk about today where we are trying to train artificial

33
00:03:26,480 --> 00:03:33,200
intelligence to race self-driving cars at speeds of over 150 miles per hour. Yeah, that's awesome,

34
00:03:33,200 --> 00:03:42,240
that's all. And we will talk about that. I'd like to start by understanding your perspective on

35
00:03:42,240 --> 00:03:52,320
autonomous vehicles racing relative to kind of the more typical autonomous vehicle challenges,

36
00:03:52,320 --> 00:03:59,440
right? In, you know, city driving on the one hand you've got to worry about, you know, pedestrians

37
00:03:59,440 --> 00:04:06,720
and, you know, untrained drivers and balls rolling in the street. All these kinds of challenges

38
00:04:06,720 --> 00:04:12,800
that, you know, we're struggling to figure out how to deal with safely, you know, not to mention

39
00:04:13,440 --> 00:04:16,160
your path planning in an urban environment and that kind of thing.

40
00:04:16,160 --> 00:04:25,600
And a track environment, your, you know, navigation, you know, is constrained quite a bit,

41
00:04:25,600 --> 00:04:31,760
that may be simpler, you know, you may tell us if not. You don't have balls typically rolling

42
00:04:31,760 --> 00:04:36,080
in the street, you don't have the pedestrians trying to run across the track, you know, how do you

43
00:04:36,080 --> 00:04:43,600
think about racing versus, you know, commercial or passenger autonomous vehicles that we're

44
00:04:43,600 --> 00:04:47,840
trying to develop in terms of, you know, relative challenging complexity.

45
00:04:48,560 --> 00:04:53,760
Yeah, I think that's a very great, great question and it touches upon a very key issue that

46
00:04:53,760 --> 00:04:58,960
you already identified that racing as a, as an environment is very different from, you know,

47
00:04:58,960 --> 00:05:04,160
regular driving or urban driving. So, so, so let me maybe, you know, touch upon where I see the

48
00:05:04,160 --> 00:05:09,040
connections and the differences between the two. So, so in a nutshell, you know, if you look at

49
00:05:09,040 --> 00:05:15,200
what is happening in the autonomous vehicle industry today in terms of making a case for

50
00:05:15,200 --> 00:05:21,440
whether or not their prototype car is safe, I really see like two, two ends of a spectrum,

51
00:05:21,440 --> 00:05:26,960
which have to be somewhat navig, we have to navigate those in order to get to like a substantial

52
00:05:26,960 --> 00:05:33,440
point where it can be considered safe enough to be running in the wild. So on one hand, I would say

53
00:05:33,440 --> 00:05:39,840
the approach is what we can describe as brute force. So, let's drive millions of miles whether

54
00:05:39,840 --> 00:05:44,160
in simulation or in the real world using hundreds of thousands of vehicles in the fleet.

55
00:05:44,800 --> 00:05:49,360
And really, you know, start looking at where did the vehicle make a mistake, when did the safety

56
00:05:49,360 --> 00:05:54,640
operator had to intervene, when did somebody disengage the autonomous mode and things like that.

57
00:05:54,640 --> 00:05:59,200
So it's like a, you know, bucket list of, oh, here's something I have to get back to my engineers

58
00:05:59,200 --> 00:06:04,560
and design, been back to the table. And so it, I don't want to undermine the value of real world

59
00:06:04,560 --> 00:06:10,240
testing. I think it's irreplaceable, but at the same time, this sort of a exhaustive approach,

60
00:06:10,880 --> 00:06:15,760
some might argue is, you know, the list of things that you have to account for are, you know,

61
00:06:15,760 --> 00:06:20,800
uncountable or infinite in some sense, the list of possible things that can go wrong. And these include

62
00:06:20,800 --> 00:06:25,440
you're checking off a list of corner cases. You've got a long list that you need to check off.

63
00:06:25,440 --> 00:06:30,320
Yeah, and I would say that it's maybe even impossible to check it off completely. So you get into

64
00:06:30,320 --> 00:06:35,920
this whole argument about what sort of a statistical guarantee could you offer at the end of the day.

65
00:06:35,920 --> 00:06:40,960
I think that's a, that's a separate discussion to be had. So you're right, you know, and the part

66
00:06:40,960 --> 00:06:47,040
of the problem is this heterogeneity in the number of objects that have to appear in the scene.

67
00:06:47,040 --> 00:06:52,320
And even if you have perfect detection of these different agents, different vehicles or

68
00:06:52,320 --> 00:06:56,960
lane markings, traffic signs, traffic lights, pedestrians, pets, they're a very long list.

69
00:06:58,080 --> 00:07:04,080
Even if you had 100% accurate scene understanding, it's very difficult to anticipate what everybody

70
00:07:04,080 --> 00:07:09,440
else is doing, which you need to do in order to plan your own sort of maneuver in the short term,

71
00:07:09,440 --> 00:07:14,720
in like, you know, the next second or two seconds. So this is where I think most of the focus of

72
00:07:14,720 --> 00:07:21,040
demonstrations and very impressive in many cases without a driver behind the wheels is being done

73
00:07:21,040 --> 00:07:27,920
today. On the other end of this spectrum is more theoretical. We need some breakthrough, I would say,

74
00:07:27,920 --> 00:07:35,520
in bridging AI and deep learning with giving guarantees or formal methods, which is like a sub-discipline

75
00:07:35,520 --> 00:07:42,640
and computer science, right? So can we design algorithms which we can, you know, look at what bad

76
00:07:42,640 --> 00:07:48,160
inputs will cause, what bad outputs. And in a nutshell, they have to be accountable for why they

77
00:07:48,160 --> 00:07:53,440
are making a mistake, which is, you know, we are very far from that. There's some very exciting work

78
00:07:53,440 --> 00:07:58,320
in that area as well, but we are not quite there yet, you know, so that breakthrough has to occur.

79
00:07:58,320 --> 00:08:02,640
So this is a wide spectrum. There's many other approaches. I'm a little bit simplifying it.

80
00:08:03,600 --> 00:08:10,000
And so I see there's many intermediate steps where you could still make progress and enhance

81
00:08:10,000 --> 00:08:16,720
safety of cell driving cars. And so one idea or rather hypothesis that we are working on is what I

82
00:08:16,720 --> 00:08:23,600
would call safety through agility, with the idea of being that if we can teach an autonomous

83
00:08:23,600 --> 00:08:30,560
vehicle how to operate at the limits of its control, how to steer aggressively, how to break

84
00:08:30,560 --> 00:08:37,520
aggressively, how to maneuver in an agile manner, then I would argue you are ultimately enhancing

85
00:08:37,520 --> 00:08:44,320
the safety of that autonomous vehicle, right? So I'll be the first one to say that, you know,

86
00:08:44,320 --> 00:08:50,640
driving safely and driving in an agile manner seem to be very contradictory, sort of objectives.

87
00:08:50,640 --> 00:08:54,000
And so we are not proposing that you weave through traffic all the time.

88
00:08:55,360 --> 00:09:00,560
But but instead there are some theoretical results to say those folks that drive a little fast

89
00:09:00,560 --> 00:09:06,960
and weave through traffic help the traffic. Yeah, yeah, you're right. I can't argue with that.

90
00:09:06,960 --> 00:09:14,400
But yeah, so the idea is we have all experienced this when we drive ourselves that there are

91
00:09:14,400 --> 00:09:19,920
irrational drivers as a mix of sort of human and semi-economist eventually autonomous cars.

92
00:09:19,920 --> 00:09:24,240
And so we've seen, you know, occasionally that driver who indicates they will take the right

93
00:09:24,240 --> 00:09:28,640
exit but then the merge left in front of you at the last second or someone who just break

94
00:09:28,640 --> 00:09:34,480
check you for no reason or speed up and overtaken an unsafe manner. So so so there's all these

95
00:09:34,480 --> 00:09:41,040
dynamic situations that the self-driving car has to deal with. And I would even go as far as saying

96
00:09:41,040 --> 00:09:49,600
that any collision or any imminent collision at the in the very last few milliseconds or even a second

97
00:09:49,600 --> 00:09:55,280
looks a lot like, you know, racing because you are at a high speed and it's like a very abrupt

98
00:09:55,280 --> 00:10:03,600
change in momentum. And so so the idea is that can we use racing as a means to learn this agile

99
00:10:03,600 --> 00:10:09,120
controller, right? So this this controller that will augment the safe operation and but kick in

100
00:10:09,120 --> 00:10:13,920
when there's an imminent collision. So so I jokingly say this but I think it's becoming true and

101
00:10:13,920 --> 00:10:18,400
true. Everybody's teaching their vehicles to remain on the road. I'm teaching them with the

102
00:10:18,400 --> 00:10:22,720
ability to go off road if it matters most if it ends up, you know, saving someone's life at the end

103
00:10:22,720 --> 00:10:29,760
of the day. So so that's the connect between being safe and being agile. And so the next question

104
00:10:29,760 --> 00:10:36,000
obviously is that how do you train a autonomous vehicle to be agile? And so that's where we draw

105
00:10:36,000 --> 00:10:41,760
inspiration from motorsport racing. And we simply say that let's race these cars against each other

106
00:10:41,760 --> 00:10:48,000
in these high speed close proximity situations, which are the norm rather than the exception when

107
00:10:48,000 --> 00:10:52,880
it comes to being on the track, right? So most of racing is drivers trying to crash each other but

108
00:10:52,880 --> 00:10:57,920
not quite. And even like impeding the progress of each other. So if we can capture those

109
00:10:57,920 --> 00:11:05,440
patient temporal interactions and you know manifest them into a robust algorithm, then we have a

110
00:11:05,440 --> 00:11:11,360
chance of bringing it back to urban driving and enhancing overall safety. So so in a nutshell,

111
00:11:11,360 --> 00:11:17,680
you know, in motorsport racing, there's a saying that if everything seems under control,

112
00:11:17,680 --> 00:11:22,000
then you're not going fast enough, right? That's the that's the mentality of the race driver.

113
00:11:22,000 --> 00:11:27,600
And so what I'm trying to do is develop an AI with with that statement as its objective function.

114
00:11:28,720 --> 00:11:38,400
Nice. So to kind of understand the the landscape and the approaches in autonomous racing on the

115
00:11:40,240 --> 00:11:45,760
you know, urban driving kind of contemporary autonomous vehicles. One of the

116
00:11:45,760 --> 00:11:55,600
dimensions in which there are strong opinions is kind of the you know vision first or vision only

117
00:11:55,600 --> 00:12:05,200
approach, you know, versus kind of sensor fusion. That's kind of correlated in some ways to end

118
00:12:05,200 --> 00:12:17,840
to end deep learning versus ensemble systems is. And I'm curious if the the racing setting has

119
00:12:17,840 --> 00:12:27,360
specific implications in those dimensions or you know, or you know, as it just is diverse, the

120
00:12:28,560 --> 00:12:34,480
directions that folks are going. Yeah. So the the short answer is there's a lot of room for

121
00:12:34,480 --> 00:12:40,160
many approaches, but but I'll I'll get into a little bit in the weeds of, you know, answering that

122
00:12:40,160 --> 00:12:45,360
more specifically. So so Geek out with me for a second here Sam. So, you know, and even it goes

123
00:12:45,360 --> 00:12:52,800
back to even what she said earlier. So, yes, racing doesn't look visually anything like urban driving.

124
00:12:52,800 --> 00:12:57,680
We don't have to solve this problem of detecting a million things on the track, right? There's

125
00:12:57,680 --> 00:13:02,160
only a few things. You would be actually surprised if there's anything besides another car on the

126
00:13:02,160 --> 00:13:07,920
track. We don't want that at all. So, so yes, you know, the equivalency is broken there. I think

127
00:13:07,920 --> 00:13:15,680
the biggest sort of if I have to sort of outline it in terms of approaches or technical issues.

128
00:13:16,720 --> 00:13:21,920
So every robot or every set of driving car has to solve these three problems of perception,

129
00:13:21,920 --> 00:13:27,600
planning and control. That's the common DNA for all of robotics. And so so in perception,

130
00:13:27,600 --> 00:13:33,280
we have a different set of problems in racing, but they are going to affect regular driving.

131
00:13:33,280 --> 00:13:38,240
I mean, list some of the challenges itself. And then we can discuss whether vision only or

132
00:13:38,240 --> 00:13:45,760
fusion is a better way to go about it. So, no one or there is literally very limited or non-existing

133
00:13:45,760 --> 00:13:54,720
data. How does lidar and camera and radar perform at speeds excess of 150 miles per hour, right? So,

134
00:13:54,720 --> 00:14:00,800
this vibration images are going to get blurred. Is there skew in the radar because you are moving

135
00:14:00,800 --> 00:14:05,680
at hundreds of feet per second. So, by the time you receive some packet, things have already moved

136
00:14:05,680 --> 00:14:11,360
around in your vicinity. And so, you know, what is the time specific to vehicles? I would have

137
00:14:11,360 --> 00:14:18,720
imagined that, you know, we'd be drawing on military uses of or, you know, aeronautical uses of

138
00:14:18,720 --> 00:14:23,040
radar and lidar and there would be lots of information about how they perform at speed.

139
00:14:23,040 --> 00:14:28,880
Yeah, but would you be surprised like the sort of sensors that we are working on with the

140
00:14:28,880 --> 00:14:33,280
full-scale car, which are the same sensors. So, let me maybe re-phrase my statement.

141
00:14:33,280 --> 00:14:39,520
Yeah. The same family of sensors, which are on urban cars, haven't been tested yet on these

142
00:14:39,520 --> 00:14:45,120
things. So, you are right. There's definitely something that I don't know of or this classified

143
00:14:45,120 --> 00:14:50,000
sensor, which has been tested. Yeah. Yeah. And I thought you were referring to

144
00:14:50,000 --> 00:14:53,840
lidar and radar as a broad class. No, no, no, no.

145
00:14:53,840 --> 00:14:58,400
It has opposed to the specific, you know, working with a specific sensor. Yeah, that's a great

146
00:14:58,400 --> 00:15:03,360
point because, you know, if we're talking about a machine learning, deep learning solution,

147
00:15:03,360 --> 00:15:06,880
they're going to be quite sensitive to the actual sensors that you're using.

148
00:15:06,880 --> 00:15:11,840
Yeah, you got it, right? So, the specific sensors themselves, we have to work with a lot of issues.

149
00:15:11,840 --> 00:15:18,400
Like, even something that you may not think about for a regular car, there's a very important aspect

150
00:15:18,400 --> 00:15:22,880
that all your sensor data has to be perfectly synchronized to the same clock.

151
00:15:23,440 --> 00:15:29,840
And in regular driving, you can bear some offset between the lidar and the camera images,

152
00:15:29,840 --> 00:15:34,560
right? So, the lidar is telling you there's an obstacle at this bearing and this distance,

153
00:15:34,560 --> 00:15:38,480
but the camera is telling you that the pixel and the obstacle is offset.

154
00:15:38,480 --> 00:15:42,960
You can get by, you can do some machine learning to fix that, learn the skew over time.

155
00:15:42,960 --> 00:15:50,880
In racing, the margins become very, very thin, right? So, the burden then is shifted to the

156
00:15:50,880 --> 00:15:56,080
software because you can only do so much hardware synchronization on the real sensor.

157
00:15:56,080 --> 00:16:02,080
So, these are just few examples in the perception stack, right? So, let's move to planning and then

158
00:16:02,080 --> 00:16:10,320
we can go back to the fusion question. So, in racing, I would say planning is somewhat harder

159
00:16:10,320 --> 00:16:15,440
than regular driving because there is no structure to the traffic, right? So, racing has some

160
00:16:15,440 --> 00:16:20,800
general etiquette that drivers respect each other. They don't want to crash their own car,

161
00:16:20,800 --> 00:16:25,360
but it's not as spelled out as the rules of the road, which are embedded deep into

162
00:16:26,000 --> 00:16:29,920
all the motion planning algorithms of regular self-dabbing vehicles today.

163
00:16:29,920 --> 00:16:34,240
So, there's no concept of yield or, you know, you don't want to yield basically,

164
00:16:34,240 --> 00:16:37,840
but at the same time, you don't want to go into unnecessary risks. So,

165
00:16:37,840 --> 00:16:45,200
so there, one of the challenges that we have to solve is we have to build state estimation algorithms

166
00:16:45,200 --> 00:16:50,160
that will give a best guess or the likelihood of what the racing driver

167
00:16:50,880 --> 00:16:55,360
in front of us and behind us is going to do. And that's another thing about racing. You also have

168
00:16:55,360 --> 00:16:59,520
to worry about what's behind you and not just everything is not just forward looking because you

169
00:16:59,520 --> 00:17:05,600
have to sometimes maneuver to gain, like, positional advantage. And so, here there's a lot of room

170
00:17:05,600 --> 00:17:15,040
for normal algorithms where, you know, you are planning in a manner that you want to trade off

171
00:17:16,000 --> 00:17:21,200
risk versus your track position, but at the same time, you really don't want to thread the

172
00:17:21,200 --> 00:17:28,320
needle between two cars if it's not absolute necessary to do so. So, so we made some, you know,

173
00:17:28,320 --> 00:17:34,000
some algorithms, which are a mix of, I would say, this end-to-end idea and, you know,

174
00:17:34,000 --> 00:17:39,920
classical approach of path planning. So, so I'll give you one example that in one of my work

175
00:17:39,920 --> 00:17:48,560
with my PhD student Trent Weiss. So, he has developed this simulator. Essentially, he has taken

176
00:17:48,560 --> 00:17:54,480
the world's most famous Formula One game. And this game is so photorealistic that it's used by

177
00:17:54,480 --> 00:18:00,000
real F1 drivers during the pandemic because they couldn't race in the real world. And so,

178
00:18:00,000 --> 00:18:04,800
it's very photorealistic. It's, you know, building upon decades of high-fidelity physics and

179
00:18:05,360 --> 00:18:10,960
ray tracing graphics and whatnot. And this game is so realistic that it actually outputs a stream

180
00:18:10,960 --> 00:18:16,560
of data to interface with these massive hardware simulators that these drivers train in.

181
00:18:17,120 --> 00:18:23,040
So, we leverage that. We leverage that and we tap or listen into that data stream. And then we

182
00:18:23,040 --> 00:18:28,960
can convert the game into a simulation environment, right? So, all of a sudden, we have methods to

183
00:18:28,960 --> 00:18:34,720
look at the images of the camera from the game from the driver's perspective and annotate that

184
00:18:34,720 --> 00:18:39,360
with some ground truth data about steering, what speed and heading and things like that.

185
00:18:39,360 --> 00:18:44,400
So, this becomes a recipe to try some end-to-end methods. And we did try them and we found that

186
00:18:45,040 --> 00:18:51,280
if you just do a complete pixels to control end-to-end implementation, where you are basing your

187
00:18:51,280 --> 00:18:56,720
steering and throttle based off the scene information or pixel information or even a history of

188
00:18:56,720 --> 00:19:01,360
pixel information or images, it's very brittle, right? So, it's simply just too brittle. The car

189
00:19:01,360 --> 00:19:08,480
cannot recover. If you go off track, you basically ram into the wall for sure. And so, we had to fix

190
00:19:08,480 --> 00:19:16,320
that by breaking this chain of not being purely end-to-end. And so, what we do is we take the images

191
00:19:16,320 --> 00:19:22,560
and instead of mapping them to control values, we map them to trajectories, right? So, we map them

192
00:19:22,560 --> 00:19:28,320
to, this is the path you want to follow for the next, you know, 100 milliseconds or one second

193
00:19:28,320 --> 00:19:34,560
or whatever horizon. And so, that's a go-control. And then, yeah, then you use some low-level control,

194
00:19:34,560 --> 00:19:39,680
like pure pursuit or model predictive control to actually figure out the steering and the throttle

195
00:19:39,680 --> 00:19:45,200
actuation to follow that path. And what we have determined, very surprisingly and interestingly,

196
00:19:45,200 --> 00:19:51,600
this is so robust, right? So, this is already as competitive as some of the best human

197
00:19:51,600 --> 00:19:58,400
export drivers in the game. And, you know, it has a very good understanding of where the track

198
00:19:58,400 --> 00:20:03,760
bounds are. And I must say that initially, we went in purely with this supervised learning

199
00:20:04,480 --> 00:20:09,360
method. So, it's like a behavioral cloning. We have tons of data of drivers driving in the game.

200
00:20:09,360 --> 00:20:15,680
But now, we have the ability to not do just purely supervised learning, but instead,

201
00:20:15,680 --> 00:20:21,840
at runtime, we can actually generate many, many likely trajectories and then synthesize

202
00:20:21,840 --> 00:20:25,680
the preferred trajectory, which has some desirable properties. So, you know, you don't want to turn

203
00:20:25,680 --> 00:20:31,120
the wheel so sharply, or you don't want to minimize some derivative of the trajectory as well.

204
00:20:31,120 --> 00:20:37,520
So, interestingly enough, the way we design these trajectories is using something called

205
00:20:37,520 --> 00:20:42,720
Bezier curves, which have their region and computer graphics. And I just want to throw in this

206
00:20:42,720 --> 00:20:48,880
trivia or snippet here that Pierre Bezier, who was the pioneer of the Bezier curve, he intent,

207
00:20:48,880 --> 00:20:54,480
he used these curves, or when they were invented or used or popularized, he used them to design

208
00:20:54,480 --> 00:20:59,760
the profile of Renault race cars, right? So, in a very serendipitous way, we are bringing the

209
00:20:59,760 --> 00:21:05,760
racing routes of Bezier curves back into autonomous racing. And so, so the last thing I would say here

210
00:21:05,760 --> 00:21:15,680
is, again, if you can put a pin in that for one sec and remember it, you mentioned a bunch of

211
00:21:15,680 --> 00:21:20,960
things I wanted to fill in on, but one of the things that you talked about was you had this

212
00:21:22,640 --> 00:21:28,080
this kind of path that your low-level system is recommending or a family of paths, and then you

213
00:21:28,080 --> 00:21:34,240
have a set of constraints or desired properties. And I'm curious what those, you know, how those

214
00:21:34,240 --> 00:21:41,440
are implemented are those heuristics or those also learned. Where does that, how do you inform

215
00:21:41,440 --> 00:21:48,640
your model of those preferences? Yeah, so they are learned, although that is a possibility to use

216
00:21:48,640 --> 00:21:54,880
some kind of inverse reinforcement learning to learn what objective function the drivers actually

217
00:21:54,880 --> 00:22:01,440
use to generate their own paths, but we aren't there quite yet. So, so what we draw inspiration from

218
00:22:01,440 --> 00:22:07,200
is the actual domain of racing, right? So, so my students have now we have

219
00:22:08,720 --> 00:22:14,320
racing rules, we have watched videos, we have watched interviews of every crash that has happened

220
00:22:14,320 --> 00:22:19,200
and how the drivers explain what went wrong in that crash. And so, this filtering process, right,

221
00:22:19,200 --> 00:22:25,760
if generators set of candidate possible trajectories you could take, and then you have some way of

222
00:22:25,760 --> 00:22:32,080
assigning cost to each trajectory. So, there could be a cost of you don't want to be, you know,

223
00:22:32,080 --> 00:22:36,880
a certain distance laterally from any opponent, and that's, you know, gives the trajectory a certain

224
00:22:36,880 --> 00:22:41,600
way. Another one, like I said before, as you want your trajectory to be have some smoothness

225
00:22:41,600 --> 00:22:46,720
properties so that, you know, the car will spin out if you rank the the steering wheel because

226
00:22:46,720 --> 00:22:53,120
these are very sensitive vehicle dynamics. And so, so this is the layer where we can

227
00:22:53,120 --> 00:23:00,080
sprinkle in the objective functions for collision avoidance, for multi agent racing, for, you know,

228
00:23:00,080 --> 00:23:06,480
taking the sticking as close as possible to the geometric race line. So, we have, you could call

229
00:23:06,480 --> 00:23:12,240
it a heuristic, but it is these are heuristics which are derived from the domain of regular

230
00:23:12,240 --> 00:23:16,880
motorsport racing. So, they're informed by, you know, what drivers typically look to maximize

231
00:23:16,880 --> 00:23:22,000
one day race. So, yeah, so there is room to do some machine learning there as well, but we haven't

232
00:23:22,000 --> 00:23:25,920
gotten to that yet. Awesome, awesome. The third point that you were mentioning.

233
00:23:27,040 --> 00:23:34,000
Yeah, I mean, I was I was talking about that initially, the way we train our algorithm to map

234
00:23:34,000 --> 00:23:41,280
images to trajectories in the front of the car ego vehicle on the track, it's it's it was using

235
00:23:41,280 --> 00:23:46,720
behavioral cloning, which means that we have tons of data observed from the game of regular,

236
00:23:46,720 --> 00:23:53,760
you know, online players. Now, we can even, you know, log into a session as a autonomous agent,

237
00:23:53,760 --> 00:23:59,360
and have a car race autonomously amongst other humans without nobody ever finding out that

238
00:23:59,360 --> 00:24:04,480
they're racing against a game AI, right? So, so, so, so essentially, we can get data,

239
00:24:04,480 --> 00:24:11,120
an observed data of other players as well. And mind you, this is, this seems like a good idea,

240
00:24:11,120 --> 00:24:16,720
but there's a lot of bad data, right? I mean, like, do you have some amateur players who are cutting

241
00:24:16,720 --> 00:24:22,480
corners and we don't want our algorithms to pick that behavior, right? We wanted to have a clean

242
00:24:22,480 --> 00:24:28,400
lap between the bounds of the track and set the fastest sort of lap time as well. So, that's why,

243
00:24:28,400 --> 00:24:34,160
if you just do behavioral cloning, as you would in some any other machine learning setting,

244
00:24:34,160 --> 00:24:39,120
so supervised learning, you just have image and here's the trajectory, which was taken by the

245
00:24:39,120 --> 00:24:43,840
expert. So, just try to, you know, do some least square error between your trajectory and the

246
00:24:43,840 --> 00:24:49,120
ground truth. So, that will get you halfway there, but because you are averaging over

247
00:24:49,840 --> 00:24:56,880
multiple levels of expert data, it won't reach or get you to the point where you become competitive

248
00:24:56,880 --> 00:25:03,520
in this in this setting. So, that's why we have to augment and take a step back from behavioral

249
00:25:03,520 --> 00:25:09,120
cloning by saying that it's not proved end to just generate one trajectory and follow it blindly,

250
00:25:09,120 --> 00:25:14,960
but let's generate a candidate of many possible trajectories and then use these sort of filtering

251
00:25:14,960 --> 00:25:20,160
methods that are described earlier to choose between them. Then the thing that I was wondering was

252
00:25:21,280 --> 00:25:26,800
if the behavioral cloning was related to or if you draw inspiration from imitation learning

253
00:25:27,600 --> 00:25:32,240
as it plays out in like reinforcement learning scenarios? Yes, yes, I would say very much so,

254
00:25:32,240 --> 00:25:38,400
it's a, they're very alike. And then we are, you know, the, we are somewhat hitting the ceiling

255
00:25:38,400 --> 00:25:43,200
of the fact that this is not meant to be a simulator. We are just, it's a game that we have,

256
00:25:43,920 --> 00:25:49,520
and by the way, anyone can, you know, buy the game for what 30 bucks and the API is open source,

257
00:25:49,520 --> 00:25:54,400
you can run all our experiments and I think I provided the link to this as well. But the,

258
00:25:54,400 --> 00:26:01,280
the, you know, this, this, this doesn't behave like a simulator where we could hook it up to some

259
00:26:01,280 --> 00:26:06,480
kind of an open AIJM or reinforcement learning framework and run millions of instances very,

260
00:26:06,480 --> 00:26:11,520
very fast to do exploration, exploitation. So we want to do that. I think we need much more

261
00:26:11,520 --> 00:26:17,520
low level access to the game and we are in conversation with the actual manufacturer of the

262
00:26:17,520 --> 00:26:23,200
the game itself for a much more formal collaboration than us just trying to infer things based

263
00:26:23,200 --> 00:26:31,680
on what's readily available. So, you know, of the, the three areas that we've talked about,

264
00:26:31,680 --> 00:26:38,800
I think perception is about what I expected. You kind of lose some complexity because you don't

265
00:26:38,800 --> 00:26:44,560
have to worry about things coming on the road, but everything's happening much faster. Control,

266
00:26:44,560 --> 00:26:48,400
you know, things are happening much faster. I expect that to be more complex.

267
00:26:48,400 --> 00:26:54,480
Planning, I think, is the one that surprises me. I would have thought that planning was simplified

268
00:26:54,480 --> 00:27:02,720
in the race environment because, you know, you go at the track is, is, is static and circular,

269
00:27:03,680 --> 00:27:10,160
at least in a simple example. And everyone's goals are the same. You don't have people kind of

270
00:27:10,160 --> 00:27:16,480
crossing through your, your domain that are trying to do random things that you have no idea or

271
00:27:16,480 --> 00:27:21,520
can't even fathom or predict what they might be trying to accomplish. But it sounds like that's

272
00:27:21,520 --> 00:27:26,320
not the case in your experience. Yeah, it's, it's, it's, it's not as easy. I mean, there are,

273
00:27:26,320 --> 00:27:33,680
there's some truth to your sort of expectation, but I think the, the thing which I think surprised us

274
00:27:33,680 --> 00:27:40,560
was, even this, even you would imagine it's easier to predict what your opponent is trying to do,

275
00:27:40,560 --> 00:27:46,320
but it turns out it's, it's pretty complicated, right? Because, because there is no, they could be

276
00:27:46,320 --> 00:27:52,400
literally the, the reachability of their likely positions in the future just explodes. Because,

277
00:27:53,040 --> 00:27:58,160
because even a small maneuver can get picked up by some algorithm or a Kalman filter and they

278
00:27:58,160 --> 00:28:02,560
will just extrapolate that to, well, they could be anywhere on the track. Well, if that's the case,

279
00:28:02,560 --> 00:28:07,600
how do I make progress? Right? So, so I think getting that piece pitch perfect has been,

280
00:28:07,600 --> 00:28:14,480
has been more of a challenge than I originally anticipated. And then the, the speed at the end

281
00:28:14,480 --> 00:28:20,000
of the day is the bottom line, which makes all of this super, super difficult, right? So, we don't

282
00:28:20,000 --> 00:28:26,080
have even the luxury of time to do something super complex at runtime, right? Because you may want

283
00:28:26,080 --> 00:28:31,600
to say, okay, when I get to this turn, I'm going to do, you know, take this race line and if

284
00:28:31,600 --> 00:28:36,960
somebody's on my race line, I'm going to plan something else. Well, you know, by the time you figure

285
00:28:36,960 --> 00:28:41,600
out your result, you're already there at the, at the turn, right? So, because the, the car is moving

286
00:28:41,600 --> 00:28:48,720
so fast. So, so getting that trade off of how do you dynamically adjust your horizon? You do,

287
00:28:48,720 --> 00:28:53,680
and then there is, there is high level planning strategy, which comes into play, right? So,

288
00:28:53,680 --> 00:29:00,880
you have to think about the effect of the vehicle dynamics on your planner. So, these cars are

289
00:29:00,880 --> 00:29:06,800
highly specialized and they have very different dynamics than regular sedans or SUVs that we drive.

290
00:29:06,800 --> 00:29:12,640
And so, therefore, you have to understand that the tires will behave differently after 10 laps.

291
00:29:12,640 --> 00:29:17,760
You have to monitor tire temperature, tire pressure, wheel slip angles because the car will just

292
00:29:17,760 --> 00:29:23,840
drift out if you try to, again, turn to send, it's very sensitive to the rate of your steering

293
00:29:23,840 --> 00:29:29,200
that you input into the car itself. You have to account for aerodynamic effects, right? So, in the,

294
00:29:29,200 --> 00:29:34,560
in the real race, and also in the simulation race that we are doing as part of preparing to,

295
00:29:35,360 --> 00:29:41,520
you know, move to the real car, all cars are same, right? It's a battle of AI algorithms.

296
00:29:41,520 --> 00:29:47,200
It's not about who has the deepest pockets or the most expensive motor. So, so, so if everything

297
00:29:47,200 --> 00:29:53,120
is the same, you have two competitive cars. How do you ever overtake your opponent? And so, in

298
00:29:53,120 --> 00:29:59,440
racing, there is this concept of slipstream or drafting. So, when you get behind an opponent,

299
00:29:59,440 --> 00:30:06,000
opportunistically, you will gain upon them because you are moving through less, sort of dirty

300
00:30:06,000 --> 00:30:11,920
air, less draft. And so, so, where's the path planner which takes that into account, right?

301
00:30:13,200 --> 00:30:18,400
It's not there yet. So, so, there is just, the devilism, the details, basically, at the end of

302
00:30:18,400 --> 00:30:23,840
the day. And that's why the motion planning algorithms, which exist for regular driving,

303
00:30:23,840 --> 00:30:28,400
you can take inspiration from them. But because of the lack of structure, there's no lanes,

304
00:30:29,040 --> 00:30:35,200
there's no defined rule set of what other opponents are really trying to do. And that's really what

305
00:30:35,200 --> 00:30:40,880
got, you know, causes the problem. And if it speak to any real race driver, which I've had the,

306
00:30:40,880 --> 00:30:46,480
the good fortune of doing so, they will tell you that they race with feel, okay? They can feel

307
00:30:46,480 --> 00:30:51,440
when the car is sitting at the edge of its traction. They can feel when the rear left is going to

308
00:30:51,440 --> 00:30:56,480
give out any time and so they can back off. In the track that we will race on in Indianapolis,

309
00:30:57,520 --> 00:31:01,360
it's very unforgiving because there's a concrete barrier on the right hand side throughout the

310
00:31:01,360 --> 00:31:07,440
over. So, there's literally, you know, no incentive to go right unless you are doing it to, to save

311
00:31:07,440 --> 00:31:13,280
yourself from a crash. So, so, so there's just a pile of issues we have to work through and make sure

312
00:31:13,280 --> 00:31:18,800
our planner is robust and can account for a combination of many of these issues that we are aware of.

313
00:31:20,960 --> 00:31:30,000
So, you in talking about planning, you raised this issue of a kind of hierarchical planning,

314
00:31:30,000 --> 00:31:34,160
you've got, you know, when you initially described it, you kind of project in, you know,

315
00:31:34,160 --> 00:31:39,120
a few milliseconds and then you're choosing a path based on that. But then there's this higher

316
00:31:39,120 --> 00:31:44,000
level planning that you might want to do. You reference the slipstream issue. I don't know if the

317
00:31:44,000 --> 00:31:48,960
track that you'll be racing on are the ones that you model are oval tracks. But if you've got a more

318
00:31:48,960 --> 00:31:53,440
complex track, you want to kind of hit the corn, hit the curves at a certain point, you know, low

319
00:31:53,440 --> 00:32:00,240
on the curve. Like, how do you incorporate that type of higher level planning in? Is that part of

320
00:32:00,240 --> 00:32:05,840
these heuristics that you include in the low level or is it a totally different process?

321
00:32:05,840 --> 00:32:10,880
So, I think different teams are taking different approaches. In my case, we have actually taken

322
00:32:10,880 --> 00:32:16,080
a cue from some data driven and, you know, some machine learning methods that can help us out there

323
00:32:16,080 --> 00:32:25,360
as well. So, we have some data to infer from how racing experts navigate high level strategic

324
00:32:25,360 --> 00:32:32,000
decisions. So, you know, there's even some very good evidence and footage of a driver intentionally

325
00:32:32,000 --> 00:32:37,600
backing off at a corner because they know that on the straightaway, they will get into the slipstream

326
00:32:37,600 --> 00:32:43,680
and be able to attempt in a better, you know, have a better shot at overtaking. So, so at the high

327
00:32:43,680 --> 00:32:49,760
level, it boils down to, if I think about it, boils down to two or three high level things that we

328
00:32:49,760 --> 00:32:58,240
have to always worry about. One is everybody, if they have done their homework, knows what is the

329
00:32:58,240 --> 00:33:03,840
geometric fastest way around the track, right? That's sort of open knowledge. It's easy to determine.

330
00:33:03,840 --> 00:33:09,680
And so, that's the one where if it's an oval, it's not as complex, but it's the one where you want to

331
00:33:09,680 --> 00:33:15,120
carry the highest speed through every corner. So, you kind of go out on entry, you touch the apex and

332
00:33:15,120 --> 00:33:21,040
then you exit wide as well. And that will give you the sort of the curve of the largest radius. So,

333
00:33:21,040 --> 00:33:25,600
it's the minimum steering input. So, everybody knows that. Everybody wants to be on that, but that's

334
00:33:25,600 --> 00:33:31,200
the problem, right? Because if someone else is on your race line, you have two options. So,

335
00:33:31,200 --> 00:33:38,400
either you go into some kind of adaptive cruise control mode, where you just stay behind them

336
00:33:38,400 --> 00:33:45,120
until they make a mistake and then you get your chance. Or you intentionally decide to deviate

337
00:33:45,120 --> 00:33:51,280
from your race line and see if there's a wide enough gap and where you want to merge back on the

338
00:33:51,280 --> 00:33:56,080
race line in front of them, all the while being aware of if there's any other cars which may

339
00:33:56,080 --> 00:34:02,560
interfere in this entire maneuver. And so, so this multi agent aspect of high speed racing is also

340
00:34:02,560 --> 00:34:08,480
what's making it very difficult. And it's a combination of both the short term path you want to plan.

341
00:34:08,480 --> 00:34:13,520
And, you know, you don't want to be myopic. You don't want to go after every opportunity of overtaking

342
00:34:13,520 --> 00:34:18,560
as well. So, that's where some strategy comes in. You want to be aware of what is your current track

343
00:34:18,560 --> 00:34:23,040
position. So, are you behind the pack? Are you in the middle? How many laps are left?

344
00:34:23,760 --> 00:34:27,920
What is the rate at which you can close the gap to your leading car? So, there's just

345
00:34:28,960 --> 00:34:35,280
all of this racing knowledge has been embodied into a code essentially by my team over the past

346
00:34:35,280 --> 00:34:41,600
year and a half. And, you know, that's what's allowing us to to match this high level strategic

347
00:34:41,600 --> 00:34:46,640
controller with the low level planner. And then even lower than that is the controller itself,

348
00:34:46,640 --> 00:34:52,480
which is going to make sure we can follow the plan that we regenerate. So, it's a mix of,

349
00:34:52,480 --> 00:34:57,440
again, I know I'm giving the same answer again, but that's really the case. It's a mix of

350
00:34:58,560 --> 00:35:05,040
these domain specific maneuvers or strategic decisions that we have been able to

351
00:35:06,880 --> 00:35:11,280
encode into some kind of a logical sort of construct. And we're trying to implement that

352
00:35:11,280 --> 00:35:17,920
using classical methods or using deep learning based approaches. Yeah. One thing comes to mind

353
00:35:17,920 --> 00:35:23,760
in thinking about this that I'm not sure I can come up with any examples of having seen.

354
00:35:24,560 --> 00:35:33,040
And that is, typically when we've got, you know, video off of a vehicle and we're labeling it,

355
00:35:33,040 --> 00:35:40,000
we're labeling it for things in the video, your description makes me think about, you know,

356
00:35:40,000 --> 00:35:46,560
is there is there some kind of model or process where it makes sense to label

357
00:35:47,920 --> 00:35:54,000
video or some other set of fees for driver intent? Like, what is the driver trying to do here?

358
00:35:54,000 --> 00:36:01,680
And then train a model based on trying to learn and to learn driver intent and, you know,

359
00:36:01,680 --> 00:36:07,040
then feed that into control. Does that make any sense? It does. And, you know, what, like just

360
00:36:07,040 --> 00:36:15,760
prior to this, this, this, this podcast earlier today, I am working with a bunch of people

361
00:36:15,760 --> 00:36:20,560
who are helping us label some of the data from these videos which are openly available.

362
00:36:20,560 --> 00:36:27,840
So, so you raise a good point about the intent and we can do a certain bit of that in the game

363
00:36:27,840 --> 00:36:34,160
because in the formula one game, we can determine the track position of whatever cars

364
00:36:34,160 --> 00:36:40,880
enough field of view. And a history of track position is an indicator of future trajectory of

365
00:36:40,880 --> 00:36:46,160
the vehicle. And so that's actually the, the ingredients to this model which is doing the state

366
00:36:46,160 --> 00:36:51,440
estimation for other agents, right? It is some kind of a recurrent neural network which is looking at

367
00:36:51,440 --> 00:36:56,400
a history of intent of the driver and then trying to predict the most likely thing that driver

368
00:36:56,400 --> 00:37:05,600
is going to do within my planning horizon. Having to capture intent just from like on board

369
00:37:05,600 --> 00:37:11,200
camera footage is pretty difficult, I would say I haven't tried it. But you would be surprised

370
00:37:11,200 --> 00:37:15,920
like even something that we may take for granted because, you know, like you would say, okay,

371
00:37:16,800 --> 00:37:22,720
if we go back to perception, we don't even think about that detecting vehicles, how difficult of

372
00:37:22,720 --> 00:37:28,240
that is a problem for said driving because there's a pre-trained networks on these massive

373
00:37:28,240 --> 00:37:34,000
data sets that can classify 3D bounding boxes and volumes of wear vehicles is wear the

374
00:37:34,000 --> 00:37:41,680
draggable surfaces. And we used some of these data sets and these pre-trained networks and we

375
00:37:41,680 --> 00:37:47,440
told them can you now tell us where the racing cars are on the track and they were like no

376
00:37:47,440 --> 00:37:55,840
better than a coin toss. So there's not even a specialized data set for doing bounding box

377
00:37:55,840 --> 00:37:59,920
detection for racing vehicles because yeah, I mean, at the end of the day, if you detect four

378
00:37:59,920 --> 00:38:05,200
wheels, it's likely a car. But the rear end of the vehicle, the side perspectives, they look very

379
00:38:05,200 --> 00:38:12,000
different from these regular vehicle detection. So I'm having to lead that effort myself and we

380
00:38:12,000 --> 00:38:18,560
have a corpus off, you know, tens of thousands of images now where we are detecting the bounding

381
00:38:18,560 --> 00:38:26,080
boxes for the specialized Indy car looking vehicles. And so my feeling is once you can get to where,

382
00:38:26,080 --> 00:38:32,000
let's say, the centroid of that vehicle detection is, then you start looking at a history of

383
00:38:32,000 --> 00:38:37,680
image sequences and that will give you some some idea of the intent of the real driver as

384
00:38:37,680 --> 00:38:41,920
opposed to the gaming driver. So there might be something, something too yet. We haven't done

385
00:38:41,920 --> 00:38:47,200
it with real data and we are relying on our state estimator which is trained on the simulation

386
00:38:47,200 --> 00:38:50,720
and the game yet to solve this problem of intent prediction there.

387
00:38:55,040 --> 00:39:01,440
So we've talked about the the challenges relative to racing and you've got some specific

388
00:39:01,440 --> 00:39:08,160
examples of the way you put the stuff to the test. You've hinted at one which is this

389
00:39:09,680 --> 00:39:14,800
autonomous challenge. But you've got another one and I think you've got an example of that in

390
00:39:14,800 --> 00:39:23,120
your background there. This one 10. Tell us about that. Yeah, so this is this is a I know if someone

391
00:39:23,120 --> 00:39:28,080
is not looking at the video, there's a one 10 scale vehicle behind me. It's a fully autonomous

392
00:39:28,080 --> 00:39:36,080
one 10 scale race car. So yeah, this is another one of my my brainchild and I really like

393
00:39:36,080 --> 00:39:42,880
developed this when I was graduating out of my PhD degree at Penn. And so before I kind of

394
00:39:42,880 --> 00:39:47,520
describe what this is all about and the in the autonomous challenge which is the next big thing

395
00:39:47,520 --> 00:39:54,080
that we are currently navigating around. Let me prefix this by by just saying you know,

396
00:39:54,080 --> 00:39:59,280
we do all the research and the cool things in our lab and we have access to all these resources.

397
00:39:59,840 --> 00:40:05,520
But I've always felt that the way you know, there's a big gap between the way we conduct research

398
00:40:05,520 --> 00:40:10,960
in cell driving and autonomous vehicles and the way we teach about these things to

399
00:40:10,960 --> 00:40:17,520
undergraduates and graduate students alike. And so so a lot of the the initiative behind

400
00:40:17,520 --> 00:40:25,360
developing this f 110 or this one 10 scale racing platform was to make autonomy accessible

401
00:40:25,360 --> 00:40:30,400
for everyone right. So I actually truly believe that this is the best time to be working in AI

402
00:40:30,400 --> 00:40:34,240
and autonomous vehicles and then you know, these these technologies are already sort of well

403
00:40:34,240 --> 00:40:41,920
knit into the fabric of society. So so this this vehicle is essentially was a scale version of

404
00:40:41,920 --> 00:40:48,400
what you would find on a regular cell driving prototype. So it has a lidar, it has cameras,

405
00:40:48,400 --> 00:40:54,400
it has an IMU sensor, it has the same family of the GPU from Nvidia that you would find on full

406
00:40:54,400 --> 00:40:59,840
scale cars. It has a wireless channel which you can remotely access for telemetry. And so

407
00:40:59,840 --> 00:41:06,240
so we developed this and we made this open source. Anyone can go to f110.org and then you will

408
00:41:06,240 --> 00:41:12,320
find this almost IKEA like instructions for how to put this together. And then you know,

409
00:41:12,320 --> 00:41:17,280
you can put the hardware together. It's is reasonably priced but then there's the software part

410
00:41:17,280 --> 00:41:23,120
right. So like I said before, this is all about improving algorithms of perception planning control.

411
00:41:23,120 --> 00:41:30,080
So I actually teach a course on autonomous racing online and you can also find out on YouTube

412
00:41:30,080 --> 00:41:36,160
it's not behind any paywall. It's just free. All the video lectures will walk you through first

413
00:41:36,160 --> 00:41:41,920
understanding the software which is based in Ross or robot operating system. And then we gradually

414
00:41:41,920 --> 00:41:48,320
go all the way to you know, path planning and perception and slam and mapping and then eventually

415
00:41:48,320 --> 00:41:52,480
racing. And so there's a great this is a great tool for doing research. It's a good tool for

416
00:41:52,480 --> 00:41:59,440
education. And for the past four years I've also been organizing the international f110

417
00:41:59,440 --> 00:42:05,200
autonomous racing competitions at some, you know, premier venues and robotics and machine learning

418
00:42:05,200 --> 00:42:10,400
and cyber physical systems. So teams from all over the world, they built their cars and then they

419
00:42:10,400 --> 00:42:16,000
come and we compete in autonomous racing. In fact, long before we went to full-scale autonomous

420
00:42:16,000 --> 00:42:22,240
racing, we already successfully showed the world's first autonomous overtake on month 10th scale,

421
00:42:22,240 --> 00:42:27,360
right. So they had to do it. Like a practice run for the for the real deal.

422
00:42:27,360 --> 00:42:33,520
Yeah, so this is this is an excellent platform. It's very popular. It's used by almost 15

423
00:42:33,520 --> 00:42:38,960
institutions around the world. And now, you know, this this is this is and I like to say it's one

424
00:42:38,960 --> 00:42:44,080
10th scale, but it's 10 times the fun. It's it's my favorite course to teach as well.

425
00:42:44,080 --> 00:42:51,360
I love that the the AWS deep racer platform. Yeah, I have. I have. I think the I give them props for

426
00:42:51,360 --> 00:42:58,400
bringing the price point to below $500, but I think this vehicle, not to kind of dismiss the AWS

427
00:42:58,400 --> 00:43:03,920
effort, but the F1 10 vehicle is a lot more heavy duty and capable. So, you know, just to give

428
00:43:03,920 --> 00:43:09,360
you an idea, this thing can go up to 16 miles per hour indoors, right. So it's impossible to run

429
00:43:09,360 --> 00:43:15,440
behind it and keep track of it. The racer is not very fast. It's not fast. I think, but so I think

430
00:43:15,440 --> 00:43:21,280
they did a good job of making sure that you have a like online simulator available. So they may

431
00:43:21,280 --> 00:43:27,040
get the onboarding process easy, which is the bulk of the effort actually. We had to invest a ton of

432
00:43:27,040 --> 00:43:34,320
time to make sure all the documentation, every single piece of what is needed to get started with

433
00:43:34,320 --> 00:43:38,320
this is taken care of, right. So you can literally let get started if you have the hardware

434
00:43:38,320 --> 00:43:44,560
and less than two hours. And so in in line of, you know, and so we cannot test the ideas on one 10

435
00:43:44,560 --> 00:43:51,760
scale in my lab, I have about 20 of these cars in my lab. So we can do very complex maneuvers

436
00:43:51,760 --> 00:43:56,640
with multiple cars, but you know, it has its limitations, right. So it's a different scale,

437
00:43:56,640 --> 00:44:01,680
different parameters, but the breaking on this vehicle is not realistic and there's no error,

438
00:44:01,680 --> 00:44:09,280
error effects at all. So our next big endeavor at UVA and my group is we are participating in this

439
00:44:09,280 --> 00:44:15,920
indie autonomous challenge, which is essentially, you know, in my view, the DARPA grand challenge

440
00:44:15,920 --> 00:44:21,280
for autonomous racing, right. So it's a million dollar race that will take place in October this year

441
00:44:21,280 --> 00:44:27,600
at the historic Indianapolis Motorsport Speedway, which is considered as part of the top three tracks

442
00:44:27,600 --> 00:44:32,240
in racing. So it's part of the triple crown and racing is what they call it. And so we will be

443
00:44:32,240 --> 00:44:39,680
racing with some fellow innovators from US and from outside of of the country about seven or eight

444
00:44:39,680 --> 00:44:46,640
cars I anticipate in in the world's first head to head fully autonomous race, where we can,

445
00:44:46,640 --> 00:44:53,200
you know, aim to go above 150 miles per hour. That's the goal. And everybody's kind of trying to,

446
00:44:53,200 --> 00:44:59,840
you know, fully immerse themselves to make that a reality. So, so, you know, just to just to quickly

447
00:44:59,840 --> 00:45:08,400
remark on on the significance of this, if you look at motorsport racing or the history of motorsport

448
00:45:08,400 --> 00:45:14,000
racing, it has always been the proving grounds for automotive technology. In fact, the reason it

449
00:45:14,000 --> 00:45:20,240
started was because when people transition from horse driven carriages to horseless carriages,

450
00:45:20,240 --> 00:45:24,240
they were very skeptical. And now we are transitioning from driver to driverless and there's

451
00:45:24,240 --> 00:45:31,440
the same sort of skepticism here. So racing became as means to to show endurance and safety and

452
00:45:31,440 --> 00:45:35,680
convince people that the engine is not going to blow up in your face and the brakes work properly

453
00:45:35,680 --> 00:45:40,960
and everything is, you know, trustworthy. So I think a similar litmus test is now required for

454
00:45:40,960 --> 00:45:48,320
the software stack for self driving. And so I think racing can become that proving ground where we

455
00:45:48,320 --> 00:45:54,560
can push the AI for self driving towards limits and show that, you know, if you can race at

456
00:45:55,280 --> 00:46:00,320
high speeds and close proximity when people are trying to intentionally block your progress

457
00:46:00,320 --> 00:46:05,920
without crashing, that's a very significant token. And it could eventually have a huge bearing

458
00:46:05,920 --> 00:46:12,240
on safety of regular autonomous driving. So I'm very excited to be involved in this challenge

459
00:46:12,240 --> 00:46:17,840
from the very get go and we can't wait to get our hands on the actual race car and transfer our

460
00:46:17,840 --> 00:46:21,760
knowledge from one times scale from the simulation on to the actual way code.

461
00:46:22,960 --> 00:46:30,400
You've got a few months, but how close do you think you are in terms of being able to successfully

462
00:46:30,400 --> 00:46:39,040
complete that challenge? Yeah, I'm a rational optimist fan. So I think it's,

463
00:46:41,680 --> 00:46:46,560
yeah, I would be a miss to say that it's going to be easy. It's a very significant undertaking.

464
00:46:46,560 --> 00:46:52,880
We all know as roboticists that when you work with the real thing, there's just a bunch of

465
00:46:52,880 --> 00:46:58,640
messy real world problems that you have to overcome before you even get to the intellectual sort of

466
00:46:58,640 --> 00:47:05,120
part of why your algorithm is better than others. So my feeling is we'll spend a solid few weeks

467
00:47:05,120 --> 00:47:10,880
at a stretch to just work through these issues. And what it helps is because most of our competitors

468
00:47:10,880 --> 00:47:17,120
are from other academic institutions. There is some collaboration happening at what is the

469
00:47:17,120 --> 00:47:21,280
base level software that everybody will have access to. So because there's a lowest common

470
00:47:21,280 --> 00:47:26,960
denominator that every team has to overcome before it becomes about the high level algorithms.

471
00:47:26,960 --> 00:47:32,560
So it is a significant undertaking. We have access to some predetermined schedule where we have

472
00:47:32,560 --> 00:47:38,560
reserved track time in Indy. And so my team and I will travel to Indy, we'll spend the entire

473
00:47:38,560 --> 00:47:46,320
summer there, possibly even the next semester. And then on October, yeah, I'm literally running

474
00:47:47,280 --> 00:47:52,640
besides my research lab and my own research, I'm also running a racing team on nights and

475
00:47:52,640 --> 00:47:59,840
games. So it's very exciting. I have no qualms about it. This is sort of what really excites me.

476
00:47:59,840 --> 00:48:06,880
I think it's going to be tough undertaking and just like any sport,

477
00:48:06,880 --> 00:48:13,440
if the outcome is a reflection of how much effort you put in, then I think that's my own thinking

478
00:48:13,440 --> 00:48:19,920
of it. So we'll go all in. We'll try to get this car running. Firstly, I don't think on the first

479
00:48:19,920 --> 00:48:27,920
day we'll touch even 25 miles per hour. But it's slowly take your car through the paces and you

480
00:48:27,920 --> 00:48:33,040
gain more confidence about your localization is working fine. You're confident that what you see

481
00:48:33,040 --> 00:48:38,640
as the position of the car is where the car is on the track. So we have a long flight checklist,

482
00:48:38,640 --> 00:48:44,720
if you will, that we have to go through. And then it becomes, you know, what did we miss when

483
00:48:44,720 --> 00:48:49,520
we were designing all these cool ideas in the simulation? How did they plan out on the track?

484
00:48:49,520 --> 00:48:54,240
What are the obvious things that we missed about the behavior of the car? And it's also,

485
00:48:54,240 --> 00:48:59,520
we have more than just computer scientists on my team. We have people from mechanical engineering,

486
00:48:59,520 --> 00:49:05,440
from systems engineering, from ECE embedded systems. There's actually a racing driver on my team

487
00:49:05,440 --> 00:49:11,120
who has some background in NASCAR racing. So it's just a pretty elaborate gig that I'm going on right

488
00:49:11,120 --> 00:49:18,960
now. That's awesome. Yeah, we started this talking about kind of what we can learn about safety

489
00:49:18,960 --> 00:49:26,720
from racing. I'm curious how you when you think about, you know, putting this AI that you're

490
00:49:26,720 --> 00:49:34,240
building into a full scale car, moving in 150 miles an hour. How do you think about the relationship

491
00:49:34,240 --> 00:49:41,920
between speed and safety and, you know, being competitive, but also being safe? How do you approach

492
00:49:41,920 --> 00:49:49,360
that? Yeah, so that's a tough one to really nail down. You know, speed is only useful if you are

493
00:49:49,360 --> 00:49:57,200
facing the right direction, right? So the first thing is to, I think, be be prioritized safety

494
00:49:57,200 --> 00:50:02,720
over speed because the cost of being unsafe is the ultimate price where you lose your car and

495
00:50:02,720 --> 00:50:10,480
you can't compete. I know it's not. So, you know, my honest feeling is that while we strive to

496
00:50:10,480 --> 00:50:17,520
go to these super high racing speed, it's going to be quite difficult to, you know, show that you

497
00:50:17,520 --> 00:50:24,240
are overtaking and going close to the barrier and taking that super risk, which is all the excitement

498
00:50:24,240 --> 00:50:31,200
about racing. You know, I honestly think that's a very tough ask. So this is not the only such

499
00:50:31,200 --> 00:50:37,040
competition. It's not the last one for sure. So I think it's a process, right? So we have sort of

500
00:50:37,040 --> 00:50:42,240
at the, just like with any field when you're at the frontier of a certain field, they're more

501
00:50:42,240 --> 00:50:48,880
sort of unanswered questions than there are answers. I feel this one is in their realm. So

502
00:50:48,880 --> 00:50:54,800
so we do prioritize collision avoidance actively, both in front of us and behind us. So even if the

503
00:50:54,800 --> 00:51:01,200
car behind us is doing something erratic, we would rather not deal with that then to be like,

504
00:51:01,200 --> 00:51:07,920
oh, let's push our elbows out and see what happens, right? So and part of it is this just mindset of

505
00:51:07,920 --> 00:51:14,720
the roots of our research is in safety of AI, safe autonomous vehicle. So it would be kind of a

506
00:51:14,720 --> 00:51:20,560
moot point if we just take an unnecessary risk and and crash our car, right? So as they say,

507
00:51:22,080 --> 00:51:26,480
to finish first, first you have to finish, right? So that's I think a good summary of how we

508
00:51:26,480 --> 00:51:32,320
approach the straight up between safety. At the same time, you know, we do want to push our car

509
00:51:32,320 --> 00:51:39,600
to the limits of how fast it can go while respecting and behaving in expected manner. So maybe

510
00:51:40,320 --> 00:51:47,200
my response to this sort of trade-off is we are comfortable going at the speed limit where the

511
00:51:47,200 --> 00:51:54,000
car behaves as we expect it to behave. So as a racing team, we hate surprises. Okay, so if things are

512
00:51:54,000 --> 00:51:59,360
deterministic, if we know how our car will behave in a given situation, sure, let's go for it.

513
00:51:59,360 --> 00:52:04,720
But as soon as we begin to get into that gray area where, hey, we didn't anticipate that.

514
00:52:04,720 --> 00:52:09,200
Oh, why did we make that staring adjustment? So maybe, you know, our models are a mess. They

515
00:52:09,200 --> 00:52:13,760
were not designed for such speeds. So we have obviously, you know, mistuned some parameters

516
00:52:13,760 --> 00:52:19,120
somewhere. But then we will apply the brakes literally and figuratively on our approach here.

517
00:52:20,720 --> 00:52:27,280
Awesome. Well, Madhu, thanks so much for taking the time to share with us a bit about your journey

518
00:52:27,280 --> 00:52:32,160
and what you're up to. It's very cool stuff. Yeah, thanks Sam for for again inviting me to this.

519
00:52:32,160 --> 00:52:37,840
I had a really fun time, very enjoyable discussion and keep an eye out in October. You will likely

520
00:52:37,840 --> 00:52:59,040
hear about this event. And yeah, I hope to be amongst the teams which crossed the finish line.

