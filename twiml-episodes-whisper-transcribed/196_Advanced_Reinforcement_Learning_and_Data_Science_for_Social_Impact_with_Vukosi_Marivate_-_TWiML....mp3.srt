1
00:00:00,000 --> 00:00:16,320
Hello and welcome to another episode of Twimble Talk, the podcast why interview interesting

2
00:00:16,320 --> 00:00:21,480
people, doing interesting things in machine learning and artificial intelligence.

3
00:00:21,480 --> 00:00:32,000
I'm your host, Sam Charrington.

4
00:00:32,000 --> 00:00:37,560
In this the final show of our deep learning endoba series, we speak with Bucosi Maravate,

5
00:00:37,560 --> 00:00:43,360
chair of data science at the University of Pretoria and co-organizer of the endoba.

6
00:00:43,360 --> 00:00:46,880
My conversation with Bucosi fell into two distinct parts.

7
00:00:46,880 --> 00:00:51,440
The first part focused on his PhD research and the area of reinforcement learning.

8
00:00:51,440 --> 00:00:57,560
And we discussed several advanced RL scenarios, including in verse RL, multiple agent RL,

9
00:00:57,560 --> 00:01:02,720
and using reinforcement learning when you have an incomplete knowledge of the environment.

10
00:01:02,720 --> 00:01:07,080
We then moved on to discuss his current research, which broadly falls under the banner of data

11
00:01:07,080 --> 00:01:09,440
science with social impact.

12
00:01:09,440 --> 00:01:14,440
Specifically, we review several of the applications he and his students are currently exploring

13
00:01:14,440 --> 00:01:18,840
in areas such as public safety and energy.

14
00:01:18,840 --> 00:01:22,840
As we close out the series, I'd like to send a final word of thanks to our friends at

15
00:01:22,840 --> 00:01:24,320
Google AI.

16
00:01:24,320 --> 00:01:28,400
If you've got an interest in machine learning research and want to level up your skills

17
00:01:28,400 --> 00:01:32,640
in one of the top ML research groups in the world, you should take a moment to learn

18
00:01:32,640 --> 00:01:37,360
more about the Google AI Residency program, which recently opened up applications for

19
00:01:37,360 --> 00:01:40,280
perspective 2019 residents.

20
00:01:40,280 --> 00:01:44,800
The Google AI Residency is a one-year machine learning research training program with the

21
00:01:44,800 --> 00:01:49,960
goal of helping individuals from all over the world and with a diverse set of educational

22
00:01:49,960 --> 00:01:55,280
and professional backgrounds become successful machine learning researchers.

23
00:01:55,280 --> 00:02:00,520
Find out more about the program at g.co slash AI Residency.

24
00:02:00,520 --> 00:02:05,360
And now on to the show.

25
00:02:05,360 --> 00:02:08,680
Hey everyone, I am on the line with Bucosi Maravate.

26
00:02:08,680 --> 00:02:15,320
Bucosi is the chair of data science at the University of Pretoria and was a co-organizer

27
00:02:15,320 --> 00:02:17,520
of the deep learning in Daba.

28
00:02:17,520 --> 00:02:20,760
Bucosi, welcome to this week in machine learning and AI.

29
00:02:20,760 --> 00:02:22,400
Thanks for having me.

30
00:02:22,400 --> 00:02:23,400
Absolutely.

31
00:02:23,400 --> 00:02:26,520
Why don't we get started by having you tell us a little bit about your background and

32
00:02:26,520 --> 00:02:31,160
how you got interested and involved in data science and machine learning?

33
00:02:31,160 --> 00:02:37,240
Yeah, I guess I have a background in electrical engineering that was my undergrad in Masters

34
00:02:37,240 --> 00:02:40,400
when I was doing my undergraduate in electrical engineering.

35
00:02:40,400 --> 00:02:45,120
I got to a point where I said, yeah, I don't think I'm interested in this power stuff.

36
00:02:45,120 --> 00:02:50,440
But I am interested in artificial intelligence and data.

37
00:02:50,440 --> 00:02:55,240
So I moved to a stream here at the University of the Vett Vater Science in Johannesburg,

38
00:02:55,240 --> 00:02:59,840
which allowed us to work on more data problems and more coding.

39
00:02:59,840 --> 00:03:05,760
And by the time I was doing my fourth year at the University of being a senior, I was

40
00:03:05,760 --> 00:03:13,520
working then on AI, specifically doing some work with neural networks at the time.

41
00:03:13,520 --> 00:03:20,640
And then I stayed on for another year at Vett University, did a Masters looking at

42
00:03:20,640 --> 00:03:22,520
some reinforcement learning work.

43
00:03:22,520 --> 00:03:29,280
I was very interested in kind of like, oh, machines can learn to make decisions and you

44
00:03:29,280 --> 00:03:33,280
only have to give them this kind of reward.

45
00:03:33,280 --> 00:03:40,480
And so after spending that year, doing that, I had applied also for a scholarship, a full

46
00:03:40,480 --> 00:03:46,800
bright scholarship to go to the US and one of the schools I had chosen was Rutgers University

47
00:03:46,800 --> 00:03:51,520
because of kind of then who would then become my future PhD advisor.

48
00:03:51,520 --> 00:03:55,720
I was like, oh, this is one of the people I read about when I was reading about RL.

49
00:03:55,720 --> 00:03:59,600
So it could be interesting to work under him.

50
00:03:59,600 --> 00:04:08,960
I then in between that started working for the CSR in early 2009 and a few months later

51
00:04:08,960 --> 00:04:17,000
I was then off to New Jersey to start Rutgers on the PhD program and then had Michael Littman

52
00:04:17,000 --> 00:04:19,120
as my PhD advisor.

53
00:04:19,120 --> 00:04:26,800
So another thing again, as you're going through the motions of doing a PhD, you look at

54
00:04:26,800 --> 00:04:32,560
the area with some depth, I work on some work in investment reinforcement learning.

55
00:04:32,560 --> 00:04:38,280
I worked a bit on kind of trying to think about having multiple reinforcement learning

56
00:04:38,280 --> 00:04:43,680
learners at all at once, but I think that kept on making me wake up every morning was

57
00:04:43,680 --> 00:04:47,040
like, I'm really interested in making reinforcement learning a little bit more practical.

58
00:04:47,040 --> 00:04:54,040
So how do you do things like evaluation where you don't have access to a simulator or complete

59
00:04:54,040 --> 00:04:58,360
embodiment, so if you think about things like medicine, if you might think about things

60
00:04:58,360 --> 00:05:02,760
like kind of education, these type of areas, you're not really going to experiment with people

61
00:05:02,760 --> 00:05:04,240
with your infrastructure learning algorithm.

62
00:05:04,240 --> 00:05:08,720
So you want to do your evaluation offline and to do that, you need to take care of a couple

63
00:05:08,720 --> 00:05:09,720
of things.

64
00:05:09,720 --> 00:05:14,240
So evaluation here, meaning that you want to see how well your model after it's learned

65
00:05:14,240 --> 00:05:17,280
actually does without having to deploy it.

66
00:05:17,280 --> 00:05:21,200
So you can't say, hey, you're going to learn how to treat cancer.

67
00:05:21,200 --> 00:05:24,000
And then after that, you build a model and you say, okay, now the model's going to be

68
00:05:24,000 --> 00:05:26,320
applied on real patients.

69
00:05:26,320 --> 00:05:28,880
That is going to be problematic in some ways.

70
00:05:28,880 --> 00:05:33,440
There is work in that area to make that actually much more possible.

71
00:05:33,440 --> 00:05:37,480
But that's the thing I was interested in, but like I don't be interested in this again,

72
00:05:37,480 --> 00:05:43,440
hey, I really enjoy working from like a challenge that's out there and then working backwards

73
00:05:43,440 --> 00:05:48,360
into what then models will be useful, what learning algorithms will then be useful to

74
00:05:48,360 --> 00:05:50,080
then develop.

75
00:05:50,080 --> 00:05:53,920
And at that time, I was at 2011, 2012, I started hearing

76
00:05:53,920 --> 00:05:58,720
this thing of like, you know, oh, there's this term called data scientist.

77
00:05:58,720 --> 00:06:05,680
And it's people who will wrangle with data, use kind of a different techniques, not necessarily

78
00:06:05,680 --> 00:06:09,640
just from computing, might be from statistics, might be like, you know, from social science

79
00:06:09,640 --> 00:06:12,280
and then try to kind of tackle these problems.

80
00:06:12,280 --> 00:06:17,560
And that way, then I kept on gravitating towards that, towards that.

81
00:06:17,560 --> 00:06:23,640
So by the end of my PhD, I was like, okay, let me go try and see.

82
00:06:23,640 --> 00:06:27,680
As I'm going back to South Africa to see if I can work in data science.

83
00:06:27,680 --> 00:06:33,000
And that's where, like, you know, arriving the last three years or so, mostly I was

84
00:06:33,000 --> 00:06:39,440
based at the CSR, working with the team of other data scientists for about three years.

85
00:06:39,440 --> 00:06:46,480
And then now I've moved to University of Victoria, then as the chair of data science, still

86
00:06:46,480 --> 00:06:54,720
contain some research with colleagues or prior colleagues at the CSR.

87
00:06:54,720 --> 00:06:59,080
Did the transition to data science or that you're kind of blossoming interest in data science

88
00:06:59,080 --> 00:07:07,080
lead to a change in direction for your PhD research, or did you complete that in reinforcement

89
00:07:07,080 --> 00:07:08,080
learning?

90
00:07:08,080 --> 00:07:13,840
I completed the PhD in reinforcement learning, but the work basically became this kind

91
00:07:13,840 --> 00:07:18,600
of looking at other looking at education.

92
00:07:18,600 --> 00:07:23,360
We were looking at health applications and all like health challenges and then working

93
00:07:23,360 --> 00:07:27,560
to build up tools for evaluation in that area.

94
00:07:27,560 --> 00:07:33,000
You mentioned a few things in the RL area that I haven't heard much about.

95
00:07:33,000 --> 00:07:36,680
The first of those is inverse RL, what's that?

96
00:07:36,680 --> 00:07:41,480
So inverse reinforcement learning is, okay, in the general reinforcement learning framework,

97
00:07:41,480 --> 00:07:47,240
you've got an environment, you've got an agent, which is the machine learner that you're

98
00:07:47,240 --> 00:07:50,640
going to have, that agent can do actions.

99
00:07:50,640 --> 00:07:54,720
So it's allowed to choose some action and then it gets carried through and it might move

100
00:07:54,720 --> 00:07:56,040
around.

101
00:07:56,040 --> 00:08:00,440
So think about like, you know, dumb example, you have a room in a room and it can choose

102
00:08:00,440 --> 00:08:05,960
to move, yeah, like to move around and then it can choose sometimes to vacuum.

103
00:08:05,960 --> 00:08:11,400
And what you do is you say, okay, I'm not going to specify how, what you must do.

104
00:08:11,400 --> 00:08:13,680
And I'll give you a reward for something, right?

105
00:08:13,680 --> 00:08:17,200
So I'll give you a one if you vacuum the dirt or something like that.

106
00:08:17,200 --> 00:08:21,960
And I'll give you a very negative reward if your patchy runs out, all right?

107
00:08:21,960 --> 00:08:27,960
So the rumor then just giving those signals will go around and it will exploit the beginning

108
00:08:27,960 --> 00:08:32,360
or try different actions, it might go in and like, you know, just vacuum in a place that

109
00:08:32,360 --> 00:08:35,040
there's nothing so you won't get a reward.

110
00:08:35,040 --> 00:08:38,400
But then sometimes it will vacuum on somewhere where there is dirt and it's sense I would

111
00:08:38,400 --> 00:08:41,920
have said there's dirt, but it didn't know how to interpret it before.

112
00:08:41,920 --> 00:08:47,520
And after a while, it will learn like, okay, yeah, look around for dirt if there's dirt vacuum

113
00:08:47,520 --> 00:08:49,320
it off.

114
00:08:49,320 --> 00:08:52,680
And then that, you know, if the battery dies, I got a very negative thing.

115
00:08:52,680 --> 00:08:57,800
So keep track of the battery level and things like so over time, you think that you will

116
00:08:57,800 --> 00:09:02,640
inculcate in it, it will learn all these expected kind of behaviors.

117
00:09:02,640 --> 00:09:06,680
So an inverse reinforcement learning is that there is no reward that's specified, right?

118
00:09:06,680 --> 00:09:10,520
So you don't have a reward, which actually is hard to specify sometimes.

119
00:09:10,520 --> 00:09:14,960
But what you do is that you can actually observe somebody do something, right?

120
00:09:14,960 --> 00:09:21,080
So you actually go in and maybe you see other rumbers or you have a human actually have

121
00:09:21,080 --> 00:09:25,200
a remote control to the room and it moves around and it does things.

122
00:09:25,200 --> 00:09:30,720
And then from there, what the goal of the learning algorithm is to do is to actually learn

123
00:09:30,720 --> 00:09:35,400
what the reward function would have been to actually replicate the behavior that it's

124
00:09:35,400 --> 00:09:36,400
seen.

125
00:09:36,400 --> 00:09:39,000
So what this makes me think of is imitation learning.

126
00:09:39,000 --> 00:09:41,400
Is that a name collision or are these related?

127
00:09:41,400 --> 00:09:42,800
Yeah, they are related.

128
00:09:42,800 --> 00:09:46,000
So that's one of the kind of other way, like imitation learning that might be multiple

129
00:09:46,000 --> 00:09:47,800
ways to do it.

130
00:09:47,800 --> 00:09:51,240
But inverse reinforcement learning could be one of the ways that you do imitation learning.

131
00:09:51,240 --> 00:09:52,240
Okay.

132
00:09:52,240 --> 00:09:53,240
Yeah.

133
00:09:53,240 --> 00:09:58,760
But one of the things that is interesting if you do really capture that award in a good

134
00:09:58,760 --> 00:10:03,720
way with a good representation is that you can then transfer it between domains.

135
00:10:03,720 --> 00:10:09,640
It's hard, it's still not trivial, but you can then learn like what's important to who

136
00:10:09,640 --> 00:10:13,520
you've been observing and then you move it to different domains and then try to then

137
00:10:13,520 --> 00:10:16,440
estimate what behavior you would have seen from that person or thing.

138
00:10:16,440 --> 00:10:18,400
Can you give an example of that?

139
00:10:18,400 --> 00:10:23,440
So let's say you've got the room again, it goes into a room, you show at the beginning,

140
00:10:23,440 --> 00:10:28,280
you train the room, but you move around the room, but you learn, okay, there's things

141
00:10:28,280 --> 00:10:31,840
such as the things such as battery state, there's things such as obstacles.

142
00:10:31,840 --> 00:10:35,560
But now you just adjust the room or you move the room into a new room.

143
00:10:35,560 --> 00:10:40,480
And then it, because it's learned the reward, you don't, you no longer, it doesn't need

144
00:10:40,480 --> 00:10:41,480
to imitate anymore.

145
00:10:41,480 --> 00:10:45,880
It can just take the reward that it learned before and then say, oh, I'm in a new room,

146
00:10:45,880 --> 00:10:47,560
but I kind of get the rules.

147
00:10:47,560 --> 00:10:48,560
Mm-hmm.

148
00:10:48,560 --> 00:10:49,560
Got it.

149
00:10:49,560 --> 00:10:53,280
So that's a good, like, you know, you, you kind of can then transfer that reward to something

150
00:10:53,280 --> 00:10:54,280
else.

151
00:10:54,280 --> 00:10:55,280
I love the Roomba example.

152
00:10:55,280 --> 00:10:56,960
I've never heard anyone use that.

153
00:10:56,960 --> 00:11:01,600
Usually we're talking about video games and robots and like, I guess the Roomba is a robot,

154
00:11:01,600 --> 00:11:08,520
but usually we're talking about video games, but the Roomba is a great example for RL,

155
00:11:08,520 --> 00:11:11,520
not that the actual Roomba actually uses RL, but...

156
00:11:11,520 --> 00:11:17,880
Yeah, I like making examples that are kind of very much more closer to people's, like,

157
00:11:17,880 --> 00:11:18,880
regular lives.

158
00:11:18,880 --> 00:11:21,680
Even though, like, most of us, I don't even have a Roomba.

159
00:11:21,680 --> 00:11:22,680
Right.

160
00:11:22,680 --> 00:11:25,480
But it's like, once you say it, people get it.

161
00:11:25,480 --> 00:11:26,480
Like, oh, okay.

162
00:11:26,480 --> 00:11:29,080
Yeah, you know, yeah, yeah, I see it, I see it now.

163
00:11:29,080 --> 00:11:30,080
Yeah.

164
00:11:30,080 --> 00:11:31,720
Roomba's even still a thing.

165
00:11:31,720 --> 00:11:32,720
Do they still...

166
00:11:32,720 --> 00:11:33,720
Yeah, yeah.

167
00:11:33,720 --> 00:11:37,320
They're a lot of them, and I've been trying to figure out how to get one from Xiaomi.

168
00:11:37,320 --> 00:11:42,640
It's not a Roomba, it's some other brand, I mean, another name, yeah, hopefully we don't

169
00:11:42,640 --> 00:11:43,640
get it.

170
00:11:43,640 --> 00:11:46,760
Yeah, but they still are there, and they're getting crazy.

171
00:11:46,760 --> 00:11:52,640
So you also mentioned multiple RL learners, kind of obvious from the context what that refers

172
00:11:52,640 --> 00:11:58,840
to, but I haven't seen much in terms of published research in that area.

173
00:11:58,840 --> 00:12:04,320
What are, kind of, some of the major challenges and results that folks have been seeing with

174
00:12:04,320 --> 00:12:05,320
multiple learners?

175
00:12:05,320 --> 00:12:11,800
Oh, this has been a while working in that space, but you can think about different settings.

176
00:12:11,800 --> 00:12:16,080
So one is that you could have, like, learners that have to co-operate.

177
00:12:16,080 --> 00:12:20,080
So working together to solve a bigger, like, high-level goal.

178
00:12:20,080 --> 00:12:24,960
So, like, you know, you can have a team playing a game, like, you know, here we can talk about

179
00:12:24,960 --> 00:12:27,000
football, which now has changed.

180
00:12:27,000 --> 00:12:33,320
I'm giving back, I'm back in South Africa, so football needs something else, so you could

181
00:12:33,320 --> 00:12:36,960
have multiple, like, you know, they're trying to play soccer, and then, again, you give them

182
00:12:36,960 --> 00:12:39,560
rewards, but then now they have to learn how to cooperate.

183
00:12:39,560 --> 00:12:43,760
That's one way of thinking about it, that's not really what I was trying to do sometime

184
00:12:43,760 --> 00:12:49,680
in my PhD, but one way was, okay, you have these different learners, but they only get different

185
00:12:49,680 --> 00:12:51,000
experiences, right?

186
00:12:51,000 --> 00:12:56,160
So the other time that they spend in the environment, it only gets them to see different parts

187
00:12:56,160 --> 00:12:57,160
of the world.

188
00:12:57,160 --> 00:13:01,360
You know, how do you take this, and then almost try to use their brains to get to something

189
00:13:01,360 --> 00:13:02,680
that is much better?

190
00:13:02,680 --> 00:13:08,200
So it brings you back to, like, ensemble methods, and could ensemble methods actually be something

191
00:13:08,200 --> 00:13:10,000
that works in reinforcement learning?

192
00:13:10,000 --> 00:13:11,000
Okay.

193
00:13:11,000 --> 00:13:12,000
Interesting.

194
00:13:12,000 --> 00:13:13,000
Yes.

195
00:13:13,000 --> 00:13:18,960
Another thing you mentioned it, the first of those examples, I did an interview recently

196
00:13:18,960 --> 00:13:26,800
about the OpenAI Dota OpenAI 5, which is, like, these five different agents that are operating

197
00:13:26,800 --> 00:13:32,640
in this environment, and need to figure out how to cooperate, and they do some interesting,

198
00:13:32,640 --> 00:13:36,200
some interesting kind of emergent behaviors we're seeing there.

199
00:13:36,200 --> 00:13:37,200
Okay.

200
00:13:37,200 --> 00:13:45,520
So you mentioned inverse RL, multiple RL learners, and then evaluation in incomplete environments,

201
00:13:45,520 --> 00:13:50,080
which you kind of alluded to with the multiple learners, where they're kind of learning different

202
00:13:50,080 --> 00:13:54,160
things independently, and then you're fusing what they're learning together.

203
00:13:54,160 --> 00:13:57,080
Was there other work that you did around these incomplete environments?

204
00:13:57,080 --> 00:14:02,880
It's not really incomplete environments, as opposed to you don't have access to them.

205
00:14:02,880 --> 00:14:11,120
So one of the things was, like, we wanted to look at health chronic disease management,

206
00:14:11,120 --> 00:14:15,840
and things like you can do things like marketing, because you've got a lot of that.

207
00:14:15,840 --> 00:14:19,160
So you don't have access to the environment in chronic disease, so you don't have access

208
00:14:19,160 --> 00:14:20,160
to your patients.

209
00:14:20,160 --> 00:14:25,320
But you can have historical diagnostic information, and also follow-up diagnostics.

210
00:14:25,320 --> 00:14:31,280
So in this case, I was looking at HIV, which, finally enough, I had also worked in my undergrad

211
00:14:31,280 --> 00:14:38,320
briefly looking at missing data for HIV, but then now I was actually looking at treatment.

212
00:14:38,320 --> 00:14:44,560
So we're going to simplify it again, so you've got a multiple patients going through treatments

213
00:14:44,560 --> 00:14:49,200
for HIV, and what you want to do to learn from there is a policy that in the future when

214
00:14:49,200 --> 00:14:55,840
you get a new patient, you can take some information from there and be able to personalize a treatment.

215
00:14:55,840 --> 00:15:01,840
But that treatment for HIV is sequential, so it's not simply a one decision is made, and

216
00:15:01,840 --> 00:15:02,840
that's it.

217
00:15:02,840 --> 00:15:05,920
So you're not going to choose a drug cocktail, and it's going to last for the life of the

218
00:15:05,920 --> 00:15:06,920
patient.

219
00:15:06,920 --> 00:15:10,720
So you're going to have multiple times you have to make decisions, so meaning you keep

220
00:15:10,720 --> 00:15:13,120
drug cocktail number one.

221
00:15:13,120 --> 00:15:18,360
It works for a while, and then it might stop working, unfortunately, given how HIV actually

222
00:15:18,360 --> 00:15:22,920
progresses, and then you have to then make a choice of switching to another treatment.

223
00:15:22,920 --> 00:15:24,640
And this could go on for a couple of times.

224
00:15:24,640 --> 00:15:28,960
So we restricted the problem into, I think, only two stages where you say you're going

225
00:15:28,960 --> 00:15:32,080
to get your initial treatment, and if you switch, what should then be the next treatment?

226
00:15:32,080 --> 00:15:36,280
So this becomes a sequential decision-making problem, which, again, is very nice for

227
00:15:36,280 --> 00:15:39,240
reinforcement learning, because that's exactly what you want to learn.

228
00:15:39,240 --> 00:15:43,520
But what you want to do is that because you're not going to have access to the real patients,

229
00:15:43,520 --> 00:15:48,800
to do the evaluation after you've learned from the data, we split the kind of learning

230
00:15:48,800 --> 00:15:57,440
into a process where some learning is used to just learn a model of the environment given

231
00:15:57,440 --> 00:15:59,080
the data that you've seen.

232
00:15:59,080 --> 00:16:03,120
So it's almost like you're building some sort of simulator, but it's going to have noise,

233
00:16:03,120 --> 00:16:07,720
because sometimes you haven't seen a specific drug cocktail used enough for you to really

234
00:16:07,720 --> 00:16:10,800
be sure what kind of effect it's going to have on a patient.

235
00:16:10,800 --> 00:16:14,600
So you have to then bring in uncertainty of saying that, okay, here you might end up

236
00:16:14,600 --> 00:16:16,760
with a viral load between here and here.

237
00:16:16,760 --> 00:16:22,160
So we then built up a model-based reinforcement learning algorithm that estimated, and the

238
00:16:22,160 --> 00:16:29,120
effect that drugs would have on a potential patient, and the information that we captured

239
00:16:29,120 --> 00:16:33,600
from the patient was like the demographics, some information about the disease at the

240
00:16:33,600 --> 00:16:38,320
beginning, and then from there you then run, and you're also learning algorithm that estimates

241
00:16:38,320 --> 00:16:43,040
then, okay, saying, okay, if you were to give a drug cocktail that was drug number, I mean,

242
00:16:43,040 --> 00:16:47,080
drug cocktail number one was this, and drug cocktail number two was this, this is likely

243
00:16:47,080 --> 00:16:52,280
how well you manage the disease over the next X amount of turns.

244
00:16:52,280 --> 00:16:59,880
Yeah, it's interesting, so it's like part of the environment is modeled probabilistically,

245
00:16:59,880 --> 00:17:05,080
and the agent has to figure out what to do with that constraint.

246
00:17:05,080 --> 00:17:10,400
Yes, yes, so because again, it brings up this thing of like you now want to allow people

247
00:17:10,400 --> 00:17:15,680
to do RL without necessarily having access to the real kind of thing, but they've got

248
00:17:15,680 --> 00:17:23,240
enough prior data to do something at least useful, and then you then could then say, okay,

249
00:17:23,240 --> 00:17:28,320
I want to also evaluate how close I am to the real world in some way.

250
00:17:28,320 --> 00:17:34,520
Some of the work of Susan Murphy at University of Michigan, they've done a lot of work in

251
00:17:34,520 --> 00:17:37,320
this area, and she was on my PhD committee.

252
00:17:37,320 --> 00:17:44,440
And so kind of fast-forwarding, you're now focused on data science at University of

253
00:17:44,440 --> 00:17:50,720
Pretoria, and a lot of your interests are centered around this idea of data science with social

254
00:17:50,720 --> 00:17:51,720
impact.

255
00:17:51,720 --> 00:17:53,520
What does that mean for you?

256
00:17:53,520 --> 00:18:01,600
So for me, social impact means like there's, we have a world that has kind of challenges,

257
00:18:01,600 --> 00:18:05,800
and from these challenges, you can come up with very interesting data science kind of problems

258
00:18:05,800 --> 00:18:08,200
that you can then do research on.

259
00:18:08,200 --> 00:18:13,920
And some of these will kind of have a flavor that's very similar around the world.

260
00:18:13,920 --> 00:18:21,040
So for example, while I was at CSR, one of the initial areas we had looked at is trying

261
00:18:21,040 --> 00:18:25,880
to think about public safety, and then thinking, if we have the constraint that we might not

262
00:18:25,880 --> 00:18:31,920
really have access to raw public safety data, could we use a proxy?

263
00:18:31,920 --> 00:18:36,280
And the proxy we had come up with was maybe social media is there, people might be describing

264
00:18:36,280 --> 00:18:40,720
incidents that are going on, like you know, it might be a fire, it might be a car accident,

265
00:18:40,720 --> 00:18:44,840
and from there, can you build something that at least gives you an indication of what

266
00:18:44,840 --> 00:18:48,280
might be going on in a town or in a city?

267
00:18:48,280 --> 00:18:54,480
So that is one, the other could be pay, I want to, you know, this data that I have access

268
00:18:54,480 --> 00:19:00,040
to, and we want to look at behavior in that data, and we want to pick out things that don't

269
00:19:00,040 --> 00:19:01,040
make any sense.

270
00:19:01,040 --> 00:19:02,200
So you want to look at anomaly.

271
00:19:02,200 --> 00:19:08,800
So I work with a student, two students to work on anomaly detection algorithms with

272
00:19:08,800 --> 00:19:13,360
that in mind, and hoping to get to a point where now, let's say you're looking at behavior

273
00:19:13,360 --> 00:19:18,240
of people purchasing electricity, which is one project, we had worked on at the CSR

274
00:19:18,240 --> 00:19:22,120
and I still continue to collaborate with some people at CSR on this, but you want to

275
00:19:22,120 --> 00:19:28,280
look at how people like purchase electricity, and if they have behavior that is anomalous,

276
00:19:28,280 --> 00:19:35,560
try to then go and understand why they are anomalous, and stick into the energy thing.

277
00:19:35,560 --> 00:19:39,720
You can then think about the same thing of saying, hey, now I'm not going to look at electricity

278
00:19:39,720 --> 00:19:42,040
purchase, but I might look at generation.

279
00:19:42,040 --> 00:19:48,760
So South Africa has been trying to build on more renewable energy, and you have a couple

280
00:19:48,760 --> 00:19:52,680
of research that we're interested in, hey, where should we be putting wind farms in the

281
00:19:52,680 --> 00:19:53,680
country?

282
00:19:53,680 --> 00:19:58,680
So we've got a couple, like, you know, a lot of data with wind data from, for all of South

283
00:19:58,680 --> 00:20:03,200
Africa, with, you know, about five, five by five kilometer pixels, and I work with some

284
00:20:03,200 --> 00:20:10,000
students then to say, what way are the most suitable places for wind farms given some constraints,

285
00:20:10,000 --> 00:20:13,960
like this place where you can build, you can be too close to communities, you can be

286
00:20:13,960 --> 00:20:18,920
too close to national parks, you can be too far away from roads, you can be too far away

287
00:20:18,920 --> 00:20:22,160
from distribution lines, those, those type of things.

288
00:20:22,160 --> 00:20:25,720
And with that, it kept on continuing where it's like, okay, fine, now you kind of know

289
00:20:25,720 --> 00:20:30,160
where your wind farms are going to be, now you want to predict how much wind you're going

290
00:20:30,160 --> 00:20:36,960
to have, let's say, over the next, the next couple of days, and then, or a couple of hours

291
00:20:36,960 --> 00:20:39,040
because then you can then predict the amount.

292
00:20:39,040 --> 00:20:44,640
So that's been going on with a couple of collaborators working in energy kind of a prediction.

293
00:20:44,640 --> 00:20:45,800
Yeah.

294
00:20:45,800 --> 00:20:50,040
So there's a bunch of interesting stuff to dive into there.

295
00:20:50,040 --> 00:20:56,200
Maybe to get started, I've got some questions about this wind farm placement problem.

296
00:20:56,200 --> 00:20:59,520
And in particular, folks have approached this placement problem with different types

297
00:20:59,520 --> 00:21:04,080
of optimizations that aren't necessarily machine learning.

298
00:21:04,080 --> 00:21:08,280
What does machine learning add to the mix in this particular type of problem?

299
00:21:08,280 --> 00:21:14,720
And how do you, what kinds of data science methods do you end up applying?

300
00:21:14,720 --> 00:21:15,720
Sure.

301
00:21:15,720 --> 00:21:23,200
So with the placement, when I work, we work with a student at African Institute for

302
00:21:23,200 --> 00:21:26,320
Mathematical Sciences, and then we use the suitability method.

303
00:21:26,320 --> 00:21:30,080
So yes, it wasn't machine learning, I was just a kind of statistical mathematical model

304
00:21:30,080 --> 00:21:37,600
that said, given what you rank, what's important to you, and given the rankings, then it changes

305
00:21:37,600 --> 00:21:38,600
the suitability.

306
00:21:38,600 --> 00:21:39,600
Got it.

307
00:21:39,600 --> 00:21:40,600
Yeah.

308
00:21:40,600 --> 00:21:47,200
So the student, Shanei Franckran, she worked on a suitability model, and that model we're

309
00:21:47,200 --> 00:21:52,640
able then to tweak it, you can then say, okay, I'm not really interested in the environmental

310
00:21:52,640 --> 00:21:54,360
things, for example.

311
00:21:54,360 --> 00:21:57,760
Like, you know, if you are that way inclined, then you could remove it.

312
00:21:57,760 --> 00:22:00,400
And then from there, we'll say, okay, these are the best places to build.

313
00:22:00,400 --> 00:22:06,440
You might say, yeah, the cost of how far I should be from roads, don't really care about

314
00:22:06,440 --> 00:22:07,440
it.

315
00:22:07,440 --> 00:22:11,400
And then it would change kind of the suitability.

316
00:22:11,400 --> 00:22:17,680
But where machine learning comes in now is on the flip side of saying, okay, fine.

317
00:22:17,680 --> 00:22:21,520
One other thing that comes into perspective is that you might have an area.

318
00:22:21,520 --> 00:22:26,400
You have some historical data in terms of how much wind was being generated.

319
00:22:26,400 --> 00:22:31,600
And now you're interested in how much wind will be generated over the next 24 hours.

320
00:22:31,600 --> 00:22:37,160
So you build, you build your wind farm, and you just need to make a decision on am I going

321
00:22:37,160 --> 00:22:41,360
to have to, like, you know, fire up my cold power station or my nuclear power station.

322
00:22:41,360 --> 00:22:44,120
I don't think nuclear power stations probably just go on and off.

323
00:22:44,120 --> 00:22:50,080
But let's say my cold power station, but I need to know kind of what's going to happen

324
00:22:50,080 --> 00:22:51,080
tomorrow.

325
00:22:51,080 --> 00:22:58,200
So they've been continuing collaborations with Boubacard Ames, with a couple of other students

326
00:22:58,200 --> 00:23:04,360
to then say, hey, can we build predictive models that can then just predict 12 hours ahead.

327
00:23:04,360 --> 00:23:08,480
And we've also brought in the Colleen Huerta, who's also at CSR, who had worked on a couple

328
00:23:08,480 --> 00:23:09,640
of models before.

329
00:23:09,640 --> 00:23:12,600
But now we're using deep learning for that.

330
00:23:12,600 --> 00:23:20,800
In this whole wind farm area, both the placement and the prediction of output, it's

331
00:23:20,800 --> 00:23:26,240
seen, it strikes me that there are a lot of moving parts to a problem like this.

332
00:23:26,240 --> 00:23:32,280
Can you kind of, you know, walk us through where some of the major challenges were and

333
00:23:32,280 --> 00:23:34,520
how they were addressed?

334
00:23:34,520 --> 00:23:35,760
Um, yeah.

335
00:23:35,760 --> 00:23:39,600
So getting all the data, I think, was challenging.

336
00:23:39,600 --> 00:23:46,040
So the, oh, the partly lucky thing is I have a wife who works in renewable energy.

337
00:23:46,040 --> 00:23:47,040
Okay.

338
00:23:47,040 --> 00:23:53,680
So we should have also, like, you know, spearheaded that I keep track of this research area,

339
00:23:53,680 --> 00:23:57,200
like as something that just keeps on kind of ongoing.

340
00:23:57,200 --> 00:24:03,280
So data science, step one is, yeah.

341
00:24:03,280 --> 00:24:09,000
So in this case, like, I do remember sometimes where I, like, you know, I would ask a student

342
00:24:09,000 --> 00:24:12,000
to ask and say, oh, yeah, I need access to data that matters like this.

343
00:24:12,000 --> 00:24:13,320
I don't know where to get it.

344
00:24:13,320 --> 00:24:15,800
And then I would just ask my wife and she would be like, oh, yeah, this would be on the

345
00:24:15,800 --> 00:24:19,880
Department of Environmental Affairs website and you would be able to get it.

346
00:24:19,880 --> 00:24:24,600
So things, things like protected areas, things like the national grid.

347
00:24:24,600 --> 00:24:29,200
So where all the big transmission lines are, those type of things.

348
00:24:29,200 --> 00:24:34,560
So you have to do kind of a big exercise on, on capturing from the design, I'm sorry,

349
00:24:34,560 --> 00:24:40,520
from the, like a potential client, what they take is being informative.

350
00:24:40,520 --> 00:24:42,520
And then from there saying, okay, what data do you have?

351
00:24:42,520 --> 00:24:46,880
And from the data, they don't have go in, find it outside to say, okay, we have to go

352
00:24:46,880 --> 00:24:49,080
find, find this data.

353
00:24:49,080 --> 00:24:55,640
And so were these various things that you were tracking the protected areas and the grid

354
00:24:55,640 --> 00:24:58,800
were these provided in a useful way?

355
00:24:58,800 --> 00:25:04,840
Like did you have to go from, I don't know, some kind of description to, like, bounding

356
00:25:04,840 --> 00:25:09,600
boxes or let long or something for various features?

357
00:25:09,600 --> 00:25:13,040
Yeah, so you're going to have assumptions that you're going to have to make, especially

358
00:25:13,040 --> 00:25:16,560
now you're working on like a five by five kilometer cell.

359
00:25:16,560 --> 00:25:21,520
So you could say how many wind turbines can fit or you fit in there, you're going to make

360
00:25:21,520 --> 00:25:28,080
an assumption that you're going to put only, like, you know, in one percent of the area.

361
00:25:28,080 --> 00:25:31,000
The simplest one is just to say, I'm going to put one wind turbine.

362
00:25:31,000 --> 00:25:35,680
It's not really true because what happens is that if you put wind turbines next to each

363
00:25:35,680 --> 00:25:40,760
other, they're going to have wakes, and from the wakes, they actually then impact on how

364
00:25:40,760 --> 00:25:43,960
much energy is actually going to be generated in total.

365
00:25:43,960 --> 00:25:47,200
So it's not simple, but you can make that assumption, say, I'm just going to have one wind

366
00:25:47,200 --> 00:25:48,200
turbine.

367
00:25:48,200 --> 00:25:52,240
And now I'm going to just try to figure out how much power would be generated.

368
00:25:52,240 --> 00:25:57,240
You have different heights of that wind turbine could be, you have different configurations

369
00:25:57,240 --> 00:25:58,720
of those wind turbines.

370
00:25:58,720 --> 00:26:06,560
So we had to kind of allow some flexibility with that of saying a user of the system can

371
00:26:06,560 --> 00:26:10,560
choose and say, I want to, I'm interested in wind, I mean, at a turbine that's at this

372
00:26:10,560 --> 00:26:14,240
height using this type of configuration, here's how big it's wind span.

373
00:26:14,240 --> 00:26:18,600
It's going to be, if you're trying to look at where all the major roads are, I'm trying

374
00:26:18,600 --> 00:26:23,640
to remember if we kind of did a hack on the Google Maps API, I might have been trying

375
00:26:23,640 --> 00:26:26,800
to figure out if there was a major road going through every block.

376
00:26:26,800 --> 00:26:30,040
And then from the estimating how far you are from a major highway.

377
00:26:30,040 --> 00:26:31,040
Yeah.

378
00:26:31,040 --> 00:26:36,800
So I think it was something of look, I think we had written some scripts for Google Maps

379
00:26:36,800 --> 00:26:45,080
to identify where all the highways were and how far each five, five kilometer pixel was

380
00:26:45,080 --> 00:26:46,800
from the major highway.

381
00:26:46,800 --> 00:26:52,520
And so for these various features, did you end up encoding them binarily?

382
00:26:52,520 --> 00:26:57,360
This one has a grid, doesn't have a grid, has a highway, doesn't have a highway and then

383
00:26:57,360 --> 00:27:03,720
just kind of counted pixels, or did you, were you kind of treating it more fine grain than

384
00:27:03,720 --> 00:27:04,720
that?

385
00:27:04,720 --> 00:27:09,760
As for Shane's work, there was a little bit more fine grain decisions that were made

386
00:27:09,760 --> 00:27:14,560
in just like, are you near, are you somewhere not too far and then are you far?

387
00:27:14,560 --> 00:27:20,840
And yeah, so you can have those knobs and then you can also kind of play with them.

388
00:27:20,840 --> 00:27:26,360
You can also then quantify them as cost instead and then say how costly is this going to

389
00:27:26,360 --> 00:27:27,360
be?

390
00:27:27,360 --> 00:27:31,680
And yeah, with some things a protected area, it's either it's there or it's not really,

391
00:27:31,680 --> 00:27:35,920
like, you know, so if there's a national park there, you don't build really sort of

392
00:27:35,920 --> 00:27:39,480
very negative, if I was thinking about rewards, they're going to be just a very big negative

393
00:27:39,480 --> 00:27:40,480
reward.

394
00:27:40,480 --> 00:27:41,480
Right, right.

395
00:27:41,480 --> 00:27:43,720
Yeah, kind of things like don't do it.

396
00:27:43,720 --> 00:27:47,920
And then if you had, then perfect where you had good wind because that was the other thing

397
00:27:47,920 --> 00:27:55,320
is that do you have a lot of wind that's in that area and then also what's your slope?

398
00:27:55,320 --> 00:27:56,320
So is it very sharp?

399
00:27:56,320 --> 00:28:00,240
A slope, if it is, you don't want to build there, you want to build as close to flat as possible.

400
00:28:00,240 --> 00:28:06,840
And you mentioned that some of these various data sets were on government websites was

401
00:28:06,840 --> 00:28:11,920
this project something that could have been done by anyone was or all the data sets publicly

402
00:28:11,920 --> 00:28:17,240
available or was there some private data that was used to figure this out?

403
00:28:17,240 --> 00:28:23,240
Yeah, so the wind data specifically, not that there is wind data that you can get for

404
00:28:23,240 --> 00:28:28,080
South Africa, that's open, but the one that we're using was one that was part of a study

405
00:28:28,080 --> 00:28:31,720
inside the CSR, so they did give access to the students to work on it.

406
00:28:31,720 --> 00:28:32,720
Okay.

407
00:28:32,720 --> 00:28:35,880
Yeah, yeah, on there, so you wouldn't necessarily have access to that, but I can point out

408
00:28:35,880 --> 00:28:43,400
people to kind of, I think there's a couple of stations across South Africa that are

409
00:28:43,400 --> 00:28:49,160
used and have public data, where if you want to go download the wind, I think it's called

410
00:28:49,160 --> 00:28:54,840
Wind Atlas South Africa, you can get data, but it would be for specific areas that are

411
00:28:54,840 --> 00:29:00,920
covered at the moment, but not every cell, the one that we had was a model that was used

412
00:29:00,920 --> 00:29:03,480
to extrapolate for the whole country, what the wind map would have been.

413
00:29:03,480 --> 00:29:07,680
Yeah, you also mentioned you did something on the utility side, is that there was different

414
00:29:07,680 --> 00:29:09,880
than the wind farm project?

415
00:29:09,880 --> 00:29:16,440
Yeah, yeah, so again, with the social impact, what I've been trying to do is get to point

416
00:29:16,440 --> 00:29:21,720
we're working with some of the local municipalities here in South Africa to look at some of their

417
00:29:21,720 --> 00:29:23,760
kind of problems.

418
00:29:23,760 --> 00:29:27,760
So with there, we had worked on, you've got electricity data in terms of purchases on

419
00:29:27,760 --> 00:29:32,440
a monthly basis, and from there, you can do kind of things, you can build, do analytics

420
00:29:32,440 --> 00:29:36,920
where you're just looking at, okay, what's kind of the span patterns, one which I still

421
00:29:36,920 --> 00:29:44,400
want to work on is now looking at these deviations from those spending patterns to try to identify

422
00:29:44,400 --> 00:29:45,400
behavior.

423
00:29:45,400 --> 00:29:53,920
So one that the city was interested in, Steve Swanee where I live and I work is could somebody

424
00:29:53,920 --> 00:29:59,920
have an install solar for you, for example, and how would we then capture that in the system

425
00:29:59,920 --> 00:30:05,880
and the students we're working with on that also kind of try to figure out a couple of

426
00:30:05,880 --> 00:30:07,520
heuristics to do this.

427
00:30:07,520 --> 00:30:11,920
So one was bringing in weather data again and looking at days or months that were particularly

428
00:30:11,920 --> 00:30:18,400
humid or they had lots of cloud cover during those months, you would expect that the solar

429
00:30:18,400 --> 00:30:21,880
use would be less because there would be less power actually generated and then you want

430
00:30:21,880 --> 00:30:26,720
to then see if that meant that the household during that time would then spend more on buying

431
00:30:26,720 --> 00:30:28,680
electricity from the city.

432
00:30:28,680 --> 00:30:32,440
What were the data sources that were used there?

433
00:30:32,440 --> 00:30:36,760
So that one, the data is internal to the city in terms of the electricity purchase data

434
00:30:36,760 --> 00:30:41,880
and then external is like using weather information and then using mapping which you have access

435
00:30:41,880 --> 00:30:44,200
to mapping for the country.

436
00:30:44,200 --> 00:30:47,680
So it's not as involved as the wind prediction one.

437
00:30:47,680 --> 00:30:51,400
Okay, and what kind of models did you end up producing for that?

438
00:30:51,400 --> 00:30:54,760
We're still trying to work on some anomaly detection models for it so that's not complete

439
00:30:54,760 --> 00:31:00,880
as yet but we are working on writing up on the analytics part of the work and then there's

440
00:31:00,880 --> 00:31:07,880
one on trying to look at the segmentation of the customers.

441
00:31:07,880 --> 00:31:12,000
So we're actually using a recent see if you can see monetary value analysis that's called

442
00:31:12,000 --> 00:31:17,760
RFM and it's used a lot in marketing but then using it now to understand the different

443
00:31:17,760 --> 00:31:21,800
baskets of customers that the city has.

444
00:31:21,800 --> 00:31:24,040
I'm sorry, what was the RFM?

445
00:31:24,040 --> 00:31:26,600
Renaissance frequency and monetary value.

446
00:31:26,600 --> 00:31:32,640
Let's see frequency monetary value and can you give us an overview of that model?

447
00:31:32,640 --> 00:31:40,320
Sure, you calculate for each customer in the last six months how much they have they

448
00:31:40,320 --> 00:31:45,320
bought, when's the last time they bought and how many times have they bought?

449
00:31:45,320 --> 00:31:49,080
For example, and from there you're then going to find some baskets so you can find that

450
00:31:49,080 --> 00:31:54,480
oh there's baskets of people buy a lot, five very frequently and they bought within the

451
00:31:54,480 --> 00:31:59,600
last month and some people might be that they buy very infrequently by small amounts

452
00:31:59,600 --> 00:32:01,840
and yeah, there's a little.

453
00:32:01,840 --> 00:32:07,600
Okay, and so you're using those metrics, the recent see frequency and value as a way

454
00:32:07,600 --> 00:32:10,920
to kind of cluster or segment the customer base?

455
00:32:10,920 --> 00:32:15,400
Yeah, it's a clustering mechanism basically and you can test it against your things like

456
00:32:15,400 --> 00:32:17,120
your k-means as well.

457
00:32:17,120 --> 00:32:20,920
The goal in applying that technique is what?

458
00:32:20,920 --> 00:32:27,440
So there is then you can think about what if then I wanted to estimate, if some of my

459
00:32:27,440 --> 00:32:32,560
customers are in one batch and I was too fine to move them to another batch, what could

460
00:32:32,560 --> 00:32:35,520
be the impact on my revenue, right?

461
00:32:35,520 --> 00:32:41,520
Because each group will have specific characteristics and there might be that you're trying to identify

462
00:32:41,520 --> 00:32:47,920
and say okay, maybe then you have people who would likely be moving to solar or something

463
00:32:47,920 --> 00:32:52,960
like that, so if I then said the people who are frequent users started using solar and

464
00:32:52,960 --> 00:32:58,600
they move to another batch, how much money would I lose from them moving to solar, but

465
00:32:58,600 --> 00:33:02,960
maybe how much could I gain if I offered a product that was much more compatible to households

466
00:33:02,960 --> 00:33:04,120
that you solar.

467
00:33:04,120 --> 00:33:10,440
So one might be I buy electricity from them at different times of the day and then I

468
00:33:10,440 --> 00:33:14,240
sell it to them back at night but I can take that same electricity I bought from them

469
00:33:14,240 --> 00:33:17,720
and I sell it to other people also and make more revenue.

470
00:33:17,720 --> 00:33:19,880
So it's kind of gaining those insights.

471
00:33:19,880 --> 00:33:27,080
You also mentioned the public safety project that was based on some social media analysis?

472
00:33:27,080 --> 00:33:32,480
Yeah, so this has been like a thread now that's run through probably the last few years

473
00:33:32,480 --> 00:33:35,520
is just working on natural language in one way or another.

474
00:33:35,520 --> 00:33:42,640
So initially when I started 2015 or so it was just to go like okay, could we use social

475
00:33:42,640 --> 00:33:48,520
media as a way to identify if there's public safety issues, so you just want it's a very

476
00:33:48,520 --> 00:33:51,400
cost and not accurate way.

477
00:33:51,400 --> 00:33:56,040
So one could be I wanted if people are complaining about an accident and they describe that there's

478
00:33:56,040 --> 00:34:01,560
an accident in a specific area in the city, could we pinpoint that and then from there

479
00:34:01,560 --> 00:34:06,080
kind of come up with a map that is just showing you from people going on to our public

480
00:34:06,080 --> 00:34:12,840
Facebook pages and putting this up so that way we kind of started and we worked on the

481
00:34:12,840 --> 00:34:20,720
kind of a initial model that was very basic language processing model and then we worked

482
00:34:20,720 --> 00:34:25,400
on it to then say okay one of the challenges that you have is that you can't really label

483
00:34:25,400 --> 00:34:32,280
a lot of the data so you can only label like some subset of it so that we worked on then

484
00:34:32,280 --> 00:34:37,400
doing kind of something like very rudimentary semi-supervised learning where you take a

485
00:34:37,400 --> 00:34:41,360
model, you take your data that you've labeled, you train a model and then you try to train

486
00:34:41,360 --> 00:34:45,720
more of the stuff that you haven't seen and you want to see if it will actually impact

487
00:34:45,720 --> 00:34:51,240
your performance, we took into account maybe even network effects so identifying kind

488
00:34:51,240 --> 00:34:54,800
of stuff about who's posting because there's these questions that come up about can you

489
00:34:54,800 --> 00:34:58,680
trust all the information that you get on social media maybe there's things like if you

490
00:34:58,680 --> 00:35:06,520
have somebody who has no followers and it just recently showed up maybe it's not you

491
00:35:06,520 --> 00:35:12,000
should just fill that out and not try to classify that and then start working with a couple

492
00:35:12,000 --> 00:35:19,440
of students like on things around like you know again using short text data for a couple

493
00:35:19,440 --> 00:35:25,680
of things so one is being one PhD student who's working on identifying authors so it's

494
00:35:25,680 --> 00:35:30,560
getting connected to this kind of trusting so saying who actually wrote this like you

495
00:35:30,560 --> 00:35:36,920
know a short piece of text and can we identify that so he's been working on kind of deep learning

496
00:35:36,920 --> 00:35:44,960
frameworks to be able to do that and there's been more work in now extending some of what

497
00:35:44,960 --> 00:35:52,320
we had done on using short text as a way to understand so right now still working on

498
00:35:52,320 --> 00:35:58,520
some methods to bring in more robustness in learning from short text without a lot

499
00:35:58,520 --> 00:36:04,280
of data so what what might happen or what I'm like hypothesizing is that if you're using

500
00:36:04,280 --> 00:36:09,560
social media as a data source some of the things that might happen over time is that there's

501
00:36:09,560 --> 00:36:16,560
a quick change in language sometimes and because of this and also because you have got like

502
00:36:16,560 --> 00:36:20,920
you know not that many words people might say the same thing in multiple ways but you

503
00:36:20,920 --> 00:36:24,240
don't have again you know you're not a Google you're not a Facebook so you're not going

504
00:36:24,240 --> 00:36:30,240
to have infinite amount of almost infinite amount of resources to actually label everything

505
00:36:30,240 --> 00:36:34,000
that you have what you might have a subset that's labeled and how can you use that smaller

506
00:36:34,000 --> 00:36:40,600
subset of data and try to make it kind of bigger and then by that improve how your machine

507
00:36:40,600 --> 00:36:44,720
learning model is actually going to perform over time so you don't want it that you train

508
00:36:44,720 --> 00:36:47,600
something and then three years later it actually is really bad.

509
00:36:47,600 --> 00:36:54,960
You mentioned that in there this kind of sub project of identifying the author of short

510
00:36:54,960 --> 00:37:00,560
pieces of text can you elaborate on that you're meaning identifying the author of a tweet

511
00:37:00,560 --> 00:37:06,440
for example or identifying the author meaning so you have the tweet but not the account

512
00:37:06,440 --> 00:37:13,320
that posted it or you trying to correlate it with authors that are outside of social media

513
00:37:13,320 --> 00:37:20,280
or what exactly you're trying to do there. Yeah so there I'll use a like okay more

514
00:37:20,280 --> 00:37:26,440
topical example today is this that you might have yes a short piece of text and what you're

515
00:37:26,440 --> 00:37:31,400
trying you you you say it sure it says it's from this person like you know they're saying

516
00:37:31,400 --> 00:37:36,360
it's from me but then you can actually look at the content and say oh actually this is

517
00:37:36,360 --> 00:37:41,800
not from this person this type of content is actually generated by these other people right

518
00:37:41,800 --> 00:37:47,320
so typically yes this might move into hey how does fake news get generated there's likely

519
00:37:47,320 --> 00:37:53,000
some generator that's like you know not that level we hope so that's one way you can think

520
00:37:53,000 --> 00:37:57,480
about it another way you can think about it's like you know you can see people taking content

521
00:37:57,480 --> 00:38:03,240
without attribution on there and you can kind of build up a source of kind of way of linguistics

522
00:38:03,240 --> 00:38:11,560
style that's that has happened I mean sorry that is in in that text so abedium woodoube who's

523
00:38:11,560 --> 00:38:18,680
supervising his PhD he's working on that and it's been kind of a way to to understand like

524
00:38:18,680 --> 00:38:24,200
you know oh this is actually real new content it's not something that somebody else posted

525
00:38:24,200 --> 00:38:29,160
before and this person might be just like you know reposting in kind of in a way you can think

526
00:38:29,160 --> 00:38:34,280
about it in terms of bots of identifying bots you can think about it in terms of terrorism in

527
00:38:34,280 --> 00:38:39,640
terms of trying to identify where source of information might have come from are you comparing it

528
00:38:39,640 --> 00:38:45,720
to other things that that user has tweeted to see if it's anomalous relative to what they've

529
00:38:45,720 --> 00:38:53,880
tweeted are you comparing it to the entire corpus to see if there's some large group of users that

530
00:38:53,880 --> 00:39:00,840
are all kind of tweeting the same things or the same way are you comparing it to some offline

531
00:39:00,840 --> 00:39:08,440
you know totally offline corpus to see if you can correlate others in one corpus to tweets

532
00:39:09,640 --> 00:39:13,480
it seems like you can do a ton of different things with this there's yeah there's a lot of

533
00:39:13,480 --> 00:39:19,240
different ways so yes one which you've highlighted we're not doing it in this case is you you

534
00:39:19,240 --> 00:39:23,480
could just look at the behavior of a person and like you know okay they write about this they tweet

535
00:39:23,480 --> 00:39:27,640
about this they might be a blog like you know they blog about this and then something shows up and

536
00:39:27,640 --> 00:39:34,200
you're like okay something's off here and that flags like you know saying hmm something is odd

537
00:39:34,840 --> 00:39:41,480
but then that doesn't really give you kind of power to then say okay where could this have come

538
00:39:41,480 --> 00:39:47,240
from but that's maybe you can then put that as a second item and say we're going to deal with this

539
00:39:47,240 --> 00:39:54,040
but a way that is like the maybe the simplest way to think about it is that you could say okay

540
00:39:54,040 --> 00:39:59,160
I'm going to characterize for something major where content comes from right so if you're looking

541
00:39:59,160 --> 00:40:04,200
at bloggers so you could if you were medium build up a huge database of all your bloggers

542
00:40:04,200 --> 00:40:08,440
and what they create and then you build a machine learning model that then every time you get a

543
00:40:08,440 --> 00:40:13,800
piece of content you can say oh it comes from this author right with with high probability I can

544
00:40:13,800 --> 00:40:18,280
tell you that this is the author who like the wrote wrote that thing but then yesterday you're

545
00:40:18,280 --> 00:40:23,720
scaling with lots lots of labels right because now you have a multi-class problem and you could have

546
00:40:23,720 --> 00:40:30,200
hundreds of thousands of labels that then put if then if you're Twitter you know millions if not

547
00:40:30,200 --> 00:40:38,440
billions over time that you've kind of gotten into so the classes might be different given different

548
00:40:38,440 --> 00:40:45,160
constraints so one you might just say is this original if is it not like and and and that could be

549
00:40:45,160 --> 00:40:51,240
a simple dichotomy that you then use as a labeler and then you want to now build the architecture

550
00:40:51,240 --> 00:40:54,600
like a deep learning architecture that can learn well from that because you don't have a

551
00:40:54,600 --> 00:41:00,760
and long space string of text you then can do even other things you can then say okay fine

552
00:41:00,760 --> 00:41:05,800
I'm not going to look at one treat an isolation maybe I look at the last five treats all right and

553
00:41:05,800 --> 00:41:11,560
then see what's actually do you go on what kinds of models are you looking at with that one

554
00:41:11,560 --> 00:41:17,400
on the deep left side yeah it's kind of kind of kind of based text models and yeah using

555
00:41:17,400 --> 00:41:22,120
auto n's and CNN's maybe that to kind of wrap things up I'm wondering as you look across this

556
00:41:22,120 --> 00:41:31,160
portfolio of projects focused on social impact applications of data science are there common threads

557
00:41:31,160 --> 00:41:38,360
or trends or challenges that you tend to see when you're trying to apply this set of tools to

558
00:41:38,360 --> 00:41:44,840
these types of problems or you know do they vary widely and don't have you know any any common

559
00:41:44,840 --> 00:41:51,800
alities yeah there's some things you learn through through time so so one is kind of how to

560
00:41:51,800 --> 00:41:57,720
define projects in a good way is good so you have to have a common language with who you're

561
00:41:57,720 --> 00:42:02,520
working with so people come to you and say we have this problem we think machine learning can

562
00:42:02,520 --> 00:42:08,360
assist like you know and then you go like okay what kind of data do you have and why do you think

563
00:42:08,360 --> 00:42:13,960
kind of predictions might help or anomaly detection might help and taking the time to kind of get

564
00:42:13,960 --> 00:42:22,840
a common language is useful because then it I think makes it much more interesting one is to stay

565
00:42:22,840 --> 00:42:27,800
away from like you know taking the ham like you know the hammer that you have and everything

566
00:42:27,800 --> 00:42:33,240
looking like a nail is that analogy yeah so sometimes you just go in and go like okay yeah

567
00:42:33,240 --> 00:42:37,960
maybe this is not for me I think you can solve this very simply we we don't need to do it in this

568
00:42:37,960 --> 00:42:43,480
way so let's get let's get somebody to help you with the simple way to to to kind of do that

569
00:42:44,440 --> 00:42:50,440
with other things like I've been with with natural language processing it's been interesting

570
00:42:50,440 --> 00:42:56,520
because you have a problem like one I hope to really get going is looking at things like

571
00:42:56,520 --> 00:43:02,040
compositional systems for like people who are working together in organizations I'd seen this

572
00:43:02,040 --> 00:43:07,640
from looking at some kind of work as a working government and they chat a lot and you might not

573
00:43:07,640 --> 00:43:11,320
have a way to track what's actually going on in there but now you're thinking oh machine learning

574
00:43:11,320 --> 00:43:15,400
could be useful in there because you can identify the context of what anybody's saying and like

575
00:43:15,400 --> 00:43:21,480
you know at any time and from there be able to a guide in resolving a problem that they're trying

576
00:43:21,480 --> 00:43:28,760
to work together to solve in a way so that brings in kind of a lot of layers of of things so I

577
00:43:28,760 --> 00:43:32,680
enjoy that I guess the problem kind of solving maybe it's part of my engineering background

578
00:43:33,560 --> 00:43:37,080
saying okay fine there's this problem that's out there how you break it down and how do you

579
00:43:37,080 --> 00:43:41,320
then take out the chunks that you'll do some science on and then some other parts are practical

580
00:43:41,320 --> 00:43:45,240
who do you have as a as a as a as a collaborated and who will take care of the practical parts and

581
00:43:45,240 --> 00:43:49,800
then I'll go look at some of the machine learning with a couple of of the students I work with or

582
00:43:49,800 --> 00:43:58,120
the other collaborators that I work with and and we work on that the other one is yeah maybe

583
00:43:58,120 --> 00:44:06,600
that also drives me is seeing people are trying things out there I'm yeah I'm organizing a workshop

584
00:44:06,600 --> 00:44:12,120
at International Data Week which is on the first from the 4th to the 8th of November and we have

585
00:44:12,120 --> 00:44:17,320
a session there on data for good and again going to see people and I know you're going to see

586
00:44:17,320 --> 00:44:23,480
people like an education trying to use data science and educate in education settings and seeing

587
00:44:23,480 --> 00:44:27,480
the problems that they're kind of having and all the time it's like you know that thing of like

588
00:44:27,480 --> 00:44:34,680
quantifying some behavior and then trying to use that to either predict or diagnose and because

589
00:44:34,680 --> 00:44:39,560
you're seeing all these people it means that there's also the decision makers behind them so these

590
00:44:39,560 --> 00:44:45,000
decision makers are trying to go like okay we know we've kind of gotten this data that we've

591
00:44:45,000 --> 00:44:49,800
either been collecting ourselves like given like example the municipality using electricity data

592
00:44:49,800 --> 00:44:57,000
but we really need to use it to improve the services that we provide for citizens and it's

593
00:44:57,000 --> 00:45:01,560
yeah it's rewarding in that way that if you come up with something and it's like you know it really

594
00:45:01,560 --> 00:45:06,680
gives some insight that people didn't know before that it could actually then make impact you

595
00:45:06,680 --> 00:45:11,880
know right there in your community that's great well because he thanks so much for taking the time

596
00:45:11,880 --> 00:45:18,360
to chat with us I enjoyed learning about the the various projects that you're working on

597
00:45:18,360 --> 00:45:26,280
yep thank you for having me and yeah I guess we look forward to again having people next year

598
00:45:26,280 --> 00:45:33,160
next year's in Dava there's obviously a couple of workshops that are coming up in different spaces

599
00:45:33,160 --> 00:45:39,240
or conferences that I might be at or some of my other collaborators on so yeah I'm on to it

600
00:45:39,240 --> 00:45:47,000
so you can find me are you at nips this year I will be speaking at black and AI okay yeah so I will

601
00:45:47,000 --> 00:45:56,360
be in Canada so it's just yeah making sure I can get there but yeah yeah I will be there like what

602
00:45:56,360 --> 00:46:02,040
are the things now again being back in in the south that low south is I haven't had to experience

603
00:46:02,040 --> 00:46:11,160
the winters and then so it's like oh damn you're going to be in Canada in December yeah yeah yeah so

604
00:46:11,160 --> 00:46:16,840
so yeah I need like you know spend some time in New Jersey so the winters were nice and ones the

605
00:46:16,840 --> 00:46:21,560
nice because the snow is beautiful but at the same time they really were depressing so being

606
00:46:21,560 --> 00:46:26,600
back in south it's been very nice because yeah they're like oh it's winter you're like no it's not

607
00:46:29,800 --> 00:46:35,160
nice nice well I'm looking forward to to meet you in Canada then okay thank you

608
00:46:35,160 --> 00:46:44,280
awesome take care all right everyone that's our show for today for more information on buccosi

609
00:46:44,280 --> 00:46:52,680
or any of the topics covered in this show visit twimmel ai.com slash talk slash 193 thanks again

610
00:46:52,680 --> 00:46:58,280
to google for their sponsorship of this series be sure to check out the 2019 AI residency program

611
00:46:58,280 --> 00:47:06,440
at g.co slash AI residency as always thanks so much for listening and catch you next time

